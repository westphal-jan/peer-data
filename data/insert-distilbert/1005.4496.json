{"id": "1005.4496", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2010", "title": "Combining Naive Bayes and Decision Tree for Adaptive Intrusion Detection", "abstract": "in this paper, a new learning algorithm for adaptive organizational network intrusion detection using naive bayesian polynomial classifier and decision procedure tree is presented, which performs balance detections and keeps false positives at acceptable level for different types of network attacks, and eliminates redundant detection attributes as well as contradictory examples from training data that make the detection model complex. the proposed algorithm also addresses some difficulties of data mining such as handling continuous attribute, dealing with unwanted missing attribute values, and reducing error noise in training data. nevertheless due to the large volumes of security audit data as well as the complex and dynamic properties of intrusion behaviours, several data miningbased intrusion detection techniques have been applied to network - based traffic data and host - based management data in the last decades. however, there remain various issues while needed to be examined towards current intrusion detection systems ( ids ). we tested the performance of our proposed algorithm with existing learning algorithms by employing on the kdd99 benchmark intrusion detection dataset. essentially the experimental results prove that the proposed algorithm achieved high detection rates ( dr ) and significant reduce false positives ( fp ) for different types of network intrusions using limited computational resources.", "histories": [["v1", "Tue, 25 May 2010 07:47:00 GMT  (477kb)", "http://arxiv.org/abs/1005.4496v1", "14 Pages, IJNSA"]], "COMMENTS": "14 Pages, IJNSA", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["dewan md farid", "nouria harbi", "mohammad zahidur rahman", "university lumiere lyon 2 - france", "jahangirnagar university", "bangladesh)"], "accepted": false, "id": "1005.4496"}, "pdf": {"name": "1005.4496.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["COMBINING NAIVE BAYES", "Dewan Md. Farid", "Nouria Harbi", "Mohammad Zahidur Rahman"], "emails": ["dewanfarid@gmail.com,", "nouria.harbi@univ-lyon2.fr", "rmzahid@juniv.edu"], "sections": [{"heading": null, "text": "10.5121/ijnsa.2010.2202 12\nIn this paper, a new learning algorithm for adaptive network intrusion detection using naive Bayesian classifier and decision tree is presented, which performs balance detections and keeps false positives at acceptable level for different types of network attacks, and eliminates redundant attributes as well as contradictory examples from training data that make the detection model complex. The proposed algorithm also addresses some difficulties of data mining such as handling continuous attribute, dealing with missing attribute values, and reducing noise in training data. Due to the large volumes of security audit data as well as the complex and dynamic properties of intrusion behaviours, several data miningbased intrusion detection techniques have been applied to network-based traffic data and host-based data in the last decades. However, there remain various issues needed to be examined towards current intrusion detection systems (IDS). We tested the performance of our proposed algorithm with existing learning algorithms by employing on the KDD99 benchmark intrusion detection dataset. The experimental results prove that the proposed algorithm achieved high detection rates (DR) and significant reduce false positives (FP) for different types of network intrusions using limited computational resources.\nKEYWORDS\nDecision Tree, Detection Rate, False Positive, Naive Bayesian classifier, Network Intrusion Detection"}, {"heading": "1. INTRODUCTION", "text": "An \u201cIntrusion Detection System (IDS)\u201d is a system for detecting intrusions that attempting to misuse the data or computing resources of a computer system. Mostly intrusions are the violation of information security policy. At first IDS was implemented for host-based that located in servers to examine the internal interfaces [1]-[3], but with the evolution of computer networks the focus gradually shifted toward network-based. Network intrusion detection system (NIDS) performs packet logging, real-time traffic analysis of IP network, and tries to discover if an intruder is attempting to break into the system [4]-[6]. Snort is an open source network intrusion detection and prevention system (NIDPS) developed by Sourcefire [7], [8]. Snort performs protocol analysis, content searching/matching, and commonly blocks a variety of intrusions such as buffer overflows, stealth port scans, web application attacks, SMB probes, and OS fingerprinting attempts. Normally, intruders in computer system are classified into two categories like internal and external intruders. Internal intruders are users in the network and have some authority, but seek to gain additional ability to take action without legitimate authorization. External intruders do not have any authorized access to the system that they attack. Two types of detection models: misuse and anomaly are commonly using by IDS. Misuse detection model performs simple pattern matching techniques to match an attack pattern corresponding to known attack patterns in the database and produces very low false positives\n(FP). Anomaly detection model identifies new attacks by analyzing the anomalous behaviors from normal behaviors [9], and achieves high detection rates (DR) for new attacks, but produces many false positives (FP). Anomaly based IDS generate rules by observing collected audit data that is the records of activities generated by the operating system. Currently adaptive intrusion detection aims to solve the problems of analyzing the huge volumes of audit data and realizing performance optimization of detection rules [10]-[14].\nDetecting intrusions using data mining algorithms such as decision tree (DT), na\u00efve Bayesian (NB) [15], neural network (NN), support vector machine (SVM) [16], k-nearest neighbors (KNN), fuzzy logic model [17], and genetic algorithm [18] have been widely used in the last decades. However, there exist various problems in current IDS such as low detection accuracy, unbalanced detection rates for different types of attacks, high false positives, redundancy of input attributes as well as examples in the training data. Another difficulty of current IDS is to detect intrusions in real time high-speed networks, because the high-speed networks require IDS to deal with large volumes of network data in a very short time. In this paper, based on a comprehensive analysis for the current research challenges in intrusion detection, a new learning algorithm for adaptive network intrusion detection using naive Bayesian classifier and decision tree is presented, which can handle the above mentioned challenging issues. This paper also addresses some difficulties of data mining such as handling continuous attribute, dealing with missing attribute values, and reducing noise in training data. The experimental results by using KDD99 benchmark intrusion detection dataset prove that the proposed algorithm has achieved both high detection rates (DR) and the significant reduction of false positives (FP) in comparison with existing methods.\nThe remainders of the paper are organized as follows. Section 2 presents the related overview of networking and intrusion detection. The basic problems of learning are discussed in Section 3, whereas our proposed algorithm is introduced in Section 4. Then, the experimental results are expressed in Section 5. Finally, our conclusions and future works are mentioned in Section 6."}, {"heading": "2. NETWORKING AND INTRUSION DETECTION OVERVIEW", "text": ""}, {"heading": "2.1. Networking Overview", "text": "In the networks, TCP/IP is widely used for network communications, which are composed of four layers: application layer, transport layer, network layer, and hardware layer that work together [19]. When data transfers across the networks, the data passes from the highest layer through intermediate layers to the lowest layer. The lowest layer sends the accumulated data to its destination through the physical network. Application layer sends and receives data for particular applications, such as DNS, HTTP, FTP, SMTP, and SNMP. It enables applications to transfer data between server and client, and passes application data to the transport layer. Transport layer is responsible for packaging data using TCP (Transmission control protocol) and UDP (user datagram protocol) so that it can be transmitted between hosts. Each TCP or UDP packet has a source port and a destination port number. Network layer or internet protocol (IP) layer is in charge of handling the addressing and routing of data received from the transport layer. After the network layer has encapsulated the transport layer data, the resulting logical units are referred to as packets. Each packet contains a header, which is composed of various fields. Commonly used network layer protocols are IPv4, IPv6, ICMP (internet control message protocol), and IGMP (internet group management protocol). It is also responsible for providing error and status information involving the addressing and routing of data. Hardware layer or data link layer tackles communications on the physical network components including cables, routers, switches, and network interface cards (NIC). The best known hardware layer protocol is Ethernet. Ethernet relies on the concept of a media access control (MAC) address, which is a unique six-byte value (such as 00-02-B4-DA-92-2C) permanently assigned to a particular NIC."}, {"heading": "2.2. Intrusion Detection Overview", "text": "Intrusion detection is the process of monitoring and analyzing the events in computer systems or networks to discover the signals of possible incidents, which attempt to compromise the confidentiality, integrity, and availability of computer resources. In general, IDS use misusebased and anomaly-based detection model for detecting intrusions. Misuse-based IDS are very effective for detecting known attacks but largely ineffective for detecting new attacks whose pattern has not stored in the database yet. It performs pattern matching to match an attack pattern corresponding to known attack patterns in the database. Anomaly-based IDS identify new attacks by analyzing anomalous behavior from normal behaviors. It has a relatively high detection rate for new attack, but produces many false positives. It uses profiles that are developed by monitoring the characteristics of typical activities over a period of time and then compares the characteristics of current activity to thresholds related to the profile. A networkbased IDS (NIDS) monitor and analyze network traffics, and use multiple sensors for detecting intrusions from internal and external networks [20]-[22]. IDS analyze the information gathered by the sensors, and return a synthesis of the input of the sensors to system administrator or intrusion prevention system. System administrator carries out the prescriptions controlled by the IDS. Today, data mining has become an indispensable tool for analyzing the input of the sensors in IDS. Fig. 1 shows a scenario of IDS to protect server machine from internal and external network.\nIdeally, IDS should have an attack detection rate (DR) of 100% along with false positive (FP) of 0%. Nevertheless, in practice this is really hard to achieve. The most important parameters involved in the performance estimation of IDS are shown in Table 1.\nThe metrics such as precision, recall, overall, and false alarm have been used to measure the performance of the data mining algorithm on the minority class [23]-[26]. From Table 1, precision, recall, and overall may be defined as follows.\nPrecision = FPTP\nTP\n+\n(1)\nRecall = FNTP\nTP\n+\n(2)\nOverall = TNFNFPTP\nTNTP\n+++\n+ (3)\nFalse Alarm = TNFNFPTP\nFNFP\n+++\n+ (4)\nDetection rate (DR) and false positive (FP) are used to estimate the performance of IDS [27], which are given as bellow:\nDR = 100* _\n_det_\nattacksTotal\nattacksectedTotal (5)\nFP = 100* __\n__\nprocessnormalTotal\nprocessedmisclassifTotal (6)"}, {"heading": "2.3. Related Work", "text": "In 1980, the concept of intrusion detection began with Anderson\u2019s seminal paper [40]; he\nintroduced a threat classification model that develops a security monitoring surveillance system\nbased on detecting anomalies in user behavior. In 1986, Dr. Denning proposed several models\nfor commercial IDS development based on statistics, Markov chains, time-series, etc [41]. In the\nearly 1980\u2019s, Stanford Research Institute (SRI) developed an Intrusion Detection Expert System\n(IDES) that monitors user behavior and detects suspicious events [42]. In 1988, a statistical\nanomaly-based IDS was proposed by Haystack [43], which used both user and group-based\nanomaly detection strategies. In 1996, Forrest et al. proposed an analogy between the human\nimmune system and intrusion detection that involved analyzing a program\u2019s system call sequences to build a normal profile [44]. In 2000, Valdes et al. [45] developed an anomaly\nbased IDS that employed na\u00efve Bayesian network to perform intrusion detecting on traffic\nbursts. In 2003, Kruegel et al. [46] proposed a multisensory fusion approach using Bayesian classifier for classification and suppression of false alarms that the outputs of different IDS\nsensors were aggregated to produce single alarm. In the same year, Shyu et al. [47] proposed an\nanomaly based intrusion detection scheme using principal components analysis (PCA), where PCA was applied to reduce the dimensionality of the audit data and arrive at a classifier that is a\nfunction of the principal components. In 2003, Yeung et al. [2] proposed an anomaly based\nintrusion detection using hidden Markov models that computes the sample likelihood of an observed sequence using the forward or backward algorithm for identifying anomalous. Lee et\nal. [48] proposed classification based anomaly detection using inductive rules to characterize\nsequences occurring in normal data. In 2000, Dickerson at al. [49] developed the Fuzzy Intrusion Recognition Engine (FIRE) using fuzzy logic that process the network data and\ngenerate fuzzy sets for every observed feature and then the fuzzy sets are used to detect network\nattacks. In 2003, Ramadas et al. [50] presented the anomalous network traffic detection with self\norganizing maps using DNS and HTTP services that the neurons are trained with normal\nnetwork traffic then real time network data is fed to the trained neurons, if the distance of the\nincoming network traffic is more than a preset threshold then it raises an alarm."}, {"heading": "3. BASIC PROBLEMS OF LEARNING", "text": ""}, {"heading": "3.1. Handling Noise in Dataset", "text": "Noise in the dataset is considered to be one of the most challenging issues in data mining. This is because the performance of the learning algorithms depends on the quality of dataset. The main idea of dealing with noisy data at the learning time is to avoid over-fitting the dataset. Noise handling can be carried out at different stages of rule induction and interpretation. The followings exhibit some typical noises being existed in the dataset.\n1) Missing attribute values: The simplest way for handling missing or unknown attribute value is to replace the missing attribute value with the most frequent attribute value in the\ndataset. Whereas, the most sophisticated way is to calculate the probability for attribute values and assign the probability value rather than the guessed value to each missing attribute value.\n2) Contradictory examples: The same examples appear more than once in the dataset with different class labels. Contradictory examples confuse the learning algorithms, so these\nexamples should be avoided or labeled correctly before learning.\n3) Redundant examples: There often exist multiple copies of the same example in the dataset. Redundant examples are not a problem if they do not form contradictions, but\nthis redundancy can change the decision trees produced by ID3 algorithm. For data mining, it\u2019s better to remove redundancy by keeping only a unique example in the dataset. By doing so, it not only saves the space of storage in dataset but also speeds significantly up the learning process.\n4) Incomplete attribute problem: When the essential attributes of a problem are not used to describe in the dataset. Suppose to distinguish men from women based on the\ndescriptions of a large group of people in terms of gender, height, weight, qualifications, and so on. The right attribute for men is \u201cgender = male\u201d and women is \u201cgender = female\u201d. If we cannot catch the right attribute, then the classification model will be more complex and less accurate.\n5) Misclassified examples: The examples in the dataset ware labeled with a wrong classification."}, {"heading": "3.2. Dealing with Continuous Attribute", "text": "The goal of dealing with continuous attributes is to discretized the continuous attribute containing continuous values (i.e., real numbers or integers) into a number of intervals. The discretized intervals can be treated in a similar way to nominal values during learning and classification. It is very important for discretization of continuous attribute to find the right places to set up interval borders. The simplest technique is to place the interval borders of continuous attribute values between each adjacent pair of attribute values that are not classified into the same class. Suppose the pair of adjacent values on attribute Ai are Ai1 and Ai2, \u201cA = (Ai1+Ai2)/2\u201d can be taken as an interval border. The information gain technique adopted in ID3 algorithm is another very efficient technique to find the most informative border to split the values of the continuous attribute. The maximum information gain is always considered for a cut point (the midpoint) between the values taken by two attribute values of different classes. Each value of the formula \u201cA = (Ai +Ai+1)/2\u201d where i = 1,\u2026,n-1 is a possible cut point, if Ai and Ai+1 have been taken by different class values in the dataset. The purpose of employing information gain is to check each of the possible cut points and find the best split point. In C4.5 algorithm, each of the possible cut points is not the midpoint between the two nearest values,\nrather than the greatest value in the entire dataset that does not exceed the midpoint. The na\u00efve Bayesian classifier also uses for discretization of continuous attribute values by constructing a probability curve for each class in the dataset. When the curves for every class have been constructed, interval borders are placed on each of those points where the leading curves are different from its two sides. A few other methods such as equal distance division, grouping, knearest neighbors, and fuzzy borders are also applied to the continuous attributes for discretization."}, {"heading": "3.3. Input Attribute Selection from Dataset", "text": "Effective input attribute selection from dataset before learning is very important, because irrelevant and redundant attributes of dataset may lead to complex classification model as well as reduce the classification accuracy [29]-[36]. In complex classification domains, input attributes of dataset may contain false correlations, which hamper the classification process. Some attributes in the dataset may be redundant, because the information they add is contained in other attributes. Also, some extra attributes can increase the computational time, and can have impact on the classification accuracy. Input attributes selection using data mining involves the selection of a subset of attributes d from a total of D original attributes of dataset, based on a given optimization principle that improves the performance of classifier. Finding a useful attribute subset is a form of search. Ideally, attribute selection methods search through the subsets of attributes, and try to find the best ones among the completing 2N candidate subsets according to some evaluation function."}, {"heading": "4. PROPOSED HYBRID ALGORITHM", "text": ""}, {"heading": "4.1. Proposed Learning Algorithm", "text": "Given a training data D = {t1,\u2026,tn} where ti = {ti1,\u2026,tih} and the training data D contains the following attributes {A1, A2,\u2026,An} and each attribute Ai contains the following attribute values {Ai1, Ai2,\u2026,Aih}. The attribute values can be discrete or continuous. Also the training data D contains a set of classes C = {C1, C2,\u2026,Cm}. Each example in the training data D has a particular class Cj. The algorithm first searches for the multiple copies of the same example in the training data D, if found then keeps only one unique example in the training data D (suppose all attribute values of two examples are equal then the examples are similar). Then the algorithm discreties the continuous attributes in the training data D by finding each adjacent pair of continuous attribute values that are not classified into the same class value for that continuous attribute. Next the algorithm calculates the prior P(Cj) and conditional P(Aij|Cj) probabilities in the training data D. The prior probability P(Cj) for each class is estimated by counting how often each class occurs in the training data D. For each attribute Ai the number of occurrences of each attribute value Aij can be counted to determine P(Ai). Similarly, the conditional probability P(Aij|Cj) for each attribute values Aij can be estimated by counting how often each attribute value occurs in the class in the training data D. Then the algorithm classifies all the examples in the training data D with these prior P(Cj) and conditional P(Aij|Cj) probabilities. For classifying the examples, the prior and conditional probabilities are used to make the prediction. This is done by combining the effects of the different attribute values from that example. Suppose the example ei has independent attribute values {Ai1, Ai2,\u2026,Aip}, we know P(Aik | Cj), for each class Cj and attribute Aik. We then estimate P(ei | Cj) by\nP(ei | Cj) = P(Cj) \u220fk=1\u2192p P(Aij | Cj) (7)\nTo classify the example, the algorithm estimates the likelihood that ei is in each class. The probability that ei is in a class is the product of the conditional probabilities for each attribute value with prior probability for that class. The posterior probability P(Cj | ei) is then found for each class and the example classifies with the highest posterior probability for that example.\nAfter classifying all the training examples, the class value for each example in training data D updates with Maximum Likelihood (ML) of posterior probability P(Cj|ei).\nCj = Ci\u2192 PML(Cj|ei). (8)\nThen again the algorithm calculates the prior P(Cj) and conditional P(Aij|Cj) probabilities using updated class values in the training data D, and again classifies all the examples of training data using these probabilities. If any of the training example is misclassified then the algorithm calculates the information gain for each attributes {A1, A2,\u2026,An} in the training data D.\nInfo(D) = \u2211 =\n      \u2212\nm\nj\njj\nD\nDCfreq\nD\nDCfreq\n1\n2 ||\n),( log\n||\n),( (9)\nInfo(T) = )(inf ||\n||\n1\ni\nn\ni\ni To T\nT \u2211\n=\n(10)\nInformation Gain (Ai) = Info(D)-Info(T) (11)\nAnd chooses one of the best attributes Ai among the attributes {A1, A2,\u2026,An} from the training data D with highest information gain value, Then split the training data D into sub-datasets {D1, D2,\u2026,Dn} depending on the chosen attribute values of Ai. After the algorithm estimates the prior and conditional probabilities for each sub-dataset Di = {D1, D2,\u2026,Dn} and classifies the examples of each sub-dataset Di using their respective probabilities. If any example of any subdataset Di is misclassified then the algorithm calculates the information gain of attributes for that sub-dataset Di, and chooses the best attribute Ai with maximum information gain value from sub-dataset Di, and split the sub-dataset Di into sub-sub-datasets Dij. Then again calculates the prior and conditional probabilities for each sub-sub-dataset Dij, and also classifies the examples of sub-sub-datasets using their respective probabilities. The algorithm will continue this process until all the examples of sub/sub-sub-datasets are correctly classified. When the algorithm correctly classifies all the examples then the prior and conditional probabilities for each datasets are preserved for future classification of unseen examples. The main procedure of proposed algorithm is described as follows.\nAlgorithm\nInput: Training Data, D\nOutput: Adaptive Intrusion Detection Model, AIDM\nProcedure:\nStep 1: Search the multiple copies of same example in D, if found then keeps only one unique example in D.\nStep 2: For each continuous attributes in D find the each adjacent pair of continuous attribute values that are not classified into the same class value for that continuous attribute\nStep 3: Calculate the prior probabilities P(Cj) and conditional probabilities P(Aij|Cj) in D.\nStep 4: Classify all the training examples using these prior and conditional probabilities, P(ei | Cj) = P(Cj) \u220fk=1\u2192p P(Aij | Cj).\nStep 5: Update the class value for each example in D with Maximum Likelihood (ML) of posterior probability, P(Cj|ei); Cj = Ci\u2192 PML(Cj|ei).\nStep 6: Recalculate the prior P(Cj) and conditional P(Aij|Cj) probabilities using updated class values in D.\nStep 7: Again classify all training examples in D using updated probability values.\nStep 8: If any training examples in D is misclassified then calculate the information gain for each attributes Ai = {A1, A2,\u2026,An} in D using equation (11).\nStep 9: Choose the best attribute Ai from D with the maximum information gain value.\nStep 10: Split dataset D into sub-datasets {D1, D2,\u2026,Dn} depending on the attribute values of Ai.\nStep 11: Calculate the prior P(Cj) and conditional P(Aij|Cj) probabilities of each sub-dataset Di.\nStep 12: Classify the examples of each sub-dataset Di with their respective prior and conditional probabilities.\nStep 13: If any example of any sub-dataset Di is misclassified then again calculate the information gain of attributes for that sub-dataset Di, and choose one of the best attribute Ai with maximum information gain, then split the sub-dataset Di into sub-sub-datasets Dij. Then again calculate the probabilities for each sub-sub-dataset Dij. Also classify the examples in sub-subdatasets using their respective probabilities.\nStep 14: Continue this process until all the examples are correctly classified.\nStep 15: Preserved all the prior and conditional probabilities for each dataset for future classification of unseen examples."}, {"heading": "5. EXPERIMENTAL ANALYSIS", "text": ""}, {"heading": "5.1. KDD Cup 1999 Dataset", "text": "The KDD cup 1999 dataset was used in the 3rd International Knowledge Discovery and Data Mining Tools Competition for building a network intrusion detector, a predictive model capable of distinguishing between intrusions and normal connections [37]. In 1998, DARPA intrusion detection evaluation program, a simulated environment was set up to acquire raw TCP/IP dump data for a local-area network (LAN) by the MIT Lincoln Lab to compare the performance of various intrusion detection methods. It was operated like a real environment, but being blasted with multiple intrusion attacks and received much attention in the research community of adaptive intrusion detection. The KDD99 dataset contest uses a version of DARPA98 dataset. In KDD99 dataset, each example represents attribute values of a class in the network data flow, and each class is labelled either normal or attack. The classes in KDD99 dataset can be categorized into five main classes (one normal class and four main intrusion classes: probe, DOS, U2R, and R2L).\n1) Normal connections are generated by simulated daily user behaviour such as downloading files, visiting web pages.\n2) Denial of Service (DoS) attack causes the computing power or memory of a victim machine too busy or too full to handle legitimate requests. DoS attacks are classified based on the services that an attacker renders unavailable to legitimate users like apache2, land, mail bomb, back, etc.\n3) Remote to User (R2L) is an attack that a remote user gains access of a local user/account by sending packets to a machine over a network communication, which include send-mail, and Xlock.\n4) User to Root (U2R) is an attack that an intruder begins with the access of a normal user account and then becomes a root-user by exploiting various vulnerabilities of the system. Most common exploits of U2R attacks are regular buffer-overflows, load-module, Fd-format, and Ffb-config.\n5) Probing (Probe) is an attack that scans a network to gather information or find known vulnerabilities. An intruder with a map of machines and services that are available on a network can use the information to look for exploits.\nIn KDD99 dataset these four attacks (DoS, U2R, R2L, and probe) are divided into 22 different attacks that tabulated in Table 2.\nThere are total 41 input attributes in KDD99 dataset for each network connection that have either discrete or continuous values and divided into three groups. The first group of attributes is the basic features of network connection, which include the duration, prototype, service, number of bytes from source IP addresses or from destination IP addresses, and some flags in TCP connections. The second group of attributes in KDD99 is composed of the content features of network connections and the third group is composed of the statistical features that are computed either by a time window or a window of certain kind of connections. The list of the input attributes in KDD99 dataset for each network connections is shown in the Table 3.\nTable 4 shows the number of examples in 10% training and testing data of KDD99 dataset."}, {"heading": "5.2. Experimental Analysis", "text": "In order to evaluate the performance of proposed algorithm for network intrusion detection, we performed 5-class classification using KDD99 intrusion detection benchmark dataset. All experiments were performed using an Intel Core 2 Duo Processor 2.0 GHz processor (2 MB Cache, 800 MHz FSB) with 1 GB of RAM. The results of the comparison of proposed algorithm with ID3 and with naive Bayesian classifier are in Table 5 and Table 6.\nWe tested the performance of proposed algorithm using the reduced dataset of 12 attributes and 17 attributes in KDD99 dataset, which increase the detection rate for intrusion classes that are summarized in Table 7."}, {"heading": "6. CONCLUSIONS AND FUTURE WORKS", "text": "This paper introduced a new hybrid learning algorithm for adaptive network intrusion detection using naive Bayesian classifier and ID3 algorithm, which analyzes the large volume of network data and considers the complex properties of attack behaviours to improve the performance of detection speed and detection accuracy. In this paper we have concentrated on the development of the performance of na\u00efve Bayesian classifier and ID3 algorithm. It has been successfully tested that this hybrid algorithm minimized false positives, as well as maximize balance detection rates on the 5 classes of KDD99 benchmark dataset. The attacks of KDD99 dataset detected with 99% accuracy using proposed algorithm. The future work focus on improving the false positives of remote to user (R2L) attack and apply this detection model into real world IDS."}, {"heading": "ACKNOWLEDGEMENTS", "text": "Support for this research received from ERIC Laboratory, University Lumi\u00e8re Lyon 2 \u2013 France, and Department of Computer Science and Engineering, Jahangirnagar University, Bangladesh."}], "references": [{"title": "An investigation of a compromised host on a honeynet being used to increase the security of a large enterprise network", "author": ["T. Jackson", "J. Levine", "J. Grizzard", "Owen", "H."], "venue": "IEEE workshop on Information Assurance and Security, IEEE, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Host-based intrusion detection using dynamic and static behavioral models", "author": ["D.Y. Yeung", "Y.X. Ding"], "venue": "Pattern Recognition, 36, 2003, pp. 229-243.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "A reinforcement learning approach for host-based intrusion detection using sequences of system calls", "author": ["X. Xu", "T. Xie"], "venue": "Proc. of International Conference on Intelligent Computing, Lecture Notes in Computer Science, LNCS 3644, 2005, pp. 995-1003.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "The use of honeynets to increase computer network security and user awareness", "author": ["S. Krasser", "J. Grizzard", "H. Owen", "Levine. J."], "venue": "Journal of Security Education, vol. 1, 2005, pp. 23-37.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "SVM approach with a genetic algorithm for network intrusion detection", "author": ["T. Shon", "J. Seo", "J. Moon"], "venue": "Proc. of 20 International Symposium on Computer and Information Sciences (ISCIS 2005), Berlin: Springer-Verlag, 2005, pp. 224-233.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Adaptive network intrusion detection method based on PCA and support vector machines", "author": ["X. Xu", "X.N. Wang"], "venue": "Lecture Notes in Artificial Intelligence (ADMA 2005), LNAI 3584, 2005, pp. 696-703.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "SNORT: The open source network intrusion system", "author": ["Martin Roesch"], "venue": "Official web page of Snort at http://www.snort.org/", "citeRegEx": "7", "shortCiteRegEx": null, "year": 0}, {"title": "Building intrusion pattern miner for sonrt network intrusion detection system", "author": ["L.C. Wuu", "C.H. Hung", "S.F. Chen"], "venue": "Journal of Systems and Software, vol. 80, Issue 10, 2007, pp. 1699- 1715.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "A comparative study of anomaly detection schemes in network intrusion detection", "author": ["A. Lazarevic", "L. Ertoz", "V. Kumar", "A. Ozgur", "Srivastava", "J."], "venue": "Proc. of the SIAM Conference on Data Mining, 2003.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Improving intrusion detection system through machine learning", "author": ["Sebastiaan Tesink"], "venue": "Technical Report, Series no. 07-02, ILK Research Group, Tilburg University, March, 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "ADAM: Detecting intrusion by data mining", "author": ["Barbara", "Daniel", "Couto", "Julia", "Jajodia", "Sushil", "Popyack", "Leonard", "Wu", "Ningning"], "venue": "IEEE Workshop on Information Assurance and Security, West Point, New York, June 5-6, 2001. International Journal of Network Security & Its Applications (IJNSA), Volume 2, Number 2, April 2010 23", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "A data mining and CIDF based approach for detecting novel and distributed intrusions", "author": ["W. Lee"], "venue": "Recent Advances in Intrusion Detection, 3  rd International Workshop, RAID 2000, Toulouse, France, October 2-4, 2000, Proc. Lecture Notes in Computer Science 1907 Springer, 2000, pp. 49-65.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2000}, {"title": "Adaptive Intrusion Detection: A Data Mining Approach", "author": ["W. Lee", "S. Stolfo", "K. Mok"], "venue": "Artificial Intelligence Review, 14(6), December 2000, pp. 533-567.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2000}, {"title": "Cost-based modeling and evaluation for data mining with application to fraud and intrusion detection", "author": ["J. Stolfo", "W. Fan", "W. Lee", "A. Prodromidis", "P.K. Chan"], "venue": "DARPA Information Survivability Conference, 2000.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2000}, {"title": "Na\u00efve Bayes vs. decision trees in intrusion detection systems", "author": ["N.B. Amor", "S. Benferhat", "Z. Elouedi"], "venue": "Proc. of 2004 ACM Symposium on Applied Computing, 2004, pp. 420-424.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Intrusion detection using neural networks and support vector machines", "author": ["S. Mukkamala", "G. Janoski", "A.H. Sung"], "venue": "Proc. of the IEEE International Joint Conference on Neural Networks, 2002, pp.1702-1707.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Mining fuzzy association rules and fuzzy frequency episodes for intrusion detection", "author": ["J. Luo", "S.M. Bridges"], "venue": "International Journal of Intelligent Systems, John Wiley & Sons, vol. 15, no. 8, 2000, pp. 687-703.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2000}, {"title": "An ensemble approach to intrusion detection based on improved multi-objective genetic algorithm", "author": ["YU Yan", "Huang Hao"], "venue": "Journal of Software, vol. 18, no. 6, June 2007, pp. 1369- 1378.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Guide to intrusion detection and prevention systems (IDPS)", "author": ["Karen Scarfone", "Peter Mell"], "venue": "National Institute of Standards and Technology, Gaithersburg, MD 20899-8930, NIST Special Publication 800-94, February, 2007.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-sensor agent-based intrusion detection system", "author": ["R. Wasniowski"], "venue": "Proc. of the 2 Annual Conference on Information Security, Kennesaw, Georgia, 2005, pp. 100-103.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2005}, {"title": "Using internal sensors for computer intrusion detection", "author": ["Diego Zamboni"], "venue": "Ph.D. dissertation, Purdue University, 2001.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "Intrusion detection systems and multi-sensor data fusion", "author": ["T. Bass"], "venue": "Communications of the ACM, 43(4), 2000, pp. 99-105.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2000}, {"title": "Robust classification for imprecise environment", "author": ["F. Provost", "T. Fawcett"], "venue": "Machine Learning, vol. 42/3, 2001, pp. 203-231.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Evaluating boosting algorithms to classify rare classes: Comparison and Improvements", "author": ["M. Joshi", "V. Kumar", "R. Agarwal"], "venue": "Proc. of the 1  st IEEE conference on Data Mining, San Jose, CA, 2001.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "Predicting rare classes: can boosting make any weak learner stronger", "author": ["M. Joshi", "R. Agarwal", "V. Kumar"], "venue": "Proc. of 8 ACM Conference ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Edmonton, Canada, 2002.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "Automated discovery of concise predictive rules for intrusion detection", "author": ["G. Helmer", "J.S.K. Wong", "V. Honavar", "L. Miller"], "venue": "Journal of Systems and Software, vol. 60, no. 3, 2002, pp. 165- 175.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Intrusion detection using a hybrid support vector machine based on entropy and TF-IDF", "author": ["R.C. Chen", "S.P. Chen"], "venue": "International Journal of Innovative Computing, Information, and Control (IJICIC), vol. 4, no. 2, 2008, pp. 413-424.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "PNrule: a new framework for learning classifier models in data mining (a case-study in network intrusion detection)", "author": ["R. Agarwal", "M.V. Joshi"], "venue": "Proceedings of 1  st SIAM Conference on Data Mining, 2001. International Journal of Network Security & Its Applications (IJNSA), Volume 2, Number 2, April 2010 24", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Intelligent feature extraction for ensemble of classifiers", "author": ["PVW Radtke", "R Sabourin", "T Wong"], "venue": "Proc. of 8  th International Conference on Document Analysis and Recognition (ICDAR 2005), Seoul: IEEE Computer Society, 2005, pp. 866-870.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "In defense of one-vs-all classification", "author": ["R. Rifkin", "A. Klautau"], "venue": "Journal of Machine Learning Research, 5, 2004, pp. 143-151.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Feature deduction and ensemble design of intrusion detection systems", "author": ["S. Chebrolu", "A. Abraham", "J.P. Thomas"], "venue": "Computer & Security, 24(4), 2004, pp. 295-307.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2004}, {"title": "Ensemble feature selection with the simple Bayesian classification", "author": ["A. Tsymbal", "S. Puuronen", "D.W. Patterson"], "venue": "Information Fusion, 4(2), 2003, pp. 87-100.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2003}, {"title": "Identifying important features for intrusion detection using support vector machines and neural networks", "author": ["A.H. Sung", "S. Mukkamala"], "venue": "Proc. of International Symposium on Applications and the Internet (SAINT 2003), 2003, pp. 209-217.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}, {"title": "Feature selection using multi-objective genetic algorithms for handwritten digit recognition", "author": ["LS Oliveira", "R Sabourin", "RF Bortolozzi", "CY Suen"], "venue": "Proc. of 16  th International Conference on Pattern Recognition (ICPR 2002), Quebec: IEEE Computer Society, 2002, pp. 568-571.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "Identifying key features for intrusion detection using neural networks", "author": ["S. Mukkamala", "A.H. Sung"], "venue": "Proc. of the ICCC International Conference on Computer Communications, 2002.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2002}, {"title": "A framework for constructing features and models for intrusion detection systems", "author": ["WK Lee", "SJ Stolfo"], "venue": "ACM Transactions on Information and System Security, 3(4), 2000, pp. 227- 261.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2000}, {"title": "A Detailed Analysis of the KDD CUP 99 Data Set", "author": ["M. Tavallaee", "E. Bagheri", "W. Lu", "A. Ghorbani"], "venue": "Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA) 2009.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2009}, {"title": "Testing intrusion detection systems: a critique of the 1998 and 1999 darpa intrusion detection system evaluations as performed by Lincoln laboratory", "author": ["J. McHugh"], "venue": "ACM Transactions on Information and System Security, vol. 3. Np. 4, 2000, pp. 262-294.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2000}, {"title": "Computer security threat monitoring and surveillance", "author": ["James P. Anderson"], "venue": "Technical Report 98-17, James P. Anderson Co., Fort Washington, Pennsylvania, USA, April 1980.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1980}, {"title": "An intrusion detection model", "author": ["Dorothy E. Denning"], "venue": "IEEE Transaction on Software Engineering, SE-13(2), 1987, pp. 222-232.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1987}, {"title": "Neumann \u201cRequirement and model for IDES- A real-time intrusion detection system,", "author": ["Dorothy E. Denning", "P.G"], "venue": "Computer Science Laboratory, SRI International,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1985}, {"title": "An intrusion detection system", "author": ["S.E. Smaha", "Haystack"], "venue": "Proc. of the IEEE Fourth Aerospace Computer Security Applications Conference, Orlando, FL, 1988, pp. 37-44.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 1988}, {"title": "A sense of self for Unix processes", "author": ["S. Forrest", "S.A. Hofmeyr", "A. Somayaji", "T.A. Longstaff"], "venue": "Proc. of the IEEE Symposium on Research in Security and Privacy, Oakland, CA, USA, 1996, pp. 120-128.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1996}, {"title": "Adaptive model-based monitoring for cyber attack detection", "author": ["A. Valdes", "K. Skinner"], "venue": "Recent Advances in Intrusion Detection Toulouse, France, 2000, pp. 80-92.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2000}, {"title": "Bayesian event classification for intrusion detection", "author": ["C. Kruegel", "D. Mutz", "W. Robertson", "F. Valeur"], "venue": "Proc. of the 19 Annual Computer Security Applications Conference, Las Vegas, NV, 2003. International Journal of Network Security & Its Applications (IJNSA), Volume 2, Number 2, April 2010 25", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2003}, {"title": "A novel anomaly detection scheme based on principal component classifier", "author": ["M.L. Shyu", "S.C. Chen", "K. Sarinnapakorn", "L. Chang"], "venue": "Proc. of the IEEE Foundations and New Directions of Data Mining Workshop, Melbourne, FL, USA, 2003, pp. 172-179.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2003}, {"title": "Data mining approaches for intrusion detection", "author": ["W. Lee", "S.J. Stolfo"], "venue": "Proc. of the 7 USENIX Security Symposium (SECURITY-98), Berkeley, CA, USA, 1998, pp. 79-94.", "citeRegEx": "48", "shortCiteRegEx": null, "year": 1998}, {"title": "Fuzzy network profiling for intrusion detection", "author": ["J.E. Dickerson", "J.A. Dickerson"], "venue": "Proc. of the 19  th International Conference of the North American Fuzzy Information Processing Society (NAFIPS), Atlanta, GA, 2000, pp. 301-306.", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "At first IDS was implemented for host-based that located in servers to examine the internal interfaces [1]-[3], but with the evolution of computer networks the focus gradually shifted toward network-based.", "startOffset": 103, "endOffset": 106}, {"referenceID": 2, "context": "At first IDS was implemented for host-based that located in servers to examine the internal interfaces [1]-[3], but with the evolution of computer networks the focus gradually shifted toward network-based.", "startOffset": 107, "endOffset": 110}, {"referenceID": 3, "context": "Network intrusion detection system (NIDS) performs packet logging, real-time traffic analysis of IP network, and tries to discover if an intruder is attempting to break into the system [4]-[6].", "startOffset": 185, "endOffset": 188}, {"referenceID": 5, "context": "Network intrusion detection system (NIDS) performs packet logging, real-time traffic analysis of IP network, and tries to discover if an intruder is attempting to break into the system [4]-[6].", "startOffset": 189, "endOffset": 192}, {"referenceID": 6, "context": "Snort is an open source network intrusion detection and prevention system (NIDPS) developed by Sourcefire [7], [8].", "startOffset": 106, "endOffset": 109}, {"referenceID": 7, "context": "Snort is an open source network intrusion detection and prevention system (NIDPS) developed by Sourcefire [7], [8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "Anomaly detection model identifies new attacks by analyzing the anomalous behaviors from normal behaviors [9], and achieves high detection rates (DR) for new attacks, but produces many false positives (FP).", "startOffset": 106, "endOffset": 109}, {"referenceID": 9, "context": "Currently adaptive intrusion detection aims to solve the problems of analyzing the huge volumes of audit data and realizing performance optimization of detection rules [10]-[14].", "startOffset": 168, "endOffset": 172}, {"referenceID": 13, "context": "Currently adaptive intrusion detection aims to solve the problems of analyzing the huge volumes of audit data and realizing performance optimization of detection rules [10]-[14].", "startOffset": 173, "endOffset": 177}, {"referenceID": 14, "context": "Detecting intrusions using data mining algorithms such as decision tree (DT), na\u00efve Bayesian (NB) [15], neural network (NN), support vector machine (SVM) [16], k-nearest neighbors (KNN), fuzzy logic model [17], and genetic algorithm [18] have been widely used in the last decades.", "startOffset": 98, "endOffset": 102}, {"referenceID": 15, "context": "Detecting intrusions using data mining algorithms such as decision tree (DT), na\u00efve Bayesian (NB) [15], neural network (NN), support vector machine (SVM) [16], k-nearest neighbors (KNN), fuzzy logic model [17], and genetic algorithm [18] have been widely used in the last decades.", "startOffset": 154, "endOffset": 158}, {"referenceID": 16, "context": "Detecting intrusions using data mining algorithms such as decision tree (DT), na\u00efve Bayesian (NB) [15], neural network (NN), support vector machine (SVM) [16], k-nearest neighbors (KNN), fuzzy logic model [17], and genetic algorithm [18] have been widely used in the last decades.", "startOffset": 205, "endOffset": 209}, {"referenceID": 17, "context": "Detecting intrusions using data mining algorithms such as decision tree (DT), na\u00efve Bayesian (NB) [15], neural network (NN), support vector machine (SVM) [16], k-nearest neighbors (KNN), fuzzy logic model [17], and genetic algorithm [18] have been widely used in the last decades.", "startOffset": 233, "endOffset": 237}, {"referenceID": 18, "context": "Networking Overview In the networks, TCP/IP is widely used for network communications, which are composed of four layers: application layer, transport layer, network layer, and hardware layer that work together [19].", "startOffset": 211, "endOffset": 215}, {"referenceID": 19, "context": "A networkbased IDS (NIDS) monitor and analyze network traffics, and use multiple sensors for detecting intrusions from internal and external networks [20]-[22].", "startOffset": 150, "endOffset": 154}, {"referenceID": 21, "context": "A networkbased IDS (NIDS) monitor and analyze network traffics, and use multiple sensors for detecting intrusions from internal and external networks [20]-[22].", "startOffset": 155, "endOffset": 159}, {"referenceID": 22, "context": "15 The metrics such as precision, recall, overall, and false alarm have been used to measure the performance of the data mining algorithm on the minority class [23]-[26].", "startOffset": 160, "endOffset": 164}, {"referenceID": 25, "context": "15 The metrics such as precision, recall, overall, and false alarm have been used to measure the performance of the data mining algorithm on the minority class [23]-[26].", "startOffset": 165, "endOffset": 169}, {"referenceID": 26, "context": "Detection rate (DR) and false positive (FP) are used to estimate the performance of IDS [27], which are given as bellow:", "startOffset": 88, "endOffset": 92}, {"referenceID": 38, "context": "Related Work In 1980, the concept of intrusion detection began with Anderson\u2019s seminal paper [40]; he introduced a threat classification model that develops a security monitoring surveillance system based on detecting anomalies in user behavior.", "startOffset": 93, "endOffset": 97}, {"referenceID": 39, "context": "Denning proposed several models for commercial IDS development based on statistics, Markov chains, time-series, etc [41].", "startOffset": 116, "endOffset": 120}, {"referenceID": 40, "context": "In the early 1980\u2019s, Stanford Research Institute (SRI) developed an Intrusion Detection Expert System (IDES) that monitors user behavior and detects suspicious events [42].", "startOffset": 167, "endOffset": 171}, {"referenceID": 41, "context": "In 1988, a statistical anomaly-based IDS was proposed by Haystack [43], which used both user and group-based anomaly detection strategies.", "startOffset": 66, "endOffset": 70}, {"referenceID": 42, "context": "proposed an analogy between the human immune system and intrusion detection that involved analyzing a program\u2019s system call sequences to build a normal profile [44].", "startOffset": 160, "endOffset": 164}, {"referenceID": 43, "context": "[45] developed an anomaly based IDS that employed na\u00efve Bayesian network to perform intrusion detecting on traffic bursts.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "[46] proposed a multisensory fusion approach using Bayesian classifier for classification and suppression of false alarms that the outputs of different IDS sensors were aggregated to produce single alarm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "[47] proposed an anomaly based intrusion detection scheme using principal components analysis (PCA), where PCA was applied to reduce the dimensionality of the audit data and arrive at a classifier that is a function of the principal components.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] proposed an anomaly based intrusion detection using hidden Markov models that computes the sample likelihood of an observed sequence using the forward or backward algorithm for identifying anomalous.", "startOffset": 0, "endOffset": 3}, {"referenceID": 46, "context": "[48] proposed classification based anomaly detection using inductive rules to characterize sequences occurring in normal data.", "startOffset": 0, "endOffset": 4}, {"referenceID": 47, "context": "[49] developed the Fuzzy Intrusion Recognition Engine (FIRE) using fuzzy logic that process the network data and generate fuzzy sets for every observed feature and then the fuzzy sets are used to detect network attacks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "Input Attribute Selection from Dataset Effective input attribute selection from dataset before learning is very important, because irrelevant and redundant attributes of dataset may lead to complex classification model as well as reduce the classification accuracy [29]-[36].", "startOffset": 265, "endOffset": 269}, {"referenceID": 35, "context": "Input Attribute Selection from Dataset Effective input attribute selection from dataset before learning is very important, because irrelevant and redundant attributes of dataset may lead to complex classification model as well as reduce the classification accuracy [29]-[36].", "startOffset": 270, "endOffset": 274}], "year": 2010, "abstractText": "In this paper, a new learning algorithm for adaptive network intrusion detection using naive Bayesian classifier and decision tree is presented, which performs balance detections and keeps false positives at acceptable level for different types of network attacks, and eliminates redundant attributes as well as contradictory examples from training data that make the detection model complex. The proposed algorithm also addresses some difficulties of data mining such as handling continuous attribute, dealing with missing attribute values, and reducing noise in training data. Due to the large volumes of security audit data as well as the complex and dynamic properties of intrusion behaviours, several data miningbased intrusion detection techniques have been applied to network-based traffic data and host-based data in the last decades. However, there remain various issues needed to be examined towards current intrusion detection systems (IDS). We tested the performance of our proposed algorithm with existing learning algorithms by employing on the KDD99 benchmark intrusion detection dataset. The experimental results prove that the proposed algorithm achieved high detection rates (DR) and significant reduce false positives (FP) for different types of network intrusions using limited computational resources.", "creator": "PScript5.dll Version 5.2.2"}}}