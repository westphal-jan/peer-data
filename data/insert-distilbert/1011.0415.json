{"id": "1011.0415", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2010", "title": "Learning Networks of Stochastic Differential Equations", "abstract": "we consider linear models for stochastic dynamics. to any such neural model can be associated a network ( namely a directed graph ) describing which degrees of freedom interact under the dynamics. we tackle particularly the problem of learning all such a network from single observation of the predicted system trajectory over a time interval $ t $.", "histories": [["v1", "Mon, 1 Nov 2010 19:09:57 GMT  (39kb)", "http://arxiv.org/abs/1011.0415v1", "This publication is to appear in NIPS 2010"]], "COMMENTS": "This publication is to appear in NIPS 2010", "reviews": [], "SUBJECTS": "math.ST cond-mat.stat-mech cs.IT cs.LG math.IT stat.TH", "authors": ["jos\u00e9 bento", "morteza ibrahimi", "andrea montanari"], "accepted": true, "id": "1011.0415"}, "pdf": {"name": "1011.0415.pdf", "metadata": {"source": "CRF", "title": "Learning Networks of Stochastic Differential Equations", "authors": ["Jos\u00e9 Bento", "Morteza Ibrahimi"], "emails": ["jbento@stanford.edu", "ibrahimi@stanford.edu", "montanari@stanford.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n01 1.\n04 15\nv1 [\nm at\nkeywords: Gaussian processes, model selection and structure learning, graphical models, sparsity and feature selection."}, {"heading": "1 Introduction and main results", "text": "Let G = (V,E) be a directed graph with weight A0ij \u2208 R associated to the directed edge (j, i) from j \u2208 V to i \u2208 V . To each node i \u2208 V in this network is associated an independent standard Brownian motion bi and a variable xi taking values in R and evolving according to\ndxi(t) = \u2211\nj\u2208\u2202+i\nA0ijxj(t) dt+ dbi(t) ,\nwhere \u2202+i = {j \u2208 V : (j, i) \u2208 E} is the set of \u2018parents\u2019 of i. Without loss of generality we shall take V = [p] \u2261 {1, . . . , p}. In words, the rate of change of xi is given by a weighted sum of the current values of its neighbors, corrupted by white noise. In matrix notation, the same system is then represented by\ndx(t) = A0x(t) dt+ db(t) , (1)\nwith x(t) \u2208 Rp, b(t) a p-dimensional standard Brownian motion and A0 \u2208 Rp\u00d7p a matrix with entries {A0ij}i,j\u2208[p] whose sparsity pattern is given by the graphG. We assume that the linear system x\u0307(t) = A0x(t) is stable (i.e. that the spectrum of A0 is contained in {z \u2208 C : Re(z) < 0}). Further, we assume that x(t = 0) is in its stationary state. More precisely, x(0) is a Gaussian random variable\nindependent of b(t), distributed according to the invariant measure. Under the stability assumption, this a mild restriction, since the system converges exponentially to stationarity.\nA portion of time length T of the system trajectory {x(t)}t\u2208[0,T ] is observed and we ask under which conditions these data are sufficient to reconstruct the graph G (i.e., the sparsity pattern of A0). We are particularly interested in computationally efficient procedures, and in characterizing the scaling of the learning time for large networks. Can the network structure be learnt in a time scaling linearly with the number of its degrees of freedom?\nAs an example application, chemical reactions can be conveniently modeled by systems of nonlinear stochastic differential equations, whose variables encode the densities of various chemical species [1, 2]. Complex biological networks might involve hundreds of such species [3], and learning stochastic models from data is an important (and challenging) computational task [4]. Considering one such chemical reaction network in proximity of an equilibrium point, the model (1) can be used to trace fluctuations of the species counts with respect to the equilibrium values. The network G would represent in this case the interactions between different chemical factors. Work in this area focused so-far on low-dimensional networks, i.e. on methods that are guaranteed to be correct for fixed p, as T \u2192 \u221e, while we will tackle here the regime in which both p and T diverge. Before stating our results, it is useful to stress a few important differences with respect to classical graphical model learning problems:\n(i) Samples are not independent. This can (and does) increase the sample complexity.\n(ii) On the other hand, infinitely many samples are given as data (in fact a collection indexed by the continuous parameter t \u2208 [0, T ]). Of course one can select a finite subsample, for instance at regularly spaced times {x(i \u03b7)}i=0,1,.... This raises the question as to whether the learning performances depend on the choice of the spacing \u03b7.\n(iii) In particular, one expects that choosing \u03b7 sufficiently large as to make the configurations in the subsample approximately independent can be harmful. Indeed, the matrix A0 contains more information than the stationary distribution of the above process (1), and only the latter can be learned from independent samples.\n(iv) On the other hand, letting \u03b7 \u2192 0, one can produce an arbitrarily large number of distinct samples. However, samples become more dependent, and intuitively one expects that there is limited information to be harnessed from a given time interval T .\nOur results confirm in a detailed and quantitative way these intuitions."}, {"heading": "1.1 Results: Regularized least squares", "text": "Regularized least squares is an efficient and well-studied method for support recovery. We will discuss relations with existing literature in Section 1.3.\nIn the present case, the algorithm reconstructs independently each row of the matrix A0. The rth row, A0r , is estimated by solving the following convex optimization problem for Ar \u2208 Rp\nminimize L(Ar; {x(t)}t\u2208[0,T ]) + \u03bb\u2016Ar\u20161 , (2) where the likelihood function L is defined by\nL(Ar; {x(t)}t\u2208[0,T ]) = 1\n2T\n\u222b T\n0\n(A\u2217rx(t)) 2 dt\u2212 1\nT\n\u222b T\n0\n(A\u2217rx(t)) dxr(t) . (3)\n(Here and below M\u2217 denotes the transpose of matrix/vector M .) To see that this likelihood function is indeed related to least squares, one can formally write x\u0307r(t) = dxr(t)/dt and complete the square for the right hand side of Eq. (3), thus getting the integral \u222b (A\u2217rx(t) \u2212 x\u0307r(t))2dt \u2212 \u222b x\u0307r(t)\n2 dt. The first term is a sum of square residuals, and the second is independent of A. Finally the \u21131 regularization term in Eq. (2) has the role of shrinking to 0 a subset of the entries Aij thus effectively selecting the structure.\nLet S0 be the support of row A0r, and assume |S0| \u2264 k. We will refer to the vector sign(A0r) as to the signed support of A0r (where sign(0) = 0 by convention). Let \u03bbmax(M) and \u03bbmin(M) stand for\nthe maximum and minimum eigenvalue of a square matrix M respectively. Further, denote by Amin the smallest absolute value among the non-zero entries of row A0r.\nWhen stable, the diffusion process (1) has a unique stationary measure which is Gaussian with covariance Q0 \u2208 Rp\u00d7p given by the solution of Lyapunov\u2019s equation [5]\nA0Q0 +Q0(A0)\u2217 + I = 0. (4)\nOur guarantee for regularized least squares is stated in terms of two properties of the covariance Q0 and one assumption on \u03c1min(A0) (given a matrix M , we denote by ML,R its submatrix ML,R \u2261 (Mij)i\u2208L,j\u2208R):\n(a) We denote by Cmin \u2261 \u03bbmin(Q0S0,S0) the minimum eigenvalue of the restriction of Q0 to the support S0 and assume Cmin > 0. (b) We define the incoherence parameter \u03b1 by letting |||Q0(S0)C ,S0 ( Q0S0,S0\n)\u22121 |||\u221e = 1\u2212 \u03b1, and assume \u03b1 > 0. (Here ||| \u00b7 |||\u221e is the operator sup norm.) (c) We define \u03c1min(A0) = \u2212\u03bbmax((A0 + A0\u2217)/2) and assume \u03c1min(A0) > 0. Note this is a stronger form of stability assumption.\nOur main result is to show that there exists a well defined time complexity, i.e. a minimum time interval T such that, observing the system for time T enables us to reconstruct the network with high probability. This result is stated in the following theorem. Theorem 1.1. Consider the problem of learning the support S0 of row A0r of the matrix A\n0 from a sample trajectory {x(t)}t\u2208[0,T ] distributed according to the model (1). If\nT > 104k2(k \u03c1min(A 0)\u22122 +A\u22122min)\n\u03b12\u03c1min(A0)C2min log (4pk \u03b4 ) , (5)\nthen there exists \u03bb such that \u21131-regularized least squares recovers the signed support of A0r with probability larger than 1\u2212 \u03b4. This is achieved by taking \u03bb = \u221a 36 log(4p/\u03b4)/(T\u03b12\u03c1min(A0)) .\nThe time complexity is logarithmic in the number of variables and polynomial in the support size. Further, it is roughly inversely proportional to \u03c1min(A0), which is quite satisfying conceptually, since \u03c1min(A0)\u22121 controls the relaxation time of the mixes."}, {"heading": "1.2 Overview of other results", "text": "So far we focused on continuous-time dynamics. While, this is useful in order to obtain elegant statements, much of the paper is in fact devoted to the analysis of the following discrete-time dynamics, with parameter \u03b7 > 0:\nx(t) = x(t \u2212 1) + \u03b7A0x(t\u2212 1) + w(t), t \u2208 N0 . (6) Here x(t) \u2208 Rp is the vector collecting the dynamical variables, A0 \u2208 Rp\u00d7p specifies the dynamics as above, and {w(t)}t\u22650 is a sequence of i.i.d. normal vectors with covariance \u03b7 Ip\u00d7p (i.e. with independent components of variance \u03b7). We assume that consecutive samples {x(t)}0\u2264t\u2264n are given and will ask under which conditions regularized least squares reconstructs the support of A0.\nThe parameter \u03b7 has the meaning of a time-step size. The continuous-time model (1) is recovered, in a sense made precise below, by letting \u03b7 \u2192 0. Indeed we will prove reconstruction guarantees that are uniform in this limit as long as the product n\u03b7 (which corresponds to the time interval T in the previous section) is kept constant. For a formal statement we refer to Theorem 3.1. Theorem 1.1 is indeed proved by carefully controlling this limit. The mathematical challenge in this problem is related to the fundamental fact that the samples {x(t)}0\u2264t\u2264n are dependent (and strongly dependent as \u03b7 \u2192 0). Discrete time models of the form (6) can arise either because the system under study evolves by discrete steps, or because we are subsampling a continuous time system modeled as in Eq. (1). Notice that in the latter case the matrices A0 appearing in Eq. (6) and (1) coincide only to the zeroth order in \u03b7. Neglecting this technical complication, the uniformity of our reconstruction guarantees as \u03b7 \u2192 0 has an appealing interpretation already mentioned above. Whenever the samples spacing is not too large, the time complexity (i.e. the product n\u03b7) is roughly independent of the spacing itself."}, {"heading": "1.3 Related work", "text": "A substantial amount of work has been devoted to the analysis of \u21131 regularized least squares, and its variants [6, 7, 8, 9, 10]. The most closely related results are the one concerning high-dimensional consistency for support recovery [11, 12]. Our proof follows indeed the line of work developed in these papers, with two important challenges. First, the design matrix is in our case produced by a stochastic diffusion, and it does not necessarily satisfies the irrepresentability conditions used by these works. Second, the observations are not corrupted by i.i.d. noise (since successive configurations are correlated) and therefore elementary concentration inequalities are not sufficient.\nLearning sparse graphical models via \u21131 regularization is also a topic with significant literature. In the Gaussian case, the graphical LASSO was proposed to reconstruct the model from i.i.d. samples [13]. In the context of binary pairwise graphical models, Ref. [11] proves high-dimensional consistency of regularized logistic regression for structural learning, under a suitable irrepresentability conditions on a modified covariance. Also this paper focuses on i.i.d. samples.\nMost of these proofs builds on the technique of [12]. A naive adaptation to the present case allows to prove some performance guarantee for the discrete-time setting. However the resulting bounds are not uniform as \u03b7 \u2192 0 for n\u03b7 = T fixed. In particular, they do not allow to prove an analogous of our continuous time result, Theorem 1.1. A large part of our effort is devoted to producing more accurate probability estimates that capture the correct scaling for small \u03b7.\nSimilar issues were explored in the study of stochastic differential equations, whereby one is often interested in tracking some slow degrees of freedom while \u2018averaging out\u2019 the fast ones [14]. The relevance of this time-scale separation for learning was addressed in [15]. Let us however emphasize that these works focus once more on system with a fixed (small) number of dimensions p.\nFinally, the related topic of learning graphical models for autoregressive processes was studied recently in [16, 17]. The convex relaxation proposed in these papers is different from the one developed here. Further, no model selection guarantee was proved in [16, 17]."}, {"heading": "2 Illustration of the main results", "text": "It might be difficult to get a clear intuition of Theorem 1.1, mainly because of conditions (a) and (b), which introduce parameters Cmin and \u03b1. The same difficulty arises with analogous results on the high-dimensional consistency of the LASSO [11, 12]. In this section we provide concrete illustration both via numerical simulations, and by checking the condition on specific classes of graphs."}, {"heading": "2.1 Learning the laplacian of graphs with bounded degree", "text": "Given a simple graph G = (V , E) on vertex set V = [p], its laplacian \u2206G is the symmetric p \u00d7 p matrix which is equal to the adjacency matrix of G outside the diagonal, and with entries \u2206Gii = \u2212deg(i) on the diagonal [18]. (Here deg(i) denotes the degree of vertex i.) It is well known that \u2206G is negative semidefinite, with one eigenvalue equal to 0, whose multiplicity is equal to the number of connected components of G. The matrix A0 = \u2212mI + \u2206G fits into the setting of Theorem 1.1 for m > 0. The corresponding model (1.1) describes the over-damped dynamics of a network of masses connected by springs of unit strength, and connected by a spring of strength m to the origin. We obtain the following result. Theorem 2.1. Let G be a simple connected graph of maximum vertex degree k and consider the model (1.1) with A0 = \u2212mI +\u2206G where \u2206G is the laplacian of G and m > 0. If\nT \u2265 2 \u00b7 105k2 (k +m\nm\n)5 (k +m2) log (4pk \u03b4 ) , (7)\nthen there exists \u03bb such that \u21131-regularized least squares recovers the signed support of A0r with probability larger than 1\u2212 \u03b4. This is achieved by taking \u03bb = \u221a 36(k +m)2 log(4p/\u03b4)/(Tm3).\nIn other words, for m bounded away from 0 and \u221e, regularized least squares regression correctly reconstructs the graph G from a trajectory of time length which is polynomial in the degree and logarithmic in the system size. Notice that once the graph is known, the laplacian \u2206G is uniquely determined. Also, the proof technique used for this example is generalizable to other graphs as well."}, {"heading": "2.2 Numerical illustrations", "text": "In this section we present numerical validation of the proposed method on synthetic data. The results confirm our observations in Theorems 1.1 and 3.1, below, namely that the time complexity scales logarithmically with the number of nodes in the network p, given a constant maximum degree. Also, the time complexity is roughly independent of the sampling rate. In Fig. 1 and 2 we consider the discrete-time setting, generating data as follows. We draw A0 as a random sparse matrix in {0, 1}p\u00d7p with elements chosen independently at random with P(A0ij = 1) = k/p, k = 5. The process xn0 \u2261 {x(t)}0\u2264t\u2264n is then generated according to Eq. (6). We solve the regularized least square problem (the cost function is given explicitly in Eq. (8) for the discrete-time case) for different values of n, the number of observations, and record if the correct support is recovered for a random row r using the optimum value of the parameter \u03bb. An estimate of the probability of successful recovery is obtained by repeating this experiment. Note that we are estimating here an average probability of success over randomly generated matrices.\nThe left plot in Fig.1 depicts the probability of success vs. n\u03b7 for \u03b7 = 0.1 and different values of p. Each curve is obtained using 211 instances, and each instance is generated using a new random matrix A0. The right plot in Fig.1 is the corresponding curve of the sample complexity vs. p where sample complexity is defined as the minimum value of n\u03b7 with probability of success of 90%. As predicted by Theorem 2.1 the curve shows the logarithmic scaling of the sample complexity with p.\nIn Fig. 2 we turn to the continuous-time model (1). Trajectories are generated by discretizing this stochastic differential equation with step \u03b4 much smaller than the sampling rate \u03b7. We draw random matrices A0 as above and plot the probability of success for p = 16, k = 4 and different values of \u03b7, as a function of T . We used 211 instances for each curve. As predicted by Theorem 1.1, for a fixed observation interval T , the probability of success converges to some limiting value as \u03b7 \u2192 0."}, {"heading": "3 Discrete-time model: Statement of the results", "text": "Consider a system evolving in discrete time according to the model (6), and let xn0 \u2261 {x(t)}0\u2264t\u2264n be the observed portion of the trajectory. The rth row A0r is estimated by solving the following convex optimization problem for Ar \u2208 Rp\nminimize L(Ar;x n 0 ) + \u03bb\u2016Ar\u20161 , (8)\nwhere\nL(Ar;x n 0 ) \u2261\n1\n2\u03b72n\nn\u22121\u2211\nt=0\n{xr(t+ 1)\u2212 xr(t)\u2212 \u03b7 A\u2217rx(t)}2 . (9)\nApart from an additive constant, the \u03b7 \u2192 0 limit of this cost function can be shown to coincide with the cost function in the continuous time case, cf. Eq. (3). Indeed the proof of Theorem 1.1 will amount to a more precise version of this statement. Furthermore, L(Ar;xn0 ) is easily seen to be the log-likelihood of Ar within model (6).\nAs before, we let S0 be the support of row A0r, and assume |S0| \u2264 k. Under the model (6) x(t) has a Gaussian stationary state distribution with covariance Q0 determined by the following modified Lyapunov equation\nA0Q0 +Q0(A0)\u2217 + \u03b7A0Q0(A0)\u2217 + I = 0 . (10)\nIt will be clear from the context whether A0/Q0 refers to the dynamics/stationary matrix from the continuous or discrete time system. We assume conditions (a) and (b) introduced in Section 1.1, and adopt the notations already introduced there. We use as a shorthand notation \u03c3max \u2261 \u03c3max(I+\u03b7 A0) where \u03c3max(.) is the maximum singular value. Also define D \u2261 ( 1 \u2212 \u03c3max ) /\u03b7 . We will assume D > 0. As in the previous section, we assume the model (6) is initiated in the stationary state.\nTheorem 3.1. Consider the problem of learning the support S0 of row A0r from the discrete-time trajectory {x(t)}0\u2264t\u2264n. If\nn\u03b7 > 104k2(kD\u22122 +A\u22122min)\n\u03b12DC2min log (4pk \u03b4 ) , (11)\nthen there exists \u03bb such that \u21131-regularized least squares recovers the signed support of A0r with probability larger than 1\u2212 \u03b4. This is achieved by taking \u03bb = \u221a (36 log(4p/\u03b4))/(D\u03b12n\u03b7).\nIn other words the discrete-time sample complexity, n, is logarithmic in the model dimension, polynomial in the maximum network degree and inversely proportional to the time spacing between samples. The last point is particularly important. It enables us to derive the bound on the continuoustime sample complexity as the limit \u03b7 \u2192 0 of the discrete-time sample complexity. It also confirms our intuition mentioned in the Introduction: although one can produce an arbitrary large number of samples by sampling the continuous process with finer resolutions, there is limited amount of information that can be harnessed from a given time interval [0, T ]."}, {"heading": "4 Proofs", "text": "In the following we denote by X \u2208 Rn\u00d7p the matrix whose (t + 1)th column corresponds to the configuration x(t), i.e. X = [x(0), x(1), . . . , x(n\u2212 1)]. Further \u2206X \u2208 Rn\u00d7p is the matrix containing configuration changes, namely \u2206X = [x(1) \u2212 x(0), . . . , x(n) \u2212 x(n \u2212 1)]. Finally we write W = [w(1), . . . , w(n\u2212 1)] for the matrix containing the Gaussian noise realization. Equivalently,\nW = \u2206X \u2212 \u03b7AX . The rth row of W is denoted by Wr.\nIn order to lighten the notation, we will omit the reference to xn0 in the likelihood function (9) and simply write L(Ar). We define its normalized gradient and Hessian by\nG\u0302 = \u2212\u2207L(A0r) = 1\nn\u03b7 XW \u2217r , Q\u0302 = \u22072L(A0r) =\n1 n XX\u2217 . (12)"}, {"heading": "4.1 Discrete time", "text": "In this Section we outline our prove for our main result for discrete-time dynamics, i.e., Theorem 3.1. We start by stating a set of sufficient conditions for regularized least squares to work. Then we present a series of concentration lemmas to be used to prove the validity of these conditions, and finally we sketch the outline of the proof.\nAs mentioned, the proof strategy, and in particular the following proposition which provides a compact set of sufficient conditions for the support to be recovered correctly is analogous to the one in [12]. A proof of this proposition can be found in the supplementary material. Proposition 4.1. Let \u03b1,Cmin > 0 be be defined by\n\u03bbmin(Q 0 S0,S0) \u2261 Cmin , |||Q0(S0)C ,S0 ( Q0S0,S0 )\u22121 |||\u221e \u2261 1\u2212 \u03b1 . (13) If the following conditions hold then the regularized least square solution (8) correctly recover the signed support sign(A0r):\n\u2016G\u0302\u2016\u221e \u2264 \u03bb\u03b1\n3 , \u2016G\u0302S0\u2016\u221e \u2264 AminCmin 4k \u2212 \u03bb, (14)\n|||Q\u0302(S0)C ,S0 \u2212Q0(S0)C ,S0 |||\u221e \u2264 \u03b1\n12 Cmin\u221a k , |||Q\u0302S0,S0 \u2212Q0S0,S0 |||\u221e \u2264 \u03b1 12 Cmin\u221a k . (15)\nFurther the same statement holds for the continuous model 3, provided G\u0302 and Q\u0302 are the gradient and the hessian of the likelihood (3).\nThe proof of Theorem 3.1 consists in checking that, under the hypothesis (11) on the number of consecutive configurations, conditions (14) to (15) will hold with high probability. Checking these conditions can be regarded in turn as concentration-of-measure statements. Indeed, if expectation is taken with respect to a stationary trajectory, we have E{G\u0302} = 0, E{Q\u0302} = Q0."}, {"heading": "4.1.1 Technical lemmas", "text": "In this section we will state the necessary concentration lemmas for proving Theorem 3.1. These are non-trivial because G\u0302, Q\u0302 are quadratic functions of dependent random variables ( the samples {x(t)}0\u2264t\u2264n ) . The proofs of Proposition 4.2, of Proposition 4.3, and Corollary 4.4 can be found in the supplementary material provided.\nOur first Proposition implies concentration of G\u0302 around 0. Proposition 4.2. Let S \u2286 [p] be any set of vertices and \u01eb < 1/2. If \u03c3max \u2261 \u03c3max(I + \u03b7 A0) < 1, then\nP { \u2016G\u0302S\u2016\u221e > \u01eb } \u2264 2|S| e\u2212n(1\u2212\u03c3max) \u01eb2/4. (16)\nWe furthermore need to bound the matrix norms as per (15) in proposition 4.1. First we relate bounds on |||Q\u0302JS \u2212 Q0JS |||\u221e with bounds on |Q\u0302ij \u2212 Q0ij |, (i \u2208 J, i \u2208 S) where J and S are any subsets of {1, ..., p}. We have,\nP(|||Q\u0302JS \u2212Q0JS)|||\u221e > \u01eb) \u2264 |J ||S|max i,j\u2208J P(|Q\u0302ij \u2212Q0ij | > \u01eb/|S|). (17)\nThen, we bound |Q\u0302ij \u2212Q0ij | using the following proposition Proposition 4.3. Let i, j \u2208 {1, ..., p}, \u03c3max \u2261 \u03c3max(I + \u03b7A0) < 1, T = \u03b7n > 3/D and 0 < \u01eb < 2/D where D = (1\u2212 \u03c3max)/\u03b7 then,\nP(|Q\u0302ij \u2212Q0ij)| > \u01eb) \u2264 2e \u2212 n 32\u03b72 (1\u2212\u03c3max) 3\u01eb2 . (18)\nFinally, the next corollary follows from Proposition 4.3 and Eq. (17). Corollary 4.4. Let J, S (|S| \u2264 k) be any two subsets of {1, ..., p} and \u03c3max \u2261 \u03c3max(I+ \u03b7A0) < 1, \u01eb < 2k/D and n\u03b7 > 3/D (where D = (1\u2212 \u03c3max)/\u03b7) then,\nP(|||Q\u0302JS \u2212Q0JS |||\u221e > \u01eb) \u2264 2|J |ke \u2212 n 32k2\u03b72 (1\u2212\u03c3max) 3\u01eb2 . (19)"}, {"heading": "4.1.2 Outline of the proof of Theorem 3.1", "text": "With these concentration bounds we can now easily prove Theorem 3.1. All we need to do is to compute the probability that the conditions given by Proposition 4.1 hold. From the statement of the theorem we have that the first two conditions (\u03b1,Cmin > 0) of Proposition 4.1 hold. In order to make the first condition on G\u0302 imply the second condition on G\u0302 we assume that \u03bb\u03b1/3 \u2264 (AminCmin)/(4k)\u2212 \u03bb which is guaranteed to hold if\n\u03bb \u2264 AminCmin/8k. (20)\nWe also combine the two last conditions on Q\u0302, thus obtaining the following\n|||Q\u0302[p],S0 \u2212Q0[p],S0|||\u221e \u2264 \u03b1\n12 Cmin\u221a k , (21)\nsince [p] = S0 \u222a (S0)C . We then impose that both the probability of the condition on Q\u0302 failing and the probability of the condition on G\u0302 failing are upper bounded by \u03b4/2 using Proposition 4.2 and Corollary 4.4. It is shown in the supplementary material that this is satisfied if condition (11) holds."}, {"heading": "4.2 Outline of the proof of Theorem 1.1", "text": "To prove Theorem 1.1 we recall that Proposition 4.1 holds provided the appropriate continuous time expressions are used for G\u0302 and Q\u0302, namely\nG\u0302 = \u2212\u2207L(A0r) = 1\nT\n\u222b T\n0\nx(t) dbr(t) , Q\u0302 = \u22072L(A0r) = 1\nT\n\u222b T\n0\nx(t)x(t)\u2217 dt . (22)\nThese are of course random variables. In order to distinguish these from the discrete time version, we will adopt the notation G\u0302n, Q\u0302n for the latter. We claim that these random variables can be coupled (i.e. defined on the same probability space) in such a way that G\u0302n \u2192 G\u0302 and Q\u0302n \u2192 Q\u0302 almost surely as n \u2192 \u221e for fixed T . Under assumption (5), it is easy to show that (11) holds for all n > n0 with n0 a sufficiently large constant (for a proof see the provided supplementary material). Therefore, by the proof of Theorem 3.1, the conditions in Proposition 4.1 hold for gradient G\u0302n and hessian Q\u0302n for any n \u2265 n0, with probability larger than 1 \u2212 \u03b4. But by the claimed convergence G\u0302n \u2192 G\u0302 and Q\u0302n \u2192 Q\u0302, they hold also for G\u0302 and Q\u0302 with probability at least 1\u2212 \u03b4 which proves the theorem.\nWe are left with the task of showing that the discrete and continuous time processes can be coupled in such a way that G\u0302n \u2192 G\u0302 and Q\u0302n \u2192 Q\u0302. With slight abuse of notation, the state of the discrete time system (6) will be denoted by x(i) where i \u2208 N and the state of continuous time system (1) by x(t) where t \u2208 R. We denote by Q0 the solution of (4) and by Q0(\u03b7) the solution of (10). It is easy to check that Q0(\u03b7) \u2192 Q0 as \u03b7 \u2192 0 by the uniqueness of stationary state distribution. The initial state of the continuous time system x(t = 0) is a N(0, Q0) random variable independent of b(t) and the initial state of the discrete time system is defined to be x(i = 0) = (Q0(\u03b7))1/2(Q0)\u22121/2x(t = 0). At subsequent times, x(i) and x(t) are assumed are generated by the respective dynamical systems using the same matrix A0 using common randomness provided by the standard Brownian motion {b(t)}0\u2264t\u2264T in Rp. In order to couple x(t) and x(i), we construct w(i), the noise driving the discrete time system, by letting w(i) \u2261 (b(T i/n)\u2212 b(T (i\u2212 1)/n)).\nThe almost sure convergence G\u0302n \u2192 G\u0302 and Q\u0302n \u2192 Q\u0302 follows then from standard convergence of random walk to Brownian motion."}, {"heading": "Acknowledgments", "text": "This work was partially supported by a Terman fellowship, the NSF CAREER award CCF-0743978 and the NSF grant DMS-0806211 and by a Portuguese Doctoral FCT fellowship."}, {"heading": "A Learning networks of stochastic differential equations: Supplementary materials", "text": "In order to prove Proposition 4.1 we first introduce two technical lemmas.\nLemma A.1. For any subset S \u2286 [p] the following decomposition holds,\nQ\u0302SC ,S ( Q\u0302S,S )\u22121 = T1 + T2 + T3 +Q 0 SC ,S ( Q0S,S )\u22121 , (23)\nwhere,\nT1 = Q 0 SC ,S (( Q\u0302S,S )\u22121 \u2212 ( Q0S,S )\u22121 ) , (24) T2 = (Q\u0302SC ,S \u2212Q0SC ,S) ( Q0S,S )\u22121 , (25) T3 = (Q\u0302SC ,S \u2212Q0SC ,S) (( Q\u0302S,S )\u22121 \u2212 ( Q0S,S )\u22121 ) . (26)\n(27)\nIn addition, if |||Q0SC ,S ( Q0S,S )\u22121 |||\u221e < 1 and \u03bbmin(Q\u0302S,S) \u2265 Cmin/2 > 0 the following relations hold,\n|||T1|||\u221e \u2264 2 \u221a k\nCmin |||Q\u0302S,S \u2212Q0S,S|||\u221e, (28)\n|||T2|||\u221e \u2264 \u221a k\nCmin |||Q\u0302SC ,S \u2212Q0SC ,S |||\u221e, (29)\n|||T3|||\u221e \u2264 2 \u221a k\nC2min |||Q\u0302SC ,S \u2212Q0SC ,S |||\u221e|||Q\u0302S,S \u2212Q0S,S|||\u221e. (30)\nThe following lemma taken from the proofs of Proposition 1 in [19] and Proposition 1 in [12] respectively is the crux to guaranteeing correct signed-support reconstruction of A0r .\nLemma A.2. If Q\u0302S0,S0 > 0, then the dual vector z\u0302 from the KKT conditions of the optimization problem (8) satisfies the following inequality,\n\u2016z\u0302(S0)C\u2016\u221e \u2264 |||Q\u0302(S0)C ,S0 ( Q\u0302S0,S0 )\u22121 |||\u221e ( 1 +\n\u2016G\u0302S0\u2016\u221e \u03bb\n) +\n\u2016G\u0302(S0)C\u2016\u221e \u03bb . (31)\nIn addition, if\n\u2016G\u0302S0\u2016\u221e \u2264 Amin\u03bbmin(Q\u0302S0,S0)\n2k \u2212 \u03bb (32)\nthen \u2016A0r \u2212 A\u0302r\u2016\u221e \u2264 Amin/2. The same result holds for problem (2).\nProof of Proposition 4.1: To guarantee that our estimated support is at least contained in the true support we need to impose that \u2016z\u0302SC\u2016\u221e < 1. To guarantee that we do not introduce extra elements in estimating the support and also to determine the correct sign of the solution we need to impose that \u2016A0r\u2212 A\u0302r\u2016\u221e \u2264 Amin/2. Now notice that since \u03bbmin(Q0S0,S0) = Cmin the relation \u03bbmin(Q\u0302S0,S0) \u2265 Cmin/2 is guaranteed as long as |||Q\u0302S0,S0 \u2212 Q0S0,S0 |||\u221e \u2264 Cmin/2. Using Lemma A.1 it is easy to see that the bounds of Proposition 4.1 lead to the conditions of Lemma A.2 being verified. Thus, these lead to a correct recovery of the signed structure of A0r .\nLemma A.3. Let r, j \u2208 [p] and let \u03c1(\u03c4) represent a p \u00d7 p matrix with all rows equal to zero except the rth row which equals the jth row of (I + \u03b7A0) \u03c4 (the \u03c4 th power of I + \u03b7A0 ). Let\nR\u0303(j) \u2208 R(n+m+1)\u00d7(n+m+1) be defined as,\nR\u0303 =  \n0 0 . . . 0 0 0 . . . 0 0 ... ... . . . ... ... ... . . . ... ...\n0 0 . . . 0 0 0 . . . 0 0 \u03c1(m) \u03c1(m\u2212 1) . . . \u03c1(1) \u03c1(0) 0 . . . 0 0 \u03c1(m+ 1) \u03c1(m) . . . \u03c1(2) \u03c1(1) \u03c1(0) . . . 0 0 ... ... . . . ... ... ... . . . 0 0 \u03c1(m+ n\u2212 1) \u03c1(m+ n\u2212 2) . . . \u03c1(n) \u03c1(n\u2212 1) \u03c1(n\u2212 2) . . . \u03c1(0) 0\n  . (33)\nDefine R(j) = 1/2(R\u0303 + R\u0303\u2217) and let \u03bdi denote its ith eigenvalue and assume \u03c3max \u2261 \u03c3max(I + \u03b7A0) < 1. Then,\np(n+m+1)\u2211\ni=1\n\u03bdi = 0, (34)\nmax i\n|\u03bdi| \u2264 1\n1\u2212 \u03c3max , (35)\np(n+m+1)\u2211\ni=1\n\u03bd2i \u2264 1\n2\nn\n1\u2212 \u03c3max . (36)\nProof. First it is immediate to see that \u2211p(n+m+1)\ni=1 \u03bdi = Tr(R) = 0. Let I1\u03c4 represent a p \u00d7 p matrix with zeros everywhere and ones in the block-position where \u03c1(\u03c4) appears and I2\u03c4 represent a similar matrix but with ones in the block-position where \u03c1(\u03c4)\u2217 appears. Then R can be written as,\nR = 1\n2\n( m+n\u22121\u2211\n\u03c4=0\nI1\u03c4 \u2297 \u03c1(\u03c4) + I2\u03c4 \u2297 \u03c1(\u03c4)\u2217 ) , (37)\nwhere \u2297 denotes the Kronecker product of matrices. This expression can be used to compute an upper bound on |\u03bdi|. Namely,\nmax i\n|\u03bdi| = \u03c3max(R) \u2264 \u221e\u2211\n\u03c4=0\n\u03c3max(I1\u03c4 \u2297 \u03c1(\u03c4)) \u2264 \u221e\u2211\n\u03c4=0\n\u03c3max(I1\u03c4 )\u03c3max(\u03c1(\u03c4)) (38)\n\u2264 \u221e\u2211\n\u03c4=0\n\u03c3max(\u03c1(\u03c4)) \u2264 \u221e\u2211\n\u03c4=0\n\u03c3\u03c4max = 1\n1\u2212 \u03c3max(\u03d5\u2217) . (39)\nFor the other bound we do, (n+m+1)p\u2211\ni=1\n\u03bd2i = Tr(R 2) \u2264 1\n4 n 2\n\u221e\u2211\n\u03c4=0\nTr(\u03c1(\u03c4)\u03c1(\u03c4)\u2217) (40)\n= 1\n2 n\n\u221e\u2211\n\u03c4=0\n\u2016\u03c1(\u03c4)\u201622 (41)\n\u2264 1 2 n\n\u221e\u2211\n\u03c4=0\n\u03c32\u03c4max \u2264 1\n2\nn\n1\u2212 \u03c3max , (42)\nwhere in the last step we used the fact that 0 \u2264 \u03c3max < 1.\nLemma A.4. Let j \u2208 [p]. Define \u03c1(\u03c4) \u2208 R1\u00d7p to be the jth row of (I+\u03b7A0)\u03c4 . Let \u03a6j \u2208 Rn\u00d7(n+m) be defined as,\n\u03a6j =   \u03c1(m) \u03c1(m\u2212 1) . . . \u03c1(1) \u03c1(0) 0 . . . 0 \u03c1(m+ 1) \u03c1(m) . . . \u03c1(2) \u03c1(1) \u03c1(0) . . . 0\n... ...\n. . . ...\n... ... . . . 0 \u03c1(m+ n\u2212 1) \u03c1(m+ n\u2212 2) . . . \u03c1(n) \u03c1(n\u2212 1) \u03c1(n\u2212 2) . . . \u03c1(0)\n  ,\n(43)\nLet \u03bdl denote the lth eigenvalue of the matrix R(i, j) = 1/2(\u03a6\u2217j\u03a6i + \u03a6 \u2217 i\u03a6j) \u2208 R(n+m)\u00d7(n+m) (where i \u2208 [p]) and assume \u03c3max \u2261 \u03c3max(I + \u03b7A0) < 1 then,\n|\u03bdl| \u2264 1\n(1\u2212 \u03c3max)2 , (44)\n1\nn\n(n+m)p\u2211\nl=1\n\u03bd2l \u2264 2 (1\u2212 \u03c3max)3 ( 1 + 3 2n\n1\n1\u2212 \u03c3max\n) . (45)\nProof. The first bound can be proved in a trivial manner. In fact, since for any matrix A and B we have \u03c3max(A+B) \u2264 \u03c3max(A) + \u03c3max(B) and \u03c3max(AB) \u2264 \u03c3max(A)\u03c3max(B) we can write\nmax l\n|\u03bdl| = \u03c3max(1/2(\u03a6\u2217j\u03a6i + \u03a6\u2217i\u03a6j)) \u2264 1/2(\u03c3max(\u03a6\u2217j\u03a6i) + \u03c3max(\u03a6\u2217i\u03a6j)) (46)\n\u2264 \u03c3max(\u03a6\u2217i\u03a6j) \u2264 \u03c3max(\u03a6i)\u03c3max(\u03a6j) \u2264 1\n(1\u2212 \u03c3max)2 , (47)\nwhere in the last inequality we used the fact \u03c3max(\u03a6j) \u2264 1/(1 \u2212 \u03c3max). The proof of this is just a copy of the proof of the bound (35) in Lemma A.3.\nBefore we prove the second bound let us introduce some notation to differentiate \u03c1(\u03c4) associated with \u03a6j from \u03c1(\u03c4) associated with \u03a6i. Let us call them \u03c1(\u03c4, j) and \u03c1(\u03c4, i) respectively. Now notice that \u03a6\u2217i\u03a6j can be written as a block matrix\n( A\u0303 D\u0303\nC\u0303 B\u0303\n) (48)\nwhere A\u0303, B\u0303, C\u0303 and D\u0303 are matrix blocks where each block is a p by p matrix. A\u0303 has p \u00d7 p blocks, B\u0303 has n\u00d7 n blocks, C\u0303 has n\u00d7m blocks and D\u0303 has m \u00d7 n blocks. If we index the blocks of each matrix with the indices x, y these can be described in the following way\nA\u0303xy =\nm\u2211\ns=1\n\u03c1(m\u2212 x+ s, i)\u2217\u03c1(m\u2212 y + s, j) (49)\nB\u0303xy =\nn\u2212x\u2211\ns=0\n\u03c1(s, i)\u2217\u03c1(s+ x\u2212 y, j), x \u2265 y (50)\nB\u0303xy =\nn\u2212y\u2211\ns=0\n\u03c1(s+ y \u2212 x, i)\u2217\u03c1(s, j), x \u2264 y (51)\nC\u0303xy =\nn\u2212x\u2211\ns=0\n\u03c1(s, i)\u2217\u03c1(m\u2212 y + x+ s, j) (52)\nD\u0303xy =\nn\u2212y\u2211\ns=0\n\u03c1(m\u2212 x+ y + s, i)\u2217\u03c1(s, j). (53)\nWith this in mind and denoting by A,B,C and D the symmetrized versions of these same matrices (e.g.: A = 1/2(A\u0303+ A\u0303\u2217)) we can write,\n(n+m)p\u2211\nl=1\n\u03bd2l = Tr(R(i, j) 2) = Tr(A2) + Tr(B2) + 2Tr(CD). (54)\nWe now compute a bound for each one of the terms. We exemplify in detail the calculation of the first bound only. First write,\nTr(A2) =\nm\u2211\nx=1\nm\u2211\ny=1\nTr(AxyA \u2217 xy). (55)\nNow notice that each Tr(AxyA\u2217xy) is a sum over \u03c41, \u03c42 \u2208 [p] of terms of the type,\n(\u03c1(m\u2212 x+ \u03c41, i)\u2217\u03c1(m\u2212 y + \u03c41, j) + \u03c1(m\u2212 x+ \u03c41, j)\u2217\u03c1(m\u2212 y + \u03c41, i))\u00d7 (56) \u00d7(\u03c1(m\u2212 y + \u03c42, j)\u2217\u03c1(m\u2212 x+ \u03c42, i) + \u03c1(m\u2212 y + \u03c42, i)\u2217\u03c1(m\u2212 x+ \u03c42, j)). (57)\nThe trace of a matrix of this type can be easily upper bounded by\n(\u03c3max) m\u2212x+\u03c41+m\u2212y+\u03c41+m\u2212y+\u03c42+m\u2212x+\u03c42 = (\u03c3max) 2(m\u2212x)+2(m\u2212y)+2\u03c41+2\u03c42 (58)\nwhich finally leads to\nTr(A2) \u2264 1 (1 \u2212 \u03c3max)4 . (59)\nDoing a similar thing to the other terms leads to\nTr(B2) \u2264 n,n\u2211\nx,y\n\u2211\n\u03c41,\u03c42\n\u03c32\u03c41+2\u03c42+2|x\u2212y|max \u2264 2n\n(1\u2212 \u03c3max)3 (60)\nTr(DC) =\nm\u2211\nx=1\nn\u2211\ny=1\nTr(CxyDyx) \u2264 m,n,n\u2212y,n\u2212y\u2211\nx,y,\u03c41,\u03c42\n\u03c32(m\u2212x)+2y+2\u03c41+2\u03c42max \u2264 1\n(1\u2212 \u03c3max)4 . (61)\nPutting all these together leads to the desired bound.\nProof of Proposition 4.2: We will start by proving that this exact same bound holds when the probability of the event {\u2016G\u0302S\u2016\u221e > \u01eb} is computed with respect to a trajectory {x(t)}nt=0 that is initiated at instant t = \u2212m with the value w(\u2212m). In other words, x(\u2212m) = w(\u2212m). Assume we have done so. Now notice that as m \u2192 \u221e, X converges in distribution to n consecutive samples from the model (6) when this is initiated from stationary state. Since \u2016G\u0302S\u2016\u221e is a continuous function of X = [x(0), ..., x(n \u2212 1)], by the Continuous Mapping Theorem, \u2016G\u0302S\u2016\u221e converges in distribution to the corresponding random variable in the case when the trajectory {x(i)}ni=0 is initiated from stationary state. Since the probability bound does not depend on m we have that this same bound holds for stationary trajectories too.\nWe now prove our claim. Recall that G\u0302j = (XjW \u2217r )/(n\u03b7). Since X is a linear function of the independent gaussian random variables W we can write XjW \u2217r = \u03b7z\n\u2217R(j)z, where z \u2208 Rp(n+m+1) is a vector of i.i.d. N(0, 1) random variables and R(j) \u2208 Rp(n+m+1)\u00d7p(n+m+1) is the symmetric matrix defined in Lemma A.3.\nNow apply the standard Bernstein method. First by union bound we have\nP { \u2016G\u0302S\u2016\u221e > \u01eb } \u2264 2|S| max j\u2208S P { z\u2217R(j)z > n\u01eb } .\nNext denoting by {\u03bdi}1\u2264i\u2264p(n+m+1) the eigenvalues of R(j), we have, for any \u03b3 > 0,\nP { z\u2217R(j)z > n\u01eb } = P\n{ p(n+m+1)\u2211\ni=1\n\u03bdiz 2 i > n\u01eb\n}\n\u2264 e\u2212n\u03b3\u01eb p(n+m+1)\u220f\ni=1\nE { e\u03b3\u03bdiz 2 i }\n= exp  \u2212n ( \u03b3\u01eb+ 1\n2n\n(n+m+1)p\u2211\ni=1\nlog(1\u2212 2\u03bdi\u03b3) )   .\nLet \u03b3 = 12 (1\u2212\u03c3max)\u01eb. Using the bound obtained for |maxi \u03bdi| in Eq. (35), Lemma A.3, |2\u03bdi\u03b3| \u2264 \u01eb. Now notice that if |x| < 1/2 then log(1 \u2212 x) > \u2212x \u2212 x2. Thus, if we assume \u01eb < 1/2 and given\nthat \u2211(n+m+1)p\ni=1 \u03bdi = 0 (see Eq. (34)) we can continue the chain of inequalities,\nP(\u2016G\u0302S\u2016\u221e > \u01eb) \u2264 2|S|max j exp\n \u2212n(\u03b3\u01eb\u2212 2\u03b32 1\nn\n(n+m+1)p\u2211\ni=1\n\u03bd2i )\n  (62)\n\u2264 2|S| exp ( \u2212n(1\n2 (1\u2212 \u03c3max)\u01eb2 \u2212\n1 4 (1\u2212 \u03c3max)2\u01eb2(1 \u2212 \u03c3max)\u22121)\n) (63)\n\u2264 2|S| exp ( \u2212n 4 (1\u2212 \u03c3max)\u01eb2 ) . (64)\nwhere the second inequality is obtained using the bound in Eq. (36).\nProof of Proposition 4.3: The proof is very similar to that of proposition 4.2. We will first show that the bound\nP(|Q\u0302ij \u2212 E(Q\u0302ij)| > \u01eb) \u2264 2e\u2212 n 32\u03b72 (1\u2212\u03c3max) 3\u01eb2 , (65)\nholds in the case where the probability measure and expectation are taken with respect to trajectories {x(i)}ni=0 that started at time instant t = \u2212m with x(\u2212m) = w(\u2212m). Assume we have done so. Now notice that as m \u2192 \u221e, X converges in distribution to n consecutive samples from the model 6 when this is initiated from stationary state. In addition, as m \u2192 \u221e, we have from lemma A.5 that E(Q\u0302ij) \u2192 Q0ij . Since Q\u0302ij is a continuous function of X = [x(0), ..., x(n\u22121)], a simple application of the Continuous Mapping Theorem plus the fact that the upper bound is continuous in \u01eb leads us to conclude that the bound also holds when the system is initiated from stationary state.\nTo prove our previous statement first recall the definition of Q\u0302 and notice that we can write,\nQ\u0302ij = \u03b7\nn z\u2217R(i, j)z, (66)\nwhere z \u2208 Rm+n is a vector of i.i.d. N(0, 1) and R(i, j) \u2208 R(n+m)\u00d7(n+m) is defined has in lemma A.4. Letting \u03bdl denote the lth eigenvalue of the symmetric matrix R(i, j) we can further write,\nQ\u0302ij \u2212 E(Q\u0302ij) = \u03b7\nn\n(n+m)p\u2211\nl=1\n\u03bdl(z 2 l \u2212 1). (67)\nBy Lemma A.4 we know that,\n|\u03bdl| \u2264 1\n(1\u2212 \u03c3max)2 , (68)\n1\nn\n(n+m)p\u2211\nl=1\n\u03bd2l \u2264 2 (1\u2212 \u03c3max)3 ( 1 + 3 2n\n1\n1\u2212 \u03c3max\n) \u2264 3\n(1\u2212 \u03c3max)3 , (69)\nwhere we applied T > 3/D in the last line.\nNow we are done since applying Bernstein trick, this time with \u03b3 = 1/8 (1\u2212\u03c3max)3\u01eb/\u03b7, and making again use of the fact that log(1\u2212 x) > \u2212x\u2212 x2 for |x| < 1/2 we get,\nP(Q\u0302ij \u2212 E(Q\u0302ij) > \u01eb) = P( (n+m)p\u2211\nl=1\n\u03bdl(z 2 l \u2212 1) > \u01ebn/\u03b7) (70)\n\u2264 e\u2212 \u03b3\u01ebn \u03b7 e\u2212\u03b3 \u2211(n+m)p l=1 \u03bdl + e\u22121/2 \u2211(m+n)p l=1 log(1\u22122\u03b3\u03bdl) (71)\n\u2264 e\u2212 \u03b3\u01ebn \u03b7\n\u2212\u03b3 \u2211(n+m)p l=1 \u03bdl+\u03b3 \u2211(n+m)p l=1 \u03bdl+2\u03b3 2 \u2211(n+m)p\nl=1 \u03bd 2 l (72)\n\u2264 e\u2212 n 32\u03b72 (1\u2212\u03c3max) 3\u01eb2 , (73)\nwhere had to assume that \u01eb < 2/D in order to apply the bound on log(1 \u2212 x). An analogous reasoning leads us to,\nP(Q\u0302ij \u2212 E(Q\u0302ij) < \u2212\u01eb) \u2264 e\u2212 n 32\u03b72 (1\u2212\u03c3max) 3\u01eb2 (74)\nand the results follows.\nLemma A.5. As before, assume \u03c3max \u2261 \u03c3max(I + \u03b7A0) < 1 and consider that model (6) was initiated at time \u2212m with w(\u2212m), that is, x(\u2212m) = w(\u2212m) then\n|E(Q\u0302ij)\u2212Q0ij | \u2264 1\nn+m\n\u03b7\n(1 \u2212 \u03c3max)2 . (75)\nProof. Let \u03c1 = I + \u03b7A0. Since,\nQ0ij = \u03b7\n\u221e\u2211\nl=0\n(\u03c1l\u03c1\u2217l)ij , (76)\nand\nE(Q\u0302ij) = \u03b7\nn+m\u22121\u2211\nl=0\nm+ n\u2212 l n+m (\u03c1l\u03c1\u2217l)ij , (77)\nwe can write,\nQ0ij \u2212 E(Q\u0302ij) = \u03b7 ( \u221e\u2211\nl=m+n\n(\u03c1l\u03c1\u2217l)ij +\nn+m\u22121\u2211\nl=1\nl\nm+ n (\u03c1l\u03c1\u2217l)ij\n) . (78)\nUsing the fact that for any matrix A and B maxij(Aij) \u2264 \u03c3max(A), \u03c3max(AB) \u2264 \u03c3max(A)\u03c3max(B) and \u03c3max(A + B) \u2264 \u03c3max(A) + \u03c3max(B) and introducing the notation \u03b6 = \u03c12 we can write,\n|E(Q\u0302ij)\u2212Q0ij | \u2264 \u03b7 ( \u03b6n+m\n1\u2212 \u03b6 + \u03b6 n+m\nm+n\u22122\u2211\nl=0\n\u03b6l ) =\n\u03b7(\u03b62 + \u03b6n+m \u2212 2\u03b6m+n+1) (m+ n)(1\u2212 \u03b6)2 (79)\n\u2264 \u03b7 (m+ n)(1 \u2212 \u03c3max)2 , (80)\nwhere we used the fact that for \u03b6 \u2208 [0, 1] and n \u2208 N we have 1\u2212\u03b6 \u2265 1\u2212 \u221a \u03b6 and \u03b62+\u03b6n\u22122\u03b61+n \u2264 1.\nProof of Theorem 3.1:\nIn order to prove Theorem 3.1 we need to compute the probability that the conditions given by Proposition 4.1 hold. From the statement of the theorem we have that the first two conditions (\u03b1,Cmin > 0) of Proposition 4.1 hold. In order to make the first condition on G\u0302 imply the second condition on G\u0302 we assume that\n\u03bb\u03b1 3 \u2264 AminCmin 4k \u2212 \u03bb (81)\nwhich is guaranteed to hold if \u03bb \u2264 AminCmin/8k. (82)\nWe also combine the two last conditions on Q\u0302 to\n|||Q\u0302[p],S0 \u2212Q0[p],S0|||\u221e \u2264 \u03b1\n12 Cmin\u221a k . (83)\nWhere [p] = S0 \u222a (S0)c. We then impose that both the probability of the condition on Q\u0302 failing and the probability of the condition on G\u0302 failing are upper bounded by \u03b4/2. Using Proposition 4.2 we see that the condition on G\u0302 fails with probability smaller than \u03b4/2 given that the following is satisfied\n\u03bb2 = 36\u03b1\u22122(n\u03b7D)\u22121 log(4p/\u03b4). (84)\nBut we also want (82) to be satisfied and so substituting \u03bb from the previous expression in (82) we conclude that n must satisfy\nn \u2265 2304k2Cmin\u22122Amin\u22122\u03b1\u22122(D\u03b7)\u22121 log(4p/\u03b4). (85)\nIn addition, the application of the probability bound in Proposition 4.2 requires that\n\u03bb2\u03b12\n9 < 1/4 (86)\nso we need to impose further that,\nn \u2265 16(D\u03b7)\u22121 log(4p/\u03b4). (87) To use Corollary 4.4 for computing the probability that the condition on Q\u0302 holds we need,\nn\u03b7 > 3/D, (88)\nand \u03b1Cmin\n12 \u221a k < 2kD\u22121. (89)\nThe last expression imposes the following conditions on k,\nk3/2 > 24\u22121\u03b1CminD. (90)\nThe probability of the condition on Q\u0302 will be upper bounded by \u03b4/2 if\nn > 4608\u03b7\u22121k3\u03b1\u22122Cmin \u22122D\u22123 log 4pk/\u03b4. (91)\nThe restriction (90) on k looks unfortunate but since k \u2265 1 we can actually show it always holds. Just notice \u03b1 < 1 and that\n\u03c3max(Q 0 S0,S0) \u2264 \u03c3max(Q0) \u2264\n\u03b7\n1\u2212 \u03c3max \u21d4 D \u2264 \u03c3\u22121max(Q0S0,S0) (92)\ntherefore CminD \u2264 \u03c3min(Q0S0,S0)/\u03c3max(Q0S0,S0) \u2264 1. This last expression also allows us to simplify the four restrictions on n into a single one that dominates them. In fact, since CminD \u2264 1 we also have C\u22122minD\n\u22122 \u2265 C\u22121minD\u22121 \u2265 1 and this allows us to conclude that the only two conditions on n that we actually need to impose are the one at Equations (85), and (91). A little more of algebra shows that these two inequalities are satisfied if\nn\u03b7 > 104k2(kD\u22122 +A\u22122min)\n\u03b12DC2min log(4pk/\u03b4). (93)\nThis conclude the proof of Theorem 3.1.\nLemma A.6. Let \u03c3max \u2261 \u03c3max(I + \u03b7A0) and \u03c1min(A0) = \u2212\u03bbmax((A0 + (A0)\u2217)/2) > 0 then,\n\u2212\u03bbmin ( A0 + (A0)\u2217\n2\n) \u2265 lim sup\n\u03b7\u21920\n1\u2212 \u03c3max \u03b7 , (94)\nlim inf \u03b7\u21920 1\u2212 \u03c3max \u03b7\n\u2265 \u2212\u03bbmax ( A0 + (A0)\u2217\n2\n) . (95)\nProof.\n1\u2212 \u03c3max \u03b7 = 1\u2212 \u03bb1/2max((I + \u03b7A0)\u2217(I + \u03b7A0)) \u03b7 (96)\n= 1\u2212 \u03bb1/2max(I + \u03b7(A0 + (A0)\u2217) + \u03b72(A0)\u2217A0)\n\u03b7 (97)\n= 1\u2212 (1 + \u03b7u\u2217(A0 + (A0)\u2217 + \u03b7(A0)\u2217A0)u)1/2\n\u03b7 , (98)\nwhere u is some unit vector that depends on \u03b7. Thus, since \u221a 1 + x = 1 + x/2 +O(x2),\nlim inf \u03b7\u21920 1\u2212 \u03c3max \u03b7 = \u2212 lim sup \u03b7\u21920\nu\u2217 ( A0 + (A0)\u2217\n2\n) u \u2265 \u2212\u03bbmax ( A0 + (A0)\u2217\n2\n) . (99)\nThe other inequality is proved in a similar way.\nProof of Theorem 2.1:\nIn order to prove Theorem 2.1 we first state and prove the following lemma,\nLemma A.7. Let G be a simple connected graph of vertex degree bounded above by k. Let A\u0303 be its adjacency matrix and A0 = \u2212hI + A\u0303 with h > k then for this A0 the system in (1) has Q0 = \u2212(1/2)(A0)\u22121 and,\n|||Q0(S0)C ,S0(Q0S0,S0)\u22121|||\u221e = |||(A0(S0)C ,(S0)C )\u22121A0(S0)C ,S0 |||\u221e \u2264 k/h. (100)\nProof. A\u0303 is symmetric so A0 is symmetric. Since A\u0303 is irreducible and non-negative, PerronFrobenious theorem tells that \u03bbmax(A\u0303) \u2264 k and consequently \u03bbmax(A0) \u2264 \u2212h + \u03bbmax(A\u0303) \u2264 \u2212h + k. Thus h > k implies that A0 is negative definite and using equation (4) we can compute Q0 = \u2212(1/2)(A0)\u22121. Now notice that, by the block matrix inverse formula, we have\n(Q0S0,S0) \u22121 = \u22122C\u22121, (101)\nQ0(S0)C ,S0 = 1\n2 ((A0(S0)C ,(S0)C ) \u22121A0(S0)C ,S0C), (102)\nwhere C = A0S0,S0 \u2212A0S0,(S0)C (A0(S0)C ,(S0)C )\u22121A0(S0)C ,S0 and thus\n|||Q0(S0)C ,S0(Q0S0,S0)\u22121|||\u221e = |||(A0(S0)C ,(S0)C )\u22121A0(S0)C ,S0 |||\u221e. (103)\nRecall the definition of |||B|||\u221e, |||B|||\u221e = max\ni\n\u2211\nj\n|Bij |. (104)\nLet z = h\u22121 and write,\n(A0(S0)C ,(S0)C ) \u22121 = \u2212z(I \u2212 zA\u0303(S0)C ,(S0)C )\u22121 = \u2212z\n\u221e\u2211\nn=0\n(zA\u0303(S0)C ,(S0)C ) n, (105)\nA0(S0)C ,S0 = z \u22121zA\u0303(S0)C ,S0 . (106)\nThis allows us to conclude that |||(A0(S0)C ,(S0)C )\u22121A0(S0)C ,S0 |||\u221e is in fact the maximum over all path generating functions of paths starting from a node i \u2208 (S0)C and hitting S0 for a first time. Let \u2126i denote this set of paths, \u03c9 a general path in G and |\u03c9| its length. Let k1, ..., k|\u03c9| denote the degree of each vertex visited by \u03c9 and note that km \u2264 k, \u2200m. Then each of these path generating functions can be written in the following form,\n\u2211\n\u03c9\u2208\u2126i\nz|\u03c9| \u2264 \u2211\n\u03c9\u2208\u2126i\n1\nk1...k|\u03c9| (kz)|\u03c9| = EG((kz) Ti,S0 ), (107)\nwhere Ti,S0 is the first hitting time of the set S0 by a random walk that starts at node i \u2208 S0C and moves with equal probability to each neighboring node. But Ti,S0 \u2265 1 and kz < 1 so the previous expression is upper bounded by kz.\nNow what remains to complete the proof of Theorem 2.1 is to compute the quantities \u03b1, Amin, \u03c1min(A\n0) and Cmin in Theorem 1.1 . From Lemma A.7 we know that \u03b1 = 1\u2212 k/(k+m). Clearly, Amin = 1. We also have that \u03c1min(A0) = \u03c3min(A0) \u2265 k + m \u2212 \u03c3max(A\u0303) \u2265 m + k \u2212 k = m. Finally,\n\u03bbmin(Q 0 S0,S0) =\n1 2 \u03bbmin(\u2212(A0)\u22121) = 1 2\n1 \u03bbmax(\u2212A0) \u2265 1 2\n1 m+ k + k \u2265 1 4(m+ k) (108)\nwhere in the last step we made use of the fact that m + k > k. Substituting these values in the inequality from Theorem 1.1 gives the desired result."}], "references": [], "referenceMentions": [], "year": 2010, "abstractText": "We consider linear models for stochastic dynamics. To any such model can be as-<lb>sociated a network (namely a directed graph) describing which degrees of freedom<lb>interact under the dynamics. We tackle the problem of learning such a network<lb>from observation of the system trajectory over a time interval T .<lb>We analyze the l1-regularized least squares algorithm and, in the setting in which<lb>the underlying network is sparse, we prove performance guarantees that are uni-<lb>form in the sampling rate as long as this is sufficiently high. This result substan-<lb>tiates the notion of a well defined \u2018time complexity\u2019 for the network inference<lb>problem. keywords: Gaussian processes, model selection and structure learning, graphical models, sparsity<lb>and feature selection.", "creator": "LaTeX with hyperref package"}}}