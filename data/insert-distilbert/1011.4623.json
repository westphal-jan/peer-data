{"id": "1011.4623", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Nov-2010", "title": "Opinion Polarity Identification through Adjectives", "abstract": "\" what other people think \" has always been an important piece bearer of information taken during various decision - making processes. today people frequently make their opinions available via the internet, and as a result, the web has become an excellent information source for gathering consumer opinions. there are now numerous web resources containing such opinions, representing e. g., internal product reviews forums, discussion groups, and blogs. but, due to the large amount of information and the wide range of sources, it is essentially impossible for a customer to read all of the reviews and make an informed good decision on whether choosing to purchase the product. it is also difficult for the manufacturer or seller of a product to accurately monitor customer opinions. for meeting this broad reason, alongside mining customer reviews, or opinion aggregator mining, performance has become an always important issue for research in web information extraction. exactly one of the important topics published in this research area is the positive identification of opinion polarity. ideally the opinion market polarity of a review decision is usually expressed with values'positive ','negative'or'neutral '. we usually propose a technique for identifying marginal polarity of reviews by approximately identifying the polarity of the adjectives that appear in them. our subsequent evaluation shows the technique can provide accuracy predictions in the area of 73 %, which is usually well above the 58 % - 64 % provided by naive bayesian classifiers.", "histories": [["v1", "Sun, 21 Nov 2010 00:15:27 GMT  (81kb)", "http://arxiv.org/abs/1011.4623v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["samaneh moghaddam", "fred popowich"], "accepted": false, "id": "1011.4623"}, "pdf": {"name": "1011.4623.pdf", "metadata": {"source": "CRF", "title": "Opinion Polarity Identification through Adjectives", "authors": ["Samaneh Moghaddam"], "emails": ["sam39@cs.sfu.ca", "popowich@sfu.ca"], "sections": [{"heading": null, "text": "\u201cWhat other people think\u201d has always been an important piece of information during various decision-making processes. Today people frequently make their opinions available via the Internet, and as a result, the Web has become an excellent source for gathering consumer opinions. There are now numerous Web resources containing such opinions, e.g., product reviews forums, discussion groups, and Blogs. But, due to the large amount of information and the wide range of sources, it is essentially impossible for a customer to read all of the reviews and make an informed decision on whether to purchase the product. It is also difficult for the manufacturer or seller of a product to accurately monitor customer opinions. For this reason, mining customer reviews, or opinion mining, has become an important issue for research in Web information extraction. One of the important topics in this research area is the identification of opinion polarity. The opinion polarity of a review is usually expressed with values \u2018positive\u2019, \u2018negative\u2019 or \u2018neutral\u2019. We propose a technique for identifying polarity of reviews by identifying the polarity of the adjectives that appear in them. Our evaluation shows the technique can provide accuracy in the area of 73%, which is well above the 58%-64% provided by na\u00efve Bayesian classifiers.\nKeywords\nOpinion Polarity, Adjective Polarity, Opinion Mining, Information Extraction."}, {"heading": "1. INTRODUCTION", "text": "The Web has significantly changed the way that consumers express their opinions. Today product reviews exist in a variety of forms on the Web; however, reading a representative selection of product reviews to make a good decision is frequently a timeconsuming process. It is also difficult for the producer or seller of a product to make use of the reviews. Recently, there has been interest in the development and use of mining and summarization tools specifically for identifying opinion polarity [1][2].\nThe polarity of a word or opinion, also called semantic orientation, indicates the direction the word or opinion deviates from the norm for its semantic group. In other words, the polarity of the words or phrases directly shows the opinion of the text writer. Polarity usually ranges on over an ordinal (i.e., discrete) scale. This scale may be in the form either of an ordered set of numerical values (e.g., one to five \u201cstars\u201d), or of an ordered set of non-numerical labels (e.g., positive, negative, neutral); the only difference between these two cases is that in the former case the distances between consecutive scores are known while in the latter the distances are not known.\nIn this paper we propose an algorithm for identifying the polarity of customer reviews. This algorithm has three phases: extract adjectives and their frequencies from the given review, predict the polarity of each adjective using the learned classifier, and classify the review based on the polarity of the adjectives.\nThe remainder of the paper is organized as follows. The next section is concerned with the proposed technique and its phases, including \u2018similarity computation\u2019, \u2018polarity classification\u2019 and \u2018opinion\npolarity identification\u2019. In Section 3 we will explain the experimental results and the evaluation of our method. Sections 4 reviews related work and the last section provides conclusions and discusses future work."}, {"heading": "2. PROPOSED TECHNIQUE", "text": "Given a review, our algorithm first collects all of the adjectives from the review and then computes the frequency of each of them. In the next step, it predicts the polarity of each adjective using a learned classifier. Then by aggregating the polarity of the opinion\u2019s adjectives (based on their frequencies), the polarity of the opinion is identified.\nFor determining the polarity of an adjective, we use a na\u00efve Bayesian classifier which was learned by a set of positive, negative, and neutral adjectives. The input of this classifier is a tuple of values showing the similarity between the given adjective and three fixed adjectives \u2018excellent\u2019, \u2018mediocre\u2019 and \u2018poor\u2019 as representative of positive, neutral and negative adjectives. These similarity values are computed using two proposed similarity functions which are based on WordNet [3]. The first similarity function is based on the adjectives\u2019 synonyms and the second one is based on the stem of the adjectives and a predefined similarity function for nouns and verbs. In the following we explain each of these phases in detail."}, {"heading": "2.1 SIMILARITY COMPUTATION", "text": "In this phase we define a similarity function for computing similarity between two adjectives making use of the WordNet functions provided in NLTK [4]. While some similarity measures have been provided for working over collections of nouns and verbs, these similarity measures do not work for adjectives and adverbs, since these functions compute similarity between two words by using hyponym/hypernym (or is-a relations). Due to the limitation of is-a hierarchies which are only available in WordNet for nouns and verbs, the defined similarity functions only work with noun-noun and verb-verb parts of speech.\nThe first similarity function we define for adjectives is called SynSim which is based on three different features of a WordNet adjective: \u2018synonym\u2019 words, \u2018similar to\u2019 words and \u2018see also\u2019 words. All of these\nfeatures contain words (mainly adjectives) having the same or nearly the same meaning.\nWe take advantage of all three features and consider the words they contain as synonym words but with different weights. For example, in WordNet \u2018good\u2019 and \u2018excellent\u2019 are not listed as synonyms. They are listed as \u2018similar\u2019 words. So, if we just use synonym words we will lose a great deal of possibly appropriate words.\nIn addition, since \u2018synonymy\u2019 shows a stronger relation than \u2018similarity\u2019, and since \u2018similar words\u2019 are stronger than \u2018see also\u2019 words, we assign different weights to them. We apply the weights of 1, 0.9 and 0.8 for \u2018synonym\u2019 words, \u2018similar to\u2019 words and \u2018see also\u2019 words respectively. Ultimately, the best weight values can be found experimentally.\nWe can now define SynSim as a recursive method in which the similarity between adj1 and adj2 is computed using the similarity value between a synonym of adj1 and adj2. We propose a maximum recursion level of three for our initial experiments to control the running time. Table 1 shows some pairs of adjectives and their similarity values computed by the SynSim function.\nThe other similarity function, called StemSim, is based on one of the predefined similarity functions in NLTK for nouns and verbs (path_similarity). The StemSim first determines the stem of the given adjective which is usually a noun or verb. Of course the stem of some of the adjectives are themselves adjectives, like \u2018poor\u2019. In this case, the method searches for a noun or verb in the synonym list and use it instead of the stem. In the next step, StemSim uses the predefined path-similarity function to\ncompute the similarity of two corresponding stems. Table 2 shows the StemSim similarity values for some adjectives.\nComparing the results of the similarity functions shows that computing similarities based on synonym words is more accurate than computing similarities based on the stems of words. However, we use both functions in the next phases and compare the final results together.\nIn this subsection, we explained how to compute the similarity of two adjectives using synonyms or corresponding stems. In the next subsection we will explain how to use similarity values to determine the polarity of adjectives."}, {"heading": "2.2 POLARITY CLASSIFICATION", "text": "As we explained before, polarity of a word refers to its strength in a classification, typically in a \u2018positive\u2019 vs. \u2018negative\u2019 sense. In this work we consider three polarity levels for adjectives: positive, negative and neutral. An adjective can imply positive meaning, like \u2018excellent\u2019, negative meaning, like \u2018poor\u2019 and neutral meaning, like \u2018mediocre\u2019.\nFor determining the polarity of adjectives we use a na\u00efve Bayesian classifier to classify adjectives. We use a set of tagged adjectives for training and testing the classifier. In this set there are 30 adjectives, 10 of them are tagged as positive, 10 as negative and 10 as neutral adjectives (Table 3). We randomly select 15 adjectives for training the classifier and use the remaining as test set.\nThe input of na\u00efve Bayesian classifier is a set of tuples containing the similarity values between the given adjective and the three fixed adjectives \u2018excellent\u2019, \u2018mediocre\u2019 and \u2018poor\u2019. We use these three\nfixed adjectives as reference points to predict the polarity of other adjectives. These similarity values are computed using the two proposed similarity functions, SynSim and StemSim, which were introduced in Section 2.1. Table 4 shows the input for learning a classifier.\nTable3: Tagged adjectives used for training and\ntesting the classifier\nPositive Neutral Negative\ngood nice awesome excellent great perfect precious satisfactory exceptional outstanding mediocre average enough fair okay ordinary fine suitable reasonable neutral\nbad awful defective faulty poor unsatisfactory imperfect weak bitter terrible\nThe input of na\u00efve Bayesian classifier is a set of tuples containing the similarity values between the given adjective and the three fixed adjectives \u2018excellent\u2019, \u2018mediocre\u2019 and \u2018poor\u2019. We use these three fixed adjectives as reference points to predict the polarity of other adjectives. These similarity values are computed using the two proposed similarity functions, SynSim and StemSim, which were introduced in Section 2.1. Table 4 shows the input for learning a classifier.\nAs shown in Table 4, the method rounds the similarity values to be able to learn the classifier with\nvery few cases. Since the training set only has 15 tagged adjectives, it is very hard to learn the classifier by using the actual values. Details on the rounding process will not be introduced here due to space constraints.\nGiven an adjective from the training set, for example \u2018nice\u2019, the method computes three similarity values, excellent_sim = SynSim(\u2018nice\u2019,\u2018excellent\u2019) = 0.16, mediocre_sim = SynSim (\u2018nice\u2019, \u2018mediocre\u2019) = 0, and poor_sim = SynSim (\u2018nice\u2019, \u2018poor\u2019) = 0. Then it rounds them and sends them as a tuple (excellent_sim, mediocre_sim, poor_sim) to learn the classifier.\nThe accuracy of the learned classifiers (based on different similarity functions) and the most informative features for each is provided in Tables 5 and 6. Note that, the accuracy and important features of the classifiers may vary in different runs, since the training set is randomly selected.\nAs shown in Table 6 the accuracy of StemClassifier is almost the same as the accuracy of random classification (about 0.33 for three classes). So using the stems of adjectives is not a good method for classifying them. On the other hand, the accuracy of SynClassifier which is learned using SynSim function is high. The SynClassifier can correctly classify a new adjective as positive, negative, or neutral with the probability of 80% which is a high accuracy value in this area.\nIn addition, as we explained before, the size of the training set we used here is small (just 15 cases). So, it is mostly probable that if we increase the size of the training set, the accuracy of the classifier will be increased. In the following phases we will use both classifiers.\nAfter learning the classifier, the method is able to predict the polarity of new adjectives. Table 7 shows some sample adjectives which are classified by the learned classifiers. As we expected, the predicted polarities by the SynClassifier are more accurate than those by the StemClassifier.\nSo far the method can identify the polarity of a single adjective. In the next step it tries to predict the polarity of an opinion using the polarity of the adjectives appearing in the opinion."}, {"heading": "2.3 POLARITY IDENTIFICATION", "text": "The last phase of our technique involves determining opinion polarity. The polarity is determined by aggregating the polarity of the extracted adjectives based on their frequencies. In other words, for each review our method assigns the scores +1, 0, and -1 to the positive, neutral, and negative adjectives respectively. Each adjective is also assigned a weight which is equal to its frequency in that review. The polarity of the review is then determined by computing the weighted average of the adjective scores. We consider two methods, the first, SynPI, is based on SynClassifier, and the second, StemPI, is based on StemClassifier.\nTable 8 shows the accuracy, false-positive and falsenegative percentages of the two polarity identification\nmethods SynPI and StemPI. Note again that since the test set is selected randomly, the results may vary in different runs.\nAs shown in Table 8, the accuracy of opinion polarity classification methods, SynPI and StemPI, are 73% and 59% respectively. It shows that, as we expected, StemPI method does not perform well for opinion classification. On the other hand, the SynPI identifies the polarity of reviews with high accuracy which shows the power of the learned classifier (SynClassifier).\nIn the next section we will evaluate our proposed technique by comparing it with a baseline classification method."}, {"heading": "3. EVALUATION", "text": "In this section, we evaluate the accuracy of our proposed opinion polarity classifier, SynPI, by comparing it with a baseline classification method (presented in Chapter 6 of NLTK [4]). The baseline classification method is based on a na\u00efve Bayesian classifier learned using a set of tagged reviews. In order to evaluate our system, we use a set of reviews available via movie_reviews in nltk.corpus [4]. These reviews have been categorized into \u2018positive\u2019 and \u2018negative\u2019 classes. Our evaluation technique involves the random selection of a set of 100 reviews, which are then provided to our system for polarity prediction.\nThis baseline method first finds the most frequent words in the training set, and then uses them to learn the na\u00efve Bayesian classifier. Each feature of this classifier indicates whether the review contains a special word [4].\nTable 9 shows accuracy and the first five important features of BaselineClassifier for different sizes of training sets (25, 50 and 100). The size of the test set which is randomly selected in each run is 100.\nAs shown in Table 9, the accuracy of the baseline method is increased by increasing the size of the training set. By using 25 reviews in a training set the method does not perform better than random classification, and by using a training set with 100 reviews, we get the accuracy of 64%. Of course, as mentioned in the NLTK book, if we use the whole dataset (containing 2000 reviews) as a training set and just use 100 reviews for test, the accuracy will be about 80%. However, producing sufficient quantities of labeled data can be very expensive in manual effort.\nWe can see that, the accuracy of the baseline method when it is trained with 100 reviews is lower than our proposed method which required just 15 adjectives in its training. This is the first advantage of our proposed method which is that it is able to provide high accuracy while using a small training set, as summarized in Table 10.\nAnother advantage of our method is its independency from the context. The baseline method learns based\non the frequency of words in the given reviews. So, it totally depends on the context of the training dataset. As shown in Table 9, the important features of the classifier are totally dependent on the review context. So, for each context we need a specific classifier. On the other hand, our proposed method is independent from the context and it depends only on the adjectives that appear in the text. When our method learns the opinion classifier, it can be applied to other contexts."}, {"heading": "4. RELATED WORK", "text": "Polarity and subjectivity of words has been studied previously in two main classes of research. One class consists of work exclusively aimed at the determination of effective metrics for representing the polarity and subjective content of words [5][6]. The other class consists of work that performs word polarity as part of a larger investigation into opinion classification and related domains [1]. Our work lies in the second class, so we focus on the opinion classification in our related work.\nTurney in [1] introduces an unsupervised learning algorithm for rating a review as positive or negative (thumbs up or down). The algorithm extracts phrases containing adjectives or adverbs and also their Part Of Speech (POS) tags conform to any of the predefined patterns. This paper also proposes a method \u2018PMI-IR\u2019 for computing semantic orientation of the phrases. PMI-IR uses Pointwise Mutual Information (PMI) and Information Retrieval (IR) to measure the similarity of pairs of words or phrases. Finally, by averaging the polarity of the extracted phrases, the method classifies the review as positive or negative. Our proposed method is somewhat similar to Turney\u2019s method, except that we use three polarities, and require minimal training data.\nDave et al. in [7] describe a tool for sifting through and combining product reviews. They used structured reviews for training and testing. The method first selects features using some substitution methods, and then uses the proposed score function to determine the polarity of them. The proposed scoring method used some machine-learning techniques using the Rainbow text-classification package to identify the polarity of each feature. Finally it uses a trained classifier to classify the reviews as positive or negative. Our approach obtains similar performance,\nbut again requires less in the way of training information.\nKamps et al. in [8] investigate Osgood\u2019s measures based on the WordNet knowledge database. Using the adjectives \u2018good\u2019 and \u2018bad\u2019 to calculate semantic polarity of word is the main evaluative dimension of Osgood. The minimal distance d(wi,wj) between words and \u2018good\u2019 or \u2018bad\u2019 shows the similarity of their semantic orientation. So, like our work, they were influenced by WordNet, but we have the further distinction of neutral polarity.\nIn the same way, Yu et al. in [9] use the HowNet knowledge database to investigate Osgood\u2019s measures to see whether this approach can be used for Chinese. In this paper, sentiment features of text are divided into characteristic words and phrases, which are extracted from the training data. Their method combines HowNet with a sentiment classifier to compute semantic similarity of characteristic words with tagged words in HowNet. It adopts the positive and negative terms as features of a sentiment classifier.\nPang et al. [10] use three machine-learning methods (Na\u00efve Bayes, Maximum Entropy classification, and Support Vector Machines) for classifying reviews as positive or negative and show that the standard machine learning techniques outperform humanproduced baselines. The results also show that the SVM technique works better in comparison with the others, but requires a substantial amount of training information."}, {"heading": "5. CONCLUSION", "text": "This paper introduces a technique for classifying a review as positive, negative, or neutral. The algorithm has three phases: (1) extracting adjectives and their frequencies from the given review, (2) predicting the polarity of each adjective using the learned classifier, and (3) classifying the review based on the weighted average polarity of the adjectives. The core of the technique is the second phase, which uses WordNet to compute similarity values between two adjectives, and then uses the similarity values to learn the classifier for predicting polarity of each adjective.\nIn experiments with 100 reviews from the movie_reviews corpus in NLTK, our algorithm attains an accuracy of 73% while the baseline method in the best case can attain an accuracy of 64%. The\nkey advantage of our method is that it can attain high accuracy using a small training set.\nIn addition, our proposed opinion polarity classifier is independent from the context and can be applied to different review types. On the other hand, the baseline classifier totally depends on the context which limits its usage. In the end, we can say that high accuracy along with simplicity of our method may encourage further work with opinion polarity."}], "references": [{"title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews", "author": ["D. Turney P"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Automatic Opinion Polarity Classification of Movie Reviews", "author": ["F. Salvetti", "S. Lewis", "C. Reichenbach"], "venue": "Colorado Research in Linguistics. Volume 17, Issue", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2004}, {"title": "WordNet: An Electronic Lexical Database", "author": ["C. Fellbaum"], "venue": "Bradford Books,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Identifying Subjective Adjectives through Web-based Mutual Information", "author": ["M. Baroni", "S. Vegnaduzzo"], "venue": "Proceedings of KONVENS, Vienna: GAI", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Acquisition of subjective adjectives with limited resources", "author": ["S. Vegnaduzzo"], "venue": "In AAAI Spring Symposium Technical Report: Exploring Affect and Attitude in Text,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Mining the peanut gallery opinion extraction and semantic classification of product reviews\u201d, WWW2003", "author": ["K. Dave", "S. Lawrence", "M. Pennock D"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "m., \"Using WordNet to Measure Semantic Orientations of Adjectives", "author": ["J. Kamps", "M. Marx", "R. Mokken", "Rijke"], "venue": "Proceedings of the fourth international conference on Language Resources and Evaluation,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Opinion Mining: A Study on Semantic Orientation Analysis for Online Document", "author": ["L. Yu", "J. Ma", "S. Tsuchiya", "F. Ren"], "venue": "Proceedings of  the 7th World Congress on Intelligent Control and Automation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Thumbs up? Sentiment Classification using Machine Learning Techniques\u201d, ACL-02 conference on Empirical methods in natural language processing ", "author": ["B. Pang", "L. Lee", "S. Vaithyanathan"], "venue": "Volume 10,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}], "referenceMentions": [{"referenceID": 0, "context": "Recently, there has been interest in the development and use of mining and summarization tools specifically for identifying opinion polarity [1][2].", "startOffset": 141, "endOffset": 144}, {"referenceID": 1, "context": "Recently, there has been interest in the development and use of mining and summarization tools specifically for identifying opinion polarity [1][2].", "startOffset": 144, "endOffset": 147}, {"referenceID": 2, "context": "These similarity values are computed using two proposed similarity functions which are based on WordNet [3].", "startOffset": 104, "endOffset": 107}, {"referenceID": 3, "context": "One class consists of work exclusively aimed at the determination of effective metrics for representing the polarity and subjective content of words [5][6].", "startOffset": 149, "endOffset": 152}, {"referenceID": 4, "context": "One class consists of work exclusively aimed at the determination of effective metrics for representing the polarity and subjective content of words [5][6].", "startOffset": 152, "endOffset": 155}, {"referenceID": 0, "context": "The other class consists of work that performs word polarity as part of a larger investigation into opinion classification and related domains [1].", "startOffset": 143, "endOffset": 146}, {"referenceID": 0, "context": "Turney in [1] introduces an unsupervised learning algorithm for rating a review as positive or negative (thumbs up or down).", "startOffset": 10, "endOffset": 13}, {"referenceID": 5, "context": "in [7] describe a tool for sifting through and combining product reviews.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "in [8] investigate Osgood\u2019s measures based on the WordNet knowledge database.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "in [9] use the HowNet knowledge database to investigate Osgood\u2019s measures to see whether this approach can be used for Chinese.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "[10] use three machine-learning methods (Na\u00efve Bayes, Maximum Entropy classification, and Support Vector Machines) for classifying reviews as positive or negative and show that the standard machine learning techniques outperform humanproduced baselines.", "startOffset": 0, "endOffset": 4}], "year": 2010, "abstractText": "\u201cWhat other people think\u201d has always been an important piece of information during various decision-making processes. Today people frequently make their opinions available via the Internet, and as a result, the Web has become an excellent source for gathering consumer opinions. There are now numerous Web resources containing such opinions, e.g., product reviews forums, discussion groups, and Blogs. But, due to the large amount of information and the wide range of sources, it is essentially impossible for a customer to read all of the reviews and make an informed decision on whether to purchase the product. It is also difficult for the manufacturer or seller of a product to accurately monitor customer opinions. For this reason, mining customer reviews, or opinion mining, has become an important issue for research in Web information extraction. One of the important topics in this research area is the identification of opinion polarity. The opinion polarity of a review is usually expressed with values \u2018positive\u2019, \u2018negative\u2019 or \u2018neutral\u2019. We propose a technique for identifying polarity of reviews by identifying the polarity of the adjectives that appear in them. Our evaluation shows the technique can provide accuracy in the area of 73%, which is well above the 58%-64% provided by na\u00efve Bayesian classifiers.", "creator": "PScript5.dll Version 5.2.2"}}}