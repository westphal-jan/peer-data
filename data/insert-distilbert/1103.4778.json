{"id": "1103.4778", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2011", "title": "Formal and Computational Properties of the Confidence Boost of Association Rules", "abstract": "some existing notions of redundancy among association rules allow for a logical - style statistical characterization and lead to irredundant bases of reasonably absolutely minimum size. nevertheless one can push the simplest intuition term of redundancy functions further and find an intuitive notion of interest of an authentic association rule, in terms of its \" novelty \" together with respect to other rules. terms namely : an irredundant rule is so because its confidence is higher than what the rest of the rules would suggest ; then, one can ask : how much higher? we propose to measure such a sort of \" novelty \" through reviewing the confidence boost of a rule, which encompasses two previous similar notions ( confidence channel width and rule blocking, of which respect the latter is closely related to the earlier measure \" coefficient improvement \" ). acting as a complement to confidence and prediction support, the confidence boost model helps organizations to obtain small and easily crisp sets of mined internal association rules, and solves the well - known consensus problem that, in exactly certain cases, rules of negative correlation reduction may pass the confidence bound. we analyze the properties correctly of two versions of the notion of confidence boost, one of them a natural generalization of the other. we develop efficient algorithmics to filter rules according to their confidence boost, maybe compare the concept to some similar notions in the bibliography, and describe the results of experiencing some experimentation employing the new notions on standard benchmark datasets. we describe an ancient open - source association mining tool tool that embodies one of our variants of confidence key boost in doing such a way that the data mining process does not require the expert user able to select any value for any parameter.", "histories": [["v1", "Thu, 24 Mar 2011 14:45:50 GMT  (180kb,D)", "http://arxiv.org/abs/1103.4778v1", null]], "reviews": [], "SUBJECTS": "cs.DB cs.AI", "authors": ["jos\\'e l balc\\'azar"], "accepted": false, "id": "1103.4778"}, "pdf": {"name": "1103.4778.pdf", "metadata": {"source": "CRF", "title": "A Formal and Computational Properties of the Confidence Boost of Association Rules", "authors": ["JOS\u00c9 L. BALC\u00c1ZAR"], "emails": ["(joseluis.balcazar@unican.es)."], "sections": [{"heading": null, "text": "A Formal and Computational Properties of the Confidence Boost of Association Rules\nJOSE\u0301 L. BALCA\u0301ZAR, Universidad de Cantabria\nSome existing notions of redundancy among association rules allow for a logical-style characterization and lead to irredundant bases of absolutely minimum size. One can push the intuition of redundancy further and find an intuitive notion of interest of an association rule, in terms of its \u201cnovelty\u201d with respect to other rules. Namely: an irredundant rule is so because its confidence is higher than what the rest of the rules would suggest; then, one can ask: how much higher?\nWe propose to measure such a sort of \u201cnovelty\u201d through the confidence boost of a rule, which encompasses two previous similar notions (confidence width and rule blocking, of which the latter is closely related to the earlier measure \u201cimprovement\u201d). Acting as a complement to confidence and support, the confidence boost helps to obtain small and crisp sets of mined association rules, and solves the well-known problem that, in certain cases, rules of negative correlation may pass the confidence bound. We analyze the properties of two versions of the notion of confidence boost, one of them a natural generalization of the other. We develop efficient algorithmics to filter rules according to their confidence boost, compare the concept to some similar notions in the bibliography, and describe the results of some experimentation employing the new notions on standard benchmark datasets. We describe an open-source association mining tool that embodies one of our variants of confidence boost in such a way that the data mining process does not require the user to select any value for any parameter.\nGeneral Terms: Algorithms, Theory, Human factors\nAdditional Key Words and Phrases: Association rule mining, association rule quality, confidence\nACM Reference Format: ACM V, N, Article A (January YYYY), 36 pages. DOI = 10.1145/0000000.0000000 http://doi.acm.org/10.1145/0000000.0000000"}, {"heading": "1. INTRODUCTION", "text": "As the now well-known task of association rule mining was defined, the problems faced were twofold. First, the quantity of candidate itemsets for antecedent X and consequent Y of association rules X \u2192 Y grows exponentially with the often already large universe of items. The introduction of a support threshold parameter was a key advance that allowed for the design of efficient frequent set miners and for the computation of association rules in large datasets: there, exploration is limited to those itemsets that appear \u201coften enough\u201d as subsets of the transactions, that is, their relative frequency exceeds a certain ratio of the transactions; see [Agrawal et al. 1996] and the references there. Then, the second problem is that, often, the set of rules provided as output is too large, specially if we consider that its purpose is to be read, and understood, by a human. We consider that this problem warrants further research, and we attempt at providing here yet one more approach to it.\nAddress at the time of submission: Departmento de Matema\u0301ticas, Estad\u0301\u0131stica y Computacio\u0301n, Av Los Castros s/n, Santander 39005, Spain (joseluis.balcazar@unican.es). This work has been partially supported by project TIN2007-66523 (FORMALISM) of Programa Nacional de Investigacio\u0301n, Ministerio de Ciencia e Innovacio\u0301n (MICINN), Spain, and by the Pascal-2 Network of the European Union. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701 USA, fax +1 (212) 869-0481, or permissions@acm.org. c\u00a9 YYYY ACM 0000-0000/YYYY/01-ARTA $10.00 DOI 10.1145/0000000.0000000 http://doi.acm.org/10.1145/0000000.0000000\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nar X\niv :1\n10 3.\n47 78\nv1 [\ncs .D\nB ]\n2 4\nM ar\n2 01\n1\nThese two difficulties are of very different sorts. The exponential growth of candidates is essentially a combinatorial, almost technological problem, and all the existing solutions are based on the acceptance that, as not all the billions of candidates can be considered within reasonable running times, we make do with those that obey the support constraint. However, this solution puts unto the shoulders of the user the heavy responsibility of choosing the support threshold, with little or no guidance about how to do it.\nOn the other hand, it is no problem for our current computing equipments to extract association rules from frequent sets. The proposal in [Agrawal et al. 1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X \u2192 Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.\nIndeed, association rule mining, in essence, amounts to enumerating all the rules that are not disproved by the data. As there are exponentially growing quantities of potential associations, even relatively large datasets are unable to disprove most of them. Therefore, in the standard \u201csupport and confidence\u201d framework, it is well-known, and easy to check using any of the public datasets and free association miners available on the web, that whereas high, demanding thresholds for these parameters generally yield few somewhat obvious rules, softening them, as much as the algorithmics (and the user patience) would allow, leads to large amounts of rules, with many of them looking very much like each other; often, they are not a user-friendly enough result of a data mining process, due to the presence of these intuitive redundancies.\nAs a preliminary filter, there are several essentially logical definitions of redundancy, patterned after similar intuitions in Propositional or First-Order Logic. This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B?\u03b3 [Balca\u0301zar 2010c] for closure-based redundancy, at confidence threshold \u03b3, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications. All these questions are thoroughly surveyed in [Balca\u0301zar 2010c]. But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X \u2192 Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties. We note that, from the point of view of the user, the usage of alternative implicational measures leads to an even worse situation, as (s)he has to choose again both the measures to apply and their corresponding thresholds. The literature on this topic is huge and cannot be reviewed here; a discussion of the relationships of our contributions with the most relevant ones among the published proposals is deferred to Subsections 7.1 and 7.2.\nOur development is based on the simple consideration that rules can be evaluated for \u201cnovelty\u201d, by comparison with the rest of the rules mined. Actually, the outcome of every Data Mining project is expected to offer some degree of novelty. If one ends up identifying only facts whose validity is obvious, these would not be really useful. However, to formally study the novelty of Data Mining results is far from being a trivial task. Indeed, novelty is, in an intuitive sense, a relative notion: it refers to facts that are, somehow, unexpected; hence, some \u201clow expectation\u201d reason must exist, and must be due to alternative facts or prediction mechanisms. That is: a piece of information is novel or is not, always with respect to a given context of previously known facts; definitions of novelty must take into account, then, some form of previously available knowledge, a notion hard to formalize (Subsection 7.1 describes some approaches, but see e.g. [Padmanabhan and Tuzhilin 2000] and the references therein).\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nHowever, as one very partial and probably insufficient, but necessary action, we claim that, as a minimum, each rule should be evaluated for novelty by comparison with the rest of the rules mined, treated as \u201calternative\u201d mechanism [Balca\u0301zar 2009]. One can attempt at measuring to what extent the confidence of the rule is substantially higher than that of related rules that would, intuitively, explain the same facts. In the same reference, the confidence width is proposed as a measure of a relative form of objective novelty or surprisingness of each individual rule with respect to other rules that hold in the same dataset. As some intuitive redundancies are not covered by that measure, the same paper proposes also to allow some rules to block other rules in case the blocked rule does not bring in enough novelty with respect to the blocker. (We give below the precise definitions of these notions.) Essentially, these proposals measure novelty through the extent to which the confidence value is \u201crobust\u201d, taken relative to the confidences of related rules, as opposed to the absolute consideration of the single rule at hand.\nTo give a hint of the sort of process we are discussing, assume a rule, of confidence say 75%, is found in a census-like dataset, stating that young people earn lesser salaries; in the presence of such a rule, a more complex one stating that young, unmarried people earn lesser salaries could be novel, but only if its confidence turns out to be substantially higher than 75%, maybe 90%. Otherwise, it would not be novel, the simpler rule should be preferred, and even the complex rule discarded (or blocked), all depending on thresholds on confidence and on some other parameter such as improvement [Bayardo et al. 1999], blocking factor, or confidence boost (to be introduced here). Further discussion will be provided along the body of the paper.\nIt was empirically demonstrated in [Balca\u0301zar 2009] that better results were obtained using both a confidence width threshold and a blocking threshold, than using a single one of these filters (or none). However, no really fast way of testing a rule for blockings was provided. Thus, our contribution here is a new attempt at formalizing the notion of novelty, the confidence boost, similar in its syntactic definition to confidence width, but different in its semantics, which is more restrictive; its main feature is that it encompasses at once both the bound on the confidence width and the ability to detect that a rule would be blocked, so that the confidence boost bound embodies both of the bounds proposed in [Balca\u0301zar 2009], yet it is computable with reasonable efficiency. Confidence boost comes in two flavors: a \u201cplain\u201d one, that we develop in Section 3, and a more general variant that takes into account the closure space implicit in the data, developed in Section 4.\nThree short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balca\u0301zar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balca\u0301zar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.2 (but not its correctness proof). Reference [Balca\u0301zar 2010a] contains the definition of closure-based confidence boost and part of the materials in Section 4, again including the main algorithm but not its correctness proof, as well as materials from Subsection 5.2. The tool yacaree which embodies closure-based confidence boost into a parameter-free association miner (Section 6) was advertised at [Balca\u0301zar 2011] (demo track). The rest of Sections 3, 4, and 5, as well as the discussions in Section 7, are unpublished."}, {"heading": "2. PRELIMINARIES", "text": "A given set of available items U is assumed; its subsets are called itemsets. We will denote itemsets by capital letters from the end of the alphabet, and use juxtaposition to denote union, as in XY . The inclusion sign as in X \u2282 Y denotes proper subset, whereas improper inclusion is denoted X \u2286 Y . For a given dataset D, consisting of n transactions, each of which is an itemset labeled with a unique transaction identifier, we can count the support sD(X) of an itemset X, which is the cardinality of the set of transactions that contain X. An\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nalternative rendering of support is its normalized version, the relative frequency or empirical probability sD(X)/n; we will work with the unnormalized quantity.\nAssociation miners explore datasets in search of valid expressions of the form X \u2192 Y , where X and Y stand for itemsets. Intuitively, an association rule X \u2192 Y means that, in the given dataset, the transactions that contain X \u201ctend to contain\u201d Y as well. The confidence of a rule X \u2192 Y is cD(X \u2192 Y ) = sD(XY )/sD(X), akin to an empirical approximation to a conditional probability. It is important to observe that the precise definition of association rules depends on the formalization chosen for the informal expression \u201ctend to\u201d, as only then these syntactical expressions become endowed with a concrete semantics and associated specific properties. For instance, if we define the meaning of X \u2192 Y through confidence, then rules X \u2192 Y and X \u2192 XY are equivalent, whereas, if we use lift (defined below), then they may not be equivalent.\nConfidence is a very natural notion to prune and rank the output of an association rule mining algorithm, but we must point out that, due to some objections that we review in Subsection 2.2, there exist other proposals of notions to replace confidence. When confidence is 1, the maximum value, we say that X \u2192 Y is an implication: every transaction containing X contains as well Y . Sometimes we use the term partial rule for an association rule of confidence less than 1. The support of a rule X \u2192 Y is sD(X \u2192 Y ) = sD(XY ). When the dataset is clear from the context, we will omit the subscript D from both support and confidence. We do allow X = \u2205 as antecedent of association rules: then the confidence coincides with the normalized support, c(\u2205 \u2192 Y ) = s(Y )/s(\u2205) = s(Y )/n. Allowing Y = \u2205 as consequent as well is possible but not very useful, as this case leads only to trivial rules equivalent to reflexivity statements; therefore we assume that such rules are omitted from all our sets of rules. In the proposal of [Agrawal et al. 1996], association rules are restricted to |Y | = 1. This allows for faster algorithmics, as rules are directly obtained from each frequent set. In fact, whereas confidence 1 implications, say, A \u2192 B and A \u2192 C jointly are indeed equivalent to A \u2192 BC, for confidence less than 1 they are not. A \u2192 BC says that B and C appear jointly often with A, whereas associations A\u2192 B and A\u2192 C, even together, provide less information, as B and C could appear often with A but not so much together (we offer an example below). Thus, we do not force |Y | = 1.\nIn many cases we assume that the context provides for a threshold on the confidence, imposing a constraint c(X \u2192 Y ) \u2265 \u03b3 on rules, and likewise a support threshold constraint s(X \u2192 Y ) > \u03c4 . It is formally convenient to use strict inequality in the latter case, to easily cater for the case where no support bound is imposed, by simply taking \u03c4 = 0; whereas, for confidence, we prefer to be able to select full-confidence implications via the nonstrict inequality with \u03b3 = 1.\nRemark 2.1. As we consider mainly confidence and support, rules X \u2192 Y and X \u2192 XY are equivalent in almost all our statements, as are all rules where some part of the left-hand side X is repeated in the right-hand side. Our novelty notions will respect as well this equivalence. The only exceptions will be in our brief considerations of lift. Two natural canonical choices to simplify the discussion are to restrict the discussion either to the rules of the form X \u2192 Y or to those of the form X \u2192 XY , where, in both cases, X \u2229 Y = \u2205. We will see in Subsection 7.2 that failing to clarify this option risks overlooking subtle differences among sets of rules enjoying, however, quite different properties. Based on the similar developments in implications and functional dependencies, we choose the latter: we will make explicit always what part of the consequent is already in the antecedent and write all our association rules as X \u2192 XY where X \u2229 Y = \u2205. However, this choice is somewhat arbitrary, and whomever prefers association rules with disjoint sides only needs to remove the copy of the antecedent from the consequent. In fact, in our implementations, at the time of showing a rule to the user, of course only the Y part of the consequent is shown.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nGiven a dataset D, an itemset X \u2286 U is closed if the support of any strictly larger itemset is strictly smaller; and is free, or a minimal generator, if the support of any strictly smaller itemset is strictly larger. We denote as X the closure of itemset X with respect to a given dataset: X is the smallest closed itemset that includes X or, equivalently, the largest itemset that includes X and has the same support as X in the dataset. It is easy to check that it is unique. The intersection of closed itemsets is closed and, ordered by inclusion, the closed itemsets form a lattice which we call \u201cclosure space\u201d. We will make liberal use of the three characteristic properties of closure operators, namely, extensivity: X \u2286 X; monotonicity: X \u2286 Y implies X \u2286 Y ; and idempotency: X = X. We will mention below further details about the connections of closure operators and free sets with association mining; see e. g. [Boulicaut et al. 2003; Zaki 2004] for further information.\nExample 2.2. We will employ as running example through most of this paper the closure space obtained from a specific dataset. For this example, the universe U includes the five items A, B, C, D, and E. The dataset consists of 12 transactions, six of which include all of U ; two more consist of ABC, again two transactions consist of AB, and then one transaction consists of CDE and another one consists of BC. It is easy to see that the associated closure-space lattice is as depicted in Figure 1, where transitive arcs have been omitted and, besides the closed sets, three minimal generators (connected to their closures) have been indicated in broken lines. The supports of all closed sets are reported in the figure for convenience. The support of each minimal generator coincides with that of its closure. Note that sometimes the minimal generator coincides with its closure, as in set BC, for one. This example illustrates that, at confidence 9/11, both the association rules B \u2192 A and B \u2192 C hold, whereas the stronger rule B \u2192 AC does not, as its confidence is only 8/11. That is, if and when B \u2192 AC holds, it would give more information than B \u2192 A and B \u2192 C holding jointly.\nWe will propose to measure the novelty of each rule with respect to the rest of the outcome of the same data mining process, through a variant of the intuitive idea of redundancy. Several notions of redundancy for association rules exist. In the early proposal [Luxenburger 1991], a rule is redundant if its confidence can be computed from that of other rules. Later, this idea has been refined, making precise what information is maintained and which operations are allowed to infer confidence or support of redundant rules: see the survey of\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nseveral concise representations and redundancy notions in [Kryszkiewicz 2002]. In [Pasquier et al. 2005] (and in earlier conference versions of their work) the following set of rules is shown to be sufficient to compute the confidence and support of any given partial rule:\nDefinition 2.3. Given a dataset and a support threshold \u03c4 acting on all sets and rules:\n(1) The min-max rules are those of the form X \u2192 XY where XY is a closed set and X is a minimal generator; they are split into the following two cases. (2) The min-max approximate rules are those of the form X \u2192 XY where XY is a closed set, X is a minimal generator, and X \u2282 XY . They have confidence less than 1. (3) The min-max exact rules are those of the form X \u2192 XY where XY is a closed set, X is a minimal generator, and X = XY . They have confidence 1.\nSimilar notions of redundancy are studied in [Zaki 2004], where, however, the approximate bases are constructed as rules having minimal generators both at the left- and at the righthand sides. These bases are quite more succinct than the sets of all association rules that hold in a specific dataset, yet they still conform far too large quantities in many cases of interest. Therefore, less demanding notions of redundancy for association rules have been studied. If we assume that the set of frequent closures is kept, so that confidences are easily computed from them, and focus on the \u201cuser-centric\u201d view, there is a very precise and natural notion that allows us to identify irredundant bases of absolutely minimum size. For the whole paper, we concentrate basically on this redundancy notion, and on a somewhat more sophisticate variant that we will describe in Section 4.\nLemma 2.4. Consider two association rules, X0 \u2192 X0Y0 and X1 \u2192 X1Y1. The following are equivalent:\n(1 ) The confidence and support of X0 \u2192 X0Y0 are always larger than or equal to those of X1 \u2192 X1Y1, in all datasets; that is, for every dataset D, we will have cD(X0 \u2192 X0Y0) \u2265 cD(X1 \u2192 X1Y1) and sD(X0Y0) \u2265 sD(X1Y1) in it. (2 ) X1 \u2286 X0 \u2286 X0Y0 \u2286 X1Y1. When these cases hold, we say that X1 \u2192 X1Y1 makes X0 \u2192 X0Y0 redundant, or also that X1 \u2192 X1Y1 is logically stronger than X0 \u2192 X0Y0. The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b]. For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis. Hence, a redundant rule is so because we can know beforehand, from the information in a basis, that its confidence will be above the threshold. These references also explain how to compute the representative basis out of the closed itemsets for the dataset.\nThe fact that statement (2) implies statement (1) in Lemma 2.4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms). The converse implication is nontrivial and much more recently shown [Balca\u0301zar 2010c]; see this reference as well for the proof that the representative basis has the minimum possible size among all bases for this notion of redundancy, and for discussions of other related redundancy notions. In particular, several other natural proposals are shown there to be equivalent to this redundancy. Also, from this same source, we will consider later on a variant which makes a deeper use of the closure operator.,\nA known property that relates representative rules to closure-based miners is:\nProposition 2.5. On a given dataset and in the presence of a fixed support threshold \u03c4 , consider the association rule X \u2192 XY , and set \u03b3 = c(X \u2192 XY ). The following are equivalent:\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\n(1 ) X \u2192 XY is a representative rule for some confidence threshold. (2 ) X \u2192 XY is a min-max rule: XY is a closed set and X is a minimal generator. (3 ) X \u2192 XY is a representative rule for confidence threshold \u03b3.\nHence, whenever we refer to X \u2192 XY as a representative rule, without mention of the specific confidence threshold \u03b3 for which it is so, we implicitly understand that we mean \u03b3 = c(X \u2192 XY ). The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X \u2192 XY is a representative rule then s(X) < s(X \u2032) for all X \u2032 \u2282 X, and s(Z) < s(XY ) for all Z with XY \u2282 Z; that is, X is a minimal generator and XY is closed.\nWe have not found the other implications explicitly stated, but they appear implicitly, in a sense, in the references that discuss these notions. We sketch here the rather simple proofs for completeness. Set \u03b3 = c(X \u2192 XY ). We assume that X \u2192 XY is a min-max rule, and consider a different rule, X \u2032 \u2192 X \u2032Y \u2032, logically stronger than X \u2192 XY ; we must argue that it fails the confidence threshold. By Lemma 2.4, we have X \u2032 \u2286 X and XY \u2286 X \u2032Y \u2032. If the left-hand sides differ, X \u2032 \u2282 X and, X being a minimal generator, s(X \u2032) > s(X); then c(X \u2032 \u2192 X \u2032Y \u2032) \u2264 c(X \u2032 \u2192 XY ) < c(X \u2192 XY ) = \u03b3. If, instead, X \u2032 = X, then XY \u2282 X \u2032Y \u2032 and, XY being closed, s(X \u2032Y \u2032) < s(XY ); we obtain that c(X \u2032 \u2192 X \u2032Y \u2032) = c(X \u2192 X \u2032Y \u2032) < c(X \u2192 XY ) = \u03b3 again. The remaining implication, (3) to (1), is obvious.\nExample 2.6. One can check that the dataset and the closure space of Example 2.2 lead to seven representative rules at confidence threshold 0.8, namely, A\u2192 BC, C \u2192 AB, B \u2192 C, \u2205 \u2192 C, \u2205 \u2192 AB, and D \u2192 ABCE, and E \u2192 ABCD. The first two have confidence exactly 0.8, the others have confidences slightly higher.\nFor fixed confidence thresholds, the representative rules at that confidence form often a properly smaller basis than the min-max rules; this can be achieved because of two reasons. One is that, obviously, min-max rules of confidence below the threshold are omitted. But a more sophisticate reason is that a representative rule at a given confidence \u03b3 may cease to be so at lower confidences: at a lower threshold \u03b3\u2032 it is possible that a stronger rule appears that makes it redundant. This observation is key in the notion of confidence width that we review next."}, {"heading": "2.1. Confidence Width", "text": "Along most of our discussions in this paper, we assume that a dataset D and a support threshold \u03c4 have been fixed: all our rules are assumed to reach strictly above that support threshold on D.\nAccording to the definition of redundancy in Lemma 2.4, all rules in the representative basis provide some irredundant information. However, it is often the case that still the representative basis contains more rules than reasonable for human inspection. In [Balca\u0301zar 2009], the intuition of redundancy is pushed further in order to gain a perspective of novelty of association rules. An irredundant rule of a given confidence c belongs to the basis for that confidence threshold \u03b3 = c: no rule of that confidence or higher makes it redundant; equivalently, all rules that make it redundant have lower confidence. Then, one can ask: \u201chow much lower?\u201d. This can be evaluated by means of the following definition from the same reference:\nDefinition 2.7. For an association rule X \u2192 XY , consider all rules that are not equivalent to X \u2192 XY (as per Remark 2.1), but such that X \u2192 XY is redundant with respect to them, and pick one with maximum confidence in D among them, say X \u2032 \u2192 X \u2032Y \u2032. The\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nconfidence width of X \u2192 XY in D is:\nw(X \u2192 XY ) = c(X \u2192 XY ) c(X \u2032 \u2192 X \u2032Y \u2032)\nThe condition that X \u2192 XY is redundant with respect to X \u2032 \u2192 X \u2032Y \u2032 implies that c(X \u2032 \u2192 X \u2032Y \u2032) \u2264 c(X \u2192 XY ), hence the confidence width is always 1 or larger. In fact, w(X \u2192 XY ) is strictly higher than 1 if and only if X \u2192 XY is a representative rule.\nTo explain better the intuition behind the notion of confidence width, consider a rule X \u2192 XY of a given confidence, say c(X \u2192 XY ) = c0 \u2208 [0, 1], and let us see what happens as we mine the representative basis at a varying confidence threshold \u03b3. If c0 < \u03b3, the rule at hand will not play any role at all, being of confidence too low for the threshold. At \u03b3 = c0, the rule becomes part of the output of any standard association mining process, but it could be that some other \u201clogically stronger\u201d rule appears at the same confidence c0. For instance, it could be that both rules A\u2192 AB and A\u2192 ABC have confidence c0: then A\u2192 AB is redundant and will not belong to the basis for that confidence. In this case, the confidence width is 1, its smallest possible value.\nIf no stronger rule appears at threshold \u03b3 = c0, then X \u2192 XY will belong to the representative basis for that threshold. Let us keep decreasing the threshold. At some lower confidence, a logically stronger rule may appear. If a logically stronger rule shows up early, at a confidence threshold \u03b3 very close to c0, then the rule X \u2192 XY is not very novel: it is too similar to the logically stronger one, and this shows in the fact that the interval of confidence thresholds where it is a representative rule is narrow. Its confidence width will be barely above 1. To the contrary, a stronger rule may take long to appear: in that case, only rules of much lower confidence entail X \u2192 XY , so that the fact that it does reach confidence c0 is novel in this sense. The interval of confidence thresholds where X \u2192 XY is a representative rule is wide, as will be the value of the confidence width. For instance, if the confidence of A \u2192 AB is 0.9, and all rules that make it redundant have confidences below 0.75, the rule is a much better candidate to novelty than it would be if some rule like A \u2192 ABC would have a confidence of 0.88: in this last case, A \u2192 AB indeed brings in additional information, but its novelty, with respect to the other rules, is not high; it only belongs to the basis when the confidence threshold is in the interval (0.88, 0.9]. In the other case where all rules that could make it redundant have confidences, say, 0.75 or less, then A \u2192 AB would belong to the basis for a considerably wider interval of confidences, (0.75, 0.9]. It states something really different from the rest of the information mined. As an objective novelty measure, thus, confidence width measures the width of the interval of confidences in which the rule at hand belongs to the representative basis.\nIt is proved in [Balca\u0301zar 2009] that, in Definition 2.7, it suffices to consider representative rules for the role of X \u2032 \u2192 X \u2032Y \u2032.\nExample 2.8. For association rule A \u2192 BC, of confidence 0.8, in Example 2.2, the confidence width is 1.2. The confidence of that rule is at least 20% higher than that of any rule that entails it. Indeed, there are two representative rules logically stronger, namely A \u2192 BCDE (of confidence 0.6) and \u2205 \u2192 ABC (of higher confidence, 2/3); hence, w(A\u2192 BC) = (8/10)/(2/3) = 1.2.\nBelow we will need Definition 2.7 in a single formula; for this, we can replace the redundancy condition with its characterization according to Lemma 2.4: w(X \u2192 XY ) =\n= c(X \u2192 XY ) max{c(X \u2032 \u2192 X \u2032Y \u2032) \u2223\u2223 (X \u2192 XY ) 6= (X \u2032 \u2192 X \u2032Y \u2032), X \u2032 \u2286 X, XY \u2286 X \u2032Y \u2032}\nwhere again we are assuming that X \u2229 Y = \u2205 and X \u2032 \u2229 Y \u2032 = \u2205.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nFor each fixed support, there are rules that are not redundant with respect to any other, different rule; then, this quotient is undefined due to the emptiness of the set in the denominator, for instance, if all candidate rules to it are of too low support. By convention, we use \u221e as value of the confidence width in that case (equivalently, likening the max to a zero). We can identify easily which rules have infinite width (this proposition is reported here for the first time):\nProposition 2.9. The value of w(X \u2192 XY ) is finite and well-defined if and only if either X 6= \u2205, or Y has some proper superset Z with s(Z) > \u03c4 . Proof. Indeed, if X = \u2205 and no proper superset of Y reaches support above \u03c4 in the dataset, then no rule can make \u2205 \u2192 Y redundant; conversely, for s(Z) > \u03c4 , \u2205 \u2192 Z is different from X \u2192 XY and makes it redundant if either X 6= \u2205 and Z = XY , or XY \u2282 Z; since this second case only needs to be applied to rules with X = \u2205, Y \u2282 Z suffices.\nThus, the only rules of infinite width are of the form \u2205 \u2192 Z with Z maximal under the condition that s(Z) > \u03c4 , and their confidence would coincide with the normalized support of Z. We observe in passing that, in practice, such maximal Z\u2019s usually have a support barely above \u03c4 , because all supersets must have a support falling below \u03c4 ; whenever the confidence threshold is substantially higher than the normalized support threshold (which does not happen always but extremely often), all rules of infinite width will be filtered out by the confidence constraint.\nIt is easy to prove a simple observation, that will be useful to compare below with confidence boost: consider the condition XY \u2286 X \u2032Y \u2032 in the rules entering the maximization of the denominator; it can be written equivalently as follows, using the other condition that X \u2032 \u2286 X and the empty-intersection assumptions:\nProposition 2.10. Assume X \u2032 \u2286 X, X \u2229 Y = \u2205, and X \u2032 \u2229 Y \u2032 = \u2205. Then XY \u2286 X \u2032Y \u2032 \u21d0\u21d2 (X \u2212X \u2032) \u2286 Y \u2032 and Y \u2286 Y \u2032.\nIn [Balca\u0301zar 2009], some intuitions are described that suggest that, for a confidence threshold \u03b3, a natural choice could be to set the confidence width threshold at 2\u2212 \u03b3; however, so far no formal support for this proposal (or any other proposal, for that matter) is known."}, {"heading": "2.2. Blocking Rules", "text": "On the basis of a clear, simple intuition described in many papers (e.g. [Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balca\u0301zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.\nThe main question behind this option is the following. Consider an association rule X \u2192 XY , and reduce the antecedent to a smaller Z \u2282 X. Whereas, intuitively, the rule with larger antecedent should be subsumed by the other, this is due to the human intuitive habit of working with full implications, where indeed this is the case. But this is not so anymore with association rules. For instance, at confidence 1, if A \u2192 C holds, then AB \u2192 C also holds, and does not bring new information. But association rules are not implications; instead, they relate relative frequencies: compared to X \u2192 XY , a smaller antecedent Z \u2282 X does not lead to a new rule Z \u2192 ZY that entails it. Actually, for Z \u2282 X, either of X \u2192 XY or Z \u2192 ZY may have arbitrarily higher confidence than the other. Indeed: rule X \u2192 XY speaks about the abundancy of Y among the population of transactions that contain X; reducing the antecedent into Z changes the population into, in principle, a larger one, and Y can be distributed at very different rates along each of these two sets of transactions. The distribution of Y in the larger population supporting Z can be very imbalanced, so that Y can appear more frequently in either.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nExample 2.11. Consider two association rules like A \u2192 C and AB \u2192 C. It is easy to construct examples where almost all transactions with A and B have C, but they are a small fraction of those having A, and thus the confidence of A\u2192 C is very small, whereas that of AB \u2192 C is high, even 1; conversely, C might hold for nearly all of the transactions having A, but it could be that the only transactions having both A and B are those without C and, then, the confidence of AB \u2192 C can be zero yet the confidence of A \u2192 C can be very high.\nExample 2.12. Returning briefly to the dataset of Example 2.2, it is easy to check that c(\u2205 \u2192 BC) < c(A\u2192 BC) whereas c(\u2205 \u2192 C) > c(B \u2192 C).\nAs a consequence, we also find the fundaments of the criticism that confidence does not detect negative correlations.\nExample 2.13. Fix a confidence threshold at 0.75, and consider a simple dataset with 10 transactions: 3 transactions BC, 6 transactions just C, and 1 transaction B. Then c(B \u2192 BC) = 0.75, reaching the confidence threshold. Most association miners would report B \u2192 C as interesting at that threshold. However, the correlation between B and C is actually negative. Indeed, C is less frequent among the transactions having B than in the total population, as c(\u2205 \u2192 C) = s(C)/n = 0.9.\nThe natural reaction, consisting of a normalization by dividing the confidence by the (normalized) support of the consequent of the rule, gives a parameter that we find in the references going by several different names: it has been called interest [Silverstein et al. 1998] or, in a slightly different but fully equivalent form, strength [Shah et al. 1999]; \u201clift\u201d seems to be catching up as a short name, possibly aided by the fact that the Intelligent Miner system from IBM employed that name. The quantity is well-known in basic probability, as it measures the deviation from independence, as a multiplicative distance from the case of fully independent X and Y , which would give value 1 for it:\nDefinition 2.14. The lift of rule X \u2192 Y is c(X\u2192Y )s(Y )/n = s(XY )\u00d7n s(X)\u00d7s(Y ) .\n(If supports are already normalized, then the factor n for the dataset size in the numerator has to be omitted.) The related parameter leverage [Piatetsky-Shapiro 1991] measures essentially the same thing, just that it does so as an additive distance. It must be noted that, contrary to confidence, the lift of X \u2192 Y does not coincide with the lift of X \u2192 XY : if we are to use lift, then we must be careful to keep the right-hand side Y disjoint from the left-hand side: X \u2229Y = \u2205. Otherwise, misleadingly higher lift values are obtained. Note also that, in case X = \u2205, the lift trivializes to 1.\nHowever, this natural measure lacks the ability to orient the rules, because, in it, the roles of X and Y are symmetric. Additionally, lift is limited in its ability to control cases where c(Z \u2192 Y ) > c(X \u2192 Y ) for \u2205 6= Z \u2282 X. We describe a case found in data from real census information, pointed out also in [Balca\u0301zar 2009]. Mining for association rules at 5% support and 100% confidence the Adult dataset from Irvine [Asuncion and Newman 2007], 67 (out of 71) rules in the basis are of the form \u201cHusband\u201d + something else \u2192 \u201cMale\u201d, and the other four rules are also of this form except for the addition of one more item in the consequent. The reason is that the rule \u201cHusband\u201d \u2192 \u201cMale\u201d, that we would expect to hold, does not reach 100% confidence: indeed, tuple 7110 includes the items \u201cHusband\u201d and \u201cFemale\u201d (instead of \u201cMale\u201d). This opens the door to many rules, intuitively uninformative, that enlarge a bit the left-hand side, just enough to avoid tuple 7110 so as to reach confidence 100%. The whole issue would not be solved by dividing all confidences by the support of \u201cMale\u201d. Further examples are given in the same paper, and in many others such as those cited above.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nIt is desirable to react to the negative correlation problem for confidence and still maintain orientability. As an alternative approach to this problem, in [Balca\u0301zar 2009] the confidence parameter is used in an intuitive way to find a threshold at which a smaller antecedent would suggest to omit a given rule. The proposal there is fully equivalent to the following one:\nDefinition 2.15. Given rule X \u2192 XY , with X \u2229 Y = \u2205, a proper subset Z \u2282 X blocks X \u2192 XY at blocking threshold b if\ns(XY )\u2212 c(Z \u2192 ZY )s(X) c(Z \u2192 ZY )s(X) \u2264 b.\nThe threshold b is intended to take positive but small values, say around 0.2 or lower. The intuition behind this definition is as follows: we will want to discard rule X \u2192 XY in case we find a rule Z \u2192 ZY , with Z \u2282 X (and therefore ZY \u2282 XY , also properly), having \u201calmost\u201d the same confidence, or larger. (In the presence of a support threshold \u03c4 , we would be requiring as well, naturally, that s(Z \u2192 ZY ) > \u03c4 .) To do this, we compare the number of tuples having XY with the quantity that would be predicted from the confidence of the rule Z \u2192 ZY .\nMore precisely, let c(Z \u2192 ZY ) = c. If Y is distributed along the support of X at the same ratio as along the larger support of Z, we would expect s(XY ) \u2248 c \u00d7 s(X): we are, thus, considering the relative error committed by c \u00d7 s(X) used as an approximation to s(XY ). In case the difference in the numerator is negative, it would mean that s(XY ) is even lower than what Z \u2192 ZY would suggest. If it is positive but the quotient is low, c(Z \u2192 ZY )\u00d7 s(X) still suggests a good approximation to c(X \u2192 XY ), and the larger rule does not bring high enough confidence with respect to the simpler one to be considered: it remains blocked. But, if the quotient is larger, and this happens for all Z, then X \u2192 XY becomes interesting since its confidence is higher enough than suggested by other rules of the form Z \u2192 ZY .\nThe higher the block threshold, the more demanding the constraint is. It can be checked that the particular problems of the Adult dataset indicated above are actually solved already by imposing just a generously tiny blocking threshold (around 0.000075). Again the specific choice of value for the blocking threshold is justified in [Balca\u0301zar 2009] just in merely intuitive terms; however, note for later use that the confidence width bound and the blocking threshold are related in that paper as follows: if the confidence width bound is b, then the blocking threshold proposed is b\u2212 1.\nExample 2.16. Due to the inequalities in Example 2.12, we can see that, at any nonnegative blocking threshold, \u2205 blocks B \u2192 C:\ns(XY )\u2212 c(Z \u2192 ZY )s(X) c(Z \u2192 ZY )s(X) = s(BC)\u2212 c(\u2205 \u2192 C)s(B) c(\u2205 \u2192 C)s(B) \u2248 9\u2212 9.16 9.16 < 0.\nLikewise, considering A\u2192 BC, we have s(ABC)\u2212 c(\u2205 \u2192 BC)s(A)\nc(\u2205 \u2192 BC)s(A) = 8\u2212 (9/12) \u2217 10 (9/12) \u2217 10 \u2248 0.066\nso that this rule would be blocked by \u2205 as soon as a blocking threshold higher than this quantity is imposed."}, {"heading": "2.3. Support Ratio", "text": "We will relate our values of confidence width and of confidence boost to an expression essentially employed first, to our knowledge, in [Kryszkiewicz 2001], where no particular name was assigned to it. Together with other similar quotients, it was introduced with the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\naim of providing a faster algorithm for computing representative rules; it turns out that, as demonstrated in [Balca\u0301zar and T\u0302\u0131rna\u0306uca\u0306 2011], this approach is efficient and useful in practice but runs into the risk of providing incomplete output, as actual representative rules may be missed. The same reference provides further analysis, including almost equally efficient alternatives whose output is complete.\nHere we introduce this notion because it is related to all of our three parameters of confidence width, blocking, and confidence boost; it will allow us to explain more carefully their mutual relationships, and it allows for confidence boost constraints to be \u201cpushed\u201d into a closure mining process, as we will do in Section 6.\nDefinition 2.17. In the presence of a support threshold \u03c4 , the support ratio of an association rule X \u2192 XY is\n\u03c3(X \u2192 XY ) = s(XY ) max{s(Z) \u2223\u2223 XY \u2282 Z, s(Z) > \u03c4} We see that this measure does not depend on the antecedent X but just on XY . Again, we set its value to \u221e if no Z exists as required for the maximization in the denominator. We have the following relationship:\nProposition 2.18. If the value of \u03c3(X \u2192 XY ) is finite and well-defined then the confidence width w(X \u2192 XY ) is also finite, and then\nw(X \u2192 XY ) \u2264 \u03c3(X \u2192 XY ).\nProof. This is easy to see from Proposition 2.9, and by observing that X \u2192 Z, for the Z 6= XY that maximizes the support in the denominator of support ratio, leads to w(X \u2192 XY ) \u2264 c(X \u2192 XY )/c(X \u2192 Z) = s(XY )/s(Z) = \u03c3(X \u2192 XY ) by simplifying the value of s(X) 6= 0.\nIt is clear that \u03c3(X \u2192 XY ) \u2265 1 for all rules; \u03c3(X \u2192 XY ) = 1 exactly when XY is not closed, since these sets are those that have some proper superset Z with the same support. The following easy consequence is worth mentioning: many of the quantities we study for an association rule X \u2192 XY are bounded from above by the support ratio and, therefore, will trivialize to values less than or equal to 1 unless we consider only closed sets XY as right hand sides. Together with Proposition 2.5, this is the reason of the importance of the closure notion in our context, and of the introduction of a closure-aware version of confidence boost in Section 4.\nExample 2.19. Looking again at association rule A \u2192 BC in Example 2.2, we see that \u03c3(A\u2192 BC) = s(ABC)/s(ABCDE) = 4/3."}, {"heading": "3. CONFIDENCE BOOST", "text": "This section introduces the first, simpler version of our main notion; it is very similar to the one given for confidence width, but with a twist that, even though formally tiny, semantically changes it far enough so as to encompass the notion of blocking.\nDefinition 3.1. The confidence boost of an association rule X \u2192 XY (always with X \u2229 Y = \u2205) is \u03b2(X \u2192 XY ) =\n= c(X \u2192 XY ) max{c(X \u2032 \u2192 X \u2032Y \u2032) \u2223\u2223 (X \u2192 XY ) 6= (X \u2032 \u2192 X \u2032Y \u2032), X \u2032 \u2286 X, Y \u2286 Y \u2032}\nAs in previous cases, the rules in the denominator are implicitly required to clear the support threshold: s(X \u2032 \u2192 X \u2032Y \u2032) > \u03c4 . Again, in case the set in the denominator is empty, the confidence boost is infinite by convention. As in Proposition 2.9, we can point out exactly which rules fall in that case: the same ones, in fact.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nProposition 3.2. The value of \u03b2(X \u2192 XY ) is finite and well-defined if and only if either X 6= \u2205, or Y has some proper superset Z with s(Z) > \u03c4 . That is: the set of rules of infinite confidence boost coincides with the set of rules of infinite width.\nProof. Like in Proposition 2.9, if X = \u2205 and no proper superset of Y reaches support above \u03c4 in the dataset, then no different rule (of sufficient support) is available for the set in the denominator. Conversely, \u2205 \u2192 Z belongs to that set if either X 6= \u2205, or Y \u2282 Z.\nAs indicated above, these cases of infinite confidence boost hardly ever appear in practice, due to their confidence being below the threshold.\nExample 3.3. Considering again association rule A \u2192 BC in Example 2.2, we find a value of the confidence boost of 16/15 for this rule. This is obtained as follows: we consider all rules X \u2032 \u2192 X \u2032Y \u2032 with X \u2032 \u2286 A and BC \u2286 Y \u2032 (and different from it); one can see that the maximum confidence among them is 0.75, attained by \u2205 \u2192 BC. Then \u03b2(A \u2192 BC) = 0.8/0.75 = 16/15 \u2248 1.066.\nThe fact that a low confidence boost corresponds to a low novelty is similar to the analogous explanation for width, and can be argued intuitively as follows. Suppose that \u03b2(X \u2192 XY ) is low, say \u03b2(X \u2192 XY ) \u2264 b, where b is just slightly larger than 1. Then, according to the definition, there must exist some different rule X \u2032 \u2192 X \u2032Y \u2032, with X \u2032 \u2286 X and Y \u2286 X \u2032Y \u2032, such that c(X\u2192XY )c(X\u2032\u2192X\u2032Y \u2032) \u2264 b, or c(X\n\u2032 \u2192 X \u2032Y \u2032) \u2265 c(X \u2192 XY )/b. This inequality says that the rule X \u2032 \u2192 X \u2032Y \u2032, stating that transactions with X \u2032 tend to have X \u2032Y \u2032, has a confidence relatively high, not much lower than that of X \u2192 XY ; equivalently, the confidence of X \u2192 XY is not much higher (it could be lower) than that of X \u2032 \u2192 X \u2032Y \u2032. But all transactions having X do have X \u2032, and all transactions having Y \u2032 have Y , so that the confidence found for X \u2192 XY is not really that novel, given that it does not give so much additional confidence over a rule that states such a similarly confident, and intuitively stronger, fact, namely X \u2032 \u2192 X \u2032Y \u2032.\nAt a bare minimum, we should not consider association rules with confidence boost 1 or less. Notice that this solves the objection against confidence that negative correlations go undetected: for instance, if the support of B is, say, 80%, a rule A \u2192 B of confidence less than that would yield a confidence boost below 1, due to the rule \u2205 \u2192 B."}, {"heading": "3.1. Boost, Lift, Support Ratio, Width, and Blocking", "text": "We present now some analyses clarifying the properties of the confidence boost. First, we see that it allows one to filter out rules that would be discarded on the basis of lift, since rules of low lift have low confidence boost.\nProposition 3.4. Let X 6= \u2205; then, the confidence boost \u03b2(X \u2192 XY ) is bounded from above by the lift of X \u2192 Y . Proof. We simply consider the rule \u2205 \u2192 Y , which differs from X \u2192 Y since X 6= \u2205. Its support is above that of X \u2192 Y and thus above the support threshold. Clearly, it appears among the rules considered to maximize the confidence in the denominator of the definition of \u03b2(X \u2192 XY ), hence \u03b2(X \u2192 XY ) \u2264 c(X\u2192XY )c(\u2205\u2192Y ) ; but c(\u2205 \u2192 Y ) = s(Y )/n and then c(X\u2192XY ) c(\u2205\u2192Y ) is exactly the lift of X \u2192 Y . In the case where X = \u2205, the lift is 1, as already indicated; this value turns out to be uninformative in this case, since any right-hand side is independent from \u2205. Confidence boost does apply to this case, being able to detect low novelty through larger consequents.\nThe only formal difference between confidence boost and confidence width of a rule X \u2192 XY is that, upon exploring alternative rules X \u2032 \u2192 X \u2032Y \u2032, in the confidence boost the antecedent X is not required anymore to be a subset of the consequent X \u2032Y \u2032, whereas it must be for X \u2032 \u2192 Y \u2032 to qualify in the computation of the width. More precisely, given that\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX \u2229 Y = \u2205 and X \u2032 \u2286 X, it follows X \u2032 \u2229 Y = \u2205, so that the condition Y \u2286 Y \u2032 is equivalent to the condition Y \u2286 X \u2032Y \u2032. Proposition 2.10 tells us that XY \u2286 X \u2032Y \u2032 \u21d0\u21d2 (X \u2212X \u2032) \u2286 Y \u2032 and Y \u2286 Y \u2032, and we see that confidence boost simply keeps the inclusion among the right-hand sides Y \u2286 Y \u2032 and does not require additionally that (X \u2212 X \u2032) \u2286 Y \u2032 anymore. This also tells us that all rules X \u2032 \u2192 X \u2032Y \u2032 that are considered for the maximization in the denominator in the definition of confidence width are also considered for the corresponding maximization in confidence boost. Thus, the value of the maximum itself is at least the same, or possibly larger, and the difference is that the boost case may consider further candidates to X \u2032 \u2192 X \u2032Y \u2032. That is:\nProposition 3.5. The confidence boost of a rule is bounded above by its confidence width: \u03b2(X \u2192 XY ) \u2264 w(X \u2192 XY ). Hence, \u03b2(X \u2192 XY ) \u2264 \u03c3(X \u2192 XY ).\nThe last sentence comes from Proposition 2.18, and was proved directly first in [Balca\u0301zar et al. 2010b]. For the next theorem, we state separately a simple technical equivalence.\nLemma 3.6. Z \u2282 X blocks X \u2192 XY at block threshold b\u22121 if and only if c(X\u2192XY )c(Z\u2192ZY ) \u2264 b.\nProof. By definition, Z \u2282 X blocks X \u2192 XY at blocking threshold b\u2212 1 if and only if s(XY )\u2212 c(Z \u2192 ZY )s(X)\nc(Z \u2192 ZY )s(X) \u2264 b\u2212 1.\nMultiplying both sides of the inequality by c(Z \u2192 ZY ), separating the two terms of the lefthand side, and replacing s(XY )/s(X) by its meaning, c(X \u2192 XY ), we find the equivalent expression\nc(X \u2192 XY )\u2212 c(Z \u2192 ZY ) \u2264 (b\u2212 1)(c(Z \u2192 ZY ) where solving for b leads to\nc(X \u2192 XY ) c(Z \u2192 ZY ) \u2264 b.\nAll the algebraic manipulations are reversible (in particular, confidences and supports appearing all along are never zero so we can multiply or divide by them without trouble.)\nWe show next that confidence boost embodies exactly both blocking and confidence width, precisely with the same relation between the thresholds as used in [Balca\u0301zar 2009], under the already stated proviso that all the association rules involved must clear the support threshold.\nTheorem 3.7. For an association rule X \u2192 XY , \u03b2(X \u2192 XY ) \u2264 b if and only if either w(X \u2192 XY ) \u2264 b or X \u2192 XY is blocked at a blocking threshold b\u2212 1. Proof. First we prove that either of low width or blocking imply low boost. We have already argued in Proposition 3.5 that \u03b2(X \u2192 XY ) \u2264 w(X \u2192 XY ). Likewise, assume that Z \u2282 X (proper subset) blocks X \u2192 XY at a blocking threshold b \u2212 1. Clearly the rule Z \u2192 ZY differs from X \u2192 XY since Z is a proper subset of X and fulfills the conditions to enter the maximum confidence denominator in the definition of confidence boost. This means that this maximum is at least as large as c(Z \u2192 ZY ), and therefore, by Lemma 3.6,\n\u03b2(X \u2192 XY ) \u2264 c(X \u2192 XY ) c(Z \u2192 ZY ) \u2264 b.\nConversely, we assume now that \u03b2(X \u2192 XY ) \u2264 b and prove that either w(X \u2192 XY ) \u2264 b or X \u2192 XY is blocked at a blocking threshold b\u22121. The definition of confidence boost tells us that there is a different rule X \u2032 \u2192 X \u2032Y \u2032 (X \u2032 \u2229 Y \u2032 = \u2205) for which s(X \u2032Y \u2032) > \u03c4 , X \u2032 \u2286 X, Y \u2286 Y \u2032, and c(X\u2192XY )c(X\u2032\u2192X\u2032Y \u2032) \u2264 b. We consider two cases, according to whether X = X \u2032. If\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX = X \u2032, necessarily Y \u2282 Y \u2032 properly, thus XY \u2282 X \u2032Y \u2032 properly, and s(X) = s(X \u2032) plus s(X \u2032Y \u2032) > \u03c4 tells us that\nw(X \u2192 XY ) \u2264 \u03c3(X \u2192 XY ) \u2264 s(XY ) s(X \u2032Y \u2032) = c(X \u2192 XY ) c(X \u2032 \u2192 X \u2032Y \u2032) \u2264 b.\nOtherwise, X \u2032 \u2282 X properly, and Y \u2286 Y \u2032 (and a fortiori X \u2032 \u2229 Y = \u2205) gives us c(X \u2032 \u2192 X \u2032Y ) \u2265 c(X \u2032 \u2192 X \u2032Y \u2032) whence c(X\u2192XY )c(X\u2032\u2192X\u2032Y ) \u2264 c(X\u2192XY ) c(X\u2032\u2192X\u2032Y \u2032) \u2264 b. Applying again Lemma 3.6, we obtain that X \u2032 blocks X \u2192 Y at blocking threshold b\u2212 1. Hence, bounding the confidence boost at b ensures us that the rules that would be filtered by that confidence boost bound are exactly the same as those that would be filtered by either (or both) of the checks w(X \u2192 XY ) \u2264 b or blocking at threshold b\u2212 1. In this sense, confidence boost embodies both low-novelty tests from [Balca\u0301zar 2009], and with the same thresholds employed there.\nWe briefly consider the case of rules with a single item in the antecedent.\nProposition 3.8. Assume that |X| = 1 in rule X \u2192 XY , that is, the left hand side is a single item. Then \u03b2(X \u2192 XY ) coincides with the minimum among the lift of X \u2192 Y and \u03c3(X \u2192 XY ). Proof. Let X \u2032 \u2192 X \u2032Y \u2032 be the rule that leads to \u03b2(X \u2192 XY ) = c(X \u2192 XY )/c(X \u2032 \u2192 X \u2032Y \u2032). It must be different from X \u2192 XY , and must clear the support threshold.\nIf X \u2032 \u2282 X, as X is a singleton, we have X \u2032 = \u2205, s(X \u2032) = n (the number of transactions in the dataset), Y \u2286 Y \u2032, s(Y \u2032) \u2264 s(Y ), and\n\u03b2(X \u2192 XY ) = c(X \u2192 XY ) c(X \u2032 \u2192 X \u2032Y \u2032) = c(X \u2192 Y ) s(Y \u2032)/n \u2265 c(X \u2192 Y ) s(Y )/n = s(XY )\u00d7 n s(X)\u00d7 s(Y )\nwhich is the value of the lift; but the boost is also less than or equal to the lift by Proposition 3.4, and they must coincide. The support ratio must be higher by Proposition 3.5, so the confidence boost equals the stated minimum.\nThe other case is where X \u2032 = X; then, as the two association rules are different, necessarily XY 6= X \u2032Y \u2032 = XY \u2032, so that \u03c3(X \u2192 XY ) \u2264 s(XY )/s(XY \u2032) = c(X \u2192 XY )/c(X \u2192 XY \u2032) because we can divide by s(X) 6= 0; that is, \u03c3(X \u2192 XY ) \u2264 \u03b2(X \u2192 XY ). The converse inequality is furnished by Proposition 3.5 and, once we have the equality \u03c3(X \u2192 XY ) = \u03b2(X \u2192 XY ), the fact that this value is the indicated minimum comes from Proposition 3.4.\nCorollary 3.9. Assume a threshold b in place such that \u03c3(X \u2192 XY ) \u2265 b is known, for |X| = 1, that is, for a rule with a single antecedent item. If the lift of X \u2192 Y is less than b, then it equals \u03b2(X \u2192 XY ).\nExample 3.10. We revisit again association rule A\u2192 BC in Example 2.2. For this rule, the lift is 16/15, less than the support ratio 4/3, so that the former coincides with the confidence boost as per Proposition 3.8. The quantities evaluated in previous examples lead now to the inequalities\n\u03b2(A\u2192 BC) = 16/15 < w(A\u2192 BC) = 6/5 < \u03c3(A\u2192 BC) = 4/3 which obey, of course, all inequalities we have proved so far and, at the same time, witness that each inequality may well be proper."}, {"heading": "3.2. Double-Threshold Confidence", "text": "In order to be of practical use, we need a deeper study of the confidence boost. As it currently stands, it makes no sense to traverse all the alternative rules to be taken into account for computing the maximum confidence in the denominator. The same sort of\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\ndifficulty appears for confidence width and for blocking. A mild precomputation allows one to compute quite efficiently the width [Balca\u0301zar 2009], but the same method does not seem to work for blocking or boost. In fact, the experiments reported in that reference resort, as indicated there, to an approximation to blocking.\nBy the reasons already discussed, we will not be interested in confidence boost bounds of 1 or less; above 1, by Proposition 3.5, we only find representative rules. Given confidence threshold \u03b3, we will show that, in order to test the confidence boost threshold, it suffices to do so against the set of representative rules computed at a lower confidence threshold, namely \u03b3/b. Indeed, consider Algorithm 1. The comparisons are written there in such a way so as to avoid division by zero in the cases of infinite boost, such as s(XAY ) = 0, which may potentially be the case.\nAlgorithm 1: A double confidence threshold algorithm\nData: dataset D; thresholds for support \u03c4 , for confidence \u03b3, and for confidence boost b > 1; rule X \u2192 XY with X \u2229 Y = \u2205, c(X \u2192 XY ) \u2265 \u03b3, and s(XY ) \u2265 \u03c4 Result: boolean value indicating whether \u03b2(X \u2192 XY ) > b mine D for the representative rules R at threshold \u03b3/b for each rule X \u2032 \u2192 X \u2032Y \u2032 \u2208 R such that X \u2032 \u2229 Y \u2032 = \u2205, X \u2032 \u2286 X and Y \u2286 Y \u2032 do\nif \u2203Z \u2282 X \u2212X \u2032 such that c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032Z \u2192 X \u2032ZY ) then return False if \u2203A \u2208 Y \u2032 \u2212XY such that c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2192 XAY ) then return False\nreturn True\nTheorem 3.11. Let X \u2192 XY be a rule of confidence at least \u03b3. Then, Algorithm 1 accepts it if and only if \u03b2(X \u2192 XY ) > b.\nProof. First we see that the rejections are correct. In each case, we just found a rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 with X \u2032\u2032 \u2286 X and Y \u2286 Y \u2032\u2032, be it X \u2032Z \u2192 X \u2032ZY or X \u2192 XAY ; also X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 6= X \u2192 XY : in the first case, Z is a proper subset of X \u2212X \u2032, so X \u2032Z 6= X, and in the second case the item A did not appear in X \u2192 XY . In each case, the rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 enters the maximization in the denominator of the confidence boost and shows that its value is less than or equal to b.\nTo see that acceptance is correct, assume \u03b2(X \u2192 XY ) \u2264 b: we prove that, at some point, rule X \u2192 XY must fail one of the two tests in the algorithm. By the definition of confidence boost, there must exist some rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032, different from X \u2192 XY , with X \u2032\u2032 \u2286 X and Y \u2286 Y \u2032\u2032, such that c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032).\nThen, from c(X \u2192 XY ) \u2265 \u03b3 we infer c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2265 \u03b3/b, so that there must exist a representative rule at confidence \u03b3/b, let it be X \u2032 \u2192 X \u2032Y \u2032 \u2208 R, that makes X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 redundant (possibly itself): by Lemma 2.4, X \u2032 \u2286 X \u2032\u2032 and X \u2032\u2032Y \u2032\u2032 \u2286 X \u2032Y \u2032. At some point (unless a correct negative answer is found earlier), the algorithm will consider this rule X \u2032 \u2192 X \u2032Y \u2032 \u2208 R. As in the proof of Theorem 3.7, we distinguish two cases.\nFirst assume that X \u2032\u2032 is a proper subset of X, X \u2032\u2032 \u2282 X. Since X \u2032 \u2286 X \u2032\u2032, we can consider Z = X \u2032\u2032 \u2212 X \u2032 \u2282 X \u2212 X \u2032: at some point, the algorithm will compare c(X \u2192 XY ) to b \u00d7 c(X \u2032Z \u2192 X \u2032ZY ). But it holds that X \u2032Z = X \u2032\u2032 and that Y \u2286 Y \u2032\u2032, resulting in c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2264 b\u00d7 c(X \u2032Z \u2192 X \u2032ZY ) and failing the test.\nAlternatively, assume X \u2032\u2032 \u2286 X holds with equality: X \u2032\u2032 = X. From X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 6= X \u2192 XY (and using X \u2229 Y = \u2205 and X \u2032\u2032 \u2229 Y \u2032\u2032 = \u2205) we know that Y \u2282 Y \u2032\u2032 is a proper inclusion: there is some A \u2208 Y \u2032\u2032 \u2286 X \u2032Y \u2032 that is not in Y . Such A is not in X either, because X \u2032\u2032 \u2229 Y \u2032\u2032 = X \u2229 Y \u2032\u2032 = \u2205, and then, in fact, A /\u2208 X \u2032, so that A \u2208 Y \u2032 \u2212XY . In due time, the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nalgorithm will compare c(X \u2192 XY ) to b \u00d7 c(X \u2192 XAY ). But X = X \u2032\u2032, and A \u2208 Y \u2032\u2032 so that AY \u2286 Y \u2032\u2032, hence c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2264 b\u00d7 c(X \u2192 XAY ) and the test will fail as well. This completes the proof."}, {"heading": "4. CLOSURE-BASED CONFIDENCE BOOST", "text": "Representative rules are a minimum size basis for redundancy, defined as per Lemma 2.4; still, they constitute often a large set. Prior to accepting the option of losing information in a quantifiable manner, as we are doing via confidence boost, one could consider the option of using stronger notions of redundancy. Several earlier papers, e. g. [Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules. In [Balca\u0301zar 2010c], besides another more complicated alternative, we follow up this suggestion as well, and employ a notion of closure-based redundancy which also turns out to provide a complete basis of provably minimum size, denoted B?. This option has definite advantages: whereas it provides bases comparable in size with, and often clearly smaller than, the set of representative rules, it has the desirable property that the portion of it that refers to partial associations (of confidence below 1) can be computed faster. The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balca\u0301zar and T\u0302\u0131rna\u0306uca\u0306 2011]); instead, the B? basis can be computed just from the closures. In this section, we port confidence boost into closure-based redundancy and the corresponding minimum-size basis B?.\nClosure-based redundancy corresponds to restricting consideration of datasets as a function of the closure operator they induce. It is well-known that the closure operator is equivalently specified by a set of implications, that is, association rules of confidence 1 (see e. g. [Zaki 2004]). Closure-based redundancy [Balca\u0301zar 2010c] takes into account the closure operator indirectly as follows:\nDefinition 4.1. Let B be a set of implications. Partial rule X0 \u2192 X0Y0 has closure-based redundancy relative to B with respect to rule X1 \u2192 X1Y1 if the inequalities\nc(X0 \u2192 X0Y0) \u2265 c(X1 \u2192 X1Y1) and s(X0 \u2192 X0Y0) \u2265 s(X1 \u2192 X1Y1)\nhold in any dataset D in which all the rules in B hold with confidence 1.\nThis redundancy has a characterization parallel to that of Lemma 2.4, proved in the same reference:\nLemma 4.2. Let B be a set of implications. Consider two association rules, X0 \u2192 X0Y0 and X1 \u2192 X1Y1. The following are equivalent:\n(1 ) Rule X0 \u2192 X0Y0 has closure-based redundancy relative to B with respect to rule X1 \u2192 X1Y1. (2 ) X1 \u2286 X0 and X0Y0 \u2286 X1Y1.\nThe closure operator in the second statement is the one corresponding to the set of implications B.\nIn all applications, B is the set of full-confidence implications holding in the dataset, so that the closure operator is actually the one induced by the dataset. For closure-based redundancy, a minimum-size basis can be constructed as well. Essentially, this basis, denoted B?\u03b3 for confidence threshold \u03b3, is defined in a manner analogous to that of the representative rules, except that it is restricted to rules of the form X \u2192 XY where both X and XY are closed sets, instead of X being a minimal generator as in representative rules. All these definitions are studied in depth in [Balca\u0301zar 2010c].\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nIf we are to employ this notion of redundancy and the B? basis, then the definition of confidence boost requires some fine tuning. This basis is often smallish because many different representative rules could correspond to many left-hand sides that are minimal generators of the same closure. Such sets of rules become a single rule in B?. But, if we use the given definition of confidence boost, these rules are syntactically different from the one in B? and \u201ckill it\u201d by forcing its boost down to 1. Thus, to avoid trivializing B?, we need to take into account the closure operator in the definition of boost. The main notion of this section is as follows:\nDefinition 4.3. The closure-based confidence boost of a rule X \u2192 XY is \u03b2(X \u2192 XY ) =\n= c(X \u2192 XY ) max{c(X \u2032 \u2192 X \u2032Y \u2032) \u2223\u2223 (X 6= X \u2032 \u2228XY 6= X \u2032Y \u2032), X \u2032 \u2286 X, Y \u2286 X \u2032Y \u2032}\nThis is the natural definition paralleling the confidence boost when the notion of reduncancy is closure-based: on one hand, the rules in the denominator may resort to the use of closures to make the rule at hand redundant, widening the options of redundancy; on the other hand, rules that are syntactically different from the rule at hand, but equivalent to it in closure-based redundancy, must be discarded, as they trivially entail the rule at hand. Failing to discard them unduly trivializes the confidence boost in many cases. Observe that the notion of confidence boost in the previous section corresponds to the particular case where the closure operator is the identity function.\nExample 4.4. Out of the seven representative rules at confidence threshold 0.8 that we enumerated in Example 2.6, some are unchanged in B?0.8, such as C \u2192 AB, B \u2192 C, \u2205 \u2192 C, and \u2205 \u2192 AB. Instead of A \u2192 BC, we find AB \u2192 C, which is equivalent to it due to the implication A \u2192 B; and, due to the implications D \u2192 CE and E \u2192 CD, it suffices to keep CDE \u2192 AB instead of the other two. If we were to employ plain confidence boost, \u03b2(CDE \u2192 AB) \u2264 1, due to rules D \u2192 ABCE and E \u2192 ABCD. Closure-based confidence boost is able to perform a finer distinction. As these two rules have the same closure of the antecedent as D = E = CDE, and the same associated closed set ABCDE, they do not enter the computation of closure-based confidence boost of CDE \u2192 AB, which is actually \u03b2(CDE \u2192 AB) = c(CDE \u2192 AB)/c(C \u2192 ABDE) = 10/7 > 1."}, {"heading": "4.1. Double-Threshold Confidence Revisited", "text": "We develop next an algorithm to compute closure-based confidence boost. We just need to make a number of adjustments to the one given for plain confidence boost: first, one must explore the rules of the B? basis for confidence \u03b3/b, instead of the representative rules for it, since that is the appropriate basis for closure-based redundancy; and, second, one must take into account the closure operator at the time of checking whether a specific B? rule may lead to guaranteeing low boost of the input rule.\nTheorem 4.5. Let X \u2192 XY be a rule of confidence at least \u03b3. Algorithm 2 accepts it if and only if \u03b2(X \u2192 XY ) > b.\nProof. We follow essentially the same steps as in Theorem 3.11, although we must argue more carefully about the places where the closure operator plays a role. Again, we see first that the rejections are correct. In each case, we just found a rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 with X \u2032\u2032 \u2286 X and Y \u2286 Y \u2032\u2032, be it X \u2032Z \u2192 X \u2032ZY or X \u2192 XAY . In both cases, (X 6= X \u2032\u2032 \u2228XY 6= X \u2032\u2032Y \u2032\u2032) holds: in the first case, X \u2032Z 6= X is explicitly checked, whereas, for the second case, A \u2208 XAY \u2286 XAY but A /\u2208 XY . In each case, the rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 contributes to the maximization in the denominator of the confidence boost and shows that its value is less than or equal to b.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nAlgorithm 2: A variant of Algorithm 1 for closure-based confidence boost\nData: dataset D; thresholds for support \u03c4 , for confidence \u03b3, and for closure-based confidence boost b > 1; rule X \u2192 XY with X \u2229 Y = \u2205, c(X \u2192 XY ) \u2265 \u03b3, and s(XY ) \u2265 \u03c4 Result: boolean value indicating whether \u03b2(X \u2192 XY ) > b mine D for the basis B? at threshold \u03b3/b for each rule X \u2032 \u2192 X \u2032Y \u2032 \u2208 B?\u03b3/b where X\n\u2032 \u2229 Y \u2032 = \u2205, with X \u2032 \u2286 X and Y \u2286 X \u2032Y \u2032 do if \u2203Z \u2282 X \u2212X \u2032 such that X \u2032Z \u2282 X (with inequality) and c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032Z \u2192 X \u2032ZY ) then\nreturn False\nif \u2203A \u2208 X \u2032Y \u2032 \u2212XY such that c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2192 XAY ) then return False\nreturn True\nTo see that acceptance is correct, assume \u03b2(X \u2192 XY ) \u2264 b: we prove that, at some point, rule X \u2192 XY must fail one of the two tests in the algorithm. By the definition of closurebased confidence boost, there must exist some rule X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 with X \u2032\u2032 \u2286 X, Y \u2286 X \u2032\u2032Y \u2032\u2032, and (X 6= X \u2032\u2032 \u2228XY 6= X \u2032\u2032Y \u2032\u2032), and such that c(X \u2192 XY ) \u2264 b \u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032). Then, from c(X \u2192 XY ) \u2265 \u03b3 we infer c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2265 \u03b3/b, so that there must exist a rule in the basis B?\u03b3/b, let it be X\n\u2032 \u2192 X \u2032Y \u2032, that makes X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032 redundant (possibly itself) under closure-based redundancy. By Lemma 4.2, X \u2032 \u2286 X \u2032\u2032 and X \u2032\u2032Y \u2032\u2032 \u2286 X \u2032Y \u2032 = X \u2032Y \u2032, where the last equality is due to the fact that X \u2032 \u2192 X \u2032Y \u2032 \u2208 B?\u03b3/b so that X \u2032Y \u2032 is closed. At some point (unless a correct negative answer is found earlier), the algorithm will consider this rule X \u2032 \u2192 X \u2032Y \u2032 \u2208 B?\u03b3/b. As in the proof of Theorem 3.7, we distinguish two cases.\nFirst assume that X \u2032\u2032 \u2282 X. Since X \u2032 \u2286 X \u2032\u2032, we can consider Z = X \u2032\u2032 \u2212X \u2032 \u2282 X \u2212X \u2032: at some point, the algorithm will compare c(X \u2192 XY ) to b\u00d7 c(X \u2032Z \u2192 X \u2032ZY ). But it holds that X \u2032Z = X \u2032\u2032 and that Y \u2286 X \u2032\u2032Y \u2032\u2032, resulting in c(X \u2192 XY ) \u2264 b \u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) = b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2264 b\u00d7 c(X \u2032Z \u2192 X \u2032ZY ) and failing the test.\nAlternatively, let\u2019s consider the case where X \u2032\u2032 \u2286 X holds with equality: X \u2032\u2032 = X, so that XY 6= X \u2032\u2032Y \u2032\u2032; on the other hand, we know now X \u2286 X = X \u2032\u2032 \u2286 X \u2032\u2032Y \u2032\u2032, and also Y \u2286 X \u2032\u2032Y \u2032\u2032, so that XY \u2286 X \u2032\u2032Y \u2032\u2032.\nAssume briefly that Y \u2032\u2032 \u2286 XY : as X \u2032\u2032 \u2286 X \u2032\u2032 = X \u2286 XY , we would obtain X \u2032\u2032Y \u2032\u2032 \u2286 XY and, therefore, the equality XY = X \u2032\u2032Y \u2032\u2032; however, we know that this equality does not hold.\nHence, Y \u2032\u2032 is not included in XY , and there is some A \u2208 Y \u2032\u2032 \u2286 X \u2032Y \u2032 that is not in XY , that is, A \u2208 X \u2032Y \u2032 \u2212 XY . (If we know that X = X, for instance when the rule X \u2192 XY comes from a B? basis, X \u2032 \u2286 X \u2032\u2032 = X = X tells us that the search for A can be circumscribed further to just A \u2208 Y \u2032 \u2212 XY .) In due time, the algorithm will compare c(X \u2192 XY ) to b\u00d7 c(X \u2192 XAY ). But X = X \u2032\u2032, and A \u2208 Y \u2032\u2032 so that XAY \u2286 X \u2032\u2032Y \u2032\u2032, hence c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) = b\u00d7 c(X \u2032\u2032 \u2192 X \u2032\u2032Y \u2032\u2032) \u2264 b\u00d7 c(X \u2192 XAY ) and the test will fail as well. This completes the proof.\nWe report on a second algorithm below."}, {"heading": "4.2. Inequalities", "text": "Compared to confidence boost, closure-based confidence boost relaxes the alternative rules to which a given rule is compared, e.g. by allowing left hand sides included in X that are not included in X; but, on the other hand, restricts them by the proviso that the rules are \u201cinequivalent\u201d in a closure-based sense, and not just different. Therefore, either can end\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nup being higher than the other, and the relationship with other quantities like width or support ratio become less clear. We must review which inequalities still hold; we start with the (partial) analogs of Propositions 3.5 and 3.4.\nProposition 4.6. Assume XY closed. Then, the closure-based confidence boost is bounded by the support ratio: \u03b2(X \u2192 XY ) \u2264 \u03c3(X \u2192 XY ).\nProof. Let Z be the proper superset ofXY of largest support above \u03c4 , so that \u03c3(X \u2192 XY ) = s(XY )/s(Z). As XY is closed, Z 6= XY . Rule X \u2192 Z enters, therefore, the maximization in the denominator of the closure-based confidence boost and leads to \u03b2(X \u2192 XY ) \u2264 c(X \u2192 XY )/c(X \u2192 Z) = s(XY )/s(Z) = \u03c3(X \u2192 XY ).\nProposition 4.7. Assume s(X) < n, the dataset size; then, the closure-based confidence boost \u03b2(X \u2192 XY ) is bounded above by the lift of X \u2192 Y .\nProof. We consider the rule \u2205 \u2192 Y . For it to play a role in closure-based confidence boost, we need \u2205 6= X, which is equivalent to s(X) < n. The rest of the argumentation is as in Proposition 3.4: its support is above the threshold, and \u03b2(X \u2192 XY ) \u2264 c(X\u2192XY )c(\u2205\u2192Y ) which is the lift of X \u2192 Y .\nIt is interesting to note that the condition about the left-hand side being nonempty in Proposition 3.4 corresponds now to having support less than the dataset size: the intuition is that any items that appear in all transactions become part of the closure of the empty set, which is now the limit case.\nWe discuss now some relationships between the plain and the closure-based versions of the confidence boost.\nProposition 4.8. Let X \u2192 XY be an association rule where XY is a closed set and X is a minimal generator. Then, \u03b2(X \u2192 XY ) \u2264 \u03b2(X \u2192 XY ).\nProof. Let \u03b2(X \u2192 XY ) = b: there must be a different rule X \u2032 \u2192 X \u2032Y \u2032 such that X \u2032 \u2286 X, Y \u2286 Y \u2032, and c(X\u2192XY )c(X\u2032\u2192X\u2032Y \u2032) = b. Assume first that X\n\u2032 \u2282 X. As X is a minimum generator, any subset of X has strictly larger support. Hence, s(X) = s(X) 6= s(X \u2032) = s(X \u2032), which implies that X 6= X \u2032; then, the same rule X \u2032 \u2192 X \u2032Y \u2032 is accounted for in \u03b2 as well, and leads to a value of at most b.\nThe remaining case is X = X \u2032, which requires that XY 6= X \u2032Y \u2032. Moreover, both X = X \u2032 \u2286 X \u2032Y \u2032 and Y \u2286 X \u2032Y \u2032 by the definition of confidence boost, and XY is closed, so that XY = XY \u2282 X \u2032Y \u2032 \u2286 X \u2032Y \u2032. Again in this case X \u2032 \u2192 X \u2032Y \u2032 is accounted for in \u03b2, and the stated inequality holds.\nCorollary 4.9. Let X \u2192 XY be a representative rule at any confidence threshold; then \u03b2(X \u2192 XY ) \u2264 \u03b2(X \u2192 XY ).\nOne interesting particular case is that of rules of confidence 1 formed when X is a minimum generator of the closed set XY itself; these rules form the min-max exact basis from Definition 2.3 [Pasquier et al. 2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]). Proposition 4.8 applies to these rules as well, of course. On the other hand, we have:\nProposition 4.10. Let X \u2192 XY be an association rule where both X and XY are closed sets. Then, \u03b2(X \u2192 XY ) \u2264 \u03b2(X \u2192 XY ).\nProof. Let \u03b2(X \u2192 XY ) = b: there must be a rule X \u2032 \u2192 X \u2032Y \u2032 such that c(X\u2192XY )c(X\u2032\u2192X\u2032Y \u2032) = b, fulfilling the conditions X \u2032 \u2286 X, Y \u2286 X \u2032Y \u2032, and either X 6= X \u2032 or XY 6= X \u2032Y \u2032. We observe\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nfirst that, as X is closed, X \u2032 \u2286 X = X. Together with X \u2229 Y = \u2205, we get for later use that X \u2032 \u2229 Y = \u2205 as well.\nWe modify the rule X \u2032 \u2192 X \u2032Y \u2032 by extending its right-hand side into a closed set, as X \u2032 \u2192 X \u2032Y \u2032, which has the same confidence, and then rewrite it into X \u2032 \u2192 X \u2032Y \u2032\u2032 by setting Y \u2032\u2032 = X \u2032Y \u2032 \u2212X \u2032. Note that Y \u2286 X \u2032Y \u2032, together with X \u2032 \u2229 Y = \u2205, leads to Y \u2286 Y \u2032\u2032.\nHence, with that rule written in this form, the properties become c(X\u2192XY )c(X\u2032\u2192X\u2032Y \u2032\u2032) = b, X \u2032 \u2286 X = X, Y \u2286 Y \u2032\u2032, and either X 6= X \u2032 or XY 6= X \u2032Y \u2032\u2032. It suffices to show that X \u2032 \u2192 X \u2032Y \u2032\u2032 and X \u2192 XY are different rules to ensure that X \u2032 \u2192 X \u2032Y \u2032\u2032 participates in the computation of \u03b2(X \u2192 XY ) and, hence, to obtain the desired inequality. But: if X 6= X \u2032, then necessarily X 6= X \u2032; and, in the other case, XY = XY 6= X \u2032Y \u2032\u2032 = X \u2032Y \u2032\u2032 as both XY and X \u2032Y \u2032\u2032 = X \u2032Y \u2032 are closed sets. This completes the proof.\nAs the B? basis consists of rules where both antecedent X and consequent XY are closed sets, we obtain:\nCorollary 4.11. Let X \u2192 XY be a rule in the B? basis (at confidence c(X \u2192 XY )); then, \u03b2(X \u2192 XY ) \u2264 \u03b2(X \u2192 XY ).\nFor the not unusual cases where a representative rule participates as well in the B? basis, Section 3 suggests measuring its confidence boost, whereas Section 4 would propose to measure its closure-based confidence boost. Now we see that there is no conflict:\nCorollary 4.12. If X \u2192 XY is both a representative rule and a member of the B? basis (both at confidence c(X \u2192 XY )), then \u03b2(X \u2192 XY ) = \u03b2(X \u2192 XY ).\nThis follows at once from Corollaries 4.9 and 4.11.\nExample 4.13. In general, either of \u03b2 and \u03b2 can be strictly larger, when permitted by the statements we have proved so far. In Example 4.4, we saw a B? rule for which \u03b2(CDE \u2192 AB) > \u03b2(CDE \u2192 AB). This also shows that Corollary 4.9 cannot be extended to the B? basis. Conversely, as A = AB in our running example, rule B \u2192 C is taken into account for the closure-based confidence boost of the representative rule A\u2192 BC, leading to \u03b2(A\u2192 BC) < 1, whereas \u03b2(A\u2192 BC) = 16/15 as we saw in Example 3.10.\nWe develop some further inequalities and yet another algorithm that we will employ in Section 6.\nTheorem 4.14. Assume that a threshold b has been fixed for the closure-based confidence boost. Consider rule X \u2192 XY where both X and XY are closed sets. Then \u03b2(X \u2192 XY ) \u2264 b if and only if either \u03c3(X \u2192 XY ) \u2264 b, or there is some closed proper subset X \u2032 \u2282 X, c(X \u2192 XY ) \u2264 b\u00d7 c(X \u2032 \u2192 X \u2032Y ).\nProof. Assume first \u03b2(X \u2192 XY ) \u2264 b. Let X \u2032 \u2192 X \u2032Y \u2032 be the rule in the denominator of the definition of \u03b2 that leads to its actual value. Due to Y \u2286 X \u2032Y \u2032, we have c(X \u2032 \u2192 X \u2032Y ) \u2265 c(X \u2032 \u2192 X \u2032Y \u2032). If X \u2032 6= X, as X is assumed closed, we can state X \u2032 \u2286 X = X so that, by monotonicity, X \u2032 \u2286 X \u2032 \u2282 X = X. Thus, c(X\u2192XY )c(X\u2032\u2192X\u2032Y ) \u2264 c(X\u2192XY ) c(X\u2032\u2192X\u2032Y \u2032) = \u03b2(X \u2192 XY ) \u2264 b, and the second case holds. If, on the other hand, X \u2032 = X, then s(X) = s(X) = s(X \u2032) = s(X \u2032) and, necessarily, XY 6= X \u2032Y \u2032; yet XY = XY \u2286 X \u2032Y \u2032 \u2286 X \u2032Y \u2032 as XY is closed, hence XY = XY \u2282 X \u2032Y \u2032, leading to \u03c3(X \u2192 XY ) \u2264 s(XY )s(X\u2032Y \u2032) = c(X\u2192XY ) c(X\u2032\u2192X\u2032Y \u2032) = \u03b2(X \u2192 XY ) \u2264 b.\nConversely, if \u03c3(X \u2192 XY ) \u2264 b then \u03b2(X \u2192 XY ) \u2264 b by Proposition 4.6. Also, assuming X \u2032 \u2282 X gives us c(X \u2192 XY ) \u2264 b \u00d7 c(X \u2032 \u2192 X \u2032Y ), where both X and X \u2032 are closed, X \u2032 = X \u2032 \u2282 X = X so that X \u2032 6= X, and rule X \u2032 \u2192 X \u2032Y participates in the computation of \u03b2(X \u2192 XY ), leading to \u03b2(X \u2192 XY ) \u2264 c(X\u2192XY )c(X\u2032\u2192X\u2032Y ) \u2264 b.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nFor convenience in a later application, we restate this theorem in its contrapositive form:\nCorollary 4.15. Assume that a threshold b has been fixed for the closure-based confidence boost. Consider rule X \u2192 XY where both X and XY are closed sets. Then \u03b2(X \u2192 XY ) > b if and only if both \u03c3(X \u2192 XY ) > b and for every closed proper subset X \u2032 \u2282 X, c(X \u2192 XY ) > b\u00d7 c(X \u2032 \u2192 X \u2032Y ).\nYet another application of this theorem is to identify the analog of Proposition 3.8 for the closure-based case. To get there, it is convenient to factor off the proof the following technical but easy fact:\nLemma 4.16. Let X be a closed singleton, that is, X = X and |X| = 1. If s(X) < n, then there is exactly one closed proper subset of X, namely \u2205 = \u2205; and, besides, X is free, that is, it is a minimum generator of itself.\nProof. By definition, \u2205 contains exactly those items that appear in all the transactions. By monotonicity, as \u2205 \u2286 Z for all Z, \u2205 is a subset of all closures. If X is a closed singleton, either \u2205 = \u2205 or \u2205 = X; this second case is ruled out by the condition s(X) < n, as s(\u2205) = s(\u2205) = n. Our statements follow.\nProposition 4.17. Assume that |X| = 1 in rule X \u2192 XY , that is, the left hand side is a single item. Further, assume that s(X) < n, and that X and XY are closed. Then \u03b2(X \u2192 XY ) coincides with the minimum among the lift of X \u2192 Y and \u03c3(X \u2192 XY ).\nProof. By Propositions 4.6 and 4.7, we already know that \u03b2(X \u2192 XY ) is less than or equal to both quantities, under the given conditions. To complete the proof, we only need to show the converse inequality, that is, \u03b2(X \u2192 XY ) is larger than or equal to the minimum among the lift of X \u2192 Y and \u03c3(X \u2192 XY ). For this, we will apply Theorem 4.14: \u03b2(X \u2192 XY ) \u2264 b if and only if either \u03c3(X \u2192 XY ) \u2264 b or there is some closed proper subset X \u2032 \u2282 X, c(X \u2192 XY ) \u2264 b\u00d7c(X \u2032 \u2192 X \u2032Y ). We observe that, by Lemma 4.16, in our current conditions there is exactly one such X \u2032, namely \u2205, and the last inequality becomes, then, the statement that the lift of X \u2192 Y is at most b; indeed, the lift coincides with c(X\u2192XY )c(\u2205\u2192Y ) .\nAs we can chose any value of b, we pick simply b = \u03b2(X \u2192 XY ) itself, so that we can infer that either \u03c3(X \u2192 XY ) \u2264 b = \u03b2(X \u2192 XY ) or the lift of X \u2192 Y is also at most b = \u03b2(X \u2192 XY ). Thus, either \u03c3(X \u2192 XY ) or the lift of X \u2192 Y are less than or equal to \u03b2(X \u2192 XY ) and, certainly, the lesser of both quantities obeys the same bound, which completes the proof.\nWe obtain the corresponding variant of Corollary 3.9:\nCorollary 4.18. Assume a threshold b in place such that \u03c3(X \u2192 XY ) \u2265 b is known, for |X| = 1, that is, for a rule with a single antecedent item. If s(X) < n, X and XY are closed, and the lift of X \u2192 Y is less than b, then it equals \u03b2(X \u2192 XY ).\nAs a consequence, \u03b2(X \u2192 XY ) = \u03b2(X \u2192 XY ) for these cases. This is also consistent with Corollary 4.12: as we have stated in Lemma 4.16, in this case X is both closed and a minimal generator; if c(X \u2192 XY ) < 1, then this implies that it is equivalent to state that X \u2192 XY is a representative rule and to state that it is in the B? basis. This corollary will be very relevant in the implementation described in Section 6."}, {"heading": "4.3. Alternative Algorithm", "text": "Theorem 4.14 leads to an alternative algorithm to filter rules from the B? basis according to their closure-based confidence boost; we present it as Algorithm 3. Its correctness is immediate from Theorem 4.14. This algorithm is part of the tool described in Section 6;\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nit tends to be better than the previous one when left-hand sides tend to be small. It pays the price of traversing all closed subsets of a given closed set but spares traversing the alternative basis at lower confidence. In our implementation, as described below, the test of the support ratio is actually pushed into the closure mining, so that it becomes unnecessary to repeat it at the time of evaluating rules.\nAlgorithm 3: An alternative algorithm for closure-based confidence boost\nData: dataset D; thresholds for support \u03c4 , for confidence \u03b3, and for closure-based confidence boost b > 1; rule X \u2192 XY with X \u2229 Y = \u2205, X and XY both closed, c(X \u2192 XY ) \u2265 \u03b3, and s(XY ) \u2265 \u03c4 Result: boolean value indicating whether \u03b2(X \u2192 XY ) > b if \u03c3(X \u2192 XY ) \u2264 b then\nreturn False if \u2203Z \u2282 X closed such that c(X \u2192 XY ) \u2264 b\u00d7 c(Z \u2192 ZY ) then\nreturn False return True"}, {"heading": "5. EMPIRICAL VALIDATION", "text": "This section describes the outcomes of several empiric applications of the notions of confidence boost; the next section describes a complete tool that employs closure-based confidence boost, and the properties we have developed, to offer parameter-less association mining. With respect to specific datasets, we report first on objective figures: numbers of rules passing rather mild confidence boost thresholds on three datasets, all consisting of real world data, but of very different characteristics. Subsequently, we briefly discuss the much more difficult and subjective question of whether the rules that we find are actually the rules one may want."}, {"heading": "5.1. Quantitative Evaluation", "text": "Dataset Adult is the training set part of the Adult US census dataset from UCI [Asuncion and Newman 2007]. Dataset Retail was downloaded from the FIMI repository, and contains typical market basket data (http://fimi.cs.helsinki.fi/); and dataset Now (based on the Neogene of the Old World dataset, public release 030710 [Fortelius 2003]) is a transactional version of a paleontological dataset from Europe: we downloaded and preprocessed slightly file NOW public 030710.xls, so that each paleontological site has been casted into a transaction, where the items in the transactions are the species of which fossile remains have been found at that site. Additional information such as name or geographical position of the site have been omitted, in order to keep the transactional format.\nTable I gives some information about the datasets: their size (in number of transactions), the number of items involved, and the total of item occurrences. Each dataset has been mined at two different levels of support and three different levels of confidence. Support thresholds were chosen so as to produce noticeable numbers of rules, and also to make sure that the closure spaces were nontrivial in size (several thousand closures). Table II reports, for each pair of support and confidence values, the basis size (RR/B?, standing for representative rules and B? basis respectively) and then the number of these basis rules, for\neach basis, passing the corresponding confidence boost thresholds as given. Of course, for the B? case we bound the closure-based confidence boost.\nOur implementation was not particularly aimed at speed. Still, for instance, computing all the figures regarding the representative rule basis took less than 35 minutes on a lowrange laptop. For the higher support threshold in each dataset, each computation time was between 20 and 45 seconds. For the larger, more demanding closure lattice at the lower support threshold of each dataset, these figures required between 2 minutes and up to a maximum of 6 minutes. It will not be difficult to improve the running times in future work, as a number of known accelerations can be applied; we are already undertaking this task. Computationally, the slowest part was always the construction of the closure lattice.\nWith respect to the outcome, we see that the reduction of the number of rules is clear, and in some cases it is very considerable. Recall that the bound at 1 of the confidence boost discards those basis rules for which a rule with higher confidence can be obtained by either reducing the antecedent, enlarging the consequent, or both; in the first case, it would mean that the rule is actually a case of negative correlation that is better left off from the output."}, {"heading": "5.2. Subjective Evaluation", "text": "Quantitatively, the figures just given imply that large fractions of representative rules are somewhat uninteresting in that they fully lack any novelty, measured according to confidence boost. However, one may question whether the actual rules passing the thresholds are \u201cthe right ones\u201d. To our subjective perception, after seeing the outcome of our experiments, the whole process makes a lot of sense, but, in order to argue that indeed bounding the confidence boost leads to a worthy data mining scheme, we should find a more convincing argumentation. We hasten to add here that using the mined rules for classification will\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nnot provide a reasonable evaluation, since for such applications we must focus on single pairs of attribute and value as right-hand side, thus making useless to consider larger righthand sides; and, also, the classification will only be sensible to minimal left-hand sides independently of their confidences (as in Subsection 7.2 below). Because of these properties, a classification task is not fine enough to provide information about the usefulness of the subtler confidence quotients involved in the confidence boost bounds.\nClearly, the difficulty of this evaluation lies in the fact that the issue is largely subjective. At the present moment, our way through is to involve \u201cend-users\u201d in the evaluation of the obtained association rules: persons that are extremely well-versed on the dataset at hand. Both for our version of confidence boost, and for a sensible extension of it to handle absence of items besides presence of items in the transactions, we are developing an analysis of educational datasets, containing information about online courses on multimedia systems and on the Linux operating system, in close cooperation with the teachers of said courses [Balca\u0301zar et al. 2010a]. Here, however, instead of looking for experts on a given dataset, we use a dataset for which some readers of this paper might be expected to be reasonably knowledgeable: in the same vein as the evaluations in [Gallo et al. 2007], we employ the titles, topics, and abstracts of all the reports submitted to the e-prints repository of the Pascal Network of Excellence along its early years of existence. This dataset, extracted from the repository by Professor Steve Gunn, was the object of a visualization challenge of the Pascal Network in 2006. (Professor Gunn has also kindly furnished to this author a similar but much larger dataset, to which we plan to apply the same scheme in the near future.)\nThe collection of papers was processed starting from a plain text file containing one line for each of the 721 papers, including the title, the subjects chosen from among the specific choices allowed by the repository (marked by a \u2019 !\u2019 sign that we changed into the word \u201csubject\u201d), and the whole text of the abstract of the report. The (mild) preprocessing consisted in removing punctuation and nonprintable characters, mapping all letters into lowercase, stripping off stop words as per the list from www.textfixer.com, and removing duplicate words from each of the transactions so obtained. This left 45185 total word occurrences chosen from a vocabulary of 8233 items. We checked the size of the closure space at supports of 10% (135 closures) and 5% (830 closures, still somewhat small), and then at 1% (too large, as after a few minutes the program was still computing the closure lattice\u2019s edges\u2014in fact, a later run showed that it consists of 59713 closures). We settled for a far from trivial but manageable closure space consisting of 9621 closed itemsets obtained at 2% support. Then, we computed the B? basis at confidences 70% (1070 rules), 75% (729) rules, and 80% (412 rules), and cut them down by filtering them at closure-based confidence boosts of 1, 1.05, 1.1, 1.15, 1.2, 1.25, 1.3, 1.35, 1.4, 1.45 and 1.5. All the runs were almost instantaneous. The figures obtained, given in Table III, make it indeed possible to proceed to manual inspection of many of these options.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nNext, as a particular case, we chose to perform an examination of the 26 rules found at 2% support, 80% confidence, and 1.5 (closure-based) confidence boost, which revealed rules with little or no redundancy among themselves, all of them semantically sensible, and with a handful of them actually quite interesting (for this author). The whole process leading to these \u201cnuggets\u201d lasted less than two hours, including all the preprocessing, for a single person (the author) and quite limited computing power (an old Centrino Solo laptop). These rules are given in Table V. The predefined subjects of the e-prints Pascal server appearing in the table have been shortened to fit the page; Table IV reports the abbreviations used for them in Tables V and VI.\nBy way of comparison, at the same level of support, at the most demanding possible level of confidence (100%), with the less redundant basis computation currently known (the Guigues-Duquenne basis, [Guigues and Duquenne 1986]), the result is 44 rules, with considerably more \u201cintuitive redundancy\u201d and less interest overall, and requires somewhat longer time to be computed. Note that, by their own definition, the rules in the B? basis do not attempt at capturing rules with 100% confidence, but just at complementing them with partial rules; hence, the Guigues-Duquenne basis has some additional information. For the sake of comparison, this basis is given in Table VI. The considerable redundancy is clear: many variants of \u201csupport\u201d implies \u201cvector\u201d become reduced to a single one under the confidence boost bound. One may ask why the similar case of \u201cvector\u201d implies \u201csupport\u201d is missing from the list of 26 rules: the answer is that its confidence is slightly under 75% and, thus, it is not reported under the 80% threshold. Once more we see that setting the thresholds with no formal guidance runs into very risky processes. It would be necessary to try and help the user by some sort of self-adjustment of the thresholds. We have attempted at one first approach along this line, which is reported next.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY."}, {"heading": "6. TOWARDS PARAMETER-FREE ASSOCIATION MINING", "text": "In this section we describe an open-source software tool that profits from closure-based confidence boost and its properties to offer a sensible association mining process, while refraining from asking the user to select any value of any parameter: our system yacaree (Yet Another Closure-based Association Rule Experimentation Environment), a proof-ofconcept currently implemented fully in pure Python. It combines several processes using lazy evaluation by means of the functional programming facilities available in current versions of Python to mine high-boost B? association rules. Its key property is the self-tuning of the support and the confidence boost thresholds.\nAs in most current proposals, yacaree mines only frequent closed itemsets; initially, it enforces a support bound that starts ridiculously low (namely, at 5 transactions). In most applications, one cannot rely on mining all frequent closures at this threshold: this might or\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nmight not be possible, depending on the dataset; therefore, along the process, the threshold will be automatically increased. Frequent closures are mined via a simplified variant of ChARM [Zaki and Hsiao 2005], rather close to a depth-first search but with the proviso that closed itemsets are produced in order of decreasing support, so that increasing the support threshold does not invalidate the closures found so far.\nThis idea is reminiscent of the decreasing support in the version of \u201capriori\u201d implemented in the Weka tool [Witten and Frank 2005], but in that well-known system the user still has to provide a maximum and a minimum values to try the support threshold, and a \u201cdelta\u201d by which the support keeps decreasing; then, the \u201capriori\u201d algorithm is run repeatedly for the corresponding sequence of support thresholds. Further, the process stops when a given number of rules, also chosen by the user, has been found. This makes it unlikely to find rules of low support. The \u201cpredictive apriori\u201d alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence. Our system works very differently, as it is able to mine closures in order of decreasing support by its own algorithmics, and self-adjusts the internal effective support bound on the basis of technological limitations, in a manner that is autonomous and independent of the confidence or of any other parameter of the mining process.\nThe closed set miner takes the form of an iterator, and searches for the next closed set to be reported only when asked to do so. Each closure found is analyzed, upon yielding it to the next phase, to see whether it can be further extended without failing the current support threshold, and all those extensions, with their explicit supporting transaction lists, are added to a heap which provides instantaneously the largest-support closed set that has not been extended so far.\nThe closures are passed on to a lattice constructor, a \u201cborder\u201d algorithm which computes the lattice structure, so that immediate predecessors of each closed set are readily available, as it is convenient for computing the basis B?. The lattice constructor itself is based on [Baixeries et al. 2009] and works also as an iterator, constructing Hasse edges only when they are needed. Rules are, then, constructed from the lattice. Closures and candidate rules are either discarded, if we can guarantee that future threshold adjustments will never recover them; or processed, if they obey the thresholds; or maintained separately on hold, if they fail the current thresholds but might turn to obey them after future adjustments.\nThe support threshold changes along the process. It starts, as indicated, at an almost trivial level, and grows, if necessary, as the monitorization of the mining process reveals that the memory consumption surpasses internal thresholds. More precisely, the heap where unexpanded closures are stored is considered in overflow when either its length, or the total memory it uses, or the sum of the lengths of the associated support lists, exceeds a corresponding predefined threshold. At that point, the minimal support constraint is recomputed and raised as necessary so that the exploration can continue. In this way, both the risk of entering a huge closure space, and the risk of memory overflow upon computing the supports of the closed sets (as sometimes happens for dense datasets) are avoided.\nWe impose a very mild confidence threshold that remains fixed, letting large quantities of rules pass; but we control the number of rules to be provided to the user via a threshold on the closure-based confidence boost, which is adjusted also along the run. We use the approximation to the confidence boost provided by the support ratio (Proposition 4.6) to push the confidence boost constraint into the mining process, and we use the lift, applied to the particular cases to which Corollary 4.18 applies, to self-adjust the boost threshold.\nIn fact, as the Hasse edges of the closures lattice are identified, the support ratio can be computed easily. If it is lower than the current confidence boost threshold, the closure is not adequate to yield high boost rules, but it could become so if, in the future, the confidence boost threshold decreases. Therefore, the confidence boost constraint is partially \u201cpushed into\u201d the mining process by temporarily omitting the expansion of such closed sets. Instead, they are maintained separately into a dedicated data structure, from where they are \u201cfished\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\noff\u201d again in case a decrease of the boost bound promotes them to candidate closures for creating high-boost rules. We take advantage of the support ratio constraint also to compute the confidence boost of rules, as per Algorithm 3: we know that, if the closed set reaches that stage, then its support ratio is high enough, so we do not need to test it again.\nThe mining process starts with a somewhat demanding confidence boost bound, that requires a rule to have at least 15% more confidence than any of the rules participating in its confidence boost in order to qualify as interesting. In some datasets, this figure is not that restrictive, and dozens of rules still make it. By default, the system writes off as result the up to 50 rules of highest boost.\nIn many datasets, though, that confidence boost bound is too demanding. The program monitors the lift of rules having one single item as antecedent and obtained from a closed set that has support ratio above the confidence boost bound (cf. Corollary 4.18). If these lift values keep decreasing, they enter a weighted average with the current confidence boost bound and may decrease it. In this way, we track the degree of correlation empirically found in the dataset to reduce conveniently the confidence boost bound. There is a static limit to this boost bound: it is never allowed to drop below 1.05. (All the hardwired limits can be modified easily in the same module statics.py of the source code.)\nThe result is a functional preliminary system, where ample room still remains for efficiency and algorithmic improvements, which shows that it is possible to find interesting association rules in a fully autonomous manner: the user simply selects a dataset and launches the process, which takes just one to five minutes in many easy datasets, and up to ten to twenty minutes on a modern laptop for a few difficult, highly dense datasets. The output is a set of rules which, in most cases, is reasonably small and shows independent and sensible associations.\nThe open source, plus some example datasets, can be downloaded from http://sourceforge.net/projects/yacaree/; these example datasets are already preprocessed into transactional form, and come from [Asuncion and Newman 2007] or [Fortelius 2003], or from the e-prints repository of the Pascal Network of Excellence. The screenshot provided in Figure 2 shows the simple interface (button \u201cRun\u201d is disabled as the system has been just run) and the two text files generated: the log, where we can see that the process took a bit over five minutes, and the start of the file containing the rules found. Both the console and the log indicate the self-adjustments of the support; along this particular run, no adjustment was performed on the boost threshold, as enough high-boost rules were found for its initial value."}, {"heading": "7. DISCUSSION", "text": "The main contribution of this paper is the closure-based confidence boost: a new concept that measures a form of objective novelty for association rules, which we have studied from the formal and algorithmic perspective and which we have used to construct open source association mining tools.\nOur starting point was the study of notions of redundancy in a \u201clogical\u201d spirit. When a rule is irredundant, we still can use relative confidences to assess the degree of irredundancy, which we see as a potentially useful formalization of objective novelty.\nA redundancy due to larger consequents can be measured by the support ratio; as such, both earlier notions like confidence width and our new proposals are related to it. A redundancy due to smaller antecedents only in some cases is handled appopriately by the preexisting confidence width, due to the stringent condition of \u201clogical\u201d redundancy; with the also preexisting notion of blocking, the case of smaller antecedents is handled in a less strict, more intuitively useful way. A bound on the simplest of the two versions of confidence boost is exactly equivalent to bounding both preexisting notions, width and blocking; therefore, our first new proposal allows for much smoother handling of the combination of the previously studied concepts.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nAs the notion of plain confidence boost turns out to be debatable for one specific \u201cclosureaware\u201d basis, the B? rules, we have proposed also a more sophisticate \u201cclosure-aware\u201d version of the confidence boost, for which we have developed the corresponding formal and algorithmic study.\nAn obvious drawback of using a confidence boost bound is the need to choose yet another parameter for the mining process, besides confidence and support. However, in our experiments, this problem did not seem to be that serious: a noticeable aspect of the confidence boost bound is that the outcome of the mining shows relatively quite low sensitivity both with respect to its precise value and with respect to the values of other parameters such as confidence: quite similar sets of rules are obtained. We quickly learned to use two standard values, at 1.05 to prune off just really low novelty rules and at 1.2 to prune more aggressively; whereas, in case the dataset still gives many rules above this threshold, occassionally we would employ the very drastic value of 1.5. This scheme tends to work well, and not only that: it also make less critical the choice of the confidence threshold, that can be safely left at a somewhat low value (say, around 0.6 to 0.7), leaving to the boost parameter the task of reducing the output size. These empirical facts were widespread to such an extent that we attempted at using (closure-based) confidence boost to try and construct a parameterfree association miner: the yacaree system, able to self-tune the closure-based confidence boost and the support thresholds. We believe that the embodiment of the computation of the B? basis together with closure-based confidence boost bounds in an open source tool will promote its use in data mining practice, as yacaree exhibits a unique quality of \u201cturnkey\u201d system that works with just the few clicks needed to choose the input dataset. Of course, it can be used as well in the standard manner, as the default initial values of confidence, support, and other internal parameters can be manually tuned effortlessly, if necessary, by data mining experts. However, this action is not anymore necessary, as yacaree is ready to do its best with no need of user choices. The system is platform independent, although in a system with small memory, the control of the heap size may require some initial tuning (to be made just once) to avoid runtime errors for lack of memory; whereas, in very powerful systems, obtaining the most of them may also require some tuning.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nThe shortcomings of confidence thresholds discussed at the beginning of Subsection 2.2 have been often interpreted as an inadequacy of the very notion of confidence. Yet, we prefer to develop our proposal in the context of support and confidence bounds, for several reasons.\nFirst, conditional probability is a concept known to many educated users from a number of scientific and engineering disciplines, so that communication between the data mining expert and the domain expert is often simplified if our measure is confidence. Second, as a very elementary concept, it is the best playground to study other proposals, such as our contribution here, which could be then lifted to other similar parameters.\nThird, and more importantly, we believe that, in fact, our approach of complementing it with relative measures will make up for many of the objections raised against confidence. In fact, our interpretation of this sort of objections is not the widespread consequence that \u201cconfidence is inapproprate\u201d to filter and rank association rules, but that \u201can absolute threshold on confidence is inappropriate\u201d to filter and rank association rules. This does not mean that it has to be replaced as a measure of intensity of implication, and, in fact, it has been observed and argued that (at least in somewhat sparse transactional datasets) the combination of support and confidence is already very good at discarding rules that are present only as statistical artifacts and do not really correspond to correlations in the phenomenon at the origin of the dataset [Megiddo and Srikant 1998]; instead, we consider that our message is that it should be complemented with relative confidence thresholds that assess the novelty of each rule by comparison with the confidence of logically (or intuitively) stronger rules. The identification of the precise notion for this task is a clear research issue, to which we have contributed via our two variants of the notion of confidence boost.\nA number of connected approaches to association rule quality exist in the literature. We discuss here those that we have found most closely related; Subsection 7.2 is devoted to the deeper analysis of a particularly close contribution. We finish the paper with a description of forthcoming work."}, {"heading": "7.1. Comparisons to Related Work", "text": "We refer to [Geng and Hamilton 2006] for an excellent survey of many options to relate supports of left and right hand sides of association rules to construct indicators of interestingness. Many of these only work on a single rule, with no reference to alternative rules with, say, smaller but otherwise arbitrary left-hand sides. A notable case is lift, which implicitly refers to a rule with the same right-hand side and an empty left-hand side, as discussed in the proof of Proposition 3.4. Compared to this family of measures, confidence boost is finer as it can distinguish among many alternative antecedents to compare, at the price of being potentially more expensive to evaluate due to the search for smaller but arbitrary left-hand sides, and larger but arbitrary right-hand sides. We have shown several algorithms that attempt at circumscribing this search to smaller spaces.\nMore sophisticated interestingness measures are possible, for instance those based on the KL-divergence between probability distributions induced with and without the given rule [Jaroszewicz and Simovici 2002]: the induced distributions satisfy the supports of the rule and of its antecedent but otherwise maximize the entropy. In preliminary tests, our approach, with quite robust settings of confidence (between 0.6 and 0.7) and boost (stardard threshold of 1.2) gives results very close to those in [Jaroszewicz and Simovici 2002].\nSeveral published works attempt at a similar detection of the \u201cexceptionality\u201d or \u201csurprisingness\u201d of rules; many of these work in the relational setting, instead of the transactional setting where our work fits. Relational data can be analysed in the transactional setting by converting a pair given by an attribute name and a value for the attribute into a single item, as we do in the Adult dataset in Table II. Assuming the relational structure of the data, however, brings in the extra power of \u201cimplicit negation\u201d of attributes, due to the incompatibility among simultaneous values of the same attribute. This implicit negation is\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nuseful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V \u2032 for V \u2032 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others. Our purely transactional setting (like for the Retail or Now datasets) does not allow us to employ this method of implicit negation and, therefore, such contributions are not directly comparable to ours.\nA few additional contributions that still lie in the transactional setting and are similar to ours are discussed next. The notions of confidence width and rule blocking from [Balca\u0301zar 2009] are similar to the \u201cpruning\u201d proposal from [Liu et al. 1999], in that the intuition is the same; also our proposal here follows an analogous intuitive path. Major differences are that, in the proposals we discuss, a large portion of the pruning becomes unnecessary because we work on minimum-size bases, namely representative rules, and, more importantly, that the pruning in [Liu et al. 1999] is based on the \u03c72 statistic, whereas we will look instead into the confidence thresholds that would make the rule \u201credundant\u201d, either in a \u201cformal logic\u201d sense or in a more intuitive, but still logical-style relaxation. Our notions are also similar to the notion of improvement, proposed in [Bayardo et al. 1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent."}, {"heading": "7.2. Minimum Antecedent and Maximum Consequent", "text": "Many works suggest further notions of redundancy, in most cases based upon mere intuition. The fact that a rule X \u2192 XY is redundant with respect to X \u2192 XY \u2032 whenever Y \u2282 Y \u2032 (in the sense of having at least the same confidence) is pointed out in many places (e.g. [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]). Our starting point being the representative basis, we only would keep X \u2192 XY if its confidence is higher than that of X \u2192 XY \u2032, by a factor indicated by the confidence boost; this quantification is an effective refinement of that known proposal.\nOn the other hand, redundancy of X \u2192 XY with respect to X \u2032 \u2192 X \u2032Y , where X \u2032 \u2282 X, is debatable. As we have already discussed in Subsection 2.2, rules X \u2192 XY and X \u2032 \u2192 X \u2032Y , where X \u2032 \u2282 X, provide different, orthogonal information. Still, one may wish to forget about AB \u2192 C if A \u2192 C is already present; this seems a natural attitude, and, in fact, explicit proposals of removing the seemingly redundant rule appear in many references, often jointly with the (correct) observation of redundancy due to larger consequents. This happens in the structural cover of [Toivonen et al. 1995], and in some of the pruning rules of [Shah et al. 1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005]. All these proposals may make sense as heuristics, and their connection to confidence boost is developed below; however, if taken as redundancy statements then they are incorrect and, in some cases, where a precise mathematical statement and its proof are provided (like [Scheffer 2005]), the proof can be seen to switch into a \u201cfull implication\u201d meaning of the \u201carrow\u201d connective, and is actually wrong, therefore, since it does not apply to partial rules. Discarding the apparently weaker rule requires more care and a finer discussion and, actually, the confidence boost provides for this.\nIn fact, without pretending to argue redundancy, one could consider rules with minimal antecedent and maximal consequent simply as an heuristic for handling a large set of mined rules, acting as a sort of summaries of rules with larger antecedents or shorter consequents, or both. As a representative of these proposals, we chose to discuss the approach of [Kryszkiewicz 1998c] which can be casted as follows:\nDefinition 7.1. For a fixed confidence threshold \u03b3 and a fixed support threshold \u03c4 , the minimal-antecedent, maximal-consequent rules MMR\u03c4,\u03b3 are those rules X \u2192 XY (with\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nX \u2229 Y = \u2205) such that c(X \u2192 XY ) \u2265 \u03b3, s(X \u2192 XY ) \u2265 \u03c4 , and for which the following holds: the only rule X \u2032 \u2192 X \u2032Y \u2032 with X \u2032 \u2229 Y \u2032 = \u2205, c(X \u2032 \u2192 X \u2032Y \u2032) \u2265 \u03b3, s(X \u2192 XY ) \u2265 \u03c4 which satisfies that X \u2032 \u2286 X and Y \u2286 Y \u2032, is itself: X = X \u2032 and Y = Y \u2032.\nThe following holds [Kryszkiewicz 1998c]:\nProposition 7.2. For a confidence threshold \u03b3 and a support threshold \u03c4 , all MMR\u03c4,\u03b3 rules are representative rules for these thresholds.\nLet us point out that these rules are subtly different from the min-max approximate basis of [Pasquier et al. 2005], given in Definition 2.3, their apparent similarity notwithstanding. There, the closed set forming the whole right-hand side is to be maximal, including the antecedent; here, only the part of the closed set that does not belong to the antecedent is to be maximal. As the antecedent is itself minimal, the notions differ. In a sense, MMR are to min-max rules as confidence boost is to confidence width.\nExample 7.3. In our running example, we find that rule BC \u2192 A has confidence \u03b3 = 8/9. It is a representative rule at its confidence threshold \u03b3 = 8/9, hence it is a min-max rule by Proposition 2.5; but it is not in MMR\u03c4,\u03b3 since c(B \u2192 A) = 10/11 > \u03b3. This example also proves that the converse of Proposition 7.2 does not hold.\nAs discussed in depth in Subsection 2.2, we must be aware that MMR\u2019s may lose information, since rules that have nonminimal antecedents may be actually irredundant and potentially interesting. Our main proposal in this paper, confidence boost, can be interpreted as a quantitative variant of MMR\u2019s, whereby nonminimal antecedents or nonmaximal consequents are likely to be considered not novel (and conversely), yet this connection depends on how well the rule clears the confidence and support thresholds. More precisely:\nProposition 7.4. Fix support and confidence thresholds \u03c4 and \u03b3. (1 ) If X \u2192 Y is a MMR\u03c4,\u03b3 rule, then \u03b2(X \u2192 Y ) \u2265 min ( s(X\u2192Y ) \u03c4 , c(X\u2192Y ) \u03b3 ) . (2 ) If X \u2192 Y is not a MMR\u03c4,\u03b3 rule, then \u03b2(X \u2192 Y ) \u2264 c(X\u2192Y )\u03b3 .\nProof.\n(1) Consider an MMR\u03c4,\u03b3 rule X \u2192 Y . Any different rule X \u2032 \u2192 Y \u2032 with X \u2032 \u2286 X and Y \u2286 Y \u2032 must fail either the support threshold \u03c4 or the confidence threshold \u03b3. First we show that, for such a rule, c(X \u2032 \u2192 Y \u2032) \u2264 max( \u03c4s(X) , \u03b3), considering two cases. Assume X \u2032 6= X, and consider rule X \u2032 \u2192 Y , which is also different from X \u2192 Y . We have s(X \u2032Y ) \u2265 s(XY ) > \u03c4 so that it must fail the confidence threshold; hence, c(X \u2032 \u2192 Y \u2032) \u2264 c(X \u2032 \u2192 Y ) < \u03b3 \u2264 max( \u03c4s(X) , \u03b3). Assume now X\n\u2032 = X: either c(X \u2032 \u2192 Y \u2032) < \u03b3, or X \u2032 \u2192 Y \u2032 fails the support threshold, s(X \u2032Y \u2032) = s(XY \u2032) \u2264 \u03c4 , whence c(X \u2032 \u2192 Y \u2032) = s(X\n\u2032Y \u2032) s(X\u2032) \u2264 \u03c4 s(X\u2032) = \u03c4 s(X) ; thus c(X \u2032 \u2192 Y \u2032) \u2264 max( \u03c4s(X) , \u03b3) again. Now we can bound the confidence boost easily: any rule considered for the maximization in the denominator of the definition of confidence boost has confidence at most max( \u03c4s(X) , \u03b3), and there are finitely many of them, so that the denominator itself\nobeys the same bound, which implies that \u03b2(X \u2192 Y ) \u2265 min ( c(X\u2192Y )\n\u03c4 s(X)\n, c(X\u2192Y )\u03b3\n) =\nmin ( s(X\u2192Y )\n\u03c4 , c(X\u2192Y ) \u03b3\n) .\n(2) This part is quite simple. If X \u2192 Y is not an MMR\u03c4,\u03b3 rule, then there must exist some different rule X \u2032 \u2192 Y \u2032 with X \u2032 \u2286 X and Y \u2286 Y \u2032 passing the support and confidence thresholds; this rule enters the maximization in the denominator of the\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\ndefinition of confidence boost, which is, then, at least \u03b3, resulting in a confidence boost \u03b2(X \u2192 Y ) \u2264 c(X\u2192Y )\u03b3 .\nThat is: a rule that is not an MMR\u03c4,\u03b3 rule, and barely clears the confidence threshold \u03b3, can be appropriately pruned as not novel due to low boost; but, if its confidence is much higher than the threshold, even if it is not MMR, it may exhibit enough novelty to make it debatable whether it must be pruned off the output. Conversely, an MMR\u03c4,\u03b3 rule that clears barely the support and confidence thresholds may turn out to be of low confidence boost, and it could be better to omit it from the output. Essentially, the same purpose is attempted by both approaches but confidence boost bounds offers a quantitative evaluation of the extent to which representative rules are appropriate as rules to choose for the output of the mining process: they will often coincide with the MMR\u03c4,\u03b3 but these will be occassionally inadequate."}, {"heading": "7.3. Further Work", "text": "Of course, the use of confidence boost does not preclude a combination with lift or any other measure of intensity of implication; to what extent these separate measures interact with confidence boost, and which ones perform best, is one among many open lines of future research.\nIndeed, whatever method is proposed to reduce the output of an association miner leaves a major doubt: are these the rules one really wants? We plan to continue working on this rather subjective issue, and intend to employ further actual end-user evaluations from dataset providers, as we have started to do with respect to partial aspects. We are working on datasets coming from an e-learning platform, for which we have a manually recorded labeling of the interest of each rule, provided by the dataset suppliers, namely, the teachers of the courses where the datasets originated, who are also available for consultation. The particular characteristics of this dataset require us first to extend our approach into handling both presence and absence of each item [Balca\u0301zar et al. 2010a; 2010b]. Also, sometimes, some of the full-confidence implications would be desirable indeed for inclusion in the output, given that working on the basis B? leaves them fully out; however, it is unclear whether confidence boost would still be the right notion, and, even so, full-confidence implications require to compute the minimal generators of each closure, therefore losing the desirable advantage offered by closure-based confidence boost operating on top of B? rules, which can be computed much faster since they only use the closures lattice. We continue to investigate this problem, and some partial progress, on which we still hope to improve, is reported in [Balca\u0301zar et al. 2010b].\nThe yacaree tool has many developments open to further work. First, since we mine frequent closures in descending support, instead of ascending, some of the optimizations in ChARM require further work before being readily applicable; also, the best algorithm in [Baixeries et al. 2009] (namely iPred) to compute Hasse edges is not applied, as it assumes a cardinality-ordered traversal of the closed sets instead of a support-oriented one; the theorems that guarantee its applicability have been obtained only recently, and a forthcoming version of yacaree will sport this faster algorithm, iPred. Also, it seems possible that a smarter coupling of the miner with the lattice computation might provide further accelerations. On the other hand, from the point of view of the user, and beyond efficiency improvement considerations, a few alternative internal configurations of the parameters might reveal themselves useful, provided one can hit with intuitive descriptions that make them clearly understandable by nonexperts: indeed, whereas the user is grateful for being able to run the program with no parameter selection, yacaree is not snake oil, and it is likely that, for certain datesets, and after seeing the result, the user may be tempted to \u201ctry again\u201d in some alternative way.\nACM Journal Name, Vol. V, No. N, Article A, Publication date: January YYYY.\nHence, we will work next on improving the speed of the system, on finding sensible ways of reporting interesting full-confidence implications without paying too much as a time overhead, and on developing interactions with end users to study their evaluations of the generated sets of rules, possibly leading thus to further refinements of the confidence boost notion and of any other aspect that might be considered. In the meantime, researchers interested in conducting their own evaluation can download the system freely and analyze the output of confidence-boost-bounded mining on their datasets; this author would be grateful to be informed of the results."}], "references": [{"title": "A new approach to online generation of association rules", "author": ["C.C. Aggarwal", "P.S. Yu"], "venue": "IEEE Transactions on Knowledge and Data Engineering 13, 4, 527\u2013540.", "citeRegEx": "Aggarwal and Yu,? 2001", "shortCiteRegEx": "Aggarwal and Yu", "year": 2001}, {"title": "Fast discovery of association rules", "author": ["R. Agrawal", "H. Mannila", "R. Srikant", "H. Toivonen", "A.I. Verkamo"], "venue": "Advances in Knowledge Discovery and Data Mining. AAAI/MIT Press, 307\u2013328.", "citeRegEx": "Agrawal et al\\.,? 1996", "shortCiteRegEx": "Agrawal et al\\.", "year": 1996}, {"title": "Yet a faster algorithm for building the Hasse diagram of a concept lattice", "author": ["J. Baixeries", "L. Szathmary", "P. Valtchev", "R. Godin"], "venue": "Proc. of the 7th International Conference on Formal Concept Analysis (ICFCA), S. Ferr\u00e9 and S. Rudolph, Eds. Lecture Notes in Artificial Intelligence Series, vol. 5548. Springer-Verlag, 162\u2013177.", "citeRegEx": "Baixeries et al\\.,? 2009", "shortCiteRegEx": "Baixeries et al\\.", "year": 2009}, {"title": "Two measures of objective novelty in association rule mining", "author": ["J.L. Balc\u00e1zar"], "venue": "PAKDD Workshops (Springer-Verlag LNCS 5669). 76\u201398.", "citeRegEx": "Balc\u00e1zar,? 2009", "shortCiteRegEx": "Balc\u00e1zar", "year": 2009}, {"title": "Closure-based confidence boost in association rules", "author": ["J.L. Balc\u00e1zar"], "venue": "JMLR Workshop and Conference Proceedings \u2013 Workshop on Applications of Pattern Analysis 11, 1\u20137.", "citeRegEx": "Balc\u00e1zar,? 2010a", "shortCiteRegEx": "Balc\u00e1zar", "year": 2010}, {"title": "Objective novelty of association rules: Measuring the confidence boost", "author": ["J.L. Balc\u00e1zar"], "venue": "EGC, S. B. Yahia and J.-M. Petit, Eds. Revue des Nouvelles Technologies de l\u2019Information Series, vol. RNTIE-19. C\u00e9padu\u00e8s-\u00c9ditions, 297\u2013302.", "citeRegEx": "Balc\u00e1zar,? 2010b", "shortCiteRegEx": "Balc\u00e1zar", "year": 2010}, {"title": "Redundancy, deduction schemes, and minimum-size bases for association rules", "author": ["J.L. Balc\u00e1zar"], "venue": "Logical Methods in Computer Science 6, 2:3, 1\u201333.", "citeRegEx": "Balc\u00e1zar,? 2010c", "shortCiteRegEx": "Balc\u00e1zar", "year": 2010}, {"title": "Parameter-free association rule mining with yacaree", "author": ["J.L. Balc\u00e1zar"], "venue": "See Khenchaf and Poncelet", "citeRegEx": "Balc\u00e1zar,? 2011", "shortCiteRegEx": "Balc\u00e1zar", "year": 2011}, {"title": "Closed-set-based discovery of representative association rules revisited", "author": ["J.L. Balc\u00e1zar", "C. T\u0302\u0131rn\u0103uc\u0103"], "venue": "See Khenchaf and Poncelet", "citeRegEx": "Balc\u00e1zar and T\u0302\u0131rn\u0103uc\u0103,? \\Q2011\\E", "shortCiteRegEx": "Balc\u00e1zar and T\u0302\u0131rn\u0103uc\u0103", "year": 2011}, {"title": "Mining educational data for patterns with negations and high confidence boost", "author": ["J.L. Balc\u00e1zar", "C. T\u0302\u0131rn\u0103uc\u0103", "M. Zorrilla"], "venue": "Taller de Miner\u0301\u0131a de Datos TAMIDA", "citeRegEx": "Balc\u00e1zar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Balc\u00e1zar et al\\.", "year": 2010}, {"title": "Filtering association rules with negations on the basis of their confidence boost", "author": ["J.L. Balc\u00e1zar", "C. T\u0302\u0131rn\u0103uc\u0103", "M.E. Zorrilla"], "venue": "KDIR", "citeRegEx": "Balc\u00e1zar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Balc\u00e1zar et al\\.", "year": 2010}, {"title": "Constraint-based rule mining in large, dense databases", "author": ["R. Bayardo", "R. Agrawal", "D. Gunopulos"], "venue": "ICDE. 188\u2013197.", "citeRegEx": "Bayardo et al\\.,? 1999", "shortCiteRegEx": "Bayardo et al\\.", "year": 1999}, {"title": "Free-sets: A condensed representation of boolean data for the approximation of frequency queries", "author": ["Boulicaut", "J.-F.", "A. Bykowski", "C. Rigotti"], "venue": "Data Min. Knowl. Discov. 7, 1, 5\u201322.", "citeRegEx": "Boulicaut et al\\.,? 2003", "shortCiteRegEx": "Boulicaut et al\\.", "year": 2003}, {"title": "Neogene of the old world database of fossil mammals (NOW)", "author": ["M. Fortelius"], "venue": "University of Helsinki, 2003, [http://www.helsinki.fi/science/now].", "citeRegEx": "Fortelius,? 2003", "shortCiteRegEx": "Fortelius", "year": 2003}, {"title": "Mini: Mining informative non-redundant itemsets", "author": ["A. Gallo", "T. De Bie", "N. Cristianini"], "venue": "PKDD, J. N. Kok, J. Koronacki, R. L. de M\u00e1ntaras, S. Matwin, D. Mladenic, and A. Skowron, Eds. Lecture Notes in Computer Science Series, vol. 4702. Springer, 438\u2013445.", "citeRegEx": "Gallo et al\\.,? 2007", "shortCiteRegEx": "Gallo et al\\.", "year": 2007}, {"title": "Interestingness measures for data mining: A survey", "author": ["L. Geng", "H.J. Hamilton"], "venue": "ACM Comput. Surv. 38, 3.", "citeRegEx": "Geng and Hamilton,? 2006", "shortCiteRegEx": "Geng and Hamilton", "year": 2006}, {"title": "Familles minimales d\u2019implications informatives r\u00e9sultant d\u2019un tableau de donn\u00e9es binaires", "author": ["J. Guigues", "V. Duquenne"], "venue": "Math\u00e9matiques et Sciences Humaines 95, 5\u201318.", "citeRegEx": "Guigues and Duquenne,? 1986", "shortCiteRegEx": "Guigues and Duquenne", "year": 1986}, {"title": "Pruning redundant association rules using maximum entropy principle", "author": ["S. Jaroszewicz", "D. Simovici"], "venue": "Proc. of the 6th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD). Lecture Notes in Artificial Intelligence. Springer-Verlag, 135\u2013147.", "citeRegEx": "Jaroszewicz and Simovici,? 2002", "shortCiteRegEx": "Jaroszewicz and Simovici", "year": 2002}, {"title": "Actes de Extraction et gestion des connaissances (EGC)", "author": ["A. Khenchaf", "P. Poncelet", "Eds."], "venue": "Revue des Nouvelles Technologies de l\u2019Information Series, vol. E.20. Hermann.", "citeRegEx": "Khenchaf et al\\.,? 2011", "shortCiteRegEx": "Khenchaf et al\\.", "year": 2011}, {"title": "Fast discovery of representative association rules", "author": ["M. Kryszkiewicz"], "venue": "Proc. of the 1st International Conference on Rough Sets and Current Trends in Computing (RSCTC), L. Polkowski and A. Skowron, Eds. Lecture Notes in Artificial Intelligence Series, vol. 1424. Springer-Verlag, 214\u2013221.", "citeRegEx": "Kryszkiewicz,? 1998a", "shortCiteRegEx": "Kryszkiewicz", "year": 1998}, {"title": "Representative association rules", "author": ["M. Kryszkiewicz"], "venue": "Proc. of the 2nd Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), X. Wu, K. Ramamohanarao, and K. B. Korb, Eds. Lecture Notes in Artificial Intelligence Series, vol. 1394. Springer-Verlag, 198\u2013209.", "citeRegEx": "Kryszkiewicz,? 1998b", "shortCiteRegEx": "Kryszkiewicz", "year": 1998}, {"title": "Representative association rules and minimum condition maximum consequence association rules", "author": ["M. Kryszkiewicz"], "venue": "See Zytkow and Quafafou [1998], 361\u2013369.", "citeRegEx": "Kryszkiewicz,? 1998c", "shortCiteRegEx": "Kryszkiewicz", "year": 1998}, {"title": "Closed set based discovery of representative association rules", "author": ["M. Kryszkiewicz"], "venue": "Proc. of the 4th International Symposium on Intelligent Data Analysis (IDA), F. Hoffmann, D. J. Hand, N. M. Adams, D. H. Fisher, and G. Guimar\u00e3es, Eds. Lecture Notes in Computer Science Series, vol. 2189. Springer-Verlag, 350\u2013359.", "citeRegEx": "Kryszkiewicz,? 2001", "shortCiteRegEx": "Kryszkiewicz", "year": 2001}, {"title": "Concise representations of association rules", "author": ["M. Kryszkiewicz"], "venue": "Proc. of the ESF Exploratory Workshop on Pattern Detection and Discovery, D. J. Hand, N. M. Adams, and R. J. Bolton, Eds. Lecture Notes in Computer Science Series, vol. 2447. Springer-Verlag, 92\u2013109.", "citeRegEx": "Kryszkiewicz,? 2002", "shortCiteRegEx": "Kryszkiewicz", "year": 2002}, {"title": "On selecting interestingness measures for association rules: User oriented description and multiple criteria decision aid", "author": ["P. Lenca", "P. Meyer", "B. Vaillant", "S. Lallich"], "venue": "European Journal of Operational Research 184, 2, 610\u2013626.", "citeRegEx": "Lenca et al\\.,? 2008", "shortCiteRegEx": "Lenca et al\\.", "year": 2008}, {"title": "Pruning and summarizing the discovered associations", "author": ["B. Liu", "W. Hsu", "Y. Ma"], "venue": "Proc. Knowledge Discovery in Databases. 125\u2013134.", "citeRegEx": "Liu et al\\.,? 1999", "shortCiteRegEx": "Liu et al\\.", "year": 1999}, {"title": "Implications partielles dans un contexte", "author": ["M. Luxenburger"], "venue": "Math\u00e9matiques et Sciences Humaines 29, 35\u201355.", "citeRegEx": "Luxenburger,? 1991", "shortCiteRegEx": "Luxenburger", "year": 1991}, {"title": "Discovering predictive association rules", "author": ["N. Megiddo", "R. Srikant"], "venue": "Proc. Knowledge Discovery in Databases. 274\u2013278.", "citeRegEx": "Megiddo and Srikant,? 1998", "shortCiteRegEx": "Megiddo and Srikant", "year": 1998}, {"title": "Small is beautiful: discovering the minimal set of unexpected patterns", "author": ["B. Padmanabhan", "A. Tuzhilin"], "venue": "Proc. Knowledge Discovery in Databases. 54\u201363.", "citeRegEx": "Padmanabhan and Tuzhilin,? 2000", "shortCiteRegEx": "Padmanabhan and Tuzhilin", "year": 2000}, {"title": "Generating a condensed representation for association rules", "author": ["N. Pasquier", "R. Taouil", "Y. Bastide", "G. Stumme", "L. Lakhal"], "venue": "J. Intell. Inf. Syst. 24, 1, 29\u201360.", "citeRegEx": "Pasquier et al\\.,? 2005", "shortCiteRegEx": "Pasquier et al\\.", "year": 2005}, {"title": "The representative basis for association rules", "author": ["V. Phan-Luong"], "venue": "Proc. of the 2001 IEEE International Conference on Data Mining (ICDM), N. Cercone, T. Y. Lin, and X. Wu, Eds. IEEE Computer Society, 639\u2013640.", "citeRegEx": "Phan.Luong,? 2001", "shortCiteRegEx": "Phan.Luong", "year": 2001}, {"title": "Discovery, analysis, and presentation of strong rules", "author": ["G. Piatetsky-Shapiro"], "venue": "Proc. Knowledge Discovery in Databases. 229\u2013248.", "citeRegEx": "Piatetsky.Shapiro,? 1991", "shortCiteRegEx": "Piatetsky.Shapiro", "year": 1991}, {"title": "Finding association rules that trade support optimally against confidence", "author": ["T. Scheffer"], "venue": "Intelligent Data Analysis 9, 293\u2013313.", "citeRegEx": "Scheffer,? 2005", "shortCiteRegEx": "Scheffer", "year": 2005}, {"title": "Interestingness and pruning of mined patterns", "author": ["D. Shah", "L. Lakshmanan", "K. Ramamritham", "S. Sudarshan"], "venue": "ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery.", "citeRegEx": "Shah et al\\.,? 1999", "shortCiteRegEx": "Shah et al\\.", "year": 1999}, {"title": "Beyond market baskets: Generalizing association rules to dependence rules", "author": ["C. Silverstein", "S. Brin", "R. Motwani"], "venue": "Data Min. Knowl. Discov. 2, 1, 39\u201368.", "citeRegEx": "Silverstein et al\\.,? 1998", "shortCiteRegEx": "Silverstein et al\\.", "year": 1998}, {"title": "Autonomous discovery of reliable exception rules", "author": ["E. Suzuki"], "venue": "Proc. Knowledge Discovery in Databases.", "citeRegEx": "Suzuki,? 1997", "shortCiteRegEx": "Suzuki", "year": 1997}, {"title": "Discovery of surprising exception rules based on intensity of implication", "author": ["E. Suzuki", "Y. Kodratoff"], "venue": "See Zytkow and Quafafou [1998].", "citeRegEx": "Suzuki and Kodratoff,? 1998", "shortCiteRegEx": "Suzuki and Kodratoff", "year": 1998}, {"title": "Selecting the right objective measure for association analysis", "author": ["Tan", "P.-N.", "V. Kumar", "J. Srivastava"], "venue": "Information Systems 29, 4, 293\u2013313.", "citeRegEx": "Tan et al\\.,? 2004", "shortCiteRegEx": "Tan et al\\.", "year": 2004}, {"title": "Pruning and grouping discovered association rules", "author": ["H. Toivonen", "M. Klemettinen", "P. Ronkainen", "K. H\u00e4t\u00f6nen", "H. Mannila"], "venue": "ECML-95 Workshop on Statistics, Machine Learning, and Knowledge Discovery in Databases. 47\u201352.", "citeRegEx": "Toivonen et al\\.,? 1995", "shortCiteRegEx": "Toivonen et al\\.", "year": 1995}, {"title": "Discovering significant patterns", "author": ["G.I. Webb"], "venue": "Machine Learning 68, 1, 1\u201333.", "citeRegEx": "Webb,? 2007", "shortCiteRegEx": "Webb", "year": 2007}, {"title": "Data Mining: Practical Machine Learning Tools and Techniques (2ed)", "author": ["I.H. Witten", "E. Frank"], "venue": "Morgan Kaufmann.", "citeRegEx": "Witten and Frank,? 2005", "shortCiteRegEx": "Witten and Frank", "year": 2005}, {"title": "Mining non-redundant association rules", "author": ["M.J. Zaki"], "venue": "Data Min. Knowl. Discov. 9, 3, 223\u2013248.", "citeRegEx": "Zaki,? 2004", "shortCiteRegEx": "Zaki", "year": 2004}, {"title": "Efficient algorithms for mining closed itemsets and their lattice structure", "author": ["M.J. Zaki", "Hsiao", "C.-J."], "venue": "IEEE Transactions on Knowledge and Data Engineering 17, 4, 462\u2013478.", "citeRegEx": "Zaki et al\\.,? 2005", "shortCiteRegEx": "Zaki et al\\.", "year": 2005}, {"title": "Principles of Data Mining and Knowledge Discovery, Second European Symposium, PKDD \u201998, Nantes, France, September 23-26, 1998, Proceedings", "author": ["J.M. Zytkow", "M. Quafafou", "Eds."], "venue": "Lecture Notes in Computer Science Series, vol. 1510. Springer.", "citeRegEx": "Zytkow et al\\.,? 1998", "shortCiteRegEx": "Zytkow et al\\.", "year": 1998}], "referenceMentions": [{"referenceID": 1, "context": "The introduction of a support threshold parameter was a key advance that allowed for the design of efficient frequent set miners and for the computation of association rules in large datasets: there, exploration is limited to those itemsets that appear \u201coften enough\u201d as subsets of the transactions, that is, their relative frequency exceeds a certain ratio of the transactions; see [Agrawal et al. 1996] and the references there.", "startOffset": 383, "endOffset": 404}, {"referenceID": 1, "context": "The proposal in [Agrawal et al. 1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X \u2192 Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.", "startOffset": 16, "endOffset": 37}, {"referenceID": 26, "context": "1996] (and already in the early [Luxenburger 1991] where, however, the support bound proposal does not appear) is to impose upon association rules X \u2192 Y a confidence constraint, that is, a threshold on the conditional probability of Y conditioned to X.", "startOffset": 32, "endOffset": 50}, {"referenceID": 0, "context": "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B \u03b3 [Balc\u00e1zar 2010c] for closure-based redundancy, at confidence threshold \u03b3, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.", "startOffset": 82, "endOffset": 124}, {"referenceID": 20, "context": "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B \u03b3 [Balc\u00e1zar 2010c] for closure-based redundancy, at confidence threshold \u03b3, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.", "startOffset": 82, "endOffset": 124}, {"referenceID": 6, "context": "This leads to minimum-size bases, such as the Representative (or Essential) Rules [Aggarwal and Yu 2001; Kryszkiewicz 1998b] for plain redundancy or the basis B \u03b3 [Balc\u00e1zar 2010c] for closure-based redundancy, at confidence threshold \u03b3, that spares the computation of minimal generators needed by the Representative Rules, but needs to be complemented with a basis for full implications.", "startOffset": 163, "endOffset": 179}, {"referenceID": 6, "context": "All these questions are thoroughly surveyed in [Balc\u00e1zar 2010c].", "startOffset": 47, "endOffset": 63}, {"referenceID": 15, "context": "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X \u2192 Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.", "startOffset": 475, "endOffset": 535}, {"referenceID": 24, "context": "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X \u2192 Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.", "startOffset": 475, "endOffset": 535}, {"referenceID": 37, "context": "But even taking redundancies into account, the results are, in many cases, unsatisfactory; therefore, many alternative quality measures exist for association rules, essentially due to the facts that, first, the confidence of a rule X \u2192 Y can be high even in cases where the actual correlation between X and Y is negative, and, second, it is often extremely difficult to settle for thresholds where interesting rules are kept but the total amount of rules can be handled; see [Geng and Hamilton 2006; Lenca et al. 2008; Tan et al. 2004] and their references for information about the rich research area opened up by these difficulties.", "startOffset": 475, "endOffset": 535}, {"referenceID": 28, "context": "[Padmanabhan and Tuzhilin 2000] and the references therein).", "startOffset": 0, "endOffset": 31}, {"referenceID": 3, "context": "However, as one very partial and probably insufficient, but necessary action, we claim that, as a minimum, each rule should be evaluated for novelty by comparison with the rest of the rules mined, treated as \u201calternative\u201d mechanism [Balc\u00e1zar 2009].", "startOffset": 232, "endOffset": 247}, {"referenceID": 11, "context": "Otherwise, it would not be novel, the simpler rule should be preferred, and even the complex rule discarded (or blocked), all depending on thresholds on confidence and on some other parameter such as improvement [Bayardo et al. 1999], blocking factor, or confidence boost (to be introduced here).", "startOffset": 212, "endOffset": 233}, {"referenceID": 3, "context": "It was empirically demonstrated in [Balc\u00e1zar 2009] that better results were obtained using both a confidence width threshold and a blocking threshold, than using a single one of these filters (or none).", "startOffset": 35, "endOffset": 50}, {"referenceID": 3, "context": "Thus, our contribution here is a new attempt at formalizing the notion of novelty, the confidence boost, similar in its syntactic definition to confidence width, but different in its semantics, which is more restrictive; its main feature is that it encompasses at once both the bound on the confidence width and the ability to detect that a rule would be blocked, so that the confidence boost bound embodies both of the bounds proposed in [Balc\u00e1zar 2009], yet it is computable with reasonable efficiency.", "startOffset": 439, "endOffset": 454}, {"referenceID": 5, "context": "Three short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balc\u00e1zar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balc\u00e1zar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.", "startOffset": 148, "endOffset": 164}, {"referenceID": 6, "context": "Three short extended abstracts of three, six, and seven pages respectively have announced results from this paper in scientific meetings; reference [Balc\u00e1zar 2010b] contains the definition of confidence boost, fragments of Section 2 (where we also review a small number of necessary facts from [Balc\u00e1zar 2010c]), part of Section 3 (the definition of confidence boost), and the algorithm in Subsection 3.", "startOffset": 294, "endOffset": 310}, {"referenceID": 4, "context": "Reference [Balc\u00e1zar 2010a] contains the definition of closure-based confidence boost and part of the materials in Section 4, again including the main algorithm but not its correctness proof, as well as materials from Subsection 5.", "startOffset": 10, "endOffset": 26}, {"referenceID": 7, "context": "The tool yacaree which embodies closure-based confidence boost into a parameter-free association miner (Section 6) was advertised at [Balc\u00e1zar 2011] (demo track).", "startOffset": 133, "endOffset": 148}, {"referenceID": 1, "context": "In the proposal of [Agrawal et al. 1996], association rules are restricted to |Y | = 1.", "startOffset": 19, "endOffset": 40}, {"referenceID": 12, "context": "[Boulicaut et al. 2003; Zaki 2004] for further information.", "startOffset": 0, "endOffset": 34}, {"referenceID": 41, "context": "[Boulicaut et al. 2003; Zaki 2004] for further information.", "startOffset": 0, "endOffset": 34}, {"referenceID": 26, "context": "In the early proposal [Luxenburger 1991], a rule is redundant if its confidence can be computed from that of other rules.", "startOffset": 22, "endOffset": 40}, {"referenceID": 23, "context": "several concise representations and redundancy notions in [Kryszkiewicz 2002].", "startOffset": 58, "endOffset": 77}, {"referenceID": 29, "context": "In [Pasquier et al. 2005] (and in earlier conference versions of their work) the following set of rules is shown to be sufficient to compute the confidence and support of any given partial rule:", "startOffset": 3, "endOffset": 25}, {"referenceID": 41, "context": "Similar notions of redundancy are studied in [Zaki 2004], where, however, the approximate bases are constructed as rules having minimal generators both at the left- and at the righthand sides.", "startOffset": 45, "endOffset": 56}, {"referenceID": 0, "context": "The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b].", "startOffset": 36, "endOffset": 78}, {"referenceID": 20, "context": "The notions come, essentially, from [Aggarwal and Yu 2001; Kryszkiewicz 1998b].", "startOffset": 36, "endOffset": 78}, {"referenceID": 0, "context": "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.", "startOffset": 209, "endOffset": 268}, {"referenceID": 20, "context": "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.", "startOffset": 209, "endOffset": 268}, {"referenceID": 30, "context": "For a fixed confidence threshold, those rules that reach it, and are not made redundant by other rules also above the threshold, form the representative (or essential) rule basis for that confidence threshold [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001]; that is, every rule that reaches the confidence threshold is either in the corresponding representative basis, or made redundant by a rule in the basis.", "startOffset": 209, "endOffset": 268}, {"referenceID": 0, "context": "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).", "startOffset": 48, "endOffset": 107}, {"referenceID": 20, "context": "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).", "startOffset": 48, "endOffset": 107}, {"referenceID": 30, "context": "4 is easy to see and was already pointed out in [Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001] (in somewhat different terms).", "startOffset": 48, "endOffset": 107}, {"referenceID": 6, "context": "The converse implication is nontrivial and much more recently shown [Balc\u00e1zar 2010c]; see this reference as well for the proof that the representative basis has the minimum possible size among all bases for this notion of redundancy, and for discussions of other related redundancy notions.", "startOffset": 68, "endOffset": 84}, {"referenceID": 19, "context": "The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X \u2192 XY is a representative rule then s(X) < s(X \u2032) for all X \u2032 \u2282 X, and s(Z) < s(XY ) for all Z with XY \u2282 Z; that is, X is a minimal generator and XY is closed.", "startOffset": 40, "endOffset": 60}, {"referenceID": 22, "context": "The implication from (1) to (2) is from [Kryszkiewicz 1998a] (see also [Kryszkiewicz 2001] for a clearer notation): if X \u2192 XY is a representative rule then s(X) < s(X \u2032) for all X \u2032 \u2282 X, and s(Z) < s(XY ) for all Z with XY \u2282 Z; that is, X is a minimal generator and XY is closed.", "startOffset": 71, "endOffset": 90}, {"referenceID": 3, "context": "In [Balc\u00e1zar 2009], the intuition of redundancy is pushed further in order to gain a perspective of novelty of association rules.", "startOffset": 3, "endOffset": 18}, {"referenceID": 3, "context": "It is proved in [Balc\u00e1zar 2009] that, in Definition 2.", "startOffset": 16, "endOffset": 31}, {"referenceID": 3, "context": "In [Balc\u00e1zar 2009], some intuitions are described that suggest that, for a confidence threshold \u03b3, a natural choice could be to set the confidence width threshold at 2\u2212 \u03b3; however, so far no formal support for this proposal (or any other proposal, for that matter) is known.", "startOffset": 3, "endOffset": 18}, {"referenceID": 11, "context": "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 0, "endOffset": 109}, {"referenceID": 25, "context": "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 0, "endOffset": 109}, {"referenceID": 28, "context": "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 0, "endOffset": 109}, {"referenceID": 33, "context": "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 0, "endOffset": 109}, {"referenceID": 38, "context": "[Bayardo et al. 1999; Liu et al. 1999; Padmanabhan and Tuzhilin 2000; Shah et al. 1999; Toivonen et al. 1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 0, "endOffset": 109}, {"referenceID": 3, "context": "1995] just to name a few), [Balc\u00e1zar 2009] proposes also a notion of \u201crule blocking\u201d, whereby a subset of the antecedent may \u201cblock\u201d an association rule, that is, forbid its being provided in the output, if the confidence of the rule with the smaller antecedent and the same consequent is higher enough.", "startOffset": 27, "endOffset": 42}, {"referenceID": 34, "context": "The natural reaction, consisting of a normalization by dividing the confidence by the (normalized) support of the consequent of the rule, gives a parameter that we find in the references going by several different names: it has been called interest [Silverstein et al. 1998] or, in a slightly different but fully equivalent form, strength [Shah et al.", "startOffset": 249, "endOffset": 274}, {"referenceID": 33, "context": "1998] or, in a slightly different but fully equivalent form, strength [Shah et al. 1999]; \u201clift\u201d seems to be catching up as a short name, possibly aided by the fact that the Intelligent Miner system from IBM employed that name.", "startOffset": 70, "endOffset": 88}, {"referenceID": 31, "context": ") The related parameter leverage [Piatetsky-Shapiro 1991] measures essentially the same thing, just that it does so as an additive distance.", "startOffset": 33, "endOffset": 57}, {"referenceID": 3, "context": "We describe a case found in data from real census information, pointed out also in [Balc\u00e1zar 2009].", "startOffset": 83, "endOffset": 98}, {"referenceID": 3, "context": "As an alternative approach to this problem, in [Balc\u00e1zar 2009] the confidence parameter is used in an intuitive way to find a threshold at which a smaller antecedent would suggest to omit a given rule.", "startOffset": 47, "endOffset": 62}, {"referenceID": 3, "context": "Again the specific choice of value for the blocking threshold is justified in [Balc\u00e1zar 2009] just in merely intuitive terms; however, note for later use that the confidence width bound and the blocking threshold are related in that paper as follows: if the confidence width bound is b, then the blocking threshold proposed is b\u2212 1.", "startOffset": 78, "endOffset": 93}, {"referenceID": 22, "context": "We will relate our values of confidence width and of confidence boost to an expression essentially employed first, to our knowledge, in [Kryszkiewicz 2001], where no particular name was assigned to it.", "startOffset": 136, "endOffset": 155}, {"referenceID": 8, "context": "aim of providing a faster algorithm for computing representative rules; it turns out that, as demonstrated in [Balc\u00e1zar and T\u0302\u0131rn\u0103uc\u0103 2011], this approach is efficient and useful in practice but runs into the risk of providing incomplete output, as actual representative rules may be missed.", "startOffset": 110, "endOffset": 139}, {"referenceID": 3, "context": ") We show next that confidence boost embodies exactly both blocking and confidence width, precisely with the same relation between the thresholds as used in [Balc\u00e1zar 2009], under the already stated proviso that all the association rules involved must clear the support threshold.", "startOffset": 157, "endOffset": 172}, {"referenceID": 3, "context": "In this sense, confidence boost embodies both low-novelty tests from [Balc\u00e1zar 2009], and with the same thresholds employed there.", "startOffset": 69, "endOffset": 84}, {"referenceID": 3, "context": "A mild precomputation allows one to compute quite efficiently the width [Balc\u00e1zar 2009], but the same method does not seem to work for blocking or boost.", "startOffset": 72, "endOffset": 87}, {"referenceID": 26, "context": "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.", "startOffset": 0, "endOffset": 51}, {"referenceID": 29, "context": "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.", "startOffset": 0, "endOffset": 51}, {"referenceID": 41, "context": "[Luxenburger 1991; Pasquier et al. 2005; Zaki 2004], suggest to treat separately the implications, which allow for more compact bases, from the partial rules.", "startOffset": 0, "endOffset": 51}, {"referenceID": 6, "context": "In [Balc\u00e1zar 2010c], besides another more complicated alternative, we follow up this suggestion as well, and employ a notion of closure-based redundancy which also turns out to provide a complete basis of provably minimum size, denoted B.", "startOffset": 3, "endOffset": 19}, {"referenceID": 22, "context": "The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balc\u00e1zar and T\u0302\u0131rn\u0103uc\u0103 2011]); instead, the B basis can be computed just from the closures.", "startOffset": 152, "endOffset": 171}, {"referenceID": 8, "context": "The best approaches to the representative rules need to work on the basis of both the closures lattice plus all the minimal generators of each closure ([Kryszkiewicz 2001], but see the related discussion in [Balc\u00e1zar and T\u0302\u0131rn\u0103uc\u0103 2011]); instead, the B basis can be computed just from the closures.", "startOffset": 207, "endOffset": 236}, {"referenceID": 41, "context": "[Zaki 2004]).", "startOffset": 0, "endOffset": 11}, {"referenceID": 6, "context": "Closure-based redundancy [Balc\u00e1zar 2010c] takes into account the closure operator indirectly as follows:", "startOffset": 25, "endOffset": 41}, {"referenceID": 6, "context": "All these definitions are studied in depth in [Balc\u00e1zar 2010c].", "startOffset": 46, "endOffset": 62}, {"referenceID": 29, "context": "3 [Pasquier et al. 2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]).", "startOffset": 2, "endOffset": 24}, {"referenceID": 16, "context": "2005] (a nonminimal basis for the implications of confidence 1, as the GD basis is sometimes smaller [Guigues and Duquenne 1986]).", "startOffset": 101, "endOffset": 128}, {"referenceID": 13, "context": "fi/); and dataset Now (based on the Neogene of the Old World dataset, public release 030710 [Fortelius 2003]) is a transactional version of a paleontological dataset from Europe: we downloaded and preprocessed slightly file NOW public 030710.", "startOffset": 92, "endOffset": 108}, {"referenceID": 14, "context": "Here, however, instead of looking for experts on a given dataset, we use a dataset for which some readers of this paper might be expected to be reasonably knowledgeable: in the same vein as the evaluations in [Gallo et al. 2007], we employ the titles, topics, and abstracts of all the reports submitted to the e-prints repository of the Pascal Network of Excellence along its early years of existence.", "startOffset": 209, "endOffset": 228}, {"referenceID": 16, "context": "By way of comparison, at the same level of support, at the most demanding possible level of confidence (100%), with the less redundant basis computation currently known (the Guigues-Duquenne basis, [Guigues and Duquenne 1986]), the result is 44 rules, with considerably more \u201cintuitive redundancy\u201d and less interest overall, and requires somewhat longer time to be computed.", "startOffset": 198, "endOffset": 225}, {"referenceID": 40, "context": "This idea is reminiscent of the decreasing support in the version of \u201capriori\u201d implemented in the Weka tool [Witten and Frank 2005], but in that well-known system the user still has to provide a maximum and a minimum values to try the support threshold, and a \u201cdelta\u201d by which the support keeps decreasing; then, the \u201capriori\u201d algorithm is run repeatedly for the corresponding sequence of support thresholds.", "startOffset": 108, "endOffset": 131}, {"referenceID": 32, "context": "The \u201cpredictive apriori\u201d alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence.", "startOffset": 67, "endOffset": 105}, {"referenceID": 40, "context": "The \u201cpredictive apriori\u201d alternative, present in that tool as well [Scheffer 2005; Witten and Frank 2005], also attempts at adjusting the support, by balancing it with respect to confidence.", "startOffset": 67, "endOffset": 105}, {"referenceID": 2, "context": "The lattice constructor itself is based on [Baixeries et al. 2009] and works also as an iterator, constructing Hasse edges only when they are needed.", "startOffset": 43, "endOffset": 66}, {"referenceID": 13, "context": "net/projects/yacaree/; these example datasets are already preprocessed into transactional form, and come from [Asuncion and Newman 2007] or [Fortelius 2003], or from the e-prints repository of the Pascal Network of Excellence.", "startOffset": 140, "endOffset": 156}, {"referenceID": 27, "context": "This does not mean that it has to be replaced as a measure of intensity of implication, and, in fact, it has been observed and argued that (at least in somewhat sparse transactional datasets) the combination of support and confidence is already very good at discarding rules that are present only as statistical artifacts and do not really correspond to correlations in the phenomenon at the origin of the dataset [Megiddo and Srikant 1998]; instead, we consider that our message is that it should be complemented with relative confidence thresholds that assess the novelty of each rule by comparison with the confidence of logically (or intuitively) stronger rules.", "startOffset": 414, "endOffset": 440}, {"referenceID": 15, "context": "We refer to [Geng and Hamilton 2006] for an excellent survey of many options to relate supports of left and right hand sides of association rules to construct indicators of interestingness.", "startOffset": 12, "endOffset": 36}, {"referenceID": 17, "context": "More sophisticated interestingness measures are possible, for instance those based on the KL-divergence between probability distributions induced with and without the given rule [Jaroszewicz and Simovici 2002]: the induced distributions satisfy the supports of the rule and of its antecedent but otherwise maximize the entropy.", "startOffset": 178, "endOffset": 209}, {"referenceID": 17, "context": "2) gives results very close to those in [Jaroszewicz and Simovici 2002].", "startOffset": 40, "endOffset": 71}, {"referenceID": 28, "context": "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V \u2032 for V \u2032 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.", "startOffset": 238, "endOffset": 309}, {"referenceID": 35, "context": "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V \u2032 for V \u2032 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.", "startOffset": 238, "endOffset": 309}, {"referenceID": 36, "context": "useful to explain novelty by comparing more specific rules stating a consequent of the form A = V to more general rules stating a consequent of the form A = V \u2032 for V \u2032 6= V , and quite interesting results along this line can be found in [Padmanabhan and Tuzhilin 2000; Suzuki 1997; Suzuki and Kodratoff 1998], among others.", "startOffset": 238, "endOffset": 309}, {"referenceID": 3, "context": "The notions of confidence width and rule blocking from [Balc\u00e1zar 2009] are similar to the \u201cpruning\u201d proposal from [Liu et al.", "startOffset": 55, "endOffset": 70}, {"referenceID": 25, "context": "The notions of confidence width and rule blocking from [Balc\u00e1zar 2009] are similar to the \u201cpruning\u201d proposal from [Liu et al. 1999], in that the intuition is the same; also our proposal here follows an analogous intuitive path.", "startOffset": 114, "endOffset": 131}, {"referenceID": 25, "context": "Major differences are that, in the proposals we discuss, a large portion of the pruning becomes unnecessary because we work on minimum-size bases, namely representative rules, and, more importantly, that the pruning in [Liu et al. 1999] is based on the \u03c7 statistic, whereas we will look instead into the confidence thresholds that would make the rule \u201credundant\u201d, either in a \u201cformal logic\u201d sense or in a more intuitive, but still logical-style relaxation.", "startOffset": 219, "endOffset": 236}, {"referenceID": 11, "context": "Our notions are also similar to the notion of improvement, proposed in [Bayardo et al. 1999] and also discussed in [Liu et al.", "startOffset": 71, "endOffset": 92}, {"referenceID": 25, "context": "1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent.", "startOffset": 28, "endOffset": 56}, {"referenceID": 39, "context": "1999] and also discussed in [Liu et al. 1999; Webb 2007]; but improvement is a measure of an absolute, additive confidence increase, with no reference to representative rules or redundancy, and it only allows for varying the antecedent into a smaller one, keeping the same consequent.", "startOffset": 28, "endOffset": 56}, {"referenceID": 0, "context": "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).", "startOffset": 0, "endOffset": 77}, {"referenceID": 20, "context": "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).", "startOffset": 0, "endOffset": 77}, {"referenceID": 30, "context": "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).", "startOffset": 0, "endOffset": 77}, {"referenceID": 33, "context": "[Aggarwal and Yu 2001; Kryszkiewicz 1998b; Phan-Luong 2001; Shah et al. 1999]).", "startOffset": 0, "endOffset": 77}, {"referenceID": 38, "context": "This happens in the structural cover of [Toivonen et al. 1995], and in some of the pruning rules of [Shah et al.", "startOffset": 40, "endOffset": 62}, {"referenceID": 33, "context": "1995], and in some of the pruning rules of [Shah et al. 1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005].", "startOffset": 43, "endOffset": 61}, {"referenceID": 32, "context": "1999] (which focuses on a slightly different approach since their main measure is actually lift, but, in fact, most of their developments work for confidence as well); and also in [Scheffer 2005].", "startOffset": 180, "endOffset": 195}, {"referenceID": 32, "context": "All these proposals may make sense as heuristics, and their connection to confidence boost is developed below; however, if taken as redundancy statements then they are incorrect and, in some cases, where a precise mathematical statement and its proof are provided (like [Scheffer 2005]), the proof can be seen to switch into a \u201cfull implication\u201d meaning of the \u201carrow\u201d connective, and is actually wrong, therefore, since it does not apply to partial rules.", "startOffset": 270, "endOffset": 285}, {"referenceID": 21, "context": "As a representative of these proposals, we chose to discuss the approach of [Kryszkiewicz 1998c] which can be casted as follows:", "startOffset": 76, "endOffset": 96}, {"referenceID": 21, "context": "The following holds [Kryszkiewicz 1998c]:", "startOffset": 20, "endOffset": 40}, {"referenceID": 29, "context": "Let us point out that these rules are subtly different from the min-max approximate basis of [Pasquier et al. 2005], given in Definition 2.", "startOffset": 93, "endOffset": 115}, {"referenceID": 2, "context": "First, since we mine frequent closures in descending support, instead of ascending, some of the optimizations in ChARM require further work before being readily applicable; also, the best algorithm in [Baixeries et al. 2009] (namely iPred) to compute Hasse edges is not applied, as it assumes a cardinality-ordered traversal of the closed sets instead of a support-oriented one; the theorems that guarantee its applicability have been obtained only recently, and a forthcoming version of yacaree will sport this faster algorithm, iPred.", "startOffset": 201, "endOffset": 224}], "year": 2013, "abstractText": "Some existing notions of redundancy among association rules allow for a logical-style characterization and lead to irredundant bases of absolutely minimum size. One can push the intuition of redundancy further and find an intuitive notion of interest of an association rule, in terms of its \u201cnovelty\u201d with respect to other rules. Namely: an irredundant rule is so because its confidence is higher than what the rest of the rules would suggest; then, one can ask: how much higher? We propose to measure such a sort of \u201cnovelty\u201d through the confidence boost of a rule, which encompasses two previous similar notions (confidence width and rule blocking, of which the latter is closely related to the earlier measure \u201cimprovement\u201d). Acting as a complement to confidence and support, the confidence boost helps to obtain small and crisp sets of mined association rules, and solves the well-known problem that, in certain cases, rules of negative correlation may pass the confidence bound. We analyze the properties of two versions of the notion of confidence boost, one of them a natural generalization of the other. We develop efficient algorithmics to filter rules according to their confidence boost, compare the concept to some similar notions in the bibliography, and describe the results of some experimentation employing the new notions on standard benchmark datasets. We describe an open-source association mining tool that embodies one of our variants of confidence boost in such a way that the data mining process does not require the user to select any value for any parameter.", "creator": "TeX"}}}