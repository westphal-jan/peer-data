{"id": "1104.0843", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2011", "title": "Phase Transitions in Knowledge Compilation: an Experimental Study", "abstract": "phase transitions involved in many complex combinational compilation problems have been widely studied since in the past decade. in this paper, we investigate phase transitions in the knowledge compilation empirically, where dfa, obdd _ and d - dnnf are chosen as the target languages to compile random or k - sat instances and industrial - like sat instances. we perform intensive statistical experiments sufficient to analyze simply the sizes of compilation results and draw the following conclusions : there exists an easy - hard - easy correlation pattern in compilations ; the peak point of sizes reflected in the pattern is only related to the ratio exponential of the reduced number of clauses to doubling that of variables when k is apparently fixed, necessarily regardless of target languages ; most sizes of compilation results increase exponentially with the number of variables actually growing, but surprisingly there also exists a phase transition that formally separates a polynomial - biased increment region from the exponential - increment region ; moreover, we explain why the phase transition in compilations occurs by easily analyzing microstructures of dfas, and conclude that a kind of solution interchangeability with more than 2 variables has a sharp transition near the peak point time of the easy - work hard - easy pattern, and thus it has great impact on the sizes of common dfas.", "histories": [["v1", "Tue, 5 Apr 2011 13:25:43 GMT  (582kb)", "http://arxiv.org/abs/1104.0843v1", null], ["v2", "Sun, 17 Apr 2011 12:41:23 GMT  (582kb)", "http://arxiv.org/abs/1104.0843v2", null], ["v3", "Fri, 3 Jun 2011 07:05:11 GMT  (201kb)", "http://arxiv.org/abs/1104.0843v3", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jian gao", "minghao yin", "ke xu"], "accepted": false, "id": "1104.0843"}, "pdf": {"name": "1104.0843.pdf", "metadata": {"source": "CRF", "title": "Phase Transitions in Knowledge Compilation: an Experimental Study", "authors": ["Jian Gao", "Minghao Yin", "Ke Xu"], "emails": ["jiangao.cn@hotmail.com;", "ymh@nenu.edu.cn", "kexu@nlsde.buaa.edu.cn"], "sections": [{"heading": null, "text": "the past decade. In this paper, we investigate phase transitions in the knowledge compilation\nempirically, where DFA, OBDD and d-DNNF are chosen as the target languages to compile\nrandom k-SAT instances and industrial-like SAT instances. We perform intensive experiments to\nanalyze the sizes of compilation results and draw the following conclusions: there exists an\neasy-hard-easy pattern in compilations; the peak point of sizes in the pattern is only related to the\nratio of the number of clauses to that of variables when k is fixed, regardless of target languages;\nmost sizes of compilation results increase exponentially with the number of variables growing, but\nthere also exists a phase transition that separates a polynomial-increment region from the\nexponential-increment region; Moreover, we explain why the phase transition in compilations\noccurs by analyzing microstructures of DFAs, and conclude that a kind of solution\ninterchangeability with more than 2 variables has a sharp transition near the peak point of the\neasy-hard-easy pattern, and thus it has great impact on the sizes of DFAs.\nKeywords: Phase transition; Knowledge compilation; Random k-SAT; Solution interchangeability"}, {"heading": "Introduction", "text": "Phase transitions, as a kind of well-known phenomenon in artificial intelligence, have attracted a great mount of attention since the paper [1]. They claimed that all NP-complete problems have a critical point that separates overconstrained and underconstrained regions, and soluble-to-insoluble phase transition occurs at this point. Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8]. Some representative problems are random k-SAT, whose phase transition point is measured by the ratio of the number of clauses to that of variables, and random Constraint Satisfaction Problems (CSPs), where in the RB model [2] an exact transition point was proved whose instances are hard to solve. Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8]. In addition, some real-world problems, such as TSP [9] and manipulation problem [10], have been shown to have phase transition phenomena. In fact, it is worth mentioning that soluble-to-insoluble phase transition studied most widely is only one\nan example Bailey et al. [11] have addressed phase transitions in #SAT, of which the decision problem is PP-complete. As second example phase transitions of backtrack-free instances have been studied [12].\nThe phase transitions mentioned above are always accompanied with the transitions of CPU\nruntimes. Namely, algorithms will suffer an easy-hard-easy pattern when solving those problems. Instances around the soluble-to-insoluble transition points are hard to solve by both systematic search algorithms and local search algorithms with other instances easy to solve. However, we will show that easy-hard-easy patterns are not only expressed in terms of the time, but also in terms of the space. That is phase transitions in knowledge compilation. Knowledge compilation [13] is used to compile all (or a part of) the solutions of a problem into a tractable language, and has been employed in many areas ranging from planning, diagnosis to formal verification and production configuration. In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18]. A knowledge compilation map [19] has been presented to analyze the succinctness of the target compilation languages, as well as identify tractable queries of them. Though many papers in this direction have been published, they have focused mostly on succinctness and tractable queries with very little attention on the easy-hard-easy pattern in compilation results, which has strong relationship with difficulty of problems.\nThis paper focuses attention on the space phase transitions, and studies the easy-hard-easy\npattern in knowledge compilation empirically. We concentrate on randomly generated k-SAT model, and discuss the phase transition phenomena that occur in compiling random SAT instances generated by different values of parameters into three target languages, i.e., OBDD, d-DNNF and DFA: OBDD is a kind of binary decision diagram with a fixed variable ordering; d-DNNF is a subset of Negation Normal Form (NNF) that satisfies determinism and decomposability; DFA can be viewed as a special case of the OBDD, whose structures are more regular. Unlike horn clauses, they are complete as target languages. Moreover, they can compile large scale instances, and are more popular than other target languages in the knowledge compilation map mentioned above. We exhibit experimental results on compiling k-SAT instances into OBDD and d-DNNF respectively showing that these two languages suffer the easy-hard-easy pattern, where sizes of compilation results increase as the ratio of clauses to variables grows from 0 but decrease when the ratio exceeds a certain point. Hence, the phase transition occurs. We also observe a phase transition of polynomial-exponential increment of sizes when compiling instances with very small ratio of clauses to variables. Furthermore, we show similar phase transitions in the industrial-like SAT instances. Besides, we analyze the structural transition of DFAs empirically to show the reason why the easy-hard-easy pattern occurs. The experimental analysis shows that a sharp transition on the existence of a kind of paths, which we call multi-interchangeable paths, occurs around peak points of the easy-hard-easy pattern.\nIt is well-known that k-SAT is NP-complete for k>2. Many academic and real-world problems can be transformed into k-SAT and solved by the efficient SAT solvers. So designing search algorithms to solve SAT problems efficiently is an essential issue in AI. To evaluate SAT algorithms, Mitchell et al. [20] introduced a model for generating random SAT instances, which can produce hard instances as it was claimed. Compared with SAT instances from industrial area, this model can obtain large amount of instances whose size and difficulty can be controlled by parameters. As a result, it has become a canonical benchmark to test various SAT algorithms. Meanwhile, theoretical analyses on the random k-SAT model have been made [3], for example, the properties of phase transitions have been identified that are widely used to analyze average computational complexity.\nIn the model discussed in [20], there are 3 parameters k, n, m that are employed to generate\nSAT instances, where k is the length of clauses, n is the number of variables, and m is the number of clauses. We use a ratio r to represent m/n. Instances are produced by generating m clauses uniformly and independently, where each clause is generated by selecting k variables without replacement from n variables and negating each variable with probability 0.5. All clauses generated are of the same length. However, those random SAT instances are different from industrial instances in nature, because industrial instances usually have special structures. In order to generate industrial-like SAT instances, Ans\u00f3tegui et al. [21] proposed some models that can produce random instances similar to industrial instances. We introduce one of these models, denoted by the powerlaw model. It generates variables with a powerlaw distribution rather than uniform manner, because they observed that the occurrences of variables in industrial instances are not uniform and about 90% variables occur less than the average. P(i)=Ci -\u03b2 is the probability distribution of variables, where the parameter \u03b2 controls the power in the model and C is a constant. It was also concluded that when the parameter \u03b2 in that model is set to 0.82, instances generated are similar to industrial instances (For more details, we refer to [21]).\nEmpirical and theoretical studies have demonstrated that there are easy-hard-easy patterns\nwhen solving the random k-SAT instances. Lots of experiments have shown that the soluble-to-insoluble phase transition will occur when r is up to a fixed value, for example, r is about 4.3 in 3-SAT [20], and mean runtimes for finding a solution by SAT algorithms are often extremely high for solving instances in the phase transition region. As r increases from 0, mean runtimes increase first but decrease when r is larger than the value at the transition point. However, it seems to be difficult to locate transition points of k-SAT by theoretical proof, as only lower and upper bounds have been found for the points [3]. For the powerlaw model, phase transition phenomenon was also observed, where its point may occur with a smaller r compared with standard random k-SAT model as reported in [21], the soluble-to-insoluble transition point is about 2.5 when k is set to 3 and \u03b2 is 0.82. Similar phenomenon also exists in #SAT [11], which is a counting problem. In the general case, #SAT is #P-complete, which is considered to be harder than NP-complete. Algorithms for solving this problem count the number of solutions in the given SAT instance. Mean runtimes of several #SAT solvers have been investigated, and the results show that those solvers also suffer the easy-hard-easy pattern, but the hardest regions of those #SAT algorithms are different. For instance, it was reported that an algorithm, called Counting Davis-Putnam [22], reaches its peak runtime when r=1.2 on the experiments of #3-SAT, while the peak point of another algorithm, called Decomposing Davis-Putnam [23], occurs when r=1.5.\neasy-hard-easy pattern."}, {"heading": "Basic Conjecture", "text": "Let nr kP be a random k-SAT instance generated with n variables and rn clauses, and let ( ) nr L kX P be\nthe size of the compilation result, where L is the target language to which nr kP is compiled (we regard\nthe number of nodes as the size, when L is OBDD or d-DNNF). Definition 1. Given n, r, k and a target language L, average size ( ( ))nrL kE X P is defined as follows:\n( ( )) ( ( )) | |nr nr nrL k L k kE X P X P P \nwhere nr kP is any problem in the set made up of all possible instances that can be generated by the\nrandom SAT model with parameters n, rn, k, and | |nrkP is the number of all possible instances. Because the structures of the target languages are very complex, it seems hard to analyze average\nbehaviors (i.e. ( ( ))nrL kE X P ) of them theoretically. However, the following conjecture seems\navailable, as it can be supported by a number of experiments. Conjecture 1. For every integer 3k  , given the number of variables n and a target language L that is a subset of NNF, there exists a positive real number rc such that For each pair (r1,r2), if r1<r2<rc, then 1 2( ( )) ( ( )) nr nr\nL k L kE X P E X P .\nFor each pair (r1,r2), if rc<r1<r2<rp, then 1 2( ( )) ( ( )) nr nr\nL k L kE X P E X P .\nwhere rp is the soluble-to-insoluble phase transition point of k-SAT. The conjecture describes that when r ranges from 0 to rp, the sizes of compilation results increase until r reaches rc and then decrease.\nExperimental Results on Random k-SAT\nIn this section, we analyze phase transitions in random k-SAT compilation using OBDD and d-DNNF as target languages. The compilers we choose for the target languages are the state-of-the-art compilers, where d-DNNF compiler was made by Darwiche (It is available at: http://reasoning.cs.ucla.edu/c2d/) and the OBDD compiler based on CUDD package was developed by Narodytska and Walsh for their work of constraint and variable ordering heuristics for compiling configuration problems [14]. According to the knowledge compilation map, all the languages in the map are subsets of NNFs. Because NNFs can be described by directed acyclic graphs, we can represent OBDD and d-DNNF using directed acyclic graphs, of which the sizes are measured by the number of its nodes and edges. However, it can be observed that the number of nodes and the number of edges change in the same manner when we compile k-SAT instances ranging r from 0 to rp, and the peak points are also in the same position. Since we only care about the changing manner and the points of maximum sizes, with the fact discussed above, we count\nto evaluate the size of d-DNNF.\nIn the following experiments, we generate SAT instances using random k-SAT model and\ncompile them into OBDDs and d-DNNFs respectively. For each combination of k and n, we vary r from 0 to the corresponding rp (relative to k). To obtain more exact results, we produce 1000 instances for each r, and calculate average nodes of the compilation results. Because of runtime limitations, we only take k ranging from 2 to 6 and n ranging from 20 to 60."}, {"heading": "Experiments on Random 3-SAT", "text": "The first set of experimental results concerns random 3-SAT instances. Fig. 1 depicts the easy-hard-easy pattern when compiling instances into d-DNNFs. We also locate the phase transition point in random 3-SAT compilations. There are 3 curves in Fig. 1, each of which corresponding to a different n ranging from 40 to 60. The peak points of those curves are with same value of the ratio r, which is 1.8. This point is far from the soluble-to-insoluble transition point where r is about 4.3.\nFig. 2 describes the experimental results of OBDDs. Three groups of instances have been\ngenerated for the OBDD experiments too. But there is a small difference in the generation parameters with n varying from 20 to 40, since the OBDD compiler needs more time to finish the experiments. Note that the curves of OBDDs have the same behaviors as curves in Fig. 1. Especially, the peak sizes occur at the same point where r is 1.8.\nInterestingly, we exhibit that when r (r>0.3 for 3-SAT) is fixed, the sizes of target languages\n0 and rp uniformly. For each r, we generate 1000 3-SAT instances varying n from 10 to 60 at increments of 5, and convert them into d-DNNFs. Compilation results are shown in Fig. 3. Curves with different values of r are all nearly linear when the logarithmic vertical axis is used, so we believe that the size grows exponentially in the general cases. However, the slope of each curve depends on r. When r is close to 1.8, the slope grows larger, and the curve of r=1.8 has the biggest slope among the 6 curves. As a result, though the average sizes increase exponentially, the sizes around phase transition regions grow fastest.\nWe also observe that there is another phase transition in compilation. That is, the sizes\nincrease from polynomially to exponentially as r grows. Fig. 4 shows this transition, where double logarithmic axes are employed to identify the polynomial increment-to-exponential increment. It is clear to see that the sizes for 3-SAT increase polynomially when r<0.3 as the curves are nearly linear, while exponentially when r>0.3. So we believe that there is a phase transition separates the polynomial and exponential sizes. It is quite similar to the classical phase transition, where the phase transition in structures of solutions separates the tractable and intractable regions [12].\nExperiments on Random k-SAT\nWe then show that phase transitions also exist in compiling k-SAT. Experimental results on k-SAT instances are depicted in Fig. 5. We generate instances by fixing n to 20, varying k from 2 to 6 and r from 0 to the corresponding rp. Each curve in Fig. 5 (a) corresponds to a different value\nwhere the peak points are relative to k. Fig. 5 (b) exhibits the compilation results on OBDDs, where the same behaviors can be obtained as those on d-DNNFs, too. Besides, curves in the two figures demonstrate that rc/rp becomes smaller as k increases.\nWe close this section by arguing that not only the size of compilation results undergoes the\neasy-hard-easy pattern, but also the runtime cost in compilations does, In [16], similar experimental results on d-DNNF for compiling 3-SAT instances have been depicted, where the peak point of runtimes is also fixed at r=1.8. As a result, it is hard to compile instances near the phase transition region but quite easier for other instances, including those hard to find a solution."}, {"heading": "Experimental Results on Industrial-Like SAT", "text": "In order to evaluate a target language, industrial instances are usually employed, such as configuration problems and instances in SATLIB. In this section, we study the phase transition of knowledge compilation in industrial-like instances. The easy-hard-easy pattern in those instances is shown and a comparison is made between random instances and industrial-like instances.\n4"}, {"heading": "Experiments on Industrial-like SAT", "text": "This subsection exhibits phase transitions and locates the phase transition point in instances generated by the powerlaw model when k is 3. To obtain more exact transition point of knowledge compilation, larger instances are compiled, where n is set to 100, 110 and 120, because it seems that instances over the soluble-to-insoluble transition point are usually soluble when n is too small. We only compile these instances into d-DNNFs, since the results of OBDDs have the same behaviors. As shown in Fig. 6, the compilation results of industrial-like 3-SAT also undergo the easy-hard-easy pattern, where the ratio at the peak points is about 1.4. It is a little smaller than that of random 3-SAT instances. Hence, the position of the peak points is consistent\nwith \u03b2 increasing from 0, reported in [21]."}, {"heading": "Comparison of Random SAT and Industrial-like SAT", "text": "We compare the compilation results of 3-SAT instances generated by the standard random model and the powerlaw model. For each model, 9 groups of instances are produced, each of which has a fixed n with r varying from 0 to 4.3 at increments of 0.1, then compiled into d-DNNFs. Next, we select the peak values of each group. Results are shown in Fig. 7, where logarithmic axis is also used. There are two curves representing the peak values of standard random model and powerlaw model respectively. From them we can see that the sizes representing industrial-like instances grow more slowly than these representing random instances. Though they both grow exponentially, compiling an industrial-like instance generated by the powerlaw model is easier than compiling a random instance with the same number of variables and clauses."}, {"heading": "Phase Transition Analysis on DFAs", "text": "In this section, we focus on the structure of DFA to explain why the easy-hard-easy pattern occurs. DFA can also be used as a target language. In the early study, DFA was used to solve CSPs by Vempary [24]. Amilhastre et al. [17] compiled configuration problems into DFAs. Such a DFA is a directed graph, its edges (the transitions of the automaton) are labeled by an assignment <xi,ai>,\nwhich means ai is assigned to xi. Nodes of DFAs are called states; the root of the graph is called the initial state. States in the graph are divided into subsets (levels), where the initial state composes level 0; labels of transitions coming from states in the same subset have the same variable but may have different values. Paths from the initial state to a final state are of the same length. Such a path represents a solution of the SAT (or CSP) instance. It is known that the DFA is a special form of the BDD, but the structure of DFAs is more regular than that of OBDDs. Because of the regular structure, we choose it to analyze the reason why the easy-hard-easy pattern occurs by studying its microstructure.\nEach clause in a SAT instance is a disjunction of literals, where a literal is either a variable or\nthe negation of a variable. We often denote a clause with k length by 1m x \u2026 jm x  1jm x \n\u2026 km x in this section. The adjoint nogood of the clause is the partial assignment\n( 1 ,0mx  ,.., ,0 jm x  ,\n1 ,1 jm x    ,\u2026, ,1 km x  ). A path is compatible with a partial assignment if\nall pairs of <xi,ai> in the partial assignment occur in some labels of the path. Adding a clause to a DFA means that paths compatible with its adjoint nogood are removed. An edge e is an adjoint edge of a path if the edge is not in the path, and there exists an edge e\u2019 in the path such that e\u2019 and e come from a common state and point to a common state. A path is an i-interchangeable path of a clause l if there exist only i adjoint edges whose variables (all variables are different) contained in the adjoint nogood of the clause and the path is compatible with the nogood. A path without such an adjoint edge is regard as a 0-interchangeable path of the clause. A 1-interchangeable path is called a single interchangeable path, whereas multi-interchangeable paths are i-interchangeable paths such that i>1."}, {"heading": "Microstructure Analysis", "text": "When a clause is conjoined to a DFA, paths compatible with the adjoint nogood of the clause have to be removed from the DFA. Consider a single path in a DFA that will be removed, 3 cases have to be investigated. If the path is a 0-interchangeable path of the clause, the size of the DFA probably decreases, because some nodes in the path should be deleted and no extra nodes are added. Fig. 8(a) shows an example of this procedure. If the path is a single-interchangeable path, the size of the DFA changes very slightly, because the nodes of the path always remain (Fig. 8(b)). If the path is a multi-interchangeable path, the size of the DFA usually increases, because the path has more than one adjoint edge. To remove the path, other paths containing adjoint edges should be separated from the removed path so that extra nodes are required. Fig. 8(c) shows an example of this procedure.\nWe only show some simple cases, while there may be more than one path compatible with\nadjoint nogood of a clause. Besides, it is known that dynamic variable ordering on BDDs or DFAs has a great impact on the sizes, but analyzing on the DFA sizes under those situations is extremely complex, so we only consider basic cases in the microstructure analysis.\nBecause of the structural complexity, we first require some approximate suppositions. We\nsuppose that the size will increase when adding a clause that has one or more multi-interchangeable paths, and a DFA is in the easy-hard phase if more than half of clauses\nexperiment is performed. We generate SAT instances with k=3 and n=25. For each r from 0 to its rp (4.3), 100 instances are generated. For each instance, we construct the DFA, and then generate 100 clauses randomly and uniformly. The number of clauses that have multi-interchangeable paths is counted. If the number is larger than 50, we regard that the instance is in the easy-hard phase. Fig. 9(a) shows the results, where the curve with circle nodes depicts the number of instances in the easy-hard phase for each r, and the curve without nodes shows the average number of DFA nodes. Similar experiments are also performed with parameter k=4 and n=18, k=5 and n=15, k=7 and n=12 respectively. Fig. 9(b) (c) and (d) depict the results.\nFrom those figures, we can observe that the number of instances have a sharp transition from\nthe increment phase to the decrement phase. It is also worth to mention that the areas of the sharp transition are very close to the peak points of the easy-hard-easy pattern, though they are not very\nfactor that makes the DFA sizes suffer an easy-hard-easy pattern is the existence of multi-interchangeable paths. Because of separations on the multi-interchangeable paths when adding clauses to a DFA, more states have to be constructed for the resultant DFAs. Besides, it is noted that the peak points are compatible with the results of the OBDD and d-DNNF.\nSolution Interchangeability\nWe then discuss the relationships between the multi-interchangeable paths and the solution interchangeability. Solution interchangeability of CSPs has been studied for decades. Freuder [25] investigated the interchangeability deeply, where various forms of interchangeability were proposed. According to his definitions, two values a, b for a variable x are fully interchangeable if every solution to the CSP containing the assignment <x, a> remains a solution when b is substituted for a, and vice versa. Here we extend the solution interchangeability by the following definitions: a SAT instance with n variables is fully multi-interchangeable if there exists more than one variable such that values 0 and 1 are interchangeable for every solution; a partial assignment is weak interchangeable if it can be extended to a solution by assigning any value (0 or 1) to each unsigned variable; a partial assignment is weak multi-interchangeable if it is weak interchangeable and its length is no more than n-2 (n is the total number of variables in an instance).\nClearly, a multi-interchangeable path implies that there must exist at least one\nmulti-interchangeable partial assignment, but a multi-interchangeable partial assignment does not mean there exists a multi-interchangeable path. That is, the definition of the multi-interchangeable path is more rigorous than that of the weak multi-interchangeable partial assignment. On the other hand, it can be seen that the definition of the multi-interchangeable path is looser than that of fully multi-interchangeable SAT instance. So the multi-interchangeable path is a more complex form of solution interchangeability between full and weak solution interchangeability.\nIn fact, when we use OBDD, d-DNNF and DFA as the target languages, the key technique\nduring the compilation is to convert solutions into a compact form. Because of the compaction, compilation results can be reduced to reasonable sizes for on-line processing. The compaction can reduce the representation of symmetric solutions by incorporating some common parts of these solutions. So the interchangeable structure of solutions determines the effectiveness of the compaction, and thus the transition of the solution interchangeability mentioned above causes the sizes of compilation results suffering the easy-hard-easy pattern."}, {"heading": "Conclusions", "text": "Our work concerns the phase transition in knowledge compilation of k-SAT, which is accompanied with an easy-hard-easy pattern on the space rather than the runtimes. We first conjectured that the ratios of clauses to variables in the random SAT model have great impact on the sizes of compilation results, where an easy-hard-easy pattern exists similar with many phase transition phenomena. DFAs, OBDDs and d-DNNFs, which are commonly employed to compile real-world problems off-line, have been chosen as the target languages for compilation. Experimental results on randomly generated k-SAT have been demonstrated in a number of figures, by which the conjecture has been supported. Interestingly, we suggested curves of average\ncan also be concluded that the sizes for 3-SAT increase exponentially as n grows when r>0.3, whereas the sizes increase polynomially when r<0.3. Hence, there exists another phase transition that separates the regions of polynomial and exponential sizes. We also exhibit that there are phase transitions in the industrial-like model Furthermore, we try to explain the reason that the existence of the easy-hard-easy pattern. From approximate analyses on the structures of DFAs, we concluded that paths with more than one adjoint edge have great impact on the sizes of DFAs, and these paths imply a kind of solution interchangeability in the SAT instances. As it seems difficult to conduct an exact evaluation on the relationships between solution interchangeability and the easy-hard-easy pattern in knowledge compilation, further works are required to uncover more inherent relations.\nAcknowledgements. We would like to thank Nina Narodytska for her BDD compiler. The work described in this paper was supported by the National Natural Science Foundation of China Granted No. 60803102 and 60973033."}], "references": [{"title": "Where the Really Hard Problems Are", "author": ["P. Cheeseman", "B. Kanefsky", "M. Taylor W."], "venue": "proc. IJCAI\u201991, pp. 331--340. Morgan Kaufmann Publishers, Inc.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1991}, {"title": "Exact Phase Transitions in Random Constraint Satisfaction Problems", "author": ["K. Xu", "W. Li"], "venue": "J. Artif. Intell. Res. 12, 93--103", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2000}, {"title": "Rigorous location of phase transitions in hard optimization problems", "author": ["D. Achlioptas", "A. Naor", "Y. Peres"], "venue": "Nature 435, 759--764", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Phase Transition Behavior: from Decision to Optimization, In: proc", "author": ["J. Slaney", "T. Walsh"], "venue": "SAT\u201902,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Beyond NP: the QSAT phase transition", "author": ["P. Gent I.", "T. Walsh"], "venue": "proc. AAAI/IAAI\u201999, pp. 648--653. AAAI Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "New Results on the Phase Transition for Random Quantified Boolean Formulas", "author": ["N. Creignou", "H. Daud\u00e9", "U. Egly", "R. Rossignol"], "venue": "proc. SAT\u201908, LNCS, vol. 4996, pp.34--47. Springer, Heidelberg", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Phase Transitions in Classical Planning: An Experimental Study", "author": ["J Rintanen"], "venue": "In proc. ICAPS\u201904, pp. 101--110", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Phase Transitions of EXPSPACE-Complete Problems", "author": ["J. Zhou", "P. Huang", "C. Yin M.: Zhou"], "venue": "Int. J. Found. Comput. Sci", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "The TSP Phase Transition", "author": ["P. Gent I.", "T. Walsh"], "venue": "Artif. Intell. 88, 349--358", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1996}, {"title": "Where Are the Really Hard Manipulation Problems? The Phase Transition in Manipulating the Veto Rule", "author": ["T. Walsh"], "venue": "proc. IJCAI\u201909, pp. 324--329. Morgan Kaufmann Publishers, Inc.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Phase Transitions of PP-Complete Satisfiability Problems", "author": ["D. Bailey D.", "V. Dalmau", "G. Kolaitis P."], "venue": "proc. IJCAI\u201901, pp. 183--192. Morgan Kaufmann Publishers, Inc.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Exact phase transition of backtrack-free search with implications on the power of greedy algorithms", "author": ["L. Li", "T. Liu", "K. Xu"], "venue": "arXiv:0811.3055", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "A survey on knowledge compilation", "author": ["M. Cadoli", "F. Donini"], "venue": "AI Communications 10, 137--150", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "Constraint and Variable Ordering Heuristics for Compiling Configuration Problems", "author": ["N. Narodytska", "T. Walsh"], "venue": "proc. IJCAI\u201907, pp. 149--154. Morgan Kaufmann Publishers, Inc.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Knowledge Compilation and Theory Approximation", "author": ["B. Selman", "A. Kautz H."], "venue": "J. ACM 43, 193--224", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "A Compiler for Deterministic, Decomposable Negation Normal Form", "author": ["A. Darwiche"], "venue": "proc. AAAI/IAAI\u201902: pp. 627--634. AAAI Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2002}, {"title": "Consistency restoration and explanations in dynamic CSPs Application to configuration", "author": ["J. Amilhastre", "H. Fargier", "P. Marquis"], "venue": "Artif. Intell. 135, 199--234", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Graphical Models", "author": ["R. Mateescu", "R. Dechter", "R. Marinescu"], "venue": "J. Artif. Intell. Res. 33, 465--519", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "A Knowledge Compilation Map", "author": ["A. Darwiche", "P. Marquis"], "venue": "J. Artif. Intell. Res. 17, 229--264", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2002}, {"title": "Hard and Easy Distributions of SAT Problems", "author": ["D.G. Mitchell", "B. Selman", "H.J. Levesque"], "venue": "proc. AAAI\u201992, pp. 459--465. AAAI Press", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "Towards Industrial-Like Random SAT Instances.In", "author": ["C. Ans\u00f3tegui", "L. Bonet M", "J. Levy"], "venue": "proc. IJCAI\u201909,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "The Good Old Davis-Putnam Procedure Helps Counting Models", "author": ["E. Birnbaum", "L. Lozinskii E."], "venue": "J. Artif. Intell. Res. 10, 457--477", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1999}, {"title": "Counting Models Using Connected Components", "author": ["Roberto J. Bayardo Jr.", "Pehoushek J. D"], "venue": "proc. AAAI\u201900, pp. 157--162. AAAI Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "proc", "author": ["Vempary N.R. Solving constraint satisfaction problems using finite state automata. In"], "venue": "AAAI\u201992, pp. 453--458. AAAI Press", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1992}, {"title": "Eliminating Interchangeable Values in Constraint Satisfaction Problems", "author": ["E.C. Freuder"], "venue": "In proc", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "Phase transitions, as a kind of well-known phenomenon in artificial intelligence, have attracted a great mount of attention since the paper [1].", "startOffset": 140, "endOffset": 143}, {"referenceID": 1, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 2, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 3, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 4, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 5, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 6, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 7, "context": "Successive studies have shown that phase transitions widely exist in complex combinational (optimization) problems [2-8].", "startOffset": 115, "endOffset": 120}, {"referenceID": 1, "context": "Some representative problems are random k-SAT, whose phase transition point is measured by the ratio of the number of clauses to that of variables, and random Constraint Satisfaction Problems (CSPs), where in the RB model [2] an exact transition point was proved whose instances are hard to solve.", "startOffset": 222, "endOffset": 225}, {"referenceID": 4, "context": "Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8].", "startOffset": 118, "endOffset": 123}, {"referenceID": 5, "context": "Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8].", "startOffset": 118, "endOffset": 123}, {"referenceID": 6, "context": "Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8].", "startOffset": 137, "endOffset": 140}, {"referenceID": 7, "context": "Furthermore, recent investigations on more complex problems have demonstrated that there are phase transitions in QBF [5,6] and planning [7] which are PSPACE-complete, and even in problems that are EXPSPACE-complete [8].", "startOffset": 216, "endOffset": 219}, {"referenceID": 8, "context": "In addition, some real-world problems, such as TSP [9] and manipulation problem [10], have been shown to have phase transition phenomena.", "startOffset": 51, "endOffset": 54}, {"referenceID": 9, "context": "In addition, some real-world problems, such as TSP [9] and manipulation problem [10], have been shown to have phase transition phenomena.", "startOffset": 80, "endOffset": 84}, {"referenceID": 10, "context": "[11] have addressed phase transitions in #SAT, of which the decision problem is PP-complete.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "As second example phase transitions of backtrack-free instances have been studied [12].", "startOffset": 82, "endOffset": 86}, {"referenceID": 12, "context": "Knowledge compilation [13] is used to compile all (or a part of) the solutions of a problem into a tractable language, and has been employed in many areas ranging from planning, diagnosis to formal verification and production configuration.", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18].", "startOffset": 328, "endOffset": 335}, {"referenceID": 14, "context": "In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18].", "startOffset": 328, "endOffset": 335}, {"referenceID": 15, "context": "In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18].", "startOffset": 328, "endOffset": 335}, {"referenceID": 16, "context": "In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18].", "startOffset": 328, "endOffset": 335}, {"referenceID": 17, "context": "In the past decades, many target languages of knowledge compilation have been proposed for compiling SAT instances and CSPs, such as Ordered Binary Decision Diagram (OBDD), prime implicates, horn approximation, deterministic, Decomposable Negation Normal Form (d-DNNF), Deterministic Finite-state Automaton (DFA) and AND/OR MDD [14-18].", "startOffset": 328, "endOffset": 335}, {"referenceID": 18, "context": "A knowledge compilation map [19] has been presented to analyze the succinctness of the target compilation languages, as well as identify tractable queries of them.", "startOffset": 28, "endOffset": 32}, {"referenceID": 19, "context": "[20] introduced a model for generating random SAT instances, which can produce hard instances as it was claimed.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Meanwhile, theoretical analyses on the random k-SAT model have been made [3], for example, the properties of phase transitions have been identified that are widely used to analyze average computational complexity.", "startOffset": 73, "endOffset": 76}, {"referenceID": 19, "context": "In the model discussed in [20], there are 3 parameters k, n, m that are employed to generate SAT instances, where k is the length of clauses, n is the number of variables, and m is the number of clauses.", "startOffset": 26, "endOffset": 30}, {"referenceID": 20, "context": "[21] proposed some models that can produce random instances similar to industrial instances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "82, instances generated are similar to industrial instances (For more details, we refer to [21]).", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "3 in 3-SAT [20], and mean runtimes for finding a solution by SAT algorithms are often extremely high for solving instances in the phase transition region.", "startOffset": 11, "endOffset": 15}, {"referenceID": 2, "context": "However, it seems to be difficult to locate transition points of k-SAT by theoretical proof, as only lower and upper bounds have been found for the points [3].", "startOffset": 155, "endOffset": 158}, {"referenceID": 20, "context": "For the powerlaw model, phase transition phenomenon was also observed, where its point may occur with a smaller r compared with standard random k-SAT model as reported in [21], the soluble-to-insoluble transition point is about 2.", "startOffset": 171, "endOffset": 175}, {"referenceID": 10, "context": "Similar phenomenon also exists in #SAT [11], which is a counting problem.", "startOffset": 39, "endOffset": 43}, {"referenceID": 21, "context": "For instance, it was reported that an algorithm, called Counting Davis-Putnam [22], reaches its peak runtime when r=1.", "startOffset": 78, "endOffset": 82}, {"referenceID": 22, "context": "2 on the experiments of #3-SAT, while the peak point of another algorithm, called Decomposing Davis-Putnam [23], occurs when r=1.", "startOffset": 107, "endOffset": 111}, {"referenceID": 13, "context": "edu/c2d/) and the OBDD compiler based on CUDD package was developed by Narodytska and Walsh for their work of constraint and variable ordering heuristics for compiling configuration problems [14].", "startOffset": 191, "endOffset": 195}, {"referenceID": 11, "context": "It is quite similar to the classical phase transition, where the phase transition in structures of solutions separates the tractable and intractable regions [12].", "startOffset": 157, "endOffset": 161}, {"referenceID": 15, "context": "We close this section by arguing that not only the size of compilation results undergoes the easy-hard-easy pattern, but also the runtime cost in compilations does, In [16], similar experimental results on d-DNNF for compiling 3-SAT instances have been depicted, where the peak point of runtimes is also fixed at r=1.", "startOffset": 168, "endOffset": 172}, {"referenceID": 20, "context": "with the fact that soluble-to-insoluble transition point of industrial-like SAT will become smaller with \u03b2 increasing from 0, reported in [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 23, "context": "In the early study, DFA was used to solve CSPs by Vempary [24].", "startOffset": 58, "endOffset": 62}, {"referenceID": 16, "context": "[17] compiled configuration problems into DFAs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Freuder [25] investigated the interchangeability deeply, where various forms of interchangeability were proposed.", "startOffset": 8, "endOffset": 12}], "year": 2011, "abstractText": "Phase transitions in many complex combinational problems have been widely studied in the past decade. In this paper, we investigate phase transitions in the knowledge compilation empirically, where DFA, OBDD and d-DNNF are chosen as the target languages to compile random k-SAT instances and industrial-like SAT instances. We perform intensive experiments to analyze the sizes of compilation results and draw the following conclusions: there exists an easy-hard-easy pattern in compilations; the peak point of sizes in the pattern is only related to the ratio of the number of clauses to that of variables when k is fixed, regardless of target languages; most sizes of compilation results increase exponentially with the number of variables growing, but there also exists a phase transition that separates a polynomial-increment region from the exponential-increment region; Moreover, we explain why the phase transition in compilations occurs by analyzing microstructures of DFAs, and conclude that a kind of solution interchangeability with more than 2 variables has a sharp transition near the peak point of the easy-hard-easy pattern, and thus it has great impact on the sizes of DFAs.", "creator": "Microsoft\u00ae Office Word 2007"}}}