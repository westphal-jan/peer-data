{"id": "1104.2086", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2011", "title": "A Universal Part-of-Speech Tagset", "abstract": "to facilitate future research in unsupervised induction of syntactic structure and to standardize best - practices, we periodically propose a tagset that consists of twelve universal part - of - speech binding categories. in addition to the tagset, we develop a pattern mapping from 25 different relational treebank tagsets to this 20 universal set. as a result, when then combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts - of - speech for its 22 different languages. we highlight the use of encoding this resource via two experiments, including one proposal that continually reports competitive accuracies for unsupervised grammar induction without gold standard part - of - speech tags.", "histories": [["v1", "Mon, 11 Apr 2011 23:06:54 GMT  (21kb)", "http://arxiv.org/abs/1104.2086v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["slav petrov", "dipanjan das", "ryan mcdonald"], "accepted": false, "id": "1104.2086"}, "pdf": {"name": "1104.2086.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["slav@google.com", "dipanjan@cs.cmu.edu", "ryanmcd@google.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n10 4.\n20 86\nv1 [\ncs .C\nL ]\n1 1\nA pr"}, {"heading": "1 Introduction", "text": "Part-of-speech (POS) tagging has received a great deal of attention as it is a critical component of most natural language processing systems. As supervised POS tagging accuracies for English (measured on the Wall Street Journal portion of the PennTreebank (Marcus et al., 1993)) have converged to around 97.3% (Toutanova et al., 2003; Shen et al., 2007), the attention has shifted to unsupervised approaches (Christodoulopoulos et al., 2010). In particular, there has been growing interest in both multilingual POS induction (Snyder et al., 2009; Naseem et al., 2009) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; Das and Petrov, 2011).\nUnderlying these studies is the idea that a set of (coarse) syntactic POS categories exist in similar\nforms across languages. These categories are often called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005). For example, Naseem et al. (2009) used the Multext-East (Erjavec, 2004) corpus to evaluate their multi-lingual POS induction system, because it uses the same tagset for multiple languages. When corpora with common tagsets are unavailable, a standard approach is to manually define a mapping from language and treebank specific fine-grained tagsets to a predefined universal set. This was the approach taken by Das and Petrov (2011) to evaluate their cross-lingual POS projection system for six different languages.\nTo facilitate future research and to standardize best-practices, we propose a tagset that consists of twelve universal POS categories. While there might be some controversy about what the exact tagset should be, we feel that these twelve categories cover the most frequent part-of-speech that exist in most languages. In addition to the tagset, we also develop a mapping from fine-grained POS tags for 25 different treebanks to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common parts-ofspeech for 22 different languages.1 Both the tagset and mappings are made available for download at http://code.google.com/p/universal-pos-tags/.\nThis resource serves multiple purposes. First, as mentioned previously, it is useful for building and evaluating unsupervised and cross-lingual taggers. Second, it also permits for a more reasonable com-\n1We include mappings for two different Chinese, German and Japanese treebanks.\nparison of accuracy across languages for supervised taggers. Statements of the form \u201cPOS tagging for language X is harder than for language Y\u201d are vacuous when the tagsets used for the two languages are incomparable (not to mention of different cardinality). Finally, it also permits language technology practitioners to train POS taggers with common tagsets across multiple languages. This in turn facilitates downstream application development as there is no need to maintain language specific rules due to differences in treebank annotation guidelines.\nIn this paper, we specifically highlight two use cases of this resource. First, using our universal tagset and mapping, we run an experiment comparing POS tag accuracies for 25 different treebanks to evaluate POS tagging accuracy on a single tagset. Second, we combine the cross-lingual projection part-of-speech taggers of Das and Petrov (2011) with the grammar induction system of Naseem et al. (2010) \u2013 which requires a universal tagset \u2013 to produce a completely unsupervised grammar induction system for multiple languages, that does not require gold POS tags in the target language."}, {"heading": "2 Tagset", "text": "While there might be some disagreement about the exact definition of an universal POS tagset (Evans and Levinson, 2009), it seems fairly indisputable that a set of coarse POS categories (or syntactic universals) exists across all languages in one form or another (Carnie, 2002; Newmeyer, 2005). Rather than arguing over definitions, we took a pragmatic standpoint during the design of the universal POS tagset and focused our attention on the POS categories that we expect to be most useful (and necessary) for users of POS taggers. In our opinion, these are NLP practitioners using POS taggers in downstream applications, and NLP researchers using POS taggers in grammar induction and other experiments.\nA high-level analysis of the tagsets underlying various treebanks shows that the majority of tagsets\nare very fine-grained and language specific. In fact, Smith and Eisner (2005) made a similar observation and defined a collapsed set of 17 English POS tags (instead of the original 45) that has subsequently been adopted by most unsupervised POS induction work. Similarly, the organizers of the CoNLL shared tasks on dependency parsing provide coarse (but still language specific) tags in addition to the finegrained tags used in the original treebanks (Buchholz and Marsi, 2006; Nivre et al., 2007). McDonald and Nivre (2007) identified eight different coarse POS tags when analyzing the errors of two dependency parsers on the 13 different languages from the CoNLL shared tasks.\nOur universal POS tagset unifies this previous work and defines the following twelve POS tags: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners and articles), ADP (prepositions and postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), \u2018.\u2019 (punctuation marks) and X (a catch-all for other categories such as abbreviations or foreign words).\nWe did not rely on intrinsic definitions of the above categories. Instead, each category is defined operationally. For each treebank under consideration, we studied the exact POS tag definitions and annotation guidelines and created a mapping from the original treebank tagset to these universal POS tags. Most of the decisions were fairly clear. For example, from the PennTreebank, VB, VBD, VBG, VBN, VBP, VBZ and MD (modal) were all mapped to VERB. A less clear case was the universal tag for particles, PRT, which was mapped from POS (possessive), RP (particle) and TO (the word \u2018to\u2019). In particular, the TO tag is ambiguous in the PennTreebank between infinitival markers and the preposition \u2018to\u2019. Thus, under this mapping, some prepositions will be marked as particles in the universal tagset. Figure 1 gives an example mapping for a sentence from the PennTreebank.\nAnother case we had to consider is that some tag\ncategories do not occur in all languages. Consider for example the case of adjectives. While all languages have a way of describing the properties of objects (which themselves are typically referred to with nouns), many have argued that Korean does not technically have adjectives, but instead expresses properties of nouns via stative verbs (Kim, 2002). As a result, in our mapping for Korean, we mapped stative verbs to the universal ADJ tag. In other cases this was clearer, e.g. the Bulgarian treebank has no category for determiners or articles. This is not to say that there are no determiners in the Bulgarian language. However, since they are not annotated as such in the treebank, we are not able to include them in our mapping.\nThe list of treebanks for which we have constructed mappings can be seen in Table 1. One main objective in publicly releasing this resource is to provide treebank and language specific experts a mechanism for refining these categories and the decisions\nwe have made, as well as adding new treebanks and languages. This resource is therefore hosted as an open source project with version control."}, {"heading": "3 Experiments", "text": "To demonstrate the efficacy of the proposed universal POS tagset, we performed two sets of experiments. First, to provide a language comparison, we trained the same supervised POS tagging model on all of the above treebanks and evaluated the tagging accuracy on the universal POS tagset. Second, we used universal POS tags (automatically projected from English) as the starting point for unsupervised grammar induction, producing completely unsupervised parsers for several languages."}, {"heading": "3.1 Language Comparisons", "text": "To compare POS tagging accuracies across different languages we trained a supervised tagger based on a trigram Markov model (Brants, 2000) on all tree-\nbanks. We chose this model for its fast speed and (close to) state-of-the-art accuracy without language specific tuning.2\nTable 1 shows the results for all 25 treebanks when training/testing on the original (O) and universal (U) tagsets. Overall, the variance on the universal tagset has been reduced by half (5.1 instead of 10.4). But of course there are still accuracy differences across the different languages. On the one hand, given a golden segmentation, tagging Japanese is almost deterministic, resulting in a final accuracy of above 99%.3 On the other hand, tagging Turkish, an agglutinative language with and average sentence length of 11.6 tokens, remains very challenging, resulting in an accuracy of only 90.2%.\nIt should be noted that the best results are obtained by training on the original treebank categories and mapping the predictions to the universal POS tags at the end (O/U column). This is because the transition model based on the universal POS tagset is less informative. An interesting experiment would be to train the latent variable tagger of Huang et al. (2009) on this tagset. Their model automatically discovers refinements of the observed categories and could potentially find a tighter fit to the data, than the one provided by the original, linguistically motivated treebank tags."}, {"heading": "3.2 Grammar Induction", "text": "We further demonstrate the utility of the universal POS tags in a grammar induction experiment. To decouple the challenges of POS tagging and parsing, golden POS tags are typically assumed in unsupervised grammar induction experiments (Carroll and Charniak, 1992; Klein and Manning, 2004).4 We propose to remove this unrealistic simplification by using POS tags automatically projected from English as the basis of a grammar induction model.\nDas and Petrov (2011) describe a cross-lingual projection framework to learn POS taggers without labeled data for the language of interest. We use their automatically induced POS tags to induce\n2Trained on the English PennTreebank this model achieves 96.7% accuracy when evaluated on the original 45 POS tags.\n3Note that the accuracy on the universal POS tags for the two Japanese treebanks is almost the same.\n4A less benevolent explanation for this practice is that grammar induction from plain text is simply still too difficult.\nsyntactic dependencies. To this end, we chose the framework of Naseem et al. (2010), in which a few universal syntactic rules (USR) are used to constrain a probabilistic Bayesian model. These rules are specified using a set of universal syntactic categories, and lead to state-of-the-art grammar induction performance superior to previous methods, such as the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction model (PGI) (Berg-Kirkpatrick and Klein, 2010).\nIn their experiments, Naseem et al. also used a set of universal categories, however, with some differences to the tagset presented here. Their tagset does not have punctuation and catch-all categories, but includes a category for auxiliaries. The auxiliary category helps define a syntactic rule that attaches verbs to an auxiliary head, which is beneficial for certain languages. However, since this rule is reversed for other languages, we omit it in our tagset. Additionally, they also used refined categories in the form of CoNLL treebank tags. In our experiments, we did not make use of refined categories, as the POS tags induced by Das and Petrov (2011) were all coarse.\nWe present results on the same eight IndoEuropean languages as Das and Petrov (2011), so that we can make use of their automatically projected POS tags. For all languages, we used the treebanks released as a part of the CoNLL-X (Buchholz and Marsi, 2006) shared task. We only considered sentences of length 10 or less, after the removal of punctuations. We performed Bayesian inference on\n5Not reported by Berg-Kirkpatrick and Klein (2010).\nthe whole treebank and report dependency attachment accuracy.\nTable 2 shows directed dependency accuracies for the DMV and PGI models using fine-grained gold POS tags. For the USR model, it reports results on gold universal POS tags (USR-G) and automatically induced universal POS tags (USR-I). The USR-I model falls short of the USR-G model, but has the advantage that it does not require any labeled data from the target language. Quite impressively, it does better than DMV for all languages, and is competitive with PGI, even though those models have access to fine-grained gold POS tags."}, {"heading": "4 Conclusions", "text": "We proposed a POS tagset consisting of twelve categories that exists across languages and developed a mapping from 25 language specific tagsets to this universal set. We demonstrated experimentally that the universal POS categories generalize well across language boundaries on an unsupervised grammar induction task, giving competitive parsing accuracies without relying on gold POS tags. The tagset and mappings are available for download at http://code.google.com/p/universal-pos-tags/"}, {"heading": "Acknowledgements", "text": "We would like to thank Joakim Nivre for allowing us to use a preliminary tagset mapping used in the work of McDonald and Nivre (2007). The second author was supported in part by NSF grant IIS-0844507."}], "references": [{"title": "Building a Treebank for French", "author": ["A. Abeill\u00e9", "L. Cl\u00e9ment", "F. Toussenel."], "venue": "Abeill\u00e9 (Abeill\u00e9, 2003), chapter 10.", "citeRegEx": "Abeill\u00e9 et al\\.,? 2003", "shortCiteRegEx": "Abeill\u00e9 et al\\.", "year": 2003}, {"title": "Treebanks: Building and Using Parsed Corpora", "author": ["A. Abeill\u00e9", "editor"], "venue": null, "citeRegEx": "Abeill\u00e9 and editor.,? \\Q2003\\E", "shortCiteRegEx": "Abeill\u00e9 and editor.", "year": 2003}, {"title": "Construction of a Basque dependency treebank", "author": ["I. Aduriz", "M.J. Aranzabe", "J.M. Arriola", "A. Atutxa", "A. Diaz de Ilarraza", "A. Garmendia", "M. Oronoz."], "venue": "Proc. of the Workshop on Treebanks and Linguistic Theories.", "citeRegEx": "Aduriz et al\\.,? 2003", "shortCiteRegEx": "Aduriz et al\\.", "year": 2003}, {"title": "Floresta sint\u00e1(c)tica: a treebank for Portuguese", "author": ["S. Afonso", "E. Bick", "R. Haber", "D. Santos."], "venue": "Proc. of LREC.", "citeRegEx": "Afonso et al\\.,? 2002", "shortCiteRegEx": "Afonso et al\\.", "year": 2002}, {"title": "Phylogenetic grammar induction", "author": ["T. Berg-Kirkpatrick", "D. Klein."], "venue": "Proc. of ACL.", "citeRegEx": "Berg.Kirkpatrick and Klein.,? 2010", "shortCiteRegEx": "Berg.Kirkpatrick and Klein.", "year": 2010}, {"title": "Development of a dependency treebank for russian and its possible applications in nlp", "author": ["I.M. Boguslavsky", "L.L. Iomdin", "I.S. Chardin", "L.G. Kreidlin."], "venue": "Proc. of LREC.", "citeRegEx": "Boguslavsky et al\\.,? 2002", "shortCiteRegEx": "Boguslavsky et al\\.", "year": 2002}, {"title": "The PDT: a 3-level annotation scenario", "author": ["A. B\u00f6hmov\u00e1", "J. Haji\u010d", "E. Haji\u010dov\u00e1", "B. Hladk\u00e1."], "venue": "Abeill\u00e9 (Abeill\u00e9, 2003), chapter 7, pages 103\u2013127.", "citeRegEx": "B\u00f6hmov\u00e1 et al\\.,? 2003", "shortCiteRegEx": "B\u00f6hmov\u00e1 et al\\.", "year": 2003}, {"title": "The TIGER Treebank", "author": ["S. Brants", "S. Dipper", "S. Hansen", "W. Lezius", "G. Smith."], "venue": "Proc. of the Workshop on Treebanks and Linguistic Theories.", "citeRegEx": "Brants et al\\.,? 2002", "shortCiteRegEx": "Brants et al\\.", "year": 2002}, {"title": "TnT - a statistical part-of-speech tagger", "author": ["T. Brants."], "venue": "Proc. of ANLP.", "citeRegEx": "Brants.,? 2000", "shortCiteRegEx": "Brants.", "year": 2000}, {"title": "CoNLL-X shared task on multilingual dependency parsing", "author": ["S. Buchholz", "E. Marsi."], "venue": "Proc. of CoNLL.", "citeRegEx": "Buchholz and Marsi.,? 2006", "shortCiteRegEx": "Buchholz and Marsi.", "year": 2006}, {"title": "Syntax: A Generative Introduction (Introducing Linguistics)", "author": ["A. Carnie."], "venue": "Blackwell Publishing.", "citeRegEx": "Carnie.,? 2002", "shortCiteRegEx": "Carnie.", "year": 2002}, {"title": "Two experiments on learning probabilistic dependency grammars from corpora", "author": ["G. Carroll", "E. Charniak."], "venue": "Working Notes of the Workshop StatisticallyBased NLP Techniques.", "citeRegEx": "Carroll and Charniak.,? 1992", "shortCiteRegEx": "Carroll and Charniak.", "year": 1992}, {"title": "Sinica treebank: Design criteria, representational issues and implementation", "author": ["K. Chen", "C. Luo", "M. Chang", "F. Chen", "C. Chen", "C. Huang", "Z. Gao."], "venue": "Abeill\u00e9 (Abeill\u00e9, 2003), chapter 13, pages 231\u2013248.", "citeRegEx": "Chen et al\\.,? 2003", "shortCiteRegEx": "Chen et al\\.", "year": 2003}, {"title": "Two decades of unsupervised POS induction: How far have we come? In Proc", "author": ["C. Christodoulopoulos", "S. Goldwater", "M. Steedman."], "venue": "of EMNLP.", "citeRegEx": "Christodoulopoulos et al\\.,? 2010", "shortCiteRegEx": "Christodoulopoulos et al\\.", "year": 2010}, {"title": "Building cast3lb: A spanish treebank", "author": ["M.A.M. Civit"], "venue": "Mart\u0131\u0301", "citeRegEx": "Civit,? \\Q2004\\E", "shortCiteRegEx": "Civit", "year": 2004}, {"title": "The Szeged Treebank", "author": ["D. Csendes", "J. Csirik", "T. Gyim\u00f3thy", "A. Kocsor."], "venue": "Springer.", "citeRegEx": "Csendes et al\\.,? 2005", "shortCiteRegEx": "Csendes et al\\.", "year": 2005}, {"title": "Unsupervised part-ofspeech tagging with bilingual graph-based projections", "author": ["D. Das", "S. Petrov."], "venue": "Proc. of ACL-HLT.", "citeRegEx": "Das and Petrov.,? 2011", "shortCiteRegEx": "Das and Petrov.", "year": 2011}, {"title": "Towards a Slovene dependency treebank", "author": ["S. D\u017eeroski", "T. Erjavec", "N. Ledinek", "P. Pajas", "Z. \u017dabokrtsky", "A. \u017dele."], "venue": "Proc. of LREC.", "citeRegEx": "D\u017eeroski et al\\.,? 2006", "shortCiteRegEx": "D\u017eeroski et al\\.", "year": 2006}, {"title": "MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora", "author": ["T. Erjavec."], "venue": "Proc. of LREC.", "citeRegEx": "Erjavec.,? 2004", "shortCiteRegEx": "Erjavec.", "year": 2004}, {"title": "The myth of language universals: Language diversity and its importance for cognitive science", "author": ["N. Evans", "S. Levinson."], "venue": "Behavioral and Brain Sciences, 32(05).", "citeRegEx": "Evans and Levinson.,? 2009", "shortCiteRegEx": "Evans and Levinson.", "year": 2009}, {"title": "Prague Arabic dependency treebank: Development in data and tools", "author": ["J. Haji\u010d", "O. Smr\u017e", "P. Zem\u00e1nek", "J. \u0160naidauf", "E. Be\u0161ka."], "venue": "Proc. of NEMLAR.", "citeRegEx": "Haji\u010d et al\\.,? 2004", "shortCiteRegEx": "Haji\u010d et al\\.", "year": 2004}, {"title": "Improving simple bigram HMM part-of-speech tagger by latent annotation", "author": ["Z. Huang", "V. Eidelman", "M. Harper."], "venue": "Proc. of NAACL-HLT.", "citeRegEx": "Huang et al\\.,? 2009", "shortCiteRegEx": "Huang et al\\.", "year": 2009}, {"title": "Stylebook for the Japanese treebank in VERBMOBIL", "author": ["Y. Kawata", "J. Bartels"], "venue": null, "citeRegEx": "Kawata and Bartels.,? \\Q2000\\E", "shortCiteRegEx": "Kawata and Bartels.", "year": 2000}, {"title": "Does Korean have adjectives", "author": ["M.J. Kim"], "venue": "MIT Working Papers in Linguistics,", "citeRegEx": "Kim.,? \\Q2002\\E", "shortCiteRegEx": "Kim.", "year": 2002}, {"title": "Corpus-based induction of syntactic structure: models of dependency and constituency", "author": ["D. Klein", "C.D. Manning."], "venue": "Proc. of ACL.", "citeRegEx": "Klein and Manning.,? 2004", "shortCiteRegEx": "Klein and Manning.", "year": 2004}, {"title": "Danish Dependency Treebank", "author": ["M.T. Kromann", "L. Mikkelsen", "S.K. Lynge."], "venue": "Proc. of the Workshop on Treebanks and Linguistic Theories.", "citeRegEx": "Kromann et al\\.,? 2003", "shortCiteRegEx": "Kromann et al\\.", "year": 2003}, {"title": "Kyoto University text corpus project", "author": ["S. Kurohashi", "M. Nagao."], "venue": "Proc. of ANLP.", "citeRegEx": "Kurohashi and Nagao.,? 1997", "shortCiteRegEx": "Kurohashi and Nagao.", "year": 1997}, {"title": "Building a large annotated corpus of English: the Penn treebank", "author": ["M.P. Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational Linguistics, 19.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "CESS-ECE: A multilingual and multilevel annotated corpus. Available for download from: http://www.lsi.upc.edu/\u223cmbertran/cess-ece", "author": ["M.A. Mart\u0131", "M. Taul\u00e9", "L. M\u00e0rquez", "M. Bertran"], "venue": null, "citeRegEx": "Mart\u0131\u0301 et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mart\u0131\u0301 et al\\.", "year": 2007}, {"title": "Characterizing the errors of data-driven dependency parsing models", "author": ["R. McDonald", "J. Nivre."], "venue": "Proc. of EMNLP-CoNLL.", "citeRegEx": "McDonald and Nivre.,? 2007", "shortCiteRegEx": "McDonald and Nivre.", "year": 2007}, {"title": "Building the Italian Syntactic", "author": ["S. Montemagni", "F. Barsotti", "M. Battista", "N. Calzolari", "O. Corazzari", "A. Lenci", "A. Zampolli", "F. Fanciulli", "M. Massetani", "R. Raffaelli", "R. Basili", "M.T. Pazienza", "D. Saracino", "F. Zanzotto", "N. Nana", "F. Pianesi", "R. Delmonte"], "venue": null, "citeRegEx": "Montemagni et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Montemagni et al\\.", "year": 2003}, {"title": "Multilingual part-of-speech tagging: Two unsupervised approaches", "author": ["T. Naseem", "B. Snyder", "J. Eisenstein", "R. Barzilay."], "venue": "JAIR, 36.", "citeRegEx": "Naseem et al\\.,? 2009", "shortCiteRegEx": "Naseem et al\\.", "year": 2009}, {"title": "Using universal linguistic knowledge to guide grammar induction", "author": ["T. Naseem", "H. Chen", "R. Barzilay", "M. Johnson."], "venue": "Proc. of EMNLP.", "citeRegEx": "Naseem et al\\.,? 2010", "shortCiteRegEx": "Naseem et al\\.", "year": 2010}, {"title": "Possible and Probable Languages: A Generative Perspective on Linguistic Typology", "author": ["F.J. Newmeyer."], "venue": "Oxford University Press.", "citeRegEx": "Newmeyer.,? 2005", "shortCiteRegEx": "Newmeyer.", "year": 2005}, {"title": "Talbanken05: A Swedish Treebank with Phrase Structure and Dependency Annotation", "author": ["J. Nivre", "J. Nilsson", "J. Hall."], "venue": "Proc. of LREC.", "citeRegEx": "Nivre et al\\.,? 2006", "shortCiteRegEx": "Nivre et al\\.", "year": 2006}, {"title": "Building a Turkish treebank", "author": ["K. Oflazer", "B. Say", "D. Zeynep Hakkani-T\u00fcr", "G. T\u00fcr."], "venue": "Abeill\u00e9 (Abeill\u00e9, 2003), chapter 15, pages 261\u2013277.", "citeRegEx": "Oflazer et al\\.,? 2003", "shortCiteRegEx": "Oflazer et al\\.", "year": 2003}, {"title": "Chinese Treebank 6.0", "author": ["M. Palmer", "N. Xue", "F. Xia", "F. Chiou", "Z. Jiang", "M. Chang"], "venue": "Technical report, Linguistic Data Consortium,", "citeRegEx": "Palmer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2007}, {"title": "Guided learning for bidirectional sequence classification", "author": ["L. Shen", "G. Satta", "A. Joshi."], "venue": "Proc. of ACL.", "citeRegEx": "Shen et al\\.,? 2007", "shortCiteRegEx": "Shen et al\\.", "year": 2007}, {"title": "Building a Linguistically Interpreted Corpus of Bulgarian: the BulTreeBank", "author": ["K. Simov", "P. Osenova", "S. Kolkovska", "E. Balabanova", "D. Doikoff", "K. Ivanova", "A. Simov", "M Kouylekov."], "venue": "Proc. of LREC.", "citeRegEx": "Simov et al\\.,? 2002", "shortCiteRegEx": "Simov et al\\.", "year": 2002}, {"title": "An annotation scheme for free word order languages", "author": ["W. Skut", "B. Krenn", "T. Brants", "H. Uszkoreit."], "venue": "Proc. of ANLP.", "citeRegEx": "Skut et al\\.,? 1997", "shortCiteRegEx": "Skut et al\\.", "year": 1997}, {"title": "Contrastive estimation: Training log-linear models on unlabeled data", "author": ["N.A. Smith", "J. Eisner."], "venue": "Proc. of ACL.", "citeRegEx": "Smith and Eisner.,? 2005", "shortCiteRegEx": "Smith and Eisner.", "year": 2005}, {"title": "Adding more languages improves unsupervised multilingual part-of-speech tagging: A Bayesian nonparametric approach", "author": ["B. Snyder", "T. Naseem", "J. Eisenstein", "R. Barzilay."], "venue": "Proc. of NAACL.", "citeRegEx": "Snyder et al\\.,? 2009", "shortCiteRegEx": "Snyder et al\\.", "year": 2009}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer."], "venue": "Proc. of HLT-NAACL.", "citeRegEx": "Toutanova et al\\.,? 2003", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "The Alpino dependency treebank", "author": ["L. Van der Beek", "G. Bouma", "R. Malouf", "G. Van Noord."], "venue": "Language and Computers, 45(1):8\u201322.", "citeRegEx": "Beek et al\\.,? 2002", "shortCiteRegEx": "Beek et al\\.", "year": 2002}, {"title": "A backoff model for bootstrapping resources for non-English languages", "author": ["C. Xi", "R. Hwa."], "venue": "Proc. of HLT-EMNLP.", "citeRegEx": "Xi and Hwa.,? 2005", "shortCiteRegEx": "Xi and Hwa.", "year": 2005}, {"title": "Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora", "author": ["D. Yarowsky", "G. Ngai."], "venue": "Proc. of NAACL.", "citeRegEx": "Yarowsky and Ngai.,? 2001", "shortCiteRegEx": "Yarowsky and Ngai.", "year": 2001}], "referenceMentions": [{"referenceID": 27, "context": "pervised POS tagging accuracies for English (measured on the Wall Street Journal portion of the PennTreebank (Marcus et al., 1993)) have converged to around 97.", "startOffset": 109, "endOffset": 130}, {"referenceID": 42, "context": "3% (Toutanova et al., 2003; Shen et al., 2007), the attention has shifted to unsupervised ap-", "startOffset": 3, "endOffset": 46}, {"referenceID": 37, "context": "3% (Toutanova et al., 2003; Shen et al., 2007), the attention has shifted to unsupervised ap-", "startOffset": 3, "endOffset": 46}, {"referenceID": 13, "context": "proaches (Christodoulopoulos et al., 2010).", "startOffset": 9, "endOffset": 42}, {"referenceID": 45, "context": ", 2009) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; Das and Petrov, 2011).", "startOffset": 64, "endOffset": 129}, {"referenceID": 44, "context": ", 2009) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; Das and Petrov, 2011).", "startOffset": 64, "endOffset": 129}, {"referenceID": 16, "context": ", 2009) and cross-lingual POS induction via treebank projection (Yarowsky and Ngai, 2001; Xi and Hwa, 2005; Das and Petrov, 2011).", "startOffset": 64, "endOffset": 129}, {"referenceID": 10, "context": "called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005).", "startOffset": 58, "endOffset": 88}, {"referenceID": 33, "context": "called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005).", "startOffset": 58, "endOffset": 88}, {"referenceID": 18, "context": "(2009) used the Multext-East (Erjavec, 2004) corpus to evaluate their multi-lingual POS induction system, because it uses the same tagset for multiple languages.", "startOffset": 29, "endOffset": 44}, {"referenceID": 10, "context": "called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005). For example, Naseem et al. (2009) used the Multext-East (Erjavec, 2004) corpus to evaluate their multi-lingual POS induction system, because it uses the same tagset for multiple languages.", "startOffset": 59, "endOffset": 124}, {"referenceID": 10, "context": "called universals to represent their cross-lingual nature (Carnie, 2002; Newmeyer, 2005). For example, Naseem et al. (2009) used the Multext-East (Erjavec, 2004) corpus to evaluate their multi-lingual POS induction system, because it uses the same tagset for multiple languages. When corpora with common tagsets are unavailable, a standard approach is to manually define a mapping from language and treebank specific fine-grained tagsets to a predefined universal set. This was the approach taken by Das and Petrov (2011) to evaluate their cross-lingual POS projection system for six different languages.", "startOffset": 59, "endOffset": 522}, {"referenceID": 16, "context": "Second, we combine the cross-lingual projection part-of-speech taggers of Das and Petrov (2011) with the grammar induction system of Naseem et al.", "startOffset": 74, "endOffset": 96}, {"referenceID": 19, "context": "While there might be some disagreement about the exact definition of an universal POS tagset (Evans and Levinson, 2009), it seems fairly indisputable that a set of coarse POS categories (or syntactic universals) exists across all languages in one form or another (Carnie, 2002; Newmeyer, 2005).", "startOffset": 93, "endOffset": 119}, {"referenceID": 10, "context": "While there might be some disagreement about the exact definition of an universal POS tagset (Evans and Levinson, 2009), it seems fairly indisputable that a set of coarse POS categories (or syntactic universals) exists across all languages in one form or another (Carnie, 2002; Newmeyer, 2005).", "startOffset": 263, "endOffset": 293}, {"referenceID": 33, "context": "While there might be some disagreement about the exact definition of an universal POS tagset (Evans and Levinson, 2009), it seems fairly indisputable that a set of coarse POS categories (or syntactic universals) exists across all languages in one form or another (Carnie, 2002; Newmeyer, 2005).", "startOffset": 263, "endOffset": 293}, {"referenceID": 9, "context": "Similarly, the organizers of the CoNLL shared tasks on dependency parsing provide coarse (but still language specific) tags in addition to the finegrained tags used in the original treebanks (Buchholz and Marsi, 2006; Nivre et al., 2007).", "startOffset": 191, "endOffset": 237}, {"referenceID": 37, "context": "In fact, Smith and Eisner (2005) made a similar observation and defined a collapsed set of 17 English POS tags (instead of the original 45) that has subsequently been adopted by most unsupervised POS induction work.", "startOffset": 9, "endOffset": 33}, {"referenceID": 9, "context": "Similarly, the organizers of the CoNLL shared tasks on dependency parsing provide coarse (but still language specific) tags in addition to the finegrained tags used in the original treebanks (Buchholz and Marsi, 2006; Nivre et al., 2007). McDonald and Nivre (2007) identified eight different coarse POS tags when analyzing the errors of two dependency parsers on the 13 different languages from the CoNLL shared tasks.", "startOffset": 192, "endOffset": 265}, {"referenceID": 20, "context": "Language Source # Tags O/O U/U O/U Arabic PADT/CoNLL07 (Haji\u010d et al., 2004) 21 96.", "startOffset": 55, "endOffset": 75}, {"referenceID": 2, "context": "0 Basque Basque3LB/CoNLL07 (Aduriz et al., 2003) 64 89.", "startOffset": 27, "endOffset": 48}, {"referenceID": 38, "context": "7 Bulgarian BTB/CoNLL06 (Simov et al., 2002) 54 95.", "startOffset": 24, "endOffset": 44}, {"referenceID": 28, "context": "8 Catalan CESS-ECE/CoNLL07 (Mart\u0131\u0301 et al., 2007) 54 98.", "startOffset": 27, "endOffset": 48}, {"referenceID": 36, "context": "0 (Palmer et al., 2007) 34 91.", "startOffset": 2, "endOffset": 23}, {"referenceID": 12, "context": "1 Chinese Sinica/CoNLL07 (Chen et al., 2003) 294 87.", "startOffset": 25, "endOffset": 44}, {"referenceID": 6, "context": "6 Czech PDT/CoNLL07 (B\u00f6hmov\u00e1 et al., 2003) 63 99.", "startOffset": 20, "endOffset": 42}, {"referenceID": 25, "context": "1 Danish DDT/CoNLL06 (Kromann et al., 2003) 25 96.", "startOffset": 21, "endOffset": 43}, {"referenceID": 27, "context": "0 English PennTreebank (Marcus et al., 1993) 45 96.", "startOffset": 23, "endOffset": 44}, {"referenceID": 0, "context": "7 French FrenchTreebank (Abeill\u00e9 et al., 2003) 30 96.", "startOffset": 24, "endOffset": 46}, {"referenceID": 7, "context": "3 German Tiger/CoNLL06 (Brants et al., 2002) 54 97.", "startOffset": 23, "endOffset": 44}, {"referenceID": 39, "context": "8 German Negra (Skut et al., 1997) 54 96.", "startOffset": 15, "endOffset": 34}, {"referenceID": 15, "context": "8 Hungarian Szeged/CoNLL07 (Csendes et al., 2005) 43 94.", "startOffset": 27, "endOffset": 49}, {"referenceID": 30, "context": "8 Italian ISST/CoNLL07 (Montemagni et al., 2003) 28 94.", "startOffset": 23, "endOffset": 48}, {"referenceID": 22, "context": "8 Japanese Verbmobil/CoNLL06 (Kawata and Bartels, 2000) 80 98.", "startOffset": 29, "endOffset": 55}, {"referenceID": 26, "context": "0 (Kurohashi and Nagao, 1997) 42 97.", "startOffset": 2, "endOffset": 29}, {"referenceID": 3, "context": "4 Portuguese Floresta Sint\u00e1(c)tica/CoNLL06 (Afonso et al., 2002) 22 96.", "startOffset": 43, "endOffset": 64}, {"referenceID": 5, "context": "4 Russian SynTagRus-RNC (Boguslavsky et al., 2002) 11 96.", "startOffset": 24, "endOffset": 50}, {"referenceID": 17, "context": "8 Slovene SDT/CoNLL06 (D\u017eeroski et al., 2006) 29 94.", "startOffset": 22, "endOffset": 45}, {"referenceID": 34, "context": "9 Swedish Talbanken05/CoNLL06 (Nivre et al., 2006) 41 93.", "startOffset": 30, "endOffset": 50}, {"referenceID": 35, "context": "1 Turkish METU-Sabanci/CoNLL07 (Oflazer et al., 2003) 31 87.", "startOffset": 31, "endOffset": 53}, {"referenceID": 9, "context": "Where applicable, we indicate whether the data set was extracted from the CoNLL 2006 (Buchholz and Marsi, 2006) or CoNLL 2007 (Nivre et al.", "startOffset": 85, "endOffset": 111}, {"referenceID": 23, "context": "While all languages have a way of describing the properties of objects (which themselves are typically referred to with nouns), many have argued that Korean does not technically have adjectives, but instead expresses properties of nouns via stative verbs (Kim, 2002).", "startOffset": 255, "endOffset": 266}, {"referenceID": 8, "context": "To compare POS tagging accuracies across different languages we trained a supervised tagger based on a trigram Markov model (Brants, 2000) on all tree-", "startOffset": 124, "endOffset": 138}, {"referenceID": 21, "context": "An interesting experiment would be to train the latent variable tagger of Huang et al. (2009) on this tagset.", "startOffset": 74, "endOffset": 94}, {"referenceID": 11, "context": "To decouple the challenges of POS tagging and parsing, golden POS tags are typically assumed in unsupervised grammar induction experiments (Carroll and Charniak, 1992; Klein and Manning, 2004).", "startOffset": 139, "endOffset": 192}, {"referenceID": 24, "context": "To decouple the challenges of POS tagging and parsing, golden POS tags are typically assumed in unsupervised grammar induction experiments (Carroll and Charniak, 1992; Klein and Manning, 2004).", "startOffset": 139, "endOffset": 192}, {"referenceID": 24, "context": "These rules are specified using a set of universal syntactic categories, and lead to state-of-the-art grammar induction performance superior to previous methods, such as the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction model (PGI) (Berg-Kirkpatrick and Klein, 2010).", "startOffset": 210, "endOffset": 235}, {"referenceID": 4, "context": "These rules are specified using a set of universal syntactic categories, and lead to state-of-the-art grammar induction performance superior to previous methods, such as the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction model (PGI) (Berg-Kirkpatrick and Klein, 2010).", "startOffset": 287, "endOffset": 321}, {"referenceID": 29, "context": "To this end, we chose the framework of Naseem et al. (2010), in which a few universal syntactic rules (USR) are used to constrain a probabilistic Bayesian model.", "startOffset": 39, "endOffset": 60}, {"referenceID": 9, "context": "For all languages, we used the treebanks released as a part of the CoNLL-X (Buchholz and Marsi, 2006) shared task.", "startOffset": 75, "endOffset": 101}, {"referenceID": 15, "context": "In our experiments, we did not make use of refined categories, as the POS tags induced by Das and Petrov (2011) were all coarse.", "startOffset": 90, "endOffset": 112}, {"referenceID": 15, "context": "In our experiments, we did not make use of refined categories, as the POS tags induced by Das and Petrov (2011) were all coarse. We present results on the same eight IndoEuropean languages as Das and Petrov (2011), so that we can make use of their automatically projected POS tags.", "startOffset": 90, "endOffset": 214}, {"referenceID": 4, "context": "Not reported by Berg-Kirkpatrick and Klein (2010).", "startOffset": 16, "endOffset": 50}, {"referenceID": 29, "context": "of McDonald and Nivre (2007). The second author", "startOffset": 3, "endOffset": 29}], "year": 2011, "abstractText": "To facilitate future research in unsupervised induction of syntactic structure and to standardize best-practices, we propose a tagset that consists of twelve universal part-ofspeech categories. In addition to the tagset, we develop a mapping from 25 different treebank tagsets to this universal set. As a result, when combined with the original treebank data, this universal tagset and mapping produce a dataset consisting of common partsof-speech for 22 different languages. We highlight the use of this resource via two experiments, including one that reports competitive accuracies for unsupervised grammar induction without gold standard part-of-speech tags.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}