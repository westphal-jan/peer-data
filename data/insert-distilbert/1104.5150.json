{"id": "1104.5150", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Apr-2011", "title": "File Transfer Application For Sharing Femto Access", "abstract": "studies in wireless access network access optimization, today's main challenges reside in infrastructure traffic offload generation and in the improvement of both capacity and coverage networks. the operators are interested in solving their localized coverage and capacity problems in areas where the macro mhz network mode signal is not presently able to serve the demand for mobile data. thus, the major issue for operators is to hopefully find the best solution at reasonable remote expanses. the femto cell seems to be the answer to this problematic. in this collaborative work ( this work is supported by the comet project aware.", "histories": [["v1", "Wed, 27 Apr 2011 14:04:27 GMT  (213kb,D)", "http://arxiv.org/abs/1104.5150v1", "15 pages, 9 figures; extended version from Conference ISCIS 2011"]], "COMMENTS": "15 pages, 9 figures; extended version from Conference ISCIS 2011", "reviews": [], "SUBJECTS": "cs.NI cs.LG", "authors": ["mariem krichen", "johanne cohen", "dominique barth"], "accepted": false, "id": "1104.5150"}, "pdf": {"name": "1104.5150.pdf", "metadata": {"source": "CRF", "title": "File Transfer Application For Sharing Femto Access", "authors": ["Mariem Krichen", "Johanne Cohen"], "emails": ["mariem.krichenjohanne.cohendominique.barth@prism.uvsq.fr"], "sections": [{"heading": null, "text": "This work addresses the sharing femto access problem considering only one SPC using game theory tools. We consider that SRCs are static and have some similar and regular connection behavior. We also note that the SPC and each SRC have a software embedded respectively on its femto access, user equipment (UE).\nAfter each connection requested by a SRC, its software will learn the strategy increasing its gain knowing that no information about the other SRCs strategies is given. The following article presents a distributed learning algorithm with incomplete information running in SRCs software. We will then answer the following questions for a game with N SRCs and one SPC: how many connections are necessary for each SRC in order to learn the strategy maximizing its gain? Does this algorithm converge to a stable state? If yes, does this state a Nash Equilibrium and is there any way to optimize the learning process duration time triggered by SRCs software?\nKeywords-component: game theory, sharing femto access, Nash Equilibrium, distributed learning algorithm, stable state."}, {"heading": "1 Introduction", "text": "Today, one of the biggest issues for Mobile Operators is to provide acceptable indoor coverage for wireless networks. Among the several in-building solutions, the femto cell is the one which is gaining significant interest. A femto cell is a small cellular base station characterized by low transmission power, limited access to a closed user group designed for residential or small business use. But its expansive buying cost is not motivating to purchase it. This solution could help operators solve localized coverage problems and extend their network. Indeed, in some areas where the macro network signal is weak, a network of open femto cells access would significantly improve the voice quality and data connectivity. This would be feasible if access points owners accept to be part of a Club where each member is willing to open up its access point\n1This work is supported by the COMET project AWARE. http://www.ftw.at/news/project-start-for-aware-ftw\nar X\niv :1\n10 4.\n51 50\nv1 [\ncs .N\nI] 2\n7 A\npr 2\n01 1\nto the other members. This idea of sharing part of its bandwidth started with FON2, a club where members share their WiFi connection and inspired us to propose a Club where members share their femto accesses with bandwidth guarantees. A femto club member could share its 3G/LTE signal securely with other club members. Incentives for an owner of an access point to be member of such a club can be not only to share a part of the cost of the access point but also to make advertisement or to share some information through a specific social network associated to the club. These incentives would logically lead the club to manage by itself only such bandwidth exchange, but since this technology uses licensed spectrum, the only model that could for the moment be adopted for sharing femto access is the one where the mobile operator is also participating. Sharing femto access is a service proposed by the Mobile Operator to its clients. These customers are divided into service providers customers (SPCs) and service requesters customers (SRCs) : SPCs are the owners of femto cells accesses for which they have contracted with a Mobile operator denoted by MO. SRCs are customers using a mobile terminal in an area covered by some SPCs access points and requesting to use these access points. Note that a user can be both a SPC and a SRC. Dynamic femto spectrum sharing is a challenging problem for all the actors. Indeed the amount of requested bandwidth by SRCs as well as the amount of bandwidth shared by SPCs and pricing should be determined such that the utility of all the agents is maximized. Since the interests of all the actors could be antagonist, especially between many SRCs requesting a same SPC, we model our system as a game to determine equilibria of such situations.\nRelated works The problem of sharing bandwidth and pricing has been already addressed by Dusit Niyato et al [2], then modeled as a game. The challenging problem in this context is that bandwidth sharing requires a peaceful co-existence of both primary and secondary users. The femto access sharing we present in this article is similar but takes also into account both of SRCs and SPCs profiles.\nThe potential games introduced by Rosenthal [8] are classical games having at least one pure Nash equilibrium. These games have a potential function such that each of its local optimums corresponds to a pure Nash equilibrium. This property has been used for congestion game in general (see [6] for a survey), with Resource Reuse in a wireless context (see [1]) and for a real-time spectrum sharing problem with QoS provisioning [10].\nA decentralized learning algorithm of Nash equilibria in multi-person stochastic games with incomplete information has been presented by M.A.L. Thathachar et all. In the considered game, the distribution of the random payoff is unknown to the players and further none of the players know the strategies or the actual moves of other players. It is proved that all stable stationary points of the algorithm are Nash equilibrium for the game [7]. The study presented in this article will use this algorithm in the game restricted to SRCs where each SRC will learn the strategy maximizing its gain using only local information. We will check whether if the stationary point the algorithm converges to is a pure Nash equilibrium.\nOur contribution. Section 2 presents the model for sharing femto access and the actors involved in this model are described. The game considering only SRCs competition is presented in Section 3. Section 4 details the principle of a distributed algorithm used to learn the game NE if any exists and some simulations results are given in Section 4.4. Finally, Section 5 draws a general conclusion and gives some perspectives.\n2FON is a for-profit company incorporated and registered in the U.K. FON was created in Madrid, Spain, by Martin Varsavsky, an Argentine/Spanish entrepreneur and founder of many companies in the last 20 years."}, {"heading": "2 Model for sharing femto access", "text": "Now, we present the model for sharing femto access. Our system is composed of SPCs and SRCs. SPCs share some amount of bandwidth with SRCs. We assume that there exists a Token Based Accounting Protocol to exchange services between SRCs and SPCs against tokens [3]. On one hand, the paradigm for spectrum sharing should guarantee a certain access speed and a data transmission speed. On the other hand, the model should propose a type of connection (that would be more expansive than others) which guarantees QoS to SRCs: connections belonging to this type will never be canceled by the SPC.\nOur work considers a unique SPC denoted by X and several SRCs. We assume that the SPC\u2019s resource reserved for sharing is an amount of bandwidth denoted by BS(X). Then, we will consider that each SRC Y requests connection from X . Actually, the bandwidth BS(X) of SPC X is divided into two parts:\nBS(X) = BSG(X) +BSY (X)\n\u2022 BSG(X) is the part of bandwidth in which SRCs communications can never be preempted. It is kind of a guaranteed QoS allocated to SRCs.\n\u2022 BSY (X) is the part of bandwidth in which SRCs communicatiosn can be preempted. This preemption is due to the fact that the SPC has priority on this part of bandwidth. Thus, a communication allocated in BSY (X) is characterized by a risk of preemption.\nFigure 1 introduces the sharing bandwidth process and the billing process in both cases of a Green and a Yellow connection allocation: let\u2019s consider a SRC Y who needs an amount of bandwidth equal to bw. bw will be allocated to Y only if it is free. If X will need bw, he will not be able to use it if the connection he allocated to Y is green. However, he will be able to preempt the connection allocated to Y if it is a yellow one.\nWe assume that there exists a Token Based Accounting Protocol to exchange services between SRCs and SPCs against tokens (representing money) [3]. The billing process depends on whether the SRC has used a green connection or a yellow one.\nIn the case of a Green connection, the SRC will spend N1 tokens corresponding to the used bandwidth bw. In the case of a Yellow connection, the SRC will spendN2 (N2 < N1) tokens if the connection succeed. Indeed, the yellow connection is cheaper than the green one due to the risk of preemption. If the yellow connection given to the SRC has failed, this connection will be free."}, {"heading": "2.1 Actors Description", "text": "In the following section, we will describe the actors involved in the model that we have just presented."}, {"heading": "2.1.1 SPC Actor", "text": "A SPC is a customer of the MO. SPC proposes to share an amount of its bandwidth with SRCs for a price per bandwidth unit which depends on the type of connection (Green,Yellow). The bandwidth split into Green and Yellow parts is determined following its sensitivity to Gain denoted by \u00b5 \u2208 [0, 1] and its sensitivity to its own connection QoS denoted by \u0393 \u2208 [0, 1]. These two parameters are dual: \u00b5+ \u0393 = 1.\nThe Gain sensitivity parameter indicates its sensitivity degree to the price of the connection shared while the QoS sensitivity parameter indicates the SPC\u2019s tolerance degree towards preemption risk. The more a SPC\nis sensitive to gain, the bigger its green part bandwidth will be because of its expansive selling price. The more a SPC is sensitive to QoS, the bigger its Yellow Part bandwidth will be since he does not want to be preempted by SRCs. When \u00b5 > 1/2, we say that the SPC is sensitive to gain. Otherwise, the SPC is considered as sensitive to its access QoS."}, {"heading": "2.1.2 SRC Actor", "text": "A SRC is also a customer of the MO in need of QoS characterized by a QoS sensitivity parameter \u03b1 and a price sensitivity parameter \u03b2. The SRC wants to use the SPC\u2019s resources. The QoS sensitivity parameter indicates the SRC\u2019s tolerance degree towards the QoS degradation while the price sensitivity parameter indicates the SRC\u2019s tolerance degree towards the cost of the connection. These two parameters are dual: \u03b1+ \u03b2 = 1.\nThe more one SRC is sensitive to QoS, the less its tolerance degree towards the QoS degradation will be. The more one SRC is sensitive to price, the less he is able to pay for the connection. When \u03b1 > 1/2, the SRC is considered as sensitive to QoS. Otherwise, the SRC is sensitive to price."}, {"heading": "2.1.3 Interaction between the SPC actor and SRCs actors", "text": "In general context, SRCs will request for some amount of bandwidth from the SPC depending of their profiles. The SPC will treat the SRCs requests for a fixed bandwidth split.\n1. For SRCs, the utility depends on their requests, the other SRCs requests as well as the SPC\u2019s decision (bandwidth allocated and type of connection) for a fixed SPC\u2019s bandwidth split. So, the SRC\u2019s utility depends mainly on its competition with other SRCs to receive some bandwidth from the same SPC.\n2. For the SPC, the utility depends on its bandwidth split for fixed SRCs requests. Since we consider only one SPC, no competition is needed for the SPC to rise its utility.\nIn our work, we will only focus on the competition between SRCs when the SPC\u2019s bandwidth split is fixed."}, {"heading": "3 Game presentation", "text": "Since only the competition between SRCs is considered, sharing femto access problem could be thus modeled as a game whereN SRCs are the players. We also consider that the SPC\u2019s bandwidth split is fixed. This could be motivated by the fact that learning methods are reliable only when the surrounding environment is invariant. We do not consider the mobility of SRCs. However, we assume that SRCs have some regular and similar connection behavior: each SRC requests the SPC\u2019s connection in nearly same time slots with almost invariant needs in terms of QoS. This means that requesting the SPC\u2019s femto access becomes almost routine for SRCs. This could be seen as repeated games.\nAlong requested connections, each SRC will learn, thanks to an algorithm running in a software embedded in its user equipment, the best strategy to be played to maximize its gain. In this article, sharing femto access game will be denoted by the game restricted to SRCs.\nThe game restricted to SRCs is defined as follows: given a fixed SPC\u2019s bandwidth split (into green part and yellow part), what would be the best strategy to be played by SRCs in order to have a stable situation where the strategy of each SRC player is optimal for him considering the other SRCs strategies. This situation corresponds to a pure Nash equilibrium in game theory. Recall that a pure Nash equilibrium of a game is a situation where, for each player, there is no unilateral strategy deviation that increases its utility [5]."}, {"heading": "3.1 Game restricted to SRCs", "text": "As mentioned in the previous section, the game restricted to SRCs assumes that the SPC\u2019s bandwidth split is fixed. Let BS be the total bandwidth the SPC is agree to share and let \u03a8S be the proportion of BSG regarding BS ."}, {"heading": "3.1.1 SRCs QoS needs", "text": "Each SRC\u2019s QoS needs depend on the type of application he requests. Requesting for femto access is equivalent to request an amount of bandwidth. Fixing this amount of bandwidth depends on the following parameters: the type of application (real time, elastic), the QoS parameter that the applications requires (delay, time transfer file, . . . ), the type of connection (Green or Yellow) and the SRC\u2019s profile (QoS sensitive SRC or price sensitive SRC).\nOur work takes into account the File Transfer Application. QoS is defined as the time transfer file that we will denote by t. The SRC\u2019s QoS satisfaction is related to t. For each SRC, the time transfer file should be between T1 and T2 and is defined as follows:\n\u2022 Case t = T1: BWMax corresponds to the required bandwidth to download a file in t = T1. If the SPC provides an amount of bandwidth equal to BWMax, then the SRC\u2019s QoS satisfaction is at the top.\n\u2022 Case t = T2: BWMin corresponds to the required bandwidth to download a file in t = T2. If the SPC provides an amount of bandwidth equal to BWMin, then the SRC\u2019s QoS satisfaction is minimal.\nEach SRC will request for a minimum amount of bandwidth and a maximum amount of bandwidth in Green and Yellow depending on its profile and on its user equipment Signal-Strength towards the SPC\u2019s femto cell.\nAll the SRCs requests can not be accepted. In fact, since the SPC\u2019s bandwidth is limited and since several SRCs could request for the SPC\u2019s connection at the same time, one possible response that a SRC\ncould receive is a deny one. Requesting for a Minimum and a Maximum amount of bandwidth will decrease the chances to receive such a response. Besides, requesting a bandwidth interval generalizes the fact of requesting a fixed amount of bandwidth. In this way, a SRC could receive an amount of bandwidth which may be different from its optimal request but would avoid him to have no payoff.\nThe minimum and the maximum amount of bandwidth are fixed depending on the SRC\u2019s profile. Note that the parameters caracterizing a SRC\u2019s profile are real in [0, 1]. We aim at translating these parameters into intervals of bandwidth requests which are actually integers. So, we introduce a parameter \u03b5 representing the discretization of the bandwidth resquested. Let SSRCibe the set of possible strategies of SRCi. In the following, we focus on the request of a SRC denoted by SRCi according to its profile.\n1. We consider the case where SRCi has its QoS sensitive parameter \u03b1i greater than 1/2. SRCi fixes a revenue threshold under which he denies any proposed connection (high QoS degradation). This threshold denoted byRev Thi corresponds to a minimum amount of bandwidth to be requested. This parameter depends on the QoS sensitivity \u03b1i of the SRC. Rev Thi = \u03b1i \u2212 \u03ba where \u03ba \u2208 [0, 1] is the allowed variation from the QoS degradation tolerance fixed according to the SRC\u2019s profile (more specifically \u03b1i).\nSSRCi = {Rev Thi, Rev Thi + \u03b5,Rev Thi + 2\u03b5, . . . , 1}.\n2. We consider the case where SRCi has its QoS sensitive parameter \u03b1i less than 1/2. This implies that its price sensitive parameter \u03b2i is greater than 1/2. SRCi fixes a cost threshold denoted by Cost Thi above which he denies any proposed connection (the cost is beyond what he is able to pay). This threshold corresponds to a maximum amount of bandwidth to be requested. This parameter depends on the QoS sensitivity of the SRC and is defined as follows: Cost Thi = \u03b1i + \u03ba.\nSSRCi = {Cost Thi, Cost Thi \u2212 \u03b5, Cost Thi \u2212 2\u03b5, . . . , 0}.\nEach element si of SSRCi permits to define an interval of bandwidth to be requested in Green and Yellow connection. This represents a couple (gi = [mGi ,M G i ], yi = [m Y i ,M Y i ]) of couples of integers. The parameters mXi ,M X i represent respectively the minimum and the maximum amount of bandwidth to be requested in X connection where X \u2208 {G, Y }. They are defined as follows :\n1. Case where SRCi has its QoS sensitive parameter \u03b1i greater than 1/2:\n(a) mGi = BWmax si and mYi = BWmax si \u00d7 (1\u2212 \u03b4) (b) MGi = BWmax and M Y i = BWmax\n2. Case where SRCi has its QoS sensitive parameter \u03b1i less than 1/2.\n(a) MGi = BWmax si and MYi = BWmax si \u00d7 (1\u2212 \u03b4) (b) mGi = BWmin and m Y i = BWmin\nFigure 2 highlights an example of a QoS sensitive SRC (\u03b1 = 0.7) and Figure 3 gives an example of a price sensitive SRC (\u03b1 = 0.3). They show the minimum and the maximum amount of bandwidth to be requested in Green and Yellow for one of the SRC\u2019s strategies."}, {"heading": "3.1.2 SPC\u2019s bandwidth allocation", "text": "Each SRC sends a request to the SPC. At reception, the SPC decides the way its bandwidth is allocated to SRCs. The request of each SRCi is represented by one element in SSRCi . According to a set \u03a0 of SRCs requets \u03a0 =< s1, s2, . . . , sN > where si corresponds to the request of SRCi, for any i, 1 \u2264 i \u2264 N , SPC gives an answer to each SRCi represented by a triple (Gi, Yi, bwi) defined as follows:\n\u2022 bwi represents the amount of bandwidth given by the SPC to SRCi.\n\u2022 Gi = 1 (resp. Yi = 1) means that SRCi has received a Green (resp. Yellow) connection from the SPC. Note that the case where Gi = 1 and Yi = 1 is not possible.\n\u2022 If Gi = 0 and if Yi = 0, then SRCi has received no connection from the SPC.\nLet config(\u03a0) be the set of all answers (one answer per SRC) of the SPC to \u03a0. In other words,\nconfig(\u03a0) =< (G1, Y1, bw1), (G2, Y2, bw2), . . . , (GN , YN , bwN ) >\nThe answers respect the two following properties. Let si be the corresponding bandwith request (gi = [mGi ,M G i ], yi = [m Y i ,M Y i ]) of SRCi.\n1. The SPC gives SRCi an amount of bandwidth equal to bwi where bwi is in the interval requested. More formally, if (Gi = 1) then bwi \u2208 gi or if (Yi = 1) then bwi \u2208 yi.\n2. The SPC provides bandwidth to SRCs in the limits of its bandwidth availability in Green and Yellow. Thus: \u2211N\ni=0Gi \u00d7 bwi < \u03a8SBS and \u2211N i=0 Yi \u00d7 bwi < (1\u2212\u03a8S)BS .\nMoreover, the SPC allocates its bandwidth in a way maximizing this outcome function:\nUSPC(config(\u03a0)) = \u2211 i Prop(bwi)(\u00b5\u2212 \u0393) (Gi + Yi(1\u2212 \u03b4)) (1)\nNote that the SPC\u2019s outcome function considers only its own profile described in Section 2.1.1. Given a SRC strategy set, the SPC allocates to each SRC a connection in Green and Yellow such as its outcome function is maximized."}, {"heading": "3.1.3 SRC Game Definition", "text": "Game theory models the interactions between players competing for a common resource. In our system, the formulation of this noncooperative game G = \u3008N , S, Uk\u3009 can be described as follows:\n\u2022 The set of players is N . Each player is a SRC. There are N SRCs.\n\u2022 The space of pure strategies S formed by the Cartesian product of each set of pure strategies\nS = SSRC1 \u00d7 SSRCi \u00d7 ...\u00d7 SSRCN\nNote that for each SRCi, the set SSRCi is defined in Section 3.1.1. A pure strategie si is a value corresponding to the request which is a couple (gi = [mGi ,M G i ], yi = [m Y i ,M Y i ]) of couples of integers.\n\u2022 A set of utility functions {U1, U2, ..., UN} that quantifies the players\u2019 preferences over the possible outcomes of the game. According to a set \u03a0 of SRCs requets \u03a0 =< s1, s2, . . . , sN > where si corresponds to the strategy of SRCi, for any i, 1 \u2264 i \u2264 N , the SRCs utilities are determined through the SPC\u2019s allocation. Since several allocation decisions could maximize the SPC\u2019s outcome function\ngiven by Equation (1), the SRC\u2019s utility corresponds to a mean of all these allocation decisions. Let sol(\u03a0) be the set of config(\u03a0) that maximizes the SPC\u2019s outcome function with M = |sol(\u03a0)|. The utility Ui(\u03a0) of SRCi from sol(\u03a0) is expressed as follows:\nUi(\u03a0) = \u2211\nc\u2208sol(\u03a0)\ngaini(c)\nM . (2)\nThe gain of SRCi from the SPC\u2019s allocation decision c in sol(\u03a0) is expressed as follows:\ngaini(c) = Revi(c)\u2212 Costi(c)\nWhere c represents a triple (Gi, Yi, bwi) to SRCi.\n\u2013 Revi(c) \u2208 [0, 1] represents the SRC\u2019s QoS satisfaction from the connection c provided by the SPC and is expressed as follows:\nRevi(c) = Rev(bwi)Gi\u03b1i +Rev(bwi)Yi(1\u2212 \u03b4)\u03b1i where Rev(bwi) \u2208 [0, 1]\n\u2013 Costi(c) \u2208 [0, 1] represents the cost of the connection c provided by the SPC and is expressed as follows:\nCosti(c) = Cost(bwi)Gi\u03b2i + Cost(bwi)Yi(1\u2212 \u03b4)\u03b2i where Cost(bwi) \u2208 [0, 1]\nWe normalize the utility of SRCi in order to have Ui(\u03a0) \u2208 [0, 1]."}, {"heading": "3.2 SRC game equilibrium", "text": "Since each SRCi has a finite set of strategies, this game has a mixed Nash equilibrium [5]. In the following, we study the existence of a pure Nash equilibrium in the sharing femto access game using the properties of potential games. The definition of potential game could be found in [8].\ntheorem 1 Each instance of the game restricted to SRCs admits at least one pure Nash equilibrium.\nThe proof of this theorem is detailed in [4].\nSketch of proof: The main idea of this proof is to show that the Best Response Dynamic in this game converges to a pure Nash equilibrium. The Best Response dynamic algorithm corresponds to a sequence of profiles computation. Let C be an arbitrary profile. If no player has incentive to change its strategy in C, then C is a pure Nash equilibrium and this algorithm stops. If at least one player has incentive to change its strategy in C, then this player changes its strategy by choosing its best response and thus we move to a new profile C \u2032. Then, the algorithm applies the same process for C \u2032 and so on. If some players have incentive to change their strategy, this means that the SPC reduces its non reserved bandwidth. Thus the Best Response Dynamic algorithm will end up since at each step the free SPC\u2019s bandwidth is reduced."}, {"heading": "4 Learning the Game restricted to SRCs\u2019 Nash equilibrium", "text": "In Section 3, we have proved that the game restricted to SRCs admits at least one pure Nash equilibrium. Now, we want to know whether a distributed algorithm (each player knows only its local information) could converge to a pure Nash equilibrium."}, {"heading": "4.1 Algorithm Principle", "text": "In the following section, we will assume that we are in a distributed context. So, each SRC player will, based only on its local information, learn the strategy maximizing its gain.\nFor a fixed \u03a8S , we will apply the steps from 2 to 5 of the algorithm presented in Figure 4\n2. Each SRC sends a request using a specific distributed algorithm denoted by Adist.\n3. The SPC defines its decision sol(\u03a0).\n4. The SPC sends its decision to all SRCs.\n5. Each SRC will compute its utility following sol(\u03a0).\nWe will repeat all these steps till convergence of Algorithm Adist. We will denote by \u03a0\u2217 the SRC strategy profile for which Adist converges. Now, we will present the Algorithm Adist. In [3], it has been proved that if the considered game has at least one pure Nash equilibrium and if there exists a sufficiently small value of the learning speed parameter for which the distributed learning algorithm converges, then the point of convergence of this algorithm is a pure Nash equilibrium. We say that this algorithm weakly converges to a Nash equilibrium.\n4.2 ALGORITHM Adist Algorithm Adist is a decentralized learning algorithm of Nash equilibrium in multi-person stochastic games with incomplete information. The principle of Adist is described as follows:\nWe consider that the strategic process for each SRC player follows a discrete learning technique.\n\u2022 Each SRCi will update its strategy at a step t denoted by sti following its local mixed strategy (probability distribution assigned to each available pure strategy). Each SRCi will thus compute its new probability vector st+1i using only a set of local information (s t i, margin t i, gain t i) where gain t i rep-\nresents the gain from the SPC\u2019s allocation decision and marginti is the pure strategy in SSRCi\n\u2022 At each step t, each SRC chooses randomly one strategy (marginti) and increases its probability of choosing this strategy(sti) according to its gain (gain t i) and a learning parameter b \u2208 [0, 1] which\nmodulates the learning speed of the different SRCs players.\nThe learning technique is based on the following update rule:\nIf j 6= marginti then s t+1 i,j = s t i,j \u2212 b.uti.sti,j\nelse st+1i,j = s t i,j \u2212 b.uti. \u2211 k 6=marginti sti,k\nSuch that: uti = gainti\u2212Ati Uti\u2212Ati is the normalized utility. The variables (U ti = maxk\u2264tgain k i ) and (A t i = maxk\u2264tgain k i ) correspond respectively to the maximum utility and the minimum utility of SRCi at iteration t. Note that it is possible to consider Ati = 0\nThe aim from using this update rule is the following: each SRC player lowers the probabilities associated to margins not played at the step t by the same percentage. The sum of these percentages is then added to the probability associated to the margin played at step t.\nAs mentioned in Theorem 1, in the game restricted to SRCs, there is at least one pure Nash equilibrium. In this article, we will try to answer the following questions: Does Adist converge? Is the point of convergence if any exists a pure Nash equilibrium? Is this algorithm reliable for Nash equilibrium computation?"}, {"heading": "4.3 Simulations", "text": "In our simulations we will consider N SRCs: each SRCi is characterized by \u03b1i (the QoS sensitivity parameter of SRCi) and is requesting for the SPC\u2019s connection characterized by \u00b5 to download a file.\nWe will only focus on the cases of a same category SRCs and more specifically QoS sensitive SRCs. Indeed, this case is the hardest one to reach stability since the SRCs requirements are conflicting. In the other possible cases, Algorithm Adist converges.\nThe simulations presented take into consideration an extremely gain sensitive SPC (i.e \u00b5 = 1) and N QoS sensitive SRCs. The N SRCs want to download a file of 1Mbyte. We will consider T2 = 300sec, \u00b5 = 1, \u03b4 = 0.1, \u03b5 = 0.1, \u03ba = 0.1, \u03a8S = 0.5 and BS = 20Mb/s. Since a femto access could support only 8 communications, we will run simulations where 2 \u2264 N \u2264 8 keeping the same input presented above. In this article, we will present the results only for 4 and 5 SRCs. The first simulation presents a scenario where SRCs have only two strategies (extremely QoS sensitive SRCs3). In the second simulation, SRCs have more than two possible strategies. In our simulations, we consider the following strategy notation si = Rev Thi"}, {"heading": "4.3.1 Scenario 1 with 5 SRCs", "text": "3An extremely QoS sensitive SRC is a SRC with \u03b1 = 1\nFor this scenario, we will as a first step analytically compute the game Nash equilibriums. To do so, we will consider the same steps presented in Figure 4 except that the SRC strategy profile is not generated with AlgorithmAdist: we will consider all the possible SRC strategy profiles and thus fill the SRCs payoff matrix with utilities corresponding to each SRC strategy profile. Figure 5 highlights 10 pure Nash equilibriums circled in red. These Nash equilibriums are detected analytically through the SRCs payoff matrix since SRCs cannot rise utility by an unilateral deviation. Now, we will run the Algorithm Adist . First, we will verify whether if it converges and then we will check whether if the point of convergence ,if any, is one among the pure Nash equilibriums detected analytically. To do so, we will consider b = 0.1 and 1000 iterations. In Figure 6 and 9, each point represents the mean over 15 iterations of respectively SRCs expected gain value and SRCs strategy probability.\nAdist converges after 780 Iterations. Figure 6 shows that the SRCs expected gain stabilize as follows: Expected gain(SRC1)=Expected gain(SRC2)=Expected gain(SRC4)=0.45 and Expected gain(SRC3)=Expected\ngain(SRC5)=0.33. In Figure 9, we remark that the convergence point (point where each SRC has a pure strategy) \u03a0\u2217 = (1, 1, 0.9, 1, 0.9) matches with one of the pure Nash equilibriums computed analytically. For a number of SRCs varying from 2 to 8, we have checked by simulations that pure Nash equilibrium\nin the game restricted to SRCs is reachable keeping the same input as scenario 1. The following table summarizes the number of iterations necessary for Adist to converge for N varying from 2 to 8. This result is true for SRCs with only two strategies."}, {"heading": "4.3.2 Scenario 2 with 4 SRCs", "text": "In the following, we will check if the fact of having more than two possible strategies per SRC could effect the results. To do so, we will consider 4 SRCs defined as follows: \u03b11 = 0.9, \u03b12 = 0.7, \u03b13 = 1 and \u03b14 = 0.9.\n6 pure Nash equilibriums are found analytically in the SRCs utility matrix and are the following:\n\u03a0\u2217 = {(1, 1, 0.9, 1, 0.9); (0.9, 0.9, 1, 1); (0.9, 1, 0.9, 1); (0.9, 1, 1, 0.9); (1, 0.9, 0.9, 1); (1, 0.9, 1, 0.9); (1, 1, 0.9, 0.9)}.\nFor Adist algorithm, we will consider b = 0.1 and 700 iterations. In Figures 8 and 9, each point represents the mean over 15 iterations of respectively SRCs expected gain value and SRCs strategy probability.\nAdist converges after 500 iterations. We notice in Figure 8 that the SRCs expected Gain stabilize as follows:\nExpected gain(SRC1)=Expected gain(SRC2)=Expected gain(SRC4)=0.45 and Expected gain(SRC3)=Expected gain(SRC5)=0.33\nEven with more than two strategies per SRC, Adist still converges to a Pure Nash equilibrium. In this simulation, \u03a0\u2217 = (0.9, 1, 1, 0.9) is a pure Nash equilibrium. Figure 9 shows that SRC1, SRC2, SRC3 and SRC4 needs respectively 175, 200, 410 and 500 iterations to learn the strategy maximizing its gain.\nWhen all the SRCs have pure strategies, we reach a stable state for the game restricted to SRCs. In order to make the system representing this game converge more rapidly, we will propose two solutions: In the first one, we consider that the system is stable if all the SRCs have a strategy with a probability equal to p (0 < p < 1).\nIf we fix p = 0.8, the software set up in the user equipment of SRC1, SRC2, SRC3 and SRC4 needs respectively 90, 90, 200 and 340 initiated connections to learn the strategy maximizing its gain. After 340 iterations, the system is considered as stable. Thus, the number of iterations forAdist convergence is reduced by 32%.\nThe second solution does not reduce the number of iterations for Adist convergence, but proposes to reduce its time duration (could also be seen as the number of requested connections). This solution is based on the fact of triggering the learning process several times per connection requested. This means that for a connection of duration D, the SRC\u2019s software will choose a new strategy following the updated strategy probability vector each d=q*D slot time (q \u2208 [0, 1]). Thus, the time duration (the number of requested connections) necessary for Adist convergence is reduced by q.\nWe have focused on the convergence of Adist taking into consideration several strategies per SRC and 2 \u2264 N \u2264 8. We have found that Adist always converges to one among the pure Nash equilibriums detected analytically in the SRCs payoff matrix. To conclude, Adist permits to learn the game restricted to SRCs\u2019 pure Nash equilibrium whatever the SRCs profiles are."}, {"heading": "4.4 Simulation results", "text": "Simulations results have shown that the game restricted to SRCs using a distributed learning algorithm converges to a pure Nash equilibrium. We have checked that this result is available for a number of SRCs varying from 2 to 8 for SRCs with exactly 2 strategies or more than 2 strategies. The distributed algorithm converges in a finite number of iterations. Two solutions has been proposed to reduce the number of requested connections necessary for this algorithm convergence. The distributed learning algorithm running in SRCs user equipments gives at convergence the minimum and the maximum amount of bandwidth to be requested by each SRC in Green and Yellow."}, {"heading": "5 Conclusion and perspectives", "text": "In this article, we investigate the problem of sharing femto access taking a file transfer application as example. Only the competition between SRCs is modeled as a game considering a fixed SPC\u2019s bandwidth split. Our simulations focus on examples where SRCs objectives conflict: SRCs belonging to the same category of QoS sensitive SRCs.\nSimulations have proved the efficiency of the Distributed Learning Algorithm: even if each SRC player has only local information, the algorithm always converges to a pure Nash equilibrium.\nAs a perspective, we will consider the sharing femto access game with several SRCs and several SPCs. The sharing femto access problem will thus be divided into two levels: a first level representing a game restricted to SRCs and a second level representing a game restricted to SPCs. We will study the properties of the second level game to check whether if they match with the game restricted to SRCs\u2019 properties. We will also focus on the convergence time optimization of the algorithm ADist applied on both SRCs game and SPCs game."}], "references": [{"title": "Congestion games with resource reuse and applications in spectrum", "author": ["Sahand Haji Ali Ahmad", "Mingyan Liu", "Yunnan Wu"], "venue": "sharing. CoRR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Microeconomic Models for Dynamic Spectrum Management in Cognitive Radio Networks, chapter 14, pages 391\u2013423", "author": ["Niyaton Dusit", "Ekram Hossain"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Tokenbased accounting and distributed pricing to introduce market mechanisms in a peer-to-peer file sharing scenario", "author": ["David Hausheer", "Nicolas C. Liebau", "Andreas Mauthe", "Ralf Steinmetz", "Burkhard Stiller"], "venue": "In Proceedings of the 3rd International Conference on Peer-to-Peer Computing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "File transfer application for sharing femto access : Game properties", "author": ["Mariem Krichen", "Johanne Cohen", "Dominique Barth"], "venue": "Technical report, Universite\u0301 de Versailles,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Equilibrium points in n-person games", "author": ["John F. Nash"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1950}, {"title": "Algorithmic Game Theory", "author": ["Nissan Nisan", "Tim Roughgarden", "\u00c9va Tardos", "Vijay V. Vazirani"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Decentralized learning of Nash equilibria in multiperson stochastic games with incomplete information", "author": ["M.A.L. Thathachar P.S. Sastry", "V.V. Phansalkar"], "venue": "IEEE transactions on system, man, and cybernetics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "A class of games possessing pure-strategy Nash equilibria", "author": ["R.W. Rosenthal"], "venue": "International Journal of Game Theory,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1973}, {"title": "A shapley value representation of potential games", "author": ["Takashi Ui"], "venue": "Games and Economic Behavior,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2000}, {"title": "Real-time secondary spectrum sharing with qos provisioning", "author": ["Yiping Xing", "Chetan N .Mathur", "M. A Haleem", "R. Chandramouli", "K. P Subbalakshmi"], "venue": "In Consumer Communications and Networking Conference (CCNC),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}], "referenceMentions": [{"referenceID": 1, "context": "Related works The problem of sharing bandwidth and pricing has been already addressed by Dusit Niyato et al [2], then modeled as a game.", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "The potential games introduced by Rosenthal [8] are classical games having at least one pure Nash equilibrium.", "startOffset": 44, "endOffset": 47}, {"referenceID": 5, "context": "This property has been used for congestion game in general (see [6] for a survey), with Resource Reuse in a wireless context (see [1]) and for a real-time spectrum sharing problem with QoS provisioning [10].", "startOffset": 64, "endOffset": 67}, {"referenceID": 0, "context": "This property has been used for congestion game in general (see [6] for a survey), with Resource Reuse in a wireless context (see [1]) and for a real-time spectrum sharing problem with QoS provisioning [10].", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "This property has been used for congestion game in general (see [6] for a survey), with Resource Reuse in a wireless context (see [1]) and for a real-time spectrum sharing problem with QoS provisioning [10].", "startOffset": 202, "endOffset": 206}, {"referenceID": 6, "context": "It is proved that all stable stationary points of the algorithm are Nash equilibrium for the game [7].", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "We assume that there exists a Token Based Accounting Protocol to exchange services between SRCs and SPCs against tokens [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 2, "context": "We assume that there exists a Token Based Accounting Protocol to exchange services between SRCs and SPCs against tokens (representing money) [3].", "startOffset": 141, "endOffset": 144}, {"referenceID": 0, "context": "The bandwidth split into Green and Yellow parts is determined following its sensitivity to Gain denoted by \u03bc \u2208 [0, 1] and its sensitivity to its own connection QoS denoted by \u0393 \u2208 [0, 1].", "startOffset": 111, "endOffset": 117}, {"referenceID": 0, "context": "The bandwidth split into Green and Yellow parts is determined following its sensitivity to Gain denoted by \u03bc \u2208 [0, 1] and its sensitivity to its own connection QoS denoted by \u0393 \u2208 [0, 1].", "startOffset": 179, "endOffset": 185}, {"referenceID": 4, "context": "Recall that a pure Nash equilibrium of a game is a situation where, for each player, there is no unilateral strategy deviation that increases its utility [5].", "startOffset": 154, "endOffset": 157}, {"referenceID": 0, "context": "Note that the parameters caracterizing a SRC\u2019s profile are real in [0, 1].", "startOffset": 67, "endOffset": 73}, {"referenceID": 0, "context": "Rev Thi = \u03b1i \u2212 \u03ba where \u03ba \u2208 [0, 1] is the allowed variation from the QoS degradation tolerance fixed according to the SRC\u2019s profile (more specifically \u03b1i).", "startOffset": 27, "endOffset": 33}, {"referenceID": 0, "context": "\u2013 Revi(c) \u2208 [0, 1] represents the SRC\u2019s QoS satisfaction from the connection c provided by the SPC and is expressed as follows:", "startOffset": 12, "endOffset": 18}, {"referenceID": 0, "context": "Revi(c) = Rev(bwi)Gi\u03b1i +Rev(bwi)Yi(1\u2212 \u03b4)\u03b1i where Rev(bwi) \u2208 [0, 1] \u2013 Costi(c) \u2208 [0, 1] represents the cost of the connection c provided by the SPC and is expressed as follows:", "startOffset": 60, "endOffset": 66}, {"referenceID": 0, "context": "Revi(c) = Rev(bwi)Gi\u03b1i +Rev(bwi)Yi(1\u2212 \u03b4)\u03b1i where Rev(bwi) \u2208 [0, 1] \u2013 Costi(c) \u2208 [0, 1] represents the cost of the connection c provided by the SPC and is expressed as follows:", "startOffset": 80, "endOffset": 86}, {"referenceID": 0, "context": "Costi(c) = Cost(bwi)Gi\u03b2i + Cost(bwi)Yi(1\u2212 \u03b4)\u03b2i where Cost(bwi) \u2208 [0, 1] We normalize the utility of SRCi in order to have Ui(\u03a0) \u2208 [0, 1].", "startOffset": 65, "endOffset": 71}, {"referenceID": 0, "context": "Costi(c) = Cost(bwi)Gi\u03b2i + Cost(bwi)Yi(1\u2212 \u03b4)\u03b2i where Cost(bwi) \u2208 [0, 1] We normalize the utility of SRCi in order to have Ui(\u03a0) \u2208 [0, 1].", "startOffset": 130, "endOffset": 136}, {"referenceID": 4, "context": "2 SRC game equilibrium Since each SRCi has a finite set of strategies, this game has a mixed Nash equilibrium [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 7, "context": "The definition of potential game could be found in [8].", "startOffset": 51, "endOffset": 54}, {"referenceID": 3, "context": "The proof of this theorem is detailed in [4].", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "In [3], it has been proved that if the considered game has at least one pure Nash equilibrium and if there exists a sufficiently small value of the learning speed parameter for which the distributed learning algorithm converges, then the point of convergence of this algorithm is a pure Nash equilibrium.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "Each SRCi will thus compute its new probability vector s i using only a set of local information (s t i, margin t i, gain t i) where gain t i represents the gain from the SPC\u2019s allocation decision and margini is the pure strategy in SSRCi \u2022 At each step t, each SRC chooses randomly one strategy (margini) and increases its probability of choosing this strategy(si) according to its gain (gain t i) and a learning parameter b \u2208 [0, 1] which modulates the learning speed of the different SRCs players.", "startOffset": 428, "endOffset": 434}, {"referenceID": 0, "context": "This means that for a connection of duration D, the SRC\u2019s software will choose a new strategy following the updated strategy probability vector each d=q*D slot time (q \u2208 [0, 1]).", "startOffset": 170, "endOffset": 176}], "year": 2011, "abstractText": "In wireless access network optimization, today\u2019s main challenges reside in traffic offload and in the improvement of both capacity and coverage networks. The operators are interested in solving their localized coverage and capacity problems in areas where the macro network signal is not able to serve the demand for mobile data. Thus, the major issue for operators is to find the best solution at reasonable expanses. The femto cell seems to be the answer to this problematic. In this work1, we focus on the problem of sharing femto access between a same mobile operator\u2019s customers. This problem can be modeled as a game where service requesters customers (SRCs) and service providers customers (SPCs) are the players. This work addresses the sharing femto access problem considering only one SPC using game theory tools. We consider that SRCs are static and have some similar and regular connection behavior. We also note that the SPC and each SRC have a software embedded respectively on its femto access, user equipment (UE). After each connection requested by a SRC, its software will learn the strategy increasing its gain knowing that no information about the other SRCs strategies is given. The following article presents a distributed learning algorithm with incomplete information running in SRCs software. We will then answer the following questions for a game with N SRCs and one SPC: how many connections are necessary for each SRC in order to learn the strategy maximizing its gain? Does this algorithm converge to a stable state? If yes, does this state a Nash Equilibrium and is there any way to optimize the learning process duration time triggered by SRCs software? Keywords-component: game theory, sharing femto access, Nash Equilibrium, distributed learning algorithm, stable state.", "creator": "LaTeX with hyperref package"}}}