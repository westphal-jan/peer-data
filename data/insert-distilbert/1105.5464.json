{"id": "1105.5464", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-May-2011", "title": "Learning to Order Things", "abstract": "there are many applications in which it is desirable to order rather than classify instances. here we consider the problem of learning how to order from instances given feedback in the form collections of unique preference judgments, i. e., statements to consider the effect that one instance evaluation should be ranked ahead of another. we outline a selective two - stage approach in which one first learns by conventional means a binary preference function indicating whether it is advisable, to rank one instance altogether before another. here we consider an on - line algorithm for learning preference functions that is based on jacob freund and schapire's'hedge'algorithm. notably in the second stage, new instances are ordered so consistently as to maximize agreement with the chosen learned preference function. however we show that the inverse problem of finding the ordering that agrees best with a learned preference function is np - complete. lastly nevertheless, we describe those simple greedy algorithms that are guaranteed to find a good approximation. finally, we help show how generic metasearch can be formulated as an ordering generating problem, and present experimental results on learning since a combination of'search industry experts ', each of which is a domain - specific query expansion strategy for a strong web search engine.", "histories": [["v1", "Fri, 27 May 2011 01:54:11 GMT  (151kb)", "http://arxiv.org/abs/1105.5464v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["w w cohen", "r e schapire", "y singer"], "accepted": false, "id": "1105.5464"}, "pdf": {"name": "1105.5464.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["William W. Cohen", "Robert E. S hapire", "Yoram Singer"], "emails": [], "sections": [{"heading": "Journal of Arti ial Intelligen e Resear h 10 (1999) 243-270 Submitted 10/98; published 5/99", "text": "Learning to Order ThingsWilliam W. Cohen w ohen resear h.att. omRobert E. S hapire s hapire resear h.att. omYoram Singer singer resear h.att. omAT&T Labs, Shannon Laboratory, 180 Park AvenueFlorham Park, NJ 07932, USA Abstra tThere are many appli ations in whi h it is desirable to order rather than lassify in-stan es. Here we onsider the problem of learning how to order instan es given feedba kin the form of preferen e judgments, i.e., statements to the e e t that one instan e shouldbe ranked ahead of another. We outline a two-stage approa h in whi h one rst learns by onventional means a binary preferen e fun tion indi ating whether it is advisable to rankone instan e before another. Here we onsider an on-line algorithm for learning preferen efun tions that is based on Freund and S hapire's \\Hedge\" algorithm. In the se ond stage,new instan es are ordered so as to maximize agreement with the learned preferen e fun -tion. We show that the problem of nding the ordering that agrees best with a learnedpreferen e fun tion is NP- omplete. Nevertheless, we des ribe simple greedy algorithmsthat are guaranteed to nd a good approximation. Finally, we show how metasear h anbe formulated as an ordering problem, and present experimental results on learning a om-bination of \\sear h experts,\" ea h of whi h is a domain-spe i query expansion strategyfor a web sear h engine.1. Introdu tionWork in indu tive learning has mostly on entrated on learning to lassify. However, thereare many appli ations in whi h it is desirable to order rather than lassify instan es. Anexample might be a personalized email lter that prioritizes unread mail. Here we will onsider the problem of learning how to onstru t su h orderings given feedba k in theform of preferen e judgments, i.e., statements that one instan e should be ranked ahead ofanother.Su h orderings ould be onstru ted based on a learned probabilisti lassi er or regres-sion model and in fa t often are. For instan e, it is ommon pra ti e in information retrievalto rank do uments a ording to their probability of relevan e to a query, as estimated by alearned lassi er for the on ept \\relevant do ument.\" An advantage of learning orderingsdire tly is that preferen e judgments an be mu h easier to obtain than the labels requiredfor lassi ation learning.For instan e, in the email appli ation mentioned above, one approa h might be to rankmessages a ording to their estimated probability of membership in the lass of \\urgent\"messages, or by some numeri al estimate of urgen y obtained by regression. Suppose,however, that a user is presented with an ordered list of email messages, and ele ts to readthe third message rst. Given this ele tion, it is not ne essarily the ase that message threeis urgent, nor is there su\u00c6 ient information to estimate any numeri al urgen y measures. 1999 AI A ess Foundation and Morgan Kaufmann Publishers. All rights reserved.\nCohen, S hapire, & SingerHowever, it seems quite reasonable to infer that message three should have been rankedahead of the others. Thus, in this setting, obtaining preferen e information may be easierand more natural than obtaining the labels needed for a lassi ation or regression approa h.Another appli ation domain that requires ordering instan es is ollaborative ltering; see,for instan e, the papers ontained in Resni k and Varian (1997). In a typi al ollaborative ltering task, a user seeks re ommendations, say, on movies that she is likely to enjoy. Su hre ommendations are usually expressed as ordered lists of re ommended movies, produ edby ombining movie ratings supplied by other users. Noti e that ea h user's movie ratings an be viewed as a set of preferen e judgements. In fa t, interpreting ratings as preferen esis advantageous in several ways: for instan e, it is not ne essary to assume that a rating of\\7\" means the same thing to every user.In the remainder of this paper, we will investigate the following two-stage approa h tolearning how to order. In stage one, we learn a preferen e fun tion, a two-argument fun tionPREF(u; v) whi h returns a numeri al measure of how ertain it is that u should be rankedbefore v. In stage two, we use the learned preferen e fun tion to order a set of new instan esX; to a omplish this, we evaluate the learned fun tion PREF(u; v) on all pairs of instan esu; v 2 X, and hoose an ordering of X that agrees, as mu h as possible, with these pairwisepreferen e judgments.For stage one, we des ribe a spe i algorithm for learning a preferen e fun tion from aset of \\ranking-experts\". The algorithm is an on-line weight allo ation algorithm, mu h likethe weighted majority algorithm (Littlestone & Warmuth, 1994) and Winnow (Littlestone,1988), and, more dire tly, Freund and S hapire's (1997) \\Hedge\" algorithm. For stage two,we show that nding a total order that agrees best with su h a preferen e fun tion is NP- omplete. Nevertheless, we show that there are e\u00c6 ient greedy algorithms that always nda good approximation to the best ordering.We then present some experimental results in whi h these algorithm are used to ombinethe results of several \\sear h experts,\" ea h of whi h is a domain-spe i query expansionstrategy for a web sear h engine. Sin e our work tou hes several di erent elds we deferthe dis ussion of related work to Se . 6.2. PreliminariesLet X be a set of instan es. For simpli ity, in this paper, we always assume that X is nite. A preferen e fun tion PREF is a binary fun tion PREF : X X ! [0; 1\u2104. A value ofPREF(u; v) whi h is lose to 1 (respe tively 0) is interpreted as a strong re ommendationthat u should be ranked above (respe tively, below) v. A value lose to 1=2 is interpretedas an abstention from making a re ommendation. As noted earlier, the hypothesis of ourlearning system will be a preferen e fun tion, and new instan es will be ranked so as toagree as mu h as possible with the preferen es predi ted by this hypothesis.In standard lassi ation learning, a hypothesis is onstru ted by ombining primitivefeatures. Similarly, in this paper, a preferen e fun tion will be a ombination of primitivepreferen e fun tions. In parti ular, we will typi ally assume the availability of a set of Nprimitive preferen e fun tions R1; : : : ; RN . These an then be ombined in the usual ways,for instan e with a boolean or linear ombination of their values. We will be espe iallyinterested in the latter ombination method.244\nLearning to Order Things a\nb\nc\nd\na\nb\nc\nd\na\nb\nc\nd\n7/8\n7/81\n1/4\n1\n3/4\nf(a)=1 f(b)=2 f(c)=0 f(d)=\u22a5\ng(a)=0 g(b)=2 g(c)=1 g(d)=2\n1/8\n1/4f() + 3/4g()\n1/8\nFigure 1: Left and middle: Two ordering fun tions and their graph representation. Right:The graph representation of the preferen e fun tion reated by a weighted (14 and34) ombination of the two fun tions. Edges with weight of 12 or 0 are omitted.It is onvenient to assume that the Ri's are well-formed in ertain ways. To this end, weintrodu e a spe ial kind of preferen e fun tion alled a rank ordering whi h is de ned byan ordering fun tion. Let S be a totally ordered set. We assume without loss of generalitythat S R. An ordering fun tion into S is any fun tion f : X ! S, where we interpret aninequality f(u) > f(v) to mean that u is ranked above v by f . It is sometimes onvenientto allow an ordering fun tion to \\abstain\" and not give a preferen e for a pair u, v. Wetherefore allow S to in lude a spe ial symbol ? not in R, and we interpret f(u) = ? tomean that u is \\unranked.\" We de ne the symbol ? to be in omparable to all the elementsin S (that is, ? 6< s and s 6< ? for all s 2 S).An ordering fun tion f indu es the preferen e fun tion Rf , de ned asRf (u; v) = 8><>: 1 if f(u) > f(v)0 if f(u) < f(v)12 otherwise.We all Rf a rank ordering for X into S. If Rf (u; v) = 1, then we say that u is preferredto v, or u is ranked higher than v. Note that Rf (u; v) = 12 if either u or v (or both) isunranked.We will sometimes des ribe and manipulate preferen e fun tions as dire ted weightedgraphs. The nodes of a graph orrespond to the instan es in X. Ea h pair (u; v) is on-ne ted by a dire ted edge with weight PREF(u; v). Sin e an ordering fun tion f indu esa preferen e fun tion Rf , we an also des ribe ordering fun tions as graphs. In Fig. 1 wegive an example of two ordering fun tions and their orresponding graphs. For brevity, wedo not draw edges (u; v) su h that PREF(u; v) = 12 or PREF(u; v) = 0.To give a on rete example of rank orderings, imagine learning to order do umentsbased on the words that they ontain. To model this, let X be the set of all do uments ina repository, and for N words w1; : : : ; wN , let fi(u) be the number of o urren es of wordwi in do ument u. Then Rfi will prefer u to v whenever wi o urs more often in u than v.As a se ond example, onsider a metasear h appli ation in whi h the goal is to ombine the245\nCohen, S hapire, & Singerrankings of several web sear h engines on some xed query. For N sear h engines e1; : : : ; eN ,one might de ne fi so that Rfi prefers web page u to web page v whenever u is rankedahead of v in the list Li produ ed by the orresponding sear h engine. To do this, one ouldlet fi(u) = k for the web page u appearing in the k-th position in the list Li, and letfi(u) = M (where M > jLij) for any web page u not appearing in Li.Feedba k from the user will be represented in a similar but more general way. We willassume that feedba k is a set element pairs (u; v), ea h representing an assertion of the form\\u should be preferred to v.\" This de nition of feedba k is less restri ted than orderingfun tions. In parti ular, we will not assume that the feedba k is onsistent| y les, su h asa > b > a, will be allowed.3. Learning a Combination of Ordering Fun tionsIn this se tion, we onsider the problem of learning a good linear ombination of a set ofordering fun tions. Spe i ally, we assume a ess to a set of ranking experts, ea h of whi hgenerates an ordering fun tion when provided with a set of instan es. For instan e, in ametasear h problem, ea h ranking expert might be a fun tion that submits the user's queryto a di erent sear h engine; the domain of instan es might be the set of all web pagesreturned by any of the ranking experts; and the ordering fun tion asso iated with ea hranking expert might be represented as in the example above (i.e., letting fi(u) = k forthe k-the web page u returned by i-th sear h engine, and letting fi(u) = M for any webpage u not retrieved by the i-th sear h engine). The user's feedba k will be a set of pairwisepreferen es between web pages. This feedba k may be obtained dire tly, for example, byasking the user to expli itly rank the URL's returned by the sear h engine; or the feedba kmay be obtained indire tly, for example, by measuring the time spent viewing ea h of thereturned pages.We note that for the metasear h problem, an approa h that works dire tly with thenumeri al s ores asso iated with the di erent sear h engines might not be feasible; thesenumeri al s ores might not be omparable a ross di erent sear h engines, or might notbe provided by all sear h engines. Another problem is that most web pages will not beindexed by all sear h engines. This an be easily modeled in our setting: rather thanletting fi(u) = M for a web page u that is not ranked by sear h engine i, one ould letfi(u) = ?. This orresponds to the assumption that the sear h engine's preferen e for urelative to ranked web pages is unknown.We now des ribe a weight allo ation algorithm that uses the preferen e fun tions Ri tolearn a preferen e fun tion of the form PREF(u; v) =PNi=1wiRi(u; v). We adopt the on-linelearning framework rst studied by Littlestone (1988) in whi h the weight wi assigned toea h ranking expert i is updated in rementally.Formally, learning is assumed to take pla e in a sequen e of rounds. On ea h round t, weassume the learning algorithm is provided with a set Xt of instan es to be ranked, for whi hea h ranking expert i 2 f1; : : : ; Ng provides an ordering fun tion f ti . (In metasear h, forinstan e, f ti is the ordering fun tion asso iated with the list Lti of web pages returned by thei-th ranking expert for the t-th query, and Xt is the set of all web pages that appear in anyof the lists Lt1; : : : ; LtN .) Ea h ordering fun tion f ti indu es a preferen e fun tion Rfti , whi hwe denote for brevity by Rti. The learner may ompute Rti(u; v) for any and all preferen e246\nLearning to Order Thingsfun tions Rti and pairs u; v 2 Xt before produ ing a ombined preferen e fun tion PREFt,whi h is then used to produ e an ordering \u0302t of Xt. (Methods for produ ing an orderingfrom a preferen e fun tion will be dis ussed below.)After produ ing the ordering \u0302t, the learner re eives feedba k from the environment.We assume that the feedba k is an arbitrary set of assertions of the form \\u should bepreferred to v.\" That is, the feedba k on the t-th round is a set F t of pairs (u; v).The algorithm we propose for this problem is based on the \\weighted majority algo-rithm\" of Littlestone and Warmuth (1994) and, more dire tly, on Freund and S hapire's(1997) \\Hedge\" algorithm. We de ne the loss of a preferen e fun tion R with respe t tothe user's feedba k F asLoss(R;F ) = P(u;v)2F (1 R(u; v))jF j = 1 1jF j X(u;v)2F R(u; v) : (1)This loss has a natural probabilisti interpretation. IfR is viewed as a randomized predi tionalgorithm that predi ts that u will pre ede v with probabilityR(u; v), then Loss(R;F ) is theprobability of R disagreeing with the feedba k on a pair (u; v) hosen uniformly at randomfrom F .It is worth noting that the assumption on the form of the feedba k an be further relaxedby allowing the user to indi ate the degree to whi h she prefers u over v. In this ase, theloss should be normalized by the weighted sum of feedba k pairs. Sin e this generalizationis rather straightforward, we assume for brevity that the feedba k is an unweighted set ofassertions over element pairs.We now an use the Hedge algorithm almost verbatim, as shown in Figure 2. Thealgorithm maintains a positive weight ve tor whose value at time t is denoted by wt =(wt1; : : : ; wtN ). If there is no prior knowledge about the ranking experts, we set all initialweights to be equal so that w1i = 1=N .On ea h round t, the weight ve tor wt is used to ombine the preferen e fun tions of thedi erent experts to obtain the preferen e fun tion PREFt(u; v) = PNi=1wtiRti(u; v). Thispreferen e fun tion is next onverted into an ordering \u0302t on the urrent set of elementsXt. For the purposes of this se tion, the method of produ ing an ordering is immaterial; inparti ular, any of the methods des ribed in Se . 4 ould be used here. Based on this ordering,the user provides feedba k F t, and the loss for ea h preferen e fun tion Loss(Rti; F t) isevaluated as in Eq. (1). Finally, the weight ve tor wt is updated using the multipli ativerule wt+1i = wti Loss(Rti ;F t)Ztwhere 2 [0; 1\u2104 is a parameter, and Zt is a normalization onstant, hosen so that theweights sum to one after the update. Thus, in ea h round, the weights of the rankingexperts are adjusted so that experts produ ing preferen e fun tions with relatively largeagreement with the feedba k are in reased.We now give the theoreti al rationale behind this algorithm. Freund and S hapire (1997)prove general results about Hedge whi h an be applied dire tly to this loss fun tion. Theirresults imply almost immediately a bound on the umulative loss of the preferen e fun tionPREFt in terms of the loss of the best ranking expert, spe i ally:247\nCohen, S hapire, & SingerAllo ate Weights for Ranking ExpertsParameters: 2 [0; 1\u2104, initial weight ve tor w1 2 [0; 1\u2104N with PNi=1 w1i = 1N ranking experts, number of rounds TDo for t = 1; 2; : : : ; T1. Re eive a set of elements Xt and ordering fun tions f t1; : : : ; f tN . Let Rti denote thepreferen e fun tion indu ed by f ti .2. Compute a total order \u0302t whi h approximatesPREFt(u; v) = NXi=1wtiRti(u; v)(Se . 4 des ribes several ways of approximating a preferen e fun tion with a totalorder.)3. Order Xt using \u0302t.4. Re eive feedba k F t from the user.5. Evaluate losses Loss(Rti; F t) as de ned in Eq. (1).6. Set the new weight ve tor wt+1i = wti Loss(Rti ;F t)Ztwhere Zt is a normalization onstant, hosen so that PNi=1 wt+1i = 1.Figure 2: The on-line weight allo ation algorithm.Theorem 1 For the algorithm of Fig. 2,TXt=1 Loss(PREFt; F t) a mini TXt=1 Loss(Rti; F t) + lnNwhere a = ln(1= )=(1 ) and = 1=(1 ).Note that Pt Loss(PREFt; F t) is the umulative loss of the ombined preferen e fun -tions PREFt, and Pt Loss(Rti; F t) is the umulative loss of the ith ranking expert. Thus,Theorem 1 states that the umulative loss of the ombined preferen e fun tions will not bemu h worse than that of the best ranking expert.Proof: We have thatLoss(PREFt; F t) = 1 1F t X(u;v)2F tXi wtiRti(u; v)= Xi wti 0 1 1F t X(u;v)2F t Rti(u; v)1A248\nLearning to Order Things= Xi wtiLoss(Rti(u; v); F t):Therefore, by Freund and S hapire's (1997) Theorem 2,TXt=1 Loss(PREFt; F t) = TXt=1Xi wtiLoss(Rti(u; v); F t) a mini TXt=1 Loss(Rti; F t) + lnN:2Of ourse, we are not interested in the loss of PREFt (sin e it is not an ordering), butrather in the performan e of the a tual ordering \u0302t omputed by the learning algorithm.Fortunately, the losses of these an be related using a kind of triangle inequality. LetDISAGREE( ;PREF) = Xu;v: (u)> (v)(1 PREF(u; v)) : (2)Theorem 2 For any PREF, F and total order de ned by an ordering fun tion ,Loss(R ; F ) DISAGREE( ;PREF)jF j +Loss(PREF; F ): (3)Proof: For x; y 2 [0; 1\u2104, let us de ne d(x; y) = x(1 y) + y(1 x). We now showthat d satis es the triangle inequality. Let x, y and z be in [0; 1\u2104, and let X, Y and Z beindependent Bernoulli (f0; 1g-valued) random variables with probability of out ome 1 equalto x, y and z, respe tively. Thend(x; z) = Pr[X 6= Z\u2104= Pr[(X 6= Y ^ Y = Z) _ (X = Y ^ Y 6= Z)\u2104 Pr[X 6= Y _ Y 6= Z\u2104 Pr[X 6= Y \u2104 + Pr[Y 6= Z\u2104= d(x; y) + d(y; z):For [0; 1\u2104-valued fun tions f; g de ned on X X, we next de neD(f; g) = Xu;v:u6=v d(f(u; v); g(u; v)):Clearly, D also satis es the triangle inequality.Let F be the hara teristi fun tion of F so that F : X X ! f0; 1g and F (u; v) = 1if and only if (u; v) 2 F . Then from the de nition of Loss and DISAGREE, we havejF j Loss(R ; F ) = D(R ; F ) D(R ;PREF) +D(PREF; F )= DISAGREE( ;PREF) + jF j Loss(PREF; F ):2Noti e that the learning algorithm Hedge minimizes the se ond term on the right handside of Eq. (3). Below, we onsider the problem of nding an ordering whi h minimizesthe rst term, namely, DISAGREE. 249\nCohen, S hapire, & Singer4. Ordering Instan es with a Preferen e Fun tion4.1 Measuring the Quality of an OrderingWe now onsider the omplexity of nding a total order that agrees best with a learnedpreferen e fun tion. To analyze this, we must rst quantify the notion of agreement betweena preferen e fun tion PREF and an ordering. One natural notion is the following: Let Xbe a set, PREF be a preferen e fun tion, and let be a total ordering of X, expressed againas an ordering fun tion (i.e., (u) > (v) if and only if u is above v in the order). Forthe analysis of this se tion, it is onvenient to use the measure AGREE( ;PREF), whi h isde ned to be the sum of PREF(u; v) over all pairs u; v su h that u is ranked above v by :AGREE( ;PREF) = Xu;v: (u)> (v)PREF(u; v): (4)Clearly, AGREE is a linear transformation of the measure DISAGREE introdu ed in Eq. (2),and hen e maximizing AGREE is equivalent to minimizing DISAGREE. This de nition isalso losely related to similarity metri s used in de ision theory and information pro ess-ing (Kemeny & Snell, 1962; Fishburn, 1970; Roberts, 1979; Fren h, 1989; Yao, 1995) (seethe dis ussion in Se . 6).4.2 Finding an Optimal Ordering is HardIdeally one would like to nd a that maximizes AGREE( ;PREF). The general opti-mization problem is of little interest in our setting, sin e there are many onstraints on thepreferen e fun tion that are imposed by the learning algorithm. Using the learning algo-rithm of Se . 3, for instan e, PREF will always be a linear ombination of simpler fun tions.However, the theorem below shows that this optimization problem is NP- omplete even ifPREF is restri ted to be a linear ombination of well-behaved preferen e fun tions. In par-ti ular, the problem is NP- omplete even if all the primitive preferen e fun tions used inthe linear ombination are rank orderings whi h map into a set S with only three elements,one of whi h may or may not be ?. (Clearly, if S onsists of more than three elements thenthe problem is still hard.)Theorem 3 The following de ision problem is NP- omplete for any set S with jSj 3:Input: A rational number ; a set X; a olle tion of N ordering fun tions fi : X ! S;and a preferen e fun tion PREF de ned asPREF(u; v) = NXi=1wiRfi(u; v) (5)where w = (w1; : : : ; wN ) is a rational weight ve tor in [0; 1\u2104N with PNi=1 wi = 1.Question: Does there exist a total order su h that AGREE( ;PREF) ?Proof: The problem is learly in NP sin e a nondeterministi algorithm an guess a totalorder and he k the weighted number of agreements in polynomial time.To prove that the problem is NP-hard we redu e from CYCLIC-ORDERING (Galil &Megido, 1977; Gary & Johnson, 1979), de ned as follows: \\Given a set A and a olle tion250\nLearning to Order ThingsC of ordered triples (a; b; ) of distin t elements from A, is there a one-to-one fun tionf : A! f1; 2; : : : ; jAjg su h that for ea h (a; b; ) 2 C we have either f(a) > f(b) > f( ) orf(b) > f( ) > f(a) or f( ) > f(a) > f(b)?\"Without loss of generality, S is either f0; 1;?g or f0; 1; 2g. We rst show that theproblem of nding an optimal total order is hard when S = f0; 1;?g. Given an instan e ofCYCLIC-ORDERING, we let X = A. For ea h triplet t = (a; b; ) we will introdu e threeordering fun tions ft;1, ft;2, and ft;3, and de ne them so that ft;1(a) > ft;1(b), ft;2(b) >ft;2( ), and ft;3( ) > ft;3(a). To do this, we let ft;1(a) = ft;2(b) = ft;3( ) = 1, ft;1(b) =ft;2( ) = ft;3(a) = 0, and ft;i( ) = ? in all other ases. We let the weight ve tor be uniform,so that wt;i = 13jCj . Let = 53 + jAj(jAj 1)=2 32 :De ne Rt(u; v) =P3i=1 wt;iRft;i(u; v), whi h is the ontribution of these three fun tionsto PREF(u; v). Noti e that for any triplet t = (a; b; ) 2 C, Rt(a; b) = 23jCj whereasRt(b; a) = 13jCj , and similarly for b; and ; a. In addition, for any pair u; v 2 A su h thatat least one of them does not appear in t, we get that Rt(u; v) = 12jCj . Sin e a total order an satisfy at most two of the three onditions (a) > (b), (b) > ( ), and ( ) > (a),the largest possible weighted number of agreements asso iated with this triple is exa tly =jCj.If the number of weighted agreements is at least , it must be exa tly , by the argumentabove; and if there are exa tly weighted agreements, then the total order must satisfyexa tly 2 out of the possible 3 relations for ea h three elements that form a triplet fromC. Thus, the onstru ted rank ordering instan e will be positive if and only if the originalCYCLIC-ORDERING instan e is positive.The ase for S = f0; 1; 2g uses a similar onstru tion; however, for ea h triplet t =(a; b; ), we de ne six ordering fun tions, f jt;1, f jt;2, and f jt;3, where j 2 f0; 1g. The basi idea here is to repla e ea h ft;i with two fun tions, f0t;i and f1t;i, that agree on the singleordering onstraint asso iated with ft;i, but disagree on all other orderings. For instan e,we will de ne these fun tions so that f jt;1(a) > f jt;1(b) for j = 0 and j = 1, but for all otherpairs u; v, f1t;1(u) > f1t;1(v) i f0t;1(v) > f0t;1(u). Averaging the two orderings f0t;1 and f1t;1will thus yield the same preferen e expressed by the original fun tion ft;1 (i.e., a preferen efor a > b only).In more detail, we let f jt;1(a) = f jt;2(b) = f jt;3( ) = 2 j, f jt;1(b) = f jt;2( ) = f jt;3(a) = 1 j,and f jt;i( ) = 2j in all other ases. We again let the weight ve tor be uniform, so thatwjt;i = 16jCj . Similar to the rst ase, we de ne Rt(u; v) = Pi;j wt;iRfjt;i(u; v). It an beveri ed that Rt is identi al to the Rt onstru ted in the rst ase. Therefore, by the sameargument, the onstru ted rank ordering instan e will be positive if and only if the originalCYCLIC-ORDERING instan e is positive. 2Although this problem is hard when jSj 3, the next theorem shows that it be omestra table for linear ombinations of rank orderings into a set S of size two. Of ourse, whenjSj = 2, the rank orderings are really only binary lassi ers. The fa t that this spe ial ase is tra table unders ores the fa t that manipulating orderings (even relatively simple251\nCohen, S hapire, & Singerones) an be omputationally more di\u00c6 ult than performing the orresponding operationson binary lassi ers.Theorem 4 The following optimization problem is solvable in linear time:Input: A set X; a set S with jSj = 2; a olle tion of N ordering fun tions fi : X ! S;and a preferen e fun tion PREF de ned by Eq. (5).Output: A total order de ned by an ordering fun tion whi h maximizesAGREE( ;PREF).Proof: Assume without loss of generality that the two-element set S is f0; 1g, andde ne (u) =Piwifi(u). We now show that any total order1 onsistent with maximizesAGREE( ;PREF). Fix a pair u; v 2 X and letqb1b2 = Xi s.t. fi(u)=b1;fi(v)=b2 wi :We an now rewrite and PREF as (u) = q10 + q11 PREF(u; v) = q10 + 12q11 + 12q00 (v) = q01 + q11 PREF(v; u) = q01 + 12q11 + 12q00 :Note that both (u) (v) and PREF(u; v) PREF(v; u) are equal to q10 q01. Hen e, if (u) > (v) then PREF(u; v) > PREF(v; u). Therefore, for ea h pair u; v 2 X, the orderde ned by agrees on all pairs with the pairwise preferen e de ned by PREF. In otherwords, we have shown thatAGREE( ;PREF) = Xfu;vgmaxfPREF(u; v);PREF(v; u)g (6)where the sum is over all unordered pairs. Clearly, the right hand side of Eq. (6) maximizesthe right hand side of Eq. (4) sin e at most one of (u; v) or (v; u) an be in luded in thelatter sum. 24.3 Finding an Approximately Optimal OrderingTheorem 3 implies that we are unlikely to nd an e\u00c6 ient algorithm that nds the optimaltotal order for a weighted ombination of rank orderings. Fortunately, there do exist e\u00c6- ient algorithms for nding an approximately optimal total order. In fa t, nding a goodtotal order is losely related to the problem of nding the minimum feedba k ar set, forwhi h there exist good approximation algorithms; see, for instan e, (Shmoys, 1997) andthe referen es therein. However, the algorithms that a hieve the good approximation re-sults for the minimum feedba k ar set problem are based on (or further approximate) alinear-programming relaxation (Seymour, 1995; Even, Naor, Rao, & S hieber, 1996; Berger& Shor, 1997; Even, Naor, S hieber, & Sudan, 1998) whi h is rather omplex to implementand quite slow in pra ti e.1. Noti e that in ase of a tie, so that (u) = (v) for distin t u; v, de nes only a partial order. Thetheorem holds for any total order whi h is onsistent with this partial order, i.e., for any 0 so that (u) > (v)) 0(u) > 0(v). 252\nLearning to Order Things Algorithm Greedy-OrderInputs: an instan e set X; a preferen e fun tion PREFOutput: an approximately optimal ordering fun tion \u0302let V = Xfor ea h v 2 V do (v) =Pu2V PREF(v; u) Pu2V PREF(u; v)while V is non-empty dolet t = argmaxu2V (u)let \u0302(t) = jV jV = V ftgfor ea h v 2 V do (v) = (v) + PREF(t; v) PREF(v; t)endwhile Figure 3: The greedy ordering algorithm.We des ribe instead a simple greedy algorithm whi h is very simple to implement. Fig-ure 3 summarizes the greedy algorithm. As we will shortly demonstrate, this algorithmprodu es a good approximation to the best total order.The algorithm is easiest to des ribe by thinking of PREF as a dire ted weighted graph,where initially, the set of verti es V is equal to the set of instan es X, and ea h edge u! vhas weight PREF(u; v). We assign to ea h vertex v 2 V a potential value (v), whi h is theweighted sum of the outgoing edges minus the weighted sum of the ingoing edges. That is, (v) = Xu2V PREF(v; u) Xu2V PREF(u; v) :The greedy algorithm then pi ks some node t that has maximum potential2, and assigns ita rank by setting \u0302(t) = jV j, e e tively ordering it ahead of all the remaining nodes. Thisnode, together with all in ident edges, is then deleted from the graph, and the potentialvalues of the remaining verti es are updated appropriately. This pro ess is repeateduntil the graph is empty. Noti e that nodes removed in subsequent iterations will haveprogressively smaller and smaller ranks.As an example, onsider the preferen e fun tion de ned by the leftmost graph of Fig. 4.(This graph is identi al to the weighted ombination of the two ordering fun tions fromFig. 1.) The initial potentials the algorithm assigns are: (b) = 2, (d) = 3=2, ( ) = 5=4,and (a) = 9=4. Hen e, b has maximal potential. It is given a rank of 4, and then node band all in ident edges are removed from the graph.The result is the middle graph of Fig. 4. After deleting b, the potentials of the remainingnodes are updated: (d) = 3=2, ( ) = 1=4, and (a) = 5=4. Thus, d will be assignedrank jV j = 3 and removed from the graph, resulting in the rightmost graph of Fig. 4.After updating potentials again, ( ) = 1=2 and (a) = 1=2. Now will be assignedrank jV j = 2 and removed, resulting in a graph ontaining the single node a, whi h will2. Ties an be broken arbitrarily in ase of two or more nodes with the same potential.253\nCohen, S hapire, & Singer a\nb\nc\nd\n7/8\n7/81\n1/4\n1\n3/4\n1/8\n1/8 a c\nd\n7/8\n7/8\n1/4\n3/4\n1/8\n1/8 a c\n1/4\n3/4\nFigure 4: Behavior of the greedy ordering algorithm. The leftmost graph is the originalinput. From this graph, node b will be assigned maximal rank and deleted,leading to the middle graph; from this graph, node d will deleted, leading to therightmost graph. In the rightmost graph, node will be ranked ahead of node a,leading the total ordering b > d > > a. nally be assigned the rank jV j = 1. The ordering produ ed by the greedy algorithm isthus b > d > > a.The next theorem shows that this greedy algorithm omes within a fa tor of two ofoptimal.Theorem 5 Let OPT(PREF) be the weighted agreement a hieved by an optimal total orderfor the preferen e fun tion PREF, and let APPROX(PREF) be the weighted agreementa hieved by the greedy algorithm. ThenAPPROX(PREF) 12OPT(PREF) :Proof: Consider the edges that are in ident on the node vj whi h is sele ted on thej-th repetition of the while loop of Figure 3. The ordering produ ed by the algorithm willagree with all of the outgoing edges of vj and disagree with all of the ingoing edges. Letaj be the sum of the weights of the outgoing edges of vj, and dj be the sum of the weightsof the ingoing edges. Clearly APPROX(PREF) PjV jj=1 aj. However, at every repetition,the total weight of all in oming edges must equal the total weight of all outgoing edges.This means that Pv2V (v) = 0, and hen e for the node v? that has maximal potential, (v?) 0. Thus on every repetition j, it must be that aj dj , so we have thatOPT(PREF) jV jXj=1(aj + dj) jV jXj=1(aj + aj) 2 APPROX(PREF):The rst inequality holds be ause OPT(PREF) an at best in lude every edge in the graph,and sin e every edge is removed exa tly on e, ea h edge must ontribute to some aj or somedj . 2 254\nLearning to Order Things 2k+3 k+2 k+3 k+1 1 2 k k+1\n1 2 k\nk+2\n2k+3Figure 5: An example of a graph (left) for whi h the node-based greedy algorithm a hievesan approximation fa tor of 12 by onstru ting the partial order on the right.In passing, we note that there are other natural greedy algorithms that do not a hievegood approximations. Consider, for example, an algorithm that starts from a graph on-sisting of all the nodes but with no edges, and iteratively adds the highest weighted edge inthe graph, while avoiding y les. It an be shown that this algorithm an produ e a verypoor partial order, given an adversarially hosen graph; there are ases where the optimaltotal order a hieves a multipli ative fa tor of O(jV j) more weighted agreements than this\\edge-based\" greedy algorithm.4.4 Improvements to the Greedy AlgorithmThe approximation fa tor of two given in Theorem 5 is tight. That is, there exist problemsfor whi h the greedy algorithm approximation is worse than the optimal solution by afa tor arbitrarily lose to two. Consider the graph shown on the left-hand side of Fig. 5. Anoptimal total order ranks the instan es a ording to their position in the gure, left to right,breaking ties randomly, and a hieves OPT(PREF) = 2k+2 weighted agreements. However,the greedy algorithm pi ks the node labeled k + 1 rst and orders all the remaining nodesrandomly, a hieving as few as APPROX(PREF) = k+2 agreements. For large k, the ratioAPPROX(PREF)=OPT(PREF) approa hes 12 .For graph of Figure 5, there is another simple algorithm whi h produ es an optimalordering: sin e the graph is already a partial order, pi king any total order onsistent withthis partial order gives an optimal result. To ope with problems su h as the one of Figure 5,we devised an improvement to the greedy algorithm whi h ombines a greedy method withtopologi al sorting. The aim of the improvement is to nd better approximations for graphswhi h are omposed of many strongly onne ted omponents.As before, the modi ed algorithm is easiest to des ribe by thinking of PREF as aweighted dire ted graph. Re all that for ea h pair of nodes u and v, there exist two edges:one from u to v with weight PREF(u; v) and one from v to u with weight PREF(v; u). Inthe modi ed greedy algorithm we will pre-pro ess the graph. For ea h pair of nodes, we255\nCohen, S hapire, & SingerAlgorithm SCC-Greedy-OrderInputs: an instan e set X; a preferen e fun tion PREFOutput: an approximately optimal ordering fun tion \u0302De ne PREF0(u; v) = maxfPREF(u; v) PREF(v; u); 0g :Find strongly onne ted omponents U1; : : : ; Uk of the graph G = (V;E) whereV = X and E = f(u; v) j PREF0(u; v) > 0g :Order the strongly onne ted omponents in any way onsistent with the partial order<s : U <s U 0 i 9u 2 U; u0 2 U 0 : (u; u0) 2 EUse algorithm Greedy-Order or full enumeration to order the instan es within ea h om-ponent Ui a ording to PREF0.Figure 6: The improved greedy ordering algorithm.remove the edge with the smaller weight and set the weight of the other edge to bej PREF(v; u) PREF(u; v) j :For the spe ial ase where PREF(v; u) = PREF(u; v) = 12 , we remove both edges. In theredu ed graph, there is at most one dire ted edge between ea h pair of nodes. Note thatthe greedy algorithm would behave identi ally on the transformed graph sin e it is basedon the weighted di eren es between the in oming and outgoing edges.We next nd the strongly onne ted omponents3 of the redu ed graph, ignoring (fornow) the weights. One an now split the edges of the redu ed graph into two lasses: inter- omponent edges onne t nodes u and v, where u and v are in di erent strongly onne ted omponents; and intra- omponent edges onne t nodes u and v from the same strongly onne ted omponent. It is straightforward to verify that any optimal order agrees with allthe inter- omponent edges. Put another way, if there is an edge from node u to node v oftwo di erent onne ted omponents in the redu ed graph, then (u) > (v) for any optimaltotal order .The rst step of the improved algorithm is thus to totally order the strongly onne ted omponents in some way onsistent with the partial order de ned by the inter- omponentedges. More pre isely, we pi k a total ordering for the omponents onsistent with thepartial order <s , de ned as follows: for omponents U and U 0, U <s U 0 i there is anedge from some node u 2 U to some node u0 2 U 0 in the redu ed graph.We next order the nodes within ea h strongly onne ted omponent, thus providing atotal order of all nodes. Here the greedy algorithm an be used. As an alternative, in ases where a omponent ontains only a few elements (say at most ve), one an nd theoptimal order between the elements of the omponent by a brute-for e approa h, i.e., byfull enumeration of all permutations.3. Two nodes u and v are in the same strongly onne ted omponent i there are dire ted paths from u tov and from v to u. 256\nLearning to Order Things a b\nc d\n0.55\n0.45\n0.95\n0.05\n0.65 0.35\n0.4 0.6\n0.5\n0.5\n0.55 0.45 ) a b c d 0.1 0.9 0.3\n0.2\n0.1 ) a b c d 0.1 0.9 0.3\n0.2\n0.1\n0.1\n0.3\n0.2\nb c d a 0.9Figure 7: An illustration of the approximation algorithm for nding a total order froma weighted ombination of ordering fun tions. The original graph (top left) isredu ed by removing at least one edge for ea h edge-pair (u; v) and (v; u) (middle).The strongly onne ted omponents are then found (right). Finally, an orderingis found within ea h strongly onne ted omponent whi h yield the order b > >d > a (bottom).The improved algorithm is summarized in Figure 6 and illustrated in Figure 7. Thereare four elements in Figure 7 whi h onstitute two strongly onne ted omponents in theredu ed graph (fbg and fa; ; dg). Therefore, b is assigned the top rank and ranked abovea, and d. If the brute-for e algorithm were used to order the omponents, then we would he k all 3! permutations between a, and d and output the total order b > > d > a,whi h is the optimal order in this toy example.In the worst ase, the redu ed graph ontains only a single strongly onne ted om-ponent. In this ase, the improved algorithm generates the same ordering as the greedyalgorithm. However, in the experiments on metasear h problems des ribed in Se . 5, manyof the strongly onne ted omponents are small; the average size of a strongly onne ted omponent is less than ve. In ases su h as these, the improved algorithm will oftenimprove on the simple greedy algorithm.4.5 Experiments with the Ordering AlgorithmsIdeally, ea h algorithm would be evaluated by determining how losely it approximates theoptimal ordering on large, realisti problems. Unfortunately, nding the optimal orderingfor large graphs is impra ti al. We thus performed two sets of experiments with the orderingalgorithms des ribed above. In the rst set of experiments, we evaluated the algorithms onsmall graphs|spe i ally, graphs for whi h the optimal ordering ould be feasibly foundwith brute-for e enumeration. In these experiments, we measure the \\goodness\" of theresulting orderings relative to the optimal ordering. In the se ond set of experiments, weevaluated the algorithms on large graphs for whi h the optimal orderings are unknown. Inthese experiments, we ompute a \\goodness\" measure whi h depends on the total weightof all edges, rather than the optimal ordering.257\nCohen, S hapire, & SingerIn addition to the simple greedy algorithm and its improvement, we also onsidered thefollowing simple randomized algorithm: pi k a permutation at random, and then outputthe better of that permutation and its reverse. It an be easily shown that this algorithma hieves the same approximation bound on expe ted performan e as the greedy algorithm.(Brie y, one of the two permutations must agree with at least half of the weighted edgesin the graph.) The random algorithm an be improved by repeating the pro ess, i.e.,examining many random permutations and their reverses, and hoosing the permutationthat a hieves the largest number of weighted agreements.In a rst set of experiments, we ompared the performan e of the greedy approximationalgorithm, the improved algorithm whi h rst nds strongly onne ted omponents, and therandomized algorithm on graphs of nine or fewer elements. For ea h number of elements, wegenerated 10;000 random graphs by hoosing PREF(u; v) uniformly at random, and settingPREF(v; u) to 1 PREF(u; v). For the randomized algorithm, we evaluated 10n randompermutations (and their reverses) where n is the number of instan es (nodes). To havea fair omparison between the di erent algorithms on the smaller graphs, we always usedthe greedy algorithm (rather than a brute-for e algorithm) to order the elements of ea hstrongly onne ted omponent of a graph.To evaluate the algorithms, we examined the redu ed graph and al ulated the averageratio of the weights of the edges hosen by the approximation algorithm to the weights ofthe edges that were hosen by the optimal order. More pre isely, let be the optimal orderand \u0302 be an order hosen by an approximation algorithm. Then for ea h random graph, we al ulated Xu; v : \u0302(u) > \u0302(v) maxfPREF(u; v) PREF(v; u); 0gXu; v : (u) > (v) maxfPREF(u; v) PREF(v; u); 0g :If this measure is 0.9, for instan e, then the total weight of the edges in the total orderpi ked by the approximation algorithm is 90% of the orresponding gure for the optimalalgorithm.We averaged the above ratios over all random graphs of the same size. The resultsare shown on the left hand side of Figure 8. On the right hand side of the gure, weshow the average running time for ea h of the algorithms as a fun tion of the number ofelements. When the number of ranked elements is more than ve, the greedy algorithmsoutperform the randomized algorithm, while their running time is mu h smaller. Thus, ifa full enumeration had been used to nd the optimal order of small strongly onne ted omponents, the approximation would have been onsistently better than the randomizedalgorithm.We note that the greedy algorithm also generally performs better on average thanthe lower bound given in Theorem 5. In fa t, ombining the greedy algorithm with pre-partitioning of the graph into strongly onne ted omponents often yields the optimal order.In the se ond set of experiments, we measured performan e and running time for largerrandom graphs. Sin e for large graphs we annot nd the optimal solution by brute-for eenumeration, we use as a \\goodness\" measure the ratio of the weights of the edges that wereleft in the redu ed graph after applying an approximation algorithm to the total weight of258\nLearning to Order Things\n5 10 15 20 25 30\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\n0.95\nNumber of elements\nF ra\nct io\nn of\nto ta\nl w ei\ngh t\nGreedy SCC + Greedy Randomized\n5 10 15 20 25 30\n0\n0.05\n0.1\n0.15\n0.2\n0.25\n0.3\n0.35\n0.4\n0.45\nNumber of elements\nR un\nni ng\nti m\ne (s\nec on\nds )\nGreedy SCC + Greedy Randomized\nFigure 9: Comparison of goodness (left) and the running time (right) of the approximationsa hieved by the greedy algorithms and the randomized algorithm as a fun tion ofthe number of ranked elements for random preferen e fun tions with 3 through 30elements. Note that the graphs for Greedy and SCC+Greedy oin ide for mostof the points. 259\nCohen, S hapire, & Singeredges in the graph. That is, for ea h random graph we al ulatedXu; v : \u0302(u) > \u0302(v) maxfPREF(u; v) PREF(v; u); 0gXu; vmaxfPREF(u; v) PREF(v; u); 0g :We ran the three algorithms with the same parameters as above (i.e., 10;000 randomgraphs). The results are given in Figure 9. The advantage of the greedy algorithms overthe randomized algorithm is even more apparent on these larger problems. Note also thatfor large graphs the performan e of the two greedy algorithms is indistinguishable. This ismainly due to the fa t that large random graphs are strongly onne ted with high proba-bility.To summarize the experiments, when there are six or more elements the greedy algorithm learly outperforms the randomized algorithm even if many randomly hosen permutationsare examined. Furthermore, the improved algorithm whi h rst nds the strongly onne ted omponents outperforms the randomized algorithm for all graph sizes. In pra ti e theimproved greedy algorithm a hieves very good approximations|within about 5 per ent ofoptimal, for the ases in whi h optimal graphs an be feasibly found.5. Experimental Results for Metasear hSo far, we have des ribed a method for learning a preferen e fun tion, and a means of onverting a preferen e fun tion into an ordering of new instan es. We will now presentsome experimental results in learning to order. In parti ular, we will des ribe results onlearning to ombine the orderings of several web \\sear h experts\" using the algorithm ofFigure 2 to learn a preferen e fun tion, and the simple greedy algorithm to order instan esusing the learned preferen e fun tion. The goals of these experiments are to illustrate thetype of problems that an be solved with our method; to empiri ally evaluate the learningmethod; to evaluate the ordering algorithm on large, non-random graphs, su h as might arisein a realisti appli ation; and to on rm the theoreti al results of the pre eding se tions.We thus restri t ourselves to omparing the learned orderings to individual sear h experts,as is suggested by Theorem 1, rather than attempt to ompare this appli ation of learning-to-order with previous experimental te hniques for metasear h, e.g., (Lo hbaum & Streeter,1989; Kantor, 1994; Boyan, Freitag, & Joa hims, 1994; Bartell, Cottrell, & Belew, 1994).We note that this metasear h problem exhibits several properties that suggest a generalapproa h su h as ours. For instan e, approa hes that learn to ombine similarity s oresare not appli able, sin e the similarity s ores of web sear h engines are often unavailable.In the experiments presented here, the learning algorithm was provided with ordered listsfor ea h sear h engine without any asso iated s ores. To further demonstrate the merits ofour approa h, we also des ribe experiments with partial feedba k|that is, with preferen ejudgments that are less informative than the relevan e judgments more typi ally used inimproving sear h engines. 260\nLearning to Order Things ML Sear h Experts UNIV Sear h ExpertsNAME NAME\\NAME\" \\NAME\"title:\\NAME\" \\NAME\" PLACENAME +LASTNAME title:\\home page\" title:NAMENAME +LASTNAME title:homepage title:\\NAME\"NAME +LASTNAME ma hine learning title:\\NAME\" PLACENAME +LASTNAME \\ma hine learning\" NAME title:\\home page\"NAME +LASTNAME ase based reasoning NAME title:\\homepage\"NAME +LASTNAME \\ ase based reasoning\" NAME wel omeNAME +LASTNAME PLACE NAME url:index.htmlNAME +LASTNAME \\PLACE\" NAME url:home.htmlNAME +LASTNAME url:index.html \\NAME\" title:\\home page\"NAME +LASTNAME url:home.html \\NAME\" title:\\homepage\"NAME +LASTNAME url:~*LASTNAME* \\NAME\" wel omeNAME +LASTNAME url:~LASTNAME \\NAME\" url:index.htmlNAME +LASTNAME url:LASTNAME \\NAME\" url:home.html\\NAME\" PLACE title:\\home page\"\\NAME\" PLACE title:\\homepage\"\\NAME\" PLACE wel ome\\NAME\" PLACE url:index.html\\NAME\" PLACE url:home.htmlTable 1: Sear h (and ranking) experts used in the metasear h experiments. In the asso- iated queries, NAME is repla ed with the person's (or university's) full name,LASTNAME with the person's last name, and PLACE is repla ed with the per-son's a\u00c6liation (or university's lo ation). Sequen es of words en losed in quotesmust appear as a phrase, and terms pre xed by title: and url: must appearin that part of the web page. Words pre xed by a \\+\" must appear in the webpage; other words may or may not appear.5.1 Test Problems and En odingWe hose to simulate the problem of learning a domain-spe i sear h engine|i.e., an enginethat sear hes for pages of a parti ular, narrow type. Ahoy! (Shakes, Langheinri h, & Etzioni,1997) is one instan e of su h a domain-spe i sear h engine. As test ases, we pi ked twoproblems: retrieving the home pages of ma hine learning resear hers (ML), and retrievingthe home pages of universities (UNIV). To obtain sample queries, we obtained a listing ofma hine learning resear hers, identi ed by name and a\u00c6liated institution, together withtheir home pages,4 and a similar list for universities, identi ed by name and (sometimes)geographi al lo ation.5 Ea h entry on a list was viewed as a query, with the asso iatedURL the sole relevant web page.4. From http://www.ai .nrl.navy.mil/ aha/resear h/ma hine-learning.html, a list maintained by DavidAha.5. From Yahoo! 261\nCohen, S hapire, & SingerWe then onstru ted a series of spe ial-purpose \\sear h experts\" for ea h domain. Thesewere implemented as query expansion methods whi h onverted a name/a\u00c6liation pair (ora name/lo ation pair) to a likely-seeming Altavista query. For example, one expert for theUNIV domain sear hed for the university name appearing as a phrase, together with thephrase \\home page\" in the title; another expert for the ML domain sear hed for all thewords in the person's name plus the words \\ma hine\" and \\learning,\" and further enfor esa stri t requirement that the person's last name appear. Overall, we de ned 16 sear hexperts for the ML domain and 22 for the UNIV domain; these are summarized in Table 1.Ea h sear h expert returned the top 30 ranked web pages. In the ML domain, there were210 sear hes for whi h at least one sear h expert returned the named home page; for theUNIV domain, there were 290 su h sear hes. The task of the learning system is to nd anappropriate way of ombining the output of these sear h experts.To give a more pre ise des ription of the sear h experts, for ea h query t, we rst onstru ted the set Xt onsisting of all web pages returned by all of the expanded queriesde ned by the sear h experts. Next, ea h sear h expert i was represented as a preferen efun tion Rti. We hose these preferen e fun tions to be rank orderings de ned with respe tto an ordering fun tion f ti in the natural way: we assigned a rank of f ti = 30 to the rstlisted page, f ti = 29 to the se ond-listed page, and so on, nally assigning a rank of f ti = 0to every page not retrieved in the top 30 by the expanded query asso iated with expert i.To en ode feedba k, we onsidered two s hemes. In the rst, we simulated ompleterelevan e feedba k|that is, for ea h query, we onstru ted feedba k in whi h the solerelevant page was preferred to all other pages. In the se ond, we simulated the sort offeedba k that ould be olle ted from \\ li k data\"|i.e., from observing a user's intera tionswith a metasear h system. For ea h query, after presenting a ranked list of pages, we notedthe rank of the one relevant web page. We then onstru ted a feedba k ranking in whi h therelevant page is preferred to all pre eding pages. This would orrespond to observing whi hlink the user a tually followed, and making the assumption that this link was preferred toprevious links.It should be emphasized that both of these forms of feedba k are simulated, and ontainless noise than would be expe ted from real user data. In reality some fra tion of therelevan e feedba k would be missing or erroneous, and some fra tion of li k data wouldnot satisfy the assumption stated above.5.2 Evaluation and ResultsTo evaluate the expe ted performan e of a fully-trained system on novel queries in thisdomain, we employed leave-one-out testing. For ea h query t, we trained the learning systemon all the other queries, and then re orded the rank of the learned system on query t. For omplete relevan e feedba k, this rank is invariant of the ordering of the training examples,but for the \\ li k data\" feedba k, it is not; the feedba k olle ted at ea h stage depends onthe behavior of the partially learned system, whi h in turn depends on the previous trainingexamples. Thus for li k data training, we trained on 100 randomly hosen permutationsof the training data and re orded the median rank for t.262\nLearning to Order Things5.2.1 Performan e Relative to Individual ExpertsThe theoreti al results provide a guarantee of performan e relative to the performan e ofthe best individual sear h (ranking) expert. It is therefore natural to onsider omparingthe performan e of the learned system to the best of the individual experts. However, forea h sear h expert, only the top 30 ranked web pages for a query are known; if the singlerelevant page for a query is not among these top 30, then it is impossible to ompute anynatural measures of performan e for this query. This ompli ates any omparison of thelearned system to the individual sear h experts.However, in spite of the in omplete information about the performan e of the sear hexperts, it is usually possible to tell if the learned system ranks a web page higher than aparti ular expert.6 Motivated by this, we performed a sign test: we ompared the rank ofthe learning systems to the rank given by ea h sear h expert, he king to see whether thisrank was lower, and dis arding queries for whi h this omparison was impossible. We thenused a normal approximation to the binomial distribution to test the following two nullhypotheses (where the probability is taken over the distribution from whi h the queries aredrawn):H1. With probability at least 0.5, the sear h expert performs better than the learningsystem (i.e., gives a lower rank to the relevant page than the learning system does.)H2. With probability at least 0.5, the sear h expert performs no worse than the learningsystem (i.e., gives an equal or lower rank to the relevant page.)In training, we explored learning rates in the range [0:001; 0:999\u2104. For omplete feedba kin the ML domain, hypothesis H1 an be reje ted with high on den e (p > 0:999) for everysear h expert and every learning rate 0:01 0:99. The same holds in the UNIV domainfor all learning rates 0:02 0:99. The results for li k data training are nearly as strong,ex ept that 2 of the 22 sear h experts in the UNIV domain show a greater sensitivity tothe learning rate: for these engines, H1 an only be reje ted with high on den e for0:3 0:6. To summarize, with high on den e, in both domains, the learned rankingsystem is no worse than any individual sear h expert for moderate values of .Hypothesis H2 is more stringent sin e it an be reje ted only if we are sure that thelearned system is stri tly better than the expert. With omplete feedba k in the ML domainand 0:3 0:8, hypothesis H2 an be reje ted with on den e p > 0:999 for 14 of the 16sear h experts. For the remaining two experts the learned system does perform better moreoften, but the di eren e is not signi ant. In the UNIV domain, the results are similar. For0:2 0:99, hypothesis H2 an be reje ted with on den e p > 0:999 for 21 of the 22sear h experts, and the learned engine tends to perform better than the single remainingexpert.Again, the results for li k data training are only slightly weaker. In the ML domain,hypothesis H2 an be reje ted for all but three experts for all but the most extreme learningrates; in the UNIV domain, hypothesis H2 an be reje ted for all but two experts for 0:4 0:6. For the remaining experts and learning rates the di eren es are not statisti ally6. The only time this annot be determined is when neither the learned system nor the expert ranks therelevant web pages in the top 30, a ase of little pra ti al interest.263\nCohen, S hapire, & Singersigni ant; however, it is not always the ase that the learned engine tends to performbetter.To summarize the experiments, for moderate values of the learned system is, withhigh on den e, stri tly better than most of the sear h experts in both domains, and neversigni antly worse than any expert. When trained with full relevan e judgments, the learnedsystem performs better on average than any individual expert.5.2.2 Other Performan e MeasuresWe measured the number of queries for whi h the orre t web page was in the top k rankedpages, for various values of k. These results are shown in Figure 10. Here the lines show theperforman e of the learned systems (with = 0:5, a generally favorable learning rate) andthe points orrespond to the individual experts. In most ases, the learned system loselytra ks the performan e of the best expert at every value of k. This is espe ially interestingsin e no single expert is best at all values of k.The nal graph in this gure investigates the sensitivity of this measure to the learningrate . As a representative illustration, we varied in the ML domain and plotted thetop-k performan e of the system learned from omplete feedba k for three values of k. Notethat performan e is roughly omparable over a wide range of values for .Another plausible measure of performan e is the average rank of the (single) relevantweb page. We omputed an approximation to average rank by arti ially assigning a rankof 31 to every page that was either unranked, or ranked above rank 30. (The latter ase isto be fair to the learned system, whi h is the only one for whi h a rank greater than 30 ispossible.) A summary of these results for = 0:5 is given in Table 2, together with someadditional data on top-k performan e. In the table, we give the top-k performan e for threevalues of k, and average rank for several ranking systems: the two learned systems; the naivequery, i.e., the person or university's name; and the single sear h expert that performedbest with respe t to ea h performan e measure. Note that not all of these experts aredistin t sin e several experts s ored the best on more than one measure.The table illustrates the robustness of the learned systems, whi h are nearly always ompetitive with the best expert for every performan e measure listed. The only ex eptionto this is that the system trained on li k data trails the best expert in top-k performan e forsmall values of k. It is also worth noting that in both domains, the naive query (simply theperson or university's name) is not very e e tive: even with the weaker li k data feedba k,the learned system a hieves a 36% de rease in average rank over the naive query in the MLdomain, and a 46% de rease in the UNIV domain.To summarize the experiments, on these domains the learned system not only performsmu h better than naive sear h strategies, but also onsistently performs at least as well as,and perhaps slightly better than, any single domain-spe i sear h expert. This observationholds regardless of the performan e metri onsidered; for nearly every metri we omputed,the learned system always equals, and usually ex eeds, the performan e of the sear h expertthat is best for that metri . Finally, the performan e of the learned system is almost asgood with the weaker \\ li k data\" training as with omplete relevan e feedba k.264\nLearning to Order Things\n0\n50\n100\n150\n200\n250\n0 5 10 15 20 25 30 35\n# qu\ner ie\ns in\nto p\nk\nk\nML: queries answered in top k\nLearned System - Full feedback Learned System - Click data\nIndividual Rankers\n0\n50\n100\n150\n200\n250\n300\n0 5 10 15 20 25 30 35\n# qu\ner ie\ns in\nto p\nk\nk\nUNIV: queries answered in top k\nLearned System - Full feedback Learned System - Click data\nIndividual Rankers\n0.40\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0 0.2 0.4 0.6 0.8 1\n% R\nel ev\nan t\nLearning Rate\nk=1\nk=4\nk=8\nFigure 10: Top and middle: Performan e of the learned system versus individual expertsfor two di erent domains. Bottom: the per entage of time the relevant web pagewas in the top-k list for k = 1,4, and 8.265\nCohen, S hapire, & Singer ML Domain University DomainTop 1 Top 10 Top 30 Avg Rank Top 1 Top 10 Top 30 Avg RankLearned (Full Feed.) 114 185 198 4.9 111 225 253 7.8Learned (Cli k Data) 93 185 198 4.9 87 229 259 7.8Naive 89 165 176 7.7 79 157 191 14.4Best (Top 1) 119 170 184 6.7 112 221 247 8.2Best (Top 10) 114 182 190 5.3 111 223 249 8.0Best (Top 30) 97 181 194 5.6 111 223 249 8.0Best (Avg Rank) 114 182 190 5.3 111 223 249 8.0Table 2: Comparison of learned systems and individual sear h queries.6. Related WorkProblems that involve ordering and ranking have been investigated in various elds su h asde ision theory, the so ial s ien es, information retrieval and mathemati al e onomi s (Bla k,1958; Kemeny & Snell, 1962; Cooper, 1968; Fishburn, 1970; Roberts, 1979; Salton &M Gill,1983; Fren h, 1989; Yao, 1995). Among the wealth of literature on the subje t, the losest toours appears to be the work of Kemeny and Snell (1962) whi h was extended by Yao (1995)and used by Balabanov and Shoham (1997) in their FAB ollaborative ltering system.These works use a similar notion of ordering fun tions and feedba k; however, they assumethat both the ordering fun tions and the feedba k are omplete and transitive. Hen e, itis not possible to leave elements unranked, or to have in onsistent feedba k whi h violatesthe transitivity requirements. It is therefore di\u00c6 ult to ombine and fuse in onsistent andin omplete orderings in the Kemeny and Snell model.There are also several related intra tability results. Most of them are on erned with thedi\u00c6 ulty in rea hing onsensus in voting systems based on preferen e ordering. Spe i ally,Bartholdi, Tovey and Tri k (1989) study the problem of nding a winner in an ele tionwhen the preferen es of all voters are irre exive, antisymmetri , transitive, and omplete.Thus, their setting is more restri tive than ours. They study two similar s hemes to de ideon a winner of an ele tion. The rst was invented by Dodgson (1876) (better known byhis pen name, Lewis Carroll) and the se ond is due to Kemeny (1959). For both models,they show that the problem of nding a winner in an ele tion is NP-hard. Among thesetwo models, the one suggested by Kemeny is the losest to ours. However, as mentionedabove, this model is more restri tive as it does not allow voters to abstain (preferen es arerequired to be omplete) or to be in onsistent (all preferen es are transitive).As illustrated by the experiments, the problem of learning to rank is losely related tothe problem of ombining the results of di erent sear h engines. Many methods for thishave been proposed by the information retrieval ommunity, and many of these are adap-tive, using relevan e judgments to make an appropriate hoi e of parameters. However,generally, rankings are ombined by ombining the s ores that were used to rank do u-ments (Lo hbaum & Streeter, 1989; Kantor, 1994). It is also frequently assumed that otherproperties of the obje ts (do uments) to be ranked are available, su h as word frequen ies.In ontrast, in our experiments, instan es are atomi entities with no asso iated propertiesex ept for their position in various rank-orderings. Similarly, we make minimal assump-266\nLearning to Order Thingstions about the rank-orderings|in parti ular, we do not assume s ores are available. Ourmethods are thus appli able to a broader lass of ranking problems.General optimization methods have also been adopted to adjust parameters of an IRsystem so as to improve agreement with a set of user-given preferen e judgments. For in-stan e, Boyan, Freitag, and Joa hims (1994) use simulated annealing to improve agreementwith \\ li k data,\" and Bartell, Cottrell and Belew (1994) use onjugate gradient des entto hoose parameters for a linear ombination of s oring fun tions, ea h asso iated witha di erent sear h expert. Typi ally, su h approa hes o er few guarantees of e\u00c6 ien y,optimality, or generalization performan e.Another related task is olle tion fusion. Here, several sear hes are exe uted on disjointsubsets of a large olle tion, and the results are ombined. Several approa hes to this prob-lem that do not rely on ombining ranking s ores have been des ribed (Towell, Voorhees,Gupta, & Johnson-Laird, 1995; Voorhees, Gupta, & Johnson-Laird, 1994). However, al-though the problem is super ially similar to the one presented here, the assumption thatthe di erent sear h engines index disjoint sets of do uments a tually makes the problemquite di erent. In parti ular, sin e it is impossible for two engines to give di erent relativeorderings to the same pair of do uments, ombining the rankings an be done relativelyeasily.Etzioni et al. (1996) formally onsidered another aspe t of metasear h|the task ofoptimally ombining information sour es with asso iated osts and time delays. Our formalresults are disjoint from theirs, as they assume that every query has a single re ognizable orre t answer, rendering ordering issues unimportant.There are many other appli ations in ma hine learning, reinfor ement learning, neuralnetworks, and ollaborative ltering that employ ranking and preferen es, e.g., (Utgo &Saxena, 1987; Utgo & Clouse, 1991; Caruana, Baluja, & Mit hell, 1996; Resni k & Varian,1997), While our work is not dire tly relevant, it might be possible to use the frameworksuggested in this paper in similar settings. This is one of our future resear h goals.Finally, we would like to note that the framework and algorithms presented in this paper an be extended in several ways. Our urrent resear h fo uses on e\u00c6 ient bat h algorithmsfor ombining preferen e fun tions, and on using restri ted ranking experts for whi h theproblem of nding an optimal total ordering an be solved in polyomial time (Freund, Iyer,S hapire, & Singer, 1998).7. Con lusionsIn many appli ations, it is desirable to order rather than lassify instan es. We investigateda two-stage approa h to learning to order in whi h one rst learns a preferen e fun tion by onventional means, and then orders a new set of instan es by nding the total orderingthat best approximates the preferen e fun tion. The preferen e fun tion that is learned isa binary fun tion PREF(u; v), whi h returns a measure of on den e re e ting how likelyit is that u is preferred to v. This is learned from a set of \\experts\" whi h suggest spe i orderings, and from user feedba k in the form of assertions of the form \\u should be preferredto v\".We have presented two sets of results on this problem. First, we presented an onlinelearning algorithm for learning a weighted ombination of ranking experts whi h is based267\nCohen, S hapire, & Singeron an adaptation of Freund and S hapire's Hedge algorithm. Se ond, we explored the omplexity of the problem of nding a total ordering that agrees best with a preferen efun tion. We showed that this problem is NP- omplete even in a highly restri tive ase,namely, preferen e predi ates that are linear ombinations of a ertain lass of well-behaved\\experts\" alled rank orderings. However, we also showed that for any preferen e predi ate,there is a greedy algorithm that always obtains a total ordering that is within a fa tor oftwo of optimal. We also presented an algorithm that rst divides the set of instan es intostrongly onne ted omponents and then uses the greedy algorithm (or full enumeration,for small omponents) to nd an approximately good order within large strongly onne ted omponents. We found that this approximation algorithm works very well in pra ti e andoften nds the best order.We also presented experimental results in whi h these algorithms were used to ombinethe results of a number of \\sear h experts,\" ea h of whi h orresponds to a domain-spe i strategy for sear hing the web. We showed that in two domains, the learned system loselytra ks and often ex eeds the performan e of the best of these sear h experts. These resultshold for either traditional relevan e feedba k models of learning, or from weaker feedba kin the form of simulated \\ li k data.\" The performan e of the learned systems also learlyex eeds the performan e of more naive approa hes to sear hing.A knowledgmentsWe would like to thank Noga Alon, Edith Cohen, Dana Ron, and Ri k Vohra for numeroushelpful dis ussions. An extended abstra t of this paper appeared in Advan es in NeuralInformation Pro essing Systems 10, MIT Press, 1998.Referen esBalabanov , M., & Shoham, Y. (1997). FAB: Content-based, ollaborative re ommenda-tion. Communi ations of the ACM, 40 (3), 66{72.Bartell, B., Cottrell, G., & Belew, R. (1994). Automati ombination of multiple rankedretrieval systems. In Seventeenth Annual International ACM SIGIR Conferen e onResear h and Development in Information Retrieval.Bartholdi, J., Tovey, C., & Tri k, M. (1989). Voting s hemes for whi h it an be di\u00c6 ultto tell who won the ele tions. So ial Choi e and Welfare, 6, 157{165.Berger, B., & Shor, P. (1997). Tight bounds for the a y li subgraph problem. Journal ofAlgorithms, 25, 1{18.Bla k, D. (1958). Theory of Committees and Ele tions. Cambridge University Press.Boyan, J., Freitag, D., & Joa hims, T. (1994). A ma hine learning ar hite ture for opti-mizing web sear h engines. Te h. rep. WS-96-05, Ameri an Asso iation of Arti ialIntelligen e. 268\nLearning to Order ThingsCaruana, R., Baluja, S., & Mit hell, T. (1996). Using the future to `Sort Out' the present:Rankprop and multitask learning for medi al risk evaluation. In Advan es in NeuralInformation Pro essing Systems (NIPS) 8.Cooper, W. (1968). Expe ted sear h length: A single measure of retrieval e e tivenessbased on the weak ordering a tion of retrieval systems. Ameri an Do umentation, 19,30{41.Dodgson, C. (1876). A method for taking votes on more than two issues. Clarendon Press,Oxford. Reprinted with dis ussion in (Bla k, 1958).Etzioni, O., Hanks, S., Jiang, T., Karp, R. M., Madani, O., & Waarts, O. (1996). E\u00c6 ientinformation gathering on the internet. In Pro eedings of the 37th Annual Sympo-sium on Foundations of Computer S ien e (FOCS-96) Burlington, Vermont. IEEEComputer So iety Press.Even, G., Naor, J., Rao, S., & S hieber, B. (1996). Divide-and- onquer approximation algo-rithms via spreading metri s. In 36th Annual Symposium on Foundations of ComputerS ien e (FOCS-96), pp. 62{71 Burlington, Vermont. IEEE Computer So iety Press.Even, G., Naor, J., S hieber, B., & Sudan, M. (1998). Approximating minimum feedba ksets and multi uts in dire ted graphs. Algorithmi a, 20 (2), 151{174.Fishburn, F. (1970). Utility Theory for De ision Making. Wiley, New York.Fren h, S. (1989). De ision Theory: An Introdu tion to the Mathemati s of Rationality.Ellis Horwood Series in Mathemati s and Its Appli ations.Freund, Y., Iyer, R., S hapire, R., & Singer, Y. (1998). An e\u00c6 ient boosting algorithm for ombining preferen es. In Ma hine Learning: Pro eedings of the Fifteenth Interna-tional Conferen e.Freund, Y., & S hapire, R. (1997). A de ision-theoreti generalization of on-line learningand an appli ation to boosting. Journal of Computer and System S ien es, 55 (1),119{139.Galil, Z., & Megido, N. (1977). Cy li ordering is NP- omplete. Theoreti al ComputerS ien e, 5, 179{182.Gary, M., & Johnson, D. (1979). Computers and Intra tability: A Guide to the Theory ofNP- ompleteness. W. H. Freeman and Company, New York.Kantor, P. (1994). De ision level data fusion for routing of do uments in the TREC3 ontext: a best ase analysis of worst ase results. In Pro eedings of the third textretrieval onferen e (TREC-3).Kemeny, J. (1959). Mathemati s without numbers. Daedalus, 88, 571{591.Kemeny, J., & Snell, J. (1962). Mathemati al Models in the So ial S ien es. Blaisdell, NewYork. 269\nCohen, S hapire, & SingerLittlestone, N. (1988). Learning qui kly when irrelevant attributes abound: A new linear-threshold algorithm. Ma hine Learning, 2 (4).Littlestone, N., & Warmuth, M. (1994). The weighted majority algorithm. Information andComputation, 108 (2), 212{261.Lo hbaum, K., & Streeter, L. (1989). Comparing and ombining the e e tiveness of la-tent semanti indexing and the ordinary ve tor spa e model for information retrieval.Information pro essing and management, 25 (6), 665{676.Resni k, P., & Varian, H. (1997). Introdu tion to spe ial se tion on Re ommender Systems.Communi ation of the ACM, 40 (3).Roberts, F. (1979). Measurement theory with appli ations to de ision making, utility, andso ial s ien es. Addison Wesley, Reading, MA.Salton, G., & M Gill, M. (1983). Introdu tion to Modern Information Retrieval. M Graw-Hill.Seymour, P. (1995). Pa king dire ted ir uits fra tionally. Combinatori a, 15, 281{288.Shakes, J., Langheinri h, M., & Etzioni, O. (1997). Dynami referen e sifting: a ase studyin the homepage domain. In Pro eedings of WWW6.Shmoys, D. (1997). Cut problems and their appli ation to divide-and- onquer. InHo hbaum, D. (Ed.), Approximation algorithms for NP-Hard Problems. PWS Pub-lishing Company, New York.Towell, G., Voorhees, E., Gupta, N., & Johnson-Laird, B. (1995). Learning olle tion fusionstrategies for information retrieval. In Ma hine Learning: Pro eedings of the TwelfthInternational Conferen e Lake Taho, California. Morgan Kaufmann.Utgo , P., & Clouse, J. (1991). Two kinds of training information for evaluation fun tionlearning. In Pro eedings of the Ninth National Conferen e on Arti ial Intelligen e(AAAI-91), pp. 596{600 Cambridge, MA. AAAI Press/MIT PRess.Utgo , P., & Saxena, S. (1987). Learning a preferen e predi ate. In Pro eedings of theFourth International Workshop on Ma hine Learning, pp. 115{121 San Fran is o,CA. Morgan Kaufmann.Voorhees, E., Gupta, N., & Johnson-Laird, B. (1994). The olle tion fusion problem. In Sev-enteenth Annual International ACM SIGIR Conferen e on Resear h and Developmentin Information Retrieval.Yao, Y. (1995). Measuring retrieval e e tiveness based on user preferen e of do uments.Journal of the Ameri an So iety for Information S ien e, 46 (2), 133{145. 270"}], "references": [], "referenceMentions": [], "year": 2011, "abstractText": null, "creator": "dvips(k) 5.78 Copyright 1998 Radical Eye Software (www.radicaleye.com)"}}}