{"id": "1107.4557", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jul-2011", "title": "Finding Deceptive Opinion Spam by Any Stretch of the Imagination", "abstract": "consumers increasingly rate, review and research products online. consequently, websites containing consumer reviews are becoming targets of opinion spam. while recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam - - - containing fictitious opinions groups that have been deliberately written to demonstrate sound authentic. integrating research work from mathematical psychology and computational linguistics, we develop and compare three unique approaches to detecting deceptive opinion rating spam, and ultimately develop a classifier that is nearly 90 % accurate on our gold - standard opinion spam dataset. based together on feature analysis of our old learned models, we additionally make several theoretical contributions, including revealing a close relationship between deceptive opinions and imaginative writing.", "histories": [["v1", "Fri, 22 Jul 2011 16:02:06 GMT  (23kb)", "http://arxiv.org/abs/1107.4557v1", "11 pages, 5 tables, data available at:this http URL"]], "COMMENTS": "11 pages, 5 tables, data available at:this http URL", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["myle ott", "yejin choi", "claire cardie", "jeffrey t hancock"], "accepted": true, "id": "1107.4557"}, "pdf": {"name": "1107.4557.pdf", "metadata": {"source": "CRF", "title": "Finding Deceptive Opinion Spam by Any Stretch of the Imagination", "authors": ["Myle Ott Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock"], "emails": ["myleott@cs.cornell.edu", "ychoi@cs.cornell.edu", "cardie@cs.cornell.edu", "jth34@cornell.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n10 7.\n45 57\nv1 [\ncs .C\nL ]\n2 2\nJu l 2\nConsumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam\u2014fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing."}, {"heading": "1 Introduction", "text": "With the ever-increasing popularity of review websites that feature user-generated opinions (e.g., TripAdvisor1 and Yelp2), there comes an increasing potential for monetary gain through opinion spam\u2014 inappropriate or fraudulent reviews. Opinion spam can range from annoying self-promotion of an unrelated website or blog to deliberate review fraud, as in the recent case3 of a Belkin employee who\n1http://tripadvisor.com 2http://yelp.com 3http://news.cnet.com/8301-1001_\n3-10145399-92.html\nhired people to write positive reviews for an otherwise poorly reviewed product.4\nWhile other kinds of spam have received considerable computational attention, regrettably there has been little work to date (see Section 2) on opinion spam detection. Furthermore, most previous work in the area has focused on the detection of DISRUPTIVE OPINION SPAM\u2014uncontroversial instances of spam that are easily identified by a human reader, e.g., advertisements, questions, and other irrelevant or nonopinion text (Jindal and Liu, 2008). And while the presence of disruptive opinion spam is certainly a nuisance, the risk it poses to the user is minimal, since the user can always choose to ignore it.\nWe focus here on a potentially more insidious type of opinion spam: DECEPTIVE OPINION SPAM\u2014fictitious opinions that have been deliberately written to sound authentic, in order to deceive the reader. For example, one of the following two hotel reviews is truthful and the other is deceptive opinion spam:\n1. I have stayed at many hotels traveling for both business and pleasure and I can honestly stay that The James is tops. The service at the hotel is first class. The rooms are modern and very comfortable. The location is perfect within walking distance to all of the great sights and restaurants. Highly recommend to both business travellers and couples. 2. My husband and I stayed at the James Chicago Hotel for our anniversary. This place is fantastic! We knew as soon as we arrived we made the right choice! The rooms are BEAUTIFUL and the staff very attentive and wonderful!! The area of the hotel is great, since I love to shop I couldn\u2019t ask for more!! We will definatly be\n4It is also possible for opinion spam to be negative, potentially in order to sully the reputation of a competitor.\nback to Chicago and we will for sure be back to the James Chicago.\nTypically, these deceptive opinions are neither easily ignored nor even identifiable by a human reader;5 consequently, there are few good sources of labeled data for this research. Indeed, in the absence of gold-standard data, related studies (see Section 2) have been forced to utilize ad hoc procedures for evaluation. In contrast, one contribution of the work presented here is the creation of the first largescale, publicly available6 dataset for deceptive opinion spam research, containing 400 truthful and 400 gold-standard deceptive reviews.\nTo obtain a deeper understanding of the nature of deceptive opinion spam, we explore the relative utility of three potentially complementary framings of our problem. Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al., 2008; Newman et al., 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al., 1999; Rayson et al., 2001).\nWe compare the performance of each approach on our novel dataset. Particularly, we find that machine learning classifiers trained on features traditionally employed in (a) psychological studies of deception and (b) genre identification are both outperformed at statistically significant levels by ngram\u2013based text categorization techniques. Notably, a combined classifier with both n-gram and psychological deception features achieves nearly 90% cross-validated accuracy on this task. In contrast, we find deceptive opinion spam detection to be well beyond the capabilities of most human judges, who perform roughly at-chance\u2014a finding that is consistent with decades of traditional deception detection research (Bond and DePaulo, 2006).\n5The second example review is deceptive opinion spam. 6Available by request at: http://www.cs.cornell.\nedu/\u02dcmyleott/op_spam\nAdditionally, we make several theoretical contributions based on an examination of the feature weights learned by our machine learning classifiers. Specifically, we shed light on an ongoing debate in the deception literature regarding the importance of considering the context and motivation of a deception, rather than simply identifying a universal set of deception cues. We also present findings that are consistent with recent work highlighting the difficulties that liars have encoding spatial information (Vrij et al., 2009). Lastly, our study of deceptive opinion spam detection as a genre identification problem reveals relationships between deceptive opinions and imaginative writing, and between truthful opinions and informative writing.\nThe rest of this paper is organized as follows: in Section 2, we summarize related work; in Section 3, we explain our methodology for gathering data and evaluate human performance; in Section 4, we describe the features and classifiers employed by our three automated detection approaches; in Section 5, we present and discuss experimental results; finally, conclusions and directions for future work are given in Section 6."}, {"heading": "2 Related Work", "text": "Spam has historically been studied in the contexts of e-mail (Drucker et al., 2002), and the Web (Gyo\u0308ngyi et al., 2004; Ntoulas et al., 2006). Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).\nJindal and Liu (2008) find that opinion spam is both widespread and different in nature from either e-mail or Web spam. Using product review data, and in the absence of gold-standard deceptive opinions, they train models using features based on the review text, reviewer, and product, to distinguish between duplicate opinions7 (considered deceptive spam) and non-duplicate opinions (considered truthful). Wu et al. (2010) propose an alternative strategy for detecting deceptive opinion spam in the absence\n7Duplicate (or near-duplicate) opinions are opinions that appear more than once in the corpus with the same (or similar) text. While these opinions are likely to be deceptive, they are unlikely to be representative of deceptive opinion spam in general. Moreover, they are potentially detectable via off-the-shelf plagiarism detection software.\nof gold-standard data, based on the distortion of popularity rankings. Both of these heuristic evaluation approaches are unnecessary in our work, since we compare gold-standard deceptive and truthful opinions.\nYoo and Gretzel (2009) gather 40 truthful and 42 deceptive hotel reviews and, using a standard statistical test, manually compare the psychologically relevant linguistic differences between them. In contrast, we create a much larger dataset of 800 opinions that we use to develop and evaluate automated deception classifiers.\nResearch has also been conducted on the related task of psycholinguistic deception detection. Newman et al. (2003), and later Mihalcea and Strapparava (2009), ask participants to give both their true and untrue views on personal issues (e.g., their stance on the death penalty). Zhou et al. (2004; 2008) consider computer-mediated deception in role-playing games designed to be played over instant messaging and e-mail. However, while these studies compare n-gram\u2013based deception classifiers to a random guess baseline of 50%, we additionally evaluate and compare two other computational approaches (described in Section 4), as well as the performance of human judges (described in Section 3.3).\nLastly, automatic approaches to determining review quality have been studied\u2014directly (Weimer et al., 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibility (Weerkamp and De Rijke, 2008). Unfortunately, most measures of quality employed in those works are based exclusively on human judgments, which we find in Section 3 to be poorly calibrated to detecting deceptive opinion spam."}, {"heading": "3 Dataset Construction and Human Performance", "text": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010). In this section, we report our efforts to gather (and validate with human judgments) the first publicly available opinion spam dataset with gold-standard deceptive opinions.\nFollowing the work of Yoo and Gretzel (2009), we compare truthful and deceptive positive reviews for hotels found on TripAdvisor. Specifically, we mine all 5-star truthful reviews from the 20 most popular hotels on TripAdvisor8 in the Chicago area.9 Deceptive opinions are gathered for those same 20 hotels using Amazon Mechanical Turk10 (AMT). Below, we provide details of the collection methodologies for deceptive (Section 3.1) and truthful opinions (Section 3.2). Ultimately, we collect 20 truthful and 20 deceptive opinions for each of the 20 chosen hotels (800 opinions total)."}, {"heading": "3.1 Deceptive opinions via Mechanical Turk", "text": "Crowdsourcing services such as AMT have made large-scale data annotation and collection efforts financially affordable by granting anyone with basic programming skills access to a marketplace of anonymous online workers (known as Turkers) willing to complete small tasks.\nTo solicit gold-standard deceptive opinion spam using AMT, we create a pool of 400 HumanIntelligence Tasks (HITs) and allocate them evenly across our 20 chosen hotels. To ensure that opinions are written by unique authors, we allow only a single submission per Turker. We also restrict our task to Turkers who are located in the United States, and who maintain an approval rating of at least 90%. Turkers are allowed a maximum of 30 minutes to work on the HIT, and are paid one US dollar for an accepted submission.\nEach HIT presents the Turker with the name and website of a hotel. The HIT instructions ask the Turker to assume that they work for the hotel\u2019s marketing department, and to pretend that their boss wants them to write a fake review (as if they were a customer) to be posted on a travel review website; additionally, the review needs to sound realistic and portray the hotel in a positive light. A disclaimer\n8TripAdvisor utilizes a proprietary ranking system to assess hotel popularity. We chose the 20 hotels with the greatest number of reviews, irrespective of the TripAdvisor ranking.\n9It has been hypothesized that popular offerings are less likely to become targets of deceptive opinion spam, since the relative impact of the spam in such cases is small (Jindal and Liu, 2008; Lim et al., 2010). By considering only the most popular hotels, we hope to minimize the risk of mining opinion spam and labeling it as truthful.\n10http://mturk.com\nindicates that any submission found to be of insufficient quality (e.g., written for the wrong hotel, unintelligible, unreasonably short,11 plagiarized,12 etc.) will be rejected.\nIt took approximately 14 days to collect 400 satisfactory deceptive opinions. Descriptive statistics appear in Table 1. Submissions vary quite dramatically both in length, and time spent on the task. Particularly, nearly 12% of the submissions were completed in under one minute. Surprisingly, an independent two-tailed t-test between the mean length of these submissions (\u2113\u0304t<1) and the other submissions (\u2113\u0304t\u22651) reveals no significant difference (p = 0.83). We suspect that these \u201cquick\u201d users may have started working prior to having formally accepted the HIT, presumably to circumvent the imposed time limit. Indeed, the quickest submission took just 5 seconds and contained 114 words."}, {"heading": "3.2 Truthful opinions from TripAdvisor", "text": "For truthful opinions, we mine all 6,977 reviews from the 20 most popular Chicago hotels on TripAdvisor. From these we eliminate:\n\u2022 3,130 non-5-star reviews; \u2022 41 non-English reviews;13\n\u2022 75 reviews with fewer than 150 characters since, by construction, deceptive opinions are\n11A submission is considered unreasonably short if it contains fewer than 150 characters.\n12Submissions are individually checked for plagiarism at http://plagiarisma.net.\n13Language is determined using http://tagthe.net.\nat least 150 characters long (see footnote 11 in Section 3.1);\n\u2022 1,607 reviews written by first-time authors\u2014 new users who have not previously posted an opinion on TripAdvisor\u2014since these opinions are more likely to contain opinion spam, which would reduce the integrity of our truthful review data (Wu et al., 2010).\nFinally, we balance the number of truthful and deceptive opinions by selecting 400 of the remaining 2,124 truthful reviews, such that the document lengths of the selected truthful reviews are similarly distributed to those of the deceptive reviews. Work by Serrano et al. (2009) suggests that a log-normal distribution is appropriate for modeling document lengths. Thus, for each of the 20 chosen hotels, we select 20 truthful reviews from a log-normal (lefttruncated at 150 characters) distribution fit to the lengths of the deceptive reviews.14 Combined with the 400 deceptive reviews gathered in Section 3.1 this yields our final dataset of 800 reviews."}, {"heading": "3.3 Human performance", "text": "Assessing human deception detection performance is important for several reasons. First, there are few other baselines for our classification task; indeed, related studies (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009) have only considered a random guess baseline. Second, assessing human performance is necessary to validate the deceptive opinions gathered in Section 3.1. If human performance is low, then our deceptive opinions are convincing, and therefore, deserving of further attention.\nOur initial approach to assessing human performance on this task was with Mechanical Turk. Unfortunately, we found that some Turkers selected among the choices seemingly at random, presumably to maximize their hourly earnings by obviating the need to read the review. While a similar effect has been observed previously (Akkaya et al., 2010), there remains no universal solution.\nInstead, we solicit the help of three volunteer undergraduate university students to make judgments on a subset of our data. This balanced subset, corresponding to the first fold of our cross-validation\n14We use the R package GAMLSS (Rigby and Stasinopoulos, 2005) to fit the left-truncated log-normal distribution.\nexperiments described in Section 5, contains all 40 reviews from each of four randomly chosen hotels. Unlike the Turkers, our student volunteers are not offered a monetary reward. Consequently, we consider their judgements to be more honest than those obtained via AMT.\nAdditionally, to test the extent to which the individual human judges are biased, we evaluate the performance of two virtual meta-judges. Specifically, the MAJORITY meta-judge predicts \u201cdeceptive\u201d when at least two out of three human judges believe the review to be deceptive, and the SKEPTIC meta-judge predicts \u201cdeceptive\u201d when any human judge believes the review to be deceptive.\nHuman and meta-judge performance is given in Table 2. It is clear from the results that human judges are not particularly effective at this task. Indeed, a two-tailed binomial test fails to reject the null hypothesis that JUDGE 2 and JUDGE 3 perform at-chance (p = 0.003, 0.10, 0.48 for the three judges, respectively). Furthermore, all three judges suffer from truth-bias (Vrij, 2008), a common finding in deception detection research in which human judges are more likely to classify an opinion as truthful than deceptive. In fact, JUDGE 2 classified fewer than 12% of the opinions as deceptive! Interestingly, this bias is effectively smoothed by the SKEPTIC meta-judge, which produces nearly perfectly class-balanced predictions. A subsequent reevaluation of human performance on this task suggests that the truth-bias can be reduced if judges are given the class-proportions in advance, although such prior knowledge is unrealistic; and ultimately, performance remains similar to that of Table 2.\nInter-annotator agreement among the three judges, computed using Fleiss\u2019 kappa, is 0.11. While there is no precise rule for interpreting kappa scores, Landis and Koch (1977) suggest\nthat scores in the range (0.00, 0.20] correspond to \u201cslight agreement\u201d between annotators. The largest pairwise Cohen\u2019s kappa is 0.12, between JUDGE 2 and JUDGE 3\u2014a value far below generally accepted pairwise agreement levels. We suspect that agreement among our human judges is so low precisely because humans are poor judges of deception (Vrij, 2008), and therefore they perform nearly at-chance respective to one another."}, {"heading": "4 Automated Approaches to Deceptive Opinion Spam Detection", "text": "We consider three automated approaches to detecting deceptive opinion spam, each of which utilizes classifiers (described in Section 4.4) trained on the dataset of Section 3. The features employed by each strategy are outlined here."}, {"heading": "4.1 Genre identification", "text": "Work in computational linguistics has shown that the frequency distribution of part-of-speech (POS) tags in a text is often dependent on the genre of the text (Biber et al., 1999; Rayson et al., 2001). In our genre identification approach to deceptive opinion spam detection, we test if such a relationship exists for truthful and deceptive reviews by constructing, for each review, features based on the frequencies of each POS tag.15 These features are also intended to provide a good baseline with which to compare our other automated approaches."}, {"heading": "4.2 Psycholinguistic deception detection", "text": "The Linguistic Inquiry and Word Count (LIWC) software (Pennebaker et al., 2007) is a popular automated text analysis tool used widely in the social sciences. It has been used to detect personality\n15We use the Stanford Parser (Klein and Manning, 2003) to obtain the relative POS frequencies.\ntraits (Mairesse et al., 2007), to study tutoring dynamics (Cade et al., 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).\nWhile LIWC does not include a text classifier, we can create one with features derived from the LIWC output. In particular, LIWC counts and groups the number of instances of nearly 4,500 keywords into 80 psychologically meaningful dimensions. We construct one feature for each of the 80 LIWC dimensions, which can be summarized broadly under the following four categories:\n1. Linguistic processes: Functional aspects of text (e.g., the average number of words per sentence, the rate of misspelling, swearing, etc.)\n2. Psychological processes: Includes all social, emotional, cognitive, perceptual and biological processes, as well as anything related to time or space.\n3. Personal concerns: Any references to work, leisure, money, religion, etc.\n4. Spoken categories: Primarily filler and agreement words.\nWhile other features have been considered in past deception detection work, notably those of Zhou et al. (2004), early experiments found LIWC features to perform best. Indeed, the LIWC2007 software used in our experiments subsumes most of the features introduced in other work. Thus, we focus our psycholinguistic approach to deception detection on LIWC-based features."}, {"heading": "4.3 Text categorization", "text": "In contrast to the other strategies just discussed, our text categorization approach to deception detection allows us to model both content and context with n-gram features. Specifically, we consider the following three n-gram feature sets, with the corresponding features lowercased and unstemmed: UNIGRAMS, BIGRAMS+, TRIGRAMS+ , where the superscript + indicates that the feature set subsumes the preceding feature set."}, {"heading": "4.4 Classifiers", "text": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector\nMachine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).\nFor a document ~x, with label y, the Na\u0131\u0308ve Bayes (NB) classifier gives us the following decision rule:\ny\u0302 = argmax c Pr(y = c) \u00b7 Pr(~x | y = c) (1)\nWhen the class prior is uniform, for example when the classes are balanced (as in our case), (1) can be simplified to the maximum likelihood classifier (Peng and Schuurmans, 2003):\ny\u0302 = argmax c Pr(~x | y = c) (2)\nUnder (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al. (2008) are equivalent. Thus, following Zhou et al. (2008), we use the SRI Language Modeling Toolkit (Stolcke, 2002) to estimate individual language models, Pr(~x | y = c), for truthful and deceptive opinions. We consider all three n-gram feature sets, namely UNIGRAMS, BIGRAMS+, and TRIGRAMS+ , with corresponding language models smoothed using the interpolated Kneser-Ney method (Chen and Goodman, 1996).\nWe also train Support Vector Machine (SVM) classifiers, which find a high-dimensional separating hyperplane between two groups of data. To simplify feature analysis in Section 5, we restrict our evaluation to linear SVMs, which learn a weight vector ~w and bias term b, such that a document ~x can be classified by:\ny\u0302 = sign(~w \u00b7 ~x+ b) (3)\nWe use SVMlight (Joachims, 1999) to train our linear SVM models on all three approaches and feature sets described above, namely POS, LIWC, UNIGRAMS, BIGRAMS+, and TRIGRAMS+ . We also evaluate every combination of these features, but for brevity include only LIWC+BIGRAMS+ , which performs best. Following standard practice, document vectors are normalized to unit-length. For LIWC+BIGRAMS+ , we unit-length normalize LIWC and BIGRAMS+ features individually before combining them."}, {"heading": "5 Results and Discussion", "text": "The deception detection strategies described in Section 4 are evaluated using a 5-fold nested crossvalidation (CV) procedure (Quadrianto et al., 2009), where model parameters are selected for each test fold based on standard CV experiments on the training folds. Folds are selected so that each contains all reviews from four hotels; thus, learned models are always evaluated on reviews from unseen hotels.\nResults appear in Table 3. We observe that automated classifiers outperform human judges for every metric, except truthful recall where JUDGE 2 performs best.16 However, this is expected given that untrained humans often focus on unreliable cues to deception (Vrij, 2008). For example, one study examining deception in online dating found that humans perform at-chance detecting deceptive profiles because they rely on text-based cues that are unrelated to deception, such as second-person pronouns (Toma and Hancock, In Press).\nAmong the automated classifiers, baseline performance is given by the simple genre identification approach (POSSVM) proposed in Section 4.1. Surprisingly, we find that even this simple auto-\n16As mentioned in Section 3.3, JUDGE 2 classified fewer than 12% of opinions as deceptive. While achieving 95% truthful recall, this judge\u2019s corresponding precision was not significantly better than chance (two-tailed binomial p = 0.4).\nmated classifier outperforms most human judges (one-tailed sign test p = 0.06, 0.01, 0.001 for the three judges, respectively, on the first fold). This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively. Work by Rayson et al. (2001) has found strong distributional differences between informative and imaginative writing, namely that the former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs,17 adverbs,18 pronouns, and pre-determiners. Indeed, we find that the weights learned by POSSVM (found in Table 4) are largely in agreement with these findings, notably except for adjective and adverb superlatives, the latter of which was found to be an exception by Rayson et al. (2001). However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al., 2008).\nBoth remaining automated approaches to detecting deceptive opinion spam outperform the simple\n17Past participle verbs were an exception. 18Superlative adverbs were an exception.\ngenre identification baseline just discussed. Specifically, the psycholinguistic approach (LIWCSVM) proposed in Section 4.2 performs 3.8% more accurately (one-tailed sign test p = 0.02), and the standard text categorization approach proposed in Section 4.3 performs between 14.6% and 16.6% more accurately. However, best performance overall is achieved by combining features from these two approaches. Particularly, the combined model LIWC+BIGRAMS+SVM is 89.8% accurate at detecting deceptive opinion spam.19\nSurprisingly, models trained only on UNIGRAMS\u2014the simplest n-gram feature set\u2014 outperform all non\u2013text-categorization approaches, and models trained on BIGRAMS+ perform even better (one-tailed sign test p = 0.07). This suggests that a universal set of keyword-based deception cues (e.g., LIWC) is not the best approach to detecting deception, and a context-sensitive approach (e.g., BIGRAMS+) might be necessary to achieve state-of-the-art deception detection performance.\nTo better understand the models learned by these automated approaches, we report in Table 5 the top 15 highest weighted features for each class (truthful and deceptive) as learned by LIWC+BIGRAMS+SVM and LIWCSVM. In agreement with theories of reality monitoring (Johnson and Raye, 1981), we observe that truthful opinions tend to include more sensorial and concrete language than deceptive opinions; in\n19The result is not significantly better than BIGRAMS+SVM.\nparticular, truthful opinions are more specific about spatial configurations (e.g., small, bathroom, on, location). This finding is also supported by recent work by Vrij et al. (2009) suggesting that liars have considerable difficultly encoding spatial information into their lies. Accordingly, we observe an increased focus in deceptive opinions on aspects external to the hotel being reviewed (e.g., husband, business,\nvacation). We also acknowledge several findings that, on the surface, are in contrast to previous psycholinguistic studies of deception (Hancock et al., 2008; Newman et al., 2003). For instance, while deception is often associated with negative emotion terms, our deceptive reviews have more positive and fewer negative emotion terms. This pattern makes sense when one considers the goal of our deceivers, namely to create a positive review (Buller and Burgoon, 1996).\nDeception has also previously been associated with decreased usage of first person singular, an effect attributed to psychological distancing (Newman et al., 2003). In contrast, we find increased first person singular to be among the largest indicators of deception, which we speculate is due to our deceivers attempting to enhance the credibility of their reviews by emphasizing their own presence in the review. Additional work is required, but these findings further suggest the importance of moving beyond a universal set of deceptive language features (e.g., LIWC) by considering both the contextual (e.g., BIGRAMS+) and motivational parameters underlying a deception as well."}, {"heading": "6 Conclusion and Future Work", "text": "In this work we have developed the first large-scale dataset containing gold-standard deceptive opinion spam. With it, we have shown that the detection of deceptive opinion spam is well beyond the capabilities of human judges, most of whom perform roughly at-chance. Accordingly, we have introduced three automated approaches to deceptive opinion spam detection, based on insights coming from research in computational linguistics and psychology. We find that while standard n-gram\u2013based text categorization is the best individual detection approach, a combination approach using psycholinguisticallymotivated features and n-gram features can perform slightly better.\nFinally, we have made several theoretical contributions. Specifically, our findings suggest the importance of considering both the context (e.g., BIGRAMS+) and motivations underlying a deception, rather than strictly adhering to a universal set of deception cues (e.g., LIWC). We have also presented results based on the feature weights learned\nby our classifiers that illustrate the difficulties faced by liars in encoding spatial information. Lastly, we have discovered a plausible relationship between deceptive opinion spam and imaginative writing, based on POS distributional similarities.\nPossible directions for future work include an extended evaluation of the methods proposed in this work to both negative opinions, as well as opinions coming from other domains. Many additional approaches to detecting deceptive opinion spam are also possible, and a focus on approaches with high deceptive precision might be useful for production environments."}, {"heading": "Acknowledgments", "text": "This work was supported in part by National Science Foundation Grants BCS-0624277, BCS0904822, HSD-0624267, IIS-0968450, and NSCC0904822, as well as a gift from Google, and the Jack Kent Cooke Foundation. We also thank, alphabetically, Rachel Boochever, Cristian DanescuNiculescu-Mizil, Alicia Granstein, Ulrike Gretzel, Danielle Kirshenblat, Lillian Lee, Bin Lu, Jack Newton, Melissa Sackler, Mark Thomas, and Angie Yoo, as well as members of the Cornell NLP seminar group and the ACL reviewers for their insightful comments, suggestions and advice on various aspects of this work."}], "references": [{"title": "Amazon mechanical turk for subjectivity word sense disambiguation", "author": ["C. Akkaya", "A. Conrad", "J. Wiebe", "R. Mihalcea."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazons Mechanical Turk, Los Angeles,", "citeRegEx": "Akkaya et al\\.,? 2010", "shortCiteRegEx": "Akkaya et al\\.", "year": 2010}, {"title": "Longman grammar of spoken and written English, volume 2", "author": ["D. Biber", "S. Johansson", "G. Leech", "S. Conrad", "E. Finegan", "R. Quirk."], "venue": "MIT Press.", "citeRegEx": "Biber et al\\.,? 1999", "shortCiteRegEx": "Biber et al\\.", "year": 1999}, {"title": "Accuracy of deception judgments", "author": ["C.F. Bond", "B.M. DePaulo."], "venue": "Personality and Social Psychology Review, 10(3):214.", "citeRegEx": "Bond and DePaulo.,? 2006", "shortCiteRegEx": "Bond and DePaulo.", "year": 2006}, {"title": "Interpersonal deception theory", "author": ["D.B. Buller", "J.K. Burgoon."], "venue": "Communication Theory, 6(3):203\u2013 242.", "citeRegEx": "Buller and Burgoon.,? 1996", "shortCiteRegEx": "Buller and Burgoon.", "year": 1996}, {"title": "An exploration of off topic conversation", "author": ["W.L. Cade", "B.A. Lehman", "A. Olney."], "venue": "Human Language Technologies: The 2010 Annual Conference of", "citeRegEx": "Cade et al\\.,? 2010", "shortCiteRegEx": "Cade et al\\.", "year": 2010}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["S.F. Chen", "J. Goodman."], "venue": "Proceedings of the 34th annual meeting on Association for Computational Linguistics, pages 310\u2013318. Association for Computational Linguistics.", "citeRegEx": "Chen and Goodman.,? 1996", "shortCiteRegEx": "Chen and Goodman.", "year": 1996}, {"title": "How opinions are received by online communities: a case study on amazon.com helpfulness votes", "author": ["C. Danescu-Niculescu-Mizil", "G. Kossinets", "J. Kleinberg", "L. Lee"], "venue": "In Proceedings of the 18th international conference on World wide web,", "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2009}, {"title": "Support vector machines for spam categorization", "author": ["H. Drucker", "D. Wu", "V.N. Vapnik."], "venue": "Neural Networks, IEEE Transactions on, 10(5):1048\u20131054.", "citeRegEx": "Drucker et al\\.,? 2002", "shortCiteRegEx": "Drucker et al\\.", "year": 2002}, {"title": "Apples-to-Apples in Cross-Validation Studies: Pitfalls in Classifier Performance Measurement", "author": ["G. Forman", "M. Scholz."], "venue": "ACM SIGKDD Explorations, 12(1):49\u201357.", "citeRegEx": "Forman and Scholz.,? 2009", "shortCiteRegEx": "Forman and Scholz.", "year": 2009}, {"title": "Combating web spam with trustrank", "author": ["Z. Gy\u00f6ngyi", "H. Garcia-Molina", "J. Pedersen."], "venue": "Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, pages 576\u2013587. VLDB Endowment.", "citeRegEx": "Gy\u00f6ngyi et al\\.,? 2004", "shortCiteRegEx": "Gy\u00f6ngyi et al\\.", "year": 2004}, {"title": "On lying and being lied to: A linguistic analysis of deception in computer-mediated communication", "author": ["J.T. Hancock", "L.E. Curry", "S. Goorha", "M. Woodworth."], "venue": "Discourse Processes, 45(1):1\u201323.", "citeRegEx": "Hancock et al\\.,? 2008", "shortCiteRegEx": "Hancock et al\\.", "year": 2008}, {"title": "Online product research", "author": ["J. Jansen."], "venue": "Pew Internet & American Life Project Report.", "citeRegEx": "Jansen.,? 2010", "shortCiteRegEx": "Jansen.", "year": 2010}, {"title": "Opinion spam and analysis", "author": ["N. Jindal", "B. Liu."], "venue": "Proceedings of the international conference on Web search and web data mining, pages 219\u2013230. ACM.", "citeRegEx": "Jindal and Liu.,? 2008", "shortCiteRegEx": "Jindal and Liu.", "year": 2008}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["T. Joachims."], "venue": "Machine Learning: ECML-98, pages 137\u2013142.", "citeRegEx": "Joachims.,? 1998", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Making large-scale support vector machine learning practical", "author": ["T. Joachims."], "venue": "Advances in kernel methods, page 184. MIT Press.", "citeRegEx": "Joachims.,? 1999", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Reality monitoring", "author": ["M.K. Johnson", "C.L. Raye."], "venue": "Psychological Review, 88(1):67\u201385.", "citeRegEx": "Johnson and Raye.,? 1981", "shortCiteRegEx": "Johnson and Raye.", "year": 1981}, {"title": "Automatically assessing review helpfulness", "author": ["S.M. Kim", "P. Pantel", "T. Chklovski", "M. Pennacchiotti."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 423\u2013 430. Association for Computational Linguistics.", "citeRegEx": "Kim et al\\.,? 2006", "shortCiteRegEx": "Kim et al\\.", "year": 2006}, {"title": "Accurate unlexicalized parsing", "author": ["D. Klein", "C.D. Manning."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational LinguisticsVolume 1, pages 423\u2013430. Association for Computational Linguistics.", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "The measurement of observer agreement for categorical data", "author": ["J.R. Landis", "G.G. Koch."], "venue": "Biometrics, 33(1):159.", "citeRegEx": "Landis and Koch.,? 1977", "shortCiteRegEx": "Landis and Koch.", "year": 1977}, {"title": "Detecting product review spammers using rating behaviors", "author": ["E.P. Lim", "V.A. Nguyen", "N. Jindal", "B. Liu", "H.W. Lauw."], "venue": "Proceedings of the 19th ACM international conference on Information and knowledge management, pages 939\u2013948. ACM.", "citeRegEx": "Lim et al\\.,? 2010", "shortCiteRegEx": "Lim et al\\.", "year": 2010}, {"title": "Electronic word-of-mouth in hospitality and tourism management", "author": ["S.W. Litvin", "R.E. Goldsmith", "B. Pan."], "venue": "Tourism management, 29(3):458\u2013468.", "citeRegEx": "Litvin et al\\.,? 2008", "shortCiteRegEx": "Litvin et al\\.", "year": 2008}, {"title": "Using linguistic cues for the automatic recognition of personality in conversation and text", "author": ["F. Mairesse", "M.A. Walker", "M.R. Mehl", "R.K. Moore."], "venue": "Journal of Artificial Intelligence Research, 30(1):457\u2013500.", "citeRegEx": "Mairesse et al\\.,? 2007", "shortCiteRegEx": "Mairesse et al\\.", "year": 2007}, {"title": "The lie detector: Explorations in the automatic recognition of deceptive language", "author": ["R. Mihalcea", "C. Strapparava."], "venue": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 309\u2013312. Association for Computational Linguistics.", "citeRegEx": "Mihalcea and Strapparava.,? 2009", "shortCiteRegEx": "Mihalcea and Strapparava.", "year": 2009}, {"title": "Lying words: Predicting deception from linguistic styles", "author": ["M.L. Newman", "J.W. Pennebaker", "D.S. Berry", "J.M. Richards."], "venue": "Personality and Social Psychology Bulletin, 29(5):665.", "citeRegEx": "Newman et al\\.,? 2003", "shortCiteRegEx": "Newman et al\\.", "year": 2003}, {"title": "Detecting spam web pages through content analysis", "author": ["A. Ntoulas", "M. Najork", "M. Manasse", "D. Fetterly."], "venue": "Proceedings of the 15th international conference on World Wide Web, pages 83\u201392. ACM.", "citeRegEx": "Ntoulas et al\\.,? 2006", "shortCiteRegEx": "Ntoulas et al\\.", "year": 2006}, {"title": "Learning to recommend helpful hotel reviews", "author": ["M.P. O\u2019Mahony", "B. Smyth"], "venue": "In Proceedings of the third ACM conference on Recommender systems,", "citeRegEx": "O.Mahony and Smyth.,? \\Q2009\\E", "shortCiteRegEx": "O.Mahony and Smyth.", "year": 2009}, {"title": "Combining naive Bayes and n-gram language models for text classification", "author": ["F. Peng", "D. Schuurmans."], "venue": "Advances in Information Retrieval, pages 547\u2013 547.", "citeRegEx": "Peng and Schuurmans.,? 2003", "shortCiteRegEx": "Peng and Schuurmans.", "year": 2003}, {"title": "The development and psychometric properties of LIWC2007", "author": ["J.W. Pennebaker", "C.K. Chung", "M. Ireland", "A. Gonzales", "R.J. Booth."], "venue": "Austin, TX, LIWC. Net.", "citeRegEx": "Pennebaker et al\\.,? 2007", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2007}, {"title": "Estimating labels from label proportions", "author": ["N. Quadrianto", "A.J. Smola", "T.S. Caetano", "Q.V. Le."], "venue": "The Journal of Machine Learning Research, 10:2349\u2013 2374.", "citeRegEx": "Quadrianto et al\\.,? 2009", "shortCiteRegEx": "Quadrianto et al\\.", "year": 2009}, {"title": "Grammatical word class variation within the British National Corpus sampler", "author": ["P. Rayson", "A. Wilson", "G. Leech."], "venue": "Language and Computers, 36(1):295\u2013 306.", "citeRegEx": "Rayson et al\\.,? 2001", "shortCiteRegEx": "Rayson et al\\.", "year": 2001}, {"title": "Generalized additive models for location, scale and shape", "author": ["R.A. Rigby", "D.M. Stasinopoulos."], "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics), 54(3):507\u2013554.", "citeRegEx": "Rigby and Stasinopoulos.,? 2005", "shortCiteRegEx": "Rigby and Stasinopoulos.", "year": 2005}, {"title": "Machine learning in automated text categorization", "author": ["F. Sebastiani."], "venue": "ACM computing surveys (CSUR), 34(1):1\u201347.", "citeRegEx": "Sebastiani.,? 2002", "shortCiteRegEx": "Sebastiani.", "year": 2002}, {"title": "Modeling statistical properties of written text", "author": ["M.\u00c1. Serrano", "A. Flammini", "F. Menczer."], "venue": "PloS one, 4(4):5372.", "citeRegEx": "Serrano et al\\.,? 2009", "shortCiteRegEx": "Serrano et al\\.", "year": 2009}, {"title": "SRILM-an extensible language modeling toolkit", "author": ["A. Stolcke."], "venue": "Seventh International Conference on Spoken Language Processing, volume 3, pages 901\u2013 904. Citeseer.", "citeRegEx": "Stolcke.,? 2002", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "Cues to deception and ability to detect lies as a function of police interview styles", "author": ["A. Vrij", "S. Mann", "S. Kristen", "R.P. Fisher."], "venue": "Law and human behavior, 31(5):499\u2013518.", "citeRegEx": "Vrij et al\\.,? 2007", "shortCiteRegEx": "Vrij et al\\.", "year": 2007}, {"title": "Outsmarting the liars: The benefit of asking unanticipated questions", "author": ["A. Vrij", "S. Leal", "P.A. Granhag", "S. Mann", "R.P. Fisher", "J. Hillman", "K. Sperry."], "venue": "Law and human behavior, 33(2):159\u2013166.", "citeRegEx": "Vrij et al\\.,? 2009", "shortCiteRegEx": "Vrij et al\\.", "year": 2009}, {"title": "Detecting lies and deceit: Pitfalls and opportunities", "author": ["A. Vrij."], "venue": "Wiley-Interscience.", "citeRegEx": "Vrij.,? 2008", "shortCiteRegEx": "Vrij.", "year": 2008}, {"title": "Credibility improves topical blog post retrieval", "author": ["W. Weerkamp", "M. De Rijke."], "venue": "ACL-08: HLT, pages 923\u2013931.", "citeRegEx": "Weerkamp and Rijke.,? 2008", "shortCiteRegEx": "Weerkamp and Rijke.", "year": 2008}, {"title": "Automatically assessing the post quality in online discussions on software", "author": ["M. Weimer", "I. Gurevych", "M. M\u00fchlh\u00e4user."], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 125\u2013128. Association", "citeRegEx": "Weimer et al\\.,? 2007", "shortCiteRegEx": "Weimer et al\\.", "year": 2007}, {"title": "Distortion as a validation criterion in the identification of suspicious reviews", "author": ["G. Wu", "D. Greene", "B. Smyth", "P. Cunningham."], "venue": "Technical report, UCD-CSI2010-04, University College Dublin.", "citeRegEx": "Wu et al\\.,? 2010", "shortCiteRegEx": "Wu et al\\.", "year": 2010}, {"title": "Comparison of Deceptive and Truthful Travel Reviews", "author": ["K.H. Yoo", "U. Gretzel."], "venue": "Information and Communication Technologies in Tourism 2009, pages 37\u201347.", "citeRegEx": "Yoo and Gretzel.,? 2009", "shortCiteRegEx": "Yoo and Gretzel.", "year": 2009}, {"title": "A comparison of classification methods for predicting deception in computermediated communication", "author": ["L. Zhou", "J.K. Burgoon", "D.P. Twitchell", "T. Qin", "J.F. Nunamaker Jr."], "venue": "Journal of Management Information Systems, 20(4):139\u2013166.", "citeRegEx": "Zhou et al\\.,? 2004", "shortCiteRegEx": "Zhou et al\\.", "year": 2004}, {"title": "A Statistical Language Modeling Approach to Online Deception Detection", "author": ["L. Zhou", "Y. Shi", "D. Zhang."], "venue": "IEEE Transactions on Knowledge and Data Engineering, 20(8):1077\u20131081.", "citeRegEx": "Zhou et al\\.,? 2008", "shortCiteRegEx": "Zhou et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008).", "startOffset": 65, "endOffset": 100}, {"referenceID": 20, "context": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008).", "startOffset": 65, "endOffset": 100}, {"referenceID": 12, "context": ", advertisements, questions, and other irrelevant or nonopinion text (Jindal and Liu, 2008).", "startOffset": 69, "endOffset": 91}, {"referenceID": 13, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al.", "startOffset": 167, "endOffset": 201}, {"referenceID": 31, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al.", "startOffset": 167, "endOffset": 201}, {"referenceID": 10, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al., 2008; Newman et al., 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al.", "startOffset": 413, "endOffset": 456}, {"referenceID": 23, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al., 2008; Newman et al., 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al.", "startOffset": 413, "endOffset": 456}, {"referenceID": 1, "context": ", 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 168, "endOffset": 209}, {"referenceID": 29, "context": ", 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 168, "endOffset": 209}, {"referenceID": 2, "context": "In contrast, we find deceptive opinion spam detection to be well beyond the capabilities of most human judges, who perform roughly at-chance\u2014a finding that is consistent with decades of traditional deception detection research (Bond and DePaulo, 2006).", "startOffset": 227, "endOffset": 251}, {"referenceID": 35, "context": "We also present findings that are consistent with recent work highlighting the difficulties that liars have encoding spatial information (Vrij et al., 2009).", "startOffset": 137, "endOffset": 156}, {"referenceID": 7, "context": "Spam has historically been studied in the contexts of e-mail (Drucker et al., 2002), and the Web (Gy\u00f6ngyi et al.", "startOffset": 61, "endOffset": 83}, {"referenceID": 9, "context": ", 2002), and the Web (Gy\u00f6ngyi et al., 2004; Ntoulas et al., 2006).", "startOffset": 21, "endOffset": 65}, {"referenceID": 24, "context": ", 2002), and the Web (Gy\u00f6ngyi et al., 2004; Ntoulas et al., 2006).", "startOffset": 21, "endOffset": 65}, {"referenceID": 12, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 39, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 40, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 39, "context": "Wu et al. (2010) propose an alternative strategy for detecting deceptive opinion spam in the absence", "startOffset": 0, "endOffset": 17}, {"referenceID": 22, "context": "Newman et al. (2003), and later Mihalcea and Strapparava (2009), ask participants to give both their true and untrue views on personal issues (e.", "startOffset": 0, "endOffset": 21}, {"referenceID": 22, "context": "(2003), and later Mihalcea and Strapparava (2009), ask participants to give both their true and untrue views on personal issues (e.", "startOffset": 18, "endOffset": 50}, {"referenceID": 38, "context": "Lastly, automatic approaches to determining review quality have been studied\u2014directly (Weimer et al., 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 6, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 16, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 25, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 12, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010).", "startOffset": 129, "endOffset": 168}, {"referenceID": 39, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010).", "startOffset": 129, "endOffset": 168}, {"referenceID": 12, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010). In this section, we report our efforts to gather (and validate with human judgments) the first publicly available opinion spam dataset with gold-standard deceptive opinions. Following the work of Yoo and Gretzel (2009), we compare truthful and deceptive positive reviews for hotels found on TripAdvisor.", "startOffset": 130, "endOffset": 389}, {"referenceID": 12, "context": "It has been hypothesized that popular offerings are less likely to become targets of deceptive opinion spam, since the relative impact of the spam in such cases is small (Jindal and Liu, 2008; Lim et al., 2010).", "startOffset": 170, "endOffset": 210}, {"referenceID": 19, "context": "It has been hypothesized that popular offerings are less likely to become targets of deceptive opinion spam, since the relative impact of the spam in such cases is small (Jindal and Liu, 2008; Lim et al., 2010).", "startOffset": 170, "endOffset": 210}, {"referenceID": 39, "context": "\u2022 1,607 reviews written by first-time authors\u2014 new users who have not previously posted an opinion on TripAdvisor\u2014since these opinions are more likely to contain opinion spam, which would reduce the integrity of our truthful review data (Wu et al., 2010).", "startOffset": 237, "endOffset": 254}, {"referenceID": 32, "context": "Work by Serrano et al. (2009) suggests that a log-normal distribution is appropriate for modeling document lengths.", "startOffset": 8, "endOffset": 30}, {"referenceID": 12, "context": "First, there are few other baselines for our classification task; indeed, related studies (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009) have only considered a random guess baseline.", "startOffset": 90, "endOffset": 144}, {"referenceID": 22, "context": "First, there are few other baselines for our classification task; indeed, related studies (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009) have only considered a random guess baseline.", "startOffset": 90, "endOffset": 144}, {"referenceID": 0, "context": "While a similar effect has been observed previously (Akkaya et al., 2010), there remains no universal solution.", "startOffset": 52, "endOffset": 73}, {"referenceID": 30, "context": "We use the R package GAMLSS (Rigby and Stasinopoulos, 2005) to fit the left-truncated log-normal distribution.", "startOffset": 28, "endOffset": 59}, {"referenceID": 36, "context": "Furthermore, all three judges suffer from truth-bias (Vrij, 2008), a common finding in deception detection research in which human judges are more likely to classify an opinion as truthful than deceptive.", "startOffset": 53, "endOffset": 65}, {"referenceID": 36, "context": "We suspect that agreement among our human judges is so low precisely because humans are poor judges of deception (Vrij, 2008), and therefore they perform nearly at-chance respective to one another.", "startOffset": 113, "endOffset": 125}, {"referenceID": 18, "context": "While there is no precise rule for interpreting kappa scores, Landis and Koch (1977) suggest that scores in the range (0.", "startOffset": 62, "endOffset": 85}, {"referenceID": 1, "context": "Work in computational linguistics has shown that the frequency distribution of part-of-speech (POS) tags in a text is often dependent on the genre of the text (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 159, "endOffset": 200}, {"referenceID": 29, "context": "Work in computational linguistics has shown that the frequency distribution of part-of-speech (POS) tags in a text is often dependent on the genre of the text (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 159, "endOffset": 200}, {"referenceID": 27, "context": "The Linguistic Inquiry and Word Count (LIWC) software (Pennebaker et al., 2007) is a popular automated text analysis tool used widely in the social sciences.", "startOffset": 54, "endOffset": 79}, {"referenceID": 17, "context": "We use the Stanford Parser (Klein and Manning, 2003) to obtain the relative POS frequencies.", "startOffset": 27, "endOffset": 52}, {"referenceID": 21, "context": "traits (Mairesse et al., 2007), to study tutoring dynamics (Cade et al.", "startOffset": 7, "endOffset": 30}, {"referenceID": 4, "context": ", 2007), to study tutoring dynamics (Cade et al., 2010), and, most relevantly, to analyze deception (Hancock et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 10, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 22, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 34, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 41, "context": "While other features have been considered in past deception detection work, notably those of Zhou et al. (2004), early experiments found LIWC features to perform best.", "startOffset": 93, "endOffset": 112}, {"referenceID": 12, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 22, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 42, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 26, "context": "When the class prior is uniform, for example when the classes are balanced (as in our case), (1) can be simplified to the maximum likelihood classifier (Peng and Schuurmans, 2003):", "startOffset": 152, "endOffset": 179}, {"referenceID": 33, "context": "(2008), we use the SRI Language Modeling Toolkit (Stolcke, 2002) to estimate individual language models, Pr(~x | y = c), for truthful and deceptive opinions.", "startOffset": 49, "endOffset": 64}, {"referenceID": 5, "context": "We consider all three n-gram feature sets, namely UNIGRAMS, BIGRAMS, and TRIGRAMS , with corresponding language models smoothed using the interpolated Kneser-Ney method (Chen and Goodman, 1996).", "startOffset": 169, "endOffset": 193}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al.", "startOffset": 42, "endOffset": 74}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al. (2008) are equivalent.", "startOffset": 42, "endOffset": 135}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al. (2008) are equivalent. Thus, following Zhou et al. (2008), we use the SRI Language Modeling Toolkit (Stolcke, 2002) to estimate individual language models, Pr(~x | y = c), for truthful and deceptive opinions.", "startOffset": 42, "endOffset": 186}, {"referenceID": 14, "context": "We use SVM (Joachims, 1999) to train our linear SVM models on all three approaches and", "startOffset": 11, "endOffset": 27}, {"referenceID": 8, "context": ", from the aggregate true positive, false positive and false negative rates, as suggested by Forman and Scholz (2009). Human performance is repeated here for JUDGE 1, JUDGE 2 and the SKEPTIC meta-judge, although they cannot be directly compared since the 160-opinion subset on which they are assessed only corresponds to the first cross-validation fold.", "startOffset": 93, "endOffset": 118}, {"referenceID": 28, "context": "The deception detection strategies described in Section 4 are evaluated using a 5-fold nested crossvalidation (CV) procedure (Quadrianto et al., 2009), where model parameters are selected for each test fold based on standard CV experiments on the training folds.", "startOffset": 125, "endOffset": 150}, {"referenceID": 36, "context": "untrained humans often focus on unreliable cues to deception (Vrij, 2008).", "startOffset": 61, "endOffset": 73}, {"referenceID": 15, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively.", "startOffset": 64, "endOffset": 88}, {"referenceID": 3, "context": "However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al., 2008).", "startOffset": 191, "endOffset": 239}, {"referenceID": 10, "context": "However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al., 2008).", "startOffset": 191, "endOffset": 239}, {"referenceID": 13, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively. Work by Rayson et al. (2001) has found strong distributional differences between informative and imaginative writing, namely that the former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs,17 adverbs,18 pronouns, and pre-determiners.", "startOffset": 65, "endOffset": 245}, {"referenceID": 13, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively. Work by Rayson et al. (2001) has found strong distributional differences between informative and imaginative writing, namely that the former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs,17 adverbs,18 pronouns, and pre-determiners. Indeed, we find that the weights learned by POSSVM (found in Table 4) are largely in agreement with these findings, notably except for adjective and adverb superlatives, the latter of which was found to be an exception by Rayson et al. (2001). However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al.", "startOffset": 65, "endOffset": 789}, {"referenceID": 29, "context": "Based on work by Rayson et al. (2001), we expect weights on the left to be positive (predictive of truthful opinions), and weights on the right to be negative (predictive of deceptive opinions).", "startOffset": 17, "endOffset": 38}, {"referenceID": 15, "context": "In agreement with theories of reality monitoring (Johnson and Raye, 1981), we observe that truthful opinions tend to include more sensorial and concrete language than deceptive opinions; in", "startOffset": 49, "endOffset": 73}, {"referenceID": 34, "context": "This finding is also supported by recent work by Vrij et al. (2009) suggesting that liars have considerable difficultly encoding spatial information into their lies.", "startOffset": 49, "endOffset": 68}, {"referenceID": 10, "context": "We also acknowledge several findings that, on the surface, are in contrast to previous psycholinguistic studies of deception (Hancock et al., 2008; Newman et al., 2003).", "startOffset": 125, "endOffset": 168}, {"referenceID": 23, "context": "We also acknowledge several findings that, on the surface, are in contrast to previous psycholinguistic studies of deception (Hancock et al., 2008; Newman et al., 2003).", "startOffset": 125, "endOffset": 168}, {"referenceID": 3, "context": "This pattern makes sense when one considers the goal of our deceivers, namely to create a positive review (Buller and Burgoon, 1996).", "startOffset": 106, "endOffset": 132}, {"referenceID": 23, "context": "Deception has also previously been associated with decreased usage of first person singular, an effect attributed to psychological distancing (Newman et al., 2003).", "startOffset": 142, "endOffset": 163}], "year": 2011, "abstractText": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam\u2014fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}