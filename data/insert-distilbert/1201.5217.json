{"id": "1201.5217", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jan-2012", "title": "Unsupervised Classification Using Immune Algorithm", "abstract": "unsupervised classification algorithm based on computational clonal selection tracing principle named unsupervised clonal selection classification ( ucsc ) is proposed in this paper. the new proposed routing algorithm is data driven and self - adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. the performance of ucsc is evaluated by comparing it consistently with the well known k - digit means algorithm using several artificial dna and real - end life data sets. the experiments do show that the proposed ucsc algorithm is more reliable and has its high classification precision comparing somewhat to traditional classification methods such as traditional k - means.", "histories": [["v1", "Wed, 25 Jan 2012 09:44:06 GMT  (165kb)", "http://arxiv.org/abs/1201.5217v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["m t al-muallim", "r el-kouatly"], "accepted": false, "id": "1201.5217"}, "pdf": {"name": "1201.5217.pdf", "metadata": {"source": "META", "title": "Unsupervised Classification Using Immune Algorithm", "authors": ["M.T. Al-Muallim"], "emails": [], "sections": [{"heading": null, "text": "principle named Unsupervised Clonal Selection Classification (UCSC) is proposed in this paper. The new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The performance of UCSC is evaluated by comparing it with the well known K-means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means.\nGeneral Terms Pattern Recognition, Algorithms.\nKeywords Artificial Immune Systems, Clonal Selection Algorithms, Clustering, K-means Algorithm."}, {"heading": "1. INTRODUCTION", "text": "Unsupervised classification which also known as data clustering is defined as the problem of classifying a collection of objects into a set of natural clusters without any a priori knowledge. Many clustering methods were proposed. These methods can be basically classified into two categories: hierarchical and partitional. In contrast to hierarchical clustering, which yields a successive level of clusters by iterative fusions or divisions, partitional clustering assigns a set of data points into K clusters without any hierarchical structure. This process usually accompanies the optimization of a criterion function [1]. One of the widely used partitional method is the K-means algorithm. It is an iterative hill-climbing algorithm. Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].\nArtificial Immune Systems (AIS) is a field of study devoted to the development of computational models based on the principles of the biological immune system. It is an emerging area that explores and employs different immunological mechanisms to\nsolve computational problems [10] A lot of immune algorithms were developed aiming to finding solutions to a broad class of complex problems. Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21],\ncomputer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].\nMany of the immune algorithms use principles inspired by the clonal selection theory of acquired immunity. The clonal selection principle is used by the immune system to describe the basic features of an immune response to an antigenic stimulus. It establishes the idea that only those cells that recognize the antigens proliferate, thus being selected against those which do not. The process of proliferating called clonal expansion. The selected cells are subject to an affinity maturation process which improves their affinity to the selective antigens [23]. The first clonal selection algorithm was proposed by [13] which named CLONALG and used for optimization. Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].\nIn this study, we tried to investigate the possibility of using clonal selection algorithm as stochastic optimization methods for clustering. Unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is proposed. The new algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The proposed approach has been tested on several artificial and reallife data sets and its performance is compared with the well known K-means algorithm [1]. Experiments show that UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means."}, {"heading": "2. UNSUPERVISED CLONAL SELECTION CLASSIFICATION (UCSC)", "text": ""}, {"heading": "2.1 Basic Principle", "text": "In UCSC, clustering problem is considered as optimization problem and the objective is to find the optimal partitions of data where the resulting clusters tend to be compact as possible. A simple criterion which is the within cluster spread is used in UCSC, this criterion needs to be minimized for good clustering. Unlike K-means which uses the square-error criterion to measure the within cluster spread, UCSC uses the sum of the Euclidean Distances of the points from their respective cluster centroids as clustering metric and uses clonal selection algorithm as clustering algorithm which ensures finding the global optima when most of others algorithms such as K-means stuck into local optima. The number of clusters K is supposed to be known and the appropriate cluster centers m1, m2,\u2026,mk have to be found such that the clustering metric J is minimized. Mathematically,\nthe clustering metric J for the K clusters C={C1, C2, \u2026, CK } is given by the following equation:\nK\ni\nN\nj ijij mxJ 1 1 )M,( (1)\nwhere djx , j = 1,\u2026, N are data points, }{ ij is a\npartition matrix witch given by the eq. (2) , M is centroid matrix witch given by the eq. (3) and d im , i = 1,\u2026, K is the mean for the Ci cluster with Ni data points.\noterwise\nCxif ij ij\n0\n1 with j\nK\ni ij 1 1\n(2)\nM=[m1 , m2 ,\u2026,mK] where N\nj\njij\ni\ni x N m 1\n1 , i = 1,\u2026, K (3)\nThe task of clonal selection algorithm is to search for the appropriate cluster centers wherefore J is minimized. Based on clustering criterion, UCSC is supposed to give right results if the clusters are compact and hyperspherical in shape."}, {"heading": "2.2 Clonal Selection Algorithm", "text": "All clonal selection algorithms have the same basic steps which\nare sumerized as follows: generate population P of antibodies (candidate solutions) while stopping criterion is not met do {\nclone P based on their affinity Submit the result population to hypermutation scheme select the highest affinity solution to form new population\nmaintain diversity in the population } select the highest affinity antibody to form the immune memory which is the solution to the problem.\nThere are certain critical issues that must be taken into consideration while designing and running a clonal selection algorithm such as representing the solution, maintaining diversity in population, affinity metric and hypermutation mechanism. Even a small change in any of these aspects may lead to a considerable change in the performance of clonal selection algorithms [26].\nThe UCSC algorithm is summarized as follows: Initialization: generate population P of n antibodies (candidate solutions) randomly For every generation do: {\naffinity measure of all antibodies in P\nclone P generating a population PC\nsubmit PC to hypermutation scheme generating Pm consolidate P & Pm affinity measure of all antibodies re-select the n highest affinity to form P\nGenerate new L individuals (randomly) replace the L lowest affinity antibodies in P with the new ones }\nfinally: select the highest affinity antibody in P which is the solution These steps will be described in details next."}, {"heading": "2.3 Solution Representing", "text": "Each antibody in P forms a string of real numbers representing the K cluster centers.\nFor d-dimensional space, the length of the string is d*K number, where the coordinates of the centers are localized in sequence.\n],.....,,[ 21 nAbAbAbp (4)\n],.....,,,...,,[ 2111211 Kddl mmmmmAb , l = 1,\u2026, n (5)\nThe first d numbers represent the d dimensions of the first cluster center; the next d positions represent those of the second cluster center, and so on."}, {"heading": "2.4 Affinity Metric", "text": "To measure the affinity of an antibody, the clusters are formed according to the centers encoded in the antibody under consideration, this is done by assigning each point djx , j =\n1,\u2026, N to one of the clusters Ci whose center are the closest to the point. After the clustering is done, the new cluster centroids are calculated by finding the mean points of the respective clusters, then clustering criterion J is calculated by eq. (1). The affinity is defined as:\nJ aff\n1 (6)\nThe maximum value of the affinity standing for the minimum value of J. Zero is assigned to the affinity if any cluster becomes empty."}, {"heading": "2.5 Cloning", "text": "Antibodies in P will be cloned proportionally to their affinities, the higher the affinity the higher the number of clones generated for the antibody. The antibodies were sorted in descending order according to their affinity and then the amount of clones generated for the antibodies was given by:\nl\nn roundncl\n(7)\nWhere ncl is number of clones and \u03b2 is clonal factor."}, {"heading": "2.6 Hypermutation Mechanism", "text": "Every antibody in PC is submitted to a mutation that is inversely proportional to the affinity and this is done according to the following equations:\n)1,0( * NAbAb (8) affe (9)\nWhere Ab* is the resulting antibody of mutate Ab , N(0,1) is a matrix of d*K Gaussian random variables with zero mean and standard deviation =1 , aff is the affinity of the antibody, which is normalized in the range [0 1].\u03b1 is a factor that resizes the value of the Gaussian mutation and it is inversely proportional to\nthe affinity, is a factor that controls the range of \u03b1 . To make the algorithm fast and data driven this factor is given as:\n)min(max datadata (10)\nWhere maxdata and mindata are the maximum and the minimum values of the data features at all dimensions. In this way, the mutation probability depends on the affinity of the antibody and also on the scope of search."}, {"heading": "2.7 New Antibodies Generator", "text": "To generate new random solutions, the scope of search which is the data distribution range in the feature space was determined. The range of data was calculated using the upper and the lower limit of the data at every dimension:\n],,,[ 21 ddata ULULULUL  (11) ],,,[ 21 ddata LLLLLLLL  (12)\nWhere UL data , and LL data are matrixes of the upper and lower\nlimits of the features respectively. Then new random solution is generated using:\nTT\ndatadatadatanew randLLULLLAb )))(diag(( (13)\nWhere rand is a matrix of d*K random variables with uniform probability distribution within the range [0 1]. This random solutions generator is used to insure a fast and accurate performance of UCSC and accelerate the convergence rate of the algorithm since all solutions are in the scope of search."}, {"heading": "3. EXPERIMENTS", "text": "The UCSC was tested using several artificial and real-life data sets, then compared with the well known K-means algorithm [1]. The UCSC was tested with the following parameters n=10, \u03b2 =5, L=4, and number of generations gen=30. For K-means algorithm [1] 1000 as a maximum number of iterations was used in case it does not terminate normally. At every experiment the algorithms were run for 100 times with different random initial configurations To provide statistical evaluation of the performance. The data sets are described below:"}, {"heading": "3.1 Artificial Data Sets", "text": "Dataset 1: An artificial dataset consisting of overlapping two classes (100 patterns each) with bivariate Gaussian density with the following parameters:\nm1=(0.1, 0.1), m2=(0.35, 0.1),\n1.00\n011.0\n21 , where \u03a3 is covariance matrix.\nThe dataset is shown in Figure (1).\nFigure .1: An artificial dataset 1 with two classes.\nDataset 2: An artificial dataset consisting of nine classes (25 patterns each) with bivariate Gaussian density with the following parameters:\nm1=(0.1, 0.1), m2=(0.1, 0.5), m3=(0.1, 0.9), m4=(0.5, 0.1), m5=(0.5, 0.5), m6=(0.5, 0.9), m7=(0.9, 0.1), m8=(0.9, 0.5), m9=(0.9, 0.9),\n08.00\n008.0 ......\n9321\nThe dataset is shown in Figure (2).\nFigure .2: An artificial dataset 2 with nine classes\nDataset 3: An artificial dataset consisting of three classes (50 patterns each) with tripartite Gaussian density with the following parameters:\nm1=(1, 1, 1), m2=(2, 2.5, 2.5), m3=(2, 3, 3),\n3.000\n03.00\n003.0\n321\nThe dataset is shown in Figure (3).\nFigure .3: An artificial dataset 3 with three classes."}, {"heading": "3.2 Real-life Data Sets", "text": "The following real-life dataset has being tested:\n1- Iris dataset [27] consists of 150 four-dimensional\npatterns in three classes (50 patterns each) represent different categories of iris flowers which have four feature values. The four feature values represent the sepal length, sepal width, petal length and the petal width in centimeters. The three classes are: Iris Setosa, Iris Versicolor and Iris Virginica. 2- Wisconsin Breast Cancer dataset [28] consists of 699\nnine-dimensional patterns in two classes which are Benign (458 patterns) and Malignant (241 patterns). The nine features are: Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape, Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, Bland Chromatin, Normal Nucleoli and Mitoses."}, {"heading": "4. RESULTS", "text": "The best classification results of UCSC and K-means after run for 100 times are shown in Table (1) which includes the obtained classification accuracy for all datasets. As we can see from Table (1) the UCSC algorithm provides better accuracy compared with K-means algorithm.\nThe experiments show that K-means algorithm got stuck at suboptimal solutions even for simple data but UCSC did not exhibit any such behavior. Table (2) shows the best values of J and its percentages of the total runs of UCSC and K-means algorithms for every dataset. As we can see from Table (2) for all datasets, UCSC finds better solutions than K-means algorithm and the clusters formed by UCSC are more compact than those formed by K-means algorithm. The results show that UCSC algorithm is more reliable than K-means algorithm because it finds the best solution all the time unlike K-means which did not find the best solution all the times.\nFor all experiments UCSC found the solution in less than 30 generations"}, {"heading": "5. DISCUSSION", "text": "means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable because it finds the best solution all the time unlike K-means which got stuck at sub-optimal solutions. UCSC algorithm has high classification precision comparing to K-means algorithm.\nThe new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible.\nUCSC algorithm has many advantages comparing to other evolutionary algorithms. One is the small population size n=10 where most of other evolutionary algorithms need at lest population size of 100. Second it found the solution in less than 30 generations.\nBased on clustering criterion used in UCSC it supposed to give right results if the clusters are compact and hyperspherical in shape."}, {"heading": "6. CONCLUSION", "text": "In this paper, unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is designed to find the optimal partition between the data. It uses within cluster spread criterion as a clustering criterion. The criterion is based on Euclidean distance between the data in the clusters. The new algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible.\nUCSC is tested on several artificial and real-life data sets and its performance is compared with the well known K-means algorithm [1]. The experiments show that UCSC algorithm has classification precision higher than K-means algorithm which got stuck at sub-optimal solutions even for simple data sets. The new algorithm finds the solution in thirty generations only and it uses a small population size n=10 where most of other evolutionary algorithms need at lest population size of 100. UCSC gives good results if the clusters are compact and hyperspherical in shape"}, {"heading": "7. REFERENCES", "text": "[1] R. Xu, et al., Clustering. Hoboken, New Jersey: John Wiley & Sons, Inc, 2009. [2] G. Babu and M. Murty, \"Clustering with evolution strategies,\" Pattern Recognition, vol. 27, pp. 321-329, 1994. [3] L. Hall, et al., \"Clustering with a genetically optimized approach,\" IEEE Transactions on Evolutionary Computation, pp. 103\u2013112, 1999. [4] U. Maulik and S. Bandyopadhyay, \"Genetic algorithm-based clustering technique,\" Pattern Recognition, vol. 33, pp. 1455- 1465, 2000. [5] L. Y. Tseng and S. B. Yang, \"A genetic approach to the automatic clustering problem,\" Pattern Recognition vol. 34, pp. 415-424, 2001. [6] D. Brown and C. Huntley, \"A practical application of simulated annealing to clustering,\" Pattern Recognition, vol. 25, pp. 401-412, 1992. [7] R. Klein and R. Dubes \"Experiments in projection and clustering by simulated annealing,\" Pattern Recognition vol. 22, pp. 213-220, 1989. [8] S. Selim and K. Alsultan, \"A simulated annealing algorithm for the clustering problems,\" Pattern Recognition vol. 24, pp. 1003-1008, 1991. [9] K. Al-Sultan, \"A Tabu search approach to the clustering problem,\" Pattern Recognition, vol. 28, pp. 1443-1451, 1995. [10] D. Dasgupta and L. F. Ni\u00f1o, Immunological Computation Theory and Applications. Boca Raton: CRC Prees, Taylor & Francis Group, 2009. [11] L. N. de Castro and F. J. Von Zuben, \"An evolutionary immune network for data clustering,\" presented at the Proceeding of Sixth Brazilian Symposium on Neural Networks, Rio de Janeiro, RJ, 2000.\n[12] L. N. de Castro and F. J. Von Zuben, \"The Clonal Selection Algorithm with Engineering Applications,\" presented at the Proceedings of GECCO, Workshop on Artificial Immune Systems and Their Applications, Las Vegas, USA, 2000. [13] L. N. de Castro and F. J. Von Zuben, \"Learning and Optimization Using the Clonal Selection Principle,\" IEEE Transactions on Evolutionary Computation, vol. 6, pp. 239-251, 2002. [14] L. N. de Castro and F. J. Von Zuben, \"aiNet: An Artificial Immune Network for Data Analysis,\" presented at the in Data Mining: A Heuristic Approach, Idea Group Publishing, USA, 2001. [15] A. Watkins and J. Timmis, \"Artificial Immune Recognition System (AIRS): An Immune-Inspired Supervised Learning Algorithm,\" Journal Genetic Programming and Evolvable Machines, vol. 5, pp. 291-317, 2004. [16] D. Dasgupta and S. Forrest, \"Novelty Detection in Time Series Data using Ideas from Immunology,\" presented at the Proceedings of The 5th International Conference on Intelligent Systems, Reno, Nevada, 1995. [17] P. D'haeseleer, et al., \"An Immunological Approach to Change Detection: Algorithms, Analisys and Implications,\" presented at the IEEE Symposium on Security and Privacy, Oakland, CA, 1996. [18] S. Forrest, et al., \"Self-Nonself Discrimination in a Computer,\" presented at the IEEE Computer Society Symposium on Research in Security and Privacy, Oakland, CA, 1994. [19] L. N. de Castro and J. Timmis, \"An artificial immune network for multimodal function optimization,\" presented at the Proceedings of the 2002 Congress on Evolutionary Computation, Honolulu, HI, 2002. [20] F. Guimar\u00e3es, et al., \"Design of mixed control systems using algorithms inspired by the immune system,\" Information Science, vol. 177, pp. 4368-4386, 15 October 2007. [21] D. H. Kim and J. H. Cho, \"Intelligent tuning of PID controller with disturbance function using immune algorithm,\" presented at the IEEE International Conference on Computational Intelligence for Measurement Systems and Applications, 2004. [22] E. Hart and J. Timmis, \"Application areas of AIS: The past, the present and the future,\" Applied Soft Computing, vol. 8, pp. 191-201, January 2008. [23] L. N. de Castro and J. Timmis, Artificial Immune Systems: A New Computational Intelligence Approach: Springer, 2002. [24] V. Cutello, et al., \"Real coded clonal selection algorithm for unconstrained global optimization using a hybrid inversely proportional hypermutation operator,\" presented at the Symposium on Applied Computing archive, Dijon, France 2006. [25] V. Cutello, et al., \"An Immune Algorithm for Protein Structure Prediction on Lattice Models,\" IEEE Transactions on Evolutionary Computation, vol. 11, pp. 101-117, 2007. [26] N. Khilwani, et al., \"Fast clonal algorithm,\" Engineering Applications of Artificial Intelligence, vol. 21, pp. 106-128, 2008. [27] R. A. Fisher, \"The use of multiple measurements in taxonomic Problems,\" Ann. Eugenics, vol. 3, pp. 179-188, 1936. [28] O. L. Mangasarian and W. H. Wolberg, \"Cancer diagnosis via linear programming,\" SIAM News, vol. 23, pp. 1-18, 1990."}], "references": [{"title": "Clustering with evolution strategies,", "author": ["G. Babu", "M. Murty"], "venue": "Pattern Recognition,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1994}, {"title": "Clustering with a genetically optimized approach,", "author": ["L. Hall"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Genetic algorithm-based clustering technique,", "author": ["U. Maulik", "S. Bandyopadhyay"], "venue": "Pattern Recognition,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "A genetic approach to the automatic clustering problem,", "author": ["L.Y. Tseng", "S.B. Yang"], "venue": "Pattern Recognition", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "A practical application of simulated annealing to clustering,", "author": ["D. Brown", "C. Huntley"], "venue": "Pattern Recognition,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1992}, {"title": "Experiments in projection and clustering by simulated annealing,", "author": ["R. Klein", "R. Dubes"], "venue": "Pattern Recognition", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1989}, {"title": "Alsultan, \"A simulated annealing algorithm for the clustering problems,", "author": ["K.S. Selim"], "venue": "Pattern Recognition", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "A Tabu search approach to the clustering problem,", "author": ["K. Al-Sultan"], "venue": "Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1995}, {"title": "Immunological Computation Theory and Applications", "author": ["D. Dasgupta", "L.F. Ni\u00f1o"], "venue": "Boca Raton: CRC Prees, Taylor & Francis Group", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "An evolutionary immune network for data clustering,", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "presented at the Proceeding of Sixth Brazilian Symposium on Neural Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "The Clonal Selection Algorithm with Engineering Applications,\" presented at the Proceedings of GECCO", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "Workshop on Artificial Immune Systems and Their Applications, Las Vegas, USA,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Learning and Optimization Using the Clonal Selection Principle,", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2002}, {"title": "aiNet: An Artificial Immune Network for Data Analysis,\" presented at the in Data Mining: A Heuristic Approach", "author": ["L.N. de Castro", "F.J. Von Zuben"], "venue": "Idea Group Publishing,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Artificial Immune Recognition System (AIRS): An Immune-Inspired Supervised Learning Algorithm,", "author": ["A. Watkins", "J. Timmis"], "venue": "Journal Genetic Programming and Evolvable Machines,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Novelty Detection in Time Series Data using Ideas from Immunology,\" presented at the", "author": ["D. Dasgupta", "S. Forrest"], "venue": "Proceedings of The 5th International Conference on Intelligent Systems, Reno, Nevada,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1995}, {"title": "An Immunological Approach to Change Detection: Algorithms, Analisys and Implications,\" presented at the", "author": ["P. D'haeseleer"], "venue": "IEEE Symposium on Security and Privacy,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Self-Nonself Discrimination in a Computer,\" presented at the IEEE Computer", "author": ["S. Forrest"], "venue": "Society Symposium on Research in Security and Privacy,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}, {"title": "An artificial immune network for multimodal function optimization,\" presented at the", "author": ["L.N. de Castro", "J. Timmis"], "venue": "Proceedings of the 2002 Congress on Evolutionary Computation,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Design of mixed control systems using algorithms inspired by the immune system,", "author": ["F. Guimar\u00e3es"], "venue": "Information Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2007}, {"title": "Intelligent tuning of PID controller with disturbance function using immune", "author": ["D.H. Kim", "J.H. Cho"], "venue": "algorithm,\" presented at the IEEE International Conference on Computational Intelligence for Measurement Systems and Applications,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Application areas of AIS: The past, the present and the future,", "author": ["E. Hart", "J. Timmis"], "venue": "Applied Soft Computing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}, {"title": "Real coded clonal selection algorithm for unconstrained global optimization using a hybrid inversely proportional hypermutation", "author": ["V. Cutello"], "venue": "operator,\" presented at the Symposium on Applied Computing archive,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "An Immune Algorithm for Protein Structure Prediction on Lattice Models,", "author": ["V. Cutello"], "venue": "IEEE Transactions on Evolutionary Computation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2007}, {"title": "Fast clonal algorithm,", "author": ["N. Khilwani"], "venue": "Engineering Applications of Artificial Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "The use of multiple measurements in taxonomic Problems,", "author": ["R.A. Fisher"], "venue": "Ann. Eugenics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1936}, {"title": "Cancer diagnosis via linear programming,", "author": ["O.L. Mangasarian", "W.H. Wolberg"], "venue": "SIAM News,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}], "referenceMentions": [{"referenceID": 0, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 1, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 2, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 3, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 103, "endOffset": 108}, {"referenceID": 4, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 5, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 6, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 135, "endOffset": 140}, {"referenceID": 7, "context": "Many of stochastic optimization methods were used in clustering problem Such as genetic algorithms GAs [2-5], simulated annealing (SA) [6-8] and tabu search (TS) [9].", "startOffset": 162, "endOffset": 165}, {"referenceID": 8, "context": "It is an emerging area that explores and employs different immunological mechanisms to solve computational problems [10] A lot of immune algorithms were developed aiming to finding solutions to a broad class of complex problems.", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 10, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 11, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 12, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 13, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 85, "endOffset": 92}, {"referenceID": 14, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 15, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 16, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 112, "endOffset": 119}, {"referenceID": 11, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 17, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 134, "endOffset": 142}, {"referenceID": 18, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 152, "endOffset": 159}, {"referenceID": 19, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 152, "endOffset": 159}, {"referenceID": 20, "context": "Applications of AIS have included the following areas: clustering and classification [11-15], anomaly detection [16-18], optimization [13, 19], control [20-21], computer security, learning, bio-informatics, image processing, robotics, virus detection and web mining [22].", "startOffset": 266, "endOffset": 270}, {"referenceID": 11, "context": "The first clonal selection algorithm was proposed by [13] which named CLONALG and used for optimization.", "startOffset": 53, "endOffset": 57}, {"referenceID": 21, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 22, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 23, "context": "Other versions of clonal selection algorithm are designed to improve the performance of CLONALG such as [24-26].", "startOffset": 104, "endOffset": 111}, {"referenceID": 23, "context": "Even a small change in any of these aspects may lead to a considerable change in the performance of clonal selection algorithms [26].", "startOffset": 128, "endOffset": 132}, {"referenceID": 24, "context": "1- Iris dataset [27] consists of 150 four-dimensional patterns in three classes (50 patterns each) represent different categories of iris flowers which have four feature values.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "2- Wisconsin Breast Cancer dataset [28] consists of 699 nine-dimensional patterns in two classes which are Benign (458 patterns) and Malignant (241 patterns).", "startOffset": 35, "endOffset": 39}], "year": 2010, "abstractText": "Unsupervised classification algorithm based on clonal selection principle named Unsupervised Clonal Selection Classification (UCSC) is proposed in this paper. The new proposed algorithm is data driven and self-adaptive, it adjusts its parameters to the data to make the classification operation as fast as possible. The performance of UCSC is evaluated by comparing it with the well known K-means algorithm using several artificial and real-life data sets. The experiments show that the proposed UCSC algorithm is more reliable and has high classification precision comparing to traditional classification methods such as K-means. General Terms Pattern Recognition, Algorithms.", "creator": "Microsoft\u00ae Office Word 2007"}}}