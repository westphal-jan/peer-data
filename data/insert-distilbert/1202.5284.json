{"id": "1202.5284", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2012", "title": "Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on Unimodal Functions", "abstract": "in this article we present first an elitism levels traverse mechanism that we implement designed to find bounds dependence on population - based exponential evolutionary algorithms solving unimodal functions. we prove its optimization efficiency theoretically and test it on onemax function deriving bounds c { \\ 1 mu } n log n - o ( { \\ mu } n ). this partial analysis can be generalized to allow any similar algorithm using variants regardless of tournament selection and genetic operators that flip or swap only 1 bit in each string.", "histories": [["v1", "Thu, 23 Feb 2012 20:21:57 GMT  (16kb)", "https://arxiv.org/abs/1202.5284v1", "accepted to Congress on Evolutionary Computation (WCCI/CEC) 2012"], ["v2", "Fri, 16 Mar 2012 04:55:09 GMT  (16kb)", "http://arxiv.org/abs/1202.5284v2", "accepted to Congress on Evolutionary Computation (WCCI/CEC) 2012"], ["v3", "Mon, 2 Apr 2012 04:27:11 GMT  (16kb)", "http://arxiv.org/abs/1202.5284v3", "accepted to Congress on Evolutionary Computation (WCCI/CEC) 2012"]], "COMMENTS": "accepted to Congress on Evolutionary Computation (WCCI/CEC) 2012", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["aram ter-sarkisov"], "accepted": false, "id": "1202.5284"}, "pdf": {"name": "1202.5284.pdf", "metadata": {"source": "CRF", "title": "Elitism Levels Traverse Mechanism For The Derivation of Upper Bounds on Unimodal Functions", "authors": ["Aram Ter-Sarkisov"], "emails": ["a.ter-sarkisov@massey.ac.nz"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 2.\n52 84\nv3 [\ncs .N\nE ]\n2 A\npr 2\n01 2\nIndex Terms\u2014Evolutionary computation, Genetic algorithms, Computational complexity\nI. INTRODUCTION\nWe analyze an elitist population-based Evolutionary Algorithm with population size \u00b5 and recombination pool size \u03bb, (\u00b5 + \u03bb)EA using a genetic operator 1-Bit-Swap that recombines information between parents (see [1]).\nMost research in theoretical EA community is focused on mutation-based single species algorithms such as (1 + 1) 1\n\u00b5 EA\n(see e.g. [2]\u2013[4]) with some sharp bounds on runtime obtained for OneMax function such as 0.982n log n in [4].\nResults on population-based algorithms are less abundant, and are restricted to mostly (\u00b5 + 1) 1\n\u00b5 EA (see [5]) with upper bound\nO(\u00b5n + n log n) and (1 + \u03bb) 1 \u00b5 EA (see [6], [7]) with upper bound on OneMax O(n log n + n\u03bb) in [6] and all linear functions O(\u230an log n\n\u03bb + n log log \u03bb log \u03bb \u230b) in [7].\nAlthough so far (\u00b5 + \u03bb) or (N + N) EAs have deserved less attention, they have been the subject of analysis in [8]\u2013[10]. Specifically, in [10] it was derived that for a (N + N) EA with mutation and tournament selection solving OneMax the upper bound is O(nN logN + n log n) if measured in the number of function evaluations.\nUnfortunately many of these results are not directly comparable due to the difference in selection functions (fitness-proportional, truncation, elitist, tournament, etc) and elitism settings (save 1 best species or some variable proportion).\nEven more significantly, it was shown already in [8] that population effect is generally problem-specific, so it is quite hard to generalize findings to other functions. There is ample evidence though (e.g. [5], [6]) that for mutation-based algorithms (incl. Randomized Local Search, RLS) optimizing simple functions such as OneMax population is not beneficial and tends to degrade performance."}, {"heading": "II. ALGORITHMS AND PROBLEMS", "text": ""}, {"heading": "A. Algorithm", "text": "Although the mechanism described in this paper is quite universal, we test it on (\u00b5 + \u03bb)EA1BS solving OneMax problem. This problem is well-known in EA community, recent achievements include [4], [11] with some sharp bounds. We selected this problem due to its simplicity and the ability to compare our findings to those available already."}, {"heading": "B. Selection function", "text": "Throughout the article we analyze an elitist recombination-driven (\u00b5+\u03bb) EA using a variant of tournament selection. It is both simple to implement and analyze. But since we recombine information between parents, we are interested in forming pairs of species in the recombination pool, and on the construction of these pairs the properties of the algorithm will be derived. This formation occurs in the following way:\nThus it is obvious that better-fit species have higher chances of entering the pool, so we can expect the proportion of \u03b1 species to be higher in the pool rather than in the population.\nC. 1-Bit-Swap Genetic Operator\nWe apply the 1-Bit-Swap operator that was found to be useful solving a large number of test problems in [1] and was analyzed extensively in [12], [13] to have outperformed the mainstream RLS algorithm both theoretically and numerically.\nAnother advantage of 1BS is that we can compare it directly to RLS, since both are local search operators that cannot move too far from the current best search point. The operator works in the following way:"}, {"heading": "III. DEFINITIONS", "text": ""}, {"heading": "A. Fitness levels partition", "text": "Basic approach to analyzing elitist EA with a simple 1-bit mutation solving unimodal binary-encoded EAs was introduced by Wegener in [14] that is based on fitness partitioning: on a set of binary strings {0, 1}n size 2n a partition into a finite number of nonempty subsets A1, A2, \u00b7 \u00b7 \u00b7 , Am is defined with ordering A1 - A2 - \u00b7 \u00b7 \u00b7 - Am s.t. all a \u2208 Am are the global optimum.\nThis approach allows definition and derivation of the lower bound of success probability of transition between states, si(a) = P (Ai+1|Ai) and the upper bound on expected convergence time of the algorithm, expected first hitting time of the best fitness level, E(Xf ) \u2264 s\u221211 + s\u221212 . . . + s\u22121m\u22121. This idea can be extended to the situation when we apply non-negative weights w(f) (see [2], [14]) and to derive lower bounds (by considering the upper bound on si(a).\nAnother tool used extensively in the analysis of EAs are potential (auxiliary) functions that measure progress (see [14]). This is especially useful when working on functions that have fitness plateaus (see e.g. [15]), in which case we make the difference:\n1) fitness functions decide whether the new binary input (species) is better than the old one 2) potential function tracks the progress between states of the algorithm (fitness levels)\nOneMax (or some simple transformation of it) is used as a potential function for more complicated problems (Royal Roads, Binary Values, Short/Long Path etc)."}, {"heading": "B. Elitism Levels Partition", "text": "In this article we extend this approach to a population-based elitist algorithm, but rather than tracking the traverse of levels of fitness, we do the same to the levels of elitism, i.e., number of elite species in the population.\nWe focus on species that can either evolve to the currentlybest over 1 iteration or are already best. Therefore, the population\nis broken down into three disjoint subsets:\n\u03b1 : currently best species\n\u03b21 : species with next-best fitness\n\u03b2\u22121 : the rest of the population that cannot evolve over 1 generation\nSince 1BS swaps exactly 1 bit between two parents, this partition in combination with the assumptions made above enables construction of a very precise model, since the value of \u03b1 cannot \u2019jump\u2018 more than 1 level of fitness and only \u03b1-species can breed better population, but only \u03b21-species may evolve into \u03b1 and change the probability of evolution."}, {"heading": "C. \u03b1-levels subpartition", "text": "This additional partition is necessary for functions with plateaus for which we use potential functions explained above. The need for it becomes evident in the next section, when probabilities of evolving elite species on two types of functions are compared. In addition to the elitism levels partition, for functions with plateaus we need to subpartition the \u03b1-level.\nIn slight abuse of notation in the rest of this article, we denote A the set of chromosomes in the population with the highest fitness. Also \u03b3 is the length of the plateau of fitness. Therefore the set A can be partitioned into\nA = A0 \u222aA1 \u222a \u00b7 \u00b7 \u00b7 \u222aA\u03b3\u22121 where each subset Am has equal fitness. In order to differentiate between Am, we assign each elite species an additional auxiliary function, Vm that tracks progress to the next level by counting the number of 1-bits in the fitness level: A0 - A1 - . . . - A\u03b3\u22121 with corresponding auxiliary values V0 < V1 . . . < V\u03b3\u22121, i.e. OneMax is used as an auxiliary function. Species with both highest fitness and auxiliary values can be viewed as super-elite or \u03b1\u2217.\nIn the next section we use the notation \u03b1, \u03b1\u2217 to denote the set of elite or super-elite species, an element of that set and the size of it. This is done to reduce notational clutter."}, {"heading": "IV. ELITISM LEVELS TRAVERSE MECHANISM FOR UPPER BOUNDS", "text": "In this section we present the main result of the article on a general function that is later confirmed by further application to OneMax Test Function. We are interested in the upper bounds on optimization time (for explanation of Landau notation see e.g. Chapter 9 in [16]).\nThe working of the Elitism Levels Traverse Mechanism can be illustrated by an example from immunology.\nThere exists a population of species size N , which is susceptible to M types of infection, which are mutually exclusive, i.e. a species cannot be infected by more than one infection. The size of each set of infected species cannot be larger than mj . We denote E\u2217j an event that there are 1 \u2264 r \u2264 mj infected species of type j, of which exactly one spawns an infected offspring that destroys a healthy member of the population. Since the sets of infected species are mutually exclusive, by additivity we obtain the probability that any of the infected species adds exactly one infected offspring:\nP\n( M \u22c3\nj=1\nE \u2217 j\n)\n= P\n( M \u22c3\nj=1\nmj \u22c3\nr=1\nE \u2217 jr\n)\n=\nM \u2211\nj=1\nmj \u2211\nr=1\nP (E\u2217jr) =\nM \u2211\nj=1\nP (E\u2217j )\nThis expression is quite complicated for a number of reasons, e.g. the knowledge of mj . Although we can find bounds on the partial sum of rows of Pascal triangle, it is guaranteed to make the derivation quite messy. Therefore we need to lower-bound this probability. We do this by considering only one infected species of each type rather than r and the event of spawning exactly one infected species by Ej . This gives us the lower bound on the total probability of adding exactly one infected offspring, which is proven in Appendix A:\nP (E\u2217j ) \u2265 P (Ej) \u2194 M \u2211\nj=1\nP (E\u2217j ) \u2265 M \u2211\nj=1\nP (Ej) (1)\nIn the notation of EA, N = \u03bb 2 , the number of pairs of parents in the recombination pool with parents that are able to produce exactly one elite offspring. \u03b4\u00b5 (for 0 < \u03b4 < 1) is the number of elite individuals in the population that, once it is reached, the probability to generate an offspring with higher fitness is arbitrarily close to one, i.e. 1\u2212o(1). We also have n\u2212 1 levels of fitness. Combining this with the upper bound on the probability of adding elite offsprings to the population, we obtain the upper bound (worst-case) on the optimization time of the algorithm:\nE\u03c4 = O\n( n \u2211\nk=1\n\u03b4\u00b5 \u2211\n\u03b1=1\n1 \u2211M\nj=1 P (Ej(\u03b1, k))\n)\n(2)\nDerivation of the upper bound from Equation 2 is rather versatile. We need to identify pairs of possible parents < p1, p2 > such that there exists some probability of swapping bits between parents \u03d5j(k) > 0 that as a results of applying a genetic operator to this pair either a new \u03b1 species evolves from lower-ranked ones or an existing \u03b1 is preserved after the recombination.\nIntuitively, for the functions with plateaus both the population size and the number of elite species are more important than for those without plateaus. In the remainder of this section we show that the probability to add a super-elite offspring when solving a function with plateaus is less than the probability to add an elite offspring when solving functions without plateaus.\nFor the rest of this section we denote f1 function without plateaus and f2 function with plateaus. What we show is that P (Ef1j (\u03b1, k)) \u2265 P (Ef2j (\u03b1, k))."}, {"heading": "A. Functions without plateaus", "text": "For this type of unimodal functions (e.g. OneMax) intuitively it is easier to add an elite offspring and thus reduce the optimization time, but we need to show it rigorously.\nThe probability to select a pair with an \u03b1-parent can be bounded by\nP f1 sel \u2265\n\u03b1 \u00b5 \u03be1\nwhere \u03be1 is the probability to select a non-elite species to be paired with the elite one. Also bound the probability to flip the bits \u03d5j(k) \u2265 \u03b7 \u2200 j, k. So the probability of an event Ej that includes pairs with elite species is\nP (Ef1j ) \u2265 ( \u03bb 2\n1\n)\n\u03b1 \u00b5 \u03b7\u03be1 = \u03bb\u03b1\u03b7\u03be1 2\u00b5\nThe probability to select a pair without the the currently-elite species is lower-bounded by \u03c11\n\u00b5 . By breaking down the set of parents Mf1\nin the recombination pool into those including \u03b1\u2212 parents, M\u2217f1\nand those that do not, M\u2217\u2217f1 , we can find the lower bound on the probability of adding another elite species:\nP (Sf1\u03b1,k) \u2265 M\u2217f1\u03bb\u03b1\u03be1\u03b7\n2\u00b5 +\nM\u2217\u2217f1 \u03bb\u03b7\u03c11\n2\u00b5"}, {"heading": "B. Functions with plateaus", "text": "As noted in [10], algorithms with well-chosen population size perform similar to, and best individuals evolve along the same path as (1 + 1)EA. The difference between (\u00b5 + \u03bb)and (1 + 1) lies in the cost of traversing plateau. For this type of functions the length of plateau \u03b3 > 1. So we have K plateaus w.l.o.g. of the same length \u03b3 \u2208 Z+, and n = \u03b3K.\nAlso we assume that at the start of the algorithm each \u2018bin\u2019 (plateau) starts with an equal number of 1\u2019s and 0\u2019s uniformly distributed, therefore fitness of the best species at the beginning of the run is 0. To track progress between jumps in fitness values we use OneMax as an auxiliary function (roughly along the lines of using potential or distance functions, see e.g. [7]) that sums bits in the plateau.\nThe tricky part in this analysis is that the selection is based on fitness of the string rather than auxiliary function, but the progress towards the next level of fitness plateau depends on the number of parents with highest auxiliary value, Vs rather than f(s). By denoting the subset of \u03b1 with highest auxiliary function \u03b1\u2217, we notice that f(\u03b1) = f(\u03b1\u2217), and V\u03b1 < V\u03b1\u2217 . Also trivially \u03b1\u2217 \u2264 \u03b1 (for the case of functions without plateaus these functions are identical and last two expressions are equalities).\nAs shown before, for a unimodal function without plateaus regardless of fitness function, the probability that one of the parents is elite is \u03b1\n\u00b5 , since if two elite species are selected for breeding,\nparent is chosen randomly. Obviously \u03b1 \u2217 \u00b5 \u2264 \u03b1 \u00b5 . Additionally,\n\u03b1\u2217 \u00b5 \u00b7 (\u03b1\u2212 \u03b1 \u2217) \u00b5 \u00b7 1 2 \u2264 \u03b1 \u2217 \u00b5 \u2264 \u03b1 \u00b5\nObviously, unlike f1, for the evolution process on f2 only a small subset of parents are of use, these having the highest and next-highest auxiliary values. Therefore pairs that do not include at least 1 of these parents can\u2019t add an \u03b1\u2217 offspring. Similar to f1, Mf2 = M \u2217 f2 +M\u2217\u2217f2 and clearly M \u2217 f2 \u2264 M\u2217f1 and M \u2217\u2217 f2 \u2264 M\u2217\u2217f1 .\nAlong the lines of arguments in the previous subsection, \u2203\u03be2 s.t. probability to select a non super-elite parent in addition to the super-elite one is upper-bounded by it. We get:\nP f2 sel \u2264 \u03b1\u2217(\u03b1\u2212 \u03b1\u2217)\u03be2 2\u00b52\nso the probability of an event that an \u03b1\u2217 parent is added to a pool and a new \u03b1\u2217 offspring evolves is upper-bounded by\nP (Ef2j ) \u2264 M\u2217f2\u03bb\u03b1 \u2217(\u03b1\u2212 \u03b1\u2217)\u03be2\u03b7 4\u00b52\nwhere \u03b7 is the lower bound on the probability of swapping bits. Therefore the probability to add one more \u03b1\u2217 species to the population is\nP (Sf2\u03b1,k) \u2264 M\u2217f2\u03bb\u03b1 \u2217(\u03b1\u2212 \u03b1\u2217)\u03be2\u03b7 4\u00b52 + M\u2217\u2217f2 \u03bb\u03b7\u03c12 2\u00b5\nCombining the inequalities above, and taking M\u2217\u2217f1 \u2265 M \u2217\u2217 f2 + \u01eb \u03c11 , 0 < \u01eb < 1, we compare the values in the first and second fractions\nin the expressions for P (Sf1\u03b1,k) and P (S f2 \u03b1,k). It is easy to see that \u2203 two constants \u03c82 < \u03c81 s.t.\nP (Sf2\u03b1,k) \u2264 \u03c82 < \u03c81 \u2264 P (S f1 \u03b1,k) (3)\nV. UPPER BOUND ON RUNTIME OF (\u00b5+ \u03bb)EA1BS ON ONEMAX TEST FUNCTION USING ELITISM LEVELS TRAVERSE MECHANISM\nIn this section we present our findings on the upper bounds on runtime of (\u00b5 + \u03bb)EA with 1-Bit-Swap operator optimizing OneMax function using the Elitism Levels Traverse Mechanism. We distinguish four pairs of parents that make possible evolution of currently-elite species:\nE1 :< \u03b1, \u03b21 >\nE2 :< \u03b21, \u03b21 >\nE3 :< \u03b1, \u03b2\u22121 >\nE4 :< \u03b21, \u03b2\u22121 >\nWe do not consider the obvious pair < \u03b1, \u03b1 > as it either adds two elite offsprings, of generates an offspring with higher fitness, something we do not use in the Mechanism.\nFor the upper bound on optimization time we only consider increase of the number of elite species by at most one. Increase by two or more is ignored, or otherwise transformed into any of the lower-ranked species. Similar approach was used in [10] in bounding the takeover time."}, {"heading": "A. Simple upper bound", "text": "Of these four cases we start analysis with the first two. Main reason is that the other two cases involve cubic function, which becomes quite complicated to solve (see next subsection). For the cases E1, E2 we get the following probabilities of success:\nP (E1) = 2\n(\n\u03bb 2 1\n)\n\u03d51(k) \u00b7 \u03b1 \u00b5 \u00b7 \u03b21 \u00b5\n(\n1\u2212 \u03b1 \u00b5\n)\n= \u03b1\u03b21\u03bb(\u00b5\u2212 \u03b1)\u03d51(k)\n\u00b53\nP (E2) =\n(\n\u03bb 2 1\n)\n\u03d52(k)\n(\n\u03b21\n\u00b5\n(\n1\u2212 \u03b1 \u00b5\n))2\n= \u03bb\u03d52(k)\u03b2 2 1(\u00b5\u2212 \u03b1)2 2\u00b54\nThe probability of at least 1 of these events is\nP (S\u03b1,k) \u2265 P (E1) + P (E2) = 2\u03d51(k)\u03b1\u03b21\u03bb(\u00b5\u2212 \u03b1)\n\u00b53\n+ \u03d52(k)\u03bb\u03b2 2 1\u03d51(k)(\u00b5\u2212 \u03b1)2 2\u00b54\nand, since P (S) is minimal, the upper bound on expected time to traverse levels of elitism large enough to get a 1\u2212 o(1) probability of evolution is\nET\u0303\u03b1,k \u2264 \u03b4\u00b5 \u2211\n\u03b1=1\n1\nP (S\u03b1) (4)\nThe expression for the expected first hitting time we obtain as a result of this setup is\nET\u0303\u03b1,k \u2264 2\u00b54 \u03b4\u00b5 \u2211\n\u03b1=1\n1\n\u03b21\u03bb(\u00b5\u2212 \u03b1)(2\u03b1\u00b5\u03d51(k)\u2212 \u03b1\u03b21\u03d52(k) + \u03b21\u00b5\u03d52(k))\n= 2\u00b54\n\u03bb \u00b7\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n(\u03d52(k)\u2212 2\u00b5\u03d51(k))\u03b12 + (2\u00b52\u03d51(k)\u2212 2\u00b5\u03d52(k))\u03b1+ \u00b52\u03d52(k)\n= 2\u00b54\n\u03bb(\u03d52(k)\u2212 2\u00b5\u03d51(k))\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n\u03b12 + b1\u03b1+ b0 (5)\nwhere\nb0 = \u00b52\u03d52(k)\n\u03d52(k)\u2212 2\u00b5\u03d51(k)\nb1 = 2\u00b5(\u00b5\u03d51(k)\u2212 \u03d52(k)) \u03d52(k)\u2212 2\u00b5\u03d51(k)\nAt this point we set \u03b21 pessimistically to 1 to simplify the derivation. This a quadratic equation in \u03b1. The full solution to Equation 5 is in Appendix B.\nThe optimization time is\nE\u03c4(\u00b5+\u03bb)EA1BS = O(\u00b5 1+\u03b52n log n) (6)\nfor some constant \u03b52(\u00b5). For the second option of \u03b4 = c\u00b5 the upper bound becomes\nE\u03c4(\u00b5+\u03bb)EA1BS = O(\u00b5n log n) (7)\nor, in the number of function evaluations\nE\u03c4(\u00b5+\u03bb)EA1BS = O(\u03bb\u00b5n log n) (8)"}, {"heading": "B. Refined upper bound", "text": "We add the other two cases to obtain a sharper upper bound on optimization time, we set \u03b21 = 1:\nP (E3) = 2\n(\n\u03bb 2 1\n)\n\u03b1 \u00b5 \u00b7 ( 1\u2212 \u03b1+ \u03b21 \u00b5 )2 \u03d53(k)\n\u2248 \u03bb\u03b1 \u00b5\n(\n1\u2212 \u03b1 \u00b5\n)2\n\u03d53(k)\nP (E4) = 2\n(\n\u03bb 2 1\n)\n\u03b21\n\u00b5\n(\n1\u2212 \u03b1 \u00b5\n)(\n1\u2212 \u03b1+ \u03b21 \u00b5\n)2\n\u03d54(k)\n\u2248 \u03bb \u00b5\n(\n1\u2212 \u03b1 \u00b5\n)3\n\u03d54(k)\nThe probability to evolve one more elite species is (P (E1), P (E2) are the same as in the previous derivation):\nP (S\u03b1,k) = P (E1) + P (E2) + P (E3) + P (E4)\nand the expected time until there are \u03b4\u00b5 elite strings in the population:\nET\u0303\u00b5,k \u2264 \u03b4\u00b5 \u2211\n\u03b1=1\n1\nS\u03b1,k\n= 2\u00b54 \u03b4\u00b5 \u2211\n\u03b1=1\n1\nb3\u03b13 + b2\u03b12 + b1\u03b1+ b0\n= 2\u00b54\nb3\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n\u03b13 + b2 b3 \u03b12 + b1 b3 \u03b1+ b0 b3\n(9)\nwhere\nb0 = \u03bb\u00b5 2(2\u00b5\u03d54(k) + \u03d52(k)) b1 = 2\u03bb\u00b5(\u00b5\u03d51(k) + \u00b5 2 \u03d53(k)\u2212 3\u00b5\u03d54(k)\u2212 \u03d52(k)) b2 = \u03bb(\u03d52(k)\u2212 4\u00b52\u03d53(k)\u2212 2\u00b5\u03d51(k)\u2212 6\u00b5\u03d54(k)) b3 = 2\u03bb(\u00b5\u03d53(k)\u2212 \u03d54(k))\nFull solution of Equation 9 is in Appendix C.\nThe upper bound on expected optimization time is (for \u03b4 6= c \u00b5 , c is a constant):\nE\u03c4(\u00b5+\u03bb)EA1BS = c\u00b51+\u01ebn log n\n\u03bb \u2212O\n(\n\u00b51+\u01ebn\n\u03bb\n)\n(10)\nfor 0 < \u01eb(\u00b5) < 1 and if \u03b4 = c \u00b5 , in the number of function evaluations:\nE\u03c4(\u00b5+\u03bb)EA1BS = c\u00b5n log n\u2212O(\u00b5n) (11)\nThis bound is sharper than the one obtained using simpler arguments earlier in this paper up to the order \u03bb (since more possibilities of adding elite species are considered). It is also comparable to the results in [6], [7], [10] (see below). Such a result likely means that population has positive effect for some relatively small \u00b5, but as it keeps increasing it either levels out (at best) or starts to degrade performance."}, {"heading": "C. Generations vs Function evaluations", "text": "Tournament selection has a property that you do not need to evaluate every species, but we need to make 2\u03bb evaluations (since two species compete for 1 slot in the recombination pool, so the number of evaluations each generation is O(\u03bb). Therefore, in terms of the number of functions evaluations the rough bound becomes O(\u00b5\u03bbn log n) and the refined one O(\u00b5n log n). If \u00b5 = \u03bb = O(1) this reduces to the well-known result of O(n log n) for OneMax function. The \u03bb term in the denominator means that for the algorithm run on parallel computers the increase in the recombination pool size improves the performance."}, {"heading": "D. Comparison to earlier results", "text": "The closest comparison we can draw is to (N+N )EA with mutation and tournament selection function in [10], O(nN logN + n log n) if measured in the number of function evaluations (Proposition 4). By setting N = O(1) = c \u2265 1 this bound becomes n log n + O(n), which is larger than just O(n log n). If instead we set \u00b5 = N = O( \u221a log n) or O( log n\nlog log n ) the result in [10] is sharper than in\nthis paper. For populations \u2126( \u221a n\nlog n ) though the bound in this article\nbecomes sharper again, e.g., for \u00b5 = N = O( \u221a n) it is cn 3\n2 log n\u2212 n 3 2 , and in [10] it is n 3\n2 log n 2 +O(n log n)."}, {"heading": "VI. DISCUSSION", "text": "We presented a new tool to analyze population-based elitist EAs, Elitism Levels Traverse Mechanism, which we used to derive a new upper bound on (\u00b5 + \u03bb) EAs with a recombination operator and a variant of tournament selection solving OneMax problem.\nWe derived and proved the lower bound on the probability of evolving exactly 1 new currently-elite species, which helped us obtain the upper bound on the expected optimization time.\nWe showed that for a function with fitness plateaus it is harder to add a super-elite offspring to the population than an elite offspring\nfor a function without plateaus. This means that the very number of super-elite species in the population is more important in the former case than the number of elite species in the latter.\nIt may seem from the derived equations that population generally degrades performance (since \u00b5 is in the numerator), but for small size of population, when the cost of functions evaluations is not much different from 1, population brings about some positive effect.\nAs it keeps increasing, the effect levels out, at the same time the costs of evaluating functions grows and population loses its benefit. For other algorithms, s.a. RLS the effect even of small-sized population is usually negative, which makes EA+1BS (and, possibly, other recombination-based algorithms) stand out.\nAt the same time the recombination pool improves performance (at least when measured in terms of the number of generations), since \u03bb is in the denominator. This means there is a benefit from increasing recombination pool size when the algorithm is run on parallel computers.\nThe Mechanism we have designed in this article proved to be quite efficient in deriving upper bounds for OneMax function and we are confident it can also yield tight upper bounds on other population-driven algorithms and more complicated problems."}, {"heading": "VII. CONCLUSIONS AND FUTURE WORK", "text": "There are many reasons to use population in evolutionary computing rather than just (1+ 1) or (1, 1) algorithms, that includes higher diversity and shorter evolutionary path (see [10]). We intend to expand the results in this article by considering the following extensions to the upper bound tool:\n1) Analysis of functions with fitness plateaus. Apparently for functions with fitness plateaus (e.g. Royal roads) both large populations and large number of elite parents are crucial compared to functions without one, so we will extend our findings to these functions as well. 2) Typical runtime analysis. It is fairly obvious that the actual number of elite species grows every generation at some rate that realistically lies between the upper and lower bounds. We need to find an approximation on the expected number of \u03b1 added to the population every generation and thus estimate the typical runtime. 3) Elitism rates analysis. In this article we never really considered the rate of elitism, i.e. the actual number of species saved in the population each generation, although numerical computation shows that it has a strong effect on the runtime. So far we only said that all the elite species are saved each generation, thus accumulating over time till \u03b4\u00b5. It would be interesting to compare elitism level 1 to 50%, i.e. if there is any difference if only 1 species is saved compared to half of the population. 4) Derivation of \u03b4\u00b5 to find the proportion of elite species that yields a high enough probability of evolution. Quite obviously it is different for functions with plateaus and without. 5) Derivation of the optimal population size. We will do this by comparing the number of functions evaluations necessary of (1 + 1) and (\u00b5+ \u03bb) algorithms."}, {"heading": "APPENDIX A PROOF OF EQUATIONS 1-2", "text": "Main idea and logic of the lower bound on the probability of adding an elite offspring and the upper bound on runtime following from this is presented in Section IV. Here we present the derivation of this bound.\nWe prove this lower bound inequality for an arbitrary subset (it is not to be confused with at trivial one of the form\n\u2211 k\u2265r ( n k ) pk(1\u2212 p)k > ( n r ) pr(1\u2212 p)n\u2212r):\nP (Ej) =\n(\n\u03bb 2 1\n)\nPselPswap =\n(\n\u03bb 2 1\n)\nPsel\u03d5j(k)\nP (E\u2217j ) = P\n( mj \u22c3\nr=1\nE \u2217 jr\n)\n=\nmj \u2211\nr=1\n(\n\u03bb 2 r\n)\nP r sel(1\u2212 Psel)\n\u03bb 2 \u2212r\n(\nr\n1\n)\n\u03d5j(k)(1\u2212 \u03d5j(k))r\u22121\nIn this expression Pswap is not necessarily the probability to swap bits < 0, 1 >. It is the probability to swap bits such that an elite offspring evolves. Since all the terms in the sum are positive, we use the lower bound on this expression:\nP (E\u2217j ) \u2265 mj \u2211\nr=1\n(\n\u03bb 2 r\n)\nP r sel(1\u2212 Psel)\n\u03bb 2 \u2212r \u03d5j(k)(1\u2212 \u03d5j(k))r\u22121\n\u2265 \u03d5j(k) (1\u2212 \u03d5j(k)\n( mj \u2211\nr=0\n(\n\u03bb 2 r\n)\nP r sel(1\u2212 \u03d5j(k))r(1\u2212 Psel)\n\u03bb 2 \u2212r\n\u2212 (1\u2212 Psel) \u03bb 2\n)\n\u2265 \u03d5j(k) ( mj \u2211\nr=0\n(\n\u03bb 2 r\n)\nP r sel(1\u2212 \u03d5j(k))r(1\u2212 Psel) \u03bb 2 \u2212r\u2212\n(1\u2212 Psel) \u03bb 2\n)\nCanceling out \u03d5j(k) and moving the term e\u22121 \u2264 (1 \u2212 Psel) \u03bb 2 \u2264 1\u221a e < 1 on the other side, LHS of the inequality becomes\nP (E\u2217j ) \u2265 mj \u2211\nr=0\n(\n\u03bb 2 r\n)\nP r sel(1\u2212 \u03d5j(k))r(1\u2212 Psel)\n\u03bb 2 \u2212r\n\u2265 (Psel(1\u2212 \u03d5j(k)) + 1\u2212 Psel) \u03bb 2 = (1\u2212 Psel\u03d5j(k)) \u03bb 2\nand the RHS is upper-bounded by\n1\u221a e + \u03bbPsel 2 = 1\u221a e + o(\u03bbc\u22121)by the argument below\nLHS is lower-bounded by (using Bernoulli inequality for \u03bb 2 \u2265 1):\nP (E\u2217j ) \u2265 (1\u2212 Psel\u03d5j(k)) \u03bb 2 \u2265 1\u2212 \u03bbPsel\u03d5j(k)\n2\nSince we can select Psel = o(\u03bbc) and \u03d5j(k) = O( 1nc ), c \u2208 Z, the expression is\nP (E\u2217j ) = 1\u2212 o(1) > 1\u221a e + o(1) = P (Ej) (12)\nthus proving the upper bound on the probability of evolving 1 more elite species for an arbitrary subset. This logic applies for each of the M subsets (types of pairs) of the recombination pool, and the inequality becomes\nP\n(\nM \u22c3\nj=1\nE \u2217 j\n)\n>\nM \u2211\nj=1\nP (Ej) (13)\nThe upper bound in Equation 2 follows directly."}, {"heading": "APPENDIX B SOLUTION OF EQUATION 5", "text": "We have a quadratic equation\nS(\u00b5, k) = \u2211\n\u03b1\nP2(\u03b1) =\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n\u03b12 + b1\u03b1+ b0\nwith\nb0 = \u00b52\u03d52(k)\n\u03d52(k)\u2212 2\u00b5\u03d51(k)\nb1 = 2\u00b5(\u00b5\u03d51(k)\u2212 \u03d52(k)) \u03d52(k)\u2212 2\u00b5\u03d51(k)\nIn order to simplify the already complicated derivation, we want the expression above in the form\nP2(\u03b1) = 1\n(\u03b1+ r)2 =\n1\n(\u03b12 + 2r\u03b1+ r2)\nfor some r, not necessarily rational. From equating coefficients it becomes clear that\nr = \u221a b0 \u2228 r = b1\n2\nand so, using the first root\nS(\u00b5, k) =\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n(\u03b1+ r)2 = \u03c81(\n\u221a b0)\u2212 \u03c81( \u221a b0 + \u03b4\u00b5+ 1)\nFor large b0 these expressions involving digamma function can be expanded asymptotically in Taylor series (we use only the first two terms):\nS(\u00b5, k) \u2248 ( 1\nb0 \u2212 1 2b0\n)\n\u2212 ( 1 b0 \u2212 \u03b4\u00b5 b0 \u2212 1 2b0 ) = \u03b4\u00b5 b0\n= \u03b4\u00b5(\u03d52(k)\u2212 2\u00b5\u03d51(k))\n\u00b52\u03d52(k) = \u03b4(\u03d52(k)\u2212 2\u00b5\u03d51(k)) \u00b5\u03d52(k)\nand therefore the expected time to traverse enough levels of elitism to improve 1 bit of the string is (plugging this expression into Equation 5)\nET\u0303\u00b5,k = 2\u00b54 \u03bb(\u03d52(k)\u2212 2\u00b5\u03d51(k)) \u00b7 \u03b4(\u03d52(k)\u2212 2\u00b5\u03d51(k)) \u00b5\u03d52(k)\n= 2\u00b53\u03b4\n\u03bb\u03d52(k)\nTo improve the pair < \u03b21, \u03b21 > we need to either swap 1 from the first parent and 0 from the second, or the other way around (any other outcome just keeps the current number of bits in each parent):\n\u03d52(k) = 2 \u00b7 k \u2212 1 n \u00b7 n\u2212 k + 1 n = 2(k \u2212 1)(n\u2212 k + 1) n2\nPlugging this into the expression for ET\u0303k, we obtain the expected optimization time of the algorithm, pessimistically assuming that at the beginning of the run the best species has only 2 1-bit and finishes at n \u2212 2, since if the fitness of \u03b21 = n \u2212 1 implies the fitness of \u03b1 = n.\nE\u03c4(\u00b5+\u03bb)EA1BS \u2264 \u00b53n2\u03b4\n\u03bb\nn\u22122 \u2211\nk=2\n1\n(k \u2212 1)(n\u2212 k + 1)\n= \u03b4\u00b53n2 \u03bb \u00b7 1 n\n(\nn\u22122 \u2211\nk=2\n1 k \u2212 1 + n\u22122 \u2211\nk=2\n1\nn\u2212 k + 1\n)\n= \u03b4\u00b53n\n\u03bb\n( log(n\u2212 1) +O(1) )\nThe second step is due to partial fraction expansion. Although this seems quite a loose bound given cubic in \u00b5, we take \u00b5 = O(\u03bb) so all we need to establish is \u03b4 to reduce the power.\nObviously 0 < \u03b4 < 1, but we need to select it s.t. summation over \u03b1 makes sense. We set \u03b4 = \u00b5\u2212\u03b51 for an arbitrary \u03b51 > 0 s.t. \u03b4\u00b5 = \u00b51\u2212\u03b51 > 1. Then \u03b4\u00b52 = \u00b52\u2212\u03b51 = \u00b51+\u03b52 . For example, \u03b5 = 1\n2 yields \u03b4\u00b5 =\n\u221a \u00b5 and \u03b4\u00b52 = \u221a\n\u00b53. Therefore, the upper bound on the expected convergence time is\nE\u03c4(\u00b5+\u03bb)EA1BS = O(\u00b5 1+\u03b52n log n) (14)\nIn fact if (similar to [10]) we set \u03b4 = c \u00b5 for c \u2208 Z+, we get \u03b4\u00b5 = c and \u03b4\u00b52 = c\u00b5 = O(\u00b5), so the expectation becomes linear in \u00b5:\nE\u03c4(\u00b5+\u03bb)EA1BS = O(\u00b5n log n) (15)"}, {"heading": "APPENDIX C SOLUTION TO EQUATION 9", "text": "We need a solution to the cubic equation of the form\nS(\u00b5, k) = \u2211\n\u03b1\nP3(\u03b1) =\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n\u03b13 + b\u20322\u03b12 + b \u2032 1\u03b1+ b0\nwhere\nb \u2032 2 = \u03d52(k)\u2212 4\u00b52\u03d53(k)\u2212 2\u00b5\u03d51(k)\u2212 6\u00b5\u03d54(k) 2(\u00b5\u03d53(k)\u2212 \u03d54(k))\nb \u2032 1 =\n\u00b5(\u00b5\u03d51(k) + \u00b5 2\u03d53(k)\u2212 3\u00b5\u03d54(k)\u2212 \u03d52(k))\n2(\u00b5\u03d53(k)\u2212 \u03d54(k))\nb \u2032 0 =\n\u00b52(2\u00b5\u03d54(k) + \u03d52(k))\n2(\u00b5\u03d53(k)\u2212 \u03d54(k))\nSolution to S(\u00b5, k) is of the form\nS(\u00b5, k) = \u2211\n\u03b1\n1\n(\u03b1+ \u03c1)3 = \u2211\n\u03b1\n1\n\u03b13 + 3\u03b12\u03c1+ 3\u03b1\u03c12 + \u03c13\nEquating the coefficients we obtain three roots \u03c1:\n\u03c1 = b\u20322 3 \u03c1 = \u00b1 \u221a\nb\u20321 3\n\u03c1 = 3 \u221a b\u20320\nTo simplify the increasingly hard notation, we select only the last root:\nS(\u00b5, k) =\n\u03b4\u00b5 \u2211\n\u03b1=1\n1\n(\u03b1+ 3 \u221a b\u20320) 3 =\n\u03c82( 3 \u221a b\u20320 + \u03b4\u00b5+ 1)\u2212 \u03c82( 3 \u221a b\u20320 + 1)\n2\n= 1\n2\n((\n\u2212 1 3 \u221a\nb\u20320 2 +\n2\u03b4\u00b5+ 1\nb\u20320\n) \u2212 (\n\u2212 1 3 \u221a\nb\u20320 2 +\n1 b\u20320\n))\n= 1 2 \u00b7 2\u03b4\u00b5 b\u20320 = \u03b4\u00b5 b\u20320\nThe second line in the derivation was obtained by expanding both second-order polygamma functions in Taylor series as b\u20320 \u2192 \u221e and taking two first terms of each function. We now combine the front term in Equation 9 with this derivation to obtain the expression on\nthe upper bound on achieving the number of elite species in the population \u03b4\u00b5:\nET\u0303\u00b5,k \u2264 2\u00b55\u03b4\n\u03bbb3b\u20320 =\n2\u03b4\u00b53\n\u03bb(2\u00b5\u03d53(k) + \u03d54(k))\nsince\nb3b \u2032 0 = 2(\u00b5\u03d53(k)\u2212 \u03d54(k)) \u00b7\n\u00b52(2\u00b5\u03d53(k) + \u03d54(k))\n2(\u00b5\u03d53(k)\u2212 \u03d54(k)) = \u00b52(2\u00b5\u03d53(k) + \u03d54(k))\nWe are now ready to find the upper bound on the expected optimization time of the algorithm:\nE\u03c4(\u00b5+\u03bb)EA1BS \u2264 n\u22123 \u2211\nk=3\nET\u0303\u00b5,k = 2\u03b4\u00b53\n\u03bb\nn\u22121 \u2211\nk=3\n1\n2\u00b5\u03d53(k) + \u03d54(k)\n(16) Here again we pessimistically assume that the best species at the start of the run has fitness 3, since in such case fitness of \u03b2\u22121 has minimal fitness of 1, otherwise we obtain inconsistencies s.a. 1\n0 . We have two\nprobabilities to consider for the two new types of pairs:\n< \u03b1, \u03b2\u22121 >: \u03d53(k) = k n \u00b7 k \u2212 2 n + n\u2212 k n \u00b7 n\u2212 k + 2 n\n= k(k \u2212 2) + (n\u2212 k)(n\u2212 k + 2)\nn2\nWe need to preserve the better parent in order to get it added to the population, so need to either select 1-bits in each parent or 0-bits in each parent. for the last swap probability, \u03d54(k), we need only to select a 0 in the \u03b21 parent and 1 in \u03b2\u22121 parent, other options either degrade the better parent or leave the current fitness.\n< \u03b21, \u03b2\u22121 >: \u03d54(k) = (n\u2212 k + 1)(k \u2212 2)\nn2\nWe continue with manipulating with the summand over k:\nS(n, k) = 1\n2\u00b5\u03d53(k) + \u03d54(k)\n= n2\n(4\u00b5\u2212 1)k2 + (n\u2212 8\u00b5\u2212 4\u00b5n+ 3)k + 4\u00b5n\u2212 2n+ 2\u00b5n2 \u2212 2\n\u2264 n 2 \u00b5 \u00b7 1 k2 \u2212 4(n+ 2)k + 2n(n+ 1)\nWe leave out the first fraction, and factor the denominator in the form (k \u2212 s)(k \u2212 r), s.t. s, r are solutions to the set of equations:\n{\ns+ r = 4(n+ 2) sr = 2n(n+ 1)\nThe resulting solution (we only use one of the roots, which are symmetric) is:\n{ s = 2n+ \u221a 2 \u221a n2 + 7n+ 8 + 4\nr = 2n\u2212 \u221a 2 \u221a n2 + 7n+ 8 + 4\nThe value under the root can be bounded by\nn+ 2 \u2264 \u221a n2 + 7n+ 8 \u2264 n+ 4\nSo the expression becomes upper-bounded by\n1\n(k \u2212 (2n+ \u221a 2(n+ 2)))(k \u2212 (2n\u2212 \u221a 2(n+ 4)))\nExpanding this in partial fractions, we obtain\n1\n2 \u221a 2(n+ 3)\n\u00b7 (\n1\nk \u2212 (2n+ \u221a 2(n+ 2))\n\u2212 1 k \u2212 (2n\u2212 \u221a 2(n+ 2))\n)\nWe obtain two sums over k:\nS1(n, k) = n\u22123 \u2211\nk=3\n1\nk \u2212 (2n+ \u221a 2(n+ 2))\n\u2248 \u03c80(n\u2212 2n\u2212 \u221a 2n)\u2212 \u03c80(3\u2212 2n\u2212 \u221a 2n) = \u03c80(\u2212(1\u2212 \u221a 2)n)\u2212 \u03c80(3\u2212 (2 + \u221a 2)n) = O(1) \u2212O(1) = \u2212O(1)\nThe result of \u2212O(1) is due to the fact that we can select any n, for which the values of digamma function are small negative constants (see Appendix D for details on Taylor series expansion of \u03c80(n) for n < 0). For the second sum, we notice the upper bound on the value in the denominator, since 2\u2212 \u221a 2 \u2248 0.58 < 1:\nS2(n, k) =\nn\u22123 \u2211\nk=3\n1\nk \u2212 (2n\u2212 \u221a 2(n+ 2))\n\u2264 n\u22123 \u2211\nk=3\n1 k \u2212 n = \u2212 n\u22123 \u2211\nk=3\n1\nn\u2212 k \u2248 \u2212 log(n\u2212 3) +O(1)\nthe minus sign in front of the expression cancels out and we obtain the upper bound for S(\u00b5, n):\nS(\u00b5, n) \u2264 n 2(log(n\u2212 3) \u2212O(1)\n\u00b5n\nand the upper bound on the expected first hitting time:\nE\u03c4(\u00b5+\u03bb)EA1BS \u2264 2\u03b4\u00b52n(log(n\u2212 3)\u2212O(1))\n\u03bb (17)\nwith \u03b4 = c \u00b5 the expression becomes (measured in the number of generations, for c > 0)\nE\u03c4(\u00b5+\u03bb)EA1BS = c\u00b5n log n\n\u03bb \u2212O\n(\n\u00b5n\n\u03bb\n)\n(18)\nor, in the number of function evaluations,\nE\u03c4(\u00b5+\u03bb)EA1BS = c\u00b5n log n\u2212O(\u00b5n) (19)"}, {"heading": "APPENDIX D MATHEMATICAL EXPRESSIONS", "text": "There is a number of important mathematical expression used throughout the article, we present some of them here:\nH(n) =\nn\u22121 \u2211\nk=0\n1 n\u2212 k = n\u22121 \u2211\nk=0\n1 k \u2248 \u222b n\u22121\n0\ndx\nn\u2212 x = log n < log n+ 1\nDigamma function:\n\u03c80(n) = log n+O\n(\n1\nn\n)\nFor \u03c80(n) with n \u2192 \u2212\u221e we use the largest term of Taylor series for asymptotic expansion:\n\u03c80(n) \u2248 \u03c0 cot(\u03c0n) +O ( 1\nn\n)\nThe values for cot(\u03c0n) for integer n, such as in this article, are infinity. Therefore for expressions for S1(n, k) and S2(n, k) we have selected some constants, e.g. \u2212(1 \u2212 \u221a 2), 2 \u2212 \u221a 2, s.t. the resulting values are constants. Since n is arbitrarily large, we can find such n that the difference between them is negative, hence we obtain term \u2212O(1)."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "In this article we present an Elitism Levels Traverse Mech-<lb>anism that we designed to find bounds on population-based Evolutionary<lb>Algorithms solving unimodal functions. We prove its efficiency theoreti-<lb>cally and test it on OneMax function deriving bounds c\u03bcn logn\u2212O(\u03bcn).<lb>This analysis can be generalized to any similar algorithm using variants<lb>of elitist selection and genetic operators that flip or swap only 1 bit in<lb>each string.<lb>", "creator": "LaTeX with hyperref package"}}}