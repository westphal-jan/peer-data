{"id": "1205.4776", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2012", "title": "Visual and semantic interpretability of projections of high dimensional data for classification tasks", "abstract": "a number of visual quality measures have tentatively been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. these methods generally concentrate on the factual interpretability of the visualization and pay little attention to the interpretability requirements of the projection axes. in this paper, we argue effectively that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration capable of high dimensional labeled data. we present a two - part user study to examine these two related but orthogonal aspects of interpretability. we first study how humans judge typically the quality of simultaneous 2d scatterplots of various datasets with varying number of classes and provide comparisons with ten unique automated measures, including a number of visual visual quality measures and related measures from various machine learning fields. we then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. broadly we conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.", "histories": [["v1", "Tue, 22 May 2012 00:10:45 GMT  (736kb,D)", "http://arxiv.org/abs/1205.4776v1", "Longer version of the VAST 2011 poster.this http URL"]], "COMMENTS": "Longer version of the VAST 2011 poster.this http URL", "reviews": [], "SUBJECTS": "cs.HC cs.LG", "authors": ["ilknur icke", "andrew rosenberg"], "accepted": false, "id": "1205.4776"}, "pdf": {"name": "1205.4776.pdf", "metadata": {"source": "CRF", "title": "Visual and semantic interpretability of projections of high dimensional data for classification tasks", "authors": ["Ilknur Icke", "Andrew Rosenberg"], "emails": ["iicke@gc.cuny.edu", "andrew@cs.qc.cuny.edu"], "sections": [{"heading": null, "text": "A number of visual quality measures have been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. These methods generally concentrate on the interpretability of the visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration of high dimensional labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first study how humans judge the quality of 2D scatterplots of various datasets with varying number of classes and provide comparisons with ten automated measures, including a number of visual quality measures and related measures from various machine learning fields. We then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. We conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.\nKeywords: dimensionality reduction, data visualization, interpretable projection pursuit, user study\nIndex Terms: H.2.8 [Database Management]: Database applications\u2014Data Mining"}, {"heading": "1 INTRODUCTION", "text": "The high dimensionality of data poses theoretical and practical challenges for visual exploration and analysis. According to the curse of dimensionality [6] theorem, the number of samples needed for a classification task increases exponentially as the number of dimensions (variables, features) increases. Moreover, irrelevant and redundant features might hinder classifier performance. On the other hand, it is costly to collect, store and process data. In exploratory analysis settings, high dimensionality prevents the users from exploring the data visually.\nFeature extraction is a two-step process that seeks suitable data representations that would help us overcome these challenges. Feature construction step creates a set of new features based on the original features and feature selection is the process of finding the best features amongst them. In this paper, we focus on feature extraction methods for visual exploration of labeled data for classification tasks. Various linear (such as principal components analysis (PCA), multiple discriminants analysis (MDA), exploratory projection pursuit) and non-linear (such as multidimensional scaling\n\u2217e-mail: iicke@gc.cuny.edu \u2020e-mail: andrew@cs.qc.cuny.edu\n(MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]). While each method optimizes a pre-designed intuitive measure of goodness of a visualization, limited number of empirical studies have been reported on how much these measures match human perception.\nIn this paper, we consider two related but orthogonal aspects of human interpretability of data projections for labeled data. Visual interpretability is concerned with how humans judge the quality of the views presented as 2D scatterplots. In the case of labeled data, visual interpretability closely relates to how easy it is to tell the members of each class apart by inspecting the scatterplot. Semantic interpretability is concerned with how these views are generated, namely the complexity of the projection functions that relate the projection axes to the original variables (features, attributes). We devised a two-part experiment to study visual and semantic interpretability. In the first part, we showed scatterplots from four datasets with varying number of classes and asked the participants to rate these views. The participants were not given any background information about the dataset and the attributes since we aimed to investigate how they would rate the views independent from a specific domain. The second part of our experiment aimed to investigate how easily humans would understand mathematical expressions with varying levels of complexity. We generated a generic set of expressions in order to study interpretability independently from a specific domain.\nThis paper is organized as follows: section 2 gives an overview of related work on characterization of the interpretability of views (2D scatterplots) of labeled data. Also included in this section is an overview of related research that addresses the interpretability of the projection (transformation) functions that generate the views. Section 3 presents the details of our user study on how humans interpret the views of datasets containing different number of groups and how the human perception relates to the automated measures proposed in related literature. Section 4 presents our user study on how easily humans can interpret mathematical expressions consisting of variables, coefficients and various operators and the relationship between the human perception and automated measures of expression complexity. We conclude with a discussion (section 5) of application of our results in development of visually and semantically interpretable projections of high dimensional datasets."}, {"heading": "2 RELATED WORK", "text": "The task of selecting interesting [10] or good views of datasets becomes more challenging as the dimensionality increases. For sufficiently high dimensional datasets, manual exploration of the space of views is impractical. In the case of labeled data, the degree of interestingness is related to how easy it is to tell the classes apart from each other by inspecting the visualization.\nLee at al. present a measure for exploratory projection pursuit of labeled data that is based on Fisher\u2019s Linear Discriminant Analysis method in [18]. The VizRank algorithm proposed by Leban et al. searches for informational 2D projections of datasets that\nar X\niv :1\n20 5.\n47 76\nv1 [\ncs .H\nC ]\n2 2\nM ay\n2 01\n2\nare evaluated by a k-Nearest Neighbor classifier [17]. The authors claim almost perfect agreement between the human judgement and the VizRank algorithm through a user study conducted using six datasets. Sips et al. propose two measures based on the notion of class consistency in [22]. One measure is based on preservation of closeness to class centroids after projection, and another is based on the entropies of the spatial distributions of the classes. The authors report a user study on a number of datasets with varying number of classes. They claim that their proposed measures are in alignment with human judgement in terms of finding all views that were labeled as good views by the participants. Tatu et al. propose two measures to evaluate the degree of separation on scatterplots of labeled data in [23]. Tatu et al. report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23]. The authors suggest that a combination of measures might be worth investigating.\nAs opposed to the various studies on visual interpretability or quality of the projections of labeled data, the interpretability of the projection axes have been addressed only in a few studies. In the case of projection pursuit, the projection functions are given as weighted linear combinations of the original features. Morton defines the interpretability of these projection functions in terms of parsimony (simplicity) and proposes rotation and entropy based methods to simplify the coefficients of the linear projections while preserving the interesting view [19]. El-Arini et al. present a dimensionality reduction method that searches over scatterplots generated by simple arithmetic expressions of the original features and assessed by accuracy of a Bayesian classifier [15]. The authors claim that expressions containing more than one or two features become less interpretable. However, no empirical study has been reported to justify this intuition.\nThere have been a number of related studies in the Human Computer Interaction (HCI) field investigating how humans perceive the complexity of mathematical expressions in order to develop improved human-computer interfaces. Anthony et al. study the effects of different input methods (keyboard, handwriting, speech) with respect to the complexity of the mathematical expressions for the purpose of developing intelligent tutoring systems [4] for algebra. The study presented by Awde et al. in [5] aims to find the most appropriate way to present a mathematical expression to visually impaired users. The modality of the presentation is selected based on a notion of human perceived complexity of mathematical expressions inferred through a user study. Their experimental design is similar to ours, where the participants are shown a number of mathematical expressions and asked to re-write and rate the expressions. Then, a relationship between the structural properties of the expressions and the human perceived complexity is derived. The set of expressions they chose came from a wide range of fields including logic and calculus. In our experiments, the set of expressions were limited to various linear/non-linear combinations of a limited number of variables representing possible data projection functions of varying complexity."}, {"heading": "3 VISUAL INTERPRETABILITY USER STUDY", "text": "We developed computer software that automatically administered the data visualization experiment without investigator intervention. In this section, we present the details on design and execution of the study along with our findings on how well the automated measures match the human perception of visual interpretability."}, {"heading": "3.1 Participants", "text": "We recruited 20 participants (13 males and 7 females) who had completed or were pursuing graduate degrees in scientific fields such as computer science, physics, biology, engineering, accounting and psychology.\nAt the beginning of the study, the participants were asked to fill out a brief questionnaire asking them about their related coursework or experience. 14 of the participants specified that they had taken a Statistics, Data Mining or a Machine Learning course."}, {"heading": "3.2 Datasets and Visual Interpretability Measures", "text": "We chose four commonly used datasets from the data mining and visual analytics literature (table 1). These datasets were selected because they contain different number of classes ranging from 2 to 9, which would let us investigate how the number and shape of the classes affect the relationship between human perception and the automated measures.\nThe Wisconsin Diagnostic Breast Cancer (WDBC) dataset contains 30 measurements characterizing malignant or benign tumors. The Wine dataset contains 13 attributes related to the chemical properties of wines from three different regions of Italy. The Segments dataset contains 19 features derived from images of seven kinds of scenes (brickface, sky, foliage, cement, window, path, grass). All three datasets were downloaded from the UCI Machine Learning Repository [2]. The Italian olive oils dataset [27] contains the amounts of eight fatty acids in olive oils that are from nine different regions of the country (downloaded from [1]).\nIn order to compare human judgement on quality of 2D views of labeled data to automated measures we chose ten measures from various fields of machine learning and visual analytics. Wrapper based methods from the feature extraction field have been designed to assess the usefulness of the extracted features with respect to the performance of classification algorithms. In this paper, we utilized four commonly used classification algorithms to assess the quality of the scatterplots for the four datasets mentioned above (section 3.3). A number of cluster validity indices have been proposed in data clustering literature in order to assess the quality of groupings generated by different clustering algorithms. These indices can also be used to measure the quality of the groupings on 2D scatterplots with respect to the class labels of the observations. For our experiments, we included three cluster validity indices (section 3.4). A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]). We included two of the proposed measures that were reported in [24] as the closest matches to the human perception through user studies (section 3.5). Table 2 presents the list of the automated measures we utilized in our experiments.\nFor a dataset with N attributes, there are N(N\u22121)/2 unique attribute pairs, where each pair can be visualized as a scatterplot. In order to choose the visualizations for our experiment, we first\ngenerated all possible 2D scatterplots for each dataset. We computed the values of the automated measures given in table 2 for the datasets. Our aim was to ensure that we chose a diverse set of visualizations with respect to the automated measures. We created five equi-width bins of values between [0-1]. Then, for each bin, we selected two scatterplots that appeared most frequently within that value range across all the automated measures. Upon completion of this process, a total of 40 scatterplots (10 for each dataset) were selected to be included in our experiments."}, {"heading": "3.3 Wrapper Methods", "text": "Given a labeled multi-dimensional dataset, the goal of a supervised learning algorithm is to build a model from the observed data in order to predict the class membership of an unseen data item correctly. Classification algorithms can be broadly considered in two categories: generative and discriminative [21]. The generative methods aim to infer probabilistic models that generate the data points for each class. The discriminative methods aim to learn a mapping between the features and the class labels directly. Regardless of the method used, the common goal of a classification algorithm is to be able to differentiate class members as accurately as possible.\nSelection of appropriate features improve the performance of classifiers. Therefore, classification performance is used to evaluate the usefulness of feature sets in wrapper based feature selection schemes [16]. Wrapper based feature selection methods can be used to assess the quality of 2D scatterplots of labeled data. Since the goal of a classifier is to tell the classes apart, high accuracy on two selected features would mean a good view of the data.\nFor our experiments, we chose four of the most common (according to [26]) classification algorithms which we briefly discuss here. Each algorithm displays a different decision boundary characteristic that is related to how the algorithm works.\nFigure 2 shows the decision boundaries generated by each algorithm on a view from the Wine dataset. The Support Vector Machine and Decision Tree algorithms generate linear decision boundaries while Naive Bayes and the K-Nearest Neighbors generate non-linear boundaries. Our goal is to investigate how each algorithm\u2019s decision boundary characteristics would relate to human perception of class separation on different datasets with varying number of classes."}, {"heading": "3.3.1 k-Nearest Neighbors (k-NN) Algorithm", "text": "In k-Nearest Neighbors algorithm, the class label of a data point is predicted based on a voting mechanism weighted by the distances to its k closest neighbors. The distance measure is generally the Euclidean metric. The k-Nearest Neighbors algorithm has also been utilized in Vizrank [27] in order to assess the quality of scatterplots. In our experiments, we chose k as \u221a N as in Vizrank, where N is the number of data points."}, {"heading": "3.3.2 Decision Tree (J48) Algorithm", "text": "A decision tree classifier creates hierarchical partitions of the data based on one attribute at a time. The algorithm builds a tree structure where each internal node represents a condition that splits the dataset into multiple partitions with respect to a measure of partition impurity such as the entropy. Because of this partitioning, the decision boundaries are orthogonal to the attribute axes (figure 2). In our experiments, we used the Weka implementation of the decision tree algorithm that is known as J48 [3]."}, {"heading": "3.3.3 Naive Bayes Algorithm", "text": "The Naive Bayes algorithm is a generative classification method that estimates the joint class density separately for each class. The assumption that all attributes are conditionally independent from each other simplifies the algorithm greatly. Despite this simplicity, the Naive Bayes algorithm has been known to outperform more complex classification algorithms on a variety of problems [13]."}, {"heading": "3.3.4 Support Vector Machine (SMO) Algorithm", "text": "In its simplest form, the Support Vector Machine is a machine learning technique that searches for a hyperplane separating the classes by the maximal margin for a two-class problem. In our experiments, we utilized the multi-class Weka implementation based on the Sequential Minimal Optimization (SMO) technique [3]."}, {"heading": "3.4 Cluster Validity Indices", "text": "Data clustering is a well-known machine learning problem of categorizing multi-dimensional data into natural groupings such that items that are in the same group are more similar to each other than items from other groups. A number of methods have been proposed in order to quantify the quality of the outcome of clustering algorithms. In the case of 2D data, cluster validity indices can be used as measures of interpretability of the visualizations. In this section, we discuss three measures that were used in our experiments. The unifying theme of these cluster validity indices is that they all aim to measure compactness and well-separation of the class structures using a distance measure and they are susceptible to outliers. Detailed overview of validity indices can be found in [12, 20].\n3.4.1 C Index (IC) The C Index is a cluster validation index defined in [14]:\nIC = SD\u2212SDmin\nSDmax\u2212SDmin where SD is the total sum, for all classes, of pairwise distances between samples of the same class (total p distances), SDmin and SDmax are the sums of p smallest/largest pairwise distances across the whole dataset. The C index returns values between 0 and 1. Smaller values of IC indicate more compact and better separated class structures.\n3.4.2 Davies-Bouldin Index (IDB) The Davies-Bouldin Index is a measure of compactness and well separation of clusters and it was proposed in [8]:\nIDB = 1 n\nn\n\u2211 i=1\nmini 6= j{ \u03b4 (Xi,X j)\n\u2206(Xi)+\u2206(X j) }\nwhere \u2206(Xi) is intra-class distance for class i and \u03b4 (Xi,X j) is interclass distance for classes i and j. Smaller values of IDB indicate more compact and better separated cluster structures. In our experiments, we normalized the IDB values to [0,1] range.\n3.4.3 Dunn\u2019s Index (IDunn)\nThe Dunn\u2019s index is a measure of compactness and well separation of clusters and it was proposed in [9]:\nIDunn = min1\u2264i\u2264n{min1\u2264 j\u2264n, j 6=i{ \u03b4 (Xi,X j)\nmax1\u2264k\u2264n{\u2206(Xk)} }}\nwhere \u03b4 ,\u2206 are defined as above. Smaller values of IDunn indicate more compact and better separated class structures. In our experiments, we normalized the IDunn to [0-1] range."}, {"heading": "3.5 Visual Quality Measures", "text": "In this section, we discuss three methods that were introduced in visual analytics literature. The Class Consistency Measure and the 2D Histogram Density Measure have been reported to be the closest matches to human perception amongst the four proposed visual quality measures through a user study [24]. Therefore, we included these measures in our experiments.\n3.5.1 LDA Index (ILDA)\nThe LDA index is based on Fisher\u2019s discriminant analysis and has been introduced in [18] for exploratory projection pursuit for classification problems:\nILDA = |W | |W +B|\nB = k\n\u2211 i=1 ni(V\u0304i.\u2212V\u0304..)(V\u0304i.\u2212V\u0304..)\u2032\nW = k\n\u2211 i=1\nni\n\u2211 j=1 (Vi j\u2212V\u0304i.)(Vi j\u2212V\u0304i.)\u2032\nwhere Vi j are data points, V\u0304i and V\u0304.. are group and dataset centroids, k is the number of groups (classes), ni is the number of points in group i, B is the between-group sum of squares and W is the within-group sum of squares. Smaller values of ILDA indicate more compact and better separated class structures."}, {"heading": "3.5.2 Class Consistency Measure (CCM)", "text": "The Class Consistency Measure (CCM) has been proposed in [22] and is based on the preservation of closeness to class centroid after a projection from the original data space into a 2D view. A data point is said to be inconsistent, if the projection places it closer to a class centroid other than its own. CCM scores each view with respect to how many consistent points it contains:\nCCM = 1\u2212 \u2211 k c=1 CC(xc)\nM\nCC = { 1, if d(xc, x\u0304c)< d(xc, x\u0304i),1\u2264 i\u2264 k, i 6= c 0, otherwise\nwhere M is the total number of data points, k is the number of classes, xc is a point in class c and x\u0304c, x\u0304i are projections of the centroid of classes c and i respectively. The CCM returns values between 0 and 1 where smaller values indicate more consistent views."}, {"heading": "3.5.3 2D Histogram Density Measure (2D-HDM)", "text": "The Histogram Density Measure (HDM) which has been proposed in [23] is a measure of class separation based on 2D histograms computed on 2D scatterplots of data. A weighted sum of entropy of each bin and its immediate neighbors (uc) is computed as follows:\n2D\u2212HDM = 1 Z \u2211x,y \u2211c uc(\u2212\u2211 c uc \u2211c uc log2 uc \u2211c uc )\n1 Z = 1 log2M \u2211x,y \u2211c uc\nwhere 1Z is a normalization factor in order to confine the values within the [0-1] range and smaller values indicate better data separation. The choice of bin size influences how this measure scores the views. In our experiments, we used 100x100 bins for each dataset."}, {"heading": "3.6 Task", "text": "Before starting the study, the participants were told that they would be shown a series of scatterplots of some datasets containing multiple groups and their task was to rate how good the view was by inspecting the visualizations. We did not provide any directions on how to define the \u201cgoodness\u201d of a view. Each scatterplot showed only the data points in different colors with respect to their class labels and no further information about the data (such as the name of the dataset or the names of the attributes) was provided. After reading the instructions, the participants were shown one scatterplot at a time and were asked to rate them on a continuous scale between 0 (very good) to 1 (very bad) with labels shown on table 3."}, {"heading": "3.7 Methodology", "text": "Each user rated a total of 45 scatterplots. Undisclosed to the participants, the first five scatterplots were artificial views showing different levels of compactness and separation between the classes from very good to very bad with respect to the automated measures. These visualizations were used as calibration views in order to help the participant get used to the interface and build their mental models for how they would rate the quality of a view. The user ratings for these calibration views were not included in the analysis of the responses. The remaining 40 pre-selected scatterplots were displayed in a randomized order to each user. In order to reduce the effect of outliers, we computed the median of user responses for each of the scatterplots and used this value in our comparisons to the automated measures."}, {"heading": "3.8 Results", "text": "Figure 3 shows the relationships between the human perception and each of the automated measures. Each plot presents the values of the corresponding automated measure versus the median value of the participant ratings for each scatterplot. A strong positive linear correlation means good alignment between the human and the automated measure.\nTable 4 summarizes the relationships between each measure and human perception for all scatterplots. Tables 5- 8 present the results\nfor each individual dataset. The measures are sorted in descending order with respect to the R2.\nThe R2 values indicate how well the linear regression model fits the data in terms of predicting the participant ratings based on each automated measure. Results on all scatterplots without consideration of a specific dataset (table 4) show that the C Index and the LDA Index did not correlate with how the participants typically judged the \u201cgoodness\u201d of a view. Two classification algorithms, Support Vector Machine and Naive Bayes ranked the top two, tightly followed by the Class Consistency Measure, Dunn Index and K-Nearest Neighbors.\nWhen we look at the results on individual datasets (tables 5- 8), we notice that the Support Vector Machine is no longer one of the top performers for datasets with larger number of classes (Segments and Olive oil). The Dunn Index shows a significant match for all datasets accept for the Olive oils dataset which might be due to the fact that, the class structures contain outliers and in some cases, the members of the same class are clumped together in multiple areas on the scatterplot. Overall, we found that Davies-Bouldin Index, Dunn Index, C Index and LDA Index might not correlate with human perception, depending on the dataset while all others seem to correlate to some extent.\nFrom these results, we infer that the degree of match between the human and the automated measure might depend on the characteristics of the views such as the shape of the clusters formed by the class members. Therefore, we hypothesize that a combination of these measures might model the human perception better than any single measure. In the next section, we derive a composite measure based on the individual measures and investigate its performance across all individual datasets included in our experiments."}, {"heading": "3.9 Combining the Automated Visual Interpretability Measures", "text": "Given the ten automated measures and the median of human responses for all datasets, we cast a prediction problem that would learn a linear model for the human responses in terms of the automated measures. We trained a linear regression model with leaveone-out cross-validation. The following linear combination of six of the ten measures was found (figure 4):\nPredictedHumanResponse(PHR) =\u22120.7772\u2217 J48+ 0.8155\u2217SMO+ \u22120.4305\u2217 IC+ \u22120.4588\u2217 IDB+ 0.6586\u2217CCM+ 0.3285\u2217HDM\u22122D+ 0.3606\nAs it can be seen on table 9, on the set of all scatterplots, the combined measure matches the human perception significantly better than any single measure reported on table 4. The composite measure is the clear winner for the WDBC and the Segment datasets. However, for Wine and Olive oil datasets, it was not the top measure in terms of matching human perception. Overall, the correlation between the composite measure and human perception was significant across all scatterplots as well as individual datasets.\nOne interesting observation is that, although the two classification algorithms that are related to density estimation (Naive Bayes and k-Nearest Neighbours) were always in alignment with human perception on all datasets, they were excluded from the composite model in favor of the discriminative classifiers."}, {"heading": "4 SEMANTIC INTERPRETABILITY USER STUDY", "text": "The goal of the semantic interpretability study is to understand how easily the users interpret/understand mathematical expressions of variables, coefficients and operators that would make up a linear or\nnon-linear projection (transformation) function characterizing the relationship between a set of variables and result of the projection.\nWe developed a software application that automatically administered the experiment and recorded participant responses without investigator intervention. The participants used a consumer grade tablet pen interface connected to the computer via a USB connection."}, {"heading": "4.1 Participants", "text": "The same 20 participants (section 3.1) that were involved in the visualization study also took part in this experiment. Before starting the study, all participants were given time to train on using the tablet pen interface."}, {"heading": "4.2 The expressions", "text": "We created 30 mathematical expressions consisting of five possible variables t,u,x,y,z, numerical coefficients, mathematical operators +,\u2212,\u2217,/, logarithm, square-root, exponential and power. Undisclosed to the participants, the first five expressions were used as calibration expressions (table 10). The purpose of these initial expressions was to establish a range of complexity of the expressions that would be shown further on. The participant responses to these expressions were not included in analysis of the results. In our experiments, the size of the shortest expression was 2 and the longest expression was 19."}, {"heading": "4.3 Task", "text": "The participants were informed that they would be shown a series of mathematical expressions of five possible variables t,u,x,y,z, numerical coefficients, mathematical operators +,\u2212,\u2217,/, logarithm, square-root, exponential and power. They were told that each expression would be displayed for 10 seconds and that their task was to study the expression within that time and write it back using the tablet pen after the expression was removed from the screen. They were also asked to rate how easy it was to understand/interpret the given expression. The rating was on a continuous scale from 0 (very easy) to 1 (very difficult) with labels shown on table 12."}, {"heading": "4.4 Methodology", "text": "After the first five calibration expressions, the remaining 25 expressions (table 11) were then shown in a randomized order to each participant. The expressions were presented to the participants in a linearized form. Specifically, we chose not to display the division operation as a fraction in order not to create a visual cue that would make it easier to interpret the expression as opposed to addition, subtraction or multiplication.\nFor each participant, we recorded the time they spent writing each expression and their rating on how easy it was to understand the expression. The images of the expressions they wrote down were automatically captured and saved to disk for manual inspection for correctness (figure 5). For this study, we only considered correct/incorrect response rather than assessing partial correctness."}, {"heading": "4.5 Results", "text": "The outcome of the study is summarized on table 11. For each expression, we report the median value of the participant ratings, median value of the total time it took for the participants to write down and rate the expression and the number of correct responses. We first examined the relationship between how an expression is rated by the participants and how frequently it was written down correctly. We hypothesized that the expressions that were frequently replicated incorrectly would also be rated as difficult to interpret by the participants. Indeed, we found that there was a strong correlation between them (Pearson\u2019s R=0.9379, Df=23, p < 0.05) indicating that the ratings given by the participants were consistent with\ntheir observed behavior (answering correctly/incorrectly). We did not find a meaningful relationship between the time taken to write the expression and the subjective rating. Most possibly, it is due to the fact that the participants did not spend much time on those expressions that they found hard to interpret. Therefore, we will present only the results based on the participant ratings here.\nIn order to define a relationship between the structure of the expression and the participant ratings, we determined various attributes of the expressions characterizing the complexity. For this purpose, we utilized a syntax-tree representation for the expressions (figure 6). The number of operands include the variables and other numerical values. A block is a sub-expression composed of multiple operators and operands. The tree depth relates to the nestedness in the expression and the number and size of the blocks indicate the distinguishable components it contains. Table 11 shows the values of the six derived attributes for each expression.\nTable 11 reveals that up to expression size 7 (up to 4 operands or 4 operators), the participants rated the expressions to be very easy-easy (rating \u2264 0.3).\nWe first looked at how much each of these attributes can predict the participant\u2019s ratings on interpretability (table 13). Unsurprisingly, the number of operators and total size affect how the expressions are rated. But this does not explain why the expressions of the same size were rated differently by the participants.\nWe cast a regression problem that learns a mapping between the structural properties of an expression and the degree of human interpretability as reported by our participants. We trained a linear model with leave-one-out cross-validation.\nPredictedHumanRating(PHR) = 0.0854\u2217Tree Depth+ \u22120.2568\u2217Number of Blocks+ \u22120.1014\u2217Avg. Block Size+ 0.0899\u2217Total Size+ 0.2151\nThis linear model is highly predictive of the human ratings with respect to tree depth, number and average size of the blocks, and the total size (Pearson\u2019s R=0.9598, Df=23, p < 0.05). Based on\nthis model, we infer that humans rate longer and nested expressions as more difficult to interpret while the existence of small number of compact blocks increase the interpretability."}, {"heading": "5 DISCUSSION", "text": "In this paper, we investigated the relationships between human perception and automated measures that aim to quantify interpretability. For visual exploration of high dimensional labeled datasets, we considered two forms of interpretability. Visual interpretability is concerned with how easy it is to tell the members of different classes apart by looking at 2D scatterplots of data. We argued that classifier performance and various clustering validity measures from the machine learning literature can also be used to assess the quality of the views besides the recently proposed visual quality measures. We presented a user study on four datasets with varying number of classes comparing ten automated measures to human perception. Our results indicated that no single measure outperforms others on all datasets. While the Dunn Index, C Index and LDA Index might not correlate with human perception well depending on the dataset, all other measures seem to correlate with human perception to some extent. However, a linear combination of a subset of the automated measures correlated significantly with human perception across all scatterplots as well as individual datasets.\nSemantic interpretability is concerned with how easy it is for humans to understand the data transformation functions that project the original features into lower dimensions. We investigated how humans would rate expressions of varying level of complexity. We found that up to expression size 7 (up to 4 operands or 4 operators), the participants rated the expressions to be very easy-easy (rating \u2264 0.3). Based on a linear combination of various structural properties of an expression, we inferred that humans rated longer and nested expressions as more difficult to interpret while the existence of small number of compact blocks increase the interpretability.\nIn exploratory analysis of labeled data, simple feature-feature combinations might not always be the best views that reveal the class structures. Linear or non-linear feature transformation functions might create better 2D views. However, the space of possible transformation functions is vast. Therefore, automated complexity measures reflecting the human perception closely will be useful in finding interpretable data transformations.\nThe automated measures for visual and semantic interpretability of data transformations can be combined in a number of ways in order to search for good views of data that are also easily understandable in terms of the original attributes. A weighted linear combination of visual and semantic interpretability measures can be utilized or they can be optimized simultaneously using a multiobjective optimization scheme.\nIn conclusion, we state that through investigation of automated measures of visual and semantic interpretability, we can improve exploratory analysis by simultaneously presenting data representations to a user that are both easy to visualize and whose axes represent dimensions that are transparently understood."}], "references": [{"title": "Evaluation of multimodal input for entering mathematical equations on the computer", "author": ["L. Anthony", "J. Yang", "K.R. Koedinger"], "venue": "CHI \u201905 extended abstracts on Human factors in computing systems, CHI EA \u201905, pages 1184\u20131187, New York, NY, USA", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Complexity of mathematical expressions in adaptive multimodal multimedia system ensuring access to mathematics for visually impaired users", "author": ["A. Awde", "Y. Bellik", "C. Tadj"], "venue": "International Journal of Computer and Information Science and Engineering, 2:103\u2013115", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Adaptive Control Processes", "author": ["R. Bellman"], "venue": "Princeton Univ. Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1961}, {"title": "Geometric methods for feature extraction and dimensional reduction", "author": ["C.J.C. Burges"], "venue": "pages 59\u201392", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "A cluster separation measure", "author": ["D.L. Davies", "D.W. Bouldin"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1979}, {"title": "Well separated clusters and optimal fuzzy-partitions", "author": ["J.C. Dunn"], "venue": "Journal of Cybernetics, 4:95\u2013104", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1974}, {"title": "A projection pursuit algorithm for exploratory data analysis", "author": ["J.H. Friedman", "J.W. Tukey"], "venue": "Computers, IEEE Transactions on, C- 23(9):881\u2013890", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1974}, {"title": "editors", "author": ["I. Guyon", "S. Gunn", "M. Nikravesh", "L. Zadeh"], "venue": "Feature Extraction, Foundations and Applications. Series Studies in Fuzziness and Soft Computing, Physica-Verlag, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Cluster validity methods: part", "author": ["M. Halkidi", "Y. Batistakis", "M. Vazirgiannis"], "venue": "i. SIGMOD Rec.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Idiot\u2019s Bayes\u2014Not so stupid after all? International Statistical Review", "author": ["D.J. Hand", "K. Yu"], "venue": "69(3):385\u2013398", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Quadratic assignment as a general dataanalysis strategy", "author": ["L. Hubert", "J. Schultz"], "venue": "British Journal of Mathematical and Statistical Psychologie, 29:190\u2013241", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1976}, {"title": "Andrew W", "author": ["T.L. Khalid El-Arini"], "venue": "Moore. Autonomous visualization. In European Conference on Principles and Practice of Knowledge Discovery in Databases ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Wrappers for feature subset selection", "author": ["R. Kohavi", "G.H. John"], "venue": "Artif. Intell., 97(1-2):273\u2013324", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Vizrank: Data visualization guided by machine learning", "author": ["G. Leban", "B. Zupan", "G. Vidmar", "I. Bratko"], "venue": "Data Mining and Knowledge Discovery, 13:119\u2013136", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "Projection pursuit for exploratory supervised classification", "author": ["E.-K. Lee", "D. Cook", "S. Klinke", "T. Lumley"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Interpretable Projection Pursuit", "author": ["S.C. Morton"], "venue": "PhD thesis, Stanford University", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1989}, {"title": "A comparison of internal and external cluster validation indexes", "author": ["E. Rend\u00f3n", "I.M. Abundez", "C. Gutierrez", "S.D. Zagal", "A. Arizmendi", "E.M. Quiroz", "H.E. Arzate"], "venue": "Proceedings of the 2011 American conference on applied mathematics and the 5th WSEAS international conference on Computer engineering and applications, AMERICAN-MATH\u201911/CEA\u201911, pages 158\u2013163, Stevens Point, Wisconsin, USA", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Discriminative vs informative learning", "author": ["Y.D. Rubinstein", "T. Hastie"], "venue": "KDD, pages 49\u201353", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1997}, {"title": "Selecting good views of high-dimensional data using class consistency", "author": ["M. Sips", "B. Neubert", "J.P. Lewis", "P. Hanrahan"], "venue": "Computer Graphics Forum, 28(3):831\u2013838", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Combining automated analysis and visualization techniques for effective exploration of high-dimensional data", "author": ["A. Tatu", "G. Albuquerque", "M. Eisemann", "J. Schneidewind", "H. Theisel", "M. Magnor", "D. Keim"], "venue": "In Proceedings of the IEEE Symposium on Visual Analytics Science and Technology (IEEE VAST),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Visual quality metrics and human perception: an initial study on 2d projections of large multidimensional data", "author": ["A. Tatu", "P. Bak", "E. Bertini", "D. Keim", "J. Schneidewind"], "venue": "Proceedings of the International Conference on Advanced Visual Interfaces, AVI \u201910, pages 49\u201356, New York, NY, USA", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}, {"title": "Dimensionality reduction: A comparative review", "author": ["L. van der Maaten", "E. Postma", "H. van den Herik"], "venue": "Technical report,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Top 10 algorithms in data mining", "author": ["X. Wu", "V. Kumar", "J. Ross Quinlan", "J. Ghosh", "Q. Yang", "H. Motoda", "G.J. McLachlan", "A. Ng", "B. Liu", "P.S. Yu", "Z.-H. Zhou", "M. Steinbach", "D.J. Hand", "D. Steinberg"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Classification of multicomponent analytical data of olive oils using different neural networks", "author": ["J. Zupan", "M. Novic", "X. Li", "J. Gasteiger"], "venue": "Analytica Chimica Acta, 292(3):219 \u2013 234", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1994}], "referenceMentions": [{"referenceID": 2, "context": "According to the curse of dimensionality [6] theorem, the number of samples needed for a classification task increases exponentially as the number of dimensions (variables, features) increases.", "startOffset": 41, "endOffset": 44}, {"referenceID": 3, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 21, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 7, "context": "edu (MDS), manifold learning, kernel PCA, evolutionary constructive induction) techniques have been proposed for dimensionality reduction and visualization ( [7, 25, 11]).", "startOffset": 158, "endOffset": 169}, {"referenceID": 6, "context": "The task of selecting interesting [10] or good views of datasets becomes more challenging as the dimensionality increases.", "startOffset": 34, "endOffset": 38}, {"referenceID": 14, "context": "present a measure for exploratory projection pursuit of labeled data that is based on Fisher\u2019s Linear Discriminant Analysis method in [18].", "startOffset": 134, "endOffset": 138}, {"referenceID": 13, "context": "are evaluated by a k-Nearest Neighbor classifier [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 18, "context": "propose two measures based on the notion of class consistency in [22].", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "propose two measures to evaluate the degree of separation on scatterplots of labeled data in [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 20, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 23, "endOffset": 27}, {"referenceID": 18, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "report a user study in [24] that compares four visual quality measures that have been proposed in [22] and [23].", "startOffset": 107, "endOffset": 111}, {"referenceID": 15, "context": "Morton defines the interpretability of these projection functions in terms of parsimony (simplicity) and proposes rotation and entropy based methods to simplify the coefficients of the linear projections while preserving the interesting view [19].", "startOffset": 242, "endOffset": 246}, {"referenceID": 11, "context": "present a dimensionality reduction method that searches over scatterplots generated by simple arithmetic expressions of the original features and assessed by accuracy of a Bayesian classifier [15].", "startOffset": 192, "endOffset": 196}, {"referenceID": 0, "context": "study the effects of different input methods (keyboard, handwriting, speech) with respect to the complexity of the mathematical expressions for the purpose of developing intelligent tutoring systems [4] for algebra.", "startOffset": 199, "endOffset": 202}, {"referenceID": 1, "context": "in [5] aims to find the most appropriate way to present a mathematical expression to visually impaired users.", "startOffset": 3, "endOffset": 6}, {"referenceID": 23, "context": "The Italian olive oils dataset [27] contains the amounts of eight fatty acids in olive oils that are from nine different regions of the country (downloaded from [1]).", "startOffset": 31, "endOffset": 35}, {"referenceID": 14, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 19, "context": "A number of visual quality measures have been introduced in visual analytics literature ( [18, 22, 23]).", "startOffset": 90, "endOffset": 102}, {"referenceID": 20, "context": "We included two of the proposed measures that were reported in [24] as the closest matches to the human perception through user studies (section 3.", "startOffset": 63, "endOffset": 67}, {"referenceID": 10, "context": "4 C Index (IC) [14] 3.", "startOffset": 15, "endOffset": 19}, {"referenceID": 4, "context": "1 Davies-Bouldin Index (IDB) [8] 3.", "startOffset": 29, "endOffset": 32}, {"referenceID": 5, "context": "2 Dunn Index (IDunn) [9] 3.", "startOffset": 21, "endOffset": 24}, {"referenceID": 14, "context": "3 LDA Index (ILDA) [18] 3.", "startOffset": 19, "endOffset": 23}, {"referenceID": 18, "context": "1 Class Consistency Measure (CCM) [22] 3.", "startOffset": 34, "endOffset": 38}, {"referenceID": 19, "context": "2 2D Histogram Density Measure (2D-HDM) [23] 3.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "Classification algorithms can be broadly considered in two categories: generative and discriminative [21].", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "Therefore, classification performance is used to evaluate the usefulness of feature sets in wrapper based feature selection schemes [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "For our experiments, we chose four of the most common (according to [26]) classification algorithms which we briefly discuss here.", "startOffset": 68, "endOffset": 72}, {"referenceID": 23, "context": "The k-Nearest Neighbors algorithm has also been utilized in Vizrank [27] in order to assess the quality of scatterplots.", "startOffset": 68, "endOffset": 72}, {"referenceID": 9, "context": "Despite this simplicity, the Naive Bayes algorithm has been known to outperform more complex classification algorithms on a variety of problems [13].", "startOffset": 144, "endOffset": 148}, {"referenceID": 8, "context": "Detailed overview of validity indices can be found in [12, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 16, "context": "Detailed overview of validity indices can be found in [12, 20].", "startOffset": 54, "endOffset": 62}, {"referenceID": 10, "context": "The C Index is a cluster validation index defined in [14]:", "startOffset": 53, "endOffset": 57}, {"referenceID": 4, "context": "The Davies-Bouldin Index is a measure of compactness and well separation of clusters and it was proposed in [8]:", "startOffset": 108, "endOffset": 111}, {"referenceID": 5, "context": "The Dunn\u2019s index is a measure of compactness and well separation of clusters and it was proposed in [9]:", "startOffset": 100, "endOffset": 103}, {"referenceID": 20, "context": "The Class Consistency Measure and the 2D Histogram Density Measure have been reported to be the closest matches to human perception amongst the four proposed visual quality measures through a user study [24].", "startOffset": 203, "endOffset": 207}, {"referenceID": 14, "context": "The LDA index is based on Fisher\u2019s discriminant analysis and has been introduced in [18] for exploratory projection pursuit for classification problems:", "startOffset": 84, "endOffset": 88}, {"referenceID": 18, "context": "The Class Consistency Measure (CCM) has been proposed in [22] and is based on the preservation of closeness to class centroid after a projection from the original data space into a 2D view.", "startOffset": 57, "endOffset": 61}, {"referenceID": 19, "context": "The Histogram Density Measure (HDM) which has been proposed in [23] is a measure of class separation based on 2D histograms computed on 2D scatterplots of data.", "startOffset": 63, "endOffset": 67}], "year": 2012, "abstractText": "A number of visual quality measures have been introduced in visual analytics literature in order to automatically select the best views of high dimensional data from a large number of candidate data projections. These methods generally concentrate on the interpretability of the visualization and pay little attention to the interpretability of the projection axes. In this paper, we argue that interpretability of the visualizations and the feature transformation functions are both crucial for visual exploration of high dimensional labeled data. We present a two-part user study to examine these two related but orthogonal aspects of interpretability. We first study how humans judge the quality of 2D scatterplots of various datasets with varying number of classes and provide comparisons with ten automated measures, including a number of visual quality measures and related measures from various machine learning fields. We then investigate how the user perception on interpretability of mathematical expressions relate to various automated measures of complexity that can be used to characterize data projection functions. We conclude with a discussion of how automated measures of visual and semantic interpretability of data projections can be used together for exploratory analysis in classification tasks.", "creator": "LaTeX with hyperref package"}}}