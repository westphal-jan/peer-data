{"id": "1206.6417", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Learning Task Grouping and Overlap in Multi-task Learning", "abstract": "in the paradigm of multi - task learning, mul - tiple related prediction tasks are learned jointly, together sharing information across the tasks. we propose a framework for multi - task learn - ing that enables one to selectively share together the information across the tasks. we assume that each specific task parameter vector is a linear combi - nation of a finite number of complex underlying basis tasks. the coefficients of applying the linear combina - tion are sparse in nature and the overlap there in the sparsity patterns of two tasks controls the amount of sharing across these. our model is based on on the simultaneous assumption that task pa - rameters within another a group lie in a low dimen - sional subspace but allows integrating the tasks in differ - ent groups to overlap with each other simply in one or more bases. experimental results on four datasets show that our approach outperforms competing methods.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (192kb)", "http://arxiv.org/abs/1206.6417v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["abhishek kumar 0001", "hal daum\u00e9 iii"], "accepted": true, "id": "1206.6417"}, "pdf": {"name": "1206.6417.pdf", "metadata": {"source": "META", "title": "Learning Task Grouping and Overlap in Multi-Task Learning", "authors": ["Abhishek Kumar", "Hal Daum\u00e9 III"], "emails": ["abhishek@cs.umd.edu", "hal@umiacs.umd.edu"], "sections": [{"heading": "1. Introduction", "text": "Multi-task learning is concerned with simultaneously learning multiple prediction tasks that are related to one another (Caruana, 1997; Thrun & Pratt, 1998). The hope is that common information relevant to prediction can be shared among these tasks and learning them jointly can result in better generalization performance than independently learning each task. The key aspect in all multi-task learning methods is the introduction of an inductive bias in the joint hypothesis space of all tasks that reflects our prior beliefs about task relatedness structure. Assumptions that task parameters lie close to each other in some geometric sense (Evgeniou & Pontil, 2004), or parameters share a common prior (Yu et al., 2005; Lee et al., 2007; Daume\u0301 III, 2009), or they lie in a low dimensional subspace (Argyriou et al., 2008a) or on a mani-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nfold (Agarwal et al., 2010) are some examples of introducing an inductive bias in the hope of achieving better generalization. A major challenge in multi-task learning is how to selectively screen the sharing of information so that unrelated tasks do not end up influencing each other. Sharing information between two unrelated tasks can worsen the performance of both tasks. This phenomenon is also known as negative transfer. In this paper, we propose a structured prior on the tasks\u2019 weight matrix (whose columns are parameter vectors for individual prediction tasks) that allows formation of groups of related tasks with partial overlap among the groups. Two tasks can have full, partial or no overlap, which is determined by number of basis tasks they share. We use the term task to refer to the actual prediction problem. We will use the term task weight or parameter vector to refer to the parameters of the model learned from training data.\nA starting point for our method is the assumption that task parameters lie in a low dimensional subspace (Argyriou et al., 2008a). This is achieved by imposing a trace-norm constraint on the task weight matrix. However, the low rank assumption does not differentiate between the tasks and assumes that all tasks are related, which may adversely affect the performance when there are unrelated tasks in the pool, or some tasks have more in common than others. One way to address this problem is to assume that there are disjoint groups of tasks. Examples of such approaches are (Jacob et al., 2008; Xue et al., 2007) where tasks are assumed to be clustered and parameters of tasks within a cluster lie close to each other in \u21132 norm sense. Our proposed method does not regularize based on the \u21132 distance between task parameters which can fail to take advantage of negative correlation between the tasks. For example, grouping on the basis of \u21132 distance can put two tasks with parameters w and \u2212w in separate clusters and block the sharing of information between them while there is clearly a relation between the tasks, i.e., the span of these two parameter vectors is one dimensional sub-space instead of being a two dimensional space. An inductive bias that regu-\nlarizes based on the subspace assumption could have exploited the task relatedness of this sort. We do not assume disjoint groups and allow partial overlap between them.\nRecently, task grouping in the subspace based regularization framework was proposed in (Kang et al., 2011). Tasks are assumed to form disjoint groups and the tasks within each group are assumed to lie in a low dimensional subspace. The parameters of tasks and the group assignment matrix are both learned using alternating style optimization that converges to a local minimum. However, the subspaces shared by each group do not have any overlap between them, which may not always reflect the true sharing structure since there is often a continuum in the sharing between tasks. One pair of tasks may have more in common than another task pair and we may not be able to take full advantage of multi-task learning by putting the two tasks in the second pair in different groups.\nIn our model, we assume that task parameters within a group lie in a low dimensional subspace, and allow two tasks from different groups to overlap by having one or more bases in common. This is achieved by assuming that there exist a small number of latent basis tasks and parameter vector of every observed task is a linear combination of these. If the columns of L denote the parameter vectors of k latent tasks, we model the parameter vector wt of observed task t as wt = Lst, where st contain the coefficients of the linear combination. However, each linear combination is assumed to be sparse in the latent bases and the overlap in the sparsity patterns of any two tasks controls the amount of sharing between these. The low dimensional subspace assumption of (Argyriou et al., 2008a) can also be thought of having a small number of latent basis tasks, however each observed task is determined by a full linear combination of these bases and there is no notion of task groups. To be more clear about the difference, if there are k latent tasks and we pick r(\u2264 k) observed tasks arbitrarily, the corresponding weight matrix of these tasks will be of rank r in the model of (Argyriou et al., 2008a). On the other hand, our model allows this matrix to be of rank less than r by imposing sparse structure on the linear combination weights. We validate our approach empirically with two synthetic and four real-world datasets and observe that our method either outperforms or performs as well as the relevant baseline methods of (Kang et al., 2011; Argyriou et al., 2008a)."}, {"heading": "2. Related Work", "text": "Several methods have been proposed in the literature for the problem of multi-task learning. Most meth-\nods work on the assumption that all tasks are related (Evgeniou & Pontil, 2004; Ando & Zhang, 2005; Argyriou et al., 2008a; Rai & Daume\u0301 III, 2010). This assumption can be violated in many real applications and can degrade the performance. To avoid this, several methods have been proposed to allow for grouping of the tasks using different notions of grouping. Some methods assume that tasks can be grouped in clusters and parameters of tasks within a cluster are either close to each other in some distance metric or share a common probabilistic prior (Bakker & Heskes, 2003; Jacob et al., 2008; Xue et al., 2007; Zhou et al., 2011). Tasks in different clusters do not interact with one another. However, these methods might fail to take advantage of negatively correlated tasks since they can put these in different clusters. A similar idea was used in (Thrun & O\u2019Sullivan), where two tasks are taken to be similar if one\u2019s parameters improve performance on the other task.\nOther methods assume that there is one group of related tasks and a small number of outlier tasks that are not related to any task in the pool (Yu et al., 2007; Chen et al., 2011). There also exist probabilistic models which attempt to learn full task covariance matrix and use it in learning of predictor functions (Zhang & Yeung, 2010b;a; Zhang & Schneider, 2010; Archambeau et al., 2011). These methods place a matrix variate prior on the task matrix W.\nAnother common assumption is that task parameters lie in a low dimensional subspace that captures the predictive structure for all the tasks (Argyriou et al., 2008a; Liu et al., 2009). These methods assume that some of features (either in original space, or in a transformed space) are inactive for all tasks. This forces all task parameters to lie in a low dimensional subspace. In (Jalali et al., 2010), this model was refined and features are assumed to be either active for all tasks, or inactive for most of the tasks. This is done by forcing W to be sum of a group sparse matrix and a sparse matrix, hence predictors no longer lie in a low dimensional subspace.\nThere exist a few methods that incorporate grouping structure in the subspace based regularization (Argyriou et al., 2008b; Kang et al., 2011). In (Argyriou et al., 2008b), tasks in each group share a common linear transformation for feature extraction. It is shown to be equivalent to minimizing the tracenorm of each groups\u2019 weight sub-matrix. The objective is non-convex and it is optimized using stochastic gradient descent. Very similar in spirit is the work of (Kang et al., 2011), where tasks within a group are assumed to lie in a low dimensional subspace\nand they minimize the square of trace-norm of each group\u2019s weight sub-matrix (instead of trace-norm as in (Argyriou et al., 2008b)). The non-convex objective is optimized using mixed integer programming. Both these methods assume that groups are disjoint and tasks are either related (within a group) or totally unrelated (in different groups). This is in contrast to the approach proposed in this paper, where the low dimensional subspace shared by group members is not exclusive to it, and two tasks from different groups are allowed to overlap in one or more bases. Intuitively, this means that some of the latent basis tasks influence more than one group. Recently, (Passos et al., 2012) posited a mixture of sparse factor analyzers structure on the collection of the task weight vectors. Their model assumes that the tasks form clusters and tasks within each cluster are a sparse combination of a task dictionary specific to that cluster. A nonparametric Bayesian approach is used to learn the number of clusters and the task dictionary sizes from the data. The task clusters do not have overlap in task dictionary elements."}, {"heading": "3. Learning Task Grouping and Overlap", "text": "In this Section, we describe our approach for modeling task grouping and overlap. We call the proposed approach as GO-MTL for Grouping and Overlap in Multi-Task Learning. Suppose we have T tasks and Zt = {(xti, yti) : i = 1, 2, . . . , Nt} be the training set for each task t = 1, 2, . . . , T . Let wt represent the weight vector for task indexed by t. These task weight vectors are stacked as columns of a matrix W, which is of size d\u00d7 T , with d being the feature dimension.\nWe assume there are k(< T ) latent basis tasks and each observed task can be represented as linear combination of a subset of these basis tasks. This assumption enables us to write the weight matrix W as W = LS, where L is a matrix of size d\u00d7 k with each column representing a latent task, and S is a matrix of size k\u00d7T containing the weights of linear combination for each task. The predictor wt for task t is given by Lst, where st is t\u2019th column of matrix S. We assume the matrix S to be sparse to enforce that each observed task is obtained from only a few of the latent tasks, indexed by the non-zero pattern of the corresponding column of matrix S. The predictive structure of the tasks is captured by the matrix L and the grouping structure is determined by matrix S. For two columns st1 and st2 of matrix S corresponding to tasks t1 and t2, the overlap between the sparsity patterns determines the number of basis tasks they have in common. Tasks that have same sparsity pattern can be seen as belonging to same group, while tasks whose sparsity\npatterns are orthogonal to each other can be seen as belonging to different groups. The partial sharing of bases allows us to do away with the concept of disjoint groups, and allows to model tasks which are not as much related as they are with tasks in their own group but which still have something in common. The task that does not share bases with any other task in the pool can be seen as outlier task.\nIf st denotes the sparsity pattern for task t, our learning cost function takes the following form:\n\u2211\nt\n\u2211\n(xti,yti)\u2208Zt L (yti, s\n\u2032 tL \u2032xti) + \u00b5||S||1 + \u03bb||L|| 2 F , (1)\nwhere L(\u00b7, \u00b7) is the empirical loss function, || \u00b7 ||1 is entry-wise \u21131 norm of the matrix and ||L||F = (tr(LL\u2032))1/2 is the Frobenius norm of matrix L. The parameter \u00b5 controls the sparsity in S. The penalty on the Frobenius norm of L regularizes the predictor weights to have low \u21132 norm and avoids overfitting.\nFor a convex empirical loss function, the cost function in Eq. 1 is convex in L for a fixed S, and is convex in S for a fixed L, however, it is not jointly convex. We adopt alternating optimization strategy that converges to a local minimum. For a fixed L, the optimization function can be decomposed in individual problems for st as\nst = argmin s\n\u2211\n(xti,yti)\u2208Zt\nL (yti, s \u2032L\u2032xti) + \u00b5||s||1, (2)\nWe use two-metric projection method to optimize Eq. 2, which has superlinear convergence (Schmidt et al., 2007; Gafni & Bertsekas, 1984). For a fixed S, the optimization problem reduces to following:\nmin L\nT \u2211\nt=1\n\u2211\n(xti,yti)\u2208Zt\nL (yti, s \u2032 tL \u2032xti) + \u03bb||L|| 2 F . (3)\nThis problem is convex in L and has a closed form solution for squared loss function, which is commonly used in regression problems. For classification problems, we use logistic loss and optimize it using Newton-Raphson method, which is commonly used to estimate logistic regression parameters and is the basis of iterative reweighted least squares algorithm (IRLS) algorithm for logistic regression (Green, 1984). We also experimented with steepest gradient descent and found it to work reasonable well on all datasets that we tried.\nAlgorithm 1 outlines the steps and initialization procedure for our approach. We adopt the following strategy for initializing L. The individual task parameters\nAlgorithm 1 GO-MTL: Grouping and Overlap for Multi-Task Learning\nInput: Zt: Labeled training data for all tasks k: Number of latent tasks \u00b5: Parameter for controlling sparsity Output: Task predictor matrix W, L and S. 1: Learn individual predictors for each task using only its own data. 2: Let W0 be the matrix that contains these initial predictors as columns. 3: Compute top-k singular vectors: W0 = U\u03a3VT 4: Initialize L to first k columns of U. while not converged do for t = 1 to T do 5: Solve Eq. 2 to obtain st.\nend for 6: Construct matrix S = [s1s2 . . . sT ]. 7: Save the previous L: Lold = L. 8: Fix S and solve Eq. 3 to obtain L.\nend while 9: Return outputs: L = Lold, S and W = LoldS.\nare learned independently using their own data without any sharing, which are then stacked as columns in a weight matrix W0. The matrix L is then initialized to the top-k left singular vectors of W0. These are the directions that capture maximum variance of task parameters in a k-dimensional space. This initialization strategy was observed to be effective in all our experiments. The alternating optimization procedure is terminated when there is little change in L or S between two consecutive iterations.\nThe parameter k determines the number of latent tasks, which is taken to be less than total number of tasks T . The amount of inductive bias depends on this number. In this respect, it is similar to the \u201cnumber of groups\u201d parameter, G, in (Kang et al., 2011). If k is very low, it may shrink the hypothesis space too much. On the other hand, if k is very high, the tasks are not forced to share information with each other. When we increased the value of k in the experiments starting from 1, the prediction accuracy improves in the beginning. After a certain value of k, the performance becomes stable and the possible decrease in performance due to large k can be controlled by increasing the sparsity penalty \u00b5. More details on this behavior are provided in Sec. 4.\nIt is possible to have an alternative formulation to Eq. 1 where we can do away with parameter k (i.e., make it equal to T ), and instead enforce a low rank penalty on matrix L, weighted by a parameter \u03b1. This\ncan be done by penalizing the nuclear norm of L, which is the tightest convex lower bound on the rank function in the unit ball of matrices (i.e., matrices with spectral norm less than one). However, there are two disadvantages to this approach: (a) this convex surrogate is not always guaranteed to produce a low rank solution, and (b) this will result in a non-smooth optimization problem for L due to non-smoothness of the nuclear norm."}, {"heading": "3.1. Regression: Squared Loss", "text": "Here, we give details about optimization of the cost function of Eq. 1 for squared loss L(a, b) = (a \u2212 b)2, commonly used in regression problems. Let us denote yt to be a column vector of length Nt that contains all the labels for task t. Similarly, let Xt be the data matrix of size d \u00d7 Nt containing all the samples for task t stacked as columns. The cost function of Eq.1 can be written as,\nmin L,S\nT \u2211\nt=1\n1\nNt ||yt \u2212X\n\u2032 tLst|| 2 + \u00b5||S||1 + \u03bb||L|| 2 F , (4)\nFor a fixed L, we need the gradient and Hessian of the squared loss function f(st) =\n1 Nt ||yt \u2212X \u2032 tLst|| 2 to\noptimize for st using two-metric projection method. These are given as \u2207stf(st) = 2 Nt L\u2032Xt(X \u2032 tLst \u2212 yt), and \u22072stf(st) = 2 Nt L\u2032XtX \u2032\ntL. For a fixed S, equating the gradient of Eq. 4 to zero gives\nT \u2211\nt=1\n1\nNt Xtyts\n\u2032 t =\nT \u2211\nt=1\n1\nNt XtX\n\u2032 tLsts \u2032 t + \u03bbL\nThis is a linear equation in L. To solve this, we apply vectorization operator on both sides, which simply stacks all columns of a matrix one above another and forms a long vector. Clearly, this is a linear operator and can pass through the summation, and we obtain\nT \u2211\nt=1\n1\nNt vec (Xtyts\n\u2032 t) = vec\n(\nT \u2211\nt=1\n1\nNt XtX\n\u2032 tLsts \u2032 t + \u03bbL\n)\n=\n[\nT \u2211\nt=1\n1\nNt (sts\n\u2032 t)\u2297 (XtX \u2032 t) + \u03bbI\n]\nvec(L),\nwhere we have used a property of Kronecker product that vec(AXB) = (B\u2032 \u2297 A)vec(X). This is in standard form of system of linear equations that is full rank and has a unique solution. It can be solved using LU decomposition or by iterative methods, which are much faster and numerically more stable then solving it using matrix inverse."}, {"heading": "3.2. Classification: Logistic Loss", "text": "We use logistic regression for classification problems, although the proposed method is not tied to any par-\nticular loss function. Here, we give details about optimizing Eq. 1 for logistic loss function, which is given as L(y, f(x)) = log(1+ exp(\u2212yf(x))), where y \u2208 {\u22121, 1} is the true label. Let us denote the logistic function by \u03c3(x) = 1/(1 + e\u2212x). For a fixed L, we need the gradient and Hessian of the loss function w.r.t. st to solve using two-metric projection method, which are given by\nf(st) = 1\nNt\nNt \u2211\ni=1\nlog(1 + exp (\u2212ytis \u2032 tL \u2032xti))\n\u2207stf(st) = \u22121\nNt\nNt \u2211\ni=1\n(yti \u2212 \u03c3(w \u2032 txti))L \u2032xti\n\u22072stf(st) = 1\nNt\nNt \u2211\ni=1\n\u03c3(w\u2032txti)(1\u2212 \u03c3(w \u2032 txti))L \u2032xtix \u2032 tiL\nwhere wt = Lst is the weight vector for task t. For a fixed S, the objective is again convex in L and we give both gradient update and Newton-Raphson update here.\n\u2207L : \u2212\nT \u2211\nt=1\n1\nNt\nNt \u2211\ni=1\n(yti \u2212 \u03c3(w \u2032 txti))xtis \u2032 t + 2\u03bbL\nFor Newton-Raphson update, we use Taylor series expansion up to second order around L, making use of directional first and second derivatives. The step direction M is obtained by solving the following system of linear equations: t\nT \u2211\nt=1\n1\nNt\nNt \u2211\ni=1\n\u03b4ti [vec(xtis \u2032 t)\u2297 vec(xtis \u2032 t) \u2032] + 2\u03bbI\n|\nvec(M)\n= vec\n(\nT \u2211\nt=1\n1\nNt\nNt \u2211\ni=1\n(yti \u2212 \u03c3(w \u2032 txti))xtis \u2032 t \u2212 2\u03bbL\n)\nwhere \u03b4ti = \u03c3(w \u2032 txti)(1 \u2212 \u03c3(w \u2032 txti)). The NewtonRaphson update is then carried out by taking a step in this direction. The step size is computed using Armijo rule.\nNewton-Raphson updates, although more costly to compute, can converge in a smaller number of iterations. Gradient updates also seemed to work reasonably well in the experiments. This can be considerably faster than Newton-Raphson, especially for large problems, since Newton-Raphson involves solving a system of linear equations of size dk multiple times for every iteration of L."}, {"heading": "4. Experiments", "text": "We perform extensive empirical evaluation of our approach to gauge its effectiveness. We carry out empir-\nical comparisons with following two competing subspace regularized multi-task learning approaches:\n\u2022 No-group MTL (Argyriou et al., 2008a): All tasks are assumed to be related, and the task parameters are assumed to lie in a low dimensional subspace. This is done by penalizing the nuclear norm of weight matrix. \u2022 Disjoint-Group MTL (DGMTL) (Kang et al., 2011): A recently proposed approach that assumes multiple disjoint groups of tasks. Task parameters within a group lie in a low dimensional space.\nIn addition, we also compare with baseline single task learning (STL), in which tasks are learned independently. Below, we report results on two synthetic and four real-world datasets. The regularization parameter \u03bb in Eq. 1 is kept fixed at 0.1 in all experiments. We expect \u03bb to depend on the dimensionality of the space and number of examples. Incidentally, all the real-world datasets used in this work have dimensionality less than 100, for which \u03bb = 0.1 seemed to work well. Of course, it can always be selected using crossvalidation. We generate four different random splits (70% train, 30% validation) on the training set for cross-validation of parameter \u00b5. The search grid was taken to be [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4]. Averaged performance for different splits is reported."}, {"heading": "4.1. Synthetic data", "text": "We use two synthetic datasets to study our approach. First, we use the synthetic data used in (Kang et al., 2011).1 This data consists of 20-dimensional feature vectors, three groups of tasks, 15 training points and 50 test points per task. There are 10 tasks in each group whose parameter vectors are identical to each other up to a scaling factor. These parameters are used\n1This data along with the source code was taken from author\u2019s website: http://wwwscf.usc.edu/ zkang/GoupMTLCode.zip\nin the model of linear regression to generate training data. The task groups in this data are disjoint.\nWe generate a second synthetic dataset to simulate overlap in groups. We retain the previous setting of 3 groups and 10 tasks in each group, but now we allow the groups to overlap in one basis. We generate parameter vectors for 4 latent tasks in 20 dimensions, with each entry drawn i.i.d. from a zero mean and unit variance normal distribution. This is essentially the matrix L in our formulation. We generate the first 10 tasks by linearly combining only first two latent tasks. The coefficients of linear combination are drawn i.i.d. from a normal distribution centered at zero with unit variance. In a similar manner, we generate the next 10 tasks by linearly combining second and third latent tasks. Last 10 task parameters are generated by linear combination of the last two latent tasks. The matrix S in our formulation that contains the coefficients of linear combination, has precisely two non-zero entries in each column for this generative model. We randomly generate 15 training and 50 test points per task, and task parameters are used to generate their real valued labels using a linear regression model. Random Gaussian noise with zero mean and 0.5 standard deviation is added to the labels.\nThe plot of root mean square error (RMSE) with changing k is shown in Fig. 1 and Fig. 2. We also show the RMSE plot with changing value of parameter G (the number of groups) in the approach of (Kang et al., 2011). GO-MTL converges to almost same RMSE for all values of k \u2265 3 for first synthetic data and k \u2265 4 for the second synthetic data. The performance of (Kang et al., 2011) is more sensitive to the number of groups parameter (G) and starts deteriorating when it is increased or decreased from the true value. The proposed approach outperforms disjoint-group MTL by a significant margin, more so on the second dataset that has overlap in groups. Ta-\nble 1 shows the exact RMSE values obtained for these datasets.\nThe sparsity patterns recovered by GO-MTL for these two data are shown in Fig. 3 and Fig. 4. We are able to recover the grouping and overlap structure for most of the tasks in both cases. For the second synthetic data (Fig. 4), support of first 10 and last 10 tasks is recovered more precisely than the support of the middle group, where a few tasks (for example, 11th, 15th and 16th task) have non-negligible coefficients not belonging to the true support. The recovery of support was found to be robust to the value of k chosen in the algorithm, as is shown in the figures. We are able to recover the support with same precision for values of k \u2265 3 for the first data and values of k \u2265 4 for the second data."}, {"heading": "4.2. Real datasets", "text": "We evaluate the proposed approach on the following four real-world datasets, two of which are regression tasks and the other two are classification tasks. We treat multi-way classification as multi-task learning problem where each task is the classification of one class from all other classes. To be fair in our comparisons, we evaluate on datasets that are used in (Argyriou et al., 2008a; Kang et al., 2011).\n\u2022 Computer Survey data: This regression dataset has been widely in the literature to evaluate various multi-task learning approaches (Argyriou et al., 2008a; Agarwal et al., 2010). The data was collected in a survey of 190 persons who rated their likelihood of purchasing each of 20 different personal computers. Here, students correspond to tasks and computers correspond to examples. All computers are rated by each student on a scale of 0-10, thus giving 20 labeled examples per task. Each computer is represented by 13 different features (RAM, cache-size, hard-disk, CPU speed, etc.). We added one more feature of constant 1 in all examples to account for the bias term in the regression. Training and test set are obtained by splitting the datasets 75%- 25%, thus giving 15 examples for training and 5 examples for test. \u2022 School data: This regression data has been used in previous works in multi-task learning (Argyriou et al., 2008a; Agarwal et al., 2010; Bakker & Heskes, 2003). This dataset is from Inner London Education Authority and consists of examination scores of 15362 students from 139 schools in London. Here, each school corre-\nsponds to a task, thus giving a total of 139 tasks. The input consists of the year of examination, 4 school-specific attributes and 3 student-specific attributes. Following (Argyriou et al., 2008a), each categorical feature is replaced with binary features, giving a total of 26 features. We again add a feature of constant 1 in all examples to account for the bias term. Training and test set are obtained by dividing examples of each task 60%-40%. Number of examples in each task are different; there are about 65 examples per task on average in training and 45 examples per task for test. \u2022 USPS Digits data: This is a handwritten digits dataset (Hull, 1994) with 10 classes.2 The images are processed using PCA and dimensionality is reduced to 87, retaining almost 95% of the variance. \u2022 MNIST Digits data: This is another handwritten digits dataset (LeCun et al., 1998) with 10 classes.2 The images are preprocessed with PCA and dimensionality reduced to 64.\nFor MNIST and USPS datasets, we use the same setup as in (Kang et al., 2011) where 1000, 500 and 500 samples are used for training, validation and test respectively. The results are summarized in Table 1. All multi-task learning approaches are able to outperform single task learning, however on School data, the improvement is not statistically significant. The proposed method is able to outperform both no-group MTL and disjoint-group MTL."}, {"heading": "5. Conclusion", "text": "We proposed a novel framework for learning grouping and overlap structure in multi-task learning, where parameters of each task group are assumed to lie in a low dimensional subspace. Our approach does not assume disjoint grouping structure, and tasks belonging to different groups are allowed to overlap with each other through sharing of one or more latent basis tasks. This is a more realistic assumption since we can have\n2We thank the authors of (Kang et al., 2011) for providing us the data used in their paper.\ntasks in our pool that are not related enough to be in the same group, but still share some information that can be exploited for better learning. We validated our model on two synthetic and four real datasets, and obtained considerable gains compared to other competing approaches for subspace regularized multi-task learning that either do not take grouping structure into account, or assume that tasks in different groups do not interact at all. For future work, we would like to extend the proposed model to learn other types of structured interaction patterns among the tasks, e.g., hierarchies of tasks."}], "references": [{"title": "Learning Multiple Tasks using Manifold Regularization", "author": ["Agarwal", "Arvind", "Daum\u00e9 III", "Hal", "Gerber", "Samuel"], "venue": "In NIPS,", "citeRegEx": "Agarwal et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2010}, {"title": "A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data", "author": ["Ando", "Rie Kubota", "Zhang", "Tong"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Ando et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ando et al\\.", "year": 2005}, {"title": "Sparse Bayesian Multi-Task Learning", "author": ["Archambeau", "Cedric", "Guo", "Shengbo", "Zoeter", "Onno"], "venue": "In NIPS,", "citeRegEx": "Archambeau et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Archambeau et al\\.", "year": 2011}, {"title": "Convex Multi-task Feature Learning", "author": ["Argyriou", "Andreas", "Evgeniou", "Theodoros", "Pontil", "Massimiliano"], "venue": "Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "An Algorithm for Transfer Learning in a Heterogeneous Environment", "author": ["Argyriou", "Andreas", "Maurer", "Pontil", "Massimiliano"], "venue": "In Proc. of ECML/PKDD,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "Task Clustering and Gating for Bayesian Multitask Learning", "author": ["Bakker", "Bart", "Heskes", "Tom"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bakker et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bakker et al\\.", "year": 2003}, {"title": "Multitask Learning", "author": ["Caruana", "Rich"], "venue": "Machine Learning,", "citeRegEx": "Caruana and Rich.,? \\Q1997\\E", "shortCiteRegEx": "Caruana and Rich.", "year": 1997}, {"title": "Integrating Low-Rank and Group-Sparse Structures for Robust Multi-Task Learning", "author": ["Chen", "Jianhui", "Zhou", "Jiayu", "Ye", "Jieping"], "venue": "In KDD,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Bayesian Multitask Learning with Latent Hierarchies", "author": ["Daum\u00e9 III", "Hal"], "venue": "In UAI,", "citeRegEx": "III and Hal.,? \\Q2009\\E", "shortCiteRegEx": "III and Hal.", "year": 2009}, {"title": "Regularized multi-task learning", "author": ["Evgeniou", "Theodoros", "Pontil", "Massimiliano"], "venue": "In SIGKDD International Conference on Knowledge Discovery and Data mining,", "citeRegEx": "Evgeniou et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2004}, {"title": "Two-metric projection methods for constrained optimization", "author": ["E. Gafni", "D. Bertsekas"], "venue": "SIAM J. Contr. Optim,", "citeRegEx": "Gafni and Bertsekas,? \\Q1984\\E", "shortCiteRegEx": "Gafni and Bertsekas", "year": 1984}, {"title": "Iteratively Reweighted Least Squares for Maximum Likelihood Estimation, and some Robust and Resistant Alternatives", "author": ["P.J. Green"], "venue": "Journal of Royal Statistical Society, Series B,", "citeRegEx": "Green,? \\Q1984\\E", "shortCiteRegEx": "Green", "year": 1984}, {"title": "A database for handwritten text recognition research", "author": ["J.J. Hull"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Hull,? \\Q1994\\E", "shortCiteRegEx": "Hull", "year": 1994}, {"title": "Clustered Multi-task Learning: a Convex Formulation", "author": ["Jacob", "Laurent", "Bach", "Francis", "Vert", "Jean-Philippe"], "venue": "In NIPS,", "citeRegEx": "Jacob et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Jacob et al\\.", "year": 2008}, {"title": "A Dirty Model for Multi-task Learning", "author": ["Jalali", "Ali", "Ravikumar", "Pradeep", "Sanghavi", "Sujay", "Ruan", "Chao"], "venue": "In NIPS,", "citeRegEx": "Jalali et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jalali et al\\.", "year": 2010}, {"title": "Learning with Whom to Share in Multi-task Feature Learning", "author": ["Kang", "Zhuoliang", "Grauman", "Kristen", "Sha", "Fei"], "venue": "In ICML,", "citeRegEx": "Kang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kang et al\\.", "year": 2011}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Learning a meta-level prior for feature relevance from multiple related tasks", "author": ["S.I. Lee", "V. Chatalbashev", "D. Vickrey", "D. Koller"], "venue": "In ICML,", "citeRegEx": "Lee et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2007}, {"title": "Multi-Task Feature Learning Via Efficient L2,1-Norm Minimization", "author": ["Liu", "Jun", "Ji", "Shuiwang", "Ye", "Jieping"], "venue": "In UAI,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Flexible Modeling of Latent Task Structures in Multitask Learning", "author": ["Passos", "Alexandre", "Rai", "Piyush", "Wainer", "Jacques", "Daum\u00e9 III", "Hal"], "venue": "In ICML,", "citeRegEx": "Passos et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Passos et al\\.", "year": 2012}, {"title": "Infinite Predictor Subspace Models for Multitask Learning", "author": ["Rai", "Piyush", "Daum\u00e9 III", "Hal"], "venue": "In AISTATS,", "citeRegEx": "Rai et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rai et al\\.", "year": 2010}, {"title": "Fast Optimization Methods for L1 Regularization: A Comparative Study and Two New Approaches", "author": ["Schmidt", "Mark", "Fung", "Glenn", "Rosales", "Romer"], "venue": "In ECML,", "citeRegEx": "Schmidt et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2007}, {"title": "Learning to Learn", "author": ["Thrun", "Sebastian", "Pratt", "Lorien"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1998}, {"title": "Multi-Task Learning for Classification with Dirichlet Process Priors", "author": ["Xue", "Ya", "Liao", "Xuejun", "Carin", "Lawrence", "Krishnapuram", "Balaji"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Xue et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2007}, {"title": "Learning Gaussian Processes from Multiple Task", "author": ["Yu", "Kai", "Tresp", "Volker", "Schwaighofer", "Anton"], "venue": "In ICML,", "citeRegEx": "Yu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2005}, {"title": "Robust MultiTask Learning with t-Processes", "author": ["Yu", "Shipeng", "tresp", "Volker", "Kai"], "venue": "In ICML,", "citeRegEx": "Yu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2007}, {"title": "Learning Multiple Tasks with a Sparse Matrix-Normal Penalty", "author": ["Zhang", "Yi", "Schneider", "Jeff"], "venue": "In NIPS,", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}, {"title": "A Convex Formulation for Learning Task Relationships in Multi-Task Learning", "author": ["Zhang", "Yu", "Yeung", "Dit-Yan"], "venue": "In UAI,", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}, {"title": "Multi-Task Learning using Generalized t-Process", "author": ["Zhang", "Yu", "Yeung", "Dit-Yan"], "venue": "In AISTATS,", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}, {"title": "Clustered Multi-task Learning Via Alternating Structure Optimization", "author": ["Zhou", "Jiayu", "Chen", "Jianhui", "Ye", "Jieping"], "venue": "In NIPS,", "citeRegEx": "Zhou et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 24, "context": "Assumptions that task parameters lie close to each other in some geometric sense (Evgeniou & Pontil, 2004), or parameters share a common prior (Yu et al., 2005; Lee et al., 2007; Daum\u00e9 III, 2009), or they lie in a low dimensional subspace (Argyriou et al.", "startOffset": 143, "endOffset": 195}, {"referenceID": 17, "context": "Assumptions that task parameters lie close to each other in some geometric sense (Evgeniou & Pontil, 2004), or parameters share a common prior (Yu et al., 2005; Lee et al., 2007; Daum\u00e9 III, 2009), or they lie in a low dimensional subspace (Argyriou et al.", "startOffset": 143, "endOffset": 195}, {"referenceID": 0, "context": "fold (Agarwal et al., 2010) are some examples of introducing an inductive bias in the hope of achieving better generalization.", "startOffset": 5, "endOffset": 27}, {"referenceID": 13, "context": "Examples of such approaches are (Jacob et al., 2008; Xue et al., 2007) where tasks are assumed to be clustered and parameters of tasks within a cluster lie close to each other in l2 norm sense.", "startOffset": 32, "endOffset": 70}, {"referenceID": 23, "context": "Examples of such approaches are (Jacob et al., 2008; Xue et al., 2007) where tasks are assumed to be clustered and parameters of tasks within a cluster lie close to each other in l2 norm sense.", "startOffset": 32, "endOffset": 70}, {"referenceID": 15, "context": "Recently, task grouping in the subspace based regularization framework was proposed in (Kang et al., 2011).", "startOffset": 87, "endOffset": 106}, {"referenceID": 15, "context": "We validate our approach empirically with two synthetic and four real-world datasets and observe that our method either outperforms or performs as well as the relevant baseline methods of (Kang et al., 2011; Argyriou et al., 2008a).", "startOffset": 188, "endOffset": 231}, {"referenceID": 13, "context": "Some methods assume that tasks can be grouped in clusters and parameters of tasks within a cluster are either close to each other in some distance metric or share a common probabilistic prior (Bakker & Heskes, 2003; Jacob et al., 2008; Xue et al., 2007; Zhou et al., 2011).", "startOffset": 192, "endOffset": 272}, {"referenceID": 23, "context": "Some methods assume that tasks can be grouped in clusters and parameters of tasks within a cluster are either close to each other in some distance metric or share a common probabilistic prior (Bakker & Heskes, 2003; Jacob et al., 2008; Xue et al., 2007; Zhou et al., 2011).", "startOffset": 192, "endOffset": 272}, {"referenceID": 29, "context": "Some methods assume that tasks can be grouped in clusters and parameters of tasks within a cluster are either close to each other in some distance metric or share a common probabilistic prior (Bakker & Heskes, 2003; Jacob et al., 2008; Xue et al., 2007; Zhou et al., 2011).", "startOffset": 192, "endOffset": 272}, {"referenceID": 25, "context": "Other methods assume that there is one group of related tasks and a small number of outlier tasks that are not related to any task in the pool (Yu et al., 2007; Chen et al., 2011).", "startOffset": 143, "endOffset": 179}, {"referenceID": 7, "context": "Other methods assume that there is one group of related tasks and a small number of outlier tasks that are not related to any task in the pool (Yu et al., 2007; Chen et al., 2011).", "startOffset": 143, "endOffset": 179}, {"referenceID": 2, "context": "There also exist probabilistic models which attempt to learn full task covariance matrix and use it in learning of predictor functions (Zhang & Yeung, 2010b;a; Zhang & Schneider, 2010; Archambeau et al., 2011).", "startOffset": 135, "endOffset": 209}, {"referenceID": 18, "context": "Another common assumption is that task parameters lie in a low dimensional subspace that captures the predictive structure for all the tasks (Argyriou et al., 2008a; Liu et al., 2009).", "startOffset": 141, "endOffset": 183}, {"referenceID": 14, "context": "In (Jalali et al., 2010), this model was refined and features are assumed to be either active for all tasks, or inactive for most of the tasks.", "startOffset": 3, "endOffset": 24}, {"referenceID": 15, "context": "There exist a few methods that incorporate grouping structure in the subspace based regularization (Argyriou et al., 2008b; Kang et al., 2011).", "startOffset": 99, "endOffset": 142}, {"referenceID": 15, "context": "Very similar in spirit is the work of (Kang et al., 2011), where tasks within a group are assumed to lie in a low dimensional subspace", "startOffset": 38, "endOffset": 57}, {"referenceID": 19, "context": "Recently, (Passos et al., 2012) posited a mixture of sparse factor analyzers structure on the collection of the task weight vectors.", "startOffset": 10, "endOffset": 31}, {"referenceID": 21, "context": "2, which has superlinear convergence (Schmidt et al., 2007; Gafni & Bertsekas, 1984).", "startOffset": 37, "endOffset": 84}, {"referenceID": 11, "context": "For classification problems, we use logistic loss and optimize it using Newton-Raphson method, which is commonly used to estimate logistic regression parameters and is the basis of iterative reweighted least squares algorithm (IRLS) algorithm for logistic regression (Green, 1984).", "startOffset": 267, "endOffset": 280}, {"referenceID": 15, "context": "In this respect, it is similar to the \u201cnumber of groups\u201d parameter, G, in (Kang et al., 2011).", "startOffset": 74, "endOffset": 93}, {"referenceID": 15, "context": "Left: RMSE with DG-MTL (Kang et al., 2011) vs.", "startOffset": 23, "endOffset": 42}, {"referenceID": 15, "context": "\u2022 Disjoint-Group MTL (DGMTL) (Kang et al., 2011): A recently proposed approach that assumes multiple disjoint groups of tasks.", "startOffset": 29, "endOffset": 48}, {"referenceID": 15, "context": "First, we use the synthetic data used in (Kang et al., 2011).", "startOffset": 41, "endOffset": 60}, {"referenceID": 15, "context": "We also show the RMSE plot with changing value of parameter G (the number of groups) in the approach of (Kang et al., 2011).", "startOffset": 104, "endOffset": 123}, {"referenceID": 15, "context": "The performance of (Kang et al., 2011) is more sensitive to the number of groups parameter (G) and starts deteriorating when it is increased or decreased from the true value.", "startOffset": 19, "endOffset": 38}, {"referenceID": 15, "context": "To be fair in our comparisons, we evaluate on datasets that are used in (Argyriou et al., 2008a; Kang et al., 2011).", "startOffset": 72, "endOffset": 115}, {"referenceID": 15, "context": ", 2008a), DG-MTL (Kang et al., 2011), GO-MTL: the proposed method.", "startOffset": 17, "endOffset": 36}, {"referenceID": 0, "context": "\u2022 Computer Survey data: This regression dataset has been widely in the literature to evaluate various multi-task learning approaches (Argyriou et al., 2008a; Agarwal et al., 2010).", "startOffset": 133, "endOffset": 179}, {"referenceID": 0, "context": "\u2022 School data: This regression data has been used in previous works in multi-task learning (Argyriou et al., 2008a; Agarwal et al., 2010; Bakker & Heskes, 2003).", "startOffset": 91, "endOffset": 160}, {"referenceID": 12, "context": "\u2022 USPS Digits data: This is a handwritten digits dataset (Hull, 1994) with 10 classes.", "startOffset": 57, "endOffset": 69}, {"referenceID": 16, "context": "\u2022 MNIST Digits data: This is another handwritten digits dataset (LeCun et al., 1998) with 10 classes.", "startOffset": 64, "endOffset": 84}, {"referenceID": 15, "context": "For MNIST and USPS datasets, we use the same setup as in (Kang et al., 2011) where 1000, 500 and 500 samples are used for training, validation and test respectively.", "startOffset": 57, "endOffset": 76}, {"referenceID": 15, "context": "We thank the authors of (Kang et al., 2011) for providing us the data used in their paper.", "startOffset": 24, "endOffset": 43}], "year": 2012, "abstractText": "In the paradigm of multi-task learning, multiple related prediction tasks are learned jointly, sharing information across the tasks. We propose a framework for multi-task learning that enables one to selectively share the information across the tasks. We assume that each task parameter vector is a linear combination of a finite number of underlying basis tasks. The coefficients of the linear combination are sparse in nature and the overlap in the sparsity patterns of two tasks controls the amount of sharing across these. Our model is based on the assumption that task parameters within a group lie in a low dimensional subspace but allows the tasks in different groups to overlap with each other in one or more bases. Experimental results on four datasets show that our approach outperforms competing methods.", "creator": "LaTeX with hyperref package"}}}