{"id": "1209.2434", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2012", "title": "Query Complexity of Derivative-Free Optimization", "abstract": "this paper provides lower bounds particularly on the convergence rate variation of derivative free optimization ( dfo ) with noisy function evaluations, finally exposing a fundamental and unavoidable gap between the performance of smooth algorithms with access to gradients etc and those with access to only function evaluations. however, there are situations in which dfo is unavoidable, and for such situations we propose a valuable new dfo algorithm that indeed is proved to be near optimal for the class graphs of strongly convex objective functions. \" a distinctive feature of the algorithm is that it uses only boolean - valued dependent function comparisons, rather than function evaluations. this analysis makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. we also thoroughly show us that regardless of whether genuine dfo is based on noisy function evaluations or traditional boolean - valued linear function comparisons, the convergence convergence rate is the same.", "histories": [["v1", "Tue, 11 Sep 2012 20:37:02 GMT  (21kb)", "http://arxiv.org/abs/1209.2434v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["kevin g jamieson", "robert d nowak", "benjamin recht"], "accepted": true, "id": "1209.2434"}, "pdf": {"name": "1209.2434.pdf", "metadata": {"source": "CRF", "title": "Query Complexity of Derivative-Free Optimization", "authors": ["Kevin G. Jamieson"], "emails": ["kgjamieson@wisc.edu", "nowak@engr.wisc.edu", "brecht@cs.wisc.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 9.\n24 34\nv1 [\nst at\n.M L\n] 1\n1 Se\np 20\nThis paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same."}, {"heading": "1 Introduction", "text": "Optimizing large-scale complex systems often requires the tuning of many parameters. With training data or simulations one can evaluate the relative merit, or incurred loss, of different parameter settings, but it may be unclear how each parameter influences the overall objective function. In such cases, derivatives of the objective function with respect to the parameters are unavailable. Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8]. When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10]. This leads one to wonder if the same equivalence can be extended to the case when function evaluations and gradients are noisy.\nSadly, this paper proves otherwise. We show that when function evaluations are noisy, the optimization error of any DFO is \u2126( \u221a 1/T ), where T is the number of evaluations. This lower bound holds even for strongly convex functions. In contrast, noisy gradient methods exhibit \u0398(1/T ) error scaling for strongly convex functions [9, 11]. A consequence of our theory is that finite differencing cannot achieve the rates of gradient methods when the function evaluations are noisy.\nOn the positive side, we also present a new derivative-free algorithm that achieves this lower bound with near optimal dimension dependence. Moreover, the algorithm uses only boolean comparisons of function values, not actual function values. This makes the algorithm applicable to situations in which the optimization is only able to probably correctly decide if the value of one configuration is better than the value of another. This is especially interesting in optimization based on human subject feedback, where paired comparisons are often used instead of numerical scoring. The convergence rate of the new algorithm is optimal in terms of T and near-optimal in terms of its dependence on the ambient dimension. Surprisingly, our lower bounds show that this new algorithm that uses only function comparisons achieves the same rate in terms of T as any algorithm that has access to function evaluations."}, {"heading": "2 Problem formulation and background", "text": "We now formalize the notation and conventions for our analysis of DFO. A function f is strongly convex with constant \u03c4 on a convex set B \u2282 Rd if there exists a constant \u03c4 > 0 such that\nf(y) \u2265 f(x) + \u3008\u2207f(x), y \u2212 x\u3009+ \u03c4 2 ||x\u2212 y||2\nfor all x, y \u2208 B. The gradient of f , if it exists, denoted \u2207f , is Lipschitz with constant L if ||\u2207f(x) \u2212 \u2207f(y)|| \u2264 L||x \u2212 y|| for some L > 0. The class of strongly convex functions with Lipschitz gradients defined on a nonempty, convex set B \u2282 Rn which take their minimum in B with parameters \u03c4 and L is denoted by F\u03c4,L,B. The problem we consider is minimizing a function f \u2208 F\u03c4,L,B. The function f is not explicitly known. An optimization procedure may only query the function in one of the following two ways.\nFunction Evaluation Oracle: For any point x \u2208 B an optimization procedure can observe Ef (x) = f(x) + w\nwhere w \u2208 R is a random variable with E[w] = 0 and E[w2] = \u03c32. Function Comparison Oracle: For any pair of points x, y \u2208 B an optimization procedure can\nobserve a binary random variable Cf (x, y) satisfying\nP (Cf (x, y) = sign{f(y)\u2212 f(x)}) \u2265 1\n2 + min\n{ \u03b40, \u00b5|f(y)\u2212 f(x)|\u03ba\u22121 } (1)\nfor some 0 < \u03b40 \u2264 1/2, \u00b5 > 0 and \u03ba \u2265 1. When \u03ba = 1, without loss of generality assume \u00b5 \u2264 \u03b40 \u2264 1/2. Note \u03ba = 1 implies that the comparison oracle is correct with a probability that is greater than 1/2 and independent of x, y. If \u03ba > 1, then the oracle\u2019s reliability decreases as the difference between f(x) and f(y) decreases.\nTo illustrate how the function comparison oracle and function evaluation oracles relate to each other, suppose Cf (x, y) = sign{Ef (y) \u2212 Ef (x)} where Ef (x) is a function evaluation oracle with additive noise w. If w is Gaussian distributed with mean zero and variance \u03c32 then \u03ba = 2 and \u00b5 \u2265 ( 4\u03c0\u03c32e )\u22121/2 (see Appendix A). In fact, this choice of w corresponds to Thurston\u2019s law of comparative judgment which is a popular model for outcomes of pairwise comparisons from human subjects [12]. If w is a \u201cspikier\u201d distribution such as a two-sided Gamma distribution with shape parameter in the range of (0, 1] then all values of \u03ba \u2208 (1, 2] can be realized (see Appendix A). Interest in the function comparison oracle is motivated by certain popular derivative-free optimization procedures that use only comparisons of function evaluations (e.g. [7]) and by optimization problems involving human subjects making paired comparisons (for instance, getting fitted for prescription lenses or a hearing aid where unknown parameters specific to each person are tuned with the familiar queries \u201cbetter or worse?\u201d). Pairwise comparisons have also been suggested as a novel way to tune web-search algorithms [13]. Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14]. The function comparison oracle presented in this work and its analysis are novel. The main contributions of this work and new art are as follows (i) lower bounds for the function evaluation oracle in the presence of measurement noise (ii) lower bounds for the function comparison oracle in the presence of noise and (iii) an algorithm for the function comparison oracle, which can also be applied to the function evaluation oracle setting, that nearly matches both the lower bounds of (i) and (ii).\nWe prove our lower bounds for strongly convex functions with Lipschitz gradients defined on a compact, convex set B, and because these problems are a subset of those involving all convex functions (and have non-empty intersection with problems where f is merely Lipschitz), the lower bound also applies to these larger classes. While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting. Moreover, we believe we are the first to show a novel upper bound for stochastic DFO using a function comparison oracle (which also applies to the function evaluation oracle). However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle [15, 16]. We discuss the relevant results in the next section following the lower bounds .\nWhile there remains many open problems in stochastic DFO (see Section 6), rates of convergence with a stochastic gradient oracle are well known and were first lower bounded by Nemirovski and Yudin [15]. These classic results were recently tightened to show a dependence on the dimension of the problem [17]. And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9]. The aim of this work is to start filling in the knowledge gaps of stochastic DFO so that it is as well understood as the stochastic gradient oracle. Our bounds are based on simple techniques borrowed from the statistical learning literature that use natural functions and oracles in the same spirit of [11]."}, {"heading": "3 Main results", "text": "The results below are presented with simplifying constants that encompass many factors to aid in exposition. Explicit constants are given in the proofs in Sections 4 and 5. Throughout, we denote the minimizer of f as x\u2217f . The expectation in the bounds is with respect to the noise in the oracle queries and (possible) optimization algorithm randomization."}, {"heading": "3.1 Query complexity of the function comparison oracle", "text": "Theorem 1. For every f \u2208 F\u03c4,L,B let Cf be a function comparison oracle with parameters (\u03ba, \u00b5, \u03b40). Then for n \u2265 8 and sufficiently large T\ninf x\u0302T sup f\u2208F\u03c4,L,B\nE [ f(x\u0302T )\u2212 f(x\u2217f ) ] \u2265    c1 exp { \u2212c2 Tn } if \u03ba = 1\nc3 ( n T ) 1 2(\u03ba\u22121) if \u03ba > 1\nwhere the infimum is over the collection of all possible estimators of x\u2217f using at most T queries to a function comparison oracle and the supremum is taken with respect to all problems in F\u03c4,L,B and function comparison oracles with parameters (\u03ba, \u00b5, \u03b40). The constants c1, c2, c3 depend the oracle and function class parameters, as well as the geometry of B, but are independent of T and n.\nFor upper bounds we propose a specific algorithm based on coordinate-descent in Section 5 and prove the following theorem for the case of unconstrained optimization, that is, B = Rn. Theorem 2. For every f \u2208 F\u03c4,L,B with B = Rn let Cf be a function comparison oracle with parameters (\u03ba, \u00b5, \u03b40). Then there exists a coordinate-descent algorithm that is adaptive to unknown \u03ba \u2265 1 that outputs an estimate x\u0302T after T function comparison queries such that with probability 1\u2212 \u03b4\nsup f\u2208F\u03c4,L,B\nE [ f(x\u0302T )\u2212 f(x\u2217f ) ] \u2264    c1 exp { \u2212c2 \u221a T n } if \u03ba = 1\nc3n ( n T ) 1 2(\u03ba\u22121) if \u03ba > 1\nwhere c1, c2, c3 depend the oracle and function class parameters as well as T ,n, and 1/\u03b4, but only poly-logarithmically."}, {"heading": "3.2 Query complexity of the function evaluation oracle", "text": "Theorem 3. For every f \u2208 F\u03c4,L,B let Ef be a function evaluation oracle with variance \u03c32. Then for n \u2265 8 and sufficiently large T\ninf x\u0302T sup f\u2208F\u03c4,L,B\nE [ f(x\u0302T )\u2212 f(x\u2217f ) ] \u2265 c\n( n\u03c32\nT\n) 1 2\nwhere the infimum is taken with respect to the collection of all possible estimators of x\u2217f using just T queries to a function evaluation oracle and the supremum is taken with respect to all problems in F\u03c4,L,B and function evaluation oracles with variance \u03c32. The constant c depends on the oracle and function class parameters, as well as the geometry of B, but is independent of T and n.\nBecause a function evaluation oracle can always be turned into a function comparison oracle (see discussion above), the algorithm and upper bound in Theorem 2 with \u03ba = 2 applies to many typical\nfunction evaluation oracles (e.g. additive Gaussian noise), yielding an upper bound of ( n3\u03c32/T )1/2 ignoring constants and log factors. This matches the rate of convergence as a function of T and \u03c32, but has worse dependence on the dimension n.\nAlternatively, under a less restrictive setting, Nemirovski and Yudin proposed two algorithms for the class of convex, Lipschitz functions that obtain rates of n1/2/T 1/4 and p(n)/T 1/2, respectively, where p(n) was left as an unspecified polynomial of n [15]. While focusing on stochastic DFO with bandit feedback, Agarwal et. al. built on the ideas developed in [15] to obtain a result that they point out implies a convergence rate of n16/T 1/2 in the optimization setting considered here [16]. Whether or not these rates can be improved to those obtained under the more restrictive function classes of above is an open question.\nA related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19]. Essentially, this setting allows the algorithm to probe the value of the function f plus noise at multiple locations where the noise changes at each time step, but each set of samples at each time experiences the same noise. Because the noise model of that work is incompatible with the one considered here, no comparisons should be made between the two."}, {"heading": "4 Lower Bounds", "text": "The lower bounds in Theorems 1 and 3 are proved using a general minimax bound [20, Thm. 2.5]. Our proofs are most related to the approach developed in [21] for active learning, which like optimization involves a Markovian sampling process. Roughly speaking, the lower bounds are established by considering a simple case of the optimization problem in which the global minimum is known a priori to belong to a finite set. Since the simple case is \u201ceasier\u201d than the original optimization, the minimum number of queries required for a desired level of accuracy in this case yields a lower bound for the original problem.\nThe following theorem is used to prove the bounds. In the terms of the theorem, f is a function to be minimized and Pf is the probability model governing the noise associated with queries when f is the true function.\nTheorem 4. [20, Thm. 2.5] Consider a class of functions F and an associated family of probability measures {Pf}f\u2208F . Let M \u2265 2 be an integer and f0, f1, . . . , fM be functions in F . Let d(\u00b7, \u00b7) : F \u00d7 F \u2192 R be a semi-distance and assume that:\n1. d(fi, fj) \u2265 2s > 0, for all 0 \u2264 i < j \u2264 M , 2. 1M \u2211M j=1 KL(Pi||P0) \u2264 a logM ,\nwhere the Kullback-Leibler divergence KL(Pi||P0) := \u222b log dPidP0 dPi is assumed to be well-defined (i.e., P0 is a dominating measure) and 0 < a < 1/8 . Then\ninf f\u0302 sup f\u2208F P(d(f\u0302 , f) \u2265 s) \u2265 inf f\u0302 max f\u2208{f0,...,fM}\nP(d(f\u0302 , f) \u2265 s) \u2265 \u221a M\n1+ \u221a M\n( 1\u2212 2a\u2212 2 \u221a a\nlogM\n) > 0 ,\nwhere the infimum is taken over all possible estimators based on a sample from Pf .\nWe are concerned with the functions in the class F := F\u03c4,L,B. The volume of B will affect only constant factors in our bounds, so we will simply denote the class of functions by F and refer explicitly to B only when necessary. Let xf := argminx f(x), for all f \u2208 F . The semi-distance we use is d(f, g) := \u2016xf \u2212 xg||, for all f, g \u2208 F . Note that each point in B can be specified by one of many f \u2208 F . So the problem of selecting an f is equivalent to selecting a point x \u2208 B. Indeed, the semi-distance defines a collection of equivalence classes in F (i.e., all functions having a minimum at x \u2208 B are equivalent). For every f \u2208 F we have infg\u2208F f(xg) = infx\u2208B f(x), which is a useful identity to keep in mind.\nWe now construct the functions f0, f1, . . . , fM that will be used for our proofs. Let \u2126 = {\u22121, 1}n so that each \u03c9 \u2208 \u2126 is a vertex of the d-dimensional hypercube. Let V \u2282 \u2126 with cardinality |V| \u2265 2n/8 such that for all \u03c9 6= \u03c9\u2032 \u2208 V , we have \u03c1(\u03c9, \u03c9\u2032) \u2265 n/8 where \u03c1(\u00b7, \u00b7) is the Hamming distance. It is known that such a set exists by the Varshamov-Gilbert bound [20, Lemma 2.9]. Denote the elements\nof V by \u03c90, \u03c91, . . . , \u03c9M . Next we state some elementary bounds on the functions that will be used in our analysis. Lemma 1. For \u01eb > 0 define the set B \u2282 Rn to be the \u2113\u221e ball of radius \u01eb and define the functions on B: fi(x) := \u03c42 ||x \u2212 \u01eb\u03c9i||2, for i = 0, . . . ,M , \u03c9i \u2208 V , and xi := argminx fi(x) = \u01eb\u03c9i. Then for all 0 \u2264 i < j \u2264 M and x \u2208 B the functions fi(x) satisfy\n1. fi is strongly convex-\u03c4 with Lipschitz-L gradients and xi \u2208 B 2. ||xi \u2212 xj || \u2265 \u01eb \u221a n 2 3. |fi(x) \u2212 fj(x)| \u2264 2\u03c4n\u01eb2 .\nWe are now ready to prove Theorems 1 and 3. Each proof uses the functions f0, . . . , fM a bit differently, and since the noise model is also different in each case, the KL divergence is bounded differently in each proof. We use the fact that if X and Y are random variables distributed according to Bernoulli distributions PX and PY with parameters 1/2 + \u00b5 and 1/2\u2212 \u00b5, then KL(PX ||PY ) \u2264 4\u00b52/(1/2\u2212 \u00b5). Also, if X \u223c N (\u00b5X , \u03c32) =: PX and Y \u223c N (\u00b5Y , \u03c32) =: Py then KL(PX ||PY ) = 1 2\u03c32 ||\u00b5X \u2212 \u00b5Y ||2."}, {"heading": "4.1 Proof of Theorem 1", "text": "First we will obtain the bound for the case \u03ba > 1. Let the comparison oracle satisfy\nP (Cfi (x, y) = sign{fi(y)\u2212 fi(x)}) = 1\n2 + min\n{ \u00b5|fi(y)\u2212 fi(x)|\u03ba\u22121, \u03b40 } .\nIn words, Cfi(x, y) is correct with probability as large as the right-hand-side of above and is monotonic increasing in fi(y) \u2212 fi(x). Let {xk, yk}Tk=1 be a sequence of T pairs in B and let {Cfi(xk, yk)}Tk=1 be the corresponding sequence of noisy comparisons. We allow the sequence {xk, yk}Tk=1 to be generated in any way subject to the Markovian assumption that Cfi(xk, yk) given (xk, yk) is conditionally independent of {xi, yi}i<k. For i = 0, . . . ,M , and \u2113 = 1, . . . , T let Pi,\u2113 denote the joint probability distribution of {xk, yk, Cfi(xk, yk)}\u2113k=1, let Qi,\u2113 denote the conditional distribution of Cfi (x\u2113, y\u2113) given (x\u2113, y\u2113), and let S\u2113 denote the conditional distribution of (x\u2113, y\u2113) given {xk, yk, Cfi(xk, yk)}\u2113\u22121k=1. Note that S\u2113 is only a function of the underlying optimization algorithm and does not depend on i.\nKL(Pi,T ||Pj,T ) = EPi,T [ log\nPi,T Pj,T\n] = EPi,T [ log \u220fT \u2113=1Qi,\u2113S\u2113\u220fT \u2113=1 Qj,\u2113S\u2113 ] = EPi,T [ log \u220fT \u2113=1 Qi,\u2113\u220fT \u2113=1Qj,\u2113 ]\n=\nT\u2211\n\u2113=1\nEPi,T [ EPi,T [ log\nQi,\u2113 Qj,\u2113\n\u2223\u2223\u2223\u2223{xk, yk}Tk=1 ]]\n\u2264 T sup x1,y1\u2208B EPi,1\n[ EPi,1 [ log\nQi,1 Qj,1\n\u2223\u2223\u2223\u2223x1, y1 ]]\nBy the second claim of Lemma 1, |fi(x) \u2212 fj(x)| \u2264 2\u03c4n\u01eb2, and therefore the bound above is less than or equal to the KL divergence between the Bernoulli distributions with parameters 12 \u00b1 \u00b5 ( 2\u03c4n\u01eb2 )(\u03ba\u22121) , yielding the bound\nKL(Pi,T |Pj,T ) \u2264 4T\u00b52\n( 2\u03c4n\u01eb2 )2(\u03ba\u22121)\n1/2\u2212 \u00b5 (2\u03c4n\u01eb2)(\u03ba\u22121) \u2264 16T\u00b52\n( 2\u03c4n\u01eb2 )2(\u03ba\u22121)\nprovided \u01eb is sufficiently small. We also assume \u01eb (or, equivalently, B) is sufficiently small so that |fi(x) \u2212 fj(x)|\u03ba\u22121 \u2264 \u03b40. We are now ready to apply Theorem 4. Recalling that M \u2265 2n/8, we want to choose \u01eb such that\nKL(Pi,T |Pj,T ) \u2264 16T\u00b52 ( 2\u03c4n\u01eb2 )2(\u03ba\u22121) \u2264 an 8 log(2) \u2264 a logM\nwith an a small enough so that we can apply the theorem. By setting a = 1/16 and equating the two sides of the equation we have \u01eb = \u01ebT := 12\u221an ( 2 \u03c4 )1/2 ( n log(2) 2048\u00b52T ) 1 4(\u03ba\u22121) (note that this also implies a sequence of sets BT by the definition of the functions in Lemma 1). Thus, the semi-distance satisfies\nd(fj , fi) = ||xj \u2212 xi|| \u2265 \u221a n/2\u01ebT \u2265 1\n2 \u221a 2\n( 2\n\u03c4\n)1/2 ( n log(2)\n2048\u00b52T\n) 1 4(\u03ba\u22121)\n=: 2sT .\nApplying Theorem 4 we have\ninf f\u0302 sup f\u2208F P(\u2016xf\u0302 \u2212 xf\u2016 \u2265 sT ) \u2265 inf f\u0302 max i\u2208{0,...,M} P(\u2016xf\u0302 \u2212 xi\u2016 \u2265 sT ) = inf f\u0302 max i\u2208{0,...,M} P(d(f\u0302 , fi) \u2265 sT )\n\u2265 \u221a M\n1+ \u221a M\n( 1\u2212 2a\u2212 2 \u221a a\nlogM\n) > 1/7 ,\nwhere the final inequality holds since M \u2265 2 and a = 1/16. Strong convexity implies that f(x) \u2212 f(xf ) \u2265 \u03c42 ||x\u2212 xf ||2 for all f \u2208 F and x \u2208 B. Therefore\ninf f\u0302 sup f\u2208F P\n( f(xf\u0302 )\u2212 f(xf ) \u2265 \u03c4\n2 s2T\n) \u2265 inf\nf\u0302 max i\u2208{0,...,M} P\n( fi(xf\u0302 )\u2212 fi(xi) \u2265 \u03c4\n2 s2T\n)\n\u2265 inf f\u0302 max i\u2208{0,...,M} P (\u03c4 2 \u2016xf\u0302 \u2212 xi\u20162 \u2265 \u03c4 2 s2T )\n= inf f\u0302 max i\u2208{0,...,M} P\n( \u2016xf\u0302 \u2212 xi\u2016 \u2265 sT ) > 1/7 .\nFinally, applying Markov\u2019s inequality we have\ninf f\u0302 sup f\u2208F E\n[ f(xf\u0302 )\u2212 f(xf ) ] \u2265 1\n7\n( 1\n32\n)( n log(2)\n2048\u00b52T .\n) 1 2(\u03ba\u22121)"}, {"heading": "4.2 Proof of Theorem 1 for \u03ba = 1", "text": "To handle the case when \u03ba = 1 we use functions of the same form, but the construction is slightly different. Let \u2113 be a positive integer and let M = \u2113n. Let {\u03bei}Mi=1 be a set of uniformly space points in B which we define to be the unit cube in Rn, so that \u2016\u03bei \u2212 \u03bej\u2016 \u2265 \u2113\u22121 for all i 6= j. Define fi(x) := \u03c4 2 ||x \u2212 \u03bei||2, i = 1, . . . ,M . Let s := 12\u2113 so that d(fi, fj) := ||x\u2217i \u2212 x\u2217j || \u2265 2s. Because \u03ba = 1, we have P (Cfi(x, y) = sign{fi(y)\u2212 fi(x)}) \u2265 \u00b5 for some \u00b5 > 0, all i \u2208 {1, . . . ,M}, and all x, y \u2208 B. We bound KL(Pi,T ||Pj,T ) in exactly the same way as we bounded it in Section 4.1 except that now we have Cfi(xk, yk) \u223c Bernoulli(12 + \u00b5) and Cfj (xk, yk) \u223c Bernoulli(12 \u2212 \u00b5). It then follows that if we wish to apply the theorem, we want to choose s so that\nKL(Pi,T |Pj,T ) \u2264 2T\u00b52/(1/2\u2212 \u00b5) \u2264 a logM = an log ( 1 2s )\nfor some a < 1/8. Using the same sequence of steps as in Section 4.1 we have\ninf f\u0302 sup f\u2208F E\n[ f(xf\u0302 )\u2212 f(xf ) ] \u2265 1\n7\n\u03c4\n2\n( 1\n2\n)2 exp { \u2212 128T\u00b5 2\nn(1/2\u2212 \u00b5)\n} ."}, {"heading": "4.3 Proof of Theorem 3", "text": "Let fi for all i = 0, . . . ,M be the functions considered in Lemma 1. Recall that the evaluation oracle is defined to be Ef (x) := f(x)+w, where w is a random variable (independent of all other random variables under consideration) with E[w] = 0 and E[w2] = \u03c32 > 0. Let {xk}nk=1 be a sequence of points in B \u2282 Rn and let {Ef (xk)}Tk=1 denote the corresponding sequence of noisy evaluations of f \u2208 F . For \u2113 = 1, . . . , T let Pi,\u2113 denote the joint probability distribution of {xk, Efi(xk)}\u2113k=1, let Qi,\u2113 denote the conditional distribution of Efi (xk) given xk, and let S\u2113 denote the conditional distribution of x\u2113 given {xk, Ef (xk)}\u2113\u22121k=1. S\u2113 is a function of the underlying optimization algorithm and does not depend on i. We can now bound the KL divergence between any two hypotheses as in Section 4.1:\nKL(Pi,T ||Pj,T ) \u2264 T sup x1\u2208B EPi,1\n[ EPi,1 [ log\nQi,1 Qj,1\n\u2223\u2223\u2223\u2223x1 ]] .\nTo compute a bound, let us assume that w is Gaussian distributed. Then\nKL(Pi,T ||Pj,T ) \u2264 T sup z\u2208B\nKL ( N (fi(z), \u03c32)||N (fj(z), \u03c32) )\n= T\n2\u03c32 sup z\u2208B\n|fi(z)\u2212 fj(z)|2 \u2264 T 2\u03c32 ( 2\u03c4n\u01eb2 )2\nby the third claim of Lemma 1. We then repeat the same procedure as in Section 4.1 to attain\ninf f\u0302 sup f\u2208F E\n[ f(xf\u0302 )\u2212 f(xf ) ] \u2265 1\n7\n( 1\n32\n)( n\u03c32 log(2)\n64T\n) 1 2\n."}, {"heading": "5 Upper bounds", "text": "The algorithm that achieves the upper bound using a pairwise comparison oracle is a combination of standard techniques and methods from the convex optimization and statistical learning literature. The algorithm is explained in full detail in Appendix B, and is summarized as follows. At each iteration the algorithm picks a coordinate uniformly at random from the n possible dimensions and then performs an approximate line search. By exploiting the fact that the function is strongly convex with Lipschitz gradients, one guarantees using standard arguments that the approximate line search makes a sufficient decrease in the objective function value in expectation [23, Ch.9.3]. If the pairwise comparison oracle made no errors then the approximate line search is accomplished by a binary-search-like scheme, essentially a golden section line-search algorithm [24]. However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25] (a similar technique was also implemented for the bandit setting of derivate-free optimization [8]). Because the analysis of each component is either known or elementary, we only sketch the proof here and leave the details to the supplementary materials."}, {"heading": "5.1 Coordinate descent", "text": "Given a candidate solution xk after k \u2265 0 iterations, the algorithm defines a search direction dk = ei where i is chosen uniformly at random from the possible n dimensions and ei is a vector of all zeros except for a one in the ith coordinate. We note that while we only analyze the case where the search direction dk is a coordinate direction, an analysis with the same result can be obtained with dk chosen uniformly from the unit sphere. Given dk, a line search is then performed to find an \u03b1k \u2208 R such that f(xk+1)\u2212 f(xk) is sufficiently small where xk+1 = xk +\u03b1kdk. In fact, as we will see in the next section, for some input parameter \u03b7 > 0, the line search is guaranteed to return an \u03b1k such that |\u03b1k \u2212 \u03b1\u2217| \u2264 \u03b7 where \u03b1\u2217 = min\u03b1\u2208R f(xk + dk\u03b1\u2217). Using the fact that the gradients of f are Lipschitz (L) we have\nf(xk + \u03b1kdk)\u2212 f(xk + \u03b1\u2217dk) \u2264 L 2 ||(\u03b1k \u2212 \u03b1\u2217)dk||2 = L 2 |\u03b1k \u2212 \u03b1\u2217|2 \u2264 L 2 \u03b72.\nIf we define \u03b1\u0302k = \u2212 \u3008\u2207f(xk),dk\u3009L then we have\nf(xk + \u03b1kdk)\u2212 f(xk) \u2264 f(xk + \u03b1\u2217dk)\u2212 f(xk) + L\n2 \u03b72\n\u2264 f(xk + \u03b1\u0302kdk)\u2212 f(xk) + L 2 \u03b72 \u2264 \u2212\u3008\u2207f(xk), dk\u3009 2 2L + L 2 \u03b72\nwhere the last line follows from applying the fact that the gradients are Lipschitz (L). Arranging the bound and taking the expectation with respect to dk we get\nE [f(xk+1)\u2212 f(x\u2217)]\u2212 L2 \u03b72 \u2264 E [f(xk)\u2212 f(x\u2217)]\u2212 E[||\u2207f(xk)||2] 2nL \u2264 E [f(xk)\u2212 f(x\u2217)] ( 1\u2212 \u03c44nL )\nwhere the second inequality follows from the fact that f is strongly convex (\u03c4). If we define \u03c1k := E [f(xk)\u2212 f(x\u2217)] then we equivalently have\n\u03c1k+1 \u2212 2nL2\u03b72\n\u03c4 \u2264\n( 1\u2212 \u03c4\n4nL\n)( \u03c1k \u2212 2nL2\u03b72\n\u03c4\n) \u2264 ( 1\u2212 \u03c4\n4nL\n)k ( \u03c10 \u2212 2nL2\u03b72\n\u03c4\n)\nwhich leads to the following result.\nTheorem 5. Let f \u2208 F\u03c4,L,B with B = Rn. For any \u03b7 > 0 assume the line search returns an \u03b1k that is within \u03b7 of the optimal after at most T\u2113(\u03b7) queries from the pairwise comparison oracle. If xK is an estimate of x\u2217 = argminx f(x) after requesting no more than K pairwise comparisons, then\nsup f\nE[f(xK)\u2212 f(x\u2217)] \u2264 4nL2\u03b72 \u03c4 whenever K \u2265 4nL \u03c4 log ( f(x0)\u2212 f(x\u2217) \u03b722nL2/\u03c4 ) T\u2113(\u03b7)\nwhere the expectation is with respect to the random choice of dk at each iteration. This implies that if we wish supf E[f(xK) \u2212 f(x\u2217)] \u2264 \u01eb it suffices to take \u03b7 = \u221a \u01eb\u03c4 4nL2 so that at\nmost 4nL\u03c4 log ( f(x0)\u2212f(x\u2217) \u01eb/2 ) T\u2113 (\u221a \u01eb\u03c4 4nL2 ) pairwise comparisons are requested."}, {"heading": "5.2 Line search", "text": "This section is concerned with minimizing a function f(xk+\u03b1kdk) over some \u03b1k \u2208 R. In particular, we wish to find an \u03b1k \u2208 R such that |\u03b1k\u2212\u03b1\u2217| \u2264 \u03b7 where \u03b1\u2217 = min\u03b1\u2208R f(xk+dk\u03b1\u2217). First assume that the function comparison oracle makes no errors. The line search operates by maintaining a pair of boundary points\u03b1+, \u03b1\u2212 such that if at some iterate we have\u03b1\u2217 \u2208 [\u03b1\u2212, \u03b1+] then at the next iterate, we are guaranteed that \u03b1\u2217 is still contained inside the boundary points but |\u03b1+\u2212\u03b1\u2212| \u2190 12 |\u03b1+\u2212\u03b1\u2212|. An initial set of boundary points \u03b1+ > 0 and \u03b1\u2212 < 0 are found using simple binary search. Thus, regardless of how far away or close \u03b1\u2217 is, we converge to it exponentially fast. Exploiting the fact that f is strongly convex (\u03c4) with Lipschitz (L) gradients we can bound how far away or close \u03b1\u2217 is from our initial iterate.\nTheorem 6. Let f \u2208 F\u03c4,L,B with B = Rn and let Cf be a function comparison oracle that makes no errors. Let x \u2208 Rn be an initial position and let d \u2208 Rn be a search direction with ||d|| = 1. If \u03b1K is an estimate of \u03b1\u2217 = argmin\u03b1 f(x+ d\u03b1) that is output from the line search after requesting no more than K pairwise comparisons, then for any \u03b7 > 0\n|\u03b1K \u2212 \u03b1\u2217| \u2264 \u03b7 whenever K \u2265 2 log2 ( 256L (f(x)\u2212 f(x+ d\u03b1\u2217))\n\u03c42\u03b72\n) ."}, {"heading": "5.3 Making the line search robust to errors", "text": "Now assume that the responses from the pairwise comparison oracle are only probably correct in accordance with the model introduced above. Essentially, the robust procedure runs the line search as if the oracle made no errors except that each time a comparison is needed, the oracle is repeatedly queried until we can be confident about the true direction of the comparison. This strategy applied to active learning is well known because of its simplicity and its ability to adapt to unknown noise conditions [25]. However, we mention that when used in this way, this sampling procedure is known to be sub-optimal so in practice, one may want to implement a more efficient approach like that of [21]. Nevertheless, we have the following lemma.\nLemma 2. [25] For any x, y \u2208 B with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, with probability at least 1 \u2212 \u03b4 the coin-tossing algorithm of [25] correctly identifies the sign of E [Cf (x, y)] and requests no more than log(2/\u03b4)4|1/2\u2212p|2 log2 ( log(2/\u03b4) 4|1/2\u2212p|2 ) pairwise comparisons.\nIt would be convenient if we could simply apply the result of Lemma 2 to our line search procedure. Unfortunately, if we do this there is no guarantee that |f(y) \u2212 f(x)| is bounded below so for the case when \u03ba > 1, it would be impossible to lower bound |1/2 \u2212 p| in the lemma. To account for this, we will sample at multiple locations per iteration as opposed to just two in the noiseless algorithm to ensure that we can always lower bound |1/2\u2212 p|. Intuitively, strong convexity ensures that f cannot be arbitrarily flat so for any three equally spaced points x, y, z on the line dk, if f(x) is equal to f(y), then it follows that the absolute difference between f(x) and f(z) must be bounded away from zero. Applying this idea and union bounding over the total number of times one must call the coin-tossing algorithm, one finds that with probability at least 1 \u2212 \u03b4, the total number of calls to the pairwise comparison oracle over the course of the whole algorithm does not exceed O\u0303 (\nnL \u03c4 ( n \u01eb )2(\u03ba\u22121) log2 ( f(x0)\u2212f(x\u2217) \u01eb ) log(n/\u03b4) ) . By finding a T > 0 that satisfies this\nbound for any \u01eb we see that this is equivalent to a rate of O ( n log(n/\u03b4) ( n T ) 1 2(\u03ba\u22121) ) for \u03ba > 1 and O ( exp { \u2212c \u221a T\nn log(n/\u03b4)\n}) for \u03ba = 1, ignoring polylog factors."}, {"heading": "6 Conclusion", "text": "This paper presented lower bounds on the performance of derivative-free optimization for (i) an oracle that provides noisy function evaluations and (ii) an oracle that provides probably correct boolean comparisons between function evaluations. Our results were proven for the class of strongly convex functions but because this class is a subset of all, possibly non-convex functions, our lower bounds hold for much larger classes as well. Under both oracle models we showed that the expected error decays like \u2126 ( (n/T )1/2 ) . Furthermore, for the class of strongly convex functions with Lipschitz gradients, we proposed an algorithm that achieves a rate of O\u0303 ( n(n/T )1/2 ) for both oracle models which shows that the lower bounds are tight with respect to the dependence on the number of iterations T and no more than a factor of n off in terms of the dimension.\nA number of open questions still remain. In particular, one would like to resolve the gap between the lower and upper bounds with respect to the dependence on the dimension. Due to real world constraints, it is also desirable to extend the pairwise comparison algorithm to operate under the conditions of constrained optimization where B is a convex, proper subset of Rd. Also, while the analysis of our algorithm relies heavily on the assumption that the function is strongly convex with Lipschitz gradients, it is unclear whether these assumptions are necessary to achieve the same rates of convergence. Developing a practical algorithm that achieves our lower bounds and does not suffer from these limiting assumptions would be a significant contribution."}, {"heading": "A Bounds on (\u03ba, \u00b5, \u03b40) for some distributions", "text": "In this section we relate the function evaluation oracle to the function comparison oracle for some common distributions. That is, if Ef (x) = f(x) + w for some random variable w, we lower bound the probability \u03b7(y, x) := P(sign{Ef (y) \u2212 Ef (x)} = sign{f(y) \u2212 f(x)}) in terms of the parameterization of (1).\nLemma 3. Let w be a Gaussian random variable with mean zero and variance \u03c32. Then \u03b7(y, x) \u2265 12 +min { 1\u221a 2\u03c0e , 1\u221a 4\u03c0\u03c32e |f(y)\u2212 f(x)| } .\nProof. Notice that \u03b7(y, x) = P(Z + |f(y)\u2212 f(x)|/ \u221a 2\u03c32 \u2265 0) where Z is a standard normal. The result follows by lower bounding the density of Z by 1\u221a 2\u03c0e\n1{|Z| \u2264 1} and integrating where 1{\u00b7} is equal to one when its arguments are true and zero otherwise.\nWe say w is a 2-sided gamma distributed random variable if its density is given by \u03b2\u03b1\n2\u0393(\u03b1) |x|\u03b1\u22121e\u2212\u03b2|x| for x \u2208 [\u2212\u221e,\u221e] and \u03b1, \u03b2 > 0. Note that this distribution is unimodal only for \u03b1 \u2208 (0, 1] and is equal to a Laplace distribution for \u03b1 = 1. This distribution has variance \u03c32 = \u03b1/\u03b22.\nLemma 4. Let w be a 2-sided gamma distributed random variable with parameters \u03b1 \u2208 (0, 1] and \u03b2 > 0. Then \u03b7(y, x) \u2265 12 +min { 1 4\u03b12\u0393(\u03b1)2 ( \u03b1 e )2\u03b1 , (\u03b2/2e) 2\u03b1 4\u03b12\u0393(\u03b1)2 |f(y)\u2212 f(x)|2\u03b1 } .\nProof. Let Ef (y) = f(y) + w and Ef (x) = f(x) + w\u2032 where w and w\u2032 are i.i.d. 2-sided gamma distributed random variables. If we lower bound e\u2212\u03b2|x| with e\u2212\u03b11{|x| \u2264 \u03b1/\u03b2} and integrate we find that P(\u2212t/2 \u2264 w \u2264 0) \u2265 min { 1\n2\u03b1\u0393(\u03b1) ( \u03b1 e )\u03b1 , (\u03b2/e) \u03b1 2\u03b1\u0393(\u03b1) (t/2) \u03b1 } . And by the symmetry and\nindependence of w and w\u2032 we have P(\u2212t \u2264 w \u2212 w\u2032) \u2265 12 + P(\u2212t/2 \u2264 w \u2264 0)P(\u2212t/2 \u2264 w \u2264 0).\nWhile the bound in the lemma immediately above can be shown to be loose, these two lemmas are sufficient to show that the entire range of \u03ba \u2208 (1, 2] is possible."}, {"heading": "B Upper Bounds - Extended", "text": "The algorithm that achieves the upper bound using a pairwise comparison oracle is a combination of a few standard techniques and methods pulled from the convex optimization and statistical learning literature. The algorithm can be summarized as follows. At each iteration the algorithm picks a coordinate uniformly at random from the n possible dimensions and then performs an approximate line search. By exploiting the fact that the function is strongly convex with Lipschitz gradients, one guarantees using standard arguments that the approximate line search makes a sufficient decrease in the objective function value in expectation [23, Ch.9.3]. If the pairwise comparison oracle made no errors then the approximate line search is accomplished by a binary-search-like scheme that is known in the literature as the golden section line-search algorithm [24]. However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25].\nB.1 Coordinate descent algorithm\nTheorem 7. Let f \u2208 F\u03c4,L,B with B = Rn. For any \u03b7 > 0 assume the line search in the algorithm of Figure 1 requires at most T\u2113(\u03b7) queries from the pairwise comparison oracle. If xK is an estimate of x\u2217 = argminx f(x) after requesting no more than K pairwise comparisons, then\nsup f\nE[f(xK)\u2212 f(x\u2217)] \u2264 4nL2\u03b72 \u03c4 whenever K \u2265 4nL \u03c4 log ( f(x0)\u2212 f(x\u2217) \u03b722nL2/\u03c4 ) T\u2113(\u03b7)\nwhere the expectation is with respect to the random choice of dk at each iteration.\nProof. First note that ||dk|| = 1 for all k with probability 1. Because the gradients of f are Lipschitz (L) we have from Taylor\u2019s theorem\nf(xk+1) \u2264 f(xk) + \u3008\u2207f(xk), \u03b1kdk\u3009+ \u03b12kL\n2 .\nNote that the right-hand-side is convex in \u03b1k and is minimized by\n\u03b1\u0302k = \u2212 \u3008\u2207f(xk), dk\u3009\nL .\nHowever, recalling how \u03b1k is chosen, if \u03b1\u2217 = argmin\u03b1 f(xk + \u03b1dk) then we have\nf(xk + \u03b1kdk)\u2212 f(xk + \u03b1\u2217dk) \u2264 L 2 ||(\u03b1k \u2212 \u03b1\u2217)dk||2 = L 2 |\u03b1k \u2212 \u03b1\u2217|2 \u2264 L 2 \u03b72.\nThis implies\nf(xk + \u03b1kdk)\u2212 f(xk) \u2264 f(xk + \u03b1\u2217dk)\u2212 f(xk) + L\n2 \u03b72\n\u2264 f(xk + \u03b1\u0302kdk)\u2212 f(xk) + L\n2 \u03b72\n\u2264 \u2212\u3008\u2207f(xk), dk\u3009 2\n2L +\nL 2 \u03b72.\nTaking the expectation with respect to dk, we have\nE [f(xk+1)] \u2264 E [f(xk)]\u2212 E [ \u3008\u2207f(xk), dk\u30092\n2L\n] + L\n2 \u03b72\n= E [f(xk)]\u2212 E [ E [ \u3008\u2207f(xk), dk\u30092 2L \u2223\u2223\u2223\u2223d0, . . . , dk\u22121 ]] + L 2 \u03b72 = E [f(xk)]\u2212 E [ ||\u2207f(xk)||2\n2nL\n] + L\n2 \u03b72\nwhere we applied the law of iterated expectation. Let x\u2217 = argminx f(x) and note that x\u2217 is a unique minimizer by strong convexity (\u03c4). Using the previous calculation we have\nE [f(xk+1)\u2212 f(x\u2217)]\u2212 L2 \u03b72 \u2264 E [f(xk)\u2212 f(x\u2217)]\u2212 E[||\u2207f(xk)||2] 2nL \u2264 E [f(xk)\u2212 f(x\u2217)] ( 1\u2212 \u03c44nL ) where the second inequality follows from\n(f(xk)\u2212 f(x\u2217))2 \u2264 (\u3008\u2207f(xk), xk \u2212 x\u2217\u3009)2\n\u2264||\u2207f(xk)||2||xk \u2212 x\u2217||2 \u2264 ||\u2207f(xk)||2 (\u03c4 2 )\u22121 (f(xk)\u2212 f(x\u2217)) .\nIf we define \u03c1k := E [f(xk)\u2212 f(x\u2217)] then we equivalently have\n\u03c1k+1 \u2212 2nL2\u03b72\n\u03c4 \u2264\n( 1\u2212 \u03c4\n4nL\n)( \u03c1k \u2212 2nL2\u03b72\n\u03c4\n) \u2264 ( 1\u2212 \u03c4\n4nL\n)k ( \u03c10 \u2212 2nL2\u03b72\n\u03c4\n)\nwhich completes the proof.\nThis implies that if we wish supf E[f(xK) \u2212 f(x\u2217)] \u2264 \u01eb it suffices to take \u03b7 = \u221a \u01eb\u03c4 4nL2 so that at\nmost 4nL\u03c4 log ( f(x0)\u2212f(x\u2217) \u01eb/2 ) T\u2113 (\u221a \u01eb\u03c4 4nL2 ) pairwise comparisons are requested.\nB.2 Line search\nThis section is concerned with minimizing a function f(xk + \u03b1dk) over some \u03b1 \u2208 R. Because we are minimizing over a single variable, \u03b1, we will restart the indexing at 0 such that the line search algorithm produces a sequence \u03b10, \u03b11, . . . , \u03b1K\u2032 . This indexing should not be confused with the indexing of the iterates x1, x2, . . . , xK . We will first present an algorithm that assumes the pairwise comparison oracle makes no errors and then extend the algorithm to account for the noise model introduced in Section 2.\nConsider the algorithm of Figure 2. At each iteration, one is guaranteed to eliminate at least 1/2 the search space at each iteration such that at least 1/4 the search space is discarded for every pairwise comparison that is requested. However, with a slight modification to the algorithm, one can guarantee a greater fraction of removal (see the golden section line-search algorithm). We use this sub-optimal version for simplicity because it will help provide intuition for how the robust version of the algorithm works.\nTheorem 8. Let f \u2208 F\u03c4,L,B with B = Rn and let Cf be a function comparison oracle that makes no errors. Let x \u2208 Rn be an initial position and let d \u2208 Rn be a search direction with ||d|| = 1. If \u03b1K is an estimate of \u03b1\u2217 = argmin\u03b1 f(x + d\u03b1) that is output from the algorithm of Figure 2 after requesting no more than K pairwise comparisons, then for any \u03b7 > 0\n|\u03b1K \u2212 \u03b1\u2217| \u2264 \u03b7 whenever K \u2265 2 log2 ( 256L (f(x)\u2212 f(x+ d\u03b1\u2217))\n\u03c42\u03b72\n) .\nProof. First note that if \u03b1K is output from the algorithm, we have 12 |\u03b1K \u2212\u03b1\u2217| \u2264 |\u03b1+K \u2212\u03b1\u2212K | \u2264 12\u03b7, as desired.\nWe will handle the cases when |\u03b1\u2217| is greater than one and less than one separately. First assume that |\u03b1\u2217| \u2265 1. Using the fact that f is strongly convex (\u03c4), it is straightforward to show that immediately\nafter exiting the initial while loops, (i) at most 2+ 12 log2 ( 8 \u03c4 (f(x)\u2212 f(x+ d\u03b1\u2217)) ) pairwise comparisons were requested, (ii) \u03b1\u2217 \u2208 [\u03b1\u2212k , \u03b1+k ], and (iii) |\u03b1+k \u2212\u03b1\u2212k | \u2264 ( 8 \u03c4 (f(x)\u2212 f(x+ d\u03b1\u2217)) )1/2 . We also have that \u03b1\u2217 \u2208 [\u03b1\u2212k+1, \u03b1+k+1] if \u03b1\u2217 \u2208 [\u03b1\u2212k , \u03b1+k ] for all k. Thus, it follows that\n|\u03b1+k+l \u2212 \u03b1\u2212k+l| = 2\u2212l|\u03b1+k \u2212 \u03b1\u2212k | \u2264 2\u2212l ( 8\n\u03c4 (f(x)\u2212 f(x+ d\u03b1\u2217))\n)1/2 .\nTo make the right-hand-side less than or equal to \u03b7/2, set l = log2\n( ( 8\u03c4 (f(x)\u2212f(x+d\u03b1 \u2217)))1/2\n\u03b7/2\n) .\nThis brings the total number of pairwise comparison requests to no more than\n2 log2\n( 32(f(x)\u2212f(x+d\u03b1\u2217))\n\u03c4\u03b7\n) .\nNow assume that |\u03b1\u2217| \u2264 1. A straightforward calculation shows that the while loops will terminate after requesting at most 2 + 12 log2 ( L \u03c4 ) pairwise comparisons. And immediately after exiting the while loops we have |\u03b1+k \u2212 \u03b1\u2212k | \u2264 2. It follows by the same arguments of above that if we want |\u03b1+k+l \u2212 \u03b1\u2212k+l| \u2264 \u03b7/2 it suffices to set l = log2 ( 4 \u03b7 ) . This brings the total number of pairwise comparison requests to no more than 2 log2 ( 8L \u03c4\u03b7 ) . For sufficiently small \u03b7 both cases are positive and the result follows from adding the two.\nThis implies that if the function comparison oracle makes no errors and it is given an iterate xk and direction dk then T\u2113 (\u221a \u01eb\u03c4 4nL2 ) \u2264 2 log2 ( 2048nL2(f(xk)\u2212f(xk+dk \u03b1\u2217)) \u03c43\u01eb ) which brings the total number of pairwise comparisons requested to at most 8nL \u03c4 log ( f(x0)\u2212f(x\u2217) \u01eb/2 ) log2 ( 2048nL2 maxk(f(xk)\u2212f(xk+dk \u03b1\u2217)) \u03c43\u01eb ) .\nB.3 Proof of Theorem 2\nWe now introduce a line search algorithm that is robust to a function comparison oracle that makes errors. Essentially, the algorithm consists of nothing more than repeatedly querying the same random pairwise comparison. This strategy applied to active learning is well known because of its simplicity and its ability to adapt to unknown noise conditions [25]. However, we mention that when used in this way, this sampling procedure is known to be sub-optimal so in practice, one may want to implement a more efficient approach like that of [21]. Consider the subroutine of Figure 3.\nLemma 5. [25] For any x, y \u2208 Rn with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, then with probability at least 1\u2212\u03b4 the algorithm of Figure 3 correctly identifies the sign of E [Cf (x, y)] and requests no more than\nlog(2/\u03b4) 4|1/2\u2212 p|2 log2 ( log(2/\u03b4) 4|1/2\u2212 p|2 )\npairwise comparisons.\nIt would be convenient if we could simply apply the result of Lemma 2 to the algorithm of Figure 2. Unfortunately, if we do this there is no guarantee that |f(y)\u2212f(x)| is bounded below so for the case when \u03ba > 1, it would be impossible to lower bound |1/2\u2212 p| in the lemma. To account for this, we will sample at four points per iteration as opposed to just two in the noiseless algorithm to ensure that we can always lower bound |1/2 \u2212 p|. We will see that the algorithm and analysis naturally adapts to when \u03ba = 1 or \u03ba > 1.\nConsider the following modification to the algorithm of Figure 2. We discuss the sampling process that takes place in [\u03b1k, \u03b1 + k ] but it is understood that the same process is repeated symmetrically in [\u03b1\u2212k , \u03b1k]. We begin with the first two while loops. Instead of repeatedly samplingCf (x, x+d\u03b1 + k ) we will have two sampling procedures running in parallel that repeatedly compare \u03b1k to \u03b1 + k and \u03b1k to 2\u03b1+k . As soon as the repeated sampling procedure terminates for one of them we terminate the second sampling strategy and proceed with what the noiseless algorithm would do with \u03b1+k assigned to be the sampling location that finished first. Once we\u2019re out of the initial while loops, instead of comparing \u03b1k to 12 (\u03b1k + \u03b1 + k ) repeatedly, we will repeatedly compare \u03b1k to 1 3 (\u03b1k + \u03b1 + k ) and \u03b1k to 2 3 (\u03b1k + \u03b1 + k ). Again, we will treat the location that finishes its sampling first as 1 2 (\u03b1k + \u03b1 + k ) in the noiseless algorithm.\nIf we perform this procedure every iteration, then at each iteration we are guaranteed to remove at least 1/3 the search space, as opposed to 1/2 in the noiseless case, so we realize that the number of iterations of the robust algorithm is within a constant factor of the number of iterations of the noiseless algorithm. However, unlike the noiseless case where at most two pairwise comparisons were requested at each iteration, we must now apply Lemma ?? to determine the number of pairwise comparisons that are requested per iteration.\nIntuitively, the repeated sampling procedure requests the most pairwise comparisons when the distance between the two function evaluations being compared smallest. This corresponds to when the distance between probe points is smallest, i.e. when \u03b7/2 \u2264 |\u03b1k \u2212 \u03b1\u2217| \u2264 \u03b7. By considering this worst case, we can bound the number of pairwise comparisons that are requested at any iteration. By strong convexity (\u03c4) we find through a straightforward calculation that max { |f(x+ d\u03b1k)\u2212 f(x+ d 23 (\u03b1k + \u03b1+k ))|, |f(x + d\u03b1k)\u2212 f(x+ d 13 (\u03b1k + \u03b1+k ))| } \u2265 \u03c418\u03b72 for all k. This implies |1/2 \u2212 p| \u2265 \u00b5 (\n\u03c4 18\u03b7\n2 )\u03ba\u22121\nso that on on any given call to the repeated querying\nsubroutine, with probability at least 1 \u2212 \u03b4 the subroutine requests no more than O\u0303 ( log(1/\u03b4)\n(\u03c4\u03b72)2(\u03ba\u22121)\n)\npairwise comparisons. However, because we want the total number of calls to the subroutine to hold with probability 1 \u2212 \u03b4, not just one, we must union bound over 4 pairwise comparisons per iteration times the number of iterations per line search times the number of line searches. This brings the total number of calls to the repeated query subroutine to no more than 4 \u00d7 3 2 log2 ( 256Lmaxk(f(xk)\u2212f(xk+dk \u03b1\u2217k)) \u03c42\u03b72 ) \u00d7 4nL\u03c4 log ( f(x0)\u2212f(x\u2217) \u03b722nL2/\u03c4 ) = O ( nL\u03c4 log 2 ( f(x0)\u2212f(x\u2217) n\u03b72 )) . If we set \u03b7 = (\n\u01eb\u03c4 4nL2 )1/2 so that E [f(xK)\u2212 f(x\u2217)] \u2264 \u01eb by Theorem 7, then the total number of\nrequested pairwise comparisons does not exceed\nO\u0303\n( nL\n\u03c4 (n \u01eb )2(\u03ba\u22121) log2 ( f(x0)\u2212 f(x\u2217) \u01eb ) log(n/\u03b4) ) .\nBy finding a T > 0 that satisfies this bound for any \u01eb we see that this is equivalent to a rate of O ( n log(n/\u03b4) ( n T ) 1 2(\u03ba\u22121) ) for \u03ba > 1 and O ( exp { \u2212c \u221a T n log(n/\u03b4) }) for \u03ba = 1, ignoring polylog factors."}], "references": [{"title": "Efficient optimization of support vector machine learning parameters for unbalanced datasets", "author": ["T. Eitrich", "B. Lang"], "venue": "Journal of computational and applied mathematics, 196(2):425\u2013436,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "A new derivative-free algorithm for the medical image registration problem", "author": ["R. Oeuvray", "M. Bierlaire"], "venue": "International Journal of Modelling and Simulation, 27(2):115\u2013124,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Introduction to derivative-free optimization, volume 8", "author": ["A.R. Conn", "K. Scheinberg", "L.N. Vicente"], "venue": "Society for Industrial Mathematics,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimal Learning", "author": ["Warren B. Powell", "Ilya O. Ryzhov"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Random gradient-free minimization of convex functions", "author": ["Y. Nesterov"], "venue": "CORE Discussion Papers,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M. Seeger"], "venue": "Arxiv preprint arXiv:0912.3995,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Differential evolution\u2013a simple and efficient heuristic for global optimization over continuous spaces", "author": ["R. Storn", "K. Price"], "venue": "Journal of global optimization, 11(4):341\u2013359,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1997}, {"title": "Stochastic convex optimization with bandit feedback", "author": ["A. Agarwal", "D.P. Foster", "D. Hsu", "S.M. Kakade", "A. Rakhlin"], "venue": "Arxiv preprint arXiv:1107.1744,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization, 19(4):1574,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithms for approximate calculation of the minimum of a convex function from its values", "author": ["V. Protasov"], "venue": "Mathematical Notes, 59:69\u201374,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Information-based complexity, feedback, and dynamics in convex programming", "author": ["M. Raginsky", "A. Rakhlin"], "venue": "Information Theory, IEEE Transactions on, (99):1\u20131,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological Review; Psychological Review, 34(4):273,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1927}, {"title": "The k-armed dueling bandits problem", "author": ["Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Active ranking using pairwise comparisons", "author": ["K.G. Jamieson", "R.D. Nowak"], "venue": "Arxiv preprint arXiv:1109.3701,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A.S. Nemirovsky", "D.B. Yudin"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Stochastic convex optimization with bandit feedback", "author": ["A. Agarwal", "D.P. Foster", "D. Hsu", "S.M. Kakade", "A. Rakhlin"], "venue": "Arxiv preprint arXiv:1107.1744,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization", "author": ["A. Agarwal", "P.L. Bartlett", "P. Ravikumar", "M.J. Wainwright"], "venue": "Information Theory, IEEE Transactions on, (99):1\u20131,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimal algorithms for online convex optimization with multi-point bandit feedback", "author": ["A. Agarwal", "O. Dekel", "L. Xiao"], "venue": "Conference on Learning Theory (COLT),", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "author": ["S. Ghadimi", "G. Lan"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Introduction to nonparametric estimation", "author": ["A.B. Tsybakov"], "venue": "Springer Verlag,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": "Information Theory, IEEE Transactions on, 54(5):2339\u20132353,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Convex optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": "Cambridge Univ Pr,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Algorithms for minimization without derivatives", "author": ["R.P. Brent"], "venue": "Dover Pubns,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Active learning in the non-realizable case", "author": ["M. K\u00e4\u00e4ri\u00e4inen"], "venue": "Algorithmic Learning Theory, pages 63\u201377. Springer,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 1, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 2, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 3, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 4, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 5, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 6, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 7, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 8, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 4, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 9, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 8, "context": "In contrast, noisy gradient methods exhibit \u0398(1/T ) error scaling for strongly convex functions [9, 11].", "startOffset": 96, "endOffset": 103}, {"referenceID": 10, "context": "In contrast, noisy gradient methods exhibit \u0398(1/T ) error scaling for strongly convex functions [9, 11].", "startOffset": 96, "endOffset": 103}, {"referenceID": 11, "context": "In fact, this choice of w corresponds to Thurston\u2019s law of comparative judgment which is a popular model for outcomes of pairwise comparisons from human subjects [12].", "startOffset": 162, "endOffset": 166}, {"referenceID": 6, "context": "[7]) and by optimization problems involving human subjects making paired comparisons (for instance, getting fitted for prescription lenses or a hearing aid where unknown parameters specific to each person are tuned with the familiar queries \u201cbetter or worse?\u201d).", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Pairwise comparisons have also been suggested as a novel way to tune web-search algorithms [13].", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14].", "startOffset": 223, "endOffset": 231}, {"referenceID": 13, "context": "Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14].", "startOffset": 223, "endOffset": 231}, {"referenceID": 14, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 4, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 9, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 14, "context": "However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 15, "context": "However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 14, "context": "While there remains many open problems in stochastic DFO (see Section 6), rates of convergence with a stochastic gradient oracle are well known and were first lower bounded by Nemirovski and Yudin [15].", "startOffset": 197, "endOffset": 201}, {"referenceID": 16, "context": "These classic results were recently tightened to show a dependence on the dimension of the problem [17].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9].", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9].", "startOffset": 141, "endOffset": 144}, {"referenceID": 10, "context": "Our bounds are based on simple techniques borrowed from the statistical learning literature that use natural functions and oracles in the same spirit of [11].", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "Alternatively, under a less restrictive setting, Nemirovski and Yudin proposed two algorithms for the class of convex, Lipschitz functions that obtain rates of n/T 1/4 and p(n)/T , respectively, where p(n) was left as an unspecified polynomial of n [15].", "startOffset": 249, "endOffset": 253}, {"referenceID": 14, "context": "built on the ideas developed in [15] to obtain a result that they point out implies a convergence rate of n/T 1/2 in the optimization setting considered here [16].", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": "built on the ideas developed in [15] to obtain a result that they point out implies a convergence rate of n/T 1/2 in the optimization setting considered here [16].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 4, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 18, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 20, "context": "Our proofs are most related to the approach developed in [21] for active learning, which like optimization involves a Markovian sampling process.", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "If the pairwise comparison oracle made no errors then the approximate line search is accomplished by a binary-search-like scheme, essentially a golden section line-search algorithm [24].", "startOffset": 181, "endOffset": 185}, {"referenceID": 23, "context": "However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25] (a similar technique was also implemented for the bandit setting of derivate-free optimization [8]).", "startOffset": 289, "endOffset": 293}, {"referenceID": 7, "context": "However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25] (a similar technique was also implemented for the bandit setting of derivate-free optimization [8]).", "startOffset": 389, "endOffset": 392}, {"referenceID": 23, "context": "This strategy applied to active learning is well known because of its simplicity and its ability to adapt to unknown noise conditions [25].", "startOffset": 134, "endOffset": 138}, {"referenceID": 20, "context": "However, we mention that when used in this way, this sampling procedure is known to be sub-optimal so in practice, one may want to implement a more efficient approach like that of [21].", "startOffset": 180, "endOffset": 184}, {"referenceID": 23, "context": "[25] For any x, y \u2208 B with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, with probability at least 1 \u2212 \u03b4 the coin-tossing algorithm of [25] correctly identifies the sign of E [Cf (x, y)] and requests no more than log(2/\u03b4) 4|1/2\u2212p|2 log2 ( log(2/\u03b4) 4|1/2\u2212p|2 ) pairwise comparisons.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] For any x, y \u2208 B with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, with probability at least 1 \u2212 \u03b4 the coin-tossing algorithm of [25] correctly identifies the sign of E [Cf (x, y)] and requests no more than log(2/\u03b4) 4|1/2\u2212p|2 log2 ( log(2/\u03b4) 4|1/2\u2212p|2 ) pairwise comparisons.", "startOffset": 127, "endOffset": 131}], "year": 2012, "abstractText": "This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same.", "creator": "LaTeX with hyperref package"}}}