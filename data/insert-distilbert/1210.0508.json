{"id": "1210.0508", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Oct-2012", "title": "Inference algorithms for pattern-based CRFs on sequence data", "abstract": "we consider conditional random fields ( crfs ) with pattern - based potentials defined on a exponential chain. in this geometric model the energy functional of a string ( labeling ) $ x _ ^ 1... x _ n $ is the sum of terms over intervals $ [ i, j ] $ \u2014 where each variable term is non - zero only if the substring $ = x _ i... x _ j $ equals a continuous prespecified pattern $ \\ # alpha $. such crfs were used in computer simulation vision, and can nowadays be naturally applied to many sequence tagging problems.", "histories": [["v1", "Mon, 1 Oct 2012 19:13:59 GMT  (63kb,DS)", "https://arxiv.org/abs/1210.0508v1", null], ["v2", "Tue, 23 Oct 2012 16:16:58 GMT  (64kb,DS)", "http://arxiv.org/abs/1210.0508v2", "improved complexity for one of the cases"], ["v3", "Thu, 8 Nov 2012 00:11:30 GMT  (65kb,DS)", "http://arxiv.org/abs/1210.0508v3", null], ["v4", "Sat, 29 Dec 2012 22:13:01 GMT  (72kb,DS)", "http://arxiv.org/abs/1210.0508v4", null], ["v5", "Fri, 20 Jan 2017 08:00:44 GMT  (60kb,D)", "http://arxiv.org/abs/1210.0508v5", "Algorithmica accepted version"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["rustem takhanov", "vladimir kolmogorov"], "accepted": true, "id": "1210.0508"}, "pdf": {"name": "1210.0508.pdf", "metadata": {"source": "CRF", "title": "Inference algorithms for pattern-based CRFs on sequence data", "authors": ["Rustem Takhanov", "Vladimir Kolmogorov"], "emails": ["takhanov@mail.ru", "vnk@ist.ac.at"], "sections": [{"heading": null, "text": "We present efficient algorithms for the three standard inference tasks in a CRF, namely computing (i) the partition function, (ii) marginals, and (iii) computing the MAP. Their complexities are respectively O(nL), O(nL`max) and O(nLmin{|D|, log(`max+1)}) where L is the combined length of input patterns, `max is the maximum length of a pattern, and D is the input alphabet. This improves on the previous algorithms of [Ye et al. NIPS 2009] whose complexities are respectively O(nL|D|), O ( n|\u0393|L2`2max ) and O(nL|D|), where |\u0393| is the number of input patterns. In addition, we give an efficient algorithm for sampling, and revisit the case of MAP with non-positive weights.\nThis paper addresses the sequence labeling (or the sequence tagging) problem: given an observation z (which is usually a sequence of n values), infer labeling x = x1 . . . xn where each variable xi takes values in some finite domain D. Such problem appears in many domains such as text and speech analysis, signal analysis, and bioinformatics.\nOne of the most successful approaches for tackling the problem is the Hidden Markov Model (HMM). The kth order HMM is given by the probability distribution p(x|z) = 1Z exp{\u2212E(x|z)} with the energy function\nE(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, zi) + \u2211\n(i,j)\u2208Ek\n\u03c8ij(xi:j) (1)\nwhere Ek = {(i, i+ k) | i \u2208 [1, n\u2212 k]} and xi:j = xi . . . xj is the substring of x from i to j. A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z:\nE(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, z) + \u2211\n(i,j)\u2208Ek\n\u03c8ij(xi:j , z) (2)\nA preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8]. This work was partially supported by the European Research Council under the European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 616160.\nar X\niv :1\n21 0.\n05 08\nv5 [\ncs .L\nG ]\n2 0\nWe study a particular variant of this model called a pattern-based CRF. It is defined via E(x|z) = \u2211 \u03b1\u2208\u0393 \u2211 [i,j]\u2286[1,n] j\u2212i+1=|\u03b1| \u03c8\u03b1ij(z) \u00b7 [xi:j = \u03b1] (3)\nwhere \u0393 is a fixed set of non-empty words, |\u03b1| is the length of word \u03b1 and [\u00b7] is the Iverson bracket. If we take \u0393 = D \u222aDk then (3) becomes equivalent to (2); thus we do not loose generality (but gain more flexibility).\nIntuitively, pattern-based CRFs allow to model long-range interactions for selected subsequences of labels. This could be useful for a variety of applications: in part-of-speech tagging patterns could correspond to certain syntactic constructions or stable idioms; in protein secondary structure prediction - to sequences of dihedral angles corresponding to stable configuration such as \u03b1-helixes; in gene prediction - to sequences of nucleatydes with supposed functional roles such as \u201cexon\u201d or \u201cintron\u201d, specific codons, etc. Inference This paper focuses on inference algorithms for pattern-based CRFs. The three standard inference tasks are\n\u2022 computing the partition function Z = \u2211\nx exp{\u2212E(x|z)};\n\u2022 computing marginal probabilities p(xi:j = \u03b1|z) for all triplets (i, j, \u03b1) present in (3);\n\u2022 computing MAP, i.e. minimizing energy (3). The complexity of solving these tasks is discussed below. We denote L = \u2211\n\u03b1\u2208\u0393 |\u03b1| to be total length of patterns and `max = max\u03b1\u2208\u0393 |\u03b1| to be the maximum length of a pattern.\nA naive approach is to use standard message passing techniques for an HMM of order k=`max\u22121. However, they would take O(n|D|k+1) time which would become impractical for large k. More efficient algorithms with complexities O(nL|D|), O ( n|\u0393|L2`2max ) and O(nL|D|) respectively were given by Ye et al. [10].1 Our first contribution is to improve this to O(nL), O(nL`max) and O(nL\u00b7min{|D|, log(`max+ 1)}) respectively (more accurate estimates are given in the next section).\nWe also give an algorithm for sampling from the distribution p(x|z). Its complexity is either (i) O(nL) per sample, or (ii) O(n) per sample with an O(nL|D|) preprocessing (assuming that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time).\nFinally, we consider the case when all costs \u03c8\u03b1ij(z) are non-positive. Komodakis and Paragios [2] gave an O(nL) technique for minimizing energy (3) in this case. We present a modification that has the same worst-case complexity but can beat the algorithm in [2] in the best case. Related work The works of [10] and [2] are probably the most related to our paper. The former applied pattern-based CRFs to the handwritten character recognition problem and to the problem of identification of named entities from texts. The latter considered a pattern-based CRF on a grid for a computer vision application; the MAP inference problem in [2] was converted to sequence labeling problems by decomposing the grid into thin \u201cstripes\u201d.\nQian et al. [5] considered a more general formulation in which a single pattern is characterized by a set of strings rather than a single string \u03b1. They proposed an exact inference algorithm and applied it to the OCR task and to the Chinese Organization Name Recognition task. However, their algorithm could take time exponential in the total lengths of input patterns; no subclasses of inputs were identified which could be solved in polynomial time.\nA different generalization (for non-sequence data) was proposed by Rother et al. [6]. Their inference procedure reduces the problem to the MAP estimation in a pairwise CRF with cycles, which\n1Some of the bounds stated in [10] are actually weaker. However, it is not difficult to show that their algorithms can be implemented in times stated above, using our Lemma 1.\nis then solved with approximate techniques such as BP, TRW or QPBO. This model was applied to the texture restoration problem.\nNguyen et al. [4] extended algorithms in [10] to the Semi-Markov model [7]. We conjecture that our algorithms can be extended to this case as well, and can yield a better complexity compared to [4].\nIn [8] we applied the pattern-based CRF model to the problem of the protein dihedral angles prediction."}, {"heading": "1 Notation and preliminaries", "text": "First, we introduce a few definitions.\n\u2022 A pattern is a pair \u03b1 = ([i, j], x) where [i, j] is an interval in [1, n] and x = xi . . . xj is a sequence over alphabet D indexed by integers in [i, j] (j \u2265 i\u2212 1). The length of \u03b1 is denoted as |\u03b1| = |x| = j \u2212 i+ 1.\n\u2022 Symbols \u201c\u2217\u201d denotes an arbitrary word or pattern (possibly the empty word \u03b5 or the empty pattern \u03b5s , ([s + 1, s], \u03b5) at position s). The exact meaning will always be clear from the context. Similary, \u201c+\u201d denotes an arbitrary non-empty word or pattern.\n\u2022 The concatenation of patterns \u03b1 = ([i, j], x) and \u03b2 = ([j+1, k], y) is the pattern \u03b1\u03b2 , ([i, k], xy). Whenever we write \u03b1\u03b2 we assume that it is defined, i.e. \u03b1 = ([\u00b7, j], \u00b7) and \u03b2 = ([j + 1, \u00b7], \u00b7) for some j.\n\u2022 For a pattern \u03b1 = ([i, j], x) and interval [k, `] \u2286 [i, j], the subpattern of \u03b1 at position [k, `] is the pattern \u03b1k:` , ([k, `], xk:`) where xk:` = xk . . . x`. If k = i then \u03b1k:` is called a prefix of \u03b1. If ` = j then \u03b1k:` is a suffix of \u03b1.\n\u2022 If \u03b2 is a subpattern of \u03b1, i.e. \u03b2 = \u03b1k:` for some [k, `], then we say that \u03b2 is contained in \u03b1. This is equivalent to the condition \u03b1 = \u2217\u03b2\u2217.\n\u2022 Di:j = {([i, j], x) | x \u2208 D[i,j]} is the set of patterns with interval [i, j]. We typically use letter x for patterns in D1:s and letters \u03b1, \u03b2, . . . for other patterns. Patterns x \u2208 D1:s will be called partial labelings.\n\u2022 For a set of patterns \u03a0 and index s \u2208 [0, n] we denote \u03a0s to be the set of patterns in \u03a0 that end at position s: \u03a0s = {([i, s], \u03b1) \u2208 \u03a0}.\n\u2022 For a pattern \u03b1 let \u03b1\u2212 be the prefix of \u03b1 of length |\u03b1| \u2212 1; if \u03b1 is empty then \u03b1\u2212 is undefined.\nWe will consider the following general problem. Let \u03a0\u25e6 be the set of patterns of words in \u0393 placed at all possible positions: \u03a0\u25e6 = {([i, j], \u03b1) | \u03b1 \u2208 \u0393)}. Let (R,\u2295,\u2297) be a commutative semiring with elements O,1 \u2208 R which are identities for \u2295 and \u2297 respectively. Define the cost of pattern x \u2208 Di:j via\nf(x) = \u2297\n\u03b1\u2208\u03a0\u25e6,x=\u2217\u03b1\u2217 c\u03b1 (4)\nwhere c\u03b1\u2208R are fixed constants. (Throughout the paper we adopt the convention that operations \u2295 and \u2297 over the empty set of arguments give respectively O and 1, and so e.g. f(\u03b5s) = 1.) Our goal is to compute\nZ = \u2295\nx\u2208D1:n f(x) (5)\nExample 1 If (R,\u2295,\u2297) = (R,+,\u00d7) then problem (5) is equivalent to computing the partition function for the energy (3), if we set c([i,j],\u03b1) = exp{\u2212\u03c8\u03b1ij(z)}. Example 2 If (R,\u2295,\u2297) = (R,min,+) where R , R \u222a {+\u221e} then we get the problem of minimizing energy (3), if c([i,j],\u03b1) = \u03c8 \u03b1 ij(z).\nThe complexity of our algorithms will be stated in terms of the following quantities:\n\u2022 P = |{\u03b1 | \u2203\u03b1\u2217 \u2208 \u0393, \u03b1 6= \u03b5}| is the number of distinct non-empty prefixes of words in \u0393. Note that P \u2264 L.\n\u2022 P \u2032 = |{\u03b1 | \u2203\u03b1+ \u2208 \u0393}| is the number of distinct proper prefixes of words in \u0393. There holds P P \u2032 \u2208 [1, |D|]. If \u0393 = D1 \u222aD2 \u222a . . . \u222aDk then PP \u2032 = |D|. If \u0393 is a sparse random subset of the set above then P P \u2032 \u2248 1.\n\u2022 I(\u0393) = {\u03b1 | \u2203\u03b1\u2217, \u2217\u03b1 \u2208 \u0393, \u03b1 6= \u03b5} is the set of non-empty words which are both prefixes and suffixes of some words in \u0393. Note that \u0393\u2286I(\u0393) and |I(\u0393)|\u2264P .\nWe will present 6 algorithms: Sec. 2: \u0398(nP ) algorithm for the case when (R,\u2295,\u2297) is a ring, i.e. it has operation that satisfies (a b)\u2295 b = a for all a, b \u2208 R. This holds for the semiring in Example 1 (but not for Example 2). Sec. 3: \u0398(nP ) algorithm for sampling. Alternatively, it can be implemented to produce independent samples in \u0398(n) time per sample with a \u0398(nP |D|) preprocessing. Sec. 4: O(n \u2211 \u03b1\u2208I(\u0393) |\u03b1|) algorithm for computing marginals for all patterns \u03b1 \u2208 \u03a0\u25e6. Sec. 5: \u0398(nP \u2032|D|) algorithm for a general commutative semiring, which is equivalent to the algorithm in [10]. It will be used as a motivation for the next algorithm. Sec. 6: O(nP logP ) algorithm for a general commutative semiring; for the semiring in Example 2 the complexity can be reduced to O(nP log(`max + 1)). Sec. 7: O(nP ) algorithm for the case (R,\u2295,\u2297) = (R,min,+), c\u03b1 \u2264 0 for all \u03b1 \u2208 \u03a0\u25e6.\nAll algorithms will have the following structure. Given the set of input patterns \u03a0\u25e6, we first construct another set of patterns \u03a0; it will typically be either the set of prefixes or the set of proper prefixes of patterns in \u03a0\u25e6. This can be done in a preprocessing step since sets \u03a0s will be isomorphmic (up to a shift) for indexes s that are sufficiently far from the boundary. (Recall that \u03a0s is the set of patterns in \u03a0 that end at position s.) Then we recursively compute messages Ms(\u03b1) for \u03b1 \u2208 \u03a0s which have the following interpretation: Ms(\u03b1) is the sum (\u201c\u2295\u201d) of costs f(x) over a certain set of partial labelings of the form x = \u2217\u03b1 \u2208 D1:s. In some of the algorithms we also compute messages Ws(\u03b1) which is the sum of f(x) over all partial labelings of the form x = \u2217\u03b1 \u2208 D1:s. Graph G[\u03a0s] The following construction will be used throughout the paper. Given a set of patterns \u03a0 and index s, we define G[\u03a0s] = (\u03a0s, E[\u03a0s]) to be the Hasse diagram of the partial order on \u03a0s, where \u03b1 \u03b2 iff \u03b1 is a suffix of \u03b2 (\u03b2 = \u2217\u03b1). In other words, G[\u03a0s] is a directed acyclic graph with the following set of edges: (\u03b1, \u03b2) belongs to E[\u03a0s] for \u03b1, \u03b2 \u2208 \u03a0s if \u03b1 \u227a \u03b2 and there exists no \u201cintermediate\u201d pattern \u03b3 \u2208 \u03a0s with \u03b1 \u227a \u03b3 \u227a \u03b2. It can be checked that graph G[\u03a0s] is a directed forest. If \u03b5s \u2208 \u03a0s then G[\u03a0s] is connected and therefore is a tree. In this case we treat \u03b5s as the root. An example is shown in Fig. 1.\nComputing partial costs Recall that f(\u03b1) for a pattern \u03b1 is the cost of all patterns inside \u03b1 (eq. (4)). We also define \u03c6(\u03b1) to be the cost of only those patterns that are suffixes of \u03b1:\n\u03c6(\u03b1) = \u2297\n\u03b2\u2208\u03a0\u25e6,\u03b1=\u2217\u03b2 c\u03b2 (6)\nQuantities \u03c6(\u03b1) and f(\u03b1) will be heavily used by the algorithms below; let us show how to compute them efficiently.\nLemma 1. Let \u03a0 be a set of patterns with \u03b5s \u2208 \u03a0 for all s \u2208 [0, n]. Values \u03c6(\u03b1) for all \u03b1 \u2208 \u03a0 can be computed using O(|\u03a0|) multiplications (\u201c\u2297\u201d). The same holds for values f(\u03b1) assuming that \u03a0 is prefix-closed, i.e. \u03b1\u2212 \u2208 \u03a0 for all non-empty patterns \u03b1 \u2208 \u03a0.\nProof. To compute \u03c6(\u00b7) for patterns \u03b1 \u2208 \u03a0s, we use the following procedure: (i) set \u03c6(\u03b5s) := 1; (ii) traverse edges (\u03b1, \u03b2) \u2208 E[\u03a0s] of tree G[\u03a0s] (from the root to the leaves) and set\n\u03c6(\u03b2) :=\n{ \u03c6(\u03b1)\u2297 c\u03b2 if \u03b2 \u2208 \u03a0\u25e6\n\u03c6(\u03b1) otherwise\nNow suppose that \u03a0 is prefix-closed. After computing \u03c6(\u00b7), we go through indexes s \u2208 [0, n] and set\nf(\u03b5s) :=1, f(\u03b1) :=f(\u03b1 \u2212)\u2297 \u03c6(\u03b1) \u2200\u03b1 \u2208 \u03a0s \u2212 {\u03b5s}\nSets of partial labelings Let \u03a0s be a set of patterns that end at position s. Assume that \u03b5s \u2208 \u03a0s. For a pattern \u03b1 \u2208 \u03a0s we define\nXs(\u03b1) = {x \u2208 D1:s | x = \u2217\u03b1} (7) Xs(\u03b1; \u03a0s) = Xs(\u03b1)\u2212 \u22c3 (\u03b1,\u03b2)\u2208E[\u03a0s] Xs(\u03b2) (8)\nIt can be seen that sets Xs(\u03b1; \u03a0s) are disjoint, and their union over \u03b1 \u2208 \u03a0s is D1:s. Furthermore, there holds\nXs(\u03b1; \u03a0s) = {x \u2208 Xs(\u03b1) | x 6= \u2217\u03b2 \u2200\u03b2 = +\u03b1 \u2208 \u03a0s} (9)\nWe will use eq. (9) as the definition of Xs(\u03b1; \u03a0s) in the case when \u03b1 /\u2208 \u03a0s."}, {"heading": "2 Computing partition function", "text": "In this section we give an algorithm for computing quantity (5) assuming that (R,\u2295,\u2297) is a ring. This can be used, in particular, for computing the partition function. We will assume that D \u2286 \u0393; we can always add D to \u0393 if needed2.\n2Note that we still claim complexity O(nP ) where P is the number of distinct non-empty prefixes of words in the original set \u0393. Indeed, we can assume w.l.o.g. that each letter in D occurs in at least one word \u03b1\u2208\u0393. (If not, then we can \u201cmerge\u201d non-occuring letters to a single letter and add this letter to \u0393; clearly, any instance over the original pair (D,\u0393) can be equivalenly formulated as an instance over the new pair. The transformation increases P only by 1). The assumption implies that |D| \u2264 P . Adding D to \u0393 increases P by at most P , and thus does not affect bound O(nP ).\nFirst, we select set \u03a0 as the set of prefixes of patterns in \u03a0\u25e6:\n\u03a0 = {\u03b1 | \u2203\u03b1\u2217 \u2208 \u03a0\u25e6} (10)\nWe will compute the following quantities for each s \u2208 [0, n], \u03b1 \u2208 \u03a0s:\nMs(\u03b1) = \u2295\nx\u2208Xs(\u03b1;\u03a0s)\nf(x) , Ws(\u03b1) = \u2295\nx\u2208Xs(\u03b1)\nf(x) (11)\nIt is easy to see that for \u03b1 \u2208 \u03a0s the following equalities relate Ms and Ws:\nMs(\u03b1) = Ws(\u03b1) \u2295\n(\u03b1,\u03b2)\u2208E[\u03a0s]\nWs(\u03b2) (12a)\nWs(\u03b1) = Ms(\u03b1)\u2295 \u2295\n(\u03b1,\u03b2)\u2208E[\u03a0s]\nWs(\u03b2) (12b)\nThese relations motivate the following algorithm. Since |\u03a0s| = P + 1 for indexes s that are sufficiently far from the boundary, its complexity is \u0398(nP ) assuming that values \u03c6(\u03b1) in eq. (13a) are computed using Lemma 1. Algorithm 1 Computing Z = \u2295\nx\u2208D1:n f(x) for a ring\n1: initialize messages: set W0(\u03b50) := O 2: for s = 1, . . . , n traverse nodes \u03b1 \u2208 \u03a0s of tree G[\u03a0s] starting from the leaves and set\nMs(\u03b1) := \u03c6(\u03b1)\u2297 Ws\u22121(\u03b1\u2212) \u2295 (\u03b1,\u03b2)\u2208E[\u03a0s] Ws\u22121(\u03b2 \u2212)  (13a) Ws(\u03b1) := Ms(\u03b1)\u2295\n\u2295 (\u03b1,\u03b2)\u2208E[\u03a0s] Ws(\u03b2) (13b)\nException: if \u03b1 = \u03b5s then set Ms(\u03b1) := O instead of (13a) 3: return Z := Wn(\u03b5n)\nTheorem 2. Algorithm 1 is correct, i.e. it returns the correct value of Z = \u2295\nx F (x)."}, {"heading": "2.1 Proof of Theorem 2", "text": "Eq. (13b) coincides with (12b); let us show that eq. (13a) holds for any \u03b1 \u2208 \u03a0s \u2212 {\u03b5s}. (Note, for \u03b1 = \u03b5s step 2 is correct: assumption D \u2286 \u0393 implies that Ds:s \u2286 \u03a0s, and therefore Xs(\u03b5s; \u03a0s) = \u2205, Ms(\u03b5s) = O).\nFor a partial labeling x \u2208 D1:s define the \u201creduced partial cost\u201d as\nf\u2212(x) = \u2297\n\u03b1\u2208\u03a0\u25e6,x=\u2217\u03b1+ c\u03b1 (14)\nIt is easy to see from (11) that for any \u03b1 \u2208 \u03a0s \u2212 {\u03b5s}\nWs\u22121(\u03b1 \u2212) = \u2211 x\u2208Xs(\u03b1) f\u2212(x) (15)\nConsider \u03b1 \u2208 \u03a0s \u2212 {\u03b5s}. We will show that for any x \u2208 Xs(\u03b1) there holds\nJx \u2208 Xs(\u03b1; \u03a0s)K\u2297 f(x) = \u03c6(\u03b1)\u2297 f\u2212(x) \u2295 (\u03b1,\u03b2)\u2208E[\u03a0s]:x\u2208Xs(\u03b2) f\u2212(x)  (16) where J\u00b7K = 1 if the argument is true, and O otherwise. This will be sufficient for establishing the theorem: summing these equations over x \u2208 Xs(\u03b1) and using (11), (15) yields eq. (13a).\nTwo cases are possible: Case 1: x \u2208 Xs(\u03b2) for some (\u03b1, \u03b2) \u2208 E[\u03a0s]. (Such \u03b2 is unique since sets Xs(\u03b2) are disjoint.) Then both sides of (16) are O. Case 2: x \u2208 Xs(\u03b1; \u03a0s). Then eq. (16) is equivalent to f(x) = \u03c6(\u03b1) \u2297 f\u2212(x). This holds since there is no pattern \u03b3 \u2208 \u03a0\u25e6s(x) with |\u03b3| > |\u03b1| (otherwise we would have \u03b3 \u2208 \u03a0s and thus x /\u2208 Xs(\u03b1; \u03a0s) by definition (9) - a contradiction)."}, {"heading": "3 Sampling", "text": "In this section consider the semiring (R,\u2295,\u2297) = (R,+,\u00d7) from Example 1. We assume that all costs c\u03b1 are strictly positive. We present an algorithm for sampling labelings x \u2208 D1:n according to the probability distribution p(x) = f(x)/Z.\nAs in the previous section, we assume that D \u2286 \u0393, and define \u03a0 to be the set of prefixes of patterns in \u03a0\u25e6 (eq. (10)). For a node \u03b1 \u2208 \u03a0s let Ts(\u03b1) be the set of nodes in the subtree of G[\u03a0s] rooted at \u03b1, with \u03b1 \u2208 Ts(\u03b1) \u2286 \u03a0s. For a pattern \u03b1 \u2208 \u03a0s+1 \u2212 {\u03b5s+1} we define set\n\u2206s(\u03b1) = Ts(\u03b1 \u2212)\u2212 \u22c3 (\u03b1,\u03b2)\u2208G[\u03a0s+1] Ts(\u03b2 \u2212) (17)\nWe can now present the algorithm (see Algorithm 2).\nAlgorithm 2 Sample x \u223c p(x) = f(x)/Z 1: run Algorithm 1 to compute messages Ms(\u03b1) for all patterns \u03b1 = ([\u00b7, s], \u00b7) \u2208 \u03a0 2: sample \u03b1n\u2208\u03a0n with probability p(\u03b1n)\u221dMn(\u03b1n) 3: for s = n\u22121, . . . , 1 sample \u03b1s \u2208 \u2206s(\u03b1s+1) with probability p(\u03b1s) \u221dMs(\u03b1s) 4: return labeling x with xs:s = (\u03b1s)s:s for s \u2208 [1, n]\nWe say that step s of the algorithm is valid if either (i) s = n, or (ii) s \u2208 [1, n \u2212 1], step s + 1 is valid, \u03b1s+1 6= \u03b5s+1 and Ms(\u03b1) > 0 for some \u03b1 \u2208 \u2206s(\u03b1s+1). (This is a recursive definition.) Clearly, if step s is valid then line 3 of the algorithm is well-defined.\nTheorem 3. (a) With probability 1 all steps of the algorithm are valid. (b) The returned labeling x \u2208 D1:n is distributed according to p(x) = f(x)/Z.\nComplexity Assume that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time.\nThe main subroutine performed by the algorithm is sampling from a given discrete distribution. Clearly, this can be done in \u0398(N) time where N is the number of allowed values of the random variable. With a \u0398(N) preprocessing, a sample can also be produced in O(1) time by the so-called \u201calias method\u201d [9].\nThis leads to two possible complexities: (i) \u0398(nP ) (without preprocessing); (ii) \u0398(n) per sample (with preprocessing). Let us discuss the complexity of this preprocessing. Running Algorithm 1 takes\n\u0398(nP ) time. After that, for each \u03b1 \u2208 \u03a0s+1 we need to run the linear time procedure of [9] for distributions p(\u03b2) \u221d Ms(\u03b2), \u03b2 \u2208 \u2206s(\u03b1s+1). The following theorem implies that this takes \u0398(nP |D|) time.\nTheorem 4. There holds \u2211\n\u03b1\u2208\u03a0s\u2212{\u03b5s} |\u2206s\u22121(\u03b1)| = |\u03a0s\u22121| \u00b7 |D|.\nProof. Consider pattern \u03b2 \u2208 \u03a0s\u22121. For a letter a \u2208 Ds:s let \u03b2a \u2208 \u03a0s be longest suffix \u03b1 of \u03b2a with \u03b1 \u2208 \u03a0s (at least one such suffix exists, namely a). It can be seen that the set {\u03b2a |a \u2208 Ds:s} is exactly the set of patterns \u03b1 \u2208 \u03a0s \u2212 {\u03b5s} for which \u2206s\u22121(\u03b1) contains \u03b2 (checking this fact is just definition chasing). Therefore, the sum in the theorem equals \u2211 \u03b2\u2208\u03a0s\u22121 |{\u03b2 a | a \u2208 Ds:s}| = |\u03a0s\u22121| \u00b7 |D|.\nTo summarize, we showed that with a \u0398(nP |D|) preprocessing we can compute independent samples from p(x) in \u0398(n) time per sample."}, {"heading": "3.1 Proof of Theorem 3", "text": "Suppose that step s \u2208 [1, n] of the algorithm is valid; this means that patterns \u03b1t for t \u2208 [s, n] are well-defined. For t \u2208 [s, n] we then define the set of patterns At = \u2206t(\u03b1t+1) \u2286 \u03a0t (if t = n then we define At = \u03a0t instead). We also define sets of labelings\nYt(\u03b1) = {yxt+1:n | y \u2208 Xt(\u03b1; \u03a0t)} \u2200\u03b1 \u2208 At (18) Yt = Yt(\u03b1t) (19)\nwhere x is a labeling with xt:t = (\u03b1t)t:t for t \u2208 [s, n]. Let Yn+1 = D1:n.\nLemma 5. Suppose that step s \u2208 [1, n] is valid. (a) Ys+1 is a disjoint union of sets Ys(\u03b1) over \u03b1 \u2208 As. (b) For each y \u2208 Ys+1 = \u22c3 \u03b1\u2208As Ys(\u03b1) there holds f(y) = consts \u00b7 f(y1:s), and consequently for any\n\u03b1 \u2208 As there holds \u2211 y\u2208Ys(\u03b1) f(y) = consts \u00b7 \u2211 y\u2208Xs(\u03b1;\u03a0s) f(y) = consts \u00b7Ms(\u03b1)\nTheorem 3 will follow from this lemma. Indeed, the lemma shows that the algorithm implicitly computes a sequence of nested sets D1:n = Yn+1 \u2287 Yn \u2287 . . . \u2287 Y1 = {x}. At step s we divide set Ys+1 into disjoint subsets Ys(\u03b1), \u03b1 \u2208 As and select one of them, Ys = Ys(\u03b1s), with the probability proportional to Ms(\u03b1s) \u221d \u2211 y\u2208Ys(\u03b1s) f(y).\nWe still need to show that if step s \u2208 [2, n] is valid then step s\u2212 1 is valid as well with probability 1. It follows from the precondition that \u03b1s sampled in line 3 satisfies Ms(\u03b1s) > 0 with probability 1; this implies that \u03b1s 6= \u03b5s. From the paragraph above we get that \u2211 y\u2208Ys f(y) > 0 with probability\n1. We also have \u2211 \u03b1\u2208As\u22121 Ms\u22121(\u03b1) \u221d \u2211 \u03b1\u2208As\u22121 \u2211 y\u2208Ys\u22121(\u03b1) f(y) = \u2211\ny\u2208Ys f(y) > 0 implying that Ms\u22121(\u03b1) > 0 for some \u03b1 \u2208 As\u22121. This concludes the proof that step s\u2212 1 is valid with probability 1.\nIt remains to prove Lemma 5.\nPart (a) First, we need to check that Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1) is equal to the disjoint union of Xs(\u03b1; \u03a0s) over \u03b1 \u2208 \u2206s(\u03b1s+1) where \u03a0\u2212s+1 = {\u03b1\u2212 | \u03b1 \u2208 \u03a0s+1}. Disjointness of Xs(\u03b1; \u03a0s) for different \u03b1 \u2208 \u03a0s is obvious. Since \u03a0\u2212s+1 \u2286 \u03a0s, then for any \u03b1 \u2208 \u2206s(\u03b1s+1), Xs(\u03b1; \u03a0s) \u2286 Xs(\u03b1 \u2212 s+1; \u03a0 \u2212 s+1) is straightforward from the definition of \u2206s(\u03b1s+1). Thus, we only need to check the inclusion of Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1) in the union. Elements of \u03a0\u2212s+1 \u222a { \u03b1\u2212s+1 } can be seen as nodes in tree G[\u03a0s]. Then any pattern x from Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1) defines the longest suffix s(x) such that s(x) \u2208 \u03a0s. It is easy to see that s(x) \u2208 Ts(\u03b1 \u2212 s+1), and moreover, the descending path in G[\u03a0s] from \u03b1 \u2212 s+1 to s(x) does not contain elements from\n\u03a0\u2212s+1 \u2212 { \u03b1\u2212s+1 } , otherwise x, s(x) /\u2208 Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1). It is easy to see that this is equivalent to s(x) \u2208 \u2206s(\u03b1s+1). Since x \u2208 Xs(s(x); \u03a0s), Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1) is a subset of the union of Xs(\u03b1; \u03a0s) over \u03b1 \u2208 \u2206s(\u03b1s+1). Now according to definition of Ys+1 we can write:\nYs+1 = {yxs+2:n | y \u2208 Xs+1(\u03b1s+1; \u03a0s+1)} = {y(\u03b1s+1)s+1:s+1xs+2:n | y \u2208 Xs(\u03b1\u2212s+1; \u03a0 \u2212 s+1)}\n= \u22c3\n\u03b1\u2208\u2206s(\u03b1s+1)\n{y(\u03b1s+1)s+1:s+1xs+2:n | y \u2208 Xs(\u03b1; \u03a0s)}\nIt only remains to check that in the last union the set corresponding to \u03b1 \u2208 \u2206s(\u03b1s+1) is exactly equal to Ys(\u03b1). Part (b) Let p be the start position of \u03b1s+1, i.e. \u03b1s+1 = ([p, s+ 1], \u00b7). Consider labeling y \u2208 Ys+1, we then must have y = \u2217\u03b1s+1\u2217. Let \u03b2 = ([i, j], \u00b7) be a pattern with y = \u2217\u03b2\u2217, j > s. We will prove that i \u2265 p; this will imply the claim.\nSuppose on the contrary that i < p. Denote \u03b3 = \u03b2i:s+1, then \u03b3 \u2208 \u03a0s+1 and \u03b3 = +\u03b1s+1. Therefore, y1:s+1 /\u2208 Xs+1(\u03b1s+1; \u03a0s+1) (since y1:s+1 = \u2217\u03b3). However, this contradicts the assumption that y \u2208 Ys+1 = Ys+1(\u03b1s+1)."}, {"heading": "4 Computing marginals", "text": "In this section we again consider the semiring (R,\u2295,\u2297) = (R,+,\u00d7) from Example 1 where all costs c\u03b1 are strictly positive, and consider a probablity distribution p(x) = f(x)/Z over labelings x \u2208 D1:n.\nFor a pattern \u03b1 we define\n\u2126(\u03b1) = {x \u2208 D1:n | x = \u2217\u03b1\u2217} (20) Z(\u03b1) = \u2211 x\u2208\u2126(\u03b1) f(x) (21)\nWe also define the set of patterns\n\u03a0 = {\u03b1 | \u2203\u03b1\u2217, \u2217\u03b1 \u2208 \u03a0\u25e6, \u03b1 is non-empty} (22)\nNote that \u03a0\u25e6 \u2286 \u03a0 and |\u03a0s| = |I(\u0393)| for indexes s that are sufficiently far from the boundary. We will present an algorithm for computing Z(\u03b1) for all patterns \u03b1 \u2208 \u03a0 in time O(n \u2211 \u03b1\u2208I(\u0393) |\u03b1|). Marginal probabilities of a pattern-based CRF can then be computed as p(xi:j = \u03b1) = Z(\u03b1)/Z for a pattern \u03b1 = ([i, j], \u00b7).\nIn the previous section we used graph G[\u03a0s] for a set of patterns \u03a0s; here we will need an analogous but a slightly different construction for patterns in \u03a0. For patterns \u03b1, \u03b2 we write \u03b1 v \u03b2 if \u03b2 = \u2217\u03b1\u2217. If we have \u03b2 = +\u03b1+ then we write \u03b1 < \u03b2.\nNow consider \u03b1 \u2208 \u03a0. We define \u03a6(\u03b1) to be the set of patterns \u03b2 \u2208 \u03a0 such that \u03b1 < \u03b2 and there is no other pattern \u03b3 \u2208 \u03a0 with \u03b1 < \u03b3 v \u03b2.\nOur algorithm is given below. In the first step it runs Algorithm 1 from left to right and from\nright to left; as a result, we get forward messages \u2212\u2192 W j(\u03b1) and backward messages \u2190\u2212 W i(\u03b1) for patterns \u03b1 = ([i, j], \u00b7) such that \u2212\u2192 W j(\u03b1) =\n\u2211 x=\u2217\u03b1 x\u2208D1:j f(x) \u2190\u2212 W i(\u03b1) = \u2211 y=\u03b1\u2217 y\u2208Di:n f(y) (23)\nAlgorithm 3 Computing values Z(\u03b1)\n1: run Algorithm 1 in both directions to get messages \u2212\u2192 W j(\u03b1), \u2190\u2212 W i(\u03b1). For each pattern \u03b1 = ([i, j], \u00b7) \u2208\n\u03a0 set\nW (\u03b1) :=\n\u2212\u2192 W j(\u03b1) \u2190\u2212 W i(\u03b1)\nf(\u03b1) (24a)\nW\u2212(\u03b1) :=\n\u2212\u2192 W j\u22121(\u03b1i:j\u22121) \u2190\u2212 W i+1(\u03b1i+1:j)\nf(\u03b1i+1:j\u22121) (24b)\n2: for \u03b1\u2208\u03a0 (in the order of decreasing |\u03b1|) set\nZ(\u03b1) := W (\u03b1) + \u2211\n\u03b2\u2208\u03a6(\u03b1)\n[ Z(\u03b2)\u2212W\u2212(\u03b2) ] (25)\nTheorem 6. Algorithm 3 is correct.\nWe prove the theorem in section 4.1, but first let us discuss algorithm\u2019s complexity. We claim that all values f(\u03b1) used by the algorithm can be computed in O(n(P + S)) time where P and S are respectively the number of distinct non-empty prefixes and suffixes of words in \u0393. Indeed, we first compute these values for patterns in the set \u2212\u2192 \u03a0 , {\u03b1 | \u2203\u03b1\u2217 \u2208 \u03a0\u25e6}; by Lemma 1, this takes O(nP ) time. This covers values f(\u03b1) used in eq. (24a). As for the value in eq. (24b) for pattern \u03b1 = ([i, j], \u00b7) \u2208 \u03a0, we can use the formula\nf(\u03b1i+1:j\u22121) = f(\u03b1)c\u0303\u03b1 \u2212\u2192 \u03c6 (\u03b1) \u2190\u2212 \u03c6 (\u03b1)\nwhere c\u0303\u03b1 = c\u03b1 if \u03b1 \u2208 \u03a0\u25e6 and c\u0303\u03b1 = 1 otherwise, and \u2212\u2192 \u03c6 (\u03b1) = \u220f \u03b2\u2208\u03a0\u25e6,\u03b1=\u2217\u03b2 c\u03b2 , \u2190\u2212 \u03c6 (\u03b1) = \u220f \u03b2\u2208\u03a0\u25e6,\u03b1=\u03b2\u2217 c\u03b2\nThe latter values can be computed in O(n(P + S)) time by applying Lemma 1 in the forward and backward directions. (In fact, they were already computed when running Algorithm 1.)\nWe showed that step 1 can be implemented in O(n(P + S)) time; let us analyze step 2. The following lemma implies that it performs O(n \u2211 \u03b1\u2208I(\u0393) |\u03b1|) arithmetic operations; since \u2211 \u03b1\u2208I(\u0393) |\u03b1| \u2265\u2211\n\u03b1\u2208\u0393 |\u03b1| \u2265 max {P, S}, we then get that the overall complexity is O(n \u2211 \u03b1\u2208I(\u0393) |\u03b1|).\nLemma 7. For each \u03b2 \u2208 \u03a0 there exist at most 2|\u03b2| patterns \u03b1 \u2208 \u03a0 such that \u03b2 \u2208 \u03a6(\u03b1).\nProof. Let \u03a8 be the set of such patterns \u03b1. Note, there holds \u03b2 = +\u03b1+. We need to show that m , |\u03a8| \u2264 2|\u03b2|. Let us order patterns \u03b1 = ([i, j], \u00b7) \u2208 \u03a8 lexicographically (first by i, then by j): \u03a8 = {\u03b11, . . . , \u03b1m} with \u03b1t = ([it, jt], \u00b7), and denote \u03c3t = (it \u2212 k) + (jt \u2212 k) \u2208 [2, 2(` \u2212 k \u2212 1)] where [k, `] is the interval for \u03b2. We will prove by induction that \u03c3t \u2265 t + 1 for t \u2208 [1,m]; this will imply that m+ 1 \u2264 \u03c3m \u2264 2(`\u2212 k \u2212 1) = 2(|\u03b2| \u2212 2), as desired.\nThe base case is trivial. Suppose that it holds for t \u2212 1; let us prove it for t. If it = it\u22121 then jt > jt\u22121 by the definition of the order on \u03a8, so the claim holds. Suppose that it > it\u22121. If jt < jt\u22121 then \u03b1t < \u03b1t\u22121 < \u03b2 contradicting the condition \u03b2 \u2208 \u03a6(\u03b1t). Thus, jt \u2265 jt\u22121, and so the claim of the induction step holds.\nRemark 1 An alternative method for computing marginals with complexity O ( n|\u0393|L2`2max ) was given in [10]. They compute value Z(\u03b1) directly from messages \u2212\u2192 M j\u2032(\u00b7) and \u2190\u2212 M i\u2032(\u00b7) by summing over pairs of patterns (thus the square factor in the complexity). In contrast, we use a recursive rule that uses previously computed values of Z(\u00b7). We also use the existence of the \u201c \u201d operation. This allows us to achieve better complexity."}, {"heading": "4.1 Proof of theorem 6", "text": "Consider labeling x \u2208 D1:n. We define \u039b(x) = {\u03b1 \u2208 \u03a0\u25e6 | x = \u2217\u03b1\u2217} to be the set of patterns contained in x. For an interval [i, j] \u2286 [1, n] we also define sets\n\u039bij(x) = {\u03b2 \u2208 \u039b(x) | \u03b2 = +xi:j+} (26a) \u039b\u2212ij(x) = {\u03b2 \u2208 \u039b(x) | \u03b2 = \u2217xi:j\u2217} (26b)\nand corresponding costs\nfij(x) = \u220f\n\u03b2\u2208\u039b(x)\u2212\u039bij(x)\nc\u03b2 (27a)\nf\u2212ij (x) = \u220f\n\u03b2\u2208\u039b(x)\u2212\u039b\u2212ij(x)\nc\u03b2 (27b)\nIt can be checked that quantities W (\u03b1), W\u2212(\u03b1) defined via (23) and (24) satisfy\nW (\u03b1) = \u2211\nx\u2208\u2126(\u03b1)\nfij(x) W \u2212(\u03b1) = \u2211 x\u2208\u2126(\u03b1) f\u2212ij (x) (28)\nwhere [i, j] is the interval for \u03b1. Consider pattern \u03b1 = ([i, j], \u00b7) \u2208 \u03a0. We will show that for any x \u2208 \u2126(\u03b1) there holds\nf(x) = fij(x) + \u2211\n\u03b2=([k,`],\u00b7)\u2208\u03a6(\u03b1):x=\u2217\u03b2\u2217\n[ f(x)\u2212 f\u2212k`(x) ] (29)\nThis will be sufficient for establishing algorithm\u2019s correctness: summing these equations over x \u2208 \u2126(\u03b1) and using (21),(28) yields eq. (25).\nLemma 8. The sum in (29) contains at most one pattern \u03b2 = ([k, `], \u00b7) \u2208 \u03a6(\u03b1) with x = \u2217\u03b2\u2217.\nProof. Consider two such patterns \u03b21 = ([k1, `1], \u00b7) and \u03b22 = ([k2, `2], \u00b7). Define k = max{k1, k2}, `=min{`1, `2}, \u03b2=xk:`, then \u03b1<\u03b2v\u03b2t for t\u2208{1, 2}. Using the definition of set \u03a0, it can be checked that \u03b2 \u2208 \u03a0. The fact that \u03b2t \u2208 \u03a6(\u03b1) then implies that \u03b2t = \u03b2 for t \u2208 {1, 2}, and so \u03b21 = \u03b22.\nWe now consider two possible cases. Case 1: There are no patterns \u03b2 = ([k, `], \u00b7) \u2208 \u03a6(\u03b1) with x = \u2217\u03b2\u2217. This implies that \u039bij(x) is empty, and therefore f(x) = fij(x). Eq. (29) thus holds. Case 2: There exists a (unique) pattern \u03b2 = ([k, `], \u00b7) \u2208 \u03a6(\u03b1) with x = \u2217\u03b2\u2217. Eq. (29) then becomes equivalent to the condition fij(x) = f \u2212 k`(x). We will prove this by showing that \u039bij(x) = \u039b \u2212 k`(x).\nThe inclusion \u039b\u2212k`(x) \u2286 \u039bij(x) is obvious; let us show the other direction. Suppose that \u03b3 = ([p, q], \u00b7) \u2208 \u039bij(x). Define p\u0302 = max{k, p}, q\u0302 = min{q, `}, \u03b3\u0302 = xp\u0302:q\u0302. It can be checked that \u03b3\u0302 \u2208 \u03a0. We also have \u03b1 < \u03b3\u0302 v \u03b2. Therefore, condition \u03b2 \u2208 \u03a6(\u03b1) implies that \u03b3\u0302 = \u03b2, and so p \u2264 k, q \u2265 `, and \u03b3 \u2208 \u039b\u2212k`(x).\n5 General case: O(nP \u2032|D|) algorithm In this section and in the next one we consider the case of a general commutative semiring (R,\u2295,\u2297) (without assuming the existence of an inverse operation for \u2295). This can be used for computing MAP in CRFs containing positive costs c\u03b1. The algorithm closely resembles the method in [10]; it is based on the same idea and has the same complexity. Our primary goal of presenting this algorithm is to motivate the O(nP log(`max + 1)) algorithm for the MAP problem given in the next section.\nFirst, we select \u03a0 as the set of proper prefixes of patterns in \u03a0\u25e6:\n\u03a0 = {\u03b1 | \u2203\u03b1+ \u2208 \u03a0\u25e6} (30)\nFor each \u03b1 \u2208 \u03a0s we will compute message\nMs(\u03b1) = \u2295\nx\u2208Xs(\u03b1;\u03a0s)\nf(x) (31)\nIn order to go from step s\u22121 to s, we will use an extended set of patterns \u03a0\u0302s:\n\u03a0\u0302s = {\u03b1 | \u03b1\u2212 \u2208 \u03a0s\u22121} \u222a {\u03b5s} (32) = {\u03b1c | \u03b1 \u2208 \u03a0s\u22121, c \u2208 Ds:s} \u222a {\u03b5s}\nIt can be checked that \u03a0s \u2286 \u03a0\u0302s and \u03a0\u25e6s \u2286 \u03a0\u0302s (33)\nIn step s we compute values Ms(\u03b1) in eq. (31) for all \u03b1 \u2208 \u03a0\u0302s. Note, we now use the generalized definition of Xs(\u03b1; \u03a0s) (eq. (9)) since we may have \u03b1 /\u2208 \u03a0s. After completing step s, messages Ms(\u03b1) for \u03b1 \u2208 \u03a0\u0302s\u2212\u03a0s can be discarded.\nOur algorithm is given below. We have |\u03a0\u0302s|=P \u2032|D|+ 1 for indexes s that are sufficiently far from the boundary, and thus the algorithm\u2019s complexity is \u0398(nP \u2032|D|) (if Lemma 1 is used for computing values \u03c6(\u03b1)). Algorithm 4 Computing Z = \u2295\nx\u2208D1:n f(x)\n1: initialize messages: set M0(\u03b50) := O 2: for s = 1, . . . , n traverse nodes \u03b1 \u2208 \u03a0\u0302s of tree G[\u03a0\u0302s] starting from the leaves and set\nMs(\u03b1) := [ \u03c6(\u03b1)\u2297Ms\u22121(\u03b1\u2212) ] \u2295 \u2295 (\u03b1,\u03b2)\u2208E[\u03a0\u0302s],\u03b2 /\u2208\u03a0s Ms(\u03b2) (34)\nIf \u03b1 = \u03b5s then use Ms\u22121(\u03b1 \u2212) = O 3: return Z := \u2295\n\u03b1\u2208\u03a0nMn(\u03b1)\nTheorem 9. Algorithm 4 is correct.\nRemark 2 As we already mentioned, Algorithm 4 resembles the algorithm in [10]. The latter computes the same set of messages as we do but using the following recursion: for a pattern \u03b1 \u2208 \u03a0s \u2212 {\u03b5s} they set\nMs(\u03b1) := \u2295\n\u03b3\u2208Ts\u22121(\u03b1\u2212)\u2212 \u22c3\n(\u03b1,\u03b2)\u2208E[\u03a0s] Ts\u22121(\u03b2\u2212)\n\u03c6(\u03b3a)\u2297Ms\u22121(\u03b3) (35)\nwhere a = \u03b1s:s is the last letter of \u03b1 and Ts\u22121(\u03b2) = {\u03b3 | \u03b3 = \u2217\u03b2, \u03b3 \u2208 \u03a0s\u22121} for \u03b2 \u2208 \u03a0s\u22121 is the set of patterns in the branch of G[\u03a0s\u22121] rooted at \u03b2. It can be shown that updates (34) and (35) are equivalent: they need exactly the same number of additions (and the same number of multiplications, if \u03c6(\u03b3a) in eq. (35) is replaced with \u03c6(\u03b1) and moved before the sum)."}, {"heading": "5.1 Proof of Theorem 9", "text": "To prove the correctness, we need to show that eq. (34) holds for each \u03b1 \u2208 \u03a0\u0302s.\nLemma 10. For any \u03b1 \u2208 \u03a0\u0302s there holds\n\u03c6(\u03b1)\u2297Ms\u22121(\u03b1\u2212) = \u2295\nx\u2208Xs(\u03b1;\u03a0\u0302s)\nf(x) (36)\nProof. For \u03b1 = \u03b5s the claim is trivial: we have D s:s \u2286 \u03a0\u0302s (since \u03b5s\u22121 \u2208 \u03a0s\u22121), therefore Xs(\u03b1; \u03a0\u0302s) = \u2205 and the sum in (36) is O. We thus assume that \u03b1 \u2208 \u03a0\u0302s\u2212{\u03b5s}. Using definition (33), it can be checked that the mapping x 7\u2192 x\u2212 is a bijection Xs(\u03b1; \u03a0\u0302s) \u2192 Xs\u22121(\u03b1\u2212; \u03a0s\u22121). Consider x \u2208 Xs(\u03b1; \u03a0\u0302s). We claim that if x = \u2217\u03b3 and \u03b3 \u2208 \u03a0\u25e6 then |\u03b3| \u2264 |\u03b1|. Indeed, we have \u03b3 \u2208 \u03a0\u0302s (since \u03a0\u25e6s \u2286 \u03a0\u0302s), and so if |\u03b3| > |\u03b1| then x /\u2208 Xs(\u03b1; \u03a0\u0302s) - a contradiction.\nUsing the claim, we conclude that \u03c6(\u03b1)\u2297 f(x\u2212) = f(x). This implies the lemma.\nThe fact \u03a0s \u2286 \u03a0\u0302s implies the following characterization of Xs(\u03b1; \u03a0s) for \u03b1 \u2208 \u03a0\u0302s:\nXs(\u03b1; \u03a0s) = { x \u2208 Xs(\u03b1)\nx 6= \u2217\u03b2 for any \u03b2 in the subtree of \u03b1 in G[\u03a0\u0302s] with \u03b2 \u2208 \u03a0s, \u03b2 6= \u03b1 } where the subtree of \u03b1 in G[\u03a0\u0302s] is defined as the set of descendants of \u03b1 in G[\u03a0\u0302s] (including \u03b1).\nNow it becomes clear that Xs(\u03b1; \u03a0\u0302s) \u2286 Xs(\u03b1; \u03a0s) and Xs(\u03b1; \u03a0s)\u2212Xs(\u03b1; \u03a0\u0302s) equals the set of partial labelings x \u2208 Xs(\u03b1) such that\n\u2022 x ends with \u03b2 \u2208 \u03a0\u0302s \u2212\u03a0s, (\u03b1, \u03b2) \u2208 E[\u03a0\u0302s], and\n\u2022 x does not end with any pattern \u03b3 \u2208 \u03a0s from the subtree of \u03b2 in G[\u03a0\u0302s].\nIt is easy to check that the last set of partial labelings equals Xs(\u03b2; \u03a0s), and such sets for different \u03b2\u2019s are disjoint. We showed that Xs(\u03b1; \u03a0s) is a disjoint union of sets Xs(\u03b1; \u03a0\u0302s) and Xs(\u03b2; \u03a0s) for (\u03b1, \u03b2) \u2208 E[\u03a0\u0302s], \u03b2 /\u2208 \u03a0s. This fact together with Lemma 10 implies eq. (34).\n6 General case: O(nP logP ) algorithm\nIn the previous section we presented an algorithm for a general commutative semiring with complexity O(nP \u2032|D|). In some applications the size of the input alphabet can be very large (e.g. hundreds or thousands), so the technique may be very costly. Below we present a more complicated version with complexity O(nP logP ). If (R,\u2295,\u2297) = (R,min,+) then this can be reduced to O(nP log(`max + 1)) using the algorithm for Range Minimum Queries by [1]. We assume that D \u2286 \u0393.\nWe will use the same definitions of sets \u03a0s and \u03a0\u0302s as in the previous section, and the same intepretation of messages Ms(\u03b1) given by eq. (31). We need to solve the following problem: given messages Ms\u22121(\u03b1) for \u03b1 \u2208 \u03a0s\u22121, compute messages Ms(\u03b1) for \u03b1 \u2208 \u03a0s.\nRecall that in the previous section this was done by computing messages Ms(\u03b1) for patterns in the extended set \u03a0\u0302s of size O(P\n\u2032|D|). The idea of our modification is to compute these messages only for patterns in the set \u03a3s where\n\u03a3\u25e6s \u2286 \u03a3s \u2286 \u03a0\u0302s \u03a3\u25e6s = \u03a0s \u222a\u03a0\u25e6s |\u03a3s| \u2264 2|\u03a3\u25e6s|\nNote that |\u03a3\u25e6s| \u2264 P +1. Patterns in \u03a3s will be called special. To define them, we will use the following notation for a node \u03b1 \u2208 \u03a0\u0302s:\n\u2022 \u03a6\u0302s(\u03b1) is the set of children of \u03b1 in the tree G[\u03a0\u0302s].\n\u2022 T\u0302s(\u03b1) is the set of nodes in the subtree of G[\u03a0\u0302s] rooted at \u03b1. We have \u03b1 \u2208 T\u0302s(\u03b1) \u2286 \u03a0\u0302s.\nWe now define set \u03a3s as follows: pattern \u03b1 \u2208 \u03a0\u0302s is special if either (i) \u03b1 \u2208 \u03a3\u25e6s, or (ii) \u03b1 has at least two children \u03b21, \u03b22 \u2208 \u03a6\u0302s(\u03b1) such that subtree T\u0302s(\u03b2i) for i \u2208 {1, 2} contains a pattern from \u03a3\u25e6s, i.e. T\u0302s(\u03b2i) \u2229 \u03a3\u25e6s 6= \u2205.\nThe set of remaining patterns \u03a0\u0302s \u2212 \u03a3s will be split into two sets As and Bs as follows:\n\u2022 As is the set of patterns \u03b1 \u2208 \u03a0\u0302s \u2212 \u03a3\u25e6s such that subtree T\u0302s(\u03b1) does not contain patterns from \u03a3\u25e6s.\n\u2022 Bs is the set of patterns \u03b1 \u2208 \u03a0\u0302s \u2212 \u03a3\u25e6s such that \u03b1 has exactly one child \u03b2 in G[\u03a0\u0302s] for which T\u0302s(\u03b2) \u2229 \u03a3\u25e6s 6=\u2205.\nClearly, \u03a0\u0302s is a disjoint union of As, Bs and \u03a3s. Consider a node \u03b1 \u2208 Bs. From the definition, \u03b1 has exactly one link to a child in G[\u03a0\u0302s] that belongs to Bs \u222a \u03a3s. If this child does not belong to \u03a3s, then it belongs to Bs and the same argument can be repeated for it. By following such links we eventually get to a node in \u03a3s; the first such node will be denoted as \u03b1\u2193.\nWe will need two more definitions. For an index t and patterns \u03b1, \u03b2 ending at position t with \u03b2 = +\u03b1 we denote\nWt(\u03b1) = \u2295\nx\u2208Xt(\u03b1)\nf(x) (37a)\nVt(\u03b1, \u03b2) = \u2295\nx\u2208Xt(\u03b1)\u2212Xt(\u03b2)\nf(x) (37b)\nWe can now formulate the structure of the algorithm (see Algorithm 5).\nAlgorithm 5 Computing Z = \u2295\nx\u2208D1:n f(x)\n1: initialize messages: set M0(\u03b5) := O 2: for each s = 1, . . . , n traverse nodes \u03b1 \u2208 \u03a3s of tree G[\u03a3s] starting from the leaves and set\nMs(\u03b1) := \u03c6(\u03b1)\u2297 [Ms\u22121(\u03b1\u2212)\u2295As(\u03b1)\u2295Bs(\u03b1)]\u2295 \u2295\n(\u03b1,\u03b2)\u2208E[\u03a3s],\u03b2 /\u2208\u03a0s\nMs(\u03b2) (38)\nwhere\nAs(\u03b1) = \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229As\nWs\u22121(\u03b2 \u2212) (39a)\nBs(\u03b1) = \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229Bs\nVs\u22121(\u03b2 \u2212, \u03b2\u2193 \u2212) (39b)\nIf \u03b1 = \u03b5s then use Ms\u22121(\u03b1 \u2212) := O 3: return Z := \u2295\n\u03b1\u2208\u03a0nMn(\u03b1)\nTo fully specify the algorithm, we still need to describe how we compute quantities As(\u03b1) and Bs(\u03b1) defined by eq. (39a) and (39b). This is addressed by the theorem below.\nTheorem 11. (a) Algorithm 5 is correct. (b) There holds |\u03a3s| \u2264 2|\u03a3\u25e6s| \u2212 1 \u2264 2P + 1. (c) Let h be the maximum depth of tree G[\u03a0s\u22121]. (Note, h \u2264 `max + 1.) With an O(P \u2032 log h) preprocessing, values Vs\u22121(\u03b1, \u03b2) for any \u03b1, \u03b2 \u2208 \u03a0s\u22121 with \u03b2 = +\u03b1 can be computed in O(log h) time. (d) Values As(\u03b1) for all \u03b1 \u2208 \u03a3s can be computed in O(P logP ) time, or in O(P ) time when (R,\u2295,\u2297)= (R,min,+).\nClearly, the theorem implies that the algorithm can be implemented in O(nP logP ) time, or in O(nP log(`max + 1)) time when (R,\u2295,\u2297)=(R,min,+). To see this, observe that the sum in (39b) is effectively over a subset of children of \u03b1 in the tree G[\u03a3s] (see Fig. 2), and this tree has size O(P ).\nBefore presenting the proof, let us make a few remarks. To give some insights into how we prove the theorem, let us make a few remarks.\nIt can be easily checked that graph G[\u03a0\u0302s] has the following structure: the root \u03b5s has |D| children, and for each child c \u2208 Ds:s \u2286 \u03a0\u0302s the subtree of G[\u03a0\u0302s] rooted at c is isomorphismic to the tree G[\u03a0s\u22121]. The isomorphism T\u0302s(c)\u2192 \u03a0s\u22121 is given by the the mapping \u03b1 7\u2192 \u03b1\u2212.\nFor nodes \u03b1, \u03b2 \u2208 \u03a0s\u22121 with \u03b2 = +\u03b1 we denote Ps\u22121(\u03b1, \u03b2) to be the unique path from \u03b1 to \u03b2 in G[\u03a0s\u22121] (treated as a set of edges in E[\u03a0s\u22121]). Analogously, for nodes \u03b1, \u03b2 \u2208 \u03a0\u0302s with \u03b2 = +\u03b1 let P\u0302s(\u03b1, \u03b2) be the unique path from \u03b1 to \u03b2 in G[\u03a0\u0302s]. It follows from the previous paragraph that if \u03b1 6= \u03b5s then path P\u0302s(\u03b1, \u03b2) is isomorphic to the path Ps\u22121(\u03b1\u2212, \u03b2\u2212)."}, {"heading": "6.1 Proof of Theorem 11(a)", "text": "The statement is equivalent to the correctness of (38). Let us first divide the sum over \u03b2 in the last expression (38) into two parts: nodes \u03b2 that belong to \u03a6\u0302(\u03b1) and those that do not:\u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229(\u03a3s\u2212\u03a0s)\nMs(\u03b2)\u2295 \u2295\n(\u03b1,\u03b2)\u2208E[\u03a3s],\u03b2 /\u2208\u03a0s\u222a\u03a6s(\u03b1)\nMs(\u03b2) (40)\nIt is easy to see that the second sum can be written as \u2211\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229BsM s(\u03b2\u2193) (see Fig. 2), where\nM s(\u03b3) = { Ms(\u03b3) if \u03b3 /\u2208 \u03a0s O otherwise\n(41)\nUsing the distributive law, we can rewrite (38) as Ms(\u03b1) := [ \u03c6(\u03b1)\u2297Ms\u22121(\u03b1\u2212) ] \u2295\n\u2295 \u03b2\u2208\u03a6\u0302s(\u03b1)\u2229As [\u03c6(\u03b1)\u2297Ws\u22121(\u03b2\u2212)]\n\u2295 \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229Bs\n[\u03c6(\u03b1)\u2297 Vs\u22121(\u03b2\u2212, \u03b2\u2193\u2212)]\u2295M s(\u03b2\u2193)\n\u2295 \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229(\u03a3s\u2212\u03a0s)\nMs(\u03b2) (42)\nWe will use eq. (34) (for which the correctness is already proved) for the case when \u03b1 \u2208 \u03a3s. We can rewrite it as follows (we use the fact that As \u2229\u03a0s = Bs \u2229\u03a0s = \u2205):\nMs(\u03b1) := [ \u03c6(\u03b1)\u2297Ms\u22121(\u03b1\u2212) ] \u2295 \u2295 \u03b2\u2208\u03a6\u0302s(\u03b1)\u2229As Ms(\u03b2)\n\u2295 \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229Bs\nMs(\u03b2) \u2295 \u2295\n\u03b2\u2208\u03a6\u0302s(\u03b1)\u2229(\u03a3s\u2212\u03a0s)\nMs(\u03b2) (43)\nThe first and the last terms of the sum in (43) equal to that of the sum in (42). The lemma below implies that the same holds for the second and third terms, thus proving the correctness of eq. (42).\nLemma 12. (a) For any \u03b1 \u2208 As there holds\nMs(\u03b1) = \u03c6(\u03b1)\u2297Ws\u22121(\u03b1\u2212) (44)\n(b) For any \u03b1 \u2208 Bs there holds\nMs(\u03b1) = [\u03c6(\u03b1)\u2297 Vs\u22121(\u03b1\u2212, \u03b1\u2193\u2212)]\u2295M s (\u03b1\u2193) (45)\nProof. Part (a) Suppose that \u03b1 \u2208 As. This means that there are no patterns \u03b2 \u2208 \u03a0\u25e6s of the form \u03b2 = +\u03b1 (recall that \u03a0\u25e6s \u2286 \u03a3\u25e6s). This in turn implies that Ms(\u03b1) = Ws(\u03b1). This also implies that for any x \u2208 Xs(\u03b1) there holds f(x) = f(x\u2212), and consequently Ws(\u03b1) = \u03c6(\u03b1)\u2297Ws\u22121(\u03b1\u2212). Part (b) Suppose that \u03b1 \u2208 Bs. The definition of Bs implies that set T\u0302s(\u03b1)\u2212 T\u0302s(\u03b1\u2193) does not contain nodes in \u03a0s or in \u03a0 \u25e6 s. Using this fact and the definition of sets Xs(\u00b7), Xs(\u00b7; \u00b7) we get the following.\n(i) If \u03b1\u2193 \u2208 \u03a0s then Xs(\u03b1; \u03a0s) = Xs(\u03b1)\u2212Xs(\u03b1\u2193). (ii) If \u03b1\u2193 /\u2208 \u03a0s then Xs(\u03b1; \u03a0s) is a disjoint union of Xs(\u03b1)\u2212Xs(\u03b1\u2193) and Xs(\u03b1\u2193; \u03a0s). (iii) Partial labeling x \u2208 Xs(\u03b1) \u2212 Xs(\u03b1\u2193) cannot end with a pattern \u03b2 = +\u03b1 \u2208 \u03a0\u25e6s. (If such \u03b2 exists then from the fact above we get \u03b2 \u2208 T\u0302s(\u03b1\u2193), i.e. \u03b2 = \u2217\u03b1\u2193 and x \u2208 Xs(\u03b1\u2193) - a contradiction.) Therefore, for such x we have f(x) = \u03c6(\u03b1) \u2297 f(x\u2212). This implies that \u2211 x\u2208Xs(\u03b1)\u2212Xs(\u03b1\u2193) f(x) =\n\u03c6(\u03b1)\u2297 Vs\u22121(\u03b1\u2212, \u03b1\u2193\u2212). Recall that Ms(\u03b1) = \u2211\nx\u2208Xs(\u03b1;\u03a0s) f(x). Using this fact and properties (i)-(iii), we conclude that (45) holds in each of the two cases (\u03b1\u2193\u2208\u03a0s and \u03b1\u2193 /\u2208\u03a0s)."}, {"heading": "6.2 Proof of Theorem 11(b)", "text": "For a node \u03b1 \u2208 \u03a0\u0302s we denote T \u25e6s (\u03b1) = T\u0302s(\u03b1) \u2229 \u03a3\u25e6s. Let us consider the process of a breadth-first search in the tree G[\u03a0\u0302s] starting from the root. At each step we will keep a certain set of nodes of the tree (which we call active nodes), and the transition to the next step is made by choosing one of the active nodes and replacing it with its children. The process stops when the set of active nodes becomes equal to the set of the leaves of the tree. To each step of the process we correspond a partition of the set \u03a3\u25e6s. The partition is defined by the following\nrule: if \u03b11, . . . , \u03b1k are active nodes, then the partition is \u03a3 \u25e6 s = k\u22c3 `=1 T \u25e6s (\u03b1`) \u22c3 \u03b1\u2208\u03a3\u25e6s ,\u03b1/\u2208T \u25e6s (\u03b1`),`=1,k {\u03b1}. Let us denote the partition at step t as Dt. Partitions of the set \u03a0s is a poset with respect to the natural order defined as follows: {Si}i\u2208I \u2264 {Pj}j\u2208J if for any i \u2208 I there is j \u2208 J such that Si \u2286 Pj . It is easy to see that D0 \u2265 D1 \u2265 D2 \u2265 . . .. Moreover, if a chosen active node \u03b1 at step t is a special one and does not belong to \u03a3\u25e6s then Dt > Dt+1. Indeed, there are at least two children of \u03b1, denoted as \u03b11 and \u03b12, such that sets T \u25e6 s (\u03b11) and T \u25e6 s (\u03b12) are nonempty (by the definition of a special node). As step t+ 1 these sets are separate components of partition Dt+1, but at step t these sets still belong to the same component of Dt; thus, Dt 6= Dt+1.\nWe know that the length of a chain Dt1 > Dt2 > . . . cannot exceed |\u03a3\u25e6s|. We conclude that the number of special patterns that do not belong to \u03a3\u25e6s is bounded by |\u03a3\u25e6s|\u22121; this implies Theorem 11(b)."}, {"heading": "6.3 Proof of Theorem 11(c)", "text": "For brevity denote t = s\u2212 1, and define a set of pairs\nJ = {(\u03b1, \u03b2) | \u03b1, \u03b2 \u2208 \u03a0t, \u03b2 is a strict descendant of \u03b1 in G[\u03a0t]}\nNote that E[\u03a0t] \u2286 J . In this section we describe a O(P \u2032 log h) preprocessing which will allow computing values Vt(\u03b1, \u03b2) for any (\u03b1, \u03b2) \u2208 J in O(log h) time. The procedure will be based on the following observation; it follows trivially from the definition (37b).\nLemma 13. For any (\u03b1, \u03b2) \u2208 J there holds\nVt(\u03b1, \u03b2) = \u2295\n(\u03b1\u2032,\u03b2\u2032)\u2208Pt(\u03b1,\u03b2)\nVt(\u03b1 \u2032, \u03b2\u2032) (46)\nDuring preprocessing we will compute values Vt(\u03b1, \u03b2) for pairs (\u03b1, \u03b2) in a certain set J\u0303 \u2286 J of size O(P \u2032 log h). In order to define J\u0303 , we need some notation. For a pattern \u03b1 \u2208 \u03a0t let h\u03b1 = |Pt(\u03b5t, \u03b1)| be the height of \u03b1 in G[\u03a0t], and for an integer d \u2208 [0, h\u03b1] let \u03b1\u2191d be the node of tree G[\u03a0t] obtained from \u03b1 by taking d steps towards the root. We now define\nJ\u0303 = {(\u03b1\u2191d, \u03b1) | \u03b1 \u2208 \u03a0t, d \u2208 [0, h\u03b1], d = 2r for r \u2208 Z\u22650}\nThe preprocessing will consist of 3 steps. Step 1: compute values Wt(\u03b1) for all \u03b1 \u2208 \u03a0t. We do it by traversing nodes \u03b1 \u2208 \u03a0t of tree G[\u03a0t] and setting\nWt(\u03b1) := Mt(\u03b1)\u2295 \u2295\n(\u03b1,\u03b2)\u2208E[\u03a0t]\nWt(\u03b2) (47)\nThis takes O(P \u2032) time. Step 2: go through \u03b1 \u2208 \u03a0t and compute values Vt(\u03b1, \u03b2) for all \u03b2 \u2208 \u03a6t(\u03b1) where \u03a6t(\u03b1) is the set of children of \u03b1 in G[\u03a0t].\nA naive way is to use the formula Vt(\u03b1, \u03b2) = Mt(\u03b1)\u2295 \u2295\n\u03b3\u2208\u03a6t(\u03b1)\u2212{\u03b2}\nWt(\u03b3)\nfor all \u03b2 \u2208 \u0393t(\u03b1); however, this would take O(k2) time where k = |\u03a6t(\u03b1)|. Instead, we do the following. Let us order patterns in \u03a6t(\u03b1) arbitrarily: \u03a6t(\u03b1) = {\u03b21, . . . , \u03b2k}. For i \u2208 [1, k] denote\n\u2212\u2192 S i = i\u22121\u2295 j=1 Wt(\u03b2j) \u2190\u2212 S i = k\u2295 j=i+1 Wt(\u03b2j)\nWe compute these values in O(k) time by setting \u2212\u2192 S 1 := O, \u2190\u2212 S k := O and then using recursions\n\u2212\u2192 S i+1 := \u2212\u2192 S i \u2295Wt(\u03b2i)\n\u2190\u2212 S i\u22121 := \u2190\u2212 S i \u2295Wt(\u03b2i)\nAfter that we set Vt(\u03b1, \u03b2i) := Mt(\u03b1)\u2295 \u2212\u2192 S i \u2295 \u2190\u2212 S i\nFor a given \u03b1 \u2208 \u03a0t the procedure takes O(|\u03a6t(\u03b1)|) time, and thus for all \u03b1 \u2208 \u03a0t it takes O(P \u2032) time. We now have values Vt(\u03b1, \u03b2) for all (\u03b1, \u03b2) \u2208 E[\u03a0t]. Step 3: compute values Vt(\u03b1, \u03b2) for all (\u03b1, \u03b2) \u2208 J\u0303 using the recursion\nVt(\u03b1 \u21912d, \u03b1) := Vt(\u03b1 \u21912d, \u03b1\u2191d) + Vt(\u03b1 \u2191d, \u03b1)\nfor d = 20, 21, . . . , 2r, . . . and (\u03b1\u21912d, \u03b1) \u2208 J\u0303 . Evaluating queries for (\u03b1, \u03b2) \u2208 J We showed how to compute values Vt(\u03b1, \u03b2) for (\u03b1, \u03b2) \u2208 J\u0303 in time O(P \u2032 log h); let us now describe how to compute value Vt(\u03b1, \u03b2) for a given (\u03b1, \u03b2) \u2208 J in time O(log h). Let us construct a sequence \u03b20, \u03b21, . . . , as follows: \u03b20 = \u03b2, and for i \u2265 0 let \u03b2i+1 = \u03b2\u2191di where d is the maximum value such that d = 2r for r \u2208 Z\u22650 and \u03b2\u2191di is still a descendant of \u03b1. We stop when we get \u03b2k = \u03b1; clearly, this happens after k = O(log h) steps. We now set\nVt(\u03b1, \u03b2) := k\u22121\u2295 i=0 Vt(\u03b2i+1, \u03b2i)"}, {"heading": "6.4 Proof of Theorem 11(d)", "text": "We will consider the general case of a commutative semiring and the case when (R,\u2295,\u2297)=(R,min,+); the latter will be called the MAP case.\nLet d\u03b1 for \u03b1 \u2208 \u03a0s\u22121 be the number of children of \u03b1 in G[\u03a0s\u22121], dmax = max\u03b1\u2208\u03a0s\u22121 d\u03b1, and d\u0303\u03b1 for \u03b1 \u2208 \u03a3s be the number of children of \u03b1 in G[\u03a3s]. We will present a O( \u2211 \u03b1\u2208\u03a0s\u22121 d\u03b1 log d\u03b1) preprocessing technique that will allow computing value As(\u03b1) for \u03b1 \u2208 \u03a3s \u2212 {\u03b5s} in time O((d\u0303\u03b1 + 1) log d\u03b1\u2212). The resulting complexity will be\nO( \u2211\n\u03b1\u2208\u03a0s\u22121 d\u03b1 log dmax) + \u2211 \u03b1\u2208\u03a3s O((d\u0303\u03b1 + 1) log dmax) = O(P log dmax)\nIn the MAP case (i.e. when (R,\u2295,\u2297) = (R,min,+)) we will present a faster solution. Namely, the preprocessing will take O( \u2211 \u03b1\u2208\u03a0s\u22121 d\u03b1) = O(P\n\u2032) time, and computing value As(\u03b1) for \u03b1 \u2208 \u03a3s \u2212 {\u03b5s} will take O(d\u0303\u03b1 + 1) time, leading to the overall complexity O(P ). For that we will use the Range Minimum Query (RMQ) problem which is defined as follows: given N numbers z1, . . . , zN , compute\nmink\u2208I zk for a given interval I = [i, j] \u2286 [1, N ]. It is known [1] that with an O(N) preprocessing each query for can be answered in O(1) time per interval.\nAs in the previous section, we denote t = s\u2212 1. We assume that for each \u03b1 \u2208 \u03a0t we already have values Wt(\u03b1) for all \u03b1 \u2208 \u03a0t (they were computed in the previous section). Preprocessing Consider \u03b1 \u2208 \u03a0t, and let us fix an ordering of children of \u03b1: \u03a6t(\u03b1) = {\u03b21, . . . , \u03b2d} where d = d\u03b1. For an interval I \u2286 [1, d] we denote\nSI(\u03b1) = \u2295 i\u2208I Wt(\u03b2i) (48)\nThe goal of preprocessing is to build a data structure that we will allow an efficient computation of SI(\u03b1) for any given interval I.\nIn the MAP case we simply run the preprocessing of [1] for the sequence Wt(\u03b21), . . . ,Wt(\u03b2d); this takes O(d) time. Value SI(\u03b1) for an interval I can then be computed in O(1) time.\nIn the general case we do the following. Define a set of intervals\nJd = {[i, j] \u2286 [1, d] | j \u2212 i = 2r \u2212 1, r \u2208 Z\u22650}\nNote that |Jd| = O(d log d). We compute quantities SI(\u03b1) for all I \u2208 Jd. This can be done in O(d log d) time by setting S[i,i](\u03b1) := Wt(\u03b2i) for i \u2208 [1, d] and then using recursions\nS[i,i+2\u03b4\u22121](\u03b1) = S[i,i+\u03b4\u22121](\u03b1)\u2295 S[i+\u03b4,i+2\u03b4\u22121](\u03b1)\nfor \u03b4 = 20, 21, . . .. Value SI(\u03b1) for an interval I can now be computed in O(log d) time. Indeed, we can represent I\nas a disjoint union of m = O(log d) intervals from Jd: I = \u22c3m i=1 Ii with Ii \u2208 Jd. We can then use the formula\nSI(\u03b1) = m\u2295 i=1 SIi(\u03b1) (49)\nComputing As(\u03b1) for \u03b1 \u2208 \u03a3s\u2212{\u03b5s} Denote d = d\u03b1\u2212 . As discussed earlier, \u03a6\u0302s(\u03b1) (the set of children of \u03b1 in G[\u03a0\u0302s]) is isomorphic to \u03a6s\u22121(\u03b1\n\u2212). Let \u0393\u0302s(\u03b1) = {\u03b21, . . . , \u03b2d} be the ordering of patterns in \u03a6\u0302s(\u03b1) such that \u03b2 \u2212 1 , . . . , \u03b2 \u2212 d is the ordering of patterns in \u03a6s\u22121(\u03b1\n\u2212) chosen in the preprocessing step. We need to compute\nAs(\u03b1) = \u2295 i\u2208J Ws\u22121(\u03b2 \u2212 i ) , J , {i \u2208 [1, d] | \u03b2i \u2208 As}\nDenote J = [1, d] \u2212 J . We can represent J as a disjoint union of at most |J | + 1 intervals I1, . . . , Im where Ii \u2286 [1, p]. Clearly, |J | = d\u0303\u03b1 (see Fig. 2), and so m \u2264 d\u0303\u03b1 + 1. We can write\nAs(\u03b1) = m\u2295 i=1 SIi(\u03b1 \u2212) (50)\nAs discussed above, each value SIi(\u03b1 \u2212) can be computed in O(1) time in the MAP case and in O(log d) in the general case. Thus, computing As(\u03b1) takes respectively O(d\u0303\u03b1+1) and O((d\u0303\u03b1+1) log d\u03b1\u2212) time, as desired."}, {"heading": "7 MAP for non-positive costs", "text": "In this section we assume that (R,\u2295,\u2297)=(R, min,+) and c\u03b1 \u2264 0 for all \u03b1 \u2208 \u03a0\u25e6. [2] gave an algorithm that makes \u0398(nP ) comparisons and \u0398(nP ) additions. We will present a modification that makes only O(n|I(\u0393)|) comparisons. The number of additions in general will still be O(nP ), but we will show that in certain scenarios it can be reduced using a Fast Fourier Transform (FFT).\nWe will assume that \u0393 contains at least one word \u03b1 with |\u03b1| = 1 (it can always be added if needed). As usual, we first select a set of patterns \u03a0 with \u03a00 = {\u03b50}; this step will be described later. For a pattern \u03b1 \u2208 \u03a0 let \u03b1\u2190 be the longest proper prefix of \u03b1 that is in \u03a0 (\u03b1 = \u03b1\u2190+, \u03b1\u2190 \u2208 \u03a0). If \u03a0 does not contains proper prefixes of \u03b1 then \u03b1\u2190 is undefined.\nWe can now present the algorithm.\nAlgorithm 6 Computing Z = min x\u2208D1:n\nf(x) (if c\u03b1 \u2264 0)\n1: initialize messages: set M0(\u03b50) := 0 2: for s = 1, . . . , n traverse nodes \u03b1 \u2208 \u03a0s of forest G[\u03a0s] starting from the leaves and set\nMs(\u03b1) := min{Mp(\u03b1\u2190) + \u03c8(\u03b1), min (\u03b1,\u03b2)\u2208E[\u03a0s] Ms(\u03b2)} (51)\nwhere p is the end position of \u03b1\u2190 (\u03b1\u2190 = ([\u00b7, p], \u00b7)) and \u03c8(\u03b1) = f(\u03b1)\u2212 f(\u03b1\u2190). If \u03b1\u2190 is undefined then ignore the first expression in (51).\n3: return Z := min\u03b1\u2208\u03a0nMn(\u03b1)\nSelecting \u03a0 It remains to specify how to choose set \u03a0. For patterns \u03b1, \u03b2, \u03b3 we define\n\u3008\u03b1|\u03b2|\u03b3\u3009 = {u = +\u03b2 + | \u03b1\u03b2\u03b3 = \u2217u\u2217} (52)\nTheorem 14. Suppose that \u03a00 = {\u03b50} and set \u03a0 contains set\n\u03a0\u0303 = { \u03b2 \u2203 labeling x\u03b1\u03b2\u03b3y \u2208 D1:n s.t. (a) \u03b1\u03b2, \u03b2\u03b3 \u2208 \u03a0\u25e6; (b) \u3008x\u03b1|\u03b2|\u03b3y\u3009 \u2229\u03a0\u25e6 = \u2205 } (53)\nThen Alg. 6 returns the correct value of Z= min x\u2208D1:n f(x).\nA proof of this theorem is given in Sec. 7.2. A simple valid option is to set \u03a0 = {\u03b1 | \u2203\u03b1\u2217, \u2217\u03b1 \u2208 \u03a0\u25e6}. Computing set \u03a0\u0303 is slightly more\ncomplicated, but can still be done in polynomial time for a given \u03a0 (we omit this procedure). In order to analyze set \u03a0\u0303, let us define\nI\u03b4 = { \u03b2 \u2203 word x\u03b1\u03b2\u03b3y with |x| = |y| = \u03b4 s.t. (a) \u03b1\u03b2, \u03b2\u03b3 \u2208 \u0393; (b) \u3008x\u03b1|\u03b2|\u03b3y\u3009 \u2229 \u0393 = \u2205 } where set \u3008\u00b7|\u00b7|\u00b7\u3009 for words is defined similarly to (52):\n\u3008\u03b1|\u03b2|\u03b3\u3009 = {\u03b1\u0302\u03b2\u03b3\u0302 | \u03b1 = \u2217\u03b1\u0302, \u03b3 = \u03b3\u0302\u2217 and \u03b1\u0302, \u03b3\u0302 6= \u03b5} (54)\nAs \u03b4 increases, set I\u03b4 monotonically shrinks, and stops changing after \u03b4 \u2265 `max = max\u03b1\u2208\u0393 |\u03b1|. We denote this limit set as I\u221e, so that I\u221e \u2286 I0 \u2286 I(\u0393)\u222a{\u03b5}. It can be seen that \u03a0\u0303s = {([\u00b7, s], \u03b1) |\u03b1 \u2208 I\u221e} for all s \u2208 [`max, n\u2212`max+1]. Complexity Assume that we use \u03a0 = \u03a0\u0303. The algorithm performs two types of operations: comparisons (to compute minima) and arithmetic operations (to compute the first expression in (51)). The\nnumber of comparisons does not exceed the total number of edges in graphs G[\u03a0s] = (\u03a0s, E[\u03a0s]) for s \u2208 [1, n], which is smaller than the number of nodes (since graphs are forests). Thus, comparisons take O(n|I\u221e|) time.\nThe time for arithmetic operations depends on how we compute quantities f(\u03b1). One possible approach is to use Lemma 1 for computing f(\u03b1) for all \u03b1 \u2208 \u03a0\u0302 where \u03a0\u0302 is the set of prefixes of patterns in \u03a0\u25e6 (note that \u03a0 \u2286 \u03a0\u0302). We have |\u03a0\u0302s| \u2264 P + 1, and therefore the resulting overall complexity is O(nP ). Next, we describe an alternative approach based on a Fast Fourier Transform."}, {"heading": "7.1 Computing f(\u03b1) using FFT", "text": "For a word \u03b1 and index s \u2265 |\u03b1| let \u03b1s be the pattern ([s\u2212 |\u03b1|+ 1, s], \u03b1). It is easy to see that\nf(\u03b1s) = \u2211 \u03b2\u2208\u0393 fs(\u03b1|\u03b2) where fs(\u03b1|\u03b2) = \u2211 t:\u03b1s=\u2217\u03b2t\u2217 c\u03b2t\nLemma 15. For fixed words \u03b1, \u03b2 quantities fs(\u03b1|\u03b2) for s \u2208 [1, n] can be computed in O(n log n) time.\nProof. We assume that |\u03b1| \u2265 |\u03b2|, otherwise the claim is trivial. Let p = |\u03b1| \u2212 |\u03b2| + 1, and define sequences a \u2208 Rn\u2212|\u03b1|+1, b \u2208 Rn\u2212|\u03b2|+1, \u03bb \u2208 {0, 1}p via\nai = fi+|\u03b1|(\u03b1|\u03b2) \u2200i \u2208 [1, n\u2212|\u03b1|] bj = c([j,j+|\u03b2|\u22121],\u03b2) \u2200j \u2208 [1, n\u2212|\u03b2|+1] \u03bbk = [\u03b1k:k+|\u03b2|\u22121 = \u03b2] \u2200k \u2208 [1, p]\nwhere [\u00b7] is the Iverson bracket. It can be checked that\nai = p\u2211 k=1 bi+k\u03bbk \u2200i \u2208 [1, n\u2212|\u03b1| ]\nThus, a is the convolution of b and the reverse of \u03bb. The convolution of such sequences can be computed in O(n log n) using a Fast Fourier Transform.\nIn practice this method can be useful for computing fs(\u03b1|\u03b2) when |\u03b1| |\u03b2|. A natural way to do this is first choose a subset S \u2286 \u0393 of words that are very often included as subwords in words from I\u221e (usually, this means S = {\u03b2 | \u03b2 \u2208 \u0393, |\u03b2| \u2264 \u03b4} where \u03b4 is some threshold constant). Then computing fs(\u03b1|\u03b2) for all \u03b1 \u2208 I\u221e and \u03b2 \u2208 S will take O (|I\u221e| \u00b7 |S|n log n) time. For \u03b2 \u2208 \u0393\u2212S quantities fs(\u03b1|\u03b2) can be computed directly.\nAn example of using such an approach is the following theorem; it is proved by taking \u03b4 = 1 and S = D.\nTheorem 16. Suppose \u0393 = D \u222a A where A consists of words of a fixed length `. Then Algorithm 6 can be implemented in O (|I\u221e| \u00b7 |D|n log n) time."}, {"heading": "7.2 Proof of Theorem 14 (correctness)", "text": "First, let us prove that for all patterns \u03b1 = ([\u00b7, s], \u00b7) \u2208 \u03a0 there holds\nMs(\u03b1) \u2265 min x=\u2217\u03b1\u2208D1:s f(x) (55)\nWe use induction on the order used in the algorithm. The base case \u03b1 = \u03b50 is ensured by the initialization step. Consider pattern \u03b1 \u2208 \u03a0 \u2212 {\u03b50}. Suppose that \u03b1\u2190 is defined; let p be the end\nposition of \u03b1\u2190. Consider partial labeling y = \u2217\u03b1\u2190 \u2208 D1:p, and let x be its unique extension by s\u2212 p letters (x = y+) such that x = \u2217\u03b1. Due to non-positivity of costs c\u03b2 we have\nf(x) = f(y) + \u03c8(\u03b1) + \u2211\n\u03b2=([i,j],\u00b7)\u2208\u03a0\u25e6 x=\u2217\u03b2\u2217 i\u2264s\u2212|\u03b1|, j>p\nc\u03b2 \u2264 f(y) + \u03c8(\u03b1)\nApplying the induction hypothesis and the inequality above yields the desired claim:\nMs(\u03b1) = min{Mp(\u03b1\u2190) + \u03c8(\u03b1), min (\u03b1,\u03b2)\u2208E[\u03a0s] Ms(\u03b2)}\n\u2265 min{ min y=\u2217\u03b1\u2190 f(y) + \u03c8(\u03b1), min (\u03b1,\u03b2)\u2208E[\u03a0s] min x=\u2217\u03b2 f(x)} \u2265 min{min x=\u2217\u03b1 f(x), min x=\u2217\u03b1 f(x)} = min x=\u2217\u03b1 f(x)\nwhere in the equations above x always denotes a partial labeling in D1:s and y denotes a partial labeling in D1:p. If \u03b1\u2190 is undefined then we can write similar inequalities but omitting expressions contaiting \u03b1\u2190.\nBy applying the claim to patterns \u03b1 = ([\u00b7, n], \u00b7) \u2208 \u03a0 we conclude that Z \u2265 minx\u2208D1:n f(x). The remainder of this section is devoted to the proof of the reverse inequality: Z \u2264 minx\u2208D1:n f(x).\nLet us fix x\u2217 \u2208 arg minx\u2208D1:n f(x). Let\n\u039b = {\u03b1 \u2208 \u03a0\u25e6 | x\u2217 = \u2217\u03b1\u2217}\nbe the set of patterns present in x\u2217, and\n\u039b\u0302 = {\u03b1 \u2208 \u039b | there is no \u03b1\u0302 \u2208 \u039b\u2212 {\u03b1}with \u03b1\u0302 = \u2217\u03b1\u2217}\nbe the set of maximal patterns in \u039b. We can assume w.l.o.g. that for each k \u2208 [1, n] there exists \u03b1 = ([i, j], \u00b7) \u2208 \u039b\u0302 with k \u2208 [i, j]. Indeed, if it is not the case for some k then we can modify x\u2217 by replacing the k-th letter of x\u2217 with some letter c \u2208 \u0393 \u2229D; this operation does not increase f(x\u2217).\nWe define a total order on patterns \u03b1 = ([i, j], \u00b7) \u2208 \u039b\u0302 as the lexicographical order with components (i, j) (the first component is more significant).\nLemma 17. (a) For each pattern \u03b2 \u2208 \u039b\u0302 there holds \u03b2 \u2208 \u03a0. (b) Consider two consecutive patterns \u03b11 \u227a \u03b12 in \u039b\u0302 with \u03b11 = ([i1, j1], \u00b7), \u03b12 = ([i2, j2], \u00b7), and let \u03b2 = x\u2217i2:j1 be the pattern at which they intersect. (By the assumption above, i2 \u2264 j1 + 1). There holds \u03b2 \u2208 \u03a0. (c) For the patterns in (b), condition Mj1(\u03b11) \u2264 f(x\u22171:j1) implies Mj2(\u03b12) \u2264 f(x \u2217 1:j2 ).\nProof. Part (a) We can write labeling x\u2217 as x\u2217 = x\u03b1\u03b2\u03b3y where patterns \u03b1, \u03b2 are empty. Let us show that this choice satisfies conditions in (53). Condition (a) holds since \u03b1\u03b2 = \u03b2\u03b3 = \u03b2 \u2208 \u03a0\u25e6. Suppose that (b) does not hold, then there exists pattern u = x\u2217k:` \u2208 \u03a0\u25e6 with u = +\u03b2+. We have u \u2208 \u039b and thus \u03b2 /\u2208 \u039b\u0302 - a contradiction. Therefore, \u03b2 \u2208 \u03a0. Part (b) The definitions of and \u039b\u0302 imply that i1 < i2. (If i1 = i2 then we must have j1 < j2, but then \u03b11 /\u2208 \u039b\u0302 - a contradiction.) There also holds j1 < j2 (otherwise we would have \u03b12 /\u2208 \u039b\u0302 - a contradiction). This means that we can write labeling x\u2217 as x\u2217 = x\u03b1\u03b2\u03b3y where \u03b1\u03b2 = \u03b11, \u03b2\u03b3 = \u03b12 and the pattern intervals are as follows:\nx \u03b1 \u03b2 \u03b3 y\n[1, i1\u22121] [i1, i2\u22121] [i2, j1] [j1+1, j2] [j2+1, n]\nLet us show that this choice satisfies conditions in (53). Condition (a) holds since \u03b1\u03b2 = \u03b11 \u2208 \u03a0\u25e6 and \u03b2\u03b3 = \u03b12 \u2208 \u03a0\u25e6. Suppose that (b) does not hold, then there exists pattern u = x\u2217k:` \u2208 \u03a0\u25e6 where k < i2 and ` > j1. This means that u \u2208 \u039b.\nFrom the definition of \u039b\u0302, there exists pattern u\u0302 = x\u2217 k\u0302:\u0302\u0300 \u2208 \u039b\u0302 with [k, `] \u2286 [k\u0302, \u0302\u0300]. To summarize, we\nhave k\u0302 \u2264 k < i2 and j1 < ` \u2264 \u0302\u0300. If k\u0302 \u2264 i1 then [i1, j1] \u2282 [k\u0302, \u0302\u0300] and thus \u03b11 /\u2208 \u039b\u0302 - a contradiction. Thus, there must hold k\u0302 > i1.\nSimilarly, we prove that \u0302\u0300< j2. This implies that \u03b11 \u227a u\u0302 \u227a \u03b12, and therefore patterns \u03b11 and \u03b12 are not consecutive in \u039b\u0302 - a contradiction. Part (c) \u03b2 is a proper prefix of \u03b1 that belongs to \u03a0. Therefore, \u03b1\u2190 is defined. We can define a sequence of patterns \u03b20 = \u03b2, \u03b21, . . . , \u03b2m = \u03b12 with \u03b2k = ([i2, sk], \u00b7), s0 = j1 < s1 < . . . < sm = j2 respectively such that \u03b2k \u2208 \u03a0 and \u03b2k\u22121 = \u03b2\u2190k for k \u2208 [1,m]. Let us prove by induction on k that Msk(\u03b2k) \u2264 f(x\u22171:sk) for k \u2208 [0,m].\nLet us first check the base of the induction. Since \u03b2, \u03b11 \u2208 \u03a0j1 and \u03b11 = \u2217\u03b2, by the definition of graph G[\u03a0j1 ] there is a (unique) path \u03b30, \u03b31, . . . , \u03b3r from \u03b30 = \u03b2 to \u03b3r = \u03b11 with (\u03b3l, \u03b3l+1) \u2208 E[\u03a0j1 ]. By eq. (51), Mj1(\u03b3l) \u2264Mj1 (\u03b3l+1). Therefore, Mj1(\u03b2) \u2264Mj1 (\u03b11) \u2264 f(x\u22171:j1) where the last inequality holds by the assumption of part (c). This establishes the base case.\nNow suppose that the claim holds for k\u2212 1 \u2208 [0,m\u2212 1]; let us prove it for k. Denote p = sk\u22121 and s = sk. Note, p is the index in step 2 of the algorithm during the processing of (s, \u03b2k). From eq. (51) and the induction hypothesis we get\nMs(\u03b2k) \u2264Mp(\u03b2k\u22121) + \u03c8(\u03b2k) \u2264 Fp(x\u22171:p) + \u03c8(\u03b2k)\nWe will prove next that f(x\u22171:p) + \u03c8(\u03b2k) = f(x \u2217 1:s), thus completing the induction step. It suffices to show that there is no pattern \u03b3 = x\u2217i:j with i < i2 and p < j \u2264 s. Suppose on the contrary that such pattern exists. By the definition of \u039b\u0302 there exists pattern \u03b3\u0302 = ([\u0302i, j\u0302], \u00b7) \u2208 \u039b\u0302 with [i, j] \u2286 [\u0302i, j\u0302]. We have i\u0302 \u2264 i < i2 and j\u0302 \u2265 j > p \u2265 s0 = j1. These facts imply that \u03b11 \u227a \u03b3\u0302 \u227a \u03b12, contradicting the assumption that \u03b11 and \u03b12 are consecutive patterns in \u039b\u0302.\nLemma 17 implies the main claim.\nCorollary 18. For each \u03b1 = ([i, j], \u00b7) \u2208 \u039b\u0302 there holds Mj(\u03b1) \u2264 f(x\u22171:j), and therefore Z \u2264 f(x\u2217).\nProof. We use induction on the total order . The lowest pattern \u03b1 \u2208 \u039b\u0302 starts at position 1; for such pattern the claim follows by inspecting Algorithm 6. The induction step follows from Lemma 17(c)."}, {"heading": "Acknowledgements", "text": "We thank Herbert Edelsbrunner for helpful discussions."}], "references": [{"title": "Recursive star-tree parallel data structure", "author": ["Omer Berkman", "Uzi Vishkin"], "venue": "SIAM Journal on Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Beyond pairwise energies: Efficient optimization for higher-order MRFs", "author": ["N. Komodakis", "N. Paragios"], "venue": "In CVPR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F Pereira"], "venue": "In ICML,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Semi-Markov conditional random field with high-order features", "author": ["Viet Cuong Nguyen", "Nan Ye", "Wee Sun Lee", "Hai Leong Chieu"], "venue": "In ICML 2011 Structured Sparsity: Learning and Inference Workshop,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Sparse higher order conditional random fields for improved sequence labeling", "author": ["Xian Qian", "Xiaoqian Jiang", "Qi Zhang", "Xuanjing Huang", "Lide Wu"], "venue": "In ICML,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Minimizing sparse higher order energy functions of discrete variables", "author": ["C. Rother", "P. Kohli", "W. Feng", "J. Jia"], "venue": "In CVPR,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Semi-Markov conditional random fields for information extraction", "author": ["S. Sarawagi", "W. Cohen"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Inference algorithms for pattern-based CRFs on sequence data", "author": ["R. Takhanov", "V. Kolmogorov"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "A linear algorithm for generating random numbers with a given distribution", "author": ["M.D. Vose"], "venue": "IEEE Transactions on software engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Conditional random fields with high-order features for sequence labeling", "author": ["Nan Ye", "Wee Sun Lee", "Hai Leong Chieu", "Dan Wu"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}], "referenceMentions": [{"referenceID": 2, "context": "A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z: E(x|z) = \u2211", "startOffset": 63, "endOffset": 66}, {"referenceID": 7, "context": "A preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Its complexity is either (i) O(nL) per sample, or (ii) O(n) per sample with an O(nL|D|) preprocessing (assuming that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time).", "startOffset": 202, "endOffset": 208}, {"referenceID": 1, "context": "Komodakis and Paragios [2] gave an O(nL) technique for minimizing energy (3) in this case.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "We present a modification that has the same worst-case complexity but can beat the algorithm in [2] in the best case.", "startOffset": 96, "endOffset": 99}, {"referenceID": 9, "context": "Related work The works of [10] and [2] are probably the most related to our paper.", "startOffset": 26, "endOffset": 30}, {"referenceID": 1, "context": "Related work The works of [10] and [2] are probably the most related to our paper.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "The latter considered a pattern-based CRF on a grid for a computer vision application; the MAP inference problem in [2] was converted to sequence labeling problems by decomposing the grid into thin \u201cstripes\u201d.", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "[5] considered a more general formulation in which a single pattern is characterized by a set of strings rather than a single string \u03b1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Their inference procedure reduces the problem to the MAP estimation in a pairwise CRF with cycles, which Some of the bounds stated in [10] are actually weaker.", "startOffset": 134, "endOffset": 138}, {"referenceID": 3, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "We conjecture that our algorithms can be extended to this case as well, and can yield a better complexity compared to [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "In [8] we applied the pattern-based CRF model to the problem of the protein dihedral angles prediction.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "5: \u0398(nP \u2032|D|) algorithm for a general commutative semiring, which is equivalent to the algorithm in [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "Complexity Assume that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time.", "startOffset": 108, "endOffset": 114}, {"referenceID": 8, "context": "With a \u0398(N) preprocessing, a sample can also be produced in O(1) time by the so-called \u201calias method\u201d [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "After that, for each \u03b1 \u2208 \u03a0s+1 we need to run the linear time procedure of [9] for distributions p(\u03b2) \u221d Ms(\u03b2), \u03b2 \u2208 \u2206s(\u03b1s+1).", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "Remark 1 An alternative method for computing marginals with complexity O ( n|\u0393|L`max ) was given in [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "The algorithm closely resembles the method in [10]; it is based on the same idea and has the same complexity.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "Remark 2 As we already mentioned, Algorithm 4 resembles the algorithm in [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 0, "context": "If (R,\u2295,\u2297) = (R,min,+) then this can be reduced to O(nP log(`max + 1)) using the algorithm for Range Minimum Queries by [1].", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "It is known [1] that with an O(N) preprocessing each query for can be answered in O(1) time per interval.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "In the MAP case we simply run the preprocessing of [1] for the sequence Wt(\u03b21), .", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "[2] gave an algorithm that makes \u0398(nP ) comparisons and \u0398(nP ) additions.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "We consider Conditional Random Fields (CRFs) with pattern-based potentials defined on a chain. In this model the energy of a string (labeling) x1 . . . xn is the sum of terms over intervals [i, j] where each term is non-zero only if the substring xi . . . xj equals a prespecified pattern \u03b1. Such CRFs can be naturally applied to many sequence tagging problems. We present efficient algorithms for the three standard inference tasks in a CRF, namely computing (i) the partition function, (ii) marginals, and (iii) computing the MAP. Their complexities are respectively O(nL), O(nL`max) and O(nLmin{|D|, log(`max+1)}) where L is the combined length of input patterns, `max is the maximum length of a pattern, and D is the input alphabet. This improves on the previous algorithms of [Ye et al. NIPS 2009] whose complexities are respectively O(nL|D|), O ( n|\u0393|L`max ) and O(nL|D|), where |\u0393| is the number of input patterns. In addition, we give an efficient algorithm for sampling, and revisit the case of MAP with non-positive weights. This paper addresses the sequence labeling (or the sequence tagging) problem: given an observation z (which is usually a sequence of n values), infer labeling x = x1 . . . xn where each variable xi takes values in some finite domain D. Such problem appears in many domains such as text and speech analysis, signal analysis, and bioinformatics. One of the most successful approaches for tackling the problem is the Hidden Markov Model (HMM). The kth order HMM is given by the probability distribution p(x|z) = 1 Z exp{\u2212E(x|z)} with the energy function E(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, zi) + \u2211 (i,j)\u2208Ek \u03c8ij(xi:j) (1) where Ek = {(i, i+ k) | i \u2208 [1, n\u2212 k]} and xi:j = xi . . . xj is the substring of x from i to j. A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z: E(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, z) + \u2211 (i,j)\u2208Ek \u03c8ij(xi:j , z) (2) A preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8]. This work was partially supported by the European Research Council under the European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 616160. 1 ar X iv :1 21 0. 05 08 v5 [ cs .L G ] 2 0 Ja n 20 17 We study a particular variant of this model called a pattern-based CRF. It is defined via", "creator": "LaTeX with hyperref package"}}}