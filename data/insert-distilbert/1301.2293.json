{"id": "1301.2293", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Aggregating Learned Probabilistic Beliefs", "abstract": "essentially we consider the task premise of aggregating beliefs of severalexperts. we assume that these beliefs are represented as probabilitydistributions. we argue that the evaluation of any aggregationtechnique depends on the semantic context validity of this task. we propose aframework, however in which we assume that nature generates samples isolated from a ` true'distribution and different experts form onto their beliefs based onthe subsets of the data they have a chance to observe. naturally, theideal aggregate distribution would be equally the one learned from thecombined sample sets. being such a formulation leads to a natural way tomeasure the accuracy of the aggregation mechanism. we show that the well - known aggregation operator linop is ideallysuited for that task. we propose a linop - based learning algorithm, inspired by the techniques developed for bayesian learning, whichaggregates the experts'biased distributions represented as bayesiannetworks. our preliminary experiments show demonstrating that this algorithmperforms well in practice.", "histories": [["v1", "Thu, 10 Jan 2013 16:25:16 GMT  (914kb)", "http://arxiv.org/abs/1301.2293v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pedrito maynard-reid ii", "urszula chajewska"], "accepted": false, "id": "1301.2293"}, "pdf": {"name": "1301.2293.pdf", "metadata": {"source": "CRF", "title": "Aggregating Learned Probabilistic Beliefs", "authors": ["Pedrito Maynard-Reid"], "emails": ["urszula@cs.stanford.edu"], "sections": null, "references": [{"title": "Theory refinement on bayesian net\u00ad", "author": ["W. Buntine"], "venue": null, "citeRegEx": "Buntine.,? \\Q1991\\E", "shortCiteRegEx": "Buntine.", "year": 1991}, {"title": "A normative examination of ensemble learning algorithms", "author": ["D.M. Pennock", "P.E. Horvitz"], "venue": "In Proc. ICML'OO,", "citeRegEx": "Pennock and Horvitz.,? \\Q2000\\E", "shortCiteRegEx": "Pennock and Horvitz.", "year": 2000}], "referenceMentions": [], "year": 2011, "abstractText": "We consider the task of aggregating beliefs of sev\u00ad eral experts. We assume that these beliefs are rep\u00ad resented as probability distributions. We argue that the evaluation of any aggregation technique depends on the semantic context of this task. We propose a framework, in which we assume that nature generates samples from a 'true' distribution and different experts form their beliefs based on the subsets of the data they have a chance to observe. Naturally, the optimal ag\u00ad gregate distribution would be the one learned from the combined sample sets. Such a formulation leads to a natural way to measure the accuracy of the aggregation mechanism. We show that the well-known aggregation operator LinOP is ideally suited for that task. We propose a LinOP-based learning algorithm, inspired by the techniques developed for Bayesian learning, which aggregates the experts' distributions represented as Bayesian networks. We show experimentally that this algorithm performs well in practice.", "creator": "pdftk 1.41 - www.pdftk.com"}}}