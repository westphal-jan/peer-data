{"id": "1301.2307", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Decision-Theoretic Planning with Concurrent Temporally Extended Actions", "abstract": "we investigate a model for allocation planning under uncertainty with temporallyextended actions, where multiple actions can safely be taken concurrently at to each decision epoch. our model is enhanced based on the options analysis framework, and combines it with internally factored state space arithmetic models, where the set of options can now be partitioned into classes that affectdisjoint state vector variables. we show that the set semantics of decisionepochs for concurrent options defines a semi - markov decisionprocess, alternatively if initially the underlying temporally extended actions being parallelized efficiently arerestricted to markov options. this property formulation allows us to use smdpalgorithms for computing the value function optimal over concurrentoptions. the concurrent options model allows overlapping execution ofoptions in order to achieve higher computational performance or in order to performa complex task. we describe a simple experiment using a navigationtask { which illustrates how concurrent options representation results in a faster planwhen compared to the case when only one specific option is taken at a time.", "histories": [["v1", "Thu, 10 Jan 2013 16:26:17 GMT  (1241kb)", "http://arxiv.org/abs/1301.2307v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["khashayar rohanimanesh", "sridhar mahadevan"], "accepted": false, "id": "1301.2307"}, "pdf": {"name": "1301.2307.pdf", "metadata": {"source": "CRF", "title": "Decision-Theoretic Planning with Concurrent Temporally Extended Actions", "authors": ["Khashayar Rohanimanesh", "Sridhar Mahadevan"], "emails": ["khash@cse.msu.edu", "mahadeva@cse.msu.edu"], "sections": null, "references": [{"title": "Exploiting structure in policy construction", "author": ["C. Boutilier", "M. Goldszmidt"], "venue": "In Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Boutilier and Goldszmidt,? \\Q1995\\E", "shortCiteRegEx": "Boutilier and Goldszmidt", "year": 1995}, {"title": "Reinforcement learn\u00ad ing methods for continuous-time markov decision problems", "author": ["S. Bradtke", "M. Duff"], "venue": "Advances in Neural Information Process\u00ad ing Systems,", "citeRegEx": "Bradtke and Duff,? \\Q1995\\E", "shortCiteRegEx": "Bradtke and Duff", "year": 1995}, {"title": "Learning multidimensional control actions from delayed reinforcements", "author": ["P. Cichosz"], "venue": "Eighth Inter\u00ad national Symposium on System-Modelling-Control (SMC-8)", "citeRegEx": "Cichosz,? \\Q1995\\E", "shortCiteRegEx": "Cichosz", "year": 1995}, {"title": "Model minimization in markov decision processes", "author": ["T. Dean", "R. Givan"], "venue": "n Proceedings of the Fourteenth National Conference on Aritificial Intel\u00ad ligenceProceedings of AAAI", "citeRegEx": "Dean and Givan,? \\Q1997\\E", "shortCiteRegEx": "Dean and Givan", "year": 1997}, {"title": "Computing factored value functions for policies in structured mdps", "author": ["D. Koller", "R. Parr"], "venue": "16th International Joint Conference on Artificial Intelli\u00ad gence (IJCAI),", "citeRegEx": "Koller and Parr,? \\Q1999\\E", "shortCiteRegEx": "Koller and Parr", "year": 1999}, {"title": "How to dynamically merge markov decision processes", "author": ["S. Singh", "D. Cohn"], "venue": "Proceedings of NIPS", "citeRegEx": "Singh and Cohn,? \\Q1998\\E", "shortCiteRegEx": "Singh and Cohn", "year": 1998}, {"title": "Between MOPs and Semi-MDPs: A framework for tempo\u00ad ral abstraction in reinforcement learning", "author": ["R. Sutton", "D. Precup", "S. Singh"], "venue": "Artificial Intelligence,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 6, "context": "We adopt the theoretical framework of options (Sutton et al., 1999) to model temporally extended actions, since it is both a well-developed rigorous framework that addresses planning under uncertainty with temporally extended actions, and it allows looking inside behaviors to im\u00ad prove composition of temporally extended actions.", "startOffset": 46, "endOffset": 67}, {"referenceID": 2, "context": "multi-dimensional vector action spaces (Cichosz, 1995) to planning with multiple simultaneous MDPs (Singh & Cohn, 1998), where the composite state space is the cross product of the state spaces of each individual", "startOffset": 39, "endOffset": 54}, {"referenceID": 6, "context": "Options are a generalization of primitive actions that include temporally extended courses of action in the context of reinforcement learning (Sutton et al., 1999).", "startOffset": 142, "endOffset": 163}, {"referenceID": 6, "context": "It has been shown earlier that the set of Markov options defines a semi-Markov decision process (SMDP) (Sutton et al., 1999).", "startOffset": 103, "endOffset": 124}, {"referenceID": 6, "context": "We adopt the rooms example from (Sutton et al., 1999) and we add doors in each of the four hallways (F igure 1).", "startOffset": 32, "endOffset": 53}, {"referenceID": 6, "context": "continuing the multi-option (Sutton et al., 1999).", "startOffset": 28, "endOffset": 49}], "year": 2011, "abstractText": "We investigate a model for planning un\u00ad der uncertainty with temporally extended ac\u00ad tions, where multiple actions can be taken concurrently at each decision epoch. Our model is based on the options framework, and combines it with factored state space mod\u00ad els, where the set of options can be parti\u00ad tioned into classes that affect disjoint state variables. We show that the set of deci\u00ad sion epochs for concurrent options defines a semi-Markov decision process, if the underly\u00ad ing temporally extended actions being paral\u00ad lelized are restricted to Markov options. This property allows us to use SMDP algorithms for computing the value function over concur\u00ad rent options. The concurrent options model allows overlapping execution of options in or\u00ad der to achieve higher performance or in or\u00ad der to perform a complex task. We describe a simple experiment using a navigation task which illustrates how concurrent options re\u00ad sults in a more optimal plan when compared to the case when only one option is taken at a time.", "creator": "pdftk 1.41 - www.pdftk.com"}}}