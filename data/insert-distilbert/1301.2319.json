{"id": "1301.2319", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jan-2013", "title": "Planning and Acting under Uncertainty: A New Model for Spoken Dialogue Systems", "abstract": "uncertainty plays a more central role in spoken dialogue systems. some stochastic models like markov decision process ( mdp ) are used to model the words dialogue manager. but the partially observable system state and user intention hinder the natural hierarchical representation of the dialogue state. mdp - based system degrades fast when uncertainty about a user's intention increases. we propose a novel electronic dialogue model formulated based on the simple partially observable markov decision breakdown process ( pomdp ). lastly we use hidden system states and identifying user intentions as the state set, parser results and low - level information as the observation set, domain actions and dialogue repair actions as the action set. here the low - level information is extracted from different input modals, including speech, keyboard, mouse, etc., using bayesian networks. because of the limitation of the exact algorithms, we focus on heuristic approximation scheme algorithms and their applicability in pomdp for dialogue management. we also propose two methods for grid point selection in grid - based approximation algorithms.", "histories": [["v1", "Thu, 10 Jan 2013 16:27:11 GMT  (1088kb)", "http://arxiv.org/abs/1301.2319v1", "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)"]], "COMMENTS": "Appears in Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI2001)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["bo zhang", "qingsheng cai", "jianfeng mao", "baining guo"], "accepted": false, "id": "1301.2319"}, "pdf": {"name": "1301.2319.pdf", "metadata": {"source": "CRF", "title": "Planning and Acting under Uncertainty: A New Model for Spoken Dialogue Systems", "authors": ["Bo Zhang", "Qingsheng Cai", "Jianfeng Mao", "Baining Guo"], "emails": [], "sections": null, "references": [{"title": "Dynamic programming", "author": ["E. R"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "R.,? \\Q1957\\E", "shortCiteRegEx": "R.", "year": 1957}, {"title": "Computing optimal policies for partially observable decision processes using compact representations", "author": ["C. Boutilier", "D. Poole"], "venue": "In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96),", "citeRegEx": "Boutilier and Poole,? \\Q1996\\E", "shortCiteRegEx": "Boutilier and Poole", "year": 1996}, {"title": "Exact and approximate", "author": ["A.R. Cassandra"], "venue": null, "citeRegEx": "Cassandra,? \\Q1998\\E", "shortCiteRegEx": "Cassandra", "year": 1998}, {"title": "Value-function approximations for", "author": ["M. Hauskrecht"], "venue": null, "citeRegEx": "Hauskrecht,? \\Q2000\\E", "shortCiteRegEx": "Hauskrecht", "year": 2000}, {"title": "Conversation as action", "author": ["T. Paek", "E. Horvitz"], "venue": null, "citeRegEx": "Paek and Horvitz,? \\Q2000\\E", "shortCiteRegEx": "Paek and Horvitz", "year": 2000}, {"title": "The optimal control of partially", "author": ["J. E"], "venue": "Sondik", "citeRegEx": "E.,? \\Q1971\\E", "shortCiteRegEx": "E.", "year": 1971}], "referenceMentions": [{"referenceID": 2, "context": "Q I\u00b7 In each step of the iteration, all the dominated vectors (Cassandra, 1998) are removed.", "startOffset": 62, "endOffset": 79}, {"referenceID": 2, "context": "There exist many exact algorithms to solve the optimal solution for POMDP (Cassandra, 1998).", "startOffset": 74, "endOffset": 91}, {"referenceID": 3, "context": "We are interested in four algorithms (Hauskrecht, 2000):", "startOffset": 37, "endOffset": 55}, {"referenceID": 3, "context": "An incremental approach (Hauskrecht, 2000) was proposed since the grid-based method is not guaranteed to converge.", "startOffset": 24, "endOffset": 42}, {"referenceID": 3, "context": "1 In (Hauskrecht, 2000), only one value function is used for each belief state.", "startOffset": 5, "endOffset": 23}, {"referenceID": 3, "context": "We use direct and look-ahead methods (Hauskrecht, 2000) to get the policy from the value function.", "startOffset": 37, "endOffset": 55}], "year": 2011, "abstractText": "Uncertainty plays a central role in spoken dialogue systems. Some stochastic models like the Markov decision process (MDP) are used to model the dialogue manager. But the partially observable system state and user intentions hinder the natural representation of the dialogue state. A MDP-based system degrades quickly when uncertainty about a user's intention increases. We propose a novel dialogue model based on the partially observable Markov decision process (POMDP). We use hidden system states and user intentions as the state set, parser results and low-level information as the observation set, and domain actions and dialogue repair actions as the action set. Here, low-level information is extracted from different input modalities, including speech, keyboard, mouse, etc., using Bayesian networks. Because of the limitation of the exact algorithms, we focus on heuristic approximation algorithms and their applicability in POMDP for dialogue management. We also propose two methods for grid point selection in grid-based algorithms.", "creator": "pdftk 1.41 - www.pdftk.com"}}}