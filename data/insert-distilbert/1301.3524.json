{"id": "1301.3524", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2013", "title": "How good is the Electricity benchmark for evaluating concept drift adaptation", "abstract": "in this correspondence, we will point out a problem pose with testing adaptive classifiers on autocorrelated data. in such a pure case random change alarms may boost the evolutionary accuracy figures. hence, we cannot be sure if the adaptation probability is working well.", "histories": [["v1", "Tue, 15 Jan 2013 22:51:40 GMT  (16kb,D)", "http://arxiv.org/abs/1301.3524v1", "2 pages of content, 1 appendix, 2 figures"]], "COMMENTS": "2 pages of content, 1 appendix, 2 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["indre zliobaite"], "accepted": false, "id": "1301.3524"}, "pdf": {"name": "1301.3524.pdf", "metadata": {"source": "CRF", "title": "How good is the Electricity benchmark for evaluating concept drift adaptation", "authors": ["Indr\u0117 \u017dliobait\u0117"], "emails": ["zliobaite@gmail.com"], "sections": [{"heading": null, "text": "Keywords: data streams, concept drift, evaluation, autocorrelated labels"}, {"heading": "Testing on the Electricity data", "text": "Concept drift (Widmer and Kubat, 1996) has become a popular research topic over the last decade and a lot of adaptive classification algorithms have been developed. The setting is as follows. Multidimensional input data is arriving over time, the goal is to predict the class label y for each instance X. In the stationary settings a classifier L : X \u2192 y is trained once and remains fixed during the operation. In the concept drift scenario the joint data distribution, i.e. p(X, y), may change over time, and, as a result, a fixed predictor L may lose accuracy over time. In the concept drift scenario a classifier can be updated at every time step taking into account the most recent data: Lt = f(Lt\u22121, Xt\u22121, yt\u22121), where t is the time step, f is the adaptation function.\nThe Electricity dataset due to Harries (1999) is a popular benchmark for testing adaptive classifiers1. It has been used in over 40 concept drift experiments2.The dataset covers a period of two years (45 312 instances recorded every half an hour, 6 input variables). A binary classification task is to predict a rise (UP) or a fall (DOWN) in the electricity price in New South Wales (Australia). The prior probability of DOWN is 58%. The data is subject to concept drift due to changing consumption habits, unexpected events and seasonality.\nThis dataset has an important property not to be ignored when evaluating concept drift adaptation. Suppose we employ a naive predictor that predicts the next label to be the same as the current label (the moving average of one). For instance, if the price goes UP now, it predict that the next time step the price will go UP as well. If the data was distributed independently, such a predictor would achieve 51% accuracy3. However, if we test this naive approach on the Electricity dataset it gives much higher 85% accuracy. This happens because the labels are not independent; there are long consecutive periods of UP and long consecutive periods of DOWN. Figure 1 plots the autocorrelation function4 of the labels.\n1. The dataset is available from e.g. http://www.liaad.up.pt/~jgama/ales/ales_5.html. 2. Google scholar, 2013 January 3. The probability that two labels in a row are the same is p(UP )2 + p(DOWN)2. 4. Autocorrelation peaks at every 48 instances (24 hours) due to the cylices of electricity consumption.\nar X\niv :1\n30 1.\n35 24\nv1 [\ncs .L\nG ]\n1 5\nJa n\n20 13\nThe problem with evaluation of adaptive classifiers on such a dataset is that we cannot be sure if a change detector (and adaptation) is working well. Suppose we have a classifier with a worthless change detection mechanism. If fires a change alarm after any instance at random with the probability \u03c1. After firing an alarm the classifier is restarted and continues training on the most recent data. Suppose we do not take into consideration any input data, we do not build any intelligent models just look at the labels. If \u03c1 = 0, i.e. no change detection, we get the majority class (always DOWN) classifier that would achieve 58% accuracy over this dataset. If \u03c1 = 1, we alarm a change as often as possible, we get the moving average of one classifier. Figure 2 plots the accuracies in between. Note that if the data was distributed independently we would get the naive accuracy 51% independently of \u03c1.\nIn the appendix we report the results of testing several adaptive classifiers implemented in MOA (Bifet et al., 2010a) and the accuracies found in the literature on the Electricity dataset.\nIn summary, the more random change alarms the classifier fires, the better the accuracy. There change alarms are not related in detecting concept drift in any way, we are not using the input data X in this experiment. Thus, getting high accuracy on the Electricity dataset does not necessarily mean that the adaptation mechanism is good. In such a case we recommend at least comparing the testing accuracies with the accuracy of the moving average of one.\nThis note is intended to be updated. There is a website for discussing this issue or leaving your comments https://sites.google.com/site/zliobaite/about_electricity."}, {"heading": "Appendix", "text": "Table 1 reports classification accuracies tested with MOA(Bifet et al., 2010a) implementations. We see that only LeveragingBag and AdaHoeffdingOptionTree outperform the moving average of one. Table 2 collects classification accuracies on the Electricity dataset as reported in published papers."}], "references": [{"title": "Early drift detection method", "author": ["Manuel Baena-Garcia", "Jose del Campo-Avila", "Raul Fidalgo", "Albert Bifet", "Ricard Gavalda", "Rafael Morales-Bueno"], "venue": "In Proc. of the 4th ECML PKDD International Workshop on Knowledge Discovery from Data Streams,", "citeRegEx": "Baena.Garcia et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Baena.Garcia et al\\.", "year": 2006}, {"title": "Learning from time-changing data with adaptive windowing", "author": ["Albert Bifet", "Ricard Gavalda"], "venue": "In Proceedings of the Seventh SIAM International Conference on Data Mining, April 26-28,", "citeRegEx": "Bifet and Gavalda.,? \\Q2007\\E", "shortCiteRegEx": "Bifet and Gavalda.", "year": 2007}, {"title": "Adaptive learning from evolving data streams", "author": ["Albert Bifet", "Ricard Gavalda"], "venue": "In Proceedings of the 8th International Symposium on Intelligent Data Analysis: Advances in Intelligent Data Analysis VIII,", "citeRegEx": "Bifet and Gavalda.,? \\Q2009\\E", "shortCiteRegEx": "Bifet and Gavalda.", "year": 2009}, {"title": "MOA: Massive online analysis", "author": ["Albert Bifet", "Geoff Holmes", "Richard Kirkby", "Bernhard Pfahringer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bifet et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bifet et al\\.", "year": 2010}, {"title": "Fast perceptron decision tree learning from evolving data streams", "author": ["Albert Bifet", "Geoff Holmes", "Bernhard Pfahringer", "Eibe Frank"], "venue": "In Proceedings of the 14th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part II,", "citeRegEx": "Bifet et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bifet et al\\.", "year": 2010}, {"title": "Leveraging bagging for evolving data streams", "author": ["Albert Bifet", "Geoffrey Holmes", "Bernhard Pfahringer"], "venue": "In Proceedings of the 2010 European conference on Machine learning and knowledge discovery in databases: Part I, ECML PKDD\u201910,", "citeRegEx": "Bifet et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bifet et al\\.", "year": 2010}, {"title": "Accuracy updated ensemble for data streams with concept drift", "author": ["Dariusz Brzezinski", "Jerzy Stefanowski"], "venue": "In Proceedings of the 6th international conference on Hybrid artificial intelligent systems - Volume Part II,", "citeRegEx": "Brzezinski and Stefanowski.,? \\Q2011\\E", "shortCiteRegEx": "Brzezinski and Stefanowski.", "year": 2011}, {"title": "Incremental learning of concept drift from streaming imbalanced data", "author": ["Gregory Ditzler", "Robi Polikar"], "venue": "IEEE Transactions on Knowledge and Data Engineering, page preprint,", "citeRegEx": "Ditzler and Polikar.,? \\Q2012\\E", "shortCiteRegEx": "Ditzler and Polikar.", "year": 2012}, {"title": "Learning with local drift detection", "author": ["Joao Gama", "Gladys Castillo"], "venue": "In Proceedings of the Second international conference on Advanced Data Mining and Applications,", "citeRegEx": "Gama and Castillo.,? \\Q2006\\E", "shortCiteRegEx": "Gama and Castillo.", "year": 2006}, {"title": "Learning with drift detection", "author": ["Joao Gama", "Pedro Medas", "Gladys Castillo", "Pedro Rodrigues"], "venue": "In Proceedings of the 7th Brazilian Symposium on Artificial Intelligence Advances in Artificial Intelligence,", "citeRegEx": "Gama et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Gama et al\\.", "year": 2004}, {"title": "Calds: context-aware learning from data streams", "author": ["Jo\u00e3o B\u00e1rtolo Gomes", "Ernestina Menasalvas", "Pedro A.C. Sousa"], "venue": "In Proceedings of the First International Workshop on Novel Data Stream Pattern Mining Techniques,", "citeRegEx": "Gomes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gomes et al\\.", "year": 2010}, {"title": "Solving nonstationary classification problems with coupled support vector machines", "author": ["Guillermo L. Grinblat", "Lucas C. Uzal", "H. Alejandro Ceccatto", "Pablo M. Granitto"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Grinblat et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Grinblat et al\\.", "year": 2011}, {"title": "Splice-2 comparative evaluation: Electricity pricing", "author": ["Michael Harries"], "venue": "Technical report, University of New South Wales,", "citeRegEx": "Harries.,? \\Q1999\\E", "shortCiteRegEx": "Harries.", "year": 1999}, {"title": "Dynamic weighted majority: An ensemble method for drifting concepts", "author": ["J. Zico Kolter", "Marcus A. Maloof"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Kolter and Maloof.,? \\Q2007\\E", "shortCiteRegEx": "Kolter and Maloof.", "year": 2007}, {"title": "AlonsoBetanzos. A robust incremental learning method for non-stationary environments. Neurocomput", "author": ["David Martinez-Rego", "Beatriz Perez-Sanchez", "Oscar Fontenla-Romero", "Amparo"], "venue": null, "citeRegEx": "Martinez.Rego et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martinez.Rego et al\\.", "year": 2011}, {"title": "Lambda-perceptron: An adaptive classifier for data streams", "author": ["N.G. Pavlidis", "D.K. Tasoulis", "N.M. Adams", "D.J. Hand"], "venue": "Pattern Recogn.,", "citeRegEx": "Pavlidis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pavlidis et al\\.", "year": 2011}, {"title": "New options for hoeffding trees", "author": ["Bernhard Pfahringer", "Geoffrey Holmes", "Richard Kirkby"], "venue": "In Proceedings of the 20th Australian joint conference on Advances in artificial intelligence,", "citeRegEx": "Pfahringer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pfahringer et al\\.", "year": 2007}, {"title": "Exponentially weighted moving average charts for detecting concept drift", "author": ["Gordon J. Ross", "Niall M. Adams", "Dimitris K. Tasoulis", "David J. Hand"], "venue": "Pattern Recogn. Lett.,", "citeRegEx": "Ross et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2012}, {"title": "Decision rules extraction from data stream in the presence of changing context for diabetes treatment", "author": ["Jakub M. Tomczak", "Adam Gonczarek"], "venue": "Knowledge and Information Systems, page preprint,", "citeRegEx": "Tomczak and Gonczarek.,? \\Q2012\\E", "shortCiteRegEx": "Tomczak and Gonczarek.", "year": 2012}, {"title": "Mining concept-drifting data streams using ensemble classifiers", "author": ["Haixun Wang", "Wei Fan", "Philip S. Yu", "Jiawei Han"], "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Wang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2003}, {"title": "Learning in the presence of concept drift and hidden contexts", "author": ["Gerhard Widmer", "Miroslav Kubat"], "venue": "Machine Learnin,", "citeRegEx": "Widmer and Kubat.,? \\Q1996\\E", "shortCiteRegEx": "Widmer and Kubat.", "year": 1996}, {"title": "Combining similarity in time and space for training set formation under concept drift", "author": ["Indre Zliobaite"], "venue": "Intell. Data Anal.,", "citeRegEx": "Zliobaite.,? \\Q2011\\E", "shortCiteRegEx": "Zliobaite.", "year": 2011}], "referenceMentions": [{"referenceID": 20, "context": "Testing on the Electricity data Concept drift (Widmer and Kubat, 1996) has become a popular research topic over the last decade and a lot of adaptive classification algorithms have been developed.", "startOffset": 46, "endOffset": 70}, {"referenceID": 12, "context": "The Electricity dataset due to Harries (1999) is a popular benchmark for testing adaptive classifiers1.", "startOffset": 31, "endOffset": 46}, {"referenceID": 16, "context": "71 (Pfahringer et al., 2007) moving average of one 85.", "startOffset": 3, "endOffset": 28}, {"referenceID": 0, "context": "00 (Baena-Garcia et al., 2006) OzaBagADWIN 84.", "startOffset": 3, "endOffset": 30}, {"referenceID": 2, "context": "21 (Bifet and Gavalda, 2009) HoeffdingAdaptiveTree 83.", "startOffset": 3, "endOffset": 28}, {"referenceID": 9, "context": "23 0 (Gama et al., 2004) AccuracyUpdatedEnsemble2 77.", "startOffset": 5, "endOffset": 24}, {"referenceID": 19, "context": "96 (Wang et al., 2003) NaiveBayes 74.", "startOffset": 3, "endOffset": 22}, {"referenceID": 19, "context": "74 (Wang et al., 2003) AccuracyWeightedEnsemble 71.", "startOffset": 3, "endOffset": 22}, {"referenceID": 19, "context": "37 (Wang et al., 2003) AccuracyUpdatedEnsemble 70.", "startOffset": 3, "endOffset": 22}, {"referenceID": 6, "context": "73 (Brzezinski and Stefanowski, 2011) MajorityClass 57.", "startOffset": 3, "endOffset": 37}], "year": 2013, "abstractText": "In this correspondence, we will point out a problem with testing adaptive classifiers on autocorrelated data. In such a case random change alarms may boost the accuracy figures. Hence, we cannot be sure if the adaptation is working well.", "creator": "LaTeX with hyperref package"}}}