{"id": "1301.3900", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2013", "title": "Conditional Independence and Markov Properties in Possibility Theory", "abstract": "conditional independence and markov properties are powerful tools allowing expression of multidimensional probability distributions by means of robust low - - dimensional classical ones. as multidimensional possibilistic models have been widely studied over for several years, the demand for analogous tools given in possibility theory seems to really be quite natural. this paper is intended to be a continuing promotion of de cooman's measure - theoretic approaches approcah to possibility theory, merely as if this comprehensive approach allows us to commonly find analogies to many important results correctly obtained in probabilistic framework. first, we recall semi - complete graphoid properties of discrete conditional possibilistic independence, properly parameterized by a continuous t - norm, and find sufficient conditions for a class of archimedean t - norms to have the graphoid property. then we introduce markov properties and simultaneously factorization of possibility order distrubtions ( again parameterized by a continuous t - norm ) and repeatedly find the relationships between them. these results are accompanied by a number of conterexamples, which show that the assumptions of specific theorems are even substantial.", "histories": [["v1", "Wed, 16 Jan 2013 15:53:09 GMT  (380kb)", "http://arxiv.org/abs/1301.3900v1", "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)"]], "COMMENTS": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence (UAI2000)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jirina vejnarova"], "accepted": false, "id": "1301.3900"}, "pdf": {"name": "1301.3900.pdf", "metadata": {"source": "CRF", "title": "Conditional Independence and Markov Properties in Possibility Theory", "authors": ["Jirina Vejnarova"], "emails": [], "sections": [{"heading": null, "text": "1 INTRODUCTION\nConditional independence and Markov properties are fundamental notions of graphical modeling; therefore they are strongly connected with the application of probability theory to artificial intelligence. Complex ity of practical problems that are of primary interest in the field of artificial intelligence usually results in the necessity to construct models with the aid of a great number of variables: more precisely, hundreds or thousands rather than tens. Processing distributions of such dimensionality would not be possible without some tools allowing us to reduce demands on com puter memory. Conditional independence and Markov properties, which are among such tools, allow expres sion of these multidimensional distributions by means\nof low-dimensional ones, and therefore to substantially decrease demands on computer memory.\nFor three centuries, probability theory was the only mathematical tool at our disposal for uncertainty quantification and processing. As a result, many im portant theoretical and practical advances have been achieved in this field. However, during the last thirty years some new mathematical tools have emerged as alternatives to probability theory. They are used in situations whose nature of uncertainty does not meet the requirements of probability theory, or those in which probabilistic approaches employ criteria that are too strict. Nevertheless, probability theory has always served as a source of inspiration for the de velopment of these nonprobabilistic calculi and these calculi have been continually confronted with proba bility theory and mathematical statistics from various points of view.\nGood examples of this fact include the numerous papers studying conditional independence in various calculi (de Campos and Huete 1999) (Fonck 1994) (Shenoy 1994) (Spohn 1980). With this paper, we will continue our efforts in the area of possibility theory (Vejnarova 1999), attempting to unify the conditional independence notion. We will follow de Cooman's measure-theoretic approach (de Cooman 1997) to pos sibility theory, but for purposes of this paper we have chosen to forego generality in favour of simplicity.\n2 BASIC TERMINOLOGY\nIn this section we will provide a brief overview of basic notions and results from (de Cooman 1997) and in Section 2.1 also from (de Baets et a!. 1999) that are necessary for understanding the sections that follow.\n2.1 TRIANGULAR NORMS\nA triangular norm (or a t- n orm) Tis a binary oper ator on [0, 1] (i.e. T : [0, 1]2 \ufffd [0, 1]) satisfying the following three conditions:\n610 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\n(i) boundary conditions: for any a E [0, 1] T(1, a) = a, T(O, a) = 0;\n(ii) isotonicity: for any a1, a2, bt, b2 E [0, 1] such that a1 \ufffd a2, b1 \ufffd b2\nT( at, bt) \ufffd T(a2, b2) ; (iii) associativ ity and commutativ ity: for any a, b, c E\n[0, 1] T (T ( a, b) , c)\nT( a, b) T(a, T(b, c)) , T(b, a).\nA t-norm T is called continuous, if T is a continuous function. In this case commutativity is just a conse quence of the remaining conditions.\nThere exist three distinct continuous t-norms, which will be studied in this paper:\n(i) Godel's t-norm:1 TG(a, b) = min ( a, b) ;\n(ii) product t-norm: Tp(a, b) = a\u00b7 b; (iii) Lukasziewicz't-norm: TL(a, b) = max (O, a+b-1).\nBecause of its associativity, any t-norm T can be ex tended to an n-ary operator rn : [0, 1]n -+ [0, 1], namely, in the following way\nT(rn- l(X t, . . . Xn-1), Xn) = rn(Xt, . . . 'Xn)\u00b7\nAt-norm Tis called Archimedean iff, for any (x, y) E ( 0, 1) 2, there exists n E N such that\nTn(x, . . . ,x) < y. Let us note that both product and Lukasziewicz'\nt-norms are Archimedean, but Godel's is not.\nA t-norm T is called strict iff it is continuous and, for any x E (0, 1), T(x, \u00b7) is strictly increasing. At-norm T is called nilpotent iff it is continuous, Archimedean and not strict, i.e., any continuous Archimedean t-norm is either strict or nilpotent. <p-transform ofT is at-norm\nT'P defined by\nT'P(x, y) = <p-1(T(<p (x), <p(y) ) . (1)\nIt can easily be seen that product t-norm is strict and Lukasziewicz' t-norm is nilpotent. Moreover, the fol lowing proposition (see e.g. (de Baets et al. 1999)) holds true:\nProposition 1 (i) A t-norm T is strict if and only if there exists a {0, 1 ]-automorphism <p such that T is the <p-tmnsform of the product t-norm.\n(ii) A t-norm T is nilpotent if and only if there ex ists a {0, i)-automorphism '!/; such that T is the '!/;-transform of Lukasziewicz' t-norm.\n1 Godel's t-norm is sometimes also called minimum t norm. But we prefer the first name, since its residual (see the last paragraph of this subsection) coincides with Godel's implication well-known from fuzzy logic.\nLet x, y E [0, 1] and T be a t-norm. We will call an element z E [0, 1] T-inv erse of x w.r.t. y iff T( z, x) = T(x, z) = y. It need no be defined uniquely (if it exists) and this ambiguity can cause serious problems in some cases. Therefore T-residual y6.Tx of y by x, which is defined as\ny6.Tx = sup{z E [0, 1]: T(z, x) \ufffd y}, is often preferred. It is well-known (see e.g. (de Cooman 1997), (de Baets et al. 1999)) that for con tinuous t-norms T the maximal T-inverse of x w.r.t. y equals to y6.Tx. Thus, for our famous t-norms we get\nyf:::,Ta X { y if X> y, 1 otherwise, { ll. if 0 \ufffd y < x, yf:::,Tp X X 1 otherwise,\n{ y - x + 1 if X> y, yf:::,TL X 1 otherwise. Let us note that if T'P is a <p-transform ofT then\nx!::,T.,Y = <p-1(<p(x) !::,T<p(y) ) .\n2.2 POSSIBILITY MEASURES AND DISTRIBUTIONS\n(2)\nLet X be a set called univ erse of discourse, which is supposed to contain at least two elements. A possibil ity measure II is a mapping from the power set P(X) of X to the real unit interval [0, 1] satisfying the following requirement: for any family { Aj, j E J} of elements of P(X)\nII( U Aj) = supii(Aj)\u00b7 jEJ jEJ\nII is called normal iff II(X) = 1. Within this paper we will deal only with normal possibility measures.\nFor any II there exists a mapping 1r : X -+ [0, 1] such that for any A E P(X), II(A) = supxEA -rr(x). 1r is called a distribution of II. This function is a possi bilistic counterpart of a density function in probability theory. Let us note that (if X is finite) II is normal iff -rr(x) = 1 for at least one x EX. Now, let us consider an arbitrary possibility measure II defined on a product universe of discourse X x Y. The marginal possibility measure is then defined by the equality IIx (A) = II( A x Y) for any A C X and the marginal possibility distribution by the corresponding expression\n-rrx(x) = sup -rr(x, y) (3) yEY\nfor any x E X. In what follows, we will omit the subscript if there are no doubts which marginal we have in mind.\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 611\n2.2.1 Almost everywhere equality\nA mapping h: X--+ [0, 1] is called fuzzy v ariable. The set of fuzzy variables on X will be denoted by 9(X). LetT be at-norm on [0, 1]. For any possibility measure II on X with distribution 1r, we define the following binary relation on 9(X). For h1 and h2 in 9(X) we say that h1 and h2 are (II, T) -equal almost ev erywhere (and write h1 (II\ufffdT) h2) iff for any x EX\nT(h1(x) , 1r(x) ) = T(h2(x), 1r(x) ) .\nThe strength of this equality is dependent not only on the possibility measure (as in probabilistic framework) but also on the choice of t-norm. For example, for product t-norm it means that the equivalent functions may differ only on a set E such that II (E) = 0, while for Godel's one the classes of equivalence are much wider. For more details see (de Cooman 1997).\nThis notion is very important for the definition of con ditional possibility distribution as well as for that of (conditional) independence.\n2.2.2 Conditioning\nConditional possibility distribution is defined as any solution of the equation\n1rxy (x, y) = T(7ry(y),1rxjY(xl y) ) , (4) for any (x, y) EX x Y. The solution of this equation is not unique (in general), but the ambiguity vanishes when almost everywhere equality is considered. We are able to obtain a representative of these conditional possibility distributions (if T is a continuous t-norm) by taking the residual\n(ITy,T) 1rxjY (xl\u00b7) = 1rxy (x, \u00b7 ).6.T7ry ( \u00b7), (5) which is defined as the greatest solution of the equation (4) (cf. also Section 2.1).\nWe note that if we use product t-norm, we will ob tain Dempster's rule of conditioning (Dempster 1967), Lukasziewicz' t-norm corresponds to \"Lukasziewicz' \" rule of conditioning2 (Fonck 1994), Godel's t-norm leads to Hisdal's rule of conditioning (Hisdal 1978), and the choice of Godel's t-norm together with (5) gives the modification of Hisdal's rule proposed by (Dubois and Prade 1988).\n2.2.3 Independence\nDe Cooman considered two variables X and Y pos sibilistically T -independent iff for any Fx E x-1\\f (X)), Fy E y- 1(P(Y)) and any Gx E {Fx, Fx}, Gy E {Fy, FF}\nII (Gx n Gy) = T (II(Gx ), II (Gy ) ).\n2This conditioning rule is somewhat questionable: from impossible combination of events we can obtain that one of them conditioned by the other is \"somewhat possible\"; for more discussion see (Vejnarova 1999).\nFrom this definition it immediately follows that the independence notion is parameterized by T. This fact was not mentioned in Zadeh's and Hisdal's works since they used only one t-norm, Godel's t-norm. Fur thermore, de Cooman's definition reveals the relation ship between independence of variables and events; for more details see (de Co oman 1997).\nWhat is more important, from the viewpoint taken in this paper, is the following theorem which is an imme diate consequence of Proposition 2.6. in (de Cooman 1997).\nTheorem 1 Let us assume that t-norm T is continu ous. Then the following propositions are equiv alent.\n(i) X and Y are T-independent.\n(ii) For any x E X and y E Y\n7rxy(x, y) = T (1rx(x) , 1ry( y) ).\n(iii) For any x E X and y E Y\nT(1rx (x) ,1ry(y) ) T(7rXJY(xiy), 1ry(y) ) = T(7rYJx (Yi x) , 1rx(x) ) .\nThis theorem shows that the notion of independence defined by de Cooman is equivalent (forT= min) to Zadeh's notion of noninteractivity (Zadeh 1978) and, in a sense, also to Hisdal 's notion of independence (His dal 1978) - if the equality sign in her definition is substituted by almost everywhere equality.\n3 CONDITIONAL INDEPENDENCE\nAmong the properties satisfied by the ternary relation !(X, Y IZ) of independence, regardless the framework in question, the following are of principal importance:\n(A1) !(X, YIZ) --+ I(Y, X IZ) symmetry, (A2) I( X, Y ZIW) --+ !(X, ZIW) decomposition, (A3) !(X, Y ZIW) --+ !(X, YIZW) weak union, (A4) [I(X, YIZW) (\\ !(X, ZIW)] --+ !(X, y ZIW)\ncontraction,\n(A5) [I( X, YIZW) (\\ !(X, ZIYW)] --+ !(X, y ZIW) intersection.\n3.1 CONDITIONAL T-INDEPENDENCE\nIn light of the above-mentioned facts (cf. Theorem 1), in (Vejnarova 1998) we defined the conditional possi bilistic independence in the following way. Variables X andY are possibilistically conditionally T -independent given Z (h(X, YIZ) ) iff for any pair (x, y) EX x Y\n(IIz,T) 7rxyrz (x, Yi\u00b7) = T(7rxrz (xl\u00b7), 7ryrz (Yi\u00b7)). (6)\n612 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nLet us stress again that we do not deal with pointwise equality, but with almost ev erywhere equality in con trast to the conditional noninteractivity (Fonck, 1994). The following theorem proven in (Vejnarova, 1999) is a \"conditional counterpart\" of Theorem 1.\nTheorem 2 Let us assume that t-norm T is continu ous. Then the following propositions are equiv alent.\n(i) X andY are T-independent giv en Z.\n(ii) For any x E X, y E Y and z E Z T(7rx1Yz(xiy, z), 1ryz(y, z)) =\n= T(1rx1z(xlz), 1ryz(y, z)).\nTheorem 2 unifies the notions of conditional nonin teractivity (Fonck 1994) and various notions of condi tional independence, which can be found in (de Cam pos and Huete 1999), (Fonck 1994) (if we use specific\nt-norms) in the sense that pointwise equalities are sub stituted by almost ev erywhere ones.\nIt should also be mentioned that one particular type of conditional independence lr(X, YIZ) has been pro posed in (de Campos and Huete 1995) for Godel's t norm.\n3.2 SEMI-GRAPHOID PROPERTIES OF CONDITIONAL T-INDEPENDENCE\nIn (Vejnarova 1999) we studied semi-graphoid proper ties of the relation Ir (X , Y I Z) and proved\nTheorem 3 For any continuous t-norm T, the rela tion Ir(X, YIZ) satisfies (Al)- (A4).\nProperty (A5) is not fulfilled in general, which is ob vious from Example 1. This example was previously published in (Vejnarova 1999), but it seems useful to have it reiterated here, as we will see later.\nExample 1 Let X= Y = Z = {0, 1} and\nJrxyz(x, y, z) = { 6 if X = y = z, else. Then\nJrxy(x, y) = { 1 if X = y, 0 else, 7rxz(x, z) = { 1 if X = z, 0 else, 1ryz(y, z) = { 1 if y = z, 0 else,\nand Jry = 7rz = 1. Then, for any continuous t-norm,3 7rXYiz(x, yiz) = T(7rxlz(xlz), 7rylz(ylz)), 1rXziY(x, zly) = T(7rxiY(xly), 7rziY(zly)),\n3Let us note that the following equalities are pointwise, since rry = rr z = 1.\nfor any (x, y, z) E X x Y x Z, but e.g.\nJrxyz(1, 0, 0) # T(1rx (1), 7ryz(O, 0)), i.e., lr(X, YIZ) and Ir(X, ZIY) hold, but Ir(X, Y Zl0) does not. <>\nTherefore we concluded:\nProposition 2 There exists no t-norm T such that lr(X, YIZ) satisfies (A1)-(A5) for arbitrary possibil ity distribution.\n3.3 GRAPHOID PROPERTY FOR ARCHIMEDEAN T-NORMS\nThis fact perfectly corresponds to the properties of probabilistic conditional independence. In probability theory, (A5) need not be satisfied if the probability dis tribution is not strictly positive. In this case the con ditional probability distributions need not be defined uniquely. In possibility theory this non-uniqueness is caused by the use of t-norms. If we adopt the ax iomatic approach presented in this paper, satisfaction of (A5) depends on the choice of at-norm and on the properties of the possibility distribution in question. If we choose an Archimedean t-norm, (A5) is always satisfied by strictly positive possibility distributions, as expressed by Theorem 4.\nLemma 1 Let T be a strict t-norm and 1r(x, y, z) be strictly positiv e. Then the following statements are equiv alent.\n(i) Variables X and Y are conditionally T -indepen dent given Z.\n(ii) Joint distribution of X , Y and Z has a form\n1r(x, y, z) = <p-1(P1 (x, z) \u00b7 pz(y, z)), for some P1 and pz, such that P1 (x, z) \u00b7 pz(y, z) E [0, 1] for all (x,y,z) E X x Y x Z, and {0, 1} automorphism <p, such that T is <p-transform of product t-norm.\nProof Let (i) be satisfied. Then\n1r(x,y,z) T(T(1r(xlz), 1r(ylz)), 1r(z)) = T(1r(xlz), 1r(y, z)) = <p-1(<p(7r(xlz)) \u00b7 <p(1r(y, z)))\nby (1) and (i) in Proposition 1, and therefore (ii) is obviously fulfilled (e.g. Pl(x, z) = <p(7r(xlz)) and pz(y, z) = <p(1r(y, z))). Let (ii) be satisfied. Then by (2), (1) and (i) in Propo sition 1\n1rXYiz(x, y, z) = = <p-1 (pi(x, z) \u00b7 pz(y, z)) l::,.T<p-1 (pi(z) \u00b7 pz(z)) =\n= <p-1 (p1(x,z) \u00b7pz(y,z)) = P1 (z) \u00b7 pz(z)\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 613\n= <p -1 ( Pl ( x, z) \u00b7 P2 ( z) . Pl ( z ) \u00b7 P2 (y, z ) ) = pl(z) \u00b7 P2(z) pl(z) \u00b7 P2(z) = <p_1 (<p(<p-1 (p!(x, z) \u00b7 P2(z))) . <p(<p-1 (p1(z) \u00b7 P2(z)))\n. <p(<p-1 (p1(z) \u00b7 P2(Y, z)))) = <p(<p-1 (p1 ( z) \u00b7 P2(z)))\n= <p_1 (<p(7rxz(x, z)) . <p(7ryz(y, z))) = <p(7rz(z)) <p(7rz(z)) = <p-1 (<p(7rxlz(xlz)) \u00b7 <p(7rylz(ylz))) = T(1rx1z(xlz), 7rylz(ylz)),\ni.e. (i) is satisfied. 0\nLemma 2 LetT be a nilpotent t-norm and 1r(x, y, z) be strictly positiv e. Then the following statements are equiv alent.\n(i) Variables X and Y are conditionally T -indepen dent given Z.\n(ii) Joint distribution of X, Y and Z has a form 1r(x, y, z) = 'l/J-1(p1(x, z) + P2(Y, z)),\nfor some P1 and P2, such that pl(x, z) + P2 (y, z) E [0, 1] for all (x, y, z) E X x Y x Z, and {0,1] automorphism '1/J, such that T is '1/J-transform of Lukasziewicz t-norm.\nProof Let (i) be satisfied. Then we have (analogous to the proof of Lemma 1)\n1r(x, y, z) = T(T(1r(xlz), 1r(ylz)), 1r(z)) = = 'l/J-1('1/J(7r(xlz)) + 'l/J(1r(y, z))- 1)\nby (1) and (ii) in Proposition 1, and therefore (ii) is obviously satisfied (e.g. p1(x, z) = 'l/J(7r(xlz)) and P2(y, z) = 'l/J(1r(y, z))- 1). Let (ii) be satisfied. Then by (2), (1) and (ii) in Propo sition 1 ITXYiz(x, y, z) =\n= '1/J-1 (p!(x, z) + P2(Y, z)) t::.T L:::.T'l/J-1 (p1(z) + P2(z)) = = '1/J-1 ((p!(x, z) + P2(Y, z)) -(p!(z) + P2(z)) + 1) = = '1/J-1 ((p1(x, z) + P2(z))- (p1(z) + P2(z))+ +(p!(z)+P2(Y, z))- (pl(z)+P2(z))+1) = = '1/J -1 ( ( '1/J ( '1/J -1 (P1 (X' z) + P2 ( z))) -'1/J('I/J-1 (p1(z) + P2(z))) + +'1/J('I/J-1 (p1(z) + P2(Y, z))) -'1/J('I/J-1 (p!(z) + p2(z))) + 1) = = '1/J-1 ('l/J(7rxz(x, z))- 'l/J(7rz(z))+ +'l/J(7ryz(y, z))- 'l/J(7rz(z)) + 1) =\n= '1/J-1 ('1/J(ITXIZ(xjz))- 1 + 'l/J(7rylz(yjz))) = = T(1rx1z(xlz), 7rylz(yiz)),\ni.e. (i) is satisfied. 0\nTheorem 4 LetT be an Archimedean t-norm and 1r be strictly positiv e possibility distribution. Then ( A5} is also satisfied.\nProof. Let h(X, YIZW) and h(X, ZjYW) be satis fied. Due to the fact that t-norm Tis Archimedean, 1r has either the form\nITXYzw(x,y,z,w) = = <p-1 (P1 (x, z, w) \u00b7 P2(Y, z, w)) = = <p-1 (a-1(x, y, w) \u00b7 a-2(y, z, w))\ndue to Lemma 1, or the form\n7rxyzw(x, y, z, w) = = '1/J-1 (p1(x,z,w) + p2(y,z,w)) = = '1/J-1 (a-I(x, y, w) + a-2(y, z, w))\ndue to Lemma 2.\nThus, we have, in the first case, for all z\n( ) P1( x,z,w) \u00b7 P2(y,z,w) 0\"1 x, y, w = ( )\n. a-2 y,z,w Choosing a fixed z = z0 we have\nwhere\nand\nTherefore\na-1(x,y,w) = f(x,w) \u00b7g(y,w)\nf(x, w) = p!(x, zo, w)\n( ) P2(Y, zo, w) g y, w = ( ) . lT2 y, zo, w\n7rxyzw(x, y, z, w) = = <p-1 (f(x, w) \u00b7 g(y, w) \u00b7a-2(y, z, w))\nand f(x, w) \u00b7 g(y, w) \u00b7 a-2(y, z, w) E [0, 1] for all ( x, y, z, w) E X x Y x Z x W, since both P1 ( x, z, w) \u00b7 P2(y,z,w) E [0,1] and a-1(x,y,w) \u00b7a-2(y,z,w) E [0,1] for all (x,y,z,w) E X x Y x Z x W, and hence h(X, Y ZIW) (again due to Lemma 1) as desired. The proof in the second case is completely analogous. We have that for all z\na-1(x, y, w) = P1(x, z, w) + P2(Y, z, w) - a-2(y, z, w). Choosing a fixed z = z0 we have\na-1(x, y, w) = f(x, w) + g(y, w) where f(x, w) = Pl(x, zo, w) and g(y, w) = P2(y, zo, w)- a-2(y, zo, w) Therefore\n7rxyzw(x,y,z,w) = = '1/J-1 (f(x, w) + g(y, w) + a-2(y, z, w))\nand f(x, w) + g(y, w) + a-2(y, z, w) E [0, 1] for all (x, y, z, w) E X x Y x Z x W, (the arguments are\n614 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nthe same as above), and hence Ir (X, Y Z I W) (again due to Lemma 2) as desired. 0\nSince Godel's t-norm is not Archimedean, Theorem 4 does not hold true for it, as can be seen from the fol lowing example:\nExample 2 Let X = Y = Z = {0, 1} and\n1l'xyz (x, y, z) = { l Then analogous to Example 1 if X = y = z, else.\n7l'XYiz (x, yiz) 1l'XZIY (x, z iy)\nmin (1l'XIz (xiz), 1l'ylz (yjz)), min (7l'xiY (x!y), 1l'ziY (z iy)),\nfor any (x, y, z) EX x Y x Z, but e.g.\n1l'xyz(1, 0, 0) #min 7l'x(1), 1l'yz (O, 0)),\ni.e. Ic(X, YIZ) and Ic(X, ZIY) hold, but Ic(X, Y Z!0) does not. <>\n4 MARKOV PROPERTIES AND FACTORIZATION\nBefore introduction of Markov properties4 and factor ization, let us present a few necessary notions from graph theory.\nA graph is a pair G = (V, E), where V is a finite set of vertices and the set of edges E is a subset of the set V x V of (unordered) pairs of distinct vertices. A subset of the vertex set A \ufffd V induces a subgraph GA = (A, EA), where the edge set EA =E n '(Ax A) is obtained from G by keeping edges with both end points in A. A graph is complete if all vertices are joined by a line. A subset is complete if it induces a complete subgraph. A maximal (with respect to set inclusion) complete subset is called clique.\nIf there is a line between a E V and b E V , a and b are said to be adjacent, otherwise they are non-adjacent. The boundary bd(A) of a subset A of vertices is the set of vertices in V \\A that are adjacent to vertices in A. The closure of A is cl(A) = AU bd(A).\nIf there is a path from a to b (a sequence a = ao, a 1, . . . , an = b of distinct vertices such that (a;_1, a;) E E for all i = 1, . . . , n) we say that a and b are in the same connectivity component. A subset S \ufffd V is called an (a, b)-separator if all paths from a to b intersect S. The subset C separates A from B if it is an (a, b)-separator for every a E A and bE B.\n4Markov properties studied in this section are, in a sense, generalization of the well-known property defining Markov chains; see e.g. (Meyer 1967)\n4.1 MARKOV PROPERTIES\nNow, let us consider the conditional independence in a special situation: we have a graph G = (V, E) and a finite collection of variables (X;) ;EV taking their values in (X;)iEV. For A C V we define\nxA = x iEAxi and X = Xv. Here we will use, for simplicity sake, the symbol fr(A,BIC) instead of Ir(XA,XniXc). With any undirected graph G = (V, E) and a collection of variables (X;)iEV we can (analogous to probability theory) associate three different Markov properties. A possibility measure is said to obey\n(P) the pairwise Markov property, relative to G and T if, for any pair (i, j) of non-adjacent vertices,\nIr(i,jjV \\ {i,j}); (L) the local Markov property, relative toG and T if,\nfor any vertex i E V , Ir(i, v \\ cl(i)lbd(i));\n(G) the global Markov property, relative to G and T if, for any triple (A, B, S) of disjoint subsets of V such that S separates A from B in G,\nIr (A, BJS).\nThe global Markov property (G) gives the general cri terion for deciding whether two groups of variables A and B are conditionally independent, given a third group of variables S. It is the strongest property, as can be seen from Theorem 5.\nThe following two theorems (Theorem 5 and Theo rem 6) are presented without proofs. Their proofs can be found in (Lauritzen 1996), since they completely depend on semi-graphoid and graphoid properties, re spectively, and not on the distributions in question.\nTheorem 5 For any undirected graph G and any pos sibility distribution on X it holds true that\n(G) \ufffd (L) \ufffd (P) . (7)\nThese three properties are really different (analogous to probabilistic framework), as can be seen from the following two examples, inspired by Example 3.6 and Example 3.5 from (Lauritzen 1996).\nExample 3 Let X = Y = Z = {0, 1} and the joint distribution of three bivariate variables X, Y and Z on the graph\n0\nbe defined as in Example 1. From the results ob tained in that example, we can see that this possibil ity distribution satisfies the pairwise Markov property (P), since lr(X, ZIY), but does not satisfy the local Markov property (L), since not fr(X, Y ZJ0). <>\nUNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000 615\nExample 4 Let U = W = X = Y = Z = {0, 1} and the joint possibility distribution of five bivariate variables be defined on the graph G\nas follows\n\u2022(u,w, x,y, z) = { : if u=w= 1&x=y=z=O, or u=w=x=O&y=z=1, else.\nIt is easy (but somewhat time-consuming) to verify that this distribution satisfies (L) (for any continuous t-norm T) but, since\nT( 7rUWIX (0, OIO) , 7rYZIX (0, OIO) ) = 1 t =F 0 = 7ruwYzlx (O, 0, 0, OIO) ,\nit does not satisfy (G) (again for arbitrary continuous t-norm T). <>\nNote that it was necessary to use five variables in Ex ample 4, since (G) {:::::::? (L) up to lVI = 4. To see this, let us consider three disjoint subsets of V: A, B, S, such that S separates A from B. Let us assume that each of these subsets is nonempty (otherwise the equiv alence is trivial). Then at least one of A and B is a singleton {i}, and therefore bd{i} \ufffd S. Then (G) fol lows from (L) using weak union (A3).\nTheorem 6 If a possibility distribution on X is such that ( A5) holds true for disjoint subsets A, B, C, D substituted for X, Y, Z, W then\n(G) {:::::::? ( L) {:::::::? ( P) .\nDue to the results obtained in the previous section (Theorem 4), we immediately get the following\nCorollary 1 LetT be an Archimedean t-norm and 1r a strictly positiv e possibility distribution. Then\n(G) {:::::::? ( L) {:::::::? ( P) .\n4.2 FACTORIZATION\nFactorization is a property even more strict than the global Markov property (G). We will say that a pos sibility distribution 1r factorizes (has a property (F)) with respect to G and T, if, for all complete subsets A \ufffd V, there exist non-negative functions \u00a2A of XA such that 1r has the form\n7r(x) = TIAI(1/JA1 (xA,), ... ' 1/JAIAI (xAIAI)),\nwhere A denotes the set of all complete subsets of V. The functions 1/J A are not uniquely determined (in gen eral), since they can be \"multiplied\" in several ways.\nWithout loss of generality we can assume (cf. (Lau ritzen 1996)) that only cliques (maximum complete subgraphs) appear as the sets, i. e., that\n1r(x) = TICI(\u00a2c1(xc,),. \u00b7 .,1/Jc1c1(xclcl)), (8)\nwhere C denotes the set of all cliques of G.\nTheorem 7 LetT be an Archimedean t-norm. Then, for any undirected graph G and any possibility distri bution 1r on X,\n(F) ===> (G).\nProof Let A, B, S be three disjoint subsets of V such that S separates A from B. Let A denote the connec tivity component in subgraph of G induced by V \\ S containing A and let B = V \\(AU S) . Since A and B are separated by S, their elements must be in different connectivity components of the subgraph induced by V\\S, and any clique of G is a subset of either A uS or BUS. Let us denote by CA the set of cliques contained in AU S. Using (8), we get\n7r(x) y1CI(\u00a2c1 (xc1), ... , 1/Jclcl(xclcl)) =\nT ( yiCAI ( 1/Jc1 (xc1), ... , 1/JclcAI (xclcAI) ), yiC\\C AI (\u00b7'\u00b7c' (xc') '1'c' (xc' ))) = 'f/ 1 1 , ... , 'f/ IC\\CAI IC\\CAI T(pl(X.Aus), (P2(x8us)).\nSince T is Archimedean, we will obtain, due to ProQ_os!tion 1 and Lemma 1 or Lemma 2, that Ir(\ufffd, BIS). Application of decomposition (A2) gives Ir(A, BIS) and the second one (due to symmetry (A1)) lr(A, BjS) as desired. D\nThe reverse of this implication is not valid, as can be seen from the following example:\nExample 5 Let X, Y, Z and W be four bivariate dis tributions defined on the graph with the joint pos sibility distribution 1r defined as follows: any of the following combinations has possibility equal to 1, the remaining combinations are equal to 0:\n(0, 0,0, 0) (0, 0, 0, 1) (0, 0, 1, 1) (0, 1,1,1) (1, 0, 0, 0) (1, 1, 0, 0) (1, 1, 1, 0) (1, 1, 1, 1) .\nFrom this definition we immediately see that 1rx,z = 1ry w = 1 and therefore the conditional distributions eq\ufffdal unconditional ones (for any continuous t-norm). Therefore we have\n1rx zJYw(O, OJO, 0) = 1 = T( 1rxJYw(OJO, 0), 1rzJYw(OJO, 0)) 1rx zJYw(1, OJO, 0) = 1 = T(7rXIYw(lJO, 0), rrz!Yw(OJO, 0)) 7rxzJYw(O, 1JO, 0) = 0 = T(rrxJYw(OJO, 0), 7l'zJYw(1JO, 0)) 7rxzJYw(1, lJO,O) = 0 = T(7rx!Yw(lJO,O), rrz!Yw(1JO,O))\nand similarly for the other values of Y and W. We will also get similar results for 7rYWIX z; therefore, we can see that the distribution 1r satisfies the global Markov property (G) with respect any continuous t norm T and the chordless 4-cycle:\n616 UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000\nBut 1r does not factorize with respect to this graph. To see it, let us assume that 1r factorizes. Then 1 = 7r (O,O,O,O) =\n= T4(\u00a2>xY (0, 0), tf>yz(O, 0), \u00a2>zw(O, 0), \u00a2>wx(O, 0)), but also\n0 = 1r (O, 1, 0, 0) = = T4(\u00a2>xY (0, 1), tf>yz(1, 0), \u00a2>zw(O, 0), \u00a2>wx(O, 0)).\nFrom this we have\nT (tf>xy(O, 1), tf>yz(1, 0)) = 0.\nSince 1 = 7r (1, 1,0,0) =\n= T4 (\u00a2>xy(1, 1), \u00a2>yz(1, 0), \u00a2>zw(O, 0), \u00a2>wx(O, 1)), it is evident that tf>yz (1, 0) = 1, therefore \u00a2>xy(O, 1) = 0. But then 1 = 1r(O, 1, 1, 1) =f.\n=f.T4 (\u00a2>xy(O, 1), tf>yz(1, 1), \u00a2>zw(1, 1), \u00a2>wx(1, 0)) =0; therefore, it is evident that 1r cannot factorize. <>\n5 CONCLUSIONS\nThe goal of this paper was to promote de Cooman's measure-theoretic approach to possibility theory by demonstrating the parallels between the probabilis tic and possibilistic approaches. We have shown that for the wide class of Archimedean t-norms, the condi tional T-independence has the same properties as the conditional independence in probability theory. We also introduced Markov properties of possibility mea sures and demonstrated that the relationships between them are completely analogous with those of prob ability measures. And finally, after introducing the T-factorization, we proved that it implies the global Markov property for Archimedean t-norms.\nThere are still some open problems, which should be solved in the near future. The first one, perhaps most important, concerns Godel's t-norm. Godel's t-norm is the \"classical\" one in possibility theory, but many the orems presented in this paper do not hold true for it, since it is not Archimedean. Hence, the task is to find analogous theorems for Godel's t-norm. The second one is to find an analogy to the Clifford-Hammersley theorem for possibility measures, i.e., to find condi tions under which\n(F) \u00a2:::::> (G) \u00a2:::::> ( L) \u00a2:::::> ( P) .\nThe usefulness of such a theorem is obvious, since it would enable to us to determine whether or not a pos sibility distribution factorizes with respect to a given graph, simply by checking the pairwise Markov prop erty.\nAcknowledgement\nThe research was financially supported by the grants MSMT no. VS96008, GA CR no. 201/98/1487 and KONTAKT ME 200/1998.\nReferences\nB. de Baets, E. Tsiporkova and R. Mesiar (1999). Con ditioning in possibility theory with strict order norms. Fuzzy Sets and Systems 106:221-229.\nL. M. de Campos and J. F. Huete (1999). Indepen dence concepts in possibility theory: part 1, part 2. Fuzzy Sets and Systems 103:127-152, 487-505.\nG. de Cooman (1997). Possibility theory I- III. Int. J. General Systems, 25:291-371.\nA. Dempster (1967). Upper and lower probabilities in duced by multivalued mappings. Ann. Math. Statist., 38:325-339.\nD. Dubois and H. Prade (1988). Possibility theory. Plenum Press, New York.\nP. Fonck (1994). Conditional independence in possibil ity theory. In: R. L. de Mantaras, P. Poole (eds.), Pro ceedings of 10th conference UAI, Morgan Kaufman, San Francisco, 221-226.\nE. Risdal (1978). Conditional possibilities indepen dence and noninteraction, Fuzzy Sets and Systems, 1:299-309.\nS. L. Lauritzen (1996). Graphical models, Oxford Uni versity Press.\nP. A. Meyer (1967). Markov Processes, Springer, LNM 26.\nP. P. Shenoy (1994). Conditional independence in valuation-based systems, Int. J. Approximate Reason ing, 10:203-234.\nW. Spohn (1980). Stochastic independence, causal in dependence and shieldability. J. Phil. Logic, 9:73-99.\nJ. Vejnarova (1998). Possibilistic independence and operators of composition of possibility measures. In: M. Huskova, J. A. Visek, P. Lachout (eds.), Prague Stochastics'98, JCMF, Prague, 575-580.\nJ. Vejnarova (1999). Conditional independence rela tions in possibility theory. In: G. de Cooman, F. Coz man, S. Moral, P. Walley (eds.), IS/PTA '99, Univer siteit Gent, 343-351.\nL. A. Zadeh (1978). Fuzzy sets as a basis for theory of possibility. Fuzzy Sets and Systems, 1:3-28."}], "references": [{"title": "Con\u00ad ditioning in possibility theory with strict order norms", "author": ["B. de Baets", "E. Tsiporkova", "R. Mesiar"], "venue": "Fuzzy Sets and Systems 106:221-229. L. M. de Campos and J. F. Huete (1999). Indepen\u00ad dence concepts in possibility theory: part 1, part 2.", "citeRegEx": "Baets et al\\.,? 1999", "shortCiteRegEx": "Baets et al\\.", "year": 1999}, {"title": "Upper and lower probabilities in\u00ad duced by multivalued mappings", "author": ["A. Dempster"], "venue": "Ann. Math. Statist., 38:325-339.", "citeRegEx": "Dempster,? 1967", "shortCiteRegEx": "Dempster", "year": 1967}, {"title": "Possibility theory", "author": ["D. Dubois", "H. Prade"], "venue": "Plenum Press, New York.", "citeRegEx": "Dubois and Prade,? 1988", "shortCiteRegEx": "Dubois and Prade", "year": 1988}, {"title": "Conditional independence in possibil\u00ad ity theory", "author": ["P. Fonck"], "venue": "In: R. L. de Mantaras, P. Poole (eds.), Pro\u00ad ceedings of 10th conference UAI, Morgan Kaufman, San Francisco, 221-226.", "citeRegEx": "Fonck,? 1994", "shortCiteRegEx": "Fonck", "year": 1994}, {"title": "Conditional possibilities indepen\u00ad dence and noninteraction", "author": ["E. Risdal"], "venue": "Fuzzy Sets and Systems,", "citeRegEx": "Risdal,? \\Q1978\\E", "shortCiteRegEx": "Risdal", "year": 1978}, {"title": "Conditional independence in valuation-based systems, Int", "author": ["P.P. Shenoy"], "venue": "J. Approximate Reason\u00ad ing, 10:203-234. W. Spohn (1980). Stochastic independence, causal in\u00ad dependence and shieldability. J. Phil. Logic, 9:73-99.", "citeRegEx": "Shenoy,? 1994", "shortCiteRegEx": "Shenoy", "year": 1994}, {"title": "Possibilistic independence and operators of composition of possibility measures", "author": ["J. Vejnarova"], "venue": "In: M. Huskova, J. A. Visek, P. Lachout (eds.), Prague Stochastics'98, JCMF, Prague, 575-580.", "citeRegEx": "Vejnarova,? 1998", "shortCiteRegEx": "Vejnarova", "year": 1998}, {"title": "Conditional independence rela\u00ad tions in possibility theory", "author": ["J. Vejnarova"], "venue": "In: G. de Cooman, F. Coz\u00ad man, S. Moral, P. Walley (eds.), IS/PTA", "citeRegEx": "Vejnarova,? 1999", "shortCiteRegEx": "Vejnarova", "year": 1999}, {"title": "Fuzzy sets as a basis for theory of possibility", "author": ["Univer\u00ad siteit Gent", "343-351. L.A. Zadeh"], "venue": "Fuzzy Sets and Systems,", "citeRegEx": "99 et al\\.,? \\Q1978\\E", "shortCiteRegEx": "99 et al\\.", "year": 1978}], "referenceMentions": [{"referenceID": 3, "context": "Good examples of this fact include the numerous papers studying conditional independence in various calculi (de Campos and Huete 1999) (Fonck 1994) (Shenoy 1994) (Spohn 1980).", "startOffset": 135, "endOffset": 147}, {"referenceID": 5, "context": "Good examples of this fact include the numerous papers studying conditional independence in various calculi (de Campos and Huete 1999) (Fonck 1994) (Shenoy 1994) (Spohn 1980).", "startOffset": 148, "endOffset": 161}, {"referenceID": 7, "context": "With this paper, we will continue our efforts in the area of possibility theory (Vejnarova 1999), attempting to unify the conditional independence notion.", "startOffset": 80, "endOffset": 96}, {"referenceID": 1, "context": "We note that if we use product t-norm, we will ob\u00ad tain Dempster's rule of conditioning (Dempster 1967), Lukasziewicz' t-norm corresponds to \"Lukasziewicz' \" rule of conditioning2 (Fonck 1994), Godel's t-norm leads to Hisdal's rule of conditioning (Hisdal 1978), and the choice of Godel's t-norm together with (5) gives the modification of Hisdal's rule proposed by (Dubois and Prade 1988).", "startOffset": 88, "endOffset": 103}, {"referenceID": 3, "context": "We note that if we use product t-norm, we will ob\u00ad tain Dempster's rule of conditioning (Dempster 1967), Lukasziewicz' t-norm corresponds to \"Lukasziewicz' \" rule of conditioning2 (Fonck 1994), Godel's t-norm leads to Hisdal's rule of conditioning (Hisdal 1978), and the choice of Godel's t-norm together with (5) gives the modification of Hisdal's rule proposed by (Dubois and Prade 1988).", "startOffset": 180, "endOffset": 192}, {"referenceID": 2, "context": "We note that if we use product t-norm, we will ob\u00ad tain Dempster's rule of conditioning (Dempster 1967), Lukasziewicz' t-norm corresponds to \"Lukasziewicz' \" rule of conditioning2 (Fonck 1994), Godel's t-norm leads to Hisdal's rule of conditioning (Hisdal 1978), and the choice of Godel's t-norm together with (5) gives the modification of Hisdal's rule proposed by (Dubois and Prade 1988).", "startOffset": 366, "endOffset": 389}, {"referenceID": 7, "context": "2This conditioning rule is somewhat questionable: from impossible combination of events we can obtain that one of them conditioned by the other is \"somewhat possible\"; for more discussion see (Vejnarova 1999).", "startOffset": 192, "endOffset": 208}, {"referenceID": 6, "context": "Theorem 1), in (Vejnarova 1998) we defined the conditional possi\u00ad bilistic independence in the following way.", "startOffset": 15, "endOffset": 31}, {"referenceID": 3, "context": "Let us stress again that we do not deal with pointwise equality, but with almost ev erywhere equality in con\u00ad trast to the conditional noninteractivity (Fonck, 1994).", "startOffset": 152, "endOffset": 165}, {"referenceID": 7, "context": "The following theorem proven in (Vejnarova, 1999) is a \"conditional counterpart\" of Theorem 1.", "startOffset": 32, "endOffset": 49}, {"referenceID": 3, "context": "Theorem 2 unifies the notions of conditional nonin\u00ad teractivity (Fonck 1994) and various notions of condi\u00ad tional independence, which can be found in (de Cam\u00ad pos and Huete 1999), (Fonck 1994) (if we use specific t-norms) in the sense that pointwise equalities are sub\u00ad stituted by almost ev erywhere ones.", "startOffset": 64, "endOffset": 76}, {"referenceID": 3, "context": "Theorem 2 unifies the notions of conditional nonin\u00ad teractivity (Fonck 1994) and various notions of condi\u00ad tional independence, which can be found in (de Cam\u00ad pos and Huete 1999), (Fonck 1994) (if we use specific t-norms) in the sense that pointwise equalities are sub\u00ad stituted by almost ev erywhere ones.", "startOffset": 180, "endOffset": 192}, {"referenceID": 7, "context": "In (Vejnarova 1999) we studied semi-graphoid proper\u00ad ties of the relation Ir (X , Y I Z) and proved", "startOffset": 3, "endOffset": 19}, {"referenceID": 7, "context": "This example was previously published in (Vejnarova 1999), but it seems useful to have it reiterated here, as we will see later.", "startOffset": 41, "endOffset": 57}], "year": 2011, "abstractText": "Conditional independence and Markov prop\u00ad erties are powerful tools allowing expression of multidimensional probability distributions by means of low-dimensional ones. As mul\u00ad tidimensional possibilistic models have been studied for several years, the demand for analogous tools in possibility theory seems to be quite natural. This paper is intended to be a promotion of de Cooman's measure\u00ad theoretic approach to possibility theory, as this approach allows us to find analogies to many important results obtained in prob\u00ad abilistic framework. First we recall semi\u00ad graphoid properties of conditional possibilis\u00ad tic independence, parameterized by a contin\u00ad uous t-norm, and find sufficient conditions for a class of Archimedean t-norms to have the graphoid property. Then we introduce Markov properties and factorization of possi\u00ad bility distributions (again parameterized by a continuous t-norm) and find the relation\u00ad ships between them. These results are ac\u00ad companied by a number of counterexamples, which show that the assumptions of specific theorems are substantial.", "creator": "pdftk 1.41 - www.pdftk.com"}}}