{"id": "1301.7379", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Towards Case-Based Preference Elicitation: Similarity Measures on Preference Structures", "abstract": "while decision theory provides an appealing normative framework for representing rich preference structures, eliciting utility or value functions typically incurs demands a large cost. for many applications involving interactive systems this costly overhead precludes the use of appropriate formal decision - theoretic models of preference. instead characteristic of performing elicitation in a vacuum, it would be useful if we could augment directly elicited preferences with some appropriate default information. in this paper we propose a case - based approach to alleviating the preference elicitation bottleneck. assuming the existence requirement of a population of users from whom we have elicited complete or incomplete preference structures, we tentatively propose simply eliciting the preferences of a new user interactively and incrementally, using the closest intact existing preference structures as potential defaults. since a notion of closeness demands a measure of distance among preference structures, this paper takes the first step process of strictly studying various distance measures over fully and partially specified preference structures. we explore the use of euclidean distance, spearmans footrule, and define a new measure, the probabilistic distance. we provide computational techniques for all three measures.", "histories": [["v1", "Wed, 30 Jan 2013 15:04:06 GMT  (389kb)", "http://arxiv.org/abs/1301.7379v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["vu a ha", "peter haddawy"], "accepted": false, "id": "1301.7379"}, "pdf": {"name": "1301.7379.pdf", "metadata": {"source": "CRF", "title": "Toward Case-Based Preference Elicitation: Similarity Measures on Preference Structures", "authors": ["Vu Ha", "Peter Haddawy"], "emails": ["@cs.uwm.edu"], "sections": [{"heading": null, "text": "While decision theory provides an appealing normative framework for representing rich preference structures, eliciting utility or value functions typically incurs a large cost. For many applications involving interactive sys tems this overhead precludes the use of for mal decision-theoretic models of preference. Instead of performing elicitation in a vacuum, it would be useful if we could augment di rectly elicited preferences with some appro priate default information. In this paper we propose a case-based approach to alleviat ing the preference elicitation bottleneck. As suming the existence of a population of users from whom we have elicited complete or in complete preference structures, we propose eliciting the preferences of a new user inter actively and incrementally, using the closest existing preference structures as potential de faults. Since a notion of closeness demands a measure of distance among preference struc tures, this paper takes the first step of study ing various distance measures over fully and partially specified preference structures. We explore the use of Euclidean distance, Spear man's footrule, and define a new measure, the probabilistic distance. We provide computa tional techniques for all three measures.\n1 INTRODUCTION\nWe are interested in the problem of building interac tive systems for which task objectives will be commu nicated in the form of user preferences. Utility the ory, the branch of decision theory that deals with rep resentation of preferences, provides a rich normative framework that is capable of capturing such aspects of preferences as tradeoffs among objectives and atti-\ntudes toward risk. But the task of eliciting a utility function is typically time consuming and tedious. For many applications involving interactive systems such overhead can preclude the use of utility theory since the cost in time and effort may be too large relative to the value of the sought after solution or because time may simply be limited. For example, we would be very unhappy if a system designed to help us select a video to watch required as much time as the entire length of the film just to elicit our preferences.\nTo reduce elicitation overhead, practitioners typically make use of assumptions (e.g. additive independence) that simplify the elicitation task by allowing a high dimensional utility function to be decomposed into a simple combination of lower-dimensional sub-utility functions. But even under such assumptions, elici tation of a complete utility function can still be too time consuming and, furthermore, the assumptions preclude representation of many kinds of interesting and common preferences.\nIn previous work [6), we investigated an approach in which we first elicit partial preference information to produce a set of candidate solutions. We then use the set of candidate solutions to identify the additional in formation to elicit that would likely be most helpful in narrowing down this set. But in order to be able to make useful inferences based only on some prefer ence information, we were forced to assume additive independence of the underlying utility function and to assume that the sub-utility functions are known.\nIn contrast, Linden, etal. [11) supplement elicited pref erences with default information to obtain a complete utility function, which is to be continually adjusted based on the user's feedback. This default preference information represents preferences that are assumed applicable to all users, such as preferences for reduced cost. The user is presented with the optimal solu tion according to the constructed utility function, to gether with some extreme points in the solution space (e.g., cheapest and shortest-time flights). The utility\n194 Ha and Haddawy\nfunction is then modified based on the user's critiques. This approach too assumes an additive utility model in order to facilitate the incorporation of user feedback.\nIn this paper we also take the approach of supplement ing elicited preferences with default information. But rather than applying one default uniformly to all users, we use elicited preferences to select an appropriate de fault from a set of defaults. Specifically, we investigate a case-based approach to providing such default infor mation. The idea is based on the observation that people tend to form clusters according to their prefer ences or tastes, an observation that has been analyzed in a large amount of literature in the area of market segmentation [5]. We envision our system to maintain a population of users with their preferences partially or completely specified in a given domain. When encoun tering a new user A, the system elicits some preference information from A and then determines which user in the population has the preference structure that is closest to the preference structure of A. The prefer ence structure of that user will be used to determine an initial default representation of A's preferences. In contrast with the previously discussed work of [6] and [11], we do not make any restrictive assumptions con cerning the form of the underlying utility functions.\nRealization of this approach to elicitation requires that we have a distance measure on preference structures. In this paper we investigate various distance measures from both theoretical and computational perspectives. The rest of the paper is organized as follows. Section 2 deals with distance measures among completely speci fied preference structures. We revisit some well-known measures such as Spearman's footrule and Euclidean distance and propose to extend these measures to be defined among utility functions. We also propose to define the probabilistic distance that measures the dif ference between two preference structures by the prob ability that they disagree on the rankings of two ran dom alternatives. In Section 3, we extend all of these definitions to define distance measures among partially specified preference structures. We provide a compu tational technique for approximating these distance measures. In Section 4, we describe MovieFinder, an experimental recommender system that recommends movies for people based on this case-based preference elicitation approach. We discuss related work and fu ture research in Section 5.\n2 DISTANCE MEASURES ON PREFERENCE ORDERS\nWe start out with a brief revie:w of utility theory for decision making. The reader is refered to [10] for more details.\nThe process of making decisions is generally modeled as the identification of the optimal alternative(s) from a set M of alternatives, using in effect a weak order\n-<, i.e. an asymmetric (a -< b =? b -/< a), negatively transitive (a -/< b, b -/< c =? a -/< c) binary relation on the set of alternatives. We will call this relation the preference structure of the decision maker: a -< b indicates that the decision maker prefers alternative b to alternative a. When neither of the two alternatives is prefered to the other (a-/< b, b-/< a), we say that the decision maker is indifferent between them and denote this relation by a \"' b. We also use the notation a j b to denote that the decision maker prefers b to a or is indifferent between them. If for all distinct alternatives a and b, either a -< b or b -< a, the -< relation is said to be a strict order.\nAn important technique that is often used in associ ation with preference orders i& the use of consistent functions that capture preference orders.\nDefinition 1 A real-valued function f : M \ufffd \ufffd is said to be consistent with a preference order -< on M if for all a, b E M, a-< b {::} f(a) < f(b).\n2.1 THE CERTAINTY CASE\nWhen a decision problem involves no uncertainty about the alternatives, we call the alternatives out comes, and denote the set of outcomes by n. For ease of exposition, we will assume throughout the paper that n is finite and n = { S1' . . \u2022\n' Sn}. It can be proven\n(10] that for any preference order -< over n there exists a function v, called a value function, that is consistent with -<, and we sometimes write -< as -<v to empha size this relationship. In the case when -< is a strict order, and suppose that the elements of n are indexed in such a way that s1 -< 82 -< ... -< 8n, we can define a value function v as v(83) = j,j = 1, . . . ,nand call this the height of Sj\u00b7 Two value functions that induce identical orders are said to be strategically equivalent. Otherwise, they are said to be strategically different.\nSuppose that there are two users with corresponding preference orders -<1 and -<2, which are weak orders On the finite set S1 = { 81, 82, ... , 8n} of outcomes. We study three distance measures between these two preference orders: Spearman's footrule, Euclidean dis tance, and probabilistic distance.\nOn the set of strict orders, the classical distance mea sure is Spearman's footrule [16]. Suppose that hij, i = 1, 2,j = 1, ... , n is the height of s3 with respect to -<i\u00b7 Then the Spearman's footrule is defined as:\n1 n\nSpearman's footrule: 8s(-<1, -<2) := 2 L lh13-h2jl\u00b7 i=1\nIt is well-known that Spearman's footrule is a metric on strict orders and has the range [0, ln2 /4J] (see, for example [4]). The three requirements for a measure to be a metric are the following (for all strict orders -<i, i = 1, 2, 3): (i) Reflexivity. d(-<1. -<2) 2:: 0,\n\"=\" iff -<1 and -<2 are identical. (ii) Symmetry. d( -<1, -<2) = d( -<2, -<1). (iii) Triangle Inequality. d( -<1, -<3) ::; d( -<1, -<2) + d( -<2, -<3)\u00b7 Another popular distance measure among strict orders is the Euclidean distance, defined as:\nn\nEuclidean distance: oE(-<1, -<2) = L(h1j- h2j)2. i=1\nThe Euclidean distance and Spearman's footrule are defined on the set of strict orders and it is not ob vious how to extend their definitions to weak orders. This is a limitation, since we do not want to rule out cases when there are equally prefered alternatives. In this paper we investigate yet another distance mea sure, called probabilistic distance that is defined on the broader class of weak orders. This distance measure captures the intuition that the difference in preferences of two users should be proportional to the chance that a uniformly randomly chosen pair (a, b) of alternatives will cause a conflict between the two users, i.e, the two users will rank a and b differently. We use an in dicator function to capture conflicts; a conflict occurs when the indicator function takes on the value 1: ! 1 if (a \ufffd1 b 1\\ b -<2 a)V\n(a -<1 bl\\ b \ufffd2 a)V C-<1,-<2(a,b)= (a\ufffd2 bl\\b-<1 a)V\n(a -<2 b 1\\ b \ufffd1 a) 0 otherwise.\nGiven this definition of conflict, the distance between two weak orders (n, -<1) and (n, -<2) is defined as:\nwhere the last equality means that the probability of conflict is the proportion of conflicting pairs of out comes (out of n(n- 1)/2 pairs) .\nProposition 1 The probabilistic distance on the set of weak orders on n is a metric with range [0, 1].\nCase-Based Preference Elicitation 195\nProof: It is evident that the probabilistic distance only takes values between 0 and 1, the distance between two identical orders is zero, and zero distance implies two identical weak orders. The symmetry of the dis tance function trivially follows from the symmetry of the conflict function. Finally, to prove the triangle in equality, we note that for all weak orders -<i, i = 1, 2, 3 and alternatives a, b, c-<t.-<a (a, b) = 1 implies either c-<t.-<2(a,b) = 1 or C-<2,-<3(a,b) = 1, and for all events X, Y, Pr(X V Y) ::; Pr(X) + Pr(Y). D\nExample 1 Suppose that there are three kinds of night entertainment in Milwaukee: going to watch a basketball game {B }, a movie {M }, and going to a blues pub {P ). Suppose that Xaviera's preference or der -<x is such that B -<x M -<x P and Yvette's preference order -<Y is such that M -<Y P -<y B. The distance between their preferences according to Spear man's footrule, Euclidean distance, and probabilistic distance, is Os(-<x,-<Y) = 2, OE(-<x,-<y) = v'6, Op( -<x, -<y) = 2/3, respectively. If we want these distances to be normalized so that their ranges are the interval [0, 1], by dividing by their correponding upper bounds, then the normalized distances are 1, y3l4 = .8660, and 2/3 = .6667, respectively. Now suppose that Zelda's preference order -<z is such that P -<z M -<z B, then the normalized distance between -<x and -<z, according to Spearman's footrule, Euclidean distance, and probabilistic distance, is 1, 1, and 1 (two orders that are reverses of one another have maximum distance).\nIt is clear from Example 1 that according to Eu clidean ( o E) and probabilistic distances ( o p), the pref erences of Yvette are closer to Xaviera's than Zelda's are, while according to Spearman's footrule (o8), they are equally distant. We say that two distance mea sures 81 and 02 on a set M are relatively equivalent if for all a, b, c E M, 81 (a, b) < 01 (a, c) {:} o2(a, b) < 82 (a, c) . For example, the Euclidean distance is rel atively equivalent to the negative of the rank order correlation coefficient ( -p). On the other hand, os is not relatively equivalent to OE and Op. It can be shown that OE and Op are also not relatively equivalent.\nIntuitively, if two distance measures on M are rela tively equivalent, then for any element a E M and a subset K \ufffd M of M, the sets of elements of K that are closest to a according to the two measures are identi cal. Since os, OE, and Op are relatively different, it remains an open question which one we should use for our framework.\n196 Ha and Haddawy\n2.2 THE UNCERTAINTY CASE\nWhen the decision alternatives are uncertain, they are usually modeled by probability distributions over out comes and are called prospects. We denote the set of all probability distributions over 0 by S. The cen tral result of utility theory is a representation theorem that identifies a set of conditions guaranteeing the ex istence of a function consistent with the preferences of a decision maker [19, 14]. The theorem states that if the preference order of a decision maker satisfies a few \"rational\" properties, then there exists a real-valued function, called a utility function u : n -+ \ufffd. over outcomes such that p -< q \u00a2:? (p, u) < (q, u). Here (p, u), the inner product of the probability vector p and the utility vector u, is the expected value of func tion u with respect to the distribution p. It is often convenient to extend u, by means of expectation, to a function u : S -+ \ufffd that maps a prospect p E S to (p, u). This function is clearly consistent with the preference order (S, -<),and we sometimes write -< as -<u to emphasize this relationship.\nIn this paper, we assume that the preference struc tures (which are weak orders over the set of prospects) of the users satisfy the required \"rational\" conditions and thus can be represented using utility functions. We now focus attention on defining a distance mea sure among such preference structures. We investigate two approaches to defining a distance measure: utility based and non-utility-based, according to whether util ity functions of the preference structures are explicitly used in the definitions.\nUtility-Based Distance Measures\nSuppose that the preference structures (S, -<1) and (S, -<2) of two users are represented by their corre sponding utility functions U1\n' U2 : n -+ \ufffd- We shall\ndefine the distance between the preference structures -<1 and -<2 as a function of two utility functions u1 and u2, which can be view as two vectors in the n dimension vector space \ufffdn.\nIt is well-known that utility functions are unique up to a positive linear transformation, i.e., if v1 is also a utility function that represents -<1, then there are a, f3 E \ufffd.a > 0 such that v1 = o:u1 + {3. u1 and v1 are called strategically equivalent utility functions. Thus, a distance measure among preference structures should be defined on the strategic equivalence classes of \ufffdn. This can be done by selecting a representative vector for each equivalence class, and define some distance measure such as Euclidean, or Spearman's footrule like distance among the representatives. To select a representative for each equivalence class, we can spec ify a set of conditions so that exactly one member of\neach equivalence class satisfies those conditions and thus will be chosen as the representative for that class.\nExample 2 Suppose that Xaviera and Yvette are in volved in a decision problem involving lotteries over three possible outcomes a, b, and c. Furthermore sup pose that Xaviera's preferences and attitude toward risks are captured by a utility function ux such that ux(a) = O,ux(b) = 1,ux(c) = 2, and Yvette's prefer ences and attitude toward risks are captured by a utility function uy such that uy(a) = 1, uy(b) = 3, uy(c) = 4. Note that Xaviera and Yvette agree on the ranking of certain outcomes, but have different attitudes to ward risky decisions. Suppose that we require that the representatives for strategic equivalence classes must have 0 as their minimum and 1 as their maximum values, i.e., we scale the utility functions from 0 to 1. With respect to these conditions, the representa tive utility functions of Xaviera and Yvette are ux and uy where ux(a) = O,ux(b) = 1/2,ux(c) = 1, and uy(a) = 0, uy(b) = 2/3, ux(c) = 1. Thus, the Euclidean (8E) and Spearman footrule-like {8s) dis tance between the preference structures of Xaviera and Yvette are: 8E(ux,uy) = JL:8(ux(s) -uy(s))2 = 1/6 and 8s(ux, uy) = 1/2 L:siux(s) -uy(s)l = 1/12.\nNon-Utility-Based Distance Measures\nNote that the above utility-based definitions of dis tance measures are sensitive to the choice of the con ditions to select representative utility functions. Since there appears no rule of thumb to select the represen tatives, these definitions are rather ad-hoc. The same can be said of the Euclidean distance and Spearman's footrule in the certainty case, since the used heights {1, 2, ... , n} of the outcomes, which are a particular choice of value functions, are also arbitrary; any in creasing sequence of numbers can be used instead.\nThe probabilistic distance overcomes this tricky prob lem by relying on the preference structures themselves, rather than a particular choice of value functions. This idea can be extended to the uncertainty case as follows. The distance between two preference orders (S, -<1), (S, -<2) is defined as: 1\n8p(-<1, -<2) = Pr(-<1 & -<2 rank p and q differently) = Is Is C-<1,-<2 (p, q)dpdq,\nwhere the conflict function c-<1,-<2 is defined over a pair (p, q) of prospects in the obvious way. Here we take\n1Note that although this formal definition of the proba bilistic distance does not involve utility functions, any oper ational definition of this measure inevitably does. In fact, any specification of a preference structure over the (infi nite) set of prospects has to involve utility functions.\nall probability distributions into consideration. In the case when the set of candidates is only a subset of S, then it would be more reasonable to integrate over only that set 2\u2022 Based on this definition, we can define the probabilistic distance of two utility functions u1, u2 to be the probabilistic distance of the two preference structures they represent: Op(ul, u2) = Op( -<uu -<u2). Proposition 2 The probabilistic distance on the set of weak orders on S is a metric with range [0, 1].\nProof: [Sketch] The proof of this proposition is identical to that of Proposition 1, except for the somewhat non obvious part that shows that if the distance between two utility functions is 0, then they must be positive linear transformations of each other. The idea here is that for two utility functions u1 and u2, the subset of S x S that consists of pairs of prospects that cause conflict between -<u1 and -<u2 is a union of two convex cones, and it can be shown that this union has zero volume if and only if the two utility functions u1 and u2 are positive linear transformations of each other. D\nExample 3 (Continuation of Example 2) The probabilistic distance between preference structures of Xaviera (-<x) and Yvette (-<y) is:\nd(-<x, -<y)\n=Is Is c\ufffd .. x .\ufffduy (p, q)dpdq = fs fs Neg[(ux o (p- q))(uy o (p- q)]dpdq = 1/9.\nHere p and q run over the probability simplex S, which is the equilateral triangle in R3 with vertices (0, 0, 1), (0, 1, 0), (1, 0, 0), UX = (0, 1, 2), Uy = (0, 2, 3), and Neg is the function that returns 1 if its argument is negative and 0 otherwise.\nNow suppose that Zelda's utility function is uz = (0, 2, 1), which implies that, unlike Xaviera and Yvette, she prefers c with certainty to b with certainty. Cal culations show that o(ux,uz) = 1/3 > 1/9, which is what we would expect: Yvette's preferences are more similar to Xaviera's than Zelda's are.\nClosely related to the distance concept is the similar ity concept in fuzzy-set theory [20, 12]. A similarity relation s is a binary fuzzy relation on a set U that satisfies the following three properties, 'Vu, v, w E U: (i) Reflexivity. s(u, u) = 1. (ii) Symmetry. s (u,v) = s(v,u) .\n(iii) *-Transitivity. s(u,v) * s(v,w) \ufffd s(u,w), 2Provided that the set is measurable.\nCase-Based Preference Elicitation 197\nwhere * is a t-norm, that is, a commutative, associa tive, non-decreasing operation on [0, 1], with 1 being the neutral element (1 * x = x * 1 = x, 'Vx E [0, 1]) and 0 being the absorbent element (0 * x = x * 0 = 0, Vx E [0, 1]). Noticeable t-norms are min, product, and Lukasiewicz operation (l(x,y) = max{O,x + y -1}). Note that the complement of the probabilistic dis tance, defined as s(-<1,-<2) = 1- Op(-<1, -<2)- the probability that two users with preference orders -<1 and -<2 will have the same preference over a uniformly randomly chosen pair (a, b) of alternatives- is a fuzzy similarity relation with respect to Lukasievicz t-norm.\n3 DISTANCE MEASURES ON PARTIALLY SPECIFIED PREFERENCE ORDERS\nWhile the distance functions proposed in the previous section provide various similarity measures that could be used to cluster preferences of multiple users, they are not much good for preference elicitation. For the purpose of elicitation we need to be able to compute the distance when at least one of the preference orders is only partially specified.\nWe first clarify what we mean by \"partially specified\" preference orders. Recall that a completely specified preference structure -< on the set M of alternatives is a weak order, i.e., an asymmetric, negatively transitive binary relation on M. For a decision maker whose pref erence structure we have completely elicited, given any two alternatives a and b, we know that there are only three possibilities: either she prefers b to a (a -< b), a to b (b -< a), or indifferent between a and b (a \"' b). However, when we have little information about the preferences of the decision maker, it might be the case that we can not say anything about her preferences over some two alternatives a and b, meaning that none of the above three possibilities applies. In such cases, we say that the preference between a and b is not spec ified, or a and b are incomparable, denoted by a II b. Thus, a partially specified order can be viewed as a partial order, or generalized weak order where for any pair of alternatives (a, b), exactly one of the four rela tions -<, >-, \"', and II holds.\nFor simplicity, we will call a partially specified prefer ence order, which is a 3-tuple ( -<,\"',II), a partial pref erence order and denote it by -<. We need a slightly different definition of consistent functions - functions that are consistent with partial preference orders.\nDefinition 2 A real-valued function f : M \ufffd lR is said to be consistent with a partial preference order -< on M if for all a,b E M, a -< b => f(a) < f (b) and a\"' b => f(a) = f(b).\n198 Ha and Haddawy\nNote that the above definition does not specify what happens when a II b. Intuitively, consistent functions capture all information contained in the partial orders, and they might contain more than that.\nWe now turn our attention to defining a distance mea sure among partially specified preference orders. In this paper we focus on the certainty case and define a distance measure among partial orders on n. Suppose the preference structures of two users are partially specified by two partial preference orders (0, -<i), i = 1, 2. Let V:* be the set of all functions that are consistent with partial order -<i, and \"Vi be the set of equivalence classes of Vi* with respect to the strategic equivalence of value functions. We can also view \"Vi as a subset of Vi* that contains strategically different functions, and any member function of Vi* is strategically equivalent to some member of \"Vi. We will use this interpretation from now on.\nWe can also view each partial order -<i as a set of complete orders that are consistent\u00b7 with it, where con sistency means that any relation between any pair of elements that holds with respect to the partial order also holds with respect to the complete orders. In the literature of graphs and orders, partial orders are also called posets, and the consistent complete orders of a poset are called its linear extensions. It is not hard to see that { -<v,: Vi E \"Vi} is just the set of linear exten sions of the partial order -<i\u00b7 For simplicity, we will refer to Vi as a linear extension, and \"Vi is the set of all linear extensions of -<i\u00b7\nSo the problem now reduces to the problem of defining a distance measure on the space of finite posets over 0. To the best of our knowledge, there is no general theory that addresses this problem. In this paper we study two approaches to defining such a measure.\nAverage-Case Distance\nIn the first approach, we consider the average-case be havior of the partial orders. We define the distance between two partial orders -<1 and -<2 to be the aver age of the distances between pairs of complete orders that are consistent with -<1 and -<2, respectively. The distance between two complete orders can be any of the distance measures discussed in the previous sec tion: Euclidean (8E), Spearman's footrule (8s), and probabilistic ( 8 p). Formally:\nwhere X can be any of the letters \"E\", \"S\", and \"P\" that denote Euclidean distancE), Spearman's footrule, and probabilistic distance, respectively. Note that these measures are not metrics on the set of partial or-\nders, since the distance between two identical partial orders that are not complete orders is always positive. But this is desirable if the two orders represent the preferences of two different users, since the complete preference orders for the two may actually differ.\nThe next question is how to compute these distances. A simplistic answer is to compute 8 x ( v1, v2) for all pairs of linear extensions (v1,v2) E Vi X V2, which involves generating all linear extensions of the partial orders. This approach is computationally prohibitive since the number of linear extensions of a poset can be exponential in terms of its cardinality. In fact, the much easier problem of counting linear extensions of posets, a fundamental problem in the theory of ordered sets with applications in computer science (sorting) and social sciences, was shown to be #P-complete 3 by Brightwell and Winkler [1].\nGiven the hardness of counting and generating linear extensions, we turn to approximation techniques to estimate 8x( -<1, -<2). Let Y be the random variable defined as Y = 8x(v1,v2), where v1,v2 are indepen dent uniform random variables on v1 and v2 respec tively. We note that E Y = 8x( -<1> -<2). We thus can appeal to the Monte Carlo simulation method to es timate 8 x (-< 1 , -< 2), provided that we have an efficient algorithm to generate Vi uniformly randomly from \"Vi.\nIt turns out that counting (approximately) and gener ating (uniformly randomly) elements of large combi natorial sets are two closely related problems. In fact, Sinclair [15] showed that an efficient algorithm for one problem can be used to construct an efficient algorithm for the other, provided the combinatorial sets have a certain structural property called self-reducibility. The set of linear extensions of a poset has this property and, not suprisingly, a number of algorithms for gen erating (almost) uniformly randomly linear extensions of posets have been developed [8, 2] in order to ad dress the fundamental problem of counting linear ex tensions. These algorithms are all randomized algo rithms based on the Markov chain Monte Carlo tech nique 4\u2022 In the Appendix we describe the best known algorithm, due to Bubley and Dyer [2] that has a run-\n3The complexity class #P, introduced by Valiant (18], consists of all counting problems whose solutions are the number of accepting states of some non-deterministic polynomial-time Turing Machine. A counting problem is #P-complete if the problem of counting the number of sat isfying assignments to a 3-SAT problem can be reduced to it in polynomial time. #P-complete problems, which are analog counting counterparts of NP-complete prob lems, are considered very difficult, especially in the view of Toda's results (17], which implies that one call to a #P complete oracle suffices to solve any problem in the poly nomial hierarchy in deterministic polynomial time.\n4See [7] for a recent survey of this method.\nning time of O(n3 log nc1 ), where n is the poset's car dinality, and tis the desired accuracy.\nNow with the help of the routine that almost uni formly randomly generates linear extensions of a poset, we can estimate c5x(-<1, -<2) by randomly generat ing Vij E Vi(i = 1, 2; j = I, ... , k), computing c5 x ( v1i, V2j), j = I, ... , k, and taking the sample mean J x = t :2:7=1 c5 x ( V1j, v2j). This sample mean is an unbiased estimator 5 of E Y = cSx(-<1, -<2) with vari ance (Var Y) I k. We can derive a confidence interval for c5x as follows. Lett be the ratio of Y's variance and square of its expectation: t = Var Y I (E Y)2, a non negative quantity that can usually be bounded above by T, which is polynomial in terms of n, the input size. Thus VarY \ufffd r(E Y)2 and Var Jx \ufffd (r(E Y)2)lk = (rc5\"i )lk. For any positive number c, Chebysev's in equality says that:\nPr((Jx-c5x)2 > cVar Jx) \ufffd Ilc,\nand thus:\nPr((Jx- c5x)2 > crc5'3clk) \ufffd Ilc,\nor equivalently:\nPr((I-vfci]k)c5x \ufffd Jx \ufffd (I+ vfci]k)c5x) 2:: I-IIc.\nAs a consequence, if we want our estimator J x to be within a multiplicative factor of I + t of c5 with proba bility of at least I-I I c, it is sufficient to take a sample of size k = f4crlt2l There is also another possible way to define the dis tance measure among partial orders based on their average-case behavior. Note that in the previous section, the Euclidean distance and the Spearmans's footrule are defined among complete orders based on the heights of the outcomes. Accordingly, we can de fine the corresponding, generalized Euclidean distance and generalized Spearman' footrule based on the aver age heights of the outcomes with respect to their con sistent complete orders. In the literature on ordered sets, the average height of an element with respect to a partial order is simply called its height. Denote the height of an element s i, j = I, . . . , n with respect to the partial order -< i, i = I, 2 by hii , we can define the distance between -<1 and -<2 as:\nGeneralized c5s : c58( -<1. -<2) := ! I:j=1 jh1j-h2il Generalized c5 E : c5k (-< 1, -<2) = JI:j=l ( h1j -h2j )2.\n5To be more precise, Jx is not an unbiased estimator for 8x, since the routine only generates almost uniform linear extensions. The incurred bias is insignificant and often simply ignored in Markov chain Monte Carlo analysis.\nCase-Based Preference Elicitation 199\nIn contrast to the previously discussed average-case distance measures, these distance measures are metrics on the set of partial orders over S. Determining the heights of elements of a poset, however, is also a #P complete problem [I] and requires the approximation technique described above.\nExtreme-Case Distance\nIn the second approach, we consider the extreme be haviors of the partial orders -<i\u00b7 Specifically, we de fine the distance \ufffdx( -<1, -<2) to be an interval whose endpoints are the minimum and the maximum of c5x(-<v1,-<v2), where ViE Vi,i = I,2, and X is either \"E\", or \"S\", or \"P\":\nThis approach gives us the flexibility in defining the concept of closeness among partial preference orders. For example, given three partial preference orders -<i , i = I, 2, 3, we can take the conservative approach and say that -<1 is closer to -<2 than to -<3 if the upper bound of \ufffdX ( -<vu -<v2) is less than the lower bound of \ufffdx ( -<vu -<va). We can also take other approaches such as the optimistic approach (minim in: closer when the lower bound is smaller) and pessimistic approach (minimax: closer when the upper bound is smaller). Computing \ufffdx(-<1, -<2) seems to be a difficult combi natorial optimization problem. A reasonable approach is to take the minimum and the maximum of a random sample of sufficiently large size as approximations for the bounds of \ufffdX\u00b7\n4 AN IMPLEMENTATION\nIn this section, we describe MovieFinder 6, an experi mental recommender system that recommends movies for people based on this case-based preference elicita tion approach. Our main goal of this experiment is to see if the probabilistic distance 8p is a reasonble measure of distance on preference structures.\nThe problem of deciding what movie to see is one of certainty, where the outcomes are the movies them selves. Each movie is characterized by 5 attributes: di rector, casting, genre, star rating, and time length. We interviewed IO graduate students to fully elicit their preferences over a set of 50 movies. We then stored these preference structures in our case base in the form of IO value functions. We then chose one student, say Xaviera, out of the IO students and \"simulated\" a rep etition of the elicitation of her preferences. We looked\n6The system is available on the World Wide Web at http:/ /cs.uwm.edu/ nguyenfmovie/moviemain.htm\n200 Ha and Haddawy\nat the partial preference structure of Xaviera at vari ous points during the elicitation process and estimated its probabilistic distance from the 10 preference struc tures in the case base (one of which is hers), using the method described in Section 3.\nAt the beginning, there was no information about Xaviera's preferences, i.e., the partial preference struc ture we had was vacuous. This structure was of an equal distance from the structures in the case base, with large variances. We expected that as the sim ulation progressed, the partial preference structure would become more informative, and the set of closest matches in the case base would become increasingly smaller, eventually to a set of preference structures that were strategically equivalent with Xaviera's pref erence structure. Our experiments with various stu dents confirmed this expectation.\nIn order to quickly narrow down the set of closest matches, it was crucial to ask the elicitation ques tions in the right order. For example, if half of the 50 films are action films and the other half are drama films, and half of the 10 students prefer action films to drama films, then the answer to a single question about preferences over the attribute \"genre\" can give us preferences over 25 x 25 = 625 pairs of movies, which in turn can halve the size of the set of closest matches.\n5 DISCUSSION\nChoosing an appropriate distance measure is only the first step in realizing our envisioned case-based ap proach \u00b7to preference elicitation and several difficult technical problems remain to be solved. The first is how to represent the case base. Since our analyses suggest that computing the distance between two pref erence structures can be computationally complex, it may be desirable to reduce the number of structures with which we must perform comparisons. One possi bility is to perform hierarchical clustering on the case base and to store prototype representations of each cluster. We could then use the hierarchical organi zation to guide the search for a best matching case or could retrieve one of the prototypes. Our distance measure could be used for the clustering but how to create a prototype representation of a set of prefer ences is an open question.\nIn the case of certainty, another possible way to speed up the process of identifying the closest match is to limit the number of outcomes and thus to reduce the complexity of distance computing algorithms. For ex ample, suppose that there are. 100 outcomes, and we take into consideration only the top 10 outcomes with respect to each partial order. In other words, we ignore\ninformation regarding the suboptimal outcomes in de termining the distance among partial preference struc tures. For each pair of partial orders, we then compute their distance based on their restrictions to the union of their corresponding top 10 elements, which is a set of at most 20 elements. This approach computes only an approximate of the actual distance, but can provide significant computational savings.\nIn a recent paper, Chajewska et al. [3] discuss an ap proach to preference elicitation similar to ours. Given a data base of user utility functions, they propose clus tering them and describing each cluster by a prototype. They propose building a decision tree for associating a user with a prototype utility function based on some elicited pairwise preferences. Their approach requires having a data base of complete utility functions. Their retrieval scheme depends on asking the user questions and ruling out utility functions that conflict with the user's answers. Since no prototype is likely to exactly match the user's preferences, this approach has the problem that the utility function retrieved is sensitive to the order in which questions are asked. In contrast, our approach would retrieve the closest matching pref erence structure, independent of the order of questions. Since Chajewska and Getoor are initially focusing on the problem of building a working system and we are initially focusing on the theoretical underpinnings, we see their work as complementary to ours.\nThe closest matching preference structure will in most cases not perfectly match all the preferences expressed by the user. In this case, we would want to modify it to incorporate the unrepresented preferences. For prefer ences that are simply lacking in the stored structure, this is trivial. For preferences that conflict, we would want to reconcile these differences by modifying the retrieved structure in some minimal way. Minimality could be defined relative to our distance measure.\nThe case-based approach we are advocating was in spired by the work on collaborative filtering [13, 9], in which the filtering system predicts how interesting a user will find items he has not seen based on the ratings that other users give to items. Each user in a popu lation rates various alternatives, e.g. newsgroup post ings or movies, according to a numeric scale. The sys tem then correlates the ratings in order to determine which users' ratings are most similar to each other. Finally, it predicts how well users will like new arti cles based on ratings from similar users. The work on collaborative filtering is not cast in the framework of decision theory and no theoretical framework or justi fication are provided for the similarity measures used. The work that we present here can be viewed as an at tempt to provide a formal basis for some of the work in this area.\nAcknowledgements\nThe authors would like to thank Hien Nguyen for the implementation of the MovieFinder system, and Tri Le for many helpful discussions. This work was partially supported by NSF grant IRI-9509165.\nAppendix\nWe describe below an algorithm, due to Bubley and Dyer [2], that almost uniformly randomly generates linear exten sions of a partial order. The algorithm has running time of O(n3log nt:-1 ), where n is the number of the elements of the partial order, and E is the desired accuracy, which means that the generated random linear extension has a probability distribution that is within a total variation dis tance 7 of E from the uniform distribution. The running time required to obtain a certain precision E is often called the mixing time of the Markov chain. A Markov chain with a mixing time polynomial with respect to the input size (which is the number of elements of the partial order in this case) and t:-1 is called rapidly mixing.\nSuppose that the partial order ..( has n elements, and N = {1, 2, ... , n }. We encode the orderings of these elements with the permutations of the elements of N, and the set of linear extensions of ..( by a subset \u00a3\u00a3( ..() of the set of all permutations of the elements of N.\nFor a given concave probability distribution f on {1, 2, . .. , n -1}, define a Markov chain M1 = {St}t;?:o on C\u00a3( ..() as follows. At any time point t ;:::: 0, toss a fair coin. If the coin lands head, then let St+I = St. If the coin lands tail, then choose an index i E {1, 2, ... , n -1} according to the distribution f. If the permutation obtained from St by switching the i-th and (i + 1)-st elements of St is also a linear extension of -<, i.e., an element of\u00a3\u00a3(-<), then let St+1 be this new permutation. Otherwise, let St+1 =St. It is easily seen that M 1 is ergodic with uniform sta tionary distribution. When f is the uniform distribution on {1, 2, ... , n- 1}, M1 is the Karzanov-Kachiyan chain with mixing time O(n5log n + n4logt:-1) [8]. Bub ley and Dyer showed that if f is defined as f(i) = i(n- i)/ K, where K = (n3 -n)/6, then M1 has mixing time of O(n3 log m-1 ).\nReferences\n[1] G. Brightwell and P. Winkler. Counting linear exten sions. Order, 8(3):225-242, 1991.\n[2] R. Bubley and M. Dyer. Faster random generation of linear extensions. In Proceedings of the Ninth An nual ACM-SIAM Symposium on Discrete Algorithms, pages 175-186, San Francisco, CA, Jan 1998.\n[3] U. Chajewska, L. Getoor, J. Norman, andY. Shahar. Utility elicitation as a classification problem. In Pro ceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, July 1998. To appear.\n7The total variation distance between two discrete dis tributions P, Q over a finite sample space S resembles the Spearman's footrule, and is defined as dTv (P, Q) = i l:sES !P(s)- Q(s)!.\nCase-Based Preference Elicitation 201\n[4] P. Diaconis and R.L. Graham. Spearman's footrule as a measure of disarray. Journal of the Royal Statisti cal Society, Series B (Methodological), 39(2):262-268, 1977.\n[5] R.E. Frank, W.F. Massy, andY. Wind. Market Seg mentation. Prentice-Hall, New Jersey, 1972.\n[6] V. Ha and P. Haddawy. Problem-focused incremental elicitation of multi-attribute utility models. In Pro ceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence, pages 215-222, August 1997.\n[7] Mark Jerrum and Alistair Sinclair. The markov chain monte carlo method: an approach to approximate counting and integration. In Dorit Hochbaum, editor, Approximations for NP-hard Problems, pages 482- 520. PWS Publishing, Boston, MA, 1996.\n[8] A. Karzanov and L. Kachiyan. On the conductance of order markov chains. Order, 8(1):7-15, 1991.\n[9] J.A. Konstan, B.N. Miller, D. Maltz, J. L. Herlocker, L.R. Gordon, and J. Reid!. Applying collaborative filtering to usenet news. Communications of the ACM, 40(4):77-87, 1997.\n[10] D.M. Kreps. Notes on the Theory of Choice. Under ground Classics in Economics. Westview Press, Boul der, 1988.\n[11] G. Linden, S. Hanks, and N. Lesh. Interactive assess ment of user preference models: The automated travel assistant. User Modeling, June 1997.\n[12] S. V. Ovchinnikov. Similarity relations, fuzzy parti tions, and fuzzy orderings. Fuzzy Sets and Systems, 40:107-126, 1991.\n[13] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and J. Reid!. Grouplens: An open architecture for col laborative filtering of netnews. In Proceedings of the 1994 Computer Supported Cooperative Work Confer ence, pages 175-186, New York, NY, 1994.\n[14] L.J. Savage. The Foundations of Statistics. John Wi ley & Sons, New York, 1954. (Second revised edition published 1972).\n[15] A. Sinclair. Algorithms for Random Generation and Counting: A Markov Chain Approach. Birkhauser, Boston-Basel-Berlin, 1993.\n[16] C. Spearman. Footrule for measuring correlation. British Journal of Psychology, 2:89-108, June 1906.\n[17] S. Toda. On the computational power of pp and +p. In Proceedings of the 30th IEEE Symposium on Foun dations of Computer Science, pages 514-519, 1989.\n[18] L.G. Valiant. The complexity of computing the per manent. Theoretical Computer Science, 8:41Q-421, 1979.\n[19] J. von Neumann and 0. Morgenstern. Theory of Games and Economic Behavior. P rinceton Univesity Press, 1944.\n[20] L. A. Zadeh. Similarity relations and fuzzy orderings. Information Sciences, pages 177-200, 1971."}], "references": [{"title": "Counting linear exten\u00ad sions", "author": ["G. Brightwell", "P. Winkler"], "venue": "Order, 8(3):225-242", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1991}, {"title": "Faster random generation of linear extensions", "author": ["R. Bubley", "M. Dyer"], "venue": "In Proceedings of the Ninth An\u00ad nual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Utility elicitation as a classification problem", "author": ["U. Chajewska", "L. Getoor", "J. Norman", "andY. Shahar"], "venue": "In Pro\u00ad ceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Spearman's footrule as a measure of disarray", "author": ["P. Diaconis", "R.L. Graham"], "venue": "Journal of the Royal Statisti\u00ad cal Society, Series B (Methodological),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1977}, {"title": "andY", "author": ["R.E. Frank", "W.F. Massy"], "venue": "Wind. Market Seg\u00ad mentation. Prentice-Hall, New Jersey", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1972}, {"title": "Problem-focused incremental elicitation of multi-attribute utility models", "author": ["V. Ha", "P. Haddawy"], "venue": "In Pro\u00ad ceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "The markov chain monte carlo method: an approach to approximate counting and integration", "author": ["Mark Jerrum", "Alistair Sinclair"], "venue": "In Dorit Hochbaum, editor, Approximations for NP-hard Problems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "On the conductance of order markov chains", "author": ["A. Karzanov", "L. Kachiyan"], "venue": "Order, 8(1):7-15", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "and J", "author": ["J.A. Konstan", "B.N. Miller", "D. Maltz", "J.L. Herlocker", "L.R. Gordon"], "venue": "Reid!. Applying collaborative filtering to usenet news. Communications of the ACM, 40(4):77-87", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1997}, {"title": "Notes on the Theory of Choice", "author": ["D.M. Kreps"], "venue": "Under\u00ad ground Classics in Economics. Westview Press, Boul\u00ad der", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1988}, {"title": "Interactive assess\u00ad ment of user preference models: The automated travel assistant", "author": ["G. Linden", "S. Hanks", "N. Lesh"], "venue": "User Modeling,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Similarity relations", "author": ["S.V. Ovchinnikov"], "venue": "fuzzy parti\u00ad tions, and fuzzy orderings. Fuzzy Sets and Systems, 40:107-126", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1991}, {"title": "and J", "author": ["P. Resnick", "N. Iacovou", "M. Suchak", "P. Bergstrom"], "venue": "Reid!. Grouplens: An open architecture for col\u00ad laborative filtering of netnews. In Proceedings of the 1994 Computer Supported Cooperative Work Confer\u00ad ence, pages 175-186, New York, NY", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1994}, {"title": "The Foundations of Statistics", "author": ["L.J. Savage"], "venue": "John Wi\u00ad ley & Sons, New York, 1954. ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1972}, {"title": "Algorithms for Random Generation and Counting: A Markov Chain Approach", "author": ["A. Sinclair"], "venue": "Birkhauser, Boston-Basel-Berlin", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "Footrule for measuring correlation", "author": ["C. Spearman"], "venue": "British Journal of Psychology,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1906}, {"title": "On the computational power of pp and +p", "author": ["S. Toda"], "venue": "Proceedings of the 30th IEEE Symposium on Foun\u00ad dations of Computer Science, pages 514-519", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1989}, {"title": "The complexity of computing the per\u00ad manent", "author": ["L.G. Valiant"], "venue": "Theoretical Computer Science, 8:41Q-421", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1979}, {"title": "Theory of Games and Economic Behavior. P rinceton", "author": ["J. von Neumann", "0. Morgenstern"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1944}, {"title": "Similarity relations and fuzzy orderings", "author": ["L.A. Zadeh"], "venue": "Information Sciences, pages 177-200", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1971}], "referenceMentions": [{"referenceID": 4, "context": "The idea is based on the observation that people tend to form clusters according to their prefer\u00ad ences or tastes, an observation that has been analyzed in a large amount of literature in the area of market segmentation [5].", "startOffset": 220, "endOffset": 223}, {"referenceID": 5, "context": "In contrast with the previously discussed work of [6] and [11], we do not make any restrictive assumptions con\u00ad cerning the form of the underlying utility functions.", "startOffset": 50, "endOffset": 53}, {"referenceID": 10, "context": "In contrast with the previously discussed work of [6] and [11], we do not make any restrictive assumptions con\u00ad cerning the form of the underlying utility functions.", "startOffset": 58, "endOffset": 62}, {"referenceID": 9, "context": "The reader is refered to [10] for more details.", "startOffset": 25, "endOffset": 29}, {"referenceID": 15, "context": "On the set of strict orders, the classical distance mea\u00ad sure is Spearman's footrule [16].", "startOffset": 85, "endOffset": 89}, {"referenceID": 3, "context": "It is well-known that Spearman's footrule is a metric on strict orders and has the range [0, ln2 /4J] (see, for example [4]).", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "Proposition 1 The probabilistic distance on the set of weak orders on n is a metric with range [0, 1].", "startOffset": 95, "endOffset": 101}, {"referenceID": 0, "context": "If we want these distances to be normalized so that their ranges are the interval [0, 1], by dividing by their correponding upper bounds, then the normalized distances are 1, y3l4 = .", "startOffset": 82, "endOffset": 88}, {"referenceID": 18, "context": "The cen\u00ad tral result of utility theory is a representation theorem that identifies a set of conditions guaranteeing the ex\u00ad istence of a function consistent with the preferences of a decision maker [19, 14].", "startOffset": 198, "endOffset": 206}, {"referenceID": 13, "context": "The cen\u00ad tral result of utility theory is a representation theorem that identifies a set of conditions guaranteeing the ex\u00ad istence of a function consistent with the preferences of a decision maker [19, 14].", "startOffset": 198, "endOffset": 206}, {"referenceID": 0, "context": "Proposition 2 The probabilistic distance on the set of weak orders on S is a metric with range [0, 1].", "startOffset": 95, "endOffset": 101}, {"referenceID": 19, "context": "Closely related to the distance concept is the similar\u00ad ity concept in fuzzy-set theory [20, 12].", "startOffset": 88, "endOffset": 96}, {"referenceID": 11, "context": "Closely related to the distance concept is the similar\u00ad ity concept in fuzzy-set theory [20, 12].", "startOffset": 88, "endOffset": 96}, {"referenceID": 0, "context": "where * is a t-norm, that is, a commutative, associa\u00ad tive, non-decreasing operation on [0, 1], with 1 being the neutral element (1 * x = x * 1 = x, 'Vx E [0, 1]) and 0 being the absorbent element (0 * x = x * 0 = 0, Vx E [0, 1]).", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "where * is a t-norm, that is, a commutative, associa\u00ad tive, non-decreasing operation on [0, 1], with 1 being the neutral element (1 * x = x * 1 = x, 'Vx E [0, 1]) and 0 being the absorbent element (0 * x = x * 0 = 0, Vx E [0, 1]).", "startOffset": 155, "endOffset": 161}, {"referenceID": 0, "context": "where * is a t-norm, that is, a commutative, associa\u00ad tive, non-decreasing operation on [0, 1], with 1 being the neutral element (1 * x = x * 1 = x, 'Vx E [0, 1]) and 0 being the absorbent element (0 * x = x * 0 = 0, Vx E [0, 1]).", "startOffset": 222, "endOffset": 228}, {"referenceID": 0, "context": "In fact, the much easier problem of counting linear extensions of posets, a fundamental problem in the theory of ordered sets with applications in computer science (sorting) and social sciences, was shown to be #P-complete 3 by Brightwell and Winkler [1].", "startOffset": 251, "endOffset": 254}, {"referenceID": 14, "context": "In fact, Sinclair [15] showed that an efficient algorithm for one", "startOffset": 18, "endOffset": 22}, {"referenceID": 7, "context": "The set of linear extensions of a poset has this property and, not suprisingly, a number of algorithms for gen\u00ad erating (almost) uniformly randomly linear extensions of posets have been developed [8, 2] in order to ad\u00ad dress the fundamental problem of counting linear ex\u00ad tensions.", "startOffset": 196, "endOffset": 202}, {"referenceID": 1, "context": "The set of linear extensions of a poset has this property and, not suprisingly, a number of algorithms for gen\u00ad erating (almost) uniformly randomly linear extensions of posets have been developed [8, 2] in order to ad\u00ad dress the fundamental problem of counting linear ex\u00ad tensions.", "startOffset": 196, "endOffset": 202}, {"referenceID": 1, "context": "These algorithms are all randomized algo\u00ad rithms based on the Markov chain Monte Carlo tech\u00ad nique 4\u2022 In the Appendix we describe the best known algorithm, due to Bubley and Dyer [2] that has a run-", "startOffset": 179, "endOffset": 182}, {"referenceID": 6, "context": "4See [7] for a recent survey of this method.", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "[3] discuss an ap\u00ad proach to preference elicitation similar to ours.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "The case-based approach we are advocating was in\u00ad spired by the work on collaborative filtering [13, 9], in which the filtering system predicts how interesting a user will find items he has not seen based on the ratings that other users give to items.", "startOffset": 96, "endOffset": 103}, {"referenceID": 8, "context": "The case-based approach we are advocating was in\u00ad spired by the work on collaborative filtering [13, 9], in which the filtering system predicts how interesting a user will find items he has not seen based on the ratings that other users give to items.", "startOffset": 96, "endOffset": 103}, {"referenceID": 1, "context": "We describe below an algorithm, due to Bubley and Dyer [2], that almost uniformly randomly generates linear exten\u00ad sions of a partial order.", "startOffset": 55, "endOffset": 58}, {"referenceID": 7, "context": ", n- 1}, M1 is the Karzanov-Kachiyan chain with mixing time O(n5log n + n4logt:-1) [8].", "startOffset": 83, "endOffset": 86}], "year": 2011, "abstractText": "While decision theory provides an appealing normative framework for representing rich preference structures, eliciting utility or value functions typically incurs a large cost. For many applications involving interactive sys\u00ad tems this overhead precludes the use of for\u00ad mal decision-theoretic models of preference. Instead of performing elicitation in a vacuum, it would be useful if we could augment di\u00ad rectly elicited preferences with some appro\u00ad priate default information. In this paper we propose a case-based approach to alleviat\u00ad ing the preference elicitation bottleneck. As\u00ad suming the existence of a population of users from whom we have elicited complete or in\u00ad complete preference structures, we propose eliciting the preferences of a new user inter\u00ad actively and incrementally, using the closest existing preference structures as potential de\u00ad faults. Since a notion of closeness demands a measure of distance among preference struc\u00ad tures, this paper takes the first step of study\u00ad ing various distance measures over fully and partially specified preference structures. We explore the use of Euclidean distance, Spear\u00ad man's footrule, and define a new measure, the probabilistic distance. We provide computa\u00ad tional techniques for all three measures.", "creator": "pdftk 1.41 - www.pdftk.com"}}}