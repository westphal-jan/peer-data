{"id": "1301.7385", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "The Lumiere Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users", "abstract": "the lumiere project mainly centers on harnessing probability and utility concepts to accurately provide assistance to any computer software users. as we review work there on bayesian user models that can be employed to infer a general users needs by considering a user's background, actions, and input queries. several application problems were tackled constantly in lumiere research, firstly including ( 1 ) the construction of bayesian models for reasoning about the time - varying goals of computer users from their computer observed actions and queries, ( 2 ) gaining access to a stream of events from software applications, ( 3 ) developing a language for transforming system events into observational variables represented in bayesian user models, ( finally 4 ) developing persistent profiles to capture changes in a user expertise, and ( 5 ) the development of an overall analytical architecture for an intelligent agent user interface. lumiere prototypes models served as basically the basis for the office assistant in the microsoft office'97 suite of productivity applications.", "histories": [["v1", "Wed, 30 Jan 2013 15:04:36 GMT  (398kb)", "http://arxiv.org/abs/1301.7385v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI cs.HC", "authors": ["eric j horvitz", "john s breese", "david heckerman", "david hovel", "koos rommelse"], "accepted": false, "id": "1301.7385"}, "pdf": {"name": "1301.7385.pdf", "metadata": {"source": "CRF", "title": "The Lumiere Project: Bayesian User Modeling for Inferring the Goals and Needs of Software Users", "authors": ["Eric Horvitz", "Jack Breese", "David Heckerman", "David Hovel", "Koos Rommelset"], "emails": ["}@microsoft.com"], "sections": [{"heading": null, "text": "1 Introduction\nUncertainty is ubiquitous in attempts to recognize an agent's goals from observations of behavior. The Lumiere project at Microsoft Research has been fo cused on leveraging methods for reasoning under un certainty about the goals of software users. At the heart of Lumiere research and prototypes are Bayesian user models that capture the uncertain relationships among the goals and needs of a user and observations about program state, sequences of actions over time, and words in a user's query. Motivating problems in clude the computation and use of probability distri butions over a user's goals for providing appropriate assistance or automated services, for dynamically tai loring language models in speech recognition, and for appropriately guiding the allocation of computational resources in an operating system.\nt Presently at Applicare Medical Imaging B. V., Box 936, 3700 AX Zeist, Netherlands.\nWe present challenges with the construction of key components of the Lumiere/Excel prototype for the Excel spreadsheet application. The Lumiere project was initiated in 1993, and the initial Lumiere/Excel prototype was first demonstrated to the Microsoft Of fice division in January 1994. Research on new appli cations and extensions continued in parallel with ef forts to integrate portions of the prototype into com mercially available software applications. In January 1997, a derivative of Lumiere research shipped as the Office Assistant in Microsoft Office '97 applications.\nWe will describe key issues with user modeling and provide an overview of Bayesian reasoning and deci sion making about user needs. Then, we will discuss user modeling for identifying the needs of users work ing with desktop productivity software. We will re view the components and overall architecture of the Lumiere system. Finally, we will discuss the influence of Lumiere research on software products.\n2 Bayesian User Models\nWe shall focus on the use of Bayesian networks and influence diagrams in embedded applications to make inferences about the goals of users-and to take ideal actions based on probability distributions over these goals. We found that Bayesian models can be effective in diagnosing a user's needs and can provide useful en hancements to legacy software applications when em bedded within these programs. Additionally, Bayesian user models can provide an infrastructure for building new kinds of services and applications in software.\nTo date, graphical probabilistic models have been em ployed largely for such diagnostic tasks as computing the likelihood of alternate diseases in patients or dis orders in machines (Horvitz, Breese & Henrion, 1988; Heckerman, Horvitz & Nathwani, 1992; Heckerman, Breese & Rommelse, 1995). However, there has been growing interest in the application of Bayesian and decision-theoretic methods to the task of modeling the beliefs, intentions, goals, and needs of users (Jameson, 1996; Horvitz, 1997). Such user modeling problems typically are dominated by uncertainty.\nRepresentations of probability and utility have been\nexplored previously in a variety of user-modeling ap plications. Models of user expertise and abilities have been used in the context of custom-tailoring the behav ior of Bayesian decision-support systems to users. For example, multiattribute utility models were employed in early versions of the Pathfinder pathology diagnostic system for pathology to custom-tailor question asking and explanation to users with differing levels of exper tise (Horvitz, Heckerman, Nathwani & Fagan, 1984). Bayesian networks were employed as user models in the Vista system to model the interpretation of pat terns of evidence by flight engineers at the NASA Mis sion Control Center. In that application, concurrent inference with the user and expert models is used to se lect the most valuable information to display (Horvitz & Barry, 1995). In the realm of modeling the goals of users, temporal probabilistic models of a pilot's goals were explored by Cooper, et al., guided by the chal lenge of custom-tailoring information displayed to pi lots of commercial aircraft (Cooper, Horvitz, Hecker man & Curry, 1988). Probabilistic models have been explored as a representation for recognizing common sense plans (Charniak & Goldman, 1993), for mak ing inferences about the goals of car drivers in nav igating in traffic (Pynadath & Wellman, 1995), and for predicting actions in a multiuser computer game (Albrecht, Zukerman, Nicholson & Bud, 1997). In terest has also been growing steadily on applications of Bayesian user modeling in educational systems. In particular, there have been efforts to model compe tency and to diagnose problems with understanding computer-based tutoring (Conati, Gertner, VanLehn & Druzdzel, 1997). The high-level goals of the Lumiere project are cap tured by the influence diagram displayed in Figure 1 which represents key aspects of user modeling and au tomated assistance in computing applications. The de cision model considers a user's goals and needs. Goals are target tasks or subtasks at the focus of a user's at tention. Needs are information or automated actions that will reduce the time or effort required to achieve goals. In some situations, we can exploit a predeter mined mapping between goals and needs. However, we typically must consider uncertainties and dependencies among these and related variables. As indicated by the variables and dependencies in the influence diagram, a user's acute needs are influenced by the acute goals as well as the user's competency with using software. Prior assistance in the form of online help and the user's background representing experience with com puting applications influence the user's competence. A user's needs directly influence or cause patterns of activity that might be sensed by watching a user's ac tivity. Such activity includes sequences of user actions recorded as the user interacts with a mouse and key board as well as visual and acoustic clues that might be sensed by a video camera and microphone. A user's goals also influence the set of active documents and the presence, instantiation, and display of data structures (e.g., Does a user-authored chart exist in a spread sheet project? Is the chart currently visible? Does it currently have system focus?).\nBayesian User Modeling 257\nFigure 1: An influence diagram for providing intel ligent assistance given uncertainty in a user's back ground, goals, and competency in working with a soft ware application.\nAt times, a user may explicitly request assistance. A user's acute needs influence the terms appearing in a user's explicit typed or vocalized queries. As indi cated in the influence diagram, the overall goal is to take automated actions to optimize the user's expected utility. A system taking autonomous action to assist users needs to balance the benefits and costs such ac tions. The value of actions depend on the nature of the action, the cost of the action, and the user's needs. As sessing and integrating such user models would allow a system to compute a probability distribution over a user's informational needs in real time, given a set of observations about activity and explicit queries, when such queries are issued.\n3 Framing, Constructing, and Assessing Bayesian User Models\nMoving from a high-level specification of the prob lem of Bayesian user modeling to specific domains and prototypes requires a detailed consideration of dis tinctions and relationships for particular software pro grams and settings. To better understand the needs and behaviors of users as they encounter problems with the use of a software application, we worked with psy chologists at Microsoft's usability laboratory to per form studies with human subjects.\nOne of the goals of the studies was to gauge the ability of experts to perform the task of guessing users' goals and to provide assistance by simply watching the user's actions through the \"keyhole\" of the interface. Diffi culties noted by experts in the study would be taken as an indication of the difficulty of automating the task of assisting users. We were also interested in identifying evidential distinctions that experts might be using to infer ( 1) the likelihood that a user needed assistance, and (2) the type of help that was needed given that assistance was desired.\nThe studies were based on a \"Wizard of Oz\" design. In the studies, naive subjects with different levels of\n258 Horvitz, Breese, Heckerman, Hovel, and Rommelse\ncompetence in using the Microsoft Excel spreadsheet application were given a set of spreadsheet tasks. Sub jects were informed that an experimental help system would be tracking their activity and would be occa sionally making guesses about the best way to help them. Assistance would appear on an adjacent com puter monitor. Experts were positioned in a separate room that was isolated acoustically from the users. The experts were given a monitor to view the subjects' screen, including their mouse and typing activity, and could type advice to users. Experts were not informed about the nature of the set of spreadsheet tasks given to the user. Both subjects and experts were told to verbalize their thoughts and the experts, subjects, and the subjects' display were videotaped.\nThe studies led to several insights. We found that ex perts had the ability to identify user goals and needs through observation. However, recognizing the goals of users was a challenging task. Experts were typically uncertain about a user's goals and about the value of providing different kinds of assistance. At times, goals would be recognized with an \"Aha!\" reaction after a period of confusion. We learned that poor advice could be quite costly to users. Even though subjects were primed with a description of the help system as being \"experimental,\" advice appearing on their dis plays was typically examined carefully and often taken seriously; even when expert advice was off the mark, subjects would often become distracted by the advice and begin to experiment with features described by the wizard. This would give experts false confirmation of successful goal recognition, and would bolster their continuing to give advice pushing the user down a dis tracting path. Such patterns of poor guesses and \"con firmatory\" feedback could lead to a focusing on the wrong problem and a loss in efficiency. Experts would become better over time with this and other problems, learning, for example, to becoming conservative with offering advice, using conditional statements (i.e., \"if you are trying to do x, then ... \"), and decomposing ad vice into a set of small, easily understandable steps.\n3.1 Identification of Distinctions with Relevance to User Needs\nThe studies with human subjects helped us to iden tify several important classes of evidential distinctions. These observational clues appeared to be valuable for making inferences about a user's problems and for making an assessment of the user's need for assistance. The classes of evidence include:\n\u2022 Search: Repetitive, scanning patterns associated with attempts to search for or access an item or functionality. Such distinctions include ob servation of the user exploring multiple menus, scrolling through text, and mousing over and clicking on multiple non-active regions.\n\u2022 Focus of attention: Selection and/or dwelling on graphical objects, dwelling on portions of a docu ment or on specific subtext after scrolling through the document.\n\u2022 Introspection: A sudden pause after a period of activity or a significant slowing of the rate of in teraction.\n\u2022 Undesired effects: Attempts to return to a prior state after an action. These observations include undoing the effect of recent action, including is suing an undo command, closing a dialog box shortly after it is opened without invocating an operation offered in the context of the dialog.\n\u2022 Inefficient command sequences: User performing operations that could be done more simply or ef ficiently via an alternate sequence of actions or through easily accessible shortcuts.\n\u2022 Domain-specific syntactic and semantic content: Consideration of special distinctions in content or structure of documents and how user inter acts with these features. These include domain specific features associated with the task.\nThese classes, when subclassed with specific types of data structures and displayed objects, provide a rich set of observations with probabilistic links to a user's goals. In our initial systems, we avoided detailed modeling of deeper commonsense knowledge associ ated with the syntactic and semantic content of doc uments and application functionality, and focused ini tially on the other classes of distinctions.\n3.2 Structuring Bayesian User Models\nGiven the results of the user studies, we set out to build and assess Bayesian models with the ability to diagnose a user's needs. We were interested in the quality of inference we might achieve through consid ering a user's background, ongoing and long-term user actions, data structures, as well as words in a user's query when such a query was issued.\nBuilding effective user models hinges on defining ap propriate variables and states of variables. The as sessed (or learned) conditional probabilities and the monitoring of users hinge on crisp and appropriate def initions of states of variables. For example, with the use of discrete Bayesian networks, we need to clearly define the specific quantity of time we define to be a \"pause after activity.\"\nFigure 2 displays a small Bayesian network that rep resents the dependency between a pause after activity and the likelihood that a user would welcome assis tance. According to the model, a user being in the state of welcoming assistance would shift the proba bility distribution of observing pauses in activity. The state of desiring assistance also influences the prob ability of detecting a recent search through multiple menus. We consider also the influence of a user's ex pertise and the difficulty of a task on the likelihood that a user will need assistance. We also note that a user will pause if he or she is distracted by events unrelated to the user's task. As indicated in Figure 2, we may wish to assert in the Bayesian user model\nFigure 2: A portion of a Bayesian user model for infer ring the likelihood that a user needs assistance, con sidering profile information as well as observations of recent activity.\nthat the difficulty of a task also directly influences the likelihood that a user will become distracted by other events.\nWe worked with experts to construct, assess, and test Bayesian models for several applications, tasks, and subtasks. Some of our models were built to be \"appli cation covering\" while others were designed to operate as simpler, context-sensitive agents that would be in voked when specific patterns of activity were observed. As an example, we built and assessed a Bayesian model focused on assisting users with the Start button in Windows 95 shell to be invoked when a user was engag ing the start button and spending more than a small amount of time navigating within this menu or revis iting the start button multiple times within a prede fined horizon. Figure 3 displays a portion of an early application-covering Bayesian network that we con structed for diagnosing a user's goals with the Excel spreadsheet application.\n4 Temporal Reasoning about User Actions\nBayesian user modeling from a sequence actions over time poses a challenging temporal reasoning prob lem. Explicit temporal reasoning adds significant com plexity to probabilistic representations and inference (Cooper, Horvitz & Heckerman, 1989). Investigation of temporal reasoning with dynamic Bayesian net work models has focused on problems and approxi mations for models that consider dependencies among variables within as well as between time slices (Dean & Kanazawa, 1989; Dagum, Galper & Horvitz, 1992; Nicholson & Brady, 1994). In the general case, we consider temporal dependen cies between a user's goals at different times and the user's behavior. Figure 4 captures a Markov represen tation of the temporal Bayesian user-modeling prob lem, where we consider dependencies among variables at adjacent time periods. As displayed in the tem poral Bayesian network, we include temporal depen dencies between goals at the present moment ( Goalto) and at earlier time periods ( Goalt;), as well as among observations E; made at different time periods. Some\nBayesian User Modeling 259\nFigure 3: Partial structure of an early formulation of a Bayesian user model for inferring a user's needs for the Excel spreadsheet application.\nvariables, such as the node labeled Profile in Figure 4, capturing the expertise of a user, may change slowly or simply persist over time (as indicated by the arc represented by a broken line).\nWe studied several approaches to temporal reasoning for user assistance, including dynamic network models and single-stage formulations of the temporal reason ing problem. In the single-stage temporal analyses, we define the target diagnostic problem as inferring the likelihood of alternative goals at the present mo ment and embed considerations of time within the def initions of observational variables or introduce time dependent conditional probabilities.\nIn our earliest Bayesian networks for Lumiere/Excel, including the model displayed in Figure 3, we repre sented and assessed temporal relationships as part of definitions of observations, such as the event, \"user performed action x less than y seconds ago.\" We also experimented with approximations based on direct as sessment of parameters of functions that specify the probabilities of observations conditioned on goals as a function of the amount of time that has transpired be tween the observation and the present moment. The intuition behind the approach is that observations seen at increasingly earlier times in the past have decreas ing relevance to the current goals of the user.\nThe time-dependent probability approach can be viewed as a temporal model-construction methodol ogy. As highlighted in Figure 5 we formulate the prob lem as a set of single stage inference problems about a user's present goals, and define observations in terms of the amount of time t that has transpired between the present moment and the most recent occurrence of an action, Ei,t\u00b7 We assess the conditional prob abilities of time-indexed actions, p(Ei,tiGoaltJ\u00b7 We found through assessment that a typical temporal dy namic for the conditional probability of observing ac tions given goals is where the probability decays to the value for the case where the evidence is not observed. That is, the conditional probabilities of observations\n260 Horvitz, Breese, Heckerman, Hovel, and Rommelse\nFigure 4: Markov model for temporal reasoning as suming dependencies among the goals of a user in ad jacent time periods. A persistent Profile variable in fluences goals and observations in all periods.\ngiven goals range from the update associated with an action occurring immediately, p(E;,tJGoaltJ, to the probability assigned for the case where the observa tion was not seen within the horizon of the analysis, p(E; = falsejGoaltJ\u00b7 We make the assumption that the rates of decay of likelihoods are independent of one another, conditioned on goals. If an observational vari able is influenced by multiple variables, we must assess the decays as a function of all of the states of its par ents. For cases where the influence of parent nodes are identified to be causally independent (noisy-or), con ditional probabilities can be constructed dynamically from the time-dependent probabilities assessed sepa rately for each parent.\nIn practice, we found it useful to assess the decay of conditional probabilities of actions given current goals with parametric functions. For specially tagged ob servational variables in the Lumiere/Excel model, ex perts assessed evidential horizon and decay parame ters. The evidential horizon is the number of actions or the amount of time that probabilistic relationships persist without change. The decay variables specify the functional class (linear, exponential, etc.) and the parameter defining the details of how the conditional probabilities change after a horizon is reached, as a function of either the amount of time that has passed or the number of actions that have occurred since the observation was noted to become true. For the expo nential case, we found it useful to assess a \"likelihood half-life\" as a function of the number of user actions that had transpired since the event was noted.\n5 Bridging the Gulf Between System Events and User Actions\nTo embed Bayesian user models into software appli cations, it is critical to gain access to a stream of user actions. Unfortunately, systems and applications have not been written with an eye to user modeling. Thus, a critical problem in developing probabilistic and decision-theoretic enhancements for user interface applications is establishing a link between user actions and system events. We found it challenging to gain ac cess to appropriate streams of user and system events. Establishing a rapport with the Excel development team was crucial for designing special instrumented\nlag of event from present moment\nFigure 5: Formulation of the temporal reasoning prob lem as a set of single-stage problems. We directly as sess conditional probabilities of actions as a function of the time that has passed since actions occurred.\nversions of Excel with a usable set of events. Even so, we were limited in the nature of events we could perceive and had to adapt the definition of evidential variables to mesh with available evidence.\nA special version of Excel was created that yielded information about subsets of mouse and keyboard ac tions, as well as information about the status of data structures in Excel files. The events included access to menus being visited and dialog boxes being opened and closed. In addition, we could gain information on the selection of specific objects, including drawing objects, charts, cells, rows, and columns.\nWe built an events system to establish a fluid link be tween low-level, atomic events and the higher-level se mantics of user action we employed in user models. The Lumiere events architecture continues to moni tor the stream of time-stamped atomic events and to convert these events into higher-level predicates, or modeled events representing user actions. We found that transforming system events into such modeled events as \"menu surfing,\" \"mouse meandering,\" and \"menu jitter\" to be a challenging endeavor. Defining these and other events required detailed analysis of the atomic event streams and iterative composition of temporal functions that could map the atomic event sequences into higher-level observations.\nTo make the definition of modeled events from atomic events more efficient and flexible, we developed the Lumiere Events Language. This temporal pattern recognition language allows atomic events to be used as modeled events directly, as well as for streams of atomic events to be formed into Boolean and set theoretic combinations of the low-level events. The language also allows system designers to compose new modeled events from previously defined modeled events and atomic events. The events language allowed us to build and modify transformation functions that would be compiled into run-time filters for modeled events. As an example, the following primitives are provided in the event language:\n\u2022 Rate( x;, t): The number of times an atomic event x; occurs in t seconds or commands.\n\u2022 Oneof( {x1, . . . , Xn},t): At least one event of a de noted set of events occurs in t.\nWe can use these and other operators in the Lumiere Events Language to define filters for higher-level events, such as user dwelled for at least t seconds fol lowing a scroll. We found it useful to include in the language an efficient means for abstracting sets of low level events into event classes specified as disjunctions of events (e.g., we specify that a user saving a file via a toolbar icon or keyboard action is to be generalized to file saved.) To adapt events defined in terms of durations to different rates of working, we added the ability to expand or contract time to a user-specific scaled time, based on detecting the average rate at which commands were executed by users.\n6 The Lumiere/Excel System\nThe Lumiere/Excel prototype for the Excel spread sheet application was constructed to demonstrate the potential of Bayesian user modeling to the Microsoft Office division. We constructed a Bayesian user model that reasoned about approximately 40 problems span ning a large portion of the Excel application. The Lumiere Events Language was used to specify obser vations as a function of the events emitted by the Excel application. The system was wedded with a Bayesian term-spotting methodology for reasoning about free text queries (Heckerman & Horvitz, 1998). The Bayesian information retrieval system recognizes ap proximately 600 terms and considers the probabilistic\nBayesian User Modeling 261\nrelevance of these terms to the areas of assistance con \ufffdidered by Lumiere/Excel. When queries are available, mference about a user goals, conditioned on a user's actions and the status of data structures, are com bined with inference about a user's goals from words. Temporal reasoning was performed with the dynamic temporal modeling approach described in Section 4.\n6.1 Overall Lumiere/Excel Architecture\nThe overall Lumiere/Excel architecture is displayed in Figure 9. Events from the interface are transformed into time-stamped observations. The observations are input to a Bayesian model and a probability distribu tion over user needs is inferred. If a query is made available, the posterior probabilities from the events system and the Bayesian term-spotting approach are combined through a weighted multiplication to yield a final posterior distribution over needs. Beyond reason ing about the probability distribution over user prob lems, the system also infers the likelihood that a user needs assistance at the present moment. This proba bility is used to control the autonomous display of as sistance when the system is running behind the scenes. A user-specified probability threshold is used to con trol the autonomous assistance.\n6.2 Lumiere/Excel Control Policies\nWe experimented with several overall control schemes for the system. In a pulsed strategy the system clock makes a call at a regular interval to a cycle of event analysis, inference, and interface action (depending on the inferred results and the user-specified thresh old). In an event-driven control policy, specific sets of atomic and or modeled events are labeled as trig ger events. When such events occur, a broader events analysis and an inference cycle is triggered. We also experimented with an augmented pulsed approach, where the system calls an analysis cycle at specific time intervals, but also when specific events are noted. In a deferred analysis, we attempt to do an analysis at prespecified time intervals but only when idle time is detected. Other opportunities for control include the use of a relatively simple probabilistic or decision theoretic analysis to make decisions about invoking a larger, less tractable analysis.\n6.3 Capturing and Harnessing a User Profile\nWe explored several approaches to custom-tailoring the performance of Lumiere/Excel to users with differ ent expertise. In a basic approach to custom-tailoring assistance, we assessed from experts probability dis tributions over a user's needs for different classes of user expertise, and allowed users to specify their back ground when using the system.\nWe also developed the means for updating these prob abilities dynamically based on observation of sets of competency indicator tasks being completed suc cessfully or specific help topics being accessed and dwelled upon. Beyond analyzing real-time events,\n262 Horvitz, Breese, Heckerman, Hovel, and Rommelse\nFigure 7: Inference behind the scenes. Components pictured include (from left to right), a display of the atomic event stream, probability distribution over needs, probability that a user would appreciate help at the current moment, and the user interface for the prototype.\nLumiere/Excel maintains a persistent competency pro file in the operating system's registry. The system was given the ability to capture at store at run time sets of key tasks completed and help topics reviewed. This profile can be used to update the probability distribu tion over needs. In a more general approach, a version of Lumiere was created that enables experts to au thor special competency variables in the Bayesian user model. These variables have values that reflect the na ture and number of times the user demonstrates suc cessful manipulation of different functionalities. These variables can be integrated into the model as any other variable but their states are stored in the persistent user profile.\n6.4 Lumiere/Excel in Operation\nIn operation, the Lumiere/Excel system continues to monitor events and to update a probability distribu tion over a user's needs. Given a stream of user events, the system infers needs as well as the overall probabil ity that the user would like assistance immediately. Figure 7 displays a snapshot of Lumiere's instrumen tation. The small window in the background of the figure displays the stream of atomic events and ob servations derived from the events. The bar graph in front of the event monitor displays the inferred prob ability distribution over the needs of the user, given the stream of evidence. Overlayed at the top of the inferred needs, is a bar graph representing the likeli hood that the user would like to be notified with some\nassistance immediately. A user interface for displaying results and interacting with Lumiere/Excel appears in the foreground. The left text box of the interface dis plays recommended assistance sorted by likelihood. A input field allows users to input free-text queries to the system. A menu below the query field allows users to specify their level of competency.\nFigure 8 displays the Lumiere prototype's user inter face, which displays a sorted list of user goals ranked by their probabilities. The figure also highlights the integration of a Bayesian analysis of words in a user's query. Figure 8(a) displays a probability distribution over needs before a query is processed. This proba bility distribution is computed solely from the user's actions. Figure 8(b) displays an updated probability distribution over needs. This distribution was created by combining the Bayesian action analysis with the output of a Bayesian analysis of terms in the user's free-text query.\nIf the main assistance interface is not displayed by the user, the system will continue to infer the likelihood a user would like to be offered assistance. When the probability that a user needs assistance exceeds a user specified threshold, a small window containing the in ferred assistance is displayed.\nFigure 9 highlights Lumiere's autonomous assistance mode. In the example, help was offered autonomously after a user searched through multiple menus, se lected the entire spreadsheet, and paused. The as sistance window contains a \"volume control\" which\nallows users to modify the probability threshold that determines when the system will provide assistance. If the user does not hover over or interact with the autonomous assistance, the window will timeout and disappear after a brief apology for the potential dis traction. Recommendations for assistance are noted and the autonomous help will not be offered again un til there is a change in the most likely topics. Beyond a user controlled probability threshold, we have ex perimented with the use of a cost-benefit analysis to control the thresholds at which autonomous assistance is provided, based on the preferences of the user for be ing alerted.\n6.5 Beyond Real-Time Assistance\nInformation about the usage of software can be learned in a variety of settings. The context for most of Lu miere research has been in the domain of real-time assistance. However, there is opportunity for using Bayesian user models to design and tailor assistance for offline review. Beyond providing assistance in real time, Lumiere was endowed with the ability to track in real-time patterns of weakness in skills for using a software application. During a session, the sys tem continues to monitor the likelihoods of user prob lems. Lumiere/Excel tracks the frequency that dif ferent problems are encountered during a session and makes recommendations at the end of a session about information the user may wish to review offline. We considered several approaches to identifying the con tent for a custom-tailored offline tutorial. The method employed in the Lumiere/Excel prototype considers, for each area of assistance that is not reviewed during a session, the number of times that the probabilities of user needs for that area exceed a predefined probabil-\nity threshold. Figure 10 demonstrates the automated generation of recommendations for further reading by Lumiere's help backgrounder.\n7 Components of Lumiere in the Real World: Office Assistant\nOur research team has worked closely with the Mi crosoft Office division at implementing methods de veloped in Lumiere research. The first phase of port ing Lumiere to the real world occurred with the com pletion of the Office '97 product suite, containing the Office Assistant. Figure 11 displays the interface for the Office Assistant. As demonstrated in Figure 11, the Office team committed to a character-based front end to relay the results of Bayesian inference. Com pared with Lumiere/Excel, the Office Assistant em ploys broader but shallower models reasoning up to thousands of user goals in each Office application. The system uses a rich set of context variables that capture information about the current view and document. However, the system does not employ persistent user profile information and does not reason about com petency. Also, the system does not use rich combi nations of events over time. Rather, the system only considers a small set of relatively atomic user actions. Furthermore the system employs a small event queue and considers only the most recent events. The sys tem also separates the analysis of words and of events. When words are available, the system does not exploit information about context and recent actions. Finally, the automated facility of providing assistance based on the likelihood that a user may need assistance or on the expected utility of such autonomous action was not employed. Rather, the results of inference are available\n264 Horvitz, Breese, Heckerman, Hovel, and Rommelse\nMore... . . ... BolherMe .....\nFigure 9: Autonomous display of assistance in Lumiere/Excel. Shortly after a user searched through several menus, selected the entire spreadsheet, and paused, the system reaches a probability threshold and posts inferred assistance.\n\ufffd YoumayfrtdtheloloM'IghelptopicsusefutfOJ \ufffd. _ pe\ufffdumg\\lllhenyou have some tine.\nI:Format cells and their contents \ufffd-Insert new rows ond columns -Delete rows and columns ;;;;;; ChttnQina size of rows and columns :_\nFigure 10: Inference about long-term needs. Lumiere/Excel observes patterns of needs in the back ground and recommends topics for offline perusal at the end of a session.\nonly when the user requests assistance explicitly. We are continuing to work closely with the Office division and other product groups on the technology transfer of more sophisticated implementations of Bayesian and decision-theoretic user modeling.\n8 Ongoing Research on Bayesian User Modeling\nThe Lumiere/Excel prototype was useful for demon strating and communicating key ideas on Bayesian user modeling. However, the prototype includes a sub set of functionalities that we have been exploring as part of our research on user modeling. Key areas of on going work on user modeling include harnessing meth ?ds for \ufffdearning Bayesian models from user log data, mtegratmg new sources of events, and employing auto mated dialog for engaging users in conversations about goals and needs.\nNew sources of events can enhance the abilities of a user modeling system to recognize goals and provide appropriate assistance. We have been pursuing oppor tunities for integrating vision and gaze-tracking into\nFig\ufffdre 11: The Office Assistant. The fielded Office Asszstant m the Office '97 suite of applications is based on Lumiere research.\nuser modeling systems. Even coarse gaze information supplement mouse and keyboard actions with ongoing streams of activity about the attention of a user to regions of a display.\nWe have also been exploring the use of value-of information computations to engage the user in dialog and to access costly information about user activity and program state. In the early days of Lumiere re search, we experimented with the use of approxima tions of value of information to consider the costs and benefits of evaluating previously unobserved variables. At any time in a session, value-of-information iden tifies previously unobserved variables that would be most valuable to evaluate. In particular rather than rely_ing on inference to generate a prob\ufffdbility distri but_wn over user goals, we can simply ask users about then goals and needs. Our work on Lumiere/Excel focused on delivering applications that would simply wa_t\ufffdh and \"listen\" for queries rather than making in qmnes. However, such dialog can be appropriate and useful.\n9 Summary and Conclusions\nWe described the Lumiere project with a focus on the Lumiere/Excel prototype. We discussed our studies with human subjects to elucidate sets of distinctions that are useful for making inferences about a user's goals and needs and our construction of Bayesian user models. We touched on issues, approximations, and assessment methods for the problem of making infer ences from a stream of user actions over time. We pr\ufffdsented a ba\ufffdic events-definition language and de scnbed an architecture for detecting and making use ?f events. We al_so presented our work to integrate ev Ide\ufffdce from actwns and words in a user's query. We reviewe\ufffd work on autonomous decision making about user assistance controlled by a user-specified probabil ity threshold. Finally, we discussed real-time inference to support the custom-tailoring of tutorial materials for review in offline settings.\nLumiere/Excel and its descendant, the Office Assis tant, represent initial steps in making software applica tions more intuitive about the goals and needs of users. The dominance of uncertainty in understanding and supporting the goals of people highlights the rich op portunities ahead for harnessing probability and utility at the computer-human interface.\nAcknowledgments\nWe are indebted to Sam Hobson for his enthusiastic support of Bayesian user modeling in Office applica tions, and to Kristin Dukay and Eric Hawley for lead ing teams of usability experts down unexplored terri tory (against Kristin's better senses). Leah Kaufman managed the Wizard of Oz studies and later studies with users of the Office Assistant. We also acknowl edge the indefatigable efforts of Adrian Klein and Eric Finkelstein who joined Sam in transforming compo nents of Lumiere into the Office Assistant and spurring the creation of an intelligent-assistance culture in the Office product group. Chris Meek reviewed an earlier draft of this paper.\nReferences\nAlbrecht, D., Zukerman, 1., Nicholson, A., and Bud, A. ( 1997). Towards a Bayesian model for keyhole plan recognition in large domains. In Proceedings of the Sixth International Conference on User Modeling, Sardinia, Italy, pages 365-376. User Modeling, Inc., Springer-Verlag.\nCharniak, E. and Goldman, R. (1993). A Bayesian model of plan recognition. Artificial Intelligence, 64(1):53-79.\nConati, C., Gertner, A., VanLehn, K., and Druzdzel, M. (1997). Online student modeling for coached problem solving using Bayesian networks. In Proceedings of the Sixth International Confer ence on User Modeling, Sardinia, Italy, pages 231-242. User Modeling, Springer-Verlag.\nCooper, G. and E. Horvitz, D. Heckerman, R. C. (1988). Conceptual design of goal understand ing systems: Investigation of temporal reason ing under uncertainty. Technical Report Techni cal Memorandum NAS2-12381, Search Technol ogy and NASA-Ames Research Center, Moun tain View, QA.\nCooper, G., Horvitz, E., and Heckerman, D. (1989). A method for temporal probabilistic reasoning. Technical Report KSL-88-30, Knowledge Sys tems Laboratory, Stanford University, Stanford, CA.\nDagum, P., Galper, A., and Horvitz, E. (1992). Dy namic network models for forecasting. In Pro ceedings of the Eighth Workshop on Uncertainty in Artificial Intelligence, pages 41-48, Stanford, CA. Association for Uncertainty in Artificial In telligence.\nBayesian User Modeling 265\nDean, T. and Kanazawa, K. (1989) . A model for rea soning about persistence and causation. Compu tational Intelligence, 5(3):142-150.\nHeckerman, D., Breese, J., and Rommelse, K. (1995). Decision-theoretic troubleshooting. CACM, 38:3:49-57 0\nHeckerman, D. and Horvitz, E. (1998). Inferring infor mational goals from free-text queries: A bayesian approach. In Proceedings of the Fourteenth Con ference on Uncertainty in Artificial Intelligence. AUAI, Morgan Kaufmann.\nHeckerman, D., Horvitz, E., and Nathwani, B. (1992). Toward normative expert systems: Part I. The Pathfinder project. Methods of information in medicine, 31:90-105.\nHorvitz, E. (1997). Agents with beliefs: Reflections on Bayesian methods for user modeling. In Pro ceedings of the Sixth International Conference on UserModeling, Sardinia, Italy, pages 441-442. User Modeling, Springer-Verlag.\nHorvitz, E. and Barry, M. (1995). Display of in formation for time-critical decision making. In Proceedings of the Eleventh Conference on Un certainty in Artificial Intelligence, pages 296- 305, Montreal, Canada. Morgan Kaufmann, San Francisco, CA.\nHorvitz, E., Breese, J., and Henrion, M. ( 1988). Deci sion theory in expert systems and artificial intel ligence. International Journal of Approximate Reasoning, Special Issue on Uncertain Reason ing, 2:247-302.\nHorvitz, E., Heckerman, D., Nathwani, B., and Fa gan, L. (1984). Diagnostic strategies in the hypothesis-directed Pathfinder system. In Pro ceedings of the First Conference on Artificial In telligence Applications, Denver, C O, pages 630- 636. IEEE.\nJameson, A. (1996). Numerical uncertainty manage ment in user and student modeling: An overview of systems and issues. User Modeling and User Adapted Interaction, 5: 193-251.\nNicholson, A. and Brady, J. (1994). Dynamic be lief networks for discrete monitoring. IEEE Transactions on Systems, Man, and Cybernet ics, 24(11): 1593-1610.\nPynadath, D. and Wellman, M. (1995). Accounting for contenxt in plan recognition with application to traffic monitoring. In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelli gence, pages 472-481, Montreal, Canada. Mor gan Kaufmann, San Francisco, CA."}], "references": [{"title": "Towards a Bayesian model for keyhole plan recognition in large domains", "author": ["D. Albrecht", "Zukerman", "A. Nicholson", "A. Bud"], "venue": "In Proceedings of the Sixth International Conference on User\u00ad", "citeRegEx": "Albrecht et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Albrecht et al\\.", "year": 1997}, {"title": "A Bayesian model of plan recognition", "author": ["E. Charniak", "R. Goldman"], "venue": "Artificial Intelligence, 64(1):53-79.", "citeRegEx": "Charniak and Goldman,? 1993", "shortCiteRegEx": "Charniak and Goldman", "year": 1993}, {"title": "Online student modeling for coached problem solving using Bayesian networks", "author": ["C. Conati", "A. Gertner", "K. VanLehn", "M. Druzdzel"], "venue": "Proceedings of the Sixth International Confer\u00ad ence on User Modeling, Sardinia, Italy, pages", "citeRegEx": "Conati et al\\.,? 1997", "shortCiteRegEx": "Conati et al\\.", "year": 1997}, {"title": "Conceptual design of goal understand\u00ad ing systems: Investigation of temporal reason\u00ad ing under uncertainty", "author": ["G. Cooper", "E. Horvitz", "R.C.D. Heckerman"], "venue": "Technical Report Techni\u00ad cal Memorandum NAS2-12381, Search Technol\u00ad", "citeRegEx": "Cooper et al\\.,? 1988", "shortCiteRegEx": "Cooper et al\\.", "year": 1988}, {"title": "A method for temporal probabilistic reasoning", "author": ["G. Cooper", "E. Horvitz", "D. Heckerman"], "venue": "Technical Report KSL-88-30, Knowledge Sys\u00ad tems Laboratory, Stanford University, Stanford, CA.", "citeRegEx": "Cooper et al\\.,? 1989", "shortCiteRegEx": "Cooper et al\\.", "year": 1989}, {"title": "Dy\u00ad namic network models for forecasting", "author": ["P. Dagum", "A. Galper", "E. Horvitz"], "venue": "Pro\u00ad ceedings of the Eighth Workshop on Uncertainty in Artificial Intelligence, pages 41-48, Stanford, CA. Association for Uncertainty in Artificial In\u00ad", "citeRegEx": "Dagum et al\\.,? 1992", "shortCiteRegEx": "Dagum et al\\.", "year": 1992}, {"title": "Decision-theoretic troubleshooting", "author": ["D. Heckerman", "J. Breese", "K. Rommelse"], "venue": "CACM, 38:3:49-57 0", "citeRegEx": "Heckerman et al\\.,? 1995", "shortCiteRegEx": "Heckerman et al\\.", "year": 1995}, {"title": "Inferring infor\u00ad mational goals from free-text queries: A bayesian approach", "author": ["D. Heckerman", "E. Horvitz"], "venue": "Proceedings of the Fourteenth Con\u00ad ference on Uncertainty in Artificial Intelligence. AUAI, Morgan Kaufmann.", "citeRegEx": "Heckerman and Horvitz,? 1998", "shortCiteRegEx": "Heckerman and Horvitz", "year": 1998}, {"title": "Toward normative expert systems: Part I", "author": ["D. Heckerman", "E. Horvitz", "B. Nathwani"], "venue": "The Pathfinder project. Methods of information in medicine, 31:90-105.", "citeRegEx": "Heckerman et al\\.,? 1992", "shortCiteRegEx": "Heckerman et al\\.", "year": 1992}, {"title": "Agents with beliefs: Reflections on Bayesian methods for user modeling", "author": ["E. Horvitz"], "venue": "Pro\u00ad ceedings of the Sixth International Conference on UserModeling, Sardinia, Italy, pages 441-442. User Modeling, Springer-Verlag.", "citeRegEx": "Horvitz,? 1997", "shortCiteRegEx": "Horvitz", "year": 1997}, {"title": "Display of in\u00ad formation for time-critical decision making", "author": ["E. Horvitz", "M. Barry"], "venue": "Proceedings of the Eleventh Conference on Un\u00ad certainty in Artificial Intelligence, pages 296305, Montreal, Canada. Morgan Kaufmann, San", "citeRegEx": "Horvitz and Barry,? 1995", "shortCiteRegEx": "Horvitz and Barry", "year": 1995}, {"title": "Deci\u00ad sion theory in expert systems and artificial intel\u00ad ligence", "author": ["E. Horvitz", "J. Breese", "M. Henrion"], "venue": "International Journal of Approximate Reasoning, Special Issue on Uncertain Reason\u00ad", "citeRegEx": "Horvitz et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 1988}, {"title": "Diagnostic strategies in the hypothesis-directed Pathfinder system", "author": ["E. Horvitz", "D. Heckerman", "B. Nathwani", "L. Fa\u00ad gan"], "venue": "In Pro\u00ad ceedings of the First Conference on Artificial In\u00ad telligence Applications,", "citeRegEx": "Horvitz et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Horvitz et al\\.", "year": 1984}, {"title": "Numerical uncertainty manage\u00ad ment in user and student modeling: An overview of systems and issues", "author": ["A. Jameson"], "venue": "User Modeling and User\u00ad Adapted Interaction, 5: 193-251.", "citeRegEx": "Jameson,? 1996", "shortCiteRegEx": "Jameson", "year": 1996}, {"title": "Dynamic be\u00ad lief networks for discrete monitoring", "author": ["A. Nicholson", "J. Brady"], "venue": "IEEE Transactions on Systems, Man, and Cybernet\u00ad ics, 24(11): 1593-1610.", "citeRegEx": "Nicholson and Brady,? 1994", "shortCiteRegEx": "Nicholson and Brady", "year": 1994}, {"title": "Accounting for contenxt in plan recognition with application to traffic monitoring", "author": ["D. Pynadath", "M. Wellman"], "venue": "Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelli\u00ad gence, pages 472-481, Montreal, Canada. Mor\u00ad", "citeRegEx": "Pynadath and Wellman,? 1995", "shortCiteRegEx": "Pynadath and Wellman", "year": 1995}], "referenceMentions": [{"referenceID": 13, "context": "However, there has been growing interest in the application of Bayesian and decision-theoretic methods to the task of modeling the beliefs, intentions, goals, and needs of users (Jameson, 1996; Horvitz, 1997).", "startOffset": 178, "endOffset": 208}, {"referenceID": 9, "context": "However, there has been growing interest in the application of Bayesian and decision-theoretic methods to the task of modeling the beliefs, intentions, goals, and needs of users (Jameson, 1996; Horvitz, 1997).", "startOffset": 178, "endOffset": 208}], "year": 2011, "abstractText": "The Lumiere Project centers on harnessing probability and utility to provide assistance to computer software users. We review work on Bayesian user models that can be em\u00ad ployed to infer a user's needs by consider\u00ad ing a user's background, actions, and queries. Several problems were tackled in Lumiere research, including ( 1) the construction of Bayesian models for reasoning about the time-varying goals of computer users from their observed actions and queries, (2) gain\u00ad ing access to a stream of events from soft\u00ad ware applications, (3) developing a language for transforming system events into observa\u00ad tional variables represented in Bayesian user models, ( 4) developing persistent profiles to capture changes in a user's expertise, and (5) the development of an overall architecture for an intelligent user interface. Lumiere proto\u00ad types served as the basis for the Office Assis\u00ad tant in the Microsoft Office '97 suite of pro\u00ad ductivity applications.", "creator": "pdftk 1.41 - www.pdftk.com"}}}