{"id": "1301.7386", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2013", "title": "Any Time Probabilistic Reasoning for Sensor Validation", "abstract": "for many real time applications, it is important to validate the information received from the sensors before entering higher levels of reasoning. this paper presents an any time probabilistic algorithm for validating the information provided by seismic sensors. the system consists of two bayesian network models. the first one is a model of the dependencies between sensors signals and it is used to validate each sensor. it provides a list total of potentially faulty sensors. to isolate then the real faults, a second bayesian network is used, which relates the potential faults with the real faults. this second model is also used to make correct the failure validation algorithm any time, by validating first the sensors that provide more information. to select the next sensor to validate, and measure perhaps the quality of the results at within each stage, an entropy function is used. this function captures in a single quantity both the certainty and specificity measures of any time algorithms. together, both models constitute a mechanism for validating sensors in an any time fashion, providing at each step the probability of correct / faulty for each sensor, and the total quality response of the results. the algorithm has been tested in the validation of temperature sensors of a battery power plant.", "histories": [["v1", "Wed, 30 Jan 2013 15:04:41 GMT  (253kb)", "http://arxiv.org/abs/1301.7386v1", "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)"]], "COMMENTS": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI1998)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["pablo h ibarguengoytia", "luis enrique sucar", "sunil vadera"], "accepted": false, "id": "1301.7386"}, "pdf": {"name": "1301.7386.pdf", "metadata": {"source": "CRF", "title": "ANY TIME PROBABILISTIC REASONING FOR SENSOR VALIDATION", "authors": ["P.H. Ibargiiengoytia"], "emails": ["pibar@iie.org.mx", "esucar@campus.mor.itesm.mx", "S.Vadera@mcs.salford.ac.uk"], "sections": [{"heading": null, "text": "1 Introduction\nArtificial intelligence (AI) techniques are playing an increasingly important role in real applications. In in dustry, different techniques have been proposed, for example, in diagnosis, automatic control, and moni toring. Generally, these applications require an over all model which usually, its inputs are mainly sensors. Also, many of these real applications need to main tain a real time behaviour, i.e., the correctness of the system depends not only on the logical result of the computation but also on the time at which the results are produced (Stankovic 1988]. Usually, real applica-\ntions possess a time limit by which some actions must be performed.\nThis paper presents a model for the validation of the sensors used in real time applications. The proposed validation is carried out in a separate module that works together with other functions in a system. In other words, it is assumed that a layered scheme is used in which the lowest level concentrates on validat ing the signals transmitted by the sensors as presented in Fig. 1 (Yung & Clarke 1989]. The main benefit of\nFigure 1: Layered diagnosis architecture.\nusing a layered approach is that it enables the con struction of models in a modular fashion. That is, it is easier to construct a model for sensor validation and then a model for the process than it is to construct an overall model in one step. This separation of the sensor validation layer can also result in simpler higher layer models and leave the higher layers to utilize other techniques.\nFaults in the sensors readings are detected in a decen tralised and hierarchical approach, so that they can be easily isolated and repaired. Additionally, suppose that the higher layers of the system represent other important and critical functions, e.g., the fault diag nosis of a nuclear plant. The intermediate layer (loop diagnosis) may be using model based reasoning to di agnose a control loop in the plant, whereas the system diagnosis layer may be utilizing a different approach. The validation module presented in this paper, utilizes a probabilistic model which considers only the rela tionships between the variables to be validated. \u00b7 This\nAny Time Probabilistic Reasoning for Sensor Validation 267\nprobabilistic model is independent of the higher layers models, so it is easier to construct and mantain when necessary.\nThis paper presents the continuation of the project described in a previous paper [Ibargiiengoytia et al. 1996]. In that paper, the authors described a proba bilistic approach to sensor validation that took advan tage of a Markov blanket property to distinguish real faults from apparent faults. A Bayesian network was used as a basis for predicting a probability distribu tion for a sensor value based on other sensors. The predicted distribution and the actual sensor reading was used in order to determine if there was a potential fault.\nHowever, the sensor validation process described in that paper works in batch mode, i.e., no intermedi ate results are available, and no attempt is made to estimate the quality of the results. For a real time application, these characteristics are inadequate. This paper presents the extension of the sensor validation algorithm, so it can be applied in real time systems. This consists in the use of any time algorithms.\nThus, the extension of the sensor validation algorithm consists in the following features. First, the use of a probabilistic causal network that relates the real and apparent faults. Second, in order to perform in any time basis, the validation algorithm selects the sensor which provides more information when validated. Fi nally, a quality function is calculated in order to char acterize the behaviour of the algorithm. The selection of the most informative sensor is made using the en tropy function.\nTo summarize, this paper presents an any time prob abilistic algorithm for validating the information pro vided by sensors. The system consists of two Bayesian network models. The first one is a model of the de pendencies between sensors and it is used to validate each sensor. It provides a list of potentially faulty sensors. To isolate the real faults, a second Bayesian network is used, which relates the potential faults with the real faults. This second model is also used to make the validation algorithm any time, by validating first the sensors that provide more information. To select the next sensor to validate, and measure the quality of the results at each stage, an entropy function is used. Together, both models constitute a mechanism for validating sensors in an any time fashion, providing at each step the probability of correct/faulty for each sensor, and the total quality of the results.\nThe next section briefly describes the basis of any time algorithms.\n2 Any Time Algorithms\nAny time algorithms represent one direction of work that aims to achieve the use of artificial intelligence techniques in real time systems. This term was ini-\ntially used by Dean in his research about time depen dent planning [Dean & Boddy 1988]. At the same time, Horvitz (1987) proposed the name of flexible computation for this mechanism. Any time algorithms are those that can be interrupted at any point dur ing computation, and return an answer whose value increases as it is allocated additional time [Boddy & Dean 1994]. However, how can this value be mea sured in a specific application? The literature con tains descriptions of different dimensions that have been proposed as metrics [Zilberstein & Russell 1996]: certainty, accuracy and specificity.\nPerformance profiles represent the expected value of these metrics for a given procedure as a function of time. In other words, performance profiles character ize the quality of an algorithm's output as a function of computation time. Figure 2 illustrates three cases of performance profiles [Zilberstein & Russell 1996], [Dean & Boddy 1988]:\nClearly, all these types of performance profiles are spe cial cases of a superclass that can be defined as mono tonic improvement, i.e., the quality of its intermediate results does not decrease as more time is spent to pro duce the result. The next section explains the basis of the validation algorithm, so that section 4 develops the any time algorithm for the sensor validation problem.\n3 Sensor Validation\nThe probabilistic sensor validation model utilizes Bayesian networks. The nodes represent the measures of the sensors. The structure of the network makes ex plicit the dependence relations between the variables.\nThe probabilistic sensor validation includes the diag nosis of all single sensors in the network. The idea is to instantiate all the nodes with the sensor read ings, except the one being validated. A probabilistic propagation provides a distribution of the posterior probability of the estimation of a signal value based on the readings of the most related signals. The esti mated value is then compared with the current value in order to decide if the measurement is correct. The most closely related variables for each sensor consist of a Markov blanket of the sensor variable. A Markov\n268 Ibargiiengoytia, Sucar, and Vadera\nblanket is defined as the set of variables that makes a variable independent from the others. In a Bayesian network, the following three sets of neighbours is suffi cient for forming a Markov blanket of a node: the set of direct predecessors, direct successors, and the direct predecessors of the successors (i.e. parents, children, and spouses) [Pearl 1988]. The set of variables that constitutes the Markov blanket of a variable can be seen as a protection of this variable against changes of variables outside the blanket. This means that, in or der to analyze a variable, it is only necessary to know the value of all variables in its blanket [Ibargiiengoytia et al. 1996]. Additionally, the extended Markov blan ket (EMB) of a sensor is formed by its Markov blanket plus the variable itself.\nHowever, since validating a sensor based on a faulty one results in an erroneous validation, the probabilis tic validation only provides a list of apparent faults. Thus, the probabilistic validation provides a list of po tential correct and potential faulty sensors. The fault isolation is carried out when the list of potential faulty sensors is compared with the list of EMB of each sen sor. When a match exists, then the faulty sensor has been distinguished. Otherwise, different conditions ex ist for the isolation of multiple failures [Ibargiiengoytia et al. 1996]. The next section describes the extensions of the sensor validation model in order to discriminate faulty and correct sensors in an any time basis.\n4 Any Time Sensor Validation\nAny time sensor validation algorithm implies that the knowledge about the state of the sensors (faulty or cor rect) becomes more certain and complete as time pro gresses. Certainty about the state of a sensor refers to the degree of belief in the correctness of a sensor, and completeness is characterized by the number of sensors from which the state is known. Thus, it is required to be able to monitor the state of the sensors during all the validation process. This is done through a vec tor whose elements PJ ( s;) represent the probabilities of failure for the sensors s;. Given that the any time validation process needs to be cyclic, the top level of the algorithm can take the form shown in Fig. 3.\nThe probabilistic validation of a single sensor (step b)\nout by calculating the probability distribution of m given the measurements oft and p. If the real value of sensor m has a probability greater than certain value, then the sensor is considered correct, and faulty oth erwise. However, if the fault is in sensor p, then the validation of m will also result in apparent fault.\nThus, the validation step is carried out by this algo rithm that receives as input, the sensor that will be validated. As output, the algorithm returns a binary value { correct,faulty} with the apparent status of the sensor.\n4.2 Selection of next sensor\nThis section develops a mathematical model for choos ing the best sensor to validate given the history of the validation process and the current state of the system. Also, the model proposed here will be used for measur ing the quality of the response in order to obtain the performance profile of the validation algorithm. The central idea is that the validation of a sensor provides\nAny Time Probabilistic Reasoning for Sensor Validation 269\nsome information and also, extra information can be inferred. Therefore, a measure of the information that a single validation produces is required. A definition of the expected amount of information that an event pro duces was first proposed by Shannon and used in com munication theory [Shannon & Weaver 1949]. Shan non proposed the following definitions.\nDefinition 4.1 Given a finite probability distribution\nPi \ufffd 0 for (i = 1, ... , n), and L:n p; = 1\nShannon's entropy measure is defined as n\nHn=Hn( Pl,\u00b7\u00b7\u00b7, Pn)=-2:.,p;log2Pi (1) i=l\nThus, the entropy measures the related number of bits required to store the information.\nSince the validation of a sensor s has two possible out comes, the entropy function H(s) is then defined as: { 0 if p = 0 or p = 1 H(s) = -plog2(p)- (1-p)log2(1- p) otherwise (2) where p represents the probability of failure of the sen sor. Notice that the expression plog2(p) = 0 when p = 1 but it is undefined when p = 0. However, since plog2(p) tends to zero as p tends to zero, the values defined in equation 2 can be safely assumed. Notice that it has its maximum when p = \ufffd 'i.e., when the ig norance is maximum, and it is zero when either p = 0 or p = 1, i.e., when the information is maximum and ignorance is minimum. This function can be consid ered either as a measure of the information provided by an experiment, or as a measure of the uncertainty in the experiment's outcome. Thus, considering each single sensor validation as an experiment, this function can be used to measure the amount of information pro vided by that validation. Then, the average amount of information E for the system can be defined as follows:\n1 n E(s1, ... ,sn) = - 2:.,H(s;)\nn i=l 1 n\n= -- L PJ(s;)log2PJ(s;) n i=l + (1- P1(s;))log2(1- PJ(s;)) 2 n = -- L PJ(s;)log2PJ(s;) (3) n i=l\nwhere n is the number of sensors in the system S, and P1(s;) represents the current probability of fail ure value assigned to sensors;. Notice that the vector whose elements are P1 ( s;) provides a measure of the certainty in the validation while the sum of n indi vidual entropies provides a specificity measure of the result.\nGiven this measure, the any time sensor validation al gorithm needs to select a sensor X that gives the best\nimprovement in the average entropy of the system S. Hence the following conditional version of equation 3 can be written\nE(S I X) = E(S I x = ok) + E(S I x = flty)\n= \ufffd (2:.,H( s; I x = ok) + 2:.,H(s; I x = flty)) (4) This function can be evaluated for each sensor and the one which gives the most information (the mini mum E(S I X;)) can be selected as the next sensor X; to be validated. The computation suggested by the above formulae could be too expensive for a real time sensor validation process. To overcome this problem, a pre compilation of the sensor selection mechanism is implemented as follows. The above formulae are used to select the sensor, Sr which gives the most informa tion. This selected sensor forms the root of a binary decision tree. A fault is simulated in this sensor and the formulae are again used to select the next sensor Sr-. Then, the root Sr is assumed to be correct, and the formulae are used to select the sensor Sr+ in this case. This results in the partial decision tree shown in Fig. 5. This process is repeated recursively on the\nAs an example, consider the network shown in Fig. 4. This process results in the decision tree shown in Fig. 6. Notice that this tree can be reduced considering\nFigure 6: Binary tree indicating the order of validation given the response of the validation step.\nonly the valid trajectories formed by the assumption of, for example, single faults among the set of sensors. See [Ibargiiengoytia 1997] for more details.\n270 lbargiiengoytia, Sucar, and Vadera\nThis decision tree can be used to select the next sensor more efficiently in real time than by performing the calculations. Thus, the selection step of the algorithm of Fig. 3 consists of simply traversing the tree one level after every single sensor validation. The cycle starts at the root, and the decision tree points to the next node in the tree according to the result of validating the current sensor.\n4.3 Isolation\nThe validation step provides only a list of potentially faulty sensors. Thus, a comparison is made between the set of potentially faulty sensors with the table of extended Markov blankets of all the sensors. When a match is found, a real fault is determined. However, the set of potentially faulty sensors is obtained after all the sensors have been validated. Therefore, in or der to extend that algorithm for any time behaviour, a different mechanism for distinguishing real faults from apparent ones is required. This new mechanism pro vides, as the output of the isolation phase, a vector with the probability of a real fault in all the sensors. This vector is refined incrementally in time, so the any time behaviour can be achieved.\nThe any time fault isolation process is based on the relationship between real and apparent faults. There are two situations that arise: (i) the existence of a real fault causes an apparent fault (as shown in Fig. 7(a)), and (ii) one apparent fault is the manifestation of sev eral possible real faults (as shown in Fig. 7(b)).\n(a) (b)\nFigure 7: Causal relation between real faults (R) and apparent (A) faults represented as nodes. In (a), one real fault causes several apparent ones, while in (b), one apparent fault is caused by one or more real faults.\nIn both figures, the relation between root nodes and leaf nodes is the same as the extended Markov blan ket (EMB) of a sensor. Considering all the sensors, a causal model relating the real and apparent faults can therefore be obtained from the fault detection Bayesian network (in fact, the EMB table is sufficient to build this network). In the first level (roots), the nodes represent the events of real failure in every sen sor. Then, the second level (leaves) is formed by nodes representing apparent failures in all the sensors. Arcs are included between every root node, and the corre sponding nodes of the extended Markov blanket. For example, the causal network shown in Fig. 8 can be obtained directly from the Bayesian network of the\ngas turbine given in Fig. 4. Thus, the consequences of\nFigure 8: Probabilistic causal model for fault isolation in the example of Fig. 4. Rt_ represents a real fault m sensor i while Aj represents an apparent fault in sensor j.\nobserving an apparent fault can be propagated in the causal network in order to obtain the probabilities of a real fault in all the sensors.\nThe network of Fig. 8 is multiply connected. Hence, the propagation method of trees of cliques is utilized [Lauritzen & Spiegelhalter 1988).\nIn general, 0(2n) conditional probabilities would be required (for a node with n parents). However, the noisy or model can be adopted here. Two assumptions need to hold in order to use this model: accountability and exception independence [Pearl1988).\nThe accountability assumption holds by the way the model is constructed, i.e., a sensor is apparently faulty only if there is a fault in its MB. The exception inde pendence assumption is concerned about a rare situ ation for this particular model. The relationship be tween the real and apparent faults is obtained from a Bayesian network in which the dependencies are as sumed to be strong. Hence, the probability of a real fault not resulting in an apparent fault is small. Fur ther, the mechanism by which a real fault in one sensor does not result in an apparent fault is even less likely to be dependent on another real fault. Hence, given that these assumptions are reasonable, the conditional probability matrix can be calculated by utilizing equa tion 5.\n(5)\nwhere d is the set of assignments of the set of apparent faults, and Td represent the set of all apparent faults actually present. Thus, the only parameter required is defined as:\nCij = 1-% = P(Aj I R; only).\nIn the case of the sensor validation problem, in an ideal case, all the parameters Cij \ufffd 1. Of course, these values can be obtained by simulation from the data if the problem is expected to depart from this ideal case. That is, according to the theory developed in Ibargiiengoytia et al. (1996), when a real fault Rt_ is\nAny Time Probabilistic Reasoning for Sensor Validation 271\npresent, it will always cause the apparent fault Aj (as suming that there is an arc from R; to Aj). The network of Fig. 8 is initialized with the following information: (i) the prior probability of all the root nodes in the model is 0.5 (assuming ignorance at the beginning of a cycle), and (ii) the parameters Cij = 0.99 for all 1 :::; i, j ::;number of nodes.\nHaving described how real and apparent faults can be related, the fault isolation model can now be summa rized. It receives as an input, a validated sensor with its detected state (faulty or correct) and updates the probability of failure of all the sensors. It does this by instantiating the value of the corresponding apparent node and using a propagation algorithm to obtain the posterior probabilities of the real faulty nodes. A vec tor Pf of these posterior probabilities represents the current state of knowledge about the sensors, and can be viewed as the output of the system at any time. For example, assuming a fault in g in the network of Fig. 4, produces the sequence of values of the proba bility vector as shown in Table 1.\nA measure that is independent of the application is the average entropy of the sensors given in equation 3. That is, if the current quality measure is:\n2 n Q(s1, ... , sn) == -- L Pj(si)log2Pj(si) (6)\nn i=l then, the reported quality function is calculated with the formula Q = 9maxQ9current where Qmax is the maximum value of the q\ufffd \u00b7 ;lity measure (i.e., n, the number of nodes). Notice that this measure captures both the certainty and specificity measures of any time algorithms. It captures certainty since the probabili ties of the sensors are used, and specificity since all the sensors are combined to give an average. Figure 9 shows the performance profile obtained with this qual ity measure for the example of Fig 4.\n5 Empirical Results\nThe sensor validation algorithm was evaluated by ap plying it to the validation of temperature sensors of the gas turbine at the Gomez Palacio power plant in\n1. 1.\ntime (a) (b)\nFigure 9: Performance profile describing the combi nation of certainty and specificity in one parameter against time. (a) without failure, (b) with a simulated failure in sensor g.\nMexico. A Bayesian network representing the depen dencies between the sensors of the plant is shown in Fig. 10. The dependency model was obtained by uti lizing an automatic learning program that uses real data from the start up phase of the turbine [Sucar et al. 1997].\nFigure 10: Probabilistic tree of the application. Nodes represent temperature signals of a gas turbine.\nThe data set was partitioned in two subsets: one parti tion for training the network, and the other partition for testing. The training/testing partition used was 70-30% of the original data set, i.e., 610 instances for training the model (calculating the prior and condi tional probabilities), and 260 instances for testing.\nTheoretically, the system should always detect and iso late single faults correctly. However, in reality, some errors may occur since in practice it is unlikely that the dependency model will be perfect. Consequently, two types of errors could occur: a correct reading might be considered faulty, and a real fault might not be de tected. These two possible errors are called type I and type II errors in the literature, and defined as follows [Cohen 1995]:\ntype I: rejection of the null hypothesis when it is true,\ntype II: acceptance of the null hypothesis when it is actually false.\nThe null hypothesis used refers to the hypothesis that a sensor is working properly. Thus, in other words,\n272 lbargiiengoytia, Sucar, and Vadera\ntype I errors occur when a correct sensor is reported as faulty while type II errors occur when faulty sensors are not detected.\nThe criteria for deciding if a reading is faulty or not can result in a trade off between these two types of errors. The criteria considered in this project are the following:\n1. Calculate the distance of the real value from the expected value, and map it to faulty if it is beyond a specified threshold and to correct if it is less than a specified threshold. The threshold values considered were 2, 2.5 and 3 times the standard deviation rr.\n2. Assume that the sensor is working properly and establish a confidence level at which this hypoth esis can be rejected, in which case it can be con sidered faulty. This confidence level is known as the p value. The p values considered were 0.05 and 0.01.\nThe accuracy of the model, i.e., the proportion of type I and II errors, is evaluated by varying the possible thresholds for each of these criteria.\nTwo different faults were simulated:\nSevere. The sensor value modified is the most distant extreme value, i.e., the real value is substituted by one which differs by minimum 50 %.\nMild. The real value is replaced by one which differs by 25 %.\nA test procedure was used to evaluate the accuracy of the whole validation process. Table 2 presents the final evaluation of the prototype with the percentage of type I and II errors for severe and mild faults.\nCriteria\nType I Type II\nType I Type II\nType I errors imply that most of the sensors in a EMB present apparent type I errors. This is more common as it can be seen in Table 2. That is, there are cases where the existence of an invalid apparent fault, to gether with the valid ones, completes the EMB of a misdiagnosed sensor. Hence, a type I error is pro duced. On the contrary, type II errors are detected at this stage when most of the sensors of a EMB present misdiagnosed apparent faults. This is very improba ble as the results of Table 2 confirms. The percentages\nare obtained comparing the average number of errors, with the total number of experiments.\n6 Discussion\nSection 4.2 developed an any time sensor validation algorithm that utilizes an entropy function as a cri terion for selecting the next sensor to validate. This entropy function calculates the amount of information that any single validation provides for diagnosing all the sensors. Hence, to evaluate this criterion, this sec tion compares the performance profile of the any time sensor validation algorithm as a function of time when the entropy based measure is used, and when a random selection scheme is used.\nquality of the response as a function of time. An ex periment consisted in the simulation of a single fault. Thus, 21 independent experiments were necessary to simulate a fault in all the sensors. In total, 260 exper iments were carried out, so every one of the 21 sensors was simulated faulty at least 12 times (12.6 times). The entropy graph represents the average of the resul tant quality with the entropy based scheme for the 21 sensors of Fig. 10. The random graph represents the average of the same experiment with a random selec tion scheme. The time axis is a qualitative comparison rather than quantitative.\nAlternatively, the results can also be evaluated by com paring the time required to reach different levels of quality. For example in Fig. 11, when the random cri terion reaches 60 % of quality, the entropy criterion has already reached more than 80 %.\nThe approach has been implemented and is being tested on the validation of temperature sensors in a gas turbine of a combined cycle power plant. The re sults for the accuracy of the model were reported in terms of the type I and type II errors and with re spect to detecting severe and mild faults. The results showed, that for this particular test application, more\nAny Time Probabilistic Reasoning for Sensor Validation 273\nstringent criteria for detecting failures reduced type I errors but did not significantly increase type II errors.\nThe results of the evaluation of the validation and iso lation phases together are shown in Table 2. Again, with a p value of 0.01, there are 2.9% of type I errors, and 0.4 % type II errors. Notice that, in general, the sensor validation algorithm performs almost perfectly with respect to undetected faulty sensors, i.e., all the faults are detected. At the same time, the rate of in correct detection faults is satisfactory for most of the criteria analyzed.\nTwo complexity aspects need to be discussed. The first one is the size of the pre compliled decision tree pre sented in section 4.2. A binary tree for n sensors con tains n levels and up to 2n-l nodes (1,048,575 nodes for 21 sensors). However, if a single fault is assumed, then the decision tree results in a pruned tree with n levels and at most n x ( n + 1) nodes. The second \u00b7 one is the complexity for probability propagation in the fault isolation network as in Fig. 8. The propaga tion complexity (using the clostering algorithm [Lau ritzen & Spiegelhalter 1988]), depends on the the size of the largest entry of the EM B table, i.e., the largest clique. However, if a tree is assumed for the detection Bayesian network, the number of nodes in the EM B table remains small, i.e., just one parent and the chil dren of a node.\n7 Conclusions\nThis paper has presented an any time, probabilistic algorithm for sensor validation. A layered approach is considered where the lowest layer performs the valida tion. A Bayesian network is used to define the relation ships between variables and to estimate the expected value of a sensor. The expected value is then compared with the actual reading obtained. If these measures differ then a faulty sensor is suspected. A faulty sensor is then distinguished from apparently faulty sensors by the use of a property based on the Markov blanket.\nAn any time version of the validation algorithm, that improves the quality of its answer incrementally, has also been presented. This any time algorithm uses a causal network to distinguish the real fault from the apparent ones. The any time behaviour is obtained with the selection of the sensor that provides more information when validated. The selection is made with the entropy function.\nThe evaluation of the any time behaviour of the al gorithm presented in this paper was done by carrying out experiments to obtain the performance profile of the entropy based selection scheme and comparing it with a random selection scheme.\nFuture research will attempt to use the probabilities obtained in the fault detection Bayesian network, as the input to the fault isolation Bayesian network. At this stage, the output of the detection network consists\nin a binary value ({correct, faulty}).\nAcknowledgments\nThanks to the anonymous referees for their comments which improved this article. This research is sup ported by a grant from CONACYT and liE under the IIE/SALFORD/CONACYT doctoral programme.\nReferences\nBoddy, M. & Dean, T. (1994), 'Decision theoretic de liberation schedulling for problem solving in time constrained environments', Artificial Intelligence 67(2), 245-286.\nCohen, P. (1995), Empirical methods for artificial in telligence, MIT press, Cambridge, Mass., U.S.A.\nDean, T. & Boddy, M. (1988), An analysis of time dependent planning, in 'Proc. Seventh Natl. Conf. on AI', St. Paul, MN, U.S.A.\nHorvitz, E. (1987), Reasoning about beliefs and ac tions under computational resource constraints, in 'Proc. Third Conference on Uncertainty in Ar tificial Intelligence', Seatle, WA, U.S.A., pp. 301- 324.\nIbargiiengoytia, P. (1997), Any time probabilistic sen sor validation, PhD dissertation, University of Salford, Computer and Mathematical Sciences, Salford U.K.\nIbargiiengoytia, P., Sucar, L. & Vadera, S. (1996), A probabilistic model for sensor validation, in 'Proc. Twelfth Conference on Uncertainty in Artificial Intelligence', Portland, Oregon, U.S.A., pp. 332- 339.\nLauritzen, S. & Spiegelhalter, D. J. (1988), 'Local com putations with probabilities on graphical struc tures and their application to expert systems', Journal of the Royal Statistical Society series B 50(2), 157-224.\nPearl, J. (1988), Probabilistic reasoning in intelligent systems: networks of plausible inference, Morgan Kaufmann, Palo Alto, Calif., U.S.A.\nShannon, C. & Weaver, W. (1949), The mathemati cal theory of communication, University of Illinois press, Urbana, Ill., U.S.A.\nStankovic, J. (1988), 'Misconceptions about real time computing: a serious problem for next generation systems', Computer 21(10), 10-19.\nSucar, L., Perez-Brito, J., Ruiz-Suarez, J. & Morales, E. (1997), 'Learning structure from data and its application to ozone prediction', Applied Intelli gence 7, 327-338.\nYung, S. & Clarke, D. (1989), 'Local sensor validation', Measurement f3 Control22 (3), 132-141.\nZilberstein, S. & Russell, S. (1996), 'Optimal compo sition of real-time systems', Artificial Intelligence 82 (1-2) ' 181-213."}], "references": [{"title": "Decision theoretic de\u00ad liberation schedulling for problem solving in time\u00ad constrained environments", "author": ["M. Boddy", "T. Dean"], "venue": "Artificial Intelligence", "citeRegEx": "Boddy and Dean,? \\Q1994\\E", "shortCiteRegEx": "Boddy and Dean", "year": 1994}, {"title": "Empirical methods for artificial in\u00ad telligence", "author": ["P. Cohen"], "venue": "MIT press,", "citeRegEx": "Cohen,? \\Q1995\\E", "shortCiteRegEx": "Cohen", "year": 1995}, {"title": "An analysis of time dependent planning, in 'Proc", "author": ["T. Dean", "M. Boddy"], "venue": "Seventh Natl. Conf. on AI',", "citeRegEx": "Dean and Boddy,? \\Q1988\\E", "shortCiteRegEx": "Dean and Boddy", "year": 1988}, {"title": "Reasoning about beliefs and ac\u00ad tions under computational resource constraints, in 'Proc", "author": ["E. Horvitz"], "venue": "Third Conference on Uncertainty in Ar\u00ad tificial Intelligence',", "citeRegEx": "Horvitz,? \\Q1987\\E", "shortCiteRegEx": "Horvitz", "year": 1987}, {"title": "Any time probabilistic sen\u00ad sor validation, PhD dissertation, University of Salford, Computer and Mathematical Sciences, Salford U.K", "author": ["P. Ibargiiengoytia"], "venue": null, "citeRegEx": "Ibargiiengoytia,? \\Q1997\\E", "shortCiteRegEx": "Ibargiiengoytia", "year": 1997}, {"title": "A probabilistic model for sensor validation, in 'Proc", "author": ["P. Ibargiiengoytia", "L. Sucar", "S. Vadera"], "venue": "Twelfth Conference on Uncertainty in Artificial Intelligence',", "citeRegEx": "Ibargiiengoytia et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Ibargiiengoytia et al\\.", "year": 1996}, {"title": "Local com\u00ad putations with probabilities on graphical struc\u00ad tures and their application to expert systems", "author": ["S. Lauritzen", "D.J. Spiegelhalter"], "venue": "Journal of the Royal Statistical Society series B", "citeRegEx": "Lauritzen and Spiegelhalter,? \\Q1988\\E", "shortCiteRegEx": "Lauritzen and Spiegelhalter", "year": 1988}, {"title": "Probabilistic reasoning in intelligent systems: networks of plausible inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl,? \\Q1988\\E", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "The mathemati\u00ad cal theory of communication, University of Illinois press, Urbana, Ill., U.S.A", "author": ["C. Shannon", "W. Weaver"], "venue": null, "citeRegEx": "Shannon and Weaver,? \\Q1949\\E", "shortCiteRegEx": "Shannon and Weaver", "year": 1949}, {"title": "Misconceptions about real time computing: a serious problem for next generation systems", "author": ["J. Stankovic"], "venue": null, "citeRegEx": "Stankovic,? \\Q1988\\E", "shortCiteRegEx": "Stankovic", "year": 1988}, {"title": "Learning structure from data and its application to ozone prediction", "author": ["L. Sucar", "J. Perez-Brito", "J. Ruiz-Suarez", "E. Morales"], "venue": "Applied Intelli\u00ad", "citeRegEx": "Sucar et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Sucar et al\\.", "year": 1997}, {"title": "Local sensor validation", "author": ["S. Yung", "D. Clarke"], "venue": "Measurement f3", "citeRegEx": "Yung and Clarke,? \\Q1989\\E", "shortCiteRegEx": "Yung and Clarke", "year": 1989}, {"title": "Optimal compo\u00ad sition of real-time systems", "author": ["S. Zilberstein", "S. Russell"], "venue": "Artificial Intelligence", "citeRegEx": "Zilberstein and Russell,? \\Q1996\\E", "shortCiteRegEx": "Zilberstein and Russell", "year": 1996}], "referenceMentions": [{"referenceID": 9, "context": ", the correctness of the system depends not only on the logical result of the computation but also on the time at which the results are produced (Stankovic 1988].", "startOffset": 145, "endOffset": 161}, {"referenceID": 5, "context": "This paper presents the continuation of the project described in a previous paper [Ibargiiengoytia et al. 1996].", "startOffset": 82, "endOffset": 111}, {"referenceID": 3, "context": "At the same time, Horvitz (1987) proposed the name of flexible computation for this mechanism.", "startOffset": 18, "endOffset": 33}, {"referenceID": 7, "context": "parents, children, and spouses) [Pearl 1988].", "startOffset": 32, "endOffset": 44}, {"referenceID": 5, "context": "This means that, in or\u00ad der to analyze a variable, it is only necessary to know the value of all variables in its blanket [Ibargiiengoytia et al. 1996].", "startOffset": 122, "endOffset": 151}, {"referenceID": 5, "context": "Otherwise, different conditions ex\u00ad ist for the isolation of multiple failures [Ibargiiengoytia et al. 1996].", "startOffset": 79, "endOffset": 108}, {"referenceID": 5, "context": "The validation step was briefly introduced in section 3 and more extensively in [Ibargiiengoytia et al. 1996].", "startOffset": 80, "endOffset": 109}, {"referenceID": 4, "context": "See [Ibargiiengoytia 1997] for more details.", "startOffset": 4, "endOffset": 26}, {"referenceID": 4, "context": "That is, according to the theory developed in Ibargiiengoytia et al. (1996), when a real fault Rt_ is", "startOffset": 46, "endOffset": 76}, {"referenceID": 10, "context": "The dependency model was obtained by uti\u00ad lizing an automatic learning program that uses real data from the start up phase of the turbine [Sucar et al. 1997].", "startOffset": 138, "endOffset": 157}, {"referenceID": 1, "context": "These two possible errors are called type I and type II errors in the literature, and defined as follows [Cohen 1995]:", "startOffset": 105, "endOffset": 117}], "year": 2011, "abstractText": "For many real time applications, it is impor\u00ad tant to validate the information received from the sensors before entering higher levels of reasoning. This paper presents an any time probabilistic algorithm for validating the in\u00ad formation provided by sensors. The sys\u00ad tem consists of two Bayesian network mod\u00ad els. The first one is a model of the dependen\u00ad cies between sensors and it is used to validate each sensor. It provides a list of potentially faulty sensors. To isolate the real faults, a second Bayesian network is used, which re\u00ad lates the potential faults with the real faults. This second model is also used to make the validation algorithm any time, by validating first the sensors that provide more informa\u00ad tion. To select the next sensor to validate, and measure the quality of the results at each stage, an entropy function is used. This func\u00ad tion captures in a single quantity both the certainty and specificity measures of any time algorithms. Together, both models consti\u00ad tute a mechanism for validating sensors in an any time fashion, providing at each step the probability of correct/faulty for each sensor, and the total quality of the results. The al\u00ad gorithm has been tested in the validation of temperature sensors of a power plant.", "creator": "pdftk 1.41 - www.pdftk.com"}}}