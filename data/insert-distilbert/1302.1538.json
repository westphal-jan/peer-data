{"id": "1302.1538", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2013", "title": "Sequential Update of Bayesian Network Structure", "abstract": "there is an obvious need for improving the performance and accuracy of a bayesian network as new data is observed. because of errors in model construction and changes in the dynamics of the domains, we again cannot continually afford to ignore the information in new data. while sequential update of parameters for a fixed structure can be accomplished using standard techniques, sequential update of network structure is still an open problem. in this paper, we investigate sequential update of bayesian networks were both parameters and structure are expected to change. we introduce a new approach that allows for demonstrating the flexible manipulation of the tradeoff between the quality of the learned networks and the amount of information that is maintained about past observations. we read formally here describe our approach including noting the necessary modifications to the scoring functions for learning bayesian networks, evaluate reduce its effectiveness through an empirical study, and extend it to correct the possible case of revealing missing data.", "histories": [["v1", "Wed, 6 Feb 2013 15:55:21 GMT  (1219kb)", "http://arxiv.org/abs/1302.1538v1", "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)"]], "COMMENTS": "Appears in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence (UAI1997)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["nir friedman", "moises goldszmidt"], "accepted": false, "id": "1302.1538"}, "pdf": {"name": "1302.1538.pdf", "metadata": {"source": "CRF", "title": "Sequential Update of Bayesian Network Structure", "authors": ["Nir Friedman", "Moises Goldszmidt"], "emails": ["nir@cs.berkeley.edu", "moises@erg.sri.com"], "sections": null, "references": [{"title": "A tutorial on learning Bayesian net\u00ad works", "author": ["D. Heckerman"], "venue": "Technical Report MSR-TR-95-06, Microsoft Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Learning Bayesian belief networks. An approach based on the MDL principle", "author": ["W. Lam", "F. Bacchus"], "venue": "Comp. lnt. ,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "A new view of the EM algorithm that justifies incremental and other variants", "author": ["R.M. Neal", "G.E. Hinton"], "venue": "Unpublished manuscript,", "citeRegEx": "Neal and Hinton.,? \\Q1994\\E", "shortCiteRegEx": "Neal and Hinton.", "year": 1994}, {"title": "Estimating the dimension of a model", "author": ["G. Schwarz"], "venue": "Ann. of Stat. ,", "citeRegEx": "Schwarz.,? \\Q1978\\E", "shortCiteRegEx": "Schwarz.", "year": 1978}, {"title": "Sequential up\u00ad dating of conditional probabilities on directed graph\u00ad", "author": ["D.J. Spiegelhalter", "S.L. Lauritzen"], "venue": "ical structures. Networks,", "citeRegEx": "Spiegelhalter and Lauritzen.,? \\Q1990\\E", "shortCiteRegEx": "Spiegelhalter and Lauritzen.", "year": 1990}], "referenceMentions": [], "year": 2011, "abstractText": "There is an obvious need for improving the per\u00ad formance and accuracy of a Bayesian network as new data is observed. Because of errors in model construction and changes in the dynamics of the domains, we cannot afford to ignore the infor\u00ad mation in new data. While sequential update of parameters for a fixed structure can be accom\u00ad plished using standard techniques, sequential up\u00ad date of network structure is still an open problem. In this paper, we investigate sequential update of Bayesian networks were both parameters and structure are expected to change. We introduce a new approach that allows for the flexible ma\u00ad nipulation of the tradeoff between the quality of the learned networks and the amount of informa\u00ad tion that is maintained about past observations. We formally describe our approach including the necessary modifications to the scoring functions for learning Bayesian networks, evaluate its effec\u00ad tiveness through and empirical study, and extend it to the case of missing data.", "creator": "pdftk 1.41 - www.pdftk.com"}}}