{"id": "1302.4976", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2013", "title": "On the Testability of Causal Models with Latent and Instrumental Variables", "abstract": "certain causal models involving unmeasured variables generally induce no independence constraints among the observed action variables but partially imply, nevertheless, inequality contraints on the observed distribution. this paper generally derives a general formula for combining such inherently instrumental variables, that is, exogenous variables that directly affect some variables but not all. so with the help of this formula, it is possible to test whether a model involving instrumental adaptive variables may account for the data, or, conversely, whether a given variables can be correctly deemed instrumental.", "histories": [["v1", "Wed, 20 Feb 2013 15:23:04 GMT  (351kb)", "http://arxiv.org/abs/1302.4976v1", "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)"]], "COMMENTS": "Appears in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (UAI1995)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["judea pearl"], "accepted": false, "id": "1302.4976"}, "pdf": {"name": "1302.4976.pdf", "metadata": {"source": "CRF", "title": "On the Testability of Causal Models with Latent and Instrumental Variables", "authors": ["Judea Pearl"], "emails": ["judea@cs."], "sections": [{"heading": null, "text": "Key words: causal modeling, instrumental variables, structural models, graphical models.\n1 INTRODUCTION\nIt is well known that one cannot infer causation from statistical data unless one is willing to supplement the data with causal assumptions. Conversely, if one de sires to test whether a given causal model is valid, statistical data obtained by passive (nonexperimen tal) observations can only refute models that con strain the joint distribution of the observables. Causal models represented by complete graphs, for exam ple, cannot be refuted by statistical data, whereas any incomplete graph is subject to empirical falsifi cation through the conditional independence relations induced by the missing edges. When all variables in a causal model are observable, conditional independence relationships are sufficient indeed for capturing all the constraints that the model imposes on the joint distri bution [Verma & Pearl 1991).\nThis is not the case when the model invokes unob served variables, also called hidden or latent variables. Verma and Pearl give an example where two graphs imply the same set of conditional independence rela tionships among the observed variables and yet they\nare empirically distinguishable because they imply dif ferent functional constraints on the distribution of those variable's. Another such example is presented in Figure 1, where models (a) and (b) both induce no independence constraints on the observed variables, due to the spurious dependencies induced by the la tent variable U. We shall see, however, that model (b), unlike (a), has testable implications which, if vio lated, can be used to falsify the model. In other words, the spurious dependencies induced by the latent vari able U are incapable of hiding all structural features of model (b). In contrast, model (a) is compatible with any joint distribution of X, Y, and Z.\nThis paper explores using the constraints induced by such structures as a mean for testing models with latent variables. The feature that makes model (b) falsifiable is the presence of two observed variables, Z and Y, such that Z is a root node and all di rected paths from Z to Y are intercepted by ob served variables. This feature constitutes a graphi cal definition of the notion of instrumental variables, which plays an important role in econometric modeling [Bowden & Turkington 1984) and in randomized trials [Imbens & Angrist 1994, Balke & Pearl 1994b)\nInstrumental variables is a technique invented by the geneticist Sewal Wright [1928] to help economists identify elasticities of supply and demand [Goldberger 1972). The key idea can be illustrated us ing a simple causal model given by the linear equation y = bx + u in which X and Y are observed and U rep resents a disturbance term, that is, unobserved factors\n436 Pearl\nthat the modeler decides to keep out of the analysis.1 It is well known that the coefficient b in the equation above cannot be estimated consistently if X and U are correlated. However , if we can find a third variable Z that is correlated with X and is (judged to be) uncor related with U, then b can be determined from the cor relations between Z, X, and Y, yielding b = Ryz/ Rxz. (This can be verified easily by multiplying both sides of the equation by Z and taking expectations.)\nBased on this simple idea, economists have de veloped elaborate techniques for estimating param eters in systems of linear simultaneous equations [Bowden & Turkington 1984]. More recently, the im portance of this idea has grown as a consequence of the realization that some of the power of these tech niques extends to nonlinear and nonparametric mod els, as characterized by the structural equations2\nx = g(z,u)\ny h(x, u) (1) together with the assumption that Z and U are inde pendent. The two-stage process defined by these equa tions, which we shall name the instrumental process, governs almost every experimental study and it is char acterized by the graph of figure 1 (b). In clinical tri als, for example, Z represents the treatment assigned to a subject, X represents the treatment actually re ceived by a subject, and Y represents an outcome of the treatment (e.g., recovery or performance). X dif fers from Z because some subjects, especially those reacting adversely to treatment, do not comply with the assignment and switch over to a different treat ment group. The difficulty in analyzing such trials stems from the strong dependency between compliance and potential treatment benefit; hence, the appearance of latent variable U in both equations.3 In general, the instrumental model, as defined in Eq. (1), governs many evaluation studies in which Z is a randomized in strument that encourages participation in the various programs under study, and Eu[h(x, u)] represents the average merit of the program corresponding to X = x. Likewise, this model governs the behavior of physical systems which are subject to random influences (U) and where it is required to estimate the effect of X on Y, and only partial control over the input variable (X) is possible.\nThe notion of instrument variables can also ben efit structure-learning programs. By incorporat ing new variables, not directly relevant to the phe nomenon under study, we can improve the relia bility of structuring decisions [Pearl & Verma 1991,\n1 We uses upper case symbols for variable names and lower case symbols for specific realizations of the variables.\n2See appendix for the relationships among graphs, structural equations and counterfactuals.\n3These equations a.re normally written using several \"er ror\" terms, for example, x == g(z, fx ), y = h(x, t:y) , with t:, and f y being jointly independent of Z. This formulation is equivalent to Eq. (1 ), since we can define U to consist of the joint space of fx and t:11\u2022\nSpirtes et al. 1993]. For example, if we are studying the effect of smoking (X) on lung cancer (Y) we might benefit from including in the analysis a variable Z such as \"anti-smoking legislation\" which acts as an instru ment for X (see Figure 1 (b)). In the absence of Z, one cannot decide whether the edge between X and Y should be oriented X - Y, X +- Y or eliminated alto gether. The joint distribution P(x, y, z), on the other hand, might supply this information, partly via con ditional independencies and partly via its bare magni tude.\nMore ambitiously, given the model shown in F ig ure 1(b ), one might ask whether the presence of the instrumental variable Z can facilitate the identifica tion of the causal effect of X on Y, Eu[h(x,u)], which is the nonparametric analogue of the coefficient b in the linear equation y = bx + u. Imbens and Angrist [1994] have shown that, in general, this identification is not possible without making additional assumptions about the functions g and h. Balke and Pearl [1994 a,b] have nevertheless shown that, it is possible to ob tain sharp, informative bounds on Eu[h(x, u)] without making such assumptions.\nHowever, the question of whether a given data set can be generated by the model of Eq. ( 1) remains unsettled. Economists and social scientists have fre quently remarked upon the difficulty of knowing or demonstrating that a variable Z is instrumental, in the sense of being uncorrelated with the disturbance U [Bartels 1991). Imbens and Angrist [1994], for ex ample, explicitly state that the model in Eq. (1) is not testable even when Z is randomized. Indeed, the basic assumption embodied in the model that Z is independent of the disturbance term of Y (i.e., all fac tors affecting Y, except X) is equivalent to what economists call exogeneity.4 For a long time, whether a variable Z is exogenous has been thought impossible to verify experimentally, since the definition involves unobservable factors such as those represented by U. The notion of exogeneity, like that of causation itself, has been viewed as a subjective modeling assumption, not as an objective property that can be tested from the data.\nThis paper tells a different story: it shows that, despite its elusive nature, exogeneity, hence, \"instrumental ity,\" can be given an empirical test. The test is not guaranteed to detect all violations of exogeneity, but it can, in certain circumstances, screen out very bad would-be instruments.\n2 THE INSTRUMENTAL INEQUALITY\nDefinition 1 (instrument) A variable Z is said to be an instrument relative to an ordered pair of variables\n4This assumption is termed superexogeneity in [Engle, et al. 1984].\nOn the Testability of Causal Models With Latent and Instrumental Variables 437\n(X, Y) if X and Y are generated by the following pro cess:\nx = g (z,u) y = h(x,u) (2)\nwhere g and h are arbitrary deterministic functions, and U is an arbitrary, unobserved random variable, independent of Z.\nThe required independence between Z and U rules out the possibility that Z is influenced by some la tent cause that also influences other variables in the system. The exclusion of z from h ( \u00b7) rules out Z hav ing any effect on Y that is not mediated by X, thus capturing the notion of locality, whereby an instru ment is presumed to \"affect X only.\" Note that no restrictions are posed on the domain of U; it may be finite or unbounded, discrete or continuous, ordered or unstructured.\nOur problem is to determine from the observed joint probability distribution P(x, y, z) whether Z can be exogenous relative to (X, Y), that is, whether there exist two functions g and h and a probability dis tribution on U and Z (with Z and U independent) such that the distribution generated by the two equa tions corresponds precisely to the observed distribu tion P (x, y, z).\nTheorem 1 A necessary condition for discrete vari ables X, Y and Z to be generated by an instrumental process as defined in Eq. (2) is that the conditional distribution P ( x, ylz) satisfies\nmax \"'[maxP (x, ylz)] S 1 X L.....J Z\n(3) y\nProof If the probability distribution P (x, y, z) is gen erated by the process defined in Eq. (2), then it can be expressed in the form\nP (x, y, z) = L P(ylx, u)P(xlz, u)P(u)P(z)\nThis can be seen by decomposing P(x, y, z, u, v) into product form along the order (y, x, v, u, z) and using the independence relations imposed by the model of Eq. (2), as displayed in the graph of Figure l (b). Therefore,\nP (x, ylz) = 2::'1- Pt(Yix, u)P2 (xlz, u)P(u) (4) = EuLP (ylx, u)P(xlz, u)\nIf Eq. (4) holds for every triplet (x, y, z), it certainly holds for a select set of triplets (x, y, z (x, y)), where z (x, y) is chosen so as to maximize P (x, ylz). Thus, summing Eq. (4) over y, gives\nL P (x, ylz(x, y)) = Eu L P (ylx, u)P (xlz (x, y), u) y\n(5)\nFor any fixed x and u, the term P(xlz (x, y), u) can be considered a function of y, which is bounded from above by unity. The summation on the r.h.s. ofEq. (5) represents a convex sum of such P terms and, hence, it must also be bounded by unity, which, after substi tuting out z (x,y), gives\n.L: m z axP (x,ylz) S 1 (6)\ny\nMoreover, since this inequality must hold for every x, we can write\nmax \"'[maxP (x, ylz)] S 1 X L.....J Z\n(7) y\nwhich proves the theorem. 0\nWe call the inequality above an instrumental inequal ity because it constitutes a necessary condition for any variable Z to qualify as an instrument relative to (X, Y). Recently, Huy Cao (1995) has shown that the inequality is not sufficient, except when X is binary.\n3 INTUITIONS, APPLICATIONS, AND EXTENSIONS\nIf all observed variables are binary, Eq. (7) reduces to the four inequalities\nP(Y = 0, X= OIZ = 0) + P(Y = 1, X= OIZ = 1) s 1 P(Y = O,X =liZ= 0) + P ( Y = l,X = liZ= 1) :51 P(Y = 1, X= OIZ = 0) + P(Y = 0, X= OIZ = 1 ) S 1 P(Y = 1, X= liZ= 0) + P ( Y = 0, X= liZ= 1) :51 (8) which were derived in an analysis of noncompliance in experimental studies [Pearl 1993].\nWe see that the instrumental inequality is violated when the controlling instrument Z manages to pro duce significant changes in the response variable Y while the direct cause, X, remains constant. Al though such changes could in principle be explained by spurious correlation through U , since X does not screen off Z from Y, the instrumental inequal ity sets a limit on the magnitude of the changes. The similarity to Bell's inequality in quantum physics [Cushing & McMullin 1989, Suppes 1988] is not acci dental; both inequalities delineate a class of observed correlations that cannot be explained by hypothesizing latent common causes. The instrumental inequality can, in fact, be viewed as a variant of Bell's inequality for cases where direct causal connection is permitted to operate between the correlated observables X and Y.\nOf special interest to experimenters is the prospect of applying the instrumental inequality to the detection of undesirable side-effects in experimental studies. In clinical trials, for example, dependencies between the treatment assignment ( Z) and factors ( U) affecting the response process can be attributed to one of two pos sibilities: either there is a direct causal effect of the as signment (Z) on the response (Y) , unmediated by the\n438 Pearl\ntreatment (X), or there is a common causal factor cor relating the two (Z and U). If the assignment is care fully randomized, then the latter possibility is ruled out and any violation of the instrumental inequality (even under conditions of imperfect compliance) can safely be attributed to some direct influence of the as signment process on subjects' response (e.g., psycho logical aversion to being treated). Alternatively, if one can rule out any direct effects of Z on Y , say through effective use of a placebo, then any observed violation of the instrumental inequality can safely be attributed to spurious dependence between Z and U, namely, to selection bias.\nThe instrumental inequality can be tightened appre ciably if we are willing to make additional assump tions about subjects' behavior - for example, that no individual can be discouraged by the encouragement instrument, or, mathematically, that for all u we have\ng(z1,u) \ufffd g(z2,u)\nwhenever z1 \ufffd z2. Such an assumption amounts to having no contrarians in the population, namely, no individual who would consistently act contrary to his or her assignment. Under this assumption, which 1m hens and Angrist (1994] call monotonicity, the inequal ities in Eq. (3) can be tightened (Balke & Pearl 1994a] to give\nP(y,X = ljZ = 0) P(y,X = ljZ = 1) > P(y,X = OIZ = 0) > P(y, X= OjZ = 1) (9)\nfor ally E {0, 1}. Violation of these inequalities now means either selection bias or a direct effect of Z on Y or the presence of contrarian subjects.\n4 THE ENIGMATIC CONTINUUM\nExtending the instrumental inequality to the case where Z and Y are continuous presents no special diffi culty. If f(yjx, z) is the conditional density function of Y given X and Z, then tracing the proof of Theorem 1 gives a condition similar to Eq. (3):\n1 max[f(yjx, z)P(xjz))dy \ufffd 1 Vx (10) y z However, the transition to continuous X involves a drastic change of behavior, and it seems that Eq. (2) induces no constraints whatsoever on the observed density.\nIt is clear that any tri-variate normal distribution f(x, y, z) can be generated by a process in which Z is instrument for (X, Y), as defined by Eq. (2). This can be seen from the fact that for any set of correla tion parameters Rxy, Ryz, and Rzx (Rzx > 0), we can always find a (unique) solution for the coefficients a, b, and c in the equations\nX = cZZ + CU y = bx + u (11)\n(the linear version of Eq. (2)) so as to satisfy the given correlation parameters under the assumption that Z and U are uncorrelated. In particular, this solution yields the celebrated instrumental variable estimator\nb = Rzy/ Rzx (12) which may have no relation whatsoever with the pro cess which actually governs the generation of Y in the data. Thus, the instrumental inequality cannot weed out a bad instrument Z if all measured variables are normally distributed.\nThe essential difference between the discrete and the continuous cases can be seen from the last step in the proof of Theorem 1. If in Eq. (5) we substitute the densities f(yjx, u) and f(xjz(x, y), u) instead of prob abilities, we obtain\n1 maxf(yjx, z)f(xjz)dy = E'U 1 f(yjx, u)f(xjz(x, y), u)dy y z y (13)\nHowever, in contrast to Eq. (5), we can not bound f(xjz(x, y), u) below unity.\nConjecture 1 If x is continuous, then every joint density f(y, xjz) can be generated by the instrumen tal process defined in Eq. {2). Although we are currently only close to achieving a general proof of Conjecture 1, some interesting special cases are worth reporting here.\nDefinition 2 (generator) Given a conditional density f(xjz), a function x = g(z, u) is said to be a gener ator of f(xjz) iff there exists some probability mea sure on the domain of U such that g is distributed as f(xjz), namely, P[g(z, u) \ufffd x) = F(xjz) when F(xjz) is the cumulative conditional distribution associated with f(xlz).\nDefinition 3 (one-to-one generator) A generator g(z, u) of f(xjz)) is said to be one-to-one iff, for every x and u, the equation x = g(z, u) has a unique solu tion for z. In other words, g( z1, u) = g( z2, u) implies Zl = Z2.\nLemma 1 Any density f(y, xjz) whose marginal f(xjz) has a one-to-one generator can be generated by an instrumental process ( Eq. ( 2)). Proof: If g(z, u) is a one-to-one generator of f(xjz), we write f(y, xjz) = f(yjx, z)f(xjz) then use x = g(z, u) to generate f(xjz), and some other function y = h'(x, z, v) to generate f(yjx, z), where u and v are independent random variables. Since g is one-to-one, we can compute a unique z = g-1(x, u) for each pair (x, u). Hence, we can substitute out z from h'(-) and obtain y = h'(x, g-1(x, u) , v) = h (x, u, v) which conforms to the process defined in Eq. (2) if we consider u as representing the pair ( u, v) .\nOn the Testability of Causal Models With Latent and Instrumental Variables 439\nExample 1 Let\n{ 2xfz f(y, xlz) = 0 0 S Y S z, 0 S X S 1 otherwise (14)\nThe marginal of this density is f(xiz) = 2x (0 S x S 1), which is independent of z. Thus, Z has no effect on X, yet, for any fixed x, Z has an effect on the density of Y , because\nf(ylx,z) = 1/z\nBy constructing a one-to-one generator for f(xlz), we will show that f(y, xlz) can still be generated by an instrumental process, in which Z has no direct effect on Y.\nThe method of constructing such a generator was shown to me by Steffen Lauritzen (personal communi cation, January 1995). We first define a new variable X' as t.. x' = (z + u)mod(1) =zEBu (15) and let U be distributed uniformly over [0, 1]. Clearly, the distribution of x' is uniform over [0, 1] for all values of z; moreover, EB has a unique inverse for z E [0, 1], which we write z = :r:' 8 u. We now express x as a function of x' so as to endow x with the desired conditional density f(xlz) = 2:r: (i.e., F(x!z) = x2). The proper transformation is x = F-1(x'lz) = R = .,jz EB u. This defines a generator for f(xlz),\nx = g(z,u) = \ufffd (16) which is one-to-one, because we can invert this equa tion to obtain\nWe are now in a position to construct the conditional density f(ylx, z) = 1/ z, 0 S y S z, by letting y be a function h of x and u. First, we construct the desired density by the standard method, letting y be a function of x, z, and v,\ny = F.Y1( vlx, z) = vz (17)\nwhere v is uniformly distributed over [0, 1], indepen dent of u. Second, we substitute out z and obtain\ny = h(z, u) = v(x2 e u)\nwhich, together with Eq. (16), generates the joint den sity specified in Eq. (14).\nCorollary 1 Every density f(y, x, z) satisfying f(xlz) = f(x) {i.e., Z and X are independent) can be generated by the instrumental process of Eq. (2).\nThis can be seen by generalizing the construction of Lemma 1 to arbitrary density f(xlz). To this end we again define x' = z $ u, and let u be distributed uni formly over [0,1]. In order to insure the proper density on x, we invoke the transformation\nx = F-1(x'lz)\nwhere F-1(x'lz) stands for the inverse cumulative dis tribution associated with f (i.e., x' = F(xlz)). Thus, our overall generator is\nx = g(z, u) = F-1(u $ ziz) (18)\nTo complete the construction, it is sufficient to show that this equation has a unique solution for z, which is certainly the case whenever F(xlz) = F(x).\nAlthough this construction does not apply to a general f(xlz), it enabled Huy Cao [1995] to prove Conjecture 1 for the case of Z is countably discrete Z.\nObservation If x is discrete, then f(xiz) may not have a one-to-one generator. In particular, the exis tence of a one-to-one generator is categorically ruled out if the corresponding probability mass function P(xiz) satisfies\np(xlzl) + p(xlz2) > 1 for some x, z1, and z2\u2022 In other words, every generator g(z, u) of such a P(xiz) has some u for which both Z1 and z2 are mapped into the same x and, moreover, the set Uo of such u's must have a nonzero probability.\nRemark To appreciate the importance of one-to-one ness, we can think of z as an action that is applied to some population, u as denoting a given unit in the population, and x = g( z, u) as the response of unit u to action z. If x is discrete, then whenever we observe\nP(xlzl) + P(xlz2) > 1 we may conclude that a non-negligible fraction of the population must be nonresponsive to the action, that is, g(z1, u) = g(z2, u) for every u in that subpopu lation, where z1 and z2 are two different actions. In contrast, no observation on continuous densities would imply the existence of such nonresponsive subpopula tions because every density f(x!z) can be realized by a population in which the response x of every individual is always sensitive to variations in actions, namely,\nVu (19) Even the extreme case of f(xiz) = f(x) can be realized in a fully responsive population satisfying Eq. (19), as is demonstrated by the one-to-one generator of Exam ple 1.\nPending questions Additional questions come to mind when we restrict the functional form of the gener ator g: Does every f(xiz) have a one-to-one generator if we limit our consideration to\n1. smooth generators, that is, g( z, u) differentiable in z for every u;\n2. monotonic generators, that is, g(z1,u) \ufffd g(z2,u) whenever z1 > z2;\n3. smooth and monotonic generators.\nThe answer, most probably, is no. Even the indepen dent case, f(xiz) = f(x), does not seem to have any smooth or monotonic one-to-one generator. Thus, the questions we need to answer are as follows:\n440 Pearl\n1. What characterizes those densities f (xiz) that do possess one-to-one monotonic generators.\n2. What characterizes the class of densities that do not have a one-to-one monotonic generator but still can be generated using instrumental mono tonic generators.\nAcknowledgment\nThe research was partially supported by Air Force grant #AFOSR/F496209410173, NSF grant #IRI9420306, and Rockwell/Northrop Micro grant #94- 100. Ed Leamer made helpful suggestions on the first draft of this paper. Steffen Lauritzen and Huy Cao have illuminated this topic with new results.\nReferences\n[Balke & Pearl 1994a] Balke, A., and Pearl, J., \"Non parametric bounds on causal effects from par tial compliance data,\" Technical Report R199-J, UCLA Computer Science Department, February 1994. Submitted to JASA.\n[Balke & Pearl 1994b] Balke, A., and Pearl, J ., \"Counterfactual probabilities: Computa tional methods, bounds, and applications,\" in R. Lopez de Mantaras and D. Poole (Eds.), Proceedings of the Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann, San Mateo, CA, 46-54, 1994.\n[Bartels 1991] Bartels, L.M., \"Instrumental and 'quasi-instrumental' variables,\" American Journal of Political Science, 35, 777-800, 1991.\n[Bowden & Turkington 1984] Bowden, R.J., and Turkington, D.A., In strumental Variables, Cambridge University Press, Cambridge, MA, 1984.\n[Cao 1995] Cao, H., \"On the empirical implications of instrumental variables with continuous treatments,\" Technical Report R-230, UCLA Computer Science Department, in prepara tion.\n[Cushing & McMullin 1989] Cushing, J.T., and Mc Mullin, E. (Eds.), Philosophical Conse quences of Quantum Theory, University of Notre Dame Press, Notre Dame, IN, 1989.\n[Engle, et al. 1984] Engle, R.F., Hendry, D.F., and Richard J .F., \"Exogeneity,\" Econometrica, 51 (2), 277-304, 1984.\n[Galles & Pearl 1995] Galles, D. and Pearl, J., \"Test ing Identifiability of Causal Effects,\" Pro ceedings of the Eleventh Conference on Un certainty in Artificial Intelligence, Morgan Kaufmann, San Mateo, CA, 1995.\n[Goldberger 1972] Goldberger, A.S., \"Structural equation models in the social sciences,\" Econometrica, 40, 979-1001, 1972.\n[Haavelmo 1943] Haavelmo, T., \"The statistical im plications of a system of simultaneous equa tions,\" Econometrica, 11, 1-12, 1943.\n[Imbens & Angrist 1994] lmbens, G.W., and Angrist, J.D., \"Identification and estimation of local average treatment effects,\" Econometrica, 62, 467-476, 1994.\n[Pearl 1993] Pearl, J., \"Aspects of graphical mod els connected with causality,\" Technical Re port R-195-LL, Computer Science Depart ment, UCLA, June 1993. Also in Proceedings of the UNICOM Seminar on Adaptive Com puting and Information Processing, Brunei University, London, 165-194, 1994.\n[Pearl 1995] Pearl, J ., \"Causal Diagrams for Experi mental Research,\" Technical Report R-218B, Computer Science Department, UCLA, 1995. To appear in Biometrika.\n[Pearl & Robins 1995] Pearl, J. and Robins, J., \"Probabilistic evaluation of sequential plans from causal models with hidden variables,\" Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence, Mor gan Kaufmann, San Mateo, CA, 1995.\n[Pearl & Verma 1991] Pearl, J. and Verma, T., \"The ory of Inferred Causation,\" Logic, Methodol ogy, and Philosophy of Science IX, Elsevier Science B.V., 789-811, 1994.\n[Robins 1987] Robins, J., Addendum to \"A new ap proach to causal inference in mortality stud ies with a sustained exposure period - ap plications to control of the healthy workers survivor effect,\" Computers and Mathemat ics with Applications, 14, 923-945, 1987.\n[Rubin 1974] Rubin, D.B., \"Estimating causal effects of treatments in randomized and nonrandom ized studies,\" Journal of Educational Psy chology, 66, 688-701, 1974.\n[Simon 1953] Simon, H.A., \"Causal ordering and iden tifiability,\" in W.C. Hood and T.C. Koop mans (Eds.), Studies in Econometric Method, Chapter 3, John Wiley and Sons, New York, 1953.\n[Spirtes et al. 1993] Spirtes, P., Glymour, C., and Schienes,R., Causation, Prediction, and Search, Springer-Verlag, New York, 1993.\n[Strotz & Wold 1971] Strotz, R.H. and Wold, H.O.A., \"Recursive versus nonrecursive systems: An attempt at synthesis,\" in H.M. Blalock (Ed.), Causal Models in the Social Sciences, Aldine, Atherton, Chicago, 1971.\n[Suppes 1988] Suppes, P., \"Probabilistic causality in space and time,\" in Skyrms, B., and Harper,\nOn the Testability of Causal Models With Latent and Instrumental Variables 441\nW.L. (Eds.), Causation, Chance, and Cre dence, 135-151, Kluwer Academic Publish ers, Dordrecht, The Netherlands, 1988.\n[Verma & Pearl 1991] Verma, T.S., and Pearl, J., \"Equivalence and synthesis of causal mod els,\" in Uncertainty in Artificial Intelligence, Vol. 6, 220-227, Elsevier Science Publishers, Cambridge, MA, 1991.\n[Wright 1928] Wright, P.G., The Tariff on Animal and Vegetable Oils, Macmillan, New York, 1928.\nAPPENDIX: GRAPHS,\nSTRUCTURAL EQUATIONS AND\nCOUNTERFACTUALS\nThis paper uses two representations of causal mod els: graphs and structural equations. By now, both representations have been considered controversial for almost a century. On the one hand, economists and social scientists have embraced these modeling tools, but they continue to debate the empirical content of the symbols they estimate and manipulate; as a re sult, the use of structural models in policy -making contexts is often viewed with suspicion. Statisticians, on the other hand, reject both representations as prob lematic (if not meaningless) and instead resort to coun terfactual notation whenever they are pressed to com municate causal information.5 This appendix presents an explication that unifies these three representation schemes in order to uncover commonalities, mediate differences, and make the causal-inference literature more generally accessible.\nStructural models The natural place to start is with a system T of struc tural equations like those in Eq. (1), which for the purposes of exposition we now write as\nz\nX y\nf(uz) g(z, u x) h(x,uy) (20)\nThese equations describe the physical processes that generate the observed data: instances (x, y, z) of vari ables X, Y , and Z. The value z of Z is determined by an unobserved factor U z which we choose to keep outside the analysis. The value x of X is determined by two factors, the value of Z and an external factor U x, and so on. If the functions /, g, and h are known, the model is parametric; otherwise, it is nonparamet ric. The contextual variables U = (U x, Uy, U z) sum marize the environment external to the system under analysis. Their values are determined outside the sys-\n5Space limitations do not permit us to offer an elaborate account of these formulations or to provide references to history of these controversies. For a more detailed account, see [Pearl 1995] and the references cited therein.\ntern, hence they are often called exogenous.6 They may stand for factors such as \"weather conditions\" or \"life style\" for which we have verbal descriptions, or they simply may serve as generic symbols for all the factors that were omitted from the analysis. Unlike regression models, structural equations make no a pri ori assumptions regarding independencies among the U variables.\nThe two defining attributes of structural equations which set them apart from ordinary algebraic equa tions are autonomy [Haavelmo 1943] and asymmetry [Simon 1953]. These attributes do not show up ex plicitly, as symbols in the equations, but implicitly, by attaching meaning to any subset of equations from T, thus restricting the type of algebraic transformations that are semantic-preserving.\nAutonomy reflects the understanding that the three equations above represent three independent pro cesses, and hence the three equations in (20) convey more information than the single vector mapping\n\ufffd \ufffd v = (x, y, z) = F(u x,uy,uz) = F(u) (21)\nwhich would be obtained from Eq. (20) by substitu tion. Indeed, for a given value of u, Eq. (21) provides merely a point value for (x, y, z) , while Eq. (20) also provides information about how that point value will change under a class of interventions which alter a se lected subset of equations.7 Eq. (20) tells us that, no matter what changes are made in the values of X, Z, and U, or in the processes (f, g) generating z and x, the value of Y will remain h(x, u y) whenever X and Uy take on the values x and u y, respectively. The empir ical content of this information can be operationalized using a hypothetical experiment in which the values of X and Uy are held constant by some external control. Under such conditions, Eq. (20) predicts the relation y = h(x, uy) to hold permanently, irrespective of any controls applied to other variables in the system.\nAsymmetry reflects the directionality of the relation ship \"is determined by.\" The equation y = h(x, uy) prescribes how changes in x (be they a product of new interventions or of changes in u) would translate into changes in y, but not the other way around. Thus, the equality sign in structural equations models is not an ordinary algebraic equality but functions more like the assignment symbol in programming languages. The identity of the dependent variable (positioned on the lhs) in each equation is useful for indexing the equa tions to be altered by a given intervention, say, holding X fixed.\n6This notion of exogeneity (synonymous with predeter minedness) is much weaker than that used in the text; the boundary between contextual and endogenous variables is often a matter of modeling choice and does not rest on any assumption of independence relative to error terms.\n7Unlike most of the literature (e.g., [Simon 1953]) we do not insist that interventions be represented as changes in U; modellers need not anticipate in advance all interventions capable of altering a given process.\n442 Pearl\nThese process-based considerations are important in the modeling phase, when the structural equations are put together. Once completed, causal analysis pro ceeds on the basis of syntactic structure alone. Given a set T of structural equations, one can define complex notions such as causation, intervention, atomic inter vention, causal effect, causal relevance, average causal effect, plans, conditional plans, identifiability, coun terfactuals, exogeneity, and so on. For example, the atomic intervention set( X = x) is modeled by replac ing the equation corresponding to X with the equation X = x and then solving the resulting set of equations for the variables of interest [Strotz & Wold 1971]. Ac cordingly, we can say that \"X is a cause ofY in context u\" if there are two values of X, x and x', such that the solution for Y under U = u and set(X = x) is different from the solution under U = u and set(X = x'). Probabilistic causality emerges when we define a prob ability distribution P( u) for the U variables, which, under the assumption that the equations have a unique solution, induces a unique distribution on the en dogenous variables for each combination of atomic in terventions. The causal effect of X on Y, denoted P(ylx), is then defined as the distribution of Y in duced by P(u) under the intervention set(X = x) [Pearl 1995]. Recently, wealth of new results have been obtained on nonparametric identification of P(ylx), thus providing conditions under which P(ylx) depend not on the functions f (\u00b7), g (\u00b7), h (-), . . . , but only on the observed distributions (see [Galles & Pearl 1995, Pearl & Robins 1995] in this volume). These condi tions require that P( u) exhibit a rich set of indepen dencies and that the equations be sparse and recursive. The precise specification of these requirements is best expressed in terms of graphs.\nGraphs Graphs offer an abstraction of structural equations. They carry the following two pieces of information:\n1. The identity of the observable variables on the rhs of each equation (often called independent variables). These are represented as nodes in the graph from which arrows emanate into the dependent variable in the equation. Thus, each equation translates into a parents-child family in a directed graph. The directed graph may be ei ther cyclic, or in the case where the equations are recursive, acyclic. The parents of variable X will be denoted by IIx, and any realization of those parent variables by 7r x.\n2. The identity of jointly independent groups of U terms in P( u). This information is represented graphically as double-arrow dashed arcs between pairs of nodes. The absence of a dashed arc between node X and a set of nodes Z1, ... , Zk implies that the corresponding U variables, U x, U z!, ... , U zk, are jointly independent. 8\n8In principle, there may be several sets of arcs repre-\nFor example, the graph in Figure 1(b) represents the structural equations in (20), since each parents-child family in the graph corresponds to one equation in (20), with parent sets:\nllz = {0}, IIx = {Z}, lly = {X}\nIn addition, the absence of a dashed arc between Z and X and between Z and Y represents the independence Uz\n_ II {Ux, Uy} or, equivalently, Z _ II {Uz, Uy }.\nCounterfactuals The counterfactual notation, usually associated with Rubin's model [Rubin 1974] (some economists refer to it as Roy's model), represents another abstraction of structural equations. The starting point is not the sys tem of equations but the set of solutions of those equa tions under different contexts (or units) U = u.9 The primitive object of analysis is the unit-based response variable, denoted Y(x, u) or Yx(u), which stands for the solution for Y under U = u and under the hypo thetical intervention set( X = x) (X may stand for a subset of variables). 10\nTo statisticians, the attractive feature of the coun terfactual notation is that it permits prior causal knowledge to be expressed as assumptions about random variables (albeit counterfactual), thus allow ing the analysis to remain within the boundaries of standard probability calculus. This conforms fully with the Bayesian requirement that all prior knowl edge be expressed as constraints on distributions; meta-probabilistic notions such as \"exogeneity,\" \"pro cesses,\" \"autonomy,\" and \"intervention\" are avoided, at least superficially.\nIf U is treated as a random variable, then the value of the counterfactual Y(x, u) becomes a random vari able as well, denoted as Y(x) or Yx. Causal analysis can then proceed by imagining the observed distribu tion P(x, y, z) as the marginal distribution of an aug mented probability function P* defined over both the observed variables and the counterfactual variables of\nsenting the same independencies in the manner described above. However, if the dependencies among the U variables are themselves a product of a recursive causal process, the arc representation is unique.\n9The term unit instead of context is used in the counter factual literature [Rubin 1974], where it normally stands for the identity of a specific individual in a population, namely, the set of attributes that characterize that indi vidual. This is precisely the role played by the vector u in structural equations. In general, u may include the time of day, the experimental conditions under study, and so on.\n10Practitioners of the counterfactual notation do not ex plicitly mention the notions of \"solution\" or \"intervention\" in the definition of Y(x, u) . Instead, the phrase \"the value that Y would take in unit u, had X been x,\" viewed as ba sic, is posited as the definition of Y(x, u) . However, since structural models offer a formal semantics (based on solv ing subsets of equations) for counterfactual phrases of this kind, the definition above is deemed more basic, and it helps illuminate the connection between structural models and counterfactual variables.\nOn the Testability of Causal Models With Latent and Instrumental Variables 443\ninterest, say Y ( x). Queries about causal effects, pre viously written P(ylx), are rephrased as queries about the marginal distribution of the counterfactual vari able of interest,- written P(Y(x) = y). The new en tities Y ( x) are treated as ordinary random variables that are connected to the observed variables via the logical constraint [Robins 1987]\nX= x ::=:::} Y(x) = Y (22) and a set of conditional independence assumptions which the investigator must supply to endow the aug mented probability, P* , with causal knowledge. These assumptions should encode (a summary of) the inves tigator's understanding of the data-generation process, previously encoded in equations or in graphs.\nFor example, to convey the understanding that the process generating X in Eq. (20) is not in itself affected by the variable Z , the analyst should communicate the independence constraint X (z) II Z. Likewise, to communicate the understanding thatin a randomized clinical trial the way subjects react (Y) to treatments (X) is statistically independent of the treatment as signment (Z) , the analyst would write Y(x)\n_ II Z.\nA collection of constraints of this type might some times be sufficient to permit a unique solution to the query of interest, e.g., P(Y(x) = y); in other cases, only bounds on the solution can be obtained. The models in Figure 1(a) and 1(b) are examples of the former and latter cases, respectively. It should be remarked though, that since users of the coun terfactual notation do not view counterfactual vari ables as by-products of a deeper model of the data generating mechanism, the process of issuing judg ments about counterfactual dependencies has not been systematized. Analysts are not always sure whether all relevant judgments have been articulated, whether the judgments articulated are redundant, or whether those judgments are consistent with the data. Such judgments can be systematized in the graphical repre sentation of structural equations, as is shown next.\nTranslation: From Graphs to Counterfactuals\nThe assumptions embodied in a causal graph can be translated into the counterfactual notation using two simple rules; the first interprets the missing arrows in the graph, the second, the missing dashed arcs. Miss ing arrows represent variables that were deemed ex cludable from (the process or the hypothetical experi ment described by) an equation. Missing arcs encode independencies among the U terms in two or more equations.\n1. Exclusion restrictions: For every variable Y hav ing parents ITy , and for every set of variables S disjoint of ITy , we have\nY (1ry)=Y(1ry , s) (23)\n2. Independence restrictions: For every pair of vari ables X and Y not connected by a dashed arc,\nwe have Y (1ry)\n_ II X (1rx) (24)\nLikewise, if X1, .. . , Xk is any set of nodes not connected to Y via dashed arcs, we have\nFor example, the graph in Figure l(a), displaying the parent sets\nITz = {0}, IIx = {Z}, ITy = {X}\nencodes the following assumptions:\n1. Exclusion restrictions: 6 Z(x) = Z(y) = Z (x , y) = Z (0) = Z\nX(y, z) = X (z), Y (x) = Y (x , z)\n2. Independence restrictions:\nX (z) _ II {Z , Y(x)}\nWe leave it to the reader to show that these assump tions are sufficient to allow computation of the causal effect P(Y(z) = y) using standard probability calculus together with axiom (22). Note that, unlike the in dependence judgments normally required by counter factual analysts, the assumptions obtained from the graph involve only parents-child relationships (e.g., Y ( x), X ( z)); remotely related counterfactuals such as Y (z) , which are cognitively less meaningful, may be derived from parents-child relationships by substitu tions but are not the object of direct subjective judg ments.\nIt is also interesting to note that the analysis of in strumental inequalities presented in this paper is valid under more general conditions than those shown in the graph of Figure 1(b). If an arrow from Y to X is added to the graph, a cyclic graph containing the feedback loop X ---. Y ---. X is obtained. (In the context of clinical trials, such a loop may represent, for example, patients deciding on dosage X by continuously moni toring their response Y.) Nonetheless, the structural equation model will not change, because, under the assumption that the cycle is stable, the equation\nx=g(z , y ,u)\ncan be replaced with\nx = g' (z , u') such that u' is still independent of z. The non para metric nature of the structural equations in (20) per mit us to make such transformations without affecting the results of the analysis. Likewise, nonparametric bounds obtained from the analysis of the acyclic graph 1b [Balke & Pearl, 1994a,b] are still valid for the cyclic case."}], "references": [{"title": "and Pearl", "author": ["A. Balke"], "venue": "J., \"Non\u00ad parametric bounds on causal effects from par\u00ad tial compliance data,\" Technical Report R199-J, UCLA Computer Science Department, February", "citeRegEx": "Balke . Pearl 1994a", "shortCiteRegEx": null, "year": 1994}, {"title": "In\u00ad strumental Variables", "author": ["R.J. Bowden", "D.A. Turkington"], "venue": "Cambridge University Press, Cambridge, MA,", "citeRegEx": "Bowden . Turkington 1984", "shortCiteRegEx": null, "year": 1984}, {"title": "On the empirical implications of instrumental variables with continuous treatments,", "author": ["H. Cao"], "venue": "Technical Report R-230,", "citeRegEx": "Cao,? \\Q1995\\E", "shortCiteRegEx": "Cao", "year": 1995}, {"title": "and Mc\u00ad Mullin", "author": ["J.T. Cushing"], "venue": "E. (Eds.), Philosophical Conse\u00ad quences of Quantum Theory, University of Notre Dame Press, Notre Dame, IN,", "citeRegEx": "Cushing . McMullin 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Hendry", "author": ["R.F. Engle"], "venue": "D.F., and Richard J .F., \"Exogeneity,\" Econometrica, 51 (2), 277-304,", "citeRegEx": "Engle. et al. 1984", "shortCiteRegEx": null, "year": 1984}, {"title": "D", "author": ["Galles"], "venue": "and Pearl, J., \"Test\u00ad ing Identifiability of Causal Effects,\" Pro\u00ad ceedings of the Eleventh Conference on Un\u00ad certainty in Artificial Intelligence, Morgan Kaufmann, San Mateo, CA,", "citeRegEx": "Galles . Pearl 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Structural equation models in the social", "author": ["A.S. Goldberger"], "venue": "sciences,\" Econometrica,", "citeRegEx": "Goldberger,? \\Q1972\\E", "shortCiteRegEx": "Goldberger", "year": 1972}, {"title": "Identification and estimation of local average treatment", "author": ["Imbens", "G.W. Angrist 1994] lmbens", "J.D. Angrist"], "venue": "effects,\" Econometrica,", "citeRegEx": "Imbens et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Imbens et al\\.", "year": 1994}, {"title": "Aspects of graphical mod\u00ad els connected with causality,\" Technical Re\u00ad port R-195-LL", "author": ["J. Pearl"], "venue": "Computer Science Depart\u00ad ment,", "citeRegEx": "Pearl,? \\Q1993\\E", "shortCiteRegEx": "Pearl", "year": 1993}, {"title": "Probabilistic evaluation of sequential plans from causal models with hidden variables,", "author": ["Pearl", "J. Robins 1995] Pearl", "J. Robins"], "venue": "Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Pearl et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Pearl et al\\.", "year": 1995}, {"title": "J", "author": ["Pearl"], "venue": "and Verma, T., \"The\u00ad ory of Inferred Causation,\" Logic, Methodol\u00ad ogy, and Philosophy of Science IX, Elsevier Science B.V., 789-811,", "citeRegEx": "Pearl . Verma 1991", "shortCiteRegEx": null, "year": 1994}, {"title": "Addendum to \"A new ap\u00ad proach to causal inference in mortality stud\u00ad ies with a sustained exposure period - ap\u00ad plications to control of the healthy workers survivor effect,\" Computers and Mathemat\u00ad", "author": ["J. Robins"], "venue": null, "citeRegEx": "Robins,? \\Q1987\\E", "shortCiteRegEx": "Robins", "year": 1987}, {"title": "Estimating causal effects of treatments in randomized and nonrandom\u00ad ized studies,", "author": ["D.B. Rubin"], "venue": "Journal of Educational Psy\u00ad chology,", "citeRegEx": "Rubin,? \\Q1974\\E", "shortCiteRegEx": "Rubin", "year": 1974}, {"title": "Causal ordering and iden\u00ad tifiability,\" in W.C", "author": ["H.A. Simon"], "venue": "Hood and T.C. Koop\u00ad mans (Eds.), Studies in Econometric Method,", "citeRegEx": "Simon,? \\Q1953\\E", "shortCiteRegEx": "Simon", "year": 1953}, {"title": "Glymour", "author": ["P. Spirtes"], "venue": "C., and Schienes,R., Causation, Prediction, and Search, Springer-Verlag, New York,", "citeRegEx": "Spirtes et al. 1993", "shortCiteRegEx": null, "year": 1993}, {"title": "and Wold", "author": ["Strotz", "R.H"], "venue": "H.O.A., \"Recursive versus nonrecursive systems: An attempt at synthesis,\" in H.M. Blalock (Ed.), Causal Models in the Social Sciences, Aldine, Atherton, Chicago,", "citeRegEx": "Strotz . Wold 1971", "shortCiteRegEx": null, "year": 1971}, {"title": "The Tariff on Animal and Vegetable Oils, Macmillan, New York, 1928. APPENDIX: GRAPHS, STRUCTURAL EQUATIONS AND COUNTERFACTUALS", "author": ["P.G. Wright"], "venue": null, "citeRegEx": "Wright,? \\Q1928\\E", "shortCiteRegEx": "Wright", "year": 1928}], "referenceMentions": [{"referenceID": 1, "context": "Based on this simple idea, economists have de\u00ad veloped elaborate techniques for estimating param\u00ad eters in systems of linear simultaneous equations [Bowden & Turkington 1984].", "startOffset": 148, "endOffset": 174}, {"referenceID": 4, "context": "4This assumption is termed superexogeneity in [Engle, et al. 1984].", "startOffset": 46, "endOffset": 66}, {"referenceID": 8, "context": "which were derived in an analysis of noncompliance in experimental studies [Pearl 1993].", "startOffset": 75, "endOffset": 87}], "year": 2011, "abstractText": "Certain causal models involving unmea\u00ad sured variables induce no independence constraints among the observed variables but imply, nevertheless, inequality con\u00ad straints on the observed distribution. This paper derives a general formula for such in\u00ad equality constraints as induced by instru\u00ad mental variables, that is, exogenous vari\u00ad ables that directly affect some variables but not all. With the help of this formula, it is possible to test whether a model involving instrumental variables may account for the data, or, conversely, whether a given vari\u00ad able can be deemed instrumental.", "creator": "pdftk 1.41 - www.pdftk.com"}}}