{"id": "1303.3319", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Mar-2013", "title": "A new type of judgement theorems for attribute characters in information system", "abstract": "the research of attribute characters in information system which contains core, necessary, unnecessary is certainly a basic and fundamentally important issue in attribute reduct. many methods for the judgement of attribute characters are based on the relationship between the objects and attributes. in highlighting this paper, a new type of judgement theorems which are absolutely based on the relationship among the attributes is proposed for preparing the judgement of attribute characters. the method solution is through comparing the two new attribute sets $ worth e ( a ) $ and $ n ( a ) $ with respect and to the designated attribute $ a $ which everything is proposed in this paper. we conclude that which type of the attribute $ a $ belongs to is determined by the relationship between $ e ( a ) $ and $ n ( a ) $ in essence. secondly, more concise and clear results are given about describing the judgment of the attribute characters through analyzing the properties of refinement and precise - refinement between $ e ( a ) $ and $ n ( a ) $ in topology. in addition, the relationship among attributes are discussed which is useful for constructing a reduct in the last section of this paper. in the last, we propose a reduct algorithm based on $ e ( a ) $, and this algorithm is an extended application of the analysis of attribute characters above.", "histories": [["v1", "Thu, 14 Mar 2013 00:35:54 GMT  (30kb,A)", "http://arxiv.org/abs/1303.3319v1", null]], "reviews": [], "SUBJECTS": "cs.DS cs.AI", "authors": ["anhui tan"], "accepted": false, "id": "1303.3319"}, "pdf": {"name": "1303.3319.pdf", "metadata": {"source": "CRF", "title": "A new type of judgement theorems for attribute characters in information system", "authors": ["Anhui Tan", "Jinjin Li", "Guoping Lin"], "emails": ["shujujiegouwang@126.com", "jinjinli@fjzs.edu.cn", "guoplin@163.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n30 3.\n33 19\nv1 [\ncs .D\nS] 1\nThe research of attribute characters in information system which contains core, necessary, unnecessary is a basic and important issue in attribute reduct. Many methods for the judgement of attribute characters are based on the relationship between the objects and attributes. In this paper, a new type of judgement theorems which are absolutely based on the relationship among attributes is proposed for the judgement of attribute characters. The method is through comparing the two new attribute sets E(a) and N(a) with respect to the designated attribute a which is proposed in this paper. We conclude that which type of the attribute a belongs to is determined by the relationship between E(a) and N(a) in essence. Secondly, more concise and clear results are given about the judgment of the attribute characters through analyzing the properties of refinement and precise-refinement between E(a) andN(a) in topology. In addition, the relationship among attributes are discussed which is useful for constructing a reduct in the last section of this paper. In the last, we propose a reduct algorithm based on E(a), and this algorithm is an extended application of the analysis of attribute characters above.\nKeywords: Rough set; Information system; Attribute reduct; Attribute characters; Discernibility matrix; reduct algorithm\n\u2217Corresponding author. Email addresses: shujujiegouwang@126.com (Anhui Tan), jinjinli@fjzs.edu.cn\n(Jinjin Li), guoplin@163.com (Guoping Lin)\nPreprint submitted to Elsevier March 19, 2015"}, {"heading": "1. Introduction", "text": "Rough set theory originally proposed by Pawlak [1][2], provides an effective method to deal with imprecision and vague in information system. Because of voluminous data that always generates in information system, multi-granular Rough set is very important as a basic Processing method, and has very widely applications in process control, conflict analysis, data mining, data fusion technique [18, 19, 20, 21]. In recent years, many topics have been widely investigated with rough sets, for example, topology, graph, algebra, lattices, fuzzy set, and so on [24\u2212 33].\nInformation system is an extension of rough set theory, which is denoted as a pair (U,A), where U is a nonempty finite set of objects called the domain set and A = {a1, a2, ..., an} is a nonempty finite set of attributes such that a : U \u2192 Va for any a \u2208 A, i.e., ax \u2208 Va, x \u2208 U, where Va is called the domain of attribute a. Each attribute based on an equivalence relation generates a partition on the domain U , and the objects belong to the same partition have the same value in Va, so the set of attributes A generates more than one partitions.\nMoreover, approximation space theory is proposed to approximate the objects that are not precise. In approximation space theory, a pair of approximation operators R\u2217, R\u2217 are introduced which are widely used.\nBecause of the importance of the attributes, attribute reduction is a basic topic in rough sets theory and information system, and it is a NP-hard problem.\nA beautiful and efficient method was introduced by Skowron and Rauszer [6] which is the discernibility matrix of the information system (U,A), where DA = {dA(x, y)|x, y \u2208 U}, dA(x, y) = {a \u2208 A|Va(x) 6= Va(y)}. Otherwise, the boolean discernibility function is proposed to compute the reduct. Many scholars devote to study this issues [11\u221214], [22, 23]. Especially, many papers studied the attribute reduct theory with the discernibility matrix[15\u2212 21].\nIn [3], Yao and Zhao discussed the reduct by discernibility matrix simplification. The thought is through deleting the attributes in every dA(x, y), and in the end, there is only one attribute in every dA(x, y), then the remaining attributes constitute a reduct. Otherwise, another reduct construction algorithm based on matrix simplification is proposed in [3]. The computing process of this algorithm is just like the operation of the boolean discernibility function. That is, delete the redundant elements in the discernibility matrix through absorption operation, then there exists no inclusion relation-\nship between any two elements of the discernibility matrix. Then pick a dA(x, y) in the discernibility matrix, and an attribute a \u2208 dA(x, y), then delete (dA(x, y) \u2212 {a}) for any other elements of the discernibility matrix. Then return to repeat the algorithm until there is only one attribute in every element of the discernibility matrix. Then the algorithm ends and a reduct is constructed.\nOtherwise, In [4], Zhang and Qiu depart the attributes into three types based on the relationship with attribute reduct which contain core, relative necessary and unnecessary attributes. Many beautiful theorems are given to describe these three type attributes. However, they are all not substantive description for attribute character.\nIn this paper, we propose an attribute subset E(a) with respect to the attribute a. We conclude that whether the attribute a is relative necessary or unnecessary is determined by E(a) virtually. Secondly, refinement and precise-refinement in topology are used to study the properties of attributes. Moreover, combined with the row-wise simplification reduct construction algorithm in [3], we construct a algorithm based on E(a).\nThe remainder of this paper is organized as follows. Some basic concepts in rough set theory are reviewed in Section 2. The three types of attributes are investigated in Section 3, and more substantial descriptions to the three types are given in this section. In Section 4, With the tool of topology, more clear and easier conclusions are given about the three types of attributes.\nBecause of the reduct based on the relationship between the attributes virtually, in section 5, the relationship between the attributes are discussed. In the last of this paper, we give a reduct algorithm based on E(a), and analysis it\u2019s efficiency through an example in [3]."}, {"heading": "2. Preliminaries", "text": "In this section, we review some basic concepts, which includes Pawlak\u2019s rough set, information system, and covering-based rough set. (see [1, 4, 5, 6,"}, {"heading": "16, 25, 27, 28])", "text": ""}, {"heading": "2.1. Pawlak\u2019s rough set", "text": "Rough set theory, proposed by Pawlak , provides a useful approach to deal with dramatic data. In classical Rough set theory, the data is divided into some equivalency classes.\nDefinition 2.1. (Approximation space) Let U be a nonempty and finite set and R be an equivalence relation on U , i.e., R is reflexive, symmetric and transitive. The ordered pair (U,R) is called an approximation space.\nSo in an approximation space (U,R), R generates a partition U/R = {X1, X2, ..., Xm} on U , where X1, X2, ..., Xm are the equivalence classes generated by the equivalence relation R.\nIn rough set, a pair of approximation operators are used to describe the objects. In the following definition, a pair of approximation operators are introduced which are widely used.\nDefinition 2.2. (Approximation operator) Let U be a nonempty and finite set and R be an equivalence relation on U , a pair of approximation operator R\u2217(X) = {x \u2208 U |RN{x} \u2286 X}, R\u2217(X) = {x \u2208 U |RN{x} \u2229 X 6= \u2205}. Where RN(x) = {y \u2208 U |xRy}. They are called the lower and upper approximation operators with respect to R, respectively.\nDefinition 2.3. (R-precise and R-rough set) Let R be an equivalence relation on U . For all X \u2286 U, if R\u2217(X) = R\n\u2217(X), then X is a R\u2212precise set; otherwise, we say X is a R\u2212rough set."}, {"heading": "2.2. Information system", "text": "The notion of information systems is an extension of rough set, and provides a convenient tool for the representation of objects in terms of their attribute values. An information system IS is a pair (U,A), where U is a nonempty finite set of objects called the domain set and A = {a1, a2, ..., an} is a nonempty finite set of attributes such that a : U \u2192 Va for any a \u2208 A, i.e., ax \u2208 Va, x \u2208 U, where Va is called the domain of attribute a.\nEach nonempty subset B \u2286 A in an IS determines an indiscernibility relation as follows: RB = {(x, y) \u2208 U \u2217 U : a(x) = a(y), \u2200a \u2208 B}.\nSince RB is an equivalence relation on U , it forms a partition U/RB = [x]B : x \u2208 U, where [x]B is the equivalence class determined by x with respect to B, i.e., [x]B = {y \u2208 U : (x, y) \u2208 RB}. U/RB reflects the basic granules of knowledge w.r.t. B in the IS.\nDefinition 2.4. (consistent)An information system (U,A), B \u2286 A, B is a consistent set iff U/RB = U/RA.\nDefinition 2.5. (reduct)An information system (U,A), B \u2286 A, B is a reduct iff B is a consistent set and for any C \u2282 B, U/RC 6= U/RA.\nLet we denote a set B can not be reducted iff for all C \u2282 B, U/RC 6= U/RB.\nDefinition 2.6. In an information system (U,A), We divide the the attribute set A into three types as follows:\n(1)(core) For a \u2208 A, a is a core attribute iff for all reduct set B, B \u2286 A, a \u2208 B.\n(2)(unnecessary) An information system (U,A), for a \u2208 A, a is an unnecessary attribute iff for all reduct B, B \u2286 A, but a /\u2208 B.\n(3)(relative necessary) An information system (U,A), for a \u2208 A, a is a relative necessary attribute iff a is not a core attribute and there exists a reduct B, B \u2286 A, and a \u2208 B.\nIn an information system (U,A), we denote (U,Bi), i \u2208 \u03c4 for all the reduct subsets of A, \u03c4 is an index set. So we denote the core attribute set as C = \u2229i\u2208\u03c4Bi, the set of all the relative necessary attributes as RN = \u222ai\u2208\u03c4Bi \u2212 \u2229i\u2208\u03c4Bi, and the set of all the unnecessary attributes as UN = A\u2212 \u222ai\u2208\u03c4Bi.\nEvery attribute can generates an equivalent relation and generates a partition, so in rough set theory, the study of attribute is very important, and discernibility matrix leads an important role to study the feature of attributes.\nDefinition 2.7. (discernibility matrix)An information system (U,A), |U | = n, for x, y \u2208 U , dA(x, y) = {a \u2208 A|Va(x) 6= Va(y)}. we say dA(x, y) is a partition discernibility set of x, y. We denote DA = {dA(x, y)|x, y \u2208 U} for the discernibility matrix of the information system (U,A).\nDefinition 2.8. (discernibility function)The discernibility function of a discernibility matrix is defined by: f(DA) = \u2227 { \u2228 d{x, y}|d{x, y} \u2208 DA, x, y \u2208 U}."}, {"heading": "2.3. Covering-based rough set", "text": "Definition 2.9. Let U be the domain of discourse and C a family of subsets of U . If none of the subsets in C is empty, and \u22c3 C = U , C is called a covering of U .\nSince it is clear that a partition is definitely a covering, the concept of coverings is an extension of the concept of partitions.\nDefinition 2.10. (Covering approximation space). Let U be a non-empty set and C be a covering of U. We call the ordered pair U, C a covering approximation space.\nDefinition 2.11. (Minimal description). Let (U,C) be a covering approximation space. If x \u2208 U , the minimal description of x is defined as Md(x) = {K \u2208 C|x \u2208 K,\u2227(\u2200S \u2208 C \u2227 x \u2208 S \u2286 K \u21d2 K = S)}.\nPaper [1, 16] introduced a new definition for binary relation-based rough sets. The concept for this definition is the neighborhood of a point.In the following we introduce the neighborhood concept into covering-based rough set.\nDefinition 2.12. (Neighborhood) Let U be a domain of objects, C a covering of U . For any x \u2208 U , we define the neighborhood of x as follows: Neighbore(x) = {\u2229K|x \u2208 K \u2208 C}.\nThe concept of Neighbore(x) is proposed to study the covering-based rough set, and let us denote a new concept N(x) that just like the notion of Neighbore(x), but they are different. In an information system (U,A), the partition discernibility sets dA(x, y) in a discernibility matrix are always used, so we denote N(a) = {dA(x, y)|a \u2208 dA(x, y), x, y \u2208 U} for the attribute a.\nIn the following, we will study the covering-based rough set of attribute with Neiborhood(x) and N(x).\nLet (U,C) be a covering approximation space and X \u2286 U .\nDefinition 2.13. (Lower approximation) The covering lower approximation operation R\u2217 : P (U) \u21d2 P (U) is defined as R\u2217(X) = \u22c3 K\u2208C\u2227K\u2286X K[28].\nDefinition 2.14. (Upper approximation) Let C be a covering of the domain U . The covering upper approximation operation R\u2217, is defined as: X \u2286 U,R\u2217(X) = \u22c3 K\u2208C\u2227K\u2229X 6=\u2205K.\nProposition 2.1. Let C be a covering of U , the followings are equal. (1) {x} \u2208 C. (2) Md(x) = {{x}}. (3) R\u2217(x) = {x}. (4) Md(x) = {R\u2217(x)}.\nProof. (1) \u21d4 (2) \u21d4 (3)) is easy to proof. So we only proof (1) \u21d4 (4). (4) \u21d2 (1): since C be a covering of U , then there exists x \u2208 K \u2208 C, thus Md(x) 6= \u2205, and Md(x) = {R\u2217(x)}, so R\u2217(x) 6= \u2205, thus R\u2217(x) = {x}, so {x} \u2208 C. (1) \u21d2 (4): if {x} \u2208 C, then R\u2217(x) = {x}, then Md(x) = {R\u2217(x)}."}, {"heading": "3. The analysis of attribute characters in information system", "text": "An information system (U,A), |U | = n, for x, y \u2208 U , dA(x, y) = {a \u2208 A|Va(x) 6= Va(y)}. the discernibility matrix of the information system (U,A) is DA = {dA(x, y)|x, y \u2208 U}. Let the covering C = {dA(x, y)}, for all x, y \u2208 U , then C is a covering of A. We denote CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute.\nOtherwise, forB \u2286 A, we denoteR\u2217(B) = {d(x, y)|d(x, y) \u2208 DA, d(x, y) \u2286 B}, R\u2217(B) = {d(x, y)|d(x, y) \u2208 DA, d(x, y) \u2229 B 6= \u2205}. So R\u2217 and R\n\u2217 in attribute covering are corresponding to those concepts in classic rough set.\nTheorem 3.1. An information system (U,A), B \u2286 A, B is a consistent set iff \u2200x, y \u2208 U, dA(x, y) 6= \u2205, then B \u2229 dA(x, y) 6= \u2205.\nproof. Sufficiency. We need to proof U/RB = U/RA. Because [x]B = {y \u2208 U : (x, y) \u2208 RB}, if B \u2229 dA(x, y) 6= \u2205, then for y \u2208 [x]A, then for any a \u2208 A, y \u2208 [x]a, and B \u2286 A, then y \u2208 [x]B . For y /\u2208 [x]A, there exists a \u2208 A, y /\u2208 [x]a, then a \u2208 dA(x, y), and B \u2229 dA(x, y) 6= \u2205, then there exists b \u2208 B, y /\u2208 [x]b, then y /\u2208 [x]B. So U/RB = U/RA.\nNecessity. If (U,B) is a consistent information system, then U/RB = U/RA. For y /\u2208 [x]A, then For y /\u2208 [x]B , there exists b \u2208 B, y /\u2208 [x]b, then b \u2208 dA(x, y), then B \u2229 dA(x, y) 6= \u2205.\nTheorem 3.2. An information system (U,A),B \u2286 A, B is a reduct iff \u2200x, y \u2208 U, dA(x, y) 6= \u2205, then B \u2229 dA(x, y) 6= \u2205, and for any a \u2208 B, B \u2212 {a} does not holds.\nProof.It is obvious from Theorem 3.1.\nCorollary 3.1. An information system (U,A), B \u2286 A, B is a reduct set iff \u2200a \u2208 A, \u2200K \u2208 N{a} \u2208 U , then B \u2229K 6= \u2205.\nProof.It is obvious from Theorem 3.1.\nCorollary 3.2. An information system (U,A), B \u2286 A, B is a reduct set, if for a \u2208 A, for every K \u2208 N(a), (B \u2212 {a}) \u2229K 6= \u2205, then a /\u2208 B.\nProof.If for every K \u2208 N(a), (B \u2212 {a}) \u2229 K 6= \u2205, then RB\u2212{a} = RB, then B can be reducted.\nIf {a} is an element of CD, we assume dA(x, y) = {a}. then y \u2208 [x](A\u2212 {a}), and y /\u2208 [x]A. then U/R(A\u2212{a}) 6= U/RA, so for any reduction (U,B),B * (A\u2212 {a}), so a \u2208 B.\nIf a \u2208 A is a core attribute, then for any reduction (U,B), a \u2208 B. If {a} is an element of CD, then for x, y, if a \u2208 dA(x, y), then there is another element b \u2208 A, b \u2208 dA(x, y), then we can proof there is a reduct set C, b \u2208 C, and a /\u2208 C.\nCorollary 3.3. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a core attribute iff Md(x) = {{x}}.\nCorollary 3.4. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a core attribute iff R\u2217(x) = {x}.\nCorollary 3.5. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a core attribute iff Md(x) = {R\u2217(x)}.\nTheorem 3.3. [6] In an information system (U,A), attribute a \u2208 A is a core iff there exists some d{x, y}, x, y \u2208 U , d{x, y} \u2208 DA, such that d{x, y} = {a} iff RA\u2212{a} 6= RA.\nTheorem 3.4. [4] In an information system (U,A), we have the conclusions as follows: (1) a \u2208 A is a relative necessary attribute iff RA\u2212{a} = RA, and \u222a{RB\u2212{a} * Ra ,where RB \u2286 RA, B \u2286 A}. (2) a \u2208 A is a unnecessary attribute iff \u222a{RB\u2212{a}} \u2286 Ra, where RB \u2286 RA, B \u2286 A.\nTheorem 3.4 describes the character of attributes, but it\u2019s just a kind of representation in definition, and lack of real substance in some degree. What the theorem wants to express is as follows:\n(a) RA\u2212{a} = RA \u21d4 when deleting a from A, the partition doesn\u2019t change \u21d4 a is not a core.\n(b) RB \u2286 RA\u21d4B is a consistent set of A. (c) \u222aRB\u2212{a} * Ra, where RB \u2286 RA \u21d4 there exists a set B0, satisfies RB0\u2212{a} * Ra, where RB0 \u2286 RA} \u21d4there exists a reduct B0 satisfies RB0\u2212{a} * Ra\u21d4 a \u2208 B0\u21d4a belongs to some reduct.\n(d) RA\u2212{a} = RA, \u222aRB\u2212{a} * Ra, where RB \u2286 RA\u21d4 a is not a core, and a belongs to some reduct\u21d4a is a relative necessary attribute.\n(e) \u222a{RB\u2212{a}} \u2286 Ra, where RB \u2286 RA, B \u2286 A\u21d4 for every reduct B, the partition generated by a is coarser than B \u2212 {a}\u21d4 for every reduct B, a /\u2208 B\u21d4a is a unnecessary attribute.\nFrom the explanation above, we can see that the therom 4.2 doesn\u2019t give more essential information. For example, In Theorem 3.4(2), it means for all reduct B, when deleting a from B, the partition doesn\u2019t become finer, then a is unnecessary. In the following, we will give some equivalence conditions to describe the feature of attributes with more substantial meaning and value.\nWe denote E(a) = {d{x, y}|a /\u2208 d{x, y} \u2286 \u222aN(a), d{x, y} \u2208 DA}. We conclude that which type of attribute a belongs to is determined by the relation between N(a) and E(a).\nLemma 3.1. \u222aE(a) = R\u2217(\u222aN(a) \u2212 {a}), and E(a) = {d{x, y}|d{x, y} \u2286 (\u222aN(a)\u2212 {a}), d{x, y} \u2208 DA}.\nProof. It\u2019s obvious.\nTheorem 3.5. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a unnecessary attribute iff for any set C \u2286 A, RC \u2286 R\u222aE(a),\u21d2RC \u2286 Ra.\nProof. Sufficiency. R\u2217{\u222aN(a) \u2212 {a}} = \u222a{M \u2208 CD,M \u2286 N(a) \u2212 {a}}, R\u2217C = \u222a{N \u2208 CD, N \u2229 C 6= \u2205}.\nFor C \u2286 \u222aE(a), RC \u2286 R\u222aE(a)/, RC \u2286 R\u222aE(a)/ \u21d2 C \u2229 {M \u2208 CD,M \u2286 N(a)\u2212 {a}} 6= \u2205, then for any reduct B, there exists C \u2286 \u222a{M \u2208 CD,M \u2286 N(a) \u2212 {a}}, C \u2286 B, C \u2229 {M \u2208 CD,M \u2286 N(a) \u2212 {a}} 6= \u2205. If C \u2229 {M \u2208 CD,M \u2286 N(a)} 6= \u2205, then B \u2229 {M \u2208 CD,M \u2286 N(a)} 6= \u2205. Then a /\u2208 B.\nNecessity. If a \u2208 A is a unnecessary attribute, then for any reduction (U,B), a /\u2208 B, because \u2200K \u2208 N{a}, B \u2229 K 6= \u2205, there exists C \u2286 \u222a{M \u2208 CD,M \u2286 N(a)\u2212{a}}, C \u2286 B, if there is a setK \u2208 N{a}, C\u2229K = \u2205, and we can proof B \u2229K = C \u2229K, then B \u2229K = \u2205, then a \u2208 B.Because a is a unnecessary attribute, then it\u2019s a contradiction.\nTheorem 3.6. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a unnecessary attribute iff for any K \u2208 E(a), and any C \u2286 A, satisfying C\u2229K 6= \u2205, then for any F \u2208 N(a), satisfying C\u2229F 6= \u2205.\nProof. Sufficiency. Because for reduct B, for any set K \u2208 E(a), satisfies B\u2229K 6= \u2205, let C = B\u2229\u222aK,K \u2208 E(a), then for any F \u2208 N(a), C\u2229K 6= \u2205, then B \u2229 F 6= \u2205, then A /\u2208 B.\nNecessity. If there exists a set C, C \u2286 A, for any setK \u2208 E(a), C\u2229K 6= \u2205, but there exists a set F0, F0 \u2208 N(a), C \u2229 F0 = \u2205. When constructing any\nreduct B, we must pick the attributes in all the d{x, y}, d{x, y} \u2208 DA. Assuming we have pick an attribute set C in every F , F \u2208 E(a).\nBecause there exists a set F0, F0 \u2208 N(a), C \u2229F0 = \u2205, so secondly we can pick a. Then the remaining d{x, y} that we have not choose attribute satisfies does\u2019t containing a, and does\u2019t contained in any attribute set in N(a). Then we can pick the attribute in the remaining d{x, y} but outside F0. Then a \u2208 B. It contradicts with the condition of a is a unnecessary attribute.\nTheorem 3.7. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a relative necessary attribute iff {a} is not an element of CD, and there exist a set C \u2286 A, RC \u2286 R\u222aE(a), and RC * Ra.\nProof. Sufficiency. {a} is not an element of CD, then a is not a core attribute.\nIf there exists a set C \u2286 \u222aE(a), RC \u2286 R\u222aE(a), and RC * Ra, then for M \u2208 CD,M \u2208 E(a), C \u2229M 6= \u2205. Let us assum C can not be reducted, because RC * Ra, then there is K \u2208 N(a), satisfies C \u2229K = \u2205, so we can pick a, satisfies ({a} \u222a C \u2286 B, where B is some reduct set. Then a is a relative necessary attribute.\nNecessity. If a \u2208 A is a relative necessary attribute, then {a} is not an element of CD, Then there exist a reduct B \u2286 A, a \u2208 B, and B \u2229M 6= \u2205, where M \u2208 E(a). Let C = B \u2229 \u222aE(a). Then we can proof C \u2286 \u222aE(a), and for M \u2208 CD,M \u2208 E(a), C \u2229M 6= \u2205, then RC \u2286 R\u222aE(a).\nIf RC \u2286 Ra, then for M \u2208 CD,M \u2208 N(a), C \u2229 M 6= \u2205, then for the ruduct B, a /\u2208 B. It contradicts with the condition of a is a relative necessary attribute.\nCorollary 3.6. CD = {dA(x, y), x, y \u2208 U} the covering-based rough sets of attribute, a \u2208 A is a relative necessary attribute iff x is not an element of CD, and there exists C \u2286 A, and F \u2208 N(a), for any set K \u2208 E(a), and C \u2229 K 6= \u2205, but C \u2229K = \u2205.\nProof. From the proof of Theorem 3.7, it holds. In the theorems above, we want to say that attribute a is unnecessary, if and only if for any attribute set C, if the partition it induces is finer than E(a), then it must be finer than a. And for the core and relative necessary attribute, it doesn\u2019t hold."}, {"heading": "4. Attribute characters in topology", "text": "An information system (U,A), |U | = n, for x, y \u2208 U , dA(x, y) = {a \u2208 A|Va(x) 6= Va(y)}. The discernibility matrix of the information system (U,A) is DA = {dA(x, y)|x, y \u2208 U}. So DA is the power set of A whose elements are all the discernibility set.\nIn topology, the concept of refinement are important. It\u2019s widely studied in compact set, pre-compact set, and so on. Precise-refinement is an extension of refinement in topology.In the following, we will study the properties of attribute form Precise-refinement and refinement.\nDefinition 4.1. For two class of power set A and B of X, A,B \u2208 2X , we call A precise-refines B iff for any KA \u2208 A, KA \u2286 KB, for some KB \u2208 B, and for any KB \u2208 B there exists some KA \u2208 A, such that KA \u2286 KB[7].\nDefinition 4.2. For two class of power set A and B of X, A,B \u2208 2X , we call A is a refinement of B iff for any KB \u2208 B, there exists some KA \u2208 A, such that KA \u2286 KB.\nTheorem 4.1. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a unnecessary attribute iff there exists M \u2286 DA, M \u2229 N(a) = \u2205, and M precise-refines N(a).\nProof. Sufficiency. If there exists M \u2286 DA, M \u2229 N(a) = \u2205, and M precise-refines N(a), then for any reduct set B, and for \u2200d{x, y} \u2208 M , B \u2229 d{x, y} 6= \u2205, because M refines N(a), for \u2200K \u2208 N(a), there exists d{x, y} \u2208 M , satisfies d{x, y} \u2286 K, then (B\u2212{a})\u2229K 6= \u2205, then a /\u2208 B.\nNecessity. If there doesn\u2019t exist M \u2286 DA,which satisfies M \u2229 N(a) = \u2205, and M precise-refines N(a), then there exist some K \u2208 N(a), satisfies d{x, y} * K where d{x, y} \u2208 DA, and a /\u2208 d{x, y}. So for any d{x, y} \u2208 DA, a /\u2208 d{x, y}, d{x, y} \u2212K 6= \u2205. Let we assume K = d{x\n\u2032, y\u2032}, for some x\u2032, y\u2032 \u2208 U . Because K \u2229 (A \u2212K) = \u2205, so (x\u2032, y\u2032) \u2208 IND(A \u2212K), so we can proof {a} \u2229RED(A\u2212K) is a reduct of A.\nCorollary 4.1. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a unnecessary attribute iff there exists M \u2286 E(a), and M precise-refines N(a).\nProof. From Theorem 4.1, if M \u2286 DA, M \u2229 N(a) = \u2205, and M preciserefines N(a), then M \u2286 E(a), then it\u2019s easy to proof.\nTheorem 4.2. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a unnecessary attribute iff E(a) is a refinement of N(a).\nProof. It holds from the proof of Corollary 4.1. .\nTheorem 4.3. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a relative necessary attribute iff a /\u2208 D(A), and there doen\u2019t exist a set M ,which satisfies M \u2286 E(a), and M precise-refines N(a).\nProof. It\u2019s obvious from Corollary 4.2.\nTheorem 4.4. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a relative necessary attribute iff E(a) is not finer than N(a), and {a} /\u2208 DA.\nCorollary 4.2. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a relative necessary attribute iff {a} /\u2208 DA, and for any a /\u2208 d{x, y} \u2208 DA, there exists some K \u2208 N(a), satisfies d{x, y} * K.\nProof. It can be concluded by the proof of Theorem 4.1.\nExample 4.1. An information system (U,A), the domain set U = {1, 2, 3, 4, 5}, the attribute set A = {a1, a2, a3, a4}. For simplicity, we give the partitions by every attribute directly.\nSa1 = {{1, 2}, {3, 4}, {5}}, Sa2 = {{1, 2, 3}, {4, 5}}, Sa3 = {{1, 2, 4}, {3, 5}}, Sa4 = {{1, 2, 3, 4}, {5}}.\nThe discernibility matrix is: U \u00d7 U 1 2 3 4 5\n1 \u2205 \u2205 {a1, a3} {a1, a2} {a1, a2, a3, a4} 2 \u2205 {a1, a3} {a1, a2} {a1, a2, a3, a4} 3 \u2205 {a2, a3} {a1, a2, a4} 4 \u2205 {a1, a3, a4} 5 \u2205\nAll the reducts are {a1, a2}, {a1, a3}, {a2, a3}. a1, a2, a3 are the relative attributes, a4 is the unnecessary attribute,and there are no core attributes.\nLet we see the relation between E(a) and N(a) for every attribute a \u2208 A.\n(1) N(a1) = {a1, a2}, {a1, a3}, {a1, a2, a4}, {a1, a3, a4}, {a1, a2, a3, a4}, E(a1) = {a2, a3}.\nBecause {a1} /\u2208 N(a), E(a1) is a refinement of N(a1), or there doesn\u2019t exist subset M \u2286 E(a1), such that M precise-refines N(a1), then a1 is a relative necessary attribute.\n(2)The situation of a2, a3 is just the same as a1. (3) N(a4) = {{a1, a2, a4}, {a1, a3, a4}, {a1, a2, a3, a4},\nE(a4) = {a1, a2}, {a1, a3}, {a2, a3} . Because E(a4) is a refinement of N(a4), or E(a4) precise-refines N(a4),\nthen a4 is a unnecessary attribute.\nIn the following, we give one more convenient method to judge the feature of attributes.\nFor the discernibility matrix DA of the information system (U,A), we call d{x, y} \u2208 DA a reducible element if there exist another d{x\n\u2032, y\u2032} \u2208 DA, satisfies d{x\u2032, y\u2032} \u2282 d{x, y}.\nWe can delete all the reducible elements, and all the reduct of A remain unchanged. So we denote Dreducible as the subset of DA whose elements are all the reducible elements of DA, and denote Dreduct = DA \u2212Dreducible.\nTheorem 4.5. For the discernibility matrix DA of the information system (U,A), a \u2208 A, a is a relative necessary attribute iff a \u2208 (\u222aDreduct),and {a} /\u2208 Dreduct.\nProof. Sufficiency. For K \u2208 DA, if there exists another K \u2032 \u2282 K, then for any reduct B, B \u2229K \u2032 6= \u2205, then B \u2229K 6= \u2205, so we can delete K when constructing any reduct.\nFor any a \u2208 (\u222aDreduct), then a \u2208 K, for some K \u2208 Dreduct, then for any other K \u2032 \u2208 Dreduct, satisfies K\n\u2032 * K. Then we can proof {a}\u2229RED(A\u2212K) is a reduct of A. Besides a is not core, then a is a relative necessary attribute.\nNecessity. If a /\u2208 \u222aDreduct, then N(a) \u2229 Dreduct = \u2205, then there exists M \u2286 DA, And M \u2229 N(a) = \u2205, satisfies M a refinement of N(a), then a is unnecessary. Then from Therom4.1, it holds.\nTheorem 4.6. For the discernibility matrix DA of the information system (U,A), a \u2208 A is a unnecessary attribute iff a \u2208 (A\u2212 \u222aDreduct).\nProof. It holds from Theorem 4.5.\nTheorem 4.7. For the discernibility matrix DA of the information system (U,A), for any d{x, y} \u2208 Dreduct, and \u2200a \u2208 d{x, y}, (d{x, y}\u2212{a}) 6= \u2205, there always exists a reduct B \u2286 A, satisfies {d{x, y} \u2212 {a}} \u2229 B = \u2205.\nProof. It holds from the proof of Theorem 4.5.\nExample 4.2. In Example 4.1, because {a1, a2} \u2282 {a1, a2, a4}, {a1, a3} \u2282 {a1, a3, a4}, {a1, a3} \u2282 {a1, a2, a3, a4}, otherwise there are not proper subsets for {a1, a2}, {a1, a3}, {a2, a3} in DA.\nThen Dreducible = {a1, a2, a4}, {a1, a3, a4}, {a1, a2, a3, a4}, and Dreduct = {a1, a2}, {a1, a3}, {a2, a3}.\nThen \u222aDreduct = {a1, a2, a3}, A\u2212 \u222aDreduct = {a4}. Because all the unnecessary attributes belong to A \u2212 \u222aDreduct ,all the relative and the core attributes belong to \u222aDreduct ,otherwise, a1 /\u2208 DA, a2 /\u2208 DA, a3 /\u2208 DA, then we can conclude the unnecessary attribute is a4, the relative attributes are a1, a2, a3."}, {"heading": "5. The relationship among attributes", "text": "Attribute reduct is based on the relationship between attributes, in essence. In this section, we will give the relationship between attributes and the attribute set. That may be useful for constructing a reduct.\nLet us give some kinds of marks for the relationship of two attributes in the following statements, and that is valid for two attribute sets.\nDefinition 5.1. In An information system (U,A), for two attributes a, b, we denote A < B, iff RA \u2286 RB, and that means the partition that generated by A is finer than by B. So we denote A \u2248 B, if RA = RB, and that means they generate the same partition of U .\nDefinition 5.2. In An information system (U,A), for two attributes a, b, let we denote a \u22b2\u22b3 b, iff for every reduct B, a \u2208 B \u21d4 b \u2208 B.\nDefinition 5.3. In An information system (U,A), for attributes a and attribute set C, we denote C \u22b2 a, iff for any reduct B, C \u2286 B \u21d2 a /\u2208 B. That means if we pick C when constructing a reduct, then a needn\u2019t be considered.\nSo from the definitions above, we can say that the propositions of a \u22b2\u22b3 b with A\u22b2B, or B \u22b2A can\u2019t hold simultaneously.\nTheorem 5.1. In An information system (U,A), for two attributes a, b, A < B, iff \u2200K \u2208 N(b), a \u2208 K, and iff a \u2208 Neibor(b). A \u2248 B iff N(a) = N(b), and iff a \u2208 Neibor(b), b \u2208 Neibor(a).\nProof. a < b \u21d4 Ra \u2286 Rb \u21d4 \u2200K \u2208 N(b),then a \u2208 K.\nTheorem 5.2. In An information system (U,A), for two attributes a, b, a \u22b2\u22b3 b, iff for any C \u2286 A, RC \u2286 Rb( RC \u2286 Ra), then RC \u2286 Ra( RC \u2286 Rb).\nProof. Sufficiency. If there exists a reduct B,satisfies a \u2208 B,and b /\u2208 B, then RB \u2286 Rb, and RB * Ra.\nNecessity. Assume there exists a set C, C \u2286 A,and RC \u2286 Rb, but RC * Ra. If there is a reduct B,satisfies a \u2208 B,then we can pick some C, C \u2286 A,and RC \u2286 Rb, RC * Ra,and C \u222a {a} belongs to some reduct.\nTheorem 5.3. In An information system (U,A), for two attributes a, b, a \u22b2\u22b3 b, iff for C \u2286 A,and R(C\u222a{a}) \u2286 Rb ( R(C\u222a{b}) \u2286 Ra ), then RC \u2286 Ra ( RC \u2286 Rb).\nProof. Sufficiency. If there exists a reduct B, satisfies a \u2208 B, and b /\u2208 B, then RB \u2286 Rb, and RB * Ra. Let C = B \u2212 {a}, then R(C\u222a{a}) \u2286 Rb, but RC * Ra.\nNecessity. Assume there exists a set C, C \u2286 A, and R(C\u222a{a}) \u2286 Rb, but RC * Ra. If there is a reduct B, satisfies a \u2208 B, then we can pick some C, C \u2286 A,and R(C\u222a{a}) \u2286 Rb, RC * Ra, and C \u222a{a} belongs to some reduct.\nIntuitively speaking, Theorem 4.4 means if for a reduct B, a \u2208 B \u21d2 b \u2208 B, then for any set C, if the partition that generated by C \u222a {a} is finer than b, then C \u222a {a} can\u2019t belongs to some reduct.\nCorollary 5.1. In An information system (U,A), for two attributes a, b, a \u22b2\u22b3 b, iff for \u2200K \u2208 (N(b) \u2212 N(a)) ( \u2200K \u2208 (N(a) \u2212 N(b))), C \u2286 A,and C \u2229K 6= \u2205, then for \u2200K \u2208 (N(a) (\u2200K \u2208 (N(b)) C \u2229K 6= \u2205.\nProof. For \u2200K \u2208 (N(b)\u2212N(a)), C \u2229K 6= \u2205 \u21d4 R(C\u222a{a}) \u2286 Rb. For \u2200K \u2208 N(a) , C \u2229K 6= \u2205\u21d4 RC \u2286 Ra. Then from Theorem 5.3, it concludes.\nFor a attribute set C and an attribute a, we have C a \u21d2 C \u22b2 a, but C \u22b2 a ; C a. In the following, an example is given to illustrate this.\nExample 5.1. Let U = {1, 2, 3, 4, 5}, A = {a1, a2, a3} is a family of equivalence relations, and the partitions they generate are as follows.\nRa1 = {{1, 2, 3}, {4, 5}}, Ra2 = {{1, 2}, {3, 4, 5}}, Ra3 = {{1, 3}, {2, 4, 5}}.\nThe discernibility matrix is:\nU \u00d7 U 1 2 3 4 5 1 \u2205 {a3} {a2, a3} {a1, a2, a3} {a2, a3} 2 \u2205 {a2, a3} {a1, a2} {a1, a2} 3 \u2205 {a1, a3} {a1, a3} 4 \u2205 \u2205 5 \u2205\nThen N(a1) = {{a1, a2}, {a1, a3}, {a1, a2, a3}}, E(a1) = {{a3}, {a2, a3}}. All the reducts are {a1, a3} and {a2, a3}, so for any reduct B, if a2 \u2208 B, then a1 /\u2208 B, so let C = {a2}, then C\u22b2a1, but the partition that generated by C is not finer than a1.\nThe next we give an equivalent conditions for C \u22b2 a.\nTheorem 5.4. In An information system (U,A, V ), for attribute a, and attribute set C, C \u22b2 a, iff any attribute set D, for \u2200K \u2208 {E(a) \u2212 N(C)}, satisfies D \u2229K 6= \u2205,then RC\u222aD \u2286 Ra,where N(C) = {d(x, y)|d(x, y) \u2229 C 6= \u2205, d(x, y) \u2208 DA}.\nProof. Sufficiency. For any reduct B, then for \u2200K \u2208 {E(a) \u2212 N(C)}, satisfies B \u2229 K 6= \u2205. If C \u2286 B, then for \u2200K \u2208 E(a), satisfies B \u2229 K 6= \u2205, then RB \u2286 Ra, then a /\u2208 B. Necessity. If there exists an attribute set D, for \u2200K \u2208 {E(a) \u2212 N(C)}, satisfies D \u2229 K 6= \u2205, then for \u2200K \u2208 E(a), satisfies (C \u222aD) \u2229K 6= \u2205, but RC\u222aD * Ra, that means to say there exists a K0 \u2208 N(a) , (C \u222aD) \u2229K0 = \u2205.\nIf C is contained in some reduct, then by Theorem 4.5, we can construct a reduct B, satisfies (C \u222a {a} \u222a RED(D)) \u2286 B, then a \u2208 B.It contradicts with the condition of C \u22b2 a.\n6. A kind of attribute reduct algorithm based on E(a)\nIn [3], Yao proposed a row-wise simplification reduct construction algorithm. His thought is described as follows:\nIt is based on the discernibility matrix M whose element in i\u2212th row, j\u2212 th column is M(i, j). For an non-empty M(x, y), it \u2019s simplified into three steps. First, absorb M(i, j) by all the elements in M ,so there are not proper subset of M(i, j) in M . Secondly, select an attribute a in M(i, j) for constructing a reduct, and absorb elements in M by {a}.Thirdly,for all M(x, y) 6= \u2205,M(x, y) \u2208 M , let M(x, y) = M(x, y)\u2212M(i, j). Then back to the first step to continue. In the end, a reduct is constructed. The row-wise simplification reduct construction algorithm proposed by Yao in [3] is recalled in the following: Input:The discernibility matrix M of an information table S. Output: A reduct R. for i = 2 to n do { for j = 1 to i\u2212 1{ if M(i, j) 6= \u2205{ //Absorb M(i, j) by every non-empty element in M for every non-empty element element M(x\u2032, y\u2032) \u2208 M do if M(x\u2032, y\u2032) \u2286 M(i, j) then M(i, j) = M(x\u2032, y\u2032).\n//Divide M(i, j) into two parts select an attribute a from M(i, j); A = M(i, j)\u2212 {a}; M(i, j) = {a};\n//simplify every non-empty element in M for every non-empty element M(x\u2032, y\u2032) \u2208 M do if a \u2208 M(x\u2032, y\u2032) then M(x\u2032, y\u2032) = {a} ; else M(x\u2032, y\u2032) = M(x\u2032, y\u2032)\u2212M(i, j) ; }// end if }// end for loop of j }// end for loop of i\nIn the section above, we point out that E(a) can decide the attribute a whether or not belongs to some reduct, so we construct a algorithm with the use of E(a) and the row-wise simplification reduct construction algorithm. The detailed algorithm is given in the following.\nIn the following,we denote a reduct set REDE(a) with respect to E(a) iff\nREDE(a) \u2286 \u222aE(a), and for any K \u2208 E(a), REDE(a) \u2229K 6= \u2205, and for any proper subset of REDE(a), that\u2019s not true.\nA algorithm with respect to E(a): Input: The set CD of subsets of attributes transformed from the dis-\ncernibility matrix DA; //Let CD = {C(i); 1 6 i 6 N}, where N represents the number of nonempty-set elements in the discernibility matrix DA; so N 6 (n2 \u2212 n)/2, n is the cardinal of the object set U . Output: A reduct R. first let R = \u2205 while ( C 6= \u2205 ) first step: select an attribute a, a \u2208 C(1) ; compute N(a), E(a); second step: compute a reduct respect to E(a) with the row-wise simplification reduct construction algorithm in [3]; we denote the reduct with respect toE(a) asREDE(a); let R = R \u222aREDE(a); third step: if there exists a K \u2208 N(a),such that REDE(a) \u2229K = \u2205; then let R = R \u2229 {a}; else continue; forth step: for every C(i\u2032) \u2208 C, let C(i\u2032) = C(i\u2032)\u2212 \u222aN(a); //because E(a) \u2286 \u222aN(a), thus C(i\u2032)\u2212 \u222aN(a) = C(i\u2032)\u2212 \u222aN(a) \u2212 \u222aE(a) if C = \u2205; {Output R; // R is a reduct End.} else return; //goto the first step } } In the second step, we can also return to the first step to compute a reduct with respect to E(a), and so the absorption operation needn\u2019t be used. We don\u2019t give more description because of the limitation of length.\nTheorem 6.1. The algorithm respect to E(a) can construct a reduct of A.\nProof. In the second step of the algorithm, we can pick a reduct respect to E(a).\nAfter the third step, we can pick a reduct with respect to E(a) \u222aN(a).\nIn the forth step,for C(i\u2032) \u2208 C, if C(i\u2032) /\u2208 E(a) \u222a N(a), then C(i\u2032) \u2212 \u222aN(a) 6= \u2205.\nFrom the method of induction, in the following of the operations of the algorithm, we will construct a reduct respect to C \u2212E(a)\u2212N(a).\nBecause after the forth step, for any C(i\u2032) \u2208 C, C(i\u2032) 6= \u2205, and for anyK \u2208 N(a), orK \u2208 E(a), such that C(i\u2032)\u2229K = \u2205, thus the union of the reduct with respect to E(a)\u222aN(a) and the reduct with respect to A\u2212\u222aE(a)\u2212\u222aN(a) is also a reduct.\nThen it\u2019s easy to proof that\u2019s a reduct of A.\nIn [3], Yao used an example to inspect the row-wise simplification reduct construction algorithm, now we will quote this example in [3] to exam the algorithm with respect to E(a).\nExample 6.1. The discernibility matrix is: U \u00d7 U 1 2 3 4 5 6\n1 \u2205 \u2205 \u2205 {a, b, f} {a, c} {a, d} 2 \u2205 \u2205 {c, d, f} {b, d} {b, c} 3 \u2205 {b, e, f} {c, e} {d, e} 4 \u2205 \u2205 \u2205 5 \u2205 \u2205 6 \u2205\nThe steps that we use the algorithm are as follows: The set CD of subsets of attributes transformed from the discernibility\nmatrix DA is CD = {{a, b, f}, {a, c}, {a, d}, {c, d, f}, {b, d}, {b, c}, {b, e, f}, {c, e}, {d, e}}.\nfirst step: select the attribute a, a \u2208 C(1) ; compute E(a) = {{c, d, f}, {b, d}, {b, c}}, N(a) = {{a, b, f}, {a, c}, {a, d}}.\nsecond step: compute a reduct respect to E(a) with the row-wise simplification reduct construction algorithm in[3]; then REDE(a) = {c, b}. Then R = REDE(a).\nthird step: because for {a, d} \u2208 N(a),such that REDE(a) \u2229 {a, d} = \u2205,\nthen R = REDE(a) \u2229 {a} = {a, b, c}; forth step: for every C(i\u2032) \u2208 C , let C(i\u2032) = C(i\u2032)\u2212 \u222aN(a). Then CD = {{e}}. Then R = REDE(a) \u222a {e}; then R = {a, b, c, e}.\nComplexity analysis of algorithms: All the elements need the absorption operation in he row-wise simplification reduct construction algorithm, and the time that each absorption operation cost is about 0(n2), so that\u2019s a complex operation. In the algorithm based on E(a), the absorption operation is performed only in E(a), but not in all the elements of the discernibility matrix. Otherwise, in the forth step,we let C(i\u2032) = C(i\u2032)\u2212\u222aN(a),for every C(i\u2032) \u2208 C , so we can delete more attributes in the matrix, and remain the elements of the discernibility matrix with fewer attributes, So that may be more simple when constructing a reduct.\nThe thought of using E(a) in this algorithm is useful for attribute reduct. Because when we construct the reduct of E(a), then a must or can\u2019t select is determined. In the next, we can delete the union of E(a) ,then the attribute set with fewer elements remained that is more simple.\nLet we study the complexity of the row-wise simplification reduct construction algorithm for Example 6.1 which is first used by Yao in [3].The algorithm traverses the discernibility matrix DA three times, and every time, the algorithm experienced the operations which contain absorption,partition for some attribute set,and inspection. So the total of times for the algorithm which used in Example 6.1 is about 36 \u2217 3 \u2217 3, where 36 is the number of the elements in the discernibility matrix DA.\nIn the algorithm based on E(a), the operations we experienced included computing E(a) and N(a), computing a reduct respect to E(a) with the rowwise simplification reduct construction algorithm, comparing REDE(a) with N(a), and for every C(i\u2032) \u2208 C, computing C(i\u2032) = C(i\u2032) \u2212 \u222aN(a). So the total of times for this algorithm is about 9 \u2217 4 where 9 is the number of elements in CD in Example 6.1.\nIn the algorithm based on E(a), we only use the row-wise simplification reduct construction algorithm for E(a), and after we pick the reduct of E(a) and N(a),we will delete all the attribute in \u222aN(a), then less attributes are left. The time complexity for the worst is about 0(n2 \u2217 ln3n),\nSo this algorithm maybe more efficient when constructing a reduct for some cases."}, {"heading": "7. Conclusion", "text": "Attribute reduct is a NP-hard problem, many methods are proposed to to find all the reducts or a single reduct, but there haven\u2019t the optimal solutions for it, so it\u2019s still a problem worth of intensive researching. In some degree, constructing a reduct is based on the relationship between attributes. In this paper, we give the substantive conclusions of attribute character in terms of the relationship among attributes. We point out that the attribute is whether unnecessary or relative necessary is determined by the relationship between E(a) and N(a) in virtual, and whether unnecessary or relative necessary with respect to some reduct is determined by the relationship of this reduct, E(a) and N(a).\nFurthermore, we give some easy and clear description of the attribute features in topology. Besides, some relationships between attributes are given and that is helpful for constructing reducts. Finally, a method of attribute reduct is given based on E(a). This kind of thought is maybe useful for the further study of attribute reduct in rough set theory."}, {"heading": "Acknowledgement", "text": "The authors would like to thank the anonymous reviews for their constructive comments. This work is supported by grants from National Natural Science Foundation of China under Grant (Nos. 71140004, 10971186)."}, {"heading": "5 (2011) 689-69.", "text": "[12] W. Wu, Attribute reduction based on evidence theory in incomplete decision systems, Information sciences 178 (2008) 1355-1371. [13] Y. Yao, Constructive and algebra methods of theory of rough sets, Information sciences 109 (1998) 21-47. [14] L. Feng, T. Li, D. Ruan, S. Gou, A vague-rough set approach for uncertain knowledge acquisition Original Research Article, Knowledge-Based Systems 6 (2011) 837C843. [15] Y. Yao, Y. Zhao, Attribute Reduction in decision-theoretic rough set models, Information sciences 178 (2008) 3356-3373. [16] J. Wang, J. Wang, Reduction algorithms based on discernibility matrix: the ordered attributes method, Journal of Computer Science and Technology 16 (2001) 489-504. [17] K. Zhao, J. Wang, A reduction algorithm meeting users\u2019 requirements, Journal of Computer Science and Technology 17 (2002) 578-593. [18] Y. Yao, Y. Zhao, J. Wang, S. Han, A model of machine learning based on user preference of attributes, Proceedings of International Conference on Rough Sets and Current Trends in Computing, 2006, pp. 587-596. [19] W. Zhang, J. Mi, W. Wu, Approaches to knowledge reductions in inconsistent systems, International Journal of Intelligent Systems 18 (2003) 989-1000. [20] Z. Pawlak, A. Skowron, Rough sets and boolean reasoning, Information Sciences 177 (2007) 41-73.\n[21] D. Chen, C. Zhang, Q. Hu, A new approach to attribute reduction of consistent and inconsistent covering decision systems with covering rough sets, Information Sciences 177 (2007) 3500-3518. [22] D. S\u0301lezak, W. Ziarko, The investigation of the Bayesian rough set model, International Journal of Approximate Reasoning 40 (2005) 81-91. [23] Y. Qian, J. Liang, C. Dang, Knowledge structure, knowledge granulation and knowledge distance in a knowledge base, International Journal of Approximate Reasoning 50 (2009) 174-188. [24] T. Yang, Q. Li, The reduction and fusion of fuzzy covering systems based on the evidence theory, International Journal of Approximate Reasoning 53 (2012) 87-103. [25] M. Hall, G. Holmes, Bench marking attribute selection techniques for discrete class data mining, IEEE Transactions on Knowledge and Data Engineering 15 (2003) 1437-1447. [26] G. Liu, Generalized rough sets over fuzzy lattices, Information Sciences"}, {"heading": "178 (2008) 1651-1662.", "text": "[27] L. Zadeh, Fuzzy logic=computing with words, IEEE Transactions on Fuzzy Systems 4 (1996) 103-111. [28] Z. Pei, D. Pei, Li Zheng, Topology vs generalized rough sets, International journal of Approximate Reasoning 52 (2001) 231-239. [29] X. Li, S. Liu, Matroidal approaches properties of rough sets via closure operators, International Journal of Approximate Reasoning 53 (2012) 513- 527. [30] A. Salama, Some topological properties of rough sets with tools for data mining, International Journal of Computer Science 8 (2011) 588-595. [31] W. Zhu, Topological approaches to covering rough sets based on relations, Information sciences 177 (2007) 1499-1508. [32] Y. Chen, D. Miao, R. Zhang, K. Wu, A rough set approach to feature selection based on power trees, Knowledge-based Systems 24 (2011) 275-281. [33] W. Zhu, F. Wang, On three types of covering rough sets, IEEE Transactions on Knowledge and Data Engineering 19 (2007) 1131-1144."}], "references": [{"title": "Rough sets", "author": ["Z. Pawlak"], "venue": "International Journal of Computer and Information Sciences 11 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1982}, {"title": "Rough sets: theoretical aspects of reasoning about data", "author": ["Z. Pawlak"], "venue": "Kluwer Academic Publishers, Dordrecht, MA", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1991}, {"title": "Discernibility matrix simplification for constructing attribute reducts", "author": ["Y. Yao", "Y. Zhao"], "venue": "Information sciences 179 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Uncertain decision making based on rough sets", "author": ["W. Zhang", "G. Qiou"], "venue": "Publishing Company of Qinghua University", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "Approximations in the space (U", "author": ["W. Zakowski"], "venue": "\u03c0) , Demonstratio Mathematica 16 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1983}, {"title": "C.Rauszer, The discernibility matrices and functions in information systems, in: R.Slowi\u0144ski(Ed.), Intelligent Decision Support, Handbook of Applications and Advances of the Rough Sets", "author": ["A. Skowron"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1992}, {"title": "The theory of topology spaces[M", "author": ["G. Gao"], "venue": "Science Publishing Company of Beijing", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Introduction to special issues on data mining and granular computing", "author": ["T. Lin"], "venue": "International Journal of Approximate Reasoning 40 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "y", "author": ["J. Mi"], "venue": "Leung, W. Wu, An uncertainty measure in partition-based fuzzy rough sets,International Journal of Approximate Reasoning 34 ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2005}, {"title": "A rough set approach for the discovery of classi?cation rules in interval-valued information systems, International", "author": ["Yee. Leung", "Manfred M. Fischer", "W. Wu", "J. Mi"], "venue": "Journal of Approximate Reasoning", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Fuzzy rough set based attribute reduction for information systems with fuzzy decisions", "author": ["Q. He", "C. Wu", "D. Chen", "S. Zhao"], "venue": "Knowledge-Based Systems 5 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Attribute reduction based on evidence theory in incomplete decision systems", "author": ["W. Wu"], "venue": "Information sciences 178 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Constructive and algebra methods of theory of rough sets", "author": ["Y. Yao"], "venue": "Information sciences 109 ", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "A vague-rough set approach for uncertain knowledge acquisition Original Research Article", "author": ["L. Feng", "T. Li", "D. Ruan", "S. Gou"], "venue": "Knowledge-Based Systems 6 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Attribute Reduction in decision-theoretic rough set models", "author": ["Y. Yao", "Y. Zhao"], "venue": "Information sciences 178 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Reduction algorithms based on discernibility matrix: the ordered attributes method", "author": ["J. Wang", "J. Wang"], "venue": "Journal of Computer Science and Technology 16 ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2001}, {"title": "A reduction algorithm meeting users\u2019 requirements", "author": ["K. Zhao", "J. Wang"], "venue": "Journal of Computer Science and Technology 17 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2002}, {"title": "A model of machine learning based on user preference of attributes", "author": ["Y. Yao", "Y. Zhao", "J. Wang", "S. Han"], "venue": "Proceedings of International Conference on Rough Sets and Current Trends in Computing", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "Approaches to knowledge reductions in inconsistent systems", "author": ["W. Zhang", "J. Mi", "W. Wu"], "venue": "International Journal of Intelligent Systems 18 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2003}, {"title": "Rough sets and boolean reasoning", "author": ["Z. Pawlak", "A. Skowron"], "venue": "Information Sciences 177 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2007}, {"title": "A new approach to attribute reduction of consistent and inconsistent covering decision systems with covering rough sets", "author": ["D. Chen", "C. Zhang", "Q. Hu"], "venue": "Information Sciences 177 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "The investigation of the Bayesian rough set model", "author": ["D. \u015alezak", "W. Ziarko"], "venue": "International Journal of Approximate Reasoning 40 ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Knowledge structure", "author": ["Y. Qian", "J. Liang", "C. Dang"], "venue": "knowledge granulation and knowledge distance in a knowledge base, International Journal of Approximate Reasoning 50 ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "The reduction and fusion of fuzzy covering systems based on the evidence theory", "author": ["T. Yang", "Q. Li"], "venue": "International Journal of Approximate Reasoning 53 ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Bench marking attribute selection techniques for discrete class data mining", "author": ["M. Hall", "G. Holmes"], "venue": "IEEE Transactions on Knowledge and Data Engineering 15 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}, {"title": "Generalized rough sets over fuzzy lattices", "author": ["G. Liu"], "venue": "Information Sciences 178 ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2008}, {"title": "Fuzzy logic=computing with words", "author": ["L. Zadeh"], "venue": "IEEE Transactions on Fuzzy Systems 4 ", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1996}, {"title": "Li Zheng", "author": ["Z. Pei", "D. Pei"], "venue": "Topology vs generalized rough sets, International journal of Approximate Reasoning 52 ", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Matroidal approaches properties of rough sets via closure operators", "author": ["X. Li", "S. Liu"], "venue": "International Journal of Approximate Reasoning 53 ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "Some topological properties of rough sets with tools for data mining", "author": ["A. Salama"], "venue": "International Journal of Computer Science 8 ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Topological approaches to covering rough sets based on relations", "author": ["W. Zhu"], "venue": "Information sciences 177 ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "A rough set approach to feature selection based on power trees", "author": ["Y. Chen", "D. Miao", "R. Zhang", "K. Wu"], "venue": "Knowledge-based Systems 24 ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "On three types of covering rough sets", "author": ["W. Zhu", "F. Wang"], "venue": "IEEE Transactions on Knowledge and Data Engineering 19 ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Rough set theory originally proposed by Pawlak [1][2], provides an effective method to deal with imprecision and vague in information system.", "startOffset": 47, "endOffset": 50}, {"referenceID": 1, "context": "Rough set theory originally proposed by Pawlak [1][2], provides an effective method to deal with imprecision and vague in information system.", "startOffset": 50, "endOffset": 53}, {"referenceID": 17, "context": "Because of voluminous data that always generates in information system, multi-granular Rough set is very important as a basic Processing method, and has very widely applications in process control, conflict analysis, data mining, data fusion technique [18, 19, 20, 21].", "startOffset": 252, "endOffset": 268}, {"referenceID": 18, "context": "Because of voluminous data that always generates in information system, multi-granular Rough set is very important as a basic Processing method, and has very widely applications in process control, conflict analysis, data mining, data fusion technique [18, 19, 20, 21].", "startOffset": 252, "endOffset": 268}, {"referenceID": 19, "context": "Because of voluminous data that always generates in information system, multi-granular Rough set is very important as a basic Processing method, and has very widely applications in process control, conflict analysis, data mining, data fusion technique [18, 19, 20, 21].", "startOffset": 252, "endOffset": 268}, {"referenceID": 20, "context": "Because of voluminous data that always generates in information system, multi-granular Rough set is very important as a basic Processing method, and has very widely applications in process control, conflict analysis, data mining, data fusion technique [18, 19, 20, 21].", "startOffset": 252, "endOffset": 268}, {"referenceID": 5, "context": "A beautiful and efficient method was introduced by Skowron and Rauszer [6] which is the discernibility matrix of the information system (U,A), where DA = {dA(x, y)|x, y \u2208 U}, dA(x, y) = {a \u2208 A|Va(x) 6= Va(y)}.", "startOffset": 71, "endOffset": 74}, {"referenceID": 21, "context": "Many scholars devote to study this issues [11\u221214], [22, 23].", "startOffset": 51, "endOffset": 59}, {"referenceID": 22, "context": "Many scholars devote to study this issues [11\u221214], [22, 23].", "startOffset": 51, "endOffset": 59}, {"referenceID": 2, "context": "In [3], Yao and Zhao discussed the reduct by discernibility matrix simplification.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "Otherwise, another reduct construction algorithm based on matrix simplification is proposed in [3].", "startOffset": 95, "endOffset": 98}, {"referenceID": 3, "context": "Otherwise, In [4], Zhang and Qiu depart the attributes into three types based on the relationship with attribute reduct which contain core, relative necessary and unnecessary attributes.", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "Moreover, combined with the row-wise simplification reduct construction algorithm in [3], we construct a algorithm based on E(a).", "startOffset": 85, "endOffset": 88}, {"referenceID": 2, "context": "In the last of this paper, we give a reduct algorithm based on E(a), and analysis it\u2019s efficiency through an example in [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "Paper [1, 16] introduced a new definition for binary relation-based rough sets.", "startOffset": 6, "endOffset": 13}, {"referenceID": 15, "context": "Paper [1, 16] introduced a new definition for binary relation-based rough sets.", "startOffset": 6, "endOffset": 13}, {"referenceID": 27, "context": "(Lower approximation) The covering lower approximation operation R\u2217 : P (U) \u21d2 P (U) is defined as R\u2217(X) = \u22c3 K\u2208C\u2227K\u2286X K[28].", "startOffset": 117, "endOffset": 121}, {"referenceID": 5, "context": "[6] In an information system (U,A), attribute a \u2208 A is a core iff there exists some d{x, y}, x, y \u2208 U , d{x, y} \u2208 DA, such that d{x, y} = {a} iff RA\u2212{a} 6= RA.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] In an information system (U,A), we have the conclusions as follows: (1) a \u2208 A is a relative necessary attribute iff RA\u2212{a} = RA, and \u222a{RB\u2212{a} * Ra ,where RB \u2286 RA, B \u2286 A}.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "For two class of power set A and B of X, A,B \u2208 2 , we call A precise-refines B iff for any KA \u2208 A, KA \u2286 KB, for some KB \u2208 B, and for any KB \u2208 B there exists some KA \u2208 A, such that KA \u2286 KB[7].", "startOffset": 187, "endOffset": 190}, {"referenceID": 2, "context": "In [3], Yao proposed a row-wise simplification reduct construction algorithm.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "The row-wise simplification reduct construction algorithm proposed by Yao in [3] is recalled in the following: Input:The discernibility matrix M of an information table S.", "startOffset": 77, "endOffset": 80}, {"referenceID": 2, "context": "struction algorithm in [3]; we denote the reduct with respect toE(a) asREDE(a); let R = R \u222aREDE(a); third step: if there exists a K \u2208 N(a),such that REDE(a) \u2229K = \u2205; then let R = R \u2229 {a}; else continue; forth step: for every C(i) \u2208 C, let C(i) = C(i)\u2212 \u222aN(a); //because E(a) \u2286 \u222aN(a), thus C(i)\u2212 \u222aN(a) = C(i)\u2212 \u222aN(a) \u2212 \u222aE(a) if C = \u2205; {Output R; // R is a reduct End.", "startOffset": 23, "endOffset": 26}, {"referenceID": 2, "context": "In [3], Yao used an example to inspect the row-wise simplification reduct construction algorithm, now we will quote this example in [3] to exam the algorithm with respect to E(a).", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "In [3], Yao used an example to inspect the row-wise simplification reduct construction algorithm, now we will quote this example in [3] to exam the algorithm with respect to E(a).", "startOffset": 132, "endOffset": 135}, {"referenceID": 2, "context": "second step: compute a reduct respect to E(a) with the row-wise simplification reduct construction algorithm in[3]; then REDE(a) = {c, b}.", "startOffset": 111, "endOffset": 114}, {"referenceID": 2, "context": "1 which is first used by Yao in [3].", "startOffset": 32, "endOffset": 35}], "year": 2015, "abstractText": "The research of attribute characters in information system which contains core, necessary, unnecessary is a basic and important issue in attribute reduct. Many methods for the judgement of attribute characters are based on the relationship between the objects and attributes. In this paper, a new type of judgement theorems which are absolutely based on the relationship among attributes is proposed for the judgement of attribute characters. The method is through comparing the two new attribute sets E(a) and N(a) with respect to the designated attribute a which is proposed in this paper. We conclude that which type of the attribute a belongs to is determined by the relationship between E(a) and N(a) in essence. Secondly, more concise and clear results are given about the judgment of the attribute characters through analyzing the properties of refinement and precise-refinement between E(a) andN(a) in topology. In addition, the relationship among attributes are discussed which is useful for constructing a reduct in the last section of this paper. In the last, we propose a reduct algorithm based on E(a), and this algorithm is an extended application of the analysis of attribute characters above.", "creator": "LaTeX with hyperref package"}}}