{"id": "1303.3754", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Mar-2013", "title": "A Last-Step Regression Algorithm for Non-Stationary Online Learning", "abstract": "assume the principle goal of a learner in standard algorithm online learning is to maintain an average loss close to the loss of the best - performing single function in some class. presented in many rare real - world problems, such streams as rating or ranking useful items, there is probably no recognizable single best target function during the runtime of the algorithm, instead the best ( local ) target function is drifting over time. we develop a novel last - step minmax optimal algorithm employed in context of a drift. we analyze the algorithm in the worst - case regret framework and show that it maintains an average loss close to that of the best slowly changing dynamic sequence error of linear functions, as effective long previously as the total of incoming drift components is sublinear. in some situations, our bound sensitivity improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. we also build on confirming the h _ infinity filter and its bound, and develop and analyze a drift second algorithm for drifting function setting. synthetic simulations demonstrate the advantages of our algorithms in a worst - case constant drift setting.", "histories": [["v1", "Fri, 15 Mar 2013 12:20:53 GMT  (443kb,D)", "http://arxiv.org/abs/1303.3754v1", "arXiv admin note: substantial text overlap witharXiv:1303.0140"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1303.0140", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["edward moroshko", "koby crammer"], "accepted": false, "id": "1303.3754"}, "pdf": {"name": "1303.3754.pdf", "metadata": {"source": "CRF", "title": "A Last-Step Regression Algorithm for Non-Stationary Online Learning", "authors": ["Edward Moroshko", "Koby Crammer"], "emails": [], "sections": [{"heading": null, "text": "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H\u221e filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting."}, {"heading": "1 Introduction", "text": "We consider the on-line learning problems, in which a learning algorithm predicts real numbers given inputs in a sequence of trials. An example of such a problem is to predict a stock\u2019s prices given input about the current state of the stock-market. In general, the goal of the algorithm is to achieve an average loss that is not much larger compared to the loss one suffers if it had always chosen to predict according to the best-performing single function from some class of functions.\nIn the past half a century, many algorithms were proposed (a review can be found in a comprehensive book on\nAppearing in Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS) 2013, Scottsdale, AZ, USA. Volume XX of JMLR: W&CP XX. Copyright 2013 by the authors.\nthe topic [10]) for this problem, some of which are able to achieve an average loss arbitrarily close to that of the best function in retrospect. Furthermore, such guarantees hold even if the input and output pairs are chosen in a fully adversarial manner with no distributional assumptions.\nCompeting with the best fixed function might not suffice for some problems. In many real-world applications, the true target function is not fixed, but is slowly drifting over time. Consider a function designed to rate movies for recommender systems given some features. Over time a rate of a movie may change as more movies are released or the season changes. Furthermore, the very own personal-taste of a user may change as well.\nWith such properties in mind, we develop new learning algorithms designed to work with target drift. The goal of an algorithm is to maintain an average loss close to that of the best slowly changing sequence of functions, rather than compete well with a single function. We focus on problems for which this sequence consists only of linear functions. Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].\nWe take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation. On each iteration the algorithm makes the optimal min-max prediction with respect to a quantity called regret, assuming it is the last iteration. Yet, unlike previous work, it is optimal when a drift is allowed. As opposed to the derivation of the last-step min-max predictor for a fixed vector, the resulting optimization problem is not straightforward to solve. We develop a dynamic program (a recursion) to solve this problem, which allows to compute the optimal last-step minmax predictor. We analyze the algorithm in the worst-case regret framework and show that the algorithm maintains an average loss close to that of the best slowly changing sequence of functions, as long as the total drift is sublinear in the number of rounds T . Specifically, we show that if the total amount of drift is T\u03bd (for \u03bd = o(1)) the cumulative regret is bounded by T\u03bd1/3 + log(T ). When the inar X\niv :1\n30 3.\n37 54\nv1 [\ncs .L\nG ]\n1 5\nM ar\n2 01\n3\nstantaneous drift is close to constant, this improves over a previous bound of Vaits and Crammer [35] of an algorithm named ARCOR that showed a bound of T\u03bd1/4 log(T ). Additionally, when no drift is introduced (stationary setting) our algorithm suffers logarithmic regret, as for the algorithm of Forster [17]. We also build on the H\u221e adaptive filter, which is min-max optimal with respect to a filtering task, and derive another learning algorithm based on the same min-max principle. We provide a regret bound for this algorithm as well, and relate the two algorithms and their respective bounds. Finally, synthetic simulations show the advantages of our algorithms when a close to constant drift is allowed."}, {"heading": "2 Problem Setting", "text": "We focus on the regression task evaluated with the squared loss. Our algorithms are designed for the online setting and work in iterations (or rounds). On each round an online algorithm receives an input-vector xt \u2208 Rd and predicts a real value y\u0302t \u2208 R. Then the algorithm receives a target label yt \u2208 R associated with xt, uses it to update its prediction rule, and then proceeds to the next round.\nOn each round, the performance of the algorithm is evaluated using the squared loss, `t(alg) = ` (yt, y\u0302t) = (y\u0302t \u2212 yt)2. The cumulative loss suffered over T iterations is, LT (alg) = \u2211T t=1 `t(alg). The goal of the algorithm is to have low cumulative loss compared to predictors from some class. A large body of work is focused on linear prediction functions of the form f(x) = x>u where u \u2208 Rd is some weight-vector. We denote by `t(u) = ( x>t u\u2212 yt\n)2 the instantaneous loss of a weight-vector u.\nWe focus on algorithms that are able to compete against sequences of weight-vectors, (u1, . . . ,uT ) \u2208 Rd\u00d7\u00b7 \u00b7 \u00b7\u00d7Rd, where ut is used to make a prediction for the tth example (xt, yt). We define the cumulative loss of such set by LT ({ut}) = \u2211T t `t(ut) and the regret of an algorithm by\nRT ({ut}) = \u2211T t (yt \u2212 y\u0302t)2 \u2212 LT ({ut}) . The goal of the algorithm is to have a low-regret, and formally to have RT ({ut}) = o(T ), that is, the average loss suffered by the algorithm will converge to the average loss of the best linear function sequence (u1 . . .uT ).\nClearly, with no restriction or penalty over the set {ut} the right term of the regret can easily be zero by setting, ut = xt(yt/ \u2016xt\u20162), which implies `t(ut) = 0 for all t. Thus, in the analysis below we incorporate the total drift of the weight-vectors defined to be,\nV=VT ({ut})= T\u22121\u2211 t=1 \u2016ut \u2212 ut+1\u20162 , \u03bd=\u03bd({ut})= V T , (1)\nwhere \u03bd is the average drift . Below we bound the regret with, RT ({ut}) \u2264 O ( T 2 3V 1 3 + log(T ) ) =\nO ( T\u03bd 1 3 + log(T ) ) . Next, we develop an explicit form of\nthe last-step min-max algorithm with drift."}, {"heading": "3 Algorithm", "text": "We define the last-step minmax predictor y\u0302T to be1,\narg min y\u0302T max yT [ T\u2211 t=1 (yt \u2212 y\u0302t)2\n\u2212 min u1,...,uT QT (u1, . . . ,uT )\n] , (2)\nwhere we define\nQt (u1, . . . ,ut) =b \u2016u1\u20162 + c t\u22121\u2211 s=1 \u2016us+1 \u2212 us\u20162\n+ t\u2211 s=1 ( ys \u2212 u>s xs )2 , (3)\nfor some positive constants b, c. The last optimization problem can also be seen as a game where the algorithm chooses a prediction y\u0302t to minimize the last-step regret, while an adversary chooses a target label yt to maximize it. The first term of (2) is the loss suffered by the algorithm while Qt (u1, . . . ,ut) defined in (3) is a sum of the loss suffered by some sequence of linear functions (u1, . . . ,ut), a penalty for consecutive pairs that are far from each other, and for the norm of the first to be far from zero.\nWe first solve recursively the inner optimization problem minu1,...,ut Qt (u1, . . . ,ut), for which we define an auxiliary function,\nPt (ut) = min u1,...,ut\u22121 Qt (u1, . . . ,ut) , (4)\nwhich clearly satisfies,\nmin u1,...,ut Qt (u1, . . . ,ut) = min ut Pt(ut) . (5)\nWe start the derivation of the algorithm with a lemma, stating a recursive form of the function-sequence Pt(ut).\nLemma 1. For t = 2, 3, . . .\nP1(u1) = Q1(u1)\nPt (ut) = min ut\u22121\n( Pt\u22121 (ut\u22121) + c \u2016ut \u2212 ut\u22121\u20162\n+ ( yt \u2212 u>t xt )2) .\n1yT and y\u0302T serve both as quantifiers (over the min and max operators, respectively), and as the optimal arguments of this optimization problem.\nThe proof appears in App. B.1. Using Lem. 1 we write explicitly the function Pt(ut).\nLemma 2. The following equality holds\nPt (ut) = u > t Dtut \u2212 2u>t et + ft , (6)\nwhere,\nD1 = bI + x1x > 1 , Dt = ( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t (7)\ne1 = y1x1 , et = ( I + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt (8)\nf1 = y 2 1 , ft = ft\u22121 \u2212 e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 + y 2 t . (9)\nNote that Dt \u2208 Rd\u00d7d is a positive definite matrix, et \u2208 Rd\u00d71 and ft \u2208 R.\nThe proof appears in App. B.2. From Lem. 2 we conclude, by substituting (6) in (5), that,\nmin u1,...,ut Qt (u1, . . . ,ut)\n= min ut\n( u>t Dtut \u2212 2u>t et + ft ) = \u2212e>t D\u22121t et + ft .\n(10)\nSubstituting (10) back in (2) we get that the last-step minmax predictor y\u0302T is given by,\narg min y\u0302T max yT [ T\u2211 t=1 (yt \u2212 y\u0302t)2 + e>TD\u22121T eT \u2212 fT ] . (11)\nSince eT depends on yT we substitute (8) in the second term of (11),\ne>TD \u22121 T eT =(( I + c\u22121DT\u22121 )\u22121 eT\u22121 + yTxT )> D\u22121T((\nI + c\u22121DT\u22121 )\u22121 eT\u22121 + yTxT ) . (12)\nSubstituting (12) and (9) in (11) and omitting terms not depending explicitly on yT and y\u0302T we get,\ny\u0302T = arg min y\u0302T max yT\n[ (yT \u2212 y\u0302T )2 + y2Tx>TD\u22121T xT\n+ 2yTx > TD \u22121 T ( I + c\u22121DT\u22121 )\u22121 eT\u22121 \u2212 y2T ] = arg min\ny\u0302T max yT\n[ ( x>TD \u22121 T xT ) y2T + y\u0302 2 T (13)\n+ 2yT ( x>TD \u22121 T ( I + c\u22121DT\u22121 )\u22121 eT\u22121 \u2212 y\u0302T )] .\nThe last equation is strictly convex in yT and thus the optimal solution is not bounded. To solve it, we follow an approach used by Forster in a different context [17]. In order to make the optimal value bounded, we assume that the adversary can only choose labels from a bounded set\nyT \u2208 [\u2212Y, Y ]. Thus, the optimal solution of (13) over yT is given by the following equation, since the optimal value is yT \u2208 {+Y,\u2212Y },\ny\u0302T = arg min y\u0302T\n[ ( x>TD \u22121 T xT ) Y 2 + y\u03022T\n+ 2Y \u2223\u2223\u2223x>TD\u22121T (I + c\u22121DT\u22121)\u22121 eT\u22121 \u2212 y\u0302T \u2223\u2223\u2223 ] .\nThis problem is of a similar form to the one discussed by Forster [17], from which we get the optimal solution, y\u0302T = clip ( x>TD \u22121 T ( I + c\u22121DT\u22121 )\u22121 eT\u22121, Y ) , where for y > 0 we define clip(x, y) = sign(x) min{|x|, y}. The optimal solution depends explicitly on the bound Y , and as its value is not known, we thus ignore it, and define the output of the algorithm to be,\ny\u0302T = x > TD \u22121 T ( I + c\u22121DT\u22121 )\u22121 eT\u22121 . (14)\nWe call the algorithm LASER for last step adaptive regressor algorithm, and it is summarized in Fig. 1. Clearly, for c = \u221e the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17]. See also the work of Azoury and Warmuth [2]. The algorithm can be combined with Mercer kernels as it employs only sums of inner- and outer-products of its inputs. This algorithm can be seen also as a forward algorithm [2]: The predictor of (14) can be seen as the optimal linear model obtained over the same prefix of length T \u2212 1 and the new input xT with fictional-label yT = 0. Specifically, from (8) we get that if yT = 0, then eT = ( I + c\u22121DT\u22121 )\u22121 eT\u22121. The prediction of the optimal predictor defined in (10) is x>T uT = x > TD \u22121 T eT = y\u0302T , where y\u0302T was defined in (14)."}, {"heading": "4 Analysis", "text": "We now analyze the performance of the algorithm in the worst-case setting, starting with the following technical lemma.\nLemma 3. For all t the following statement holds,\nD\u2032t\u22121D \u22121 t xtx > t D \u22121 t D \u2032 t\u22121 \u2212D\u22121t\u22121 + D\u2032t\u22121 ( D\u22121t D \u2032 t\u22121 + c \u22121I ) 0\nwhere D\u2032t\u22121 = ( I + c\u22121Dt\u22121 )\u22121 .\nThe proof appears in App. B.3. We next bound the cumulative loss of the algorithm,\nTheorem 4. Assume the labels are bounded supt |yt| \u2264 Y for some Y \u2208 R. Then the following bound holds,"}, {"heading": "Parameters: 0 < b < c", "text": "Initialize: Set D0 = (bc)/(c \u2212 b) I \u2208 Rd\u00d7d and e0 = 0 \u2208 Rd For t = 1, . . . , T do \u2022 Receive an instance xt \u2022 Compute Dt = ( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t (7)\n( )\u22121"}, {"heading": "Output: eT , DT", "text": "LT (LASER) \u2264 min u1,...,uT\n[ b \u2016u1\u20162 + cVT ({ut})\n+ LT ({ut}) ] + Y 2\nT\u2211 t=1 x>t D \u22121 t xt .\nProof. Fix t. A long algebraic manipulation yields,\n(yt \u2212 y\u0302t)2 + min u1,...,ut\u22121 Qt\u22121 (u1, . . . ,ut\u22121)\n\u2212 min u1,...,ut Qt (u1, . . . ,ut)\n= (yt \u2212 y\u0302t)2 + 2ytx>t D\u22121t D\u2032t\u22121et\u22121\n+e>t\u22121 [ \u2212D\u22121t\u22121+D\u2032t\u22121 ( D\u22121t D \u2032 t\u22121+c \u22121I )] et\u22121\n+ y2t x > t D \u22121 t xt \u2212 y2t . (15)\nSubstituting the specific value of the predictor y\u0302t = x>t D \u22121 t D \u2032 t\u22121et\u22121 from (14), we get that (15) equals to,\ny\u03022t + y 2 t x > t D \u22121 t xt + e > t\u22121 [ \u2212D\u22121t\u22121\n+ D\u2032t\u22121 ( D\u22121t D \u2032 t\u22121 + c \u22121I ) ] et\u22121\n=e>t\u22121D \u2032 t\u22121D \u22121 t xtx > t D \u22121 t D \u2032 t\u22121et\u22121 + e > t\u22121 [ \u2212D\u22121t\u22121\n+ D\u2032t\u22121 ( D\u22121t D \u2032 t\u22121 + c \u22121I ) ] et\u22121 + y 2 t x > t D \u22121 t xt\n=e>t\u22121 [ D\u2032t\u22121D \u22121 t xtx > t D \u22121 t D \u2032 t\u22121 \u2212D\u22121t\u22121 (16)\n+ D\u2032t\u22121 ( D\u22121t D \u2032 t\u22121 + c \u22121I ) ] et\u22121 + y 2 t x > t D \u22121 t xt .\nParameters: 1 < a , 0 < b, c Initialize: Set P0 = b\u22121I \u2208 Rd\u00d7d and w0 = 0 \u2208 Rd For t = 1, . . . , T do \u2022 Receive an instance xt \u2022 Output prediction y\u0302t = x>t wt\u22121 \u2022 Receive the correct label yt \u2022 Compute P\u0303t = ( P\u22121t\u22121 + (a\u2212 1)xtx>t\n)\u22121 \u2022 Update wt = wt\u22121 + aP\u0303t(yt \u2212 y\u0302t)xt \u2022 Update Pt = P\u0303t + c\u22121I"}, {"heading": "Output: wT , PT", "text": "Figure 2: An H\u221e algorithm for online regression.\nUsing Lem. 3 we upper bound (16) with, y2t x > t D \u22121 t xt \u2264 Y 2x>t D \u22121 t xt . Finally, summing over t \u2208 {1, . . . , T} gives the desired bound,\nT\u2211 t=1 (yt \u2212 y\u0302t)2 \u2212 min u1,...,uT\n[ b \u2016u1\u20162 + c\nT\u22121\u2211 t=1 \u2016ut+1 \u2212 ut\u20162\n+ T\u2211 t=1 ( yt \u2212 u>t xt\n)2]\n= LT (LASER)\u2212 min u1,...,uT\n[ b \u2016u1\u20162+cVT ({ut}) + LT ({ut}) ]\n\u2264 Y 2 T\u2211 t=1 x>t D \u22121 t xt\nIn the next lemma we further bound the right term of Thm. 4. This type of bound is based on the usage of the covariance-like matrix D.\nLemma 5.\nT\u2211 t=1 x>t D \u22121 t xt \u2264 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ c\u22121 T\u2211 t=1 Tr (Dt\u22121) . (17)\nProof. Similar to the derivation of Forster [17] (details omitted due to lack of space),\nx>t D \u22121 t xt \u2264 ln |Dt|\u2223\u2223Dt \u2212 xtx>t \u2223\u2223 = ln |Dt|\u2223\u2223\u2223(D\u22121t\u22121 + c\u22121I)\u22121\u2223\u2223\u2223 = ln\n|Dt| |Dt\u22121| \u2223\u2223(I + c\u22121Dt\u22121)\u2223\u2223 = ln\n|Dt| |Dt\u22121|\n+ ln \u2223\u2223(I + c\u22121Dt\u22121)\u2223\u2223 .\nand because ln \u2223\u2223 1 bD0 \u2223\u2223 \u2265 0 we get \u2211Tt=1 x>t D\u22121t xt \u2264 ln \u2223\u2223 1 bDT\n\u2223\u2223 + \u2211Tt=1 ln \u2223\u2223(I + c\u22121Dt\u22121)\u2223\u2223 \u2264 ln \u2223\u2223 1bDT \u2223\u2223 + c\u22121 \u2211T t=1 Tr (Dt\u22121) .\nAt first sight it seems that the right term of (17) may grow super-linearly with T , as each of the matrices Dt grows with t. The next two lemmas show that this is not the case, and in fact, the right term of (17) is not growing too fast, which will allow us to obtain a sub-linear regret bound. Lem. 6 analyzes the properties of the recursion of D defined in (7) for scalars, that is d = 1. In Lem. 7 we extend this analysis to matrices.\nLemma 6. Define f(\u03bb) = \u03bb\u03b2/ (\u03bb+ \u03b2) + x2 for \u03b2, \u03bb \u2265 0 and some x2 \u2264 \u03b32. Then: (1) f(\u03bb) \u2264 \u03b2 + \u03b32 (2) f(\u03bb) \u2264\n\u03bb+ \u03b32 (3) f(\u03bb) \u2264 max { \u03bb, 3\u03b32+ \u221a \u03b34+4\u03b32\u03b2\n2\n} .\nThe proof appears in App. B.6. We build on Lem. 6 to bound the maximal eigenvalue of the matrices Dt. Lemma 7. Assume \u2016xt\u20162 \u2264 X2 for some X . Then, the eigenvalues of Dt (for t \u2265 1), denoted by \u03bbi (Dt), are upper bounded by maxi \u03bbi (Dt) \u2264 max { 3X2+ \u221a X4+4X2c 2 , b+X 2 } .\nProof. By induction. From (7) we have that \u03bbi(D1) \u2264 b + X2 for i = 1, . . . , d. We proceed with a proof for some t. For simplicity, denote by \u03bbi = \u03bbi(Dt\u22121) the ith eigenvalue of Dt\u22121 with a corresponding eigenvector vi. From (7) we have,\nDt = ( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t\n( D\u22121t\u22121 + c \u22121I )\u22121 + I \u2016xt\u20162\n= d\u2211 i viv > i ( \u03bbic \u03bbi + c + \u2016xt\u20162 ) . (18)\nPlugging Lem. 6 in (18) we get, Dt \u2211d i viv > i max { 3X2+ \u221a X4+4X2c 2 , b+X 2 }\n= max { 3X2+ \u221a X4+4X2c 2 , b+X 2 } I .\nFinally, equipped with the above lemmas we prove the main result of this section.\nCorollary 8. Assume \u2016xt\u20162 \u2264 X2, |yt| \u2264 Y . Then,\nLT (LASER) \u2264 b \u2016u1\u20162 + LT ({ut}) + Y 2 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223 +c\u22121Y 2Tr (D0) + cV\n+c\u22121Y 2Tdmax\n{ 3X2 + \u221a X4 + 4X2c\n2 , b+X2\n} .\n(19)"}, {"heading": "Furthermore, set b = \u03b5c for some 0 < \u03b5 < 1.", "text": "Denote by \u00b5 = max { 9/8X2, (b+X2) 2\n8X2\n} and M =\nmax { 3X2, b+X2 }\n. If V \u2264 T \u221a 2Y 2dX \u00b53/2 (low drift) then\nby setting\nc = (\u221a 2TY 2dX/V )2/3\n(20)\nwe have,\nLT (LASER) \u2264 b \u2016u1\u20162 + 3 (\u221a 2Y 2dX )2/3 T 2/3V 1/3\n+ \u03b5\n1\u2212 \u03b5 Y 2d+ LT ({ut}) + Y 2 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223 . (21)\nThe proof appears in Sec. A.1. A few remarks are in order. First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9]. In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]). See also the work of Azoury and Warmuth [2]. Second, substituting V = T\u03bd we get that the bound depends on the average drift as T 2/3(T\u03bd)1/3 = T\u03bd1/3. Clearly, to have a sublinear regret we must have \u03bd = o(1). Third, Vaits and Crammer [35] recently proposed an algorithm, called ARCOR, for the same setting. The regret of ARCOR depends on the total drift as \u221a TV \u2032 log(T ), where their definition of total drift is a sum of the Euclidean differences V \u2032 = \u2211T\u22121 t \u2016ut+1\u2212ut\u2016, rather than the squared norm. When the instantaneous drift \u2016ut+1 \u2212 ut\u2016 is constant, this notion of total drift is related to our average drift, V \u2032 = T \u221a \u03bd. Therefore, in this case the bound of ARCOR [35] is \u03bd1/4T log(T ) which is worse than our bound, both since it has an additional log(T ) factor (as opposed to our additive log term) and since \u03bd = o(1). Therefore we expect that our algorithm will perform better than ARCOR [35] when the instantaneous drift is approximately constant. Indeed, the synthetic simulations described in Sec. 6 further support this conclusion. Fourth, Herbster and Warmuth [22] developed shifting bounds for general gradient descent algorithms with projection of the weight-vector using the Bregman divergence. In their bounds, there is a factor greater than 1 multiplying the term LT ({ut}), leading to a small regret only when the data is close to be realizable with linear models. Yet, their bounds have better dependency on d, the dimension of the inputs x. Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting. However, to have sublinear regret they require a strong assumption on the drift V = o(1), while we require only V = o(T ). Fifth, if V \u2265 T Y\n2dM \u00b52 then by setting c =\n\u221a Y 2dMT/V\nwe have,\nLT (LASER) \u2264 b \u2016u1\u20162 + 2 \u221a Y 2dTMV\n+ \u03b5\n1\u2212 \u03b5 Y 2d+ LT ({ut}) + Y 2 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223 (22)\n(See App. B.5 for details). The last bound is linear in T and can be obtained also by a naive algorithm that outputs y\u0302t = 0 for all t."}, {"heading": "5 An H\u221e Algorithm for Online Regression", "text": "Adaptive filtering is an active and well established area of research in signal processing. Formally, it is equivalent to online learning. On each iteration t the filter receives an input xt \u2208 Rd and predicts a corresponding output y\u0302t. It then receives the true desired output yt and updates its internal model. Many adaptive filtering algorithms employ linear models, that is, at time t they output y\u0302t = w>t xt. For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].\nOne possible difference between adaptive filtering and online learning can be viewed in the interpretation of algorithms, and as a consequence, of their analysis. In online learning, the goal of an algorithm is to make predictions y\u0302t, and the predictions are compared to the predictions of some function from a known class (e.g. linear, parameteized by u). Thus, a typical online performance bound relates the quality of the algorithm\u2019s predictions with the quality of some function\u2019s g(x) = u>x predictions, using some non-negative loss measure `(w>t xt, yt). Such bounds often have the following shape,\nalgorithm loss with respect to observation\ufe37 \ufe38\ufe38 \ufe37\u2211 t `(w>t xt, yt) \u2264 A function u loss\ufe37 \ufe38\ufe38 \ufe37\u2211 t `(u>xt, yt) +B,\nfor some multiplicative-factor A and an additive factor B.\nAdaptive filtering is similar to the realizable setting in machine learning, where it is assumed the existence of some filter and the goal is to recover it using noisy observations. Often it is assumed that the output is a corrupted version of the output of some function, y = f(x) + n, with some noise n. Thus a typical bound relates the quality of an algorithm\u2019s predictions with respect to the target filter u and the amount of noise in the problem,\nalgorithm loss with respect to a reference\ufe37 \ufe38\ufe38 \ufe37\u2211 t `(w>t xt,u >xt) \u2264 A amount of noise\ufe37 \ufe38\ufe38 \ufe37\u2211 t `(u>xt, yt) +B .\nThe H\u221e filters (see e.g. papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting. These filters are reminiscent of the celebrated Kalman filter [23], which was motivated and analyzed in a stochastic setting with Gaussian noise. A pseudocode of one such filter we modified to online linear regression appears in Fig. 2. Theory of H\u221e filters states [33, Section 11.3] the following bound on its performance as a filter.\nTheorem 9. Assume the filter is executed with parameters a > 1 and b, c > 0. Then, for all input-output pairs (xt, yt) and for all reference vectors ut the following bound holds on the filter\u2019s performance, \u2211T t=1 ( x>t wt \u2212 x>t ut\n)2 \u2264 aLT ({ut}) + b \u2016u1\u20162 + cVT ({ut}) .\nFrom the theorem we establish a regret bound for the H\u221e algorithm to online learning.\nCorollary 10. Fix \u03b1 > 0. The total squared-loss suffered by the algorithm is bounded by\nLT (H\u221e) \u2264 (1 + 1/\u03b1+ (1 + \u03b1) a)LT ({ut}) (23) + (1 + \u03b1) b \u2016u1\u20162 + (1 + \u03b1) cVT ({ut}) .\nProof. Using a bound of Hassibi and Kailath [4, Lemma 4] we have that for all \u03b1 > 0, ( yt \u2212 x>t wt )2 \u2264( 1 + 1\u03b1 ) ( yt \u2212 x>t ut )2 + (1 + \u03b1) [ x>t (wt \u2212 ut) ]2 . Plugging back into the theorem and collecting the terms we get the desired bound.\nThe bound holds for any \u03b1 > 0. We plug \u03b1 =\u221a LT ({ut})/ ( aLT ({ut}) + cV + b \u2016u1\u20162 ) in (23) to\nget,\nLT (H\u221e) \u2264 (1 + a)LT ({ut}) + cV + b \u2016u1\u20162\n+ 2 \u221a( aLT ({ut}) + cV + b \u2016u1\u20162 ) LT ({ut})\n\u2264 (1 + a+ 2 \u221a a)LT ({ut}) + cV + b \u2016u1\u20162\n+ 2 \u221a( cV + b \u2016u1\u20162 ) LT ({ut}) .\nIntuitively, we expect the H\u221e algorithm to perform better when the data is close to linear, that is when LT ({ut}) is small, as, conceptually, it was designed to minimize a loss with respect to weights {ut}. On the other hand, LASER is expected to perform better when the data is hard to predict with linear models, as it is not motivated from this assumption. Indeed, the bounds reflect these observations.\nComparing the last bound with (21) we note a few differences. First, the factor (1 + a+ 2 \u221a a) \u2265 4 of LT ({ut}) is worse for H\u221e than for LASER, which is a unit. Second, LASER has worse dependency in the drift T 2/3V 1/3, while forH\u221e it is about cV +2 \u221a cV LT ({ut}). Third, the\nH\u221e has an additive factor \u223c \u221a LT ({ut}), while LASER has an additive logarithmic factor, at most.\nHence, the bound of the H\u221e based algorithm is better when the cumulative loss LT ({ut}) is small. In this case, 4LT ({ut}) is not a large quantity, and as all the other quantities behave like \u221a LT ({ut}), they are small as well. On the other hand, if LT ({ut}) is large, and is linear in T , the first term of the bound becomes dominant, and thus the factor of 4 for the H\u221e algorithm makes its bound\nhigher than that of LASER. Both bounds were obtained from a min-max approach, either directly (LASER) or viareduction from filtering (H\u221e). The bound of the former is lower in hard problems. Kivinen et al. [26] proposed another approach for filtering with a bound depending on\u2211 t \u2016ut\u2212ut\u22121\u2016 and not the sum of squares as we have both for LASER and the H\u221e-based algorithm."}, {"heading": "6 Simulations", "text": "We evaluate the LASER and H\u221e algorithms on four synthetic datasets. We set T = 2000 and d = 20. For all datasets, the inputs xt \u2208 R20 were generated such that the first ten coordinates were grouped into five groups of size two. Each such pair was drawn from a 45\u25e6 rotated Gaussian distribution with standard deviations 10 and 1. The remaining 10 coordinates were drawn from independent Gaussian distributions N (0, 2). The first synthetic dataset was generated using a sequence of vectors ut \u2208 R20 for which the only non-zero coordinates are the first two, where their values are the coordinates of a unit vector that is rotating with a constant rate (linear drift). Specifically, we have \u2016ut\u2016 = 1 and the instantaneous drift \u2016ut \u2212 ut\u22121\u2016 is constant. The second synthetic dataset was generated using a sequence of vectors ut \u2208 R20 for which the only non-zero coordinates are the first two. This vector in R2 is of unit norm \u2016ut\u2016 = 1 and rotating in a rate of t\u22121 (sublinear drift). In addition every 50 time-steps the two-dimensional vector defined above was \u201cembedded\u201d in different pair of coordinates of the reference vector ut, for the first 50 steps it were coordinates 1, 2, in the next 50 examples, coordinates 3, 4, and so on.\nThis change causes a switch in the reference vector ut. For the first two datasets we set yt = x>t ut (linear data). The third and fourth datasets are the same as first and second except we set yt = x>t ut + nt where nt \u223c N (0, 0.05) (noisy data).\nWe compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e. The algorithms\u2019 parameters were tuned using a single random sequence. We repeat each experiment 100 times reporting the mean cumulative square-loss. The results are summarized in Fig. 3 (best viewed in color).\nFor the first and third datasets (left plots of Fig. 3) we observe the superior performance of the LASER algorithm over previous approaches. LASER has a good tracking ability, fast learning rate and it is designed to perform well in severe conditions like linear drift.\nFor the second and fourth datasets (right plots of Fig. 3), where we have sublinear drift level, we get that ARCOR outperforms LASER since it is especially designed for sublinear amount of data drift, yet, H\u221e outperforms ARCOR when there is no noise (top-right plot).\nFor the third and fourth datasets (bottom plots of Fig. 3), where we added noise to labels, the performance of H\u221e degrades, as expected from our discussion in Sec. 5."}, {"heading": "7 Related Work", "text": "The problem of performing online regression was studied for more than fifty years in statistics, signal processing and machine learning. We already mentioned the work of Widrow and Hoff [37] who studied a gradient descent algorithm for the squared loss. Many variants of the algorithm were studied since then. A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input\u2019s scale.\nThere exists a large body of work on this problem proposed by the machine learning community, which clearly cannot be covered fully here. We refer the reader to a encyclopedic book in the subject [10]. Gradient descent based algorithms for regression with the squared loss were proposed by Cesa-Bianchi et al. [8] about two decades ago. These algorithms were generalized and extended by Kivinen and Warmuth [24] using additional regularization functions.\nAn online version of the ridge regression algorithm in the worst-case setting was proposed and analyzed by Foster [18]. A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36]. The recursive least squares (RLS) [21] is a similar algorithm proposed for adaptive filtering. Both algorithms make use\nof second order information, as they maintain a weightvector and a covariance-like positive semi-definite (PSD) matrix used to re-weight the input. The eigenvalues of this covariance-like matrix increase with time t, a property which is used to prove logarithmic regret bounds.\nThe derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29]. These algorithms are motivated from the last-step min-max predictor. While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting. Moroshko and Crammer [29] also discussed a weak variant of the non-stationary setting, where the complexity is measured by the total distance from a reference vector u\u0304, rather than the total distance of consecutive vectors (as in this paper), which is more relevant to non-stationary problems. Note also that Moroshko and Crammer [29] did not derive algorithms for the nonstationary setting, but just show a bound of the weighted min-max algorithm (designed for the stationary setting) in the weak non-stationary setting.\nOur work is mostly close to a recent algorithm [35] called ARCOR. This algorithm is based on the RLS algorithm with an additional projection step, and it controls the eigenvalues of a covariance-like matrix using scheduled resets. The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively. All of these algorithms that were designed to have numerically stable computations, perform covariance reset from time to time. Our algorithm, LASER, is simpler as it does not involve these steps, and it controls the increase of the eigenvalues of the covariance matrix D implicitly rather than explicitly by \u201caveraging\u201d it with a fixed diagonal matrix (see (7)). The Kalman filter [23] and the H\u221e algorithm (e.g. [33]) designed for filtering take a similar approach, yet the exact algebraic form is different (Fig. 1 vs. Fig. 2).\nARCOR also controls explicitly the norm of the weight vector, which is used for its analysis, by projecting it into a bounded set, as was also proposed by Herbster and Warmuth [22]. Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7]. Some of these algorithms were designed to have sparse functions in the kernel space (e.g. [13, 15]). Note that our algorithm LASER is simpler as it does not perform any of these operation explicitly. Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28]."}, {"heading": "8 Summary and Conclusions", "text": "We proposed a novel algorithm for non-stationary online regression designed and analyzed with the squared loss. The algorithm was developed from the last-step minmax predictor for non-stationary problems, and we showed an exact recursive form of its solution. We also described an algorithm based on the H\u221e filter, that is motivated from a min-max approach as well, yet for filtering, and bounded its regret. Simulations showed its superior performance in a worst-case (close to a constant per iteration) drift.\nAn interesting future direction is to extend the algorithm for general loss functions rather than the squared loss. Currently, to implement the algorithm we need to perform either matrix inversion or eigenvector decomposition, we like to design a more efficient version of the algorithm. Additionally, for the algorithm to perform well, the amount of drift V or a bound over it are used by the algorithm. An interesting direction is to design algorithms that automatically detect the level of drift, or are invariant to it."}, {"heading": "A Proofs", "text": ""}, {"heading": "A.1 Proof of Corollary 8", "text": "Proof. Plugging Lem. 5 in Thm. 4 we have for all (u1 . . .uT ),\nLT (LASER) \u2264 b \u2016u1\u20162 + cV + LT ({ut})\n+ Y 2 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ c\u22121Y 2 T\u2211\nt=1\nTr (Dt\u22121) .\nUsing Lem. 7 we bound the RHS and get\nLT (LASER) \u2264 b \u2016u1\u20162 + LT ({ut}) + Y 2 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223 +c\u22121Y 2Tr (D0) + cV\n+c\u22121Y 2Tdmax\n{ 3X2 + \u221a X4 + 4X2c\n2 , b+X2\n} .\nThe term c\u22121Y 2Tr (D0) does not depend on T , because c\u22121Y 2Tr (D0) = c \u22121Y 2d bcc\u2212b = \u03b5 1\u2212\u03b5Y 2d . To show (21), note that V \u2264 T \u221a 2Y 2dX \u00b53/2 \u21d4 \u00b5 \u2264 (\u221a 2Y 2dXT V )2/3 =\nc . We thus have that ( 3X2 + \u221a X4 + 4X2c ) /2 \u2264(\n3X2 + \u221a 8X2c ) /2 \u2264 \u221a 8X2c, and we get a bound on\nthe right term of (19),\nmax {( 3X2 + \u221a X4 + 4X2c ) /2, b+X2 } \u2264\nmax {\u221a 8X2c, b+X2 } \u2264 2X \u221a 2c .\nUsing this bound and plugging the value of c from (20) we bound (19) and conclude the proof, (\u221a 2TY 2dX\nV\n)2/3 V + Y 2Td2X \u221a\u221a\u221a\u221a2(\u221a2TY 2dX V )\u22122/3 = 3 (\u221a 2TY 2dX )2/3 V 1/3 ."}, {"heading": "SUPPLEMENTARY MATERIAL", "text": ""}, {"heading": "B.1 Proof of Lem. 1", "text": "Proof. We calculate\nPt (ut) = min u1,...,ut\u22121\n( b \u2016u1\u20162 + c\nt\u22121\u2211 s=1 \u2016us+1 \u2212 us\u20162\n+ t\u2211 s=1 ( ys \u2212 u>s xs\n)2)\n= min ut\u22121 min u1,...,ut\u22122\n( b \u2016u1\u20162 + c\nt\u22122\u2211 s=1 \u2016us+1 \u2212 us\u20162\n+ t\u22121\u2211 s=1 ( ys \u2212 u>s xs )2 + c \u2016ut \u2212 ut\u22121\u20162\n+ ( yt \u2212 u>t xt\n)2)\n= min ut\u22121\n( Pt\u22121 (ut\u22121) + c \u2016ut \u2212 ut\u22121\u20162\n+ ( yt \u2212 u>t xt\n)2)"}, {"heading": "B.2 Proof of Lem. 2", "text": "Proof. By definition, P1 (u1) = Q1 (u1) = b \u2016u1\u20162 +( y1 \u2212 u>1 x1 )2 = u>1 ( bI + x1x > 1 ) u1 \u2212 2y1u>1 x1 + y21 , and indeed D1 = bI + x1x>1 , e1 = y1x1, and f1 = y 2 1 . We proceed by induction, assume that, Pt\u22121 (ut\u22121) = u>t\u22121Dt\u22121ut\u22121 \u2212 2u>t\u22121et\u22121 + ft\u22121. Applying Lem. 1\nwe get,\nPt (ut) = min ut\u22121\n( u>t\u22121Dt\u22121ut\u22121 \u2212 2u>t\u22121et\u22121 + ft\u22121\n+ c \u2016ut \u2212 ut\u22121\u20162 + ( yt \u2212 u>t xt\n)2)\n= min ut\u22121\n( u>t\u22121 (cI + Dt\u22121)ut\u22121\n\u2212 2u>t\u22121 (cut + et\u22121) + ft\u22121 + c \u2016ut\u2016 2\n+ ( yt \u2212 u>t xt )2) =\u2212 (cut + et\u22121)> (cI + Dt\u22121)\u22121 (cut + et\u22121)\n+ ft\u22121 + c \u2016ut\u20162 + ( yt \u2212 u>t xt )2 =u>t ( cI + xtx > t \u2212 c2 (cI + Dt\u22121) \u22121 ) ut\n\u2212 2u>t [ c (cI + Dt\u22121) \u22121 et\u22121 + ytxt ] \u2212 e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 + ft\u22121 + y 2 t\nUsing Woodbury identity we continue to develop the last equation,\n=u>t ( cI + xtx > t\n\u2212c2 [ c\u22121I\u2212 c\u22122 ( D\u22121t\u22121 + c \u22121I )\u22121]) ut\n\u2212 2u>t [( I + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt ] \u2212 e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 + ft\u22121 + y 2 t\n=u>t (( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t ) ut\n\u2212 2u>t [( I + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt ] \u2212 e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 + ft\u22121 + y 2 t ,\nand indeed Dt = ( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t ,\net = ( I + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt and, ft = ft\u22121 \u2212 e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 + y 2 t , as desired."}, {"heading": "B.3 Proof of Lem. 3", "text": "Proof. We first use the Woodbury equation to get the following two identities\nD\u22121t = [( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t ]\u22121 = D\u22121t\u22121 + c \u22121I\n\u2212 ( D\u22121t\u22121 + c \u22121I ) xtx > t ( D\u22121t\u22121 + c \u22121I )\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\nand ( I + c\u22121Dt\u22121 )\u22121 = I\u2212 c\u22121 ( D\u22121t\u22121 + c \u22121I )\u22121\nMultiplying both identities with each other we get, D\u22121t ( I + c\u22121Dt\u22121 )\u22121 = [ D\u22121t\u22121 + c \u22121I\n\u2212 ( D\u22121t\u22121 + c \u22121I ) xtx > t ( D\u22121t\u22121 + c \u22121I )\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n][ I\n\u2212 c\u22121 ( D\u22121t\u22121 + c \u22121I )\u22121 ]\n= D\u22121t\u22121 \u2212 ( D\u22121t\u22121 + c \u22121I ) xtx > t D \u22121 t\u22121\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n(24)\nand, similarly, we multiply the identities in the other order and get, (\nI + c\u22121Dt\u22121 )\u22121 D\u22121t\n= D\u22121t\u22121 \u2212 D\u22121t\u22121xtx > t\n( D\u22121t\u22121 + c \u22121I )\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n(25)\nFinally, from (24) we get,( I + c\u22121Dt\u22121 )\u22121 D\u22121t xtx > t D \u22121 t ( I + c\u22121Dt\u22121 )\u22121 \u2212D\u22121t\u22121 + ( I + c\u22121Dt\u22121 )\u22121 [ D\u22121t ( I + c\u22121Dt\u22121\n)\u22121 +c\u22121I\n] = ( I + c\u22121Dt\u22121 )\u22121 D\u22121t xtx > t D \u22121 t ( I + c\u22121Dt\u22121\n)\u22121 \u2212D\u22121t\u22121\n+ [ I\u2212 c\u22121 ( D\u22121t\u22121 + c \u22121I )\u22121] [ D\u22121t\u22121 + c \u22121I \u2212 ( D\u22121t\u22121 + c \u22121I ) xtx > t D \u22121 t\u22121\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt ] We develop the last equality and use (24) and (25) in the second equality below,\n= ( I + c\u22121Dt\u22121 )\u22121 D\u22121t xtx > t D \u22121 t ( I + c\u22121Dt\u22121 )\u22121 \u2212D\u22121t\u22121 + D \u22121 t\u22121 \u2212 D\u22121t\u22121xtx > t D \u22121 t\u22121\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n= [ D\u22121t\u22121 \u2212 D\u22121t\u22121xtx > t ( D\u22121t\u22121 + c \u22121I )\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt ] xtx > t[\nD\u22121t\u22121 \u2212 ( D\u22121t\u22121 + c \u22121I ) xtx > t D \u22121 t\u22121\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n]\n\u2212 D\u22121t\u22121xtx > t D \u22121 t\u22121 1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt\n= \u2212 x>t ( D\u22121t\u22121 + c \u22121I ) xtD \u22121 t\u22121xtx > t D \u22121 t\u22121(\n1 + x>t ( D\u22121t\u22121 + c \u22121I ) xt )2 0"}, {"heading": "B.4 Derivations for Thm. 4", "text": "(yt \u2212 y\u0302t)2 + min u1,...,ut\u22121 Qt\u22121 (u1, . . . ,ut\u22121)\n\u2212 min u1,...,ut Qt (u1, . . . ,ut)\n= (yt \u2212 y\u0302t)2 \u2212 e>t\u22121D\u22121t\u22121et\u22121 + ft\u22121 + e>t D \u22121 t et \u2212 ft = (yt \u2212 y\u0302t)2 \u2212 e>t\u22121D\u22121t\u22121et\u22121 + e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 \u2212 y2t\n+ (( I + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt )> D\u22121t((\nI + c\u22121Dt\u22121 )\u22121 et\u22121 + ytxt ) where the last equality follows (8). We proceed to develop the last equality,\n= (yt \u2212 y\u0302t)2 \u2212 e>t\u22121D\u22121t\u22121et\u22121 + e>t\u22121 (cI + Dt\u22121) \u22121 et\u22121 \u2212 y2t\n+ e>t\u22121 ( I + c\u22121Dt\u22121 )\u22121 D\u22121t ( I + c\u22121Dt\u22121 )\u22121 et\u22121\n+ 2ytx > t D \u22121 t ( I + c\u22121Dt\u22121 )\u22121 et\u22121 + y 2 t x > t D \u22121 t xt\n= (yt \u2212 y\u0302t)2 + e>t\u22121 ( \u2212D\u22121t\u22121+(\nI + c\u22121Dt\u22121 )\u22121 [ D\u22121t ( I + c\u22121Dt\u22121 )\u22121 +c\u22121I ]) et\u22121 + 2ytx > t D \u22121 t ( I + c\u22121Dt\u22121 )\u22121 et\u22121\n+ y2t x > t D \u22121 t xt \u2212 y2t .\nB.5 Details for the bound (22)\nTo show the bound (22), note that, V \u2265 T Y 2dM \u00b52 \u21d4 \u00b5 \u2265\u221a\nTY 2dM V = c . We thus have that the right term of (19) is\nupper bounded as follows,\nmax\n{ 3X2 + \u221a X4 + 4X2c\n2 , b+X2 } \u2264max { 3X2, \u221a X4 + 4X2c, b+X2\n} \u2264max { 3X2, \u221a 2X2, \u221a 8X2c, b+X2\n} = \u221a 8X2 max\n{ 3X2\u221a 8X2 , \u221a c, b+X2\u221a 8X2 }\n= \u221a 8X2 \u221a\u221a\u221a\u221amax{ (3X2)2 8X2 , c, (b+X2) 2 8X2 } = \u221a 8X2 \u221a max {\u00b5, c} \u2264 \u221a 8X2 \u221a \u00b5 = M .\nUsing this bound and plugging c = \u221a Y 2dMT/V\nwe bound (19), \u221a\nY 2dMT V V + 1\u221a Y 2dMT\nV\nTdY 2M =\n2 \u221a Y 2dMTV ."}, {"heading": "B.6 Proof of Lem. 6", "text": "Proof. For the first property of the lemma we have that f(\u03bb) = \u03bb\u03b2/ (\u03bb+ \u03b2) + x2 \u2264 \u03b2 \u00d7 1 + x2. The second property follows from the symmetry between \u03b2 and \u03bb. To prove the third property we decompose the function as, f(\u03bb) = \u03bb\u2212 \u03bb 2\n\u03bb+\u03b2 + x 2. Therefore, the function is bounded\nby its argument f(\u03bb) \u2264 \u03bb if, and only if, \u2212 \u03bb 2\n\u03bb+\u03b2 + x 2 \u2264 0.\nSince we assume x2 \u2264 \u03b32, the last inequality holds if, \u2212\u03bb2+\u03b32\u03bb+\u03b32\u03b2 \u2264 0, which holds for \u03bb \u2265 \u03b3 2+ \u221a \u03b34+4\u03b32\u03b2\n2 .\nTo conclude. If \u03bb \u2265 \u03b3 2+ \u221a \u03b34+4\u03b32\u03b2\n2 , then f(\u03bb) \u2264 \u03bb. Otherwise, by the second property, we have, f(\u03bb) \u2264 \u03bb + \u03b32 \u2264 \u03b32+ \u221a \u03b34+4\u03b32\u03b2\n2 + \u03b3 2 =\n3\u03b32+ \u221a \u03b34+4\u03b32\u03b2\n2 , as required."}], "references": [{"title": "Tracking the best disjunction", "author": ["P. Auer", "M. Warmuth"], "venue": "Electronic Colloquium on Computational Complexity (ECCC),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Relative loss bounds for on-line density estimation with the exponential family of distributions", "author": ["K. Azoury", "M. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Analysis of the normalized lms algorithm with gaussian inputs", "author": ["N.J. Bershad"], "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1986}, {"title": "Performance of adaptive estimation algorithms in dependent random environments", "author": ["R.R. Bitmead", "B.D.O. Anderson"], "venue": "IEEE Trans. on Automatic Control,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1980}, {"title": "Online regression competitive with changing predictors", "author": ["S. Busuttil", "Y. Kalnishkan"], "venue": "In ALT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Tracking the best hyperplane with a simple budget perceptron", "author": ["G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Worst case quadratic loss bounds for on-line prediction of linear functions by gradient descent", "author": ["N. Ceas-Bianchi", "P.M. Long", "M.K. Warmuth"], "venue": "IEEE Tran. on NN,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "A second-order perceptron algorithm", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "Siam Journal of Commutation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Application of the least squares algorithm to the observer design for linear time-varying systems", "author": ["M.-S. Chen", "J.-Y. Yen"], "venue": "Automatic Control, IEEE Tran. on,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Confidenceweighted linear classification for text categorization", "author": ["K. Crammer", "M. Dredze", "F. Pereira"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Online classification on a budget", "author": ["K. Crammer", "J. Kandola", "Y. Singer"], "venue": "In NIPS,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Adaptive regularization of weighted vectors", "author": ["K. Crammer", "A. Kulesza", "M. Dredze"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "The forgetron: A kernel-based perceptron on a fixed budget", "author": ["O. Dekel", "S. Shalev-shwartz", "Y. Singer"], "venue": "In NIPS", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "In COLT,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "On relative loss bounds in generalized linear regression", "author": ["J. Forster"], "venue": "In Fundamentals of Computation Theory (FCT),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1999}, {"title": "Prediction in the worst case", "author": ["D. Foster"], "venue": "The Annals of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1991}, {"title": "Logical covariance matrix reset in self-tuning control", "author": ["S. Goodhart", "K. Burnham", "D. James"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1991}, {"title": "Aggregating strategies", "author": ["V.G.Vovk"], "venue": "Proceedings of the Third Annual Workshop on Computational Learning Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1990}, {"title": "Recursive least squares", "author": ["M. Hayes"], "venue": "In Statistical Digital Signal Processing and Modeling,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1996}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M. Warmuth"], "venue": "JMLR, 1:281\u2013309,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2001}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Transactions of the ASME\u2013 Journal of Basic Engineering,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1960}, {"title": "Exponential gradient versus gradient descent for linear predictors", "author": ["J. Kivinen", "M.K.Warmuth"], "venue": "Information and Computation,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Online learning with kernels", "author": ["J. Kivinen", "A. Smola", "R. Williamson"], "venue": "In NIPS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "The pnorm generalization of the lms algorithm for adaptive filtering", "author": ["J. Kivinen", "M.K. Warmuth", "B. Hassibi"], "venue": "In Proc. 13th IFAC Symposium on System Identification,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "Inf. Comput.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1994}, {"title": "Adaptive bound optimization for online convex optimization", "author": ["H.B. McMahan", "M.J. Streeter"], "venue": "In COLT,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Weighted last-step min-max algorithm with improved sub-logarithmic regret", "author": ["E. Moroshko", "K. Crammer"], "venue": "In The 23nd International Conference on Algorithmic Learning Theory, ALT", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Modified least squares algorithm incorporating exponential resetting and forgetting", "author": ["M. Salgado", "G. Goodwin", "R. Middleton"], "venue": "International J. of Control,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1988}, {"title": "Adaptive Filters", "author": ["A.H. Sayed"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2008}, {"title": "A game theory approach to constrained minimax state estimation", "author": ["D. Simon"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2006}, {"title": "Optimal State Estimation: Kalman, H Infinity, and Nonlinear Approaches", "author": ["D. Simon"], "venue": "Wiley- Interscience,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2006}, {"title": "The last-step minimax algorithm", "author": ["E. Takimoto", "M. Warmuth"], "venue": "In ALT,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2000}, {"title": "Re-adapting the regularization of weights for non-stationary regression", "author": ["N. Vaits", "K. Crammer"], "venue": "In ALT,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Competitive on-line statistics", "author": ["V. Vovk"], "venue": "International Statistical Review,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2001}, {"title": "Adaptive switching circuits. In Institute of Radio Engineers, Western Electronic Show and Convention", "author": ["B. Widrow", "M.E. Hoff"], "venue": "Convention Record, Part", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1960}], "referenceMentions": [{"referenceID": 8, "context": "the topic [10]) for this problem, some of which are able to achieve an average loss arbitrarily close to that of the best function in retrospect.", "startOffset": 10, "endOffset": 14}, {"referenceID": 25, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 0, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 20, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 23, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 25, "endOffset": 40}, {"referenceID": 23, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 199, "endOffset": 203}, {"referenceID": 5, "context": "Some previous algorithms [27, 1, 22, 25] designed for this problem are based on gradient descent, with additional control on the norm (or Bregman divergence) of the weight-vector used for prediction [25], or the number of inputs used to define it [7].", "startOffset": 247, "endOffset": 250}, {"referenceID": 15, "context": "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.", "startOffset": 110, "endOffset": 114}, {"referenceID": 32, "context": "We take a different route and derive an algorithm based on the last-step min-max approach proposed by Forster [17] and later used [34] for online density estimation.", "startOffset": 130, "endOffset": 134}, {"referenceID": 33, "context": "stantaneous drift is close to constant, this improves over a previous bound of Vaits and Crammer [35] of an algorithm named ARCOR that showed a bound of T\u03bd log(T ).", "startOffset": 97, "endOffset": 101}, {"referenceID": 15, "context": "Additionally, when no drift is introduced (stationary setting) our algorithm suffers logarithmic regret, as for the algorithm of Forster [17].", "startOffset": 137, "endOffset": 141}, {"referenceID": 15, "context": "To solve it, we follow an approach used by Forster in a different context [17].", "startOffset": 74, "endOffset": 78}, {"referenceID": 15, "context": "This problem is of a similar form to the one discussed by Forster [17], from which we get the optimal solution, \u0177T = clip ( xTD \u22121 T ( I + cDT\u22121 )\u22121 eT\u22121, Y ) , where for y > 0 we define clip(x, y) = sign(x) min{|x|, y}.", "startOffset": 66, "endOffset": 70}, {"referenceID": 34, "context": "Clearly, for c = \u221e the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].", "startOffset": 76, "endOffset": 80}, {"referenceID": 15, "context": "Clearly, for c = \u221e the LASER algorithm reduces to the AAR algorithm of Vovk [36], or the last-step min-max algorithm of Forster [17].", "startOffset": 128, "endOffset": 132}, {"referenceID": 1, "context": "See also the work of Azoury and Warmuth [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 1, "context": "This algorithm can be seen also as a forward algorithm [2]: The predictor of (14) can be seen as the optimal linear model obtained over the same prefix of length T \u2212 1 and the new input xT with fictional-label yT = 0.", "startOffset": 55, "endOffset": 58}, {"referenceID": 15, "context": "Similar to the derivation of Forster [17] (details omitted due to lack of space),", "startOffset": 37, "endOffset": 41}, {"referenceID": 34, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 15, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 19, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 7, "context": "First, when the total drift V = 0 goes to zero, we set c = \u221e and thus we have Dt = bI + \u2211t s=1 xsx > s used in recent algorithms [36, 17, 21, 9].", "startOffset": 129, "endOffset": 144}, {"referenceID": 15, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 63, "endOffset": 67}, {"referenceID": 34, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 15, "context": "In this case the algorithm reduces to the algorithm by Forster [17] (which is also the Aggregating Algorithm for Regression of Vovk [36]), with the same logarithmic regret bound (note that the last term of (21) is logarithmic in T , see the proof of Forster [17]).", "startOffset": 258, "endOffset": 262}, {"referenceID": 1, "context": "See also the work of Azoury and Warmuth [2].", "startOffset": 40, "endOffset": 43}, {"referenceID": 33, "context": "Third, Vaits and Crammer [35] recently proposed an algorithm, called ARCOR, for the same setting.", "startOffset": 25, "endOffset": 29}, {"referenceID": 33, "context": "Therefore, in this case the bound of ARCOR [35] is \u03bdT log(T ) which is worse than our bound, both since it has an additional log(T ) factor (as opposed to our additive log term) and since \u03bd = o(1).", "startOffset": 43, "endOffset": 47}, {"referenceID": 33, "context": "Therefore we expect that our algorithm will perform better than ARCOR [35] when the instantaneous drift is approximately constant.", "startOffset": 70, "endOffset": 74}, {"referenceID": 20, "context": "Fourth, Herbster and Warmuth [22] developed shifting bounds for general gradient descent algorithms with projection of the weight-vector using the Bregman divergence.", "startOffset": 29, "endOffset": 33}, {"referenceID": 4, "context": "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.", "startOffset": 24, "endOffset": 27}, {"referenceID": 18, "context": "Busuttil and Kalnishkan [6] developed a variant of the Aggregating Algorithm [20] for the non-stationary setting.", "startOffset": 77, "endOffset": 81}, {"referenceID": 35, "context": "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].", "startOffset": 52, "endOffset": 56}, {"referenceID": 29, "context": "For example, a well known online learning algorithm [37] for regression, which is basically a gradient-descent algorithm with the squared-loss, is known as the least mean-square (LMS) algorithm in the adaptive filtering literature [31].", "startOffset": 231, "endOffset": 235}, {"referenceID": 31, "context": "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.", "startOffset": 16, "endOffset": 24}, {"referenceID": 30, "context": "papers by Simon [33, 32]) are a family of (robust) linear filters developed based on a min-max approach, like LASER, and analyzed in the worst case setting.", "startOffset": 16, "endOffset": 24}, {"referenceID": 21, "context": "These filters are reminiscent of the celebrated Kalman filter [23], which was motivated and analyzed in a stochastic setting with Gaussian noise.", "startOffset": 62, "endOffset": 66}, {"referenceID": 24, "context": "[26] proposed another approach for filtering with a bound depending on \u2211 t \u2016ut\u2212ut\u22121\u2016 and not the sum of squares as we have both for LASER and the H\u221e-based algorithm.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 64, "endOffset": 70}, {"referenceID": 3, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 64, "endOffset": 70}, {"referenceID": 12, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 150, "endOffset": 154}, {"referenceID": 33, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 162, "endOffset": 166}, {"referenceID": 9, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 175, "endOffset": 183}, {"referenceID": 28, "context": "We compared six algorithms: NLMS (normalized least mean square) [3, 5] which is a state-of-the-art first-order algorithm, AROWR (AROW for Regression) [14], ARCOR [35], CR-RLS [11, 30], LASER and H\u221e.", "startOffset": 175, "endOffset": 183}, {"referenceID": 35, "context": "We already mentioned the work of Widrow and Hoff [37] who studied a gradient descent algorithm for the squared loss.", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input\u2019s scale.", "startOffset": 72, "endOffset": 78}, {"referenceID": 2, "context": "A notable example is the normalized least mean squares algorithm (NLMS) [5, 3] that adapts to the input\u2019s scale.", "startOffset": 72, "endOffset": 78}, {"referenceID": 8, "context": "We refer the reader to a encyclopedic book in the subject [10].", "startOffset": 58, "endOffset": 62}, {"referenceID": 6, "context": "[8] about two decades ago.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "These algorithms were generalized and extended by Kivinen and Warmuth [24] using additional regularization functions.", "startOffset": 70, "endOffset": 74}, {"referenceID": 16, "context": "An online version of the ridge regression algorithm in the worst-case setting was proposed and analyzed by Foster [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 18, "context": "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].", "startOffset": 74, "endOffset": 78}, {"referenceID": 34, "context": "A related algorithm called Aggregating Algorithm (AA) was studied by Vovk [20], and later applied to the problem of linear regression with square loss [36].", "startOffset": 151, "endOffset": 155}, {"referenceID": 19, "context": "The recursive least squares (RLS) [21] is a similar algorithm proposed for adaptive filtering.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].", "startOffset": 77, "endOffset": 81}, {"referenceID": 27, "context": "The derivation of our algorithm shares similarities with the work of Forster [17] and the work of Moroshko and Crammer [29].", "startOffset": 119, "endOffset": 123}, {"referenceID": 15, "context": "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "While the algorithms of Forster [17] and Moroshko and Crammer [29] are designed for the stationary setting, our work is primarily designed for the nonstationary setting.", "startOffset": 62, "endOffset": 66}, {"referenceID": 27, "context": "Moroshko and Crammer [29] also discussed a weak variant of the non-stationary setting, where the complexity is measured by the total distance from a reference vector \u016b, rather than the total distance of consecutive vectors (as in this paper), which is more relevant to non-stationary problems.", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "Note also that Moroshko and Crammer [29] did not derive algorithms for the nonstationary setting, but just show a bound of the weighted min-max algorithm (designed for the stationary setting) in the weak non-stationary setting.", "startOffset": 36, "endOffset": 40}, {"referenceID": 33, "context": "Our work is mostly close to a recent algorithm [35] called ARCOR.", "startOffset": 47, "endOffset": 51}, {"referenceID": 9, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 28, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 17, "context": "The Covariance Reset RLS algorithm (CR-RLS) [11, 30, 19] is another example of an algorithm that resets a covariance matrix but every fixed amount of data points, as opposed to ARCOR that performs these resets adaptively.", "startOffset": 44, "endOffset": 56}, {"referenceID": 21, "context": "The Kalman filter [23] and the H\u221e algorithm (e.", "startOffset": 18, "endOffset": 22}, {"referenceID": 31, "context": "[33]) designed for filtering take a similar approach, yet the exact algebraic form is different (Fig.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "ARCOR also controls explicitly the norm of the weight vector, which is used for its analysis, by projecting it into a bounded set, as was also proposed by Herbster and Warmuth [22].", "startOffset": 176, "endOffset": 180}, {"referenceID": 23, "context": "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].", "startOffset": 71, "endOffset": 75}, {"referenceID": 5, "context": "Other approaches to control its norm are to shrink it multiplicatively [25] or by removing old examples [7].", "startOffset": 104, "endOffset": 107}, {"referenceID": 11, "context": "[13, 15]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "[13, 15]).", "startOffset": 0, "endOffset": 8}, {"referenceID": 7, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 12, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 10, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 103, "endOffset": 114}, {"referenceID": 14, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 169, "endOffset": 177}, {"referenceID": 26, "context": "Finally, few algorithms that employ second order information were recently proposed for classification [9, 14, 12], and later in the online convex programming framework [16, 28].", "startOffset": 169, "endOffset": 177}], "year": 2013, "abstractText": "The goal of a learner in standard online learning is to maintain an average loss close to the loss of the best-performing single function in some class. In many real-world problems, such as rating or ranking items, there is no single best target function during the runtime of the algorithm, instead the best (local) target function is drifting over time. We develop a novel last-step minmax optimal algorithm in context of a drift. We analyze the algorithm in the worst-case regret framework and show that it maintains an average loss close to that of the best slowly changing sequence of linear functions, as long as the total of drift is sublinear. In some situations, our bound improves over existing bounds, and additionally the algorithm suffers logarithmic regret when there is no drift. We also build on the H\u221e filter and its bound, and develop and analyze a second algorithm for drifting setting. Synthetic simulations demonstrate the advantages of our algorithms in a worst-case constant drift setting.", "creator": "LaTeX with hyperref package"}}}