{"id": "1306.0963", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2013", "title": "Inferring Robot Task Plans from Human Team Meetings: A Generative Modeling Approach with Logic-Based Prior", "abstract": "we aim to fundamentally reduce precisely the burden stress of rapid programming and deploying autonomous decision systems to work closely in concert with people in time - critical domains, such as military field operations and disaster response. deployment protocol plans for these operations are frequently negotiated on - the - fly by teams of human planners. a human operator then translates the agreed upon plan into machine instructions for the robots. we present an algorithm itself that indirectly reduces this translation burden by inferring clearly the final plan from a processed form of the human command team's planning conversation. our approach combines probabilistic generative modeling with enhanced logical path plan validation used to compute a highly structured prior over possible plans. this hybrid approach enables enable us attempting to overcome the challenge of performing inference over the associated large solution space with only maintaining a small amount of noisy data from the team planning session. we validate the algorithm through human subject experimentation and show we are able to infer either a human team's final plan with 83 % accuracy on professional average. we also describe a robot demonstration in which two normal people plan and execute a first - response collaborative task with a pr2 robot. to share the best of our knowledge, this is the first work that integrates a logical planning technique within a full generative model to perform plan diagram inference.", "histories": [["v1", "Wed, 5 Jun 2013 02:17:11 GMT  (182kb,D)", "http://arxiv.org/abs/1306.0963v1", "Appears in Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI-13)", "reviews": [], "SUBJECTS": "cs.AI cs.CL cs.RO stat.ML", "authors": ["been kim", "caleb m chacha", "julie a shah"], "accepted": true, "id": "1306.0963"}, "pdf": {"name": "1306.0963.pdf", "metadata": {"source": "CRF", "title": "Inferring Robot Task Plans from Human Team Meetings: A Generative Modeling Approach with Logic-Based Prior", "authors": ["Been Kim", "Caleb M. Chacha", "Julie Shah"], "emails": ["julie_a_shah}@csail.mit.edu"], "sections": [{"heading": "Introduction", "text": "Robots are increasingly introduced to work in concert with people in high-intensity domains, such as military field operations and disaster response. They have been deployed to gain access to areas that are inaccessible to people (Casper and Murphy 2003; Micire 2002), and to inform situation assessment (Larochelle et al. 2011). The human-robot interface has long been identified as a major bottleneck in utilizing these robotic systems to their full potential (Murphy 2004). As a result, we have seen significant research efforts aimed at easing the use of these systems in the field, including careful design and validation of supervisory and control interfaces (Jones et al. 2002; Cummings, Brzezinski, and Lee 2007; Barnes et al. 2011; Goodrich et al. 2009). Much of this prior work has focused on ease of use at \u201cexecution time.\u201d However, a significant bottleneck also exists\nCopyright c\u00a9 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nin planning the deployments of autonomous systems and in programming these systems to coordinate their task execution with the rest of the human team. Deployment plans are frequently negotiated by human team members on-thefly and under time pressure (Casper and Murphy 2002; Casper and Murphy 2003). For a robot to execute part of this plan, a human operator must transcribe and translate the result of the team planning session.\nIn this paper we present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human team\u2019s planning conversation. Our approach combines probabilistic generative modeling with logical plan validation which is used to compute a highly structured prior over possible plans. This hybrid approach enables us to overcome the challenge of performing inference over the large solution space with only a small amount of noisy data from the team planning session.\nRather than working with raw natural language, our algorithm takes as input a structured form of the human dialog. Processing human dialogue into more machine understandable forms is an important research area (Kruijff, Jan\u0131cek, and Lison 2010; Tellex et al. 2011; Koomen et al. 2005; Palmer, Gildea, and Xue 2010; Pradhan et al. 2004), but we view this as a separate problem and do not focus on it in this paper.\nThe form of input we use preserves many of the challenging aspects of natural human planning conversations and can be thought of as very \u2018noisy\u2019 observations of the final plan. Because the team is discussing the plan under time pressure, the planning sessions often consist of a small number of succinct communications. Our approach reliably infers the majority of final agreed upon plan, despite the small amount of noisy data.\nWe validate the algorithm through human subject experimentation and show we are able to infer a human team\u2019s final plan with 83% accuracy on average. We also describe a robot demonstration in which two people plan and execute a first-response collaborative task with a PR2 robot. To the best of our knowledge, this is the first work that integrates a logical planning technique within a generative model to perform plan inference.\nar X\niv :1\n30 6.\n09 63\nv1 [\ncs .A\nI] 5\nJ un\n2 01\n3"}, {"heading": "Problem Formulation", "text": "Disaster response teams are increasingly utilizing webbased planning tools to plan their deployments (Di Ciaccio, Pullen, and Breimyer 2011). Dozens to hundreds of responders log in to plan their deployment using audio/video conferencing, text chat, and annotatable maps. In this work, we focus on inferring the final plan using the text data that can be logged from chat or transcribed speech. This section formally describes our problem formulation, including the inputs and outputs of our inference algorithm."}, {"heading": "Planning Problem", "text": "A plan consists of a set of actions together with execution timestamps associated with those actions. A plan is valid if it achieves a user-specified goal state without violating userspecified plan constraints. In our work, the full set of possible actions is not necessarily specified apriori and actions may also be derived from the dialog.\nActions may be constrained to execute in sequence or in parallel with other actions. Other plan constraints include discrete resource constraints (e.g. there are two medical teams), and temporal deadlines on time durative actions (e.g. a robot can be deployed for up to one hour at a time due to battery life constraints). Formally, we assume our planning problem may be represented in Planning Domain Description Language (PDDL) 2.1.\nIn this paper, we consider a fictional rescue scenario that involves a radioactive material leakage accident in a building with multiple rooms, as shown in Figure 1. This is the scenario we use in human subject experiments for proof-ofconcept of our approach. A room either has a patient that needs to be assessed in person or a valve that needs to be fixed. The scenario is specified by the following information. Goal State: All patients are assessed in person by a medical crew. All valves are fixed by a mechanic. All rooms are inspected by a robot. Constraints: For safety, the radioactivity of a room must be inspected by a robot before human crews can be sent to the room (sequence constraint). There are two medical crews, red and blue (discrete resource constraint). There is one human mechanic (discrete resource constraint). There are two robots, red and blue (discrete resource constraint). Assumption: All tasks (e.g. inspecting a room, fixing a valve) take the same unit of time and there are no hard temporal constraints in the plan. This assumption was made to conduct the initial proof-of-concept experimentation described in this paper. However, the technical approach readily generalizes to variable task durations and temporal constraints, as described later.\nThe scenario produces a very large number of possible plans (more than 1012), many of which are valid for achieving the goals without violating the constraints.\nWe assume that the team reaches an agreement on a final plan. Techniques introduced by (Kim, Bush, and Shah 2013) can be used to detect the strength of agreement, and encourage the team to discuss further to reach an agreement if necessary. We leave for future study the situation where\nthe team agrees on a flexible plan with multiple options to be decided among later. While we assume that the team is more likely to agree on a valid plan, we do not rule out the possibility that the final plan is invalid.\nAlgorithm Input Text data from the human team conversation is collected in the form of utterances, where each utterance is one person\u2019s turn in the discussion, as shown in Table 1. The input to our algorithm is a machine understandable form of human conversation data, as illustrated in the right-hand column of Table 1. This structured form captures the actions discussed and the proposed ordering relations among actions for each utterance.\nAlthough we are not working with raw natural language, this form of data still captures many of the characteristics that make plan inference based on human conversation challenging. Table 1 shows part of the data, using the following short-hand:\nST = SendTo rr = red robot, br = blue robot rm = red medical, bm = blue medical e.g. ST(br, A) = SendTo(blue robot, room A)\nUtterance tagging An utterance is tagged as an ordered tuple of sets of grounded predicates. Each predicate represents an action applied to a set of objects (crew member, robot, room, etc.), as is the standard definition of a dynamic predicate in PDDL. Each set of grounded predicates represents a collection of actions that, according to the utterance, should happen in parallel. The order of the sets of grounded predicates indicates the relative order in which these collections of actions should happen. For example, ({ST(rr, B), ST(br, G)}, {ST(rm, B)}) corresponds to simultaneously sending the red robot to room B and the blue robot to room G, followed by sending the red medical team to room B.\nAs one can see, the structured dialog is still very noisy. Each utterance (i.e. U1-U7) discusses a partial plan and only predicates that are explicitly mentioned in the utterance are tagged (e.g. U6-U7: the \u201cand then\u201d in U7 implies a sequencing constraint with the predicate discussed in U6, but the\nstructured form of U7 does not include ST(r,B)). Typos and misinformation are tagged as they are (e.g. U3), and the utterances to revise information are not placed in context (e.g. U4). Utterances that clearly violate ordering constraints (e.g. U1: all actions cannot happen at the same time) are tagged as they are. In addition, the information regarding whether the utterance was a suggestion, rejection or agreement of an partial plan is not coded.\nNote that the utterance tagging only contains information about relative ordering between the predicates appearing in that utterance, not the absolute ordering of their appearance in the final plan. For example, U2 specifies that the two grounded predicates happen at the same time. It does not say when the two predicates happen in the final plan or whether other predicates happen in parallel. This simulates how humans perceive the conversation \u2014 at each utterance, humans only observe the relative ordering, and infer the absolute order of predicates based on the whole conversation and an understanding of which orderings make a valid plan."}, {"heading": "Algorithm Output", "text": "The output of the algorithm is an inferred final plan, which is sampled from the probability distribution over final plans. The final plan has a similar representation to the structured utterance tags, and is represented as an ordered tuple of sets of grounded predicates. The predicates in each set represent actions that happen in parallel, and the ordering of sets indicates sequence. Unlike the utterance tags, the sequence ordering relations in the final plan represent the absolute order in which the actions are to be carried out. For example, a plan can be represented as ({A1, A2}, {A3}, {A4, A5, A6}), whereAi represents a predicate. In this plan,A1 andA2 will happen at plan time step 1, A3 happens at plan time step 2, and so on."}, {"heading": "Technical Approach and Related Work", "text": "It is natural to take a probabilistic approach to the plan inference problem since we are working with noisy data. However the combination of a small amount of noisy data and a very large number of possible plans means that an approach using typical uninformative priors over plans will frequently fail to converge to the team\u2019s plan in a timely manner.\nThis problem could also be approached as a logical constraint problem of partial order planning, if there were no noise in the utterances. In other words, if the team discussed only the partial plans relating to the final plan and did not make any errors or revisions, then a plan generator such as a PDDL solver (Coles et al. 2009) could produce the final plan with global sequencing. Unfortunately human conversation data is sufficiently noisy to preclude this approach.\nThis motivates a combined approach. We build a probabilistic generative model for the structured utterance observations. We use a logic-based plan validator (Howey, Long, and Fox 2004) to compute a highly structured prior distribution over possible plans, which encodes our assumption that the final plan is likely, but not required, to be a valid plan. This combined approach naturally deals with noise in the data and the challenge of performing inference over plans with only a small amount of data. We perform sampling inference in the model using Gibbs sampling and MetropolisHastings steps within to approximate the posterior distribution over final plans. We show through empirical validation with human subject experiments that the algorithm achieves 83% accuracy on average.\nCombining a logical approach with probabilistic modeling has gained interest in recent years. (Getoor and Mihalkova 2011) introduce a language for describing statistical models over typed relational domains and demonstrate model learning using noisy and uncertain real-world data. (Poon and Domingos 2006) introduce statistical sampling to improve the efficiency of search for satisfiability testing. (Richardson and Domingos 2006; Singla and Domingos 2007; Poon and Domingos 2009; Raedt 2008) introduce Markov logic networks, and form the joint distribution of a probabilistic graphical model by weighting the formulas in a first-order logic.\nOur approach shares with Markov logic networks the philosophy of combining logical tools with probabilistic modeling. Markov logic networks utilize a general first-order logic to help infer relationships among objects, but they do not explicitly address the planning problem, and we note the formulation and solution of planning problems in first-order logic is often inefficient. Our approach instead exploits the highly structured planning domain by integrating a widely used logical plan validator within the probabilistic generative model."}, {"heading": "Algorithm", "text": ""}, {"heading": "Generative Model", "text": "In this section, we explain the generative model of human team planning dialog (Figure 2) that we use to infer the team\u2019s final plan. We start with a plan latent variable that must be inferred by observing utterances in the planning\nsession. The model generates each utterance in the conversation by sampling a subset of the predicates in plan and computing the relative ordering in which they appear in the utterance. This mapping from the absolute ordering in plan to the relative ordering of predicates in an utterance is described in more detail below. Since the conversation is short, and the noise level is high, our model does not distinguish utterances based on the order of which they appear in the conversation.\nWe describe the generative model step by step:\n1. Variable plan: The plan variable in Figure 2 is defined as an ordered tuple of sets of grounded predicates and represents the final plan agreed upon by the team. The prior distribution over the plan variable is given by:\np(plan) \u221d { e\u03b1 if plan is valid 1 if plan is invalid.\n(1)\nwhere \u03b1 is a positive number. This models our assumption that the final plan is more likely, but not necessarily required, to be a valid plan. We describe in the next section how we evaluate the validity of a plan. Each set of predicates in plan is assigned a consecutive absolute plan step index s, starting at s = 1 working from left to right in the ordered tuple. For example, given plan = ({A1, A2}, {A3}, {A4, A5, A6}), where each Ai is a predicate, A1 and A2 occur in parallel at plan step s = 1 and A6 occurs at plan step s = 3.\n2. Variable snt : Each of n predicates in an utterance t is assigned a step index snt . s n t is given by the absolute plan\nstep s where the corresponding predicate pnt (explained later), appears in plan. snt is sampled as follows. For each utterance, n predicates are sampled from plan. For example, consider n = 2 where first sampled predicate appears in the second set of plan and the second sampled predicate appears in the fourth set of plan. Then s1t = 2 and s 2 t = 4. The probability of a set being sampled is proportional to the number of predicates in the set. For example, given plan = ({A1, A2}, {A3}, {A4, A5, A6}), the probability of selecting the first set ({A1, A2}) is 26 . This models that people are more likely to discuss plan steps that include many predicates. Formally,\np(snt = i|plan) = # predicates in set i in plan total # predicates in plan . (2)\n3. Variable s\u2032t: The variable s\u2032t is an array of size n that specifies, for each utterance t, the relative ordering of predicates as they appear in plan. s\u2032t is generated from st as follows:\np(s\u2032t|st) \u221d { e\u03b2 if s\u2032t = f(st) 1 if s\u2032t 6= f(st).\n(3)\nwhere \u03b2 > 0. The function f is a deterministic mapping from the absolute ordering st to the relative ordering s\u2032t. f takes as input a vector of absolute plan step indices and\nproduces a vector of consecutive indeces. For example, f maps st = (2, 4) to s\u2032t = (1, 2), and st = (5, 7, 2) to s\u2032t = (2, 3, 1). This variable models the way predicates and their orders appear in human conversation; people do not often refer to the absolute ordering, and frequently use relative terms such as \u201cbefore\u201d and \u201cafter\u201d to describe partial sequences of the full plan. People also make mistakes or otherwise incorrectly specify an ordering, hence our model allows for inconsistent relative orderings with nonzero probability.\n4. Variable pnt : The variable pnt represents the nth predicate that appears in the tth utterance. This is sampled given snt , the plan variable and a noise parameter wp. With probability wp, we sample the predicate pnt uniformly from the \u201ccorrect\u201d set snt in plan as follows:\np(pnt = i|plan, snt = j) =\n{ 1\n# pred. in set j if i is in set j 0 o.w.\nWith probability 1\u2212wp, we sample the predicate pnt uniformly from \u201cany\u201d set in plan (i.e. from all predicates mentioned in the dialog), therefore\np(pnt = i|plan, snt = j) = 1\ntotal # predicates . (4)\nIn other words, with higher probability wp, we sample a value for pnt that is consistent with s n t , but allow nonzero probability that pnt is sampled from a random plan. This allows the model to incorporate the noise in the planning conversation, including mistakes or plans that are later revised.\nPDDL Validator We use the Planning Domain Description Language (PDDL) 2.1 plan validator tool (Howey, Long, and Fox 2004) to evaluate the prior distribution over possible plans. The plan validator is a standard tool that takes as input a planning problem described in PDDL and a proposed solution plan, and\nchecks if the plan is valid. Some validators can also compute a value for plan quality, if the problem specification includes a plan metric. Validation is often much cheaper than generating a valid plan, and gives us a way to compute p(plan) up to proportionality in a computationally efficient manner. Leveraging this efficiency, we use Metropolis-Hastings sampling to sample the plan without calculating the partition function, as described in the next section.\nMany elements of the PDDL domain and problem specification are defined by the capabilities and resources at a particular response team\u2019s disposal. The PDDL specification may largely be reused from mission to mission, but some elements will change or may be specified incorrectly. For example the plan specification may misrepresent the number of responders available or may leave out implicit constraints that people take for granted. In the Experimental Evaluation section we demonstrate the robustness of our approach using both complete and degraded PDDL plan specifications."}, {"heading": "Gibbs Sampling", "text": "We use Gibbs sampling to perform inference on the generative model. There are two latent variables to sample: plan and the collection of variables snt . We iterate between sampling plan given all other variables and sampling the snt variables given all other variables. The PDDL validator is used when the plan variable is sampled.\nUnlike snt , where we can write down an analytic form to sample from the posterior, it is intractable to directly resample the plan variable, as it requires calculating the number of all possible valid and invalid plans. Therefore we use a Metropolis-Hasting (MH) algorithm to sample from the plan posterior distribution within the Gibbs sampling steps. In this section, we explain how plan and the snt variables are sampled.\nSampling plan using Metropolis-Hastings The posterior of plan can be represented as the product of the prior and likelihood as follows:\np(plan|s, p) \u221d p(plan)p(s, p|plan)\n= p(plan) T\u220f t=1 N\u220f n=1 p(snt , p n t |plan)\n= p(plan) T\u220f t=1 N\u220f n=1 p(snt |plan)p(pnt |plan, snt )\n(5)\nThe MH sampling algorithm is widely used to sample from a distribution when direct sampling is difficult. The typical MH algorithm defines a proposal distribution, Q(x\u2032|xt) which samples a new point (i.e. x\u2032: a value of the plan variable in our case) given the current point xt. The new point can be achieved by randomly selecting one of the possible moves, as defined below. The proposed point is accepted or rejected with probability of min(1, acceptance ratio).\nUnlike simple cases where a Gaussian distribution can be used as a proposal distribution, our proposal distribution needs to be defined over the plan space. Recall that plan is\nrepresented as an ordered tuple of sets of predicates, and the new point is suggested by performing one of the following moves:\n\u2022 Select a predicate. If it is in the current plan, move it to either: 1) the next set of predicates, 2) the previous set or 3) remove it from the current plan. If it is not in the current plan, move it to one of the existing set.\n\u2022 Select two sets in plan, and switch their orders. These moves are sufficient to move from an arbitrary plan to another arbitrary plan using the set of moves defined above. The probability of each of these moves described above is chosen such that the the proposal distribution is symmetric: Q(x\u2032|xt) = Q(xt|x\u2032). This symmetry simplifies the calculation of the acceptance ratio.\nSecond, the ratios of the proposal distribution at the current and proposed points are calculated. When plan is valid and invalid respectively, p(plan) is proportional to e\u03b1 and 1 respectively, as described in Equation 1. Plan validity is evaluated using the PDDL validation tool. The remaining term, p(snt |plan)p(pnt |plan, snt ), is calculated using Equations 2 and 4.\nThird, the proposed plan is accepted with the following probability: min ( 1, p\n\u2217(plan=x\u2032|s,p) p\u2217(plan=xt|s,p)\n) , where p\u2217 is a function\nthat is proportional to the posterior distribution.\nSampling snt Fortunately, there exists an analytic expression for the posterior of snt :\np(st|plan, pt, s\u2032t) \u221d p(st|plan)p(pt, s\u2032t|plan, st) = p(st|plan)p(pt|plan, st)p(s\u2032t|st)\n= p(s\u2032t|st) N\u220f n=1 p(snt |plan)p(pnt |plan, snt )\nNote this analytic expression can be expensive to evaluate if the number of possible values of snt is large. In that case one can marginalize out snt , as the one variable we truly care about is the plan variable."}, {"heading": "Experimental Evaluation", "text": "In this section we evaluate the performance of our plan inference algorithm through initial proof-of-concept human subject experimentation and show we are able to infer a human team\u2019s final plan with 83% accuracy on average. We also describe a robot demonstration in which two people plan and execute a first-response collaborative task with a PR2 robot. Human Team Planning Data We designed a web-based collaboration tool that is modeled after the NICS system (Di Ciaccio, Pullen, and Breimyer 2011) used by first response teams, but with a modification that requires the team to communicate soley via text chat. Twenty-three teams of two (total of 46 participants) were recruited through Amazon Mechanical Turk and the greater Boston area. Recruitment was restricted to participants located in US to increase the probability that participants were fluent in English. Each team was provided the fictional rescue scenario described in this paper, and was asked to collaboratively plan a rescue\nmission. At the completion of the planning session, each participant was asked to summarize the final agreed upon plan in the structured form described previously. An independent analyst reviewed the planning sessions to resolve discrepancies between the two member\u2019s final plan descriptions, when necessary. Utterance tagging was performed by the three analysts: the first and second authors, and an independent analyst. Two of the three analysts tagged and reviewed each team planning session. On average, 19% of predicates mentioned per data set did not end up in the final plan. Algorithm Implementation The algorithm is implemented in Python, and the VAL PDDL 2.1 plan validator (Howey, Long, and Fox 2004) is used. We perform 3000 Gibbs sampling steps on the data from each planning session. Within one Gibbs sampling step, we perform 400 steps of the Metropolis-Hastings (MH) algorithm to sample the plan. Every 20 samples are selected to measure the accuracy. wp is set to 0.8, \u03b1 is 10, \u03b2 is 5. Results We evaluate the quality of the final plan produced by our algorithm in terms of (1) accuracy of task allocation among agents (e.g. which medic travels to which room), and (2) accuracy of plan sequence.\nTwo metrics for task allocation accuracy are evaluated: 1) [% Inferred] the percent of inferred plan predicates that appear in the team\u2019s final plan, and 2) [% Noise Rej] the percent noise rejection of extraneous predicates that are discussed but do not appear in the team\u2019s final plan.\nWe evaluate the accuracy of the plan sequence as follows. We say a pair of predicates is correctly ordered if it is consistent with the relative ordering in the true final plan. We measure the percent accuracy of sequencing [% Seq] by # correctly ordered pairs of correct predicates\ntotal # of pairs of correct predicates . Only correctly estimated predicates are compared, as there is no ground truth relation for predicates that are not in the true final plan. We use this relative sequencing measure because it does not compound the sequence errors, as an absolute difference measure would (e.g. where the error in the ordering of one predicate early in the plan shifts the position of all subsequent predicates).\nOverall plan accuracy is computed as the arithmetic mean of the two task allocation and one plan sequence accuracy measures. Our algorithm is evaluated under three conditions: 1) [PDDL] perfect PDDL files, 2) [PDDL-1] PDDL problem file with missing goals/constants (delete one patient and one robot), 3) [PDDL-2] PDDL domain file missing a constraint (delete precondition that a robot needs to inspect the room before a human crew can enter), and 4) [no PDDL] using an uninformative prior over possible plans.\nResults, shown in Table 2, show that our algorithm infers final plans with greater than 80% on average, and achieves good noise rejection of extraneous predicates discussed in conversation. We also show our approach is relatively robust to degraded PDDL specifications. Concept-of-Operations Robot Demonstration We illustrate the use of our plan inference algorithm with a robot demonstration in which two people plan and execute a firstresponse collaborative task with a PR2 robot. Two participants plan an impending deployment using the web-based\ncollaborative tool that we developed. Once the planning session is complete, the dialog is manually tagged. The plan inferred from this data is confirmed with the human planners, and is provided to the robot to execute. The registration of predicates to robot actions, and room names to map locations, is performed offline in advance. While the first responders are on their way to the accident scene, the PR2 autonomously navigates to each room performing online localization, path planning, and obstacle avoidance. The robot informs the rest of the team as it inspects each room and confirms it is safe for the human team members to enter. Video of this demo is here: http://tiny.cc/uxhcrw."}, {"heading": "Future Work", "text": "Our aim is to reduce the burden of programming a robot to work in concert with a human team. We present an algorithm that combines a probabilistic approach with logical plan validation to infer a plan from human team conversation. We empirically demonstrate that this hybrid approach enables us to infer the team\u2019s final plan with about 83% accuracy on average.\nNext, we plan to investigate the speed and ease with which a human planner can \u201cfix\u201d the inferred plan to achieve near 100% plan accuracy. We are also investigating automatic mechanisms for translating raw natural dialog into the structured form our algorithm takes as input."}, {"heading": "Acknowledgement", "text": "The authors thank Matt Johnson and James Saunderson for helpful discussions and feedback.\nThis work is sponsored by ASD (R&E) under Air Force Contract FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations are those of the authors and are not necessarily endorsed by the United States Government."}], "references": [{"title": "Designing effective soldier-robot teams in complex environments: training, interfaces, and individual differences", "author": ["Barnes"], "venue": null, "citeRegEx": "Barnes,? \\Q2011\\E", "shortCiteRegEx": "Barnes", "year": 2011}, {"title": "Workflow study on human-robot interaction in usar", "author": ["Casper", "J. Murphy 2002] Casper", "R. Murphy"], "venue": "In IEEE ICRA,", "citeRegEx": "Casper et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Casper et al\\.", "year": 2002}, {"title": "Human-robot interactions during the robot-assisted urban search and rescue response at the world trade center", "author": ["Casper", "J. Murphy 2003] Casper", "R. Murphy"], "venue": "IEEE SMCS 33(3):367\u2013385", "citeRegEx": "Casper et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Casper et al\\.", "year": 2003}, {"title": "Managing concurrency in temporal planning using planner-scheduler interaction", "author": ["Coles"], "venue": "Artificial Intelligence", "citeRegEx": "Coles,? \\Q2009\\E", "shortCiteRegEx": "Coles", "year": 2009}, {"title": "Operator performance and intelligent aiding in unmanned aerial vehicle scheduling", "author": ["Brzezinski Cummings", "M.L. Lee 2007] Cummings", "A.S. Brzezinski", "J.D. Lee"], "venue": "IEEE Intelligent Systems", "citeRegEx": "Cummings et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cummings et al\\.", "year": 2007}, {"title": "Enabling distributed command and control with standards-based geospatial collaboration", "author": ["Pullen Di Ciaccio", "R. Breimyer 2011] Di Ciaccio", "J. Pullen", "P. Breimyer"], "venue": "In IEEE International Conference on HST", "citeRegEx": "Ciaccio et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ciaccio et al\\.", "year": 2011}, {"title": "Learning statistical models from relational data", "author": ["Getoor", "L. Mihalkova 2011] Getoor", "L. Mihalkova"], "venue": "In International Conference on Management of data,", "citeRegEx": "Getoor et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Getoor et al\\.", "year": 2011}, {"title": "Towards using UAVs in wilderness search and rescue: Lessons from field trials. Interaction Studies, Special Issue on Robots in the Wild: Exploring Human-Robot Interaction in Naturalis", "author": ["Goodrich"], "venue": null, "citeRegEx": "Goodrich,? \\Q2009\\E", "shortCiteRegEx": "Goodrich", "year": 2009}, {"title": "Autonomous robots in swat applications: Research, design, and operations challenges. AUVSI", "author": ["Jones"], "venue": null, "citeRegEx": "Jones,? \\Q2002\\E", "shortCiteRegEx": "Jones", "year": 2002}, {"title": "Quantitative estimation of the strength of agreements in goal-oriented meetings", "author": ["Bush Kim", "B. Shah 2013] Kim", "L. Bush", "J. Shah"], "venue": null, "citeRegEx": "Kim et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2013}, {"title": "Generalized inference with multiple semantic role labeling systems", "author": ["Koomen"], "venue": null, "citeRegEx": "Koomen,? \\Q2005\\E", "shortCiteRegEx": "Koomen", "year": 2005}, {"title": "Continual processing of situated dialogue in human-robot collaborative activities", "author": ["Jan\u0131cek Kruijff", "G. Lison 2010] Kruijff", "M. Jan\u0131cek", "P. Lison"], "venue": null, "citeRegEx": "Kruijff et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kruijff et al\\.", "year": 2010}, {"title": "Establishing human situation awareness using a multi-modal operator control unit in an urban search & rescue human-robot team", "author": ["Larochelle"], "venue": "IEEE Ro-Man,", "citeRegEx": "Larochelle,? \\Q2011\\E", "shortCiteRegEx": "Larochelle", "year": 2011}, {"title": "Semantic role labeling", "author": ["Gildea Palmer", "M. Xue 2010] Palmer", "D. Gildea", "N. Xue"], "venue": "Synthesis Lectures on Human Language Technologies", "citeRegEx": "Palmer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2010}, {"title": "Sound and efficient inference with probabilistic and deterministic dependencies", "author": ["Poon", "H. Domingos 2006] Poon", "P. Domingos"], "venue": "In AAAI,", "citeRegEx": "Poon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2006}, {"title": "Unsupervised semantic parsing", "author": ["Poon", "H. Domingos 2009] Poon", "P. Domingos"], "venue": "In EMNLP", "citeRegEx": "Poon et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2009}, {"title": "Shallow semantic parsing using support vector machines", "author": ["Pradhan"], "venue": null, "citeRegEx": "Pradhan,? \\Q2004\\E", "shortCiteRegEx": "Pradhan", "year": 2004}, {"title": "Markov logic networks. Machine learning 62(1):107\u2013136", "author": ["Richardson", "M. Domingos 2006] Richardson", "P. Domingos"], "venue": null, "citeRegEx": "Richardson et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2006}, {"title": "Markov logic in infinite domains", "author": ["Singla", "P. Domingos 2007] Singla", "P. Domingos"], "venue": null, "citeRegEx": "Singla et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Singla et al\\.", "year": 2007}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["Tellex"], "venue": null, "citeRegEx": "Tellex,? \\Q2011\\E", "shortCiteRegEx": "Tellex", "year": 2011}], "referenceMentions": [], "year": 2013, "abstractText": "We aim to reduce the burden of programming and deploying autonomous systems to work in concert with people in time-critical domains, such as military field operations and disaster response. Deployment plans for these operations are frequently negotiated on-the-fly by teams of human planners. A human operator then translates the agreed upon plan into machine instructions for the robots. We present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human team\u2019s planning conversation. Our approach combines probabilistic generative modeling with logical plan validation used to compute a highly structured prior over possible plans. This hybrid approach enables us to overcome the challenge of performing inference over the large solution space with only a small amount of noisy data from the team planning session. We validate the algorithm through human subject experimentation and show we are able to infer a human team\u2019s final plan with 83% accuracy on average. We also describe a robot demonstration in which two people plan and execute a first-response collaborative task with a PR2 robot. To the best of our knowledge, this is the first work that integrates a logical planning technique within a generative model to perform plan inference.", "creator": "LaTeX with hyperref package"}}}