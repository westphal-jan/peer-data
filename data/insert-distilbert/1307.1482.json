{"id": "1307.1482", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2013", "title": "Towards Combining HTN Planning and Geometric Task Planning", "abstract": "in translating this paper we present up an intimate interface between a symbolic planner and a geometric task planner, which is different to a standard trajectory planner in that the former is able to solely perform geometric reasoning on abstract entities - - - tasks. we believe that this symbolic approach facilitates a more principled interface to symbolic planning, while also leaving more efficient room for the geometric planner to make independent decisions. we show how the two individual planners could be theoretically interfaced, consider and suggest how readily their manual planning and backtracking could be interleaved. we also provide insights for a methodology specific for using the combined system, and experimental results to use as a benchmark with future extensions to both the combined system, as well as to the geometric task planner.", "histories": [["v1", "Thu, 4 Jul 2013 20:28:40 GMT  (3183kb)", "http://arxiv.org/abs/1307.1482v1", "RSS Workshop on Combined Robot Motion Planning and AI Planning for Practical Applications, June 2013"]], "COMMENTS": "RSS Workshop on Combined Robot Motion Planning and AI Planning for Practical Applications, June 2013", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lavindra de silva", "amit kumar pandey", "mamoun gharbi", "rachid alami"], "accepted": false, "id": "1307.1482"}, "pdf": {"name": "1307.1482.pdf", "metadata": {"source": "CRF", "title": "Towards Combining HTN Planning and Geometric Task Planning", "authors": ["Lavindra de Silva", "Amit Kumar Pandey", "Mamoun Gharbi", "Rachid Alami"], "emails": ["ldesilva@laas.fr", "akpandey@laas.fr", "magharbi@laas.fr", "rachid@laas.fr"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nThe past few years have seen a great deal of interest in interfacing symbolic and geometric reasoning. A common theme has been to define how geometric entities and capabilities should be meaningfully used within symbolic planning, and how symbolic information can be used, perhaps as heuristics, in geometric planning. In this paper we follow this trend. Broadly, we are interested in the link between a geometric task/action and a symbolic action, what geometric information we should publicise to the symbolic (resp. geometric) planner, and how can we include them in symbolic (resp. geometric) states and actions. An unavoidable issue that arises when combining the two planning approaches is \u201cbacktracking\u201d\u2014 trying alternative options for choices that were already made during planning. Both approaches are capable of backtracking at their own levels when a plan being pursued turns out to not work: the symbolic planner when some precondition is not met, and the geometric planner when a path/trajectory being planned cannot avoid a collision. It is therefore important to decide how we can effectively interleave geometric and symbolic backtracking [1], [2], and how we should switch between them.\nIn [2], [3] the authors discuss algorithms for geometric backtracking by extending the Justin robot with symbolicgeometric planning capabilities: they use the JSHOP2 [4] HTN planner for the symbolic planning component and a specialised path planner for the geometric one. Unlike our approach, the authors keep the symbolic state orthogonal to the geometric state: changing, for instance, the pose of an object on a table has no consequence on the symbolic state. We require symbolic and geometric states to be intertwined, which is natural in some domains. To this end, we derive symbolic facts from the geometric state and use these in symbolic planning.\n*This work was conducted within the EU SAPHARI project (www.saphari.eu) funded by the E.C. division FP7-IST under contract ICT-287513.\n**LAAS/CNRS, 7, Av. du Colonel Roche, 31077 Toulouse, France. {ldesilva,akpandey,magharbi,rachid}@laas.fr\nTo interface symbolic and geometric planning, the authors in [5], [6] introduce \u201csemantic attachments,\u201d which associate selected predicates in the planning domain to external procedures called at runtime to evaluate the predicates. In [7], the semantic attachments are implemented using a trajectory planner that computes collision free trajectories; if one exists, then the corresponding semantic attachment evaluates to true , and false otherwise. Likewise, we use \u201cevaluable predicates,\u201d with a minor difference where we link them to more abstract entities called geometric tasks, which may or may not invoke a trajectory planner. The authors also introduce \u201ceffect applicators\u201d in effects of actions that consult the geometric planner to set certain state variables (e.g. position and orientation of a moved object) in the symbolic domain. Effect applicators, however, cannot make decisions between different outcomes, such as choosing where to place an object. In our work we do want to give the geometric planner some leeway to make such choices.\nIn some works there is a tight integration between symbolic and geometric planning. In [8], for instance, a hierarchical planner plans all the way down to the level of geometric actions. Similarly, [9] describes a special purpose hierarchical planner combined with a geometric motion planner for planning, and then executing the most basic actions while the plan is still being constructed. This is different to the work described above which formulate a complete plan first, before executing it. The Asymov [10] system is a combined task and motion planner for problems that are difficult to solve when the symbolic planner is in control of the geometric search, e.g. in the geometric Towers of Hanoi problem that the authors present. Compared to other approaches, in Asymov the geometric planner uses the symbolic planner\u2014as well as the symblic model of the domain\u2014as a heuristic when choosing roadmaps during geometric search. Similarly, in [11] a symbolic planner guides a sampling-based motion planner, which in turn sends back utility estimates to improve the guide in the next iteration.\nUnlike previous approaches, our work concerns the use of a geometric task planner instead of a typical trajectory planner; the former lets us define the interface to symbolic planning in a more meaningful way\u2014by providing a higher level of abstraction to low level geometric actions like picking and placing\u2014and also gives more leeway to the geometric level to make decisions. Unlike past work we are also interested here in a principled methodology for developing symbolic-geometric planning domains: this paper provides useful insights in this direction. We present an initial prototype implementation of the combined planning framework including basic interleaved backtracking, and an analysis of its runtime performance;\nwe intend to use these results as a benchmark for future experiments with different backtracking strategies currently being developed, and to develop better heuristics for the geometric task planning component itself."}, {"heading": "II. BACKGROUND", "text": "In this paper we refer to the popular STRIPS classical planning language [12]. More importantly, we make use of the Hierarchical Task Network (HTN) planning formalism. While classical planners focus on bringing about states of affairs or \u201cgoals-to-be,\u201d HTN planners focus on solving abstract tasks or \u201cgoals-to-do.\u201d In this paper we use a popular type of HTN planning called \u201ctotally-ordered\u201d HTN (henceforth simply referred to as HTN) planning, which has proven to be efficient in certain domains [13]. An HTN planning problem is the 3-tuple \u3008d, S0,D\u3009, where d is the sequence of (primitive or abstract) tasks to solve, S0 is an initial state as in classical planning, and D is an HTN planning domain. Specifically, an HTN planning domain is the pair D = \u3008A,M\u3009 where A\u2014the primitives of the domain\u2014is a finite set of operators as before, andM is a finite set of methods. A method is a tuple consisting of the name of the method, the abstract task that the method is used to solve, a precondition specifying when the method is applicable (like an operator\u2019s precondition), and a body indicating which tasks are used to solve the task associated with the method. The method-body is a sequence of primitive and/or abstract tasks. The planning process works by selecting applicable reduction methods from M and applying them to abstract tasks in d in a depth-first manner. In each iteration this will typically result in d becoming a \u201cmore primitive\u201d sequence of tasks. The process continues until d has only primitive tasks left. At any stage in the planning process, if no applicable method can be found for an abstract task, the planner essentially \u201cbacktracks\u201d and tries an alternative method for an abstract task refined earlier.\nFor the geometric counterpart, we adopt the approach of finding a solution in a discrete space of candidate grasps and placements [3], [14] for tasks involving picking and placing. Basically, our geometric task planner (GTP)1 iterates in a four dimensional search space, consisting of a set of agent \u201ceffort\u201d levels, a set of discrete grasps, a set of object placement positions, and a set of object placement orientations (see Figure 1). For each object, sets of possible grasps are pre-computed and stored for the anthropomorphic hands and the robot\u2019s gripper, which are later filtered based on task requirements and the environment. The amount of \u201ceffort units\u201d required to perform certain tasks like moving the head, extending an arm, and standing up are predefined; to this end, we have made simplifying assumptions about which tasks (e.g. head movements) require less effort than others (e.g. standing up). At runtime, sets of placement positions and possible orientations of objects are dynamically extracted, based on the environment, the task, and restrictions on how much effort should be put into the task. These sets are then weighted based on the environment and situation, with criteria such as grasp and placement stability, feasibility of simultaneous grasps by\n1We also use GTP as an abbreviation for geometric task planning.\ntwo agents, the agent\u2019s visibility of the object, and estimated effort to see and reach it.\nThe advantage of the GTP framework is that a variety of day-to-day tasks like showing, giving, hiding, and making accessible can be represented in terms of different constraints, based on factors like reachability, visibility, desired effort level, and the ability to grasp. A geometric solution is found using a constraint hierarchy based approach, by carefully introducing these constraints successively at different stages of planning. This facilitates the reduction of the search space successively, before introducing relatively more computationally expensive constraints.\nWe shall now briefly highlight the GTP algorithm. The outermost loop starts from the lowest estimated effort required (to view and reach objects) for the task and incrementally moves to the highest. For each such effort estimate, the algorithm iterates on the candidate points where the task could be performed, excluding those that did not work with lower effort estimates. For each such point, the algorithm iterates on the possible object grasps if it is not already in the gripper, excluding those that already failed for lower effort estimates. For each such grasp, if a collision-free pick is possible\u2014i.e. there is a path to a configuration associated with the grasp\u2014 the algorithm tries the different possible object orientations, excluding those that are in collision (e.g. with a surface), and those that do not satisfy the visibility threshold and other task oriented symbolic constraints, such as maintaining the object facing front. Finally, the planner obtains a tuple consisting of a grasp, a placement position and a placement orientation, which is then used to find a collision free trajectory."}, {"heading": "III. A SYMBOLIC-GEOMETRIC PLANNING EXAMPLE", "text": "In this section we detail a concrete domain that illustrates how symbolic and geometric planning is interfaced and combined. We also highlight our approach to interleaving HTN and GTP backtracking, but leave the detailed algorithms for a separate paper. Suppose a PR2 robot is working as a library receptionist. Library members reserve books online with their membership ID, which is also used to top up their library credit. The ID can be used to look up membership details like email address and books reserved and borrowed. Reserved books are collected in person from the library. Once an online reservation is made, (human) librarians make the books accessible (i.e. reachable without navigating from the current position, and visible) to the PR2 on an adjacent table.\nThe HTN domain is illustrated graphically in Figure 2 and detailed in Table I. The top-level HTN task is MANAGEORDER(M) for member M . It has one method (named m1) with two subtasks: LEND(M) and TAKEPAYMENT(M). The first is associated with three methods\u2014m2,m3,m4\u2014which are tried in that order. Method m2 trivially succeeds if there are no (more) books held by the member and hence no more books to give. If it is not applicable, m3 is tried, which has the following actions: pick (via GTP) from the adjacent shelf a book reserved by the member, speak out the title, make it accessible to the member on the desk, perform some bookkeeping\u2014e.g. send the current total to the Point-of-Sale (POS) machine\u2014and then recursively call LEND(M).\nMethod m4 starts with an HTN abstract task to display a book, which refines into the three steps focussed on showing a book to the person. The abstract task is followed by giving the\nbook to the person,2 waiting for it to be taken\u2014which relies on the gripper angle and force sensors to check if the book has successfully been taken\u2014and then the bookkeeping action as before, ending with a recursive call to LEND(M). Note that a book is given only if it is deemed light enough to be directly taken from the gripper, and that by forcing an ordering on m3 and m4 we are encoding a preference for placing a book on the table over handing it (directly) to the member, allowing the member to pick up the book and put it in a bag/handbag at his/her own pace.\nThe TAKEPAYMENT(M) task of m1 has methods m6 and m7. Method m6 has a single action to debit the account corresponding to the member ID according to the number of books lent (all books have the same cost), if there is enough\n2We could also imagine more generic GIVEBK(B, M) and MAKEBKACC(B, M) actions that can handle any object type or give and make books accessible for reasons other than lending.\ncredit C in the member\u2019s account. If not, the member must pay by credit card (m7). The PLACEPOSM(M) task refines into two methods for giving the POS machine: if the machine is (likely) reachable it is simply picked up, but if not\u2014 presumably because the (shared) machine is with the receptionist at an adjacent desk\u2014the PR2 navigates to the machine, picks it up, and navigates back; the PR2 then asks the user to swipe the card and enter the PIN, and then puts the machine on the POS machine stand. The PUTAWAYPOSM(M) task includes actions to thank the person and to put the machine somewhere that is away from the person\u2019s reach and visibility, and EMAIL(M) emails the member an invoice.\nThis HTN domain serves to highlight some key features. First, the HTN developer interfaces with the GTP using evaluable predicates. To this end, every (relevant) GTP task t is associated with an evaluable predicate\u2014denoted t?\u2014in the HTN domain (e.g. GTP task SHOW(O,H) has evaluable predicate show(O,H)? for some object O and human H), which evaluates to true if t has a GTP solution and false otherwise. Whenever such an evaluable predicate is mentioned in the precondition of an operator (resp. action), we call it a Geometric-Symbolic (GS) operator (resp. action). A GTP task t is also associated with an add list function\u2014denoted t+\u2014and a delete list function\u2014denoted t\u2212\u2014which are the (possibly empty) add and delete lists for t computed by the GTP, based basically on the world resulting from the solution that was found for t on calling evaluable predicate t?. Add list function show(o1, h1)+ might, for instance, return the set {visible(o1, h1), accessible(o1, h1)} and show(o1, h1)\u2212 the set {visible(o3, h1), accessible(o3, h1)}: that is, after making object o1 visible to human h1, the object is also accessible to h1, but object o3 is no longer visible nor accessible to h1. The effects of a GS operator is the combination of its \u201cstatic\u201d add and delete lists with those obtained via the add and delete list functions.\nAn important concept we exploit is that of a \u201cshared predicate\u201d (or \u201cshared literal\u201d), which is a standard literal that is based on geometrical properties and hence modelled more accurately by the GTP. For example, predicate reachable(o, h) in the HTN domain (see method m8), which specifies that object o is reachable to human h, is derived from the 3D world with a heuristic based on the area covered on extending the robot\u2019s arm with respect to all its degrees of freedom [1].\nWe highlight some interesting interleaving of GTP and HTN planning\u2014backtracking in particular\u2014possible with the domain described. Suppose the library reception desk is small and somewhat cluttered, and that a member has reserved two big books b1 and b2. Assume there is enough space on the table to make one of them accessible (to the member), but not enough space to make them both accessible, nor to make one accessible but give the other (directly), as the books are so big that they block the robot-arm\u2019s path to the person. Figure 3 shows a part of a possible combined HTN-GTP planning scenario. In the figure, b1 is successfully picked and made accessible\u2014i.e. the GTP tasks (third column) corresponding to the PICK(b1) and MAKEBKACC(b1,m) GS actions (second column) are successfully planned. Then, LEND(M) is recur-\nsively called during HTN planning. However, according to our scenario, the attempt to make book b2 accessible (after picking it up) will fail. At this point the GTP will backtrack all the way up to PICK(b1) (third column) but not find a way to reposition the first book so as to make the second accessible. The system will then resort to HTN bactracking, which will choose the alternative method m4 to give b2 directly to the person.3 According to our initial scenario, this will also fail even after the GTP backtracks to reposition b1 (not shown in the figure). The HTN planner will then backtrack once again up the hierarchy and perhaps choose method m4 to give b1 directly to the person, after which it should be possible to make b2 accessible and continue planning.\nThe last column of Figure 3 shows the mapping of the four \u201ccompound\u201d GTP tasks in the third column into grasp and placement actions. A more interesting domain would be where these actions are encapsulated into one compound PICKMAKEACCESSIBLE(O,H) task (for object O and human H), instead of the two tasks PICK(O) and MAKEACC(O,H). This will allow the GTP to backtrack from PLACE(O) to GRASP(O), allowing failure to be detected early in HTN planning\u2014when PICKMAKEACCESSIBLE(O,H) fails because a (future) GTP task/action (PLACE(O) in our example), due to be tried later by the HTN planner, is predicted by the GTP to be impossible. Such encapsulation can also minimise GTP backtracking by, from the outset, planning with respect to definite future GTP actions (e.g. planning the grasp with respect to the placement).\nIV. IMPLEMENTATION\nAs mentioned in Section II, we have adapted an HTN planner and implemented a GTP. We have also sufficiently implemented the algorithms presented in this paper to gain some valuable insights. In our setup, the (real) PR2 is in a\n3We assume that the book is light enough to be handed to the person.\nroom with objects like tables, shelves, and chairs, and the same is modelled in 3D, onto which humans and objects (e.g. books) are dynamically projected whenever they are detected in the real room by respectively a Kinect (Microsoft) sensor, and PR2\u2019s stereo cameras coupled with a pattern-based marker detection module. For 3D visualization and planning we use the Move3D software [15].\nOur current GTP implementation has some of the functionality depicted in Figure 3, including: (i) storing the sequence of GTP tasks pursued so far; (ii) basic backtracking to find an alternative solution for a chosen GTP task in the sequence; and (iii) computing predicates such as visible(O,A), reachable(O,A), on(O,O2), inside(O,O2) and coveredBy(O,O2) for an agent A and objects O,O2, where the first two are computed based on the concept of mightability maps presented in [1]\u2014which the authors showed to be computed and updated fast enough for online HRI\u2014and the other facts using techniques from the geometric analysis of the 3D world model, and domain specific heuristics.4\nWe demonstrate our implementation in figures 4 and 5, where the second is essentially a screen dump of the visible(O,H) and reachable(O,H) shared literals computed. Figure 4 (a) is the initial state with two books on the table next to the PR2, and a small white platform in front of it to exchange objects. Planning starts with the PR2 picking (b) the grey book and making it accessible (c) to the human on the platform. The same is done for the white book in (d) and (e). The position of the white book, however, makes the grey one no longer visible to the human, which later makes it impossible to give the POS machine to him\u2014in the current example this requires that all books be visible to him. Consequently, the GTP backtracks and finds a slightly different way to place the white book (f) so that both books are then visible.\nFigure 5 (a) shows that at the start, the grey book (Grey) and the white book (White) are not visible (Vis) nor reachable (Reach) to the human, as they both require an effort (E) of either 3 or 4, instead of 1. Figure 5 (d) shows how after backtracking and moving the white book, the grey one becomes visible once again. Note that something is deemed visible to a human based on a threshold on the percentage of pixels visible, using the approach presented in [16]. Our threshold here is that at least 50% of an object should be visible to the human for the fact to hold."}, {"heading": "V. EXPERIMENTAL RESULTS", "text": "To analyse the runtime performance of the combined HTNGTP system we implemented and ran the domain depicted in Figure 2. Specifically, we implemented most HTN and GTP tasks in the domain except for NAVTO(Obj) (which requires further work), and we modified the HTN domain slightly by replacing PUTON(O1, O2) with MAKEACC(O,H), and grouping PICK(O) together with the 4 other GTP tasks for reasons explained in Section III.\nWe ran the experiments on the PR2, which has two quadcore i7 Xeon processors (8 cores), 24 GB of memory, and\n4Note that by deriving and using geometric states as shared literals we need to address the ramifications of geometric backtracking on already pursued symbolic actions. Due to space limits we leave our solution for another paper.\na 500 GB hard drive.5 We only analysed the performance of the HTN-GTP system with HTN backtracking alone\u2014we did not exploit geometric backtracking; we intend to use these results as a baseline to compare against an extended HTNGTP system being developed, which interleaves backtracking as shown in Figure 3. We ran the experiment 100 times, where each run started by calling the MANAGEORDER(M) task in Figure 2. The initial state of the GTP was similar to that in Figure 4 except that there was also a POS machine. We kept the GTP initial state fixed: automatically generating initial states with different positions and orientations for books is left as future work. We do note, however, that manual adjustments to the GTP initial state did not seem to change the experimental results. The HTN initial state was such that the member had to always pay by credit card, which forced method m7 to be selected\u2014the one that relies on the GTP.6\nThe results are summarised in Table II. We note that HTN planning (alone) took negligible time. Observe that PUTAWAY(O,H) was the most \u201cdifficult\u201d task to plan: the\n5Running the HTN-GTP system on the PR2 allowed using real object and human locations for constructing the initial states for planning, and also directly executing plans found.\n6We invite the reader to view a video of a single run of the experiment at www.tinyurl.com/pr2-exp; it has been edited for easier viewing.\nGTP could not find a solution 52% of the time, and it took 51 seconds on average, making it also the most computationally expensive task. On the contrary, the GTP always found a solution for GIVE(O,H), which was also the least computationally expensive task.\nAlthough, intuitively, it should be possible to find solutions less often for GIVE(O,H) than for SHOW(O,H), this was not the case because GIVE(O,H) is followed by SHOW(O,H) in our HTN domain: hence if there is no solution for SHOW(O,H) then GIVE(O,H) will not be attempted, and if SHOW(O,H) does have a solution then it is quite likely that GIVE(O,H) will also have one, as they both rely on the ability to make an object visible.7\nInterestingly, MAKEACC(O,H) and PUTAWAY(O,H) have similar results in their respective columns in the table, but the latter takes much longer to plan. This is due to different thresholds on visibility: for an object to be deemed accessible it is sufficient if (along with reachability requirements) at least 50% of the object\u2019s pixels are visible to the person, whereas for an object to be considered successfully put away, we have set that value to 0%. Since our GTP approach is constraint hierarchy based, the computation time is greatly affected by what stage in the planning process the planner fails. As pixel based visibility computation is relatively computationally expensive, it is left for the final stages of planning. It appears that with PUTAWAY(O,H), checking the feasibility of visibility constraints fails more times than with MAKEACC(O,H), as in most cases objects were not completely hidden\u2014in fact, they were sufficiently visible.\nThe experiments revealed that our combined HTN-GTP domain was, in some sense, \u201ccomplete\u201d\u2014the combination was almost always able to find HTN-GTP solutions for MANAGEORDER(M), without frequent backtracking. There was only one HTN-GTP planning attempt that failed completely (with 8 backtracks), when the GTP could not put/hide away the POS machine\u2014within the 60-second time limit we had set for GTP\u2014despite all symbolic backtracking attempts. On average the symbolic planner backtracked about once (actually, 0.86 times) per run before finding a solution, with slightly under 10% of the total runs backtracking more than 3 times per run. This suggests that GTP backtracking should, perhaps, be done sparingly\u2014rather than every time a GTP task being pursued has no solution\u2014by relying more on HTN backtracking, albeit at the expense of completeness. Another tradeoff between completeness and efficiency is to significantly\n7While GIVE(O, H) also needs O to be reachable to H in free space, in our scenario this is easy to achieve.\nreduce the grasps and orientations tested by GTP tasks like MAKEACC(O,M) to a few \u201cgood\u201d ones that generally work well; the number of pixels tested when determining object visibility could also be reduced in a similar way. We believe that these improvements will make the combined system more practical for real-world applications."}, {"heading": "VI. CONCLUSION", "text": "We have presented an approach to combining HTN and geometric task planning, which allows more sophisticated reasoning than possible with standard trajectory planning. The combination makes way for rich backtracking at multiple levels, and also interleaved backtracking. We showed how the two planners could be interfaced, and gave insights into a methodology for developing HTN-GTP domains. Our prototype implementation is able to do basic GTP backtracking, and to compute and share symbolic facts, which the HTN developer can use in preconditions. Finally, we presented experimental results that we intend to use as a benchmark to test future extensions, and for developing heuristics for the GTP."}], "references": [{"title": "Mightability maps: A perceptual level decisional framework for co-operative and competitive human-robot interaction", "author": ["A.K. Pandey", "R. Alami"], "venue": "IROS, 2010, pp. 5842\u20135848.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Combining task and path planning for a humanoid twoarm robotic system", "author": ["L. Karlsson", "J. Bidot", "F. Lagriffoul", "A. Saffiotti", "U. Hillenbrand", "F. Schmidt"], "venue": "ICAPS Workshop on Combining Task and Motion Planning for Real-World Applications, 2012, pp. 13\u201320.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Constraint propagation on interval bounds for dealing with geometric backtracking", "author": ["F. Lagriffoul", "D. Dimitrov", "A. Saffiotti", "L. Karlsson"], "venue": "IROS, 2012, pp. 957\u2013964.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Total-order planning with partially ordered subtasks", "author": ["D. Nau", "H. Mu\u00f1oz Avila", "Y. Cao", "A. Lotem", "S. Mitchell"], "venue": "IJCAI, 2001, pp. 425\u2013430.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Integrating symbolic and geometric planning for mobile manipulation", "author": ["C. Dornhege", "M. Gissler", "M. Teschner", "B. Nebel"], "venue": "IEEE International Workshop on Safety, Security and Rescue Robotics, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Semantic attachments for domain-independent planning systems", "author": ["C. Dornhege", "P. Eyerich", "T. Keller", "S. Tr\u00fcg", "M. Brenner", "B. Nebel"], "venue": "ICAPS, 2009.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Integrating task and motion planning using semantic attachments", "author": ["C. Dornhege", "P. Eyerich", "T. Keller", "M. Brenner", "B. Nebel"], "venue": "Bridging the Gap Between Task and Motion Planning, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Combined task and motion planning for mobile manipulation", "author": ["J. Wolfe", "B. Marthi", "S.J. Russell"], "venue": "ICAPS, 2010, pp. 254\u2013258.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Hierarchical task and motion planning in the now", "author": ["L.P. Kaelbling", "T. Lozano-P\u00e9rez"], "venue": "ICRA, 2011, pp. 1470\u20131477.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "A robot task planner that merges symbolic and geometric reasoning", "author": ["S. Cambon", "F. Gravot", "R. Alami"], "venue": "ECAI, 2004, pp. 895\u2013899.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Sampling-based motion and symbolic action planning with geometric and differential constraints", "author": ["E. Plaku", "G. Hager"], "venue": "ICRA, 2010, pp. 5002\u20135008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "STRIPS: A new approach to the application of theorem proving to problem solving", "author": ["R. Fikes", "N. Nilsson"], "venue": "Artificial Intelligence, vol. 2, no. 3-4, pp. 189\u2013208, 1971.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1971}, {"title": "SHOP: Simple hierarchical ordered planner", "author": ["D. Nau", "Y. Cao", "A. Lotem", "H. Mu\u00f1oz-Avila"], "venue": "IJCAI, 1999, pp. 968\u2013973.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "Towards planning human-robot interactive manipulation tasks: Task dependent and human oriented autonomous selection of grasp and placement", "author": ["A.K. Pandey", "J.-P. Saut", "D. Sidobre", "R. Alami"], "venue": "IEEE RAS/EMBS BioRob, 2012, pp. 1371\u20131376.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Move3d: a generic platform for path planning", "author": ["T. Simeon", "J.-P. Laumond", "F. Lamiraux"], "venue": "4th Int. Symp. on Assembly and Task Planning, 2001, pp. 25\u201330.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards shared attention through geometric reasoning for human robot interaction", "author": ["L. Marin-Urias", "E. Sisbot", "A. Pandey", "R. Tadakuma", "R. Alami"], "venue": "IEEE-RAS International Conference on Humanoid Robots, 2009, pp. 331 \u2013336. 6", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "It is therefore important to decide how we can effectively interleave geometric and symbolic backtracking [1], [2], and how we should switch between them.", "startOffset": 106, "endOffset": 109}, {"referenceID": 1, "context": "It is therefore important to decide how we can effectively interleave geometric and symbolic backtracking [1], [2], and how we should switch between them.", "startOffset": 111, "endOffset": 114}, {"referenceID": 1, "context": "In [2], [3] the authors discuss algorithms for geometric backtracking by extending the Justin robot with symbolicgeometric planning capabilities: they use the JSHOP2 [4] HTN planner for the symbolic planning component and a specialised path planner for the geometric one.", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "In [2], [3] the authors discuss algorithms for geometric backtracking by extending the Justin robot with symbolicgeometric planning capabilities: they use the JSHOP2 [4] HTN planner for the symbolic planning component and a specialised path planner for the geometric one.", "startOffset": 8, "endOffset": 11}, {"referenceID": 3, "context": "In [2], [3] the authors discuss algorithms for geometric backtracking by extending the Justin robot with symbolicgeometric planning capabilities: they use the JSHOP2 [4] HTN planner for the symbolic planning component and a specialised path planner for the geometric one.", "startOffset": 166, "endOffset": 169}, {"referenceID": 4, "context": "fr To interface symbolic and geometric planning, the authors in [5], [6] introduce \u201csemantic attachments,\u201d which associate selected predicates in the planning domain to external procedures called at runtime to evaluate the predicates.", "startOffset": 64, "endOffset": 67}, {"referenceID": 5, "context": "fr To interface symbolic and geometric planning, the authors in [5], [6] introduce \u201csemantic attachments,\u201d which associate selected predicates in the planning domain to external procedures called at runtime to evaluate the predicates.", "startOffset": 69, "endOffset": 72}, {"referenceID": 6, "context": "In [7], the semantic attachments are implemented using a trajectory planner that computes collision free trajectories; if one exists, then the corresponding semantic attachment evaluates to true , and false otherwise.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "In [8], for instance, a hierarchical planner plans all the way down to the level of geometric actions.", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "Similarly, [9] describes a special purpose hierarchical planner combined with a geometric motion planner for planning, and then executing the most basic actions while the plan is still being constructed.", "startOffset": 11, "endOffset": 14}, {"referenceID": 9, "context": "The Asymov [10] system is a combined task and motion planner for problems that are difficult to solve when the symbolic planner is in control of the geometric search, e.", "startOffset": 11, "endOffset": 15}, {"referenceID": 10, "context": "Similarly, in [11] a symbolic planner guides a sampling-based motion planner, which in turn sends back utility estimates to improve the guide in the next iteration.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "In this paper we refer to the popular STRIPS classical planning language [12].", "startOffset": 73, "endOffset": 77}, {"referenceID": 12, "context": "\u201d In this paper we use a popular type of HTN planning called \u201ctotally-ordered\u201d HTN (henceforth simply referred to as HTN) planning, which has proven to be efficient in certain domains [13].", "startOffset": 184, "endOffset": 188}, {"referenceID": 2, "context": "For the geometric counterpart, we adopt the approach of finding a solution in a discrete space of candidate grasps and placements [3], [14] for tasks involving picking and placing.", "startOffset": 130, "endOffset": 133}, {"referenceID": 13, "context": "For the geometric counterpart, we adopt the approach of finding a solution in a discrete space of candidate grasps and placements [3], [14] for tasks involving picking and placing.", "startOffset": 135, "endOffset": 139}, {"referenceID": 0, "context": "For example, predicate reachable(o, h) in the HTN domain (see method m8), which specifies that object o is reachable to human h, is derived from the 3D world with a heuristic based on the area covered on extending the robot\u2019s arm with respect to all its degrees of freedom [1].", "startOffset": 273, "endOffset": 276}, {"referenceID": 14, "context": "For 3D visualization and planning we use the Move3D software [15].", "startOffset": 61, "endOffset": 65}, {"referenceID": 0, "context": "Our current GTP implementation has some of the functionality depicted in Figure 3, including: (i) storing the sequence of GTP tasks pursued so far; (ii) basic backtracking to find an alternative solution for a chosen GTP task in the sequence; and (iii) computing predicates such as visible(O,A), reachable(O,A), on(O,O2), inside(O,O2) and coveredBy(O,O2) for an agent A and objects O,O2, where the first two are computed based on the concept of mightability maps presented in [1]\u2014which the authors showed to be computed and updated fast enough for online HRI\u2014and the other facts using techniques from the geometric analysis of the 3D world model, and domain specific heuristics.", "startOffset": 476, "endOffset": 479}, {"referenceID": 15, "context": "Note that something is deemed visible to a human based on a threshold on the percentage of pixels visible, using the approach presented in [16].", "startOffset": 139, "endOffset": 143}], "year": 2013, "abstractText": "In this paper we present an interface between a symbolic planner and a geometric task planner, which is different to a standard trajectory planner in that the former is able to perform geometric reasoning on abstract entities\u2014tasks. We believe that this approach facilitates a more principled interface to symbolic planning, while also leaving more room for the geometric planner to make independent decisions. We show how the two planners could be interfaced, and how their planning and backtracking could be interleaved. We also provide insights for a methodology for using the combined system, and experimental results to use as a benchmark with future extensions to both the combined system, as well as to the geometric task planner.", "creator": "TeX"}}}