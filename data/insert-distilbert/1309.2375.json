{"id": "1309.2375", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2013", "title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "abstract": "we introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner - outer iteration procedure. we analyze the runtime limitations of the framework and collectively obtain rates errors that improve state - of - the - art results estimates for various key machine learning optimization machine problems including svm, explicit logistic anomaly regression, ridge regression, lasso, and intrinsic multiclass svm. experiments validate our theoretical findings.", "histories": [["v1", "Tue, 10 Sep 2013 05:39:25 GMT  (38kb,D)", "https://arxiv.org/abs/1309.2375v1", null], ["v2", "Tue, 8 Oct 2013 06:06:09 GMT  (38kb,D)", "http://arxiv.org/abs/1309.2375v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.NA stat.CO", "authors": ["shai shalev-shwartz", "tong zhang 0001"], "accepted": true, "id": "1309.2375"}, "pdf": {"name": "1309.2375.pdf", "metadata": {"source": "CRF", "title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "authors": ["Shai Shalev-Shwartz", "Tong Zhang"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "We consider the following generic optimization problem associated with regularized loss minimization of linear predictors: Let X1, . . . , Xn be matrices in Rd\u00d7k (referred to as instances), let \u03c61, . . . , \u03c6n be a sequence of vector convex functions defined on Rk (referred to as loss functions), let g(\u00b7) be a convex function defined on Rd (referred to as a regularizer), and let \u03bb \u2265 0 (referred to as a regularization parameter). Our goal is to solve:\nmin w\u2208Rd P (w) where P (w) =\n[ 1\nn n\u2211 i=1 \u03c6i(X > i w) + \u03bbg(w)\n] . (1)\nFor example, in ridge regression the regularizer is g(w) = 12\u2016w\u2016 2 2, the instances are column vectors, and for every i the i\u2019th loss function is \u03c6i(a) = 12(a\u2212 yi) 2, for some scalar yi.\nLet w\u2217 = argminw P (w) (we will later make assumptions that imply that w \u2217 is unique). We say that w is -accurate if P (w) \u2212 P (w\u2217) \u2264 . Our main result is a new algorithm for solving (1). If g is 1-strongly convex and each \u03c6i is (1/\u03b3)-smooth (meaning that its gradient is (1/\u03b3)-Lipschitz), then our algorithm finds, with probability of at least 1\u2212 \u03b4, an -accurate solution to (1) in time\nO ( d ( n+ min { 1\n\u03bb \u03b3 ,\n\u221a n\n\u03bb \u03b3\n}) log(1/ ) log(1/\u03b4) max{1, log2(1/(\u03bb \u03b3 n))} ) = O\u0303 ( d ( n+ min { 1\n\u03bb \u03b3 ,\n\u221a n\n\u03bb \u03b3\n})) .\nThis applies, for example, to ridge regression and to logistic regression with L2 regularization. The O notation hides constants terms and the O\u0303 notation hides constants and logarithmic terms. We make these explicit in the formal statement of our theorems. \u2217School of Computer Science and Engineering, The Hebrew University, Jerusalem, Israel \u2020Department of Statistics, Rutgers University, NJ, USA \u2021Baidu Inc., Beijing, China\nar X\niv :1\n30 9.\n23 75\nv2 [\nst at\n.M L\n] 8\nO ct\n2 01\n3\nIntuitively, we can think of 1\u03bb\u03b3 as the condition number of the problem. If the condition number is O(n) then our runtime becomes O\u0303(dn). This means that the runtime is nearly linear in the data size. This matches the recent result of Shalev-Shwartz and Zhang [25], Le Roux et al. [15], but our setting is significantly more general. When the condition number is much larger than n, our runtime becomes O\u0303(d \u221a n \u03bb \u03b3 ). This significantly improves over the result of [25, 15]. It also significantly improves over the\nruntime of accelerated gradient descent due to Nesterov [18], which is O\u0303(dn \u221a\n1 \u03bb \u03b3 ).\nBy applying a smoothing technique to \u03c6i, we also derive a method that finds an -accurate solution to (1) assuming that each \u03c6i is O(1)-Lipschitz, and obtain the runtime\nO\u0303 ( d ( n+ min { 1\n\u03bb ,\n\u221a n\n\u03bb\n})) .\nThis applies, for example, to SVM with the hinge-loss. It significantly improves over the rate d\u03bb of SGD (e.g. [22]), when 1\u03bb n.\nWe can also apply our results to non-strongly convex regularizers (such as the L1 norm regularizer), or to non-regularized problems, by adding a slight L2 regularization. For example, for L1 regularized problems, and assuming that each \u03c6i is (1/\u03b3)-smooth, we obtain the runtime of\nO\u0303 ( d ( n+ min { 1\n\u03b3 ,\n\u221a n\n\u03b3\n})) .\nThis applies, for example, to the Lasso problem, in which the goal is to minimize the squared loss plus an L1 regularization term.\nTo put our results in context, in the table below we specify the runtime of various algorithms (while ignoring constants and logarithmic terms) for three key machine learning applications; SVM in which \u03c6i(a) = max{0, 1 \u2212 a} and g(w) = 12\u2016w\u2016 2 2, Lasso in which \u03c6i(a) = 1 2(a \u2212 yi)\n2 and g(w) = \u03c3\u2016w\u20161, and Ridge Regression in which \u03c6i(a) = 12(a \u2212 yi) 2 and g(w) = 12\u2016w\u2016 2 2. Additional applications, and a more detailed runtime comparison to previous work, are given in Section 5. In the table below, SGD stands for Stochastic Gradient Descent, and AGD stands for Accelerated Gradient Descent.\nProblem Algorithm Runtime\nSVM\nSGD [22] d\u03bb AGD [17] dn \u221a 1 \u03bb\nThis paper d ( n+ min{ 1\u03bb , \u221a n \u03bb } )\nLasso\nSGD and variants (e.g. [28, 27, 21]) d 2\nStochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1\nThis paper d ( n+ min{1 , \u221a n } )\nRidge Regression\nExact d2n+ d3 SGD [15], SDCA [25] d ( n+ 1\u03bb ) AGD [18] dn \u221a 1 \u03bb\nThis paper d ( n+ min{ 1\u03bb , \u221a n \u03bb} )\nTechnical contribution: Our algorithm combines two ideas. The first is a proximal version of stochastic dual coordinate ascent (SDCA).1 In particular, we generalize the recent analysis of [25] in two directions. First, we allow the regularizer, g, to be a general strongly convex function (and not necessarily the squared Euclidean norm). This allows us to consider non-smooth regularization function, such as the L1 regularization. Second, we allow the loss functions, \u03c6i, to be vector valued functions which are smooth (or Lipschitz) with respect to a general norm. This generalization is useful in multiclass applications. As in [25], the runtime of this procedure is O\u0303 ( d ( n+ 1\u03bb\u03b3 )) . This would be a nearly linear time (in the size of the data) if 1\u03bb\u03b3 = O(n). Our second idea deals with the case 1 \u03bb\u03b3 n by iteratively approximating the objective function P with objective functions that have a stronger regularization. In particular, each iteration of our acceleration procedure involves approximate minimization of P (w) + \u03ba2\u2016w\u2212 y\u2016 2 2, with respect to w, where y is a vector obtained from previous iterates and \u03ba is order of 1/(\u03b3n). The idea is that the addition of the relatively strong regularization makes the runtime of our proximal stochastic dual coordinate ascent procedure be O\u0303(dn). And, with a proper choice of y at each iteration, we show that the sequence of solutions\nof the problems with the added regularization converge to the minimum of P after \u221a\n1 \u03bb\u03b3n iterations. This yields the overall runtime of d \u221a\nn \u03bb\u03b3 .\nAdditional related work: As mentioned before, our first contribution is a proximal version of the stochastic dual coordinate ascent method and extension of the analysis given in Shalev-Shwartz and Zhang [25]. Stochastic dual coordinate ascent has also been studied in Collins et al. [3] but in more restricted settings than the general problem considered in this paper. One can also apply the analysis of stochastic coordinate descent methods given in Richt\u00e1rik and Tak\u00e1c\u030c [19] on the dual problem. However, here we are interested in understanding the primal sub-optimality, hence an analysis which only applies to the dual problem is not sufficient.\nThe generality of our approach allows us to apply it for multiclass prediction problems. We discuss this in detail later on in Section 5. Recently, [13] derived a stochastic coordinate ascent for structural SVM based on the Frank-Wolfe algorithm. Although with different motivations, for the special case of multiclass problems with the hinge-loss, their algorithm ends up to be the same as our proximal dual ascent algorithm (with the same rate). Our approach allows to accelerate the method and obtain an even faster rate.\nThe proof of our acceleration method adapts Nesterov\u2019s estimation sequence technique, studied in Devolder et al. [7], Schmidt et al. [20], to allow approximate and stochastic proximal mapping. See also [1, 6]. In particular, it relies on similar ideas as in Proposition 4 of [20]. However, our specific requirement is different, and the proof presented here is different and significantly simpler than that of [20].\nThere have been several attempts to accelerate stochastic optimization algorithms. See for example [12, 11, 4] and the references therein. However, the runtime of these methods have a polynomial dependence on 1/ even if \u03c6i are smooth and g is \u03bb-strongly convex, as opposed to the logarithmic dependence on 1/ obtained here. As in [15, 25], we avoid the polynomial dependence on 1/ by allowing more than a single pass over the data.\n1Technically speaking, it may be more accurate to use the term randomized dual coordinate ascent, instead of stochastic dual coordinate ascent. This is because our algorithm makes more than one pass over the data, and therefore cannot work directly on distributions with infinite support. However, following the convention in the prior machine learning literature, we do not make this distinction."}, {"heading": "2 Preliminaries", "text": "All the functions we consider in this paper are proper convex functions over a Euclidean space. We use R to denote the set of real numbers and to simplify our notation, when we use R to denote the range of a function f we in fact allow f to output the value +\u221e.\nGiven a function f : Rd \u2192 R we denote its conjugate function by\nf\u2217(y) = sup x [y>x\u2212 f(x)] .\nGiven a norm \u2016 \u00b7 \u2016P we denote the dual norm by \u2016 \u00b7 \u2016D where\n\u2016y\u2016D = sup x:\u2016x\u2016P=1\ny>x.\nWe use \u2016\u00b7\u2016 or \u2016\u00b7\u20162 to denote the L2 norm, \u2016x\u2016 = x>x. We also use \u2016x\u20161 = \u2211\ni |xi| and \u2016x\u2016\u221e = maxi |xi|. The operator norm of a matrix X with respect to norms \u2016 \u00b7 \u2016P , \u2016 \u00b7 \u2016P \u2032 is defined as\n\u2016X\u2016P\u2192P \u2032 = sup u:\u2016u\u2016P=1 \u2016Xu\u2016P \u2032 .\nA function f : Rk \u2192 Rd is L-Lipschitz with respect to a norm \u2016 \u00b7 \u2016P , whose dual norm is \u2016 \u00b7 \u2016D, if for all a, b \u2208 Rd, we have \u2016f(a)\u2212 f(b)\u2016D \u2264 L \u2016a\u2212 b\u2016P . A function f : Rd \u2192 R is (1/\u03b3)-smooth with respect to a norm \u2016 \u00b7 \u2016P if it is differentiable and its gradient is (1/\u03b3)-Lipschitz with respect to \u2016 \u00b7 \u2016P . An equivalent condition is that for all a, b \u2208 Rd, we have\nf(a) \u2264 f(b) +\u2207f(b)>(a\u2212 b) + 1 2\u03b3 \u2016a\u2212 b\u20162P .\nA function f : Rd \u2192 R is \u03b3-strongly convex with respect to \u2016 \u00b7 \u2016P if\nf(w + v) \u2265 f(w) +\u2207f(w)>v + \u03b3 2 \u2016v\u20162P .\nIt is well known that f is \u03b3-strongly convex with respect to \u2016 \u00b7 \u2016P if and only if f\u2217 is (1/\u03b3)-smooth with respect to the dual norm, \u2016 \u00b7 \u2016D.\nThe dual problem of (1) is\nmax \u03b1\u2208Rk\u00d7n D(\u03b1) where D(\u03b1) =\n[ 1\nn n\u2211 i=1 \u2212\u03c6\u2217i (\u2212\u03b1i)\u2212 \u03bbg\u2217 ( 1 \u03bbn n\u2211 i=1 Xi\u03b1i )] , (2)\nwhere \u03b1i is the i\u2019th column of the matrix \u03b1, which forms a vector in Rk. We will assume that g is strongly convex which implies that g\u2217(\u00b7) is continuous differentiable. If we define\nv(\u03b1) = 1\n\u03bbn n\u2211 i=1 Xi\u03b1i and w(\u03b1) = \u2207g\u2217(v(\u03b1)), (3)\nthen it is known that w(\u03b1\u2217) = w\u2217, where \u03b1\u2217 is an optimal solution of (2). It is also known that P (w\u2217) = D(\u03b1\u2217) which immediately implies that for all w and \u03b1, we have P (w) \u2265 D(\u03b1), and hence the duality gap defined as P (w(\u03b1))\u2212D(\u03b1) can be regarded as an upper bound on both the primal sub-optimality, P (w(\u03b1))\u2212P (w\u2217), and on the dual sub-optimality, D(\u03b1\u2217)\u2212D(\u03b1)."}, {"heading": "3 Main Results", "text": "In this section we describe our algorithms and their analysis. We start in Section 3.1 with a description of our proximal stochastic dual coordinate ascent procedure (Prox-SDCA). Then, in Section 3.2 we show how to accelerate the method by calling Prox-SDCA on a sequence of problems with a strong regularization. Throughout the first two sections we assume that the loss functions are smooth. Finally, we discuss the case of Lipschitz loss functions in Section 3.3.\nThe proofs of the main acceleration theorem (Theorem 3) is given in Section 4. The rest of the proofs are provided in the appendix."}, {"heading": "3.1 Proximal Stochastic Dual Coordinate Ascent", "text": "We now describe our proximal stochastic dual coordinate ascent procedure for solving (1). Our results in this subsection holds for g being a 1-strongly convex function with respect to some norm \u2016 \u00b7 \u2016P \u2032 and every \u03c6i being a (1/\u03b3)-smooth function with respect to some other norm \u2016 \u00b7 \u2016P . The corresponding dual norms are denoted by \u2016 \u00b7 \u2016D\u2032 and \u2016 \u00b7 \u2016D respectively.\nThe dual objective in (2) has a different dual vector associated with each example in the training set. At each iteration of dual coordinate ascent we only allow to change the i\u2019th column of \u03b1, while the rest of the dual vectors are kept intact. We focus on a randomized version of dual coordinate ascent, in which at each round we choose which dual vector to update uniformly at random.\nAt step t, let v(t\u22121) = (\u03bbn)\u22121 \u2211\niXi\u03b1 (t\u22121) i and let w (t\u22121) = \u2207g\u2217(v(t\u22121)). We will update the i-th dual variable \u03b1(t)i = \u03b1 (t\u22121) i + \u2206\u03b1i, in a way that will lead to a sufficient increase of the dual objective. For the primal problem, this would lead to the update v(t) = v(t\u22121)+(\u03bbn)\u22121Xi\u2206\u03b1i, and thereforew(t) = \u2207g\u2217(v(t)) can also be written as\nw(t) = argmax w\n[ w>v(t) \u2212 g(w) ] = argmin\nw\n[ \u2212w> ( n\u22121\nn\u2211 i=1 Xi\u03b1 (t) i\n) + \u03bbg(w) ] .\nNote that this particular update is rather similar to the update step of proximal-gradient dual-averaging method (see for example Xiao [27]). The difference is on how \u03b1(t) is updated.\nThe goal of dual ascent methods is to increase the dual objective as much as possible, and thus the optimal way to choose \u2206\u03b1i would be to maximize the dual objective, namely, we shall let\n\u2206\u03b1i = argmax \u2206\u03b1i\u2208Rk\n[ \u2212 1 n \u03c6\u2217i (\u2212(\u03b1i + \u2206\u03b1i))\u2212 \u03bbg\u2217(v(t\u22121) + (\u03bbn)\u22121Xi\u2206\u03b1i) ] .\nHowever, for a complex g\u2217(\u00b7), this optimization problem may not be easy to solve. To simplify the optimization problem we can rely on the smoothness of g\u2217 (with respect to a norm \u2016 \u00b7 \u2016D\u2032) and instead of directly maximizing the dual objective function, we try to maximize the following proximal objective which is a lower bound of the dual objective:\nargmax \u2206\u03b1i\u2208Rk\n[ \u2212 1 n \u03c6\u2217i (\u2212(\u03b1i + \u2206\u03b1i))\u2212 \u03bb ( \u2207g\u2217(v(t\u22121))>(\u03bbn)\u22121Xi\u2206\u03b1i + 1 2 \u2016(\u03bbn)\u22121Xi\u2206\u03b1i\u20162D\u2032 )] = argmax\n\u2206\u03b1i\u2208Rk\n[ \u2212\u03c6\u2217i (\u2212(\u03b1i + \u2206\u03b1i))\u2212 w(t\u22121)>Xi\u2206\u03b1i \u2212 1\n2\u03bbn \u2016Xi\u2206\u03b1i\u20162D\u2032\n] .\nIn general, this optimization problem is still not necessarily simple to solve because \u03c6\u2217 may also be complex. We will thus also propose alternative update rules for \u2206\u03b1i of the form \u2206\u03b1i = s(\u2212\u2207\u03c6i(X>i w(t\u22121))\u2212\u03b1 (t\u22121) i ) for an appropriately chosen step size parameter s > 0. Our analysis shows that an appropriate choice of s still leads to a sufficient increase in the dual objective.\nIt should be pointed out that we can always pick \u2206\u03b1i so that the dual objective is non-decreasing. In fact, if for a specific choice of \u2206\u03b1i, the dual objective decreases, we may simply set \u2206\u03b1i = 0. Therefore throughout the proof we will assume that the dual objective is non-decreasing whenever needed.\nThe theorems below provide upper bounds on the number of iterations required by our prox-SDCA procedure.\nTheorem 1. Consider Procedure Prox-SDCA as given in Figure 1. Let \u03b1\u2217 be an optimal dual solution and let > 0. For every T such that\nT \u2265 ( n+ R2\n\u03bb\u03b3\n) log (( n+ R2\n\u03bb\u03b3\n) \u00b7 D(\u03b1 \u2217)\u2212D(\u03b1(0)) ) ,\nwe are guaranteed that E[P (w(T ))\u2212D(\u03b1(T ))] \u2264 . Moreover, for every T such that\nT \u2265 ( n+ \u2308 R2\n\u03bb\u03b3\n\u2309) \u00b7 ( 1 + log ( D(\u03b1\u2217)\u2212D(\u03b1(0)) )) ,\nlet T0 = T \u2212 n\u2212 dR 2 \u03bb\u03b3 e, then we are guaranteed that E[P (w\u0304)\u2212D(\u03b1\u0304)] \u2264 .\nWe next give bounds that hold with high probability.\nTheorem 2. Consider Procedure Prox-SDCA as given in Figure 1. Let \u03b1\u2217 be an optimal dual solution, let D, P > 0, and let \u03b4 \u2208 (0, 1).\n1. For every T such that\nT \u2265 \u2308( n+ R2\n\u03bb\u03b3\n) log ( 2(D(\u03b1\u2217)\u2212D(\u03b1(0)))\nD\n)\u2309 \u00b7 \u2308\nlog2\n( 1\n\u03b4\n)\u2309 ,\nwe are guaranteed that with probability of at least 1\u2212 \u03b4 it holds that D(\u03b1\u2217)\u2212D(\u03b1(T )) \u2264 D.\n2. For every T such that\nT \u2265 \u2308( n+ R2\n\u03bb\u03b3\n) ( log ( n+ R2\n\u03bb\u03b3\n) + log ( 2(D(\u03b1\u2217)\u2212D(\u03b1(0)))\nP\n))\u2309 \u00b7 \u2308\nlog2\n( 1\n\u03b4\n)\u2309 ,\nwe are guaranteed that with probability of at least 1\u2212 \u03b4 it holds that P (w(T ))\u2212D(\u03b1(T )) \u2264 P .\n3. Let T be such that T \u2265 ( n+ \u2308 R2\n\u03bb\u03b3\n\u2309) \u00b7 ( 1 + \u2308 log ( 2(D(\u03b1\u2217)\u2212D(\u03b1(0)))\nP\n)\u2309) \u00b7 \u2308\nlog2\n( 2\n\u03b4\n)\u2309 ,\nand let T0 = T \u2212 n \u2212 dR 2\n\u03bb\u03b3 e. Suppose we choose dlog2(2/\u03b4)e values of t uniformly at random from T0 + 1, . . . , T , and then choose the single value of t from these dlog2(2/\u03b4)e values for which P (w(t))\u2212D(\u03b1(t)) is minimal. Then, with probability of at least 1\u2212\u03b4 we have thatP (w(t))\u2212D(\u03b1(t)) \u2264 P .\nThe above theorem tells us that the runtime required to find an accurate solution, with probability of at least 1\u2212 \u03b4, is\nO ( d ( n+ R2\n\u03bb\u03b3\n) \u00b7 log ( D(\u03b1\u2217)\u2212D(\u03b1(0)) ) \u00b7 log ( 1\n\u03b4\n)) . (4)\nThis yields the following corollary.\nCorollary 1. The expected runtime required to minimize P up to accuracy is\nO ( d ( n+ R2\n\u03bb\u03b3\n) \u00b7 log ( D(\u03b1\u2217)\u2212D(\u03b1(0)) )) .\nProof. We have shown that with a runtime of O ( d ( n+ R 2\n\u03bb\u03b3\n) \u00b7 log ( 2(D(\u03b1\u2217)\u2212D(\u03b1(0))) )) we can find an\naccurate solution with probability of at least 1/2. Therefore, we can run the procedure for this amount of time and check if the duality gap is smaller than . If yes, we are done. Otherwise, we would restart the process. Since the probability of success is 1/2 we have that the average number of restarts we need is 2, which concludes the proof."}, {"heading": "3.2 Acceleration", "text": "The Prox-SDCA procedure described in the previous subsection has the iteration bound of O\u0303 ( n+ R 2\n\u03bb\u03b3\n) .\nThis is a nearly linear runtime whenever the condition number, R2/(\u03bb\u03b3), is O(n). In this section we show how to improve the dependence on the condition number by an acceleration procedure. In particular, throughout this section we assume that 10n < R 2\n\u03bb\u03b3 . We further assume throughout this subsection that the regularizer, g, is 1-strongly convex with respect to the Euclidean norm, i.e. \u2016u\u2016P \u2032 = \u2016 \u00b7 \u20162. This also implies that \u2016u\u2016D\u2032 is the Euclidean norm. A generalization of the acceleration technique for strongly convex regularizers with respect to general norms is left to future work.\nThe main idea of the acceleration procedure is to iteratively run the Prox-SDCA procedure, where at iteration t we call Prox-SDCA with the modified objective, P\u0303t(w) = P (w) + \u03ba2\u2016w\u2212 y\n(t\u22121)\u20162, where \u03ba is a relatively large regularization parameter and the regularization is centered around the vector\ny(t\u22121) = w(t\u22121) + \u03b2(w(t\u22121) \u2212 w(t\u22122))\nfor some \u03b2 \u2208 (0, 1). That is, our regularization is centered around the previous solution plus a \u201cmomentum term\u201d \u03b2(w(t\u22121) \u2212 w(t\u22122)).\nA pseudo-code of the algorithm is given in Figure 2. Note that all the parameters of the algorithm are determined by our theory.\nRemark 1. In the pseudo-code below, we specify the parameters based on our theoretical derivation. In our experiments, we found out that this choice of parameters also work very well in practice. However, we also found out that the algorithm is not very sensitive to the choice of parameters. For example, we found out that running 5n iterations of Prox-SDCA (that is, 5 epochs over the data), without checking the stopping condition, also works very well.\nThe main theorem is the following.\nTheorem 3. Consider the accelerated Prox-SDCA algorithm given in Figure 2.\n\u2022 Correctness: When the algorithm terminates we have that P (w(t))\u2212 P (w\u2217) \u2264 .\n\u2022 Runtime:\n\u2013 The number of outer iterations is at most\n1 + 2\n\u03b7 log(\u03be1/ ) \u2264 1 +\n\u221a 8R2\n\u03bb\u03b3n\n( log ( 2R2\n\u03bb\u03b3n\n) + log ( P (0)\u2212D(0) )) .\n\u2013 Each outer iteration involves a single call to Prox-SDCA, and the averaged runtime required by each such call is\nO ( dn log ( R2\n\u03bb\u03b3n\n)) .\nBy a straightforward amplification argument we obtain that for every \u03b4 \u2208 (0, 1) the total runtime required by accelerated Prox-SDCA to guarantee an -accurate solution with probability of at least 1\u2212 \u03b4 is\nO ( d \u221a nR2\n\u03bb \u03b3 log\n( R2\n\u03bb \u03b3 n\n) ( log ( R2\n\u03bb\u03b3n\n) + log ( P (0)\u2212D(0) )) log ( 1\n\u03b4\n)) ."}, {"heading": "3.3 Non-smooth, Lipschitz, loss functions", "text": "So far we have assumed that for every i, \u03c6i is a (1/\u03b3)-smooth function. We now consider the case in which \u03c6i might be non-smooth, and even non-differentiable, but it is L-Lipschitz.\nFollowing Nesterov [17], we apply a \u201csmoothing\u201d technique. We first observe that if \u03c6 is L-Lipschitz function then the domain of \u03c6\u2217 is in the ball of radius L.\nLemma 1. Let \u03c6 : Rk \u2192 R be an L-Lipschitz function w.r.t. a norm \u2016 \u00b7 \u2016P and let \u2016 \u00b7 \u2016D be the dual norm. Then, for any \u03b1 \u2208 Rk s.t. \u2016\u03b1\u2016D > L we have that \u03c6\u2217(\u03b1) =\u221e.\nProof. Fix some \u03b1 with \u2016\u03b1\u2016D > L. Let x0 be a vector such that \u2016x0\u2016P = 1 and \u03b1>x0 = \u2016\u03b1\u2016D (this is a vector that achieves the maximal objective in the definition of the dual norm). By definition of the conjugate we have\n\u03c6\u2217(\u03b1) = sup x [\u03b1> x\u2212 \u03c6(x)]\n= \u2212\u03c6(0) + sup x\n[\u03b1> x\u2212 (\u03c6(x)\u2212 \u03c6(0))]\n\u2265 \u2212\u03c6(0) + sup x\n[\u03b1> x\u2212 L\u2016x\u2212 0\u2016P ]\n\u2265 \u2212\u03c6(0) + sup c>0\n[\u03b1> (cx0)\u2212 L\u2016cx0\u2016P ]\n= \u2212\u03c6(0) + sup c>0 (\u2016\u03b1\u2016D \u2212 L) c =\u221e .\nThis observation allows us to smooth L-Lipschitz functions by adding regularization to their conjugate. In particular, the following lemma generalizes Lemma 2.5 in [26].\nLemma 2. Let \u03c6 be a proper, convex, L-Lipschitz function w.r.t. a norm \u2016 \u00b7 \u2016P , let \u2016 \u00b7 \u2016D be the dual norm, and let \u03c6\u2217 be the conjugate of \u03c6. Assume that \u2016 \u00b7 \u20162 \u2264 \u2016 \u00b7 \u2016D. Define \u03c6\u0303\u2217(\u03b1) = \u03c6\u2217(\u03b1) + \u03b32\u2016\u03b1\u2016 2 2 and let \u03c6\u0303 be the conjugate of \u03c6\u0303\u2217. Then, \u03c6\u0303 is (1/\u03b3)-smooth w.r.t. the Euclidean norm and\n\u2200a, 0 \u2264 \u03c6(a)\u2212 \u03c6\u0303(a) \u2264 \u03b3L2/2 .\nProof. The fact that \u03c6\u0303 is (1/\u03b3)-smooth follows directly from the fact that \u03c6\u0303\u2217 is \u03b3-strongly convex. For the second claim note that\n\u03c6\u0303(a) = sup b\n[ ba\u2212 \u03c6\u2217(b)\u2212 \u03b3\n2 \u2016b\u201622\n] \u2264 sup\nb [ba\u2212 \u03c6\u2217(b)] = \u03c6(a)\nand\n\u03c6\u0303(a) = sup b\n[ ba\u2212 \u03c6\u2217(b)\u2212 \u03b3\n2 \u2016b\u201622\n] = sup\nb:\u2016b\u2016D\u2264L\n[ ba\u2212 \u03c6\u2217(b)\u2212 \u03b3\n2 \u2016b\u201622 ] \u2265 sup\nb:\u2016b\u2016D\u2264L\n[ ba\u2212 \u03c6\u2217(b)\u2212 \u03b3\n2 \u2016b\u20162D\n] \u2265 sup\nb:\u2016b\u2016D\u2264L [ba\u2212 \u03c6\u2217(b)]\u2212 \u03b3 2 L2\n= \u03c6(a)\u2212 \u03b3 2 L2 .\nRemark 2. It is also possible to smooth using different regularization functions which are strongly convex with respect to other norms. See Nesterov [17] for discussion."}, {"heading": "4 Proof of Theorem 3", "text": "The first claim of the theorem is that when the procedure stops we have P (w(t))\u2212P (w\u2217) \u2264 . We therefore need to show that each stopping condition guarantees that P (w(t))\u2212 P (w\u2217) \u2264 .\nFor the second stopping condition, recall thatw(t) is an t-accurate minimizer of P (w)+ \u03ba2\u2016w\u2212y (t\u22121)\u20162,\nand hence by Lemma 3 below (with z = w\u2217, w+ = w(t), and y = y(t\u22121)):\nP (w\u2217) \u2265 P (w(t)) +Q (w\u2217;w(t), y(t\u22121))\n\u2265 P (w(t))\u2212 \u03c1\u03ba 2\u00b5 \u2016y(t\u22121) \u2212 w(t)\u20162 \u2212 (1 + \u03c1/\u00b5) t .\nIt is left to show that the first stopping condition is correct, namely, to show that after 1 + 2\u03b7 log(\u03be1/ ) iterations the algorithm must converge to an -accurate solution. Observe that the definition of \u03bet yields that \u03bet = (1\u2212\u03b7/2)t\u22121 \u03be1 \u2264 e\u2212\u03b7(t\u22121)/2\u03be1. Therefore, to prove that the first stopping condition is valid, it suffices to show that for every t, P (w(t))\u2212 P (w\u2217) \u2264 \u03bet.\nRecall that at each outer iteration of the accelerated procedure, we approximately minimize an objective of the form\nP (w; y) = P (w) + \u03ba\n2 \u2016w \u2212 y\u20162 .\nOf course, minimizing P (w; y) is not the same as minimizing P (w). Our first lemma shows that for every y, if w+ is an -accurate minimizer of P (w; y) then we can derive a lower bound on P (w) based on P (w+) and a convex quadratic function of w.\nLemma 3. Let \u00b5 = \u03bb/2 and \u03c1 = \u00b5 + \u03ba. Let w+ be a vector such that P (w+; y) \u2264 minw P (w, y) + . Then, for every z,\nP (z) \u2265 P (w+) +Q (z;w+, y) ,\nwhere Q (z;w +, y) = \u00b5\n2 \u2225\u2225\u2225z \u2212 (y \u2212 \u03c1\u00b5(y \u2212 w+))\u2225\u2225\u22252 \u2212 \u03c1\u03ba2\u00b5\u2016y \u2212 w+\u20162 \u2212 (1 + \u03c1/\u00b5) . Proof. Denote\n\u03a8(w) = P (w)\u2212 \u00b5 2 \u2016w\u20162 .\nWe can write 1\n2 \u2016w\u20162 = 1 2 \u2016y\u20162 + y>(w \u2212 y) + 1 2 \u2016w \u2212 y\u20162 .\nIt follows that\nP (w) = \u03a8(w) + \u00b5 2 \u2016w\u20162 = \u03a8(w) + \u00b5 2 \u2016y\u20162 + \u00b5 y>(w \u2212 y) + \u00b5 2 \u2016w \u2212 y\u20162 .\nTherefore, we can rewrite P (w; y) as:\nP (w; y) = \u03a8(w) + \u00b5 2 \u2016y\u20162 + \u00b5 y>(w \u2212 y) + \u03c1 2 \u2016w \u2212 y\u20162 .\nLet w\u0303 = argminw P (w; y). Therefore, the gradient 2 of P (w; y) w.r.t. w vanishes at w\u0303, which yields\n\u2207\u03a8(w\u0303) + \u00b5y + \u03c1(w\u0303 \u2212 y) = 0 \u21d2 \u2207\u03a8(w\u0303) + \u00b5y = \u03c1(y \u2212 w\u0303) .\nBy the \u00b5-strong convexity of \u03a8 we have that for every z,\n\u03a8(z) \u2265 \u03a8(w\u0303) +\u2207\u03a8(w\u0303)>(z \u2212 w\u0303) + \u00b5 2 \u2016z \u2212 w\u0303\u20162 .\nTherefore,\nP (z) = \u03a8(z) + \u00b5 2 \u2016y\u20162 + \u00b5 y>(z \u2212 y) + \u00b5 2 \u2016z \u2212 y\u20162\n\u2265 \u03a8(w\u0303) +\u2207\u03a8(w\u0303)>(z \u2212 w\u0303) + \u00b5 2 \u2016z \u2212 w\u0303\u20162 + \u00b5 2 \u2016y\u20162 + \u00b5 y>(z \u2212 y) + \u00b5 2 \u2016z \u2212 y\u20162 = P (w\u0303; y)\u2212 \u03c1 2 \u2016w\u0303 \u2212 y\u20162 +\u2207\u03a8(w\u0303)>(z \u2212 w\u0303) + \u00b5 y>(z \u2212 w\u0303) + \u00b5 2 ( \u2016z \u2212 w\u0303\u20162 + \u2016z \u2212 y\u20162 ) = P (w\u0303; y)\u2212 \u03c1\n2 \u2016w\u0303 \u2212 y\u20162 + \u03c1(y \u2212 w\u0303)>(z \u2212 w\u0303) + \u00b5 2\n( \u2016z \u2212 w\u0303\u20162 + \u2016z \u2212 y\u20162 ) = P (w\u0303; y) + \u03c1\n2 \u2016w\u0303 \u2212 y\u20162 + \u03c1(y \u2212 w\u0303)>(z \u2212 y) + \u00b5 2\n( \u2016z \u2212 w\u0303\u20162 + \u2016z \u2212 y\u20162 ) .\n2If the regularizer g(w) in the definition of P (w) is non-differentiable, we can replace\u2207\u03a8(w\u0303) with an appropriate sub-gradient of \u03a8 at w\u0303. It is easy to verify that the proof is still valid.\nIn addition, by standard algebraic manipulations,\n\u03c1 2 \u2016w\u0303 \u2212 y\u20162 + \u03c1(y \u2212 w\u0303)>(z \u2212 y) + \u00b5 2 \u2016z \u2212 w\u0303\u20162 \u2212 (\u03c1 2 \u2016w+ \u2212 y\u20162 + \u03c1(y \u2212 w+)>(z \u2212 y) + \u00b5 2 \u2016z \u2212 w+\u20162 ) = ( \u03c1(w+ \u2212 y)\u2212 \u03c1(z \u2212 y) + \u00b5(w+ \u2212 z) )> (w\u0303 \u2212 w+) + \u03c1+ \u00b5\n2 \u2016w\u0303 \u2212 w+\u20162\n= (\u03c1+ \u00b5)(w+ \u2212 z)>(w\u0303 \u2212 w+) + \u03c1+ \u00b5 2 \u2016w\u0303 \u2212 w+\u20162\n= 1\n2 \u2225\u2225\u2225\u2225\u221a\u00b5(w+ \u2212 z) + \u03c1+ \u00b5\u221a\u00b5 (w\u0303 \u2212 w+) \u2225\u2225\u2225\u22252 \u2212 \u00b52 \u2016z \u2212 w+\u20162 \u2212 (\u03c1+ \u00b5)22\u00b5 \u2016w\u0303 \u2212 w+\u20162 + \u03c1+ \u00b52 \u2016w\u0303 \u2212 w+\u20162\n\u2265 \u2212\u00b5 2 \u2016z \u2212 w+\u20162 \u2212 \u03c1(\u03c1+ \u00b5) 2\u00b5 \u2016w\u0303 \u2212 w+\u20162 .\nSince P (\u00b7; y) is (\u03c1 + \u00b5)-strongly convex and w\u0303 minimizes P (\u00b7; y), we have that for every w+ it holds that \u03c1+\u00b5\n2 \u2016w\u0303 \u2212 w +\u20162 \u2264 P (w+; y) \u2212 P (w\u0303; y). Combining all the above and using the fact that for every w, y,\nP (w; y) \u2265 P (w), we obtain that for every w+,\nP (z) \u2265 P (w+) + \u03c1 2 \u2016w+ \u2212 y\u20162 + \u03c1(y\u2212w+)>(z \u2212 y) + \u00b5 2 \u2016z \u2212 y\u20162 \u2212\n( 1 + \u03c1\n\u00b5\n)( P (w+; y)\u2212 P (w\u0303; y) ) .\nFinally, using the assumption P (w+; y) \u2264 minw P (w; y) + we conclude our proof.\nWe saw that the quadratic function P (w+) + Q (z;w+, y) lower bounds the function P everywhere. Therefore, any convex combination of such functions would form a quadratic function which lower bounds P . In particular, the algorithm (implicitly) maintains a sequence of quadratic functions, h1, h2, . . ., defined as follows. Choose \u03b7 \u2208 (0, 1) and a sequence y(1), y(2), . . . that will be specified later. Define,\nh1(z) = P (0) +QP (0)\u2212D(0)(z; 0, 0) = P (0) + \u00b5\n2 \u2016z\u20162 \u2212 (1 + \u03c1/\u00b5)(P (0)\u2212D(0)) ,\nand for t \u2265 1, ht+1(z) = (1\u2212 \u03b7)ht(z) + \u03b7(P (w(t+1)) +Q t+1(z;w(t+1), y(t))) .\nThe following simple lemma shows that for every t \u2265 1 and z, ht(z) lower bounds P (z).\nLemma 4. Let \u03b7 \u2208 (0, 1) and let y(1), y(2), . . . be any sequence of vectors. Assume that w(1) = 0 and for every t \u2265 1, w(t+1) satisfies P (w(t+1); y(t)) \u2264 minw P (w; y(t)) + t+1. Then, for every t \u2265 1 and every vector z we have\nht(z) \u2264 P (z) .\nProof. The proof is by induction. For t = 1, observe that P (0; 0) = P (0) and that for every w we have P (w; 0) \u2265 P (w) \u2265 D(0). This yields P (0; 0) \u2212minw P (w; 0) \u2264 P (0) \u2212 D(0). The claim now follows directly from Lemma 3. Next, for the inductive step, assume the claim holds for some t\u2212 1 \u2265 1 and let us prove it for t. By the recursive definition of ht and by using Lemma 3 we have\nht(z) = (1\u2212 \u03b7)ht\u22121(z) + \u03b7(P (w(t)) +Q t(z;w(t), y(t\u22121))) \u2264 (1\u2212 \u03b7)ht\u22121(z) + \u03b7P (z) .\nUsing the inductive assumption we obtain that the right-hand side of the above is upper bounded by (1 \u2212 \u03b7)P (z) + \u03b7P (z) = P (z), which concludes our proof.\nThe more difficult part of the proof is to show that for every t \u2265 1,\nP (w(t)) \u2264 min w ht(w) + \u03bet .\nIf this holds true, then we would immediately get that for every w\u2217,\nP (w(t))\u2212 P (w\u2217) \u2264 P (w(t))\u2212 ht(w\u2217) \u2264 P (w(t))\u2212min w ht(w) \u2264 \u03bet .\nThis will conclude the proof of the first part of Theorem 3, since \u03bet = \u03be1(1\u2212 \u03b7/2)t\u22121 \u2264 \u03be1 e\u2212(t\u22121)\u03b7/2, and therefore, 1 + 2\u03b7 log(\u03be1/ ) iterations suffice to guarantee that P (w\n(t))\u2212 P (w\u2217) \u2264 . Define\nv(t) = argmin w ht(w) .\nLet us construct an explicit formula for v(t). Clearly, v(1) = 0. Assume that we have calculated v(t) and let us calculate v(t+1). Note that ht is a quadratic function which is minimized at v(t). Furthermore, it is easy to see that for every t, ht is \u00b5-strongly convex quadratic function. Therefore,\nht(z) = ht(v (t)) +\n\u00b5 2 \u2016z \u2212 v(t)\u20162 .\nBy the definition of ht+1 we obtain that\nht+1(z) = (1\u2212 \u03b7)(ht(v(t)) + \u00b5\n2 \u2016z \u2212 v(t)\u20162) + \u03b7(P (w(t+1)) +Q t+1(z;w(t+1), y(t))) .\nSince the gradient of ht+1(z) at v(t+1) should be zero, we obtain that v(t+1) should satisfy\n(1\u2212 \u03b7)\u00b5(v(t+1) \u2212 v(t)) + \u03b7\u00b5 ( v(t+1) \u2212 (y(t) \u2212 \u03c1\u00b5(y (t) \u2212 w(t+1))) ) = 0\nRearranging, we obtain\nv(t+1) = (1\u2212 \u03b7)v(t) + \u03b7(y(t) \u2212 \u03c1\u00b5(y (t) \u2212 w(t+1))) . (5)\nGetting back to our second phase of the proof, we need to show that for every t we have P (w(t)) \u2264 ht(v (t)) + \u03bet. We do so by induction. For the case t = 1 we have\nP (w(1))\u2212 h1(v(1)) = P (0)\u2212 h1(0) = (1 + \u03c1/\u00b5)(P (0)\u2212D(0)) = \u03be1 .\nFor the induction step, assume the claim holds for t \u2265 1 and let us prove it for t+ 1. We use the shorthands,\nQt(z) = Q t(z;w (t), y(t\u22121)) and \u03c8t(z) = Qt(z) + P (w(t)) .\nLet us rewrite ht+1(v(t+1)) as\nht+1(v (t+1)) = (1\u2212 \u03b7)ht(v(t+1)) + \u03b7\u03c8t+1(v(t+1))\n= (1\u2212 \u03b7)(ht(v(t)) + \u00b5\n2 \u2016v(t) \u2212 v(t+1)\u20162) + \u03b7\u03c8t+1(v(t+1)) .\nBy the inductive assumption we have ht(v(t)) \u2265 P (w(t)) \u2212 \u03bet and by Lemma 3 we have P (w(t)) \u2265 \u03c8t+1(w (t)). Therefore,\nht+1(v (t+1)) \u2265 (1\u2212 \u03b7)(\u03c8t+1(w(t))\u2212 \u03bet +\n\u00b5 2 \u2016v(t) \u2212 v(t+1)\u20162) + \u03b7\u03c8t+1(v(t+1)) (6)\n= (1\u2212 \u03b7)\u00b5\n2 \u2016v(t) \u2212 v(t+1)\u20162 + \u03b7\u03c8t+1(v(t+1)) + (1\u2212 \u03b7)\u03c8t+1(w(t))\u2212 (1\u2212 \u03b7)\u03bet .\nNext, note that we can rewrite\nQt+1(z) = \u00b5 2 \u2016z \u2212 y(t)\u20162 + \u03c1(z \u2212 y(t))>(y(t) \u2212 w(t+1)) + \u03c1 2 \u2016y(t) \u2212 w(t+1)\u20162 \u2212 (1 + \u03c1/\u00b5) t+1 .\nTherefore,\n\u03b7\u03c8t+1(v (t+1)) + (1\u2212 \u03b7)\u03c8t+1(w(t))\u2212 P (w(t+1)) + (1 + \u03c1/\u00b5) t+1 (7)\n= \u03b7\u00b5 2 \u2016v(t+1) \u2212 y(t)\u20162 + (1\u2212 \u03b7)\u00b5 2 \u2016w(t) \u2212 y(t)\u20162 + \u03c1(\u03b7v(t+1) + (1\u2212 \u03b7)w(t) \u2212 y(t))>(y(t) \u2212 w(t+1)) + \u03c1\n2 \u2016y(t) \u2212 w(t+1)\u20162\nSo far we did not specify \u03b7 and y(t) (except y(0) = 0). We next set\n\u03b7 = \u221a \u00b5/\u03c1 and \u2200t \u2265 1, y(t) = (1 + \u03b7)\u22121(\u03b7v(t) + w(t)) .\nThis choices guarantees that (see (5))\n\u03b7v(t+1) + (1\u2212 \u03b7)w(t) = \u03b7(1\u2212 \u03b7)v(t) + \u03b72(1\u2212 \u03c1 \u00b5 )y(t) + \u03b72 \u03c1 \u00b5 w(t+1) + (1\u2212 \u03b7)w(t)\n= w(t+1) + (1\u2212 \u03b7) [ \u03b7v(t) +\n\u03b72(1\u2212 \u03c1\u00b5) 1\u2212 \u03b7 y(t) + w(t)\n]\n= w(t+1) + (1\u2212 \u03b7) [ \u03b7v(t) \u2212 1\u2212 \u03b7 2\n1\u2212 \u03b7 y(t) + w(t) ] = w(t+1) + (1\u2212 \u03b7) [ \u03b7v(t) \u2212 (1 + \u03b7)y(t) + w(t)\n] = w(t+1) .\nWe also observe that t+1 \u2264 \u03b7\u03bet2(1+\u03b7\u22122) which implies that (1 + \u03c1/\u00b5) t+1 + (1\u2212 \u03b7)\u03bet \u2264 (1\u2212 \u03b7/2)\u03bet = \u03bet+1. Combining the above with (6) and (7), and rearranging terms, we obtain that\nht+1(v (t+1))\u2212 P (w(t+1)) + \u03bet+1 \u2212 (1\u2212 \u03b7)\u00b5 2 \u2016w(t) \u2212 y(t)\u20162\n\u2265 (1\u2212 \u03b7)\u00b5 2 \u2016v(t) \u2212 v(t+1)\u20162 + \u03b7\u00b5 2 \u2016v(t+1) \u2212 y(t)\u20162 \u2212 \u03c1 2 \u2016y(t) \u2212 w(t+1)\u20162 .\nNext, observe that \u03c1\u03b72 = \u00b5 and that by (5) we have\ny(t) \u2212 w(t+1) = \u03b7 [ \u03b7y(t) + (1\u2212 \u03b7)v(t) \u2212 v(t+1) ] .\nWe therefore obtain that\nht+1(v (t+1))\u2212 P (w(t+1)) + \u03bet+1 \u2212 (1\u2212 \u03b7)\u00b5 2 \u2016w(t) \u2212 y(t)\u20162\n\u2265 (1\u2212 \u03b7)\u00b5 2 \u2016v(t) \u2212 v(t+1)\u20162 + \u03b7\u00b5 2 \u2016y(t) \u2212 v(t+1)\u20162 \u2212 \u00b5 2 \u2016\u03b7y(t) + (1\u2212 \u03b7)v(t) \u2212 v(t+1)\u20162 .\nThe right-hand side of the above is non-negative because of the convexity of the function f(z) = \u00b52\u2016z \u2212 v(t+1)\u20162, which yields\nP (w(t+1)) \u2264 ht+1(v(t+1)) + \u03bet+1 \u2212 (1\u2212 \u03b7)\u00b5\n2 \u2016w(t) \u2212 y(t)\u20162 \u2264 ht+1(v(t+1)) + \u03bet+1 .\nThis concludes our inductive argument.\nProving the \u201cruntime\u201d part of Theorem 3: We next show that each call to Prox-SDCA will terminate quickly. By the definition of \u03ba we have that\nR2\n(\u03ba+ \u03bb)\u03b3 = n .\nTherefore, based on Corollary 1 we know that the averaged runtime at iteration t is\nO ( dn log ( D\u0303t(\u03b1 \u2217)\u2212 D\u0303t(\u03b1(t\u22121)) \u03b7\n2(1+\u03b7\u22122)\u03bet\u22121\n)) .\nThe following lemma bounds the initial dual sub-optimality at iteration t \u2265 4. Similar arguments will yield a similar result for t < 4.\nLemma 5. D\u0303t(\u03b1 \u2217)\u2212 D\u0303t(\u03b1(t\u22121)) \u2264 t\u22121 + 36\u03ba\n\u03bb \u03bet\u22123 .\nProof. Define \u03bb\u0303 = \u03bb + \u03ba, f(w) = \u03bb \u03bb\u0303 g(w) + \u03ba 2\u03bb\u0303 \u2016w\u20162, and g\u0303t(w) = f(w) \u2212 \u03ba\u03bb\u0303w >y(t\u22121). Note that \u03bb\u0303 does not depend on t and therefore v(\u03b1) = 1\nn\u03bb\u0303\n\u2211 iXi\u03b1i is the same for every t. Let,\nP\u0303t(w) = 1\nn n\u2211 i=1 \u03c6i(X > i w) + \u03bb\u0303g\u0303t(w) .\nWe have P\u0303t(w (t\u22121)) = P\u0303t\u22121(w (t\u22121)) + \u03baw(t\u22121)>(y(t\u22122) \u2212 y(t\u22121)) . (8)\nSince g\u0303\u2217t (\u03b8) = maxw w>(\u03b8 + \u03ba \u03bb\u0303 y(t\u22121))\u2212 f(w) = f\u2217(\u03b8 + \u03ba \u03bb\u0303 y(t\u22121)) ,\nwe obtain that the dual problem is\nD\u0303t(\u03b1) = \u2212 1\nn \u2211 i \u03c6\u2217i (\u2212\u03b1i)\u2212 \u03bb\u0303f\u2217(v(\u03b1) + \u03ba \u03bb\u0303 y(t\u22121))\nLet z = \u03ba \u03bb\u0303 (y(t\u22121) \u2212 y(t\u22122)), then, by the smoothness of f\u2217 we have\nf\u2217(v(\u03b1)+ \u03ba\n\u03bb\u0303 y(t\u22121)) = f\u2217(v(\u03b1)+\n\u03ba \u03bb\u0303 y(t\u22122) +z) \u2264 f\u2217(v(\u03b1)+ \u03ba \u03bb\u0303 y(t\u22122))+\u2207f\u2217(v(\u03b1)+ \u03ba \u03bb\u0303 y(t\u22122))>z+ 1 2 \u2016z\u20162 .\nApplying this for \u03b1(t\u22121) and using w(t\u22121) = \u2207g\u0303\u2217t\u22121(v(\u03b1(t\u22121))) = \u2207f\u2217(v(\u03b1(t\u22121)) + \u03ba\u03bb\u0303y (t\u22122)), we obtain\nf\u2217(v(\u03b1(t\u22121)) + \u03ba \u03bb\u0303 y(t\u22121)) \u2264 f\u2217(v(\u03b1(t\u22121)) + \u03ba \u03bb\u0303 y(t\u22122)) + w(t\u22121)>z + 1 2 \u2016z\u20162 .\nIt follows that\n\u2212D\u0303t(\u03b1(t\u22121)) + D\u0303t\u22121(\u03b1(t\u22121)) \u2264 \u03baw(t\u22121)>(y(t\u22121) \u2212 y(t\u22122)) + \u03ba2\n2\u03bb\u0303 \u2016y(t\u22121) \u2212 y(t\u22122)\u20162 .\nCombining the above with (8), we obtain that\nP\u0303t(w (t\u22121))\u2212 D\u0303t(\u03b1(t\u22121)) \u2264 P\u0303t\u22121(w(t\u22121))\u2212 D\u0303t\u22121(\u03b1(t\u22121)) +\n\u03ba2 2\u03bb\u0303 \u2016y(t\u22121) \u2212 y(t\u22122)\u20162 .\nSince P\u0303t(w(t\u22121)) \u2265 D\u0303t(\u03b1\u2217) and since \u03bb\u0303 \u2265 \u03ba we get that\nD\u0303t(\u03b1 \u2217)\u2212 D\u0303t(\u03b1(t\u22121)) \u2264 t\u22121 +\n\u03ba 2 \u2016y(t\u22121) \u2212 y(t\u22122)\u20162 .\nNext, we bound \u2016y(t\u22121) \u2212 y(t\u22122)\u20162. We have\n\u2016y(t\u22121) \u2212 y(t\u22122)\u2016 = \u2016w(t\u22121) \u2212 w(t\u22122) + \u03b2(w(t\u22121) \u2212 w(t\u22122) \u2212 w(t\u22122) + w(t\u22123))\u2016 \u2264 3 max\ni\u2208{1,2} \u2016w(t\u2212i) \u2212 w(t\u2212i\u22121)\u2016 ,\nwhere we used the triangle inequality and \u03b2 < 1. By strong convexity of P we have, for every i,\n\u2016w(i) \u2212 w\u2217\u2016 \u2264\n\u221a P (w(i))\u2212 P (w\u2217)\n\u03bb/2 \u2264 \u221a \u03bei \u03bb/2 ,\nwhich implies\n\u2016w(t\u2212i) \u2212 w(t\u2212i\u22121)\u2016 \u2264 \u2016w(t\u2212i) \u2212 w\u2217\u2016+ \u2016w\u2217 \u2212 w(t\u2212i\u22121)\u2016 \u2264 2 \u221a \u03bet\u2212i\u22121 \u03bb/2 .\nThis yields the bound\n\u2016y(t\u22121) \u2212 y(t\u22122)\u20162 \u2264 72\u03bet\u22123 \u03bb .\nAll in all, we have obtained that\nD\u0303t(\u03b1 \u2217)\u2212 D\u0303t(\u03b1(t\u22121)) \u2264 t\u22121 +\n36\u03ba\n\u03bb \u03bet\u22123 .\nGetting back to the proof of the second claim of Theorem 3, we have obtained that\nD\u0303t(\u03b1 \u2217)\u2212 D\u0303t(\u03b1(t\u22121))\n\u03b7 2(1+\u03b7\u22122)\u03bet\u22121\n\u2264 t\u22121\u03b7 2(1+\u03b7\u22122)\u03bet\u22121 + 36\u03ba\u03bet\u22123 \u03bb \u03b7 2(1+\u03b7\u22122)\u03bet\u22121 \u2264 (1\u2212 \u03b7/2)\u22121 + 36\u03ba2(1 + \u03b7 \u22122)\n\u03bb\u03b7 (1\u2212 \u03b7/2)\u22122\n\u2264 (1\u2212 \u03b7/2)\u22124 ( 1 + 72\u03ba(1 + \u03b7\u22122)\n\u03bb\u03b7 ) \u2264 (1\u2212 \u03b7/2)\u22122 ( 1 + 36\u03b7\u22125 ) ,\nwhere in the last inequality we used \u03b7\u22122\u2212 1 = 2\u03ba\u03bb , which implies that 2\u03ba \u03bb (1 + \u03b7 \u22122) \u2264 \u03b7\u22124. Using 1 < \u03b7\u22125, 1\u2212 \u03b7/2 \u2265 0.5, and taking log to both sides, we get that\nlog\n( D\u0303t(\u03b1\n\u2217)\u2212 D\u0303t(\u03b1(t\u22121)) \u03b7\n2(1+\u03b7\u22122)\u03bet\u22121\n) \u2264 2 log(2) + log(37)\u2212 5 log(\u03b7) \u2264 7 + 2.5 log ( R2\n\u03bb\u03b3n\n) .\nAll in all, we have shown that the average runtime required by Prox-SDCA(P\u0303t, \u03b72(1+\u03b7\u22122)\u03bet\u22121, \u03b1 (t\u22121)) is upper bounded by\nO ( dn log ( R2\n\u03bb\u03b3n\n)) ,\nwhich concludes the proof of the second claim of Theorem 3."}, {"heading": "5 Applications", "text": "In this section we specify our algorithmic framework to several popular machine learning applications. In Section 5.1 we start by describing several loss functions and deriving their conjugate. In Section 5.2 we describe several regularization functions. Finally, in the rest of the subsections we specify our algorithm for Ridge regression, SVM, Lasso, logistic regression, and multiclass prediction."}, {"heading": "5.1 Loss functions", "text": "Squared loss: \u03c6(a) = 12(a\u2212 y) 2 for some y \u2208 R. The conjugate function is\n\u03c6\u2217(b) = max a ab\u2212 1 2 (a\u2212 y)2 = 1 2 b2 + yb\nLogistic loss: \u03c6(a) = log(1 + ea). The derivative is \u03c6\u2032(a) = 1/(1 + e\u2212a) and the second derivative is \u03c6\u2032\u2032(a) = 1\n(1+e\u2212a)(1+ea) \u2208 [0, 1/4], from which it follows that \u03c6 is (1/4)-smooth. The conjugate function is\n\u03c6\u2217(b) = max a ab\u2212 log(1 + ea) = { b log(b) + (1\u2212 b) log(1\u2212 b) if b \u2208 [0, 1] \u221e otherwise\nHinge loss: \u03c6(a) = [1\u2212 a]+ := max{0, 1\u2212 a}. The conjugate function is\n\u03c6\u2217(b) = max a ab\u2212max{0, 1\u2212 a} = { b if b \u2208 [\u22121, 0] \u221e otherwise\nSmooth hinge loss: This loss is obtained by smoothing the hinge-loss using the technique described in Lemma 2. This loss is parameterized by a scalar \u03b3 > 0 and is defined as:\n\u03c6\u0303\u03b3(a) =  0 a \u2265 1 1\u2212 a\u2212 \u03b3/2 a \u2264 1\u2212 \u03b3 1\n2\u03b3 (1\u2212 a) 2 o.w.\n(9)\nThe conjugate function is\n\u03c6\u0303\u2217\u03b3(b) =\n{ b+ \u03b32 b\n2 if b \u2208 [\u22121, 0] \u221e otherwise\nIt follows that \u03c6\u0303\u2217\u03b3 is \u03b3 strongly convex and \u03c6\u0303 is (1/\u03b3)-smooth. In addition, if \u03c6 is the vanilla hinge-loss, we have for every a that\n\u03c6(a)\u2212 \u03b3/2 \u2264 \u03c6\u0303(a) \u2264 \u03c6(a) .\nMax-of-hinge: The max-of-hinge loss function is a function from Rk to R, which is defined as:\n\u03c6(a) = max j [cj + aj ]+ ,\nfor some c \u2208 Rk. This loss function is useful for multiclass prediction problems. To calculate the conjugate of \u03c6, let\nS = {\u03b2 \u2208 Rk+ : \u2016\u03b2\u20161 \u2264 1} (10)\nand note that we can write \u03c6 as \u03c6(a) = max\n\u03b2\u2208S \u2211 j \u03b2j(cj + aj) .\nHence, the conjugate of \u03c6 is\n\u03c6\u2217(b) = max a\n[ a>b\u2212 \u03c6(a) ] = max\na min \u03b2\u2208S a>b\u2212\u2211 j \u03b2j(cj + aj)  = min\n\u03b2\u2208S max a a>b\u2212\u2211 j \u03b2j(cj + aj)  = min \u03b2\u2208S \u2212\u2211 j \u03b2jcj + \u2211 j max aj aj(bj \u2212 \u03b2j)  . Each inner maximization over aj would be\u221e unless \u03b2j = bj . Therefore,\n\u03c6\u2217(b) = { \u2212c>b if b \u2208 S \u221e otherwise\n(11)\nSmooth max-of-hinge This loss obtained by smoothing the max-of-hinge loss using the technique described in Lemma 2. This loss is parameterized by a scalar \u03b3 > 0. We start by adding regularization to the conjugate of the max-of-hinge given in (11) and obtain\n\u03c6\u0303\u2217\u03b3(b) =\n{ \u03b3 2\u2016b\u2016\n2 \u2212 c>b if b \u2208 S \u221e otherwise\n(12)\nTaking the conjugate of the conjugate we obtain\n\u03c6\u0303\u03b3(a) = max b b>a\u2212 \u03c6\u0303\u2217\u03b3(b)\n= max b\u2208S b>(a+ c)\u2212 \u03b3 2 \u2016b\u20162 = \u03b3\n2 \u2016(a+ c)/\u03b3\u20162 \u2212 \u03b3 2 min b\u2208S \u2016b\u2212 (a+ c)/\u03b3\u20162 (13)\nWhile we do not have a closed form solution for the minimization problem over b in the definition of \u03c6\u0303\u03b3 above, this is a problem of projecting onto the intersection of the L1 ball and the positive orthant, and can be solved efficiently using the following procedure, adapted from [9].\nProject(\u00b5)\nGoal: solve argminb \u2016b\u2212 \u00b5\u20162 s.t. b \u2208 Rk+, \u2016b\u20161 \u2264 1 Let: \u2200i, \u00b5\u0303i = max{0, \u00b5i} If: \u2016\u00b5\u0303\u20161 \u2264 1 stop and return b = \u00b5\u0303 Sort: let i1, . . . , ik be s.t. \u00b5i1 \u2265 \u00b5i2 \u2265 . . . \u2265 \u00b5ik Find: j\u2217 = max { j : j \u00b5\u0303ij + 1\u2212 \u2211j r=1 \u00b5\u0303ir > 0\n} Define: \u03b8 = \u22121 + \u2211j\u2217 r=1 \u00b5\u0303ir Return: b s.t. \u2200i, bi = max{\u00b5i \u2212 \u03b8/j\u2217, 0}\nIt also holds that \u2207\u03c6\u0303\u03b3(a) = argminb\u2208S \u2016b \u2212 (a + c)/\u03b3\u20162, and therefore the gradient can also be calculated using the above projection procedure.\nNote that if \u03c6 being the max-of-hinge loss, then \u03c6\u2217(b) + \u03b3/2 \u2265 \u03c6\u0303\u2217\u03b3(b) \u2265 \u03c6\u2217(b) and hence \u03c6(a)\u2212 \u03b3/2 \u2264 \u03c6\u0303\u03b3(a) \u2264 \u03c6(a).\nObserve that all negative elements of a + c does not contribute to \u03c6\u0303\u03b3 . This immediately implies that if \u03c6(a) = 0 then we also have \u03c6\u0303\u03b3(a) = 0.\nSoft-max-of-hinge loss function: Another approach to smooth the max-of-hinge loss function is by using soft-max instead of max. The resulting soft-max-of-hinge loss function is defined as\n\u03c6\u03b3(a) = \u03b3 log\n( 1 +\nk\u2211 i=1 e(ci+ai)/\u03b3\n) , (14)\nwhere \u03b3 > 0 is a parameter. We have\nmax i [ci + ai]+ \u2264 \u03c6\u03b3(a) \u2264 max i [ci + ai]+ + \u03b3 log(k + 1) .\nThe j\u2019th element of the gradient of \u03c6 is\n\u2207j\u03c6\u03b3(a) = e(cj+aj)/\u03b3 1 + \u2211k\ni=1 e (ci+ai)/\u03b3\n.\nBy the definition of the conjugate we have \u03c6\u2217\u03b3(b) = maxa a >b \u2212 \u03c6\u03b3(a). The vector a that maximizes the above must satisfy\n\u2200j, bj = e(cj+aj)/\u03b3 1 + \u2211k\ni=1 e (ci+ai)/\u03b3\n.\nThis can be satisfied only if bj \u2265 0 for all j and \u2211 j bj \u2264 1. That is, b \u2208 S. Denote Z = \u2211k i=1 e (ci+ai)/\u03b3 and note that\n(1 + Z)\u2016b\u20161 = Z \u21d2 Z = \u2016b\u20161 1\u2212 \u2016b\u20161 \u21d2 1 + Z = 1 1\u2212 \u2016b\u20161 .\nIt follows that\naj = \u03b3(log(bj) + log(1 + Z))\u2212 cj = \u03b3(log(bj)\u2212 log(1\u2212 \u2016b\u20161))\u2212 cj\nwhich yields\n\u03c6\u2217\u03b3(b) = \u2211 j (\u03b3(log(bj)\u2212 log(1\u2212 \u2016b\u20161))\u2212 cj) bj + \u03b3 log(1\u2212 \u2016b\u20161)\n= \u2212c>b+ \u03b3 (1\u2212 \u2016b\u20161) log(1\u2212 \u2016b\u20161) +\u2211 j bj log(bj)  . Finally, if b /\u2208 S then the gradient of a>b\u2212\u03c6\u03b3(a) does not vanish anywhere, which means that \u03c6\u2217\u03b3(b) =\u221e. All in all, we obtain\n\u03c6\u2217\u03b3(b) =\n{ \u2212c>b+ \u03b3 ( (1\u2212 \u2016b\u20161) log(1\u2212 \u2016b\u20161) + \u2211 j bj log(bj) ) if b \u2208 S\n\u221e otherwise (15)\nSince the entropic function, \u2211\nj bj log(bj) is 1-strongly convex over S with respect to theL1 norm, we obtain that \u03c6\u2217\u03b3 is \u03b3-strongly convex with respect to the L1 norm, from which it follows that \u03c6\u03b3 is (1/\u03b3)-smooth with respect to the L\u221e norm."}, {"heading": "5.2 Regularizers", "text": "L2 regularization: The simplest regularization is the squared L2 regularization\ng(w) = 1\n2 \u2016w\u201622 .\nThis is a 1-strongly convex regularization function whose conjugate is\ng\u2217(\u03b8) = 1\n2 \u2016\u03b8\u201622 .\nWe also have \u2207g\u2217(\u03b8) = \u03b8 .\nFor our acceleration procedure, we also use the L2 regularization plus a linear term, namely,\ng(w) = 1\n2 \u2016w\u20162 \u2212 w>z ,\nfor some vector z. The conjugate of this function is\ng\u2217(\u03b8) = max w\n[ w>(\u03b8 + z)\u2212 1\n2 \u2016w\u20162\n] = 1\n2 \u2016\u03b8 + z\u20162 .\nWe also have \u2207g\u2217(\u03b8) = \u03b8 + z .\nL1 regularization: Another popular regularization we consider is the L1 regularization,\nf(w) = \u03c3 \u2016w\u20161 .\nThis is not a strongly convex regularizer and therefore we will add a slight L2 regularization to it and define the L1-L2 regularization as\ng(w) = 1\n2 \u2016w\u201622 + \u03c3\u2032 \u2016w\u20161 , (16)\nwhere \u03c3\u2032 = \u03c3\u03bb for some small \u03bb. Note that\n\u03bbg(w) = \u03bb\n2 \u2016w\u201622 + \u03c3\u2016w\u20161 ,\nso if \u03bb is small enough (as will be formalized later) we obtain that \u03bbg(w) \u2248 \u03c3\u2016w\u20161. The conjugate of g is\ng\u2217(v) = max w\n[ w>v \u2212 1\n2 \u2016w\u201622 \u2212 \u03c3\u2032\u2016w\u20161\n] .\nThe maximizer is also\u2207g\u2217(v) and we now show how to calculate it. We have\n\u2207g\u2217(v) = argmax w\n[ w>v \u2212 1\n2 \u2016w\u201622 \u2212 \u03c3\u2032\u2016w\u20161 ] = argmin\nw\n[ 1\n2 \u2016w \u2212 v\u201622 + \u03c3\u2032\u2016w\u20161 ] A sub-gradient of the objective of the optimization problem above is of the form w \u2212 v + \u03c3\u2032z = 0, where z is a vector with zi = sign(wi), where if wi = 0 then zi \u2208 [\u22121, 1]. Therefore, if w is an optimal solution then for all i, either wi = 0 or wi = vi\u2212 \u03c3\u2032sign(wi). Furthermore, it is easy to verify that if w is an optimal solution then for all i, if wi 6= 0 then the sign of wi must be the sign of vi. Therefore, whenever wi 6= 0 we have that wi = vi \u2212 \u03c3\u2032sign(vi). It follows that in that case we must have |vi| > \u03c3\u2032. And, the other direction is also true, namely, if |vi| > \u03c3\u2032 then setting wi = vi \u2212 \u03c3\u2032sign(vi) leads to an objective value whose i\u2019th component is\n1\n2\n( \u03c3\u2032 )2 + \u03c3\u2032(|vi| \u2212 \u03c3\u2032) \u2264 1\n2 |vi|2 ,\nwhere the right-hand side is the i\u2019th component of the objective value we will obtain by setting wi = 0. This leads to the conclusion that\n\u2207ig\u2217(v) = sign(vi) [ |vi| \u2212 \u03c3\u2032 ] + =\n{ vi \u2212 \u03c3\u2032sign(vi) if |vi| > \u03c3\u2032\n0 o.w.\nIt follows that g\u2217(v) = \u2211 i sign(vi) [ |vi| \u2212 \u03c3\u2032 ] + vi \u2212 1 2 \u2211 i ( [ |vi| \u2212 \u03c3\u2032 ] + )2 \u2212 \u03c3\u2032 \u2211 i [ |vi| \u2212 \u03c3\u2032 ] +\n= \u2211 i [ |vi| \u2212 \u03c3\u2032 ] + ( |vi| \u2212 \u03c3\u2032 \u2212 1 2 [ |vi| \u2212 \u03c3\u2032 ] + ) = 1\n2 \u2211 i ([ |vi| \u2212 \u03c3\u2032 ] + )2 .\nAnother regularization function we\u2019ll use in the accelerated procedure is\ng(w) = 1\n2 \u2016w\u201622 + \u03c3\u2032 \u2016w\u20161 \u2212 z>w . (17)\nThe conjugate function is\ng\u2217(v) = 1\n2 \u2211 i ([ |vi + zi| \u2212 \u03c3\u2032 ] + )2 ,\nand its gradient is \u2207ig\u2217(v) = sign(vi + zi) [ |vi + zi| \u2212 \u03c3\u2032 ] +"}, {"heading": "5.3 Ridge Regression", "text": "In ridge regression, we minimize the squared loss with L2 regularization. That is, g(w) = 12\u2016w\u2016 2 and for every i we have that xi \u2208 Rd and \u03c6i(a) = 12(a\u2212 yi) 2 for some yi \u2208 R. The primal problem is therefore\nP (w) = 1\n2n n\u2211 i=1 (x>i w \u2212 yi)2 + \u03bb 2 \u2016w\u20162 .\nBelow we specify Prox-SDCA for ridge regression. We use Option I since it is possible to derive a closed form solution to the maximization of the dual with respect to \u2206\u03b1i. Indeed, since \u2212\u03c6\u2217i (\u2212b) = \u221212b\n2 + yib we have that the maximization problem is\n\u2206\u03b1i = argmax b \u22121 2 (\u03b1 (t+1) i + b) 2 + yi(\u03b1 (t+1) i + b)\u2212 w (t\u22121)>xib\u2212 b2\u2016xi\u20162 2\u03bbn\n= argmax b \u22121 a\n( 1 + \u2016xi\u20162\n2\u03bbn\n) b2 \u2212 ( \u03b1\n(t+1) i + w (t\u22121)>xi \u2212 yi ) b\n= \u2212 \u03b1\n(t+1) i + w (t\u22121)>xi \u2212 yi 1 + \u2016xi\u2016 2\n2\u03bbn\n.\nApplying the above update and using some additional tricks to improve the running time we obtain the following procedure.\nProx-SDCA((xi, yi)ni=1, , \u03b1 (0), z) for solving ridge regression\nGoal: Minimize P (w) = 12n \u2211n i=1(x > i w \u2212 yi)2 + \u03bb ( 1 2\u2016w\u2016 2 \u2212 w>z )\nInitialize v(0) = 1\u03bbn \u2211n i=1 \u03b1 (0) i xi, \u2200i, y\u0303i = yi \u2212 x>i z Iterate: for t = 1, 2, . . . Randomly pick i\n\u2206\u03b1i = \u2212 \u03b1 (t\u22121) i +v (t\u22121)>xi\u2212y\u0303i 1+ \u2016xi\u20162 2\u03bbn \u03b1 (t) i \u2190 \u03b1 (t\u22121) i + \u2206\u03b1i and for j 6= i, \u03b1 (t) j \u2190 \u03b1 (t\u22121) j\nv(t) \u2190 v(t\u22121) + \u2206\u03b1i\u03bbn xi Stopping condition:\nLet w(t) = v(t) + z Stop if 12n \u2211n i=1 ( (x>i w (t) \u2212 yi)2 + (\u03b1(t)i + yi)2 \u2212 y2i ) + \u03bbw(t) > v(t) \u2264\nThe runtime of Prox-SDCA for ridge regression becomes\nO\u0303 ( d ( n+ R2\n\u03bb\n)) ,\nwhere R = maxi \u2016xi\u2016. This matches the recent results of [15, 25]. If R2/\u03bb n we can apply the accelerated procedure and obtain the improved runtime\nO\u0303 ( d \u221a nR2\n\u03bb\n) ."}, {"heading": "5.4 Logistic Regression", "text": "In logistic regression, we minimize the logistic loss with L2 regularization. That is, g(w) = 12\u2016w\u2016 2 and for every i we have that xi \u2208 Rd and \u03c6i(a) = log(1 + ea). The primal problem is therefore3\nP (w) = 1\nn n\u2211 i=1 log(1 + ex > i w) + \u03bb 2 \u2016w\u20162 .\nThe dual problem is\nD(\u03b1) = 1\nn n\u2211 i=1 (\u03b1i log(\u2212\u03b1i)\u2212 (1 + \u03b1i) log(1 + \u03b1i))\u2212 \u03bb 2 \u2016v(\u03b1)\u20162 ,\nand the dual constraints are \u03b1 \u2208 [\u22121, 0]n. Below we specify Prox-SDCA for logistic regression using Option III.\nProx-SDCA((xi)ni=1, , \u03b1 (0), z) for logistic regression\nGoal: Minimize P (w) = 1n \u2211n i=1 log(1 + e x>i w) + \u03bb ( 1 2\u2016w\u2016 2 \u2212 w>z )\nInitialize v(0) = 1\u03bbn \u2211n i=1 \u03b1 (0) i xi, and \u2200i, pi = x>i z Define: \u03c6\u2217(b) = b log(b) + (1\u2212 b) log(1\u2212 b) Iterate: for t = 1, 2, . . .\nRandomly pick i p = x>i w (t\u22121) q = \u22121/(1 + e\u2212p)\u2212 \u03b1(t\u22121)i s = min ( 1, log(1+ep)+\u03c6\u2217(\u2212\u03b1(t\u22121)i )+p\u03b1 (t\u22121) i +2q 2\nq2(4+ 1 \u03bbn \u2016xi\u20162) ) \u2206\u03b1i = sq \u03b1 (t) i = \u03b1 (t\u22121) i + \u2206\u03b1i and for j 6= i, \u03b1 (t) j = \u03b1 (t\u22121) j\nv(t) = v(t\u22121) + \u2206\u03b1i\u03bbn xi Stopping condition:\nlet w(t) = v(t) + z Stop if 1n \u2211n i=1 ( log(1 + ex > i w (t) ) + \u03c6\u2217(\u2212\u03b1(t\u22121)i ) ) + \u03bbw(t)>v(t) \u2264\nThe runtime analysis is similar to the analysis for ridge regression.\n3Usually, the training data comes with labels, yi \u2208 {\u00b11}, and the loss function becomes log(1 + e\u2212yix > i w). However, we can\neasily get rid of the labels by re-defining xi \u2190 \u2212yixi."}, {"heading": "5.5 Lasso", "text": "In the Lasso problem, the loss function is the squared loss but the regularization function is L1. That is, we need to solve the problem:\nmin w\n[ 1\n2n n\u2211 i=1 (x>i w \u2212 yi)2 + \u03c3\u2016w\u20161\n] , (18)\nwith a positive regularization parameter \u03c3 \u2208 R+. Let y\u0304 = 12n \u2211n i=1 y 2 i , and let w\u0304 be an optimal solution of (18). Then, the objective at w\u0304 is at most the objective at w = 0, which yields\n\u03c3\u2016w\u0304\u20161 \u2264 y\u0304 \u21d2 \u2016w\u0304\u20162 \u2264 \u2016w\u0304\u20161 \u2264 y\u0304\n\u03c3 .\nConsider the optimization problem\nmin w P (w) where P (w) =\n1\n2n n\u2211 i=1 (x>i w \u2212 yi)2 + \u03bb ( 1 2 \u2016w\u201622 + \u03c3 \u03bb \u2016w\u20161 ) , (19)\nfor some \u03bb > 0. This problem fits into our framework, since now the regularizer is strongly convex. Furthermore, if w\u2217 is an ( /2)-accurate solution to the problem in (19), then P (w\u2217) \u2264 P (w\u0304) + /2 which yields [\n1\n2n n\u2211 i=1 (x>i w \u2217 \u2212 yi)2 + \u03c3\u2016w\u2217\u20161\n] \u2264 [ 1\n2n n\u2211 i=1 (x>i w\u0304 \u2212 yi)2 + \u03c3\u2016w\u0304\u20161\n] + \u03bb\n2 \u2016w\u0304\u201622 + /2 .\nSince \u2016w\u0304\u201622 \u2264 (y\u0304/\u03c3) 2, we obtain that setting \u03bb = (\u03c3/y\u0304)2 guarantees that w\u2217 is an accurate solution to the original problem given in (18). In light of the above, from now on we focus on the problem given in (19). As in the case of ridge regression, we can apply Prox-SDCA with Option I. The resulting pseudo-code is given below. Applying the above update and using some additional tricks to improve the running time we obtain the following procedure.\nProx-SDCA((xi, yi)ni=1, , \u03b1 (0), z) for solving L1 \u2212 L2 regression\nGoal: Minimize P (w) = 12n \u2211n i=1(x > i w \u2212 yi)2 + \u03bb ( 1 2\u2016w\u2016 2 + \u03c3\u2032\u2016w\u20161 \u2212 w>z )\nInitialize v(0) = 1\u03bbn \u2211n i=1 \u03b1 (0) i xi, and \u2200j, w (0) j = sign(v (0) j + zj)[|v (0) j + zj | \u2212 \u03c3\u2032]+ Iterate: for t = 1, 2, . . . Randomly pick i\n\u2206\u03b1i = \u2212 \u03b1 (t\u22121) i +w (t\u22121)>xi\u2212yi 1+ \u2016xi\u20162 2\u03bbn \u03b1 (t) i = \u03b1 (t\u22121) i + \u2206\u03b1i and for j 6= i, \u03b1 (t) j = \u03b1 (t\u22121) j v(t) = v(t\u22121) + \u2206\u03b1i\u03bbn xi \u2200j, w(t)j = sign(v (t) j + zj)[|v (t) j + zj | \u2212 \u03c3\u2032]+\nStopping condition: Stop if 12n \u2211n i=1 ( (x>i w (t) \u2212 yi)2 \u2212 2yi\u03b1(t)i + (\u03b1 (t) i ) 2 ) + \u03bbw(t)>v(t) \u2264\nLet us now discuss the runtime of the resulting method. Denote R = maxi \u2016xi\u2016 and for simplicity, assume that y\u0304 = O(1). Choosing \u03bb = (\u03c3/y\u0304)2, the runtime of our method becomes\nO\u0303 ( d ( n+ min { R2\n\u03c32 ,\n\u221a nR2\n\u03c32\n})) .\nIt is also convenient to write the bound in terms of B = \u2016w\u0304\u20162, where, as before, w\u0304 is the optimal solution of the L1 regularized problem. With this parameterization, we can set \u03bb = /B2 and the runtime becomes\nO\u0303 ( d ( n+ min { R2B2 , \u221a nR2B2 })) .\nThe runtime of standard SGD is O(dR2B2/ 2) even in the case of smooth loss functions such as the squared loss. Several variants of SGD, that leads to sparser intermediate solutions, have been proposed (e.g. [14, 21, 27, 8, 10]). However, all of these variants share the runtime ofO(dR2B2/ 2), which is much slower than our runtime when is small.\nAnother relevant approach is the FISTA algorithm of [2]. The shrinkage operator of FISTA is the same as the gradient of g\u2217 used in our approach. It is a batch algorithm using Nesterov\u2019s accelerated gradient technique. For the squared loss function, the runtime of FISTA is\nO ( dn \u221a R2B2 ) .\nThis bound is worst than our bound by a factor of at least \u221a n.\nAnother approach to solving (18) is stochastic coordinate descent over the primal problem. [21] showed that the runtime of this approach is\nO\n( dnB2 ) ,\nunder the assumption that \u2016xi\u2016\u221e \u2264 1 for all i. Similar results can also be found in [16]. For our method, the runtime depends on R2 = maxi \u2016xi\u201622. If R2 = O(1) then the runtime of our method is much better than that of [21]. In the general case, if maxi \u2016xi\u2016\u221e \u2264 1 then R2 \u2264 d, which yields the runtime of\nO\u0303 ( d ( n+ min { dB2 , \u221a ndB2 })) .\nThis is the same or better than [21] whenever d = O(n)."}, {"heading": "5.6 Linear SVM", "text": "Support Vector Machines (SVM) is an algorithm for learning a linear classifier. Linear SVM (i.e., SVM with linear kernels) amounts to minimizing the objective\nP (w) = 1\nn n\u2211 i=1 [1\u2212 x>i w]+ + \u03bb 2 \u2016w\u20162 ,\nwhere [a]+ = max{0, a}, and for every i, xi \u2208 Rd. This can be cast as the objective given in (1) by letting the regularization be g(w) = 12\u2016w\u2016 2 2, and for every i, \u03c6i(a) = [1\u2212 a]+, is the hinge-loss.\nLet R = maxi \u2016xi\u20162. SGD enjoys the rate of O ( 1 \u03bb ) . Many software packages apply SDCA and obtain\nthe rate O\u0303 ( n+ 1\u03bb ) . We now show how our accelerated proximal SDCA enjoys the rate O\u0303 ( n+ \u221a n \u03bb ) . This is significantly better than the rate of SGD when \u03bb < 1/n. We note that a default setting for \u03bb, which often works well in practice, is \u03bb = 1/n. In this case, \u03bb = /n 1/n.\nOur first step is to smooth the hinge-loss. Let \u03b3 = and consider the smooth hinge-loss as defined in (9). Recall that the smooth hinge-loss satisfies\n\u2200a, \u03c6(a)\u2212 \u03b3/2 \u2264 \u03c6\u0303(a) \u2264 \u03c6(a) .\nLet P\u0303 be the SVM objective while replacing the hinge-loss with the smooth hinge-loss. Therefore, for every w\u2032 and w,\nP (w\u2032)\u2212 P (w) \u2264 P\u0303 (w\u2032)\u2212 P\u0303 (w) + \u03b3/2 .\nIt follows that if w\u2032 is an ( /2)-optimal solution for P\u0303 , then it is -optimal solution for P . For the smoothed hinge loss, the optimization problem given in Option I of Prox-SDCA has a closed form solution and we obtain the following procedure:\nProx-SDCA((x1, . . . , xn), , \u03b1(0), z) for solving SVM (with smooth hinge-loss as in (9))\nDefine: \u03c6\u0303\u03b3 as in (9) Goal: Minimize P (w) = 1n \u2211n i=1 \u03c6\u0303\u03b3(x > i w) + \u03bb ( 1 2\u2016w\u2016 2 \u2212 w>z )\nInitialize w(0) = z + 1\u03bbn \u2211n i=1 \u03b1 (0) i xi Iterate: for t = 1, 2, . . . Randomly pick i\n\u2206\u03b1i = max ( \u2212\u03b1(t\u22121)i , min ( 1\u2212 \u03b1(t\u22121)i , 1\u2212x>i w(t\u22121)\u2212\u03b3 \u03b1 (t\u22121) i\n\u2016xi\u20162/(\u03bbn)+\u03b3 )) \u03b1\n(t) i \u2190 \u03b1 (t\u22121) i + \u2206\u03b1i and for j 6= i, \u03b1 (t) j \u2190 \u03b1 (t\u22121) j\nw(t) \u2190 w(t\u22121) + \u2206\u03b1i\u03bbn xi Stopping condition:\nStop if 1n \u2211n i=1 ( \u03c6\u0303\u03b3(x > i w (t))\u2212 \u03b1(t)i + \u03b3 2 (\u03b1 (t) i ) 2 ) + \u03bbw(t) > (w(t) \u2212 z) \u2264\nDenote R = maxi \u2016xi\u2016. Then, the runtime of the resulting method is\nO\u0303 ( d ( n+ min { R2\n\u03b3 \u03bb ,\n\u221a nR2\n\u03b3 \u03bb\n})) .\nIn particular, choosing \u03b3 = we obtain a solution to the original SVM problem in runtime of\nO\u0303 ( d ( n+ min { R2\n\u03bb ,\n\u221a nR2\n\u03bb\n})) .\nAs mentioned before, this is better than SGD when 1\u03bb n."}, {"heading": "5.7 Multiclass SVM", "text": "Next we consider Multiclass SVM using the construction described in Crammer and Singer [5]. Each example consists of an instance vector xi \u2208 Rd and a label yi \u2208 {1, . . . , k}. The goal is to learn a matrix W \u2208 Rd,k such that W>xi is a k\u2019th dimensional vector of scores for the different classes. The prediction is the coordinate of W>xi of maximal value. The loss function is\nmax j 6=yi\n(1 + (W>xi)j \u2212 (W>xi)yi) .\nThis can be written as \u03c6((W>xi)\u2212 (W>xi)yi) where\n\u03c6i(a) = max j [ci,j + aj ]+ ,\nwith ci being the all ones vector except 0 in the yi coordinate. We can model this in our framework as follows. Given a matrix M let vec(M) be the column vector obtained by concatenating the columns of M . Let ej be the all zeros vector except 1 in the j\u2019th coordinate. For every i, let ci = 1 \u2212 eyi and let Xi \u2208 Rdk,k be the matrix whose j\u2019th column is vec(xi(ej \u2212 eyi)>). Then,\nX>i vec(W ) = W >xi \u2212 (W>xi)yi .\nTherefore, the optimization problem of multiclass SVM becomes:\nmin w\u2208Rdk\nP (w) where P (w) = 1\nn n\u2211 i=1 \u03c6i(X > i w) + \u03bb 2 \u2016w\u20162 .\nAs in the case of SVM, we will use the smooth version of the max-of-hinge loss function as described in (13). If we set the smoothness parameter \u03b3 to be then an ( /2)-accurate solution to the problem with the smooth loss is also an -accurate solution to the original problem with the non-smooth loss. Therefore, from now on we focus on the problem with the smooth max-of-hinge loss.\nWe specify Prox-SDCA for multiclass SVM using Option I. We will show that the optimization problem in Option I can be calculated efficiently by sorting a k dimensional vector. Such ideas were explored in [5] for the non-smooth max-of-hinge loss.\nLet w\u0302 = w \u2212 1\u03bbnXi\u03b1 (t\u22121) i . Then, the optimization problem over \u03b1i can be written as\nargmax \u03b1i:\u2212\u03b1i\u2208S\n(\u2212c>i \u2212 w\u0302>Xi)\u03b1i \u2212 \u03b3\n2 \u2016\u03b1i\u20162 \u2212\n1\n2\u03bbn \u2016Xi\u03b1i\u20162 . (20)\nAs shown before, if we organize w\u0302 as a d\u00d7k matrix, denoted W\u0302 , we have thatX>i w\u0302 = W\u0302>xi\u2212 (W\u0302>xi)yi . We also have that\nXi\u03b1i = \u2211 j vec(xi(ej \u2212 eyi)>)\u03b1i,j = vec(xi \u2211 j \u03b1i,j(ej \u2212 eyi)>) = vec(xi(\u03b1i \u2212 \u2016\u03b1i\u20161eyi)>) .\nIt follows that an optimal solution to (20) must set \u03b1i,yi = 0 and we only need to optimize over the rest of the dual variables. This also yields,\n\u2016Xi\u03b1i\u20162 = \u2016xi\u20162\u2016\u03b1i\u201622 + \u2016xi\u20162\u2016\u03b1i\u201621 .\nSo, (20) becomes:\nargmax \u03b1i:\u2212\u03b1i\u2208S,\u03b1i,yi=0\n(\u2212c>i \u2212 w\u0302>Xi)\u03b1i \u2212 \u03b3\n2 \u2016\u03b1i\u201622 \u2212\n\u2016xi\u20162\n2\u03bbn \u2016\u03b1i\u201622 \u2212\n\u2016xi\u20162\n2\u03bbn \u2016\u03b1i\u201621 . (21)\nThis is equivalent to a problem of the form:\nargmin a\u2208Rk\u22121+ ,\u03b2\n\u2016a\u2212 \u00b5\u201622 + C\u03b22 s.t. \u2016a\u20161 = \u03b2 \u2264 1 , (22)\nwhere\n\u00b5 = c>i + w\u0302 >Xi\n\u03b3 + \u2016xi\u2016 2\n\u03bbn\nand C = \u2016xi\u20162 \u03bbn\n\u03b3 + \u2016xi\u2016 2\n\u03bbn\n= 1\n\u03b3\u03bbn \u2016xi\u20162 + 1\n.\nThe equivalence is in the sense that if (a, \u03b2) is a solution of (22) then we can set \u03b1i = \u2212a. Assume for simplicity that \u00b5 is sorted in a non-increasing order and that all of its elements are nonnegative (otherwise, it is easy to verify that we can zero the negative elements of \u00b5 and sort the non-negative, without affecting the solution). Let \u00b5\u0304 be the cumulative sum of \u00b5, that is, for every j, let \u00b5\u0304j = \u2211j r=1 \u00b5r. For every j, let zj = \u00b5\u0304j \u2212 j\u00b5j . Since \u00b5 is sorted we have that\nzj+1 = j+1\u2211 r=1 \u00b5r \u2212 (j + 1)\u00b5j+1 = j\u2211 r=1 \u00b5r \u2212 j\u00b5j+1 \u2265 j\u2211 r=1 \u00b5r \u2212 j\u00b5j = zj .\nNote also that z1 = 0 and that zk = \u00b5\u0304k = \u2016\u00b5\u20161 (since the coordinate of \u00b5 that corresponds to yi is zero). By the properties of projection onto the simplex (see [9]), for every z \u2208 (zj , zj+1) we have that the projection of \u00b5 onto the set {b \u2208 Rk+ : \u2016b\u20161 = z} is of the form ar = max{0, \u00b5r \u2212 \u03b8/j} where \u03b8 = (\u2212z + \u00b5\u0304j)/j. Therefore, the objective becomes (ignoring constants that do not depend on z),\nj\u03b82 + Cz2 = (\u2212z + \u00b5\u0304j)2/j + Cz2 .\nThe first order condition for minimality w.r.t. z is\n\u2212(\u2212z + \u00b5\u0304j)/j + Cz = 0 \u21d2 z = \u00b5\u0304j\n1 + jC .\nIf this value of z is in (zj , zj+1), then it is the optimal z and we\u2019re done. Otherwise, the optimum should be either z = 0 (which yields \u03b1 = 0 as well) or z = 1.\na = OptimizeDual(\u00b5,C)\nSolve the optimization problem given in (22) Initialize: \u2200i, \u00b5\u0302i = max{0, \u00b5i}, and sort \u00b5\u0302 s.t. \u00b5\u03021 \u2265 \u00b5\u03022 \u2265 . . . \u2265 \u00b5\u0302k Let: \u00b5\u0304 be s.t. \u00b5\u0304j = \u2211j i=1 \u00b5\u0302i Let: z be s.t. zj = min{\u00b5\u0304j \u2212 j\u00b5\u0302j , 1} and zk+1 = 1 If: \u2203j s.t. \u00b5\u0304j1+jC \u2208 [zj , zj+1]\nreturn a s.t. \u2200i, ai = max { 0, \u00b5i \u2212 ( \u2212 \u00b5\u0304j1+jC + \u00b5\u0304j ) /j }\nElse: Let j be the minimal index s.t. zj = 1 set a s.t. \u2200i, ai = max{0, \u00b5i \u2212 (\u2212zj + \u00b5\u0304j)/j} If: \u2016a\u2212 \u00b5\u20162 + C \u2264 \u2016\u00b5\u20162\nreturn a Else:\nreturn (0, . . . , 0)\nThe resulting pseudo-codes for Prox-SDCA is given below. We specify the procedure while referring to W as a matrix, because it is the more natural representation. For convenience of the code, we also maintain in \u03b1i,yi the value of \u2212 \u2211 j 6=yi \u03b1i,j (instead of the optimal value of 0).\nProx-SDCA((x1, y1)ni=1, , \u03b1, Z) for solving Multiclass SVM (with smooth hinge-loss as in (13))\nDefine: \u03c6\u0303\u03b3 as in (13) Goal: Minimize P (W ) = 1n \u2211n i=1 \u03c6\u0303\u03b3((W >xi)\u2212 (W>xi)yi) + \u03bb ( 1 2vec(W ) >vec(W )\u2212 vec(W )>vec(Z) )\nInitialize W = Z + 1\u03bbn \u2211n i=1 xi\u03b1 > i Iterate: for t = 1, 2, . . . Randomly pick i W\u0302 = W \u2212 1\u03bbnxi\u03b1 > i\np = x>i W\u0302 , p = p\u2212 pyi , c = 1\u2212 eyi , \u00b5 = c+p \u03b3+\u2016xi\u20162/(\u03bbn) , C = 1 1+\u03b3\u03bbn/\u2016xi\u20162 a = OptimizeDual(\u00b5,C) \u03b1i = \u2212a, \u03b1yi = \u2016a\u20161 W = W\u0302 + 1\u03bbnxi\u03b1 > i Stopping condition: let G = 0 for i = 1, . . . , n a = W>xi, a = a\u2212 ayi , c = 1\u2212 eyi , b = Project((a+ c)/\u03b3) G = G+ \u03b32 (\u2016(a+ c)/\u03b3\u2016 2 \u2212 \u2016b\u2212 (a+ c)/\u03b3\u20162) + c>\u03b1(t)i + \u03b3 2 (\u2016\u03b1 (t) i \u20162 \u2212 (\u03b1 (t) i,yi )2)\nStop if G/n+ \u03bbvec(W )>vec(W \u2212 Z) \u2264"}, {"heading": "6 Experiments", "text": "In this section we compare Prox-SDCA, its accelerated version Accelerated-Prox-SDCA, and the FISTA algorithm of [2], on L1 \u2212 L2 regularized loss minimization problems.\nThe experiments were performed on three large datasets with very different feature counts and sparsity, which were kindly provided by Thorsten Joachims (the datasets were also used in [24]). The astro-ph dataset classifies abstracts of papers from the physics ArXiv according to whether they belong in the astrophysics section; CCAT is a classification task taken from the Reuters RCV1 collection; and cov1 is class 1 of the covertype dataset of Blackard, Jock & Dean. The following table provides details of the dataset characteristics.\nDataset Training Size Testing Size Features Sparsity astro-ph 29882 32487 99757 0.08%\nCCAT 781265 23149 47236 0.16% cov1 522911 58101 54 22.22%\nThese are binary classification problems, with each xi being a vector which has been normalized to be \u2016xi\u20162 = 1, and yi being a binary class label of \u00b11. We multiplied each xi by yi and following [24], we employed the smooth hinge loss, \u03c6\u0303\u03b3 , as in (9), with \u03b3 = 1. The optimization problem we need to solve is therefore\nmin w P (w) where P (w) =\n1\nn n\u2211 i=1 \u03c6\u0303\u03b3(x > i w) + \u03bb 2 \u2016w\u201622 + \u03c3\u2016w\u20161 .\nIn the experiments, we set \u03c3 = 10\u22125 and vary \u03bb in the range {10\u22126, 10\u22127, 10\u22128, 10\u22129}. The convergence behaviors are plotted in Figure 3. In all the plots we depict the primal objective as a function of the number of passes over the data (often referred to as \u201cepochs\u201d). For FISTA, each iteration involves a single pass over the data. For Prox-SDCA, each n iterations are equivalent to a single pass over the data. And, for Accelerated-Prox-SDCA, each n inner iterations are equivalent to a single pass over the data. For Prox-SDCA and Accelerated-Prox-SDCA we implemented their corresponding stopping conditions and terminate the methods once an accuracy of 10\u22123 was guaranteed.\nIt is clear from the graphs that Accelerated-Prox-SDCA yields the best results, and often significantly outperform the other methods. Prox-SDCA behaves similarly when \u03bb is relatively large, but it converges much slower when \u03bb is small. This is consistent with our theory. Finally, the relative performance of FISTA and Prox-SDCA depends on the ratio between \u03bb and n, but in all cases, Accelerated-Prox-SDCA is much faster than FISTA. This is again consistent with our theory."}, {"heading": "7 Discussion and Open Problems", "text": "We have described and analyzed a proximal stochastic dual coordinate ascent method and have shown how to accelerate the procedure. The overall runtime of the resulting method improves state-of-the-art results in many cases of interest.\nThere are two main open problems that we leave to future research. Open Problem 1. When 1\u03bb\u03b3 is larger than n, the runtime of our procedure becomes O\u0303 ( d \u221a n \u03bb\u03b3 ) . Is it\npossible to derive a method whose runtime is O\u0303 ( d ( n+ \u221a 1 \u03bb\u03b3 )) ?\nOpen Problem 2. Our Prox-SDCA procedure and its analysis works for regularizers which are strongly convex with respect to an arbitrary norm. However, our acceleration procedure is designed for regularizers which are strongly convex with respect to the Euclidean norm. Is is possible to extend the acceleration procedure to more general regularizers?"}, {"heading": "Acknowledgements", "text": "The authors would like to thank Fen Xia for careful proof-reading of the paper which helped us to correct numerous typos. Shai Shalev-Shwartz is supported by the following grants: Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) and ISF 598-10. Tong Zhang is supported by the following grants: NSF IIS-1016061, NSF DMS-1007527, and NSF IIS-1250985."}, {"heading": "A Proofs of Iteration Bounds for Prox-SDCA", "text": "The proof technique follows that of Shalev-Shwartz and Zhang [25], but with the required generality for handling general strongly convex regularizers and smoothness/Lipschitzness with respect to general norms.\nWe prove the theorems for running Prox-SDCA while choosing \u2206\u03b1i as in Option I. A careful examination of the proof easily reveals that the results hold for the other options as well. More specifically, Lemma 6 only requires choosing \u2206\u03b1i = s(u (t\u22121) i \u2212\u03b1 (t\u22121) i ) as in (23), and Option III chooses s to optimize the bound on the right hand side of (25), and hence ensures that the choice can do no worse than the result of Lemma 6 with any s. The simplification in Option IV and V employs the specific simplification of the bound in Lemma 6 in the proof of the theorems.\nThe key lemma is the following:\nLemma 6. Assume that \u03c6\u2217i is \u03b3-strongly-convex. For any iteration t, let Et denote the expectation with respect to the randomness in choosing i at round t, conditional on the value of \u03b1(t\u22121). Then, for any iteration t and any s \u2208 [0, 1] we have\nEt[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2265 s n [P (w(t\u22121))\u2212D(\u03b1(t\u22121))]\u2212 ( s n )2 G(t) 2\u03bb ,\nwhere\nG(t) = 1\nn n\u2211 i=1 ( \u2016Xi\u20162D\u2192D\u2032 \u2212 \u03b3(1\u2212 s)\u03bbn s ) Et [ \u2016u(t\u22121)i \u2212 \u03b1 (t\u22121) i \u2016 2 D ] ,\nand \u2212u(t\u22121)i = \u2207\u03c6i(X>i w(t\u22121)). Proof. Since only the i\u2019th element of \u03b1 is updated, the improvement in the dual objective can be written as\nn[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] = ( \u2212\u03c6\u2217(\u2212\u03b1(t)i )\u2212 \u03bbng \u2217 ( v(t\u22121) + (\u03bbn)\u22121Xi\u2206\u03b1i )) \u2212 ( \u2212\u03c6\u2217(\u2212\u03b1(t\u22121)i )\u2212 \u03bbng \u2217 ( v(t\u22121) )) The smoothness of g\u2217 implies that g\u2217(v + \u2206v) \u2264 h(v; \u2206v), where h(v; \u2206v) := g\u2217(v) + \u2207g\u2217(v)>\u2206v + 1 2\u2016\u2206v\u2016 2 D\u2032 . Therefore,\nn[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2265 ( \u2212\u03c6\u2217(\u2212\u03b1(t)i )\u2212 \u03bbnh ( v(t\u22121); (\u03bbn)\u22121Xi\u2206\u03b1i )) \ufe38 \ufe37\ufe37 \ufe38\nA\n\u2212 ( \u2212\u03c6\u2217(\u2212\u03b1(t\u22121)i )\u2212 \u03bbng \u2217 ( v(t\u22121) )) \ufe38 \ufe37\ufe37 \ufe38\nB\n.\nBy the definition of the update we have for all s \u2208 [0, 1] that\nA = max \u2206\u03b1i \u2212\u03c6\u2217(\u2212(\u03b1(t\u22121)i + \u2206\u03b1i))\u2212 \u03bbnh\n( v(t\u22121); (\u03bbn)\u22121Xi\u2206\u03b1i ) \u2265 \u2212\u03c6\u2217(\u2212(\u03b1(t\u22121)i + s(u (t\u22121) i \u2212 \u03b1 (t\u22121) i )))\u2212 \u03bbnh(v (t\u22121); (\u03bbn)\u22121sXi(u (t\u22121) i \u2212 \u03b1 (t\u22121) i )). (23)\nFrom now on, we omit the superscripts and subscripts. Since \u03c6\u2217 is \u03b3-strongly convex, we have that\n\u03c6\u2217(\u2212(\u03b1+s(u\u2212\u03b1))) = \u03c6\u2217(s(\u2212u)+(1\u2212s)(\u2212\u03b1)) \u2264 s\u03c6\u2217(\u2212u)+(1\u2212s)\u03c6\u2217(\u2212\u03b1)\u2212 \u03b3 2 s(1\u2212s)\u2016u\u2212\u03b1\u20162D (24)\nCombining this with (23) and rearranging terms we obtain that\nA \u2265 \u2212s\u03c6\u2217(\u2212u)\u2212 (1\u2212 s)\u03c6\u2217(\u2212\u03b1) + \u03b3 2 s(1\u2212 s)\u2016u\u2212 \u03b1\u20162D \u2212 \u03bbnh(v; (\u03bbn)\u22121sX(u\u2212 \u03b1))\n= \u2212s\u03c6\u2217(\u2212u)\u2212 (1\u2212 s)\u03c6\u2217(\u2212\u03b1) + \u03b3 2 s(1\u2212 s)\u2016u\u2212 \u03b1\u20162D \u2212 \u03bbng\u2217(v)\u2212 sw>X(u\u2212 \u03b1)\u2212 s2\u2016X(u\u2212 \u03b1)\u20162D\u2032 2\u03bbn \u2265 \u2212s(\u03c6\u2217(\u2212u) + w>Xu) + (\u2212\u03c6\u2217(\u2212\u03b1)\u2212 \u03bbng\u2217(v))\n+ s\n2\n( \u03b3(1\u2212 s)\u2212\ns\u2016X\u20162D\u2192D\u2032 \u03bbn\n) \u2016u\u2212 \u03b1\u20162D + s(\u03c6\u2217(\u2212\u03b1) + w>X\u03b1).\nSince \u2212u = \u2207\u03c6(X>w) we have \u03c6\u2217(\u2212u) + w>Xu = \u2212\u03c6(X>w), which yields\nA\u2212B \u2265 s [ \u03c6(X>w) + \u03c6\u2217(\u2212\u03b1) + w>X\u03b1+ ( \u03b3(1\u2212 s)\n2 \u2212 s\u2016X\u20162D\u2192D\u2032 2\u03bbn\n) \u2016u\u2212 \u03b1\u20162D ] . (25)\nNext note that with w = \u2207g\u2217(v), we have g(w) + g\u2217(v) = w>v. Therefore:\nP (w)\u2212D(\u03b1) = 1 n n\u2211 i=1 \u03c6i(X > i w) + \u03bbg(w)\u2212 ( \u2212 1 n n\u2211 i=1 \u03c6\u2217i (\u2212\u03b1i)\u2212 \u03bbg\u2217(v) )\n= 1\nn n\u2211 i=1 \u03c6i(X > i w) + 1 n n\u2211 i=1 \u03c6\u2217i (\u2212\u03b1i) + \u03bbw>v\n= 1\nn n\u2211 i=1 ( \u03c6i(X > i w) + \u03c6 \u2217 i (\u2212\u03b1i) + w>Xi\u03b1i ) .\nTherefore, if we take expectation of (25) w.r.t. the choice of i we obtain that\n1 s Et[A\u2212B] \u2265 [P (w)\u2212D(\u03b1)]\u2212 s 2\u03bbn \u00b7 1 n n\u2211 i=1 ( \u2016Xi\u20162D\u2192D\u2032 \u2212 \u03b3(1\u2212 s)\u03bbn s ) Et[\u2016ui \u2212 \u03b1i\u20162D]\ufe38 \ufe37\ufe37 \ufe38\n=G(t)\n.\nWe have obtained that\nn s Et[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2265 [P (w(t\u22121))\u2212D(\u03b1(t\u22121))]\u2212\nsG(t)\n2\u03bbn . (26)\nMultiplying both sides by s/n concludes the proof of the lemma.\nEquipped with the above lemmas we are ready to prove Theorem 1 and Theorem 2.\nProof of Theorem 1. The assumption that \u03c6i is (1/\u03b3)-smooth implies that \u03c6\u2217i is \u03b3-strongly-convex. We will apply Lemma 6 with\ns = n\nn+R2/(\u03bb\u03b3) =\n\u03bbn\u03b3\nR2 + \u03bbn\u03b3 \u2208 [0, 1] .\nRecall that \u2016Xi\u2016D\u2192D\u2032 \u2264 R. Therefore, the choice of s implies that\n\u2016Xi\u20162D\u2192D\u2032 \u2212 \u03b3(1\u2212 s)\u03bbn s \u2264 R2 \u2212 1\u2212 s s/(\u03bbn\u03b3) = R2 \u2212R2 = 0 ,\nand hence G(t) \u2264 0 for all t. This yields,\nEt[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2265 s n (P (w(t\u22121))\u2212D(\u03b1(t\u22121))) . (27)\nTaking expectation of both sides with respect to the randomness at previous rounds, and using the law of total expectation, we obtain that\nE[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2265 s n E[P (w(t\u22121))\u2212D(\u03b1(t\u22121))] . (28)\nBut since (t\u22121)D := D(\u03b1 \u2217)\u2212D(\u03b1(t\u22121)) \u2264 P (w(t\u22121))\u2212D(\u03b1(t\u22121)) andD(\u03b1(t))\u2212D(\u03b1(t\u22121)) = (t\u22121)D \u2212 (t) D , we obtain that E[ (t)D ] \u2264 ( 1\u2212 sn ) E[ (t\u22121)D ] \u2264 ( 1\u2212 sn )t (0) D \u2264 (0) D e \u2212 st n . Therefore, whenever t \u2265 n\ns log(\n(0) D / D) =\n( n+ R 2\n\u03bb\u03b3\n) log(\n(0) D / D) ,\nwe are guaranteed that E[ (t)D ] would be smaller than D. Using again (28), we can also obtain that\nE[P (w(t))\u2212D(\u03b1(t))] \u2264 n s E[D(\u03b1(t+1))\u2212D(\u03b1(t))] = n s E[ (t)D \u2212 (t+1) D ] \u2264 n s E[ (t)D ]. (29)\nSo, requiring E[ (t)D ] \u2264 s n P we obtain an expected duality gap of at most P . This means that we should require\nt \u2265 ( n+ R 2\n\u03bb\u03b3\n) log((n+ R 2\n\u03bb\u03b3 ) \u00b7 (0) D P ) ,\nwhich proves the first part of Theorem 1. Next, we sum the first inequality of (29) over t = T0 + 1, . . . , T to obtain\nE  1 T \u2212 T0 T\u2211 t=T0+1 (P (w(t))\u2212D(\u03b1(t)))  \u2264 n s(T \u2212 T0) E[D(\u03b1(T+1))\u2212D(\u03b1(T0+1))].\nNow, if we choose w\u0304, \u03b1\u0304 to be either the average vectors or a randomly chosen vector over t \u2208 {T0 + 1, . . . , T}, then the above implies\nE[P (w\u0304)\u2212D(\u03b1\u0304)] \u2264 n s(T \u2212 T0) E[D(\u03b1(T+1))\u2212D(\u03b1(T0+1))]\n\u2264 n s(T \u2212 T0) E[ (T0+1)D )] \u2264 n s(T \u2212 T0) (0) D e \u2212 sT0 n .\nIt follows that in order to obtain a result of E[P (w\u0304)\u2212D(\u03b1\u0304)] \u2264 P , we need to have\nT0 \u2265 n\ns log\n( n\n(0) D\ns(T \u2212 T0) P\n) .\nIn particular, the choice of T \u2212 T0 = ns and T0 = n s log( (0) D / P ) satisfies the above requirement.\nProof of Theorem 2. Define t0 = dns log(2 (0) D / D)e. The proof of Theorem 1 implies that for every t, E[ (t)D ] \u2264 (0) D e \u2212 st n . By Markov\u2019s inequality, with probability of at least 1/2 we have (t)D \u2264 2 (0) D e \u2212 st n . Applying it for t = t0 we get that (t0) D \u2264 D with probability of at least 1/2. Now, lets apply the same argument again, this time with the initial dual sub-optimality being (t0)D . Since the dual is monotonically non-increasing, we have that (t0)D \u2264 (0) D . Therefore, the same argument tells us that with probability of at least 1/2 we would have that (2t0)D \u2264 D. Repeating this dlog2(1/\u03b4)e times, we obtain that with probability of at least 1 \u2212 \u03b4, for some k we have that (kt0)D \u2264 D. Since the dual is monotonically non-decreasing, the claim about the dual sub-optimality follows.\nNext, for the duality gap, using (27) we have that for every t such that (t\u22121)D \u2264 D we have\nP (w(t\u22121))\u2212D(\u03b1(t\u22121)) \u2264 n s E[D(\u03b1(t))\u2212D(\u03b1(t\u22121))] \u2264 n s D .\nThis proves the second claim of Theorem 2. For the last claim, suppose that at round T0 we have (T0) D \u2264 D. Let T = T0 + n/s. It follows that if we choose t uniformly at random from {T0, . . . , T \u2212 1}, then E[P (w(t)) \u2212 D(\u03b1(t))] \u2264 D. By Markov\u2019s inequality, with probability of at least 1/2 we have P (w(t)) \u2212 D(\u03b1(t)) \u2264 2 D. Therefore, if we choose log2(2/\u03b4) such random t, with probability \u2265 1\u2212 \u03b4/2, at least one of them will have P (w(t))\u2212D(\u03b1(t)) \u2264 2 D. Combining with the first claim of the theorem, choosing D = P /2, and applying the union bound, we conclude the proof of the last claim of Theorem 2."}], "references": [{"title": "Estimate sequence methods: extensions and approximations", "author": ["Michel Baes"], "venue": "Institute for Operations Research, ETH, Zu\u0308rich, Switzerland,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Exponentiated gradient algorithms for conditional random fields and max-margin markov networks", "author": ["M. Collins", "A. Globerson", "T. Koo", "X. Carreras", "P. Bartlett"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["Andrew Cotter", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "arXiv preprint arXiv:1106.4574,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["K. Crammer", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Smooth optimization with approximate gradient", "author": ["Alexandre d\u2019Aspremont"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "First-order methods of smooth convex optimization with inexact oracle", "author": ["Olivier Devolder", "Francois Glineur", "Yu. Nesterov"], "venue": "Technical Report 2011/2,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["J. Duchi", "Y. Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Efficient projections onto the l 1-ball for learning in high dimensions", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Composite objective mirror descent", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Ambuj Tewari"], "venue": "In Proceedings of the 23rd Annual Conference on Learning Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework", "author": ["Saeed Ghadimi", "Guanghui Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Accelerated gradient methods for stochastic optimization and online learning", "author": ["Chonghai Hu", "Weike Pan", "James T Kwok"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Stochastic block-coordinate frank-wolfe optimization for structural svms", "author": ["S. Lacoste-Julien", "M. Jaggi", "M. Schmidt", "P. Pletscher"], "venue": "arXiv preprint arXiv:1207.4747,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "In NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "A Stochastic Gradient Method with an Exponential Convergence Rate for Strongly-Convex Optimization with Finite Training Sets", "author": ["Nicolas Le Roux", "Mark Schmidt", "Francis Bach"], "venue": "arXiv preprint arXiv:1202.6258,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Efficiency of coordinate descent methods on huge-scale optimization problems", "author": ["Y. Nesterov"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Smooth minimization of non-smooth functions", "author": ["Yurii Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Gradient methods for minimizing composite objective function", "author": ["Yurii Nesterov"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function", "author": ["Peter Richt\u00e1rik", "Martin Tak\u00e1\u010d"], "venue": "Mathematical Programming,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Convergence rates of inexact proximal-gradient methods for convex optimization", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "Technical Report arXiv:1109.2415,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Stochastic methods for l 1-regularized loss minimization", "author": ["S. Shalev-Shwartz", "A. Tewari"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Pegasos: Primal Estimated sub-GrAdient SOlver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "In ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Stochastic methods for l1 regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": "In ICML,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "arXiv preprint arXiv:1209.1873,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Trading accuracy for sparsity in optimization problems with sparsity constraints", "author": ["Shai Shalev-Shwartz", "Nathan Srebro", "Tong Zhang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Dual averaging method for regularized stochastic learning and online optimization", "author": ["Lin Xiao"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "On the dual formulation of regularized linear systems", "author": ["Tong Zhang"], "venue": "Machine Learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2002}], "referenceMentions": [{"referenceID": 24, "context": "This matches the recent result of Shalev-Shwartz and Zhang [25], Le Roux et al.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "[15], but our setting is significantly more general.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "This significantly improves over the result of [25, 15].", "startOffset": 47, "endOffset": 55}, {"referenceID": 14, "context": "This significantly improves over the result of [25, 15].", "startOffset": 47, "endOffset": 55}, {"referenceID": 17, "context": "It also significantly improves over the runtime of accelerated gradient descent due to Nesterov [18], which is \u00d5(dn \u221a 1 \u03bb \u03b3 ).", "startOffset": 96, "endOffset": 100}, {"referenceID": 21, "context": "[22]), when 1 \u03bb n.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "SVM SGD [22] d \u03bb AGD [17] dn \u221a 1 \u03bb", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "SVM SGD [22] d \u03bb AGD [17] dn \u221a 1 \u03bb", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 26, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 22, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 30, "endOffset": 38}, {"referenceID": 15, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 30, "endOffset": 38}, {"referenceID": 17, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 48, "endOffset": 55}, {"referenceID": 1, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 48, "endOffset": 55}, {"referenceID": 14, "context": "Ridge Regression Exact d2n+ d3 SGD [15], SDCA [25] d ( n+ 1 \u03bb )", "startOffset": 35, "endOffset": 39}, {"referenceID": 24, "context": "Ridge Regression Exact d2n+ d3 SGD [15], SDCA [25] d ( n+ 1 \u03bb )", "startOffset": 46, "endOffset": 50}, {"referenceID": 17, "context": "AGD [18] dn \u221a 1 \u03bb", "startOffset": 4, "endOffset": 8}, {"referenceID": 24, "context": "1 In particular, we generalize the recent analysis of [25] in two directions.", "startOffset": 54, "endOffset": 58}, {"referenceID": 24, "context": "As in [25], the runtime of this procedure is \u00d5 ( d ( n+ 1 \u03bb\u03b3 )) .", "startOffset": 6, "endOffset": 10}, {"referenceID": 24, "context": "Additional related work: As mentioned before, our first contribution is a proximal version of the stochastic dual coordinate ascent method and extension of the analysis given in Shalev-Shwartz and Zhang [25].", "startOffset": 203, "endOffset": 207}, {"referenceID": 2, "context": "[3] but in more restricted settings than the general problem considered in this paper.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "One can also apply the analysis of stochastic coordinate descent methods given in Richt\u00e1rik and Tak\u00e1\u010d [19] on the dual problem.", "startOffset": 102, "endOffset": 106}, {"referenceID": 12, "context": "Recently, [13] derived a stochastic coordinate ascent for structural SVM based on the Frank-Wolfe algorithm.", "startOffset": 10, "endOffset": 14}, {"referenceID": 6, "context": "[7], Schmidt et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "[20], to allow approximate and stochastic proximal mapping.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "See also [1, 6].", "startOffset": 9, "endOffset": 15}, {"referenceID": 5, "context": "See also [1, 6].", "startOffset": 9, "endOffset": 15}, {"referenceID": 19, "context": "In particular, it relies on similar ideas as in Proposition 4 of [20].", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "However, our specific requirement is different, and the proof presented here is different and significantly simpler than that of [20].", "startOffset": 129, "endOffset": 133}, {"referenceID": 11, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 10, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 3, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 14, "context": "As in [15, 25], we avoid the polynomial dependence on 1/ by allowing more than a single pass over the data.", "startOffset": 6, "endOffset": 14}, {"referenceID": 24, "context": "As in [15, 25], we avoid the polynomial dependence on 1/ by allowing more than a single pass over the data.", "startOffset": 6, "endOffset": 14}, {"referenceID": 26, "context": "Note that this particular update is rather similar to the update step of proximal-gradient dual-averaging method (see for example Xiao [27]).", "startOffset": 135, "endOffset": 139}, {"referenceID": 0, "context": "Let s = argmax s\u2208[0,1] [ \u2212\u03c6i (\u2212(\u03b1 (t\u22121) i + sq))\u2212 sw (t\u22121)>Xiq \u2212 s2 2\u03bbn \u2016Xiq\u20162D\u2032 ]", "startOffset": 17, "endOffset": 22}, {"referenceID": 16, "context": "Following Nesterov [17], we apply a \u201csmoothing\u201d technique.", "startOffset": 19, "endOffset": 23}, {"referenceID": 25, "context": "5 in [26].", "startOffset": 5, "endOffset": 9}, {"referenceID": 16, "context": "See Nesterov [17] for discussion.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "The conjugate function is \u03c6\u2217(b) = max a ab\u2212 log(1 + e) = { b log(b) + (1\u2212 b) log(1\u2212 b) if b \u2208 [0, 1] \u221e otherwise", "startOffset": 94, "endOffset": 100}, {"referenceID": 8, "context": "While we do not have a closed form solution for the minimization problem over b in the definition of \u03c6\u0303\u03b3 above, this is a problem of projecting onto the intersection of the L1 ball and the positive orthant, and can be solved efficiently using the following procedure, adapted from [9].", "startOffset": 281, "endOffset": 284}, {"referenceID": 14, "context": "This matches the recent results of [15, 25].", "startOffset": 35, "endOffset": 43}, {"referenceID": 24, "context": "This matches the recent results of [15, 25].", "startOffset": 35, "endOffset": 43}, {"referenceID": 13, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 26, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 9, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "Another relevant approach is the FISTA algorithm of [2].", "startOffset": 52, "endOffset": 55}, {"referenceID": 20, "context": "[21] showed that the runtime of this approach is", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Similar results can also be found in [16].", "startOffset": 37, "endOffset": 41}, {"referenceID": 20, "context": "If R2 = O(1) then the runtime of our method is much better than that of [21].", "startOffset": 72, "endOffset": 76}, {"referenceID": 20, "context": "This is the same or better than [21] whenever d = O(n).", "startOffset": 32, "endOffset": 36}, {"referenceID": 4, "context": "7 Multiclass SVM Next we consider Multiclass SVM using the construction described in Crammer and Singer [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "Such ideas were explored in [5] for the non-smooth max-of-hinge loss.", "startOffset": 28, "endOffset": 31}, {"referenceID": 8, "context": "By the properties of projection onto the simplex (see [9]), for every z \u2208 (zj , zj+1) we have that the projection of \u03bc onto the set {b \u2208 R+ : \u2016b\u20161 = z} is of the form ar = max{0, \u03bcr \u2212 \u03b8/j} where \u03b8 = (\u2212z + \u03bc\u0304j)/j.", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "In this section we compare Prox-SDCA, its accelerated version Accelerated-Prox-SDCA, and the FISTA algorithm of [2], on L1 \u2212 L2 regularized loss minimization problems.", "startOffset": 112, "endOffset": 115}, {"referenceID": 23, "context": "The experiments were performed on three large datasets with very different feature counts and sparsity, which were kindly provided by Thorsten Joachims (the datasets were also used in [24]).", "startOffset": 184, "endOffset": 188}, {"referenceID": 23, "context": "We multiplied each xi by yi and following [24], we employed the smooth hinge loss, \u03c6\u0303\u03b3 , as in (9), with \u03b3 = 1.", "startOffset": 42, "endOffset": 46}, {"referenceID": 24, "context": "The proof technique follows that of Shalev-Shwartz and Zhang [25], but with the required generality for handling general strongly convex regularizers and smoothness/Lipschitzness with respect to general norms.", "startOffset": 61, "endOffset": 65}, {"referenceID": 0, "context": "Then, for any iteration t and any s \u2208 [0, 1] we have Et[D(\u03b1)\u2212D(\u03b1)] \u2265 s n [P (w(t\u22121))\u2212D(\u03b1(t\u22121))]\u2212 ( s n )2 G(t) 2\u03bb ,", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "By the definition of the update we have for all s \u2208 [0, 1] that", "startOffset": 52, "endOffset": 58}, {"referenceID": 0, "context": "We will apply Lemma 6 with s = n n+R2/(\u03bb\u03b3) = \u03bbn\u03b3 R2 + \u03bbn\u03b3 \u2208 [0, 1] .", "startOffset": 60, "endOffset": 66}], "year": 2013, "abstractText": "We introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner-outer iteration procedure. We analyze the runtime of the framework and obtain rates that improve state-of-the-art results for various key machine learning optimization problems including SVM, logistic regression, ridge regression, Lasso, and multiclass SVM. Experiments validate our theoretical findings.", "creator": "LaTeX with hyperref package"}}}