{"id": "1312.4814", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Dec-2013", "title": "Mining Malware Specifications through Static Reachability Analysis", "abstract": "the number of malicious online software ( malware ) users is growing out of control. syntactic signature based detection cannot cope with such growth and simple manual construction of malware signature databases databases needs to literally be replaced by numerous computer learning based search approaches. currently, a single modern signature capturing the semantics of a malicious behavior can be used to replace an arbitrarily large number of old - fashioned synthetic syntactical pattern signatures. however teaching computers to learn such behaviors is certainly a challenge. existing work relies on dynamic analysis to extract malicious behaviors, but such technique does not guarantee the coverage of all behaviors. to not sidestep this limitation we show consumers how to learn malware signatures using static reachability analysis. the idea is to model binary programs using pushdown systems ( strategies that can be used to model the stack operations occurring concurrently during the binary cookie code execution ), use reachability analysis to extract behaviors in the form of false trees, and use subtrees that are common among the trees extracted from a training set of malware files as signatures. to detect malware we partially propose algorithm to merely use a tree automaton to electronically compactly store malicious behavior trees and check if any of the subtrees extracted from the file under analysis library is malicious. experimental quantitative data shows that our approach can be used to learn signatures from either a training set set of malware files and use them to detect a legitimate test set of malware that is 5 % times plus the size of the training set.", "histories": [["v1", "Tue, 17 Dec 2013 15:08:39 GMT  (75kb,D)", "http://arxiv.org/abs/1312.4814v1", "Lecture notes in computer science (2013)"]], "COMMENTS": "Lecture notes in computer science (2013)", "reviews": [], "SUBJECTS": "cs.CR cs.AI cs.LO", "authors": ["hugo daniel macedo", "tayssir touili"], "accepted": false, "id": "1312.4814"}, "pdf": {"name": "1312.4814.pdf", "metadata": {"source": "CRF", "title": "Mining malware specifications through static reachability analysis", "authors": ["Hugo Daniel Macedo", "Tayssir Touili"], "emails": ["macedo@liafa.univ-paris-diderot.fr", "touili@liafa.univ-paris-diderot.fr"], "sections": [{"heading": "1 Introduction", "text": "Malware (malicious software) is software developed to damage the system that executes it, e.g.: virus, trojans, rootkits, etc. A malware variant performs the same damage as another known malware, but its code, its syntactical representation, is different. Malware can be grouped into families, sets of malware sharing a common trait. Security reports acknowledge a steady increase in the number of new malware. For instance, in 2010 the number of newly unique variants of malware was 286 million [13] and recent numbers confirm the trend [21]. Such numbers challenge current malware detection technology and because variants can be automatically generated the problem tends to get worse. Research confirms the unsuitability of current malware detectors [14,24]. The problem is the low-level of the techniques used.\nThe basic detection technique is signature matching, it consists in the inspection of the binary code and search for patterns in the form of binary sequences [27]. Such patterns, malware signatures in the jargon and syntactic signatures throughout this paper,\nar X\niv :1\n31 2.\n48 14\nv1 [\ncs .C\nR ]\n1 7\nD ec\n2 01\n2 are manually introduced in a database by experts. As it is possible to automatically generate an unbounded number of variants, such databases would have to grow arbitrarily, not to mention it takes about two months to manually update them [14].\nAn alternative to signature detection is dynamic analysis, which runs malware in a virtual machine. Therefore, it is possible to check the program behavior, for instance to detect calls to system functions or changes in sensitive files, but as the execution duration must be limited in time it is difficult to trigger the malicious behaviors, since these may be hidden behind user interaction or require delays.\nTo overcome the problems of the previous techniques, a precise notion of malicious behavior was introduced. Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22]. Such techniques allow to check the behavior (not the syntax) of the program without executing it. A malicious behavior is a pattern written as a logical formula that specifies at a semantic level how the syntactic instructions in the binary executable perform damage during execution. As the malicious behavior is the same in all the variants of a malware, such patterns can be used as modern (semantic) signatures which can be efficiently stored.\nThe prime example of a malicious behavior is self-replication [27]. A typical\nl1 : push m l2 : mov ebx 0 l3 : push ebx l4 : call GetModuleFileName l5 : push m l6 : call CopyFile\nFig. 1. Malware assembly fragment.\ninstance of such behavior is a program that copies its own binary representation into another file, as exemplified in the assembly fragment of Fig. 1. The attacker program discovers and stores its file path into a memory address m by calling the GetModuleFileName function with 0 as first parameter and m as second parameter. Later such file name is used to infect another file by calling\nCopyFile with m as first parameter. Such malicious behaviors can naturally be defined in terms of system functions calls and data flow relationships.\nSystem functions are the mediators between programs and their environment (user data, network access,. . . ), and as those functions can be given a fixed semantics, and are defined in an Application Programming Interface (API), they can be used as a common denominator between programs, i.e. if the syntactical representation of programs is different but both interact in the same way with the environment, the programs are semantically equivalent from an observer perspective.\nA data flow expresses that a value outputted at a certain time instant of program execution by a function is used as an input by another function at a following instant. For example when a parameter is outputted by a system call and is used as an input of another. Such data flow relations allow us to characterize combined behaviors purported by the related system calls. For instance, in the example of Fig. 1 it is the data flow evidenced by the variablem, defined at the invocation of GetModuleFileName and used at the invocation of CopyFile that establishes the self-replication behavior.\nThe malicious behaviors can be described naturally by trees expressing data flows among system calls made at runtime. Due to code branches during execution it is possible to have several flows departing from the same system call, thus a tree structure is particularly suitable to represent malicious behaviors. Plus, as such behaviors are described independently of the functionality of the code that makes the calls, system call\n3 data flow based signatures are more robust against code obfuscations. Thus, a remaining challenge is to learn such trees from malware binary executables.\nRecent work [2,10,14] shows that we can teach computers to learn malicious behavior specifications. Given a set of malware, the problem of extracting malicious behavior signatures consists in the extraction of the behaviors included in the set and use statistical machinery to choose the ones that are more likely to appear. However the approaches rely on dynamic analysis of executables which do not fully cover all behaviors. To overcome these limitations, in this paper we show how to use static reachability analysis to extract malicious behaviors, thus covering the whole behaviors of a program at once and within a limited time.\nOur approach. We address such challenge in the following way: given the set of known malware binary executables, we extract its malicious behaviors in the form of edge labeled trees with two kinds of nodes. One kind represents the knowledge that a system function is called, the other kind of nodes represents which values were passed as parameters in the call (because some data flows between functions are only malicious when the calls were made with a specific parameter e.g. the 0 passed to GetModuleFileName in the self-replication behavior). Tree labels describe either a relation among system calls or the number of the parameter instantiated. For example, the malicious behavior displayed in Fig. 1 can be displayed in the tree shown in Fig. 2. The tree captures the self-replication behavior.\nThe edge on the left means that the GetModuleFileName function is called with 0 as first parameter (thus it will output the path to the malware file that called it) while the edge on the right captures the data flow between the two system calls i.e. the second parameter of a call to GetModuleFileName is an output\nand it is used as an input in the first parameter of a call to CopyFile. Thus, such tree describes the following behavior: GetModuleFileName is called with 0 as first parameter and its second parameter will be used as input in the first parameter of a subsequent call to CopyFile.\nThe first step in the tree extraction process is to model the malware binaries, which involves modeling (recursive) procedure calling and return, and parameter passing that are implemented using a stack. For this aim, we model each of the files using a pushdown system (PDS), an automaton that mimics the binary code execution as a state transition system. With this model one is able to rigorously define the behavior of the program and use the decidable and efficient state reachability analysis of PDSs to calculate all the states and the contents of the stack that can occur during execution. Therefore, if malware performs a system call with certain parameters, the reachability analysis will reveal it even if the call is obfuscated, e.g.: jump to function address. The same happens if the call is made using indirect addressing because the analysis will reveal that during execution the entry point of the system call is reached. Our approach also works against bitwise manipulation of parameters, because we assume the system functions are not changed by the attacker, thus when the executions reaches the entry point of the system function, parameters must not be obfuscated, for instance in the example above even\n4 if the value of m is obfuscated, at the entry point of the call the value must be m to purport the self-replication behavior.\nFrom the reachability analysis of each PDS, we obtain a multi-automaton (MA), a finite automaton encoding the possibly infinite reachable configurations (states and stack contents)[8,12]. As the number of system functions is finite, we cut the finite automaton to represent only the states corresponding to system function entry points and stacks limited to the finite number of parameters passed to the function.\nWe analyze all data flows using the MAs to build trees, written as system call dependency trees (SCDTs), representing such flows. The extracted trees correspond to a superset of the data flows present in the malware because the PDS model is an overapproximation of the behaviors in the binary program. This means, that when a data flow is found using our approach, there exists an execution path in the model evidencing such data flow, but such execution path may not be possible in the binary program due to approximation errors.\nFrom the trees (SCDTs) extracted from the set of known malware binary executables we use a data-mining algorithm to compute the most frequent subtrees. We assume such correspond to malicious behaviors and we will term them malicious system call dependency trees (MalSCDTs). The usage of such data-mining algorithm allows to compute behaviors, which we use as signatures that are general and implementation details independent, therefore robust.\nTo store and recognize MalSCDTs we infer an automaton, termed HELTA, recognizing trees containing MalSCDTs as subtrees. This allows to efficiently store the malware signatures and recognize behaviors if they are hidden inside another behavior. The overview of the learning process from the malware files to the database of semantic signatures is depicted in Figure 3.\nTo evaluate the efficiency of the computed malicious behaviors, we show they can be applied to efficiently detect malware. To perform malware detection on a binary executable, we extract trees using the same procedure used in the learning process (described above), but applied to a single file. We check whether the automaton storing malicious behaviors accepts any subtree of the extracted trees (SCDTs). If that is the case the executable contains a malicious behavior and is classified as malware. The depiction of such process is shown in Figure 4.\n5 We implemented a tool that extracts the behaviors and selects the malicious candidates using an algorithm for the frequent subgraph problem1. With such tool we were able to infer some signatures not inferred using previous approaches [2,10,14] because our signatures track calls to functions of the Win32 API instead of calls to the Native API. It is a fact that it is always possible to use the previous approaches to find Native API level signatures equivalent to the ones we infer, therefore we do not claim our tool can express more behaviors, instead we claim that our approach is complementary to such works. It allows to express behaviors at different API levels and to extract more abstract/readable (Win32 API level) signatures.\nWe obtained promising results, and we were able to detect 983 malware files using the malicious trees inferred from 193 malware files, with a 0% false positive rate (thus showing our approach learns malicious behaviors that do not appear in benign programs). This number of detected malware is larger than the 16 files reported in [10] and in line with the 912 files detected in [14]. Our false positive detection rate is better (5% reported in [2]).\nOutline. In Section 2 we show how to model binary executables as PDSs. Malware signatures are defined as labeled trees in Section 3. We present an algorithm to infer malware specifications in Section 4, and we show how to use tree automata to perform malware detection in Section 5. Experimental data shows our approach can be used to detect malware as detailed in Section 6. The related work is summarized in Section 7 and in Section 8 we present conclusions and future work."}, {"heading": "2 Binary code modeling", "text": "Malware detection is performed directly in the executable encoding of the software (binary code containing machine instructions and data). By modeling the operational semantics of binary code, we are able to analyze it without relying on execution. This section introduces the modeling framework and how we model executable files."}, {"heading": "2.1 Pushdown systems", "text": "A pushdown system (PDS) is a triple P = (P, \u0393,\u2206) where P is a finite set of control points, \u0393 is a finite alphabet of stack symbols, and \u2206 \u2286 (P \u00d7 \u0393 ) \u00d7 (P \u00d7 \u0393 \u2217) is a finite set of transition rules. A configuration \u3008p, \u03c9\u3009 of P is an element of P \u00d7 \u0393 \u2217. We write \u3008p, \u03b3\u3009 \u21aa\u2192 \u3008q, \u03c9\u3009 instead of ((p, \u03b3), (q, \u03c9)) \u2208 \u2206. The immediate successor relation P\u2286 (P \u00d7 \u0393 \u2217) \u00d7 (P \u00d7 \u0393 \u2217) is defined as follows: if \u3008p, \u03b3\u3009 \u21aa\u2192 \u3008q, \u03c9\u3009, then \u3008p, \u03b3\u03c9\u2032\u3009 P \u3008q, \u03c9\u03c9\u2032\u3009 for every \u03c9\u2032 \u2208 \u0393 \u2217. The reachability relation\u21d2 is defined as the reflexive and transitive closure of the immediate successor relation.\nGiven a set of configurations C, post(C) is defined as the set of immediate successors of the elements in C. The reflexive and transitive closure of post is denoted as post\u2217(C) = {c\u2032 \u2208 P \u00d7 \u0393 \u2217 | \u2203c \u2208 C, c \u21d2 c\u2032} . Analogously pre(C) is defined as the set of immediate predecessors of elements in C. Its reflexive and transitive closure is denoted as pre\u2217(C) = {c \u2208 P \u00d7 \u0393 \u2217 | \u2203c\u2032 \u2208 C, c\u21d2 c\u2032}.\n1 A tree is a special case of a graph\n6 Given a pushdown system P = (P, \u0393,\u2206), a P-multi-automaton, P \u2212MA or MA when P is clear from context, is a tuple A = (\u0393,Q, \u03b4, P, F ), where Q is a finite set of states, \u03b4 \u2286 Q \u00d7 \u0393 \u00d7 Q is a transition relation, P \u2286 Q is the set of initial states corresponding to the control points of P , and F \u2286 Q is a set of final states.\nThe transition relation for MA is the smallest relation\u2192\u2286 Q\u00d7 \u0393 \u2217 \u00d7Q satisfying:\n\u2013 q \u03b3\u2212\u2192 q\u2032 if (q, \u03b3, q\u2032) \u2208 \u03b4 \u2013 q \u03c9\u03b3\u2212\u2212\u2192 q\u2032 if q \u03c9\u2212\u2192 q\u2032\u2032 and q\u2032\u2032 \u03b3\u2212\u2192 q\u2032\nA accepts (recognizes) a configuration \u3008p, w\u3009 if p w\u2212\u2192 q for some q \u2208 F . The set of configurations recognized by a MA A is called regular and is designated by Conf(A). The post\u2217 and pre\u2217 of regular configurations can be efficiently computed:\nTheorem 1. [8,12] For a pushdown system P = (P, \u0393,\u2206) and MA A, there exist MAs Apost\u2217 and Apre\u2217 recognizing post\u2217(Conf(A)) and pre\u2217(Conf(A)) respectively. These can be constructed in polynomial time and space."}, {"heading": "2.2 Modeling binary programs with PDSs", "text": "We use the approach detailed in [24, Section 2] to model each executable program P. The approach relies on the assumption that there exists an oracle O computing a PDS P = (P, \u0393,\u2206) from the binary program, where P corresponds to the control points of the program, \u0393 corresponds to the approximate set of values pushed to the stack, and \u2206 models the different instructions of the program. The obtained PDS mimics the runs of program P.\nIn addition to the approach of [24], let API be the set of all Application Programming Interface function names available in the program. We assume the oracle O approximates the set PAPI \u2286 P of control points of a program that correspond to instruction addresses that at program runtime are translated (dynamically linked) by the operating system into system function entry points, the number of parameters of such functions and the type of each parameter. We consider a simple type system: \u03c4 ::= in | out (in for input parameter, and out for output) containing the atomic value out used to denote a parameter that is modified after function execution and in to denote the parameter is not changed by the function.\nWe assume, O computes a function %\u03bb : PAPI \u2192 API that identifies program control points corresponding to system calls with an unique function name, a function %\u03c4 : PAPI \u00d7 N \u2192 2\u03c4 such that %\u03c4 (p, n) is the set2 of possible types of the n-th parameter of the system call that has p as entry point, and a function %ar : PAPI \u2192 N defining the number of parameters for each system call in PAPI For example, if we consider the program of Fig. 1, we obtain PAPI = {lg, lc} since these two points correspond to system call entry points, %\u03bb(lg) = GetModuleF ileName since lg corresponds to the entry point of the function GetModuleFileName. %ar(lg) = 3 since GetModuleFileName has three parameters, and %\u03c4 (lg, 2) = {out} since the second parameter of the GetModuleFileName function is defined as an output, and analogously %\u03c4 (lg, 1) = %\u03c4 (lg, 3) = {in}, since these correspond to input parameters.\n2 The API defines parameters that are both input and output.\n7"}, {"heading": "3 Malicious behavior specifications", "text": "As already mentioned, malicious behaviors, data flow relationships between system function calls, will be expressed as trees where nodes represent system functions or parameter values and edges specify the data flow or the number of the parameter to which the value was passed. We will now formally introduce the notion of edge labeled trees."}, {"heading": "3.1 Edge labeled trees", "text": "An unranked alphabet is a finite set F of symbols. Given an unranked alphabet F , let a set of colors C be an alphabet of unary symbols and disjoint from F , and X be a set of variables disjoint from F . The set T (F , C,X ) of colored terms over the unranked alphabet F , colors C and variables X it is the smallest set of terms such that:\n\u2013 F \u2286 T (F , C,X ), \u2013 X \u2286 T (F , C,X ), and \u2013 f(c1(t1), . . . , cn(tn)) \u2208 T (F , C,X ), for n \u2265 1, ci \u2208 C, ti \u2208 T (F , C,X ).\nf\nba\nc1 c2\nFig. 5. Example\nIf X = \u2205 then T (F , C,X ) is written as T (F , C), and its elements are designated as ground terms. Each element of the set of terms can be represented by an edge labeled tree. For example, let F = {f}, C = {c1, c2}, and X = \u2205. The colored tree f(c1(a), c2(b)) \u2208 T (F , C) can be represented by the edge labeled tree of Fig. 5.\nLet Xn be a set of n variables. A term E \u2208 T (F , C,Xn) is called an environment and the expression E[t1, . . . , tn] for t1, . . . , tn \u2208 T (F , C) denotes the term in T (F , C) obtained from E by replacing the variable xi by ti for each 1 \u2264 i \u2264 n.\nA subtree t\u2032 of a tree t in T (L, C), written as t\u2032 C t, is a term such that there exists an environment E in T (L, C, {x}) where x appears only once and t = E[t\u2032].\nThe tree f(c1(a), c2(b)) represents the same behavior as tree f(c2(b), c1(a)). Thus, to efficiently compare edge labeled trees, and to avoid missing malicious behaviors due to tree representation, we define a canonical representation of edge labeled trees. We assume that F and C are totally ordered.\nA term is in canonical form if it is a constant (leaf) or if it is a function (tree node) where each argument is in canonical form and arguments are sorted without repetitions by term order.\nLet c \u2208 C and t \u2208 F(C, T ) such that F , C, and T are respectively ordered by <F , <C , and <T , and t is in canonical form. We assume a subtree insertion operation (insert_subtree) where insert_subtree(c(t), t\u2032) adds c(t) as a child to the root of t\u2032 in the correct place to maintain a canonical representation of the tree, overwriting if the subtree c(t) already exists."}, {"heading": "3.2 System call dependency trees", "text": "We will represent malware behaviors as trees encoding data flow relationships between system function calls. Tree nodes represent either system functions or parameter values.\n8 Edge colors label the characteristics of the data flow between functions, e.g. 2 1 labeling an edge from function f and f \u2032 means that at some point f is called with some value v as second parameter, which is of type out, and afterwards f \u2032 is called with v as first parameter, which in turn is of type in. Moreover, when an edge connects a node labeled with function f and a child node with some value v, meaning the function was called with parameter v, it will be labeled with the number of the parameter, thus to represent a call was made with 0 as first parameter to function f , we add 1 as a label of the edge from node f to node 0.\nDefinition 1. Formally, let F be the set of all system call function names (the union of all possibly API function names returned by the oracle of Section 2) and values passed as function parameters (a subset of the union of all \u0393 sets calculated by the oracle). In addition, let C be a set of colors containing all the possible parameter numbers and data flows, i.e.: C = {1, . . . ,maxf\u2208API(%ar(f))} \u222a {x y | x, y \u2208 {1, . . . ,maxf\u2208API(%ar(f))}} A System Call Dependency Tree, written as SCDT, is defined as a ground term of the set T (F , C).\nExample. Let F = {0,GetModuleFileName,CopyFile} and C = {1, 2 1}, the behavior of Fig. 2 can be described by t = GetModuleFileName ( 1(0), 2 1(CopyFile) ) ."}, {"heading": "4 Mining malware specifications", "text": "In this section we show how to compute the SCDTs corresponding to malware behaviors that we will use as malware specifications. Given a finite set of programs P1, . . . ,Pq known to be malicious in advance we compute PDSs P1, . . . ,Pq that model these malicious programs. Then, for each PDS Pi we compute a set of trees TSi that contains the data flows represented as SCDTs for the program Pi. From the computed set of trees for each program, TS1, . . . ,TSq , we calculate the common subtrees, the ones that are most probable to appear in malware, that we use as malware specifications.\nTo compute the sets of trees TSi we proceed as follows: For each program Pi modeled as a PDS Pi we compute the finite automaton encoding the set of reachable configurations from the initial state using the reachability analysis algorithm from [12]. As there may be an infinite number of configurations and we are only interested in the configurations whose control points correspond to a system function entry point with some finite number of elements in the stack (only the parameters of the function under consideration are important), we build another automaton recognizing such finite set of configurations. For each of such configurations, understood as possible data flow origins, we repeat the process to calculate the reachable configurations, understood as possible data flow destinations. Then, if a data flow between configurations is found, i.e. the value passed as a parameter to an origin configuration has type out and the same value passed as a parameter of type in to a destination configuration, we build a SCDT with the origin function as root node and an edge to a node corresponding to the destination function.\nTo calculate the common subtrees we use the algorithm [30] computing frequent subgraph, to compute frequent subtrees.\n9"}, {"heading": "4.1 System call targeted reachability analysis", "text": "To compute the data flows for a malware pushdown system model P = (P, \u0393,\u2206), we first calculate the reachability of P using the algorithms presented in [12]. From P we build the (MA) automaton A that recognizes the post\u2217(\u3008pi, \u3009), i.e. the set of reachable configurations from the initial configuration \u3008pi, \u3009, where pi is a designated initial control point and denotes the empty stack.\nMA Trimming. To compute data flows between system call related control points po, pd \u2208 PAPI with parameter numbers %ar(po) = m and %ar(pd) = n we need to consider only the topm+1 and n+1 elements of the stack reached at control points po and pd because, in assembly, parameters are passed to functions through the stack. Before invoking a function the parameters are pushed in reverse order into the stack, and after the return address is pushed. Thus, if a function receives m parameters, then at its entry point, for instance po, the top m + 1 elements of the stack correspond to the parameters plus the return address. Thus we only need to consider the top m+1 elements of the stack reached at control point po. This is the reason why we can analyze the possibly infinite number of configurations encoded in the reachability resulting finite automaton, we only inspect a finite subset. To abbreviate the algorithm that computes SCDT we define such subset of configurations in terms of a new automaton obtained by cutting the MA resulting from the reachability analysis.\nDefinition 2. Given a MA A recognizing the reachable configurations of a PDS P = (P, \u0393,\u2206) we define the trim automaton A\u2020 as the automaton recognizing the configurations in the set: {\u3008p, w\u3009 \u2208 PAPI \u00d7 \u0393 \u2217 | |w| = %ar(p) + 1 \u2227 \u2203w\u2032 \u2208 \u0393 \u2217s.t. \u3008p, ww\u2032\u3009 is accepted by A}\nIntuitively, we cut the automaton and keep only configurations where control points p correspond to system function entry points, and the stacks are bounded by the number of parameters of the function plus one to take into account the return address. The trim operation will be written as \u03a8 , thusA\u2020 = \u03a8(A). It is trivial to prove that theConf(A\u2020) is a finite language, in fact the number of configurations corresponding to valid system call function entry point, and its finite number of parameters is at most: O(|PAPI | \u00b7 |\u0393 | \u00b7maxp\u2208PAPI (%ar(p)))."}, {"heading": "4.2 Extracting SCDTs", "text": "Algorithms 1 and 2 detail our approach to extract behaviors. We assume a maximum tree height h \u2208 N is given as input. We write \u03c9[n] to denote the n-th element of some word \u03c9 \u2208 \u0393 \u2217. Algorithm 1: ExtractSCDT\n1 forall the Pi do 2 TSi \u2190\u2212 \u2205; 3 A\u2020i \u2190\u2212 \u03a8(post\n\u2217(\u3008pi, \u3009)); 4 forall the \u3008po, \u03c9o\u3009 \u2208 Conf(A\u2020i ) do 5 TSi \u2190\u2212 TSi\u222a{BuildSCDT(\u3008po, \u03c9o\u3009,h)}; 6 end 7 end 8 return TS; The Algorithm 1 iterates over the models P1, . . . ,Pq (line 1). For each it initializes the set of resulting trees to the empty set (line 2) and computes the configurations corresponding to system calls that are reachable from the given initial configuration \u3008pi, \u3009 (line 3). The initial configuration is built using the binary executable entry point\n10\nand an empty stack. Then, for every configuration corresponding to a system call entry point \u3008po, \u03c9o\u3009 recognized by the trim automaton (line 4) it calls BuildSCDT to build a SCDT tree of height at most h with the function of entry point po as root (line 5).\nThe BuildSCDT procedure is displayed in Algorithm 2, it is used to recursively build a tree. First, the tree to be returned is initialized to be the origin system call entry point po (line 1). When the maximum desired tree height is not reached (line 2), we calculate what are the system calls reached from \u3008po, \u03c9o\u3009 (line 3) and check for flows to any system call related configuration \u3008pd, \u03c9d\u3009 (line 4). If a data flow is found between two configurations (line 5), i.e. there are parameter numbers n andm such that the value passed to system call at control point po is the same as the value passed in position m of system call at a control point pd, and there is in fact a flow (line 6) i.e. the parameter n of the function corresponding to the entry point po is of type out and the parameter m of the function corresponding to the entry point pd is of type in, we add a new child with label n m to the recursively computed tree for the destination system call pd (line 7).\nAlgorithm 2: BuildSCDT 1 tree = %\u03bb(po); 2 if h > 0 then 3 A\u2020 \u2190\u2212 \u03a8(post\u2217(\u3008po, \u03c9o\u3009)); 4 forall the \u3008pd, \u03c9d\u3009 \u2208 Conf(A\u2020) \\ {\u3008po, \u03c9o\u3009} do 5 forall the (n,m) s.t. 1 \u2264 n \u2264 %ar(po) \u2227 1 \u2264 m \u2264 %ar(pd) do 6 if wo[n] = wd[m] \u2227 %\u03c4 (po, n) = out \u2227 %\u03c4 (pd,m) = in then 7 tree\u2190\u2212 insert_subtree (n m(BuildSCDT(\u3008pd, \u03c9d\u3009 , h\u2212 1)), tree); 8 end 9 end\n10 end 11 end 12 forall the n \u2208 {1, .., %ar(po)} do 13 tree\u2190\u2212 insert_subtree (n(wo[n]), tree); 14 end 15 return tree;\nTo add the edges representing the values passed as parameters in the call of po we iterate over the possible number of parameters of the origin system call entry point (line 12) and add an edge with the number of parameter n and the value passed in the stack \u03c9o[n] (line 13). When the maximum desired tree height is reached, the algorithm returns only a tree with po as root and the values passed as parameters in the call."}, {"heading": "4.3 Computing malicious behavior trees", "text": "After extracting SCDTs for each of the inputed malware programs, one has to compute which are the ones that correspond to malicious behaviors. The SCDTs that correspond to malicious behaviors will be named malicious trees. To choose the malicious trees we compute the most frequent subtrees in the set TS of trees extracted from the set of malware used to train our detector. For that we need the notion of support set, the set of trees containing some given subtree, and the notion of tree support that gives the ratio of trees containing the subtree to the whole set of trees.\nGiven a finite set of trees TS \u2286 T (F , C) and a tree t \u2208 TS, the support set of a tree t is defined as Tt = {t\u2032 | t C t\u2032, t\u2032 \u2208 TS}. The tree support of a tree t in the set TS is\n11\ncalculated as sup(t) = |Tt||TS| . For a fixed threshold k the set of frequent trees of T is the set of trees with tree support greater than k.\nDefinition 3. For a set of system call dependency trees trees TS \u2286 T (F , C) and a given threshold k, a malicious behavior tree is a tree t \u2208 TS s.t. sup(t) \u2265 k. The set of malicious behavior trees will be called MalSCDT.\nTo compute frequent subtrees we specialize the frequent subgraph algorithm presented in [30] to the case of trees. The algorithm receives a set of trees and a support value k \u2208 [0, 1] and outputs all the subtrees with support at least k. The graph algorithm works by defining a lexicographical order among the trees and mapping each to a canonical representation using a code based on the depth-first search tree generated by the traversal. Using such lexicographical order the subtree search space can be efficiently explored avoiding duplicate computations."}, {"heading": "5 Malware detection", "text": "We show in this section how the malicious behaviors trees that we computed using our techniques can be used to efficiently detect malware. To decide whether a given program P is malware or not, we apply again the technique described in Section 4 to compute the SCDTs for the program P being analyzed. Then we check whether such trees correspond to malicious behaviors, i.e. whether such trees contain subtrees that correspond to malicious behaviors.\nTo efficiently perform this task, we use tree automata. The advantage of using tree automata is that we can build the minimal automaton that recognizes the set of malicious signatures, to obtain a compact and efficient database. Plus, malware detection, using membership in automata, can be done efficiently. However, we need to adapt tree\nautomata to suite malware detection, that is, to define automata that can recognize edge labeled trees. Furthermore, we cannot use standard tree automata because the trees that can be generated from the program P to be analyzed may have arbitrary arities (since we do not know a priori the behaviors of P). For example the behavior of the program P can be described by the tree of Fig. 6 that contains the self-replication malicious behavior of Fig. 2. However, if we use a binary tree automaton H to recognize the tree of Fig. 2, H will not recognize the tree of Fig. 6, because P contains the malicious behaviors and extra behaviors. To overcome this problem we will use unranked tree automata (a.k.a. hedge automata), since the trees that can be obtained by analysing program P might have arbitrary arity.\nIn this section, we show how to use hedge automata for malware detection. First, we give the formal definition of hedge automata. Then, we show how we can infer a hedge automaton to recognize malicious behaviors that may be contained in some tree. And we conclude by explaining how to use it to detect malware.\n12"}, {"heading": "5.1 Tree automata for edge labeled trees", "text": "Definition 4. An hedge edge labeled tree automaton (HELTA) over T (F , C) is a tuple H = (QH,F , C,A, \u2206H) where QH is a finite set of states, A \u2286 QH is the set of final states, and\u2206H is a finite set of rewriting rules defined as f(R)\u2192 q for f \u2208 F , q \u2208 QH, and R \u2286 [ C(QH) ]\u2217 is a regular word language over C(QH) i.e. the language encoding all the possible children of the tree node f . We define a move relation \u2212\u2192H between ground terms in T (F \u222aQH, C) as follows: Let t, t\u2032 \u2208 T (F \u222a QH, C), the move relation \u2212\u2192H is defined by: t \u2212\u2192H t\u2032 iff there exists an environment E \u2208 T (F \u222a QH, C, {x}), a rule r = f(R) \u2192 q \u2208 \u2206H such that t = E[f(c1(q1), . . . , cn(qn)))], and c1(q1) . . . cn(qn) \u2208 R, and t\u2032 = E[q]. We write \u2217\u2212\u2192H to denote the reflexive and transitive closure of \u2212\u2192H. Given an HELTA H = (QH,F , C,A, \u2206H) and an edge labeled tree t, we say that t is accepted by a state q if t \u2217\u2212\u2192H q, t is accepted by H if \u2203q \u2208 A s.t. t \u2217\u2212\u2192H q.\nIntuitively, given an input term t, a run of H on t according to the move relation\u2212\u2192H can be done in a bottom-up manner as follows: first, we assign nondeterministically a state q to each leaf labeled with symbol f if there is in \u2206H a rule of the form f(R)\u2192 q such that \u2208 R. Then, for each node labeled with a symbol f , and having the terms c1(t1), . . . , c1(tn) as children, we must collect the states q1, . . . , qn assigned to all its children, i.e., such that ci(ti)\n\u2217\u2212\u2192H qi , for 1 \u2264 i \u2264 n, and then associate a state q to the node itself if there exists in \u2206H a rule r = f(R)\u2192 q such that q1 . . . qn \u2208 R. A term t is accepted if H reaches the root of t in a final state."}, {"heading": "5.2 Inferring tree automata from malicious behavior trees", "text": "In this section we show how to infer an HELTA recognizing trees containing the inferred malicious behaviors. Thus, if t is a malicious behavior, and t\u2032 is a behavior of a program P that is under analysis, such that t\u2032 contains the behavior described by t, the automaton must recognize it. As an example assume t \u2208 MalSCDT is a tree of the form f(c1(a), c2(b))), s.t. a, b \u2208 F and E \u2208 T (F , C, {x}) is an environment, then the automaton must recognize trees t\u2032 of the form: E[f(c11(t11), . . . , c1m1(t 1 m1), c1(a(e1)), c21(t 2 1), . . . , c 2 m2(t 2 m2), c2(b(e2)), c 3 1(t 3 1), . . . , c 3 m3(t 3 m3))] meaning the tree is embedded in other tree, i.e. t is a subtree of t\u2032 and it may have extra behaviors cji (t j i ) and also extra subtrees e1, e2 \u2208 T (F , C) as child of the leafs a and b. Let t \u2208 MalSCDT, we define the operation \u2126 : MalSCDT \u2192 T (F , C) that transforms a malicious tree into the set of all system call dependency trees containing the malicious behavior t. \u2126 is defined inductively as:\n(1) \u2126(a) = {a(t) | t \u2208 T (F , C)}, if a \u2208 F is a leaf, (2) \u2126(f(c1(t1), . . . , cn(tn))) = {f(c11(t11), . . . , c1n1(t 1 n1), c1(\u2126(t1)), c 2 1(t 2 1), . . . ,\nc2n2(t 2 n2), . . . , c n 1 (t n 1 ), . . . , c n nn(t n nn), cn(\u2126(tn)), c n+1 1 (t n+1 1 ), . . . , c n+1 nn+1(t n+1 nn+1)) | cji \u2208 C and t j i \u2208 T (F , C)}, otherwise.\nThe first rule asserts that after the leaves of the malicious behavior t there may be other behaviors, while the second asserts that in the nodes of the tree t\u2032 there may be\n13\nextra behaviors, for instance the edge to ExitProcess in Fig. 6. Then, if t is a malicious behavior tree, we would like to compute an HELTA that recognizes all the trees t\u2032 s.t. \u2203t\u2032\u2032 \u2208 \u2126(t) and t\u2032 = E[t\u2032\u2032] for an environment E \u2208 T (F , C, {x}).\nLet MalSCDT be a finite set of malicious trees, by definition each t \u2208MalSCDT is a term of T (F , C). We infer an HELTA H = (QH,F , C,A, \u2206H) recognizing trees containing malicious behaviors. Where QH = {qt | tC t\u2032 and t\u2032 \u2208MalSCDT} \u222a {qt | t \u2208 F} i.e. contains a state for each subtree of the trees to accept, plus a state for each possible symbol of the alphabet that will be reached when a subtree with such symbol as root is not recognized. The final states are defined as the states that correspond to recognizing a malicious tree A = {qt | t \u2208MalSCDT}. And \u2206H is defined by rules:"}, {"heading": "R1 For all f \u2208 F , f([C(QH)]\u2217)\u2192 qf \u2208 \u2206H", "text": "R2 For all t = f(c1(t1), . . . , cn(tn)) such that tC t\u2032 and t\u2032 \u2208MalSCDT, f( [ C(QH) ]\u2217 c1(qt1) [ C(QH) ]\u2217 . . . [ C(QH) ]\u2217 cn(qtn) [ C(QH) ]\u2217 ) \u2192 qf(c1(t1),...,cn(tn)) \u2208 \u2206 H\nR3 For all final state qt \u2208 A and all f \u2208 F , f( [ C(QH) ]\u2217 , qt, [ C(QH) ]\u2217 )\u2192 qt \u2208 \u2206H\nIntuitively, for f \u2208 F , states qf recognize all the terms whose roots are f . This is ensured by R1. In the rules [C(QH)]\u2217 allows to recognize terms t in (1) and cji (t j i ) in (2). For a subtree ti of a malicious behavior t in every MalSCDT, qti recognizes \u2126(qti). This is ensured by rules R2, which guarantees that a malicious tree containing extra behaviors is recognized. R3 guarantees that a tree containing a malicious behavior as subtree is recognized, i.e. R3 ensures that if t is a malicious behavior and E \u2208 T (F , C, {x}) is an environment, then qt recognizes E[t\u2032] for every t\u2032 in \u2126(t).\nIn the following we assert that if a tree t\u2032 contains a subtree t\u2032\u2032 that contains a malicious behavior t, then the inferred automaton will recognize it (even if there are extra behaviors). Proof should follow by induction.\nTheorem 2. Given a term t \u2208MalSCDT, and t\u2032 \u2208 T (F , C). If there \u2203t\u2032\u2032 \u2208 \u2126(t) and an environment E \u2208 T (F , C, {x}) and t\u2032 = E[t\u2032\u2032], then t\u2032 \u2217\u2212\u2192H qt."}, {"heading": "5.3 Malware detection", "text": "The detection phase works as follows. Given a program P to analyze we build a PDS model P using the approach described in Section 2, then we extract the set of behaviors TS contained in P using the approach in Section 4. Then we use the automaton H to search if any of the trees in TS can be matched by the automaton. If that is the case the program P is deemed malware.\nExample. Suppose the tree in Fig. 6 was extracted and the tree in Fig. 2 is the only malicious behavior in MalSCDT, which in turn is defined using C = {1, 2 1} and F = {0,CopyFile,ExitProcess,GetModuleFileName}. We define an automaton H where the set of states is QH = {q0, qExitProcess, qCopyFile, qGetModuleFileName(1(0),2 1(CopyFile))}, the accepting set is A = {qGetModuleFileName(1(0),2 1(CopyFile))}, and \u2206H contains rules processing the leaves: 0([C(QH)]\u2217) \u2212\u2192H q0, ExitProcess([C(QH)]\u2217) \u2212\u2192H qExitProcess, and CopyFile([C(QH)]\u2217) \u2212\u2192H qCopyFile. And a rule GetModuleFileName([C(QH)]\u2217, 1(q0), [C(QH)]\u2217, 2 1(qCopyFile), [C(QH)]\u2217) \u2212\u2192H qGetModuleFileName(1(0),2 1(CopyFile)) processing the whole malicious behavior of Fig. 2.\n14"}, {"heading": "6 Experiments", "text": "To evaluate our approach, we implemented a tool prototype that was tested on a dataset of real malware and benign programs. The input dataset of malware contains 1176 malware instances (Virus, Backdoors, Trojans, Worms,. . . ) collected from virus repositories as VX Heavens and a disjoint dataset of 250 benign files collected from a Windows XP fresh operating system installation. We arbitrarily split the malware dataset into a training and test group. The train dataset was used to infer the malicious trees that were used in the detection of the samples of the test group. We were able to detect 983 malware files using the malicious trees inferred from 193 malware files, and show that benign programs are benign, thus a 0% false positive rate."}, {"heading": "6.1 Inferring malicious behaviors", "text": "To infer malicious behaviors, we transformed each of the 193 malware binary files into a PDS model using the approach described in Section 2. To implement the oracle O, we use the PoMMaDe tool [25] that uses Jakstab [19] and IDA Pro [15]. Jakstab performs static analysis of the binary program. However, it does not allow to extract API functions information, so IDA Pro is used to obtain such information, thus obtaining %ar and %\u03bb. The %\u03c4 function was obtained by querying the available information in the MSDN website.\nWe apply Algorithm 1 to the PDS models to extract SCDTs for each of the malware instances. The current results were obtained with an h value of 2. In practice, to avoid the overapproximation of malicious trees, in the generation of SCDTs for the detection phase we consider the condition in line 6 of Algorithm 2, wo[n] = wd[m] true only when we know the value outputted by the oracle is precise.\nTo compute the MalSCDT we encode the extracted SCDT as graphs and try to calculate the most frequent subgraphs. We use the gSpan [30] tool for that, it computes frequent subgraph structures using a depth-first tree search over a canonical labeling of graph edges relying on the linear ordering property of the labeling to prune the search space. The tool has been applied in various domains as active chemical compound structure mining and its performance is competitive among other tools [29]. The tool supports only undirected graphs, therefore a mismatch\nwith the trees (that can be seen as rooted, acyclic direct graphs) used in this work. The mismatch is overcome via a direction tag in the graph labels.\nFor the 193 files extracted SCDTs we have run the gSpan tool with support 0.6%. This is a tunable value for which we chose the one that allows better detection results. With this value we obtained 1026 subtrees (MalSCDTs), and best detection results. From the inferred malicious trees output from gSpan, we build a tree automaton recognizing such trees.\nThe training dataset contains 12 families of malware summarized in Table 1. In average, our tool extracts 7 SCDTs in 30 seconds for each malware file. To store the 1026 discovered MalSCDTs the automaton file used 24Kb of memory.\n15"}, {"heading": "6.2 Detecting malware", "text": "Malware detection is reduced to generating SCDTs and checking whether they are recognized by the inferred automaton. Thus, to perform detection on an input binary file, we model it as PDS using the approach described in Section 2 and extract SCDTs using the approach detailed in Section 4.2. If any subtree of the extracted tree is recognized by the automaton recognizing the malicious behaviors, we decide the binary sample is malware. We implemented such procedure in our tool and were able to detect 983 malware samples from 330 different families.\nIn Table 2 we show the range of malware families and number of samples that our tool detects as malware. In average, our tool extracts 64 SCDTs in 2.15 seconds for each file (this value may be largely improved given that runtime efficiency was not a main goal of the prototype design). The discrepancy in the number of trees generated (compared to the training set) is justified by an implementation choice regarding the oracle approximation of the set of values pushed to the stack. In the generation of SCDTs for the detection phase we consider the condition in line 6 of Algorithm 2, wo[n] = wd[m] true even if the values are approximated. Such cases were discarded in the generation of SCDTs in the inference step where it holds only when the oracle outputs precise values. The automaton tree recognition execution time is negligible (< 0.08 secs) in all cases. To check the robustness of the detector, we applied it to a set of 250 benign programs. Our tool was able to classify such programs as benign, obtaining a 0% false positive rate. In 88% of the cases the tool extracts SCDTs and at least in 44% of the files there is a call to a function involved in malicious behavior (e.g. GetModuleFileName, ShellExecute,. . . ), but no tree was recognized as malicious. This value is in line with the values detailed in [10,14] and better than the 5% reported in [2]."}, {"heading": "7 Related work", "text": "Malicious behaviors have been defined in different ways. The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality. Our work is close to the approaches using model checking and temporal logic formulas as malicious behavior specification [24,25]. In such works specifications have to be designed by hand while we are able to learn them automatically. Some of the trees we infer describe malicious behaviors encoded in such formulas.\nRegarding semantic signature inference there are the works [10,14] where the extraction of behaviors is based on dynamic analysis of executables. From the execution traces collected, data flow dependencies among system calls are recovered by comparing parameters and type information. The outcome are dependence graphs where the nodes are labeled by system function names and the edges capture the dependencies between the system calls. Another dynamic analysis based approach is the one of [2] where trees, alike ours, express the same kind of data flows between nodes representing system calls. Both approaches are limited by the drawbacks of dynamic analysis. For instance, time limitations, limited system call tracing or an overhead up to 90\u00d7\n17\nslower during execution [23]. Plus, from the dataset made publicly available in [2], we notice the signatures involve only functions from the Native API library. Our approach has the advantage of being API independent, thus the level of analysis may be tuned, plus Win32 API function based signatures should be shorter as each high level function should be translated into a set of calls to the Native API functions.\nIn [7] the authors propose to learn behaviors of binary files by extracting program control-flow graphs using dynamic analysis. Such graphs contain assembly instructions that correspond to control flow information e.g. jmp, but that introduces more possibilities to circumvent such signatures by rewriting the code. From the graphs, trees are computed and the union of all such trees is used to infer an automaton that is used in detection. Our inference does not output all the trees, only the most frequent, improving the learning process and generalizing from the training dataset.\nAn alternative to semantic signatures are works based on machine learning approaches as [28], which shows that by mining \u201cn\u2212grams\u201d (a sequence of n bits), it is possible to distinguish malware from benign program. In our approach, the distinguishing features (malicious behaviors) can be seen as traces of program execution, thus having a meaning that can be more easily understood."}, {"heading": "8 Conclusion", "text": "In this work, we have shown how to combine static reachability analysis techniques to infer malware semantic signatures in the form of malicious trees, which describe the data flows among system calls. Our experiments show that the approach can be used to automatically infer specifications of malicious behaviors and detect several malware samples from an a priori given smaller set of malware. We were able to detect 983 malware files using the malicious trees inferred from 193 malware files, and applied the detector to 250 benign files obtaining a 0% false positive rate.\nAs future work we envisage the improvement of the binary modeling techniques, for example enriching the function parameter type system to allow better approximations. The usage of more advanced mining techniques, e.g. structural leap mining used in [14], can be used to improve the learning approach. In another direction, given the relation between modal formulas and tree models a comparison between our approach and the approach in [24] concerning expressiveness and complexity is envisaged. Finally, a complexity study with respect to the depth of the trees extraction (parameter h in Algorithm 1) and size of the HELTA would be another alternative direction.\nSumming up, the reachability analysis of PDS models of executables can play a major role in the malware specification inference domain. The ability to precisely analyze stack behavior enables the extraction of executables system call data flows and overcomes typical obfuscated calls to such routines."}], "references": [{"title": "An abstract theory of computer viruses", "author": ["L.M. Adleman"], "venue": "In Proceedings of the 8th Annual Int. Cryptology Conference on Advances in Cryptology,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1988}, {"title": "Malware analysis with tree automata inference", "author": ["D. Babic", "D. Reynaud", "D. Song"], "venue": "In CAV,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Static analysis of binary code to isolate malicious behaviors", "author": ["J. Bergeron", "M. Debbabi", "M.M. Erhioui", "B. Ktari"], "venue": "In WETICE,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Toward an Abstract Computer Virology", "author": ["G. Bonfante", "M. Kaczmarek", "J.-Y. Marion"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "On Abstract Computer Virology from a Recursion Theoretic Perspective", "author": ["G. Bonfante", "M. Kaczmarek", "J.-Y. Marion"], "venue": "Journal in Computer Virology,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2006}, {"title": "A Classification of Viruses Through Recursion Theorems", "author": ["G. Bonfante", "M. Kaczmarek", "J.-Y. Marion"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Architecture of a morphological malware detector", "author": ["G. Bonfante", "M. Kaczmarek", "J.-Y. Marion"], "venue": "Journal in Computer Virology,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Reachability analysis of pushdown automata: Application to model-checking", "author": ["A. Bouajjani", "J. Esparza", "O. Maler"], "venue": "In CONCUR,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "Static analysis of executables to detect malicious patterns", "author": ["M. Christodorescu", "S. Jha"], "venue": "In Proceedings of the 12th conf. on USENIX Security Symposium,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Mining specifications of malicious behavior", "author": ["M. Christodorescu", "S. Jha", "C. Kruegel"], "venue": "In Proceedings of the 1st India software engineering conference,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Semantics-aware malware detection", "author": ["M. Christodorescu", "S. Jha", "S.A. Seshia", "D.X. Song", "R.E. Bryant"], "venue": "In IEEE Symposium on Security and Privacy,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Efficient algorithms for model checking pushdown systems", "author": ["J. Esparza", "D. Hansel", "P. Rossmanith", "S. Schwoon"], "venue": "In CAV,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Symantec internet security threat report trends", "author": ["M. Fossi", "G. Egan", "K. Haley", "E. Johnson", "T. Mack", "T. Adams", "J. Blackbird", "M. Low", "D. Mazurek", "D. McKinney"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Synthesizing near-optimal malware specifications from suspicious behaviors", "author": ["M. Fredrikson", "S. Jha", "M. Christodorescu", "R. Sailer", "X. Yan"], "venue": "In IEEE S. Security and Privacy,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Using verification technology to specify and detect malware", "author": ["A. Holzer", "J. Kinder", "H. Veith"], "venue": "In EUROCAST,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "Detecting malicious code by model checking", "author": ["J. Kinder", "S. Katzenbeisser", "C. Schallhart", "H. Veith"], "venue": "In DIMVA,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Proactive Detection of Computer Worms Using Model Checking", "author": ["J. Kinder", "S. Katzenbeisser", "C. Schallhart", "H. Veith"], "venue": "IEEE Trans. on Dependable and Secure Computing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Jakstab: A static analysis platform for binaries", "author": ["J. Kinder", "H. Veith"], "venue": "In CAV,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "A general definition of malware", "author": ["S. Kramer", "J.C. Bradfield"], "venue": "Journal in computer virology,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Static verification of worm and virus behavior in binary executables using model checking", "author": ["P. Singh", "A. Lakhotia"], "venue": "In Information Assurance Workshop,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Dynamic program analysis of Microsoft Windows applications", "author": ["A. Skaletsky", "T. Devor", "N. Chachmon", "R.S. Cohn", "K.M. Hazelwood", "V. Vladimirov", "M. Bach"], "venue": "In ISPASS,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Efficient malware detection using model-checking", "author": ["F. Song", "T. Touili"], "venue": "In FM,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Pushdown model checking for malware detection", "author": ["F. Song", "T. Touili"], "venue": "In TACAS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "LTL model-checking for malware detection", "author": ["F. Song", "T. Touili"], "venue": "In TACAS", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "The Art of Computer Virus", "author": ["P. Szor"], "venue": "Research and Defense. Addison-Wesley Pro.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Mal-id: Automatic malware detection using common segment analysis and meta-features", "author": ["G. Tahan", "L. Rokach", "Y. Shahar"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "A quantitative comparison of the subgraph miners MoFa, gSpan, FFSM, and Gaston", "author": ["M. W\u00f6rlein", "T. Meinl", "I. Fischer", "M. Philippsen"], "venue": "Knowledge Discovery in Databases,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2005}, {"title": "gSpan: Graph-based substructure pattern mining", "author": ["X. Yan", "J. Han"], "venue": "In ICDM,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}], "referenceMentions": [{"referenceID": 12, "context": "For instance, in 2010 the number of newly unique variants of malware was 286 million [13] and recent numbers confirm the trend [21].", "startOffset": 85, "endOffset": 89}, {"referenceID": 13, "context": "Research confirms the unsuitability of current malware detectors [14,24].", "startOffset": 65, "endOffset": 72}, {"referenceID": 21, "context": "Research confirms the unsuitability of current malware detectors [14,24].", "startOffset": 65, "endOffset": 72}, {"referenceID": 24, "context": "The basic detection technique is signature matching, it consists in the inspection of the binary code and search for patterns in the form of binary sequences [27].", "startOffset": 158, "endOffset": 162}, {"referenceID": 13, "context": "As it is possible to automatically generate an unbounded number of variants, such databases would have to grow arbitrarily, not to mention it takes about two months to manually update them [14].", "startOffset": 189, "endOffset": 193}, {"referenceID": 2, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 8, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 10, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 14, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 15, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 16, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 23, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 21, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 22, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 19, "context": "Such is the outcome of the recent use of model-checking techniques to perform virus detection [3,9,11,16,17,18,26,24,25,22].", "startOffset": 94, "endOffset": 123}, {"referenceID": 24, "context": "The prime example of a malicious behavior is self-replication [27].", "startOffset": 62, "endOffset": 66}, {"referenceID": 1, "context": "Recent work [2,10,14] shows that we can teach computers to learn malicious behavior specifications.", "startOffset": 12, "endOffset": 21}, {"referenceID": 9, "context": "Recent work [2,10,14] shows that we can teach computers to learn malicious behavior specifications.", "startOffset": 12, "endOffset": 21}, {"referenceID": 13, "context": "Recent work [2,10,14] shows that we can teach computers to learn malicious behavior specifications.", "startOffset": 12, "endOffset": 21}, {"referenceID": 7, "context": "From the reachability analysis of each PDS, we obtain a multi-automaton (MA), a finite automaton encoding the possibly infinite reachable configurations (states and stack contents)[8,12].", "startOffset": 180, "endOffset": 186}, {"referenceID": 11, "context": "From the reachability analysis of each PDS, we obtain a multi-automaton (MA), a finite automaton encoding the possibly infinite reachable configurations (states and stack contents)[8,12].", "startOffset": 180, "endOffset": 186}, {"referenceID": 1, "context": "With such tool we were able to infer some signatures not inferred using previous approaches [2,10,14] because our signatures track calls to functions of the Win32 API instead of calls to the Native API.", "startOffset": 92, "endOffset": 101}, {"referenceID": 9, "context": "With such tool we were able to infer some signatures not inferred using previous approaches [2,10,14] because our signatures track calls to functions of the Win32 API instead of calls to the Native API.", "startOffset": 92, "endOffset": 101}, {"referenceID": 13, "context": "With such tool we were able to infer some signatures not inferred using previous approaches [2,10,14] because our signatures track calls to functions of the Win32 API instead of calls to the Native API.", "startOffset": 92, "endOffset": 101}, {"referenceID": 9, "context": "This number of detected malware is larger than the 16 files reported in [10] and in line with the 912 files detected in [14].", "startOffset": 72, "endOffset": 76}, {"referenceID": 13, "context": "This number of detected malware is larger than the 16 files reported in [10] and in line with the 912 files detected in [14].", "startOffset": 120, "endOffset": 124}, {"referenceID": 1, "context": "Our false positive detection rate is better (5% reported in [2]).", "startOffset": 60, "endOffset": 63}, {"referenceID": 7, "context": "[8,12] For a pushdown system P = (P, \u0393,\u2206) and MA A, there exist MAs Apost\u2217 and Apre\u2217 recognizing post\u2217(Conf(A)) and pre\u2217(Conf(A)) respectively.", "startOffset": 0, "endOffset": 6}, {"referenceID": 11, "context": "[8,12] For a pushdown system P = (P, \u0393,\u2206) and MA A, there exist MAs Apost\u2217 and Apre\u2217 recognizing post\u2217(Conf(A)) and pre\u2217(Conf(A)) respectively.", "startOffset": 0, "endOffset": 6}, {"referenceID": 21, "context": "In addition to the approach of [24], let API be the set of all Application Programming Interface function names available in the program.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "To compute the sets of trees TSi we proceed as follows: For each program Pi modeled as a PDS Pi we compute the finite automaton encoding the set of reachable configurations from the initial state using the reachability analysis algorithm from [12].", "startOffset": 243, "endOffset": 247}, {"referenceID": 27, "context": "To calculate the common subtrees we use the algorithm [30] computing frequent subgraph, to compute frequent subtrees.", "startOffset": 54, "endOffset": 58}, {"referenceID": 11, "context": "To compute the data flows for a malware pushdown system model P = (P, \u0393,\u2206), we first calculate the reachability of P using the algorithms presented in [12].", "startOffset": 151, "endOffset": 155}, {"referenceID": 27, "context": "To compute frequent subtrees we specialize the frequent subgraph algorithm presented in [30] to the case of trees.", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "The algorithm receives a set of trees and a support value k \u2208 [0, 1] and outputs all the subtrees with support at least k.", "startOffset": 62, "endOffset": 68}, {"referenceID": 22, "context": "To implement the oracle O, we use the PoMMaDe tool [25] that uses Jakstab [19] and IDA Pro [15].", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "To implement the oracle O, we use the PoMMaDe tool [25] that uses Jakstab [19] and IDA Pro [15].", "startOffset": 74, "endOffset": 78}, {"referenceID": 27, "context": "We use the gSpan [30] tool for that, it computes frequent subgraph structures using a depth-first tree search over a canonical labeling of graph edges relying on the linear ordering property of the labeling to prune the search space.", "startOffset": 17, "endOffset": 21}, {"referenceID": 26, "context": "The tool has been applied in various domains as active chemical compound structure mining and its performance is competitive among other tools [29].", "startOffset": 143, "endOffset": 147}, {"referenceID": 9, "context": "This value is in line with the values detailed in [10,14] and better than the 5% reported in [2].", "startOffset": 50, "endOffset": 57}, {"referenceID": 13, "context": "This value is in line with the values detailed in [10,14] and better than the 5% reported in [2].", "startOffset": 50, "endOffset": 57}, {"referenceID": 1, "context": "This value is in line with the values detailed in [10,14] and better than the 5% reported in [2].", "startOffset": 93, "endOffset": 96}, {"referenceID": 0, "context": "The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality.", "startOffset": 53, "endOffset": 56}, {"referenceID": 3, "context": "The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality.", "startOffset": 94, "endOffset": 101}, {"referenceID": 4, "context": "The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality.", "startOffset": 94, "endOffset": 101}, {"referenceID": 5, "context": "The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality.", "startOffset": 94, "endOffset": 101}, {"referenceID": 18, "context": "The foundational approaches via computable functions [1], based in Kleene\u2019s recursion theorem [4,5,6], or the neat definition using MALog [20] capture the essence of such behaviors, but are too abstract to be used in practice or require the full specification of software functionality.", "startOffset": 138, "endOffset": 142}, {"referenceID": 21, "context": "Our work is close to the approaches using model checking and temporal logic formulas as malicious behavior specification [24,25].", "startOffset": 121, "endOffset": 128}, {"referenceID": 22, "context": "Our work is close to the approaches using model checking and temporal logic formulas as malicious behavior specification [24,25].", "startOffset": 121, "endOffset": 128}, {"referenceID": 9, "context": "Regarding semantic signature inference there are the works [10,14] where the extraction of behaviors is based on dynamic analysis of executables.", "startOffset": 59, "endOffset": 66}, {"referenceID": 13, "context": "Regarding semantic signature inference there are the works [10,14] where the extraction of behaviors is based on dynamic analysis of executables.", "startOffset": 59, "endOffset": 66}, {"referenceID": 1, "context": "Another dynamic analysis based approach is the one of [2] where trees, alike ours, express the same kind of data flows between nodes representing system calls.", "startOffset": 54, "endOffset": 57}, {"referenceID": 20, "context": "slower during execution [23].", "startOffset": 24, "endOffset": 28}, {"referenceID": 1, "context": "Plus, from the dataset made publicly available in [2], we notice the signatures involve only functions from the Native API library.", "startOffset": 50, "endOffset": 53}, {"referenceID": 6, "context": "In [7] the authors propose to learn behaviors of binary files by extracting program control-flow graphs using dynamic analysis.", "startOffset": 3, "endOffset": 6}, {"referenceID": 25, "context": "An alternative to semantic signatures are works based on machine learning approaches as [28], which shows that by mining \u201cn\u2212grams\u201d (a sequence of n bits), it is possible to distinguish malware from benign program.", "startOffset": 88, "endOffset": 92}, {"referenceID": 13, "context": "structural leap mining used in [14], can be used to improve the learning approach.", "startOffset": 31, "endOffset": 35}, {"referenceID": 21, "context": "In another direction, given the relation between modal formulas and tree models a comparison between our approach and the approach in [24] concerning expressiveness and complexity is envisaged.", "startOffset": 134, "endOffset": 138}], "year": 2013, "abstractText": "The number of malicious software (malware) is growing out of control. Syntactic signature based detection cannot cope with such growth and manual construction of malware signature databases needs to be replaced by computer learning based approaches. Currently, a single modern signature capturing the semantics of a malicious behavior can be used to replace an arbitrarily large number of old-fashioned syntactical signatures. However teaching computers to learn such behaviors is a challenge. Existing work relies on dynamic analysis to extract malicious behaviors, but such technique does not guarantee the coverage of all behaviors. To sidestep this limitation we show how to learn malware signatures using static reachability analysis. The idea is to model binary programs using pushdown systems (that can be used to model the stack operations occurring during the binary code execution), use reachability analysis to extract behaviors in the form of trees, and use subtrees that are common among the trees extracted from a training set of malware files as signatures. To detect malware we propose to use a tree automaton to compactly store malicious behavior trees and check if any of the subtrees extracted from the file under analysis is malicious. Experimental data shows that our approach can be used to learn signatures from a training set of malware files and use them to detect a test set of malware that is 5 times the size of the training set.", "creator": "LaTeX with hyperref package"}}}