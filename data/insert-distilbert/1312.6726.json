{"id": "1312.6726", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2013", "title": "Bounded Rational Decision-Making in Changing Environments", "abstract": "a perfectly rational decision - forming maker chooses the best action with the highest utility gain from a set of possible actions. the optimality principles that describe such decision processes don't take into account the computational budget costs of finding the optimal action. bounded rational decision - making addresses this problem by nearly specifically trading itself off information - processing costs and expected surplus utility. interestingly, a similar trade - off between energy and entropy arises when describing changes in thermodynamic systems. this similarity has been recently used to describe bounded rational agents. crucially, this framework assumes essentially that the environment does not therefore change while the decision - based maker is computing towards the optimal policy. when this requirement is simply not fulfilled, such the practical decision - maker will suffer inefficiencies in utility, that arise because the current policy is optimal for solving an environment in studying the past. here we borrow concepts resulting from recent non - classical equilibrium statistical thermodynamics to quantify these inefficiencies and illustrate with simulations its precise relationship with computational resources.", "histories": [["v1", "Tue, 24 Dec 2013 00:22:44 GMT  (123kb,D)", "http://arxiv.org/abs/1312.6726v1", "9 pages, 2 figures, NIPS 2013 Workshop on Planning with Information Constraints"]], "COMMENTS": "9 pages, 2 figures, NIPS 2013 Workshop on Planning with Information Constraints", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jordi grau-moya", "daniel a braun"], "accepted": false, "id": "1312.6726"}, "pdf": {"name": "1312.6726.pdf", "metadata": {"source": "CRF", "title": "Bounded Rational Decision-Making in Changing Environments", "authors": ["Jordi Grau-Moya", "Daniel A. Braun"], "emails": ["jordi.grau@tuebingen.mpg.de", "daniel.braun@tuebinen.mpg.de"], "sections": [{"heading": "1 Introduction", "text": "Classical decision-making theories assume that a perfect rational decision-maker should always pick the option with the best expected utility, thus ignoring the computational costs that the search for the best option entails. Experiments in decision-making under uncertainty have been shown to violate these classical theories [1]. As a consequence many alternative explanations have been proposed to explain, at first sight, this irrational behaviour [2, 3, 4, 5]. A recent theory of bounded rationality for decision-making has been proposed that takes into account the computational cost of the search of the optimal policy. Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].\nThe theory of bounded rationality shares the same mathematical framework used in statistical physics to describe changes in thermodynamic systems [3, 11, 12]. In the same way a thermodynamic system trades-off its internal energy with an entropic cost\u2014that is higher for high temperature\u2014a bounded rational agent trades-off the expected utility of a computed policy with a information-processing cost\u2014that is higher for low rationality. Furthermore, bounded rationality takes into account model uncertainty, meaning that the model used to describe the world or policy is wrong or partially incorrect, thus allowing deviations from this model [13, 14].\nHowever, the theory assumes that the utility function shown to the agent remains unchanged for the time that the agent spends computing until he samples his optimal action. An interesting problem arises when the agent is facing changing environments in such a way that the he cannot compute the optimal policy instantaneously but he still can use the previously computed policy to make a decision. In the present paper we look at the inefficiencies in utility gains due to non-optimal policy\nar X\niv :1\n31 2.\n67 26\nv1 [\ncs .A\nI] 2\n4 D\nec 2\nchanges. In particular, we consider the special case where the used policy lags behind the optimal policy. This could be useful to explain human decision-making in fast changing environments with time-scales close to reaction times but also it serves as a first step towards having a measure of inefficiency of mechanistic systems that can use computational resources and they have to allocate them optimally."}, {"heading": "2 Decision-making with information-processing costs", "text": "The deliberation process of a bounded rational decision maker consists in the transformation of a prior probabilistic model or policy p0(x) of an action x \u2208 X into a posterior policy p1(x) taking into account the utility function \u2206U(x) and the transformation cost from the prior distribution to the posterior distribution. This trade-off is characterized by the free energy difference (FED)1 [3].\n\u2206F [p] = \u2211 x\np(x)\u2206U(x)\ufe38 \ufe37\ufe37 \ufe38 Expected utility under p\n\u2212 1 \u03b2 \u2211 x p(x) log p(x)\np0(x)\ufe38 \ufe37\ufe37 \ufe38 Transformation cost\n. (1)\nThe first term is the expected utility under policy p and the second term is a transformation cost measured by the Kullback-Leibler divergence (DKL(p||p0) = \u2211 x p(x) log p(x) p0(x)\n) between an arbitrary distribution p and the equilibrium distribution p0. The resource parameter \u03b2 sets the relative importance between the transformation cost and the maximization of \u2206U(x). The optimal policy p1(x) for \u03b2 > 0 can be found by the maximization of the FED that is p1(x) = argmaxp \u2206F [p]. However, for \u03b2 < 0, 1\u03b2DKL(p||p0) is concave and thus the optimal policy is found by minimizing the FED that is p1(x) = argminp \u2206F [p]. For \u03b2 = 0, p1(x) = p0(x). The interpretation of positive \u03b2 is that the agent finds himself in a collaborative or exploitable environment, whereas for negative \u03b2 he finds himself in an adversarial environment with presumed rationality \u03b2. The solution for positive or negative \u03b2 is the same:\np1(x) = 1\nZ p0(x)e\n\u03b2\u2206U(x) (2)\nwith partition function Z = \u2211 x p0(x)e \u03b2\u2206U(x).\nReplacing the non-optimal policy p for the optimal policy p1 in Equation 1 the free energy difference becomes\n\u2206F = \u2211 x p1(x)\u2206U(x)\u2212 1 \u03b2 \u2211 x p1(x) log p1(x) p0(x) = 1 \u03b2 logZ (3)\nIt will be useful in later parts of the paper to re-express the optimal posterior distribution of Equation 2 in the following terms:\np1(x) = p0(x)e \u03b2\u2206U(x)\u2212\u03b2\u2206F (4)\nand\n\u2206U(x) = 1\n\u03b2 log\np1(x) p0(x) + \u2206F (5)\nIn summary, the process of decision-making proceeds as follows. At the beginning the agent finds himself in an environment where he is optimal given his computational constraints with the policy p0. Then he experiences a change in the environment, and thus he observes a change in the utility\n1 Our free energy difference corresponds, in statistical physics, to the negative free energy difference because of the use of energies (costs) instead of utilities.\nfunction measured by \u2206U(x). Given this change in the environment the previous policy p0 is not optimal anymore and then he needs to compute the new optimal policy p1 given the resources \u03b2. In order to do so, the process of computation requires the maximization of the free energy of Equation 1. An assumption of this process is that if the environment changes instantaneously, the change in utility \u2206U(x) has to remain the same during the whole computation and it can only change again when the agent has sampled an action from the already computed optimal policy.\nImportantly, if this assumption is not fulfilled the agent is not applying the optimal policy. In the next section we are going to give the thermodynamic interpretation of the above framework for decisionmaking, and moreover we are going to go further by looking at non-equilibrium thermodynamics that will serve as a motivation for the description of the aforementioned inefficiencies in decisionmaking with information-processing constraints."}, {"heading": "3 Non-equilibrium thermodynamics", "text": "Time evolution of a thermodynamic system can be described by a trajectory in phase space that specifies the position and velocity of all particles at any given time. When some external parameters \u03bb of such a system vary with time (e.g. a change in a magnetic potential or position of the wall of a piston) work is being applied to the system and it will evolve along a path from an initial state A to a final state B. When the change in the parameters is done infinitely slowly the ensemble of microstates at any specified time can be described by an equilibrium distribution and the work performed on such a system is equivalent to the free energy difference W = \u2206F = FB \u2212 FA. However, when the parameters are applied in finite time, the work performed on the system will depend on the initial microscopic conditions and will be on average higher than the free energy difference [15]\nW \u2265 \u2206F. (6)\nIn this case, when changing \u03bb the ensemble of microstates cannot be described by an equilibrium distribution and then it is said that the system is in non-equilibrium.\nWe can define the equilibrium distribution when the external parameter is held fixed. Without loss of generality, if the parameter \u03bb \u2208 [0, 1] controls a switching process between an initial potential2 UA (\u03bb = 0) and the final potential UB (\u03bb = 1), the equilibrium distribution for any intermediate \u03bb can be described with the Boltzmann distribution\np\u03bb(x) = 1\nZ\u03bb e\u2212\u03b2U\u03bb(x) (7)\nwhere U\u03bb(x) = UA(x) + \u03bb(UB(x) \u2212 UA(x)). In statistical physics, it is well known that the Boltzmann distribution solves the variational problem of minimizing the free energy F = U \u2212 TS that is a trade-off between the internal energy of the system and an entropic cost times a temperature. More formally, for any given external parameter \u03bb the Boltzmann distribution satisfies:\np\u03bb(x) = argmin p F\u03bb[p] = argmin p \u2211 x p(x)U\u03bb(x) + 1 \u03b2 \u2211 x p(x) log p(x)\nwhere \u03b2 = 1/kT , k is the Boltzmann constant and T the temperature. Note that the free energy can also be expressed as F\u03bb = \u2212 1\u03b2 logZ\u03bb and thus it is only defined in equilibrium states, so for an arbitrary p, F\u03bb[p] is in fact a non-equilibrium free energy.\nImportantly, when the switching is produced in finite time, the system will find itself in a nonequilibrium state that cannot be described by Equation 7. Furthermore, the work applied to the system is going to be higher than the free energy difference. The average extra work applied to the system is\nWdiss = W \u2212\u2206F. 2A potential in physics can be thought as a negative utility function in decision-making\nWhen the switching process ends at \u03bb = 1 the system will start to equilibrate towards the equilibrium distribution pB under the potential UB . During this process the extra work Wdiss will be dissipated in form of heat to the environment at temperature T and the non-equilibrium free energy difference \u2206F [p] := FB [p] \u2212 F [pA] of the system will be minimized towards the equilibrium free energy difference \u2206F , assuming that the system was initially in equilibrium. The dissipated work, in other words, is a measure of the inefficiency of a process that drives the system from an equilibrium state A to another equilibrium state B.\nRecent advances in non-equilibrium thermodynamics have shown a remarkable fact, that is transforming the inequality of Equation 6 into an equality (called Jarzynski equality [16]):\ne\u2212\u03b2\u2206F = e\u2212\u03b2W (8)\nwhere the over-line denotes an average over all possible realizations of a process that drives the system from an equilibrium state A to, in general, a non-equilibrium state B, and W denotes the work spent in such a process. Specifically, the above equality says that, no matter how the driving process is implemented, we can specify equilibrium quantities from work fluctuations in the nonequilibrium process. Or in other words, this equality connects non-equilibrium thermodynamics with equilibrium thermodynamics. We will borrow the previous results to describe inefficiencies in the process of decision-making in the next section."}, {"heading": "4 Inefficiencies due to lag in the policy", "text": "In this section we are going to use the aforementioned non-equilibrium results from statistical physics to describe inefficiencies due to not using an optimal policy. We are going to consider two simple scenarios where the change in utility function \u2206U(x) is applied instantaneously or in N timesteps. In both cases, we assume that the agent takes one timestep to notice the change in utility function, then samples an action from the previous policy and finally computes the optimal policy instantaneously. Due to this lag in the optimal policy the amount of expected utility gained by the agent will not be the optimal one (where the optimal one is the free energy difference) thus having inefficiencies. We will quantify these inefficiencies similarly to the dissipated work in nonequilibrium thermodynamics."}, {"heading": "4.1 One-step scenario", "text": "In the one-step scenario the agent has to sample only one action. At the beginning of the process he is using an initial policy p0(x) that is optimal for the utility function U0(x) given his resources \u03b2. Then there is an external change switching the utility function from U0(x) to U1(x) such that it provokes a \u2206U(x) from the point of view of the agent. Importantly, at the moment of this increase in the utility function he is still using his previous policy p0. This process is described with the following table:\nTimestep t 0 1 Utility function U0(x) U1(x) Policy p0(x) p0(x)\nThe average in expected utility difference from t = 0 to t = 1 is\nUnet = \u2211 x p0(x)\u2206U(x)\nThis quantity is the average net utility that the agent gains using the non-optimal policy. The average dissipated or \u201cwasted\u201d utility because not using the optimal policy is the difference between the optimal increase in utility \u2206F and the net utility Unet:\nUdiss := \u2206F \u2212 Unet (9) = \u2206F \u2212 \u2211 x p0(x)\u2206U(x)\n= \u2206F \u2212 \u2211 x p0(x) [ 1 \u03b2 log p1(x) p0(x) + \u2206F ] (10)\n= 1\n\u03b2 \u2211 x p0(x) log p0(x) p1(x) . (11)\nEquation 10 is obtained by using Equation 5 and the step from 10 to 11 is done noticing that \u2206F is a constant under the expectation over p0 and cancels out.\nApart from the description of the inefficiencies derived above, the Jarzysnki-like equality for decision making can be recovered in the following way. From Equation 4 we can re-arrange the terms to have:\np1(x) p0(x) e\u03b2\u2206F = e\u03b2\u2206U(x)\nDoing an expectation over the initial conditions p0 yields\n\u2211 x p0(x) p1(x) p0(x) e\u03b2\u2206F = \u2211 x p0(x)e \u03b2\u2206U(x)\nwhere the left term is a constant under the expectation and the right term is actually the average over all possible realizations of the process, thus giving:\ne\u03b2\u2206F =e\u03b2\u2206U(x)\nThe interpretation of this result in decision-making is that the utility gains along the path of actions taken by an agent, gives us information about the optimal utility gains given his computational resources."}, {"heading": "4.2 N-step scenario", "text": "Consider now that the agent is exposed to the same increase in utility \u2206U(x), but in N timesteps. After every timestep the agent is able to notice the increase in the utility function \u2206U(x)N but he is still using the previous policy. Next, he computes the optimal policy for this increase in utility. The following table describes this process:\nTimestep 0 1 2 ... t ... N Utility function U0(x) U1(x) U2(x) ... Ut(x) ... UN (x) Policy p0(x) p0(x) p1(x) ... pt\u22121(x) ... pN\u22121(x)\nwhere now Ut(x) = U0(x) + tN\u2206U(x) for t \u2208 N : 0 \u2264 t \u2264 N and the optimal policy at timestep t builds on the previous policy thus yielding:\npt(x) = pt\u22121(x)e \u03b2 N \u2206U(x)\u2211\nx\u2032 pt\u22121(x \u2032)e \u03b2 N \u2206U(x\n\u2032) (12)\nfor t > 0. The dissipated utility at timestep t > 0 is\nUdiss(t) = 1\n\u03b2 \u2211 x pt\u22121(x) log pt\u22121(x) pt(x) (13)\nand the overall dissipated utility for the whole process is\nUNdiss = N\u2211 t=1 Udiss(t) = 1 \u03b2 N\u2211 t=1 \u2211 x pt\u22121(x) log pt\u22121(x) pt(x) (14)\nSimilar to Equation 9 we can define the net utility gain for the N-step scenario as follows:\nUNnet := \u2206F \u2212 UNdiss (15)\nNote that the average dissipation is lower when more time-steps are used for the change in the potential\nUNdiss \u2265 U N+1 diss\n.\nWe recover the one-step scenario for N = 1, corresponding to an instantaneous change in utility. Similar to a quasi-static change in a thermodynamic system, for N \u2192 \u221e, we get an infinitely slow change in utility, thus UNdiss \u2192 0 and then the net utility equals the free energy difference UNnet = \u2206F .\nJarzynski derivation\nIn a N-step scenario, similarly to Equation 5, we have that:\n\u2206F = 1\nN [\u2206U(x1) + \u2206U(x2)...+ \u2206U(xt) + ...+ \u2206U(xN )]\u2212\n\u2212 1 \u03b2 log p1(x1) p0(x1) \u2212 1 \u03b2 log p2(x2) p1(x2) ...\u2212 1 \u03b2 log pt(xt) pt\u22121(xt) ...\u2212 1 \u03b2 log pN (xN ) pN\u22121(xN )\n= 1\nN \u2211 t \u2206U(xt)\u2212 1 \u03b2 N\u2211 t=1 log pt(xt) pt\u22121(xt)\nwhere the sub-index denotes the timestep. With this relationship the exponential of the free energy difference is\nexp (\u03b2\u2206F ) = exp\n( \u03b2\nN N\u2211 t \u2206U(xt)\u2212 N\u2211 t=1 log pt(xt) pt\u22121(xt)\n)\n= exp\n( \u03b2\nN N\u2211 t \u2206U(xt) ) N\u220f t pt\u22121(xt) pt(xt)\nwhere \u220fN t pt\u22121(xt) is the probability of the \u201cpath\u201d of actions and 1 N \u2211N t \u2206U(xt) is the utility gain\nalong the path exactly as the Jarzynski formulation. So by doing the expectation over \u220f t pt(xt) we have:\nexp (\u03b2\u2206F ) = exp\n( \u03b2\nN N\u2211 t \u2206U(xt)\n)\nanalogous to the one-step scenario."}, {"heading": "5 Simulations", "text": "In the following simulations we are going to illustrate how the number of steps and the resources affect the dissipated utility. Consider the situation where the agent can choose between two possible\nactions x \u2208 {a, b} and he observes a \u2206U(x) = (\u22122, 5). Importantly, this change in the utility function is made in several timesteps, allowing him to recompute the optimal policy at the end of every timestep. In particular, for this simulation the total number of timesteps is set to N = 4. The initial policy of the agent is just p0(x) = (0.5, 0.5).\nIn this particular scenario, we show in Figure 1(A-C) the different values of the dissipated utility, free energy difference and the net utility with respect to the rationality parameter \u03b2. At the first timestep the agent is using the policy p0 that does not depend on \u03b2 so the net utility is the same for all \u03b2\u2014see Figure 1C. The increase in free energy is higher for higher \u03b2 in the different timesteps\u2014 see Figure 1B. In the limit case of \u03b2 \u2192 0, the agent has no resources to change his policy and then the only gain in utility is the net utility. The dissipated utility for the first timestep increases with increasing \u03b2 because it is a measure of inefficiency compared to the free energy difference. Notice that for this timestep, the dissipated utility is unavoidable because the agent just uses p0. However, in the next timesteps the agent can actually use his resources to compute the optimal policy\u2014with a lag of one timestep\u2014 and by doing so, reduce the dissipated utility. For high \u03b2 = 5, the dissipated utility is almost only present in the first timestep because the agent with such a high rationality is able to quickly adopt the best policy in the second timestep, and thus being already optimal for later timesteps. This happens because we imposed a linear grow in \u2206U(x) and thus best policy for the second timestep is also the best policy for later timesteps. In general situations, this will not happen and the agent could, in principle, have high inefficiencies (high dissipated utility) even though he may have high rationality \u03b2. In Figure 1D we show the sum of utilities for all timesteps and we see that the total net utility is less than the free energy difference plateaus for high \u03b2 only due to the inefficiencies in the first timestep.\nIn Figure 2 we show the sum over all timesteps of the net utility, the dissipated utility and the free energy difference for the whole process exactly as in Figure 1D but now also varying the total number of timesteps N . Note that the free energy difference is independent of N . We observe that for higher N the more similar the surface of net utility is to the free energy difference. In the particular, in an infinitely slow change of utility, or in other words when N \u2192 \u221e, the net utility would be exactly the free energy difference. An instant switching of \u2206U(x) would correspond to the case of N = 1, where the agent is the most inefficient."}, {"heading": "6 Conclusions", "text": "We described a framework of decision-making under information-processing costs and looked at the analogies it has with the evolution of thermodynamic systems into equilibrium. We borrowed concepts from non-equilibrium thermodynamics and applied them to describe inefficiencies in decisionmaking due the use of non-optimal policies when the decision-maker cannot adapt perfectly to a fast changing environment. We showed an equivalent interpretation of the Jarzynski equality in thermodynamics for decision-making that allows relating fluctuations in the possibly suboptimal achieved net utility of an agent to the optimally achievable utility given by the free energy difference. The main contribution of this work is to quantify the inefficiencies that arise in bounded rational decisionmakers when the environment changes faster than the agent can respond. These inefficiencies could be irrelevant in slow-changing environments but of a greater importance in fast-changing environments as because the computed policies could differ in great deal with the optimal policies."}, {"heading": "Acknowledgments", "text": "This study was supported by the DFG, Emmy Noether grant BR4164/1-1."}], "references": [{"title": "Risk, ambiguity, and the savage axioms", "author": ["Daniel Ellsberg"], "venue": "The Quarterly journal of economics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1961}, {"title": "Decision making with imperfect decision makers, volume 28", "author": ["Tatiana Valentine Guy", "Miroslav K\u00e1rn\u1ef3", "David H Wolpert"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Thermodynamics as a theory of decision-making with informationprocessing costs", "author": ["Pedro A. Ortega", "Daniel A. Braun"], "venue": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Information, utility and bounded rationality", "author": ["Pedro A. Ortega", "Daniel A. Braun"], "venue": "Artificial General Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Trading value and information in mdps. In Decision Making with Imperfect Decision Makers", "author": ["Jonathan Rubin", "Ohad Shamir", "Naftali Tishby"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "An introduction to stochastic control theory, path integrals and reinforcement learning", "author": ["Hilbert J. Kappen"], "venue": "AIP Conference Proceedings,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Path integrals and symmetry breaking for optimal control theory", "author": ["H J Kappen"], "venue": "Journal of Statistical Mechanics: Theory and Experiment,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Efficient computation of optimal actions", "author": ["Emanuel Todorov"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Alt\u00fcn. Relative entropy policy search", "author": ["Jan Peters", "Katharina M\u00fclling", "Yasemin"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Path integral control and bounded rationality", "author": ["D.A. Braun", "P.A. Ortega", "E. Theodorou", "S. Schaal"], "venue": "In Adaptive Dynamic Programming And Reinforcement Learning (ADPRL),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Information theory-the bridge connecting bounded rational game theory and statistical physics", "author": ["David H Wolpert"], "venue": "In Complex Engineered Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Thermodynamics of prediction", "author": ["Susanne Still", "David A Sivak", "Anthony J Bell", "Gavin E Crooks"], "venue": "Physical Review Letters,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "The effect of model uncertainty on cooperation in sensorimotor interactions", "author": ["J. Grau-Moya", "E. Hez", "G. Pezzulo", "D.A. Braun"], "venue": "Journal of The Royal Society Interface,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Risk-sensitivity in bayesian sensorimotor integration", "author": ["Jordi Grau-Moya", "Pedro A. Ortega", "Daniel A. Braun"], "venue": "PLoS Comput Biol, 8(9):e1002698,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Equalities and inequalities: irreversibility and the second law of thermodynamics at the nanoscale", "author": ["Christopher Jarzynski"], "venue": "In Time,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Nonequilibrium equality for free energy differences", "author": ["C. Jarzynski"], "venue": "Phys. Rev. Lett., 78:2690\u20132693,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}], "referenceMentions": [{"referenceID": 0, "context": "Experiments in decision-making under uncertainty have been shown to violate these classical theories [1].", "startOffset": 101, "endOffset": 104}, {"referenceID": 1, "context": "As a consequence many alternative explanations have been proposed to explain, at first sight, this irrational behaviour [2, 3, 4, 5].", "startOffset": 120, "endOffset": 132}, {"referenceID": 2, "context": "As a consequence many alternative explanations have been proposed to explain, at first sight, this irrational behaviour [2, 3, 4, 5].", "startOffset": 120, "endOffset": 132}, {"referenceID": 3, "context": "As a consequence many alternative explanations have been proposed to explain, at first sight, this irrational behaviour [2, 3, 4, 5].", "startOffset": 120, "endOffset": 132}, {"referenceID": 4, "context": "As a consequence many alternative explanations have been proposed to explain, at first sight, this irrational behaviour [2, 3, 4, 5].", "startOffset": 120, "endOffset": 132}, {"referenceID": 5, "context": "Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].", "startOffset": 124, "endOffset": 140}, {"referenceID": 6, "context": "Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].", "startOffset": 124, "endOffset": 140}, {"referenceID": 7, "context": "Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].", "startOffset": 124, "endOffset": 140}, {"referenceID": 8, "context": "Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].", "startOffset": 124, "endOffset": 140}, {"referenceID": 9, "context": "Similar ideas are getting increasing interest and being used in different fields as control , robotics and machine learning [6, 7, 8, 9, 10].", "startOffset": 124, "endOffset": 140}, {"referenceID": 2, "context": "The theory of bounded rationality shares the same mathematical framework used in statistical physics to describe changes in thermodynamic systems [3, 11, 12].", "startOffset": 146, "endOffset": 157}, {"referenceID": 10, "context": "The theory of bounded rationality shares the same mathematical framework used in statistical physics to describe changes in thermodynamic systems [3, 11, 12].", "startOffset": 146, "endOffset": 157}, {"referenceID": 11, "context": "The theory of bounded rationality shares the same mathematical framework used in statistical physics to describe changes in thermodynamic systems [3, 11, 12].", "startOffset": 146, "endOffset": 157}, {"referenceID": 12, "context": "Furthermore, bounded rationality takes into account model uncertainty, meaning that the model used to describe the world or policy is wrong or partially incorrect, thus allowing deviations from this model [13, 14].", "startOffset": 205, "endOffset": 213}, {"referenceID": 13, "context": "Furthermore, bounded rationality takes into account model uncertainty, meaning that the model used to describe the world or policy is wrong or partially incorrect, thus allowing deviations from this model [13, 14].", "startOffset": 205, "endOffset": 213}, {"referenceID": 2, "context": "This trade-off is characterized by the free energy difference (FED)1 [3].", "startOffset": 69, "endOffset": 72}, {"referenceID": 14, "context": "However, when the parameters are applied in finite time, the work performed on the system will depend on the initial microscopic conditions and will be on average higher than the free energy difference [15] W \u2265 \u2206F.", "startOffset": 202, "endOffset": 206}, {"referenceID": 0, "context": "Without loss of generality, if the parameter \u03bb \u2208 [0, 1] controls a switching process between an initial potential2 UA (\u03bb = 0) and the final potential UB (\u03bb = 1), the equilibrium distribution for any intermediate \u03bb can be described with the Boltzmann distribution", "startOffset": 49, "endOffset": 55}, {"referenceID": 15, "context": "Recent advances in non-equilibrium thermodynamics have shown a remarkable fact, that is transforming the inequality of Equation 6 into an equality (called Jarzynski equality [16]):", "startOffset": 174, "endOffset": 178}], "year": 2013, "abstractText": "A perfectly rational decision-maker chooses the best action with the highest utility gain from a set of possible actions. The optimality principles that describe such decision processes do not take into account the computational costs of finding the optimal action. Bounded rational decision-making addresses this problem by specifically trading off information-processing costs and expected utility. Interestingly, a similar trade-off between energy and entropy arises when describing changes in thermodynamic systems. This similarity has been recently used to describe bounded rational agents. Crucially, this framework assumes that the environment does not change while the decision-maker is computing the optimal policy. When this requirement is not fulfilled, the decision-maker will suffer inefficiencies in utility, that arise because the current policy is optimal for an environment in the past. Here we borrow concepts from non-equilibrium thermodynamics to quantify these inefficiencies and illustrate with simulations its relationship with computational resources.", "creator": "LaTeX with hyperref package"}}}