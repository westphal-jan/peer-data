{"id": "1401.3491", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2014", "title": "Soft Goals Can Be Compiled Away", "abstract": "soft goals extend the normal classical model of aggregate planning with typically a simple model of simple preferences. the best social plans are then not the ones with least cost but the ones with maximum utility, just where the utility of a plan is the sum of the utilities of the soft goals achieved \u2014 minus the plan cost. finding soft plans with high utility appears to involve simply two linked problems : choosing a subset of appropriate soft goals to achieve and finding a low - cost plan to achieve them. new search algorithms quickly and heuristics have been developed for planning programs with soft goals, and a new budget track feature has been introduced in the international planning competition ( ipc ) to test their performance. in this note, we show basically however that these extensions are potentially not needed : soft goals don't increase the expressive power of the basic model systems of planning with action costs, long as happens they can easily be compiled away. we apply this compilation to the problems of the net - benefit track of the most recent ipc, and others show firmly that optimal and satisficing cost - based planners do better on the primary compiled problems than optimal and satisficing net - benefit planners on the original problems with explicit soft goals. furthermore, we show exactly that penalties, or negative preferences expressing conditions to avoid, can better also be compiled away using a similar idea.", "histories": [["v1", "Wed, 15 Jan 2014 05:39:49 GMT  (188kb)", "http://arxiv.org/abs/1401.3491v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["emil keyder", "hector geffner"], "accepted": false, "id": "1401.3491"}, "pdf": {"name": "1401.3491.pdf", "metadata": {"source": "CRF", "title": "Soft Goals Can Be Compiled Away", "authors": ["Emil Keyder", "Hector Geffner"], "emails": ["emil.keyder@upf.edu", "hector.geffner@upf.edu"], "sections": [{"heading": "1. Models", "text": "A STRIPS problem is a tuple P = \u3008F, I,O,G\u3009 where F is a set of fluents, I \u2286 F and G \u2286 F are the initial state and goal situation, and O is a set of actions or operators with precondition, add, and delete lists Pre(a), Add(a), and Del(a) respectively, all of which are subsets of F . An action sequence \u03c0 = \u3008a0, . . . , an\u3009 is applicable in P if the actions ai, i = 0, . . . , n, are all in O, and there exists a sequence of states \u3008s0, . . . , sn+1\u3009, such that s0 = I, Pre(ai) \u2286 si and si+1 = si \u222a Add(ai) \\ Del(ai) for i = 0, . . . , n. The applicable action sequence \u03c0 achieves a fluent g if g \u2208 sn+1, and is a plan for P if it achieves each goal g in G, which we write as \u03c0 |= G. In the classical setting, the cost of a plan c(\u03c0) is given by |\u03c0|, the number of actions in \u03c0. This cost structure is generalized with the addition of a cost function over the operators:\nc\u00a92009 AI Access Foundation. All rights reserved.\nDefinition 1 A STRIPS problem with action costs is a tuple Pc = \u3008F, I,O,G, c\u3009, where P = \u3008F, I,O,G\u3009 is a STRIPS problem and c is a function c : O 7\u2192 R+0 where R + 0 stands for the non-negative reals.\nThe cost of a plan \u03c0 for a problem Pc is then given by\nc(\u03c0) = |\u03c0|\u2211 i=1 c(ai) (1)\nwhere ai denotes the ith action in \u03c0. The cost function c(\u03c0) = |\u03c0| is obtained as a special case when c(o) = 1 for all o \u2208 O. Adding utilities or soft goals to the problem formulation results in a new model:\nDefinition 2 A STRIPS problem with action costs and soft goals is a tuple Pu = \u3008F, I,O, G, c, u\u3009, where P = \u3008F, I,O,G, c\u3009 is a STRIPS problem with action costs, and u is a partial function u : F 7\u2192 R+ that maps a subset of fluents (the soft goals) into positive reals.\nIn a STRIPS problem with soft goals Pu, the utility of a plan is given by the difference between the total utility obtained by the plan and its cost:\nu(\u03c0) = \u2211 p:\u03c0|=p u(p) \u2212 c(\u03c0) . (2)\nA plan \u03c0 for a problem with soft goals Pu is optimal when no other plan \u03c0\u2032 has a utility u(\u03c0\u2032) higher than u(\u03c0). The utility of an optimal plan for a problem with no hard goals is never negative, as the empty plan has non-negative utility and zero cost.\nThe most recent International Planning Competition (IPC6) featured Sequential Optimal and Net Benefit Optimal tracks in which the objective was to find optimal plans with respect to the models captured by Equation 1 and Equation 2 respectively (Helmert, Do, & Refanidis, 2008).1"}, {"heading": "2. Equivalence", "text": "Given a problem P with soft goals, an equivalent problem P \u2032 with action costs and no soft goals can be defined whose plans encode corresponding plans for P . This transformation, first introduced by Keyder and Geffner (2007), is simple and direct, yet seems to have escaped the attention of researchers in the area (Smith, 2004; Sanchez & Kambhampati, 2005; Bonet & Geffner, 2008; Baier, Bacchus, & McIlraith, 2007). Also, unlike the compilation of soft goals into numeric variables and arbitrary plan metrics (Edelkamp, 2006), the proposed transformation makes use of neither and requires from planners only the ability to handle\n1. In PDDL3, soft goals are represented by expressions of the form (\u2217 u (is-violated \u3008pref\u3009)) appearing in the problem metric where pref is a preference or soft goal associated with a formula A. When A is a single fluent, the expression corresponds to u(A) = u in the terminology used here. Most of the competition benchmarks contain only preferences of this form. The more general case that arises when A is a compound formula over fluents is considered in Section 4.\naction costs, the basic functionality required in the satisficing track of the most recent IPC (Helmert et al., 2008).2\nWe write actions as tuples of the form o = \u3008Pre(o),Eff(o)\u3009, where the effects can be positive (Adds) or negative (Deletes). We assume that for each soft goal fluent p, P also contains a fluent p representing its negation. These can be introduced in the standard way, adding p to the initial state if p is not initially true, and including p in the Add and Delete lists of all actions deleting or adding p respectively (Gazen & Knoblock, 1997; Nebel, 2000). The problem P \u2032 with action costs and no soft goals that is equivalent to the problem P with soft goals can then be obtained by the following transformation:\nDefinition 3 For a STRIPS problem with action costs and soft goals P = \u3008F, I,O,G, c, u\u3009, the compiled STRIPS problem with action costs is P \u2032 = \u3008F \u2032, I \u2032, O\u2032, G\u2032, c\u2032\u3009 with\n\u2022 F \u2032 = F \u222a S\u2032(P ) \u222a S(P ) \u222a {normal-mode, end-mode}\n\u2022 I \u2032 = I \u222a S(P ) \u222a {normal-mode}\n\u2022 G\u2032 = G \u222a S\u2032(P )\n\u2022 O\u2032 = O\u2032\u2032 \u222a {collect(p), forgo(p) | p \u2208 SG(P )} \u222a {end}\n\u2022 c\u2032(o) =  c(o) if o \u2208 O\u2032\u2032 u(p) if o = forgo(p) 0 if o = collect(p) or o = end\nwhere\n\u2022 SG(P ) = {p | (p \u2208 F ) \u2227 (u(p) > 0)}\n\u2022 S\u2032(P ) = {p\u2032 | p \u2208 SG(P )}\n\u2022 S(P ) = {p\u2032 | p\u2032 \u2208 S\u2032(P )}\n\u2022 end = \u3008{normal-mode}, {end-mode,\u00acnormal-mode}\u3009\n\u2022 collect(p) = \u3008{end-mode, p, p\u2032}, {p\u2032,\u00acp\u2032}\u3009\n\u2022 forgo(p) = \u3008{end-mode, p, p\u2032}, {p\u2032,\u00acp\u2032}\u3009\n\u2022 O\u2032\u2032 = {\u3008Pre(o) \u222a {normal-mode},Eff(o)\u3009 | o \u2208 O}\n2. Edelkamp\u2019s transformation associates with the soft goals p1, . . . , pm numeric variables n1, . . . , nm, each with domain {0, 1}. The utility for a plan is then expressed as U(\u03c0) = Pn i=1 ni \u2217 u(pi)\u2212 cost(\u03c0), where\nu(pi) represents the utility associated with soft goal pi and ni represents the value of the numeric variable in the final state achieved by the plan. This transformation also eliminates soft goals, but requires in its place a plan metric whose terms (namely, whether the variables u(pi) are 1 or 0) are state-dependent. Current heuristics can not deal with such metrics (See Sections 3 and 4).\nFor each soft goal p in P , the transformation adds a dummy hard goal p\u2032 in P \u2032 that can be achieved in two ways: with the action collect(p) that has cost 0 but requires p to be true, or with the action forgo(p) that has cost equal to the utility of p yet can be performed when p is false, or equivalently when p is true. These two actions can be used only after the end action that makes the fluent end-mode true, while the actions from the original problem P can be used only when the fluent normal-mode is true prior to the execution of the end action. Moreover, exactly one of {collect(p), forgo(p)} can appear for each soft goal p in the plan, as both delete their shared precondition p\u2032, which no action makes true. As there is no way to make normal-mode true again after it is deleted by the end action, all plans \u03c0\u2032 for P \u2032 have the form \u03c0\u2032 = \u3008\u03c0, end, \u03c0\u2032\u2032\u3009, where \u03c0 is a plan for P and \u03c0\u2032\u2032 is a sequence of |S\u2032(P )| collect(p) and forgo(p) actions in any order, the former appearing when \u03c0 |= p, and the latter otherwise.\nThe two problems P and P \u2032 are equivalent in the sense that there is a correspondence between the plans for P and P \u2032, and corresponding plans are ranked in the same way. More specifically, for any plan \u03c0 for P , there is a plan \u03c0\u2032 for P \u2032 that extends \u03c0 with the end action and a set of collect and forgo actions, and this plan has cost c(\u03c0\u2032) = \u2212u(\u03c0) + \u03b1, where \u03b1 is a constant that is independent of both \u03c0 and \u03c0\u2032. Finding an optimal (maximum utility) plan \u03c0 for P is therefore equivalent to finding an optimal (minimum cost) plan \u03c0\u2032 for P \u2032.\nProposition 1 (Correspondence between plans) For an applicable action sequence \u03c0 in P , let an extension \u03c0\u2032 of \u03c0 denote any sequence obtained by appending to \u03c0 the end action followed by some permutation of the actions collect(p) and forgo(p) for all p \u2208 SG(P ), when \u03c0 |= p and \u03c0 6|= p respectively. Then\n\u03c0 is a plan for P \u21d0\u21d2 \u03c0\u2032 is a plan for P \u2032\nProof: (\u21d2) The new actions in P \u2032 do not delete any p \u2208 F , so any hard goal achieved by \u03c0 will remain true in the final state reached by \u03c0\u2032, and we have that \u03c0\u2032 |= G. For all p \u2208 F such that u(p) > 0, either \u03c0 |= p or \u03c0 6|= p. In the first case, p\u2032 is achieved by collect(p), in the second, by forgo(p), therefore \u03c0\u2032 |= S\u2032(P ). Since G\u2032 = G\u222aS\u2032(P ), we have that \u03c0\u2032 |= G\u2032. (\u21d0) If \u03c0\u2032 is a plan for P \u2032, then all hard goals G in P must be made true by \u03c0\u2032 before the end action, as after this action only collect and forgo actions can be applied and these can not make any p \u2208 F true. The plan obtained by removing the end action and all collect and forgo actions must therefore achieve G and thus is a valid plan for P . 2\nProposition 2 (Correspondence between utilities and costs) Let \u03c01 and \u03c02 be two plans for P , and let \u03c0\u20321 and \u03c0 \u2032 2 be extensions of \u03c01 and \u03c02 respectively. Then,\nu(\u03c01) > u(\u03c02) \u21d0\u21d2 c(\u03c0\u20321) < c(\u03c0\u20322)\nProof: Let \u03c0 be a plan for P and \u03c0\u2032 an extension of \u03c0. We demonstrate that c(\u03c0\u2032) = \u2212u(\u03c0) + \u2211 p\u2208SG(P ) u(p). Since the summation in this expression is a constant for a given problem P , the assertion follows directly:\nc(\u03c0\u2032) = c(\u03c0) + c\u2032(end) + \u2211\nforgo(p)\u2208\u03c0\u2032 c\u2032(forgo(p)) + \u2211 collect(p)\u2208\u03c0\u2032 c\u2032(collect(p))\n= c(\u03c0) + \u2211\nforgo(p)\u2208\u03c0\u2032 c\u2032(forgo(p))\n= c(\u03c0) + \u2211 p:\u03c0 6|=p u(p)\n= c(\u03c0) + \u2211\np\u2208SG(P ) u(p)\u2212 \u2211 p:\u03c0|=p u(p)\n= \u2212u(\u03c0) + \u2211\np\u2208SG(P )\nu(p)\n2\nProposition 3 (Equivalence) Let \u03c0 be a plan for P , and \u03c0\u2032 be a plan for P \u2032 that extends \u03c0. Then,\n\u03c0 is an optimal plan for P \u21d0\u21d2 \u03c0\u2032 is an optimal plan for P \u2032\nProof: Direct from the two propositions above. 2\nIn the following section, we empirically compare the performance of net-benefit planners on problems P with explicit soft goals to that of sequential planners on problems P \u2032 in which soft goals have been compiled away. In order to improve the latter, we make the transformation of Definition 3 more effective with a simple trick. Recall that for a single plan \u03c0 for P , there are many extensions \u03c0\u2032 in P \u2032, all containing the same actions and having the same cost, but differing in the way the collect and forgo actions are ordered. For efficiency purposes, the implementation enforces a fixed but arbitrary ordering p1, . . . , pm on the soft goals in P by adding the dummy hard goal p\u2032i as a precondition of the actions collect(pi+1) and forgo(pi+1) for i = 1, . . . ,m\u22121. The result is that there is a single possible extension \u03c0\u2032 of every plan \u03c0 in P , and the space of plans to search is therefore reduced. This optimization is used in the experiments reported below."}, {"heading": "3. Experimental Results", "text": "The formal results above imply that the best plans for a problem P with action costs and soft goals can be computed by looking for the best plans for the compiled problem P \u2032 with action costs and no soft goals, to which standard classical planning techniques can be applied. To test the practical value of the transformation, we evaluate the performance of both optimal and satisficing planning techniques for soft goals. Some problems in the test suite contain preferences over conjunctions rather than single fluents. Such preferences are handled with a variant of the approach described above, detailed in Section 4.\nThe results shown in the three columns in Table 1 labelled \u2018Net-benefit optimal planners\u2019 are the results as reported by the organizers of the 2008 International Planning Competition (IPC6) (Helmert et al., 2008). All other results were obtained using the same machines and\nsettings as used in the competition: Xeon Woodcrest computers with clock speeds of 2.33 GHz, with a time limit of 30 minutes and a memory limit of 2GB.\nIn the first set of experiments, we consider the problems used in the Net Benefit Optimal (NBO) track of IPC6, in which soft goals are defined in terms of goal-state preferences (Gerevini & Long, 2006), and compare the results obtained by the three optimal netbenefit planners with the results obtained by their Sequential Optimal (SO) variants on their compilations.3 The three planners entered in the NBO track of IPC6 were Gamer, Mips-XXL, and HSP*P. The SO planners we test on the compiled versions of the NBO problems are the SO versions of Gamer (Edelkamp & Kissmann, 2008) and Mips-XXL (Edelkamp & Jabbar, 2008) and the two SO planners HSP*F and HSP * 0 (Haslum, 2008). 4 These were ranked first, fifth, second, and third, respectively, in the SO track (Helmert et al., 2008). Three out of the six domains from the NBO track of IPC6 involve numeric variables that appear in the preconditions of actions. The SO version of Gamer does not handle numeric variables, and we are therefore unable to run Gamer on such problems. Numeric variables never appear as soft goals and are left untouched by our compilation.\nThe data in Table 1 show that the two HSP* planners from the SO track run on the compiled problems do as well as, or better than, the best planner from the NBO track run on the original problems with soft goals. The maximum number of solved problems for a domain is higher for the NBO track planners in only a single domain, openstacks (7 vs. 6). In all other domains, SO planners are able to solve a larger number of problems than the\n3. The compiled problems are currently available at http://ipc.informatik.uni-freiburg.de/Domains. 4. All versions of HSP* have a bug which may cause suboptimal or invalid solutions to be computed in domains with non-monotonic numeric variables (numeric variables whose values may both increase and decrease) that occur in preconditions of actions or goals (See http://ipc.informatik.uni-freiburg. de/Planners). Such variables are present only in the transport domain out of all those tested, yet plans computed by HSP* for both versions of the domain turn out to be valid (as verified by the VAL plan validator, Howey & Long, 2003) and optimal in the instances in which they can be checked against the costs of plans computed by other planners.\nmaximum number solved by any NBO planner. Considering the performance of the NBO and SO variants of each planner, the compilation benefits most the two versions of the heuristic search planner HSP*, leaving the BDD planners Gamer and Mips-XXL relatively unaffected. Interestingly, HSP*0 using the compilation ends up solving more problems than Gamer, the winner of the NBO track (78 vs. 71). The drastically better performance of the SO versions of HSP* compared to the net-benefit version is the result of the simple scheme for handling soft goals in the latter, in which optimal plans are computed for each possible subset of soft goals in the problem (roughly), and a change in the search algorithm from IDA* to A*.\nIn the second set of experiments, we consider the three domains from the NBO track of IPC6 which do not contain numeric variables in the preconditions of actions, and the domain rovers from the net-benefit track of IPC5. Domains containing numeric variables in the preconditions of actions are not considered due to the lack of state-of-the-art cost-based planners able to handle them. Domains other than rovers from the NB track of IPC5 are not considered as they contain disjunctive, existentially qualified, or universally qualified soft goals which our current implementation does not support. The satisficing net-benefit planners we test on these problems are SGPlan (Hsu & Wah, 2008), the winner of the net benefit track from IPC5, YochanPS (Benton, Do, & Kambhampati, 2009), which received a distinguished performance award in the same competition, and a satisficing variant of MIPS-XXL, which also received a distinguished performance award in that competition and competed in the optimal track of IPC6. We solve the compiled versions of the problems with LAMA, the winner of the sequential satisficing track from IPC6. YochanPS, MIPS-XXL, and LAMA are anytime planners, and the results discussed below refer to the cost of the best plan found by each at the end of the evaluation period of 30 minutes.\nEntries in Table 2 show the number of problems in each domain for which the plan generated by a planner is the best or only plan produced. We report this data rather than showing graphs of plan utilities as the absolute difference between the quality of plans is not meaningful in itself except when the shortest plans (that ignore costs and/or soft goals) for the problem are significantly more costly. The results show that running a state-of-the-art cost-based planner on the compiled problems yields the best plan in 98 out of the total 110 instances, almost three times the number of instances in which the best-performing native soft goals planner, MIPS-XXL, gives the best plan. Furthermore, in 22 out of the 23\nproblems for which MIPS-XXL finds the best plan in the pegsol domain, LAMA finds a plan with the same quality. The problems in which satisficing net-benefit planners outperform LAMA run on the compiled problems are therefore very few.\nThese results appear to contradict the results reported by Benton et al. (2009), where the native net-benefit planner, YochanPS, yields better results than a cost-based planner, YochanCOST, run on problems compiled according to an earlier version of our transformation (Keyder & Geffner, 2007). The discrepancy appears to be the result of the non-informative cost-based heuristic used in YochanCOST, which leads to plans that forgo all soft goals, and the fact that they do not make use of the optimization discussed at the end of Section 2, which results in an unnecessary blowup of the state space. For an analysis of the differences between some recent cost-based planners, see the paper by Keyder and Geffner (2008)."}, {"heading": "4. Extensions", "text": "We have shown that it is possible to compile away positive utilities u(p) associated with single fluents p. We show now that this compilation can be extended to deal with positive utilities defined on formulas over fluents and to negative utilities defined on both single fluents and formulas. Negative utilities stand for conditions to be avoided rather than sought; for example, a utility u(p \u2227 q) = \u221210 penalizes a plan that results in a state where both p and q are true with an extra cost of 10. The compilation of soft goals defined on formulas is based on the standard compilation of goal and precondition formulas in classical planning (Gazen & Knoblock, 1997; Nebel, 1999).\nA positive utility on a logical formula A can be compiled away by introducing a new fluent pA that can be achieved at zero cost from any end state where A holds, and by assigning the utility associated with A to pA. If A is a DNF formula D1 \u2228 . . . \u2228 Dn, it suffices to add n new actions a1, . . . , an with ai = \u3008Di, pA\u3009 for i = 1, . . . , n. If A is a CNF formula C1 \u2227 . . . \u2227 Cn, a fluent pi is introduced for each i = 1, . . . , n, along with actions aij = \u3008Cij , pi\u3009 for j = 1, . . . , |Ci|, where Cij stands for the jth fluent of Ci. We also introduce an action a = \u3008{p1, . . . , pn}, pA\u3009 that allows the addition of fluent pA in states where A holds. All the newly introduced actions have zero cost, and must be applicable in P \u2032 after the actions of the original problem P and before the collect and forgo actions. The best extensions of any plan \u03c0 that achieves A in P will then achieve pA and use the collect action to achieve the hard goal fluent p\u2032A associated with pA at zero cost.\nA negative utility u(A) < 0 on a formula A in DNF or CNF can be compiled away in two steps, by first substituting a positive utility \u2212u(\u00acA) on the negation \u00acA of A and then compiling this positive utility on a formula into a utility on a single fluent as described above. This makes use of the fact that the negation of a formula in CNF is a formula in DNF and vice versa."}, {"heading": "5. Summary", "text": "We have shown that soft goals do not add expressive power and can be easily compiled away. This implies that no new search algorithms or heuristics are strictly required for handling them. From a practical standpoint, experiments indicate that state-of-the-art sequential planners outperform state-of-the-art net-benefit planners on compiled versions of\nthe benchmarks used in recent planning competitions. Furthermore, similar transformations can be used to compile away positive and negative utilities on logical formulas in DNF or CNF."}, {"heading": "Acknowledgments", "text": "We thank Malte Helmert for his help with compiling and running many of the IPC6 planners, Patrik Haslum for his help with all aspects of various versions of HSP, and J. Benton for his help with compiling and running YochanPS. H. Geffner is partially supported by Grant TIN2006-15387-C03-03 from MEC, Spain."}], "references": [{"title": "A heuristic search approach to planning with temporally extended preferences", "author": ["J.A. Baier", "F. Bacchus", "S.A. McIlraith"], "venue": "In Proc. IJCAI-07,", "citeRegEx": "Baier et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Baier et al\\.", "year": 2007}, {"title": "Anytime heuristic search for partial satisfaction planning", "author": ["J. Benton", "M. Do", "S. Kambhampati"], "venue": "Artificial Intelligence,", "citeRegEx": "Benton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Benton et al\\.", "year": 2009}, {"title": "Heuristics for planning with penalties and rewards formulated in logic and computed through circuits", "author": ["B. Bonet", "H. Geffner"], "venue": "Artificial Intelligence,", "citeRegEx": "Bonet and Geffner,? \\Q2008\\E", "shortCiteRegEx": "Bonet and Geffner", "year": 2008}, {"title": "On the compilation of plan constraints and preferences", "author": ["S. Edelkamp"], "venue": "In Proc. ICAPS-06,", "citeRegEx": "Edelkamp,? \\Q2006\\E", "shortCiteRegEx": "Edelkamp", "year": 2006}, {"title": "MIPS-XXL: Featuring external shortest path search for sequential optimal plans and external branch-and-bound for optimal net benefit", "author": ["S. Edelkamp", "S. Jabbar"], "venue": "In 6th. Int. Planning Competition Booklet (ICAPS-08)", "citeRegEx": "Edelkamp and Jabbar,? \\Q2008\\E", "shortCiteRegEx": "Edelkamp and Jabbar", "year": 2008}, {"title": "Gamer: Bridging planning and general game playing with symbolic search", "author": ["S. Edelkamp", "P. Kissmann"], "venue": "In 6th. Int. Planning Competition Booklet (ICAPS-08)", "citeRegEx": "Edelkamp and Kissmann,? \\Q2008\\E", "shortCiteRegEx": "Edelkamp and Kissmann", "year": 2008}, {"title": "Combining the expressiveness of UCPOP with the efficiency of Graphplan", "author": ["B. Gazen", "C. Knoblock"], "venue": "Proc. 4th European Conf. on Planning,", "citeRegEx": "Gazen and Knoblock,? \\Q1997\\E", "shortCiteRegEx": "Gazen and Knoblock", "year": 1997}, {"title": "Preferences and soft constraints in PDDL3", "author": ["A. Gerevini", "D. Long"], "venue": "In Proc. ICAPS-06 Workshop on Preferences and Soft Constraints in Planning,", "citeRegEx": "Gerevini and Long,? \\Q2006\\E", "shortCiteRegEx": "Gerevini and Long", "year": 2006}, {"title": "Additive and reversed relaxed reachability heuristics revisited", "author": ["P. Haslum"], "venue": "In 6th. Int. Planning Competition Booklet (ICAPS-08)", "citeRegEx": "Haslum,? \\Q2008\\E", "shortCiteRegEx": "Haslum", "year": 2008}, {"title": "VAL\u2019s progress: The automatic validation tool for PDDL2.1 used in the international planning competition", "author": ["R. Howey", "D. Long"], "venue": "In Proc. 2003 ICAPS Workshop on The Competition: Impact,", "citeRegEx": "Howey and Long,? \\Q2003\\E", "shortCiteRegEx": "Howey and Long", "year": 2003}, {"title": "The SGPlan planning system in IPC6", "author": ["Hsu", "C.-W", "B.W. Wah"], "venue": "In 6th. Int. Planning Competition Booklet (ICAPS-08)", "citeRegEx": "Hsu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2008}, {"title": "Set-additive and TSP heuristics for planning with action costs and soft goals", "author": ["E. Keyder", "H. Geffner"], "venue": "In Proc. ICAPS-06 Workshop on Heuristics for DomainIndependent Planning", "citeRegEx": "Keyder and Geffner,? \\Q2007\\E", "shortCiteRegEx": "Keyder and Geffner", "year": 2007}, {"title": "Heuristics for planning with action costs revisited", "author": ["E. Keyder", "H. Geffner"], "venue": "In Proc. 18th European Conference on Artificial Intelligence,", "citeRegEx": "Keyder and Geffner,? \\Q2008\\E", "shortCiteRegEx": "Keyder and Geffner", "year": 2008}, {"title": "Compilation schemes: A theoretical tool for assessing the expressive power of planning formalisms", "author": ["B. Nebel"], "venue": "In Proc. KI-99: Advances in Artificial Intelligence,", "citeRegEx": "Nebel,? \\Q1999\\E", "shortCiteRegEx": "Nebel", "year": 1999}, {"title": "On the compilability and expressive power of propositional planning", "author": ["B. Nebel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Nebel,? \\Q2000\\E", "shortCiteRegEx": "Nebel", "year": 2000}, {"title": "Planning graph heuristics for selecting objectives in over-subscription planning problems", "author": ["R. Sanchez", "S. Kambhampati"], "venue": "In Proc. ICAPS-05,", "citeRegEx": "Sanchez and Kambhampati,? \\Q2005\\E", "shortCiteRegEx": "Sanchez and Kambhampati", "year": 2005}, {"title": "Choosing objectives in over-subscription planning", "author": ["D.E. Smith"], "venue": "In Proc. ICAPS-04,", "citeRegEx": "Smith,? \\Q2004\\E", "shortCiteRegEx": "Smith", "year": 2004}], "referenceMentions": [{"referenceID": 16, "context": "This transformation, first introduced by Keyder and Geffner (2007), is simple and direct, yet seems to have escaped the attention of researchers in the area (Smith, 2004; Sanchez & Kambhampati, 2005; Bonet & Geffner, 2008; Baier, Bacchus, & McIlraith, 2007).", "startOffset": 157, "endOffset": 257}, {"referenceID": 3, "context": "Also, unlike the compilation of soft goals into numeric variables and arbitrary plan metrics (Edelkamp, 2006), the proposed transformation makes use of neither and requires from planners only the ability to handle", "startOffset": 93, "endOffset": 109}, {"referenceID": 10, "context": "This transformation, first introduced by Keyder and Geffner (2007), is simple and direct, yet seems to have escaped the attention of researchers in the area (Smith, 2004; Sanchez & Kambhampati, 2005; Bonet & Geffner, 2008; Baier, Bacchus, & McIlraith, 2007).", "startOffset": 41, "endOffset": 67}, {"referenceID": 14, "context": "These can be introduced in the standard way, adding p to the initial state if p is not initially true, and including p in the Add and Delete lists of all actions deleting or adding p respectively (Gazen & Knoblock, 1997; Nebel, 2000).", "startOffset": 196, "endOffset": 233}, {"referenceID": 8, "context": "The SO planners we test on the compiled versions of the NBO problems are the SO versions of Gamer (Edelkamp & Kissmann, 2008) and Mips-XXL (Edelkamp & Jabbar, 2008) and the two SO planners HSPF and HSP * 0 (Haslum, 2008).", "startOffset": 206, "endOffset": 220}, {"referenceID": 1, "context": "These results appear to contradict the results reported by Benton et al. (2009), where the native net-benefit planner, YochanPS, yields better results than a cost-based planner, YochanCOST, run on problems compiled according to an earlier version of our transformation (Keyder & Geffner, 2007).", "startOffset": 59, "endOffset": 80}, {"referenceID": 1, "context": "These results appear to contradict the results reported by Benton et al. (2009), where the native net-benefit planner, YochanPS, yields better results than a cost-based planner, YochanCOST, run on problems compiled according to an earlier version of our transformation (Keyder & Geffner, 2007). The discrepancy appears to be the result of the non-informative cost-based heuristic used in YochanCOST, which leads to plans that forgo all soft goals, and the fact that they do not make use of the optimization discussed at the end of Section 2, which results in an unnecessary blowup of the state space. For an analysis of the differences between some recent cost-based planners, see the paper by Keyder and Geffner (2008).", "startOffset": 59, "endOffset": 720}, {"referenceID": 13, "context": "The compilation of soft goals defined on formulas is based on the standard compilation of goal and precondition formulas in classical planning (Gazen & Knoblock, 1997; Nebel, 1999).", "startOffset": 143, "endOffset": 180}], "year": 2009, "abstractText": "Soft goals extend the classical model of planning with a simple model of preferences. The best plans are then not the ones with least cost but the ones with maximum utility, where the utility of a plan is the sum of the utilities of the soft goals achieved minus the plan cost. Finding plans with high utility appears to involve two linked problems: choosing a subset of soft goals to achieve and finding a low-cost plan to achieve them. New search algorithms and heuristics have been developed for planning with soft goals, and a new track has been introduced in the International Planning Competition (IPC) to test their performance. In this note, we show however that these extensions are not needed: soft goals do not increase the expressive power of the basic model of planning with action costs, as they can easily be compiled away. We apply this compilation to the problems of the net-benefit track of the most recent IPC, and show that optimal and satisficing cost-based planners do better on the compiled problems than optimal and satisficing netbenefit planners on the original problems with explicit soft goals. Furthermore, we show that penalties, or negative preferences expressing conditions to avoid, can also be compiled away using a similar idea.", "creator": "TeX"}}}