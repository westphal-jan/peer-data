{"id": "1401.3830", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Interactive Cost Configuration Over Decision Diagrams", "abstract": "in many ai domains such as product configuration, a user should interactively specify a solution that must satisfy a set of constraints. in such scenarios, offline compilation of feasible solutions into a tractable representation is an important agile approach to confidently delivering historically efficient backtrack - free user interaction simulation online. where in particular, binary decision diagrams ( bdds ) have been successfully used as a compilation template target for product and service execution configuration. in this presentation paper basically we discuss how to extend bdd - tag based configuration to scenarios involving cost functions which express user preferences.", "histories": [["v1", "Thu, 16 Jan 2014 04:48:15 GMT  (426kb)", "http://arxiv.org/abs/1401.3830v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["henrik reif", "ersen", "tarik hadzic", "david pisinger"], "accepted": false, "id": "1401.3830"}, "pdf": {"name": "1401.3830.pdf", "metadata": {"source": "CRF", "title": "Interactive Cost Configuration Over Decision Diagrams", "authors": ["Henrik Reif Andersen", "Tarik Hadzic", "David Pisinger"], "emails": ["hra@configit.com", "t.hadzic@4c.ucc.ie", "pisinger@man.dtu.dk"], "sections": [{"heading": null, "text": "We first show that an efficient, robust and easy to implement extension is possible if the cost function is additive, and feasible solutions are represented using multi-valued decision diagrams (MDDs). We also discuss the effect on MDD size if the cost function is non-additive or if it is encoded explicitly into MDD. We then discuss interactive configuration in the presence of multiple cost functions. We prove that even in its simplest form, multiple-cost configuration is NP-hard in the input MDD. However, for solving two-cost configuration we develop a pseudo-polynomial scheme and a fully polynomial approximation scheme. The applicability of our approach is demonstrated through experiments over real-world configuration models and product-catalogue datasets. Response times are generally within a fraction of a second even for very large instances."}, {"heading": "1. Introduction", "text": "Interactively specifying a solution that must satisfy a number of combinatorial restrictions is an important problem in many AI domains related to decision making: from buying a product online, selling an insurance policy to setting up a piece of equipment. Solutions are often modeled as assignments to variables over which constraints are imposed. When assigning variables without sufficient guidance, a user might be forced to backtrack, since some of the choices he made cannot be extended in a way that would satisfy all of the succeeding constraints. To improve the usability of interaction it is therefore important to indicate to a user all values that participate in at least one remaining solution. If a\nc\u00a92010 AI Access Foundation. All rights reserved.\nuser is assigning only such values he is guaranteed to be able to reach any feasible solution while never being forced to backtrack. We refer to the task of computing such values as calculating valid domains (CVD). Since this is a computationally challenging (NP-hard) problem, and short execution times are important in an interactive setting, it has been suggested to compile offline (prior to user interaction) the set of all feasible solutions into a representation form that supports efficient execution of CVD during online interaction.\nM\u00f8ller, Andersen, and Hulgaard (2002) and Hadzic, Subbarayan, Jensen, Andersen, M\u00f8ller, and Hulgaard (2004) investigated such an approach by using binary decision diagrams (BDDs) as a compilation target. BDDs are one of the data-structures investigated in the knowledge compilation community which preprocess original problem formulations into more tractable representations to enhance solving the subsequent tasks. CVD is just one of such tasks occurring in the configuration domain. Knowledge compilation has been successfully applied to a number of other areas such as planning, diagnosis, model checking etc. Beside BDDs, a number of other structures, such as various sublanguages of negation normal forms (NNFs) (Darwiche & Marquis, 2002), AND/OR diagrams (Mateescu, Dechter, & Marinescu, 2008), finite state automata (Vempaty, 1992; Amilhastre, Fargier, & Marquis, 2002) and various extensions of decision diagrams (Drechsler, 2001; Wegener, 2000; Meinel & Theobald, 1998) are used as compilation targets. Some of them are suitable for interactive configuration as well. In particular, Vempaty (1992) suggested compiling constraints into an automaton. However, BDDs are the most investigated data structures with a tool support unrivaled by other emerging representations. There are many highly optimized open-source BDD packages (e.g., Somenzi, 1996; Lind-Nielsen, 2001) that allow easy and efficient manipulation of BDDs. In contrast, publicly available, open-source compilers are still being developed for many newer representations. In particular, the application of BDDs to configuration resulted in a patent approval (Lichtenberg, Andersen, Hulgaard, M\u00f8ller, & Rasmussen, 2001) and the establishment of the spinoff company Configit A/S1.\nThe work in this paper is motivated by decision making scenarios where solutions are associated with a cost function, expressing implicitly properties such as price, quality, failure probability etc. A user might prefer one solution over another given the value of such properties. A natural way in which a user expresses his cost preferences in a configuration setting is to bound the minimal or maximal cost of any solution he is willing to accept. We therefore study the problem of calculating weighted valid domains (wCVD), where we eliminate those values that in every valid solution are more expensive than a user-provided maximal cost. We present a configurator that supports efficient cost bounding for a wide class of additive cost functions. Our approach is easily implementable and scales well for all the instances that were previously compiled into BDDs for standard interactive configuration. The cornerstone of our approach is to reuse the robust compilation of constraints into a BDD, and then extract a corresponding multi-valued decision diagram (MDD). The resulting MDD allows us to label edges with weights and utilize efficient shortest path algorithms to label nodes and filter expensive values on MDD edges. While our MDD extraction technique is novel, labeling edges in a decision diagram is suggested in other works as well. In its most generic interpretation (Wilson, 2005), edges of a decision diagram can be labeled with elements of a semiring to support algebraic computations relevant for probabilistic rea-\n1. http://www.configit.com\nsoning, optimization etc. Amilhastre et al. (2002) suggest labeling edges of an automaton to reason abut optimal restorations and explanations. In general, many knowledge compilation structures have their weighted counterparts, many of which are captured in the framework of valued negation normal forms (VNNFs) (Fargier & Marquis, 2007). These structures are utilized for probabilistic reasoning, diagnosis, and other tasks involving reasoning about real-valued rather than Boolean functions. Some of them can in principle be used for wCVD queries, but the public tool support for weighted variants is less available or is tailored for tasks outside the configuration domain.\nWe further extend our approach to support valid domains computation in the presence of multiple cost functions. A user often has multiple conflicting objectives, that should be satisfied simultaneously. Traditional approaches in multi-criteria optimization (Figueira, Greco, & Ehrgott, 2005; Ehrgott & Gandibleux, 2000) typically interact with a user in a way that is unsuitable in a configuration setting \u2014 cost functions are combined in a single objective and in each interaction step few non-dominated solutions are sampled and displayed to a user. Based on user selections a more adequate aggregation of costs is performed before the next interaction step. We suggest a more configuration-oriented interaction approach where domains are bounded with respect to multiple costs. We prove that this is a particularly challenging problem. Computing valid domains over an MDD in the presence of two cost functions (2-wCVD) is NP-hard, even in the simplest extension of linear inequalities with positive coefficients and Boolean variables. Despite this negative result, we provide an implementation of 2-wCVD queries in pseudo-polynomial time and space and develop a fully polynomial time approximation scheme (FPTAS). We prove that no pseudo-polynomial algorithm and hence no fully polynomial approximation scheme exists for computing domains in the presence of arbitrarily many cost functions since that is an NP-hard problem in the strong sense. Finally, we demonstrate through experimental evaluation the applicability of both the wCVD and 2-wCVD query over large real-world configuration models and product-catalogue datasets. To the best of our knowledge, we present the first interactive configurator supporting configuration wrt. cost restrictions in a backtrack-free and complete manner. This constitutes a novel addition to both existing product-configuration approaches as well as to approaches within multi-criteria decision making (Figueira et al., 2005).\nThe remainder of the paper is organized as follows. In Section 2 we describe background work and notation. In Section 3 we describe our approach to implementing wCVD query over an MDD while in Section 4 we show how to compile such an MDD. In Section 5 we discuss configuring in the presence of multiple costs. In Section 6 we present empirical evaluation of our approach. In Section 7 we describe related work and finally we conclude in Section 8."}, {"heading": "2. Preliminaries", "text": "We will briefly review the most important concepts and background."}, {"heading": "2.1 Constraint Satisfaction Problems", "text": "Constraint satisfaction problems (CSPs) form a framework for modeling and solving combinatorial problems, where a solution to a problem can be formulated as an assignment to\nvariables that satisfy certain constraints. In its standard form, CSP involves only a finite number of variables, defined over finite domains.\nDefinition 1 (CSP) A constraint satisfaction problem (CSP) is a triple (X,D,F ) where X is a set of variables {x1, . . . , xn}, D = D1\u00d7. . .\u00d7Dn is the Cartesian product of their finite domains D1, . . . , Dn and F = {f1, ..., fm} is a set of constraints defined over variables X. Each constraint f is a function defined over a subset of variables Xf \u2286 X called the scope of f . It maps each assignment to the Xf variables into {0, 1} where 1 indicates that f is satisfied and 0 indicates that f is violated by the assignment. The solution is an assignment to all variables X that satisfies all constraints simultaneously.\nFormally, an assignment of values a1, . . . , an to variables x1, . . . , xn is denoted as a set of pairs \u03c1 = {(x1, a1), . . . , (xn, an)}. The domain of an assignment dom(\u03c1) is the set of variables which are assigned: dom(\u03c1) = {xi | \u2203a \u2208 Di.(xi, a) \u2208 \u03c1} and if all variables are assigned, i.e. dom(\u03c1) = X, we refer to \u03c1 as a total assignment. We say that a total assignment \u03c1 is valid if it satisfies all the rules, which is denoted as \u03c1 |= F . A partial assignment \u03c1, dom(\u03c1) \u2286 X is valid if it can be extended to a total assignment \u03c1\u2032 \u2287 \u03c1 that is valid \u03c1\u2032 |= F . We define the solution space Sol as the set of all valid total assignments, i.e. Sol = {\u03c1 | \u03c1 |= F, dom(\u03c1) = X}."}, {"heading": "2.2 Interactive Configuration", "text": "Interactive configuration is an important application domain where a user is assisted in specifying a valid configuration (of a product, a service or something else) by interactively providing feedback on valid options for unspecified attributes. Such a problem arises in a number of domains. For example, when buying a product, a user should specify a number of product attributes. Some attribute combinations might not be feasible and if no guidance is provided, the user might reach a dead-end when interacting with the system. He will be forced to backtrack, which might seriously decrease the user satisfaction.\nIn many cases, valid configurations can be implicitly described by specifying restrictions on combining product attributes. We use a CSP model to represent such restrictions, and each CSP solution corresponds to a valid configuration. Each configurable attribute is represented with a variable, so that each attribute option corresponds to a value in the variable domain. In Example 1 we illustrate a simple configuration problem and its CSP model.\nExample 1 To specify a T-shirt we have to choose the color (black, white, red, or blue), the size (small, medium, or large) and the print (\u201dMen In Black\u201d - MIB or \u201dSave The Whales\u201d - STW). If we choose the MIB print then the color black has to be chosen as well, and if we choose the small size then the STW print (including a large picture of a whale) cannot be selected as the picture of a whale does not fit on the small shirt. The configuration problem (X,D,F ) of the T-shirt example consists of variables X = {x1, x2, x3} representing color, size and print. Variable domains are D1 = {0, 1, 2, 3} (black ,white, red , blue), D2 = {0, 1, 2} (small ,medium, large), and D3 = {0, 1} (MIB ,STW ). The two rules translate to F = {f1, f2}, where f1 is x3 = 0 \u21d2 x1 = 0 (MIB \u21d2 black) and f2 is (x2 = 0 \u21d2 x3 6= 1) (small \u21d2 not STW ). There are |D1||D2||D3| = 24 possible assignments. Eleven of these assignments are valid configurations and they form the solution space shown in Fig. 1. \u2666\nThe fundamental task that we are concerned with in this paper is calculating valid domains (CVD) query. For a partial assignment \u03c1 representing previously made user assignments, the configurator calculates and displays a valid domain VD i[\u03c1] \u2286 Di for each unassigned variable xi \u2208 X \\ dom(\u03c1). A domain is valid if it contains those and only those values with which \u03c1 can be extended to a total valid assignment \u03c1\u2032. In our example, if a user selects a small T-shirt (x2 = 0), valid domains should be restricted to a MIB print V D3 = {0} and black color V D1 = {0}.\nDefinition 2 (CVD) Given a CSP model (X,D,F ), for a given partial assignment \u03c1 compute valid domains:\nVDi[\u03c1] = {a \u2208 Di | \u2203\u03c1\u2032.(\u03c1\u2032 |= F and \u03c1 \u222a {(xi, a)} \u2286 \u03c1\u2032)}\nThis task is of main interest since it delivers important interaction requirements: backtrackfreeness (user should never be forced to backtrack) and completeness (all valid configurations should be reachable) (Hadzic et al., 2004). There are other queries relevant for supporting user interaction such as explanations and restorations from a failure, recommendations of relevant products, etc., but CVD is an essential operation in our mode of interaction and is of primary importance in this paper."}, {"heading": "2.3 Decision Diagrams", "text": "Decision diagrams form a family of rooted directed acyclic graphs (DAGs) where each node u is labeled with a variable xi and each of its outgoing edges e is labeled with a value a \u2208 Di. No node may have more than one outgoing edge with the same label. The decision diagram contains one or more terminal nodes, each labeled with a constant and having no outgoing edges. The most well known member of this family are binary decision diagrams (BDDs) (Bryant, 1986) which are used for manipulating Boolean functions in many areas, such as verification, model checking, VLSI design (Meinel & Theobald, 1998; Wegener, 2000; Drechsler, 2001) etc. In this paper we will primarily operate with the following variant of multi-valued decision diagrams:\nDefinition 3 (MDD) An MDD denoted M is a rooted directed acyclic graph (V,E), where V is a set of vertices containing the special terminal vertex 1 and a root r \u2208 V . Further, var : V \u2192 {1, . . . , n+ 1} is a labeling of all nodes with a variable index such that var(1) = n+1. Each edge e \u2208 E is denoted with a triple (u, u\u2032, a) of its start node u, its end node u\u2032 and an associated value a.\nWe work only with ordered MDDs. A total ordering < of the variables is assumed such that for all edges (u, u\u2032, a), var(u) < var(u\u2032). For convenience we assume that the variables\nin X are ordered according to their indices. Ordered MDDs can be considered as being arranged in n layers of vertices, each layer being labeled with the same variable index. We will denote with Vi the set of all nodes labeled with xi, Vi = {u \u2208 V | var(u) = i}. Similarly, we will denote with Ei the set of all edges originating in Vi, i.e. Ei = {e(u, u\u2032, a) \u2208 E | var(u) = i}. Unless otherwise specified, we assume that on each path from the root to the terminal, every variable labels exactly one node.\nAn MDD encodes a CSP solution set Sol \u2286 D1 \u00d7 . . . \u00d7 Dn, defined over variables {x1, . . . , xn}. To check whether an assignment a = (a1, . . . , an) \u2208 D1\u00d7 . . .\u00d7Dn is in Sol we traverse M from the root, and at every node u labeled with variable xi, we follow an edge labeled with ai. If there is no such edge then a is not a solution, i.e., a 6\u2208 Sol. Otherwise, if the traversal eventually ends in terminal 1 then a \u2208 Sol. We will denote with p : u1 u2 any path in MDD from u1 to u2. Also, edges between u and u\n\u2032 will be sometimes denoted as e : u\u2192 u\u2032. A value a of an edge e(u, u\u2032, a) will be sometimes denoted as v(e). We will not make distinction between paths and assignments. Hence, the set of all solutions represented by the MDD is Sol = {p | p : r 1}. In fact, every node u \u2208 Vi can be associated with a subset of solutions Sol(u) = {p | p : u 1} \u2286 Di \u00d7 . . .\u00d7Dn.\nDecision diagrams can be exponentially smaller than the size of the solution set they encode by merging isomorphic subgraphs. Two nodes u1, u2 are isomorphic if they encode the same solution set Sol(u1) = Sol(u2). In Figure 2 we show a fully expanded MDD 2(a) and an equivalent merged MDD 2(b) for the T-shirt solution space. In addition to merging isomorphic subgraphs, another compression rule is usually utilized: removing redundant nodes. A node u \u2208 Vi is redundant if it has Di outgoing edges, each pointing to the same node u\u2032. Such nodes are eliminated by redirecting incoming edges from u to u\u2032 and deleting u from V . This introduces long edges that skip layers. An edge e(u, u\u2032, a) is long if var(u)+1 < var(u\u2032). In this case, e encodes the set of solutions: {a}\u00d7Dvar(u)+1\u00d7 . . .\u00d7Dvar(u\u2032)\u22121. We will refer to an MDD where both merging of isomorphic nodes and removal of redundant nodes have taken place as a reduced MDD, which constitutes a multi-valued generalization of BDDs which are typically reduced and ordered. A reduced MDD for the T-shirt CSP is shown in Figure 3. In this paper, unless emphasized otherwise, by MDD we always assume an ordered merged but not reduced MDD, since exposition is simpler, and removal of redundant nodes can have at most a linear effect on size. Given a variable ordering\nthere is a unique merged MDD for a given CSP (X,D,F ) and its solution set Sol. The size of MDD depends critically on the ordering, and could vary exponentially. It can grow exponentially with the number of variables, but in practice, for many interesting problems the size is surprisingly small.\nInteractive Configuration over Decision Diagrams. A particularly attractive property of decision diagrams is that they support efficient execution of a number of important queries, such as checking for consistency, validity, equivalence, counting, optimization etc. This is utilized in a number of application domains where most of the problem description is known offline (diagnosis, verification,etc.). In particular, calculating valid domains is linear in the size of the MDD. Since calculating valid domains is an NP-hard problem in the size of the input CSP model, it is not possible to guarantee interactive response in real-time. In fact, the unacceptably long worst-case response times have been empirically observed in a purely search-based approach to computing valid domains (Subbarayan et al., 2004). Therefore, by compiling CSP solutions off-line (prior to user interaction) into a decision diagram, we can efficiently (in the size of the MDD) compute valid domains during online interaction with a user. It is important to note that the order in which the user decides variables is completely unconstrained, i.e. it does not depend on the ordering of MDD variables. In our previous work we utilized Binary Decision Diagrams (BDDs) to represent all valid configurations so that CVD queries can be executed efficiently (Hadzic et al., 2004). Of course, BDDs might be exponentially large in the input CSP, but for many classes of constraints they are surprisingly compact."}, {"heading": "3. Interactive Cost Processing over MDDs", "text": "The main motivation for this work is extending the interactive configuration approach of M\u00f8ller et al. (2002), Hadzic et al. (2004), Subbarayan et al. (2004) to situations where in addition to a CSP model (X,D,F ) involving only hard constraints, there is also a cost function:\nc : D1 \u00d7 . . .\u00d7Dn \u2192 R.\nIn product configuration setting, this could be a product price. In uncertainty setting, the cost function might indicate a probability of an occurrence of an event represented by a\nsolution (failure of a hardware component, withdrawal of a bid in an auction etc.). In any decision support context, the cost function might indicate user preferences. There is a number of cost-related queries in which a user might be interested, e.g. finding an optimal solution, or computing a most probable explanation. We, however, assume that a user is interested in tight control of both the variable values as well as the cost of selected solutions. For example, a user might desire a specific option xi = a, but he would also care about how would such an assignment affect the cost of the remaining optimal solutions. We should communicate this information to the user, and allow him to strike the right balance between the cost and variable values by allowing him to interactively limit the maximal cost of the product in addition to assigning variable values. Therefore, in this paper we are primarily concerned with implementing a weighted CVD (wCVD) query: for a user-specified maximum cost K, we should indicate which values in the unassigned variable domains can be extended to a total assignment that is valid and costs less than K. From now on, we assume that a user is interested in bounding the maximal cost (limiting the minimal cost is symmetric).\nDefinition 4 (wCVD) Given a CSP model (X,D,F ), a cost function c : D \u2192 R and a maximal cost K, for a given partial assignment \u03c1 a weighted CVD (wCVD) query requires computation of the valid domains:\nVDi[\u03c1,K] = {a \u2208 Di | \u2203\u03c1\u2032.(\u03c1\u2032 |= F and \u03c1 \u222a {(xi, a)} \u2286 \u03c1\u2032 and c(\u03c1\u2032) \u2264 K)}\nIn this section we assume that an MDD representation of all CSP solutions is already generated in an offline compilation step. We postpone discussion of MDD compilation to Section 4 and discuss only delivering efficient online interaction on top of such MDD. We will first discuss the practicability of implementing wCVD queries through explicit encoding of costs into an MDD. We will then provide a practical and efficient approach to implementing wCVD over an MDD when the cost function is additive. Finally, we will discuss further extensions to handling more expressive cost functions."}, {"heading": "3.1 Handling Costs Explicitly", "text": "An immediate approach to interactively handling a cost function is to treat the cost as any other solution attribute, i.e. to add a variable y to variables X and add the constraint\ny = c(x1, . . . , xn) (1)\nto formulas F to enforce that y is equal to the total cost. The resulting configuration model is compiled into an MDD M \u2032 and a user is able to bound the cost by restricting the domain of y.\nAssuming the variable ordering x1 < . . . < xn in the original CSP model (X,D,F ), and assuming we inserted a cost variable into the i-th position, the new variable set X \u2032 has a variable ordering x\u20321 < . . . < x \u2032 n+1 s.t. x \u2032 1 = x1, . . . , x \u2032 i\u22121 = xi\u22121, x \u2032 i = y and x \u2032 i+1 = xi, . . . , x \u2032 n+1 = xn. The domain D \u2032 i of variable x \u2032 i is the set of all feasible costs C(Sol) = {c(s) | s \u2208 Sol}. We will now demonstrate that the MDD M \u2032 may be exponentially larger than M .\nLemma 1 |E\u2032i| \u2265 |C(Sol)|.\nProof 1 For the i-th layer of MDD M \u2032 corresponding to variable y, for each cost c \u2208 C(Sol) there must be at least one path p : r 1 with c(p) = c, and for such a path, an edge e \u2208 E\u2032i at the i-th layer must be labeled with v(e) = c. Hence, for each cost there must be at least one edge in E\u2032i. This proves the lemma.\nFurthermore, at least one of the layers of nodes V \u2032i , V \u2032 i+1 has a number of nodes greater\nthan \u221a |E\u2032i|. This follows from the following lemma:\nLemma 2 For the i-th layer of MDD M \u2032, |V \u2032i | \u00b7 |V \u2032i+1| \u2265 |E\u2032i|.\nProof 2 Since there are at most |V \u2032i |\u00b7|V \u2032i+1| pairs of nodes (u1, u2) \u2208 V \u2032i\u00d7V \u2032i+1, the statement follows from the fact that for each pair (u1, u2) there can be at most one edge e : u1 \u2192 u2. Namely, every solution p3 formed by concatenating paths p1 : r u1 and p2 : u2 1 has a unique cost c(p3). However, if there were two edges e1, e2 : u1 \u2192 u2, they would have to have different values v(e1) 6= v(e2). But then, the same solution c(p3) would correspond to two different costs v(e1), v(e2).\nFrom the above considerations we see that whenever the range of possible costs C(Sol) is exponential, the resulting MDD M \u2032 would be exponentially large as well. This would result in a significantly increased size |V \u2032|/|V |, particularly when there is a large number of isomorphic nodes in M that would become non-isomorphic once the variable y is introduced (since they root paths with different costs). An extreme instance of such a behavior is presented in Example 2. Furthermore, even if C(Sol) is not large, there could be orders of magnitude of increase in the size of M \u2032 due to breaking of isomorphic nodes in the MDD as will be empirically demonstrated in Section 6, Table 3, for a number of configuration instances. This is a major disadvantage as otherwise efficient CVD algorithms become unusable since they operate over a significantly larger structure.\nExample 2 Consider a model C(X,D,F ) with no constraints F = {}, and Boolean variables Dj = {0, 1}, j = 1 . . . , n. The solution space includes all assignments Sol = D1 \u00d7 . . . \u00d7 Dn and a corresponding MDD M(V,E) has one vertex and two edges at each layer, |V | = n+1, |E| = 2 \u00b7n. If we use the cost function: c(x1, . . . , xn) = \u2211n j=1 2\nj\u22121 \u00b7xj, there is an exponential number of feasible costs C(Sol) = {0, . . . , 2n \u2212 1}. Hence, |E\u2032i| \u2265 2n and for the i-th layer corresponding to variable y, at least one of the layers |V \u2032i |, |V \u2032i+1| is greater than \u221a 2n = 2n/2.\nHowever, if there was no significant node isomorphism in M , adding a y variable does not necessarily lead to a significant increase in size. An extreme instance of this is an MDD with no isomorphic nodes, for example when every edge is labeled with a unique value. For such an MDD, the number of non-terminal nodes is n \u00b7 |Sol|. By adding a cost variable y, the resulting MDD would add at most one node per path, leading to an MDD with at most (n+1) \u00b7 |Sol| nodes. This translates to a minor increase in size: |V \u2032|/|V | = (n+1)/n. This property will be empirically demonstrated in Section 6, Table 3, for product-catalogue datasets. In the remainder of this paper we develop techniques tailored for instances where a large increase in size occurs. We avoid explicit cost encoding and aim to exploit the structure of the cost function to implement wCVD."}, {"heading": "3.2 Processing Additive Cost Functions", "text": "One of the main contributions of this paper is a practical and efficient approach to deliver wCVD queries if the cost function is additive. An additive cost function has the form\nc(x1, . . . , xn) = n \u2211\ni=1\nci(xi)\nwhere a cost ci(ai) \u2208 R is assigned for every variable xi and every value in its domain ai \u2208 Di.\nAdditive functions are one of the most important and frequently used modeling constructs. A number of important combinatorial problems are modeled as integer linear programs where often both the constraints and the objective function are linear, i.e. represent special cases of additive cost functions. In multi-attribute utility theory user preferences are under certain assumptions aggregated into a single additive function through weighted summation of utilities of individual attributes. In a product configuration context, many properties are additive such as the memory capacity of a computer or the total weight. In particular, based on our experience in commercially applying configuration technology, the price of a product can often be modeled as the (weighted) sum of prices of individual parts."}, {"heading": "3.2.1 The Labeling Approach", "text": "Assuming that we are given an MDD representation of the solution space Sol and a cost function c, our approach to answering wCVD queries is based on three steps: 1) restricting MDD wrt. the latest user assignment, 2) labeling remaining nodes by executing shortest path algorithms and 3) filtering too expensive values by using node labels.\nRestricting MDD. We are given a user assignment xi = ai, where xi can be any of the unassigned variables, regardless of its position in the MDD variable ordering. We initialize MDD pruning by removing all edges e(u, u\u2032, a), that are not in agreement with the latest assignment, i.e. where var(u) = i and a 6= ai. This might cause a number of other edges and nodes to become unreachable from the terminal or the root if we removed the last edge in the set of children edges Ch(u) or parent edges P (u\u2032). Any unreachable edge must be removed as well. The pruning is repeated until a fixpoint is reached, i.e. until no more nodes or edges can be removed. Algorithm 1 implements this scheme in O(|V |+ |E|) time and space by using a queue Q to maintain the set of edges that are yet to be removed.\nNote that unassigning a user assignment xi = ai can be easily implemented in linear time as well. It suffices to restore a copy of the initial MDD M , and perform restriction wrt. a partial assignment \u03c1 \\ {(xi, ai)} where \u03c1 is a current assignment. Algorithm 1 is easily extended for this purpose by initializing the edge removal list Q with edges incompatible wrt. any of the assignments in \u03c1. Computing Node Labels. Remaining edges e(u, u\u2032, a) in each layer Ei are implicitly labeled with c(e) = ci(a). In the second step we compute for each MDD node u \u2208 V an upstream cost of the shortest path from the root r to u, denoted as U [u], and a downstream cost of the shortest path from u to the terminal 1, denoted as D[u]:\nU [u] = min p:r u\n{\n\u2211\ne\u2208p\nc(e)\n}\n, D[u] = min p:u 1\n{\n\u2211\ne\u2208p\nc(e)\n}\n(2)\nAlgorithm 1: Restrict MDD. Data: MDD M(V,E), variable xi, value ai foreach e \u2208 Ei, v(e) 6= ai do\nQ.push(e);\nwhile Q 6= \u2205 do e(u, u\u2032, a)\u2190 Q.pop(); delete e from M ; if Ch(u) = \u2205 then\nforeach e : u\u2032\u2032 \u2192 u do Q.push(e);\nif P (u\u2032) = \u2205 then foreach e : u\u2032 \u2192 u\u2032\u2032 do\nQ.push(e);\nAlgorithm 2 computes U [u] and D[u] labels in \u0398(|V |+ |E|) time and space.\nAlgorithm 2: Update U,D labels. Data: MDD M(V,E), Cost function c D[\u00b7] =\u221e, D[1] = 0; foreach i = n, . . . , 1 do\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nD[u] = min{D[u], c(e) +D[u\u2032]}\nU [\u00b7] =\u221e, U [r] = 0; foreach i = 1, . . . , n do\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nU [u\u2032] = min{U [u\u2032], c(e) + U [u]}\nComputing Valid Domains. Once the upstream and downstream costs U,D are computed, we can efficiently compute valid domains VDi wrt. any maximal cost bound K since: VDi[K] = {v(e) | U [u] + c(e) +D[u\u2032] \u2264 K, e : u\u2192 u\u2032, u \u2208 Vi} (3) This can be achieved in a linear-time traversal \u0398(|V |+ |E|) as shown in Algorithm 3.\nAlgorithm 3: Compute valid domains. Data: MDD M(V,E), Cost function c, Maximal cost K foreach i = 1, . . . , n do\nV Di = \u2205; foreach u \u2208 Vi do\nforeach e : u\u2192 u\u2032 do if U [u] + c[e] +D[u\u2032] \u2264 K then\nV Di \u2190 V Di \u222a {v(e)};\nHence the overall interaction is as follows. Given a current partial assignment \u03c1, MDD is restricted wrt. \u03c1 through Algorithm 1. Labels U,D are then computed through Algorithm 2 and valid domains are computed using Algorithm 3. The execution of all of these algorithms\nrequires \u0398(|V |+ |E|) time and space. Hence, when an MDD representation of the solution space is available, we can interactively enforce additive cost restrictions in linear time and space."}, {"heading": "3.3 Processing Additive Costs Over Long Edges", "text": "Our scheme can be extended to MDDs containing long edges. While for multivalued CSP models with large domains space savings due to long edges might not be significant, for binary models and binary decision diagrams (BDDs) more significant savings are possible. Furthermore, in a similar fashion, our scheme might be adopted over other versions of decision diagrams that contain long edges (with different semantics) such as zero-suppressed BDDs where a long edge implies that all skipped variables are assigned 0.\nRecall that in reduced MDDs, redundant nodes u \u2208 Vi which have Di outgoing edges, each pointing to the same node u\u2032, are eliminated. An edge e(u, u\u2032, a) with var(u) = k and var(u\u2032) = l is long if k + 1 < l, and in this case, e encodes a set of solutions: {a} \u00d7 Dk+1 \u00d7 . . . \u00d7 Dl\u22121. The labeling of edges can be generalized to accommodate such edges as well. Let domains D\u2032j , j = 1, . . . , n represent variable domains updated wrt. the current assignment, i.e. D\u2032j = Dj if xj is unassigned, and D \u2032 j = {\u03c1[xj ]} otherwise. An edge e(u, u\u2032, a), (var(u) = k, var(u\u2032) = l) is removed if a 6\u2208 D\u2032k in an analogous way to the MDD pruning in the previous subsection. Otherwise, it is labeled with\nc(e) = ck(a) +\nl\u22121 \u2211\nj=k+1\nmin a\u2032\u2208D\u2032j\ncj(a \u2032) (4)\nwhich is the cost of the cheapest assignment to xk, . . . , xl\u22121 consistent with the edge and the partial assignment \u03c1. Once the edges are labeled, the upstream and downstream costs U,D are computed in \u0398(|V |+ |E|) time, in the same manner as in the previous subsection.\nHowever, computing valid domains has to be extended. As before, a sufficient condition for a \u2208 VD i is the existence of an edge e : u\u2192 u\u2032, originating in the i-th layer u \u2208 Vi such that v(e) = a and U [u] + c[e] +D[u\u2032] \u2264 K. (5) However, this is no longer a necessary condition, as even if there is no edge satisfying (5), there could exist a long edge skipping the i-th layer that still allows a \u2208 VD i. We therefore, for each layer i, have to compute the cost of the cheapest path skipping the layer:\nP [i] = min{U [u] + c(e) +D[u\u2032] | e : u\u2192 u\u2032 \u2208 E, var(u) < i < var(u\u2032)} (6)\nIf there is no edge skipping the i-th layer, we set P [i] =\u221e. Let cmin[i] denote the cheapest value in D\u2032i, i.e. cmin[i] = mina\u2208D\u2032i ci(a). To determine if there is a long edge allowing a \u2208 VD i, for an unassigned variable xi, the following must hold:\nP [i] + ci(a)\u2212 cmin[i] \u2264 K (7)\nFinally, a sufficient and necessary condition for a \u2208 VD i is that one of the conditions (5) and (7) holds. If variable xi is assigned with a value drawn from a valid domain in a previous step, we are guaranteed that V Di = {\u03c1[xi]} and no calculations are necessary. Labels P [i]\nAlgorithm 4: Update P labels. Data: MDD M(V,E), Cost function c P [\u00b7] =\u221e; foreach i = 1, . . . , n do\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nforeach j \u2208 {var(u) + 1, . . . , var(u\u2032)\u2212 1} do P [j] = min{P [j], U [u] + c(e) +D[u\u2032]};\ncan be computed by Algorithm 4 in worst-case O(|E| \u00b7 n) time. Note that this bound is over-pessimistic as it assumes that every edge in |E| is skipping every variable in X.\nOnce the auxiliary structures U,D, P are computed, valid domains can be efficiently extracted using Algorithm 5. For each unassigned variable xi, value a \u2208 Di is in a valid domain VDi[K] iff the following holds: condition (7) is satisfied or for an edge e(u, u\n\u2032, a) \u2208 E condition (5) is satisfied. For each non-assigned variable i, the algorithm first checks for each value a \u2208 Di whether it is supported by a skipping edge P [i]. Afterwards, it scans the i-th layer and extracts values supported by edges Ei. This is achieved in \u0398(|D|+ |V |+ |E|) time, where |D| = \u2211ni=1 |Di|.\nAlgorithm 5: Computing valid domains V Di. Data: MDD M(V,E), cost function C, maximal cost K foreach i = 1, . . . , n do\nV Di = \u2205; if xi assigned to ai then\nV Di \u2190 {ai}; continue;\nforeach a \u2208 Di do if P [i] + ci(a)\u2212 cmin[i] \u2264 K then\nV Di \u2190 V Di \u222a {a};\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nif U [u] + c[e] +D[u\u2032] \u2264 K then V Di \u2190 V Di \u222a {v(e)};\nAgain, the overall interaction remains the same. Labels P can be incrementally updated in worst case O(|E| \u00b7 n) time. Valid domains are then extracted in \u0398(|D|+ |V |+ |E|) time. In response to changing a cost restriction K, auxiliary labels need not be updated. Valid domains are extracted directly using Algorithm 5 in \u0398(|D|+ |V |+ |E|) time."}, {"heading": "3.4 Handling Non-Additive Cost Functions", "text": "In certain interaction settings, the cost function is not additive. For example, user preferences might depend on an entire package of features rather than a selection of each individual feature. Similarly, the price of a product need not be a simple sum of costs of individual parts, but might depend on combinations of parts that are selected. In general, our cost\nfunction c(x1, . . . , xn) might be a sum of non-unary cost functions ci, i = 1, . . . , k,\nc(x1, . . . , xn) = k \u2211\ni=1\nci(Xi)\nwhere each cost function ci expresses a unique contribution of combination of features within a subset of variables Xi \u2286 X,\nci : \u220f\nj\u2208Xi\nDj \u2192 R."}, {"heading": "3.4.1 Non-Unary Labeling", "text": "Our approach can be extended to handle non-unary costs by adopting labeling techniques that are used with other graphical representations (e.g., Wilson, 2005; Mateescu et al., 2008). Assume we are given a cost function c(x1, . . . , xn) = \u2211k i=1 ci(Xi). Let A(i) denote the set of all cost functions cj such that xi is the last variable in the scope of cj :\nA(i) = {cj | xi \u2208 Xj and xi\u2032 6\u2208 Xj ,\u2200i\u2032 > i}.\nGiven assignment a(a1, . . . , ai) to variables x1, . . . , xi, we can evaluate every function cj \u2208 Ai. If the scope of cj is a strict subset of {x1, . . . , xi}, we set cj(a) to be the value of cj(\u03c0Xj (a)) where \u03c0Xj (a) is a projection of a onto Xj . Now, for every path p : r u, u \u2208 Vi+1, and its last edge (in the i-th layer) e \u2208 Ei, we label e with the sum of all cost functions that have become completely instantiated after assigning xi = ai:\nc(e, p) = \u2211\ncj\u2208A(i)\ncj(p). (8)\nWith respect to such labeling, a cost of a solution represented by a path p would indeed be the sum of costs of its edges: \u2211\ne\u2208p c(e, p). In order to apply our approach developed for additive cost functions in Section 3.2, each edge should be labeled with a cost that is the same for any incoming path. However, this is not possible in general. We therefore have to expand the original MDD, by creating multiple copies of e and splitting incoming paths to ensure that any two paths p1, p2 sharing a copy e\n\u2032 of an edge e induce the same edge cost c(e\u2032, p1) = c(e\n\u2032, p2). Such an MDD, denoted as Mc, can be generated using for example search with caching isomorphic nodes as suggested by Wilson (2005), or by extending the standard apply operator to handle weights as suggested by Mateescu et al. (2008)."}, {"heading": "3.4.2 Impact on the Size", "text": "The increase in size of Mc relatively to the cost-oblivious version M depends on the \u201dadditivity\u201d of the cost function c. For example, for fully additive cost functions (each scope Xi contains a single variable) Mc = M , since a label on c(e) is the same regardless of the incoming path. However, if the entire cost function c is a single non-additive component c1(X1) with global scope (X1 = X), then only the edges in the last MDD layer are labeled, as in the case of explicit cost encoding into MDD from Section 3.1. There must be at least C(Sol) edges in the last layer, one for each feasible cost. Hence, if the range of costs C(Sol)\nis exponential, so is the size of Mc. Furthermore, even if C(Sol) is of limited size, an increase in Mc might be significant due to breakup of node isomorphisms in previous layers. In case of explicit cost encoding (Section 3.1) such an effect is demonstrated empirically in Section 6. A similar effect on the size would occur in other graphical-representations. For example, in representations exploiting global CSP structure - such as weighted cluster trees (Pargamin, 2003) - adding non-additive cost functions increases the size of the clusters, as it is required that for each non-additive component ci(Xi) at least one cluster contains the entire scope Xi. Furthermore, criteria for node merging of Wilson (2005) and Mateescu et al. (2008) are more refined, since nodes are no longer isomorphic if they root the same set of feasible paths, but the paths must be of the same cost as well."}, {"heading": "3.4.3 Semiring Costs and Probabilistic Queries", "text": "Note that our approach can be further generalized to accommodate more general aggregation of costs as discussed by Wilson (2005). Cost functions ci need not map assignments of Xi variables into the set of real numbers R but to any set A equipped with operators \u2295,\u2297 such that A = (A,0,1,\u2295,\u2297) is a semiring. The MDD property that is computed is \u2295p:r 1\u2297e\u2208p c(e). Operator \u2297 aggregates edge costs while operator \u2295 aggregates path costs. In a semiring \u2295 distributes over \u2297, and the global computation can be done efficiently by local node-based aggregations, much as a shortest path is computed. Our framework is based on reasoning about paths of minimal cost which corresponds to using A = (R+, 0, 1,min,+) but different semirings could be used. In particular, by taking A = (R+, 0, 1,+,\u00d7) we can handle probabilistic reasoning. Each cost function ci corresponds to a conditional probability table, the cost of an edge c(e), e : u \u2192 u\u2032 \u2208 Ei corresponds to the probability of P (xi = v(e)) given any of the assignments p : r u. The cost of a path c(p) = \u220f\ne\u2208p c(e) is a probability of an event represented by the path, and for a given value a \u2208 Di we can get the marginal probability of P (xi = a) by computing \u2211\ne(u,u\u2032,a)\u2208Ei (U [u]\u00d7 c(e)\u00d7D[u\u2032])."}, {"heading": "4. Compiling MDDs", "text": "In the previous section we showed how to implement cost queries once the solution space is represented as an MDD. In this section, we discuss how to generate such MDDs from a CSP model description (X,D,F ). Our goal is to develop an efficient and easy to implement approach that can handle all instances handled previously through BDD-based configuration (Hadzic et al., 2004).\nVariable Ordering. The first step is to choose an ordering for CSP variables X. This is critical since different variable orders could lead to exponential differences in MDD size. This is a well investigated problem, especially for binary decision diagrams. For a fixed formula, deciding if there is an ordering such that the resulting BDD would have at most T nodes (for some threshold T ) is an NP-hard problem (Bollig & Wegener, 1996). However, there are well developed heuristics, that either exploit the structure of the input model or use variable swapping in existing BDD to improve the ordering in a local-search manner (Meinel & Theobald, 1998). For example, fan-in and weight heuristics are popular when the input is in the form of a combinational circuits. If the input is a CSP, a reasonable heuristic is to choose an ordering that minimizes the path-width of the corresponding constraint graph,\nas an MDD is in worst case exponential in the path-width (Bodlaender, 1993; Wilson, 2005; Mateescu et al., 2008). Investigating heuristics for variable ordering is out of the scope of our work, and in the remainder of this paper we assume that the ordering is already given. In all experiments we use default orderings provided for the instances.\nCompilation Technique. Our approach is to first compile a CSP model into a binary decision diagrams (BDD) by exploiting highly optimized and stable BDD packages (e.g., Somenzi, 1996) and afterwards extract the corresponding MDD. Dedicated MDD packages are rare, provide limited functionality and their implementations are not as optimized as BDD packages to offer competitive performance (Miller & Drechsler, 2002). An interesting recent alternative is to generate BDDs through search with caching isomorphic nodes. Such an approach was suggested by Huang and Darwiche (2004) to compile BDDs from CNF formulas, and it proved to be a valuable addition to standard compilation based on pairwise BDD conjunctions. However, such compilation technology is still in the early stages of development and an open-source implementation is not publicly available."}, {"heading": "4.1 BDD Encoding", "text": "Regardless of the BDD compilation method, the finite domain CSP variables X first have to be encoded by Boolean variables. Choosing a proper encoding is important since the intermediate BDD might be too large or inadequate for subsequent extraction. In general, each CSP variable xi would be encoded with ki Boolean variables {xi1, . . . , xiki}. Each a \u2208 Di has to be mapped into a bit vector enci(a) = (a1, . . . , aki) \u2208 {0, 1}ki such that for different values a 6= a\u2032 we get different vectors enci(a) 6= enci(a\u2032). There are several standard Boolean encodings of multi-valued variables (Walsh, 2000). In the log encoding scheme each xi is encoded with ki = dlog|Di|e Boolean variables, each representing a digit in binary notation. A multivalued assignment xi = a is translated into a set of assignments x i j = aj such that a = \u2211ki\nj=1 2 j\u22121aj . Additionally, a domain constraint \u2211ki j=1 2 j\u22121xij < |Di| is added to forbid those bit assignments (ai1, . . . , a i ki ) that encode values outside domain Di. The direct encoding (or 1-hot encoding) is also common, and especially well suited for efficient propagation when searching for a single solution. In this scheme, each multi-valued variable xi is encoded with |Di| Boolean variables {xi1, . . . , xiki}, where each variable x i j indicates whether the j-th value in domain aj \u2208 Di is assigned. For each variable xi, exactly one value fromDi has to be assigned. Therefore, we enforce a domain constraint x i 1+. . .+x i ki\n= 1 for each i = 1, . . . , n. Hadzic, Hansen, and O\u2019Sullivan (2008) have empirically demonstrated that using log encoding rather than direct encoding yields smaller BDDs.\nThe set of Boolean variables is fixed as the union of all encoding variables, Xb = \u22c3n\ni=1{xi1, . . . , xiki} but we still have to specify the ordering. A common ordering that is well suited for efficiently answering configuration queries is clustered ordering. Here, Boolean variables {xi1, . . . , xiki} are grouped into blocks that respect the ordering among finite-domain variables x1 < . . . < xn. That is,\nxi1j1 < x i2 j2 \u21d4 i1 < i2 \u2228 (i1 = i2 \u2227 j1 < j2).\nThere might be other orderings that yield smaller BDDs for specific classes of constraints. Bartzis and Bultan (2003) have shown that linear arithmetic constraints can be represented\nmore compactly if Boolean variables xij are grouped wrt. bit-position j rather than the finite-domain variable xi, i.e. x i1 j1\n< xi2j2 \u21d4 j1 < j2 \u2228 (j1 = j2 \u2227 i1 < i2). However, configuration constraints involve not only linear arithmetic constraints, and space savings reported by Bartzis and Bultan (2003) are significant only when all the variable domains have a size that is a power of two. Furthermore, clustered orderings yield BDDs that preserve essentially the same combinatorial structure which allows us to extract MDDs efficiently as will be seen in Section 4.2.\nExample 3 Recall that in the T-shirt example D1 = {0, 1, 2, 3}, D2 = {0, 1, 2}, D3 = {0, 1}. The log encoding variables are x11 < x12 < x21 < x22 < x31, inducing a variable set Xb = {1, 2, 3, 4, 5}. The log-BDD with clustered variable ordering is shown in Figure 4(a). \u2666"}, {"heading": "4.2 MDD Extraction", "text": "Once the BDD is generated using clustered variable ordering we can extract a corresponding MDD using a method which was originally suggested by Hadzic and Andersen (2006) and that was subsequently expanded by Hadzic et al. (2008). In the following considerations, we will use a mapping cvar(xij) = i to denote the CSP variable xi of an encoding variable xij and, with a slight abuse of notation, we will apply cvar also to BDD nodes u labeled with xij . For terminal nodes, we define cvar(0) = cvar(1) = n+1 (recall that BDD has two terminal nodes 0 and 1 indicating false and true respectively). Analogously, we will use a mapping pos(xij) = j to denote the position of a bit that the variable is encoding.\nOur method is based on recognizing a subset of BDD nodes that captures the core of the MDD structure, and that can be used directly to construct the corresponding MDD.\nIn each block of BDD layers corresponding to a CSP variable xi, Li = Vxi 1 \u222a . . . \u222a Vxi ki , it suffices to consider only those nodes that are reachable by an edge from a previous block of layers: Ini = {u \u2208 Li | \u2203(u\u2032,u)\u2208E cvar(u\u2032) < cvar(u)}. For the first layer we take In1 = {r}. The resulting MDD M(V \u2032, E\u2032) M contains only nodes in Ini, V \u2032 = \u22c3n+1 i=1 Ini and is constructed using extraction Algorithm 6. An edge e(u, u \u2032, a) is added to E\u2032 whenever traversing BDD B from u wrt. encoding of a ends in u\u2032 6= 0. Traversals are executed using Algorithm 7. Starting from u, in each step the algorithm traverses BDD by taking the low branch when corresponding bit ai = 0 or high branch when ai = 1. Traversal takes at most ki steps, terminating as soon as it reaches a node labeled with a different CSP variable. The MDD extracted from a log-BDD in Figure 4(a) is shown in Figure 4(b).\nAlgorithm 6: Extract MDD. Data: BDD B(V,E) E\u2032 \u2190 {},V \u2032 \u2190 {r}; foreach i = 1, . . . , n do\nforeach u \u2208 Ini do foreach a \u2208 Di do\nu\u2032 \u2190 Traverse(u, a);1 if u\u2032 6= 0 then\nE\u2032 \u2190 E\u2032 \u222a {(u, u\u2032, a)}; V \u2032 \u2190 V \u2032 \u222a {u\u2032}\nreturn (V \u2032, E\u2032);\nAlgorithm 7: Traverse BDD. Data: BDD B(V,E), u, a i\u2190 cvar(u); (a1, . . . , aki)\u2190 enci(v); repeat\ns\u2190 pos(u); if as = 0 then\nu\u2190 low(u);\nelse u\u2190 high(u);\nuntil cvar(u) 6= i ; return u;\nSince each traversal (in line 1 of Algorithm 6) takes O(dlog|Di|e) steps, the running time for the MDD extraction is O(\n\u2211n i=1 |Ini| \u00b7 |Di| \u00b7 dlog|Di|e). The resulting MDD M(V \u2032, E\u2032)\nhas at most O( \u2211n i=1 |Ini| \u00b7 |Di|) edges because we add at most |Di| edges for every node u \u2208 Ini. Since we keep only nodes in Ini, |V \u2032| = \u2211n i=1 |Ini| \u2264 |V |."}, {"heading": "4.3 Input Model and Implementation Details", "text": "An important factor for usability of our approach is the easiness of specifying the input CSP model. BDD packages are callable libraries with no default support for CSP-like input language. To the best of our knowledge, the only open-source BDD-compilation tool that\naccepts as an input a CSP-like model is CLab (Jensen, 2007). It is a configuration interface on top of a BDD package BuDDy (Lind-Nielsen, 2001). CLab constructs a BDD for each input constraint and conjoins them to get the final BDD. Furthermore CLab generates a BDD using log-encoding with clustered ordering which suits well our extraction approach. Therefore, our compilation approach is based on using CLab to specify the input model and generate a BDD that will be used by our extraction Algorithm 6.\nNote that after extracting the MDD, we preprocess it for efficient online querying. We expand the long edges and merge isomorphic nodes to get a merged MDD. We then translate it into a more efficient form for online processing. We rename BDD node names to indexes from 0, . . . , |V |, where root has index 0 and terminal 1 has index |V |. This allows for subsequent efficient implementation of U and D labels, as well as an efficient access to children and parent edges of each node. In our initial experiments we got an order of magnitude speed-up of wCVD queries after we switched from BDD node names (which required using less efficient mapping for U , D, Ch and P structures)."}, {"heading": "5. Interactive Configuration With Multiple Costs", "text": "In a number of domains, a user should configure in the presence of multiple cost functions which express often conflicting objectives that a user wants to achieve simultaneously. For example, when configuring a product, a user wants to minimize the price, while maximizing the quality, reducing the ecological impact, shortening delivery time etc. We assume therefore that in addition to the CSP model (X,D,F ) whose solution space is represented by a merged MDD M , we are given k additive cost functions\nci(x1, . . . , xn) = n \u2211\nj=1\ncij(xi), i = 1 . . . , k\nexpressing multiple objectives. Multi-cost scenarios are often considered within the multicriteria optimization framework (Figueira et al., 2005; Ehrgott & Gandibleux, 2000). It is usually assumed that there is an optimal (but unknown) way to aggregate multiple objectives into a single objective function that would lead to a solution that achieves the best balance in satisfying various objectives. The algorithms sample few efficient solutions (nondominated wrt. objective criteria) and display them to the user. Through user input, the algorithms learn how to aggregate objectives more adequately which is then used for the next sampling of efficient solutions etc. In some approaches a user is asked to explicitly assign weights wi to objectives ci which are then aggregated through weighted summation c =\n\u2211k i=1wici.\nWhile adopting these techniques to run over a compiled representation of solution space would immediately improve their complexity guarantees and would be useful in many scenarios where multi-criteria techniques are traditionally used, we believe that in a configuration setting, a more explicit control over variable values is needed. A user should easily explore the effect of assigning various variable values on other variables as well as cost functions. We therefore suggest to directly extend our wCVD query so that a user could explore the effect of cost restrictions in the same way he explores interactions between regular variables. The key query that we want to deliver is computing valid domains wrt. multiple cost restrictions:\nDefinition 5 (k-wCVD) Given a CSP model (X,D,F ), additive cost functions cj : D \u2192 R, and maximal costs Kj, j = 1, . . . , k, for a given partial assignment \u03c1, compute:\nVD i[\u03c1, {Kj}kj=1] = {a \u2208 Di | \u2203\u03c1\u2032.(\u03c1\u2032 |= F and \u03c1 \u222a {(xi, a)} \u2286 \u03c1\u2032 and k \u2227\nj=1\ncj(\u03c1 \u2032) \u2264 Kj)}\nWe are particularly interested in two-cost configuration as it is more likely to occur in practice and has strong connections to existing research in solving Knapsack problems and multi-criteria optimization. In the reminder of the section we will first discuss the complexity of 2-wCVD queries and then develop a practical implementation approach. We will then discuss the general k-wCVD query.\n5.1 Complexity of 2-wCVD query\nWe assume that as an input to the problem we have a merged MDD M , additive cost functions c1, c2 and cost bounds K1,K2. The first question is whether it is possible for some restricted forms of additive cost functions c1, c2 to implement 2-wCVD in polynomial time. For this purpose we formulate a decision-version of the 2-wCVD problem:\nProblem 1 (2-wCVD-SAT) Given CSP (X,D,F ) and MDD M representation of its solution space, and given two additive cost functions ci(x) = \u2211n j=1 cij(xj), i = 1, 2 with cost restrictions K1,K2, decide whether F \u2227 c1(x) \u2264 K1 \u2227 c2(x) \u2264 K2 is satisfiable.\nUnfortunately, the answer is no even if both constraints involve only positive coefficients, and have binary domains. To show this we reduce from the well-known Two-Partition Problem (TPP) which is NP-hard (Garey & Johnson, 1979). For a given set of positive integers S = {s1, . . . , sn}, the TPP asks to decide whether it is possible to split a set of indexes I = {1, . . . , n} into two sets A and I \\A such that the sum in each set is the same: \u2211\ni\u2208A si = \u2211 i\u2208I\\A si.\nProposition 3 The 2-wCVD-SAT problem defined over Boolean variables and involving only linear cost functions with positive coefficients is NP-hard.\nProof 3 We show the stated by reduction from TPP. In order to reduce TPP to two-cost configuration we introduce 2n binary variables x1, . . . , x2n such that i \u2208 A if and only if x2i\u22121 = 1 and i \u2208 A \\ I if and only if x2i = 1. We construct an MDD for F = {x1 6= x2, . . . , x2n\u22121 6= x2n} and introduce two linear cost functions with positive coefficients, c1(x) = \u2211n i=1 si \u00b7 x2i\u22121 and c2(x) = \u2211n i=1 si \u00b7 x2i. The overall capacity constraints are set to K1 = K2 = \u2211\ni\u2208I si/2. By setting A = {i \u2208 I | x2i\u22121 = 1} it is easily seen that F \u2227 c1(x) \u2264 K1 \u2227 c2(x) \u2264 K2 is satisfiable if and only if the TPP has a feasible solution. Hence, if we were able to solve 2-wCVD-SAT with Boolean variables and positive linear cost functions in polynomial time, we would also be able to solve the TPP problem polynomially.\n5.2 Pseudo-Polynomial Scheme for 2-wCVD\nIn the previous subsection we demonstrated that answering 2-wCVD queries is NP-hard even for the simplest class of positive linear cost functions over Boolean domains. Hence, there\nis no hope of solving 2-wCVD with guaranteed polynomial execution time unless P = NP . However, we still want to provide a practical solution to the 2-wCVD problem. We hope to avoid worst-case performance by exploiting the specific nature of the cost-functions we are processing. In this subsection we therefore show that 2-wCVD can be solved in pseudopolynomial time by extending our labeling approach from Section 3.2. Furthermore, we show how to adopt advanced techniques used for the Knapsack problem (Kellerer, Pferschy, & Pisinger, 2004)."}, {"heading": "5.2.1 Overall Approach", "text": "Our algorithm runs analogous to the single-cost approach developed in Section 3.2. After restricting the MDD wrt. a current assignment, we calculate upstream and downstream costs U,D (which are no longer constants but lists of tuples), and use them to check for each edge e, whether v(e) is in a valid domain.\nFor a given edge e : u \u2192 u\u2032, labeled with costs c1(e), c2(e), it follows v(e) \u2208 V Di iff there are paths p : r u, and p\u2032 : u\u2032 1 such that c1(p) + c1(e) + c1(p\n\u2032) \u2264 K1 and c2(p) + c2(e) + c2(p \u2032) \u2264 K2. At each node u it suffices to store two sets of labels:\nU [u] = {(c1(p), c2(p)) | p : r u}\nD[u] = {(c1(p), c2(p)) | p : u 1} Then, for given cost restrictionsK1,K2, and an edge e : u\u2192 u\u2032, u \u2208 Vi, domain V Di[K1,K2] contains v(e) if for some (a1, a2) \u2208 U [u] and (b1, b2) \u2208 D[u] it holds\na1 + c1(e) + b1 \u2264 K1 \u2227 a2 + c2(e) + b2 \u2264 K2 (9)"}, {"heading": "5.2.2 Exploiting Pareto Optimality", "text": "While in the single-cost case it was sufficient to store at U [u], D[u] only the minimal value (the cost of the shortest path to root/terminal), in multi-cost case we need to store multiple tuples. The immediate extension would require storing at most K1 \u00b7K2 tuples at each node. However, we need to store only non-dominated tuples in U and D lists. If there are two tuples (a1, a2) and (a \u2032 1, a \u2032 2) in the same list such that\na1 \u2264 a\u20321 and a2 \u2264 a\u20322\nthen we may delete (a\u20321, a \u2032 2) as if test (9) succeeds for (a \u2032 1, a \u2032 2) it will also succeed for (a1, a2). The remaining entries are the costs of pareto-optimal solutions. A solution is pareto-optimal wrt. solution set S and cost functions c1, c2 if it is not possible to find a cheaper solution in S with respect to one cost without increasing the other. Path p : r 1 represents a pareto-optimal solution in Sol iff for each node u on the path, both sub-paths p1 : r u and p2 : u 1 are pareto-optimal wrt. the sets of paths {p : r u} and {p : u 1} respectively. Hence, for each node u it suffices to store:\nU [u] = {(c1(p), c2(p)) | p : r u, \u2200p\u2032:r u(c1(p) \u2264 c1(p\u2032) \u2228 (c2(p) \u2264 c2(p\u2032))}\nD[u] = {(c1(p), c2(p)) | p : u 1,\u2200p\u2032:u 1(c1(p) \u2264 c1(p\u2032) \u2228 (c2(p) \u2264 c2(p\u2032))}\nNote that due to pareto-optimality, for each a1 \u2208 {0, . . . ,K1} and each a2 \u2208 {0, . . . ,K2} there can be at most one tuple in U or D where the first coordinate is a1 or the second coordinate is a2. Therefore, for each node u, U [u] and D[u] can have at most min{K1,K2} entries. Hence, the space requirements of our algorithmic scheme are in worst case O(|V |\u00b7K) where K = min{K1,K2}."}, {"heading": "5.2.3 Computing U and D Sets", "text": "We will now discuss how to compute the U and D sets efficiently by utilizing advanced techniques for solving Knapsack problems (Kellerer et al., 2004). We recursively update U and D sets in a layer by layer manner as shown in Algorithm 8. The critical component of each recursion step in the algorithm is merging lists in lines 2 and 4. In this operation a new list is formed such that all dominated tuples are detected and eliminated. In order to do this efficiently, it is critical to keep both U and D lists sorted wrt. the first coordinate, i.e.\n(a1, a2) \u227a (a\u20321, a\u20322) \u2261 a1 < a2.\nIf U and D are sorted, they can be merged in O(K) time using the list-merging algorithm for Knapsack optimization from (Kellerer et al., 2004, Section 3.4).\nAlgorithm 8: Update U,D labels.\nData: MDD M , Cost functions c1, c2, Bounds K1, K2 U [\u00b7] = {(\u221e,\u221e)}, U [r] = {(0, 0)}; foreach i = 1, . . . , n do\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nS \u2190 \u2205; foreach (a1, a2) \u2208 U [u] do\nif a1 + c1(e) \u2264 K1 \u2227 a2 + c2(e) \u2264 K2 then S \u2190 S \u222a (a1 + c1(e), a2 + c2(e));1\nU [u\u2032]\u2190MergeLists(S,U [u\u2032]);2\nD[\u00b7] = {(\u221e,\u221e)}, D[1] = {(0, 0)}; foreach i = n, . . . , 1 do\nforeach u \u2208 Vi do foreach e : u\u2192 u\u2032 do\nS \u2190 \u2205; foreach (a1, a2) \u2208 D[u\u2032] do\nif a1 + c1(e) \u2264 K1 \u2227 a2 + c2(e) \u2264 K2 then S \u2190 S \u222a (a1 + c1(e), a2 + c2(e));3\nD[u]\u2190MergeLists(S,D[u]);4\nThe time complexity is determined by populating list S (in lines 1 and 3) and merging (in lines 2 and 4). Each of these updates takes O(K) in worst case. Since we perform these updates for each edge e \u2208 E, the total time complexity of Algorithm 8 is O(|E| \u00b7K) in the worst case."}, {"heading": "5.2.4 Valid Domains Computation", "text": "Once the U,D sets are updated we can extract valid domains in a straightforward manner using Algorithm 9. For each edge e : u\u2192 u\u2032 the algorithm evaluates whether v(e) \u2208 V Di in worst case O(|U [u]| \u00b7 |D[u\u2032]|) = O(K2) steps. Hence, valid domain extraction takes in worst case O(|E| \u00b7K2) steps.\nAlgorithm 9: Compute valid domains.\nData: MDD M , Cost functions c1, c2, Cost bounds K1,K2, Labels U ,D foreach i = 1, . . . , n do\nVDi \u2190 \u2205; foreach u \u2208 Vi do\nforeach e : u\u2192 u\u2032 do foreach (a1, a2) \u2208 U [u], (b1, b2) \u2208 D[u\u2032] do\nif a1 + c1(e) + b1 \u2264 K1 \u2227 a2 + c2(e) + b2 \u2264 K2 then VDi \u2190 VDi \u222a {v(e)}; break;\nHowever, we can improve the running time of valid domains computation by exploiting (1) pareto-optimality and (2) the fact that the sets U,D are sorted. It is critical to observe that given an edge e : u \u2192 u\u2032, for each (a1, a2) \u2208 U [u] it suffices to perform the validity test (9) only for a tuple (b\u22171, b \u2217 2) \u2208 D[u\u2032], where b\u22171 is a maximal first coordinate satisfying a1 + c1(e) + b1 \u2264 K1, i.e. b\u22171 = max{b1 | (b1, b2) \u2208 D[u\u2032], a1 + c1(e) + b1 \u2264 K1}.\nNamely, if the test succeeds for some (b\u20321, b \u2032 2) where b \u2032 1 < b \u2217 1, it will also succeed for (b \u2217 1, b \u2217 2) since due to pareto-optimality, b\u20321 < b \u2217 1 \u21d2 b\u22172 < b\u20322 and hence a2+c2(e)+b\u22172 < a2+c2(e)+b\u20322 \u2264 K2. Since the lists are sorted, comparing all relevant tuples can be performed efficiently by traversing U [u] in increasing order, while traversing D[u\u2032] in decreasing order. Algorithm 10 implements the procedure.\nAlgorithm 10: Extract edge value.\nData: MDD M , Cost constraints c1, c2, Bounds K1, K2, Edge e : u\u2192 u\u2032 in Ei a(a1, a2) = U [u].begin(); b(b1, b2) = D[u\n\u2032].end(); while a 6= > \u2227 b 6= \u22a5 do\nif a1 + c1(e) + b1 > K1 then b(b1, b2)\u2190 D[u\u2032].previous(); continue;\nelse if a1 + c1(e) + b1 \u2264 K1 \u2227 a2 + c2(e) + b2 \u2264 K2 then1 VDi \u2190 VDi \u222a {v(e)}; return;2\na(a1, a2)\u2190 U [u].next();\nThe algorithm relies on several list operations. Given list L of sorted tuples, operations L.begin() and L.end() return the first and the last tuple respectively wrt. the list ordering.\nOperations L.next() and L.previous() return the next and the previous element in the list wrt. the ordering. Elements > and \u22a5 indicate two special elements that appear after the last and before the first element in the list respectively. They indicate that we have passed beyond the boundary of the list. The algorithm terminates (line 2) as soon as the test succeeds. Otherwise, it keeps iterating over tuples until we have processed either the last tuple in U [u] or the first tuple in D[u\u2032]. In that case the algorithm terminates as it is guaranteed that v(e) 6\u2208 V Di. In each step, we traverse at least one element from U [u] or D[u\u2032]. Hence, in total we can execute at most U [u] + D[u\u2032] \u2264 2K operations. Therefore, the time complexity of single edge traversal is O(K) and the complexity of valid domains computation of Algorithm 9 (after replacing the quadratic loop with Algorithm 10) is O(|E| \u00b7K) where K = min{K1,K2}.\nIn conclusion, we have developed a pseudo-polynomial scheme for computing valid domains wrt. two cost functions (2-wCVD). The space complexity is dominated by storing U and D sets at each node. In worst case we have to store O(|V | \u00b7 K) entries. The time complexity to compute U and D labels and extract valid domains takes O(|E| \u00b7K) steps. The overall interaction is similar to the single-cost approach. After assigning a variable, we have to recompute the labels as well as extract domains. If we tighten cost restrictions K1,K2 to K \u2032 1 \u2264 K1,K \u20322 \u2264 K2 we only need to extract domains. However, if we relax either of the cost restrictions, such as K \u20321 > K1 we need to recompute the labels as well. More precisely, labels U,D need to be recomputed only if K1 > K max 1 where K max 1 was the initial cost restriction after the last assignment."}, {"heading": "5.2.5 Further Extensions", "text": "Note that our approach can, in principle, be extended to handle general k-wCVD query for a fixed k. Lists U and D would contain the set of non-dominated k-tuples, ordered such that: (a1, . . . , ak) \u227a (a\u20321, . . . , a\u2032k) iff for the smallest coordinate j for which aj 6= a\u2032j it holds aj < a\u2032j . Both the list merging as well as valid domains extraction would be directly generalized to operate over such ordered sets, although the time complexity for testing dominans will increase. The worst-case complexity would depend on the size of an efficient frontier, which for k cost functions with cost bounds K is bounded by O(Kk\u22121). In practice however, we could expect that the number of non-dominated tuples be much smaller, especially for cost functions over smaller scopes and with smaller coefficients. Note that our approach can also be extended to accommodate non-additive cost functions by expanding the MDD to accommodate non-unary labels in the same fashion as discussed in Section 3.4.\n5.3 Approximation Scheme for 2-wCVD\nIn this subsection we analyze the complexity of answering 2-wCVD queries in approximative manner, i.e. how can we improve running time guarantees by settling for an approximate solution. Assume that one of the constraints K2 is fixed while the second constraint may be exceeded with a small tolerance (1+ )K1. For example, a user might be willing to tolerate a small increase in price as long as strict quality restrictions are met. In this section we present a fully polynomial time approximation scheme (FPTAS) for calculating valid domains in time O(En1 ) for this problem. The FPTAS should satisfy that no feasible solution with respect to the original costs should be fathomed, and that any feasible configuration found\nby use of the FPTAS in the domain restriction should satisfy the cost constraint within (1 + )K1. Finally, the FPTAS should have running time polynomial in 1/ and the input size.\nIn order to develop the FPTAS we use a standard scaling technique (Schuurman & Woeginger, 2005) originally presented by Ibarra and Kim (1975). Given an , let n be the number of decision variables. Set T = K1/(n + 1) and determine new costs c\u03031(e) = bc1(e)/T c and new bounds K\u03031 = dK1/T e. We then perform the valid domains computation (label updating and domain extraction) as described in Section 5.2, using the scaled weights. The following propositions prove that we obtained a FPTAS scheme.\nProposition 4 The running time of valid domains computation is O(1 En)\nProof 4 We may assume that K\u03031 < K2 as otherwise we may interchange the two costs. The running time becomes\nO(EK\u03031) = O(EK1/T ) = O(EK1 n+ 1\nK1 ) = O(En\n1\n)\nsince n \u2264 V this is polynomial in the input size O(V + E) and the precision 1 . Proposition 5 If a solution was feasible with respect to the original costs, then it is also feasible with respect to the scaled costs.\nProof 5 Assume that \u2211 e\u2208p c1(e) \u2264 K1. Then \u2211\ne\u2208p\nc\u03031(e) = \u2211\ne\u2208p\nbc1(e)/T c \u2264 1\nT\n\u2211\ne\u2208p\nc1(e) \u2264 1\nT K1 \u2264 d\n1 T K1e = K\u03031\nProposition 6 Any solution that was feasible with respect to the scaled costs c\u03031(e) satisfies original constraints within (1 + )K1.\nProof 6 Assume that \u2211 e\u2208p c\u03031(e) \u2264 C\u03031. Then \u2211\ne\u2208p c1(e) = T \u2211 e\u2208p c1(e)/T \u2264 T \u2211 e\u2208p(bc1(e)/T c+ 1) \u2264 T \u2211 e\u2208p c\u03031(e) + Tn\n\u2264 TK\u03031 + Tn = T dK1/T e+ Tn \u2264 T (K1/T + 1) + Tn = K1 + T (n+ 1)\nSince T = K1/(n+ 1) we get \u2211\ne\u2208p\nc1(e) \u2264 K1 + (n+ 1) K1/(n+ 1) = (1 + )K1\nwhich shows the stated.\nThe time complexity can be further improved using techniques from Kellerer et al. (2004) for the Knapsack Problem, but we are here only interested in showing the existence of a FPTAS.\nBy the considerations in previous subsections we have fully analyzed the complexity of answering 2-wCVD queries. We first showed that this is an NP-hard problem. We then developed a pseudo-polynomial scheme for solving it, and finally we devised a fully polynomial time approximation scheme. Even though we cannot provide polynomial running-time guarantees, based on these considerations, we can hope to provide a reasonable performance for practical instances, as it will be demonstrated in Section 6.\n5.4 Complexity of k-wCVD Query\nWe conclude this section by discussing complexity of general k-wCVD queries. While our practical implementation efforts are focused on implementing 2-wCVD queries, or other wCVD queries where the number of cost constraints is known in advance, for completeness we consider a generic problem of delivering k-wCVD for arbitrary k, i.e. where k is part of the input to the problem.\nWe will prove now that for such a problem there is no pseudo-polynomial scheme unless NP=P. We will show that decision version of such problem k-wCVD-SAT is NP-hard in the strong sense (Garey & Johnson, 1979) by reduction from the bin-packing problem (BPP) which is strongly NP-hard (Garey & Johnson, 1979). In the decision form the BPP asks whether a given set of numbers s1, . . . , sn can be placed into k bins of size K each. Notice, that we cannot use reduction below for showing NP-hardness of 2-wCVD-SAT, since k is a part of the input in BPP.\nTheorem 7 The k-wCVD-SAT problem with variable k, is strongly NP-hard.\nProof 7 For a given instance of BPP we reduce it to a k-wCVD-SAT instance as follows: We construct an MDD for a CSP (X,D,F ) over n variables X = {x1, . . . , xn} each with a domain of size k, Di = {1, . . . , k}, i = 1, . . . , n. We set F = \u2205, so that resulting MDD allows all assignments. It has n nonterminal nodes u1, . . . , un corresponding to the numbers s1, . . . , sn. Between two nodes ui, ui+1 we have k edges with costs (c1(e), c2(e), . . . , ck(e)) set to\n(si, 0, . . . , 0), (0, si, 0, . . . , 0), (0, 0, si, 0, . . . , 0), . . . , (0, . . . , si),\nThe first node u1 is the root u1 = r while the last node un is connected to the terminal un+1 = 1. The overall capacity constraints are (K1, . . . ,Kk) = (K, . . . ,K).\nIt is easily seen that we may find a path from r to 1 if and only if the BPP has a feasible solution. Since the BPP is strongly NP-hard we have shown that k-wCVD-SAT also is strongly NP-hard."}, {"heading": "6. Experimental Evaluation", "text": "We implemented our compilation scheme and the algorithms for wCVD and 2-wCVD queries. We performed a number of experiments to evaluate the applicability of our approach as well as to confirm various hypotheses made throughout the paper. We used two sets of instances whose properties are presented in Table 1. The first set corresponds to real-world configuration problems available at configuration benchmarks library CLib2. These are CSP models with configuration constraints. They correspond to highly structured configuration problems with a huge number of similar solutions. The second set of instances represents product-catalogue datasets used by Nicholson, Bridge, and Wilson (2006). These catalogues are defined explicitly, as tables of solutions. They represent a much smaller and sparser set of solutions.\n2. http://www.itu.dk/research/cla/externals/clib/"}, {"heading": "6.1 MDD Size", "text": "In the first set of experiments, for each instance we generated a log-encoded BDD B using CLab (Jensen, 2007). We then extracted a corresponding MDD M from B. Finally, we expanded long edges in M and merged isomorphic nodes to generate a merged MDD M \u2032. We compare the sizes of B, M and M \u2032 in Table 2. For each structure we provide the number of nodes V and edges E. We also provide the size of the BDD B. We conclude from the table that both BDDs and MDDs are exponentially smaller than the size of the solution space for configuration instances while not as significantly smaller for more diverse product configuration catalogues. Furthermore, we can see that the number of edges in merged MDDs M \u2032 is not significantly larger in comparison to extracted MDDs M . Hence, due to simpler online algorithms, using merged MDDs seems well suited for online reasoning. We can also see that multi-valued encoding in many cases reduces the number of nodes and edges in comparison to BDDs. Even though compilation times are less important since the generation of the MDD is performed offline, it is worth noting that for the largest instance, Renault, it took around 2min and 30sec to compile the instance into a BDD and extract an MDD."}, {"heading": "6.1.1 Encoding Cost Explicitly", "text": "We also investigated the impact of encoding cost information explicitly into an MDD. For each instance we compared the size of the MDD without and with cost variables (M and M c respectively). For configuration benchmarks we introduce an additional variable y \u2208 [0, 10000] such that y = \u2211ni=1 aixi where coefficients ai are randomly drawn from the interval [0, 50]. We put variable y as the last in the ordering since for other positions we get MDDs of similar size, and putting y at the end allows easier theoretical analysis. Since\nproduct catalogues already contain the cost variable y (price), we produce a cost-oblivious version M by existentially quantifying y, M = \u2203yM c.\nIn Table 3 we compare the MDDsM andM c. For both structures we provide the number of edges as well as the representation size in kilobytes. We also show the size of cost range C(Sol). We observe that for configuration instances that have a high level of sharing and compression, introducing cost information explicitly induces an order of magnitude increase in size even when the cost range C(Sol) is limited (400 times increase for Bike2 instance). MDDs for the two largest instances could not be generated. However, for product catalogues which have much less sharing, removing cost information does not have a dramatic effect. In the worst case, the number of edges in M c is two times larger than in M . Hence, the experimental results confirm that introducing cost explicitly could have a dramatic effect for MDD representations of highly compressed solution spaces, usually implicitly defined through conjunction of combinatorial constraints. However, the effect of adding explicit cost information might be modest when the solution space is defined explicitly, as a (sparse) list of database entries, such as the case for product catalogues. Furthermore, the size of the cost range C(Sol) needs not be significant for a large increase in size to take place.\n6.2 Response Times for wCVD Queries\nIn the second set of experiments, we evaluated the performance of wCVD queries over merged MDD representations of configuration instances. We report the running times for both computing U and D labels (Algorithm 2) as well as computing valid domains (Algorithm 3). In Table 4 we report both average and worst-case running times over initial merged MDDs\nfrom Table 2. We also report the time necessary to restrict the MDD wrt. an assignment (Algorithm 1). We randomly create an additive cost function c by assigning for each variable xi and each value a \u2208 Di a cost ci(a) from [0, 50]. Valid domains are computed wrt. the maximal cost restriction K that is set to a value larger than the the length of the longest MDD path wrt. cost function c. This ensures the longest execution time of Algorithm 3. Each data-point in the table is an average or a maximum over 1000 executions on a Fedora 9 operating system, using dual Quad core Intel Xeon processor running at 2.66 GHz. Only one core is used for each instance. Empirical evaluation demonstrates that response times are easily within acceptable interaction bounds even for the largest instances, where in worst case the MDD nodes are labeled within 0.13 seconds, valid domains are computed within 0.07 seconds and MDD is restricted wrt. an assignment within 0.28 seconds.\n6.3 Response Times for 2-wCVD Query\nWe generated analogous statistics for 2-wCVD in Table 5. We tested the performance of our algorithms under the computationally most demanding circumstances: we operate over the original (fully-sized) MDD, even though during interaction it would be reduced due to user assignments. Furthermore, both cost functions c1, c2 have a global scope, and we use no cost restrictions when computing U and D labels (i.e. we ignore the condition in line 1 of Algorithm 10 and hence, U [1] and D[r] correspond to an entire efficient frontier). Normally, cost functions would involve only a subset of variables and only a fraction of the labels on the efficient frontier (within restrictionsK1,K2) would be relevant for the user. We generate cost functions c1, c2 by drawing costs ci(a) randomly from [0, 50]. For computing valid domains, we use restrictions K1,K2 larger than the lengths of corresponding longest\npaths, so that all possible solutions in the efficient frontier are allowed. This would lead to the longest execution time of Algorithm 9.\nOur algorithms can easily handle the first five instances. For the largest two instances, if U and D labels are known, calculating valid domains can be done within a fraction of a second. Hence, a user can efficiently explore the effect of various cost restrictionsK1,K2 wrt. a fixed partial assignment. After a user assigns a variable, recomputing U and D labels takes in total on average less than 0.85 seconds, or in worst case less than 1.4 seconds. While this is already within acceptable interaction times, the usability of the system can be further enhanced, e.g. by using a layered display of information: always reacting with the information that is fastest to compute (such as CVD or wCVD), and while the user is analyzing it, execute more time consuming operations. In particular, the entire efficient frontier is known as soon as U labels are generated \u2014 in worst case within 0.64 seconds. At this stage, a user can explore the \u201dcost-space\u201d while D labels are computed (on average within the next 0.79 seconds). Note that the running times can be reduced through a number of additional schemes, e.g. by computing U and D labels in parallel, if two or more processors are present.\nOur empirical evaluation demonstrates the practical value of our approach. Even the NP-hard 2-wCVD query can be implemented with response times suitable for interactive use, when applied to huge configuration instances. Note, however, that in order to achieve such performance it is critical to optimize MDD implementation as well as to utilize advanced list operation techniques. Our initial implementation efforts that failed to do so, led to response times measured in tens of seconds for the largest instances."}, {"heading": "7. Related Work", "text": "There are several directions of related work. There is a large variety of representations investigated in the area of knowledge compilation that might be suitable for supporting interactive decision making with cost restrictions. There are also a number of approaches to handle multiple cost functions in multi-criteria optimization."}, {"heading": "7.1 Compiled Knowledge Representation Forms", "text": "In this paper we used binary decision diagrams (BDDs) and multi-valued decision diagrams (MDDs) as compiled representations of our CSP model. However, there might be other compiled representations that might be more suitable for supporting interactive configuration. Any compiled representation that supports efficient consistency checking and conditioning would in theory support polytime interactive configuration. To calculate valid domains it suffices for each value to restrict the representation and check if it is consistent. Any representation that supports efficient optimization and conditioning would support polytime cost restrictions. It would suffice to restrict the representation with a value and check if the minimum is smaller than a threshold value. We will therefore briefly survey some of the related compiled representations and evaluate their suitability for our framework.\nKnowledge-Compilation Structures. Probably the most well known framework for comparing various compiled forms of propositional theories is based on viewing them as special classes of negation normal form (NNF) languages (Darwiche & Marquis, 2002). NNFs are directed acyclic graphs where internal nodes are associated with conjunctions (\u2227) or disjunctions (\u2228), while leaf nodes are labeled with literals (x,\u00acx) or constants true or false. By imposing various restrictions we get subclasses of NNF languages that support efficient execution of various queries and transformations. More restrictive representations are less succinct i.e. they can be exponentially larger for some instances, but they support a larger number of queries and transformations in polytime. A comprehensive overview of such representations is presented by Darwiche and Marquis (2002).\nThe critical restriction that makes NNF languages more tractable is decomposability. It exploits variable independencies by enforcing that children of an \u2227-node have nonoverlapping variable scopes. Hence, for a propositional formula F = F1 \u2227 F2 such that var(F1) \u22c2\nvar(F2) = \u2205, to evaluate satisfiability of F it suffices to independently evaluate F1 and F2. A resulting language is decomposable negation normal form (DNNF) which already supports in polytime two operations critical for calculating valid domains: consistency checking and conditioning. However, no general DNNF compiler exists. Current compilation approach based on exhaustive DPLL search with caching isomorphic nodes (Huang & Darwiche, 2005) constructs subsets of DNNF that satisfy an additional property\nof determinism. Any two children of an \u2228-node are mutually exclusive. The resulting structure is called deterministic decomposable negation normal form (d-DNNF). This structure would be an interesting target for cost-configuration. For Boolean CSP models, additive cost functions could be efficiently optimized over d-DNNFs. For multi-valued models however, more research is necessary on how to encode finite-domain values in a way that allows efficient cost processing. The tool support for compiling d-DNNFs so far takes as an input only CNF formulas, and we are unaware of extensions allowing direct compilation of general CSP models.\nOther known knowledge representation forms can be retrieved by enforcing additional properties. For example, by further enforcing that all nodes are decision nodes and that each variable is encountered at most once on each path (read-once property) we get free BDDs (FBDDs). After enforcing that all decision nodes appear wrt. fixed ordering we get ordered BDDs (OBDDs). In fact, the d-DNNF compiler of Huang and Darwiche (2005) can be specialized to compile OBDDs, which proved to be a valuable alternative way to BDD compilation.\nWeighted and Multi-Valued Knowledge Compilation Structures. Most of the compiled representations for propositional theories have valued counterparts. Many of them can be seen as special cases of valued NNFs (VNNF) (Fargier & Marquis, 2007). Roughly, every valued counterpart is obtained by changing the semantics of nodes, from logical operators (such as \u2227, \u2228) to general operators \u2297 (that could be arithmetic, such as + and \u2217). Values of functions represented by these structures are no longer in {0, 1} but in R. Furthermore, functions need not be defined over Boolean domains, but could take finite-domain values. In general, subsets of VNNF that satisfy decomposability and operator distributivity support efficient optimization (Fargier & Marquis, 2007) and could, in principle, be used to support cost configuration.\nConstruction of MDDs based on encoding into BDDs has been discussed by Srinivasan, Kam, Malik, and Brayton (1990). Amilhastre et al. (2002) augmented automata of Vempaty (1992) with edge weights to reason about optimal restorations and explanations. These weighted extensions correspond closely to our weighted MDDs since the variant of automata used by Vempaty (1992) is equivalent to merged MDDs (Hadzic et al., 2008). However, the weights are used to compute different queries and while we generate MDDs based on widely available BDD-packages, Vempaty (1992) does not report compilation tools used. Semiring labeled decision diagrams (SLDDs) (Wilson, 2005) label edges of an (unordered) MDD with values from a semiring and allow computation of a number of queries relevant for reasoning under uncertainty. Due to relaxed ordering, SLDDs are more succinct than our weighted MDDs and are therefore an attractive target for cost-based configuration. However, the proposal for now seems to be theoretic, and does not seem to be implemented. Arithmetic circuits are directed acyclic graphs where internal nodes are labeled with summation and multiplication operators while leaf nodes are labeled with constants or variables (Darwiche, 2002). They could be seen as a valued extension of d-DNNFs and hence are more succinct than SLDDs. Furthermore, they support efficient optimization when all coefficients are positive (in Bayesian context - they support efficient computing of most probable explanations). Compilation technology for ACs is not directly applicable to general CSP models, as it is used primarily for representing Bayesian networks. It is based on compiling d-DNNFs or tree clustering approaches (Darwiche, 2002, 2003). In our context, ACs might be use-\nful when optimizing non-additive objective functions with multiplicative coefficients such as multi-linear functions induced by Bayesian networks. However, for purely propositional constraints over which an additive cost function should be optimized, a purely propositional representation form (such as d-DNNF) would be more adequate. Furthermore, efficient optimization queries based on ACs implicitly assume that all constants (at leaf nodes) are positive, which is the case when modeling Bayesian networks, but does not hold for general cost functions.\nGlobal Structure Approaches. A number of techniques based on tree-clustering (Dechter & Pearl, 1989) and variable-elimination (Dechter, 1999) exploit variable independencies that are present globally in a CSP model. Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993). While most of these techniques are geared towards enhancing search for a single (optimal) solution (adaptive consistency, bucket elimination etc), the same concepts can be utilized for compiling representations of all solutions. AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order. Due to utilization of variable independencies through \u2227-nodes, they are more succinct than MDDs and are therefore an attractive compilation target for cost-configuration. Furthermore, they are already extended to handle weighted graphical models to support Bayesian reasoning. However, publicly available tool support is limited and does not allow processing weighted CVD queries. Tree-driven-automata (Fargier & Vilarem, 2004) utilize tree clustering (Dechter & Pearl, 1989), to generate a partial variable ordering that is used to generate an automaton. Tree-driven-automata are equivalent to AND/OR MDDs and when restricted to the Boolean case they represent a subset of d-DNNF languages called strongly ordered decomposable decision graphs (SO-DDG) (Fargier & Marquis, 2006). Like AND/OR MDDs they are more succinct than MDDs and therefore are an interesting target for cost-configuration. However, tools for compiling tree-driven-automata are yet to become publicly available, and so far they have not been extended to handle costs. Weighted cluster trees of Pargamin (2003) are a weighted extension of cluster trees used to support interactive configuration with preferences. However, there is no publicly available compilation tool (an internal company-based implementation was presented), and the clusters are represented explicitly without utilizing compressions based on local structure through decision diagrams or other compiled representations. Tree-of-BDDs (ToB) (Subbarayan, 2008) directly exploit tree clustering by representing each cluster as a BDD. However, they do not support conditioning in polytime which is a fundamental transformation in supporting user interaction (assigning variables). However, they can be compiled for instances for which d-DNNF compilation fails, and empirical evaluation shows that on average conditioning times are short.\nBDD Extensions. There is a large variety of weighted extensions of binary decision diagrams, that represent real-valued functions f : {0, 1}n \u2192 R rather than Boolean functions f : {0, 1}n \u2192 {0, 1}. These extensions are limited to Boolean variables and their adoption in future would have to consider encoding techniques of multi-valued variables that avoid explosion in size and support cost processing. Comprehensive overviews of these extensions are presented by Drechsler (2001), Wegener (2000), and Meinel and Theobald (1998). An immediate extension is in the form of algebraic decision diagrams (ADDs) (Bahar, Frohm, Gaona,\nHachtel, Macii, Pardo, & Somenzi, 1993), also known as multi-terminal BDDs (MTBDDs), that are essentially BDDs with multiple terminal nodes - one for each cost value. This is a structure-oblivious approach to encoding cost, much as our approach of explicitly encoding cost as a variable. The size grows quickly with increase of the number of terminals. Therefore a number of BDD extensions are introduced based on labeling edges with weights. They differ mostly on cost operators and decomposition types associated with nodes. Edge-valued BDDs (EVBDDs) (Lai & Sastry, 1992) label every edge with an additive cost value c(e) so that for an edge e : u \u2192 u\u2032, the value val(u) = c(e) + val(u\u2032) when v(e) = 1 (otherwise val(u) = val(u\u2032)). Factored EVBDDs (FEVBDDs) (Tafertshofer & Pedram, 1997) introduce multiplicative weights, so that when v(e) = 1, value val(u) = c(e) + w(e) \u00b7 val(u\u2032) (otherwise val(u) = val(u\u2032)). Affine ADDs (AADDs) of Sanner and McAllester (2005) further introduce additive and multiplicative edge weights for any edge (regardless of v(e)). Then val(u) = c(e) + w(e) \u00b7 val(u\u2032) for every edge. It has been shown that AADDs are a special case of valued NNFs (Fargier & Marquis, 2007).\nAn orthogonal extension of BDDs is to change decomposition type of nodes. OBDDs are based on Shannon decomposition fu = xifu0 \u2228 \u00acxifu1 . We can change this decomposition type to positive Davio (pD) decomposition fu = f0 \u2295 xif1 or negative Davio(nD) decomposition fu = f0 \u2295 \u00acxif1. By using pD decomposition we get ordered functional decision diagrams (OFDDs) (Kebschull & Rosenstiel, 1993). These structures are incomparable to OBDDs, i.e. they might be exponentially larger or smaller than OBDDs depending on the instance. However, ordered Kronecker functional decision diagrams (OKFDDs)(Drechsler, Sarabi, Theobald, Becker, & Perkowski, 1994) allow all three decomposition types, thus generalizing both OBDDs and OFDDs. Extending OFDDs with additive edge weights leads to binary moment diagrams (BMDs) (Bryant & Chen, 1995), adding also multiplicative edge weights leads to multiplicative binary moment diagrams (\u2217BMDs). Analogously, by extending OKFDDs with additive and multiplicative edge weights we get Kronecker binary moment diagrams (KBMDs) and K\u2217BMDs respectively (Drechsler, Becker, & Ruppertz, 1996).\nIt is unclear whether Boolean structures with advanced cost labeling schemes can be used directly to represent multi-valued CSP models with cost functions. However, we could compare the generalizations of such labeling schemes to multi-valued structures. A multivalued generalization of EVBDDs would correspond roughly to our weighted MDDs. However, introducing both additive and multiplicative weights as in AADDs would correspond to a generalization of our labeling scheme that could prove to be useful for labeling multilinear cost functions. Namely, through introduction of multiplicative weights there would be more subgraph sharing, and not as many nodes would have to be refined to accommodate non-additive costs. However, due to multiplicative factors, it is not obvious if our cashing technique based on computing U,D can be directly extended, especially if some of the coefficients are negative. In case of additive cost functions though, all of these schemes would correspond to our labeling scheme. Most of these structures pay the price in less efficient operators (such as apply operator) and larger memory requirements as they maintain more information. Therefore, for compiling Boolean functions, using these structures would pose an unnecessary overhead in comparison to OBDDs. Hence, for models with a large number of propositional (configuration) constraints, and an additive cost function, we would not gain from compiling using these structures even in the Boolean case. When\nthe cost function is non-additive, introducing more elaborate cost representations might prove beneficial for reducing memory requirements, but might make our label computing technique unapplicable. From a practical point of view, while there are implementations supporting Boolean versions of these structures, we are not aware of any tool supporting multi-valued generalizations of these structures nor input language format that can be used for specifying general propositional constraints."}, {"heading": "7.2 Multi-Objective Cost Processing", "text": "Our multiple-cost configuration is close to approaches within a framework of multi-criteria optimization where a decision maker should find a solution subject to multiple (often conflicting) objectives (Figueira et al., 2005; Ehrgott & Gandibleux, 2000). In particular, our MDD-based algorithms are very close to the approaches for solving multiobjective shortest path problem, where for a given graph (V,E) each arc is labeled with multiple costs, and the goal is typically to compute the set of Pareto-optimal (efficient, non-dominated) solutions (Ehrgott & Gandibleux, 2000; Mu\u0308ller-Hannemann & Weihe, 2001; Tarapata, 2007; Reinhardt & Pisinger, 2009). It has been shown that the multi-objective shortest path problem is intractable. In particular, the number of Pareto-optimal solutions can grow exponentially with the number of vertices |V |, but a FPTAS (fully polynomial time approximation scheme) has been developed for approximating the set of Pareto-optimal solutions. However, the way in which the solution space of multi-criteria optimization problems is explored is significantly different from our approach. Typically, in each interaction step a subset of Pareto-optimal solutions is computed and afterwards a decision maker interactively navigates through the set in order to reach the satisfying compromising solution. Interactive methods in multi-criteria optimization usually compute a subset of solutions on the efficient frontier, suggest it to the user for evaluation, and based on his input compute a new set of solutions (Figueira et al., 2005, Chapter 16). These techniques would use the user input to better estimate the way to aggregate multiple objectives, and some of them would require the user to explicitly assign weights of importance to objectives. In contrast, instead of being primarily driven by the costs of solutions, our interactive approach supports reasoning about the variable assignments in the solutions themselves through valid domains computation. It is an inherently different way of exploring the solution space which is more adequate for users that want explicit control over variable assignments and not just indicating the importance of cost functions.\nMost of the approaches in the CSP community model preferences as soft constraints (Meseguer, Rossi, & Shiex, 2006) that can be partially satisfied or violated, with a goal to find the most satisfying or the least violating solution. This usually presupposes that preferences can be aggregated via algebraic operators, and as such is more related to single-cost optimization problems. However, the approach by Rollo\u0301n and Larrosa (2006) deals with multiple costs explicitly. It utilizes global structure (i.e. variable independencies) of the weighted CSP model to compute an efficient frontier through bucket-based variable elimination. A highly related approach that utilizes global structure of the generalized additive independence (GAI) network is presented by Dubus, Gonzales, and Perny (2009). In order to compute the efficient frontier, the authors use a message passing computation mechanism which is analogous to computing buckets. In addition, the authors develop a fully\npolynomial approximation scheme to approximate the efficient frontier and demonstrate the significant improvement in performance. However, neither of these methods can exploit the fact that the solution space of hard constraints is available in a compiled representation. Instead, these methods operate only over an unprocessed model specification (whether it is a weighted CSP or a GAI network) treating both the hard and soft constraints uniformly and hence allowing the scope of hard constraints to decrease the variable independencies in the model (and thus decrease the performance of the algorithms). Furthermore, the result of computation of these methods does not allow a full exploration of efficient solutions. For each value on the frontier only a single supporting efficient solution is maintained while we maintain for each efficient value the set of all supporting efficient solutions. Hence, it is not possible to efficiently retrieve valid domains even after the algorithms terminate. It would be interesting to see however, whether these methods could be adopted to work over MDD representations of a solution space.\nKnapsack constraints are special case of two-cost configuration problems over a universally true MDD. Trick (2001) used dynamic programming to propagate Knapsack constraints during CSP search. Fahle and Sellmann (2002) presented an approximated filtering algorithm, based on various integer programming bounds for the Knapsack problem. Sellmann (2004) presented a fully polynomial time approximation algorithm for approximated filtering. However, these techniques were considered in constraint propagation context and none of them considered processing over existing MDD structure."}, {"heading": "8. Conclusions and Future Work", "text": "In this paper we presented an extension of BDD-based interactive configuration to configuring in the presence of cost restrictions. We guarantee polynomial-time cost configuration when the cost function is additive and feasible solutions are represented using multi-valued decision diagram. We process cost restrictions over an MDD which is extracted from an underlying BDD. We therefore strictly extend BDD-based configuration of Hadzic et al. (2004) to support cost-bounding of additive cost functions without incurring exponential increase in complexity. Our implementation delivers running times that easily satisfy interactive response-time requirements. Furthermore, our approach can be extended to support bounding in the presence of non-additive and semiring-based costs.\nWe further extended our approach by considering cost bounding wrt. multiple costs. We proved that this is an NP-hard problem in the input MDD size even when processing only two linear inequalities with positive coefficients and Boolean variables. However, we provided a pseudo-polynomial scheme and fully polynomial approximation scheme for twocost configuration (which, in principle, can be extended to any k-cost configuration for a fixed k). Our empirical evaluation demonstrated that despite inherent hardness of this problem we can still provide satisfying performance in interactive setting. Our interaction based on computing valid domains wrt. multiple cost restrictions is a novel addition to interaction modes within multiple-criteria decision making (Figueira et al., 2005). We provide an explicit control over variable assignments as well as cost functions.\nIn the future we plan to investigate other compiled representations over which delivering cost configuration might be efficient and to investigate practical approaches to processing non-unary cost functions. In particular, we plan to examine whether existing methods to\nmultiobjective non-unary optimization (e.g., Rollo\u0301n & Larrosa, 2006; Dubus et al., 2009) can be adopted to operate over MDD representation of a solution space."}, {"heading": "Acknowledgments", "text": "We would like to thank the anonymous reviewers for their extensive comments that helped us improve the paper. We would also like to thank Erik van der Meer for providing the T-shirt example. The first version of this paper was created while Tarik Hadzic was at the IT University of Copenhagen, while the updated version was made at the Cork Constraint Computation Centre with a support from an IRCSET/Embark Initiative Postdoctoral Fellowship Scheme."}], "references": [{"title": "Consistency Restoration and Explanations in Dynamic CSPs-Application to Configuration", "author": ["J. Amilhastre", "H. Fargier", "P. Marquis"], "venue": "Artificial Intelligence,", "citeRegEx": "Amilhastre et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Amilhastre et al\\.", "year": 2002}, {"title": "Algebraic decision diagrams and their applications", "author": ["R. Bahar", "E. Frohm", "C. Gaona", "E. Hachtel", "A. Macii", "A. Pardo", "F. Somenzi"], "venue": "In IEEE/ACM International Conference on CAD,", "citeRegEx": "Bahar et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Bahar et al\\.", "year": 1993}, {"title": "Construction of efficient BDDs for bounded arithmetic constraints", "author": ["C. Bartzis", "T. Bultan"], "venue": "TACAS, Vol. 2619 of Lecture Notes in Computer Science,", "citeRegEx": "Bartzis and Bultan,? \\Q2003\\E", "shortCiteRegEx": "Bartzis and Bultan", "year": 2003}, {"title": "A tourist guide through treewidth", "author": ["H.L. Bodlaender"], "venue": "Acta Cybernetica,", "citeRegEx": "Bodlaender,? \\Q1993\\E", "shortCiteRegEx": "Bodlaender", "year": 1993}, {"title": "Improving the variable ordering of OBDDs is NP-complete", "author": ["B. Bollig", "I. Wegener"], "venue": "Computers, IEEE Transactions on,", "citeRegEx": "Bollig and Wegener,? \\Q1996\\E", "shortCiteRegEx": "Bollig and Wegener", "year": 1996}, {"title": "Graph-Based Algorithms for Boolean Function Manipulation", "author": ["R.E. Bryant"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "Bryant,? \\Q1986\\E", "shortCiteRegEx": "Bryant", "year": 1986}, {"title": "Verification of Arithmetic Circuits with Binary Moment Diagrams", "author": ["R.E. Bryant", "Chen", "Y.-A"], "venue": "Proceedings of the 32nd ACM/IEEE Design Automation Conference,", "citeRegEx": "Bryant et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bryant et al\\.", "year": 1995}, {"title": "A Knowledge Compilation Map", "author": ["A. Darwiche", "P. Marquis"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Darwiche and Marquis,? \\Q2002\\E", "shortCiteRegEx": "Darwiche and Marquis", "year": 2002}, {"title": "A Logical Approach to Factoring Belief Networks", "author": ["A. Darwiche"], "venue": "KR2002: Principles of Knowledge Representation and Reasoning,", "citeRegEx": "Darwiche,? \\Q2002\\E", "shortCiteRegEx": "Darwiche", "year": 2002}, {"title": "A differential approach to inference in Bayesian networks", "author": ["A. Darwiche"], "venue": "Journal of the ACM,", "citeRegEx": "Darwiche,? \\Q2003\\E", "shortCiteRegEx": "Darwiche", "year": 2003}, {"title": "Bucket Elimination: A Unifying Framework for Reasoning", "author": ["R. Dechter"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter,? \\Q1999\\E", "shortCiteRegEx": "Dechter", "year": 1999}, {"title": "Tree-Clustering for Constraint Networks", "author": ["R. Dechter", "J. Pearl"], "venue": "Artificial Intelligence,", "citeRegEx": "Dechter and Pearl,? \\Q1989\\E", "shortCiteRegEx": "Dechter and Pearl", "year": 1989}, {"title": "Efficient representation and manipulation of switching functions based on ordered Kronecker functional decision diagrams", "author": ["R. Drechsler", "A. Sarabi", "M. Theobald", "B. Becker", "M.A. Perkowski"], "venue": "In DAC \u201994: Proceedings of the 31st annual conference on Design automation,", "citeRegEx": "Drechsler et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Drechsler et al\\.", "year": 1994}, {"title": "Binary decision diagrams in theory and practice", "author": ["R. Drechsler"], "venue": "International Journal on Software Tools for Technology Transfer (STTT),", "citeRegEx": "Drechsler,? \\Q2001\\E", "shortCiteRegEx": "Drechsler", "year": 2001}, {"title": "K*BMDs: A New Data Structure for Verification", "author": ["R. Drechsler", "B. Becker", "S. Ruppertz"], "venue": "EDTC", "citeRegEx": "Drechsler et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Drechsler et al\\.", "year": 1996}, {"title": "Multiobjective Optimization using GAI Models", "author": ["Dubus", "J.-P", "C. Gonzales", "P. Perny"], "venue": null, "citeRegEx": "Dubus et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dubus et al\\.", "year": 2009}, {"title": "A Survey and Annotated Bibliography of Multiobjective Combinatorial Optimization", "author": ["M. Ehrgott", "X. Gandibleux"], "venue": "OR Spektrum,", "citeRegEx": "Ehrgott and Gandibleux,? \\Q2000\\E", "shortCiteRegEx": "Ehrgott and Gandibleux", "year": 2000}, {"title": "Cost Based Filtering for the Constrained Knapsack Problem", "author": ["T. Fahle", "M. Sellmann"], "venue": "Annals of Operations Research,", "citeRegEx": "Fahle and Sellmann,? \\Q2002\\E", "shortCiteRegEx": "Fahle and Sellmann", "year": 2002}, {"title": "On the Use of Partially Ordered Decision Graphs in Knowledge Compilation and Quantified Boolean Formulae", "author": ["H. Fargier", "P. Marquis"], "venue": "In Proceedings of AAAI", "citeRegEx": "Fargier and Marquis,? \\Q2006\\E", "shortCiteRegEx": "Fargier and Marquis", "year": 2006}, {"title": "On Valued Negation Normal Form Formulas", "author": ["H. Fargier", "P. Marquis"], "venue": "In Proceedings of IJCAI", "citeRegEx": "Fargier and Marquis,? \\Q2007\\E", "shortCiteRegEx": "Fargier and Marquis", "year": 2007}, {"title": "Compiling CSPs into Tree-Driven Automata for", "author": ["H. Fargier", "Vilarem", "M.-C"], "venue": "Interactive Solving. Constraints,", "citeRegEx": "Fargier et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Fargier et al\\.", "year": 2004}, {"title": "Multiple Criteria Decision Analysis: State of the Art Surveys", "author": ["J.R. Figueira", "S. Greco", "M. Ehrgott"], "venue": null, "citeRegEx": "Figueira et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Figueira et al\\.", "year": 2005}, {"title": "Computers and Intractability-A Guide to the Theory of NP-Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "Garey and Johnson,? \\Q1979\\E", "shortCiteRegEx": "Garey and Johnson", "year": 1979}, {"title": "Fast Backtrack-Free Product Configuration using a Precompiled Solution Space Representation", "author": ["T. Hadzic", "S. Subbarayan", "R.M. Jensen", "H.R. Andersen", "J. M\u00f8ller", "H. Hulgaard"], "venue": "Proceedings of PETO Conference,", "citeRegEx": "Hadzic et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hadzic et al\\.", "year": 2004}, {"title": "A BDD-based Polytime Algorithm for Cost-Bounded Interactive Configuration", "author": ["T. Hadzic", "H.R. Andersen"], "venue": "In Proceedings of AAAI", "citeRegEx": "Hadzic and Andersen,? \\Q2006\\E", "shortCiteRegEx": "Hadzic and Andersen", "year": 2006}, {"title": "On Automata, MDDs and BDDs in Constraint Satisfaction", "author": ["T. Hadzic", "E.R. Hansen", "B. O\u2019Sullivan"], "venue": "In Proceedings of the ECAI 2008 Workshop on Inference Methods based on Graphical Structures of Knowledge", "citeRegEx": "Hadzic et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hadzic et al\\.", "year": 2008}, {"title": "Using DPLL for efficient OBDD construction", "author": ["J. Huang", "A. Darwiche"], "venue": "In Proceedings of SAT", "citeRegEx": "Huang and Darwiche,? \\Q2004\\E", "shortCiteRegEx": "Huang and Darwiche", "year": 2004}, {"title": "DPLL with a trace: From SAT to knowledge compilation", "author": ["J. Huang", "A. Darwiche"], "venue": null, "citeRegEx": "Huang and Darwiche,? \\Q2005\\E", "shortCiteRegEx": "Huang and Darwiche", "year": 2005}, {"title": "Fast approximation algorithms for the knapsack and sum of subset problem", "author": ["O. Ibarra", "C. Kim"], "venue": "Journal of the ACM,", "citeRegEx": "Ibarra and Kim,? \\Q1975\\E", "shortCiteRegEx": "Ibarra and Kim", "year": 1975}, {"title": "CLab: A C++ library for fast backtrack-free interactive product configuration. http://www.itu.dk/people/rmj/clab", "author": ["R.M. Jensen"], "venue": null, "citeRegEx": "Jensen,? \\Q2007\\E", "shortCiteRegEx": "Jensen", "year": 2007}, {"title": "Efficient graph-based computation and manipulation of functional decision diagrams. Design Automation, 1993, with the European Event in ASIC Design. Proceedings", "author": ["U. Kebschull", "W. Rosenstiel"], "venue": "European Conference", "citeRegEx": "Kebschull and Rosenstiel,? \\Q1993\\E", "shortCiteRegEx": "Kebschull and Rosenstiel", "year": 1993}, {"title": "Edge-valued binary decision diagrams for multi-level hierarchical verification", "author": ["Lai", "Y.-T", "S. Sastry"], "venue": "Proceedings of the 29th ACM/IEEE conference on Design automation,", "citeRegEx": "Lai et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Lai et al\\.", "year": 1992}, {"title": "Method of configuring a product. US Patent No: 7,584,079", "author": ["J. Lichtenberg", "H.R. Andersen", "H. Hulgaard", "J. M\u00f8ller", "A.S. Rasmussen"], "venue": null, "citeRegEx": "Lichtenberg et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lichtenberg et al\\.", "year": 2001}, {"title": "BuDDy - A Binary Decision Diagram Package. http://sourceforge.net/projects/buddy", "author": ["J. Lind-Nielsen"], "venue": null, "citeRegEx": "Lind.Nielsen,? \\Q2001\\E", "shortCiteRegEx": "Lind.Nielsen", "year": 2001}, {"title": "AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Graphical Models", "author": ["R. Mateescu", "R. Dechter", "R. Marinescu"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Mateescu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mateescu et al\\.", "year": 2008}, {"title": "Algorithms and Data Structures in VLSI", "author": ["C. Meinel", "T. Theobald"], "venue": null, "citeRegEx": "Meinel and Theobald,? \\Q1998\\E", "shortCiteRegEx": "Meinel and Theobald", "year": 1998}, {"title": "On the Construction of Multiple-Valued Decision Diagrams", "author": ["D.M. Miller", "R. Drechsler"], "venue": "In Proceedings of the 32nd International Symposium on Multiple-Valued Logic (ISMVL\u201902),", "citeRegEx": "Miller and Drechsler,? \\Q2002\\E", "shortCiteRegEx": "Miller and Drechsler", "year": 2002}, {"title": "Product configuration over the internet", "author": ["J. M\u00f8ller", "H.R. Andersen", "H. Hulgaard"], "venue": "In INFORMS Conference on Information Systems and Technology", "citeRegEx": "M\u00f8ller et al\\.,? \\Q2002\\E", "shortCiteRegEx": "M\u00f8ller et al\\.", "year": 2002}, {"title": "Pareto Shortest Paths is Often Feasible in Practice", "author": ["M. M\u00fcller-Hannemann", "K. Weihe"], "venue": "In WAE \u201901: Proceedings of the 5th International Workshop on Algorithm Engineering,", "citeRegEx": "M\u00fcller.Hannemann and Weihe,? \\Q2001\\E", "shortCiteRegEx": "M\u00fcller.Hannemann and Weihe", "year": 2001}, {"title": "Decision Diagrams: Fast and Flexible Support for Case Retrieval and Recommendation", "author": ["R. Nicholson", "D.G. Bridge", "N. Wilson"], "venue": "In Proceedings of ECCBR", "citeRegEx": "Nicholson et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nicholson et al\\.", "year": 2006}, {"title": "Extending Cluster Tree Compilation with non-Boolean variables in Product Configuration: a Tractable Approach to Preference-based Configuration", "author": ["B. Pargamin"], "venue": "In IJCAI\u201903 Workshop on Configuration", "citeRegEx": "Pargamin,? \\Q2003\\E", "shortCiteRegEx": "Pargamin", "year": 2003}, {"title": "Multi-Objective and Multi-Constrained NonAdditive Shortest Path Problems", "author": ["L.B. Reinhardt", "D. Pisinger"], "venue": "Computers and Operations Research", "citeRegEx": "Reinhardt and Pisinger,? \\Q2009\\E", "shortCiteRegEx": "Reinhardt and Pisinger", "year": 2009}, {"title": "Bucket elimination for multiobjective optimization problems", "author": ["E. Roll\u00f3n", "J. Larrosa"], "venue": "Journal of Heuristics,", "citeRegEx": "Roll\u00f3n and Larrosa,? \\Q2006\\E", "shortCiteRegEx": "Roll\u00f3n and Larrosa", "year": 2006}, {"title": "Affine Algebraic Decision Diagrams (AADDs) and their Application to Structured Probabilistic Inference", "author": ["S. Sanner", "D.A. McAllester"], "venue": "In Proceedings of IJCAI", "citeRegEx": "Sanner and McAllester,? \\Q2005\\E", "shortCiteRegEx": "Sanner and McAllester", "year": 2005}, {"title": "Approximation schemes \u2014 a tutorial", "author": ["P. Schuurman", "G.J. Woeginger"], "venue": "Lectures on Scheduling. Forthcoming", "citeRegEx": "Schuurman and Woeginger,? \\Q2005\\E", "shortCiteRegEx": "Schuurman and Woeginger", "year": 2005}, {"title": "The Practice of Approximated Consistency for Knapsack Constraints", "author": ["M. Sellmann"], "venue": null, "citeRegEx": "Sellmann,? \\Q2004\\E", "shortCiteRegEx": "Sellmann", "year": 2004}, {"title": "CUDD: Colorado university decision diagram package. ftp://vlsi .colorado.edu/pub", "author": ["F. Somenzi"], "venue": null, "citeRegEx": "Somenzi,? \\Q1996\\E", "shortCiteRegEx": "Somenzi", "year": 1996}, {"title": "Algorithms for discrete function manipulation", "author": ["A. Srinivasan", "T. Kam", "S. Malik", "R.K. Brayton"], "venue": "In International Conference on CAD,", "citeRegEx": "Srinivasan et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Srinivasan et al\\.", "year": 1990}, {"title": "Comparing two implementations of a complete and backtrack-free interactive configurator", "author": ["S. Subbarayan", "R.M. Jensen", "T. Hadzic", "H.R. Andersen", "H. Hulgaard", "J. M\u00f8ller"], "venue": "In Proceedings of CP\u201904 CSPIA Workshop,", "citeRegEx": "Subbarayan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Subbarayan et al\\.", "year": 2004}, {"title": "On Exploiting Structures for Constraint Solving", "author": ["S.M. Subbarayan"], "venue": "Ph.D. thesis,", "citeRegEx": "Subbarayan,? \\Q2008\\E", "shortCiteRegEx": "Subbarayan", "year": 2008}, {"title": "Factored edge-valued binary decision diagrams", "author": ["P. Tafertshofer", "M. Pedram"], "venue": "In Formal Methods in System Design,", "citeRegEx": "Tafertshofer and Pedram,? \\Q1997\\E", "shortCiteRegEx": "Tafertshofer and Pedram", "year": 1997}, {"title": "Selected multicriteria shortest path problems: An analysis of complexity, models and adaptation of standard algorithms", "author": ["Z. Tarapata"], "venue": "International Journal of Applied Mathematics and Computer Science,", "citeRegEx": "Tarapata,? \\Q2007\\E", "shortCiteRegEx": "Tarapata", "year": 2007}, {"title": "A dynamic programming approach for consistency and propagation for knapsack constraints. In 3rd international workshop on integration of AI and OR techniques in constraint programming for combinatorial optimization problems CPAI-OR", "author": ["M. Trick"], "venue": null, "citeRegEx": "Trick,? \\Q2001\\E", "shortCiteRegEx": "Trick", "year": 2001}, {"title": "Solving constraint satisfaction problems using finite state automata", "author": ["N.R. Vempaty"], "venue": "In Proceedings of the Tenth National Conference on Artificial Intelligence,", "citeRegEx": "Vempaty,? \\Q1992\\E", "shortCiteRegEx": "Vempaty", "year": 1992}, {"title": "SAT v CSP", "author": ["T. Walsh"], "venue": "Proceedings of CP", "citeRegEx": "Walsh,? \\Q2000\\E", "shortCiteRegEx": "Walsh", "year": 2000}, {"title": "Branching Programs and Binary Decision Diagrams. Society for Industrial and Applied Mathematics (SIAM)", "author": ["I. Wegener"], "venue": null, "citeRegEx": "Wegener,? \\Q2000\\E", "shortCiteRegEx": "Wegener", "year": 2000}, {"title": "Decision diagrams for the computation of semiring valuations", "author": ["N. Wilson"], "venue": "In Proceedings of the Nineteenth International Joint Conference on Artificial Intelligence (IJCAI-05),", "citeRegEx": "Wilson,? \\Q2005\\E", "shortCiteRegEx": "Wilson", "year": 2005}], "referenceMentions": [{"referenceID": 53, "context": "Beside BDDs, a number of other structures, such as various sublanguages of negation normal forms (NNFs) (Darwiche & Marquis, 2002), AND/OR diagrams (Mateescu, Dechter, & Marinescu, 2008), finite state automata (Vempaty, 1992; Amilhastre, Fargier, & Marquis, 2002) and various extensions of decision diagrams (Drechsler, 2001; Wegener, 2000; Meinel & Theobald, 1998) are used as compilation targets.", "startOffset": 210, "endOffset": 263}, {"referenceID": 13, "context": "Beside BDDs, a number of other structures, such as various sublanguages of negation normal forms (NNFs) (Darwiche & Marquis, 2002), AND/OR diagrams (Mateescu, Dechter, & Marinescu, 2008), finite state automata (Vempaty, 1992; Amilhastre, Fargier, & Marquis, 2002) and various extensions of decision diagrams (Drechsler, 2001; Wegener, 2000; Meinel & Theobald, 1998) are used as compilation targets.", "startOffset": 308, "endOffset": 365}, {"referenceID": 55, "context": "Beside BDDs, a number of other structures, such as various sublanguages of negation normal forms (NNFs) (Darwiche & Marquis, 2002), AND/OR diagrams (Mateescu, Dechter, & Marinescu, 2008), finite state automata (Vempaty, 1992; Amilhastre, Fargier, & Marquis, 2002) and various extensions of decision diagrams (Drechsler, 2001; Wegener, 2000; Meinel & Theobald, 1998) are used as compilation targets.", "startOffset": 308, "endOffset": 365}, {"referenceID": 33, "context": "There are many highly optimized open-source BDD packages (e.g., Somenzi, 1996; Lind-Nielsen, 2001) that allow easy and efficient manipulation of BDDs.", "startOffset": 57, "endOffset": 98}, {"referenceID": 56, "context": "In its most generic interpretation (Wilson, 2005), edges of a decision diagram can be labeled with elements of a semiring to support algebraic computations relevant for probabilistic rea-", "startOffset": 35, "endOffset": 49}, {"referenceID": 25, "context": "M\u00f8ller, Andersen, and Hulgaard (2002) and Hadzic, Subbarayan, Jensen, Andersen, M\u00f8ller, and Hulgaard (2004) investigated such an approach by using binary decision diagrams (BDDs) as a compilation target.", "startOffset": 62, "endOffset": 108}, {"referenceID": 8, "context": "Beside BDDs, a number of other structures, such as various sublanguages of negation normal forms (NNFs) (Darwiche & Marquis, 2002), AND/OR diagrams (Mateescu, Dechter, & Marinescu, 2008), finite state automata (Vempaty, 1992; Amilhastre, Fargier, & Marquis, 2002) and various extensions of decision diagrams (Drechsler, 2001; Wegener, 2000; Meinel & Theobald, 1998) are used as compilation targets. Some of them are suitable for interactive configuration as well. In particular, Vempaty (1992) suggested compiling constraints into an automaton.", "startOffset": 105, "endOffset": 494}, {"referenceID": 21, "context": "This constitutes a novel addition to both existing product-configuration approaches as well as to approaches within multi-criteria decision making (Figueira et al., 2005).", "startOffset": 147, "endOffset": 170}, {"referenceID": 0, "context": "Amilhastre et al. (2002) suggest labeling edges of an automaton to reason abut optimal restorations and explanations.", "startOffset": 0, "endOffset": 25}, {"referenceID": 23, "context": "This task is of main interest since it delivers important interaction requirements: backtrackfreeness (user should never be forced to backtrack) and completeness (all valid configurations should be reachable) (Hadzic et al., 2004).", "startOffset": 209, "endOffset": 230}, {"referenceID": 5, "context": "The most well known member of this family are binary decision diagrams (BDDs) (Bryant, 1986) which are used for manipulating Boolean functions in many areas, such as verification, model checking, VLSI design (Meinel & Theobald, 1998; Wegener, 2000; Drechsler, 2001) etc.", "startOffset": 78, "endOffset": 92}, {"referenceID": 55, "context": "The most well known member of this family are binary decision diagrams (BDDs) (Bryant, 1986) which are used for manipulating Boolean functions in many areas, such as verification, model checking, VLSI design (Meinel & Theobald, 1998; Wegener, 2000; Drechsler, 2001) etc.", "startOffset": 208, "endOffset": 265}, {"referenceID": 13, "context": "The most well known member of this family are binary decision diagrams (BDDs) (Bryant, 1986) which are used for manipulating Boolean functions in many areas, such as verification, model checking, VLSI design (Meinel & Theobald, 1998; Wegener, 2000; Drechsler, 2001) etc.", "startOffset": 208, "endOffset": 265}, {"referenceID": 48, "context": "In fact, the unacceptably long worst-case response times have been empirically observed in a purely search-based approach to computing valid domains (Subbarayan et al., 2004).", "startOffset": 149, "endOffset": 174}, {"referenceID": 23, "context": "In our previous work we utilized Binary Decision Diagrams (BDDs) to represent all valid configurations so that CVD queries can be executed efficiently (Hadzic et al., 2004).", "startOffset": 151, "endOffset": 172}, {"referenceID": 35, "context": "The main motivation for this work is extending the interactive configuration approach of M\u00f8ller et al. (2002), Hadzic et al.", "startOffset": 89, "endOffset": 110}, {"referenceID": 23, "context": "(2002), Hadzic et al. (2004), Subbarayan et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 23, "context": "(2002), Hadzic et al. (2004), Subbarayan et al. (2004) to situations where in addition to a CSP model (X,D,F ) involving only hard constraints, there is also a cost function: c : D1 \u00d7 .", "startOffset": 8, "endOffset": 55}, {"referenceID": 34, "context": "Our approach can be extended to handle non-unary costs by adopting labeling techniques that are used with other graphical representations (e.g., Wilson, 2005; Mateescu et al., 2008).", "startOffset": 138, "endOffset": 181}, {"referenceID": 55, "context": "Such an MDD, denoted as Mc, can be generated using for example search with caching isomorphic nodes as suggested by Wilson (2005), or by extending the standard apply operator to handle weights as suggested by Mateescu et al.", "startOffset": 116, "endOffset": 130}, {"referenceID": 34, "context": "Such an MDD, denoted as Mc, can be generated using for example search with caching isomorphic nodes as suggested by Wilson (2005), or by extending the standard apply operator to handle weights as suggested by Mateescu et al. (2008).", "startOffset": 209, "endOffset": 232}, {"referenceID": 40, "context": "For example, in representations exploiting global CSP structure - such as weighted cluster trees (Pargamin, 2003) - adding non-additive cost functions increases the size of the clusters, as it is required that for each non-additive component ci(Xi) at least one cluster contains the entire scope Xi.", "startOffset": 97, "endOffset": 113}, {"referenceID": 39, "context": "For example, in representations exploiting global CSP structure - such as weighted cluster trees (Pargamin, 2003) - adding non-additive cost functions increases the size of the clusters, as it is required that for each non-additive component ci(Xi) at least one cluster contains the entire scope Xi. Furthermore, criteria for node merging of Wilson (2005) and Mateescu et al.", "startOffset": 98, "endOffset": 356}, {"referenceID": 34, "context": "Furthermore, criteria for node merging of Wilson (2005) and Mateescu et al. (2008) are more refined, since nodes are no longer isomorphic if they root the same set of feasible paths, but the paths must be of the same cost as well.", "startOffset": 60, "endOffset": 83}, {"referenceID": 56, "context": "Note that our approach can be further generalized to accommodate more general aggregation of costs as discussed by Wilson (2005). Cost functions ci need not map assignments of Xi variables into the set of real numbers R but to any set A equipped with operators \u2295,\u2297 such that A = (A,0,1,\u2295,\u2297) is a semiring.", "startOffset": 115, "endOffset": 129}, {"referenceID": 23, "context": "Our goal is to develop an efficient and easy to implement approach that can handle all instances handled previously through BDD-based configuration (Hadzic et al., 2004).", "startOffset": 148, "endOffset": 169}, {"referenceID": 3, "context": "as an MDD is in worst case exponential in the path-width (Bodlaender, 1993; Wilson, 2005; Mateescu et al., 2008).", "startOffset": 57, "endOffset": 112}, {"referenceID": 56, "context": "as an MDD is in worst case exponential in the path-width (Bodlaender, 1993; Wilson, 2005; Mateescu et al., 2008).", "startOffset": 57, "endOffset": 112}, {"referenceID": 34, "context": "as an MDD is in worst case exponential in the path-width (Bodlaender, 1993; Wilson, 2005; Mateescu et al., 2008).", "startOffset": 57, "endOffset": 112}, {"referenceID": 8, "context": "Such an approach was suggested by Huang and Darwiche (2004) to compile BDDs from CNF formulas, and it proved to be a valuable addition to standard compilation based on pairwise BDD conjunctions.", "startOffset": 44, "endOffset": 60}, {"referenceID": 54, "context": "There are several standard Boolean encodings of multi-valued variables (Walsh, 2000).", "startOffset": 71, "endOffset": 84}, {"referenceID": 54, "context": "There are several standard Boolean encodings of multi-valued variables (Walsh, 2000). In the log encoding scheme each xi is encoded with ki = dlog|Di|e Boolean variables, each representing a digit in binary notation. A multivalued assignment xi = a is translated into a set of assignments x i j = aj such that a = \u2211ki j=1 2 aj . Additionally, a domain constraint \u2211ki j=1 2 xj < |Di| is added to forbid those bit assignments (a1, . . . , a i ki ) that encode values outside domain Di. The direct encoding (or 1-hot encoding) is also common, and especially well suited for efficient propagation when searching for a single solution. In this scheme, each multi-valued variable xi is encoded with |Di| Boolean variables {x1, . . . , xki}, where each variable x i j indicates whether the j-th value in domain aj \u2208 Di is assigned. For each variable xi, exactly one value fromDi has to be assigned. Therefore, we enforce a domain constraint x i 1+. . .+x i ki = 1 for each i = 1, . . . , n. Hadzic, Hansen, and O\u2019Sullivan (2008) have empirically demonstrated that using log encoding rather than direct encoding yields smaller BDDs.", "startOffset": 72, "endOffset": 1022}, {"referenceID": 2, "context": "Bartzis and Bultan (2003) have shown that linear arithmetic constraints can be represented", "startOffset": 0, "endOffset": 26}, {"referenceID": 2, "context": "However, configuration constraints involve not only linear arithmetic constraints, and space savings reported by Bartzis and Bultan (2003) are significant only when all the variable domains have a size that is a power of two.", "startOffset": 113, "endOffset": 139}, {"referenceID": 23, "context": "2 MDD Extraction Once the BDD is generated using clustered variable ordering we can extract a corresponding MDD using a method which was originally suggested by Hadzic and Andersen (2006) and that was subsequently expanded by Hadzic et al.", "startOffset": 161, "endOffset": 188}, {"referenceID": 23, "context": "2 MDD Extraction Once the BDD is generated using clustered variable ordering we can extract a corresponding MDD using a method which was originally suggested by Hadzic and Andersen (2006) and that was subsequently expanded by Hadzic et al. (2008). In the following considerations, we will use a mapping cvar(xj) = i to denote the CSP variable xi of an encoding variable xj and, with a slight abuse of notation, we will apply cvar also to BDD nodes u labeled with xj .", "startOffset": 226, "endOffset": 247}, {"referenceID": 29, "context": "accepts as an input a CSP-like model is CLab (Jensen, 2007).", "startOffset": 45, "endOffset": 59}, {"referenceID": 33, "context": "It is a configuration interface on top of a BDD package BuDDy (Lind-Nielsen, 2001).", "startOffset": 62, "endOffset": 82}, {"referenceID": 21, "context": "Multi-cost scenarios are often considered within the multicriteria optimization framework (Figueira et al., 2005; Ehrgott & Gandibleux, 2000).", "startOffset": 90, "endOffset": 141}, {"referenceID": 28, "context": "In order to develop the FPTAS we use a standard scaling technique (Schuurman & Woeginger, 2005) originally presented by Ibarra and Kim (1975). Given an , let n be the number of decision variables.", "startOffset": 120, "endOffset": 142}, {"referenceID": 56, "context": "The second set of instances represents product-catalogue datasets used by Nicholson, Bridge, and Wilson (2006). These catalogues are defined explicitly, as tables of solutions.", "startOffset": 97, "endOffset": 111}, {"referenceID": 39, "context": "Remaining four instances are product catalogues used by Nicholson et al. (2006). For each instance we provide the number of solutions Sol, number of variables X, the minimal, maximal and average domain size.", "startOffset": 56, "endOffset": 80}, {"referenceID": 29, "context": "In the first set of experiments, for each instance we generated a log-encoded BDD B using CLab (Jensen, 2007).", "startOffset": 95, "endOffset": 109}, {"referenceID": 7, "context": "A comprehensive overview of such representations is presented by Darwiche and Marquis (2002). The critical restriction that makes NNF languages more tractable is decomposability.", "startOffset": 65, "endOffset": 93}, {"referenceID": 25, "context": "These weighted extensions correspond closely to our weighted MDDs since the variant of automata used by Vempaty (1992) is equivalent to merged MDDs (Hadzic et al., 2008).", "startOffset": 148, "endOffset": 169}, {"referenceID": 56, "context": "Semiring labeled decision diagrams (SLDDs) (Wilson, 2005) label edges of an (unordered) MDD with values from a semiring and allow computation of a number of queries relevant for reasoning under uncertainty.", "startOffset": 43, "endOffset": 57}, {"referenceID": 8, "context": "Arithmetic circuits are directed acyclic graphs where internal nodes are labeled with summation and multiplication operators while leaf nodes are labeled with constants or variables (Darwiche, 2002).", "startOffset": 182, "endOffset": 198}, {"referenceID": 7, "context": "In fact, the d-DNNF compiler of Huang and Darwiche (2005) can be specialized to compile OBDDs, which proved to be a valuable alternative way to BDD compilation.", "startOffset": 42, "endOffset": 58}, {"referenceID": 7, "context": "In fact, the d-DNNF compiler of Huang and Darwiche (2005) can be specialized to compile OBDDs, which proved to be a valuable alternative way to BDD compilation. Weighted and Multi-Valued Knowledge Compilation Structures. Most of the compiled representations for propositional theories have valued counterparts. Many of them can be seen as special cases of valued NNFs (VNNF) (Fargier & Marquis, 2007). Roughly, every valued counterpart is obtained by changing the semantics of nodes, from logical operators (such as \u2227, \u2228) to general operators \u2297 (that could be arithmetic, such as + and \u2217). Values of functions represented by these structures are no longer in {0, 1} but in R. Furthermore, functions need not be defined over Boolean domains, but could take finite-domain values. In general, subsets of VNNF that satisfy decomposability and operator distributivity support efficient optimization (Fargier & Marquis, 2007) and could, in principle, be used to support cost configuration. Construction of MDDs based on encoding into BDDs has been discussed by Srinivasan, Kam, Malik, and Brayton (1990). Amilhastre et al.", "startOffset": 42, "endOffset": 1098}, {"referenceID": 0, "context": "Amilhastre et al. (2002) augmented automata of Vempaty (1992) with edge weights to reason about optimal restorations and explanations.", "startOffset": 0, "endOffset": 25}, {"referenceID": 0, "context": "Amilhastre et al. (2002) augmented automata of Vempaty (1992) with edge weights to reason about optimal restorations and explanations.", "startOffset": 0, "endOffset": 62}, {"referenceID": 0, "context": "Amilhastre et al. (2002) augmented automata of Vempaty (1992) with edge weights to reason about optimal restorations and explanations. These weighted extensions correspond closely to our weighted MDDs since the variant of automata used by Vempaty (1992) is equivalent to merged MDDs (Hadzic et al.", "startOffset": 0, "endOffset": 254}, {"referenceID": 0, "context": "Amilhastre et al. (2002) augmented automata of Vempaty (1992) with edge weights to reason about optimal restorations and explanations. These weighted extensions correspond closely to our weighted MDDs since the variant of automata used by Vempaty (1992) is equivalent to merged MDDs (Hadzic et al., 2008). However, the weights are used to compute different queries and while we generate MDDs based on widely available BDD-packages, Vempaty (1992) does not report compilation tools used.", "startOffset": 0, "endOffset": 447}, {"referenceID": 10, "context": "A number of techniques based on tree-clustering (Dechter & Pearl, 1989) and variable-elimination (Dechter, 1999) exploit variable independencies that are present globally in a CSP model.", "startOffset": 97, "endOffset": 112}, {"referenceID": 3, "context": "Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993).", "startOffset": 156, "endOffset": 174}, {"referenceID": 34, "context": "AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order.", "startOffset": 12, "endOffset": 35}, {"referenceID": 49, "context": "Tree-of-BDDs (ToB) (Subbarayan, 2008) directly exploit tree clustering by representing each cluster as a BDD.", "startOffset": 19, "endOffset": 37}, {"referenceID": 3, "context": "Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993). While most of these techniques are geared towards enhancing search for a single (optimal) solution (adaptive consistency, bucket elimination etc), the same concepts can be utilized for compiling representations of all solutions. AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order. Due to utilization of variable independencies through \u2227-nodes, they are more succinct than MDDs and are therefore an attractive compilation target for cost-configuration. Furthermore, they are already extended to handle weighted graphical models to support Bayesian reasoning. However, publicly available tool support is limited and does not allow processing weighted CVD queries. Tree-driven-automata (Fargier & Vilarem, 2004) utilize tree clustering (Dechter & Pearl, 1989), to generate a partial variable ordering that is used to generate an automaton. Tree-driven-automata are equivalent to AND/OR MDDs and when restricted to the Boolean case they represent a subset of d-DNNF languages called strongly ordered decomposable decision graphs (SO-DDG) (Fargier & Marquis, 2006). Like AND/OR MDDs they are more succinct than MDDs and therefore are an interesting target for cost-configuration. However, tools for compiling tree-driven-automata are yet to become publicly available, and so far they have not been extended to handle costs. Weighted cluster trees of Pargamin (2003) are a weighted extension of cluster trees used to support interactive configuration with preferences.", "startOffset": 157, "endOffset": 1680}, {"referenceID": 3, "context": "Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993). While most of these techniques are geared towards enhancing search for a single (optimal) solution (adaptive consistency, bucket elimination etc), the same concepts can be utilized for compiling representations of all solutions. AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order. Due to utilization of variable independencies through \u2227-nodes, they are more succinct than MDDs and are therefore an attractive compilation target for cost-configuration. Furthermore, they are already extended to handle weighted graphical models to support Bayesian reasoning. However, publicly available tool support is limited and does not allow processing weighted CVD queries. Tree-driven-automata (Fargier & Vilarem, 2004) utilize tree clustering (Dechter & Pearl, 1989), to generate a partial variable ordering that is used to generate an automaton. Tree-driven-automata are equivalent to AND/OR MDDs and when restricted to the Boolean case they represent a subset of d-DNNF languages called strongly ordered decomposable decision graphs (SO-DDG) (Fargier & Marquis, 2006). Like AND/OR MDDs they are more succinct than MDDs and therefore are an interesting target for cost-configuration. However, tools for compiling tree-driven-automata are yet to become publicly available, and so far they have not been extended to handle costs. Weighted cluster trees of Pargamin (2003) are a weighted extension of cluster trees used to support interactive configuration with preferences. However, there is no publicly available compilation tool (an internal company-based implementation was presented), and the clusters are represented explicitly without utilizing compressions based on local structure through decision diagrams or other compiled representations. Tree-of-BDDs (ToB) (Subbarayan, 2008) directly exploit tree clustering by representing each cluster as a BDD. However, they do not support conditioning in polytime which is a fundamental transformation in supporting user interaction (assigning variables). However, they can be compiled for instances for which d-DNNF compilation fails, and empirical evaluation shows that on average conditioning times are short. BDD Extensions. There is a large variety of weighted extensions of binary decision diagrams, that represent real-valued functions f : {0, 1}n \u2192 R rather than Boolean functions f : {0, 1}n \u2192 {0, 1}. These extensions are limited to Boolean variables and their adoption in future would have to consider encoding techniques of multi-valued variables that avoid explosion in size and support cost processing. Comprehensive overviews of these extensions are presented by Drechsler (2001), Wegener (2000), and Meinel and Theobald (1998).", "startOffset": 157, "endOffset": 2953}, {"referenceID": 3, "context": "Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993). While most of these techniques are geared towards enhancing search for a single (optimal) solution (adaptive consistency, bucket elimination etc), the same concepts can be utilized for compiling representations of all solutions. AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order. Due to utilization of variable independencies through \u2227-nodes, they are more succinct than MDDs and are therefore an attractive compilation target for cost-configuration. Furthermore, they are already extended to handle weighted graphical models to support Bayesian reasoning. However, publicly available tool support is limited and does not allow processing weighted CVD queries. Tree-driven-automata (Fargier & Vilarem, 2004) utilize tree clustering (Dechter & Pearl, 1989), to generate a partial variable ordering that is used to generate an automaton. Tree-driven-automata are equivalent to AND/OR MDDs and when restricted to the Boolean case they represent a subset of d-DNNF languages called strongly ordered decomposable decision graphs (SO-DDG) (Fargier & Marquis, 2006). Like AND/OR MDDs they are more succinct than MDDs and therefore are an interesting target for cost-configuration. However, tools for compiling tree-driven-automata are yet to become publicly available, and so far they have not been extended to handle costs. Weighted cluster trees of Pargamin (2003) are a weighted extension of cluster trees used to support interactive configuration with preferences. However, there is no publicly available compilation tool (an internal company-based implementation was presented), and the clusters are represented explicitly without utilizing compressions based on local structure through decision diagrams or other compiled representations. Tree-of-BDDs (ToB) (Subbarayan, 2008) directly exploit tree clustering by representing each cluster as a BDD. However, they do not support conditioning in polytime which is a fundamental transformation in supporting user interaction (assigning variables). However, they can be compiled for instances for which d-DNNF compilation fails, and empirical evaluation shows that on average conditioning times are short. BDD Extensions. There is a large variety of weighted extensions of binary decision diagrams, that represent real-valued functions f : {0, 1}n \u2192 R rather than Boolean functions f : {0, 1}n \u2192 {0, 1}. These extensions are limited to Boolean variables and their adoption in future would have to consider encoding techniques of multi-valued variables that avoid explosion in size and support cost processing. Comprehensive overviews of these extensions are presented by Drechsler (2001), Wegener (2000), and Meinel and Theobald (1998).", "startOffset": 157, "endOffset": 2969}, {"referenceID": 3, "context": "Both time and space complexity of these techniques turn out to be bounded exponentially in the size of an important graph-connectivity notion of tree-width (Bodlaender, 1993). While most of these techniques are geared towards enhancing search for a single (optimal) solution (adaptive consistency, bucket elimination etc), the same concepts can be utilized for compiling representations of all solutions. AND/OR MDDs (Mateescu et al., 2008) when restricted to Boolean variables are a subset of d-DNNF formulas, where variable labeling respects a pseudo-tree obtained by a variable elimination order. Due to utilization of variable independencies through \u2227-nodes, they are more succinct than MDDs and are therefore an attractive compilation target for cost-configuration. Furthermore, they are already extended to handle weighted graphical models to support Bayesian reasoning. However, publicly available tool support is limited and does not allow processing weighted CVD queries. Tree-driven-automata (Fargier & Vilarem, 2004) utilize tree clustering (Dechter & Pearl, 1989), to generate a partial variable ordering that is used to generate an automaton. Tree-driven-automata are equivalent to AND/OR MDDs and when restricted to the Boolean case they represent a subset of d-DNNF languages called strongly ordered decomposable decision graphs (SO-DDG) (Fargier & Marquis, 2006). Like AND/OR MDDs they are more succinct than MDDs and therefore are an interesting target for cost-configuration. However, tools for compiling tree-driven-automata are yet to become publicly available, and so far they have not been extended to handle costs. Weighted cluster trees of Pargamin (2003) are a weighted extension of cluster trees used to support interactive configuration with preferences. However, there is no publicly available compilation tool (an internal company-based implementation was presented), and the clusters are represented explicitly without utilizing compressions based on local structure through decision diagrams or other compiled representations. Tree-of-BDDs (ToB) (Subbarayan, 2008) directly exploit tree clustering by representing each cluster as a BDD. However, they do not support conditioning in polytime which is a fundamental transformation in supporting user interaction (assigning variables). However, they can be compiled for instances for which d-DNNF compilation fails, and empirical evaluation shows that on average conditioning times are short. BDD Extensions. There is a large variety of weighted extensions of binary decision diagrams, that represent real-valued functions f : {0, 1}n \u2192 R rather than Boolean functions f : {0, 1}n \u2192 {0, 1}. These extensions are limited to Boolean variables and their adoption in future would have to consider encoding techniques of multi-valued variables that avoid explosion in size and support cost processing. Comprehensive overviews of these extensions are presented by Drechsler (2001), Wegener (2000), and Meinel and Theobald (1998). An immediate extension is in the form of algebraic decision diagrams (ADDs) (Bahar, Frohm, Gaona,", "startOffset": 157, "endOffset": 3001}, {"referenceID": 41, "context": "Affine ADDs (AADDs) of Sanner and McAllester (2005) further introduce additive and multiplicative edge weights for any edge (regardless of v(e)).", "startOffset": 23, "endOffset": 52}, {"referenceID": 21, "context": "Our multiple-cost configuration is close to approaches within a framework of multi-criteria optimization where a decision maker should find a solution subject to multiple (often conflicting) objectives (Figueira et al., 2005; Ehrgott & Gandibleux, 2000).", "startOffset": 202, "endOffset": 253}, {"referenceID": 51, "context": "In particular, our MDD-based algorithms are very close to the approaches for solving multiobjective shortest path problem, where for a given graph (V,E) each arc is labeled with multiple costs, and the goal is typically to compute the set of Pareto-optimal (efficient, non-dominated) solutions (Ehrgott & Gandibleux, 2000; M\u00fcller-Hannemann & Weihe, 2001; Tarapata, 2007; Reinhardt & Pisinger, 2009).", "startOffset": 294, "endOffset": 398}, {"referenceID": 21, "context": "Our multiple-cost configuration is close to approaches within a framework of multi-criteria optimization where a decision maker should find a solution subject to multiple (often conflicting) objectives (Figueira et al., 2005; Ehrgott & Gandibleux, 2000). In particular, our MDD-based algorithms are very close to the approaches for solving multiobjective shortest path problem, where for a given graph (V,E) each arc is labeled with multiple costs, and the goal is typically to compute the set of Pareto-optimal (efficient, non-dominated) solutions (Ehrgott & Gandibleux, 2000; M\u00fcller-Hannemann & Weihe, 2001; Tarapata, 2007; Reinhardt & Pisinger, 2009). It has been shown that the multi-objective shortest path problem is intractable. In particular, the number of Pareto-optimal solutions can grow exponentially with the number of vertices |V |, but a FPTAS (fully polynomial time approximation scheme) has been developed for approximating the set of Pareto-optimal solutions. However, the way in which the solution space of multi-criteria optimization problems is explored is significantly different from our approach. Typically, in each interaction step a subset of Pareto-optimal solutions is computed and afterwards a decision maker interactively navigates through the set in order to reach the satisfying compromising solution. Interactive methods in multi-criteria optimization usually compute a subset of solutions on the efficient frontier, suggest it to the user for evaluation, and based on his input compute a new set of solutions (Figueira et al., 2005, Chapter 16). These techniques would use the user input to better estimate the way to aggregate multiple objectives, and some of them would require the user to explicitly assign weights of importance to objectives. In contrast, instead of being primarily driven by the costs of solutions, our interactive approach supports reasoning about the variable assignments in the solutions themselves through valid domains computation. It is an inherently different way of exploring the solution space which is more adequate for users that want explicit control over variable assignments and not just indicating the importance of cost functions. Most of the approaches in the CSP community model preferences as soft constraints (Meseguer, Rossi, & Shiex, 2006) that can be partially satisfied or violated, with a goal to find the most satisfying or the least violating solution. This usually presupposes that preferences can be aggregated via algebraic operators, and as such is more related to single-cost optimization problems. However, the approach by Roll\u00f3n and Larrosa (2006) deals with multiple costs explicitly.", "startOffset": 203, "endOffset": 2638}, {"referenceID": 21, "context": "Our multiple-cost configuration is close to approaches within a framework of multi-criteria optimization where a decision maker should find a solution subject to multiple (often conflicting) objectives (Figueira et al., 2005; Ehrgott & Gandibleux, 2000). In particular, our MDD-based algorithms are very close to the approaches for solving multiobjective shortest path problem, where for a given graph (V,E) each arc is labeled with multiple costs, and the goal is typically to compute the set of Pareto-optimal (efficient, non-dominated) solutions (Ehrgott & Gandibleux, 2000; M\u00fcller-Hannemann & Weihe, 2001; Tarapata, 2007; Reinhardt & Pisinger, 2009). It has been shown that the multi-objective shortest path problem is intractable. In particular, the number of Pareto-optimal solutions can grow exponentially with the number of vertices |V |, but a FPTAS (fully polynomial time approximation scheme) has been developed for approximating the set of Pareto-optimal solutions. However, the way in which the solution space of multi-criteria optimization problems is explored is significantly different from our approach. Typically, in each interaction step a subset of Pareto-optimal solutions is computed and afterwards a decision maker interactively navigates through the set in order to reach the satisfying compromising solution. Interactive methods in multi-criteria optimization usually compute a subset of solutions on the efficient frontier, suggest it to the user for evaluation, and based on his input compute a new set of solutions (Figueira et al., 2005, Chapter 16). These techniques would use the user input to better estimate the way to aggregate multiple objectives, and some of them would require the user to explicitly assign weights of importance to objectives. In contrast, instead of being primarily driven by the costs of solutions, our interactive approach supports reasoning about the variable assignments in the solutions themselves through valid domains computation. It is an inherently different way of exploring the solution space which is more adequate for users that want explicit control over variable assignments and not just indicating the importance of cost functions. Most of the approaches in the CSP community model preferences as soft constraints (Meseguer, Rossi, & Shiex, 2006) that can be partially satisfied or violated, with a goal to find the most satisfying or the least violating solution. This usually presupposes that preferences can be aggregated via algebraic operators, and as such is more related to single-cost optimization problems. However, the approach by Roll\u00f3n and Larrosa (2006) deals with multiple costs explicitly. It utilizes global structure (i.e. variable independencies) of the weighted CSP model to compute an efficient frontier through bucket-based variable elimination. A highly related approach that utilizes global structure of the generalized additive independence (GAI) network is presented by Dubus, Gonzales, and Perny (2009). In order to compute the efficient frontier, the authors use a message passing computation mechanism which is analogous to computing buckets.", "startOffset": 203, "endOffset": 3000}, {"referenceID": 50, "context": "Trick (2001) used dynamic programming to propagate Knapsack constraints during CSP search.", "startOffset": 0, "endOffset": 13}, {"referenceID": 17, "context": "Fahle and Sellmann (2002) presented an approximated filtering algorithm, based on various integer programming bounds for the Knapsack problem.", "startOffset": 0, "endOffset": 26}, {"referenceID": 17, "context": "Fahle and Sellmann (2002) presented an approximated filtering algorithm, based on various integer programming bounds for the Knapsack problem. Sellmann (2004) presented a fully polynomial time approximation algorithm for approximated filtering.", "startOffset": 0, "endOffset": 159}, {"referenceID": 21, "context": "multiple cost restrictions is a novel addition to interaction modes within multiple-criteria decision making (Figueira et al., 2005).", "startOffset": 109, "endOffset": 132}, {"referenceID": 22, "context": "We therefore strictly extend BDD-based configuration of Hadzic et al. (2004) to support cost-bounding of additive cost functions without incurring exponential increase in complexity.", "startOffset": 56, "endOffset": 77}, {"referenceID": 15, "context": "multiobjective non-unary optimization (e.g., Roll\u00f3n & Larrosa, 2006; Dubus et al., 2009) can be adopted to operate over MDD representation of a solution space.", "startOffset": 38, "endOffset": 88}], "year": 2010, "abstractText": "In many AI domains such as product configuration, a user should interactively specify a solution that must satisfy a set of constraints. In such scenarios, offline compilation of feasible solutions into a tractable representation is an important approach to delivering efficient backtrack-free user interaction online. In particular, binary decision diagrams (BDDs) have been successfully used as a compilation target for product and service configuration. In this paper we discuss how to extend BDD-based configuration to scenarios involving cost functions which express user preferences. We first show that an efficient, robust and easy to implement extension is possible if the cost function is additive, and feasible solutions are represented using multi-valued decision diagrams (MDDs). We also discuss the effect on MDD size if the cost function is non-additive or if it is encoded explicitly into MDD. We then discuss interactive configuration in the presence of multiple cost functions. We prove that even in its simplest form, multiple-cost configuration is NP-hard in the input MDD. However, for solving two-cost configuration we develop a pseudo-polynomial scheme and a fully polynomial approximation scheme. The applicability of our approach is demonstrated through experiments over real-world configuration models and product-catalogue datasets. Response times are generally within a fraction of a second even for very large instances.", "creator": "dvips(k) 5.96dev Copyright 2007 Radical Eye Software"}}}