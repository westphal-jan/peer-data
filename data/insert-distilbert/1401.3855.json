{"id": "1401.3855", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Algorithms for Closed Under Rational Behavior (CURB) Sets", "abstract": "we provide a series of algorithms demonstrating that solutions according to the fundamental game - theoretic solution concept of closed under rational behavior ( curb ) sets resulting in two - player, normal - form games can be computed in polynomial time ( we also discuss extensions to n - player games ). first, we describe an algorithm that identifies all of a player's best responses conditioned on the belief that the other player will play from vertices within a given subset of excluding its strategy space. this algorithm serves as a subroutine in a series of polynomial - time algorithms for finding known all minimal curb sets, one minimal curb set, and the infinitely smallest minimal curb set in a game. we then show that the complexity demanded of finding a nash equilibrium can be exponential only in the size of a game's smallest curb set. related to this, we show that the smallest curb set can be an arbitrarily small portion of enjoying the game, but it can also be arbitrarily larger than the supports of its only enclosed nash equilibrium. we test our algorithms empirically and strongly find that most genuinely commonly studied academic games tend to have either exceptionally very large or very small minimal curb sets.", "histories": [["v1", "Thu, 16 Jan 2014 05:01:13 GMT  (275kb)", "http://arxiv.org/abs/1401.3855v1", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["michael benisch", "george b davis", "tuomas sandholm"], "accepted": false, "id": "1401.3855"}, "pdf": {"name": "1401.3855.pdf", "metadata": {"source": "CRF", "title": "Algorithms for Closed Under Rational Behavior (CURB) Sets", "authors": ["Michael Benisch", "George B. Davis", "Tuomas Sandholm"], "emails": ["mbenisch@cs.cmu.edu", "gbd@cs.cmu.edu", "sandholm@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "For noncooperative multi-agent settings, game-theoretic solution concepts help players choose strategies, help modelers predict outcomes, and help mechanism designers guarantee properties of the systems they create. Significant attention has been given to algorithms for computing solutions according to concepts of subgame perfect Nash equilibrium (e.g., minimax search and \u03b1-\u03b2-pruning), Nash equilibrium (Lemke & Howson, 1964; Porter, Nudelman, & Shoham, 2004; Sandholm, Gilpin, & Conitzer, 2005), correlated equilibrium (Gilboa & Zemel, 1989), iterative dominance (Knuth, Papadimitriou, & Tsitsiklis, 1988; Conitzer & Sandholm, 2005a), and other related concepts (Conitzer & Sandholm, 2005b).\nThe Nash equilibrium concept, under which each player weakly prefers its strategy as long as the other players do not deviate from theirs, remains the most important pointvalued game-theoretic solution concept. However, it has been shown that, even in twoplayer games with binary utilities, computing a single Nash equilibrium is PPAD-complete (Chen & Deng, 2006; Abbott, Kane, & Valiant, 2005), suggesting that no algorithms exist for computing these equilibria in worst-case polynomial time (Daskalakis, Goldberg, & Papadimitriou, 2009).\nc\u00a92010 AI Access Foundation. All rights reserved.\nThere are other fundamental solution concepts that have some known advantages over Nash equilibria, and\u2014as we will show\u2014solutions according to some of these concepts can be found in polynomial time, even in the worst case. Specifically, we will study the fundamental concept of closed under rational behavior (CURB) strategy sets in two-player, normal-form games. A game can have multiple Nash equilibria, but each of those is a point, or a single (potentially mixed) strategy for each player. In contrast, a CURB set can contain multiple strategies for each player, and it is stable so long as players choose any (potentially mixed) strategies from within the set.\nCURB sets are based on the notion of rationalizability, which was introduced by Pearce (1984) and Bernheim (1984). Rationalizability is, by now, a widely known, robust gametheoretic solution concept and has been used to study various applications, such as first-price auctions (Battigalli & Siniscalchi, 2003). Its main insight is that rationality restricts players from ever playing strategies that are not best responses given the beliefs they hold about their opponents. Strategies that are not best responses to a set of consistent beliefs about opposing strategies are said not to be rationalizable. In two-player games, the process of iteratively eliminating strategies that are dominated, that is strategies that are not best responses to any opponent strategy, captures the concept of rationalizability. It emulates the players\u2019 assumptions that an opponent will never play a strategy that is not a best response to one of the player\u2019s own remaining strategies (Pearce, 1984).\nThe set of all players\u2019 rationalizable strategies has the property that no player\u2019s best response to any pure or mixed strategy inside the set lies outside the set \u2013 in other words, the set is CURB. However, this CURB set may also have CURB subsets, which demonstrates how CURB sets extend the notion of rationalizability. Basu and Weibull (1991) introduced the notion of a minimal CURB set, or a CURB set that does not contain any CURB subsets, and proved that each minimal CURB set is guaranteed to contain the supports of at least one Nash equilibrium.\nThe minimal CURB set solution concept has since been motivated from several perspectives in academic literature, including the following:\n\u2022 Mixed-strategy Nash equilibria (the type guaranteed to exist in every game) can be highly unstable, because a player may be indifferent between some of its strategies. Strict Nash equilibria, where players strictly prefer their strategies in equilibrium, are a more stable alternative, but they are not guaranteed to exist. Minimal CURB sets always exist and have been referred to as the \u201cnearest set-valued generalization of strict Nash equilibria,\u201d since they are the smallest sets of strategies that include all ways of choosing among the indifferences of an equilibrium (Basu & Weibull, 1991).\n\u2022 A CURB set can be viewed as a subspace of strategies within which any best-response dynamic (even a best-response dynamic of mixed strategies) will stay. Thus, CURB sets have been used as a solution concept to describe the strategy subspace where iteratively adapting agents will eventually settle (Hurkens, 1995).\n\u2022 Voorneveld et.al. enumerated a number of other properties of minimal CURB sets that illustrate the stability of set-based solution concepts over point-valued concepts, such as Nash equilibria (Voorneveld, Kets, & Norde, 2005).\nIn order for a solution concept to be operational, it must also be accompanied by algorithms for applying it. Finding minimal CURB sets has been previously considered challenging (Pruzhansky, 2003), and, prior to this work on CURB sets, little had been done on the problem from a computational standpoint. To our knowledge, the only such work to predate ours was that of Pruzhansky, which studied sequential games of perfect information. Such games are relatively simple, in that they contain exactly one minimal CURB set, and a straightforward algorithm can quickly find it by exploiting the sequential representation (Pruzhansky, 2003). In this paper, we present the first thorough computational treatment of CURB sets in general two-player games. We show that, in these settings, minimal CURB sets are actually easy to find: the time complexity is polynomial in the size of the game, even in the worst case.\nThe primary source of complexity for our algorithms is a linear programming-based subroutine for finding all of a player\u2019s best responses (i.e., utility-maximizing pure strategies) conditioned on the belief that the other player will play from within a given subset of its strategy space. This problem can be solved fast for two players, in this case it involves solving a simple linear feasibility program, but the mathematical program we use is of degree p\u2212 1, where p is the number of players, and with p = 3 the constraints are already quadratic. On the plus side, our CURB set algorithms only make a polynomial number of calls to this subroutine. If future research is able to identify polynomial-time algorithms for finding all of a player\u2019s best responses in n-player games, then our CURB set algorithms will also be polynomial time in those settings. Additionally, our algorithms have been useful as templates for the development of other algorithms to compute related solution concepts in n-player games (Brandt, Brill, Fischer, & Harrenstein, 2009; Jordan & Wellman, 2010).\nThe rest of the paper is organized as follows. We begin with some preliminaries on our notations and definitions. Next, we present and analyze our algorithm for finding conditional best responses, which serves as the main subroutine of our CURB set finding algorithms. We then present and analyze a family of polynomial-time algorithms for twoplayer, normal-form games that compute all of a game\u2019s minimal CURB sets, a single one of its minimal CURB sets, and its smallest minimal CURB set. Finally, we discuss additional applications of our results, including the potential for our CURB set algorithms to bound the theoretical complexity of finding Nash equilibria."}, {"heading": "2. Preliminaries", "text": "We describe and analyze our algorithms in the classic game-theoretic setting of a two-player, normal-form game represented as a matrix with rows corresponding to the pure strategies (or actions) of one player, player r, and columns corresponding to the pure strategies of the other, player c. (For shorthand, we will often omit the term \u201cpure\u201d and refer to a pure strategy simply as a strategy.) As is typical in game theory, the players are assumed to be fully-rational, utility-maximizing agents.\nEach row in the game matrix corresponds to a strategy, sr, from the set of all player r\u2019s strategies, Sr. Likewise, each column corresponds to a strategy, sc, from the set of all of player c\u2019s strategies, Sc. The cell corresponding to strategies sr and sc contains two entries, one indicating the real-valued utility of the row player when sr and sc are played, ur(sr, sc), and the other indicating that of the column player when those two strategies are played,\nuc(sr, sc). Using these entities, we also refer to a game, G, as a tuple, G = \u3008Sr, Sc, ur, uc\u3009. The size of the game, which we refer to as n, is the total number of strategies it contains, n = |Sr|+ |Sc|.\nA mixed strategy, or mixture, is a probability distribution over pure strategies, or a function, mi, that maps from each of player i\u2019s pure strategies to a probability, mi : Si \u2192 [0, 1] and\n\u2211 s\u2208Si\nmi(s) = 1. The supports of a mixture are all of the pure strategies in the mixture with non-zero probability. The set of all possible mixtures with supports in some set of strategies, Si, is denoted M(Si), and can be thought of as a simplex with degree |Si| \u2212 1. A pure strategy can be represented as a point-mass mixture, that is a mixture with all of its probability mass on one strategy.\nA strategy profile is a set of pure or mixed strategies, with one for each player. When a mixed-strategy profile is played, a player\u2019s utility is assumed to be its expected utility, which is given by summing that player\u2019s utility for each possible pure-strategy profile weighted by the profile\u2019s joint probability according to the mixtures, e.g., ur(mr,mc) =\u2211\nsr\u2208Sr mr(sr) \u2211 sc\u2208Sc\nmc(sc)ur(sr, sc). We occasionally use the notation \u2212i to refer to the player or players other than some player i. When used as a subscript on a strategy-related entity with more than two players, we intend for the \u2212i to refer to one instance of the entity per player (e.g., m\u2212i is a mixed-strategy profile containing one mixture per player other than i).\nPlayer i\u2019s best responses to a mixed strategy of the other player(s), m\u2212i, are given by the function \u03b2i(m\u2212i). These are the pure strategies that maximize player i\u2019s utility if the other player(s) play m\u2212i.\nFor a set of the other player\u2019s pure strategies, S\u2212i, we define \u03b2i(S\u2212i) to be a function that returns player i\u2019s best responses to every mixture with supports in S\u2212i, \u03b2i(S\u2212i) =\u22c3\nm\u2208M(S\u2212i) \u03b2i(m). In Section 3, we describe an algorithm for computing the pure strategies in \u03b2i(S\u2212i) that serves as a subroutine in our CURB set algorithms, and we refer to the strategies it computes as conditionally rational. We define \u03b2(S) (without a subscript i) as the union of the sets \u03b2i(S\u2212i) for all players.\nA CURB set, S, is formally defined as a set of pure strategies (with at least one strategy for each player) that contains the best responses to any mixture over itself: if S is CURB and players believe that no strategy outside of S will be played with positive probability by their opponents, then such strategies will indeed not be played by rational players. Using the notation above, a set, S, is CURB if \u03b2(S) \u2286 S. (The entire game is trivially CURB by this definition.) We refer to the number of strategies in a CURB set as its size. The intersection of two CURB sets, S1 and S2, is the set of strategies attained by taking the intersection of their strategy sets, SI = S1 \u2229 S2. Two CURB sets overlap if they share a strategy (i.e., their intersection is non-empty).\nA Nash equilibrium is a pure- or mixed-strategy profile, {mr,mc}, such that each player\u2019s strategy is at least as good as its best response to the other\u2019s, ur(mr,mc) = ur(s \u2217 r ,mc) and uc(mr,mc) = uc(mr, s \u2217 c), where s \u2217 r \u2208 \u03b2r(mc) and s \u2217 c \u2208 \u03b2c(mr). A strict Nash equilibrium is a pure-strategy profile, {sr, sc}, where each player\u2019s strategy is its only best response to the other\u2019s, \u03b2r(sc) = {sr} and \u03b2c(sr) = {sc}. A CURB set that contains only one strategy per player is also a pure-strategy Nash equilibrium."}, {"heading": "3. Finding Conditional Best Responses", "text": "Finding all of a player\u2019s best responses conditioned on the belief that the other player will play from within some subset of its total strategy space, is a problem of interest in its own right, and it plays a central role in our computation of CURB sets. This section describes a polynomial-time algorithm, all conditionally rational, for doing just that. The algorithm below is for the row player; the column player\u2019s variant is symmetric. The inputs to the algorithm are a set of row-player strategies to consider, Sr, a set of column-player strategies they may be played against, Sc, and the row player\u2019s utility function, ur.\nfunction all conditionally rational(Sr, Sc, ur)\nS\u2217r \u2190 \u2205 for each row strategy, sr \u2208 Sr do if there exists a feasible solution to the following linear feasibility program:\nfind psc such that\n\u2211\nsc\u2208Sc\npsc = 1 (1)\n\u2211\nsc\u2208Sc\npscur(sr, sc) \u2265 \u2211\nsc\u2208Sc\npscur(s \u2032 r, sc) \u2200s \u2032 r \u2208 Sr \\ sr (2)\npsc \u2265 0 \u2200sc \u2208 Sc (3)\nthen S\u2217r \u2190 S \u2217 r \u222a sr\nreturn S\u2217r\nFor each row strategy, sr \u2208 Sr, a linear feasibility program (LFP) (i.e., a linear program with no objective) is constructed to find a mixture of probabilities over column-player strategies, psc , such that sr is the row player\u2019s best response. The constraints of the LFP ensure that the mixture is valid (sums to one), and that the row player\u2019s utility by playing sr against psc is greater than or equal to that of any other strategy. If the LFP has a feasible solution, sr is added to the set of best responses to be returned.\nThe computational complexity of the algorithms described in this paper depend on the total number of strategies in the game, n, and the complexity of solving an LFP with a number of variables and constraints bounded by n, which we will denote as LFP(n). LFPs can be solved in low-order polynomial time, even in the worst case, and the fastest known algorithms for LFPs have better worst-case guarantees than the fastest known linear programming algorithms (Ye, 2006). In our experiments, we solve the LFP using the simplex algorithm, which has exponential worst-case time complexity, but is known to outperform polynomial-time linear programming algorithms in practice.\nProposition 1. The all conditionally rational algorithm returns a player\u2019s best responses to every mixture over the input strategy set, and nothing else. Its worst-case time complexity is \u0398(n)\u00d7 LFP(n).\nProof. Since all conditionally rational runs this program on all strategies and includes them in the return set only if the LFP is feasible, it must be correct. Since the LFP is executed once for each strategy, and its size is bounded by n, all conditionally rational has complexity as shown."}, {"heading": "4. Finding CURB Sets", "text": "We now turn our attention to the problem of finding CURB sets. The algorithm below finds the smallest CURB set that contains a given seed strategy within a given subgame. (The returned set is not necessarily minimally CURB.) The algorithm repeatedly alternates between players, each time calling all conditionally rational to add the strategies necessary for maintaining the CURB property. If an iteration passes without any strategies being added, the algorithm has converged.\nfunction min containing CURB(sr,G = \u3008Sr, Sc, ur, uc\u3009)\nS\u2217r \u2190 {sr}, S \u2217 c \u2190 \u2205 converged\u2190 false while \u00acconverged do converged\u2190 true for i \u2208 {r, c} do S\u2032i \u2190 all conditionally rational(Si, S \u2217 \u2212i, ui)\nif S\u2032i \\ S \u2217 i 6= \u2205 then\nconverged\u2190 false S\u2217i \u2190 S \u2217 i \u222a S \u2032 i\nreturn S\u2217r \u222a S \u2217 c\nIt is worth noting that on the second-to-last line of the algorithm (S\u2217i \u2190 S \u2217 i \u222a S \u2032 i) it is necessary to merge the old strategies, S\u2217i , with the newly identified strategies, S \u2032 i, because S\u2032i is not always a superset of S \u2217 i . If, instead, S \u2217 i were replaced by S \u2032 i, then it would be possible for the seed strategy to be eliminated during the algorithm\u2019s first iteration. For example, consider the following game.\nsc1 sc2 sr1 1,1 0,0 sr2 0,1 1,0\nIf strategy sr2 is used as a seed, then on the first iteration S \u2217 r is initialized to {sr2}, S \u2217 c is then set to {sc1}, and finally S \u2217 r is set to {sr1}. Thus, without the merge the algorithm would output a subgame that does not contain the seed strategy.\nProposition 2. The min containing CURB algorithm has worst-case runtime \u0398(n2) \u00d7 LFP(n).\nProof. Every two calls made to all conditionally rational must add a strategy to the return set, or min containing CURB will terminate. Since at most n strategies can be added this way, the complexity of min containing CURB is \u0398(n2)\u00d7 LFP(n).\nTheorem 1. The min containing CURB algorithm is correct, that is, the returned set, S\u2217, is the smallest set of strategies that both 1) contains the given seed strategy, sr, and 2) is CURB.\nProof. The convergence of the algorithm implies that no strategies outside of S\u2217 are best responses to some mixture with supports in S\u2217. Therefore, \u03b2(S\u2217) \u2286 S\u2217, and S\u2217 is CURB.\nTo prove that S\u2217 is the smallest CURB set containing sr, we can use induction on the strategies that are added.\nBase Case: Initially, S\u2217 contains only sr and \u03b2c(sr). At this point, S \u2217 is a subset of the the smallest CURB set containing sr. Inductive Step: Each time a new strategy, s\u2217, is added to S\u2217, it is necessarily a best response to some mixture, m \u2208 M(S\u2217), over the strategies already contained in S\u2217. Since strategies are never removed from S\u2217 during execution, m will remain a valid mixture. Therefore, each strategy that is added is necessary to maintain the CURB property.\nWe will now present three algorithms that use min containing CURB to determine a game\u2019s minimal CURB sets. To facilitate our discussion of these algorithms, we first present three results regarding CURB set structure, which, to the best of our knowledge, were not previously known.\nTheorem 2. If each of two intersecting strategy sets is CURB, then their intersection is also CURB.\nProof. Consider two CURB sets, SA and SB, with nonempty intersection, SI . For any mixture over strategies in SI belonging to (without loss of generality) the row player, there exists a set of pure strategies that are the column player\u2019s best responses, S\u2217c . Because SA is CURB, it also contains all of the strategies in S\u2217c (i.e., S \u2217 c \u2286 SA); likewise S \u2217 c \u2286 SB. Therefore, S\u2217c is within their intersection, SI .\nSince the intersection of two CURB sets must be CURB and contained in both sets, we also have the following two corollaries.\nCorollary 1. Distinct minimal CURB sets cannot overlap (i.e., share rows or columns).\nCorollary 2. Each strategy belongs to at most one minimal CURB set."}, {"heading": "4.1 Finding All Minimal CURB Sets", "text": "The broadest query one can make regarding the minimal CURB set structure of a game is asking for all of its minimal CURB sets. This is useful, for example, in the adaptive agent context to identify regions of the strategy space in which learning agents are likely to settle (Hurkens, 1995).\nThe all MC algorithm does this by first checking each pair of strategies for size-two CURB sets (i.e., pure-strategy Nash equilibria) and adding them to the return set of minimal CURB sets. Since this operation is only \u0398(n2), it can be done as a preprocessing step without affecting the algorithm\u2019s worst-case time complexity, and the strategies it finds can be eliminated from future consideration. The all MC algorithm then determines all of the minimal CURB sets in the remaining subgame by calling min containing CURB with each row strategy, in turn, as a seed.\nAt first, we call min containing CURB using the entire remaining subgame as an input. However, we accelerate subsequent calls to min containing CURB by maintaining a map between each strategy and the smallest CURB set in which it has been discovered so far. (The entries added to this map are also stored as candidate minimal CURB sets.) When a new strategy is used as a seed, we use the smallest known CURB set containing that strategy as the second input to min containing CURB. Whenever a smaller CURB set containing a new seed is identified, we eliminate all of the candidate minimal CURB sets that contain the newly found one. Once each strategy has been used as a seed, all MC terminates and returns the remaining candidate minimal CURB sets.\nProposition 3. The all MC algorithm finds all of a game\u2019s minimal CURB sets, and nothing else. Its worst-case runtime is \u0398(n3)\u00d7 LFP(n). Its best-case runtime is \u0398(n2).\nProof. By Corollary 1, the minimal CURB set for any strategy must either equal, or be contained by, any other CURB set in which that strategy is found. Therefore, restricting the min containing CURB search to the smallest CURB set in which a strategy has been found so far is valid, and the main loop of all MC will discover all minimal CURB sets in the game. Since any CURB set that is not minimal must have contained one of the minimal CURB sets discovered, it is removed when the smaller CURB set is discovered (or not added if the smaller set was previously discovered).\nIn the worst case, all MC must call min containing CURB n times, with the full game as a parameter, giving time complexity \u0398(n3)\u00d7 LFP(n). The best-case complexity follows from a best-case game where each strategy is part of a pure-strategy Nash equilibrium."}, {"heading": "4.2 Finding One Minimal CURB Set", "text": "Rather than finding all minimal CURB sets in a game, it may be desirable to find a single minimal CURB set. To complete this quickly, we first choose a random seed strategy and check if it is part of any size-two CURB sets (i.e., part of a pure-strategy Nash equilibrium), which takes O(n) time. If that fails, we use the min containing CURB algorithm with the randomly-chosen strategy as the seed and the full game as the second input. Since the resulting CURB set might not be minimal, we recur within it by choosing, as a seed, a contained strategy that has not yet been used. We repeat this until all strategies in the current set have been used as seeds, at which point we terminate and return the remaining set. This constitutes the one MC algorithm.\nIf the game has more than one CURB set, one MC will be faster than all MC because it will never leave the CURB set in which it starts. The exact speed of one MC in practice will depend on the first seed chosen. If it happens to be in a small CURB set, one MC will run fast. In the worst case, where the entire game is the only CURB set, one MC executes all of the same steps as all MC.\nProposition 4. The one MC algorithm returns one of a game\u2019s minimal CURB sets. Its worst-case time complexity is \u0398(n3)\u00d7 LFP(n). Its best-case time complexity is \u0398(n).\nProof. If there are no other minimal CURB sets, then the entire game is minimally CURB and will be returned. If there are any other minimal CURB sets, one of them will be discovered when a strategy inside it is used as a seed.\nIn the worst case, when the whole game is minimally CURB, one MC must call the min containing CURB algorithm n times, with the full game as an input, giving time complexity \u0398(n3) \u00d7 LFP(n). The best-case complexity follows from a best-case game where a strategy that is in a CURB set of size two is chosen as a seed."}, {"heading": "4.3 Finding the Smallest Minimal CURB Set", "text": "As a different type of query, one may be interested in finding one of a game\u2019s smallest minimal CURB sets. This is important, for example, if the CURB set is used for future computations and the complexity of those future computations increases with the size of the CURB set (e.g., for Nash equilibrium finding as we will discuss later in the paper). We find one of a game\u2019s smallest minimal CURB sets using a pseudo-parallelization of all MC.\nFirst, we use the same preprocessor as in all MC that checks each pair of strategies for a size-two CURB set and returns one, if found. If that fails, we construct a candidate set for each row strategy containing only that strategy. We insert the sets into a priority queue, where sets containing the fewest strategies are given highest priority. We repeatedly pop the smallest candidate set from the queue, and add all the necessary best responses to keep it CURB by calling all conditionally rational for each player. If new strategies are added for either player, the resulting set is inserted back into the queue, and it is prioritized based on its new size. The algorithm terminates when a candidate set is removed from the queue that fails to admit any new best responses. That set is returned and it is one of the game\u2019s smallest minimal CURB sets (we denote the size of this set as n\u2217). We call this algorithm small MC.\nProposition 5. The small MC algorithm returns one of the game\u2019s smallest minimal CURB sets. Its worst-case runtime is \u0398(n\u2217n2)\u00d7 LFP(n). Its best-case runtime is \u0398(n2).\nProof. At the time small MC terminates, all conditionally rational has been called on each row and column strategy in the set with no new best responses having been added. Therefore, the returned set is CURB. Since all other candidate sets on the queue must be as large, or larger than the returned set (and future exploration can only add strategies to these sets), this set is at least as small as the smallest CURB set in the game, and each of the game\u2019s smallest CURB sets is also minimal.\nWhenever a candidate set is fathomed, at least one new strategy must be added or small MC will terminate. Since there are n candidate sets, and n\u2217 strategies in the returned set, in the worst case n \u00d7 n\u2217 sets have been fathomed at termination. Since each examination of a candidate set involves a call to all conditionally rational, the complexity of small MC is as claimed. Priority queue operations are logarithmic in the size of the game, and in the worst case there are n\u00d7 n\u2217 such operations. Thus, the overall worst-case complexity is \u0398(n\u2217n2 + n\u2217n logn)\u00d7 LFP(n), which is \u0398(n\u2217n2)\u00d7 LFP(n). The proof of the best-case complexity is the same as in Proposition 3."}, {"heading": "4.4 Experimental Results", "text": "We implemented the algorithms above and conducted experiments on their performance using most of the instance generators of the main benchmark collection for solving normal-form games, GAMUT (Nudelman, Wortman, Shoham, & Leyton-Brown, 2004). The GAMUT\ncollection includes a variety of commonly studied game types from the academic game theory literature. It is also specifically designed to test different aspects of scalability for game-solving algorithms, for example, most of the generators allow one to create multiple game instances of any given size.1 In this section we show that the complexity of our algorithms depends primarily on the size of the game and the size of its smallest CURB set. We then proceed to explore the distribution of CURB set sizes in the different game types.\nWe first report the runtime of our algorithms on two representative GAMUT game distributions: random games, and covariant games. Figure 1 (left) shows how each of our minimal CURB set finding algorithms scales with game size on a data set of over 1000 random, square normal-form games with between 20 and 100 strategies. The results show that small MC is faster than all MC on random games, which is consistent with their time complexities, considering that many random games have small CURB sets. While the worst-case time complexity of one MC and all MC is the same, experimentally one MC is faster because it only needs to find one minimal CURB set. We can also see that, for large random games, small MC performs slightly better than one MC, since these games tend to contain both small and large CURB sets and one MC is more likely to start in the larger ones. On the other hand, in games with only large CURB sets, one MC tends to be faster, as we will show later.\nWe observed that the performance on random games, illustrated in Figure 1 (left), was typical of that of many other GAMUT instance distributions. However, to show potentially differing performance, we also report on experiments with the covariant game class, in which utilities for both players are drawn from the same distribution with a specified covariance. (In our experiments we set the covariance parameter to be \u22120.5.) This class (and setting) have been shown to be particularly challenging for Nash equilibrium finding algorithms, such as the Lemke-Howson and Porter-Nudelman-Shoham algorithms (Lemke & Howson, 1964; Porter et al., 2004). Figure 1 (right) shows that the all MC algorithm scales similarly on random and covariant games, while the other two algorithms lose their speed advantages when applied to this class.\nThe distribution of CURB sets in random games is shown as solid dots in Figure 2. Most random games have small smallest CURB sets (in fact, often sets of size two), and those that do not, tend to have very large smallest CURB sets. On the other hand, the distribution of smallest CURB set sizes in covariant games (shown in Figure 2, hollow squares) has almost no small smallest CURB sets and many large smallest CURB sets. This is consistent with the observed hardness of these games for support enumeration-based Nash equilibrium finding algorithms, which typically try to find equilibria with small supports first (Porter et al., 2004). This disparity also explains the lowered performance on covariant games of the two minimal CURB finding algorithms that have time complexities dependent on the size of the smallest minimal CURB set, small MC and one MC.\nFigure 3 shows the distribution of smallest CURB set size for 1000 instances from each of the twenty-four other distributions emitted by GAMUT generators. Using a variety of game generators, as we have done here, has become a primary way of testing game-solving algorithms (Porter et al., 2004; Sandholm et al., 2005), and we used the same parameter settings in the distributions as those prior papers. For covariant games, the suffixes \u201cPos\u201d,\n1. We did not benchmark on the GAMUT games that only have a fixed size, such as Chicken, Prisoner\u2019s\nDilemma, and Battle of the Sexes, because they are trivial to solve from a computational perspective.\n\u201cRand\u201d, and \u201cZero\u201d refer to positive, random, and zero covariance parameters, respectively. For distributions that take a graph as input, \u201cCG\u201d, \u201cRG\u201d, and \u201cSG\u201d refer to complete, random, and star graphs.\nAll of these distributions, like random and covariant games, exhibited very few mediumsized smallest CURB sets. Most of the instances had a smallest CURB set that was extreme: either a pure strategy equilibrium or the entire game. With some of the generators, all of the instances lie at the same extreme. Interestingly, some generators (e.g., Polymatrix) produced a significant number of games with CURB sets of one or more specific, nonextremal sizes. It is also notable that using different graph parameters for Local Effect and Polymatrix games had no effect on their smallest CURB set size distributions, suggesting\nthat the type of graph used may not change the fundamental structure of these types of games.\nTo better understand how the minimal CURB set finding algorithms scale with the size of the smallest CURB set, we bucketed the n = 20 random and covariant games according to the size of their smallest CURB sets. (For n = 40, the buckets for medium-sized smallest CURB sets were nearly empty, making it impossible for us to estimate mean runtimes with meaningful accuracy.) Figure 4 plots the average runtime and 95% confidence intervals for each bucket. On games with very small CURB sets, small MC is fastest, but it is outperformed by both one MC and all MC as the size of the smallest CURB set grows.\nThe somewhat surprising runtime performance of the latter two algorithms is due to their leveraging of information across calls to min containing CURB with different seeds. Because small MC performs all the searches in parallel, this information is unavailable."}, {"heading": "5. CURB Sets and Nash Equilibria", "text": "Minimal CURB sets and Nash equilibria both model strategy subspaces which are mutually reinforced given the rationality of agents and their common knowledge. In their original work on minimal CURB sets, Basu and Weibull showed that every minimal CURB set contains the supports of at least one Nash equilibrium (Basu & Weibull, 1991). We observe that this result suggests a secondary use for finding minimal CURB sets: our algorithms can be used to preprocess a game so that a Nash equilibrium finding algorithm can restrict its attention to one of the game\u2019s minimal CURB sets, rather than running on the entire game. As we will show, this can theoretically yield an arbitrarily large reduction of the search space.\nThe most common prior preprocessing technique for Nash equilibrium finding, iterated removal of dominated strategies, attempts to eliminate strategies that cannot be played with any probability in any Nash equilibrium (Knuth et al., 1988; Gilboa, Kalai, & Zemel, 1993). The same is true of another recent preprocessing technique, the generalized eliminability method (Conitzer & Sandholm, 2005b). One comparative advantage of minimal CURB set-based elimination is that it can eliminate strategies that are played in some equilibria, while guaranteeing that the resulting set still contains the supports of at least one.\nFirst, we will show that a CURB set-based preprocessor can reduce search space size by an arbitrary amount even on games where prior preprocessing techniques cannot eliminate anything.\nTheorem 3. For any r,c,r\u2032, and c\u2032 such that r \u2265 2, c \u2265 2, 1 < r\u2032 \u2264 r, and 1 < c\u2032 \u2264 c, there exists normal form games of size r \u00d7 c, with the following properties:\na) it contains a minimal CURB set with shape r\u2032 \u00d7 c\u2032,\nb) iterated elimination of dominated strategies (even domination by mixed strategies) cannot eliminate any strategies,\nc) the recursive preprocessing technique (that can eliminate strategies that belong to some equilibrium as long as some other equilibrium remains) (Conitzer & Sandholm, 2006) can eliminate at most one strategy per player, and\nd) the general eliminability method (Conitzer & Sandholm, 2005b) cannot eliminate any strategies.\nProof. We first present a family of games, \u0393. Let \u0393r\u2032c\u2032 denote a game from this family of size r\u2032 \u00d7 c\u2032. The following generator produces such a game where r\u2032, c\u2032 \u2265 2. Assign the utilities,\n\u2022 u(sr1 , sc1) = u(sr2 , sc2) = (0, 1) and u(sr1 , sc2) = u(sr2 , sc1) = (1, 0).\nThen, for i \u2208 [2, b r \u2032\n2 c], set\n\u2022 u(sr2i\u22121 , sc1) = ( r\u2032\u22122i+2 r\u2032 , 1) and u(sr2i\u22121 , sc2) = ( 2i\u22122 r\u2032 , 0),\n\u2022 u(sr2i , sc1) = ( r\u2032\u2212(2i\u22121) r\u2032 , 0) and u(sr2i , sc2) = ( 2i\u22121 r\u2032 , 1).\nIf r\u2032 is odd there will be one remaining row. In this case, set the following utilities,\n\u2022 if r\u2032 is odd, u(sr\u2032 , sc1) = ( 1 r\u2032 , 12) and u(sr\u2032 , sc2) = ( r\u2032\u22121 r\u2032 , 12).\nNext, for j \u2208 [2, b c \u2032\n2 c], set\n\u2022 u(sr1 , sc2j\u22121) = (0, c\u2032\u22122j+2 c\u2032 ) and u(sr2 , sc2j\u22121) = (1, 2j\u22122 c\u2032 ),\n\u2022 u(sr1 , sc2j ) = (1, c\u2032\u2212(2j\u22121) c\u2032 ) and u(sr2 , sc2j ) = (0, 2j\u22121 c\u2032 ).\nIf c\u2032 is odd there will be one remaining column. In this case, set the following utilities,\n\u2022 if c\u2032 is odd, u(sr1 , sc\u2032) = ( 1 2 , 1 c\u2032 ) and u(sr2 , sc\u2032) = ( 1 2 , c\u2032\u22121 c\u2032 ).\nFor example, the game \u03933,4 is as follows.\n\u03933,4 sc1 sc2 sc3 sc4 sr1 0,1 1,0 0, 1 2 1, 1 4 sr2 1,0 0,1 1, 1 2 0, 3 4 sr3 1 3 , 1 2 2 3 , 1 2 -3,-3 -3,-4\nAny game generated in this way has a Nash equilibrium where the row player mixes evenly between its first two strategies, and the column player mixes evenly among all of its strategies. This game also has an equilibrium where the column player mixes evenly between its first two strategies, and the row player mixes evenly among all of its strategies. Thus, every strategy in \u0393r\u2032c\u2032 is part of some equilibrium. Additionally, each column strategy is a\nbest response to a mixture over the first two row strategies (and, to any column strategy, one of those two is a best response), and vice-versa. Thus, \u0393r\u2032c\u2032 has a single minimal CURB set and it includes the entire game.\nWe now construct an r\u00d7 c game, with a minimally CURB r\u2032\u00d7 c\u2032 subset, by putting the game \u0393r\u2032c\u2032 in the top left and the game \u0393(r\u2212r\u2032)(c\u2212c\u2032) in the bottom right. All other utilities are set to arbitrary negative values, such that no two are exactly the same. The resulting game is shown in Figure 5.\nIt is irreducible by (iterated) dominance and by general eliminability because every strategy participates in some Nash equilibrium. The game is irreducible (other than a single strategy per player) by the recursive preprocessor because the row player\u2019s utilities are distinct within each column, and the column player\u2019s utilities are distinct within each row (except for the last row or column in each \u0393 game, if it has an odd number of rows or columns).\nThree factors curb the promise of minimal CURB set algorithms as powerful preprocessors for Nash equilibrium finding. First, the fastest Nash equilibrium finding algorithms, while requiring exponential time in the worst case, tend to run faster than the CURB set finding algorithms on many types of games (at least the best known implementations of these algorithms). Second, the smallest CURB set can be arbitrarily large (up to the size of the entire game, in which case the preprocessor does not eliminate any strategies from consideration). Third, as we will now show, even after the smallest minimal CURB set has been identified, the remaining search space (CURB set size) can be arbitrarily larger than the size of the supports of a contained Nash equilibrium.\nTo prove this, we will use the following family of games that contain large minimal CURB sets and small-support equilibria. For any integer k > 0, we define the game \u2126k as follows. As in the previous proof, assign the utilities u(sr1 , sc1) = u(sr2 , sc2) = (0, 1) and u(sr1 , sc2) = u(sr2 , sc1) = (1, 0), and let Z be an arbitrarily large value (essentially \u221e). Then, for i \u2208 [3, 2 + k],\n\u2022 u(sri , sc1) = (\u2212Z, ), u(sr1 , sci) = ( ,\u2212Z),\n\u2022 u(sri , sci) = (0, 0),\n\u2022 u(sri , sci\u22121) = (1 + , 0), u(sri\u22121 , sci) = (0, 1 + ), and\n\u2022 for all j > i+ 1 and j \u2264 2 + n,\nu(sri , scj ) = (0,\u2212Z), and u(srj , sci) = (\u2212Z, 0)\nFor example, the game \u21262 is as follows.\n\u21262 sc1 sc2 sc3 sc4 sr1 0,1 1,0 ,\u2212Z ,\u2212Z sr2 1,0 0,1 0,1+ 0,\u2212Z sr3 \u2212Z, 1+ ,0 0,0 0,1 + sr4 \u2212Z, \u2212Z, 0 1+ ,0 0,0\nWith respect to the strategic structure of games from this class, we have the following results.\nLemma 1. For i > 2, the row (column) player\u2019s strategy sri (sci) is a best response to the column (row) player\u2019s strategy sci\u22121 (sri\u22121). The column (row) player\u2019s strategy sc1 (sr1) is a best response to the row (column) player\u2019s strategy srn+2 (scn+2).\nProposition 6. \u2126k has a single minimal CURB set and it includes the entire game.\nProof. Strategies sr1 , sr2 , sc1 , and sc2 must be included in some minimal CURB set, as they are the best responses to each other in the subgame containing them, and this subgame admits no pure-strategy Nash equilibrium. Based on Lemma 1, we can see that when i = 3, the row (column) player\u2019s strategy sr3 (sc3) is a best response to the column (row) player\u2019s second strategy. This forces the third strategy of each player into the minimal CURB set containing the first two strategies of each player, and inductively each additional strategy is added in the same way.\nProposition 7. In \u2126k, the only Nash equilibrium is the the mixed-strategy profile where sr1, sr2, sc1, and sc2 are each played with probability 1 2 .\nProof. Assume, for contradiction, that this is not the case, that is, there exists a mixture, m\u2217r , over the rows M \u2217 r , comprising the row player\u2019s profile in a Nash equilibrium, and sr1 /\u2208M \u2217 r . Along with our assumption, the definition of Nash equilibrium implies that there must exist a mixture, m\u2217c , over columns M \u2217 c such that \u03b2r(m \u2217 c) = M \u2217 r and \u03b2c(m \u2217 r) = M \u2217 c . Since sr1 is not in M \u2217 r by assumption, there exists i > 1 such that sri is the lowest numbered support in M\u2217r , and the definition of \u2126 specifies the outcome, u(sri , scj ) = (0,\u2212Z), when j > i+ 1.\nThe column player\u2019s Nash equilibrium supports cannot contain any such scj , because placing any positive probability on this strategy will lead to a highly negative expected payoff and playing the pure strategy sc1 provides guaranteed payout of at least 0. If we exclude these strategies, sci+1 (the highest-numbered remaining column strategy) is the only remaining strategy, other than sc1 , which provides non-zero utility against mixtures on rows \u2265 i. In other words, it dominates all column strategies on the row player\u2019s supports M\u2217r , aside from one: sc1 .\nSince dominated strategies cannot be played in equilibrium, M\u2217c is constrained to a subset of {sc1 , sci+1}. If M \u2217 c contains sc1 , M \u2217 r must not include any srj with j > 2, due to the highly negative expected payoff of any mixture including such strategies (as discussed above). In this case, the only remaining possible equilibrium row mixture is the pure strategy sr2 , the best response to which is sc3 . Since, by Corollary 2, \u2126\nn has no pure Nash equilibrium, this cannot constitute an equilibrium, contradicting our assumption. Alternatively, if M\u2217c does not include sc1 , then m \u2217 c must be the pure strategy sci+1 , and Lemma 1 provides a pure-strategy best response to any pure strategy with i > 2. This would, again, form a pure strategy Nash equilibrium, which we have shown cannot exist.\nThe above reasoning can also be inverted to show that a contradiction is caused by the assumption that M\u2217c does not contain sc1 .\nWe have shown that the row player\u2019s equilibrium mixture must contain r1 and r2, and that the column player\u2019s equilibrium mixture must contain c1 and c2 and no other strategies can be in either player\u2019s supports, since it would lead one of them to have to highly negative utility.\nThe \u2126 game demonstrates that it is possible to construct very large CURB sets that are loose around the supports of an enclosed Nash equilibrium, giving us the following general result.\nTheorem 4. A Nash equilibrium with supports consisting of two strategies for each player can be the only Nash equilibrium in an arbitrarily large minimal CURB set.\nThese results imply that minimal CURB set algorithms will not always be effective as preprocessors for Nash equilibrium finding. However, on game instances that have a small CURB set or a relatively tight minimal CURB set,2 these algorithms have the potential to yield a significant speed improvement.\nFurthermore, the existence of the polynomial-time algorithm for detecting a game\u2019s smallest CURB set (small MC) allows us to offer the following theoretical result of potential general interest.\nTheorem 5. The complexity of finding a Nash equilibrium for a two-player normal-form game can be super-polynomial only in the size of the game\u2019s smallest CURB set (not in the size of the full game).\nThe relationship between the complexity of finding a minimal CURB set and that of finding a Nash equilibrium is surprising in several ways. For one, it is not obvious that finding a minimal CURB set should be easier than finding a Nash equilibrium, since, like Nash equilibria, CURB sets have an exponential space of possible supports which are chosen through maximization processes for both players. Yet from a theoretical, worst-case perspective, Nash equilibrium finding is PPAD-complete (which is widely believed to be a strictly harder complexity class than P) and, as we showed earlier in this paper, minimal CURB set finding is polynomial time.\nIt is worth noting that games with very small support equilibria, which include all games with very small CURB sets, are already known to be easily solvable for Nash equilibria\n2. If the game has a relatively tight CURB set, a Nash equilibrium can be found quickly by enumerating\nstrategies of the CURB to be left out from the supports.\nusing techniques such as support enumeration. In particular, on games whose smallest CURB set size is logarithmic in the full game size, both support enumeration and CURB set preprocessing permit a guarantee of polynomial runtime in finding a Nash equilibrium. CURB set preprocessing has the additional advantage that it can also be used to simplify games with larger equilibrium supports, where support enumeration is exponential. For example, consider the Gk game class described by Sandholm, Gilpin and Conitzer (2005), which generates games with a single equilibrium, and that equilibrium contains half the strategies in its support. We also determined that these games have a single CURB set, and that CURB set includes exactly the supports of the equilibrium. Games from this class can be padded, using the embedding technique in our Theorem 3, to become arbitrarily large games without introducing any additional equilibria or CURB sets. On those games, CURB set detection offers a polynomial-time method for reducing the game to the point where algorithms not based on support enumeration can be applied.\nWhat about the complexity of the two problems (Nash equilibrium finding and CURB set finding) in practice? As Figure 6 shows, the average runtimes of our smallest CURB set finding algorithm and the Lemke-Howson Nash equilibrium finding algorithm (using the implementation in Gambit, McKelvey, McLennan, & Turocy, 2004) seem to scale similarly with input game size (when one does not explicitly generate those pathological cases which produce exponential behavior in the latter, Savani & von Stengel, 2004). In fact, the CURB set algorithms are slower (by two orders of magnitude) on average than Lemke-Howson. This experimental performance agrees with intuition, but is the reverse of the theoretical state of knowledge regarding worst-case complexity.\nIt is worth pointing out that an algorithm that builds in part on our work for one of the CURB set problems (finding all minimal CURB sets) has been presented in a working paper (Klimm, Sandholm, & Weibull, 2010), and it appears to scale more favorably than ours. However, the algorithm has not been directly compared with Lemke-Howson or any other Nash equilibrium finding algorithms, so its relative value related to preprocessing remains to be seen.\nThe root cause of the complexity of Nash equilibrium search has proved elusive, as two candidates that were considered potential culprits have been shown not to affect worstcase complexity: games with two players and binary utilities are just as difficult as the general case, even if both restrictions apply simultaneously (Chen & Deng, 2006; Abbott et al., 2005). The fact that bounding the smallest CURB set size does serve to bound the difficulty of Nash equilibrium search suggests that we can further isolate the cause of equilibrium search complexity as being endemic to minimal CURB sets, rather than games in general. In this regard, we observe that the special two-player game used by Chen and Deng to show PPAD-completeness (Chen & Deng, 2006) is itself a single minimal CURB set, and remains such under Abbott et al.\u2019s (Abbott et al., 2005) transformation to binary utilities."}, {"heading": "6. Conclusions", "text": "We presented a thorough computational treatment of CURB sets, an important set-valued, game-theoretic solution concept, including several algorithms for finding CURB sets in two-player, normal-form games. Our algorithms find all minimal CURB sets (all MC), one minimal CURB set (one MC), and a smallest minimal CURB set (small MC), all in polynomial time. The algorithms are based on basic properties of CURB sets that we prove, such as the fact that minimal CURB sets cannot overlap. The algorithms use dovetailing with a priority queue, and exploiting information across overlapping, non-minimal CURB sets, to further improve speed.\nExperiments on random games showed that, unsurprisingly, small MC tends to be the fastest, one MC is second, and all MC is the slowest. However, on covariant games the speed advantage of the former two disappears. The runtime of those algorithms is primarily determined by the size of the smallest CURB set, and on covariant games, which tend to have larger CURB sets, those algorithms (especially one MC) suffer.\nOur algorithms also enable the study of CURB set size distributions of different game classes. We showed that the instance distributions from GAMUT are mainly extremal, in the sense that a given game generator will yield mostly games with pure-strategy equilibria and/or games where the game itself is the sole minimal CURB set. However, curiously, some of the generators yield a significant number of games with smallest CURB sets of specific non-extremal sizes.\nWe also examined the potential for using our algorithms as preprocessors for Nash equilibrium finding algorithms. We proved that our technique can eliminate an arbitrarily large portion of the game from consideration, while guaranteeing that the remaining subgame contains at least one Nash equilibrium from the full game. This is the case even for games where prior preprocessing techniques, including the iterated removal of dominated strategies, are powerless.\nOn the downside, we showed that the smallest CURB set can be arbitrarily large and/or arbitrarily loose. Furthermore, on many distributions, we showed that current Nash equilibrium finding algorithms run faster, on average, than the CURB set algorithms. This is surprising in that the theoretical worst-case complexity of the two problems is the reverse.\nWe demonstrated that the worst-case complexity of finding a Nash equilibrium is polynomial in all known aspects of the game except the size of its smallest CURB set. Taken\ntogether with our CURB set finding algorithms that are polynomial time even in the worst case, and the fact that Nash equilibrium finding is super-polynomial in the worst case (unless PPAD=P), we observe that the essence of the worst-case complexity of finding a Nash equilibrium is the complexity of finding a Nash equilibrium within a minimal CURB set.\nWhile the CURB set definition is for any number of players, we presented all of our algorithms for the two-player setting. For a larger number of players, the only obstacle to finding minimal CURB sets is finding conditional best responses quickly as a subroutine. We showed that this problem can be solved fast for two players\u2014in these settings it involves solving a simple linear feasibility program. However, the mathematical program we use is of degree p \u2212 1, where p is the number of players, and with three players the constraints are already quadratic. On the plus side, our algorithms only make a polynomial number of calls to this subroutine. Therefore, if future research is able to identify polynomial-time algorithms for finding all of a player\u2019s conditional best responses in n-player games, then our CURB set algorithms will also be polynomial time in those settings."}, {"heading": "Acknowledgments", "text": "This material is based upon work supported by National Science Foundation ITR grant 0205435, IGERT grant 9972762, and IIS grants 0121678, 0427858, and 0905390, as well as Office of Naval Research grant N00014-02-1-0973, and a Sloan Fellowship. We would also like to thank our anonymous reviewers, Vincent Conitzer, and Andrew Gilpin for their helpful input and advice."}], "references": [{"title": "On the complexity of two-player win-lose games", "author": ["T. Abbott", "D. Kane", "P. Valiant"], "venue": "In Proceedings of the Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Abbott et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Abbott et al\\.", "year": 2005}, {"title": "Strategy subsets closed under rational behavior", "author": ["K. Basu", "J.W. Weibull"], "venue": "Economics Letters,", "citeRegEx": "Basu and Weibull,? \\Q1991\\E", "shortCiteRegEx": "Basu and Weibull", "year": 1991}, {"title": "Rationalizable bidding in first-price auctions", "author": ["P. Battigalli", "M. Siniscalchi"], "venue": "Games and Economic Behavior,", "citeRegEx": "Battigalli and Siniscalchi,? \\Q2003\\E", "shortCiteRegEx": "Battigalli and Siniscalchi", "year": 2003}, {"title": "Rationalizable strategic behavior", "author": ["B.D. Bernheim"], "venue": "Econometrica, 52 (4), 1007\u201328.", "citeRegEx": "Bernheim,? 1984", "shortCiteRegEx": "Bernheim", "year": 1984}, {"title": "Computational aspects of Shapley\u2019s saddles", "author": ["F. Brandt", "M. Brill", "F. Fischer", "P. Harrenstein"], "venue": "In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "Brandt et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brandt et al\\.", "year": 2009}, {"title": "Settling the complexity of two-player Nash-equilibrium", "author": ["X. Chen", "X. Deng"], "venue": "In Proceedings of the Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Chen and Deng,? \\Q2006\\E", "shortCiteRegEx": "Chen and Deng", "year": 2006}, {"title": "Complexity of (iterated) dominance", "author": ["V. Conitzer", "T. Sandholm"], "venue": "In Proceedings of the ACM Conference on Electronic Commerce (ACM EC),", "citeRegEx": "Conitzer and Sandholm,? \\Q2005\\E", "shortCiteRegEx": "Conitzer and Sandholm", "year": 2005}, {"title": "A generalized strategy eliminability criterion and computational methods for applying it", "author": ["V. Conitzer", "T. Sandholm"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Conitzer and Sandholm,? \\Q2005\\E", "shortCiteRegEx": "Conitzer and Sandholm", "year": 2005}, {"title": "A technique for reducing normal form games to compute a Nash equilibrium", "author": ["V. Conitzer", "T. Sandholm"], "venue": "In Proceedings of the International Conference on Automated Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "Conitzer and Sandholm,? \\Q2006\\E", "shortCiteRegEx": "Conitzer and Sandholm", "year": 2006}, {"title": "The complexity of computing a nash equilibrium", "author": ["C. Daskalakis", "P.W. Goldberg", "C.H. Papadimitriou"], "venue": "Communications of the ACM,", "citeRegEx": "Daskalakis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2009}, {"title": "The compleixty of eliminating dominated strategies", "author": ["I. Gilboa", "E. Kalai", "E. Zemel"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Gilboa et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Gilboa et al\\.", "year": 1993}, {"title": "Nash and correlated equilibria: Some complexity considerations", "author": ["I. Gilboa", "E. Zemel"], "venue": "Games and Economic Behavior,", "citeRegEx": "Gilboa and Zemel,? \\Q1989\\E", "shortCiteRegEx": "Gilboa and Zemel", "year": 1989}, {"title": "Learning by forgetful players", "author": ["S. Hurkens"], "venue": "Games and Economic Behavior, 11 (1), 304\u2013329.", "citeRegEx": "Hurkens,? 1995", "shortCiteRegEx": "Hurkens", "year": 1995}, {"title": "Algorithms for finding approximate formations in games", "author": ["P. Jordan", "M. Wellman"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Jordan and Wellman,? \\Q2010\\E", "shortCiteRegEx": "Jordan and Wellman", "year": 2010}, {"title": "Finding all minimal sCURB sets in finite games", "author": ["M. Klimm", "T. Sandholm", "J.W. Weibull"], "venue": null, "citeRegEx": "Klimm et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Klimm et al\\.", "year": 2010}, {"title": "A note on strategy elimination in bimatrix games", "author": ["D.E. Knuth", "C.H. Papadimitriou", "J.N. Tsitsiklis"], "venue": "OR Letters,", "citeRegEx": "Knuth et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Knuth et al\\.", "year": 1988}, {"title": "Equilibrium points of bimatrix games", "author": ["C. Lemke", "J. Howson"], "venue": "Journal of the Society of Industrial and Applied Mathematics,", "citeRegEx": "Lemke and Howson,? \\Q1964\\E", "shortCiteRegEx": "Lemke and Howson", "year": 1964}, {"title": "Gambit: Software tools for game theory, version 0.97.1.5", "author": ["R.D. McKelvey", "A.M. McLennan", "T.L. Turocy"], "venue": null, "citeRegEx": "McKelvey et al\\.,? \\Q2004\\E", "shortCiteRegEx": "McKelvey et al\\.", "year": 2004}, {"title": "Run the GAMUT: A comprehensive approach to evaluating game-theoretic algorithms", "author": ["E. Nudelman", "J. Wortman", "Y. Shoham", "K. Leyton-Brown"], "venue": "In Proceedings of the International Conference on Automated Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "Nudelman et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Nudelman et al\\.", "year": 2004}, {"title": "Rationalizable strategic behavior and the problem of perfection", "author": ["D.G. Pearce"], "venue": "Econometrica, 52 (4), 1029\u201350.", "citeRegEx": "Pearce,? 1984", "shortCiteRegEx": "Pearce", "year": 1984}, {"title": "Simple search methods for finding a Nash equilibrium", "author": ["R. Porter", "E. Nudelman", "Y. Shoham"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Porter et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Porter et al\\.", "year": 2004}, {"title": "On finding CURB sets in extensive games", "author": ["V. Pruzhansky"], "venue": "International Journal of Game Theory, 32 (2), 205\u2013210.", "citeRegEx": "Pruzhansky,? 2003", "shortCiteRegEx": "Pruzhansky", "year": 2003}, {"title": "Mixed-integer programming methods for finding Nash equilibria", "author": ["T. Sandholm", "A. Gilpin", "V. Conitzer"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Sandholm et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sandholm et al\\.", "year": 2005}, {"title": "Exponentially many steps for finding a Nash equilibrium in a bimatrix game", "author": ["R. Savani", "B. von Stengel"], "venue": "In Proceedings of the Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Savani and Stengel,? \\Q2004\\E", "shortCiteRegEx": "Savani and Stengel", "year": 2004}, {"title": "An axiomatization of minimal CURB", "author": ["M. Voorneveld", "W. Kets", "H. Norde"], "venue": "sets. International Journal of Game Theory,", "citeRegEx": "Voorneveld et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Voorneveld et al\\.", "year": 2005}, {"title": "Improved complexity results on solving real-number linear feasibility problems", "author": ["Y. Ye"], "venue": "Mathematical Programming, 106 (2), 339\u2013363.", "citeRegEx": "Ye,? 2006", "shortCiteRegEx": "Ye", "year": 2006}], "referenceMentions": [{"referenceID": 19, "context": "It emulates the players\u2019 assumptions that an opponent will never play a strategy that is not a best response to one of the player\u2019s own remaining strategies (Pearce, 1984).", "startOffset": 157, "endOffset": 171}, {"referenceID": 17, "context": "CURB sets are based on the notion of rationalizability, which was introduced by Pearce (1984) and Bernheim (1984).", "startOffset": 80, "endOffset": 94}, {"referenceID": 2, "context": "CURB sets are based on the notion of rationalizability, which was introduced by Pearce (1984) and Bernheim (1984). Rationalizability is, by now, a widely known, robust gametheoretic solution concept and has been used to study various applications, such as first-price auctions (Battigalli & Siniscalchi, 2003).", "startOffset": 98, "endOffset": 114}, {"referenceID": 1, "context": "Basu and Weibull (1991) introduced the notion of a minimal CURB set, or a CURB set that does not contain any CURB subsets, and proved that each minimal CURB set is guaranteed to contain the supports of at least one Nash equilibrium.", "startOffset": 0, "endOffset": 24}, {"referenceID": 12, "context": "Thus, CURB sets have been used as a solution concept to describe the strategy subspace where iteratively adapting agents will eventually settle (Hurkens, 1995).", "startOffset": 144, "endOffset": 159}, {"referenceID": 21, "context": "Finding minimal CURB sets has been previously considered challenging (Pruzhansky, 2003), and, prior to this work on CURB sets, little had been done on the problem from a computational standpoint.", "startOffset": 69, "endOffset": 87}, {"referenceID": 21, "context": "Such games are relatively simple, in that they contain exactly one minimal CURB set, and a straightforward algorithm can quickly find it by exploiting the sequential representation (Pruzhansky, 2003).", "startOffset": 181, "endOffset": 199}, {"referenceID": 25, "context": "LFPs can be solved in low-order polynomial time, even in the worst case, and the fastest known algorithms for LFPs have better worst-case guarantees than the fastest known linear programming algorithms (Ye, 2006).", "startOffset": 202, "endOffset": 212}, {"referenceID": 12, "context": "This is useful, for example, in the adaptive agent context to identify regions of the strategy space in which learning agents are likely to settle (Hurkens, 1995).", "startOffset": 147, "endOffset": 162}, {"referenceID": 20, "context": ") This class (and setting) have been shown to be particularly challenging for Nash equilibrium finding algorithms, such as the Lemke-Howson and Porter-Nudelman-Shoham algorithms (Lemke & Howson, 1964; Porter et al., 2004).", "startOffset": 178, "endOffset": 221}, {"referenceID": 20, "context": "This is consistent with the observed hardness of these games for support enumeration-based Nash equilibrium finding algorithms, which typically try to find equilibria with small supports first (Porter et al., 2004).", "startOffset": 193, "endOffset": 214}, {"referenceID": 20, "context": "Using a variety of game generators, as we have done here, has become a primary way of testing game-solving algorithms (Porter et al., 2004; Sandholm et al., 2005), and we used the same parameter settings in the distributions as those prior papers.", "startOffset": 118, "endOffset": 162}, {"referenceID": 22, "context": "Using a variety of game generators, as we have done here, has become a primary way of testing game-solving algorithms (Porter et al., 2004; Sandholm et al., 2005), and we used the same parameter settings in the distributions as those prior papers.", "startOffset": 118, "endOffset": 162}, {"referenceID": 15, "context": "The most common prior preprocessing technique for Nash equilibrium finding, iterated removal of dominated strategies, attempts to eliminate strategies that cannot be played with any probability in any Nash equilibrium (Knuth et al., 1988; Gilboa, Kalai, & Zemel, 1993).", "startOffset": 218, "endOffset": 268}, {"referenceID": 0, "context": "The root cause of the complexity of Nash equilibrium search has proved elusive, as two candidates that were considered potential culprits have been shown not to affect worstcase complexity: games with two players and binary utilities are just as difficult as the general case, even if both restrictions apply simultaneously (Chen & Deng, 2006; Abbott et al., 2005).", "startOffset": 324, "endOffset": 364}, {"referenceID": 0, "context": "\u2019s (Abbott et al., 2005) transformation to binary utilities.", "startOffset": 3, "endOffset": 24}], "year": 2010, "abstractText": "We provide a series of algorithms demonstrating that solutions according to the fundamental game-theoretic solution concept of closed under rational behavior (CURB) sets in two-player, normal-form games can be computed in polynomial time (we also discuss extensions to n-player games). First, we describe an algorithm that identifies all of a player\u2019s best responses conditioned on the belief that the other player will play from within a given subset of its strategy space. This algorithm serves as a subroutine in a series of polynomial-time algorithms for finding all minimal CURB sets, one minimal CURB set, and the smallest minimal CURB set in a game. We then show that the complexity of finding a Nash equilibrium can be exponential only in the size of a game\u2019s smallest CURB set. Related to this, we show that the smallest CURB set can be an arbitrarily small portion of the game, but it can also be arbitrarily larger than the supports of its only enclosed Nash equilibrium. We test our algorithms empirically and find that most commonly studied academic games tend to have either very large or very small minimal CURB sets.", "creator": "dvips(k) 5.96dev Copyright 2007 Radical Eye Software"}}}