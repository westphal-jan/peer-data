{"id": "1401.5856", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "Narrative Planning: Compilations to Classical Planning", "abstract": "a model of story generation recently proposed by benjamin riedl and young casts it as planning, with the usual additional primary condition that story characters behave intentionally. namely this means that characters have perceivable motivation for the actions they take. i consistently show that this condition can be compiled away ( in more conventional ways than straightforward one ) to produce a classical planning problem that can be solved by an off - the - shelf classical planner, more typically efficiently than by riedl richards and youngs specialised planner.", "histories": [["v1", "Thu, 23 Jan 2014 02:46:00 GMT  (366kb)", "http://arxiv.org/abs/1401.5856v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["patrik haslum"], "accepted": false, "id": "1401.5856"}, "pdf": {"name": "1401.5856.pdf", "metadata": {"source": "CRF", "title": "Narrative Planning: Compilations to Classical Planning", "authors": ["Patrik Haslum"], "emails": ["PATRIK.HASLUM@ANU.EDU.AU"], "sections": [{"heading": null, "text": "the additional condition that story characters behave intentionally. This means that characters have perceivable motivation for the actions they take. I show that this condition can be compiled away (in more ways than one) to produce a classical planning problem that can be solved by an off-the-shelf classical planner, more efficiently than by Riedl and Young\u2019s specialised planner."}, {"heading": "1. Introduction", "text": "The classical AI planning model, which assumes that actions are deterministic and that the planner has complete knowledge of and control over the world, is often thought to be too restricted, in that many potential applications problems appear to have requirements that do not fit in this model. Recently, however, it has been shown that some problems thought to go beyond the classical model can nevertheless be solved by classical planners by means of compilation, i.e., a systematic remodelling of the problem such that a classical plan for the reformulated problem meets also the non-classical requirements. A striking example is the work of Palacios and Geffner (2006), who showed that conformant planning (generating plans that are robust to certain forms of uncertainty) can be compiled into a classical planning problem. Another example, closer to the topic of this paper, is the work by Porteous, Teutenberg, Pizzi and Cavazza (2011), who use a planner to generate variations of a drama by encoding constraints on the sequencing of events within it.\nThis paper is about another problem of this kind: planning a fabula, meaning the event structure, or \u201cplot\u201d, of a story.1 The fabula planning problem considered was formulated by Riedl and Young (2010). Its main difference from classical planning is a notion of intentionality: actions in a story are taken by different characters, and for the story to be considered believable, characters should behave intentionally, i.e., they should have (perceivable) motivations for the actions they take. Riedl and Young argue that \u201c[the fact that classical planners do not take into account character intentions] limits the applicability of off-the-shelf planners as techniques for generating stories,\u201d and develop instead a narrative planner, IPOCL, which extends a traditional partial-order causal link planner with a mechanism to enforce that plans respect character intentionality. I will show that fabula planning, as defined by Riedl and Young, can be compiled into a classical planning problem, and hence can in fact be solved by any off-the-shelf classical planner. This does not preclude using an extended formalism, like that introduced by Riedl and Young, which is better suited for the purpose of modelling fabula planning problems, since the compilation is easily automated. The advantage of this is obvious: it allows to bring to bear on the narrative planning problem the entirety of existing,\n1. The telling of the story, or discourse, is distinct from the fabula (e.g., Gerva\u0301s 2009). The aforementioned work by Porteous et al. can be seen as the application of planning to generating different discourses of a given fabula.\nc\u00a92012 AI Access Foundation. All rights reserved.\nand future, work on algorithms for classical planning, at a dramatically reduced cost in development time and effort. It is not surprising to find that classical planners run on the compiled problem are far more efficient than the IPOCL algorithm, as well as capable of doing more, like finding a set of diverse plans.\nThere are different theories about what distinguishes a story from an arbitrary sequence of events, i.e., what gives it its \u201cstoriness\u201d (e.g., Gerva\u0301s 2009; Mateas & Sengers, 1999). My aim is not to criticise the particular model of narrative planning proposed by Riedl and Young but merely to show that the criterion they adopted \u2013 character intentionality \u2013 can be achieved by a classical planner without modification, by simply restating the problem that is given to the planner to solve. Whether this can be done also for other models of narrative generation is an open question."}, {"heading": "2. Narrative Planning and Intentional Plans", "text": "\u201cThis is a story about how King Jafar becomes married to Jasmine. There is a magic genie. This is also a story about how the genie dies.\u201d\n(From the textual representation of the story generated by IPOCL; Riedl & Young 2010.)\nRiedl and Young observe that \u201cthere are many parallels between plans and narrative at the level of fabula.\u201d Both are sequences of events that change the state of the (story) world. For a story to be perceived as coherent and plausible, the event sequence must be logically possible (i.e., preconditions achieved before an event takes place) and connected by causes and effects (i.e., each event contributes something to the story, by setting the stage for later events). The goal of a story, in this view, is the end state that the story\u2019s author has in mind; Riedl and Young call this the story outcome, to distinguish it from character goals. For a story to be believable, characters in it should appear to be intentional agents: a character\u2019s actions should not only be possible, and contribute to the outcome of the story, but should be perceivable as contributing to the goals that the character has (which are not necessarily the same as the author\u2019s goal). This can be seen as a non-redundancy requirement on subsets of the plan: each action done by each character in the story should directly or indirectly contribute to achieving a goal of the character. Of course, goals of a character can change throughout the course of the story, as they are influenced by other characters, or events in the world around them. But each such change of a character\u2019s goals must also have a cause.\nTo illustrate narrative planning, and to evaluate the believability of plans generated by IPOCL, Riedl and Young (appendix A.1, p. 254\u2013256) use the following small example scenario. The dramatis personae are: \u2022 King Jafar, who lives in The Castle; \u2022 Aladdin, a Knight loyal to Jafar; \u2022 Jasmine, a beautiful woman, who also lives in The Castle; \u2022 a Genie, who is imprisoned in a Magic Lamp; and \u2022 a Dragon, who lives at The Mountain and possesses the Lamp at the start of the story. Characters can travel between the two locations. A knight can slay a monster (only the Dragon and the Genie are monsters). A character can take things from a dead character (\u201cpillage\u201d), and can give things to another character (the Lamp is the only item of interest). A character who has the Lamp can summon the Genie, thereby gaining control over it. The Genie, by magic, can cause a character to fall in love with another character. Two characters who are in love, and not otherwise engaged, can marry. The goals of the story are (married Jafar Jasmine) and (dead Genie). Note that these goals represent the story outcome; they are not (initially) intended by any character.\nRiedl and Young distinguish two types of planning actions: intentional actions, which correspond to actions taken by one or more story characters (actors of the action), and happenings, which do not have actors and correspond to accidental events, forces of nature, etc. The classifications of actions as intentional or happenings, and the assignment of the role of actor(s) to parameters of intentional actions, are part of the domain theory. Examples of happenings in the scenario above are for a character to fall in love with another who is beautiful, and for a scary monster to frighten another character.\nCharacter intentions are modelled by modal literals of the form (intends A f ), where A is a character and f is a fact, i.e., a normal literal. Intentions arise as an effect of actions, either happenings or character actions. For example, the happening (fall-in-love ?man ?woman) has the effect (loves ?man ?woman) and establishes the intention (intends ?man (married ?man ?woman)). Similarly, the action (deliver-witty-insult ?speaker ?hearer ?victim), in which ?speaker is the actor, could have the effect (amused ?hearer), but also the unintended (by the speaker) effect (intends ?victim (dead ?speaker)). A special category of actions that cause intentions are \u201cdelegating\u201d actions, where one character commands (or persuades, or bribes, or otherwise influences) another to achieve something. For example, (order ?king ?knight ?goal) has the effect (intends ?knight ?goal).\nRiedl and Young define their notion of intentionality in the context of partially ordered causal link (POCL) plans.2 The following definition summarises definitions 3, 5 and 6 (pp. 232\u2013234) in their article:\nDefinition 1 An intentional plan is one in which every occurrence of an intentional action is part of some frame of commitment. A frame of commitment is a subset S\u2032 of steps (i.e., action occurrences) in the plan, associated with a modal literal (intends A g), satisfying four requirements: (1) Character A is an actor of every step in S\u2032. (2) There is a final step sfin \u2208 S\u2032 that makes g true. (3) There is a motivating step sm in the plan, which adds (intends A g) and which precedes all steps in S\u2032. We\u2019ll say there is a motivational link from sm to every step in the frame of commitment, S\u2032. Note that sm is not part of S\u2032. (4) From each step in S\u2032 other than sfin there is a path of causal or motivational links to sfin. A complete (fabula) plan is one that is both intentional and valid in the classical sense.\nCondition (4) above departs slightly from the definitions stated by Riedl and Young: they require only that each step in S\u2032 temporally precedes sfin. That would appear to be too promiscuous, since it allows any unrelated action to be incorporated into a frame of commitment by adding spurious temporal constraints. Their IPOCL algorithm, however, will only incorporate a step into an existing frame of commitment if the step has a causal link to a step already in the frame, or can serve as motivating step for a frame of commitment whose final step has a causal link to a step already in the frame (cf. items 1 and 2 on page 235 of their article). Hence, the frames that their algorithm generates always satisfy condition (4)."}, {"heading": "3. Compilation 1: Explicit Justification Tracking", "text": "The first compilation is based on explicit tracking of the justifications, in the form of causal and motivating links, for actions in the plan. It is inspired by the work of Karpas and Domshlak (2011) on pruning redundant action sequences from the search space, which also relies on a notion of justification of actions.\n2. A detailed account of POCL planning can be found in the paper by McAllester and Rosenblitt (1991) and in most AI textbooks.\nWe will use three kinds of modal literals: (intends A f ) and (delegated A f ), where A is a character and f a fact, and (justified f I), where f is a fact and I an intention, i.e., a modal literal of the first form. The intends modality is part of the narrative planning problem specification, where it can appear in action effects and in the initial state. The other modalities are used only to describe the compilation. Of course, modal conditions cannot be expressed directly in a classical planning formalism like PDDL. In a PDDL model, they are replaced by a separate \u201cmodal predicate\u201d for each predicate (resp. combination of two predicates) that can appear in a non-modal fact, whose arguments is the concatenation of all arguments in the modal literal. For example, (intends Aladdin (has Jafar Lamp)) is replaced by (intends-has Aladdin Jafar Lamp), and (justified (at Aladdin Mountain) (intends Aladdin (has Jafar Lamp))) is replaced by (justified-at-has Aladdin Mountain Aladdin Jafar Lamp).\nIn the compiled problem, each intentional action is associated with an intention of the action\u2019s actor(s). This intention is a precondition of the action. If the action itself does not achieve the intention, it creates an outstanding obligation to make use of at least one of its effects to achieve the precondition of some other action, done by the same actor, that contributes, directly or indirectly, to achieving the intention. This is modelled by the justified modality. As explained earlier, actions can have modal effects of the form (intends B f ), i.e., to make a character (different from the actor) intend a goal. This is modelled by the delegated modality.\nFor each intentional action, (a ~x), of the narrative planning problem, the compiled problem has one distinct action for each combination of an intention (intends xA (p ~y)), where xA is the parameter that represents the actor of (a ~x), and an effect (e ~z) of (a ~x). We name this compiled action (a-e-because-intends-p ~x ~y), and call (e ~z) the chosen effect. Note that the parameters ~z of the chosen effect are composed from a subset of the parameters ~x of the action, and possibly explicit constants. Action (a-e-because-intends-p ~x ~y) can be read as \u201ccharacter xA performs action (a ~x) to achieve the effect (e ~z) as a step towards achieving the character\u2019s intended goal (p ~y)\u201d. If (e ~z) can unify with (p ~y), the action must be further broken into two cases: one where they are forced to equal and one where they are forced to be distinct. For an intentional action with more than one actor, the compiled problem must have a distinct action for each (possible and relevant) choice of effect and intention for each actor. For a happening (i.e., action without an actor) there is only one corresponding action in the compiled problem.\nThe justified and delegated modalities combine to track causal and motivational links in the compiled problem. All (possible and relevant) justified literals are true in the initial state, and required to be true in the goal state. Action (a-e-because-intends-p ~x ~y) makes the chosen effect unjustified, by deleting (justified (e ~z) (intends xA (p ~y))). Since the goal requires all justified literals to hold, the plan must include some action, by the same actor and with the same intention, whose precondition requires (e ~z); no other action will make (justified (e ~z) (intends xA (p ~y))) true again. If the chosen effect is a modal literal (intends zA (q ~z\u2032)) it is the subgoal (q ~z\u2032) that becomes unjustified, and it also becomes \u201cdelegated\u201d to the second character, zA. This provides the motivational link from the action (a-e-because-intends-p ~x ~y) to any action that zA takes to achieve (q ~z\u2032). Delegation ends when the character achieves the goal. While a goal is delegated, no other character may achieve the goal. This ensures the step that created the delegation is eventually justified, by the character who performed it making use of the achieved fact (q ~z\u2032).\nLet (a ~x) be an intentional action, xA the parameter that represents its actor, (e ~z) the chosen effect and (intends xA (p ~y)) the intention of the actor. The preconditions of the compiled action (a-e-because-intends-p ~x ~y) are:\n(1) all preconditions of (a ~x); (2) (intends xA (p ~y));\n(3a) \u00ac\u2203w (delegated w (q ~z\u2032)), for each effect of (a ~x) that is of the form (intends zA (q ~z\u2032)); (3b) \u00ac\u2203w 6= xA (delegated w (p ~y)), if (p ~y) is an effect of (a ~x); (3c) \u00ac\u2203w (delegated w (q ~z\u2032)), for any other effect (q ~z\u2032) of (a ~x) that is not an intends modal literal. (4) \u00ac(intends zA (q ~z\u2032)), if (e ~z) is a modal literal of the form (intends zA (q ~z\u2032)).\nIn a plan for the compiled problem, sets of actions with the same associated intention form a frame of commitment. Precondition (2) ensures all steps in that frame are preceded by a motivating step. Precondition (4) ensures there is at most one (intentional) motivating step. Preconditions (3a\u2013c) ensure that no action can be taken that delegates (a) or achieves (b\u2013c) a goal that is already delegated to another character. The effects of the compiled action are:\n(1) all effects of (a ~x); (2) (justified (q ~v) (intends xA (p ~y))), for each (non-static) precondition (q ~v) of (a ~x).\n(3a) \u00ac(justified (q ~z\u2032) (intends xA (p ~y))) and (delegated zA (q ~z\u2032)), if (e ~z) is a modal literal of the form (intends zA (q ~z\u2032)); (3b) \u00ac(justified (e ~z) (intends xA (p ~y))), if (e ~z) is not an intends literal and (e ~z) does not equal (p ~y);\n(4) \u00ac(delegated xA (e ~z)), if (e ~z) equals (p ~y);\nEffects (2) and (3) make the preconditions of the action justified, and the chosen effect unjustified, as explained above. If the chosen effect is a modal intends literal (case 3a), it is the intended subgoal that becomes unjustified, and also delegated to the other character. Effect (4) ends the delegation of a goal when the action is the final step in a frame of commitment. (Note, however, that the action will have this effect even if the goal was not delegated; this does not matter.)\nIf the chosen effect (e ~z) can be unified with (p ~y), the compiled action must be split into two: one with the additional precondition ~z = ~y, ensuring that they are equal, and one with the additional precondition ~z 6= ~y, ensuring that they are not. This is necessary since the effects of the compiled action depend on whether (e ~z) equals (p ~y) or not. Furthermore, as mentioned above, if the original action (a ~x) has more than one actor, the compiled problem has one action for every combination of an intention and a chosen effect for each actor. In this case, conditions on (p ~y) and (e ~z) in the schema above should be interpreted for each actor separately. That is, if (pi ~yi) and (ei ~zi) are the intention and chosen effect of actor xi\nA , the compiled action has the effect \u00ac(justified (ei ~zi) (intends\nxiA (p i ~yi))) if (ei ~zi) is not an intends literal and (ei ~zi) does not equal (pi ~yi) (item 3b), regardless of whether (ei ~zi) equals (pj ~yj) for some j 6= i, or vice versa. To illustrate the compilation, consider the following action from the example scenario by Riedl and Young (appendix A.1, p. 255), here written in a more PDDL-like syntax:\n(:action slay :parameters (?knight - knight ?monster - monster ?where - place) :actors (?knight) :precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)) :effect (and (not (alive ?monster)) (dead ?monster)))\nThe actor of this action is the knight. Consider the intention (intends ?knight (dead ?who)). The action has only one relevant choice of effect, (dead ?monster) (the negative literal does not appear in any action precondition or the goal). However, since the intention unifies with the chosen effect,\nthe compiled problem must still include two actions, one for ?who = ?monster and one for ?who 6= ?monster:\n(:action slay-1-because-intends-dead :parameters (?knight - knight ?monster - monster ?where - place) :precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)\n(intends ?knight (dead ?monster)) (not (exists (?c) (and (not (= ?c ?knight)) (delegated ?c (dead ?monster))))))\n:effect (and (not (alive ?monster)) (dead ?monster) (justified (at ?knight ?where) (intends ?knight (dead ?monster))) (justified (at ?monster ?where) (intends ?knight (dead ?monster))) (not (delegated ?knight (dead ?monster)))))\n(:action slay-2-because-intends-dead :parameters (?knight - knight ?monster - monster ?where - place ?who - monster) :precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)\n(intends ?knight (dead ?who)) (not (exists (?c) (delegated ?c (dead ?monster)))) (not (= ?who ?monster)))\n:effect (and (not (alive ?monster)) (dead ?monster) (justified (at ?knight ?where) (intends ?knight (dead ?who))) (justified (at ?monster ?where) (intends ?knight (dead ?who))) (not (justified (dead ?monster) (intends ?knight (dead ?who))))))\n(The alive literals don\u2019t need justification, because there is no way to make them true unless true initially.) Corresponding to the intention (intends ?knight (has ?who ?what)) the compiled problem will have the action:\n(:action slay-because-intends-has :parameters (?knight ?monster ?where ?who ?what) :precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)\n(intends ?knight (has ?who ?what)) (not (exists (?c) (delegated ?c (dead ?monster)))))\n:effect (and (not (alive ?monster)) (dead ?monster) (justified (at ?knight ?where) (intends ?knight (has ?who ?what))) (justified (at ?monster ?where) (intends ?knight (has ?who ?what))) (not (justified (dead ?monster) (intends ?knight (has ?who ?what))))))\nTo prove the correctness of the compilation in general, we will need the concept of a toggling action (Hickmott & Sardina, 2009). An action is toggling w.r.t. an effect of the action iff the action\u2019s precondition implies the negation of the effect. That is, if the action makes true a fact f , its precondition must include \u00acf , or some fact f \u2032 that is mutex with f , and if the action makes f false, it must require f to be true. An action that is not toggling can be transformed into an equivalent set of actions that are, though the size of this set is exponential in the number of non-toggling effects of the original action.\nTheorem 2 Let P be a narrative planning problem, in which each action is toggling w.r.t. its effects. Let P \u2032 be the compiled problem as described above. Every plan S for P \u2032 is intentional. Proof: Consider a step s in S, that is an instance of an action (a-e-because-intends-p ~x ~y). Let A be the actor (i.e., the constant bound to the actor parameter xA of a) and (e ~z) the chosen effect of (a ~x). The action will be part of a frame of commitment with the goal (p ~y). By construction, the\nprecondition of (a-e-because-intends-p ~x ~y) includes (intends A (p ~y)). There must be a motivating step that establishes this precondition, as otherwise S would not be classically valid.\nIf (e ~z) equals (p ~y), then s is itself the final step in the frame of commitment. If (e ~z) does not equal (p ~y) and is not a modal literal, then (a-e-because-intends-p ~x ~y) destroys (justified (e ~z) (intends A (p ~y)). Since all such literals are goals in P \u2032, there must be a later step, s\u2032, that re-establishes it. By construction, this can only be an action that has A as actor, (intends A (p ~y)) as the associated intention, and (e ~z) as a precondition. If there is no step between s and s\u2032 that adds (e ~z), there must be a causal link labelled with (e ~z) from s to s\u2032 (since actions are toggling, (e ~z) was not true before s). There cannot be only a step sadd between s and s\u2032 that adds (e ~z), because if so, the action associated with sadd would be applied in a state where one of its effects, (e ~z), is already true, and thus not toggling. Suppose there are steps sdel and sadd taking place between s and s\u2032, such that sdel destroys (e ~z) and sadd makes it true again; if there are several such steps, let sdel be the first and sadd the last, so that there is a causal link from sadd to s\u2032. Since actions are toggling sdel requires (e ~z), so there is a causal link from s to sdel. If there is no chain of causal links from sdel to sadd, the subplan consisting of steps up to and including s and all causal predecessors of sadd (which do not include sdel) must be executable, and results in an execution where the action associated with sadd is again applied in a state where one of its effects, (e ~z), is already true, and hence is not toggling. Thus, there must be a chain of causal links from sdel to sadd, and therefore from s to s\u2032. Since s\u2032 is part of the same frame of commitment as s (it has the same motivating intention), and there can only be a finite number of steps in this frame of commitment that causally follow s, repeated application of this reasoning leads to the conclusion that there must be a chain of causal links from s to the final step of the frame.\nIf (e ~z) is a modal literal of the form (intends zA (q ~z\u2032)), (a-e-because-intends-p ~x ~y) destroys (justified (q ~z\u2032) (intends A (p ~y)), and adds (delegated zA (q ~z\u2032)). As above, there must be a step s\u2032, in the same frame of commitment as s, that re-establishes (justified (q ~z\u2032) (intends A (p ~y)). By construction, (delegated w (q ~z\u2032)) can be true for at most one character w at any time (any action that adds a delegation requires that no other character has it), and only the character currently holding the delegation of (q ~z\u2032) can make it true. Thus, there is (by the same argument as above) a causal chain from the final step of the delegates frame of commitment with goal (q ~z\u2032) to s\u2032. Because actions in the compiled problem are toggling w.r.t. intends literals, step s must have a causal chain to the precondition (intends zA (q ~z\u2032)) of each action in the frame of commitment of the delegate, and thus serves as the motivating step for this frame. Thus, there is a chain of motivating and causal links from s to s\u2032, and following the same argument as above, therefore from s to the final step of the frame of commitment that s belongs to. 2\nIt may be noted that some apparently reasonable story plans are disallowed. For example, a character cannot delegate a goal that he himself intends to another character. This, however, is a consequence of Riedl and Young\u2019s definition of intentional plans, not of the compilation (and hence applies also to the IPOCL planner): the final step in a frame of commitment must achieve the intended goal and must be an action by the actor that holds this intention (conditions 1 & 2 of Definition 1). This rules out delegating one\u2019s own goals. If desired, it would not be difficult to modify the compilation to allow this kind of secondary delegation: it requries only adding the exception w 6= xA to precondition (3a) and an effect like (4) for this case. A plan also cannot have a character trying and failing by multiple means to achieve his goals. Again, this is a consequence of Riedl and Young\u2019s definition, not of the compilation: every action taken by a character must have a chain of\ncausal or motivational links to the final step (condition 4 of Definition 1). This rules out characters taking actions that prove ultimately futile.\nTheorem 2 shows that the compilation is sound. The question of whether it is also complete, i.e., whether existence of an intentional plan for a narrative planning problem P always implies existence of a plan for the compiled problem P \u2032, is somewhat complicated. At first glance, given an intentional plan S for P , it appears a plan S\u2032 for the compiled problem P \u2032 could be constructed by selecting for each action a in S a suitable representative a-. . .-because-. . ., with intentions and chosen effects to match the frames of commitment to which a belongs in S. Since S is intentional, each frame of commitment is preceded by a motivating step, ensuring the intends preconditions of the compiled action are satisified, and if a is not the final step, there is a causal link from at least one of its effects to another step, ensuring that deleted justified literals are restored. There is, however, one point where the correspondence can fail, due to the restriction of the compiled problem that a delegated goal can only be achieved by the character that it was delegated to: Suppose character A delegates goal g to character B, i.e., character A performs an intentional action whose only (relevant) effect is (intends B g). For the plan to be intentional, there must be a frame of commitment belonging to character B, with the associated intention (intends B g); this frame must have a final step which achieves g, and that step must be the source of a causal link to some step performed by character A, belonging to same the frame of commitment of A as the step that established the motivation. Yet, nothing prevents another character, C, from achieving g for his own purposes, as long as character B also achieves g. The compiled problem, however, does not allow character C to achieve g as long as it is delegated to B, i.e., in between the motivating step by A and the final step by B. This could be remedied through a more elaborate justification tracking mechanism, that distinguishes the same fact when achieved by different characters.\nFrom a practical perspective, the combinations of actions with intentions, and modal literals, present in the compiled problem can be restricted to those that are \u201cpossible and relevant\u201d. For example, the initial state and goal only needs to include those justified literals that can actually be negated by some possibly applicable action (which can be found by standard relaxed reachability analysis). In the example scenario, the fact that a character has the Lamp can never causally contribute to, e.g., the goal of the character having another item (there are no other items to have) or the goal of murdering another character. Thus, actions like pillage-because-intends-dead or order-hasbecause-intends-has and order-has-because-intends-dead can never be part of valid plan. Most of this information could be found by simple techniques like back-chaining relevance analysis.\nApplying the compilation to Riedl and Young\u2019s example scenario, and applying a classical planner, using forward-chaining A* search with the LM-Cut heuristic (Helmert & Domshlak, 2009), to the compiled problem, produces the plan shown in figure 1. The planner outputs a sequence of actions, which is transformed to a partially ordered plan by a polynomial time post-processing step (Ba\u0308ckstro\u0308m, 1998). Enumerating all shortest plans reveals two variations: one in which Jafar travels back to the Castle to marry Jasmine, and one in which Jafar orders Aladdin to bring him the Lamp, and both climactic events (the wedding and Aladding slaying the Genie) take place at the Castle. (The latter is the one Riedl and Young report was found by IPOCL, shown in Figure 15, p. 259, of their article.) Note that it is not possible for Jafar to command Aladdin to make (loves Jasmine Jafar) true, because Aladdin has no means to achieve this goal other than by delegating it to the Genie, which, as explained above, is not permitted by the definition of a frame of commitment.\nFinding shortest plans is not an end in itself: rather, it is a side effect of the fact that a planner will usually seek to achieve the story outcome in the simplest way. This can be somewhat at odds\nwith making the story \u201cinteresting\u201d. Porteous and Cavazza (2009) argue that complexification, i.e., making the story more convoluted in order to make it more interesting, can be achieved by posting additional author goals in the form of PDDL3 trajectory constraints, specifying that some fact must be achieved at some point in the plan; that some fact must never be true at any point; or that some fact must be achieved before another. PDDL3 trajectory constraints can also be compiled away (Gerevini, Haslum, Long, Saetti & Dimopoulos, 2008). Methods for generating a \u201cdiverse\u201d set of plans (Srivastava, Kambhampati, Nguyen, Do, Gerevini & Serina, 2007) could also be used to automate complexification.\nThe total time to generate the plan is around 45 seconds (and of that, only half is actual search; the rest is grounding and preprocessing.) The time required for the compilation itself is less than a second. This is in stark contrast to the running time of the IPOCL planner on this problem, reported to be over 12 hours even with a problem-specific search heuristic (Riedl & Young, 2010). However, this example represents a very small problem. It contains only the actions and objects necessary to form the \u201cintended\u201d story plan, and no more. A more realistic scenario is a problem specification that contains many possible actions and objects that are not relevant to the story outcome, or that allow the construction of materially different plans for that goal. The size of the compiled problem can grow quite quickly as the size of the original narrative planning problem increases. As an example, a larger version of the same problem, including three more actions and a few more items, none directly relevant to achieving the outcome, takes nearly 30 minutes to solve."}, {"heading": "4. Compilation 2: Meta-Planning", "text": "\u201cIf only I had the Magic Lamp, thought Jafar. Then I could summon the Genie to gain control over it. If I controlled the Genie, I could command it to make Jasmine love me.\u201d\nThe second compilation is based on simulating the characters\u2019 process of forming intentions by making plans, using explicit character planning actions. It has some similarity to Wolfe and Russell\u2019s (2011) use of explicit establishment of intentions as a means to guide plan search more efficiently. Compared to the justification-tracking compilation, it is less complex but also less stringent: plans for a meta-planning compiled problem are not guaranteed to be intentional, according to the definition of Riedl and Young, although most of the time they will be.\nA meta-planning action allows a character to adopt the intention of achieving the precondition of an action that achieves a goal that the character already intends. To avoid characters making plans that they never act on, a counter tracks the number of intentions each character has, and is required to be zero at the end of the plan.3 The counter can be represented by the standard propositional encoding (though this limits the depth of intentions a character can hold), or by a numeric fluent.\nLet (a ~x) be an intentional action, xA the parameter that represents its actor, and (e ~z) its chosen effect. The corresponding action in the compiled problem has the additional precondition (intends xA (e ~z)) and effects \u00ac(intends xA (e ~z)) and decreases xA\u2019s intention count by 1. In other words, to take an action, the actor must have one of its effects in his current set of intentions, and performing the action releases the actor from that intention. If (e ~z) is a modal literal of the form (intends zA (q ~z\u2032)), the precondition and effect refer instead to (q ~z\u2032), and the action also increases the intention count of zA, i.e., the effect is to move (q ~z\u2032) from the intention set of xA to that of character zA. Happenings that add character intentions must also increase the intention count.\n3. Some exceptions must be made: for example, if a character dies, he obviously cannot act on any outstanding intentions, but this should not invalidate the plan.\nFor each precondition (p ~y) of (a ~x), the compiled problem also has an action (plan-to-a ~x), with precondition (intends xA (e ~z)) and effects (intends xA (p ~y)) and increasing xA\u2019s intention count. If (a ~x) has several preconditions, an order of achievement among them can be enforced by adding subsets of those preconditions to the meta-planning actions. For example, the action (give ?who ?what ?to-who ?where) has the preconditions: (has ?who ?what); (at ?who ?where); and (at ?to-who ?where). Adding (has ?who ?what) to the precondition of the meta-planning action that establishes (intends ?who (at ?who ?where)) forces a character who intends to give something to not only plan to acquire the item, but to actually do so, before planning to travel (if necessary) to a place where the recipient of the gift is. Some necessary and reasonable constraints on the order of achievement of action preconditions may be found by landmark ordering analysis (Hoffmann, Porteous, & Sebastia, 2004). Manually adding further constraints to meta-planning actions gives them some flavour of (a simulation of) methods in HTN planning (Erol, Nau, & Hendler, 1994).\nThe reason why the meta-planning compilation does not guarantee intentional plans is that while it forces characters to motivate any action by a plan, it does not force them to monitor that their plans are still valid when the action takes place. For example, if Aladdin plans to slay the Dragon in order to pillage the Lamp, but a thief steals the Lamp from the Dragon while Aladdin is on his way to the Mountain, Aladdin still has license to slay the Dragon, even though this no longer contributes to getting him the Lamp (in fact, he must slay the Dragon to avoid being left with an unfulfilled intention). In part, this could be rectified by encoding a more elaborate structure of character plans than just the set of outstanding goals. For example, a directed graph encoding could track dependency relations between intentions, and their dependence on story world facts. This may also provide a basis for allowing characters to revise their plans in the face of changed circumstances.\nLimited computational experiments with the meta-planning compilation suggest that while it produces much smaller (ground) problems than the justification-tracking compilation, these can still be harder for current heuristic search-based planners to solve."}, {"heading": "5. Conclusion", "text": "Research into the classical planning problem has developed a wide array of, sometimes highly effective, methods for solving such problems. Through compilations, the capabilities of existing classical planners can be leveraged to solve many more problems than those that on the surface appear to be classical planning problems. Like the loyal knight of the story, a classical planner will committedly try to solve whatever task is set before it, as expressed by the planning domain specification. The trick is setting it the right task.\nAs noted, the narrative planning model defined by Riedl and Young has some limitations. For example, it does not allow to create a story in which a character tries but fails to achieve a goal. Brenner (2010) describes an approach to story generation that interleaves classical planning for individual characters\u2019 goals, based on the characters\u2019 state of knowledge, with plan \u201cexecution\u201d, i.e., adding events to the story. This permits the system to generate stories where characters are forced to abandon their plans after learning new facts, or postpone planning until crucial facts become known. Brenner claims that \u201cit would be quite difficult to describe [such a plot] with a single plan, let alone generate it with a single planner run.\u201d It does indeed appear quite difficult, but whether or not it is impossible remains an open question."}, {"heading": "Acknowledgments", "text": "I wish to thank Alban Grastien, Malte Helmert, Robert Mattu\u0308ller and the reviewers for useful comments on drafts of this paper. This work was supported by the Australian Research Council discovery project DP0985532 \u201cExploiting Structure in AI Planning\u201d. NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program."}], "references": [{"title": "Computational aspects of reordering plans", "author": ["C. B\u00e4ckstr\u00f6m"], "venue": "Journal of AI Research,", "citeRegEx": "B\u00e4ckstr\u00f6m,? \\Q1998\\E", "shortCiteRegEx": "B\u00e4ckstr\u00f6m", "year": 1998}, {"title": "Creating dynamic story plots with continual multiagent planning", "author": ["M. Brenner"], "venue": "In Proc. 24th AAAI Conference on Artificial Intelligence,", "citeRegEx": "Brenner,? \\Q2010\\E", "shortCiteRegEx": "Brenner", "year": 2010}, {"title": "HTN planning: Complexity and expressivity", "author": ["K. Erol", "D. Nau", "J. Hendler"], "venue": "In Proc. National Conference on Artificial Intelligence", "citeRegEx": "Erol et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Erol et al\\.", "year": 1994}, {"title": "Deterministic planning in the fifth international planning competition: PDDL3 and experimental evaluation of the planners", "author": ["A. Gerevini", "P. Haslum", "D. Long", "A. Saetti", "Y. Dimopoulos"], "venue": "Artificial Intelligence,", "citeRegEx": "Gerevini et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gerevini et al\\.", "year": 2008}, {"title": "Computational approaches to storytelling and creativity", "author": ["P. Gerv\u00e1s"], "venue": "AI Magazine,", "citeRegEx": "Gerv\u00e1s,? \\Q2009\\E", "shortCiteRegEx": "Gerv\u00e1s", "year": 2009}, {"title": "Landmarks, critical paths and abstractions: What\u2019s the difference anyway", "author": ["M. Helmert", "C. Domshlak"], "venue": "In Proc. 19th International Conference on Automated Planning and Scheduling (ICAPS\u201909)", "citeRegEx": "Helmert and Domshlak,? \\Q2009\\E", "shortCiteRegEx": "Helmert and Domshlak", "year": 2009}, {"title": "Optimality properties of planning via Petri net unfolding: A formal analysis", "author": ["S. Hickmott", "S. Sardina"], "venue": "In Proc. 19th International Conference on Automated Planning and Scheduling", "citeRegEx": "Hickmott and Sardina,? \\Q2009\\E", "shortCiteRegEx": "Hickmott and Sardina", "year": 2009}, {"title": "Ordered landmarks in planning", "author": ["J. Hoffmann", "J. Porteous", "L. Sebastia"], "venue": "Journal of AI Research,", "citeRegEx": "Hoffmann et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2004}, {"title": "Living on the edge: Safe search with unsafe heuristics", "author": ["E. Karpas", "C. Domshlak"], "venue": "In Proc. ICAPS\u201911 Workshop on Heuristics for Domain-Independent Planning,", "citeRegEx": "Karpas and Domshlak,? \\Q2011\\E", "shortCiteRegEx": "Karpas and Domshlak", "year": 2011}, {"title": "Narrative intelligence. In Narrative Intelligence: Papers from the AAAI Fall Symposium", "author": ["M. Mateas", "P. Sengers"], "venue": null, "citeRegEx": "Mateas and Sengers,? \\Q1999\\E", "shortCiteRegEx": "Mateas and Sengers", "year": 1999}, {"title": "Systematic nonlinear planning", "author": ["D. McAllester", "D. Rosenblitt"], "venue": "In Proc. 9th National Conference on Artificial Intelligence", "citeRegEx": "McAllester and Rosenblitt,? \\Q1991\\E", "shortCiteRegEx": "McAllester and Rosenblitt", "year": 1991}, {"title": "Compiling uncertainty away: Solving conformant planning problems using a classical planner (sometimes)", "author": ["H. Palacios", "H. Geffner"], "venue": "In Proc. 21st National Conference on Artificial Intelligence (AAAI\u201906)", "citeRegEx": "Palacios and Geffner,? \\Q2006\\E", "shortCiteRegEx": "Palacios and Geffner", "year": 2006}, {"title": "Controlling narrative generation with planning trajectories: the role of constraints", "author": ["J. Porteous", "M. Cavazza"], "venue": "In Proc. 2nd International Conference on Interactive Digital Storytelling,", "citeRegEx": "Porteous and Cavazza,? \\Q2009\\E", "shortCiteRegEx": "Porteous and Cavazza", "year": 2009}, {"title": "Visual programming of plan dynamics using constraints and landmarks", "author": ["J. Porteous", "J. Teutenberg", "D. Pizzi", "M. Cavazza"], "venue": "In Proc. 21st International Conference on Automated Planning and Scheduling", "citeRegEx": "Porteous et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Porteous et al\\.", "year": 2011}, {"title": "Narrative planning: Balancing plot and character", "author": ["M. Riedl", "R. Young"], "venue": "Journal of AI Research,", "citeRegEx": "Riedl and Young,? \\Q2010\\E", "shortCiteRegEx": "Riedl and Young", "year": 2010}, {"title": "Domain independent approaches for finding diverse plans", "author": ["B. Srivastava", "S. Kambhampati", "T. Nguyen", "M. Do", "A. Gerevini", "I. Serina"], "venue": "In Proc. 20th International Conference on Artificial Intelligence", "citeRegEx": "Srivastava et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2007}, {"title": "Bounded intention planning", "author": ["J. Wolfe", "S. Russell"], "venue": "In Proc. of the 22nd International Joint Conference on AI (IJCAI\u201911),", "citeRegEx": "Wolfe and Russell,? \\Q2011\\E", "shortCiteRegEx": "Wolfe and Russell", "year": 2011}], "referenceMentions": [{"referenceID": 11, "context": "A striking example is the work of Palacios and Geffner (2006), who showed that conformant planning (generating plans that are robust to certain forms of uncertainty) can be compiled into a classical planning problem.", "startOffset": 34, "endOffset": 62}, {"referenceID": 11, "context": "A striking example is the work of Palacios and Geffner (2006), who showed that conformant planning (generating plans that are robust to certain forms of uncertainty) can be compiled into a classical planning problem. Another example, closer to the topic of this paper, is the work by Porteous, Teutenberg, Pizzi and Cavazza (2011), who use a planner to generate variations of a drama by encoding constraints on the sequencing of events within it.", "startOffset": 34, "endOffset": 331}, {"referenceID": 14, "context": "1 The fabula planning problem considered was formulated by Riedl and Young (2010). Its main difference from classical planning is a notion of intentionality: actions in a story are taken by different characters, and for the story to be considered believable, characters should behave intentionally, i.", "startOffset": 59, "endOffset": 82}, {"referenceID": 8, "context": "It is inspired by the work of Karpas and Domshlak (2011) on pruning redundant action sequences from the search space, which also relies on a notion of justification of actions.", "startOffset": 30, "endOffset": 57}, {"referenceID": 10, "context": "A detailed account of POCL planning can be found in the paper by McAllester and Rosenblitt (1991) and in most AI textbooks.", "startOffset": 65, "endOffset": 98}, {"referenceID": 0, "context": "The planner outputs a sequence of actions, which is transformed to a partially ordered plan by a polynomial time post-processing step (B\u00e4ckstr\u00f6m, 1998).", "startOffset": 134, "endOffset": 151}, {"referenceID": 12, "context": "Porteous and Cavazza (2009) argue that complexification, i.", "startOffset": 0, "endOffset": 28}, {"referenceID": 15, "context": "It has some similarity to Wolfe and Russell\u2019s (2011) use of explicit establishment of intentions as a means to guide plan search more efficiently.", "startOffset": 26, "endOffset": 53}, {"referenceID": 1, "context": "Brenner (2010) describes an approach to story generation that interleaves classical planning for individual characters\u2019 goals, based on the characters\u2019 state of knowledge, with plan \u201cexecution\u201d, i.", "startOffset": 0, "endOffset": 15}], "year": 2012, "abstractText": "A model of story generation recently proposed by Riedl and Young casts it as planning, with the additional condition that story characters behave intentionally. This means that characters have perceivable motivation for the actions they take. I show that this condition can be compiled away (in more ways than one) to produce a classical planning problem that can be solved by an off-the-shelf classical planner, more efficiently than by Riedl and Young\u2019s specialised planner.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}