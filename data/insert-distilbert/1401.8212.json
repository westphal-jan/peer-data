{"id": "1401.8212", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jan-2014", "title": "Human Activity Recognition using Smartphone", "abstract": "human activity recognition has wide applications in medical research and human survey system. in this clinical project, we design a robust activity recognition system based on a smartphone. the system uses a 3 - dimentional smartphone accelerometer as the active only sensor to collect time series signals, from which 31 features are generated in both time and frequency domain. activities are classified overall using 4 different passive learning methods, i. e., quadratic classifier, k - nearest neighbor reconstruction algorithm, support vector machine, and artificial neural networks. dimensionality reduction is performed through both feature extraction and subset selection. besides employing passive learning, we now also apply active learning decomposition algorithms to reduce data labeling expense. experiment results show that the classification rate of passive learning reaches 84. 4 % and it is robust to common positions and poses of using cellphone. the good results of active learning on real data demonstrate a reduction of labeling labor to correctly achieve comparable performance with passive learning.", "histories": [["v1", "Thu, 30 Jan 2014 17:28:10 GMT  (552kb)", "http://arxiv.org/abs/1401.8212v1", null]], "reviews": [], "SUBJECTS": "cs.CY cs.HC cs.LG", "authors": ["amin rasekh", "chien-an chen", "yan lu"], "accepted": false, "id": "1401.8212"}, "pdf": {"name": "1401.8212.pdf", "metadata": {"source": "CRF", "title": "Human Activity Recognition using Smartphone", "authors": ["Amin Rasekh", "Chien-An Chen", "Yan Lu"], "emails": [], "sections": [{"heading": null, "text": "research and human survey system. In this project, we design a robust activity recognition system based on a smartphone. The system uses a 3-dimentional smartphone accelerometer as the only sensor to collect time series signals, from which 31 features are generated in both time and frequency domain. Activities are classified using 4 different passive learning methods, i.e., quadratic classifier, k-nearest neighbor algorithm, support vector machine, and artificial neural networks. Dimensionality reduction is performed through both feature extraction and subset selection. Besides passive learning, we also apply active learning algorithms to reduce data labeling expense. Experiment results show that the classification rate of passive learning reaches 84.4% and it is robust to common positions and poses of cellphone. The results of active learning on real data demonstrate a reduction of labeling labor to achieve comparable performance with passive learning."}, {"heading": "1. INTRODUCTION", "text": "The demands for understanding human activities have grown in health-care domain, especially in elder care support, rehabilitation assistance, diabetes, and cognitive disorders. [1,2,3]. A huge amount of resources can be saved if sensors can help caretakers record and monitor the patients all the time and report automatically when any abnormal behavior is detected. Other applications such as human survey system and location indicator are all benefited from the study. Many studies have successfully identified activities using wearable sensors with very low error rate, but the majority of the previous works are done in the laboratories with very constrained settings. Readings from multiple body-attached sensors achieve low error-rate, but the complicated setting is not feasible in practice.\nThis project uses low-cost and commercially available smartphones as sensors to identify human activities. The growing popularity and computational power of smartphone make it an ideal candidate for non-intrusive body-attached sensors. According to the statistic of US mobile subscribers, around 44% of mobile subscribers in 2011 own smartphones and 96% of these smartphones have built-in inertial sensors such as accelerometer or gyroscope [4,5]. Research has shown that gyroscope can help activity recognition even though its contribution alone is not as\ngood as accelerometer [6,7]. Because gyroscope is not so easily accessed in cellphones as accelerometer, our system only uses readings from a 3-dimensional accelerometer. Unlike many other works before, we relaxed the constraints of attaching sensors to fixed body position with fixed device orientation. In our design, the phone can be placed at any position around waist such as jacket pocket and pants pocket, with arbitrary orientation. These are the most common positions where people carry mobile phones.\nTraining process is always required when a new activity is added to the system. Parameters of the same algorithm may need to be trained and adjusted when the algorithm runs on different devices due to the variance of sensors. However, labeling a time-series data is a time consuming process and it is not always possible to request users to label all the training data. As a result, we propose using active learning technique to accelerate the training process. Given a classifier, active learning intelligently queries the unlabeled samples and learns the parameters from the correct labels answered by the oracle, usually human. In this fashion, users label only the samples that the algorithm asks for and the total amount of required training samples is reduced. To the best of our knowledge, there is no previous study on applying active learning to human activity recognition problem.\nThe goal of this project is to design a light weight and accurate system on smartphone that can recognize human activities. Moreover, to reduce the labeling time and burden, active learning models are developed. Through testing and comparing different learning algorithms, we find one that best fit our system in terms of efficiency and accuracy on a smartphone."}, {"heading": "2. LITERATURE REVIEW", "text": "Human activity recognition has been studied for years and researchers have proposed different solutions to attack the problem. Existing approaches typically use vision sensor, inertial sensor and the mixture of both. Machine learning and threshold-base algorithms are often applied. Machine learning usually produces more accurate and reliable results, while threshold-based algorithms are faster and simpler. One or multiple cameras have been used to capture and identify body posture [8, 9]. Multiple accelerometers and gyroscopes attached to different body positions are the most common solutions [10-13]. Approaches that combine both vision and\ninertial sensors have also been purposed [14]. Another essential part of all these algorithms is data processing. The quality of the input features has a great impact on the performance. Some previous works are focused on generating the most useful features from the time series data set [15]. The common approach is to analyze the signal in both time and frequency domain.\nActive learning technique has been applied on many machine learning problems that are time-consuming and labor-expensive to label samples. Some applications include speech recognition, information extraction, and handwritten character recognition [18,19,20]. This technique, however, has yet been applied on the human activity problem before."}, {"heading": "3. METHODS", "text": ""}, {"heading": "3.1 Feature Generation", "text": "To collect the acceleration data, each subject carries a smartphone for a few hours and performs some activities. In this project, five kinds of common activities are studied, including walking, limping, jogging, walking upstairs, and walking downstairs. The position of the phone can be anywhere close to the waist and the orientation is arbitrary.\nThe built-in accelerometer we use has maximum sampling frequency 50 Hz and \u00b13g sensitivity. According to a previous study, body movements are constrained within frequency components below 20Hz, and 99% of the energy is contained below 15 Hz [16]. According to Nyquist frequency theory, 50 Hz accelerometer is sufficient for our study. A low-pass filter with 25Hz cutoff frequency is applied to suppress the noise. Also, due to the instability of phone sensor, which may drop samples accidentally, interpolation is applied to fill the gaps.\nTo analyze the activities in a short period, we group every 256 sample in a window, which corresponds to 5.12 sec length of data. The choice of 256, which is a power of two, is a preferred size when applying Fast Fourier Transformation. For each sample window, 31 features are extracted in both time domain and frequency domain as shown in Table 1. Except for the average resultant acceleration, all the other features are generated for x, y and z directions."}, {"heading": "3.2 Classifiers", "text": "In this project, four kinds of classifiers are employed to classify the activity as described below."}, {"heading": "3.2.1 Quadratic Classifier", "text": "If we assume every class is normally distributed, then the discriminant function for class is defined as\n( )\n( )\n( )\n| | ( ),\nwhere and represent the mean and covariance of the Gaussian distribution of class , respectively.\nGiven a feature vector x, a quadratic classifier assigns\n( ) ( ) . Therefore, the decision\nboundary is in general a quadratic curve."}, {"heading": "3.2.2 k-Nearest Neighbor", "text": "The k-nearest neighbor (kNN) algorithm classifies unlabeled instances based on a voting of the labels of k closest training examples in the feature space.\nkNN is a lazy learning algorithm since it defers data processing until a classification request arises. Because kNN uses local information, it can achieve highly adaptive performance. On the other hand, kNN involves large storage requirement and intensive computation, and the value of k also needs to be determined properly."}, {"heading": "3.2.3 Support Vector Machine", "text": "As a supervised classifier, a standard support vector machine (SVM) aims to find a hyperplane separating 2 classes which maximizes the distance to the closest points from each class. The closest points are called support vectors.\nGiven n training data points {xi}, and class labels {yi}, , a hyperplane separating two classes has the form ( )\nSuppose {wk} is the set of all such hyperplanes. The optimal hyperplane is defined by \u2211 and b is set by the Karush Kuhn Tucker conditions where { } maximize\n\u2211\n\u2211 \u2211\n,\nsubject to \u2211\nIn the linearly separable case, only the \u2019s corresponding support vectors will be non-zero.\nSince the data points x only enter calculation via dot product, we can use a mapping ( ) to transform them to\nanother feature space such that the originally non-linearly separable data can be linearly separable after mapping. Moreover, ( ) is not necessarily an explicit function. Instead, we are only interested in a kernel function\n( ) ( ) ( )\nwhich satisfies Mercer\u2019s condition. In this study, we use a radial basis function kernel\n( ) | |\n.\nTo extend a standard SVM for multiclass problem, we use the one-against-all strategy, which trains a standard SVM for each class and assigns an unknown pattern to the class with the highest score."}, {"heading": "3.2.4 Artificial Neural Network", "text": "An artificial neural network (ANN) is a computational model consisting of interconnected artificial neurons (or nodes) that is inspired from biological neural networks. ANNs are able to model complex relationships between inputs and outputs or to find patterns in data.\nIn this project, we use a class of ANN called multilayer perceptron (MLP) as a classifier as illustrated in Fig. 1. Backpropagation algorithm is used in the training process."}, {"heading": "3.3 Dimensionality Reduction", "text": "There are two ways to do feature dimension reduction: feature extraction and feature selection."}, {"heading": "3.3.1 Feature Extraction", "text": "Feature extraction transforms the original high dimensional data to a lower dimension feature space. The transformation can be linear or nonlinear. In this project, we employed Linear Discriminant Analysis (LDA)."}, {"heading": "3.3.2 Feature Selection", "text": "Feature selection is a technique of selecting a subset of most relevant features from the original features. While feature selection may be regarded as a special case of feature extraction mathematically, the researches in these two areas are quite different.\nIn feature selection, an objective function is needed to evaluate candidate features. Two kinds of objective functions are available: filters and wrappers. Filters evaluate the feature subsets based on their information content like\ninterclass distance or statistical independence. Wrappers evaluate features by the prediction accuracy of a classifier. In this study, we use wrappers for feature selection."}, {"heading": "3.4 Active Learning", "text": "Active learning is one of the mainstream machine learning methods for solving a class of problems where a large amount of unlabeled data may be available or easily obtained, but labels are difficult, expensive, and timeconsuming to achieve. The core idea of active learning is that a machine learning technique can achieve higher accuracy using fewer training labels if it selects the data from which it learns [17] The learning process involves interaction with an oracle who labels unlabeled data samples through guided queries made by the learner as illustrated in Fig. 2. In order to get higher classification rate through less labeled training set, the learner searches to label the unlabeled instances that are most informative.\nThe problem of selecting unlabeled instances is thus the principal challenge for the active learning process. Typically, the query builds upon notions of uncertainty in classification. For example, samples that are most likely to be misclassified can be considered to be the most informative and will be chosen for query.\nIn this study, the uncertainty )(xu for every unlabeled\ninstance x is quantified in a distinct way depending upon what learning algorithm is used, as follows:\nQuadratic Classifier\nQuery is performed first for the unlabeled instances that are nearest to the discriminant line and are accordingly most uncertain. For a two-class problem, uncertainty for an unlabeled instance x is measured as:\n1 21 )()()(   xgxgxu\nwhere )(xg i is the quadratic discriminant function for class i . For a multi-class classification problem, )(xu is first\ncalculated for all binary combinations of existing classes and the maximum value is considered as the measure of uncertainty for instance x .\nk-Nearest Neighbors\nApplication of distance measure is not feasible for the kNN technique. The uncertainty is measured using the concept of Shannon entropy H . In mathematical terms,\nc c\nc ppxHxu  log)()(\nwhere c denotes classes and c p is the probability that\ninstance x belongs to a specific class. c p is calculated through dividing the number of neighbors that belong to a specific class over the total number of neighbors k.\nSupport Vector Machines\nSince we adopt the one-against-all method for multiclass problem, we choose the sample that has the smallest distance to the decision boundary as the next query.\nArtificial Neural Networks\nGiven a sample, the output of ANN consists of the probability of the sample belonging to each class. Similar to the uncertainty measure used in kNN, query is made here for the sample that has the highest entropy."}, {"heading": "4. RESULTS AND DISCUSSIONS", "text": ""}, {"heading": "4.1 Data Collection", "text": "Our experiment data is collected by three persons using a HTC Evo Smartphone. A total amount of 1393 samples are obtained. 75% of the data is used for training and the rest is used for testing.\nIn order to illustrate the complexity of the classification problem, the first two LDA components are plotted in Fig. 3(a), and the two best selected features are illustrated in Fig. 3(b). As observed, the classification problem is nontrivial. Two activities of walking upstairs and downstairs, in specific, are very difficult to be discriminated."}, {"heading": "4.2 Passive Learning", "text": "Four classifiers, quadratic, kNN, ANN, and SVM, are studied. SVM-KM [21] and Matlab ANN toolboxes are used in this study. All methods are tested with the samples in original feature space, LDA subspace, and sequential forward selection (SFS) subspace. We run SFS algorithm on each classifier and pick the best five features that are selected by all classifiers. The same feature subset is then used on all classifiers. The selected features are variance, 75 percentile, frequency entropy, and peak frequency. It is also observed that z-axis is the most informative direction because cellphones are usually attached to human body vertically and the z-axis, which is perpendicular to the screen, is independent to the orientation of the phone.\nFig. 4 shows the performance of each classifier in different feature spaces. The maximum classification rate is achieved when SVM is used with the SFS (84.4%). The quadratic algorithm, on the other hand, has the worst performance. For all classifiers except SVM, the performance is highest in the LDA subspace and lowest in the original feature space. Quadratic classifier gives the lowest classification rate due to the non-Gaussian distribution of each class. Feature subset selection enhances the performance of the SVM method because it removes the features that misguide the algorithm. kNN classification rate is noticeably improved after LDA is performed. kNN is highly sensitive to the scales of different features. LDA alleviates this problem through reducing the feature space into a more normalized and smaller subspace."}, {"heading": "4.3 Active Learning", "text": "For our experiments, we consider a randomly initialized training set, a test set, and a query set that contains unlabeled samples. Passive learning results showed that dimensionality reduction (SFS and LDA) may significantly enhance the classification performance. Accordingly, the active learning is performed here using the subset of features and LDA subspace.\nThe test set comprises 25% of the original dataset. The active learning model queries the unlabeled samples from the query set only, whereas the classification rate is reported on the test set. For every classifier, the average classification rate is reported (averaged over 50 runs).\nThe initial training set is seeded randomly by selecting 4 training samples per class and the remaining samples form the query set. For each round of active learning, one unlabeled sample is selected from the query set and added to the training set.\nIf the samples chosen for the query are selected solely based upon the uncertainty measure, there is a possibility that certain regions in the feature space are never explored. This problem is most serious for quadratic classifier as the training set converges to a long and thin space along the discriminant curve as it grows with more queries. Under these circumstances, the distributions of classes extremely deviate from their true shape. To deal with this problem, some samples may be picked from the query set randomly than using the uncertainty measure. For our problem, the probability that the query is made randomly is set to 0.10.\nPerformance of active learning algorithms is commonly assessed by constructing learning curves. It is a plot that shows the performance measure of interest (e.g. classification rate) as a function of the number of queries performed. Fig. 5 presents learning curves for the first 300 samples labeled using the uncertainty query (with 10% random sampling) and pure random sampling for all four classifiers.\nFor kNN classifier, the active learning curve clearly dominates the baseline random sampling curve for all the points. While the learning curves for both active and random sampling for LDA and SFS start from the same classification rate (0.44), the maximum learning rate is achieved when 50 100 150 200 250 300 0.4 0.45\n0.5\n0.55\n0.6\n0.65\n0.7\n0.75\n0.8\n0.85\n0.9\nNumber of training instances added\nC la\ns s if ic\na ti o n r\na te\nKNN\nRandom sampling (LDA) Active sampling (LDA) Random sampling (SFS) Active sampling (SFS)\nactive sampling is performed in LDA space. These findings are consistent with the results of passive learning where learning process in LDA space outperformed original highdimensional space and selected subset.\nSVM active learning algorithm also performs better than random sampling in both LDA and selected subset space. While the results of passive learning showed that SVM performs better in selected subset space, it is observed here this is not true when only 20 instances are used. In the other words, if very small dataset is available, it is more efficient to use the LDA space than the selected subset space. The learning curves for the selected subspace, nevertheless, dominate those for LDA after about 70 queries are made.\nWhile the results showed active learning obviously outperforms random sampling for KNN and SVM techniques, no precise conclusion might be made for ANN. While the performance increases as more queries are made in general, the learning curves significantly oscillate. This instability may be due to the high sensitivity of weight functions to the new samples added to the training set when this set is small. As observed more clearly for the LDA space, the oscillations damp with increasing size of the training set.\nOpposite to KNN, SVM, and ANN, the quadratic active learning algorithm is totally dominated by the random sampling except for the first 10 queries. After these initial queries, the training set is filled with the samples that are located around the discriminant curves. This happens because of the query strategy described in section 3.4. The distribution of samples deviates from their true distribution. While SVM also uses the distance measure for queries, this problem is not serious for this algorithm. This is rooted in how SVM works. While quadratic classifier uses all samples to classify, SVM uses only samples around the boundary. Therefore, SVM is not as sensitive to the distribution of the queried samples in the training set."}, {"heading": "5. CONCLUSIONS", "text": "Human activity recognition has broad applications in medical research and human survey system. In this project, we designed a smartphone-based recognition system that recognizes five human activities: walking, limping, jogging, going upstairs and going downstairs. The system collected time series signals using a built-in accelerometer, generated 31 features in both time and frequency domain, and then reduced the feature dimensionality to improve the performance. The activity data were trained and tested using 4 passive learning methods: quadratic classifier, k-nearest neighbor algorithm, support vector machine, and artificial neural networks.\nThe best classification rate in our experiment was 84.4%, which is achieved by SVM with features selected by SFS. Classification performance is robust to the orientation and the position of smartphones. Besides, active learning\nalgorithms were studied to reduce the expense of labeling data. Experiment results demonstrated the effectiveness of active learning in saving labeling labor while achieving comparable performance with passive learning. Among the four classifiers, KNN and SVM improve most after applying active learning. The results demonstrate that entropy and distance to the boundary are robust uncertainty measures when performing queries on KNN and SVM respectively. Conclusively, SVM is the optimal choice for our problem.\nFuture work may consider more activities and implement a real-time system on smartphone. Other query strategies such as variance reduction and density-weighted methods may be investigated to enhance the performance of active learning schemes proposed here."}, {"heading": "6. REFERENCES", "text": "[1] Morris, M., Lundell, J., Dishman, E., Needham, B.: New\nPerspectives on Ubiquitous Computing from Ethnographic Study of Elders with Cognitive Decline. In: Proc. Ubicomp (2003).\n[2] Lawton, M. P.: Aging and Performance of Home Tasks.\nHuman Factors (1990)\n[3] Consolvo, S., Roessler, P., Shelton, B., LaMarcha, A.,\nSchilit, B., Bly, S.: Technology for Care Networks of Elders. In: Proc. IEEE Pervasive Computing Mobile and Ubiquitous Systems: Successful Aging (2004).\n[4] http://www.isuppli.com/MEMS-and-\nSensors/News/Pages/Motion-Sensor-Market-forSmartphones-and-Tablets-Set-to-Double-by-2015.aspx.\n[5] http://www.comscore.com/Press_Events/Press_Releases\n/2011/11/comScore_Reports_September_2011_U.S._M obile_Subscriber_Market_Share.\n[6] S.W Lee and K. Mase. Activity and location recognition\nusing wearable sensors. IEEE Pervasive Computing, 1(3):24\u201332, 2002.\n[7] K. Kunze and P. Lukowicz. Dealing with sensor\ndisplacement in motion-based on body activity recognition systems. Proc. 10th Int. Conf. on Ubiquitous computing, Sep 2008\n[8] T.B.Moeslund,A.Hilton,V.Kruger, A survey of\nadvances in vision-based human motion capture and analysis, Computer Vision Image Understanding 104 (2- 3) (2006) 90\u2013126\n[9] R. Bodor, B. Jackson, and N. Papanikolopoulos. Vision-\nbased human tracking and activity recognition. In Proc. of the 11th Mediterranean Conf. on Control and Automation, June 2003\n[10] L. Bao and S. S. Intille, \u201cActivity recognition from user-\nannotated acceleration data,\u201d Pers Comput., Lecture Notes in computer Science, vol. 3001, pp. 1\u201317, 2004.\n[11] U. Maurer, A. Rowe, A. Smailagic, and D. Siewiorek,\n\u201cLocation and activity recognition using eWatch: A wearable sensor platform,\u201d Ambient Intell. Everday Life, Lecture Notes in Computer Science, vol. 3864, pp. 86\u2013102, 2006.\n[12] J. Parkka, M. Ermes, P. Korpipaa, J. Mantyjarvi, J.\nPeltola, and I. Korhonen, \u201cActivity classification using realistic data from wearable sensors,\u201d IEEE Trans. Inf. Technol. Biomed., vol. 10, no. 1, pp. 119\u2013128, Jan. 2006.\n[13] N.Wang, E. Ambikairajah,N.H. Lovell, and B.G. Celler,\n\u201cAccelerometry based classification of walking patterns using time-frequency analysis,\u201d in Proc. 29th Annu. Conf. IEEE Eng. Med. Biol. Soc., Lyon, France, 2007, pp. 4899\u20134902.\n[14] Y. Tao, H. Hu, H. Zhou, Integration of vision and\ninertial sensors for 3D arm motion tracking in homebased rehabilitation, Int. J. Robotics Res. 26 (6) (2007) 607\u2013624.\n[15] Preece S J, Goulermas J Y, Kenney L P J and Howard D\n2008b A comparison of feature extraction methods for the classification of dynamic activities from accelerometer data IEEE Trans. Biomed. Eng. at press\n[16] E. K. Antonsson and R. W. Mann, \u201cThe frequency\ncontent of gait,\u201d J. Biomech., vol. 18, no. 1, pp. 39\u2013\n47, 1985\n[17] Settles, B. (2010). \u201cActive learning literature survey.\u201d\nComputer Sciences Technical Report 1648, University of Wisconsin-Madison.\n[18] K. Lang and E. Baum. Query learning can work poorly\nwhen a human oracle is used. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 335\u2013340. IEEE Press, 1992.\n[19] X. Zhu. Semi-Supervised Learning with Graphs. PhD\nthesis, Carnegie Mellon University, 2005a.\n[20] B. Settles, M. Craven, and L. Friedland. Active learning\nwith real annotation costs. In Proceedings of the NIPS Workshop on Cost-Sensitive Learning, pages 1\u201310, 2008a.\n[21] Available at\nhttp://en.wikipedia.org/wiki/Artificial_neural_network\n[22] S. Canu and Y. Grandvalet and V. Guigue and A.\nRakotomamonjy \"SVM and Kernel Methods Matlab Toolbox \", Perception Syst\u00e8mes et Information, INSA de Rouen, Rouen, France, 2005"}], "references": [{"title": "New Perspectives on Ubiquitous Computing from Ethnographic Study of Elders with Cognitive Decline", "author": ["M. Morris", "J. Lundell", "E. Dishman", "B. Needham"], "venue": "Proc. Ubicomp", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Aging and Performance of Home Tasks", "author": ["M.P. Lawton"], "venue": "Human Factors", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "Technology for Care Networks of Elders", "author": ["S. Consolvo", "P. Roessler", "B. Shelton", "A. LaMarcha", "B. Schilit", "S. Bly"], "venue": "Proc. IEEE Pervasive Computing Mobile and Ubiquitous Systems: Successful Aging", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Activity and location recognition using wearable sensors", "author": ["S.W Lee", "K. Mase"], "venue": "IEEE Pervasive Computing,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2002}, {"title": "Dealing with sensor displacement in motion-based on body activity recognition systems", "author": ["K. Kunze", "P. Lukowicz"], "venue": "Proc. 10th Int. Conf. on Ubiquitous computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Visionbased human tracking and activity recognition", "author": ["R. Bodor", "B. Jackson", "N. Papanikolopoulos"], "venue": "In Proc. of the 11th Mediterranean Conf. on Control and Automation,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2003}, {"title": "Activity recognition from userannotated acceleration data", "author": ["L. Bao", "S.S. Intille"], "venue": "Pers Comput., Lecture Notes in computer Science, vol. 3001, pp. 1\u201317, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Location and activity recognition using eWatch: A wearable sensor platform", "author": ["U. Maurer", "A. Rowe", "A. Smailagic", "D. Siewiorek"], "venue": "Ambient Intell. Everday Life, Lecture Notes in Computer Science, vol. 3864, pp. 86\u2013102, 2006.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Activity classification using realistic data from wearable sensors", "author": ["J. Parkka", "M. Ermes", "P. Korpipaa", "J. Mantyjarvi", "J. Peltola", "I. Korhonen"], "venue": "IEEE Trans. Inf. Technol. Biomed., vol. 10, no. 1, pp. 119\u2013128, Jan. 2006.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Accelerometry based classification of walking patterns using time-frequency analysis", "author": ["N.Wang", "E. Ambikairajah", "N.H. Lovell", "B.G. Celler"], "venue": "Proc. 29th Annu. Conf. IEEE Eng. Med. Biol. Soc., Lyon, France, 2007, pp. 4899\u20134902.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Integration of vision and inertial sensors for 3D arm motion tracking in homebased rehabilitation", "author": ["Y. Tao", "H. Hu", "H. Zhou"], "venue": "Int. J. Robotics Res", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "2008b A comparison of feature extraction methods for the classification of dynamic activities from accelerometer data", "author": ["J Preece S", "Y Goulermas J", "J Kenney L P", "D Howard"], "venue": "IEEE Trans. Biomed. Eng", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "The frequency content of gait", "author": ["E.K. Antonsson", "R.W. Mann"], "venue": "J. Biomech., vol. 18, no. 1, pp. 39\u2013 47, 1985", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1985}, {"title": "Active learning literature survey.", "author": ["B. Settles"], "venue": "Computer Sciences Technical Report 1648,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Query learning can work poorly when a human oracle is used", "author": ["K. Lang", "E. Baum"], "venue": "In Proceedings of the IEEE International Joint Conference on Neural Networks,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1992}, {"title": "Semi-Supervised Learning with Graphs", "author": ["X. Zhu"], "venue": "PhD thesis,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Active learning with real annotation costs", "author": ["B. Settles", "M. Craven", "L. Friedland"], "venue": "In Proceedings of the NIPS Workshop on Cost-Sensitive Learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "SVM and Kernel Methods Matlab Toolbox", "author": ["S. Canu", "Y. Grandvalet", "V. Guigue", "A. Rakotomamonjy"], "venue": "Perception Syste\u0300mes et Information, INSA de Rouen, Rouen, France,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "[1,2,3].", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "[1,2,3].", "startOffset": 0, "endOffset": 7}, {"referenceID": 2, "context": "[1,2,3].", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "Research has shown that gyroscope can help activity recognition even though its contribution alone is not as good as accelerometer [6,7].", "startOffset": 131, "endOffset": 136}, {"referenceID": 4, "context": "Research has shown that gyroscope can help activity recognition even though its contribution alone is not as good as accelerometer [6,7].", "startOffset": 131, "endOffset": 136}, {"referenceID": 5, "context": "One or multiple cameras have been used to capture and identify body posture [8, 9].", "startOffset": 76, "endOffset": 82}, {"referenceID": 6, "context": "Multiple accelerometers and gyroscopes attached to different body positions are the most common solutions [10-13].", "startOffset": 106, "endOffset": 113}, {"referenceID": 7, "context": "Multiple accelerometers and gyroscopes attached to different body positions are the most common solutions [10-13].", "startOffset": 106, "endOffset": 113}, {"referenceID": 8, "context": "Multiple accelerometers and gyroscopes attached to different body positions are the most common solutions [10-13].", "startOffset": 106, "endOffset": 113}, {"referenceID": 9, "context": "Multiple accelerometers and gyroscopes attached to different body positions are the most common solutions [10-13].", "startOffset": 106, "endOffset": 113}, {"referenceID": 10, "context": "inertial sensors have also been purposed [14].", "startOffset": 41, "endOffset": 45}, {"referenceID": 11, "context": "Some previous works are focused on generating the most useful features from the time series data set [15].", "startOffset": 101, "endOffset": 105}, {"referenceID": 14, "context": "Some applications include speech recognition, information extraction, and handwritten character recognition [18,19,20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 15, "context": "Some applications include speech recognition, information extraction, and handwritten character recognition [18,19,20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 16, "context": "Some applications include speech recognition, information extraction, and handwritten character recognition [18,19,20].", "startOffset": 108, "endOffset": 118}, {"referenceID": 12, "context": "According to a previous study, body movements are constrained within frequency components below 20Hz, and 99% of the energy is contained below 15 Hz [16].", "startOffset": 149, "endOffset": 153}, {"referenceID": 13, "context": "The core idea of active learning is that a machine learning technique can achieve higher accuracy using fewer training labels if it selects the data from which it learns [17] The learning process involves interaction with an oracle who labels unlabeled data samples through guided queries made by the learner as illustrated in Fig.", "startOffset": 170, "endOffset": 174}, {"referenceID": 13, "context": "The active learning cycle (from [17])", "startOffset": 32, "endOffset": 36}], "year": 2011, "abstractText": "Human activity recognition has wide applications in medical research and human survey system. In this project, we design a robust activity recognition system based on a smartphone. The system uses a 3-dimentional smartphone accelerometer as the only sensor to collect time series signals, from which 31 features are generated in both time and frequency domain. Activities are classified using 4 different passive learning methods, i.e., quadratic classifier, k-nearest neighbor algorithm, support vector machine, and artificial neural networks. Dimensionality reduction is performed through both feature extraction and subset selection. Besides passive learning, we also apply active learning algorithms to reduce data labeling expense. Experiment results show that the classification rate of passive learning reaches 84.4% and it is robust to common positions and poses of cellphone. The results of active learning on real data demonstrate a reduction of labeling labor to achieve comparable performance with passive learning.", "creator": "Microsoft\u00ae Word 2010"}}}