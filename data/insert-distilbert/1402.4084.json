{"id": "1402.4084", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2014", "title": "Selective Sampling with Drift", "abstract": "recently there has been much work on selective sampling, an online active random learning setting, in which algorithms work in rounds. on each round an algorithm receives an independent input and makes a prediction. then, it can decide whether to query a label, and if so to update its model, otherwise the input is discarded. most of this work is focused on the stationary case, where it is assumed that there is a fixed target model, and the performance estimates of the algorithm is compared to a fixed model. however, in many real - world applications, such as spam prediction, the best target function may reach drift once over time, or have slight shifts from time to time. we develop a novel selective sampling algorithm for the drifting reference setting, analyze it under no assumptions on the mechanism generating the sequence of instances, and derive new mistake bounds that depend on the amount of drift in the problem. simulations occurring on synthetic and real - world datasets also demonstrate also the superiority of our algorithms as a selective sampling algorithm in the drifting setting.", "histories": [["v1", "Mon, 17 Feb 2014 17:53:57 GMT  (296kb,D)", "http://arxiv.org/abs/1402.4084v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["edward moroshko", "koby crammer"], "accepted": false, "id": "1402.4084"}, "pdf": {"name": "1402.4084.pdf", "metadata": {"source": "CRF", "title": "Selective Sampling with Drift", "authors": ["Edward Moroshko", "Koby Crammer"], "emails": ["edward.moroshko@gmail.com", "koby@ee.technion.ac.il"], "sections": [{"heading": null, "text": "Recently there has been much work on selective sampling, an online active learning setting, in which algorithms work in rounds. On each round an algorithm receives an input and makes a prediction. Then, it can decide whether to query a label, and if so to update its model, otherwise the input is discarded. Most of this work is focused on the stationary case, where it is assumed that there is a fixed target model, and the performance of the algorithm is compared to a fixed model. However, in many real-world applications, such as spam prediction, the best target function may drift over time, or have shifts from time to time. We develop a novel selective sampling algorithm for the drifting setting, analyze it under no assumptions on the mechanism generating the sequence of instances, and derive new mistake bounds that depend on the amount of drift in the problem. Simulations on synthetic and real-world datasets demonstrate the superiority of our algorithms as a selective sampling algorithm in the drifting setting."}, {"heading": "1 Introduction", "text": "We consider the online binary classification task, in which a learning algorithm predicts a binary label given inputs in a sequence of rounds. An example of such task is classification of emails based on their content as spam or not spam. Traditionally, the purpose of a learning algorithm is to make the number of mistakes as small as possible compared to predictions of some single function from some class. We call this setting the stationary setting.\nFollowing the pioneering work of Rosenblatt [18] many al-\nAppearing in Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS) 2014, Reykjavik, Iceland. JMLR: W&CP volume 33. Copyright 2014 by the authors.\ngorithms were proposed for this setting. Some of them are able to employ second-order information. For example, the second-order perceptron algorithm [5] extends the original perceptron algorithm and uses the spectral properties of the data to improve performance. Another example is the AROW algorithm [8] which uses confidence as a secondorder information. All these second-order algorithms can be seen as RLS (Regularized Least Squares) based, as their update equations are similar to those of RLS, updating a weight vector and a covariance-like matrix. Under the stationary setting, RLS-based second-order algorithms have been successfully applied to the regression and classification tasks, as shown in Table 1.\nDespite the extensive and impressive guarantees that can be made for algorithms in such setting [5, 8], competing with the best fixed function is not always good enough. In many real-world applications, the true target function is not fixed, but is slowly changing over time, or switching from time to time. These reasons led to the development of algorithms and accompanying analysis for drifting and shifting settings, which we collectively call the non-stationary setting. For online regression, few algorithms were developed for this setting [13, 22, 16]. Yet, for online classification, the Shifting Perceptron algorithm [4] is a first-order algorithm that shrinks the weight vector each iteration, and in this way weaken dependence on the past. The Modified Perceptron algorithm [3] is another first-order algorithm that had been shown to work well in the drifting setting [9]. In this paper we derive a new RLS-based second-order algorithm for classification, designed to work with target drift, and thus we fill the missing configuration in Table 1. Our algorithm extends the second-order perceptron algorithm [5], and we provide a performance bound in the mistake bound model.\nA practical variant of the fully supervised online classification setting, is where, at each prediction step, the learner can abstain from observing the current label. This setting is called selective sampling [12]. In this setting a learning algorithm actively decides when to query for a label. If the label is queried, then the label value can be used to improve future predictions, and otherwise the algorithm never knows whether his prediction was correct. Roughly\nar X\niv :1\n40 2.\n40 84\nv1 [\ncs .L\nG ]\n1 7\nFe b\n20 14\nspeaking, selective sampling algorithms can be divided in two groups. In the first group, a simple randomized rule is used to turn fully supervised algorithm to selective sampling algorithm. The rule uses the margin of the estimate. This group includes the selective sampling versions of the perceptron and the second-order perceptron algorithms [7]. In the second group, selective sampling algorithms are derived based on comparing the variance of the RLS estimate to some threshold. This group includes the BBQ algorithm [6], where the threshold decays polynomially with t as t\u2212\u03ba, and more involved variants where the threshold depends on the margin of the RLS estimate [10, 17].\nIn all previous work on selective sampling the performance of an algorithm is compared to the performance of a single linear comparator. To the best of our knowledge, our work is the first instance of learning online in the context of drifting in the selective sampling setting. We build on the work of Cesa-Bianchi et al [7] that combined a randomized rule into the Perceptron algorithm, yielding a selective sampling algorithm. We analyze the resulting algorithm in the drifting setting, and derive a bound on the expected number of mistakes of the algorithm. Thus, we fill the non-stationary cell in Table 2. Simulations on synthetic and real-world datasets show the advantages of our algorithm, in a fully supervised and selective sampling settings."}, {"heading": "2 Problem setting", "text": "We consider the standard online learning model [1, 15] for binary classification, in which learning proceeds in a sequence of rounds t = 1, 2, . . . , T . In round t the algorithm observes an instance xt \u2208 Rd and outputs a prediction y\u0302t \u2208 {\u22121,+1} for the label yt associated with xt. We say that the algorithm has made a prediction mistake if y\u0302t 6= yt, and denote by Mt the indicator function of the event y\u0302t 6= yt. After observing the correct label yt the algorithm may update its prediction rule, and then proceeds to the next round. We denote by m the total number of mistakes over a sequence of T examples.\nThe performance of an algorithm is measured by the total number of mistakes it makes on an arbitrary sequence of examples. In the standard performance model, the goal is to bound this total number of mistakes in terms of the performance of the best fixed linear classifier u \u2208 Rd in hindsight. Since finding u \u2208 Rd that minimizes the number of mistakes on a known sequence is a computationally hard problem, the performance of the best predictor in hindsight is often measured using the cumulative hinge loss L\u03b3,T (u) =\u2211T t=1 `\u03b3,t (u), where `\u03b3,t (u) = max { 0, \u03b3 \u2212 ytu>xt } is\nthe hinge loss of the competitor u on round t for some margin threshold \u03b3 > 0.\nIn the drifting setting that we consider in this work, the learning algorithm faces the harder goal of bounding its total number of mistakes in terms of the cumulative hinge loss achieved by an arbitrary sequence u1, u2, . . . , uT \u2208 Rd of comparison vectors. The cumulative hinge loss of such sequence is L\u03b3,T ({ut}) = \u2211T t=1 `\u03b3,t (ut). To make this goal feasible, the bound is allowed to scale also with the norm of u1 and the total amount of drift defined to be V = V ({ut}) = \u2211T t=2 \u2016ut \u2212 ut\u22121\u2016 2.\nWe consider two settings: (a) standard supervised online binary classification (described above), and (b) selective sampling. In the later setting, after each prediction the learner may observe the correct label yt only by issuing a query. If no query is issued at time t, then yt remains unknown. We represent the algorithm\u2019s decision of querying the label at time t through the value of a Bernoulli random variable Zt, and the event of a mistake with the indicator variable Mt = 1. Note that we measure the performance of the algorithm by the total number of mistakes it makes on a sequence of examples, including the rounds where the true label yt remains unknown.\nFinally, L\u0304\u03b3,T ({ut}) = E [\u2211T t=1MtZt`\u03b3,t (ut) ]\nis the expected total hinge loss of a competitor on mistaken and queried rounds, and trivially L\u0304\u03b3,T ({ut}) \u2264 L\u03b3,T ({ut})."}, {"heading": "3 Algorithms", "text": "Online algorithms work in rounds. On round t the algorithm receives an input xt and makes a prediction. We follow Moroshko and Crammer [16] and design the prediction as a last-step min-max problem in the context of drifting. Yet, unlike all previous work, we design algorithms for classification. Specifically, prediction is the solution of the following optimization problem,\ny\u0302T = arg min y\u0302T\u2208{\u22121,+1} max yT\u2208{\u22121,+1} [ T\u2211 t=1 (yt \u2212 y\u0302t)2\n\u2212 min u1,...,uT QT (u1, . . . , uT )\n] , (1)\nwhere\nQt (u1, . . . , ut) =b \u2016u1\u20162 + c t\u22121\u2211 s=1 \u2016us+1 \u2212 us\u20162\n+ t\u2211 s=1 ( ys \u2212 u>s xs )2\nfor some positive constants b, c1.\nThis optimization problem can also be seen as a game where the algorithm chooses a prediction label y\u0302t \u2208 {\u22121,+1} to minimize the last-step regret, while an adversary chooses a target label yt \u2208 {\u22121,+1} to maximize it. The first term of (1) is the loss suffered by the algorithm while Qt (u1, . . . , ut) is a sum of the loss suffered by some sequence of linear functions {us}ts=1, a penalty for consecutive pairs that are far from each other, and for the norm of the first to be far from zero.\nThe following lemma enables to solve (1) by specifying means to solve the inner optimization problem in (1).\nLemma 1 ([16], Lemma 2). Denote Pt (ut) = minu1,...,ut\u22121 Qt (u1, . . . , ut). Then Pt (ut) = u > t Dtut \u2212 2u>t et + ft where,\nD1 = bI + x1x > 1 Dt = ( D\u22121t\u22121 + c \u22121I )\u22121 + xtx > t (2)\ne1 = y1x1 et = ( I+c\u22121Dt\u22121 )\u22121 et\u22121+ytxt (3)\nf1 = y 2 1 ft=ft\u22121 \u2212 e>t\u22121 (cI+Dt\u22121) \u22121 et\u22121+y 2 t ,\nwhere,Dt \u2208 Rd\u00d7d is a PSD matrix, et \u2208 Rd\u00d71 and ft \u2208 R.\nFrom the lemma we solve, minu1,...,ut Qt (u1, . . . , ut), by,\nmin u1,...,ut Qt (u1, . . . , ut) = min ut Pt(ut) = \u2212e>t D\u22121t et+ft . (4) Next, we substitute the value of eT from (3) (as a function of yT ) in (4), and then substitute (4) in (1). Omitting terms not depending explicitly on yT and y\u0302T we get from (1) that,\ny\u0302T = arg min y\u0302T\u2208{\u22121,+1} max yT\u2208{\u22121,+1}\n[ ( x>TD \u22121 T xT ) y2T\n+ 2yT ( x>TD \u22121 T ( I + c\u22121DT\u22121 )\u22121 eT\u22121 \u2212 y\u0302T ) + y\u03022T\n]\n= arg min y\u0302T\u2208{\u22121,+1}\n[ x>TD \u22121 T xT\n+ 2 \u2223\u2223\u2223x>TD\u22121T (I + c\u22121DT\u22121)\u22121 eT\u22121 \u2212 y\u0302T \u2223\u2223\u2223+ y\u03022T ] = sign(p\u0302t)|t=T ,\nwhere\np\u0302t = x > t D \u22121 t ( I + c\u22121Dt\u22121 )\u22121 et\u22121 . (5)\nTo the best of our knowledge, this is the first application of the last-step min-max approach directly for classification, and not as a reduction from regression, which is possible by employing the square loss, as in least-squares\n1We still use the squared loss in (1), as done for least-squares SVMs [21, 20], which allows us to compute all quantities analytically.\nSVMs [21, 20]. Indeed, we showed that the optimal prediction for classification is the sign of the optimal prediction for regression [16].\nOur algorithm includes the second-order perceptron [5] algorithm as a special case when c = \u221e. The second-order perceptron algorithm is indeed using the sign of the optimal min-max prediction for regression [11], which is in fact the prediction of the AAR algorithm [23] (aka \u201dforward algorithm\u201d [2]). Additionally, similar to other algorithms [18, 5], we update the algorithm only on mistaken rounds. We call the algorithm LASEC for last-step adaptive classifier. LASEC is a special case of Fig. 1 when setting a =\u221e (see below). Note that in the pseudocode two indices are used, the current time t and the number of examples used to update the model k. This makes the presentation simpler as some examples are not used to update the model, the ones for which there was no classification mistake. Note, the update equations of Fig. 1 are essentially (2) and (3). The LASEC algorithm can be seen as an extension to the non-stationary setting of the second-order perceptron algorithm [5]. Indeed, for c = \u221e the LASEC algorithm is reduced to the second-order perceptron algorithm.\nNext, we turn LASEC from an algorithm that uses the labels of all inputs to one that queries labels stochastically. Specifically, the algorithm uses the margin |p\u0302t| defined in (5) to randomly choose whether to make a prediction. We interpret large values of the margin |p\u0302t| as being confident in the prediction, which should reduce the probability of querying the label. Specifically, the algorithm is querying a label with probability a/(a + |p\u0302t|) for some a > 0. If a \u2192 \u221e the algorithm will always query, and reduce to LASEC, while if a\u2192 0 it will never query.\nThis approach for deriving selective-algorithms from margin-based online algorithms is not new, and was used to design an algorithm for the non-drifting case [7]. Yet, unlike other selective sampling algorithms [7, 6, 10, 17], our algorithm is designed to work in the drifting setting. Since the algorithm is based on the LASEC algorithm, we call it LASEC-SS, where SS stands for selective sampling. The algorithm is summarized in Fig. 1 as well. Note that LASEC-SS includes other algorithms as special cases. Specifically, LASEC-SS is reduced for c =\u221e to the selective sampling version of the second-order perceptron algorithm [7], and as mentioned above, for a =\u221e it is reduced to LASEC, and the setting of both c = \u221e, a = \u221e reduces the algorithm to the second-order perceptron, which in turn reduces to the perceptron algorithm for b\u2192\u221e.\nThe algorithm is flexible enough to be tuned both to drifting or non-drifting setting (using c), between selective sampling or supervised learning (using a), and between firstorder or second-order modeling (using b).\nOur algorithm can be combined with Mercer kernels as it employs only sums of inner- and outer-products of the in-\nParameters: 0 < b < c , 0 < a Initialize: Set D0 = (bc)/(c \u2212 b) I \u2208 Rd\u00d7d , e0 = 0 \u2208 Rd and k = 1 For t = 1, . . . , T do \u2022 Receive an instance xt \u2208 Rd \u2022 Set\n( )\u22121\nputs. This allows it to build non-linear models (e.g. [19])."}, {"heading": "4 Analysis", "text": "We now prove bounds for the number of mistakes of our algorithm. We provide a mistake bound for the fully supervised version (LASEC) and for the selective sampling version (LASEC-SS). Our bounds depend on the total drift of the reference sequence Vm = \u2211m k=2 \u2016uk \u2212 uk\u22121\u2016\n2 which is calculated on rounds when the algorithm makes updates. We denote byM \u2286 {1, 2, . . .} the set of indices when the algorithm updates. For the supervised setting it is the set of mistaken trials (Mt = 1). For the selective sampling setting it is the set of indices when Zt = 1 and Mt = 1.\nTheorem 2. Assume the LASEC algorithm (of Fig. 1 with a = \u221e) is run on a finite sequence of examples. Then for any reference sequence {ut} and \u03b3 > 0 the number m = |M| of mistakes satisfies\nm \u2264 1 \u03b3 L\u03b3,T ({ut})\n+ 1\n\u03b3 \u221a\u221a\u221a\u221a(b \u2016u1\u20162 + cVm + m\u2211 k=1 ( u>k xk )2)\u2211 t\u2208M x>t D \u22121 k xt\n(6)\nRemark 3. For the stationary case, when uk = u \u2200k (Vm = 0) and we set c = \u221e for the LASEC algorithm we recover the second-order perceptron bound [5].\nTheorem 4. Assume the LASEC-SS algorithm of Fig. 1 is run on a sequence of T examples with parameter a > 0. Then for any reference sequence {ut} and \u03b3 > 0 the expected number of mistakes satisfies\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut})\n+ a\n2\u03b32\n( b \u2016u1\u20162 + cVm + E [ T\u2211 t=1 MtZt ( u>t xt )2])\n+ 1\n2a E [ T\u2211 t=1 MtZtx > t D \u22121 t xt ] . (7)\nMoreover, the expected number of labels queried by the algorithm equals \u2211T t=1 E [ a\na+|p\u0302t|\n] .\nRemark 5. As in other context [7]: Thm. 2 is not a special case of Thm. 4. Indeed, setting a = \u221e makes the bound of Thm. 4 unbounded, as opposed to Thm. 2. Also, from the last part of Thm. 4 we observe that more labels would be queried for larger values of a. However, the tradeoff between number of queries and mistakes is not clear. Remark 6. For the stationary case, when uk = u \u2200k (Vm = 0) and we set c = \u221e for the LASEC-SS algorithm we recover the bound of the selective sampling version of the second-order perceptron algorithm [7].\nThe bound (7) depends on the parameter a. If we would know the future, by setting,\na = \u03b3 \u221a\u221a\u221a\u221a\u221a E [\u2211T t=1MtZtx > t D \u22121 t xt ] b \u2016u1\u20162 + cVm + E [\u2211T t=1MtZt ( u>t xt\n)2] we would minimize the bound and get\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut})\n+ 1\n\u03b3 \u221a\u221a\u221a\u221a\u221a\u221a\u221a\u221a\u221a\u221a ( b \u2016u1\u20162 + cVm + E [ T\u2211 t=1 MtZt ( u>t xt )2])\n\u00d7 ( E [ T\u2211 t=1 MtZtx > t D \u22121 t xt ]) .\nThe last bound is an expectation version of the mistake bound for the (deterministic) LASEC algorithm of Thm. 2, and it might be even sharper than the LASEC bound, since the magnitude of the three quantities L\u0304\u03b3,T ({ut}), E [\u2211T t=1MtZt ( u>t xt )2] and E [\u2211T t=1MtZtx > t D \u22121 t xt\n] is ruled by the size of the random set of updates {t : ZtMt = 1}, which is typically smaller than the set of mistaken trials of the deterministic algorithm.\nWe now prove the bounds in Thm. 2 and Thm. 4, in the following unified proof.\nProof. Consider only the rounds t when the algorithm makes an update, that is t \u2208 M. Noting that our choice p\u0302t = x > t S \u22121 t ( I + c\u22121Dk\u22121 )\u22121 ek\u22121 (in Fig. 1) is the same as the prediction of the LASER algorithm for regression with drift, we can use the result proven by Moroshko and Crammer [16] (Theorem 4 therein), from where we have that for any sequence u1, . . . , um\u2211 t\u2208M (p\u0302t \u2212 yt)2 \u2264b \u2016u1\u20162 + c m\u2211 k=2 \u2016uk \u2212 uk\u22121\u20162\n+ m\u2211 k=1 ( yk \u2212 u>k xk )2 + \u2211 t\u2208M x>t D \u22121 k xt . (8)\nNote that in (8) the sums are over rounds when the algorithm makes an update (for simplicity, we write yk as shorthand for ytk where tk \u2208M). Expanding the squares in (8), lower bound p\u03022t \u2265 0 and substituting ytp\u0302t = \u2212 |p\u0302t| when t \u2208M we obtain\u2211\nt\u2208M |p\u0302t| \u2264\nb 2 \u2016u1\u20162 + c 2 Vm \u2212 m\u2211 k=1 yku > k xk\n+ 1\n2 m\u2211 k=1 ( u>k xk )2 + 1 2 \u2211 t\u2208M x>t D \u22121 k xt .\nThe last bound is correct for any sequence uk. We replace uk with a\u03b3uk (for some a > 0) and get\u2211 t\u2208M |p\u0302t| \u2264b a2 2\u03b32 \u2016u1\u20162 + c a2 2\u03b32 Vm \u2212 a \u03b3 m\u2211 k=1 yku > k xk\n+ a2\n2\u03b32 m\u2211 k=1 ( u>k xk )2 + 1 2 \u2211 t\u2208M x>t D \u22121 k xt .\nUsing \u03b3\u2212`\u03b3,t (ut) \u2264 ytu>t xt, which follows the definition of the hinge loss, we get\u2211 t\u2208M (|p\u0302t|+ a) \u2264 a \u03b3 \u2211 t\u2208M `\u03b3,t (ut) + 1 2 \u2211 t\u2208M x>t D \u22121 k xt\n+ a2\n2\u03b32\n( b \u2016u1\u20162 + cVm +\nm\u2211 k=1 ( u>k xk\n)2) . (9)\nNext, to prove the bound for the LASEC algorithm in Thm. 2, we further bound |p\u0302t| \u2265 0 in (9) and then divide it by a. We obtain\nm \u2264 1 \u03b3 \u2211 t\u2208M `\u03b3,t (ut) + 1 2a \u2211 t\u2208M x>t D \u22121 k xt\n+ a\n2\u03b32\n( b \u2016u1\u20162 + cVm +\nm\u2211 k=1 ( u>k xk\n)2) .\nThe last bound is minimized by setting\na = \u03b3 \u221a\u221a\u221a\u221a \u2211t\u2208M x>t D\u22121k xt b \u2016u1\u20162 + cVm + \u2211m k=1 ( u>k xk )2 ,\nand by using \u2211 t\u2208M `\u03b3,t (ut) \u2264 L\u03b3,T ({ut}) we get the desired bound of Thm. 2,\nm \u2264 1 \u03b3 L\u03b3,T ({ut})\n+ 1\n\u03b3 \u221a\u221a\u221a\u221a(b \u2016u1\u20162 + cVm + m\u2211 k=1 ( u>k xk )2)\u2211 t\u2208M x>t D \u22121 k xt .\nTo prove the mistake bound for the LASEC-SS algorithm in Thm. 4, we note that the sum \u2211 t\u2208M (|p\u0302t|+ a) on the LHS\nof (9) can be written as \u2211 tMtZt (|p\u0302t|+ a). Taking expectation on both sides of (9) and using EZt = a/ (a+ |p\u0302t|) we bound the expected number of mistakes of the algorithm,\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut})\n+ a\n2\u03b32\n( b \u2016u1\u20162 + cVm + E [ T\u2211 t=1 MtZt ( u>t xt )2])\n+ 1\n2a E [ T\u2211 t=1 MtZtx > t D \u22121 t xt ] .\nThe value of the expected number of queried labels trivially follows, E [\u2211T t=1 Zt ] = \u2211T t=1 E [ a\na+|p\u0302t|\n] .\nNext, we further bound the term \u2211 t\u2208M x > t D \u22121 k xt in Thm. 2. Using Lemma 5 and Lemma 7 of Moroshko and Crammer [16] we have\u2211\nt\u2208M x>t D \u22121 k xt \u2264 ln\n\u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ c\u22121 m\u2211\nk=1\nTr (Dk\u22121)\n\u2264 ln \u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ c\u22121Tr (D0) + m\nc dmax\n{ 3X2 + \u221a X4 + 4X2c\n2 , b+X2\n} , (10)\nwhere \u2016xt\u20162 \u2264 X2. Substituting (10) in (6) we get a bound of the form m \u2264 1\u03b3D + 1 \u03b3 \u221a A (B +mC) for the LASEC algorithm, solved for m with the following technical lemma.\nLemma 7. Let A,B,C,D, \u03b3,m > 0 satisfy m \u2264 1\u03b3D + 1 \u03b3 \u221a A (B +mC). Then\nm \u2264 1 \u03b3 D + 1 2\u03b32 AC\n+ 1\n\u03b3\n\u221a 1\n\u03b3 DAC +\n1\n4\u03b32 (AC)\n2 +AB . (11)\nThe proof appears in the supplementary material. Using Lem. 7 we have the bound (11) for the LASEC algorithm,\nwhere\nA = b \u2016u1\u20162 + cVm + m\u2211 k=1 ( u>k xk )2 ,\nB = ln \u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ c\u22121Tr (D0) ,\nC = c\u22121dmax {( 3X2 + \u221a X4 + 4X2c ) /2, b+X2 } ,\nD = L\u03b3,T ({ut}) .\nNext, we use corollary 8 from Moroshko and Crammer [16] to get the final bound for LASEC. Corollary 8. Assume \u2016xt\u20162 \u2264 X2 and set b = \u03b5c for\nsome 0 < \u03b5 < 1. Denote \u00b5 = max { 9/8X2, (b+X2) 2\n8X2\n} .\nAssume the LASEC algorithm is run on T examples. If Vm \u2264 T \u221a 2dX \u00b53/2 then by setting c = (\u221a 2TdX Vm )2/3 we have the bound (11) for the number of mistakes of the LASEC algorithm, where\nD = L\u03b3,T ({ut}) , A = b \u2016u1\u20162 + (\u221a 2dX )2/3 T 2/3V 1/3m + m\u2211 k=1 ( u>k xk )2 ,\nB = ln \u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ \u03b51\u2212 \u03b5d,\nC = (4dX) 2/3 T\u22121/3V 1/3m .\nProof. As was shown [16] we have\nmax\n{ 3X2 + \u221a X4 + 4X2c\n2 , b+X2\n} = 2X \u221a 2c ,\nand thus A = b \u2016u1\u20162 + cVm + m\u2211 k=1 ( u>k xk )2 = b \u2016u1\u20162 + (\u221a 2dX )2/3 T 2/3V 1/3m +\nm\u2211 k=1 ( u>k xk )2 ,\nB = ln \u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ c\u22121Tr (D0) = ln \u2223\u2223\u2223\u22231bDm \u2223\u2223\u2223\u2223+ \u03b51\u2212 \u03b5d , C = 2 \u221a\n2dX\u221a c\n= 2 \u221a\n2dX(\u221a 2TdX Vm )1/3 = (4dX)2/3 T\u22121/3V 1/3m .\nThe last bound for the LASEC algorithm is difficult to interpret. Roughly speaking, the number of mistakes grows with the amount of drift as \u223cT 1/3V 2/3m , because A\u223cT 2/3V 1/3m ,C\u223cT\u22121/3V 1/3m and the bound is\u223cAC. Another bound for the drifting setting was shown by Cavallanti et al for the Shifting Perceptron [4]. However, they\nused other notation of drift, which uses the norm rather than the square norm of the difference of comparison vectors, as we do. Thus, the two bounds are not comparable in general.\nNext, we move to get explicit mistake bound for the LASEC-SS algorithm, by bounding the right term in Thm. 4. Again, using Lemma 5 and Lemma 7 from [16] we get, T\u2211 t=1 MtZtx > t D \u22121 t xt \u2264 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ c\u22121 T\u2211 t=1 Tr (Dt\u22121)\n\u2264 ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ c\u22121Tr (D0) + Tc\u22121dmax {( 3X2 + \u221a X4 + 4X2c ) /2, b+X2 } .\nCombining this bound with Thm. 4 we get,\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut})\n+ a\n2\u03b32\n( b \u2016u1\u20162 + cVm + E [ T\u2211 t=1 MtZt ( u>t xt )2])\n+ 1\n2a\n( E ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ c\u22121Tr (D0)\n+ Tc\u22121dmax {( 3X2 + \u221a X4 + 4X2c ) /2, b+X2 }) .\nWe now state the main result of this section, bounding the expect number of mistakes of the LASEC-SS algorithm. This is an immediate application of corollary 8 from [16]. Corollary 9. Assume \u2016xt\u20162 \u2264 X2 and set b = \u03b5c for\nsome 0 < \u03b5 < 1. Denote \u00b5 = max { 9/8X2, (b+X2) 2\n8X2\n} .\nAssume the LASEC-SS algorithm is run on T examples. If Vm \u2264 T \u221a 2dX \u00b53/2 then by setting c = (\u221a 2TdX Vm )2/3 we get\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut}) + b a 2\u03b32 \u2016u1\u20162\n+ a\n2\u03b32\n(\u221a 2dX )2/3 T 2/3V 1/3m\n+ a\n2\u03b32 E [ T\u2211 t=1 MtZt ( u>t xt )2]\n+ 1\n2a\n( E ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ \u03b51\u2212 \u03b5d+ (4dX)2/3 T 2/3V 1/3m ) .\nAgain, we can optimize the last bound for the algorithm\u2019s parameter a. Setting\na = \u03b3 \u221a\u221a\u221a\u221a\u221a\u221a\u221a\u221a E ln \u2223\u2223 1 bDT \u2223\u2223+ \u03b51\u2212\u03b5d+ (4dX)2/3 T 2/3V 1/3m( b \u2016u1\u20162 + (\u221a 2dX )2/3 T 2/3V 1/3 m\n+E [\u2211T t=1MtZt ( u>t xt )2] )\nwe obtain\nE [ T\u2211 t=1 Mt ] \u2264 1 \u03b3 L\u0304\u03b3,T ({ut})\n+ 1\n\u03b3\n[( b \u2016u1\u20162 + (\u221a 2dX )2/3 T 2/3V 1/3m\n+ E [ T\u2211 t=1 MtZt ( u>t xt )2])(E ln \u2223\u2223\u2223\u22231bDT \u2223\u2223\u2223\u2223+ \u03b51\u2212 \u03b5d\n+ (4dX) 2/3 T 2/3V 1/3m\n)]1/2 ."}, {"heading": "5 Experimental Study", "text": "We evaluated our algorithm with both synthetic and realworld data with shifts, by comparing the average accuracy (total number of correct online classifications divided by the number of examples) of LASEC and LASEC-SS.\nData: In our first experiment we use a synthetic dataset with 10, 000 examples of dimension d = 50. The inputs xt \u2208 R50 were drawn from a zero-mean unit-covariance Gaussian distribution. The target ut \u2208 R50 is a zeromean unit-covariance Gaussian vector, which is switched every 500 examples to some other random vector. That is u1 = ... = u500, u501 = ... = u1000, .... The labels are set according to yt = sign(x>t ut). Our second experiment uses the US Postal Service handwritten digits recognition corpus (USPS) [14]. It contains normalized grey scale images of size 16\u00d716, divided into a training (test) set of 7, 291 (2, 007) images. We combined the sets to get 9, 298 examples. Based on the USPS multiclass data we generated binary data with shifts. We chose at random some digits to be positive class (the other digits are negative class). The partition to positive and negative classes is changed every 500 examples at random, that is every 500 samples we changed the subgroup of labels (out of 10) that are labeled as +1 (labels in the complementary subgroup are labeled as -1). Each set of experiments was repeated 50 times and the error bars in the plots correspond to the 95% confidence interval over the 50 runs.\nSupervised Online Learning with Drift: In the supervised-online classification task we compared the performance of LASEC (setting a =\u221e in Fig. 1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].\nBoth the Shifting Perceptron and the Randomized Budget Perceptron are tuned using a single parameter (denoted by \u03bb and B respectively). Since the optimal values of these\nparameters simply reduced these algorithms to the original Perceptron, we set \u03bb = 0.01 and B = 500 for synthetic data, and \u03bb = 0.0001 and B = 1, 000 for real-world data. The setting of B = 500 is actually the switching window, while for real-world data we alleviated the Randomized Budget Perceptron and used twice the switching window as the budget. For the LASEC and SOP algorithms the parameters were tuned using a random draw of the data.\nThe results comparing supervised classification algorithms on synthetic data are shown in Fig. 2(a). While for t < 500 (before the first shift) the SOP algorithm is the best as expected, we see that the LASEC algorithm deals better with the shifts and outperforms other algorithms. For the realworld USPS dataset (see Fig. 2(d)) LASEC slightly outperforms SOP, and both outperform other perceptron-like algorithms, due to the usage of second-order information.\nSelective Sampling Online Learning with Drift: For the selective sampling task we compared the LASEC-SS algorithm from Fig. 1 to several selective sampling algorithms: the selective sampling version of second-order perceptron algorithm (SOP-SS) [7], the selective sampling version of perceptron algorithm (Perceptron-SS) [7] and the BBQ algorithm [6]. In addition to the BBQ algorithm [6], we also consider a variant of the BBQ algorithm, which we call BBQ-I. This algorithm is similar to the original BBQ algorithm but it performs updates only when the queried label is different from the predicted label. Each algorithm has one parameter that controls the tradeoff between the query rate (fraction of queried labels) and the accuracy of the algorithm. For fairness, this parameter was set to get about the same query rate for all algorithms.\nFig. 2(b) and Fig. 2(e) summarize the accuracy of the algorithms on synthetic data for query rate \u223c0.1 and \u223c0.4. In both cases LASEC-SS outperforms other algorithms. Before the first shift at round 500 the BBQ is the best as expected from previous results [17], but its performance significantly degrade after the first shift. This is because this algorithm performs query when the quantity rt = x>t A \u22121 t xt is large enough (see [6]), while the matrix At grows each time a label is queried. Large At makes rt small, the algorithm converges and stops query labels. If after that a switch occurs, the algorithm fails in predictions but cannot query correct labels because rt is small. This causes a significant degradation in the prediction accuracy. On the other hand, the BBQ-I algorithm performs less updates (as it performs updates only when a mistake occurs), and thus the algorithm converges much slower. This makes it simpler to adapt to changing environment, after a switch occurs. We note that for stationary environment (when ut = u \u2200t), BBQ outperforms BBQ-I, as well as other selective sampling algorithms (see [17]). For low query rate as in Fig. 2(b), all algorithms hardly deal with the shifts, as expected. However, our algorithm still converges on a bet-\nter average accuracy. For higher rate as in Fig. 2(e), our algorithm deals well with the shifts and the average accuracy does not decrease. This is in contrary to other algorithms. For the SOP-SS algorithm we see in Fig. 2(e) that the performance increase over time after an initial drop. This is because the SOP algorithm tends to converge fast and then it acts as no labels are needed, because the margin is large. After a data shift, the algorithm experiences a drop because no labels are sampled. After some time the algorithm detects that labels are needed (because the margin is small) and performance increase.\nFig. 2(c) and Fig. 2(f) show the tradeoff between average accuracy and fraction of queried labels on synthetic and real-world (USPS) data accordingly. Evidently, LASECSS is the best selective sampling algorithm in the drifting setting. In addition, we can see that unlike the stationary setting where it was shown [7] that a small fraction of labels are enough to get the accuracy of a fully supervised setting, in the drifting case much more labels are needed. This is because old queried labels cannot contribute to form a good predictor due to a drift in the model, and the algorithm must query more labels to have a good prediction accuracy. Yet, our algorithm can employ half of the labels to\nget performance not too far from the full information case."}, {"heading": "6 Conclusions", "text": "We proposed a novel second-order algorithm for binary classification designed to work in non-stationary (drifting) selective sampling setting. Our algorithm is based on the last-step min-max approach, and we showed how to solve the last-step min-max optimization problem directly for classification using the square loss. To the best of our knowledge, this is the first algorithm designed to work in the selective sampling setting when there is a drift. We proved mistake bound for the algorithm in the fully supervised setting, and a bound for the expected number of mistakes for the selective sampling version of the algorithm. Experimental study shows that our algorithm outperforms other algorithms, in the supervised and selecting sampling settings. For the algorithm to perform well, the amount of drift V or a bound over it should be known in advance. An interesting direction is to design algorithms that automatically detect the level of drift, or are invariant to it.\nAcknowledgements: This research was funded in part by the Intel Collaborative Research Institute for Computa-\ntional Intelligence (ICRI-CI) and in part by an Israeli Science Foundation grant ISF- 1567/10."}, {"heading": "A SUPPLEMENTARY MATERIAL", "text": "A.1 Proof of Lem. 7\nProof. We follow equivalency of the following inequalities,\nm\u2212 1 \u03b3 D \u2264 1 \u03b3\n\u221a A (B +mC)\nm2 \u2212 2 \u03b3 mD + 1 \u03b32 D2 \u2264 1 \u03b32 A (B +mC)\nm2 \u2212 ( 2\n\u03b3 D +\n1\n\u03b32 AC\n) m+ 1\n\u03b32 D2 \u2212 1 \u03b32 AB \u2264 0\nm \u2264\n( 2\n\u03b3 D +\n1\n\u03b32 AC\n+\n\u221a( 2\n\u03b3 D +\n1\n\u03b32 AC\n)2 \u2212 4 ( 1\n\u03b32 D2 \u2212 1 \u03b32 AB\n)) /2\n= 1\n\u03b3 D +\n1\n2\u03b32 AC\n+ 1\n\u03b3\n\u221a 1\n\u03b3 DAC +\n1\n4\u03b32 (AC)\n2 +AB ."}], "references": [{"title": "Queries and concept learning", "author": ["Dana Angluin"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1987}, {"title": "Relative loss bounds for on-line density estimation with the exponential family of distributions", "author": ["K.S. Azoury", "M.W. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "A polynomial-time algorithm for learning noisy linear threshold functions", "author": ["Avrim Blum", "Alan M. Frieze", "Ravi Kannan", "Santosh Vempala"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1998}, {"title": "Tracking the best hyperplane with a simple budget perceptron", "author": ["Giovanni Cavallanti", "Nicol\u00f2 Cesa-Bianchi", "Claudio Gentile"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "A second-order perceptron algorithm", "author": ["Nicol\u00f3 Cesa-Bianchi", "Alex Conconi", "Claudio Gentile"], "venue": "Siam Journal of Commutation,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Robust bounds for classification via selective sampling", "author": ["Nicol\u00f2 Cesa-Bianchi", "Claudio Gentile", "Francesco Orabona"], "venue": "In ICML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Worst-case analysis of selective sampling for linear classification", "author": ["Nicol\u00f2 Cesa-Bianchi", "Claudio Gentile", "Luca Zaniboni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Adaptive regularization of weighted vectors", "author": ["K. Crammer", "A. Kulesza", "M. Dredze"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Regret minimization with concept drift", "author": ["Koby Crammer", "Yishay Mansour", "Eyal Even-Dar", "Jennifer Wortman Vaughan"], "venue": "In COLT,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Robust selective sampling from single and multiple teachers", "author": ["Ofer Dekel", "Claudio Gentile", "Karthik Sridharan"], "venue": "In COLT,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "On relative loss bounds in generalized linear regression", "author": ["Jurgen Forster"], "venue": "In Fundamentals of Computation Theory (FCT),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1999}, {"title": "Selective sampling using the Query By Committee algorirhm", "author": ["Y. Freund", "H.S. Seung", "E. Shamir", "N. Tishby"], "venue": "Machine Learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Tracking the best linear predictor", "author": ["Mark Herbster", "Manfred K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "A database for handwritten text recognition research", "author": ["J.J. Hull"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1994}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["Nick Littlestone"], "venue": "Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1987}, {"title": "A last-step regression algorithm for non-stationary online learning", "author": ["Edward Moroshko", "Koby Crammer"], "venue": "In AISTATS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Better algorithms for selective sampling", "author": ["Francesco Orabona", "Nicol\u00f2 Cesa-Bianchi"], "venue": "In ICML, pages 433\u2013440,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "The perceptron: A probabilistic model for information storage and organization in the brain", "author": ["F. Rosenblatt"], "venue": "Psychological Review,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1958}, {"title": "Learning with Kernels: Support Vector Machines, Regularization, Optimization and Beyond", "author": ["B. Sch\u00f6lkopf", "A.J. Smola"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Least Squares Support Vector Machines", "author": ["J.A.K. Suykens", "T. van Gestel", "J. de Brabanter"], "venue": "World Scientific Publishing Company Incorporated,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2002}, {"title": "Least squares support vector machine classifiers", "author": ["Johan A.K. Suykens", "Joos Vandewalle"], "venue": "Neural Processing Letters,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Re-adapting the regularization of weights for non-stationary regression", "author": ["Nina Vaits", "Koby Crammer"], "venue": "In The 22nd International Conference on Algorithmic Learning Theory, ALT", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Competitive on-line statistics", "author": ["Volodya Vovk"], "venue": "International Statistical Review,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}], "referenceMentions": [{"referenceID": 17, "context": "Following the pioneering work of Rosenblatt [18] many al-", "startOffset": 44, "endOffset": 48}, {"referenceID": 4, "context": "For example, the second-order perceptron algorithm [5] extends the original perceptron algorithm and uses the spectral properties of the data to improve performance.", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "Another example is the AROW algorithm [8] which uses confidence as a secondorder information.", "startOffset": 38, "endOffset": 41}, {"referenceID": 4, "context": "Despite the extensive and impressive guarantees that can be made for algorithms in such setting [5, 8], competing with the best fixed function is not always good enough.", "startOffset": 96, "endOffset": 102}, {"referenceID": 7, "context": "Despite the extensive and impressive guarantees that can be made for algorithms in such setting [5, 8], competing with the best fixed function is not always good enough.", "startOffset": 96, "endOffset": 102}, {"referenceID": 12, "context": "For online regression, few algorithms were developed for this setting [13, 22, 16].", "startOffset": 70, "endOffset": 82}, {"referenceID": 21, "context": "For online regression, few algorithms were developed for this setting [13, 22, 16].", "startOffset": 70, "endOffset": 82}, {"referenceID": 15, "context": "For online regression, few algorithms were developed for this setting [13, 22, 16].", "startOffset": 70, "endOffset": 82}, {"referenceID": 3, "context": "Yet, for online classification, the Shifting Perceptron algorithm [4] is a first-order algorithm that shrinks the weight vector each iteration, and in this way weaken dependence on the past.", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "The Modified Perceptron algorithm [3] is another first-order algorithm that had been shown to work well in the drifting setting [9].", "startOffset": 34, "endOffset": 37}, {"referenceID": 8, "context": "The Modified Perceptron algorithm [3] is another first-order algorithm that had been shown to work well in the drifting setting [9].", "startOffset": 128, "endOffset": 131}, {"referenceID": 4, "context": "Our algorithm extends the second-order perceptron algorithm [5], and we provide a performance bound in the mistake bound model.", "startOffset": 60, "endOffset": 63}, {"referenceID": 11, "context": "This setting is called selective sampling [12].", "startOffset": 42, "endOffset": 46}, {"referenceID": 22, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 37, "endOffset": 48}, {"referenceID": 1, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 37, "endOffset": 48}, {"referenceID": 10, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 37, "endOffset": 48}, {"referenceID": 15, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 49, "endOffset": 57}, {"referenceID": 21, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 49, "endOffset": 57}, {"referenceID": 4, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 73, "endOffset": 79}, {"referenceID": 7, "context": "Stationary Non-stationary Regression [23, 2, 11] [16, 22] Classification [5, 8] This work", "startOffset": 73, "endOffset": 79}, {"referenceID": 6, "context": "This group includes the selective sampling versions of the perceptron and the second-order perceptron algorithms [7].", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "This group includes the BBQ algorithm [6], where the threshold decays polynomially with t as t\u2212\u03ba, and more involved variants where the threshold depends on the margin of the RLS estimate [10, 17].", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "This group includes the BBQ algorithm [6], where the threshold decays polynomially with t as t\u2212\u03ba, and more involved variants where the threshold depends on the margin of the RLS estimate [10, 17].", "startOffset": 187, "endOffset": 195}, {"referenceID": 16, "context": "This group includes the BBQ algorithm [6], where the threshold decays polynomially with t as t\u2212\u03ba, and more involved variants where the threshold depends on the margin of the RLS estimate [10, 17].", "startOffset": 187, "endOffset": 195}, {"referenceID": 6, "context": "We build on the work of Cesa-Bianchi et al [7] that combined a randomized rule into the Perceptron algorithm, yielding a selective sampling algorithm.", "startOffset": 43, "endOffset": 46}, {"referenceID": 0, "context": "2 Problem setting We consider the standard online learning model [1, 15] for binary classification, in which learning proceeds in a sequence of rounds t = 1, 2, .", "startOffset": 65, "endOffset": 72}, {"referenceID": 14, "context": "2 Problem setting We consider the standard online learning model [1, 15] for binary classification, in which learning proceeds in a sequence of rounds t = 1, 2, .", "startOffset": 65, "endOffset": 72}, {"referenceID": 6, "context": "Since finding u \u2208 R that minimizes the number of mistakes on a known sequence is a computationally hard problem, the performance of the best predictor in hindsight is often measured using the cumulative hinge loss L\u03b3,T (u) = \u2211T t=1 `\u03b3,t (u), where `\u03b3,t (u) = max { 0, \u03b3 \u2212 ytuxt } is Stationary Non-stationary [7] This work", "startOffset": 309, "endOffset": 312}, {"referenceID": 15, "context": "We follow Moroshko and Crammer [16] and design the prediction as a last-step min-max problem in the context of drifting.", "startOffset": 31, "endOffset": 35}, {"referenceID": 15, "context": "Lemma 1 ([16], Lemma 2).", "startOffset": 9, "endOffset": 13}, {"referenceID": 20, "context": "To the best of our knowledge, this is the first application of the last-step min-max approach directly for classification, and not as a reduction from regression, which is possible by employing the square loss, as in least-squares We still use the squared loss in (1), as done for least-squares SVMs [21, 20], which allows us to compute all quantities analytically.", "startOffset": 300, "endOffset": 308}, {"referenceID": 19, "context": "To the best of our knowledge, this is the first application of the last-step min-max approach directly for classification, and not as a reduction from regression, which is possible by employing the square loss, as in least-squares We still use the squared loss in (1), as done for least-squares SVMs [21, 20], which allows us to compute all quantities analytically.", "startOffset": 300, "endOffset": 308}, {"referenceID": 20, "context": "SVMs [21, 20].", "startOffset": 5, "endOffset": 13}, {"referenceID": 19, "context": "SVMs [21, 20].", "startOffset": 5, "endOffset": 13}, {"referenceID": 15, "context": "Indeed, we showed that the optimal prediction for classification is the sign of the optimal prediction for regression [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 4, "context": "Our algorithm includes the second-order perceptron [5] algorithm as a special case when c = \u221e.", "startOffset": 51, "endOffset": 54}, {"referenceID": 10, "context": "The second-order perceptron algorithm is indeed using the sign of the optimal min-max prediction for regression [11], which is in fact the prediction of the AAR algorithm [23] (aka \u201dforward algorithm\u201d [2]).", "startOffset": 112, "endOffset": 116}, {"referenceID": 22, "context": "The second-order perceptron algorithm is indeed using the sign of the optimal min-max prediction for regression [11], which is in fact the prediction of the AAR algorithm [23] (aka \u201dforward algorithm\u201d [2]).", "startOffset": 171, "endOffset": 175}, {"referenceID": 1, "context": "The second-order perceptron algorithm is indeed using the sign of the optimal min-max prediction for regression [11], which is in fact the prediction of the AAR algorithm [23] (aka \u201dforward algorithm\u201d [2]).", "startOffset": 201, "endOffset": 204}, {"referenceID": 17, "context": "Additionally, similar to other algorithms [18, 5], we update the algorithm only on mistaken rounds.", "startOffset": 42, "endOffset": 49}, {"referenceID": 4, "context": "Additionally, similar to other algorithms [18, 5], we update the algorithm only on mistaken rounds.", "startOffset": 42, "endOffset": 49}, {"referenceID": 4, "context": "The LASEC algorithm can be seen as an extension to the non-stationary setting of the second-order perceptron algorithm [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 6, "context": "This approach for deriving selective-algorithms from margin-based online algorithms is not new, and was used to design an algorithm for the non-drifting case [7].", "startOffset": 158, "endOffset": 161}, {"referenceID": 6, "context": "Yet, unlike other selective sampling algorithms [7, 6, 10, 17], our algorithm is designed to work in the drifting setting.", "startOffset": 48, "endOffset": 62}, {"referenceID": 5, "context": "Yet, unlike other selective sampling algorithms [7, 6, 10, 17], our algorithm is designed to work in the drifting setting.", "startOffset": 48, "endOffset": 62}, {"referenceID": 9, "context": "Yet, unlike other selective sampling algorithms [7, 6, 10, 17], our algorithm is designed to work in the drifting setting.", "startOffset": 48, "endOffset": 62}, {"referenceID": 16, "context": "Yet, unlike other selective sampling algorithms [7, 6, 10, 17], our algorithm is designed to work in the drifting setting.", "startOffset": 48, "endOffset": 62}, {"referenceID": 6, "context": "Specifically, LASEC-SS is reduced for c =\u221e to the selective sampling version of the second-order perceptron algorithm [7], and as mentioned above, for a =\u221e it is reduced to LASEC, and the setting of both c = \u221e, a = \u221e reduces the algorithm to the second-order perceptron, which in turn reduces to the perceptron algorithm for b\u2192\u221e.", "startOffset": 118, "endOffset": 121}, {"referenceID": 18, "context": "[19]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "For the stationary case, when uk = u \u2200k (Vm = 0) and we set c = \u221e for the LASEC algorithm we recover the second-order perceptron bound [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 6, "context": "As in other context [7]: Thm.", "startOffset": 20, "endOffset": 23}, {"referenceID": 6, "context": "For the stationary case, when uk = u \u2200k (Vm = 0) and we set c = \u221e for the LASEC-SS algorithm we recover the bound of the selective sampling version of the second-order perceptron algorithm [7].", "startOffset": 189, "endOffset": 192}, {"referenceID": 15, "context": "1) is the same as the prediction of the LASER algorithm for regression with drift, we can use the result proven by Moroshko and Crammer [16] (Theorem 4 therein), from where we have that for any sequence u1, .", "startOffset": 136, "endOffset": 140}, {"referenceID": 15, "context": "Using Lemma 5 and Lemma 7 of Moroshko and Crammer [16] we have \u2211", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "Next, we use corollary 8 from Moroshko and Crammer [16] to get the final bound for LASEC.", "startOffset": 51, "endOffset": 55}, {"referenceID": 15, "context": "As was shown [16] we have", "startOffset": 13, "endOffset": 17}, {"referenceID": 3, "context": "Another bound for the drifting setting was shown by Cavallanti et al for the Shifting Perceptron [4].", "startOffset": 97, "endOffset": 100}, {"referenceID": 15, "context": "Again, using Lemma 5 and Lemma 7 from [16] we get,", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "This is an immediate application of corollary 8 from [16].", "startOffset": 53, "endOffset": 57}, {"referenceID": 13, "context": "Our second experiment uses the US Postal Service handwritten digits recognition corpus (USPS) [14].", "startOffset": 94, "endOffset": 98}, {"referenceID": 4, "context": "1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].", "startOffset": 73, "endOffset": 76}, {"referenceID": 17, "context": "1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].", "startOffset": 103, "endOffset": 107}, {"referenceID": 3, "context": "1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].", "startOffset": 143, "endOffset": 146}, {"referenceID": 2, "context": "1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].", "startOffset": 182, "endOffset": 185}, {"referenceID": 3, "context": "1) to five other algorithms: the second-order perceptron algorithm (SOP) [5], the Perceptron algorithm [18], the Shifting Perceptron algorithm [4], the Modified Perceptron algorithm [3] and the Randomized Budget Perceptron algorithm [4].", "startOffset": 233, "endOffset": 236}, {"referenceID": 6, "context": "1 to several selective sampling algorithms: the selective sampling version of second-order perceptron algorithm (SOP-SS) [7], the selective sampling version of perceptron algorithm (Perceptron-SS) [7] and the BBQ algorithm [6].", "startOffset": 121, "endOffset": 124}, {"referenceID": 6, "context": "1 to several selective sampling algorithms: the selective sampling version of second-order perceptron algorithm (SOP-SS) [7], the selective sampling version of perceptron algorithm (Perceptron-SS) [7] and the BBQ algorithm [6].", "startOffset": 197, "endOffset": 200}, {"referenceID": 5, "context": "1 to several selective sampling algorithms: the selective sampling version of second-order perceptron algorithm (SOP-SS) [7], the selective sampling version of perceptron algorithm (Perceptron-SS) [7] and the BBQ algorithm [6].", "startOffset": 223, "endOffset": 226}, {"referenceID": 5, "context": "In addition to the BBQ algorithm [6], we also consider a variant of the BBQ algorithm, which we call BBQ-I.", "startOffset": 33, "endOffset": 36}, {"referenceID": 16, "context": "Before the first shift at round 500 the BBQ is the best as expected from previous results [17], but its performance significantly degrade after the first shift.", "startOffset": 90, "endOffset": 94}, {"referenceID": 5, "context": "This is because this algorithm performs query when the quantity rt = xt A \u22121 t xt is large enough (see [6]), while the matrix At grows each time a label is queried.", "startOffset": 103, "endOffset": 106}, {"referenceID": 16, "context": "We note that for stationary environment (when ut = u \u2200t), BBQ outperforms BBQ-I, as well as other selective sampling algorithms (see [17]).", "startOffset": 133, "endOffset": 137}, {"referenceID": 6, "context": "In addition, we can see that unlike the stationary setting where it was shown [7] that a small fraction of labels are enough to get the accuracy of a fully supervised setting, in the drifting case much more labels are needed.", "startOffset": 78, "endOffset": 81}], "year": 2017, "abstractText": "Recently there has been much work on selective sampling, an online active learning setting, in which algorithms work in rounds. On each round an algorithm receives an input and makes a prediction. Then, it can decide whether to query a label, and if so to update its model, otherwise the input is discarded. Most of this work is focused on the stationary case, where it is assumed that there is a fixed target model, and the performance of the algorithm is compared to a fixed model. However, in many real-world applications, such as spam prediction, the best target function may drift over time, or have shifts from time to time. We develop a novel selective sampling algorithm for the drifting setting, analyze it under no assumptions on the mechanism generating the sequence of instances, and derive new mistake bounds that depend on the amount of drift in the problem. Simulations on synthetic and real-world datasets demonstrate the superiority of our algorithms as a selective sampling algorithm in the drifting setting.", "creator": "LaTeX with hyperref package"}}}