{"id": "1402.6516", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2014", "title": "Modelling the Lexicon in Unsupervised Part of Speech Induction", "abstract": "automatically inducing the syntactic part - of - speech categories for words in text is a fundamental task in computational linguistics. while the performance of unsupervised tagging models has been slowly improving, current limited state - of - the - art systems make the completely obviously incorrect assumption for that all tokens of a given word type must share a single part - of - speech tag. this one - tag - per - type heuristic counters the tendency of hidden markov model based sequential taggers to over generate short tags for a given word type. however, it is clearly incompatible with basic finite syntactic theory. in this paper we extend a state - of - the - art pitman - bound yor hidden markov model tagger with an explicit model of identifying the lexicon. in doing so we are able successfully to incorporate a soft bias towards inducing few tags per type. we develop a particle filter for drawing samples from the posterior of our model and present empirical results that show that our model is competitive with and faster than the state - of - the - art without simply making any unrealistic restrictions.", "histories": [["v1", "Wed, 26 Feb 2014 12:37:04 GMT  (89kb,D)", "http://arxiv.org/abs/1402.6516v1", "To be presented at the 14th Conference of the European Chapter of the Association for Computational Linguistics"]], "COMMENTS": "To be presented at the 14th Conference of the European Chapter of the Association for Computational Linguistics", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["greg dubbin", "phil blunsom"], "accepted": false, "id": "1402.6516"}, "pdf": {"name": "1402.6516.pdf", "metadata": {"source": "CRF", "title": "Modelling the Lexicon in Unsupervised Part of Speech Induction", "authors": ["Greg Dubbin", "Phil Blunsom"], "emails": ["Gregory.Dubbin@wolfson.ox.ac.uk", "Phil.Blunsom@cs.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Research on the unsupervised induction of partof-speech (PoS) tags has the potential to improve both our understanding of the plausibility of theories of first language acquisition, and Natural Language Processing applications such as Speech Recognition and Machine Translation. While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and\nJohnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in many of these works is that models based on a Hidden Markov Model (HMM) graphical structure suffer from a tendency to assign too many different tags to the tokens of a given word type. Models which restrict word types to only occur with a single tag show a significant increase in performance, even though this restriction is clearly at odds with the gold standard labeling (Brown et al., 1992; Clark, 2003; Blunsom and Cohn, 2011). While the empirically observed expectation for the number of tags per word type is close to one, there are many exceptions, e.g. words that occur as both nouns and verbs (opening, increase, related etc.).\nIn this paper we extend the Pitman-Yor HMM tagger (Blunsom and Cohn, 2011) to explicitly include a model of the lexicon that encodes from which tags a word type may be generated. For each word type we draw an ambiguity class which is the set of tags that it may occur with, capturing the fact that words are often ambiguous between certain tags (e.g. Noun and Verb), while rarely between others (e.g. Determiner and Verb). We extend the type based Sequential Monte Carlo (SMC) inference algorithm of Dubbin and Blunsom (2012) to incorporate our model of the lexicon, removing the need for the heuristic inference technique of Blunsom and Cohn (2011).\nWe start in Section 3 by introducing the original PYP-HMM model and our extended model of the lexicon. Section 4 introduces a Particle Gibbs sampler for this model, a basic SMC method that generates samples from the model\u2019s posterior. We evaluate these algorithms in Section 5, analyzing their behavior in comparisons to previously proposed state-of-the-art approaches.\nar X\niv :1\n40 2.\n65 16\nv1 [\ncs .C\nL ]\n2 6\nFe b\n20 14"}, {"heading": "2 Background", "text": "From the early work in the 1990\u2019s, much of the focus on unsupervised PoS induction has been on hidden Markov Models (HMM) (Brown et al., 1992; Kupiec, 1992; Merialdo, 1993). The HMM has proven to be a powerful model of PoS tag assignment. Successful approaches generally build upon the HMM model by expanding its context and smoothing the sparse data. Constraints such as tag dictionaries simplify inference by restricting the number of tags to explore for each word (Goldwater and Griffiths, 2007). Ganchev et al. (2010) used posterior regularization to ensure that word types have a sparse posterior distribution over tags. A similar approach constrains inference to only explore tag assignments such that all tokens of the same word type are assigned the same tag. These constraints reduce tag assignment ambiguity while also providing a bias towards the natural sparsity of tag distributions in language (Clark, 2003). However they do not provide a model based solution to tag ambiguity.\nRecent work encodes similar sparsity information with non-parametric priors, relying on Bayesian inference to achieve strong results without any tag dictionaries or constraints (Goldwater and Griffiths, 2007; Johnson, 2007; Gao and Johnson, 2008). Liang et al. (2010) propose a typebased approach to this Bayesian inference similar to Brown et al. (1992), suggesting that there are strong dependencies between tokens of the same word-type. Lee et al. (2010) demonstrate strong results with a similar model and the introduction of a one-tag-per-type constraint on inference.\nBlunsom and Cohn (2011) extend the Bayesian inference approach with a hierarchical nonparametric prior that expands the HMM context to trigrams. However, the hierarchical nonparametric model adds too many long-range dependencies for the type-based inference proposed earlier. The model produces state-of-the art results with a one-tag-per-type constraint, but even with this constraint the tag assignments must be roughly inferred from an approximation of the expectations.\nAmbiguity classes representing the set of tags each word-type can take aid inference by making the sparsity between tags and words explicit. Toutanova and Johnson (2008) showed that modelling ambiguity classes can lead to positive results with a small tag-dictionary extracted from the\ndata. By including ambiguity classes in the model, this approach is able to infer ambiguity classes of unknown words.\nMany improvements in part-of-speech induction over the last few years have come from the use of semi-supervised approaches in the form of projecting PoS constraints across languages with parallel corpora (Das and Petrov, 2011) or extracting them from the wiktionary (Li et al., 2012). These semi-supervised methods ultimately rely on a strong unsupervised model of PoS as their base. Thus, further improvements in unsupervised models, especially in modelling tag constrains, should lead to improvements in semi-supervised part-ofspeech induction.\nWe find that modelling the lexicon in part-ofspeech inference can lead to more efficient algorithms that match the state-of-the-art unsupervised performance. We also note that the lexicon model relies heavily on morphological information, and suffers without it on languages with flexible word ordering. These results promise further improvements with more advanced lexicon models."}, {"heading": "3 The Pitman-Yor Lexicon Hidden Markov Model", "text": "This article proposes enhancing the standard Hidden Markov Model (HMM) by explicitly incorporating a model of the lexicon that consists of word types and their associated tag ambiguity classes. The ambiguity class of a word type is the set of possible lexical categories to which tokens of that type can be assigned. In this work we aim to learn the ambiguity classes unsupervised rather than have them specified in a tag dictionary.\nThe Lexicon HMM (Lex-HMM) extends the Pitman-Yor HMM (PYP-HMM) described by Blunsom and Cohn (2011). When the ambiguity class of all of the word types in the lexicon is the complete tagset, the two models are the same."}, {"heading": "3.1 PYP-HMM", "text": "The base of the model applies a hierarchical Pitman-Yor process (PYP) prior to a trigram hidden Markov model to jointly model the distribution of a sequence of latent word tags, t, and word tokens, w. The joint probability defined by the transition, P\u03b8(tl|tn\u22121, tn\u22122), and emission, P\u03b8(wn|tn), distributions of a trigram HMM is\nP\u03b8(t,w) = N+1\u220f n=1 P\u03b8(tl|tn\u22121, tn\u22122)P\u03b8(wn|tn)\nwhere N = |t| = |w| and the special tag $ is added to denote the sentence boundaries. The model defines a generative process in which the tags are selected from a transition distribution, tl|tl\u22121, tl\u22122, T , determined by the two previous tags in their history, and the word tokens are selected from the emission distribution, wl|tl, E, of the latest tag.\ntn|tn\u22121, tn\u22122, T \u223c Ttn\u22121,tn\u22122 wn|tn, E \u223c Etn\nThe PYP-HMM draws the above multinomial distributions from a hierarchical Pitman-Yor Process prior. The Pitman-Yor prior defines a smooth back off probability from more complex to less complex transition and emission distributions. In the PYP-HMM trigram model, the transition distributions form a hierarchy with trigram transition distributions drawn from a PYP with the bigram transitions as their base distribution, and the bigram transitions similarly backing off to the unigram transitions. The hierarchical prior can be intuitively understood to smooth the trigram transition distributions with bigram and unigram distributions in a similar manner to an ngram language model (Teh, 2006). This back-off structure greatly reduces sparsity in the trigram distributions and is achieved by chaining together the PYPs through their base distributions:\nTij |aT , bT , Bi \u223c PYP(aT , bT , Bi) Bi|aB, bB, U \u223c PYP(aB, bB, U) U |aU , bU \u223c PYP(aU , bU ,Uniform). Ei|aE , bE , C \u223c PYP(aE , bE , Ci),\nwhere Tij , Bi, and U are trigram, bigram, and unigram transition distributions respectively, and Ci is either a uniform distribution (PYP-HMM) or a bigram character language model distribution to model word morphology (PYP-HMM+LM).\nSampling from the posterior of the hierarchical PYP is calculated with a variant of the Chinese Restaurant Process (CRP) called the Chinese Restaurant Franchise (CRF) (Teh, 2006; Goldwater et al., 2006). In the CRP analogy, each latent variable (tag) in a sequence is represented by a customer entering a restaurant and sitting at one of an infinite number of tables. A customer chooses to sit at a table in a restaurant according to the\nprobability\nP (zn = k|z1:n\u22121) =\n{ c\u2212k \u2212a n\u22121+b 1 \u2264 k \u2264 K \u2212\nK\u2212a+b n\u22121+b k = K \u2212 + 1 (1)\nwhere zn is the index of the table chosen by the nth customer to the restaurant, z1:n\u22121 is the seating arrangement of the previous n \u2212 1 customers to enter, c\u2212k is the count of the customers at table k, and K\u2212 is the total number of tables chosen by the previous n \u2212 1 customers. All customers at a table share the same dish, representing the value assigned to the latent variables. When customers sit at an empty table, a new dish is assigned to that table according to the base distribution of the PYP. To expand the CRP analogy to the CRF for hierarchical PYPs, when a customer sits at a new table, a new customer enters the restaurant of the PYP of the base distribution.\nBlunsom and Cohn (2011) explored two Gibbs sampling methods for inference with the PYPHMM model. The first individually samples tag assignments for each token. The second employs a tactic shown to be effective by earlier works by constraining inference to only one tag per word type (PYP-1HMM). However marginalizing over all possible table assignments for more than a single tag is intractable. Blunsom and Cohn (2011) approximates the PYP-1HMM tag posteriors for a particular sample according to heuristic fractional table counts. This approximation is shown to be particularly inaccurate for values of a close to one."}, {"heading": "3.2 The Lexicon HMM", "text": "We define the lexicon to be the set of all word types (W ) and a function (L) which maps each word type (Wi \u2208 W ) to an element in the power set of possible tags T ,\nL : W \u2192 P(T ).\nThe Lexicon HMM (Lex-HMM) generates the lexicon with all of the word types and their ambiguity classes before generating the standard HMM parameters. The set of tags associated with each word type is referred to as its ambiguity class si \u2286 T . The ambiguity classes are generated from a multinomial distribution with a sparse, PitmanYor Process prior,\nsi|S \u223c S S|aS , bS \u223c PY P (aS , bS , G)\nwhere S is the multinomial distribution over all possible ambiguity classes. The base distribution of the PYP, G, chooses the size of the ambiguity class according to a geometric distribution (normalized so that the size of the class is at most the number of tags |T |). G assigns uniform probability to all classes of the same size. A plate diagram for this model is shown in Figure 1.\nThis model represents the observation that there are relatively few distinct ambiguity classes over all of the word types in a corpus. For example, the full Penn-Treebank Wall Street Journal (WSJ) corpus with 45 possible tags and 49,206 word types has only 343 ambiguity classes. Figure 2 shows that ambiguity classes in the WSJ have a powerlaw distribution. Furthermore, these classes are generally small; the average ambiguity class in the WSJ corpus has 2.94 tags. The PYP prior favors power-law distributions and the modified geometric base distribution favors smaller class sizes.\nOnce the lexicon is generated, the standard HMM parameters can be generated as described in section 3.1. The base emission probabilities C are constrained to fit the generated lexicon. The standard Lex-HMM model emission probabilities for tag ti are uniform over all word types with ti in their ambiguity class. The character language model presents a challenge because it is non-trivial to renormalise over words with ti in their ambiguity class. In this case word types without ti in their\nLog-Log Ambiguity Class Frequency vs. Rank\nambiguity class are assigned an emission probability of 0 and the model is left deficient.\nNeither of the samplers proposed by Blunsom and Cohn (2011) and briefly described in section 3.1 are well suited to inference with the lexicon. Local Gibbs sampling of individual token-tag assignments would be very unlikely to explore a range of confusion classes, while the type based approximate sample relies on a one-tag-per-type restriction. Thus in the next section we extend the Particle Filtering solution presented in Dubbin and Blunsom (2012) to the problem of simultaneous resampling the ambiguity class as well as the tags for all tokens of a given type. This sampler provides both a more attractive inference algorithm for the original PYP-HMM and one adaptable to our Lex-HMM."}, {"heading": "4 Inference", "text": "To perform inference with both the lexicon and the tag assignments, we block sample the ambiguity class assignment as well as all tag assignments for tokens of the same word type. It would be intractable to exactly calculate the probabilities to sample these blocks. Particle filters are an example of a Sequential Monte Carlo technique which generates unbiased samples from a distribution without summing over the intractable number of possibilities.\nThe particle filter samples multiple independent sequences of ambiguity classes and tag assignments. Each sequence of samples, called a parti-\ncle, is generated incrementally. For each particle, the particle filter first samples an ambiguity class, and then samples each tag assignment in sequence based only on the previous samples in the particle. The value of the next variable in a sequence is sampled from a proposal distribution based only on the earlier values in the sequence. Each particle is assigned an importance weight such that a particle sampled proportional to its weight represents an unbiased sample of the true distribution.\nEach particle represents a specific sampling of an ambiguity class, tag sequence, tW,p1:n , and the count deltas, zW,p1:n . The term t W,p 1:n denotes the sequence of n tags generated for word-type W and stored as part of particle p \u2208 [1, P ]. The count deltas store the differences in the seating arrangement neccessary to calculate the posterior probabilities according to the Chinese restaurant franchise described in section 3.1. The table counts from each particle are the only data necessary to calculate the probabilities described in equation (1).\nThe ambiguity class for a particle is proposed by uniformly sampling one tag from the tagset to add to or remove from the previous iteration\u2019s ambiguity class with the additional possibility of using the same ambiguity class. The particle weights are then set to\nP (sW,p|S\u2212W )\u220f t\u2208sW,p(et + 1) #(Et) \u220f t\u2208T\u2212sW,p(et) #(Et)\nwhere P (sW,p|S\u2212W ) is the probability of the ambiguity class proposed for particle p for word type W given the ambiguity classes for the rest of the vocabulary, et is the number of word types with t in their ambiguity class, and #(Et) is the number of tables in the CRP for the emission distribution of tag t. The last two terms of the equation correct for the difference in the base probabilities of the words that have already been sampled with a different lexicon.\nAt each token occurrence n, the next tag assignment, tW,pn for each particle p \u2208 [1, P ] is determined by the seating decisions zW,pn , which are made according the proposal distribution:\nqW,pn (z W,p n |z W,p 1:n\u22121, z \u2212W ) \u221d\nP (zW,pn |c\u22122, c\u22121, z W,p 1:n\u22121, z \u2212W )\n\u00d7P (c+1n |c\u22121n , zW,pn , z W,p 1:n\u22121, z \u2212W ) \u00d7P (c+2n |zW,pn , c+1n , z W,p 1:n\u22121, z \u2212W ) \u00d7P (wWn |zW,pn , z W,p 1:n\u22121, z \u2212W ).\nIn this case, c\u00b1kn represents a tag in the context of site tWn offset by k, while z W,p 1:n\u22121 and z\n\u2212W represent the table counts from the seating decisions previously chosen by particle p and the values at all of the sites where a word token of type W does not appear, respectively. This proposal distribution ignores changes to the seating arrangement between the three transitions involving the site n. The specific tag assignement, tW , pn, is completely determined by the seating decisions sampled according to this proposal distribution. Once all of the particles have been sampled, one of them is sampled with probability proportional to its weight. This final sample is a sample from the target distribution.\nAs the Particle Filter is embedded in a Gibbs sampler which cycles over all word types this algorithm is an instance of Particle Gibbs. Andrieu et al. (2010) shows that to ensure the samples generated by SMC for a Gibbs sampler have the target distribution as the invariant density, the particle filter must be modified to perform a conditional SMC update. This means that the particle filter guarantees that one of the final particles is assigned the same values as the previous Gibbs iteration. Therefore, a special 0th particle is automatically assigned the value from the prior iteration of the Gibbs sampler at each site n, though the proposal probability qWn (t W,0 n |tW,p1:n\u22121, z W,p 1:n\u22121) still has to be calculated to update the weight \u03c9W,pn properly. This ensures that the sampler has a chance of reverting to the prior iteration\u2019s sequence."}, {"heading": "5 Experiments and Results", "text": "We provide an empirical evaluation of our proposed Lex-HMM in terms of the accuracy of the taggings learned according to the most popular metric, and the distributions over ambiguity classes. Our experimental evaluation considers the impact of our improved Particle Gibbs inference algorithm both for the original PYP-HMM and when used for inference in our extended model.\nWe intend to learn whether the lexicon model can match or exceed the performance of the other models despite focusing on only a subset of the possible tags each iteration. We hypothesize that an accurate lexicon model and the sparsity it induces over the number of tags per word-type will improve the performance over the standard PYPHMM model while also decreasing training time. Furthermore, our lexicon model is novel, and its\nSampler M-1 Accuracy Time (h) Meta-Model (CGS10) 76.1 \u2014 MEMM (BBDK10) 75.5 \u223c40* Lex-HMM 71.1 7.9 Type PYP-HMM 70.1 401.2 Local PYP-HMM 70.2 8.6 PYP-1HMM 75.6 20.6 Lex-HMM+LM 77.5 16.9 Type PYP-HMM+LM 73.5 446.0 PYP-1HMM+LM 77.5 34.9\nTable 1: M-1 Accuracy on the WSJ Corpus: Comparison of the accuracy of each of the samplers with and without the language model emission prior on the English WSJ Corpus. The second column reports run time in hours where available*. Note the Lex-HMM+LM model matches the PYP1HMM+LM approximation despite finishing in half the time. The abbreviations in parentheses indicate that the results were reported in CGS10 (Christodoulopoulos et al., 2010) and BBDK10 (Berg-Kirkpatrick et al., 2010) *CGS10 reports that the MEMM model takes approximately 40 hours on 16 cores.\naccuracy in representing ambiguity classes is an important aspect of its performance. The model focuses inference on the most likely tag choices, represented by ambiguity classes."}, {"heading": "5.1 Unsupervised Part-of-Speech Tagging", "text": "The most popular evaluation for unsupervised part-of-speech taggers is to induce a tagging for a corpus and compare the induced tags to those annotated by a linguist. As the induced tags are simply integer labels, we must employ a mapping between these and the more meaningful syntactic categories of the gold standard. We report results using the many-to-one (M-1) metric considered most intuitive by the evaluation of Christodoulopoulos et al. (2010). M-1 measures the accuracy of the model after mapping each predicted class to its most frequent corresponding tag. While Christodoulopoulos et al. (2010) found Vmeasure to be more stable over the number of parts-of-speech, this effect doesn\u2019t appear when the number of tags is constant, as in our case. For experiments on English, we report results on the entire Penn. Treebank (Marcus et al., 1993). For other languages we use the corpora made available for the CoNLL-X Shared Task (Buchholz and\nMarsi, 2006). All Lex-HMM results are reported with 10 particles as no significant improvement was found with 50 particles.\nTable 1 compares the M-1 accuracies of both the PYP-HMM and the Lex-HMM models on the Penn. Treebank Wall Street Journal corpus. Blunsom and Cohn (2011) found that the Local PYPHMM+LM sampler is unable to mix, achieving accuracy below 50%, therefore it has been left out of this analysis. The Lex-HMM+LM model achieves the same accuracy as the state-of-theart PYP-1HMM+LM approximation. The LexHMM+LM\u2019s focus on only the most likely tags for each word type allows it to finish training in half the time as the PYP-1HMM+LM approximation without any artificial restrictions on the number of tags per type. This contrasts with other approaches that eliminate the constraint at a much greater cost, e.g. the Type PYP-HMM, the MEMM, and the Meta-Model 1\nThe left side of table 2 compares the M-1 accuracies of the Lex-HMM model to the PYP-HMM model. These models both ignore word morphology and rely on word order. The 1HMM approximation achieves the highest average accuracy. The Lex-HMM model matches or surpasses the typebased PYP-HMM approach in six languages while running much faster due to the particle filter considering a smaller set of parts-of-speech for each particle. However, in the absence of morphological information, the Lex-HMM model has a similar average accuracy to the local and typebased PYP-HMM samplers. The especially low performance on Hungarian, a language with free word ordering and strong morphology, suggests that the Lex-HMM model struggles to find ambiguity classes without morphology. The Lex-HMM model has a higher average accuracy than the typebased or local PYP-HMM samplers when Hungarian is ignored.\nThe right side of table 2 compares the M-1 accuracies of the Lex-HMM+LM model to the PYPHMM+LM. The language model leads to consistently improved performance for each of the samplers excepting the token sampler, which is unable to mix properly with the additional complexity. The accuracies achieved by the 1HMM+LM\n1While were unable to get an estimate on the runtime of the Meta-Model, it uses a system similar to the feature-based system of the MEMM with an additional feature derived from the proposed class from the brown model. Therefore, it is likely that this model has a similar runtime.\nsampler represent the previous state-of-the-art. These results show that the Lex-HMM+LM model achieves state-of-the-art M-1 accuracies on several datasets, including the English WSJ. The LexHMM+LM model performs nearly as well as, and often better than, the 1HMM+LM sampler without any restrictions on tag assignments.\nThe drastic improvement in the performance of the Lex-HMM model reinforces our hypothesis that morphology is critical to the inference of ambiguity classes. Without the language model representing word morphology, the distinction between ambiguity classes is too ambiguous. This leads the sampler to infer an excess of poor ambiguity classes. For example, the tag assignments from the Lex-PYP model on the WSJ dataset consist of 660 distinct ambiguity classes, while the Lex-PYP+LM tag assignments only have 182 distinct ambiguity classes.\nNote that while the Lex-HMM and LexHMM+LM samplers do not have any restrictions on inference, they do not sacrifice time. The additional samples generated by the particle filter are mitigated by limiting the number of tags each particle must consider. In practice, this results in the Lex-HMM samplers with 10 particles running in half time as the 1HMM samplers. The LexHMM+LM sampler with 10 particles took 16.9 hours, while the 1HMM+LM sampler required 34.9 hours. Furthermore, the run time evaluation does not take advantage of the inherent distributed nature of particle filters. Each of the particles can be sampled completely independentally from the\nothers, making it trivial to run each on a seperate core."}, {"heading": "5.2 Lexicon Analysis", "text": "While section 5.1 demonstrates that the LexHMM+LM sampler performs similarly to the more restricted 1HMM+LM, we also seek to evaluate the accuracy of the lexicon model itself. We compare the ambiguity classes extracted from the gold standard and predicted tag assignments of the WSJ corpus. We also explore the relationship between the actual and sampled ambiguity classes.\nThe solid curve in figure 2 shows the distribution of the number of word types assigned to each ambiguity set extracted from the gold standard tag assignments from the Penn Treebank Wall Street Journal corpus. The straight line strongly indicates that ambiguity classes follow a Zipfian distribution. Figure 2 also graphs the distribution of the ambiguity classes extracted from the best tagassignment prediction from the model. The predicted graph has a similar shape to the gold standard but represents half as many distinct ambiguity classes - 182 versus 343.\nFor a qualitative analysis of the generated lexicon, table 3 lists frequent ambiguity classes and the most common words assigned to them. The 14 most frequent ambiguity classes contain only one tag each, the top half of table 3 shows the 5 most frequent. One third of the word-types in the first five rows of the table are exactly matched with the ambiguity classes from the gold standard. Most of the remaining words in those rows are assigned to\na class representing almost all of the words\u2019 occurrences in the gold standard, e.g., \u2018Corp.\u2019 is an NNP in 1514 out of 1521 occurrences. Some words are assigned to classes with similar parts of speech, e.g. {NNS} rather than {NN} for week.\nThe lower half of table 3 shows the most frequent ambiguity classes with more than a single tag. The words assigned to the {NN,CD}, {DT,NNP}, and {NN,JJ} classes are not themselves ambiguous. Rather words that are unambiguously one of the two tags are often assigned to an ambiguity class with both. The most common types in the {NN, CD} set are unambiguously either NN or CD. In many cases the words are merged into broader ambiguity classes because the Lex-HMM+LM uses the language model to model the morphology of words over individual partsof-speech, rather than entire ambiguity classes. Therefore, a word-type is likely to be assigned a given ambiguity class as long as at least one part-of-speech in that ambiguity class is associated with morphologically similar words. These results suggest modifying the Lex-HMM+LM to model word morphology over ambiguity classes rather than parts-of-speech.\nThe {VB,NN} and {VBN,JJ} are representative of true ambiguity classes. Occurrences of words in these classes are likely to be either of the possible parts-of-speech. These results show that the LexHMM is modelling ambiguity classes as intended."}, {"heading": "6 Conclusion", "text": "This paper described an extension to the PYPHMM part-of-speech model that incorporates a sparse prior on the lexicon and an SMC based inference algorithm. These contributions provide a more plausible model of part-of-speech induction which models the true ambiguity of tag to type assignments without the loss of performance of earlier HMM models. Our empirical evaluation indicates that this model is able to meet or exceed the performance of the previous state-of-the-art across a range of language families.\nIn addition to the promising empirical results, our analysis indicates that the model learns ambiguity classes that are often quite similar to those in the gold standard. We believe that further improvements in both the structure of the lexicon prior and the inference algorithm will lead to additional performance gains. For example, the model could be improved by better modelling the relationship between a word\u2019s morphology and its ambiguity class. We intend to apply our model to recent semi-supervised approaches which induce partial tag dictionaries from parallel language data (Das and Petrov, 2011) or the Wiktionary (Li et al., 2012). We hypothesize that the additional data should improve the modelled lexicon and consequently improve tag assignments.\nThe Lex-HMM models ambiguity classes to focus the sampler on the most likely parts-of-speech for a given word-type. In doing so, it matches or improves on the accuracy of other models while running much faster."}], "references": [{"title": "Particle markov chain monte carlo methods", "author": ["Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein."], "venue": "Journal Of The Royal Statistical Society Series B, 72(3):269\u2013342.", "citeRegEx": "Andrieu et al\\.,? 2010", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "Painless unsupervised learning with features", "author": ["Taylor Berg-Kirkpatrick", "Alexandre Bouchard-C\u00f4t\u00e9", "John DeNero", "Dan Klein."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2010", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2010}, {"title": "A hierarchical Pitman-Yor process hmm for unsupervised part of speech induction", "author": ["Phil Blunsom", "Trevor Cohn."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages", "citeRegEx": "Blunsom and Cohn.,? 2011", "shortCiteRegEx": "Blunsom and Cohn.", "year": 2011}, {"title": "Class-based n-gram models of natural language", "author": ["Peter F. Brown", "Peter V. deSouza", "Robert L. Mercer", "Vincent J. Della Pietra", "Jenifer C. Lai."], "venue": "Comput. Linguist., 18:467\u2013479, December.", "citeRegEx": "Brown et al\\.,? 1992", "shortCiteRegEx": "Brown et al\\.", "year": 1992}, {"title": "Conll-x shared task on multilingual dependency parsing", "author": ["Sabine Buchholz", "Erwin Marsi."], "venue": "Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLL-X \u201906, pages 149\u2013164, Morristown, NJ, USA. Association", "citeRegEx": "Buchholz and Marsi.,? 2006", "shortCiteRegEx": "Buchholz and Marsi.", "year": 2006}, {"title": "Two decades of unsupervised POS induction: How far have we come", "author": ["Christos Christodoulopoulos", "Sharon Goldwater", "Mark Steedman"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Christodoulopoulos et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Christodoulopoulos et al\\.", "year": 2010}, {"title": "Combining distributional and morphological information for part of speech induction", "author": ["Alexander Clark."], "venue": "Proceedings of the tenth Annual Meeting of the European Association for Computational Linguistics (EACL), pages 59\u201366.", "citeRegEx": "Clark.,? 2003", "shortCiteRegEx": "Clark.", "year": 2003}, {"title": "Unsupervised part-of-speech tagging with bilingual graph-based projections", "author": ["Dipanjan Das", "Slav Petrov."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume", "citeRegEx": "Das and Petrov.,? 2011", "shortCiteRegEx": "Das and Petrov.", "year": 2011}, {"title": "Unsupervised bayesian part of speech inference with particle gibbs", "author": ["Gregory Dubbin", "Phil Blunsom."], "venue": "Peter A. Flach, Tijl De Bie, and Nello Cristianini, editors, ECML/PKDD (1), volume 7523 of Lecture Notes in Computer Science, pages 760\u2013773.", "citeRegEx": "Dubbin and Blunsom.,? 2012", "shortCiteRegEx": "Dubbin and Blunsom.", "year": 2012}, {"title": "Posterior regularization for structured latent variable models", "author": ["Kuzman Ganchev", "Jo\u00e3o Gra\u00e7a", "Jennifer Gillenwater", "Ben Taskar."], "venue": "Journal of Machine Learning Research, 99:2001\u20132049, August.", "citeRegEx": "Ganchev et al\\.,? 2010", "shortCiteRegEx": "Ganchev et al\\.", "year": 2010}, {"title": "A comparison of bayesian estimators for unsupervised hidden markov model pos taggers", "author": ["Jianfeng Gao", "Mark Johnson."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP \u201908, pages 344\u2013352,", "citeRegEx": "Gao and Johnson.,? 2008", "shortCiteRegEx": "Gao and Johnson.", "year": 2008}, {"title": "A fully bayesian approach to unsupervised part-of-speech tagging", "author": ["Sharon Goldwater", "Tom Griffiths."], "venue": "Proc. of the 45th Annual Meeting of the ACL (ACL-2007), pages 744\u2013751, Prague, Czech Republic, June.", "citeRegEx": "Goldwater and Griffiths.,? 2007", "shortCiteRegEx": "Goldwater and Griffiths.", "year": 2007}, {"title": "Interpolating between types and tokens by estimating power-law generators", "author": ["Sharon Goldwater", "Tom Griffiths", "Mark Johnson."], "venue": "Y. Weiss, B. Sch\u00f6lkopf, and J. Platt, editors, Advances in Neural Information Processing Systems 18, pages 459\u2013", "citeRegEx": "Goldwater et al\\.,? 2006", "shortCiteRegEx": "Goldwater et al\\.", "year": 2006}, {"title": "Why doesnt EM find good HMM POS-taggers? In Proc", "author": ["Mark Johnson."], "venue": "of the 2007 Conference on Empirical Methods in Natural Language Processing (EMNLP-2007), pages 296\u2013305, Prague, Czech Republic.", "citeRegEx": "Johnson.,? 2007", "shortCiteRegEx": "Johnson.", "year": 2007}, {"title": "Robust part-of-speech tagging using a hidden Markov model", "author": ["Julian Kupiec."], "venue": "Computer Speech and Language, 6:225\u2013242.", "citeRegEx": "Kupiec.,? 1992", "shortCiteRegEx": "Kupiec.", "year": 1992}, {"title": "Simple type-level unsupervised pos tagging", "author": ["Yoong Keok Lee", "Aria Haghighi", "Regina Barzilay."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP \u201910, pages 853\u2013861, Morristown, NJ, USA. Associ-", "citeRegEx": "Lee et al\\.,? 2010", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Wiki-ly supervised part-of-speech tagging", "author": ["Shen Li", "Jo\u00e3o V. Gra\u00e7a", "Ben Taskar."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL \u201912,", "citeRegEx": "Li et al\\.,? 2012", "shortCiteRegEx": "Li et al\\.", "year": 2012}, {"title": "Typebased MCMC", "author": ["P. Liang", "M.I. Jordan", "D. Klein."], "venue": "North American Association for Computational Linguistics (NAACL).", "citeRegEx": "Liang et al\\.,? 2010", "shortCiteRegEx": "Liang et al\\.", "year": 2010}, {"title": "Building a large annotated corpus of English: the Penn treebank", "author": ["Mitchell P. Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."], "venue": "Computational Linguistics, 19(2):313\u2013330.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Tagging english text with a probabilistic model", "author": ["Bernard Merialdo."], "venue": "Computational Linguistics, 20:155\u2013171.", "citeRegEx": "Merialdo.,? 1993", "shortCiteRegEx": "Merialdo.", "year": 1993}, {"title": "A hierarchical bayesian language model based on Pitman-Yor processes", "author": ["Yee Whye Teh."], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Lin-", "citeRegEx": "Teh.,? 2006", "shortCiteRegEx": "Teh.", "year": 2006}, {"title": "A Bayesian LDA-based model for semi-supervised part-of-speech tagging", "author": ["Kristina Toutanova", "Mark Johnson."], "venue": "J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 1521\u2013", "citeRegEx": "Toutanova and Johnson.,? 2008", "shortCiteRegEx": "Toutanova and Johnson.", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 6, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 5, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 21, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 11, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 2, "context": "While there has been much prior work on this task (Brown et al., 1992; Clark, 2003; Christodoulopoulos et al., 2010; Toutanova and Johnson, 2008; Goldwater and Griffiths, 2007; Blunsom and Cohn, 2011), a common thread in", "startOffset": 50, "endOffset": 200}, {"referenceID": 3, "context": "with a single tag show a significant increase in performance, even though this restriction is clearly at odds with the gold standard labeling (Brown et al., 1992; Clark, 2003; Blunsom and Cohn, 2011).", "startOffset": 142, "endOffset": 199}, {"referenceID": 6, "context": "with a single tag show a significant increase in performance, even though this restriction is clearly at odds with the gold standard labeling (Brown et al., 1992; Clark, 2003; Blunsom and Cohn, 2011).", "startOffset": 142, "endOffset": 199}, {"referenceID": 2, "context": "with a single tag show a significant increase in performance, even though this restriction is clearly at odds with the gold standard labeling (Brown et al., 1992; Clark, 2003; Blunsom and Cohn, 2011).", "startOffset": 142, "endOffset": 199}, {"referenceID": 2, "context": "In this paper we extend the Pitman-Yor HMM tagger (Blunsom and Cohn, 2011) to explicitly include a model of the lexicon that encodes from which tags a word type may be generated.", "startOffset": 50, "endOffset": 74}, {"referenceID": 7, "context": "We extend the type based Sequential Monte Carlo (SMC) inference algorithm of Dubbin and Blunsom (2012) to incorporate our model of the lexicon, removing the need for the heuristic inference technique of Blunsom and Cohn (2011).", "startOffset": 77, "endOffset": 103}, {"referenceID": 2, "context": "We extend the type based Sequential Monte Carlo (SMC) inference algorithm of Dubbin and Blunsom (2012) to incorporate our model of the lexicon, removing the need for the heuristic inference technique of Blunsom and Cohn (2011).", "startOffset": 203, "endOffset": 227}, {"referenceID": 3, "context": "focus on unsupervised PoS induction has been on hidden Markov Models (HMM) (Brown et al., 1992; Kupiec, 1992; Merialdo, 1993).", "startOffset": 75, "endOffset": 125}, {"referenceID": 14, "context": "focus on unsupervised PoS induction has been on hidden Markov Models (HMM) (Brown et al., 1992; Kupiec, 1992; Merialdo, 1993).", "startOffset": 75, "endOffset": 125}, {"referenceID": 19, "context": "focus on unsupervised PoS induction has been on hidden Markov Models (HMM) (Brown et al., 1992; Kupiec, 1992; Merialdo, 1993).", "startOffset": 75, "endOffset": 125}, {"referenceID": 11, "context": "Constraints such as tag dictionaries simplify inference by restricting the number of tags to explore for each word (Goldwater and Griffiths, 2007).", "startOffset": 115, "endOffset": 146}, {"referenceID": 9, "context": "Ganchev et al. (2010) used posterior regularization to ensure that word", "startOffset": 0, "endOffset": 22}, {"referenceID": 6, "context": "also providing a bias towards the natural sparsity of tag distributions in language (Clark, 2003).", "startOffset": 84, "endOffset": 97}, {"referenceID": 11, "context": "out any tag dictionaries or constraints (Goldwater and Griffiths, 2007; Johnson, 2007; Gao and Johnson, 2008).", "startOffset": 40, "endOffset": 109}, {"referenceID": 13, "context": "out any tag dictionaries or constraints (Goldwater and Griffiths, 2007; Johnson, 2007; Gao and Johnson, 2008).", "startOffset": 40, "endOffset": 109}, {"referenceID": 10, "context": "out any tag dictionaries or constraints (Goldwater and Griffiths, 2007; Johnson, 2007; Gao and Johnson, 2008).", "startOffset": 40, "endOffset": 109}, {"referenceID": 9, "context": "out any tag dictionaries or constraints (Goldwater and Griffiths, 2007; Johnson, 2007; Gao and Johnson, 2008). Liang et al. (2010) propose a typebased approach to this Bayesian inference similar to Brown et al.", "startOffset": 87, "endOffset": 131}, {"referenceID": 3, "context": "(2010) propose a typebased approach to this Bayesian inference similar to Brown et al. (1992), suggesting that there are", "startOffset": 74, "endOffset": 94}, {"referenceID": 15, "context": "Lee et al. (2010) demonstrate strong results with a similar model and the introduction of a one-tag-per-type constraint on inference.", "startOffset": 0, "endOffset": 18}, {"referenceID": 13, "context": "Toutanova and Johnson (2008) showed that modelling ambiguity classes can lead to positive results with a small tag-dictionary extracted from the data.", "startOffset": 14, "endOffset": 29}, {"referenceID": 7, "context": "Many improvements in part-of-speech induction over the last few years have come from the use of semi-supervised approaches in the form of projecting PoS constraints across languages with parallel corpora (Das and Petrov, 2011) or extract-", "startOffset": 204, "endOffset": 226}, {"referenceID": 16, "context": "ing them from the wiktionary (Li et al., 2012).", "startOffset": 29, "endOffset": 46}, {"referenceID": 2, "context": "The Lexicon HMM (Lex-HMM) extends the Pitman-Yor HMM (PYP-HMM) described by Blunsom and Cohn (2011). When the ambiguity class of all of the word types in the lexicon is the complete tagset, the two models are the same.", "startOffset": 76, "endOffset": 100}, {"referenceID": 20, "context": "tuitively understood to smooth the trigram transition distributions with bigram and unigram distributions in a similar manner to an ngram language model (Teh, 2006).", "startOffset": 153, "endOffset": 164}, {"referenceID": 2, "context": "Blunsom and Cohn (2011) explored two Gibbs", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Blunsom and Cohn (2011) approximates the PYP-1HMM tag posteriors for a particular sample according to heuristic fractional", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Neither of the samplers proposed by Blunsom and Cohn (2011) and briefly described in section 3.", "startOffset": 36, "endOffset": 60}, {"referenceID": 8, "context": "Thus in the next section we extend the Particle Filtering solution presented in Dubbin and Blunsom (2012) to the problem of simultaneous resampling the ambiguity class as well as the tags", "startOffset": 80, "endOffset": 106}, {"referenceID": 0, "context": "Andrieu et al. (2010) shows that to ensure the samples generated by SMC for a Gibbs sampler have the target distribution as the invariant density, the particle filter must be modified to perform a condi-", "startOffset": 0, "endOffset": 22}, {"referenceID": 5, "context": "(Christodoulopoulos et al., 2010) and BBDK10 (Berg-Kirkpatrick et al.", "startOffset": 0, "endOffset": 33}, {"referenceID": 1, "context": ", 2010) and BBDK10 (Berg-Kirkpatrick et al., 2010) *CGS10 reports that the MEMM model takes approximately 40 hours on 16 cores.", "startOffset": 19, "endOffset": 50}, {"referenceID": 18, "context": "Treebank (Marcus et al., 1993).", "startOffset": 9, "endOffset": 30}, {"referenceID": 4, "context": "For other languages we use the corpora made available for the CoNLL-X Shared Task (Buchholz and Marsi, 2006).", "startOffset": 82, "endOffset": 108}, {"referenceID": 4, "context": "ric considered most intuitive by the evaluation of Christodoulopoulos et al. (2010). M-1 measures the accuracy of the model after mapping each predicted class to its most frequent corresponding tag.", "startOffset": 51, "endOffset": 84}, {"referenceID": 4, "context": "ric considered most intuitive by the evaluation of Christodoulopoulos et al. (2010). M-1 measures the accuracy of the model after mapping each predicted class to its most frequent corresponding tag. While Christodoulopoulos et al. (2010) found Vmeasure to be more stable over the number of parts-of-speech, this effect doesn\u2019t appear when the number of tags is constant, as in our case.", "startOffset": 51, "endOffset": 238}, {"referenceID": 2, "context": "Blunsom and Cohn (2011) found that the Local PYPHMM+LM sampler is unable to mix, achieving accuracy below 50%, therefore it has been left", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "PYP-HMM columns indicate the results of word type based particle filtering with 10 and 100 particles, respectively, while the Local and 1HMM columns use the token based sampler and the 1HMM approximation described by Blunsom and Cohn (2011). The token based sampler was run for 500 iterations and the other samplers for 200.", "startOffset": 217, "endOffset": 241}, {"referenceID": 7, "context": "We intend to apply our model to recent semi-supervised approaches which induce partial tag dictionaries from parallel language data (Das and Petrov, 2011) or the Wiktionary (Li et al.", "startOffset": 132, "endOffset": 154}, {"referenceID": 16, "context": "We intend to apply our model to recent semi-supervised approaches which induce partial tag dictionaries from parallel language data (Das and Petrov, 2011) or the Wiktionary (Li et al., 2012).", "startOffset": 173, "endOffset": 190}], "year": 2014, "abstractText": "Automatically inducing the syntactic partof-speech categories for words in text is a fundamental task in Computational Linguistics. While the performance of unsupervised tagging models has been slowly improving, current state-of-the-art systems make the obviously incorrect assumption that all tokens of a given word type must share a single part-of-speech tag. This one-tag-per-type heuristic counters the tendency of Hidden Markov Model based taggers to over generate tags for a given word type. However, it is clearly incompatible with basic syntactic theory. In this paper we extend a state-ofthe-art Pitman-Yor Hidden Markov Model tagger with an explicit model of the lexicon. In doing so we are able to incorporate a soft bias towards inducing few tags per type. We develop a particle filter for drawing samples from the posterior of our model and present empirical results that show that our model is competitive with and faster than the state-of-the-art without making any unrealistic restrictions.", "creator": "TeX"}}}