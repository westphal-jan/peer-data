{"id": "1403.0157", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2014", "title": "Network Traffic Decomposition for Anomaly Detection", "abstract": "in this paper we focus on the detection of network anomalies ( like denial of service ( dos ) attacks and port scans in a unified manner. while there has been an extensive amount of research in network anomaly detection, current state of the art methods are only able to detect one logical class of anomalies at triple the cost of others. the key tool we will use is based on the spectral decomposition of a trajectory / hankel matrix which is able to detect observed deviations from both between and within correlation present in the observed network traffic data. detailed instrumentation experiments on synthetic and real network traces shows a significant apparent improvement in detection capability over competing approaches. in the measurement process we also address the issue of determining robustness of anomaly detection systems responding in roughly a principled fashion.", "histories": [["v1", "Sun, 2 Mar 2014 04:18:00 GMT  (785kb)", "http://arxiv.org/abs/1403.0157v1", "Submitted to The Journal of Data Mining and Knowledge Discovery (DAMI)"]], "COMMENTS": "Submitted to The Journal of Data Mining and Knowledge Discovery (DAMI)", "reviews": [], "SUBJECTS": "cs.LG cs.NI", "authors": ["tahereh babaie", "sanjay chawla", "sebastien ardon"], "accepted": false, "id": "1403.0157"}, "pdf": {"name": "1403.0157.pdf", "metadata": {"source": "CRF", "title": "Network Traffic Decomposition for Anomaly Detection", "authors": ["Tahereh Babaie", "Sebastien Ardon"], "emails": ["tahereh.babaie@nicta.com.au", "sanjay.chawla@sydney.edu.au", "sebastien.ardon@nicta.com.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 3.\n01 57\nv1 [\ncs .L\nG ]\n2 M\nar 2\n01 4\nKeywords Anomaly Detection \u00b7 Hankel Matrix \u00b7 SVD"}, {"heading": "1 Introduction", "text": "In its most abstract form, network traffic can be described by a time series y(t), where y represents the observed state of the traffic. For example, y(t) could simply be the total number of packets or could be a vector, where each component represents an active flow. A flow is an aggregation of packets by attributes like source and destination ip address.\nT. Babaie School of IT, University of Sydney, Sydney, NSW, Australia ATP Research Laboratory, NICTA, Alexandria, NSW, Australia E-mail: tahereh.babaie@nicta.com.au\nS. Chawla School of IT, University of Sydney, Sydney, NSW, Australia E-mail: sanjay.chawla@sydney.edu.au\nS. Ardon ATP Research Laboratory, NICTA, Alexandria, NSW, Australia E-mail: sebastien.ardon@nicta.com.au\nIn order to detect anomalies in network traffic we must first model the generative process, which gives rise to the observable time series < y(t) >. Assume that the latent variables x(t). The relationship between y(t) and x(t) can be abstractly represented by a model as y(t) = f (x(t)). We can learn the model and obtain an estimation as y\u0302 = f (x\u0302(t)). Then an anomaly occurs of time t if y(t)\u2212 y\u0302(t) is greater than a predefined threshold. In order to design the generative model we have to capture different forms of correlation between variables of the system which we describe here.\n1.1 Between and Within Flow Correlation\nAn important aspect that needs to be captured in any model of network traffic is the presence of between and within correlation in packet flows. For example, consider Figure 1(a), which shows the the time series of two flows, f1(t) and f2(t). The point labeled D is an example where the correlation within flow f1(t) flows has deviated from the expected norm. Similarly, the point labeled P is where the correlation between the two flows f1 and f2 has deviated in a localized time window. The anomaly D is an example of a Denial of Service (DoS) attack while an anomaly P is an example of port scan. Discovering events like P and D is the focus of this paper.\n1.2 The Trajectory/Hankel Matrix\nA key tool that we will use to detect correlation deviation in network traffic, is the trajectory (or Hankel) matrix that will be constructed from the observed time series (see Takens et al (1981); Broomhead and King (1986a)). For example, given two flows { f1(i), f2(i)}Ti=1, the Hankel matrix (H) of window length L < T of the two flows is given by\n\n   \nf1(1) . . . f1(L) f1(2) . . . f1(L+ 1)\n... ... ... f1(T \u2212L+ 1) . . . f1(T )\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2223\nf2(1) . . . f2(L) f2(2) . . . f2(L+ 1)\n... ... ... f2(T \u2212L+ 1) . . . f2(T )\n\n   \nNow the key insight of the paper, is that the SVD of correlation (or covariance) matrix of the Hankel matrix (H), will capture both between and within correlation in network flows. Thus a low rank decomposition of H will characterize the manifold structure M between the flows as well as help identify the anomalies which deviate from the inferred manifold structure. For example, Figure 1(b), shows the relationship between the flows f1 and f2 and also the direction of the most dominant eigenvector of the standard correlation matrix (without the time lag). This decomposition is unable to capture the port scan (P) anomaly because, P is not a simple violation of the between flow correlation but the existing correlation is violated only in a localized time window. In Figure 1(c), it is clear that a time window lag (L = 1), captures the spatial correlation in a small time window and thus the P anomaly is away from the main eigenvector. In Figure 1(d), there is no correlation violation within flow f2 and thus the P anomaly is in the direction of the main eigenvector.\nThe remainder of this paper is structured as follows. Section 3 explains the technique behind the singular spectrum analysis and its extension and compares both techniques with PCA. Section 5 presents a validation of the different analysis algorithm based on SSA on a real traffic data and analyses their capability for anomaly detection. A brief background is presented in section 6 and we discuss some conclusion remarks in section 7."}, {"heading": "2 Hankel Matrix and Generative Model", "text": "We now justify the decomposition of the Hankel matrix based on a generative model of the data. In particular we will show that if data is generated by a Linear Dyanmical System (LDS), then the SVD decomposition of the Hankel matrix can be used to estimate the LDS.\nAssume data is generated from a Linear Dynamical System (LDS) given by:\nx(t + 1) = Ax(t)+w(t) y(t) =Cx(t)+ v(t)\nwhere\n\u2013 x(t) \u2208 Rn is the system state vector, \u2013 A defines the system\u2019s dynamics, \u2013 w is the vector that captures the system error, e.g. a random vector from N (0,Q), \u2013 y(t) \u2208 Rm is the observation vector, \u2013 C) is the measurement function, \u2013 v is the vector that represents the measurement error, e.g. a random vector from\nN (0,R),\nFig.2 presents a graphical model of LDS.\nProblem 1 Assume that data is generated from an LDS governed by the equation above. Given a sequence of observations {yi}ni=1, estimate A,C,Q and R.\nTo solve the above problem, we need to define the Hankel matrix of the observations as\nH(t) =\n\n    \ny(t) y(t + 1) y(t + 2) ... y(n\u2212 \u2113+ 1) y(t + 1) y(t + 2) . . . ...\n... y(t + \u2113) . . . y(n)\n\n    \nwhere y(t) is m\u00d7 n observation at time t, and H is a \u2113\u00d7 n\u2032 where n\u2032 = n\u2212 \u2113+ 1. Equivalently, H is a Hankel matrix if and only if there exists a sequence ,s1,s2, ... such that Hi, j = si+ j\u22121 (see Iokhvidov et al (1982)). Therefore, every Hankel matrix uniquely determines a time series and every time series can be transferred into a Hankel matrix, i.e.:\nH(t \u2212 i)\u21d4 yi(t) where yi(t) = {y(i),y(i+ 1), ...,y(t), ...}. By replacing the entries of the Hankel matrix with their equivalent from the LDS:\nH(1) =\n\n   \nCAx(0) CAx(1) CAx(2) ... CAx(n\u2212 \u2113) CAx(1) CAx(2) . . .\n... ...\nCAx(\u2113\u22121) . . . CAx(n\u22121)\n\n    =\n\n   \nCAx(0) CA2x(0) CA3x(0) ... CAn\u2212\u2113+1x(0) CA2x(0) CA3x(0) . . .\n... ...\nCA\u2113x(0) . . . CAnx(0)\n\n   \n= ( CA CA2 CA3 ... CA\u2113 )T \u00b7 ( x(0) Ax(0) A2x(0) . . . An\u2212\u2113\u22122x(0) )\nDefine: P = ( CA CA2 CA3 ... CA\u2113 )T\nQ = ( x(0) Ax(0) A2x(0) . . . An\u2212\u2113\u22122x(0) )\nthen: H(1) = PQ\nThe shifted Hankel matrices can be described by:\nH(i) = PAi\u22121Q\nTo obtain the matrices A and B, perform singular value decomposition of H(1):\nH(1) =U\u03a32V T\nwhere \u03a32 is a diagonal \u2113\u00d7 \u2113 matrix containing the singular values and the \u2113 columns of U are the singular vectors. Selecting the top-k (1 < k < \u2113) singular values from the matrix \u03a32,denoted by \u03a3k, and k associated singular vectors, denoted by Uk, we define reduced rank matrices:\nPk . = Uk\u03a3k\nQk . = \u03a3kV T\nUsing the 1-shifted Hankel matrix H(2) and the reduced rank matrices Pk and Qk:\nH(2) = PkAkQk =Uk\u03a3Ak\u03a3V T\nThen the matrix Ak can be approximated as:\nAk = (Uk\u03a3k)\u22121H(2)(\u03a3kV T )\u22121\nThen, given Ak we can estimate Ck as:\nCk = P \u22121 1 Ak\nwhere P1 is the first m rows of the matrix P. Given Ak and Ck, we can estimate\n\u03b4k = y\u2212 y\u0302 = y\u2212Ckx\u0302\nAn outlier is reported whenever |\u03b4k| exceeds a predefined threshold.\nIn practice, we are able to use the decomposition of the Hankel matrix to identify outliers. Recall once again the SDV of the Hankel matrix:\nH(1) =U\u03a32V T\n= \u2211ki=1 \u03bb 1/2 i UiV \u2032 i +\u2211 \u2113 i=k+1 \u03bb 1/2 i UiV \u2032 i\nIf we define H\u0302 . = \u2211ki=1 \u03bb 1/2 i UiV \u2032 i and \u2206k . = \u2211\u2113i=k+1 \u03bb 1/2 i UiV \u2032 i then:\n\u2206k = H(1)\u2212 H\u0302 We know that every Hankel matrix is associated with a time series. Therefore if these matrices would be Hankel then we can obtain the error space. This can be performed by means of diagonal averaging procedure. The averaging over the diagonals i+ j = const of a matrix is called Hankelization. It transforms an arbitrary \u2113\u00d7n\u2032 matrix to the form of a Hankel matrix, which can be subsequently converted to a time series. A Detailed procedure of Hankeliztion is given in Appendix A."}, {"heading": "3 Multivariate Singular Spectrum Analysis", "text": "The application of SVD to Hankel matrix is known as SSA or M-SSA. The key advantage of M-SSA is its ability to succinctly capture both between (spatial) and within (temporal) correlation in the underlying network traffic flows. Here we give a step-by-step introduction to SSA, as a method of discovering anomalies.\n1. Assume the network flow volume through a router at a pre-specified level of granularity (e.g.five minutes) is given by the time series.\ny1,y2, . . . ,ym,wm+1,wm+2, . . . ,wn,yn+1,yn+2, . . .\nWe have used both y and w to indicate that the nature of traffic has changed for n\u2212m+ 1 time steps after ym. In practice we of course don\u2019t know where and when the traffic changes and is precisely what we want to infer.\n2. Choose an integer \u2113 < m, known as the embedding dimension and form the Hankel matrix for the x part of the time series.\nY =\n\n   y1 y2 . . . y\u2113 y2 y3 . . . y\u2113+1 . . . . . . . . . . . . ym\u2212\u2113+1 ym\u2212\u2113+2 . . . ym\n\n  \nWhere each Yi = (yi,yi+1, . . . ,yi+\u2113)\u2032, is of dimension \u2113. In SSA, the assumption is that Y captures the main dynamics of the network flow. We now apply the Singular Value Decomposition (SVD) of Y as follows.\n3. For the \u2113\u00d7 \u2113 covariance matrix of Y give by C = Y \u00d7Y \u2032\n4. Compute the eigendecomposition of C = [U,D] where U is matrix where each column is a eigenvector and D is the diagonal matrix of eigenvalues. The relationship between C, U and D is given as\nCU(:, i) = D(i, i)U(:, i) for each i\n5. Form an k-dimensional subspace M of R\u2113 where k \u2264 \u2113, by using the top-k eigenvectors of U , i.e., M =UsU \u2032s. The space M is where the \u201cnormal\u201d traffic lives and our objective is to look for changes in the flow which cannot be explained by M. This is achieved by projecting a sliding window of \u2113 dimensional vectors on M and raising an alarm whenever the deviation between a vector and its projection on M becomes large.\n6. For example, consider a \u2113-dim vector which contains parts of the changed traffic y\u2032is.\nz = (ym\u22121,ym,w1, . . . ,w\u2113\u2212m\u22121) \u2032.\nThen, the deviation between z and its projection on M is given by e = \u2016z\u2212Mz\u2016. Assuming that the wi\u2019s were generated by anomalous traffic, then the deviation e will be large relative to deviations caused by normal traffic.\n7. To reconstruct the refined time series we proceed in a manner inverse to the step 2. On the other hand, if the objective is to reconstruct the original time series then we have to apply a hankelization (inverse) operator. The network anomaly detection process remains unaffected by the inverse operation. More details can be found in Vautard and Ghil (1989); Ghil et al (2002); Golyandina et al (2010).\nBefore we go into further details about SSA we illustrate the key steps using a simple example.\nExample 1 Assume that a sample time series is given as\ny(t) =\n\n\n sin(.2t)+ \u03b5(t) if 1 \u2264 t \u2264 175 sin(.3t)+ \u03b5(t) if 176 \u2264 t \u2264 375 sin(.2t)+ \u03b5(t) if 376 \u2264 t \u2264 560\nHere \u03b5(t) is gaussian N (0,1) noise. Notice that there is a change in the time series between t = 176 and t = 376. Fig. 3(a and b) show the example time series without the noise and the time series with added noise. Fig. 3(c) shows the deviation of the signal for different values of \u2113 and k. It is clear that the deviation becomes larger near time step 176 and then returns to its normal value after the change signal disappears around time step 376.\n3.1 Choice of Parameters in SSA\nThe key idea in SSA is the use of a trajectory matrix Y which then factorized using SVD. The formal relationship between Y and the underlying dynamics of the time series has been extensively researched in both the statistics and physics community. The key take away from the theoretical literature is that for an appropriate choice of \u2113, the trajectory matrix will capture the appropriate dynamics of the underlying system (see Takens et al (1981); Broomhead and King (1986a,c,b)). The choice of \u2113 along with k (the dimensionality of the projected subspace) and the threshold (e) are three important parameters that need to calibrated and set. These parameters are\nlike \u201cknobs\u201d which a network administrator can use to adapt to specific network characteristics.\nExample 1 above already provides some indication of how the choices of \u2113 and k have on time series monitoring. For example, for \u2113 = 20, the deviation e is less than for other values of \u2113. This may surprising at first but notice the initial part of the time series has an intrinsic dimensionality of 1 (as it is composed of one sin term). Thus a smaller value of \u2113 is better at capturing the dynamics of the time series than a larger value \u2113= 50,70. Now consider, the two cases where L = 50 but k = 2 or k = 4. Notice that the projected error (in the middle) is almost identical but at the tails the projection error is higher for k = 2 than k = 4. This shows that while the choice of k has a significant impact on the projection error of the normal traffic, when it comes to detecting the anomalous part the method is quite robust for different choices of k. In fact this is one of the key strengths of SSA that we will exploit in the analysis of real network traffic data."}, {"heading": "4 Network Anomaly Types", "text": "A key contribution of our paper is that the approach based on M-SSA is able to detect almost all known types of network anomalies. In this section we describe the different types of common anomalies and explain why M-SSA provides subsumes other anomaly detectors. Table 1 lists the common anomalies defined using the flow as a 5- tuple (source IP address, destination IP address, source port number, destination port\nnumber, transport protocol). More details can be found in Silveira et al (2010a,b); Lakhina et al (2005, 2004a).\nA Denial of Service (DoS) attack occurs when the attacking hosts send a large number of small packets - typically TCP SYN segments - to the attacked host and service, i.e. a single IP address and port number, in order to deplete the system resources in the target host. The resulting traffic from DoS attack consists of a relatively small number of flows with large packet counts as DoS attack tools often forge the source port number. Note that the specific case of Distributed Denial of Service (DDoS) attacks is effectively the same attack, but with several source IP addresses. The number of attacking hosts however, is typically much smaller than the packet count. We thus consider DDoS to be a special case of a DoS attack, and label as such.\nPort scans are typically used by attackers to discover open ports on the target host. This is accomplished by sending small packets as connections requests to a large number of different ports on a single destination IP address. At the flow level, they are therefore characterized as an increase in the number of flows, each with a small packet count.\nLarge file transfers are characterized by a few flows with packet counts which are significantly larger than what common applications use.\nPrefix outages occurs when part of the network becomes unreachable, they can be identified when traffic from one or more IP prefixes disappears, which translates in a drop in the number of flows.\nLink outage is in a way a more severe version of Prefix outage, where the number of flows on the link drop close to zero."}, {"heading": "5 Experimental evaluation", "text": "We have evaluated our proposed approach using both real and synthetic data sets. For comparison we have implemented well known network anomaly techniques based on wavelets, kalman filtering, fourier analysis and the more recent ASTUTE method.\nThe use of synthetic data sets and simulation is a prerequisite for a rigorous evaluation strategy for network anomaly detection (Ringberg et al (2008); Soule et al (2005); Silveira et al (2010a)).\n5.1 Detection Capability\nWe evaluate the detection capability of M-SSA using two real network traces which we now describe."}, {"heading": "5.1.1 Datasets", "text": "The first traffic trace if from the Abilene network1 and has been used previously for network anomaly detection (see Silveira et al (2010a,b); Lakhina et al (2005, 2004a)). The data set consists of a one month traffic trace from a backbone router in New York during August 2007. The Juniper router used to collect the data generated sampled J-flow statistics at the rate of 1/100. The flows were aggregated at five minute intervals. The key attributes of the flow are: number of packets, number of distinct source IP addresses, number of distinct destination IP addresses, number of distinct source port numbers and number of distinct destination ports numbers.\nThe second, and more recent, traffic trace is from the MAWI (Measurement and Analysis on the WIDE Internet) archive project in Japan2. Here the data was sampled from a 150Mbps trans-pacific link between Japan and the United States for 63-hours in April 2012.\nLabelling traffic traces with anomalies is notoriously difficult. The commonly accepted method is to combine algorithmic detection with manual inspection of the\n1 Internet2 - http://www.internet2.edu/ 2 http://www.wide.ad.jp/project/wg/mawi.html\ndata. We have followed the URCA (Unsupervised Root Cause Analysis) method proposed by Silveira and Diot (2010) with a false positive rate of 2\u00d710\u22129, followed by a thorough manual inspection of the data set."}, {"heading": "5.1.2 Results", "text": "Table 3 and Fig. 9 show the results of the different methods including M-SSA. The following are the key take aways.\n1. M-SSA is capable of detecting a much wider range of anomalies regardless of their types. For the Abilene data, M-SSA was able to identify 100% of DoS attacks and over 95% port scans. Similarly on the MAWI data set the detection rate was 100% for DoS attacks and over 90% for port scans. 2. All other techniques (which were compared) can be placed in two groups: Wavelets, Kalman and Fourier have high detection rates only for DoS attacks while ASTUTE performs exceedingly well only for port scan anomalies. 3. In the Abilene data, around 7% of the anomalies are related to link outages. Here again, M-SSA has a 100% detection rate and except for Fourier, other techniques also have a high detection rate with Wavelets doing the best.\nTo understand the results better we have carried out a deeper analysis by examining the characteristic features of the anomalies. In Fig. 5 we plot the known Abilene anomalies using two features. The x-axis represents the change in packet counts between two consecutive time bins. The y-axis represents the number of distinct flows (5 tuples) in the time bin.\nThe first observation is that the set of anomalies are clustered in distinct groups, with the set of anomalies detected by Wavelet and Kalman approximately common (Wavelet is slightly better in detecting some port scans). Secondly, the Kalman filter and Wavelet techniques are not able to find anomalies caused by large number of flows with small packet counts. These includes anomalies where the rate of change in packet count in individual flows over time is small, e.g. port scans, prefix outages and file transfers. Wavelet as a time-frequency technique is able to flag sudden changes in traffic, but will miss any small variations such as port scans and absorb them in the main trend.\nThe Kalman filter technique is effective at detecting anomalies when the packet count variation over time is significant, such as DoS attacks. This is expected, as Kalman Filtering is essentially a forecasting technique in the time dimension. Another observation is that ASTUTE is not able to detect anomalies involving a few large flows (bottom right hand corner of Fig. 5), such as DoS attacks. This is also expected, as ASTUTE is not able to detect large volume change in a few number of flows, because the AAV process threshold is not violated (as the denominator of AAV is the standard deviation which will be large) as mentioned by Silveira et al (2010b); Silveira and Diot (2010).\nThe results and analysis clearly suggest, as has been noted before by Silveira et al (2010a), that a hybrid approach consisting of ASTUTE and Kalman (or Wavelet) will capture most of the anomalies. Importantly, Fig. 5 shows that the proposed M-SSA based approach is able to detect anomalies regardless of their location on the feature\nproperties map. M-SSA is able to detect significant temporal changes in traffic as well as changes in the number of flows. M-SSA searches for correlation across flows properties (ASTUTE applies the same search concept between flows), while at the same time looking for temporal variation in a lag window dimension of \u2113. ASTUTE is limited to two consecutive time bins.\n5.2 Detection Performance\nIn order to evaluate the robustness and sensitivity of M-SSA we have designed a simulation set up where we inject artificial anomalies in real traces and measure the trade-off between the true positive and false positives using ROC curves. One of the biggest challenges in network anomaly detection systems, and which has limited their widespread adoption, is the high false positive rate exhibited by most existing techniques (see Ringberg et al (2008); Axelsson (2000))."}, {"heading": "5.2.1 Simulation", "text": "Our simulation is based on real trace data augmented with anomalous traffic injected in a similar fashion as in Silveira et al (2010a); Ringberg et al (2008); Axelsson (2000). However and in addition to previous work, we build a simulation model which captures several distinctive characteristics of anomalies. We consider the distribution of time between anomalies, duration, magnitude (packet count for DoS attacks, num-\nber of flows for port scans, etc), and the anomaly type distribution (DoS, port scan, etc).\nWe first estimate the above parameters based on available observations in traffic traces. For example Fig. 6 and Fig. 7 show the histograms of these property values for DoS attacks and port scans respectively, as observed in the Abilene trace. We start the simulation assuming a non-anomalous time bin and choose the next attack time, by sampling from the empirical probability distribution of the time between anomalies. The anomaly type is then also chosen by sampling from the anomaly type distribution. At this point, a synthetic anomaly is generated by sampling from the anomaly duration and magnitude distribution, and injected into the synthetic trace. This process is repeated until the end of the simulation. The resulting trace therefore inherit the most significant statistical properties of the real data, e.g. the frequency of attacks and their magnitude."}, {"heading": "5.2.2 Results", "text": "The trade-off between false positive and true positive rate using the simulation data are captured using the ROC curve and are shown in Fig. 8. The simulation parameters for all algorithms are set as per Table 2. The ROC curves depicted in Fig. 8 show that M-SSA has higher true positive rate for a given false positive rate, compared with all other techniques. For example, for a false positive rate of 0.01%, M-SSA detects 90% of anomalies, whereas Wavelet and ASTUTE only detect 77% and 81% respectively. A Hybrid detector including Wavelets, Kalman and ASTUTE shows slightly better trade-off for a false positive rate less than 10\u22125 but M-SSA is better for the rest of interval. The Area Under Curve (AUC) which measures the overall performance of the detector has been shown in Fig. 8 (left).\n5.3 Configuration of Parameters\nWe now evaluate the impact of the parameters: Lag Window Length (\u2113), the dimensionality k of the projected space and the detection threshold q\u03b2 ."}, {"heading": "5.3.1 Lag window length (\u2113)", "text": "The key take away from the theoretical literature is that for an appropriate choice of \u2113, the Hankel matrix will capture the appropriate dynamics of the underlying system (see Takens et al (1981). According to Takens et al (1981); Broomhead and King (1986a,b) and Ghil et al (2002), the choice of \u2113 must consider the trade-off between the maximum period (frequency) resolved and the statistical confidence of the result. A large value of \u2113 will potentially better capture the long range trends but the size of the covariance matrix will be larger which will have to be estimated from a time series of effective length n\u2212 \u2113+ 1.\nThe choice of \u2113 has a significant impact on detection performance of different anomalies. DoS attacks and port scans are emblematic of two types of deviations in network traffic. DoS attacks are characterized by large changes in a (relatively) small number of flows as the attacking hosts send a large number of small packets to deplete system resources in the attacked host (see Fig. 6 and Fig. 5). Thus DoS like anomalies cause high temporal variation (within flows correlation) in the responsible flows and can be detected using techniques based on time series analysis. Port scans, in the other hand, are characterized as small increases in a large number of flows (see Fig. 7 and Fig. 5). This is required to detect for spatial correlation across flows (correlation between the flows) in order to find port scans. We run an experiment to discuss the impact of window length on capturing temporal/spatial correlation, i.e. whithin/between flow correlation, of the traffic data. ROC curves in Fig. 9a and Fig. 9b present DoS\nand port scan detection performance (separately) for varying window length. We describe the main findings learned from this experiment as follows.\n\u2013 It is clear that the detection of DoS is almost independent of the window length, see Fig. 9a. This is expected as DoS attacks cause high correlation within flows (temporal variations) and this can be always captured even if the window length is zero, i.e. the common PCA is able to report them.\n\u2013 Across flows correlation is crucially dependent of window length as shown in Fig. 9b. Thus the choice of window size has significant impact on detecting port scans. When the window length is zero the correlation across the flows can not be captured. when the window length is large across flows correlation is suppressed. What is required is a localized window where deviation from normal correlation can be detected. According to the experiment, detecting port scans is improved for window length of \u2113 = {4,8,12} (hours) while it is worsen for smaller/larger window length."}, {"heading": "5.3.2 Grouping indices (k)", "text": "Another important parameter of M-SSA affecting results is the grouping indices, i.e. which components are grouped to provide the reconstructed data. The aim of our technique is to make a decomposition of the observed traffic into the sum of underlying traffic system (can be a number of interpretable components such as a slowly varying trend, oscillatory components) and a structureless noise, as Y = X +E. The decomposition of the series Y into these two part is viable if the resulting additive components X and E are approximately separable from each other. Suppose the the full reconstructed components are denoted by Vi = Mz for i = {1,2, ...,m\u00d7 \u2113}. To\nselect which components to group, we compute the weighted correlation matrix (wcorr), where each element of the matrix \u03c1i j is defined as:\n\u03c1i j = covw(Vi,V j)\n\u03c3w(Vi)\u03c3w(V j)\nusing:\n\u03c32w(Vi) =W \u2032V \u2032 i Vi , covw(Vi,V j) =W \u2032V \u2032i V j\nwhere wt =min{t, \u2113,n\u2212\u2113} for t = {1 : n} is the weighting vector. If the absolute value of the w-correlations for two Vi and V j is small (ideally zero), so the corresponding series are almost w-orthogonal and well separable. Fig. 10 shows the absolute values of w-correlation for the first 50 reconstructed components. This is a grade matrix plot from red (corresponding to 1) to blue (corresponding to 0), which shows both the separability and dominance of components with highest eigenvalues values. This plot is useful to select how many components to select in the reconstruction phase, as we only need to select the first k components with the largest w-corr values. From Fig. 10, we observe that the absolute value of the w-correlation for first 10 components are naturally grouped, a property that is observed for both the Abilene and MAWI datasets. We therefore suggest to use the first 10 components for the reconstruction when using M-SSA. So the X = \u2211i=10i=1 Vi and residual space E = Y \u2212X . In next section we will see that how the values of w-correlation can also be checked for adjusting the decision parameter (q\u03b2 ) so that a false positive rate can be met."}, {"heading": "5.3.3 Decision Variable (q\u03b2 )", "text": "For the decision threshold value (i.e., when to raise an alarm for any anomaly investigating E space), we use the variables proposed in previous studies (see Lakhina et al (2004b); Jackson and Mudholkar (1979); Jensen and Solomon (1972))in network anomaly detection but we address the problem associated with this criteria as discussed by\nRingberg et al (2007). The threshold q\u03b2 is defined as\nq\u03b2 = Q(\u03bbk+1 : \u03bb\u2113\u00d7m,\u03b2 )\n= \u03c61[ (1\u2212\u03b2 )\n\u221a (2\u03c62h2)\n\u03c61 + 1+ \u03c62h(h\u22121) \u03c6 21 ]1/h\ndenotes the threshold for the 1\u2212\u03b2 confidence level, corresponds to a false alarm rate of \u03b2 , and\nh = 1\u2212 2\u03c61\u03c63 3\u03c622 , \u03c6i = \u2113m \u2211 j=k+1 \u03bbi for i = 1,2,3.\nBased on Jensen and Solomon (1972) the Q in the above equation follows a gaussian distribution, and this convergence is robust even when the original data deviates from a gaussian distribution. Ringberg et al (2007) had questioned the robustness of the Q metric - especially in the low false positive regime. Brauckhoff et al (2009) have shown that the main reason the metric is not robust is because the use of standard PCA results in a residual which exhibits temporal correlation. In principle the residual should correspond to noise and be completely uncorrelated. Thus by ensuring that temporal correlation (in the case of KL transform) and spatio-temporal correlation (in the case of M-SSA) is captured by the model, the Q metric is robust.\nThe w-correlation matrix computed above can help verify if the residual space, given by E = Y \u2212X where X is the reconstructed space, contains correlated elements or not. For example, the w-correlation plot in Fig. 10 clearly shows that that when X is the space spanned by Vi for i > 10, the reconstructed elements are strongly worthogonal in both Abilene and MAWI traffic, resulting in uncorrelated residuals."}, {"heading": "6 Related Work", "text": "Current network infrastructure is protected against malicious attacks by signaturebased Intrusion Detection Systems (IDS) (Roesch (1999); Paxson (1998)). However, it is well known that attackers can circumvent these systems by generating small modifications of known signatures.\nIn principle, anomaly-based detection systems (ADS) offer an attractive alterative to signature-based systems. ADS are based on the notion of \u201dstatistical normality\u201d, and malicious events are those that cause deviations from normal behavior. The major challenge is to characterize normal traffic subject to the constraint that network traffic exhibits non-stationary behavior.\nExisting techniques for ADS are based on decomposition methods of network time series. For example Lakhina et al (2004b,a, 2005) has proposed the use of Principal Component Analysis (PCA) for detection of network wide anomalies. Zhang et al (2005) has compared the use of Fourier, Wavelets and ARIMA methods for detection of link anomalies and then have used \u21131 optimization to recover the origin-destination pairs which may have caused the link anomalies to appear. Further refinements on PCA and state methods like Kalman Filtering have been extensively investigated for first extracting the normal behavior and then reporting deviations from normality as\npotential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).\nThe mathematical basis of Singular Spectrum Analysis (SSA) is the celebrated result in nonlinear dynamics due to Takens et al (1981). Taken\u2019s theorem asserts that the latent non-linear dynamics governing can be recovered using a delayed time embedding of the observable time series. The first practical use of Taken\u2019s theorem for time series analysis and the connection with spectral methods like singular value decomposition (SVD) was first proposed by Broomhead and King (1986a,c). Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002)."}, {"heading": "7 Conclusions", "text": "In this paper we have proposed a unified and robust method for network anomaly detection based on Multivariate Singular Spectrum Analysis (M-SSA). As M-SSA can detect deviations from both spatial and temporal correlation present in the data, it allows for the detection of both DoS and port scan attacks. A DoS attack is an example of temporal deviation while a port scan attack violates spatial correlation. Besides the use of M-SSA for network anomaly detection, we have carried out a comprehensive evaluation and compared M-SSA with other approaches based on wavelets, fourier analysis, kalman filtering and the recently introduced ASTUTE method. We have also carried out a rigorous analysis of the parameter configurations that accompany the use of M-SSA and address some of the important issues that have been raised in the networks community. Finally we have introduced a new labeled dataset from a large backbone link between Japan and the United States.\nAcknowledgements This work is partially supported by NICTA3. NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program."}, {"heading": "Appendix A Hankelization", "text": "The averaging over the diagonals i+ j = const of the matrices XIi is called Hankelization. The purpose of diagonal averaging is to transform a matrix to the form of a Hankel matrix, which can be subsequently converted to a time series. In other word, diagonal averaging maps matrices XIi into a time series. to be continued ... Let Hankelization operator H acting on any arbitrary matrix to turn it into a Hankle matrix in an optimal way. By applying the Hankelization procedure to all matrix components of XIi the expansion will be:\nX = XI1 + ...+XIm 3 http://nicta.com.au/\nwhere XI1 = H XI1 . Since all the matrices on the right-hand side of the expansion are Hankel matrices, each matrix uniquely specifies the time series and we thus obtain the decomposition of the original time series:\nXI1 \u2261 Y1(t) ... XIm \u2261 Ym(t)\nThe complete original series is simply spume of the thus far obtained components.\nY (t) = Y1(t)+Y2(t)+ ...+Ym(t)"}], "references": [{"title": "Monte Carlo SSA: Detecting irregular oscillations in the Presence of Colored Noise", "author": ["MR Allen", "LA Smith"], "venue": "J Climate", "citeRegEx": "Allen and Smith,? \\Q1996\\E", "shortCiteRegEx": "Allen and Smith", "year": 1996}, {"title": "The base-rate fallacy and the difficulty of intrusion detection", "author": ["S Axelsson"], "venue": "ACM Trans Inf Syst Secur", "citeRegEx": "Axelsson,? \\Q2000\\E", "shortCiteRegEx": "Axelsson", "year": 2000}, {"title": "A signal analysis of network traffic anomalies. In: IMW\u201902", "author": ["P Barford", "J Kline", "D Plonka", "A Ron"], "venue": "Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment,", "citeRegEx": "Barford et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Barford et al\\.", "year": 2002}, {"title": "Applying PCA for traffic anomaly detection: Problems and solutions", "author": ["D Brauckhoff", "K Salamatian", "M May"], "venue": null, "citeRegEx": "Brauckhoff et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brauckhoff et al\\.", "year": 2009}, {"title": "Extracting qualitative dynamics from experimental data", "author": ["D Broomhead", "GP King"], "venue": "Physica D, Nonlinear Phenomena,", "citeRegEx": "Broomhead and King,? \\Q1986\\E", "shortCiteRegEx": "Broomhead and King", "year": 1986}, {"title": "Extracting qualitative dynamics from experimental data", "author": ["D Broomhead", "GP King"], "venue": "Physica D: Nonlinear Phenomena", "citeRegEx": "Broomhead and King,? \\Q1986\\E", "shortCiteRegEx": "Broomhead and King", "year": 1986}, {"title": "On the qualitative analysis of experimental dynamical systems. Nonlinear Phenomena and Chaos S", "author": ["DS Broomhead", "GP King"], "venue": null, "citeRegEx": "Broomhead and King,? \\Q1986\\E", "shortCiteRegEx": "Broomhead and King", "year": 1986}, {"title": "Aberrant behavior detection in time series for network monitoring", "author": ["JD Brutlag"], "venue": "Proceedings of the 14th USENIX conference on System administration, USENIX Association,", "citeRegEx": "Brutlag,? \\Q2000\\E", "shortCiteRegEx": "Brutlag", "year": 2000}, {"title": "Interdecadal oscillations and the warming trend in global temperature time series", "author": ["M Ghil", "R Vautard"], "venue": null, "citeRegEx": "Ghil and Vautard,? \\Q1991\\E", "shortCiteRegEx": "Ghil and Vautard", "year": 1991}, {"title": "Advanced spectral methods for climatic time series", "author": ["M Ghil", "MR Allen", "MD Dettinger", "K Ide", "D Kondrashov", "ME Mann", "AW Robertson", "A Saunders", "Y Tian", "F Varadi", "P Yiou"], "venue": "Reviews of Geophysics", "citeRegEx": "Ghil et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ghil et al\\.", "year": 2002}, {"title": "Analysis of Time Series Structure: SSA and Related Techniques", "author": ["N Golyandina", "V Nekrutkin", "A Zhigljavsky"], "venue": "Chapman & Hall/CRC Monographs on Statistics & Applied Probability,", "citeRegEx": "Golyandina et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golyandina et al\\.", "year": 2010}, {"title": "Pictures P (1982) Hankel and Toeplitz matrices and forms: algebraic theory", "author": ["IS Iokhvidov", "J Nicholson", "D Keaton", "W Beatty", "E Herrman", "T Griffith", "J Kosinski"], "venue": null, "citeRegEx": "Iokhvidov et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Iokhvidov et al\\.", "year": 1982}, {"title": "Control Procedures for Residuals Associated with Principal Component Analysis", "author": ["JE Jackson", "GS Mudholkar"], "venue": null, "citeRegEx": "Jackson and Mudholkar,? \\Q1979\\E", "shortCiteRegEx": "Jackson and Mudholkar", "year": 1979}, {"title": "A gaussian approximation to the distribution of a definite quadratic form", "author": ["DR Jensen", "H Solomon"], "venue": "Journal of the American Statistical Association", "citeRegEx": "Jensen and Solomon,? \\Q1972\\E", "shortCiteRegEx": "Jensen and Solomon", "year": 1972}, {"title": "Sketch-based change detection: methods, evaluation, and applications", "author": ["B Krishnamurthy", "S Sen", "Y Zhang", "Y Chen"], "venue": "Proceedings of the 3rd ACM SIGCOMM conference on Internet measurement,", "citeRegEx": "Krishnamurthy et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Krishnamurthy et al\\.", "year": 2003}, {"title": "Characterization of network-wide anomalies in traffic flows", "author": ["A Lakhina", "M Crovella", "C Diot"], "venue": "Proceedings of the 4th ACM SIGCOMM conference on Internet measurement,", "citeRegEx": "Lakhina et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lakhina et al\\.", "year": 2004}, {"title": "Diagnosing network-wide traffic anomalies", "author": ["A Lakhina", "M Crovella", "C Diot"], "venue": "SIGCOMM Comput Commun Rev", "citeRegEx": "Lakhina et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lakhina et al\\.", "year": 2004}, {"title": "Mining anomalies using traffic feature distributions", "author": ["A Lakhina", "M Crovella", "C Diot"], "venue": "SIGCOMM Comput. Commun. Rev.,", "citeRegEx": "Lakhina et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lakhina et al\\.", "year": 2005}, {"title": "Network anomaly detection based on wavelet analysis. EURASIP Journal on Advances in Signal Processing - Special issue on signal processing applications in network intrusion detection systems 2009:4:1\u20134:16", "author": ["W Lu", "AA Ghorbani"], "venue": null, "citeRegEx": "Lu and Ghorbani,? \\Q2009\\E", "shortCiteRegEx": "Lu and Ghorbani", "year": 2009}, {"title": "Bro: a system for detecting network intruders in real-time", "author": ["Tahereh Babaie"], "venue": "Paxson V", "citeRegEx": "Babaie,? \\Q1998\\E", "shortCiteRegEx": "Babaie", "year": 1998}, {"title": "Sensitivity of pca for traffic anomaly detection", "author": ["H Ringberg", "A Soule", "J Rexford", "C Diot"], "venue": "USENIX Association,", "citeRegEx": "Ringberg et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ringberg et al\\.", "year": 2007}, {"title": "The need for simulation in evaluating anomaly detectors", "author": ["H Ringberg", "M Roughan", "J Rexford"], "venue": "RICS Perform Eval Rev", "citeRegEx": "Ringberg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ringberg et al\\.", "year": 2008}, {"title": "Astute: detecting a different class of traffic anomalies", "author": ["F Silveira", "C Diot", "N Taft", "R Govindan"], "venue": "IEEE INFOCOM 2010 conference,", "citeRegEx": "Silveira et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Silveira et al\\.", "year": 2010}, {"title": "Detecting traffic anomalies using an equilibrium property", "author": ["F Silveira", "C Diot", "N Taft", "R Govindan"], "venue": "Proceedings of the ACM SIGCOMM 2010 conference,", "citeRegEx": "Silveira et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Silveira et al\\.", "year": 2010}, {"title": "Combining filtering and statistical methods for anomaly detection", "author": ["A Soule", "K Salamatian", "N Taft"], "venue": "Proceedings of the ACM SIGMETRICS 2010 conference,", "citeRegEx": "Soule et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Soule et al\\.", "year": 2005}, {"title": "Detecting strange attractors in turbulence", "author": ["F Takens", "D Rand", "LS Young"], "venue": null, "citeRegEx": "Takens et al\\.,? \\Q1981\\E", "shortCiteRegEx": "Takens et al\\.", "year": 1981}, {"title": "Singular spectrum analysis in nonlinear dynamics, with applications to paleo", "author": ["R Vautard", "M Ghil"], "venue": "ematics,", "citeRegEx": "Vautard and Ghil,? \\Q1989\\E", "shortCiteRegEx": "Vautard and Ghil", "year": 1989}, {"title": "Singular-spectrum analysis: a toolkit for short, noisy chaotic signals", "author": ["R Vautard", "P Yiou", "M Ghil"], "venue": "Physica D, Nonlinear Phenomena,", "citeRegEx": "Vautard et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Vautard et al\\.", "year": 1992}, {"title": "Spectral analysis of climate data. Surveys in Geophysics", "author": ["P Yiou", "E Baert", "M Loutre"], "venue": "Phys D", "citeRegEx": "Yiou et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Yiou et al\\.", "year": 1996}], "referenceMentions": [{"referenceID": 4, "context": "2 The Trajectory/Hankel Matrix A key tool that we will use to detect correlation deviation in network traffic, is the trajectory (or Hankel) matrix that will be constructed from the observed time series (see Takens et al (1981); Broomhead and King (1986a)).", "startOffset": 229, "endOffset": 256}, {"referenceID": 26, "context": "More details can be found in Vautard and Ghil (1989); Ghil et al (2002); Golyandina et al (2010).", "startOffset": 29, "endOffset": 53}, {"referenceID": 26, "context": "More details can be found in Vautard and Ghil (1989); Ghil et al (2002); Golyandina et al (2010).", "startOffset": 29, "endOffset": 72}, {"referenceID": 26, "context": "More details can be found in Vautard and Ghil (1989); Ghil et al (2002); Golyandina et al (2010). Before we go into further details about SSA we illustrate the key steps using a simple example.", "startOffset": 29, "endOffset": 97}, {"referenceID": 1, "context": "One of the biggest challenges in network anomaly detection systems, and which has limited their widespread adoption, is the high false positive rate exhibited by most existing techniques (see Ringberg et al (2008); Axelsson (2000)).", "startOffset": 215, "endOffset": 231}, {"referenceID": 1, "context": "Our simulation is based on real trace data augmented with anomalous traffic injected in a similar fashion as in Silveira et al (2010a); Ringberg et al (2008); Axelsson (2000). However and in addition to previous work, we build a simulation model which captures several distinctive characteristics of anomalies.", "startOffset": 159, "endOffset": 175}, {"referenceID": 4, "context": "According to Takens et al (1981); Broomhead and King (1986a,b) and Ghil et al (2002), the choice of l must consider the trade-off between the maximum period (frequency) resolved and the statistical confidence of the result.", "startOffset": 34, "endOffset": 85}, {"referenceID": 12, "context": ", when to raise an alarm for any anomaly investigating E space), we use the variables proposed in previous studies (see Lakhina et al (2004b); Jackson and Mudholkar (1979); Jensen and Solomon (1972))in network anomaly detection but we address the problem associated with this criteria as discussed by", "startOffset": 143, "endOffset": 172}, {"referenceID": 12, "context": ", when to raise an alarm for any anomaly investigating E space), we use the variables proposed in previous studies (see Lakhina et al (2004b); Jackson and Mudholkar (1979); Jensen and Solomon (1972))in network anomaly detection but we address the problem associated with this criteria as discussed by", "startOffset": 143, "endOffset": 199}, {"referenceID": 13, "context": "Based on Jensen and Solomon (1972) the Q in the above equation follows a gaussian distribution, and this convergence is robust even when the original data deviates from a gaussian distribution.", "startOffset": 9, "endOffset": 35}, {"referenceID": 13, "context": "Based on Jensen and Solomon (1972) the Q in the above equation follows a gaussian distribution, and this convergence is robust even when the original data deviates from a gaussian distribution. Ringberg et al (2007) had questioned the robustness of the Q metric - especially in the low false positive regime.", "startOffset": 9, "endOffset": 216}, {"referenceID": 13, "context": "Based on Jensen and Solomon (1972) the Q in the above equation follows a gaussian distribution, and this convergence is robust even when the original data deviates from a gaussian distribution. Ringberg et al (2007) had questioned the robustness of the Q metric - especially in the low false positive regime. Brauckhoff et al (2009) have shown that the main reason the metric is not robust is because the use of standard PCA results in a residual which exhibits temporal correlation.", "startOffset": 9, "endOffset": 333}, {"referenceID": 12, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).", "startOffset": 47, "endOffset": 70}, {"referenceID": 12, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).", "startOffset": 47, "endOffset": 90}, {"referenceID": 3, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).", "startOffset": 91, "endOffset": 106}, {"referenceID": 3, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).", "startOffset": 91, "endOffset": 134}, {"referenceID": 3, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)).", "startOffset": 91, "endOffset": 154}, {"referenceID": 3, "context": "potential anomalies (see Barford et al (2002); Lu and Ghorbani (2009); Zhang et al (2005); Brutlag (2000); Krishnamurthy et al (2003); Soule et al (2005)). The mathematical basis of Singular Spectrum Analysis (SSA) is the celebrated result in nonlinear dynamics due to Takens et al (1981). Taken\u2019s theorem asserts that the latent non-linear dynamics governing can be recovered using a delayed time embedding of the observable time series.", "startOffset": 91, "endOffset": 289}, {"referenceID": 3, "context": "The first practical use of Taken\u2019s theorem for time series analysis and the connection with spectral methods like singular value decomposition (SVD) was first proposed by Broomhead and King (1986a,c). Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 171, "endOffset": 344}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 167}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 192}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 217}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 242}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 261}, {"referenceID": 0, "context": "Further application of the technique in climate and geophysical time series analysis has been extensively investigated in Vautard et al (1992); Allen and Smith (1996); Golyandina et al (2010); Vautard and Ghil (1989); Ghil and Vautard (1991); Yiou et al (1996); Ghil et al (2002).", "startOffset": 144, "endOffset": 280}], "year": 2014, "abstractText": "In this paper we focus on the detection of network anomalies like Denial of Service (DoS) attacks and port scans in a unified manner. While there has been an extensive amount of research in network anomaly detection, current state of the art methods are only able to detect one class of anomalies at the cost of others. The key tool we will use is based on the spectral decomposition of a trajectory/hankel matrix which is able to detect deviations from both between and within correlation present in the observed network traffic data. Detailed experiments on synthetic and real network traces shows a significant improvement in detection capability over competing approaches. In the process we also address the issue of robustness of anomaly detection systems in a principled fashion.", "creator": "LaTeX with hyperref package"}}}