{"id": "1403.6636", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Mar-2014", "title": "Sign Language Lexical Recognition With Propositional Dynamic Logic", "abstract": "this paper explores the use of propositional dynamic logic ( pdl ) as a suitable formal framework for tasks describing sign language ( sl ), the language of deaf people, in the context of natural machine language processing. naive sls are visual, complete, standalone languages approaches which are just traditionally as brightly expressive learners as oral languages. signs in sl usually correspond to sequences of highly specific body postures interleaved or with movements, which make reference to real world objects, characters or situations. out here we propose a broader formal representation of sl signs, that will help us with the analysis of automatically - collected spanish hand tracking measurement data from french sign language ( fsl ) video corpora. we further show publicly how such a representation could help us with the design of computer aided sl verification tools, which in turn today would bring us closer to the development of devised an automatic recognition system algorithm for these languages.", "histories": [["v1", "Wed, 26 Mar 2014 11:47:37 GMT  (6302kb,D)", "http://arxiv.org/abs/1403.6636v1", "6 pages, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), August, 2013"]], "COMMENTS": "6 pages, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), August, 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["arturo curiel", "christophe collet 0002"], "accepted": true, "id": "1403.6636"}, "pdf": {"name": "1403.6636.pdf", "metadata": {"source": "CRF", "title": "Sign Language Lexical Recognition With Propositional Dynamic Logic", "authors": ["Arturo Curiel", "Paul Sabatier", "Christophe Collet"], "emails": ["curiel@irit.fr", "collet@irit.fr"], "sections": [{"heading": "1 Introduction", "text": "Sign languages (SL), the vernaculars of deaf people, are complete, rich, standalone communication systems which have evolved in parallel with oral languages (Valli and Lucas, 2000). However, in contrast to the last ones, research in automatic SL processing has not yet managed to build a complete, formal definition oriented to their automatic recognition (Cuxac and Dalle, 2007). In SL, both hands and nonmanual features (NMF), e.g. facial muscles, can convey information with their placements,\n\u2217Supported by CONACYT (Mexico) scholarship program.\nconfigurations and movements. These particular conditions can difficult the construction of a formal description with common natural language processing (NLP) methods, since the existing modeling techniques are mostly designed to work with one-channel sound productions inherent to oral languages, rather than with the multi-channel partially-synchronized information induced by SLs.\nOur research strives to address the formalization problem by introducing a logical language that lets us represent SL from the lowest level, so as to render the recognition task more approachable. For this, we use an instance of a formal logic, specifically Propositional Dynamic Logic (PDL), as a possible description language for SL signs.\nFor the rest of this section, we will present a brief introduction to current research efforts in the area. Section 2 presents a general description of our formalism, while section 3 shows how our work can be used when confronted with real world data. Finally, section 4 present our final observations and future work.\nImages for the examples where taken from (DictaSign, 2012) corpus."}, {"heading": "1.1 Current Sign Language Research", "text": "Extensive efforts have been made to achieve efficient automatic capture and representation of the subtle nuances commonly present in sign language discourse (Ong and Ranganath, 2005). Research ranges from the development of hand and body trackers (Dreuw et al., 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006). Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff\nar X\niv :1\n40 3.\n66 36\nv1 [\ncs .C\nL ]\n2 6\nM ar\n2 01\n4\net al., 2005; Meir et al., 2006; Wittmann, 1991), so as to gain understanding of the underlying mechanisms of SL communication.\nWorks like (Losson and Vannobel, 1998) deal with the creation of a lexical description oriented to computer-based sign animation. Report (Filhol, 2009) describes a lexical specification to address the same problem. Both propose a thoroughly geometrical parametric encoding of signs, thus leaving behind meaningful information necessary for recognition and introducing data beyond the scope of recognition. This complicates the reutilization of their formal descriptions. Besides, they don\u2019t take in account the presence of partial information. Treating partiality is important for us, since it is often the case with automatic tools that incomplete or unrecognizable information arises. Finally, little to no work has been directed towards the unification of raw collected data from SL corpora with higher level descriptions (Dalle, 2006)."}, {"heading": "2 Propositional Dynamic Logic for", "text": "SL\nPropositional Dynamic Logic (PDL) is a multimodal logic, first defined by (Fischer and Ladner, 1979). It provides a language for describing programs, their correctness and termination, by allowing them to be modal operators. We work with our own variant of this logic, the Propositional Dynamic Logic for Sign Language (PDLSL), which is just an instantiation of PDL where we take signers\u2019 movements as programs.\nOur sign formalization is based on the approach of (Liddell and Johnson, 1989) and (Filhol, 2008). They describe signs as sequences of immutable key postures and movement transitions.\nIn general, each key posture will be characterized by the concurrent parametric state of each body articulator over a time-interval. For us, a body articulator is any relevant body part involved in signing. The parameters taken in account can vary from articulator to articulator, but most of the time they comprise their configurations, orientations and their placement within one or more places of articulation. Transitions will correspond to the movements executed between fixed postures."}, {"heading": "2.1 Syntax", "text": "We need to define some primitive sets that will limit the domain of our logical language.\nDefinition 2.1 (Sign Language primitives). Let BSL = {D,W,R,L} be the set of relevant body articulators for SL, where D, W, R and L represent the dominant, weak, right and left hands, respectively. Both D and W can be aliases for the right or left hands, but they change depending on whether the signer is right-handed or left-handed, or even depending on the context. Let \u03a8 be the two-dimensional projection of a human body skeleton, seen by the front. We define the set of places of articulation for SL as \u039bSL = {HEAD, CHEST, NEUTRAL, . . .}, such that for each \u03bb \u2208 \u039bSL, \u03bb is a sub-plane of \u03a8, as shown graphically in figure 1. Let CSL be the set of possible morphological configurations for a hand. Let \u2206 = {\u2191,\u2197,\u2192,\u2198, \u2193,\u2199,\u2190,\u2196} be the set of relative directions from the signer\u2019s point of view, where each arrow represents one of eight possible two-dimensional direction vectors that share the same origin. For vector \u03b4 \u2208 \u2206, we define vector \u2190\u2212 \u03b4 as the same as \u03b4 but with the inverted abscissa axis, such that \u2190\u2212 \u03b4 \u2208 \u2206. Let vector \u03b4\u0302 indicate movement with respect to the dominant or weak hand in the following manner:\n\u03b4\u0302 = { \u03b4 if D \u2261 R or W \u2261 L \u2190\u2212 \u03b4 if D \u2261 L or W \u2261 R\nFinally, let \u2212\u2192v1 and \u2212\u2192v2 be any two vectors with the same origin. We denote the rotation angle between the two as \u03b8(\u2212\u2192v1 ,\u2212\u2192v2).\nNow we define the set of atomic propositions that we will use to characterize fixed states, and a set of atomic actions to describe movements.\nDefinition 2.2 (Atomic Propositions for SL Body Articulators \u03a6SL). The set of atomic propositions for SL articulators (\u03a6SL) is defined as:\n\u03a6SL = {\u03b21\u03b4\u03b22 ,\u039e \u03b21 \u03bb , T \u03b21 \u03b22 ,F\u03b21c ,\u2220\u03b4\u03b21}\nwhere \u03b21, \u03b22 \u2208 BSL, \u03b4 \u2208 \u2206, \u03bb \u2208 \u039bSL and c \u2208 CSL.\nIntuitively, \u03b21\u03b4\u03b22 indicates that articulator \u03b21 is placed in relative direction \u03b4 with respect to articulator \u03b22. Let the current place of articulation of \u03b22 be the origin point of \u03b22\u2019s Cartesian system (C\u03b22). Let vector \u2212\u2192 \u03b21 describe the current place of articulation of \u03b21 in C\u03b22. Proposition \u03b21\u03b4\u03b22 holds when \u2200\n\u2212\u2192v \u2208 \u2206, \u03b8( \u2212\u2192 \u03b21, \u03b4) \u2264 \u03b8( \u2212\u2192 \u03b21, \u2212\u2192v ).\n\u039e\u03b21\u03bb asserts that articulator \u03b21 is located in \u03bb. T \u03b21\u03b22 is active whenever articulator \u03b21 physically touches articulator \u03b22. F\u03b21c indicates that c is the morphological configuration of articulator \u03b21. Finally, \u2220\u03b4\u03b21 means that an articulator \u03b21 is oriented towards direction \u03b4 \u2208 \u2206. For hands, \u2220\u03b4\u03b21 will hold whenever the vector perpendicular to the plane of the palm has the smallest rotation angle with respect to \u03b4.\nDefinition 2.3 (Atomic Actions for SL Body Articulators \u03a0SL). The atomic actions for SL articulators ( \u03a0SL) are given by the following set:\n\u03a0SL = {\u03b4\u03b21 ,!\u03b21}\nwhere \u03b4 \u2208 \u2206 and \u03b21 \u2208 BSL. Let \u03b21\u2019s position before movement be the origin of \u03b21\u2019s Cartesian system (C\u03b21) and \u2212\u2192 \u03b21 be the position vector of \u03b21 in C\u03b21 after moving. Action \u03b4\u03b21 indicates that \u03b21 moves in relative direction \u03b4 in C\u03b21 if \u2200 \u2212\u2192v \u2208 \u2206, \u03b8( \u2212\u2192 \u03b21, \u03b4) \u2264 \u03b8( \u2212\u2192 \u03b21, \u2212\u2192v ).\nAction !\u03b21 occurs when articulator \u03b21 moves rapidly and continuously (thrills) with-\nout changing it\u2019s current place of articulation.\nDefinition 2.4 (Action Language for SL Body Articulators ASL). The action language for body articulators (ASL) is given by the following rule:\n\u03b1 ::= \u03c0 | \u03b1 \u2229 \u03b1 | \u03b1 \u222a \u03b1 | \u03b1;\u03b1 | \u03b1\u2217\nwhere \u03c0 \u2208 \u03a0SL. Intuitively, \u03b1 \u2229 \u03b1 indicates the concurrent execution of two actions, while \u03b1 \u222a \u03b1 means that at least one of two actions will be nondeterministically executed. Action \u03b1;\u03b1 describes the sequential execution of two actions. Finally, action \u03b1\u2217 indicates the reflexive transitive closure of \u03b1.\nDefinition 2.5 (Language PDLSL ). The formulae \u03d5 of PDLSL are given by the following rule:\n\u03d5 ::= > | p | \u00ac\u03d5 | \u03d5 \u2227 \u03d5 | [\u03b1]\u03d5\nwhere p \u2208 \u03a6SL, \u03b1 \u2208 ASL."}, {"heading": "2.2 Semantics", "text": "PDLSL formulas are interpreted over labeled transition systems (LTS), in the spirit of the possible worlds model introduced by (Hintikka, 1962). Models correspond to connected graphs representing key postures and transitions: states are determined by the values of their propositions, while edges represent sets of executed movements. Here we present only a small extract of the logic semantics.\nDefinition 2.6 (Sign Language Utterance Model USL). A sign language utterance model (USL), is a tuple USL = (S,R, J\u00b7K\u03a0SL , J\u00b7K\u03a6SL) where:\n\u2022 S is a non-empty set of states\n\u2022 R is a transition relation R \u2286 S\u00d7S where, \u2200s \u2208 S, \u2203s\u2032 \u2208 S such that (s, s\u2032) \u2208 R.\n\u2022 J\u00b7K\u03a0SL : \u03a0SL \u2192 R, denotes the function mapping actions to the set of binary relations.\n\u2022 J\u00b7K\u03a6SL : S \u2192 2\u03a6SL , maps each state to a set of atomic propositions.\nWe also need to define a structure over sequences of states to model internal dependencies between them, nevertheless we decided to omit the rest of our semantics, alongside satisfaction conditions, for the sake of readability."}, {"heading": "3 Use Case: Semi-Automatic Sign Recognition", "text": "We now present an example of how we can use our formalism in a semi-automatic sign recognition system. Figure 2 shows a simple module diagram exemplifying information flow in the system\u2019s architecture. We proceed to briefly describe each of our modules and how they work together."}, {"heading": "3.1 Tracking and Segmentation Module", "text": "The process starts by capturing relevant information from video corpora. We use an existing head and hand tracker expressly developed for SL research (Gonzalez and Collet, 2011). This tool analyses individual video instances, and returns the frame-by-frame positions of the tracked articulators. By using this information, the module can immediately calculate speeds and directions on the fly for each hand.\nThe module further employs the method proposed by the authors in (Gonzalez and Collet, 2012) to achieve sub-lexical segmentation from the previously calculated data. Like them, we use the relative velocity between hands to identify when hands either move at the same time, independently or don\u2019t move at all. With these, we can produce a set of possible key postures and transitions that will serve as input to the modeling module."}, {"heading": "3.2 Model Extraction Module", "text": "This module calculates a propositional state for each static posture, where atomic PDLSL\nformulas codify the information tracked in the previous part. Detected movements are interpreted as PDLSL actions between states.\nFigure 3 shows an example of the process. Here, each key posture is codified into propositions acknowledging the hand positions with respect to each other (R\u2190L ), their place of articulation (e.g. \u201cleft hand floats over the torse\u201d with \u039eLTORSE), their configuration (e.g. \u201cright hand is open\u201d with FROPENPALM_CONFIG) and their movements (e.g. \u201cleft hand moves to the upleft direction\u201d with \u2197L).\nThis module also checks that the generated graph is correct: it will discard simple tracking errors to ensure that the resulting LTS will remain consistent."}, {"heading": "3.3 Verification Module", "text": "First of all, the verification module has to be loaded with a database of sign descriptions encoded as PDLSL formulas. These will characterize the specific sequence of key postures that morphologically describe a sign. For example, let\u2019s take the case for sign \u201croute\u201d in FSL, shown in figure 4, with the following PDLSL formulation,\nExample 3.1 (ROUTEFSL formula).\n(\u039eRFACE \u2227 \u039eLFACE \u2227 L\u2192R \u2227 FRCLAMP \u2227 FLCLAMP \u2227 T RL )\u2192 [\u2190R \u2229 \u2192L](L\u2192R \u2227 FRCLAMP \u2227 FLCLAMP \u2227 \u00acT RL )\n(1)\nFormula (1) describes ROUTEFSL as a sign with two key postures, connected by a twohand simultaneous movement (represented with operator \u2229). It also indicates the position of each hand, their orientation, whether they touch and their respective configurations (in this example, both hold the same CLAMP configuration).\nThe module can then verify whether a sign formula in the lexical database holds in any sub-sequence of states of the graph generated in the previous step. Algorithm 1 sums up the process.\nAlgorithm 1 PDLSL Verification Algorithm Require: SL modelMSL Require: connected graph GSL Require: lexical database DBSL 1: Proposals_For[state_qty] 2: for state s \u2208 GSL do 3: for sign \u03d5 \u2208 DBSL where s \u2208 \u03d5 do 4: if MSL, s |= \u03d5 then 5: Proposals_For[s].append(\u03d5) 6: end if 7: end for 8: end for 9: return Proposals_For\nFor each state, the algorithm returns a set of possible signs. Expert users (or higher level algorithms) can further refine the process by introducing additional information previously missed by the tracker."}, {"heading": "4 Conclusions and Future Work", "text": "We have shown how a logical language can be used to model SL signs for semi-automatic recognition, albeit with some restrictions. The traits we have chosen to represent were imposed by the limits of the tracking tools we had to our disposition, most notably working\nwith 2D coordinates. With these in mind, we tried to design something flexible that could be easily adapted by computer scientists and linguists alike. Our primitive sets, were intentionally defined in a very general fashion due to the same reason: all of the perceived directions, articulators and places of articulation can easily change their domains, depending on the SL we are modeling or the technological constraints we have to deal with. Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.\nFrom the application side, we still need to create an extensive sign database codified in PDLSL and try recognition on other corpora, with different tracking information. For verification and model extraction, further optimizations are expected, including the handling of data inconsistencies and repairing broken queries when verifying the graph.\nRegarding our theoretical issues, future work will be centered in improving our language to better comply with SL research. This includes adding new features, like incorporating probability representation to improve recognition. We also expect to finish the definition of our formal semantics, as well as proving correction and complexity of our algorithms."}], "references": [{"title": "The paradox of sign language morphology", "author": ["Aronoff et al.2005] Mark Aronoff", "Irit Meir", "Wendy Sandler"], "venue": null, "citeRegEx": "Aronoff et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Aronoff et al\\.", "year": 2005}, {"title": "Probl\u00e9matique des chercheurs en traitement automatique des langues des signes, volume 48 of Traitement Automatique des Langues", "author": ["Cuxac", "Dalle2007] Christian Cuxac", "Patrice Dalle"], "venue": "Lavoisier,", "citeRegEx": "Cuxac et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cuxac et al\\.", "year": 2007}, {"title": "High level models for sign language analysis by a vision system. In Workshop on the Representation and Processing of Sign Language: Lexicographic Matters and Didactic Scenarios (LREC), Italy, ELDA, page", "author": ["Patrice Dalle"], "venue": null, "citeRegEx": "Dalle.,? \\Q2006\\E", "shortCiteRegEx": "Dalle.", "year": 2006}, {"title": "Enhancing a sign", "author": ["Dreuw et al.2009] Philippe Dreuw", "Daniel Stein", "Hermann Ney"], "venue": null, "citeRegEx": "Dreuw et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dreuw et al\\.", "year": 2009}, {"title": "The SignSpeak project - bridging the gap between signers and speakers", "author": ["Dreuw et al.2010] Philippe Dreuw", "Hermann Ney", "Gregorio Martinez", "Onno Crasborn", "Justus Piater", "Jose Miguel Moya", "Mark Wheatley"], "venue": null, "citeRegEx": "Dreuw et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dreuw et al\\.", "year": 2010}, {"title": "Mod\u00e8le descriptif des signes pour un traitement automatique des langues des signes", "author": ["Michael Filhol"], "venue": "Ph.D. thesis,", "citeRegEx": "Filhol.,? \\Q2008\\E", "shortCiteRegEx": "Filhol.", "year": 2008}, {"title": "Zebedee: a lexical description model for sign language synthesis", "author": ["Michael Filhol"], "venue": null, "citeRegEx": "Filhol.,? \\Q2009\\E", "shortCiteRegEx": "Filhol.", "year": 2009}, {"title": "Propositional dynamic logic of regular programs", "author": ["Fischer", "Ladner1979] Michael J. Fischer", "Richard E. Ladner"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Fischer et al\\.,? \\Q1979\\E", "shortCiteRegEx": "Fischer et al\\.", "year": 1979}, {"title": "Robust tracking for processing of videos of communication\u2019s gestures. GestureBased Human-Computer Interaction and Simulation, page 93\u2013101", "author": ["Gianni", "Dalle2009] Fr\u00e9d\u00e9ric Gianni", "Patrice Dalle"], "venue": null, "citeRegEx": "Gianni et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gianni et al\\.", "year": 2009}, {"title": "Robust body parts tracking using particle filter and dynamic template", "author": ["Gonzalez", "Collet2011] Matilde Gonzalez", "Christophe Collet"], "venue": "In 2011 18th IEEE International Conference on Image Processing (ICIP),", "citeRegEx": "Gonzalez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonzalez et al\\.", "year": 2011}, {"title": "Sign segmentation using dynamics and hand configuration for semiautomatic annotation of sign language corpora", "author": ["Gonzalez", "Collet2012] Matilde Gonzalez", "Christophe Collet"], "venue": null, "citeRegEx": "Gonzalez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gonzalez et al\\.", "year": 2012}, {"title": "HamNoSys\u2014Representing sign language data in language resources and language processing contexts", "author": ["Thomas Hanke"], "venue": "In Proceedings of the Workshop", "citeRegEx": "Hanke.,? \\Q2004\\E", "shortCiteRegEx": "Hanke.", "year": 2004}, {"title": "Analyse s\u00e9mantico-cognitive d\u2019\u00e9nonc\u00e9s en Langue des Signes Fran\\ccaise pour une g\u00e9n\u00e9ration automatique de s\u00e9quences gestuelles", "author": ["Fanch Lejeune"], "venue": "Ph.D. thesis,", "citeRegEx": "Lejeune.,? \\Q2004\\E", "shortCiteRegEx": "Lejeune.", "year": 2004}, {"title": "Using signing space as a representation for sign language processing", "author": ["Lenseigne", "Dalle2006] Boris Lenseigne", "Patrice Dalle"], "venue": null, "citeRegEx": "Lenseigne et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lenseigne et al\\.", "year": 2006}, {"title": "American sign language: The phonological base", "author": ["Liddell", "Johnson1989] S.K. Liddell", "R.E. Johnson"], "venue": null, "citeRegEx": "Liddell et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Liddell et al\\.", "year": 1989}, {"title": "Sign language formal description and synthesis", "author": ["Losson", "Vannobel1998] Olivier Losson", "Jean-Marc Vannobel"], "venue": "INT.JOURNAL OF VIRTUAL REALITY,", "citeRegEx": "Losson et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Losson et al\\.", "year": 1998}, {"title": "Re-thinking sign language verb classes: the body as subject. In Sign Languages: Spinning and Unraveling the Past, Present and Future", "author": ["Meir et al.2006] Irit Meir", "Carol Padden", "Mark Aronoff", "Wendy Sandler"], "venue": null, "citeRegEx": "Meir et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Meir et al\\.", "year": 2006}, {"title": "Automatic sign language analysis: a survey and the future beyond lexical meaning", "author": ["Ong", "Ranganath2005] Sylvie C.W. Ong", "Surendra Ranganath"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Ong et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ong et al\\.", "year": 2005}, {"title": "Sign language structure: An outline of the visual communication systems of the american deaf", "author": ["William C. Stokoe"], "venue": "Journal of Deaf Studies and Deaf Education,", "citeRegEx": "Stokoe.,? \\Q2005\\E", "shortCiteRegEx": "Stokoe.", "year": 2005}, {"title": "Linguistics of American Sign Language Text, 3rd Edition: An Introduction", "author": ["Valli", "Lucas2000] Clayton Valli", "Ceil Lucas"], "venue": null, "citeRegEx": "Valli et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Valli et al\\.", "year": 2000}, {"title": "Classification linguistique des langues sign\u00e9es non vocalement", "author": ["Henri Wittmann"], "venue": "Revue que\u0301be\u0301coise de linguistique the\u0301orique et applique\u0301e,", "citeRegEx": "Wittmann.,? \\Q1991\\E", "shortCiteRegEx": "Wittmann.", "year": 1991}], "referenceMentions": [{"referenceID": 3, "context": "Research ranges from the development of hand and body trackers (Dreuw et al., 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006).", "startOffset": 63, "endOffset": 107}, {"referenceID": 12, "context": ", 2009; Gianni and Dalle, 2009), to the design of high level SL representation models (Lejeune, 2004; Lenseigne and Dalle, 2006).", "startOffset": 86, "endOffset": 128}, {"referenceID": 4, "context": "Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff ar X iv :1 40 3.", "startOffset": 123, "endOffset": 157}, {"referenceID": 18, "context": "Linguistic research in the area has focused on the characterization of corporal expressions into meaningful transcriptions (Dreuw et al., 2010; Stokoe, 2005) or common patterns across SL (Aronoff ar X iv :1 40 3.", "startOffset": 123, "endOffset": 157}, {"referenceID": 6, "context": "Report (Filhol, 2009) describes a lexical specification to address the same problem.", "startOffset": 7, "endOffset": 21}, {"referenceID": 2, "context": "Finally, little to no work has been directed towards the unification of raw collected data from SL corpora with higher level descriptions (Dalle, 2006).", "startOffset": 138, "endOffset": 151}, {"referenceID": 5, "context": "Our sign formalization is based on the approach of (Liddell and Johnson, 1989) and (Filhol, 2008).", "startOffset": 83, "endOffset": 97}, {"referenceID": 5, "context": "Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.", "startOffset": 117, "endOffset": 131}, {"referenceID": 11, "context": "Propositions can also be changed, or even induced, by existing written sign representation languages such as Zebedee (Filhol, 2008) or HamNoSys (Hanke, 2004), mainly for the sake of extendability.", "startOffset": 144, "endOffset": 157}], "year": 2014, "abstractText": "This paper explores the use of Propositional Dynamic Logic (PDL) as a suitable formal framework for describing Sign Language (SL), the language of deaf people, in the context of natural language processing. SLs are visual, complete, standalone languages which are just as expressive as oral languages. Signs in SL usually correspond to sequences of highly specific body postures interleaved with movements, which make reference to real world objects, characters or situations. Here we propose a formal representation of SL signs, that will help us with the analysis of automatically-collected hand tracking data from French Sign Language (FSL) video corpora. We further show how such a representation could help us with the design of computer aided SL verification tools, which in turn would bring us closer to the development of an automatic recognition system for these languages.", "creator": "LaTeX with hyperref package"}}}