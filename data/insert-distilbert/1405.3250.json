{"id": "1405.3250", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2014", "title": "Understanding the Complexity of Lifted Inference and Asymmetric Weighted Model Counting", "abstract": "in this paper essentially we study lifted inference for the weighted first - order model counting problem ( wfomc ), which counts the assignments that satisfy every a given sentence in using first - called order logic ( fol ) ; it has applications in statistical relational learning ( srl ) and probabilistic databases ( pdb ). we present several results. first, we describe a lifted inference algorithm that generalizes prior approaches occurring in srl and pdb. second, we provide a novel dichotomy result for a non - trivial fragment of fo cnf sentences, showing that for each sentence the wfomc problem is done either in ptime or # p - hard in the size of the input domain ; we prove that, in the first case our algorithm solves the wfomc problem in ptime, and in the second case it fails. third, we present several properties of the algorithm. finally, we \" discuss limitations of lifted inference for symmetric probabilistic databases ( where the weights of ground literals are depend only on the ordered relation name, and not on the constants of the domain ), and prove the impossibility of a dichotomy result for the complexity of probabilistic inference criteria for the entire language fol.", "histories": [["v1", "Tue, 13 May 2014 18:39:11 GMT  (50kb)", "https://arxiv.org/abs/1405.3250v1", null], ["v2", "Tue, 29 Jul 2014 17:31:31 GMT  (50kb)", "http://arxiv.org/abs/1405.3250v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB cs.LO", "authors": ["eric gribkoff", "guy van den broeck", "dan suciu"], "accepted": false, "id": "1405.3250"}, "pdf": {"name": "1405.3250.pdf", "metadata": {"source": "CRF", "title": "Understanding the Complexity of Lifted Inference and Asymmetric Weighted Model Counting", "authors": ["Eric Gribkoff"], "emails": ["eagribko@cs.uw.edu", "guyvdb@cs.ucla.edu", "suciu@cs.uw.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 5.\n32 50\nv2 [\ncs .A\nI] 2\n9 Ju\nl 2 01\nIn this paper we study lifted inference for the Weighted First-Order Model Counting problem (WFOMC), which counts the assignments that satisfy a given sentence in firstorder logic (FOL); it has applications in Statistical Relational Learning (SRL) and Probabilistic Databases (PDB). We present several results. First, we describe a lifted inference algorithm that generalizes prior approaches in SRL and PDB. Second, we provide a novel dichotomy result for a non-trivial fragment of FO CNF sentences, showing that for each sentence the WFOMC problem is either in PTIME or #P-hard in the size of the input domain; we prove that, in the first case our algorithm solves the WFOMC problem in PTIME, and in the second case it fails. Third, we present several properties of the algorithm. Finally, we discuss limitations of lifted inference for symmetric probabilistic databases (where the weights of ground literals depend only on the relation name, and not on the constants of the domain), and prove the impossibility of a dichotomy result for the complexity of probabilistic inference for the entire language FOL."}, {"heading": "1 INTRODUCTION", "text": "Weighted model counting (WMC) is a problem at the core of many reasoning tasks. It is based on the model counting or #SAT task (Gomes et al., 2009), where the goal is to count assignments that satisfy a given logical sentence. WMC generalizes model counting by assigning a weight to each assignment, and computing the sum of their weights. WMC has many applications in AI and its importance is increasing. Most notably, it underlies state-of-the-art probabilistic in-\nference algorithms for Bayesian networks (Darwiche, 2002; Sang et al., 2005; Chavira and Darwiche, 2008), relational Bayesian networks (Chavira et al., 2006) and probabilistic programs (Fierens et al., 2011).\nThis paper is concerned with weighted first-order model counting (WFOMC), where we sum the weights of assignments that satisfy a sentence in finite-domain first-order logic. Again, this reasoning task underlies efficient algorithms for probabilistic reasoning, this time for popular representations in statistical relational learning (SRL) (Getoor and Taskar, 2007), such as Markov logic networks (Van den Broeck et al., 2011; Gogate and Domingos, 2011) and probabilistic logic programs (Van den Broeck et al., 2014). Moreover, WFOMC uncovers a deep connection between AI and database research, where query evaluation in probabilistic databases (PDBs) (Suciu et al., 2011) essentially considers the same task. A PDB defines a probability, or weight, for every possible world, and each database query is a sentence encoding a set of worlds, whose combined probability we want to compute.\nEarly on, the disconnect between compact relational representations of uncertainty, and the intractability of inference at the ground, propositional level was noted, and efforts were made to exploit the relational structure for inference, using so-called lifted inference algorithms (Poole, 2003; Kersting, 2012). SRL and PDB algorithms for WFOMC all fall into this category. Despite these commonalities, there are also important differences. SRL has so far considered symmetric WFOMC problems, where relations of the same type are assumed to contribute equally to the probability of a world. This assumption holds for certain queries on SRL models, such as single marginals and partition functions, but fails for more complex conditional probability queries. These break lifted algorithms based on symmetric WFOMC (Van den Broeck and Darwiche, 2013). PDBs, on the other hand, have considered the asymmetric WFOMC setting from the start. Prob-\nabilistic database tuples have distinct probabilities, many have probability zero, and no symmetries can be expected. However, current asymmetric WFOMC algorithms (Dalvi and Suciu, 2012) suffer from a major limitation of their own, in that they can only count models of sentences in monotone disjunctive normal form (MDNF) (i.e., DNF without negation). Such sentences represent unions of conjunctive database queries (UCQ). WFOMC encodings of SRL models almost always fall outside this class.\nThe present work seeks to upgrade a well-known PDB algorithm for asymmetric WFOMC (Dalvi and Suciu, 2012) to the SRL setting, by enabling it to count models of arbitrary sentences in conjunctive normal form (CNF). This permits its use for lifted SRL inference with arbitrary soft or hard evidence, or equivalently, probabilistic database queries with negation. Our first contribution is this algorithm, which we call LiftR, and is presented in Section 3.\nAlthough LiftR has clear practical merits, we are in fact motivated by fundamental theoretical questions. In the PDB setting, our algorithm is known to come with a sharp complexity guarantee, called the dichotomy theorem (Dalvi and Suciu, 2012). By only looking at the structure of the first-order sentence (i.e., the database query), the algorithm reports failure when the problem is #P-hard (in terms of data complexity), and otherwise guarantees to solve it in time polynomial in the domain (i.e., database) size. It can thus precisely classify MDNF sentences as being tractable or intractable for asymmetric WFOMC. Whereas several complexity results for symmetric WFOMC exist (Van den Broeck, 2011; Jaeger and Van den Broeck, 2012), the complexity of asymmetric WFOMC for SRL queries with evidence is still poorly understood. Our second and main contribution, presented in Section 4, is a novel dichotomy result over a small but non-trivial fragment of CNFs. We completely classify this class of problems as either computable in polynomial time or #P-hard. This represents a first step towards proving the following conjecture: LiftR provides a dichotomy for asymmetric WFOMC on arbitrary CNF sentences, and therefore perfectly classifies all related SRL models as tractable or intractable for conditional queries.\nAs our third contribution, presented in Section 5, we illustrate the algorithm with examples that show its application to common probabilistic models. We discuss the capabilities of LiftR that are not present in other lifted inference techniques.\nAs our fourth and final contribution, in Section 6, we discuss extensions of our algorithm to symmetric WFOMC, but also show the impossibility of a di-\nchotomy result for arbitrary first-order logic sentences."}, {"heading": "2 BACKGROUND", "text": "We begin by introducing the necessary background on relational logic and weighted model counting."}, {"heading": "2.1 RELATIONAL LOGIC", "text": "Throughout this paper, we will work with the relational fragment of first-order logic (FOL), which we now briefly review. An atom P (t1, . . . , tn) consists of predicate P /n of arity n followed by n arguments, which are either constants or logical variables{x, y, . . . }. A literal is an atom or its negation. A formula combines atoms with logical connectives and quantifiers \u2203 and \u2200. A substitution [a/x] replaces all occurrences of x by a. Its application to formula F is denoted F [a/x]. A formula is a sentence if each logical variable x is enclosed by a \u2200x or \u2203x. A formula is ground if it contains no logical variables. A clause is a universally quantified disjunction of literals. A term is an existentially quantified conjunction of literals. A CNF is a conjunction of clauses, and a DNF is a disjunction of terms. A monotone CNF or DNF contains no negation symbols. As usual, we drop the universal quantifiers from the CNF syntax.\nThe semantics of sentences are defined in the usual way (Hinrichs and Genesereth, 2006). An interpretation, or world, I that satisfies sentence \u2206 is denoted by I \u22a7 \u2206, and represented as a set of literals. Our algorithm checks properties of sentences that are undecidable in general FOL, but decidable, with the following complexity, in the CNF fragment we investigate.\nTheorem 2.1. (Sagiv and Yannakakis, 1980) Checking whether logical implication Q \u21d2 Q\u2032 or equivalence Q \u2261 Q\u2032 holds between two CNF sentences is \u03a0p2complete."}, {"heading": "2.2 WEIGHTED MODEL COUNTING", "text": "Weighted model counting was introduced as a propositional reasoning problem.\nDefinition 2.2 (WMC). Given a propositional sentence \u2206 over literals L, and a weight function w \u2236 L \u2192 R \u22650, the weighted model count (WMC) is\nWMC(\u2206,w) = \u2211 I\u22a7\u2206 \u220f \u2113\u2208I w(\u2113). We will consider its generalization to weighted firstorder model counting (WFOMC), where \u2206 is now a sentence in relational logic, and L consists of all ground first-order literals for a given domain of constants.\nThe WFOMC task captures query answering in prob-\nabilistic database. Take for example the database\nProf(Anne) \u2236 0.9 Prof(Charlie) \u2236 0.1 Student(Bob) \u2236 0.5 Student(Charlie) \u2236 0.8\nAdvises(Anne,Bob) \u2236 0.7 Advises(Bob,Charlie) \u2236 0.1 and the UCQ (monotone DNF) query\nQ = \u2203x,\u2203y, Prof(x) \u2227 Advises(x, y) \u2227 Student(y). If we set \u2206 = Q and w to map each literal to its probability in the database, then our query answer is\nPr(Q) =WFOMC(\u2206,w) = 0.9 \u22c5 0.7 \u22c5 0.5 = 0.315. We refer to the general case above as asymmetric WFOMC, because it allows w(Prof(Anne)) to be different from w(Prof(Charlie)). We use symmetric WFOMC to refer to the special case where w simplifies into two weight functions w\u22c6, w\u0304\u22c6 that map predicates to weights, instead of literals, that is\nw(\u2113) = \u23a7\u23aa\u23aa\u23a8 \u23aa\u23aa\u23a9 w\u22c6(P ) when \u2113 is of the form P (c) w\u0304\u22c6(P ) when \u2113 is of the form \u00acP (c)\nSymmetric WFOMC no longer directly captures PDBs. Yet it can still encode many SRL models, including parfactor graphs (Poole, 2003), Markov logic networks (MLNs) (Richardson and Domingos, 2006) and probabilistic logic programs (De Raedt et al., 2008). We refer to (Van den Broeck et al., 2014) for the details, and show here the following example MLN.\n2 Prof(x) \u2227 Advises(x, y) \u21d2 Student(y)\nIt states that the probability of a world increases by a factor e2 with every pair of people x, y for which the formula holds. Its WFOMC encoding has \u2206 equal to\n\u2200x,\u2200y, F(x, y) \u21d4\n[Prof(x) \u2227 Advises(x, y) \u21d2 Student(y)] and weight functions w\u22c6, w\u0304\u22c6 such that w\u22c6(F) = e2 and all other predicates map to 1.\nAnswering an SRL query Q given evidence E, that is, Pr(Q \u2223E), using a symmetric WFOMC encoding, generally requires solving two WFOMC tasks:\nPr(Q \u2223E) = WFOMC(Q \u2227E \u2227\u2206,w) WFOMC(E \u2227\u2206,w)\nSymmetric WFOMC problems are strictly more tractable than asymmetric ones. We postpone the discussion of this observation to Section 5, but already note that all theories \u2206 with up to two logical variables per formula support domain-lifted inference (Van den Broeck, 2011), which means that any WFOMC query runs in time polynomial in the domain size (i.e, number of constants). For conditional probability queries, even though fixedparameter complexity bounds exist that use symmetric WFOMC (Van den Broeck and Darwiche, 2013),\nthe actual underlying reasoning task is asymmetric WFOMC, whose complexity we investigate for the first time.\nFinally, we make three simplifying observations. First, SRL query Q and evidence E typically assign values to random variables. This means that the query and evidence can be absorbed into the asymmetric weight function, by setting the weight of literals disagreeing with Q or E to zero. We hence compute:\nPr(Q \u2223E) = WFOMC(\u2206,wQ\u2227E) WFOMC(\u2206,wE)\nThis means that our complexity analysis for a given encoding \u2206 applies to both numerator and denominator for arbitrary Q and E, and that polytime WFOMC for \u2206 implies polytime Pr(Q \u2223E) computation. The converse is not true, since it is possible that both WFOMC calls are #P-hard, but their ratio is in PTIME. Second, we will from now on assume that \u2206 is in CNF. The WFOMC encoding of many SRL formalisms is already in CNF, or can be reduced to it (Van den Broeck et al., 2014). For PDB queries that are in monotone DNF, we can simply compute Pr(Q) = 1 \u2212 Pr(\u00acQ), which reduces to WFOMC on a CNF. Moreover, by adjusting the probabilities in the PDB, this CNF can also be made monotone. Third, we will assume that w(\u2113) = 1\u2212w(\u00ac\u2113), which can always be achieved by normalizing the weights.\nUnder these assumptions, we can simply refer to WFOMC(Q,w) as Pr(Q), to Q as the CNF query, to w(\u2113) as the probability Pr(\u2113), and to the entire weight function w as the PDB. This is in agreement with notation in the PDB literature.\n3 ALGORITHM LiftR\nWe present here the lifted algorithm LiftR (pronounced lift-ER), which, given a CNF formula Q computes Pr(Q) in polynomial time in the size of the PDB, or fails. In the next section we provide some evidence for its completeness: under certain assumptions, if LiftR fails on formula Q, then computing Pr(Q) is #P-hard in the PDB size."}, {"heading": "3.1 DEFINITIONS", "text": "An implicate of Q is some clause C s.t. the logical implication Q \u21d2 C holds. C is a prime implicate if there is no other implicate C\u2032 s.t. C\u2032 \u21d2 C.\nA connected component of a clause C is a minimal subset of its atoms that have no logical variables in common with the rest of the clause. If some prime implicate C has more than one connected component,\nthen we can write it as:\nC =D1 \u2228D2 \u2228\u22ef \u2228Dm\nwhere each Di is a clause with distinct variables. Applying distributivity, we write Q in union-CNF form:\nQ = Q1 \u2228Q2 \u2228\u22ef\u2228Qm\nwhere each Qi is a CNF with distinct variables.\nWe check for disconnected prime implicates D1 \u2228D2 where both D1 and D2 subsume some clause of Q. Intuitively, this means that when we apply inclusion/exclusion to the union-CNF, the resulting queries are simpler. The search for D1, D2 can proceed using some standard inference algorithm, e.g. resolution. By Theorem 2.1, this problem is \u03a0p2-complete in the size of the query Q, but independent of the PDB size.\nA set of separator variables for a query Q = \u22c0ki=1Ci is a set of variables xi, i = 1, k such that, (a) for each clause Ci, xi occurs in all atoms of Ci, and (b) any two atoms (not necessarily in the same clause) referring to the same relation R have their separator variable on the same position."}, {"heading": "3.2 PREPROCESSING", "text": "We start by transforming Q (and PDB) such that:\n1. No constants occur in Q. 2. If all the variables in Q are x1, x2, . . . , xk, then\nevery relational atom in Q (positive or negated) is of the form R(xi1 , xi2 , . . . ) such that i1 < i2 < . . .\nCondition (1) can be enforced by shattering Q w.r.t. its variables. Condition (2) can be enforced by modifying both the query Q and the database, in a process called ranking and described in the appendix. Here, we illustrate ranking on an example. Consider the query:\nQ = (R(x, y) \u2228 S(x, y)) \u2227 (\u00acR(x, y) \u2228 \u00acS(y, x)) Define R1(x, y) \u2261 R(x, y) \u2227 (x < y); R2(x) \u2261 R(x,x); R3(y, x) \u2261 R(x, y)\u2227(x > y). Define similarly S1, S2, S3. Given a PDB with relations R, S, we define a new PDB\u2032 over the six relations by setting Pr(R1(a, b)) = Pr(R(a, b)) when a < b, Pr(R1(a, b)) = 0 when a > b, Pr(R2(a)) = Pr(R(a, a)), etc. Then, the query Q over PDB is equivalent to the following query over PDB\u2019:\n(R1(x, y) \u2228 S1(x, y)) \u2227 (\u00acR1(x, y) \u2228 \u00acS3(x, y)) (R2(x) \u2228 S2(x)) \u2227 (\u00acR2(x) \u2228 \u00acS2(x)) (R3(x, y) \u2228 S3(x, y)) \u2227 (\u00acR3(x, y) \u2228 \u00acS1(x, y))"}, {"heading": "3.3 ALGORITHM DESCRIPTION", "text": "Algorithm LiftR, given in Figure 1, proceeds recursively on the structure of the CNF query Q. When it reaches ground atoms, it simply looks up their proba-\nbilities in the PDB. Otherwise, it performs the following sequence of steps.\nFirst, it tries to express Q as a union-CNF. If it succeeds, and if the union can be partitioned into two sets that do not share any relational symbols, Q = Q1\u2228Q2, then it applies a Decomposable Disjunction: Pr(Q) = 1 \u2212 (1 \u2212Pr(Q1)(1 \u2212Pr(Q2)) Otherwise, it applies the Inclusion/Exclusion formula:\nPr(Q) = \u2212 \u2211 s\u2286[m] (\u22121)\u2223s\u2223Pr(\u22c0 i\u2208s Qi) However, before computing the recursive probabilities, our algorithm first checks for equivalent expressions, i.e. it checks for terms s1, s2 in the inclusion/exclusion formula such that \u22c0i\u2208s1 Qi \u2261 \u22c0i\u2208s2 Qi: in that case, these terms either cancel out, or add up (and need be computed only once). We show in Section 5.4 the critical role that the cancellation step plays for the completeness of the algorithm. To check cancellations, the algorithm needs to check for equivalent CNF expressions. This can be done using some standard inference algorithm (recall from Theorem 2.1 that this problem is \u03a0p2-complete in the size of the CNF expression).\nIf neither of the above steps apply, then the algorithm checks if Q can be partitioned into two sets of clauses that do not share any common relation symbols. In that case, Q = Q\u2032\u2227Q\u2032\u2032, and its probability is computed using a Decomposable Conjunction: Pr(Q) = Pr(Q\u2032) \u22c5Pr(Q\u2032\u2032) Finally, if none of the above cases apply to the CNF query Q = C1 \u2227 C2 \u2227 \u22ef \u2227 Ck, then the algorithm tries to find a set of separator variables x1, . . . , xk (one for each clause). If it finds them, then the probability is given by a Decomposable Universal Quantifier:\nPr(Q) = \u220f a\u2208Domain Pr(C1[a/x1] \u2227\u22ef\u2227Ck[a/xk]) We prove our first main result:\nTheorem 3.1. One of the following holds: (1) either LiftR fails on Q, or (2) for any domain size n and a PDB consisting of probabilities for the ground tuples, LiftR computes Pr(Q) in polynomial time in n.\nProof. (Sketch) The only step of the algorithm that depends on the domain size n is the decomposable universal quantifier step; this also reduces by 1 the arity of every relation symbol, since it substitutes it by the same constant a. Therefore, the algorithm runs in time O(nk), where k is the largest arity of any relation symbol. We note that the constant behind O(\u22ef) may be exponential in the size of the query Q."}, {"heading": "4 MAIN COMPLEXITY RESULT", "text": "In this section we describe our main technical result of the paper: that the algorithm is complete when restricted to a certain class of CNF queries.\nWe first review a prior result, to put ours in perspective. (Dalvi and Suciu, 2012) define an algorithm for Monotone DNF (called Unions Of Conjunctive Queries), which can be adapted to Monotone CNF; that adaptation is equivalent to LiftR restricted to Monotone CNF queries. (Dalvi and Suciu, 2012) prove:\nTheorem 4.1. If algorithm LiftR FAILS on a Monotone CNF query Q, then computing Pr(Q) is #P-hard. However, the inclusion of negations in our query language increases significantly the difficulty of analyzing query complexities. Our major technical result of the paper extends Theorem 4.1 to a class of CNF queries with negation.\nDefine a Type-1 query to be a CNF formula where each clause has at most two variables denoted x, y, and each atom is of one of the following three kinds:\n\u2013 Unary symbols R1(x),R2(x),R3(x), . . . \u2013 Binary symbols S1(x, y), S2(x, y), . . . \u2013 Unary symbols T1(y), T2(y), . . .\nor the negation of these symbols.\nOur main result is:\nTheorem 4.2. For every Type-1 query Q, if algorithm LiftR FAILS then computing Pr(Q) is #P-hard. The proof is a significant extension of the techniques used by (Dalvi and Suciu, 2012) to prove Theorem 4.1; we give a proof sketch in Section 7 and include the full proof in the appendix.\n5 PROPERTIES OF LiftR\nWe now describe several properties of LiftR, and the relationship to other lifted inference formalisms."}, {"heading": "5.1 NEGATIONS CAN LOWER THE COMPLEXITY", "text": "The presence of negations can lower a query\u2019s complexity, and our algorithm exploits this. To see this, consider the following query\nQ = (Tweets(x) \u2228 \u00acFollows(x, y)) \u2227 (Follows(x, y) \u2228 \u00acLeader(y))\nThe query says that if x follows anyone then x tweets, and that everybody follows the leader1. Our goal is to compute the probability Pr(Q), knowing the probabilities of all atoms in the domain. We note that the two clauses are dependent (since both refer to the relation Follow), hence we cannot simply multiply their probabilities; in fact, we will see that if we remove all negations, then the resulting query is #P-hard; the algorithm described by (Dalvi and Suciu, 2012) would immediately get stuck on this query. Instead, LiftR takes advantage of the negation, by first computing the prime implicate: Tweets(x) \u2228 \u00acLeader(y) which is a disconnected clause (the two literals use disjoint logical variables, x and y respectively). After applying distributivity we obtain:\nQ \u2261(Q \u2227 (Tweets(x))) \u2228 (Q \u2227 (\u00acLeader(y))) \u2261Q1 \u2228Q2\nand LiftR applies the inclusion-exclusion formula: Pr(Q) =Pr(Q1) +Pr(Q2) \u2212Pr(Q1 \u2227Q2) After simplifying the three queries, they become:\nQ1 =(Follows(x, y) \u2228 \u00acLeader(y))\u2227 (Tweets(x)) Q2 =(Tweets(x) \u2228 \u00acFollows(x, y)) \u2227 (\u00acLeader(y))\nQ1 \u2227Q2 =(Tweets(x)) \u2227 (\u00acLeader(y)) The probability of Q1 can now be obtained by multi-\n1To see this, rewrite the query as (Follows(x, y) \u21d2 Tweets(x)) \u2227 (Leader(y) \u21d2 Follows(x, y)).\nplying the probabilities of its two clauses; same for the other two queries. As a consequence, our algorithm computes the probability Pr(Q) in polynomial time in the size of the domain and the PDB.\nIf we remove all negations from Q and rename the predicates we get the following query: h1 =(R(x) \u2228 S(x, y)) \u2227 (S(x, y) \u2228 T (y)) (Dalvi and Suciu, 2012) proved that computing the probability of h1 is #P-hard in the size of the PDB. Thus, the query Q with negation is easy, while h1 is hard, and our algorithm takes advantage of this by applying resolution."}, {"heading": "5.2 ASYMMETRIC WEIGHTS CAN INCREASE THE COMPLEXITY", "text": "(Van den Broeck, 2011) has proven that any query with at most two logical variables per clause is domainliftable. Recall that this means that one can compute its probability in PTIME in the size of the domain, in the symmetric case, when all tuples in a relation have the same probability. However, queries with at most two logical variables per clause can become #P-hard when computed over asymmetric probabilities, as witnessed by the query h1 above."}, {"heading": "5.3 COMPARISON WITH PRIOR LIFTED FO-CIRCUITS", "text": "(Van den Broeck et al., 2011; Van den Broeck, 2013) introduce FO d-DNNF circuits, to compute symmetric WFOMC problems. An FO d-DNNF is a circuit whose nodes are one of the following: decomposable conjunction (Q1 \u2227Q2 where Q1,Q2 do not share any common predicate symbols), deterministic-disjunction (Q1\u2228Q2 where Q1 \u2227 Q2 \u2261 false), inclusion-exclusion, decomposable universal quantifier (a type of \u2200x,Q(x)), and deterministic automorphic existential quantifier. The latter is an operation that is specific only to structures with symmetric weights, and therefore does not apply to our setting. We prove that our algorithm can compute all formulas that admit an FO d-DNNF circuit.\nFact 5.1. If Q admits an FO d-DNNF without a deterministic automorphic existential quantifier, then LiftR computes Pr(Q) in PTIME in the size of the PDB. The proof is immediate by noting that all other node types in the FO d-DNNF have a corresponding step in LiftR, except for deterministic disjunction, which our algorithm computes using inclusion-exclusion: Pr(Q1\u2228 Q2) = Pr(Q1)+Pr(Q2)\u2212Pr(Q1\u2227Q2) = Pr(Q1)+Pr(Q2) because Q1 \u2227 Q2 \u2261 false. However, our algorithm is strictly more powerful than FO d-DNNFs for the asymmetric WFOMC task, as we explain next."}, {"heading": "5.4 CANCELLATIONS IN INCLUSION/EXCLUSION", "text": "We now look at a more complex query. First, let us denote four simple queries:\nq0 = (R(x0) \u2228 S1(x0, y0)) q1 = (S1(x1, y1) \u2228 S2(x1, y1)) q2 = (S2(x2, y2) \u2228 S3(x2, y2)) q3 = (S3(x3, y3) \u2228 T (y3))\n(Dalvi and Suciu, 2012) proved that their conjunction, i.e. the query h3 = q0 \u2227 q1 \u2227 q2 \u2227 q3, is #P-hard in data complexity. Instead of h3, consider: QW = (q0 \u2228 q1) \u2227 (q0 \u2228 q3) \u2227 (q2 \u2228 q3) There are three clauses sharing relation symbols, hence we cannot apply a decomposable conjunction. However, each clause is disconnected, for example q0 and q1 do not share logical variables, and we can thus write QW as a disjunction. After removing redundant terms: QW = (q0 \u2227 q2) \u2228 (q0 \u2227 q3) \u2228 (q1 \u2227 q3) Our algorithm applies the inclusion/exclusion formula: Pr(QW ) = Pr(q0 \u2227 q2) +Pr(q0 \u2227 q3) +Pr(q1 \u2227 q3) \u2212Pr(q0 \u2227 q2 \u2227 q3) \u2212Pr(q0 \u2227 q1 \u2227 q3) \u2212Pr(q0 \u2227\u22ef\u2227 q3) +Pr(q0 \u2227\u22ef\u2227 q3)\nAt this point our algorithm performs an important step: it cancels out the last two terms of the inclusion/exclusion formula. Without this key step, no algorithm could compute the query in PTIME, because the last two terms are precisely h3, which is #P-hard. To perform the cancellation the algorithm needs to first check which FOL formulas are equivalent, which, as we have seen, is decidable for our language (Theorem 2.1). Once the equivalent formulas are detected, the resulting expressions can be organized in a lattice, as shown in Figure 2, and the coefficient of each term in the inclusion-exclusion formula is precisely the lattice\u2019s Mo\u0308bius function (Stanley, 1997)."}, {"heading": "6 EXTENSIONS AND LIMITATIONS", "text": "We describe here an extension of LiftR to symmetric WFOMC, and also prove that a complete characterization of the complexity of all FOL queries is impossible."}, {"heading": "6.1 SYMMETRIC WFOMC", "text": "Many applications of SRL require weighted model counting for FOL formulas over PDBs where the probabilities are associated to relations rather than individual tuples. That is, Friend(a, b) has the same probability, independently of the constants a, b in the domain. In that symmetric WFOMC case, the model has\na large number of symmetries (since the probabilities are invariant under permutations of constants), and lifted inference algorithms may further exploit these symmetries. (Van den Broeck, 2013) employ one operator that is specific to symmetric probabilities, called atom counting, which is applied to a unary predicate R(x) and iterates over all possible worlds of that predicate. Although there are 2n possible worlds for R, by conditioning on any world, the probability will depend only on the cardinality k of R, because of the symmetries. Therefore, the system iterates over k = 0, n, and adds the conditional probabilities multiplied by (n\nk ).\nFor example, consider the following query: H = (\u00acR(x) \u2228 S(x, y) \u2228 \u00acT (y)) (1) Computing the probabilities of this query is #P-hard (Theorem 4.2). However, if all tuples R(a) have the same probability r \u2208 [0,1], and similarly tuples in S,T have probabilities s, t, then one can check that2\nPr(H) = \u2211 k,l=0,n rk \u22c5 (1 \u2212 r)n\u2212k \u22c5 tl \u22c5 (1 \u2212 t)n\u2212l \u22c5 (1 \u2212 skl)\nDenote Sym-LiftR the extension of LiftR with a deterministic automorphic existential quantifier operator. The question is whether this algorithm is complete for computing the probabilities of queries over PDBs with symmetric probabilities. Folklore belief was that this existential quantifier operator was the only operator required to exploit the extra symmetries available in PDBs with symmetric probabilities. For example, all queries in (Van den Broeck et al., 2011) that can be computed in PTIME over symmetric PDBs have the property that, if one removes all unary predicates from the query, then the residual query can be computed in PTIME over asymmetric PDBs.\nWe answer this question in the negative. Consider the following query:\nQ =(S(x1, y1) \u2228 \u00acS(x1, y2) \u2228 \u00acS(x2, y1) \u2228 S(x2, y2)) Here, we interpret S(x, y) as a typed relation, where\n2Conditioned on \u2223R\u2223 = k and \u2223T \u2223 = l, the query is true if S contains at least one pair (a, b) \u2208 R \u00d7 T .\nthe values x and y are from two disjoint domains, of sizes n1, n2 respectively, in other words, S \u2286 [n1]\u00d7[n2]. Theorem 6.1. We have that\n\u2013 Pr(Q) can be computed in time polynomial in the size of a symmetric PDB with probability p as Pr(Q) = f(n1, n2) + g(n1, n2) where:\nf(n1,0) = 1 f(n1, n2) = n1\u2211\nk=1\n(n1 k )pkn2g(n1 \u2212 k,n2)\ng(0, n2) = 1 g(n1, n2) = n2\u2211\n\u2113=1\n(n2 \u2113 )(1 \u2212 p)n1\u2113f(n1, n2 \u2212 \u2113)\n\u2013 Sym-LiftR fails to compute Q.\nThe theorem shows that new operators will be required for symmetric WFOMC. We note that it is currently open whether computing Pr(Q) is #P-hard in the case of asymmetric WFOMC.\nProof. Denote Dx,Dy the domains of the variables x and y. Fix a relation S \u2286 D1 \u00d7 D2. We will denote a1, a2, . . . \u2208 D1 elements from the domain of the variable x, and b1, b2, . . . \u2208 D2 elements from the domain of the variable y. For any a, b, define a \u227a b if (a, b) \u2208 S, and a \u227b b if (a, b) /\u2208 S; in the latter case we also write b \u227a a. Then, (1) for any a, b, either a \u227a b or b \u227a a, (2) \u227a is a partial order on the disjoint union of the domains D1 and D2 iff S satisfies the query Q. The first property is immediate. To prove the second property, notice that Q states that there is no cycle of length 4: x1 \u227a y2 \u227a x2 \u227a y1 \u227a x1. By repeatedly applying resolution between Q with itself, we derive that there are no cycles of length 6, 8, 10, etc. Therefore, \u227a is transitive, hence a partial order. Any finite, partially ordered set has a minimal element, i.e. there exists z s.t. \u2200x, x /\u227a z. Let Z be the set of all minimal elements, and denote X =D1\u2229Z and Y =D2 \u2229Z. Then exactly one of X or Y is non-empty, because if both were non-empty then, for a \u2208 X and b \u2208 Y we have either a \u227a b or a \u227b b contradicting their minimality. Assuming X \u2260 \u2205, we have\n(a) for all a \u2208 X and b \u2208 D2, (a, b) \u2208 S, and (b) Q is true on the relation S\u2032 = (D1 \u2212X)\u00d7D2. This justifies the recurrence formula for Pr(Q)."}, {"heading": "6.2 THE COMPLEXITY OF ARBITRARY FOL QUERIES", "text": "We conjecture that, over asymmetric probabilities (asymmetric WFOMC), our algorithm is complete, in the sense that whenever it fails on a query, then the query is provably #P-hard. Notice that LiftR applies only to a fragment of FOL, namely to CNF formulas without function symbols, and where all variables are universally quantified. We present here an impossibility result showing that a complete algorithm cannot exist for general FOL queries. We use for that a classic result by Trakhtenbrot (Libkin, 2004):\nTheorem 6.2 (Finite satisfiability). The problem: \u201cgiven a FOL sentence \u03a6, check whether there exists a finite model for \u03a6\u201d is undecidable.\nFrom here we obtain:\nTheorem 6.3. There exists no algorithm that, given any FOL sentence Q checks whether Pr(Q) can be computed in PTIME in the asymmetric PDB size.\nProof. By reduction from the finite satisfiability problem. Fix the hard query H in Eq.(1), for which the counting problem is #P-hard. Recall that H uses the symbols R,S,T . Let \u03a6 be any formula over a disjoint relational vocabulary (i.e. it doesn\u2019t use R,S,T ). We will construct a formulaQ, such that computing Pr(Q) is in PTIME iff \u03a6 is unsatisfiable in the finite: this proves the theorem. To construct Q, first we modify \u03a6 as follows. Let P (x) be another fresh, unary relational symbol. Rewrite \u03a6 into \u03a6\u2032 as follows: replacing every (\u2203x.\u0393) with (\u2203x.P (x)\u2227\u0393) and every (\u2200x.\u0393) with(\u2200x.P (x) \u21d2 \u0393) (this is not equivalent to the guarded fragment of FOL); leave the rest of the formula unchanged. Intuitively, \u03a6\u2032 checks if \u03a6 is true on the substructure defined by the domain elements that satisfy P . More precisely: for any database instance I, \u03a6\u2032 is true on I iff \u03a6 is true on the substructure of I defined by the domain elements that satisfy P (x). Define the query Q = (H \u2227\u03a6\u2032). We now prove the claim. If \u03a6 is unsatisfiable then so is \u03a6\u2032, and therefore Pr(Q) = 0 is trivially computable in PTIME. If \u03a6 is satisfiable, then fix any deterministic database instance I that satisfies \u03a6; notice that I is deterministic, and I \u22a7 \u03a6. Let J be any probabilistic instance over the vocabulary for H over a domain disjoint from I. Define P (x) as follows: P (a) is true for all domain elements a \u2208 I, and P (b) is false for all domain elements b \u2208 J . Consider now the probabilistic database\nI \u222a J . (Thus, P (x) is also deterministic, and selects the substructure I from I \u222a J ; therefore, \u03a6\u2032 is true in I \u222a J .) We have Pr(Q) = Pr(H \u2227 \u03a6\u2032) = Pr(H), because \u03a6\u2032 is true on I\u222aJ . Therefore, computing Pr(Q) is #P-hard. Notice the role of P : while I satisfies \u03a6, it is not necessarily the case that I \u222a J satisfies \u03a6. However, by our construction we have ensured that I \u222a J satisfies \u03a6\u2032."}, {"heading": "7 PROOF OF THEOREM 4.2", "text": "The proof of Theorem 4.2 is based on a reduction from the #PP2-CNF problem, which is defined as follows. Given two disjoint sets of Boolean variables X1, . . . ,Xn and Y1, . . . , Yn and a bipartite graph E \u2286 [n]\u00d7 [n], count the number of satisfying truth assignments #\u03a6 to the formula: \u03a6 = \u22c0(i,j)\u2208E(Xi \u2228 Yj). (Provan and Ball, 1983) have shown that this problem is #P-hard.\nMore precisely, we prove the following: given any Type-1 query Q on which the algorithm LiftR fails, we can reduce the #PP2-CNF problem to computing Pr(Q) on a PDB with domain size n. The reduction consists of a combinatorial part (the construction of certain gadgets), and an algebraic part, which makes novel use of the concepts of algebraic independence (Yu, 1995) and annihilating polynomials (Kayal, 2009). We include the latter in the appendix, and only illustrate here the former on a particular query of Type-1.\nWe illustrate the combinatorial part of the proof on the following query Q: (R(x) \u2228 \u00acS(x, y) \u2228 T (y))\u2227 (\u00acR(x) \u2228 S(x, y) \u2228 \u00acT (y)) To reduce \u03a6 to the problem of computing Pr(Q), we construct a structure with unary predicates R and T and binary predicate S, with active domain [n]. We define the tuple probabilities as follows. Letting x, y, a, b \u2208 (0,1) be four numbers that will be specified later, we define:\nPr(R(i)) = x Pr(T (j)) = y\nPr(S(i, j)) = { a if (i, j) \u2208 E b if (i, j) /\u2208 E\nNote this PDB does not have symmetric probabilities: in fact, over structures with symmetric probabilities one can compute Pr(Q) in PTIME. Let \u03b8 denote a valuation of the variables in \u03a6. Let E\u03b8 denote the event \u2200i.(R(i) = true iff \u03b8(Xi) = true) \u2227 \u2200j.(T (j) = true iff \u03b8(Yj) = true). E\u03b8 completely fixes the unary predicates R and T and\nleaves S unspecified. Given E\u03b8, each Boolean variable corresponding to some S(x, y) is now independent of every other S(x\u2032, y\u2032). In general, given an assignment of R(i) and T (j), we examine the four formulas that define the probability that the query is true on (i, j): F1 = Q[R(i) = 0, T (j) = 0], F2 = Q[R(i) = 0, T (j) = 1], F3 = Q[R(i) = 1, T (j) = 0], F4 =Q[R(i) = 1, T (j) = 1]. For Q, F1, F2, F3, F4 are as follows:\nF1 = \u00acS(i, j) F2 = F3 = true F4 = S(i, j) Denote f1, f2, f3, f4 the arithmetization of these Boolean formulas:\nf1 = { 1 \u2212 a if (i, j) \u2208 E1 \u2212 b if (i, j) /\u2208 E f4 = { a if (i, j) \u2208 Eb if (i, j) /\u2208 E\nNote that f2 = f3 = 1 and do not change Pr(Q). Define the parameters k, l, p, q of E\u03b8 as k = number of i\u2019s s.t. R(i) = true, l = number of j\u2019s s.t. T (j) = true, p = number of (i, j) \u2208 E s.t. R(i) = T (j) = true, q = number of (i, j) \u2208 E s.t. R(i) = T (j) = false. Let N(k, l, p, q) = the number of \u03b8\u2019s that have parameters k, l, p, q. If we knew all (n + 1)2(m + 1)2 values of N(k, l, p, q), we could recover #\u03a6 by summing over N(k, l, p, q) where q = 0. That is, #\u03a6 = \u2211k,l,pN(k, l, p,0). We now describe how to solve for N(k, l, p, q), completing the hardness proof for Pr(Q). We have Pr(E\u03b8) = xk(1 \u2212 x)n\u2212kyl(1 \u2212 y)n\u2212l and Pr(Q\u2223E\u03b8) = ap(1 \u2212 a)qbkl\u2212p(1 \u2212 b)(n\u2212k)(n\u2212l)\u2212q. Combined, these give the following expression for Pr(Q):\nPr(Q) =\u2211 \u03b8 Pr(Q\u2223E\u03b8)Pr(E\u03b8) = (1 \u2212 b)n2(1 \u2212 x)n(1 \u2212 y)n \u2211\nk,l,p,q\nT (1)\nwhere:\nT =N(k, l, p, q) \u2217 (a/b)p[(1 \u2212 a)/(1 \u2212 b)]q [x/(1 \u2212 b)n(1 \u2212 x)]k[y/(1 \u2212 b)n (1 \u2212 y)]l[b(1 \u2212 b)]kl\n=N(k, l, p, q) \u2217ApBqXkY lCkl (2) Equations (1) and (2) express Pr(Q) as a polynomial in X,Y,A,B,C with unknown coefficients N(k, l, p, q). Our reduction is the following: we choose (n+1)2(m+ 1)2 values for the four parameters x, y, a, b \u2208 (0,1), consult an oracle for Pr(Q) for these settings of the parameters, then solve a linear system of (n+1)2(m+1)2 equations in the unknowns N(k, l, p, q). The crux of the proof consists of showing that the matrix of the system is non-singular: this is far from trivial, in fact\nhad we started from a PTIME query Q then the system would be singular. Our proof consists of two steps (1) prove that we can choose X,Y,A,B independently, in other words that the mapping (x, y, a, b) \u21a6(X,Y,A,B) is locally invertible (has a non-zero Jacobian), and (2) prove that there exists a choice of(n + 1)2(m + 1)2 values for (X,Y,A,B) such that the matrix of the system is non-singular: then, by (1) it follows that we can find (n + 1)2(m + 1)2 values for(x, y, a, b) that make the matrix non-singular, completing the proof. For our particular example, Part (1) can be verified by direct computations (see Section A.3); for general queries this requires Section A.12. Part (2) for this query is almost as general as for any query and we show it in Section A.2."}, {"heading": "8 RELATED WORK", "text": "The algorithm and complexity results of (Dalvi and Suciu, 2012), which apply to positive queries, served as the starting point for our investigation of asymmetric WFOMC with negation. See (Suciu et al., 2011) for more background on their work. The tuple-independence assumption of PDBs presents a natural method for modeling asymmetric WFOMC. Existing approaches for PDBs can express complicated correlations (Jha et al., 2010; Jha and Suciu, 2012) but only consider queries without negation.\nClose in spirit to the goals of our work are (Van den Broeck, 2011) and (Jaeger and Van den Broeck, 2012). They introduce a formal definition of lifted inference and describe a powerful knowledge compilation technique for WFOMC. Their completeness results for firstorder knowledge compilation on a variety of query classes motivate our exploration of the complexity of lifted inference. (Cozman and Polastro, 2009) analyze the complexity of probabilistic description logics.\nOther investigations of evidence in lifted inference include (Van den Broeck and Davis, 2012), who allow arbitrary hard evidence on unary relations, (Bui et al., 2012), who allow asymmetric soft evidence on a single unary relation, and (Van den Broeck and Darwiche, 2013), who allow evidence of bounded Boolean rank. Our model allows entirely asymmetric probabilities and evidence."}, {"heading": "9 CONCLUSION", "text": "Our first contribution is the algorithm LiftR for counting models of arbitrary CNF sentences over asymmetric probabilistic structures. Second, we prove a novel dichotomy result that completely classifies a subclass\nof CNFs as either PTIME or #P-hard. Third, we describe capabilities of LiftR not present in prior lifted inference techniques. Our final contribution is an extension of our algorithm to symmetric WFOMC and a discussion of the impossibility of establishing a dichotomy for all first-order logic sentences."}, {"heading": "Acknowledgements", "text": "This work was partially supported by ONR grant #N00014-12-1-0423, NSF grants IIS-1115188 and IIS-1118122, and the Research Foundation-Flanders (FWO-Vlaanderen)."}, {"heading": "A APPENDIX", "text": ""}, {"heading": "A.1 RANKING QUERIES", "text": "We show here that every query can be ranked (see Section 3.2), by modifying both the query Q and the database. Each relational symbol R of arity k is replaced by several symbols, one for each possible order of its attributes. We illustrate this for the case of a binary relation symbol R(x, y). Given a domain of size n and probabilities Pr(R(a, b)) for all tuples in R, we create three new relation symbols, R1(x, y),R2(x),R3(y, x), and define their probabilities as follows:\nPr(R1(a, b)) ={ Pr(R(a, b)) if a < b0 otherwise Pr(R2(a)) =Pr(R(a, a)) Pr(R3(b, a)) ={ Pr(R(a, b)) if a > b0 otherwise\nThen, we also modify the query as follows. First, we replace every atom R(x, y) with R1(x, y) \u2228R\u20322(x, y) \u2228 R3(y, x), and every negated atom \u00acR(x, y) with \u00acR1(x, y)\u2227\u00acR\u20322(x, y)\u2227\u00acR3(y, x), re-write the query in CNF, then replace each clause containing some atom R\u20322(x, y) with two clauses: in the first we substitute y \u2236= x, and in the second we replace R\u20322(x, y) with false (which means that, if R\u20322(x, y) was positive then we remove it, and if it was negated then we remove the entire clause). Section 3.2 provides an example of this procedure."}, {"heading": "A.2 PROVING THE MATRIX OF", "text": "SECTION 7 IS INVERTIBLE\nLetM(m1,m2, n1, n2) be the matrix whose entries are: ApuB q vX k wY l zC kl uv\nwhere the row is (p, q, k, l) and column is (u, v,w, z) and the ranges are:\np, u = 0, ..,m1 \u2212 1\nq, v = 0, ..,m2 \u2212 1\nk,w = 0, .., n1 \u2212 1\nl, z = 0, .., n2 \u2212 1\nGiven a vector X0,X1, . . . ,Xn\u22121 denote V(X) the determinant of their Vandermonde matrix: V (X) = \u220f0\u2264k<k\u2032<n(Xk \u2212Xk\u2032)\nLemma A.1. If m1 =m2 = 1 then\ndet(M) = Cn1n2(n1\u22121)(n2\u22121)/400 V n2(X)V n1(Y )\nProof. The matrix M(1,1, n1, n2) has the following entries:\nXkwY l zC kl 00\nAll elements in row (k, l) have the common factor Ckl00. After we factorize it from each row, the remaining matrix is a Kronecker product of two Vandermonde matrices."}, {"heading": "Lemma A.2.", "text": "det(M(m1,m2, n1, n2)) = \u220f u>0\n(Au \u2212A0)m2n1n2 det(M(1,m2, n1, n2))\ndet(M(m1 \u2212 1,m2, n1, n2)) Where in M(m1 \u2212 1,m2, n1, n2) instead of A0, . . . ,Am1\u22122 we have A1, . . . ,Am1\u22121, i.e. the index u is shifted by one, and similarly in Cuv the index u is shifted by one.\nProof. We eliminate A0, similarly to how we would eliminate it from a Vandermonde matrix: subtract from row (p + 1, q, k, l) the row (p, q, k, l) multiplied by A0; do this bottom up, and cancel A0 in all rows, except the rows of the form (0, q, k, l). We only need to be careful that, when we cancel A0 in row (p+1, q, k, l) we use the same q, k, l to determine the row (p, q, k, l). For an illustration we show below these two rows(p, q, k, l) and (p + 1, q, k, l), and the two columns,(0, v0,w0, z0) and (u, v,w, z): In the original matrix:\n\u239b\u239c\u239c\u239c\u239c\u239c\u239d \u22ee \u22ee \u22ee \u22ee \u22ee . . . T1 . . . T2 . . . \u22ee \u22ee \u22ee \u22ee \u22ee . . . T3 . . . T4 . . .\n\u22ee \u22ee \u22ee \u22ee \u22ee \u239e\u239f\u239f\u239f\u239f\u239f\u23a0 Where:\nT1 = A p 0B q v0 Xkw0Y l z0 Ckl0,v0 T2 = A p uB q vX k wY l zC kl uv T3 = A p+1 0 B q v0 Xkw0Y l z0 Ckl0,v0 T4 = A p+1 u B q vX k wY l zC kl uv\nSubtract the first row times A0 from the second row, and obtain:\n\u239b\u239c\u239c\u239c\u239c\u239c\u239d \u22ee \u22ee \u22ee \u22ee \u22ee . . . T1 . . . T2 . . . \u22ee \u22ee \u22ee \u22ee \u22ee . . . 0 . . . T4 \u2212A0T2 . . . \u22ee \u22ee \u22ee \u22ee \u22ee \u239e\u239f\u239f\u239f\u239f\u239f\u23a0 Where: T4 \u2212A0T2 = (Au \u2212A0)ApuBqvXkwY lzCkluv Repeat for all rows in this order: (m1\u22121, q, k, l), (m1\u2212 2, q, k, l), . . . , (1, q, k, l), and for all combinations of q, k, l. Let\u2019s examine the resulting matrix.\nAssume that the first m2n1n2 rows are of the form(0, q, k, l). Also, assume that the firstm2n1n2 columns are the form (0, v,w, z) (permute if necessary) Therefore the matrix looks like this:\n( m1 . . . 0 M \u2032 ) Where:\n\u2022 The top-left m2n1n2 rows and columns are preciselym1 =M(1,m2, n1, n2). Notice that this matrix does not depend on A. All entries below it are 0. \u2022 Therefore, det(M) = det(m1)det(M \u2032) where M \u2032 is the bottom right matrix (what remains after removing the first m2n1n2 rows and columns). This follows from a theorem on expanding determinants \u2022 M \u2032 has a factor (Au \u2212 A0) in every column(u, v,w, z). Factorize this common factor, noting that it occurs m2n1n2 times (for all combinations of v,w, z). Thus:\ndet(M \u2032) =\u220f u (Au \u2212A0)m2n1n2det(M \u2032\u2032) where M \u2032\u2032 is the matrix resulting from M \u2032 after factorizing.\n\u2022 The entries of M \u2032\u2032 are precisely:\nApuB q vX k wY l zC kl uv\nwhere p = 0, . . . ,m1 \u2212 2, and u = 1, . . . ,m1 \u2212 1 and the other indices have the same range as before. \u2022 Therefore, M \u2032\u2032 = M(m1 \u2212 1,m2, n1, n2), with the only change that the index u is shifted by one.\nLemmas A.1 and A.2 prove that det(M) \u2260 0 whenever all the A\u2019s, the B\u2019s, the X \u2019s, and the Z\u2019s are distinct, and all Cuv \u2260 0. Thus, our determinant in Section 7 is nonzero, as Cuv = (Au \u2212 1)(Bv \u2212 1)/(Bv \u2212Au)."}, {"heading": "A.3 PROVING THE FUNCTIONS OF", "text": "SECTION 7 ARE LOCALLY INVERTIBLE\nIn this section, we prove that the functions from the example in Section 7 are locally invertible:\nX(x, b) = x(1 \u2212 x)(1 \u2212 b)n Y (y, b) = y(1 \u2212 y)(1 \u2212 b)n A(a, b) =a\nb\nB(a, b) =1 \u2212 a 1 \u2212 b\nWe show this by computing the determinant of the Jacobian matrix of these functions. In the general proof, the concept of algebraic independence replaces the notion of locally invertible.\nLet J be the Jacobian matrix of the vector-valued function F (x, y, a, b) =(X(x, b), Y (y, b),A(a, b),B(a, b)).\nJ = \u239b\u239c\u239c\u239c\u239c\u239d 1 b\n\u2212a b2\n0 0 \u22121 1\u2212b 1\u2212a (1\u2212b)2 0 0\n0 nx (1\u2212x)(1\u2212b)n+1 1 (1\u2212x)2(1\u2212b)n\n0\n0 ny (1\u2212y)(1\u2212b)n+1\n0 1 (1\u2212y)2(1\u2212b)n \u239e\u239f\u239f\u239f\u239f\u23a0 The determinant of this matrix is: det(J) = b \u2212 a(1 \u2212 y)2(1 \u2212 x)2b2(1 \u2212 b)2(n+1) For any values of x, y, a, b s.t. a \u2260 b, det(J) \u2260 0. By the inverse function theorem, F is invertible in some neighborhood contained in (0,1)4. We pick our values of x, y, a, b to lie within this neighborhood."}, {"heading": "A.4 DEFINITIONS", "text": "Let Q be a query with a single left unary and a single right unary symbol U(x), V (y). Let F be its Boolean formula, and denote:\nF00 = F [0/U,0/V ] F01 = F [0/U,1/V ] F10 = F [1/U,0/V ] F11 = F [1/U,1/V ]\nWith some abuse of notation we refer to these functions as F1, F2, F3, F4, and their arithmetizations to multilinear polynomials as f1, f2, f3, f4.\nCall Q splittable if F has a prime implicate consisting only of unary symbols with at least one left unary symbol U and at least one right unary symbol V . Note\nthat if Q is splittable, then the algorithm applies the inclusion/exclusion formula. Call Q decomposable if F = (F1 \u2227 F2), where all left unary symbols Ui are in F1, all right unary symbols Vj are in F2, and F1, F2 do not share any common symbols (they are independent). Note that if Q is decomposable, then the algorithm applies decomposable conjunction.\nCall Q immediately unsafe if it is neither splittable nor decomposable. When running the algorithm on an immediately unsafe query Q, the algorithm is immediately stuck.\nGiven queries Q,Q\u2032 we say that Q rewrites to Q\u2032, with notation Q \u2192 Q\u2032, if Q\u2032 can be obtained from Q by setting some symbol to true or to false, i.e. F \u2032 = F [0/Z] or F \u2032 = F [1/Z]. Call a query Q unsafe if it can be rewritten to some immediately unsafe query: Q \u2192 . . . \u2192 Q\u2032 and Q\u2032 is immediately unsafe.\nCall a query Q forbidden if it is immediately unsafe, and any further rewriting Q \u2192 Q\u2032 is to a safe query (i.e. Pr(Q\u2032) can be computed by the algorithm, and therefore is in PTIME).\nFact A.3. Q is splittable iff one of the four functions F1, . . . , F4 is unsatisfiable.\nProof. If Q is splittable then it has a prime implicate of the form ((\u00ac)U \u2228 (\u00ac)V ). Then that corresponding function is 0. For example, suppose Q \u21d2 (\u00acU \u2228 V ). Then F10 = F [1/U,0/V ] = 0. Fact A.4. Q is decomposable iff there exists polynomials g0, g1 and h0, h1 such that the polynomials f00, f01, f10, f11 factorize as follows:\nf00 = g0h0\nf01 = g0h1\nf10 = g1h0\nf11 = g1h1\nProof. Assume f00, f01, f10, f11 factorize as above. Then we have f = (1 \u2212 u)(1 \u2212 v)f00 + \u22c5 \u22c5 \u22c5 + uvf11 =((1 \u2212 u)g0 + ug1)((1 \u2212 v)h0 + vh1) proving that Q is decomposable. The converse is immediate.\nOur hardness proof requires the following background on multivariate polynomials:\nDefinition A.5 (Annihilating Polynomial). Let f1, . . . , fn be multivariate polynomials. An annihilating polynomial is a polynomial A(z1, . . . , zn) such that the following identity holds: A(f1, . . . , fn) = 0.\nDefinition A.6 (Algebraic Independence). A set of polynomials f1, . . . , fn is algebraically independent if there does not exist an annihilating polynomial that annihilates f1, . . . , fn. If f1, . . . , fn have an annihilating polynomial, then the Jacobian determinant Det(J(f1, . . . , fn)) = 0 everywhere. In this case, the polynomials are said to be algebraically dependent.\nProposition A.7. If f1, . . . , fn are over n \u2212 1 variables, then they have an annihilating polynomial. Equivalently, f1, . . . , fn are algebraically dependent.\nProposition A.8. If f1, . . . , fn have an annihilating polynomial, and any n \u2212 1 are algebraically independent, then there exists a unique irreducible annihilating polynomial A for f1, . . . , fn.\nProposition A.9. If the Jacobian J(f1, . . . , fn) has rank less than n, then f1, . . . , fn have an annihilating polynomial.\nOur proofs consider annihilating polynomials for the four Boolean functions resulting from a query Q conditioned on its unary left and right predicates.\nConsider the following two examples of annihilating polynomials:\n\u2022 If Q decomposes: f1 = g0h0, f2 = g0h1, f3 = g1h0, f4 = g1h1, then the annihilating polynomial is A = f1f4 \u2212 f2f3 = 0 \u2022 Suppose f1 = x1 + x2 \u2212 x1x2, f2 = x1x2, f3 = x1. Then A = (f1 + f2 \u2212 f3)f3 \u2212 f2 = 0\nWe also need the following: (1) The ideal generated by f1, . . . , fn, denoted \u27e8f1, . . . , fn\u27e9, is the set of polynomials of the form f1h1 + \u22c5 \u22c5 \u22c5 + fnhn, for arbitrary h1, . . . , hn. (2) The variety of an ideal I is V (I) ={a\u2223\u2200f \u2208 I, f[a/x] = 0}. In particular, V (f1, . . . , fn) is the variety of \u27e8f1, . . . , fn\u27e9 and consists of all common roots of f1, . . . , fn. (3) Hilbert\u2019s Nullstellensatz: if V (I) \u2286 V (f) then there exists m s.t. fm \u2208 I. We only need a very simple consequence: if p is irreducible and V (p) \u2286 V (f), then f \u2208 \u27e8p\u27e9. In other words, f is divisible by p."}, {"heading": "A.5 OUTLINE OF HARDNESS PROOF", "text": "Given a forbidden query Q, we prove hardness by reduction from #PP2CNF (see Section 7). Given a PP2CNF formula \u03a6:\n\u03a6 = \u22c0 (i,j)\u2208E\n(Xi \u2228 Yj)\nWhere E \u2286 [n]\u00d7[n], we set the probabilities as follows: Pr(U(i)) = u Pr(V (j)) = v Pr(X1(i, j)) = x1,Pr(X2(i, j) = x2, . . . if(i, j) \u2208 E Pr(X1(i, j)) = y1,Pr(X2(i, j) = y2, . . . if(i, j) /\u2208 E\nFix an assignment \u03b8 \u2236 {X1, . . . ,Xn, Y1, . . . , Yn} \u2192{0,1}. Define the following parameters of \u03b8:\nk = number of i\u2019s s.t. Xi = 1\nl = number of j\u2019s s.t. Yj = 1 q = number of (i, j) \u2208 E s.t. Xi = 0, Yj = 0 r = number of (i, j) \u2208 E s.t. Xi = 0, Yj = 1 s = number of (i, j) \u2208 E s.t. Xi = 1, Yj = 0 p = number of (i, j) \u2208 E s.t. Xi = 1, Yj = 1\nLet N(k, l, q, r, s, p) = number of assignments \u03b8 with these parameters.\nBy repeating the calculations we did for the example query, and omitting a constant factor, we obtain: Pr(Q) = \u2211 k,l,q,r,s,p N(k, l, q, r, s, p)AqBrCsDpXkY lHkl\nWhere:\nA = f00(x1, x2, . . . )/f00(y1, y2, . . . ) B = f01(x1, x2, . . . )/f01(y1, y2, . . . ) C = f10(x1, x2, . . . )/f10(y1, y2, . . . ) D = f11(x1, x2, . . . )/f11(y1, y2, . . . ) H = depends on A,B,C,D\nX = depends on A,B,C,D and u\nY = depends on A,B,C,D and v\nAs in the example of Section 7, we use an oracle for Pr(Q) repeatedly to construct a system of linear equations and solve for N(k, l, q, r, s, p) in polynomial time. From here we derive #\u03a6.\nTo do this, we must prove that the matrix M of the resulting system has det(M) \u2260 0. The same technique used in Section A.2 generalizes to prove that M is non-singular, as long as we can produce distinct values for A,B,C, and D. This establishes the following: Fact A.10. Let m = \u2223E\u2223. Consider four sequences of m+1 distinct numbers:\nAu u = 0, . . . ,m\nBv v = 0, . . . ,m\nCw w = 0, . . . ,m\nDz z = 0, . . . ,m\nSuppose that for every combination of u, v,w, z we can find probabilities x1, x2, . . . , y1, y2, . . . s.t. Au = f00(x1, x2, . . . )/f00(y1, y2, . . . ), Bv = f01(x1, x2, . . . )/f01(y1, y2, . . . ), etc. Then det(M) \u2260 0. Thus, to prove that Pr(Q) is #P-hard it suffices to prove that the four functions A,B,C,D are invertible: that is, given their output values Au, . . . ,Dz , we must find inputs x1, x2, . . . , y1, y2, . . . s.t. when the functions are applied to those inputs they result in the desired values.\nClearly, A,B,C,D are not invertible in two trivial cases: when some of the functions f00, f01, f10, f11 are constants, or when two or more are equivalent. There are several other special cases, detailed later. As we will see, some of these cases may still be solved by identifying a subset of {A,B,C,D} which is invertible, and the rest of the cases are solved by a second hardness proof technique referred to as the zigzag construction.\nOverloading terminology, we say that a query Q is invertible iff A,B,C,D (or a subset thereof, if some functions are equivalent or constant) are invertible. The case analysis of Section A.7 proves the following theorem:\nTheorem A.11. Let Q be a forbidden Type 1 query. Then one of the following holds:\n\u2022 Q is invertible and we apply the hardness proof as described above \u2022 Q admits the zigzag construction and hardness proof of Section A.11\nA.6 IMPLICATIONS OF ALGEBRAIC INDEPENDENCE\nEstablishing the algebraic independence of the functions A,B,C,D is one of two primary challenges in the proof technique of Section A.5. We discuss here how algebraic independence of the functions f1g1, f2g2, f3g3, f4g4 implies the invertibility of A,B,C,D.\nTheorem A.12. Let Q be a forbidden query with two unary atoms U,V . Suppose the four functions F00, F01, F10, F11 are distinct and non-constant (Note that this implies that there are at least two variables x1, x2). Then the Jacobian of the four functions A,B,C,D has rank 4.\nProof. We denote the four functions f1(x), f2(x), f3(x), f4(x), where x = (x1, x2, . . . ) is the set of variables. Further denote g1(y) = f1[y/x], . . . , g4(y) = f4[y/x], where y = (y1, y2, . . . ) are distinct new variables. Re-\ncall that:\nA =f1(x)/g1(y) B =f2(x)/g2(y) C =f3(x)/g3(y) D =f4(x)/g4(y)\nTheir Jacobian has the same rank as the Jacobian of their log, which is:\nlog(A) = log(f1) \u2212 log(g1) log(B) = log(f2) \u2212 log(g2) log(C) = log(f3) \u2212 log(g3) log(D) = log(f4) \u2212 log(g4)\nThe Jacobian matrix looks like this:\nJ = \u239b\u239c\u239c\u239d 1 f1 \u2202f1 \u2202x1 1 f1 \u2202f1 \u2202x2 . . . \u2212 1 g1 \u2202g1 \u2202y1 \u2212 1 g1 \u2202g1 \u2202y2 . . .\n\u22ee \u22ee . . . \u22ee \u22ee . . . 1 f4 \u2202f4 \u2202x1 1 f4 \u2202f4 \u2202x2 . . . \u2212 1 g4 \u2202g4 \u2202y1 \u2212 1 g4 \u2202g4 \u2202y2 . . . \u239e\u239f\u239f\u23a0 Each column corresponding to a y-variable has a minus sign. Reversing these signs, which does not change the rank of the matrix, we obtain the Jacobian of these four functions:\nlog(f1) + log(g1) log(f2) + log(g2) log(f3) + log(g3) log(f4) + log(g4)\nThis Jacobian is of rank 4 iff the four functions f1g1, f2g2, f3g3, f4g4 are algebraically independent."}, {"heading": "A.7 CASE ANALYSIS", "text": "Queries which satisfy the assumptions of Lemma A.19 are invertible, and we apply the hardness proof described in Section A.5. We consider the remaining queries that do not satisfy the conditions of Lemma A.19.\nThese queries possess functions f1, f2, f3, f4 such that:\n\u2200q \u2208 Factors(f4) \u2212Factors(f3), \u2200p \u2208 Factors(f3), V (p, q) \u2286 V (f1 \u2217 f2)\nAnd the same holds for all permutations of f1, f2, f3, f4 in the above equations.\nLet:\nf \u20323 =Factors(f3) \u2212 Factors(f4) (1) f \u20324 =Factors(f4) \u2212 Factors(f3) f34 =Factors(f3) \u2229 Factors(f4)\nThe condition above is equivalent to:\n\u2200p \u2208 f3, q \u2208 f \u2032 4, V (p, q) \u2286 V (f1 \u2217 f2)\nand permuting f3, f4: \u2200p \u2208 f \u20323, q \u2208 f4, V (p, q) \u2286 V (f1 \u2217 f2) The two conditions above are equivalent to the following:\n\u2200p \u2208 f \u20323, q \u2208 f \u2032 4, V (p, q) \u2286 V (f1 \u2217 f2) \u2200p \u2208 f \u20323, q \u2208 f34, V (p, q) \u2286 V (f1 \u2217 f2) \u2200p \u2208 f34, q \u2208 f \u2032 4, V (p, q) \u2286 V (f1 \u2217 f2)\nIn the last two cases p, q have disjoint sets of variables. We prove the following:\nProposition A.13. If p, q, are irreducible polynomials over disjoint sets of variables, then V (p, q) \u2286 V (f \u2217 g) iff V (p, q) \u2286 V (f) or V (p, q) \u2286 V (g). The proposition follows from the following lemma. Lemma A.14. Let p(x), q(y) be irreducible polynomials, over disjoint sets of variables x and y respectively. Suppose V (p, q) \u2286 V (f1f2) where f1(x, y), f2(x, y) are arbitrary polynomials. Then at least one of the following holds:\n\u2022 V (p, q) \u2286 V (f1) \u2022 V (p, q) \u2286 V (f2)\nProof. Notice that V (p, q) = {(a, b)\u2223p(a) = 0 \u2227 q(b) = 0}. In other words, V (p, q) is the cartesian product V (p) \u00d7 V (q), and the assumption of the lemma is: \u2200a \u2208 V (p),\u2200b \u2208 V (q)\u21d2 (a, b) \u2208 V (f1f2) We claim:\n\u2200a \u2208 V (p) \u2236 either q divides f1[a/x] or (*) q divides f2[a/x]\nIndeed, if a \u2208 V (p), then: {a} \u00d7 V (q) \u2286 V ((f1f2)[a/x])\nThus q divides f1[a/x]f2[a/x], hence it either divides f1[a/x] or divides f2[a/x] (because it is irreducible). We claim that the following stronger property holds:\neither: \u2200a \u2208 V (p), q divides f1[a/x] (**) or: \u2200a \u2208 V (p), q divides f2[a/x]\nThis claim proves the lemma, because in the first case V (p, q) \u2286 V (f1), and in the second case V (p, q) \u2286 V (f2). We prove (**) by using the remainder of dividing f1(x, y) by q(y), which we denote g1. In other words:\ng1(x, y) = sumece(x)ye (1)\nWhere every exponent sequence e for y is \u201csmaller\u201d than the multidegree of g. Formally, following standard notations for multivariate polynomials and Gro\u0308bner bases, fix an admissible monomial order <, then g1 is the normal form of g1 w.r.t. p, that is f1 \u21d2\u2217q g1 and there is no h s.t. g1 \u21d2q h. Similarly, let g2(x, y) be the remainder of dividing f2 by q: g2(x, y) = sume\u2032de\u2032(x)ye\u2032 (2) From (*) we have:\n\u2200a \u2208 V (p) \u2236 (+) either: \u2200e, ce[a/x] = 0 or \u2200e\u2032, de\u2032[a/x] = 0\nThis implies: \u2200a \u2208 V (p),\u2200e, e\u2032ce[a/x]de\u2032[a/x] = 0 Or, equivalently: \u2200e, e\u2032,\u2200a \u2208 V (p), ce[a/x]de\u2032 [a/x] = 0 Or, still equivalently: \u2200e, e\u2032 \u2236 p(x) divides ce(x)de\u2032(x) Since p(x) is irreducible, it implies that p(x) either divides ce(x) or divides de\u2032(x). We claim that the following holds:\neither: \u2200e, p(x) divides ce(x) (++) or: \u2200e\u2032, p(x) divides de\u2032(x)\nSuppose not. Then there exists e such that p(x) does not divide ce(x) and there exists e\u2032 such that p(x) does not divide de\u2032(x). This is a contradiction, because we know that p(x) must divide one of ce(x) or de\u2032(x). Property (++) immediately implies (**).\nIntuitively, proposition A.13 generalizes the fact that: V (p) \u2286 V (fg) implies V (p) \u2286 V (f) or V (p) \u2286 V (g) (because V (p) \u2286 V (f \u2217 g) implies that p divides fg, hence it divides either f or g, because p is irreducible).\nBy applying this argument repeatedly we obtain V (p, q) \u2286 V (r), where r is some factor of f1 or f2. Recall from equation (1) that f \u20323 = Factors(f3) \u2212 Factors(f4) and f \u20324 = Factors(f4) \u2212 Factors(f3). Abusing notation by using f1 to denote Factors(f1),\nthe conditions become:\n\u2200p \u2208 f \u20323, q \u2208 f34, either(p \u2208 f1 \u222a f2) or (q \u2208 f1 \u222a f2) \u2200p \u2208 f34, q \u2208 f \u2032 4, either(p \u2208 f1 \u222a f2) or (q \u2208 f1 \u222a f2)\nThese conditions are equivalent to: (f \u20323 \u2286 f1 \u222a f2) or (f34 \u2286 f1 \u222a f2)(f34 \u2286 f1 \u222a f2) or (f \u20324 \u2286 f1 \u222a f2) Indeed, suppose otherwise, i.e. there exists p \u2208 f \u20323 and q \u2208 f34 s.t. neither p nor q are in f1 \u222af2: then the first condition above fails too.\nApplying distributivity, these conditions are equivalent to: (f \u20323 \u2286 f1 \u222a f2) and (f \u20324 \u2286 f1 \u222a f2) or\nf34 \u2286 f1 \u222a f2\nIn other words, the proposition fails only on queries that satisfy the following three conditions, and all conditions obtained by permuting f1, . . . , f4:\nf3 \u2286 f1 \u222a f2 (C1)\nor\nf4 \u2286 f1 \u222a f2 (C2)\nor\n\u2206(f3, f4) \u2286 f1 \u222a f2 (C3) Where \u2206 denotes the symmetric difference operator.\nWe can now classify the queries that do not satisfy the assumptions of Lemma A.19 according to the following corollary:\nCorollary A.15. If a query Q does not satisfy the assumptions of A.19, then one of the following two cases holds:\n1. There exists an irreducible factor w that occurs in only one of the four functions F1, . . . , F4. Assume without loss of generality that w \u2208 F4. Then (C1) must hold, under all permutations of f1, f2, f3. This implies that every factor that occurs in f1, f2, f3 occurs in at least two of them.\nTherefore, these functions look like this:\nf1 = p \u2217 q \u2217 s\nf2 = p \u2217 r \u2217 s\nf3 = q \u2217 r \u2217 s\nf4 = w \u2217 . . .\nThat is, p contains all factors that occur in both f1 and f2, likewise for q, r, s, and w occurs only in f4. For example:\nf1 = x1x2(1 \u2212 x3) f2 = x1(1 \u2212 x3) f3 = x2(1 \u2212 x3) f4 = x3\n2. Every factor occurs in two or more functions.Then the functions look like this:\nf1 = p \u2217 q \u2217 r \u2217 [rest] f2 = p \u2217 s \u2217 t \u2217 [rest] f3 = q \u2217 s \u2217 r \u2217 [rest] f4 = r \u2217 t \u2217 r \u2217 [rest]\nwhere p consists of all factors that occur in both f1 and f2, likewise for q, r, s, t, and [rest] represents factors that occur in three or more functions.\nIn Section A.8 and Section A.9 we describe how queries of these type are handled. For all other queries, the conditions of A.19 are satisfied and we apply the hardness proof described in Section A.5."}, {"heading": "A.8 CASE 1", "text": "In this section, we prove that queries falling into case 1 of the analysis of Corollary A.15 still contain an algebraically independent set of functions such that the hardness proof of Section A.5 applies.\nOur four functions look like:\nf1 = p \u2217 q \u2217 s\nf2 = p \u2217 r \u2217 s\nf3 = q \u2217 r \u2217 s\nf4 = w \u2217 . . .\nWhere p is a product of factors, and similarly q, r, s. w is any factor. Note that p, q, r, s do not share any variables, due to multilinearity.\nWe assume that f4 \u2260 1 and is distinct from each of f1, f2, f3.\nWe consider the following possibilities:\nf1 = f2 = f3\nor\nf1 = f2, f1 \u2260 f3\nor\nf1 \u2260 f2, f1 \u2260 f2, f2 \u2260 f3\nNote that the cases f1 = f3, f1 \u2260 f2 and f2 = f3, f2 \u2260 f1 are symmetric to the second case, f1 = f2, f1 \u2260 f3.\nSuppose f1 = f2 = f3. This implies that p = q = r = 1, and s is any factor. Our functions are:\nf1 = s\nf2 = s\nf3 = s\nf4 = w \u2217 . . .\nIf s = 1, then we can invert the unary predicates (by replacing each probability p with 1 \u2212 p) as necessary to ensure that f4 = f00, and we can solve the #PP2CNF by summing over assignments where the number of clauses with end points both false is held to zero.\nIf s \u2260 1, then we group f1, f2, f3 into a single function, f \u2032. We consider an annihilating polynomial A s.t. A(f \u2032g\u2032, f4g4) = 0. We set g4 = 0 and g\u2032 \u2260 0 (by setting the factor w of f4 to 0) and obtain A(f \u2032,0) = 0 \u21d2 A = a2R, a contradiction of the irreducibility of A. This shows algebraic independence of the polynomials f \u2032g\u2032, f1g4, allowing the hardness reduction of Section A.5 to proceed.\nNext, suppose f1 = f2, f1 \u2260 f3. If f3 = 1, then q = r = s = 1 and our functions are:\nf1 = p\nf2 = p\nf3 = 1\nf4 = w \u2217 . . .\nAs before, we group f1 and f2 and ensure (by manipulating tuple probabilities for the unary predicates) that f4 corresponds to f00. Algebraic independence of f1g1 and f4g4 follows by the same argument above.\nThe case f1 = f2 = 1, and f3 \u2260 1, is impossible due to the assumed structure on our functions (every factor in f3 also appears in either f1 or f2)\nConsider now the case when f1, f2, f3 are distinct. Since s appears in all three functions, we ignore it for now and look at p, q, r. For the functions to be distinct, we must have at least two of these factors not equal to 1 (and themselves distinct). Assume wlog that p \u2260 1, q \u2260 1, p \u2260 q.\nThen, if r = 1, our functions are:\nf1 = p \u2217 q \u2217 s\nf2 = p \u2217 s\nf3 = q \u2217 s\nf4 = w \u2217 . . .\nSince p, q, s are over distinct variables, there are at least 3 distinct variables in f1, f2, f3. Consider the (rectangular) Jacobian of f1, f2, f3 with respect to x1, x2, x3, where x1 is chosen s.t. x1 is in p, x2 is in q, and x3 is in s.\nThe Jacobian contains the following 3x3 sub matrix:\nJ = \u239b\u239c\u239d qs\u2202p/\u2202x1 ps\u2202q/\u2202x2 pq\u2202s/\u2202x3 s\u2202p/\u2202x1 0 p\u2202s/\u2202x3 0 s\u2202q/\u2202x2 q\u2202s/\u2202x3 \u239e\u239f\u23a0\nThe determinant of J is: det(J) = \u2212pqs \u2217 \u2202p/\u2202x1 \u2217 \u2202q/\u2202x2 \u2217 \u2202s/\u2202x3 \u2260 0 This establishes the algebraic independence of f1, f2, f3.\nSuppose there exists an annihilating polynomial A(a1, a2, a3, a4) s.t. A(f1g1, f2g2, f3g3, f4g4) = 0. We set g4 = 0 (using the distinct w factor) and set g1 = c1 \u2260 0, g2 = c2 \u2260 0, g3 = c3 \u2260 0. We obtain A(c1f1, c2f2, c3f3,0) = 0. It follows that A = a4R, as any terms of A without a4 imply the existence of an annihilating polynomial for c1f1, c2f2, c3f3, which implies an annihilating polynomial for f1, f2, f3. Thus, by contradiction, f1, f2, f3, f4 are algebraically independent.\nThe final case is if r \u2260 1. Our functions are:\nf1 = p \u2217 q \u2217 s\nf2 = p \u2217 r \u2217 s\nf3 = q \u2217 r \u2217 s\nf4 = w \u2217 . . .\nSince p, r, q are over distinct variables, there are at least 3 distinct variables in f1, f2, f3. As before, we consider the (rectangular) Jacobian of f1, f2, f3 with respect to x1, x2, x3, where x1 is chosen s.t. x1 is in p, x2 is in q, and x3 is in r.\nThe Jacobian contains the following 3x3 sub matrix:\nJ = \u239b\u239c\u239d q\u2202p/\u2202x1 p\u2202q/\u2202x2 0 r\u2202p/\u2202x1 0 p\u2202r/\u2202x3 0 r\u2202q/\u2202x2 q\u2202r/\u2202x3 \u239e\u239f\u23a0\nWith determinant:\ndet(J) = \u22122qpr\u2202p/\u2202x1 \u2217 \u2202q/\u2202x2 \u2217 \u2202r/\u2202x3\nNone of these terms are constantly zero, so we have that the determinant is nonzero. Repeating the previous argument with annihilating polynomials, we prove that f1, f2, f3, f4 are algebraically independent."}, {"heading": "A.9 CASE 2", "text": "We prove that queries falling into case 2 of the analysis of Corollary A.15 are precisely those queries satisfying the conditions of the zigzag construction. For these queries, we prove hardness as described in Section A.11.\nOur four functions look like:\nf1 = p \u2217 q \u2217 r\nf2 = p \u2217 s \u2217 t\nf3 = q \u2217 s \u2217 k\nf4 = r \u2217 t \u2217 k\nWhere arbitrary additional factors may be added, as long as each of these additional factors appears in at least three of the four functions.\nOnly p and k, or q and t, or r and s, can share variables. Every other pair of factors appears together in one of f1, f2, f3, f4, and thus must have distinct variables by multilinearity. Let x be the variables of p, k, let y be the variables of q, t, and let z be the variables of r, s, with x, y, z all disjoint. We have:\nf1 = p(x) \u2217 q(y) \u2217 r(z) f2 = p(x) \u2217 t(y) \u2217 s(z) f3 = k(x) \u2217 q(y) \u2217 s(z) f4 = k(x) \u2217 t(y) \u2217 s(z)\nBecause x, y, z are disjoint sets of variables, we can set p(x) = k(x) = c1 \u2260 0, q(y) = t(y) = c2 \u2260 0, and r(z) = s(z) = c3 \u2260 0. (If a factor is identically one, then ci = 1)\nThis gives us:\nf1 = c1 \u2217 c2 \u2217 c3\nf2 = c1 \u2217 c2 \u2217 c3\nf3 = c1 \u2217 c2 \u2217 c3\nf4 = c1 \u2217 c2 \u2217 c3\nNote that any additional factors, added to at least three of the four functions, must be over an independent set of variables. Thus, we can set each such additional factor to 1 and retain the same value of f1, f2, f3, f4 as above.\nThis gives us a setting of all four functions to a constant, non-zero value. This is the precondition for ap-\nplying the zigzag construction of Section A.11."}, {"heading": "A.10 MULTIPLE UNARY SYMBOLS", "text": "We prove that a query with multiple left or right unary symbols can always be rewritten to an equivalent, in terms of hardness, query with one unary symbol.\nA.10.1 Rewriting an immediately unsafe query\nWe first prove that, if Q is immediately unsafe, it is equivalent to a query with only one left and one right unary symbol.\nProposition A.16. If Q is immediately unsafe and U any unary symbol, then Q[0/U] is not splittable, and Q[1/U] is not splittable. Proof. Let Q[0/U]\u21d2 T , where T is a prime implicate consisting only of unary symbols, with at least one Ui and one Vj . Then Q \u21d2 U \u2228T , and one can check that no strict subset of U \u2228 T is an implicate of Q, hence U \u2228 T is a prime implicate of Q, proving that Q is splittable, a contradiction.\nProposition A.17. If Q is immediately unsafe, has at least two unary symbols U1, U2, and both Q[0/U1,0/U2] and Q[1/U1,0/U2] are satisfiable, then at least one of the following four queries is not decomposable: Q[0/U1],Q[1/U1],Q[0/U2],Q[1/U2] Proof. We use the following two facts:\n(A) If p does not depend on u and divides f , then p divides both f[0/u] and f[1/u] (B) Conversely: let u, v be two distinct variables, f a multilinear polynomial, and assume f[0/u] \u2260 0. Let p\u2032(v), p(v) be the unique factors of f and f[0/u], respectively, that contain v. Then, if p\u2032(v) does not depend on u, then p\u2032(v) = p(v). In other words, the factor p(v) of f[0/u] is also a factor of f . Notice that we must assume f[0/u] \u2260 0, otherwise p(u) is not uniquely defined. The same statement holds for f[1/u]. Suppose both q[0/U1] and q[1/U1] are decomposable. Let v be any variable corresponding to a right predicate. Since q depends on v, at least one of q[0/U1], q[1/U1] also depends on v, and we assume wlog q[0/U1] depends on v. Let p(v) be the irreducible factor of q[0/U1] that contains v. By definition, p(v) does not depend on U2. From fact (A) we obtain:\np(v) divides q[0/U1,0/U2] and p(v) divides q[0/U1,1/U2]\nSuppose now that q[0/U2] is also decomposable, and let p\u2032(v) be its irreducible factor containing the variable v. (If q[0/U2] does not depend on v, then p\u2032(v) = 1.) From Fact (A) we also obtain:\np\u2032(v) divides q[0/U1,0/U2] and p\u2032(v) divides q[1/U1,0/U2]\nWe apply fact (B) to f = q[0/U1] and f[0/U2] = q[0/U1,0/U2]: their factors containing v are p(v) and p\u2032(v) respectively, and since q[0/U1,0/U2] \u2260 0 we must have p(v) = p\u2032(v). We apply fact (B) again to f = q[1/U1] and f[0/U2] = q[1/U1,0/U2]: since the latter has the factor p(v), so must the former, in other words p(v) is a factor of q[1/U1]. Therefore p(v) is a factor of q, and does not contain any unary symbol U1, U2, . . . . Repeating this argument for every variable v, we conclude that q is decomposable, which is a contradiction.\nThe only cases that remain to be handled are when:\nQ[0/U1] = 0 and Q[1/U2] = 0 or Q[0/U1] = 0 and Q[1/U2] = 0\nThus, either Q \u21d2 (U1 \u21d4 U2), or Q \u21d2 (U1 \u21d4 \u00acU2). We treat these cases by substituting all occurrences of the predicate U2 with U1 (or \u00acU1) in Q. The new query Q\u2032 has the same probability as Q but one fewer unary symbol.\nA.10.2 Hardness of Q after inclusion/exclusion\nWe prove that if the algorithm starts with queryQ and reaches an immediately unsafe query Q\u2032 during an inclusion/exclusion step, there is a sequence of deterministic rewrites from Q to an immediately unsafe query Q\u2032\u2032. This shows that, if the algorithm gets stuck during an inclusion/exclusion step while computing Pr(Q), then computing Pr(Q) is #P-hard. Suppose Q is splittable. Then Q contains one or more splittable clauses of the form (Li\u2228Ri), where Li is the disjunction of one or more left unary symbols and Ri is the disjunction of one or more right unary symbols:\nQ = (L1 \u2228R1) \u2227 (L2 \u2228R2) \u2227\u22ef\u2227 (Lm \u2228Rm) \u2227Q After splitting on the (L1 \u2228 R1) clause and applying distributivity, Q may be written:\nQ = L1 \u2227 (L2 \u2228R2) \u2227\u22ef \u2227 (Lm \u2228Rm) \u2227Q \u2228\nR1 \u2227 (L2 \u2228R2) \u2227\u22ef\u2227 (Lm \u2228Rm) \u2227Q = Q1 \u2228Q2\nWe may continue to split Q1 and Q2 into Q11,Q12,Q21,Q22, and so on. Some clauses may be lost due to the introduction of redundancy, but in general we end up with an expression for Q as the disjunction of 2m CNF formulas Qi:\nQ = Q1 \u2228Q2 \u2228\u22ef \u2228Q2m\nEach Qi is of the form:\nQi = Lw1 \u2227\u22ef\u2227Lwj \u2227Rz1 \u2227\u22ef\u2227Rzk \u2227Q\nWhere w and z define sequences mapping to L1, . . . , Lm and R1, . . . ,Rm.\nThe above expression for Q in terms of the Qi is generated by the algorithm before applying the inclusion/exclusion step. Thus, the algorithm attempts to compute Pr(Q) recursively according to the formula Pr(Q) = \u2212\u2211s\u2286[m](\u22121)\u2223s\u2223Pr(\u22c0i\u2208s Qi). Note that every term in this summation can be written in the general form of Qi above. We claim that, if any term of the summation is immediately unsafe, there is a deterministic rewrite sequence \u03c1 (setting unary symbols to true or false) that satisfies each Li and Rj clause, such that Qi[\u03c1] = Q[\u03c1], and that Q[\u03c1] is immediately unsafe. This implies that, if the algorithm gets stuck while recursively processing a query Q after an inclusion/exclusion step, Q is #P-hard.\nWe now prove the following proposition, from which the above claim follows immediately.\nProposition A.18. If Q\u2032 = L \u2227 Q, where L is a disjunction of only left or only right unary symbols, and Q\u2032 is immediately unsafe, then there exists a unary symbol Ui in L and value \u03b1 \u2208 {0,1} such that Q\u2032[\u03b1/Ui] = true\u2227Q[\u03b1/Ui] =Q[\u03b1/Ui], and Q[\u03b1/Ui] is immediately unsafe.\nProof. Let m be the number of positive literals in L and n be the number of negated literals, such that L may be written:\nL = U1 \u2228\u22ef\u2228Um \u2228 \u00acUm+1 \u2228\u22ef \u2228 \u00acUm+n\nDenote by q the arithmetization of the grounding of Q\u2032 over a domain of size 1.\nThe clause L in Q\u2032 implies that q must take the fol-\nlowing form:\nq = \u2211 s\u2286[m+n] \u220f i\u2208s,\n1\u2264i\u2264m\nui \u220f j\u2208s,\nm+1\u2264j\u2264m+n (1 \u2212 uj)fs Which states that every term of q must contain a variable corresponding to some Ui in L. Now, suppose that q[1/ui] is decomposable for all 1 \u2264 i \u2264 m and q[0/ui] is decomposable for all m + 1 \u2264 j \u2264 m + n. We can write q[1/u1] as follows: q[1/u1] = f{1} + \u2211\ns\u2286[m+n]\n\u220f i\u2208s,\n1\u2264i\u2264m, i\u22601\nui \u220f j\u2208s,m+1\u2264j\u2264m+n\n(1 \u2212 uj)fs\n= s1t1\nWhere s1 is a polynomial that contains every left unary variable, and t1 is a polynomial that contains every right unary variable,, and the variables of s1 and t1 are disjoint. Since t1 divides q[1/u1], and t1 does not depend on any ui, we have that t1 also divides q[1/u1,0/u2, . . . ,0/um,1/um+1, . . . ,1/um+n] = f{1}. Repeating this process for every ui, we see that ti divides fi, for every 1 \u2264 i \u2264 m + n. Finally, each ti must divide q[1/u1, . . . ,1/um,0/um+1, . . . ,0/um+n], or ti = tj for all i, j. Let t denote this common value. We may repeat this process for all subsets of [m+n] of size two, obtaining that t must also divide those, and continue for all subsets of size 3,4, . . . ,m + n, until we have that t divides fs for all s \u2286 [m + n]. From here, we see that t divides q, contradicting the assumption that Q\u2032 was not decomposable."}, {"heading": "A.11 ZIGZAG CONSTRUCTION", "text": "The zigzag construction is a technique used in (Dalvi and Suciu, 2012) to prove the #P-hardness of positive queries. The essence of their technique is that, given a query Q, one can construct a DB such that Pr(Q) \u2261 Pr(Q\u2032), where Q\u2032 = Q1 \u2227Q2 \u2227 \u22ef; essentially, Q\u2032 is the conjunction of multiple copies of Q, each over distinct relational atoms except for their unary atoms, which are connected in a linear chain from Q1 \u2192 Q2 \u2192 \u22ef. This is an essential tool in their reduction from #\u03a6 for positive queries. The full construction is quite complex, and we refer to their work for complete details.\nWe note here one crucial assumption behind the zigzag construction that prevents it from applying directly to queries with negation: with a monotone query, by setting tuple probabilities to 0 or 1 as appropriate, it\nis simple to ensure that Pr(Q\u2032) does not depend on unwanted edges between atoms of KB, e.g., between a unary atom of Qi and a unary atom of Qi+2. If the query is monotone, we simply set all such probabilities to 1 (in the CNF case) and the undesired components of the query vanish. However, this is not guaranteed to work for queries with negation: we must consider all possible assignments to tuples in the domain, and thus, in general, the claim that Pr(Q) \u2261 Pr(Q\u2032) fails. The motivation for our analysis in Section A.9 is that, when the probabilities on each unwanted edge of the query Q\u2032 can be set to some non-zero constant ci, we can treat all unwanted components of the expression for Pr(Q\u2032) as constant factor c0, dependent on the size of the domain and the constants c1, . . . , ck. This gives us Pr(Q) \u2261 c0Pr(Q\u2032), allowing us in these cases to use the zigzag construction to prove hardness for queries with negation."}, {"heading": "A.12 ALGEBRAIC VARIETIES", "text": "Lemma A.19. Suppose there exists two factors p \u2208 Factors(f3), q \u2208 Factors(f4) such that the following hold:\n(a) V (q) /\u2286 V (f3) (b) V (p, q) /\u2286 V (f1) \u222a V (f2)\nIf k1, k2 are algebraically independent, then the polynomials f1k1, f2k2, f3k3, f4k4 are algebraically independent.\nProof. Suppose the contrary, that there exists an annihilating polynomial: A(f1k1, . . . , f4k4) = 0 From (b) we derive that there exists some value a \u2208 V (p, q) such that: f1[a/x] \u2260 0, f2[a/x] \u2260 0, f3[a/x] = f4[a/x] = 0 From (a) and (b) we derive that V (q) is not included in V (f1)\u222aV (f2)\u222aV (f3). Otherwise V (q) \u2286 V (f1f2f3) and by Hilbert\u2019s Nullstellensatz: (f1f2f3)m \u2208 \u27e8q\u27e9, hence q is a factor of (f1f2f3)m, hence it is a factor of either f1, f2, or f3, violating either (b) or (a) Thus, there exists a value b \u2208 V (q) such that:\nf1[b/x] \u2260 0, f2[b/x] \u2260 0, f3[b/x] \u2260 0, f4[b/x] = 0 We claim that it is possible to choose a and b such that they are consistent, in other words we claim that p[b/x] has some free variables (not set by b) such that we can obtain a by setting those variables to some constants.\nThis is easiest to see using the quotient construction.\nIf R[x] denotes the ring of multivariate polynomials over x, then R[x]/q(x) is the quotient ring. For any polynomial f(x) \u2208 R[x], its equivalence class is denoted [f(x)] \u2208 R[x]/q(x). Setting q = 0 means, technically, replacing every polynomial f with [f ]. Note that [q(x)] = 0, which implies [f4] = 0, and we have [f1], [f2], [f3] \u2260 0, because V (q) is not a subset of V (f1f2f3). For a polynomial F (x, y) \u2208 R[x, y], its equivalence class [F (x, y)] is obtained by writing F as a sum of monomials: F = sumeCe(x)ye Then [F (x, y)] = sume[Ce(x)]ye. Therefore, [f1k1] =[f1]k1, and likewise for f2, f3, f4. Denoting B(z1, z2, z3) = A(z1, z2, z3,0), we cannot have B \u2261 0 because then A would be reducible. Thus:\n0 =[A(f1k1, . . . , f4k4)] =A([f1]k1, [f2]k2, [f3]k3,0) =B([f1]k1, [f2]k2, [f3]k3) =B1([f1]k1, [f2]k2, [f3]k3)\nSince B([f1]k1, . . . ) is identically 0, there exists an irreducible polynomial B1 s.t. B1([f1]k1, . . . ) is identically 0. Next, we set [p] = 0. Formally, we obtain this by constructing the new quotient ring (R[x]/\u27e8q\u27e9)/\u27e8p\u27e9, and mapping every polynomial [f] to [[f]]. We have [[p]] = 0, hence [[f3]] = 0. We claim that[[f1]], [[f2]] \u2260 0. Indeed, suppose [[f1]] = 0, then[f1] \u2208 \u27e8[p]\u27e9, which is equivalent to f1 \u2208 \u27e8p, q\u27e9, but this contradicts (b). Therefore:\n0 =B1([[f1]]k1, [[f2]]k2, [[f3]]k3) =B1([[f1]]k1, [[f2]]k2,0)\nSince [[f1]], [[f2]] are non-zero, we can substitute all their variables with constants s.t. [[f1]] = c1 \u2260 0,[[f2]] = c2 \u2260 0: 0 = B1(c1k1, c2k2,0) This is a contradiction, proving the claim."}], "references": [{"title": "Exact lifted inference with distinct soft evidence on every object", "author": ["Hung B Bui", "Tuyen N Huynh", "Rodrigo de Salvo Braz"], "venue": "In AAAI,", "citeRegEx": "Bui et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bui et al\\.", "year": 2012}, {"title": "On probabilistic inference by weighted model counting", "author": ["Mark Chavira", "Adnan Darwiche"], "venue": "Artificial Intelligence,", "citeRegEx": "Chavira and Darwiche.,? \\Q2008\\E", "shortCiteRegEx": "Chavira and Darwiche.", "year": 2008}, {"title": "Compiling relational Bayesian networks for exact inference", "author": ["Mark Chavira", "Adnan Darwiche", "Manfred Jaeger"], "venue": "International Journal of Approximate Reasoning,", "citeRegEx": "Chavira et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chavira et al\\.", "year": 2006}, {"title": "The dichotomy of probabilistic inference for unions of conjunctive queries", "author": ["Nilesh Dalvi", "Dan Suciu"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Dalvi and Suciu.,? \\Q2012\\E", "shortCiteRegEx": "Dalvi and Suciu.", "year": 2012}, {"title": "A logical approach to factoring belief networks", "author": ["Adnan Darwiche"], "venue": "Proceedings of KR,", "citeRegEx": "Darwiche.,? \\Q2002\\E", "shortCiteRegEx": "Darwiche.", "year": 2002}, {"title": "Probabilistic inductive logic programming: theory and applications", "author": ["Luc De Raedt", "Paolo Frasconi", "Kristian Kersting", "Stephen Muggleton", "editors"], "venue": null, "citeRegEx": "Raedt et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Raedt et al\\.", "year": 2008}, {"title": "Inference in probabilistic logic programs using weighted CNF\u2019s", "author": ["Daan Fierens", "Guy Van den Broeck", "Ingo Thon", "Bernd Gutmann", "Luc De Raedt"], "venue": "In Proceedings of UAI,", "citeRegEx": "Fierens et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fierens et al\\.", "year": 2011}, {"title": "An Introduction to Statistical Relational Learning", "author": ["L. Getoor", "B. Taskar", "editors"], "venue": null, "citeRegEx": "Getoor et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Getoor et al\\.", "year": 2007}, {"title": "Probabilistic theorem proving", "author": ["Vibhav Gogate", "Pedro Domingos"], "venue": "In Proceedings of UAI,", "citeRegEx": "Gogate and Domingos.,? \\Q2011\\E", "shortCiteRegEx": "Gogate and Domingos.", "year": 2011}, {"title": "Liftability of probabilistic inference: Upper and lower bounds", "author": ["Manfred Jaeger", "Guy Van den Broeck"], "venue": "In Proceedings of the 2nd International Workshop on Statistical Relational AI,", "citeRegEx": "Jaeger and Broeck.,? \\Q2012\\E", "shortCiteRegEx": "Jaeger and Broeck.", "year": 2012}, {"title": "Probabilistic databases with markoviews", "author": ["Abhay Jha", "Dan Suciu"], "venue": "Proceedings of the VLDB Endowment,", "citeRegEx": "Jha and Suciu.,? \\Q2012\\E", "shortCiteRegEx": "Jha and Suciu.", "year": 2012}, {"title": "Lifted inference seen from the other side: The tractable features", "author": ["Abhay Jha", "Vibhav Gogate", "Alexandra Meliou", "Dan Suciu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jha et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jha et al\\.", "year": 2010}, {"title": "The complexity of the annihilating polynomial", "author": ["Neeraj Kayal"], "venue": "In Computational Complexity,", "citeRegEx": "Kayal.,? \\Q2009\\E", "shortCiteRegEx": "Kayal.", "year": 2009}, {"title": "Lifted probabilistic inference", "author": ["Kristian Kersting"], "venue": "In Proceedings of European Conference on Artificial Intelligence (ECAI),", "citeRegEx": "Kersting.,? \\Q2012\\E", "shortCiteRegEx": "Kersting.", "year": 2012}, {"title": "First-order probabilistic inference", "author": ["David Poole"], "venue": "In IJCAI,", "citeRegEx": "Poole.,? \\Q2003\\E", "shortCiteRegEx": "Poole.", "year": 2003}, {"title": "The complexity of counting cuts and of computing the probability that a graph is connected", "author": ["J Scott Provan", "Michael O Ball"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Provan and Ball.,? \\Q1983\\E", "shortCiteRegEx": "Provan and Ball.", "year": 1983}, {"title": "Equivalences among relational expressions with the union and difference operators", "author": ["Yehoshua Sagiv", "Mihalis Yannakakis"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Sagiv and Yannakakis.,? \\Q1980\\E", "shortCiteRegEx": "Sagiv and Yannakakis.", "year": 1980}, {"title": "Solving Bayesian networks by weighted model counting", "author": ["T. Sang", "P. Beame", "H. Kautz"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Sang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sang et al\\.", "year": 2005}, {"title": "Enumerative Combinatorics", "author": ["Richard P. Stanley"], "venue": null, "citeRegEx": "Stanley.,? \\Q1997\\E", "shortCiteRegEx": "Stanley.", "year": 1997}, {"title": "Probabilistic databases", "author": ["Dan Suciu", "Dan Olteanu", "Christopher R\u00e9", "Christoph Koch"], "venue": "Synthesis Lectures on Data Management,", "citeRegEx": "Suciu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Suciu et al\\.", "year": 2011}, {"title": "On the completeness of firstorder knowledge compilation for lifted probabilistic inference", "author": ["Guy Van den Broeck"], "venue": "In NIPS,", "citeRegEx": "Broeck.,? \\Q2011\\E", "shortCiteRegEx": "Broeck.", "year": 2011}, {"title": "Lifted Inference and Learning in Statistical Relational Models", "author": ["Guy Van den Broeck"], "venue": "PhD thesis,", "citeRegEx": "Broeck.,? \\Q2013\\E", "shortCiteRegEx": "Broeck.", "year": 2013}, {"title": "On the complexity and approximation of binary evidence in lifted inference", "author": ["Guy Van den Broeck", "Adnan Darwiche"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Broeck and Darwiche.,? \\Q2013\\E", "shortCiteRegEx": "Broeck and Darwiche.", "year": 2013}, {"title": "Conditioning in first-order knowledge compilation and lifted probabilistic inference", "author": ["Guy Van den Broeck", "Jesse Davis"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Broeck and Davis.,? \\Q2012\\E", "shortCiteRegEx": "Broeck and Davis.", "year": 2012}, {"title": "Lifted probabilistic inference by first-order knowledge compilation", "author": ["Guy Van den Broeck", "Nima Taghipour", "Wannes Meert", "Jesse Davis", "Luc De Raedt"], "venue": "In IJCAI,", "citeRegEx": "Broeck et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Broeck et al\\.", "year": 2011}, {"title": "Skolemization for weighted first-order model counting", "author": ["Guy Van den Broeck", "Wannes Meert", "Adnan Darwiche"], "venue": "In Proceedings of the 14th International Conference on Principles of Knowledge Representation and Reasoning (KR),", "citeRegEx": "Broeck et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Broeck et al\\.", "year": 2014}, {"title": "On relations between jacobians and minimal polynomials", "author": ["Jie-Tai Yu"], "venue": "Linear algebra and its applications,", "citeRegEx": "Yu.,? \\Q1995\\E", "shortCiteRegEx": "Yu.", "year": 1995}], "referenceMentions": [{"referenceID": 4, "context": "Most notably, it underlies state-of-the-art probabilistic inference algorithms for Bayesian networks (Darwiche, 2002; Sang et al., 2005; Chavira and Darwiche, 2008), relational Bayesian networks (Chavira et al.", "startOffset": 101, "endOffset": 164}, {"referenceID": 17, "context": "Most notably, it underlies state-of-the-art probabilistic inference algorithms for Bayesian networks (Darwiche, 2002; Sang et al., 2005; Chavira and Darwiche, 2008), relational Bayesian networks (Chavira et al.", "startOffset": 101, "endOffset": 164}, {"referenceID": 1, "context": "Most notably, it underlies state-of-the-art probabilistic inference algorithms for Bayesian networks (Darwiche, 2002; Sang et al., 2005; Chavira and Darwiche, 2008), relational Bayesian networks (Chavira et al.", "startOffset": 101, "endOffset": 164}, {"referenceID": 2, "context": ", 2005; Chavira and Darwiche, 2008), relational Bayesian networks (Chavira et al., 2006) and probabilistic programs (Fierens et al.", "startOffset": 66, "endOffset": 88}, {"referenceID": 6, "context": ", 2006) and probabilistic programs (Fierens et al., 2011).", "startOffset": 35, "endOffset": 57}, {"referenceID": 8, "context": "Again, this reasoning task underlies efficient algorithms for probabilistic reasoning, this time for popular representations in statistical relational learning (SRL) (Getoor and Taskar, 2007), such as Markov logic networks (Van den Broeck et al., 2011; Gogate and Domingos, 2011) and probabilistic logic programs (Van den Broeck et al.", "startOffset": 223, "endOffset": 279}, {"referenceID": 19, "context": "Moreover, WFOMC uncovers a deep connection between AI and database research, where query evaluation in probabilistic databases (PDBs) (Suciu et al., 2011) essentially considers the same task.", "startOffset": 134, "endOffset": 154}, {"referenceID": 14, "context": "Early on, the disconnect between compact relational representations of uncertainty, and the intractability of inference at the ground, propositional level was noted, and efforts were made to exploit the relational structure for inference, using so-called lifted inference algorithms (Poole, 2003; Kersting, 2012).", "startOffset": 283, "endOffset": 312}, {"referenceID": 13, "context": "Early on, the disconnect between compact relational representations of uncertainty, and the intractability of inference at the ground, propositional level was noted, and efforts were made to exploit the relational structure for inference, using so-called lifted inference algorithms (Poole, 2003; Kersting, 2012).", "startOffset": 283, "endOffset": 312}, {"referenceID": 3, "context": "However, current asymmetric WFOMC algorithms (Dalvi and Suciu, 2012) suffer from a major limitation of their own, in that they can only count models of sentences in monotone disjunctive normal form (MDNF) (i.", "startOffset": 45, "endOffset": 68}, {"referenceID": 3, "context": "The present work seeks to upgrade a well-known PDB algorithm for asymmetric WFOMC (Dalvi and Suciu, 2012) to the SRL setting, by enabling it to count models of arbitrary sentences in conjunctive normal form (CNF).", "startOffset": 82, "endOffset": 105}, {"referenceID": 3, "context": "In the PDB setting, our algorithm is known to come with a sharp complexity guarantee, called the dichotomy theorem (Dalvi and Suciu, 2012).", "startOffset": 115, "endOffset": 138}, {"referenceID": 16, "context": "(Sagiv and Yannakakis, 1980) Checking whether logical implication Q \u21d2 Q or equivalence Q \u2261 Q holds between two CNF sentences is \u03a0p2complete.", "startOffset": 0, "endOffset": 28}, {"referenceID": 14, "context": "Yet it can still encode many SRL models, including parfactor graphs (Poole, 2003), Markov logic networks (MLNs) (Richardson and Domingos, 2006) and probabilistic logic programs (De Raedt et al.", "startOffset": 68, "endOffset": 81}, {"referenceID": 3, "context": "(Dalvi and Suciu, 2012) define an algorithm for Monotone DNF (called Unions Of Conjunctive Queries), which can be adapted to Monotone CNF; that adaptation is equivalent to Lift restricted to Monotone CNF queries.", "startOffset": 0, "endOffset": 23}, {"referenceID": 3, "context": "(Dalvi and Suciu, 2012) prove: Theorem 4.", "startOffset": 0, "endOffset": 23}, {"referenceID": 3, "context": "The proof is a significant extension of the techniques used by (Dalvi and Suciu, 2012) to prove Theorem 4.", "startOffset": 63, "endOffset": 86}, {"referenceID": 3, "context": "We note that the two clauses are dependent (since both refer to the relation Follow), hence we cannot simply multiply their probabilities; in fact, we will see that if we remove all negations, then the resulting query is #P-hard; the algorithm described by (Dalvi and Suciu, 2012) would immediately get stuck on this query.", "startOffset": 257, "endOffset": 280}, {"referenceID": 3, "context": "If we remove all negations from Q and rename the predicates we get the following query: h1 =(R(x) \u2228 S(x, y)) \u2227 (S(x, y) \u2228 T (y)) (Dalvi and Suciu, 2012) proved that computing the probability of h1 is #P-hard in the size of the PDB.", "startOffset": 129, "endOffset": 152}, {"referenceID": 3, "context": "q0 = (R(x0) \u2228 S1(x0, y0)) q1 = (S1(x1, y1) \u2228 S2(x1, y1)) q2 = (S2(x2, y2) \u2228 S3(x2, y2)) q3 = (S3(x3, y3) \u2228 T (y3)) (Dalvi and Suciu, 2012) proved that their conjunction, i.", "startOffset": 115, "endOffset": 138}, {"referenceID": 18, "context": "Once the equivalent formulas are detected, the resulting expressions can be organized in a lattice, as shown in Figure 2, and the coefficient of each term in the inclusion-exclusion formula is precisely the lattice\u2019s M\u00f6bius function (Stanley, 1997).", "startOffset": 233, "endOffset": 248}, {"referenceID": 15, "context": "(Provan and Ball, 1983) have shown that this problem is #P-hard.", "startOffset": 0, "endOffset": 23}, {"referenceID": 26, "context": "The reduction consists of a combinatorial part (the construction of certain gadgets), and an algebraic part, which makes novel use of the concepts of algebraic independence (Yu, 1995) and annihilating polynomials (Kayal, 2009).", "startOffset": 173, "endOffset": 183}, {"referenceID": 12, "context": "The reduction consists of a combinatorial part (the construction of certain gadgets), and an algebraic part, which makes novel use of the concepts of algebraic independence (Yu, 1995) and annihilating polynomials (Kayal, 2009).", "startOffset": 213, "endOffset": 226}, {"referenceID": 3, "context": "The algorithm and complexity results of (Dalvi and Suciu, 2012), which apply to positive queries, served as the starting point for our investigation of asymmetric WFOMC with negation.", "startOffset": 40, "endOffset": 63}, {"referenceID": 19, "context": "See (Suciu et al., 2011) for more background on their work.", "startOffset": 4, "endOffset": 24}, {"referenceID": 11, "context": "Existing approaches for PDBs can express complicated correlations (Jha et al., 2010; Jha and Suciu, 2012) but only consider queries without negation.", "startOffset": 66, "endOffset": 105}, {"referenceID": 10, "context": "Existing approaches for PDBs can express complicated correlations (Jha et al., 2010; Jha and Suciu, 2012) but only consider queries without negation.", "startOffset": 66, "endOffset": 105}, {"referenceID": 0, "context": "Other investigations of evidence in lifted inference include (Van den Broeck and Davis, 2012), who allow arbitrary hard evidence on unary relations, (Bui et al., 2012), who allow asymmetric soft evidence on a single unary relation, and (Van den Broeck and Darwiche, 2013), who allow evidence of bounded Boolean rank.", "startOffset": 149, "endOffset": 167}], "year": 2014, "abstractText": "In this paper we study lifted inference for the Weighted First-Order Model Counting problem (WFOMC), which counts the assignments that satisfy a given sentence in firstorder logic (FOL); it has applications in Statistical Relational Learning (SRL) and Probabilistic Databases (PDB). We present several results. First, we describe a lifted inference algorithm that generalizes prior approaches in SRL and PDB. Second, we provide a novel dichotomy result for a non-trivial fragment of FO CNF sentences, showing that for each sentence the WFOMC problem is either in PTIME or #P-hard in the size of the input domain; we prove that, in the first case our algorithm solves the WFOMC problem in PTIME, and in the second case it fails. Third, we present several properties of the algorithm. Finally, we discuss limitations of lifted inference for symmetric probabilistic databases (where the weights of ground literals depend only on the relation name, and not on the constants of the domain), and prove the impossibility of a dichotomy result for the complexity of probabilistic inference for the entire language FOL.", "creator": "LaTeX with hyperref package"}}}