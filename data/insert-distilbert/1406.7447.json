{"id": "1406.7447", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jun-2014", "title": "Unimodal Bandits without Smoothness", "abstract": "we consider stochastic bandit problems with a continuum set of arms and where the expected performance reward is a continuous and unimodal function of the arm. no further assumption is made regarding the smoothness and the structure of the expected reward function. we propose stochastic pentachotomy ( sp ), an algorithm for which we derive finite - time regret upper limit bounds. in particular, we show that, while for any expected reward function $ \\ mu $ that behaves as $ \\ mu ( x ) = \\ mu ( x ^ \\ star ) - c | x - x ^ \\ star | ^ \\ xi $ locally around its maximizer $ x ^ \\ star $ for some $ \\ xi, c & gt ; 0 $, the sp algorithm this is order - optimal, i. e., its regret scales as $ o ( \\ sqrt { t \\ log ( t ) } ) $ when the time horizon $ t $ grows large. this regret filter scaling is achieved without the knowledge of $ \\ xi $ and $ c $. our algorithm is based significantly on asymptotically optimal sequential statistical tests used to successively prune an interval that contains the best arm with high probability. to our knowledge, the sp algorithm constitutes the first sequential arm selection rule that achieves a desired regret scaling as $ o ( \\ sqrt { t } ) $ up to a logarithmic optimal factor for non - immediate smooth expected reward functions, as well as for smooth functions occurring with unknown smoothness.", "histories": [["v1", "Sat, 28 Jun 2014 23:45:30 GMT  (42kb,D)", "https://arxiv.org/abs/1406.7447v1", "22 pages"], ["v2", "Fri, 6 Mar 2015 13:24:33 GMT  (144kb,D)", "http://arxiv.org/abs/1406.7447v2", "25 pages"]], "COMMENTS": "22 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["richard combes", "alexandre proutiere"], "accepted": false, "id": "1406.7447"}, "pdf": {"name": "1406.7447.pdf", "metadata": {"source": "CRF", "title": "Unimodal Bandits without Smoothness", "authors": ["Richard Combes", "Alexandre Prouti\u00e8re"], "emails": [], "sections": [{"heading": null, "text": "\u221a T log(T )) and O( \u221a log(T )/T ),\nrespectively, when the time horizon T grows large. These scalings are achieved without the knowledge of \u03be and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to successively trim an interval that contains the best arm with high probability. To our knowledge, the SP algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error scaling as O( \u221a T ) and O(1/ \u221a T ), respectively, up to a logarithmic factor for non-smooth expected reward functions, as well as for smooth functions with unknown smoothness."}, {"heading": "1 Introduction", "text": "This paper considers the problem of stochastic unimodal optimization with bandit feedback which is a generalization of the classical multi-armed bandit problem solved by Lai and Robbins [19]. The problem is defined by a continuous and unimodal expected reward function \u00b5 defined on the interval [0, 1]. For this problem, we consider algorithms that repeatedly select an arm x \u2208 [0, 1], and get a noisy reward of mean \u00b5(x). The performance of an algorithm is characterized by its regret and its optimization error up to time horizon T (the number of observed noisy rewards). The regret is the difference between the average cumulative reward one would obtain if the function \u00b5 was known, i.e., T supx\u2208[0,1] \u00b5(x), and the actual average cumulative reward achieved under the algorithm. The optimization error is the difference between supx\u2208[0,1] \u00b5(x) and the expected reward of the arm selected at time T . Known lower bounds for the regret and optimization error scale as \u2126( \u221a T ) (for linear reward functions) and \u2126(1/ \u221a T ) (for quadratic reward functions), respectively. Our objective is to devise an algorithm whose regret and optimization error scale as O( \u221a T ) and O(1/ \u221a T ) up to a logarithmic factor for a large class of unimodal and continuous reward functions. Such an algorithm would hence be order-optimal. Importantly we merely make any assumption on the smoothness of the reward function \u2013 the latter can even be non-differentiable. This contrasts with all existing work investigating similar continuum-armed bandit problems, and where strong assumptions are made on the structure and smoothness of the reward function. These structure and smoothness are known to the decision maker, and are explicitly used in the design of efficient algorithms. \u2217Supelec, France, mail: richard.combes@supelec.fr \u2020KTH, Sweden, mail: alepro@kth.se\nar X\niv :1\n40 6.\n74 47\nv2 [\ncs .L\nG ]\n6 M\nar 2\n01 5\nWe propose Stochastic Pentachotomy (SP), an algorithm for which we derive finite-time upper bounds on regret and optimization error. In particular, we show that its regret and optimization error scale as O( \u221a T log(T )) and O( \u221a log(T )/T ) for any unimodal and continuous reward function \u00b5 that behaves as \u00b5(x) = \u00b5(x?) \u2212 C|x \u2212 x?|\u03be locally around its maximizer x? for some \u03be, C > 0. These scalings are achieved without the knowledge of \u03be or C, i.e., without the knowledge of the smoothness of \u00b5. The SP algorithm consists in successively narrowing an interval in [0, 1] while ensuring that the arm with the highest mean reward remains in this interval with high probability. The narrowing subroutine is a sequential test that takes as input an interval and samples a few arms in the interior of this interval until it gathers enough information to actually reduce the interval. We investigate a general class of such sequential tests. In particular, we provide a (finite time) lower bound of their expected sampling complexity given some guaranteed minimax risk, and design a sequential test that matches this lower bound. This optimal test is used in the SP algorithm. Interestingly, we show that to be efficient, a sequential test needs to sample at least three arms in the interior of the interval to reduce. This implies that a stochastic version of the celebrated Golden section search algorithm cannot achieve a reasonably low regret or optimization error over a large class of reward functions. Indeed such an algorithm would sample only two arms in the interval to reduce. We illustrate the performance of our algorithms using numerical experiments and compare its regret to that of existing algorithms that leverage the smoothness and structure of the reward function.\nTo our knowledge, SP is the first algorithm for continuous unimodal bandit problems that is orderoptimal for a large class of expected reward functions: Its regret and optimization error scale asO( \u221a T log(T ))\nand O( \u221a\nlog(T )/T ) for non-smooth reward functions, as well as for smooth functions with unknown smoothness.\nRelated work. Stochastic bandit problems with a continuous set of arms have recently received a lot of attention. Various kinds of structured reward functions have been explored, i.e., linear [10], Lipschitz [2], [17], [5], and convex [1], [22]. In these papers, the knowledge of the structure greatly helps the design of efficient algorithms (e.g. for Lipschitz bandits, except in [6], the Lipschitz constant is assumed to be known). More importantly, the smoothness or regularity of the reward function near its maximizer is also assumed to be known and leveraged in the algorithms. Indeed, most existing algorithms use a discretization of the set of arms that depends on this smoothness, and this is crucial to guarantee a regret scaling as O( \u221a T ). As discussed in [5], [4], without the knowledge of the smoothness, these algorithms would yield a much higher regret (e.g. scaling as O(T 2/3) for the algorithm proposed in [4]). Unimodal bandits with a continuous set of arms have been addressed in [9], [24]. In [9], the author shows that Kiefer-Wolfowitz (KW) stochastic approximation algorithm achieves a regret of the order of O( \u221a T ) under some strong regularity assumptions on the reward function (strong convexity). LSE, the algorithm proposed in [24], has a regret that scales as O( \u221a T log(T )), but requires the knowledge of the smoothness of the reward function. LSE is a stochastic version of the Golden section search algorithm, and iteratively eliminates subsets of arms based on PAC-bounds derived after appropriate sampling. By design, under LSE, the sequence of parameters used for the PAC bounds is pre-defined, and in particular does not depend of the observed rewards. As a consequence, LSE may explore too much sub-optimal parts of the set of arms. Our algorithm exploits more adaptive sequential statistical tests to remove subsets of arms, and yields a lower regret even without the knowledge of the smoothness of the reward function. A naive way to address continuous-armed bandit problems consists in discretizing the set of arms, and in applying efficient discrete bandit algorithms. This method was introduced in [18], and revisited in [7] in the case of unimodal rewards. To get a regret scaling as O( \u221a T log(T )) using this method, the reward function needs to be smooth and the discretization should depend on the smoothness of the function near its maximizer.\nOur problem is related to stochastic derivative-free optimization problems where the goal is to get close to the maximizer of the reward function as quickly as possible, see e.g. [23], [14], and references therein. However, as explained in [1], minimizing regret and optimization error constitute different ob-\njectives. Finally, it is worth mentioning papers investigating the design of sampling strategies to identify the best arm in multi-armed bandit problems, see e.g. [21], [11], [3], [15], [13]. These strategies apply to finite sets of arms, but resemble our sequential statistical tests used to reduce the interval containing the best arm. We believe that our analysis (e.g. we derive finite-time lower bounds for the expected sampling complexity of a set of tests), and our proof techniques are novel."}, {"heading": "2 Problem Formulation and Notation", "text": "We consider continuous bandit problems where the set of arms is the interval [0, 1], and where the expected reward \u00b5 is a continuous and unimodal function of the arm. More precisely, there exists x? such that x 7\u2192 \u00b5(x) is strictly increasing (resp. decreasing) in [0, x?] (resp. in [x?, 1]). We denote by U the set of such functions. Define \u00b5? = \u00b5(x?).\nTime proceeds in rounds indexed by n = 1, 2, . . .. When arm x is selected in round n, the observed rewardXn(x) is a random variable whose expectation is \u00b5(x) and whose distribution is \u03bd(\u00b5(x)), where \u03bd refers to an exponential family of distributions with one parameter (e.g Bernoulli, exponential, Gaussian, ...). We assume that the rewards (Xn(x), n \u2265 1) are i.i.d., and are independent across arms. At each round, a decision rule or algorithm selects an arm depending on the arms chosen in earlier rounds, and the corresponding observed rewards. Let x\u03c0(n) denote the arm selected in round n under the algorithm \u03c0. The set \u03a0 of all possible algorithms consists of sequential decision rules \u03c0 such that for any n \u2265 2, x\u03c0(n) is F\u03c0n\u22121-measurable where F\u03c0n is the \u03c3-algebra generated by (x\u03c0(s), Xs(x\u03c0(s)), s = 1, . . . , n). The performance of an algorithm \u03c0 \u2208 \u03a0 with time horizon T is characterized by its regret R\u03c0(T ) and optimization error E\u03c0(T ) defined as R\u03c0(T ) = T\u00b5?\u2212 \u2211T n=1 E[\u00b5(x\u03c0(n))] and E\u03c0(T ) = \u00b5?\u2212E[\u00b5(x\u03c0(T ))]. Our objective is to devise an algorithm minimizing these performance metrics. Importantly, the only information available to the decision maker about the reward function \u00b5 is that \u00b5 \u2208 U . In particular, the smoothness of \u00b5 around x? remains unknown \u2013 actually \u00b5 could well not be differentiable, e.g. \u00b5(x) = \u00b5? \u2212 |x\u2212 x?|\u03be for \u03be \u2208 (0, 1).\nNotation. In what follows, for any \u03b1, \u03b2, we denote by KL (\u03b1, \u03b2) the Kullback-Leibler divergence between distributions \u03bd(\u03b1) and \u03bd(\u03b2). When \u03b1, \u03b2 \u2208 [0, 1], and when \u03bd(\u00b7) is the family of Bernoulli distributions, this KL divergence is denoted by KL2(\u03b1, \u03b2) = KL (\u03b1, \u03b2) = \u03b1 log(\u03b1\u03b2 ) + (1\u2212\u03b1) log( 1\u2212\u03b1 1\u2212\u03b2 )."}, {"heading": "3 Stochastic Polychotomy Algorithms", "text": "We present here a family of sequential arm selection rules, referred to as Stochastic Polychotomy (SP). These algorithms consist in successively narrowing an interval in [0, 1] while ensuring that the best arm x? remains in this interval with high probability. Under the SP algorithms, the set of rounds is divided into phases, where each phase consists in running a subroutine narrowing the interval containing the best arm. The narrowing subroutine used the SP algorithms, and referred to as ITK (Interval Trimming withK sampled arms), starts with an interval I = [x, x] and K arms x1, . . . , xK with x \u2264 x1 < . . . < xK \u2264 x. It samples these K arms until a decision is taken to reduce the interval I and to output interval I \u2032 equal to either I1 = [x,max{xk : xk < x}] or I2 = [min{xk : xk > x}, x]. The subroutine ITK is described in details in the next subsection, and its outcome is illustrated in Figure 1.\nThe pseudo-code of the Stochastic Pentachotomy algorithm, an example of SP algorithm, is presented in Algorithm 1. It uses the narrowing subroutine IT3 exploiting samples from three arms in the interior of the input interval. IT3 splits the input interval into five parts (hence the name \u201dPentachotomy\u201d), and outputs a trimmed interval (referred to as I \u2032 in the pseudo-code) and its running time (expressed in number of rounds, and referred to as ` in the pseudo-code). The subroutine IT3 takes as input an interval, a time horizon (equal to the remaining number of rounds in the bandit problem), as well as a parameter controlling its risk, defined as the probability that the subroutine outputs an interval that does not contain\nAlgorithm 1 The Stochastic Pentachotomy algorithm Input parameters: time horizon T and confidence parameter \u03b3 > 1/2. Initialization: I \u2190 [0, 1] and s\u2190 T . While s > 0:\nRun IT3(I, s, T\u2212\u03b3) and let (I \u2032, `) be its output, I \u2190 I \u2032, s\u2190 s\u2212 `.\nthe arm with the highest reward. In the Stochastic Pentachotomy algorithm, the risk parameter in IT3 is always taken equal to T\u2212\u03b3 where \u03b3 > 1/2. This choice will ensure that the regret of the algorithm has an optimal scaling in T . Note that LSE, the stochastic version of Golden section search algorithm, belongs to the family of SP algorithms (for LSE, K = 4, x1 = x, and x4 = x).\n3.1 ITK: Asymptotically Optimal Sequential Tests for Interval Trimming The narrowing subroutines used in each phase of SP algorithms can be interpreted as sequential tests whose final decision is to trim a specific part of the input interval. The ITK subroutine belongs to the following generic family T of sequential tests. Sequential Tests for Interval Trimming. A sequential test \u03c7 \u2208 T takes as inputs (i) an interval I = [x, x] \u2282 [0, 1], and K arms to sample from x1, . . . , xK with x \u2264 x1 < . . . < xK \u2264 x, and (ii) a time horizon s that represents the maximum number of samples the test can gather. In round n \u2264 s, the sequential test decides either to terminate and to output a reduced interval I1 = [x,max{xk : xk < x}] or I2 = [min{xk : xk > x}, x], or to acquire a new sample from one of the arms x1, . . . , xK . The successive decisions taken under sequential test \u03c7 are represented by S\u03c7(n) \u2208 {0, 1, 2}. For n \u2264 s, if S\u03c7(n) = 1, the sequential test terminates and outputs the interval I1. Similarly if S\u03c7(n) = 2, \u03c7 terminates and outputs I2. When S\u03c7(n) = 0 and n < s, the sequential test further samples an arm x\u03c7(n) in {x1, . . . , xK}. Finally, if S\u03c7(s) = 0, we say that the test does not terminate, and it outputs the initial interval I . The sequential test is adapted in the sense that x\u03c7(n) and S\u03c7(n) are F\u03c7n\u22121-measurable. We denote by S\u03c7 \u2208 {0, 1, 2} the final outcome of the test \u03c7. The length of a sequential test \u03c7 is defined as L\u03c7 = inf{n \u2264 s : S\u03c7(n) 6= 0} if the test terminates and L\u03c7 = s otherwise. \u03c7 also outputs its length.\nITK Subroutine. To specify our sequential test \u03c7 =ITK , we introduce the following notation. Define the sets of functions Bu = {\u00b5 \u2208 U : x? /\u2208 Iu}, u \u2208 {1, 2}. We also introduce for any u \u2208 {1, 2}, the function iu : RK+ \u2192 R with\niu(\u00b51, . . . , \u00b5K) = inf \u03bb\u2208Bu K\u2211 k=1 KL (\u00b5k, \u03bb(xk)).\nWe further denote by t\u03c7k (n) = \u2211n\u2228L\u03c7 n\u2032=1 1{x\u03c7(n\u2032) = xk} the number of times arm xk is sampled up to time n and before the test \u03c7 terminates. Finally, we define the empirical average reward of arm xk up to round n \u2264 L\u03c7 as:\n\u00b5\u0302k(n) = 1\nt\u03c7k (n) n\u2211 n\u2032=1 Xn\u2032(xk)1{x\u03c7(n) = xk},\nif t\u03c7k (n) > 0 and \u00b5\u0302k(n) = 0 otherwise. Let \u00b5\u0302(n) = (\u00b5\u03021(n), . . . , \u00b5\u0302K(n)) and t\u0304 \u03c7(n) = min1\u2264k\u2264K t \u03c7 k (n). \u03c7 =ITK samples K arms in the interior of I = [x, x], i.e., x < x1 < . . . < xK < x. To simplify the presentation, we assume that for k = 1, . . . ,K, xk = x + k(x \u2212 x)/(K + 1). This assumption is not crucial, and our analysis remains valid for any choice of arms provided that they lie in the interior of I .\nThe sequential test \u03c7 =ITK has inputs I and s, as any other test in T . However \u03c7 takes an additional input \u03b6 > 0, used to control its risk. Now ITK(I, s, \u03b6) is defined as follows.\nDefine F (f, s,K) = eK+1\u2212f (fdf log(s)e/K)K ,\nand let f(s, \u03b6) \u2265 K + 1 be such that F (f(s, \u03b6), s,K) \u2264 \u03b6 (the precise choice of f(s, \u03b6) is free). The test proceeds as follows: For any n \u2264 s:\n(i) If there exists u \u2208 {1, 2} such that t\u0304\u03c7(n)iu(\u00b5\u0302(n)) \u2265 f(s, \u03b6), then S\u03c7(n) = u, i.e., \u03c7 terminates and its final output is S\u03c7 = u (ties are broken arbitrarily if both conditions t\u0304\u03c7(n)iu(\u00b5\u0302(n)) \u2265 f(s, \u03b6) for u = 1, 2 hold).\n(ii) Otherwise S\u03c7(n) = 0, and \u03c7 samples arm x\u03c7(n) = x1+(n mod K).\nThe sequential test \u03c7 outputs the interval IS\u03c7 where I0 = [x, x], I1 = [x, xK ] and I2 = [x1, x], and its length L\u03c7.\nThe performance (i.e. the minimax risk and length) of ITK will be analysed in Section 4. In view of the results derived in Sections 4 and 5, ITK is asymptotically optimal among the sequential tests in T . The design of ITK (e.g. the use of functions iu, u \u2208 {1, 2}) is actually motivated by the fundamental performance limits of tests in T derived in Section 5.\nRemark 1 In the following sections, we will mainly consider the case where the risk \u03b6 = s\u2212\u03b3 with \u03b3 > 0. In this case, one may choose f(s, s\u2212\u03b3) = f(s) := \u03b3 log(s) + 3K log(log(s)) + C, where C > 0 is independent of s and \u03b3."}, {"heading": "3.2 IT\u20323: A Computationally Efficient Sequential Test", "text": "Next we present IT\u20323, a sequential test which is computationally simpler than IT3. IT \u2032 3 is not asymptotically optimal, but its implementation is much simpler than that of IT3. Its rationale involves calculating an explicit lower bound of functions iu, u \u2208 {1, 2}, and hence IT\u20323 does not require us to compute iu. For \u2265 0, we define the function KL?, : R2 \u2192 R as:\nKL?, (\u00b51, \u00b52) = 1{\u00b51 < \u00b52} [ KL ( \u00b51 + ,\n\u00b51 + \u00b52 2\n\u2212 ) + KL ( \u00b52 \u2212 ,\n\u00b51 + \u00b52 2 +\n)] .\nand KL?(\u00b51, \u00b52) = KL?,0(\u00b51, \u00b52). The sequential test \u03c7\u2032 = IT\u20323 with inputs I , s and \u03b6 is defined by: for any n \u2264 s,\n(i) If t\u0304\u03c7 \u2032 (n)KL?(\u00b5\u03021(n), \u00b5\u03022(n)) \u2265 f(s, \u03b6), then S\u03c7 \u2032 (n) = 1, i.e., \u03c7\u2032 terminates and its final output is\nS\u03c7 \u2032 = 1. Similarly if t\u0304\u03c7 \u2032 (n)KL?(\u00b5\u03023(n), \u00b5\u03022(n)) \u2265 f(s, \u03b6), then S\u03c7 \u2032 (n) = 2.\n(ii) Otherwise S\u03c7 \u2032 (n) = 0, and \u03c7\u2032 samples arm x\u03c7 \u2032 (n) = x1+(n mod 3)."}, {"heading": "4 Performance Analysis of the Stochastic Pentachotomy Algorithm", "text": "In this section, we analyze the performance of the Stochastic Pentachotomy algorithm. To this aim, we first study how the interval trimming subroutines ITK (for K \u2265 3) and IT\u20323 perform.\n4.1 Minimax Risk and Length of ITK Let \u03c7 \u2208 T be a sequential test for interval trimming. For any \u00b5 \u2208 U , the risk \u03b1\u03c7(\u00b5) of \u03c7 is the probability that \u03c7 outputs an interval that does not contain the optimal arm, i.e, \u03b1\u03c7(\u00b5) = \u22112 u=1 1{\u00b5 \u2208 Bu}P\u00b5[S\u03c7 = u]. The minimax risk of \u03c7 is then defined as \u03b1\u03c7 = sup\u00b5\u2208U \u03b1 \u03c7(\u00b5). Observe that a test that does not terminate (almost surely) has a risk equal to 0, but then its length would be maximal. The analysis of the performance of a test hence consists in characterizing the trade-off between its risk and its length. The next theorem provides upper bounds of the minimax risk of ITK , as well as of the number of times arms are sampled before the test terminates.\nTheorem 4.1 Let K \u2265 3 and I \u2282 [0, 1]. (i) For any s \u2265 1, the minimax risk of ITK(I, s, \u03b6) is smaller than \u03b6. (ii) Let \u03b3 > 0, u \u2208 {1, 2} and k \u2208 1, . . . ,K. For all \u00b5 \u2208 U \\Bu, the test \u03c7 =ITK(I, s, s\u2212\u03b3) satisfies:\nlim sup s\u2192\u221e E\u00b5[t\u03c7k (s)] log(s) \u2264 \u03b3 iu(\u00b5(x1), . . . , \u00b5(xK)) .\nThe above theorem provides asymptotic guarantees on the length of ITK . Next, we provide a finitetime analysis of the length of IT3 and IT\u20323, and we also derive an upper bound of the minimax risk of IT\u20323.\nFinite-time analysis of IT3 and IT\u20323. The next theorem provides explicit upper bounds on the expected length of IT3 and IT\u20323. A high-probability upper-bound on the test length is also provided. This result relies on an explicit lower bound of iu(\u00b51, \u00b52, \u00b53). Theorem 4.2 will be instrumental in the regret analysis of the Stochastic Pentachotomy algorithm. We restrict the analysis to Bernoulli rewards. This is mainly for simplicity, and the proof techniques can be extended to sub-Gaussian rewards with straightforward modifications.\nTheorem 4.2 Consider I \u2282 [0, 1], \u03b3 > 0 and tests \u03c7 \u2208 {IT3(I, s, s\u2212\u03b3), IT\u20323(I, s, s\u2212\u03b3)}. (i) \u03c7 has minimax risk less than s\u2212\u03b3 . (ii) Define m = 1 if x? \u2208 [x2, x] and m = 3 otherwise. Define \u03b4 = (\u00b5(x2)\u2212 \u00b5(xm))/2. Then, we have that for all 0 < < \u03b4/2, for all k = 1, 2, 3 and all s \u2265 1:\nE\u00b5[t\u03c7k (s)] \u2264 f(s) KL?, (\u00b5(xm), \u00b5(x2)) + 2 \u22122.\n(iii) We have the following inequalities:\n(a) P\u00b5[t\u03c7k (s) \u2265 8f(s)\u03b4 \u22122] \u2264 2e\u2212f(s)\n(b) E\u00b5[t\u03c7k (s)] \u2264 32 + f(s)\n\u03b42\n(c) lim sup s\u2192\u221e E\u00b5[t\u03c7k (s)] log(s) \u2264 \u03b3 KL?(\u00b5(xm), \u00b5(x2)) .\nRecall that f(s) := \u03b3 log(s) + 9 log(log(s)) + C, see Remark 1."}, {"heading": "4.2 Regret Upper Bounds of the SP algorithm", "text": "Next, we analyze the regret of the Stochastic Pentachotomy algorithm. We refer to as SP\u2019 the algorithm using the narrowing subroutines IT\u20323 (instead of IT3 for SP). Recall that the successive narrowing subroutines IT3, the risk is always chosen equal to T\u2212\u03b3 , as specified in Algorithm 1. We first derive an upper bound valid for all \u00b5 \u2208 U and all time horizon T . We then specify the bound when \u00b5 behaves as \u00b5(x) = \u00b5(x?) \u2212 C|x \u2212 x?|\u03be locally around its maximizer x? for some \u03be, C > 0. To simplify the presentation, our bounds are stated and proved for Bernoulli rewards, but the analysis can be extended to other exponential families of distributions.\nLet \u00b5 \u2208 U . For any \u2206 > 0, define the following functions, which will be used to state our regret upper bound:\ng\u00b5(\u2206) = \u00b5 ? \u2212max(\u00b5(x? \u2212\u2206), \u00b5(x? + \u2206))\nh\u00b5(\u2206) = min\n{ min\nx\u2208[x?,x?+\u2206/4] (\u00b5(x)\u2212 \u00b5(x+ \u2206/4)), min x\u2208[x?\u2212\u2206/4,x?] (\u00b5(x)\u2212 \u00b5(x\u2212\u2206/4)) } Theorem 4.3 Let \u03c8 = 3/4. Under Algorithm \u03c0 = SP or \u03c0 = SP\u2019, for all \u00b5 \u2208 U , all T \u2265 1, and all N \u2265 1, the regret satisfies:\nR\u03c0(T ) \u2264 \u00b5?NT 1\u2212\u03b3 + Tg\u00b5(\u03c8N ) + 3(f(T ) + 32) N\u22121\u2211 N \u2032=0 g\u00b5(\u03c8 N \u2032)h\u00b5(\u03c8 N \u2032)\u22122.\nWe now make the regret upper bound of Theorem 4.3 explicit by considering a particular class of unimodal functions.\nDefinition 4.4 For given 0 < C1 \u2264 C2 < \u221e, we define U(C1, C2) the set of all unimodal functions \u00b5 \u2208 U for which there exists \u03be > 0 such that:\n(P1) \u00b5(x)\u2212 \u00b5(y) \u2265 C1(|x? \u2212 y|\u03be \u2212 |x? \u2212 x|\u03be) for all 0 \u2264 y \u2264 x \u2264 x? and x? \u2264 x \u2264 y \u2264 1.\n(P2) |\u00b5? \u2212 \u00b5(x)| \u2264 C2|x? \u2212 x|\u03be for all x \u2208 [0, 1].\nNote that for any \u00b5 \u2208 U such that |\u00b5? \u2212 \u00b5(x)| \u223cx\u2192x? C|x? \u2212 x|\u03be with C > 0, there exists C1 > 0 suitably small and C2 < \u221e suitably large such that \u00b5 \u2208 U(C1, C2). Also note that if \u00b5 \u2208 U is differentiable on [0, 1] \\ {x?}, with C1|x? \u2212 x|\u03be\u22121 \u2264 |\u00b5\u2032(x)| \u2264 C2|x? \u2212 x|\u03be\u22121, then \u00b5 \u2208 U(C1, C2).\nTheorem 4.5 Assume that the algorithm \u03c0 = SP or \u03c0 = SP\u2019is parametrized by \u03b3 > 1/2. For all \u00b5 \u2208 U(C1, C2), the regret satisfies:\nR\u03c0(T ) \u2264 2\u03c8 \u22123\u03be/2C2 C1a\u03be\n\u221a 3T (f(T ) + 32)\n\u03c8\u2212\u03be \u2212 1 + \u00b5?T 1\u2212\u03b3\nlog(TC1\u03c8 \u2212\u03be)\n\u03be log(1/\u03c8) = O(\n\u221a T log(T )).\nwhere a\u03be = 4\u2212\u03be min(1, 2\u03be \u2212 1), and where \u03be is the parameter associated with \u00b5 in Definition 4.4.\nTheorem 4.5 states that SP and SP\u2019 are order-optimal for all reward functions in U(C1, C2) (with arbitrary C1 and C2). They achieve a regret scaling as O( \u221a T log(T )) without the knowledge of the behaviour of the reward function around its maximizer. Although the regret upper bound of Theorem 4.5 is stated for reward functions in class U(C1, C2), we emphasize again that C1, C2 and \u03be are not input parameters of the algorithms."}, {"heading": "4.3 Optimization error of the SP algorithm", "text": "We conclude this section by deriving an upper bound on the optimization error of algorithms SP and SP\u2019.\nTheorem 4.6 Let \u03c8 = 3/4. Assume that the algorithm \u03c0 = SP or \u03c0 = SP\u2019is parametrized by \u03b3 > 1/2. For all \u00b5 \u2208 U(C1, C2), the optimization error under \u03c0 satisfies:\nE\u03c0(T ) \u2264 C2 C1a\u03be\n\u221a 24f(T )\nT (\u03c8\u22122\u03be \u2212 1) +\n3T\u2212\u03b3\u00b5? log(TC1\u03c8 \u2212\u03be)\n\u03be log(1/\u03c8) = O(\n\u221a log(T )/T ),\nwith a\u03be = 4\u2212\u03be min(1, 2\u03be \u2212 1), and where \u03be is the parameter associated with \u00b5 in Definition 4.4."}, {"heading": "5 Fundamental Performance Limits for Interval Trimming Subroutines", "text": "The next theorem provides a lower bound on the expected number of times each arm xk, k = 1, . . . ,K must be sampled under any sequential test with given minimax risk. The lower bound is valid for any time horizon s, which contrasts with the asymptotic lower bounds usually derived in the bandit literature (see e.g. [19]). The proof of this lower bound relies on an elegant information-theoretic argument that exploits the log-sum inequality to derive lower bounds of KL divergence numbers.\nTheorem 5.1 Let \u03c7 \u2208 T be a sequential test for interval trimming with minimax risk \u03b1. Let \u00b5 \u2208 U , and u \u2208 {1, 2}. Let \u03b2 = P\u00b5[S\u03c7 = u]. If \u03b1 \u2264 \u03b2, then\ninf \u03bb\u2208Bu K\u2211 k=1 E\u00b5[t\u03c7k (s)]KL (\u00b5(xk), \u03bb(xk)) \u2265 KL2(\u03b2, \u03b1).\nFrom the above result, we deduce Corollary 5.2 stating that any sequential test with time horizon s and with minimax risk s\u2212\u03b3 , for \u03b3 \u2208 (0, 1], has a length that scales at least as \u03b3 log(s) as s grows large. Note that the sequential tests ITK match these lower bound and are hence asymptotically optimal.\nCorollary 5.2 Let \u03b3 \u2208 (0, 1], u \u2208 {1, 2}, and \u00b5 \u2208 U . Consider a sequence (indexed by s) of sequential tests \u03c7s with time horizon s and minimax risk \u03b1\u03c7s = s\u2212\u03b3 , such that lims\u2192\u221e P\u00b5[S\u03c7s = u] = \u03b2 > 0. Then: lim infs\u2192\u221e inf\u03bb\u2208Bu \u2211K k=1 E\u00b5[t\u03c7sk (s)] log(s) KL (\u00b5(xk), \u03bb(xk)) \u2265 \u03b3\u03b2.\nAnother consequence of Theorem 5.1 is presented in Corollary 5.3. The latter states that it is impossible to construct a sequential test that samples at most two arms in the interior of I , that terminates before the time horizon s with probability larger than 1/2 and that has a minimax risk strictly less than 1/4. Note that if a test terminates before s with probability less than 1/2, its expected length is at least s/2. Such a test would be useless in bandit problems since running it with time horizon s = T would incur a regret linearly growing with T .\nCorollary 5.3 Consider the family of sequential tests running on the interval I = [x, x], and arms x = x1 < x2 < x3 < x4 = x. There exists \u00b5 \u2208 U , such that for any sequential test \u03c7 of this family with arbitrary finite time horizon s and minimax risk \u03b1 < 1/4, we have P\u00b5[S\u03c7 6= 0] \u2264 1/2 (i.e., the test does not terminate before s with probability 1/2).\nRecall that Kiefer\u2019s Golden section search algorithm [16] uses two points in the interior of the interval to reduce. Hence, the above corollary implies that it is impossible to construct a stochastic version of this algorithm that performs well without additional assumptions on the smoothness and structure of the reward function. Actually, LSE, proposed in [24], is a stochastic version of the Golden section search algorithm, but to analyze its regret, additional assumptions on the structure of the reward function are made (its minimal slope and smoothness).\nCorollary 5.3 is a direct consequence of Theorem 5.1: the choice of the reward function \u00b5 used in Corollary 5.3 is illustrated in Figure 2, and the result is obtained by considering a sequence (indexed by > 0) of unimodal functions \u03bb \u2208 B1. An efficient test must distinguish between \u00b5 and \u03bb based on the reward samples at x1, x2, x3, x4. By letting \u2192 0, we see that under such a test, the number of samples from x3 must be arbitrary large."}, {"heading": "6 Numerical Experiments", "text": "In this section, we briefly explore the performance of SP\u2032 (using parameter \u03b3 = 0.6), and compare it to that of two other algorithms, namely KL-UCB(\u03b4) and KW. KL-UCB(\u03b4) consists in applying the KLUCB algorithm [12] to the discrete set of arms {0, \u03b4, 2\u03b4, . . . , 1}. KW is the algorithm proposed in [9]. The performance of LSE [24] is not reported here, since it is generally outperformed by KL-UCB(\u03b4), as shown in [7].\nWe consider two reward functions satisfying our assumptions with \u03be = 1/2 and \u03be = 2, respectively. More precisely, \u00b5(x) = 1 \u2212 (2|1/2 \u2212 x|)\u03be for x \u2208 [0, 1]. The first function is not differentiable at its maximizer, whereas the second function is just quadratic. Note that KW should then perform well for the quadratic rewards (there the regret scales as O( \u221a T ) [9]), but there is not guarantee that it would do well for the non-differentiable reward functions. For KL-UCB(\u03b4), the optimal discretization step \u03b4 depends on the smoothness of the reward function, and is set to (log(T )/ \u221a T )1/\u03be.\nIn Figure 3, we present the regret of the various algorithms (averaged over 10 independent runs). Observe that without the knowledge of the smoothness of the function, SP\u2032 is able to significantly outperform the two other algorithms. As expected, KW does not perform well when \u03be = 1/2, but outperforms KL-UCB(\u03b4) for \u03be = 2.\nFigure 4 presents a graphical illustration of a typical run of SP\u2032 with reward function \u00b5(x) = 1 \u2212 (2|1/2 \u2212 x|)\u03be, \u03be = 0.5 (left), and \u03be = 2 (right), time horizon T = 106 and \u03b3 = 0.6. We represent the shape of \u00b5 and the successive intervals returned by IT\u20323, starting at the bottom of the y-axis. The thickness of the segments is an increasing function of the length of IT\u20323. In both cases, we observe that the successive intervals contain the optimal arm x?. When the search interval gets narrower (we are closer to the peak), the intervals get thicker since the duration of the test increases when the separation between arms {x1, x2, x3} decreases. Also remark that when the expected reward function is flatter (here \u03be = 2), the algorithm tends to spend more time on each given interval. Additional numerical experiments are presented in Appendix."}, {"heading": "7 Conclusion", "text": "In this paper, we have presented the first order-optimal algorithms for one-dimensional continuous unimodal bandit problems that do not explicitly take into account the structure or the smoothness of the expected reward function. In some sense, the proposed algorithm learns and adapts its sequential decisions to the smoothness of the function. Future work will be devoted to applying the techniques used to\ndevise our algorithms to other structured bandits with continuum set of arms (i.e., Lipschitz or convex bandits). We also would like to extend our analysis to the case where the set of arms lies in a space of higher dimension."}, {"heading": "A Additional numerical experiments", "text": "Figure 5 compares the regret of the various algorithms for a triangular reward function \u00b5(x) = 1 \u2212 (2|1/2 \u2212 x|), and illustrates a typical run of the SP\u2032 algorithm for such a reward function with time horizon T = 106 and \u03b3 = 0.6."}, {"heading": "B Proofs", "text": ""}, {"heading": "B.1 Proof of Theorem 4.1", "text": "Proof of (i) (Minimax risk). Let \u00b5 \u2208 U , and consider the test \u03c7 =ITK . By definition, its risk is:\n\u03b1\u03c7(\u00b5) = 2\u2211 u=1 1{\u00b5 \u2208 Bu}P\u00b5[S\u03c7 = u].\nIf \u00b5 /\u2208 B1 \u222a B2, then \u03b1\u03c7(\u00b5) = 0 so that the risk is indeed smaller than \u03b6. Now we assume that \u00b5 \u2208 Bu and we derive an upper bound of P\u00b5[S\u03c7 = u]. By definition of ITK , the event S\u03c7 = u implies that there exists n \u2264 s such that t\u0304\u03c7(n)iu(\u00b5\u0302(n)) \u2265 f(s, \u03b6). Using the following two facts: (a) \u00b5 \u2208 Bu and (b) t\u03c7k (n) \u2265 t\u0304\u03c7(n), we have\nf(s, \u03b6) \u2264 t\u0304\u03c7(n)is(\u00b5\u0302(n)) = t\u0304\u03c7(n) inf \u03bb\u2208Bu K\u2211 k=1 KL (\u00b5\u0302k(n), \u03bb(xk))\n(a) \u2264 t\u0304\u03c7(n) K\u2211 k=1 KL (\u00b5\u0302k(n), \u00b5(xk)) (b) \u2264 K\u2211 k=1 t\u03c7k (n)KL (\u00b5\u0302k(n), \u00b5(xk)).\nTherefore we have proven that:\n\u03b1\u03c7(\u00b5) \u2264 P\u00b5 [ sup n\u2264s K\u2211 k=1 t\u03c7k (n)KL (\u00b5\u0302k(n), \u00b5(xk)) \u2265 f(s, \u03b6) ]\nApplying Theorem B.4 (presented at the end of the appendix) with \u03b4 := f(s, \u03b6), we obtain:\n\u03b1\u03c7(\u00b5) \u2264 eK+1\u2212f(s,\u03b6)(f(s, \u03b6)df(s, \u03b6) log(s)e/K)K \u2264 \u03b6.\nThe above inequality holds for all \u00b5 \u2208 U , and hence the minimax risk satisfies \u03b1\u03c7 \u2264 \u03b6, which concludes the proof of (i).\nProof of (ii) (Expected length). We now consider 1 \u2264 k \u2264 K and we derive an upper bound of E\u00b5[t\u03c7k (s)]. Fix > 0, and define t0 = (1 + )f(s, \u03b6)/iu(\u00b5(x1), . . . , \u00b5(xK)). Introduce the following two sets of rounds:\nA = {1 \u2264 n \u2264 s : x(n) = xk, t \u03c7 (n) \u2264 t0}, B = {1 \u2264 n \u2264 s : x(n) = xk, t \u03c7 (n) \u2265 t0}.\nWe have t\u03c7k (s) \u2264 |A|+ |B|. Furthermore, in each round n \u2208 A, t \u03c7 k (n) is incremented, therefore |A| \u2264 t0. Now let n \u2208 B. By design of ITK , this implies that: t0 \u2264 t\u0304\u03c7(n) and t\u0304\u03c7(n)iu(\u00b5\u0302(n)) \u2264 f(s, \u03b6). Therefore:\nt0iu(\u00b5\u0302(n)) \u2264 f(s, \u03b6),\nand thus: iu(\u00b5\u0302(n)) \u2264 iu(\u00b5(x1), . . . , \u00b5(xK))/(1 + ). (1)\nNow one can verify that the function (\u03bb1, . . . , \u03bbK) 7\u2192 \u2211K k=1 KL (\u00b5(xk), \u03bbk) attains its infimum on Bu. By continuity of KL in its second argument, there must exist \u03bb? \u2208 Bu such that:\niu(\u00b5(x1), . . . , \u00b5(xK)) = K\u2211 k=1 KL (\u00b5(xk), \u03bb?(xk)).\nLet \u03b7 > 0 such that we have |\u00b5\u0302k(n)\u2212 \u00b5(xk)| \u2264 \u03b7 for all k. Since \u03bb? \u2208 Bu, this implies that:\niu(\u00b5\u0302(n)) = inf \u03bb\u2208Bu K\u2211 k=1 KL (\u00b5\u0302k(n), \u03bb(xk)) \u2264 K\u2211 k=1 KL (\u00b5\u0302k(n), \u03bb?(xk)). (2)\nSince |\u00b5\u0302k(n)\u2212 \u00b5(xk)| \u2264 \u03b7 for all k, the r.h.s. of (2) tends to iu(\u00b5(x1), . . . , \u00b5(xK)) < iu(\u00b5(x1), . . . , \u00b5(xK))/(1 + ) as \u03b7 \u2192 0. Hence the inequality (1) cannot hold for arbitrary small \u03b7.\nHence, there exists \u03b70 such that n \u2208 B implies maxk |\u00b5\u0302k(n) \u2212 \u00b5(xk)| \u2265 \u03b70. Note that \u03b70 might depend on and \u00b5(x1), . . . , \u00b5(xK). Using Lemma B.5, we get E[|B|] = o(log(s)).\nTherefore we have:\nE[t\u03c7k (s)] \u2264 (1 + )f(s, \u03b6)\niu(\u00b5(x1), . . . , \u00b5(xK)) + o(log(s)).\nAs noted in remark 1, when considering \u03b6 = s\u2212\u03b3 , we may use f(s, \u03b6) = \u03b3 log(s) + o(log(s)), hence:\nlim sup s\u2192\u221e E[t\u03c7k (s)] log(s) \u2264 (1 + )\u03b3 iu(\u00b5(x1), . . . , \u00b5(xK)) .\nSince the above inequality holds for all > 0, we obtain the announced result:\nlim sup s\u2192\u221e E[t\u03c7k (s)] log(s) \u2264 \u03b3 iu(\u00b5(x1), . . . , \u00b5(xK)) .\nwhich concludes the proof of (ii)."}, {"heading": "B.2 Proof of Theorem 4.2", "text": "We start by proving Lemma B.1 which shows that iu can be lower bounded by the KL? function.\nLemma B.1 Consider Bernoulli rewards. Define m = 1 if u = 1 and m = 3 otherwise. Then we have for all u \u2208 {1, 2}:\niu(\u00b5(x1), \u00b5(x2), \u00b5(x3)) \u2265 KL ?(\u00b5(xm), \u00b5(x2)).\nProof. We only prove the statement for u = 1, as the case u = 2 follows by symmetry. By a slight abuse of notation we denote \u00b5(xk) and \u03bb(xk) by \u00b5k and \u03bbk respectively.\nFirst note that if \u00b52 < \u00b51, we have KL?(\u00b51, \u00b52) = 0 and the statement holds because iu(\u00b5(x1), \u00b5(x2), \u00b5(x3)) \u2265 0, since the KL divergence is positive.\nNow consider the case \u00b52 \u2265 \u00b51. We have the inequality:\ni1(\u00b51, \u00b52, \u00b53) = inf \u03bb\u2208B1 3\u2211 k=1 KL (\u00b5k, \u03bbk) \u2265 inf \u03bb\u2208B1 2\u2211 k=1 KL (\u00b5k, \u03bbk).\nDefine function \u03c6 : [0, 1]2 \u2192 R by \u03c6(\u03bb1, \u03bb2) = \u22112 k=1 KL (\u00b5k, \u03bbk). Define the set \u039b = {(\u03bb1, \u03bb2) : \u03bb1 \u2265 \u03bb2}. Consider \u03bb \u2208 B1, then x 7\u2192 \u03bb(x) attains its maximum in [x, x1], and since \u03bb is unimodal we must have \u03bb1 \u2265 \u03bb2. Therefore:\ni1(\u00b51, \u00b52, \u00b53) \u2265 min (\u03bb1,\u03bb2)\u2208\u039b \u03c6(\u03bb1, \u03bb2). (3)\nConsider (\u03bb?1, \u03bb ? 2) \u2208 arg min(\u03bb1,\u03bb2)\u2208\u039b \u03c6(\u03bb1, \u03bb2). We are going to prove that we must have \u03bb?1 = \u03bb?2. Consider two subcases (a) 0 \u2264 \u03bb?2 \u2264 \u00b51 and (b) \u00b51 \u2264 \u03bb?2 \u2264 1. In case (a) we must have \u03bb?1 = \u00b51 since \u03bb1 7\u2192 KL (\u00b51, \u03bb1) attains its minimum at \u00b51. In turn we must have \u03bb?2 = \u00b51 = \u03bb?1 since \u03bb1 7\u2192 KL (\u00b51, \u03bb1) is decreasing for \u03bb1 \u2264 \u00b51 \u2264 \u00b52. In case (b), we must have \u03bb?1 = \u03bb?2 because \u03bb1 7\u2192 KL (\u00b51, \u03bb1) is increasing for \u03bb1 \u2265 \u03bb?2 \u2265 \u00b51. In both cases we have proven that \u03bb?1 = \u03bb?2.\nDefine function \u03c6\u0303(\u03bb) = \u03c6(\u03bb, \u03bb), from the reasoning above we have that:\nmin (\u03bb1,\u03bb2)\u2208\u039b \u03c6(\u03bb1, \u03bb2) = min \u03bb\u2208[0,1] \u03c6\u0303(\u03bb).\n\u2022 If \u00b51 = \u00b52 = 0, then \u03c6(0, 0) = 0 so that the optimum is \u03bb? = 0.\n\u2022 If \u00b51 = \u00b52 = 1, then \u03c6(1, 1) = 0, so that the optimum is \u03bb? = 1.\n\u2022 Otherwise, denote by \u03c6\u0303\u2032 the first derivative of \u03c6\u0303. We have:\n\u03c6\u0303\u2032(\u03bb) = 2\u2212 (\u00b51 + \u00b52) 1\u2212 \u03bb \u2212 \u00b51 + \u00b52 \u03bb .\nand \u03c6\u0303\u2032(0+) = \u2212\u221e and \u03c6\u0303\u2032(1\u2212) = +\u221e so that \u03c6\u0303 attains its maximum in the interior of [0, 1]. Solving for \u03c6\u0303\u2032(\u03bb?) = 0 we obtain the unique solution \u03bb? = (\u00b51 + \u00b52)/2.\nWe observe that in the three above cases, the optimum is \u03bb? = (\u00b51 + \u00b52)/2. We have proven the announced inequality:\ni1(\u00b5(x1), . . . , \u00b5(xK)) \u2265 min (\u03bb1,\u03bb2)\u2208\u039b \u03c6(\u03bb1, \u03bb2) = min \u03bb\u2208[0,1] \u03c6\u0303(\u03bb) = \u03c6\u0303((\u00b51 + \u00b52)/2) = KL?(\u00b51, \u00b52).\nProof of Theorem 4.2. (i) Minimax risk of IT3. The minimax risk of IT3 is upper bounded by \u03b6 by Theorem 4.1.\n(i)\u2019 Minimax risk of \u03c7 =IT\u20323. Let \u00b5 \u2208 Bu, let us upper bound P\u00b5[S\u03c7 = u]. Without loss of generality consider u = 1 and a time instant n \u2264 s such that S\u03c7(n) = 1. By definition of IT\u20193 this implies that t\u0304\u03c7(n)KL?(\u00b5\u03021(n), \u00b5\u03022(n)) \u2265 f(s, \u03b6). We deduce that:\nf(s, \u03b6) \u2264 t\u0304\u03c7(n)KL?(\u00b5\u03021(n), \u00b5\u03022(n)) (a)\n\u2264 t\u0304\u03c7(n)i1(\u00b5\u03021(n), . . . , \u00b5\u0302K(n))\n= t\u0304\u03c7(n) inf \u03bb\u2208B1 K\u2211 k=1 KL (\u00b5\u0302k(n), \u03bb(xk))\n(b) \u2264 t\u0304\u03c7(n) K\u2211 k=1 KL (\u00b5\u0302k(n), \u00b5(xk))\n(c) \u2264 K\u2211 k=1 t\u03c7k (n)KL (\u00b5\u0302k(n), \u00b5(xk)).\nwhere we have used (a) Lemma B.1, (b) the fact that \u00b5 \u2208 B1 (c) the fact that t\u0304\u03c7(n) \u2264 t\u03c7k (n) for all k. Applying theorem B.4 once again:\n\u03b1\u03c7(\u00b5) \u2264 P [ sup n\u2264s K\u2211 k=1 t\u03c7k (n)KL (\u00b5\u0302k(n), \u00b5(xk)) \u2265 f(s, \u03b6) ] \u2264 \u03b6\nwhich proves that \u03b1\u03c7(\u00b5) \u2264 \u03b6 for all \u00b5 \u2208 U and concludes the proof of (i)\u2019. (ii) Expected duration of \u03c7 =IT3. The proof of (ii) for IT\u20323 follows by the same arguments. By a slight abuse of notation we denote \u00b5(xk) by \u00b5k. Without loss of generality, consider \u00b5 such that x? \u2208 [x2, x]. Therefore we have that \u00b52 > \u00b51 since \u00b5 is unimodal. Fix 0 < < \u03b4/2, and define t0 = f(s, \u03b6)/KL?, (\u00b51, \u00b52). Introduce the two sets of instants:\nA = {1 \u2264 n \u2264 s : x(n) = xk, t\u0304\u03c7(n) \u2264 t0} , B = {n \u2265 1 : x(n) = xk, max k\u2032\u2208{1,2} |\u00b5\u0302k\u2032(n)\u2212 \u00b5k\u2032 | \u2265 }.\nWe prove that x(n) = xk implies that n \u2208 A\u222aB. Consider n such that t\u0304\u03c7(n) \u2265 t0 and |\u00b5\u0302k\u2032(n)\u2212\u00b5k\u2032 | \u2264 , k\u2032 \u2208 {1, 2}. Since < \u03b4/2 \u2264 (\u00b52 \u2212 \u00b51)/4 we have:\n\u00b5\u03021(n) \u2264 \u00b51 + \u2264 (\u00b51 + \u00b52)/2\u2212 \u2264 (\u00b5\u03021(n) + \u00b5\u03022(n))/2 \u00b5\u03022(n) \u2265 \u00b52 \u2212 \u2265 (\u00b51 + \u00b52)/2 + \u2265 (\u00b5\u03021(n) + \u00b5\u03022(n))/2\nso that KL ?(\u00b5\u03021(n), \u00b5\u03022(n)) \u2265 KL ?, (\u00b51, \u00b52). Applying Lemma B.1, we have:\nt\u0304(n)i1(\u00b5\u0302(n)) \u2265 t\u0304\u03c7(n)KL ?(\u00b5\u03021(n), \u00b5\u03022(n)) \u2265 t0KL ?, (\u00b51, \u00b52) = f(s).\nTherefore we cannot have x(n) = xk. We have proven that t\u03c7k (s) \u2264 |A| + |B|. Furthermore, at each instant n \u2208 A, t\u0304\u03c7(n) is incremented, therefore |A| \u2264 t0. Let us upper bound the expected size of B. Decompose B = B1 \u222aB2, with:\nBk \u2032 = {n \u2265 1 : x(n) = xk, |\u00b5\u0302k\u2032(n)\u2212 \u00b5k\u2032 | \u2265 }.\nLet n \u2208 Bk\u2032 and define a = \u2211 n\u2032\u2264n 1{n\u2032 \u2208 Bk\n\u2032} so that n is the a-th instant of Bk\u2032 . Then we have that t\u03c7k\u2032(n) \u2265 a and applying [8][Lemma 2.2] we have that for k\u2032 \u2208 {1, 2}, E[|Bk\n\u2032 |] \u2264 \u22122. Therefore E[|B|] \u2264 2 \u22122. So statement (ii) is proven:\nE\u00b5[t\u03c7k (s)] \u2264 t0 + 2 \u22122 =\nf(s)\nKL?, (\u00b5(x1), \u00b5(x2)) + 2 \u22122.\n(iii) Further bounds on the duration of \u03c7 =IT3. The proof of (iii) for IT\u20323 follows by the same arguments. To establish the announced inequalities, we will use the following fact: from Pinsker\u2019s inequality KL (\u03b1, \u03b2) \u2265 2(\u03b1\u2212 \u03b2)2 for all (\u03b1, \u03b2) \u2208 [0, 1]2, so that:\nKL ?, (\u00b51, \u00b52) \u2265 4((\u00b52 \u2212 \u00b51)/2\u2212 2 )2 \u2265 4(\u03b4 \u2212 2 )2,\nIn particular for = \u03b4/4 we have KL ?, (\u00b51, \u00b52) \u2265 \u03b42. Inequality (a). Define t0 = 8f(s)\u03b4\u22122 and n0 = 3t0. By design of IT3, for all k we have t \u03c7 k (n0) = t0. Set\n= \u03b4/4. If both \u00b5\u03021(n0) \u2264 \u00b51 + and \u00b5\u03022(n0) \u2265 \u00b52 \u2212 then we have:\nt\u0304\u03c7(n0)KL ?(\u00b5\u03021(n0), \u00b5\u03022(n0)) \u2265 t0KL ?, (\u00b51, \u00b52) \u2265 8f(s)\u03b4\u22122\u03b42 = 8f(s) > f(s).\nso that IT3 must terminate at time n0 or before. Hence, applying Hoeffding\u2019s inequality:\nP\u00b5[t\u03c7k (s) \u2265 t0] \u2264 P[\u00b5\u0302k(n0) \u2265 \u00b51 + ] + P[\u00b5\u03022(n0) \u2264 \u00b52 \u2212 ] \u2264 2e \u22122t0 2 = 2e\u2212f(s).\nwhich is the announced result. Inequality (b). Once again setting = \u03b4/4, and using both KL ?, (\u00b52, \u00b51) \u2265 \u03b42 and statement (ii), we obtain the second claim:\nE\u00b5[t\u03c7k (s)] \u2264 f(s) + 32\n\u03b42\nInequality (c). By statement (ii), and using the fact that f(s) = \u03b3 log(s) + o(log(s)), for all > 0, we have:\nlim sup s\u2192\u221e E\u00b5[t\u03c7k (s)] log(s) \u2264 \u03b3 KL?, (\u00b5(x1), \u00b5(x2)) ,\nso that letting \u2192 0 in the above expression yields:\nlim sup s\u2192\u221e E\u00b5[t\u03c7k (s)] log(s) \u2264 \u03b3 KL?(\u00b5(x1), \u00b5(x2)) ,\nwhich concludes the proof of statement (iii)."}, {"heading": "B.3 Proof of Theorem 4.3", "text": "Fix N throughout the proof. We introduce the following notations. The algorithm proceeds in phases, each phase corresponding to a call of IT3 (or IT\u20323) subroutine. We define I\nN \u2032 the interval output after the N \u2032-th call of IT3, with I0 = [0, 1]. We define \u03c4N \u2032 the duration of the N \u2032-th call of IT3. Define the event:\nA = \u2229NN \u2032=0{x? \u2208 IN \u2032 },\nwhich corresponds to sample paths where the first N -th calls of IT3 have returned an interval containing the optimal arm x?. We denote by Ac the complement of A.\nThe regret due to sample paths in Ac is upper bounded by \u00b5?TP[Ac]. The regret due to the N \u2032-th phase for sample paths inA is upper bounded by E[\u03c4N \u20321{A}(\u00b5?\u2212minx\u2208IN\u2032 \u00b5(x))]. This is true because the N \u2032-th phase has duration \u03c4N \u2032 , and during that phase only arms in IN \u2032 are sampled so that the regret of a sample in IN \u2032\nis upper bounded by \u00b5? \u2212minx\u2208IN\u2032 \u00b5(x). Therefore the regret admits the following upper bound:\nR\u03c0(T ) \u2264 \u00b5?TP[Ac] + \u2211 N \u2032\u22650 E[\u03c4N \u2032 1{A}(\u00b5? \u2212 min x\u2208IN\u2032 \u00b5(x))].\nConsider a sample path in A, and N \u2032 \u2264 N , then we have |IN \u2032 | \u2264 \u03c8N \u2032 and x? \u2208 IN \u2032 . Therefore \u00b5?\u2212minx\u2208IN\u2032 \u00b5(x) \u2264 g\u00b5(\u03c8N \u2032 ) by definition of g\u00b5. Similarly, consider a sample path inA, andN \u2032 > N . Then we have IN \u2032 \u2282 IN , |IN | \u2264 \u03c8N and x? \u2208 IN . Therefore:\n\u00b5? \u2212 min x\u2208IN\u2032 \u00b5(x) \u2264 \u00b5? \u2212 min x\u2208IN \u00b5(x) \u2264 g\u00b5(\u03c8N ),\nand the regret satisfies:\nR\u03c0(T ) \u2264 \u00b5?TP[Ac] + N\u2211\nN \u2032=0\ng\u00b5(\u03c8 N \u2032)E[\u03c4N \u2032 1{A}] + g\u00b5(\u03c8N ) \u2211 N \u2032>N E[\u03c4N \u2032 1{A}]\n\u2264 \u00b5?TP[Ac] + N\u2211\nN \u2032=0\ng\u00b5(\u03c8 N \u2032)E[\u03c4N \u2032 1{A}] + g\u00b5(\u03c8N )E[ \u2211 N \u2032>N \u03c4N \u2032 ],\n\u2264 \u00b5?TP[Ac] + N\u2211\nN \u2032=0\ng\u00b5(\u03c8 N \u2032)E[\u03c4N \u2032 1{A}] + Tg\u00b5(\u03c8N ),\nwhere we have used the fact that \u2211 N \u2032>N \u03c4 N \u2032 \u2264 \u2211 N \u2032\u22650 \u03c4\nN \u2032 = T . We now upper bound the probability of event Ac. Since x? \u2208 I0 = [0, 1], the occurrence of Ac\nimplies that there exists N \u2032 < N such that x? \u2208 IN \u2032 and x? 6\u2208 IN \u2032+1 so that we have the inclusion:\nAc \u2282 \u222aN\u22121N \u2032=0{x ? \u2208 IN \u2032 , x? /\u2208 IN \u2032+1}.\nSince the event {x? \u2208 IN \u2032 , x? /\u2208 IN \u2032+1} corresponds to an incorrect decision taken under IT3, we have P[x? \u2208 IN \u2032 , x? /\u2208 IN \u2032+1] \u2264 T\u2212\u03b3 , because of Theorem 4.2. Using a union bound we obtain the upper bound:\nP[Ac] \u2264 N\u22121\u2211 N \u2032=0 P[x? \u2208 IN \u2032 , x? /\u2208 IN \u2032+1] \u2264 NT\u2212\u03b3 .\nThe regret upper bound becomes:\nR\u03c0(T ) \u2264 \u00b5?NT 1\u2212\u03b3 + Tg\u00b5(\u03c8N ) + N\u2211\nN \u2032=0\ng\u00b5(\u03c8 N \u2032)E[\u03c4N \u2032 1{A}].\nFinally, from Theorem 4.2, we have that E[\u03c4N \u20321{A}] \u2264 3(f(T ) + 32)(\u03b4(IN \u2032))\u22122 (we sample from 3 arms) where \u03b4(IN \u2032 ) is the quantity \u03b4 defined in the statement of Theorem 3, when the interval considered by IT3 is IN \u2032 . Since we are considering a sample path in A, and N \u2032 \u2264 N we have once again that |IN \u2032 | \u2264 \u03c8N \u2032 and x? \u2208 IN \u2032 so that \u03b4(IN \u2032) \u2265 h\u00b5(\u03c8N \u2032 ) by definition of h\u00b5. Therefore: E[\u03c4N \u2032 1{A}] \u2264 3(f(T ) + 32)(h\u00b5(\u03c8 N \u2032))\u22122. We obtain finally:\nR\u03c0(T ) \u2264 \u00b5?NT 1\u2212\u03b3 + Tg\u00b5(\u03c8N ) + 3(f(T ) + 32) N\u2211\nN \u2032=0\ng\u00b5(\u03c8 N \u2032)(h\u00b5(\u03c8 N \u2032))\u22122,\nwhich is the announced result and concludes the proof."}, {"heading": "B.4 Proof of Theorem 4.5", "text": "To prove Theorem 4.5, we use the following intermediate result.\nProposition 1 For all \u00b5 \u2208 U(C1, C2): (a) g\u00b5(\u2206) \u2264 C2\u2206\u03be; (b) h\u00b5(\u2206) \u2265 C1a\u03be\u2206\u03be, with a\u03be = 4\u2212\u03be min(1, 2\u03be \u2212 1)\nProof. (a) By definition of g\u00b5 and since \u00b5 \u2208 U(C1, C2), we have:\ng\u00b5(\u2206) = \u00b5 ? \u2212min(\u00b5(x? \u2212\u2206), \u00b5(x? + \u2206)) \u2264 C2\u2206\u03be.\n(b) Consider x such that x? \u2264 x \u2264 x? + \u2206/4. Since since \u00b5 \u2208 U(C1, C2), we have:\n\u00b5(x)\u2212 \u00b5(x+ \u2206/4) \u2265 C1((x+ \u2206/4\u2212 x?)\u03be \u2212 (x\u2212 x?)\u03be).\nFix \u2206, and define the function l(x) = (x+ \u2206/4\u2212 x?)\u03be \u2212 (x\u2212 x?)\u03be. Its first derivative is:\nl\u2032(x) = \u03be((x+ \u2206/4\u2212 x?)\u03be\u22121 \u2212 (x\u2212 x?)\u03be\u22121).\nTherefore the function x 7\u2192 l(x) on interval [x?, x?+ \u2206/4] is increasing if \u03be \u2265 1 and decreasing if \u03be < 1 so we get the lower bound:\nmin x\u2208[x?,x?+\u2206/4]\n\u00b5(x)\u2212 \u00b5(x+ \u2206/4) \u2265\n{ C1l(x ?) = C1(\u2206/4) \u03be if \u03be \u2265 1\nC1l(x ? + \u2206/4) = C1(2 \u03be \u2212 1)(\u2206/4)\u03be if \u03be < 1\nso that h\u00b5(\u2206) \u2265 C1 min(1, 2\u03be \u2212 1)(\u2206/4)\u03be as announced. Let us now prove Theorem 4.5. From Theorem 4.3, we can decompose the regret upper bound into three terms:\nR\u03c0(T ) \u2264 r1(T ) + r2(T ) + r3(T ) r1(T ) = \u00b5 ?NT 1\u2212\u03b3\nr2(T ) = Tg\u00b5(\u03c8 N )\nr3(T ) = 3(\u03b3 log(T ) + 32) N\u2211 N \u2032=0 g\u00b5(\u03c8 N \u2032)(h\u00b5(\u03c8 N \u2032))\u22122.\nWe proceed to upper bound each term. The first term r1(T ) is explicit. By Proposition 1, the second term is upper bounded as: r2(T ) \u2264 TC2\u03c8\u03beN . As for the third term r3(T ), by Proposition 1, we have that g\u00b5(\u03c8 N \u2032) \u2264 C2\u03c8\u03beN \u2032 and h\u00b5(\u03c8N \u2032 ) \u2265 C1a\u03be\u03c8\u03beN \u2032 , so that:\nN\u2211 N \u2032=0 g\u00b5(\u03c8 N \u2032)(h\u00b5(\u03c8 N \u2032))\u22122 \u2264 N\u2211 N \u2032=0 C2(C1a\u03be) \u22122\u03c8\u2212\u03beN \u2032 \u2264 C2\u03c8 \u2212\u03be(N+1) C21a 2 \u03be(\u03c8 \u2212\u03be \u2212 1) .\nFinally, we get:\nR\u03c0(T ) \u2264 \u00b5?NT 1\u2212\u03b3 + TC2\u03c8\u03beN + 3(f(T ) + 32)C2\u03c8\n\u2212\u03be(N+1)\nC21a 2 \u03be(\u03c8 \u2212\u03be \u2212 1)\nDefine M \u2265 0 (not necessarily an integer) such that the last two terms in the r.h.s. of the above inequality are equal:\nC2T\u03c8 \u03beM =\n3(f(T ) + 32)C2\u03c8 \u2212\u03be(M+1)\nC21a 2 \u03be(\u03c8 \u2212\u03be \u2212 1)\n.\nWe have that:\n\u03c8\u22122\u03beM = TC21a 2 \u03be(\u03c8 \u2212\u03be \u2212 1)\n3(f(T ) + 32)\u03c8\u2212\u03be \u2264 TC21\nsince a\u03be \u2264 1, \u03c8\u2212\u03be \u2212 1 \u2264 \u03c8\u2212\u03be and f(T ) \u2265 1. Taking logarithms we deduce that:\nM \u2264 log(TC1) \u03be log(1/\u03c8) .\nNow set N \u2261 dMe for the remainder of the proof. We obtain the announced upper bound:\nR\u03c0(T ) \u2264 \u00b5?(M + 1)T 1\u2212\u03b3 + TC2\u03c8\u03beM + \u03c8\u2212\u03be 3(f(T ) + 32)C2\u03c8\n\u2212\u03be(M+1)\nC21a 2 \u03be(\u03c8 \u2212\u03be \u2212 1) \u2264 \u00b5?T 1\u2212\u03b3 ( log(TC1)\n\u03be log(1/\u03c8) + 1\n) + (1 + \u03c8\u2212\u03be)TC2\u03c8 \u03beM\n\u2264 \u00b5?T 1\u2212\u03b3 log(TC1\u03c8 \u2212\u03be)\n\u03be log(1/\u03c8) + 2\u03c8\u22123\u03be/2C2 C1a\u03be\n\u221a 3T (f(T ) + 32)\n\u03c8\u2212\u03be \u2212 1 .\nThis concludes the proof."}, {"heading": "B.5 Proof of Theorem 4.6", "text": "The proof proceeds along the same lines as the proof of Theorem 4.5. Define M \u2265 0 such that:\n24f(T )\u03c8\u22122\u03be(M+1)\na2\u03beC 2 1 (\u03c8\n\u22122\u03be \u2212 1) = T.\nLet us first upper bound M . We have that:\n\u03c8\u22122\u03be(M+1) = C21a 2 \u03beT (\u03c8 \u22122\u03be \u2212 1) 24f(T ) \u2264 C21T\u03c8\u22122\u03be.\nusing the fact that a\u03be \u2264 1, f(T ) \u2265 1 and \u03c8\u22122\u03be \u2212 1 \u2264 \u03c8\u22122\u03be. Hence, taking logarithms:\nM \u2264M + 1 \u2264 log(TC1\u03c8 \u2212\u03be)\n\u03be log(1/\u03c8) .\nWe now fix N = bMc for the remainder of the proof. Once again the algorithm proceeds in phases, each phase corresponding to a call to IT3 (or IT\u20323). We define I\nN \u2032 the interval output by the N \u2032-th call of IT3, with I0 = [0, 1]. We define \u03c4N \u2032 the duration of the N \u2032-th call of IT3. We define two events:\nA = \u2229NN \u2032=0{x? \u2208 IN \u2032 }, B = \u2229NN \u2032=0{\u03c4N \u2032 \u2264 24f(T )h\u00b5(\u03c8N \u2032 )\u22122}\nA corresponds to sample paths where the first N -th calls of IT3 have returned an interval containing the optimal arm x?. B corresponds to sample paths where the firstN -th calls to IT3 have not lasted more than their \u201ctypical length\u201d (as prescribed by Theorem 4.2). The optimization error can hence be decomposed according to the occurrence of A and B:\nE\u03c0(T ) = E[(\u00b5? \u2212 \u00b5(x(T ))1{A \u2229B}] + E[(\u00b5? \u2212 \u00b5(x(T ))1{(A \u2229B)c}] \u2264 E[(\u00b5? \u2212 \u00b5(x(T ))1{A \u2229B}] + \u00b5?E[1{(A \u2229B)c}] \u2264 E[(\u00b5? \u2212 \u00b5(x(T ))1{A \u2229B}] + \u00b5?(P[Ac] + P[Bc \u2229A]).\nWe will establish two facts:\n(a) P[Ac] + P[Bc \u2229A] \u2264 3MT\u2212\u03b3\n(b) (\u00b5? \u2212 \u00b5(x(T ))1{A \u2229B} \u2264 C2\u03c8\u03be(M+1) a.s.\nIf (a) and (b) hold we have that:\nE\u03c0(T ) \u2264 C2\u03c8\u03be(M+1) + 3\u00b5?MT\u2212\u03b3 \u2264 C2 C1a\u03be\n\u221a 24f(T )\nT (\u03c8\u22122\u03be \u2212 1) +\n3T\u2212\u03b3\u00b5? log(TC1\u03c8 \u2212\u03be)\n\u03be log(1/\u03c8) .\nwhich is precisely the announced result. Fact (a) From Theorem 4.2, statement (i), we know that P[Ac] \u2264 NT\u2212\u03b3 since the risk of IT3 is upper bounded by T\u2212\u03b3 . Furthermore, from Theorem 4.2, statement (iii a), we know that P[Bc \u2229 A] \u2264 2NT\u2212\u03b3 since test IT3 applied to an interval of size \u03c8N \u2032 that contains the optimal arm has length greater than 24f(T )h\u00b5(\u03c8N \u2032 )\u22122 with probability less than 2e\u2212f(T ) \u2264 2T\u2212\u03b3 . Hence P[Ac] + P[Bc \u2229 A] \u2264 3NT\u2212\u03b3 \u2264 3MT\u2212\u03b3 as announced. Fact (b) Let us prove that if B occurs, then the first N -th calls to IT3 terminate before the time horizon T . Indeed, if B occurs, applying Proposition 1, one has:\nN\u2211 N \u2032=0 \u03c4N \u2032 \u2264 24f(T ) N\u2211 N \u2032=0 h\u00b5(\u03c8 N \u2032)\u22122 \u2264 24f(T ) a2\u03beC 2 1 N\u2211 N \u2032=0 \u03c8\u22122\u03beN \u2032\n\u2264 24f(T )\u03c8 \u22122\u03be(N+1)\na2\u03beC 2 1 (\u03c8\n\u22122\u03be \u2212 1) \u2264 24f(T )\u03c8\n\u22122\u03be(M+1)\na2\u03beC 2 1 (\u03c8\n\u22122\u03be \u2212 1) = T\nso that the first N tests do terminate before T . Furthermore, if A occurs, the N -th test returns an arm x such that |x\u2212 x?| \u2264 \u03c8M+1. In turn, by proposition 1, one has |\u00b5? \u2212 \u00b5(x)| \u2264 g\u00b5(\u03c8M+1) \u2264 C2\u03c8\u03be(M+1). Hence we have proven that, if both A and B occur one has (\u00b5? \u2212 \u00b5(x(T )) \u2264 C2\u03c8\u03be(M+1), so that (\u00b5? \u2212 \u00b5(x(T ))1{A \u2229B} \u2264 C2\u03c8\u03be(M+1) a.s. as announced. This concludes the proof."}, {"heading": "B.6 Proof of Theorem 5.1", "text": "We work with a given sequential test \u03c7 throughout the proof and we omit the superscript \u03c7 for clarity. Without loss of generality, let u = 1. We work with a fixed parameter \u03bb \u2208 B1. We denote by Y (s) = (X1(x(1)), . . . , Xs(x(s))) the observed rewards from round 1 to round s. We denote by Ps and Qs the probability distribution of Y (s) under \u00b5 and \u03bb respectively. From Lemma B.3 (stated and proved at the end of the appendix), we have:\nKL (Ps||Qs) = K\u2211 k=1 E[tk(s)]KL (\u00b5(xk), \u03bb(xk)). (4)\nConsider the event S = 1. Since the sequential test \u03c7 has minimax risk smaller than \u03b1, and \u03bb \u2208 B1, we have P\u03bb[S = 1] \u2264 \u03b1. Recall that by assumption P\u00b5[S = 1] = \u03b2 and \u03b1 \u2264 \u03b2. Now S is a function of Y (s). Using Lemma B.2 (stated at the end of the appendix):\nKL (Ps||Qs) \u2265 KL2(P\u00b5[S(s) = 1],P\u03bb[S(s) = 1]) \u2265 KL2(\u03b2, \u03b1). (5)\nwhere we have used the fact that \u03b1 7\u2192 KL2(\u03b2, \u03b1) is decreasing for \u03b1 \u2264 \u03b2. Putting (4) and (5) together, we obtain:\nK\u2211 k=1 E[tk(s)]KL (\u00b5(xk), \u03bb(xk)) \u2265 KL2(\u03b2, \u03b1).\nTaking the infimum over \u03bb \u2208 B1, we obtain the claimed result:\ninf \u03bb\u2208B1 K\u2211 k=1 E[tk(s)]KL (\u00b5(xk), \u03bb(xk)) \u2265 KL2(\u03b2, \u03b1)."}, {"heading": "B.7 Proof of Corollary 5.2", "text": "Let us denote \u03b2s = P\u00b5[Ss = 1], where Ss is the final decision taken under test \u03c7s. Since \u03b2s \u2192s\u2192\u221e \u03b2 > 0 there exists s0 such that for all s \u2265 s0 we have \u03b2s \u2265 s\u2212\u03b3 . Since \u03c7s has minimax risk \u03b1 = s\u2212\u03b3 , for all s \u2265 s0, applying Theorem 5.1, we obtain:\ninf \u03bb\u2208B1 K\u2211 k=1 E[tk(s)]KL (\u00b5(xk), \u03bb(xk)) \u2265 KL2(\u03b2s, \u03b1) = KL2(\u03b2s, s\u2212\u03b3). (6)\nNow by definition of KL2, we have that:\nKL2(\u03b2s, s\u2212\u03b3) = \u03b2s log(\u03b2s) + \u03b2s\u03b3 log(s) + (1\u2212 \u03b2s) log(1\u2212 \u03b2s) + (1\u2212 \u03b2s) log(1\u2212 s\u2212\u03b3).\nSince \u03b2s \u2192s\u2192\u221e \u03b2 > 0, we have that KL2(\u03b2s, s\u2212\u03b3) \u223cs\u2192\u221e \u03b3\u03b2 log(s). Letting s\u2192\u221e in (6) we have:\nlim inf s\u2192\u221e inf \u03bb\u2208B1 K\u2211 k=1 E\u00b5[tk(s)] log(s) KL (\u00b5(xk), \u03bb(xk)) \u2265 \u03b3\u03b2,\nwhich concludes the proof."}, {"heading": "B.8 Proof of Corollary 5.3", "text": "The proof is constructive: we exhibit a function \u00b5 such that P\u00b5[S\u03c7 6= 0] \u2265 1/2. Without loss of generality we consider interval I = [0, 1]. Consider the function \u00b5(x) = 1\u22122|1/2\u2212x|. \u00b5 is clearly unimodal, with x? = 1/2 and \u00b5? = 1.\nWe proceed by contradiction. Consider a test \u03c7 such that P\u00b5[S\u03c7 6= 0] \u2265 1/2. Since S\u03c7 \u2208 {0, 1, 2}, there exists u \u2208 {1, 2} such that P\u00b5[S\u03c7 = u] \u2265 1/4. Without loss of generality consider u = 1. Let > 0, and define the function \u03bb which is linear on intervals {[x1, x2], [x2, x3], [x2, (x3 + x4)/2], [(x3 + x4)/2, x4] with \u03bb(xk) = \u00b5(xk), k 6= 3 and \u03bb(x3) = \u00b5(x2) + , and \u03bb((x3 + x4)/2) = 1. One can check that \u03bb is unimodal, and attains its maximum in [x3, x4]. We recall that \u03b1 < 1/4 and applying Theorem 5.1, we obtain the following inequality:\nK\u2211 k=1 E\u00b5[tk(s)]KL (\u00b5(xk), \u03bb(xk)) \u2265 KL2(1/4, \u03b1).\nSince KL (\u00b5(xk), \u03bb(xk)) = KL (\u00b5(xk), \u00b5(xk)) = 0, for k 6= 3, and t3(s) \u2264 s we obtain:\nsKL (\u00b5(x3), \u00b5(x3) + ) \u2265 KL2(1/4, \u03b1). (7)\nSince \u03b1 < 1/4 we have that KL2(1/4, \u03b1) > 0. On the other hand 7\u2192 KL (\u00b5(x3), \u00b5(x3) + ) is continuous, and KL (\u00b5(x3), \u00b5(x3)) = 0. Therefore inequality (7) cannot hold for all > 0. This is a contradiction and proves that a test \u03c7 as considered here cannot exist, which concludes the proof."}, {"heading": "B.9 Technical results", "text": "Lemma B.2 gives a lower bound of the KL divergence of probability measures using the KL divergence between two Bernoulli distributions.\nLemma B.2 Let P and Q be two probability measures on a probability space (\u2126,F ,P). Assume that P and Q are both absolutely continuous with respect to measure m(dx). Then:\nKL (P ||Q) \u2265 sup A\u2208F KL2(P (A), Q(A)).\nProof. The proof is based on the log-sum inequality. We recall the derivation of the log-sum inequality here. Consider f(x) = x log(x). We have that f \u2032\u2032(x) = 1/x, so that f is convex. We define p, q the densities of P,Q with respect to measure m. Then for all A \u2208 F :\u222b\nA\nlog\n( p(x)\nq(x)\n) p(x)m(dx) = \u222b A f ( p(x) q(x) ) q(x)m(dx)\n= Q(A) \u222b A f ( p(x) q(x) ) q(x) Q(A) m(dx)\n(a) \u2265 Q(A)f (\u222b\nA\np(x)\nq(x)\nq(x)\nQ(A) m(dx) ) = Q(A)f ( P (A)\nQ(A)\n) = P (A) log ( P (A)\nQ(A)\n) .\nand (a) holds because of Jensen\u2019s inequality. Applying the reasoning above to A and Ac = \u2126 \\A:\nKL (P ||Q) = \u222b\n\u2126\nlog\n( p(x)\nq(x)\n) p(x)m(dx)\n= \u222b A log ( p(x) q(x) ) p(x)m(dx) + \u222b Ac log ( p(x) q(x) ) p(x)m(dx)\n\u2265 P (A) log ( P (A)\nQ(A)\n) + P (Ac) log ( P (Ac)\nQ(Ac) ) = P (A) log ( P (A)\nQ(A)\n) + (1\u2212 P (A)) log ( 1\u2212 P (A) 1\u2212Q(A) ) = KL2(P (A), Q(A)).\nSo for all A we have: KL (P ||Q) \u2265 KL2(P (A), Q(A)),\nand taking the supremum over A \u2208 F concludes the proof. Lemma B.3 evaluates the KL divergence between sample paths of a given test under two different parameters. The proof follows from a straightforward conditioning argument and is omitted here.\nLemma B.3 We denote by Y (s) = (X1(x(1)), . . . , Xs(x(s))) the observed rewards from time 1 to s. Consider \u00b5, \u03bb \u2208 U , and denote by Ps and Qs the probability distribution of Y (s) under \u00b5 and \u03bb respectively. Then we have:\nKL (Ps||Qs) = K\u2211 k=1 E[tk(s)]KL (\u00b5(xk), \u03bb(xk)).\nTheorem B.4 is a concentration inequality for sums of KL divergences. It was derived derived in [20], and is stated here for completeness.\nTheorem B.4 [20] For all \u03b4 \u2265 (K + 1) and s \u2265 1 we have:\nP [ sup n\u2264s K\u2211 k=1 tk(n)KL (\u00b5\u0302k(n), \u00b5(xk)) \u2265 \u03b4 ] \u2264 eK+1\u2212\u03b4 ( d\u03b4 log(s)e\u03b4 K )K . (8)\nLemma B.5 is a technical result showing that the expected number of times the empirical mean of i.i.d. variables deviates by more than \u03b4 from its expectation is o(log(n)), n being the time horizon.\nLemma B.5 Let {Xn}n\u22651 be a family of i.i.d. random variables with common expectation \u00b5 and finite second moment. Define \u00b5\u0302(n) = (1/n) \u2211n n\u2032=1Xn\u2032 . For \u03b4 > 0 define\nD\u03b4(s) = \u2211s n=1 1{|\u00b5\u0302(n)\u2212 \u00b5| \u2265 \u03b4}. Then we have that for all \u03b4:\nE[D\u03b4(s)] log(s) \u2192s\u2192\u221e 0.\nProof. We define v2 = E[(X1 \u2212 \u00b5)2] the variance. Using the fact that {Xn}n\u22651 are independent, we have that E[(\u00b5\u0302(n)\u2212 \u00b5)2] = v2/n. Applying Chebychev\u2019s inequality we have that:\nP[|\u00b5\u0302(n)\u2212 \u00b5| \u2265 \u03b4] \u2264 E[(\u00b5\u0302(n)\u2212 \u00b5) 2]\n\u03b42 =\nv2\nn\u03b42 .\nTherefore, we recognize the harmonic series:\nE[D\u03b4(s)] = s\u2211\nn=1\nP[|\u00b5\u0302(n)\u2212 \u00b5| \u2265 \u03b4] \u2264 v 2\n\u03b42 s\u2211 n=1 1 n \u2264 v 2(log(s) + 1) \u03b42 ,\nso that sups E[D\u03b4(s)]/ log(s) <\u221e. Applying the law of large numbers, we have that \u00b5\u0302(n)\u2192n\u2192\u221e \u00b5 a.s., so that |\u00b5\u0302(n)\u2212 \u00b5| occurs only finitely many times a.s. Hence supsD \u03b4(s) <\u221e a.s and D\u03b4(s)/ log(s)\u2192 0 a.s.\nWe have proven that sups E[D\u03b4(s)]/ log(s) <\u221e andD\u03b4(s)/ log(s)\u2192 0 a.s. so applying Lebesgue\u2019s dominated convergence theorem we get the announced result:\nE[D\u03b4(s)] log(s) \u2192s\u2192\u221e 0,\nwhich concludes the proof."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>We consider stochastic bandit problems with a continuous set of arms and where the expected re-<lb>ward is a continuous and unimodal function of the arm. No further assumption is made regarding<lb>the smoothness and the structure of the expected reward function. For these problems, we propose<lb>the Stochastic Pentachotomy (SP) algorithm, and derive finite-time upper bounds on its regret and<lb>optimization error. In particular, we show that, for any expected reward function \u03bc that behaves as<lb>\u03bc(x) = \u03bc(x)\u2212 C|x\u2212 x| locally around its maximizer x for some \u03be, C > 0, the SP algorithm is<lb>order-optimal. Namely its regret and optimization error scale as O(<lb>\u221a<lb>T log(T )) and O(<lb>\u221a<lb>log(T )/T ),<lb>respectively, when the time horizon T grows large. These scalings are achieved without the knowledge<lb>of \u03be and C. Our algorithm is based on asymptotically optimal sequential statistical tests used to suc-<lb>cessively trim an interval that contains the best arm with high probability. To our knowledge, the SP<lb>algorithm constitutes the first sequential arm selection rule that achieves a regret and optimization error<lb>scaling as O(<lb>\u221a<lb>T ) and O(1/<lb>\u221a<lb>T ), respectively, up to a logarithmic factor for non-smooth expected<lb>reward functions, as well as for smooth functions with unknown smoothness.", "creator": "LaTeX with hyperref package"}}}