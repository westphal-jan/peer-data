{"id": "1408.5490", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2014", "title": "New Ideas for Brain Modelling 2", "abstract": "this paper describes a relatively simple way of allowing a brain model to self - organise its concept patterns through nested structures. time is a key element and a simulator itself would be able to show how patterns may form and then fire in sequence, as part of a search or thought learning process. it likewise uses a very simple equation component to show players how the inhibitors in particular, can gradually switch off certain areas, to allow other areas to become the prominent ones and thereby define the likely current brain state. this aspect allows for a small amount of control over what appears to be a chaotic structure inside it of the analyzed brain. apparently it essentially is attractive because it is but still mostly controlled mechanical mode and therefore can be added as an automatic process, or the physiological modelling of that. the paper also describes how the nested pattern structure can be now used as a basic counting mechanism. this extended version integrates further with the existing cognitive model and provides new conclusions.", "histories": [["v1", "Sat, 23 Aug 2014 11:05:00 GMT  (1891kb)", "http://arxiv.org/abs/1408.5490v1", "This is an extended version ofarXiv:1403.6274, with a different conclusions section as well"], ["v2", "Tue, 2 Sep 2014 19:45:56 GMT  (510kb)", "http://arxiv.org/abs/1408.5490v2", "This is an extended version ofarXiv:1403.6274, with a different conclusions section as well"]], "COMMENTS": "This is an extended version ofarXiv:1403.6274, with a different conclusions section as well", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["kieran greer"], "accepted": false, "id": "1408.5490"}, "pdf": {"name": "1408.5490.pdf", "metadata": {"source": "META", "title": "DCS Paper", "authors": ["Kieran Greer"], "emails": [], "sections": [{"heading": null, "text": "concept patterns through nested structures. Time is a key element and a simulator would be able to show how patterns may form and then fire in sequence, as part of a search or thought process. It uses a very simple equation to show how the inhibitors in particular, can switch off certain areas, to allow other areas to become the prominent ones and thereby define the current brain state. This allows for a small amount of control over what appears to be a chaotic structure inside of the brain. It is attractive because it is still mostly mechanical and therefore can be added as an automatic process, or the modelling of that. The paper also describes how the nested pattern structure can be used as a basic counting mechanism. This extended version1 integrates further with the existing cognitive model and provides new conclusions.\nKeywords: neural modelling, self-organise, connection strengths, mathematical process."}, {"heading": "1 Introduction", "text": "This paper describes a relatively simple way of allowing a brain model to self-organise its concept patterns through nested structures. Time is a key element and a simulator would be able to show how patterns may form and then fire in sequence, as part of a search or thought process. The equation that is tested is possibly a simplified version of existing ones ([13] equation 1, for example) which would also consider the synaptic connections in detail. This model is very much generalised and considers the pattern firing properties only. As such, it would be a quicker algorithm to use and so it may allow for more economic test runs that are concerned with this aspect in particular. The algorithm is attractive because it is still mostly\n1 This is an extended version of the paper accepted by The Science and Information Conference (SAI'14), London, 27 \u2013 29 August, 2014.\ncan also be used as a basic counting mechanism and so might be useful for more mathematical operations.\nThe pattern model that is suggested is one of the most commonly occurring models that we have in the real world and so it is clearly understood and could be added to a computer program relatively easily. It is however a very high-level idea, without exact cell workings or connections, for example. After the model and the reasons for suggesting it are described, some tests based on a relatively simple equation will be presented, to show the correctness of the idea.\nThe rest of this paper is structured as follows: section 2 describes some related work. Section 3 describes the main ideas of the new model. Section 4 describes some tests and results that confirm the main idea, while section 6 gives some conclusions on the work."}, {"heading": "2 Related Work", "text": "This section is more biologically-oriented, where the author is not particularly expert, but the papers might make some relevant points. The aim is to show that the proposed structure is at least practical. The paper [13] is quite closely related and includes a number of important statements. It gives one example of an equation for the firing rate that includes the whole range of inputs, including external sensory and other neurons\u2019 excitatory/inhibitory input. It states that for the firing to be sustained, that is, to be relevant, requires sufficient feedback from the firing neurons, to maintain the level of excitation. Once the process starts however, this can then excite and bring in other neurons, when inhibitory inputs also need to fire, to stop the process from saturating. A weighted equation is given to describe how the process can self-stabilise if \u2018enough\u2019 inhibitory inputs fire and a comparison with the equation is given in section 4. The paper [10] also studies the real biological brain and in particular, the chemospecific steering and\nsynaptic growth and also theories about the processes. While current theory suggests that growth is driven by the neuron itself, that paper would require it to be driven almost completely by the charged \u2018signal\u2019. Current theory also suggests that the neuron is required first, before the synapses can grow to it. However, they do note a pairwise chemospecific signalling process, as opposed to something that is just random and they also note that their result is consistent with the known preferences of different types of \u2018interneurons\u2019 to form synapses on specific domains of nearby neurons.\nThe paper [14] also describes how neurons can change states and start firing at different rates. The paper [11] describes that there are both positive and negative regulators. The positive regulators can give rise to the growth of new synaptic connections and this can also form memories. There are also memory suppressors, to ensure that only salient features are learned. Long-term memory endures by virtue of the growth of new synaptic connections, a structural change that parallels the duration of the behavioural memory. As the memory fades, the connections retract over time. So, there appears to be constructive synaptic processes and these can form memory structures. The paper [12] is more computer-based and describes tests that show how varying the refractory (neuron dynamics) time with relation to link time delays (signal) can vary the transition states. They note that it is required to only change the properties of a small number of driver nodes, which have more input connections than others. These nodes can control synchronization locally and they note that depending on the time scale of the nodes, some links are dynamically pruned, leading to a new effective topology with altered synchronization patterns. The structures tested are larger control loops, but it is interesting that the tests use very definite circular pattern shapes. The work of Santiago Ram\u00f3n y Cajal2 has been suggested as relevant, in particular, with relation to pacemaker cells. This is definitely interesting and will be discussed in the conclusions of section 6. However, while Cajal appears to classify\n2 http://www.scholarpedia.org/article/Santiago_Ram\u00f3n_y_Cajal.\ntypes. It is only interested in location for allowing them to operate as part of a thinking process.\nThe author has proposed neural network or cognitive models previously [4][5][6][7] and it is hoped that this paper does not contradict that work. The aim has been to build a computer model that copies the brain processes as closely as possible, so as to realise a better or more realistic AI model. It is still a computer program however and a close inspection of how the biological components work has not been considered yet. The goal is to try and make the underlying processes as mechanical, or automatic, as possible, so that the minimum amount of additional intelligence is required for them to work. Earlier themes included dynamic or more chaotic linking, time-based events, pattern formation with state changes, clustering and even hierarchical structures with terminating states or nodes. This paper is associated with some of the earlier work, including the more chaotic neural network structures [4][5], or the pattern forming levels of the cognitive model [6][7]."}, {"heading": "3 Reasons For the Firing Patterns Model", "text": "It is important to remember that an energy supply is required to cause the neurons to fire. It is probably correct to think that the brain must receive a constant supply of energy to work. If a neuron fires, this would necessarily use up some of the energy, which is why the supply must be refreshed. If thinking about the single neuron, it is thought that ion channels cause the neuron activation, where pressure or force is not the main mechanism3. A neuron itself does not have the intelligence to fire, in the sense that it is reactive and not proactive. The fact that inhibitors are used to suppress the firing rate shows that the neurons cannot decide this for themselves. They also need an automatic mechanism to switch off. The activation might be traced back to the external stimulus, which is a continuous energy source, although pressure would be another one [15]. Note also that the brain would be expected to give feedback, which in turn might\n3 Pressure is not very relevant for this paper, but was used as part of an earlier argument [4] to help the synaptic structures to grow and re-balance.\nmake sense to nest sub-concepts, based on the idea of distance alone."}, {"heading": "3.1 Sub-Concepts", "text": "When thinking about brain firing patterns, it appears to be very random and complex. Pictures or scans of activity however usually show distinct brain areas that are active, where this in itself is interesting. If the firing activity was completely random, then specific areas should possibly not be present, as synapses would travel in any direction to other neurons. So there is an indication here that the firing activity is contained. This then means that it could be inwards, or inside the originally activated area. This can sometimes be almost the whole brain, however. A simple example might also illustrate something. Thinking about a coffee cup, the cup itself can be imagined, sitting by itself. To expand the scenario, possibly a kettle is imagined, filling the cup with water. A specific action would also be invoked here. But is it the case that when the kettle is imagined, the whole kitchen scenario is retrieved? Even if this is done sub-consciously, it would put the scenario into a familiar context, when the kettle and subsequent actions are then easy. This is therefore interesting, because it suggests that the larger activity areas could be these larger concepts that then contain lots of smaller ones inside of them. The kitchen can contain a kettle and a cup, for example. If firing is restricted to the kitchen scenario, it is easy to imagine that it might activate the other smaller kitchen-related concepts. This is also a part of how we try to model the real world, mathematically or formally, in our processes or diagrams, for example.\nFurther, a single concept can be imagined by itself and even without a background. But the addition of context, invoked by an action or other object, forces the relevant background, even if it is relatively weak. So is the coffee cup and kettle driving the activation and triggering the kitchen that lives somewhere else, or is the span or area of activation now wide enough to activate part of the parent kitchen concept? If the firing was always inwards then activating a larger concept would be difficult, so at least some lateral or outwards positive activation is\ndirectly (see possibly the \u03b8 value of equation 1 in [13]). As separate pattern groups also need to link, lateral signals could excite a general area between them as well. An action might even originate in a different brain region, bringing all of the connected areas into play. Figure 1 is a schematic of the general idea. There is a larger pattern with nested ones and some excitatory and some inhibitory signals. Traversing the larger area would bring in more of the background patterns or images. So the currently firing pattern is what defines the brain state. If there is no other way of controlling this, the ability to switch off the other areas in an automatic manner is required. If the parent provider encapsulates the new or most active next state, then this activity could be through a relatively simple and easy to understand process. The inhibitors will naturally send more negative feedback to their neighbouring environment, thereby weakening the parent signal compared to the new firing pattern. If new areas inside of them then become active, the process can repeat again. The most obvious catch is the fact that lateral linking and activation is always required and also from other brain regions that perform other functions. It is however, still a natural way to self-organise."}, {"heading": "3.2 Mathematical Processes", "text": "Another interesting use of the nested patterns is not to retrieve sub-concepts, but to implement a basic timer, counter or even battery, that could be part of more mathematical\na particular group of neurons. A more general supply is converted into one that can schedule something, or run for a pre-determined amount of time. It might be part of a whole cycle of pattern activations as follows: Some pattern activates another pattern that is the on-switch to a timer or battery. The on-switch activates the outer-most pattern of the nested group that makes up the new structure. This cycles inwards as described, until the inner-most pattern is activated. This might be 3 nested patterns, for example. Each nested pattern, when activated, might send a signal somewhere, but the inner-most one also sends a signal to the off-switch pattern that is beside the on-switch. The off-switch sends inhibitors to the on-switch, asking it to turn off. This then removes the signal inducer to the new structure and the whole cycle can stop.\nAs this is only an idea, an alternative and possibly better mechanism would be to slowly increase both the excitatory and inhibitory signals. The first activation phase from the outermost pattern to the first nested one might not activate all neurons one level in. This also means however that they would not all send inhibitory signals back. So the outer-most pattern might be able to send several phases of signal before it receives an overwhelming inhibitory signal. The same situation can occur between any of the nested pattern sets. Continual activation signals can switch on more neurons the next level in, but then they also send more inhibitory signals back. If the excitatory signal is mostly inwards and the inhibitory one mostly outwards, this should result in the whole region eventually switching itself off.\nSlightly more doubtful: if the inhibitory signal only affects active neurons, then they can possibly fire in any direction, because the inner patterns will receive less than the outer ones, based on time events and so the outer ones will switch off first. So there would still be the desired and gradual build-up of signal and shut-down afterwards. Note that these cases require a constant, external energy supply, which then gets shut-down or ignored. It would also be helpful if inhibitors could change a neuron state without switching it off completely and ideas of\ncase. Some area of the brain excites and starts the outer-most pattern firing. This is the \u2018on\u2019 switch with a signal to the outer-most circle. The pattern cycles through to the inner-most one that can then ask for the provider to switch off. This is the \u2018off\u2019 switch. Each nested pattern can also send a signal somewhere else, which would implement the counting mechanism.\nThe paper [13] notes another model that already exists called Synfire chains. Synfire chains fire in a definite outwards direction and offer some degree of control through firing stages at different levels. This then leads to problems of explosion from a sustained input and requires noise or other to control the firing rates. So the main question for the model of this paper is whether it can actually occur naturally, as other formations appear to be outward facing. It is worth remembering that clear pattern boundaries get created however.\nAs well as deciding to fire, this paper would require the neuron to intelligently control direction. Why would the neurons prefer to fire inwards instead of any direction? The theory of this paper however allows that intelligence to be replaced with an economic reason, based on the conservation of energy. If thinking about stigmergic systems, [2] for example, the ant colony selects the most economic path unintentionally and neurons equally influence each other. The idea of grouping more closely, neurons that fire at the same time, is also the well-known doctrine of Hebb [9]. The search process would also conceivably converge on terminal states [4],\ntogether wire together\u2019 requires a link between the two or more groups involved. If search occurs from a broad group to a smaller terminal state; then if that search is outwards, as in Figure 3a, the distance between the terminal states and the nodes in general is greater than if it is inwards, as in Figure 3b. Note in particular the case where the terminal states join to complete a circuit. Also, exactly as with stigmergy, if both pattern sets receive the same amount of energy, Figure 3b will reinforce more, because the signal can take a shorter route. That might just provide a reason why it is easier for the inward pointing search to then connect with another related search area, than the outward pointing one. Therefore, even by chance, a random process might prefer the inward facing groups."}, {"heading": "4 Testing and Results", "text": "Testing of the theory can be carried out by implementing some basic reinforcement algorithms and updating specific node values, to simulate the different timings of the node pattern activations. The traditional increment/decrement reinforcement algorithm worked well enough to give the desired result. With that, the node value is incremented with excitatory input and decremented with inhibitory input. The decrement value can be weighted to be only a fraction of the increment. Some assumptions are made with regards to the neurons, which helps to simplify the problem further:\n Each neuron has only one excitatory output and one inhibitory output.\n The inhibitory output goes only to any other neuron that is in any parent pattern.\n Neurons are in the same pattern if they fire at the same time. This is measured by time\nincrements t1 \u2026 tn."}, {"heading": "4.1 Test Conditions", "text": "The equation 1 for firing rate networks in [13] is probably a complete version of the equation that might be used. These tests only consider the excitatory/inhibitory part, to measure how the patterns will switch on and off through their interactions. The firing interactions are further restricted by the aforementioned assumptions. The resulting test equation for this paper could therefore be written as follows:\nXit = \u2211 \u0727\u0750\u2212 (\u2211 \u2211 \u2211 (\u072a \u0755\u0746\u2217 \u07dc)  \u0b40\u0b35  \u0bec\u0b40\u0b35  \u0b40j i \u0b40\u0b35 )\nwhere y  t and \u0745\u2208 i\u0732 and \u074a\u0750\u0746 \u2208 i\u0732 , and\nXit = total input signal for neuron i at time t. Ep = total excitatory input signal for neuron p in pattern P. Hjy = total inhibitory input signal for neuron j at time y. \u03b4 = weights inhibitory signal. t = time interval for firing neuron. y = time interval for any other neuron. n = total number of neurons. m = total number of time intervals. l = total number of active patterns. Pi = pattern for neuron i. P = total number of patterns.\nIn words, the tests measure how the total signal input to each neuron pattern changes. All neurons in the same pattern fire at the same time and send each other their positive signal. Any\nnested patterns are active, for example, the inner-most sends inhibitory signals to both the outer-most pattern and the first nested one. The first nested pattern sends inhibitory signals to just the outer-most one. Over time, neurons continue to fire based on - total pattern firing strength minus total inhibitory firing strength from all other nested patterns."}, {"heading": "4.2 Test Results", "text": "The test results are quite straightforward and show the desired set of relative counts or signal strengths. Just the traditional increment/decrement algorithm is shown in Table 1. There are 25 neurons in total and 5 in each nested pattern. The inhibitory signal is set to be half that of an excitatory one, but if a pattern only contains 5 neurons, that leaves a possible 20 other neurons that might send inhibitory signals. Each firing cycle activates a new nested pattern, until all patterns are active. After that, each firing cycle would update signals from all patterns. The inhibitory signal is sent from the inner pattern to its outer ones only, so the inner-most one does not receive inhibitory signals. When all patterns are active, the inhibitory signal builds up to overwhelm the excitatory signal. This of course, depends on the pre-set relative strengths and numbers of excitatory and inhibitory signals.\nNeurons 1 to 5 are the outer-most pattern. Neurons 6 to 10 are the first nested pattern and so on, until neurons 21 to 25 are the inner-most nested pattern. At time t1, the first pattern only fires (neurons 1 to 5). At time t2 pattern 1, then pattern 2 fires. At time t3, pattern 1, then pattern 2, then pattern3 fire, and so on. The outer patterns have more excitatory input to start with, but as the other patterns switch on and send negative feedback, eventually they will switch off the outer patterns. This would then actually starve the inner patterns of input, until they switch off as well.\nNeurons t = 3 t = 4 t = 5 Neurons t = 3 t = 4 t = 5 1 7.5 5.0 0.0 16 0.0 5.0 7.5 2 7.5 5.0 0.0 17 0.0 5.0 7.5 3 7.5 5.0 0.0 18 0.0 5.0 7.5 4 7.5 5.0 0.0 19 0.0 5.0 7.5 5 7.5 5.0 0.0 20 0.0 5.0 7.5 6 7.5 7.5 5.0 21 0.0 0.0 5.0 7 7.5 7.5 5.0 22 0.0 0.0 5.0 8 7.5 7.5 5.0 23 0.0 0.0 5.0 9 7.5 7.5 5.0 24 0.0 0.0 5.0 10 7.5 7.5 5.0 25 0.0 0.0 5.0 11 5.0 7.5 7.5 12 5.0 7.5 7.5 13 5.0 7.5 7.5 14 5.0 7.5 7.5 15 5.0 7.5 7.5"}, {"heading": "5 Cognitive Model", "text": "It turns out that the nested ensembles can fit into the current cognitive model, described in [5][6][7] and most recently in [4]. All of the elements mentioned in earlier papers are still relevant and so the model can be refined further. While it may not be 100% correct biologically, it is becoming quite detailed and still consistent over the main ideas."}, {"heading": "5.1 Hierarchical Nesting", "text": "The first thing to think about again is the regions, or nested regions, of pattern ensembles. As the individual elements are likely to be located randomly, duplication can help. For example, if the concepts in question are duplicated they can occur in different locations and collections, but the permanent ensemble will probably be formed where they are located closest to each other. It is noted that duplication also occurs because different parts of the brain store the\nfirst, satisfy the input requirements and reinforce the most, as in stigmergy. Therefore, duplication makes it more likely that any ensemble can form, or if the neuron is missing, does it just get created? It is also noted that neurons are created from some sort of chemical reaction and are not required to grow at the end of a synapse, or anything like that. So the stimulus itself can create new neurons as needed.\nIf looking at the neural network model of [7] again - trying to justify everything is silly, but a similar situation that favours a unique set of closer grouped entities might be relevant. It was also shown in the neural network that noisy input could be filtered out more easily, which might also be a helpful feature for the nested ensembles. The noise would be filtered out more easily because it might not be consistently the same in each group, whereas each specific concept would be. Keeping the individual groups separate does not allow random noise to form into more common clusters. The ensembles are then connected through the hierarchy. It has also been suggested that the physical space and the logical space are different. For a comparison with the neural network, the hidden layer(s) is a combination of the nodes in the level below. For a nested ensemble, this is simply the parent or enclosing region of the group in question. This can continue up to the outer-most region. That would be the largest region, but would represent the most global and general concept as well. So the hierarchy is from the smaller nested regions to the larger enclosing one. The idea of a trigger, as shown in the earlier figures [4][6], is also appropriate and is even represented in Figure 1 of this paper. It could be the connecting synapse between the two inner circles that might be used to link-up different types of concept into logical sequences.\nAlso, can Figure 3 of this paper be compared to the concept trees of other papers [4], figure 6, for example? It is shown again here in Figure 4. Static knowledge also needs to be learned and base nodes at the bottom of trees might provide activation paths to the groups or ensembles at the leaves that then get arranged further through time. The dynamic time-based layer is maybe where neurons groups are initially connected to form concepts, but it is better to have 3\nensembles are also somewhere along this first time-based line and then up through the whole hierarchy.\nFigure 3 of this paper maybe has the node structures 180 degrees the wrong way round, where the broader regions should try to connect. The idea of a construction process in one direction and a search in the opposite direction is also again consistent. We can guess that the construction process for the ensemble hierarchy is again from the static concept trees to the dynamic global concepts. If that is the case, we would in fact see small details first and then aggregate them into larger entities. This is good for another reason. There is then a direct path to these smaller concepts that gets added during their formation and would allow them to be\nfrom our general impression to the finer details. We find the general region first and then search inside of that for specific information. If these end with concept tree-like structures, then the small ensembles can even trace down to the single terminating base nodes. Or maybe if the search is unclear, a larger area must be activated first, as in browsing.\nLooking at the actual human brain, the search probably starts in the neocortex [8] which is the thin upper layer that envelops most of the rest of the brain. So that is OK and is a top-down cognitive search. This means that the initial learning process must be more bottom-up and possibly carried out more through observation than prediction or interpretation. But that is probably OK as well. The hippocampus is supposed to be where memories are stored, or at least, is critical to their formation. It is a separate structure to the neocortex, as the concept trees are to the ensemble hierarchy.\nSynfire chains [13] demonstrate a cascading activation process over a hierarchical structure that could represent a search process over the ensemble hierarchy. This has been pointed out earlier in section 3.2 as opposite to the inward firing process assumed by the nested ensembles, but it may in fact be the same. The inward firing of this paper is from the outer region to the nested regions, which is the same as from the upper hierarchical level to the multiple lower levels. It is just the physical representation that was confusing. One difference might be that while the outer-most region represents one basic concept, it might contain more neurons numerically. These then excite more concepts in the next level but they are each represented by smaller numbers of neurons. This is interesting in itself, if a neuron must represent something specific, or can it be purely functional? It might be worth mentioning the pyramidal neurons found by Cajal, for section 5.2 in particular. These have multiple inputs at the base and an output axon with synapses that span any area and so can flow in any direction.\nIt has been shown previously [2][3] how ant or termite colonies can collectively determine an optimal route through a basic reinforcement mechanism, without any prior or global knowledge about the route. Each insect leaves a trace that is read by the other insects and it is only that process which determines the optimal route. The Figure 3 of his paper shows how a similar process will encourage the closer sets of neurons to form together first, as the overall distances are less. This is also based on local information only and with no prior knowledge. As these insects are believed to work through a nervous system and not a brain as humans have, it is reasonable to apply a similar type of process for the pattern constructions. Research has already shown how firing neuron activity can saturate ([13], for example), but this does not mean a free energy supply. It must also be considered that if a signal is sent from a neuron to more than one place, then it can only be at a fraction of the single signal strength and so it might require a faster firing rate to maintain the same strength to multiple places. Maybe the inhibitors can help to self-regulate the firing rate. The more that feeder neurons activate an area, the more it will send out inhibitors that in turn might slow down the feeder activation signals, until some happy medium is met.\nDistance is also important along a single route and must be considered along with the energy consumption and the neuron threshold value. More energy would be required to force a signal along a longer path, where repeated firing by the feeder neurons would probably be required to maintain the signal flow. The paper [4] includes very basic equations that consider disruption of the signal over some distance. There does not have to be a forceful disruption for this aspect, only the natural impedances, but similar types of equation can be applied. These will be described in quite abstract and general terms, so it is the idea of them and not exact values that is important. For a signal to be maintained therefore, we need to consider how much energy might be lost over a particular distance. For example:\nLet Tm be the threshold for the neuron that is to be activated.\nfeeder neuron to the next neuron. Let \u03b4 be the distance from the feeder neuron to the activation neuron. Let \u03b1 be the amount of signal that is lost per unit distance.\nThen, even if a neuron can eject the same amount of output that is received as input, the output signal required by the feeder neuron might be:\nIsn + (\u03b4 \u00d7 \u03b1). Or an excess of (\u03b4 \u00d7 \u03b1) is required to cover the distance of the signal to the next neuron.\nAs a neuron can act as a capacitor, this can mean that multiple signals are sent and stored, until the cumulative result fires the activation neuron. If the activation neuron is then required to activate another neuron further along, it faces the same problem. Thinking again in very abstract terms, the additional required signal becomes a multiple of the requirements of each individual neuron along the path. For example, if neuron 1 needs to fire twice to send enough signal to activate neuron 2 and neuron 2 needs to fire twice to send enough signal to activate neuron 3; then neuron 1 needs to fire 4 times to allow neuron 3 to fire. As far as balancing the neurons\u2019 organisation inside of any ensemble is concerned, this is actually a good result. Consider a line of these neurons that span a particular region, where the distances between them varies as follows:\nN1 5 N2 2 N3 2 N4 2 N5 10 N6 10 N7\nWhen clustering, it can be a bit localised, where typically the closest distance between any two points is measured. If the neurons N1 to N7 represent the points along a line, then neuron N3 would typically be considered to be at the centre of a cluster. If a region spans the whole area from N1 to N7 however, we would prefer any new neurons that get added to be evenly spaced and not to amass around neuron N3, being related with the closest local distances. If we use a\nis determined by the distance over the whole region only and not between individual neurons. In the example, if each numerical value is the additional required signal to reach the next neuron, then a value of 2 is required to go from N3 to N4, for example. But N4 then also needs 2 to go to N5, and so on. We are also trying to minimise the amount of energy that is required and also allow synapses to travel in both directions from a single neuron output. With a cumulative multiplicative count, a cluster centre like N3 would travel to N1 in one direction and N7 in the other, requires (2 x 5) + (2 x 2 x 10 x 10) = 410 additional firings. Neuron N5 looks like it is at the edge of a cluster, but to span the same distance, it requires (5 x 2 x 2 x 2) + (10 x 10) = 140 additional firings. The larger distances are prohibitive for neurons not located in the centre, distance-wise. So if this region was excited from the centre, which appears to be the most economic, it would prefer neuron N5 over neuron N3. This might also help to space the creation of new neurons better, because the energy or stimulus is always located in the centre and not necessarily in the densest region.\nThere is also a robustness or integrity reason why a central activation is better. If the activation path to the ensemble was at the edge and not at the centre, then it might be easier to change the ensemble concept by adding neurons to the other side of the edge. If the activation path is to the centre, then even if something new gets added, the original concept can maintain its original meaning, where the change is an addition rather than a radical shift to something else."}, {"heading": "5.3 One-way System?", "text": "With clear input and output sets to neurons and the requirements to complete circuits, it may be thought that most processes are one-way systems that are cyclic in nature. Although, recent brain models show fibrous or tree-like branching properties in the broadest granularity. Cyclic or circular completions are very easy to understand, but assume that the whole process is \u2018as one\u2019, where it might then be further assumed that the signals that flow need to be very similar. While they match with the known neuron functionality, there may be other problems. For one thing, there are definite regions in the brain and so signals would need to cross boundaries and\nof the hierarchy to the bottom in the neocortex (or the simulated neural network model), then to complete the cycle it needs to flow back up again, which is again possibly changing the functionality. So can a different suggestion be made. An alternative way to complete a circuit is to have (at least) two halves that meet or join. This is attractive for a number of reasons. One is the distance reason again. It would be possible for any brain region to start sending a signal into the \u2018middle area\u2019 of the brain, for example and have it travel anywhere else. It might then meet a matching signal from the receiving area. The two can join to reinforce and complete a slightly different mode of circuit. This could even be at the other side of the brain and so there does not have to be a long feedback loop to the original source. This means that when a stimulus is set off, the neocortex or some other area can independently start working to satisfy it. It can run through its own structures to try to match the signal. So there are at least two halves working independently that then try to match. The signals that meet would then actually collide instead of flow in the same direction together, but they still complete the circuit and the interaction might even facilitate the essential ingredient of resonance [1][5]. The signals can maybe meet at the boundaries, such as somewhere around the concept trees layer in the computer-based model."}, {"heading": "6 Conclusions", "text": "The purpose of this paper is to show how nested, or more specific patterns, may become the main focus in a generally excited area. They might even be used as part of more complex mathematical processes. Rather than the exact details of how they might be created, or link to each other, etc., the paper describes how they might be useful. Simulation would be easier if the interaction between the patterns only was considered, using a general equation for their relative strengths. The mechanical process can also work with a minimum of complexity and would allow these patterns to form and fire in sequence. It would also realise some level of natural order, which would be better than the very random and chaotic structures that appear to be present.\neconomic. As described in section 2, the mechanism is still compatible with earlier work.\nThe second purpose of this paper is to integrate the new findings into the whole cognitive model. It appears that the nested ensembles fit-in almost seamlessly with the existing ideas and through studying them, other helpful information has been obtained. In particular, there are several examples of how the processes can naturally regulate themselves and perform the type of functionality that you might think requires some level of intelligence. Energy economy means that self-organisation is very important and will naturally tend to unique concepts that are evenly spaced. The idea of resonance being important is also enhanced, if some form of joining is to be preferred over the less violent reinforcement through cyclic links. But then, each brain area can keep its own functionality and have a sort of interface. Also, the earlier ideas of the dynamic hierarchical network joining with the static knowledge-based one is still central to the whole architecture and even small pieces of evidence from the real biological world can help to support the ideas, where established theories are not so clear."}], "references": [{"title": "Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system", "author": ["G. Carpenter", "S. Grossberg", "D. Rosen"], "venue": "Neural Networks,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1991}, {"title": "Ant algorithms and stigmergy, Future Generation", "author": ["M. Dorigo", "E. Bonabeau", "G. Theraulaz"], "venue": "Computer Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "La reconstruction dun id et les coordinations internidividuelles chez Bellicositermes natalensis et Cubitermes sp., La th\u00e9orie de la stigmergie: essais d\u2019interpr\u00e9tation du comportment des termites constructeurs", "author": ["P.P. Grass\u00e9"], "venue": "Insectes Sociaux,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1959}, {"title": "New Ideas for Brain Modelling, accepted for publication by Journal of Information Technology Research (JITR)", "author": ["K. Greer"], "venue": "Special issue on: From Natural Computing to Self-organizing Intelligent Complex Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Artificial Neuron Modelling Based on Wave Shape, BRAIN", "author": ["K. Greer"], "venue": "Broad Research in Artificial Intelligence and Neuroscience,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Turing: Then, Now and Still Key, book chapter in: \u2018Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) - Turing 2012", "author": ["K. Greer"], "venue": "Eds. X-S. Yang, Studies in Computational Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Symbolic Neural Networks for Clustering Higher-Level Concepts", "author": ["K. Greer"], "venue": "NAUN International Journal of Computers, Issue 3,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "The Organisation of Behaviour", "author": ["D.O. Hebb"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1949}, {"title": "Statistical connectivity provides a sufficient foundation for specific functional connectivity in neocortical neural microcircuits", "author": ["S.L. Hill", "Y. Wang", "I. Riachi", "F. Sch\u00fcrmann", "H. Markram"], "venue": "Proceedings of the National Academy of Sciences", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "The Molecular Biology of Memory Storage: A Dialogue Between Genes and Synapses", "author": ["E.R. Kandel"], "venue": "Science magazine,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "Control of synchronization patterns in neural-like Boolean networks, arXiv preprint repository, http://arxiv.org", "author": ["D.P. Rosin", "D. Rontani", "D.J. Gauthier", "E. Scholl"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Sodium channels, the electrogenisome and the electrogenistat: lessons and questions from the clinic", "author": ["S.G. Waxman"], "venue": "The Journal of Physiology,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Regional brain blood flow in man during acute changes in arterial blood gases", "author": ["C.K. Willie", "D.B. Macleod", "A.D. Shaw", "K.J. Smith", "Y.C. Tzeng", "N.D. Eves", "K Ikeda", "J. Graham", "N.C. Lewis", "T.A. Day", "P.N. Ainslie"], "venue": "The Journal of Physiology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}], "referenceMentions": [{"referenceID": 8, "context": "The paper [10] also studies the real biological brain and in particular, the chemospecific steering and", "startOffset": 10, "endOffset": 14}, {"referenceID": 11, "context": "The paper [14] also describes how neurons can change states and start firing at different rates.", "startOffset": 10, "endOffset": 14}, {"referenceID": 9, "context": "The paper [11] describes that there are both positive and negative regulators.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "The paper [12] is more computer-based and describes tests that show how varying the refractory (neuron dynamics) time with relation to link time delays (signal) can vary the transition states.", "startOffset": 10, "endOffset": 14}, {"referenceID": 3, "context": "The author has proposed neural network or cognitive models previously [4][5][6][7] and it is hoped that this paper does not contradict that work.", "startOffset": 70, "endOffset": 73}, {"referenceID": 4, "context": "The author has proposed neural network or cognitive models previously [4][5][6][7] and it is hoped that this paper does not contradict that work.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": "The author has proposed neural network or cognitive models previously [4][5][6][7] and it is hoped that this paper does not contradict that work.", "startOffset": 76, "endOffset": 79}, {"referenceID": 6, "context": "The author has proposed neural network or cognitive models previously [4][5][6][7] and it is hoped that this paper does not contradict that work.", "startOffset": 79, "endOffset": 82}, {"referenceID": 3, "context": "This paper is associated with some of the earlier work, including the more chaotic neural network structures [4][5], or the pattern forming levels of the cognitive model [6][7].", "startOffset": 109, "endOffset": 112}, {"referenceID": 4, "context": "This paper is associated with some of the earlier work, including the more chaotic neural network structures [4][5], or the pattern forming levels of the cognitive model [6][7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 5, "context": "This paper is associated with some of the earlier work, including the more chaotic neural network structures [4][5], or the pattern forming levels of the cognitive model [6][7].", "startOffset": 170, "endOffset": 173}, {"referenceID": 6, "context": "This paper is associated with some of the earlier work, including the more chaotic neural network structures [4][5], or the pattern forming levels of the cognitive model [6][7].", "startOffset": 173, "endOffset": 176}, {"referenceID": 12, "context": "The activation might be traced back to the external stimulus, which is a continuous energy source, although pressure would be another one [15].", "startOffset": 138, "endOffset": 142}, {"referenceID": 3, "context": "3 Pressure is not very relevant for this paper, but was used as part of an earlier argument [4] to help the synaptic structures to grow and re-balance.", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "8 localised firing already exist [12].", "startOffset": 33, "endOffset": 37}, {"referenceID": 1, "context": "If thinking about stigmergic systems, [2] for example, the ant colony selects the most economic path unintentionally and neurons equally influence each other.", "startOffset": 38, "endOffset": 41}, {"referenceID": 7, "context": "The idea of grouping more closely, neurons that fire at the same time, is also the well-known doctrine of Hebb [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 3, "context": "The search process would also conceivably converge on terminal states [4],", "startOffset": 70, "endOffset": 73}, {"referenceID": 4, "context": "It turns out that the nested ensembles can fit into the current cognitive model, described in [5][6][7] and most recently in [4].", "startOffset": 94, "endOffset": 97}, {"referenceID": 5, "context": "It turns out that the nested ensembles can fit into the current cognitive model, described in [5][6][7] and most recently in [4].", "startOffset": 97, "endOffset": 100}, {"referenceID": 6, "context": "It turns out that the nested ensembles can fit into the current cognitive model, described in [5][6][7] and most recently in [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 3, "context": "It turns out that the nested ensembles can fit into the current cognitive model, described in [5][6][7] and most recently in [4].", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "If looking at the neural network model of [7] again - trying to justify everything is silly, but a similar situation that favours a unique set of closer grouped entities might be relevant.", "startOffset": 42, "endOffset": 45}, {"referenceID": 3, "context": "The idea of a trigger, as shown in the earlier figures [4][6], is also appropriate and is even represented in Figure 1 of this paper.", "startOffset": 55, "endOffset": 58}, {"referenceID": 5, "context": "The idea of a trigger, as shown in the earlier figures [4][6], is also appropriate and is even represented in Figure 1 of this paper.", "startOffset": 58, "endOffset": 61}, {"referenceID": 3, "context": "Also, can Figure 3 of this paper be compared to the concept trees of other papers [4], figure 6, for example? It is shown again here in Figure 4.", "startOffset": 82, "endOffset": 85}, {"referenceID": 3, "context": "Integration of elements into the Cognitive Model, also from [4].", "startOffset": 60, "endOffset": 63}, {"referenceID": 1, "context": "It has been shown previously [2][3] how ant or termite colonies can collectively determine an optimal route through a basic reinforcement mechanism, without any prior or global knowledge about the route.", "startOffset": 29, "endOffset": 32}, {"referenceID": 2, "context": "It has been shown previously [2][3] how ant or termite colonies can collectively determine an optimal route through a basic reinforcement mechanism, without any prior or global knowledge about the route.", "startOffset": 32, "endOffset": 35}, {"referenceID": 3, "context": "The paper [4] includes very basic equations that consider disruption of the signal over some distance.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "The signals that meet would then actually collide instead of flow in the same direction together, but they still complete the circuit and the interaction might even facilitate the essential ingredient of resonance [1][5].", "startOffset": 214, "endOffset": 217}, {"referenceID": 4, "context": "The signals that meet would then actually collide instead of flow in the same direction together, but they still complete the circuit and the interaction might even facilitate the essential ingredient of resonance [1][5].", "startOffset": 217, "endOffset": 220}], "year": 2014, "abstractText": "This paper describes a relatively simple way of allowing a brain model to self-organise its concept patterns through nested structures. Time is a key element and a simulator would be able to show how patterns may form and then fire in sequence, as part of a search or thought process. It uses a very simple equation to show how the inhibitors in particular, can switch off certain areas, to allow other areas to become the prominent ones and thereby define the current brain state. This allows for a small amount of control over what appears to be a chaotic structure inside of the brain. It is attractive because it is still mostly mechanical and therefore can be added as an automatic process, or the modelling of that. The paper also describes how the nested pattern structure can be used as a basic counting mechanism. This extended version integrates further with the existing cognitive model and provides new conclusions.", "creator": "Microsoft Word - ai_pattern_dcs2.docx"}}}