{"id": "1409.1455", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2014", "title": "Unsynthesizable Cores - Minimal Explanations for Unsynthesizable High-Level Robot Behaviors", "abstract": "with the increasing ubiquity of multi - capable, general - purpose robots arises within the need today for enabling non - expert users to command these robots to perform complex high - level tasks. to this short end, high - level robot module control has seen the application introduction of generic formal methods to remotely automatically remotely synthesize correct - by - construction controllers from user - defined specifications ; synthesis fails if and conditions only happen if there exists no controller that achieves otherwise the specified behavior. recent work has also addressed the challenge of providing easy - to - understand human feedback to users when managing a specification fails to yield a corresponding controller. existing techniques provide feedback on portions of the specification that cause the failure, but do so at a coarse granularity. this important work presents techniques for eventually refining this feedback, extracting minimal explanations of unsynthesizability.", "histories": [["v1", "Thu, 4 Sep 2014 14:50:54 GMT  (457kb,D)", "http://arxiv.org/abs/1409.1455v1", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["vasumathi raman", "hadas kress-gazit"], "accepted": false, "id": "1409.1455"}, "pdf": {"name": "1409.1455.pdf", "metadata": {"source": "CRF", "title": "Unsynthesizable Cores \u2013 Minimal Explanations for Unsynthesizable High-Level Robot Behaviors", "authors": ["Vasumathi Raman", "Hadas Kress-Gazit"], "emails": ["vasu@caltech.edu)."], "sections": [{"heading": null, "text": "Index Terms\u2014high-level behaviors, formal methods, temporal logic.\nI. INTRODUCTION\nAs robots become increasingly general-purpose and ubiquitous, there is a growing need for them to be easily controlled by a wide variety of users. The near future will likely see robots in homes and offices, performing everyday tasks such as fetching coffee and tidying rooms. The challenge of programming robots to perform these tasks has until recently been the domain of experts, requiring hard-coded implementations with the ad-hoc use of low-level techniques such as path-planning during execution.\nRecent advances in the use of formal methods for robot control have enabled non-expert users to command robots to perform high-level tasks using a specification language instead of programming the robot controller (e.g., [1\u20136]). There are several approaches in which correct-by-construction controllers are automatically synthesized from a description of the desired behavior and assumptions on the environment in which the robot operates [5, 6]. If a controller implementing the specification exists, one is returned. However, for specifications that have no implementation (i.e. unsynthesizable specifications), the process of pin-pointing the cause of the problem can be a frustrating and time-consuming process. This has motivated recent algorithms for explaining unsynthesizability of specifications [7, 8], revising specifications [9], and adding\n*V. Raman is supported by STARnet, a Semiconductor Research Corporation program, sponsored by MARCO and DARPA. H. Kress-Gazit is supported by NSF CAREER CNS-0953365 and DARPA N66001-12-1-4250.\nV. Raman is with the Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena CA 91125 (e-mail: vasu@caltech.edu).\n2H. Kress-Gazit is with the Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY 14853, USA hadaskg at cornell.edu\nManuscript received August 21, 2014.\nenvironment assumptions that would make the specification synthesizable [10].\nThere are two ways in which a specification can be unsynthesizable \u2013 it is either unsatisfiable, in which case the specified robot behavior cannot be achieved in any environment, or it is unrealizable, in which case there exists an admissible environment (satisfying the specified assumptions) that prevents the robot from achieving its specified behavior. Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].\nPrevious approaches left open the challenge of refining feedback to the finest possible granularity, providing the user with a minimal cause of unsynthesizability. The main contribution of this paper is to to identify unsynthesizable cores \u2013 minimal subsets of the desired robot behavior that cause it to be unsatisfiable or unrealizable. The analysis makes use of off-the-shelf Boolean satisfiability (SAT) solvers and existing synthesis tools to find this minimal cause of unsynthesizability, and therefore lends itself to generalization to any formal specification language for which the relevant tools exist. This paper subsumes the results presented in [14, 15], and extends the core-finding capabilities to previously unaddressed cases, as described in Section VII. In particular, this is the first paper to present a sound and complete algorithm for finding unsynthesizable cores (as defined in Section III) for specifications in the GR(1) fragment of Linear Temporal Logic (LTL), and discuss special considerations necessitated by specifications in the robotics problem domain.\nThe paper is structured as follows. Section II reviews terms and preliminaries. Section III describes types of unsynthesizability, and presents a formal definition of the problem of identifying unsynthesizable cores. Section IV describes related work on analyzing unsynthesizable specifications. Sections V and VI present techniques for using Boolean satisfiability to identify unsatisfiable and unrealizable cores respectively. Section VII describes an alternative method for identifying cores, based on iterated realizability checks. Section VIII demonstrates the effectiveness of the more fine-grained feedback on example specifications. The paper concludes with a description of future work in Section IX."}, {"heading": "II. PRELIMINARIES", "text": "The high-level tasks considered in this work involve a robot operating in a known workspace. The robot reacts to events\nar X\niv :1\n40 9.\n14 55\nv1 [\ncs .R\nO ]\n4 S\nep 2\n01 4\n2 in the environment, which are captured by its sensors, in a manner compliant with the task specification, by choosing from a set of actions including moving between adjacent locations. The tasks may include infinitely repeated behaviors such as patrolling a set of locations. Examples of such highlevel tasks include search and rescue missions and the DARPA Urban Challenge."}, {"heading": "A. Controller Synthesis", "text": "High-level control for robotics is inherently a hybrid domain, consisting of both discrete and continuous components. Automated correct-by-construction controller synthesis for this domain using formal methods requires a discrete abstraction and a description of the task in a formal specification language. The discrete abstraction of the high-level robot task consists of a set of propositions X whose truth value is controlled by the environment and read by the robot\u2019s sensors, and a set of action and location propositions Y controlled by the robot; the set of all propositions AP = X \u222aY . The value of each \u03c0 \u2208 AP is the abstracted binary state of a low-level black box component. More details on the discrete abstraction used in this work can be found in [5].\nThe formal language used for high-level specifications in this work is Linear Temporal Logic (LTL) [16], a modal logic that includes temporal operators, allowing formulas to specify the truth values of atomic propositions over time. LTL is appropriate for specifying robotic behaviors because it provides the ability to describe changes in the truth values of propositions over time. To allow users who may be unfamiliar with LTL to define specifications, some tools like LTLMoP [17] include a parser that automatically translates English sentences belonging to a defined grammar [18] into LTL formulas, as well as some natural language capabilities, as described in [14].\n1) Linear Temporal Logic (LTL): LTL formulas are constructed from atomic propositions \u03c0 \u2208 AP according to the following recursive grammar:\n\u03d5 ::= \u03c0 | \u00ac\u03d5 | \u03d5 \u2228\u03d5 | \u00a9\u03d5 | \u03d5 U \u03d5,\nwhere \u00ac is negation, \u2228 is disjunction, \u00a9 is \u201cnext\u201d, and U is a strong \u201cuntil\u201d. Conjunction (\u2227), implication (\u21d2), equivalence (\u21d4), \u201ceventually\u201d ( ) and \u201calways\u201d ( ) are derived from these operators. The truth of an LTL formula is evaluated over sequences of truth assignments to the propositions in AP. In this paper, truth assignments are represented as subsets P \u2286 AP, with \u03c0 \u2208 P being set to true and \u03c0 \u2208 AP\\P being false. Informally, the formula \u00a9\u03d5 expresses that \u03d5 is true in the next position in the sequence. Similarly, \u03d5 expresses that \u03d5 is true at every position, and \u03d5 expresses that \u03d5 is true at some position in the sequence. Therefore, the formula \u03d5 is satisfied if \u03d5 is true infinitely often. For a formal definition of the semantics of LTL, see [19].\nThe task specifications in this paper are expressed as LTL formulas of the form \u03d5 = \u03d5e \u21d2 \u03d5s, where \u03d5e encodes assumptions about the environment\u2019s behavior and \u03d5s represents the desired robot behavior. \u03d5e and \u03d5s each have the structure \u03d5p =\u03d5 ip\u2227\u03d5 tp\u2227\u03d5 g p , where \u03d5 ip,\u03d5 tp and \u03d5 g p for p\u2208{e,s} represent\nthe initial conditions, transition relation and goals for the environment (e) and the robot (s) respectively. This fragment of LTL is called Generalized Reactivity (1) or GR(1) [20].\nThe subformulas \u03d5 te and \u03d5 ts above are referred to as safety formulas, and encode assumptions on the environment and restrictions on the system transitions respectively. Each consists of a conjunction of formulas of the form Ai, where each Ai is a Boolean formula over AP (formulas over\u00a9AP= {\u00a9\u03c0 | \u03c0 \u2208 AP} are also allowed in \u03d5 ts). On the other hand, \u03d5eg and \u03d5sg are referred to as liveness formulas, and consist of conjunctions of clauses of the form B j. Each B j is a Boolean formula over AP, and represents an event that should occur infinitely often when the robot controller is executed. The initial conditions \u03d5 ie and \u03d5 is are non-temporal Boolean formulae over X and Y respectively.\nAn LTL formula \u03d5 is realizable if, for every time step, given a truth assignment to the environment propositions for the next time step, there is an assignment of truth values to the robot propositions such that the resulting infinite sequence of truth assignments satisfies \u03d5 . The synthesis problem is to find an automaton that encodes these assignments, i.e. whose executions satisfy \u03d5 . For a synthesizable specification \u03d5 , synthesis produces an implementing automaton, enabling the construction of a hybrid controller that produces the desirable high-level, autonomous robot behavior. The reader is referred to [20] and [5] for details of the synthesis procedure, and to [5, 17] for a description of how the extracted discrete automaton is transformed into low-level robot control."}, {"heading": "B. Environment Counterstrategy", "text": "In the case of unsynthesizable specifications, the counterstrategy synthesis algorithm introduced in [21] gives an automatic method of constructing a strategy for the environment, which provides sequences of environment actions that prevent the robot from achieving the specified behavior. The counterstrategy takes the form of a finite state machine:\nDefinition 1 An environment counterstrategy for LTL formula \u03d5 is a tuple Ae\u03d5 = (Q,Q0,X ,Y,\u03b4e,\u03b4s,\u03b3X ,\u03b3Y ,\u03b3goals) where \u2022 Q is a set of states. \u2022 Q0 \u2286 Q is a set of initial states. \u2022 X is a set of inputs (sensor propositions). \u2022 Y is a set of outputs (location and action propositions). \u2022 \u03b4e : Q \u2192 2X is a deterministic input function, which\nprovides the input propositions that are true in the next time step given the current state q, and satisfies \u03d5 te. \u2022 \u03b4s : Q\u00d7 2X \u2192 2Q is the (nondeterministic) transition relation. If \u03b4s(q,x) = /0 for some x \u2208 2X ,q \u2208 Q, then there is no next-step assignment to the set of outputs that satisfies the robot\u2019s transition relation \u03d5 ts , given the next set of environment inputs x and the current state q. \u2022 \u03b3X : Q\u2192 2X is a transition labeling, which associates with each state the set of environment propositions that are true over incoming transitions for that state (note that this set is the same for all transitions into a given state). Moreover, if q\u2032 \u2208 \u03b4s(q,x) then \u03b3X (q\u2032) = x. \u2022 \u03b3Y : Q\u2192 2Y is a state labeling, associating with each state the set of robot propositions true in that state.\n3 start r3 r4 r5 r6 r7 r8 goalr2\nThe counterstrategy Ae\u03d5 provides truth assignments to the input propositions (in the form of the transition function \u03b4e) that prevent the robot from fulfilling its specification. The inputs provided by \u03b4e in each state satisfy \u03d5 te, meaning that for all q\u2208 Q, the truth assignment sequence (\u03b3X (q)\u222a \u03b3Y(q),\u03b3X (\u03b4e(q))) satisfies Ai for each conjunct Ai in \u03d5 te (note that Ai is a formula over two consecutive time steps). In addition, all infinite executions of Ae\u03d5 satisfy \u03d5e\u2227\u00ac\u03d5s."}, {"heading": "III. PROBLEM STATEMENT", "text": "A specification that does not yield an implementing automaton is called unsynthesizable. Unsynthesizable specifications are either unsatisfiable, in which case the robot cannot succeed no matter what happens in the environment (e.g., if the task requires patrolling a disconnected workspace), or unrealizable, in which case there exists at least one environment that can prevent the desired behavior (e.g., if in the above task, the environment can disconnect an otherwise connected workspace, such as by closing a door). More examples illustrating the two cases can be found in [8].\nIn either case, the robot can fail in one of two ways: either it ends up in a state from which it has no moves that satisfy the specified safety requirements \u03d5 ts (this is termed deadlock), or the robot is able to change its state infinitely, but one of the goals in \u03d5gs is unreachable without violating \u03d5 ts (termed livelock). In the context of unsatisfiability, an example of deadlock is when the system safety conditions contain a contradiction within themselves. Similarly, unrealizable deadlock occurs when the environment has at least one strategy for forcing the system into a deadlocked state. Livelock occurs when there is one or more goals that cannot be reached while still following the given safety conditions.\nConsider Specification 1, in which the robot is operating in the workspace depicted in Fig. 1. The robot starts at the left hand side of the hallway (1), and must visit the goal on the right (4). The safety requirements specify that the robot should not pass through region r5 if it senses a person (2). Additionally, the robot should always activate its camera (3).\nSpecification 1 Unrealizable specification \u2013 livelock 1) Robot starts in start with camera\n(\u03c0start \u2227\u03c0camera, part of \u03d5 is)) 2) If you are sensing a person then do not r5\n( (\u00a9\u03c0person\u21d2\u00ac\u00a9\u03c0r5), part of \u03d5ts) 3) Always activate the camera ( \u00a9\u03c0camera, part of \u03d5ts) 4) Visit the goal ( \u03c0goal , part of \u03d5 g s )\nIt is clear that the environment can prevent the goal in (4) by always activating the \u201cperson\u201d sensor (\u03c0person), because of the initial condition in (1) and the safety requirement in (2). Note that Specification 1 is a case of livelock: the robot can satisfy the safety requirement indefinitely by moving between the first four rooms on the left, but is prevented from ever reaching the goal if it sees a person all the time \u2013 the environment is able to disconnect the topology using the person sensor.\nPrevious work produced explanations of unsynthesizability in terms of combinations of the specification components (i.e., initial conditions, safeties and goals) [8]. However, in many cases, the true conflict lies in small subformulas of these components. For example, the safety requirement (3) in Specification 1 is irrelevant to its unsynthesizability, and should be excluded from any explanation of failure. The specification analysis algorithm presented in [8] will narrow down the cause of unsynthesizability to the goal in (4), but will also highlight the entirety of \u03d5 ts , declaring that the environment can prevent the goal because of some subset of the safeties (without identifying the exact subset).\nThis motivates the identification of small, minimal, \u201ccore\u201d explanations of the unsynthesizability. A first step is to define what is meant by an unsynthesizable core. This paper draws inspiration from the Boolean satisfiability (SAT) literature to define an unsynthesizable core of a GR(1) LTL formula. Given an unsatisfiable SAT formula in conjunctive normal form (CNF), an unsatisfiable core is traditionally defined as a subset of CNF clauses that is still unsatisfiable. A minimal unsatisfiable core is one such that every proper subset is satisfiable; a given SAT formula can have multiple minimal unsatisfiable cores of varying sizes. This definition should be distinguished from that of a minimum unsatisfiable core, which is one containing the smallest number of original clauses that are unsatisfiable in themselves. While there are several practical techniques for computing minimal unsatisfiable cores, and many modern SAT-solvers include this functionality, there are no known practical algorithms for computing minimum cores. This paper will therefore focus on leveraging existing tools for computing minimal unsatisfiable cores, to compute minimal unsynthesizable cores.\nLet \u03d51 \u03d52 (\u03d51 \u227a \u03d52) denote that \u03d51 is a subformula (strict subformula) of \u03d52.\nDefinition 2 Given a specification \u03d5 = \u03d5e \u21d2 \u03d5s, a minimal unsynthesizable core is a subformula \u03d5\u2217s \u03d5s such that \u03d5e \u21d2 \u03d5\u2217s is unsynthesizable, and for all \u03d5 \u2032s \u227a \u03d5\u2217s , \u03d5e \u21d2 \u03d5 \u2032s is synthesizable.\nProblem 1 Given an unsynthesizable formula \u03d5 , return a minimal unsynthesizable core \u03d5\u2217s \u03d5s."}, {"heading": "IV. RELATED WORK", "text": "Robotics researchers have recently considered the problem of revising specifications that cannot be satisfied by a given robot system [9, 11, 12] . The work in [9] addressed the problem of revising unsatisfiable LTL specifications. The author defines a partial order on LTL formulas, and defines the notion of a valid relaxation for an LTL specification, which\n4 informally corresponds to the set of formulas \u201cgreater than\u201d formulas in the specification according to this partial order. Formula relaxation for unreachable states is accomplished by recursively removing all positive occurrences of unreachable propositions. Specifications with logical inconsistencies are revised by augmenting the synchronous product of the robot and environment specifications with previously disallowed transitions as needed to achieve the goal state. In [11, 12], the authors present exact and approximate algorithms for finding minimal revisions of specification automata, by removing the minimum number of constraints from the unsatisfiable specification. They too encode the problem as an instance of Boolean satisfiability, and solve it using efficient SAT solvers. However, the work presented in this paper differs in its objective, which is to provide feedback on existing specifications, not rewrite them. Moreover, unlike the above approaches, this work deals with reactive specifications.\nAlthough explaining unachievable behaviors has only recently been studied in the context of robotics, there has been considerable prior work on unsatisfiability and unrealizability of LTL in the formal methods literature, and the problem of identifying small causes of failure has been studied from several perspectives. For unsatisfiable LTL formulas, the authors of [22] suggest a number of notions of unsatisfiable cores, tied to the corresponding method of extraction. These include definitions based on the syntactic structure of the formula parse tree, subsets of conjuncts in various conjunctive normal form translations of the formula, resolution proofs from bounded model-checking (BMC), and tableaux constructions. The authors of [23] employ a formal definition of causality to explain counterexamples provided by model-checkers on unsatisfiable LTL formulas; the advantage of this method is the flexibility of defining an appropriate causal model.\nThe technique of extracting an unsatisfiable core from a BMC resolution proof is one that is well-used in the Boolean satisfiability (SAT) and SAT Modulo Theories (SMT) (e.g., [24, 25]) literature. A similar technique was used in [26] for debugging declarative specifications. In that work, the abstract syntax tree (AST) of an inconsistent specification was translated to CNF, an unsatisfiable core was extracted from the CNF, and the result was mapped back to the relevant parts of the AST. The approach in [26] only generalizes to specification languages that are reducible to SAT, a set which does not include LTL; this paper presents a similar approach, using SAT solvers to identify unsatisfiable cores for LTL.\nThe authors of [27] also attempted to generalize the idea of unsatisfiable cores to the case of temporal logic using SAT-based bounded model checkers. Temporal atoms of the original LTL specification were associated with activation variables, which were then used to augment the formulas used by a SAT-based bounded model checker. The result, in the case of an unsatisfiable LTL formula, was a subset of the activation variables corresponding to the atoms that cannot be satisfied simultaneously. The approach presented here for unsatisfiability is very similar, in that the SAT formulas used to determine the core are exactly those that would be used for bounded model checking. However, a major difference is that this work does not use activation variables in order to\nidentify conjuncts in the core, but maintains a mapping from the original formula to clauses in the SAT instance.\nIn the context of unrealizability, the authors of [28] propose definitions for helpful assumptions and guarantees, and compute minimal explanations of unrealizability (i.e., unrealizable cores) by iteratively expelling unhelpful constraints. Their algorithm assumes an external realizability checker, which is treated as a black box, and performs iterated realizability tests. This work will draw on the same iterative realizability approach in Section VII. The authors in [29] use model-based diagnosis to remove not only guarantees but also irrelevant output signals from the specification. These output signals are those that can be set arbitrarily without affecting the unrealizability of the specification. Model-based diagnoses provide more information than a single unrealizable core, but requires the computation of many unrealizable cores. In [29], this is accomplished using techniques similar to those in [28], which in turn require many realizability checks. The main advantage of the work presented here is that it reduces the number of computationally expensive realizability checks required for most specifications, as detailed in Sections V and VI.\nTo identify and eliminate the source of unrealizability, some works like [10, 30] provide a minimal set of additional environment assumptions that, if added, would make the specification realizable; this is accomplished in [30] using efficient analysis of turn-based probabilistic games, and in [10] by mining the environment counterstrategy. On the other hand, the work presented in this paper takes the environment assumptions as fixed, and the goal is to compute a minimal subset of the robot guarantees that is unrealizable. Seen from another perspective, this work presumes that the assumptions accurately capture the specification designer\u2019s understanding of the robot\u2019s environment, and provides the source of failure in the specified guarantees."}, {"heading": "V. UNSATISFIABLE CORES VIA SAT", "text": "This section describes how unsatisfiable components of the robot specification \u03d5s are further analyzed to narrow the cause of unsatisfiability, for both deadlock and livelock, using Boolean satisfiability testing. Extending these techniques to the environment assumptions \u03d5e is straightforward.\nThe Boolean satisfiability problem or SAT is the problem of determining whether there exists a truth assignment to a set of propositions that satisfies a given Boolean formula. A Boolean formula in Conjunctive Normal Form (CNF) is one that has been rewritten as a conjunction of clauses, each of which is a disjunctions of literals, where a literal is a Boolean proposition or its negation. For a Boolean formula in CNF, an unsatisfiable core is defined as a subset of CNF clauses whose conjunction is still unsatisfiable; a minimal unsatisfiable core is one such that removing any clause results in a satisfiable formula."}, {"heading": "A. Unsatisfiable Cores for Deadlock", "text": "Given a depth d and an LTL safety formula \u03d5 over propositions \u03c0 \u2208 AP, the propositional formula \u03c8d is constructed over\n5 lounge hall_W ha ll_ C h a ll_ Nr4 r3 r2r1 r6 r5 kitchenc\nFig. 2: Map of hospital workspace (\u201cc\u201d is the closet)\n\u22c3 0\u2264i\u2264d+1 AP\ni, where \u03c0 i \u2208 APi represents the value of \u03c0 \u2208 AP at time step i, as:\n\u03c8d(\u03d5) = \u2227\n0\u2264i\u2264d \u03d5[\u00a9\u03c0/\u03c0 i+1][\u03c0/\u03c0 i],\nwhere \u03d5[a/b] represents \u03d5 with all occurrences of subformula a replaced with b. This formula is called the depth-d unrolling of \u03d5 . Consider Specification 2. \u03c80(\u03d5 ts) = \u00ac\u03c00kitchen \u2227 \u03c01camera and \u03c81(\u03d5 ts) = \u00ac\u03c00kitchen \u2227 \u03c01camera \u2227\u00ac\u03c01kitchen \u2227 \u03c02camera, where \u03c0 ikitchen is a propositional variable representing the value of \u03c0kitchen at time step i. Given the depth-d unrolling \u03c8d(\u03d5 ts) of the robot safety formula, define \u03c8df romInit =\u03d5 i s[\u03c0/\u03c00]\u2227\u03c8d(\u03d5 ts).\nIn the case of deadlock, which can be identified as in [7, 8], a series of Boolean formulas {\u03c8df romInit} is produced by incrementally unrolling the robot safety formula \u03d5 ts , and the satisfiability of \u03c8df romInit is checked at each depth. To perform this check, the formula \u03c8df romInit is first converted into CNF, so that it can be provided as input to an off-the-shelf SAT-solver; this work uses PicoSAT [31]. Converting a Boolean formula to CNF form can, in the worst case, cause an exponential increase in the size of the formula. However, since \u03c8df romInit consists of conjunctions of simple Boolean formulas, the resulting CNFs are small in practice. If \u03c8df romInit is found unsatisfiable, there is no valid sequence of actions that follow the robot safety condition for d time steps starting from the initial condition. In this case, the SAT solver returns a minimal unsatisfiable subformula, in the form of a subset of the CNF clauses.\nWhen translating the Boolean formula \u03c8df romInit to CNF, a mapping is maintained between the portions of the the original specification, and the clauses they generate. This enables the CNF minimal unsatisfiable core to be traced back to the corresponding safety conjuncts and initial conditions in the specification.\nSpecification 2 Core-finding example \u2013 unsatisfiable deadlock 1) Start in the kitchen (\u03d5 is):\n\u03c0kitchen 2) Avoid the kitchen (\u03d5 is, \u03d5ts): \u00ac\u03c0kitchen\u2227 \u00ac\u03c0kitchen 3) Always activate your camera (\u03d5ts): \u00a9\u03c0camera\nSpecification 2 is a deadlocked specification, referring to a robot operating in the workspace depicted in Fig. 2. The described method begins at the initial state described by \u03d5 is (lines 1 and 2), and unrolls it to \u03c80f romInit = \u03c0 0 kitchen \u2227 \u00ac\u03c00kitchen \u2227 \u00ac\u03c00kitchen \u2227 \u03c01camera above. Note that \u03c80f romInit is\nalready unsatisfiable, and the core is given by the subformula \u03c00kitchen\u2227\u00ac\u03c00kitchen, which in turn maps back to lines 1 and 2. This is because the two statements combined require the robot to both start in the kitchen and not start in the kitchen. Section VIII contains another example demonstrating unsatisfiable core-finding for deadlock."}, {"heading": "B. Unsatisfiable Cores for Livelock", "text": "In the case of livelock, a similar unrolling procedure can be applied to determine the core set of clauses that prevent a goal from being fulfilled. A propositional formula is generated by unrolling the robot safety from the initial state for a predetermined number of time steps, with an additional clause \u03d5dgoal representing the unsatisfied liveness condition being required to hold at the final time step for that depth. Consider the livelocked Specification 3.\nSpecification 3 Core-finding example \u2013 unsatisfiable livelock 1) Start in the kitchen (\u03d5 is):\n\u03c0kitchen 2) Avoid hall w (\u03d5 is, \u03d5ts): \u00ac\u03c0hall w\u2227 \u00ac\u03c0hall w 3) Always activate your camera (\u03d5ts): \u00a9\u03c0camera 4) Patrol r3 (\u03d5gs ): \u03c0r3\nUnrolling the robot safety to depth d, with the added clause \u03d5dgoal = \u03c0 d r3 for liveness at depth d, results in:\n\u03c8df romInit \u2227\u03d5dgoal = \u03c00kitchen\u2227 \u2227\n0\u2264i\u2264d \u00ac\u03c0 ihall w\n\u2227 \u2227\n1\u2264i\u2264d+1 \u03c0 icamera\u2227 \u2227 0\u2264i\u2264d \u03d5 itopo\u2227\u03c0dr3\nwhere \u03d5 itopo represents the topology constraints on the robot unrolled at time i. \u03c8df romInit is unsatisfiable for any d \u2265 0."}, {"heading": "C. Unroll Depth", "text": "In the case of deadlock, the propositional formula \u03c8df romInit can be built for increasingly larger depths until it is found to be unsatisfiable for some d; by the definition of deadlock, there will always exist such a d. This gives us a sound and complete method for determining the depth to which the safety formula must be unrolled in order to identify an unsatisfiable core for deadlock. For livelock, on the other hand, determining the shortest depth that will produce a meaningful core is a much bigger challenge. Consider the above example. For unroll depths less than or equal to 3, the unsatisfiable core returned will include just the environment topology, since the robot cannot reach r3 from the kitchen in 3 steps or fewer, even if it is allowed into hall w; however, this is not a meaningful core.\nFor d \u2265 3 the core is given by the subformula: \u03c00kitchen\u2227 \u2227\n0\u2264i\u2264d \u00ac\u03c0 ihall w\u2227\u03c0dr3\u2227 \u2227 0\u2264i\u2264d \u03d5 itopo,\nwhich maps back to specification sentences (1), (2) and (4) in Specification 3. This is because the robot cannot reach r3\n6 without passing through hall w. Section VIII contains another example demonstrating unsatisfiable core-finding for livelock.\nThe depth required to produce a meaningful core for unsatisfiability is bounded above by the number of distinct states that the robot can be in, i.e. the number of possible truth assignments to all the input and output propositions. However, efficiently determining the shortest depth that will produce a meaningful core remains a future research challenge, and for the purpose of this work, a fixed depth of 15 time steps was used for the examples presented, unless otherwise indicated.\nAlgorithm 1 summarizes the core-finding procedure described in this section. The module SAT_SOLVER takes as input a Boolean formula in CNF form and returns a minimal unsatisfiable core (MUS). MAP_BACK maps the returned CNF clauses to portions of the original specification; in LTLMoP, this mapping returns sentences in structured English or natural language.\nAlgorithm 1 Unsatisfiable Cores via SAT solving 1: function UNSAT_BMC(\u03d5,max depth, reason) 2: MUS \u2190 /0 3: if reason==deadlock then 4: for d := 1 to max depth do 5: MUS \u2190 SAT_SOLVER(\u03c8df romInit ) 6: if MUS 6= /0 then return MAP_BACK(MUS) 7: else 8: MUS \u2190 SAT_SOLVER(\u03c8max depthf romInit \u2227\u03d5 max depth goal )\nreturn MAP_BACK(MUS)\nD. Interactive Exploration of Unrealizable Tasks\nIf the specification is unrealizable rather than unsatisfiable, the above techniques do not apply directly to identify a core. This is because if the specification is satisfiable but unrealizable, there exist sequences of truth assignments to the input variables that allow the system requirements to be met. Therefore, in order to produce an unsatisfiable Boolean formula, all sequences of truth assignments to the input variables that satisfy the environment assumptions must be considered. This requires one depth-d Boolean unrolling for each possible length-d sequence of inputs, where each unrolling encodes a distinct sequence of inputs in the unrolled Boolean formula. In the worst case, the number of depth-d Boolean formulas that must be generated before an unsatisfiable formula is found grows exponentially in d.\nHowever, unsatisfiable cores do enable a useful enhancement to an interactive visualization of the environment counterstrategy. Since succinctly summarizing the cause of an unrealizable specification is often challenging even for humans, one approach to communicating this cause in a user-friendly manner is through an interactive game (shown in Fig. 3). The tool illustrates environment behaviors that will cause the robot to fail, by letting the user play as the robot against an adversarial environment. At each discrete time step, the user is presented with the current goal to pursue and the current state of the environment. They are then able to respond by changing the location of the robot and the status of its actuators. Examples of this tool in action are given in [7, 8].\n}Game history\nkitchen\nExplanation of invalid move\nCurrent goal\nEnvironment state\nFig. 3: Screenshot of interactive visualization tool for Specification 4. The user is prevented from following the target into the kitchen in the next step (denoted by the blacked out region) due to the portion of the specification displayed.\nAn initial version of this tool simply prevented the user from making moves that were disallowed by the specification. However, by using the above core-finding technique, a specific explanation can be given about the part of the original specification that would be violated by the attempted invalid move. This is achieved by finding the unsatisfiable core of a singlestep satisfiability problem constructed over the user\u2019s current state, the desired next state, and all of the robot\u2019s specified safety conditions.\nConsider Specification 4, which first appeared in [14]. The robot is instructed to follow a human partner (Line 1) through the workspace depicted in 2. This means that the robot should always eventually be in any room that the human visits. Additionally, the robot has been banned from entering the kitchen in Line 2. We discover that the robot cannot achieve its goal of following the human if the human enters the kitchen. This conflict is presented to the user as depicted in Fig. 3: the environment sets its state to represent the target\u2019s being in the kitchen, and then, when the user attempts to enter the kitchen, the tool explains that this move is in conflict with Line 2.\nSpecification 4 Example of unrealizability 1) Follow me. 2) Avoid the kitchen."}, {"heading": "VI. UNREALIZABLE CORES VIA SAT", "text": "As described in Section V-D, the extension of the SAT-based core-finding techniques described in Section V to unrealizable specifications requires examining the exact environment input sequences that cause the failure. Considering all possible environment input sequences is not feasible; fortunately, the environment counterstrategy sometimes provides us with exactly those input sequences that cause unsynthesizability.\nConsider a counterstrategy Ae\u03d5 = (Q,Q0,X ,Y,\u03b4e,\u03b4s,\u03b3X ,\u03b3Y ,\u03b3goals) for formula \u03d5 . It allows the following characterizations of deadlock and livelock: \u2022 Deadlock There exists a state in the counterstrategy such\nthat there is a truth assignments to inputs, for which no\n7 truth assignment to outputs satisfies the robot transition relation. Formally,\n\u2203q \u2208 Q s.t. \u03b4s(q,\u03b4e(q)) = /0\n\u2022 Livelock There exist a set of states C in the counterstrategy such that the robot is trapped in C no matter what it does, and there is some robot liveness Bk in \u03d5 g s that is\nnot satisfied by any state in C. Formally,\n\u2203C \u2286 Q,Bk \u03d5gs s.t. \u2200q \u2208 C,q 6|= Bk,\u03b4s(q,\u03b4e(q))\u2286 C\nHere \u201cq 6|= Bk\u201d indicates that the truth assignment given by \u03b3X (q)\u222a \u03b3Y(q) does not satisfy the propositional formula Bk. Note that there is always such a set of states in the counterstrategy in the case of livelock."}, {"heading": "A. Unrealizable Cores for Deadlock", "text": "Consider Specification 5 on the workspace in Fig. 1. The robot starts in r5 with the camera on (1). The safety conditions specify that the robot should not pass through the region marked r5 if it senses a person (2). In addition, the robot must stay in place if it senses a person (3). Finally, the robot should always activate its camera (4). Here, the environment can force the robot into deadlock by activating the \u201cperson\u201d sensor (\u03c0person) when the robot is in r5, because there is then no way the robot can fulfil both (2) and (3).\nSpecification 5 Core-finding example \u2013 deadlock 1) Robot starts in r5 with camera (\u03d5 is):\n\u03c0r5\u2227\u03c0camera 2) If you are sensing person then do not r5 (\u03d5ts): (\u00a9\u03c0person\u21d2\u00ac\u00a9\u03c0r5) 3) If you are sensing person then stay there (\u03d5ts): (\u00a9\u03c0person\u21d2 (\u00a9\u03c0start \u21d4 \u03c0start \u2227\u00a9\u03c0r2\u21d4 \u03c0r2...)) 4) Always activate your camera (\u03d5ts):\n\u00a9\u03c0camera\nThe environment counterstrategy Ae\u03d5 is as follows: \u2022 Q = Q0 = {q1} \u2022 X = {\u03c0person}, Y = {\u03c0r5,\u03c0camera} \u2022 \u03b4e(q1) = {\u03c0person}, \u03b4s(q1,{\u03c0person}) = /0, \u03b4s(q1, /0) = /0 \u2022 \u03b3X (q1) = {\u03c0person}, \u03b3Y(q1) = {\u03c0r5,\u03c0camera} \u2022 \u03b3goals(q1) = 1 The state q1 is deadlocked, because given the input \u03c0person in the next time step, there is a conflict between safety conditions 2 and 3, and the robot has no valid move (so \u03b4s(q1,{\u03c0person}) = /0). Note that \u03b4s(q1, /0) = /0 indicates that the environment strategy does not include any transition out of q1 where the environment does not activate the \u201cperson\u201d sensor.\nFor q \u2208 Q, the propositional-representation of q is defined as:\n\u03c8state(q) = \u2227\nx\u2208\u03b3X (q) x\u2227 \u2227 x\u2208X\\\u03b3X (q) \u00acx\u2227 \u2227 y\u2208\u03b3Y (q) y\u2227 \u2227 y\u2208Y\\\u03b3Y (q) \u00acy\nIn the example above, \u03c8state(q1) = \u03c0person\u2227\u03c0r5\u2227\u03c0camera. As before, let \u03c0 i represent the value of \u03c0 \u2208 AP at time step i, and APi = {\u03c0 i | \u03c0 \u2208 AP}. For example, in Specification 5, AP0 = {\u03c00person,\u03c00r5,\u03c00camera} and AP1 = {\u03c01person,\u03c01r5,\u03c01camera}.\nGiven LTL specification \u03d5 , q\u2208Q such that \u03b4s(q,\u03b4e(q)) = /0, construct a propositional formula over AP0\u222aAP1 as follows:\n\u03c8dead(q,\u03d5) = \u03c8state(q)[\u03c0/\u03c00]\u2227 \u2227\nz\u2208\u03b4e(q) z1\u2227 \u2227 z\u2208X\\\u03b4e(q) \u00acz1\n\u2227\u03d5 ts[\u00a9\u03c0/\u03c01][\u03c0/\u03c00], Intuitively, this formula represents the satisfaction of the robot safety condition in the next step from state q, with the additional restriction that the input variables be bound to the values provided by \u03b4e(q) in the next time step.\nIn the above case, \u03c8dead(q1,\u03d5) = \u03c00person\u2227\u03c00r5\u2227\u03c00camera\u2227\u03c01person\u2227\u03c01camera\u2227\u03d50topo \u2227(\u03c01person\u21d2\u00ac\u03c01r5)\u2227 (\u03c01person\u21d2 (\u03c01r5\u21d4 \u03c00r5\u2227 ...)),\nwhere \u03d5 itopo is a formula over APi \u222aAPi+1 representing the topological constraints on the robot motion at time i (i.e. which rooms it can move to at time i+1 given where it is at time i, and mutual exclusion between rooms).\nNote that if q is a deadlocked state, then by definition \u03c8dead(q,\u03d5) is unsatisfiable, since there is no valid setting to the robot propositions in the next time step starting from q. A SAT solver can now be used to find a minimal unsatisfiable subformula, as in Section V.\nIn the above example, the SAT solver finds the core of \u03c8dead(q,\u03d5) as the subformula\n\u03c00r5\u2227\u03c01person\u2227 (\u03c01person\u21d2\u00ac\u03c01r5)\u2227 (\u03c01person\u21d2 (\u03c01r5\u21d4 \u03c00r5)). This is because the two statements combined require the robot to both stay in r5 and not be in r5 in time step 1. This gives us a core explanation of the deadlock caused in state q. Taking the union over the cores for all the deadlocked states provides a concise explanation of how the environment can force the robot into a (not necessarily unique) deadlock situation. Section VIII contains another, more complex example demonstrating unrealizable core-finding for deadlocked specifications."}, {"heading": "B. Unrealizable Cores for Livelock", "text": "Consider Specification 1 again. If the environment action is to always set \u03c0person, then the safety requirement in 2 enforces that the robot will never activate \u03c0r5, because it is explicitly forbidden from doing so when sensing a person. This is livelock because the robot can continue to move between start and r2\u2212 r4. The environment counterstrategy Ae\u03d5 is as follows: \u2022 Q = {q1,q2,q3,q4}, Q0 = {q1} \u2022 X = {\u03c0person},Y = {\u03c0start ,\u03c0r2,\u03c0r3, ...,\u03c0r8,\u03c0goal ,\u03c0camera} \u2022 \u2200q \u2208 Q,\u03b4e(q) = {\u03c0person} \u2022\n\u03b4s(qi,{\u03c0person}) =  {q1,q2} if i = 1{qi\u22121,qi,qi+1} for 2\u2264 i\u2264 3{q3,q4} if i = 4 Additionally, \u03b4s(q, /0) = /0 for all q.\n\u2022 \u2200q \u2208 Q,\u03b3X (q) = {\u03c0person}. \u2022 \u03b3Y(qi) = { {\u03c0camera,\u03c0start} if i = 1 {\u03c0camera,\u03c0ri} for 2\u2264 i\u2264 4 \u2022 \u2200i,\u03b3goals(qi) = 1 (since there is only one goal).\n8 1) Countertraces: One of the main sources of complexity in analyzing an environment counterstrategy is that it might depend on the behavior of the system. However, sometimes it is possible to extract a single trace of inputs such that no output trace fulfil the specification. Following [21], we call such a trace a countertrace. A countertrace does not always exist, but it does simplify our analysis. Computing countertraces is expensive [21], but it is possible to identify whether a given counterstrategy is a countertrace by checking that all paths from an initial state follow the same sequence of environment inputs. For the analysis that follows, we assume that the counterstrategy is a countertrace. We will later discuss how to analyze counterstrategies that are not traces. Note that counterstrategy Ae\u03d5 for Specification 1 above is a countertrace.\nIn the case of livelock, we know there exists a set of states C in the counterstrategy that trap the robot, locking it away from the goal. Without loss of generality, C consists of (possibly overlapping) cycles of states. In the specifications of the form considered in this work, robot goals are of the form Bi for 1\u2264 i\u2264 n, where each Bi is a propositional formula over AP = X \u222aY . Suppose the algorithm in [8] identified goal Bk as the goal responsible for livelock. Let Qk be the set of all states in Ae\u03d5 that prevent goal Bk, and let Ck be the set of maximal k-preventing cycles in Qk, i.e. cycles that are not contained in any other cycle in Qk (modulo state-repetition). Let C1 = (q10,q 1 1, ...,q 1 a) and C2 = (q 2 0,q 2 1, ...,q 2 b) be cycles, and define C1 \u227a C2 if a < b and there is some offset index o in C2 such that all of C1 is found in C2 starting at o, i.e. q1i = q2(i+o) mod (b+1) for all 0 \u2264 i \u2264 a. This expresses that C1 is a strict sub-cycle of C2. Formally,\nQk = {q \u2208 Q|\u03b3goals(q) = k}\nCallk = {(q0,q1, ...,ql)|\u22000\u2264 i\u2264 l,qi \u2208 Qk, \u2200i < l,qi+1 \u2208 \u03b4s(qi,\u03b4e(qi)),qi 6= qi+1, q0 \u2208 \u03b4s(ql ,\u03b4e(ql)),q0 6= ql},\nCk = {C \u2208Callk |\u2200C\u2032 \u2208Callk ,C 6\u227aC\u2032}.\nIn Specification 1, there is only one goal, \u03c0goal . C1 = (q1,q2,q3,q4,q3,q2) is a maximal 1-preventing cycle.\nGiven an initial state q, a depth d and an LTL safety formula \u03d5 ts over \u03c0 \u2208 AP, we construct a propositional formula \u03c8d(\u03d5 ts,q) over \u22c3 0\u2264i\u2264d+1 AP i as:\n\u03c8d(\u03d5 ts,q) = \u03c8state(q)[\u03c0/\u03c0 0]\u2227 \u2227 0\u2264i\u2264d \u03d5 ts[\u00a9\u03c0/\u03c0 i+1][\u03c0/\u03c0 i].\nThis formula is called the depth-d unrolling of \u03d5 ts from q, and represents the tree of length-d + 1 truth assignment sequences that satisfy \u03d5 ts , starting from q. Note that a depthd unrolling governs d + 1 time steps, because each conjunct in \u03d5 ts governs the current as well as next time steps. In the example, \u03c8d(\u03d5 ts,q1) =\n\u03c00start \u2227\u03c00camera\u2227 \u2227\n0\u2264i\u2264d (\u03d5 itopo\u2227\u03c0 i+1camera\u2227 (\u03c0 i+1person\u21d2\u00ac\u03c0 i+1r5 )).\nGiven a cycle of states C = (q0,q1, ...,ql)\u2208 Ae\u03d5 , and a depth d, construct a propositional formula \u03c8dX (C) over \u22c3 0\u2264i\u2264dX i,\nwhere xi \u2208X i represents the value of each input x\u2208X in state qi mod (l+1) for 0\u2264 i\u2264 d, as:\n\u03c8dX (C) = \u2227\n0\u2264i\u2264d ( \u2227 p\u2208\u03b3X (qi mod (l+1)) xi\u2227 \u2227 p\u2208X\\\u03b3X (qi mod (l+1)) \u00acxi).\nThis formula is called the depth-d environment-unrolling of C, and represents the sequence of inputs seen when following cycle C for d time-steps. In the example, the depth-d environment unrolling of C1 is \u03c8dX (C) = \u2227 0\u2264i\u2264d \u03c0 iperson.\nNow, given an LTL safety specification \u03d5 ts over \u03c0 \u2208 AP, a goal Bk, a maximal k-preventing cycle Ck = (q0,q1, ...,ql) \u2208 Ck, and an unrolling depth d, construct propositional formula \u03c8dlive(Bk,Ck,\u03d5 t s) over \u22c3 0\u2264i\u2264d+1 AP i as:\n\u03c8dlive(Bk,Ck,\u03d5 t s) =\n\u03c8d+1X (Ck)\u2227\u03c8d(\u03d5 ts,q0)\u2227Bk[\u03c0/\u03c0d ].\nIntuitively, this formula expresses the requirement that the goal Bk be fulfilled after some depth-d unrolling of the safety formula starting from state q0, given the input sequence provided by \u03c8d+1X (Ck) (note that this input sequence extends to the final time step in the safety formula unrolling). This is an unsatisfiable propositional formula, and can be used to determine the core set of clauses that prevent a goal from being fulfilled. Taking the union of cores over all Ck \u2208 Ck gives a concise explanation of the ways in which the environment can prevent the robot from fulfilling the goal. This step makes use of the fact that the counterstrategy is a countertrace, since otherwise the reason for unrealizability might involve an interplay between two input sequences.\nIn the above example, \u03c8dlive(\u03c0goal ,C1,\u03d5 t s) =\n\u03c00start \u2227\u03c00camera\u2227 \u2227\n0\u2264i\u2264d+1 \u03c0 iperson\n\u2227 \u2227\n0\u2264i\u2264d (\u03d5 itopo\u2227\u03c0 i+1camera\u2227 (\u03c0 i+1person\u21d2\u00ac\u03c0 i+1r5 ))\n\u2227\u03c0dgoal .\nIn the case of livelock, the choice of unroll depth d determines the quality of the core returned. Recall that for deadlock, the propositional formula \u03c8dead(q,\u03d5) is built over just one step, since it is already known to cause a conflict with the robot transition relation, and be unsatisfiable. The unsatisfiable core of this formula is a meaningful unrealizable core in this case because it provides the immediate reason for the deadlock. For livelock, on the other hand, determining the shortest depth to which a cycle Ck must be unrolled to produce a meaningful core is not obvious.\nIn the above example, for unroll depths less than or equal to 8, the unsatisfiable core returned will include just the environment topology, since the robot cannot reach the goal from the start in 8 steps or fewer, even if it is allowed into r5; however, this is not a meaningful core. Unrolling to depth 9 or greater returns the expected subformula that includes \u2227 0\u2264i\u2264d(\u03c0 i+1person\u21d2\u00ac\u03c0 i+1r5 ). Automatically determining the shortest depth that will produce a meaningful core remains a research challenge, but a good heuristic is to use the maximum distance between two states in the environment counterstrategy (i.e. the diameter of the graph representing the\n9 counterstrategy, or the sum of the diameters of its connected components).\n2) General Counterstrategies: It may be tempting to try and use a similar approach to find unrealizable cores from counterstrategies that are not countertraces. However, since the input sequences can now depend on the system behavior, it becomes necessary to encode all possible paths through the counterstrategy. Even so, since the counterstrategy only contains paths that are valid for the system specification, we found that the returned core often contained these added constraints on the system instead of the original specification. Instead, we used the approach described in Section VII to extract a minimal core in the case of livelock, when the counterstrategy was not a countertrace.\nAlgorithm 2 Unrealizable Cores via SAT solving 1: function UNREAL_BMC(\u03d5 , reason) 2: MUS \u2190 /0 3: Ae\u03d5 = (Q,Q0, ...,)\u2190 COUNTERSTRATEGY(\u03d5) 4: if reason==deadlock then 5: for q \u2208 Q such that \u03b4s(q,\u03b4e(q)) = /0 do 6: MUS \u2190 MUS \u222a SAT_SOLVER(\u03c8dead(q,\u03d5)) 7: else 8: k\u2190 livelocked goal 9: if IS_COUNTERTRACE(Ae\u03d5 , k) then 10: Callk \u2190 FIND_PREVENTING_CYCLES(A e \u03d5 , k) 11: for Ck \u2208 {C \u2208Callk |\u2200C \u2032 \u2208Callk ,C 6\u227aC\n\u2032} do 12: MUS\u2190MUS \u222a SAT_SOLVER(\u03c8dlive(Bk,Ck,\u03d5 t s)) 13: else 14: \u03d5badInits \u2190 CHOOSE_ONE(Q0) 15: MUS \u2190 UNREAL_ITERATE(\u03d5,\u03d5badInits ,k)\nreturn MAP_BACK(MUS)\nAlgorithm 2 summarizes the core-finding procedure described in this section. The module IS_COUNTERTRACE checks that all paths form a single initial state in the counterstrategy follow the same sequence of inputs. FIND_PREVENTING_CYCLES finds cycles in Ae\u03d5 that prevent goal k. UNREAL_ITERATE is described in Section VII.\nNote that, since unsatisfiability is a special case of unrealizability (in which not just some, but any environment can prevent the robot from fulfilling its specification), the above analysis also applies to unsatisfiable specifications. Moreover, a countertrace can always be extracted for an unsatisfiable specification, and so the approach in Section VI-B1 applies for livelock. However, the analysis presented in Section V is more efficient for unsatisfiability, as it does not require explicit-state extraction of the environment counterstrategy."}, {"heading": "VII. UNSYNTHESIZABLE CORES VIA ITERATED SYNTHESIS", "text": "As discussed in Sections V and VI, the SAT-based approach to identifying an unsynthesizable core for the case of livelock presents the challenge of determining a depth to which the LTL formula must be instantiated with propositions. This minimal depth is often tied to the number of regions in the robot workspace, and is usually easy to estimate. However, no efficient, sound method is known for determining this minimal unrolling depth. In addition, if the counterstrategy is\nnot a countertrace, the techniques in Section VI do not readily apply to extracting an unrealizable core. In both these cases, the SAT-based analysis described in Section VI may return a core that does not capture the real cause of failure, causing confusion when presented to the user. Fortunately, alternative, more computationally expensive techniques can be used to return a minimal core in these cases.\nThis section presents one such alternative approach to determining the minimal subset of the robot safety conjuncts that conflicts with a specified goal. The approach is based on iterated realizability checks, removing conjuncts from the safety formula and testing realizability of the remaining specification. While this approach is guaranteed to yield a minimal unsynthesizable core, it requires repeated calls to a realizability oracle, which may be expensive for specifications with a large number of conjuncts.\nRecall from Section II the syntactic form of the LTL specifications considered in this work. In particular, the formula \u03d5gs is a conjunction \u2227ngs j=1 B j, where each B j is a Boolean formula over AP, and represents an event that should occur infinitely often when the robot controller is executed. Similarly, \u03d5 ts represents the robot safety constraints; it is a conjunction \u2227nts i=1 Ai where each Ai is a Boolean formula over AP and \u00a9AP. In the case of livelock, the initial specification analysis presented in [8] provides a specific liveness condition Bk that causes the unsynthesizability (i.e. either unsatisfiability or unrealizability), and can also identify one of the initial states \u03d5badInits from which the robot cannot fulfil Bk. However, the specific conjuncts of the safety formula \u03d5 ts that prevent this liveness are not identified. The key idea behind using realizability tests to determine an unrealizable or unsatisfiable core of safety formulas is as follows. If on removing a safety conjunct from the robot formula, the specification remains unsynthesizable, then there exists an unsynthesizable core that does not include that conjunct (since the remaining conjuncts are sufficient for unsynthesizability). Therefore, in order to identify an unsynthesizable core, it is sufficient to iterate through the conjuncts of \u03d5 ts , removing safety conditions one at a time and checking for realizability.\nAlgorithm 3 presents the formal procedure for performing these iterated tests, given the index k of the liveness condition that causes the unsynthesizability. Denote by \u03d5s[S,\u03d5badInits ,k]\u2286 \u03d5s the formula \u03d5badInits \u2227 \u2227 i\u2208S Ai\u2227 Bk for indices in a set S. Let Si denote set S at iteration i. Set S1 is initialized to the indices of all safety conjuncts, i.e. S1 = {1, ...,nts} in line 2. In each iteration of the loop in lines 3- 7, the next conjunct Ai is omitted from the robot transition relation, and realizability of \u03d5e\u21d2 \u03d5s[Si\\{i},\u03d5badInits ,k] is checked (line 4). If removing conjunct i causes an otherwise unsynthesizable specification to become synthesizable, it is retained for the next iteration (line 5); otherwise it is permanently deleted from the set of conjuncts Si (line 6-7). After iterating through all the conjuncts in {1, ...,nts}, the final set Snts+1 determines a minimal unsynthesizable core of \u03d5e\u21d2\u03d5s that prevents liveness k. Note that the core is non-unique, and depends both on the order of iteration on the safety conjuncts, and on the initial\n10\nstate \u03d5badInits returned by the synthesis algorithm.\nTheorem VII.1 Algorithm 3 yields a minimal unsynthesizable core of \u03d5e\u21d2 \u03d5s.\nProof: Each iteration i of the loop in Algorithm 3, lines 3-7, maintains the invariant that \u03d5e \u21d2 \u03d5s[Si,\u03d5badInits ,k] is unsynthesizable; thus, \u03d5e \u21d2 \u03d5s[Snts+1,\u03d5 badInit s ,k] is unsynthesizable when the loop is exited. Moreover, removing any of the safety conjuncts in Snts+1 yields a synthesizable specification. To see this, assume for a contradiction that there exists j \u2208 Snts+1 such that \u03d5e \u21d2 \u03d5s[Snts+1\\{ j},\u03d5 badInit s ,k] is unsynthesizable. Clearly, Snts+1 \u2286 S j, so by definition of , \u03d5s[Snts+1\\{ j},\u03d5 badInit s ,k] \u03d5s[S j\\{ j},\u03d5badInits ,k]. Therefore, if \u03d5e\u21d2\u03d5s[S j\\{ j},\u03d5badInits ,k] is synthesizable, then \u03d5e \u21d2 \u03d5s[Snts+1\\{ j},\u03d5 badInit s ,k] must be synthesizable, since any implementation that satisfies \u03d5s[S j\\{ j},\u03d5badInits ,k] also satisfies \u03d5s[Snts+1\\{ j},\u03d5 badInit s ,k] . Since j was not removed from S j on the jth iteration, \u03d5e \u21d2 \u03d5s[S j\\{ j},\u03d5badInits ,k] is synthesizable. It follows that \u03d5e \u21d2 \u03d5s[Snts+1\\{ j},\u03d5 badInit s ,k] must be synthesizable, a contradiction.\nAlgorithm 3 Unsynthesizable Cores via Iterated Realizability Testing\n1: function UNREAL ITERATE(\u03d5 = \u03d5e,\u21d2 \u03d5s,\u03d5badInits ,k) 2: S1 = {1,2, ...,nts} 3: for i := 1 to nts do 4: if (\u03d5e\u21d2 \u03d5s[Si\\{i},\u03d5badInits ,k]) is synthesizable then 5: Si+1\u2190 Si 6: else 7: Si+1\u2190 Si\\{i}\nreturn \u03d5s[Snts+1,\u03d5 badInit s ,k])\nNote that Algorithm 3 yields an unsynthesizable core for livelock, for both unsatisfiable and unrealizable specifications. It is sound and complete, because it will always yield a minimal set of safety conditions that prevent the relevant liveness. As compared with the methods presented in Sections V and VI, it circumvents the problem of determining the depth to which to instantiate the LTL safety formula in a propositional SAT instance. Moreover, if \u03d5s[S,\u03d5badInits ,k] is replaced with \u03d5badInits \u2227 \u2227 i\u2208S Ai\u2227 TRUE (i.e. the robot liveness condition is trivial), the algorithm also yields an unsynthesizable core in the case of deadlock."}, {"heading": "A. Computational Tradeoffs", "text": "There is a computational tradeoff involved in performing a synthesizability (i.e. realizability) check once for every conjunct in the safety formula, instead of once for the entire specification. Algorithm 3 checks synthesizability once in each iteration of the loop in lines 3-7. Using the efficient algorithm in [20], each realizability check takes time O((mn\u03a3)3), where \u03a3 is the size of the state space, i.e. \u03a3 = 2|X\u222aY|, and m,n are the number of environment and system liveness conditions, respectively. Therefore the complexity of Algorithm 3 is O((nts)(mn\u03a3)3). On the other hand, the complexity of the approach described in Section VI requires only one call to the\ncounterstrategy synthesis algorithm, but multiple calls to the SAT solver. The SAT solver is invoked with Boolean formulas in CNF form that are, in the worst case, exponential in the size of the original LTL conjuncts, although the conjunctive form of the original GR(1) specifications mitigates some of this blowup in practice. Additionally, iterated realizability tests do not require explicit extraction of the environment counterstrategy, as in the case of the SAT-based tests presented in Section VI. The relative appropriateness of the two methods (SAT-based vs. iterated realizability testing) for the case of deadlock will depend on the specific unsynthesizable formula.\nFor example, in Specification 4, the calls to SAT_SOLVER made as part of the approach in Algorithm 2 took <1ms each to complete on a 1.3 GHz Intel Core i5 processor with 8GB of RAM. On the other hand, for the same specification with line (2) replaced with Always do not r5 ( (\u00ac\u00a9\u03c0r5)), each call took approximately 60s. This was exceptional, and most of the calls to SAT_SOLVER for the examples in this paper (including those in section VIII) took <1ms each. On the other hand, each call to COUNTERSTRATEGY for the approach in Algorithm 3 took approximately 5ms for the example in Section VIII-B."}, {"heading": "VIII. EXAMPLES", "text": "This section presents examples of the cores identified for unsynthesizable specifications. The examples presented previously appeared in [7], and this section demonstrates the improvement of the proposed approach over the analysis presented in that work. These examples were run using the opensource LTLMoP toolbox [17], within which all the technical outcomes presented in this paper have been implemented."}, {"heading": "A. Deadlock", "text": "Consider the specification in Fig. 5, where the robot is operating in the workspace depicted in Fig. 4. The robot starts in the porch. The safety conditions govern what it should do when it senses a \u201cperson\u201d (stay with them and radio for help) or a \u201chazardous item\u201d (pick up the hazardous item and carry it to the porch). The robot should not visit the porch unless it is carrying a hazardous item. The robot\u2019s goals are to patrol all rooms in the workspace.\nThe environment can cause deadlock by setting the person sensor to true and the hazardous item sensor to false when the robot is in the porch. Note that sensing a hazardous item results in the robot activating the \u201cpick up\u201d action, which in turn results in the proposition \u201ccarrying item\u201d being set. Similarly,\n11\nsensing a person results in the robot turning on the radio. Now the state in which both \u201cradio\u201d and \u201ccarrying item\u201d are true in the porch is a deadlocked state because of the safety conditions, \u201cIf you are activating radio or you were activating radio then stay there\u201d and \u201cIf you did not activate carrying item then always not porch\u201d, since there is no way to satisfy both from this state.\nFig. 5(a) depicts the sentences highlighted by the algorithm in [7]. A subset of sentences in the specification is identified by triangle-shaped markers in the left-hand margin, and the color-coding is based on whether they correspond to initial, safety or liveness conditions. The sentences highlighted in 5(a) include all initial (red) and safety (blue) conditions, which forms a very large subset of the original specification. On the other hand, Fig. 5(b) depicts the much smaller subset\nof guilty sentences returned by the analysis presented in Algorithm 2 (these sentences are all highlighted in red). The core sentences highlighted correspond to the safety conditions that cause deadlock \u2013 in this example, removing any one of these sentences results in a synthesizable specification."}, {"heading": "B. Livelock", "text": "Consider the specification in Fig. 6, also in the same workspace. The robot starts in the deck and its goal is to visit the porch. However, based on whether it senses a person or a fire, it has to keep out of the kitchen and the living room, respectively. Fig. 6(a) depicts the sentences highlighted by the algorithm in [7], which includes all safety conditions (red) in addition to the goal (green). This includes irrelevant sentences,\n12\nsuch as the one that requires the robot to always turn on the camera. Fig. 6(b) depicts the core returned by Algorithm 3 \u2013 only those safeties that directly contribute to keeping the robot out of the porch are returned."}, {"heading": "IX. CONCLUSIONS", "text": "This paper provides techniques for analyzing high-level robot specifications that are unsynthesizable, with the goal of providing a minimal explanation for why the robot specification is inconsistent, or how the environment can prevent the robot from fulfilling the desired guarantees. The causes of failure presented in this work take the form of unsynthesizable subsets of the original specification, or cores. A suite of SATbased techniques is presented for identifying unsatisfiable and unrealizable cores in the case of deadlock and most cases of livelock; iterated realizability checking is used to identify cores in cases where the SAT-based analysis fails. Examples show that the additional analysis provides improvements in terms of reducing the number of sentences in the original specification highlighted, and ignoring irrelevant subformulas.\nFuture work includes automatically determining the depth for obtaining a meaningful core in the case of livelock for the SAT-based approaches, and exploring SAT-based techniques that do not require explicit state extraction of the counterstrategy automaton. Another direction for future study is a systematic empirical comparison of SAT-based techniques with approaches based on iterated realizability testing, to evaluate scalability and relative computation time for practical examples."}], "references": [{"title": "A fully automated framework for control of linear systems from temporal logic specifications", "author": ["M. Kloetzer", "C. Belta"], "venue": "IEEE Transactions on Automatic Control, vol. 53, no. 1, pp. 287\u2013297, 2008.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Sampling-Based motion planning with deterministic \u03bc-calculus specifications", "author": ["S. Karaman", "E. Frazzoli"], "venue": "IEEE Conference on Decision and Control (CDC), 2009.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "Sampling- Based motion planning with temporal goals", "author": ["A. Bhatia", "L.E. Kavraki", "M.Y. Vardi"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), 2010, pp. 2689\u20132696.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Controlling wild bodies using linear temporal logic", "author": ["L. Bobadilla", "O. Sanchez", "J. Czarnowski", "K. Gossman", "S. LaValle"], "venue": "Robotics: Science and Systems (RSS), Los Angeles, CA, USA, June 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Temporal-Logic-Based reactive mission and motion planning", "author": ["H. Kress-Gazit", "G.E. Fainekos", "G.J. Pappas"], "venue": "IEEE Transactions on Robotics, vol. 25, no. 6, pp. 1370\u20131381, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Receding horizon control for temporal logic specifications", "author": ["T. Wongpiromsarn", "U. Topcu", "R.M. Murray"], "venue": "Hybrid Systems: Computation and Control (HSCC), 2010, pp. 101\u2013110.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Automated feedback for unachievable High-Level robot behaviors", "author": ["V. Raman", "H. Kress-Gazit"], "venue": "IEEE  International Conference on Robotics and Automation (ICRA), 2012, pp. 5156\u20135162.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Explaining impossible High-Level robot behaviors", "author": ["V. Raman", "H. Kress-Gazit"], "venue": "IEEE Transactions on Robotics, vol. PP, no. 99, pp. 1 \u201311, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Revising temporal logic specifications for motion planning", "author": ["G.E. Fainekos"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), 2011, pp. 40\u201345.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Mining assumptions for synthesis", "author": ["W. Li", "L. Dworkin", "S.A. Seshia"], "venue": "ACM-IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE), 2011, pp. 43\u201350.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "On the revision problem of specification automata", "author": ["K. Kim", "G.E. Fainekos", "S. Sankaranarayanan"], "venue": "IEEE International Conference on Robotics and Automation (ICRA), 2012, pp. 5171\u20135176.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Approximate solutions for the minimal revision problem of specification automata", "author": ["K. Kim", "G.E. Fainekos"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2012, pp. 265\u2013271.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Analyzing unsynthesizable specifications for high-level robot behavior using LTLMoP", "author": ["V. Raman", "H. Kress-Gazit"], "venue": "Computer Aided Verification (CAV), 2011, pp. 663\u2013668.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Sorry Dave, i\u2019m afraid i can\u2019t do that: Explaining unachievable robot tasks using natural language", "author": ["V. Raman", "C. Lignos", "C. Finucane", "K.C.T. Lee", "M.P. Marcus", "H. Kress-Gazit"], "venue": "Robotics: Science and Systems, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards minimal explanations of unsynthesizability for high-level robot behaviors", "author": ["V. Raman", "H. Kress-Gazit"], "venue": "IROS, 2013, pp. 757\u2013762.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "The temporal logic of programs", "author": ["A. Pnueli"], "venue": "Foundations of Computer Science (FOCS), 1977, pp. 46\u201357.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1977}, {"title": "LTLMoP: Experimenting with language, temporal logic and robot control", "author": ["C. Finucane", "G. Jing", "H. Kress-Gazit"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2010, pp. 1988 \u2013 1993.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Translating structured english to robot controllers", "author": ["H. Kress-Gazit", "G.E. Fainekos", "G.J. Pappas"], "venue": "Advanced Robotics, vol. 22, no. 12, pp. 1343\u20131359, 2008.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2008}, {"title": "Synthesis of Reactive(1) Designs", "author": ["N. Piterman", "A. Pnueli", "Y. Sa\u2019ar"], "venue": "Verification, Model Checking, and Abstract Interpretation (VMCAI). Springer, 2006, pp. 364\u2013380.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Debugging formal specifications using simple counterstrategies", "author": ["R. K\u00f6nighofer", "G. Hofferek", "R. Bloem"], "venue": "Formal Methods in Computer-Aided Design (FMCAD), 2009, pp. 152\u2013159.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Towards a notion of unsatisfiable cores for LTL", "author": ["V. Schuppan"], "venue": "Fundamentals of Software Engineering (FSEN), 2009, pp. 129\u2013145.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Explaining counterexamples using causality", "author": ["I. Beer", "S. Ben-David", "H. Chockler", "A. Orni", "R.J. Trefler"], "venue": "Formal Methods in System Design, vol. 40, no. 1, pp.  13 20\u201340, 2012.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Verification of proofs of unsatisfiability for CNF formulas", "author": ["E. Goldberg", "Y. Novikov"], "venue": "Design, Automation and Test in Europe Conference and Exhibition (DATE), 2003, pp. 886\u2013891.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2003}, {"title": "A simple and flexible way of computing small unsatisfiable cores in SAT modulo theories", "author": ["A. Cimatti", "A. Griggio", "R. Sebastiani"], "venue": "International Conference on Theory and Applications of Satisfiability Testing (SAT). Berlin, Heidelberg: Springer-Verlag, 2007, pp. 334\u2013339. [Online]. Available: http://dl.acm.org/citation. cfm?id=1768142.1768174", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "Debugging overconstrained declarative models using unsatisfiable cores", "author": ["I. Shlyakhter", "R. Seater", "D. Jackson", "M. Sridharan", "M. Taghdiri"], "venue": "IEEE International Conference on Automated Software Engineering (ASE), 2003, pp. 94\u2013105.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2003}, {"title": "Boolean abstraction for temporal logic satisfiability", "author": ["A. Cimatti", "M. Roveri", "V. Schuppan", "S. Tonetta"], "venue": "Computer Aided Verification (CAV), 2007, pp. 532\u2013546.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Diagnostic information for realizability", "author": ["A. Cimatti", "M. Roveri", "V. Schuppan", "A. Tchaltsev"], "venue": "Verification, Model Checking, and Abstract Interpretation (VMCAI), 2008, pp. 52\u201367.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Debugging unrealizable specifications with Model-Based diagnosis", "author": ["R. K\u00f6nighofer", "G. Hofferek", "R. Bloem"], "venue": "International Conference on Hardware and Software: Verification and Testing (HVC). Berlin, Heidelberg: Springer-Verlag, 2011, pp. 29\u201345. [Online]. Available: http://dl.acm.org/citation.cfm?id=1987082.1987090", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Environment assumptions for synthesis", "author": ["K. Chatterjee", "T.A. Henzinger", "B. Jobstmann"], "venue": "International Conference on Concurrency Theory (CONCUR). Berlin, Heidelberg: Springer- Verlag, 2008, pp. 147\u2013161. [Online]. Available: http://dx.doi.org/10.1007/978-3-540-85361-9 14", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}, {"title": "PicoSAT essentials", "author": ["A. Biere"], "venue": "Journal on Satisfiability (JSAT), vol. 4, no. 2-4, pp. 75\u201397, 2008.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 1, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 2, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 3, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 4, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 5, "context": ", [1\u20136]).", "startOffset": 2, "endOffset": 7}, {"referenceID": 4, "context": "There are several approaches in which correct-by-construction controllers are automatically synthesized from a description of the desired behavior and assumptions on the environment in which the robot operates [5, 6].", "startOffset": 210, "endOffset": 216}, {"referenceID": 5, "context": "There are several approaches in which correct-by-construction controllers are automatically synthesized from a description of the desired behavior and assumptions on the environment in which the robot operates [5, 6].", "startOffset": 210, "endOffset": 216}, {"referenceID": 6, "context": "This has motivated recent algorithms for explaining unsynthesizability of specifications [7, 8], revising specifications [9], and adding", "startOffset": 89, "endOffset": 95}, {"referenceID": 7, "context": "This has motivated recent algorithms for explaining unsynthesizability of specifications [7, 8], revising specifications [9], and adding", "startOffset": 89, "endOffset": 95}, {"referenceID": 8, "context": "This has motivated recent algorithms for explaining unsynthesizability of specifications [7, 8], revising specifications [9], and adding", "startOffset": 121, "endOffset": 124}, {"referenceID": 9, "context": "environment assumptions that would make the specification synthesizable [10].", "startOffset": 72, "endOffset": 76}, {"referenceID": 8, "context": "Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].", "startOffset": 115, "endOffset": 126}, {"referenceID": 10, "context": "Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].", "startOffset": 115, "endOffset": 126}, {"referenceID": 11, "context": "Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].", "startOffset": 115, "endOffset": 126}, {"referenceID": 12, "context": "Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].", "startOffset": 181, "endOffset": 185}, {"referenceID": 7, "context": "Feedback about the cause of unsynthesizability can be provided to the user in the form of a modified specification [9, 11, 12], a highlighted fragment of the original specification [13], or by allowing the user to interact with a simulated adversarial environment that prevents the robot from achieving the specified behavior [8].", "startOffset": 326, "endOffset": 329}, {"referenceID": 13, "context": "This paper subsumes the results presented in [14, 15], and extends the core-finding capabilities to previously unaddressed cases, as described in Section VII.", "startOffset": 45, "endOffset": 53}, {"referenceID": 14, "context": "This paper subsumes the results presented in [14, 15], and extends the core-finding capabilities to previously unaddressed cases, as described in Section VII.", "startOffset": 45, "endOffset": 53}, {"referenceID": 4, "context": "More details on the discrete abstraction used in this work can be found in [5].", "startOffset": 75, "endOffset": 78}, {"referenceID": 15, "context": "The formal language used for high-level specifications in this work is Linear Temporal Logic (LTL) [16], a modal logic that includes temporal operators, allowing formulas to specify the truth values of atomic propositions over time.", "startOffset": 99, "endOffset": 103}, {"referenceID": 16, "context": "To allow users who may be unfamiliar with LTL to define specifications, some tools like LTLMoP [17] include a parser that automatically translates English sentences belonging to a defined grammar [18] into LTL formulas, as well as some natural language capabilities, as described in [14].", "startOffset": 95, "endOffset": 99}, {"referenceID": 17, "context": "To allow users who may be unfamiliar with LTL to define specifications, some tools like LTLMoP [17] include a parser that automatically translates English sentences belonging to a defined grammar [18] into LTL formulas, as well as some natural language capabilities, as described in [14].", "startOffset": 196, "endOffset": 200}, {"referenceID": 13, "context": "To allow users who may be unfamiliar with LTL to define specifications, some tools like LTLMoP [17] include a parser that automatically translates English sentences belonging to a defined grammar [18] into LTL formulas, as well as some natural language capabilities, as described in [14].", "startOffset": 283, "endOffset": 287}, {"referenceID": 18, "context": "This fragment of LTL is called Generalized Reactivity (1) or GR(1) [20].", "startOffset": 67, "endOffset": 71}, {"referenceID": 18, "context": "The reader is referred to [20] and [5] for details of the synthesis procedure, and to [5, 17] for a description of how the extracted discrete automaton is transformed into low-level robot control.", "startOffset": 26, "endOffset": 30}, {"referenceID": 4, "context": "The reader is referred to [20] and [5] for details of the synthesis procedure, and to [5, 17] for a description of how the extracted discrete automaton is transformed into low-level robot control.", "startOffset": 35, "endOffset": 38}, {"referenceID": 4, "context": "The reader is referred to [20] and [5] for details of the synthesis procedure, and to [5, 17] for a description of how the extracted discrete automaton is transformed into low-level robot control.", "startOffset": 86, "endOffset": 93}, {"referenceID": 16, "context": "The reader is referred to [20] and [5] for details of the synthesis procedure, and to [5, 17] for a description of how the extracted discrete automaton is transformed into low-level robot control.", "startOffset": 86, "endOffset": 93}, {"referenceID": 19, "context": "In the case of unsynthesizable specifications, the counterstrategy synthesis algorithm introduced in [21] gives an automatic method of constructing a strategy for the environment, which provides sequences of environment actions that prevent the robot from achieving the specified behavior.", "startOffset": 101, "endOffset": 105}, {"referenceID": 19, "context": "marked with some robot goal [21].", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": "More examples illustrating the two cases can be found in [8].", "startOffset": 57, "endOffset": 60}, {"referenceID": 7, "context": ", initial conditions, safeties and goals) [8].", "startOffset": 42, "endOffset": 45}, {"referenceID": 7, "context": "The specification analysis algorithm presented in [8] will narrow down the cause of unsynthesizability to the goal in (4), but will also highlight the entirety of \u03c6 t s , declaring that the environment can prevent the goal because of some subset of the safeties (without identifying the exact subset).", "startOffset": 50, "endOffset": 53}, {"referenceID": 8, "context": "robot system [9, 11, 12] .", "startOffset": 13, "endOffset": 24}, {"referenceID": 10, "context": "robot system [9, 11, 12] .", "startOffset": 13, "endOffset": 24}, {"referenceID": 11, "context": "robot system [9, 11, 12] .", "startOffset": 13, "endOffset": 24}, {"referenceID": 8, "context": "The work in [9] addressed the problem of revising unsatisfiable LTL specifications.", "startOffset": 12, "endOffset": 15}, {"referenceID": 10, "context": "In [11, 12], the authors present exact and approximate algorithms for finding minimal revisions of specification automata, by removing the minimum number of constraints from the unsatisfiable specification.", "startOffset": 3, "endOffset": 11}, {"referenceID": 11, "context": "In [11, 12], the authors present exact and approximate algorithms for finding minimal revisions of specification automata, by removing the minimum number of constraints from the unsatisfiable specification.", "startOffset": 3, "endOffset": 11}, {"referenceID": 20, "context": "For unsatisfiable LTL formulas, the authors of [22] suggest a number of notions of unsatisfiable cores, tied to the corresponding method of extraction.", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "The authors of [23] employ a formal definition of causality to explain counterexamples provided by model-checkers on unsatisfiable LTL formulas; the advantage of this method is the flexibility of defining an appropriate causal model.", "startOffset": 15, "endOffset": 19}, {"referenceID": 22, "context": ", [24, 25]) literature.", "startOffset": 2, "endOffset": 10}, {"referenceID": 23, "context": ", [24, 25]) literature.", "startOffset": 2, "endOffset": 10}, {"referenceID": 24, "context": "A similar technique was used in [26] for debugging declarative specifications.", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "The approach in [26] only generalizes to specification languages that are reducible to SAT, a set which does not include LTL; this paper presents a similar approach, using SAT solvers to identify unsatisfiable cores for LTL.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "The authors of [27] also attempted to generalize the idea of unsatisfiable cores to the case of temporal logic using SAT-based bounded model checkers.", "startOffset": 15, "endOffset": 19}, {"referenceID": 26, "context": "In the context of unrealizability, the authors of [28] propose definitions for helpful assumptions and guarantees, and com-", "startOffset": 50, "endOffset": 54}, {"referenceID": 27, "context": "The authors in [29] use model-based diagnosis to remove not only guarantees but also irrelevant output signals from the specification.", "startOffset": 15, "endOffset": 19}, {"referenceID": 27, "context": "In [29], this is accomplished using techniques similar to those in [28], which in turn require many realizability checks.", "startOffset": 3, "endOffset": 7}, {"referenceID": 26, "context": "In [29], this is accomplished using techniques similar to those in [28], which in turn require many realizability checks.", "startOffset": 67, "endOffset": 71}, {"referenceID": 9, "context": "To identify and eliminate the source of unrealizability, some works like [10, 30] provide a minimal set of additional environment assumptions that, if added, would make the specification realizable; this is accomplished in [30] using efficient analysis of turn-based probabilistic games, and in [10] by mining the environment counterstrategy.", "startOffset": 73, "endOffset": 81}, {"referenceID": 28, "context": "To identify and eliminate the source of unrealizability, some works like [10, 30] provide a minimal set of additional environment assumptions that, if added, would make the specification realizable; this is accomplished in [30] using efficient analysis of turn-based probabilistic games, and in [10] by mining the environment counterstrategy.", "startOffset": 73, "endOffset": 81}, {"referenceID": 28, "context": "To identify and eliminate the source of unrealizability, some works like [10, 30] provide a minimal set of additional environment assumptions that, if added, would make the specification realizable; this is accomplished in [30] using efficient analysis of turn-based probabilistic games, and in [10] by mining the environment counterstrategy.", "startOffset": 223, "endOffset": 227}, {"referenceID": 9, "context": "To identify and eliminate the source of unrealizability, some works like [10, 30] provide a minimal set of additional environment assumptions that, if added, would make the specification realizable; this is accomplished in [30] using efficient analysis of turn-based probabilistic games, and in [10] by mining the environment counterstrategy.", "startOffset": 295, "endOffset": 299}, {"referenceID": 6, "context": "In the case of deadlock, which can be identified as in [7, 8], a series of Boolean formulas {\u03c8f romInit} is produced by incrementally unrolling the robot safety formula \u03c6 t s , and the satisfiability of \u03c8f romInit is checked at each depth.", "startOffset": 55, "endOffset": 61}, {"referenceID": 7, "context": "In the case of deadlock, which can be identified as in [7, 8], a series of Boolean formulas {\u03c8f romInit} is produced by incrementally unrolling the robot safety formula \u03c6 t s , and the satisfiability of \u03c8f romInit is checked at each depth.", "startOffset": 55, "endOffset": 61}, {"referenceID": 29, "context": "To perform this check, the formula \u03c8f romInit is first converted into CNF, so that it can be provided as input to an off-the-shelf SAT-solver; this work uses PicoSAT [31].", "startOffset": 166, "endOffset": 170}, {"referenceID": 6, "context": "Examples of this tool in action are given in [7, 8].", "startOffset": 45, "endOffset": 51}, {"referenceID": 7, "context": "Examples of this tool in action are given in [7, 8].", "startOffset": 45, "endOffset": 51}, {"referenceID": 13, "context": "Consider Specification 4, which first appeared in [14].", "startOffset": 50, "endOffset": 54}, {"referenceID": 19, "context": "Following [21], we call such a trace a countertrace.", "startOffset": 10, "endOffset": 14}, {"referenceID": 19, "context": "Computing countertraces is expensive [21], but it is possible to identify whether a given counterstrategy is a countertrace by checking that all paths from an initial state follow the same sequence of environment inputs.", "startOffset": 37, "endOffset": 41}, {"referenceID": 7, "context": "Suppose the algorithm in [8] identified goal Bk as the goal responsible for livelock.", "startOffset": 25, "endOffset": 28}, {"referenceID": 7, "context": "In the case of livelock, the initial specification analysis presented in [8] provides a specific liveness condition Bk that causes the unsynthesizability (i.", "startOffset": 73, "endOffset": 76}, {"referenceID": 18, "context": "Using the efficient algorithm in [20], each realizability check takes time O((mn\u03a3)3), where \u03a3 is the size of the state space, i.", "startOffset": 33, "endOffset": 37}, {"referenceID": 6, "context": "The examples presented previously appeared in [7], and this section demonstrates the improvement of the proposed approach over the analysis presented in that work.", "startOffset": 46, "endOffset": 49}, {"referenceID": 16, "context": "These examples were run using the opensource LTLMoP toolbox [17], within which all the technical outcomes presented in this paper have been implemented.", "startOffset": 60, "endOffset": 64}, {"referenceID": 6, "context": "(a) Sentences highlighted using approach in [7] (b) Sentences highlighted using proposed approach", "startOffset": 44, "endOffset": 47}, {"referenceID": 6, "context": "(a) Sentences highlighted using approach in [7] (b) Sentences highlighted using proposed approach", "startOffset": 44, "endOffset": 47}, {"referenceID": 6, "context": "5(a) depicts the sentences highlighted by the algorithm in [7].", "startOffset": 59, "endOffset": 62}, {"referenceID": 6, "context": "6(a) depicts the sentences highlighted by the algorithm in [7], which includes all safety conditions (red) in addition to the goal (green).", "startOffset": 59, "endOffset": 62}], "year": 2014, "abstractText": "With the increasing ubiquity of multi-capable, general-purpose robots arises the need for enabling non-expert users to command these robots to perform complex high-level tasks. To this end, high-level robot control has seen the application of formal methods to automatically synthesize correct-byconstruction controllers from user-defined specifications; synthesis fails if and only if there exists no controller that achieves the specified behavior. Recent work has also addressed the challenge of providing easy-to-understand feedback to users when a specification fails to yield a corresponding controller. Existing techniques provide feedback on portions of the specification that cause the failure, but do so at a coarse granularity. This work presents techniques for refining this feedback, extracting minimal explanations of unsynthesizability.", "creator": "LaTeX with hyperref package"}}}