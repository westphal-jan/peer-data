{"id": "1409.6110", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Sep-2014", "title": "Best-Arm Identification in Linear Bandits", "abstract": "we study the best - arm weapon identification problem in linear bandit, where the rewards of the arms depend linearly on an unknown parameter $ \\ theta ^ * $ and the objective is to return the favored arm identification with the largest reward. we characterize the complexity of the problem and introduce sample allocation - strategies that pull toward arms to identify the best arm with a fixed confidence, while minimizing the sample budget. in particular, we show the importance of exploiting the global linear structure to generally improve the estimate of the reward of near - optimal manufacturing arms. we analyze the chosen proposed strategies and compare their empirical performance. finally, clearly we point out the connection to the $ g $ - optimality regression criterion used in optimal experimental design.", "histories": [["v1", "Mon, 22 Sep 2014 08:41:02 GMT  (78kb)", "https://arxiv.org/abs/1409.6110v1", null], ["v2", "Tue, 4 Nov 2014 14:21:28 GMT  (79kb)", "http://arxiv.org/abs/1409.6110v2", "In Advances in Neural Information Processing Systems 27 (NIPS), 2014"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["marta soare", "alessandro lazaric", "r\u00e9mi munos"], "accepted": true, "id": "1409.6110"}, "pdf": {"name": "1409.6110.pdf", "metadata": {"source": "CRF", "title": "Best-Arm Identification in Linear Bandits", "authors": ["Marta Soare Alessandro Lazaric", "R\u00e9mi Munos"], "emails": ["marta.soare@inria.fr", "alessandro.lazaric@inria.fr", "remi.munos@inria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n40 9.\n61 10\nv2 [\ncs .L\nG ]\n4 N\nov 2\n01 4"}, {"heading": "1 Introduction", "text": "The stochastic multi-armed bandit problem (MAB) [16] offers a simple formalization for the study of sequential design of experiments. In the standard model, a learner sequentially chooses an arm out of K and receives a reward drawn from a fixed, unknown distribution relative to the chosen arm. While most of the literature in bandit theory focused on the problem of maximization of cumulative rewards, where the learner needs to trade-off exploration and exploitation, recently the pure exploration setting [5] has gained a lot of attention. Here, the learner uses the available budget to identify as accurately as possible the best arm, without trying to maximize the sum of rewards. Although many results are by now available in a wide range of settings (e.g., best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.\nAn interesting variant of the MAB setup is the stochastic linear bandit problem (LB), introduced in [3]. In the LB setting, the input space X is a subset of Rd and when pulling an arm x, the learner observes a reward whose expected value is a linear combination of x and an unknown parameter \u03b8\u2217 \u2208 Rd. Due to the linear structure of the problem, pulling an arm gives information about the parameter \u03b8\u2217 and indirectly, about the value of other arms. Therefore, the estimation of K meanrewards is replaced by the estimation of the d features of \u03b8\u2217. While in the exploration-exploitation setting the LB has been widely studied both in theory and in practice (e.g., [1, 14]), in this paper we focus on the pure-exploration scenario.\nThe fundamental difference between the MAB and the LB best-arm identification strategies stems from the fact that in MAB an arm is no longer pulled as soon as its sub-optimality is evident (in high probability), while in the LB setting even a sub-optimal arm may offer valuable information about the parameter vector \u03b8\u2217 and thus improve the accuracy of the estimation in discriminating among near-optimal arms. For instance, consider the situation when K\u22122 out of K arms are already discarded. In order to identify the best arm, MAB algorithms would concentrate the sampling on the two remaining arms to increase the accuracy of the estimate of their mean-rewards until the discarding condition is met for one of them. On the contrary, a LB pure-exploration strategy would seek to pull the arm x \u2208 X whose observed reward allows to refine the estimate \u03b8\u2217 along the dimensions which are more suited in discriminating between the two remaining arms. Recently, the best-arm identification in linear bandits has been studied in a fixed budget setting [10], in this paper we study the sample complexity required to identify the best-linear arm with a fixed confidence.\n\u2217This work was done when the author was a visiting researcher at Microsoft Research New-England. \u2020Current affiliation: Google DeepMind."}, {"heading": "2 Preliminaries", "text": "The setting. We consider the standard linear bandit model. Let X \u2286 Rd be a finite set of arms, where |X | = K and the \u21132-norm of any arm x \u2208 X , denoted by ||x||, is upper-bounded by L. Given an unknown parameter \u03b8\u2217 \u2208 Rd, we assume that each time an arm x \u2208 X is pulled, a random reward r(x) is generated according to the linear model r(x) = x\u22a4\u03b8\u2217 + \u03b5, where \u03b5 is a zero-mean i.i.d. noise bounded in [\u2212\u03c3;\u03c3]. Arms are evaluated according to their expected reward x\u22a4\u03b8\u2217 and we denote by x\u2217 = argmaxx\u2208X x\u22a4\u03b8\u2217 the best arm in X . Also, we use \u03a0(\u03b8) = argmaxx\u2208X x\u22a4\u03b8 to refer to the best arm corresponding to an arbitrary parameter \u03b8. Let \u2206(x, x\u2032) = (x \u2212 x\u2032)\u22a4\u03b8\u2217 be the value gap between two arms, then we denote by \u2206(x) = \u2206(x\u2217, x) the gap of x w.r.t. the optimal arm and by \u2206min = minx\u2208X \u2206(x) the minimum gap, where \u2206min > 0. We also introduce the sets Y = {y = x \u2212 x\u2032, \u2200x, x\u2032 \u2208 X} and Y\u2217 = {y = x\u2217 \u2212 x, \u2200x \u2208 X} containing all the directions obtained as the difference of two arms (or an arm and the optimal arm) and we redefine accordingly the gap of a direction as \u2206(y) = \u2206(x, x\u2032) whenever y = x\u2212 x\u2032. The problem. We study the best-arm identification problem. Let x\u0302(n) be the estimated best arm returned by a bandit algorithm after n steps. We evaluate the quality of x\u0302(n) by the simple regret Rn = (x\n\u2217 \u2212 x\u0302(n))\u22a4\u03b8\u2217. While different settings can be defined (see [8] for an overview), here we focus on the (\u01eb, \u03b4)-best-arm identification problem (the so-called PAC setting), where given \u01eb and \u03b4 \u2208 (0, 1), the objective is to design an allocation strategy and a stopping criterion so that when the algorithm stops, the returned arm x\u0302(n) is such that P ( Rn \u2265 \u01eb ) \u2264 \u03b4, while minimizing the needed number of steps. More specifically, we will focus on the case of \u01eb = 0 and we will provide high-probability bounds on the sample complexity n.\nThe multi-armed bandit case. In MAB, the complexity of best-arm identification is characterized by the gaps between arm values, following the intuition that the more similar the arms, the more pulls are needed to distinguish between them. More formally, the complexity is given by the problemdependent quantity HMAB = \u2211K i=1\n1 \u22062i i.e., the inverse of the pairwise gaps between the best arm and the suboptimal arms. In the fixed budget case, HMAB determines the probability of returning the wrong arm [2], while in the fixed confidence case, it characterizes the sample complexity [7].\nTechnical tools. Unlike in the multi-arm bandit scenario where pulling one arm does not provide any information about other arms, in a linear model we can leverage the rewards observed over time to estimate the expected reward of all the arms in X . Let xn = (x1, . . . , xn) \u2208 Xn be a sequence of arms and (r1, . . . , rn) the corresponding observed (random) rewards. An unbiased estimate of \u03b8\u2217 can be obtained by ordinary least-squares (OLS) as \u03b8\u0302n = A\u22121xn bxn , where Axn = \u2211n t=1 xtx \u22a4 t \u2208 R d\u00d7d and bxn = \u2211n t=1 xtrt \u2208 Rd. For any fixed sequence xn, through Azuma\u2019s inequality, the prediction error of the OLS estimate is upper-bounded in high-probability as follows. Proposition 1. Let c = 2\u03c3 \u221a 2 and c\u2032 = 6/\u03c02. For every fixed sequence xn, we have1\nP ( \u2200n \u2208 N, \u2200x \u2208 X , \u2223\u2223x\u22a4\u03b8\u2217 \u2212 x\u22a4\u03b8\u0302n \u2223\u2223 \u2264 c||x||A\u22121\nxn\n\u221a log(c\u2032n2K/\u03b4) ) \u2265 1\u2212 \u03b4. (1)\nWhile in the previous statement xn is fixed, a bandit algorithm adapts the allocation in response to the rewards observed over time. In this case a different high-probability bound is needed.\nProposition 2 (Thm. 2 in [1]). Let \u03b8\u0302\u03b7n be the solution to the regularized least-squares problem with regularizer \u03b7 and let A\u0303\u03b7\nx = \u03b7Id + Ax. Then for all x \u2208 X and every adaptive sequence xn such\nthat at any step t, xt only depends on (x1, r1, . . . , xt\u22121, rt\u22121), w.p. 1\u2212 \u03b4, we have \u2223\u2223x\u22a4\u03b8\u2217 \u2212 x\u22a4\u03b8\u0302\u03b7n \u2223\u2223 \u2264 ||x||(A\u0303\u03b7 xn ) \u22121 ( \u03c3 \u221a d log (1 + nL2/\u03b7 \u03b4 ) + \u03b71/2||\u03b8\u2217|| ) . (2) The crucial difference w.r.t. Eq. 1 is an additional factor \u221a d, the price to pay for adapting xn to the samples. In the sequel we will often resort to the notion of design (or \u201csoft\u201d allocation) \u03bb \u2208 Dk, which prescribes the proportions of pulls to arm x and Dk denotes the simplex X . The counterpart of the design matrix A for a design \u03bb is the matrix \u039b\u03bb = \u2211 x\u2208X \u03bb(x)xx\n\u22a4 . From an allocation xn we can derive the corresponding design \u03bbxn as \u03bbxn(x) = Tn(x)/n, where Tn(x) is the number of times arm x is selected in xn, and the corresponding design matrix is Axn = n\u039b\u03bbxn .\n1Whenever Prop.1 is used for all directions y \u2208 Y , then the logarithmic term becomes log(c\u2032n2K2/\u03b4) because of an additional union bound. For the sake of simplicity, in the sequel we always use logn(K 2/\u03b4).\n3 The Complexity of the Linear Best-Arm Identification Problem\nAs reviewed in Sect. 2, in the MAB case the complexity of the best-arm identification task is characterized by the reward gaps between the optimal and suboptimal arms. In this section, we propose an extension of the notion of complexity to the case of linear best-arm identification. In particular, we characterize the complexity by the performance of an oracle with access to the parameter \u03b8\u2217.\nStopping condition. Let C(x)= {\u03b8 \u2208 Rd, x \u2208 \u03a0(\u03b8)} be the set of parameters \u03b8 which admit x as an optimal arm. As illustrated in Fig. 1, C(x) is the cone defined by the intersection of half-spaces such that C(x) = \u2229x\u2032\u2208X {\u03b8 \u2208 R\nd, (x \u2212 x\u2032)\u22a4\u03b8 \u2265 0} and all the cones together form a partition of the Euclidean space Rd. We assume that the oracle knows the cone C(x\u2217) containing all the parameters for which x\u2217 is optimal. Furthermore, we assume\nthat for any allocation xn, it is possible to construct a confidence set S\u2217(xn) \u2286 Rd such that \u03b8\u2217 \u2208 S\u2217(xn) and the (random) OLS estimate \u03b8\u0302n belongs to S\u2217(xn) with high probability, i.e., P ( \u03b8\u0302n \u2208 S\u2217(xn) ) \u2265 1 \u2212 \u03b4. As a result, the oracle stopping criterion simply checks whether the confidence set S\u2217(xn) is contained in C(x\u2217) or not. In fact, whenever for an allocation xn the set S\u2217(xn) overlaps the cones of different arms x \u2208 X , there is ambiguity in the identity of the arm \u03a0(\u03b8\u0302n). On the other hand when all possible values of \u03b8\u0302n are included with high probability in the \u201cright\u201d cone C(x\u2217), then the optimal arm is returned. Lemma 1. Let xn be an allocation such that S\u2217(xn) \u2286 C(x\u2217). Then P ( \u03a0(\u03b8\u0302n) 6= x\u2217 ) \u2264 \u03b4.\nArm selection strategy. From the previous lemma2 it follows that the objective of an arm selection strategy is to define an allocation xn which leads to S\u2217(xn) \u2286 C(x\u2217) as quickly as possible.3 Since this condition only depends on deterministic objects (S\u2217(xn) and C(x\u2217)), it can be computed independently from the actual reward realizations. From a geometrical point of view, this corresponds to choosing arms so that the confidence set S\u2217(xn) shrinks into the optimal cone C(x\u2217) within the smallest number of pulls. To characterize this strategy we need to make explicit the form of S\u2217(xn). Intuitively speaking, the more S\u2217(xn) is \u201caligned\u201d with the boundaries of the cone, the easier it is to shrink it into the cone. More formally, the condition S\u2217(xn) \u2286 C(x\u2217) is equivalent to\n\u2200x \u2208 X , \u2200\u03b8 \u2208 S\u2217(xn), (x\u2217 \u2212 x)\u22a4\u03b8 \u2265 0 \u21d4 \u2200y \u2208 Y\u2217, \u2200\u03b8 \u2208 S\u2217(xn), y\u22a4(\u03b8\u2217 \u2212 \u03b8) \u2264 \u2206(y).\nThen we can simply use Prop. 1 to directly control the term y\u22a4(\u03b8\u2217 \u2212 \u03b8) and define\nS\u2217(xn) = { \u03b8 \u2208 Rd, \u2200y \u2208 Y\u2217, y\u22a4(\u03b8\u2217 \u2212 \u03b8) \u2264 c||y||A\u22121xn \u221a logn(K 2/\u03b4) } . (3)\nThus the stopping condition S\u2217(xn) \u2286 C(x\u2217) is equivalent to the condition that, for any y \u2208 Y\u2217,\nc||y||A\u22121 xn\n\u221a logn(K 2/\u03b4) \u2264 \u2206(y). (4)\nFrom this condition, the oracle allocation strategy simply follows as\nx \u2217 n = argmin\nxn max y\u2208Y\u2217\nc||y||A\u22121xn \u221a logn(K 2/\u03b4)\n\u2206(y) = argmin xn max y\u2208Y\u2217 ||y||A\u22121xn \u2206(y) . (5)\nNotice that this strategy does not return an uniformly accurate estimate of \u03b8\u2217 but it rather pulls arms that allow to reduce the uncertainty of the estimation of \u03b8\u2217 over the directions of interest (i.e., Y\u2217) below their corresponding gaps. This implies that the objective of Eq. 5 is to exploit the global linear assumption by pulling any arm in X that could give information about \u03b8\u2217 over the directions in Y\u2217, so that directions with small gaps are better estimated than those with bigger gaps.\n2For all the proofs in this paper, we refer the reader to the long version of the paper [18]. 3Notice that by definition of the confidence set and since \u03b8n \u2192 \u03b8\u2217 as n \u2192 \u221e, any strategy repeatedly\npulling all the arms would eventually meet the stopping condition.\nSample complexity. We are now ready to define the sample complexity of the oracle, which corresponds to the minimum number of steps needed by the allocation in Eq. 5 to achieve the stopping condition in Eq. 4. From a technical point of view, it is more convenient to express the complexity of the problem in terms of the optimal design (soft allocation) instead of the discrete allocation xn. Let \u03c1\u2217(\u03bb) = maxy\u2208Y\u2217 ||y||2\u039b\u22121\n\u03bb\n/\u22062(y) be the square of the objective function in Eq. 5 for any design\n\u03bb \u2208 Dk. We define the complexity of a linear best-arm identification problem as the performance achieved by the optimal design \u03bb\u2217 = argmin\u03bb \u03c1\u2217(\u03bb), i.e.\nHLB = min \u03bb\u2208Dk max y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb \u22062(y) = \u03c1\u2217(\u03bb\u2217). (6)\nThis definition of complexity is less explicit than in the case of HMAB but it contains similar elements, notably the inverse of the gaps squared. Nonetheless, instead of summing the inverses over all the arms, HLB implicitly takes into consideration the correlation between the arms in the term ||y||2\n\u039b\u22121 \u03bb\n, which represents the uncertainty in the estimation of the gap between x\u2217 and x (when\ny = x\u2217 \u2212 x). As a result, from Eq. 4 the sample complexity becomes N\u2217 = c2HLB logn(K\n2/\u03b4), (7) where we use the fact that, if implemented over n steps, \u03bb\u2217 induces a design matrix A\u03bb\u2217 = n\u039b\u03bb\u2217 and maxy ||y||2A\u22121\n\u03bb\u2217\n/\u22062(y) = \u03c1\u2217(\u03bb\u2217)/n. Finally, we bound the range of the complexity.\nLemma 2. Given an arm set X \u2286 Rd and a parameter \u03b8\u2217, the complexity HLB (Eq. 6) is such that max y\u2208Y\u2217\n||y||2/(L\u22062min) \u2264 HLB \u2264 4d/\u22062min. (8) Furthermore, if X is the canonical basis, the problem reduces to a MAB and HMAB\u2264HLB\u22642HMAB. The previous bounds show that \u2206min plays a significant role in defining the complexity of the problem, while the specific shape of X impacts the numerator in different ways. In the worst case the full dimensionality d appears (upper-bound), and more arm-set specific quantities, such as the norm of the arms L and of the directions Y\u2217, appear in the lower-bound.\n4 Static Allocation Strategies\nThe oracle stopping condition (Eq. 4) and allocation strategy (Eq. 5) cannot be implemented in practice since \u03b8\u2217, the gaps \u2206(y), and the directions Y\u2217 are unknown. In this section we investigate how to define algorithms that only rely on the information available from X and the samples collected over time. We introduce an empirical stopping criterion and two static allocations.\nEmpirical stopping criterion. The stopping condition S\u2217(xn) \u2286 C(x\u2217) cannot be tested since S\u2217(xn) is centered in the unknown parameter \u03b8\u2217 and C(x\u2217) depends on the unknown optimal arm x\u2217. Nonetheless, we notice that given X , for each\nx \u2208 X the cones C(x) can be constructed beforehand. Let S\u0302(xn) be a high-probability confidence set such that for any xn, \u03b8\u0302n \u2208 S\u0302(xn) and P(\u03b8\u2217 \u2208 S\u0302(xn)) \u2265 1 \u2212 \u03b4. Unlike S\u2217, S\u0302 can be directly computed from samples and we can stop whenever there exists an x such that S\u0302(xn) \u2286 C(x). Lemma 3. Let xn = (x1, . . . , xn) be an arbitrary allocation sequence. If after n steps there exists an arm x \u2208 X such that S\u0302(xn) \u2286 C(x) then P ( \u03a0(\u03b8\u0302n) 6= x\u2217 ) \u2264 \u03b4.\nArm selection strategy. Similarly to the oracle algorithm, we should design an allocation strategy that guarantees that the (random) confidence set S\u0302(xn) shrinks in one of the cones C(x) within the fewest number of steps. Let \u2206\u0302n(x, x\u2032) = (x \u2212 x\u2032)\u22a4\u03b8\u0302n be the empirical gap between arms x, x\u2032. Then the stopping condition S\u0302(xn) \u2286 C(x) can be written as\n\u2203x \u2208 X , \u2200x\u2032 \u2208 X ,\u2200\u03b8 \u2208 S\u0302(xn), (x\u2212 x\u2032)\u22a4\u03b8 \u2265 0 \u21d4 \u2203x \u2208 X , \u2200x\u2032 \u2208 X , \u2200\u03b8 \u2208 S\u0302(xn), (x \u2212 x\u2032)\u22a4(\u03b8\u0302n \u2212 \u03b8) \u2264 \u2206\u0302n(x, x\u2032). (9)\nThis suggests that the empirical confidence set can be defined as\nS\u0302(xn) = { \u03b8 \u2208 Rd, \u2200y \u2208 Y, y\u22a4(\u03b8\u0302n \u2212 \u03b8) \u2264 c||y||A\u22121\nxn\n\u221a logn(K 2/\u03b4) } . (10)\nUnlike S\u2217(xn), S\u0302(xn) is centered in \u03b8\u0302n and it considers all directions y \u2208 Y . As a result, the stopping condition in Eq. 9 could be reformulated as\n\u2203x \u2208 X , \u2200x\u2032 \u2208 X , c||x\u2212 x\u2032||A\u22121 xn\n\u221a logn(K\n2/\u03b4) \u2264 \u2206\u0302n(x, x\u2032). (11) Although similar to Eq. 4, unfortunately this condition cannot be directly used to derive an allocation strategy. In fact, it is considerably more difficult to define a suitable allocation strategy to fit a random confidence set S\u0302 into a cone C(x) for an x which is not known in advance. In the following we propose two allocations that try to achieve the condition in Eq. 11 as fast as possible by implementing a static arm selection strategy, while we present a more sophisticated adaptive strategy in Sect. 5. The general structure of the static allocations in summarized in Fig. 2.\nG-Allocation Strategy. The definition of the G-allocation strategy directly follows from the observation that for any pair (x, x\u2032) \u2208 X 2 we have that ||x \u2212 x\u2032||A\u22121 xn \u2264 2maxx\u2032\u2032\u2208X ||x\u2032\u2032||A\u22121 xn . This suggests that an allocation minimizing maxx\u2208X ||x||A\u22121 xn\nreduces an upper bound on the quantity tested in the stopping condition in Eq. 11. Thus, for any fixed n, we define the G-allocation as\nx G n = argmin\nxn\nmax x\u2208X ||x||A\u22121xn . (12)\nWe notice that this formulation coincides with the standard G-optimal design (hence the name of the allocation) defined in experimental design theory [15, Sect. 9.2] to minimize the maximal meansquared prediction error in linear regression. The G-allocation can be interpreted as the design that allows to estimate \u03b8\u2217 uniformly well over all the arms in X . Notice that the G-allocation in Eq. 12 is well defined only for a fixed number of steps n and it cannot be directly implemented in our case, since n is unknown in advance. Therefore we have to resort to a more \u201cincremental\u201d implementation. In the experimental design literature a wide number of approximate solutions have been proposed to solve the NP-hard discrete optimization problem in Eq. 12 (see [4, 17] for some recent results and [18] for a more thorough discussion). For any approximate G-allocation strategy with performance no worse than a factor (1+\u03b2) of the optimal strategy xGn , the sample complexity N\nG is bounded as follows. Theorem 1. If the G-allocation strategy is implemented with a \u03b2-approximate method and the stopping condition in Eq. 11 is used, then\nP [ NG \u2264 16c 2d(1 + \u03b2) logn(K 2/\u03b4)\n\u22062min \u2227 \u03a0(\u03b8\u0302NG) = x\u2217\n] \u2265 1\u2212 \u03b4. (13)\nNotice that this result matches (up to constants) the worst-case value of N\u2217 given the upper bound on HLB. This means that, although completely static, the G-allocation is already worst-case optimal.\nXY-Allocation Strategy. Despite being worst-case optimal, G-allocation is minimizing a rather loose upper bound on the quantity used to test the stopping criterion. Thus, we define an alternative static allocation that targets the stopping condition in Eq. 11 more directly by reducing its left-handside for any possible direction in Y . For any fixed n, we define the XY-allocation as\nx XY n = argmin\nxn\nmax y\u2208Y ||y||A\u22121 xn . (14)\nXY-allocation is based on the observation that the stopping condition in Eq. 11 requires only the empirical gaps \u2206\u0302(x, x\u2032) to be well estimated, hence arms are pulled with the objective of increasing the accuracy of directions in Y instead of arms X . This problem can be seen as a transductive variant of the G-optimal design [19], where the target vectors Y are different from the vectors X used in the design. The sample complexity of the XY-allocation is as follows. Theorem 2. If the XY-allocation strategy is implemented with a \u03b2-approximate method and the stopping condition in Eq. 11 is used, then\nP [ NXY \u2264 32c 2d(1 + \u03b2) logn(K 2/\u03b4)\n\u22062min \u2227 \u03a0(\u03b8\u0302NXY ) = x\u2217\n] \u2265 1\u2212 \u03b4. (15)\nAlthough the previous bound suggests that XY achieves a performance comparable to the Gallocation, in fact XY may be arbitrarily better than G-allocation (for an example, see [18]).\n5 XY-Adaptive Allocation Strategy\nInput: decision space X \u2208Rd; parameter \u03b1; confidence \u03b4 Set j=1; X\u0302j=X ; Y\u03021=Y; \u03c10=1; n0=d(d+ 1) + 1 while |X\u0302j | > 1 do \u03c1j = \u03c1j\u22121\nt = 1;A0 = I while \u03c1j/t \u2265 \u03b1\u03c1j\u22121(xj\u22121nj\u22121)/nj\u22121 do\nSelect arm xt = argmin x\u2208X max y\u2208Y\ny\u22a4(A+ xx\u22a4)\u22121y\nUpdate At = At\u22121 + xtx\u22a4t , t = t+ 1 \u03c1j = max\ny\u2208Y\u0302j y\u22a4A\u22121t y\nend while Compute b = \u2211t s=1 xsrs; \u03b8\u0302j = A \u22121 t b X\u0302j+1 = X for x \u2208 X do\nif \u2203x\u2032 : ||x \u2212 x\u2032|| A \u22121\nt\n\u221a logn(K 2/\u03b4) \u2264 \u2206\u0302j(x \u2032, x) then\nX\u0302j+1 = X\u0302j+1 \u2212 {x} end if\nend for Y\u0302j+1 = {y = (x\u2212 x\n\u2032);x, x\u2032 \u2208 X\u0302j+1} end while Return \u03a0(\u03b8\u0302j)\nFigure 3: XY-Adaptive allocation algorithm\nFully adaptive allocation strategies. Although both G- and XY-allocation are sound since they minimize upper-bounds on the quantities used by the stopping condition (Eq. 11), they may be very suboptimal w.r.t. the ideal performance of the oracle introduced in Sec. 3. Typically, an improvement can be obtained by moving to strategies adapting on the rewards observed over time. Nonetheless, as reported in Prop. 2, whenever xn is not a fixed sequence, the bound in Eq. 2 should be used. As a result, a factor \u221a d would appear in the definition of the confidence sets and in the stopping condition. This directly implies that the sample complexity of a fully adaptive strategy would scale linearly with the dimensionality d of the problem, thus removing any advantage w.r.t. static allocations. In fact, the sample complexity of G- and XYallocation already scales linearly with d and from Lem. 2 we cannot expect to im-\nprove the dependency on \u2206min. Thus, on the one hand, we need to use the tighter bounds in Eq. 1 and, on the other hand, we require to be adaptive w.r.t. samples. In the sequel we propose a phased algorithm which successfully meets both requirements using a static allocation within each phase but choosing the type of allocation depending on the samples observed in previous phases.\nAlgorithm. The ideal case would be to define an empirical version of the oracle allocation in Eq. 5 so as to adjust the accuracy of the prediction only on the directions of interest Y\u2217 and according to their gaps \u2206(y). As discussed in Sect. 4 this cannot be obtained by a direct adaptation of Eq. 11. In the following, we describe a safe alternative to adjust the allocation strategy to the gaps.\nLemma 4. Let xn be a fixed allocation sequence and \u03b8\u0302n its corresponding estimate for \u03b8\u2217. If an arm x \u2208 X is such that\n\u2203x\u2032 \u2208 X s.t. c||x\u2032 \u2212 x||A\u22121xn \u221a logn(K 2/\u03b4) < \u2206\u0302n(x \u2032, x), (16)\nthen arm x is sub-optimal. Moreover, if Eq. 16 is true, we say that x\u2032 dominates x.\nLem. 4 allows to easily construct the set of potentially optimal arms, denoted X\u0302 (xn), by removing from X all the dominated arms. As a result, we can replace the stopping condition in Eq. 11, by just testing whether the number of non-dominated arms |X\u0302 (xn)| is equal to 1, which corresponds to the case where the confidence set is fully contained into a single cone. Using X\u0302 (xn), we construct Y\u0302(xn) = {y = x\u2212x\u2032;x, x\u2032 \u2208 X\u0302 (xn)}, the set of directions along which the estimation of \u03b8\u2217 needs to be improved to further shrink S\u0302(xn) into a single cone and trigger the stopping condition. Note that if xn was an adaptive strategy, then we could not use Lem. 4 to discard arms but we should rely on the bound in Prop. 2. To avoid this problem, an effective solution is to run the algorithm through phases. Let j \u2208 N be the index of a phase and nj its corresponding length. We denote by X\u0302j the set of non-dominated arms constructed on the basis of the samples collected in the phase j \u2212 1. This set is used to identify the directions Y\u0302j and to define a static allocation which focuses on reducing the uncertainty of \u03b8\u2217 along the directions in Y\u0302j . Formally, in phase j we implement the allocation\nx j nj = argmin\nxnj max y\u2208Y\u0302j ||y||A\u22121 xnj , (17)\nwhich coincides with a XY-allocation (see Eq. 14) but restricted on Y\u0302j . Notice that xjnj may still use any arm in X which could be useful in reducing the confidence set along any of the directions in\nY\u0302j . Once phase j is over, the OLS estimate \u03b8\u0302j is computed using the rewards observed within phase j and then is used to test the stopping condition in Eq. 11. Whenever the stopping condition does not hold, a new set X\u0302j+1 is constructed using the discarding condition in Lem. 4 and a new phase is started. Notice that through this process, at each phase j, the allocation xjnj is static conditioned on the previous allocations and the use of the bound from Prop. 1 is still correct.\nA crucial aspect of this algorithm is the length of the phases nj . On the one hand, short phases allow a high rate of adaptivity, since X\u0302j is recomputed very often. On the other hand, if a phase is too short, it is very unlikely that the estimate \u03b8\u0302j may be accurate enough to actually discard any arm. An effective way to define the length of a phase in a deterministic way is to relate it to the actual uncertainty of the allocation in estimating the value of all the active directions in Y\u0302j . In phase j, let \u03c1j(\u03bb) = maxy\u2208Y\u0302j ||y|| 2 \u039b\u22121\n\u03bb\n, then given a parameter \u03b1 \u2208 (0, 1), we define\nnj = min { n \u2208 N : \u03c1j(\u03bb\nx j n )/n \u2264 \u03b1\u03c1j\u22121(\u03bbj\u22121)/nj\u22121\n} , (18)\nwhere xjn is the allocation defined in Eq. 17 and \u03bb j\u22121 is the design corresponding to xj\u22121nj\u22121 , the allocation performed at phase j \u2212 1. In words, nj is the minimum number of steps needed by the XY-adaptive allocation to achieve an uncertainty over all the directions of interest which is a fraction \u03b1 of the performance obtained in the previous iteration. Notice that given Y\u0302j and \u03c1j\u22121 this quantity can be computed before the actual beginning of phase j. The resulting algorithm using the XY-Adaptive allocation strategy is summarized in Fig. 3. Sample complexity. Although the XY-Adaptive allocation strategy is designed to approach the oracle sample complexity N\u2217, in early phases it basically implements a XY-allocation and no significant improvement can be expected until some directions are discarded from Y\u0302 . At that point, XY-adaptive starts focusing on directions which only contain near-optimal arms and it starts approaching the behavior of the oracle. As a result, in studying the sample complexity of XY-Adaptive we have to take into consideration the unavoidable price of discarding \u201csuboptimal\u201d directions. This cost is directly related to the geometry of the arm space that influences the number of samples needed before arms can be discarded from X . To take into account this problem-dependent quantity, we introduce a slightly relaxed definition of complexity. More precisely, we define the number of steps needed to discard all the directions which do not contain x\u2217, i.e. Y \u2212 Y\u2217. From a geometrical point of view, this corresponds to the case when for any pair of suboptimal arms (x, x\u2032), the confidence set S\u2217(xn) does not intersect the hyperplane separating the cones C(x) and C(x\u2032). Fig. 1 offers a simple illustration for such a situation: S\u2217 no longer intercepts the border line between C(x2) and C(x3), which implies that direction x2 \u2212 x3 can be discarded. More formally, the hyperplane containing parameters \u03b8 for which x and x\u2032 are equivalent is simply C(x) \u2229 C(x\u2032) and the quantity\nM\u2217 = min{n \u2208 N, \u2200x 6= x\u2217, \u2200x\u2032 6= x\u2217,S\u2217(xXYn ) \u2229 (C(x) \u2229 C(x\u2032)) = \u2205} (19) corresponds to the minimum number of steps needed by the static XY-allocation strategy to discard all the suboptimal directions. This term together with the oracle complexity N\u2217 characterizes the sample complexity of the phases of the XY-adaptive allocation. In fact, the length of the phases is such that either they correspond to the complexity of the oracle or they can never last more than the steps needed to discard all the sub-optimal directions. As a result, the overall sample complexity of the XY-adaptive algorithm is bounded as in the following theorem. Theorem 3. If the XY-Adaptive allocation strategy is implemented with a \u03b2-approximate method and the stopping condition in Eq. 11 is used, then\nP [ N \u2264 (1 + \u03b2)max{M \u2217, 16\u03b1 N \u2217}\nlog(1/\u03b1) log\n(c \u221a logn(K 2/\u03b4)\n\u2206min\n) \u2227 \u03a0(\u03b8\u0302N ) = x\u2217 ] \u2265 1\u2212 \u03b4. (20)\nWe first remark that, unlike G and XY , the sample complexity of XY-Adaptive does not have any direct dependency on d and \u2206min (except in the logarithmic term) but it rather scales with the oracle complexity N\u2217 and the cost of discarding suboptimal directions M\u2217. Although this additional cost is probably unavoidable, one may have expected that XY-Adaptive may need to discard all the suboptimal directions before performing as well as the oracle, thus having a sample complexity of O(M\u2217+N\u2217). Instead, we notice that N scales with the maximum of M\u2217 and N\u2217, thus implying that XY-Adaptive may actually catch up with the performance of the oracle (with only a multiplicative factor of 16/\u03b1) whenever discarding suboptimal directions is less expensive than actually identifying the best arm."}, {"heading": "6 Numerical Simulations", "text": "We illustrate the performance of XY-Adaptive and compare it to the XY-Oracle strategy (Eq. 5), the static allocations XY and G, as well as with the fully-adaptive version of XY where X\u0302 is updated at each round and the bound from Prop.2 is used. For a fixed confidence \u03b4 = 0.05, we compare the sampling budget needed to identify the best arm with probability at least 1 \u2212 \u03b4. We consider a set of arms X \u2208 Rd, with |X | = d+ 1 including the canonical basis (e1, . . . , ed) and an additional arm xd+1 = [cos(\u03c9) sin(\u03c9) 0 . . . 0]\n\u22a4. We choose \u03b8\u2217 = [2 0 0 . . . 0]\u22a4, and fix \u03c9 = 0.01, so that \u2206min = (x1 \u2212 xd+1)\u22a4\u03b8\u2217 is much smaller than the other gaps. In this setting, an efficient sampling strategy should focus on reducing the uncertainty in the direction y\u0303 = (x1 \u2212 xd+1) by pulling the arm x2 = e2 which is almost aligned with y\u0303. In fact, from the rewards obtained from x2 it is easier to decrease the uncertainty about the second component of \u03b8\u2217, that is precisely the dimension which allows to discriminate between x1 and xd+1. Also, we fix \u03b1 = 1/10, and the noise \u03b5 \u223c N (0, 1). Each phase begins with an initialization matrix A0, obtained by pulling once each canonical arm. In Fig. 4 we report the sampling budget of the algorithms, averaged over 100 runs, for d = 2 . . . 10.\nThe results. The numerical results show that XYAdaptive is effective in allocating the samples to shrink the uncertainty in the direction y\u0303. Indeed, XY-adaptive identifies the most important direction after few phases and is able to perform an allocation which mimics that of the oracle. On the contrary, XY and G do not adjust to the empirical gaps and consider all directions as equally important. This behavior forces XY and G to allocate samples until the uncertainty is smaller than \u2206min in all directions. Even though the Fully-adaptive algorithm also identifies the most informative direction rapidly, the \u221a d term in the bound delays the discarding of the arms and prevents the algorithm from gaining any advantage compared to XY and G. As shown in Fig. 4,\nthe difference between the budget of XY-Adaptive and the static strategies increases with the number of dimensions. In fact, while additional dimensions have little to no impact on XY-Oracle and XY-Adaptive (the only important direction remains y\u0303 independently from the number of unknown features of \u03b8\u2217), for the static allocations more dimensions imply more directions to be considered and more features of \u03b8\u2217 to be estimated uniformly well until the uncertainty falls below \u2206min."}, {"heading": "7 Conclusions", "text": "In this paper we studied the problem of best-arm identification with a fixed confidence, in the linear bandit setting. First we offered a preliminary characterization of the problem-dependent complexity of the best arm identification task and shown its connection with the complexity in the MAB setting. Then, we designed and analyzed efficient sampling strategies for this problem. The G-allocation strategy allowed us to point out a close connection with optimal experimental design techniques, and in particular to the G-optimality criterion. Through the second proposed strategy, XY-allocation, we introduced a novel optimal design problem where the testing arms do not coincide with the arms chosen in the design. Lastly, we pointed out the limits that a fully-adaptive allocation strategy might have in the linear bandit setting and proposed a phased-algorithm, XY-Adaptive, that learns from previous observations, without suffering from the dimensionality of the problem. Since this is one of the first works that analyze pure-exploration problems in the linear-bandit setting, it opens the way for an important number of similar problems already studied in the MAB setting. For instance, we can investigate strategies to identify the best-linear arm when having a limited budget or study the best-arm identification when the set of arms is very large (or infinite). Some interesting extensions also emerge from the optimal experimental design literature, such as the study of sampling strategies for meeting the G-optimality criterion when the noise is heterosckedastic, or the design of efficient strategies for satisfying other related optimality criteria, such as V-optimality.\nAcknowledgments This work was supported by the French Ministry of Higher Education and Research, Nord-Pas de Calais Regional Council and FEDER through the \u201cContrat de Projets Etat Region 2007\u20132013\", and European Community\u2019s Seventh Framework Programme under grant agreement no 270327 (project CompLACS)."}, {"heading": "B Proofs", "text": ""}, {"heading": "B.1 Lemmas", "text": "Proof of Lemma 1. The proof follows from the fact that if S\u2217(xn) \u2286 C(x\u2217) and \u03b8\u0302n \u2208 S\u2217(xn) with high probability, then \u03b8\u0302n \u2208 C(x\u2217) which implies that \u03a0(\u03b8\u0302n) = x\u2217 by definition of the cone C(x\u2217).\nBefore proceeding to the proof of Lemma 2 we introduce the following technical tool.\nProposition 3 (Equivalence-Theorem in [13]). Define f(x; \u03be) = x\u22a4M(\u03be)\u22121x, where M(\u03be) is a d\u00d7 d non-singular matrix and x is a column vector in Rd. We consider two extremum problems."}, {"heading": "The first is to choose \u03be so that", "text": "(1) \u03be maximizes detM(\u03be) (D-optimal design)"}, {"heading": "The second one is to choose \u03be so that", "text": "(2) \u03be minimizes max f(x; \u03be) (G-optimal design)\nWe note that the integral with respect to \u03be of f(x; \u03be) is d; hence, max f(x; \u03be) \u2265 d, and thus a sufficient condition for \u03be to satisfy (2) is\n(3) max f(x; \u03be) = d."}, {"heading": "Statements (1), (2) and (3) are equivalent.", "text": "Proof of Lemma 2. Upper-bound. We have the following sequence of inequalities\nmax y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb \u22062(y) \u2264 1 \u22062min max y\u2208Y\u2217 ||y||2 \u039b\u22121 \u03bb \u2264 4 \u22062min max x\u2208X ||x||2 \u039b\u22121 \u03bb ,\nwhere the second inequality comes from a triangle inequality on ||y||2 \u039b\u22121\n\u03bb\n. Thus we obtain\n\u03c1\u2217(\u03bb\u2217) = min \u03bb\u2208Dk max y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb \u22062(y) \u2264 4 \u22062min min \u03bb\u2208Dk max x\u2208X ||x||2 \u039b\u22121 \u03bb = 4d \u22062min ,\nwhere the last equality follows from the Kiefer-Wolfowitz equivalence theorem presented in Prop. 3."}, {"heading": "Lower-bound.", "text": "We focus on the numerator y\u22a4\u039b\u22121\u03bb y. Since \u039b\u03bb is a positive definite matrix, we define its decomposition \u039b\u03bb = Q\u0393Q\u22a4, where Q is an orthogonal matrix and \u0393 is the diagonal matrix containing the eigenvalues. As a result the numerator can be written as\ny\u22a4\u039b\u22121\u03bb y = y \u22a4Q\u0393\u22121Q\u22a4y = w\u22a4\u0393\u22121w,\nwhere we renamed Q\u22a4y = w. If we denote by \u03b3max the largest eigenvalue of \u039b\u03bb (i.e., the largest value in \u0393), then\nw\u22a4\u0393\u22121w \u2265 1/\u03b3maxw\u22a4w = 1/\u03b3max||y||2. The largest eigenvalue \u03b3max is upper-bounded by the sum of the largest eigenvalues of the matrices \u03bb(x)xx\u22a4 which is \u03bb(x)||x||2. As a result, we obtain the bound \u03b3max \u2264 \u2211 x \u03bb(x)||x||2 \u2264 L, since ||x||2 \u2264 L and \u03bb is in the simplex. Thus we have\nmin \u03bb\u2208Dk max y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb \u22062(y) \u2265 1 L max y\u2208Y\u2217 ||y||2 \u2206(y)2 \u2265 maxy\u2208Y\u2217 ||y|| 2 L\u22062min .\nComparison with the K-armed bandit complexity.\nFinally, we show how the sample complexity reduces to the known quantity in the MAB case. If the arms in X coincide with the canonical basis of Rd, then for any allocation \u03bb the design matrix \u039b\u03bb becomes a diagonal matrix of the form diag(\u03bb(x1), . . . , \u03bb(xK)). As a result, we obtain\nHLB = min \u03bb\u2208Dk max y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb\n\u22062(y) = min \u03bb\u2208Dk max x\u2208X\u2212{x\u2217}\n1/\u03bb(x) + 1/\u03bb(x\u2217)\n\u22062(x) .\nIf we use the allocation \u03bb(x) = 1/(\u03bd\u22062(x)) and \u03bb(x\u2217) = 1/(\u03bd\u2206min), with \u03bd = 1/\u22062min +\u2211 x 6=x\u2217 1/\u2206 2(x), we obtain\nHLB \u2264 max x\u2208X\u2212{x\u2217} \u03bd\u22062(x) + \u03bd\u22062min \u22062(x) = max x\u2208X\u2212{x\u2217} \u03bd + \u03bd \u22062min \u22062(x)\n= 2\u03bd = 2 ( 1 \u22062min + \u2211\nx 6=x\u2217\n1\n\u22062(x)\n) = 2HMAB.\nOn the other hand, letting x\u0303 be the second best arm and \u2206(x\u2217) = \u2206min, we have that\nHLB = min \u03bb\u2208Dk max x 6=x\u2217\n1/\u03bb(x) + 1/\u03bb(x\u2217)\n\u22062(x)\n= min \u03bb\u2208Dk max { max x 6=x\u2217 1/\u03bb(x) + 1/\u03bb(x\u2217) \u22062(x) ; 1/\u03bb(x\u0303) + 1/\u03bb(x\u2217) \u22062(x\u2217) }\n\u2265 min \u03bb\u2208Dk max { max x 6=x\u2217 1/\u03bb(x) \u22062(x) ; 1/\u03bb(x\u2217) \u22062(x\u2217) }\n= min \u03bb\u2208Dk max x\u2208X\n1/\u03bb(x) \u22062(x) .\nWe set 1/\u03bb(x)\u22062(x) equal to a constant c and thus we get \u03bb(x) = 1 c\u22062(x) . Since 1 c \u2211 x\u2208X 1 \u22062(x) = 1, it follows that:\nc = \u2211\nx\u2208X\n1\n\u22062(x) =\n\u2211\nx 6=x\u2217\n1\n\u22062(x) +\n1\n\u22062min = HMAB.\nThus, we get that HMAB \u2264 HLB \u2264 2HMAB. This shows that HLB is a well defined notion of complexity for the linear best-arm identification problem and the corresponding sample complexity N\u2217 is coherent with existing results in the MAB case.\nProof of Lemma 3. The proof follows from the fact that if S\u0302(xn) \u2286 C(x) and \u03b8\u2217 \u2208 S\u0302(xn) with high probability, then \u03b8\u2217 \u2208 C(x) which implies that \u03a0(\u03b8\u0302n) = x = x\u2217."}, {"heading": "B.2 Proofs of Theorem 1 and Theorem 2", "text": "Proof of Theorem 1. The statement follows from Prop. 1 and the performance guarantees for the different implementations of the G-optimal design. By recalling the empirical stopping condition in Eq. 11 and the definition \u03c1G(\u03bb) = maxx x\u22a4\u039b \u22121 \u03bb x, we notice that from a simple triangle inequality applied to ||y||A\u22121 , a sufficient condition for stopping is that for any x \u2208 X\n4c2\u03c1G\u0303n logn(K 2/\u03b4)\nn \u2264 \u2206\u03022n(x\u2217, x),\nwhere \u03c1G\u0303n = \u03c1 G(\u03bb x G\u0303 n ) and xG\u0303n is the allocation obtained from rounding the optimal design \u03bb G obtained from the continuous relaxation or the greedy incremental algorithm. From Prop. 1 we have that the following inequalities\n\u2206\u0302n(x \u2217, x) \u2265 \u2206(x\u2217, x)\u2212 c||x\u2217 \u2212 x||A\u22121\nx G n\n\u221a logn(K 2/\u03b4) \u2265 \u2206(x\u2217, x)\u2212 2c\n\u221a \u03c1G\u0303n logn(K 2/\u03b4)\nn ,\nhold with probability 1 \u2212 \u03b4. Combining this with the previous condition and since the condition must hold for all x \u2208 X , we have that a sufficient condition to stop using the G-allocation is\n16c2\u03c1G\u0303n logn(K 2/\u03b4)\nn \u2264 \u2206min,\nwhich defines the level of accuracy that the G-allocation needs to achieve before stopping. Since \u03c1G\u0303n \u2264 (1 + \u03b2)d then the statement follows by inverting the previous inequality.\nProof of Theorem 2. We follow the same steps as in the proof of Theorem 1.\nC Implementation of the Allocation Strategies\nIn this section we discuss about possible implementations of the allocation strategies illustrated in sections 4 and 5 and we discuss their approximation accuracy guarantees.\nThe efficient rounding procedure. We first report the general structure of the efficient rounding procedure defined in [15, Chapter 12] to implement a design \u03bb into an allocation xn for any fixed number of steps n. Let p = supp(\u03bb) the support of \u03bb,4 then we want to compute the number of pulls ni (with i = 1, . . . , p) for all the arms in the support of \u03bb. Basically, the fast implementation of the design is obtained in two phases, as follows:\n\u2022 In the first phase, given the sample size n and the number of support points p, we calculate their corresponding frequencies ni = \u2308(n\u2212 12p)\u03bbi\u2309, where n1, n2, . . . , np are positive integers with \u2211 i\u2264p ni \u2265 n.\n\u2022 The second phase loops until the discrepancy (\u2211 i\u2264p ni ) \u2212 n is 0, either:\n\u2013 increasing a frequency nj which attains nj/\u03bbj = mini\u2264p(n\u2212 1)/\u03bbi to nj+1, or \u2013 decreasing some nk with (nk \u2212 1)/\u03bbk = maxi\u2264p(ni \u2212 1)/\u03bbi to n\u2212 1.\nAn interesting feature of this procedure is that when moving from n to n + 1 the corresponding allocations xn and xn+1 only differ for one element i which is increased by 1, i.e., the discrete allocation is monotonic in n.\n4For a fixed design \u03bb \u2208 RK , we say that its support is given by all arms in X whose corresponding features in \u03bb are different than 0.\nImplementation of the G-allocation. A first option is to optimize a continuous relaxation of the problem and compute the optimal design. Let \u03c1G(\u03bb) = maxx x\u22a4\u039b \u22121 \u03bb x, the optimal design is\n\u03bbG = arg min \u03bb\u2208Dk max x\u2208X ||x||2 \u039b\u22121 \u03bb = arg min \u03bb\u2208Dk \u03c1G(\u03bb). (21)\nThis is a convex optimization problem and it can be solved using the projected gradient algorithm, interior point techniques, or multiplicative algorithms. To move from the design \u03bbG to a discrete allocation we use the efficient rounding technique presented above and we obtain that the resulting allocation xG\u0303t is guaranteed to be monotonic as the number of times an arm x is pulled is nondecreasing with t. Thus from xG\u0303t we obtain a simple incremental rule, where the arm xt is the arm for which xG\u0303t recommends one pull more than in x G\u0303 t\u22121. An alternative is to directly implement an incremental version of Eq. 12 by selecting at each step t the greedy arm\nxt = argmin x\u2208X max x\u2032\u2208X\nx\u2032\u22a4 ( Axt\u22121+xx \u22a4 ) \u22121x\u2032 = argmin\nx\u2208X max x\u2032\u2208X\nx\u2032\u22a4 [ A\u22121 xt\u22121 \u2212 A\u22121 xt\u22121 xx\u22a4A\u22121 xt\u22121\n1 + x\u22a4A\u22121xt\u22121x\n] x\u2032, (22)\nwhere the second formulation follows from the matrix inversion lemma. This allocation is somehow simpler and more direct than using the continuous relaxation but it may come with a higher efficiency loss.\nBefore reporting the performance guarantees for the two implementations proposed above, we introduce an additional technical lemma which will be useful in the proofs on the performance guarantees. Although the lemma is presented for a specific definition of uncertainty \u03c1, any other notion including design matrices of the kind \u039b\u03bb will satisfy the same guarantee.\nLemma 5. Let \u03c1(\u03bb) = maxx\u2208X x\u22a4\u039b\u22121\u03bb x be a measure of uncertainty of interest for any design \u03bb \u2208 DK . We denote by \u03bb\u2217 = argmin\u03bb\u2208DK \u03c1(\u03bb) the optimal design and for any n > d we introduce the optimal discrete allocation as\nx \u2217 n = arg min\nxn\u2208Xn max x\u2208X\nx\u22a4\u039b\u22121\u03bbxnx\nn ,\nwhere \u03bbxn is the (fractional) design corresponding to xn. Then we have\n\u03c1(\u03bb\u2217) \u2264 \u03c1(x\u2217n) \u2264 ( 1 + p\nn\n) \u03c1(\u03bb\u2217), (23)\nwhere p = supp(\u03bb\u2217) is the number of points in the support of \u03bb\u2217. If d linearly independent arms are available in X , then we can upper bound the size of the support of \u03bb\u2217 and obtain\n\u03c1(\u03bb\u2217) \u2264 \u03c1(x\u2217n) \u2264 ( 1 + d(d+ 1)\nn\n) \u03c1(\u03bb\u2217). (24)\nProof. The first part of the statement follows by the definition of \u03bb\u2217 as the minimizer of \u03c1. Let x\u0303n by an efficient rounding technique applied on \u03bb\u2217 such as the one described in Lemma 12.8 in [15]. Then x\u0303n has the same support as \u03bb\u2217 and an efficiency loss bounded by p/n. As a result, we have\n\u03c1(x\u2217n) \u2264 \u03c1(x\u0303n) \u2264 ( 1 + p\nn\n) \u03c1(\u03bb\u2217),\nwhere the first inequality comes from the fact that x\u2217n is the minimizer of \u03c1 among allocations of length n. Then, from Caratheodory\u2019s theorem (see e.g., [15] ) the number of support points used in \u03bb\u2217 is upper bounded by p \u2264 d(d + 1)/2 + 1 (under the assumption that there are d linearly independent arms in X ). The final result follows by a rough maximization of d(d+1)/2n+1/n \u2264 d(d+ 1)/n.\nRemark 1. Note that the same upper-bound for the number of support points holds for any design, due to the properties of the design matrices. In fact, any design matrix is symmetric by construction, which implies that it is completely described by D = d(d + 1)/2 elements and can thus be seen as a point in RD. Moreover, a design matrix is a convex combination of a subset of points in RD and thus it belongs to the convex hull of that subset of points. Caratheodory\u2019s theorem states that each point in the convex hull of any subset of points in RD can be defined as a convex combination of at\nmost D+1 points. It directly follows that any design matrix can be expressed using (d(d+1)/2)+1 points.\nIt follows that the allocation xG\u0303t obtained applying the rounding procedure has the following performance guarantee. Lemma 6. For any t \u2265 d, the rounding procedure defined in [15, Chapter 12] returns an allocation x G\u0303 t , whose corresponding design \u03bb\nG\u0303 = \u03bb x G\u0303 t is such that5\n\u03c1G(\u03bbG\u0303) \u2264 ( 1 + d+ d2 + 2\n2t\n) d.\nProof of Lemma 6. We follow the same steps as in the proof of Lemma 5 to obtain the term \u03b2 = d+d2+2\n2t . Then, noting that the performance of the optimal strategy \u03c1 G(\u03bb\u2217G) = d (from Prop. 3), the\nresults follows.\nImplementation of the XY-allocation. Notice that the complexity of the XY-allocation trivially follows from the complexity of the G-allocation and it is NP-hard. As a result, we need to propose approximate solutions to compute an allocation xX\u0303Yn as for the G-allocation. Let \u03c1XY(\u03bb) = maxy\u2208Y y\n\u22a4\u039b\u22121\u03bb y, then the first option is the compute the optimal solution to the continuous relaxed problem\n\u03bbXY = arg min \u03bb\u2208Dk max y\u2208Y ||y||2 \u039b\u22121 \u03bb = arg min \u03bb\u2208Dk \u03c1XY(\u03bb). (25)\nAnd then compute the corresponding discrete allocation xX\u0303Yn using the efficient rounding procedure. Alternatively, we can use an incremental greedy algorithm which at each step t returns the arm\nxt = argmin x\u2208X max y\u2208Y\ny\u22a4 ( Axt\u22121 + xx \u22a4 )\u22121 y. (26)\nLemma 7. For any t \u2265 d, the rounding procedure defined in [15, Chapter 12] returns an allocation x X\u0303Y t , whose corresponding design \u03bb\nX\u0303Y = \u03bb x X\u0303Y t is such that\n\u03c1XY(\u03bbX\u0303Y) \u2264 2 ( 1 + d+ d2 + 2\n2t\n) d.\nProof of Lemma 7. The proof follows from the fact that for any pair (x, x\u2032)\n||x\u2212 x\u2032||A\u22121xn \u2264 2 maxx\u2032\u2032\u2208X ||x \u2032\u2032||A\u22121xn .\nThen the proof proceeds as in Lemma 6.\nImplementation of XY-adaptive allocation. The allocation rule in Eq. 17 basically coincides with the XY-allocation and its properties extend smoothly."}, {"heading": "D Proof of Theorem 3", "text": "Before proceeding to the proof, we first report the proofs of two adittional lemmas.\nProof of Lemma 4. Let y = x\u2032 \u2212 x. Using the definition of S\u0302(xn) in Eq. 10, and the fact that \u03b8\u2217 \u2208 S\u0302(xn) with high probability, we have\n(x\u2032 \u2212 x)\u22a4(\u03b8\u0302n \u2212 \u03b8\u2217) \u2264 c||x\u2032 \u2212 x||A\u22121 x \u221a logn(K 2/\u03b4).\nSince the condition in Eq. 16 is true, it follows that\n(x\u2032 \u2212 x)\u22a4(\u03b8\u0302n \u2212 \u03b8\u2217) \u2264 c||x\u2032 \u2212 x||A\u22121x \u221a logn(K\n2/\u03b4) \u2264 \u2206\u0302n(x\u2032, x) \u21d4 \u2212(x\u2032 \u2212 x)\u22a4\u03b8\u2217 \u2264 0 \u21d4 x\u22a4\u03b8\u2217 \u2264 x\u2032\u22a4\u03b8\u2217\nthus x is dominated by x\u2032 and x cannot be the optimal arm.\n5We recall that from any allocation xn the corresponding design \u03bbx is such that \u03bbxn(x) = Tn(x)/n.\nLemma 8. For any phase j, the length is such that nj \u2264 max{M\u2217, 16\u03b1 N\u2217} with probability 1\u2212 \u03b4.\nProof of Lemma 8. We first summarize the different quantities measuring the performance of an allocation strategy in different settings. For any design \u03bb \u2208 DK , we define\n\u03c1\u2217(\u03bb) = max y\u2208Y\u2217\n||y||2 \u039b\u22121\n\u03bb \u22062(y) ; \u03c1XY(\u03bb) = max y\u2208Y ||y||2 \u039b\u22121 \u03bb ; \u03c1j(\u03bb) = max y\u2208Y\u0302j ||y||2 \u039b\u22121 \u03bb . (27)\nFor any n, we also introduce the value of each of the previous quantities when the corresponding optimal (discrete) allocation is used\n\u03c1\u2217n = \u03c1 \u2217(\u03bbx\u2217n); \u03c1 XY n = \u03c1 XY(\u03bb x XY n ); \u03c1jn = \u03c1 j(\u03bb x j n ). (28)\nFinally, we introduce the optimal designs\n\u03bb\u2217 = arg min \u03bb\u2208DK \u03c1\u2217(\u03bb); \u03bbXY = arg min \u03bb\u2208DK \u03c1XY(\u03bb); \u03bbj = arg min \u03bb\u2208DK \u03c1j(\u03bb). (29)\nLet \u01eb\u2217 be the smallest \u01eb such that there exists a pair (x, x\u2032), with x 6= x\u2217 and x\u2032 6= x\u2217, such that the confidence set S = {\u03b8 : \u2200y \u2208 Y, |y\u22a4(\u03b8 \u2212 \u03b8\u2217)| \u2264 \u01eb} overlaps with the hyperplane C(x) \u2229 C(x\u2032). Since M\u2217 is defined as the smallest number of steps needed by the XY strategy to avoid any overlap between S\u2217 and the hyperplanes C(x) \u2229 C(x\u2032), then we have that after M\u2217 steps\nc\n\u221a \u03c1XYM\u2217 logn(K 2/\u03b4)\nM\u2217 < \u01eb\u2217. (30)\nWe consider two cases to study the length of a phase j.\nCase 1: \u221a \u03c1jnj nj \u2265 \u01eb\u2217 c \u221a\nlogn(K 2/\u03b4)\n. From Eq. 30 it immediately follows that\n\u03c1jnj nj \u2265 \u03c1 XY M\u2217 M\u2217 . (31)\nFrom definitions in Eqs. 27 and 28, since Y\u0302j \u2286 Y we have for any n, \u03c1jn \u2264 \u03c1XYn . As a result, if nj \u2265 M\u2217, since \u03c1jn/n is a non-increasing function, then we would have the sequence of inequalities\n\u03c1jnj nj \u2264 \u03c1 j M\u2217 M\u2217 \u2264 \u03c1 XY M\u2217 M\u2217 ,\nwhich contradicts Eq. 31. Thus nj \u2264 M\u2217.\nCase 2: \u221a \u03c1jnj nj \u2264 \u01eb\u2217 c \u221a\nlogn(K 2/\u03b4)\n. We first relate the performance at phase j with the performance of\nthe oracle. For any n\n\u03c1jn = \u03c1 j(\u03bb x j n ) \u2264 \u03c1j(\u03bbx\u2217n) = max\ny\u2208Y\u0302j\ny\u22a4\u039b\u22121\u03bb x \u2217 n y = max y\u2208Y\u0302j\ny\u22a4\u039b\u22121\u03bb x \u2217 n y\n\u22062(y) \u2206(y) \u2264 max\ny\u2208Y\u0302j\ny\u22a4\u039b\u22121\u03bb x \u2217 n y\n\u22062(y) max y\u2208Y\u0302j\n\u22062(y).\nIf now we consider n = nj , then the definition case 2 implies that the estimation error \u221a \u03c1jnj/nj is\nsmall enough so that all the directions in Y\u2212Y\u2217 have already been discarded from Y\u0302j and Y\u0302j \u2286 Y\u2217. Thus\n\u03c1jnj \u2264 maxy\u2208Y\u2217 y\u22a4\u039b\u22121\u03bb x \u2217 nj y\n\u22062(y) max y\u2208Y\u0302j \u22062(y) = \u03c1\u2217nj max y\u2208Y\u0302j \u22062(y). (32)\nThis relationship does not provide a bound on nj yet. We first need to recall from Prop. 1 that for any y \u2208 Y (and notably for the directions in Y\u0302j) we have\n|y\u22a4(\u03b8\u0302j\u22121 \u2212 \u03b8\u2217)| \u2264 c \u221a y\u22a4A\u22121j\u22121y logn(K 2/\u03b4),\nwhere Aj\u22121 = A x j\u22121 nj\u22121 is the matrix constructed from the pulls within phase j \u2212 1. Since xj\u22121n is obtained from a XY-allocation applied on directions in Y\u0302j\u22121, we obtain that for any y \u2208 Y\u0302j\n|y\u22a4(\u03b8\u0302j\u22121 \u2212 \u03b8\u2217)| \u2264 c \u221a logn(K\n2/\u03b4) max y\u2208Y\u0302j\u22121\n\u221a y\u22a4A\u22121j\u22121y = c\n\u221a logn(K\n2/\u03b4)\u03c1j\u22121nj\u22121 nj\u22121 ,\nReordering the terms in the previous expression we have that for any y \u2208 Y\u0302j\n\u2206(y) \u2264 \u2206\u0302j\u22121(y) + c \u221a logn(K 2/\u03b4)\u03c1j\u22121nj\u22121\nnj\u22121 .\nSince the direction y is included in Y\u0302j then the discard condition in Eq. 16 failed for y, implying\nthat \u2206\u0302j\u22121(y) \u2264 c \u221a logn(K 2/\u03b4)\u03c1j\u22121nj\u22121 nj\u22121 . Thus we finally obtain\nmax y\u2208Y\u0302j\n\u2206(y) \u2264 2c \u221a logn(K 2/\u03b4)\u03c1j\u22121nj\u22121\nnj\u22121 .\nCombining this with Eq. 32 we have\n\u03c1jnj \u2264 \u03c1\u2217nj4c2 logn(K 2/\u03b4)\u03c1j\u22121nj\u22121 nj\u22121 .\nUsing the stopping condition of phase j and the relationship between the performance \u03c1j , we obtain that at time n\u0304 = nj \u2212 1\n\u03c1jn\u0304 n\u0304 \u2265 \u03b1 \u03c1j\u22121nj\u22121 nj\u22121 \u2265 \u03b1 4c2 logn(K 2/\u03b4) \u03c1jnj \u03c1\u2217nj\nWe can further refine the previous inequality as\n\u03c1jn\u0304 n\u0304 \u2265 \u03b1\u03c1 \u2217 N\u2217 4N\u2217 N\u2217\nc2 logn(K 2/\u03b4)\u03c1\u2217N\u2217 \u03c1jnj \u03c1\u2217nj \u2265 \u03b1\u03c1 \u2217 N\u2217 4N\u2217 \u03c1jnj \u03c1\u2217nj ,\nwhere we use the definition of N\u2217 in Eq. 7, which implies c \u221a logn(K 2/\u03b4)\u03c1\u2217N\u2217/N \u2217 \u2264 1. Reordering the terms and using n\u0304 = nj \u2212 1, we obtain\nnj \u2264 1 + 4N\u2217\n\u03b1\n\u03c1jnj\u22121\n\u03c1jnj \u03c1\u2217nj \u03c1\u2217N\u2217 .\nFrom Lemma 5 and the optimal designs defined in Eq. 29 we have\nnj \u2264 1 + 4N\u2217\n\u03b1 (1 + d(d+ 1)/(nj \u2212 1))\u03c1j(\u03bbj) \u03c1j(\u03bbj) (1 + d(d + 1)/(nj \u2212 1))\u03c1\u2217(\u03bb\u2217) \u03c1\u2217(\u03bb\u2217) .\nUsing the fact that the algorithm forces nj \u2265 d(d+ 1) + 1, the statement follows.\nProof of Theorem 3. Let J be the index of any phase for which |X\u0302J | > 1. Then there exist at least one arm x \u2208 X (beside x\u2217) for which the discarding condition in Lemma 4 is not triggered, which corresponds to the fact that for all arms x\u2032 \u2208 X\nc||x\u2212 x\u2032||A\u22121 x J nJ\n\u221a logn(K 2/\u03b4) \u2265 \u2206\u0302J(x, x\u2032).\nBy developing the right hand side, we have\n\u2206\u0302J(x, x \u2032) \u2265 \u2206(x, x\u2032)\u2212 c||x\u2212 x\u2032||A\u22121\nx J nJ\n\u221a logn(K 2/\u03b4) \u2265 \u2206min \u2212 c \u221a \u03c1JnJ logn(K 2/\u03b4)\nnJ\nwhich leads to the condition\n2c\n\u221a \u03c1JnJ logn(K 2/\u03b4)\nnJ \u2265 \u2206min. (33)\nUsing the phase stopping condition and the initial value of \u03c10 we have\n\u03c1JnJ nJ \u2264 \u03b1 \u03c1J\u22121nJ\u22121 nJ\u22121 \u2264 \u03b1J \u03c1 0 n0 = \u03b1J .\nBy joining this inequality with Eq. 33 we obtain\n\u03b1J \u2265 \u2206 2 min\n4c2 logn(K 2/\u03b4)\n,\nand it follows that J \u2264 log(4c2 logn(K2/\u03b4)/\u22062min)/ log(1/\u03b1) which together with Lemma 8 leads to the final statement."}, {"heading": "E Additional Empirical Results", "text": "For the setting described in Sec. 6, in order to point out the different repartitions of the sampling budget over arms, in Fig. 5 we present the number of samples allocated per arm, for the case when the input space X \u2286 R5. We remind that the arms denoted x1, . . . , x5 form the canonical basis and arm x6 = [cos(\u03c9) sin(\u03c9) 0 0 0].\nWe can notice that even though the Fully-adaptive algorithm identifies the most informative direction and focuses the sampling on arm x2, its sample complexity still has a growth linear in the dimension, due to the extra \u221a d term in his bound. Consequently, the advantage over the static strategies is canceled. On the other hand, XY-adaptive \u201clearns\u201d the gaps from the observations and allocates the samples very similarly to XY-oracle, without suffering a large loss in terms of the sampling budget. However, XY-adaptive\u2019s sample complexity has to account for the the re-initializations made at the beginning of a new phase.\nFinally, we notice that in this problem that static allocations, XY and G, perform a uniform allocation over the canonical arms. Another interesting remark is that the number of pulls to one canonical arm is smaller than the samples that XY-oracle allocated to x2. This is explained by the \u201cmutual information\u201d coming from the multiple observations on all directions, which helps in reducing the overall uncertainty of the confidence set."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Yasin Abbasi-Yadkori", "D\u00e1vid P\u00e1l", "Csaba Szepesv\u00e1ri"], "venue": "In Proceedings of the 25th Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Best arm identification in multiarmed bandits", "author": ["Jean-Yves Audibert", "S\u00e9bastien Bubeck", "R\u00e9mi Munos"], "venue": "In Proceedings of the 23rd Conference on Learning Theory (COLT),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Using confidence bounds for exploitation-exploration trade-offs", "author": ["Peter Auer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Submodularity and randomized rounding techniques for optimal experimental design", "author": ["Mustapha Bouhtou", "Stephane Gaubert", "Guillaume Sagnol"], "venue": "Electronic Notes in Discrete Mathematics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Pure exploration in multi-armed bandits problems", "author": ["S\u00e9bastien Bubeck", "R\u00e9mi Munos", "Gilles Stoltz"], "venue": "In Proceedings of the 20th International Conference on Algorithmic Learning Theory (ALT),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Multiple identifications in multiarmed bandits", "author": ["S\u00e9bastien Bubeck", "Tengyao Wang", "Nitin Viswanathan"], "venue": "In Proceedings of the International Conference in Machine Learning (ICML),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems", "author": ["Eyal Even-Dar", "Shie Mannor", "Yishay Mansour"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Best arm identification: A unified approach to fixed budget and fixed confidence", "author": ["Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric"], "venue": "In Proceedings of the 26th Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Multi-bandit best arm identification", "author": ["Victor Gabillon", "Mohammad Ghavamzadeh", "Alessandro Lazaric", "S\u00e9bastien Bubeck"], "venue": "In Proceedings of the 25th Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning", "author": ["Matthew D. Hoffman", "Bobak Shahriari", "Nando de Freitas"], "venue": "In Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "lil\u2019 UCB : An optimal exploration algorithm for multi-armed bandits", "author": ["Kevin G. Jamieson", "Matthew Malloy", "Robert Nowak", "S\u00e9bastien Bubeck"], "venue": "In Proceeding of the 27th Conference on Learning Theory (COLT),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Information complexity in bandit subset selection", "author": ["Emilie Kaufmann", "Shivaram Kalyanakrishnan"], "venue": "In Proceedings of the 26th Conference on Learning Theory (COLT),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "The equivalence of two extremum problems", "author": ["Jack Kiefer", "Jacob Wolfowitz"], "venue": "Canadian Journal of Mathematics,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1960}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["Lihong Li", "Wei Chu", "John Langford", "Robert E. Schapire"], "venue": "In Proceedings of the 19th International Conference on World Wide Web (WWW),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Optimal Design of Experiments", "author": ["Friedrich Pukelsheim"], "venue": "Classics in Applied Mathematics. Society for Industrial and Applied Mathematics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Some aspects of the sequential design of experiments", "author": ["Herbert Robbins"], "venue": "Bulletin of the American Mathematical Society,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1952}, {"title": "Approximation of a maximum-submodular-coverage problem involving spectral functions, with application to experimental designs", "author": ["Guillaume Sagnol"], "venue": "Discrete Appl. Math.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}], "referenceMentions": [{"referenceID": 15, "context": "The stochastic multi-armed bandit problem (MAB) [16] offers a simple formalization for the study of sequential design of experiments.", "startOffset": 48, "endOffset": 52}, {"referenceID": 4, "context": "While most of the literature in bandit theory focused on the problem of maximization of cumulative rewards, where the learner needs to trade-off exploration and exploitation, recently the pure exploration setting [5] has gained a lot of attention.", "startOffset": 213, "endOffset": 216}, {"referenceID": 1, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 44, "endOffset": 51}, {"referenceID": 10, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 44, "endOffset": 51}, {"referenceID": 6, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 73, "endOffset": 76}, {"referenceID": 5, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 95, "endOffset": 102}, {"referenceID": 11, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 95, "endOffset": 102}, {"referenceID": 8, "context": ", best-arm identification with fixed budget [2, 11] and fixed confidence [7], subset selection [6, 12], and multi-bandit [9]), most of the work considered only the multi-armed setting, with K independent arms.", "startOffset": 121, "endOffset": 124}, {"referenceID": 2, "context": "An interesting variant of the MAB setup is the stochastic linear bandit problem (LB), introduced in [3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 0, "context": ", [1, 14]), in this paper we focus on the pure-exploration scenario.", "startOffset": 2, "endOffset": 9}, {"referenceID": 13, "context": ", [1, 14]), in this paper we focus on the pure-exploration scenario.", "startOffset": 2, "endOffset": 9}, {"referenceID": 9, "context": "Recently, the best-arm identification in linear bandits has been studied in a fixed budget setting [10], in this paper we study the sample complexity required to identify the best-linear arm with a fixed confidence.", "startOffset": 99, "endOffset": 103}, {"referenceID": 7, "context": "While different settings can be defined (see [8] for an overview), here we focus on the (\u01eb, \u03b4)-best-arm identification problem (the so-called PAC setting), where given \u01eb and \u03b4 \u2208 (0, 1), the objective is to design an allocation strategy and a stopping criterion so that when the algorithm stops, the returned arm x\u0302(n) is such that P ( Rn \u2265 \u01eb ) \u2264 \u03b4, while minimizing the needed number of steps.", "startOffset": 45, "endOffset": 48}, {"referenceID": 1, "context": "In the fixed budget case, HMAB determines the probability of returning the wrong arm [2], while in the fixed confidence case, it characterizes the sample complexity [7].", "startOffset": 85, "endOffset": 88}, {"referenceID": 6, "context": "In the fixed budget case, HMAB determines the probability of returning the wrong arm [2], while in the fixed confidence case, it characterizes the sample complexity [7].", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "2 in [1]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": "12 (see [4, 17] for some recent results and [18] for a more thorough discussion).", "startOffset": 8, "endOffset": 15}, {"referenceID": 16, "context": "12 (see [4, 17] for some recent results and [18] for a more thorough discussion).", "startOffset": 8, "endOffset": 15}], "year": 2014, "abstractText": "We study the best-arm identification problem in linear bandit, where the rewards of the arms depend linearly on an unknown parameter \u03b8 and the objective is to return the arm with the largest reward. We characterize the complexity of the problem and introduce sample allocation strategies that pull arms to identify the best arm with a fixed confidence, while minimizing the sample budget. In particular, we show the importance of exploiting the global linear structure to improve the estimate of the reward of near-optimal arms. We analyze the proposed strategies and compare their empirical performance. Finally, as a by-product of our analysis, we point out the connection to the G-optimality criterion used in optimal experimental design.", "creator": "LaTeX with hyperref package"}}}