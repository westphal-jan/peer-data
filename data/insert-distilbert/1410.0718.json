{"id": "1410.0718", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Oct-2014", "title": "Not All Neural Embeddings are Born Equal", "abstract": "neural language models learn word representations that together capture rich linguistic and conceptual information. here we investigate the embeddings learned by neural machine translation models. we show that translation - based auditory embeddings outperform those learned by cutting - to edge monolingual recognition models at single - language tasks requiring tighter knowledge management of more conceptual similarity assignment and / or syntactic role. the findings suggest that, while monolingual models learn information about how many concepts are related, neural - translation models better themselves capture their true ontological status.", "histories": [["v1", "Thu, 2 Oct 2014 21:35:35 GMT  (23kb,D)", "http://arxiv.org/abs/1410.0718v1", "4 pages plus 1 page of references"], ["v2", "Thu, 13 Nov 2014 15:58:35 GMT  (83kb,D)", "http://arxiv.org/abs/1410.0718v2", "4 pages plus 1 page of references"]], "COMMENTS": "4 pages plus 1 page of references", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["felix hill", "kyunghyun cho", "sebastien jean", "coline devin", "yoshua bengio"], "accepted": false, "id": "1410.0718"}, "pdf": {"name": "1410.0718.pdf", "metadata": {"source": "CRF", "title": "Not All Neural Embeddings are Born Equal", "authors": ["Felix Hill", "KyungHyun Cho"], "emails": [], "sections": [{"heading": null, "text": "It is well known that word representations can be learned from the distributional patterns in corpora. Originally, such representations were constructed by counting word co-occurrences, so that the features in one word\u2019s representation corresponded to other words [13, 19]. Neural language models, an alternative means to learn word representations, use language data to optimise (latent) features with respect to a language modelling objective. The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17]. The representations learned by neural models (sometimes called embeddings) generally outperform those acquired by co-occurence counting models when applied to NLP tasks [3].\nDespite these clear results, it is not well understood how the architecture of neural models affects the information encoded in their embeddings. Here, we explore this question by considering the embeddings learned by architectures with a very different objective function to monolingual language models: neural machine translation models. We show that translation-based embeddings outperform monolingual embeddings on two types of task: those that require knowledge of conceptual similarity (rather than simply association or relatedness), and those that require knowledge of syntactic role. We discuss what the findings indicate about the information content of different embeddings, and suggest how this content might emerge as a consequence of the translation objective."}, {"heading": "1 Learning embeddings from language data", "text": "Both neural language models and translation models learn real-valued embeddings (of specified dimension) for words in some pre-specified vocabulary, V , covering many or all words in their training corpus. At each training step, a \u2018score\u2019 for the current training example (or batch) is computed based on the embeddings in their current state. This score is compared to the model\u2019s objective function, and the error is backpropagated to update both the model weights (affecting how the score is computed from the embeddings) and the embedding features. At the end of this process, the embeddings should encode information that enables the model to optimally satisfy its objective."}, {"heading": "1.1 Monolingual models", "text": "In the original neural language model [4] and subsequent variants [9], each training example consists of n subsequent words, of which the model is trained to predict the n-th word given the first n \u2212\nar X\niv :1\n41 0.\n07 18\nv1 [\ncs .C\nL ]\n2 O\nct 2\n1 words. The model first represents the input as an ordered sequence of embeddings, which it transforms into a single fixed length \u2018hidden\u2019 representation by, e.g., concatenation and non-linear projection. Based on this representation, a probability distribution is computed over the vocabulary, from which the model can sample a guess at the next word. The model weights and embeddings are updated to maximise the probability of correct guesses for all sentences in the training corpus.\nMore recent work has shown that high quality word embeddings can be learned via models with no nonlinear hidden layer [15, 17]. Given a single word in the corpus, these models simply predict which other words will occur nearby. For each word w in V , a list of training cases (w, c) : c \u2208 V is extracted from the training corpus. For instance, in the skipgram approach [15], for each \u2018cue word\u2019 w the \u2018context words\u2019 c are sampled from windows either side of tokens of w in the corpus (with c more likely to be sampled if it occurs closer to w).1 For each w in V , the model initialises both a cue-embedding, representing the w when it occurs as a cue-word, and a context-embedding, used when w occurs as a context-word. For a cue word w, the model can use the corresponding cueembedding and all context-embeddings to compute a probability distribution over V that reflects the probability of a word occurring in the context of w. When a training example (w, c) is observed, the model updates both the cue-word embedding of w and the context-word embeddings in order to increase the conditional probability of c."}, {"heading": "1.2 Translation-based embeddings", "text": "Neural translation models generate an appropriate sentence in their target language St given a sentence Ss in their source language [see, e.g., 18, 6]. In doing so, they learn distinct sets of embeddings for the vocabularies Vs and Vt in the source and target languages respectively.\nObserving a training case (Ss, St), such a model represents Ss as an ordered sequence of embeddings of words from Vs. The sequence for Ss is then encoded into a single representation RS .2 Finally, by referencing the embeddings in Vt, RS and a representation of what has been generated thus far, the model decodes a sentence in the target language word by word. If at any stage the decoded word does not match the corresponding word in the training target St, the error is recorded. The weights and embeddings in the model, which together parameterise the encoding and decoding process, are updated based on the accumulated error once the sentence decoding is complete.\nDespite differences in architecture, the translation objective results in similar pressures being exerted on the embeddings for both models. The source language embeddings must be such that the model can combine them to form single representations for ordered sequences of multiple words (which in turn must enable the decoding process). The target language embeddings must facilitate the process of decoding these representations into correct target-language sentences."}, {"heading": "2 Comparing Mono-lingual and Translation-based Embeddings", "text": "To learn translation-based embeddings, we trained both the RNN encoder-decoder [RNNenc, 7] and the RNN Search architectures [2] on a 300m word corpus of English-French sentence pairs. We conducted all experiments with the resulting (English) source embeddings from these models. For comparison, we trained a monolingual skipgram model [14] and its Glove variant [17] for the same number of epochs on the English half of the bilingual corpus. We also extracted embeddings from a full-sentence language model [CW, 8] trained for several months on a larger 1bn word corpus.\nAs in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances and correlating these distances with (gold-standard) human judgements. Table 1 shows the correlations of different model embeddings with three such gold-standard resources, WordSim-353 [1], MEN [5] and SimLex-999 [11]. Interestingly, translation embeddings perform best on SimLex-999, while the two sets of monolingual embeddings perform better on modelling the MEN and WordSim353. To interpret these results, it should be noted that SimLex-999 evaluation quantifies conceptual similarity (dog - wolf ), whereas MEN and WordSim-353 (despite its name) quantify more general relatedness (dog - collar) [12]. The results seem to indicate that translation-based embeddings better capture similarity, while monolingual embeddings better capture relatedness.\n1 Subsequent variants apply different algorithms for selecting the set of (w, c) from the training corpus [10] 2Alternatively, subsequences (phrases) of Ss may be encoded at this stage in place of the whole sentence [2].\nTo test this hypothesis further, we ran two more evaluations focused specifically on similarity. The TOEFL synonym test contains 80 cue words, each with four possible answers, of which one is a correct synonym [13]. We computed the proportion of questions answered correctly by each model, where a model\u2019s answer was the nearest (cosine) neighbour to the cue word in its vocabulary.3 In addition, we tested how well different embeddings enabled a supervised classifier to distinguish between synonyms and antonyms. For 500 hand-labelled pairs we presented a Guassian SVM with the concatenation of the two word embeddings. We evaluated accuracy using 8-fold cross-validation.\nAs shown in Table 1, translation-based embeddings outperform all monolingual embeddings on these two additional similarity-focused tasks. Qualitative analysis of nearest neighbours (bottom rows) also supports the conclusion that proximity in the translation embedding space corresponds to similarity while proximity in the monolingual embedding space reflects relatedness."}, {"heading": "2.1 Quantity of training data", "text": "In previous work, monolingual models were trained on corpora many times larger than the English half of our parallel translation corpus. To check if these models simply need more training data to capture similarity as effectively as translation models, we trained them on increasingly large subsets of Wikipedia.4 The results refute this possibility: the performance of monolingual embeddings on similarity tasks converges well below the level of the translation-based embeddings (Fig. 1)."}, {"heading": "2.2 Analogy questions", "text": "Lexical analogy questions are an alternative way of evaluating word representations [15, 17]. In this task, models must identify the correct answer (girl) when presented with questions such as \u2018man is to boy as woman is to ...\u2019. For skipgram-style embeddings, it has been shown that if m,b and w are the embeddings for man, boy and woman respectively, the correct answer is often the nearest neighbour in the vocabulary (by cosine distance) to the vector v = w + b\u2212m [14].\n3To control for different vocabularies, we restricted the effective vocabulary of each model to the intersection of all model vocabularies, and excluded all questions that contained an answer outiside of this intersection.\n4 We could not do the same for the translation models because of the scarcity of bilingual corpora.\nWe evaluated the embeddings on this task using the same vector-algebra method as [14]. As before we excluded questions containing a word outside the intersection of all model vocabularies, and restricted all answer searches to this reduced vocabulary, leaving 11,166 analogies. Of these, 7219 are classed as \u2018syntactic\u2019, in that they exemplify mappings between parts-of-speech or syntactic roles (fast, fastest; heavy \u2014 heaviest), and 3947 are classed as \u2018semantic\u2018 (Ottawa, Canada; Paris \u2014 France), deriving from wider world knowledge. As shown in Fig. 2, the translation-based embeddings seem to yield poor answers to semantic analogy questions, but are very effective for syntactic analogies, outperforming the monolingual embeddings, even those trained on much more data."}, {"heading": "3 Conclusions", "text": "Neural machine translation models are more effective than monolingual models at learning embeddings that encode information about concept similarity and syntactic role. In contrast, monolingual models encode general inter-concept relatedness (as applicable to semantic analogy questions), but struggle to capture similarity, even when training on larger corpora. For skipgram-style models, whose objective is to predict linguistically collocated pairs, this limitation is perhaps unsurprising, since co-occurring words are, in general, neither semantically nor syntactically similar. However, the fact that it also applies to the full-sentence model CW suggests that inferring similarity is problematic for monolingual models even with knowledge of the precise (ordered) contexts of words. This may be because very dissimilar words (such as antonyms) actually often occur in identical linguistic contexts.\nWhen considering the strengths of translation embeddings - similarity and syntactic role - it is notable that each item in the three similarity-focused evaluations consists of word groups or pairs of identical syntactic role. Thus, the strong performance of translation embeddings on similarity tasks cannot be simply a result of their encoding of richer syntactic information. To perform well on SimLex-999, embeddings must encode information approximating what concepts are (their function or ontology), even when this contradicts the signal conferred by co-occurrence (as can be the case for related-but-dissimilar concept pairs) [11]. The translation objective seems particularly effective at inducing models to encode such ontological or functional information in word embeddings.\nWhile much remains unknown about this process, one cause might be the different ways in which words partition the meaning space of a language. In cases where a French word has two possible English translations (e.g. gagner \u2192 win / earn), we note that the (source) embeddings of the two English words are very close. It appears that, since the translation model, which has limited encoding capacity, is trained to map tokens of win and earn to the same place in the target embedding space, it is efficient to move these concepts closer in the source space. While clear-cut differences in how languages partition meaning space, such as (gagner = win, earn), may in fact be detrimental to similarity modelling (win and earn are not synonymous to English speakers), in general, languages partition meaning space in less drastically different ways. We hypothesize that these small differences are the key to how neural translation models approximate ontological similarity so effectively. At the same time, since two dissimilar or even antonymous words in the source language should never correspond to a single word in the target language, these pairs diverge in the embedding space, rendering two antonymous embeddings easily distinguishable from those of two synonyms."}], "references": [{"title": "A study on similarity and relatedness using distributional and wordnet-based approaches", "author": ["Eneko Agirre", "Enrique Alfonseca", "Keith Hall", "Jana Kravalova", "Marius Pasca", "Aitor Soroa"], "venue": "In Proceedings of NAACL-HLT", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "[cs.CL],", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2003}, {"title": "Multimodal distributional semantics", "author": ["Elia Bruni", "Nam-Khanh Tran", "Marco Baroni"], "venue": "J. Artif. Intell. Res.(JAIR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder\u2013Decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": "In Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "In Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Natural language processing (almost) from scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Learning abstract concepts from multi-modal data: Since you probably can\u2019t see what i mean", "author": ["Felix Hill", "Anna Korhonen"], "venue": "In Proceedings of EMNLP 2014,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": "[cs.CL],", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": "arXiv preprint arXiv:1408.3456,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "A solution to plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["Thomas K Landauer", "Susan T Dumais"], "venue": "Psychological review,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1997}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "A scalable hierarchical distributed language model", "author": ["Andriy Mnih", "Geoffrey E Hinton"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning"], "venue": "In Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Anonymized. In Anonymized", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc Le"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Peter D Turney", "Patrick Pantel"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}], "referenceMentions": [{"referenceID": 12, "context": "Originally, such representations were constructed by counting word co-occurrences, so that the features in one word\u2019s representation corresponded to other words [13, 19].", "startOffset": 161, "endOffset": 169}, {"referenceID": 18, "context": "Originally, such representations were constructed by counting word co-occurrences, so that the features in one word\u2019s representation corresponded to other words [13, 19].", "startOffset": 161, "endOffset": 169}, {"referenceID": 3, "context": "The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17].", "startOffset": 91, "endOffset": 101}, {"referenceID": 15, "context": "The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17].", "startOffset": 91, "endOffset": 101}, {"referenceID": 8, "context": "The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17].", "startOffset": 91, "endOffset": 101}, {"referenceID": 14, "context": "The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17].", "startOffset": 151, "endOffset": 159}, {"referenceID": 16, "context": "The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17].", "startOffset": 151, "endOffset": 159}, {"referenceID": 2, "context": "The representations learned by neural models (sometimes called embeddings) generally outperform those acquired by co-occurence counting models when applied to NLP tasks [3].", "startOffset": 169, "endOffset": 172}, {"referenceID": 3, "context": "In the original neural language model [4] and subsequent variants [9], each training example consists of n subsequent words, of which the model is trained to predict the n-th word given the first n \u2212", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "In the original neural language model [4] and subsequent variants [9], each training example consists of n subsequent words, of which the model is trained to predict the n-th word given the first n \u2212", "startOffset": 66, "endOffset": 69}, {"referenceID": 14, "context": "More recent work has shown that high quality word embeddings can be learned via models with no nonlinear hidden layer [15, 17].", "startOffset": 118, "endOffset": 126}, {"referenceID": 16, "context": "More recent work has shown that high quality word embeddings can be learned via models with no nonlinear hidden layer [15, 17].", "startOffset": 118, "endOffset": 126}, {"referenceID": 14, "context": "For instance, in the skipgram approach [15], for each \u2018cue word\u2019 w the \u2018context words\u2019 c are sampled from windows either side of tokens of w in the corpus (with c more likely to be sampled if it occurs closer to w).", "startOffset": 39, "endOffset": 43}, {"referenceID": 1, "context": "To learn translation-based embeddings, we trained both the RNN encoder-decoder [RNNenc, 7] and the RNN Search architectures [2] on a 300m word corpus of English-French sentence pairs.", "startOffset": 124, "endOffset": 127}, {"referenceID": 13, "context": "For comparison, we trained a monolingual skipgram model [14] and its Glove variant [17] for the same number of epochs on the English half of the bilingual corpus.", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "For comparison, we trained a monolingual skipgram model [14] and its Glove variant [17] for the same number of epochs on the English half of the bilingual corpus.", "startOffset": 83, "endOffset": 87}, {"referenceID": 0, "context": "As in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances and correlating these distances with (gold-standard) human judgements.", "startOffset": 23, "endOffset": 32}, {"referenceID": 4, "context": "As in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances and correlating these distances with (gold-standard) human judgements.", "startOffset": 23, "endOffset": 32}, {"referenceID": 2, "context": "As in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances and correlating these distances with (gold-standard) human judgements.", "startOffset": 23, "endOffset": 32}, {"referenceID": 0, "context": "Table 1 shows the correlations of different model embeddings with three such gold-standard resources, WordSim-353 [1], MEN [5] and SimLex-999 [11].", "startOffset": 114, "endOffset": 117}, {"referenceID": 4, "context": "Table 1 shows the correlations of different model embeddings with three such gold-standard resources, WordSim-353 [1], MEN [5] and SimLex-999 [11].", "startOffset": 123, "endOffset": 126}, {"referenceID": 10, "context": "Table 1 shows the correlations of different model embeddings with three such gold-standard resources, WordSim-353 [1], MEN [5] and SimLex-999 [11].", "startOffset": 142, "endOffset": 146}, {"referenceID": 11, "context": "To interpret these results, it should be noted that SimLex-999 evaluation quantifies conceptual similarity (dog - wolf ), whereas MEN and WordSim-353 (despite its name) quantify more general relatedness (dog - collar) [12].", "startOffset": 218, "endOffset": 222}, {"referenceID": 9, "context": "1 Subsequent variants apply different algorithms for selecting the set of (w, c) from the training corpus [10] Alternatively, subsequences (phrases) of Ss may be encoded at this stage in place of the whole sentence [2].", "startOffset": 106, "endOffset": 110}, {"referenceID": 1, "context": "1 Subsequent variants apply different algorithms for selecting the set of (w, c) from the training corpus [10] Alternatively, subsequences (phrases) of Ss may be encoded at this stage in place of the whole sentence [2].", "startOffset": 215, "endOffset": 218}, {"referenceID": 12, "context": "The TOEFL synonym test contains 80 cue words, each with four possible answers, of which one is a correct synonym [13].", "startOffset": 113, "endOffset": 117}, {"referenceID": 14, "context": "Lexical analogy questions are an alternative way of evaluating word representations [15, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 16, "context": "Lexical analogy questions are an alternative way of evaluating word representations [15, 17].", "startOffset": 84, "endOffset": 92}, {"referenceID": 13, "context": "For skipgram-style embeddings, it has been shown that if m,b and w are the embeddings for man, boy and woman respectively, the correct answer is often the nearest neighbour in the vocabulary (by cosine distance) to the vector v = w + b\u2212m [14].", "startOffset": 238, "endOffset": 242}, {"referenceID": 13, "context": "We evaluated the embeddings on this task using the same vector-algebra method as [14].", "startOffset": 81, "endOffset": 85}, {"referenceID": 10, "context": "To perform well on SimLex-999, embeddings must encode information approximating what concepts are (their function or ontology), even when this contradicts the signal conferred by co-occurrence (as can be the case for related-but-dissimilar concept pairs) [11].", "startOffset": 255, "endOffset": 259}], "year": 2017, "abstractText": "Neural language models learn word representations that capture rich linguistic and conceptual information. Here we investigate the embeddings learned by neural machine translation models. We show that translation-based embeddings outperform those learned by cutting-edge monolingual models at single-language tasks requiring knowledge of conceptual similarity and/or syntactic role. The findings suggest that, while monolingual models learn information about how concepts are related, neural-translation models better capture their true ontological status. It is well known that word representations can be learned from the distributional patterns in corpora. Originally, such representations were constructed by counting word co-occurrences, so that the features in one word\u2019s representation corresponded to other words [13, 19]. Neural language models, an alternative means to learn word representations, use language data to optimise (latent) features with respect to a language modelling objective. The objective can be to predict either the next word given the initial words of a sentence [4, 16, 9], or simply a nearby word given a single cue word [15, 17]. The representations learned by neural models (sometimes called embeddings) generally outperform those acquired by co-occurence counting models when applied to NLP tasks [3]. Despite these clear results, it is not well understood how the architecture of neural models affects the information encoded in their embeddings. Here, we explore this question by considering the embeddings learned by architectures with a very different objective function to monolingual language models: neural machine translation models. We show that translation-based embeddings outperform monolingual embeddings on two types of task: those that require knowledge of conceptual similarity (rather than simply association or relatedness), and those that require knowledge of syntactic role. We discuss what the findings indicate about the information content of different embeddings, and suggest how this content might emerge as a consequence of the translation objective. 1 Learning embeddings from language data Both neural language models and translation models learn real-valued embeddings (of specified dimension) for words in some pre-specified vocabulary, V , covering many or all words in their training corpus. At each training step, a \u2018score\u2019 for the current training example (or batch) is computed based on the embeddings in their current state. This score is compared to the model\u2019s objective function, and the error is backpropagated to update both the model weights (affecting how the score is computed from the embeddings) and the embedding features. At the end of this process, the embeddings should encode information that enables the model to optimally satisfy its objective. 1.1 Monolingual models In the original neural language model [4] and subsequent variants [9], each training example consists of n subsequent words, of which the model is trained to predict the n-th word given the first n \u2212 1 ar X iv :1 41 0. 07 18 v1 [ cs .C L ] 2 O ct 2 01 4 1 words. The model first represents the input as an ordered sequence of embeddings, which it transforms into a single fixed length \u2018hidden\u2019 representation by, e.g., concatenation and non-linear projection. Based on this representation, a probability distribution is computed over the vocabulary, from which the model can sample a guess at the next word. The model weights and embeddings are updated to maximise the probability of correct guesses for all sentences in the training corpus. More recent work has shown that high quality word embeddings can be learned via models with no nonlinear hidden layer [15, 17]. Given a single word in the corpus, these models simply predict which other words will occur nearby. For each word w in V , a list of training cases (w, c) : c \u2208 V is extracted from the training corpus. For instance, in the skipgram approach [15], for each \u2018cue word\u2019 w the \u2018context words\u2019 c are sampled from windows either side of tokens of w in the corpus (with c more likely to be sampled if it occurs closer to w).1 For each w in V , the model initialises both a cue-embedding, representing the w when it occurs as a cue-word, and a context-embedding, used when w occurs as a context-word. For a cue word w, the model can use the corresponding cueembedding and all context-embeddings to compute a probability distribution over V that reflects the probability of a word occurring in the context of w. When a training example (w, c) is observed, the model updates both the cue-word embedding of w and the context-word embeddings in order to increase the conditional probability of c. 1.2 Translation-based embeddings Neural translation models generate an appropriate sentence in their target language St given a sentence Ss in their source language [see, e.g., 18, 6]. In doing so, they learn distinct sets of embeddings for the vocabularies Vs and Vt in the source and target languages respectively. Observing a training case (Ss, St), such a model represents Ss as an ordered sequence of embeddings of words from Vs. The sequence for Ss is then encoded into a single representation RS .2 Finally, by referencing the embeddings in Vt, RS and a representation of what has been generated thus far, the model decodes a sentence in the target language word by word. If at any stage the decoded word does not match the corresponding word in the training target St, the error is recorded. The weights and embeddings in the model, which together parameterise the encoding and decoding process, are updated based on the accumulated error once the sentence decoding is complete. Despite differences in architecture, the translation objective results in similar pressures being exerted on the embeddings for both models. The source language embeddings must be such that the model can combine them to form single representations for ordered sequences of multiple words (which in turn must enable the decoding process). The target language embeddings must facilitate the process of decoding these representations into correct target-language sentences. 2 Comparing Mono-lingual and Translation-based Embeddings To learn translation-based embeddings, we trained both the RNN encoder-decoder [RNNenc, 7] and the RNN Search architectures [2] on a 300m word corpus of English-French sentence pairs. We conducted all experiments with the resulting (English) source embeddings from these models. For comparison, we trained a monolingual skipgram model [14] and its Glove variant [17] for the same number of epochs on the English half of the bilingual corpus. We also extracted embeddings from a full-sentence language model [CW, 8] trained for several months on a larger 1bn word corpus. As in previous studies [1, 5, 3], we evaluate embeddings by calculating pairwise (cosine) distances and correlating these distances with (gold-standard) human judgements. Table 1 shows the correlations of different model embeddings with three such gold-standard resources, WordSim-353 [1], MEN [5] and SimLex-999 [11]. Interestingly, translation embeddings perform best on SimLex-999, while the two sets of monolingual embeddings perform better on modelling the MEN and WordSim353. To interpret these results, it should be noted that SimLex-999 evaluation quantifies conceptual similarity (dog wolf ), whereas MEN and WordSim-353 (despite its name) quantify more general relatedness (dog collar) [12]. The results seem to indicate that translation-based embeddings better capture similarity, while monolingual embeddings better capture relatedness. 1 Subsequent variants apply different algorithms for selecting the set of (w, c) from the training corpus [10] Alternatively, subsequences (phrases) of Ss may be encoded at this stage in place of the whole sentence [2].", "creator": "LaTeX with hyperref package"}}}