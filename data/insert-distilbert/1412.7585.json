{"id": "1412.7585", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2014", "title": "Converting Instance Checking to Subsumption: A Rethink for Object Queries over Practical Ontologies", "abstract": "efficiently querying description logic ( dl ) ontologies is simultaneously becoming a vital task in various data - intensive dl applications. considered as a basic service for answering object queries over dl ontologies, instance checking can be realized by using the most specific concept ( msc ) search method, which converts instance checking into subsumption problems. this method, however, loses its simplicity and efficiency when applied to large and complex ontologies, as it tends to generate very large msc'parameter s that could lead to intractable reasoning. in this paper, we propose a revision to this additional msc method for dl shi, allowing it to generate much to simpler and rather smaller concepts that are specific - enough to answer a given query. with independence between computed msc's, scalability for query answering can also be achieved by distributing and parallelizing the computations. an empirical mba evaluation shows up the efficacy of our revised msc method and the significant efficiency achieved when considering using it for manually answering object queries.", "histories": [["v1", "Wed, 24 Dec 2014 02:18:01 GMT  (329kb,D)", "https://arxiv.org/abs/1412.7585v1", "International Journal of Intelligence Science, 2014"], ["v2", "Tue, 17 Feb 2015 20:23:48 GMT  (329kb,D)", "http://arxiv.org/abs/1412.7585v2", null], ["v3", "Thu, 26 Feb 2015 17:18:41 GMT  (329kb,D)", "http://arxiv.org/abs/1412.7585v3", null]], "COMMENTS": "International Journal of Intelligence Science, 2014", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jia xu", "patrick shironoshita", "ubbo visser", "nigel john", "mansur kabuka"], "accepted": true, "id": "1412.7585"}, "pdf": {"name": "1412.7585.pdf", "metadata": {"source": "CRF", "title": "Converting Instance Checking to Subsumption: A Rethink for Object Queries over Practical Ontologies", "authors": ["Jia Xu", "Patrick Shironoshita", "Ubbo Visser", "Nigel John", "Mansur Kabuka"], "emails": ["j.xu11@umiami.edu"], "sections": [{"heading": null, "text": "1 Converting Instance Checking to Subsumption: A Rethink for Object Queries over Practical Ontologies\nJia Xu, Patrick Shironoshita, Ubbo Visser, Nigel John, and Mansur Kabuka\nAbstract\u2014Efficiently querying Description Logic (DL) ontologies is becoming a vital task in various data-intensive DL applications. Considered as a basic service for answering object queries over DL ontologies, instance checking can be realized by using the most specific concept (MSC) method, which converts instance checking into subsumption problems. This method, however, loses its simplicity and efficiency when applied to large and complex ontologies, as it tends to generate very large MSC\u2019s that could lead to intractable reasoning. In this paper, we propose a revision to this MSC method for DL SHI, allowing it to generate much simpler and smaller concepts that are specific-enough to answer a given query. With independence between computed MSC\u2019s, scalability for query answering can also be achieved by distributing and parallelizing the computations. An empirical evaluation shows the efficacy of our revised MSC method and the significant efficiency achieved when using it for answering object queries.\nIndex Terms\u2014Description Logic, Query, Ontology, SHI, MSC\nF"}, {"heading": "1 INTRODUCTION", "text": "D ESCRIPTION logics (DLs) play an ever-growingrole in providing a formal and semantic-rich way to model and represent (semi-) structured data in various applications, including semantic web, healthcare, and biomedical research, etc [1]. A knowledge base in description logic, usually referred to as a DL ontology, consists of an assertional component (ABox A) for data description, where individuals (single objects) are introduced and their mutual relationships are described using assertional axioms. Semantic meaning of the ABox data can then be unambiguously specified by a terminological component (TBox T ) of the DL ontology, where abstract concepts and roles (binary relations) of the application domain are properly defined.\nIn various applications of description logics, one of the core tasks for DL systems is to provide an efficient way to manage and query the assertional knowledge (i.e. ABox data) in a DL ontology, especially for those data-intensive applications; and DL systems are expected to scale well with respect to (w.r.t.) the fast growing ABox data, in settings such as semantic webs or biomedical systems. The most basic reasoning service provided by existing DL systems for retrieving objects from ontology ABoxes is instance checking, which tests whether an individual is member of a given concept. Instance retrieval (i.e. retrieve all instances of a given concept) then can be realized by performing a set of instance checking calls.\nIn recent years, considerable efforts have been dedicated to the optimization of algorithms for ontology reasoning and query answering [2], [3], [4]. However,\n\u2022 J. Xu, P. Shironoshita, U. Visser, N. John, and M. Kabuka are all with University of Miami, Coral Gables, FL 33146. Corresponding E-mail: j.xu11@umiami.edu\ndue to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.g. up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13]. In practice, since the TBox and the query are usually much smaller comparing with the ABox, the reasoning efficiency could be mostly affected by the size of the ABox.\nOne of the solutions to this reasoning scalability problem is to develop a much more efficient algorithm that can easily handle large amount of ABox data. While another one is to reduce size of the data by either partitioning the ABox into small and independent fragments that can be easily handled in parallel by existing systems [14], [15], [16], or converting the ABox reasoning into a TBox reasoning task (i.e. ontology reasoning without an ABox), which could be \u201csomewhat\u201d independent of the data size, if the TBox is static and relatively simple, as demonstrated in this paper.\nA common intuition about converting instance checking into a TBox reasoning task is the so-called most specific concept (MSC) method [17], [10], [18] that computes the MSC of a given individual and reduces any instance checking of this individual into a subsumption test (i.e. test if one concept is more general than the other). More precisely, for a given individual, its most specific concept should summarize all information of the individual in a given ontology ABox, and should be specific enough to be subsumed by any concept that the individual belongs to. Therefore, once the most specific concept C of an individual a is\nar X\niv :1\n41 2.\n75 85\nv3 [\ncs .A\nI] 2\n6 Fe\nb 20\n15\n2 known, in order to check if a is instance of any given concept D, it is sufficient to test if C is subsumed by D. With the MSC of every individual in the ABox, the efficiency of online object queries can then be boosted by performing an offline classification of all MSC\u2019s that can pre-compute many instance checks [10]. Moreover, if a large ontology ABox consists of data with great diversity and isolation, using the MSC method for instance checking could be more efficient than the original ABox reasoning, since the MSC would have the tableau algorithm to explore only the related information of the given individual, poten-\ntially restricted to a small subset of the ABox. Also, this method allows the reasoning to be parallelized and distributed, since MSC\u2019s are independent of each other and each preserves complete information of the corresponding individual.\nDespite these appealing properties possessed by the MSC method, the computation of a MSC could be difficult even for a very simple description logic such as ALE . The difficulty arises mainly from the support of qualified existential restrictions (e.g. \u2203R.C) in DLs, such that when converting a role assertion (e.g. R(a, b)) of some individual into an existential restriction, information of that given individual may not be preserved completely. For a simple example, consider converting assertions\nR(a, a) and A(a)\ninto a concept for individual a. In this case, we can always find a more specific concept for a in the form of\nA u \u2203R.\u2203R. \u00b7 \u00b7 \u00b7 \u2203R\ufe38 \ufe37\ufe37 \ufe38 n .A\nby increasing n, and none of them would capture the complete information of individual a. Such information loss is due to the occurrence of cycles in the role assertions, and none of the existential restrictions in DL could impose a circular interpretation (model) unless nominals (e.g. {a}) are involved or (local) reflexivity is presented [5].\nMost importantly, due to the support of existential restrictions, computation of the MSC for a given individual may involve assertions of other entities that are connected to it through role assertions. This implies not only the complexity of the computation for MSC\u2019s but also the potential that the resulting MSC\u2019s may have larger than desired sizes. In fact, in many of the practical ontology ABoxes (e.g. a social network or semantic webs), most of the individuals could be connected to each other through role assertions, forming a huge connected component in the ABox graph. Under this situation, the resulting MSC could be extremely large and reasoning with it may completely degenerate into an expensive reasoning procedure.\nIn this paper, we propose a revised MSC method for\nVisualize Graph Schema Start Confirm Selection User Select Subgraph Download Data in Background (once) Data Sampling/Graph Slicing in Background Graph Analytics / ML Yes\nNo\nClient: Request Graph Schema Start Server: Send Schema (JSON Object?) Visualize Graph Schema Client: Invoke Visualization End\nSelect Graph Nodes & Edges Start Pass Selection as JSON Object to Server User Select Subgraph Convert Selection into Faunus Script or Graphx Filter End Server: Get Schema for a given User Pass Script/Filter to Data Backend\nRun Selected Algorithm on User Graph Start Save Result into HDFS as Temporary File Run Algorithm & Present Result Load Result in HDFS into Graph DB (HBase) End Client: Invoke ElasticSearch to Get Data from HBase Display Data Table in UI\nRun Selected Algorithm on Filtered Data Start Save Result into HDFS Run Algorithm & Present Result Client: Request Top K Result End Server: Read Data From HDFS and Send Result Display Data in UI Default: Graphic Detailed: Tables Download Data from HBase into HDFs Download Data Only Once from Graph DB (Pre-Loading)\nTransform Data Format for Selected Algorithm Start Run Selected Algorithm Download Data Only Once from Graph DB (Pre-Loading) Save Result into HDFS Post-processing if any (e.g. write result back to local graph) End Run Algorithm\nClient: Request Top K Result Server: Read Result from HDFS Start Present Result End Display Data using Tables Server: Enrich Result with MusicGraph Data (Query Info with ID) Display Data in UI using Graphs (options) Show Details? Yes No User Select Algorithm (Graphlab/Graphx) Run Algorithm on Selected Data\nPresent Result (Table/Graph)\nRetrieve Result\nEnd\nClient: User select data for machine learning: <item, feature_vector> Server: Run Faunus to Filter Raw Data Start Run ML Algorithm End Save result to HDFS Server: Convert filtered raw data into proper format for ML algorithm Run ML algorithms from graphlab or spark\nCompute a revised MSC for each individual in ABox based on the current query\nUse the revised MSC\u2019s for subsumption test against the current query concept\nReturn all the individuals that have its MSC subsumed by the query concept\nFig. 1. A procedure for instance retrieval for a given query based on our revised MSC method.\nDL SHI that attempts to tackle the above mentioned problems, by applying a call-by-need strategy together with optimizations. That is, instead of computing the most specific concepts that could be used to answer any queries in the future, the revised method takes into consideration only the related ABox information with current query and computes a concept for each individual that is only specific enough to answer it w.r.t. the TBox. Based on this strategy, the revision allows the method to generate much simpler and smaller concepts than the original MSC\u2019s by ignoring irrelevant ABox assertions. On the other hand, the complexity reduction comes with the price of recomputation (i.e. online computation of MSC\u2019s) for every new coming query if no optimization is applied. Nevertheless, as shown in our experimental evaluation, the simplicity achieved could be significant in many practical ontologies, and the overhead is thus negligible comparing with the reasoning efficiency gained for each instance checking and query answering. Moreover, due to the re-computations, we do not assume a static ontology or query, and the ABox data is amenable to frequent modifications, such as insertion or deletion, which is in contrast to the original MSC method where a relatively static ABox is assumed. A procedure for instance retrieval based on our revised MSC method is shown in Figure 1.\nThe revised MSC method could be very useful for efficient instance checking in many practical ontologies, where the TBox is usually small and manageable while the ABox is in large scale as a database and tends to change frequently. Particularly, this method would be appealing to large ontologies in non-Horn DLs, where current optimization techniques such as rule-based reasoning or pre-computation may fall short. Moreover, the capability to parallelize the computation is another compelling reason to use this technique, in cases where answering object queries may demand thousands or even millions of instance checking tasks.\nOur contributions in this paper are summarized as follows:\n3 1) We propose a call-by-need strategy for the original MSC method that, instead of computing the most specific concepts offline to handle any given query, it allows us to focus on the current queries and to generate online much smaller concepts that are sufficient to compute the answers. This strategy makes our MSC method suitable for query answering in ontologies, where frequent modifications to the ontology data are not uncommon. 2) We propose optimizations that can be used to further reduce sizes of computed concepts in practical ontologies for more efficient instance checking. 3) Finally, we evaluate our approach on a range of test ontologies with large ABoxes, including ones generated by existing benchmark tools and realistic ones used in biomedical research.\nThe evaluation shows the efficacy of our proposed approach that can generate significantly smaller concepts than the original MSC. It also shows the great reasoning efficiency that can be achieved when using the revised MSC method for instance checking and query answering.\nThe rest of the paper is organized as follows: in Section 2, we introduce the the background knowledge of a description logic and DL ontology; in Section 3, we give more detailed discussion about the MSC method and our call-by-need strategy; Section 4 presents the technical details of the revised MSC method; Section 5 discusses the related work; Section 6 presents an empirical evaluation on our proposed method; and finally, Section 7 concludes our work."}, {"heading": "2 PRELIMINARIES", "text": "The technique proposed in this paper is for description logic SHI. For technical reasons, we need a constrained use of nominals on certain conditions (i.e. assertion cycles), which requires logic SHIO. Thus, in this section, we give a brief introduction to formal syntax and semantics of logic SHIO, DL ontologies, and basic reasoning tasks for derivation of logical entailments from DL ontologies.\n2.1 Description Logic SHIO The vocabulary of description logic SHIO includes a set R of named roles with a subset R+ \u2286 R of transitive roles, a set C of named (atomic) concepts, and a set I of named individuals.\nDefinition 2.1 (SHIO-Role). A role in SHIO is either a named (atomic) one R \u2208 R or an inverse one R\u2212 with R \u2208 R, and the complete role set of SHIO can be denoted R\u2217 = R \u222a {R\u2212 | R \u2208 R}. To avoid role representation such as R\u2212\u2212, a function Inv(\u00b7) is defined, such that Inv(R)\n= R\u2212 if R is a role name, and Inv(R)=P if R = P\u2212 for some role name P .\nA role R is transitive, denoted Trans(R), if either R or Inv(R) belongs to R+.\nDefinition 2.2 (SHIO-Concept). A SHIO-concept is either an atomic (named) concept or a complex one that can be defined using the following constructs recursively\nC, D ::= A | {o} | > | \u22a5 | \u00acC | C uD | C tD | \u2200R.C | \u2203R.C\nwhere A is an atomic concept in C, o is a named individual, and R \u2208 R\u2217.\nDescription logic SHI is then defined as a fragment of SHIO, which disallows the use of nominal (i.e. {o}) as a construct for building complex concepts.\nDefinition 2.3 (SHIO Semantics). The meaning of an entity in SHIO is defined by a model-theoretical semantics using an interpretation denoted I = (\u2206I , .I), where \u2206I is referred to as a non-empty domain and .I is an interpretation function.\nThe function .I maps every atomic concept in C to a subset of \u2206I , every ABox individual to an element of \u2206I , and every role to a subset of \u2206I \u00d7 \u2206I . Interpretation for other concepts and inverse role are given below:\n>I = \u2206I \u22a5I = \u2205 {o}I = {oI} \u00acCI = \u2206I\\CI\n(R\u2212)I = {(y, x) | (x, y) \u2208 RI} (C uD)I = CI \u2229DI (C tD)I = CI \u222aDI (\u2203R.C)I = {x | \u2203y.(x, y) \u2208 RI \u2227 y \u2208 CI} (\u2200R.C)I = {x | \u2200y.(x, y) \u2208 RI \u2227 y \u2208 CI}\nDefinition 2.4 (Simple-Form Concept). A concept is said to be in simple form, if the maximum level of nested quantifiers in this concept is less than 2.\nFor example, given an atomic concept A, both A and \u2203R.A are simple-form concepts, while \u2203R1.(Au\u2203R2.A) is not, since its maximum level of nested quantifiers is two. Notice however, an arbitrary concept can be linearly reduced to the simple form by assigning new concept names for fillers of the quantifiers. For example, \u2203R1.\u2203R2.C can be converted to \u2203R1.D by letting D \u2261 \u2203R2.C where D is a new concept name."}, {"heading": "2.2 DL Ontologies and Reasoning", "text": "Definition 2.5 (SHI-Ontology). A SHI ontology is a tuple, denoted K = (T ,A), where T is called a TBox and A is called an ABox.\nThe TBox T is constituted by a finite set of role inclusion axioms (i.e. R1 v R2 with R1, R2 \u2208 R\u2217) and a finite set of concept inclusion axioms in the form of C v D and C \u2261 D, where C, D are SHI concepts. The former is\n4 called a general concept inclusion axiom (GCI), and the latter can be simply converted into two GCIs as C v D and D v C.\nThe ABox A consists of a finite set of assertions, in the form of A(a) (concept assertion) and R(a, b) (role assertion), where A is a concept, R is a role, and a, b are named individuals in I.\nIn a role assertion R(a, b), individual a is referred to as a R-predecessor of b, and b is a R-successor (or R\u2212predecessor) of a. If b is a R-successor of a, b is also called a R-neighbor of a.\nAn interpretation I satisfies an axiom C v D (written I |= C v D), iff CI \u2286 DI , and I satisfies an axiom or assertion:\nR1 v R2 iff RI1 \u2286 RI2 C(a) iff aI \u2208 CI\nR(a, b) iff (aI , bI) \u2208 RI .\nIf I satisfies every axiom and assertion of an ontology K, I is called a model of K, written I |= K. In turn, K is said satisfiable iff it has at least one model; otherwise, it is unsatisfiable or inconsistent.\nDefinition 2.6 (Logical Entailment). Given an ontology K and an axiom \u03b1, \u03b1 is called a logical entailment of K, denoted K |= \u03b1, if \u03b1 is satisfied in every model of K.\nDefinition 2.7 (Instance checking). Given an ontology K, a DL concept C and an individual a \u2208 I, instance checking is defined to test if K |= C(a) holds.\nNotice that, instance checking is considered the central reasoning service for information retrieval from ontology ABoxes [19], and more complex reasoning services, such as instance retrieval, can be realized based on this basic service. Instance checking can also be viewed as a procedure of individual \u201cclassification\u201d that verifies if an individual can be classified into some defined DL concepts.\nAn intuition to implement this instance checking service is to convert it into a concept subsumption test by using the so-called most specific concept (MSC) method.\nDefinition 2.8 (Most Specific Concept [20]). Let K = (T ,A) be an ontology, and a be an individual in I. A concept C is called the most specific concept for a w.r.t. A, written MSC(A, a), if for every concept D that K |= D(a), T |= C v D.\nThe MSC method turns the instance checking into a TBox reasoning problem. That is, once the most specific concept MSC(A, a) of an individual a is known, to decide if K |= D(a) holds for an arbitrary concept D, it suffices to test if T |= MSC(A, a) v D [10].\nOntology reasoning algorithm in current systems (e.g. Pellet, and HermiT, etc.) are based on (hyper) tableau algorithms [7], [4], [6], [21]. For details of a standard tableau algorithm for SHIO, we refer readers to the work in [22]."}, {"heading": "2.2.1 Assumption", "text": "For accuracy of the technique presented in this paper, without loss of generality, we assume all ontology concepts are in simple form as defined previously, and the concept in any concept assertion is atomic."}, {"heading": "3 CLASSIFICATION OF INDIVIDUALS", "text": ""}, {"heading": "3.1 The MSC method", "text": "The MSC method for individual checking is based on the idea that, an individual can be classified into a given concept D, if and only if there exists a concept behind its ABox assertions subsumed by D [20], [17], [18]. Computation of the MSC for a given individual then demands converting its ABox assertions into a concept. This task can be easily accomplished if the individual possesses only concept assertions, by simply collapsing the involved concepts into a single term using the concept conjunction. When role assertions are involved, however, a more complex procedure is demanded, and the method we used here is called rolling-up [23], which is elaborated in the next section.\nUsing the MSC method for instance checking might eliminate the memory limitation for reasoning with large ABoxes, especially when the ABox A consists of data in great diversity and isolation. This is simply because each computed MSC(A, a) should comprise of only related information of the given individual, and makes the subsumption test (i.e. K |= MSC(A, a) v D) as efficient as an ontology reasoning that explores only a (small) portion of A.\nHowever, as discussed in Section 1, due to the support of existential restrictions in DLs, great complexity for computation of MSC\u2019s may arise when role assertions are involved. Besides, due to the completeness that should be guaranteed by each MSC(A, a) (i.e. the MSC should be subsumed by any concept that the individual a belongs to.), the resulting MSC\u2019s may turn out to be a very large concept, whenever there is a great number of individuals in A connected to each other by role assertions. In the worst case, reasoning with a MSC may degenerate into a complete ABox reasoning that could be prohibitively expensive. For example, when MSC(A, a) preserves complete information of A, its interpretation will form a tableau, the size of which can be in the same scale of A."}, {"heading": "3.2 The Call-by-Need Strategy", "text": "Since the larger than desired sizes of MSC\u2019s are usually caused by its completeness as discussed above, a possible optimization to the MSC method is thus to abandon the completeness that is required to deal with any query concepts, and to apply a \u201ccall-by-need\u201d strategy. That is, for an arbitrary query concept D, instead of computing the MSC for each individual a, we compute a concept that is only specific-enough to determine if a can be classified into D. As suggested\n5 by its name, this revision to the original MSC method, instead of taking the complete information of individual a when computing the \"MSC\", will consider only the ABox assertions that are relevant to the current query concept.\nA simple way to realize this strategy is to assign a fresh name A every time to a given (complex) query concept D by adding the axiom A \u2261 D to T ,1 and to concentrate only on ABox assertions that would (probably) classify an individual a into A w.r.t.T . Consequently, this implementation requires an analysis of the ontology axioms/assertions, such that the possibility of each role assertion to affect individual classification (w.r.t. named concept in T ) can be figured out. Computation of a specific-enough concept should then concentrate on role assertions that are not impossible. We abuse the notation here to denote this specific-enough concept for individual a w.r.t. ABox A, current query concept Q, and named concepts in T as MSCT (A,Q, a), and we call the method that uses MSCT for instance checking the MSCT method.\nDefinition 3.1. Let K = (T ,A) be an ontology, a be an individual in A, and Q a current query concept for individuals. A concept C is called a specific-enough concept for a w.r.t. named concepts in T , Q and A, written MSCT (A,Q, a), if K |= Q(a), T |= C v Q.\nSince in our procedure we will add the query concept Q into T as a named concept, we can simplify the notation MSCT (A,Q, a) as MSCT (A, a)."}, {"heading": "3.3 A Syntactic Premise", "text": "To decide whether a role assertion could affect classification of a given individual, a sufficient and necessary condition as stated previously is that, the concept behind this assertion conjuncted with other essential information of the individual should be subsumed by the given concept w.r.t. T [20], [17], [18]. Formally, for a role assertion R(a, b) that makes individual a classified into a concept A, the above sufficient and necessary condition in SHI can be expressed as:\nK |= \u2203R.B uA0 v A, (1)\nwhere b \u2208 B is entailed by K, and concept A0 summarizes the rest of the information of a that is also essential to this classification, with A0 6v A.\nAs shown in [16], for subsumption (1) to hold when A is a named concept, there must exist some role restriction \u2203R\u2032.C with R v R\u2032 in left-hand side of TBox axioms (see (2) and the following axiom equivalency) for concept definition; otherwise \u2203R.B is not comparable (w.r.t. subsumption) with other concepts (except > and its equivalents). This syntactic condition for the\n1. Note that, to follow the simple-form concept restriction, multiple axioms may be added.\ndeduction of (1) is formally expressed in the following proposition.\nProposition 3.1 ([16]). Let K = (T ,A) be a SHI ontology with simple-form concepts only, \u2203R.B, A0 and A be SHI concepts, where A is named. If\nK |= \u2203R.B uA0 v A\nwith A0 6v A, there must exist some GCIs in T in the form of:\n\u2203R\u2032.C1 ./ C2 v C3 (2)\nwhere R v R\u2032 and ./ is a place holder for t and u, Ci\u2019s are SHI concepts. Also note the following equivalence:\n\u2203R.C v D \u2261 \u00acD v \u2200R.\u00acC \u2203R.C v D \u2261 C v \u2200R\u2212.D\nC1 u C2 v D \u2261 C1 v D t \u00acC2 This proposition is proven in [16]. It states in fact a syntactic premise in SHI for a role assertion to be essential for some individual classification. That is, if a role assertion R(a, b) is essential for derivation of A(a) for some named concept A, there must exist a related axiom in T in the form of (2) for R v R\u2032. We denote this syntactic premise for R(a, b) to affect a\u2019s classification as SYN_COND. Using this condition, we can easily rule out role assertions that are definitely irrelevant to the query concept and will not be considered during the computation of a MSCT .\n4 COMPUTATION OF MSCT In this section, we present the technique that computes a MSCT for a given individual w.r.t. a given query. We assume the ABox considered here is consistent, since for any inconsistent ABox, the MSCT is always the bottom concept \u22a5 [24]. Essentially, the task is to convert ABox assertions into a single concept for a given individual, using the concept conjunction and the so-called rolling-up technique. This rolling-up technique was introduced in [23] to convert conjunctive queries into concept terms, and was also used by [25] to transform datalog rules into DL axioms. We adapt this technique here to roll up ABox assertions into DL concepts."}, {"heading": "4.1 The Rolling-up Procedure", "text": "Converting concept assertions into a concept is straightforward by simply taking conjunction of the involved concepts. When role assertions are involved, the rolling-up technique can be used to transform assertions into a concept by eliminating individuals in them. For example, given the following assertions\nMale(Tom), hasParent(Tom, Mary), Lawyer(Mary), (3)\ntransforming them for individual Tom using the rolling up and concept conjunction can generate a single\n6 concept assertion\n(Male u \u2203hasParent.Lawyer)(Tom).\nGeneralize the Information: The transformation here is for individual Tom, and if individual Mary is not explicitly indicated in the query, it should be sufficient to rewrite hasParent(Tom, Mary), Lawyer(Mary) into \u2203hasParent.Lawyer(Tom), without loss of any information that is essential for query answering. Even if Mary is explicitly indicated in the query, we can still eliminate it by using a representative concept that stands for this particular individual in the given ABox [26]. For example, we can add an assertion Amary(Mary) to the ABox, where Amary is a new concept name and a representative concept for individual Mary. The above role assertions for Tom then can be transformed into concept \u2203hasParent.(Lawyer u Amary)(Tom); and if the query is also rewritten using concept Amary , the completeness of the query answering can be guaranteed, as indicated by the following theorem [26].\nTheorem 4.1 ([26]). Let K = (T ,A) be a DL ontology, a, b be two individuals in A, R a role, and C1, \u00b7 \u00b7 \u00b7 , Cn DL concepts. Given a representative concept name Ab not occurring in K:\nK |= R(a, b) \u2227 C1(b) \u2227 \u00b7 \u00b7 \u00b7 \u2227 Cn(b)\nif and only if\nK \u222a {Ab(b)} |= \u2203R.(Ab u C1 u \u00b7 \u00b7 \u00b7 u Cn)(a)\nThe rolling-up procedure here can be better understood by considering a graph induced by the role assertions to be rolled up, which is defined as follows:\nDefinition 4.1. A set of ABox role assertions in SHI can be represented by a graph G, in which there is a node x for each individual x in the assertions, and an edge between node x and y for each role assertion R(x, y).\nNotice that, due to the support of inverse roles in SHI, edges in G are not directed. A role path in the graph G is then defined as a set of roles corresponding to the set of edges (no duplicate allowed) leading from one node to another. For example, given assertions R1(x, y) and R2(z, y), the role path from x to z is {R1, R\u22122 }, and its reverse from z to x is {R2, R \u2212 1 }.\nThe rolling-up for a given individual x is then able to generate concepts by eliminating individuals in branches of the tree-shaped graph G, starting from the leaf nodes and rolling up towards the root node indicated by x. Moreover, all the information of each individual being rolled up should be absorbed into a single concept by conjunction during the procedure. For example, if we have additional assertions\nhasSister(Mary, Ana) and Professor(Ana)\nfor Mary in (3), the rolling-up for Tom should then generate concept\nMaleu\u2203hasParent.(Lawyeru\u2203hasSister.Professor).\nInverse Role: The support of inverse roles in SHI makes this rolling-up procedure bidirectional, thus, making it applicable to computing MSCT for any individual in the ABox. For example, to compute a MSCT for individual Mary in example (3), we simply treat this individual as the root, and roll up assertions from leaves to root to generate the concept\nLawyer u \u2203hasParent\u2212.Male.\nTransitive Role: In the rolling-up procedure, no particular care needs to be taken to deal with transitive roles, since any role assertions derived from transitive roles will be automatically preserved [26]. For example, given R a transitive role, R(a, b), R(b, c) two role assertions, and B(b), C(c) two concept assertions in the ABox, rolling-up these four assertions for individual a can generate assertion \u2203R.(B u \u2203R.C)(a), from which together with the TBox axioms, we can still derive the fact that\n(\u2203R.(B u \u2203R.C) u \u2203R.C)(a).\nAssertion Cycles: This rolling-up technique, however, may suffer information loss if the graph G contains cycles (i.e. a role path leading from one node to itself without duplicate graph edges). For example, given the following two assertions:\nR1(x, y) and R2(x, y), (4)\nindividuals x and y are related by two roles, and a cycle is thus induced in the corresponding graph. Rolling-up assertions for individual x using the method described above might generate concept \u2203R1.> u \u2203R2.>, and the fact that x is connected to the same individual y through different roles is lost. Consequently, this may compromise the resulting concept as a specific-enough concept for x to answer the current query. For example, let C be a query concept defined as:\n\u2203R1.\u2203R\u22122 .\u2203R1.>.\nIt can be found out through ABox reasoning that individual x is an instance of C; while on the other hand, it is also not difficult to figure out that \u2203R1.>u\u2203R2.> is not subsumed by C.\nMultiple solutions to this problem have been proposed, such as an approximation developed by [27], and the use of cyclic concept definition with greatest fixpoint semantics [24], [28]. In this paper, we choose to use the nominal (e.g. {x}) to handle circles as suggested by [20], [19], which allows explicit indication of named individuals in a concept, hence, being able to indicate the joint node of a cycle. The above two assertions in (4) then can be transformed into a concept for individual x as either \u2203R1.{y} u \u2203R2.{y} or {x}u\u2203R1.\u2203R\u22122 .{x}, each with the nominal used for\n7 a chosen joint node, and both preserve complete information of the cycle. In our approach, when rolling up a cycle in G, we always treat the cycle as a single branch and generate concepts of the second style. That is, our procedure will treat a chosen joint node x as both the tail (i.e. leaf) and the head (i.e. root) of the branch. For clarity of the following presentation, we denote the tail as xt and the head as xh.\nBased on the discussion so far, the transformation of assertions for a given individual now can be formalized as follows. Let x be a named individual, and \u03b3 be an ABox assertion for x. \u03b3 can be transformed into a concept C\u03b3 for x:\nC\u03b3 =  C if \u03b3 = C(x) | C(xh) \u2203R.D if \u03b3 = R(x, y), and D(y) \u2203R\u2212.D if \u03b3 = R(y, x), and D(y) {xh} u \u2203R.{xt} if \u03b3 = R(xh, xt) {xh} u \u2203R.D if \u03b3 = R(xh, y), and D(y) {xh} u \u2203R\u2212.D if \u03b3 = R(y, xh), and D(y) {xt} if \u03b3 = R(xt, y)|R(y, xt)|C(xt)\nNotice that, concept D here is a obtained concept when rolling up branch(es) in G up to node y, and transforming any assertion of a cycle tail xt always generates {xt}, as complete information of x will be preserved when rolling up to the head xh. Thereafter, given a set S of all assertions of individual x, MSCT (A, x) can be obtained by rolling up all branches induced by role assertions in S and taking the conjunction of all obtained concepts. When S is empty, however, individual x in the ABox can only be interpreted as an element of the entire domain, and thus, the resulting concept is simply the top entity >. Computation of a MSCT (A, x) then can be formalized using the following equation:\nMSCT (A, x) = { > if S = \u2205 u\u03b3\u2208S C\u03b3 if otherwise"}, {"heading": "4.2 Branch Pruning", "text": "To apply the call-by-need strategy, the previously defined syntactic premise SYN_COND is employed, and a branch to be rolled up in graph G will be truncated at the point where the edge does not have SYN_COND satisfied. More precisely, if an assertion R(x, y) in a branch does not have the corresponding SYN_COND satisfied, it will not affect any classification of individual x w.r.t. T . Moreover, any effects of the following assertions down the branch will not be able to propagate through R(x, y) to x, and thus should not be considered during the rolling-up of this branch.\nThis branch pruning technique could be a simple yet an efficient way to reduce complexity of a MSCT , especially for those practical ontologies, where many of the ABox individuals may have a huge number of role assertions and only a (small) portion of them have SYN_COND satisfied. For a simple example, consider an\nindividual x in an ontology ABox with the following assertions:\nR1(x, y1), R2(x, y2), \u00b7 \u00b7 \u00b7 , Rn(x, yn),\nwhere n could be a very large number and only R1 has SYN_COND satisfied. Rolling up these assertions for individual x without the pruning will generate the concept\n\u2203R1.C1 u \u2203R2.C2 u \u00b7 \u00b7 \u00b7 u \u2203.Rn.Cn,\nwhere yi \u2208 Ci. Using this concept for any instance checking of x could be expensive, as its interpretation might completely restore the tableau structure that is induced by these assertions. However, when the pruning is applied, the new MSCT should be \u2203R1.C1, the only role restriction that is possible to affect individual classification of x w.r.t. named concepts in T .\nGoing beyond such simple ontologies, this optimization technique may also work in complex ontologies, where most of the role assertions in ABox could have SYN_COND satisfied. For example, consider the following assertions\nR0(x0, x1), R1(x1, x2), \u00b7 \u00b7 \u00b7 , Rn(xn, xn+1),\nwith all roles except R2 having SYN_COND satisfied. Rolling up these assertions for individual x0 will start from the leaf xn+1 up towards the root x0, and generate the concept\n\u2203R0.\u2203R1. \u00b7 \u00b7 \u00b7 .\u2203Rn.C,\nwhere xn+1 \u2208 C. However, with pruning applied, the rolling-up in this branch will start from x2 instead of xn+1, since R2(x2, x3) will not affect classification of individual x2 w.r.t. T and the branch is truncated at this point.\nFurthermore, with branch pruning, cycles should only be considered in the truncated graph, which may further simplify the computation of MSCT \u2019s."}, {"heading": "4.3 Further Optimization and Implementation", "text": "The branch pruning here is based on SYN_COND to rule out irrelevant assertions, which in fact can be further improved by developing a more rigorous premise for a role assertion to affect individual classification. For exposition, consider the following ontology K:\n({\u2203R.C v D}, {\u00acD(a), R(a, b), \u00acC(b)}). (5)\nWhen computing MSCT (A, a) using the proposed method, assertion R(a, b) will be rolled up as the corresponding SYN_COND is satisfied. However, it is not difficult to see that, R(a, b) here actually makes no contribution to a\u2019s classification, since individual b is in the complement of concept C, making a an instance of \u2203R.\u00acC. Besides, individual a has already been asserted as an instance of concept \u00acD, and hence cannot be classified into D unless the ABox is inconsistent.\n8 With these observations, a more rigorous premise based on SYN_COND can be derived. That is, to determine the possibility for R(a, b) to affect classification of individual a, beyond checking in T the existence of any axiom in the form of\n\u2203R\u2032.C1 ./ C2 v C3,\nwith R v R\u2032 and ./ a place holder for t and u, we also check the following cases for any found axiom: case 1. if there is any concept B0 in explicit concept\nassertions of individual b, such that K |= B0 v \u00acC1, or case 2. if there is any concept A0 in explicit concept assertions of individual a, such that K |= A0 v \u00ac(C3 t \u00acC2)2 or K |= A0 v \u00acC3, respectively for ./ standing for u or t.\nIf either one of the above cases happens, that particular \u2203R\u2032.C1 in the left hand side of the axiom in fact makes no contribution to the inference of a\u2019s classification, unless the ABox is inconsistent where MSC\u2019s are always \u22a5 [24]. Thus, a revised condition requires not only the existence of a related axiom in the form of (2) but also with none of the above cases happening. We denote this condition as SYN_COND\u2217, and use it to rule out assertions that are irrelevant to the current query.\nThis optimization is useful to prevent rolling-up of role assertions in an arbitrary direction on existence of related axioms in T . Instead, it limits the procedure to the direction that is desired by the original intention underlying the design of the given ontology. For example, in (5), the axiom \u2203R.C v D specifies that, any individual having a R-neighbor in C is an instance of D and any individual having a R\u2212-neighbor in \u00acD is an instance of \u00acC.3 However, if individual x is asserted to have a R-neighbor in \u00acC or a R\u2212-neighbor in D, that role assertion should not be rolled-up for x just on existence of this axiom.\nWith all the insights discussed so far, an algorithm for computation of MSCT (A, x) is presented here as a recursive procedure, the steps of which are summarized in Figure 2.\nProposition 4.1 (Algorithm Correctness). The algorithm presented in Figure 2 computes a MSCT (A, x) for a given SHI ontology (T ,A) and an individual x in A.\nProof: We prove by induction. Basis: For a leaf node x in G, which has no other role\nassertions except those up the branches, rolling it up yields the conjunction of concepts in its concept assertions, which preserves sufficient information of the part of the branch being rolled so far. If x is the tail of a cycle, returning {xt} is sufficient, as other information of x will be gathered when the rolling-up comes to the head.\n2. Note the axiom equivalence C1 u C2 v D \u2261 C1 v D t \u00acC2. 3. Note that \u2203R.C v D is equivalent with \u2203R\u2212.\u00acD v \u00acC.\n1) In this recursive procedure, if x has already been visited before (cycle detected), mark x as the joint node and return {xt}. 2) Obtain a set S of all explicit assertions in A of the given individual x, which have not been visited before. 3) For every role assertion \u03b3 : Ri(x, yi) \u2208 S (respectively Ri(yi, x)) that has SYN_COND\u2217 satisfied and has not been visited yet, invoke this procedure recursively to compute concept Di for yi. The rolling-up in this branch for x then yields C\u03b3 = \u2203Ri.Di (respectively \u2203R\u2212i .Di). 4) For every concept assertion \u03b3 : Ci(x) \u2208 S, C\u03b3 = Ci. 5) Return MSCT (A, x) that equals to: > if S = \u2205 u\u03b3\u2208S C\u03b3 u {xh} if S 6= \u2205, and x is marked u\u03b3\u2208S C\u03b3 if otherwise\nFig. 2. A recursive procedure for computation of MSCT (A, x).\nInductive Step: Let x be a node in the middle of some branch(es) in G. For every role assertion Ri(x, yi) of x down the branch, assume the procedure generates a concept Di for rolling up to each node yi, which preserves sufficient information (w.r.t. current query) of the part of branches being rolled up so far. Then, rolling up each R(x, yi) generates \u2203R.Di, and together with concept assertions of x, the concept conjunction preserves sufficient information of all branches being rolled up to x. If x is marked as a joint node of a cycle, {xh} is also in the conjunction, so that the circular path property can be preserved. If x is the root node, the conjunction is thus a MSCT (A, x) that preserves sufficient information of x w.r.t. current query.\nThis algorithm visits every relevant ABox assertion at most once, and it terminates after all related assertions are visited."}, {"heading": "5 RELATED WORK", "text": "The idea of most specific concept for instance checking was first discussed in [18], and later extensively studied by [20], [17] for the algorithms and the computational complexity. To deal with existential restrictions when computing the most specific concept, [24], [29], [28] discussed the use of cyclic concepts with greatest fixpoint semantics for preservation of information induced by the role assertions, and [27] also proposed an approximation for most specific concept in DLs with existential restrictions.\nOn the other hand, for efficient ABox reasoning and instance checking, various optimization techniques have been developed, including lazy unfolding, absorption, heuristic guided search, exploration of Horn\n9 clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].\nA common direction of these optimization techniques is to reduce the high degree of nondeterminism that is mainly introduced by GCIs in the TBox: given an GCI C v D, it can be converted to a disjunction C t \u00acD, for which a tableau algorithm will have to nondeterministically choose one of the disjuncts for tableau expansion, resulting in an exponentialtime behavior of the tableau algorithm w.r.t. the data size. Absorption optimizations [30], [32], [33] were developed to reduce such nondeterminism by combining GCIs for unfoldable concepts, such that the effectiveness of lazy unfolding can be maximized. For example, axioms A v C and A v D can be combined into A v C u D, where A is a named concept; then the inference engine can deduce C uD(a) if the ABox contains A(a). Notice however, this technique may allow only parts of TBox axioms to be absorbed, thus, may not be able to eliminate all sources of nondeterminism especially when ontologies are complex. Based on the absorption optimization, [34] proposed an approach for efficient ABox reasoning for ALCIQ that will convert ABox assertions into TBox axioms, apply a absorption technique on the TBox, and covert instance retrieval into concept satisfaction problems.\nAnother way to reduce nondeterminism is the exploration of Horn clauses in DLs, since there exist reasoning techniques for Horn clauses that can be deterministic [35], [5]. [5] takes advantage of this in their HermiT reasoner by preprocessing a DL ontology into DL-clauses and invoking the hyperresolution for the Horn clauses, avoiding unnecessary nondeterministic handling of Horn problems in existing DL tableau calculi.\nFor non-Horn DL, techniques such as model merging [2] and pseudo model merging [31] can be used to capture some deterministic information of named individuals. These techniques are based on the assumption of a consistent ABox and the observation that usually individuals are members of a small number of concepts. The (pseudo) model merging technique merges clash-free tableau models that are constructed by disjunction rules for a consistent ABox, and can figure out individuals that are obviously non-instance of a given concept. For example, if in one tableau model individual a belongs to concept C while in another a belongs to \u00acC, it is then obvious that individual a cannot be deterministically inferred to be an instance of concept C, thus, eliminating the unnecessary instance checking for C(a).\nAnother option for scalable ABox reasoning is the use of tractable DL languages. For example, the description logic EL and its extension EL++, which allow existential restrictions and conjunction as introduced by [36], [37], possess intriguing algorithmic properties such that the satisfiability problem and implication in this DL language can be deter-\nmined in polynomial time. Another notable example of lightweight DLs is the so-called DL-LITE family identified by [38], which is specifically tailored to capture basic DL properties and expressivity while still be able to achieve low computational complexity for both TBox and ABox reasoning. In [39], [9] they further identified that, for conjunctive queries that are FOL-reducible, answering them in ontologies of any DL-LITE logic enjoys a LOGSPACE data complexity.\nBased on the above lightweight DLs, efficient DL reasoners are developed, such as OWLIM [40], ELK reasoner [41], and Oracle\u2019s native inference engine for RDF data sets [42].\n[43] proposed an approximation technique for instance retrieval, which computes both lower bound and upper bound of an answer set of individuals for a given query concept. Their approach invokes an axiom rewriting procedure that converts an ontology in Horn DL into a datalog program, and then uses Oracle\u2019s native inference engine to derive the bounds for query answering.\nRecently, techniques for partitioning or modularizing ABoxes into logically-independent fragments have been developed [15], [16]. These techniques partition ABoxes into logically-independent modules, such that each will preserve complete information of a given set of individuals, and thus can be reasoned independently w.r.t. the TBox and be able to take advantage of existing parallel-processing techniques."}, {"heading": "6 EMPIRICAL EVALUATION", "text": "We implemented the rolling-up procedures for computation of MSCT \u2019s based on the OWL API4, and evaluated the MSC method for instance checking and retrieving on a lab PC with Intel(R) Xeon(R) 3.07 GHz CPU, Windows 7, and 1.5 GB Java Heap. For the test suite, we have collected a set of well-known ontologies with large ABoxes:\n1) LUBM(s) (LM) are benchmark ontologies generated using the tool provided by [44], 2) Arabidopsis thaliana (AT) and Caenorhabditis elegans (CE) are two biomedical ontologies5, sharing a common TBox called Biopax that models biological pathways, and 3) DBpedia\u2217 (DP) ontologies are extended from the original DBpedia ontology [45]: expressivity of their TBox is extended from ALF to SHI by adding complex roles and concepts defined on role restrictions; their ABoxes are obtained by random sampling on the original triple store.\nDetails of these ontologies can be found in Table 1, in terms of DL expressivity, number of atomic concepts (# Cpts), TBox axioms (# Axms), named individuals (# Ind.), and ABox assertions (# Ast.). Notice that, DL\n4. http://sourceforge.net/projects/owlapi 5. http://www.reactome.org/download\n10\nexpressivity of AT and CE is originally SHIN , but in our experiments, number restrictions (i.e N ) in their ontology TBox are removed.\n6.1 Complexity of MSCT Using the MSC (or MSCT ) method, the original instance checking problem is converted to a subsumption test, the complexity of which could be computationally high w.r.t. both size of a TBox and size of the testing concepts [10]. Therefore, when evaluating the rolling-up procedure for computation of MSCT \u2019s, one of the most important criteria is the size of each resultant MSCT , as it is the major factor to the time efficiency of a subsumption test, given a relatively static ontology TBox.\nAs we already know, one of the major source of complexity in ontology reasoning is the so-called \"and-branching\", which introduces new individuals in the tableau expansion through the \u2203-rule, and affects the searching space of the reasoning algorithm as discussed in [10]. Thus, when evaluating sizes of computed MSCT \u2019s, we measure both the level of nested quantifiers (i.e. quantification depth) and the number of conjuncts of each MSCT . For example, the concept\n\u2203R1.C1 u \u2203R2.(C2 u \u2203R3.C3)\nhas quantification depth 2 and number of conjuncts 2 (i.e. \u2203R1.C1 and \u2203R2.(C2 u \u2203R3.C3))."}, {"heading": "6.1.1 Experiment Setup", "text": "To evaluate and show efficacy of the proposed strategy and optimization, we have implemented the following three versions of the rolling-up method for comparison: V1. The original rolling-up procedure adapted to\nABox assertions without applying the call-byneed strategy, which computes the most specific concept w.r.t. A for a given individual. V2. The rolling-up procedure with the proposed callby-need strategy based on SYN_COND, which features the branch pruning as fully discussed in Section 4.2. V3. The rolling-up procedure with the call-by-need strategy based on SYN_COND\u2217 as discussed in Section 4.3.\nWe compute the MSCT for each individual in every ontology using the three methods respectively, and report in Table 2 and Table 3 the maximum and the average of quantification depth and number of conjuncts of the concepts, respectively. We also demonstrate the running-time efficiency of the optimized rollingup procedure by showing the average time spent on computation of a MSCT for each individual in Figure 3."}, {"heading": "6.1.2 Result Analysis", "text": "As we can see from Table 2 and Table 3, the sizes of MSCT \u2019s generated by V2 and V3 are significantly smaller than those generated by V1 (the original method), which are almost in the same scale of size of the corresponding ontology ABox. The large size of MSCT \u2019s from V1 is caused by the fact that most individuals (greater than 99%) in each of these ontologies are connected together by role paths in the graph. The bulk of each MSCT makes the original MSC method completely inefficient and unscalable for answering object queries, as a subsumption test based on these concepts would be prohibitively expensive as a complete ABox reasoning. Thus, the comparison here reflects the potential and the importance of our proposed optimizations in this paper, which revive the MSC (i.e. MSCT ) method as an efficient way for instance checking and object query answering.\nThe comparison between V2 and V3 demonstrates the efficacy of the optimization technique discussed in Section 4.3, which could prevent the rolling-up\n11\n1\nin arbitrary directions by providing a more rigorous precondition based on SYN_COND. This optimization could be useful in many practical ontologies, especially when their ABoxes contain \u201chot-spots\u201d individuals that connect (tens of) thousands of individuals together and could cause the rolling-up to generate concepts with a prohibitive quantification depth.\nIn particular, in our previous study of modularization for ontology ABoxes [16], the biomedical ontologies (i.e. AT and CE ) are found to be complex with many of their ontology roles (33 out of 55) used for concept definitions, and their ABoxes are hard\nto be modularized even with various optimization techniques applied [16]. However, in this paper, we found much simpler MSCT \u2019s can also be achieved in these complex ontologies when the optimization (i.e. SYN_COND\u2217) is applied. For example, the maximum quantification depths of computed MSCT \u2019s in both AT and CE are decreased significantly from more than 1,000 to less than 10. Nevertheless, it should also be noted that, effectiveness of this optimization may vary on different ontologies, depending on their different levels of complexity and different amount of explicit information in their ABoxes that can be explored for optimization.\nTo further evaluate the complexity of MSCT \u2019s, we estimate the number of potential tableau nodes that coud be created when reasoning with a MSCT , based on the number of existential quantifiers in the concept. We show the distribution of this estimation for MSCT \u2019s of each ontology in Figure 4, where the X-axis gives the size range and the Y-axis gives the number of MSCT \u2019s that fall in each category.\n6.2 Reasoning with MSCT In this section, we will show the efficiency that can be achieved when using the computed MSCT for instance checking and retrieving. We conduct the experiments on the collected ontologies, and measure the average reasoning time that is required when performing instance checking (for every ABox individual) and instance retrieval using the MSCT method, respectively."}, {"heading": "6.2.1 Experiment Setup", "text": "We will not compare our method with a particular optimization technique for ABox reasoning, such as lazy unfolding, absorption, or model merging, etc., since they have already been built into existing reasoners and it is usually hard to control reasoners to switch on or off a particular optimization technique. Additionally, the MSCT method still relies on the reasoning services provided by the state-of-art reasoners. Nevertheless, we do compare the reasoning efficiency between the MSCT method and a regular complete ABox reasoning using existing reasoners, but only to show the effectiveness of the proposed MSCT method for efficient instance checking and data retrieving. Moreover, we also compare the MSCT method with the ABox partitioning method (modular reasoning) developed in [16], as they are developed based on the similar principles and both allow parallel or distributed reasoning.\nThe MSCT \u2019s here are computed using algorithm V3, and the ABox partitioning technique used is the most optimized one presented in [16]. For a regular complete ABox reasoning, the reasoners used are OWL DL reasoners, HermiT [5] and Pellet [6], each of which has its particular optimization techniques\n12\nQuery on biomedical ontologies : Q1 = Control u \u2200controlled.Catalysis u \u2200controller.PhysicalEntity Q2 = Interaction u \u2200participant.PhysicalEntity Q3 = Interaction u \u2203interactionType.> u \u2203participant.> u \u2200participant.Gene u \u2203phenotype.> Q4 = PhysicalEntity u \u2200entityReference.DnaReference u \u2200memberPhysicalEntity.Dna Q5 = PhysicalEntity u \u2203entityReference.SmallMoleculeReference\nu \u2203feature.BindingFeature u \u2203notfeature.BingdingFeature u \u2203memberPhysicalEntity.SmallMolecule\nQuery on DBpedia\u2217 ontologies : Q1 = Person u \u2203nationality.(Country u \u2203officialLanguage.Engilish) Q2 = Music u \u2203composer.MusicalArtist Q3 = Person u \u2203child.Human u \u2203spouse.Person Q4 = Event u \u2203commander.Person u \u2203place.City Q5 = Produce u \u2203manufacturer.(Organization u \u2203place.Country)\nFig. 5. Queries for biomedical and DBpedia\u2217 ontologies.\nimplemented for the reasoning algorithm. Both the MSCT method and the modular reasoning are based on reasoner HermiT, and they are not parallelized but instead running in an arbitrary sequential order of MSCT \u2019s or ABox partitions.\nQueries. LUBM comes with 14 standard queries. For biomedical and DBpedia\u2217 ontologies respectively, queries listed in Figure 5 are used.\nFor each test ontology, we run the reasoning for each of the given queries. We report the average reasoning time spent on instance checking (Figure 6) and instance retrieval (Figure 7), respectively. The reasoning time reported here does not include the time spent for resource initialization (i.e. ontology loading and reasoner initialization), since the initialization stage can be done offline for query answering. However, it is obvious that the MSCT method should be more efficient, since it only requires to load an ontology TBox while a regular ABox reasoning requires to load an entire ontology (including large ABoxes). For reasoning with MSCT \u2019s and ABox partitions, any updates during the query answering procedure (e.g. update the reasoner for different ABox partitions or different MSCT \u2019s) is counted into the reasoning time.\nAnother point worth noting here is that, for answering object queries using either modular reasoning or the MSCT method, the overhead (time for ABox modularization or computation of MSCT \u2019s) should be taken into account. However, as shown in previous section and in [16], this overhead is negligible comparing with the efficiency gained on the reasoning, not to mention when these two methods get parallelized using existing frameworks such as MapReduce [46]."}, {"heading": "6.2.2 Result Analysis", "text": "As can be seen from the above two figures, using the MSCT method, reasoning efficiency for both instance checking and instance retrieval in the testing ontologies has been improved significantly: (i) by more than three orders of magnitude when comparing with a complete reasoning; (ii) and by about two orders of magnitude (except in LUBM1 and LUBM2)\nwhen comparing with the modular reasoning. For the latter, the improvement in LUBM1 and LUBM2 are not as significant as in others, which is because of the simplicity of these two ontologies that allows fine granularity of ABox partitions to be achieved [16].\nOn the other hand, using the MSCT method in complex ontologies, such as AT and CE, the great improvement in reasoning efficiency comes from the reduction of searching space for reasoning algorithms, by branch pruning and also concept absorption during the computation of MSCT \u2019s. For example, consider an individual x having the following n role assertions:\nR(x, y1), R(x, y2), \u00b7 \u00b7 \u00b7 , R(x, yn),\nwhere yi \u2208 D and n tends to be large in these practical ontologies. Rolling up these assertions may generate a set of \u2203R.D\u2019s, the conjunction of which is still \u2203R.D. Thus, when using this concept for instance checking, the interpretation may generate only one R-neighbor of individual x instead of n."}, {"heading": "6.3 Scalability Evaluation", "text": "Using the MSCT method for query answering over large ontologies is intended for distributed (parallel) computing. However, even if it is executed sequentially in a single machine, linear scalability may still be achieved on large ontologies that are not extremely complex; and there are mainly two reasons for that: first, the computation of MSCT \u2019s focuses on only the\n13\nquery-relevant assertions instead of the entire ABox; second, the obtained MSCT \u2019s could be very simple, sizes of which could be significantly smaller than that of the ABoxes. We test the scalability of this method for query answering (sequentially executed) using the benchmark ontology LUBM, which models organization of universities with each university constituted about 17,000 related individuals. The result is show in Figure 8."}, {"heading": "7 CONCLUSION AND OUTLOOK", "text": "In this paper, we proposed a revised MSC method for efficient instance checking. This method allows the ontology reasoning to explore only a much smaller subset of ABox data that is relevant to a given instance checking problem, thus being able to achieve great efficiency and to solve the limitation of current memory-based reasoning techniques. It can be particularly useful for answering object queries over those large non-Horn DL ontologies, where existing optimization techniques may fall short and answering object queries may demand thousands or even millions of instance checking tasks. Most importantly, due to the independence between MSCT \u2019s, scalability for query answering over huge ontologies (e.g. in the setting of semantic webs) could also be achieved by parallelizing the computations.\nOur technique currently works for logic SHI, which is semi-expressive and is sufficient for many of the practical ontologies. However, the use of more expressive logic in modeling application domains requires more advanced technique for efficient data retrieving from ontology ABoxes. For the future work, we will investigate on how to extend the current technique to support SHIN or SHIQ that are featured with (qualified) number restrictions. We will concentrate on extending the rolling-up procedure to generate number restrictions, such as \u2265 nR.> or \u2265 nR.C, whenever there is a need. We will also have to take a particular care of the identical individual problem, where concepts and role assertions of an individual can be derived via individual equivalence."}], "references": [{"title": "Ontologies and the semantic web", "author": ["I. Horrocks"], "venue": "Communications of the ACM, vol. 51, no. 12, pp. 58\u201367, 2008.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "Optimising tableaux decision procedures for description logics", "author": ["I.R. Horrocks"], "venue": "Ph.D. dissertation, University of Manchester, 1997.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1997}, {"title": "On the scalability of description logic instance retrieval", "author": ["V. Haarslev", "R. M\u00f6ller"], "venue": "Journal of Automated Reasoning, vol. 41, no. 2, pp. 99\u2013142, 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Optimized Reasoning in Description Logics using Hypertableaux", "author": ["B. Motik", "R. Shearer", "I. Horrocks"], "venue": "Proceedings of Conference on Automated Deduction (CADE), ser. LNAI, F. Pfenning, Ed., vol. 4603. Bremen, Germany: Springer, July 17\u201320 2007, pp. 67\u201383.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Hypertableau reasoning for description logics", "author": ["\u2014\u2014"], "venue": "Journal of Artificial Intelligence Research, vol. 36, no. 1, pp. 165\u2013228, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Pellet: A practical owl-dl reasoner", "author": ["E. Sirin", "B. Parsia", "B.C. Grau", "A. Kalyanpur", "Y. Katz"], "venue": "Journal of Web Semantics, vol. 5, no. 2, pp. 51 \u2013 53, 2007.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "RACER system description", "author": ["V. Haarslev", "R. M\u00f6ller"], "venue": "Proceedings of the First International Joint Conference on Automated Reasoning. Siena, Italy: Springer, June 2001, pp. 701\u2013 705.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Using an expressive description logic: Fact or fiction?", "author": ["I. Horrocks"], "venue": "Proceedings of Knowlege Representation and Reasoning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Tractable reasoning and efficient query answering in description logics: The DL-Lite family", "author": ["D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati"], "venue": "Journal of Automated reasoning, vol. 39, no. 3, pp. 385\u2013429, 2007.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "The Description Logic Handbook: Theory, Implementation, and Applications", "author": ["F. Donini"], "venue": "ch. Complexity of Reasoning", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Conjunctive query answering for the description logic", "author": ["B. Glimm", "I. Horrocks", "C. Lutz", "U. Sattler"], "venue": "Journal Artificial Intelligence Research, vol. 31, pp. 157\u2013204, 2008.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Data complexity of query answering in expressive description logics via tableaux", "author": ["M. Ortiz", "D. Calvanese", "T. Eiter"], "venue": "Journal of Automated Reasoning, vol. 41, no. 1, pp. 61\u201398, 2008.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Complexity results and practical algorithms for logics in knowledge representation", "author": ["S. Tobies"], "venue": "Ph.D. dissertation, RWTH Aachen, 2001.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "A scalable approach for partitioning owl knowledge bases", "author": ["Y. Guo", "J. Heflin"], "venue": "International Workshop on Scalable Semantic Web Knowledge Base Systems (SSWS). Geogia, USA: Springer, November 2006, pp. 636\u2013641.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Towards abox modularization of semi-expressive description logics", "author": ["S. Wandelt", "R. M\u00f6ller"], "venue": "Applied Ontology, vol. 7, no. 2, pp. 133\u2013167, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Extract ABox Modules for Efficient Ontology Querying", "author": ["J. Xu", "P. Shironoshita", "U. Visser", "N. John", "M. Kabuka"], "venue": "ArXiv e-prints, vol. arXiv:1305.4859 [cs.AI], May 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Deduction in concept languages: From subsumption to instance checking", "author": ["F. Donini", "M. Lenzerini", "D. Nardi", "A. Schaerf"], "venue": "Journal of logic and computation, vol. 4, no. 4, pp. 423\u2013452, 1994.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1994}, {"title": "Reasoning and revision in hybrid representation systems", "author": ["B. Nebel"], "venue": "Germany: Springer-Verlag Germany,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1990}, {"title": "Reasoning with individuals in concept languages", "author": ["A. Schaerf"], "venue": "Data and Knowledge Engineering, vol. 13, no. 2, pp. 141\u2013176, 1994.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1994}, {"title": "Most specific concepts for knowledge bases with incomplete information", "author": ["F. Donini", "A. Era"], "venue": "Proceedings of CIKM, Baltimor, MD, November 1992, pp. 545\u2013551.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1992}, {"title": "FaCT++ description logic reasoner: System description", "author": ["D. Tsarkov", "I. Horrocks"], "venue": "Proceedings of International Joint Conference on Automated Reasoning. Seattle, WA, USA: Springer, August 2006, pp. 292\u2013297.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "A tableau decision procedure for\\ mathcal {SHOIQ", "author": ["I. Horrocks", "U. Sattler"], "venue": "Journal of Automated Reasoning, vol. 39, no. 3, pp. 249\u2013276, 2007.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "A conjunctive query language for description logic aboxes", "author": ["I. Horrocks", "S. Tessaris"], "venue": "Proceedings of AAAI, Austin, TX, USA, August 2000, pp. 399\u2013404.  14", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Computing the least common subsumer and the most specific concept in the presence of cyclic aln-concept descriptions", "author": ["F. Baader", "R. K\u00fcsters"], "venue": "KI-98: Advances in Artificial Intelligence, A. G. Otthein Herzog, Ed. Bremen, Germany: Springer, 1998, pp. 129\u2013140.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1998}, {"title": "Description logic rules.", "author": ["M. Kr\u00f6tzsch", "S. Rudolph", "P. Hitzler"], "venue": "in ECAI,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Reasoning with individuals for the description logic SHIQ", "author": ["I. Horrocks", "U. Sattler", "S. Tobies"], "venue": "Proceedings of Conference on Automated Deduction (CADE). Pittsburgh, PA, USA: Springer, June 2000, pp. 482\u2013496.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2000}, {"title": "Approximating most specific concepts in description logics with existential restrictions", "author": ["R. K\u00fcsters", "R. Molitor"], "venue": "KI 2001: Advances in Artificial Intelligence, F. Baader, G. Brewka, and T. Eiter, Eds. Vienna, Austria: Springer, 2001, pp. 33\u201347.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2001}, {"title": "Least common subsumers and most specific concepts in a description logic with existential restrictions and terminological cycles", "author": ["F. Baader"], "venue": "IJCAI, vol. 3, 2003, pp. 319\u2013324.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2003}, {"title": "Computing least common subsumers in description logics with existential restrictions", "author": ["F. Baader", "R. K\u00fcsters", "R. Molitor"], "venue": "IJCAI, vol. 99, 1999, pp. 96\u2013101.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1999}, {"title": "A tableau decision procedure for\\ mathcal {SHOIQ", "author": ["I. Horrocks", "U. Sattler"], "venue": "Journal of Automated Reasoning, vol. 39, no. 3, pp. 249\u2013276, 2007.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2007}, {"title": "Exploiting pseudo models for tbox and abox reasoning in expressive description logics", "author": ["V. Haarslev", "R. M\u00f6ller", "A.-Y. Turhan"], "venue": "International Joint Conference on Automated Reasoning. Siena, Italy: Springer, 2001, pp. 61\u201375.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2001}, {"title": "Binary absorption in tableauxbased reasoning for description logics", "author": ["A.K. Hudek", "G. Weddell"], "venue": "Proceedings of Int. Workshop on Description Logics (DL 2006), vol. 189, 2006, pp. 86\u201396.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient reasoning with range and domain constraints", "author": ["D. Tsarkov", "I. Horrocks"], "venue": "Proceedings of The 2004 Description Logic Workshop (DL 2004), vol. 104, 2004, pp. 41\u201350.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2004}, {"title": "Assertion absorption in object queries over knowledge bases.", "author": ["J. Wu", "A.K. Hudek", "D. Toman", "G.E. Weddell"], "venue": "in International Conference on the Principles of Knowledge Representation and Reasoning,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "Description logic programs: Combining logic programs with description logic", "author": ["B. Grosof", "I. Horrocks", "R. Volz", "S. Decker"], "venue": "Proceedings of WWW. Budapest, Hungary: ACM, May 2003, pp. 48\u201357.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "Pushing the el envelope", "author": ["F. Baader", "S. Brand", "C. Lutz"], "venue": "Proceedings of IJCAI. Edinburgh, UK: Morgan-Kaufmann Publishers, August 2005, pp. 364\u2013369.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2005}, {"title": "Pushing the el envelope further", "author": ["F. Baader", "S. Brandt", "C. Lutz"], "venue": "Proceedings of the OWLED 2008 DC Workshop on OWL: Experiences and Directions, Karlsruhe, Germany, October 2008.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Dl-lite: Tractable description logics for ontologies", "author": ["D. Calvanese", "G. De Giacomo", "D. Lembo", "M. Lenzerini", "R. Rosati"], "venue": "Proceedings of AAAI, vol. 5, 2005, pp. 602\u2013607.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2005}, {"title": "Owlim: A family of scalable semantic repositories", "author": ["B. Bishop", "A. Kiryakov", "D. Ognyanoff", "I. Peikov", "Z. Tashev", "R. Velkov"], "venue": "Semantic Web, vol. 2, no. 1, pp. 33\u201342, 2011.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2011}, {"title": "Concurrent classification of EL ontologies", "author": ["Y. Kazakov", "M. Kr\u00f6tzsch", "F. Siman\u010d\u00edk"], "venue": "ISWC. Bonn, Germany: Springer, October 2011, pp. 305\u2013320.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2011}, {"title": "Implementing an inference engine for rdfs/owl constructs and user-defined rules in oracle", "author": ["Z. Wu", "G. Eadon", "S. Das", "E.I. Chong", "V. Kolovski", "M. Annamalai", "J. Srinivasan"], "venue": "Proceedings of IEEE 24th International Conference on Data Engineering (ICDE). Cancun, Mexico: IEEE, April 2008, pp. 1239\u20131248.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2008}, {"title": "Making the most of your triple store: query answering in owl 2 using an rl reasoner", "author": ["Y. Zhou", "B. Cuenca Grau", "I. Horrocks", "Z. Wu", "J. Banerjee"], "venue": "Proceedings of the 22nd international conference on World Wide Web. Rio, Brazil: International World Wide Web Conferences Steering Committee, May 2013, pp. 1569\u20131580.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "LUBM: A benchmark for owl knowledge base systems.", "author": ["Y. Guo", "Z. Pan", "J. Heflin"], "venue": "Journal of Web Semantics,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2005}, {"title": "Dbpedia: A nucleus for a web of open data", "author": ["S. Auer", "C. Bizer", "G. Kobilarov", "J. Lehmann", "R. Cyganiak", "Z. Ives"], "venue": "Proceedings of ISWC. Busan, Korea: Springer, November 2007, pp. 722\u2013735.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Mapreduce: simplified data processing on large clusters", "author": ["J. Dean", "S. Ghemawat"], "venue": "Communications of the ACM, vol. 51, no. 1, pp. 107\u2013113, 2008.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "D ESCRIPTION logics (DLs) play an ever-growing role in providing a formal and semantic-rich way to model and represent (semi-) structured data in various applications, including semantic web, healthcare, and biomedical research, etc [1].", "startOffset": 233, "endOffset": 236}, {"referenceID": 1, "context": "In recent years, considerable efforts have been dedicated to the optimization of algorithms for ontology reasoning and query answering [2], [3], [4].", "startOffset": 135, "endOffset": 138}, {"referenceID": 2, "context": "In recent years, considerable efforts have been dedicated to the optimization of algorithms for ontology reasoning and query answering [2], [3], [4].", "startOffset": 140, "endOffset": 143}, {"referenceID": 3, "context": "In recent years, considerable efforts have been dedicated to the optimization of algorithms for ontology reasoning and query answering [2], [3], [4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 3, "context": "edu due to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.", "startOffset": 107, "endOffset": 110}, {"referenceID": 4, "context": "edu due to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.", "startOffset": 112, "endOffset": 115}, {"referenceID": 5, "context": "edu due to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.", "startOffset": 124, "endOffset": 127}, {"referenceID": 6, "context": "edu due to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.", "startOffset": 135, "endOffset": 138}, {"referenceID": 7, "context": "edu due to the enormous amount of ABox data in realistic applications, existing DL systems, such as HermiT [4], [5], Pellet [6], Racer [7] and FaCT++ [8], still have difficulties in handling the large ABoxes, as they are all based on the (hyper)tableau algorithm that is computationally expensive for expressive DLs (e.", "startOffset": 150, "endOffset": 153}, {"referenceID": 8, "context": "up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13].", "startOffset": 138, "endOffset": 141}, {"referenceID": 9, "context": "up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13].", "startOffset": 143, "endOffset": 147}, {"referenceID": 10, "context": "up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13].", "startOffset": 149, "endOffset": 153}, {"referenceID": 11, "context": "up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13].", "startOffset": 155, "endOffset": 159}, {"referenceID": 12, "context": "up to EXPTIME for instance checking in DL SHIQ), where the complexity is usually measured in the size of the TBox, the ABox and the query [9], [10], [11], [12], [13].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "While another one is to reduce size of the data by either partitioning the ABox into small and independent fragments that can be easily handled in parallel by existing systems [14], [15], [16], or converting the ABox reasoning into a TBox reasoning task (i.", "startOffset": 176, "endOffset": 180}, {"referenceID": 14, "context": "While another one is to reduce size of the data by either partitioning the ABox into small and independent fragments that can be easily handled in parallel by existing systems [14], [15], [16], or converting the ABox reasoning into a TBox reasoning task (i.", "startOffset": 182, "endOffset": 186}, {"referenceID": 15, "context": "While another one is to reduce size of the data by either partitioning the ABox into small and independent fragments that can be easily handled in parallel by existing systems [14], [15], [16], or converting the ABox reasoning into a TBox reasoning task (i.", "startOffset": 188, "endOffset": 192}, {"referenceID": 16, "context": "A common intuition about converting instance checking into a TBox reasoning task is the so-called most specific concept (MSC) method [17], [10], [18] that computes the MSC of a given individual and reduces any instance checking of this individual into a subsumption test (i.", "startOffset": 133, "endOffset": 137}, {"referenceID": 9, "context": "A common intuition about converting instance checking into a TBox reasoning task is the so-called most specific concept (MSC) method [17], [10], [18] that computes the MSC of a given individual and reduces any instance checking of this individual into a subsumption test (i.", "startOffset": 139, "endOffset": 143}, {"referenceID": 17, "context": "A common intuition about converting instance checking into a TBox reasoning task is the so-called most specific concept (MSC) method [17], [10], [18] that computes the MSC of a given individual and reduces any instance checking of this individual into a subsumption test (i.", "startOffset": 145, "endOffset": 149}, {"referenceID": 9, "context": "With the MSC of every individual in the ABox, the efficiency of online object queries can then be boosted by performing an offline classification of all MSC\u2019s that can pre-compute many instance checks [10].", "startOffset": 201, "endOffset": 205}, {"referenceID": 4, "context": "{a}) are involved or (local) reflexivity is presented [5].", "startOffset": 54, "endOffset": 57}, {"referenceID": 18, "context": "Notice that, instance checking is considered the central reasoning service for information retrieval from ontology ABoxes [19], and more complex reasoning services, such as instance retrieval, can be realized based on this basic service.", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "8 (Most Specific Concept [20]).", "startOffset": 25, "endOffset": 29}, {"referenceID": 9, "context": "That is, once the most specific concept MSC(A, a) of an individual a is known, to decide if K |= D(a) holds for an arbitrary concept D, it suffices to test if T |= MSC(A, a) v D [10].", "startOffset": 178, "endOffset": 182}, {"referenceID": 6, "context": ") are based on (hyper) tableau algorithms [7], [4], [6], [21].", "startOffset": 42, "endOffset": 45}, {"referenceID": 3, "context": ") are based on (hyper) tableau algorithms [7], [4], [6], [21].", "startOffset": 47, "endOffset": 50}, {"referenceID": 5, "context": ") are based on (hyper) tableau algorithms [7], [4], [6], [21].", "startOffset": 52, "endOffset": 55}, {"referenceID": 20, "context": ") are based on (hyper) tableau algorithms [7], [4], [6], [21].", "startOffset": 57, "endOffset": 61}, {"referenceID": 21, "context": "For details of a standard tableau algorithm for SHIO, we refer readers to the work in [22].", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "The MSC method for individual checking is based on the idea that, an individual can be classified into a given concept D, if and only if there exists a concept behind its ABox assertions subsumed by D [20], [17], [18].", "startOffset": 201, "endOffset": 205}, {"referenceID": 16, "context": "The MSC method for individual checking is based on the idea that, an individual can be classified into a given concept D, if and only if there exists a concept behind its ABox assertions subsumed by D [20], [17], [18].", "startOffset": 207, "endOffset": 211}, {"referenceID": 17, "context": "The MSC method for individual checking is based on the idea that, an individual can be classified into a given concept D, if and only if there exists a concept behind its ABox assertions subsumed by D [20], [17], [18].", "startOffset": 213, "endOffset": 217}, {"referenceID": 22, "context": "When role assertions are involved, however, a more complex procedure is demanded, and the method we used here is called rolling-up [23], which is elaborated in the next section.", "startOffset": 131, "endOffset": 135}, {"referenceID": 19, "context": "T [20], [17], [18].", "startOffset": 2, "endOffset": 6}, {"referenceID": 16, "context": "T [20], [17], [18].", "startOffset": 8, "endOffset": 12}, {"referenceID": 17, "context": "T [20], [17], [18].", "startOffset": 14, "endOffset": 18}, {"referenceID": 15, "context": "As shown in [16], for subsumption (1) to hold when A is a named concept, there must exist some role restriction \u2203R\u2032.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "1 ([16]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 15, "context": "This proposition is proven in [16].", "startOffset": 30, "endOffset": 34}, {"referenceID": 23, "context": "We assume the ABox considered here is consistent, since for any inconsistent ABox, the MSCT is always the bottom concept \u22a5 [24].", "startOffset": 123, "endOffset": 127}, {"referenceID": 22, "context": "This rolling-up technique was introduced in [23] to convert conjunctive queries into concept terms, and was also used by [25] to transform datalog rules into DL axioms.", "startOffset": 44, "endOffset": 48}, {"referenceID": 24, "context": "This rolling-up technique was introduced in [23] to convert conjunctive queries into concept terms, and was also used by [25] to transform datalog rules into DL axioms.", "startOffset": 121, "endOffset": 125}, {"referenceID": 25, "context": "Even if Mary is explicitly indicated in the query, we can still eliminate it by using a representative concept that stands for this particular individual in the given ABox [26].", "startOffset": 172, "endOffset": 176}, {"referenceID": 25, "context": "(Lawyer u Amary)(Tom); and if the query is also rewritten using concept Amary , the completeness of the query answering can be guaranteed, as indicated by the following theorem [26].", "startOffset": 177, "endOffset": 181}, {"referenceID": 25, "context": "1 ([26]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "Transitive Role: In the rolling-up procedure, no particular care needs to be taken to deal with transitive roles, since any role assertions derived from transitive roles will be automatically preserved [26].", "startOffset": 202, "endOffset": 206}, {"referenceID": 26, "context": "Multiple solutions to this problem have been proposed, such as an approximation developed by [27], and the use of cyclic concept definition with greatest fixpoint semantics [24], [28].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Multiple solutions to this problem have been proposed, such as an approximation developed by [27], and the use of cyclic concept definition with greatest fixpoint semantics [24], [28].", "startOffset": 173, "endOffset": 177}, {"referenceID": 27, "context": "Multiple solutions to this problem have been proposed, such as an approximation developed by [27], and the use of cyclic concept definition with greatest fixpoint semantics [24], [28].", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "{x}) to handle circles as suggested by [20], [19], which allows explicit indication of named individuals in a concept, hence, being able to indicate the joint node of a cycle.", "startOffset": 39, "endOffset": 43}, {"referenceID": 18, "context": "{x}) to handle circles as suggested by [20], [19], which allows explicit indication of named individuals in a concept, hence, being able to indicate the joint node of a cycle.", "startOffset": 45, "endOffset": 49}, {"referenceID": 23, "context": "C1 in the left hand side of the axiom in fact makes no contribution to the inference of a\u2019s classification, unless the ABox is inconsistent where MSC\u2019s are always \u22a5 [24].", "startOffset": 165, "endOffset": 169}, {"referenceID": 17, "context": "The idea of most specific concept for instance checking was first discussed in [18], and later extensively studied by [20], [17] for the algorithms and the computational complexity.", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "The idea of most specific concept for instance checking was first discussed in [18], and later extensively studied by [20], [17] for the algorithms and the computational complexity.", "startOffset": 118, "endOffset": 122}, {"referenceID": 16, "context": "The idea of most specific concept for instance checking was first discussed in [18], and later extensively studied by [20], [17] for the algorithms and the computational complexity.", "startOffset": 124, "endOffset": 128}, {"referenceID": 23, "context": "To deal with existential restrictions when computing the most specific concept, [24], [29], [28] discussed the use of cyclic concepts with greatest fixpoint semantics for preservation of information induced by the role assertions, and [27] also proposed an approximation for most specific concept in DLs with existential restrictions.", "startOffset": 80, "endOffset": 84}, {"referenceID": 28, "context": "To deal with existential restrictions when computing the most specific concept, [24], [29], [28] discussed the use of cyclic concepts with greatest fixpoint semantics for preservation of information induced by the role assertions, and [27] also proposed an approximation for most specific concept in DLs with existential restrictions.", "startOffset": 86, "endOffset": 90}, {"referenceID": 27, "context": "To deal with existential restrictions when computing the most specific concept, [24], [29], [28] discussed the use of cyclic concepts with greatest fixpoint semantics for preservation of information induced by the role assertions, and [27] also proposed an approximation for most specific concept in DLs with existential restrictions.", "startOffset": 92, "endOffset": 96}, {"referenceID": 26, "context": "To deal with existential restrictions when computing the most specific concept, [24], [29], [28] discussed the use of cyclic concepts with greatest fixpoint semantics for preservation of information induced by the role assertions, and [27] also proposed an approximation for most specific concept in DLs with existential restrictions.", "startOffset": 235, "endOffset": 239}, {"referenceID": 29, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 21, "endOffset": 24}, {"referenceID": 4, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 26, "endOffset": 29}, {"referenceID": 1, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 45, "endOffset": 48}, {"referenceID": 30, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "clauses of DLs [30], [4], [5], model merging [2] and extended pseudo model merging technique [31], [3].", "startOffset": 99, "endOffset": 102}, {"referenceID": 29, "context": "Absorption optimizations [30], [32], [33] were developed to reduce such nondeterminism by combining GCIs for unfoldable concepts, such that the effectiveness of lazy unfolding can be maximized.", "startOffset": 25, "endOffset": 29}, {"referenceID": 31, "context": "Absorption optimizations [30], [32], [33] were developed to reduce such nondeterminism by combining GCIs for unfoldable concepts, such that the effectiveness of lazy unfolding can be maximized.", "startOffset": 31, "endOffset": 35}, {"referenceID": 32, "context": "Absorption optimizations [30], [32], [33] were developed to reduce such nondeterminism by combining GCIs for unfoldable concepts, such that the effectiveness of lazy unfolding can be maximized.", "startOffset": 37, "endOffset": 41}, {"referenceID": 33, "context": "Based on the absorption optimization, [34] proposed an approach for efficient ABox reasoning for ALCIQ that will convert ABox assertions into TBox axioms, apply a absorption technique on the TBox, and covert instance retrieval into concept satisfaction problems.", "startOffset": 38, "endOffset": 42}, {"referenceID": 34, "context": "Another way to reduce nondeterminism is the exploration of Horn clauses in DLs, since there exist reasoning techniques for Horn clauses that can be deterministic [35], [5].", "startOffset": 162, "endOffset": 166}, {"referenceID": 4, "context": "Another way to reduce nondeterminism is the exploration of Horn clauses in DLs, since there exist reasoning techniques for Horn clauses that can be deterministic [35], [5].", "startOffset": 168, "endOffset": 171}, {"referenceID": 4, "context": "[5] takes advantage of this in their HermiT reasoner by preprocessing a DL ontology into DL-clauses and invoking the hyperresolution for the Horn clauses, avoiding unnecessary nondeterministic handling of Horn problems in existing DL tableau calculi.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "For non-Horn DL, techniques such as model merging [2] and pseudo model merging [31] can be used to capture some deterministic information of named individuals.", "startOffset": 50, "endOffset": 53}, {"referenceID": 30, "context": "For non-Horn DL, techniques such as model merging [2] and pseudo model merging [31] can be used to capture some deterministic information of named individuals.", "startOffset": 79, "endOffset": 83}, {"referenceID": 35, "context": "For example, the description logic EL and its extension EL, which allow existential restrictions and conjunction as introduced by [36], [37], possess intriguing algorithmic properties such that the satisfiability problem and implication in this DL language can be determined in polynomial time.", "startOffset": 130, "endOffset": 134}, {"referenceID": 36, "context": "For example, the description logic EL and its extension EL, which allow existential restrictions and conjunction as introduced by [36], [37], possess intriguing algorithmic properties such that the satisfiability problem and implication in this DL language can be determined in polynomial time.", "startOffset": 136, "endOffset": 140}, {"referenceID": 37, "context": "Another notable example of lightweight DLs is the so-called DL-LITE family identified by [38], which is specifically tailored to capture basic DL properties and expressivity while still be able to achieve low computational complexity for both TBox and ABox reasoning.", "startOffset": 89, "endOffset": 93}, {"referenceID": 8, "context": "In [39], [9] they further identified that, for conjunctive queries that are FOL-reducible, answering them in ontologies of any DL-LITE logic enjoys a LOGSPACE data complexity.", "startOffset": 9, "endOffset": 12}, {"referenceID": 38, "context": "Based on the above lightweight DLs, efficient DL reasoners are developed, such as OWLIM [40], ELK reasoner [41], and Oracle\u2019s native inference engine for RDF data sets [42].", "startOffset": 88, "endOffset": 92}, {"referenceID": 39, "context": "Based on the above lightweight DLs, efficient DL reasoners are developed, such as OWLIM [40], ELK reasoner [41], and Oracle\u2019s native inference engine for RDF data sets [42].", "startOffset": 107, "endOffset": 111}, {"referenceID": 40, "context": "Based on the above lightweight DLs, efficient DL reasoners are developed, such as OWLIM [40], ELK reasoner [41], and Oracle\u2019s native inference engine for RDF data sets [42].", "startOffset": 168, "endOffset": 172}, {"referenceID": 41, "context": "[43] proposed an approximation technique for instance retrieval, which computes both lower bound and upper bound of an answer set of individuals for a given query concept.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Recently, techniques for partitioning or modularizing ABoxes into logically-independent fragments have been developed [15], [16].", "startOffset": 118, "endOffset": 122}, {"referenceID": 15, "context": "Recently, techniques for partitioning or modularizing ABoxes into logically-independent fragments have been developed [15], [16].", "startOffset": 124, "endOffset": 128}, {"referenceID": 42, "context": "1) LUBM(s) (LM) are benchmark ontologies generated using the tool provided by [44], 2) Arabidopsis thaliana (AT) and Caenorhabditis elegans (CE) are two biomedical ontologies5, sharing a common TBox called Biopax that models biological pathways, and 3) DBpedia\u2217 (DP) ontologies are extended from the original DBpedia ontology [45]: expressivity of their TBox is extended from ALF to SHI by adding complex roles and concepts defined on role restrictions; their ABoxes are obtained by random sampling on the original triple store.", "startOffset": 78, "endOffset": 82}, {"referenceID": 43, "context": "1) LUBM(s) (LM) are benchmark ontologies generated using the tool provided by [44], 2) Arabidopsis thaliana (AT) and Caenorhabditis elegans (CE) are two biomedical ontologies5, sharing a common TBox called Biopax that models biological pathways, and 3) DBpedia\u2217 (DP) ontologies are extended from the original DBpedia ontology [45]: expressivity of their TBox is extended from ALF to SHI by adding complex roles and concepts defined on role restrictions; their ABoxes are obtained by random sampling on the original triple store.", "startOffset": 326, "endOffset": 330}, {"referenceID": 9, "context": "both size of a TBox and size of the testing concepts [10].", "startOffset": 53, "endOffset": 57}, {"referenceID": 9, "context": "As we already know, one of the major source of complexity in ontology reasoning is the so-called \"and-branching\", which introduces new individuals in the tableau expansion through the \u2203-rule, and affects the searching space of the reasoning algorithm as discussed in [10].", "startOffset": 267, "endOffset": 271}, {"referenceID": 15, "context": "In particular, in our previous study of modularization for ontology ABoxes [16], the biomedical ontologies (i.", "startOffset": 75, "endOffset": 79}, {"referenceID": 15, "context": "AT and CE ) are found to be complex with many of their ontology roles (33 out of 55) used for concept definitions, and their ABoxes are hard to be modularized even with various optimization techniques applied [16].", "startOffset": 209, "endOffset": 213}, {"referenceID": 15, "context": "Moreover, we also compare the MSCT method with the ABox partitioning method (modular reasoning) developed in [16], as they are developed based on the similar principles and both allow parallel or distributed reasoning.", "startOffset": 109, "endOffset": 113}, {"referenceID": 15, "context": "The MSCT \u2019s here are computed using algorithm V3, and the ABox partitioning technique used is the most optimized one presented in [16].", "startOffset": 130, "endOffset": 134}, {"referenceID": 4, "context": "For a regular complete ABox reasoning, the reasoners used are OWL DL reasoners, HermiT [5] and Pellet [6], each of which has its particular optimization techniques", "startOffset": 87, "endOffset": 90}, {"referenceID": 5, "context": "For a regular complete ABox reasoning, the reasoners used are OWL DL reasoners, HermiT [5] and Pellet [6], each of which has its particular optimization techniques", "startOffset": 102, "endOffset": 105}, {"referenceID": 15, "context": "However, as shown in previous section and in [16], this overhead is negligible comparing with the efficiency gained on the reasoning, not to mention when these two methods get parallelized using existing frameworks such as MapReduce [46].", "startOffset": 45, "endOffset": 49}, {"referenceID": 44, "context": "However, as shown in previous section and in [16], this overhead is negligible comparing with the efficiency gained on the reasoning, not to mention when these two methods get parallelized using existing frameworks such as MapReduce [46].", "startOffset": 233, "endOffset": 237}, {"referenceID": 15, "context": "For the latter, the improvement in LUBM1 and LUBM2 are not as significant as in others, which is because of the simplicity of these two ontologies that allows fine granularity of ABox partitions to be achieved [16].", "startOffset": 210, "endOffset": 214}], "year": 2015, "abstractText": "Efficiently querying Description Logic (DL) ontologies is becoming a vital task in various data-intensive DL applications. Considered as a basic service for answering object queries over DL ontologies, instance checking can be realized by using the most specific concept (MSC) method, which converts instance checking into subsumption problems. This method, however, loses its simplicity and efficiency when applied to large and complex ontologies, as it tends to generate very large MSC\u2019s that could lead to intractable reasoning. In this paper, we propose a revision to this MSC method for DL SHI, allowing it to generate much simpler and smaller concepts that are specific-enough to answer a given query. With independence between computed MSC\u2019s, scalability for query answering can also be achieved by distributing and parallelizing the computations. An empirical evaluation shows the efficacy of our revised MSC method and the significant efficiency achieved when using it for answering", "creator": "LaTeX with hyperref package"}}}