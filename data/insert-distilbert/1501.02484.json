{"id": "1501.02484", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2015", "title": "Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart Devices", "abstract": "smart devices with built - in sensors, shared computational capabilities, and network gateway connectivity have become increasingly pervasive. the crowds of smart devices offer opportunities to collectively sense and perform computing tasks in an unprecedented scale. this paper presents crowd - ml, a privacy - preserving machine learning framework for a crowd of smart devices, which can solve a wide range of discrete learning problems for crowdsensing data with purely differential privacy threshold guarantees. hence crowd - ml endows a crowdsensing system with an ability to learn classifiers or predictors online from shared crowdsensing data privately with minimal computational overheads on networking devices and servers, suitable for a practical and large - scale employment of the framework. we analyze the performance and the scalability of crowd - ml, and implement the system with off - the - shelf smartphones as a proof of concept. often we demonstrate the advantages of crowd - related ml with real and simulated experiments under various conditions.", "histories": [["v1", "Sun, 11 Jan 2015 18:57:28 GMT  (681kb,D)", "http://arxiv.org/abs/1501.02484v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.DC cs.NI", "authors": ["jihun hamm", "adam champion", "guoxing chen", "mikhail belkin", "dong xuan"], "accepted": false, "id": "1501.02484"}, "pdf": {"name": "1501.02484.pdf", "metadata": {"source": "CRF", "title": "Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart Devices", "authors": ["Jihun Hamm", "Adam Champion", "Guoxing Chen", "Mikhail Belkin", "Dong Xuan"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION"}, {"heading": "A. Crowdsensing", "text": "Smart devices are increasingly pervasive in daily life. These devices are characterized by their built-in sensors (e.g., accelerometers, cameras, and, microphones), programmable computation ability, and Internet connectivity via wireless or cellular networks. These include stationary devices such as smart thermostats and mobile devices such as smartphones or in-vehicle systems. More and more devices are also being interconnected, often referred to as the \u201cInternet of Things.\u201d Inter-connectivity offers opportunities for crowds of smart devices to collectively sense and compute in an unprecedented scale. Various applications of crowdsensing have been proposed, including personal health/fitness monitoring, environmental sensing, and monitoring road/traffic conditions (see Section II-A), and the list is currently expanding.\nCrowdsensing is used primarily for collecting and analyzing aggregate data from a population of participants. However, more complex and useful tasks can be performed beyond calculation of aggregate statistics, by using machine learning algorithms on crowdsensing data. Examples of such tasks include: learning optimal settings of room temperatures for smart thermostats; predicting user activity for context-aware services and physical monitoring; suggesting the best driving routes; recognizing audio events from microphone sensors. Specific algorithms and data types for these tasks are different, but they can all be trained in standard unsupervised or supervised learning settings: given sensory features (time, location,\nmotion, environmental measures, etc.), train an algorithm or model that can accurately predict a variable of interest (temperature setting, current user activity, amount of traffic, audio events, etc.). Conventionally, crowdsensing and machine learning are performed as two separate processes: devices passively collect and send data to a central location, and analyses or learning procedures are performed at the remote location. However, current generations of smart devices have computing capabilities in addition to sensing. In this paper, we propose to utilize computing capabilities of smart devices, and integrate sensing and learning processes together into a crowdsensing system. As we will show, the integration allows us to design a system with better privacy and scalability."}, {"heading": "B. Privacy", "text": "Privacy is an important issue for crowdsensing applications. By assuring participants\u2019 privacy, a crowdsensing system can appeal to a larger population of potential participants, which increases the utility of such a system. However, many crowdsensing systems in the literature do not employ any privacy-preserving mechanism (see Section II-B), and existing mechanisms used in crowdsensing (see [1]) are often difficult to compare qualitatively across different systems or data types. In the last decade, differential privacy has gained popularity as a formal and quantifiable measure of privacy risk in data publishing [2]\u2013[4]. Briefly, differential privacy measures how much the outcome of a procedure changes probabilistically by presence/absence of any single subject in the original data. The measure provides an upper bound on privacy loss regardless of the content of data or any prior knowledge an adversary might have. While differential privacy has been applied in data publishing and machine learning, (see Section II-B), it has not been broadly adopted in crowdsensing systems. In this paper, we integrate differentially private mechanisms into the crowdsensing system as well, which can provide strong protection against various types of possible attacks (see Section III-C)."}, {"heading": "C. Proposed work", "text": "This paper presents Crowd-ML, a privacy-preserving machine learning framework for crowdsensing system that consists of a server and smart devices (see Fig. 1). Crowd-ML is a distributed learning framework that integrates sensing,\nar X\niv :1\n50 1.\n02 48\n4v 1\n[ cs\n.L G\n] 1\n1 Ja\nn 20\n15\nlearning, and privacy mechanisms together, and can build classifiers or predictors of interest from crowdsensing data using computing capability of devices with formal privacy guarantees.\nAlgorithmically, Crowd-ML learns a classifier or predictor by a distributed incremental optimization. Optimal parameters of a classifier or predictor are found by minimizing the risk function associated with a given task [5] (see Section III-A for details). Specifically, the framework finds optimal parameters by incrementally minimizing the risk function using a variant of stochastic (sub)gradient descent (SGD) [6]. Unlike batch learning, SGD requires only the gradient information to be communicated between devices and a server, which has two important consequences: 1) computation load can be distributed among the devices, enhancing scalability of the system; 2) private data of the devices need not be communicated directly, enhancing privacy. By exploiting these two properties, Crowd-ML efficiently learns a classifier or predictor from a crowd of devices, with a guarantee of -differential privacy. Differential privacy mechanism is applied locally on each device, using Laplace noise for the gradients and exponential mechanisms for other information (see Section III-C).\nWe show advantages of Crowd-ML by analyzing its scalability and privacy-performance trade-offs (Section IV), and by testing the framework with demonstrative tasks implemented on Android smartphones and in simulated environments under various conditions (see Section V).\nIn summary, we make the following contributions:\n\u2022 We present Crowd-ML, a general framework for machine learning with smart devices from crowdsensing data, with many potential applications. \u2022 We show differential privacy guarantees of Crowd-ML that provide a strong privacy mechanism against various types of attacks in crowdsensing. To the best of our knowledge, Crowd-ML is the first general framework that integrates sensing, learning, and differentially private mechanisms for crowdsensing. \u2022 We analyze the framework to show that the cost of\nprivacy preservation can be minimized and that the computational and communication overheads on devices are only moderate, allowing a large-scale deployment of the framework. \u2022 We implement a prototype and evaluate the framework with a demonstrative task in a real environment as well as large-scale experiments in a simulated environment.\nThe remainder of this paper is organized as follows. We first review related work in Section II. Section III describes the Crowd-ML framework. Section IV analyzes Crowd-ML in terms of privacy-performance trade-off, computation, and communication loads. Section V presents an implementation of Crowd-ML and experimental evaluations. We discuss remaining issues and conclude in Section VI."}, {"heading": "II. RELATED WORK", "text": "Crowd-ML integrates distributed learning algorithms and differential privacy mechanisms into a crowdsensing system. In this section, we review related work in crowdsensing and learning systems, and privacy-preserving mechanisms."}, {"heading": "A. Crowdsensing and learning", "text": "There is a vast amount of work in crowdsensing, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey papers [7] and [1]). Crowdsensing systems aim to achieve mass collection and mining of environmental and human-centric data such as social interactions, political issues of interest, exercise patterns, and people\u2019s impact on the environment [8]. Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12]. Data collected by crowdsensing can also be used to mine high-level patterns or to predict variables of interest using machine learning. Applications of learning applied to crowdsensing include learning of bus waiting times [13] and recognizing user activities (see [14] for a review). Jigsaw [15] and Lifestreams [16] also use pattern recognition in sensed data from mobile devices. From the system perspective, these work use devices to passively sense and send data to a central server on which analyses take place, which we will refer to as the centralized approach. In contrast, sensing and learning can be performed purely inside each device without a server, which we call the decentralized approach. For example, SoundSense [17] learns a classifier on a smartphone to recognized various audio events without communicating with the back-end. Mixed centralized and decentralized approaches are also used in [18], [19], where a portion of computation is performed off-line on a server. CQue [18] provides a query interface for privacyaware probabilistic learning of users\u2019 contexts, and ACE [19] uses static association rules to learn users\u2019 contexts. Systemwise, our work differs from those centralized or decentralized approaches in that we use a distributed approach to perform learning by devices and server together, which improves privacy and scalability of the system. We are not aware of any other crowdsensing system that takes a similar approach. Also, the cited papers are oriented towards novel applications,\nbut our work focuses on a general framework for learning a wide range of algorithms and applications.\nCrowd-ML also builds on recent advances in incremental distributed learning [20], [21], which show that a near-optimal convergence rate is achievable despite communication delays. A privacy-preserving stochastic gradient descent method is presented briefly in [22]. Unlike the latter, we presents a complete framework for privacy-preserving multi-device learning, with performance analysis and demonstrations in real environments."}, {"heading": "B. Privacy-preserving mechanisms", "text": "Privacy is an important issue in data collection and analysis. In particular, preserving privacy of users\u2019 locations has been studied by many researchers (see [23] for a survey). To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1]. Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk. Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17]. So far, formal and general privacy mechanisms have not been adopted broadly in crowdsensing. Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally. To our best knowledge, Crowd-ML is the first framework to provide formal privacy guarantees in general crowd-based learning with smart devices."}, {"heading": "III. CROWD-ML", "text": "In this section, we describe our Crowd-ML in detail: system, algorithms, and privacy mechanisms."}, {"heading": "A. System and workflow", "text": "The Crowd-ML system consists of a server and multiple smart devices that are capable of sensory data collection, numerical computation, and communication over a public network with the server (see Fig. 1). The goal of CrowdML is to learn a classifier or predictor of interest from crowdsensing data collectively by multiple devices. A widerange of classifiers or predictors can be learned by minimizing an empirical risk associated with a given task, a common method in statistical learning [5]. Formally, let x \u2208 RD be a feature vector from preprocessing sensory input such as audio, video, accelerometer, etc, and y be a target variable we aim to predict from x, such as user activity. For regression, y can be a real number and for classification, y is a discrete label y \u2208 {1, ..., C} with C classes. We define data as N pairs of (feature vector, target variable) generated i.i.d. from an unknown distribution by all participating devices up to present:\nD = {(x1, y1), ..., (xN , yN )}. (1)\nSuppose we use a classifier/predictor h(x;w) with a tunable parameter vector w, and a loss function l(y, h(x;w)) to measure the performance of the classifier/predictor with respect to the true target y. A wide range of learning algorithms can be represented by h and l, e.g., regression, logistic regression, and Support Vector Machine (see [32] for more examples). If there are M smart devices, we find the optimal parameters w of the classifier/predictor by minimizing the empirical risk over all M devices:\nR(w) = M\u2211 m=1 1 |Dm| \u2211\n(x,y)\u2208Dm\nl(h(x;w), y) + \u03bb\n2 \u2016w\u20162, (2)\nwhere Dm is a set of samples generated from device m only, and \u03bb2 \u2016w\u2016\n2 is a regularization term. This risk function (2) can be minimized by many optimization methods. In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34]. SGD minimizes the risk by updating w sequentially\nw(t+ 1)\u2190 \u03a0W [w(t)\u2212 \u03b7(t)g(t)] , (3)\nwhere \u03b7(t) is the learning rate, and g(t) is the gradient of the loss function\ng = \u2207wl(h(x;w), y), (4)\nevaluated with the sample (x, y) and the current parameter w(t). We assume the parameter domain W is a d-dimensional ball of some large radius R, and the projection is \u03a0W = min(1, R/\u2016w\u2016)w. By default, we use the learning rate\n\u03b7(t) = c\u221a t , (5)\nwhere c is a constant hyperparameter. When computing gradients, we use a \u2018minibatch\u2019 of b samples to compute the averaged gradient\ng\u0303 = 1\nb \u2211 i \u2207wl(h(xi;w), yi), (6)\nwhich plays an important role in the performance-privacy trade-off and the scalability (Section IV). In Crowd-ML, risk minimization by SGD is performed by distributing the main workload (=computation of averaged gradients) to M devices. Note that each device generates data and compute gradients using its own data. The workflow is described in Fig. 2."}, {"heading": "B. Algorithms", "text": "Crowd-ML algorithms are presented in Algorithms 1 and 2. Device Routine 1 collects samples. When the number of samples reaches the minibatch size b, the routine tries to checks out the current model parameters w from the server and calls Device Routine 2. Device Routine 2 computes the averaged gradient from the stored samples and w received from the server, sanitizes information by Device Routine 3, and sends the sanitized information to the server. Device Routine 3 uses Laplace noise and exponential mechanisms (in the next section) to sanitize the averaged gradient g\u0302, the\nnumber of misclassified samples n\u0302e and the label counts n\u0302ky . Device Routines 1-3 are performed independently and asynchronously by multiple devices.\nServer Routine 1 sends out current parameters w when requested and Server Routine 2 receives checkins (g\u0302, ns, n\u0302e,n\u0302ky) from devices when requested. The whole procedure ends when the total number of iteration exceeds a maximum value Tmax, or the overall error is below a threshold \u03c1.\nRemark 1: In Device Routine 1, if check-out fails, the device keeps collecting samples and retries check-out later. A prolonged period of network outage for a device can make the parameter outdated for the device, but it does not affect the overall learning critically. Similarly, failure to check-in information with server in Device Routine 2 is non-critical.\nRemark 2: In Device Routine 2, we can randomly set aside a small portion of samples as test data. In this case, the misclassification error is computed only from these held-out samples, and their gradients will not be used in the average g\u0302.\nRemark 3: In Server Routine 2, more recent update methods [35], [36] can be used in place of the simple update rule (3) without affecting differential privacy nor changing device routines. Similarly, adaptive learning rates [37], [38] can be used in place of (5), which can provide a robustness to large gradients from outlying or malignant devices."}, {"heading": "C. Privacy mechanism", "text": "In crowdsensing systems, private data of users can be leaked by many ways. System administrators/analysts can violate the privacy intentionally, or they may leak private information unintentionally when publishing data analytics. There are also more hostile types of attacks: by malignant devices posing\nAlgorithm 1 Device side Input: privacy levels g, e, yk , minibatch size b, max buffer size B, classifier model (C, h, l, \u03bb from Eq. (2)) Init: set ns = 0, ne = 0, nky = 0, k = 1, ..., C Communication to server: g\u0302, ns, n\u0302e, n\u0302ky Communication from server: w Device Routine 1\nif ns \u2265 B then stop collection to prevent resource outage else receive a sample (x, y) (in a regular interval or triggered by events), and add to the secure local buffer ns = ns + 1 end if if ns \u2265 b then\ncheckout w from the server via https call Device Routine 2.\nend if Device Routine 2\nUsing w from the server and {(x, y)} from the local buffer,\nfor i = 1, ..., ns do make a prediction ypred = h(xi;w) n (yi) y = n (yi) y + 1\nne = ne + I[y pred i 6= yi] Incur a loss l(ypred, yi) Compute a subgradient gi = \u2207wl(h(xi;w))\nend for Compute the average g\u0303 = 1ns \u2211 i gi + \u03bbw Sanitize data with Device Routine 3 Checkin g\u0302, ns, n\u0302e n\u0302ky , k = 1, ..., C with server via https Reset ns = 0, ne = 0, nky = 0, k = 1, ..., C\nDevice Routine 3 Sample g\u0302 = g\u0303 + z from Eq. (10) Sample n\u0302e = ne + z from Eq. (11) Sample n\u0302ky = n k y + z, k = 1, ..., C from Eq. (12)\nas legitimate devices, by hackers poaching data stored on the server or eavesdropping on communication between devices and servers. Instead of preserving privacy separately for each attack type, we can preserve privacy from all these attacks by a local privacy-preserving mechanism that is implemented on each device and sanitizes any information before it leaves the device. A local mechanism assumes that an adversary can potentially access all communication between devices and the server, which subsumes the other attack attacks. This is because the other forms of data that are 1) visible to malignant device, 2) stored in the server, or 3) released in public, are all derived from what is communicated between devices and the server. We adopt a local -differential privacy as a quantifiable measure of privacy in Crowd-ML. Formally, a (randomized) algorithm which takes data D as input and outputs f , is called\nAlgorithm 2 Sever side Input: number of devices M , learning rate schedule \u03b7(t), t = 1, 2, ..., Tmax, desired error \u03c1, classifier model (C, h, l, \u03bb from Eq. (2)) Init: t = 0, randomized w, Nms = 0, N m e = 0, N k,m y , m ="}, {"heading": "1, ...,M, k = 1, ..., C", "text": "Stopping criteria: t \u2265 Tmax or \u2211M m N m e\u2211M\nm N m s \u2264 \u03c1 Server Routine 1\nwhile Stopping criteria not met do Listen to and accept checkout requests Authenticate device Send current parameters w to device\nend while Server Routine 2\nwhile Stopping criteria not met do Listen to and accept checkin requests Authenticate device (suppose it is device m) Receive g\u0302, ns, n\u0302e, n\u0302ky , k = 1, ..., C. Nms = N m s + ns\nNme = N m e + n\u0302e Nk,my = N k,m y + n\u0302 k y w = w \u2212 \u03b7(t)g\u0302 t = t+ 1\nend while\n-differentially private if\nP (f(D) \u2208 S) P (f(D\u2032) \u2208 S) \u2264 e (7)\nfor all measurable S \u2282 T of the output range, and for all data sets D and D\u2032 differing in a single item. That is, even if an adversary has the whole data D except a single item, it cannot infer much more about that item from the output of the algorithm f . A smaller makes such an inference more difficult, and therefore makes the algorithm more privatepreserving. When the algorithm outputs a real-valued vector f \u2208 RD, its global sensitivity can be defined by\nS(f) = max D,D\u2032 \u2016f(D)\u2212 f(D\u2032)\u20161. (8)\nwhere \u2016 \u00b7 \u20161 is the L1 norm. A basic result from the definition of differential privacy is that a vector-valued function f with sensitivity S(f) can be made -differentially private [3] by adding an independent Laplace noise vector z1\nP (z) \u221d e\u2212 S(f) \u2016z\u20161 . (9)\nIn Crowd-ML, we consider -differential privacy of any single (feature,label)-sample, revealed by communications from all devices to the server, which are the gradients g\u0303, the numbers of samples ns, the number of misclassified samples ne, and the labels counts nky 2. The amount of noise required depends\n1As a variant, ( , \u03b4)-differential privacy can be achieved by adding Gaussian noise.\n2The communication from the server to devices {w(t)} can be reconstructed by (3) from {g(t)}, and therefore is redundant to consider.\non the choice of loss functions. We compute this value for multiclass logistic regression (Table I), but it can be computed similarly for other loss functions as well. By adding elementwise independent Laplace noise z to averaged gradients g\u0303\ng\u0302 = 1\nb \u2211 i gi + z, P (z) \u221d e\u2212 gb 4 |z|, (10)\nwe have the following privacy guarantee:\nTheorem 1 (Averaged gradient perturbation). The transmission of g\u0303 by Eq. (10) is g-differentially private.\nSee Appendix A for proof. To sanitize ne and nky , we add \u2018discrete\u2019 Laplace noise [39] as follows:\nn\u0302e = ne + z, P (z) \u221d e\u2212 e 2 |z|, (11)\nn\u0302ky = n k y + z, P (z) \u221d e\u2212\nyk 2 |z|, (12)\nwhere z = 0,\u00b11,\u00b12, .... These mechanisms has the following privacy guarantees:\nTheorem 2 (Error and label counts). The transmission of ne and nky by Eqs. (11) and (12) is e- and yk - differentially private, respectively.\nSee Appendix B for proof. Practically, a system administrator chooses depending on the desired level of privacy for the data collected. A small (\u2192 0) may be used for data that users deem highly private such as current location, and a large (\u2192\u221e) may be used for less private data such as ambient temperature."}, {"heading": "IV. ANALYSIS", "text": "In this section, we analyze the privacy-performance tradeoff and the scalability of Crowd-ML. As discussed in Related Work, most existing crowdsensing systems use purely centralized or purely decentralized approaches, while Crowd-ML uses a distributed approach. By design, Crowd-ML achieves differential privacy with little loss of performance (O(1/b)), only moderate computation load due to its simple optimization method, and reduced communication load and delay (O(1/b)), where b is the minibatch size."}, {"heading": "A. Privacy vs Performance", "text": "Privacy costs performance: the more private we make the system, the less accurate the outcome of analysis/learning is. From Theorem 1, Crowd-ML is -differentially private by perturbing averaged gradients. The centralized approach can also be made -differentially private by feature and label perturbation (Appendix C). Below we compare the\nimpact of privacy on performance between the centralized and Crowd-ML. The performance of an SGD-based learning can be represented by its rate of convergence to the optimal value/parameters E[l(w(t))\u2212l(w\u2217)] at iteration t, which in turn depends on the properties of the loss l(\u00b7) (such as Lipschitzcontinuity and strong-convexity) and the step size \u03b7(t), with the best known rate being O(1/t) [40]. When other conditions are the same, the convergence rate is roughly proportional E[l(w(t)) \u2212 l(w\u2217)] \u221d G2 to the amount of noise in the estimated gradient G2 = supt E[\u2016g\u0302(t)\u20162] [41]. For CrowdML, we have from (10)\nE[\u2016g\u0302\u20162] = E[\u2016g\u0303\u20162] + E[\u2016z\u20162] = 1 b E[\u2016g\u20162] + 32D (b g)2 , (13)\nwhere the first term is the amount of noise due to sampling, and the latter is due to Laplace noise mechanism with Ddimensional features. By choosing a large enough batch size b, the impact of sampling noise and Laplace noise can be made arbitrarily small3. In contrast, the centralized approach has to add Laplace noise of constant variance 8 2 to each feature and perturb labels with a constant probability (Appendix C). Regardless of which optimization method is used (SGD or not), the centralized approach has no means of mitigating the negative impact of constant noise on the accuracy of learned model, which will be especially problematic with a small .\nIn the decentralized approach, a device need not interact with a server, and is almost free of privacy concerns. However, the increased privacy comes at the cost of performance. In Crowd-ML and the centralized approach, samples pooled from all devices are used in the learning process, whereas in the decentralized approach, each device can use only a fraction (\u223c 1/M ) of samples. This undermines the accuracy of a model learned by the decentralized approach. For example, it is known from the VC-theory for binary classification problems that the upper-bound of the estimation error with a 1/M -times smaller sample size is \u221a M/ logM -times larger [43]."}, {"heading": "B. Scalability", "text": "Scalability is determined by computation and communication loads and latencies on both device and server sides. We compare these factors between centralized, crowd, and decentralized learning approaches.\n1) Computation load: For all three approaches, we assume the same preprocessing is performed on each device to compute features from raw sensory input or metadata. On the device side, the centralized learning approach requires generation of Laplace noise per sample on the device. The crowd and the decentralized approaches perform partial and full learning on the device, respectively, and requires more processing. Specifically, Crowd-ML requires computation of a gradient per sample, a vector summation (for averaging) per sample, and generation of Laplace random noise per minibatch. A lowend smart device capable of floating-point computation can\n3although a larger batch size means fewer updates given the same number of samples N , and too large a batch size can negatively affect the convergence rate (see [42] for discussion).\nperform these operations. The decentralized learning approach can use any learning algorithms, including SGD similar to Crowd-ML. However, if the decentralized approach is to make up for the smaller sample size (1/M ) compared to CrowdML, it may require more complex optimization methods which results in higher computation load. For all three approaches, the number of devices M do not affect per-device computation load. Computational load on the server is also different for these approaches. The centralized approach puts the highest load on the server, as all computations take place on the server. In contrast, Crowd-ML puts minimal load on the server which is the SGD update (3), since the main computation is performed distributed by the devices.\n2) Communication load: To process incoming streams of data from the device in time, the network and the server should have enough throughput. The centralized learning approach requires N number of samples to be sent over the network to the server. For Crowd-ML with a minibatch size of b, devices send N/b gradients altogether, and receives the same number of current parameters, both of the same dimension as a feature vector. Therefore, the data transmission is reduced by a factor of b/2 compared to the centralized approach.\n3) Communication latency: When using a public (and mobile) network, latency is non-negligible. In the centralized approach, latency may not be an issue, since the server need not required to send any real-time feedback to the devices. In Crowd-ML, latency is an issue that can affect its performance. There are three possible delays that add up to the overall latency of communication:\n\u2022 Request delay(\u03c4req): time since the check-out request from a device until the receipt of the request at the server \u2022 Check-out delay (\u03c4co): time since the receipt of a request at the server and the receipt of the parameter at the device \u2022 Check-in delay (\u03c4ci): time since the receipt of the parameters at the device until the receipt of the check-ins at the server\nDue to delays, if a device checks out the parameter w at time t0 and checks in the gradient g\u0302 and the server receives g\u0302 at time t0 + \u03c4co + \u03c4ci, the server may have already updated the parameters w multiple times using the gradients from other devices received during this time period. This number of updates is roughly (\u03c4co + \u03c4ci) \u00d7MFs/b, where M is the number of devices, Fs is the data sampling rate per device, and 1/b is the reduction factor due to minibatch. Again, choosing a large batch size b relative to MFs can reduce the latency. While exact analysis of impact of latency is difficult, there are several related results known in the literature without considering privacy. Nedic\u0301 et al. proved that delayed asynchronous incremental update converges with probability 1 to an optimal value, assuming a finite maximum latency. Recent work in distributed incremental update [20], [21] also shows that a near-optimal convergence rate is achievable despite delays. In particular, Dekel et al. [21] shows that delayed incremental updates are scalable with M by adapting the minibatch size."}, {"heading": "V. EVALUATION", "text": "In this section, we describe a prototype of Crowd-ML implemented on off-the-shelf android phones and activity recognition experiments on android smartphones. We also perform digit and object recognition experiments under varying conditions in simulated environments and demonstrate the advantages of Crowd-ML analyzed in Section IV.\nA. Implementation\nWe implement a Crowd-ML prototype with three components: a Web portal, commercial off-the-shelf smart devices, and a central server. On the device side, we implement Algorithm 1 on commercial off-the-shelf smartphones as an app using Android OS 4.3+. Our prototype uses smartphones, but will be easily ported to other smart device platforms. On the server side, we implement Algorithm 2 on a Lenovo ThinkCentre M82 machine with a quad-core 3.2 GHz Intel Core i5-3470 CPU and 4 GB RAM running Ubuntu Linux 14.04. The server runs the Apache Web server (version 2.4) and a MySQL database (version 5.5).\nAlso on the server side, our Crowd-ML prototype provides a Web portal over HTTPS where users can browse ongoing crowd-learning tasks and join them by downloading the app to their smart devices. To enhance transparency, details of tasks (objective, sensory data collected, labels collected, and learning algorithms used) and our privacy mechanisms is explained. It also displays timely statistics about crowd-learning applications such as error rates and activity label distributions, which are differentially private. We implement the portal in Python using the Django4 Web application framework and Matplotlib5 for statistical visualization."}, {"heading": "B. Activity Recognition in Real Environments", "text": "In this experiment, we perform activity recognition on smart devices. The purpose of this demonstration is to show CrowdML working in a real environment, so we choose a simple task of recognizing three types of user activities (\u201cStill\u201d, \u201cOn Foot\u201d, and \u201cIn Vehicle\u201d). We install a prototype Crowd-ML application on 7 smartphones (Galaxy Nexus, Nexus S, and Galaxy S3) running Android 4.3 or 4.4. The seven smartphones are carried by college students and faculty over a period of a few days. The devices\u2019 triaxial accelerometers are sampled at 20 Hz. In this demonstration, we avoid manual annotation of activity labels to facilitate data acquisition, and instead use Google\u2019s activity recognition service to obtain ground truth labels. Acceleration magnitudes |a| = \u221a a2x + a 2 y + a 2 z are computed continuously over 3.2 s sliding windows. Feature extraction is performed by computing the 64-bin FFT of the acceleration magnitudes. We set the sampling rate Fs = 1/30 Hz, that is, a feature vector x and its label y is generated every 30 s. However, to avoid getting highly correlated samples and to increase diversity of features, we collect a sample only when its label has changed from its\n4http://www.djangoproject.com 5http://matplotlib.org\nprevious value. For example, samples acquired during sleeping are discard automatically as they all have \u201cStill\u201d labels. This lowers the actual sampling rate to about Fs = 1/352 Hz (or every six minute or so). With this low rate, no battery problem was observed.\nWe use 3-class logistic regression (Table I) with \u03bb = 0, b = 1, \u22121 = 0 and a range of \u03b7 values. Repeated experiments with different parameters are time-consuming, and we leave the full investigation to the second experiment in a simulated environment. In Fig. 3, we shows the collective error curves for\nthe first 300 samples from the 7 devices. The error is a timeaveraged misclassification error as the learning progresses: Err(t) = 1t \u2211t i=1 I[yi 6= y pred i (wi)]. The error curves for different learning rates (5) are very similar, and virtually converge after only 50 samples (=7 samples per device). This experiment is a proof-of-concept that Crowd-ML can learn a common classifier fast, from only a small number of samples per user."}, {"heading": "C. Digit/Object Recognition in Simulated Environments", "text": "To evaluate Crowd-ML under various conditions, we perform a series of experiments on handwritten digit recognition and visual object recognition. Since the two results are quite similar, we only describe the digit recognition results (object recognition result is in Appendix D). The MNIST dataset6 consists of 60000 training and 10000 test images of handwritten digits (0 to 9), which is a standard benchmark dataset for learning algorithms. The task is to classify a test image as one of the 10 digit classes. The images from MNIST data are preprocessed with PCA to have a reduced dimension of 50, and L1 normalized. In this experiment, we compare the performance of centralized, Crowd-ML, and decentralized learning approaches using the same data and classifier (multiclass logistic regression), under different conditions such as privacy level , minibatch size b, and delays. To test the algorithms with a full control of parameters, we run the algorithms in a simulated environment instead of on a real network. We can therefore choose the number of devices and maximum delays arbitrarily. For simplicity, we set \u03c4 = \u03c4req = \u03c4co = \u03c4ci (Section IV-B3). The \u03c4 is the maximum delay, and the actually delays are sampled randomly and uniformly from [0, \u03c4 ] for each communication instance.7\n6http://yann.lecun.com/exdb/mnist/ 7We can test with any distribution other than uniform distribution as well.\nAll results in this section are averaged test errors from 10 trials. For each trial, assignment of samples, order of devices, perturbation noise, and amounts of delay are randomized. Test errors are computed as functions of the iteration (=the number of samples used), up to five passes through the data. Hyperparameters \u03bb (Table I) and c (5) are selected from the averaged test error from 10 trials. We set the number of devices M = 1000. Consequently, each device has 60 training and 10 test samples on average.\nFig. 4 compares the performance of the centralized, crowd, and decentralized learning approaches, without privacy or delay ( \u22121 = 0, b = 1, \u03c4 = 0). The error of centralized batch training is the smallest (0.1), in a tie with Crowd-ML. The error curve of Crowd-ML converges to the same low value as centralized approach. It shows that incremental update by SGD in Crowd-ML is as accurate as batch learning, when privacy and delay are not considered. In contrast, the error curve of decentralized approach converges at a slower rate and also converges to a high error (\u223c 0.5), despite using the same overall number of samples as other algorithms, due to the lack of data sharing.\nWe perform tests with varying levels of privacy . The privacy impacts the centralized approach via (15) and (16)8 and also Crowd-ML via (10). With low privacy ( \u22121 \u2192 0), the performance of both centralized and crowd approaches are almost the same as Fig. 4, and we omit the result. With high privacy ( \u2192 0), the performance of both approaches degrades to a unusable level. Here we show their performances at \u22121 = 0.1 in Fig. 5, where the performance is in a transition state between high and low privacy regions. Firstly, the centralized and crowd approaches both perform worse than they did in Fig. 4, which is the price of privacy preservation. Among these results, Crowd-ML with a minibatch size b = 20 has the smallest asymptotic error, much below the centralized (batch). Crowd-ML with b = 1 and 10 still achieves similar or better asymptotic error compared to Central (batch). As predicted from Section IV, increasing the minibatch size improves the performance of Crowd-ML. When SGD is used for centralized approach (Central SGD) with perturbed features and labels, its\n8The features and labels for test data are not perturbed.\nperformance is very poor (\u223c 0.9) regardless of the minibatch size, due to the larger noise required to provide the same level of privacy as Crowd-ML.\nLastly, we look at the impact of delays on Crowd-ML with privacy \u22121 = 0.1. We test with different delays in the unit of \u2206 = \u03c4/(MFs), that is, the number of samples generated by all device during the delay of size \u03c4 . In Fig. 6, we show the results with two minibatch sizes (b = 1, 20) and varying delays (1\u2206, 10\u2206, 100\u2206, 1000\u2206). The delay of 1000\u2206 means that a maximum of 3\u00d71000 samples are generated among the devices, between the time a single device requests a check-out from the server and the time the server received the check-in from that device, which is quite large. Fig. 6 shows that the increase in the delay somewhat slows down the convergence with a minibatch size of 1, and the converged value of error is similar to or worse than Central (batch). However, it also shows that with a minibatch size of 20, delay has little effect on the convergence, and the error is much lower than Central (batch). Note that with the minibatch size of 20, there is a small plateau in the beginning of error curves, reflecting the fact that the devices are initially waiting for their minibatches to be filled before computing begins. After this initial waiting time, the error starts to decrease at a fast rate."}, {"heading": "VI. CONCLUSION", "text": "In this paper, we proposed Crowd-ML, a machine learning framework for a crowd of smart devices. Compared to\nprevious crowdsensing systems, Crowd-ML is a framework that integrates sensing, learning, and privacy mechanisms together, and can build classifiers or predictors of interest from crowdsensing data using computing capability of smart devices. Algorithmically, Crowd-ML utilizes recent advances in distributed and incremental learning, and implements strong differentially private mechanisms. We analyzed Crowd-ML and showed that Crowd-ML can outperform centralized approaches while providing better privacy and scalability, and can also take advantages of larger shared data which decentralized approaches cannot. We implemented a prototype of Crowd-ML and evaluated the framework with a simple activity recognition task in a real environment as well as larger-scale experiments in simulated environments which demonstrate the advantages of the design of Crowd-ML. Crowd-ML is a general framework for a range of different learning algorithms with crowdsensing data, and is open to further refinements for specific applications.\nAPPENDIX"}, {"heading": "A. Proof of Theorem 1", "text": "In our algorithms, a device receives w from the server and sends averaged gradients g\u0302 along with other information. We assume \u2016x\u20161 \u2264 1 which can be easily achieved by normalizing the data. The sensitivity of an averaged gradient for logistic regression is 4/b as shown below. There are C parameter vectors w1, ..., wC for multiclass logistic regression. Let the matrix of gradient vectors corresponding to C parameter vectors be\ng = [g1 g2 \u00b7 \u00b7 \u00b7 gC ] = x[P1 \u00b7 \u00b7 \u00b7 Py\u22121 \u00b7 \u00b7 \u00b7 PC ] + \u03bb[w1 \u00b7 \u00b7 \u00b7 wC ] = xM + \u03bb[w1 \u00b7 \u00b7 \u00b7 wC ],\nwhere Pj = P (y = j|x;w) is the posterior probability, and M is a row vector of Pj\u2019s. Without loss of generality, consider two minibatches D and D\u2032 that differ in only the first sample x1. The difference of averaged gradients g\u0303(D) and g\u0303\u2032(D\u2032) is\n\u2016g\u0303 \u2212 g\u0303\u2032\u20161 \u2264 1\nb (\u2016x1M1\u20161 + \u2016x\u20321M \u20321\u20161) \u2264\n4 b ,\nTo see \u2016M1\u20161 \u2264 2, note that the absolute sum of the entries of M1 is 2(1\u2212Py1) \u2264 2. The sensitivity of multiple minibatches g\u0302(1), ..., g\u0302(T ) is the same as the sensitivity of a single g\u0302(t), and the -differential privacy follows from Proposition 1 of [3]."}, {"heading": "B. Proof of Theorem 2", "text": "In addition to the averaged gradients, a device sends to the server the numbers of samples ns, the number of misclassified samples ne, and the labels counts nky . Perturbation by adding discrete Laplace noise is equivalent to random sampling by exponential mechanism [44] with P (n\u0302e|ne) \u221d e\u2212 e 2 |n\u0302e\u2212ne|, n\u0302e \u2208 Z. If two datasets D and D\u2032 are different in only one item, then the score function d = \u2212|n\u0302e\u2212ne| changes at most by 1. That is, maxD,D\u2032 |d(n\u0302e, ne(D)) \u2212 d(n\u0302e, ne(D\u2032))| = 1. As with multiple gradients, the sensitivity of multiples sets of (n\u0302e, n\u0302ky) is the same as the sensitivity of a single set, and\ne-differential privacy follows from Theorem 6 of [44]. Proof of yk -differential privacy of nky is similar.\nRemark 1: Unlike the gradient g\u0302, the information (ns, n\u0302e, n\u0302ky) is not required for learning itself, but for monitoring the progress of each device on the server side. Therefore, e and yk can be set to be very small without affecting the learning performance, so that = g + e + C yk \u2248 g .\nRemark 2: n\u0302e and n\u0302ky can be negative with a small probability, but have a limited effect on the estimates of the error rate and the prior at the server. After receiving T minibatches, the error rate and the prior estimates are\nErrest = \u2211T i n\u0302e(i)\u2211T i ns(i) and P est(y = k) = \u2211T i n\u0302 k y(i)\u2211T i ns(i) . (14)\nSince n\u0302e(i)\u2212ne(i) is independent for i = 1, 2, ... and has zeromean and constant variance 2e \u2212 e/2\n(1\u2212e\u2212 e/2)2 [39], the estimate of error rate converge almost surely to the true error rate with vanishing variances as T increases. The same can be said of the estimate of prior P (y)."}, {"heading": "C. Differential Privacy in Centralized Approach", "text": "For completeness of the paper, we also describe the - differential privacy mechanisms for the centralized approach. In the centralized approach, data are directly sent to the server. Without a privacy mechanism, an adversary can potentially observe all data. To prevent this, -differential privacy can be enforced by perturbing the features\nf(x) = x+ z, , P (z) \u221d e\u2212 x 2 |z|, (15)\nand also perturbing the labels. To perturb labels, we use exponential mechanism to sample a noisy label y\u0302 given a true label y from\nP (y\u0302|y) \u221d e y 2 d(y,y\u0302), y, y\u0302 \u2208 {1, ..., C} (16)\nwhere we use the score function d(y, y\u0302) = I[y = y\u0302].\nTheorem 3 (Feature and label perturbation). The transmission of x and y by feature perturbation (15) and exponential mechanism (16) is x- and y-differentially private.\nProof: Assume \u2016x\u20161 \u2264 1. Feature transmission is an identity operation and therefore has sensitivity 2. For label transmission, the score function d(y\u0302, y) = I[y\u0302 = y] changes at most by 1 by changing y. From Proposition 1 of [3] and Theorem 6 of [44], respectively, we achieve x- and ydifferential privacy of data.\nNote that the sensitivity is independent of the number of features and labels sent, and we have to add the same level of independent noise to the features and apply the same amount of label perturbation. An overall -differential privacy is achieved by = x+ y . The required privacy levels x and y can be chosen differently, and we use x = y = /2 in the experiments."}, {"heading": "D. Experiments with Visual Object Recognition Task", "text": "We repeat the experiments in Section V-C for an object recognition task using CIFAR-10 dataset, which consists of images of 10 types of objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) collected by [45]. We use 50,000 training and 10,000 test images from CIFAR10. To compute features, we use a convolutional neural network 9 trained using ImageNet ILSVRC2010 dataset10, which consists of 1.2 million images of 1000 categories. We apply CIFAR-10 images to the network, and use the 4096- dimensional output from the last hidden layer of the network as features. Those features are preprocessed with PCA to have a reduced dimension of 100, and are L1 normalized. We use the same setting in Section V-C to test Crowd-ML on this object recognition task. The results are given in Figs. 7, 8, 9. The figures are very similar to the handwritten digit recognition task (Figs. 4, 5, 6), except that the error is larger (e.g., 0.3 in Fig. 7) than the error for digit recognition (0.1 in Fig. 4). This is because CIFAR dataset is more challenging than MNIST due to variations in color, pose, view point, and background of object images."}], "references": [{"title": "A Survey on Privacy in Mobile Participatory Sensing Applications", "author": ["D. Christin", "A. Reinhardt", "S.S. Kanhere", "M. Hollick"], "venue": "J. Syst. Softw., vol. 84, pp. 1928\u20131946, 2011.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1928}, {"title": "Privacy-Preserving Data Mining on Vertically Partitioned Databases", "author": ["C. Dwork", "K. Nissim"], "venue": "Proc. CRYPTO. Springer, 2004. 9https://github.com/jetpacapp/DeepBeliefSDK 10http://www.image-net.org/challenges/LSVRC 0 0.5 1 1.5 2 2.5 x 10  5 0.4 0.5 0.6 0.7 0.8 0.9  1 Iteration  Test error Crowd\u2212ML (b=1,1\u2206) Crowd\u2212ML (b=1,10\u2206) Crowd\u2212ML (b=1,100\u2206) Crowd\u2212ML (b=1,1000\u2206) Crowd\u2212ML (b=20,1\u2206) Crowd\u2212ML (b=20,10\u2206) Crowd\u2212ML (b=20,100\u2206) Crowd\u2212ML (b=20,1000\u2206) Central (batch) Fig. 9: Impact of delays on Crowd-ML with privacy ( \u22121 = 0.1), varying minibatch sizes, and varying delays.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2004}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "Theory of Cryptography. Springer, 2006, pp. 265\u2013284.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "Automata, languages and programming. Springer, 2006, pp. 1\u201312.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "springer,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "The annals of mathematical statistics, pp. 400\u2013407, 1951.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1951}, {"title": "A survey of mobile phone sensing", "author": ["N.D. Lane", "E. Miluzzo", "H. Lu", "D. Peebles", "T. Choudhury", "A.T. Campbell"], "venue": "Comm. Mag., vol. 48, pp. 140\u2013150, September 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Human-Centric Sensing", "author": ["M. Srivastava", "T. Abdelzaher", "B. Szymanski"], "venue": "Phil. Trans. R. Soc. A, vol. 370, pp. 176\u2013197, 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Micro- Blog: Sharing and Querying Content Through Mobile Phones and Social Participation", "author": ["S. Gaonkar", "J. Li", "R.R. Choudhury", "L. Cox", "A. Schmidt"], "venue": "Proc. ACM MobiSys, 2008.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "PoolView: Stream Privacy for Grassroots Participatory Sensing", "author": ["R.K. Ganti", "N. Pham", "Y.-E. Tsai", "T.F. Abdelzaher"], "venue": "Proc. ACM SenSys, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "BikeNet: A Mobile Sensing System for Cyclist Experience Mapping", "author": ["S.B. Eisenman", "E. Miluzzo", "N.D. Lane", "R.A. Peterson", "G.-S. Ahn", "A.T. Campbell"], "venue": "ACM Trans. Sensor Networks, vol. 6, no. 1, 2009.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "PEIR, the Personal Environmental Impact Report, as a Platform for Participatory Sensing Systems Research", "author": ["M. Mun", "S. Reddy", "K. Shilton", "N. Yau", "J. Burke", "D. Estrin", "M. Hansen", "E. Howard", "R. West", "P. Boda"], "venue": "Proc. ACM MobiSys, 2009.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "How Long to Wait? Predicting Bus Arrival Time with Mobile Phone based Participatory Sensing", "author": ["P. Zhou", "Y. Zheng", "M. Li"], "venue": "Proc. ACM MobiSys, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey on human activity recognition using wearable sensors", "author": ["O.D. Lara", "M.A. Labrador"], "venue": "Communications Surveys & Tutorials, IEEE, vol. 15, no. 3, pp. 1192\u20131209, 2013.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "The Jigsaw Continuous Sensing Engine for Mobile Phone Applications", "author": ["H. Lu", "J. Yang", "Z. Liu", "N.D. Lane", "T. Choudhury", "A.T. Campbell"], "venue": "Proc. ACM SenSys, 2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Lifestreams: A Modular Sense-Making Toolset for Identifying Important Patterns from Everyday Life", "author": ["C.-K. Hsieh", "H. Tangmunarunkit", "F. Alquaddoomi", "J. Jenkins", "J. Kang", "C. Ketcham", "B. Longstaff", "J. Selsky", "B. Dawson", "D. Swendeman", "D. Estrin", "N. Ramanathan"], "venue": "Proc. ACM SenSys, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Soundsense: scalable sound sensing for people-centric applications on mobile phones", "author": ["H. Lu", "W. Pan", "N.D. Lane", "T. Choudhury", "A.T. Campbell"], "venue": "Proceedings of the 7th international conference on Mobile systems, applications, and services. ACM, 2009, pp. 165\u2013178.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Leveraging Graphical Models to Improve Accuracy and Reduce Privacy Risks of Mobile Sensing", "author": ["A. Parate", "M.-C. Chiu", "D. Ganesan", "B.M. Marlin"], "venue": "Proc. ACM MobiSys, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "ACE: Exploiting Correlation for Energy-Efficient and Continuous Context Sensing", "author": ["S. Nath"], "venue": "Proc. ACM MobiSys, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed delayed stochastic optimization.", "author": ["A. Agarwal", "J.C. Duchi"], "venue": "in Proc. NIPS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Optimal distributed online prediction", "author": ["O. Dekel", "R. Gilad-Bachrach", "O. Shamir", "L. Xiao"], "venue": "Proc. ICML, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Stochastic gradient descent with differentially private updates", "author": ["S. Song", "K. Chaudhuri", "A.D. Sarwate"], "venue": "Proc. IEEE GlobalSIP, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "A survey of computational location privacy", "author": ["J. Krumm"], "venue": "Personal and Ubiquitous Computing, vol. 13, no. 6, pp. 391\u2013399, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "k-Anonymity: A Model for Protecting Privacy", "author": ["L. Sweeney"], "venue": "Int. J. Uncertainty, Fuzziness, Knowl. Syst., vol. 10, no. 5, pp. 557\u2013570, 2002.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Protocols for secure computations", "author": ["A.C. Yao"], "venue": "2013 IEEE Symp. Found. Comp. Sci. IEEE, 1982, pp. 160\u2013164.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2013}, {"title": "Privacy-preserving data publishing: A survey of recent developments", "author": ["B. Fung", "K. Wang", "R. Chen", "P.S. Yu"], "venue": "ACM Comp. Surveys (CSUR), vol. 42, no. 4, p. 14, 2010.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "Composition attacks and auxiliary information in data privacy", "author": ["S.R. Ganta", "S.P. Kasiviswanathan", "A. Smith"], "venue": "Proc. ACM SIGKDD. ACM, 2008, pp. 265\u2013273.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2008}, {"title": "Privacy integrated queries: an extensible platform for privacy-preserving data analysis", "author": ["F.D. McSherry"], "venue": "Proc. ACM SIGMOD. ACM, 2009, pp. 19\u201330.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "JMLR, vol. 12, pp. 1069\u20131109, 2011.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Energy- Efficient Continuous Activity Recognition on Mobile Phones", "author": ["Z. Yan", "V. Subbaraju", "D. Chakraborty", "A. Misra", "K. Aherer"], "venue": "Proc. ISWC, 2012.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "A Public Domain Dataset for Human Activity Recognition Using Smartphones", "author": ["D. Anguita", "A. Ghio", "L. Oneto", "X. Parra", "J.L. Reyes-Ortiz"], "venue": "Proc. ESANN, 2013.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic gradient descent tricks", "author": ["L. Bottou"], "venue": "Neural Networks: Tricks of the Trade. Springer, 2012, pp. 421\u2013436.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "Annal Math. Stat., pp. 400\u2013407, 1951.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1951}, {"title": "Online learning and stochastic approximations", "author": ["L. Bottou"], "venue": "On-line learning in neural networks, vol. 17, p. 9.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 0}, {"title": "Primal-dual subgradient methods for convex problems", "author": ["Y. Nesterov"], "venue": "Math. Program., vol. 120, no. 1, pp. 221\u2013259, Apr. 2009.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "A stochastic gradient method with an exponential convergence rate for finite training sets", "author": ["N.L. Roux", "M. Schmidt", "F.R. Bach"], "venue": "Proc. NIPS, 2012, pp. 2663\u20132671.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "COLT 2010, p. 257, 2010.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "No more pesky learning rates", "author": ["T. Schaul", "S. Zhang", "Y. LeCun"], "venue": "Proceedings of The 30th International Conference on Machine Learning, 2013, pp. 343\u2013351.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "A Discrete Analogue of the Laplace distribution", "author": ["S. Inusah", "T.J. Kozubowski"], "venue": "J. Stat. Plan. Inf., vol. 136, no. 3, pp. 1090\u20131102, 2006.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization, vol. 19, no. 4, pp. 1574\u20131609, 2009.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2009}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["O. Shamir", "T. Zhang"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13), S. Dasgupta and D. Mcallester, Eds., vol. 28, no. 1, 2013, pp. 71\u201379.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["A. Cotter", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "Advances in Neural Information Processing Systems, 2011, pp. 1647\u20131655.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2011}, {"title": "Neural network learning: Theoretical foundations", "author": ["M. Anthony", "P.L. Bartlett"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1999}, {"title": "Mechanism design via differential privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "Proc. IEEE FOCS, 2007.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Tech. Rep., 2009.", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "However, many crowdsensing systems in the literature do not employ any privacy-preserving mechanism (see Section II-B), and existing mechanisms used in crowdsensing (see [1]) are often difficult to compare qualitatively across different systems or data types.", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "In the last decade, differential privacy has gained popularity as a formal and quantifiable measure of privacy risk in data publishing [2]\u2013[4].", "startOffset": 135, "endOffset": 138}, {"referenceID": 3, "context": "In the last decade, differential privacy has gained popularity as a formal and quantifiable measure of privacy risk in data publishing [2]\u2013[4].", "startOffset": 139, "endOffset": 142}, {"referenceID": 4, "context": "Optimal parameters of a classifier or predictor are found by minimizing the risk function associated with a given task [5] (see Section III-A for details).", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "Specifically, the framework finds optimal parameters by incrementally minimizing the risk function using a variant of stochastic (sub)gradient descent (SGD) [6].", "startOffset": 157, "endOffset": 160}, {"referenceID": 6, "context": "There is a vast amount of work in crowdsensing, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey papers [7] and [1]).", "startOffset": 164, "endOffset": 167}, {"referenceID": 0, "context": "There is a vast amount of work in crowdsensing, and we focus on the system aspect of previous work with representative papers (we refer the reader to survey papers [7] and [1]).", "startOffset": 172, "endOffset": 175}, {"referenceID": 7, "context": "Crowdsensing systems aim to achieve mass collection and mining of environmental and human-centric data such as social interactions, political issues of interest, exercise patterns, and people\u2019s impact on the environment [8].", "startOffset": 220, "endOffset": 223}, {"referenceID": 8, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 44, "endOffset": 47}, {"referenceID": 9, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 72, "endOffset": 76}, {"referenceID": 11, "context": "Examples of such systems include Micro-Blog [9], PoolView [10], BikeNet [11], and PEIR [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "Applications of learning applied to crowdsensing include learning of bus waiting times [13] and recognizing user activities (see [14] for a review).", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "Applications of learning applied to crowdsensing include learning of bus waiting times [13] and recognizing user activities (see [14] for a review).", "startOffset": 129, "endOffset": 133}, {"referenceID": 14, "context": "Jigsaw [15] and Lifestreams [16] also use pattern recognition in sensed data from mobile devices.", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "Jigsaw [15] and Lifestreams [16] also use pattern recognition in sensed data from mobile devices.", "startOffset": 28, "endOffset": 32}, {"referenceID": 16, "context": "For example, SoundSense [17] learns a classifier on a smartphone to recognized various audio events without communicating with the back-end.", "startOffset": 24, "endOffset": 28}, {"referenceID": 17, "context": "Mixed centralized and decentralized approaches are also used in [18], [19], where a portion of computation is performed off-line on a server.", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "Mixed centralized and decentralized approaches are also used in [18], [19], where a portion of computation is performed off-line on a server.", "startOffset": 70, "endOffset": 74}, {"referenceID": 17, "context": "CQue [18] provides a query interface for privacyaware probabilistic learning of users\u2019 contexts, and ACE [19] uses static association rules to learn users\u2019 contexts.", "startOffset": 5, "endOffset": 9}, {"referenceID": 18, "context": "CQue [18] provides a query interface for privacyaware probabilistic learning of users\u2019 contexts, and ACE [19] uses static association rules to learn users\u2019 contexts.", "startOffset": 105, "endOffset": 109}, {"referenceID": 19, "context": "Crowd-ML also builds on recent advances in incremental distributed learning [20], [21], which show that a near-optimal convergence rate is achievable despite communication delays.", "startOffset": 76, "endOffset": 80}, {"referenceID": 20, "context": "Crowd-ML also builds on recent advances in incremental distributed learning [20], [21], which show that a near-optimal convergence rate is achievable despite communication delays.", "startOffset": 82, "endOffset": 86}, {"referenceID": 21, "context": "A privacy-preserving stochastic gradient descent method is presented briefly in [22].", "startOffset": 80, "endOffset": 84}, {"referenceID": 22, "context": "In particular, preserving privacy of users\u2019 locations has been studied by many researchers (see [23] for a survey).", "startOffset": 96, "endOffset": 100}, {"referenceID": 23, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 91, "endOffset": 95}, {"referenceID": 24, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 130, "endOffset": 134}, {"referenceID": 25, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "To preserve privacy of general data types formally, several mechanisms such as k-anonymity [24] and secure multiparty computation [25] have been proposed, for data publishing [26] and also for participatory sensing [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 1, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 31, "endOffset": 34}, {"referenceID": 3, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 35, "endOffset": 38}, {"referenceID": 26, "context": "Recently, differential privacy [2]\u2013[4] has addressed several weaknesses of k-anonymity [27], and gained popularity as a quantifiable measure of privacy risk.", "startOffset": 87, "endOffset": 91}, {"referenceID": 27, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 81, "endOffset": 85}, {"referenceID": 28, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "Differential privacy has been used for privacy-preserving data analysis platform [28], for sanitization of learned models parameters from data [29], and for privacypreserving data mining from distributed time-series data [17].", "startOffset": 221, "endOffset": 225}, {"referenceID": 8, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 63, "endOffset": 66}, {"referenceID": 12, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 67, "endOffset": 71}, {"referenceID": 14, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 73, "endOffset": 77}, {"referenceID": 18, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 78, "endOffset": 82}, {"referenceID": 29, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 84, "endOffset": 88}, {"referenceID": 30, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 90, "endOffset": 94}, {"referenceID": 9, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 102, "endOffset": 106}, {"referenceID": 11, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 108, "endOffset": 112}, {"referenceID": 17, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "Among the crowdsensing systems cited in the previous section ( [9]\u2013[13], [15]\u2013[19], [30], [31]), only [10], [12], [18] provide privacy mechanisms, of which only [10] address the privacy more formally.", "startOffset": 161, "endOffset": 165}, {"referenceID": 4, "context": "A widerange of classifiers or predictors can be learned by minimizing an empirical risk associated with a given task, a common method in statistical learning [5].", "startOffset": 158, "endOffset": 161}, {"referenceID": 31, "context": ", regression, logistic regression, and Support Vector Machine (see [32] for more examples).", "startOffset": 67, "endOffset": 71}, {"referenceID": 32, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 59, "endOffset": 63}, {"referenceID": 31, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 160, "endOffset": 164}, {"referenceID": 33, "context": "In this work we use stochastic (sub)gradient descent (SGD) [33] which is one of the simplest optimization methods and is also suitable for large-scale learning [32], [34].", "startOffset": 166, "endOffset": 170}, {"referenceID": 34, "context": "Remark 3: In Server Routine 2, more recent update methods [35], [36] can be used in place of the simple update rule (3) without affecting differential privacy nor changing device routines.", "startOffset": 58, "endOffset": 62}, {"referenceID": 35, "context": "Remark 3: In Server Routine 2, more recent update methods [35], [36] can be used in place of the simple update rule (3) without affecting differential privacy nor changing device routines.", "startOffset": 64, "endOffset": 68}, {"referenceID": 36, "context": "Similarly, adaptive learning rates [37], [38] can be used in place of (5), which can provide a robustness to large gradients from outlying or malignant devices.", "startOffset": 35, "endOffset": 39}, {"referenceID": 37, "context": "Similarly, adaptive learning rates [37], [38] can be used in place of (5), which can provide a robustness to large gradients from outlying or malignant devices.", "startOffset": 41, "endOffset": 45}, {"referenceID": 2, "context": "A basic result from the definition of differential privacy is that a vector-valued function f with sensitivity S(f) can be made -differentially private [3] by adding an independent Laplace noise vector z1", "startOffset": 152, "endOffset": 155}, {"referenceID": 38, "context": "To sanitize ne and ny , we add \u2018discrete\u2019 Laplace noise [39] as follows:", "startOffset": 56, "endOffset": 60}, {"referenceID": 39, "context": "The performance of an SGD-based learning can be represented by its rate of convergence to the optimal value/parameters E[l(w(t))\u2212l(w\u2217)] at iteration t, which in turn depends on the properties of the loss l(\u00b7) (such as Lipschitzcontinuity and strong-convexity) and the step size \u03b7(t), with the best known rate being O(1/t) [40].", "startOffset": 322, "endOffset": 326}, {"referenceID": 40, "context": "When other conditions are the same, the convergence rate is roughly proportional E[l(w(t)) \u2212 l(w\u2217)] \u221d G to the amount of noise in the estimated gradient G = supt E[\u2016\u011d(t)\u2016] [41].", "startOffset": 172, "endOffset": 176}, {"referenceID": 42, "context": "For example, it is known from the VC-theory for binary classification problems that the upper-bound of the estimation error with a 1/M -times smaller sample size is \u221a M/ logM -times larger [43].", "startOffset": 189, "endOffset": 193}, {"referenceID": 41, "context": "3although a larger batch size means fewer updates given the same number of samples N , and too large a batch size can negatively affect the convergence rate (see [42] for discussion).", "startOffset": 162, "endOffset": 166}, {"referenceID": 19, "context": "Recent work in distributed incremental update [20], [21] also shows that a near-optimal convergence rate is achievable despite delays.", "startOffset": 46, "endOffset": 50}, {"referenceID": 20, "context": "Recent work in distributed incremental update [20], [21] also shows that a near-optimal convergence rate is achievable despite delays.", "startOffset": 52, "endOffset": 56}, {"referenceID": 20, "context": "[21] shows that delayed incremental updates are scalable with M by adapting the minibatch size.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": ", \u011d(T ) is the same as the sensitivity of a single \u011d(t), and the -differential privacy follows from Proposition 1 of [3].", "startOffset": 117, "endOffset": 120}, {"referenceID": 43, "context": "Perturbation by adding discrete Laplace noise is equivalent to random sampling by exponential mechanism [44] with P (n\u0302e|ne) \u221d e\u2212 e 2 |n\u0302e\u2212ne|, n\u0302e \u2208 Z.", "startOffset": 104, "endOffset": 108}, {"referenceID": 43, "context": "As with multiple gradients, the sensitivity of multiples sets of (n\u0302e, n\u0302y) is the same as the sensitivity of a single set, and e-differential privacy follows from Theorem 6 of [44].", "startOffset": 177, "endOffset": 181}, {"referenceID": 38, "context": "and has zeromean and constant variance 2e \u2212 e/2 (1\u2212e\u2212 e/2)2 [39], the estimate of error rate converge almost surely to the true error rate with vanishing variances as T increases.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": "From Proposition 1 of [3] and Theorem 6 of [44], respectively, we achieve x- and ydifferential privacy of data.", "startOffset": 22, "endOffset": 25}, {"referenceID": 43, "context": "From Proposition 1 of [3] and Theorem 6 of [44], respectively, we achieve x- and ydifferential privacy of data.", "startOffset": 43, "endOffset": 47}, {"referenceID": 44, "context": "We repeat the experiments in Section V-C for an object recognition task using CIFAR-10 dataset, which consists of images of 10 types of objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) collected by [45].", "startOffset": 228, "endOffset": 232}], "year": 2015, "abstractText": "Smart devices with built-in sensors, computational capabilities, and network connectivity have become increasingly pervasive. The crowds of smart devices offer opportunities to collectively sense and perform computing tasks in an unprecedented scale. This paper presents Crowd-ML, a privacy-preserving machine learning framework for a crowd of smart devices, which can solve a wide range of learning problems for crowdsensing data with differential privacy guarantees. Crowd-ML endows a crowdsensing system with an ability to learn classifiers or predictors online from crowdsensing data privately with minimal computational overheads on devices and servers, suitable for a practical and large-scale employment of the framework. We analyze the performance and the scalability of Crowd-ML, and implement the system with off-the-shelf smartphones as a proof of concept. We demonstrate the advantages of Crowd-ML with real and simulated experiments under various conditions.", "creator": "LaTeX with hyperref package"}}}