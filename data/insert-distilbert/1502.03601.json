{"id": "1502.03601", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Feb-2015", "title": "A Predictive System for detection of Bankruptcy using Machine Learning techniques", "abstract": "bankruptcy is a legal narrative procedure that claims a person or organization as a debtor. it is essential to ascertain the risk of bankruptcy occurrences at correct initial stages to actually prevent financial losses. in this perspective, different soft computing techniques can be employed to ascertain bankruptcy. this study tool proposes a novel bankruptcy prediction simulation system to categorize the companies based on extent of risk. the prediction system acts partially as a decision support tool for detection of bankruptcy", "histories": [["v1", "Thu, 12 Feb 2015 11:07:51 GMT  (526kb)", "http://arxiv.org/abs/1502.03601v1", "11 pages, 7 figures"]], "COMMENTS": "11 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["kalyan nagaraj", "amulyashree sridhar"], "accepted": false, "id": "1502.03601"}, "pdf": {"name": "1502.03601.pdf", "metadata": {"source": "CRF", "title": "A Predictive System for detection of Bankruptcy using Machine Learning techniques", "authors": ["Kalyan Nagaraj", "Amulyashree Sridhar"], "emails": ["kalyan1991n@gmail.com", "0908amulyashree@gmail.com"], "sections": [{"heading": null, "text": "Bankruptcy is a legal procedure that claims a person or organization as a debtor. It is essential to ascertain the risk of bankruptcy at initial stages to prevent financial losses. In this perspective, different soft computing techniques can be employed to ascertain bankruptcy. This study proposes a bankruptcy prediction system to categorize the companies based on extent of risk. The prediction system acts as a decision support tool for detection of bankruptcy\nKeywords: Bankruptcy, soft computing, decision support tool"}, {"heading": "1. Introduction", "text": "Bankruptcy is a situation in which a firm is incapable to resolve its monetary obligations leading to legal threat. The financial assets of companies are sold out to clear the debt which results in huge financial losses to the investors. Bankruptcy results in decreased liquidity of capital and minimized financial improvement. It is reported by World Bank data that Indian government resolves the insolvency in an average of 4.3 years [1]. There is a need to design effective strategies for prediction of bankruptcy at an earlier stage to avoid financial crisis. Bankruptcy can be predicted using mathematical techniques, hypothetical models as well as soft computing techniques [2]. Mathematical techniques are primary methods used for estimation of bankruptcy based on financial ratios. These methods are based on single or multi variable models. Hypothetical models are developed to support the theoretical principles. These models are statistically very complex based on their assumptions. Hence soft computing techniques are extensively used for developing predictive models in finance. Some of the popular soft computing techniques include Bayesian networks, logistic regression, decision tress, support vector machines and neural networks.\nIn this study, different soft computing techniques are employed to predict bankruptcy. Further based on the performance of the classifiers, the best model is chosen for development of a decision support system in R programming language. The support system can be utilized by stock holders and investors to predict the performance of a company based on the nature of risk associated."}, {"heading": "2. Background", "text": "Several studies have been conducted in the recent past reflecting the importance of soft computing techniques. The studies and the technologies implemented are briefly discussed below.\n2.1. Machine Learning\nis broadly referred as knowledge discovery in database (KDD). Different learning algorithms are implemented to extract patterns from data. These algorithms can either be supervised or unsupervised. Supervised learning is applied when the output of a function is previously known. Unsupervised learning is applied when the target function is unknown. The general layout for machine learning process is described below:\nData collection: The data related to domain of concern is extracted from public platforms and data warehouses. The data will be raw and unstructured format. Hence pre-processing measures must be adopted\nData pre-processing: The initial dataset is subjected for pre-processing. Pre-processing is performed to remove the outliers and redundant data. The missing values are replaced by normalization and transformation\nDevelopment of models: The pre-processed data is subjected to different machine learning algorithms for development of models. The models are constructed based on classification, clustering, pattern recognition and association rules\nKnowledge Extraction: The models are evaluated to represent the knowledge captured. This knowledge attained can be used for better decision making process [3]."}, {"heading": "2.2 Classification algorithms", "text": "Several classification algorithms are implemented in recent past for financial applications. They are discussed briefly below:\nLogistic Regression: It is a classifier that predicts the outcome based probabilities of logistic function. It estimates the relationship between different independent variables and the dependent outcome variable based on probabilistic value. It may be either binary or multinomial classifier. The logistic function is denoted as:\nF(x) = 1\n1+e -(\u03b20+\u03b21x)\n\u03b20 and \u03b21are coefficients for input variable x. The value of F(x) ranges from zero to one. The logistic regression model generated is also called as generalized linear model [4].\nNa\u00efve Bayes classifier: It is a probabilistic classifier based on the assumptions of Bayes theorem [5]. It is based on independent dependency among all the features in the dataset. Each feature contributes independently to the total probability in model. The classifier is used for supervised learning. The Bayesian probabilistic model is defined as:\n)(\n)|()( )|(\nxp\nCxpCp xCp k k k \np(Ck|x) = posterior probability\np(Ck)=prior probability\np(x)= probability of estimate\np(x|Ck)=likelihood of occurrence of x\nRandom Forest: They are classifier which construct decision trees for building the model and outputs the mode value of individual trees as result of prediction. The algorithm was developed by Breiman [6]. Classification is performed by selecting a new input vector from training set. The vector is placed at the bottom of each of the trees in the forest. The proximity is computed for the tree. If the tree branches are at the same level, then proximity is incremented by one. The proximity evaluated is standardized as a function of the number of trees generated. Random forest algorithms compute the important features in a\nin decision tree models.\nNeural networks: They are learning algorithms inspired from the neurons in human brain. The network comprises of interconnected neurons as a function of input data [7]. Based on the synapse received from input data, weights are generated to compute the output function. The networks can either be feedforward or feed-back in nature depending upon the directed path of the output function. The error in input function is minimized by subjecting the network for back-propagation which optimizes the error rate. The network may also be computed from several layers of input called as multilayer perceptron. Neural networks have immense applications in pattern recognition, speech recognition and financial modeling.\nSupport vector machine: They are supervised learning algorithms based on non-probabilistic classification of dataset into categories in high dimensional space. The algorithm was proposed by Vapnik [8]. The training dataset is assumed as a p-dimensional vector which is to be classified using (p-1) dimensional hyperplane. The largest separation achieved between data points is considered optimal. Hyperplane function is represented as:\n).(),,( bxwsignbwxf \nw = normalized vector to the hyperplane x = p-dimensional input vector b = bias value The marginal separator is defined as 2|k|/||w||. \u2018k\u2019 represents the number of support vectors generated by the model. The data instances are classified based on the below criteria If (w \u00b7 x +b) = k, indicates all the positive instances. If (w \u00b7 x +b) = -k, indicates the set of negative instances. If (w \u00b7 x +b) = 0, indicates the set of neutral instances."}, {"heading": "3. Related Work", "text": "Detection of bankruptcy is a typical classification problem in machine learning application. Development of mathematical and statistical models for bankruptcy prediction was initiated by Beaver in the year 1960 [9]. The study focused on the univariate analysis of different financial factors to detect bankruptcy. An important development in this arena was recognized by Altman who developed a multivariate Z-score model of five variables [10]. Z-score model is considered as a standard model for estimating the probability of default in bankruptcy. Logistic regression was also instigated to evaluate bankruptcy [11]. These techniques are considered as standard estimates for prediction of financial distress. But these models pose statistical restrictions leading to their limitations. To overcome these limitations probit [12] and logit models [13] were implemented for financial applications. In later years, neural networks were implemented for estimating the distress in financial organizations [14, 15, and 16]. Neural networks are often subjected to overfitting leading to false predictions. Decision trees were also applied for predicting financial distress [17, 18]. Support vector machines have also been used employed in predicting bankruptcy for financial companies [19, 20]. In recent years, several hybrid models have been adopted to improve the performance of individual classifiers for detection of bankruptcy [21, 22]."}, {"heading": "4. Methodology", "text": ""}, {"heading": "4.1. Collection of Bankruptcy dataset", "text": "The qualitative bankruptcy dataset was retrieved from UCI Machine Learning Repository [23]. The dataset comprised of 250 instances based on 6 attributes. The output had two classes of nominal type describing the instance as \u2018Bankrupt\u2019 (107 cases) or \u2018Non-bankrupt\u2019 (143 cases)."}, {"heading": "4.2. Feature Selection", "text": "It is important to remove the redundant attributes from the dataset. Hence correlation based feature selection technique was employed. The feature based algorithm selects the significant attributes based on the class value. If the attribute is having high correlation with the class variable and minimal correlation with other attributes of the dataset it is presumed to be a good attribute. If the attribute have high correlation with the attributes then they are discarded from the study.\nThe features selected after correlational analysis are subjected to data partitioning followed by application of different machine learning algorithms. The dataset is split into training (2/3 rd of the dataset) and test dataset (1/3 rd of the dataset) respectively. In the training phase different classifiers are applied to build an optimal model. The model is validated using the test set in the testing phase. Once the dataset is segregated, different learning algorithms was employed on the training dataset. The algorithms include logistic regression, Bayesian classifier, random forest, neural network and support vector machines. Models generated from each of the classifier were assessed for their performance using the test dataset. A ten-fold cross validation strategy was adopted to test the accuracy. In this procedure, the test dataset is partitioned into ten subsamples and each subsample is used to test the performance of the model generated from training dataset. This step is performed to minimize the probability of overfitting. The accuracy of each algorithm was estimated from the cross validated outcomes."}, {"heading": "4.4. Developing a predictive decision support system", "text": "From the previous step, the classifier with highest prediction accuracy is selected for developing a decision support system to predict the nature of bankruptcy. The prediction system was implemented in RStudio interface, a statistical programming toolkit. Different libraries were invoked for development of the predictive system including \u2018gWidgets \u2019and \u2018RGtk2\u2019. The predictive tool develops a model for evaluating the outcome bankruptcy class for user input data. Predicted class is compared with the actual class value from the dataset to compute the percentage of error prediction from the system. The support system estimates the probability of bankruptcy among customers. It can be used as an initial screening tool to strengthen the default estimate of a customer based on his practises.\nThe methodology of this study is illustrated in Figure 1.\n5. Results and Discussion\nThe bankruptcy dataset utilized for this study is available at UCI Machine Learning Repository. The dataset comprising of six different features is described in Table 1. The distribution of class outcome is shown in Figure-2."}, {"heading": "5.2. Correlation based Attribute selection", "text": "The bankruptcy dataset was subjected for feature selection to extract the relevant attributes. The nominal values in bankruptcy dataset were converted to numeric values for performing feature selection. The values of each of the descriptors were scaled as P=1, A=0.5 and N=0 representing the range for positive, average and negative values. The procedure was repeated for all the six attributes in dataset. Pearson correlation filter was applied for the numerical dataset to remove the redundant features with a threshold value of 0.7. The analysis revealed that all the six attributes were highly correlated with the outcome variable. In order to confirm the results from correlation, another feature selection method was applied for the dataset. Information gain ranking filter method was applied to test the importance of features. The algorithm discovered similar results as that of correlation. Hence all the six attributes from the dataset were considered for the study. The correlational plot for the features is shown in Figure 3.\nFigure 3: The correlational plot illustrating the importance of each feature"}, {"heading": "5.3. Machine learning algorithms", "text": "The features extracted from previous step were subjected for different machine learning algorithms in R. The algorithms were initially applied for the training set to develop predictive models. These models were further evaluated using the test set. Performance of each model was adjudged using different statistical parameters like confusion matrix and receiver operating characteristics (ROC) curve. Confusion matrix is a contingency table that represents the performance of machine learning algorithms [24]. It represents the relationship between actual class outcome and predicted class outcome based on the following four estimates:\na) True positive (TP): The actual negative class outcome is predicted as negative class from the model\nb) False positive (FP): The actual negative class outcome is predicted as a positive class outcome. It leads to Type-1 error\nc) False negative (FN): The actual positive class outcome is predicted as negative class from the model. It leads to Type-2 error\nd) True negative (TN): The actual class outcome excluded is also predicted to be excluded from the model.\nBased on these four parameters the performance of algorithms can be adjudged by the following ratios.\nFNTNFPTP\nTNTP Accuracy\n\n (%)\nFNTP\nTP TPR\n (%)\nTNFP\nFP FPR\n (%)\nFPTP\nTP precision\n (%)\nROC curve is a plot of false positive rate (X-axis) versus true positive rate (Y-axis). It is represents the accuracy of a classifier [25].\nclassifier is represented in Figure 4."}, {"heading": "5.4. SVM based decision supportive system in R", "text": "Based on the accuracy in previous step, it was seen that support vector based classifier outperformed other machine learning techniques. The classifier was implemented using radial basis function (RBF) kernel. It is also referred as Gaussian RBF kernel. The kernel representation creates a decision boundary for the non-linear attributes in high dimensional space. The attributes are converted to linear form by mapping using this kernel function. An optimal hyperplane is constructed in feature space by considering the inner product of the kernel. Hyperplane is considered as optimal if it creates a widest gap from the input attributes to the target class. Furthermore, to achieve optimization C and gamma parameters are\nmargin creating a wider hyperplane, whereas the value of C being larger leads to overfitting called as hard margin. Hence the value of C must be selected by balancing between the soft and hard margin. Gamma is used for non-linear classifiers for constructing the hyperplane. It is used to control the shape of the classes to be separated. If the value of gamma is small it results in high variance and minimal bias producing a pointed thrust. While a bigger gamma value leads to minimal variance and maximum bias producing a broader and soft thrust. The values of C and gamma were optimized and selected for classification. The classified instances from RBF kernel is observed in Figure 5.\nBased on the RBF classifier the prediction system was constructed in R. The bankruptcy dataset is initially loaded into the predictive system as a .csv file. The home page of predictive tool loaded with bankruptcy dataset is shown in Figure 6.\nThe system fetches the dataset and stores as a dataframe. Dataframe is a vector list used to store the data as a table in R. RBF-kernel SVM model is developed for the bankruptcy dataset. It is displayed in Figure 7.\nAfter the model is developed, users can enter their data in the text input boxes for predicting bankruptcy. Each of the six input parameters have values as 1, 0.5 or 0 (positive, average and negative) respectively. Based on SVM model built for the initial dataset, the predictive system estimates the probability of bankruptcy as either B (Bankruptcy) or NB (Non Bankruptcy). The predicted outcome is saved as a .csv file in the local directory of user\u2019s system to view the results. The output from the predictive system is shown in Figure 4, 5 and 6 respectively."}, {"heading": "5.5. Developing the prediction system as a package", "text": "The predictive system for detecting bankruptcy was encoded as a package in RStudio. The package was developed using interdependent libraries \u2018devtools\u2019 and \u2018roxygen2\u2019. The package can be downloaded by users in their local machines followed by installing and running the package in RStudio. Once the package is installed users can run the predictive system for detection of bankruptcy using their input data."}, {"heading": "6. Conclusion", "text": "The results suggest that machine learning techniques can be implemented for prediction of bankruptcy. To serve the financial organizations for identifying risk oriented customers a prediction system was implemented. The predictive system helps to predict bankruptcy for a customer dataset based on the SVM model."}, {"heading": "7. References", "text": "[1] Personal Bankruptcy or Insolvency laws in India. (http://blog.ipleaders.in/personal-bankruptcy-or-\ninsolvency-laws-in-india/). Retrieved on Nov, 2014.\nand Logistic Regression to Predict Companies Financial Bankruptcy in Tehran Stock Exchanges.\u201d International Journal of Emerging Research in Management &Technology, 2(9): pp. 7-16.\n[3] M. Kantardzic (2003). \u201cData mining: Concepts, models, methods, and algorithms.\u201d John Wiley & Sons.\n[4] X. Wu et. al (2008). \u201cTop 10 algorithms in data mining\u201d. Knowl Inf Syst. 14: pp 1-37.\n[4] Hosmer David W, Lemeshow, Stanley (2000). \u201cApplied Logistic Regression\u201d. Wiley.\n[5] Rish, Irina (2001). \"An empirical study of the naive Bayes classifier\". IJCAI Workshop on Empirical Methods in AI.\n[6] Breiman, Leo (2001). \"Random Forests.\u201d Machine Learning 45 (1):pp. 5\u201332.\n[7] McCulloch, Warren; Walter Pitts (1943). \"A Logical Calculus of Ideas Immanent in Nervous Activity\". Bulletin of Mathematical Biophysics 5 (4): pp. 115\u2013133.\n[8] Cortes, C.; Vapnik, V. (1995). \"Support-vector networks\". Machine Learning 20 (3): 273.\n[9] Altman E (1968). Financial ratios, discriminant analysis and prediction of corporate bankruptcy. The Journal of Finance. 23(4), 589-609.\n[10] Martin, D (1977). Early warning of bank failures: A logit regression approach. Journal of Banking and Finance. 1, 249-276.\n[11] Lo, A (1984). Essays in financial and quantitative economics. Ph.D. dissertation, Harvard University.\n[12] J. A. Ohlson (1980). \u201cFinancial ratios and the probabilistic prediction of bankruptcy,\u201d Journal of Accounting Research, 18(1), pp. 109-131.\n[13] B. Back et. al (1996). \u201cChoosing Bankruptcy Predictors using Discriminant Analysis, Logit Analysis and Genetic Algorithms,\u201d Turku School of Economics and Business Administration.\n[14] J. E. Boritz, D. B. Kennedy (1995) \u201cEffectiveness of neural network types for prediction of business failure,\u201d Expert Systems with Applications. 9(4): pp. 95-112.\n[15] P. Coats, L. Fant (1992). \u201cA neural network approach to forecasting financial distress,\u201d Journal of Business Forecasting, 10(4), pp. 9-12.\n[16] M. D.Odom, R. Sharda (1990), \u201cA neural network model for bankruptcy prediction,\u201d IJC NN International Joint Conference on Neural Networks, 2, p. 163-168.\n[17] J. Sun, H. Li (2008). \u201cData mining method for listed companies\u2019 financial distress prediction,\u201d Knowledge-Based Systems. 21(1): pp. 1-5. 2008.\n[18] \u0130. H. Ek\u015fi (2011). \u201cClassification of firm failure with classification and regression trees,\u201d International Research Journal of Finance and Economics. 76, pp. 113-120.\n[19] V. Fan, v. Palaniswami (2000).\u201cSelecting bankruptcy bredictors using a support vector machine approach,\u201d Proceedings of the Internal Joint Conference on Neural Networks. pp. 354-359.\n[20] S. Falahpour, R. Raie (2005). \u201cApplication of support vector machine to predict financial distress using financial ratios\u201d. Journal of Accounting and Auditing Studies. 53, pp. 17-34.\n[21] Hyunchul Ahn, Kyoung-jae Kim (2009). \u201cBankruptcy prediction modeling with hybrid case-based reasoning and genetic algorithms approach\u201d. Applied Soft Computing. 9(2): pp. 599-607.\n[22] Ming-Yuan Leon Li, Peter Miu (2010). \u201cA hybrid bankruptcy prediction model with dynamic loadings on accounting-ratio-based and market-based information: A binary quantile regression approach\u201d. Journal of Empirical Finance. 17(4): pp. 818-833.\n[23] A. Martin, T Miranda Lakshmi, Prasanna Venkateshan (2014). \u201cAn Analysis on Qualitative Bankruptcy Prediction rules using Ant-miner\u201d. IJ Intelligent System and Applications. 01: pp. 36-44.\n[24] Stehman, Stephen V. (1997). \"Selecting and interpreting measures of thematic classification accuracy\". Remote Sensing of Environment. 62 (1): pp. 77\u201389.\n861 \u2013 874."}], "references": [{"title": "Data mining: Concepts, models, methods, and algorithms.", "author": ["M. Kantardzic"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Top 10 algorithms in data mining", "author": ["X. Wu et"], "venue": "Knowl Inf Syst", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "An empirical study of the naive Bayes classifier", "author": ["Rish", "Irina"], "venue": "IJCAI Workshop on Empirical Methods in AI", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Random Forests.", "author": ["Breiman", "Leo"], "venue": "Machine Learning", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "A Logical Calculus of Ideas Immanent in Nervous Activity", "author": ["McCulloch", "Warren", "Walter Pitts"], "venue": "Bulletin of Mathematical Biophysics", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1943}, {"title": "Support-vector networks", "author": ["C. Cortes", "V. Vapnik"], "venue": "Machine Learning", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "Financial ratios, discriminant analysis and prediction of corporate bankruptcy", "author": ["E Altman"], "venue": "The Journal of Finance", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1968}, {"title": "Early warning of bank failures: A logit regression approach", "author": ["D Martin"], "venue": "Journal of Banking and Finance", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1977}, {"title": "Essays in financial and quantitative economics", "author": ["A Lo"], "venue": "Ph.D. dissertation,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1984}, {"title": "Financial ratios and the probabilistic prediction of bankruptcy,", "author": ["J.A. Ohlson"], "venue": "Journal of Accounting Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1980}, {"title": "Choosing Bankruptcy Predictors using Discriminant Analysis, Logit Analysis and Genetic Algorithms,", "author": ["B. Back et"], "venue": "Turku School of Economics and Business Administration", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1996}, {"title": "Effectiveness of neural network types for prediction of business failure,", "author": ["J.E. Boritz", "D.B. Kennedy"], "venue": "Expert Systems with Applications", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1995}, {"title": "A neural network approach to forecasting financial distress,", "author": ["P. Coats", "L. Fant"], "venue": "Journal of Business Forecasting,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1992}, {"title": "A neural network model for bankruptcy prediction,", "author": ["M.D.Odom", "R. Sharda"], "venue": "IJC NN International Joint Conference on Neural Networks,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1990}, {"title": "Data mining method for listed companies\u2019 financial distress prediction,", "author": ["J. Sun", "H. Li"], "venue": "Knowledge-Based Systems", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "2000).\u201cSelecting bankruptcy bredictors using a support vector machine approach,", "author": ["V. Fan", "v. Palaniswami"], "venue": "Proceedings of the Internal Joint Conference on Neural Networks", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Application of support vector machine to predict financial distress using financial ratios", "author": ["S. Falahpour", "R. Raie"], "venue": "Journal of Accounting and Auditing Studies", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Bankruptcy prediction modeling with hybrid case-based reasoning and genetic algorithms approach", "author": ["Hyunchul Ahn", "Kyoung-jae Kim"], "venue": "Applied Soft Computing", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "A hybrid bankruptcy prediction model with dynamic loadings on accounting-ratio-based and market-based information: A binary quantile regression approach", "author": ["Ming-Yuan Leon Li", "Peter Miu"], "venue": "Journal of Empirical Finance", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "An Analysis on Qualitative Bankruptcy Prediction rules using Ant-miner", "author": ["A. Martin", "T Miranda Lakshmi", "Prasanna Venkateshan"], "venue": "IJ Intelligent System and Applications", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Selecting and interpreting measures of thematic classification accuracy", "author": ["Stehman", "Stephen V"], "venue": "Remote Sensing of Environment", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "An Introduction to ROC Analysis", "author": ["Fawcett", "Tom"], "venue": "Pattern Recognition Letters", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "This knowledge attained can be used for better decision making process [3].", "startOffset": 71, "endOffset": 74}, {"referenceID": 1, "context": "The logistic regression model generated is also called as generalized linear model [4].", "startOffset": 83, "endOffset": 86}, {"referenceID": 2, "context": "Na\u00efve Bayes classifier: It is a probabilistic classifier based on the assumptions of Bayes theorem [5].", "startOffset": 99, "endOffset": 102}, {"referenceID": 3, "context": "The algorithm was developed by Breiman [6].", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "The network comprises of interconnected neurons as a function of input data [7].", "startOffset": 76, "endOffset": 79}, {"referenceID": 5, "context": "The algorithm was proposed by Vapnik [8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 6, "context": "Development of mathematical and statistical models for bankruptcy prediction was initiated by Beaver in the year 1960 [9].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "An important development in this arena was recognized by Altman who developed a multivariate Z-score model of five variables [10].", "startOffset": 125, "endOffset": 129}, {"referenceID": 8, "context": "Logistic regression was also instigated to evaluate bankruptcy [11].", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "To overcome these limitations probit [12] and logit models [13] were implemented for financial applications.", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "To overcome these limitations probit [12] and logit models [13] were implemented for financial applications.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "Decision trees were also applied for predicting financial distress [17, 18].", "startOffset": 67, "endOffset": 75}, {"referenceID": 15, "context": "Support vector machines have also been used employed in predicting bankruptcy for financial companies [19, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 16, "context": "Support vector machines have also been used employed in predicting bankruptcy for financial companies [19, 20].", "startOffset": 102, "endOffset": 110}, {"referenceID": 17, "context": "In recent years, several hybrid models have been adopted to improve the performance of individual classifiers for detection of bankruptcy [21, 22].", "startOffset": 138, "endOffset": 146}, {"referenceID": 18, "context": "In recent years, several hybrid models have been adopted to improve the performance of individual classifiers for detection of bankruptcy [21, 22].", "startOffset": 138, "endOffset": 146}, {"referenceID": 19, "context": "Collection of Bankruptcy dataset The qualitative bankruptcy dataset was retrieved from UCI Machine Learning Repository [23].", "startOffset": 119, "endOffset": 123}, {"referenceID": 20, "context": "Confusion matrix is a contingency table that represents the performance of machine learning algorithms [24].", "startOffset": 103, "endOffset": 107}, {"referenceID": 21, "context": "It is represents the accuracy of a classifier [25].", "startOffset": 46, "endOffset": 50}], "year": 2015, "abstractText": "Bankruptcy is a legal procedure that claims a person or organization as a debtor. It is essential to ascertain the risk of bankruptcy at initial stages to prevent financial losses. In this perspective, different soft computing techniques can be employed to ascertain bankruptcy. This study proposes a bankruptcy prediction system to categorize the companies based on extent of risk. The prediction system acts as a decision support tool for detection of bankruptcy", "creator": "Microsoft\u00ae Word 2010"}}}