{"id": "1502.05696", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2015", "title": "Approval Voting and Incentives in Crowdsourcing", "abstract": "the growing need for labeled training data has made crowdsourcing an important part of machine learning. the quality of crowdsourced labels is, however, adversely affected by three factors : ( 1 ) the workers are not experts ; ( 2 ) the incentives of the workers are not aligned with those of the interface requesters ; and ( 3 ) the interface quality does better not allow workers to convey their knowledge accurately, by forcing even them to make a single choice among a different set of options. thoroughly in interpreting this paper, we thoroughly address these crucial issues addressed by introducing network approval voting to utilize the expertise needs of workers who only have partial knowledge of the true answer, and coupling it with a ( \" strictly proper \" ) nash incentive - compatible compensation mechanism. we show rigorous independent theoretical guarantees of optimality of our payment mechanism together with a simple axiomatic characterization. we also conduct empirical studies on amazon mechanical behavior turk which validate our approach.", "histories": [["v1", "Thu, 19 Feb 2015 20:42:55 GMT  (1516kb,D)", "https://arxiv.org/abs/1502.05696v1", null], ["v2", "Tue, 19 May 2015 09:12:50 GMT  (314kb,D)", "http://arxiv.org/abs/1502.05696v2", "International Conference on Machine Learning (ICML) 2015"], ["v3", "Mon, 7 Sep 2015 05:21:06 GMT  (3874kb,D)", "http://arxiv.org/abs/1502.05696v3", null]], "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.LG cs.MA", "authors": ["nihar b shah", "dengyong zhou", "yuval peres"], "accepted": true, "id": "1502.05696"}, "pdf": {"name": "1502.05696.pdf", "metadata": {"source": "CRF", "title": "Approval Voting and Incentives in Crowdsourcing", "authors": ["Nihar B. Shah", "Dengyong Zhou", "Yuval Peres"], "emails": ["nihar@eecs.berkeley.edu", "dengyong.zhou@microsoft.com", "peres@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "In the big data era, with the ever increasing complexity of machine learning models such as deep learning, the demand for large amounts of labeled data is growing at an unprecedented scale. A primary means of label collection is crowdsourcing, through commercial web services like Amazon Mechanical Turk where crowdsourcing workers or annotators perform tasks in exchange for monetary payments. Unfortunately, the data obtained via crowdsourcing is typically highly erroneous (Kazai et al., 2011; Vuurens et al., 2011; Wais et al., 2010) due to the lack of expertise of workers, lack of appropriate incentives, and often the lack of an appropriate interface for the workers to express their knowledge. Several statistical aggregation methods (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al.,\nWhat is the language in this image?\nLatin Thai Tamil Japanese Hebrew Chinese Russian Hindi\n(a)\nLatin Thai Tamil Japanese Hebrew Chinese Russian Hindi\nSelect ALL options that could be the language in this image\n(b)\nFigure 1: Illustration of a task with (a) the standard single selection interface, and (b) an approval-voting interface.\nar X\niv :1\n50 2.\n05 69\n6v 3\n[ cs\n.G T\n] 7\nS ep\n2 01\n2012; Zhou et al., 2012; Shah et al., 2015) have been proposed in the literature for improving the quality of the data. Our approach complements these techniques in that we endeavor to obtain higher-quality labels directly via novel interface and incentive mechanisms while not increasing the labeling cost.\nThe typical crowdsourcing labeling task consists of a set of questions such as images to be labeled, and each question is associated with a set of options. Each option is the name of a category and the true label for any question is one of these options. In principle, for each question, the worker is required to select the option that she believes is most likely to be correct. More formally, it involves eliciting the mode of the worker\u2019s belief. Such a \u201csingle-selection\u201d crowdsourcing setting has been studied extensively, both empirically and theoretically.\nIn this paper, we consider an alternative \u201capproval-voting\u201d means of eliciting labels from the workers, wherein the worker is allowed to select multiple options for every question.1 See Figure 1 for an example. Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively. For instance, Coombs (1953) posits that \u201cIt seems to be a common experience of individuals taking objective tests to feel confident about eliminating some of the wrong alternatives and then guess from among the remaining ones\u201d and that \u201cIndividuals taking the test should be instructed to cross out all the alternatives which they consider wrong.\u201d Under this approval-voting interface, we will require a worker to select every option which she believes could possibly be correct. Mathematically, we formulate this problem as eliciting the support of the beliefs of workers for each question. In the setting of crowdsourcing, as compared to single-selection, selecting multiple options would allow for obtaining more information about the partial knowledge of these non-expert workers. This additional information is particularly valuable for difficult labeling questions, allowing for the identification of the sources of difficulty. Indeed, Coombs et al. (1956) conclude that under such a questionnaire, \u201cclear evidence for the existence of partial information mediating responses to multiple choice items was obtained.\u201d\nLet us illustrate the utility of approval voting using an example in Figure 1. Assume that there are two workers. The first worker believes the true label to be either \u201ccheetah\u201d or \u201cleopard\u201d, but certainly not any other option; the second worker is confused about some other aspect of the image, and believes the true label to be either \u201ccheetah\u201d or \u201cjaguar\u201d, but certainly none of the others. If each worker is allowed to select only a single answer, it may turn out that the first worker selects \u201cleopard\u201d and the second worker selects \u201cjaguar\u201d. Their responses will thus not provide any definitive answer about the true label. In contrast, if we fully elicit their knowledge by letting them select multiple options, that is, (\u201ccheetah\u201d, \u201cleopard\u201d) from the first worker and (\u201ccheetah\u201d, \u201cjaguar\u201d) from the other worker, then \u201ccheetah\u201d becomes a clear winner.\nAlbeit its great flexibility in eliciting partial knowledge, approval voting alone is not sufficient for high quality crowdsourcing. A worker may have no incentive to truthfully disclose her partial knowledge on the crowdsourcing question. For instance, the worker may simply choose all provided options as her answer and get paid. To address this problem, we need to couple approval voting with an appropriate \u201cincentivecompatible\u201d payment mechanism such that a worker receives her maximum expected payment if and only if she truthfully discloses her partial knowledge (that is, the support of her belief) on the crowdsourcing question. In other words, the payment mechanism has to be a \u201cstrictly proper scoring rule\u201d. Moreover, we want the mechanism to be \u201cfrugal\u201d, paying as less as possible to a worker who simply selects all provided options as her answer. The problem setting for incentive mechanism design is formally described in Section 2.\nOur first result is negative, proving that unfortunately no mechanism can be incentive compatible for this setting (Section 3). This impossibility result leads us to introduce a \u201ccoarse belief\u201d assumption that relies on a certain granularity in people\u2019s beliefs.\nOur next result is the design of a payment mechanism and associated proofs showing that our mechanism 1The literature on psychology often refers to approval voting as \u201csubset selection\u201d.\nis incentive compatible and frugal (Section 4). Furthermore, we show that it is the only mechanism which satisfies these two requirements.\nWe then generalize the analysis of our mechanism to settings where the coarse belief assumption may not be satisfied, and show that our mechanism simply incentivizes workers to select options for which their belief is relatively high enough (Section 5). This perspective also leads to a simple axiomatic characterization of our mechanism.\nWe then report results from preliminary experiments verifying certain basic hypotheses underlying our approach (Section 6). The paper then diversifies to investigate two closely related settings, that of general utility functions (Section 7) and that of a problem of reporting only high enough beliefs (Section 8). The paper concludes with a discussion in Section 9."}, {"heading": "Related literature", "text": "Approval voting (Ottewell, 1977; Kellett and Mott, 1977; Weber, 1977; Brams and Fishburn, 1978) is a form of voting in which each voter can \u201capprove of\u201d (that is, select) multiple candidates. No further preferences among these candidates is specified by the voter. Our proposed interface for crowdsourcing elicits approvals on the candidate options for each question. Closer to our setting of crowdsourcing, approval voting has been studied in the context of question and answer forums (Jain et al., 2009) and Doodle polls (Zou et al., 2014). The focus of the present paper is on the design of incentive mechanisms with properties that fundamentally hold irrespective of the nature of the setting.\nThe framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future. The payment is a function of the agent\u2019s response and the outcome of the event. The payment is called \u201cstrictly proper\u201d if its expectation, with respect to the belief of the agent about the event, is strictly maximized when the agent reports her true belief. Proper scoring rules however provide a very broad class of mechanisms, and do not specify any particular mechanism for use. The mechanism proposed in the present paper may alternatively be viewed as the \u201coptimal\u201d proper scoring rules for eliciting supports of workers\u2019 beliefs across multiple questions.\nShah and Zhou (2015) consider a crowdsourcing setup with the traditional single-selection setting, also eliciting the workers\u2019 confidences for each response. They propose a mechanism to suitably incentivize workers and show that their proposed mechanism is shown to be the only one satisfying a proposed \u201cno-freelunch\u201d axiom. While the setting of our work is different from that of Shah and Zhou (2015), interestingly, our mechanism that was derived for a different interface and under a different set of assumptions, turns out to be the only mechanism that can satisfy the no-free-lunch axiom (adapted to our setting).\nThe mechanisms presented subsequently in the present paper assume the presence of some \u201cgold standard\u201d questions whose answers are known apriori to the system designer. There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions. These works typically elicit additional information from the workers, such as asking them to predict the responses of other workers. The mechanisms designed therein can generally provide only weaker guarantees due to the absence of a gold standard answer to compare with."}, {"heading": "2 Problem setup", "text": "Consider N \u2265 1 questions, each of which has B \u2265 2 options to choose from. For each option, exactly one of the B options is correct. We assume that these N questions contain G (1 \u2264 G \u2264 N) \u201cgold standard\u201d questions, that is, questions to which the mechanism designer knows the answers apriori. These\ngold standard questions are assumed to be mixed uniformly at random among the N questions, and the worker is evaluated based on her performance on these G questions. For every individual question, we assume that the worker has, in her mind, a distribution over the B options representing her beliefs of the probabilities of the respective options being correct. We assume that these belief-distributions of a worker are independent across questions (Gibbons et al., 1979). For any integerK, we will use the standard notation of [K] as a shorthand for the set {1, . . . ,K}.\nOur goal is to elicit, for every question, the support of the worker\u2019s distribution over the B options. In other words, we wish to incentivize the worker such that for each question, the worker should select the smallest subset of the set of options such that the correct answer according to her belief lies in the selected subset. Formally, suppose that for any question i \u2208 [N ], the worker believes that the probability of option b \u2208 [B] being correct is pib, for some non-negative values pi1, . . . , piB that sum to one. Then the goal is to incentivize the worker to, for each question i \u2208 [N ], select precisely the set of options\n{b \u2208 [B] | pib 6= 0}. (1)\nPayment function. As mentioned earlier, the worker\u2019s performance is evaluated based on her responses to the gold standard questions. For any question in the gold standard, we denote the evaluation of the worker\u2019s performance on this question by a value in the set {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B}: the magnitude of this value represents the number of options she had selected and the sign is positive if the correct answer was in that subset and negative otherwise. For instance, if the worker selected four options for a certain gold standard question but none of them was correct, then the evaluation of this response is denoted as \u201c\u22124\u201d; if the worker selects two options for a gold standard question and one of them turns out to be the correct option then the evaluation of this response is denoted as \u201c+2\u201d.\nWe will assume that the payments are bounded, that is, any payment must lie in the interval [\u03b1min, \u03b1max], for some values \u03b1min and \u03b1max > \u03b1min. The choice of the two parameters \u03b1min and \u03b1max may be made keeping various factors in mind, such as guidelines of the crowdsourcing platform used, the budget constraints, and the minimum wage. We will assume that the values of the two parameters are given to us.\nLet\nf : {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B}G \u2192 [\u03b1min, \u03b1max]\ndenote the payment function. It is this function f which must be designed in order to incentivize the worker. We will let that a worker who answers everything perfectly should be paid an amount \u03b1max, that is,\nf(1, . . . , 1) = \u03b1max. (2)\nExpected payment. A quantity central to our analysis is the expected payment, where the expectation is from the point of view of the worker, and is taken over the randomness in the choice of the G gold standard questions among the N questions, and over the N probability distributions representing her beliefs for the N questions. Let us formalize this notion. Suppose that for question i \u2208 [N ], the worker has selected some yi \u2208 [B] of the B options. Further, let si \u2208 [0, 1] denote the probability, under the worker\u2019s beliefs, that the correct answer to question i lies in this set of yi selected options. In other words, si denotes the sum of the beliefs for the yi options selected by the worker (consequently, the sum of the beliefs for the options not selected is (1\u2212 si)). Then from the worker\u2019s point of view, her expected payment for this selection is\n1( N G ) \u2211 (j1,...,jG)\u2286[N ] \u2211 ( 1,..., G)\u2208{\u22121,1}G ( G\u220f i=1 (1\u2212 sji)1{ i=\u22121}s 1{ i=1} ji f( 1yj1 , . . . , GyjG) ) . (3)\nThe outer summation in (3) corresponds to the expectation with respect to the random distribution of the G gold standard questions in the N total questions, and the inner summation corresponds to the expectation with respect to the worker\u2019s beliefs of her choices being correct. In this paper, we assume that the\nworkers aim to maximize their expected rewards; extending our theory to more general utility functions is straightforward.\nGiven the presence of gold standard questions, the performance of any worker is based only on her responses to questions to which answers are already known by the mechanism designer, the payments made to different workers do not depend on each other and hence we consider only one worker without loss of generality.\nGoal. The goal is to design mechanisms that are incentive compatible:\nDefinition 1 (Incentive compatibility). A mechanism is incentive compatible if the expected payment (Equation (3)), from the worker\u2019s point of view, is strictly maximized when she selects precisely the support (Equation (1)) of her belief for each question.\nNote that the definition of incentive compatibility used here considers a \u201cstrict\u201d maximization. Observe that a worker who selects all the options for all the questions doesn\u2019t give any useful information. In order to deter such \u201cfreeloading\u201d behavior, one would like to ensure that in addition to paying a (large enough) amount \u03b1 to a good worker, the mechanism should expend as small an amount as possible on such a worker. This leads to a notion of \u201cfrugality\u201d.\nDefinition 2 (Frugality). An incentive-compatible mechanism f is frugal if\nf(B, . . . , B) \u2264 f \u2032(B, . . . , B)\nfor every incentive-compatible mechanism f \u2032 that has f \u2032(1, . . . , 1) = f(1, . . . , 1).\nOur goal is to design mechanisms that are incentive-compatible, and whenever they exist, find the mechanism(s) that is (are) most frugal."}, {"heading": "3 An impossibility result and a coarse-beliefs assumption", "text": "It turns out that, unfortunately, we must face a roadblock in the first step: We can show that there exists no mechanism that is incentive compatible.\nTheorem 3.1. For any N , G and B \u2265 2, there is no mechanism that can guarantee that the worker will be incentivized to select precisely the support of her distribution for each question.\nThe proof of this result and other theoretical results (except Theorem 4.1) are provided in the appendix. In order to circumvent this impossibility result, we appeal to a certain well-understood property of\nhuman belief."}, {"heading": "Coarse beliefs assumption", "text": "There is an extensive literature in psychology establishing the coarseness of processing and perception in humans. For instance, Miller\u2019s celebrated paper (Miller, 1956) establishes the information and storage capacity of humans, that an average human being can typically distinguish at most about seven states. This granualrity of human computation is verified in many subsequent experiments (Shiffrin and Nosofsky, 1994; Saaty and Ozdemir, 2003). Jones and Loe (2013) establish the ineffectiveness of finer-granularity response elicitation. Mullainathan et al. (2008) hypothesize that humans often group things into categories; this hypothesis is experimentally verified by Siddiqi (2011) in a specific setting. We incorporate this established notion of coarseness of human processing in our model in terms of a simple assumption.\nConsider some (fixed and known) value \u03c1 > 0, and assume that the probability of any option for any question, according to the worker\u2019s belief, is either zero or greater than \u03c1. The impossibility shown in\nTheorem 3.1 pertains to \u03c1 = 0. Also, one must necessarily take into account situations when a worker is totally clueless about a question, that is, when her belief is distributed uniformly over all options. Hence we restrict \u03c1 < 1B . To summarize, we make the following \u201ccoarse belief\u201d assumption.\nDefinition 3 (Coarse belief assumption). The worker\u2019s belief for any option for any question lies in the set {0} \u222a (\u03c1, 1] for some (fixed and known) \u03c1 \u2208 ( 0, 1B ) .\nWe wish to elicit the full support of the workers\u2019 beliefs, given a coarseness of belief that assigns a value of zero to very low probability categories. The goal is to design mechanisms that are incentive-compatible and frugal, assuming the coarse belief assumption holds true."}, {"heading": "4 Incentive mechanism", "text": "Mechanism 1 presents our proposed mechanism for the problem at hand, under the coarse belief assumption.\nMechanism 1 Incentive mechanism for approval voting \u2022 Input: Evaluations of the worker\u2019s answers to the G gold standard questions (x1, . . . , xG) \u2208 {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B}G\n\u2022 Output: The worker\u2019s payment\nf(x1, . . . , xG) = (\u03b1max \u2212 \u03b1min)(1\u2212 \u03c1) \u2211G i=1(xi\u22121) G\u220f i=1 1{xi \u2265 1}+ \u03b1min\nThe payment is based only on the evaluation of the worker\u2019s responses to the gold standard questions. It is easy to describe the mechanism in words: The payment is \u03b1min plus\n\u2022 0 if the correct answer is not selected for any of the questions, otherwise\n\u2022 (\u03b1max \u2212 \u03b1min) reduced by (100\u03c1)% for each incorrect option selected.\nThe following pair of theorems present our main results, proving that this mechanism is the one and only mechanism that satisfies our requirements.\nTheorem 4.1. Under the coarse-beliefs assumption, Mechanism 1 is incentive-compatible and frugal.\nThe following theorem shows that our mechanism is strictly better than any other mechanism.\nTheorem 4.2. Under the coarse-beliefs assumption, there is no other incentive-compatible mechanism that expends as small an amount as Mechanism 1 on a worker who does not attempt any question.\nTo show the optimality and uniqueness properties claimed in Theorem 4.1 and Theorem 4.2 respectively, we prove the absence of other good mechanisms via contradiction-based arguments. Specifically, for any candidate mechanism, we identify a set of beliefs for which the worker will not be incentivized to act as required. In line with our earlier argument of beliefs being \u201ccoarse\u201d, the beliefs considered in these proofs are simple enough: the worker has some belief about one of the options, knows for sure that certain other options are incorrect, and is indifferent among the rest of the options.\nTo put things in perspective, observe that \u03c1 = 0 eliminates the dependence of the payment in Mechanism 1 on \u2211 i xi and makes the mechanism incentive incompatible. The impossibility result of Theorem 3.1 proves that every possible mechanism must necessarily suffer this fate. The remainder of this section is devoted to the proof of Theorem 4.1. The reader may feel free to jump to Section 5 without any loss in continuity."}, {"heading": "Proof of Theorem 4.1", "text": "Without loss of generality, assume that \u03b1min = 0 since in our setting, the property of incentive compatibility is invariant to any constant shift and positive scale of the payment. We adopt the succinct notation of \u03b1 := \u03b1max \u2212 \u03b1min.\nIncentive compatibility. First consider the case N = G = 1. In this case, Mechanism 1 reduces to\nf(x) = \u03b1(1\u2212 \u03c1)(x1\u22121)1{x1 \u2265 1}.\nSuppose without loss of generality that the worker\u2019s beliefs for the B options are p1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 pm > \u03c1 > pm+1 = \u00b7 \u00b7 \u00b7 = pB = 0 for some m \u2208 [B]. An incentive-compatible mechanism must strictly maximize the worker\u2019s expected payment when she selects the support of her belief, that is, the options {1, . . . ,m}. The expected payment, $sup, under this selection is\n$sup = \u03b1 m\u2211 i=1 pi(1\u2212 \u03c1)m\u22121\n= (1\u2212 \u03c1)m\u22121.\nSuppose the worker selects some other set of options {o1, . . . , o`} \u2286 [B], {o1, . . . , o`} 6= [m]. Then her expected payment $oth under the proposed mechanism for this selection is\n$oth = \u03b1 \u2211\u0300 i=1 poi(1\u2212 \u03c1)`\u22121\n\u2264 \u03b1 \u2211\u0300 i=1 pi(1\u2212 \u03c1)`\u22121, (4)\nsince p1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 pB . If ` = m then the inequality in (4) is strict since pj < pi for all (j > m, i \u2264 m). Thus the expected payment under the choice ` = m but with a selection different from the support is strictly lower than $sup. Also observe that the expected payment on selecting ` > m is upper bounded by (1 \u2212 \u03c1)`\u22121, which is strictly smaller than $sup. Let us now consider the remaining, interesting case of ` < m. Since pi > \u03c1 for all i \u2208 [m], we have\n$oth < \u03b1 ( m\u2211 i=1 pi \u2212 (m\u2212 `)\u03c1 ) (1\u2212 \u03c1)`\u22121\n= \u03b1 (1\u2212 (m\u2212 `)\u03c1) (1\u2212 \u03c1)`\u22121\n\u2264 \u03b1 (1\u2212 (m\u2212 (`+ 1))\u03c1) (1\u2212 \u03c1)`\n...\n\u2264 \u03b1(1\u2212 \u03c1)m\u22121\n= $sup.\nThis completes the proof for the case N = G = 1. Let us now consider the case of N = G \u2265 1. By our assumption of the independence of the beliefs of the worker across the questions, the expected payment equals\nG\u220f i=1 E [ \u03b1(1\u2212 \u03c1)(xi\u22121)1{xi \u2265 1} ] .\nSince the payments are non-negative, if each individual component in the product is maximized then the product is also necessarily maximized. Each individual component simply corresponds to the setting of N = G = 1 discussed earlier. Thus calling upon our earlier result, we get that the expected payment for the case N = G > 1 is maximized when the worker acts as desired for every question.\nLet us finally consider the case of N > G \u2265 1. Recall from (3) that the expected payment for the general case is a cascade of two expectations: the outer expectation is with respect to the uniformly random distribution of the G gold standard questions among the N total questions, while the inner expectation is taken over the worker\u2019s beliefs of the different questions conditioned on the choice of the gold standard questions. The arguments above for the caseN = G prove that every individual term in the inner expectation is maximized when the worker acts as desired. The expected payment is thus maximized when the worker acts as desired.\nFrugality. We first present a lemma that forms the workhorse of this and other subsequent proofs.\nLemma 4.3. Consider some y, y\u2032 \u2208 [B]N and some I \u2286 [N ] such that yi = y\u2032i+1 for all i \u2208 I, and yi = y\u2032i for all i /\u2208 I. Then any incentive compatible mechanism f must necessarily satisfy\n1( N G ) \u2211 (j1,...,jG)\u2286[N ] f(yj1 , . . . , yjG) \u2265 1( N G ) \u2211 (j1,...,jG)\u2286[N ] (1\u2212 \u03c1)|I\u2229{j1,...,jG}|f(y\u2032j1 , . . . , y \u2032 jG ).\nFurthermore, a necessary condition for the above equation to be satisfied with equality is\nf( 1y \u2032 j1 , . . . , Gy \u2032 jG ) = 0\nfor all (j1, . . . , jG) \u2286 [N ], and all {( 1, . . . , G) \u2208 {\u22121, 1}G\\{1}G | i = 1 whenever ji /\u2208 I}.\nThe proof of the lemma is provided in the appendix. We now prove the frugality of our proposed mechanism using this lemma. Consider any incentive compatible mechanism f such that f(1, . . . , 1) = \u03b1. Consider any x0 \u2208 [B \u2212 1]. Applying Lemma 4.3 with y = (x0 + 1, . . . , x0 + 1), y\u2032 = (x0, . . . , x0) and I = [G] gives\nf(x0 + 1, . . . , x0 + 1) \u2265 (1\u2212 \u03c1)Gf(x0, . . . , x0).\nA repeated application of this inequality for all x0 \u2208 [B \u2212 1] gives\nf(B, . . . , B) \u2265 (1\u2212 \u03c1)(B\u22121)Gf(1, . . . , 1) = (1\u2212 \u03c1)(B\u22121)G\u03b1.\nMechanism 1 achieves this lower bound on f(B, . . . , B) with equality, thereby completing the proof."}, {"heading": "5 Robustness to the coarse beliefs assumption", "text": "We earlier made the \u201ccoarse belief\u201d assumption that the worker\u2019s belief for any option, when non-zero, is atleast \u03c1. We then designed the Mechanism 1 that is incentive compatible with respect to eliciting the\nsupports of the beliefs of the worker. A natural question then arises is: How does the mechanism perform if the coarse beliefs assumption is violated? Does the mechanism break down?\nIn this section, we generalize the results presented earlier in the paper to the setting where workers may have arbitrary beliefs. It turns out that our proposed mechanism continues to incentivize workers to act in a certain desirable way."}, {"heading": "5.1 Incentivizing workers with finer beliefs", "text": "Suppose that Mechanism 1 (for a certain value of \u03c1) is encountered by a worker who may have arbitrary beliefs. Interestingly, it turns out that the mechanism doesn\u2019t break down, but instead does something desirable: it incentivizes the worker to select all options for which the relative belief of the worker is high enough.\nTheorem 5.1. Under Mechanism 1, for any question, a worker with beliefs 1 \u2265 p1 \u2265 . . . \u2265 pB \u2265 0 will be incentivized to select options {1, . . . ,m} where\nm = arg max z\u2208[m] ( pz\u2211z i=1 pi > \u03c1 ) .\nIt is not hard to interpret this incentivized action. The worker selects options one by one in decreasing order of her beliefs as long as the selected option contributes a fraction more than \u03c1 to the total belief of the selected options.\nLet us now verify that the earlier result of Theorem 4.1 for \u201ccoarse beliefs\u201d is indeed a special case of Theorem 5.1. To this end, suppose the beliefs of the worker for any particular question are p1 \u2265 \u00b7 \u00b7 \u00b7 pk > \u03c1 > pk+1 = \u00b7 \u00b7 \u00b7 = pB = 0 for some k \u2208 [B]. Then we have\npz\u2211z i=1 pi = 0\u2211z i=1 pi = 0 < \u03c1 for all z \u2265 k + 1,\nand pz\u2211z i=1 pi \u2265 pz 1 > \u03c1 for all z \u2264 k.\nIt follows that under the result of Theorem 5.1, a worker with \u201ccoarse beliefs\u201d will be incentivized to select precisely the support of her beliefs."}, {"heading": "5.2 An axiomatic derivation", "text": "We now present an alternative axiomatic derivation of our mechanism when accommodating workers with arbitrary beliefs. The derivation involves a \u201cno-free-lunch axiom\u201d of Shah and Zhou (2015), which when adapted to our approval-voting based setting is defined as follows. We say that a worker has \u2018attempted\u2019 a question if for that question, she doesn\u2019t select all the B options. We say that the answer to a question is wrong if the correct option does not lie in the set of selected options.\nDefinition 4 (No-free-lunch; adapted from Shah and Zhou (2015)). If the answer to every attempted question in the gold standard turns out to be wrong, then the worker gets a payment of zero, namely,\nf(x1, . . . , xG) = 0 \u2200 (x1, . . . , xG) \u2208 {\u2212(B \u2212 1), . . . ,\u22121, B}G\\{B}G.\nThe no-free-lunch axiom is quantitatively different from the criterion of frugality proposed in this paper. However, both these notions have the same qualitative goal, namely to minimize the expenditure when no useful data is obtained, while providing higher payments to workers providing better data. Interestingly, as we show below, both these notions lead to the same (unique) mechanism under our setting of approval voting.\nTheorem 5.2. Consider no assumptions on the minimum value of the belief, and suppose the workers must be incentivized to select options {1, . . . ,m} where m = arg maxz ( pz\u2211z i=1 pi > \u03c1 )\n. Then, Mechanism 1 is the one and only mechanism that is incentive compatible and satisfies no-free-lunch."}, {"heading": "6 Preliminary experiments", "text": "This section presents results from an evaluation of our proposed mechanism, Mechanism 1, on the popular Amazon Mechanical Turk (mturk.com) commercial crowdsourcing platform. The goal of this preliminary experimental exercise is to perform a basic check on whether our mechanism has the potential to work in practice. Specifically, our goal is to evaluate the primary hypotheses underlying the theory: (i) whether workers are able to make a judicious use of the approval voting setup, (ii) whether the existence of the mechanism make any difference, and (iii) if there is a opposition from the workers to the interface or the mechanism for any reason.\nIt is important to keep in mind that conclusive experiments for mechanism design are in general quite expensive with respect to time (workers may need months to understand a new mechanism) and budget. They are unlike typical machine-learning experiments that require only existing benchmark datasets. Moreover, the wordings or the interface may exert a significant influence on the workers\u2019 behavior. Like most mechanism design papers, we position our work primarily as a theoretical study. We expect that more detailed experiments will follow the publication of our work; indeed, it is best if experiments on such incentive schemes are conducted by multiple groups."}, {"heading": "6.1 Methods", "text": "We conducted three separate sets of experiments, with over 200 workers in each experiment:\n\u2022 Identifying languages from displayed text (Figure 1)\n\u2022 Identifying animals in displayed images (Figure 2(a))\n\u2022 Identifying textures in displayed images (Figure 2(b)).\nIn each experiment, every worker was assigned one of four mechanisms uniformly at random. The variable component of each mechanism was executed as a \u201cbonus payment\u201d based on the evaluation of the worker\u2019s performance on the gold standard questions, on top of a guaranteed payment of 10 cents (this was \u03b1min). The four mechanisms tested were:\n\u2022 Single-selection interface with additive payments: The worker must select a single option for every question. The bonus starts at zero and is increased additively by a fixed amount for every correct answer.\n\u2022 Skip-based single-selection interface with multiplicative payments (Shah and Zhou, 2015): For every question, the worker can either select one option or skip the question. The bonus starts at a certain positive value, is reduced by a certain fraction for each skipped question, and becomes zero in case of an incorrect answer.\n\u2022 Approval-voting interface with a fixed payment: The bonus is fixed.\n\u2022 Approval-voting interface with Mechanism 1.\nGiven the caveats associated to experiments on mechanism design as mentioned earlier, we provided detailed instructions about the task and the mechanism to each worker, and also made them work through multiple examples. The entire data related to the experiments, including the interfaces used, specifics about the payment mechanisms, and the responses of the workers, is available on the website of the first author."}, {"heading": "6.2 Results", "text": "Let us first eyeball the raw data. Figure 3 presents combined results from the three experiments. Figure 3(a) shows the breakup of the evaluations of all the collected responses. The magnitude of the evaluation represents the number of options selected and its sign denotes whether the correct option was selected (positive) or not (negative). Figure 3(b) depicts the fraction of responses to attempted questions that turned out to\nbe wrong. Figure 3(c) depicts the fraction of responses that were correct when only one option was selected. Figure 3(d) depicts the average payment per worker. Using this data, let us now investigate the three questions posed at the beginning of the experiments:\n(i) Are the workers making a judicious use of the approval voting setup? One can observe from Figure 3(a) more than 40% responses comprised a selection of two or three options, suggesting that the workers did understand the concept of approval voting.\n(ii) Does the presence of a mechanism makes a difference? We compared the data from the approval voting setup under the fixed mechanism with the data from the approval voting setup under Mechanism 1. In particular, we applied Hotelling\u2019s T-squared test, where we treated the response by any worker to any question as a two-dimensional data point, with the number options selected and the correctness of the answer as the two dimensions. The results of this test are listed in Table 1. We could reject the null hypothesis (of the two sets of data being drawn from distributions with identical means) with p < 0.01 for each of the three experiments.\n(iii) Is there is an opposition from the workers to the interface or the mechanism for any reason? We also elicited feedback about the task from every worker, informing them that the feedback will not affect their payment. We received mostly neutral feedback, some positive feedback, and no negative feedback about either the approval voting interface or our mechanism.\nAll in all, these preliminary experiments indicate that our mechanism is practical and can potentially be useful for many applications in machine learning, paying higher amounts to good workers and lower amounts to freeloaders or spammers.\nA concluding remark. A standard means of denoising data from crowdsourcing is to ask every question to multiple workers, and employ a statistical aggregation algorithm to aggregate the data so obtained. In the future, we wish to evaluate the performance of our proposed interface and mechanism on such aggregated data. To this end, our goal for the future is to design algorithms designed towards statistical aggregation of data collected through the interface and mechanism proposed in this paper."}, {"heading": "7 General utility functions", "text": "In this section, we consider a setting where the worker, instead of maximizing her expected payment, aims to maximize the expected value of some utility function of her payment.\nConsider any function U : R \u2192 R. Suppose that instead of aiming to maximize the expected payment, the worker has some utility U for any payment made to her, and that she aims to maximize the expected utility. In other words, for any payment f made to the worker (based on the evaluation of her answers to the gold standard questions), her utility for this payment is U(f). The worker aims to maximize the expected value of U(f).\nWe will require the function U to be strictly increasing and invertible. The results presented so far in the paper implicitly assumed that the utility is simply the identity function, namely U(x) = x. The function U is assumed to be public knowledge.\nGiven the evaluations x1, . . . , xG of the worker\u2019s responses to the G gold standard questions, consider\nthe following payment mechanism:\nf(x1, . . . , xG) = U \u22121 ( (U(\u03b1max)\u2212 U(\u03b1min))(1\u2212 \u03c1) \u2211G i=1(xi\u22121)\nG\u220f i=1 1{xi \u2265 1}+ U(\u03b1min)\n) . (5)\nIt is easy to see that the properties of Mechanism 1 carry over to this mechanism in the case of a general utility function U . This feature is formalized in the following proposition.\nProposition 7.1. For a worker who aims to maximize function U of the payment, the mechanism in Equation (5) is incentive compatible, frugal, and is the one and only incentive compatible mechanism to satisfy the no-free-lunch axiom."}, {"heading": "8 An alternative problem statement", "text": "In earlier sections, we made the coarse belief assumption of the existence of some \u03c1 \u2208 (0, 1B ) such that the belief of a worker for any option is assumed to either equal 0 or more than \u03c1. We then designed a mechanism to elicit the support of the worker\u2019s belief under this assumption. A natural question that arises is that instead of making a coarse belief assumption, can we fix a parameter, say, \u03c3 \u2208 (0, 1), and incentivize the worker to select all options for which her belief is strictly greater \u03c3? Although not the primary focus of this paper, we devote the present section to investigating this complimentary setting out of intellectual curiosity as well as practical relevance. As we show below, the answer to this question is both yes and no."}, {"heading": "8.1 Problem setting", "text": "For a given value of \u03c3 \u2208 (0, 1), we will call a mechanism as incentive compatible if the expected payment of any worker is strictly maximized when the worker selects all options for which her belief is strictly greater than \u03c3.\nWe retain most notation form Section 2, with a few exceptions as follows. We continue to let f denote the payment function; f : {\u2212(B\u22121), . . . , B}G \u2192 [\u03b1min, \u03b1max]. Observe that unlike the setting considered earlier in Section 2, here we have included 0 in the domain of the payment function. This is because under the present setting, when \u03c3 \u2265 1B , there is a possibility that the worker has a belief no more than \u03c3 for each option, for instance, if the worker is totally clueless.\nLet us define two integers smin and smax as smin = 1{\u03c3 < 1B} and smax = min{d 1 \u03c3 e \u2212 1, B}. 2 Observe that if if \u03c3 < 1B then it is meaningless to let the worker select zero options since the belief for at least one option must be 1B or higher. Also observe that for any value of \u03c3 \u2208 (0, 1), it is meaningless to allow the worker to select d 1\u03c3 e or more options, since it is mathematically impossible for those many options to have beliefs more than \u03c3. As a result, we will require the worker to select at least smin and at most smax options for any question. The goal remains to design the payment function f(x1, . . . , xG) when |xi| \u2208 {smin, . . . , smax} for every i \u2208 [G]. If the worker\u2019s responses do not satisfy this condition, then we assume the convention of setting the payment to a small enough value (say, \u03b1min or some further penalty).\nWe do not assume the restriction of coarseness of the beliefs. We stick to the identity utility function, while noting that extension to other utility functions is straightforward following Section 7.\nFinally, we note some special cases which we exclude from the subsequent analysis. The case of \u03c3 = 0 degenerates to the impossibility result of Theorem 3.1 proved earlier. The cases of B = 2 or \u03c3 \u2265 12 degenerate to the \u201cskip-based\u201d single-selection setting studied in Shah and Zhou (2015). Hence we focus on the case of B \u2265 3 and \u03c3 \u2208 (0, 12) in the rest of this section.\n2The function 1 : {True, False} \u2192 {0, 1} is the indicator function, with 1{x} = 1 if x is true, and 0 otherwise."}, {"heading": "8.2 Mechanism", "text": "Mechanism 2 Incentive mechanism for the alternative problem formulation \u2022 Input: Evaluations of the worker\u2019s answers to the G gold standard questions (x1, . . . , xG)\n\u2022 Output: Define a function g : R\u2192 R as\ng(y) = (B \u2212 |y|)\u03c3 + 1{y \u2265 1}.\nThe worker\u2019s payment is\nf(x1, . . . , xG) = a+ b G\u2211 i=1 g(xi),\nwhere a = \u03b1min and b = \u03b1max\u2212\u03b1minG((B\u22121)\u03c3+1) .\nGiven the conventions described in the previous subsection for the payment function, it remains to construct the payment function under \u201cnormal\u201d conditions, that is, when smin \u2264 xi \u2264 smax for every i \u2208 [G]. Mechanism 2 now presents our proposed mechanism for this setting.\nTheorem 8.1. Consider any \u03c3 \u2208 (0, 12), N \u2265 G \u2265 1 and B \u2265 3. Consider the goal of designing a mechanism such that for each question, the worker is incentivized to select every option for which her belief is more than \u03c3. Assume that no belief equals exactly \u03c3. Then Mechanism 2 is incentive compatible.\nThe function g, in words, penalizes the selection of an incorrect option by \u03c3 and rewards the selection of the correct option by 1. Under beliefs {p1, . . . , pB} for a gold standard question, when the worker answers as per our requirements, the expected value of g equals \u2211B i=1max{pi, \u03c3}.\nThe setting also permits a \u201cmultiplicative\u201d mechanism, consistent with the earlier results in this paper.\nCorollary 8.2. Under the assumption that no belief equals exactly \u03c3, the mechanism\nf(x1, . . . , xG) = a+ b G\u220f i=1 (g(xi)\u2212 c),\nfor some constants a, b > 0 and c \u2264 g(\u2212smax), is also incentive compatible."}, {"heading": "8.3 Uniqueness and an impossibility result", "text": "In this section, we show that the core structure of Mechanism 2, namely the function g, is essential for any mechanism. We also show that the (mild) assumption of no belief equalling exactly \u03c3 is unavoidable.\nTheorem 8.3. Consider any \u03c3 \u2208 (0, 12) and any B \u2265 3. Consider the goal of designing a mechanism such that for each question, the worker is incentivized to select every option for which her belief is more than \u03c3. Then: (A) Under the assumption that no belief equals exactly \u03c3, when G = 1, the function g is the one and only incentive-compatible mechanism upto a constant shift and positive scaling. (B) For any N \u2265 G \u2265 1, no mechanism is incentive compatible in the absence of this assumption.\nWhile we do not have a complete answer as to what the \u201cbest\u201d or \u201cunique\u201d mechanism is for general values of N and G, but going by results proved earlier in the paper, we conjecture that the multiplicative version of the mechanism (Corollary 8.2) may possess attractive properties. Further exploration of this setting is beyond the scope of this paper."}, {"heading": "9 Discussion and open problems", "text": "Our goal is to deliver high quality labels for machine learning applications, at low costs, by means of incentive mechanisms or aggregation algorithms or both. In this paper, we pursue the former approach. We take an approval-voting based means of gathering labeled data from crowdsourcing. We design an incentive mechanism via a principled theoretical approach, and prove appealing properties of optimality and uniqueness of our proposed mechanism. Preliminary experiments conducted on Amazon Mechanical Turk corroborate the usefulness of this mechanism for practical scenarios. Our mechanism may also draw more experts to the crowdsourcing platform since their compensation will be significantly higher than that of mediocre workers, unlike most compensation mechanisms in current use.\nWe conclude with a discussion on closely related topics that merit investigation in the future. Aggregation of labels. For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012). An open problem is the design of aggregation algorithms for approval-voting-based data: algorithms that can exploit the specific structure of the responses that arise as a result of the approval voting interface and the proposed mechanism. There is indeed work on aggregation algorithms (Masso\u0301 and Vorsatz, 2008; Caragiannis et al., 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing.\nChoosing the right interface. There are tradeoffs between various interfaces for crowdsourcing. For instance, the approval voting interface elicits the support of the belief whereas the single selection interface elicits the mode. Choosing among these two interfaces would depend on the application under consideration, and moreover, one may adaptively switch between the two depending on the data obtained. A natural question that one may further ask is, why not elicit the entire belief distribution itself? While the entire belief distribution seems to supercede the support and the mode, stating the distribution will also require much more time and effort from the workers, and often also suffer from a higher noise. These tradeoffs must be taken into account when choosing the interface for the application at hand.\nThe coarse beliefs parameter. One may wish to evaluate the value of \u03c1 by explicitly asking workers on the crowdsourcing platform for this value. However, it is noted in the literature (e.g., see Shah et al. (2015) for experiments on Amazon Mechanical Turk) that the cardinal representations that humans provide are not always consistent with their respective mental beliefs, and are far noisier. This phenomenon suggests the requirement of developing alternative methods of evaluating this parameter. Indeed, measurement is considered one of the most difficult parts of behavioral research.\nWe look forward to future work exploring these topics in depth."}, {"heading": "Acknowledgements", "text": "This paper was presented in part at the International Conference on Machine Learning (ICML) 2015. The work of the first author was supported in part by a Microsoft Research PhD fellowship."}, {"heading": "APPENDIX", "text": ""}, {"heading": "A Proofs", "text": "In this section, we present proofs of the various theoretical results presented in the paper."}, {"heading": "A.1 Proof of Theorem 3.1: Impossibility", "text": "We assume that there indeed exists some incentive-compatible payment function f , and prove a contradiction.\nLet us first consider the special case of N = G = 1 and B = 2. Since N = G = 1, there is only one question. Let p1 > 0.5 be the probability, according to the belief of the worker, that option 1 is correct; the worker then believes that option 2 is correct with probability (1\u2212 p1).\nWhen p1 = 1, we need the worker to select option 1 alone. Thus we need\nf(1) > f(2).\nWhen p1 \u2208 (0.5, 1), we require the worker to select options 1 and 2, as opposed to selecting option 1 alone. For this we need\np1f(1) + (1\u2212 p1)f(\u22121) < f(2)\nIt follows that we need\n(1\u2212 p1)(f(1)\u2212 f(\u22121)) > f(1)\u2212 f(2). (6)\nHowever, the inequality (6) is satisfied only when f(1) > f(\u22121) and (1\u2212 p1) > f(1)\u2212f(2)f(1)\u2212f(\u22121) . Thus for any given payment function f , a worker with belief (1\u2212 p1) \u2208 (0, f(1)\u2212f(2)f(1)\u2212f(\u22121)) will not be incentivized to select the support of her belief. This yields a contradiction.\nWe now move on to the general case of N \u2265 G \u2265 1 and B \u2265 2. Consider a worker who is clueless about questions 2 through N (i.e., her belief is uniform across all options for these questions). Suppose this worker selects all B options for these questions as desired. For the first question, suppose that the worker is sure that options 3, . . . , B are incorrect. We are now left with the first question and the first two options for this question. Letting X denote a random variable representing the evaluation of the worker\u2019s response to the first question, the expected payment then is\nG N E[f(X,B, . . . , B)] + (1\u2212 G N )f(B, . . . , B).\nThe expectation in the first term is taken with respect to the randomness in X . Defining\nf\u0303(X) := G N f(X,B, . . . , B) + (1\u2212 G N )f(B, . . . , B),\nand applying the same arguments to f\u0303 as those for f for the case of N = G = 1, B = 2 above gives the desired contradiction. This thus completes the proof of impossibility.\nA.2 Proof of Lemma 4.3: The workhorse lemma\nConsider some \u03c10 \u2208 (\u03c1, 1B ). Consider a worker such that for every question i \u2208 I, her belief is \u03c10 for the first option and 1\u2212\u03c10yi\u22121 for each of the last (yi \u2212 1) options. For every question i /\u2208 I, her belief is uniformly distributed among the first yi options. Now, if the worker selects precisely the support of her beliefs for every question then her expected payment $1 is\n$1 = 1( N G ) \u2211 (j1,...,jG)\u2286[N ] f(yj1 , . . . , yjG). (7)\nWe will compare the aforementioned action to another action, where for each question i \u2208 I, the worker selects only the last (yi \u2212 1) options but not the first option; for each question i /\u2208 I, the worker selects the support of her belief. Under this action, the expected payment $2 is $2 = 1( N G ) \u2211 (j1,...,jG) \u2286[N ] \u2211 ( 1,..., G) \u2208{\u22121,1}G 1{{ji | i = \u22121} \u2286 I}(1\u2212 \u03c10)|I\u2229{ji| i=1}|\u03c1|I\u2229{ji| i=\u22121}|0 f( 1y \u2032 j1 , . . . , Gy \u2032 jG ).\n(8)\nIn the expression (8), the outer summation represents the expectation over the random choice of the G gold standard questions among the N questions. The inner summation represents the expectation with respect to the correctness or incorrectness of the answers to the G gold standard questions: for any question i, i = 1 captures the event where the ith question in the gold standard is answered correctly and i = \u22121 represents the event of this question being answered incorrectly. The term 1{{ji | i = \u22121} \u2286 I} ensures that only the questions in I can be wrong, since it is only these questions for which the worker has selected a subset of her belief\u2019s support.\nSince f(x) \u2265 0 for all x, we can lower bound $2 as\n$2 \u2265 1( N G ) \u2211 (j1,...,jG)\u2286[N ] (1\u2212 \u03c10)|I\u2229{j1,...,jG}|f(y\u2032j1 , . . . , y \u2032 jG ). (9)\nAn incentive compatible mechanism must incentivize the worker to perform the first action (over the second), i.e, must have $1 > $2. Thus from (7) and (9), we get\n1( N G ) \u2211 (j1,...,jG)\u2286[N ] f(yj1 , . . . , yjG) > 1( N G ) \u2211 (j1,...,jG)\u2286[N ] (1\u2212 \u03c10)|I\u2229{j1,...,jG}|f(y\u2032j1 , . . . , y \u2032 jG ). (10)\nNote that (10) must hold for all \u03c10 > \u03c1. The left hand side of (10) does not involve \u03c10 whereas the right hand side is continuous in \u03c10. It follows that\n1( N G ) \u2211 (j1,...,jG)\u2286[N ] f(yj1 , . . . , yjG) \u2265 1( N G ) \u2211 (j1,...,jG)\u2286[N ] (1\u2212 \u03c1)|I\u2229{j1,...,jG}|f(y\u2032j1 , . . . , y \u2032 jG ). (11)\nThis proves the first part of the lemma. We now move on to the second part of the lemma, concerning equality in (11). Suppose f( 1y\u2032j1 , . . . , Gy \u2032 jG ) is strictly positive for any (j1, . . . , jG) \u2286 [N ], {( 1, . . . , G) \u2208 {\u22121, 1}G\\{1}G | i = 1 whenever ji /\u2208 I}. Then (11) will necessarily be a strict inequality. The claimed necessary condition for equality is thus established."}, {"heading": "A.3 Proof of Theorem 4.2: Frugality", "text": "Without loss of generality, assume that \u03b1min = 0 since in our setting, the property of incentive compatibility is invariant to any constant shift and positive scale of the payment. We adopt the succinct notation of \u03b1 := \u03b1max \u2212 \u03b1min.\nConsider any incentive compatible mechanism f such that f(1, . . . , 1) = \u03b1 and f(B, . . . , B) = (1 \u2212 \u03c1)G(B\u22121)\u03b1. We will show that this payment mechanism must be identical to Mechanism 1.\nWe consider the set of evaluations x whose elements are non-decreasing, i.e., x1 \u2265 x2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 xG; The proof for any other ordering follows in an identical manner.\nFirst consider any x such that xG > 0.\n\u2022 Let \u03b3(x) denote the number of distinct entries in x:\n\u03b3(x) := 1 + G\u22121\u2211 i=1 1{xi 6= xi+1}\n\u2022 Let \u03c3(x) denote the size of the last jump in x:\n\u03c3(x) := xj \u2212 xj+1 where j = arg max i\u2208[G\u22121] xi 6= xi+1\n\u2022 Let \u03b2(x) denote the numeric value of x in a B-ary number system:\n\u03b2(x) := G\u2211 i=1 BG\u2212i(xi \u2212 1).\nFor example, if B = 5, G = 5 and x = (5, 5, 4, 1, 1) then \u03b3(x) = |{5, 4, 1}| = 3, \u03c3(x) = 4\u2212 1 = 3 (where j = 3), and \u03b2(x) = 4 \u00b7 54 + 4 \u00b7 53 + 3 \u00b7 52 + 0 \u00b7 51 + 0 \u00b7 50 = 3075. The proof involves three nested levels of induction: on \u03b3, on \u03c3 and then on \u03b2.\nWe first induct on \u03b3. The base case is the set {x|\u03b3(x) = 1}, i.e., the set of vectors which have the same value for all its components. Consider any x0 \u2208 [B\u22121]. Applying Lemma 4.3 with y = (x0+1, . . . , x0+1) and y\u2032 = (x0, . . . , x0) gives\nf(x0 + 1, . . . , x0 + 1) \u2265 (1\u2212 \u03c1)Gf(x0, . . . , x0).\nSince this inequality is true for every x0 \u2208 [B \u2212 1], we have\nf(B, . . . , B) \u2265 (1\u2212 \u03c1)(B\u2212x0)Gf(x0, . . . , x0) \u2265 (1\u2212 \u03c1)(B\u22121)Gf(1, . . . , 1).\nSetting f(B, . . . , B) = (1\u2212 \u03c1)(B\u22121)\u03b1 and f(1, . . . , 1) = \u03b1 proves the base case. Now suppose our hypothesis is true for all {x|\u03b3(x) \u2264 \u03b30 \u2212 1} for some \u03b30 \u2208 {2, . . . , B}. We will now prove that the hypothesis is also true for all {x|\u03b3(x) \u2264 \u03b30}. Towards this goal, we will now induct on \u03c3. The set of all {x|\u03b3(x) = \u03b30 \u2212 1} can be treated as a base case for our induction, with this base case corresponding to \u03c3 = 0. Due to the induction hypothesis on \u03b3, the base case of \u03c3 = 0 is already proven.\nNow suppose that the hypothesis is true for all {x|\u03b3(x) = \u03b30, \u03c3(x) \u2264 \u03c30 \u2212 1} for some \u03c30 \u2208 [B \u2212 1]. We will prove that the hypothesis remains true for all {x|\u03b3(x) = \u03b30, \u03c3(x) = \u03c30}. To this end, we will induct on \u03b2.\nRecall that we have restricted our attention to those x which have their elements in a descending order. Observe that the element with the minimum value of \u03b2 in the set {x|\u03b3(x) = \u03b30, \u03c3(x) = \u03c30} is (\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 1, . . . , 1). We will prove the hypothesis for this element as the base case for our induction on \u03b2. Applying Lemma 4.3 with y = (\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30 + 1, 1, . . . , 1) and y\u2032 = (\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30, 1, . . . , 1) gives the inequality\nc1f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30 + 1, 1, . . . , 1) + c\u20321f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, 1, 1, . . . , 1) + \u2211\ns({\u03b30+\u03c30\u22121,...,\u03c30+2}\n( csf(s, 1, 1, . . . , 1) + c \u2032 sf(s, \u03c30 + 1, 1, . . . , 1) ) \u2265 c1(1\u2212 \u03c1)f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30, 1, . . . , 1) + c\u20321f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, 1, 1, . . . , 1)\n+ \u2211\ns({\u03b30+\u03c30\u22121,...,\u03c30+2}\n( csf(s, 1, 1, . . . , 1) + c \u2032 s(1\u2212 \u03c1)f(s, \u03c30, 1, . . . , 1) ) , (12)\nfor some positive constants c1, c\u20321, cs, c \u2032 s (which represent the probabilities of the respective set of G questions being chosen as the G gold standard questions). Now, for any s ( {\u03b30 + \u03c30\u2212 1, . . . , \u03c30 +2}, observe that \u03b3(s, \u03c30 + 1, 1, . . . , 1) \u2264 \u03b30 \u2212 1 and \u03b3(s, \u03c30, 1, . . . , 1) \u2264 \u03c30 \u2212 1. Thus from our induction hypothesis, we have\nf(s, \u03c30 + 1, 1, . . . , 1) = (1\u2212 \u03c1)f(s, \u03c30, 1, . . . , 1). (13)\nAlso, \u03b3(\u03b30 + \u03c30\u2212 1, . . . , \u03c30 +2, \u03c30, 1, . . . , 1) = \u03b30 and \u03c3(\u03b30 + \u03c30\u2212 1, . . . , \u03c30 +2, \u03c30, 1, . . . , 1) = \u03c30\u2212 1. Consequently from our induction hypothesis, we have\nf(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30, 1, . . . , 1) = (1\u2212 \u03c1)\u03b30+\u03c30\u22122+\u00b7\u00b7\u00b7+\u03c30+1+\u03c30\u22121\u03b1. (14)\nSubstituting (13) and (14) in (12) and canceling out common terms gives\nf(\u03b30+\u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30 + 1, 1, . . . , 1) \u2265 (1\u2212 \u03c1)\u03b30+\u03c30\u22122+\u00b7\u00b7\u00b7+\u03c30\u03b1.\nWe will now derive a matching upper bound on f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30 + 1, 1, . . . , 1). Applying Lemma 4.3 with y = (\u03b30+\u03c30\u2212 1, . . . , \u03c30+1, 2, . . . , 2) and y\u2032 = (\u03b30+\u03c30\u2212 1, . . . , \u03c30+1, 1, . . . , 1) gives\nc1f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 2, . . . , 2) + \u2211\ns({\u03b30+\u03c30\u22121,...,\u03c30+1}\ncsf(s, 2, . . . , 2)\n\u2265 c1(1\u2212 \u03c1)G\u2212\u03b3+1f(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 1, . . . , 1) + \u2211\ns({\u03b30+\u03c30\u22121,...,\u03c30+1}\ncs(1\u2212 \u03c1)G\u2212|s|f(s, 1, . . . , 1),\n(15)\nfor some positive constants c1, cs. Now, for any s ( {\u03b30+\u03c30\u22121, . . . , \u03c30+2}, observe that \u03b3(s, 2, . . . , 2) \u2264 \u03b30 \u2212 1 and \u03b3(s, 1, . . . , 1) \u2264 \u03c30 \u2212 1. Thus from our induction hypothesis, we have\nf(s, 2, . . . , 2) = (1\u2212 \u03c1)G\u2212|s|f(s, 1, . . . , 1). (16)\nAlso, \u03b3(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 2, . . . , 2) \u2264 \u03b30 and \u03c3(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 2, . . . , 2) = \u03c30 \u2212 1. Consequently from our induction hypothesis,\nf(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 1, 2, . . . , 2) = (1\u2212 \u03c1)\u03b30+\u03c30\u22122+...+\u03c30+G\u2212\u03b3+1\u03b1. (17)\nSubstituting these values in (15) and canceling out common terms gives\nf(\u03b30 + \u03c30 \u2212 1, . . . , \u03c30 + 2, \u03c30 + 1, 1, . . . , 1) \u2264 (1\u2212 \u03c1)\u03b30+\u03c30\u22122+\u00b7\u00b7\u00b7+\u03c30\u03b1.\nWe have thus proved that the hypothesis is true for x = (\u03b30+\u03c30\u2212 1, . . . , \u03c30+2, \u03c30+1, 1, . . . , 1), the base case for our induction on \u03b2.\nNow consider some x\u2217 such that \u03b3(x\u2217) = \u03b30, \u03c3(x\u2217) = \u03c30 and \u03b2(x\u2217) = \u03b20, for some \u03b20. Let us denote the components of x\u2217 as x\u2217 = (x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x\n\u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G) with x \u2217 1 \u2265 x\u22172 \u2265 \u00b7 \u00b7 \u00b7 \u2265\nx\u2217m > \u03c30 + x \u2217 G for some m \u2265 0, m1 \u2265 1, m+m1 < G. Suppose the hypothesis is true for all {x|\u03b3(x) = \u03b30, \u03c3(x) = \u03c30, \u03b2(x) \u2264 \u03b20\u22121}. Applying Lemma 4.3 with y = (x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G, . . . , \u03c30 + x\u2217G\ufe38 \ufe37\ufe37 \ufe38 m1 , x\u2217G, . . . , x \u2217 G) and y\u2032 = (x\u22171, . . . , x \u2217 m, \u03c30 + x\n\u2217 G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G) gives the inequality\nc1f(x \u2217 1, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G)\n+ \u2211\ns({x\u22171,...,x\u2217m,\u03c30+x\u2217G,...,\u03c30+x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncsf(s, x \u2217 G, . . . , x \u2217 G)\n\u2265 c1(1\u2212 \u03c1)m1f(x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38 m1 , x\u2217G, . . . , x \u2217 G)\n+ \u2211\ns({x\u22171,...,x\u2217m,\u03c30+x\u2217G\u22121,...,\u03c30+x \u2217 G\u22121\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncs(1\u2212 \u03c1) \u2211 i 1{si=\u03c30+x\u2217G\u22121}f(s, x\u2217G, . . . , x \u2217 G), (18)\nfor some positive constants c1, cs. Observe that\n\u03b3(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G) = { \u03b30 \u2212 1 if \u03c30 = 1 \u03b30 otherwise,\nand the induction hypothesis is satisfied in the first case. In the second case,\n\u03c3(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G) = \u03c30 \u2212 1,\nand hence the induction hypothesis is satisfied in the second case as well. Thus\nf(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G)\n= (1\u2212 \u03c1) \u2211m i=1(x \u2217 i\u22121)+m1(\u03c30+x\u2217G\u22122)+(G\u2212m1\u2212m)(x \u2217 G\u22121)\u03b1. (19)\nFor any for any s ( {x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38 m1\n}, define m1(s) := \u2211 i 1{si = \u03c30+x\u2217G\u2212\n1}. Observe that if m1(s) > 0 then either \u03b3((s, x\u2217G, . . . , x\u2217G)) \u2264 \u03b30 \u2212 1 or \u03c3((s, x\u2217G, . . . , x\u2217G)) \u2264 \u03c30 \u2212 1; if m1(s) = 0 then \u03b3((s, x\u2217G, . . . , x \u2217 G)) \u2264 \u03b30 \u2212 1. For any s ( {x\u22171, . . . , x\u2217m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n}, define\nm\u03031(s) := \u2211\ni 1{si = \u03c30 + x\u2217G}. Observe that if m\u03031(s) > 0 then either \u03b3((s, x\u2217G, . . . , x\u2217G)) \u2264 \u03b30 \u2212 1 or \u03b2((s, x\u2217G, . . . , x \u2217 G)) \u2264 \u03b20 \u2212 1; if m\u03031(s) = 0 then \u03b3((s, x\u2217G, . . . , x\u2217G)) \u2264 \u03b30 \u2212 1. Consequently from our induction hypothesis we have\u2211 s({x\u22171,...,x\u2217m,\u03c30+x\u2217G,...,\u03c30+x\n\u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncsf(s, x \u2217 G, . . . , x \u2217 G)\n= \u2211\ns({x\u22171,...,x\u2217m,\u03c30+x\u2217G\u22121,...,\u03c30+x \u2217 G\u22121\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncs(1\u2212 \u03c1) \u2211 i 1{si=\u03c30+x\u2217G\u22121}f(s, x\u2217G, . . . , x \u2217 G).\n(20)\nSubstituting (19) and (20) in (18) and canceling out common terms gives\nf(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G)\n\u2265 (1\u2212 \u03c1)m1f(x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G \u2212 1, . . . , \u03c30 + x\u2217G \u2212 1\ufe38 \ufe37\ufe37 \ufe38 m1 , x\u2217G, . . . , x \u2217 G)\n= (1\u2212 \u03c1) \u2211m i=1(x \u2217 i\u22121)+m1(\u03c30+x\u2217G\u22121)+(G\u2212m1\u2212m)(x \u2217 G\u22121)\u03b1.\nWe will now employ Lemma 4.3 again to derive a matching lower bound. Setting y = (x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x\n\u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G + 1, . . . , x \u2217 G + 1) and y \u2032 = (x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G)\nin Lemma 4.3 yields the inequality\nc1f(x \u2217 1, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G + 1, . . . , x \u2217 G + 1)\n+ \u2211\ns({x\u22171,...,x\u2217m,\u03c30+x\u2217G,...,\u03c30+x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncsf(s, x \u2217 G + 1, . . . , x \u2217 G + 1)\n\u2265 c1(1\u2212 \u03c1)m1f(x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G, . . . , \u03c30 + x\u2217G\ufe38 \ufe37\ufe37 \ufe38 m1 , x\u2217G, . . . , x \u2217 G)\n+ \u2211\ns({x\u22171,...,x\u2217m,\u03c30+x\u2217G,...,\u03c30+x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n}\ncs(1\u2212 \u03c1)G\u2212|s|f(s, x\u2217G, . . . , x\u2217G), (21)\nfor some positive constants c1, cs. Observe that\n\u03b3(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G + 1, . . . , x \u2217 G + 1) = { \u03b30 \u2212 1 if \u03c30 = 1 \u03b30 otherwise,\nand that the induction hypothesis is satisfied in the first case. In the second case,\n\u03c3(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G + 1, . . . , x \u2217 G + 1) = \u03c30 \u2212 1,\nand hence the induction hypothesis is satisfied in the second case as well. Thus\nf(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G + 1, . . . , x \u2217 G + 1)\n= (1\u2212 \u03c1) \u2211m i=1(x \u2217 i\u22121)+m1(\u03c30+x\u2217G\u22121)+(G\u2212m1\u2212m)(x \u2217 G\u22122)\u03b1. (22)\nNow consider any s ( {x\u22171, . . . , x\u2217m, \u03c30 + x\u2217G, . . . , \u03c30 + x\u2217G\ufe38 \ufe37\ufe37 \ufe38 m1\n}, and recall our notation of m\u03031(s) := \u2211 i 1{si =\n\u03c30 + x \u2217 G}. If \u03c30 = 1 or if m\u03031(s) = 0 then \u03b3((s, x\u2217G + 1, . . . , x\u2217G + 1)) \u2264 \u03b30 \u2212 1; if \u03c3 > 1 and m\u03031(s) > 0 then \u03b3((s, x\u2217G + 1, . . . , x \u2217 G + 1)) \u2264 \u03b30 and \u03c3(s, x\u2217G + 1, . . . , x\u2217G + 1) \u2264 \u03c30 \u2212 1. If m\u03031(s) = 0 then \u03b3((s, x\u2217G, . . . , x \u2217 G)) \u2264 \u03b30 \u2212 1, otherwise \u03b3((s, x\u2217G, . . . , x\u2217G)) \u2264 \u03b30, \u03c3((s, x\u2217G, . . . , x\u2217G)) = \u03c30 and \u03b2((s, x\u2217G, . . . , x \u2217 G)) \u2264 \u03b20 \u2212 1. These terms thus satisfy our induction hypothesis and hence\nf(s, x\u2217G + 1, . . . , x \u2217 G + 1) = (1\u2212 \u03c1)G\u2212|s|f(s, x\u2217G, . . . , x\u2217G). (23)\nSubstituting (22) and (23) in (21) gives us our desired matching lower bound\nf(x\u22171, . . . , x \u2217 m, \u03c30 + x \u2217 G, . . . , \u03c30 + x \u2217 G\ufe38 \ufe37\ufe37 \ufe38\nm1\n, x\u2217G, . . . , x \u2217 G) \u2264 (1\u2212 \u03c1)\n\u2211m i=1(x \u2217 i\u22121)+m1(\u03c30+x\u2217G\u22121)+(G\u2212m1\u2212m)(x \u2217 G\u22121)\u03b1.\nThis completes the proof for {x|xi \u2265 0 \u2200 i \u2208 [G]}. We will now show that f(x) = 0 for all {x | mini\u2208[G] xi < 0}. The arguments above for the case {x | mini\u2208[G] xi > 0} imply that for any incentive-compatible function f , the first part of Lemma 4.3 must be satisfied with equality. This allows us to employ the second part of Lemma 4.3. For i \u2208 [G], let yi = y \u2032 i = xi if xi > 0, and yi \u2212 1 = y\u2032i = |xi| otherwise; set yi = y\u2032i = B for all i \u2208 {G + 1, . . . , N}. Then the second part of Lemma 4.3 necessitates f(x1, . . . , xG) = 0, thus completing the proof.\nA.4 Proof of Theorem 5.1: Mechanism in absence of coarse belief assumption\nWithout loss of generality, assume that \u03b1min = 0 since in our setting, the property of incentive compatibility is invariant to any constant shift and positive scale of the payment. We adopt the succinct notation of \u03b1 := \u03b1max \u2212 \u03b1min.\nFirst consider the case of N = G = 1. Mechanism 1 reduces to f(x) = \u03b1(1 \u2212 \u03c1)(x1\u22121)1{x1 \u2265 0}. Suppose without loss of generality that the worker\u2019s beliefs for the B options are p1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 pB and suppose m = arg maxz ( p(z)\u2211z i=1 p(i) > \u03c1 )\n. A mechanism that is incentive compatible will strictly maximize the worker\u2019s expected payment when she selects the options {1, . . . ,m}.\nSuppose a worker decides to select some ` of the B options, say options {o1, . . . , o`} \u2286 [B]. Then it is easy to see that her expected payment,\n\u03b1 \u2211\u0300 i=1 poi(1\u2212 \u03c1)`\u22121,\nis maximized when she selects options {1, . . . , `}, i.e., the ` options that are most likely to be correct. It remains to show that among all choices of ` \u2208 [B], the expected payment is maximized when the worker selects ` = m. Let $` denote the expected payment when the worker selects ` options:\n$` = \u03b1 \u2211\u0300 i=1 pi(1\u2212 \u03c1)`\u22121.\nHence for any ` \u2208 {2, . . . , B}, we have\n$`\u22121 $`\n= \u03b1 \u2211`\u22121 i=1 pi(1\u2212 \u03c1)`\u22122\n\u03b1 \u2211` i=1 pi(1\u2212 \u03c1)`\u22121 = 1 1\u2212 \u03c1\n( 1\u2212 p`\u2211`\ni=1 pi\n) .\nWe know that p`\u2211` i=1 pi < \u03c1 whenever ` > m, and p`\u2211` i=1 pi > \u03c1 when ` = m. Furthermore, since p` decreases\nwith ` and \u2211`\ni=1 pi increases with `, it must also be that p`\u2211` i=1 pi > \u03c1 for all ` < m. Thus we have $`$`\u22121 > 1\nfor all ` \u2264 m and $`$`\u22121 < 1 for all ` > m, or in other words,\n\u00b7 \u00b7 \u00b7 < $m\u22122 < $m\u22121 < $m > $m+1 > $m+2 > \u00b7 \u00b7 \u00b7 .\nIt follows that the worker will be incentivized to choose ` = m. Let us now consider the case of N = G \u2265 1. By our assumption of the independence of the beliefs of the worker across the questions, the expected payment equals\nG\u220f i=1 E [ \u03b1(1\u2212 \u03c1)(xi\u22121)1{xi \u2265 0} ] .\nSince the payments are non-negative, if each individual component in the product is maximized then the product is also necessarily maximized. Each individual component simply corresponds to the setting of N = G = 1 discussed earlier. Thus calling upon our earlier result, we get that the expected payment for the case N = G \u2265 1 is maximized when the worker acts as desired for every question.\nLet us finally consider the general case ofN \u2265 G \u2265 1. Recall from (3) that the expected payment for the general case is a cascade of two expectations: the outer expectation is with respect to the uniformly random distribution of the G gold standard questions among the N total questions, while the inner expectation is\ntaken over the worker\u2019s beliefs of the different questions conditioned on the choice of the gold standard questions and restricts attention to only these G questions. The arguments above for the case N = G prove that every individual term in the inner expectation is maximized when the worker acts as desired. The outer expectation does not affect this argument. The expected payment is thus maximized when the worker acts as desired."}, {"heading": "A.5 Proof of Theorem 5.2: Uniqueness", "text": "Without loss of generality, assume that \u03b1min = 0 since in our setting, the property of incentive compatibility is invariant to any constant shift and positive scale of the payment. We adopt the succinct notation of \u03b1 := \u03b1max\u2212\u03b1min. The proof of this theorem employs some of the tools developed in Shah and Zhou (2015). We begin with a lemma deriving a condition that must necessarily be satisfied by any incentive-compatible mechanism. Note that we are not making the coarse belief assumption and supposing that workers can have arbitrary beliefs.\nLemma A.1. Any incentive-compatible mechanism must satisfy\nf(x1, . . . , xi\u22121, xi + 1, xi+1, . . . , xG)\n= (1\u2212 \u03c1)f(x1, . . . , xi\u22121, xi, xi+1, . . . , xG) + \u03c1f(x1, . . . , xi\u22121,\u2212xi, xi+1, . . . , xG),\nfor every i \u2208 [G] and (x1, . . . , xi\u22121, xi+1, . . . , xG) \u2208 {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B}G\u22121, xi \u2208 [B \u2212 1].\nNote that the lemma does not use the no-free-lunch condition. The proof of the lemma is provided at the end of this section. Using this lemma, we now complete the proof of the theorem.\nConsider any incentive-compatible mechanism f that satisfies the no-free-lunch condition. We first show that the mechanism must necessarily make a zero payment when one more more questions in the gold standard are attempted incorrectly. To this end, observe that since f \u2265 0 and \u03c1 \u2208 (0, 1), the statement of Lemma A.1 necessitates that for every i \u2208 [G] and (x1, . . . , xi\u22121, xi+1, . . . , xG) \u2208 {\u2212(B\u22121), . . . , B}G\u22121, xi \u2208 [B \u2212 1]:\nIf f(x1, . . . , xi\u22121, xi + 1, xi+1, . . . , xG) = 0\nthen f(x1, . . . , xi\u22121, xi, xi+1, . . . , xG) = f(x1, . . . , xi\u22121,\u2212xi, xi+1, . . . , xG) = 0.\nA repeated application of this argument implies:\nIf f(x1, . . . , xi\u22121, B, xi+1, . . . , xG) = 0 then f(x1, . . . , xi\u22121, xi, xi+1, . . . , xG) = 0,\nfor all xi \u2208 {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B \u2212 1}. Now consider any evaluation (x1, . . . , xG) which has at least one incorrect answer. Suppose without loss of generality that the first question is the one answered incorrectly, i.e., x1 \u2264 \u22121. The nofree-lunch condition then makes f(x1, B, . . . , B) = 0. Applying our arguments from above we get that f(x1, x2, . . . , xG) = 0 for every value of (x2, . . . , xG) \u2208 {\u2212(B \u2212 1), . . . ,\u22121, 1, . . . , B}.\nSubstituting this necessary condition in Lemma A.1, we get that for every question i \u2208 {1, . . . , G} and every (x1, . . . , xi\u22121, xi+1, . . . , xG) \u2208 [B]G\u22121, xi \u2208 [B \u2212 1],\nf(x1, . . . , xi\u22121, xi + 1, xi+1, . . . , xG) = (1\u2212 \u03c1)f(x1, . . . , xi\u22121, xi, xi+1, . . . , xG).\nSubstituting f(1, . . . , 1) = \u03b1, we get the desired answer. We now return to complete the proof of Lemma A.1.\nProof of Lemma A.1. First consider the case ofG = N . Consider some \u03b7, \u03b3 \u2208 {0, . . . , G\u22121}with \u03b7+\u03b3 < G. Suppose i = \u03b7 + \u03b3 + 1, x1, . . . , x\u03b7 \u2208 [B \u2212 1], x\u03b7+1, . . . , x\u03b7+\u03b3 \u2208 \u2212[B \u2212 1] and x\u03b7+\u03b3+2, . . . , xN = B.\nFor every question j \u2208 [\u03b7 + \u03b3], suppose the worker\u2019s belief is \u03b4j \u2208 (0, \u03c1) for the last option and 1\u2212\u03b4j|xj | each for the first |xj | options. One can verify that since \u03b4j < \u03c1 < 1B and |xj | \u2264 B \u2212 1, it must be that 1\u2212\u03b4j |xj | > \u03b4j , and that incentive-compatibility requires incentivizing the worker to select the first |xj | options. Suppose the worker does so. Now for every question j\u2032 \u2208 {\u03b7 + \u03b3 + 2, . . . , N}, suppose the belief of the worker is uniform across all B options. The worker should be incentivized to select all B options in this case; suppose the worker does so. Finally, for question i, suppose the worker\u2019s belief is \u03b4 \u2208 (\u03c12 , 3\u03c1 2 ) for the last option and 1\u2212\u03b4|xi| each for the first |xi| options. Then the worker must be incentivized to select the first |xi| options alone if \u03b4 < \u03c1, and select the last option along with the first |xi| options if \u03b4 > \u03c1.\nDefine {rj}j\u2208[\u03b7+\u03b3] as rj = \u03b4j for j \u2208 [\u03b7], and rj = 1 \u2212 \u03b4j for j \u2208 {\u03b7 + 1, \u03b7 + \u03b3}. Let := { 1, . . . , \u03b7+\u03b3} \u2208 {\u22121, 1}\u03b7+\u03b3 . Incentive-compatibility for question i necessitates (1\u2212 \u03b4) \u2211\n\u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 , xi, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  + \u03b4\n\u2211 \u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 ,\u2212xi, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  \u03b4>\u03c1\n\u2276 \u03b4<\u03c1 \u2211 \u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 , xi + 1, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  . The left hand side of this expression is the expected payment if the worker chooses the first |xi| options for question (\u03b7 + \u03b3 + 1), while the right hand side is the expected payment if she chooses the first |xi| options as well as the last option. For any real-valued variable q, and for any real-valued constants a, b and c,\naq q<c\n\u2276 q>c b \u21d2 ac = b .\nWith q = 1\u2212 \u03b4 in this argument, we get (1\u2212 \u03c1) \u2211\n\u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 , xi, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  + \u03c1\n\u2211 \u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 ,\u2212xi, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  \u2212\n\u2211 \u2208{\u22121,1}\u03b7+\u03b3 f( 1x1, . . . , \u03b7x\u03b7, \u03b7+1x\u03b7+1, . . . , \u03b7+\u03b3x\u03b7+\u03b3 , xi + 1, B, . . . , B) \u220f j\u2208[\u03b7+\u03b3] r 1\u2212 j 2 j (1\u2212 rj) 1+ j 2  = 0. (24)\nThe left hand side of (24) represents a polynomial in (\u03b7 + \u03b3) variables {rj}\u03b7+\u03b3j=1 which evaluates to zero for all values of the variables within an (\u03b7+ \u03b3)-dimensional solid ball. Thus, the coefficients of the monomials in this polynomial must be zero. In particular, the constant term must be zero. The constant term appears when j = 1 \u2200 j in the summations in (24). Setting the constant term to zero gives\n(1\u2212 \u03c1)f(x1, . . . , x\u03b7+\u03b3 , x\u03b7+\u03b3+1, B, . . . , B) + \u03c1f(x1, . . . , x\u03b7+\u03b3 ,\u2212x\u03b7+\u03b3+1, B, . . . , B) \u2212 f(x1, . . . , x\u03b7+\u03b3 , x\u03b7+\u03b3+1 + 1, B, . . . , B) = 0\nas desired. Since the arguments above hold for any permutation of theN questions, this completes the proof for the case of G = N .\nNow consider the case G < N . Let g : {\u2212(B \u2212 1), . . . ,\u22121, 1, \u00b7 \u00b7 \u00b7 , B}N \u2192 R+ represent the expected payment given an evaluation of all the N answers, when the identities of the gold standard questions are unknown. Here, the expectation is with respect to the (uniformly random) choice of the G gold standard questions. If (x1, . . . , xN ) \u2208 {\u2212(B \u2212 1), . . . ,\u22121, 1, \u00b7 \u00b7 \u00b7 , B}N are the evaluations of the worker\u2019s answers to the N questions then the expected payment is\ng(x1, . . . , xN ) = 1( N G ) \u2211 (i1,...,iG)\u2286{1,...,N} f(xi1 , . . . , xiG). (25)\nApplying the same arguments to g as done to f above, gives\n(1\u2212 \u03c1)g(x1, . . . , x\u03b7+\u03b3 , x\u03b7+\u03b3+1, B, . . . , B) + \u03c1g(x1, . . . , x\u03b7+\u03b3 ,\u2212x\u03b7+\u03b3+1, B, . . . , B) \u2212 g(x1, . . . , x\u03b7+\u03b3 , x\u03b7+\u03b3+1 + 1, B, . . . , B) = 0. (26)\nThe proof now proceeds via an induction on the quantity (G \u2212 \u03b7 \u2212 \u03b3 \u2212 1). We begin with the case of (G\u2212 \u03b7 \u2212 \u03b3 \u2212 1) = G\u2212 1 which implies \u03b7 = \u03b3 = 0. In this case (24) simplifies to\n(1\u2212 \u03c1)g(x1, B, . . . , B) + \u03c1g(\u2212x1, B, . . . , B) = g(x1 + 1, B, . . . , B).\nApplying the expansion of function g in terms of function f from (25) for some x1 \u2208 [B \u2212 1] gives\n(1\u2212 \u03c1) (c1f(x1, B, . . . , B) + c2f(B,B, . . . , B)) + \u03c1 (c1f(\u2212x1, B, . . . , B) + c2f(B,B, . . . , B)) = c1f(x1 + 1, B, . . . , B) + c2f(B,B, . . . , B)\nfor constants c1 > 0 and c2 > 0 that respectively represent the probabilities that the first question is picked and not picked in the set of G gold standard questions. Cancelling out the common terms on both sides of the equation, we get the desired result\n(1\u2212 \u03c1)f(x1, B, . . . , B) + \u03c1f(\u2212x1, B, . . . , B) = f(x1 + 1, B, . . . , B).\nNext, we consider the case when (G \u2212 \u03b7 \u2212 \u03b3 \u2212 1) questions are skipped in the gold standard, and assume that the result is true when more than (G\u2212\u03b7\u2212\u03b3\u22121) questions are skipped in the gold standard. In (26), the functions g decompose into a sum of the constituent f functions. These constituent functions f are of two types: the first where all of the first (\u03b7 + \u03b3 + 1) questions are included in the gold standard, and the second where one or more of the first (\u03b7 + \u03b3 + 1) questions are not included in the gold standard. The second case corresponds to situations where there are more than (G\u2212 \u03b7\u2212 \u03b3 \u2212 1) questions skipped in the gold standard and hence satisfies our induction hypothesis. The terms corresponding to these functions thus cancel out in the expansion of (26). The remainder comprises only evaluations of function f for arguments in which the first (\u03b7 + \u03b3 + 1) questions are included in the gold standard. Since the last (N \u2212 \u03b7 \u2212 \u03b3 \u2212 1) questions are skipped by the worker, the remainder evaluates to\n(1\u2212 \u03c1)c3f(x1, . . . , x\u03b7+\u03b3 , xi, B, . . . , B) + \u03c1c3f(x1, . . . , x\u03b7+\u03b3 ,\u2212xi, B, . . . , B) = c3f(x1, . . . , x\u03b7+\u03b3 , xi + 1, B, . . . , B) (27)\nfor some constant c3 > 0. Dividing throughout by c3 gives the desired result. Finally, the arguments above hold for any permutation of the first G questions, thus completing the proof.\nA.6 Proof of Theorem 8.1: Mechanism under alternative formulation\nWithout loss of generality, assume that a = 0 and b = 1 since in our setting, the property of incentive compatibility is invariant to any constant shift and positive scale of the payment.\nFirst consider the case of N = G = 1. Suppose without loss of generality that the worker\u2019s beliefs for the B options are p1, . . . , pB . It is easy to verify that the expected payment $sup when the worker selects the options {o1, . . . , om}, for some m, equals\nB\u03c3 + B\u2211 i=1 (poi \u2212 \u03c3).\nIt follows that the payment is strictly maximized when the worker selects all options whose beliefs are greater than B, given the assumption that none of the beliefs exactly equals \u03c3.\nThe arguments above complete the proof for the case N = G = 1. The extension to N \u2265 G \u2265 1 follow in a manner identical to the analogous extension in the proof of Theorem 4.1.\nThe proof of Corollary 8.2 follows in an identical fashion.\nA.7 Proof of Theorem 8.3: Negative results under alternative formulation\nWe present the results of uniqueness and impossibility respectively. We will let f denote any incentive compatible mechanism."}, {"heading": "A.7.1 Part A: Uniqueness", "text": "Consider any m \u2208 {1, . . . , smax \u2212 1}. Consider the set of beliefs p1 = \u03c3 + \u03b4, p2 = \u00b7 \u00b7 \u00b7 = pm+1 = 1\u2212\u03c3\u2212\u03b4m and pm+2 = \u00b7 \u00b7 \u00b7 = pB = 0, for some value of \u03b4 in the neighborhood of 0. For the values of m under consideration, one can verify that \u03c3 < 1\u2212\u03c3m < 1. Consequently, there exists some value \u03b4max > 0 such that for every \u03b4 \u2208 [\u2212\u03b4max, \u03b4max] we have 0 \u2264 \u03c3 + \u03b4 \u2264 1 and \u03c3 < 1\u2212\u03c3\u2212\u03b4m \u2264 1. In order to achieve the stated goal, we would thus require to incentivize the worker to select options 1 through (m + 1) if \u03b4 > 0, and select options 2 through (m+ 1) if \u03b4 < 0. The mechanism f therefore must satisfy the pair of inequalities\nf(m+ 1) \u03b4<0 \u2276 \u03b4>0 (1\u2212 \u03c3 \u2212 \u03b4)f(m) + (\u03c3 + \u03b4)f(\u2212m).\nSince the right hand side of the expression above is linear in \u03b4 but the left hand side is a constant, we must have\nf(m+ 1) = (1\u2212 \u03c3)f(m) + \u03c3f(\u2212m) for all m \u2208 {1, . . . , smax \u2212 1}. (28)\nWe will return to this equation later. Next consider any m \u2208 {1, . . . , smax \u2212 2}. Consider the set of beliefs p1 = \u03c3 + \u03b4, p2 = \u03c3 + \u03b4, p3 = \u00b7 \u00b7 \u00b7 = pm+2 = 1\u22122\u03c3\u22122\u03b4m and pm+3 = \u00b7 \u00b7 \u00b7 = pB = 0, for some value of \u03b4 in the neighborhood of 0. For the values of m under consideration, one can verify that \u03c3 < 1\u22122\u03c3m < 1. Consequently, there exists some value \u03b4max > 0 such that for every \u03b4 \u2208 [\u2212\u03b4max, \u03b4max] we have 0 \u2264 \u03c3 + \u03b4 \u2264 1 and \u03c3 < 1\u22122\u03c3\u22122\u03b4m \u2264 1. In order to achieve the stated goal, we would thus require to incentivize the worker to select options 1 through (m+ 2) if \u03b4 > 0, and select options 3 through (m+ 2) if \u03b4 < 0. The mechanism f thus must satisfy\nf(m+ 2) \u03b4<0 \u2276 \u03b4>0 (1\u2212 2\u03c3 \u2212 2\u03b4)f(m) + (2\u03c3 + 2\u03b4)f(\u2212m).\nSince the right hand side of the expression above is linear in \u03b4 but the left hand side is a constant, we must have\nf(m+ 2) = (1\u2212 2\u03c3)f(m) + 2\u03c3f(\u2212m) for all m \u2208 {1, . . . , smax \u2212 2}. (29)\nIt follows from (28) and (29) that the values of f(m) for everym \u2208 {\u2212(smax\u22121), . . . ,\u22121, 1, . . . , smax\u2212 2} can be expressed in terms of a linear combination of f(smax) and f(smax \u2212 1). We will now prove that the same holds true for f(\u2212smax) and f(0) as well, whenever these quantities are defined.\nThe quantity f(\u2212smax) is defined only when smax < B. The reason is that when smax = B, f(\u2212smax) = f(\u2212B) corresponds to a scenario where all the options are selected and the correct option is not, which is impossible. Now consider the set of beliefs p1 = \u03c3 + \u03b4, p2 = \u00b7 \u00b7 \u00b7 = psmax = 1\u2212\u03c3\u2212\u03b4\u2212 smax\u22121 , psmax+1 = , and psmax+2 = \u00b7 \u00b7 \u00b7 = pB = 0, for some values of \u2265 0 and \u03b4 in the neighborhood of 0. From the definition of smax, one can easily verify that \u03c3 < 1\u2212\u03c3\u2212 smax\u22121 < 1 whenever smax > 1. Consequently, there exist some values \u03b4max > 0 and max \u2208 (0, \u03c3) such that for every \u03b4 \u2208 [\u2212\u03b4max, \u03b4max] and for every \u2208 [0, max], we have 0 \u2264 \u03c3 + \u03b4 \u2264 1 and when smax > 1, we also have \u03c3 < 1\u2212\u03c3\u2212\u03b4\u2212 smax\u22121 \u2264 1. In order to achieve the stated goal, we would thus require to incentivize the worker to select options 1 through smax if \u03b4 > 0, and select options 2 through smax if \u03b4 < 0. The mechanism f therefore must satisfy\n(1\u2212 )f(smax) + f(\u2212smax) \u03b4<0 \u2276 \u03b4>0 (1\u2212 \u03c3 \u2212 \u03b4 \u2212 )f(smax \u2212 1) + (\u03c3 + \u03b4 + )f(\u2212(smax \u2212 1)).\nSince the right hand side of the expression above is linear in \u03b4 but the left hand side does not depend on\u03b4, we must have\n(1\u2212 )f(smax) + f(\u2212smax) = (1\u2212 \u03c3 \u2212 )f(smax \u2212 1) + (\u03c3 + )f(\u2212(smax \u2212 1)).\nSince this equation must be true for every \u2208 [0, max], we must have\n\u2212f(smax) + f(\u2212smax) = \u2212f(smax \u2212 1) + f(\u2212(smax \u2212 1)).\nThus the term f(\u2212smax), whenever applicable, can also be written as a linear combination of f(smax) and f(smax \u2212 1).\nThe quantity f(0) is defined only when \u03c3 > 1B . The reason is that when \u03c3 \u2264 1 B , it is mathematically impossible for the beliefs for all the B options to be less than or equal to \u03c3 (recall our assumption that no belief equals exactly \u03c3). Now consider the set of beliefs p1 = \u03c3 + \u03b4, p2 = \u00b7 \u00b7 \u00b7 = pB = 1\u2212\u03c3\u2212\u03b4B\u22121 , for some value of \u03b4 in the neighborhood of 0. One can verify that in this case of \u03c3 > 1B , it must be that 0 < 1\u2212\u03c3B\u22121 < \u03c3. Consequently, there exists some value \u03b4max > 0 such that for every \u03b4 \u2208 [\u2212\u03b4max, \u03b4max], we have 0 \u2264 \u03c3 + \u03b4 \u2264 1 and 0 \u2264 1\u2212\u03c3\u2212\u03b4B\u22121 < \u03c3. In order to achieve the stated goal, we would thus require to incentivize the worker to select option 1 if \u03b4 > 0, and select no options if \u03b4 < 0. The mechanism f therefore must satisfy\n(\u03c3 + \u03b4)f(1) + (1\u2212 \u03c3 \u2212 \u03b4)f(\u22121) \u03b4<0 \u2276 \u03b4>0 f(0).\nSince the left hand side of the expression above is linear in \u03b4 but the right hand side is a constant, we must have\n\u03c3f(1) + (1\u2212 \u03c3)f(\u22121) = f(0).\nThus the term f(0), whenever applicable, can also be written as a linear combination of f(smax) and f(smax \u2212 1).\nFrom the arguments above, we get that the design of f has only two degrees of freedom. Given that our claim is only up to some shift and scale, the claim is proved."}, {"heading": "A.7.2 Part B: Impossibility", "text": "Let us first prove the result for the case of N = G = 1. The result of part A of Theorem 8.3 implies that if there exists an incentive compatible mechanism for this setting, then the mechanism must be that of Mechanism 2 up to a constant shift and positive scale. Consider a worker with the belief p1 = 1\u2212\u03c3, p2 = \u03c3 and p3 = \u00b7 \u00b7 \u00b7 pB = 0. Since \u03c3 < 12 , under an incentive compatible mechanism, the expected payment must be strictly larger if the worker selects only option 1 as compared to the expected payment when the worker selects options 1 and 2. However, one can compute that under Mechanism 2, the expected payment in the two cases is identical. It follows that under any possible incentive-compatible mechanism, the expected payment must be identical in the two following two actions of the worker (a) selecting only option 1, and (b) selecting options 1 and 2. It follows that no mechanism is incentive compatible.\nWe now move on to the general case of N \u2265 G \u2265 1. Consider a worker who knows the answers to questions 2 through N with a belief of 1 in each case. Suppose that for each of these (N \u2212 1) questions, this worker selects the respective options that she thinks are correct. We are now left with the first question. LettingX denote a random variable representing the evaluation of the worker\u2019s response to the first question, the expected payment from the worker\u2019s point of view is\nG N E[f(X, 1, . . . , 1)] + (1\u2212 G N )f(1, . . . , 1).\nThe expectation in the first term is taken with respect to the randomness in X . Defining\nf\u0303(X) := G N f(X, 1, . . . , 1) + (1\u2212 G N )f(1, . . . , 1),\nand applying the same arguments to f\u0303 as those for f for the case of N = G = 1 above gives the desired contradiction. This completes the proof."}], "references": [{"title": "Satisfaction approval voting", "author": ["Steven J Brams", "D Marc Kilgour"], "venue": "In Voting Power and Procedures,", "citeRegEx": "Brams and Kilgour.,? \\Q2014\\E", "shortCiteRegEx": "Brams and Kilgour.", "year": 2014}, {"title": "Verification of forecasts expressed in terms of probability", "author": ["Glenn W Brier"], "venue": "Monthly weather review,", "citeRegEx": "Brier.,? \\Q1950\\E", "shortCiteRegEx": "Brier.", "year": 1950}, {"title": "Approximation algorithms and mechanism design for minimax approval voting", "author": ["Ioannis Caragiannis", "Dimitris Kalaitzis", "Evangelos Markakis"], "venue": "In AAAI,", "citeRegEx": "Caragiannis et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Caragiannis et al\\.", "year": 2010}, {"title": "Elimination scoring: An empirical evaluation", "author": ["Leverne S Collet"], "venue": "Journal of Educational Measurement,", "citeRegEx": "Collet.,? \\Q1971\\E", "shortCiteRegEx": "Collet.", "year": 1971}, {"title": "On the use of objective examinations", "author": ["Clyde H Coombs"], "venue": "Educational and Psychological Measurement,", "citeRegEx": "Coombs.,? \\Q1953\\E", "shortCiteRegEx": "Coombs.", "year": 1953}, {"title": "The assessment of partial knowledge", "author": ["Clyde H Coombs", "John Edgar Milholland", "Frank Burton Womer"], "venue": "Educational and Psychological Measurement,", "citeRegEx": "Coombs et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Coombs et al\\.", "year": 1956}, {"title": "Crowdsourced judgement elicitation with endogenous proficiency", "author": ["Anirban Dasgupta", "Arpita Ghosh"], "venue": "In Proceedings of the 22nd international conference on World Wide Web,", "citeRegEx": "Dasgupta and Ghosh.,? \\Q2013\\E", "shortCiteRegEx": "Dasgupta and Ghosh.", "year": 2013}, {"title": "Maximum likelihood estimation of observer error-rates using the EM algorithm", "author": ["Alexander Philip Dawid", "Allan M Skene"], "venue": "Applied statistics,", "citeRegEx": "Dawid and Skene.,? \\Q1979\\E", "shortCiteRegEx": "Dawid and Skene.", "year": 1979}, {"title": "The repeated insertion model for rankings: Missing link between two subset choice models", "author": ["Jean-Paul Doignon", "Aleksandar Peke\u010d", "Michel Regenwetter"], "venue": null, "citeRegEx": "Doignon et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Doignon et al\\.", "year": 2004}, {"title": "A random utility model for approval voting", "author": ["J-Cl Falmagne", "Michael Regenwetter"], "venue": "Journal of Mathematical Psychology,", "citeRegEx": "Falmagne and Regenwetter.,? \\Q1996\\E", "shortCiteRegEx": "Falmagne and Regenwetter.", "year": 1996}, {"title": "Incentives to counter bias in human computation", "author": ["Boi Faltings", "Radu Jurca", "Pearl Pu", "Bao Duy Tran"], "venue": "In Second AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "Faltings et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faltings et al\\.", "year": 2014}, {"title": "A subset selection technique for scoring items on a multiple choice test", "author": ["Jean D Gibbons", "Ingram Olkin", "Milton Sobel"], "venue": null, "citeRegEx": "Gibbons et al\\.,? \\Q1979\\E", "shortCiteRegEx": "Gibbons et al\\.", "year": 1979}, {"title": "Strictly proper scoring rules, prediction, and estimation", "author": ["Tilmann Gneiting", "Adrian E Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Gneiting and Raftery.,? \\Q2007\\E", "shortCiteRegEx": "Gneiting and Raftery.", "year": 2007}, {"title": "The chance element in the multiple choice test item", "author": ["Paul Horst"], "venue": "The Journal of General Psychology,", "citeRegEx": "Horst.,? \\Q1932\\E", "shortCiteRegEx": "Horst.", "year": 1932}, {"title": "Designing incentives for online question and answer forums", "author": ["Shaili Jain", "Yiling Chen", "David C Parkes"], "venue": "In Proceedings of the 10th ACM conference on Electronic commerce,", "citeRegEx": "Jain et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2009}, {"title": "Optimal number of questionnaire response categories more may not be better", "author": ["W Paul Jones", "Scott A Loe"], "venue": "SAGE Open,", "citeRegEx": "Jones and Loe.,? \\Q2013\\E", "shortCiteRegEx": "Jones and Loe.", "year": 2013}, {"title": "Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing", "author": ["David R Karger", "Sewoong Oh", "Devavrat Shah"], "venue": null, "citeRegEx": "Karger et al\\.,? \\Q1953\\E", "shortCiteRegEx": "Karger et al\\.", "year": 1953}, {"title": "Crowdsourcing for book search evaluation: impact of HIT design on comparative system ranking", "author": ["Gabriella Kazai", "Jaap Kamps", "Marijn Koolen", "Natasa Milic-Frayling"], "venue": "In ACM SIGIR conference on Research and development in Information Retrieval,", "citeRegEx": "Kazai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kazai et al\\.", "year": 2011}, {"title": "Presidential primaries: Measuring popular choice", "author": ["John Kellett", "Kenneth Mott"], "venue": "Polity, pages 528\u2013537,", "citeRegEx": "Kellett and Mott.,? \\Q1977\\E", "shortCiteRegEx": "Kellett and Mott.", "year": 1977}, {"title": "Eliciting truthful answers to multiple-choice questions", "author": ["Nicolas Lambert", "Yoav Shoham"], "venue": "In ACM conference on Electronic commerce,", "citeRegEx": "Lambert and Shoham.,? \\Q2009\\E", "shortCiteRegEx": "Lambert and Shoham.", "year": 2009}, {"title": "Variational inference for crowdsourcing", "author": ["Qiang Liu", "Jian Peng", "Alexander T Ihler"], "venue": "In NIPS,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Aggregation theorems and the combination of probabilistic rank orders. In Probability models and statistical analyses for ranking data, pages 216\u2013240", "author": ["AAJ Marley"], "venue": null, "citeRegEx": "Marley.,? \\Q1993\\E", "shortCiteRegEx": "Marley.", "year": 1993}, {"title": "Weighted approval voting", "author": ["Jordi Mass\u00f3", "Marc Vorsatz"], "venue": "Economic Theory,", "citeRegEx": "Mass\u00f3 and Vorsatz.,? \\Q2008\\E", "shortCiteRegEx": "Mass\u00f3 and Vorsatz.", "year": 2008}, {"title": "The magical number seven, plus or minus two: some limits on our capacity for processing information", "author": ["George A Miller"], "venue": "Psychological review,", "citeRegEx": "Miller.,? \\Q1956\\E", "shortCiteRegEx": "Miller.", "year": 1956}, {"title": "Eliciting informative feedback: The peer-prediction method", "author": ["Nolan Miller", "Paul Resnick", "Richard Zeckhauser"], "venue": "Management Science,", "citeRegEx": "Miller et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2005}, {"title": "Coarse thinking and persuasion", "author": ["Sendhil Mullainathan", "Joshua Schwartzstein", "Andrei Shleifer"], "venue": "The Quarterly journal of economics,", "citeRegEx": "Mullainathan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mullainathan et al\\.", "year": 2008}, {"title": "The arthmetic of voting", "author": ["Guy Ottewell"], "venue": "In defence of variety,", "citeRegEx": "Ottewell.,? \\Q1977\\E", "shortCiteRegEx": "Ottewell.", "year": 1977}, {"title": "A Bayesian truth serum for subjective data", "author": ["Dra\u017een Prelec"], "venue": "Science, 306(5695):462\u2013466,", "citeRegEx": "Prelec.,? \\Q2004\\E", "shortCiteRegEx": "Prelec.", "year": 2004}, {"title": "Is approval voting optimal given approval votes", "author": ["Ariel D Procaccia", "Nisarg Shah"], "venue": "In NIPS,", "citeRegEx": "Procaccia and Shah.,? \\Q2015\\E", "shortCiteRegEx": "Procaccia and Shah.", "year": 2015}, {"title": "Learning from crowds", "author": ["Vikas C Raykar", "Shipeng Yu", "Linda H Zhao", "Gerardo Hermosillo Valadez", "Charles Florin", "Luca Bogoni", "Linda Moy"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Raykar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Raykar et al\\.", "year": 2010}, {"title": "Approval voting and positional voting methods: Inference, relationship, examples", "author": ["Michel Regenwetter", "Ilia Tsetlin"], "venue": "Social Choice and Welfare,", "citeRegEx": "Regenwetter and Tsetlin.,? \\Q2004\\E", "shortCiteRegEx": "Regenwetter and Tsetlin.", "year": 2004}, {"title": "Why the magic number seven plus or minus two", "author": ["Thomas L Saaty", "Mujgan S Ozdemir"], "venue": "Mathematical and Computer Modelling,", "citeRegEx": "Saaty and Ozdemir.,? \\Q2003\\E", "shortCiteRegEx": "Saaty and Ozdemir.", "year": 2003}, {"title": "Elicitation of personal probabilities and expectations", "author": ["Leonard J Savage"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Savage.,? \\Q1971\\E", "shortCiteRegEx": "Savage.", "year": 1971}, {"title": "Double or nothing: Multiplicative incentive mechanisms for crowdsourcing", "author": ["Nihar B. Shah", "Dengyong Zhou"], "venue": "In NIPS,", "citeRegEx": "Shah and Zhou.,? \\Q2015\\E", "shortCiteRegEx": "Shah and Zhou.", "year": 2015}, {"title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence", "author": ["Nihar B Shah", "Sivaraman Balakrishnan", "Joseph K Bradley", "Abhay Parekh", "Kannan Ramchandran", "Martin Wainwright"], "venue": "AIStats,", "citeRegEx": "Shah et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2015}, {"title": "Seven plus or minus two: a commentary on capacity limitations", "author": ["RM Shiffrin", "RM Nosofsky"], "venue": "Psychological review,", "citeRegEx": "Shiffrin and Nosofsky.,? \\Q1994\\E", "shortCiteRegEx": "Shiffrin and Nosofsky.", "year": 1994}, {"title": "Does coarse thinking matter for option pricing? Evidence from an experiment", "author": ["Hammad Siddiqi"], "venue": "IUP Journal of Behavioral Finance,", "citeRegEx": "Siddiqi.,? \\Q2011\\E", "shortCiteRegEx": "Siddiqi.", "year": 2011}, {"title": "How much spam can you take? An analysis of crowdsourcing results to increase accuracy", "author": ["Jeroen Vuurens", "Arjen P de Vries", "Carsten Eickhoff"], "venue": "In ACM SIGIR Workshop on Crowdsourcing for Information Retrieval,", "citeRegEx": "Vuurens et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Vuurens et al\\.", "year": 2011}, {"title": "Towards building a high-quality workforce with Mechanical Turk", "author": ["Paul Wais", "Shivaram Lingamneni", "Duncan Cook", "Jason Fennell", "Benjamin Goldenberg", "Daniel Lubarov", "David Marin", "Hari Simons"], "venue": "NIPS workshop on computational social science and the wisdom of crowds,", "citeRegEx": "Wais et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wais et al\\.", "year": 2010}, {"title": "Comparison of voting systems", "author": ["Robert J Weber"], "venue": "New Haven: Cowles Foundation Discussion paper A,", "citeRegEx": "Weber.,? \\Q1977\\E", "shortCiteRegEx": "Weber.", "year": 1977}, {"title": "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise. In Advances in neural information processing", "author": ["Jacob Whitehill", "Paul Ruvolo", "Ting-fan Wu", "Jacob Bergsma", "Javier Movellan"], "venue": null, "citeRegEx": "Whitehill et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Whitehill et al\\.", "year": 2009}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["Dengyong Zhou", "John Platt", "Sumit Basu", "Yi Mao"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}, {"title": "Approval voting behavior in Doodle polls", "author": ["James Zou", "Reshef Meir", "David Parkes"], "venue": "In The 5th Workshop on Computational Social Choice,", "citeRegEx": "Zou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 17, "context": "Unfortunately, the data obtained via crowdsourcing is typically highly erroneous (Kazai et al., 2011; Vuurens et al., 2011; Wais et al., 2010) due to the lack of expertise of workers, lack of appropriate incentives, and often the lack of an appropriate interface for the workers to express their knowledge.", "startOffset": 81, "endOffset": 142}, {"referenceID": 37, "context": "Unfortunately, the data obtained via crowdsourcing is typically highly erroneous (Kazai et al., 2011; Vuurens et al., 2011; Wais et al., 2010) due to the lack of expertise of workers, lack of appropriate incentives, and often the lack of an appropriate interface for the workers to express their knowledge.", "startOffset": 81, "endOffset": 142}, {"referenceID": 38, "context": "Unfortunately, the data obtained via crowdsourcing is typically highly erroneous (Kazai et al., 2011; Vuurens et al., 2011; Wais et al., 2010) due to the lack of expertise of workers, lack of appropriate incentives, and often the lack of an appropriate interface for the workers to express their knowledge.", "startOffset": 81, "endOffset": 142}, {"referenceID": 13, "context": "Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively.", "startOffset": 118, "endOffset": 228}, {"referenceID": 4, "context": "Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively.", "startOffset": 118, "endOffset": 228}, {"referenceID": 5, "context": "Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively.", "startOffset": 118, "endOffset": 228}, {"referenceID": 3, "context": "Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively.", "startOffset": 118, "endOffset": 228}, {"referenceID": 11, "context": "Approval voting is known to have many advantages over single-selection systems in psychology and social choice theory (Horst, 1932; Coombs, 1953; Coombs et al., 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively.", "startOffset": 118, "endOffset": 228}, {"referenceID": 3, "context": ", 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively. For instance, Coombs (1953) posits that \u201cIt seems to be a common experience of individuals taking objective tests to feel confident about eliminating some of the wrong alternatives and then guess from among the remaining ones\u201d and that \u201cIndividuals taking the test should be instructed to cross out all the alternatives which they consider wrong.", "startOffset": 8, "endOffset": 241}, {"referenceID": 3, "context": ", 1956; Collet, 1971; Brams and Fishburn, 1978; Gibbons et al., 1979): it provides workers more flexibility to express their beliefs, and utilizes the expertise of workers with partial knowledge more effectively. For instance, Coombs (1953) posits that \u201cIt seems to be a common experience of individuals taking objective tests to feel confident about eliminating some of the wrong alternatives and then guess from among the remaining ones\u201d and that \u201cIndividuals taking the test should be instructed to cross out all the alternatives which they consider wrong.\u201d Under this approval-voting interface, we will require a worker to select every option which she believes could possibly be correct. Mathematically, we formulate this problem as eliciting the support of the beliefs of workers for each question. In the setting of crowdsourcing, as compared to single-selection, selecting multiple options would allow for obtaining more information about the partial knowledge of these non-expert workers. This additional information is particularly valuable for difficult labeling questions, allowing for the identification of the sources of difficulty. Indeed, Coombs et al. (1956) conclude that under such a questionnaire, \u201cclear evidence for the existence of partial information mediating responses to multiple choice items was obtained.", "startOffset": 8, "endOffset": 1176}, {"referenceID": 26, "context": "Related literature Approval voting (Ottewell, 1977; Kellett and Mott, 1977; Weber, 1977; Brams and Fishburn, 1978) is a form of voting in which each voter can \u201capprove of\u201d (that is, select) multiple candidates.", "startOffset": 35, "endOffset": 114}, {"referenceID": 18, "context": "Related literature Approval voting (Ottewell, 1977; Kellett and Mott, 1977; Weber, 1977; Brams and Fishburn, 1978) is a form of voting in which each voter can \u201capprove of\u201d (that is, select) multiple candidates.", "startOffset": 35, "endOffset": 114}, {"referenceID": 39, "context": "Related literature Approval voting (Ottewell, 1977; Kellett and Mott, 1977; Weber, 1977; Brams and Fishburn, 1978) is a form of voting in which each voter can \u201capprove of\u201d (that is, select) multiple candidates.", "startOffset": 35, "endOffset": 114}, {"referenceID": 14, "context": "Closer to our setting of crowdsourcing, approval voting has been studied in the context of question and answer forums (Jain et al., 2009) and Doodle polls (Zou et al.", "startOffset": 118, "endOffset": 137}, {"referenceID": 42, "context": ", 2009) and Doodle polls (Zou et al., 2014).", "startOffset": 25, "endOffset": 43}, {"referenceID": 1, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future.", "startOffset": 31, "endOffset": 112}, {"referenceID": 32, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future.", "startOffset": 31, "endOffset": 112}, {"referenceID": 12, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future.", "startOffset": 31, "endOffset": 112}, {"referenceID": 19, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future.", "startOffset": 31, "endOffset": 112}, {"referenceID": 27, "context": "There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions.", "startOffset": 39, "endOffset": 144}, {"referenceID": 24, "context": "There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions.", "startOffset": 39, "endOffset": 144}, {"referenceID": 10, "context": "There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions.", "startOffset": 39, "endOffset": 144}, {"referenceID": 24, "context": "There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions.", "startOffset": 39, "endOffset": 144}, {"referenceID": 6, "context": "There is a parallel line of literature (Prelec, 2004; Miller et al., 2005; Faltings et al., 2014; Miller et al., 2005; Dasgupta and Ghosh, 2013) that explores the design of mechanisms that operate in the absence of any gold standard questions.", "startOffset": 39, "endOffset": 144}, {"referenceID": 1, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future. The payment is a function of the agent\u2019s response and the outcome of the event. The payment is called \u201cstrictly proper\u201d if its expectation, with respect to the belief of the agent about the event, is strictly maximized when the agent reports her true belief. Proper scoring rules however provide a very broad class of mechanisms, and do not specify any particular mechanism for use. The mechanism proposed in the present paper may alternatively be viewed as the \u201coptimal\u201d proper scoring rules for eliciting supports of workers\u2019 beliefs across multiple questions. Shah and Zhou (2015) consider a crowdsourcing setup with the traditional single-selection setting, also eliciting the workers\u2019 confidences for each response.", "startOffset": 32, "endOffset": 830}, {"referenceID": 1, "context": "The framework of scoring rules (Brier, 1950; Savage, 1971; Gneiting and Raftery, 2007; Lambert and Shoham, 2009) considers the design of payment mechanisms to elicit predictions about an event whose actual outcome will be observed in the future. The payment is a function of the agent\u2019s response and the outcome of the event. The payment is called \u201cstrictly proper\u201d if its expectation, with respect to the belief of the agent about the event, is strictly maximized when the agent reports her true belief. Proper scoring rules however provide a very broad class of mechanisms, and do not specify any particular mechanism for use. The mechanism proposed in the present paper may alternatively be viewed as the \u201coptimal\u201d proper scoring rules for eliciting supports of workers\u2019 beliefs across multiple questions. Shah and Zhou (2015) consider a crowdsourcing setup with the traditional single-selection setting, also eliciting the workers\u2019 confidences for each response. They propose a mechanism to suitably incentivize workers and show that their proposed mechanism is shown to be the only one satisfying a proposed \u201cno-freelunch\u201d axiom. While the setting of our work is different from that of Shah and Zhou (2015), interestingly, our mechanism that was derived for a different interface and under a different set of assumptions, turns out to be the only mechanism that can satisfy the no-free-lunch axiom (adapted to our setting).", "startOffset": 32, "endOffset": 1212}, {"referenceID": 11, "context": "We assume that these belief-distributions of a worker are independent across questions (Gibbons et al., 1979).", "startOffset": 87, "endOffset": 109}, {"referenceID": 23, "context": "For instance, Miller\u2019s celebrated paper (Miller, 1956) establishes the information and storage capacity of humans, that an average human being can typically distinguish at most about seven states.", "startOffset": 40, "endOffset": 54}, {"referenceID": 35, "context": "This granualrity of human computation is verified in many subsequent experiments (Shiffrin and Nosofsky, 1994; Saaty and Ozdemir, 2003).", "startOffset": 81, "endOffset": 135}, {"referenceID": 31, "context": "This granualrity of human computation is verified in many subsequent experiments (Shiffrin and Nosofsky, 1994; Saaty and Ozdemir, 2003).", "startOffset": 81, "endOffset": 135}, {"referenceID": 15, "context": "Jones and Loe (2013) establish the ineffectiveness of finer-granularity response elicitation.", "startOffset": 0, "endOffset": 21}, {"referenceID": 15, "context": "Jones and Loe (2013) establish the ineffectiveness of finer-granularity response elicitation. Mullainathan et al. (2008) hypothesize that humans often group things into categories; this hypothesis is experimentally verified by Siddiqi (2011) in a specific setting.", "startOffset": 0, "endOffset": 121}, {"referenceID": 15, "context": "Jones and Loe (2013) establish the ineffectiveness of finer-granularity response elicitation. Mullainathan et al. (2008) hypothesize that humans often group things into categories; this hypothesis is experimentally verified by Siddiqi (2011) in a specific setting.", "startOffset": 0, "endOffset": 242}, {"referenceID": 33, "context": "The derivation involves a \u201cno-free-lunch axiom\u201d of Shah and Zhou (2015), which when adapted to our approval-voting based setting is defined as follows.", "startOffset": 51, "endOffset": 72}, {"referenceID": 33, "context": "The derivation involves a \u201cno-free-lunch axiom\u201d of Shah and Zhou (2015), which when adapted to our approval-voting based setting is defined as follows. We say that a worker has \u2018attempted\u2019 a question if for that question, she doesn\u2019t select all the B options. We say that the answer to a question is wrong if the correct option does not lie in the set of selected options. Definition 4 (No-free-lunch; adapted from Shah and Zhou (2015)).", "startOffset": 51, "endOffset": 436}, {"referenceID": 33, "context": "\u2022 Skip-based single-selection interface with multiplicative payments (Shah and Zhou, 2015): For every question, the worker can either select one option or skip the question.", "startOffset": 69, "endOffset": 90}, {"referenceID": 33, "context": "The cases of B = 2 or \u03c3 \u2265 12 degenerate to the \u201cskip-based\u201d single-selection setting studied in Shah and Zhou (2015). Hence we focus on the case of B \u2265 3 and \u03c3 \u2208 (0, 12) in the rest of this section.", "startOffset": 96, "endOffset": 117}, {"referenceID": 7, "context": "For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012).", "startOffset": 164, "endOffset": 290}, {"referenceID": 40, "context": "For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012).", "startOffset": 164, "endOffset": 290}, {"referenceID": 29, "context": "For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012).", "startOffset": 164, "endOffset": 290}, {"referenceID": 20, "context": "For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012).", "startOffset": 164, "endOffset": 290}, {"referenceID": 41, "context": "For the traditional single-selection setting, there is a long, existing line of work on statistical methods to aggregate redundant noisy data from multiple workers (Dawid and Skene, 1979; Whitehill et al., 2009; Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Zhou et al., 2012).", "startOffset": 164, "endOffset": 290}, {"referenceID": 22, "context": "There is indeed work on aggregation algorithms (Mass\u00f3 and Vorsatz, 2008; Caragiannis et al., 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al.", "startOffset": 47, "endOffset": 149}, {"referenceID": 2, "context": "There is indeed work on aggregation algorithms (Mass\u00f3 and Vorsatz, 2008; Caragiannis et al., 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al.", "startOffset": 47, "endOffset": 149}, {"referenceID": 0, "context": "There is indeed work on aggregation algorithms (Mass\u00f3 and Vorsatz, 2008; Caragiannis et al., 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al.", "startOffset": 47, "endOffset": 149}, {"referenceID": 28, "context": "There is indeed work on aggregation algorithms (Mass\u00f3 and Vorsatz, 2008; Caragiannis et al., 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al.", "startOffset": 47, "endOffset": 149}, {"referenceID": 21, "context": ", 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing.", "startOffset": 84, "endOffset": 183}, {"referenceID": 9, "context": ", 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing.", "startOffset": 84, "endOffset": 183}, {"referenceID": 8, "context": ", 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing.", "startOffset": 84, "endOffset": 183}, {"referenceID": 30, "context": ", 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing.", "startOffset": 84, "endOffset": 183}, {"referenceID": 0, "context": ", 2010; Brams and Kilgour, 2014; Procaccia and Shah, 2015) and probabilistic models (Marley, 1993; Falmagne and Regenwetter, 1996; Doignon et al., 2004; Regenwetter and Tsetlin, 2004) for approval-voting in the context of social choice theory; their objective, however, is primarily of fairness and stretgyproofing of the voting procedure, as opposed to our goal of denoising data obtained from multiple heterogeneous workers as required for labeling tasks in crowdsourcing. Choosing the right interface. There are tradeoffs between various interfaces for crowdsourcing. For instance, the approval voting interface elicits the support of the belief whereas the single selection interface elicits the mode. Choosing among these two interfaces would depend on the application under consideration, and moreover, one may adaptively switch between the two depending on the data obtained. A natural question that one may further ask is, why not elicit the entire belief distribution itself? While the entire belief distribution seems to supercede the support and the mode, stating the distribution will also require much more time and effort from the workers, and often also suffer from a higher noise. These tradeoffs must be taken into account when choosing the interface for the application at hand. The coarse beliefs parameter. One may wish to evaluate the value of \u03c1 by explicitly asking workers on the crowdsourcing platform for this value. However, it is noted in the literature (e.g., see Shah et al. (2015) for experiments on Amazon Mechanical Turk) that the cardinal representations that humans provide are not always consistent with their respective mental beliefs, and are far noisier.", "startOffset": 8, "endOffset": 1511}], "year": 2015, "abstractText": "The growing need for labeled training data has made crowdsourcing an important part of machine learning. The quality of crowdsourced labels is, however, adversely affected by three factors: (1) the workers are not experts; (2) the incentives of the workers are not aligned with those of the requesters; and (3) the interface does not allow workers to convey their knowledge accurately, by forcing them to make a single choice among a set of options. In this paper, we address these issues by introducing approval voting to utilize the expertise of workers who have partial knowledge of the true answer, and coupling it with a (\u201cstrictly proper\u201d) incentive-compatible compensation mechanism. We show rigorous theoretical guarantees of optimality of our mechanism together with a simple axiomatic characterization. We also conduct preliminary empirical studies on Amazon Mechanical Turk which validate our approach.", "creator": "LaTeX with hyperref package"}}}