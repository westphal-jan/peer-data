{"id": "1503.06450", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2015", "title": "Multilingual Open Relation Extraction Using Cross-lingual Projection", "abstract": "open domain relation extraction systems identify relation and binary argument phrases in a sentence without relying on any underlying schema. however, current state - of - the - art relation extraction systems are available only for english because of growing their heavy reliance on linguistic tools such as part - of - speech taggers websites and dependency parsers. we present a cross - lingual annotation projection method for language independent relation resource extraction. we evaluate our method on a manually annotated test set and present results on three typologically different xml languages. we later release these manual annotations and enable extracted relations procedures in ten original languages from red wikipedia.", "histories": [["v1", "Sun, 22 Mar 2015 18:05:08 GMT  (83kb,D)", "https://arxiv.org/abs/1503.06450v1", "Proceedings of NAACL 2015"], ["v2", "Fri, 5 Jun 2015 19:05:14 GMT  (46kb,D)", "http://arxiv.org/abs/1503.06450v2", "Proceedings of NAACL 2015"]], "COMMENTS": "Proceedings of NAACL 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["manaal faruqui", "shankar kumar"], "accepted": true, "id": "1503.06450"}, "pdf": {"name": "1503.06450.pdf", "metadata": {"source": "CRF", "title": "Multilingual Open Relation Extraction Using Cross-lingual Projection", "authors": ["Manaal Faruqui", "Shankar Kumar"], "emails": ["mfaruqui@cs.cmu.edu", "shankarkumar@google.com"], "sections": [{"heading": "1 Introduction", "text": "Relation extraction (RE) is the task of assigning a semantic relationship between a pair of arguments. The two major types of RE are closed domain and open domain RE. While closed-domain RE systems (Bunescu and Mooney, 2005; Bunescu, 2007; Mintz et al., 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al., 2007; Carlson et al., 2010; Fader et al., 2011; Mausam et al., 2012) use an arbitrary phrase to specify a relationship. In this paper, we focus on open-domain RE for multiple languages. Although there are advantages to closed domain RE (Banko and Etzioni, 2008), it is expensive to construct a closed set of relation types which would be meaningful across multiple languages.\nOpen RE systems extract patterns from sentences in a given language to identify relations. For learn-\ning these patterns, the sentences are analyzed using a part of speech tagger, a dependency parser and possibly a named-entity recognizer. In languages other than English, these tools are either unavailable or not accurate enough to be used. In comparison, it is easier to obtain parallel bilingual corpora which can be used to build machine translation systems (Resnik and Smith, 2003; Smith et al., 2013).\nIn this paper, we present a system that performs RE on a sentence in a source language by first translating the sentence to English, performing RE in English, and finally projecting the relation phrase back to the source language sentence. Our system assumes the availability of a machine translation system from a source language to English and an open RE system in English but no any other analysis tool in the source language. The main contributions of this work are:\n\u2022 A pipeline to develop relation extraction system for any source language.\n\u2022 Extracted open relations in 61 languages based on Wikipedia corpus.\n\u2022 Manual judgements for the projected relations in three languages.\nWe first describe our methodology for language independent cross-lingual projection of extracted relations (\u00a72) followed by the relation annotation procedure and the results (\u00a73). The manually annotated relations in 3 languages and the automatically extracted relations in 61 languages are available at: http://cs.cmu.edu/\u02dcmfaruqui/ soft.html.\nar X\niv :1\n50 3.\n06 45\n0v 2\n[ cs\n.C L\n] 5\nJ un\n2 01"}, {"heading": "2 Multilingual Relation Extraction", "text": "Our method of RE for a sentence s = \u3008s1, s2, . . . sN \u3009 in a non-English language consists of three steps: (1) Translation of s into English, that generates a sentence t = \u3008t1, t2, . . . tM \u3009 with word alignments a relative to s, (2) Open RE on t, and (3) Relation projection from t to s. Figure 1 shows an example of RE in Spanish using our proposed pipeline.1 We employ OLLIE2 (Mausam et al., 2012) for RE in English and GOOGLE TRANSLATE3 API for translation from the source language to English, although in principle, we could use any translation system to translate the language to English. We next describe each of these components."}, {"heading": "2.1 Relation Extraction in English", "text": "Suppose t = \u3008t1, t2, . . . , tM \u3009 is a tokenized English sentence. Open relation extraction computes triples of non-overlapping phrases (arg1; rel; arg2) from the sentence t. The two arguments arg1 and arg2 are connected by the relation phrase rel.\nWe utilized OLLIE (Mausam et al., 2012) to extract the relation tuples for every English sentence. We chose OLLIE because it has been shown to give a higher yield at comparable precision relative to other open RE systems such as REVERB and WOEparse (Mausam et al., 2012). OLLIE was trained by extracting dependency path patterns on annotated training data. This training data was bootstrapped from a set of high precision seed tuples extracted from a simpler RE system REVERB (Fader\n1This is a sample sentence and is not taken from Wikipedia. 2http://knowitall.github.io/ollie/ 3https://developers.google.com/\ntranslate/\nData: s, t, a, pt Result: ps P \u2190 PhraseExtract(s, t, a) ps = \u2205, score = \u2212\u221e, overlap = 0 for (phrs, phrt) \u2208 P do\nif BLEU(phrt, pt) > score then if phrt \u2229 pt 6= \u2205 then\npt \u2190 phrt score\u2190 BLEU(phrt, pt) overlap\u2190 phrt \u2229 pt\nif overlap 6= 0 then length =\u221e for (phrs, pt) \u2208 P do\nif len(phrs) < length then length\u2190 len(phrs) ps \u2190 phrs;\nelse ps \u2190WordAlignmentProj(s, t, a, pt);\nAlgorithm 1: Cross-lingual projection of phrase pt from a target sentence t to a source sentence s using word alignments a and parallel phrases P .\net al., 2011). In Godse killed Gandhi, the extracted relation (Godse; killed; Gandhi) can be expressed by the dependency pattern: arg1 \u2191 nsubj \u2191 rel:postag=VBD \u2193 dobj \u2193 arg2.4 OLLIE also normalizes the relation phrase for some of the phrases, for example is president of is normalized to be president of. 5"}, {"heading": "2.2 Cross-lingual Relation Projection", "text": "We next describe an algorithm to project the extracted relation tuples in English back to the source language sentence. Given a source sentence, the GOOGLE TRANSLATE API provides us its translation along with the word-to-word alignments relative to the source. If s = sN1 and t = tM1 denote the source and its English translation, then the alignment a = {aij : 1 \u2264 i \u2264 N ; 1 \u2264 j \u2264 M} where,\n4Example borrowed from Mausam et al. (2012) 5For sentences where the veracity of a relation depends on a clause, OLLIE also outputs the clause. For example, in Early astronomers believed that Earth is the center of the universe, the relation (Earth; be center of; universe) is supplemented by an (AttributedTo: believe; Early astronomers) clause. We ignore this clausal information.\naij = 1 if si is aligned to tj , and is 0 otherwise. A naive word-alignment based projection would map every word from a phrase extracted in English to the source sentence. This algorithm has two drawbacks: first, since the word alignments are many-to-many, each English word can be possibly mapped to more than one source word which leads to ambiguity in its projection; second, a word level mapping can produce non-contiguous phrases in the source sentence, which are hard to interpret semantically.\nTo tackle these problems, we introduce a novel algorithm that incorporates a BLEU score (Papineni et al., 2002) based phrase similarity metric to perform cross-lingual projection of relations. Given a source sentence, its translation, and the wordto-word alignment, we first extract phrase-pairs P using the phrase-extract algorithm (Och and Ney, 2004). In each extracted phrase pair (phrs, phrt) \u2208 P , phrs and phrt are contiguous word sequences in s and t respectively. We next determine the translations of arg1, rel and arg2 from the extracted phrase-pairs.\nFor each English phrase p \u2208 {arg1, rel, arg2}, we first obtain the phrase-pair (phrs, phrt) \u2208 P such that phrt has the highest BLEU score relative to p subject to the condition that p \u2229 phrt 6= \u2205 i.e, there is at least one word overlap between the two phrases. This condition is necessary since we use BLEU score with smoothing and may obtain a nonzero BLEU score even with zero word overlap. If there are multiple phrase-pairs in P that correspond to the same target phrase phrt, we select the shortest source phrase (phrs). However, if there is no word overlap between the target phrase p and any of the target phrases in P , we project the phrase using the word-alignment based projection. The cross-lingual projection method is presented in Algorithm 1."}, {"heading": "3 Experiments", "text": "Evaluation for open relations is a difficult task with no standard evaluation datasets. We first describe the construction of our multilingual relation extraction dataset and then present the experiments.\nAnnotation. The current approach to evaluation for open relations (Fader et al., 2011; Mausam et al., 2012) is to extract relations from a sentence and manually annotate each relation as either valid\n(1) or invalid (0) for the sentence. For example, in the sentence: \u201cMichelle Obama, wife of Barack Obama was born in Chicago\u201d, the following are possible annotations: a) (Michelle Obama; born in; Chicago): 1, b) (Barack Obama; born in; Chicago): 0. Such binary annotations are not available for languages apart from English. Furthermore, a binary 1/0 label is a coarse annotation that could unfairly penalize an extracted relation which has the correct semantics but is slightly ungrammatical. This could occur either when prepositions are dropped from the relation phrase or when there is an ambiguity in the boundary of the relation phrase.\nTherefore to evaluate our multilingual relation extraction framework, we obtained annotations from professional linguists for three typologically different languages: French, Hindi, and Russian. The annotation task is as follows: Given a sentence and a pair of arguments (extracted automatically from the sentence), the annotator identifies the most relevant contiguous relation phrase from the sentence that establishes a plausible connection between the two arguments. If there is no meaningful contiguous relation phrase between the two arguments, the arguments are considered invalid and hence, the extracted relation tuple from the sentence is considered incorrect.\nGiven the human annotated relation phrase and the automatically extracted relation phrase, we can measure the similarity between the two, thus alleviating the problem of coarse annotation in binary judgments. For evaluation, we first report the percentage of valid arguments. Then for sentences with valid arguments, we use smoothed sentence-level BLEU score (max n-gram order = 3) to measure the similarity of the automatically extracted relation relative to the human annotated relation.6\nResults. We extracted relations from the entire Wikipedia7 corpus in Russian, French and Hindi from all sentences whose lengths are in the range of 10 \u2212 30 words. We randomly selected 1, 000 relations for each of these languages and annotated them. The results are shown in table 1. The percent-\n6We obtained two annotations for \u2248 300 Russian sentences. Between the two annotations, the perfect agreement rate was 74.5% and the average BLEU score was 0.85.\n7www.wikipedia.org\nage of valid extractions is highest in French (81.6%) followed by Hindi and Russian (64.0%). Surprisingly, Russian obtains the lowest percentage of valid relations but has the highest BLEU score between the automatic and the human extracted relations. This could be attributed to the fact that the average relation length (in number of words) is the shortest for Russian. From table 1, we observe that the length of the relation phrase is inversely correlated with the BLEU score.\nFigure 2 shows the distribution of the number of extracted relations across bins of similar BLEU scores. Interestingly, the highest BLEU score bin\n(1) contains the maximum number of relations in all three languages. This is an encouraging result since it implies that the majority of the extracted relation phrases are identical to the manually annotated relations. Table 2 lists the sizes of automatically extracted relations on 61 different languages from Wikipedia that we are going to make publicly available. These were selected to include a mixture of high-resource, low-resource, and typologically different languages. Table 3 shows examples of randomly selected relations in different languages along with their English translations."}, {"heading": "4 Related Work", "text": "Cross-lingual projection has been used for transfer of syntactic (Yarowsky and Ngai, 2001; Hwa et al., 2005) and semantic information (Riloff et al., 2002; Pado\u0301 and Lapata, 2009). There has been a growing interest in RE for languages other than English. Gamallo et al. (2012) present a dependency-parser based open RE system for Spanish, Portuguese and Galician. RE systems for Korean have been developed for both open-domain (Kim et al., 2011) and closed-domain (Kim and Lee, 2012; Kim et al., 2014) using annotation projection. These approaches use a Korean-English parallel corpus to project relations extracted in English to Korean. Following projection, a Korean POS-tagger and a dependency parser are employed to learn a RE system\nfor Korean. Tseng et al. (2014) describe an open RE for Chinese that employs word segmentation, POS-tagging, dependency parsing. Lewis and Steedman (2013) learn clusters of semantically equivalent relations across French and English by creating a semantic signature of relations by entity-typing. These relations are extracted using CCG parsing in English and dependency parsing in French. Blessing and Schu\u0308tze (2012) use inter-wiki links to map relations from a relation database in a pivot language to the target language and use these instances for learning in a distant supervision setting. Gerber and Ngomo (2012) describe a multilingual pattern extraction system for RDF predicates that uses preexisting knowledge bases for different languages."}, {"heading": "5 Conclusion", "text": "We have presented a language independent open domain relation extraction pipeline and have evaluated its performance on three typologically different languages: French, Hindi and Russian. Our cross-lingual projection method utilizes OLLIE and GOOGLE TRANSLATE to extract relations in the language of interest. Our approach does not rely on the availability of linguistic resources such as POS-taggers or dependency parsers in the target language and can thus be extended to multiple languages supported by a machine translation system. We are releasing the manually annotated judgements for open relations in the three languages and the open relations extracted over the entire Wikipedia corpus in 61 languages. The resources are available at: http://cs.cmu.edu/\u02dcmfaruqui/ soft.html."}, {"heading": "Acknowledgment", "text": "This work was performed when the first author was an intern at Google. We thank Richard Sproat for providing comments on an earlier draft of this paper. We thank Hao Zhang for helping us with the relation extraction framework, and Richard Zens and Kishore Papineni for their feedback on this work. We are grateful to Bruno Cartoni, Vitaly Nikolaev and their teams for providing us annotations of multilingual relations."}], "references": [{"title": "The tradeoffs between open and traditional relation extraction", "author": ["Banko", "Etzioni2008] Michele Banko", "Oren Etzioni"], "venue": "In Proceedings of ACL", "citeRegEx": "Banko et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2008}, {"title": "Semantic parsing via paraphrasing", "author": ["Berant", "Liang2014] J. Berant", "P. Liang"], "venue": "In Proceedings of ACL", "citeRegEx": "Berant et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "Crosslingual distant supervision for extracting relations of different complexity", "author": ["Blessing", "Sch\u00fctze2012] Andre Blessing", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of CIKM", "citeRegEx": "Blessing et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Blessing et al\\.", "year": 2012}, {"title": "A shortest path dependency kernel for relation extraction", "author": ["Bunescu", "Mooney2005] Razvan C. Bunescu", "Raymond J. Mooney"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Bunescu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2005}, {"title": "Learning to extract relations from the web using minimal supervision", "author": ["Razvan C. Bunescu"], "venue": "In Proceedings of ACL", "citeRegEx": "Bunescu.,? \\Q2007\\E", "shortCiteRegEx": "Bunescu.", "year": 2007}, {"title": "Toward an architecture for never-ending language learning", "author": ["Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R. Hruschka Jr.", "Tom M. Mitchell"], "venue": "Proceedings of AAAI", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Identifying relations for open information extraction", "author": ["Fader et al.2011] Anthony Fader", "Stephen Soderland", "Oren Etzioni"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Fader et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2011}, {"title": "Dependencybased open information extraction", "author": ["Marcos Garcia", "Santiago Fern\u00e1ndez-Lanza"], "venue": "In Proceedings of ROBUS-UNSUP", "citeRegEx": "Gamallo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gamallo et al\\.", "year": 2012}, {"title": "Extracting multilingual natural-language patterns for rdf predicates", "author": ["Gerber", "Ngomo2012] Daniel Gerber", "AxelCyrille Ngonga Ngomo"], "venue": "In Proceedings of the 18th International Conference on Knowledge Engineering and Knowledge", "citeRegEx": "Gerber et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gerber et al\\.", "year": 2012}, {"title": "Bootstrapping parsers via syntactic projection across parallel texts", "author": ["Hwa et al.2005] Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak"], "venue": "Natural Language Engineering,", "citeRegEx": "Hwa et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hwa et al\\.", "year": 2005}, {"title": "A graph-based cross-lingual projection approach for weakly supervised relation extraction", "author": ["Kim", "Lee2012] Seokhwan Kim", "Gary Geunbae Lee"], "venue": "In Proceedings of ACL", "citeRegEx": "Kim et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2012}, {"title": "A cross-lingual annotation projection-based selfsupervision approach for open information extraction", "author": ["Kim et al.2011] Seokhwan Kim", "Minwoo Jeong", "Jonghoon Lee", "Gary Geunbae Lee"], "venue": "Proceedings of IJCNLP", "citeRegEx": "Kim et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2011}, {"title": "Crosslingual annotation projection for weakly-supervised", "author": ["Kim et al.2014] Seokhwan Kim", "Minwoo Jeong", "Jonghoon Lee", "Gary Geunbae Lee"], "venue": null, "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Unsupervised induction of cross-lingual semantic relations", "author": ["Lewis", "Steedman2013] Mike Lewis", "Mark Steedman"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Lewis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2013}, {"title": "Open language learning for information extraction", "author": ["Mausam et al.2012] Mausam", "Michael Schmitz", "Robert Bart", "Stephen Soderland", "Oren Etzioni"], "venue": "In Proceedings of EMNLP-CoNLL", "citeRegEx": "Mausam et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mausam et al\\.", "year": 2012}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of ACL", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "The alignment template approach to statistical machine translation", "author": ["Och", "Ney2004] Franz Josef Och", "Hermann Ney"], "venue": "Comput. Linguist.,", "citeRegEx": "Och et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Och et al\\.", "year": 2004}, {"title": "Cross-lingual annotation projection of semantic roles", "author": ["Pad\u00f3", "Lapata2009] Sebastian Pad\u00f3", "Mirella Lapata"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Pad\u00f3 et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Pad\u00f3 et al\\.", "year": 2009}, {"title": "Bleu: A method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of ACL", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "The web as a parallel corpus", "author": ["Resnik", "Smith2003] Philip Resnik", "Noah A. Smith"], "venue": null, "citeRegEx": "Resnik et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Resnik et al\\.", "year": 2003}, {"title": "Inducing information extraction systems for new languages via cross-language projection", "author": ["Riloff et al.2002] Ellen Riloff", "Charles Schafer", "David Yarowsky"], "venue": "In Proceedings of COLING", "citeRegEx": "Riloff et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2002}, {"title": "Dirt cheap web-scale parallel text from the common crawl", "author": ["Smith et al.2013] Jason R. Smith", "Herve Saint-Amand", "Magdalena Plamada", "Philipp Koehn", "Chris CallisonBurch", "Adam Lopez"], "venue": "Proceedings of ACL", "citeRegEx": "Smith et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Smith et al\\.", "year": 2013}, {"title": "Chinese open relation extraction for knowledge acquisition", "author": ["Lung-Hao Lee", "Shu-Yen Lin", "Bo-Shun Liao", "Mei-Jun Liu", "Hsin-Hsi Chen", "Oren Etzioni", "Anthony Fader"], "venue": "Proceedings of EACL", "citeRegEx": "Tseng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tseng et al\\.", "year": 2014}, {"title": "Information extraction over structured data: Question answering with freebase", "author": ["Yao", "Van Durme2014] Xuchen Yao", "Benjamin Van Durme"], "venue": "In Proceedings of ACL", "citeRegEx": "Yao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2014}, {"title": "Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora", "author": ["Yarowsky", "Ngai2001] David Yarowsky", "Grace Ngai"], "venue": "In Proceedings of NAACL", "citeRegEx": "Yarowsky et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Yarowsky et al\\.", "year": 2001}, {"title": "Textrunner: Open information extraction on the web", "author": ["Stephen Soderland"], "venue": "In Proceedings of NAACL: Demonstrations", "citeRegEx": "Soderland.,? \\Q2007\\E", "shortCiteRegEx": "Soderland.", "year": 2007}], "referenceMentions": [{"referenceID": 4, "context": "While closed-domain RE systems (Bunescu and Mooney, 2005; Bunescu, 2007; Mintz et al., 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al.", "startOffset": 31, "endOffset": 141}, {"referenceID": 15, "context": "While closed-domain RE systems (Bunescu and Mooney, 2005; Bunescu, 2007; Mintz et al., 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al.", "startOffset": 31, "endOffset": 141}, {"referenceID": 5, "context": ", 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al., 2007; Carlson et al., 2010; Fader et al., 2011; Mausam et al., 2012) use an arbitrary phrase to specify a relationship.", "startOffset": 144, "endOffset": 227}, {"referenceID": 6, "context": ", 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al., 2007; Carlson et al., 2010; Fader et al., 2011; Mausam et al., 2012) use an arbitrary phrase to specify a relationship.", "startOffset": 144, "endOffset": 227}, {"referenceID": 14, "context": ", 2009; Yao and Van Durme, 2014; Berant and Liang, 2014) consider only a closed set of relationships between two arguments, open domain systems (Yates et al., 2007; Carlson et al., 2010; Fader et al., 2011; Mausam et al., 2012) use an arbitrary phrase to specify a relationship.", "startOffset": 144, "endOffset": 227}, {"referenceID": 21, "context": "In comparison, it is easier to obtain parallel bilingual corpora which can be used to build machine translation systems (Resnik and Smith, 2003; Smith et al., 2013).", "startOffset": 120, "endOffset": 164}, {"referenceID": 14, "context": "1 We employ OLLIE2 (Mausam et al., 2012) for RE in English and GOOGLE TRANSLATE3 API for translation from the source language to English, although in principle, we could use any translation system to translate the language to English.", "startOffset": 19, "endOffset": 40}, {"referenceID": 14, "context": "We utilized OLLIE (Mausam et al., 2012) to extract the relation tuples for every English sentence.", "startOffset": 18, "endOffset": 39}, {"referenceID": 14, "context": "We chose OLLIE because it has been shown to give a higher yield at comparable precision relative to other open RE systems such as REVERB and WOEparse (Mausam et al., 2012).", "startOffset": 150, "endOffset": 171}, {"referenceID": 14, "context": "Example borrowed from Mausam et al. (2012) For sentences where the veracity of a relation depends on a clause, OLLIE also outputs the clause.", "startOffset": 22, "endOffset": 43}, {"referenceID": 18, "context": "To tackle these problems, we introduce a novel algorithm that incorporates a BLEU score (Papineni et al., 2002) based phrase similarity metric to perform cross-lingual projection of relations.", "startOffset": 88, "endOffset": 111}, {"referenceID": 6, "context": "The current approach to evaluation for open relations (Fader et al., 2011; Mausam et al., 2012) is to extract relations from a sentence and manually annotate each relation as either valid (1) or invalid (0) for the sentence.", "startOffset": 54, "endOffset": 95}, {"referenceID": 14, "context": "The current approach to evaluation for open relations (Fader et al., 2011; Mausam et al., 2012) is to extract relations from a sentence and manually annotate each relation as either valid (1) or invalid (0) for the sentence.", "startOffset": 54, "endOffset": 95}, {"referenceID": 9, "context": "Cross-lingual projection has been used for transfer of syntactic (Yarowsky and Ngai, 2001; Hwa et al., 2005) and semantic information (Riloff et al.", "startOffset": 65, "endOffset": 108}, {"referenceID": 20, "context": ", 2005) and semantic information (Riloff et al., 2002; Pad\u00f3 and Lapata, 2009).", "startOffset": 33, "endOffset": 77}, {"referenceID": 11, "context": "RE systems for Korean have been developed for both open-domain (Kim et al., 2011) and closed-domain (Kim and Lee, 2012; Kim et al.", "startOffset": 63, "endOffset": 81}, {"referenceID": 12, "context": ", 2011) and closed-domain (Kim and Lee, 2012; Kim et al., 2014) using annotation projection.", "startOffset": 26, "endOffset": 63}, {"referenceID": 7, "context": "Gamallo et al. (2012) present a dependency-parser based open RE system for Spanish, Portuguese and Galician.", "startOffset": 0, "endOffset": 22}], "year": 2015, "abstractText": "Open domain relation extraction systems identify relation and argument phrases in a sentence without relying on any underlying schema. However, current state-of-the-art relation extraction systems are available only for English because of their heavy reliance on linguistic tools such as part-of-speech taggers and dependency parsers. We present a cross-lingual annotation projection method for language independent relation extraction. We evaluate our method on a manually annotated test set and present results on three typologically different languages. We release these manual annotations and extracted relations in 61 languages from Wikipedia.", "creator": "LaTeX with hyperref package"}}}