{"id": "1503.07104", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2015", "title": "Analysis of Spectrum Occupancy Using Machine Learning Algorithms", "abstract": "in this paper, formally we analyze the spectrum occupancy using different procedural machine learning techniques. both supervised classification techniques ( naive bayesian classifier ( nbc ), decision matrix trees ( dt ), support vector machine ( svm ), linear regression ( lr ) ) and unsupervised algorithm ( hidden markov model ( hmm ) ) are studied to find the best managed technique with the highest classification access accuracy ( ca ). a detailed comparison of the supervised and continuous unsupervised algorithms in terms of the computational deployment time and classification accuracy information is performed. the supervised classified occupancy status is further utilized to evaluate the corresponding probability density of secondary user outage time for the future allocation time slots, which can be used by system designers to define spectrum allocation and spectrum sharing policies. numerical results subsequently show that svm is therefore the best algorithm among all excluding the supervised and unsupervised classifiers. based on this, we proposed a new svm algorithm by combining it with fire fly algorithm ( ffa ), which each is once shown trying to outperform all other algorithms.", "histories": [["v1", "Tue, 24 Mar 2015 16:38:32 GMT  (134kb)", "http://arxiv.org/abs/1503.07104v1", "21 pages, 6 figures"]], "COMMENTS": "21 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.NI cs.LG", "authors": ["freeha azmat", "yunfei chen", "nigel stocks"], "accepted": false, "id": "1503.07104"}, "pdf": {"name": "1503.07104.pdf", "metadata": {"source": "CRF", "title": "Analysis of Spectrum Occupancy Using Machine Learning Algorithms", "authors": ["Freeha Azmat", "Yunfei Chen"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n50 3.\n07 10\n4v 1\n[ cs\n.N I]\n2 4\nM ar\nIn this paper, we analyze the spectrum occupancy using different machine learning techniques. Both supervised techniques (naive Bayesian classifier (NBC), decision trees (DT), support vector machine (SVM), linear regression (LR)) and unsupervised algorithm (hidden markov model (HMM)) are studied to find the best technique with the highest classification accuracy (CA). A detailed comparison of the supervised and unsupervised algorithms in terms of the computational time and classification accuracy is performed. The classified occupancy status is further utilized to evaluate the probability of secondary user outage for the future time slots, which can be used by system designers to define spectrum allocation and spectrum sharing policies. Numerical results show that SVM is the best algorithm among all the supervised and unsupervised classifiers. Based on this, we proposed a new SVM algorithm by combining it with fire fly algorithm (FFA), which is shown to outperform all other algorithms.\nIndex Terms\nFire fly algorithm, hidden markov model, spectrum occupancy and support vector machine.\nMarch 25, 2015 DRAFT\n1 I. INTRODUCTION\nA cognitive radio network (CRN) is composed of two types of users, namely, the licensed primary users (PU\u2019s) and the unlicensed secondary users (SU\u2019s). The core idea behind CR is to allow unlicensed user\u2019s access to the licensed bands in an opportunistic manner to avoid interference with the licensed users. To achieve this, a realistic understanding of the dynamic usage of the spectrum is required. The spectrum measurement is an important step towards the realistic understanding of the dynamic spectrum usage. Various spectrum measurement campaigns covering a wide range of frequencies have been performed [1]. These pectrum measurements studies have found significant amount of unused frequency bands in the case of normal usage due to the static spectrum regulations. This has led researchers to understand the spectrum occupancy characteristics in depth for exploiting the free spectrum."}, {"heading": "A. Problem definition", "text": "Many studies have been performed to understand the occupancy statistics. For instance, the statistical and spectral occupation analysis of the measurements was presented in [2] in order to study the traffic density in all frequency bands. In [3], autoregressive model was used to predict the radio resource availability using occupancy measurements in order to achieve uninterrupted data transmission of secondary users. In [4], the occupancy statistics were utilized to select the best channels for control and data transmission purposes, so that less time is required for switching transmission from one channel to the other for the case when the PU appears. Further, In [5], [6], the bandwidth efficiency was maximized by controlling the transmission power of cognitive radio using spectrum occupancy measurements.\nIn [7], different time series models were used to categorize specific occupancy patterns in the spectrum measurements. All of the aforementioned works have evaluated the spectrum occupancy models by using conventional probabilistic or statistical tools. These tools are often limited due to assumptions required to derive their theories. For example, one has to determine whether the value is random variable or a random process in order to use either probabilistic and statistical\nMarch 25, 2015 DRAFT\n2 tools. On the other hand, machine learning (ML) is a very powerful tool that has received increasing attention recently [8]. The machine learning algorithms are often heuristic, as they don\u2019t have any prerequisites or assumptions on data. As a result, in many cases, they provide higher accuracy than conventional probabilistic and statistical tools. There are very few works on the use of ML in spectrum occupancy. For example, the ML works related to CR in [9]- [13] discussed cooperative spectrum sensing and spectrum occupancy variation. However, in this paper, we aim to provide a comprehensive investigation on the use of ML for analyzing spectrum occupancy. The motivation is that different ML algorithms are often suitable for different types of data. Thus, one needs to try different ML algorithms in order to find the one that suits the spectrum data best, not just one ML algorithm."}, {"heading": "B. Contributions", "text": "The contributions are listed as follows:\n1. We propose the use of ML algorithms in spectrum occupancy study. Both supervised and unsupervised algorithms are used. The machine learning techniques are advantageous because they are capable of implicitly learning the surrounding environment and are much more adaptive compared with the traditional spectrum occupancy models. They can describe more optimized decision regions on feature space than other approaches. In [9] and [10], ML was used for cooperative spectrum sensing. However we use ML for spectrum occupancy modelling that may be used in all CR operations, including spectrum management, spectrum decision and spectrum sensing. In [11], authors have discussed call-based modelling for analyzing the spectrum usage of the dataset collected from the cellular network operator. Further, they have shown that random walk process can be used for modeling aggregate cell capacity. However, we use ML to model spectrum occupancy in time slots for all important bands. 2. We have utilized four supervised algorithms, naive Bayesian classifier (NBC), decision trees (DT), support vector machine (SVM), linear regression (LR), and one unsupervised algorithm, hidden markov model (HMM), to classify the occupancy status of time slots. The classified\nMarch 25, 2015 DRAFT\n3 occupancy status is further utilized for evaluating the probability of SU outage. In [12], HMM was used to predict the channel status. Our supervised algorithms and modified HMM all perform better than HMM. In [13], LR was used to investigate the spectrum occupancy variation in time and frequency. Our approach outperforms LR as well.\n3. We propose a new technique that combines SVM with fire fly algorithm (FFA) that\noutperforms all supervised and unsupervised algorithms.\nThe rest of the paper is organized as follows: Section II explains the system model, followed by the detailed explanation of classifiers in Section III. The numerical results and discussion are presented in Section IV."}, {"heading": "II. SYSTEM MODEL", "text": ""}, {"heading": "A. Measurement setup and data", "text": "We have measured the data from 880 MHz to 2500 MHz containing eight main radio frequency bands for approximately four months (6th Feb-18th June 2013) at the University of Warwick using radiometer. The eight bands are: 880-915 MHz, 925-960 MHz, 1900-1920 MHz, 1920-1980 MHz, 1710-1785 MHz, 1805-1880 MHz, 2110-2170 MHz and 2400-2500 MHz. The number of the frequency bins in each band varies. For example, the band 925-960 MHz contains 192 frequency bins, each occupying a bandwidth of 0.18 MHz, while the band 1710-1785 MHz contains 448 frequency bins, each occupying a bandwidth of 0.167 MHz. The data is arranged in a two dimensional matrix (ti, fj) for each band; where each row ti represents the measured data at different frequencies in one minute while each column fj represents the data at different time instants of each frequency bin. As we have measured the data for four months which constitute 131 days (188917 minutes), the numbers of rows are 188917 while the number of columns varies according to the number of the frequency bins in a particular band.\nMarch 25, 2015 DRAFT\n4"}, {"heading": "B. SU Model", "text": "In a network of licensed users, SU is allowed to access the licensed band without causing any harmful interference to the PU. Let i denote the time slot and j denote the frequency bin, where i = 1, 2, ..n, j = 1, 2, ...k, n represents the total number of time slots and k represents the total number of frequency bins. Using energy detection [14], if yi(j) is the sample sensed at the ith time slot in the jth frequency bin. One has\nyi(j) = xi(j) + wi(j) (1a)\nor yi(j) = wi(j) (1b)\nwhere xi(j) represents the received PU signal and wi(j) represents the additive white Gaussian noise (AWGN) with zero mean and variance \u03c32w. Each sample is compared with a threshold (\u03b3). The selection of \u03b3 is very important because small values of \u03b3 will cause false alarms while large values will miss spectrum opportunities. The computation of \u03b3 was explained in [15]. In our approach, the threshold is dynamic and its selection is explained in Section IV-B. The spectrum status is given as\nSi(j) =\n   \n  \n1, yi(j) > \u03b3\n0, yi(j) < \u03b3.\nThe occupancy for the ith time slot for all k frequency bins is defined as\nOC i =\n\u2211k\nj=1 S i(j)\nk (2)\nFor example, a three minutes interval for the band 880 - 890 MHz having 9 frequency bins is shown in Fig.1, where each bin occupies 1MHz. For each frequency bin, Si(j) is decided. Once Si(j) is evaluated, the occupancy OC i is calculated using (2). It is observed that more frequency bins are occupied for the first minute than for the second and third minutes so that it has less chance for SU to transmit. Following the discussion above, we need to set the criteria for quantifying this chance based on the occupancies.\nMarch 25, 2015 DRAFT\n5"}, {"heading": "C. PU Model", "text": "As per our approach, the status of PU (P i) for each ith time slot can be decided using the\nfollowing rules:\nP i =\n             \n            \n1, OC i > Uoc (Condition 1)\n1, Loc <= OC i <= Uoc AND con i < B (Condition 2)\n0, Loc <= OC i <= Uoc AND con i >= B (Condition 3)\n0, OC i < Loc (Condition 4)\nwhere Uoc and Loc represents the maximum and minimum values of occupancy for all n time slots, coni represents the number of consecutive free frequency bins in each ith time slot and B represents the maximum value of coni, when PU is considered present. Each condition is explained as follows:\n1. Condition 1 and Condition 4: The values of Uoc and Loc vary with the frequency band, the\nMarch 25, 2015 DRAFT\n6 day and the threshold. Our test show that Uoc should not be less than 75% and Loc should not be greater than 40%. For fixed frequency band and day, we have evaluated Uoc and Loc for different thresholds in Section IV-B. In order to guarantee PU protection and ensure SU transmission when the values of OC i lie in the range between Loc and Uoc, further criterion is applied.\n2. Condition 2 and Condition 3: When Loc <= OC i <= Uoc, it is difficult to apply condition 1 and condition 4. So we evaluate coni for each time slot. If coni > B for Loc <= OC i <= Uoc , there exists at least B consecutive free frequency bins in ith time slot; thus SU can transmit and vice versa when coni > B. The value of B is selected to provide PU protection. This will be explained in Section IV-B."}, {"heading": "D. Machine Learning Framework for SU and PU Model", "text": "ML constructs a classifier to map Si to P i, where Si = [Si(1), Si(2), ..Si(k)] represents the feature vector and P i is the corresponding response to the feature vector. There are two steps for constructing a classifier:\n1) Training: Let Sitrain = [S i(1)train, S i(2)train..., S i(k)train] T denote the training spectrum status and P itrain represent the training PU status for the ith time slot respectively, where i = 1, 2, ..n1 and n1 represents the number of training time slots fed into the classifier.\n2) Testing: Once the classifier is successfully trained, it is ready to receive the test vector for\nclassification. Let Sitest = [S i(1)test, S i(2)test..., S i(k)test] T denote the testing spectrum status and P itest represent the testing PU status for the ith time slot respectively, where i = n1+1, n1+2, ..n2 and n2 represents the length of testing sequence. It is assumed that n = n1+n2. For our proposed approach, the matrix of size n \u2217 k is divided into 15% training data matrix of size n1 \u2217 k and 85% testing data matrix of size n2 \u2217 k. The value P itest is not used during the testing but as a reference for computing the classification error.\n3) Classification Accuracy (CA): Let P ieval denote the PU status determined by the classifier for the ith time slot. The classifier categorizes the testing vector Sitest as \u2019occupied class\u2019 (i.e., P ieval = 1) or \u2019unoccupied class\u2019 (i.e., P i eval = 0). Therefore, the PU status is correctly determined,\nMarch 25, 2015 DRAFT\n7 when P ieval= P i test, giving CA i = 1. The misdetection occurs, when P ieval = 0 and P i test = 1 while false alarm occurs, when P ieval = 1 and P i test = 0, giving CA i = 0."}, {"heading": "E. Probability of SU outage", "text": "Let Pieval be a vector of length ((n2\u2212n1)+1) evaluated by each classifier, and P i eval represent the presence/absence of PU for the ith time slot. When P ieval = 0, SU is allowed to utilize the ith time slot. Define outsu as the minimum value of consecutive free time slots required by SU for transmission. SU outage occurs, when SU cannot find outsu consecutive free time slots in a vector Pieval of length ((n2 \u2212 n1) + 1). The probability of SU outage is given by\nP (SUoutage) = 1\u2212 P (SUtransmit) (3a)\nwhere\nP (SUtransmit) = C \u2211\nc=1\nP (FBc) (3b)\nwhere FBc represents the block of free consecutive time slots of length outsu, c = {1, 2, ..C} and C represents the total number of free blocks present in P ieval. The probability for a free block starting at index, say r in P ieval is evaluated using the following equation\nP (FBc) =\nr+outsu \u220f\ni=r\nOC i. (3c)"}, {"heading": "III. PROPOSED ALGORITHMS", "text": "In the proposed approach, five machine learning algorithms are utilized to predict the future PU status using the occupancy data, which is a function of time, frequency and threshold. Among them, four are supervised learning algorithms: NBC, DT, SVM and LR, while one is an unsupervised algorithm, HMM. The motivation to use five different algorithms is to find the best machine learning algorithm as they have different characteristics.\nMarch 25, 2015 DRAFT\n8"}, {"heading": "A. Naive Bayesian Classifier", "text": "A Naive Bayesian classifier is a generative model based on the Bayes theorem. It is also called \u2019independent feature model\u2019 because it does not take dependency of features into account. The feature vector for the ith time slot in our model contains all the samples which are independent of each other, since every feature represents a specific frequency bin. For example, the status vector of the ith time slot is given as Si = Si(1), Si(1), Si(2), .., Si(k), where Si(1) is independent from Si(2). However, the response variable in our approach i.e. PU status (P i) is a dependent variable which is affected by each frequency bin. As our features are independent, so we will use NBC for classification. The probability of Si belonging to the class P i evaluated using the Bayes theorem is formally defined as [16]\np(P i, Si) = p(P i) \u2217 p(Si|P i). (4)\nwhen P i = 0, Si will be classified as \u2019idle\u2019 class, while when P i = 1, Si will be classified as \u2019occupied\u2019 class. The goal is to find the class with the largest posterior probability in the classification phase. The classification rule is given as\nclassify(S\u0302i) = argmaxSi{p(P i, (S\u0302i)} (5)\nwhere S\u0302i = { \u02c6Si(1), \u02c6Si(2)... \u02c6Si(k)}. NBC is sensitive to the choice of kernel and the prior probability distribution of classes. This will be explained in Section IV-B."}, {"heading": "B. Decision Trees", "text": "Decision tree builds classification or regression models in the form of a tree structure. The decision trees used in this approach are classification trees whose leaf represents the class labels. Unlike NBC, it can handle feature interactions and dependencies. In DT, the decision is made on each internal node which is used as a basis for dividing the data into two subsets while leaf nodes represent the class labels (in the case of classification trees) or the real numbers (in the case of regression trees). Data come in the form\nMarch 25, 2015 DRAFT\n9 (Si, P i) = (Si(1), Si(2), Si(3).., Si(k), P i). (6)\nwhere P i is the dependent variable representing the class label of ith time slot. The class labels P i are assigned by calculating the entropy of the feature, as [17]\nEntropy(t) = \u2212 Z \u2211\nid=0\np(id|t) log2p(id|t). (7)\nWhere p(id|t) denote the fraction of records belonging to class id at a given node t and Z represents the total number of classes. In our approach, Z = 1. The smaller entropy implies that all records belong to the same class. It will be discussed in Section IV-C on how fraction of records per node affects the classification accuracy of DT."}, {"heading": "C. Support Vector Machines", "text": "SVM is a discriminative classifier with high accuracy. Unlike DT, it prevents over-fitting and can be used for online learning [18]. There are two types of classifiers in SVM: linear SVM for separable data and non-linear SVM for non-separable data. The linear classifier is used here. The training feature and response vectors can be represented as D = (P i, Si) where P i \u2208 {0, 1} . The two classes are separated by defining a random division line H represented as d.Si+b = \u03c1, where d and b represent the weighting vector and bias, respectively, while \u03c1 represents the constant for dividing two hyper planes. The maximum-margin hyper planes that divide the points having P i = 1 from those P i = 0 are given as:\nP i = +1 when d.Si + b > \u03c1 (Occupied Class) (8a)\nP i = 0 when d.Si \u2212 b < \u03c1 (Idle Class) (8b)\nThe separation between two hyper planes is margin, controlled by the parameter called box constraint Boxct. We have evalauted the optimal value of Boxct using a bio-inspired technique i.e. FFA in our approach.\nMarch 25, 2015 DRAFT\n10"}, {"heading": "D. SVM with Fire Fly Algorithm", "text": "In FFA, let X be a group of fire flies, X = [l1, l2, ..lX ], initially located at specific positions aX = [al1 , al2 , ..alX ]. Each fire fly moves and tries find a brighter fire fly, which has more light intensity than its own. The objective function f(x) used for evaluating the brightness of the fire fly in our approach is the classification accuracy i. e. f(x) = CA(aX). When a fire fly, say l1 finds another brighter fire fly l2 at another location having more intensity compared to its own, it tends to move towards fire fly l2. The change in position is determined as [20]\nav+1l1 = a v l1 + \u03b20e\n\u2212\u03c8l1l2rd 2\nl1l2 (avl2 \u2212 a v l1 ) + \u03b1(rand\u2212 0.5) (9)\nwhere v represents the number of iterations, al1 and al2 represents the position of fire fly l1 and l2 respectively, \u03b1, \u03b20 and \u03c8l1l2 are constants and rand is a uniformly distributed random number. For our approach, the starting positions of the X fire flies are initialized, while the position of each fire fly represents the value of box constraints Boxct."}, {"heading": "E. Linear Regression", "text": "The flexibility of linear regression to include mixture of various features in different dimensions e. g. space, frequency, time and threshold as a linear combination is the main motivation of using it for modeling in this approach. The linear regression model for our approach is given by:\nP i = e0 + e1S i(1) + e2S i(2) + ...+ ekS i(k) = e0 +\nk \u2211\nj=1\nejS i(j). (10)\nwhere the class label P i is represented as a linear combination of parameters e1, e2, , ek and features (Si(1), Si(2), .., Si(k)) in the ith time slot. The stepwise-linear regression is used in this approach. In each step, the optimal term based on the value of defined \u2019criterion\u2019 is selected. The \u2019criterion\u2019 can be set as the sum of squares error (SSE), deviance, akaike information criterion (AIC), Bayesian information criterion (BIC) or R-squared etc. SSE is used in this approach. The small values of SSE are encouraged for a good model. It is observed from (10), that the computational time for evaluating the response of the model linearly increases with the number\nMarch 25, 2015 DRAFT\n11\nof frequency bins/ predictors involved. So we need to select an appropriate number of predictors for linear regression."}, {"heading": "F. Hidden Markov Models", "text": "It is an unsupervised algorithm for modeling the time series data. The motivation to use the unsupervised algorithm is that it does not need the training phase. In HMM, the sequence of states can be recovered by an analysis of the sequence of observations. The set of states and observations are represented by U and G given as U = (u1, u2, ...uN), G = (g1, g2, ...gM), where u1 and u2 represent the states when P i = 0 and P i = 1, respectively. The observations g1 and g2 represent the value of OC i corresponding to each P i. HMM is defined as\n\u03bb = (Ch, Dh, \u03c0) (11)\nwhere the transition array Ch is the probability of switching from state u1 to state u2 given as [21], Ch = [c12] = P (qt = u2|qt\u22121 = u1). The Dh is the probability of observation g1 being produced from state, Dh = [d1,2] = P (ot = g1,2|qt = u2) and \u03c0 is the initial probability array, \u03c0 = P (q1 = u2).\nHMM has two main steps. In the first step, the sequence of observations O = (o1, o2, ...oT ), transition probability matrix Ch and emission probability matrix Dh are utilized to find the probability of observations O given hmm model \u03bb given in ( [21], Eq.13) as, P (O|\u03bb) = \u2211\nQ P (O|Q, \u03bb)P (Q|\u03bb), where Q = (q1, q2, ...qT ) and P (O|Q, \u03bb) = \u220fT t=1 P (ot|qt, \u03bb) = gq1(o1) \u2217\ngq2(o2)..gqT (oT ). The probability of the state sequence is given as P (Q|\u03bb) = \u03c0q1cq1q2cq2q3...cqT\u22121qT . In the second step, the hidden state sequence, that is most likely to have produced an observation is decoded using the viterbi algorithm. The most likely sequence of states QL generated using the viterbi algorithm is matched with the expected fixed state sequence Q to compute classification accuracy. HMM can be also be supervised by adding two extra steps as Step(a): Use the initial guesses of Ch and Dh to compute Q and O, that are used for computing P (O|\u03bb) in forward algorithm\nMarch 25, 2015 DRAFT\n12\nStep(b): Use O, Dh and Ch in Step(a) to estimate the transition probability matrix Ch\u2032 and emission probability matrix Dh\u2032 using maximum likelihood estimation [22]. The Ch\u2032 and Dh\u2032 collectively form the estimated HMM model (\u03bbe) that can be further used for evaluating P (O|\u03bb) and QL using the forward algorithm and the Viterbi algorithm respectively."}, {"heading": "IV. NUMERICAL RESULTS AND DISCUSSION", "text": "In order to analyze the occupancy of the eight bands, the statistics of data in all bands from 880 to 2500 MHz are presented in Section IV-A. The classification criteria are explained in Section IV-B. The selection of the best parameters for each model using the classification criteria are discussed in Section IV-C. The classification models with the optimal parameters are compared to find the best classifier in terms of the CA, defined as CA = No. of correct classficationsTotal number of test samples"}, {"heading": "A. Statistics of Data", "text": "The CDF plot is shown in Fig.2 which gives the summarized view of all power ranges for the eight bands. It can be observed from Fig.2 that the eight bands can be categorized into two main groups. Group A contains those bands that have wide power ranges between -110 dBm to -30 dBm including 1805-1800 MHz, 1710-1785 MHz and 2110-2170 MHz. Group B has five bands: 925-960 MHz, 880-915 MHz, 2400-2500 MHz, 1920-1980 MHz and 1900-1920 MHz that have power ranges between -110 dBm and -100 dBm. Thus, Group A bands have larger standard deviation than Group B bands. Next we discuss the effects of two main parameters (frequency and threshold) on occupancy.\n1) Occupancy Vs Threshold: The threshold selection is an important task for analyzing the occupancy of each time slot. We took the minimum and the maximum value of power for each frequency band and tested seven values of thresholds in this range. Each band is analyzed separately for the seven values of the threshold using the four months data. Due to limited space, only 925-960 MHz is given in Fig.3. It is observed that occupancy monotonically decreases when the value of threshold increases. These results have proved that larger value of threshold will classify less samples as occupied.\nMarch 25, 2015 DRAFT\n13\n2) Occupancy Vs Frequency: The relationship between occupancy and frequency is analyzed by computing the occupancy of the jth bin individually. Eq.(2) can be modified for computing the occupancy of the jth frequency bin (OCj = \u2211 n i=1 Si(j)\nn ). We have found in Fig.4 a unique\nperiodicity in some bands. We found that four bands can be categorized as the periodic group bands: 880-915 MHz, 1710-1785 MHz, 2110-2170 MHz and 2400-2500 MHz bands. The bands 925-960 MHz, 1805-1880 MHz, 1920-1980 MHz and 2110-2170 MHz do not have this property.\nThe periodicity may be caused by the usage pattern. For instance, the periodicity in each band lies in their uplink/downlink usage pattern. For instance, the bands 1710-1785 MHz and 1900-1920 MHz are uplinks, while the aperiodic bands 1805-1880 MHz and 1920-1980 MHz are downlinks. The uplink transmits data from the mobile user to base station so that its activity is completely determined by mobile users\u2019s periodic usage pattern. On the other hand, the downlink transmits the data from base station to the mobile user so that its activity is also affected by control and broadcast channels, making it less or non periodic."}, {"heading": "B. Classification Criteria", "text": "This subsection studies the choice of Uoc, Loc, coni and B in Section II-C as shown in Fig 5. We have utilized Day1 (1-1440 min), Day 2 (1441-2448 min) and Day 5 (7200-8640 min) in Band 880-915 MHz, and four different values of threshold: \u03b3 = [\u2212102,\u2212104,\u2212106,\u2212108] dBm. The parameters Uoc and Loc will be selected by Ms, which represents the occupancy split that divides the data into occupied and idle classes. It varies from 0.1 to 0.9 with a step size of 0.1. It is observed in Fig.5 that the value of CA depends on day and the value of threshold. The actual value of OC itrain in (2) always lies in a certain range, [Ls, Us], where Ls represents the lowest value of OC itrain and Us represents the maximum value of OC i train. When Ls <=Ms <= Us, two groups of classes P i = 0 (available class) and P i = 1 (occupied class) can be classified correctly. When Ms > Us or Ms < Ls, all the samples will be classified as one class because OC itrain is a closed set whose values do not lie outside the range [Ls, Us]. This explains why the CA = 1 for [Loc, Uoc] = [0.1, 0.2] and [Loc, Uoc] = [0.75, 0.9] while CA < 1\nMarch 25, 2015 DRAFT\n14\nfor [Loc, Uoc] = [0.2, 0.75] for Day 1 using \u03b3 = \u2212102 dBm. Thus, the classification cannot be performed when Ms > Us or Ms < Ls. The optimal range is [Loc, Uoc] = [0.2, 0.75] for CA < 1. However, for CA < 1, there are four different choices of threshold available. In our proposed approach, we choose that specific value of threshold that contains the largest number of values between Loc and Uoc. Following this, we have selected \u03b3 = \u2212102 dBm for Day1, Day2 and Day5 as the optimal threshold which ensures the largest amount of samples between Loc and Uoc. The [Loc, Uoc] = [0.2, 0.75] for Day 1, [Loc, Uoc] = [0.4, 0.85] for Day2 and [Loc, Uoc] = [0.2, 0.80] for Day 5 respectively. The optimal values of \u03b3, Uoc and Loc are further used for finding B for each day."}, {"heading": "C. Model Performance Comparison", "text": "Following the discussion above, we have compared the performance of the algorithms in this section using 1 month data of Band 880-915 MHz. Our tests show that the number of minimum observations/node for DT can be seclected as 17, number of predictors for LR as 15, normal kernel for NBC and linear kernel for SVM. The optimal splitting range, optimal threshold and B will be selected corresponding to the data of each day.\n1) Supervised VS Unsupervised Algorithms using k = 55: In Fig. 6(a), it is observed that the mean CA attained by LR, SVM, DT, NBC and HMM is 0.9257, 0.9162, 0.8483, 0.9493 and 0.4790 respectively. The mean computation time in each iteration by LR, SVM, DT, NBC and HMM is 350.19, 0.092, 0.0136, 0.0045, and 0.0171 seconds, respectively. Thus, NBC is the best considering the accuracy and complexity.\n2) Supervised vs Unsupervised Algorithms using K = 192 : We have compared HMM, Trained HMM, SVM, DT and NBC in Fig.6(b) for 30 days. Each iteration represents 1 day. LR is not shown as it takes an excessively long time in this case. It is observed that trained HMM performed better than HMM, but worst than DT, NBC and SVM. The mean CA attained by Trained HMM, HMM, SVM, DT and NBC is 0.6816, 0.4887, 0.8528, 0.8392, 0.7970 while the computational time for each iteration of Trained HMM, HMM, SVM, DT and NBC 0.0205,\nMarch 25, 2015 DRAFT\n15\n0.09066, 0.0135, 0.0163, 0.0095 seconds, respectively. Thus, SVM is the best in this case with highest CA and shortest time.\n3) SVM with Fire Fly Algorithm : So far, the best overall performance is attained by the linear SVM technique. The performance of linear SVM is affected by the value of Boxct as illustrated in Section IV-C. The fire fly algorithm can be used to select the best value of Boxct. We set \u03b1 = 1, \u03b20 = 2 and \u03c8l1l2 = 1.3 for FFA. Fig. 7(a) depicts that \u2019SVM+FFA\u2019 performs better than the conventional SVM in most of the cases. The mean CA attained by SVM+FFA, SVM, DT, NBC and HMM is 0.8728, 0.8499, 0.7970, 0.8392 and 0.4822, respectively.\n4) Probability of SU Outage: This probability is computed using SVM+FFA, SVM, DT, NBC and HMM and compared with the expected P (SUoutage) to compute the difference between evaluated and expected values. It is evident in Fig. 7(b) that SVM+FFA has predicted the P (SUoutage) with minimum difference and is very close to the expected one. The expected SU outage is 0.9191 in Fig. 7(b) while the predicted P (SUoutage) using SVM+FFA, SVM, NBC, DT and HMM is 0.9264, 0.9322, 0.9638, 0.9577 and 1, respectively. The P (SUoutage) for HMM is always 1, which implies that HMM has failed to find any block of consecutive free time slot of length outsu.\n5) Supervised vs Unsupervised Algorithms using different Training/ Testing Data vectors:\nWe have presented the detailed comparison of supervised and unsupervised algorithms using different sizes of training and testing data Table 1. The classification accuracy and computation time for all supervised algorithms increases with an increase in the size of the training data. SVM+FFA has attained the highest CA but with the longest computation time in most cases."}], "references": [{"title": "Oh, \u201dA survey of Measurement-based spectrum occupancy modelling for cognitive radios", "author": ["Y. Chen", "H-S"], "venue": "IEEE Communications Surveys and Tutorials, Vol. PP, Issue", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Occupation measurements supporting dynamic spectrum allocation for cognitive radio design", "author": ["V. Blaschke", "H. Jaekel", "T. Renk", "C. Kloeck", "F.K. Jondral"], "venue": "Proc. CrownCom\u201907,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Predicting radio resource availability in cognitive radio an experimental examination", "author": ["S. Kaneko", "S. Nomoto", "T. Ueda", "S. Nomura", "K. Takeuchi"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Mammela, \u201dClassification-based predictive channel selection for cognitive radios", "author": ["M. Hoyhtya", "A.S. Pollin"], "venue": "Proc. ICC10,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Probability-based transmit power control for dynamic spectrum access", "author": ["X. Zhou", "J. Ma", "Y. Li", "Y.H. Kwon", "A.C.K. Soong", "G. Zhao"], "venue": "Proc. DySPAN08,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Probability-based optimization of inter-sensing duration and power control in cognitive radio", "author": ["X. Zhou", "J. Ma", "Y. Li", "Y.H. Kwon", "A.C.K. Soong"], "venue": "IEEE Transactions on Wireless Communications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Spectrum occupancy statistics and time series models for cognitive radio", "author": ["Z. Wang", "S. Salous"], "venue": "Journal of Signal Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Machine learning for science and society", "author": ["C. Rudin", "K.L. Wagstaff"], "venue": "Springer Journal on Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Cooperative Spectrum Sensing Under a Random Geometric Primary User Network Model", "author": ["K.W. Choi", "E. Hossain", "D.I. Kin"], "venue": "IEEE Transaction on Wireless Communications,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Primary Users in Cellular Networks: A Large-scale Measurement Study", "author": ["D. Willkomm", "S. Machiraju", "J. Bolot", "A. Wolisz"], "venue": "IEEE Symposium on New Frontiers in Dynamic Spectrum Access Networks, DySPAN\u2019", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Channel status prediction for cognitive radio networks", "author": ["V.K. Tumuluru", "P. Wang", "D. Niyato"], "venue": "Wiley Wireless Communications and Mobile Computing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "A linear mixed-effects model of wireless spectrum occupancy", "author": ["S. Pagadarai", "A.M. Wyglinski"], "venue": "EURASIP Journal on Wireless Communications and Networking", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Energy-detection based spectrum sensing for cognitive radio", "author": ["Z. Xuping", "P. Jianguo"], "venue": "Proc. CCWMSN07, pp", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Petain, \u201dMaximizing the Utility of Radio Spectrum: Broadband Spectrum Measurements and Occupancy Model for Use by Cognitive Radio", "author": ["J. A"], "venue": "Ph.D. dissertation, Georgia Institute of Technology,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "A user\u2019s guide to support vector machines\u201d, Data Mining Techniques for the Life Sciences", "author": ["A. b. Hur", "J. Weston"], "venue": "Methods in Molecular Biology,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Firefly algorithms for multimodal optimization", "author": ["X. Yang"], "venue": "LNCS 5792,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Hidden markov models\u201d, Aug 2004, available online at, http://digital.cs.usu.edu/\u223ccyan/CS7960/hmm-tutorial.pdf", "author": ["P. Blunsom"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Type-supervised hidden Markov models for part-of-speech tagging with incomplete tag dictionaries", "author": ["D. Garrette", "J. Baldridge"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Various spectrum measurement campaigns covering a wide range of frequencies have been performed [1].", "startOffset": 96, "endOffset": 99}, {"referenceID": 1, "context": "For instance, the statistical and spectral occupation analysis of the measurements was presented in [2] in order to study the traffic density in all frequency bands.", "startOffset": 100, "endOffset": 103}, {"referenceID": 2, "context": "In [3], autoregressive model was used to predict the radio resource availability using occupancy measurements in order to achieve uninterrupted data transmission of secondary users.", "startOffset": 3, "endOffset": 6}, {"referenceID": 3, "context": "In [4], the occupancy statistics were utilized to select the best channels for control and data transmission purposes, so that less time is required for switching transmission from one channel to the other for the case when the PU appears.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Further, In [5], [6], the bandwidth efficiency was maximized by controlling the transmission power of cognitive radio using spectrum occupancy measurements.", "startOffset": 12, "endOffset": 15}, {"referenceID": 5, "context": "Further, In [5], [6], the bandwidth efficiency was maximized by controlling the transmission power of cognitive radio using spectrum occupancy measurements.", "startOffset": 17, "endOffset": 20}, {"referenceID": 6, "context": "In [7], different time series models were used to categorize specific occupancy patterns in the spectrum measurements.", "startOffset": 3, "endOffset": 6}, {"referenceID": 7, "context": "On the other hand, machine learning (ML) is a very powerful tool that has received increasing attention recently [8].", "startOffset": 113, "endOffset": 116}, {"referenceID": 8, "context": "For example, the ML works related to CR in [9][13] discussed cooperative spectrum sensing and spectrum occupancy variation.", "startOffset": 43, "endOffset": 46}, {"referenceID": 11, "context": "For example, the ML works related to CR in [9][13] discussed cooperative spectrum sensing and spectrum occupancy variation.", "startOffset": 46, "endOffset": 50}, {"referenceID": 8, "context": "In [9] and [10], ML was used for cooperative spectrum sensing.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "In [11], authors have discussed call-based modelling for analyzing the spectrum usage of the dataset collected from the cellular network operator.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [12], HMM was used to predict the channel status.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [13], LR was used to investigate the spectrum occupancy variation in time and frequency.", "startOffset": 3, "endOffset": 7}, {"referenceID": 12, "context": "Using energy detection [14], if y(j) is the sample sensed at the i time slot in the j frequency bin.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "The computation of \u03b3 was explained in [15].", "startOffset": 38, "endOffset": 42}, {"referenceID": 15, "context": "The change in position is determined as [20] a l1 = a v l1 + \u03b20e \u2212\u03c8l1l2rd 2 l1l2 (avl2 \u2212 a v l1 ) + \u03b1(rand\u2212 0.", "startOffset": 40, "endOffset": 44}, {"referenceID": 16, "context": "HMM is defined as \u03bb = (Ch, Dh, \u03c0) (11) where the transition array Ch is the probability of switching from state u1 to state u2 given as [21], Ch = [c12] = P (qt = u2|qt\u22121 = u1).", "startOffset": 136, "endOffset": 140}, {"referenceID": 16, "context": "oT ), transition probability matrix Ch and emission probability matrix Dh are utilized to find the probability of observations O given hmm model \u03bb given in ( [21], Eq.", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "Step(b): Use O, Dh and Ch in Step(a) to estimate the transition probability matrix Ch\u2032 and emission probability matrix Dh\u2032 using maximum likelihood estimation [22].", "startOffset": 159, "endOffset": 163}], "year": 2015, "abstractText": "In this paper, we analyze the spectrum occupancy using different machine learning techniques. Both supervised techniques (naive Bayesian classifier (NBC), decision trees (DT), support vector machine (SVM), linear regression (LR)) and unsupervised algorithm (hidden markov model (HMM)) are studied to find the best technique with the highest classification accuracy (CA). A detailed comparison of the supervised and unsupervised algorithms in terms of the computational time and classification accuracy is performed. The classified occupancy status is further utilized to evaluate the probability of secondary user outage for the future time slots, which can be used by system designers to define spectrum allocation and spectrum sharing policies. Numerical results show that SVM is the best algorithm among all the supervised and unsupervised classifiers. Based on this, we proposed a new SVM algorithm by combining it with fire fly algorithm (FFA), which is shown to outperform all other algorithms. Index Terms Fire fly algorithm, hidden markov model, spectrum occupancy and support vector machine. March 25, 2015 DRAFT", "creator": "LaTeX with hyperref package"}}}