{"id": "1505.00388", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2015", "title": "Order-Revealing Encryption and the Hardness of Private Learning", "abstract": "an order - revealing encryption scheme gives a public optimization procedure by which two ciphertexts can be analyzed compared to reveal the ordering of their underlying plaintexts. we let show how necessary to use elementary order - revealing encryption to facilitate separate computationally efficient pac learning from efficient $ ( \\ epsilon, \\ delta ) $ - differentially learned private pac learning. that is, we construct a concept class that is efficiently pac learnable, but for networks which every efficient learner fails to be differentially private. this answers a question of kasiviswanathan et um al. ( focs'+ 08, siam j. comput.'11 ).", "histories": [["v1", "Sun, 3 May 2015 02:23:49 GMT  (36kb,D)", "http://arxiv.org/abs/1505.00388v1", "28 pages"]], "COMMENTS": "28 pages", "reviews": [], "SUBJECTS": "cs.CR cs.CC cs.LG", "authors": ["mark bun", "mark zhandry"], "accepted": false, "id": "1505.00388"}, "pdf": {"name": "1505.00388.pdf", "metadata": {"source": "CRF", "title": "Order-Revealing Encryption and the Hardness of Private Learning", "authors": ["Mark Bun", "Mark Zhandry"], "emails": ["mbun@seas.harvard.edu.", "mzhandry@gmail.com."], "sections": [{"heading": null, "text": "To prove our result, we give a generic transformation from an order-revealing encryption scheme into one with strongly correct comparison, which enables the consistent comparison of ciphertexts that are not obtained as the valid encryption of any message. We believe this construction may be of independent interest.\nKeywords: differential privacy, learning theory, order-revealing encryption\n\u2217School of Engineering & Applied Sciences, Harvard University. mbun@seas.harvard.edu. Supported by an NDSEG fellowship and NSF grant CNS-1237235. \u2020Stanford University. mzhandry@gmail.com. Supported by the DARPA PROCEED program.\nar X\niv :1\n50 5.\n00 38\n8v 1\n[ cs\n.C R\n] 3\nM ay"}, {"heading": "1 Introduction", "text": "Many agencies hold sensitive information about individuals, where statistical analysis of this data could yield great societal benefit. The line of work on differential privacy [DMNS06] aims to enable such analysis while giving a strong formal guarantee on the privacy afforded to individuals. Noting that the framework of computational learning theory captures many of these statistical tasks, Kasiviswanathan et al. [KLN+11] initiated the study of differentially private learning. Roughly speaking, a differentially private learner is required to output a classification of labeled examples that is accurate, but does not change significantly based on the presence or absence of any individual example.\nThe early positive results in private learning established that, ignoring computational complexity, any concept class is privately learnable with a number of samples logarithmic in the size of the concept class [KLN+11]. Since then, a number of works have improved our understanding of the sample complexity \u2013 the minimum number of examples \u2013 required by such learners to simultaneously achieve accuracy and privacy. Some of these works showed that privacy incurs an inherent additional cost in sample complexity; that is, some concept classes require more samples to learn privately than they require to learn without privacy [BKN10, CH11, BNS13, FX14, CHS14, BNSV15]. In this work, we address the complementary question of whether there is also a computational price of differential privacy for learning tasks, for which much less is known. The initial work of Kasiviswanathan et al. [KLN+11] identified the important question of whether any efficiently PAC learnable concept class is also efficiently privately learnable, but only limited progress has been made on this question since then [BKN10, Nis14].\nOur main result gives a strong negative answer to this question. We exhibit a concept class that is efficiently PAC learnable, but under plausible cryptographic assumptions cannot be learned efficiently and privately. To prove this result, we establish a connection between private learning and order-revealing encryption. We construct a new order-revealing encryption scheme with strong correctness properties that may be of independent learning-theoretic and cryptographic interest."}, {"heading": "1.1 Differential Privacy and Private Learning", "text": "We first recall Valiant\u2019s (distribution-free) PAC model for learning [Val84]. Let C be a concept class consisting of concepts c : X \u2192 {0, 1} for a data universe X. A learner L is given n samples of the form (xi, c(xi)) where the xi\u2019s are drawn i.i.d. from an unknown distribution, and are labeled according to an unknown concept c. The goal of the learner is to output a hypothesis h : X \u2192 {0, 1} from a hypothesis class H that approximates c well on the unknown distribution. That is, the probability that h disagrees with c on a fresh example from the unknown distribution should be small \u2013 say, less than 0.05. The hypothesis class H may be different from C, but in the case where H \u2286 C we call L a proper learner. Moreover, we say a learner is efficient if it runs in time polynomial in the description size of c and the size of its examples.\nKasiviswanathan et al. [KLN+11] defined a private learner to be a PAC learner that is also differentially private. Two samples S = {(x1, b1), . . . , (xn, bn)} and S\u2032 = {(x\u20321, b\u20321), . . . , (x\u2032n, b\u2032n)} are said to be neighboring if they differ on exactly one example, which we think of as corresponding to one individual\u2019s information. A randomized learner L : (X \u00d7 {0, 1})n \u2192 H is (\u03b5, \u03b4)-differentially private if for all neighboring datasets S and S\u2032 and all sets T \u2286 H,\nPr[L(S) \u2208 T ] \u2264 e\u03b5 Pr[L(S\u2032) \u2208 T ] + \u03b4.\nThe original definition of differential privacy [DMNS06] took \u03b4 = 0, a case which is called pure differential privacy. The definition with positive \u03b4, called approximate differential privacy, first appeared in [DKM+06] and has since been shown to enable substantial accuracy gains. Throughout this introduction, we will think of \u03b5 as a small constant, e.g. \u03b5 = 0.1, and \u03b4 = o(1/n).\nKasiviswanathan et al. [KLN+11] gave a generic \u201cPrivate Occam\u2019s Razor\u201d algorithm, showing that any concept class C can be privately (properly) learned using O(log |C|) samples. Unfortunately, this algorithm runs in time \u2126(|C|), which is exponential in the description size of each concept. With an eye toward designing efficient private learners, Blum et al. [BDMN05] made the powerful observation that any efficient learning algorithm in the statistical queries (SQ) framework of Kearns [Kea98] can be efficiently simulated with differential privacy. Moreover, Kasiviswanathan et al. [KLN+11] showed that the efficient learner for the concept class of parity functions based on Gaussian elimination can also be implemented efficiently with differential privacy. These two techniques \u2013 SQ learning and Gaussian elimination \u2013 are essentially the only methods known for computationally efficient PAC learning. The fact that these can both be implemented privately led Kasiviswanathan et al. [KLN+11] to ask whether all efficiently learnable concept classes could also be efficiently learned with differential privacy.\nBeimel et al. [BKN10] made partial progress toward this question in the special case of pure differential privacy with proper learning, showing that the sample complexity of efficient learners can be much higher than that of inefficient ones. Specifically, they showed that assuming the existence of pseudorandom generators with exponential stretch, there exists for any `(d) = \u03c9(log d) a concept class over {0, 1}d for which every efficient proper private learner requires \u2126(d) samples, but an inefficient proper private learner only requires O(`(d)) examples. Nissim [Nis14] strengthened this result substantially for \u201crepresentation learning,\u201d where a proper learner is further restricted to output a canonical representation of its hypothesis. He showed that, assuming the existence of one-way functions, there exists a concept class that is efficiently representation learnable, but not efficiently privately representation learnable (even with approximate differential privacy). With Nissim\u2019s kind permission, we give the details of this construction in Section 5.\nDespite these negative results for proper learning, one might still have hoped that any efficiently learnable concept class could be efficiently improperly learned with privacy. Indeed, a number of works have shown that, especially with differential privacy, improper learning can be much more powerful than proper learning. For instance, Beimel et al. [BKN10] showed that under pure differential privacy, the simple class of Point functions (indicators of a single domain element) requires \u2126(d) samples to privately learn properly, but only O(log d) samples to privately learn improperly. Moreover, computational separations are known between proper and improper learning even without privacy considerations. Pitt and Valiant [PV88] showed that unless NP = RP, k-term DNF are not efficiently properly learnable, but they are efficiently improperly learnable [Val84].\nUnder plausible cryptographic assumptions, we resolve the question of Kasiviswanathan et al. [KLN+11] in the negative, even for improper learners. The assumption we need is the existence of \u201cstrongly correct\u201d order-revealing encryption (ORE) schemes, described in Section 1.3.\nTheorem 1.1 (Informal). Assuming the existence of strongly correct ORE, there exists an efficiently computable concept class EncThresh that is efficiently PAC learnable, but not efficiently learnable by any (\u03b5, \u03b4)-differentially private algorithm.\nWe stress that this result holds even for improper learners and for the relaxed notion of approximate differential privacy. We remark that cryptography has played a major role in shaping our understanding of the computational complexity of learning in a number of models (e.g.\n[Val84, KV94, Kha95, Ser00]). It has also been used before to show separations between what is efficiently learnable in different models (e.g. [Blu94, SG04])."}, {"heading": "1.2 Our Techniques", "text": "We give an informal overview of the construction and analysis of the concept class EncThresh. We first describe the concept class of thresholds Thresh and its simple PAC learning algorithm. Consider the domain [N ] = {1, . . . , N}. Given a number t \u2208 [N ], a threshold concept ct is defined by ct(x) = 1 if and only if x \u2264 t. The concept class of thresholds admits a simple and efficient proper PAC learning algorithm LThresh. Given a sample {(x1, ct(x1)), . . . , (xn, ct(xn))} labeled by an unknown concept ct, the learner LThresh identifies the largest positive example xi\u2217 and outputs the hypothesis h = cxi\u2217 . That is, LThresh chooses the threshold concept that minimizes the empirical error on its sample. To achieve a small constant error on any underlying distribution on examples, it suffices to take n = O(1) samples.\nA simple but important observation about LThresh is that it is completely oblivious to the actual numeric values of its examples, or even to the fact that the domain is [N ]. In fact, LThresh works equally well on any totally-ordered domain on which it can efficiently compare examples. In an extreme case, the learner LThresh still works when its examples are encrypted under an orderrevealing encryption (ORE) scheme, which guarantees that LThresh is able to learn the order of its examples, but nothing else about them. Up to small technical modifications, our concept class EncThresh is exactly the class Thresh where examples are encrypted under an ORE scheme.\nFor EncThresh to be efficiently PAC learnable, it must be learnable even under distributions that place arbitrary weight on examples corresponding to invalid ciphertexts. To this end, we require a \u201cstrong correctness\u201d condition on our ORE scheme. The strong correctness condition ensures that all ciphertexts, even those that are not obtained as encryptions of messages, can be compared in a consistent fashion. This condition is not met by current constructions of ORE, and one of the technical contributions of this work is a generic transformation from weakly correct ORE schemes to strongly correct ones.\nWhile a learner similar to LThresh is able to efficiently PAC learn the concept class EncThresh, we argue that it cannot do so while preserving differential privacy with respect to its examples. Intuitively, the security of the ORE scheme ensures that essentially the only thing a learner for EncThresh can do is output a hypothesis that compares an example to one it already has. We make this intuition precise by giving an algorithm that traces the hypothesis output by any efficient learner back to one of the examples used to produce it. This formalization builds conceptually on the connection between differential privacy and traitor-tracing schemes (see Section 1.4), but requires new ideas to adapt to the PAC learning model."}, {"heading": "1.3 Order-Revealing Encryption", "text": "Motivated by the task of answering range queries on encrypted databases, an order-revealing encryption (ORE) scheme [BCO11, BLR+15] is a special type of symmetric key encryption scheme where it is possible to publicly sort ciphertexts according to the order of the plaintexts. More precisely, the plaintext space of the scheme is the set of integers [N ] = {1, ..., N},1 and in addition to the private encryption and decryption procedures Enc,Dec, there is a public comparison procedure Comp that takes as input two ciphertexts, and reveals the order of the corresponding plaintexts.\n1More generally, any totally-ordered plaintext space can be considered\nThe notion of best-possible semantic security, defined in Boneh et al. [BLR+15], intuitively captures the requirement that, given a collection of ciphertexts, no information about the plaintexts is learned, except for the ordering.\nKnown constructions of order-revealing encryption. Order-revealing encryption can be seen as a special case of 2-input functional encryption. In such a scheme, there are several functions f1, ..., fk, and given two ciphertexts c0, c1 encrypting m0,m1, it is possible to learn fi(m0,m1) for all i \u2208 [k]. General multi-input functional encryption schemes can be obtained from indistinguishability obfuscation [GGG+14] or multilinear maps [BLR+15]. It is also possible to build ORE from singleinput functional encryption with function privacy, which means that f is kept secret. Such schemes can be build from regular single-input schemes without function privacy by work of Brakerski and Segev [BS15], and such single-input schemes can also be built from obfuscation [GGH+13b] or multilinear maps [GGHZ14].\nUnfortunately, the above constructions are insufficient for our purposes. The issue arises from the fact that our learner needs to work for any distribution on ciphertexts, even distributions whose support includes malformed ciphertexts. Unfortunately, previous constructions only achieve a weak form of correctness, which guarantees that encrypting two messages and then comparing the ciphertexts using Comp produces the same result (with overwhelming probability) as comparing the plaintexts directly. This requirement only specifies how Comp works on valid ciphertexts, namely actual encryptions of messages. Moreover, correctness is only guaranteed for these messages with overwhelming probability, meaning even some valid ciphertexts may cause Comp to misbehave.\nFor our learner, this weak form of correctness means, for some distributions that place significant weight on bad ciphertexts, the comparison procedure is completely useless, and thus the learner will fail for these distributions.\nWe therefore need a stronger correctness guarantee. We need that, for any two ciphertexts, the comparison procedure is consistent with decrypting the two ciphertexts and comparing the resulting plaintexts. This correctness guarantee is meaningful even for improperly generated ciphertexts.\nWe note that none of the existing constructions of order-revealing encryption outlined above satisfy this stronger notion. For the obfuscation-based schemes, ciphertexts consist of obfuscated programs. In these schemes, it is easy to describe invalid ciphertexts where the obfuscated program performs incorrectly, causing the comparison procedure to output the wrong result. In the multilinear map-based schemes, the underlying instantiation use current \u201cnoisy\u201d multilinear maps, such as [GGH13a]. An invalid ciphertext could, for example, have too much noise, which will cause the comparison procedure to behave unpredictably.\nObtaining strong correctness. We first argue that, for all existing ORE schemes, the scheme can be modified so that Comp is correct for all valid ciphertexts. We then give a generic conversion from any ORE scheme with weakly correct comparison, including the tweaked existing schemes, into a strongly correct scheme. We simply modify the ciphertext by adding a non-interactive zero-knowledge (NIZK) proof that the ciphertext is well-formed, with the common reference string added to the public comparison key. Then the decryption and comparison procedures check the proof(s), and only output the result (either decryption or comparison) if the proof(s) are valid. The (computational) zero-knowledge property of the NIZK implies that the addition of the proof to the ciphertext does not affect security. Meanwhile, NIZK soundness implies that any ciphertext\naccepted by the decryption and comparison procedures must be valid, and the weak correctness property of the underlying ORE implies that for valid ciphertexts, decryption and comparison are consistent. The result is that comparisons are consistent with decryption for all ciphertexts, giving strong correctness.\nAs we need strong correctness for every ciphertext, even hard-to-generate ones, we need the NIZK proofs to have perfect soundness, as opposed to computational soundness. Such NIZK proofs were built in [GOS12].\nWe note also that the conversion outlined above is not specific to ORE, and applies more generally to functional encryption schemes."}, {"heading": "1.4 Related Work", "text": "Hardness of Private Query Release. One of the most basic and well-studied statistical tasks in differential privacy is the problem of releasing answers to counting queries. A counting query asks,\u201cwhat fraction of the records in a dataset D satisfy the predicate q?\u201d. Given a collection of k counting queries q1, . . . , qk from a family Q, the goal of a query release algorithm is to release approximate answers to these queries while preserving differential privacy. A remarkable result of Blum et al. [BLR08], with subsequent improvements by [DNR+09, DRV10, RR10, HR10, GRU12, HLM12], showed that an arbitrary sequence of counting queries can be answered accurately with differential privacy even when k is exponential in the dataset size n. Unfortunately, all of these algorithms that are capable of answering more than n2 queries are inefficient, running in time exponential in the dimensionality of the data. Moreover, several works [DNR+09, Ull13, BZ14] have gone on to show that this inefficiency is likely inherent.\nThese computational lower bounds for private query release rely on a connection between the hardness of private query release and traitor-tracing schemes, which was first observed by Dwork et al. [DNR+09]. Traitor-tracing schemes were introduced by Chor, Fiat, and Naor [CFN94] to help digital content producers identify pirates as they illegally redistribute content. Traitor-tracing schemes are conceptually analogous to the example reidentification scheme we use to obtain our hardness result for private learning. Instantiating this connection with the traitor-tracing scheme of Boneh, Sahai, and Waters [BSW06], which relies on certain assumptions in bilinear groups, Dwork et al. [DNR+09] exhibited a family of 2O\u0303( \u221a n) queries for which no efficient algorithm can produce a data structure which could be used to answer all queries in this family. Very recently, Boneh and Zhandry [BZ14] constructed a new traitor-tracing scheme based on indistinguishability obfuscation that yields the same infeasibility result for a family of n \u00b7 2O(d) queries on records of size d. Extending this connection, Ullman [Ull13] constructed a specialized traitor-tracing scheme to show that no efficient private algorithm can answer more than O\u0303(n2) arbitrary queries that are given as input to the algorithm.\nDwork et al. [DNR+09] also showed strong lower bounds against private algorithms for producing synthetic data. Synthetic data generation algorithms produce a new \u201cfake\u201d dataset, whose rows are of the same type as those in the original dataset, with the promise that the answers to some restricted set of queries on the synthetic dataset well-approximate the answers on the original dataset. Assuming the existence of one-way functions, Dwork et al. [DNR+09] exhibited an efficiently computable collection of queries for which no efficient private algorithm can produce useful synthetic data. Ullman and Vadhan [UV11] refined this result to hold even for extremely simple classes of queries.\nNevertheless, the restriction to synthetic data is significant to these results, and they do not rule\nout the possibility that other privacy-preserving data structures can be used to answer large families of restricted queries. In fact, when the synthetic data restriction is lifted, there are algorithms (e.g. [HRS12, TUV12, CTUW14, DNT14]) that answer queries from certain exponentially large families in subexponential time. One can view the problem of synthetic data generation as analogous to proper learning. In both cases, placing natural syntactic restrictions on the output of an algorithm may in fact come at the expense of utility or computational efficiency.\nEfficiency of SQ Learning. Feldman and Kanade [FK12] addressed the question of whether information-theoretically efficient SQ learners \u2013 i.e., those making polynomially many queries \u2013 could be made computationally efficient. One of their main negative results showed that unless NP = RP, there exists a concept class with polynomial query complexity that is not efficiently SQ learnable. Moreover, this concept class is efficiently PAC learnable, which suggests that the restriction to SQ learning can introduce an inherent computational cost.\nWe show that the concept class EncThresh can be learned (inefficiently) with polynomially many statistical queries. The result of Blum et al. [BDMN05] discussed above, showing that SQ learning algorithms can be efficiently simulated by differentially private algorithms, thus shows that EncThresh also separates SQ learners making polynomially many queries from computationally efficient SQ learners.\nCorollary 1.2 (Informal). Assuming the existence of strongly correct ORE, the concept class EncThresh is efficiently PAC learnable and has polynomial SQ query complexity, but is not efficiently SQ learnable.\nWhile our proof relies on much stronger hardness assumptions, it reveals ORE as a new barrier to efficient SQ learning. As discussed in more detail in Section 3.3, even though their result is about computational hardness, Feldman and Kanade\u2019s choice of a concept class relies crucially on the fact that parities are hard to learn in the SQ model even information-theoretically. By contrast, our concept class EncThresh is computationally hard to SQ learn for a reason that appears fundamentally different than the information-theoretic hardness of SQ learning parities.\nLearning from Encrypted Data. Several works have developed schemes for training, testing, and classifying machine learning models over encrypted data (e.g. [GLN13, BPTG14]). In a model use case, a client holds a sensitive dataset, and uploads an encrypted version of the dataset to a cloud computing service. The cloud service then trains a model over the encrypted data and produces an encrypted classifier it can send back to the client, ideally without learning anything about the examples it received. The notion of privacy afforded to the individuals in the dataset here is complementary to differential privacy. While the cloud service does not learn anything about the individuals in the dataset, its output might still depend heavily on the data of certain individuals.\nIn fact, our non-differentially private PAC learner for the class EncThresh exactly performs the task of learning over encrypted data, producing a classifier without learning anything about its examples beyond their order (this addresses the difficulty of implementing comparisons from prior work [GLN13]). Thus one can interpret our results as showing that not only are these two notions of privacy for machine learning training complementary, but that they may actually be in conflict. Moreover, the strong correctness guarantee we provide for ORE (which applies more generally to multi-input functional encryption) may help enable the theoretical study of learning from encrypted data in other PAC-style settings."}, {"heading": "2 Preliminaries and Definitions", "text": ""}, {"heading": "2.1 PAC Learning and Private PAC Learning", "text": "For each k \u2208 N, let Xk be an instance space (such as {0, 1}k), where the parameter k represents the size of the elements in Xk. Let Ck be a set of boolean functions {c : Xk \u2192 {0, 1}}. The sequence (X1, C1), (X2, C2), . . . represents an infinite sequence of learning problems defined over instance spaces of increasing dimension. We will generally suppress the parameter k, and refer to the problem of learning C as the problem of learning Ck for every k.\nA learner L is given examples sampled from an unknown probability distribution D over X, where the examples are labeled according to an unknown target concept c \u2208 C. The learner must select a hypothesis h from a hypothesis class H that approximates the target concept with respect to the distribution D. More precisely,\nDefinition 2.1. The generalization error of a hypothesis h : X \u2192 {0, 1} (with respect to a target concept c and distribution D) is defined by errorD(c, h) = Prx\u223cD[h(x) 6= c(x)]. If errorD(c, h) \u2264 \u03b1 we say that h is an \u03b1-good hypothesis for c on D.\nDefinition 2.2 (PAC Learning [Val84]). Algorithm L : (X \u00d7 {0, 1})n \u2192 H is an (\u03b1, \u03b2)-accurate PAC learner for the concept class C using hypothesis class H with sample complexity n if for all target concepts c \u2208 C and all distributionsD onX, given an input of n samples S = ((xi, c(xi)), . . . , (xn, c(xn))), where each xi is drawn i.i.d. fromD, algorithm L outputs a hypothesis h \u2208 H satisfying Pr[errorD(c, h) \u2264 \u03b1] \u2265 1\u2212\u03b2. The probability here is taken over the random choice of the examples in S and the coin tosses of the learner L.\nThe learner L is efficient if it runs in time polynomial in the size parameter k, the representation size of the target concept c, and the accuracy parameters 1/\u03b1 and 1/\u03b2. Note that a necessary (but not sufficient) condition for L to be efficient is that its sample complexity n is polynomial in the learning parameters.\nIf H \u2286 C then L is called a proper learner. Otherwise, it is called an improper learner.\nKasiviswanathan et al. [KLN+11] defined a private learner as a PAC learner that is also differentially private. Recall the definition of differential privacy:\nDefinition 2.3. A learner L : (X\u00d7{0, 1})n \u2192 H is (\u03b5, \u03b4)-differentially private if for all sets T \u2286 H, and neighboring sets of examples S \u223c S\u2032,\nPr[L(S) \u2208 T ] \u2264 e\u03b5 Pr[L(S\u2032) \u2208 T ] + \u03b4.\nThe technical object that we will use to show our hardness results for differential privacy is what we call an example reidentification scheme. It is analogous to the hard-to-sanitize database distributions [DNR+09, UV11] and re-identifiable database distributions [BUV14] used in prior works to prove hardness results for private query release, but is adapted to the setting of computational learning. In the first step, an algorithm Genex chooses a concept and a sample S labeled according to that concept. In the second step, a learner L receives either the sample S or the sample S\u2212i where an appropriately chosen example i is replaced by a junk example, and learns a hypothesis h. Finally, an algorithm Traceex attempts to use h to identify one of the rows given to L. If Traceex succeeds at identifying such a row with high probability, then it must be able to distinguish L(S) from L(S\u2212i), showing that L cannot be differentially private. We formalize these ideas below.\nDefinition 2.4. An (\u03b1, \u03be)-example reidentification scheme for a concept class C consists of a pair of algorithms, (Genex,Traceex) with the following properties.\nGenex(k, n) Samples a concept c \u2208 Ck and an associated distribution D. Draws i.i.d. examples x1, . . . , xn \u2190R D, and a fixed value x0. Let S denote the labeled sample ((x1, c(x1)), . . . , (xn, c(xn)), and for any index i \u2208 [n], let S\u2212i denote the sample with the pair (xi, c(xi)) replaced with (x0, c(x0)).\nTraceex(h) Takes state shared with Genex as well as a hypothesis h and identifies an index in [n] (or \u22a5 if none is found).\nThe scheme obeys the following \u201ccompleteness\u201d and \u201csoundness\u201d criteria on the ability of Traceex to identify an example given to a learner L.\nCompleteness. A good hypothesis can be traced to some example. That is, for every efficient learner L,\nPr[errorD(c, h) \u2264 \u03b1 \u2227 Traceex(h) = \u22a5] \u2264 \u03be.\nHere, the probability is taken over h\u2190R L(S) and the coins of Genex and Traceex.\nSoundness. For every efficient learner L, Traceex cannot trace i from the sample S\u2212i. That is, for all i \u2208 [n],\nPr[Traceex(h) = i] \u2264 \u03be\nfor h\u2190R L(S\u2212i).\nWe may sometimes relax the completeness condition to hold only under certain restrictions on L\u2019s output (e.g. L is a proper learner or L is a representation learner). In this case, we say the (Genex,Traceex) is an example reidentification scheme for (properly, representation) learning a class C.\nTheorem 2.5. Let (Genex,Traceex) be an (\u03b1, \u03be)-example reidentification scheme for a concept class C. Then for every \u03b2 > 0 and polynomial n(k), there is no efficient (\u03b5, \u03b4)-differentially private (\u03b1, \u03b2)-PAC learner for C using n samples when\n\u03b4 <\n( 1\u2212 \u03b2 \u2212 \u03be\nn\n) \u2212 e\u03b5\u03be.\nIn a typical setting of parameters, we will take \u03b1, \u03b2, \u03b5 = O(1) and \u03b4, \u03be = o(1/n), in which case the inequality in Theorem 2.5 will be satisfied for sufficiently large n.\nProof. Suppose instead that there were a computationally efficient (\u03b5, \u03b4)-differentially private (\u03b1, \u03b2)PAC learner L for C using n samples. Then there exists an i \u2208 [n] such that Pr[Traceex(L(S)) = i] \u2265 (1\u2212 \u03b2 \u2212 \u03be)/n. However, since L is differentially private,\nPr[Traceex(L(S\u2212i)) = i] \u2265 e\u2212\u03b5 (\n1\u2212 \u03b2 \u2212 \u03be n\n\u2212 \u03b4 ) > \u03be(n),\nwhich contradicts the soundness of (Genex,Traceex)."}, {"heading": "2.2 Order-Revealing Encryption", "text": "Definition 2.6. An Order-Revealing Encryption (ORE) scheme is a tuple (Gen,Enc,Dec,Comp) of algorithms where:\n\u2022 Gen(1\u03bb, 1`) is a randomized procedure that takes as inputs a security parameter \u03bb and plaintext length `, and outputs a secret encryption/decryption key sk and public parameters params.\n\u2022 Enc(sk,m) is a potentially randomized procedure that takes as input a secret key sk and a message m \u2208 {0, 1}`, and outputs a ciphertext c.\n\u2022 Dec(sk, c) is a deterministic procedure that takes as input a secret key sk and a ciphertext c, and outputs a plaintext message m \u2208 {0, 1}` or a special symbol \u22a5.\n\u2022 Comp(params, c0, c1) is a deterministic procedure that \u201ccompares\u201d two ciphertexts, outputting either \u201c>\u201d, \u201c<\u201d, \u201c=\u201d, or \u22a5.\nCorrectness. An ORE scheme must satisfy two separate correctness requirements:\n\u2022 Correct Decryption: This is the standard notion of correctness for an encryption scheme, which says that decryption succeeds. We will only consider strongly correct decryption, which requires that decryption always succeeds. For all security parameters \u03bb and message lengths `,\nPr[Dec(sk, Enc(sk,m) ) = m : (sk, params)\u2190 Gen(1\u03bb, 1`)] = 1.\n\u2022 Correct Comparison: We require that the comparison function succeeds. We will consider two notions, namely strong and weak. In order to define these notions, we first define two auxiliary functions:\n\u2013 Compplain(m0,m1) is just the plaintext comparison function. That is, for m0 < m1, Compplain(m0,m1) = \u201c < \u201d, Compplain(m1,m0) = \u201c > \u201d, and Compplain(m0,m0) = \u201c = \u201d.\n\u2013 Compciph(sk, c0, c1) is a ciphertext comparison function which uses the secret key. If first computes mb = Dec(sk, cb) for b = 0, 1. If either m0 = \u22a5 or m1 = \u22a5 (in other words, if either decryption failed), then Compciph outputs \u22a5. If both m0,m1 6= \u22a5, then the output is Compplain(m0,m1).\nNow we define our comparison correctness notions:\n\u2013 Weakly Correct Comparison: This informally requires that comparison is consistent with encryption. For all security parameters \u03bb, message lengths `, and messages m0,m1 \u2208 {0, 1}`,\nPr [ Comp(params, c0, c1) = Compplain(m0,m1) :\n(sk, params)\u2190 Gen(1\u03bb, 1`) cb \u2190 Enc(sk,mb)\n] = 1.\nIn particular, for correctly generated ciphertexts, Comp never outputs \u22a5.\n\u2013 Strongly Correct Comparison: This informally requires that comparison is consistent with decryption. For all security parameters \u03bb, message lengths `, and ciphertexts c0, c1,\nPr [ Comp(params, c0, c1) = Compciph(sk, c0, c1) : (sk, params)\u2190 Gen(1\u03bb, 1`) ] = 1.\nSecurity. For security, we will consider a relaxation of the \u201cbest possible\u201d security notion of Boneh et al. [BLR+15]. Namely, we only consider static adversaries that submit all queries at once. \u201cBest possible\u201d security is a modification of the standard notion of CPA security for symmetric key encryption to block trivial attacks. That is, since the comparison function always leaks the order of the plaintexts, the left and right sets of challenge messages must have the same order. In our relaxation where all challenge messages are queried at once, we can therefore assume without loss of generality that the left and right sequences of messages are sorted in ascending order. For simplicity, we will also disallow the adversary from querying on the same message more than once. This gives the following definition:\nDefinition 2.7. An ORE scheme (Gen,Enc,Dec,Comp) is statically secure if, for all efficient adversaries A, |Pr[W0]\u2212Pr[W1]| is negligible, where Wb is the event that A outputs 1 in the following experiment:\n\u2022 A produces two message sequences m(L)1 < m (L) 2 < \u00b7 \u00b7 \u00b7 < m (L) q and m (R) 1 < m (R) 2 < \u00b7 \u00b7 \u00b7 < m (R) q\n\u2022 The challenger runs (sk, params) \u2190 Gen(1\u03bb, 1`). It then responds to A with params, as well as c1, . . . , cq where\nci =\n{ Enc(sk,m\n(L) i ) if b = 0\nEnc(sk,m (R) i ) if b = 1\n\u2022 A outputs a guess b\u2032 for b.\nWe also consider a weaker definition, which only allows the sequences m (L) i and m (R) i to differ\nat a single point:\nDefinition 2.8. An ORE scheme (Gen,Enc,Dec,Comp) is statically single-challenge secure if, for all efficient adversaries A, |Pr[W0]\u2212 Pr[W1]| is negligible, where Wb is the event that A outputs 1 in the following experiment:\n\u2022 A produces a sequence of messages m1 < m2 < \u00b7 \u00b7 \u00b7 < mq, and challenge messages mL,mR such that mi < mL < mR < mi+1 for some i \u2208 [q \u2212 1].\n\u2022 The challenger runs (sk, params) \u2190 Gen(1\u03bb, 1`). It then responds to A with params, as well as c1, . . . , cq where ci = Enc(sk,mi) and\nc\u2217 =\n{ Enc(sk,mL) if b = 0\nEnc(sk,mR) if b = 1\n\u2022 A outputs a guess b\u2032 for b.\nWe now argue that these two definitions are equivalent up to some polynomial loss in security.\nTheorem 2.9. (Gen,Enc,Dec,Comp) is statically secure if and only if it is statically single-challenge secure.\nProof. We prove that single-challenge security implies many-challenge security through a sequence of hybrids. Each hybrid will only differ in the messages mi that are encrypted, and each adjacent hybrid will only differ in a single message. The first hybrid will encrypt m (L) i , and the last hybrid will encrypt m (R) i . Thus, by applying the single-challenge security for each hybrid, we conclude that the first and last hybrids are indistinguishable, thus showing many-challenge security.\nHybrid j for j \u2264 q.\nmi =\n{ min(m\n(L) i ,m (R) i ) if i \u2264 j\nm (L) i if i > j\nFirst, notice that all the mi are in order since both sequences m (L) i and m (R) i are in order. Second, the only difference between Hybrid (j \u2212 1) and Hybrid j is that mj = m(L)j in Hybrid (j \u2212 1) and mj = min(m (L) j ,m (R) j ) in Hybrid j. Thus, single-challenge security implies that each adjacent hybrid is indistinguishable. Moreover, for j where m (L) j < m (R) j , the two hybrids are actually identical.\nHybrid j for j > q.\nmi =\n{ min(m\n(L) i ,m (R) i ) if i \u2264 2q \u2212 j\nm (R) i if i > 2q \u2212 j\nAgain, notice that all the mi are in order. Moreover, the only different between Hybrid (2q\u2212j) and Hybrid (2q\u2212 j + 1) is that mj = min(m(L)j ,m (R) j ) in Hybrid (2q\u2212 j) and mj = m (R) j in Hybrid (2q\u2212 j + 1). Thus, single-challenge security implies that each adjacent hybrid is indistinguishable. Moreover, for j where m\n(L) j > m (R) j , the two hybrids are actually identical.\n3 The Concept Class EncThresh and its Learnability\nLet (Gen,Enc,Dec,Comp) be a statically secure ORE scheme with strongly correct comparison. We define a concept class EncThresh, which intuitively captures the class of threshold functions where examples are encrypted under the ORE scheme. Throughout this discussion, we will take N = 2` and regard the plaintext space of the ORE scheme to be [N ] = {1, . . . , N}. Ideally we would like, for each threshold t \u2208 [N + 1] and each (sk, params)\u2190 Gen(1\u03bb), to define a concept\nft,sk,params(c) =\n{ 1 if Decsk(c) < t\n0 otherwise.\nHowever, we need to make a few technical modifications to ensure that EncThresh is efficiently PAC learnable.\n1. In order for the learner to be able to use the comparison function Comp, it must be given the public parameters params generated by the ORE scheme. We address this in the natural way by attaching a set of public parameters to each example. Moreover, we define EncThresh so that each concept is supported on the single set of public parameters that corresponds to the secret key used for encryption and decryption.\n2. Only a subset of binary strings form valid (sk, params) pairs that are actually produced by Gen in the ORE scheme. To represent concepts, we need a reasonable encoding scheme for these valid pairs. The encoding scheme we choose is the polynomial-length sequence of random coin tosses used by the algorithm Gen to produce (sk, params).\nWe now formally describe the concept class EncThresh. Each concept is parameterized by a string r, representing the coin tosses of the algorithm Gen, and a threshold t \u2208 [N + 1] for N = 2`. In what follows, let (skr, paramsr) be the keys output by Gen(1\u03bb, 1`) when run on the sequence of coin tosses r. Let\nft,r(params, c) = { 1 if (params = paramsr) \u2227 (Dec(skr, c) 6= \u22a5) \u2227 (Dec(skr, c) < t) 0 otherwise.\nNotice that given t and r, the concept ft,r can be efficiently evaluated. The description length k of the instance space Xk = {0, 1}k is polynomial in the security parameter \u03bb and plaintext length `.\n3.1 An Efficient PAC Learner for EncThresh\nWe argue that EncThresh is efficiently PAC learnable by formalizing the argument from the introduction. Because we need to include the ORE public parameters in each example, the PAC learner L (Algorithm 3) for EncThresh actually works in two stages. In the first stage, L determines whether there is significant probability mass on examples corresponding to some public parameters params. Recall that each concept in EncThresh is supported on exactly one such set of parameters. If there is no significant mass on any params, then the all-zeroes hypothesis is a good hypothesis. On the other hand, if there is a heavy set of parameters, the learner L applies Comp using those parameters to learn a good comparator.\nTheorem 3.1. Let \u03b1, \u03b2 > 0. There exists a PAC learning algorithm L for the concept class EncThresh achieving error \u03b1 and confidence 1 \u2212 \u03b2. Moreover, L is efficient (running in time polynomial in the parameters k, 1/\u03b1, log(1/\u03b2)).\nProof. Fix a target concept ft,r \u2208 EncThreshk and a distribution D on examples. First observe that the learner L always outputs a hypothesis with one-sided error, i.e. we always have h \u2264 ft,r pointwise. Also observe that ft\u2032,r \u2264 ft,r pointwise for any t\u2032 < t. These both follow from the strong correctness of the ORE scheme. Let (skr, paramsr) denote the keys output by Gen(1\u03bb, 1`) when run on the sequence of coin tosses r. Let POS denote the set of examples (params, c) on which ft,r(params, c) = 1. We divide the analysis of the learner in to two cases based on the weight D places on POS.\nAlgorithm 1 Learner L for EncThresh\n1. Request examples {(params1, c1, b1), . . . , (paramsn, cn, bn)} for n = dlog(1/\u03b2)/\u03b1e.\n2. Identify an i for which bi = 1 and set params \u2217 = paramsi; if no such i exists, return h \u2261 0.\n3. Let G = {j : paramsj = params\u2217, bj = 1}. Let j\u2217 \u2208 G be an index with Comp(params\u2217, cj , cj\u2217) \u2208 {<,=,\u22a5} for all j \u2208 G.\n4. Return h defined by\nh(params, c) = { 1 if (params = params\u2217) \u2227 (Comp(params\u2217, c, cj\u2217) \u2208 {<,=}) 0 otherwise.\nCase 1: D places weight at least \u03b1 on POS. Define t\u0302 \u2208 [N + 1] as the largest t\u0302 \u2264 t such that errorD(ft\u0302,r, ft,r) \u2265 \u03b1. Such a t\u0302 is guaranteed to exist since f0,r is the all-zeros function, and therefore errorD(f0,r, ft,r) is equal to the weight D places on POS, which is at least \u03b1.\nSuppose ft\u0302+1,r \u2264 h pointwise. Since h has one-sided error (that is, h \u2264 ft,r pointwise), we have errorD(ft\u0302+1,r, ft,r) = errorD(ft\u0302+1,r, h) + errorD(h, ft,r), or\nerrorD(h, ft,r) = errorD(ft\u0302+1,r, ft,r)\u2212 errorD(ft\u0302+1,r, h) \u2264 errorD(ft\u0302+1,r, ft,r) < \u03b1.\nTherefore, it suffices to show that ft\u0302+1,r \u2264 h with probability at least 1 \u2212 \u03b2. This is guaranteed as long as L receives a sample (paramsr, ci, 1) with t\u0302 \u2264 Dec(skr, ci) < t. In other words, ft,r(params r, ci) = 1 and ft\u0302,r(params r, ci) = 0. Since ft\u0302,r \u2264 ft,r pointwise, such samples exactly account for the error between ft\u0302,r and ft,r. Thus since errorD(ft\u0302,r, ft,r) \u2265 \u03b1, for each i it must be that t\u0302 \u2264 Dec(skr, ci) < t with probability at least \u03b1. The learner L therefore receives some sample ci with t\u0302 \u2264 Dec(skr, ci) < t with probability at least 1 \u2212 (1 \u2212 \u03b1)n \u2265 1 \u2212 \u03b2 (since we took n \u2265 log(1/\u03b2)/\u03b1).\nCase 2: D places less than \u03b1 weight on POS. Then the identically zero hypothesis has error at most \u03b1, so the claim holds because 0 \u2264 h \u2264 ft,r.\n3.2 Hardness of Privately Learning EncThresh\nWe now prove the hardness of privately learning EncThresh by constructing an example reidentification scheme for this concept class. Recall that an example reidentification scheme consists of two algorithms, Genex, which selects a distribution, a concept, and examples to give to a learner, and Traceex which attempts to identify one of the examples the learner received.\nOur example reidentification scheme yields a hard distribution even for weak-learning, where the error parameter \u03b1 is taken to be inverse-polynomially close to 1/2.\nTheorem 3.2. Let \u03b3(n) and \u03be(n) be noticeable functions. Let (Gen,Enc,Dec,Comp) be a statically single-challenge secure ORE scheme. Then there exists an (efficient) (\u03b1 = 12 \u2212 \u03b3, \u03be)-example reidentification scheme (Genex,Traceex) for the concept class EncThresh.\nWe start with an informal description of the scheme (Genex,Traceex). The algorithm Genex sets up the parameters of the ORE scheme, chooses the \u201cmiddle\u201d threshold concept corresponding to t = N/2, and sets the distribution on examples to be encryptions of uniformly random messages (together with the correct public parameters needed for comparison). Let m1 < m2 < \u00b7 \u00b7 \u00b7 < mn denote the sorted sequence of messages whose encryptions make up the sample produced by Genex (with overwhelming probability, they are indeed distinct). We can thus break the plaintext space up into buckets of the formBi = [mi,mi+1). Suppose L is a (weak) learner that produces a hypothesis h with advantage \u03b3 over random guessing. Such a hypothesis hmust be able to distinguish encryptions of messages m \u2264 t from encryptions of messages m > t with advantage \u03b3. Thus, there must be a pair of adjacent buckets Bi\u22121, Bi for which h can distinguish encryptions of messages from Bi\u22121 from encryptions from Bi with advantage \u03b3 n .\nThis observation leads to a natural definition for Traceex: locate a pair of adjacent buckets Bi\u22121, Bi that h distinguishes, and output the identity i of the example separating those buckets. Completeness of the resulting scheme, i.e. the fact that some example is reidentified when L succeeds, follows immediately from the preceding discussion. We argue soundness, i.e. that an example absent from L\u2019s sample is not identified, by reducing to the static security of the ORE scheme. The intuition is that if L is not given example i, then it should not be able to distinguish encryptions from bucket Bi\u22121 from encryptions from bucket Bi.\nTo make the security reduction somewhat more precise, suppose for the sake of contradiction that there is an efficient algorithm L that violates the soundness of (Genex,Traceex) with noticeable probability \u03be. That is, there is some i such that even without example i, the algorithm L manages to produce (with probability \u03be) a hypothesis h that distinguishes Bi\u22121 from Bi. A natural first attempt to violate the security of the ORE is to construct an adversary that challenges on the message sequences m1 < \u00b7 \u00b7 \u00b7 < mi\u22121 < m(L)i < mi+1, <,mn and m1 < \u00b7 \u00b7 \u00b7 < mi\u22121 < m (R) i < mi+1 < \u00b7 \u00b7 \u00b7 < mn, where m (L) i is randomly chosen from Bi\u22121 and m (R) i is randomly chosen from Bi. Then if h can distinguish Bi\u22121 from Bi, the adversary can distinguish the two sequences. Unfortunately, this approach fails for a somewhat subtle reason. The hypothesis h is only guaranteed to distinguish Bi\u22121 from Bi with probability \u03be. If h fails to distinguish the buckets \u2013 or distinguishes them in the opposite direction \u2013 then the adversary\u2019s advantage is lost.\nTo overcome this issue, we instead rely on the security of the ORE for sequences that differ on two messages. For the \u201cleft\u201d challenge, our adversary samples two messages from the same randomly chosen bucket, Bi\u22121 or Bi (in addition to requesting encryptions of m1, . . . ,mi\u22121,mi, . . . ,mn). For the \u201cright\u201d challenge, it samples one message from each bucket Bi\u22121 and Bi. Let c\n0 and c1 be the ciphertexts corresponding to thee challenge messages. If h agrees on c0 and c1, then this suggests the messages are from the same bucket, and the adversary should guess \u201cleft\u201d. On the other hand, if h disagrees on c0 and c1, then the adversary should guess \u201cright\u201d. If h distinguishes the buckets Bi\u22121 and Bi, this adversary does strictly better than random guessing. On the other hand, even if h fails to distinguish the buckets, the adversary does at least as well as random guessing. So overall, it still has a noticeable advantage at the ORE security game.\nWe now give the formal proof of Theorem 3.2.\nProof. We construct an example reidentification scheme for EncThresh as follows. The algorithm Genex fixes the threshold t = N/2 and samples (sk\nr, paramsr) \u2190R Gen(1\u03bb, 1`), yielding a concept ft,r. Let D be the distribution of (paramsr,Enc(skr,m)) for uniformly random m \u2208 [N ]. Let m\u20321, . . . ,m \u2032 n \u2190R [N ], and let m1 \u2264 \u00b7 \u00b7 \u00b7 \u2264 mn be the result of sorting the m\u2032i. Let m0 = 0 and\nmn+1 = N . Since n = poly(k) N , these random messages will be well-spaced. In particular, with overwhelming probability, |mi+1\u2212mi| > 1 for every i, so we assume this is the case in what follows. Genex then sets the samples to be (x1 = (params r,Enc(skr,m\u20321)), . . . , xn = (params r,Enc(skr,m\u2032n))). Let x0 = (params r,Enc(skr,m0)) be a \u201cjunk\u201d example.\nThe algorithm Traceex creates buckets Bi = [mi,mi+1). For each i, let\npi = Pr m\u2208Bi,coins of Enc\n[h(paramsr,Enc(sk,m)) = 1].\nBy sampling random choices of m in each bucket, Traceex can efficiently compute a good estimate p\u0302i \u2248 pi for each i (Lemma 3.3). It then accuses the least i for which p\u0302i\u22121 \u2212 p\u0302i \u2265 \u03b3n , and \u22a5 if none is found.\nLemma 3.3. Let K = 8n 2\n\u03b32 log(9n/\u03be). For each i = 0, . . . , n, let\np\u0302i = 1\nK K\u2211 j=1 h(xj)\nwhere xj = (params r,Enc(skr,mj)) for i.i.d. m1, . . . ,mK \u2190R Bi. Then |p\u0302i \u2212 pi| \u2264 \u03b34n for every i with probability at least 1\u2212 \u03be/4.\nProof. By a Chernoff bound, the probability that any given p\u0302i deviates from pi by more than \u03b3 4n is at most 2 exp(\u2212K\u03b32/8n2) \u2264 \u03be4(n+1) . The lemma follows by a union bound.\nWe first verify completeness for this scheme. Let L be a learner for EncThresh using n examples. If the hypothesis h produced by L is (12\u2212\u03b3)-good, then there exists i0 < i1 such that pi0\u2212pi1 \u2265 2\u03b3. If this is the case, then there must be an i for which pi\u22121 \u2212 pi \u2265 2\u03b3n . Then with probability all but \u03be(n)/2 over the estimates p\u0302i, we have p\u0302i\u22121 \u2212 p\u0302i \u2265 \u03b3n , so some index is accused.\nNow we verify soundness. Fix a PPT L, and let j\u2217 \u2208 [n]. Suppose L violates the soundness of the scheme with respect to j\u2217, i.e.\nPr h\u2190RL(S\u2212j\u2217 ),coins of Genex\n[Traceex(h) = j \u2217] > \u03be.\nWe will use L to construct an adversary A for the ORE scheme that succeeds with noticeable advantage. It suffices to build an adversary for the static (many-challenge) security of ORE, with Theorem 2.9 showing how to convert it to a single-challenge adversary. This many-challenge adversary is presented as Algorithm 2. (While not explicitly stated, the adversary should halt and output a random guess whenever the messages it samples are not well-spaced.)\nLet i\u2217 be such that mi\u2217 = m \u2032 j\u2217 . With probability at least \u03be over the parameters (sk r, paramsr), the choice of messages, the choice of the hypothesis h, and the coins of Traceex, there is a gap p\u0302i\u2217\u22121 \u2212 p\u0302i\u2217 \u2265 \u03b3n . Hence, by Lemma 3.3, there is a gap pi\u2217\u22121 \u2212 pi\u2217 \u2265 \u03b3 2n with probability at least \u03be 2 .\nWe now calculate the advantage of the adversary A. Fix a hypothesis h. For notational simplicity, let p = pi\u2217\u22121 and let q = pi\u2217 . Let y0 = h(params r, c0i\u2217) and y1 = h(params r, c1i\u2217). Then the adversary\u2019s success probability is:\nAlgorithm 2 ORE adversary A\n1. Sample m\u20321, . . . ,m \u2032 n \u2190R [N ], and let m1 \u2264 \u00b7 \u00b7 \u00b7 \u2264 mn be the result of sorting the m\u2032j . Let \u03c0\nbe the permutation on {1, . . . , n} such that m\u03c0(j) = m\u2032j . Let m0 = 0. Let i\u2217 = \u03c0(j\u2217) so that mi\u2217 = m \u2032 j\u2217 .\n2. Construct pairs (m0L,m 1 L) and (m 0 R,m 1 R) as follows. Let B0 = (mi\u2217\u22121,mi\u2217) and B1 =\n(mi\u2217 ,mi\u2217+1). Sample m 0 L \u2264 m1L at random from the same Bj , for a random choice of j \u2208 {0, 1}. Sample m0R \u2190R B0 and m1R \u2190R B1.\n3. Challenge on the pair of sequences m0,m1, . . . ,mi\u2217\u22121,m 1 L,m 2 L,mi\u2217 , . . . ,mn and\nm0,m1, . . . ,mi\u2217\u22121,m 1 R,m 2 R,mi\u2217 , . . . ,mn, receiving ciphertexts c1, . . . , c 0 i\u2217 , c 1 i\u2217 , . . . , cn. For j 6= j\u2217, let c\u2032j = c\u03c0(j) so that c\u2032j is an encryption of m\u2032j .\n4. Set t = N/2 and let S\u2212j\u2217 = { (paramsr, c\u20321, \u03c7(m \u2032 1 \u2264 t)), . . . , (paramsr, c\u2032j\u2217\u22121, \u03c7(m\u2032j\u2217\u22121 \u2264 t)),\n(paramsr, c0, 1), (params r, c\u2032j\u2217+1, \u03c7(m \u2032 j\u2217+1 \u2264 t)), . . . , (paramsr, c\u2032n, \u03c7(m\u2032n \u2264 t)) } = {\n(paramsr, c\u03c0(1), \u03c7(m\u03c0(1) \u2264 t)), . . . , (paramsr, c\u03c0(j\u2217\u22121), \u03c7(m\u03c0(j\u2217\u22121) \u2264 t)), (paramsr, c0, 1), (params r, c\u03c0(j\u2217+1), \u03c7(m\u03c0(j\u2217+1) \u2264 t)), . . . , (paramsr, c\u03c0(n), \u03c7(m\u03c0(n) \u2264 t)) }\nObtain h\u2190R L(S\u2212j\u2217).\n5. Guess b\u2032 = 0 if h(paramsr, c0i\u2217) = h(params r, c1i\u2217). Otherwise guess b \u2032 = 1.\nPr[b\u2032 = b] = 1\n2 (Pr[y0 = y1|b = 0] + Pr[y0 6= y1|b = 1])\n= 1 2 ( 1 2 (p2 + (1\u2212 p)2 + q2 + (1\u2212 q)2) + (1\u2212 pq \u2212 (1\u2212 p)(1\u2212 q))) = 1\n2 +\n1 2 (p\u2212 q)2.\nThus if p\u2212 q \u2265 \u03b32n , then the adversary\u2019s advantage is at least \u03b32 4n2 . On the other hand, even for arbitrary values of p, q, the advantage is still nonnegative. Therefore, the advantage of the strategy is at least \u03be\u03b3 2\n8n2 \u2212 negl(k) (the negl(k) term coming from the assumption that the m\u2032i sampled where\ndistinct), which is a noticeable function of the parameter k. This contradicts the static security of the ORE scheme.\n3.3 The SQ Learnability of EncThresh\nThe statistical query (SQ) model is a natural restriction of the PAC model by which a learner is able to measure statistical properties of its examples, but cannot see the individual examples themselves. We recall the definition of an SQ learner.\nDefinition 3.4 (SQ learning [Kea98]). Let c : X \u2192 {0, 1} be a target concept and let D be a distribution over X. In the SQ model, a learner is given access to a statistical query oracle STAT(c,D). It may make queries to this oracle of the form (\u03c8, \u03c4), where \u03c8 : X \u00d7{0, 1} \u2192 {0, 1} is a query function and \u03c4 \u2208 (0, 1) is an error tolerance. The oracle STAT(c,D) responds with a value v such that |v \u2212 Prx\u2208D[\u03c8(x, c(x)) = 1]| \u2264 \u03c4 . The goal of a learner is to produce, with probability at least 1 \u2212 \u03b2, a hypothesis h : X \u2192 {0, 1} such that errorD(c, h) \u2264 \u03b1. The query functions must be efficiently evaluable, and the tolerance \u03c4 must be lower bounded by an inverse polynomial in k and 1/\u03b1.\nThe query complexity of a learner is the worst-case number of queries it issues to the statistical query oracle. An SQ learner is efficient if it also runs in time polynomial in k, 1/\u03b1, 1/\u03b2.\nFeldman and Kanade [FK12] investigated the relationship between query complexity and computational complexity for SQ learners. They exhibited a concept class C which is efficiently PAC learnable and SQ learnable with polynomially many queries, but assuming NP 6= RP, is not efficiently SQ learnable. Concepts in this concept class take the form\ng\u03c6,y(x, x \u2032) =\n{ PARy(x \u2032) if x = \u03c6\n0 otherwise.\nHere, PARy(x \u2032) is the inner product of y and x\u2032 modulo 2. The concept class C consists of g\u03c6,y where \u03c6 is a satisfiable 3-CNF formula and y is the lexicographically first satisfying assignment to \u03c6. The efficient PAC learner for parities based on Gaussian elimination shows that C is also efficiently PAC learnable. It is also (inefficiently) SQ learnable with polynomially many queries: either the all-zeroes hypothesis is good, or an SQ learner can recover the formula \u03c6 bit-by-bit and determine the satisfying assignment y by brute force. On the other hand, because parities are information-theoretically hard to SQ learn, the satisfying assignment y remains hidden to an SQ learner unless it is able to solve 3-SAT.\nIn this section, we show that the concept class EncThresh shares these properties with C. Namely, we know that EncThresh is efficiently PAC learnable and because it is not efficiently privately learnable, it is not efficiently SQ learnable [BDMN05]. We can also show that EncThresh has an SQ learner with polynomial query complexity. Making this observation about EncThresh is of interest because the hardness of SQ learning EncThresh does not seem to be related to the (informationtheoretic) hardness of SQ learning parities.\nProposition 3.5. The concept class EncThresh is (inefficiently) SQ learnable with polynomially many queries.\nAs with C there are two cases. In the first case, the target distribution places nearly zero weight on examples with params = paramsr, and so the all-zeroes hypothesis is good. In the second case, the target distribution places noticeable weight on these examples, and our learner can use statistical queries to recover the comparison parameters paramsr bit-by-bit. Once the public parameters are recovered, our learner can determine a corresponding secret key by brute force. Lemma 3.6 below shows that any corresponding secret key \u2013 even one that is not actually skr \u2013 suffices. The learner can then use binary search to determine the threshold value t.\nProof. Let ft,r be the target concept, D be the target distribution, and \u03b1 be the target error rate. With the statistical query (x\u00d7 b 7\u2192 b, \u03b1/4), we can determine whether the all-zeroes hypothesis is\naccurate. That is, if we receive a value that is less than \u03b1/2, then Prx\u2208D[ft,r(x) = 1] \u2264 \u03b1. If not, then we know that Prx\u2208D[ft,r(x) = 1] \u2265 \u03b1/4, so D places significant weight on examples prefixed with paramsr. Suppose now that we are in the latter case.\nLet m = |params|. For i = 1, . . . ,m, define \u03c8i(params, c, b) = 1 if paramsi = 1 and b = 1, and \u03c8i(params, c, b) = 0 otherwise. Then by asking the queries (\u03c8i, \u03b1/16), we can determine each bit paramsri of params\nr. Now by brute force search, we determine a secret key sk for which (sk, paramsr) \u2208 Range(Gen). The recovered secret key sk may not necessarily be the same as skr. However, the following lemma shows that sk and skr are functionally equivalent:\nLemma 3.6. Suppose (Gen,Enc,Dec,Comp) is a strongly correct ORE scheme. Then for any pair (sk1, params), (sk2, params) \u2208 Range(Gen), we have that Decsk1(c) = Decsk2(c) for all ciphertexts c.\nWith the secret key sk in hand, we now conduct a binary search for the threshold t. Recall that we have an estimate v for the weight that ft,r places on positive examples, i.e. |v\u2212Prx\u2208D[ft,r(x) = 1]| \u2264 \u03b1/4. Starting at t1 = N/2, we issue the query (\u03d51, \u03b1/4) where \u03d51(params, c, b) = 1 iff params = paramsr and Dec(sk, c) < t. Let ht1 denote the hypothesis\nht1(params, c) = { 1 if (params = paramsr) \u2227 (Dec(sk, c) 6= \u22a5) \u2227 (Dec(sk, c) < t1) 0 otherwise.\nThus, the query (\u03d51, \u03b1/4) approximates the weight ht1 places on positive examples. Let the answer to this query be v1. If |v1 \u2212 v| \u2264 \u03b1/2, then we can halt and output the good hypothesis ht1 . Otherwise, if v1 < v \u2212 \u03b1/2, we set the next threshold to t2 = 3N/4, and if v1 > v + \u03b1/2, we set the next threshold to t2 = N/4. We recurse up to logN = ` = poly(k) times, yielding a good hypothesis for ft,r.\nProof of Lemma 3.6. Suppose the lemma is not true. First suppose that there exists a ciphertext c such that Dec(sk1, c) = p1 < p2 = Dec(sk2, c). Let c\n\u2032 \u2208 Enc(sk1, p2). Then by strong correctness applied to the parameters (sk1, params), we must have Comp(params, c, c\n\u2032) = \u201c<\u201d. Now by strong correctness applied to (sk2, params), we must have Dec(sk2, c \u2032) > p2. Thus, p1 < Dec(sk1, c \u2032) = p2 < Dec(sk2, c \u2032). Repeating this argument, we obtain a contradiction because the message space is finite. Now suppose instead that there is a ciphertext c for which Dec(sk1, c) = p \u2208 [N ], but Dec(sk2, c) = \u22a5. Let c\u2032 \u2208 Enc(sk1, p\u2032) for some p\u2032 > p. Then Comp(params, c, c\u2032) = \u201c<\u201d by strong correctness applied to (params, sk1). But Comp(params, c, c\n\u2032) = \u201c\u22a5\u201d by strong correctness applied to (params, sk2), again yielding a contradiction."}, {"heading": "4 ORE with Strong Correctness", "text": "We now explain how to obtain ORE with strongly correct comparison, as all prior ORE schemes only satisfy the weaker notion of correctness. The lack of strong correctness is easiest to see with the scheme of Boneh et al. [BLR+15]. The protocol is built from current multilinear map constructions, which are noisy. If the noise terms grow too large, the correctness of the multilinear map is not guaranteed. The comparison function in [BLR+15] is computed by performing multilinear operations, and for correctly generated ciphertexts, the operations will give the right answer. However, there exist ciphertexts, namely those with very large noise, for which the comparison function\ngives an incorrect output. The result is that the comparison operation is not guaranteed to be consistent with decrypting the ciphertexts and comparing the plaintexts.\nAs described in the introduction, we give a generic conversion from any ORE scheme with weakly correct comparison into a strongly correct scheme. We simply modify the encryption algorithm by adding a non-interactive zero-knowledge (NIZK) proof that the resulting ciphertext is well-formed. Then the decryption and comparison procedures check the proof(s), and only output a non-\u22a5 result (either decryption or comparison) if the proof(s) are valid.\nInstantiating our scheme. In our construction, we need the (weak) correctness of the underlying ORE scheme to hold with probability one. However, the existing protocols only have correctness with overwhelming probability, so some minor adjustments need to be made to the protocols. This is easiest to see in the ORE scheme of Boneh et al. [BLR+15]. The Boneh et al. scheme uses noisy multilinear maps [GGH13a] which may introduce errors. Therefore, the protocol described in [BLR+15] only achieves the (weak) correctness property with overwhelming probability, whereas we will require (weak) correctness with probability 1 for the conversion. However, it is straightforward to generate the parameters for the protocol in such a way as to completely eliminate errors. Essentially, the parameters in the protocol have an error term that is generated by a (discrete) Gaussian distribution, which has unbounded support. Instead, we truncate the Gaussian, resulting in a noise distribution with bounded support. By truncating sufficiently far from the center, the resulting distribution is also statistically close to the full Gaussian, so security of the protocol with truncated noise follows from the security of the protocol with un-truncated noise. By truncating the noise distribution, it is straightforward to set parameters so that no errors can occur.\nIt is similarly straightforward to modify current obfuscation candidates, which are also built from multilinear maps, to obtain perfect (weak) correctness by truncating the noise distributions. Thus, our scheme has instantiations using multilinear maps or iO."}, {"heading": "4.1 Conversion from Weakly Correct ORE", "text": "We describe our generic conversion from an order-revaling encryption scheme with weak correctness using NIZKs. We will need the following additional tools:\nPerfectly binding commitments. A perfectly binding commitment Com is a randomized algorithm with two properties. The first is perfect binding, which states that if Com(m; r) = Com(m\u2032; r\u2032), then m = m\u2032. The second requirement is computational hiding, which states that the distributions Com(m) and Com(m\u2032) are computationally indistinguishable for any messages m,m\u2032. Such commitments can be built, say, from any injective one-way function.\nPerfectly sound NIZK. A NIZK protocol consists of three algorithms:\n\u2022 Setup(1\u03bb) is a randomized algorithm that outputs a common reference string crs.\n\u2022 Prove(crs, x, w) takes as input a common reference string crs, an NP statement x, and a witness w, and produces a proof \u03c0.\n\u2022 Ver(crs, x, \u03c0) takes as input a common reference string crs, statement x, and a proof \u03c0, and outputs either accept or reject.\nWe make three requirements for a NIZK:\n\u2022 Perfect Completeness. For all security parameters \u03bb and any true statement x with witness w,\nPr[Ver(crs, x, \u03c0) = accept : crs\u2190 Setup(1\u03bb);\u03c0 \u2190 Prove(crs, x, w)] = 1.\n\u2022 Perfect Soundness. For all security parameters \u03bb, any false statement x and any (invalid) proof \u03c0,\nPr[Ver(crs, x, \u03c0) = accept : crs\u2190 Setup(1\u03bb)] = 0.\n\u2022 Computational Zero Knowledge. There exists a simulator S1,S2 such that for any computationally bounded adversary A, the quantity\n\u2016Pr[AProve(crs,\u00b7,\u00b7)(crs) = 1 : crs\u2190 Setup(1\u03bb)]\u2212 Pr[ASim(crs,\u03c4,\u00b7,\u00b7)(crs) = 1 : (crs, \u03c4)\u2190 S1(1\u03bb)]\u2016\nis negligible, where Sim(crs, \u03c4, x, w) outputs S2(crs, \u03c4, x) if w is a valid witness for x, and Sim(crs, \u03c4, x, w) = \u22a5 if w is invalid.\nNIZKs satisfying these requirements can be built from bilinear maps [GOS12]."}, {"heading": "4.1.1 The Construction", "text": "We now give our conversion. Let (Setup,Prove,Ver) be a perfectly sound NIZK and (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032) and ORE with weakly correct comparison. We will assume that Enc\u2032 is deterministic; if not, we can derandomize Enc\u2032 using a pseudorandom function. Let Com be a perfectly binding commitment. We construct a new ORE scheme (Gen,Enc,Dec,Comp) with strongly correct comparison:\n\u2022 Gen(1\u03bb, 1`): run (sk\u2032, params\u2032) \u2190 Gen\u2032(1\u03bb, 1`). Let \u03c3 = Com(sk; r) for randomness r, and run crs \u2190 Setup(1\u03bb). Then the secret key is sk = (sk\u2032, r, crs) and the public parameters are params = (params\u2032, \u03c3, crs).\n\u2022 Enc(sk,m): Compute c\u2032 = Enc\u2032(sk\u2032,m). Let xc\u2032 be the statement \u2203m\u0302, s\u0302k \u2032 , r\u0302 : \u03c3 = Com(s\u0302k \u2032 , r\u0302)\u2227\nc\u2032 = Enc\u2032(s\u0302k \u2032 , m\u0302). Run \u03c0c\u2032 = Prove(crs, xc\u2032 , (m, sk \u2032, r) ). Output the ciphertext c = (c\u2032, \u03c0c\u2032).\n\u2022 Dec(sk, c): Write c = (c\u2032, \u03c0c\u2032). If Ver(crs, xc\u2032 , \u03c0c\u2032) = reject, output \u22a5. Otherwise, output m = Dec\u2032(sk\u2032, c\u2032).\n\u2022 Comp(params, c0, c1); white cb = (c\u2032b, \u03c0c\u2032b) and params = (params \u2032, \u03c3, crs). If Ver(crs, xc\u2032b , \u03c0c \u2032 b ) =\nreject for either b = 0, 1, then output \u22a5. Otherwise, output Comp\u2032(params\u2032, c\u20320, c\u20321).\nCorrectness. Notice that, for each plaintext m, the ciphertext component c\u2032 = Enc\u2032(sk\u2032,m) is the unique value such that Dec(sk, (c\u2032, \u03c0)) = m for some proof \u03c0. Moreover, the completeness of the zero knowledge proof implies that Enc(sk,m) outputs a valid proof. Decryption correctness follows.\nFor strong comparison correctness, consider two ciphertexts c0, c1 where cb = (c \u2032 b, \u03c0c\u2032b). Suppose both proofs \u03c0c\u2032b are valid, which means that verification passes when running Comp and so\nComp(params, c0, c1) = Comp \u2032(params\u2032, c\u20320, c \u2032 1). Verification also passes when decrypting cb, and so Dec(sk, cb) = Dec \u2032(sk\u2032, c\u2032b).\nSince the proofs are valid, c\u2032b = Enc \u2032(sk\u2032,mb) for some mb for both b = 0, 1. The weak correctness of comparison for (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032) implies that Comp\u2032(params\u2032, c\u20320, c \u2032 1) = Compplain(m0,m1). The decryption correctness of (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032) then implies that Dec(sk\u2032, c\u2032b) = mb, and therefore Dec(sk, cb) = mb. Thus Compciph(sk, c0, c1) = Compplain(m0,m1). Putting it all together, Comp(params, c0, c1) = Compciph(sk, c0, c1), as desired.\nNow suppose one of the proofs \u03c0c\u2032b are invalid. Then Comp(params, c0, c1) = \u22a5 and Dec(sk, cb) = \u22a5. This means Compciph(sk, c0, c1) = \u22a5 = Comp(params, c0, c1), as desired.\nSecurity. To prove security, we first use the zero-knowledge simulator to simulate the proofs \u03c0\u2032c without using a witness (namely, the secret decryption key). Then we use the hiding property of the commitment to replace \u03c3 with a commitment to 0. At this point, the entire game can be simulated using an Enc\u2032 oracle, and so the security reduces to the security of Enc\u2032.\nTheorem 4.1. If (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032) is a (statically) secure ORE, (Setup,Prove,Ver) is computationally zero knowledge, and Com is computationally hiding, then (Gen,Enc,Dec,Comp) is a statically secure ORE.\nProof. We will prove security through a sequence of hybrids. Let A be an adversary with advantage in breaking the static security of (Gen,Enc,Dec,Comp).\nHybrid 0. This is the real experiment, where \u03c3 \u2190 Com(sk), crs \u2190 Setup(1\u03bb), and the proofs \u03c0c\u2032 are answered using Prove and valid witnesses. A has advantage in distinguishing the left and right ciphertexts.\nHybrid 1. This is the same as Hybrid 0, except that crs is generated as (crs, \u03c4)\u2190 S1(1\u03bb), and all proofs are generated using S2(crs, \u03c4, \u00b7). The zero knowledge property of (Setup,Prove,Ver) shows that this is indistinguishable from Hybrid 0.\nHybrid 2. This is the same as Hybrid 1, except that \u03c3 \u2190 Com(0). Since the randomness for computing \u03c3 is not needed for simulation, this change is undetectable using the hiding of Com.\nThus the advantage of A in Hybrid 2 is at least \u2212negl for some negligible function negl. Now consider the following adversary cB that attempts to break the security of (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032). B simulates A, and forwards the message sequences m(L)1 < m (L) 2 < \u00b7 \u00b7 \u00b7 < m (L) q and m (R) 1 < m (R) 2 < \u00b7 \u00b7 \u00b7 < m(R)q produced by A to its own challenger. In response, it receives params\u2032, and ciphertexts c\u2032i, where c\u2032i encrypts either m (L) i if b = 0 or m (R) i if b = 1, for a random bit b chosen by the challenger.\nB now generates \u03c3 \u2190 Com(0) and (crs, \u03c4)\u2190 S1(1\u03bb), and lets params = (params\u2032, \u03c3, crs). It also computes \u03c0c\u2032i \u2190 S2(crs, \u03c4, xc\u2032i), and defines ci = (c \u2032 i, \u03c0c\u2032i), and gives params and the ci to A. Finally when A outputs a guess b\u2032 for b, B outputs the same guess b\u2032. We see that the view of A as a subroutine of B is exactly the same view as in Hybrid 2. Thus, b\u2032 = b with probability at least \u2212 negl. The security of (Gen\u2032,Enc\u2032,Dec\u2032,Comp\u2032) implies that this quantity, and hence , must be negligible. Thus A must have negligible advantage in breaking the security of (Gen,Enc,Dec,Comp)."}, {"heading": "5 A Separation for Representation Learning", "text": "In this section, we show how to construct a concept class ValidSig that separates efficient representation learning from efficient private representation learning, assuming only the existence of one-way functions. Here by \u201crepresentation learning\u201d we mean a restricted form of proper learning where a learner must output a particular representation (i.e. encoding) of a hypothesis h in the concept class C. As with proper learning, this is a natural syntactic restriction to place on a learner: for instance, if one wants to learn linear threshold functions (LTF), it makes sense to require a learner to produce the actual coefficients of an LTF, rather than an arbitrary circuit that happens to compute an LTF.\nThe construction is based on the following elegant idea due to Kobbi Nissim [Nis14]. Suppose H : D \u2192 R is a cryptographic hash function with the property that given x1, . . . , xn with y = H(x1) = \u00b7 \u00b7 \u00b7 = H(xn), it is infeasible for an efficient adversary to find another x for which H(x) = y. Consider the concept class HashPoint consisting of the concepts\nfx(x \u2032) =\n{ 1 if H(x) = H(x\u2032)\n0 otherwise.\nfor every x \u2208 R. The representation of a concept fx is the point x. The concept class HashPoint is very easy to learn (by representation) without privacy: a learner can identify any positive example xi and output the representation xi. Since H(xi) = H(x), the concept fxi is actually equal to the target concept fx. On the other hand, a learner that identifies an index x\n\u2217 for which fx\u2217 = fx cannot be differentially private, since the security of the hash function means it is infeasible to produce such an x\u2217 that is not present in the sample.\nNote that this argument breaks down if one tries to show that HashPoint is not privately properly learnable. While it is infeasible to privately produce a representation x\u2217 for which fx\u2217 is a good hypothesis, the hypothesis h(x) = \u03c7(H(x) = h(xi)) is equal as a function to every good fx\u2217 . Moreover, this hypothesis can be constructed privately as long as the sample contains sufficiently many positive examples.\nWe make this discussion formal by constructing a concept class ValidSig based on super-secure digital signature schemes, which can be constructed from one-way functions. Our use of signatures to derive hardness results for private proper learning is very analogous to prior hardness results for synthetic data generation [DNR+09, UV11].\nDefinition 5.1. A digital signature scheme is a triple of algorithms (Gen,Sign,Ver) where\n\u2022 Gen(1\u03bb) produces a key pair (sk, vk).\n\u2022 Sign(sk,m) takes the private signing key sk and a message m \u2208 {0, 1}\u2217 and produces a signature \u03c3 for the message m.\n\u2022 Ver(vk,m, \u03c3) takes the public verification key vk, a message m, and a signature \u03c3, and (deterministically) outputs a bit indicating whether \u03c3 is a valid signature for m.\nThe correctness property of a digital signature scheme is that for every (sk, vk)\u2190R Gen(1\u03bb), every message m \u2208 {0, 1}\u2217, and every signature \u03c3 \u2190R Sign(sk,m), we have Ver(vk,m, \u03c3) = 1.\nDefinition 5.2. A digital signature scheme is super-secure under adaptive chosen-plaintext attacks if all efficient adversaries A win the following weak forgery game with negligible probability:\n\u2022 The challenger samples (sk, vk)\u2190R Gen(1\u03bb).\n\u2022 The adversary A is given vk and oracle access to Sign(sk, \u00b7). It adaptively queries the signing oracle, obtaining a sequence of message-signature pairs A. It then outputs a forgery (m\u2217, \u03c3\u2217).\n\u2022 The value of the game is 1 iff Ver(vk,m\u2217, \u03c3\u2217) = 1 and (m\u2217, \u03c3\u2217) /\u2208 A.\nIt is known that super-secure digital signature schemes can be constructed from one-way functions [NY89, Rom90, KK05, Gol04].\nWe now describe our concept class ValidSig. Let (Gen,Sign,Ver) be a super-secure digital signature scheme. We define a concept class ValidSig as follows. Fix the message length `. For every (vk,m, \u03c3) with m \u2208 {0, 1}` and Ver(vk,m, \u03c3) = 1, define the concept\nfvk,m,\u03c3(vk \u2032,m\u2032, \u03c3\u2032) = { 1 if (vk = vk\u2032) \u2227 (Ver(vk,m\u2032, \u03c3\u2032) = 1) 0 otherwise.\nFor convenience, we also include the all-zeroes hypothesis in ValidSig, with representation \u22a5.\nTheorem 5.3. Let \u03b1, \u03b2 > 0. There exists a proper PAC learning algorithm L for the concept class ValidSig achieving error \u03b1 and confidence 1 \u2212 \u03b2. Moreover, L is efficient (running in time polynomial in the parameters k, 1/\u03b1, log(1/\u03b2)).\nAlgorithm 3 Learner L for ValidSig\n1. Request examples {((vk\u20321,m\u20321, \u03c3\u20321), b1), . . . , ((vk\u2032n,m\u2032n, \u03c3\u2032n), bn)} for n = dlog(1/\u03b2)/\u03b1e.\n2. Identify an i for which bi = 1 and return the representation (vk \u2032 i,m \u2032 i, \u03c3 \u2032 i). If no such i exists,\nreturn \u22a5 representing the all-zeroes hypothesis.\nProof. Fix a target concept fvk,m,\u03c3 \u2208 ValidSigk and a distribution D on examples. Let POS denote the set of examples (vk\u2032,m\u2032, \u03c3\u2032) on which fvk,m,\u03c3(vk\n\u2032,m\u2032, \u03c3\u2032) = 1. We divide the analysis of the learner into three cases based on the weight D places on the sets POS.\nCase 1: D places at least \u03b1 weight on POS. Then L receives a positive example with probability at least 1\u2212 (1\u2212\u03b1)n \u2265 1\u2212 \u03b2, and is thus able to identify a concept that equals the target concept.\nCase 2: D places less than \u03b1 weight on POS. If L gets a positive example, then the analysis of Case 1 applies. Otherwise, the all-zeroes hypothesis is \u03b1-good.\nWe now prove the hardness of properly privately learning ValidSig by constructing an example reidentification scheme for properly learning this concept class. Our example reidentification scheme yields a hard distribution even when the error parameter \u03b1 is taken to be inverse-polynomially close to 1.\nTheorem 5.4. Let \u03b3(n) and \u03be(n) be noticeable functions. Let (Gen,Sign,Ver) be a super-secure digital signature scheme. Then there exists an (efficient) (\u03b1 = 1 \u2212 \u03b3, \u03be)-example reidentification scheme (Genex,Traceex) for representation learning the concept class ValidSig.\nWe now give the proof of Theorem 5.4.\nProof. We construct an example reidentification scheme for ValidSig as follows. The algorithm Genex samples (sk, vk) \u2190R Gen(1\u03bb), a message m \u2208 {0, 1}`, and a signature \u03c3 \u2190R Sign(sk,m), yielding a concept fvk,m,\u03c3. Let D be the distribution of (vk,m,Sign(sk,m)) for random m \u2190R {0, 1}`. Genex then samples x0, x1, . . . , xn i.i.d. from D. Given a representation (vk\u2217,m\u2217, \u03c3\u2217), the algorithm Traceex simply identifies an index i for which xi = (vk\n\u2217,m\u2217, \u03c3\u2217), and outputs \u22a5 if none is found. We first verify completeness for this scheme. Let L be a learner for ValidSig using n examples. If the representation (vk\u2217,m\u2217, \u03c3\u2217) produced by L represents an (1\u2212 \u03b3)-good hypothesis, then it must be the case that vk\u2217 = vk and Ver(vk,m\u2217, \u03c3\u2217) = 1. Thus, if L violates the completeness condition, it can be used to construct the weak forgery adversary A (Figure 4) that succeeds with noticeable probability \u03be.\nAlgorithm 4 Weak forgery adversary A\n1. Query the signing oracle on random messages m\u20321, . . . ,m \u2032 n \u2190R {0, 1}`, obtaining signatures\n\u03c3\u20321, . . . , \u03c3 \u2032 n.\n2. Run L on the labeled examples ((vk,m\u20321, \u03c3 \u2032 1), 1), . . . , ((vk,m \u2032 n, \u03c3 \u2032 n), 1), obtaining a representa-\ntion (m\u2217, \u03c3\u2217).\n3. Output the forgery (m\u2217, \u03c3\u2217).\nNow we verify soundness for the scheme. Observe that for any i, the sample S\u2212i contains no information about message mi. Therefore, the learner has a 2\n\u2212` = negl(k) probability at producing a representation containing message mi, proving soundness.\nAcknowledgements. We gratefully acknowledge Kobbi Nissim and Salil Vadhan for helpful discussions about this work, and also thank Salil Vadhan for suggestions on its presentation."}], "references": [{"title": "Order-preserving encryption revisited: Improved security analysis and alternative solutions", "author": ["Alexandra Boldyreva", "Nathan Chenette", "Adam O\u2019Neill"], "venue": "In CRYPTO,", "citeRegEx": "Boldyreva et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boldyreva et al\\.", "year": 2011}, {"title": "Practical privacy: the SuLQ framework", "author": ["Avrim Blum", "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim"], "venue": null, "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "Bounds on the sample complexity for private learning and private data release", "author": ["Amos Beimel", "Shiva Prasad Kasiviswanathan", "Kobbi Nissim"], "venue": "In TCC,", "citeRegEx": "Beimel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Beimel et al\\.", "year": 2010}, {"title": "A learning theory approach to noninteractive database privacy", "author": ["Avrim Blum", "Katrina Ligett", "Aaron Roth"], "venue": "In Cynthia Dwork, editor,", "citeRegEx": "Blum et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2008}, {"title": "Semantically secure order-revealing encryption: Multi-input functional encryption without obfuscation", "author": ["Dan Boneh", "Kevin Lewi", "Mariana Raykova", "Amit Sahai", "Mark Zhandry", "Joe Zimmerman"], "venue": "In Proc. of EUROCRYPT,", "citeRegEx": "Boneh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Boneh et al\\.", "year": 2015}, {"title": "Separating distribution-free and mistake-bound learning models over the boolean domain", "author": ["Avrim Blum"], "venue": "SIAM J. Comput.,", "citeRegEx": "Blum.,? \\Q1994\\E", "shortCiteRegEx": "Blum.", "year": 1994}, {"title": "Private learning and sanitization: Pure vs. approximate differential privacy", "author": ["Amos Beimel", "Kobbi Nissim", "Uri Stemmer"], "venue": null, "citeRegEx": "Beimel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Beimel et al\\.", "year": 2013}, {"title": "Differentially private release and learning of threshold functions", "author": ["Mark Bun", "Kobbi Nissim", "Uri Stemmer", "Salil P. Vadhan"], "venue": "CoRR, abs/1504.07553,", "citeRegEx": "Bun et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bun et al\\.", "year": 2015}, {"title": "Machine learning classification over encrypted data", "author": ["Raphael Bost", "Raluca Ada Popa", "Stephen Tu", "Shafi Goldwasser"], "venue": "IACR Cryptology ePrint Archive,", "citeRegEx": "Bost et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bost et al\\.", "year": 2014}, {"title": "Function-private functional encryption in the privatekey setting", "author": ["Zvika Brakerski", "Gil Segev"], "venue": "In TCC,", "citeRegEx": "Brakerski and Segev.,? \\Q2015\\E", "shortCiteRegEx": "Brakerski and Segev.", "year": 2015}, {"title": "Fully collusion resistant traitor tracing with short ciphertexts and private keys", "author": ["Dan Boneh", "Amit Sahai", "Brent Waters"], "venue": "In Proceedings of the 24th Annual International Conference on The Theory and Applications of Cryptographic Techniques,", "citeRegEx": "Boneh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Boneh et al\\.", "year": 2006}, {"title": "Fingerprinting codes and the price of approximate differential privacy", "author": ["Mark Bun", "Jonathan Ullman", "Salil P. Vadhan"], "venue": "In Symposium on Theory of Computing,", "citeRegEx": "Bun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bun et al\\.", "year": 2014}, {"title": "Multiparty key exchange, efficient traitor tracing, and more from indistinguishability obfuscation", "author": ["Dan Boneh", "Mark Zhandry"], "venue": "In Advances in Cryptology - CRYPTO 2014 - 34th Annual Cryptology Conference,", "citeRegEx": "Boneh and Zhandry.,? \\Q2014\\E", "shortCiteRegEx": "Boneh and Zhandry.", "year": 2014}, {"title": "Tracing traitors", "author": ["Benny Chor", "Amos Fiat", "Moni Naor"], "venue": "Yvo Desmedt, editor, CRYPTO,", "citeRegEx": "Chor et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Chor et al\\.", "year": 1994}, {"title": "Sample complexity bounds for differentially private learning", "author": ["Kamalika Chaudhuri", "Daniel Hsu"], "venue": "COLT, volume 19 of JMLR Proceedings,", "citeRegEx": "Chaudhuri and Hsu.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri and Hsu.", "year": 2011}, {"title": "The large margin mechanism for differentially private maximization", "author": ["Kamalika Chaudhuri", "Daniel Hsu", "Shuang Song"], "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Chaudhuri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2014}, {"title": "Faster private release of marginals on small databases", "author": ["Karthekeyan Chandrasekaran", "Justin Thaler", "Jonathan Ullman", "Andrew Wan"], "venue": "ITCS 2014,", "citeRegEx": "Chandrasekaran et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chandrasekaran et al\\.", "year": 2014}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor"], "venue": "In Serge Vaudenay, editor, EUROCRYPT,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith"], "venue": "In Shai Halevi and Tal Rabin, editors, TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "On the complexity of differentially private data release: efficient algorithms and hardness results", "author": ["Cynthia Dwork", "Moni Naor", "Omer Reingold", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2009}, {"title": "Using convex relaxations for efficiently and privately releasing marginals", "author": ["Cynthia Dwork", "Aleksandar Nikolov", "Kunal Talwar"], "venue": "In Proceedings of the Thirtieth Annual Symposium on Computational Geometry,", "citeRegEx": "Dwork et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2014}, {"title": "Boosting and differential privacy. In FOCS, pages 51\u201360", "author": ["Cynthia Dwork", "Guy N. Rothblum", "Salil P. Vadhan"], "venue": "IEEE Computer Society,", "citeRegEx": "Dwork et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2010}, {"title": "Computational bounds on statistical query learning", "author": ["Vitaly Feldman", "Varun Kanade"], "venue": "In COLT 2012 - The 25th Annual Conference on Learning Theory, June", "citeRegEx": "Feldman and Kanade.,? \\Q2012\\E", "shortCiteRegEx": "Feldman and Kanade.", "year": 2012}, {"title": "Sample complexity bounds on differentially private learning via communication", "author": ["Vitaly Feldman", "David Xiao"], "venue": "complexity. CoRR,", "citeRegEx": "Feldman and Xiao.,? \\Q2014\\E", "shortCiteRegEx": "Feldman and Xiao.", "year": 2014}, {"title": "Multi-input functional encryption", "author": ["Shafi Goldwasser", "S. Dov Gordon", "Vipul Goyal", "Abhishek Jain", "Jonathan Katz", "FengHao Liu", "Amit Sahai", "Elaine Shi", "Hong-Sheng Zhou"], "venue": "In EUROCRYPT,", "citeRegEx": "Goldwasser et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goldwasser et al\\.", "year": 2014}, {"title": "Candidate multilinear maps from ideal lattices", "author": ["Sanjam Garg", "Craig Gentry", "Shai Halevi"], "venue": "In Proc. of EUROCRYPT,", "citeRegEx": "Garg et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Garg et al\\.", "year": 2013}, {"title": "Candidate indistinguishability obfuscation and functional encryption for all circuits", "author": ["Sanjam Garg", "Craig Gentry", "Shai Halevi", "Mariana Raykova", "Amit Sahai", "Brent Waters"], "venue": "In Proc. of FOCS,", "citeRegEx": "Garg et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Garg et al\\.", "year": 2013}, {"title": "Fully secure functional encryption without obfuscation", "author": ["Sanjam Garg", "Craig Gentry", "Shai Halevi", "Mark Zhandry"], "venue": null, "citeRegEx": "Garg et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Garg et al\\.", "year": 2014}, {"title": "Ml confidential: Machine learning on encrypted data", "author": ["Thore Graepel", "Kristin Lauter", "Michael Naehrig"], "venue": "Information Security and Cryptology ICISC 2012,", "citeRegEx": "Graepel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graepel et al\\.", "year": 2013}, {"title": "Foundations of cryptography: volume 2, basic applications", "author": ["Oded Goldreich"], "venue": "Cambridge university press,", "citeRegEx": "Goldreich.,? \\Q2004\\E", "shortCiteRegEx": "Goldreich.", "year": 2004}, {"title": "New techniques for noninteractive zero-knowledge", "author": ["Jens Groth", "Rafail Ostrovsky", "Amit Sahai"], "venue": "J. ACM,", "citeRegEx": "Groth et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Groth et al\\.", "year": 2012}, {"title": "Iterative constructions and private data release", "author": ["Anupam Gupta", "Aaron Roth", "Jonathan Ullman"], "venue": "In TCC,", "citeRegEx": "Gupta et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2012}, {"title": "A simple and practical algorithm for differentially private data release", "author": ["Moritz Hardt", "Katrina Ligett", "Frank McSherry"], "venue": null, "citeRegEx": "Hardt et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2012}, {"title": "A multiplicative weights mechanism for privacypreserving data analysis", "author": ["Moritz Hardt", "Guy N. Rothblum"], "venue": "In FOCS,", "citeRegEx": "Hardt and Rothblum.,? \\Q2010\\E", "shortCiteRegEx": "Hardt and Rothblum.", "year": 2010}, {"title": "Private data release via learning thresholds", "author": ["Moritz Hardt", "Guy N. Rothblum", "Rocco A. Servedio"], "venue": "In Dana Randall, editor,", "citeRegEx": "Hardt et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2012}, {"title": "Efficient noise-tolerant learning from statistical queries", "author": ["Michael Kearns"], "venue": "J. ACM,", "citeRegEx": "Kearns.,? \\Q1998\\E", "shortCiteRegEx": "Kearns.", "year": 1998}, {"title": "Cryptographic lower bounds for learnability of boolean functions on the uniform distribution", "author": ["Michael Kharitonov"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Kharitonov.,? \\Q1995\\E", "shortCiteRegEx": "Kharitonov.", "year": 1995}, {"title": "On constructing universal one-way hash functions from arbitrary one-way functions", "author": ["Jonathan Katz", "Chiu-Yuen Koo"], "venue": "IACR Cryptology ePrint Archive,", "citeRegEx": "Katz and Koo.,? \\Q2005\\E", "shortCiteRegEx": "Katz and Koo.", "year": 2005}, {"title": "What can we learn privately", "author": ["Shiva Prasad Kasiviswanathan", "Homin K. Lee", "Kobbi Nissim", "Sofya Raskhodnikova", "Adam Smith"], "venue": "SIAM J. Comput.,", "citeRegEx": "Kasiviswanathan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kasiviswanathan et al\\.", "year": 2011}, {"title": "Cryptographic limitations on learning boolean formulae and finite automata", "author": ["Michael Kearns", "Leslie Valiant"], "venue": "J. ACM,", "citeRegEx": "Kearns and Valiant.,? \\Q1994\\E", "shortCiteRegEx": "Kearns and Valiant.", "year": 1994}, {"title": "Universal one-way hash functions and their cryptographic applications", "author": ["M. Naor", "M. Yung"], "venue": "In Proceedings of the Twenty-first Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Naor and Yung.,? \\Q1989\\E", "shortCiteRegEx": "Naor and Yung.", "year": 1989}, {"title": "Computational limitations on learning from examples", "author": ["Leonard Pitt", "Leslie G. Valiant"], "venue": "J. ACM,", "citeRegEx": "Pitt and Valiant.,? \\Q1988\\E", "shortCiteRegEx": "Pitt and Valiant.", "year": 1988}, {"title": "One-way functions are necessary and sufficient for secure signatures", "author": ["J. Rompel"], "venue": "In Proceedings of the Twenty-second Annual ACM Symposium on Theory of Computing,", "citeRegEx": "Rompel.,? \\Q1990\\E", "shortCiteRegEx": "Rompel.", "year": 1990}, {"title": "Interactive privacy via the median mechanism", "author": ["Aaron Roth", "Tim Roughgarden"], "venue": "In STOC,", "citeRegEx": "Roth and Roughgarden.,? \\Q2010\\E", "shortCiteRegEx": "Roth and Roughgarden.", "year": 2010}, {"title": "Computational sample complexity and attribute-efficient learning", "author": ["Rocco A. Servedio"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Servedio.,? \\Q2000\\E", "shortCiteRegEx": "Servedio.", "year": 2000}, {"title": "Equivalences and separations between quantum and classical learnability", "author": ["Rocco A. Servedio", "Steven J. Gortler"], "venue": "SIAM J. Comput.,", "citeRegEx": "Servedio and Gortler.,? \\Q2004\\E", "shortCiteRegEx": "Servedio and Gortler.", "year": 2004}, {"title": "Faster algorithms for privately releasing marginals", "author": ["Justin Thaler", "Jonathan Ullman", "Salil P. Vadhan"], "venue": "In ICALP", "citeRegEx": "Thaler et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Thaler et al\\.", "year": 2012}, {"title": "Answering n2+o(1) counting queries with differential privacy is hard", "author": ["Jonathan Ullman"], "venue": "In STOC,", "citeRegEx": "Ullman.,? \\Q2013\\E", "shortCiteRegEx": "Ullman.", "year": 2013}, {"title": "PCPs and the hardness of generating private synthetic data", "author": ["Jonathan Ullman", "Salil P. Vadhan"], "venue": "In Yuval Ishai, editor, TCC,", "citeRegEx": "Ullman and Vadhan.,? \\Q2011\\E", "shortCiteRegEx": "Ullman and Vadhan.", "year": 2011}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Commun. ACM,", "citeRegEx": "Valiant.,? \\Q1984\\E", "shortCiteRegEx": "Valiant.", "year": 1984}], "referenceMentions": [], "year": 2015, "abstractText": "An order-revealing encryption scheme gives a public procedure by which two ciphertexts can be compared to reveal the ordering of their underlying plaintexts. We show how to use order-revealing encryption to separate computationally efficient PAC learning from efficient (\u03b5, \u03b4)-differentially private PAC learning. That is, we construct a concept class that is efficiently PAC learnable, but for which every efficient learner fails to be differentially private. This answers a question of Kasiviswanathan et al. (FOCS \u201908, SIAM J. Comput. \u201911). To prove our result, we give a generic transformation from an order-revealing encryption scheme into one with strongly correct comparison, which enables the consistent comparison of ciphertexts that are not obtained as the valid encryption of any message. We believe this construction may be of independent interest.", "creator": "LaTeX with hyperref package"}}}