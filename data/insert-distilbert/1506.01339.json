{"id": "1506.01339", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Jun-2015", "title": "Exploiting an Oracle That Reports AUC Scores in Machine Learning Contests", "abstract": "in machine learning contests such as the large scale visual talent recognition challenge and the kdd challenge cup, contestants can submit candidate solutions and receive from an oracle ( typically the organizers of the competition ) the accuracy of their guesses compared to ( a subset of ) the ground - truth labels. a commonly used selection accuracy metric for binary classification tasks is also the area under the receiver operating characteristics curve ( auc ), which is equivalent to the probability of deciding correct response in a 2 - alternative forced choice ( 2afc ) task in which the classifier must distinguish one positively correlated labeled example from one more negatively labeled example. in this paper piece we illustrate how knowledge of the 2afc score c of a set of guesses constrains the set of unknown possible labelings that the dataset can have. we then show that the worst - case number of possible binary labelings of n examples corresponding to any particular 2afc score c w. \u2212 r. t. some candidate solution is 2 ^ n.", "histories": [["v1", "Wed, 3 Jun 2015 18:06:49 GMT  (3kb)", "https://arxiv.org/abs/1506.01339v1", null], ["v2", "Fri, 13 Nov 2015 15:02:42 GMT  (116kb,D)", "http://arxiv.org/abs/1506.01339v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jacob whitehill"], "accepted": true, "id": "1506.01339"}, "pdf": {"name": "1506.01339.pdf", "metadata": {"source": "CRF", "title": "Exploiting an Oracle that Reports AUC Scores in Machine Learning Contests", "authors": ["Jacob Whitehill"], "emails": ["whitehill@harvard.edu"], "sections": [{"heading": null, "text": "and the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the organizers of the competition) the accuracy of their guesses compared to the ground-truth labels. One of the most commonly used accuracy metrics for binary classification tasks is the Area Under the Receiver Operating Characteristics Curve (AUC). In this paper we provide proofs-of-concept of how knowledge of the AUC of a set of guesses can be used, in two different kinds of attacks, to improve the accuracy of those guesses. On the other hand, we also demonstrate the intractability of one kind of AUC exploit by proving that the number of possible binary labelings of n examples for which a candidate solution obtains a AUC score of c grows exponentially in n, for every c \u2208 (0, 1)."}, {"heading": "Introduction", "text": "Machine learning and data-mining competitions such as the ImageNet Large Scale Visual Recognition Challenge [RDS+15], KDD Cup [KDD15], and Facial Expression Recognition and Analysis (FERA) Challenge [VGA+15] have helped to advance the state-of-the-art of machine learning, deep learning, and computer vision research. By establishing common benchmarks and setting a clearer boundary between training and testing datasets \u2013 participants typically never gain access to the testing labels directly \u2013 these competitions help researchers to estimate the performance of their classifiers more reliably. However, the benefit of such contests depends on the integrity of the competition and the generalizability of performance to real-world contexts. If contestants could somehow \u201chack\u201d the competition to learn illegitimately the labels of the test set and increase their scores, then the value of the contest would diminish greatly.\nOne potential window that data-mining contestants could exploit is the accuracy \u201coracle\u201d set up by the competition organizers to give contestants a running estimate of their classifier\u2019s performance: In many data-mining contests (e.g., those organized by Kaggle), contestants may submit, up to a fixed maximum number of times per day, a set of guesses for the labels in the testing set. The oracle will then reply with the accuracy of the contestant\u2019s guesses on a (possibly randomized) subset of the test data. There are several ways in which these oracle answers can be exploited, including: (1) If some contestants were able to circumvent the daily maximum number of accuracy queries they can submit to the oracle (e.g., by illegally registering multiple accounts on the competition\u2019s website), then they could use those extra oracle responses to perform additional parameter or hyperparameter optimization over the test set and potentially gain a competitive edge. (2) The accuracy reported by the oracle, even though it is an aggregate performance metric over the entire test set (or a large subset), could convey information about the labels of individual examples in the test set. Contestants could use this information to refine their guesses about the test labels. Given that the difference in accuracy between contestants is often tiny \u2013 in KDD Cup 2015, for example, the #1 and #2 contestants\u2019 accuracies differed by 0.0003 AUC [KDD15] \u2013 even a small edge achieved by exploiting the AUC oracle can be perceived as worthwhile.\nTo date, attacks of type (1) have already been implemented and documented [Sim15]. However, to the best of our knowledge, attacks of type (2) have not previously been investigated. In this paper, we consider how an attacker\nar X\niv :1\n50 6.\n01 33\n9v 2\n[ cs\n.L G\n] 1\n3 N\nov 2\ncould orchestrate attacks of type (2) on an oracle that reports the Area Under the Receiver Operating Characteristics Curve (AUC), which is one of the most common performance metrics for binary classifiers. Specifically, we make the following contributions:\n(a) We describe an attack whereby an attacker whose classifier already achieves high AUC and who knows the prevalence of each class can use the oracle to infer the labels of a few test examples with complete certainty.\n(b) We provide a proof-of-concept of how the AUC score c of a set of guesses constrains the set of possible labelings of the entire test set, and how this information can be harnessed, using standard Bayesian inference, to improve the accuracy of those guesses.\n(c) We show that a brute-force attack of type (b) above is computationally tractable only for very small datasets. Specifically, we prove that the number of possible binary labelings of n examples for which a candidate solution obtains a AUC score of c grows exponentially in n, for every c \u2208 (0, 1).\nAs the importance and prominence of data-mining competitions continue to increase, attackers will find more and more ingenious methods of hacking them. The greater goal of this paper is to raise awareness of this potential danger."}, {"heading": "Related Work", "text": "Our work is related to the problem of data leakage, which is the inadvertent introduction of information about test data into the training dataset of data-mining competitions. Leakage has been named one of the most important datamining mistakes [MNEI09] and can be surprisingly insidious and difficult to identify and prevent [KBF+00, KRPS12]. Leakage has traditionally been defined in a \u201cstatic\u201d sense, e.g., an artifact of the data preparation process that causes certain features to reveal the target label with complete certainty. The exploitation of an AUC oracle can be seen as a form of \u201cdynamic\u201d leakage: the oracle\u2019s AUC response during the competition to a set of guesses submitted by a contestant can divulge the identity of particular test labels or at least constrain the set of possible labelings.\nOur research also relates to privacy-preserving machine learning and differential privacy (e.g., [Dwo11, CM09, BLR13]), which are concerned with how to provide useful aggregate statistics about a dataset \u2013 e.g., the mean value of a particular attribute, or even a hyperplane to be used for classifying the data \u2013 without disclosing private information about particular examples within the dataset. [SCM14], for example, proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. The prior work most similar to ours is by [MH13], who show how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. In a simulation on 100 samples, they show how a simple Markov-chain Monte Carlo algorithm can recover the remaining 10% of missing test labels, with high accuracy, if 90% of the test labels are already known."}, {"heading": "ROC, AUC, and 2AFC", "text": "One of the most common ways to quantify the performance of a binary classifier is the Receiver Operating Characteristics (ROC) curve. Suppose a particular test set has ground-truth labels y1, . . . , yn \u2208 {0, 1} and the classifier\u2019s guesses for these labels are y\u03021, . . . , y\u0302n \u2208 R. For any fixed threshold \u03b8 \u2208 R, the false positive rate of these guesses is FP(\u03b8) .= 1n0 \u2211 i\u2208Y\u2212 I[y\u0302i \u2265 \u03b8] and the true positive rate is TP(\u03b8) . = 1n1 \u2211 i\u2208Y+ I[y\u0302i \u2265 \u03b8], where I[\u00b7] \u2208 {0, 1} is an indicator function, Y\u2212 = {i : yi = 0} and Y+ = {i : yi = 1} are the index sets of the negatively and positively labeled examples, and n0 = |Y\u2212|, n1 = |Y+|. The ROC curve is constructed by plotting (FP(\u03b8),TP(\u03b8)) for all possible \u03b8. The Area Under the ROC Curve (AUC) is then the integral of the ROC curve over the interval [0, 1].\nAn alternative but equivalent interpretation of the AUC [TC00, AGH+05], which we use in this paper, is that it is equal to the probability of correct response in a 2-Alternative Forced-Choice (2AFC) task, whereby the classifier\u2019s real-valued outputs are used to discriminate between one positively labeled and one negatively labeled example drawn from the set of all such pairs in the test set. If the AUC is 1, then the classifier can discriminate between a positive and a negative example perfectly (i.e., with probability 1). A classifier that guesses randomly has AUC of 0.5. Using\nthis probabilistic definition, given the ground-truth labels y1:n . = y1, . . . , yn and the classifier\u2019s real-valued guesses y\u03021:n . = y\u03021, . . . , y\u0302n, we can define the function f to compute the AUC of the guesses as:\nf(y1:n, y\u03021:n)\n. =\n1\nn0n1 \u2211 i\u2208Y\u2212 \u2211 j\u2208Y+ I[y\u0302i < y\u0302j ] + 1 2 I[y\u0302i = y\u0302j ]\nIn this paper, we will assume that the classifier\u2019s guesses y\u03021, . . . , y\u0302n are all distinct (i.e., y\u0302i = y\u0302j \u21d0\u21d2 i = j), which in many classification problems is common. In this case, the formula above simplifies to:\nf(y1:n, y\u03021:n) . =\n1\nn0n1 \u2211 i\u2208Y\u2212 \u2211 j\u2208Y+ I[y\u0302i < y\u0302j ] (1)\nAs is evident in Eq. 1, all that matters to the AUC is the relative ordering of the y\u0302i, not their exact values. Also, if all examples belong to the same class and either n1 = 0 or n0 = 0, then the AUC is undefined. Finally, the AUC is a rational number because it can be written as the fraction of two integers p and q. We use these facts later in the paper."}, {"heading": "Exploiting the AUC Score: A Simple Example", "text": "As a first example of how knowing the AUC of a set of guesses can reveal the ground-truth test labels, consider a hypothetical tiny test set of just 4 examples such that yi \u2208 {0, 1} is the ground-truth label for example i \u2208 {1, 2, 3, 4}. Suppose a contestant estimates, through some machine learning process, that the probabilities that these examples belong to the positive class are y\u03021 = 0.5, y\u03022 = 0.6, y\u03023 = 0.9, and y\u03024 = 0.4, and that the contestant submits these guesses to the oracle. If the oracle replies that these guesses have an AUC of 0.75, then the contestant can conclude with complete certainty that the true solution is y1 = 1, y2 = 0, y3 = 1, and y4 = 0 because this is the only groundtruth labeling satisfying Eq. 1 (see Table 1). The contestant can then revise his/her guesses based on the information returned by the oracle and receive a perfect score. Interestingly, in this example, the fact that the AUC is 0.75 is even more informative than if the AUC of the initial guesses were 1, because the latter is satisfied by three different ground-truth labelings.\nThis simple example raises the question of whether knowledge of the AUC could be exploited in more general cases. In the next sections we explore two possible attacks that a contestant might wage.\nAttack 1: Deducing Highest/Lowest-Ranked Labels with Certainty In this section we describe how a contestant, whose guesses are already very accurate (AUC close to 1), can orchestrate an attack to infer a few of the test set labels with complete certainty. This could be useful for several reasons: (1) Even though the attacker\u2019s AUC is close to 1, he/she may not know the actual test set labels \u2013 see Table 1 for an example. If the same test examples were ever re-used in a subsequent competition, then knowing their labels could be helpful. (2) Once the attacker knows some of the test labels with certainty, he/she can now use these examples for training. This can be especially beneficial when the test set is drawn from a different population than the training set (e.g., different set of human subjects\u2019 face images [VJM+11]). (3) If multiple attackers all score a high AUC but have very different sets of guesses, then they could potentially collude to infer the labels of a large number of test examples.\nThe attack requires rather strong prior knowledge of the exact number of positive and negative examples in the test set (n1 and n0, respectively).\nProposition 1. LetD be a dataset with labels y1, . . . , yn, of which n0 are negative and n1 are positive. Let y\u03021, . . . , y\u0302n be a contestant\u2019s real-valued guesses for the labels of D such that y\u0302i = y\u0302j \u21d0\u21d2 i = j. Let c = f(y1:n, y\u03021:n) denote the AUC achieved by the real-valued guesses with respect to the ground-truth labels. For any positive integer k \u2264 n0, if c > 1\u2212 1n1 + k n0n1\n, then the first k examples according to the rank order of y\u03021, . . . , y\u0302n must be negatively labeled. Similarly, for any positive integer k \u2264 n1, if c > 1\u2212 1n0 + k n0n1\n, then the last k examples according to the rank order of y\u03021, . . . , y\u0302n must be positively labeled."}, {"heading": "AUC for different labelings", "text": "Proof. Without loss of generality, suppose that the indices are arranged such that the y\u0302i are sorted, i.e., y\u03021 < . . . < y\u0302n. Suppose, by way of contradiction, that m of the first k examples were positively labeled, where 1 \u2264 m \u2264 k. For each such possible m, we can find at least m(n0 \u2212 k) pairs that are misclassified according to the real-valued guesses by pairing each of the m positively labeled examples within the index range {i : 1 \u2264 i \u2264 k} with each of (n0 \u2212 k) negatively labeled examples within the index range {j : k + 1 \u2264 j \u2264 n}. In each such pair (i, j), yi = 1 and yj = 0, and yet y\u0302i < y\u0302j , and thus the pair is misclassified. The minimum number of misclassified pairs, over all m in the range {1, . . . , k}, is clearly n0 \u2212 k (for m = 1). Since there are n0n1 total pairs in D consisting of one positive and one negative example, and since the AUC is maximized when the number of misclassified pairs is minimized, then the maximum AUC that could be achieved when m \u2265 1 of the first k examples are positively labeled is\n1\u2212 n0 \u2212 k n0n1 = 1\u2212 1 n1 + k n0n1\nBut this is less than c. We must therefore conclude that m = 0, i.e., all of the first k examples are negatively labeled. The proof is exactly analogous for the case when c > 1\u2212 1n0 + k n0n1 ."}, {"heading": "Example", "text": "Suppose that a contestant\u2019s real-valued guesses y\u03021, . . . , y\u0302n achieve an AUC of c = 0.985 on a dataset containing n0 = 45 negative and n1 = 55 positive examples, and that n0 and n1 are known to him/her. Then the contestant can conclude that the labels of the first (according to the rank order of y\u03021, . . . , y\u0302n) 7 examples must be negative and the labels of the last 17 examples must be positive.\nAttack 2: Integration over Satisfying Solutions The second attack that we describe treats the AUC reported by the oracle as an observed random variable in a standard supervised learning framework. In contrast to Attack 1, no prior knowledge of n0 or n1 is required. Note that the\nattack we describe uses only a single oracle query to improve an existing set of real-valued guesses. More sophisticated attacks might conceivably refine the contestant\u2019s guesses in an iterative fashion using multiple queries. Notation: In this section only, capital letters denote random variables and lower-case letters represent instantiated values.\nConsider the graphical model of Fig. 1, which depicts a test set containing n examples where each example i is described by a vectorXi \u2208 Rm ofm features (e.g., image pixels). Under the model, each label Yi \u2208 {0, 1} is generated according to P (Yi = 1 | xi, \u03b8) = g(xi, \u03b8), where g : Rm \u00d7 Rm \u2192 [0, 1] could be, for example, the sigmoid function of logistic regression and \u03b8 \u2208 Rm is the classifier parameter. Note that this is a standard probabilistic discriminative model \u2013 the only difference is that we have created an intermediate variable Y\u0302i \u2208 [0, 1] to represent g(xi, \u03b8) explicitly for each i. Specifically, we define:\nP (y\u0302i | xi, \u03b8) = \u03b4(y\u0302i \u2212 g(xi, \u03b8)) P (Yi = 1 | y\u0302i) = y\u0302i\nwhere \u03b4 is the Dirac delta function. The classification parameter \u03b8 can be estimated from training data (not shown), and thus we consider it to be observed. Using X1:n and an estimate for \u03b8, the contestant can then compute Y\u03021:n and submit these as his/her guesses to the competition organizers. The question is: if the competition allows access to an oracle that reportsC (i.e., variable C is observed), how can this additional information be used? Since the AUC C is a deterministic function (Eq. 1) of y1:n and y\u03021:n, we have:\nP (c | y1:n, y\u03021:n) = \u03b4(f(y1:n, y\u03021:n)\u2212 c)\nThen, according to standard Bayesian inference, the contestant can use C to update his/her posterior estimate of each\nlabel Yi as follows:\nP (yi | y\u03021:n, c) = \u2211 y\u00aci P (y1:n | y\u03021:n, c)\nwhere y\u00aci refers to y1, . . . , yi\u22121, yi+1, . . . , yn. = \u2211 y\u00aci P (c | y1:n, y\u03021:n)P (y1:n | y\u03021:n) P (c | y\u03021:n) \u221d \u2211 y\u00aci P (c | y1:n, y\u03021:n)\u220f j P (yj | y\u0302j)\n =\n\u2211 y\u00aci \u03b4(f(y1:n, y\u03021:n)\u2212 c) \u220f j P (yj | y\u0302j)\n= \u2211 y\u00aci :\nf(y1:n, y\u03021:n) = c\n\u220f j P (yj | y\u0302j) (2)\nIn other words, to compute the (unnormalized) posterior probability that Yi = yi given C = c, simply find all label assignments to the other variables Y1, . . . , Yi\u22121, Yi+1, . . . , Yn such that the AUC is c, and then compute the sum of the likelihoods \u220f j P (yj | y\u0302j) over all such assignments."}, {"heading": "Simulation", "text": "As a proof-of-concept of the algorithm described above, we conducted a simulation on a tiny dataset of n = 16 examples. In particular, we let g(x, \u03b8) = (1 + exp(\u2212\u03b8>x))\u22121 (sigmoid function for logistic regression), and we sampled \u03b8 and X1, . . . , Xn from an m-dimensional Normal distribution with zero mean and diagonal unit covariance. In our simulations, the contestant does not know the value of \u03b8 but can estimate it from a training dataset containing k examples (with L2 regularization of 1). In each simulation, the contestant computes Y\u03021:n from its estimate of \u03b8 and the feature vectors X1:n. The contestant then submits Y\u03021:n as guesses to the oracle, receives the AUC score C, and then computes P (Y1 = 1 | y\u03021:n, c), . . . , P (Yn = 1 | y\u03021:n, c). The contestant then submits these posterior probabilities as its second set of guesses and receives an updated AUC score C \u2032. After each simulation run, we record the accuracy gain C \u2032 \u2212 C. By varying k \u2208 {1, . . . , 20}, m \u2208 {4, 5, . . . , 16}, and averaging over 50 simulation runs per (m, k) combination, we can then compute the expected accuracy gain \u2206AUC (i.e., C \u2032 \u2212 C) as a function of the initial AUC (C).\nResults: The graph in Fig. 2 indicates that, for a wide range of starting AUC values C, a small but worthwhile average increase in accuracy can be achieved, particularly when C is closer to 0.5."}, {"heading": "Tractability", "text": "In the simulation above, we used a brute-force approach when solving Eq. 2: we created a list of all 2n possible binary tuples (y1, . . . , yn) and then simply selected those tuples that satisfied f(y1:n, y\u03021:n) = c. However, if the number of such tuples were small, and if one could efficiently enumerate over them, then the attack would become much more practical. This raises an important question: for a dataset of size n and a fixed set of real-valued guesses y\u03021, . . . , y\u0302n, are there certain AUC values for which the number of possible binary labelings is sub-exponential in n? We investigate this question in the next section."}, {"heading": "The Number of Satisfying Solutions Grows Exponentially in n for Every AUC", "text": "c \u2208 (0, 1) In this section we prove that the number of tuples (y1, . . . , yn) for which a contestant\u2019s guesses achieve a fixed AUC c grows exponentially in n, for every c \u2208 (0, 1). (Note that this is different from proving that, for a dataset of some fixed size n, the number of tuples (y1, . . . , yn) for which a contestant\u2019s guesses achieve some AUC c is exponential in n.) Our proof is by construction: for any AUC c = pq , p, q \u2208 Z +, p < q, we show how to construct a dataset of size n = 4q such that the number of satisfying binary labelings is at least (2\u2212 2 |c\u2212 0.5|)n/4. Intuitively, this lower-bound grows more quickly for AUC values close to 0.5 than for AUC values close to 0 or 1.\nFirst, we prove a simple lemma:\nLemma 1. Let a, b, c \u2208 Z such that a > b > 0 and c \u2265 0. Then a+cb+c \u2264 a b .\nProof. By way of contradiction, suppose a+cb+c > a b . Then\n(a+ c)b > a(b+ c)\nab+ bc > ab+ ac\nbc > ac\nwhich implies b > a.\nProposition 2. LetD be a dataset consisting of n = 4q examples for some q \u2208 Z+, and let y\u03021, . . . , y\u0302n be a contestant\u2019s real-valued guesses for the binary labels of D such that y\u0302i = y\u0302j \u21d0\u21d2 i = j. Then for any AUC c such that c = pq , p, q \u2208 Z + and p < q, the number of distinct binary labelings y1, . . . , yn for which f(y1:n, y\u03021:n) = c is at least (2\u2212 2 |c\u2212 0.5|)n/4.\nProof. Without loss of generality, suppose that the indices are arranged such that the y\u0302i are sorted, i.e., y\u03021 < . . . < y\u0302n. Since the AUC is invariant under monotonic transformations of the real-valued guesses, we can represent each y\u0302i simply by its index i. Since c is a fraction of pairs that are correctly classified, we can write it as p/q for positive integers p, q. We will handle the cases c \u2265 0.5 and c < 0.5 separately.\nCase 1 (0.5 \u2264 c < 1): Construct a dataset of size n = 4q as shown in Fig. 3: the first 2(2p \u2212 q) entries are negative examples, and of the remaining 2(3q \u2212 2p) entries (which we call the \u201cright band\u201d), 2q are positive and 4(q \u2212 p) are negative. Moreover, the right band is arranged symmetrically in the following sense: for each i \u2208 {2(2p\u2212 q) + 1, . . . , 4q}, yi = 1 \u21d0\u21d2 yj = 1 where j = 2(2p\u2212 q) + (4q \u2212 i+ 1).\nGiven this construction, we must calculate how many pairs containing one positive and one negative example are correctly and incorrectly classified. Note that each of the first 2(2p \u2212 q) negative examples in the left band can be paired with each of the 2q positive examples in the right band, and that each of these positive examples has a higher y\u0302 value than the negative examples; hence, each of these 2q(2)(2p \u2212 q) = 8pq \u2212 4q2 pairs is classified correctly. The only remaining pairs of examples occur within the right band. To calculate the number of correctly/incorrectly classified pairs in the right band, we exploit the fact that it is symmetric: For any index pair (i, j) where i, j \u2208 {2(2p \u2212 q) + 1, . . . , 4q}, where yi = 0 and yj = 1, and where i < j (and hence y\u0302i < y\u0302j), we can find exactly one other pair (i\u2032, j\u2032) for which yi\u2032 = 0 and yj\u2032 = 1 and for which i\u2032 > j\u2032. Hence, within the right band, the numbers of correctly and incorrectly classified pairs are equal. Since there are 2q(4)(q \u2212 p) = 8q2 \u2212 8pq pairs within this band total, then 4q2 \u2212 4pq are classified correctly and 4q2 \u2212 4pq are classified incorrectly.\nSumming the pairs of examples within the right band and the pairs between the left and right bands, we have 8pq \u2212 4q2 + 8q2 \u2212 8pq = 4q2 pairs total. The number of correctly classified pairs is 4q2 \u2212 4pq + 8pq \u2212 4q2 = 4pq, and thus the AUC is 4pq/(4q2) = p/q = c, as desired.\nNow that we have constructed a single labeling of size n = 4q for which the AUC is c, we can construct many more simply by varying the positions of the 2q positive entries within the right band of 2(3q\u2212 2p) entries. To preserve\nsymmetry, we can vary the positions of half of the positive examples within half of the right band and then simply \u201creflect\u201d the positions onto the other half. In total, the number of choices is:(\n3q \u2212 2p q ) =\n(3q \u2212 2p)! q!(3q \u2212 2p\u2212 q)!\n= (3q \u2212 2p)! q!(2q \u2212 2p)!\n= (3q \u2212 2p)(3q \u2212 2p\u2212 1) \u00b7 \u00b7 \u00b7 (2q \u2212 2p+ 2)(2q \u2212 2p+ 1)\nq(q \u2212 1) \u00b7 \u00b7 \u00b7 (2)(1)\nWe now apply Lemma 1 and the fact that the numerator and denominator both contain q terms:( 3q \u2212 2p\nq ) \u2265 ( 3q \u2212 2p\nq )q = ( 3q \u2212 2p\nq )n/4 = (3\u2212 2c)n/4\nCase 2 (0 < c < 0.5): The proof is analogous except that we \u201cflip\u201d the AUC around 0.5 and correspondingly \u201cflip\u201d the labels left-to-right. Let r = q \u2212 p (so that r/q = 1\u2212 p/q). Then, we form a similar construction as above, except that the left sequence of all negative examples is moved to the right. Specifically, we create a symmetric sequence of length 2(3q \u2212 2r) such that 2q examples are positive and 4(q \u2212 r) are negative. We then append 2(2r \u2212 q) entries to the right that are all negative. This results in\n1 2 (2q \u00d7 4(q \u2212 r)) = 4q2 \u2212 4qr\npairs that are classified correctly and\n2(2r \u2212 q)\u00d7 2q + 1 2 (2q \u00d7 4(q \u2212 r))\n= 8qr \u2212 4q2 + 4q2 \u2212 4qr = 4qr\npairs that are classified incorrectly. In total, there are 4qr+4q2\u22124qr = 4q2 pairs, so that the AUC is (4q2\u22124qr)/4q2 = 1\u2212 r/q = p/q, as desired.\nAnalogously to above, we can form( 3q \u2212 2r\nq\n) =\n(3q \u2212 2r)! q!(2q \u2212 2r)!\n\u2265 (\n3q \u2212 2r q )n/4 = ( 3q \u2212 2(q \u2212 p)\nq )n/4 = ( q + 2p\nq )n/4 = (1 + 2c) n/4\nsymmetric constructions of the left band. Combining Case 1 and Case 2, we find that the number of binary labelings for which the AUC is c is at least\n(2\u2212 2 |c\u2212 0.5|)n/4\nfor all 0 < c < 1."}, {"heading": "Conclusion", "text": "In this paper we have examined properties of the Area Under the ROC Curve (AUC) that can enable a contestant of a data-mining contest to exploit an oracle that reports AUC scores to illegitimately attain higher performance. We presented two simple attacks: one whereby a contestant whose guesses already achieve high accuracy can infer, with complete certainty, the values of a few of the test set labels; and another whereby a contestant can harness the oracle\u2019s AUC information to improve his/her guesses using standard Bayesian inference. To our knowledge, our paper is the first to formally investigate these kinds of attacks.\nThe practical implications of our work are mixed: On the one hand, we have provided proofs-of-concept that systematic exploitation of AUC oracles is possible, which underlines the importance of taking simple safeguards such as (a) adding noise to the output of the oracle, (b) limiting the number of times that a contestant may query the oracle, and (c) not re-using test examples across competitions. On the other hand, we also provided evidence \u2013 in the form of a proof that the number of binary labelings for which a set of guesses attains an AUC of c grows exponentially in the test set size n \u2013 that brute-force probabilistic inference to improve one\u2019s guesses is intractable except for tiny datasets. It is conceivable that some approximate inference algorithms might overcome this obstacle.\nAs data-mining contests continue to grow in number and importance, it is likely that more creative exploitation \u2013 e.g., attacks that harness multiple oracle queries instead of just single queries \u2013 will be attempted. It is even possible that the focus of effort in such contests might shift from developing effective machine learning classifiers to querying the oracle strategically, without training a useful classifier at all. With our paper we hope to highlight an important potential problem in the machine learning community."}], "references": [{"title": "In Journal of Machine Learning Research", "author": ["Shivani Agarwal", "Thore Graepel", "Ralf Herbrich", "Sariel Har-Peled", "Dan Roth. Generalization bounds for the area under the ROC curve"], "venue": "pages 393\u2013425,", "citeRegEx": "AGH05", "shortCiteRegEx": null, "year": 2005}, {"title": "Journal of the ACM (JACM)", "author": ["Avrim Blum", "Katrina Ligett", "Aaron Roth. A learning theory approach to noninteractive database privacy"], "venue": "60(2):12,", "citeRegEx": "BLR13", "shortCiteRegEx": null, "year": 2013}, {"title": "In Advances in Neural Information Processing Systems", "author": ["Kamalika Chaudhuri", "Claire Monteleoni. Privacy-preserving logistic regression"], "venue": "pages 289\u2013296,", "citeRegEx": "CM09", "shortCiteRegEx": null, "year": 2009}, {"title": "editors", "author": ["Cynthia Dwork. Differential privacy. In HenkC.A. van Tilborg", "Sushil Jajodia"], "venue": "Encyclopedia of Cryptography and Security, pages 338\u2013340. Springer US,", "citeRegEx": "Dwo11", "shortCiteRegEx": null, "year": 2011}, {"title": "Kdd-cup 2000 organizers\u2019 report: Peeling the onion", "author": ["Ron Kohavi", "Carla E Brodley", "Brian Frasca", "Llew Mason", "Zijian Zheng"], "venue": "ACM SIGKDD Explorations Newsletter, 2(2):86\u201393,", "citeRegEx": "KBF00", "shortCiteRegEx": null, "year": 2000}, {"title": "Leakage in data mining: Formulation", "author": ["Shachar Kaufman", "Saharon Rosset", "Claudia Perlich", "Ori Stitelman"], "venue": "detection, and avoidance. ACM Transactions on Knowledge Discovery from Data (TKDD), 6(4):15,", "citeRegEx": "KRPS12", "shortCiteRegEx": null, "year": 2012}, {"title": "Academic radiology", "author": ["Gregory J Matthews", "Ofer Harel. An examination of data confidentiality", "disclosure issues related to publication of empirical roc curves"], "venue": "20(7):889\u2013896,", "citeRegEx": "MH13", "shortCiteRegEx": null, "year": 2013}, {"title": "Handbook of statistical analysis and data mining applications", "author": ["Gary Miner", "Robert Nisbet", "John Elder IV"], "venue": "Academic Press,", "citeRegEx": "MNEI09", "shortCiteRegEx": null, "year": 2009}, {"title": "International Journal of Computer Vision (IJCV)", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge"], "venue": "pages 1\u201342, April", "citeRegEx": "RDS15", "shortCiteRegEx": null, "year": 2015}, {"title": "CoRR", "author": ["Ben Stoddard", "Yan Chen", "Ashwin Machanavajjhala. Differentially private algorithms for empirical machine learning"], "venue": "abs/1411.5428,", "citeRegEx": "SCM14", "shortCiteRegEx": null, "year": 2014}, {"title": "MIT Technology Review", "author": ["Tom Simonite. Why", "how Baidu cheated an artificial intelligence test"], "venue": "6", "citeRegEx": "Sim15", "shortCiteRegEx": null, "year": 2015}, {"title": "Signal detection theory in the 2AFC paradigm: attention", "author": ["C. Tyler", "C.-C. Chen"], "venue": "channel uncertainty and probability summation. Vision Research, 40(22):3121\u20133144", "citeRegEx": "TC00", "shortCiteRegEx": null, "year": 2000}, {"title": "Gary McKeown", "author": ["M Valstar", "J Girard", "T Almaev"], "venue": "Marc Mehu, Lijun Yin, Maja Pantic, and J Cohn. Fera 2015-second facial expression recognition and analysis challenge. Proc. IEEE ICFG", "citeRegEx": "VGA15", "shortCiteRegEx": null, "year": 2015}, {"title": "The first facial expression recognition and analysis challenge", "author": ["Michel F. Valstar", "Bihan Jiang", "Marc M\u00e9hu", "Maja Pantic", "Klaus Scherer"], "venue": "Proceedings of the IEEE International Conference on Automatic Face and Gesture Recognition,", "citeRegEx": "VJM11", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 8, "context": "Abstract In machine learning contests such as the ImageNet Large Scale Visual Recognition Challenge [RDS15] and the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the organizers of the competition) the accuracy of their guesses compared to the ground-truth labels.", "startOffset": 100, "endOffset": 107}, {"referenceID": 8, "context": "Machine learning and data-mining competitions such as the ImageNet Large Scale Visual Recognition Challenge [RDS15], KDD Cup [KDD15], and Facial Expression Recognition and Analysis (FERA) Challenge [VGA15] have helped to advance the state-of-the-art of machine learning, deep learning, and computer vision research.", "startOffset": 108, "endOffset": 115}, {"referenceID": 12, "context": "Machine learning and data-mining competitions such as the ImageNet Large Scale Visual Recognition Challenge [RDS15], KDD Cup [KDD15], and Facial Expression Recognition and Analysis (FERA) Challenge [VGA15] have helped to advance the state-of-the-art of machine learning, deep learning, and computer vision research.", "startOffset": 198, "endOffset": 205}, {"referenceID": 10, "context": "To date, attacks of type (1) have already been implemented and documented [Sim15].", "startOffset": 74, "endOffset": 81}, {"referenceID": 7, "context": "Leakage has been named one of the most important datamining mistakes [MNEI09] and can be surprisingly insidious and difficult to identify and prevent [KBF00, KRPS12].", "startOffset": 69, "endOffset": 77}, {"referenceID": 9, "context": "[SCM14], for example, proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics.", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "The prior work most similar to ours is by [MH13], who show how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.", "startOffset": 42, "endOffset": 48}, {"referenceID": 13, "context": ", different set of human subjects\u2019 face images [VJM11]).", "startOffset": 47, "endOffset": 54}], "year": 2015, "abstractText": "In machine learning contests such as the ImageNet Large Scale Visual Recognition Challenge [RDS15] and the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the organizers of the competition) the accuracy of their guesses compared to the ground-truth labels. One of the most commonly used accuracy metrics for binary classification tasks is the Area Under the Receiver Operating Characteristics Curve (AUC). In this paper we provide proofs-of-concept of how knowledge of the AUC of a set of guesses can be used, in two different kinds of attacks, to improve the accuracy of those guesses. On the other hand, we also demonstrate the intractability of one kind of AUC exploit by proving that the number of possible binary labelings of n examples for which a candidate solution obtains a AUC score of c grows exponentially in n, for every c \u2208 (0, 1).", "creator": "LaTeX with hyperref package"}}}