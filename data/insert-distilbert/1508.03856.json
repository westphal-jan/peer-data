{"id": "1508.03856", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Aug-2015", "title": "Two-stage Cascaded Classifier for Purchase Prediction", "abstract": "in this paper published we describe our machine learning solution dynamics for completing the recsys challenge, 2015. we have proposed a time efficient two - stage cascaded classifier for the prediction of buy sessions and purchased items within such sessions. based on the model, several interesting features found, and formation of our own test bed, today we have additionally achieved a mostly reasonable score. usage of random forests helps us to cope with the effect results of the multiplicity of good models depending on periodically varying subsets of features in the purchased items prediction and, in its rapid turn, boosting coefficient is used as a suitable testing technique to overcome severe class imbalance of calculating the buy - session prediction.", "histories": [["v1", "Sun, 16 Aug 2015 19:27:35 GMT  (28kb)", "http://arxiv.org/abs/1508.03856v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["sheikh muhammad sarwar", "mahamudul hasan", "dmitry i ignatov"], "accepted": false, "id": "1508.03856"}, "pdf": {"name": "1508.03856.pdf", "metadata": {"source": "CRF", "title": "Two-stage Cascaded Classifier for Purchase Prediction", "authors": ["Sheikh Muhammad Sarwar", "Dmitry I. Ignatov"], "emails": ["smsarwar@du.ac.bd", "munna09bd@gmail.com", "dignatov@hse.ru", "permissions@acm.org."], "sections": [{"heading": null, "text": "ar X\niv :1\n50 8.\n03 85\n6v 1\n[ cs\n.I R\n] 1\n6 A\nug 2\n01 5\nCategories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Filtering; 1.2.6 [Artificial Intelligence]: Learning\nKeywords supervised learning, class imbalance, e-commerce"}, {"heading": "1. INTRODUCTION", "text": "For us, the most challenging part of the competition is the classical problem in machine learning, class imbalance [?]. The task of the challenge is to predict \u201cbuy sessions\u201d from a large set of sessions. Each session contains the click data of several anonymous users. However, only 5% of the training data consist of buy sessions, which is actually half a million among 9.3 million sessions. Hence, if we consider two classes (buy and non-buy), a severe class imbalance problem appears. Apart from predicting the buy sessions, the challenge organizers also want to know which items would be bought from a buy session. In order to answer these two questions, we have come up with two machine learning models, where one model is able to select the buy sessions and the other one finds the related items. For finding buy sessions while handling the class imbalance problem, we use the\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00.\nAdaboost.M1 implementation from Weka machine learning framework. We have finally found interesting features and achieved a reasonable score of 45,027 in the challenge."}, {"heading": "2. PROBLEM STATEMENT", "text": "RecSys Challenge 2015 provides a data set containing the clickstream data of several users of an e-commerce site over the duration of six months. The training data set is composed of a set of sessions S and each session s \u2208 S contains a set of items Is. Bs \u2286 Is denotes the set of items which has been bought in session s. There are two types of sessions Sb (the sessions that end in buying) and Snb (the sessions that do not end in buying) as follows:\nSb = {s \u2208 S : Bs 6= \u2205}, and Snb = S \\ Sb.\nThe test data also contains a set of sessions St and St \u2229 S = \u2205. Now, given the set of sessions St, our task is to find all the sessions Stb \u2286 St, which have at least one buy event. Moreover, if a session s contains a buy event, we have to predict the set of items Bs that was bought. The final solution should contain sessions Sl and the set of items As for each session s \u2208 Sl, which should be bought. There is an original solution file, which contains a set of sessions Sb, and for each session s \u2208 Sb there is a set of items Bs which were bought in that session. However, rather than maximizing any traditional evaluation function we will have to maximize a unique scoring function based on the original solution file, which is shown below:\nscore(St) = \u2211\n\u2200s\u2208Sl\n(\u22121)[s6\u2208Sb] |Sb|\n|St| + [s \u2208 Sb]\n|As \u2229Bs| |As \u222aBs| , where\n[Z] equals 1 if Z is true and 0 otherwise (Iverson notation)."}, {"heading": "2.1 Observation about the Scoring Function", "text": "According to the challenge description, buying event occurs in only 5% of the sessions and that\u2019s why we can assume that the penalty for predicting wrong sessions is only 0.05. From the other hand, for predicting a right session it is possible to achieve 1.05 score and as a consequence the strategy should be to identify most of the sessions as buy sessions. However, there is a limitation in the solution file size (<25MB) and that is why a proper level of precision should be reached in choosing the resulting sessions.\n2.2 Data Description\nThe task contains three data files: click data file, buy data file and test data file. The click data file contains all the click sessions (Sc) and some information about the items clicked in those sessions, while the buy data file contains a set of sessions (Sb) in which at least one item has been bought. The click data file contains a set of tuples in the form {sessionId, timestamp, itemId, category} and the buy data file contains a set of tuples in the form {sessionId, timestamp, itemId, price, quantity}. The test data file follows the same data schema as the click data file. The data description is provided in Table 1."}, {"heading": "3. DATA PREPROCESSING", "text": ""}, {"heading": "3.1 Resolving Missing Category Information", "text": "At first we extract several properties of items and assign 0 as category number to the items with unknown category (almost half of the sessions items belong to this category). In fact the data were collected over six months period \u2013 from April to September, where most of the category information appeared after mid of June. We assume that the e-commerce site could not provide category data for that period of time. However, as an item repeatedly occurred in different sessions, it is possible to recover the category for most of the items using the data from June to September. While resolving the category we try to recover only regular category, i.e. we do not use special category . However, from our analysis it was evident that an item belongs to several categories. Nonetheless, we want to find a specific category for a specific item. So, we resolve item categories using the following rule: if an item belongs to several categories, the actual category is its most frequent one in the click data. After resolving the categories we append the attribute originalCategory to each click data."}, {"heading": "3.2 Performing Temporal Ordering", "text": "At first, we sort both the click file and buy file using sessionId, which has a specific benefit that we will discuss later. Then for each of the sessions belonging to the files we sort\nthe session data by timestamp. By so doing we can find the temporal ordering in the click and buy data. This temporal ordering helps us determine the order of user\u2019s clicks on the items in a session. Moreover, the duration of a click could easily be found by simply subtracting time of that click from the time of the next click. Now, for each distinct item in a session if we sum the duration of the clicks in which the item appears, we define the duration of the item in that session. After sorting by timestamp we append itemDuration (the amount of time an item is inspected in a session) to each click data."}, {"heading": "3.3 Extraction of Item Properties", "text": "We extract several other properties, which are specific to an item and append it to each click data. The properties are listed in Table 2. At first we tried to solve the problem using only click-buy ratio and obtained a score of 29000. In that process, we averaged the click-buy ratio of all the items in a session and if the average was over the threshold of 5.5 we identified that session as a buy one. After that we picked half of the items by sorting on click-buy ratio. Using this simple approach we understood that we need to build features using this valuable statistic for developing our machine learning solution."}, {"heading": "3.4 Development of an Alternative Testbed", "text": "We have developed a complete framework in Java for performing the task, which includes the development of our own testbed. The development of our own independent testbed is crucial since there are only three chances of submission in the challenge per 24-hours. In order to do that we put each buy session s from all the sessions in our click data Sc to a file clickBuy (click sessions ended in buy) and all non-buy sessions are placed to the file onlyClick (click sessions not ended in buy). We sort all the click and buy sessions by sessionId in advance and split them finally (within O(|Sc|log|Sc|)).\nAfter splitting, we randomly take half of the sessions in the clickBuy file to create our local test set and solution file; the remaining half of the data from clickBuy file is left for training our model and its evaluation in our own testbed.\nFinally, we add randomly chosen one fourth of sessions from the onlyClick file to our new test set; the remaining goes to our new training set. As a result, we have our own original testing file and test (solution) file using which we can estimate the performance of our classifier. The number of sessions in our own test data is 2439481, while the original test data contains 2312432 sessions. Moreover, we kept 254510 buy sessions in our test data and according to scoring function shown in Section 2, we can achieve at most 254510 \u00d7 1.05 = 267235.5 score from our own test data."}, {"heading": "4. PROPOSED SOLUTION", "text": "The task is intuitively divided in to two subtasks: predicting the outcome of a session and given a session predicting the set of items that should be bought in that session. So, we construct two classifiers to address these two subtasks. However, at first we thought of building a single classifier that would extract features from the items from the sessions in training data, and, given the items of a session in test data, it should classify the item as buy or non-buy. Unfortunately, in this process we have to handle a large feature data. If we look at Table 3, it is evident that developing only an item-based classifier would require to build a model for 1049817 items labeled with buy and 25565682 items marked as non-buy. Building any sophisticated classifier around that amount of data would take a huge computation time. Hence, at first we predict the sessions, which would end in buy, and then look for the prospective bought items in those sessions. So, we need to develop two classifiers: item classifier and session classifier."}, {"heading": "4.1 Item Classifier", "text": "An important observation about item classifier is that we have to train the classifier only with the click data of the buy sessions in training data. The click data of a buy session contain a set of items that was bought (Bs) and a set of items that was not bought (As). Now for each item i \u2208 Bs we extract both session-based and item-based features. After that we label that item as buy and each item i \u2208 As as nonbuy. By considering only the buy sessions we get 1049817 bought items and 1264870 non-bought ones. As a result, the class imbalance problem is less stressed and the classifier has to be trained with only 215053 data in total, which results in short training time.\nSince we obtained our own testbed (see Section 3.4), we have our local solution file, which we can use to verify the performance of our method. We have tried to predict items with the classifier given the sessions in the local solution file i.e. we pretend that we know the correct sessions beforehand and we only try to test the efficiency of our item classifier. The maximum achievable score from our local solution file is 267235.5. Since we have met Rashomon effect (multiplicity of good subsets of features/models) in this item classification, we use Random Forests (RF) to cope with this difficulty [?]; moreover, RF classifier has shown the best score in our testbed and the highest Average Jaccard measure (see Table 5). The performance of the classifiers in shown in 5 and the selected features are described in Table 4. In order to extract features 9,10,14,15,21 and 21 we cluster session data using category that we resolved previously in 3.1."}, {"heading": "4.2 Session Classifier", "text": "We have 509696 buy sessions and 8740001 non-buy ones\nin the training data. Rather than looking at the feature of the items, we look at the features of sessions. There are\ntwo important observations for building the session classifier: 1) Since we have only 0.05 penalty for selecting a non-buy session, it should be a high recall classifier; 2) As there exists class imbalance problem, a classifier would tend to predict most of the sessions as non-buy.\nIn order to address the problems we performed resampling of data and classified sessions using AdaBoost.M1 algorithm. AdaboostM1 comes as a remedy for class imbalance problem combined with resampling [?], and it gives us the highest recall among the classifiers we tested. Table 8 shows that even though RF works better when classifying items, it cannot reach high recall when classifying sessions; moreover, it takes the highest time for model training. For Adaboost.M1 the model is built in a smaller period of time (3 min 2 s for 1896886 feature vectors) and evaluation is done in 23 s for 2312432 feature vectors. We have experimented with Adaboost.M1 using different set of features; we describe the selected features in Table 6. In Table 7 we show the performance of Adaboost.M1 with the set of all the extracted features and it produces the highest score \u2013 107763.7. However, in our local testbed it returns a huge number of sessions that cannot be accommodated in the solution file of less than 25 MB (the challenge constraint). From Table 7 one can observe that with selected features we obtain a score of 106508.4, which is the highest considering the file size. Finally, we have obtained our best challenge score 45027 by cascading Adaboost.M1 with resampling for session classification and RF for choosing items.\nIn Table 7 we show the result of considering different subsets of features obtained from Table 6. We excluded the time based features, aggregated features, and other subsets to evaluate the session classifier. Moreover, we mention two of the challenge scores and show the respective score from our own testbed. As there are 2312432 session in the challenge test data, we can assume that there are 115622 (5%) buy sessions in it and the Maximum Possible Score (MPS) from the test data can be 115622 \u00d7 1.05 =121402, approximately. However, we kept 254510 buy sessions in our test data and the MPS from our testbed can be 267235.5 (see Table 5). As shown in Table 7, we achieve our best score 45027 (37% of challenge test data), when our testbed score is 106508 (39% of our own test data). When we achieve 39127 (32% of challenge test data), our testbed score is 96077 (35% of our own test data). So, we can assert that we are able to approximate our challenge score from our testbed one."}, {"heading": "5. CONCLUSIONS", "text": "It seems the proposed approach can be applied in a similar clickstream classification setting. The usage of a cascade of two different classifiers is beneficial when one experiences severe imbalance between buy and non-buy sessions and multiplicity of good feature subsets. Moreover, learning and classification phases are reasonably short for this subtask decomposition. We have no doubts that further model tuning would definitely allow to achieve a better score."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "In this paper we describe our machine learning solution for the RecSys Challenge 2015. We have proposed a timeefficient two-stage cascaded classifier for the prediction of buy sessions and purchased items within such sessions. Based on the model, several interesting features found, and formation of our own test bed, we have achieved a reasonable score. Usage of Random Forests helps us to cope with the effect of the multiplicity of good models depending on varying subsets of features in the purchased items prediction and, in its turn, boosting is used as a suitable technique to overcome severe class imbalance of the buy-session prediction.", "creator": "LaTeX with hyperref package"}}}