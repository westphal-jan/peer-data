{"id": "1509.02487", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Sep-2015", "title": "Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection", "abstract": "we formulate and study a globally fundamental search and detection problem, basically schedule optimization, motivated by a variety challenges of current real - world applications, ranging ultimately from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines.", "histories": [["v1", "Tue, 8 Sep 2015 18:28:24 GMT  (705kb)", "http://arxiv.org/abs/1509.02487v1", null], ["v2", "Thu, 10 Sep 2015 02:22:51 GMT  (705kb)", "http://arxiv.org/abs/1509.02487v2", null]], "reviews": [], "SUBJECTS": "cs.DS cs.LG", "authors": ["ahmad mahmoody", "evgenios m kornaropoulos", "eli upfal"], "accepted": false, "id": "1509.02487"}, "pdf": {"name": "1509.02487.pdf", "metadata": {"source": "CRF", "title": "Optimizing Static and Adaptive Probing Schedules for Rapid Event Detection", "authors": ["Ahmad Mahmoody"], "emails": ["eli}@cs.brown.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n02 48\n7v 1\n[ cs\n.D S]\n8 S\nep 2\nWe consider a large system consists of many nodes, where each node has its own rate of generating new events, or items. A monitoring application can probe a small number of nodes at each step, and our goal is to compute a probing schedule that minimizes the expected number of undiscovered items at the system, or equivalently, minimizes the expected time to discover a new item in the system. We study the Schedule Optimization problem both for deterministic and randomized memoryless algorithms. We provide lower bounds on the cost of an optimal schedule and construct close to optimal schedules with rigorous mathematical guarantees. Finally, we present an adaptive algorithm that starts with no prior information on the system and converges to the optimal memoryless algorithms by adapting to observed data."}, {"heading": "1 Introduction", "text": "We introduce and study a fundamental stochastic search and detection problem, Schedule Optimization, that captures a variety of practical applications, ranging from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines.\nOur optimization problem consists of a large set of units, or nodes, that generate events, or items, according to a random process with known or unknown parameters. A detection algorithm can discover new items in the system by probing a small number of nodes in each step. This setting defines a discrete, infinite time process, and the goal of the stochastic optimization problem is to construct a probing schedule that minimizes the long term expected number of undiscovered items in the system, or equivalently, minimizes the expected time to discover a new item in the system.\nWe outline several important applications of this schedule optimization problem:\nNews and Feed Aggregators. To provide up to date summary of the news, news aggregator sites need to constantly browse the Web, and often also the blogosphere and social networks, for new items. Scanning a site for new items requires significant communication and computation resources, thus the news aggregator can scan only a few sites simultaneously. The frequency of visiting a site has to depend on the likelihood of finding new items in that site. [9,21,1]\nAlgorithmic Trading on Data. An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16]. The critical issue in this application is the speed of discovering new events, but again there is a resource limit on the number of sites that the search algorithm can scan simultaneously.\nDetecting Anomaly and Machine Malfunction. In large server farm or any other large collection of semi-autonomous machines a central controller needs to identify and contain anomalies and malefactions as soon as possible, before they spread in the system. To minimize interference with the system\u2019s operation the controller must probe only a small number of machines in each step."}, {"heading": "1.1 Our Contribution", "text": "We consider an infinite, discrete time process in which n nodes generate new items according to a stochastic process which is governed by a generating vector \u03c0 (see Section 3 for details). An algorithm can probe up to c nodes per step to discover all new items in these nodes. The goal is to minimize the cost of the algorithm (or the probing schedule), which we define as the long term (steady state) expected number of undiscovered items in the system.\nWe first show that the obvious approach of probing at each step the nodes with maximum expected number of undiscovered items at that step is not optimal. In fact, the cost of such a schedule can be arbitrary far from the optimal.\nOur first result toward the study of efficient schedules is a lower bound on the cost of any deterministic or random schedule as a function of the generating vector \u03c0.\nNext we assume that the generating vector \u03c0 is known and study explicit constructions of deterministic and random schedules. We construct a deterministic schedule whose cost is within a factor of (3 + (c\u2212 1)/c) of the optimal cost, and a very simple, memoryless random schedule with cost that is within a factor of (2 + (c\u2212 1)/c) from optimal, where c is the maximum number of probes at each step.\nFinally, we address the more realistic scenario in which the generating vector, \u03c0, is not known to the algorithm and may change in time. We construct an adaptive scheduling algorithm that learns from probing the nodes and converges to the optimal memoryless random schedule."}, {"heading": "2 Related Work", "text": "The News and Feed Aggregation problem is a very well-studied topic, in which the general goal is to obtain the updates of news websites (e.g. by RSS feeds). Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21]. In [21] it is assumed that the rates of the news publication does not change, where in our setting these rates may change and our algorithm (Adaptive) can adapt itself to the new setting. Also, we assume at any given time the number of probes is fixed (or bounded) regarding the limited computational power for simultaneous probes, but [21] uses a relaxed assumption by fixing the number of probes over a time window of a fixed length which may result in high number of probes at a single time step. Finally, [21] introduces a deterministic algorithm in which the number of probes to each feed is obtained by applying the Lagrange multipliers method (very similar result to Theorem 3), but they loose the guarantee on optimality of their solution, by rounding the estimated number of probes to integers. In contrast, our solution provides theoretical guarantee on optimality of our output schedule.\nWeb-crawling is another related topic, where a web-crawler aims to obtain the most recent snapshots of the web. However, it differs from our model substantially: in web-crawling algorithm data get updated, so missing some intermediate snapshot would not affect the quality of the algorithm, where in our model data are generated and they all need to be processed [3,22].\nThere has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7]. Our model deviates from the Outbreak Detection problem as it is geared to detection in virtual networks such as the Web or social networks embedded in the Internet, where a monitor can reach (almost) any node at about the same cost.\nAnother related problem is the Emerging Topic Detection problem, where the goal is to identify emergent topics in a social network, assuming full access to the stream of all postings. Besides having different objectives, our model differs mainly in this accessibility assumption: the social network providers have an immediate access to all tweets or postings as they are submitted to their servers, whereas in our model we consider an outside observer who needs an efficient mechanism to monitor changes, without having such full access privilege [2,15].\nIn the next section, we formally define our model and the Schedule Optimization problem."}, {"heading": "3 Model and Problem Definition", "text": "We study an infinite, discrete time process in which a set of n nodes, indexed by 1, . . . , n, generate new items according to a random generating process. The generating process at a given time step is characterized by a generating vector \u03c0 = (\u03c01, . . . , \u03c0n), where \u03c0i is the expected number of new items generated at\nnode i at that step (by either a Bernoulli or a Poisson process). The generation processes in different nodes are independent.\nWe focus first on a static generating process in which the generating vector does not change in time. We then extend our results to adapt to generating vectors that change in time.\nOur goal is to detect new events as fast as possible by probing in each step a small number of nodes. In particular, we consider probing schedules that can probe up to c nodes per step.\nDefinition 1 (Schedule). A c-schedule is a function S : N \u2192 {1, . . . , n}c specifying a set of c nodes to be probed at any time t \u2208 N. A deterministic function S defines a deterministic schedule, otherwise the schedule is random.\nDefinition 2 (Memoryless Schedule). A random schedule is memoryless if it is defined by a vector p = (p1, . . . , pn) such that at any step the schedule probes a set C of c items with probability \u220f\nj\u2208C pi independent of any other event. In that case we use the notation S = p.\nDefinition 3 (Cyclic Schedule). A schedule, S, is \u2113-cyclic if there is a finite time t0 such that from time t0 on, the schedule repeats itself every period of \u2113 steps. A schedule is cyclic if it is \u2113-cyclic for some positive integer \u2113.\nThe quality of a probing schedule is measured by the speed in which it discovers new items in the system. When a schedule probes a node i at a time t, all items that were generated at that node by time t\u2212 1 are discovered (thus, each item is not discovered in at least one step). We define the cost of a probing schedule as the long term expected number of undiscovered items in the system.\nDefinition 4 (Cost). The cost of schedule S in a system of n nodes with generating vector \u03c0 is\ncost (S, \u03c0) = lim t\u2192\u221e\n1\nt\nt \u2211\nt\u2032=1\nE [ QS(t) ]\n= lim t\u2192\u221e\n1\nt\nt \u2211\nt\u2032=1\nn \u2211\ni=1\nE [ QSi (t) ] ,\nwhere QSi (t) is the number of undiscovered items at node i and at time t, and QS(t) =\n\u2211n i=1 Q S i (t). The expectation is taken over the distribution of the gen-\nerating system and the probing schedule.\nWhile the cost can be unbounded for some schedules, the cost of the optimal schedule is always bounded. To see that, consider a round-robin schedule, S, that probes each node every n steps. Clearly no item is undiscovered in this schedule for more than n steps, and the expected number of items generated in an interval of n steps is n\n\u2211n i=1 \u03c0i. Thus, Q S(t) \u2264 n\u2211ni=1 \u03c0i, which implies cost (S, \u03c0) \u2264 n \u2211n\ni=1 \u03c0i. Therefore, without loss of generality we can restrict our discussion to bounded cost schedules. Also, note that when the sequence { E [ QS(t) ]} t\u2208N converges we have cost (S, \u03c0) = lim\nt\u2192\u221e E [ QS(t) ] (Cesaro Means [6]).\nOne can equivalently define the cost of a schedule in terms of the expected time that an item is in the system until it is discovered.\nLemma 1. Let \u03c9Si be the expected waiting time of an item generated at node i until node i is probed by schedule S. Then\ncost (S, \u03c0) = n \u2211\ni=1\n\u03c0i\u03c9 S i .\nProof. Following the definition of the cost function we have\ncost (S, \u03c0) = lim t\u2192\u221e\n1\nt\nt \u2211\nt\u2032=1\nn \u2211\ni=1\nE [ QSi (t \u2032) ] =\nn \u2211\ni=1\n[\nlim t\u2192\u221e\n\u2211t t\u2032=1 E\n[ QSi (t \u2032) ]\nt\n]\n=\nn \u2211\ni=1\n\u03c0i\u03c9 S i ,\nwhere the last eqaulity is obtained by applying Little\u2019s Law [12]. \u2293\u2294\nCorollary 1. A schedule that minimizes the expected number of undiscovered items in the system simultaneously minimizes the expected time that an item is\nundiscovered.\nCorollary 2. For any schedule S, cost (S, \u03c0) \u2265 \u2211n\ni=1 \u03c0i.\nProof. As mentioned above, when we probe a node i at time t we discover only the items that have been generated by time t \u2212 1. Therefore, \u03c9Si \u2265 1, and by Lemma 1 the proof is complete. \u2293\u2294\nNow, our main problem is defined as the following:\nDefinition 5 (Schedule Optimization). Given a generating vector \u03c0 and a positive integer c, find a c-schedule with minimum cost.\nWhen the generating vector is not known a priori to the algorithm the goal is to design a schedule that converges to an optimal one. For that we need the following definition:\nDefinition 6 (Convergence). We say schedule S converges to schedule S \u2032, if for any generating vector \u03c0, lim\nt\u2192\u221e\n\u2223 \u2223 \u2223E [ QS(t) ] \u2212 E [ QS \u2032 (t) ]\u2223 \u2223 \u2223 = 0."}, {"heading": "4 Results", "text": "We start this section by, first, showing that the obvious approach of maximizing the expected number of detections at each step is far from optimal. We then prove a lower bound on the cost of any schedule, and provide deterministic and memoryless c-schedules that are within a factor of (3 + (c \u2212 1)/c) and (2 + (c \u2212 1)/c), respectively, from the optimal. Finally, we introduce an algorithm, Adaptive , which outputs a scheduleA that converges to the optimalmemoryless 1-schedule when the generating vector \u03c0 is not known in advance. We also show that Adaptive can be used to obtain a c-schedule Ac whose cost is within (2 + (c\u2212 1)/c) factor of any optimal c-schedule.\nThroughout this section, by \u03c4Si (t) we mean the number of steps from the last time that node i was probed until time t, while executing schedule S; if i has\nnot been probed so far, we let \u03c4Si (t) = t. Using the definition, it is easy to see that\nE [ QSi (t) ] = \u03c0iE [ \u03c4Si (t) ] , (1)\nwhen the expectations are over the randomness of both S and \u03c0. Therefore, if the expectation is over only the randomness of \u03c0 we have\nE [ QSi (t) ] = \u03c0i\u03c4 S i (t). (2)"}, {"heading": "4.1 On Maximizing Immediate Gain", "text": "Let S be a 1-schedule that at each step, probes the node with the maximum expected number of undetected items. By (2), the expected number of undetected items at node i and at time t is \u03c0i\u03c4 S i (t), and thus, S(t) = argmaxi \u03c0i\u03c4Si (t).\nNow, suppose \u03c0i = 2 \u2212i, for 1 \u2264 i \u2264 n. Since the probability that node 1 has an undetected item in each step is at least 1/2, node i is probed no more than once in each 2i\u22121 steps. Thus, the expected number of time steps that an item at node i will stay undetected is at least 12i\u22121 (1+ . . .+2 i\u22121) = 2 i\u22121+1 2 > 2\ni\u22122. Using Lemma 1, the cost of this schedule is at least\n\u2211n i=1 \u03c0i\u03c9i > \u2211n i=1 2 \u2212i2i\u22122 = \u2126(n). Now, consider an alternative schedule that probes node i in each step with probability 2\u2212i/2/Z, where Z =\n\u2211n j=1 2 \u2212j/2. The expected number of steps\nbetween two probes of i is Z/2\u2212i/2, and the cost of this schedule is\nn \u2211\ni=1\n2\u2212i\n(\n2\u2212i/2 \u2211n\nj=1 2 \u2212j/2\n)\u22121\n=\n\n\nn \u2211\nj=1\n2\u2212j/2\n\n\n2\n= O(1).\nThus, optimizing immediate gain is not optimal in this problem."}, {"heading": "4.2 Lower Bound on Optimal Cost", "text": "In this section we provide a lower bound on the optimal cost, i.e., the cost of an optimal schedule.\nTheorem 1. For any c-schedule O with finite cost we have\ncost (O, \u03c0) \u2265 max\n\n\n\nn \u2211\ni=1\n\u03c0i, 1\n2c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n)2 \n\n\n.\nProof. First, by Corollary 2, cost (O, \u03c0) \u2265 \u2211ni=1 \u03c0i. Now we show cost (O, \u03c0) \u2265 1 2c ( \u2211n i=1 \u221a \u03c0i )2 . Fix a positive integer t > 0, and suppose during the time interval [0, t], O probes node i at steps t1, t2, . . . , tni . Let t0 = 0 and tni+1 = t. So, the sequence t0, . . . , tni+1 partition the interval [0, t] into ni + 1 intervals\nIi(j) = [tj + 1, tj+1], for 0 \u2264 j \u2264 ni, and the length of Ii(j) is \u2113i(j) = tj+1 \u2212 tj . Applying the Cauchy-Schwartz inequality we have:\nni \u2211\nj=0\n\u2113i(j) 2\nni \u2211\nj=0\n1 \u2265\n\n\nni \u2211\nj=0\n\u2113i(j)\n\n\n2\n=\u21d2 ni \u2211\nj=0\n\u2113i(j) 2 \u2265 1\nni + 1\n\n\nni \u2211\nj=0\n\u2113i(j)\n\n\n2\n= t2\nni + 1 =\nt2\nni\n(\n1\u2212 1 ni + 1\n)\n.\nFor t\u2032 \u2208 Ii(j), QOi (t\u2032) is a Poisson random variable with parameter \u03c0i(t\u2032 \u2212 tj). Therefore,\nt \u2211\nt=1\nE [ QOi (t \u2032) ] =\nni \u2211\nj=0\n\u2211\nt\u2032\u2208Ii(j) E [ QOi (t \u2032) ] = \u03c0i\nni \u2211\nj=0\n(1 + . . .+ \u2113i(j))\n= \u03c0i\nni \u2211\nj=0\n\u2113i(j)(\u2113i(j) + 1) 2 \u2265 \u03c0i 2\nni \u2211\nj=0\n\u2113i(j) 2 \u2265 \u03c0i\n2\nt2\nni\n(\n1\u2212 1 ni + 1\n)\n.\nBy summing over all nodes and averaging over t, we have\nn \u2211\ni=1\nt \u2211\nt\u2032=1\n1 t E [ QOi (t \u2032) ]\n\u2265 n \u2211\ni=1\n1\nt \u03c0i 2\nt2\nni\n(\n1\u2212 1 ni + 1\n)\n=\nn \u2211\ni=1\n\u03c0i 2 t\nni\n(\n1\u2212 1 ni + 1\n)\n\u2265 1 c\n(\nn \u2211\ni=1\nni t\n)(\nn \u2211\ni=1\n\u03c0i 2 t\nni\n(\n1\u2212 1 ni + 1\n)\n)\n\u2265 1 2c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n\u221a\n(\n1\u2212 1 ni + 1\n)\n)2\n, (3)\nwhere in the second line we use the fact that if the schedule executed c probes in each step then\n\u2211n i=1 ni t \u2264 c, and the third line is obtained by applying the\nCauchy-Schwartz inequality. It remains to show that for any schedule with finite cost, and any i such that \u03c0i > 0, lim t\u2192\u221e\nni = \u221e. For sake of contradiction assume that there is a time s such that the node i is never probed by O at time t > s. So, E [\nQOi (t) ] = \u03c0(t\u2212s) and we have cost (O, \u03c0) \u2265 1t \u2211t t\u2032=s E [ QOi ] (t) = \u03c0it (t\u2212s)(t\u2212s\u22121)\n2 which converges to \u221e as t \u2192 \u221e, which is a contradiction. Hence, for all i, lim\nt\u2192\u221e ni = \u221e, and using\n(4.2) we obtain\ncost (O, \u03c0) \u2265 lim t\u2192\u221e\n1\n2c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n\u221a\n(\n1\u2212 1 ni + 1\n)\n)2\n= 1\n2c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n)2\n,\nwhich completes the proof. \u2293\u2294\n4.3 Deterministic (3 + (c \u2212 1)/c)-Approximation Schedule\nWe construct a deterministic 1-schedule in which each node i is probed approximately every ni = \u2211n j=1 \u221a \u03c0j\u221a\n\u03c0i steps, and using that, present our (3 + (c\u2212 1)/c)-\napproximation schedule. For each i let ri be a nonnegative integer such that 2ri \u2265 ni > 2ri\u22121, and let \u03c1 = maxi ri. Lemma 2. There is a 2\u03c1-cyclic 1-schedule D such that node i is probed exactly every 2ri steps.\nProof. Without loss of generality assume \u2211n i=1 2 \u2212ri = 1, otherwise we can add auxiliary nodes to complete the sum to 1, with the powers (ri\u2019s) associated with the auxiliary nodes all bounded by \u03c1.\nWe prove the lemma by induction on \u03c1. If \u03c1 = 0, then there is only one node, and the schedule is 1-cyclic. Now, assume the statement holds for all \u03c1\u2032 < \u03c1. Since the smallest frequency is 2\u2212\u03c1, and the sum of the frequencies is 1, there must be two nodes, v and u, with same frequency 2\u2212\u03c1. Join the two nodes to a new node w with frequency 2\u2212\u03c1+1. Repeat this process for all nodes with frequency 2\u2212\u03c1. We are left with a collection of nodes all with frequencies > 2\u2212\u03c1. By the inductive hypothesis there is a ( 2\u03c1\u22121 )\n-cyclic schedule D\u2032 such that each node i is probed exactly each 2ri steps. In particular a node w that replaced u and v is probed exactly each 2\u2212\u03c1+1 steps.\nNow, we create an 2\u03c1-schedule, D, whose cycle is obtained by repeating the cycle of D\u2032 two times. For each probe to w that replaced a pair u, v, in the first cycle we probe u and in the second cycle we probe v. Thus, u and v are probed exactly every 2\u03c1 steps, and the new schedule does not change the frequency of probing nodes with frequency larger than 2\u2212\u03c1. \u2293\u2294 Theorem 2. The cost of the deterministic 1-schedule D is no more than 3 times of the optimal cost.\nProof. By Lemma 2 each node i is probed exactly every 2ri steps. Using 2ri\u22121 <\u2211n j=1\n\u221a \u03c0j\u221a\n\u03c0i we have 2ri + 1 \u2264 2\u00b7\n\u2211n j=1 \u221a \u03c0j\u221a\n\u03c0i + 1, and therefore\nlim t\u2192\u221e\n1\nt\nt \u2211\nt\u2032=1\nE [ QDi (t \u2032) ]\n= lim t\u2192\u221e\n1\nt\nt\n2ri\n2ri \u2211\nt\u2032=1\nE [ QDi (t \u2032) ]\n= 1\n2ri\n2ri \u2211\nt\u2032=1\n\u03c0it \u2032 = \u03c0i 2ri\n2ri(2ri + 1)\n2\n\u2264 \u03c0i 2\n(\n2 \u2211n\nj=1 \u221a \u03c0j\u221a\n\u03c0i + 1\n)\n= \u221a \u03c0i \u00b7\nn \u2211\nj=1\n\u221a \u03c0j + \u03c0i 2 .\nThus by Theorem 1, we have\ncost (D, \u03c0) = lim t\u2192\u221e\n1\nt\nn \u2211\ni=1\nt \u2211\nt\u2032=1\nE [ QDi (t \u2032) ]\n\u2264 n \u2211\ni=1\n\n \u221a \u03c0i \u00b7\nn \u2211\nj=1\n\u221a \u03c0j\n\n+ 1\n2\nn \u2211\ni=1\n\u03c0i\n=\n\n\nn \u2211\nj=1\n\u221a \u03c0j\n\n\n2\n+ 1\n2\nn \u2211\nj=1\n\u03c0j \u2264 3 \u00b7 cost (O, \u03c0) ,\nwhere cost (O, \u03c0) is the optimal cost. \u2293\u2294\nUsing the previous deterministic 1-schedule, the following corollary provides a c-schedule whose cost is within (3 + (c\u2212 1)/c) factor of the optimal cost.\nCorollary 3. There is a deterministic c-schedule Dc whose cost is at most (3 + (c\u2212 1)/c) times of the optimal cost.\nProof. Consider the execution of the deterministic 1-schedule D constructed in Theorem 2 on generating vector 1c\u03c0. Let Dc be a deterministic c-schedule obtained by grouping c consecutive probes of D into one step. Suppose O is an optimal c-schedule. Applying equation (1),\ncost (Dc, \u03c0) = n \u2211\ni=1\n\u03c0i\u03c9 Dc i =\nn \u2211\ni=1\n\u03c0i c c\u03c9D c\ni \u2264 n \u2211\ni=1\n\u03c0i c (\u03c9Di + c\u2212 1)\n= cost (D, \u03c0) + n \u2211\ni=1\n(c\u2212 1)\u03c0i c \u2264 3 ( n \u2211\ni=1\n\u221a\n\u03c0i c\n)2\n+\nn \u2211\ni=1\n(c\u2212 1)\u03c0i c\n= 3\n2c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n)2\n+ n \u2211\ni=1\n(c\u2212 1)\u03c0i c \u2264 ( 3 + c\u2212 1 c ) cost (O, \u03c0) ,\nwhere the first inequality holds because some items could be detected in less than c steps in the 1-schedule but are counted in one full step of the c-schedule. The last inequality is obtained by applying Theorem 1. \u2293\u2294"}, {"heading": "4.4 On Optimal Memoryless Schedule", "text": "Here, we consider memoryless schedules, and show that the memoryless 1-schedule with minimum cost can be easily computed. We call a memoryless schedule with minimum cost among memoryless schedules, an optimal memoryless schedule. We also provide an upper bound on the minimum cost of a memoryless c-schedule.\nTheorem 3. Let R = (p1, . . . , pn) be a memoryless 1-schedule. Then cost (R, \u03c0) \u2265 ( \u2211n\ni=1\n\u221a \u03c0i )2 , and the equality holds if and only if pi = \u221a \u03c0i\u2211\nn j=1 \u221a \u03c0j , for all i.\nProof. Since probing each node i is a geometric distribution with parameter pi, the expected time until an item generated in node i is discovered, is \u03c9 R i = 1/pi. Therefore, by Lemma 1, we have cost (R, \u03c0) = \u2211n\ni=1 \u03c0i pi . We find p\u2217 =\nargminS=p cost (R, \u03c0), using the Lagrange multipliers:\n\u2202\n\u2202pj\n(\nn \u2211\ni=1\n\u03c0i pi + \u03bb\nn \u2211\ni=1\npi\n)\n= 0 =\u21d2 pj \u221d \u221a \u03c0j .\nTherefore, cost (R, \u03c0) is minimized if pi = \u221a \u03c0i\u2211\nn j=1 \u221a \u03c0j , and in this case the (mini-\nmized) cost will be\ncost (R, \u03c0) = n \u2211\ni=1\n\n \u221a \u03c0i \u00b7\nn \u2211\nj=1\n\u221a \u03c0j\n\n =\n(\nn \u2211\ni=1\n\u221a \u03c0i\n)2\n. \u2293\u2294\nCorollary 4. The cost of the optimal memoryless 1-schedule is within a factor of 2 of the cost of any optimal 1-schedule.\nProof. The cost of the schedule R in Theorem 3 is ( \u2211n\ni=1\n\u221a \u03c0i )2 , which is\nbounded by 2 \u00b7 cost (O, \u03c0) for an optimal 1-schedule O using Theorem 1. \u2293\u2294\nCorollary 5. There is memoryless c-schedule, Rc, whose cost is within a factor of (2 + (c\u2212 1)/c) of any optimal c-schedule.\nProof. Suppose Rc is a memoryless c-schedule obtained by choosing c probes in each step, each chosen according to the optimal memoryless 1-schedule, R, computed in Theorem 3. Using the same argument as in the proof of Corollary 3 we have\ncost (Rc, \u03c0) \u2264 1 c\n(\nn \u2211\ni=1\n\u221a \u03c0i\n)2\n+ c\u2212 1 c\nn \u2211\ni=1\n\u03c0i \u2264 ( 2 + c\u2212 1 c ) cost (O, \u03c0) ,\nfor an optimal c-schedule O. \u2293\u2294"}, {"heading": "4.5 On Adaptive Algorithm for Memoryless Schedules", "text": "Assume now that the scheduling algorithm starts with no information on the generating vector \u03c0 (or that the vector has changed). We design and analyze an adaptive algorithm, Adaptive, that outputs a schedule A convergent to the optimal memoryless algorithm R (see Section 4.4) by gradually learning the vector \u03c0 by observing the system. To simplify the presentation we present and analyze a 1-schedule algorithm. The results easily scale up to any integer c > 1, where the adaptive algorithm outputs a c-schedule convergent to Rc (as in Section 4.4).\nEach iteration of the algorithm Adaptive starts with an estimate \u03c0\u0303 = (\u03c0\u03031, . . . , \u03c0\u0303n) of the unknown generating vector \u03c0 = (\u03c01, . . . , \u03c0n). Based on this estimate the algorithm chooses to probe node i with probability pi(t) = \u221a \u03c0\u0303i\u2211\nn j=1 \u221a \u03c0\u0303j (which is\nthe optimal memoryless schedule if t\u03c0 was the correct estimate). If nodes i is\nprobed at time t, the estimate of \u03c0i is updated to \u03c0\u0303i0 \u2190 max(1,ci0)\nt , where ci0 is the total number of new items discovered in that node since time 0.\nAlgorithm 1: Adaptive\nOutputs: A(t), for t = 1, 2, . . .. begin\n(c1, . . . , cn) \u2190 (0, . . . , 0); (\u03c0\u03031, . . . , \u03c0\u0303n) \u2190 (1, . . . , 1); for t = 1, 2, . . . do\nfor i \u2208 {1, . . . , n} do pi(t) \u2190 \u221a \u03c0\u0303i\u2211\nn j=1 \u221a \u03c0\u0303j ;\nA(t) \u223c p(t); output A(t); c\u2032 \u2190 number of new items caught at i0; ci0 \u2190 ci0 + c\u2032; \u03c0\u0303i0 \u2190 max(1,ci0) t ;\nWe denote the output of Adaptive schedule by A and the optimal memoryless 1-schedule by R = p\u2217 = (p\u22171, . . . , p\u2217n); see Section 4.4. Our main result of this section is the following theorem.\nTheorem 4. The schedule A converges toR, and thus, cost (A, \u03c0) = cost (R, \u03c0).\nTo prove Theorem 4 we need the following lemmas.\nLemma 3. For any time t and i \u2208 [n] we have pi(t) \u2265 1n\u221at .\nProof. It is easy to see that pi(t) will reach its lowest value at time t only if for j 6= i we have \u03c0\u0303j = 1 and \u03c0\u0303i = 1t\u22121 (which requires i to be probed at time t\u2212 1). Therefore, pi(t) \u2265 1/ \u221a t\u22121\n1/ \u221a t\u22121+n\u22121 = 1 1+(n\u22121) \u221a t\u22121 \u2265 1 n \u221a t . \u2293\u2294\nDefine \u03b4(t) = 4n exp ( \u2212\u03c0\u2217t1/36 ) and let N0 be the smallest integer t such that\nexp ( \u2212 \u221a t\n2n\n) \u2264 2 exp ( \u2212\u03c0\u2217t1/36 ) . Note that one can choose \u03b4(t) = 4n exp ( \u2212\u03c0\u2217t1/2\u2212\u01eb6 )\nfor any \u01eb \u2208 (0, 1/2), and for convenience we chose \u01eb = 1/6. Lemma 4. For any time t \u2265 N0, with probability \u2265 1 \u2212 \u03b4(t)/2, all the nodes are probed during the time interval [t/2, t) .\nProof. By Lemma 3, the probability of not probing i during the time interval [t/2, t) is at most\nt\u22121 \u220f\nt\u2032=t/2\n(1\u2212 pi(t\u2032)) \u2264 ( 1\u2212 1 n \u221a t\n)t/2\n\u2264 e\u2212 t 2n \u221a t \u2264 2 exp ( \u2212\u03c0\u2217t 1/3\n6\n)\n= \u03b4(t)\n2n .\nA union bound over all the nodes completes the proof. \u2293\u2294\nLemma 5. Suppose node i is probed at a time t\u2032 > t/2. Then,\nPr [ |\u03c0\u0303i(t\u2032)\u2212 \u03c0i| > t\u2212 1 3\u03c0i ] < \u03b4(t)\n2n .\nProof. We estimate \u03c0 from t\u2032 > t/2 steps, each with \u03c0i expected number of new items. Applying a Chernoff bound [18] for the sum of t\u2032 independent random variables with either Bernulli or Poisson distribution we have\nPr [ |\u03c0\u0303i(t\u2032)\u2212 \u03c0i| > t\u2212 1 3 \u03c0i ] < 2 exp\n(\n\u2212 t \u2212 2 3\u03c0it \u2032\n3\n) \u2264 2 exp ( \u2212 t \u2212 2 3\u03c0\u2217t\n6\n)\n= \u03b4(t)\n2n . \u2293\u2294\nNote that by union bound, Lemma 5 holds, with probability at least 1\u2212\u03b4(t)/2, for all the nodes that are probed after t/2.\nLemma 6. Suppose t \u2265 N0. With probability at least 1 \u2212 \u03b4(t) we have for all i \u2208 [n],\n(\n1\u2212 1 t1/3 + 1\n)\np\u2217i \u2264\n\u221a\n1\u2212 t\u22121/3 1 + t\u22121/3 p\u2217i \u2264 pi(t) \u2264\n\u221a\n1 + t\u22121/3 1\u2212 t\u22121/3 p \u2217 i \u2264 ( 1 + 1 t1/3 \u2212 1 ) p\u2217i\nProof. Applying Lemma 4, Lemma 5 and a union bound, with probability 1\u2212\u03b4(t) all the nodes are probed during the time [t/2, t) and |\u03c0\u0303i(t) \u2212 \u03c0i| \u2264 t\u22121/3\u03c0i for all i \u2208 [n]. Since pi(t) = \u221a \u03c0\u0303i(t)\n\u2211 j \u221a \u03c0\u0303j(t) , we obtain\npi(t) \u2265 \u221a (1\u2212 t\u22121/3)\u03c0i \u2211\nj\n\u221a (1 + t\u22121/3)\u03c0j =\n\u221a\n1\u2212 t\u22121/3 1 + t\u22121/3\n\u221a \u03c0i\n\u2211\nj\n\u221a \u03c0j =\n\u221a\n1\u2212 t\u22121/3 1 + t\u22121/3 p\u2217i \u2265 (1\u2212 1 t1/3 + 1 )p\u2217i\nwhere the last inequality uses the Taylor series of \u221a 1 + x. The upper bound is obtained by a similar argument. \u2293\u2294\nCorollary 6. The variation distance between the distribution p(t) = (p1(t), . . . , pn(t)) used by algorithm Adaptive at time t \u2265 N0, and the distribution p\u2217 = (p\u2217i , . . . , p\u2217n) used by the optimal memoryless algorithm satisfy\n\u2016 p(t)\u2212 p\u2217 \u2016= 1 2\nn \u2211\ni=1\n|pi(t)\u2212 p\u2217i | \u2264 n t1/3 \u2212 1 + \u03b4(t) t\u2192\u221e\u2212\u2192 0.\nFinally, we present our proof for Theorem 4.\nProof of Theorem 4. Recall that we defined \u03c4Si (t) as the number of steps from the last time that node i was probed until time t in an execution of an schedule S, and E [\nQSi ] = \u03c0iE [ \u03c4Si (t) ] .\nLet F (t) indicate the event that the inequalities in Lemma 6 are held for \u2200t\u2032 \u2208 [t/2, t). Therefore, Pr [F (t)] < 1 \u2212 \u03b4(t/2)\u00b7t2 by applying union bound over all t\u2032 \u2208 [t/2, t), and using the fact that \u03b4(t\u2032) \u2264 \u03b4(t/2). Therefore,\n|E [ QA(t) ] \u2212 E [ QR(t) ] | = \u2223 \u2223 \u2223\n\u2223 \u2223\nn \u2211\ni=1\n\u03c0iE [ \u03c4Ai (t) ]\n\u2212 n \u2211\ni=1\n\u03c0iE [ \u03c4Ri (t) ]\n\u2223 \u2223 \u2223 \u2223 \u2223\n\u2264 n \u2211\ni=1\n\u03c0i \u2223 \u2223E [ \u03c4Ai (t) ] \u2212 E [ \u03c4Ri (t) ]\u2223 \u2223\n\u2264 n \u2211\ni=1\n\u03c0i \u2223 \u2223E [ \u03c4Ai (t) ] \u2212 E [ \u03c4Ai (t) | F (t) ]\u2223 \u2223\n+\nn \u2211\ni=1\n\u03c0i \u2223 \u2223E [ \u03c4Ai (t) | F (t) ] \u2212 E [ \u03c4Ri (t) ]\u2223 \u2223 ,\nwhere we used the triangle inequality for both inequalities. So, it suffices to show that for every i,\nlim t\u2192\u221e\n\u2223 \u2223E [ \u03c4Ai (t) ] \u2212 E [ \u03c4Ai (t) | F (t) ]\u2223\n\u2223 = lim t\u2192\u221e\n\u2223 \u2223E [ \u03c4Ai (t) | F (t) ] \u2212 E [ \u03c4Ri (t) ]\u2223 \u2223 = 0.\nObviously, \u03c4Ai (t) \u2264 t. Now by letting t \u2265 2N0 we have,\nE [ \u03c4Ai (t) ] = Pr [F (t)]E [ \u03c4Ai (t) | F (t) ] + Pr [\u00acF (t)]E [ \u03c4Ai (t) | \u00acF (t) ]\n\u2264 E [ \u03c4Ai (t) | F (t) ]\n+ \u03b4(t/2)t\n2 t = E\n[ \u03c4Ai (t) | F (t) ]\n+ \u03b4(t/2)t2\n2 . (4)\nWe also get\nE [ \u03c4Ai (t) ]\n\u2265 ( 1\u2212 \u03b4(t/2)t 2 ) E [ \u03c4Ai (t) | F (t) ]\n(5)\n= E [ \u03c4Ai (t) | F (t) ] \u2212 \u03b4(t/2)t 2 E [ \u03c4Ai (t) | F (t) ] \u2265 E [ \u03c4Ai (t) | X ] \u2212 \u03b4(t)t 2 2 .\nNote that lim t\u2192\u221e\n\u03b4(t/2)t2\n2 = limt\u2192\u221e 4ne\n\u2212\u03c0\u2217t 1/3\n6 3\u221a 2 t2 = 0, and thus by (4) and (5) we have\nlim t\u2192\u221e\nE [ \u03c4Ai (t) ] \u2212 E [ \u03c4Ai (t) | F (t) ] = 0 \u21d2 lim t\u2192\u221e \u2223 \u2223E [ \u03c4Ai (t) ] \u2212 E [ \u03c4Ai (i) | F (t) ]\u2223 \u2223 = 0.\n(6)\nNow, we show that lim t\u2192\u221e\n\u2223 \u2223E [ \u03c4Ai (t) | F (t) ] \u2212 E [ \u03c4Ri (t) ]\u2223 \u2223 = 0. So here, we as-\nsume F (t) holds. So for every i \u2208 [n], node i is probed in [t/2, t), and for all t\u2032 \u2208 [t/2, t) we have\n(i) pi(t \u2032) \u2265\n(\n1\u2212 1 t\u20321/3+1\n) p\u2217i \u2265 ( 1\u2212 1 (t/2)1/3+1 ) p\u2217i . So,\nE [ \u03c4Ai (t) | F (t) ]\n\u2264 ( 1\u2212 1 (t/2)1/3 + 1\n)\u22121 1\np\u2217i =\n( 1 + (t/2)\u22121/3 ) 1\np\u2217i .\n(ii) pi(t \u2032) \u2264\n(\n1 + 1 t\u20321/3\u22121\n) p\u2217i \u2264 ( 1 + 1 (t/2)1/3\u22121 ) p\u2217i . Hence,\nE [ \u03c4Ai (t) | F (t) ]\n\u2265 ( 1 + 1\n(t/2)1/3 \u2212 1\n)\u22121 1\np\u2217i =\n( 1\u2212 (t/2)\u22121/3 ) 1\np\u2217i .\nObviously E [ \u03c4Ri (t) ] = 1p\u2217i , since probing node i by R can be viewed as a geometric distribution with parameter p\u2217i , and since \u03b4(t) \u2192 0 as t \u2192 \u221e we have\nE [ \u03c4Ri (t) ]\n= 1\np\u2217i = lim t\u2192\u221e\n( 1\u2212 (t/2)\u22121/3 ) 1\np\u2217i \u2264 lim t\u2192\u221e E [ \u03c4Ai (t) | F (t) ]\n\u2264 lim t\u2192\u221e\n( 1 + (t/2)\u22121/3 ) 1\np\u2217i =\n1\np\u2217i = E\n[ \u03c4Ri (t) ] .\nTherefore,\nlim t\u2192\u221e\n|E [ \u03c4Ai (t) | F (t) ] \u2212 E [ \u03c4Ri (t) ] | = 0. (7)\nThus, by (6) and (7) we have lim t\u2192\u221e\n|E [ QA(t) ] \u2212E [ QR(t) ] | = 0, and A converges to S, and since lim\nt\u2192\u221e E [ QS(t) ] = ( \u2211n i=1\n\u221a \u03c0i )2 , it implies that lim\nt\u2192\u221e E [ QA(t) ]\n= ( \u2211n\ni=1\n\u221a \u03c0i )2\n= cost (A, \u03c0) (by Cesaro Mean [6]). \u2293\u2294 Note that one can obtain an adaptive schedule Ac by choosing c probes in each step, at each round of Adaptive, and using similar argument as in Section 4.4 (and similar to Corollary 3), it is easy to see that Ac converges to Rc.\nFinally, if \u03c0 changes, the Adaptive algorithm converges to the new optimal memoryless algorithm, as the change in the rate of generating new items is observed by Adaptive."}], "references": [{"title": "Adaptive pull-based policies for wide area data delivery", "author": ["L. Bright", "A. Gal", "L. Raschid"], "venue": "ACM Transactions on Database Systems (TODS) 31(2), 631\u2013671", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Emerging topic detection on twitter based on temporal and social terms evaluation", "author": ["M. Cataldi", "L. Di Caro", "C. Schifanella"], "venue": "Proceedings of the Tenth International Workshop on Multimedia Data Mining. pp. 4:1\u20134:10. MDMKDD \u201910, ACM, New York, NY, USA", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "The discoverability of the web", "author": ["A. Dasgupta", "A. Ghosh", "R. Kumar", "C. Olston", "S. Pandey", "A. Tomkins"], "venue": "Proceedings of the 16th international conference on World Wide Web. pp. 421\u2013430. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "The growing role of news in trading automation (Oct 2009), http://www.machinereadablenews.com/images/dl/Machine_Readable_News_and_Algorithmic_Trading.pdf", "author": ["A. Delaney"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Alphaflash trader automated trading based on economic events", "author": ["D.B. Group"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Divergent series, vol", "author": ["G.H. Hardy"], "venue": "334. American Mathematical Soc.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1991}, {"title": "Review of sensor placement strategies for contamination warning systems in drinking water distribution systems", "author": ["W. Hart", "R. Murray"], "venue": "Journal of Water Resources Planning and Management 136(6), 611\u2013619", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "How computers trawl a sea of data for stock picks", "author": ["B. Hope"], "venue": "The Wall Street Journal (Apr 2015),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Online refresh strategies for content based feed aggregation", "author": ["R. Horincar", "B. Amann", "T. Arti\u00e8res"], "venue": "World Wide Web pp. 1\u201335", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficient sensor placement optimization for securing large water distribution networks", "author": ["A. Krause", "J. Leskovec", "C. Guestrin", "J. VanBriesen", "C. Faloutsos"], "venue": "Journal of Water Resources Planning and Management 134(6), 516\u2013526", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "The robot journalist in the age of social physics: The end of human journalism? In: The New World of Transitioned Media, pp", "author": ["N.L. Latar"], "venue": "65\u201380. Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Probability, Statistics, and Random Processes For Electrical Engineering (3rd Edition)", "author": ["A. Leon-Garcia"], "venue": "Prentice Hall, 3 edn.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J.M. VanBriesen", "N.S. Glance"], "venue": "Berkhin, P., Caruana, R., Wu, X. (eds.) KDD. pp. 420\u2013429. ACM", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Discovering the web\u2019s hidden alpha (Jun 2014), http://www.eaglealpha.com/whitepaper_pdf", "author": ["E.A. Ltd"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Twittermonitor: Trend detection over the twitter stream", "author": ["M. Mathioudakis", "N. Koudas"], "venue": "Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data. pp. 1155\u20131158. SIGMOD \u201910, ACM, New York, NY, USA", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Structured Data Challenges in Finance and Statistics (Nov 2011), http://www.slideshare.net/wesm/structured-data-challenges-in-finance-and-statistics", "author": ["W. McKinney"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "The handbook of news analytics in finance, vol", "author": ["G. Mitra", "L. Mitra"], "venue": "596. John Wiley & Sons", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Probability and computing: Randomized algorithms and probabilistic analysis", "author": ["M. Mitzenmacher", "E. Upfal"], "venue": "Cambridge University Press", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Deriving dynamics of web pages: A survey", "author": ["M. Oita", "P. Senellart"], "venue": "TWAW (Temporal Workshop on Web Archiving)", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "The battle of the water sensor networks (bwsn): A design challenge for engineers and algorithms", "author": ["A Ostfeld"], "venue": "Journal of Water Resources Planning and Management 134(6), 556\u2013568", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient monitoring algorithm for fast news alerts", "author": ["K.C. Sia", "J. Cho", "H.K. Cho"], "venue": "Knowledge and Data Engineering, IEEE Transactions on 19(7), 950\u2013961", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimal crawling strategies for web search engines", "author": ["J.L. Wolf", "M.S. Squillante", "P. Yu", "J. Sethuraman", "L. Ozsen"], "venue": "Proceedings of the 11th international conference on World Wide Web. pp. 136\u2013147. ACM", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2002}], "referenceMentions": [{"referenceID": 8, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 0, "context": "[9,21,1] Algorithmic Trading on Data.", "startOffset": 0, "endOffset": 8}, {"referenceID": 3, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 13, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 4, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 16, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 10, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 7, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 15, "context": "An emerging trend in algorithmic stock trading is the use of automatic search through the Web, the blogosphere, and social networks for relevant information that can be used in fast trading, before it appears in the more popular news sites [4,14,5,17,11,8,16].", "startOffset": 240, "endOffset": 259}, {"referenceID": 18, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 8, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 0, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 33, "endOffset": 41}, {"referenceID": 20, "context": "Among many introduced objectives [19,9,1] in studying this problem, the most similar one to our cost function is the delay function presented by [21].", "startOffset": 145, "endOffset": 149}, {"referenceID": 20, "context": "In [21] it is assumed that the rates of the news publication does not change, where in our setting these rates may change and our algorithm (Adaptive) can adapt itself to the new setting.", "startOffset": 3, "endOffset": 7}, {"referenceID": 20, "context": "Also, we assume at any given time the number of probes is fixed (or bounded) regarding the limited computational power for simultaneous probes, but [21] uses a relaxed assumption by fixing the number of probes over a time window of a fixed length which may result in high number of probes at a single time step.", "startOffset": 148, "endOffset": 152}, {"referenceID": 20, "context": "Finally, [21] introduces a deterministic algorithm in which the number of probes to each feed is obtained by applying the Lagrange multipliers method (very similar result to Theorem 3), but they loose the guarantee on optimality of their solution, by rounding the estimated number of probes to integers.", "startOffset": 9, "endOffset": 13}, {"referenceID": 2, "context": "However, it differs from our model substantially: in web-crawling algorithm data get updated, so missing some intermediate snapshot would not affect the quality of the algorithm, where in our model data are generated and they all need to be processed [3,22].", "startOffset": 251, "endOffset": 257}, {"referenceID": 21, "context": "However, it differs from our model substantially: in web-crawling algorithm data get updated, so missing some intermediate snapshot would not affect the quality of the algorithm, where in our model data are generated and they all need to be processed [3,22].", "startOffset": 251, "endOffset": 257}, {"referenceID": 19, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 125, "endOffset": 129}, {"referenceID": 12, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 9, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 6, "context": "There has been an extensive work on Outbreak Detection (motivated in part by the \u201cBattle of Water Sensors Network\u201d challenge [20]) using statistic or mobile sensor in physical domains, and regarding a variety of objectives [13,10,7].", "startOffset": 223, "endOffset": 232}, {"referenceID": 1, "context": "Besides having different objectives, our model differs mainly in this accessibility assumption: the social network providers have an immediate access to all tweets or postings as they are submitted to their servers, whereas in our model we consider an outside observer who needs an efficient mechanism to monitor changes, without having such full access privilege [2,15].", "startOffset": 364, "endOffset": 370}, {"referenceID": 14, "context": "Besides having different objectives, our model differs mainly in this accessibility assumption: the social network providers have an immediate access to all tweets or postings as they are submitted to their servers, whereas in our model we consider an outside observer who needs an efficient mechanism to monitor changes, without having such full access privilege [2,15].", "startOffset": 364, "endOffset": 370}, {"referenceID": 5, "context": "(Cesaro Means [6]).", "startOffset": 14, "endOffset": 17}, {"referenceID": 11, "context": "i=1 \u03c0i\u03c9 S i , where the last eqaulity is obtained by applying Little\u2019s Law [12].", "startOffset": 75, "endOffset": 79}, {"referenceID": 17, "context": "Applying a Chernoff bound [18] for the sum of t\u2032 independent random variables with either Bernulli or Poisson distribution we have Pr [ |\u03c0\u0303i(t)\u2212 \u03c0i| > t\u2212 1 3 \u03c0i ]", "startOffset": 26, "endOffset": 30}], "year": 2017, "abstractText": "We formulate and study a fundamental search and detection problem, Schedule Optimization, motivated by a variety of real-world applications, ranging from monitoring content changes on the web, social networks, and user activities to detecting failure on large systems with many individual machines. We consider a large system consists of many nodes, where each node has its own rate of generating new events, or items. A monitoring application can probe a small number of nodes at each step, and our goal is to compute a probing schedule that minimizes the expected number of undiscovered items at the system, or equivalently, minimizes the expected time to discover a new item in the system. We study the Schedule Optimization problem both for deterministic and randomized memoryless algorithms. We provide lower bounds on the cost of an optimal schedule and construct close to optimal schedules with rigorous mathematical guarantees. Finally, we present an adaptive algorithm that starts with no prior information on the system and converges to the optimal memoryless algorithms by adapting to observed data.", "creator": "LaTeX with hyperref package"}}}