{"id": "1509.07234", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Sep-2015", "title": "Sparsity-based Correction of Exponential Artifacts", "abstract": "however this paper describes an exponential transient excision simulation algorithm ( etea ). in biomedical time quan series analysis, e. g., in vivo neural recording and electrocorticography ( ecog ), some measurement time artifacts take the form of piecewise exponential transients. the proposed exponential method is formulated as an unconstrained convex parameter optimization problem, normally regularized by smoothed l1 - norm penalty function, problems which can be solved by majorization - minimization ( mm ) method. with either a slight modification of the integral regularizer, etea can also suppress more irregular piecewise smooth simulation artifacts, especially, ocular artifacts ( oa ) contained in electroencephalog - discrete raphy ( eeg ) data. examples of synthetic signal, eeg data, and artificial ecog data are presented to illustrate the proposed synthetic algorithms.", "histories": [["v1", "Thu, 24 Sep 2015 04:50:00 GMT  (1727kb)", "http://arxiv.org/abs/1509.07234v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["yin ding", "ivan w selesnick"], "accepted": false, "id": "1509.07234"}, "pdf": {"name": "1509.07234.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["(yd372@nyu.edu)"], "sections": [{"heading": null, "text": "ar X\niv :1\n50 9.\n07 23\n4v 1\n[ cs\n.L G\n] 2\n4 Se\np 20\nThis paper describes an exponential transient excision algorithm (ETEA). In biomedical time series analysis, e.g., in vivo neural recording and electrocorticography (ECoG), some measurement artifacts take the form of piecewise exponential transients. The proposed method is formulated as an unconstrained convex optimization problem, regularized by smoothed \u21131-norm penalty function, which can be solved by majorization-minimization (MM) method. With a slight modification of the regularizer, ETEA can also suppress more irregular piecewise smooth artifacts, especially, ocular artifacts (OA) in electroencephalography (EEG) data. Examples of synthetic signal, EEG data, and ECoG data are presented to illustrate the proposed algorithms."}, {"heading": "1 Introduction", "text": "This work is motivated by the problem of suppressing various types of artifacts in recordings of neural activity. In a recent study [25], typical artifacts in in vivo neural recordings are classified into four types (Type 0 to 3, see Section 2.2 and Figure 3 in [25]). This classification covers many artifacts in the scope of human brain activity recordings, e.g., electroencephalography (EEG) and electrocorticography (ECoG). In this paper, we consider the suppression of Type 0 and Type 1 artifacts. For the purpose of flexibility and generality, we redefine them in terms of morphological characteristics:\n\u2022 Type 0: a smooth protuberance that can be modeled as x\u0302(t) = te\u2212\u03b1t, when t > t0.\n\u2022 Type 1: an abrupt jump followed by an exponential decay that can be modeled as x\u0302(t) = e\u2212\u03b1t, when t > t0.\nFigure 1 shows examples of the two types of artifacts. We do not consider the other two types in this work because our previous works have addressed efficient algorithms to remove such artifacts. For instance, lowpass filtering/total variation denoising (LPF/TVD) [61] suppresses Type 2 artifacts (Figure 1c), and lowpass filtering/compound sparse denoising (LPF/CSD) [60, 61] can remove sparse and blocky spikes (Type 3 shown in Figure 1d).\nThe approach proposed in this paper is based on an optimization problem intended to capture the primary morphological characteristics of the artifacts using sparsity-inducing regularization. To formulate the problem, we model the observed time series as\ny(t) = f(t) + x(t) + w(t), (1)\nPreprint submitted to Signal Processing (Manuscript) Corresponding author: Yin Ding (yd372@nyu.edu)\nwhere f is a lowpass signal, x is a piecewise smooth transient signal (i.e., Type 0 or Type 1 artifacts), and w is stationary white Gaussian noise. More specifically, f is assumed to be restricted to a certain range of low frequencies. In other words, H(f) \u2248 0, where H is a high-pass filter. Note that in the signal model (1), conventional LTI filtering is not suitable to estimate either f or x from y, because component x, as a piecewise smooth signal comprised of transients, is not band limited.\nIn order to estimate the components, we combine LTI filtering with sparsity-based techniques. We formulate an optimization problem for both decomposition and denoising. A computationally efficient algorithm is derived to solve the optimization problem, based on the theory of majorization-minimization (MM) [15, 24, 36].\nIn addition, this paper specifies how to generate a smoothed penalty function and its majorizer from a non-smooth one, in order to overcome a numerical issue that arises when the penalty function is not differentiable."}, {"heading": "1.1 Related works", "text": "Some recent works recover signals with transients by various algorithms. In [19], a slowly varying signal is modeled as a local polynomial and an optimization problem using Tikhonov regularization is formulated to capture it. In [47], the slowly varying trend is modeled as a higher-order sparse-derivative signal (e.g., the third-order derivative is sparse).\nInstead of estimating the slowly varying component via regularization, the LPF/TVD method [61] estimates a lowpass component by LTI filtering and a piecewise constant component by optimization. In this case, an optimization problem is formulated to estimate the piecewise constant component. The approach proposed here uses a similar technique to recover the lowpass component, but in contrast to LPF/TVD, it is more general \u2014 the regularization is more flexible with a tunable parameter, so that LPF/TVD can be considered as a special case.\nAnother algorithm related to the approach taken in this paper is the transient artifact reduction algorithm (TARA) [60] which is utilized to suppress additive piecewise constant artifacts and spikes (similar to a hybrid of Type 2 and Type 3 artifact). The approaches proposed in this work target different types of artifacts (Type 0 and Type 1) and applied in different applications.\nThe irregularity of Type 0 transients leads to a more complicated artifact removal problem, where the artifact are irregular fluctuations. A typical example in EEG is ocular artifacts (OA) caused by the blink and/or movement of eyes. To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48]. The concept of spatial-frequency in acoustic analysis is also used to remove OA from multichannel signals [44, 64]. In this work, we present a new method to suppress ocular artifacts by proposing a specific model and using sparse optimization.\nThis paper adopts a regularizer inspired by the generalized 1-D total variation [27], wherein the derivative operator in conventional total variation regularizer is generalized to a recursive filter. The regularizers adopted in ETEA and second-order ETEA coincide with first-order and second-order cases of generalized 1-D total variation, respectively. Some differences to the problem discussed in [27] are as follow. Firstly, the signal model (1) allows a lowpass baseline as a component, hence, ETEA can be seen as a combination of conventional LTI filtering and generalized 1-D total variation. Secondly, we consider a formulation in terms of banded matrices, for computational efficiency. Thirdly, we give optimality conditions of the proposed problems, and use these conditions as a guide to set the regularization parameters."}, {"heading": "2 Preliminaries", "text": ""}, {"heading": "2.1 Notation", "text": "We use bold uppercase letters for matrices, e.g., A and B, and bold lowercase letters for vectors, e.g., x and y. We use column vectors for one-dimensional series. For example, a vector x \u2208 RN is written as\nx = [ x(0), x(1), \u00b7 \u00b7 \u00b7 , x(N \u2212 1) ]T\n(2)\nwhere [ \u00b7 ]T denotes matrix transpose. The \u21131-norm and squared \u21132-norm of x are defined as\n\u2016x\u20161 := \u2211\nn\n|x(n)|, \u2016x\u201622 := \u2211\nn\nx2(n). (3)\nThe inverse transpose of a matrix is denoted as A\u2212T. The first-order difference operator D of size (N\u22121)\u00d7N is\nD :=\n\n    \n\u22121 1 \u22121 1\n. . . . . .\n\u22121 1\n\n     . (4)\nWe use f(x; a) to denote a function of x determined by parameter a, to distinguish it from a function with\ntwo ordered arguments, e.g., f(x, y)."}, {"heading": "2.2 LTI filter with matrix formulation", "text": "A discrete-time filter can be described as\n\u2211\nk\nak y(n\u2212 k) = \u2211\nk\nbk x(n\u2212 k), (5)\nwith transfer function H(z) = B(z)/A(z). For a finite length signal, (5) can be rewritten as\nAy = Bx, (6)\nwhere A,B \u2208 RN\u00d7N are both banded matrices. When H is a zero-phase filter with a\u2212k = ak and b\u2212k = bk, then A and B are both symmetric Toeplitz matrices\nA =\n\n       \na1 a0 a0 a1 a0 . . . . . . . . .\na0 a1 a0\na0 a1\n\n        , (7a)\nB =\n\n       \nb1 b0 b0 b1 b0 . . . . . . . . .\nb0 b1 b0\nb0 b1\n\n        . (7b)\nIn this case, disregarding a few samples on both edges, y can be re-written as:\ny = BA\u22121x = Hx. (8)\nA detailed description of such zero-phase filters is given in Section V of Ref. [61], where two parameters, d and fc, determine the order of the filter and the cut-off frequency, respectively. In this paper, B is a square matrix, in contrast to [61]. The simplest case (d = 1) is given by (7)."}, {"heading": "2.3 Majorization-Minimization", "text": "Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57]. Suppose a minimization problem has a objective function J : RN \u2192 R, then the majorizer G(u,v) : RN \u00d7 RN \u2192 R satisfies\nG(u,v) = J(u), when u = v, (9a) G(u,v) > J(u), when u 6= v. (9b)\nThen MM iteratively solves\nu(k+1) = argmin u G(u,u(k)) (10)\nuntil convergence, where k is iteration index. The detailed derivation and proof of convergence of MM are given in [35]."}, {"heading": "3 Majorization of smoothed penalty function", "text": "When using sparse-regularized optimization to recover a signal, the \u21131-norm is widely utilized. To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo \u2113p-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33]. Other non-convex penalty functions can also be used. In [46] a logarithm penalty function is discussed (\u2018log\u2019 function in Table 1), and in [59], an arctangent function is used (\u2018atan\u2019 function Table 1). However, each of these functions is non-differentiable at zero, where \u03c6\u2032(0\u2212) 6= \u03c6\u2032(0+). A method, to avoid the discontinuity in the derivative, is to smooth the function.\nConsider the smoothed function \u03c6\u01eb : R \u2192 R+\n\u03c6\u01eb(u) := \u03c6(\u03c1(u; \u01eb)), (11)\nwhere function \u03c1 : R \u2192 R+ is defined as\n\u03c1(u; \u01eb) := \u221a u2 + \u01eb, \u01eb > 0. (12)\nBecause \u221a u2 + \u01eb is always greater than zero, \u03c6\u01eb has a continuous first-order derivative\n\u03c6\u2032\u01eb(u) = u\u221a\nu2 + \u01eb \u03c6\u2032(\n\u221a\nu2 + \u01eb). (13)\nTable 1 gives the smoothed penalty functions \u03c6\u01eb corresponding to \u03c6 in the first column, and Figure 2(ab) illustrates the penalty function and its smoothed version. The parameter \u01eb controls the similarity of \u03c6\u01eb to non-smooth function \u03c6. When \u01eb \u2192 0, \u03c6\u01eb(u) \u2248 \u03c6(u). In practice, we set \u01eb to a very small number (e.g. 10\u221210)."}, {"heading": "3.1 Majorization of smoothed penalty function", "text": "We assume the non-smooth function \u03c6 satisfies the following conditions:\n1. \u03c6(u) is continuous on R.\n2. \u03c6(u) is twice continuously differentiable on R\\{0}.\n3. \u03c6(u) is even symmetric: \u03c6(u) = \u03c6(\u2212u).\n4. \u03c6(u) is increasing and concave on R+.\nUnder such assumptions, we find a quadratic function g : R\u00d7 R \u2192 R,\ng(u, v;\u03c6) = \u03c6\u2032(v) 2v u2 + \u03c6(v)\u2212 v 2 \u03c6\u2032(v), (14)\nmajorizing \u03c6 when v 6= 0 [10, Lemma 1]. However, \u03c6 might not be differentiable at zero, e.g., all functions \u03c6 in Table 1. To avoid this issue, we use (11) to ensure the objective function is continuous and differentiable. Then the MM method can be applied without the occurrence of numerical issues (e.g., divide by zero). The following proposition indicates a suitable majorizer of the smoothed penalty functions.\nProposition 1. If function \u03c6 satisfies the listed four conditions in the previous paragraph and g in (14) is a majorizer of \u03c6, then\ng\u01eb(u, v;\u03c6\u01eb) = g(\u03c1(u; \u01eb), \u03c1(v; \u01eb);\u03c6), (15)\nis majorizer of \u03c6\u01eb(u) = \u03c6(\u03c1(u; \u01eb)) for u, v \u2208 R, and if writing explicitly, then g\u01eb in (15) is\ng\u01eb(u, v;\u03c6\u01eb) = u2\n2\u03c8(v) + \u03c6\u01eb(v)\u2212\nv 2 \u03c6\u2032\u01eb(v), (16)\nwhere \u03c8(v) = v/\u03c6\u2032\u01eb(v) 6= 0.\nThe proof of Proposition 1 is given in A. Figure 2c and Figure 2d give examples of using function (16) to\nmajorize the smoothed penalty functions in Figure 2a and Figure 2b, respectively."}, {"heading": "4 Exponential transient excision algorithm", "text": "To formulate the problem of exponential transient excision, we define R as\nR :=\n\n    \n\u2212r 1 \u2212r 1\n. . . . . .\n\u2212r 1\n\n     . (17)\nThe first-order derivative operator D is a special case of R with r = 1. In this paper we restrict 0 < r < 1 to distinguish them. As a filter, R can be seen to be a first-order filter attenuating low frequencies, with a transfer function\nR(z) := 1\u2212 rz\u22121. (18)\nDriving the system R(z) with the step exponential\nx(n) =\n \n\n0, n < n0, rn\u2212n0 , n > n0, (19)\nproduces an impulse \u03b4(n\u2212 n0) as an output. If input signal x is a step exponential with rate r, i.e., a Type 1 artifact, then\nv = Rx (20)\nwill be sparse.\nNote that r should be known beforehand. In practice, we can estimate it from the time-constant of a Type 1 artifact. Using observation data y, if we can measure the time N0 over which a Type 1 transient decays to half its initial height, then r can be found by solving rN0 = 0.5. We ignore the influence of the slowly varying baseline, as we assume the exponential decays much faster. If the transients have an approximately equal decay rate, then we can use an average measured form multiple transients."}, {"heading": "4.1 Problem definition", "text": "In signal model (1), if an estimate x\u0302 is known, then we can estimate f by\nf\u0302 = (y \u2212 x\u0302)\u2212H(y \u2212 x\u0302), (21)\nwhere H = BA\u22121 is a highpass filter, where the A and B matrices are both banded with a structure as (7). Correspondingly, noise w is y\u2212 (x\u0302+ f\u0302) = H(y\u2212 x\u0302), which indicates a suitable data fidelity term \u2016H(y\u2212x)\u201622. Moreover, when the component x is modeled as (19), we can use v = Rx as its sparse representation. Hence, we propose to formulate the estimation of x from noisy data y as the unconstrained optimization problem:\nx\u2217 = argmin x\n{\nP1(x) = \u2016H(y\u2212 x)\u201622 + \u03bb \u2211\nn\n\u03c6\u01eb([Rx]n) } , (22)\nwhere \u03bb > 0 is the regularization parameter related to noise level."}, {"heading": "4.2 Algorithm derivation", "text": "Using the majorizer of smoothed penalty function (16), and recalling thatH = BA\u22121 illustrated in Section 2.2, we majorize the objective function (22),\nG(x, z;P1) = \u2016H(y\u2212 x)\u201622 + \u03bb \u2211\nn\ng\u01eb([Rx]n, [Rz]n;\u03c6\u01eb)\n= \u2016BA\u22121(y \u2212 x)\u201622 + xTRT [ \u039b(Rz) ] Rx+ C (23)\nwhere C does not depend on x, and [ \u039b(Rz) ] \u2208 R(N\u22121)\u00d7(N\u22121) is a diagonal matrix\n[ \u039b(Rz) ]\nn,n =\n\u03bb\n2\u03c8([Rz]n) (24)\nwhere \u03c8(u) := u/\u03c6\u2032\u01eb(u), which is listed in Table 1. Then the minimizer of (23) is given by\nx = [ A\u2212TBTBA\u22121 +RT [ \u039b(Rz) ] R ]\n\u22121\nA\u2212TBTBA\u22121y. (25)\nNote that, calculating (25) directly requires the solution to a large dense system of equations. However,\nsince A is invertable, we can factor A out and write (25) as\nx(k+1) = A [ BTB+ATRT [ \u039b(Rx(k)) ] RA ]\n\u22121\nBTBA\u22121y, (26)\nwhere the MM procedure (10) is adopted with z = x(k). Note that the matrix to be inverted in (26) is banded, so that the solution can be computed efficiently by fast banded system solvers (e.g., [28, 29]). Moreover, in (26), all matrix multiplications are between banded ones. Table 2 summarizes the algorithm to solve (22)."}, {"heading": "4.3 Optimality condition and parameter selection", "text": "For problem (22), it is difficult to derive optimality conditions directly. Here, we consider the optimality condition indirectly via an equivalent problem, similar to the discussion of optimality condition for total\nvariation problems in [2, 17] and for LPF/TVD in [61].\nTo facilitate our derivation, we firstly denote the optimal solution of (22) by x\u2217. We then define v\u2217 = Rx\u2217\nwhere R is given by (17). We define G \u2208 RN\u00d7(N\u22121),\nG :=\n\n            \n0 1 0 r 1 0 r2 r 1 0 ... . . . . . . rN\u22123 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 r 1 0 rN\u22122 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 r2 r 1\n\n            \n(28)\nwhich satisfies\nRG = I. (29)\nThe operatorG acts as an inverse filter ofR. Using the above assumptions, we derive the following proposition regarding optimality conditions for (22).\nProposition 2. If x\u2217 is an optimal solution to (22), then v\u2217 = Rx\u2217 is an optimal solution to problem\nv\u2217 = argmin v Q(v), (30)\nwhere\nQ(v) = \u2016H(y0 \u2212Gv)\u201622 + \u03bb \u2211\nn\n\u03c6\u01eb([v]n). (31)\nand y0 = y \u2212 (x\u2217 \u2212GRx\u2217).\nProof. We define x0 \u2208 RN as\nx0 := Gv \u2217 = GRx\u2217 (32)\nwhere x\u2217 is the optimal solution to (22). Note that x0 and x \u2217 share an identical v\u2217 = Rx0 = Rx \u2217. Moreover, we define the difference between x\u2217 and x0 as\nd := x\u2217 \u2212 x0. (33)\nIt follows that Rd = Rx\u2217 \u2212Rx0 = 0. As a consequence, x0 is the optimal solution to problem\nx0 =argmin x P1(u) (34a)\ns.t. x = u\u2212 d. (34b)\nNote x0(0) = 0 must be satisfied in (34) because of the definition of G. Thus, we can write an equivalent problem to (34) using (32),\n{x0,v\u2217} = argmin x,v P1(u) (35a)\ns.t. x = u\u2212 d (35b) x = Gv (35c)\nwhere {x0,v\u2217} must be the optimal solution. In problem (35), u is uniquely determined by linear functions of v and d, so problem (35) can be simplified by substituting the variables,\n{x0,v\u2217} = argmin x,v Q(v) (36a)\ns.t. x = Gv (36b)\nwhere Q(v) = P1(u), with u = Gv + d, and can be written explicitly,\nQ(v) = \u2016H(y \u2212Gv \u2212 d)\u201622 + \u03bb \u2211\nn\n\u03c6\u01eb([RGv +Rd]n). (37)\nBecause RG = I and Rd = 0, we simplify (37) as\nQ(v) = \u2016H(y0 \u2212Gv)\u201622 + \u03bb \u2211\nn\n\u03c6\u01eb([v]n) (38)\nwhere y0 = y \u2212 d. In this case, the equality constraint in (36) is redundant. We can solve the unconstrained problem (30) first, and then compute x0 by (32). This implies that v \u2217 is the optimal solution to (30) and satisfies \u2207Q(v\u2217) = 0.\nUsing Proposition 2, instead of problem (22), we alternatively consider the optimality condition of problem (30) where as long as x\u2217 is an optimal solution of (22), v\u2217 is an optimal solution of (30). Moreover, we can rewrite the optimality condition of (30) as\np(n) = \u03bb\u03c6\u2032\u01eb([v \u2217]n) = \u03bb\u03c6 \u2032 \u01eb([Rx \u2217]n), (39)\nwhere p = 2GTHTH(y0 \u2212 x0), which can be rewritten as\np = 2GTHTH(y \u2212 x\u2217). (40)\nNote that, writing p as (40) does not require the solution to problem (30) or to compute d and y0. Therefore, although we derived an indirect way to verify the optimality condition for (22), the final procedure is direct.\nSetting parameter \u03bb. The equation (39) can be used as a guide to set the regularization parameter \u03bb. Suppose the observation data is composed of Gaussian noise only, then a proper value of \u03bb should make the solution of (22) almost identically zero. Thus, its sparse representation v\u2217, given by (20), should be all zero as well. In this case, we can calculate a vector q, which depends only on noise,\nq = 2GTHTHw. (41)\nWhen p is calculated by (40), we find a constraint that \u2212\u03bb < p(n) < \u03bb, by the property of \u03c6\u01eb. Furthermore, since x\u2217 \u2248 0 is expected when the observation is pure noise (i.e., y = w), the values of q \u2248 p can be\nconsidered bounded\nq(n) \u2208 [\u2212\u03bb,+\u03bb], when |v(n)| 6 \u03b2\u01eb, for n \u2208 ZN (42)\nwith high probability. The value \u03b2\u01eb here is related to \u01eb, and since \u01eb is extremely small, it can be simply assumed to be 0. As a consequence, the value of \u03bb needs to satisfy\n\u03bb > max { |2[GTHTHw]n|, n \u2208 ZN } . (43)\nFurther, if the statistical property of the noise can be exploited, e.g., w(n) \u223c N (0, \u03c32w), \u03bb can be set statistically, such that\n\u03bb = 2.5\u03c3w\u20162h1\u20162 (44)\nwhere \u03c3w is the standard deviation of the noise and h1 is the impulse response corresponding to system GTHTH. Note that, GTHTH is a filter with a transfer function P1(z) = H 2(z)/R(z). Hence, although we give the matrix G to derive the approach to set \u03bb, it is not required to compute h1 because the filter P1(z) can be implemented directly using H(z) in (8), and R(z) in (18)."}, {"heading": "4.4 Example: synthetic signal", "text": "To illustrate ETEA, the algorithm is tested on a simulated signal and compared to other methods. Figure 3 shows the test signal and its components: a lowpass signal f , a transient component x, composed of three exponential decays, and white Gaussian noise with \u03c3w = 0.20. The noisy observation is shown in Figure 3 in gray.\nDenoising. The result of conventional lowpass filtering is shown in Figure 4a. The result is smooth, but the step edges of each pulse are diminished. Moreover, if compared to the true low-pass baseline, the result is also distorted. The result of using LPF/TVD [61] is illustrated in Figure 4b. Although the abrupt jumps have been preserved, serious staircase effects appear. LPF/TVD uses the first-order derivative operator D in regularization. The derivative of an exponential is another exponential, therefore the derivative is unlikely to have a sufficiently sparse representation. A compensative method is to widen the bandwidth of the lowpass\nfilter, however, this leads to a noisy result. The result presented in Figure 4b is selected by tuning all necessary parameters of LPF/TVD to optimize RMSE (root-mean-square error) value.\nThe result of the proposed ETEA method is shown in Figure 4c. The step edges and decay behavior are well preserved (RMSE = 0.057). We use a smoothed \u21131-norm penalty function. In this example, we set \u01eb = 10\u221210, r = 0.94, filter order parameter d = 1, cut-off frequency fc = 0.013 cycle/sample, and regularization parameter is calculated by (44) based on the noise principle.\nDecomposition. Wavelet-based methods for artifact correction have been described in [1, 25, 40, 56]. In Figure 5a, we illustrate denoising and decomposition results obtained using the stationary (un-decimated) wavelet transform [11] with Haar wavelet using hard-threshold determined by the \u221a 2 logN\u03c3w thresholding scheme. The denoised result is further enhanced by the artifact-free denoising method [13, 14] which uses total variation minimization to overcome pseudo-Gibbs oscillations. Although the denoising output is relatively smooth and captures the discontinuities, the decomposed components are both distorted. Compared to the true components in Figure 3, the lowpass subband deviates from true lowpass component (especially at about n = 100). The transient component, reconstructed from other subbands after denoising, has to compensate for the error. Hence, the estimated transient component does not have a zero baseline (see bottom of Figure 5a).\nNon-convex penalty functions can be used to improve the result of ETEA. Here we use the smoothed non-convex logarithm penalty function in Table 1 (a = 2). The filtering result is shown in Figure 5b, where discontinuities are more accurately preserved, and the RMSE is reduced to 0.043 compared with the result in Figure 4c. We also illustrate the decomposed f and x components in Figure 5b. ETEA recovers both of the components accurately. The algorithm run-time is not affected by the choice of penalty function. In this example, 50 iterations of the algorithm takes about 25 ms on a MacBook Pro 2012 with a 2.7 GHz CPU, implemented in Matlab 8.4."}, {"heading": "4.5 Example: artifact removal of ECoG data", "text": "Conventional EEG studies and most clinical EEG applications are restricted below 75 Hz [51]. Advanced measuring methods such as ECoG records multichannel cortical potentials from the micro-electrodes located inside human skull with a higher sampling rate. In this example, we use a 5-second ECoG signal epoch, with a sampling rate of 2713 Hz, recorded from a mesial temporal lobe epilepsy (MTLE) patient.\nFigure 6a shows the raw data in gray and the corrected data by ETEA in black. There are two Type 1 artifacts identified in this 5-second epoch. One is at about t = 1.20 second, and the other is at about t = 3.60 second. In signal model (1), suppressing component x which represents artifacts, the corrected data (f + w) should preserve the components. We show the corrected data in Figure 6a, where the two Type 1 spikes are correctly removed. The decomposed artifact is illustrated in Figure 6a as well, which adheres a zero-baseline.\nSince wavelet-based methods have been successfully applied to suppress artifacts [1, 25, 40]. a comparison with a wavelet-based method is shown in Figure 6b. We use the stationary (un-decimated) wavelet transform [11] with Haar wavelet filter and the non-negative garrote threshold function [18],as recommended in [25]. The thresholding has been applied to all the subbands except the lowpass band, and the artifact component is obtained by subtracting the corrected data from the raw data. As shown, this approach estimates transient pulses but the estimated pulse adheres to the shape of the Haar wavelet filter: a positive-negative pulse (see the bottom square box in Figure 6b), but not the true Type 1 artifact in Figure 1b.\nTo more clearly illustrate the estimated results by the two methods, we show the details of the corrected data and the artifact from t = 3.50 to 3.65 second in dashed line boxes in Figure 1a and Figure 1b, respectively. Since the wavelet-based method cannot correctly estimate Type 1 artifact in this case, a \u2018bump\u2019 can be observed in Figure 6b to compensate the error. Moreover, this inappropriate estimation will cause the corrected data to change before Type 1 artifact actually occurs (see Figure 1b). In contrast, ETEA estimates the artifact as the abrupt drift with a decay, then it exicises the artifact without influencing the data before the transient occurs (see Figure 1a).\nIn this example, for the signal with a length of 13565 samples, the proposed algorithm converges within 40 iterations, and takes about 330 ms on a MacBook Pro 2012 with 2.7 GHz CPU, implemented in Matlab 8.4. The cost function history is shown in Figure 7."}, {"heading": "5 Higher-order ETEA", "text": "In the previous section, we have presented ETEA based on signal model (1), suitable for Type 1 artifacts, where the component x has discontinuous step exponential transients. Here we illustrate another version of ETEA based on signal model (1), where the component x models Type 0 artifacts.\nFirst, we consider the operator\nR2 :=\n\n    \nr2 \u22122r 1 r2 \u22122r 1\n. . . . . . . . .\nr2 \u22122r 1\n\n     , (45)\nwhere R2 \u2208 R(N\u22122)\u00d7N has three non-zero coefficients in each row. As a special case, when r = 1, R2 is the second-order difference operator, and \u2016R2x\u20161 is the same as the regularizer used in [30] for \u21131 detrending.\nTaking R2 as a filter, the transfer function is\nR2(z) = (1 \u2212 rz\u22121)2, (46)\nwhich has a double zero at z = r. The impulse response of system R\u221212 (z) is (n+ 1)r n, when n > 0. It has the same shape as Figure 1a, which is a suitable model for the Type 0 artifacts in [25]. Therefore, R2x is sparse when x is composed of such piecewise smooth transients. Similar to (22), we formulate the problem\nx\u2217 = argmin x\n{\nP2(x) = \u2016H(y\u2212 x)\u201622 + \u03bb \u2211\nn\n\u03c6\u01eb([R2x]n) }\n(47)\nto estimate the transient component x, so that the corrected data is y \u2212 x\u0302, and the low-pass trend f can be estimated by (21). Additionally, (47) can be easily solved by ETEA (in Table 2) substituting R by R2.\nAn example of complicated and irregular artifacts is the eye blink/movement artifacts in EEG data, which may have various morphologies and durations. In this case, we assume that the artifacts can be estimated by a continuous piecewise smooth waveform, generated by applying a certain sparse impulse sequence to R\u221212 (z)\n(46). In other words, we broaden our signal model so that the artifact is not only equivalent to an isolated Type 0 transient as in [25], but also a superposition of multiple such transients, with some freedom of scaling and shifting. The problem of estimating x can be solved by (47) in this case as well."}, {"heading": "5.1 Example: Simulated data", "text": "Figure 8 shows the simulated data and its lowpass and transient components. The transient component has several pulses with different heights and widths. They are obtained by feeding a sequence of impulses into system R\u221212 (z). The filter is given in (5) with ak = [1,\u22122r, r2], b0 = 1, and r = 0.950. Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].\nAs a comparison to the proposed approach, we use the EMD based denoising algorithm in [32], which uses wavelet coefficient thresholding techniques on decomposed IMFs. More specifically, we use clear first iterative interval thresholding (CIIT) with smoothly clipped absolute deviation (SCAD) penalty thresholding [31, 32], with 20 iterations, and the result is shown in Figure 9b. In this example, in order to perform decomposition, among the entire eight IMFs, the thresholding is performed on IMFs 1-5, their summation is considered as the transients illustrated in Figure 9a, and IMFs 6-8 are considered as the estimation of the lowpass component. The EMD based method achieves a decent denoising performance, but does not accurately estimate the components. For instance, the simulated data has a smooth dip at about n = 700 (circled in Figure 9a). EMD decomposes it into higher IMFs since they are varying slowly, which degrades the estimation. We may group the lowpass and transient components differently to avoid this problem, for instance, grouping IMF 1-6 together in order to include more oscillations into transient component, but this causes other distortion, where the decomposed transient component contains a lowpass signal and does not adhere to a baseline of zero.\nThe result obtained using second-order ETEA is illustrated in Figure 9b. ETEA estimates both the lowpass and transient components well, and recovers the signal by x+ f precisely with RMSE = 0.87 (with the smoothed \u21131 penalty function). The regularization parameter \u03bb for problem (47) was similar to (44),\n\u03bb \u2248 2.5\u03c3w\u20162h2\u20162, (48)\nwhere h2 is the impulse response of system H 2(z)/R2(z), and R2(z) is defined in (46). The decomposition is accurate. There are no compensating waveforms between the estimated x and f at n = 700, comparing to the estimation in Figure 9a.\nThrough numerical experiments, we found that second-order ETEA is not very sensitive to parameter r. Figure 9c shows the RMSE of denoising the data in Figure 8a, using r \u2208 [0.85, 0.99]. In this test, all filter parameters (fc and d) are the same and \u03bb is set by (48). In most cases, the results are better than EMD-CIIT. In addition, r should not be too small or very close to 1. If r has to be very small to yield a good estimation of component x, it must fluctuate extremely rapidly, then it must be closer to a sequence of sparse spikes (i.e., Type 3 artifacts in [25]), which differs from the signal model. For such a signal, other algorithms are more suitable, e.g., LPF/CSD [60, 61]. Similarly, if r has to be very close to 1 to fit the transients, then the transients must be very close to a piecewise linear signal, which is also not how we model the signal initially. As a consequence, we suggest to set r in the range 0.90 < r < 0.98."}, {"heading": "5.2 Example: ocular artifacts suppression", "text": "In this example, we use ETEA with R2 to correct EEG with eye blink/movement artifacts. Figure 10a shows a 10 second signal from channel Fp1, with sampling rate fs = 256 Hz, downloaded from [38]. As a channel located on forehead, Fp1 is very sensitive to the motion of eyes and eyebrows, and in this example, eye movement artifacts with large amplitudes are present through the entire signal. Applying second-order ETEA with r = 0.95, the results for corrected data and extracted OA are illustrated in Figure 10b.\nAs a comparison, we use multivariate empirical mode decomposition (MEMD) [52] to correct the data. MEMD is a recently developed algorithm extending conventional EMD. It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42]. In this example, we use 4 EEG channels (Fp1, Fp2, C3, C4) measured simultaneously as the input, and decompose the higher-index IMFs (low-frequency subbands) considered to be artifacts [53, Section V]. More specifically, among all 14 IMFs decomposed in this example, we use IMF 1-4 as the corrected data, and the rest as artifacts. The corrected data and estimated OA are shown in Figure 10c.\nFrom the results in Figure 10b and Figure 10c, ETEA estimates artifacts more clearly than MEMD. In the MEMD result, some small-amplitude higher frequency oscillations leak into the artifact (e.g., about t = 5.5 and 9.0 second). Moreover, some artifacts are introduced after applying MEMD method to correct the data,\n(e.g., about t = 3.0 and 9.5 second in Figure 10c). Some oscillations are generated as transients where the abrupt artifacts occur. In contrast, in Figure 10b, there are no oscillations introduced either in the estimated artifacts or the corrected data.\nComputational Efficiency. Figure 11 shows the average computation time as a function of the signal length. In this experiment, we calculate the time of computation of ETEA (22) and second-order ETEA (47) with different filter settings (controlled by parameter d), using input signal lengths from 5000 to 105. For each length, we average the computation time over 10 trials. For each trial, run 40 iterations of each algorithm. The experiment is implemented in Matlab 8.4 on a MacBook Pro 2012 with 2.7 GHz CPU.\nAs shown, the proposed algorithms have a run time of order O(N). Most of the computation time is consumed by the step of solving the linear system Q\u22121b in Table 2, where Q is a banded matrix and we use a fast banded solver.\nAdditionally, fast iterative shrinkage-thresholding algorithm (FISTA) [3, 7], which is an acceleration scheme for iterative shrinkage-thresholding algorithm (ISTA) [6], (a special formulation of MM) may be used to further accelerate the algorithm."}, {"heading": "6 Conclusion", "text": "This paper proposes a new algorithm for denoising and artifact removal for signals comprising artifacts arising in measured data, e.g., neural time-series recordings, using sparse optimization. The first algorithm, ETEA, assumes the signal is composed of a lowpass signal and an exponential transients (Type 1). It is formulated as an optimization problem regularized by differentiable and smooth penalty function. The second algorithm is an extension of ETEA, using a higher-order recursive filter, which is applicable for correction of continuous protuberance transients (Type 0), and more irregular artifacts. As applications, we have shown that ETEA with different regularizers (R and R2) are suitable for the suppression of Type 1 artifact in ECoG data and ocular artifacts (OA) (as sequential Type 0 artifacts) in conventional EEG data, with detailed comparisons to some state-of-the-art methods. Both of the above algorithms are computationally efficient because they are formulated in terms of banded matrices. A promising future work is to extend the above data correcting methods to multichannel data."}, {"heading": "Acknowledgments", "text": "The authors would like to thank Jonathan Viventi of the Department of Biomedical Engineering of Duke University, and Justin Blanco of the Electrical and Computer Engineering Department of United States\nNaval Academy, for providing the data and giving useful comments."}, {"heading": "A Proof of Proposition 1", "text": "Proof. Substitute the variables u and v in (14) by\nu = \u221a x2 + \u01eb, and v = \u221a z2 + \u01eb. (49)\nTherefore, for x, z \u2208 R, the inequality holds:\n\u03c6\u2032( \u221a z2 + \u01eb)\n2 \u221a z2 + \u01eb\n(x2 + \u01eb) + \u03c6( \u221a z2 + \u01eb)\u2212 \u221a z2 + \u01eb\n2 \u03c6\u2032(\n\u221a z2 + \u01eb) > \u03c6( \u221a x2 + \u01eb). (50)\nThe right of the inequality is the majorizer of the smoothed penalty function \u03c6( \u221a x2 + \u01eb). 1) If z 6= 0, we can multiply z to the nominator and denominator of the first term on the left side of (50),\n\u03c6\u2032( \u221a z2 + \u01eb)\n2 \u221a z2 + \u01eb\n(x2 + \u01eb) = x2\n2z\n(\n\u03c6\u2032( \u221a z2 + \u01eb) z\u221a\nz2 + \u01eb\n)\n+ \u01eb\n2z\n(\n\u03c6\u2032( \u221a z2 + \u01eb) z\u221a\nz2 + \u01eb\n)\n= x2\n2z \u03c6\u2032\u01eb(z) +\n\u01eb\n2z \u03c6\u2032\u01eb(z). (51)\nMultiplying the nominator and denominator of the third term on the left side of (50) by \u221a z2 + \u01eb,\n\u221a z2 + \u01eb\n2 \u03c6\u2032(\n\u221a z2 + \u01eb) = z2\n2 \u221a z2 + \u01eb\n\u03c6\u2032( \u221a z2 + \u01eb) + \u01eb\n2 \u221a z2 + \u01eb\n\u03c6\u2032( \u221a z2 + \u01eb)\n= z\n2\n(\n\u03c6\u2032( \u221a z2 + \u01eb) z\u221a\nz2 + \u01eb\n)\n+ \u01eb\n2z\n(\n\u03c6\u2032( \u221a z2 + \u01eb) z\u221a\nz2 + \u01eb\n)\n= z\n2 \u03c6\u2032\u01eb(z) +\n\u01eb\n2z \u03c6\u2032\u01eb(z). (52)\nUsing the results in (51) and (52), the inequality (50) can be rewritten as\nx2 2z \u03c6\u2032\u01eb(z) + \u01eb 2z \u03c6\u2032\u01eb(z) + \u03c6\u01eb(z)\u2212 z 2 \u03c6\u2032\u01eb(z)\u2212 \u01eb 2z \u03c6\u2032\u01eb(z) > \u03c6\u01eb(x), (53)\nwhich can be reorganize into\ng\u01eb(x, z;\u03c6\u01eb) = \u03c6\u2032\u01eb(z)\n2z x2 + \u03c6\u01eb(z)\u2212\nz 2 \u03c6\u2032\u01eb(z) > \u03c6\u01eb(x). (54)\n2) If z = 0 and x 6= 0, by Lagrange\u2019s Mean Value Theorem [55, Theorem 5.10], since function \u03c6(x) is continuous and \u03c6\u2032\u2032(x) 6 0 on x > 0, there exists a value \u03be in the range \u221a \u01eb < \u03be < \u221a x2 + \u01eb that \u03c6\u2032( \u221a \u01eb) > \u03c6\u2032(\u03be) > \u03c6\u2032( \u221a x2 + \u01eb) satisfying\n\u03c6\u2032(\u03be) ( \u221a x2 + \u01eb\u2212\u221a\u01eb ) = \u03c6( \u221a x2 + \u01eb)\u2212 \u03c6(\u221a\u01eb). (55)\nMoreover, consider the square that is always positive\n( \u221a x2 + \u01eb \u2212\u221a\u01eb)2 = x2 + \u01eb\u2212 2 \u221a \u01eb(x2 + \u01eb) + \u01eb > 0, (56)\nwhich implies the inequality\nx2 > 2 \u221a \u01eb(x2 + \u01eb)\u2212 2\u01eb. (57)\nFurthermore, we can multiply both sides of (57) by a positive term \u03c6\u2032(\n\u221a \u01eb)\n2 \u221a \u01eb , and then adopt the result from\n(55), so that:\n\u03c6\u2032( \u221a \u01eb)\n2 \u221a \u01eb\nx2 > \u03c6\u2032(\n\u221a \u01eb)\n2 \u221a \u01eb\n(\n2 \u221a \u01eb(x2 + \u01eb)\u2212 2\u01eb )\n(58a)\n= \u03c6\u2032( \u221a \u01eb) ( \u221a x2 + \u01eb\u2212\u221a\u01eb )\n(58b)\n> \u03c6\u2032(\u03be) ( \u221a x2 + \u01eb\u2212\u221a\u01eb )\n(58c)\n= \u03c6( \u221a x2 + \u01eb)\u2212 \u03c6(\u221a\u01eb), (58d)\nwhich leads to\n\u03c6\u2032( \u221a \u01eb)\n2 \u221a \u01eb\nx2 + \u03c6( \u221a \u01eb) > \u03c6( \u221a x2 + \u01eb). (59)\nBecause \u03c6\u01eb in (13) is differentiable on R, we can find its second-order derivative at zero,\nlim z\u21920\n\u03c6\u2032\u2032\u01eb (z) = \u03c6\u2032( \u221a \u01eb)\u221a \u01eb , (60)\nand by L\u2019Ho\u0302pital\u2019s rule [55, Theorem 5.13], we have\nlim z\u21920\n\u03c6\u2032\u01eb(z)\n2z = lim z\u21920\n\u03c6\u2032\u2032\u01eb (z)\n2 =\n\u03c6\u2032( \u221a \u01eb)\n2 \u221a \u01eb , (61)\nwhich implies that (59) is in the same form of the majorizer (54) at z = 0. 3) If x = z = 0, then the condition (9) follows immediately."}], "references": [{"title": "Employing spatially constrained ICA and wavelet denoising", "author": ["M.T. Akhtar", "W. Mitsuhashi", "C.J. James"], "venue": "for automatic removal of artifacts from multichannel EEG data. Signal Processing, 92(2):401\u2013 416", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimization with sparsity-inducing penalties", "author": ["F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski"], "venue": "Foundations and Trends in Machine Learning, 4(1):1\u2013106", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM J. Imag. Sci., 2(1):183\u2013202", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Enhancing sparsity by reweighted l1 minimization", "author": ["E.J. Cand\u00e8s", "M.B. Wakin", "S. Boyd"], "venue": "J. Fourier Anal. Appl.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Feature-enhanced synthetic aperture radar image formation based on nonquadratic regularization", "author": ["M. Cetin", "W.C. Karl"], "venue": "IEEE Trans. Image Process.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Nonlinear wavelet image processing: variational problems, compression, and noise removal through wavelet shrinkage", "author": ["A. Chambolle", "R.A. De Vore", "N.-Y. Lee", "B.J. Lucier"], "venue": "IEEE Trans. Image Process.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "On the convergence of the iterates of FISTA", "author": ["A. Chambolle", "V.R. Dossal"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Using empirical mode decomposition for iris recognition", "author": ["C.-P. Chang", "J.-C. Lee", "Y. Su", "P.S. Huang", "T.-M. Tu"], "venue": "Computer Standards & Interfaces, 31(4):729\u2013739", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Inter-trial analysis of postmovement beta activities in EEG signals using multivariate empirical mode decomposition", "author": ["H.-C. Chang", "P.-L. Lee", "M.-T. Lo", "Y.-T. Wu", "K.-W. Wang", "G.-Y. Lan"], "venue": "IEEE Trans. Neural Systems and Rehabilitation Engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Group-sparse signal denoising: Non-convex regularization, convex optimization", "author": ["P.-Y. Chen", "I.W. Selesnick"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Translation-invariant de-noising", "author": ["R.R. Coifman", "D.L. Donoho"], "venue": "A. Antoniadis, editor, Wavelets and Statistics. Springer-Verlag Lecture Notes", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1995}, {"title": "Integration of amplitude and phase statistics for complete artifact removal in independent components of neuromagnetic recordings", "author": ["J. Dammers", "M. Schiek", "F. Boers", "C. Silex", "M. Zvyagintsev", "U. Pietrzyk", "K. Mathiak"], "venue": "IEEE Trans. Biomed. Eng.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Artifact free signal denoising with wavelets", "author": ["S. Durand", "J. Froment"], "venue": "Proc. ICASSP", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "Reconstruction of wavelet coefficients using total variation minimization", "author": ["S. Durand", "J. Froment"], "venue": "SIAM J. Sci. Comput., 24(5):1754\u20131767", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "Majorization-minimization algorithms for wavelet-based image restoration", "author": ["M. Figueiredo", "J. Bioucas-Dias", "R. Nowak"], "venue": "IEEE Trans. Image Process.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Multivariate empirical mode decomposition and application to multichannel filtering", "author": ["J. Fleureau", "A. Kachenoura", "L. Albera", "J.-C. Nunes", "L. Senhadji"], "venue": "Signal Processing, 91(12):2783\u20132792", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "On sparse representations in arbitrary redundant bases", "author": ["J.-J. Fuchs"], "venue": "IEEE Trans. Inform. Theory, 50(6):1341\u20131344", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Wavelet shrinkage denoising using the non-negative garrote", "author": ["H. Gao"], "venue": "Journal of Computational and Graphical Statistics, 7(4):pp. 469\u2013488", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1998}, {"title": "A balanced combination of Tikhonov and total variation regularizations for reconstruction of piecewise-smooth signals", "author": ["A. Gholami", "S.M. Hosseini"], "venue": "Signal Processing, 93(7):1945\u20131960", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Automatic removal of ocular artefacts using adaptive filtering and independent component analysis for electroencephalogram data", "author": ["C. Guerrero-Mosquera", "A. Navia-V\u00e1zquez"], "venue": "IET Signal Processing, 6(2):99\u2013106", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech pitch determination based on Hilbert-Huang transform", "author": ["H. Huang", "J. Pan"], "venue": "Signal Processing,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "The empirical mode decomposition and Hilbert spectrum for nonlinear and non-stationary time series analysis", "author": ["N.E. Huang", "Z. Shen", "S.R. Long", "M.C. Wu", "H.H. Shih", "Q. Zheng", "N.C. Yen", "C.C. Tung", "H.H. Liu"], "venue": "Proc. Roy. Soc. Lon", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "A confidence limit for the empirical mode decomposition and Hilbert spectral analysis", "author": ["N.E. Huang", "M.-L.C. Wu", "S.R. Long", "S.S.P. Shen", "W. Qu", "P. Gloersen", "K.L. Fan"], "venue": "Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences, 459", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2037}, {"title": "A tutorial on MM algorithms", "author": ["D.R. Hunter", "K. Lange"], "venue": "Amer. Statist., 58:30\u201337", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2004}, {"title": "Artifact characterization and removal for in vivo neural recording", "author": ["M.K. Islam", "A. Rastegarnia", "A.T. Nguyen", "Z. Yang"], "venue": "Journal of Neuroscience Methods, 226(0):110\u2013123", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Automatic removal of eye movement and blink artifacts from EEG data using blind component separation", "author": ["C.A. Joyce", "I.F. Gorodnitsky", "M. Kutas"], "venue": "Psychophysiology, 41(2):313\u2013325", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "A signal processing approach to generalized 1-d total variation", "author": ["F.I. Karahanoglu", "I. Bayram", "D. Van De Ville"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Explicit formula for the inverse of a tridiagonal matrix by backward continued fractions", "author": ["E. Kilic"], "venue": "Applied Mathematics and Computation, 197(1):345\u2013357", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "The inverse of banded matrices", "author": ["E. Kilic", "P. Stanica"], "venue": "Journal of Computational and Applied Mathematics, 237(1):126\u2013135", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "l1 trend filtering", "author": ["S. Kim", "K. Koh", "S. Boyd", "D. Gorinevsky"], "venue": "SIAM Review, 51(2):339\u2013360", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Empirical mode decomposition based soft-thresholding", "author": ["Y. Kopsinis", "S. McLaughlin"], "venue": "16th European Signal Processing Conference", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Development of EMD-based denoising methods inspired by wavelet thresholding", "author": ["Y. Kopsinis", "S. McLaughlin"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Sparse regression using mixed norms", "author": ["M. Kowalski"], "venue": "Applied and Computational Harmonic Analysis, 27(3):303 \u2013 324", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "Sparse solutions of underdetermined linear systems", "author": ["I. Kozlov", "A. Petukhov"], "venue": "W. Freeden et al., editor, Handbook of Geomathematics. Springer", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimization", "author": ["K. Lange"], "venue": "Springer New York", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2004}, {"title": "Optimization transfer using surrogate objective functions", "author": ["K. Lange", "D. Hunter", "I. Yang"], "venue": "J. of Comp. Graph. Statist., 9:1\u201320", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2000}, {"title": "Automatic artifact rejection from multichannel scalp EEG by wavelet ICA", "author": ["N. Mammone", "F. La Foresta", "F.C. Morabito"], "venue": "IEEE J. Sensors,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2012}, {"title": "Empirical mode decomposition-based timefrequency analysis of multivariate signals: The power of adaptive data analysis", "author": ["D.P. Mandic", "N.U. Rehman", "Z. Wu", "N.E. Huang"], "venue": "Signal Processing Magazine,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2013}, {"title": "Wavelet-based motion artifact removal for functional near-infrared spectroscopy", "author": ["B. Molavi", "G.A. Dumont"], "venue": "Physiological Measurement, 33(2):259", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2012}, {"title": "Artifact suppression from EEG signals using data adaptive time domain filtering", "author": ["M.K.I. Molla", "M.R. Islam", "T. Tanaka", "T.M. Rutkowski"], "venue": "Neurocomputing, 97:297\u2013308", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Multivariate EMD based approach to EOG artifacts separation from EEG", "author": ["M.K.I. Molla", "T. Tanaka", "T.M. Rutkowski"], "venue": "Proc. ICASSP 2012, pages 653\u2013656", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "Separation of EOG artifacts from EEG signals using bivariate EMD", "author": ["M.K.I. Molla", "T. Tanaka", "T.M. Rutkowski", "A. Cichocki"], "venue": "Proc. ICASSP 2010, pages 562\u2013565", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2010}, {"title": "Removal of the eye-blink artifacts from EEGs via STF-TS modeling and robust minimum variance beamforming", "author": ["K. Nazarpour", "Y. Wongsawat", "S. Sanei", "J.A. Chambers", "S. Oraintara"], "venue": "IEEE Trans. Biomed. Eng., 55(9):2221\u20132231", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2008}, {"title": "Noisy signal recovery via iterative reweighted l1-minimization", "author": ["D. Needell"], "venue": "Proc. Forty-Third Asilomar Conference on Signals, Systems and Computers, pages 113\u2013117", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2009}, {"title": "Analysis of the recovery of edges in images and signals by minimizing nonconvex regularized least-squares", "author": ["M. Nikolova"], "venue": "Multiscale Modeling and Simulation, 4(3):960\u2013991", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2005}, {"title": "ECG enhancement and QRS detection based on sparse derivatives", "author": ["X. Ning", "I.W. Selesnick"], "venue": "Biomedical Signal Processing and Control, 8(6):713\u2013723", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2013}, {"title": "Online removal of eye movement and blink EEG artifacts using a high-speed eye tracker", "author": ["B. Noureddin", "P.D. Lawrence", "G.E. Birch"], "venue": "IEEE Trans. Biomed. Eng., 59(8):2103\u20132110", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2012}, {"title": "A time-frequency based approach for generalized phase synchrony assessment in nonstationary multivariate signals", "author": ["A. Omidvarnia", "G. Azemi", "P.B. Colditz", "B. Boashash"], "venue": "Digital Signal Processing, 23(3):780\u2013790", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2013}, {"title": "EEG gamma band oscillations differentiate the planning of spatially directed movements of the arm versus eye: Multivariate empirical mode decomposition analysis", "author": ["C. Park", "M. Plank", "J. Snider", "S. Kim", "H.C. Huang", "S. Gepshtein", "T.P. Coleman", "H. Poizner"], "venue": "IEEE Trans. Neural Systems and Rehabilitation Engineering,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2014}, {"title": "Biomedical Signal Analysis - A Case-study Approach", "author": ["R.M. Rangayyan"], "venue": "IEEE and Wiley, New York, NY", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2002}, {"title": "Multivariate empirical mode decomposition", "author": ["N.U. Rehman", "D.P. Mandic"], "venue": "Proceedings of the Royal Society A, 466", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2117}, {"title": "Filter bank property of multivariate empirical mode decomposition", "author": ["N.U. Rehman", "D.P. Mandic"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2011}, {"title": "One or two frequencies? The empirical mode decomposition answers", "author": ["G. Rilling", "P. Flandrin"], "venue": "IEEE Trans. Signal Process., 56(1):85\u201395", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2008}, {"title": "Principles of mathematical analysis", "author": ["W. Rudin"], "venue": "McGraw-Hill", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1976}, {"title": "Wavelet analysis for detecting body-movement artifacts in optical topography signals", "author": ["H. Sato", "N. Tanaka", "M. Uchida", "Y. Hirabayashi", "M. Kanai", "T. Ashida", "I. Konishi", "A. Maki"], "venue": "NeuroImage, 33(2):580\u2013 587", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2006}, {"title": "Majorization-minimization algorithms for nonsmoothly penalized objective functions", "author": ["E.D. Schifano", "R.L. Strawderman", "M.T. Wells"], "venue": "Electron. J. Statist., 4:1258\u20131299", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2010}, {"title": "Polynomial smoothing of time series with additive step discontinuities", "author": ["I.W. Selesnick", "S. Arnold", "V. Dantham"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2012}, {"title": "Sparse signal estimation by maximally sparse convex optimization", "author": ["I.W. Selesnick", "I. Bayram"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2014}, {"title": "Transient artifact reduction algorithm (TARA) based on sparse optimization", "author": ["I.W. Selesnick", "H.L. Graber", "Y. Ding", "T Zhang", "R.L. Barbour"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2014}, {"title": "Simultaneous low-pass filtering and total variation denoising", "author": ["I.W. Selesnick", "H.L. Graber", "S. Douglas", "S. Pfeil", "R.L. Barbour"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2014}, {"title": "Method for eliminating mode mixing of empirical mode decomposition based on the revised blind source separation", "author": ["B. Tang", "S. Dong", "T. Song"], "venue": "Signal Processing, 92(1):248\u2013258", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2012}, {"title": "Iterative reweighted l1 and l2 methods for finding sparse solutions", "author": ["D. Wipf", "S. Nagarajan"], "venue": "IEEE. J. Sel. Top. Signal Processing,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2010}, {"title": "Efficient implementation of RMVB for eyeblink artifacts removal of EEG via STF-TS modeling", "author": ["Y. Wongsawat"], "venue": "Proc. ROBIO 2008, pages 1567\u20131572", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2008}, {"title": "Illumination preprocessing for face images based on empirical mode decomposition", "author": ["X. Xie"], "venue": "Signal Processing, 103(0):250\u2013257", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2014}, {"title": "Dictionary learning for sparse approximations with the majorization method", "author": ["M. Yaghoobi", "T. Blumensath", "M.E. Davies"], "venue": "IEEE Trans. Signal Process.,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 2009}, {"title": "Improved Hilbert\u2013Huang transform based weak signal detection methodology and its application on incipient fault diagnosis and ECG signal analysis", "author": ["J. Yan", "L. Lu"], "venue": "Signal Processing, 98:74\u201387", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2014}, {"title": "Compressed sensing of complex-valued data", "author": ["S. Yu", "A.S. Khwaja", "J. Ma"], "venue": "Signal Processing, 92(2):357\u2013362", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2012}, {"title": "EOG artifact correction from EEG recording using stationary subspace analysis and empirical mode decomposition", "author": ["H. Zeng", "A. Song", "R. Yan", "H. Qin"], "venue": "Sensors, 13(11):14839\u201314859", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 24, "context": "In a recent study [25], typical artifacts in in vivo neural recordings are classified into four types (Type 0 to 3, see Section 2.", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "2 and Figure 3 in [25]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 59, "context": "For instance, lowpass filtering/total variation denoising (LPF/TVD) [61] suppresses Type 2 artifacts (Figure 1c), and lowpass filtering/compound sparse denoising (LPF/CSD) [60, 61] can remove sparse and blocky spikes (Type 3 shown in Figure 1d).", "startOffset": 68, "endOffset": 72}, {"referenceID": 58, "context": "For instance, lowpass filtering/total variation denoising (LPF/TVD) [61] suppresses Type 2 artifacts (Figure 1c), and lowpass filtering/compound sparse denoising (LPF/CSD) [60, 61] can remove sparse and blocky spikes (Type 3 shown in Figure 1d).", "startOffset": 172, "endOffset": 180}, {"referenceID": 59, "context": "For instance, lowpass filtering/total variation denoising (LPF/TVD) [61] suppresses Type 2 artifacts (Figure 1c), and lowpass filtering/compound sparse denoising (LPF/CSD) [60, 61] can remove sparse and blocky spikes (Type 3 shown in Figure 1d).", "startOffset": 172, "endOffset": 180}, {"referenceID": 14, "context": "A computationally efficient algorithm is derived to solve the optimization problem, based on the theory of majorization-minimization (MM) [15, 24, 36].", "startOffset": 138, "endOffset": 150}, {"referenceID": 23, "context": "A computationally efficient algorithm is derived to solve the optimization problem, based on the theory of majorization-minimization (MM) [15, 24, 36].", "startOffset": 138, "endOffset": 150}, {"referenceID": 35, "context": "A computationally efficient algorithm is derived to solve the optimization problem, based on the theory of majorization-minimization (MM) [15, 24, 36].", "startOffset": 138, "endOffset": 150}, {"referenceID": 18, "context": "In [19], a slowly varying signal is modeled as a local polynomial and an optimization problem using Tikhonov regularization is formulated to capture it.", "startOffset": 3, "endOffset": 7}, {"referenceID": 45, "context": "In [47], the slowly varying trend is modeled as a higher-order sparse-derivative signal (e.", "startOffset": 3, "endOffset": 7}, {"referenceID": 59, "context": "Instead of estimating the slowly varying component via regularization, the LPF/TVD method [61] estimates a lowpass component by LTI filtering and a piecewise constant component by optimization.", "startOffset": 90, "endOffset": 94}, {"referenceID": 58, "context": "Another algorithm related to the approach taken in this paper is the transient artifact reduction algorithm (TARA) [60] which is utilized to suppress additive piecewise constant artifacts and spikes (similar to a hybrid of Type 2 and Type 3 artifact).", "startOffset": 115, "endOffset": 119}, {"referenceID": 39, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 81, "endOffset": 97}, {"referenceID": 40, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 81, "endOffset": 97}, {"referenceID": 41, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 81, "endOffset": 97}, {"referenceID": 67, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 81, "endOffset": 97}, {"referenceID": 0, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 11, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 19, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 25, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 36, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 46, "context": "To suppress OA, there are approaches based on empirical mode decomposition (EMD) [41, 42, 43, 69], and on independent component analysis (ICA) methods [1, 12, 20, 26, 37, 48].", "startOffset": 151, "endOffset": 174}, {"referenceID": 42, "context": "The concept of spatial-frequency in acoustic analysis is also used to remove OA from multichannel signals [44, 64].", "startOffset": 106, "endOffset": 114}, {"referenceID": 62, "context": "The concept of spatial-frequency in acoustic analysis is also used to remove OA from multichannel signals [44, 64].", "startOffset": 106, "endOffset": 114}, {"referenceID": 26, "context": "This paper adopts a regularizer inspired by the generalized 1-D total variation [27], wherein the derivative operator in conventional total variation regularizer is generalized to a recursive filter.", "startOffset": 80, "endOffset": 84}, {"referenceID": 26, "context": "Some differences to the problem discussed in [27] are as follow.", "startOffset": 45, "endOffset": 49}, {"referenceID": 59, "context": "[61], where two parameters, d and fc, determine the order of the filter and the cut-off frequency, respectively.", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "In this paper, B is a square matrix, in contrast to [61].", "startOffset": 52, "endOffset": 56}, {"referenceID": 14, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 59, "endOffset": 71}, {"referenceID": 34, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 59, "endOffset": 71}, {"referenceID": 55, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 59, "endOffset": 71}, {"referenceID": 14, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 161, "endOffset": 177}, {"referenceID": 23, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 161, "endOffset": 177}, {"referenceID": 35, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 161, "endOffset": 177}, {"referenceID": 55, "context": "3 Majorization-Minimization Majorization-Minimization (MM) [15, 35, 57] is a procedure to replace a difficult optimization problem by a sequence of simpler ones [15, 24, 36, 57].", "startOffset": 161, "endOffset": 177}, {"referenceID": 34, "context": "The detailed derivation and proof of convergence of MM are given in [35].", "startOffset": 68, "endOffset": 72}, {"referenceID": 3, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 82, "endOffset": 97}, {"referenceID": 33, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 82, "endOffset": 97}, {"referenceID": 43, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 82, "endOffset": 97}, {"referenceID": 61, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 82, "endOffset": 97}, {"referenceID": 4, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 178, "endOffset": 197}, {"referenceID": 66, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 178, "endOffset": 197}, {"referenceID": 64, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 178, "endOffset": 197}, {"referenceID": 56, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 178, "endOffset": 197}, {"referenceID": 32, "context": "To further enhance sparsity, some methods use iteratively re-weighting procedures [4, 34, 45, 63], or a non-convex pseudo lp-norm (0 < p < 1), or a mixed-norm in the regularizer [5, 68, 66, 58, 33].", "startOffset": 178, "endOffset": 197}, {"referenceID": 44, "context": "In [46] a logarithm penalty function is discussed (\u2018log\u2019 function in Table 1), and in [59], an arctangent function is used (\u2018atan\u2019 function Table 1).", "startOffset": 3, "endOffset": 7}, {"referenceID": 57, "context": "In [46] a logarithm penalty function is discussed (\u2018log\u2019 function in Table 1), and in [59], an arctangent function is used (\u2018atan\u2019 function Table 1).", "startOffset": 86, "endOffset": 90}, {"referenceID": 27, "context": ", [28, 29]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 28, "context": ", [28, 29]).", "startOffset": 2, "endOffset": 10}, {"referenceID": 1, "context": "variation problems in [2, 17] and for LPF/TVD in [61].", "startOffset": 22, "endOffset": 29}, {"referenceID": 16, "context": "variation problems in [2, 17] and for LPF/TVD in [61].", "startOffset": 22, "endOffset": 29}, {"referenceID": 59, "context": "variation problems in [2, 17] and for LPF/TVD in [61].", "startOffset": 49, "endOffset": 53}, {"referenceID": 59, "context": "The result of using LPF/TVD [61] is illustrated in Figure 4b.", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "Wavelet-based methods for artifact correction have been described in [1, 25, 40, 56].", "startOffset": 69, "endOffset": 84}, {"referenceID": 24, "context": "Wavelet-based methods for artifact correction have been described in [1, 25, 40, 56].", "startOffset": 69, "endOffset": 84}, {"referenceID": 38, "context": "Wavelet-based methods for artifact correction have been described in [1, 25, 40, 56].", "startOffset": 69, "endOffset": 84}, {"referenceID": 54, "context": "Wavelet-based methods for artifact correction have been described in [1, 25, 40, 56].", "startOffset": 69, "endOffset": 84}, {"referenceID": 10, "context": "In Figure 5a, we illustrate denoising and decomposition results obtained using the stationary (un-decimated) wavelet transform [11] with Haar wavelet using hard-threshold determined by the \u221a 2 logN\u03c3w thresholding scheme.", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "The denoised result is further enhanced by the artifact-free denoising method [13, 14] which uses total variation minimization to overcome pseudo-Gibbs oscillations.", "startOffset": 78, "endOffset": 86}, {"referenceID": 13, "context": "The denoised result is further enhanced by the artifact-free denoising method [13, 14] which uses total variation minimization to overcome pseudo-Gibbs oscillations.", "startOffset": 78, "endOffset": 86}, {"referenceID": 49, "context": "5 Example: artifact removal of ECoG data Conventional EEG studies and most clinical EEG applications are restricted below 75 Hz [51].", "startOffset": 128, "endOffset": 132}, {"referenceID": 0, "context": "Since wavelet-based methods have been successfully applied to suppress artifacts [1, 25, 40].", "startOffset": 81, "endOffset": 92}, {"referenceID": 24, "context": "Since wavelet-based methods have been successfully applied to suppress artifacts [1, 25, 40].", "startOffset": 81, "endOffset": 92}, {"referenceID": 38, "context": "Since wavelet-based methods have been successfully applied to suppress artifacts [1, 25, 40].", "startOffset": 81, "endOffset": 92}, {"referenceID": 10, "context": "We use the stationary (un-decimated) wavelet transform [11] with Haar wavelet filter and the non-negative garrote threshold function [18],as recommended in [25].", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "We use the stationary (un-decimated) wavelet transform [11] with Haar wavelet filter and the non-negative garrote threshold function [18],as recommended in [25].", "startOffset": 133, "endOffset": 137}, {"referenceID": 24, "context": "We use the stationary (un-decimated) wavelet transform [11] with Haar wavelet filter and the non-negative garrote threshold function [18],as recommended in [25].", "startOffset": 156, "endOffset": 160}, {"referenceID": 29, "context": "As a special case, when r = 1, R2 is the second-order difference operator, and \u2016R2x\u20161 is the same as the regularizer used in [30] for l1 detrending.", "startOffset": 125, "endOffset": 129}, {"referenceID": 31, "context": "Figure 9: Example 3: Denoising and decomposition results by (a) EMD based denoising (EMD-CIIT [32]) and (b) ETEA.", "startOffset": 94, "endOffset": 98}, {"referenceID": 24, "context": "It has the same shape as Figure 1a, which is a suitable model for the Type 0 artifacts in [25].", "startOffset": 90, "endOffset": 94}, {"referenceID": 24, "context": "In other words, we broaden our signal model so that the artifact is not only equivalent to an isolated Type 0 transient as in [25], but also a superposition of multiple such transients, with some freedom of scaling and shifting.", "startOffset": 126, "endOffset": 130}, {"referenceID": 21, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 35, "endOffset": 43}, {"referenceID": 22, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 35, "endOffset": 43}, {"referenceID": 7, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 15, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 20, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 37, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 52, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 60, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 63, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 65, "context": "Empirical mode decomposition (EMD) [22, 23], a powerful method for analyzing signals, has been successfully utilized in different fields, including neuroscience, biometrics, speech recognition, electrocardiogram (ECG) analysis, and fault detection [8, 16, 21, 39, 54, 62, 65, 67].", "startOffset": 248, "endOffset": 279}, {"referenceID": 31, "context": "As a comparison to the proposed approach, we use the EMD based denoising algorithm in [32], which uses wavelet coefficient thresholding techniques on decomposed IMFs.", "startOffset": 86, "endOffset": 90}, {"referenceID": 30, "context": "More specifically, we use clear first iterative interval thresholding (CIIT) with smoothly clipped absolute deviation (SCAD) penalty thresholding [31, 32], with 20 iterations, and the result is shown in Figure 9b.", "startOffset": 146, "endOffset": 154}, {"referenceID": 31, "context": "More specifically, we use clear first iterative interval thresholding (CIIT) with smoothly clipped absolute deviation (SCAD) penalty thresholding [31, 32], with 20 iterations, and the result is shown in Figure 9b.", "startOffset": 146, "endOffset": 154}, {"referenceID": 24, "context": ", Type 3 artifacts in [25]), which differs from the signal model.", "startOffset": 22, "endOffset": 26}, {"referenceID": 58, "context": ", LPF/CSD [60, 61].", "startOffset": 10, "endOffset": 18}, {"referenceID": 59, "context": ", LPF/CSD [60, 61].", "startOffset": 10, "endOffset": 18}, {"referenceID": 50, "context": "As a comparison, we use multivariate empirical mode decomposition (MEMD) [52] to correct the data.", "startOffset": 73, "endOffset": 77}, {"referenceID": 8, "context": "It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42].", "startOffset": 78, "endOffset": 89}, {"referenceID": 48, "context": "It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42].", "startOffset": 78, "endOffset": 89}, {"referenceID": 47, "context": "It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42].", "startOffset": 78, "endOffset": 89}, {"referenceID": 51, "context": "It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42].", "startOffset": 163, "endOffset": 171}, {"referenceID": 40, "context": "It has been used in different aspects of EEG signal analysis and applications [9, 50, 49], including removing the ocular artifacts (OA) from multichannel EEG data [53, 42].", "startOffset": 163, "endOffset": 171}, {"referenceID": 2, "context": "Additionally, fast iterative shrinkage-thresholding algorithm (FISTA) [3, 7], which is an acceleration scheme for iterative shrinkage-thresholding algorithm (ISTA) [6], (a special formulation of MM) may be used to further accelerate the algorithm.", "startOffset": 70, "endOffset": 76}, {"referenceID": 6, "context": "Additionally, fast iterative shrinkage-thresholding algorithm (FISTA) [3, 7], which is an acceleration scheme for iterative shrinkage-thresholding algorithm (ISTA) [6], (a special formulation of MM) may be used to further accelerate the algorithm.", "startOffset": 70, "endOffset": 76}, {"referenceID": 5, "context": "Additionally, fast iterative shrinkage-thresholding algorithm (FISTA) [3, 7], which is an acceleration scheme for iterative shrinkage-thresholding algorithm (ISTA) [6], (a special formulation of MM) may be used to further accelerate the algorithm.", "startOffset": 164, "endOffset": 167}], "year": 2015, "abstractText": "This paper describes an exponential transient excision algorithm (ETEA). In biomedical time series analysis, e.g., in vivo neural recording and electrocorticography (ECoG), some measurement artifacts take the form of piecewise exponential transients. The proposed method is formulated as an unconstrained convex optimization problem, regularized by smoothed l1-norm penalty function, which can be solved by majorization-minimization (MM) method. With a slight modification of the regularizer, ETEA can also suppress more irregular piecewise smooth artifacts, especially, ocular artifacts (OA) in electroencephalography (EEG) data. Examples of synthetic signal, EEG data, and ECoG data are presented to illustrate the proposed algorithms.", "creator": "LaTeX with hyperref package"}}}