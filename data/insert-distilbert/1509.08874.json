{"id": "1509.08874", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2015", "title": "Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2014", "abstract": "this research explores effects of various training settings between polish and using english statistical standard machine translation systems for spoken language. various elements of the ted parallel text development corpora for the iwslt 2014 evaluation campaign were individually used as the basis for training of language models, and for development, tuning and testing of the translation automation system as well as wikipedia based comparable corpora prepared by us. the bleu, nist, wi meteor and ter metrics were used to evaluate the effects of data preparations on translation results. our language experiments included systems, which use lemma and morphological information on polish words. we also conducted a deep analysis of provided polish data as preparatory standard work patterns for describing the automatic data correction and cleaning phase.", "histories": [["v1", "Tue, 29 Sep 2015 18:17:22 GMT  (303kb)", "http://arxiv.org/abs/1509.08874v1", "Machine Translation, West slavic, Proceedings of the 11th International Workshop on Spoken Language Translation, Tahoe Lake, USA, 2014. arXiv admin note: text overlap witharXiv:1409.0473by other authors"]], "COMMENTS": "Machine Translation, West slavic, Proceedings of the 11th International Workshop on Spoken Language Translation, Tahoe Lake, USA, 2014. arXiv admin note: text overlap witharXiv:1409.0473by other authors", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["krzysztof wo{\\l}k", "krzysztof marasek"], "accepted": false, "id": "1509.08874"}, "pdf": {"name": "1509.08874.pdf", "metadata": {"source": "CRF", "title": "Polish - English Speech Statistical Machine Translation Systems for the IWSLT 2014", "authors": ["Krzysztof Wo\u0142k", "Krzysztof Marasek"], "emails": ["kwolk@pja.edu.pl,", "kmarasek@pja.edu.pl"], "sections": [{"heading": "1. Introduction", "text": "Polish is one of the complex West-Slavic languages, which represents a serious challenge to any SMT system. The grammar of the Polish language, with its complicated rules and elements, together with a big vocabulary (due to complex declension) are the main reasons for its complexity (in Polish there are seven cases, three genders, animate and inanimate nouns, adjectives agreed with nouns in terms of gender, case and number and a lot of words borrowed from other languages which are often inflected similarly to those of Polish origin).\nThis greatly affects the data and data structure required for statistical models of translation. The lack of available and appropriate resources required for data input to SMT systems presents another problem. SMT systems should work best in specified, not too wide text domains and will not perform well for general use. Good quality parallel data, especially in a required domain has low availability. In general, Polish and English differ also in syntax. English is a positional language, which means that the syntactic order (the order of words in a sentence) plays a very important role, particularly due to limited inflection of words (e.g. lack of declension endings). Sometimes, the position of a word in a sentence is the only indicator of the sentence meaning. In the English sentence, the subject group comes before the predicate, so the sentence is ordered according to the Subject-Verb-Object (SVO) schema. In Polish, however, there is no specific word order imposed and the word order has no decisive influence on the understanding of the sentence. One can express the same thought in several ways, which is not possible in English. For example, the sentence \u201eI just tasted a new orange juice.\u201d can be written in Polish as \u201eSpr\u00f3bowa\u0142em w\u0142a\u015bnie nowego soku pomara\u0144czowego\u201d, or \u201dNowego soku pomara\u0144czowego w\u0142a\u015bnie spr\u00f3bowa\u0142em.\u201d, or \u201dW\u0142a\u015bnie spr\u00f3bowa\u0142em nowego soku pomara\u0144czowego.\u201d, or \u201eW\u0142a\u015bnie nowego soku pomara\u0144czowego spr\u00f3bowa\u0142em.\u201d Differences in potential\nsentence orders make the translation process more complex, especially when working on a phrase-model with no additional lexical information.\nAs a result starting point was much lower than for other languages, however our progress in last 3 years was faster than others [1,2]. The aim of this work is to create an SMT system for translation from Polish to English (and the other way round, i.e. from English to Polish) to address the IWSLT 2014 [3] evaluation campaign requirements. This paper is structured as follows: Section 2 explains the Polish data preparation. Section 3 presents the English language issues. Section 4 describes the translation evaluation methods. Section 5 presents the results. Lastly in Section 6 we summarize potential implications and ideas for future work."}, {"heading": "2. Preparation of the Polish data", "text": "The Polish data in the TED talks (about 17 MB) include almost 2,5 million words that are not tokenized. The transcripts themselves are provided as pure text encoded with UTF-8 and the transcripts are prepared by the IWSLT team [4]. In addition, they are separated into sentences (one per line) and aligned in language pairs.\nIt should be emphasized that both automatic and manual preprocessing of this training information was required. The extraction of the transcription data from the provided XML files ensured an equal number of lines for English and Polish. However, some of the discrepancies in the text parallelism could not be avoided. These discrepancies are mainly repetitions of the Polish text not included in the English text.\nAnother problem was that TED 2013 data was full of errors. [5]. For the IWSLT 2014 we helped in repairing those errors in train, test and development sets. It was done semiautomatically by the usage of our tool described in [6]. We repaired spelling errors that artificially increased the dictionary size in Polish side of the corpora. Additionally we filtered out and repaired bi-sentences with odd nesting, such as: Part A, Part A, Part B, Part B. e.g. \u201cAle b\u0119d\u0119 stara\u0142 si\u0119 udowodni\u0107, \u017ce mimo z\u0142o\u017cono\u015bci, Ale b\u0119d\u0119\nstara\u0142 si\u0119 udowodni\u0107, \u017ce mimo z\u0142o\u017cono\u015bci, istniej\u0105 pewne rzeczy pomagaj\u0105ce w zrozumieniu. istniej\u0105 pewne rzeczy\npomagaj\u0105ce w zrozumieniu.\u201d\nSome parts (words or full phrases or even whole sentences) were duplicated. Furthermore, there were segments containing repetitions of whole sentences inside a single segment. For instance: Sentence A. Sentence A. e.g.\n\u201cZakumuluj\u0105 si\u0119 u tych najbardziej pijanych i sk\u0105pych. Zakumuluj\u0105 si\u0119 u tych najbardziej pijanych i sk\u0105pych.\u201d\nor\nPart A, Part B, Part B, Part C e.g.\n\u201d Matka mo\u017ce si\u0119 ponownie rozmna\u017ca\u0107, ale jak wysok\u0105 cen\u0119 p\u0142aci, przez akumulacj\u0119 toksyn w swoim organizmie - przez akumulacj\u0119 toksyn w swoim organizmie - \u015bmier\u0107 pierwszego\nm\u0142odego.\u201d\nOverall, in the train set we found about 7% of spelling errors and about 15% of insertion errors. Luckily such problems occur only on the Polish side of the corpora. In our opinion the pre-processing tools used to align the corpus were not adjusted for the Polish language. Cleaning those problems increases BLEU score by the factor of 1,5 \u2013 2.\nThe number of unique Polish words and their forms was 144,115 and 59,296 English unique word forms. The disproportionate vocabulary sizes are also a challenge especially in translation from English to Polish.\nAnother problem is that the TED Talks do not have any specific domain. Statistical Machine Translation by definition works best when very specific domain data is used. The data we have is a mix of various, unrelated topics. This is most likely the reason why we cannot expect big improvements with this data and generally low scores in translation quality metrics.\nThere is not much focus on Polish in the campaign, so there is almost no additional data in Polish in comparison to a huge amount of data in, for example, French or German. At first we used perplexity measurement metrics to determine the data we obtained. Some of the data we were able to obtain from the OPUS [12] project page, some from another small projects and the rest was collected manually using web crawlers. We created those corpora and used them. What we created was:\n\u2022 A Polish \u2013 English dictionary (bilingual parallel)\n\u2022 Additional (newer) TED Talks data sets not included in the original train data (we crawled bilingual data and created a corpora from it) (bilingual parallel)\n\u2022 E-books (monolingual PL + monolingual EN)\n\u2022 Proceedings of UK House of Lords (monolingual EN)\n\u2022 Subtitles for movies and TV series (monolingual PL)\n\u2022 Parliament and senate proceedings (monolingual PL)\n\u2022 Wikipedia Comparable Corpus (bilingual parallel)\n\u2022 Euronews Comparable Corpus (bilingual parallel)\n\u2022 Repository of PJIIT\u2019s diplomas (monolingual PL)\n\u2022 Many PL monolingual data web crawled from main web portals like blogs, chip.pl, Focus newspaper archive, interia.pl, wp.pl, onet.pl, money.pl, Usenet, Termedia, Wordpress web pages, Wprost newspaper archive, Wyborcza newspaper archive, Newsweek newspaper archive, etc.\n\u201cOther\u201d in the table below stands for many very small models merged together. In Table 1 we show the perplexity values of the obtained data with no smoothing (PPL in Table 1) as well as smoothed with the Kneser-Ney algorithm\n(PPL+KN in Table 1). We used the MITLM [29] toolkit for that evaluation. As an evaluation set we used dev2010 data, which was used for tuning. Its dictionary covers 2861 words.\nEMEA are texts from the European Medicines Agency, KDE4 is a localization file of that GUI, ECB stands for European Central Bank corpus, OpenSubtitles [12] are movies and TV series subtitles, EUNEWS is a web crawl of the euronews.com web page and EUBOOKSHOP comes from bookshop.europa.eu. Lastly bilingual TEDDL is additional TED data. We ensured that this data was not overlapping with the test or development sets. As can be seen from the Table 1, all additional data has big perplexity values, so no astonishing improvements based only on data could be expected.\nWIKIPEDIA and EUNEWS are parallel corpora extracted by us from comparable corpora. We were able to obtain 4,498 topic-aligned articles from the Euronews and about 1M from the Wikipedia. The Wikipedia corpus was about 104MB in size and contained 475,470 parallel sentences. Its first version was acknowledged as permissible data for the IWSLT 2014 evaluation campaign. The Euronews corpora contained 1,617 bi-sentences.\nIn order to extract the parallel sentence pairs we decided to facilitate Yalign Tool [26]. The Yalign tool was designed in order to automate parallel text mining process by finding sentences that are close translation matches from the comparable corpora. This opened up avenues for harvesting parallel corpora from sources like translated documents and the web. What is more Yalign is not limited to any language pair. But creation of own alignment models for two required languages is necessary.\nThe Yalign tool was implemented using a sentence similarity metric that produces a rough estimate (a number between 0 and 1) of how likely it is for two sentences to be a translation of each other. Additionally it uses a sequence aligner, that produces an alignment that maximizes the sum of the individual (per sentence pair) similarities between two documents. Yalign\u2019s main algorithm is actually a wrapper before standard sequence alignment algorithm [26].\nFor the sequence alignment Yalign uses a variation of the Needleman-Wunch algorithm [27] to find an optimal alignment between the sentences in two given documents. The algorithm has polynomial time worst-case complexity and it produces an optimal alignment. Unfortunately it can\u2019t handle alignments that cross each other or alignments from two sentences into a single one [27].\nSince the sentence similarity is a computationally expensive operation, the implemented variation of the Needleman-Wunch algorithm uses A* approach to explore the search space instead of using the classical dynamic programming method that would require N * M calls to the sentence similarity matrix.\nAfter the alignment, only sentences that have a high probability of being translations are included in the final alignment. The result is filtered in order to deliver high quality alignments. To do this, a threshold value is used, such that if the sentence similarity metric is low enough the pair is excluded.\nFor the sentence similarity metric the algorithm uses a statistical classifier\u2019s likelihood output and adapts it into the <0,1> range.\nThe classifier must be trained in order to determine if a pair of sentences is translation of each other or not. The particular classifier used in the Yalign project was a Support Vector Machine. Besides being excellent classifier, SVMs can provide a distance to the separation hyperplane during classification, and this distance can be easily modified using a Sigmoid Function to return likelihood between 0 and 1 [28].\nThe use of a classifier means that the quality of the alignment depends not only on the input but also on the quality of the trained classifier.\nTo train the classifier a good quality parallel data was necessary as well as a dictionary with translation probability included. For this purposes we used TED talks [3] corpora enhanced by us during the IWSLT\u201913 Evaluation Campaign [5]. In order to obtain a dictionary we trained a phrase table and extracted 1-grams from it. We used the MGIZA++ tool for word and phrase alignment. The lexical reordering was set to use the msd-bidirectional-fe method and the symmetrisation method was set to grow-diag-final-and for word alignment processing [5].\nBefore use of a training translation model, preprocessing that included removal of long sentences (set to 80 words) had to be performed. The Moses toolkit scripts [7] were used for this purpose.\nThe final processing corpus included 185,527 lines from the Polish to English corpus. However, the disproportionate vocabulary sizes remained. One of the solutions to this problem (according to work of Bojar [10]) was to use stems instead of surface forms in order to reduce the Polish vocabulary size. Such a solution also requires a creation of an SMT system from Polish stems to plain Polish. Subsequently, we used PSI-TOOLKIT [9] to convert each Polish word into a lemma. The toolkit is a tool chain for automatic processing of Polish language and to lesser extent other languages like English, German, French, Spanish and Russian (with the focus on machine translation). The tool chain includes segmentation, tokenization, lemmatization, shallow parsing, deep parsing, rule-based machine translation, statistical machine translation, automatic generation of inflected forms from lemma sequences and automatic post edition. The toolkit was used as an additional information source for the SMT system preparation. It can be also used as a first step for\nimplementing a factored SMT system that, unlike a phrasebased system, includes morphological analysis, translation of lemmas and features as well as generation of surface forms. Incorporating additional linguistic information should effectively improve translation performance [8]."}, {"heading": "2.1. Polish lemma extraction", "text": "As previously mentioned, lemma extracted from Polish words are used instead of surface forms to overcome the problem of the huge difference in vocabulary sizes. For Polish lemma extraction, a tool chain that included tokenization and lemmatization from PSI-TOOLS was used.\nThese tools used in sequence provide a rich output that includes a lemma form of the tokens, prefixes, suffixes and morphosyntatic tags. Unfortunately unknown words like names or abbreviations or numbers, etc. are lost in the process. Also capitalization as well as punctuation does not remain. To preserve this relevant information we implemented a specialized tool that basing on differences between input and output of the PSI-TOOLS restored most of the lost information. The lemmatized version of the Polish training data was reduced to 36,065 unique words and the polish language model was also reduced from 156,970 to 32,873 unique words. The results of this work are presented in Table 2 and in Table 3. Each experiment was done only on the baseline data sets in PL->EN and EN->PL direction. The system settings are described in Chapter 5. The year column shows the test set that was used in the experiment, if a year has L suffix in means that it is lemmatized version of the baseline system."}, {"heading": "YEAR BLEU NIST TER MET", "text": ""}, {"heading": "YEAR BLEU NIST TER MET", "text": "Our experiments show that lemma translation to EN in each test set decreased the evaluation scores, contrary translation from EN to lemma for each set increased the translation quality. Such solution requires also training of a system from lemma into PL in order to restore proper surface\nforms of the words. We trained such system as well and evaluated it on official tests sets from years 2010-2014 and tuned on 2010 development data. The results for that system are presented in Table 4. Even that the scores are relatively high the results do not seem to be satisfactory enough to provide overall improvement of EN-LEMMA-PL pipeline over direct translation from EN to PL."}, {"heading": "YEAR BLEU NIST TER MET", "text": "To confirm our prediction we conducted additional experiment in which the English sentences were first translated into lemma and secondly we translated lemma into Polish surface forms. The results of such combined translation are showed in Table 5. They decrease the translation quality in comparison to direct translation from EN to PL. What is more by lemmatizing PL we lost much significant information. As a part of the future work we intend to lemmatize only not very common words, but we are still aware of that most of the Polish words will appear quire rare due to many word forms. We anticipate that most of the words will be replaced by lemmas. Unfortunately also the quality of lemma to surface is of low quality. The Polish declension is complex e.g. sometimes even a steam is changed doe to phonetic/phontactic rules."}, {"heading": "YEAR BLEU NIST TER MET", "text": ""}, {"heading": "3. English Data Preparation", "text": ""}, {"heading": "4. Evaluation Methods", "text": "human judgments. Among the commonly used SMT metrics are: Bilingual Evaluation Understudy (BLEU), the U.S. National Institute of Standards & Technology (NIST) metric, the Metric for Evaluation of Translation with Explicit Ordering (METEOR), and Translation Error Rate (TER).\nAccording to Koehn, BLEU [11] uses textual phrases of varying length to match SMT and reference translations. Scoring of this metric is determined by the weighted averages of those matches. [13]\nTo encourage infrequently used word translation, the NIST [13] metric scores the translation of such words higher and uses the arithmetic mean of the n-gram matches. Smaller differences in phrase length incur a smaller brevity penalty. This metric has shown advantages over the BLEU metric.\nThe METEOR [13] metric also changes the brevity penalty used by BLEU, uses the arithmetic mean like NIST, and considers matches in word order through examination of higher order n-grams. These changes increase score based on recall. It also considers best matches against multiple reference translations when evaluating the SMT output.\nTER [14] compares the SMT and reference translations to determine the minimum number of edits a human would need to make for the translations to be equivalent in both fluency and semantics. The closest match to a reference translation is used in this metric. There are several types of edits considered: word deletion, word insertion, word order, word substitution, and phrase order."}, {"heading": "5. Experimental Results", "text": "A number of experiments were performed to evaluate various versions for our SMT systems. The experiments involved a number of steps. Processing of the corpora was accomplished, including tokenization, cleaning, factorization, conversion to lower case, splitting, and a final cleaning after splitting. Training data was processed, and the language model was developed. Tuning was performed for each experiment. Lastly, the experiments were conducted.\nThe baseline system testing was done using the Moses open source SMT toolkit with its Experiment Management System (EMS) [15]. The SRI Language Modeling Toolkit (SRILM) [19] with an interpolated version of the Kneser-Key discounting (interpolate \u2013unk \u2013kndiscount) was used for 5- gram language model training. We used the MGIZA++ tool for word and phrase alignment. KenLM [17] was used to binarize the language model, with a lexical reordering set to use the msd-bidirectional-fe model. Reordering probabilities of phrases are conditioned on lexical values of a phrase. It considers three different orientation types on source and target phrases like monotone(M), swap(S) and discontinuous(D). The bidirectional reordering model adds probabilities of possible mutual positions of source counterparts to current and following phrases [18]. MGIZA++ is a multi-threaded version of the well-known GIZA++ tool [20]. The symmetrization method was set to grow-diag-final-and for word alignment processing. First two-way direction alignments obtained from GIZA++ were intersected, so only the alignment points that occurred in both alignments remained. In the second phase, additional alignment points existing in their union were added. The growing step adds potential alignment points of unaligned words and neighbors. Neighborhood can be set directly to left, right, top or bottom, as well as to diagonal (grow-diag). In the final step, alignment points between words from which at least one is unaligned are\nadded (grow-diag-final). If the grow-diag-final-and method is used, an alignment point between two unaligned words appears. [15]\nWe conducted about a hundred of experiments using test and development 2010 data to determine the best possible translation settings from Polish to English and the reverse. For experiments we used Moses SMT with Experiment Management System (EMS) [15]. Starting from baseline (BLEU: 16,70) system tests, we raised our score through extending the language model with more data and by interpolating it linearly. We determined that not using lower casing, changing maximum sentence length to 95, maximum phrase length to 6 improves the BLEU score. Additionally we changed the language model order from 5 to 6 and changed the discounting method from Kneser-Ney to Witten-Bell. Those setting proved to increase translation quality for PL-EN language pair in [5]. In the training part, we changed the lexicalized reordering method from msd-bidirectional-fe to hier-mslr-bidirectional-fe. The system was also enriched with Operation Sequence Model (OSM) [21]. The motivation for OSM is that it provides phrase-based SMT models the ability to memorize dependencies and lexical triggers, it can search for any possible reordering, and it has a robust search mechanism. Additionally, OSM takes source and target context into account, and it does not have the spurious phrasal segmentation problem. The OSM is valuable especially for the strong reordering mechanism. It couples translation and reordering, handles both short and long distance reordering, and does not require a hard reordering limit [21]. What is more we used Compound Splitting feature [8]. Tuning was done using MERT tool with batch-mira feature and n-best list size was changed from 100 to 150. This setting and language models produced the score of BLEU equal to 21,57. Lastly we used all parallel data we were able to obtain. We adapted it using Modified Moore Levis Filtering [8]. From our experiments we conducted that best results are obtained when sampling about 150,000 bi-sentences from in-domain corpora and by using filtering after the word alignment. The ratio of data to be kept was set to 0,8 obtaining our best score equal to 23,74.\nBecause of a much bigger dictionary, the translation from EN to PL is significantly more complicated. Our baseline system score was 9,95 in BLEU. Similarly to PL-EN direction we determined that not using lower casing, changing maximum sentence length to 85, maximum phrase length to 7 improves the BLEU score. Additionally we set the language model order from 5 to 6 and changed the discounting method from Kneser-Ney to Witten-Bell. In the training part, we changed the lexicalized reordering method from msdbidirectional-fe to tgttosrc. The system was also enriched with Operation Sequence Model (OSM). What is more we used Compund Splitting feature and we did punctuation normalization. Tuning was done using MERT tool with batchmira feature and n-best list size was changed from 100 to 150. Training a hierarchical phrase-based translation model also improved results in this translation scenario [16].\nThis setting and language models produced the score of BLEU equal to 19,81. Lastly we used all parallel data we were able to obtain. We adapted it using Modified Moore Levis Filtering [8]. From our experiments we conducted that best results are obtained when sampling about 150,000 bisentences from in-domain corpora and by using filtering after the word alignment. The ratio of data to be kept was set to 0,9 obtaining our best score equal to 22,76.\nThe experiments on our best systems were conducted with the use of the test data from years 2010-2014. These results are showed in Table 6 and Table 7, respectively, for the Polish-to-English and English-to-Polish translations. They are measured by the BLEU, NIST, TER and METEOR metrics. Note that a lower value of the TER metric is better, while the other metrics are better when their values are higher."}, {"heading": "6. Discussion & Conclusions", "text": "What is more, converting Polish surface forms of words to lemma reduces the Polish vocabulary, which should improve the English-to-Polish translation performance and opposite. The Polish to English translation typically outscores the English to Polish translation, even on the same data. It is also what we would expect in our experiments with lemma, nonetheless our initial assumptions were not confirmed in empirical tests.\nSeveral potential opportunities for future work are of interest. Additional experiments using extended language models are warranted to determine if this improves SMT scores. We are also interested in developing some more web crawlers in order to obtain additional data that would most likely prove useful. What is more, the Wikipedia corpus we\ncreated is still very noisy. We are currently working on cleaning it semi-automatically.\nIn future we intend to try clustering the training data into word classes in order to obtain smoother distributions and better generalizations. Using class-based models was shown to be useful when translating into morphologically rich languages like Polish [23]. We are also planning on using Unsupervised Transliteration Models, that proved to be quite useful in MT for translating OOV words, for disambiguation and for translating closely related languages [24]. This feature would most likely help us overcome difference in the vocabulary size, especially when translating into PL. Using a Fill-up combination technique (instead of interpolation) that is useful when the relevance of the models is known a priori: typically, when one is trained on in-domain data and the others on out-of-domain data is also in our interests [25].\nNeural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. We would like to test such methodology on PL-EN language pair in accordance to [22]."}, {"heading": "7. Acknowledgements", "text": "This work is supported by the European Community from the European Social Fund within the Interkadra project UDAPOKL-04.01.01-00-014/10-00 and Eu-Bridge 7th FR EU project (grant agreement n\u00b0287658)."}], "references": [{"title": "Overview of the IWSLT2012 Evaluation Campaign", "author": ["M. Cetollo", "J. Niehues", "S. Stuker", "L. Bentivogli", "M. Federico"], "venue": "Proceedings of the 10th International Workshop on Spoken Language Translation", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Report on the 10 IWSLT Evaluation Campaign", "author": ["M. Cetollo", "J. Niehues", "S. Stuker", "L. Bentivogli", "M. Federico"], "venue": "Proceedings of the 10th International Workshop on Spoken Language Translation (IWSLT), Heidelberg,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Polish \u2013 English Speech Statistical Machine Translation Systems for the IWSLT 2013", "author": ["K. Wo\u0142k", "K. Marasek"], "venue": "Proceedings of the 10th International Workshop on Spoken Language Translation (IWSLT), Heidelberg,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Sentence Meaning Based Alignment Method for Parallel Text Corpora Preparation", "author": ["K. Wo\u0142k", "K. Marasek", "\u201eA"], "venue": "Advances in Intelligent Systems and Computing", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Moses: Open Source Toolkit for Statistical Machine Translation", "author": ["P. Koehn", "H. Hoang", "A. Birch", "C. Callison-Burch", "M. Federico", "N. Bertoldi", "B. Cowan", "W. Shen", "C. Moran", "R. Zens", "C. Dyer", "R. Bojar", "A. Constantin", "E. Herbst"], "venue": "Proceedings of the ACL 2007 Demo and Poster Sessions,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Polish -English Statistical Machine Translation of Medical Texts", "author": ["K. Wo\u0142k", "K. Marasek"], "venue": "New Research in Multimedia and Internet Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Junczys- Dowmunt, \u201ePSI-Toolkit: Natural language processing pipeline", "author": ["F. Grali\u0144ski", "M.K. Jassem"], "venue": "Computational Linguistics - Applications, Heidelberg: Springer", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Rich Morphology and What Can We Expect from Hybrid Approaches to MT", "author": ["O. Bojar"], "venue": "Invited talk at International Workshop on Using Linguistic Information for Hybrid Machine Translation(LIHMT-2011),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "What is a Better Translation?", "author": ["P. Koehn"], "venue": "Reflections on Six Years of Running Evaluation Campaigns,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Parallel Data, Tools and Interfaces in OPUS", "author": ["J. Tiedemann"], "venue": "Proceedings of the 8th International Conference on Language Resources and Evaluation", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Enhanced Bilingual Evaluation Understudy\", Lecture Notes on Information Theory, volume 2 number", "author": ["K. Wo\u0142k", "K. Marasek"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "A Study of Translation Edit Rate with Targeted Human Annotation", "author": ["M. Snover", "B. Dorr", "R. Schwartz", "L. Micciulla", "J. Makhoul"], "venue": "Proceedings of 7th Conference of the Assoc. for Machine Translation in the Americas,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Real-Time Statistical Speech Translation", "author": ["K. Wo\u0142k", "K. Marasek"], "venue": "Advances in Intelligent Systems and Computing", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Hierarchical Phrase-Based Translation", "author": ["D. Chiang"], "venue": "Computational Linguistics Volume 33, Number", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2007}, {"title": "KenLM: Faster and smaller language model queries", "author": ["K. Heafield"], "venue": "Proceedings of Sixth Workshop on Statistical Machine Translation, Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Using linear interpolation and weighted reordering hypotheses in the Moses system", "author": ["M. Costa-Jussa", "J. Fonollosa"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "SRILM \u2013 An Extensible Language Modeling Toolkit", "author": ["A. Stolcke"], "venue": "INTERSPEECH,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2002}, {"title": "Parallel Implementations of Word Alignment Tool\u201d, Software Engineering, Testing, and Quality Assurance for Natural Language", "author": ["Q. Gao", "S. Vogel"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "A Joint Sequence Model with Integrated Reordering", "author": ["N. Durrani", "H. Schmid", "A. Fraser"], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv cs.CL 1409.0473,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Investigating the Usefulness of Generalized Word Representations in SMT", "author": ["N. Durrani", "P. Koehn", "H. Schmid", "A. Fraser"], "venue": "Proceedings of the 25th Annual Conference on Computational Linguistics (COLING),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Integrating an Unsupervised Transliteration Model  into Statistical Machine Translation", "author": ["N. Durrani", "P. Koehn", "H. Hoang", "H. Sajjad"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Fill-up versus Interpolation Methods for Phrase-based SMT Adaptation", "author": ["A. Bisazza", "N. Ruiz", "M. Federico"], "venue": "In Proceedings of IWSLT 2011,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features", "author": ["Thorsten Joachims"], "venue": "Lecture Notes in Computer Science Volume", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1998}, {"title": "Interative Language Model Estimation: Efficient Data Structure & Algorithms", "author": ["B. Hsu", "J. Glass"], "venue": "In Proceedings Interspeech,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "As a result starting point was much lower than for other languages, however our progress in last 3 years was faster than others [1,2].", "startOffset": 128, "endOffset": 133}, {"referenceID": 1, "context": "As a result starting point was much lower than for other languages, however our progress in last 3 years was faster than others [1,2].", "startOffset": 128, "endOffset": 133}, {"referenceID": 2, "context": "[5].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "It was done semiautomatically by the usage of our tool described in [6].", "startOffset": 68, "endOffset": 71}, {"referenceID": 9, "context": "from the OPUS [12] project page, some from another small projects and the rest was collected manually using web crawlers.", "startOffset": 14, "endOffset": 18}, {"referenceID": 24, "context": "We used the MITLM [29] toolkit for", "startOffset": 18, "endOffset": 22}, {"referenceID": 9, "context": "EMEA are texts from the European Medicines Agency, KDE4 is a localization file of that GUI, ECB stands for European Central Bank corpus, OpenSubtitles [12] are movies and TV series subtitles, EUNEWS is a web crawl of the euronews.", "startOffset": 151, "endOffset": 155}, {"referenceID": 23, "context": "provide a distance to the separation hyperplane during classification, and this distance can be easily modified using a Sigmoid Function to return likelihood between 0 and 1 [28].", "startOffset": 174, "endOffset": 178}, {"referenceID": 2, "context": "For this purposes we used TED talks [3] corpora enhanced by us during the IWSLT\u201913 Evaluation Campaign [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 2, "context": "The lexical reordering was set to use the msd-bidirectional-fe method and the symmetrisation method was set to grow-diag-final-and for word alignment processing [5].", "startOffset": 161, "endOffset": 164}, {"referenceID": 4, "context": "The Moses toolkit scripts [7] were used for this purpose.", "startOffset": 26, "endOffset": 29}, {"referenceID": 7, "context": "One of the solutions to this problem (according to work of Bojar [10]) was to use stems instead of surface forms in order to reduce the Polish", "startOffset": 65, "endOffset": 69}, {"referenceID": 6, "context": "Subsequently, we used PSI-TOOLKIT [9] to convert each Polish word into a lemma.", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "Incorporating additional linguistic information should effectively improve translation performance [8].", "startOffset": 99, "endOffset": 102}, {"referenceID": 8, "context": "According to Koehn, BLEU [11] uses textual phrases of varying length to match SMT and reference translations.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "[13]", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "To encourage infrequently used word translation, the NIST [13] metric scores the translation of such words higher and uses the arithmetic mean of the n-gram matches.", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "The METEOR [13] metric also changes the brevity penalty used by BLEU, uses the arithmetic mean like NIST, and considers matches in word order through examination of higher order n-grams.", "startOffset": 11, "endOffset": 15}, {"referenceID": 11, "context": "TER [14] compares the SMT and reference translations to determine the minimum number of edits a human would need to make for the translations to be equivalent in both fluency and semantics.", "startOffset": 4, "endOffset": 8}, {"referenceID": 12, "context": "The baseline system testing was done using the Moses open source SMT toolkit with its Experiment Management System (EMS) [15].", "startOffset": 121, "endOffset": 125}, {"referenceID": 16, "context": "The SRI Language Modeling Toolkit (SRILM) [19] with an interpolated version of the Kneser-Key discounting (interpolate \u2013unk \u2013kndiscount) was used for 5gram language model training.", "startOffset": 42, "endOffset": 46}, {"referenceID": 14, "context": "KenLM [17] was used to binarize the language model, with a lexical reordering set to use the msd-bidirectional-fe model.", "startOffset": 6, "endOffset": 10}, {"referenceID": 15, "context": "The bidirectional reordering model adds probabilities of possible mutual positions of source counterparts to current and following phrases [18].", "startOffset": 139, "endOffset": 143}, {"referenceID": 17, "context": "MGIZA++ is a multi-threaded version of the well-known GIZA++ tool [20].", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "[15] We conducted about a hundred of experiments using test and development 2010 data to determine the best possible translation settings from Polish to English and the reverse.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "For experiments we used Moses SMT with Experiment Management System (EMS) [15].", "startOffset": 74, "endOffset": 78}, {"referenceID": 2, "context": "Those setting proved to increase translation quality for PL-EN language pair in [5].", "startOffset": 80, "endOffset": 83}, {"referenceID": 18, "context": "The system was also enriched with Operation Sequence Model (OSM) [21].", "startOffset": 65, "endOffset": 69}, {"referenceID": 18, "context": "It couples translation and reordering, handles both short and long distance reordering, and does not require a hard reordering limit [21].", "startOffset": 133, "endOffset": 137}, {"referenceID": 5, "context": "What is more we used Compound Splitting feature [8].", "startOffset": 48, "endOffset": 51}, {"referenceID": 5, "context": "using Modified Moore Levis Filtering [8].", "startOffset": 37, "endOffset": 40}, {"referenceID": 13, "context": "Training a hierarchical phrase-based translation model also improved results in this translation scenario [16].", "startOffset": 106, "endOffset": 110}, {"referenceID": 5, "context": "Levis Filtering [8].", "startOffset": 16, "endOffset": 19}, {"referenceID": 2, "context": "training files has some positive impact, among the variations of the experiments [5].", "startOffset": 81, "endOffset": 84}, {"referenceID": 20, "context": "Using class-based models was shown to be useful when translating into morphologically rich languages like Polish [23].", "startOffset": 113, "endOffset": 117}, {"referenceID": 21, "context": "and for translating closely related languages [24].", "startOffset": 46, "endOffset": 50}, {"referenceID": 22, "context": "Using a Fill-up combination technique (instead of interpolation) that is useful when the relevance of the models is known a priori: typically, when one is trained on in-domain data and the others on out-of-domain data is also in our interests [25].", "startOffset": 243, "endOffset": 247}, {"referenceID": 19, "context": "[22].", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "This research explores effects of various training settings between Polish and English Statistical Machine Translation systems for spoken language. Various elements of the TED parallel text corpora for the IWSLT 2014 evaluation campaign were used as the basis for training of language models, and for development, tuning and testing of the translation system as well as Wikipedia based comparable corpora prepared by us. The BLEU, NIST, METEOR and TER metrics were used to evaluate the effects of data preparations on translation results. Our experiments included systems, which use lemma and morphological information on Polish words. We also conducted a deep analysis of provided Polish data as preparatory work for the automatic data correction and cleaning phase.", "creator": "Word"}}}