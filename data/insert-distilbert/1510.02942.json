{"id": "1510.02942", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Oct-2015", "title": "Evaluation of Joint Multi-Instance Multi-Label Learning For Breast Cancer Diagnosis", "abstract": "multi - instance multi - label ( miml ) learning is commonly a challenging technique problem in many aspects. such learning approaches might be useful for many medical diagnosis applications including ultrasound breast cancer detection protocol and classification. in this study subset of digipath projection dataset ( whole slide digital breast cancer histopathology images ) are used for training comprehension and evaluation of additional six state - of - the - art miml methods.", "histories": [["v1", "Sat, 10 Oct 2015 14:30:25 GMT  (5465kb,D)", "http://arxiv.org/abs/1510.02942v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["baris gecer", "ozge yalcinkaya", "onur tasar", "selim aksoy"], "accepted": false, "id": "1510.02942"}, "pdf": {"name": "1510.02942.pdf", "metadata": {"source": "CRF", "title": "Evaluation of Joint Multi-Instance Multi-Label Learning For Breast Cancer Diagnosis", "authors": ["Baris Gecer", "Ozge Yalcinkaya", "Onur Tasar", "Selim Aksoy"], "emails": ["baris.gecer@cs.bilkent.edu.tr,", "ozge.yalcinkaya@cs.bilkent.edu.tr,", "onur.tasar@cs.bilkent.edu.tr,", "saksoy@cs.bilkent.edu.tr"], "sections": [{"heading": null, "text": "Evaluation of Joint Multi-Instance Multi-Label Learning For Breast Cancer Diagnosis\nBaris Gecer\u2217, Ozge Yalcinkaya\u2020, Onur Tasar\u2021 and Selim Aksoy\u00a7 Department of Computer Engineering,\nBilkent University, Ankara, 06800, Turkey \u2217baris.gecer@cs.bilkent.edu.tr, \u2020ozge.yalcinkaya@cs.bilkent.edu.tr, \u2021onur.tasar@cs.bilkent.edu.tr, \u00a7saksoy@cs.bilkent.edu.tr\nAbstract\u2014Multi-instance multi-label (MIML) learning is a challenging problem in many aspects. Such learning approaches might be useful for many medical diagnosis applications including breast cancer detection and classification. In this study subset of digiPATH dataset (whole slide digital breast cancer histopathology images) are used for training and evaluation of six state-ofthe-art MIML methods.\nAt the end, performance comparison of these approaches are given by means of effective evaluation metrics. It is shown that MIML-kNN achieve the best performance that is %65.3 average precision, where most of other methods attain acceptable results as well.\nI. INTRODUCTION\nBreast cancer is the most prevalent form of cancers among women [1]. Although those who live in the developed world have more survival rates [2], patients have less change in developing countries. Medical image processing might have a huge contribution to experts for analysis of histopathology images by improving interpretation or indicating candidate disease locations [1].\nSome different types of breast cancers on histopatholgy images are shown in Fig. I. Breast cancers does not have a particular shapes and their types are not necessarily consecutive. This make its detection and classification very hard for both experts and computer aid systems. There are so many information about breast cancer and its types in the literature but we omit the informations that require expertise in this field and focus on learning from labelled data by the experts in this study.\nWe introduce a well-collected dataset of digital histopathology images: digiPATH project in which consists of 240 digital images (in average size of 90.000\u00d770.000 pixels) of breast biopsies from 14 different diagnostic categories of cancer [3]. Each H&E stained biopsy slides which were scanned at 40X magnification, labeled by 203 pathologists where 3 of them are world-class expert in this area. Rectangular part of the image that is visible on the pathologist\u2019s screen are logged while they diagnosis the images where world-class experts marked a bounding box in each image to indicate disease.\nDiagnosis of a particular histopathology image might differentiate among experts and there might be more than one label from an expert for an image as it can be seen in the dataset. Thus, detection and classification of a case become more complicated than the traditional machine learning aspect, as we know one digital image might have healthy and different type of diseased regions at the same time. Such data set can be\nused for machine learning by only combining multi-instance and multi-label learning approaches.\nMulti instance learning is a variation of the supervised learning. In classical supervised learning (Fig.Ia), each sample in the training set is assigned to a specific label.\nIn multi-instance learning as illustrated in Fig.Ib, each image has one or more regions of interest associated with a label. So, each training image is considered as a bag of instances. In binary case, the image is labeled as positive if\nar X\niv :1\n51 0.\n02 94\n2v 1\n[ cs\n.C V\n] 1\n0 O\nct 2\n01 5\nthere is at least one positive instance in the bag. It is labeled as negative if all the instances are negative [5]. Goal of the multiinstance learning is to classify test images using the trained classifier by multi-instance images.\nMulti-label learning is another variation of the supervised learning where each image has multiple labels instead of only one as shown in Fig.Ic. For example, a nature image can be labeled as any of objects that is included in the image (i.e. sea, island and sky). The goal is to train a classifier from a collection of these multi-labeled images.\nOne can combine these two learning methods for learning from such images that has a bag of instances and each image is associated with one or more labels (Fig.Id). In our research, the main interest is such combination which is the most convenient to solve the problem mentioned above where each histopathology image has multiple concerned regions and labeled by the pathologists individually.\nThis paper is organized as follows: in Section 2 we provide an overview of related work. Section 3 provides a detailed explanation of the experiments done and effectiveness of the methods are demonstrated. Finally, we provide a discussion in Section 4 and draw conclusions in Section 5."}, {"heading": "II. RELATED WORK", "text": "During the past few years, many MIML algorithms have been introduced. To name a few of state-of-the-art MIML methods, Zhou and Zhang [4] proposed MIMLSVM by decomposing MIML to single-instance multi-label learning and MIMLBOOST by decomposing MIML to multi-instance single-label learning. Zhang et.al. [6] proposed M3MIML, (i.e. Maximum Margin Method) which learns from multiinstance multi-label examples by maximum margin strategy and an adaptation of radial basis function (RBF) method [7] MIMLRBF which is a neural network style algorithm is proposed by Zhang et.al. [8]. A MIML nearest neighbor method MIML-kNN is proposed by Zhang and Min-Ling [9], that uses the popular k-nearest neighbor techniques. Yu-Feng Li et.al. [10] proposed KISAR (Key Instances Sharing Among\nRelated labels) which is a MIML algorithm tries to observe the relation between instance and label by considering the fact that highly relevant labels share some instances."}, {"heading": "III. EXPERIMENTS", "text": "In this study, we compare the effectiveness of state-ofthe-art algorithms that combine multi-instance and multi-label learning on a subset of digiPATH project dataset which is mentioned earlier.\nFirstly, we extract LBP features from regions that consist dense information about existence and type of a cancer from the behaviour of experts. The methods mentioned in section. II, then, trained and tested with these features. Finally performance of these methods are evaluated."}, {"heading": "A. Feature Extraction", "text": "For brevity, we use only 120 images from the set and their corresponding diagnoses that are labelled by 3 world-class experts. Note that each expert might label a particular case with more than one diagnosis. View-logs of these experts are used to detect region of interests (ROI) of the images by the proposed method in the study [3], where these ROIs are detected by considering zoom peaks, slow pannings and fixation durations that are longer than 2 seconds.\nMost of the time mutual spatial arrangement of nuclei in a tissue is enough information for detection of a breast cancer and its classification to a cancer type. Thus, we first apply a transformation based on the method in [11] to cropped ROI images (i.e. Fig. 3(a)) that are originally in RGB color space where the transformation generate a map (i.e. Fig. 3(b)) that unveil nuclei. Then we extract LBP features (i.e. Fig. 3(c)) of this gray-scale nuclei image by comparing each pixel to each of its 8 neighbours and normalize features such that they add up to 1. Only 5 classes of disease types over 14 classes, are considered as labels in the experiments that are \u2019Non proliferative changes only\u2019, \u2019Usual ductal hyperplasia\u2019, \u2019Atypical ductal hyperplasia\u2019, \u2019Ductal carcinoma in situ\u2019, \u2019Invasive carcinoma\u2019.\nIn the experiments we consider a bag of features of detected ROIs and labels of a particular expert on a particular image as a \u2019case\u2019. We divide 360 cases (120 images and 3 experts) into well-balanced training and testing sets with respect to their disease types. When we remove cases that does not include any significant ROI, training and testing sets end up with 173 and 153 cases respectively."}, {"heading": "B. Methods", "text": "We experimented six algorithms on our dataset and evaluated results according to some popular evaluation criteria. All of the algorithms return a predicted label set after testing phase. We used this predicted label set and the actual test label set while doing evaluations. Short description of algorithms are as follows:\nMIML-kNN: This algorithm solves MIML problem by using the popular k-nearest neighbor techniques. Given a set of MIML training examples, it considers their neighbors and citers which regard it as their own neighbors. The MIMLkNN algorithm involves two different parameters, i.e. r (the number of nearest neighbors considered) and c (the number\nof citers considered). According to experiments in [9], we selected those parameters as r = 10, c = 20.\nMIMLRBF: In this algorithm, two layer neural network structure is used. This neural network gets a bag X consisting of n instances x1, x2, . . . , xn, where each instance xk is a ddimensional feature vector and each output unit of it is related to a possible class label. The first layer of this neural network is constituted by using k-medoids clustering. After that, the weights between first and second layer are computed. Finally, the test set is given to the trained neural network for prediction. MIMLRBF algorithm involves two different parameters, i.e. the fraction parameter and the scaling factor \u00b5. We chose those parameters as \u03b1 = 0.1, \u00b5 = 0.6 according to experiments in [8].\nMIMLSVM: This algorithm decomposes the multi instance multi label problem into single instance single label problems instead of considering the problem as a whole. Let X denotes the bag of instances and Y the set of class labels. MIMLSVM maps the bag of instances Xi into a single instance zi with the help of constructive clustering. In this step, the algorithm reduces the problem to single instance multi label problem. After that MIMLSVM produces a number of independent single instance single label components by using MLSVM algorithm [4]. Parameters of the MIMLSVM are type of svm, gamma value of svm, cost and ratio; we chose type of the svm as RBF and gamma as 1; ratio is the number of clusters, cost parameter is the value used for the base svm classifier, these values were selected as 0.2 and 1, respectively.\nMIMLBOOST: This is another algorithm that reduces the problem into simpler ones like MIMLSVM. The algorithm decomposes the multi instance multi label problem into multi instance single label problems by converting each MIML examples to MISL one. After this step intermediate MIBOOSTING algorithm reduces the MISL problems to single instance single problems [4]. The algorithm takes three parameters; round, svm, cost. Svm and cost parameter are the same ones with the MIMLSVM algorithm and we selected the same values for them. Round parameter determines the number of boosting round which is 25 in our experiment.\nKISAR: This algorithm tries to find a relation between the bag of instances and class labels. The algorithm provides a mapping from a bag of instances to a feature vector, each bag of instances can be represented with these vectors so the vectors can be regarded as prototypes. According to the KISAR\nalgorithm similarity of the prototypes of cases having relevant labels should be higher. Parameters are selected according to [10].\nM3MIML: This algorithm finds a linear model for each class. The outputs of each class is set according to maximum prediction of MIML example over the linear model. Then, the outputs on all possible classes are combined to define the margin of the MIML example. So, the relation between the instances and the labels of an MIML example are exploited by M3MIML. The cost parameter is chosen according to [6]."}, {"heading": "C. Evaluation Metrics", "text": "In traditional supervised learning accuracy is often used as the performance evaluation criterion. However, while learning with multi-instance images associated with multiple labels, accuracy becomes less meaningful. Therefore, we used some other popular metrics that are more suitable for MIML such as hamming loss, one-error, coverage, ranking loss and average precision [12].\n\u2022 Hamming loss: It evaluates how many times an\nexample-label pair is misclassified, i.e., false alarm or misclassification. Since this is a loss function, optimal value for hamming loss is zero.\n\u2022 One-error: It evaluates how many times the top-ranked label is not in the set of proper labels of the example. The performance is perfect when one-error = 0; the smaller the value of one-error, the better the performance.\n\u2022 Ranking loss: It evaluates the average fraction of label pairs that are misordered for the example. The performance is better when the value of ranking loss is closer to zero.\n\u2022 Coverage: It evaluates how many steps are need, on the average, to go down the list of labels in order to cover all the proper labels of the example. The performance is better when the value of coverage is smaller.\n\u2022 Average precision: The average precision evaluates the average fraction of proper labels ranked above a particular label. The performance is perfect if the value of average precision equal to one.\nWe obtained predicted labels from six algorithms by using our dataset. We evaluate their effectiveness according to the metrics above. Results are shown in the table below:\nAlgorithms h.l. o.e. r.l. co. a.p. MIML-kNN 0.203 0.261 0.570 0.856 0.653 M3MIML 0.580 0.601 0.286 0.921 0.634 MIMLRBF 0.210 0.339 0.640 1.130 0.586 MIMLBOOST 0.200 0.632 0.360 1.176 0.581 MIMLSVM 0.329 0.804 0.524 1.705 0.460 KISAR 0.741 0.656 0.546 1.784 0.461"}, {"heading": "IV. DISCUSSION", "text": "MIML-kNN obtained the best performance over other methods with respect to all evaluation criteria, although MIMLRBF and MIMLBOOST also achieved close performances according to only hamming loss. In addition, KISAR has the worst performance compared to others. Although the performances achieved in the experiments are not bad there is still room for improvement. For instance, we used shrank version of whole slide images by the rate of one over sixteen, when the original images are used the performance is expected to be improved. Since running time of such computation would be very high, we kept it like this.\nWe used LBP features due to their simplicity, robustness and efficiency. We did not consider any histopathological structure that a particular cancer type might have to keep it brief. A new research topic might be investigating such meaningful structures. Also, we extracted the LBP features only from nuclei channel. This might be improved by extracting features from H&E staining, LAB channels etc. additionally. Moreover, label of other 200 pathologist that we did not use in this study can improve the performance as well as the other 120 unused histopathology images.\nWhile applying algorithms to our dataset we chose parameters according to optimum values obtained in previous works. In contrast to the study [10], which shows that KISAR\nand MIMLSVM achieved better performance than others, they are the worst two methods in our study in terms of average precision. This inconsistency might stem from the difference of datasets used.\nSince each approach is robust to different problem characteristics, one can increase the performance by combining all these approaches in a smart manner."}, {"heading": "V. CONCLUSION", "text": "In conclusion, we compared six different multi-instance multi-label supervised learning algorithms on a subset of digiPATH dataset. Then, we used some popular MIML evaluation criteria to measure their performances. Considering that the dataset has limited number of samples and MIML learning is a highly complicated learning problem compared to traditional machine learning, we achieve significant performances almost in all approaches, especially MIML-kNN gave the best performance that is %65.3 in average precision."}], "references": [{"title": "P", "author": ["M. Veta", "J. Pluim"], "venue": "J. van Diest, M. A. Viergever, Breast cancer histopathology image analysis: a review., IEEE transactions on bio-medical engineering 61 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "B", "author": ["P. Boyle"], "venue": "Levin, et al., World cancer report 2008., IARC Press, International Agency for Research on Cancer", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Localization of diagnostically relevant regions of interest in whole slide images", "author": ["E. Mercan", "S. Aksoy", "L.G. Shapiro", "D.L. Weaver", "T. Brunye", "J.G. Elmore"], "venue": "in: Pattern Recognition (ICPR), 2014 22nd International Conference on, IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-instance multi-label learning with application to scene classification", "author": ["Z.-H. Zhou", "M.-L. Zhang"], "venue": "in: Advances in Neural Information Processing Systems", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Review of multi-instance learning and its applications", "author": ["J. Yang"], "venue": "Technical Report, Tech. Rep", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "M3miml: A maximum margin method for multi-instance multi-label learning", "author": ["M.-L. Zhang", "Z.-H. Zhou"], "venue": "in: Data Mining, 2008. ICDM\u201908. Eighth IEEE International Conference on, IEEE", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Neural networks for pattern recognition", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1995}, {"title": "Mimlrbf: Rbf neural networks for multi-instance multi-label learning", "author": ["M.-L. Zhang", "Z.-J. Wang"], "venue": "Neurocomputing 72 ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "A k-nearest neighbor based multi-instance multilabel learning algorithm", "author": ["M.-L. Zhang"], "venue": "in: Tools with Artificial Intelligence (ICTAI), 2010 22nd IEEE International Conference on, volume 2, IEEE", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Towards discovering what patterns trigger what labels", "author": ["Y.-F. Li", "J.-H. Hu", "Y. Jiang", "Z.-H. Zhou"], "venue": "in: Twenty-Sixth AAAI Conference on Artificial Intelligence", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "D", "author": ["A.C. Ruifrok"], "venue": "A. Johnston, Quantification of histochemical staining by color deconvolution., Analytical and quantitative cytology and histology/the International Academy of Cytology [and] American Society of Cytology 23 ", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Multi-instance multi-label learning", "author": ["Z.-H. Zhou", "M.-L. Zhang", "S.-J. Huang", "Y.-F. Li"], "venue": "Artificial Intelligence 176 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Breast cancer is the most prevalent form of cancers among women [1].", "startOffset": 64, "endOffset": 67}, {"referenceID": 1, "context": "Although those who live in the developed world have more survival rates [2], patients have less change in developing countries.", "startOffset": 72, "endOffset": 75}, {"referenceID": 0, "context": "Medical image processing might have a huge contribution to experts for analysis of histopathology images by improving interpretation or indicating candidate disease locations [1].", "startOffset": 175, "endOffset": 178}, {"referenceID": 2, "context": "000 pixels) of breast biopsies from 14 different diagnostic categories of cancer [3].", "startOffset": 81, "endOffset": 84}, {"referenceID": 3, "context": "This figure is obtained from [4]", "startOffset": 29, "endOffset": 32}, {"referenceID": 4, "context": "It is labeled as negative if all the instances are negative [5].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "To name a few of state-of-the-art MIML methods, Zhou and Zhang [4] proposed MIMLSVM by decomposing MIML to single-instance multi-label learning and MIMLBOOST by decomposing MIML to multi-instance single-label learning.", "startOffset": 63, "endOffset": 66}, {"referenceID": 5, "context": "[6] proposed M3MIML, (i.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Maximum Margin Method) which learns from multiinstance multi-label examples by maximum margin strategy and an adaptation of radial basis function (RBF) method [7] MIMLRBF which is a neural network style algorithm is proposed by Zhang et.", "startOffset": 159, "endOffset": 162}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "A MIML nearest neighbor method MIML-kNN is proposed by Zhang and Min-Ling [9], that uses the popular k-nearest neighbor techniques.", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "[10] proposed KISAR (Key Instances Sharing Among Related labels) which is a MIML algorithm tries to observe the relation between instance and label by considering the fact that highly relevant labels share some instances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "View-logs of these experts are used to detect region of interests (ROI) of the images by the proposed method in the study [3], where these ROIs are detected by considering zoom peaks, slow pannings and fixation durations that are longer than 2 seconds.", "startOffset": 122, "endOffset": 125}, {"referenceID": 10, "context": "Thus, we first apply a transformation based on the method in [11] to cropped ROI images (i.", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "method proposed by [3].", "startOffset": 19, "endOffset": 22}, {"referenceID": 10, "context": "(b) Extracted nuclei of (a) in gray-scale with a transformation based on [11].", "startOffset": 73, "endOffset": 77}, {"referenceID": 8, "context": "According to experiments in [9], we selected those parameters as r = 10, c = 20.", "startOffset": 28, "endOffset": 31}, {"referenceID": 7, "context": "6 according to experiments in [8].", "startOffset": 30, "endOffset": 33}, {"referenceID": 3, "context": "After that MIMLSVM produces a number of independent single instance single label components by using MLSVM algorithm [4].", "startOffset": 117, "endOffset": 120}, {"referenceID": 3, "context": "After this step intermediate MIBOOSTING algorithm reduces the MISL problems to single instance single problems [4].", "startOffset": 111, "endOffset": 114}, {"referenceID": 9, "context": "Parameters are selected according to [10].", "startOffset": 37, "endOffset": 41}, {"referenceID": 5, "context": "The cost parameter is chosen according to [6].", "startOffset": 42, "endOffset": 45}, {"referenceID": 11, "context": "Therefore, we used some other popular metrics that are more suitable for MIML such as hamming loss, one-error, coverage, ranking loss and average precision [12].", "startOffset": 156, "endOffset": 160}, {"referenceID": 9, "context": "In contrast to the study [10], which shows that KISAR and MIMLSVM achieved better performance than others, they are the worst two methods in our study in terms of average precision.", "startOffset": 25, "endOffset": 29}], "year": 2015, "abstractText": "Multi-instance multi-label (MIML) learning is a challenging problem in many aspects. Such learning approaches might be useful for many medical diagnosis applications including breast cancer detection and classification. In this study subset of digiPATH dataset (whole slide digital breast cancer histopathology images) are used for training and evaluation of six state-ofthe-art MIML methods. At the end, performance comparison of these approaches are given by means of effective evaluation metrics. It is shown that MIML-kNN achieve the best performance that is %65.3 average precision, where most of other methods attain acceptable results as well.", "creator": "LaTeX with hyperref package"}}}