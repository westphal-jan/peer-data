{"id": "1511.02124", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Nov-2015", "title": "Barrier Frank-Wolfe for Marginal Inference", "abstract": "we introduce a globally - convergent algorithm for periodically optimizing the tree - reweighted ( trw ) variational objective over the marginal polytope. the algorithm is therefore based on the conditional gradient reconciliation method ( david frank - wolfe ) and moves hidden pseudomarginals safely within the marginal polytope through repeated maximum a posteriori ( map ) calls. this modular structure enables us as to leverage black - box map solvers ( both exact and approximate ) for variational inference, and obtains more accurate results than mainstream tree - reweighted compression algorithms that optimize over the local consistency relaxation. theoretically, we bound the sub - optimality for the proposed algorithm despite extending the trw objective having unbounded gradients at depth the boundary of the marginal marginal polytope. empirically, we demonstrate the far increased quality of results found by tightening the relaxation parameters over the marginal hollow polytope as well as the largest spanning tree polytope on synthetic random and real - imaginary world instances.", "histories": [["v1", "Fri, 6 Nov 2015 15:48:53 GMT  (1614kb,D)", "https://arxiv.org/abs/1511.02124v1", "25 pages, 12 figures, To appear in Neural Information Processing Systems (NIPS) 2015"], ["v2", "Wed, 25 Nov 2015 18:57:33 GMT  (1613kb,D)", "http://arxiv.org/abs/1511.02124v2", "25 pages, 12 figures, To appear in Neural Information Processing Systems (NIPS) 2015, Corrected reference and cleaned up bibliography"]], "COMMENTS": "25 pages, 12 figures, To appear in Neural Information Processing Systems (NIPS) 2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["rahul g krishnan", "simon lacoste-julien", "david sontag"], "accepted": true, "id": "1511.02124"}, "pdf": {"name": "1511.02124.pdf", "metadata": {"source": "CRF", "title": "Barrier Frank-Wolfe for Marginal Inference", "authors": ["Rahul G. Krishnan", "Simon Lacoste-Julien"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Markov random fields (MRFs) are used in many areas of computer science such as vision and speech. Inference in these undirected graphical models is generally intractable. Our work focuses on performing approximate marginal inference by optimizing the Tree Re-Weighted (TRW) objective (Wainwright et al., 2005). The TRW objective is concave, is exact for tree-structured MRFs, and provides an upper bound on the log-partition function.\nFast combinatorial solvers for the TRW objective exist, including Tree-Reweighted Belief Propagation (TRBP) (Wainwright et al., 2005), convergent message-passing based on geometric programming (Globerson and Jaakkola, 2007), and dual decomposition (Jancsary and Matz, 2011). These methods optimize over the set of pairwise consistency constraints, also called the local polytope. Sontag and Jaakkola (2007) showed that significantly better results could be obtained by optimizing over tighter relaxations of the marginal polytope. However, deriving a message-passing algorithm for the TRW objective over tighter relaxations of the marginal polytope is challenging. Instead, Sontag and Jaakkola (2007) use the conditional gradient method (also called Frank-Wolfe) and offthe-shelf linear programming solvers to optimize TRW over the cycle consistency relaxation. Rather than optimizing over the cycle relaxation, Belanger et al. (2013) optimize the TRW objective over the exact marginal polytope. Then, using Frank-Wolfe, the linear minimization performed in the inner loop can be shown to correspond to MAP inference.\nThe Frank-Wolfe optimization algorithm has seen increasing use in machine learning, thanks in part to its efficient handling of complex constraint sets appearing with structured data (Jaggi, 2013; Lacoste-Julien and Jaggi, 2015). However, applying Frank-Wolfe to variational inference presents challenges that were never resolved in previous work. First, the linear minimization performed in the inner loop is computationally expensive, either requiring repeatedly solving a large linear program, as in Sontag and Jaakkola (2007), or performing MAP inference, as in Belanger et al. (2013). Second, the TRW objective involves entropy terms whose gradients go to infinity near the boundary of the feasible set, therefore existing convergence guarantees for Frank-Wolfe do not apply. Third, variational inference using TRW involves both an outer and inner loop of Frank-Wolfe, where the outer loop optimizes the edge appearance probabilities in the TRW entropy bound to tighten it.\nar X\niv :1\n51 1.\n02 12\n4v 2\n[ st\nat .M\nL ]\n2 5\nN ov\n2 01\nNeither Sontag and Jaakkola (2007) nor Belanger et al. (2013) explore the effect of optimizing over the edge appearance probabilities.\nAlthough MAP inference is in general NP hard (Shimony, 1994), it is often possible to find exact solutions to large real-world instances within reasonable running times (Sontag et al., 2008; Allouche et al., 2010; Kappes et al., 2013). Moreover, as we show in our experiments, even approximate MAP solvers can be successfully used within our variational inference algorithm. As MAP solvers improve in their runtime and performance, their iterative use could become feasible and as a byproduct enable more efficient and accurate marginal inference. Our work provides a fast deterministic alternative to recently proposed Perturb-and-MAP algorithms (Papandreou and Yuille, 2011; Hazan and Jaakkola, 2012; Ermon et al., 2013).\nContributions. This paper makes several theoretical and practical innovations. We propose a modification to the Frank-Wolfe algorithm that optimizes over adaptively chosen contractions of the domain and prove its rate of convergence for functions whose gradients can be unbounded at the boundary. Our algorithm does not require a different oracle than standard Frank-Wolfe and could be useful for other convex optimization problems where the gradient is ill-behaved at the boundary.\nWe instantiate the algorithm for approximate marginal inference over the marginal polytope with the TRW objective. With an exact MAP oracle, we obtain the first provably convergent algorithm for the optimization of the TRW objective over the marginal polytope, which had remained an open problem to the best of our knowledge. Traditional proof techniques of convergence for first order methods fail as the gradient of the TRW objective is not Lipschitz continuous.\nWe develop several heuristics to make the algorithm practical: a fully-corrective variant of FrankWolfe that reuses previously found integer assignments thereby reducing the need for new (approximate) MAP calls, the use of local search between MAP calls, and significant re-use of computations between subsequent steps of optimizing over the spanning tree polytope. We perform an extensive experimental evaluation on both synthetic and real-world inference tasks."}, {"heading": "2 Background", "text": "Markov Random Fields: MRFs are undirected probabilistic graphical models where the probability distribution factorizes over cliques in the graph. We consider marginal inference on pairwise MRFs with N random variables X1, X2, . . . , XN where each variable takes discrete states xi \u2208 VALi. Let G = (V,E) be the Markov network with an undirected edge {i, j} \u2208 E for every two variables Xi and Xj that are connected together. Let N (i) refer to the set of neighbors of variable Xi. We organize the edge log-potentials \u03b8ij(xi, xj) for all possible values of xi \u2208 VALi, xj \u2208 VALj in the vector \u03b8ij , and similarly for the node log-potential vector \u03b8i. We regroup these in the overall vector ~\u03b8. We introduce a similar grouping for the marginal vector ~\u00b5: for example, \u00b5i(xi) gives the coordinate of the marginal vector corresponding to the assignment xi to variable Xi.\nTree Re-weighted Objective (Wainwright et al., 2005): Let Z(~\u03b8) be the partition function for the MRF andM be the set of all valid marginal vectors (the marginal polytope). The maximization of the TRW objective gives the following upper bound on the log partition function:\nlogZ(~\u03b8) \u2264 min \u03c1\u2208T max ~\u00b5\u2208M \u3008~\u03b8, ~\u00b5\u3009+H(~\u00b5;\u03c1)\ufe38 \ufe37\ufe37 \ufe38 TRW(~\u00b5;~\u03b8,\u03c1) , (1) where the TRW entropy is:\nH(~\u00b5;\u03c1) := \u2211 i\u2208V (1\u2212 \u2211 j\u2208N (i) \u03c1ij)H(\u00b5i) + \u2211 (ij)\u2208E \u03c1ijH(\u00b5ij), H(\u00b5i) := \u2212 \u2211 xi \u00b5i(xi) log\u00b5i(xi). (2)\nT is the spanning tree polytope, the convex hull of edge indicator vectors of all possible spanning trees of the graph. Elements of \u03c1 \u2208 T specify the probability of an edge being present under a specific distribution over spanning trees.M is difficult to optimize over, and most TRW algorithms optimize over a relaxation called the local consistency polytope L \u2287M: L := { ~\u00b5 \u2265 0, \u2211xi \u00b5i(xi) = 1 \u2200i \u2208 V, \u2211xi \u00b5ij(xi, xj) = \u00b5j(xj),\u2211xj \u00b5ij(xi, xj) = \u00b5i(xi) \u2200{i, j} \u2208 E} .\nThe TRW objective TRW(~\u00b5; ~\u03b8,\u03c1) is a globally concave function of ~\u00b5 over L, assuming that \u03c1 is obtained from a valid distribution over spanning trees of the graph (i.e. \u03c1 \u2208 T). Frank-Wolfe (FW) Algorithm: In recent years, the Frank-Wolfe (aka conditional gradient) algorithm has gained popularity in machine learning (Jaggi, 2013) for the optimization of convex\nfunctions over compact domains (denoted D). The algorithm is used to solve minx\u2208D f(x) by iteratively finding a good descent vertex by solving the linear subproblem:\ns(k) = argmin s\u2208D \u3008\u2207f(x(k)), s\u3009 (FW oracle), (3)\nand then taking a convex step towards this vertex: x(k+1) = (1 \u2212 \u03b3)x(k) + \u03b3s(k) for a suitably chosen step-size \u03b3 \u2208 [0, 1]. The algorithm remains within the feasible set (is projection free), is invariant to affine transformations of the domain, and can be implemented in a memory efficient manner. Moreover, the FW gap g(x(k)) := \u3008\u2212\u2207f(x(k)), s(k) \u2212 x(k)\u3009 provides an upper bound on the suboptimality of the iterate x(k). The primal convergence of the Frank-Wolfe algorithm is given by Thm. 1 in Jaggi (2013), restated here for convenience: for k \u2265 1, the iterates x(k) satisfy:\n(4)f(x(k))\u2212 f(x\u2217) \u2264 2Cf k + 2 ,\nwhere Cf is called the \u201ccurvature constant\u201d. Under the assumption that \u2207f is L-Lipschitz continuous1 on D, we can bound it as Cf \u2264 Ldiam||.||(D)2.\nMarginal Inference with Frank-Wolfe: To optimize max~\u00b5\u2208M TRW(~\u00b5; ~\u03b8,\u03c1) with Frank-Wolfe, the linear subproblem (3) becomes argmax~\u00b5\u2208M\u3008\u03b8\u0303, ~\u00b5\u3009, where the perturbed potentials \u03b8\u0303 correspond to the gradient of TRW(~\u00b5; ~\u03b8,\u03c1) with respect to ~\u00b5. Elements of \u03b8\u0303 are of the form \u03b8c(xc) +Kc(1 + log\u00b5c(xc)), evaluated at the pseudomarginals\u2019 current location inM, where Kc is the coefficient of the entropy for the node/edge term in (2). The FW linear subproblem here is thus equivalent to performing MAP inference in a graphical model with potentials \u03b8\u0303 (Belanger et al., 2013), as the vertices of the marginal polytope are in 1-1 correspondence with valid joint assignments to the random variables of the MRF, and the solution of a linear program is always achieved at a vertex of the polytope. The TRW objective does not have a Lipschitz continuous gradient overM, and so standard convergence proofs for Frank-Wolfe do not hold."}, {"heading": "3 Optimizing over Contractions of the Marginal Polytope", "text": "Motivation: We wish to (1) use the fewest possible MAP calls, and (2) avoid regions near the boundary where the unbounded curvature of the function slows down convergence. A viable option to address (1) is through the use of correction steps, where after a Frank-Wolfe step, one optimizes over the polytope defined by previously visited vertices of M (called the fully-corrective Frank-Wolfe (FCFW) algorithm and proven to be linearly convergence for strongly convex objectives (Lacoste-Julien and Jaggi, 2015)). This does not require additional MAP calls. However, we found (see Sec. 5) that when optimizing the TRW objective overM, performing correction steps can surprisingly hurt performance. This leaves us in a dilemma: correction steps enable decreasing the objective without additional MAP calls, but they can also slow global progress since iterates after correction sometimes lie close to the boundary of the polytope (where the FW directions become less informative). In a manner akin to barrier methods and to Garber and Hazan (2013)\u2019s local linear oracle, our proposed solution maintains the iterates within a contraction of the polytope. This gives us most of the mileage obtained from performing the correction steps without suffering the consequences of venturing too close to the boundary of the polytope. We prove a global convergence rate for the iterates with respect to the true solution over the full polytope.\nWe describe convergent algorithms to optimize TRW(~\u00b5; ~\u03b8,\u03c1) for ~\u00b5 \u2208 M. The approach we adopt to deal with the issue of unbounded gradients at the boundary is to perform Frank-Wolfe within a contraction of the marginal polytope given by M\u03b4 for \u03b4 \u2208 [0, 1], with either a fixed \u03b4 or an adaptive \u03b4. Definition 3.1 (Contraction polytope). M\u03b4 := (1 \u2212 \u03b4)M + \u03b4 u0, where u0 \u2208 M is the vector representing the uniform distribution.\nMarginal vectors that lie withinM\u03b4 are bounded away from zero as all the components of u0 are strictly positive. Denoting V(\u03b4) as the set of vertices of M\u03b4 , V as the set of vertices of M and f(~\u00b5) := \u2212TRW(~\u00b5; ~\u03b8,\u03c1), the key insight that enables our novel approach is that:\narg min v(\u03b4)\u2208V(\u03b4)\n\u2329 \u2207f,v(\u03b4) \u232a \ufe38 \ufe37\ufe37 \ufe38\n(Linear Minimization overM\u03b4)\n\u2261 arg min v\u2208V \u3008\u2207f, (1\u2212 \u03b4)v + \u03b4u0\u3009\ufe38 \ufe37\ufe37 \ufe38 (Definition of v(\u03b4)) \u2261 (1\u2212 \u03b4) arg min v\u2208V \u3008\u2207f,v\u3009+ \u03b4u0.\ufe38 \ufe37\ufe37 \ufe38 (Run MAP solver and shift vertex)\n1I.e. \u2016\u2207f(x)\u2212\u2207f(x\u2032)\u2016\u2217\u2264 L\u2016x\u2212 x\u2032\u2016 for x,x\u2032 \u2208 D. Notice that the dual norm \u2016\u00b7\u2016\u2217 is needed here.\nAlgorithm 1: Updates to \u03b4 after a MAP call (Adaptive \u03b4 variant)\n1: At iteration k. Assuming x(k),u0, \u03b4(k\u22121), f are defined and s(k) has been computed 2: Compute g(x(k)) = \u3008\u2212\u2207f(x(k)), s(k) \u2212 x(k)\u3009 (Compute FW gap) 3: Compute gu(x(k)) = \u3008\u2212\u2207f(x(k)),u0 \u2212 x(k)\u3009 (Compute \u201cuniform gap\u201d) 4: if gu(x(k)) < 0 then 5: Let \u03b4\u0303 = g(x (k))\n\u22124gu(x(k)) (Compute new proposal for \u03b4)\n6: if \u03b4\u0303 < \u03b4(k\u22121) then 7: \u03b4(k) = min ( \u03b4\u0303, \u03b4 (k\u22121)\n2\n) (Shrink by at least a factor of two if proposal is smaller)\n8: end if 9: end if (and set \u03b4(k) = \u03b4(k\u22121) if it was not updated)\nTherefore, to solve the FW subproblem (3) overM\u03b4 , we can run as usual a MAP solver and simply shift the resulting vertex ofM towards u0 to obtain a vertex ofM\u03b4 . Our solution to optimize over restrictions of the polytope is more broadly applicable to the optimization problem defined below, with f satisfying Prop. 3.3 (satisfied by the TRW objective) in order to get convergence rates. Problem 3.2. Solve minx\u2208D f(x) where D is a compact convex set and f is convex and continuously differentiable on the relative interior of D. Property 3.3. (Controlled growth of Lipschitz constant over D\u03b4). We define D\u03b4 := (1\u2212 \u03b4)D+ \u03b4u0 for a fixed u0 in the relative interior of D. We suppose that there exists a fixed p \u2265 0 and L such that for any \u03b4 > 0, \u2207f(x) has a bounded Lipschitz constant L\u03b4 \u2264 L\u03b4\u2212p \u2200x \u2208 D\u03b4 .\nFixed \u03b4: The first algorithm fixes a value for \u03b4 a-priori and performs the optimization over D\u03b4 . The following theorem bounds the sub-optimality of the iterates with respect to the optimum over D. Theorem 3.4 (Suboptimality bound for fixed-\u03b4 algorithm). Let f satisfy the properties in Prob. 3.2 and Prop. 3.3, and suppose further that f is finite on the boundary ofD. Then the use of Frank-Wolfe for minx\u2208D\u03b4 f(x) realizes a sub-optimality over D bounded as:\nf(x(k))\u2212 f(x\u2217) \u2264 2C\u03b4 (k + 2) + \u03c9 (\u03b4 diam(D)) ,\nwhere x\u2217 is the optimal solution in D, C\u03b4 \u2264 L\u03b4 diam||.||(D\u03b4)2, and \u03c9 is the modulus of continuity function of the (uniformly) continuous f (in particular, \u03c9(\u03b4) \u2193 0 as \u03b4 \u2193 0).\nThe full proof is given in App. C. The first term of the bound comes from the standard Frank-Wolfe convergence analysis of the sub-optimality of x(k) relative to x\u2217(\u03b4), the optimum over D\u03b4 , as in (4) and using Prop. 3.3. The second term arises by bounding f(x\u2217(\u03b4))\u2212 f(x\u2217) \u2264 f(x\u0303)\u2212 f(x\u2217) with a cleverly chosen x\u0303 \u2208 D\u03b4 (as x\u2217(\u03b4) is optimal in D\u03b4). We pick x\u0303 := (1 \u2212 \u03b4)x\u2217 + \u03b4u0 and note that \u2016x\u0303 \u2212 x\u2217\u2016\u2264 \u03b4 diam(D). As f is continuous on a compact set, it is uniformly continuous and we thus have f(x\u0303)\u2212 f(x\u2217) \u2264 \u03c9(\u03b4 diam(D)) with \u03c9 its modulus of continuity function. Adaptive \u03b4: The second variant to solve minx\u2208D f(x) iteratively perform FW steps over D\u03b4 , but also decreases \u03b4 adaptively. The update schedule for \u03b4 is given in Alg. 1 and is motivated by the convergence proof. The idea is to ensure that the FW gap over D\u03b4 is always at least half the FW gap over D, relating the progress over D\u03b4 with the one over D. It turns out that FW-gap-D\u03b4 = (1 \u2212 \u03b4)FW-gap-D + \u03b4 \u00b7 gu(x(k)), where the \u201cuniform gap\u201d gu(x(k)) quantifies the decrease of the function when contracting towards u0. When gu(x(k)) is negative and large compared to the FW gap, we need to shrink \u03b4 (see step 5 in Alg. 1) to ensure that the \u03b4-modified direction is a sufficient descent direction. We can show that the algorithm converges to the global solution as follows: Theorem 3.5 (Global convergence for adaptive-\u03b4 variant over D). For a function f satisfying the properties in Prob. 3.2 and Prop. 3.3, the sub-optimality of the iterates obtained by running the FW updates over D\u03b4 with \u03b4 updated according to Alg. 1 is bounded as:\nf(x(k))\u2212 f(x\u2217) \u2264 O ( k\u2212 1 p+1 ) .\nA full proof with a precise rate and constants is given in App. D. The sub-optimality hk := f(x(k))\u2212 f(x\u2217) traverses three stages with an overall rate as above. The updates to \u03b4(k) as in Alg. 1 enable us\nAlgorithm 2: Approximate marginal inference overM (solving (1)). Here f is the negative TRW objective. 1: Function TRW-Barrier-FW(\u03c1(0), , \u03b4(init),u0): 2: Inputs: Edge-appearance probabilities \u03c1(0), \u03b4(init) \u2264 1\n4 initial contraction of polytope, inner loop\nstopping criterion , fixed reference point u0 in the interior ofM. Let \u03b4(\u22121) = \u03b4(init). 3: Let V := {u0} (visited vertices), x(0) = u0 (Initialize the algorithm at the uniform distribution) 4: for i = 0 . . .MAX RHO ITS do {FW outer loop to optimize \u03c1 over T} 5: for k = 0 . . .MAXITS do {FCFW inner loop to optimize x overM} 6: Let \u03b8\u0303 = \u2207f(x(k); ~\u03b8,\u03c1(i)) (Compute gradient) 7: Let s(k) \u2208 arg min\nv\u2208M \u3008\u03b8\u0303,v\u3009 (Run MAP solver to compute FW vertex)\n8: Compute g(x(k)) = \u3008\u2212\u03b8\u0303, s(k) \u2212 x(k)\u3009 (Inner loop FW duality gap) 9: if g(x(k)) \u2264 then\n10: break FCFW inner loop (x(k) is -optimal) 11: end if 12: \u03b4(k) = \u03b4(k\u22121) (For Adaptive-\u03b4: Run Alg. 1 to modify \u03b4) 13: Let s(k)(\u03b4) = (1\u2212 \u03b4 (k))s(k) + \u03b4(k)u0 and d (k) (\u03b4) = s (k) (\u03b4) \u2212 x (k) (\u03b4-contracted quantities) 14: x(k+1) = arg min{f(x(k) + \u03b3 d(k)(\u03b4)) : \u03b3 \u2208 [0, 1]} (FW step with line search) 15: Update correction polytope: V := V \u222a {s(k)} 16: x(k+1) := CORRECTION(x(k+1), V, \u03b4(k),\u03c1(i)) (optional: correction step) 17: x(k+1), Vsearch := LOCALSEARCH(x(k+1), s(k), \u03b4(k),\u03c1(i)) (optional: fast MAP solver) 18: Update correction polytope (with vertices from LOCALSEARCH): V := V \u222a {Vsearch} 19: end for 20: \u03c1v \u2190 minSpanTree(edgesMI(x(k))) (FW vertex of the spanning tree polytope) 21: \u03c1(i+1) \u2190 \u03c1(i) + ( i\ni+2 )(\u03c1v \u2212 \u03c1(i)) (Fixed step-size schedule FW update for \u03c1 kept in relint(T))\n22: x(0) \u2190 x(k), \u03b4(\u22121) \u2190 \u03b4(k\u22121) (Re-initialize for FCFW inner loop) 23: If i < MAX RHO ITS then x(0) = CORRECTION(x(0), V, \u03b4(\u22121),\u03c1(i+1)) 24: end for 25: return x(0) and \u03c1(i)\nto (1) upper bound the duality gap overD as a function of the duality gap inD\u03b4 and (2) lower bound the value of \u03b4(k) as a function of hk. Applying the standard Descent Lemma with the Lipschitz constant on the gradient of the form L\u03b4\u2212p (Prop. 3.3), and replacing \u03b4(k) by its bound in hk, we get the recurrence: hk+1 \u2264 hk \u2212 Chp+2k . Solving this gives us the desired bound.\nApplication to the TRW Objective: min~\u00b5\u2208M\u2212TRW(~\u00b5; ~\u03b8,\u03c1) is akin to minx\u2208D f(x) and the (strong) convexity of \u2212TRW(~\u00b5; ~\u03b8,\u03c1) has been previously shown (Wainwright et al., 2005; London et al., 2015). The gradient of the TRW objective is Lipschitz continuous overM\u03b4 since all marginals are strictly positive. Its growth for Prop. 3.3 can be bounded with p = 1 as we show in App. E.1. This gives a rate of convergence of O(k\u22121/2) for the adaptive-\u03b4 variant, which interestingly is a typical rate for non-smooth convex optimization. The hidden constant is of the order O(\u2016\u03b8\u2016\u00b7|V |). The modulus of continuity \u03c9 for the TRW objective is close to linear (it is almost a Lipschitz function), and its constant is instead of the order O(\u2016\u03b8\u2016+|V |)."}, {"heading": "4 Algorithm", "text": "Alg. 2 describes the pseudocode for our proposed algorithm to do marginal inference with TRW(~\u00b5; ~\u03b8,\u03c1). minSpanTree finds the minimum spanning tree of a weighted graph, and edgesMI(~\u00b5) computes the mutual information of edges of G from the pseudomarginals in ~\u00b52 (to perform FW updates over \u03c1 as in Alg. 2 in Wainwright et al. (2005)). It is worthwhile to note that our approach uses three levels of Frank-Wolfe: (1) for the (tightening) optimization of \u03c1 over T, (2) to perform approximate marginal inference, i.e for the optimization of ~\u00b5 overM, and (3) to perform the correction steps (lines 16 and 23). We detail a few heuristics that aid practicality.\nFast Local Search: Fast methods for MAP inference such as Iterated Conditional Modes (Besag, 1986) offer a cheap, low cost alternative to a more expensive combinatorial MAP solver. We\n2The component ij has value H(\u00b5i) +H(\u00b5j)\u2212H(\u00b5ij).\nwarm start the ICM solver with the last found vertex s(k) of the marginal polytope. The subroutine LOCALSEARCH (Alg. 6 in Appendix) performs a fixed number of FW updates to the pseudomarginals using ICM as the (approximate) MAP solver.\nRe-optimizing over the Vertices of M (FCFW algorithm): As the iterations of FW progress, we keep track of the vertices of the marginal polytope found by Alg. 2 in the set V . We make use of these vertices in the CORRECTION subroutine (Alg. 5 in Appendix) which re-optimizes the objective function over (a contraction of) the convex hull of the elements of V (called the correction polytope). x(0) in Alg. 2 is initialized to the uniform distribution which is guaranteed to be inM (andM\u03b4). After updating \u03c1, we set x(0) to the approximate minimizer in the correction polytope. The intuition is that changing \u03c1 by a small amount may not substantially modify the optimal x\u2217 (for the new \u03c1) and that the new optimum might be in the convex hull of the vertices found thus far. If so, CORRECTION will be able to find it without resorting to any additional MAP calls. This encourages the MAP solver to search for new, unique vertices instead of rediscovering old ones.\nApproximate MAP Solvers: We can swap out the exact MAP solver with an approximate MAP solver. The primal objective plus the (approximate) duality gap may no longer be an upper bound on the log-partition function (black-box MAP solvers could be considered to optimize over an inner bound to the marginal polytope). Furthermore, the gap over D may be negative if the approximate MAP solver fails to find a direction of descent. Since adaptive-\u03b4 requires that the gap be positive in Alg. 1, we take the max over the last gap obtained over the correction polytope (which is always non-negative) and the computed gap over D as a heuristic. Theoretically, one could get similar convergence rates as in Thm. 3.4 and 3.5 using an approximate MAP solver that has a multiplicative guarantee on the gap (line 8 of Alg. 2), as was done previously for FW-like algorithms (see, e.g., Thm. C.1 in Lacoste-Julien et al. (2013)). With an -additive error guarantee on the MAP solution, one can prove similar rates up to a suboptimality error of . Even if the approximate MAP solver does not provide an approximation guarantee, if it returns an upper bound on the value of the MAP assignment (as do branch-and-cut solvers for integer linear programs, or Sontag et al. (2008)), one can use this to obtain an upper bound on logZ (see App. J)."}, {"heading": "5 Experimental Results", "text": "Setup: The L1 error in marginals is computed as: \u03b6\u00b5 := 1N \u2211N i=1|\u00b5i(1) \u2212 \u00b5\u2217i (1)|. When using exact MAP inference, the error in logZ (denoted \u03b6logZ) is computed by adding the duality gap to the primal (since this guarantees us an upper bound). For approximate MAP inference, we plot the primal objective. We use a non-uniform initialization of \u03c1 computed with the Matrix Tree Theorem (Sontag and Jaakkola, 2007; Koo et al., 2007). We perform 10 updates to \u03c1, optimize ~\u00b5 to a duality gap of 0.5 onM, and always perform correction steps. We use LOCALSEARCH only for the realworld instances. We use the implementation of TRBP and the Junction Tree Algorithm (to compute exact marginals) in libDAI (Mooij, 2010). Unless specified, we compute marginals by optimizing the TRW objective using the adaptive-\u03b4 variant of the algorithm (denoted in the figures as M\u03b4).\nMAP Solvers: For approximate MAP, we run three solvers in parallel: QPBO (Kolmogorov and Rother, 2007; Boykov and Kolmogorov, 2004), TRW-S (Kolmogorov, 2006) and ICM (Besag, 1986) using OpenGM (Andres et al., 2012) and use the result that realizes the highest energy. For exact inference, we use Gurobi Optimization (2015) or toulbar2 (Allouche et al., 2010).\nTest Cases: All of our test cases are on binary pairwise MRFs. (1) Synthetic 10 nodes cliques: Same setup as Sontag and Jaakkola (2007, Fig. 2), with 9 sets of 100 instances each with coupling strength drawn from U [\u2212\u03b8, \u03b8] for \u03b8 \u2208 {0.5, 1, 2, . . . , 8}. (2) Synthetic Grids: 15 trials with 5 \u00d7 5 grids. We sample \u03b8i \u223c U [\u22121, 1] and \u03b8ij \u2208 [\u22124, 4] for nodes and edges. The potentials were (\u2212\u03b8i, \u03b8i) for nodes and (\u03b8ij ,\u2212\u03b8ij ;\u2212\u03b8ij , \u03b8ij) for edges. (3) Restricted Boltzmann Machines (RBMs): From the Probabilistic Inference Challenge 2011.3 (4) Horses: Large (N \u2248 12000) MRFs representing images from the Weizmann Horse Data (Borenstein and Ullman, 2002) with potentials learned by Domke (2013). (5) Chinese Characters: An image completion task from the KAIST Hanja2 database, compiled in OpenGM by Andres et al. (2012). The potentials were learned using Decision Tree Fields (Nowozin et al., 2011). The MRF is not a grid due to skip edges that tie nodes at various offsets. The potentials are a combination of submodular and supermodular and therefore a harder task for inference algorithms.\n3http://www.cs.huji.ac.il/project/PASCAL/index.php\nOn the Optimization ofM versusM\u03b4 We compare the performance of Alg. 2 on optimizing over M (with and without correction), optimizing over M\u03b4 with fixed-\u03b4 = 0.0001 (denoted M0.0001) and optimizing over M\u03b4 using the adaptive-\u03b4 variant. These plots are averaged across all the trials for the first iteration of optimizing over T. We show error as a function of the number of MAP calls since this is the bottleneck for large MRFs. Fig. 1(a), 1(b) depict the results of this optimization aggregated across trials. We find that all variants settle on the same average error. The adaptive \u03b4 variant converges faster on average followed by the fixed \u03b4 variant. Despite relatively quick convergence forM with no correction on the grids, we found that correction was crucial to reducing the number of MAP calls in subsequent steps of inference after updates to \u03c1. As highlighted earlier, correction steps onM (in blue) worsen convergence, an effect brought about by iterates wandering too close to the boundary ofM."}, {"heading": "On the Applicability of Approximate MAP Solvers", "text": "Synthetic Grids: Fig. 1(c) depicts the accuracy of approximate MAP solvers versus exact MAP solvers aggregated across trials for 5 \u00d7 5 grids. The results using approximate MAP inference are competitive with those of exact inference, even as the optimization is tightened over T. This is an encouraging and non-intuitive result since it indicates that one can achieve high quality marginals through the use of relatively cheaper approximate MAP oracles.\nRBMs: As in Salakhutdinov (2008), we observe for RBMs that the bound provided by TRW(~\u00b5; ~\u03b8,\u03c1) over L\u03b4 is loose and does not get better when optimizing over T. As Fig. 1(d) depicts for a single RBM, optimizing overM\u03b4 realizes significant gains in the upper bound on logZ which improves with updates to \u03c1. The gains are preserved with the use of the approximate MAP solvers. Note that there are also fast approximate MAP solvers specifically for RBMs (Wang et al., 2014).\nHorses: See Fig. 2 (right). The models are close to submodular and the local relaxation is a good approximation to the marginal polytope. Our marginals are visually similar to those obtained by TRBP and our algorithm is able to scale to large instances by using approximate MAP solvers.\nGround Truth\nGround Truth TRBP Marginals\nTRBP Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals \u2212 Opt Rho\nCOND\u22120.01 Marginals \u2212 Opt Rho\nGround Truth MAP TRBP FW(1) FW(10)\nGround Truth\nGround Truth TRBP Marginals\nTRBP Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals \u2212 Opt Rho\nCOND\u22120.01 Marginals \u2212 Opt Rho\nGround Truth MAP TRBP FW(1) FW(10)\nGround Truth\nGround Truth TRBP Marginals\nTRBP Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals \u2212 Opt Rho\nCOND\u22120.01 Marginals \u2212 Opt Rho\nGround Truth MAP T (10)\nGround Truth\nGround Truth TRBP Marginals\nTRBP Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals\nCOND\u22120.01 Marginals \u2212 Opt Rho\nCOND\u22120.01 Marginals \u2212 Opt Rho\nGround Truth MAP TRBP FW(1) FW(10)\nFigure 2: Results on real world test cases. FW(i) corresponds to the final marginals at the ith iteration of optimizing \u03c1. The area highlighted on the Chinese Characters depicts the region of uncertainty."}, {"heading": "On the Importance of Optimizing over T", "text": "Synthetic Cliques: In Fig. 1(e), 1(f), we study the effect of tightening over T against coupling strength \u03b8. We consider the \u03b6\u00b5 and \u03b6logZ obtained for the final marginals before updating \u03c1 (step 19) and compare to the values obtained after optimizing over T (marked with \u03c1opt). The optimization over T has little effect on TRW optimized over L\u03b4 . For optimization overM\u03b4 , updating \u03c1 realizes better marginals and bound on logZ (over and above those obtained in Sontag and Jaakkola (2007)).\nChinese Characters: Fig. 2 (left) displays marginals across iterations of optimizing over T. The submodular and supermodular potentials lead to frustrated models for which L\u03b4 is very loose, which results in TRBP obtaining poor results.4 Our method produces reasonable marginals even before the first update to \u03c1, and these improve with tightening over T."}, {"heading": "Related Work for Marginal Inference with MAP Calls", "text": "Hazan and Jaakkola (2012) estimate logZ by averaging MAP estimates obtained on randomly perturbed inflated graphs. Our implementation of the method performed well in approximating logZ but the marginals (estimated by fixing the value of each random variable and estimating logZ for the resulting graph) were less accurate than our method (Fig. 1(e), 1(f))."}, {"heading": "6 Discussion", "text": "We introduce the first provably convergent algorithm for the TRW objective over the marginal polytope, under the assumption of exact MAP oracles. We quantify the gains obtained both from marginal inference overM and from tightening over the spanning tree polytope. We give heuristics that improve the scalability of Frank-Wolfe when used for marginal inference. The runtime cost of iterative MAP calls (a reasonable rule of thumb is to assume an approximate MAP call takes roughly the same time as a run of TRBP) is worthwhile particularly in cases such as the Chinese Characters where L is loose. Specifically, our algorithm is appropriate for domains where marginal inference is hard but there exist efficient MAP solvers capable of handling non-submodular potentials. Code is available at https://github.com/clinicalml/fw-inference.\nOur work creates a flexible, modular framework for optimizing a broad class of variational objectives, not simply TRW, with guarantees of convergence. We hope that this will encourage more research on building better entropy approximations. The framework we adopt is more generally applicable to optimizing functions whose gradients tend to infinity at the boundary of the domain.\nOur method to deal with gradients that diverge at the boundary bears resemblance to barrier functions used in interior point methods insofar as they bound the solution away from the constraints. Iteratively decreasing \u03b4 in our framework can be compared to decreasing the strength of the barrier, enabling the iterates to get closer to the facets of the polytope, although its worthwhile to note that we have an adaptive method of doing so."}, {"heading": "Acknowledgements", "text": "RK and DS gratefully acknowledge the support of the Defense Advanced Research Projects Agency (DARPA) Probabilistic Programming for Advancing Machine Learning (PPAML) Program under\n4We run TRBP for 1000 iterations using damping = 0.9; the algorithm converges with a max norm difference between consecutive iterates of 0.002. Tightening over T did not significantly change the results of TRBP.\nAir Force Research Laboratory (AFRL) prime contract no. FA8750-14-C-0005. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of DARPA, AFRL, or the US government."}, {"heading": "A Preliminaries", "text": ""}, {"heading": "A.1 Summary of Supplementary Material", "text": "The supplementary material is divided into two parts:\n(1) The first part is dedicated to the exposition of the theoretical results presented in the main paper. Section B details the variants of the Frank-Wolfe algorithm that we used and analyzed. Section C gives the proof to Theorem 3.4 (fixed \u03b4) while Section D gives the proof to Theorem 3.5 (adaptive \u03b4). Finally, Section E applies the convergence theorem to the TRW objective and investigates the relevant constants.\n(2) The remainder of the supplementary material provides more information about the experimental setup as well as additional experimental results."}, {"heading": "A.2 Descent Lemma", "text": "The following descent lemma is proved in Bertsekas (1999) (Prop. A24) and is standard for any convergence proof of first order methods. We provide a proof here for completeness. It also highlights the origin of the requirement that we use dual norm pairings between x and the gradient of f(x) (because of the generalized Cauchy-Schwartz inequality).\nLemma A.1. Descent Lemma\nLet x\u03b3 := x + \u03b3d and suppose that f is continuously differentiable on the line segment from x to x\u03b3max for some \u03b3max > 0. Suppose that L = sup\u03b1\u2208]0,\u03b3max] ||\u2207f(x+\u03b1d)\u2212\u2207f(x)||\u2217 ||\u03b1d|| is finite, then we have:\nf(x\u03b3) \u2264 f(x) + \u03b3\u3008\u2207f(x),d\u3009+ \u03b32\n2 L||d||2, \u2200\u03b3 \u2208 [0, \u03b3max]. (5)\nProof. Let 0 < \u03b3 \u2264 \u03b3max. Denoting l(\u03b1) = f(x+ \u03b1d), we have that:\nf(x\u03b3)\u2212 f(x) = l(\u03b3)\u2212 l(0)\n= \u222b \u03b3 0 \u2207\u03b1l(\u03b1)d\u03b1\n= \u222b \u03b3 0 \u3008d,\u2207f(x+ \u03b1d)\u3009d\u03b1\n= \u222b \u03b3 0 \u3008d,\u2207f(x)\u3009d\u03b1+ \u222b \u03b3 0 dT (\u2207f(x+ \u03b1d)\u2212\u2207f(x))d\u03b1\n\u2264 \u222b \u03b3 0 \u3008d,\u2207f(x)\u3009d\u03b1+ \u2223\u2223\u2223\u2223\u222b \u03b3 0 dT (\u2207f(x+ \u03b1d)\u2212\u2207f(x)) \u2223\u2223\u2223\u2223 d\u03b1\n\u2264 \u222b \u03b3 0 \u3008d,\u2207f(x)\u3009d\u03b1+ \u222b \u03b3 0 ||d|| ||\u2207f(x+ \u03b1d)\u2212\u2207f(x)||\u2217 d\u03b1\n= \u03b3\u3008d,\u2207f(x)\u3009+ \u222b \u03b3 0 ||d|| ||\u2207f(x+ \u03b1d)\u2212\u2207f(x)||\u2217 \u03b1||d|| \u03b1||d|| d\u03b1\n\u2264 \u03b3\u3008d,\u2207f(x)\u3009+ \u222b \u03b3 0 ||d|| L||d||\u03b1d\u03b1\n= \u03b3\u3008d,\u2207f(x)\u3009+ L 2 \u03b32||d||2\nRearranging terms, we get the desired bound."}, {"heading": "B Frank-Wolfe Algorithms", "text": "In this section, we present the various algorithms that we use to do fully corrective Frank-Wolfe (FCFW) with adaptive contractions over the domain D, as was done in our experiments."}, {"heading": "B.1 Overview of the Modified Frank-Wolfe Algorithm (FW with Away Steps)", "text": "To implement the approximate correction steps in the fully corrective Frank-Wolfe (FCFW) algorithm, we use the Frank-Wolfe algorithm with away steps (Wolfe, 1970), also known as the modified Frank-Wolfe (MFW) algorithm (Gue\u0301lat and Marcotte, 1986). We give pseudo-code for MFW in Algorithm 3 (taken from (LacosteJulien and Jaggi, 2015)). This variant of Frank-Wolfe adds the possibility to do an \u201caway step\u201d (see step 5 in Algorithm 3) in order to avoid the zig zagging phenomenon that slows down Frank-Wolfe when the solution is close to the boundary of the polytope. For a strongly convex objective (with Lipschitz continuous gradient), the MFW was known to have asymptotic linear convergence (Gue\u0301lat and Marcotte, 1986) and its global linear convergence rate was shown recently (Lacoste-Julien and Jaggi, 2015), accelerating the slow general sublinear rate of Frank-Wolfe. When performing a correction over the convex hull over a (somewhat small) set of vertices ofD\u03b4 , this convergence difference was quite significant in our experiments (MFW converging in a small number of iterations to do an approximate correction vs. FW taking hundreds of iterations to reach a similar level of accuracy). We note that the TRW objective is strongly convex when all the edge probabilities are nonzero (Wainwright et al., 2005); and that it has Lipschitz gradient over D\u03b4 (but not D).\nThe gap computed in step 6 of Algorithm 3 is non-standard; it is a sufficient condition to ensure the global linear convergence of the outer FCFW algorithm when using Algorithm 3 as a subroutine to implement the approximate correction step. See Lacoste-Julien and Jaggi (2015) for more details.\nThe MFW algorithm requires more bookkeeping than standard FW: in addition to the current iterate x(k), it also maintains both the active set S(k) (to search for the \u201caway vertex\u201d) as well as the barycentric coordinates \u03b1(k) (to know what are the away step-sizes that ensure feasibility \u2013 see step 13) i.e. x(k) = \u2211 v\u2208S(k) \u03b1 (k) v v.\nAlgorithm 3: Modified Frank-Wolfe algorithm (FW with Away Steps) \u2013 used for approximate correction\n1: Function MFW(x(0),\u03b1(0),V, ) to optimize over conv(V): 2: Inputs: Set of atoms V , starting point x(0) = \u2211 v\u2208S(0) \u03b1 (0) v v where S(0) is active set and \u03b1(0) the active\ncoordinates, stopping criterion . 3: for k = 0 . . .K do 4: Let sk \u2208 arg min\nv\u2208V \u3008\u2207f(x(k)),v\u3009 and dFWk := sk \u2212 x(k) (the FW direction)\n5: Let vk \u2208 arg max v\u2208S(k)\n\u2329 \u2207f(x(k)),v \u232a and dAk := x (k) \u2212 vk (the away direction)\n6: gpFWk := \u2329 \u2212\u2207f(x(k)),dFWk + dAk \u232a (stringent gap is FW + away gap to work better for FCFW) 7: if gpFWk \u2264 then 8: return x(k), \u03b1(k), S(k). 9: else\n10: if \u2329 \u2212\u2207f(x(k)),dFWk \u232a \u2265 \u2329 \u2212\u2207f(x(k)),dAk \u232a then 11: dk := dFWk , and \u03b3max := 1 (choose the FW direction) 12: else 13: dk := dAk , and \u03b3max :=\n\u03b1vk (1\u2212\u03b1vk )\n(choose away direction; maximum feasible step-size) 14: end if 15: Line-search: \u03b3k \u2208 arg min \u03b3\u2208[0,\u03b3max] f ( x(k) + \u03b3dk ) 16: Update x(k+1) := x(k) + \u03b3kdk 17: Update coordinates \u03b1(k+1) accordingly (see Lacoste-Julien and Jaggi (2015)). 18: Update S(k+1) := {v s.t. \u03b1(k+1)v > 0} 19: end if 20: end for"}, {"heading": "B.2 Fully Corrective Frank-Wolfe (FCFW) with Adaptive-\u03b4", "text": "We give in Algorithm 4 the pseudo-code to perform fully corrective Frank-Wolfe optimization over D by iteratively optimizing over D\u03b4 with adaptive-\u03b4 updates. If \u03b4 is kept constant (skipping step 10), then Algorithm 4 implements the fixed \u03b4 variant over D\u03b4 . We describe the algorithm as maintaining the correction set of atoms V (k+1) over D (rather than D\u03b4), as \u03b4 is constantly changing. One can easily move back and forth between V (k+1) and its contraction V\u03b4 = (1\u2212 \u03b4(k))V (k+1) + \u03b4(k)u0, and so we note that an efficient implementation might work with either representation cheaply (for example, by storing only V (k+1) and \u03b4, not the perturbed version of the correction polytope). The approximate correction over V\u03b4 is implemented using the MFW algorithm described in Algorithm 3, which requires a barycentric representation \u03b1(k) of the current iter-\nate x(k) over the correction polytope V\u03b4 . Our notation in Algorithm 4 uses the elements of V as indices, rather than their contracted version; that is, we maintain the property that x(k) = \u2211 v\u2208V \u03b1 (k) v [(1\u2212 \u03b4(k))v+ \u03b4(k)u0]. As V\u03b4 changes when \u03b4 changes, we need to update the barycentric representation of x(k) accordingly \u2013 this is done in step 11 with the following equation. Suppose that we decrease \u03b4 to \u03b4\u2032. Then the old coordinates \u03b1 can be updated to new coordinates \u03b1\u2032 for the new contraction polytope as follows:\n\u03b1\u2032v = \u03b1v 1\u2212 \u03b4 1\u2212 \u03b4\u2032 for v \u2208 V \\ {u0},\n\u03b1\u2032u0 = 1\u2212 \u2211 v 6=u0 \u03b1\u2032v. (6)\nThis ensures that \u2211 v \u03b1vv(\u03b4) = \u2211 v \u03b1 \u2032 vv(\u03b4\u2032), where v(\u03b4) := (1\u2212 \u03b4)v + \u03b4u0, and that the coordinates form a valid convex combination (assuming that \u03b4\u2032 \u2264 \u03b4), as can be readily verified.\nAlgorithm 4: Optimizing f over D using Fully Corrective Frank-Wolfe (FCFW) with Adaptive-\u03b4 Algorithm. 1: FCFW(x(0),V, , \u03b4(init)) 2: Inputs: Set of atoms V so that D = conv(V), active set S(0), starting point x(0) = \u2211 v\u2208S(0) \u03b1 (0) v [(1\u2212 \u03b4(init))v + \u03b4(init)u0] where \u03b1(0) are the active coordinates, \u03b4(init) \u2264 14\ndescribes the initial contraction of the polytope, stopping criterion , u0 is a fixed reference point in the relative interior of D.\n3: Let V (0) := S(0) (optionally, a bigger V (0) could be passed as argument for a warm start), \u03b4(\u22121) := \u03b4(init) 4: for k = 0 . . .K do 5: Let s(k) \u2208 arg min\nv\u2208V\n\u2329 \u2207f(x(k)),v \u232a (the FW vertex)\n6: Compute g(x(k)) = \u3008\u2212\u2207f(x(k)), s(k) \u2212 x(k)\u3009 (FW gap) 7: if g(x(k)) \u2264 then 8: return x(k) 9: end if\n10: Let \u03b4(k) be \u03b4(k\u22121) updated according to Algorithm 1. 11: Update \u03b1(k) accordingly (using (6)) 12: Let s(k)(\u03b4) := (1\u2212 \u03b4 (k))s(k) + \u03b4(k)u0 13: Let dFWk := s (k) (\u03b4) \u2212 x (k)\n14: Line-search: \u03b3k \u2208 arg min \u03b3\u2208[0,1]\nf ( x(k) + \u03b3dFWk ) 15: Set x(temp) := x(k) + \u03b3kdFWk (initialize correction to the update after a FW step with line search) 16: \u03b1(temp) = (1\u2212 \u03b3k)\u03b1(k) 17: \u03b1(temp) s(k) \u2190 \u03b1(temp) s(k)\n+ \u03b3k (update coordinates according to the FW step) 18: Update (non-contracted) correction polytope: V (k+1) := V (k) \u222a {s(k)} 19: Let V\u03b4 = (1\u2212 \u03b4(k))V (k+1) + \u03b4(k)u0 (contracted correction polytope) 20: x(k+1), \u03b1(k+1) := MFW(x(temp),\u03b1(temp), V\u03b4, ) (approximate correction step on V\u03b4 using MFW) 21: end for"}, {"heading": "C Bounding the Sub-optimality for Fixed \u03b4 Variant", "text": "The pseudocode for optimizing over D\u03b4 for a fixed \u03b4 is given in Algorithm 4 (by ignoring the step 10 which updates \u03b4). It is stated with a stopping criterion , but it can alternatively be run for a fixed number of K iterations. The following theorem bounds the suboptimality of the iterates with respect to the true optimum x\u2217 over D. If one can compute the constants in the theorem, one can choose a target contraction amount \u03b4 to guarantee a specific suboptimality of \u2032; otherwise, one can choose \u03b4 using heuristics. Note that unlike the adaptive-\u03b4 variant, this algorithm does not converge to the true solution as K \u2192 \u221e unless x\u2217 happens to belong to D\u03b4 . But the error can be controlled by choosing \u03b4 small enough. Theorem C.1 (Suboptimality bound for fixed-\u03b4 algorithm). Let f satisfy the properties in Problem 3.2 and suppose its gradient is Lipschitz continuous on the contractions D\u03b4 as in Property 3.3. Suppose further that f is finite on the boundary of D.\nThen f is uniformly continuous on D and has a modulus of continuity function \u03c9 quantifying its level of continuity, i.e. |f(x)\u2212 f(x\u2032)|\u2264 \u03c9(\u2016x\u2212 x\u2032\u2016) \u2200x,x\u2032 \u2208 D, with \u03c9(\u03c3) \u2193 0 as \u03c3 \u2193 0.\nLet x\u2217 be an optimal point of f over D. The iterates x(k) \u2208 D\u03b4 of the FCFW algorithm as described in Algorithm 4 for a fixed \u03b4 > 0 has sub-optimality over D bounded as:\nf(x(k))\u2212 f(x\u2217) \u2264 2C\u03b4 (k + 2) + \u03c9 (\u03b4 diam(D)) , (7)\nwhere C\u03b4 \u2264 diam(D\u03b4)2L\u03b4 . Note that different norms can be used in the definition of \u03c9(\u00b7) and C\u03b4 .\nProof. Let x\u2217(\u03b4) be an optimal point of f over D\u03b4 . As f has a Lipschitz continuous gradient over D\u03b4 , we can use any standard convergence result of the Frank-Wolfe algorithm to bound the suboptimality of the iterate x(k) over D\u03b4 . Algorithm 4 (with a fixed \u03b4) describes the FCFW algorithm which guarantees at least as much progress as the standard FW algorithm (by step 15 and 20a), and thus we can use the convergence result from Jaggi (2013) as already stated in (4): f(x(k)) \u2212 f(x\u2217(\u03b4)) \u2264 2C\u03b4 (k+2)\nwith C\u03b4 \u2264 diam(D\u03b4)2L\u03b4 , where L\u03b4 comes from Property 3.3. This gives the first term in (7). Note that if the function f is strongly convex, then the FCFW algorithm has also a linear convergence rate (Lacoste-Julien and Jaggi, 2015), though we do not cover this here.\nWe now need to bound the difference f(x\u2217(\u03b4)) \u2212 f(x\u2217) coming from the fact that we are not optimizing over the full domain, and giving the second term in (7). We let x\u0303(\u03b4) be the contraction of x\u2217 on D\u03b4 towards u0, i.e. x\u0303(\u03b4) := (1 \u2212 \u03b4)x\u2217 + \u03b4u0.5 Note that \u2016x\u0303(\u03b4) \u2212 x\u2217\u2016= \u03b4\u2016x\u2217 \u2212 u0\u2016\u2264 \u03b4 diam(D), and thus can be made arbitrarily small by letting \u03b4 \u2193 0. Because x\u0303(\u03b4) \u2208 D\u03b4 , we have that f(x\u0303(\u03b4)) \u2265 f(x\u2217(\u03b4)) as x\u2217(\u03b4) is optimal over D\u03b4 . Thus f(x\u2217(\u03b4))\u2212 f(x\u2217) \u2264 f(x\u0303(\u03b4))\u2212 f(x\u2217) \u2264 \u03c9(\u2016x\u0303(\u03b4) \u2212 x\u2217\u2016) by the uniform continuity of f (that we explain below). Since \u03c9 is an increasing function, we have \u03c9(\u2016x\u0303(\u03b4) \u2212 x\u2217\u2016) \u2264 \u03c9(\u03b4 diam(D)), giving us the control on the second term of (7). See Figure 3 for an illustration of the four points considered in this proof.\nFinally, we explain why f is uniformly continuous. As f is a (lower semi-continuous) convex function, it is continuous at every point where it is finite. As f is said to be finite at its boundary (and it is obviously finite in the relative interior of D as it is continuously differentiable there), then f is continuous over the whole of D. As D is compact, this means that f is also uniformly continuous over D.\nWe note that the modulus of continuity function \u03c9 quantifies the level of continuity of f . For a Lipschitz continuous function, we have \u03c9(\u03c3) \u2264 L\u03c3. If instead we have \u03c9(\u03c3) \u2264 C\u03c3\u03b1 for some \u03b1 \u2208 [0, 1], then f is actually \u03b1-Ho\u0308lder continuous. We will see in Section E.2 that the TRW objective is not Lipschitz continuous, but it is \u03b1-Ho\u0308lder continuous for any \u03b1 < 1, and so is \u201calmost\u201d Lipschitz continuous. From the theorem, we see that to get an accuracy of the order , we would need (\u03b4 diam(D))\u03b1 < , and thus a contraction of \u03b4 < (1/\u03b1)\ndiam(D) .\n5Note that without a strong convexity assumption on f , the optimum over D\u03b4 , x\u2217(\u03b4), could be quite far from the optimum over D, x\u2217, which is why we need to construct this alternative close point to x\u2217."}, {"heading": "D Convergence with Adaptive-\u03b4", "text": "In this section, we show the convergence of the adaptive-\u03b4 FW algorithm to optimize a function f satisfying the properties in Problem 3.2 and Property 3.3 (Lipschitz gradient over D\u03b4 with bounded growth).\nThe adaptive update for \u03b4 (given in Algorithm 1) can be used with the standard Frank-Wolfe optimization algorithm or also the fully corrective Frank-Wolfe (FCFW) variant. In FCFW, we ensure that every update makes more progress than a standard FW step with line-search, and thus we will show the convergence result in this section for standard FW (which also applies to FCFW). We describe the FCFW variant with approximate correction steps in Algorithm 4, as this is what we used in our experiments.\nWe first list a few definitions and lemmas that will be used for the main convergence convergence result given in Theorem D.6. We begin with the definitions of duality gaps that we use throughout this section. The FrankWolfe gap is our primary criterion for halting and measuring the progress of the optimization over D. The uniform gap is a measure of the decrease obtainable from moving towards the uniform distribution.\nDefinition D.1. We define the following gaps:\n1. The Frank-Wolfe (FW) gap is defined as: g(x(k)) := \u3008\u2212\u2207f(x(k)), s(k) \u2212 x(k)\u3009.\n2. The uniform gap is defined as: gu(x(k)) := \u3008\u2212\u2207f(x(k)),u0 \u2212 x(k)\u3009.\n3. The FW gap over D\u03b4 is: g(\u03b4(k))(x (k)) := \u3008\u2212\u2207f(x(k)), s(k)(\u03b4) \u2212 x (k)\u3009.\nThe name for the uniform gap comes from the fact that the FW gap over D\u03b4 can be expressed as a convex combination of the FW gap over D and the uniform gap:\ng(\u03b4(k))(x (k)) = \u3008\u2212\u2207f(x(k)), (1\u2212 \u03b4(k))s(k) + \u03b4(k)u0 \u2212 x(k)\u3009\n= (1\u2212 \u03b4(k))g(x(k)) + \u03b4(k)gu(x(k)). (8)\nThe uniform gap represents the negative directional derivative of f at x(k) in the direction u0 \u2212 x(k). When the uniform gap is negative (thus f is increasing when moving towards u0 from x(k)), then the contraction is hurting progress, which explains the type of adaptive update for \u03b4 given by Algorithm 1 where we consider shrinking \u03b4 in this case. This enables us to crucially relate the FW gap over D\u03b4 with the one over D, as given in the following lemma, using the assumption that \u03b4(init) \u2264 1\n4 .\nLemma D.2 (Gaps relationship). For iterates progressing as in Algorithm 4 with adaptive update on \u03b4 as given in Algorithm 1, the gap over D\u03b4 and D are related as : g(\u03b4(k))(x (k)) \u2265 g(x (k)) 2 .\nProof. The duality gaps g(x(k)) and g(\u03b4(k))(x (k)) computed as defined in (D.1) during Algorithm 4 are related by equation (8).\nWe analyze two cases separately:\n(1) When gu(x(k)) \u2265 0, for \u03b4(init) \u2264 14 , we have g(\u03b4(k))(x (k)) \u2265 3 4 g(x(k)) as \u03b4(k) \u2264 \u03b4(init).\n(2) When gu(x(k)) < 0, from the update rule in lines 5 to 7 in Algorithm 1, we have \u03b4(k) \u2264 g(x (k))\n\u22124gu(x(k)) =\u21d2\n\u03b4(k)gu(x (k)) \u2265 \u2212 g(x (k)) 4 . Therefore, g(\u03b4(k))(x (k)) \u2265 3 4 g(x(k))\u2212 g(x (k)) 4 = g(x (k)) 2 .\nTherefore, the gap over D\u03b4 and D are related as : g(\u03b4(k))(x (k)) \u2265 g(x (k)) 2 .\nAnother property that we will use in the convergence proof is that \u2212gu is upper bounded for any convex function f :6\nLemma D.3 (Bounded negative uniform gap). Let f be a continuously differentiable convex function on the relative interior of D. Then for any fixed u0 in the relative interior of D, \u2203B s.t.\n\u2200x \u2208 D, \u2212gu(x) = \u3008\u2207f(x),u0 \u2212 x\u3009 \u2264 B. (9)\nIn particular, we can take the finite value:\nB := \u2016\u2207f(u0)\u2016\u2217diam\u2016\u00b7\u2016(D) (10)\n6Note that on the other hand, gu(x) might go to infinity as x gets close to the boundary ofD as the gradient of f is allowed to be unbounded. Fortunately, we only need an upper bound on \u2212gu, not a lower bound.\nProof. As f is convex, its directional derivative is a monotone increasing function in any direction. Let u0 and x be points in the relative interior of D; then their gradient exists and we have by the monotonicity property:\n\u3008\u2207f(u0)\u2212\u2207f(x),u0 \u2212 x\u3009 \u2265 0 =\u21d2 \u3008\u2207f(u0),u0 \u2212 x\u3009 \u2265 \u3008\u2207f(x),u0 \u2212 x\u3009 .\nThis inequality is valid for all x in the relative interior of D, and can be extended to the boundary by taking limits (with potentially the RHS become minus infinity, but this is not a problem). Finally, by the definition of the dual norm (generalized Cauchy-Schwartz), we have \u3008\u2207f(u0),u0 \u2212 x\u3009 \u2264 \u2016\u2207f(u0)\u2016\u2217\u2016u0 \u2212 x\u2016\u2264 \u2016\u2207f(u0)\u2016\u2217diam\u2016\u00b7\u2016(D).\nFinally, we need a last property of Algorithm 4 that allows us to bound the amount of perturbation \u03b4(k) of the polytope at every iteration as a function of the sub-optimality over D.\nLemma D.4 (Lower bound on perturbation). Let B be a bound such that \u22128gu(x) \u2264 B for all x \u2208 D (given by Lemma D.3). Then at every stage of Algorithm 4, we have that:\n\u03b4(init) \u2265 \u03b4(k) \u2265 min { hk B , \u03b4(init) } ,\nwhere \u03b4(init) is the initial value of \u03b4 and hk := f(x(k))\u2212 f(x\u2217) is the sub-optimality of the iterate.\nProof. When defining \u03b4(k) in step 10 of Algorithm 4, we either preserve the value of \u03b4(k\u22121) or if we update it, then by the lines 6 and 7 of Algorithm 1, we have \u03b4(k) \u2265 \u03b4\u0303\n2 = 1 2 g(x(k)) \u22124gu(x(k)) \u2265 g(x (k)) B (by using gu(x(k)) < 0\nin this case). Since g(x(k)) \u2265 hk (the FW gap always upper bounds the suboptimality), we conclude \u03b4(k) \u2265 min{hk\nB , \u03b4(k\u22121)}. Unrolling this recurrence, we thus get:\n\u03b4(k) \u2265 min {\nmin 0\u2264l\u2264k hl B , \u03b4(init)\n} = min { hk B , \u03b4(init) } .\nFor the last equality, we used the fact that hk is non-increasing since Algorithm 4 decreases the objective at every iteration (using the line-search in step 14).\nWe now bound the generalization of a standard recurrence that will arise in the proof of convergence. This is a generalization of the technique used in Teo et al. (2007) (also used in the context of Frank-Wolfe in the proof of Theorem C.4 in Lacoste-Julien et al. (2013)). The basic idea is that one can bound a recurrence inequality by the solution to a differential equation. We provide a detailed proof of the bound for completeness here.\nLemma D.5 (Recurrence inequality solution). Let 1 < a \u2264 b. Suppose that hk is any non-negative sequence that satisfies the recurrence inequality:\nhk+1 \u2264 hk \u2212 1\nbC0 (hk)\na with initial condition ha\u221210 \u2264 C0.\nThen hk is strictly decreasing (unless it equals zero) and can be bounded for k \u2265 0 as:\nhk \u2264 (\nC0\n(a\u22121 b )k + 1\n) 1 a\u22121\nProof. Taking the continuous time analog of the recurrence inequality, we consider the differential equation:\ndh dt = \u2212ha bC0 with initial condition h(0) = C 1 a\u22121 0 .\nSolving it:\ndh dt = \u2212ha bC0\n=\u21d2 \u222b dh\nha = \u222b \u2212dt bC0\n=\u21d2 [ \u2212h1\u2212a\na\u2212 1 ]h(t) h(0) = \u2212 t\u2212 0 bC0\n( Using the initial conditions:)\n=\u21d2 \u22121 h(t)a\u22121 + 1 C0 = \u2212t(a\u2212 1) bC0\n=\u21d2 1 h(t)a\u22121 = ( ( a\u2212 1 b )t+ 1 ) 1 C0\n=\u21d2 h(t) = (\nC0\n(a\u22121 b )t+ 1\n) 1 a\u22121\n.\nWe now denote the solution to the differential equation as h\u0303(t). Note that it is a strictly decreasing convex\nfunction (which could also be directly implied from the differential equation as: d 2h dt2 = \u2212a h\na\u22121 bC0\ufe38 \ufe37\ufe37 \ufe38 >0 h\u2032(t)\ufe38\ufe37\ufe37\ufe38 <0 > 0 ).\nOur strategy will be to show by induction that if hk \u2264 h\u0303(k), then hk+1 \u2264 h\u0303(k + 1). This allows us to bound the recurrence by the solution to the differential equation.\nAssume that hk \u2264 h\u0303(k). The base case is h0 \u2264 h\u0303(0) = C 1 a\u22121 0 , which is true by the initial condition on h0.\nConsider the utility function l(h) := h \u2212 h a\nbC0 which is maximized at h\u0304 := ( bC0 a ) 1 a\u22121 . This function can\nbe verified to be strictly concave for a > 1 and therefore is increasing for h \u2264 h\u0304. Note that the recurrence inequality can be written as hk+1 \u2264 l(hk). Since h\u0303 is decreasing and that h\u0303(0)) = C 1 a\u22121 0 \u2264 ( bC0 a ) 1 a\u22121 = h\u0304 (the last inequality holds since b \u2265 a), we have h\u0303(t) \u2264 h\u0304 for all t \u2265 0, and so h\u0303(t) is always in the monotone increasing region of l.\nFrom the induction hypothesis and the monotonicity of l, we thus get that l(hk) \u2264 l(h\u0303(k)).\nNow the convexity of h\u0303(t) gives us h\u0303(k+1) \u2265 h\u0303(k)+h\u0303\u2032(k) = h\u0303(k)\u2212 h\u0303(k) a\nbC0 = l(h\u0303(k)). Combining these two\nfacts with the recurrence inequality hk+1 \u2264 l(hk), we get: hk+1 \u2264 l(hk) \u2264 l(h\u0303(k)) \u2264 h\u0303(k + 1), completing the induction step and the main part of the proof.\nFinally, whenever hk > 0, we have that hk+1 < hk from the recurrence inequality, and so hk is strictly decreasing as claimed.\nGiven these elements, we are now ready to state the main convergence result for Algorithm 4. The convergence rate goes through three stages with increasingly slower rate. The level of suboptimality hk determines the stage. We first give the high level intuition behind these stages. Recall that by Lemma D.4, hk lower bounds the amount of perturbation \u03b4(k), and thus when hk is big, the function f is well-behaved by Property 3.3. In the first stage, the suboptimality is bigger than some target constant (which implies that the FW gap is big), yielding a geometric rate of decrease of error (as is standard for FW with line-search in the first few steps). In the second stage, the suboptimality is in an intermediate regime: it is smaller than the target constant, but big enough compared to the initial \u03b4init so that f is still well-behaved onD\u03b4(k) . We get there the usualO(1/k) rate as in standard FW. Finally, in the third stage, we get the slower O(k\u2212 1 p+1 ) rate where the growth in O(\u03b4\u2212p) of the Lipschitz constant of f over D\u03b4 comes into play. Theorem D.6 (Global convergence for adaptive-\u03b4 variant over D). Consider the optimization of f satisfying the properties in Problem 3.2 and Property 3.3. Let C\u0303 := Ldiam\u2016\u00b7\u2016(D)2, where L is from Property 3.3. Let B be the upper bound on the negative uniform gap: \u22128gu(x) \u2264 B for all x \u2208 D, as used in Lemma D.4 (arising from Lemma D.3). Then the iterates x(k) obtained by running the Frank-Wolfe updates over D\u03b4 with line-search with \u03b4 updated according to Algorithm 1 (or as summarized in a FCFW variant in Algorithm 4), have suboptimality hk upper bounded as:\n1. hk \u2264 ( 1 2 )k h0 +\nC\u0303 \u03b4 p 0 for k such that hk \u2265 max{B\u03b40, 2C\u0303\u03b4p0 },\n2. hk \u2264 2C\u0303\u03b4p0\n[ 1\n1 4 (k\u2212k0)+1 ] for k such that B\u03b40 \u2264 hk \u2264 2C\u0303\u03b4p0 ,\n3. hk \u2264 [ max(C\u0303,B\u03b4 p+1 0 )B p\np+1 max(8,p+2) (k\u2212k1)+1\n] 1 p+1\n= O(k \u2212 1 p+1 ) for k such that hk \u2264 B\u03b40,\nwhere \u03b40 = \u03b4(init), h0 is the initial suboptimality, and k0 and k1 are the number of steps to reach stage 2 and 3\nrespectively which are bounded as: k0 \u2264 max(0, dlog 1 2 C\u0303 h0\u03b4 p 0 e), k0 \u2264 k1 \u2264 k0 + max\n( 0, d 8C\u0303\nB\u03b4 p+1 0\ne \u2212 4 ) .\nProof. Let x\u03b3 := x(k) + \u03b3dFWk with d FW k defined in step 12 in Algorithm 4. Note that x\u03b3 \u2208 D\u03b4 with \u03b4 = \u03b4(k) for all \u03b3 \u2208 [0, 1]. We apply the Descent Lemma A.1 on this update to get:\nf(x\u03b3) \u2264 f(x(k)) + \u03b3\u3008\u2207f(x(k)),dFWk \u3009+ \u03b32 L\u2016dFWk \u20162\n2 (\u03b4(k)) p \u2200\u03b3 \u2208 [0, 1].\nWe have L\u2016dFWk \u20162\u2264 C\u0303 by assumption and \u3008\u2207f(x(k)),dFWk \u3009 = \u2212g(\u03b4)(x(k)) by definition. Moreover, x(k+1) is defined to make at least as much progress than the line-search result min\u03b3\u2208[0,1] f(x\u03b3) (line 14 and 15), and so we have:\nf(x(k+1)) \u2264 f(x(k))\u2212 \u03b3g(\u03b4)(x(k)) + \u03b32 C\u0303\n2 (\u03b4(k)) p \u2200\u03b3 \u2208 [0, 1]\n\u2264 f(x(k))\u2212 \u03b3 2 g(x(k)) + \u03b32 C\u0303 2 (\u03b4(k)) p \u2200\u03b3 \u2208 [0, 1].\nFor the final inequality, we used Lemma D.2 which relates the gap over D\u03b4 to the gap over D.\nSubtracting f(x\u2217) from both sides and using g(x(k)) \u2265 hk by convexity, we get:\nhk+1 \u2264 hk \u2212 \u03b3hk\n2 +\n\u03b32C\u0303\n2 (\u03b4(k)) p .\nNow, using Lemma D.4, we have that \u03b4(k) \u2265 min(hk B , \u03b4(init)):\nhk+1 \u2264 hk \u2212 \u03b3 hk 2 + \u03b32 2 C\u0303( min(hk\nB , \u03b4(init)) )p \u2200\u03b3 \u2208 [0, 1]. (11) We refer to (11) as the master inequality. Since we no longer have a dependance on \u03b4(k), we refer to \u03b4(init) as \u03b40. We now follow a similar form of analysis as in the proof of Theorem C.4 in Lacoste-Julien et al. (2013). To solve this and bound the suboptimality, we consider three stages:\n1. Stage 1: The min in the denominator is \u03b40 and hk is big: hk \u2265 max{B\u03b40, 2C\u0303\u03b4p0 }.\n2. Stage 2: The min in the denominator is \u03b40 and hk is small: B\u03b40 \u2264 hk \u2264 2C\u0303\u03b4p0 .\n3. Stage 3: The min in the denominator is hk B , i.e.: hk \u2264 B\u03b40.\nSince hk is decreasing, once we leave a stage, we no longer re-enter it. The overall strategy for each stage is as follows. For each recurrence that we get, we select a \u03b3\u2217 that realizes the tightest upper bound on it.\nSince we are restricted that \u03b3\u2217 \u2208 [0, 1], we have to consider when \u03b3\u2217 > 1 and \u03b3\u2217 \u2264 1. For the former, we bound the recurrence obtained by substituting \u03b3 = 1 into (11). For the latter, we substitute the form of \u03b3\u2217 into the recurrence and bound the result.\nStage 1\nWe consider the case where hk \u2265 B\u03b40. This yields:\nhk+1 \u2264 hk \u2212 \u03b3hk\n2 +\n\u03b32C\u0303\n2 (\u03b40) p (12)\nThe bound is minimized by setting \u03b3\u2217 = hk\u03b4 p 0\n2C\u0303 . On the other hand, the bound is only valid for \u03b3 \u2208 [0, 1],\nand thus if \u03b3\u2217 > 1, i.e. hk > 2C\u0303\u03b4p0 (stage 1), then \u03b3 = 1 will yield the minimum feasible value for the bound. Unrolling the recursion (12) for \u03b3 = 1 during this stage (where hl > 2C\u0303\u03b4p0 for l < k as hk is decreasing), we get:\nhk+1 \u2264 hk 2 + C\u0303\n2\u03b4p0\n\u2264 1 2\n( hk\u22121\n2 +\nC\u0303\n2\u03b4p0\n) + C\u0303\n2\u03b4p0\n\u2264 ( 1\n2\n)k+1 h0 + C\u0303\n2\u03b4p0 k\u2211 l=0 ( 1 2 )l \ufe38 \ufe37\ufe37 \ufe38 \u2264 \u2211\u221e l=0( 1 2 ) l =2\nthus hk \u2264 ( 1\n2\n)k h0 + C\u0303\n\u03b4p0 , (13)\ngiving the bound for the iterates in the first stage.\nWe can compute an upper bound on the number of steps it takes to reach a suboptimality of 2C\u0303 \u03b4 p 0 by looking at the minimum k which ensures that the bound in (13) becomes smaller than 2C\u0303 \u03b4 p 0 , yielding kmax = max(0, dlog 1 2 C\u0303 h0\u03b4 p 0 e). Therefore, let k0 \u2264 kmax be the first k such that hk \u2264 2C\u0303\u03b4p0 .\nStage 2\nFor this case analysis, we refer to k as being the iterations after k0 steps have elapsed. I.e. if knew := k \u2212 k0, then we refer to knew as k moving forward.\nIn stage 2, we suppose that B\u03b40 \u2264 hk \u2264 2C\u0303\u03b4p0 . This means that \u03b3 \u2217 =\nhk\u03b4 p 0\n2C\u0303 \u2264 1.\nSubstituting \u03b3 = \u03b3\u2217 into (12) yields: hk+1 \u2264 hk \u2212 h2k \u03b4 p 0\n8C\u0303 .\nUsing the result of Lemma D.5 with a = 2, b = 4 and C0 = 2C\u0303\u03b4p0 , we get the bound:\nhk \u2264 2C\u0303 \u03b4 p 0\nk\u2212k0 4\n+ 1 .\nIt is worthwhile to point out at this juncture that the bound obtained for stage 2 is the same as the one for regular Frank-Wolfe, but with a factor of 4 worse due to the factor of 1\n2 in front of the FW gap which appeared due to\nLemma D.2.\nStage 3\nHere, we suppose hk \u2264 B\u03b40. We can compute a bound on the number of steps k1 needed get to stage 3 by looking at the number of steps it takes for the bound in stage 2 to becomes less than B\u03b40:\n2C\u0303 \u03b4p0\n[ 4\nk1 \u2212 k0 + 4 ] \u2264 B\u03b40[\n1\nk1 \u2212 k0 + 4\n] \u2264 B\u03b4 p+1 0\n8C\u0303\nk1 \u2265 k0 + d 8C\u0303\nB\u03b4p+10 e \u2212 4.\nAs before, moving forward, our notation on k represents the number of steps taken after k1 steps.\nThen, the master inequality (11) becomes:\nhk+1 \u2264 hk \u2212 \u03b3\n2 hk +\n\u03b32C\u0303Bp\n2hpk .\nTo simplify the rest of the analysis, we replace C\u0303Bp with F := max(B\u03b4p+10 , C\u0303)B p. We then get the bound:\nhk+1 \u2264 hk \u2212 \u03b3\n2 hk +\n\u03b32F 2hk , (14)\nwhich is minimized by setting \u03b3\u2217 := h p+1 k 2F . Since F \u2265 Bp+1\u03b4p+10 (by construction) and h p+1 k \u2264 (B\u03b40) p+1 (by the condition to be in stage 3), we necessarily have that \u03b3\u2217 \u2264 1. We chose the value of F to avoid having to consider the possibility \u03b3\u2217 > 1 as we did in the distinction between stage 1 and stage 2.\nHence, substituting \u03b3 = \u03b3\u2217 in (14), we get:\nhk+1 \u2264 hk \u2212 hp+2k 8F .\nUsing the result of Lemma D.5 with a = p+ 2, b = max(8, p+ 2) and C0 = F , we get the bound:\nhk \u2264\n[ max(C\u0303, B\u03b4p+10 )B p\np+1 max(8,p+2) (k \u2212 k1) + 1\n] 1 p+1\n= O(k \u2212 1 p+1 ),\nconcluding the proof.\nInterestingly, the obtained rate of O(1/ \u221a k) for p = 1 (for the TRW objective e.g.) is the standard rate that one would get for the optimization of a general non-smooth convex function with the projected subgradient method (and it is even a lower bound for some class of first-order methods; see e.g. Section 3.2 in Nesterov (2004)). The fact that our function f does not have Lipschitz continuous gradient on the whole domain brings us back to the realm of non-smooth optimization. It is an open question whether Algorithm 4 has an optimal rate for the class of functions defined in the assumptions of Theorem D.6."}, {"heading": "E Properties of the TRW Objective", "text": "In this section, we explicitly compute bounds for the constants appearing in the convergence statements for our fixed-\u03b4 and adaptive-\u03b4 algorithms for the optimization problem given by:\nmin ~\u00b5\u2208M\n\u2212TRW(~\u00b5; ~\u03b8,\u03c1).\nIn particular, we compute the Lipschitz constant for its gradient overM\u03b4 (Property 3.3), we give a form for its modulus of continuity function \u03c9(\u00b7) (used in Theorem 3.4), and we compute B, the upper bound on the negative uniform gap (as used in Lemma D.3)."}, {"heading": "E.1 Property 3.3 : Controlled Growth of Lipschitz Constant overM\u03b4", "text": "We first motivate our choice of norm overM. Recall that ~\u00b5 can be decomposed into |V |+|E| blocks, with one pseudo-marginal vector \u00b5i \u2208 \u2206VALi for each node i \u2208 V , and one vector \u00b5ij \u2208 \u2206VALiVALj per edge {i, j} \u2208 E, where \u2206d is the probability simplex over d values. We let c be the cliques in the graph (either nodes or edges). From its definition in (2), f(~\u00b5) := \u2212TRW(~\u00b5; ~\u03b8,\u03c1) decomposes as a separable sum of functions of each block only:\nf(~\u00b5) := \u2212TRW(~\u00b5; ~\u03b8,\u03c1) = \u2212 \u2211 c (KcH(\u00b5c) + \u3008\u03b8c,\u00b5c\u3009) =: \u2211 c gc(\u00b5c), (15)\nwhere Kc is (1\u2212 \u2211 j\u2208N (i) \u03c1ij) if c = i and \u03c1ij if c = {i, j}. The function gc also decomposes as a separable sum: gc(\u00b5c) :=\n\u2211 xc Kc\u00b5c(xc) log(\u00b5c(xc))\u2212 \u03b8c(xc)\u00b5c(xc) =: \u2211 xc gc,xc(\u00b5c(xc)). (16)\nAs M is included in a product of probability simplices, we will use the natural `\u221e/`1 block-norm, i.e. \u2016~\u00b5\u2016\u221e,1:= maxc\u2016\u00b5c\u20161. The diameter ofM in this norm is particularly small: diam\u2016\u00b7\u2016\u221e,1(M) \u2264 2. The dual norm of the `\u221e/`1 block-norm is the `1/`\u221e block-norm, which is what we will need to measure the Lipschitz constant of the gradient (because of the dual norm pairing requirement from the Descent Lemma A.1).\nLemma E.1. Consider the `\u221e/`1 norm on M and its dual norm `1/`\u221e to measure the gradient. Then \u2207TRW(~\u00b5; ~\u03b8,\u03c1) is Lipschitz continuous overM\u03b4 with respect to these norms with Lipschitz constant L\u03b4 \u2264 L\u03b4 with:\nL \u2264 4|V |max ij\u2208E (VALiVALj). (17)\nProof. We first consider one scalar component of the separable gc(\u00b5c) function given in (16) (i.e. for one \u00b5c(xc) coordinate). Its derivative is Kc(1 + log(\u00b5c(xc))\u2212 \u03b8c(xc) with second derivative Kc\u00b5c(xc) . If ~\u00b5 \u2208M\u03b4 , then we have \u00b5c(xc) \u2265 \u03b4u0(xc) = \u03b4nc , where nc is the number of possible values that the assignment variable xc can take. Thus for ~\u00b5 \u2208 M\u03b4 , we have that the xc-component of gc is Lipschitz continuous with constant |Kc|nc/\u03b4. We thus have:\n\u2016\u2207gc(\u00b5c)\u2212\u2207gc(\u00b5\u2032c)\u2016\u221e = max xc |g\u2032c,xc(\u00b5(xc))\u2212 g \u2032 c,xc(\u00b5 \u2032(xc))|\n\u2264 |Kc|nc \u03b4 \u2016\u00b5c \u2212 \u00b5\u2032c\u2016\u221e\u2264 |Kc|nc \u03b4 \u2016\u00b5c \u2212 \u00b5\u2032c\u20161.\nConsidering now the `1-sum over blocks, we have: \u2016\u2207f(~\u00b5)\u2212\u2207f(~\u00b5\u2032)\u20161,\u221e = \u2211 c \u2016\u2207gc(\u00b5c)\u2212\u2207gc(\u00b5\u2032c)\u2016\u221e\n\u2264 \u2211 c Kcnc \u03b4 \u2016\u00b5c \u2212 \u00b5\u2032c\u20161\u2264 1 \u03b4 (\u2211 c Kcnc ) \u2016~\u00b5\u2212 ~\u00b5\u2032\u2016\u221e,1.\nThe Lipschitz constant is thus indeed L \u03b4 with L := \u2211 c|Kc|nc. Let us first consider the sum for c \u2208 V ; we\nhave Ki = 1\u2212 \u2211 j\u2208N (i) \u03c1ij . Thus:\u2211\ni |Ki| \u2264 |V |+ \u2211 i \u2211 j\u2208N (i) \u03c1ij\n= |V |+2 \u2211 ij\u2208E \u03c1ij = |V |+2(|V |\u22121) \u2264 3|V |.\nHere we used the fact that \u03c1ij came from the marginal probability of edges of spanning trees (and so with |V |\u22121 edges). Similarly, we have \u2211 ij\u2208E |Kij |\u2264 |V |. Combining these we get:\nL = \u2211 c |Kc|nc \u2264 (max c nc) \u2211 c |Kc|\u2264 max ij\u2208E VALiVALj4|V |. (18)\nRemark 1. The important quantity in the convergence of Frank-Wolfe type algorithms is C\u0303 = Ldiam(M)2. We are free to take any dual norm pairs to compute this quantity, but some norms are better aligned with the problem than others. Our choice of norm in Lemma E.1 gives C\u0303 \u2264 16|V |k2 where k is the maximum number of possible values a random variable can take. It is interesting that |E| does not appear in the constant. If instead we had used the `2/`1 block-norm onM, we get that diam`2/`1(M)\n2 = 4(|V |+|E|), while the constant L with dual norm `2/`\u221e would be instead maxc|Kc|nc which is bigger than maxc nc = k2, thus giving a worse bound."}, {"heading": "E.2 Modulus of Continuity Function", "text": "We begin by computing a modulus of continuity function for \u2212x log x with an additive linear term. Lemma E.2. Let g(x) := \u2212Kx log x+ \u03b8x. Consider x, x\u2032 \u2208 [0, 1] such that |x\u2212 x\u2032|\u2264 \u03c3, then:\n|g(x\u2032)\u2212 g(x)|\u2264 \u03c3|\u03b8|+2\u03c3|K|max{\u2212 log(2\u03c3), 1} =: \u03c9g(\u03c3). (19)\nProof. Without loss of generality assume x\u2032 > x, then we have two cases:\nCase i. If x > \u03c3, then we have that the Lipschitz constant of g(x) is L\u03c3 = |\u03b8|+|K||(1 + log \u03c3)| (obtained by taking the supremum of its derivative). Therefore, we have that |g(x\u2032)\u2212 g(x)|\u2264 L\u03c3\u03c3. Note that L\u03c3\u03c3 \u2192 0 when \u03c3 \u2192 0 even if L\u03c3 \u2192\u221e, since L\u03c3 grows logarithmically.\nCase ii. If x \u2264 \u03c3, then x\u2032 \u2264 x+ \u03c3 \u2264 2\u03c3. Therefore:\n|g(x\u2032)\u2212 g(x)|\u2264 |K||x log x\u2212 x\u2032 log x\u2032|+|\u03b8||x\u2032 \u2212 x|. (20)\nNow, we have that \u2212x log x is non-negative for x \u2208 [0, 1]. Furthermore, we have that \u2212x log x is increasing when x < exp(\u22121) and decreasing afterwards. First suppose that 2\u03c3 \u2264 exp(\u22121); then \u2212x\u2032 log x\u2032 \u2265 \u2212x log x \u2265 0 which implies:\n|x log x\u2212 x\u2032 log x\u2032|\u2264 \u2212x\u2032 log x\u2032 \u2264 \u22122\u03c3 log(2\u03c3).\nIn the case 2\u03c3 > exp(\u22121), then we have:\n|x log x\u2212 x\u2032 log x\u2032|\u2264 max y\u2208[0,1] {\u2212y log y} = exp(\u22121) \u2264 2\u03c3.\nCombining these two possibilities, we get:\n|x log x\u2212 x\u2032 log x\u2032|\u2264 2\u03c3max{\u2212 log(2\u03c3), 1}.\nThe inequality (20) thus becomes:\n|g(x\u2032)\u2212 g(x)|\u2264 |K|2\u03c3max{\u2212 log(2\u03c3), 1}+ |\u03b8|\u03c3,\nwhich is what we wanted to prove.\nFor small \u03c3, the dominant term of the function \u03c9g(\u03c3) in Lemma E.2 is of the formC \u00b7\u2212\u03c3 log \u03c3 for a constantC. If we require that this be smaller than some small \u03be > 0, then we can choose an approximate \u03c3 by solving for x in\u2212Ax log x = \u03be yielding x = exp(W\u22121 \u03beA ) where W\u22121 is the negative branch of the Lambert W-function. This is almost linear and yields approximately x = O(\u03be) for small \u03be. In fact, we have that \u03c9g(\u03c3) \u2264 C\u2032\u03c3\u03b1 for any \u03b1 < 1, and thus g is \u201calmost\u201d Lipschitz continuous.\nLemma E.3. The following function is a modulus of continuity function for the TRW(~\u00b5; ~\u03b8,\u03c1) objective over M with respect to the `\u221e norm:\n\u03c9(\u03c3) := \u03c3\u2016\u03b8\u20161+2\u03c3K\u0303 max{\u2212 log(2\u03c3), 1}, (21)\nwhere K\u0303 := 4|V |maxij\u2208E VALiVALj .\nThat is, for ~\u00b5, ~\u00b5\u2032 \u2208M with \u2016~\u00b5\u2032 \u2212 ~\u00b5\u2016\u221e\u2264 \u03c3, we have:\n|TRW(~\u00b5; ~\u03b8,\u03c1)\u2212 TRW(~\u00b5\u2032; ~\u03b8,\u03c1)|\u2264 \u03c9(\u03c3).\nProof. TRW(~\u00b5; ~\u03b8,\u03c1) can be decomposed into functions of the form \u2212Kx log x+ \u03b8x (see (15) and (16)) and so we apply the Lemma E.2 element-wise. Let c index the clique component in the marginal vector.\n|TRW(~\u00b5; ~\u03b8,\u03c1)\u2212 TRW(~\u00b5\u2032; ~\u03b8,\u03c1)| = \u2211 c \u2211 xc |gc,xc(\u00b5c(xc))\u2212 gc,xc(\u00b5 \u2032 c(xc))|\n(Using Lemma E.2 and \u2016~\u00b5\u2032 \u2212 ~\u00b5\u2016\u221e\u2264 \u03c3) \u2264 \u2211 c \u2211 xc (|Kc|2\u03c3max{\u2212 log(2\u03c3), 1}+ |\u03b8(xc)|\u03c3)\n= 2\u03c3max{\u2212 log(2\u03c3), 1} \u2211 c |Kc|nc + \u2016\u03b8\u20161\u03c3,\nwhere we recall nc is the number of values that xc can take. By re-using the bound on \u2211 c|Kc|nc from (18), we get the result."}, {"heading": "E.3 Bounded Negative Uniform Gap", "text": "Lemma E.4 (Bound for the negative uniform gap of TRW objective). For the negative TRW objective f(~\u00b5) := \u2212TRW(~\u00b5; ~\u03b8,\u03c1), the bound B on the negative uniform gap as given in Lemma D.3 for u0 being the uniform distribution can be taken as:\nB = 2 \u2211 c max xc |\u03b8c(xc)|=: 2\u2016~\u03b8\u20161,\u221e (22)\nProof. From Lemma D.3, we want to bound \u2016\u2207f(u0)\u2016\u2217= \u2016~\u03b8 +\u2207~\u00b5H(u0;\u03c1))\u2016\u2217. The clique entropy terms H(\u00b5c) are maximized by the uniform distribution, and thus u0 is a stationary point of the TRW entropy function with zero gradient. We can thus simply take B = \u2016~\u03b8\u2016\u2217diam\u2016\u00b7\u2016(M). By taking the `\u221e/`1 norm on M, we get a diameter of 2, giving the given bound."}, {"heading": "E.4 Summary", "text": "We now give the details of suboptimality guarantees for our suggested algorithm to optimize f(~\u00b5) := \u2212TRW(~\u00b5; ~\u03b8,\u03c1) over M. The (strong) convexity of the negative TRW objective is shown in (Wainwright et al., 2005; London et al., 2015). M is the convex hull of a finite number of vectors representing assignments to random variables and therefore a compact convex set. The entropy function is continously differentiable on the relative interior of the probability simplex, and thus the TRW objective has the same property on the relative interior ofM. Thus \u2212TRW(~\u00b5; ~\u03b8,\u03c1) satisfies the properties laid out in Problem 3.2.\nLemma E.5 (Suboptimality bound for optimizing \u2212TRW(~\u00b5; ~\u03b8,\u03c1) with the fixed-\u03b4 algorithm). For the optimization of \u2212TRW(~\u00b5; ~\u03b8,\u03c1) overM\u03b4 with \u03b4 \u2208 (0, 1], the suboptimality is bounded as:\nTRW(~\u00b5\u2217; ~\u03b8,\u03c1)\u2212 TRW(~\u00b5(k); ~\u03b8,\u03c1) \u2264 2C\u03b4 (k + 2) + \u03c9 (2\u03b4) , (23)\nwith ~\u00b5\u2217 the optimizer of TRW(~\u00b5; ~\u03b8,\u03c1) in M, where C\u03b4 \u2264 16 |V |max(ij)\u2208E VALiVALj\n\u03b4 , and \u03c9(\u03c3) =\n\u03c3\u2016~\u03b8\u20161+2\u03c3K\u0303 max{\u2212 log(2\u03c3), 1}, where K\u0303 := 4|V |maxij\u2208E VALiVALj .\nProof. Using diam\u2016\u00b7\u2016\u221e,1(M) \u2264 2, and L\u03b4 from Lemma E.1, we can compute C\u03b4 \u2264 diam(M) 2L\u03b4 . Lemma E.3 computes the modulus of continuity \u03c9(\u03c3). The rate then follows directly from Theorem C.1.\nLemma E.6 (Global convergence rate for optimizing \u2212TRW(~\u00b5; ~\u03b8,\u03c1) with the adaptive-\u03b4 algorithm). Consider the optimization of \u2212TRW(~\u00b5; ~\u03b8,\u03c1) overM with the optimum given by ~\u00b5\u2217. The iterates ~\u00b5(k) obtained by running the Frank-Wolfe updates overM\u03b4 using line-search with \u03b4 updated according to Algorithm 1 (or as summarized in a FCFW variant in Algorithm 4), have suboptimality hk = TRW(~\u00b5\u2217; ~\u03b8,\u03c1)\u2212 TRW(~\u00b5(k); ~\u03b8,\u03c1) upper bounded as:\n1. hk \u2264 ( 1 2 )k h0 + C\u0303 \u03b40 for k such that hk \u2265 max{B\u03b40, 2C\u0303\u03b40 }, 2. hk \u2264 2C\u0303\u03b40 [ 1 1 4 (k\u2212k0)+1 ] for k such that B\u03b40 \u2264 hk \u2264 2C\u0303\u03b40 , 3. hk \u2264 [ max(C\u0303,B\u03b420)B\n1 4 (k\u2212k1)+1\n] 1 2\n= O(k\u2212 1 2 ) for k such that hk \u2264 B\u03b40,\nwhere\n\u2022 \u03b40 = \u03b4(init) \u2264 14\n\u2022 C\u0303 := 16|V |max(ij)\u2208E(VALiVALj)\n\u2022 B = 16\u2016~\u03b8\u20161,\u221e\n\u2022 h0 is the initial suboptimality\n\u2022 k0 and k1 are the number of steps to reach stage 2 and 3 respectively which are bounded as: k0 \u2264 max(0, dlog 1\n2\nC\u0303 h0\u03b40 e) k0 \u2264 k1 \u2264 k0 + max\n( 0, d 8C\u0303\nB\u03b420 e \u2212 4\n)\nProof. Using diam\u2016\u00b7\u2016\u221e,1(M) \u2264 2, we bound C\u0303 \u2264 Ldiam\u2016\u00b7\u2016\u221e,1(M) 2 with L (from Property 3.3) derived in Lemma E.1. We bound \u22128gu(~\u00b5(k)) (the upper bound on the negative uniform gap) using the value derived in Lemma E.4. The rate then follows directly from Theorem D.6 using p = 1 (see Lemma E.1 where L\u03b4 \u2264 L \u03b4 ).\nThe dominant term in Lemma E.6 is C\u0303B k\u2212 1 2 , with C\u0303B = O(\u2016~\u03b8\u20161,\u221e|V |). We thus find that both bounds depend on norms of ~\u03b8. This is unsurprising since large potentials drive the solution of the marginal inference problem away from the centre ofM, corresponding to regions of high entropy, and towards the boundary of the polytope (lower entropy). Regions of low entropy correspond to smaller components of the marginal vector,\nwhich in turn result in larger and poorly behaved gradients of\u2212TRW(~\u00b5; ~\u03b8,\u03c1), which slows down the resulting optimization."}, {"heading": "F Correction and Local Search Steps in Algorithm 2", "text": "Algorithm 5 details the CORRECTION procedure used in line 16 of Algorithm 2 to implement the correction step of the FCFW algorithm. It uses the modified Frank-Wolfe algorithm (FW with away steps), as detailed in Algorithm 3. Algorithm 6 depicts the LOCALSEARCH procedure used in line 17 of Algorithm 2. The local search is performing FW overM\u03b4 for a fixed \u03b4 using the iterated conditional mode algorithm as an approximate FW oracle. This enables the finding in a cheap of way of more vertices to augment the correction polytope V .\nAlgorithm 5: Re-Optimizing over correction polytope V using MFW, f is the negative TRW objective\n1: CORRECTION(x(0), V, \u03b4,\u03c1) 2: Let f(\u00b7) := -TRW(\u00b7; ~\u03b8,\u03c1); we use MFW to optimize over the contracted correction polytope conv(V\u03b4)\nwhere V\u03b4 := (1\u2212 \u03b4)V + \u03b4u0. 3: Let be the desired accuracy of the approximate correction. 4: Let \u03b1(0) be such that x(0) = \u2211 v\u2208V\u03b4 \u03b1 (0) v v. 5: x(new) \u2190 MFW(x(0),\u03b1(0), V\u03b4, ) (see Algorithm 3) 6: return x(new)\nAlgorithm 6: Local Search using Iterated Conditional Modes, f is the negative TRW objective\n1: LOCALSEARCH(x(0),vinit, \u03b4,\u03c1) 2: s(0) \u2190 vinit 3: V \u2190 \u2205 4: for k = 0 . . .MAXITS do 5: \u03b8\u0303 = \u2207f(x(k); ~\u03b8,\u03c1) 6: s(k+1) \u2190ICM(\u2212\u03b8\u0303, s(k)) (Approximate FW search using ICM; we initialize ICM at previously found vertex s(k)) 7: s(k+1)(\u03b4) \u2190 (1\u2212 \u03b4)s (k+1) + \u03b4u0 8: V \u2190 V \u222a {s(k+1)} 9: d(k)(\u03b4) \u2190 s (k+1) (\u03b4) \u2212 x (k)\n10: Line-search: \u03b3k \u2208 arg min \u03b3\u2208[0,1]\nf ( x(k) + \u03b3d (k)\n(\u03b4) ) 11: Update x(k+1) := x(k) + \u03b3kd (k)\n(\u03b4) (FW update) 12: end for 13: return x(k+1), V"}, {"heading": "G Comparison to perturbAndMAP", "text": "Perturb & MAP. We compared the performance between our method and perturb & MAP for inference on 10 node Synthetic cliques. We expand on the method we used to evaluate perturbAndMAP in Figure 1(e) and 1(f). We re-implemented the algorithm to estimate the partition function in Python (as described in Hazan and Jaakkola (2012), Section 4.1) and used toulbar2 (Allouche et al., 2010) to perform MAP inference over an inflated graph where every variable maps to five new variables. The log partition function is estimated as the mean energy of 10 exact MAP calls on the expanded graph where the single node potentials are perturbed by draws from the Gumbel distribution. To extract marginals, we fix the value of a variable to every assignment, estimate the log partition function of the conditioned graph and compute beliefs based on averaging the results of adding the unary potentials to the conditioned values of the log partition function.\nH Correction Steps for Frank-Wolfe overM Recall that the correction step is done over the correction polytope, the set of all vertices ofM encountered thus far in the algorithm. On experiments conducted overM, we found that using a better correction algorithm often hurt performance. This potentially arises in other constrained optimization problems where the gradients are\nunbounded at the boundaries of the polytope. We found that better correction steps over the correction polytope (the convex hull of the vertices explored by the MAP solver, denoted V in Algorithm 2), often resulted in a solution at or near a boundary of the marginal polytope (shared with the correction polytope). This resulted in the iterates becoming too small. We know that the Hessian of TRW(~\u00b5; ~\u03b8,\u03c1) is ill conditioned near the boundaries of the marginal polytope. Therefore, we hypothesize that this is because the gradient directions obtained when the iterates became too small are simply less informative. Consequently, the optimization over M suffered. We found that the duality gap over M would often increase after a correction step when this phenomenon occurred. The variant of our algorithm based on M\u03b4 is less sensitive to this issue since the restriction of the polytope bounds the smallest marginal and therefore also controls the quality of the gradients obtained."}, {"heading": "I Additional Experiments", "text": "For experiments on the 10 node synthetic cliques, we can also track the average number of ILP calls required to converge to a fixed duality gap for any \u03b8. This is depicted in Figure 5(c). Optimizing over T realized three to four times as many MAP calls as the first iteration of inference.\nFigure 4 depicts additional examples from the Chinese Characters test set. Here, we also visualize results from a wrapper around TRBPs implementation in libDAI (Mooij, 2010) that performs tightening over T. Here too we find few gains over optimizing over L.\nFigure 5(a), 5(b) depicts the comparison of convergence of algorithm variants overM andM\u03b4 (same setup as Figure 1(a), 1(b). Here, we plot \u03b6\u00b5.\nJ Bounding logZ with Approximate MAP Solvers\nSuppose that we use an approximate MAP solver for line 7 of Algorithm 2. We show in this section that if the solver returns an upper bound on the value of the MAP assignment (as do branch-and-cut solvers for integer linear programs), we can use this to get an upper bound on logZ. For notational consistency, we consider using Algorithm 2 for minx\u2208D f(x), where f(x) = \u2212TRW(~\u00b5; ~\u03b8,\u03c1) is convex, x = ~\u00b5, and D =M.\nThe property that the duality gap may be used as a certificate of optimality (Jaggi, 2013) gives us:\nf(x\u2217) \u2265 f(x(k))\u2212 g(x(k)) =\u21d2 \u2212f(x\u2217) \u2264 \u2212f(x(k)) + g(x(k)). (24) Adding the gap onto the TRW objective yields an upper bound on the optimum (which from Equation 1 is an upper bound on logZ), i.e. logZ \u2264 \u2212f(x\u2217). From our definition of the duality gap g(x(k)) (line 8 in Algorithm 2) and (24), we have:\nlogZ \u2264 \u2212f(x\u2217) \u2264 \u2212f(x(k)) + \u2329 \u2212\u2207f(x(k)), s(k) \u2212 x(k) \u232a = \u2212f(x(k)) + \u2329 \u2212\u2207f(x(k)), s(k)\n\u232a \ufe38 \ufe37\ufe37 \ufe38\nMAP call\n\u2212 \u2329 \u2212\u2207f(x(k)),x(k) \u232a \ufe38 \ufe37\ufe37 \ufe38\nCan be computed efficiently\n,\nwhere s(k) = arg minv\u2208D \u2329 \u2207f(x(k)),v \u232a = arg maxv\u2208D \u2329 \u2212\u2207f(x(k)),v \u232a (line 7 in Algorithm 2). Thus,\nif the approximate MAP solver returns an upper bound \u03ba such that maxv\u2208D \u2329 \u2212\u2207f(x(k)),v \u232a \u2264 \u03ba, then we\nget the following upper bound on the log-partition function: logZ \u2264 \u2212f(x(k)) + \u03ba\u2212 \u2329 \u2212\u2207f(x(k)),x(k) \u232a . (25)\nFor example, we could use a linear programming relaxation or a message-passing algorithm based on dual decomposition such as Sontag et al. (2008) to obtain the upper bound \u03ba. There is a subtle but important point to note about this approach. Despite the fact that we may use a relaxation ofM such as L or the cycle relaxation to compute the upper bound, we evaluate it at ~\u00b5(k) that is guaranteed to be withinM. This should be contrasted to instead optimizing over a relaxation such as L directly with Algorithm 2. In the latter setting, the moment we move towards a fractional vertex (in line 14) we would immediately take ~\u00b5(k+1) out ofM. Because of this difference, we expect that this approach will typically result in significantly tighter upper bounds on logZ."}, {"heading": "Supplementary References", "text": "D. P. Bertsekas. Nonlinear programming. Athena Scientific, Belmont, MA, 1999. J. Gue\u0301lat and P. Marcotte. Some comments on Wolfe\u2019s \u2018away step\u2019. Mathematical Programming, 35(1):110\u2013\n119, 1986. Y. Nesterov. Introductory Lectures on Convex Optimization. Kluwer Academic Publishers, Norwell, MA, 2004. C. Teo, A. Smola, S. Vishwanathan, and Q. Le. A scalable modular convex solver for regularized risk mini-\nmization. In KDD, 2007. P. Wolfe. Convergence Theory in Nonlinear Programming. In J. Abadie, editor, Integer and Nonlinear Pro-\ngramming, pages 1\u201323. North-Holland, 1970."}], "references": [{"title": "Nonlinear programming", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas.,? \\Q1999\\E", "shortCiteRegEx": "Bertsekas.", "year": 1999}, {"title": "Some comments on Wolfe\u2019s \u2018away step", "author": ["J. Gu\u00e9lat", "P. Marcotte"], "venue": "Mathematical Programming,", "citeRegEx": "Gu\u00e9lat and Marcotte.,? \\Q1986\\E", "shortCiteRegEx": "Gu\u00e9lat and Marcotte.", "year": 1986}, {"title": "Introductory Lectures on Convex Optimization", "author": ["Y. Nesterov"], "venue": null, "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "A scalable modular convex solver for regularized risk minimization", "author": ["C. Teo", "A. Smola", "S. Vishwanathan", "Q. Le"], "venue": "In KDD,", "citeRegEx": "Teo et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Teo et al\\.", "year": 2007}, {"title": "Convergence Theory in Nonlinear Programming", "author": ["P. Wolfe"], "venue": "Integer and Nonlinear Programming,", "citeRegEx": "Wolfe.,? \\Q1970\\E", "shortCiteRegEx": "Wolfe.", "year": 1970}], "referenceMentions": [{"referenceID": 4, "context": "Instead, Sontag and Jaakkola (2007) use the conditional gradient method (also called Frank-Wolfe) and offthe-shelf linear programming solvers to optimize TRW over the cycle consistency relaxation. Rather than optimizing over the cycle relaxation, Belanger et al. (2013) optimize the TRW objective over the exact marginal polytope.", "startOffset": 91, "endOffset": 270}, {"referenceID": 4, "context": "Instead, Sontag and Jaakkola (2007) use the conditional gradient method (also called Frank-Wolfe) and offthe-shelf linear programming solvers to optimize TRW over the cycle consistency relaxation. Rather than optimizing over the cycle relaxation, Belanger et al. (2013) optimize the TRW objective over the exact marginal polytope. Then, using Frank-Wolfe, the linear minimization performed in the inner loop can be shown to correspond to MAP inference. The Frank-Wolfe optimization algorithm has seen increasing use in machine learning, thanks in part to its efficient handling of complex constraint sets appearing with structured data (Jaggi, 2013; Lacoste-Julien and Jaggi, 2015). However, applying Frank-Wolfe to variational inference presents challenges that were never resolved in previous work. First, the linear minimization performed in the inner loop is computationally expensive, either requiring repeatedly solving a large linear program, as in Sontag and Jaakkola (2007), or performing MAP inference, as in Belanger et al.", "startOffset": 91, "endOffset": 983}, {"referenceID": 4, "context": "Instead, Sontag and Jaakkola (2007) use the conditional gradient method (also called Frank-Wolfe) and offthe-shelf linear programming solvers to optimize TRW over the cycle consistency relaxation. Rather than optimizing over the cycle relaxation, Belanger et al. (2013) optimize the TRW objective over the exact marginal polytope. Then, using Frank-Wolfe, the linear minimization performed in the inner loop can be shown to correspond to MAP inference. The Frank-Wolfe optimization algorithm has seen increasing use in machine learning, thanks in part to its efficient handling of complex constraint sets appearing with structured data (Jaggi, 2013; Lacoste-Julien and Jaggi, 2015). However, applying Frank-Wolfe to variational inference presents challenges that were never resolved in previous work. First, the linear minimization performed in the inner loop is computationally expensive, either requiring repeatedly solving a large linear program, as in Sontag and Jaakkola (2007), or performing MAP inference, as in Belanger et al. (2013). Second, the TRW objective involves entropy terms whose gradients go to infinity near the boundary of the feasible set, therefore existing convergence guarantees for Frank-Wolfe do not apply.", "startOffset": 91, "endOffset": 1042}, {"referenceID": 4, "context": "The primal convergence of the Frank-Wolfe algorithm is given by Thm. 1 in Jaggi (2013), restated here for convenience: for k \u2265 1, the iterates x satisfy: (4) f(x)\u2212 f(x\u2217) \u2264 2Cf k + 2 , where Cf is called the \u201ccurvature constant\u201d.", "startOffset": 36, "endOffset": 87}, {"referenceID": 4, "context": "A viable option to address (1) is through the use of correction steps, where after a Frank-Wolfe step, one optimizes over the polytope defined by previously visited vertices of M (called the fully-corrective Frank-Wolfe (FCFW) algorithm and proven to be linearly convergence for strongly convex objectives (Lacoste-Julien and Jaggi, 2015)). This does not require additional MAP calls. However, we found (see Sec. 5) that when optimizing the TRW objective overM, performing correction steps can surprisingly hurt performance. This leaves us in a dilemma: correction steps enable decreasing the objective without additional MAP calls, but they can also slow global progress since iterates after correction sometimes lie close to the boundary of the polytope (where the FW directions become less informative). In a manner akin to barrier methods and to Garber and Hazan (2013)\u2019s local linear oracle, our proposed solution maintains the iterates within a contraction of the polytope.", "startOffset": 91, "endOffset": 874}, {"referenceID": 0, "context": "The following descent lemma is proved in Bertsekas (1999) (Prop.", "startOffset": 41, "endOffset": 58}, {"referenceID": 4, "context": "To implement the approximate correction steps in the fully corrective Frank-Wolfe (FCFW) algorithm, we use the Frank-Wolfe algorithm with away steps (Wolfe, 1970), also known as the modified Frank-Wolfe (MFW) algorithm (Gu\u00e9lat and Marcotte, 1986).", "startOffset": 149, "endOffset": 162}, {"referenceID": 1, "context": "To implement the approximate correction steps in the fully corrective Frank-Wolfe (FCFW) algorithm, we use the Frank-Wolfe algorithm with away steps (Wolfe, 1970), also known as the modified Frank-Wolfe (MFW) algorithm (Gu\u00e9lat and Marcotte, 1986).", "startOffset": 219, "endOffset": 246}, {"referenceID": 1, "context": "For a strongly convex objective (with Lipschitz continuous gradient), the MFW was known to have asymptotic linear convergence (Gu\u00e9lat and Marcotte, 1986) and its global linear convergence rate was shown recently (Lacoste-Julien and Jaggi, 2015), accelerating the slow general sublinear rate of Frank-Wolfe.", "startOffset": 126, "endOffset": 153}, {"referenceID": 1, "context": "To implement the approximate correction steps in the fully corrective Frank-Wolfe (FCFW) algorithm, we use the Frank-Wolfe algorithm with away steps (Wolfe, 1970), also known as the modified Frank-Wolfe (MFW) algorithm (Gu\u00e9lat and Marcotte, 1986). We give pseudo-code for MFW in Algorithm 3 (taken from (LacosteJulien and Jaggi, 2015)). This variant of Frank-Wolfe adds the possibility to do an \u201caway step\u201d (see step 5 in Algorithm 3) in order to avoid the zig zagging phenomenon that slows down Frank-Wolfe when the solution is close to the boundary of the polytope. For a strongly convex objective (with Lipschitz continuous gradient), the MFW was known to have asymptotic linear convergence (Gu\u00e9lat and Marcotte, 1986) and its global linear convergence rate was shown recently (Lacoste-Julien and Jaggi, 2015), accelerating the slow general sublinear rate of Frank-Wolfe. When performing a correction over the convex hull over a (somewhat small) set of vertices ofD\u03b4 , this convergence difference was quite significant in our experiments (MFW converging in a small number of iterations to do an approximate correction vs. FW taking hundreds of iterations to reach a similar level of accuracy). We note that the TRW objective is strongly convex when all the edge probabilities are nonzero (Wainwright et al., 2005); and that it has Lipschitz gradient over D\u03b4 (but not D). The gap computed in step 6 of Algorithm 3 is non-standard; it is a sufficient condition to ensure the global linear convergence of the outer FCFW algorithm when using Algorithm 3 as a subroutine to implement the approximate correction step. See Lacoste-Julien and Jaggi (2015) for more details.", "startOffset": 220, "endOffset": 1651}, {"referenceID": 4, "context": "As f has a Lipschitz continuous gradient over D\u03b4 , we can use any standard convergence result of the Frank-Wolfe algorithm to bound the suboptimality of the iterate x over D\u03b4 . Algorithm 4 (with a fixed \u03b4) describes the FCFW algorithm which guarantees at least as much progress as the standard FW algorithm (by step 15 and 20a), and thus we can use the convergence result from Jaggi (2013) as already stated in (4): f(x) \u2212 f(x(\u03b4)) \u2264 2C\u03b4 (k+2) with C\u03b4 \u2264 diam(D\u03b4)L\u03b4 , where L\u03b4 comes from Property 3.", "startOffset": 107, "endOffset": 390}, {"referenceID": 3, "context": "This is a generalization of the technique used in Teo et al. (2007) (also used in the context of Frank-Wolfe in the proof of Theorem C.", "startOffset": 50, "endOffset": 68}, {"referenceID": 3, "context": "This is a generalization of the technique used in Teo et al. (2007) (also used in the context of Frank-Wolfe in the proof of Theorem C.4 in Lacoste-Julien et al. (2013)).", "startOffset": 50, "endOffset": 169}, {"referenceID": 2, "context": "2 in Nesterov (2004)).", "startOffset": 5, "endOffset": 21}], "year": 2015, "abstractText": "We introduce a globally-convergent algorithm for optimizing the tree-reweighted (TRW) variational objective over the marginal polytope. The algorithm is based on the conditional gradient method (Frank-Wolfe) and moves pseudomarginals within the marginal polytope through repeated maximum a posteriori (MAP) calls. This modular structure enables us to leverage black-box MAP solvers (both exact and approximate) for variational inference, and obtains more accurate results than tree-reweighted algorithms that optimize over the local consistency relaxation. Theoretically, we bound the sub-optimality for the proposed algorithm despite the TRW objective having unbounded gradients at the boundary of the marginal polytope. Empirically, we demonstrate the increased quality of results found by tightening the relaxation over the marginal polytope as well as the spanning tree polytope on synthetic and real-world instances.", "creator": "LaTeX with hyperref package"}}}