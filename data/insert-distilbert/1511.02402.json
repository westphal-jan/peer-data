{"id": "1511.02402", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2015", "title": "Max-Sum Diversification, Monotone Submodular Functions and Semi-metric Spaces", "abstract": "in many applications devices such as web - based search, document summarization, facility location and other applications, the results are considerably preferable to be both representative and diversified subsets of documents. the goal of this functional study is to select a good \" comparative quality \", bounded - size subset of a given set c of items, generated while maintaining reduces their diversity along relative domain to a semi - metric distance function. this problem typically was first studied by borodin et h al \\ cite { max borodin }, but a crucial property used throughout their proof procedure is the triangle inequality. in this modified proof, we want to relax the triangle inequality and we relate the approximation ratio of max - sum diversification problem to the parameter of the relaxed triangle inequality in the normal form of the problem ( ( i. e., a uniform matroid ) solution and also in an arbitrary matroid.", "histories": [["v1", "Sat, 7 Nov 2015 20:56:51 GMT  (17kb)", "http://arxiv.org/abs/1511.02402v1", "This article draws heavily fromarXiv:1203.6397by other authors"]], "COMMENTS": "This article draws heavily fromarXiv:1203.6397by other authors", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["sepehr abbasi zadeh", "mehrdad ghadiri"], "accepted": false, "id": "1511.02402"}, "pdf": {"name": "1511.02402.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mehrdad Ghadiri", "M. Ghadiri"], "emails": ["ghadiri}@ce.sharif.edu"], "sections": [{"heading": null, "text": "ar X\niv :1\n51 1.\n02 40\n2v 1\n[ cs\n.L G\n] 7\nN ov\n2 01\n5"}, {"heading": "Introduction", "text": "In many search applications, the search engine should guess the correct results from a given query; therefore, it is important to deliver a diversified and representative set of documents to a user. Diversification can be viewed as a trade-off between having more relevant results and having more diverse results among the top results for a given query [3]. \u201cJaguar\u201d is a cliche example in the diversification literature [2, 4, 9], but it illustrates the point perfectly as it has different meanings including car, animal, and a football team. A set of good \u201cquality\u201d result should cover all these diversified items. The paper by Borodin et al [1] determines the good quality results with a monotone submodular function and defines diversity as the sum of distances between selected objects. Since they consider the distances to be metric, they ask in the conclusion section:\nFor a relaxed version of the triangle inequality can we relate the approximation ratio to the parameter of a relaxed triangle inequality?\nIn this study we answer to this question. We call this relaxed triangle inequality distance as semi-metric. A semi-metric distance on a set of items is just like a metric distance, but the triangle inequality is relaxed with a parameter \u03b1 \u2265 1 (i.e., d(u, v) \u2264 \u03b1(d(v, w)+d(w, u))). Answering to this question will make this method applicable to algorithms that are defined on semi-metric spaces, e.g., [5, 7, 8]. The IBM\u2019s Query by Image Content system is one of the other best-known examples of the semi-metric usage in practice; although, it does not\nsatisfy the triangle inequality [6]. By modifying the analysis of the previous proposed algorithms in [1], we will show that these algorithms can still achieve a 2\u03b1-approximation for this question in the case that there is not any matroid constraint and a 2\u03b12-approximation for an arbitrary matroid constraint. In other words, these new modified analysis are a generalization of the previous analysis as they are consistent with the previous approximation ratios for \u03b1 = 1 (i.e., the metric distance).\nProblem 1. Max-Sum Diversification\nLet U be the underlying ground set, and let d(., .) be a semi-metric distance function on U . The goal of the problem is to find a subset S \u2286 U that:\nmaximizes f(S) + \u03bb \u2211\n{u,v}:u,v\u2208S d(u, v)\nsubject to |S| = p,\nwhere p is a given constant number and \u03bb is a parameter specifying a trade-off between the distance and submodular function. We give a 2\u03b1\u2212approximation for this problem.\nFirstly we introduce our notations following [1]. For any S \u2286 U , we let d(S) = \u2211 {u,v}:u,v\u2208S d(u, v). We can also define d(S, T ), for any two disjoint sets S and T as: d(S \u222a T )\u2212 d(S)\u2212 d(T ).\nLet \u03c6(S) and u be the value of the objective function and an element in U \u2212 S respectively. We can define the marginal gain of the distance function as\ndu(S) = \u2211 v\u2208S d(u, v)\nand similarly marginal gain of the wight function as:\nfu(S) = f(S + u)\u2212 f(S).\nThe total marginal gain can also be defined using du(S) and fu(S) as\n\u03c6u(S) = fu(S) + \u03bbdu(S).\nLet\nf \u2032u(S) = 1\n2 fu(S),\n\u03c6\u2032u(S) = f \u2032 u(S) + \u03bbdu(S).\nStarting with an empty set S, the greedy algorithm (Algorithm 1) adds an element u from U \u2212 S in each iteration, in such a way that maximize \u03c6\u2032u(S).\nLemma 1. Given an \u03b1-relaxed triangle inequality semi-metric distance function d(., .), and two disjoint sets X and Y , we have the following inequality:\n\u03b1(|X | \u2212 1)d(X,Y ) \u2265 |Y |d(X)\nAlgorithm 1 Greedy algorithm\n1: Input 2: U : set of ground elements 3: p: size of final set 4: Output 5: S: set of selected elements with size p 6: S = \u2205 7: while |S| < p do 8: find u \u2208 U \\ S maximizing \u03c6\u2032\nu (S)\n9: S = S \u222a {u} 10: end while 11: return S\nProof. Consider u, v \u2208 X and an arbitrary w \u2208 Y . We know that:\n\u03b1(d(v, w) + d(w, u)) \u2265 d(u, v)\nBy changing w we get:\n\u03b1(d({v}, Y ) + d({u}, Y )) \u2265 |Y |d(u, v)\nand then all combinations of u and v:\n\u03b1(|X | \u2212 1)d(X,Y ) \u2265 |Y |d(X)\nTheorem 1. Algorithm 1 achieves a 2\u03b1-approximation for solving Problem 1 with \u03b1-relaxed distance d(., .) and monotone submodular function f .\nProof. Let Gi be the greedy solution at the end of step i, i < p and G be the greedy solution at the end of the algorithm. Suppose that O is the optimal solution and let A = O \u2229 Gi, B = Gi \\ A and C = O \\ A. Obviously the algorithm achieves the optimal solution when p = 1; thus we assume p > 1. Now we consider two different cases: |C| = 1 and |C| > 1. If |C| = 1 then i = p\u2212 1. Let C = {v} and u be the element that algorithm will take for the next (last) step. Then for all v \u2208 U \\ S we have:\n\u03c6\u2032u(Gi) \u2265 \u03c6 \u2032 v(Gi)\nf \u2032u(Gi) + \u03bbdu(Gi) \u2265 f \u2032 v(Gi) + \u03bbdv(Gi)\nthus:\n\u03c6u(Gi) = fu(Gi) + \u03bbdu(Gi)\n\u2265 f \u2032u(Gi) + \u03bbdu(Gi) \u2265 f \u2032v(Gi) + \u03bbdv(Gi) \u2265 1\n2 \u03c6v(Gi)\nas a result \u03c6(G) \u2265 12\u03c6(O) \u2265 1 2\u03b1\u03c6(O). Now consider |C| > 1. By using Lemma 1 we have the following inequalities:\n\u03b1(|C| \u2212 1)d(B,C) \u2265 |B|d(C) (1)\n\u03b1(|C| \u2212 1)d(A,C) \u2265 |A|d(C) (2)\n\u03b1(|A| \u2212 1)d(A,C) \u2265 |C|d(A) (3)\nA and C are two disjoint sets and we know that A \u222a C = O; thus:\nd(A,C) + d(A) + d(C) = d(O) (4)\nWe can assume that p > 1 and |C| > 1 (The greedy algorithm obviously finds the optimal solution when p = 1). Then following multipliers are applied to equations 1, 2, 3, 4 respectively:\n1 (|C|\u22121) , |C|\u2212|B| p(|C|\u22121) , i p(p\u22121) , i|C| \u03b1p(p\u22121) .\nIf we add them, we have:\nd(B,C) + d(A,C)\u2212 d(A,C) i|C|(1 \u2212 1 \u03b1 )\np(p\u2212 1) \u2212 d(C)\ni|C|(p\u2212 |C|)\n\u03b1p(p\u2212 1)(|C| \u2212 1) \u2265 d(O)\ni|C|\n\u03b1p(p \u2212 1)\nSince p > |C| and \u03b1 \u2265 1,\nd(A,C) + d(B,C) \u2265 d(O) i|C|\n\u03b1p(p \u2212 1) .\nthus (we substituted 1 \u03b1 with x, thus 0 < x \u2264 1),\nd(C,Gi) \u2265 d(O) xi|C|\np(p \u2212 1)\nFrom the submodularity of f \u2032(.) we can get\n\u2211\nv\u2208C\nf \u2032v(Gi) \u2265 f \u2032(C \u222aGi)\u2212 f \u2032(Gi)\nalso the monotonity of f \u2032(.) suggests that\nf \u2032(C \u222aGi)\u2212 f \u2032(Gi) \u2265 f \u2032(O) \u2212 f \u2032(G).\nSubsequently we have:\n\u2211\nv\u2208C\nf \u2032v(Gi) \u2265 f \u2032(O)\u2212 f \u2032(G).\nTherefore \u2211\nv\u2208C\n\u03c6\u2032v(Gi) = \u2211\nv\u2208C\n[f \u2032v(Gi) + \u03bbd({v}, Gi)]\n= \u2211\nv\u2208C\nf \u2032v(Gi) + \u03bbd(C,Gi)\n\u2265 [f \u2032(O) \u2212 f \u2032(G)] + d(O) \u03bbxi|C|\np(p \u2212 1) .\nLet ui+1 be the element taken at step (i+ 1), then we have\n\u03c6\u2032ui+1(Gi) \u2265 1\np [f \u2032(O)\u2212 f \u2032(G)] + d(O)\n\u03bbxi\np(p\u2212 1) .\nIf we sum over all i from 0 to p\u2212 1, we have\n\u03c6\u2032(G) =\np\u22121\u2211\ni=0\n\u03c6\u2032ui+1(Gi) \u2265 [f \u2032(O)\u2212 f \u2032(G)] + d(O)\n\u03bbx\n2\nHence,\nf \u2032(G) + \u03bbd(G) \u2265 f \u2032(O) \u2212 f \u2032(G) + d(O) \u03bbx\n2\nand\n\u03c6(G) = f(G) + \u03bbd(G) \u2265 1\n2 [f(O) + x\u03bbd(O)]\n\u2265 x\n2 [f(O) + \u03bbd(O)]\n= 1\n2\u03b1 \u03c6(O).\n\u2293\u2294\nProblem 2. Max-Sum Diversification for Matroids\nLet U be the underlying ground set, and F be the set of independent subsets of U such that M =< U,F > is a matroid. Let d(., .) be a semi-metric distance function on U and f(.) be a non-negative monotone submodular set function measuring the weight of the subsets of U . This problem aims to find a subset S \u2286 F that:\nmaximizes f(S) + \u03bb \u2211\n{u,v}:u,v\u2208S d(u, v)\nwhere \u03bb is a parameter specifying a trade-off between the two objectives. Again, \u03c6(S) is the value of the objective function. Because of the monotonicity of the \u03c6(.), S should be a basis of the matroid M. We give a 2\u03b1\u2212approximation for this problem.\nWithout loss of generality, we assume that the rank of the matroid is greater than one. Let\n{x, y} = argmax x,y\u2208F [f({x, y}) + \u03bbd(x, y)].\nWe now consider the following local search algorithm:\nAlgorithm 2 Local Search algorithm\n1: Input 2: U : set of ground elements 3: M =< U ,F >: a matroid on U 4: S: a basis of M containing both x and y 5: Output 6: S 7: while \u2203{u \u2208 (U \u2212 S) \u2227 v \u2208 S} such that S + u\u2212 v \u2208 F \u2227 \u03c6(S + u\u2212 v) > \u03c6(S) do 8: S = S + u\u2212 v 9: end while 10: return S\nTheorem 2. Algorithm 2 achieves an approximation ratio of 2\u03b12 for max-sum diversification with a matroid constraint.\nAs the algorithm is optimal for the case that the rank of the matroid is two, we assume that the rank of the matroid is greater than two. The notation is like before and O and S are the optimal solution and the solution at the end of the local search algorithm, respectively. Let A = O \u2229S, B = S\u2212A and C = O\u2212A. We utilize the following two lemmas from the [1].\nLemma 2. For any two sets X,Y \u2208 F with |X | = |Y |, there is a bijective mapping g : X \u2192 Y such that X \u2212 x+ g(x) \u2208 F for any x \u2208 X.\nSince both S and O are bases of the matroid, they have the same cardinality; subsequently, B and C have the same cardinality, too. Let g : B \u2192 C be the bijective mapping results from Lemma 2 such that S \u2212 b + g(b) \u2208 F for any b \u2208 B. Let B = {b1, b2, ..., bt}, and let ci = g(bi) for all i. As claimed before, since the algorithm is optimal for t = 1, we assume t \u2265 2. Lemma 3. \u2211t\ni=1 f(S \u2212 bi + ci) \u2265 (t\u2212 2)f(S) + f(O).\nNow we are going to prove two lemmas regarding to our semi-metric distance function. Lemma 4. If t > 2, \u03b1(d(B,C) \u2212 \u2211t\ni=1 d(bi, ci)) \u2265 d(C).\nProof. For any bi, cj , ck, we have\n\u03b1(d(bi, cj) + d(bi, ck)) \u2265 d(cj , ck).\nSumming up these inequalities over all i, j, k with i 6= j, i 6= k, j 6= k, we have each d(bi, cj) with i 6= j is counted (t\u2212 2) times; and each d(ci, cj) with i 6= j is counted (t\u2212 2) times. Therefore\n\u03b1(t\u2212 2)[d(B,C) \u2212 t\u2211\ni=1\nd(bi, ci)] \u2265 (t\u2212 2)d(C),\nand the lemma follows.\nLemma 5. \u2211t\ni=1 d(S \u2212 bi + ci) \u2265 (t\u2212 2)d(S) + 1 \u03b1 d(O).\nProof.\nt\u2211\ni=1\nd(S \u2212 bi + ci)\n=\nt\u2211\ni=1\n[d(S) + d(ci, S \u2212 bi)\u2212 d(bi, S \u2212 bi)]\n= td(S) + t\u2211\ni=1\nd(ci, S \u2212 bi)\u2212 t\u2211\ni=1\nd(bi, S \u2212 bi)\n= td(S) +\nt\u2211\ni=1\nd(ci, S)\u2212 t\u2211\ni=1\nd(ci, bi)\u2212 t\u2211\ni=1\nd(bi, S \u2212 bi)\n= td(S) + d(C, S) \u2212 t\u2211\ni=1\nd(ci, bi)\u2212 d(A,B)\u2212 2d(B).\nThere are two cases. If t > 2 then by Lemma 4 we have\nd(C, S)\u2212 t\u2211\ni=1\nd(ci, bi)\n= d(A,C) + d(B,C) \u2212 t\u2211\ni=1\nd(ci, bi)\n\u2265 d(A,C) + 1\n\u03b1 d(C).\nWe know that\nd(S) = d(A) + d(B) + d(A,B)\nthus we have\n2d(S)\u2212 d(A,B) \u2212 2d(B) \u2265 d(A).\nTherefore\nt\u2211\ni=1\nd(S \u2212 bi + ci)\n= td(S) + d(C, S)\u2212 t\u2211\ni=1\nd(ci, bi)\u2212 d(A,B)\u2212 2d(B)\n\u2265 (t\u2212 2)d(S) + d(A,C) + 1\n\u03b1 d(C) + d(A)\n\u2265 (t\u2212 2)d(S) + 1\n\u03b1 d(O)\nif t = 2, then since the rank of the matroid is greater than two, A 6= \u2205. Let z be an element in A, then we have\n2d(S) + d(C, S)\u2212 t\u2211\ni=1\nd(ci, bi)\u2212 d(A,B) \u2212 2d(B)\n= d(A,C) + d(B,C)\u2212 t\u2211\ni=1\nd(ci, bi) + 2d(A) + d(A,B)\n\u2265 d(A,C) + d(c1, b2) + d(c2, b1) + d(A) + d(z, b1) + d(z, b2)\n\u2265 d(A,C) + d(A) + 1\n\u03b1 d(c1, z) +\n1 \u03b1 d(c2, z)\n\u2265 d(A,C) + d(A) + 1\n\u03b12 d(c1, c2)\n\u2265 1\n\u03b12 (d(A,C) + d(A) + d(C))\n\u2265 1\n\u03b12 d(O)\nTherefore\nt\u2211\ni=1\nd(S \u2212 bi + ci)\n= td(S) + d(C, S) \u2212 t\u2211\ni=1\nd(ci, bi)\u2212 d(A,B) \u2212 2d(B)\n\u2265 (t\u2212 2)d(S) + 1\n\u03b12 d(O).\nThis completes the proof.\nNow we can complete the proof of Theorem 2.\nProof. Since S is a locally optimal solution, we have \u03c6(S) \u2265 \u03c6(S \u2212 bi + ci) for all i. Therefore for all i we have\nf(S) + \u03bbd(S) \u2265 f(S \u2212 bi + ci) + \u03bbd(S \u2212 bi + ci)\nSumming up over all i, we have\ntf(S) + \u03bbtd(S) \u2265 t\u2211\ni=1\nf(S \u2212 bi + ci) + \u03bb t\u2211\ni=1\nd(S \u2212 bi + ci)\nBy Lemma 3 we know\ntf(S) + \u03bbtd(S) \u2265 (t\u2212 2)f(S) + f(O) + \u03bb t\u2211\ni=1\nd(S \u2212 bi + ci)\nThen by Lemma 5 we have\ntf(S) + \u03bbtd(S) \u2265 (t\u2212 2)f(S) + f(O) + \u03bb(t\u2212 2)d(S) + \u03bb\n\u03b12 d(O)\nTherefore,\n2f(S) + 2\u03bbd(S) \u2265 f(O) + \u03bb\n\u03b12 d(O)\nSince \u03b1 \u2265 1,\n2f(S) + 2\u03bbd(S) \u2265 f(O) + \u03bb\n\u03b12 d(O) \u2265\n1\n\u03b12 \u03c6(O)\n\u03c6(S) \u2265 1\n2\u03b12 \u03c6(O).\n\u2293\u2294"}, {"heading": "Conclusion", "text": "In this study we answer a proposed question in [1] about the existence of a bound on max-sum diversification problem with semi-metric distances and give a 2\u03b1-approximation for this question in the case that there is not any matroid constraint and a 2\u03b12-approximation for an arbitrary matroid constraint. One interesting question that may be posed is whether it is possible to prove similar results for a non-monotone submodular function?"}], "references": [{"title": "Max-sum diversification, monotone submodular functions and dynamic updates", "author": ["A. Borodin", "H.C. Lee", "Y. Ye"], "venue": "In Proceedings of the 31st symposium on Principles of Database Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Web search using automatic classification", "author": ["C. Chekuri", "M.H. Goldwasser", "P. Raghavan", "E. Upfal"], "venue": "In Proceedings of the Sixth International Conference on the World Wide Web,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Less is more: probabilistic models for retrieving fewer relevant documents", "author": ["H. Chen", "D.R. Karger"], "venue": "In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Novelty and diversity in information retrieval evaluation", "author": ["C.L. Clarke", "M. Kolla", "G.V. Cormack", "O. Vechtomova", "A. Ashkan", "S. B\u00fcttcher", "I. MacKinnon"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Comparing top k lists", "author": ["R. Fagin", "R. Kumar", "D. Sivakumar"], "venue": "SIAM Journal on Discrete Mathematics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Relaxing the triangle inequality in pattern matching", "author": ["R. Fagin", "L. Stockmeyer"], "venue": "International Journal of Computer Vision,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Streaming-data algorithms for high-quality clustering", "author": ["L. O\u2019callaghan", "A. Meyerson", "R. Motwani", "N. Mishra", "S. Guha"], "venue": "In icde,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2002}, {"title": "Shape matching: Similarity measures and algorithms", "author": ["R.C. Veltkamp"], "venue": "In Shape Modeling and Applications, SMI 2001 International Conference on.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Learn from web search logs to organize search results", "author": ["X. Wang", "C. Zhai"], "venue": "In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "This problem was first studied by Borodin et al [1], but a crucial property used throughout their proof is the triangle inequality.", "startOffset": 48, "endOffset": 51}, {"referenceID": 2, "context": "Diversification can be viewed as a trade-off between having more relevant results and having more diverse results among the top results for a given query [3].", "startOffset": 154, "endOffset": 157}, {"referenceID": 1, "context": "\u201cJaguar\u201d is a cliche example in the diversification literature [2, 4, 9], but it illustrates the point perfectly as it has different meanings including car, animal, and a football team.", "startOffset": 63, "endOffset": 72}, {"referenceID": 3, "context": "\u201cJaguar\u201d is a cliche example in the diversification literature [2, 4, 9], but it illustrates the point perfectly as it has different meanings including car, animal, and a football team.", "startOffset": 63, "endOffset": 72}, {"referenceID": 8, "context": "\u201cJaguar\u201d is a cliche example in the diversification literature [2, 4, 9], but it illustrates the point perfectly as it has different meanings including car, animal, and a football team.", "startOffset": 63, "endOffset": 72}, {"referenceID": 0, "context": "The paper by Borodin et al [1] determines the good quality results with a monotone submodular function and defines diversity as the sum of distances between selected objects.", "startOffset": 27, "endOffset": 30}, {"referenceID": 4, "context": ", [5, 7, 8].", "startOffset": 2, "endOffset": 11}, {"referenceID": 6, "context": ", [5, 7, 8].", "startOffset": 2, "endOffset": 11}, {"referenceID": 7, "context": ", [5, 7, 8].", "startOffset": 2, "endOffset": 11}, {"referenceID": 5, "context": "satisfy the triangle inequality [6].", "startOffset": 32, "endOffset": 35}, {"referenceID": 0, "context": "By modifying the analysis of the previous proposed algorithms in [1], we will show that these algorithms can still achieve a 2\u03b1-approximation for this question in the case that there is not any matroid constraint and a 2\u03b1-approximation for an arbitrary matroid constraint.", "startOffset": 65, "endOffset": 68}, {"referenceID": 0, "context": "Firstly we introduce our notations following [1].", "startOffset": 45, "endOffset": 48}, {"referenceID": 0, "context": "We utilize the following two lemmas from the [1].", "startOffset": 45, "endOffset": 48}], "year": 2015, "abstractText": "In many applications such as web-based search, document summarization, facility location and other applications, the results are preferable to be both representative and diversified subsets of documents. The goal of this study is to select a good \u201cquality\u201d, bounded-size subset of a given set of items, while maintaining their diversity relative to a semimetric distance function. This problem was first studied by Borodin et al [1], but a crucial property used throughout their proof is the triangle inequality. In this modified proof we want to relax the triangle inequality and relate the approximation ratio of max-sum diversification problem to the parameter of the relaxed triangle inequality in the normal form of the problem (i.e., a uniform matroid) and also in an arbitrary matroid. Introduction In many search applications, the search engine should guess the correct results from a given query; therefore, it is important to deliver a diversified and representative set of documents to a user. Diversification can be viewed as a trade-off between having more relevant results and having more diverse results among the top results for a given query [3]. \u201cJaguar\u201d is a cliche example in the diversification literature [2, 4, 9], but it illustrates the point perfectly as it has different meanings including car, animal, and a football team. A set of good \u201cquality\u201d result should cover all these diversified items. The paper by Borodin et al [1] determines the good quality results with a monotone submodular function and defines diversity as the sum of distances between selected objects. Since they consider the distances to be metric, they ask in the conclusion section: For a relaxed version of the triangle inequality can we relate the approximation ratio to the parameter of a relaxed triangle inequality? In this study we answer to this question. We call this relaxed triangle inequality distance as semi-metric. A semi-metric distance on a set of items is just like a metric distance, but the triangle inequality is relaxed with a parameter \u03b1 \u2265 1 (i.e., d(u, v) \u2264 \u03b1(d(v, w)+d(w, u))). Answering to this question will make this method applicable to algorithms that are defined on semi-metric spaces, e.g., [5, 7, 8]. The IBM\u2019s Query by Image Content system is one of the other best-known examples of the semi-metric usage in practice; although, it does not 2 S. Abbasi Zadeh and M. Ghadiri satisfy the triangle inequality [6]. By modifying the analysis of the previous proposed algorithms in [1], we will show that these algorithms can still achieve a 2\u03b1-approximation for this question in the case that there is not any matroid constraint and a 2\u03b1-approximation for an arbitrary matroid constraint. In other words, these new modified analysis are a generalization of the previous analysis as they are consistent with the previous approximation ratios for \u03b1 = 1 (i.e., the metric distance). Problem 1. Max-Sum Diversification Let U be the underlying ground set, and let d(., .) be a semi-metric distance function on U . The goal of the problem is to find a subset S \u2286 U that: maximizes f(S) + \u03bb \u2211 {u,v}:u,v\u2208S d(u, v) subject to |S| = p, where p is a given constant number and \u03bb is a parameter specifying a trade-off between the distance and submodular function. We give a 2\u03b1\u2212approximation for this problem. Firstly we introduce our notations following [1]. For any S \u2286 U , we let d(S) = \u2211 {u,v}:u,v\u2208S d(u, v). We can also define d(S, T ), for any two disjoint sets S and T as: d(S \u222a T )\u2212 d(S)\u2212 d(T ). Let \u03c6(S) and u be the value of the objective function and an element in U \u2212 S respectively. We can define the marginal gain of the distance function as du(S) = \u2211 v\u2208S d(u, v) and similarly marginal gain of the wight function as: fu(S) = f(S + u)\u2212 f(S). The total marginal gain can also be defined using du(S) and fu(S) as \u03c6u(S) = fu(S) + \u03bbdu(S). Let f \u2032 u(S) = 1 2 fu(S), \u03c6u(S) = f \u2032 u(S) + \u03bbdu(S). Starting with an empty set S, the greedy algorithm (Algorithm 1) adds an element u from U \u2212 S in each iteration, in such a way that maximize \u03c6u(S). Lemma 1. Given an \u03b1-relaxed triangle inequality semi-metric distance function d(., .), and two disjoint sets X and Y , we have the following inequality: \u03b1(|X | \u2212 1)d(X,Y ) \u2265 |Y |d(X) Max-Sum Diversification and Semi-metric Spaces 3 Algorithm 1 Greedy algorithm 1: Input 2: U : set of ground elements 3: p: size of final set 4: Output 5: S: set of selected elements with size p 6: S = \u2205 7: while |S| < p do 8: find u \u2208 U \\ S maximizing \u03c6\u2032 u (S) 9: S = S \u222a {u} 10: end while 11: return S Proof. Consider u, v \u2208 X and an arbitrary w \u2208 Y . We know that: \u03b1(d(v, w) + d(w, u)) \u2265 d(u, v) By changing w we get: \u03b1(d({v}, Y ) + d({u}, Y )) \u2265 |Y |d(u, v) and then all combinations of u and v: \u03b1(|X | \u2212 1)d(X,Y ) \u2265 |Y |d(X) Theorem 1. Algorithm 1 achieves a 2\u03b1-approximation for solving Problem 1 with \u03b1-relaxed distance d(., .) and monotone submodular function f . Proof. Let Gi be the greedy solution at the end of step i, i < p and G be the greedy solution at the end of the algorithm. Suppose that O is the optimal solution and let A = O \u2229 Gi, B = Gi \\ A and C = O \\ A. Obviously the algorithm achieves the optimal solution when p = 1; thus we assume p > 1. Now we consider two different cases: |C| = 1 and |C| > 1. If |C| = 1 then i = p\u2212 1. Let C = {v} and u be the element that algorithm will take for the next (last) step. Then for all v \u2208 U \\ S we have: \u03c6u(Gi) \u2265 \u03c6 \u2032 v(Gi) f \u2032 u(Gi) + \u03bbdu(Gi) \u2265 f \u2032 v(Gi) + \u03bbdv(Gi) thus: \u03c6u(Gi) = fu(Gi) + \u03bbdu(Gi) \u2265 f \u2032 u(Gi) + \u03bbdu(Gi) \u2265 f \u2032 v(Gi) + \u03bbdv(Gi) \u2265 1 2 \u03c6v(Gi) 4 S. Abbasi Zadeh and M. Ghadiri as a result \u03c6(G) \u2265 12\u03c6(O) \u2265 1 2\u03b1\u03c6(O). Now consider |C| > 1. By using Lemma 1 we have the following inequalities: \u03b1(|C| \u2212 1)d(B,C) \u2265 |B|d(C) (1) \u03b1(|C| \u2212 1)d(A,C) \u2265 |A|d(C) (2) \u03b1(|A| \u2212 1)d(A,C) \u2265 |C|d(A) (3) A and C are two disjoint sets and we know that A \u222a C = O; thus: d(A,C) + d(A) + d(C) = d(O) (4) We can assume that p > 1 and |C| > 1 (The greedy algorithm obviously finds the optimal solution when p = 1). Then following multipliers are applied to equations 1, 2, 3, 4 respectively: 1 (|C|\u22121) , |C|\u2212|B| p(|C|\u22121) , i p(p\u22121) , i|C| \u03b1p(p\u22121) . If we add them, we have: d(B,C) + d(A,C)\u2212 d(A,C) i|C|(1 \u2212 1 \u03b1 ) p(p\u2212 1) \u2212 d(C) i|C|(p\u2212 |C|) \u03b1p(p\u2212 1)(|C| \u2212 1) \u2265 d(O) i|C| \u03b1p(p \u2212 1) Since p > |C| and \u03b1 \u2265 1, d(A,C) + d(B,C) \u2265 d(O) i|C| \u03b1p(p \u2212 1) . thus (we substituted 1 \u03b1 with x, thus 0 < x \u2264 1), d(C,Gi) \u2265 d(O) xi|C| p(p \u2212 1) From the submodularity of f (.) we can get \u2211 v\u2208C f \u2032 v(Gi) \u2265 f (C \u222aGi)\u2212 f (Gi) also the monotonity of f (.) suggests that f (C \u222aGi)\u2212 f (Gi) \u2265 f (O) \u2212 f (G). Subsequently we have: \u2211 v\u2208C f \u2032 v(Gi) \u2265 f (O)\u2212 f (G). Max-Sum Diversification and Semi-metric Spaces 5", "creator": "LaTeX with hyperref package"}}}