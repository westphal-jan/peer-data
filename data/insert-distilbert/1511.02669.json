{"id": "1511.02669", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2015", "title": "Enacting textual entailment and ontologies for automated essay grading in chemical domain", "abstract": "we propose a system for automated essay grading using ontologies theory and semantic textual review entailment. primarily the process of textual entailment is guided by hypotheses, which they are extracted from a domain ontology. textual entailment checks if the truth of the hypothesis follows from a given given text. we automatically enact textual entailment to compare students answer to a model answer only obtained from ontology. we validated the solution against various essays written specifically by students in the chemistry domain.", "histories": [["v1", "Mon, 9 Nov 2015 13:21:02 GMT  (117kb,D)", "http://arxiv.org/abs/1511.02669v1", "16th Int. Symposium on Computational Intelligence and Informatics (CINTI2015), Budapest, Hungary, 19-21 November, 2015"]], "COMMENTS": "16th Int. Symposium on Computational Intelligence and Informatics (CINTI2015), Budapest, Hungary, 19-21 November, 2015", "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["adrian groza", "roxana szabo"], "accepted": false, "id": "1511.02669"}, "pdf": {"name": "1511.02669.pdf", "metadata": {"source": "CRF", "title": "Enacting textual entailment and ontologies for automated essay grading in chemical domain", "authors": ["Adrian Groza", "Roxana Szabo"], "emails": ["Adrian.Groza@cs.utcluj.ro,", "Roxana.Szabo@cs-gw.utcluj.ro"], "sections": [{"heading": null, "text": "Index Terms\u2014automated essay grading, natural language processing, textual entailment, ontologies\nI. INTRODUCTION\nAssessment is an essential part of the learning process, especially in formative learning settings. In the current context of massive open online courses (MOOC), assessment is challenging as it aims to ensure consistency, reliability and do not favor one person against another. In formative assessment the problem of workload and timely results is even greater, as the task is carried out more frequently while the interpretation of one human marker differs from another.\nWhile essay questions are advantageous to student learning and assessment there are obvious disadvantages for the instructor. Grading of essay and discussion questions is time consuming even with the help of teaching assistants. Automated essay grading [21] aims at automatically assigning a grade to a students essay by means of various features. Since the argument structure is crucial for evaluating essay quality, persuasive essays are extensively studied [22]. By automatically identifying arguments, the evaluator is be able to inspect the essay\u2019s plausibility. We argue that information technology is able to assist and support teachers in these challenges.\nOur research hyphotesis relies on the correlation between textual entailment [1] and answer correctness. In a typical answer assessment scenario, we expect a correct answer to entail the reference answer. However a student may wish to skip the details already mentioned in the question. Hence, the problem is whether the answer, along with the question, entail the reference answer.\nLet the question be a, student answer be s and the reference answer be r. Correctness means a \u2227 s\u21d2 r and contradiction means s \u2227 a \u21d2 \u00acr. We propose the usage of recognizing textual entailment (RTE) along with shallow text features to train on the system dataset and testing it on the test dataset\nprovided. The evaluation metrics used will be according to the Coh-Metrix system [10]. The final grade will be obtained from the first grade computed from the comparison between the students answer and the hypotheses generated from the model ontology, and the second grade that will be obtained from evaluation of the metrics.\nThe rest of the paper is organized as follows: Section II presents the system architecture and the NLP tools enacted. Section III details a running scenario on students essays in the chemical domain. Section IV discusses related work, while section V concludes the paper."}, {"heading": "II. SYSTEM ARCHITECTURE", "text": "The proposed ontology-based essay grading system (OntoEG1) consists of a set of integrated natural language tools (see Fig. 1). The system is structured on layers. The first layer contains the Text2Onto tool [3], used to obtain a consistent ontology from a corpus of high ranked or relevant essays in a given domain. The second layer exploits the OWLNatural service [9], to generate natural text from a selected ontology. We organise the text generated by OWLNatural as a set of hypotheses.\nIn the second layer, textual entailment is used to analyse the domain hypotheses on the available essays. The EOP system [14] is trained using a set of pairs \u3008Text,Hyphotesis\u3009. For experiments, we created a data set in the chemical domain containing 100 pairs of text/hypothesis divided into 50\u201d%\u201d of entailment pairs and 50\u201d%\u201d of non-entailment pairs. The text is represented by the student\u2019s essay to be reviewed. The hypotheses are generated from a domain ontology and filtered by the teacher. Based on the model generated after training, the EOP system computes the confidence of hypotheses entailment within the text. This confidence constitutes the basis for grading the essay.\nAutomatic grading includes also various readability metrics. For this step, we use GATE tool for natural language processing [4], to get the number of tokens or number of sentences from text. We integrate Coh-Metrix service [11] to compute various cohesion and coherence metrics for written texts.\nThe system components and the main workflow appear in Fig. 1. The following four components are detailed: (1)\n1The tool is available at http://cs-gw.utcluj.ro/\u223cadrian/tools/ontoeg\nar X\niv :1\n51 1.\n02 66\n9v 1\n[ cs\n.A I]\n9 N\nov 2\n01 5\ndeveloping the domain ontology, (2) generating hypothesis from ontology, (3) textual entailment methods, and (3) natural language processing of essays.\nA. Developing the domain ontology\nWe assume that the professor provides a corpus of relevant documents in the domain of interest. Our approach is to automatically generate a domain ontology from this corpus. For this task, we rely on Text2Onto framework for ontology learning from textual resources.\nThree main features distinguish Text2Onto: Firstly, learned knowledge is represented at a meta-level Probabilistic Ontology Model (POM). Secondly, user interaction is a core aspect of Text2Onto and the fact that the system calculates a confidence for each learned object allows to design visualizations of the POM. Thirdly, by incorporating strategies for data-driven change discovery, we avoid processing the whole corpus from scratch each time it changes. Instead, POM selectively updates itself, according to the corpus changes only. Besides increasing efficiency, this solution allows to trace the evolution of the ontology with respect to the changes in the underlying corpus.\nText2Onto combines machine learning approaches with basic linguistic processing such as tokenization or lemmatizing and shallow parsing [3]. Since it is based on the GATE framework it is very flexible with respect to the set of linguistic algorithms used. Another benefit of using GATE is the seamless integration of JAPE rules which provides finite state transduction over annotations based on regular expressions.\nThe main workflow of ontology generation consists of: preprocessing, execution of algorithms, combining results. During preprocessing, Text2Onto calls GATE applications to tokenize the document, split sentences, tag Part of Speech and match JAPE rules. GATE creates indexes for the document and the result of this is obtained as an AnnotationSet. In the next step, Text2Onto executes the applied algorithms in a pre-specified order: i) concept, ii) instance, iii) similarity,\niv) subclass-of, v) instance-of, vi) relation and vii) subtopic-of. The basic heuristic employed in Text2Onto to extract concepts and instances is that nouns represent concepts and proper nouns are instances. If more than one algorithm is applied for each category, then the final relevance value is computed based on the selected combiner strategies [12].\nGiven a student essay, we need to analyse its content against the domain ontology available from the previous step. We rely on ReVerb [6] to extract triplets from the student essay.\nReVerb is designed for Web-scale information extraction, where the target relations cannot be specified in advance and speed is important. ReVerb first identifies relation phrases that satisfy the syntactic and lexical constraints, and then finds a pair of NP arguments for each identified relation phrase. A confidence score is assigned to the resulting extractions using a logistic regression classifier.\nThis algorithm differs in three important ways from previous Open IE systems like TextRunner [24]. Firstly, the relation phrase is identified holistically rather than word-by-word. Secondly, potential phrases are filtered based on statistics over a large corpus (the implementation of our lexical constraint). Finally, ReVerb is \u201crelation first\u201d rather than \u201carguments first\u201d, which avoids a common error like confusing a noun in the relation phrase for an argument, (e.g. the noun \u201cdeal\u201d in \u201cmade a deal with\u201d) [6].\nGiven an input sentence s, ReVerb uses extraction algorithm 1. In the second part of the algorithm, for each relation phrase r identified in Step 1, find the nearest noun phrase x to the left of r in sentence s such that x is not a relative pronoun or the existential there. Then, the algorithm finds the nearest noun phrase y to the right of r in sentence s. If such an (x, y) pair could be found, the tuple \u3008x, r, y\u3009 is returned.\nInput : s - sentence; foreach verb v \u2208 s do\nfind the longest sequence of words rv such that: (1) rv starts at v, (2) rv satisfies the syntactic constraint, and (3) rv satisfies the lexical constraint\nend if \u2203 pair of matches adjacent or overlap in s then\nmerge them into a single match; end foreach relation phrase r do\nfind the nearest noun phrase x to the left of r \u2208 s such that x /\u2208 RelativePronoun \u222a {There}, Find the nearest noun phrase y to the right of r \u2208 s.\nend return \u3008x, r, y\u3009.\nAlgorithm 1: Relation extraction algorithm.\nOpen Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a prespecified vocabulary. ReVerb takes raw text as input, and outputs triplets \u3008argument1, relationPhrase, argument2\u3009, as illustrated in example 1.\nEvery OrganicSulfurCompound \u2261 OrganicCompound u \u2203 hasPart . OrganicSulfurGroup.\nExample 1 (Triplets extraction with ReVerb). Given the sentence: \u201cVitamin D is toxic in large amounts.\u201d, the extracted triple is: \u3008vitamin d, be toxic in, large amount\u3009. For \u201cBananas are an excellent source of potassium\u201d, ReVerb extracts the triple \u3008bananas, be source of, potassium\u3009.\nB. Generating hyphothesis\nWe use OWLNatural to generate natural language hypotheses from a domain ontology. OWLNatural is natural language generation engine that produces descriptions of individuals and classes in English and Greek from ontologies that have been annotated with linguistic and user modeling information expressed in RDF. The OWL verbalizer takes its input in OWL syntax and produces an output in a fragment of Attempto Controlled English (ACE) [8].\nC. Enacting textual entailment\nTextual entailment (TE) is a directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. Given two text fragments, one named Text (T ) - the entailing and the other named Hypothesis (H) - the entailed.\nRecognizing Textual Entailment (RTE) has been proposed [5] as a generic task that captures major semantic inference needs across many natural language processing applications. The Recognizing Textual Entailment task consists in recognizing whether the Hypothesis can be inferred from the Text. We use a graduated definition of entailment: T entails H (T \u21d2 H) if, typically, a human reading T would infer that H is most likely true. Positive entailment is illustrated in example 2.\nExample 2 (Positive entailment). T : In chemical reactions with metals, nonmetals\ngain electrons to form negative ions. H: The nonmetals become negative ions.\nThe correctness means that the text entails the hypothesis, so we obtain the positive entailment. The contradiction means that the text does not entail the hypothesis, and there are an negative entailment. An example of a negative TE (text contradicts hypothesis) is illustrated by example 3.\nExample 3 (Negative entailment). T : Nonmetallic elements also react with other non-\nmetals, in this case forming molecular compounds.\nH: Metals react with nonmetals in order to form ions.\nAn example of a non-TE (text does not entail nor contradict) is illustrated by example 4.\nExample 4 (Non entailment). T : A chemical reaction is one in which the organi-\nzation of the atoms is altered. H: The burning of methane is a chemical reaction is\nin the presence of oxygen.\nThe Excitement Open Platform (EOP) is a generic architecture for textual inference in multiple languages. The platform includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting. The input consists of the text T and hypothesis H . The output is an entailment judgment, either Entailment if T entails H , or NonEntailment if the relation does not hold. A confidence score for the decision is also returned in both cases.\nThe overall structure consists of two main parts: Linguistic Analysis Pipeline and Entailment Core. The Linguistic Analysis Pipeline (LAP) is a series of linguistic annotation components range from tokenization to part of speech tagging, chinking, Named Entity Recognition and parsing. Entailment Core consists of Entailment Decision Algorithms (EDAs) and more subordinate components. An EDA takes an entailment decision while components provide static and dynamic information for the EDA. The Entailment Decision Algorithm (EDA) computes an entailment decision for a given Text/Hypothesis pair, and can use components that provide standardized algorithms or knowledge resources. Currently, the EOP ships with three EDAs each following a different approach: transformationbased, edit-distance based, and classification based. Scoring Components accept a Text/Hypothesis pair as an input, and return a vector of scores. Distance Components that can produce normalized and unnormalized distance/similarity values in addition to the score vector. Annotation Components can be used to add different annotations to the Text/Hypothesis pairs. Syntactic Knowledge Components capture entailment relationships between syntactic and lexical-syntactic expressions.\nKnowledge is needed to recognize cases where T and H use different textual expressions (words, phrases) while preserving entailment (e.g., home \u2192 house, Hawaii \u2192 America, born in \u2192 citizen of). The EOP contains a wide range of knowledge resources, including lexical and syntactic resources. Part of them are mannually grabbed from dictionaries, while others are automatically learned. The EOP platform includes three different approaches to RTE: i) an EDA based on transformations between T and H; ii) an EDA based on edit distance algorithms; and iii) a classification based EDA using features extracted from T and H .\nTransformation-based EDA applies a sequence of transformations on T with the goal of making it identical to H . Consider the following example where the text is The boy was located by the police and the hypothesis is \u201dThe child was found by the police\u201c. Two transformations: boy \u2192 child and located\u2192 found do the job.\nEdit distance EDA involves using algorithms casting textual entailment as the problem of mapping the whole content of T\ninto the content of H . Mappings are performed as sequences of editing operations (i.e., insertion, deletion and substitution) on text portions needed to transform T into H , where each edit operation has an associated cost. The underlying intuition is that the probability of an entailment relation between T and H is related to the distance between them.\nClassification based EDA uses a maximum entropy classifier to combine the outcomes of several scoring functions and to learn a classification model for recognizing entailment. The scoring functions extract a number of features at various linguistic levels (bag-of-words, syntactic dependencies, semantic dependencies, named entities) [14]\nMaxEntClassificationEDA is an Entailment Decision Algorithm (EDA) based on a prototype system called Textual Inference Engine (TIE). Results for the three EDAs included in the EOP platform are reported in Table I. Each line represents an EDA, the language and the dataset on which the EDA was evaluated.\nD. Natural language processing with GATE.\nFor natural language procesing we use GATE (General Architecture For Text Engineering). In GATE the logic is arranged in modules that are called pipelines. GATE contains an information extraction pipeline called ANNIE composed of several components: Tokenizer, Gazetteer List,Sentence Splitter, POS Tagger, Semantic Tagger that annotates entities such as Person, Organization, Location, and an Orthographic Co-reference that adds identity relations between the entities annotated by the Semantic Tagger. The tokeniser splits the text into very simple tokens such as numbers, punctuation and words of dierent types. The role of the gazetteer is to identify entity names in the text based on lists."}, {"heading": "III. RUNNING SCENARIO", "text": "Consider the essay in example 5.\nExample 5 (Sample essay in the chemical domain). \u201cAll the matter in the universe is composed of the atoms of more than 100\ndifferent chemical elements, which are found both in pure form and combined\nin chemical compounds.First,a sample of any given pure element is composed\nonly of the atoms characteristic of that element, and the atoms of each element\nare unique. For example, the atoms that constitute carbon are different from\nthose that make up iron, which are in turn different from those of gold. Every\nelement is designated by a unique symbol consisting of one or more letters\nAcylBromide \u2261 AcylHalide u \u2203hasPart.AcylBromideGroup AcylChloride \u2261 AcylHalide u \u2203hasPart.AcylChlorideGroup AcylCompound \u2261 OrganicCompound u \u2203hasPart.AcylGroup AcylFluoride \u2261 AcylHalide u \u2203hasPart.AcylFluorideGroup AcylHalide \u2261 OrganicCompound u \u2203hasPart.AcylHalideGroup AcylIodide \u2261 AcylHalide u \u2203hasPart.AcylIodideGroup Alcohol \u2261 OrganicCompound u \u2203hasPart.HydroxylGroup Aldehyde \u2261 OrganicCompound u \u2203hasPart.AldehydeGroup Amide \u2261 OrganicCompound u \u2203hasPart.AmideGroup Amine \u2261 OrganicCompound u \u2203hasPart.AmineGroup Atom v \u00acOrganicCompound CarbonylCompound \u2261 OrganicCompound u \u2203hasPart.CarbonylGroup CarboxylicAcid \u2261 OrganicCompound u \u2203hasPart.CarboxylicAcidGroup Ester \u2261 OrganicCompound u \u2203hasPart.EsterGroup Ether \u2261 OrganicCompound u \u2203hasPart.EtherGroup HalogenCompound \u2261 OrganicCompound u \u2203hasPart.HalogenAtom Hydrocarbon \u2261 OrganicCompound u \u2203hasPart.CarbonAtom u \u2203 hasPart HydrogenAtom u \u2200 hasPart (CarbonAtom t HydrogenAtom) Imine \u2261 OrganicCompound u \u2203hasPart.ImineGroup Ketone \u2261 OrganicCompound u \u2203hasPart.KetoneGroup OrganicCompound \u2261 Compound u \u2203hasPart.CarbonGroup OrganicCompound v \u00acAtom OrganicSulfurCompound \u2261 OrganicCompound u \u2203hasPart.OrganicSulfurG PrimaryAmine \u2261 OrganicCompound u \u2203hasPart.PrimaryAmineGroup SecondaryAmine \u2261 OrganicCompound u \u2203hasPart.SecondaryAmineGroup TertiaryAmine \u2261 OrganicCompound u \u2203hasPart.TertiaryAmineGroup\nWe run a use case scenario based on the essay in example 5. Firstly, we load the domain knowledge, that is the ontology in chemical domain shown in Fig. 3. Secondly, we generate the list of hypothesis based on the ontology, like in Fig.2. Thirdly,\nwe select a specific number of hypothesis, which will be used by the component of textual entailment. Finnaly, we load the essay, and we run the component for textual entailment. The system runs each hypothesis on the essay and returns a confidence value in [0..10] for each hypothesis. Performing these steps in the essay in example 5 on six hypothesis, we obtain the results in Table II. These confidece values are used to compute the grade.\nConsider a set of 10 essay to assess in the chemical domain. Assume that the domain ontology have been already generated by TextToOnto or available from various ontology repositories. The professor has the following four tasks:\n1) Load the domain ontology (i.e. organic compound.owl); 2) Generate all the hypothesis in natural language from that\nontology (based on OWLNatural); 3) Select the hypothesis against which the essay should be\nverified; 4) Load the essay to be check if entails the selected\nhypothesis (based on textual entailment). Table III shows the assessment when the user selects different number of hypothesis. The execution time varies between 1.5 and 3 minutes for 10 hypothesis, and between 3.5 and 4.5 minutes in case of 20 hypothesis. Table IV shows the results obtained after the comparison with the similar system PaperRater, and manual evaluation."}, {"heading": "IV. DISCUSSION AND RELATED WORK", "text": "The current methods of essay scoring can be categorized into two classes: holistic scoring and rubric-based scoring.\nIn holistic scoring, the essay is assessed and a single score selected from a predefined score range is assigned as an overall score [25]. In the analytical or rubric-based scoring method, essays are assessed on the basis of a certain set of well-defined features [25]. Each feature has a scale associated with it and the final score awarded to the essay is the sum of scores of all the essay rubrics/features.\nThe National Assessment Program Literacy and Numeracy (NAPLAN) [7] rubric of persuasive essay grading lists a set of criteria for marking persuasive writing. The Spelling Mark algorithm is developed to formalise the NAPLAN rubric for marking spelling based on common heuristics and rules of the English language. The first step is to obtain the total number of words in the essay and the number of spelling errors in the essay. Then, each word is categorized based on the difficulty level into one of four classes: simple, common, difficult or challenging, while the number of correct and incorrect words in each category is counted. The final step in the algorithm is to assign the spelling mark according to the set of rules [7].\nPaperRater (https://www.paperrater.com/) is an automated proofreading system that combines NLP, machine learning, information retrieval and data mining to help students write better. PaperRater is also used by schools and universities in over 46 countries to check for plagiarism. The system has a core NLP engine using statistical and rules to extract language features from essays and translate that into statistical models. The three major features are: spell checker, grammar checker, and plagiarism checker. The tool also has a vocabulary builder tool designed to help students learn proper usage of more sophisticated words.\nA complementary line of research is given by argumentative writing support systems [13]. Assisting students in essays with structured and sound arguments is an important educational goal [20]. Hence, various argumentative support systems has been applied in collaborative educational environments [2], [18]. Persuasive essays are extensively studied in the context of automated essay grading. Since argument structure is crucial for evaluating essay quality, [22] identifies the argumentative discourse structure by means of discourse marking. The goal is to model argument components as well as argumentative relations that constitute the argumentative discourse structure in persuasive essays. The annotation scheme includes three ar-\ngument components (major claim, claim and premise) and two argumentative relations (support and attack) [22]. The legal educational system LARGO [17] uses an ontology containing the concepts \u201ctest\u201d, \u201chypothetical\u201d, and \u201cfact situation\u201d and roles such as \u201cdistinction\u201d and \u201cmodification\u201d, while NLP based queries are used to interrogate biomedical data in [16]. The system Convince Me [19] employs more scientific-focused primitives such as hypothesis and data elements with explain and contradict links. Other systems such as Rationale [23] provide more expansive primitive sets that allow users to construct arguments in different domains. Our work fits in this context by using natural language processing for argument mining. The automatic grading mechanism could benefit from a system able to identify arguments in a student essay."}, {"heading": "V. CONCLUSION", "text": "We developed a NLP tool for automatically essay grading in different domains. We enacted textual entailment to compare the text written by a student with the requirments of a human evaluator. These requirments are generated in natural language from a given domain ontology. The main benefit is that the user can select different ontologies for processing text in various domains. However, the confidence in the assessment depends on the precision of the textual entailment method that relies on domain datasets for training.\nIn line with [15], we currently aim to assess the confidence in the system by performing more comparisons with humans that evaluate essays."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank the reviewers for valuable comments. This research was supported by the Technical University of ClujNapoca, Romania, through the internal research project GREEN-VANETS."}], "references": [{"title": "A survey of paraphrasing and textual entailment methods", "author": ["I. Androutsopoulos", "P. Malakasiotis"], "venue": "Journal of Artificial Intelligence Research, pp. 135\u2013187, 2010.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2010}, {"title": "Face to face cooperation with coffee", "author": ["F. Belgiorno", "R. De Chiara", "I. Manno", "M. Overdijk", "V. Scarano", "W. van Diggelen"], "venue": "Times of Convergence. Technologies Across Learning Contexts. Springer, 2008, pp. 49\u201357.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Text2Onto", "author": ["P. Cimiano", "J. V\u00f6lker"], "venue": "Natural language processing and information systems. Springer, 2005, pp. 227\u2013238.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Gate: an architecture for development of robust hlt applications", "author": ["H. Cunningham", "D. Maynard", "K. Bontcheva", "V. Tablan"], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 2002, pp. 168\u2013175.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "The pascal recognising textual entailment challenge", "author": ["I. Dagan", "O. Glickman", "B. Magnini"], "venue": "Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment. Springer, 2006, pp. 177\u2013190.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Identifying relations for open information extraction", "author": ["A. Fader", "S. Soderland", "O. Etzioni"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011, pp. 1535\u20131545.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "An innovative approach for automatically grading spelling in essays using rubric-based scoring", "author": ["A. Fazal", "F.K. Hussain", "T.S. Dillon"], "venue": "Journal of Computer and System Sciences, vol. 79, no. 7, pp. 1040\u2013 1056, 2013.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Attempto controlled english for knowledge representation", "author": ["N.E. Fuchs", "K. Kaljurand", "T. Kuhn"], "venue": "Reasoning Web. Springer, 2008, pp. 104\u2013124.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Generating multilingual descriptions from linguistically annotated OWL ontologies: the NaturalOWL system", "author": ["D. Galanis", "I. Androutsopoulos"], "venue": "Proceedings of the Eleventh European Workshop on Natural Language Generation. Association for Computational Linguistics, 2007, pp. 143\u2013146.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Coh-Metrix providing multilevel analyses of text characteristics", "author": ["A.C. Graesser", "D.S. McNamara", "J.M. Kulikowich"], "venue": "Educational Researcher, vol. 40, no. 5, pp. 223\u2013234, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Cohmetrix: Analysis of text on cohesion and language", "author": ["A.C. Graesser", "D.S. McNamara", "M.M. Louwerse", "Z. Cai"], "venue": "Behavior research methods, instruments, & computers, vol. 36, no. 2, pp. 193\u2013202, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "GATE: A framework and graphical development environment for robust NLP tools and applications", "author": ["K.B.H. Cunningham", "D. Maynard", "V. Tablan"], "venue": "40th Annual Meeting of the ACL, 2002.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2002}, {"title": "Arguing with justifications between collaborating agents", "author": ["I.A. Letia", "A. Groza"], "venue": "Argumentation in Multi-Agent Systems. Springer Berlin Heidelberg, 2012, pp. 102\u2013116.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "The excitement open platform for textual inferences", "author": ["B. Magnini", "R. Zanoli", "I. Dagan", "K. Eichler", "G. Neumann", "T.-G. Noh", "S. Pado", "A. Stern", "O. Levy"], "venue": "ACL 2014, p. 43, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Comparison between web-based automated essay scoring software and human ESL essay assessment: A preliminary investigation", "author": ["M.R. Manap"], "venue": "International Conference on Social Sciences & Humanities, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Question answering over biomedical linked data with grammatical framework", "author": ["A. Marginean"], "venue": "Journal of Web Semantics, p. in press, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Re-evaluating LARGO in the classroom: Are diagrams better than text for teaching argumentation skills?", "author": ["N. Pinkwart", "C. Lynch", "K. Ashley", "V. Aleven"], "venue": "in Intelligent Tutoring Systems. Springer,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "Educational technologies for teaching argumentation skills", "author": ["N. Pinkwart", "B.M. McLaren"], "venue": "Bentham Science Publishers,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Improved reasoning with Convince Me", "author": ["P. Schank", "M. Ranney"], "venue": "Conference companion on Human factors in computing systems. ACM, 1995, pp. 276\u2013277.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1995}, {"title": "Computersupported argumentation: A review of the state of the art", "author": ["O. Scheuer", "F. Loll", "N. Pinkwart", "B.M. McLaren"], "venue": "International Journal of Computer-Supported Collaborative Learning, vol. 5, no. 1, pp. 43\u2013102, 2010.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Handbook of automated essay evaluation: Current applications and new directions", "author": ["M.D. Shermis", "J. Burstein"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Identifying argumentative discourse structures in persuasive essays", "author": ["C. Stab", "I. Gurevych"], "venue": "Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)(Oct. 2014), Association for Computational Linguistics, p.(to appear).", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "The rationale for rationale", "author": ["T. Van Gelder"], "venue": "Law, probability and risk, vol. 6, no. 1-4, pp. 23\u201342, 2007.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Textrunner: open information extraction on the web", "author": ["A. Yates", "M. Cafarella", "M. Banko", "O. Etzioni", "M. Broadhead", "S. Soderland"], "venue": "Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. Association for Computational Linguistics, 2007, pp. 25\u201326.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Toward automated multi-trait scoring of essays: Investigating links among holistic, analytic, and text feature", "author": ["R.K.Y.W. Lee", "C. Gentile"], "venue": "scores. Appl. Linguist.,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}], "referenceMentions": [{"referenceID": 20, "context": "Automated essay grading [21] aims at automatically assigning a grade to a students essay by means of various features.", "startOffset": 24, "endOffset": 28}, {"referenceID": 21, "context": "Since the argument structure is crucial for evaluating essay quality, persuasive essays are extensively studied [22].", "startOffset": 112, "endOffset": 116}, {"referenceID": 0, "context": "Our research hyphotesis relies on the correlation between textual entailment [1] and answer correctness.", "startOffset": 77, "endOffset": 80}, {"referenceID": 9, "context": "The evaluation metrics used will be according to the Coh-Metrix system [10].", "startOffset": 71, "endOffset": 75}, {"referenceID": 2, "context": "The first layer contains the Text2Onto tool [3], used to obtain a consistent ontology from a corpus of high ranked or relevant essays in a given domain.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "The second layer exploits the OWLNatural service [9], to generate natural text from a selected ontology.", "startOffset": 49, "endOffset": 52}, {"referenceID": 13, "context": "The EOP system [14] is trained using a set of pairs \u3008Text,Hyphotesis\u3009.", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "For this step, we use GATE tool for natural language processing [4], to get the number of tokens or number of sentences from text.", "startOffset": 64, "endOffset": 67}, {"referenceID": 10, "context": "We integrate Coh-Metrix service [11] to compute various cohesion and coherence metrics for written texts.", "startOffset": 32, "endOffset": 36}, {"referenceID": 2, "context": "Text2Onto combines machine learning approaches with basic linguistic processing such as tokenization or lemmatizing and shallow parsing [3].", "startOffset": 136, "endOffset": 139}, {"referenceID": 11, "context": "If more than one algorithm is applied for each category, then the final relevance value is computed based on the selected combiner strategies [12].", "startOffset": 142, "endOffset": 146}, {"referenceID": 5, "context": "We rely on ReVerb [6] to extract triplets from the student essay.", "startOffset": 18, "endOffset": 21}, {"referenceID": 23, "context": "This algorithm differs in three important ways from previous Open IE systems like TextRunner [24].", "startOffset": 93, "endOffset": 97}, {"referenceID": 5, "context": "the noun \u201cdeal\u201d in \u201cmade a deal with\u201d) [6].", "startOffset": 39, "endOffset": 42}, {"referenceID": 7, "context": "The OWL verbalizer takes its input in OWL syntax and produces an output in a fragment of Attempto Controlled English (ACE) [8].", "startOffset": 123, "endOffset": 126}, {"referenceID": 4, "context": "Recognizing Textual Entailment (RTE) has been proposed [5] as a generic task that captures major semantic inference needs across many natural language processing applications.", "startOffset": 55, "endOffset": 58}, {"referenceID": 13, "context": "The scoring functions extract a number of features at various linguistic levels (bag-of-words, syntactic dependencies, semantic dependencies, named entities) [14] MaxEntClassificationEDA is an Entailment Decision Algorithm (EDA) based on a prototype system called Textual Inference Engine (TIE).", "startOffset": 158, "endOffset": 162}, {"referenceID": 24, "context": "In holistic scoring, the essay is assessed and a single score selected from a predefined score range is assigned as an overall score [25].", "startOffset": 133, "endOffset": 137}, {"referenceID": 24, "context": "In the analytical or rubric-based scoring method, essays are assessed on the basis of a certain set of well-defined features [25].", "startOffset": 125, "endOffset": 129}, {"referenceID": 6, "context": "The National Assessment Program Literacy and Numeracy (NAPLAN) [7] rubric of persuasive essay grading lists a set of criteria for marking persuasive writing.", "startOffset": 63, "endOffset": 66}, {"referenceID": 6, "context": "The final step in the algorithm is to assign the spelling mark according to the set of rules [7].", "startOffset": 93, "endOffset": 96}, {"referenceID": 12, "context": "A complementary line of research is given by argumentative writing support systems [13].", "startOffset": 83, "endOffset": 87}, {"referenceID": 19, "context": "Assisting students in essays with structured and sound arguments is an important educational goal [20].", "startOffset": 98, "endOffset": 102}, {"referenceID": 1, "context": "Hence, various argumentative support systems has been applied in collaborative educational environments [2], [18].", "startOffset": 104, "endOffset": 107}, {"referenceID": 17, "context": "Hence, various argumentative support systems has been applied in collaborative educational environments [2], [18].", "startOffset": 109, "endOffset": 113}, {"referenceID": 21, "context": "Since argument structure is crucial for evaluating essay quality, [22] identifies the argumentative discourse structure by means of discourse marking.", "startOffset": 66, "endOffset": 70}, {"referenceID": 21, "context": "gument components (major claim, claim and premise) and two argumentative relations (support and attack) [22].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "The legal educational system LARGO [17] uses an ontology containing the concepts \u201ctest\u201d, \u201chypothetical\u201d, and \u201cfact situation\u201d and roles such as \u201cdistinction\u201d and \u201cmodification\u201d, while NLP based queries are used to interrogate biomedical data in [16].", "startOffset": 35, "endOffset": 39}, {"referenceID": 15, "context": "The legal educational system LARGO [17] uses an ontology containing the concepts \u201ctest\u201d, \u201chypothetical\u201d, and \u201cfact situation\u201d and roles such as \u201cdistinction\u201d and \u201cmodification\u201d, while NLP based queries are used to interrogate biomedical data in [16].", "startOffset": 245, "endOffset": 249}, {"referenceID": 18, "context": "The system Convince Me [19] employs more scientific-focused primitives such as hypothesis and data elements with explain and contradict links.", "startOffset": 23, "endOffset": 27}, {"referenceID": 22, "context": "Other systems such as Rationale [23] provide more expansive primitive sets that allow users to construct arguments in different domains.", "startOffset": 32, "endOffset": 36}, {"referenceID": 14, "context": "In line with [15], we currently aim to assess the confidence in the system by performing more comparisons with humans that evaluate essays.", "startOffset": 13, "endOffset": 17}], "year": 2015, "abstractText": "We propose a system for automated essay grading using ontologies and textual entailment. The process of textual entailment is guided by hypotheses, which are extracted from a domain ontology. Textual entailment checks if the truth of the hypothesis follows from a given text. We enact textual entailment to compare students answer to a model answer obtained from ontology. We validated the solution against various essays written by students in the chemistry domain.", "creator": "LaTeX with hyperref package"}}}