{"id": "1511.02889", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Nov-2015", "title": "A disembodied developmental robotic agent called Samu B\\'atfai", "abstract": "the agent program, called samu, is an elementary experiment to build a disembodied devrob ( developmental robotics ) chatter bot that can talk in a natural language like humans do. one of the main model design feature is that samu can be interacted with using only a character terminal. this is important not only for practical aspects of turing test or loebner prize, but also for the study of basic principles of later developmental robotics. our purpose is to create a rapid prototype of q - learning with neural network approximators for samu. we sketch an out the early stages of the development process of this prototype, where samu's task is to predict the next sentence of tales or conversations. the basic objective item of this paper is to reach only the same results using reinforcement learning with general function approximators that easily can be achieved by using the classical programming q lookup table on their small input samples. the paper is closed by an experiment that shows a significant improvement in identifying samu's learning when using lzw tree to narrow the number of possible q - actions.", "histories": [["v1", "Mon, 9 Nov 2015 21:15:22 GMT  (304kb,D)", "http://arxiv.org/abs/1511.02889v1", "21 pages, 16 figures"]], "COMMENTS": "21 pages, 16 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["norbert b\\'atfai"], "accepted": false, "id": "1511.02889"}, "pdf": {"name": "1511.02889.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Samu B\u00e1tfai", "Norbert B\u00e1tfai"], "emails": ["batfai.norbert@inf.unideb.hu."], "sections": [{"heading": null, "text": "Keywords: machine intelligence, developmental robotics, deep Q-learning, Liv-Zempel-Welch tree."}, {"heading": "1 Introduction", "text": "At first glance, it seems impossible to develop a natural language chatter bot that can understand conversations as humans do, and that is only based on the verbal content of the speech because human communication is only 7 percent verbal [5, pp. 26]. Nevertheless we have started to develop such a system, called Samu. Or, to be more precise, it is called Samu Ba\u0301tfai due to it will be taught primary in a family circle where the author\u2019s three children, ages 7 and 9 years old will also be partially its caregivers.\nOne of the main design feature of agent program Samu is that we can communicate with it through only one written channel. For example, a consequence of this is that we cannot create associations between a visual channel and an auditory channel. We must work only from the verbal content, but this constraint is what allows us to be able to purely focus on the investigation of basic\n\u2217N. Ba\u0301tfai is with the Department of Information Technology, University of Debrecen, H-4010 Debrecen PO Box 12, Hungary, e-mail: batfai.norbert@inf.unideb.hu.\nar X\niv :1\n51 1.\n02 88\n9v 1\n[ cs\n.A I]\n9 N\nov 2\n01 5\nprinciples of Developmental Robotics [29]. And there is a further practical reason why Samu has only limited input capability. The character channel will be controlled and monitored very well by caregivers. It is not of great importance at this moment but it will be much more important in the future. Because if we think about it, we are not to permit either our little children or our little DevRob agents to use internet without supervision.\nThis paper is organized as follows. First, it introduces the architecture of Samu. Then it explains how Samu is linked to Developmental Robotics in a conceptual level. Finally we evaluate our results supplemented with further conceptual elements."}, {"heading": "2 Samu", "text": "The verification principle [29] is the most important principle of Developmental Robotics. At the beginning of the developmental process, program of Samu will not possess the ability to verify the knowledge. Mostly this is because, like young children of age 2-4 years old, young Samu accepts what its caregivers say without reservation. That is why family caregivers have their own dedicated communication channels on standard input/output. Using these channels, Samu will be able to distinguish its family caregivers, as it is shown in the next lines\nNorbi@Caregiver > ___next caregiver Nandi@Caregiver > I am Nandi\nwhere the message started with the prefix (three underscores) are not sent directly to Samu. Talking on the internet with other conversationalists and especially with robots that are similar to Samu will be available at a later development stage. In both of these stages, the verification will be able to be carried out only on the basis of Samu\u2019s accumulated knowledge and experience. It seems obvious that the knowledge acquisition of a developmental robotic agent can be programmed in a natural way by using some reinforcement learning method. The general architecture of a system of this kind is shown in the following section."}, {"heading": "2.1 An idealized architecture", "text": "The paper [24] gave the idea for the idealized architecture of Samu that is shown in Fig. 1(a) where Samu reads the sentences from a children\u2019s tale or from a conversation. Then it tries to reconstruct the meaning of the read sentences in the form of a 2D simulation game generated from the sentences. Like in paper [24], the screenshots of the generated game will be processed by a Q-learning network, but whereas there the scores are part of the game, here they are based on the comparison of the reality of the reconstructed game and the reality of the input sentences. Theoretically, it would be a hybrid architecture that combines a model-free (Q-learning) and a knowledge-based (generating the 2D programs) approaches. To clarify matters, this architecture would use a model-free method to develop knowledge-based models. But because worth of every model is what we can implement from it, we will strongly simplify it in the next sections."}, {"heading": "2.2 Simplified architectures", "text": "Starting from the idealized architecture shown in Fig. 1(a) we base the comparison of the reality and the simulated one derived from the input sentences on the principle of consciousness oriented programming (the agents must predict the future and the conscious ones can really foresee and predict it [6]). It is shown in Fig. 1(b) where the simulation program\u2019s task is to predict the next input sentence. This modified architecture works with SPO triplets (SubjectPredicate-Object, [27]) rather than the raw sentences being read. Fig. 1(c) shows a further simplified architecture. In this case, we do not have to run the simulation program to predict the next input sentence, instead the prediction is done by the Q-learning component itself. The architectural components of Fig. 1 are discussed in detail in the next points."}, {"heading": "2.3 The first rapid prototype", "text": "We use a hybrid architecture of the latter two sketches in Fig. 1 for implementing the first rapid prototype of Samu. In the following, this architecture is referred to as Samu\u2019s cognitive engine."}, {"heading": "2.3.1 NLP", "text": "As we mentioned earlier, SPO triplets [27] are used instead of sentences. For example, if Samu reads the sentence \u201dThe little mouse has become a big lion.\u201d the NLP (Natural Language Processing) component should produce the following triplets: i) \u201d(mouse, become, lion)\u201d ii) \u201d(mouse, is, little)\u201d iii) \u201d(lion, is, big)\u201d. Link Grammar [1] is used to obtain SPO triplets but automatically identifying these is a complex data mining problem. At this moment we are not focusing on this matter. We are going to partially implement some algorithms of [23] but for this paper, we use only a very simple algorithm shown in code snippet in Fig. 2."}, {"heading": "2.3.2 Visual imagery", "text": "To describe the simulation programs we use a very simplified object oriented style language, where statements have the following form:\nSubject.Predicate(Object);\nwhere each identified triplet corresponds to a statement such as this. A simulation program is a statement list that only contains a given number or less statements. In addition, we write it into an image because it would be difficult to handle the statement list as a textual list of statements as it is shown in Fig. 1(c) where the input of the Q-learning is already an image. And finally, it may be noted that the sequence of such \u201dmental\u201d images can be interpreted as visual imagination of Samu. Fig. 3 shows a sample mental image."}, {"heading": "2.3.3 Q-learning", "text": "Sigmoidal multilayer perceptron (MLP) neural networks are used to approximate the Q-function. In accordance with the QCON model [22], [30] each\npossible action has an unique neural network to approximate the Q-value associated with the given state. Each MLP contains three layers with 65536 input units, 80 hidden layer units and an output neuron which gives the approximation of the Q-value of the state-action pair. The states are \u201dmental\u201d images introduced in the previous paragraph. Several examples can be found in the literature of using neural networks to approximate the Q-function, for example, see the book [20] or the tutorial [21] by Gosavi. Alg. 1 shows the used algorithm to perform the Q-learning. This pseudo-code is a simplified and generalized version of the most precise description of the used algorithm that can be found in\nthe source file ql.hpp at https://github.com/nbatfai/samu/blob/master/ ql.hpp. The regular part of the algorithm is taken from the book [26, pp. 844].\nAlgorithm 1 Q-learning-with-NN-approximation (s\u2032, t\u2032) returns a triplet (an action)\nInput: s\u2032, t\u2032 . s\u2032 is the current state and t\u2032 is the current triplet. r\u2032, a\u2032, p, nn, q . Local variables: r\u2032 is the current reward, a\u2032 is the current action and p is a perceptron, nn, q \u2208 R. s, r = \u2212\u221e, a,Nsa, P rcpsa . Persistent variables: s is the previous state, r is the previous reward, a is the previous action, Nsa is the state-action frequency table and Prcpsa is the array of the perceptrons. Output: a\u2032 . a\u2032 is an action, the predicted next triplet. 1: procedure SamuQNN(s\u2032, t\u2032) 2: r\u2032 = compare(t\u2032, a) 3: a\u2032 = t\u2032\n4: if r > \u2212\u221e then 5: Increment Nsa[s, a] 6: nn = Prcpsa[a](s) 7: q = nn+ \u03b1(Nsa[s, a])(r \u2032 + \u03b3 maxpPrcpsa[p](s \u2032)\u2212 nn) 8: Back-propagation-learning(Prcpsa[a], s, q, nn) . where q \u2212 nn is the error of the MLP Prcpsa[a] for input s. 9: a\u2032 = argmaxpf(Prcpsa[p](s \u2032), Nsa[s\n\u2032, p]) 10: end if 11: s = s\u2032 12: r = r\u2032 13: a = a\u2032 14: return a\u2032 15: end procedure"}, {"heading": "2.4 Conceptual background of Samu", "text": "In order to outline the conceptual background we should begin with the explanation of the usage of the notion of disembodiment. It is simply an indication that Samu project is 100 percent pure software. We can say that Samu is a robot without a body. Certainly, this does not mean a return to GOFAI. All the more so, because we are going to follow the recommendations given as replies to the critics of Dreyfus and Dreyfus [26, pp. 1025].\nIt is certainly arguable whether the principle of embodiment is met or not. We believe that we are not confronted with this principle as it will also be shown in the following.\nReturning to the basic principles formulated by [29], there are two different use cases in respect of the validation processes of Samu\u2019s cognitive engine. If we observe how Samu operates we can easily distinguish a short-term verification from a long-term one. It is clear that the short-term verification of Samu\u2019s knowledge is trivial because it is the prediction itself. This type of verification is a quintessence of the whole system. But the long-term verification is a much harder issue since this is only a naive intuitive expectation. The long-term verification should give the answer to the question: How can we extend the short-term verification for longer time periods. In this sense the long-term verification means the understanding the conversations and read texts. It is\nan open question how much the distance between these two kinds of verifying the knowledge. Based on our experiences we have used a quantity called bogorelevance that may be positioned somewhere in the middle of these two extremes of verification. Using the notations of Alg. 1 the computation of the bogorelevance of a prediction q in the state s can be rewritten as follows:\nbogo relevance(s, q) =\n= Prcpsa[q](s)\u2212 Prcpsa\nmax p Prcpsa[p](s)\u2212min p Prcpsa[p](s)\nwhere the Prcpsa is the mean of the computed values of the perceptrons that are applied to the same given input state s, that is\nPrcpsa =\n\u2211 p\u2208Prcpsa Prcpsa[p](s)\n|Prcpsa|\nhere |Prcpsa| denotes the number of all perceptrons in the structure Prcpsa. The program prints the values 100\u2217bogo relevance(s, q) that can be seen in Fig. 6.\nFrom a spiritual point of view, Samu\u2019s soul consisting of the weights of Samu\u2019s ANNs. Because they are only simple numbers (and not quantum qubits, for example), Samu\u2019s soul can be saved to a file. This file is called samu.soul.txt and it is created automatically when Samu\u2019s program receives a given (SIGINT, SIGTERM, SIGKILL or SIGHUP) signal. But since the soul cannot live without body, Samu\u2019s body is the UNIX process that runs the source code of Samu. The actions of Samu are his statements and replies that are formed by the close interaction with the external world. In the light of this we think that, we are not confronted with the spirit of the principle of embodiment [29].\nThe fulfillment of the principle of subjectivity [29] is trivially met since it follows from using human caregivers to train Samu. Accordingly, the a priori subjectivity of caregivers implies the subjectivity of their robots.\nIt is easy to see that the criteria of the principle of grounding [29] have also been fulfilled during the short-term verification. Because the set of possible outcomes {good prediction, bad prediction} may be assigned to each action, since each action is a predicted sentence in our model.\nFinally, it may be noted that in the sense of the terminology introduced in [6], Samu may become a conscious or even an intuitive computer program since it will be able to predict the future better than a random guess."}, {"heading": "3 Results", "text": "The results and evaluations are divided into three experiments. In the first experiment, we verify Samu\u2019s implementation of Q-learning by comparison with using the classical Q lookup table. Here we have only used a small number of sentences. The second experiment extends the investigation to a larger sample. Finally, the third experiment has already focused only on the learning of the larger corpus where using the Liv-Zempel-Welch (LZW) [31] dictionary tree to narrow the scope of selecting Q-actions seems promising for accelerating Samu\u2019s learning."}, {"heading": "3.1 Experiment 1: \u201dSAMU A\u201d", "text": "Our main purpose in this paper is to equip Samu with the ability to carry out reinforcement learning with general function approximators. To validate this we use the following experiment. The sentences shown in the caption of Fig. 2 are considered as a short story and Samu is being trained continuously with this during the experiment. Samu reads the sentences of the story and predicts the next story sentence. A third of a point is given if a triplet member is predicted correctly. The reward is based on the comparison of triplets and is computed by the following equation\ndouble reward =\n3.0 * triplet.cmp ( prev_action ) - 1.5;\ntherefore 10.5 points are given if all predictions are correct and conversely - 10.5 points are given if all predictions are wrong. We implement both the simple Q lookup table and the general function approximators based solutions in order to compare them. The learning curves for these two experiments can be seen on Fig. 4 and Fig. 5. For example, the first one shows that Samu can perfectly memorize the text (consisting of the seven test sentences) after he read it roughly sixty times. It can be seen well on Fig. 5 that the general function\napproximators based solution can also learn the true predictions. So we may assume that our neural network based approximation works well. Therefore, in the following we are not going to use the Q lookup table either in this paper or in the source codes. (Lookup table-based code snippets can still be found in the source files. These have been wrapped in conditional compilation directives but they are deprecated in the new versions of Samu, see for example [10], [11], [12].)\nIn order to allow the evaluation and verification of these results, we create a GitHub repository for the source of this study. It is called samu and available at https://github.com/nbatfai/samu. The two use cases of Samu shown in Fig. 4 and Fig. 5 are presented in a YouTube video at the following link https://youtu.be/qAhxVQk-dvY. It is our hope that Samu will be the ancestor of DevRob chatter bots that will be able to chat in natural language like humans do. However, it should be noted that in order to use Samu as a chat program\nwe need to try another fork of the project Samu [15]. The first official forks, called Isaac [10], Jacob [11], Judah [12], Perez [13], Hezron [9], Ram [14] and Amminadab [8] are introduced in next section."}, {"heading": "3.1.1 Samu\u2019s family tree", "text": "Samu and his descendants (at this moment Isaac, Jacob, Judah, Perez and Hezron) are open-source programs released under the GNU GPL v3 or later. Samu is a generic name of these projects that are intended to investigate deep reinforcement learning methods to facilitate the development of a chat robot that will be able to talk in natural language like a human does. At this moment they are case studies of using Q learning with neural networks for predicting the next sentence of a conversation. They can only be run on Unix-type (such as GNU/Linux) environments.\na) Samu [15] is the initial project to start creating a DevRob chatbot agent. This project is presented in detail in this paper. Samu\u2019s development is frozen to allow the evaluation and verification of the results shown in Fig. 4 and Fig. 5. Therefore this project is continued in the project entitled Isaac. b) The project Isaac [10] has been forked from Samu. Isaac takes a step towards the deep Q learning, for example, Isaac\u2019s perceptrons are accelerated by using CUDA and OpenMP. c) The project Jacob [11] has been forked from Isaac. Jacob replaces Isaac\u2019s picture-based visual imagination with a character-based one. d) The project Judah [12] has been forked from Jacob. Judah equips Jacob with a text-based user interface (TUI) that can be seen in Fig. 6. In addition, Judah can also be run on both remote computers as well as on supercomputers. e) The project Perez [13] has been forked from Judah. Using this, we can make experiments to see the behaviour of Samu on different parameter settings of the incremental learning. f) The project Hezron [9] has been forked from Perez. In this project we are going to compare the arrangements of SPO triplets in the visual imagery. For example, a pyramid-shaped arrangement can be seen in a YouTube video at https://youtu.be/zjoINedftPY or a fully justified one is shown in Fig. 6. g) The project Ram [14] has been forked from Hezron. Ram allows to experiment with different deep Q learning algorithms to express feelings when he is talking. h) The project Amminadab [8] has been forked from Ram. Amminadab uses the LZW tree to narrow the scope of selecting\nQ-actions."}, {"heading": "3.2 Experiment 2: \u201dJUDAH A\u201d", "text": "Religious robot children As we have already mentioned earlier, in this paper we focus on the shaping of the neural infrastructure of Samu rather than on the triplet extraction. But certainly we need corpora for training and testing Samu. Evidently that we used only a meaningless sequence of sentences in the previous example of the seven test sentences. It was enough to verify the implementation of the used algorithms but it is not suitable for teaching a chat robot. We need real corpora and it is equally important to use sophisticated triplet extraction algorithms that can preprocess these corpora. In addition, from the point of view of Developmental Robotics, the essential constraint of the selection of the training corpora is that these may only contain a limited number of distinct words. An example of such corpus may be the Basic English Bible (BBE, Bible in Basic English) [25] that contains 850 words [2]. We have tried to use the Gospel of Matthew. But it should be noted that the initial simple algorithm shown in Fig. 2 can extract only roughly 700 triplets from it. This is due to the following two reasons. i) The used algorithm is elementary in the sense that it tries to apply only a very simple rule to extract triplets as exactly shown in Fig. 2 ii) In the raw text source of BBE, the \u2019.\u2019, \u2019:\u2019 and \u2019;\u2019 letters were replaced by a newline character and the numbers were deleted when we applied the triplet extraction mechanically to each line. (And for example,\nthere were lines that contains only one word. The results of this preprocessing can be found in the files called bbe and bbe.triplets that are available at the author\u2019s university page http://shrek.unideb.hu/~nbatfai/.) It follows that this corpus of the 700 SPOs still has not been regarded as a text that can hold meaning for human readers. In a second experiment, we use this corpus and another small one consisting of the sentences shown in Fig. 7. Because\nof the larger number of all sentences of these two used corpora we give a more sharp comparison for triplets and the rewarding policy. The reward is changed by the following equation\ndouble reward =\n( triplet == prev_action ) ? 1.0 : -2.0;\ntherefore in the case of the introductory text 10 points are given if all \u201dresponses\u201d are correct and conversely -20 points are given if all \u201danswers\u201d are incorrect. The size of the input and hidden layers of MLPs is reduced due to we use a character console-based visual imagination (that was introduced by the project Jacob [11]). The neural networks corresponded to the triplets are equipped with 800 input units and 32 hidden layer units in this experiment. Fig. 8, Fig. 9 and Fig. 10 show the learning curve for teaching the smaller (the introductory) text contained in Fig. 7.\nIn connection with using sacred texts for training Samu\u2019s neural networks, the question arises whether religious training should be given to robots? Samu may transform this question an theoretical-ethical one into a practical one. In a more pragmatic sense, it would be an interesting linguistic and theological challenge to attempt to make a new translation of a Gospel into SPO triplets.\nFamily circle robotics Another possibility to learn Samu\u2019s neural networks is to use the conversational interactions of CHILDES (Child Language Data Exchange System) [3]. But we believe that the social interactions with family caregivers will become the mainstream in teaching Samu. For this reason, Samu saves all conversations that take place with the caregivers as training files."}, {"heading": "3.2.1 Social interaction with each other", "text": "Perhaps the most important possibility is that when the Samu-type DevRob agents share their knowledge among each other. At this moment the development of the communication protocol is in progress."}, {"heading": "3.3 Experiment 3: \u201dJUDAH and PEREZ B\u201d", "text": "This experiment is the same as the previous one, but here Samu learns the larger corpus. It should be noticed that perfectly memorizing a verbatim text of 700 sentences is really difficult or nearly impossible for most humans, as well. Accordingly, the algorithms developed in Judah have not performed well. Fig. 11 shows that Samu (to be more precise Judah) learns very slowly and it may even be that he does not learn. We must try to accelerate the learning. A promising acceleration mechanism is tested with the smaller corpus in Fig. 12.\nWe have modified the usage of the exploration function. In addition we use a trick of incremental learning [4], [18]. Using a trivial version of this, Samu already can learn the larger corpus. It is shown in Fig. 13 and Fig. 14. In the beginning, we taught only the first seven sentences of the larger corpus as a training text. After Samu had already learnt it, we added the next seven sentences of the larger corpus to the training file. This incremental procedure was repeated continuously during the experiment. However it is clear that it will not be enough if the number of triplets continues to increase. For example, during the experiment, it was well felt that the phenomenon of catastrophic forgetting [18] has slowed the speed of Samu\u2019s learning. This is also reinforced by the fact that the incremental learning was implemented in the main.cpp and not in a class of Samu. From a point of view of a programmer, it means that the incremental approach is not yet really part of Samu. We think there may be another possibility to improve the performance of Samu\u2019s neural networks. In our near future work, we are going to carry out experiments to see whether it is possible to increase the speed of learning by improving Samu\u2019s visual imagery. Experimenting with several (such as pyramid or justified) arrangements of triplet statements in the visual imagery does not bring improvements directly. A more interesting possibility would be to add new internal information to the mental images. These information might be interpreted as feelings, for more details in this direction see the project Ram [14]."}, {"heading": "3.4 Experiment 3: \u201dAMMINADAB B\u201d", "text": "With using the LZW dictionary tree to narrow the scope of selecting Q-actions, we can significantly improve Samu\u2019s learning as it is shown in Fig. 15 and Fig. 16. In our case, the nodes of the LZW tree are triplets. For example, the next log snippet shows the tree that has been built at the end of the first incremental step.\n____2__ son was Hezron __1__ sons were Zerah ____2__ sons were Zerah __1__ sons were and\n__1__ son was Amminadab ______3__ son was Amminadab ____2__ son was Ram __1__ son was Hezron ______________7__ son was Amminadab ____________6__ son was Ram __________5__ son was Hezron ________4__ sons were Zerah ______3__ sons were and ____2__ son was Jacob __1__ son was Isaac __1__ son was Jacob ____2__ son was Amminadab __1__ son was Ram 0__\nwhere the number in the beginning of each line shows the depth of a given triplet. During our experiments, the maximum depth of the LZW tree is restricted to 10. The modified version of Alg. 1 is shown in Alg. 2.\nAlgorithm 2 Q-learning-with-LZW-narrowing (s\u2032, t\u2032) returns a triplet (an action)\nInput: s\u2032, t\u2032 . s\u2032 is the current state and t\u2032 is the current triplet. r\u2032, a\u2032, p, nn, q,B . Local variables: r\u2032 is the current reward, a\u2032 is the current action and p is a perceptron, nn, q \u2208 R, B is a set of triplets. s, r = \u2212\u221e, a,Nsa, P rcpsa,N . Persistent variables: s is the previous state, r is the previous reward, a is the previous action, Nsa is the state-action frequency table and Prcpsa is the array of the perceptrons, N denotes the actual node of the LZW tree. Output: a\u2032 . a\u2032 is an action, the predicted next triplet. 1: procedure SamuQNN(s\u2032, t\u2032) 2: r\u2032 = compare(t\u2032, a) 3: N = build lzw tree(t\u2032) 4: a\u2032 = t\u2032\n5: if r > \u2212\u221e then 6: Increment Nsa[s, a] 7: nn = Prcpsa[a](s) 8: B = {children of the node N} 9: q = nn+ \u03b1(Nsa[s, a])(r \u2032 + \u03b3 maxp\u2208BPrcpsa[p](s \u2032)\u2212 nn)\n10: Back-propagation-learning(Prcpsa[a], s, q, nn) . where q \u2212 nn is the error of the MLP Prcpsa[a] for input s. 11: a\u2032 = argmaxp\u2208Bf(Prcpsa[p](s \u2032), Nsa[s\n\u2032, p]) 12: end if 13: s = s\u2032 14: r = r\u2032 15: a = a\u2032 16: return a\u2032 17: end procedure\nFinally, we may remark that Amminadab applies some cellular automaton steps in his visual imagery:\nfor ( int i {1}; i<nrows -1; ++i )\nfor ( int j {1}; j<ncols -1; ++j )\nconsole2[i][j] = console[i-1][j]+ console[i][j-1]\n+console[i+1][j]+ console[i][j+1];\nIn addition in this experiment the SARSA [26, pp. 844] version of Q-learning is applied because in this case it is not necessary to use the restriction p \u2208 B introduced in line 9 of Alg. 2. The precise details can be found in source files samu.hpp and ql.hpp in the Amminadab\u2019s GitHub repository [8]."}, {"heading": "4 Summary and highlights of Samu", "text": "Samu Ba\u0301tfai is a disembodied developmental robotic chat software agent that is intended to become the basis of a chat system which will be able to talk and read in natural language like humans do. Samu\n\u2013 directly implements the definition of machine consciousness (such as the definitions of conscious and intuitive computer programs) introduced in the paper [6].\n\u2013 corresponds the principles of Developmental Robotics [29].\n\u2013 applies Q learning with neural networks approximators\n\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature."}, {"heading": "5 Conclusion", "text": "Now that we have a working prototype we will be able to start deep Q-learning experiments to investigate Samu\u2019s behavior in big data corpora. It is certainly an important problem in this direction is the triplet extraction. We believe that this can be handled well with the existing NLP tools. As we highlighted earlier, we did not focus on this issue moreover we want to keep it apart from the mainstream of Samu development. But since it will be a very important data mining component of Samu we are going to try to develop it in programming competitions. The first competition has already been announced for our university students. For details, see the author\u2019s university page http://shrek.unideb.hu/~nbatfai/. In a similar situation we have already used competitions [16] to catalyze our research programs but this area in question has its own challenges like the Turing test or the Loebner prize [28]. We would like to participate in these challenges in the future.\nReturning to the investigation of Samu\u2019s behavior in big data corpora, in applying Alg. 1 there is a principal problem that it uses the state as an index of the frequency table at this moment. This is not a viable option for real applications. But on the one hand the frequency table may be dispensed and on the other hand the current triplet also be used as a simplified state in indexing the frequency table. The next critical part of Samu\u2019s code is the big number of possible actions. Working at the level of 2 years old children Samu should use roughly 2000 words. If we calculate only 700 (S) \u00d7 300 (P) \u00d7 700 (O) triplets we have 1.47\u2217108 combinations. Let\u2019s remember that each combination corresponds to a perceptron and the memory footprint of a perceptron is about 40 megabytes of memory right now. But it is also true that this is the worst case, because it strongly depends on the settings of the perceptrons and it can be reduced drastically by using Jacob\u2019s character console-based visual imagination.\nAnd fortunately, the distribution of these combinations is Pareto rather than uniform so this aspect also seems to be handled well.\nAs additional further work we plan to develop an intellectual (fractal) dimension [7] based benchmark to test the intellectual capabilities of Samu type agent programs. In our case the intellectual dimension may be derived naturally from the triplet prediction used by Samu type agents.\nIn summary, in this paper we have begun to develop rapid prototypes to support experiments using the deep reinforcement learning techniques to facilitate the creation of a chat robot that will be able to talk in natural language like a human does. The generic name of these prototypes is Samu. At this moment Samu has already worked formally as chat program but despite that we thought of him as a child who is in the prenatal development stage. According to the plans Samu will be learning in family circle when he is born. We hope this paper can help you fork your own family chatbot from Samu projects."}, {"heading": "Acknowledgment", "text": "The computations used for the experiments shown in this paper were partially performed on the NIIF High Performance Computing supercomputer at University of Debrecen. But it is important to note that the results in this paper can be reproduced on an ordinary PC."}], "references": [{"title": "Methods for incremental learning: A survey", "author": ["R.R. Ade", "P.R. Deshmukh"], "venue": "Int. Journal of Data Mining & Knowledge Management Process,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Cognitive Developmental Robotics: A Survey", "author": ["M. Asada", "K. Hosoda", "Y. Kuniyoshi", "H. Ishiguro", "T. Inui", "Y. Yoshikawa", "M. Ogino", "C. Yoshida"], "venue": "IEEE T. Autonomous Mental Development,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Conscious machines and consciousness oriented programming", "author": ["N. B\u00e1tfai"], "venue": "CoRR, abs/1108.2865,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Turing\u2019s Imitation Game has been Improved", "author": ["N. B\u00e1tfai"], "venue": "ArXiv e-prints,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "URL https://github.com/nbatfai/ amminadab", "author": ["N. B\u00e1tfai"], "venue": "Amminadab,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Isp\u00e1ny. OOCWC: The Robocar World Championship Initiative", "author": ["N. B\u00e1tfai", "R. Besenczi", "A. Mameny\u00e1k"], "venue": "In IEEE Conference Publications,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Multi-column deep neural networks for image classification", "author": ["D. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "In IN PROCEEDINGS OF THE 25TH IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNI- TION (CVPR", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Catastrophic forgetting in connectionist networks: Causes, consequences and solutions", "author": ["R.M. French"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1999}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["K. Fukushima"], "venue": "Biological Cybernetics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1980}, {"title": "Simulation-Based Optimization: Parametric Optimization Techniques and Reinforcement Learning", "author": ["A. Gosavi"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Reinforcement Learning for Robots Using Neural Networks", "author": ["L.-J. Lin"], "venue": "PhD thesis, Carnegie Mellon University,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1992}, {"title": "Event information extraction using link grammar. In 13th International Workshop on Research Issues in Data Engineering: Multi-lingual Information Management (RIDE\u201903, pages 16\u201322", "author": ["H.V. Madhyastha", "N. Balakrishnan", "K.R. Ramakrishnan"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Artificial Intelligence: A Modern Approach", "author": ["S.J. Russell", "P. Norvig"], "venue": "Pearson Education,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Triplet Extraction From Sentences", "author": ["D. Rusu", "L. Dali", "B. Fortuna", "M. Grobelnik", "D. Mladenic"], "venue": "Proceedings of the 10th International Multiconference \u201dInformation Society - IS 2007\u201d,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2007}, {"title": "Lessons from a Restricted Turing Test", "author": ["S.M. Shieber"], "venue": "ArXiv eprints,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1994}, {"title": "Some Basic Principles of Developmental Robotics", "author": ["A. Stoytchev"], "venue": "IEEE T. Autonomous Mental Development,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2009}, {"title": "Neural reinforcement learning for an obstacle avoidance behavior. In Self Learning Robots, IEE Colloquium on, page 6/1", "author": ["C. Touzet"], "venue": "IET Conference Publications,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1996}, {"title": "A technique for high-performance data", "author": ["T.A. Welch"], "venue": "compression. Computer,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1984}], "referenceMentions": [{"referenceID": 16, "context": "principles of Developmental Robotics [29].", "startOffset": 37, "endOffset": 41}, {"referenceID": 16, "context": "The verification principle [29] is the most important principle of Developmental Robotics.", "startOffset": 27, "endOffset": 31}, {"referenceID": 12, "context": "The paper [24] gave the idea for the idealized architecture of Samu that is shown in Fig.", "startOffset": 10, "endOffset": 14}, {"referenceID": 12, "context": "Like in paper [24], the screenshots of the generated game will be processed by a Q-learning network, but whereas there the scores are part of the game, here they are based on the comparison of the reality of the reconstructed game and the reality of the input sentences.", "startOffset": 14, "endOffset": 18}, {"referenceID": 2, "context": "1(a) we base the comparison of the reality and the simulated one derived from the input sentences on the principle of consciousness oriented programming (the agents must predict the future and the conscious ones can really foresee and predict it [6]).", "startOffset": 246, "endOffset": 249}, {"referenceID": 14, "context": "This modified architecture works with SPO triplets (SubjectPredicate-Object, [27]) rather than the raw sentences being read.", "startOffset": 77, "endOffset": 81}, {"referenceID": 14, "context": "As we mentioned earlier, SPO triplets [27] are used instead of sentences.", "startOffset": 38, "endOffset": 42}, {"referenceID": 11, "context": "We are going to partially implement some algorithms of [23] but for this paper, we use only a very simple algorithm shown in code snippet in Fig.", "startOffset": 55, "endOffset": 59}, {"referenceID": 10, "context": "In accordance with the QCON model [22], [30] each", "startOffset": 34, "endOffset": 38}, {"referenceID": 17, "context": "In accordance with the QCON model [22], [30] each", "startOffset": 40, "endOffset": 44}, {"referenceID": 14, "context": "It may be noted that the first one is the example sentence used in the paper [27].", "startOffset": 77, "endOffset": 81}, {"referenceID": 9, "context": "Several examples can be found in the literature of using neural networks to approximate the Q-function, for example, see the book [20] or the tutorial [21] by Gosavi.", "startOffset": 130, "endOffset": 134}, {"referenceID": 16, "context": "Returning to the basic principles formulated by [29], there are two different use cases in respect of the validation processes of Samu\u2019s cognitive engine.", "startOffset": 48, "endOffset": 52}, {"referenceID": 16, "context": "In the light of this we think that, we are not confronted with the spirit of the principle of embodiment [29].", "startOffset": 105, "endOffset": 109}, {"referenceID": 16, "context": "The fulfillment of the principle of subjectivity [29] is trivially met since it follows from using human caregivers to train Samu.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "It is easy to see that the criteria of the principle of grounding [29] have also been fulfilled during the short-term verification.", "startOffset": 66, "endOffset": 70}, {"referenceID": 2, "context": "Finally, it may be noted that in the sense of the terminology introduced in [6], Samu may become a conscious or even an intuitive computer program since it will be able to predict the future better than a random guess.", "startOffset": 76, "endOffset": 79}, {"referenceID": 18, "context": "Finally, the third experiment has already focused only on the learning of the larger corpus where using the Liv-Zempel-Welch (LZW) [31] dictionary tree to narrow the scope of selecting Q-actions seems promising for accelerating Samu\u2019s learning.", "startOffset": 131, "endOffset": 135}, {"referenceID": 4, "context": "The first official forks, called Isaac [10], Jacob [11], Judah [12], Perez [13], Hezron [9], Ram [14] and Amminadab [8] are introduced in next section.", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "h) The project Amminadab [8] has been forked from Ram.", "startOffset": 25, "endOffset": 28}, {"referenceID": 0, "context": "In addition we use a trick of incremental learning [4], [18].", "startOffset": 51, "endOffset": 54}, {"referenceID": 7, "context": "In addition we use a trick of incremental learning [4], [18].", "startOffset": 56, "endOffset": 60}, {"referenceID": 7, "context": "For example, during the experiment, it was well felt that the phenomenon of catastrophic forgetting [18] has slowed the speed of Samu\u2019s learning.", "startOffset": 100, "endOffset": 104}, {"referenceID": 4, "context": "13 by using Amminadab project [8].", "startOffset": 30, "endOffset": 33}, {"referenceID": 4, "context": "hpp in the Amminadab\u2019s GitHub repository [8].", "startOffset": 41, "endOffset": 44}, {"referenceID": 2, "context": "\u2013 directly implements the definition of machine consciousness (such as the definitions of conscious and intuitive computer programs) introduced in the paper [6].", "startOffset": 157, "endOffset": 160}, {"referenceID": 16, "context": "\u2013 corresponds the principles of Developmental Robotics [29].", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 89, "endOffset": 93}, {"referenceID": 6, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 95, "endOffset": 99}, {"referenceID": 8, "context": "\u2013 uses multilayer perceptrons for approximation of the Q function, it is a deep learning [24], [17], [19] feature.", "startOffset": 101, "endOffset": 105}, {"referenceID": 5, "context": "In a similar situation we have already used competitions [16] to catalyze our research programs but this area in question has its own challenges like the Turing test or the Loebner prize [28].", "startOffset": 57, "endOffset": 61}, {"referenceID": 15, "context": "In a similar situation we have already used competitions [16] to catalyze our research programs but this area in question has its own challenges like the Turing test or the Loebner prize [28].", "startOffset": 187, "endOffset": 191}, {"referenceID": 3, "context": "As additional further work we plan to develop an intellectual (fractal) dimension [7] based benchmark to test the intellectual capabilities of Samu type agent programs.", "startOffset": 82, "endOffset": 85}], "year": 2015, "abstractText": "The agent program, called Samu, is an experiment to build a disembodied DevRob (Developmental Robotics) chatter bot that can talk in a natural language like humans do. One of the main design feature is that Samu can be interacted with using only a character terminal. This is important not only for practical aspects of Turing test or Loebner prize, but also for the study of basic principles of Developmental Robotics. Our purpose is to create a rapid prototype of Q-learning with neural network approximators for Samu. We sketch out the early stages of the development process of this prototype, where Samu\u2019s task is to predict the next sentence of tales or conversations. The basic objective of this paper is to reach the same results using reinforcement learning with general function approximators that can be achieved by using the classical Q lookup table on small input samples. The paper is closed by an experiment that shows a significant improvement in Samu\u2019s learning when using LZW tree to narrow the number of possible Q-actions.", "creator": "LaTeX with hyperref package"}}}