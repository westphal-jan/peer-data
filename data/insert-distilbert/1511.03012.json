{"id": "1511.03012", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2015", "title": "Information retrieval in folktales using natural language processing", "abstract": "traditionally our educational aim everywhere is to extract information about literary characters in unstructured texts. we employ natural language processing and neural reasoning on domain ontologies. the first task is to identify the main characters \" and the parts of the story where these characters are described or act. we illustrate the system in a scenario in the folktale domain. the visual system relies on a folktale ontology that we have developed based on propp'original s model for folktales without morphology.", "histories": [["v1", "Tue, 10 Nov 2015 08:13:49 GMT  (342kb,D)", "http://arxiv.org/abs/1511.03012v1", "IEEE 11 International Conference on Intelligent Computer Communication and Processing (ICCP2015), Cluj-Napoca, Romania, 3-5 September 2014"]], "COMMENTS": "IEEE 11 International Conference on Intelligent Computer Communication and Processing (ICCP2015), Cluj-Napoca, Romania, 3-5 September 2014", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR", "authors": ["adrian groza", "lidia corde"], "accepted": false, "id": "1511.03012"}, "pdf": {"name": "1511.03012.pdf", "metadata": {"source": "CRF", "title": "Information retrieval in folktales using natural language processing", "authors": ["Adrian Groza", "Lidia Corde"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\u2014Natural language processing, ontologies, literary character, folktales.\nI. INTRODUCTION\nRecognising literary characters in various narrative texts is challenging both from the literary and technical perspective. From the literary viewpoint, the meaning of the term \u201ccharacter\u201d leaves space to various interpretations. From the technical perspective, literary texts contain a lot of data about emotions, social life or inner life of the characters, while they are very thin on technical, straight-forward messages. To infer the character type from literary texts might pose problems even to the human readers [4].\nInteractions between literary characters contain rich social networks. Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].\nOur aim is to correctly determine the relationships of a character in a tale and to find its role upon the development of the story. In line with [16], the first task is to identify the parts of the story where that character is involved. Our approach relies on interleaving natural language processing and ontology-based reasoning. We enact our method in the folktale domain.\nInformation extraction systems usually have three components responsible for: named entity recognition, co-reference resolution and relationship extraction. These modules are integrated in a pipeline, in a layered manner, given that each task will use information provided by the previous neighbor. Natural language processing has been applied in the domain of folktales [14], [8]. Formal models for folktales have been proposed in [12], [15]. Character identification in folktales have been approached in [17], [19].\nThe remaining of the paper is organized as follows: Section II presents the ontology that we developed for modeling\nthe domain of folktales. Section III depicts the architecture of our system. Section IV illustrates our method to extract knowledge about characters. Section V presents the experimental results on seven folktales. Section VI browses related work, while section VII concludes the paper."}, {"heading": "II. ENGINEERING THE FOLKTALE ONTOLOGY", "text": "To support reasoning in the folktale domain, we developed an ontology used to extract knowledge regarding characters. We assume the reader is familiarised with the syntax of Description Logic (DL). For a detailed explanation about families of description logics, the reader is referred to [3].\nTo support character identification and reasoning on these characters we need structured domain knowledge. Hence, we developed an ontology for the folktale domain as shown in Fig. 3. Our folktale ontology formalizes knowledge from three sources: 1) the folktale morphology as described by the Propp model [15]; 2) various entities specific to folktales (i.e., animals, witch, dragons); and 3) common family relations (i.e., child, fiancee, groom). In the following, these three knowledge sources are detailed:\na) Folktale morphology: Firstly, we rely on the Propp\u2019s model [15] of the folktale domain. In the Propp\u2019s model the story broke down into several sections. Propp demonstrated that the sequence of sections appears in the same chronological order in Russian folktales. Propp identified a set of character types that appear in most of the folktales (see Table I).\nThe corresponding formalization in Description Logic appears in Fig. 1, where the characters are divided in nine types978-1-4673-8200-7/15 $31.00 c\u00a9 2015 IEEE\nar X\niv :1\n51 1.\n03 01\n2v 1\n[ cs\n.C L\n] 1\n0 N\nov 2\n01 5\nA1 Agent t Donor t FalseHero t Hero t Prisoner t Villain t Dispatcher t MagicalHelper t Princess v Character A2 Hero u Villain v FalseHero A3 PositiveCharacter t NegativeCharacter v Character A4 Villain t FalseHero t Prisoner v NegativeCharacter A5 Hero t MagicalHelper t Agent t Donor t Prisoner t Dispatcher v\nPositiveCharacter\nFig. 1. Formalising the Propp\u2019s model of folktales.\nA21 Bear t Bird t Dog t Duck t Frog t Horse t Lion v SingleAnimal A22 Enchantress \u2261 Witch A23 Enchantress v Woman u SingleSocialStatus A24 Giant v Supernatural A25 Goldsmith t Helmsman v SingleSocialStatus A26 King v SingleSocialStatus A27 Oven v Object A28 Prince \u2261 Son u \u2203hasParent.King t \u2203hasParent.Queen A29 Prince v SingleSocialStatus A30 Princess \u2261 Daughter u \u2203hasParent.King t \u2203hasParent.Queen\nFig. 2. Common entities in the folktale domain.\n(axiom 1). In axiom 2, a false hero is a hero who is also a villain. Axiom 3 divides the characters into negative and positive ones. Note that positive and negative characters are not disjoint, as for instance the concept Prisoner belongs to both sets.\nb) Folktale main entities: Secondly, the common entities appearing in folktales were formalized in Fig. 2. The axioms depict the animals (axiom 21), witches or enchantresses which are women with a single social status (axioms 22 and 23), and supernatural characters like Giant in axiom 24. Specific characters like Goldsmith or King, and various objects (i.e. oven) are also modeled. A prince is defined in axiom 28 as a son that have a parent either a king or a queen. Similarly, the princess is a daughter with at least on parent of type king or queen (axiom 30).\nc) Family relationships in folktale: Fig. 4 lists part of the family relationships adapted to reason in the folktale domain. A significant part of these relationships are correlated with the recurrent theme of the main character who is finding his bride or fiancee.\nTo facilitate reasoning on the ontology, we allow several extensions of the ALC version of description logics [3]. Using role inheritance we can specify that the role hasFather is more specific than the role hasParent. Hence, if we find in the folktale that a character has a father, the system deduces based on role inheritance that the character has also a parent. Similarly, inverse roles like hasChild and hasParent are used to infer new knowledge based on the partial knowledge extracted by natural language processing. If we identify that two individuals are related by the role hasChild, the system deduces that those individuals are also related by the role hasParent. The domain restriction specifies that only persons can have brothers. The range restriction constraints the range of the role hasGender to the concept Gender."}, {"heading": "III. SYSTEM ARCHITECTURE", "text": "Extracting knowledge about characters is obtained by interleaving natural language processing (NLP) and reasoning on ontologies. The NLP component is based on GATE text engineering tool [5], while reasoning in DL on the OWLAPI [10], as depicted by the architecture in Fig. 5.\nFirstly, the folktale ontology is processed using OWLAPI to generate classes of characters from the ontology into GATE. The folktale corpus is analysed aiming to populate the ontology and to annotate each folktale with the identified named entities. In parallel to the annotation process, the Stanford parser creates the coreference information files. The task is challenging, as even a human might have a problem in decoreferencing some of the sentences, as example 1 illustrates.\nExample 1. \u201dThe Smiths went to visit the Robertsons. After that, they stayed home, watching tv.\u201d, where \u201dthey\u201d might be tied to the Smiths, or the Robertsons, or to both of the families.\nFor de-coreferencing, the following pipeline was designed (left part of Fig. 5). The tokenizer groups all the letters into words. Next, the sentence splitter (Ssplit) groups the sequence of tokens obtained in the previous step into sentences. The part of speech (POS) annotation labels all the tokens from a sentence with their POS tags. Lemma annotation generates the word lemmas for all the tokens in the corpus. The next step is to apply named entity recognition (NER) so that the numerical and temporal entities are recognized. This is done using a conditional random fields (CRF) sequence taggers trained on various corpora. The parse function provides a full syntactic analysis for each sentence in the corpora. Finally, the coreference chain annotation (Dcoref) obtains both the\npronominal and nominal coreference resolution. After coreference resolution, the stories are updated with the coreference information.\nThe Reverb information extraction tool [7] is used to generate triplets containing the following structure: \u3008nominal phrase, verb phrase, nominal phrase\u3009. For the sentence \u201dGood heavens, said the girl, no strawberries grow in winter\u201d, the output of Reverb is exemplified in Table III. In order to obtain the triplets, each sentence has to be POS-tagged and NPchunked.\nIV. INTERLEAVING NATURAL LANGUAGE PROCESSING WITH REASONING ON ONTOLOGIES\nThis section details three algorithms used to identify knowledge about characters. Algorithm 1 identifies characters in the folktale. Algorithm 3 is used for anaphora resolution of the named entities recognized as characters. Algorithm 2 extracts knowledge about characters from the de-coreferences. The execution flow of this pipeline, is presented in Fig. 6.\nNatural language processing is enacted to populate the folktale ontology. The extraction Algorithm 1 is performed repetitively on a document, each time using the newly populated ontology file. In this way, the algorithm interleaves reasoning on ontology with natural language processing based on Japes rules [18]. The first step is to apply the Jape rules JN on the folktale corpus aiming to identify all the definite and indefinite nominal phrases. Given that the characters are nominal phrases, this first step returns all the information needed, plus some extra phrases that have to be filtered out.\nNext, the Jape rules JC are enacted to select candidate characters from the set of nominal phrases previously identified. For each character found, a set of rules JR is used to match the character against a concept in the ontology.\nTABLE III EXTRACTING TRIPLETS FROM FOLKTALES USING REVERB.\nOriginal Sentence Nominal Phrase (arg1) Verb Phrase (arg2)\nNominal Phrase (arg3) Extraction Confidence POS tags Chunk tags\n10 3 4 5 9 11 12 Good heavens, said the girl, no strawberries grow in winter.\nno strawberries\ngrow in winter 0.505 JJ NNS , VBD DT NN , DT NNS VB IN NN . B-NP I-NP O B-VP B-NP I-NP O B-NP I-NP\nThe king\u2019s daughter began to cry , for daughter was afraid of the cold frog which daughter did not like to touch, and which was now to sleep in daughter pretty, clean little bed. daughter was afraid of the cold frog 0.691 DT NN POS NN VBD TO VB , IN NN VBD JJ IN DT JJ NN WDT NN VBD RB IN TO VB , CC WDT VBD RB TO VB RP NN RB , JJ JJ NN . B-NP I-NP I-NP I-NP B-VP IVP I-VP O B-PP B-NP B-VP BADJP B-PP B-NP I-NP I-NP BNP I-NP B-VP O O B-VP I-VP O O B-NP B-VP B-ADVP B-VP I-VP B-NP I-NP B-ADVP O BNP I-NP I-NP O When everything was stowed on board a ship, faithful John put on the dress of a merchant, and the king was forced to do the same in order to make king quite unrecognizable. John put on the dress of a merchant 0.876 WRB NN VBD VBN IN NN DT NN , NN NNP VBD IN DT NN IN DT NN , CC DT NN VBD VBN TO VB DT JJ IN NN TO VB NN RB JJ . B-ADVP B-NP B-VP I-VP BPP B-NP B-NP I-NP O B-NP BNP B-VP B-PP B-NP I-NP I-NP I-NP I-NP O O B-NP I-NP BVP I-VP I-VP I-VP B-NP I-NP B-SBAR O B-VP I-VP B-NP BADJP I-ADJP O Sons each kept watch in turn, and sat on the highest oak and looked towards the tower. each kept watch in turn 0.880 NNPS DT VBD NN IN NN , CC VBD IN DT JJS NN CC VBD IN DT NN .\nO B-NP B-VP B-NP B-PP BNP O O B-VP B-PP B-NP I-NP I-NP O B-VP B-PP B-NP I-NP O\nRapunzel grew into the most beautiful child under the sun. Rapunzel grew into\nthe most beautiful child 0.830 NNP VBD IN DT RBS JJ NN IN DT NN . B-NP B-VP B-PP B-NP I-NP INP I-NP B-PP B-NP I-NP O\nThe king\u2019s son ascended, but instead of finding son dearest rapunzel, son found the enchantress, who gazed at son with wicked and venomous looks. the enchantress gazed at son 0.586 DT NN POS NN VBD , CC RB IN VBG NN NN NN , NN VBD DT NN , WP VBD IN NN IN JJ CC JJ NNS . B-NP I-NP I-NP I-NP B-VP O O B-PP I-PP B-VP B-NP I-NP I-NP O B-NP B-VP B-NP I-NP O B-NP B-VP B-PP B-NP B-PP B-NP I-NP I-NP I-NP O\nInput : Of - Folktale ontology; S - Corpus of folktales; JN - Jape rules to identify definite and indefinite nominal phrases; JC - Jape rules to identify candidate characters; JR - Jape rules to identify character\u2019s relation to the ontology;\nResult: C: Set of annotated characters;\nC \u2190 \u2205; NP \u2190 applyRules(JN , S); while applyRules(JC, S, NP ) 6= null do\nNC \u2190 applyRules(JC, S, NP ); Rel\u2190 applyRules(JR, S, NC); foreach r \u2208 Rel do\nforeach concept from r do if checkCast(NC, concept) then\ncast(NC, concept); end\nend end while is referred(S, NC) do\nRef = getReference(); link(NC, Ref );\nend C \u2190 C \u222aNC;\nend Algorithm 1: Character extraction algorithm.\nAfter identifying a concept for which the character is an instance, the algorithm exploits reasoning on ontology to identify all atomic concepts to which the character belongs. For instance, a character identified as Daughter will be an instance of Girl, Child, Maiden, SinglePerson (recall Fig. 4). For each concept to which the character belongs, the algorithm looks again in the corpus to see if there are other mentions of the newly introduced character. If this is the case, the character is related with the new knowledge.\nInput : S: Corpus of folktales; P : Pipeline configuration for decoreferencing; FN : List with filenames for each S; SC: Stanford-CoreNLP command; Result: D: Decoreferenced texts of files from FN ;\nFiles = run(SC, P , FN ); foreach file in Files do\nD \u2190 S; foreach coref group \u2208 file do\nrep\u2190 findRepresentative(coref group); foreach coref word \u2208 coref group do\nreplace(D, coref word, rep ); end\nend end\nAlgorithm 2: Decoreference algorithm.\nThe decoreferencing algorithm (Alg. 2) uses as input the processing pipeline and the folktale corpus. The basic processing steps needed are the following: tokenize, ssplit, pos, lemma, ner, parse, dcoref. The decoreferencing algorithm is run on all stories at once, but it generates different output file for each story represented by the filename. In the first step, the Stanford parser applies the execution pipeline on the corpora of folktales. For each resulted file, the algorithm searches for coreference groups. In order to be able to return the modified text, the original text has to be stored in the returning argument of the algorithm. For each coreference group found, firstly the referenced word has to be processed and kept into a variable and then, each coreferenced word found, belonging to the group, has to be replaced in the original text with the referenced variable. In the end, the decoreferenced text for each corpus file is obtained.\nAlgorithm 3 takes as input the result of algorithms 1 and (alg 2. The set of characters is used as the input, while the decoreferenced texts are used as an environment from which the algorithm extracts the perspective. For each character in the set of characters resulted from the extraction algorithm (alg 1), each line that resulted from reverb execution is processed. From each line, the sentence is extracted based on the output\nInput : R: Reverb command; V : The version indicator. True if long version, false otherwise; C: Set of characters resulted from algorithm 1; D: Decoreferenced text resulted from algorithm 2;\nResult: P : String containing character\u2019s perspective in S;\nRR = run(R, D); if V = true then\nforeach c \u2208 C do foreach line \u2208 RR do\nsentence\u2190 getSentence(line); if c \u2208 sentence then\nP \u2190 P \u222a sentence; end\nend end\nelse foreach c \u2208 C do\nforeach line \u2208 RR do triplet\u2190 getTriplet(line); if c \u2208 triplet then\nP \u2190 P \u222a triplet; end\nend end\nend Algorithm 3: Finding character\u2019s perspective.\nformat of the Reverb service presented in Table III. If the character, from the character set, is mentioned in the sentence, then the sentence is appended to the output variable. These columns are combined in a triplet, and it is checked to see whether the current character appears is present in this triplet. In this case, the triplet is appended to the output variable. This algorithms score is represented by a subunitary number that represents the confidence that the extraction was correct."}, {"heading": "V. EXPERIMENTAL RESULTS", "text": "A. Running scenario\nThe system was tested against seven stories (Table V). This section illustrates the results of this pipeline for the secondary character Henry from the story \u201cThe frog king\u201d. The fragment on which the algorithms were applied is listed in Example 2.\nExample 2. \u201dThen they went to sleep, and next morning when the sun awoke them, a carriage came driving up with eight white horses, which had white ostrich feathers on their heads, and were harnessed with golden chains, and behind stood the young king\u2019s servant Faithful Henry. Faithful Henry had been so unhappy when his master was changed into a frog, that he had caused three iron bands to be laid round his heart, lest it should burst with grief and sadness. The carriage was to conduct the young king into his kingdom. Faithful Henry helped them both in, and placed himself behind again, and was full of joy because of this deliverance. And when they had driven a part of the way the king\u2019s son heard a cracking behind him as if something had broken. So he turned round\nand cried, \u201dHenry, the carriage is breaking.\u201d \u201dNo, master, it is not the carriage. It is a band from my heart, which was put there in my great pain when you were a frog and imprisoned in the well.\u201d Again and once again while they were on their way something cracked, and each time the king\u2019s son thought the carriage was breaking, but it was only the bands which were springing from the heart of Faithful Henry because his master was set free and was happy.\u201d\nThe method has two kind of results - one for the long version, and one for the short version. Firstly, the results for the short version are listed in Table IV. Note that the output text is the decoreferenced one - this is the reason why the character might talk about itself in third person. Because of the de-coreferenced version of the stories part of text might not be correct from the human reader perspective. But it is the easiest way to understand the context of a character. Otherwise, it would be hard to see that when the text says \u201dhis master\u201d, that \u201dhis\u201d refers to Henry, as Example 3 bears out.\nExample 3. 1. Then companion went to sleep, and next morning when the sun awoke companion, a band came driving up with eight white horses, which had white ostrich feathers on companion heads, and were harnessed with golden chains, and behind stood the young king\u2019s servant faithful Henry.\n2. Faithful Henry had been so unhappy when henry master was changed into a frog, that Henry had caused three iron bands to be laid round henry heart, lest heart should burst with grief and sadness.\n3. Faithful Henry helped bands both in, and placed Henry behind again, and was full of joy because of this deliverance.\n4. Again and once again while you were on you way something cracked, and each time the king\u2019s son thought the band was breaking , but it was only the bands which were springing from the heart of faithful Henry because Henry master was set free and was happy.\u201d\nThere are some cases in which there will be no result for a character (Example 4). Given that the character was extracted from the original file, by using Algorithm 1, there is a certainty that the character exists in the story.\nExample 4. When trying to search for the perspective of character \u201dwaiting-maid\u201d in the story \u201dFaithful John\u201d, the application will not be able to find any solution. In the unmodified text, the son character is introduced in the following way: \u201dShe took him by the hand and led him upstairs, for she was the waiting-maid.\u201d\nThis happens because, when the anaphoric decoreference is run (Algorithm 2), the file is changed in the following way: \u201dGirl took oh by the hand and led oh upstairs , for girl was the girl .\u201d. The change happened because the decoreferencing tool interpreted \u201dthe waiting-maid\u201d as being tied up to the word \u201dshe\u201d, and, which is tied to \u201dthe girl\u201d from the following phrase \u201dThen said the girl \u2018 the princess must see these , girl has such great pleasure in golden things , that girl will buy all you have . \u2019\u201d. In this way, this character\u2019s part will be attributed to the \u201dgirl\u201d, which is the main character of the story. This situation in which the story is talking about a general character, but only after the main events, the character is finally revealed, is called cataphora [11].\nB. Accuracy of the method\nThe accuracy of our method is influenced by: 1) accuracy of character identification; 2) accuracy of identifying coreferences; 3) accuracy of Reverb when extracting triplets (the confidence indicator). Each of this services has an accuracy error that will be propagated from one component to another. We performed various tests on the corpus used for character identification, and we obtained an average accuracy of 70% (Table V). When calculating the accuracy, 20 characters were taken into consideration, meaning that for each story, about 3 characters were chosen. These characters were manually selected from the set of characters output by the character extraction system presented in [17], [19]. The characters were selected by choosing 2 main characters and a secondary character for each story.\nThe testing was performed on seven different stories, and for each story, a set of main characters was chosen. The obtained overall accuracy is 74%, having an overall precision of 90% and a recall of 60%. The results are presented in Fig. 7. Figure 8 depicts the distribution of precision, recall and accuracy over the stories. The values were calculated using the following formulas:\nprecision = tptp+fp recall = tptp+fn\naccuracy = tp+tntp+fp+tn+fn where tp means true positive, and represents the number of sentences that are found both in the manually annotated set and the test set, tn means true negative and represents the number of sentences that are neither in the manually annotated\nset, nor in the test set, fp means false positive and represents the number of sentences that are in the test set and not in the manually annotated set, and fn means false negative and represents the number of sentences that are in the manually annotated set, but not in the test set. In the folktale context, the tp represents the number of sentences that belong to the character\u2019s perspective, all those sentences that involve the character in any way.\nThe average F-score for the Stanford-CoreNLP of 59.5 influences greatly the performance of the algorithm, as the characters perspective cannot be extracted, given that the character is not seen as being part of the sentence. The accuracy can be improved if a better decoreferencing tool will be used. Other coreference tools are For the anaphoric decoreference, there are several other tools (BART, JAVARAP, GuiTar and ARKref), but, from all, the Stanford-CoreNLP has be highest accuracy percentage.\nThere is ongoing research in the coreference resolution domain, When calculating the performance scores, the extraction of the correct sentence was considered, and not on the correctness of the extracted sentence. Even though the right sentence was extracted, the information in the sentence will be according to the coreference resolution result. Hence, an error might be observed when reviewing the structure of the sentences. The algorithms performance is also influenced by the scores obtained by the Reverb tool. Also, the named entity recognition has an average precision of 79% and a\nrecall of 72%. These scores do not influence directly the algorithms performance, but they have an effect on the number of characters for which the algorithm will try to find the roles they have on the development of the story. Together, all these scores combined, give the performance scores of the characters perspective in texts.\nThe current version does not extract information about the characters\u2019 roles. The information extracted consists of the character identification, that is presented in [17], [19], and the story involving the character. The story can be presented in a standardized version."}, {"heading": "VI. DISCUSSION", "text": "We can enact our solution in other domains instead of folktales. We exemplify he following three domains: a) software requirements, b) marketing and c) medical domain.\nConsider the domain of software requirements, where these requirements are written in natural language. Our system will support the identification of various actors appearing in the requirements document. First, one needs to replace the folktale ontology with a requirement ontology that provides knowledge on use cases, actors, their roles, etc. The same pipeline will be used to: 1) identify main actors (admin, various users, etc) and 2) extract knowledge about various actions these actors are supposed to perform.\nAnother domain that could benefit from the same pipeline of execution, would be the marketing domain. Consider a dataset of product reviews or accommodation places in the tourism domain [20]. The system would extract only the sentences that reference the mentioned item. By having access to all the sentences of interest, further analysis is facilitated without having to process the entire text.\nSimilar extraction systems have been proposed for the medical domain to extract information from clinical narratives. In this line, the MedEx system [21] aims to extract the medication information from clinical narratives. Similarly, there is also the OpenClinical system for assisting health care providers.\nIn our approach, the extraction algorithm part is separated from the perspective searching part. Therefore, any ontology and any document can be used in order to find the character\u2019s or object\u2019s perspective in the document.\nWe tested our method only on seven stories. With a complexity of O(n3) in sentence length of syntactic parsing, our syntactic based on Stanford parser might be too slow for large corpus as the one of 15099 narratives analysed in [4]."}, {"heading": "VII. CONCLUSIONS", "text": "Our method is able to extract knowledge on various characters. Our current accuracy for information extraction in the folktale domain is 74%. The experimental results were obtained for seven stories in the folktale domain. The precision score is above 90%, With an overall recall of only 60%, there are high chances that not all the information regarding a product was extracted.\nThe developed algorithms aggregate three different services: Firstly, the named entity recognition was implemented by\nusing an ontology based on Propps formal model. Based of this ontology, and some implemented Jape rules, the characters are extracted from a given story. Secondly, a coreference resolution tool was implemented by enacting anaphoric resolution to eliminate co-referenced words and to replace them with their representative, Thirdly, finding relationships between characters was integrated in order to link two noun phrases with a verbal phrase."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank the reviewers for their valuable comments. Part of this work was supported by the Department of Computer Science of Technical University of Cluj-Napoca, Romania."}], "references": [{"title": "Parsing screenplays for extracting social networks from movies", "author": ["A. Agarwal", "S. Balasubramanian", "J. Zheng", "S. Dash"], "venue": "EACL 2014, pp. 50\u201358, 2014.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Social network analysis of Alice in Wonderland", "author": ["A. Agarwal", "A. Corvalan", "J. Jensen", "O. Rambow"], "venue": "Workshop on Computational Linguistics for Literature, 2012, pp. 88\u201396.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "The description logic handbook: theory, implementation, and applications", "author": ["F. Baader"], "venue": "Cambridge university press,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "A bayesian mixed effects model of literary character", "author": ["D. Bamman", "T. Underwood", "N.A. Smith"], "venue": "Proceedings of the 52st Annual Meeting of the Association for Computational Linguistics (ACL14), 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Evolving GATE to meet new challenges in language engineering", "author": ["K. Bontcheva", "V. Tablan", "D. Maynard", "H. Cunningham"], "venue": "Natural Language Engineering, vol. 10, no. 3-4, pp. 349\u2013373, 2004.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Extracting social networks from literary fiction", "author": ["D.K. Elson", "N. Dames", "K.R. McKeown"], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics. Association for Computational Linguistics, 2010, pp. 138\u2013147.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Identifying relations for open information extraction", "author": ["A. Fader", "S. Soderland", "O. Etzioni"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011, pp. 1535\u20131545.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Annotating with Propp\u2019s morphology of the folktale: reproducibility and trainability", "author": ["B. Fisseni", "A. Kurji", "B. L\u00f6we"], "venue": "Literary and Linguistic Computing, vol. 29, no. 4, pp. 488\u2013510, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Identification of speakers in novels.", "author": ["H. He", "D. Barbosa", "G. Kondrak"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "The OWL API: A Java API for OWL ontologies.", "author": ["M. Horridge", "S. Bechhofer"], "venue": "Semantic Web,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Differential effects of constraints in the processing of Russian cataphora", "author": ["N. Kazanina", "C. Phillips"], "venue": "The Quarterly Journal of Experimental Psychology, vol. 63, no. 2, pp. 371\u2013400, 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "A declarative model for simple narratives", "author": ["R. Lang"], "venue": "Proceedings of the AAAI fall symposium on narrative intelligence, 1999, pp. 134\u2013141.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "Structural analysis on social network constructed from characters in literature texts", "author": ["G.-M. Park", "S.-H. Kim", "H.-G. Cho"], "venue": "Journal of Computers, vol. 8, no. 9, pp. 2442\u20132447, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "A description logic ontology for fairy tale generation", "author": ["F. Peinado", "P. Gerv\u00e1s", "B. D\u0131\u0301az-Agudo"], "venue": "Procs. of the Workshop on Language Resources for Linguistic Creativity, LREC, vol. 4, 2004, pp. 56\u201361.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2004}, {"title": "Morphology of the Folktale", "author": ["V.I. Propp"], "venue": "American Folklore Society,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1958}, {"title": "An NLP-based cross-document approach to narrative structure discovery", "author": ["N. Reiter", "A. Frank", "O. Hellwig"], "venue": "Literary and Linguistic Computing, vol. 29, no. 4, pp. 583\u2013605, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Interleaving ontology-based reasoning and natural language processing for character identification in folktales", "author": ["D. Suciu", "A. Groza"], "venue": "IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP2014), Cluj-Napoca, Romania, 2014, pp. 67\u201374.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Gate Jape grammar tutorial", "author": ["D. Thakker", "T. Osman", "P. Lakin"], "venue": "Nottingham Trent University, UK, Phil Lakin, UK, Version, vol. 1, 2009.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Integrating DBpedia and SentiWordNet for a tourism recommender system", "author": ["B. Varga", "A. Groza"], "venue": "Intelligent Computer Communication and Processing (ICCP), 2011 IEEE International Conference on. IEEE, 2011, pp. 133\u2013136.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Medex: a medication information extraction system for clinical narratives", "author": ["H. Xu", "S.P. Stenner", "S. Doan", "K.B. Johnson", "L.R. Waitman", "J.C. Denny"], "venue": "Journal of the American Medical Informatics Association, vol. 17, no. 1, pp. 19\u201324, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 3, "context": "To infer the character type from literary texts might pose problems even to the human readers [4].", "startOffset": 94, "endOffset": 97}, {"referenceID": 12, "context": "Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].", "startOffset": 79, "endOffset": 83}, {"referenceID": 5, "context": "Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].", "startOffset": 130, "endOffset": 133}, {"referenceID": 0, "context": "Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].", "startOffset": 147, "endOffset": 150}, {"referenceID": 8, "context": "Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].", "startOffset": 162, "endOffset": 165}, {"referenceID": 1, "context": "Extracting these social networks from narrative text has gained much attention [13] in different domains such as literary fiction [6], screenplays [1], or novels [9], [2].", "startOffset": 167, "endOffset": 170}, {"referenceID": 15, "context": "In line with [16], the first task is to identify the parts of the story where that character is involved.", "startOffset": 13, "endOffset": 17}, {"referenceID": 13, "context": "Natural language processing has been applied in the domain of folktales [14], [8].", "startOffset": 72, "endOffset": 76}, {"referenceID": 7, "context": "Natural language processing has been applied in the domain of folktales [14], [8].", "startOffset": 78, "endOffset": 81}, {"referenceID": 11, "context": "Formal models for folktales have been proposed in [12], [15].", "startOffset": 50, "endOffset": 54}, {"referenceID": 14, "context": "Formal models for folktales have been proposed in [12], [15].", "startOffset": 56, "endOffset": 60}, {"referenceID": 16, "context": "Character identification in folktales have been approached in [17], [19].", "startOffset": 62, "endOffset": 66}, {"referenceID": 2, "context": "For a detailed explanation about families of description logics, the reader is referred to [3].", "startOffset": 91, "endOffset": 94}, {"referenceID": 14, "context": "Our folktale ontology formalizes knowledge from three sources: 1) the folktale morphology as described by the Propp model [15]; 2) various entities specific to folktales (i.", "startOffset": 122, "endOffset": 126}, {"referenceID": 14, "context": "a) Folktale morphology: Firstly, we rely on the Propp\u2019s model [15] of the folktale domain.", "startOffset": 62, "endOffset": 66}, {"referenceID": 2, "context": "To facilitate reasoning on the ontology, we allow several extensions of the ALC version of description logics [3].", "startOffset": 110, "endOffset": 113}, {"referenceID": 4, "context": "The NLP component is based on GATE text engineering tool [5], while reasoning in DL on the OWLAPI [10], as depicted by the architecture in Fig.", "startOffset": 57, "endOffset": 60}, {"referenceID": 9, "context": "The NLP component is based on GATE text engineering tool [5], while reasoning in DL on the OWLAPI [10], as depicted by the architecture in Fig.", "startOffset": 98, "endOffset": 102}, {"referenceID": 6, "context": "The Reverb information extraction tool [7] is used to generate triplets containing the following structure: \u3008nominal phrase, verb phrase, nominal phrase\u3009.", "startOffset": 39, "endOffset": 42}, {"referenceID": 17, "context": "In this way, the algorithm interleaves reasoning on ontology with natural language processing based on Japes rules [18].", "startOffset": 115, "endOffset": 119}, {"referenceID": 10, "context": "This situation in which the story is talking about a general character, but only after the main events, the character is finally revealed, is called cataphora [11].", "startOffset": 159, "endOffset": 163}, {"referenceID": 16, "context": "These characters were manually selected from the set of characters output by the character extraction system presented in [17], [19].", "startOffset": 122, "endOffset": 126}, {"referenceID": 16, "context": "The information extracted consists of the character identification, that is presented in [17], [19], and the story involving the character.", "startOffset": 89, "endOffset": 93}, {"referenceID": 18, "context": "Consider a dataset of product reviews or accommodation places in the tourism domain [20].", "startOffset": 84, "endOffset": 88}, {"referenceID": 19, "context": "In this line, the MedEx system [21] aims to extract the medication information from clinical narratives.", "startOffset": 31, "endOffset": 35}, {"referenceID": 3, "context": "With a complexity of O(n) in sentence length of syntactic parsing, our syntactic based on Stanford parser might be too slow for large corpus as the one of 15099 narratives analysed in [4].", "startOffset": 184, "endOffset": 187}], "year": 2015, "abstractText": "Our aim is to extract information about literary characters in unstructured texts. We employ natural language processing and reasoning on domain ontologies. The first task is to identify the main characters and the parts of the story where these characters are described or act. We illustrate the system in a scenario in the folktale domain. The system relies on a folktale ontology that we have developed based on Propp\u2019s model for folktales morphology.", "creator": "TeX"}}}