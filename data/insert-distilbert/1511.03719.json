{"id": "1511.03719", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2015", "title": "Universum Prescription: Regularization Using Unlabeled Data", "abstract": "this paper shows that simply prescribing \" none of the above \" labels to unlabeled data has a beneficial regularization effect to supervised learning. we call it universum prescription by the fact that the globally prescribed labels cannot collectively be one of the supervised labels. in not spite of its simplicity, universum prescription obtained competitive results in simultaneous training deep convolutional networks optimization for cifar - 10, cifar - 100 and stl - 10 datasets. historically a qualitative justification of incorporating these approaches using rademacher complexity is traditionally presented. the marginal effect of a regularization parameter - - probability of sampling from different unlabeled data - - is also studied empirically.", "histories": [["v1", "Wed, 11 Nov 2015 22:46:46 GMT  (99kb,D)", "http://arxiv.org/abs/1511.03719v1", null], ["v2", "Wed, 18 Nov 2015 19:54:22 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v2", null], ["v3", "Sun, 22 Nov 2015 22:12:09 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v3", null], ["v4", "Thu, 21 Jan 2016 06:11:33 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v4", null], ["v5", "Mon, 15 Feb 2016 18:52:30 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v5", null], ["v6", "Mon, 25 Apr 2016 21:10:32 GMT  (99kb,D)", "http://arxiv.org/abs/1511.03719v6", null], ["v7", "Fri, 18 Nov 2016 01:15:30 GMT  (104kb,D)", "http://arxiv.org/abs/1511.03719v7", "7 pages for article, 3 pages for supplemental material. To appear in AAAI-17"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xiang zhang", "yann lecun"], "accepted": true, "id": "1511.03719"}, "pdf": {"name": "1511.03719.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xiang Zhang", "Yann LeCun"], "emails": ["yann}@cs.nyu.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "The idea of exploiting the wide abundance of unlabeled data to improve the accuracy of supervised learning tasks is a very natural one. In this paper, we study what is perhaps the simplest way to exploit unlabeled data in the context of deep learning. We assume that the unlabeled samples do not belong to any of the categories of the supervised task, and we force the classifier to produce a \u201cnone of the above\u201d output for these samples. This is by no means a new idea, but we show empirically and theoretically that doing so has a beneficial regularization effect on supervised task and reduces the generalization gap, the expected difference between the test error and the training error. We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)).\nOur work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006). The definition of universum is a set of unlabeled data that are known not to belong to any of the classes but in the same domain of the training data. We extended the idea of using universum from support vector machines to deep learning.\nUsing unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)). In these approaches, prescribing supervised labels to unlabeled data is part of the overall algorithm. They are the opposite case of universum prescription.\nRepresentation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction.\nThe methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data.\nUniversum prescription is also related to the idea of dark knowledge (Bucilu et al. (2006)) (Hinton et al. (2015)). The idea is to prescribe \u201csoft\u201d targets from an ensemble of models to a single model,\nar X\niv :1\n51 1.\n03 71\n9v 1\n[ cs\n.L G\n] 1\n1 N\nov 2\n01 5\nand improvement on classification accuracy is observed. Our methods prescribe \u201csoft\u201d targets to unlabeled data as well, except that the targets are agnostic to the classification problem.\nRegularization \u2013 techniques for the control of overfitting or generalization gap \u2013 has been studied extensively. Most of the practical approaches implement a secondary optimization objective, such as L1 or L2 norm. Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance.\nAs part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed. There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)). We qualitatively justify the methods using Radamacher complexity (Bartlett & Mendelson (2003)), similar to Wan et al. (2013)."}, {"heading": "2 UNIVERSUM PRESCRIPTION", "text": "In this section we attempt to formalize the the trick of prescribing \u201cnone of the above\u201d labels. We call it universum prescription because these labels could not belong to any supervised class. Consider the problem of exclusive k-way classification. In inference we can find the most probable class y \u2208 {1, 2, . . . , k} given input x. In learning we hope to find a hypothesis function h \u2208 H mapping to Rk so that the label is determined by y = argmini hi(x). The following assumptions are made.\n1. (Loss assumption) The loss used as the optimization objective is negative log-likelihood:\nL(h, x, y) = hy(x) + log [ k\u2211 i=1 exp(\u2212hi(x)) ] . (1)\n2. (Universum assumption) The proportion of samples belonging to one of the k classes in the unlabeled data is negligible.\nThe loss assumption assumes that the probability of class y given an input x can be thought of as\nPr[Y = y|x, h] = exp(\u2212hy(x))\u2211k i=1 exp(\u2212hi(x)) , (2)\nwhere (X,Y ) \u223c D and D is the distribution where labeled data are sampled. We use lowercase letters for values, uppercase letters for random variables and bold uppercase letters for distribution. The loss assumption is simply a necessary detail rather than a limitation.\nThe universum assumption implicates that labeled classes are a negligible subset. In many practical cases we only care about a small number of classes, either by problem design or due to high cost in the labeling process. At the same time, a very large amount of unlabeled data is easily obtained. Put in mathematics, assuming we draw unlabeled data from distribution U, the assumption states that\nPr (X,Y )\u223cU\n[X,Y \u2208 {1, 2, . . . , k}] \u2248 0. (3)\nThis is opposite to the assumptions of information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)). All the methods discussed below prescribe agnostic targets to the unlabeled data. During learning, we randomly present an unlabeled sample to the optimization procedure with probability p."}, {"heading": "2.1 UNIFORM PRESCRIPTION", "text": "It is known that negative log-likelihood is simply a reduced form of cross-entropy\nL(h, x, y) = \u2212 k\u2211 i=1 Q[Y = i|x] log Pr[Y = i|x, h] (4)\nin which the target probabilityQ[Y = y|x] = 1 andQ[Y = i|x] = 0 for i 6= y. Under the universum assumption, if we are presented with an unlabeled sample x, we would hope to prescribe some Q so\nthat every class has some equally minimal probability. Q also has to satisfy \u2211k i=1Q[Y = i|x] = 1 by the probability axioms. The only possible choice for Q is then Q[Y |x] = 1/k. The learning algorithm then uses the cross-entropy loss instead of negative log-likelihood.\nIt is worth noting that uniform output has the maximum entropy among all possible choices. In the case that the hypothesis h is parameterized as a deep neural network, uniform output is achieved when these parameters are constantly 0. Therefore, uniform prescription may have the effect of reducing the magnitude of parameters, similar to norm-based regularization."}, {"heading": "2.2 DUSTBIN CLASS", "text": "Another way of prescribing agnostic target is to append a \u201cdustbin\u201d class to the supervised task. This requires some changes to the hypothesis function h such that it outputs k + 1 targets. For deep learning models one can simply extend the last parameterized layer. All unlabeled data are prescribed to this extra \u201cdustbin\u201d class. The learning algorithm remains unchanged.\nThe effect of dustbin class is clearly seen in the loss function of an unlabeled sample (x, k + 1)\nL(h, x, k + 1) = hk+1(x) + log [ k+1\u2211 i=1 exp(\u2212hi(x)) ] . (5)\nThe second term is a \u201csoft\u201d maximum for all dimensions of \u2212h. When an unlabeled sample is present, the algorithm attempts to introduce smoothness by minimizing probability spikes."}, {"heading": "2.3 BACKGROUND CLASS", "text": "We could further simplify dustbin class by removing parameters for class k + 1. For some given threshold constant \u03c4 , we could change the probability of a labeled sample to\nPr[Y = y|x, h] = exp(\u2212hy(x)) exp(\u2212\u03c4) + \u2211k i=1 exp(\u2212hi(x)) , (6)\nand an unlabeled sample\nPr[Y = k + 1|x, h] = exp(\u2212\u03c4) exp(\u2212\u03c4) + \u2211k i=1 exp(\u2212hi(x)) . (7)\nThis will result in changes to the loss function of a labeled sample (x, y) as\nL(h, x, y) = hy(x) + log\n[ exp(\u2212\u03c4) +\nk\u2211 i=1 exp(\u2212hi(x))\n] , (8)\nand an unlabeled sample\nL(h, x, k + 1) = \u03c4 + log [ exp(\u2212\u03c4) +\nk\u2211 i=1 exp(\u2212hi(x))\n] . (9)\nWe call this method background class and \u03c4 background constant. Similar to dustbin class, the algorithm attempts to minimize the spikes of outputs, but limited to a certain extent by the inclusion of exp(\u2212\u03c4) in the partition function. In our experiments \u03c4 is always set to 0."}, {"heading": "3 THEORETICAL JUSTIFICATION", "text": "In this part, we derive a qualitative justification for universum prescription using probably approximately correct (PAC) learning (Valiant (1984)). By a \u201cqualitative\u201d theory, we are comparing with numerical or combinatorial bounds such as growth function (Massart (2000), Vapnik (1998)), VapnikChervonenkis dimension (Vapnik & Chervonenkis (1971)), covering numbers (Dudley (1967)) and others. Our theory is based on Rademacher complexity (Bartlett & Mendelson (2003)), similar to the work by Wan et al. (2013) in which both dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) are justified. Rademacher complexity is usually a lower-bound of other numerical or combinatorial complexity measurement, therefore our qualitative intuition is more accurate using it.\nDefinition 1 (Empirical Rademacher complexity). Let F be a family of functions mapping from U to R, and S = (x1, x2, . . . , xm) a fixed sample of size m with elements in X . Then, the empirical Rademacher complexity of F with respect to the sample S is defined as:\nR\u0302S(F) = E \u03b7 [ sup f\u2208F 1 m m\u2211 i=1 \u03b7if(xi) ] (10)\nwhere \u03b7 = (\u03b71, . . . , \u03b7m)T , with \u03b7i\u2019s independent random variables taking values from a discrete uniform distribution on {\u22121, 1}. Definition 2 (Rademacher complexity). Let D denote the distribution from which the samples were drawn. For any integer m \u2265 1, the Rademacher complexity of F is the expectation of the empirical Rademacher complexity over all samples of size m drawn according to D:\nRm(F ,D) = E S\u223cDm [R\u0302S(F )] (11)\nIt could be argued that the distribution for \u03b7 is arbitrary. There are other possiblities such as Gaussian complexity (Bartlett & Mendelson (2003)), but they can all be generalized to stochastic compexity as in Zhang (2013) and result in the same conclusions. In the case that f has multiple outputs, one can simply add the complexity measurements for each outputs together and the theory still holds.\nTwo qualitative properties of Rademacher complexity is worth noting here. First of all, Rademacher complexity is always non-negative by the convexity of supremum\nR\u0302S(F) = E \u03b7 [ sup f\u2208F 1 m m\u2211 i=1 \u03b7if(xi) ] \u2265 sup f\u2208F 1 m m\u2211 i=1 E \u03b7i [\u03b7i]f(xi) = 0. (12)\nSecondly, if for a fixed input all functions in F output the same value, then it\u2019s Rademacher complexity is 0. Assume for any f \u2208 F we have f(x) = f0(x), then\nR\u0302S(F) = E \u03b7 [ sup f\u2208F 1 m m\u2211 i=1 \u03b7if(xi) ] = E \u03b7 [ sup f\u2208F 1 m m\u2211 i=1 \u03b7if0(x) ] = 1 m m\u2211 i=1 E \u03b7i [\u03b7i]f0(x) = 0. (13)\nTherefore, one way to qualitatively minimize Rademacher complexity is to regularize functions in F such that all functions tend to have the same output for a given input. Universum prescription precisely does that \u2013 the prescribed outputs for unlabeled data are all constantly the same.\nThe principal PAC-learning result from literature is an approximation bound for function spaces that has finite bounds for outputs. We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000). We refer the reader to these publications for proof. Theorem 1 (Approximation bound with finite bound on output). For a well-defined objective E(h, x, y) over hypothesis class H, input set X and output set Y , if it has an upper bound M > 0, then with probability at least 1\u2212 \u03b4, the following holds for all hypothesis h \u2208 H:\nE (x,y)\u223cD [E(h, x, y)] \u2264 1 m \u2211 (x,y)\u2208S E(h, x, y) + 2Rm(F ,D) +M \u221a log 2\u03b4 2m , (14)\nwhere the function family F is defined as\nF = {E(h, x, y)|h \u2208 H} , (15)\nD is a distribution on the samples (x, y), and S is a set of samples of size m drawn indentically and independently from D.\nIn the theorem above, the objective functional E(h, x, y) should be lower-bounded by 0, and it corresponds to a negatively correlated compatibility measurement between a hypothesis h and a sample (x, y). It is similar to the definition of energy used by energy-based learning in LeCun et al. (2006). It could be the error function E(h, x, y) = 1 \u2212 1{y = argmini(hi(x))}, the exponential function E(h, x, y) = exp(hy(x)), the negative probability function E(h, x, y) = 1 \u2212 Pr[Y = y|x, h], or simply the loss E(h, x, y) = L(h, x, y).\nCIFAR-10 0.00 7.02 7.02 0.72 7.59 6.87 0.07 6.66 6.59 1.35 8.38 7.03 CIFAR-100 F. 0.09 37.58 37.49 4.91 36.23 31.32 2.52 32.84 30.32 8.56 40.57 42.01 CIFAR-100 C. 0.04 22.74 22.70 0.67 23.42 22.45 0.40 20.45 20.05 3.73 24.97 21.24 STL-10 0.00 31.16 31.16 2.02 36.54 34.52 3.03 36.58 33.55 14.89 38.95 24.06 STL-10 Tiny. 0.00 31.16 31.16 0.62 30.15 29.47 0.00 27.96 27.96 0.11 30.38 30.27\nFor some choices of E we have a bound E(h, x, y) \u2264 M by design, whereas for some others it is more intricate to believe M exists. If the learning algorithm is an iterative optimization procedure such as gradient descent, at each step one could believe that a limit M exists relatively to the current hypothesis h0 (Zhang (2013)). This is because of the dynamics of iterative optimization \u2013 the algorithm can only explore some sublevel hypothesis setH0 in later steps. The meaning of the theorem is two-folded. When applying the theorem to the joint problem of training using both labeled and unlabeled data, the third term on the right hand of inequality 14 is reduced by the augmentation of the extra data. The joint problem can be written as (x, y) \u223c (1\u2212 p)D+ pU. The value of the term Rm(F , (1\u2212 p)D+ pU) is also reduced when we prescribe constant outputs, due to the qualitative properties of Rademacher complexity discussed before.\nThe second fold is that when the theorem applies to the supervised distribution D, we would hope that Rm(F ,D) can be bounded by Rm(F , (1 \u2212 p)D + pU) and Rm(F ,U). It turns out that a weighted sum of Ri(F ,D), i = 1, 2, . . . ,m is bounded. Theorem 2 (Rademacher complexity bound on distribution mixture). Let P (m, i) = \u2211m i=0 ( m i ) (1\u2212\np)m\u2212ipi im and Q(m, i) = \u2211m i=0 ( m i ) (1\u2212 p)ipm\u2212i im , we have\nm\u2211 i=1 Q(m, i)Ri(F ,D) \u2264 Rm(F , (1\u2212 p)D+ pU) + m\u2211 i=1 P (m, i)Ri(F ,U) (16)\nTable 1: ConvNet for section 4\nLAYERS DESCRIPTION\n1-3 Conv 256x3x3 4 Pool 2x2 5-8 Conv 512x3x3 9 Pool 2x2 10-13 Conv 1024x3x3 14 Pool 2x2 15-18 Conv 1024x3x3 19 Pool 2x2 20-23 Conv 2048x3x3 24 Pool 2x2 25-26 Full 2048\nThe proof of theorem 2 is in supplemental material. We also show that \u2211m i=0 P (m, i) \u2264 1 and \u2211m i=0Q(m, i) \u2264 1. The derivation above tells us that a weighted sum of the Rademacher complexity of the supervised problems for dataset size from 1 tom is bounded by the joint problem of sizem and a weighted sum of unsupervised problems. Therefore, for different sample sizes of labeled and unlabeled data, universum prescription may bring improvement for generalization."}, {"heading": "4 EXPERIMENTS ON IMAGE CLASSIFICATION", "text": "In this section we test the methods on some image classification tasks. Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as the non-linearity after all convolutional and linear layers. Two dropout (Srivastava et al. (2014)) layers of probability 0.5 are inserted before the final two linear layers. The algorithm used is stochastic\ngradient descent with momentum (Polyak (1964), Sutskever et al. (2013)) 0.9 and a minibatch size of 32. The initial learning rate is 0.005 which is halved every 60,000 minibatch steps. The training stops at 400,000 minibatch steps. Table 1 summarizes the configurations. For a convolutional layer the number of output feature maps is shown, and for a linear layer the number of hidden units. The weights are initialized in the same way as He et al. (2015).\nThe initial motivation for choosing such a big network is to make sure it will have enough capacity for overfitting so that the effect of regularization is clearly shown. However, in practice such a large network already has a very good baseline even without universum prescription. This is probably due to the data augmentation steps below, which are used in all our experiments.\n1. (Horizontal flip.) Flip the image horizontally with probability 0.5.\n2. (Scale.) Randomly scale the image between 1/1.2 and 1.2 times of its height and width.\n3. (Crop.) Randomly crop a 32-by-32 region in the scaled image.\n4. (Rotation.) Randomly rotate between \u2212\u03c0/6 and \u03c0/6 radians."}, {"heading": "4.1 CIFAR-10 AND CIFAR-100", "text": "The samples of CIFAR-10 and CIFAR-100 datasets (Krizhevsky (2009)) are from the 80 million tiny images dataset (Torralba et al. (2008)). Each dataset contains 60,000 samples, consitituting a very small portion of 80 million. This is an ideal case for our methods, in which we can use the entire 80 million images as the unlabeled data. The CIFAR-10 dataset has 10 classes, and CIFAR100 has 20 (coarse) or 100 (fine-grained) classes. Table 2 contains the results. The generalization gap is approximated by the difference between testing and training errors. All of the universum prescription models use unlabeled data with probability p = 0.2.\nTable 3: Comparison of single-model CIFAR-10 and CIFAR-100 results, in second and third columns. The fourth column indicates whether data augmentation is used for CIFAR-10. The numbers are percentages.\nMETHOD 10 100 AUG.\nuniversum prescription 6.66 32.84 YES Graham (2014) 6.28 24.30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.38 38.57 YES Wan et al. (2013) 11.10 N/A NO Zeiler & Fergus (2013) 15.13 42.51 NO\nWe compared other single-model results on CIFAR-10 and CIFAR-100 (fine-grained case) in table 3. It shows that our network is competitive to the state of the art."}, {"heading": "4.2 STL-10", "text": "The STL-10 dataset (Coates et al. (2011)) has size 96-by-96 for its images. We downsampled them to 32- by-32 so as to use the same model. The dataset contains a very small number of training samples \u2013 5000 in total. The accompanying unlabeled dataset is larger with 100,000 samples. There is no guarantee that these extra samples are outside of the supervised training classes. Both the dataset size and failure to comply with universum assumption might be the reason why universum prescription failed.\nTo verify that the extra data is the problem, we also performed an experiment using the 80 million tiny images as the unlabeled dataset, as shown in table 2. Due to long training times of our models, we did not perform 10-fold training as in the original paper by Coates et al. (2011), therefore our result is not comparable to those in the literature. We present them only to show the effectiveness of universum prescription influenced by the universum assumption on the unlabled data."}, {"heading": "5 EFFECT OF THE REGULARIZATION PARAMETER", "text": "One natural question to ask of our models is how would change of the probability p of sampling from unlabeled data affect the results. In this section we show the experiments. To prevent an exhaustive search on the regularization parameter from overfitting our models on the testing data, we use a different model for this section. It is described in table 4, which has 9 parameterized layers in total.\nThe design is inspired by Sermanet et al. (2013). For each choice of p we conducted 6 experiments combining universum prescription models and dropout. The dropout layers are two ones added in between the fully-connected layers with dropout probability 0.5. Figure 1 shows the results.\nFrom figure 1 we can conclude that increasing p will descrease generalization gap. However, we cannot make p too large since after a certain point the training collapses and both training and testing errors become worse. Comparing between CIFAR-10/100 and STL-10, the model variance is affected by the combined size of labeled and unlabeled datasets.\n6 CONCLUSION AND OUTLOOK\nThis article shows that universum prescription can be used to regularize a multi-class classification problem using extra unlabeled data. Two assumptions are made, in which one is that loss used is negative log-likelihood and the other is negligible probability of a supervised sample existing in the unlabeled data. The loss assumption is a necessary detail rather than a limitation. The three universum prescription methods are uniform prescription, dustbin class and background class. We further provided a theoretical justification. Experiments are done using CIFAR-10, CIFAR-100 and STL-10 datasets. The effect of the regularization parameter is also studied empirically. In the future, we hope to apply these methods to a broader range of problems."}, {"heading": "ACKNOWLEDGMENTS", "text": "We gratefully acknowledge the support of NVIDIA Corporation with the donation of 2 Tesla K40 GPUs used for this research. Sainbayar Sukhbaatar offered many useful comments. Aditya Ramesh and Junbo Zhao helped cross-checking the proofs."}, {"heading": "APPENDIX: PROOF OF THEOREM 2", "text": "Lemma 1 (Separation of dataset on empirical Rademacher complexity). Let S be a dataset of size m. If S1 and S2 are two non-overlap subset of S such that |S1| = m\u2212 i, |S2| = i and S1 \u222a S2 = S, then\nR\u0302S(F) \u2265 m\u2212 i m R\u0302S1(F)\u2212 i m R\u0302S2(F) (17)\nProof. Let (xj , yj) \u2208 S1 for j = 1, 2, . . . ,m \u2212 i and (xj , yj) \u2208 S2 for i = m \u2212 j + 1,m \u2212 j + 2, . . . ,m. Denote N as the discrete uniform distribution on {1,\u22121}. We can derive by the convexity of supremum and symmetry of N\nR\u0302S1(F) = E \u03b7\u223cNm\u2212i [ sup f\u2208F 1 m\u2212 i m\u2212i\u2211 j=1 \u03b7jf(xj) ]\n= 2\nm\u2212 i E\u03b7\u223cNm\u2212i [ sup f\u2208F 1 2 m\u2212i\u2211 j=1 \u03b7jf(xj) ]\n= 2\nm\u2212 i E\u03b7\u223cNm [ sup f\u2208F ( 1 2 m\u2212i\u2211 j=1 \u03b7jf(xj) + 1 2 m\u2211 j=m\u2212i+1 \u03b7jf(xj)\u2212 1 2 m\u2211 j=m\u2212i+1 \u03b7jf(xj) )]\n= 2\nm\u2212 i E\u03b7\u223cNm [ sup f\u2208F ( 1 2 m\u2211 j=1 \u03b7jf(xj)\u2212 1 2 m\u2211 j=m\u2212i+1 \u03b7jf(xj) )]\n\u2264 2 m\u2212 i E\u03b7\u223cNm\n[ 1\n2 sup f\u2208F\n( m\u2211\nj=1\n\u03b7jf(xj) ) + 1\n2 sup f\u2208F\n( m\u2211\nj=m\u2212i+1\n\u2212\u03b7jf(xj)\n)]\n= m\nm\u2212 i E\u03b7\u223cNm [ sup f\u2208F 1 m m\u2211 j=1 \u03b7jf(xj) ] + i m\u2212 i E\u03b7\u223cNi [ sup f\u2208F 1 i m\u2211 j=m\u2212i+1 \u2212\u03b7jf(xj) ]\n= m\nm\u2212 i E\u03b7\u223cNm [ sup f\u2208F 1 m m\u2211 j=1 \u03b7jf(xj) ] + i m\u2212 i E\u03b7\u223cNi [ sup f\u2208F 1 i m\u2211 j=m\u2212i+1 \u03b7jf(xj) ]\n= m m\u2212 i R\u0302S(F) + i m\u2212 i R\u0302S2(F).\nThe lemma is obtained by directly transforming the inequality above.\nFor any function space F and distribution D, denote R0(F ,D) = 0 and R\u0302\u2205(F) = 0. Define P (m, i) =\u2211m i=0 ( m i ) (1\u2212p)m\u2212ipi i m andQ(m, i) = \u2211m i=0 ( m i ) (1\u2212p)ipm\u2212i i m . By definition of Rademacher complexity and lemma 1, we get\nRm(F , (1\u2212 p)D+ pU) = E S\u223c((1\u2212p)D+pU)m [R\u0302S(F )]\n= m\u2211 i=0\n( m\ni\n) (1\u2212 p)m\u2212ipi E\nS1\u223cDm\u2212i\n[ E\nS2\u223cUi [R\u0302S1\u222aS2(F )]\n]\n\u2265 m\u2211 i=0\n( m\ni\n) (1\u2212 p)m\u2212ipi E\nS1\u223cDm\u2212i\n[ E\nS2\u223cUi\n[ m\u2212 i m R\u0302S1(F)\u2212 i m R\u0302S2(F) ]]\n= m\u2211 i=0\n( m\ni\n) (1\u2212 p)m\u2212ipi [ m\u2212 i m E S1\u223cDm\u2212i [ R\u0302S1(F) ] \u2212 i m E S2\u223cUi [ R\u0302S2(F) ]]\n= m\u2211 i=0\n( m\ni\n) (1\u2212 p)m\u2212ipi [ m\u2212 i m Rm\u2212i(F ,D)\u2212 i m Ri(F ,U) ]\n= [ m\u2211 i=0 Q(m,m\u2212 i)Rm\u2212i(F ,D) ] \u2212 [ m\u2211 i=0 P (m, i)Ri(F ,U) ]\n= [ m\u2211 i=1 Q(m, i)Ri(F ,D) ] \u2212 [ m\u2211 i=1 P (m, i)Ri(F ,U) ] .\nTheorem 2 is therefore established. The fact that \u2211m i=0Q(m, i) \u2264 1 and \u2211m\ni=0 P (m, i) \u2264 1 is evident from the proof by each term being less than a term of the binomial expansion."}], "references": [{"title": "Learning from hints in neural networks", "author": ["Abu-Mostafa", "Yaser S"], "venue": "Journal of complexity,", "citeRegEx": "Abu.Mostafa and S.,? \\Q1990\\E", "shortCiteRegEx": "Abu.Mostafa and S.", "year": 1990}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Bartlett", "Peter L", "Mendelson", "Shahar"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bartlett et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2003}, {"title": "Model selection and error estimation", "author": ["Bartlett", "Peter L", "Boucheron", "St\u00e9phane", "Lugosi", "G\u00e1bor"], "venue": "Machine Learning,", "citeRegEx": "Bartlett et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2002}, {"title": "A model of inductive bias learning", "author": ["Baxter", "Jonathan"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "Baxter and Jonathan.,? \\Q2000\\E", "shortCiteRegEx": "Baxter and Jonathan.", "year": 2000}, {"title": "Scaling learning algorithms towards ai", "author": ["Bengio", "Yoshua", "LeCun", "Yann"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Representation learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pierre"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Multitask learning: A knowledge-based source of inductive bias", "author": ["Caruana", "Richard"], "venue": "In Proceedings of the Tenth International Conference on Machine Learning,", "citeRegEx": "Caruana and Richard.,? \\Q1993\\E", "shortCiteRegEx": "Caruana and Richard.", "year": 1993}, {"title": "A Discussion of Semi-Supervised Learning and Transduction, pp. 473\u2013478", "author": ["O. Chapelle", "B. Schlkopf", "A. Zien"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "Semi-supervised learning. Adaptive computation and machine learning", "author": ["Chapelle", "Olivier", "Schlkopf", "Bernhard", "Zien", "Alexander"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["Coates", "Adam", "Ng", "Andrew Y", "Lee", "Honglak"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Data dependent regularization", "author": ["Corduneanu", "Adrian", "Jaakkola", "Tommi"], "venue": null, "citeRegEx": "Corduneanu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Corduneanu et al\\.", "year": 2006}, {"title": "The sizes of compact subsets of hilbert space and continuity of gaussian processes", "author": ["Dudley", "Richard M"], "venue": "Journal of Functional Analysis,", "citeRegEx": "Dudley and M.,? \\Q1967\\E", "shortCiteRegEx": "Dudley and M.", "year": 1967}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["Erhan", "Dumitru", "Bengio", "Yoshua", "Courville", "Aaron", "Manzagol", "Pierre-Antoine", "Vincent", "Pascal", "Samy"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Erhan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "Learning by transduction", "author": ["Gammerman", "Alexander", "Vovk", "Volodya", "Vapnik", "Vladimir"], "venue": "In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "Gammerman et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Gammerman et al\\.", "year": 1998}, {"title": "Neural networks and the bias/variance dilemma", "author": ["Geman", "Stuart", "Bienenstock", "Elie", "Doursat", "Ren\u00e9"], "venue": "Neural computation,", "citeRegEx": "Geman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Geman et al\\.", "year": 1992}, {"title": "Spatially-sparse convolutional neural networks", "author": ["Graham", "Benjamin"], "venue": "CoRR, abs/1409.6070,", "citeRegEx": "Graham and Benjamin.,? \\Q2014\\E", "shortCiteRegEx": "Graham and Benjamin.", "year": 2014}, {"title": "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "arXiv preprint arXiv:1502.01852,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Distilling the knowledge in a neural network", "author": ["Hinton", "Geoffrey", "Vinyals", "Oriol", "Dean", "Jeff"], "venue": "arXiv preprint arXiv:1503.02531,", "citeRegEx": "Hinton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey E", "Osindero", "Simon", "Teh", "Yee-Whye"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Rademacher penalties and structural risk minimization", "author": ["Koltchinskii", "Vladimir"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Koltchinskii and Vladimir.,? \\Q2001\\E", "shortCiteRegEx": "Koltchinskii and Vladimir.", "year": 2001}, {"title": "Rademacher processes and bounding the risk of function learning. In High dimensional probability II, pp. 443\u2013457", "author": ["Koltchinskii", "Vladimir", "Panchenko", "Dmitriy"], "venue": null, "citeRegEx": "Koltchinskii et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Koltchinskii et al\\.", "year": 2000}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex"], "venue": null, "citeRegEx": "Krizhevsky and Alex.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Alex.", "year": 2009}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "A tutorial on energybased learning", "author": ["LeCun", "Yann", "Chopra", "Sumit", "Hadsell", "Raia", "Ranzato", "Marc\u2019Aurelio", "Huang", "Fu-Jie"], "venue": null, "citeRegEx": "LeCun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2006}, {"title": "Deeply-supervised nets", "author": ["Lee", "Chen-Yu", "Xie", "Saining", "Gallagher", "Patrick", "Zhang", "Zhengyou", "Tu", "Zhuowen"], "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Some applications of concentration inequalities to statistics", "author": ["Massart", "Pascal"], "venue": "In Annales de la Faculte\u0301 des sciences de Toulouse: Mathe\u0301matiques,", "citeRegEx": "Massart and Pascal.,? \\Q2000\\E", "shortCiteRegEx": "Massart and Pascal.", "year": 2000}, {"title": "Skeletonization: A technique for trimming the fat from a network via relevance assessment", "author": ["Mozer", "Michael C", "Smolensky", "Paul"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mozer et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Mozer et al\\.", "year": 1989}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Nair", "Vinod", "Hinton", "Geoffrey E"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Nair et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2010}, {"title": "Some methods of speeding up the convergence of iteration methods", "author": ["B.T. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "Polyak,? \\Q1964\\E", "shortCiteRegEx": "Polyak", "year": 1964}, {"title": "Efficient learning of sparse representations with an energy-based model", "author": ["Ranzato", "Marc\u2019Aurelio", "Poultney", "Christopher", "Chopra", "Sumit", "LeCun", "Yann"], "venue": "In et al., J. Platt (ed.), Advances in Neural Information Processing Systems (NIPS 2006),", "citeRegEx": "Ranzato et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2006}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Sermanet", "Pierre", "Eigen", "David", "Zhang", "Xiang", "Mathieu", "Micha\u00ebl", "Fergus", "Rob", "LeCun", "Yann"], "venue": "CoRR, abs/1312.6229,", "citeRegEx": "Sermanet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sermanet et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "Simonyan and Zisserman,? \\Q2014\\E", "shortCiteRegEx": "Simonyan and Zisserman", "year": 2014}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Symbolic-neural systems and the use of hints for developing complex systems", "author": ["Suddarth", "Steven C", "Holden", "Alistair DC"], "venue": "International Journal of Man-Machine Studies,", "citeRegEx": "Suddarth et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Suddarth et al\\.", "year": 1991}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Sutskever", "Ilya", "Martens", "James", "Dahl", "George", "Hinton", "Geoffrey"], "venue": "In Proceedings of the 30th international conference on machine learning", "citeRegEx": "Sutskever et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2013}, {"title": "Learning to Learn", "author": ["Thrun", "Sebastian", "Pratt", "Lorien (eds"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1998}, {"title": "80 million tiny images: A large data set for nonparametric object and scene recognition", "author": ["Torralba", "Antonio", "Fergus", "Rob", "Freeman", "William T"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Torralba et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 1958}, {"title": "A theory of the learnable", "author": ["Valiant", "Leslie G"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant and G.,? \\Q1984\\E", "shortCiteRegEx": "Valiant and G.", "year": 1984}, {"title": "The Nature of Statistical Learning Theory", "author": ["Vapnik", "Vladimir N"], "venue": null, "citeRegEx": "Vapnik and N.,? \\Q1995\\E", "shortCiteRegEx": "Vapnik and N.", "year": 1995}, {"title": "Estimation of Dependences Based on Empirical Data", "author": ["Vapnik", "Vladimir N"], "venue": null, "citeRegEx": "Vapnik and N.,? \\Q2006\\E", "shortCiteRegEx": "Vapnik and N.", "year": 2006}, {"title": "On the uniform convergence of relative frequencies of events to their probabilities", "author": ["Vapnik", "Vladimir N", "Chervonenkis", "A Ya"], "venue": "Theory of Probability & Its Applications,", "citeRegEx": "Vapnik et al\\.,? \\Q1971\\E", "shortCiteRegEx": "Vapnik et al\\.", "year": 1971}, {"title": "Regularization of neural networks using dropconnect", "author": ["Wan", "Li", "Zeiler", "Matthew", "Zhang", "Sixin", "LeCun", "Yann", "Fergus", "Rob"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Inference with the universum", "author": ["Weston", "Jason", "Collobert", "Ronan", "Sinz", "Fabian", "Bottou", "L\u00e9on", "Vapnik", "Vladimir"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Weston et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2006}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "CoRR, abs/1301.3557,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}, {"title": "Pac-learning for energy-based models", "author": ["Zhang", "Xiang"], "venue": "Master\u2019s thesis,", "citeRegEx": "Zhang and Xiang.,? \\Q2013\\E", "shortCiteRegEx": "Zhang and Xiang.", "year": 2013}, {"title": "Introduction to semi-supervised learning", "author": ["Zhu", "Xiaojin", "Goldberg", "Andrew B"], "venue": "Synthesis lectures on artificial intelligence and machine learning,", "citeRegEx": "Zhu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)).", "startOffset": 270, "endOffset": 291}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)).", "startOffset": 270, "endOffset": 388}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006).", "startOffset": 270, "endOffset": 484}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006).", "startOffset": 270, "endOffset": 516}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006). The definition of universum is a set of unlabeled data that are known not to belong to any of the classes but in the same domain of the training data.", "startOffset": 270, "endOffset": 534}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009).", "startOffset": 115, "endOffset": 139}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al.", "startOffset": 115, "endOffset": 165}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al.", "startOffset": 115, "endOffset": 249}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al.", "startOffset": 115, "endOffset": 301}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)).", "startOffset": 115, "endOffset": 327}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 69}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 95}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 140}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al.", "startOffset": 48, "endOffset": 229}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al.", "startOffset": 48, "endOffset": 250}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task.", "startOffset": 48, "endOffset": 272}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2).", "startOffset": 48, "endOffset": 598}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2).", "startOffset": 48, "endOffset": 615}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data.", "startOffset": 48, "endOffset": 776}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data.", "startOffset": 48, "endOffset": 803}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data. Universum prescription is also related to the idea of dark knowledge (Bucilu et al. (2006)) (Hinton et al.", "startOffset": 48, "endOffset": 969}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data. Universum prescription is also related to the idea of dark knowledge (Bucilu et al. (2006)) (Hinton et al. (2015)).", "startOffset": 48, "endOffset": 992}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al.", "startOffset": 36, "endOffset": 61}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance.", "startOffset": 36, "endOffset": 97}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed.", "startOffset": 36, "endOffset": 228}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed.", "startOffset": 36, "endOffset": 243}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed. There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al.", "startOffset": 36, "endOffset": 400}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)).", "startOffset": 142, "endOffset": 162}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)).", "startOffset": 142, "endOffset": 231}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)). We qualitatively justify the methods using Radamacher complexity (Bartlett & Mendelson (2003)), similar to Wan et al.", "startOffset": 142, "endOffset": 327}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)). We qualitatively justify the methods using Radamacher complexity (Bartlett & Mendelson (2003)), similar to Wan et al. (2013).", "startOffset": 142, "endOffset": 358}, {"referenceID": 7, "context": "This is opposite to the assumptions of information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al.", "startOffset": 124, "endOffset": 148}, {"referenceID": 7, "context": "This is opposite to the assumptions of information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)).", "startOffset": 124, "endOffset": 174}, {"referenceID": 41, "context": "Our theory is based on Rademacher complexity (Bartlett & Mendelson (2003)), similar to the work by Wan et al. (2013) in which both dropout (Srivastava et al.", "startOffset": 99, "endOffset": 117}, {"referenceID": 33, "context": "(2013) in which both dropout (Srivastava et al. (2014)) and dropconnect (Wan et al.", "startOffset": 30, "endOffset": 55}, {"referenceID": 33, "context": "(2013) in which both dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) are justified.", "startOffset": 30, "endOffset": 91}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 91}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 120}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 141}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000). We refer the reader to these publications for proof.", "startOffset": 68, "endOffset": 177}, {"referenceID": 22, "context": "It is similar to the definition of energy used by energy-based learning in LeCun et al. (2006). It could be the error function E(h, x, y) = 1 \u2212 1{y = argmini(hi(x))}, the exponential function E(h, x, y) = exp(hy(x)), the negative probability function E(h, x, y) = 1 \u2212 Pr[Y = y|x, h], or simply the loss E(h, x, y) = L(h, x, y).", "startOffset": 75, "endOffset": 95}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data.", "startOffset": 70, "endOffset": 91}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al.", "startOffset": 70, "endOffset": 233}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded.", "startOffset": 70, "endOffset": 254}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded.", "startOffset": 70, "endOffset": 295}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as the non-linearity after all convolutional and linear layers.", "startOffset": 70, "endOffset": 462}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as the non-linearity after all convolutional and linear layers. Two dropout (Srivastava et al. (2014)) layers of probability 0.", "startOffset": 70, "endOffset": 574}, {"referenceID": 28, "context": "gradient descent with momentum (Polyak (1964), Sutskever et al.", "startOffset": 32, "endOffset": 46}, {"referenceID": 28, "context": "gradient descent with momentum (Polyak (1964), Sutskever et al. (2013)) 0.", "startOffset": 32, "endOffset": 71}, {"referenceID": 16, "context": "The weights are initialized in the same way as He et al. (2015). The initial motivation for choosing such a big network is to make sure it will have enough capacity for overfitting so that the effect of regularization is clearly shown.", "startOffset": 47, "endOffset": 64}, {"referenceID": 37, "context": "1 CIFAR-10 AND CIFAR-100 The samples of CIFAR-10 and CIFAR-100 datasets (Krizhevsky (2009)) are from the 80 million tiny images dataset (Torralba et al. (2008)).", "startOffset": 137, "endOffset": 160}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.", "startOffset": 7, "endOffset": 25}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.", "startOffset": 7, "endOffset": 58}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.", "startOffset": 7, "endOffset": 98}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.38 38.57 YES Wan et al. (2013) 11.", "startOffset": 7, "endOffset": 131}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.38 38.57 YES Wan et al. (2013) 11.10 N/A NO Zeiler & Fergus (2013) 15.", "startOffset": 7, "endOffset": 167}, {"referenceID": 9, "context": "2 STL-10 The STL-10 dataset (Coates et al. (2011)) has size 96-by-96 for its images.", "startOffset": 29, "endOffset": 50}, {"referenceID": 9, "context": "2 STL-10 The STL-10 dataset (Coates et al. (2011)) has size 96-by-96 for its images. We downsampled them to 32by-32 so as to use the same model. The dataset contains a very small number of training samples \u2013 5000 in total. The accompanying unlabeled dataset is larger with 100,000 samples. There is no guarantee that these extra samples are outside of the supervised training classes. Both the dataset size and failure to comply with universum assumption might be the reason why universum prescription failed. To verify that the extra data is the problem, we also performed an experiment using the 80 million tiny images as the unlabeled dataset, as shown in table 2. Due to long training times of our models, we did not perform 10-fold training as in the original paper by Coates et al. (2011), therefore our result is not comparable to those in the literature.", "startOffset": 29, "endOffset": 795}, {"referenceID": 31, "context": "The design is inspired by Sermanet et al. (2013). For each choice of p we conducted 6 experiments combining universum prescription models and dropout.", "startOffset": 26, "endOffset": 49}], "year": 2017, "abstractText": "This paper shows that simply prescribing \u201cnone of the above\u201d labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR100 and STL-10 datasets. A qualitative justification of these approaches using Rademacher complexity is presented. The effect of a regularization parameter \u2013 probability of sampling from unlabeled data \u2013 is also studied empirically.", "creator": "LaTeX with hyperref package"}}}