{"id": "1511.04317", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Nov-2015", "title": "Novel Feature Extraction, Selection and Fusion for Effective Malware Family Classification", "abstract": "modern malware is designed with mutation characteristics, namely serial polymorphism and metamorphism, which causes an enormous growth in the number of variants of malware samples. categorization of malware samples on the cellular basis of their behaviors is essential primarily for the computer security community in order to group samples likely belonging to same family. microsoft released a malware prototype classification challenge exercise in 2015 ending with a huge dataset of near 0. 5 terabytes of data, containing more than 20k malware samples. the analysis of this dataset inspired the development of of a novel paradigm that is effective in categorizing malware variants into their actual family groups. this paradigm is presented and discussed in the present paper, where emphasis has been given to the phases related to the extraction, and selection of a set of novel features for the effective representation of malware samples. features can be grouped according to different characteristics of malware behavior, and their fusion is performed according strongly to a weak per - class weighting paradigm. the proposed method achieved a very high accuracy ( $ \\ approx $ 0. 998 ) on the microsoft malware challenge dataset.", "histories": [["v1", "Fri, 13 Nov 2015 15:33:02 GMT  (6463kb,D)", "http://arxiv.org/abs/1511.04317v1", null], ["v2", "Thu, 10 Mar 2016 10:21:15 GMT  (6794kb,D)", "http://arxiv.org/abs/1511.04317v2", null]], "reviews": [], "SUBJECTS": "cs.CR cs.AI", "authors": ["mansour ahmadi", "dmitry ulyanov", "stanislav semenov", "mikhail trofimov", "giorgio giacinto"], "accepted": false, "id": "1511.04317"}, "pdf": {"name": "1511.04317.pdf", "metadata": {"source": "CRF", "title": "Novel feature extraction, selection and fusion for effective malware family classification", "authors": ["Mansour Ahmadi", "Giorgio Giacinto", "Dmitry Ulyanov", "Stanislav Semenov", "Mikhail Trofimov"], "emails": ["mansour.ahmadi@unica.diee.it", "giacinto@diee.unica.it", "dmitry.ulyanov@skolkovotech.ru", "stasg7@gmail.com", "mikhail.trofimov@phystech.edu"], "sections": [{"heading": null, "text": "Keywords Windows Malware, Machine learning, Malware family, Computer security, Classification, Microsoft Malware Classification Challenge"}, {"heading": "1. INTRODUCTION", "text": "In recent years, malware coders developed sophisticated techniques to elude traditional as well as modern malware protection mechanisms. On the other hand, developers of\n.\nanti-malware solutions need to develop counter mechanisms for detecting and deactivating them, playing a cat-and-mouse game. The huge number of malware families, and malware variants inside the families, causes a major problem for antimalware products. For example, McAfee Lab\u2019s antimalware solutions reported more than 350M total unique malware samples in Q4 of 2014, that represents a growth of 17% with respect to the analogous data in Q3 [5]. Symantec reported more than 44.5 million new pieces of malware created in May 2015 [6]. Analyzing the malicious intent in this vast amount of data requires a huge effort by anti malware companies. One of the main reasons for this high volume of malware samples is the extensive use of polymorphic and metamorphic techniques by malware developers, which means that malicious executable files belonging to the same malware family are constantly modified and/or obfuscated. In particular, polymorphic malware has a static mutation engine that encrypts and decrypts the code, while metamorphic malware automatically modify the code each time it is propagated. Malware detection and classification techniques are two separate tasks, that are performed by anti-malware companies. Firstly, an executable needs to be analyzed to detect if it exhibits any malicious content: Then, in the case a malware is detected, it is assigned to the most appropriate malware family through a classification mechanism. There are various ways for detecting malware in the wild, and detecting a zero-day malware is still a challenging task. For example, Kaspersky recently discovered a new variant of duqu, Duqu 2.0, in their own internal networks in July of 2015 [3]. The detection of this kind of advanced malware is usually carried out within a sandbox environment, and a powerful heuristic engine. After the malware detection step, malware need to be categorized into groups, corresponding to their families, for further analysis. As far as a very high number of malware variants is concerned, the need for the automation of this process is clear-cut. The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46]. Analyzers extract various characteristics from the programs\u2019 syntax and semantic such as operation codes [40] and function call graph [23] from the disassembled code, or string signatures [22] and byte code n-grams ar X iv :1 51 1. 04 31 7v 1 [ cs .C R ] 1 3 N\nov 2\n[44, 2] from the hex code, or extracting different structural characteristics from the PE header, such as dependencies between APIs [48] and DLLs [34]. Some other works [42] also explored the analysis of metadata such as the number of bitmaps, the size of import and export address table besides PE header\u2019s content. The aforementioned contentbased detection systems like those considering bytecode ngrams, APIs, and assembly instruction,s are inherently susceptible to false detection due to the fact of polymorphism and metamorphism. In addition, these techniques are not appropriated in the case of malware samples such as the one with 00yCuplj2VTc9ShXZDvnxz hash name, that does not contain any APIs, and also contains a few assembly instructions because of packing. In this paper, we propose a learning-based system which uses different malware characteristics to effectively assign malware samples to their corresponding families without doing any deobfuscation and unpacking process. In particular, for each malware sample, we compute not only a set of content-based features by relying on state-of-the-art mechanisms, but also we propose the extraction of powerful complementary statistical features that reflects the structure of portable executable (PE) files. The decision of not using more complex models like n-grams, sequences, bags or graphs, allowed us to devise a simple, yet effective, and efficient malware classification system. Moreover, we implemented an algorithm, inspired by the forward stepwise feature selection algorithm [25], to combine the most relevant feature categories to feed the classifier, and show the trade-off between the number of features and accuracy. To better exploit both the richness of the available information, in the number of the malware samples for training the classifier, and the number of features used to represent the samples, we resorted to ensemble techniques such as bagging [29]. We evaluated our system on the data provided by Microsoft for their malware Challenge hosted at Kaggle1, and achieved 99.77% accuracy. It is worth to point out that this paper does not deal with malware detection, as the proposed system focuses on malware classification. Consequently, we didn\u2019t make any analysis of malware designed to evade detection. The source code of our method will be available through the website of the authors. In summary, the original contributions of this paper are the following:\n\u2022 The extraction and evaluation of different features based on the content and the structure of a malware that is performed directly on the packed executable file, and doesn\u2019t require the costly task of unpacking,\n\u2022 A novel technique that extracts information on the structural characteristics of PEs, to accurately classify even obfuscated malware,\n\u2022 The use of a limited number of features compared to other state-of-the-art systems, so that the method is apt to be used in large-scale malware categorization tasks,\n\u2022 An algorithm for feature fusion that outputs the most effective concatenation of features categories, each category being related to different aspects of the malware,\n1https://www.kaggle.com/c/malware-classification\nthus avoiding the combination of all the possible feature categories, and providing a trade-off between the accuracy and the number of features,\n\u2022 The performances of the proposed malware classification technique have been assessed on the dataset recently released by Microsoft, that can be considered one of the most updated and reliable testbeds for the task at hand.\nThe rest of the paper is organized as follows: a survey on the related work is presented in section 2; section 3 presents the details of the proposed method. Results of the experiments are discussed in section 4, and conclusions and future work will wrap up the paper."}, {"heading": "2. RELATED WORK", "text": "Prior to the development of signatures for antimalware products, the two main tasks that have to be carried out within the scope of malware analysis are malware detection, and malware classification. While the goal of malware detection mechanisms is to catch the malware in the wild, malware classification systems assign each sample to the correct malware family. These systems can be roughly divided into two groups, based, respectively, on dynamic or static analysis. Dynamic analysis. Researchers have put a lot of effort in proposing behaviour-based malware detection methods that capture the behavior of the program at runtime. One way to observe the behavior of a program is to monitor the interactions of the program with the operating system through the analysis of the system calls [45, 37]. In order to devise an effective and more robust system, some approaches considered additional semantic information like the sequence of the system calls [9], and the use of graph representations [27, 20, 26]. These approaches monitor the program\u2019s behaviour by analyzing the temporal order of the API calls, and the effect of API calls on registers [21], or by extracting a behavioural graph based on the dependency between API call parameters. Additionally, in contrast to the above program-centric detection approaches, some proposals address the issue by a global, system-wide approach. For example, Lanzi et al. [30] proposed an access activity model that captures the generalized interactions of benign applications with operating system resources, such as files and the registry, and then detects the malware with very a very low false positive rate. A recent survey on 36 research papers on dynamic analysis techniques [38] pointed out that the common shortcomings of dynamic analysis techniques are the problematic and somewhat obscure assumptions regarding the use of execution-driven datasets, and the lack of details and motivation on the security precautions that have been taken during the experimental phase. Moreover, recent malware is shipped with dynamic anti-analysis defenses that hide the malicious behaviour in the case a dynamic analysis environment is detected [36] and the lack of code coverage, as dynamic analysis is not designed to explore all or, at least, multiple execution paths of an executable [32]. Static analysis. On the other hand, static approaches perform the analysis without actually executing the program. The research literature exhibits a large variety of static analysis methods. SAFE [17] and SAVE [43] have been among the most influential approaches in heuristic static malware detection, as these works inspired many researchers in this\nAPI: Application Programming Interface BYT: Byte code, FC: Function Call STC: Structural features, OP: Operation code\narea. The above two works proposed the use of different patterns to detect the presence of malicious content in executable files. Since that time, a large variety of techniques have been explored based on different malware attributes, such as the header of the PE, the body of the PE, or both of them. Analysis is further carried out either directly on the bytecode [44, 2], or by disassembling the code and extracting opcodes and other relevant detailed information on the content of the program [40]. The main issue in static analysis is coping with packing and obfuscation. Recenlty, some paper addresses this issue by proposing a generic approach for the automatic deobfuscation of obfuscated programs without making any assumption about the the obfuscation technique Yadegari et al.[47]. Static techniques have been also employed to assess if a malware detected in the wild is similar to a previously-seen variant, without actually performing the costly task of unpacking [24, 34]. All of the malware detection and malware classification systems rely on the extraction of either static or dynamic features. So, basically, the same features used for malware detection are used for malware classification purposes. As this paper focuses on malware classification based on the extraction of static features, Table 1 summarize the prominent static techniques tailored to both the detection and the classification of PE malware designed for MS Windows systems. As far as the experiments reported in the literature have been performed on different datasets, we haven\u2019t reported the related performances, as a comparison of the attained accuracy would have not been fair. Table 1 shows, in the type column, if the paper is related to malware detection or classification. The column feature shows if the features are extracted from the PE header or from the PE body. Finally, the structure column reports on the extraction of any complex features, related, for example, to a relationship or a dependency among PE elements."}, {"heading": "3. SYSTEM ARCHITECTURE", "text": "As this paper focuses on malware classification, the most relevant issue is related to the choice of the features that will be used to represent each malware sample for the classification task. Our approach was guided by the rationale that to attain accurate and fast classification results, we should integrate different types of features, such as content-based\nfeatures as well as structural features."}, {"heading": "3.1 Malware representation", "text": "Before entering into the details of the features that we extracted for the classification task, we will briefly review the different ways in which a malware samples can be represented. Two common representations of a malware samples are by the hex view, and the assembly view. The hex view represents the machine code as a sequence of hexadecimal digits, which is the accumulation of consecutive 16-bytes words, like in the following representation:\n004010D0 8D 15 A8 80 63 00 BF 55 70 00 00 52 FF 72 7C 53\nThe first value represents the starting address of these machine codes in the memory, and each value (byte) bears a meaningful element for the PE, like instruction codes or data. The task of disassembling a binary executable into its sequence of assembly instructions can be performed by two main techniques, namely by the linear sweep algorithm, and the recursive traversal algorithm [41]. Although neither approach is absolutely precise, the recursive approach is usually far less susceptible to mistakes than the linear sweep algorithm because the code is disassembled according to the jump and branch instructions. The Interactive Disassembler (IDA) [1] tool is one of the most popular recursive traversal disassembler, which performs automatic code analysis on binary files using cross-references between code sections, knowledge of parameters of API calls, and other information. For example, IDA interprets the aforementioned byte sequence as shown in Figure 1."}, {"heading": "3.2 Features", "text": "For accurate and fast classification, we propose to extract features both from the hex view, and from the assembly view to exploit complementary information brought by these two representations. These complementary information are usually related to the essence of maliciousness, like obfuscation, and the experimental results will show how the combination of information from the two views can help improving the effectiveness of the whole system. In the following subsections we provide details on each feature that has been used and the reasoning of selecting them. It is worth to point out the reason why we are not considering features extracted from the PE header. While it is well known that the PE header can be a rich source of information, the task at hand is more challenging as the PE header is not available, according to the rules of the Microsoft challenge that provided the dataset used in this paper.\n3.2.1 Hex dump-based features\n1. N-grams: A N-gram is a contiguous sequence of n items from a\ngiven sequence. N-grams are intensively used for characterizing sequences in different areas, e.g. computational linguistics, and DNA sequencing. The representation of a malware sample as a sequence of hex values can be effectively described through n-gram analysis to capture beneficial information about the type of malware. Each element in a byte sequence can take one out of 257 different values, i.e., the 256 byte range, plus the special ?? symbol. The \u201d??\u201d symbol indicates that the corresponding byte has no mapping in the executable file, namely the contents of those addresses are uninitialized within the file. This value can be discarded as, from an experimental point of view, it turned out that better results are achieved by taking into account just the 256 symbols. Examples of N-gram analysis include 1-gram (1G) features, which represent just the byte frequency, and thus are described with a 256-dimensional vector, and 2-gram features, which measure the frequency of all 2-byte combinations, thus having dimension of 2562. As far as low computational complexity is concerned in our assumption, 1-gram is just considered in the experiments.\n2. Metadata: We extracted the following metadata features (MD1), namely, the size of the file, and the address of the first bytes sequence. The address is an hexadecimal number, and we converted it to the corresponding decimal value for homogeneity with the other features values.\n3. Entropy: Entropy (ENT) is a measure of the amount of disorder, and can be used to detect the possible presence of obfuscation [31, 10]. Entropy is computed on the byte-level representation of each malware sample and the goal is to measure the disorder of the distribution of bytes in the bytecode as a value between 0 (Order) and 8 (Randomness). First, we apply the sliding window method to represent the malware as a series of entropy measures E = ei : i = 1, ..., N , where ei is the entropy measured in each window, and N is the number of windows, and then the entropy is calculated using the Shannon\u2019s formula:\nei = \u2212 m\u2211\nj=1\np (j) log2 p (j) (1)\nwhere p(j) is the frequency of byte j within window i, and m is a number of distinct bytes in the window. Then, we consider statistics of entropy sequences obtained using the sliding window method, that is, we calculate the entropy for each window of 10000 bytes and then we consider a number of statistical measures like quantiles, percentiles, mean, and variance of the obtained distribution. In addition, we compute the entropy of all the bytes in a malware.\n4. Image representation: An original way to represent a malware sample is to visualize the byte code by interpreting each byte as the gray-level of one pixel in an image [35]. As shown in Figure 2, the resulting images have very fine texture\npatterns (e.g. see Figure 2a, and Figure 2b), that can be used as visual signatures for each malware family. Although matching visual patterns need a huge processing time, some features that describe the textures in an image [4] such as the Haralick features (IMG1), or the Local Binary Patterns features (IMG2) can be efficient and quite effective for the malware classification task. The representation of malware as images may sometimes cause problems, as in the case shown in Figure 2c, where the texture patterns of the two images are almost similar, even if the two malware samples that are represented belong to different classes. In addition, we have to take into account the case in which the resources (.rsrc) section of a PE file contains image files (e.g. see Figure 2d). As the same image files can be used as resources for different malware families, the extracted image patterns from these part of the malware may produce false positives. As far as the .rsrc section may not be always in the same position within a PE file, removing those parts from our analysis was not an easy task. Therefore, as these features are used in conjunction with other feature, we considered the texture patterns computed over the whole image.\n5. Strings: We extracted possible ASCII strings from each PE using its hex dump. Since this method extracts a lot of garbage along with actual strings, the usage of string features directly is inappropriate. Consequently, to reduce noise and to avoid overfitting, only histograms related to the distribution of the strings\u2019 lengths was used.\n3.2.2 Features extracted from disassembled files\n1. Metadata: After disassembling, we computed the size of the file, and the number of lines in the file, and included these features within the Metadata category (MD2).\n2. Symbol: The frequencies of the following set of symbols (SYM), -, +, *, ], [, ?, @, are taken into account as a high frequency of these characters is typical of code that has been designed to evade detection, for example by resorting to indirect calls, or dynamic library loading. In indirect calls, the address of the callee is taken from the memory/register. Although the implementation of calls depends both on the architecture, and on the optimal decision of compiler, indirect calls may reveal some information on data location obfuscation [33]. Dynamic library loading is another mechanism where an executable file loads a library into memory at runtime, and accesses its functions based on their address, so that static analyzers cannot capture the name of the imported functions.\n3. Operation Code: Operation codes (OPC) are the mnemonic representation of machine code, which symbolize assembly instruction. The full list of x86 instruction set is large and complex, so we select a subset of 93 operation codes based either on their commonness, or on their\nfrequent use in malicious applications [14], and measure the frequency of them in each malware sample. While instruction replacement techniques can be used to evade detection [18], their effects on malware classification tasks is limited, both for its rare use, and, consequently, for its negligible contribution to the computation of the statistics.\n4. Register: Most of the processor registers in x86 architecture are used for dedicated tasks, but in some cases register renaming is used to make the analysis harder [18]. Consequently, the frequency of use of the registers can be a useful helper for assign a malware sample to one family, as the experiments will show.\n5. Application Programming Interface: We also measure the frequency of use of Windows Application Programming Interfaces (API). As far as the total number of APIs is extremely large, considering them all would bring little or no meaningful information for malware classification. Consequently, we restricted our analysis to the top 794 frequent APIs used by malicious binaries based on an analysis on near 500K malware samples [7]. This feature category is discriminative for a subset of malware samples, because some samples might contain any API call because of packing, while some other samples might load some of its APIs by resorting to dynamic loading through the LoadLibrary API. For example, the sample with hash code 00yCuplj2VTc9ShXZDvnxz was packed with aspack2, and it does not contain any API call, and most of the disassembled code just contains data define instructions like db (see Figure 3) and dd (see Figure 4).\n6. Section: A PE consists of some predefined sections like .text, .data, .bss, .rdata, .edata, .idata, .rsrc, .tls, and .reloc. Because of evasion techniques like packing, the default sections can be modified, reordered, and new sections can be created. We extract different characteristics from sections, which are listed in Table 2. In Section 4.2 we will point out that this\n2http://www.aspack.com/\ncategory is the one with the higher influence in the classification performances.\n7. Data Define: As shown in Figure 3 and Figure 4, some malware samples do not contain any API call, and just contain few operation codes, because of packing, In particular, they mostly contain db, dw, and dd instructions, which are used for setting byte, word, and double word respectively. Consequently, we propose to include this novel set of features for malware classification as it has a high discriminative power for a number of malware families. The full list of features in this category is presented in Table 3.\n8. Miscellaneous: We extracted the frequency of 95 manual chosen keywords (MISC) from the disassembled code. Some of these keywords are related to the interpretation of IDA from the code like 75 adjacent dash-lines which show the border of blocks of PE and counting them represent the number of blocks in PE. Others are some strings like hkey_local_machine which represent the access to a specific path of Windows registry, and the rest are related to the code like dll which shows the number of imported DLLs. Because of the limitation of the pages of the paper, the full list will be available in our online repository."}, {"heading": "3.3 Feature fusion", "text": "The simplest way for combining feature categories is to stack all the feature categories in a single, long feature vector, and then run a classifier on them. However, it is often\nin the feature selection process that some of the features turn out to be irrelevant for class discrimination. Including such irrelevant features leads not only to unnecessary computational complexity, but also to the potential decrease of the accuracy of the resulting model. Within the vast literature on feature selection, we focused on two approaches. One approach is the best subset selection technique [25] that can be summarized as follows. Starting with subsets containing just one feature, a classifier is trained, and the subsets with the highest value of the objective function used to assess the performance (e.g., accuracy, loss functions, etc.) is retained. Then, the process is repeated for any subset containing f features, where f is increased by one at each step so that, for example, all the possible subsets of two\nfeatures ( f 2 ) = f(f\u22121) 2 are considered. The other technique that we considered is the textitforward stepwise selection technique which starts with a model containing no feature, and then gradually augments the feature set by adding more features one by one to the model. This technique for feature selection is computationally more efficient than the best subset selection technique because the former just considers f\u2211\ni=1\n(f \u2212k) = f(f+1) 2 subsets, while the latter considers all 2f\npossible models, using a greedy approach. Based on the above considerations, we implemented an original version of the forward stepwise selection algorithm, where instead of considering one feature at a time, we considered all the subset of features belonging to a feature category at a time. At each step, the feature set that produces the minimum value of logloss (see section 3.5 ) will be added to the model. The process stops when adding more features does not decrease the value of logloss. The source code of the algorithm will be available in our repository."}, {"heading": "3.4 Classification", "text": "As for the feature selection task, over the years a large number of classification techniques have been proposed by the scientific community, and the choice of the most appropriate classifier for a given task is often guided by previous experience in different domains, as well as by trial&error procedures. However, recently some researchers evaluated the performances of about 180 classifiers arising from different families, using various datasets, and they concluded that random forests and SVM are the two classification mechanisms that have the highest likelihood to produce good performances [19]. On the other hand, most of the winners in the very recent Kaggle competitions used the XGBoost technique [8], which is a parallel implementation of the gradient boosting tree classifier, that in most of the cases produced better performances than those produced by random forests. The XGBoost technique is available as a library, im-\nplemented as a parallel algorithm that is fast and efficient, and whose parameters are completely tunable. The high performance and effectiveness of XGBoost is the main motivating reason for using this library for the task at hand. In addition, we also use bagging [15] to boost our single model, which is simple, classifier independent, and yet an efficient method to improve the classification quality. More details on the classification technique will be provided in the experimental section."}, {"heading": "3.5 Evaluation measures", "text": "The performance in classification has been assessed by using two measures, namely, the accuracy, and the logarithmic loss. The accuracy has been measured as the fraction of correct predictions. As classification accuracy alone is usually not enough to assess the robustness of the prediction, we also measured the logarithmic loss (logloss), which is a soft measurement of accuracy that incorporates the concept of probabilistic confidence. It is the Cross entropy3 between the distribution of the true labels and the predicted probabilities. As shown in equation 2, it is the negative log likelihood of the model,\nlogloss = \u2212 1 N N\u2211 i=1 M\u2211 j=1 yij log(pij) (2)\nwhere N is the number of observations, M is the number of class labels, log is the natural logarithm, yij is 1 if observation i is in class j and 0 otherwise, and pij is the predicted probability that observation i is in class j."}, {"heading": "4. EXPERIMENTS AND RESULTS", "text": ""}, {"heading": "4.1 Data", "text": "Microsoft released almost half a terabyte of data related to 21741 malware samples, where 10868 samples are used for training, and the rest is for testing. The ID of each malware sample is a 20 characters hash value. The files are from nine different malware families, namely Ramnit (R), Lollipop (L), Kelihos_ver3 (K3), Vundo (V), Simda (S), Tracur (T), Kelihos_ver1 (K1), Obfuscator.ACY (O), Gatak (G). The class label of each file is represented by an integer from 1 to 9, where \u20191\u2019 represented the first malware family in the above list, and \u20199\u2019 the last one. There are two files for each malware sample, one containing the hex code, and the other one containing the disassembled code (see Section 3.1). Microsoft removed the PE header to ensure file sterility. The distribution of data across the 9 families is shown in Figure 5."}, {"heading": "4.2 Feature importance", "text": "Although there is no strict consensus about the meaning of importance, we refer to two common ways to measure the importance of the features when decision tree classifiers are used, i.e., the mean decrease accuracy, and the mean decrease impurity [16]. These two metrics respectively measure the decrease in accuracy or the decrease in impurity4 associated with each feature. In both cases, the importance of a given feature is proportional to the amount of decrease\n3https://en.wikipedia.org/wiki/Cross entropy 4Gini impurity is a standard decision-tree splitting metric.\nin accuracy or impurity related to that feature. While in Section 4 we will discuss the relationship between each feature category and the classification accuracy based on the feature fusion algorithm, in this section we report the importance of the features based on the mean decrease impurity to give a better insight on the relevance of each feature category for the attribution of the family to a given malware sample. For this purpose, we used the Random Forest algorithm, and the results are reported in Figure 6. It is worth to point out that Figure 6 shows that the two novel structural feature categories that we propose in this paper, namely SEC and DP, are among the top important features that most contribute to the decrease in the impurity of the classification tree."}, {"heading": "4.3 Results", "text": "Table 4 and Table 5 respectively show the classification performances related to each individual feature category, and the performances related to the combination of feature categories. In particular, Table 5 provides useful information for data analysts to evaluate the trade-off between the number of features used, and the significance of the increase of the classification performances. We proceeded by leveraging on the feature fusion algorithm, by adding one by one the feature category that achieves the lowest logloss on training data. The attained results suggest that the combination of all the feature categories except the IMG2 category lead to the lowest logloss on all training data, while the combination of all the feature categories leads to the lowest logloss on training data by employing cross validation. According to these results, we fine tuned the parameters of the XGBoost algorithm on these two feature configurations, as well as for the Bagging technique (see Table 6). In particular, by adding the external bagging technique, we created a training set with 8 times more samples instead of just using the plain training set. We considered all L train samples and sampled Alpha \u00d7 L more samples with replacement, where the best value of Alpha was found by grid search and set to 1.\nThe proposed methodology for the classification of mal-\nware allowed achieving a very promising accuracy on the training set of 99.77%, as well as a very low logloss of 0.0096 on the combination of all categories, and 99.76% accuracy and 0.0094 logloss on the combination of the best feature categories, based on the outcome of the feature fusion algorithm.\nThe confusion matrix, and the log normalized confusion matrix of the final model are respectively shown in Figure 7 and Figure 8. As far as the class labels of the test data were not provided by Microsoft, the only possible way to perform the evaluation on test data is through the submission of the predictions of our model to the competition website. Hence, we ran the experiments on test data and achieved a very low logloss, which is 0.0064 on combination of best categories and 0.0063 on combination of all categories."}, {"heading": "4.4 Comparison and Discussion", "text": "To the best of our knowledge, this is the first paper based on the malware dataset that was recently released by Mi-\ncrosoft. Consequently, the effectiveness of the proposed approach can be assessed by comparing the reported results with the ones attained by the winner of the Microsoft malware challenge 5. The winner of the competition attained 0.9983 accuracy, and 0.0031 logloss, on 4-fold cross validation, and 0.0028 logloss on test data, thus confirming the effectiveness of the proposed method, as the significance of this small difference in statistically negligible. While the performances are quite close, it is worth pointing out the differences between the method proposed in this paper and the one followed by the winning team. The proposed method is characterized by a limited computational complexity compared to the winning method, both in terms of the number and type of features, and in the classification technique employed. Firstly, the winning team relied on a large set of well-known features, while we designed the proposed system\n5http://blog.kaggle.com/2015/05/26/microsoft-malwarewinners-interview-1st-place-no-to-overfitting/\nnot only by focusing on the features in the literature that proved to be effective, but also designing novel structural features that could provide a gain in performance with a limited computational cost. As an example, the winning team relied on the extraction of byte code N-grams and operation code N-grams, that require large computational resources both during the training phase, and the testing phase. The complexity of the classification step employed in the proposed method is lower than the ones of the winning team. Both methods rely on the ensemble paradigm, where the winning team resorted to an ensemble of different classifiers in a semi-supervised setting, while we resorted to a standard implementation of XGBoost with bagging. Thus, we can conclude that the proposed method exhibits a better tradeoff between computational complexity and performances. The proposed method has not yet been tested for robustness against evasion attacks [11, 28] or poisoning attacks [13, 12] because these kinds of attacks are more frequent against malware detectors rather than against malware classifiers. Attacks against malware classifiers may be used to mislead automatic signature extractors, that analyze malware samples belonging to a family to design effective signatures. As the effectiveness of such attacks depends on a deep knowledge of the malware classifier, as well as of the signature extractor, and this knowledge cannot be reliably inferred from the outside of the system without insider support, we can conclude that these kind of attacks are highly rare. On the other hand, an analysis of the robustness of the system against evasion and poisoning attacks is worth to be carried out if the proposed system is modified to act as a malware detector."}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "we presented a malware classification system characterized by a limited complexity both in feature design and in the classification mechanism employed. To attain this goal, we proposed a number of novel features to represent in a compact way some discriminant characteristics between different families. In particular, We focused on the extraction of novel structural features, that, if compared to contentbased features, are easier to compute, and allow the classification of obfuscated and packed malware without the need of deobfuscation and unpacking processes. Reported results allowed assessing the effectiveness of these features both with respect to classification accuracy, and to impurity.\nThe main motivation behind the choice of a light systems is its suitability for an industrial use, where the trade-off between complexity and performances can be a key issue. Very often, the gain in performances of complex systems on validation data is negligible compared to the performances of less complex ones. In addition, complex system makes hard the task for an analyst to understand the classification results from the set of features related to a given sample. While we haven\u2019t addressed this issue in this paper, we believe in its noteworthiness to gather information about the core common characteristics of malware samples within a family."}, {"heading": "6. REFERENCES", "text": "[1] Ida : Disassembler and debugger.\nhttps://www.hex-rays.com/products/ida/, 2013.\n[2] Novel active learning methods for enhanced {PC} malware detection in windows {OS}. Expert Systems with Applications, 41(13):5843 \u2013 5857, 2014.\n[3] Duqu is back. http://www.kaspersky.com/about/ news/virus/2015/Duqu-is-back, 2015.\n[4] Mahotas features. http://mahotas.readthedocs.org/ en/latest/features.html, 2015.\n[5] Mcafee labs threats report, february. http://www.mcafee.com/us/resources/reports/\nrp-quarterly-threat-q4-2014.pdf, 2015.\n[6] Symantec intelligent report, may. https://www.symantec.com/content/en/us/\nenterprise/other_resources/intelligence_ report_05-2015.en-us.pdf, 2015.\n[7] Top maliciously used apis. https: //www.bnxnet.com/top-maliciously-used-apis/, 2015.\n[8] Xgboost. https://github.com/dmlc/xgboost, 2015.\n[9] M. Ahmadi, A. Sami, H. Rahimi, and B. Yadegari. Malware detection by behavioural sequential patterns. Computer Fraud & Security, 2013(8):11 \u2013 19, 2013.\n[10] D. Baysa, R. Low, and M. Stamp. Structural entropy and metamorphic malware. Journal of Computer Virology and Hacking Techniques, 9(4):179\u2013192, 2013.\n[11] B. Biggio, I. Corona, D. Maiorca, B. Nelson,\nN. A\u030aa\u0306rndiA\u0308G\u0306, P. Laskov, G. Giacinto, and F. Roli. Evasion attacks against machine learning at test time. In H. Blockeel, K. Kersting, S. Nijssen, and F. A\u030a\u00a1eleznA\u0303\u00a1, editors, Machine Learning and Knowledge Discovery in Databases, volume 8190 of Lecture Notes in Computer Science, pages 387\u2013402. Springer Berlin Heidelberg, 2013.\n[12] B. Biggio, B. Nelson, and P. Laskov. Poisoning attacks against support vector machines. In 29th Int\u2019l Conf. on Machine Learning (ICML). Omnipress, Omnipress, 2012.\n[13] B. Biggio, K. Rieck, D. Ariu, C. Wressnegger, I. Corona, G. Giacinto, and F. Roli. Poisoning behavioral malware clustering. In Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop, AISec \u201914, pages 27\u201336, New York, NY, USA, 2014. ACM.\n[14] D. Bilar. Statistical structures: Fingerprinting malware for classification and analysis. In Blackhat, 2006.\n[15] L. Breiman. Bagging predictors. Mach. Learn., 24(2):123\u2013140, Aug. 1996.\n[16] L. Breiman, J. Friedman, R. Olshen, and C. Stone. Classification and Regression Trees. Wadsworth and Brooks, Monterey, CA, 1984. new edition [?]?\n[17] M. Christodorescu and S. Jha. Static analysis of executables to detect malicious patterns. In Proceedings of the 12th Conference on USENIX Security Symposium - Volume 12, SSYM\u201903, pages 12\u201312, Berkeley, CA, USA, 2003. USENIX Association.\n[18] M. Christodorescu, S. Jha, S. Seshia, D. Song, and R. Bryant. Semantics-aware malware detection. In Security and Privacy, 2005 IEEE Symposium on, pages 32\u201346, May 2005.\n[19] M. Ferna\u0301ndez-Delgado, E. Cernadas, S. Barro, and\nD. Amorim. Do we need hundreds of classifiers to solve real world classification problems? J. Mach. Learn. Res., 15(1):3133\u20133181, Jan. 2014.\n[20] M. Fredrikson, S. Jha, M. Christodorescu, R. Sailer, and X. Yan. Synthesizing near-optimal malware specifications from suspicious behaviors. In Proceedings of the 2010 IEEE Symposium on Security and Privacy, SP \u201910, pages 45\u201360, Washington, DC, USA, 2010. IEEE Computer Society.\n[21] M. Ghiasi, A. Sami, and Z. Salehi. Dynamic vsa: a framework for malware detection based on register contents. Engineering Applications of Artificial Intelligence, 44:111 \u2013 122, 2015.\n[22] K. Griffin, S. Schneider, X. Hu, and T.-C. Chiueh. Automatic generation of string signatures for malware detection. In Proceedings of the 12th International Symposium on Recent Advances in Intrusion Detection, RAID \u201909, pages 101\u2013120, Berlin, Heidelberg, 2009. Springer-Verlag.\n[23] X. Hu, T.-c. Chiueh, and K. G. Shin. Large-scale malware indexing using function-call graphs. In Proceedings of the 16th ACM Conference on Computer and Communications Security, CCS \u201909, pages 611\u2013620, New York, NY, USA, 2009. ACM.\n[24] G. Jacob, P. M. Comparetti, M. Neugschwandtner, C. Kruegel, and G. Vigna. A static, packer-agnostic filter to detect similar malware samples. In Proceedings of the 9th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA\u201912, pages 102\u2013122, Berlin, Heidelberg, 2013. Springer-Verlag.\n[25] G. James, D. Witten, T. Hastie, and R. Tibshirani. An Introduction to Statistical Learning: With Applications in R. Springer Publishing Company, Incorporated, 2014.\n[26] F. Karbalaie, A. Sami, and M. Ahmadi. Semantic malware detection by deploying graph mining. International Journal of Computer Science Issues, 9(1), 2012.\n[27] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X. Zhou, and X. Wang. Effective and efficient malware detection at the end host. In Proceedings of the 18th Conference on USENIX Security Symposium, SSYM\u201909, pages 351\u2013366, Berkeley, CA, USA, 2009. USENIX Association.\n[28] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna. Automating mimicry attacks using static binary analysis. In Proceedings of the 14th Conference on USENIX Security Symposium - Volume 14, SSYM\u201905, pages 11\u201311, Berkeley, CA, USA, 2005. USENIX Association.\n[29] L. I. Kuncheva. Ensemble Methods, pages 186\u2013229. John Wiley & Sons, Inc., 2014.\n[30] A. Lanzi, D. Balzarotti, C. Kruegel, M. Christodorescu, and E. Kirda. Accessminer: Using system-centric models for malware protection. In Proceedings of the 17th ACM Conference on Computer and Communications Security, CCS \u201910, pages 399\u2013412, New York, NY, USA, 2010. ACM.\n[31] R. Lyda and J. Hamrock. Using entropy analysis to find encrypted and packed malware. IEEE Security and Privacy, 5(2):40\u201345, Mar. 2007.\n[32] A. Moser, C. Kruegel, and E. Kirda. Exploring multiple execution paths for malware analysis. In Proceedings of the 2007 IEEE Symposium on Security and Privacy, SP \u201907, pages 231\u2013245, Washington, DC, USA, 2007. IEEE Computer Society.\n[33] A. Moser, C. Kruegel, and E. Kirda. Limits of static analysis for malware detection. In Computer Security Applications Conference, 2007. ACSAC 2007. Twenty-Third Annual, pages 421\u2013430, Dec 2007.\n[34] M. Narouei, MansourAhmadi, G. Giacinto, H. Takabi, and A. Sami. Dllminer: Structural mining for malware detection. Security and Communication Networks, 2015.\n[35] L. Nataraj, S. Karthikeyan, G. Jacob, and B. S. Manjunath. Malware images: Visualization and automatic classification. In Proceedings of the 8th International Symposium on Visualization for Cyber Security, VizSec \u201911, pages 4:1\u20134:7, New York, NY, USA, 2011. ACM.\n[36] J. Qiu, B. Yadegari, B. Johannesmeyer, S. Debray, and X. Su. A framework for understanding dynamic anti-analysis defenses. In Proceedings of the 4th Program Protection and Reverse Engineering Workshop, PPREW-4, pages 2:1\u20132:9, New York, NY, USA, 2014. ACM.\n[37] K. Rieck, T. Holz, C. Willems, P. Dussel, and P. Laskov. Learning and classification of malware behavior. In Proceedings of the 5th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA \u201908, pages 108\u2013125, Berlin, Heidelberg, 2008. Springer-Verlag.\n[38] C. Rossow, C. Dietrich, C. Grier, C. Kreibich, V. Paxson, N. Pohlmann, H. Bos, and M. van Steen. Prudent practices for designing malware experiments: Status quo and outlook. In Security and Privacy (SP), 2012 IEEE Symposium on, pages 65\u201379, May 2012.\n[39] A. Sami, B. Yadegari, H. Rahimi, N. Peiravian, S. Hashemi, and A. Hamze. Malware detection based on mining api calls. In Proceedings of the 2010 ACM Symposium on Applied Computing, SAC \u201910, pages 1020\u20131025, New York, NY, USA, 2010. ACM.\n[40] I. Santos, F. Brezo, X. Ugarte-Pedrero, and P. G. Bringas. Opcode sequences as representation of executables for data-mining-based unknown malware detection. Information Sciences, 231(0):64 \u2013 82, 2013. Data Mining for Information Security.\n[41] B. Schwarz, S. Debray, and G. Andrews. Disassembly of executable code revisited. In Proceedings of the Ninth Working Conference on Reverse Engineering (WCRE\u201902), WCRE \u201902, pages 45\u2013, Washington, DC, USA, 2002. IEEE Computer Society.\n[42] M. Shafiq, S. Tabish, F. Mirza, and M. Farooq. Pe-miner: Mining structural information to detect malicious executables in realtime. In E. Kirda, S. Jha, and D. Balzarotti, editors, Recent Advances in Intrusion Detection, volume 5758 of Lecture Notes in Computer Science, pages 121\u2013141. Springer Berlin Heidelberg, 2009.\n[43] A. H. Sung, J. Xu, P. Chavez, and S. Mukkamala. Static analyzer of vicious executables (save). In Proceedings of the 20th Annual Computer Security Applications Conference, ACSAC \u201904, pages 326\u2013334,\nWashington, DC, USA, 2004. IEEE Computer Society.\n[44] S. M. Tabish, M. Z. Shafiq, and M. Farooq. Malware detection using statistical analysis of byte-level file content. In Proceedings of the ACM SIGKDD Workshop on CyberSecurity and Intelligence Informatics, CSI-KDD \u201909, pages 23\u201331, New York, NY, USA, 2009. ACM.\n[45] C. Willems, T. Holz, and F. Freiling. Toward automated dynamic malware analysis using cwsandbox. Security Privacy, IEEE, 5(2):32\u201339, March 2007.\n[46] T. Wu\u0308chner, M. Ochoa, and A. Pretschner. Malware detection with quantitative data flow graphs. In Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security, ASIA CCS \u201914, pages 271\u2013282, New York, NY, USA, 2014. ACM.\n[47] B. Yadegari, B. Johannesmeyer, B. Whitely, and S. Debray. A generic approach to automatic deobfuscation of executable code. In IEEE Security and Privacy. IEEE, 2015.\n[48] Y. Ye, D. Wang, T. Li, D. Ye, and Q. Jiang. An intelligent pe-malware detection system based on association mining. Journal in Computer Virology, 4(4):323\u2013334, 2008."}], "references": [{"title": "Malware detection by behavioural sequential patterns", "author": ["M. Ahmadi", "A. Sami", "H. Rahimi", "B. Yadegari"], "venue": "Computer Fraud & Security, 2013(8):11 \u2013 19,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Structural entropy and metamorphic malware", "author": ["D. Baysa", "R. Low", "M. Stamp"], "venue": "Journal of Computer Virology and Hacking Techniques, 9(4):179\u2013192,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "Evasion attacks against machine learning at test time", "author": ["B. Biggio", "I. Corona", "D. Maiorca", "B. Nelson", "N. \u00c5\u0103rndi\u00c4\u011e", "P. Laskov", "G. Giacinto", "F. Roli"], "venue": "H. Blockeel, K. Kersting, S. Nijssen, and F. \u00c5\u00a1elezn\u00c3\u00a1, editors, Machine Learning and Knowledge Discovery in Databases, volume 8190 of Lecture Notes in Computer Science, pages 387\u2013402. Springer Berlin Heidelberg,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Poisoning attacks against support vector machines", "author": ["B. Biggio", "B. Nelson", "P. Laskov"], "venue": "29th Int\u2019l Conf. on Machine Learning (ICML). Omnipress, Omnipress,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Poisoning behavioral malware clustering", "author": ["B. Biggio", "K. Rieck", "D. Ariu", "C. Wressnegger", "I. Corona", "G. Giacinto", "F. Roli"], "venue": "Proceedings of the 2014 Workshop on Artificial Intelligent and Security Workshop, AISec \u201914, pages 27\u201336, New York, NY, USA,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Statistical structures: Fingerprinting malware for classification and analysis", "author": ["D. Bilar"], "venue": "Blackhat,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "Bagging predictors", "author": ["L. Breiman"], "venue": "Mach. Learn., 24(2):123\u2013140, Aug.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "Classification and Regression Trees", "author": ["L. Breiman", "J. Friedman", "R. Olshen", "C. Stone"], "venue": "Wadsworth and Brooks, Monterey, CA,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1984}, {"title": "Static analysis of executables to detect malicious patterns", "author": ["M. Christodorescu", "S. Jha"], "venue": "Proceedings of the 12th Conference on USENIX Security Symposium - Volume 12, SSYM\u201903, pages 12\u201312, Berkeley, CA, USA,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "Semantics-aware malware detection", "author": ["M. Christodorescu", "S. Jha", "S. Seshia", "D. Song", "R. Bryant"], "venue": "Security and Privacy, 2005 IEEE Symposium on, pages 32\u201346, May", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "Do we need hundreds of classifiers to solve real world classification problems", "author": ["M. Fern\u00e1ndez-Delgado", "E. Cernadas", "S. Barro", "D. Amorim"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Synthesizing near-optimal malware specifications from suspicious behaviors", "author": ["M. Fredrikson", "S. Jha", "M. Christodorescu", "R. Sailer", "X. Yan"], "venue": "Proceedings of the 2010 IEEE Symposium on Security and Privacy, SP \u201910, pages 45\u201360, Washington, DC, USA,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Dynamic vsa: a framework for malware detection based on register contents", "author": ["M. Ghiasi", "A. Sami", "Z. Salehi"], "venue": "Engineering Applications of Artificial Intelligence, 44:111 \u2013 122,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Automatic generation of string signatures for malware detection", "author": ["K. Griffin", "S. Schneider", "X. Hu", "T.-C. Chiueh"], "venue": "Proceedings of the 12th International Symposium on Recent Advances in Intrusion Detection, RAID \u201909, pages 101\u2013120, Berlin, Heidelberg,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2009}, {"title": "Large-scale malware indexing using function-call graphs", "author": ["X. Hu", "T.-c. Chiueh", "K.G. Shin"], "venue": "In Proceedings of the 16th ACM Conference on Computer and Communications Security,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "A static, packer-agnostic filter to detect similar malware samples", "author": ["G. Jacob", "P.M. Comparetti", "M. Neugschwandtner", "C. Kruegel", "G. Vigna"], "venue": "Proceedings of the 9th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA\u201912, pages 102\u2013122, Berlin, Heidelberg,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "An Introduction to Statistical Learning: With Applications in R", "author": ["G. James", "D. Witten", "T. Hastie", "R. Tibshirani"], "venue": "Springer Publishing Company, Incorporated,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic malware detection by deploying graph mining", "author": ["F. Karbalaie", "A. Sami", "M. Ahmadi"], "venue": "International Journal of Computer Science Issues, 9(1),", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Effective and efficient malware detection at the end host", "author": ["C. Kolbitsch", "P.M. Comparetti", "C. Kruegel", "E. Kirda", "X. Zhou", "X. Wang"], "venue": "Proceedings of the 18th Conference on USENIX Security Symposium, SSYM\u201909, pages 351\u2013366, Berkeley, CA, USA,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Automating mimicry attacks using static binary analysis", "author": ["C. Kruegel", "E. Kirda", "D. Mutz", "W. Robertson", "G. Vigna"], "venue": "Proceedings of the 14th Conference on USENIX Security Symposium - Volume 14, SSYM\u201905, pages 11\u201311, Berkeley, CA, USA,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2005}, {"title": "Ensemble Methods, pages 186\u2013229", "author": ["L.I. Kuncheva"], "venue": "John Wiley & Sons, Inc.,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2014}, {"title": "Accessminer: Using system-centric models for malware protection", "author": ["A. Lanzi", "D. Balzarotti", "C. Kruegel", "M. Christodorescu", "E. Kirda"], "venue": "Proceedings of the 17th ACM Conference on Computer and Communications Security, CCS \u201910, pages 399\u2013412, New York, NY, USA,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2010}, {"title": "Using entropy analysis to find encrypted and packed malware", "author": ["R. Lyda", "J. Hamrock"], "venue": "IEEE Security and Privacy, 5(2):40\u201345, Mar.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Exploring multiple execution paths for malware analysis", "author": ["A. Moser", "C. Kruegel", "E. Kirda"], "venue": "Proceedings of the 2007 IEEE Symposium on Security and Privacy, SP \u201907, pages 231\u2013245, Washington, DC, USA,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2007}, {"title": "Limits of static analysis for malware detection", "author": ["A. Moser", "C. Kruegel", "E. Kirda"], "venue": "Computer Security Applications Conference, 2007. ACSAC 2007. Twenty-Third Annual, pages 421\u2013430, Dec", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "Dllminer: Structural mining for malware detection", "author": ["M. Narouei", "MansourAhmadi", "G. Giacinto", "H. Takabi", "A. Sami"], "venue": "Security and Communication Networks,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2015}, {"title": "Malware images: Visualization and automatic classification", "author": ["L. Nataraj", "S. Karthikeyan", "G. Jacob", "B.S. Manjunath"], "venue": "Proceedings of the 8th International Symposium on Visualization for Cyber Security, VizSec \u201911, pages 4:1\u20134:7, New York, NY, USA,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}, {"title": "A framework for understanding dynamic anti-analysis defenses", "author": ["J. Qiu", "B. Yadegari", "B. Johannesmeyer", "S. Debray", "X. Su"], "venue": "Proceedings of the 4th Program Protection and Reverse Engineering Workshop, PPREW-4, pages 2:1\u20132:9, New York, NY, USA,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning and classification of malware behavior", "author": ["K. Rieck", "T. Holz", "C. Willems", "P. Dussel", "P. Laskov"], "venue": "Proceedings of the 5th International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, DIMVA \u201908, pages 108\u2013125, Berlin, Heidelberg,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Prudent practices for designing malware experiments: Status quo and outlook", "author": ["C. Rossow", "C. Dietrich", "C. Grier", "C. Kreibich", "V. Paxson", "N. Pohlmann", "H. Bos", "M. van Steen"], "venue": "In Security and Privacy (SP),", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Malware detection based on mining api calls", "author": ["A. Sami", "B. Yadegari", "H. Rahimi", "N. Peiravian", "S. Hashemi", "A. Hamze"], "venue": "Proceedings of the 2010 ACM Symposium on Applied Computing, SAC \u201910, pages 1020\u20131025, New York, NY, USA,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2010}, {"title": "Opcode sequences as representation of executables for data-mining-based unknown malware detection", "author": ["I. Santos", "F. Brezo", "X. Ugarte-Pedrero", "P.G. Bringas"], "venue": "Information Sciences, 231(0):64 \u2013 82,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2013}, {"title": "Disassembly of executable code revisited", "author": ["B. Schwarz", "S. Debray", "G. Andrews"], "venue": "Proceedings of the Ninth Working Conference on Reverse Engineering (WCRE\u201902), WCRE \u201902, pages 45\u2013, Washington, DC, USA,", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2002}, {"title": "Pe-miner: Mining structural information to detect malicious executables in realtime", "author": ["M. Shafiq", "S. Tabish", "F. Mirza", "M. Farooq"], "venue": "E. Kirda, S. Jha, and D. Balzarotti, editors, Recent Advances in Intrusion Detection, volume 5758 of Lecture Notes in Computer Science, pages 121\u2013141. Springer Berlin Heidelberg,", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2009}, {"title": "Static analyzer of vicious executables (save)", "author": ["A.H. Sung", "J. Xu", "P. Chavez", "S. Mukkamala"], "venue": "Proceedings of the 20th Annual Computer Security Applications Conference, ACSAC \u201904, pages 326\u2013334,  Washington, DC, USA,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2004}, {"title": "Malware detection using statistical analysis of byte-level file content", "author": ["S.M. Tabish", "M.Z. Shafiq", "M. Farooq"], "venue": "Proceedings of the ACM SIGKDD Workshop on CyberSecurity and Intelligence Informatics, CSI-KDD \u201909, pages 23\u201331, New York, NY, USA,", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2009}, {"title": "Toward automated dynamic malware analysis using cwsandbox", "author": ["C. Willems", "T. Holz", "F. Freiling"], "venue": "Security Privacy, IEEE, 5(2):32\u201339, March", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Malware detection with quantitative data flow graphs", "author": ["T. W\u00fcchner", "M. Ochoa", "A. Pretschner"], "venue": "Proceedings of the 9th ACM Symposium on Information, Computer and Communications Security, ASIA CCS \u201914, pages 271\u2013282, New York, NY, USA,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2014}, {"title": "A generic approach to automatic deobfuscation of executable code", "author": ["B. Yadegari", "B. Johannesmeyer", "B. Whitely", "S. Debray"], "venue": "IEEE Security and Privacy. IEEE,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2015}, {"title": "An intelligent pe-malware detection system based on association mining", "author": ["Y. Ye", "D. Wang", "T. Li", "D. Ye", "Q. Jiang"], "venue": "Journal in Computer Virology, 4(4):323\u2013334,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 30, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 79, "endOffset": 91}, {"referenceID": 39, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 79, "endOffset": 91}, {"referenceID": 25, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 79, "endOffset": 91}, {"referenceID": 36, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 115, "endOffset": 130}, {"referenceID": 28, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 115, "endOffset": 130}, {"referenceID": 0, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 115, "endOffset": 130}, {"referenceID": 37, "context": "The analysis of malicious programs is usually carried out by static techniques [39, 48, 34] and dynamic techniques [45, 37, 9, 46].", "startOffset": 115, "endOffset": 130}, {"referenceID": 31, "context": "Analyzers extract various characteristics from the programs\u2019 syntax and semantic such as operation codes [40] and function call graph [23] from the disassembled code, or string signatures [22] and byte code n-grams ar X iv :1 51 1.", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "Analyzers extract various characteristics from the programs\u2019 syntax and semantic such as operation codes [40] and function call graph [23] from the disassembled code, or string signatures [22] and byte code n-grams ar X iv :1 51 1.", "startOffset": 134, "endOffset": 138}, {"referenceID": 13, "context": "Analyzers extract various characteristics from the programs\u2019 syntax and semantic such as operation codes [40] and function call graph [23] from the disassembled code, or string signatures [22] and byte code n-grams ar X iv :1 51 1.", "startOffset": 188, "endOffset": 192}, {"referenceID": 35, "context": "[44, 2] from the hex code, or extracting different structural characteristics from the PE header, such as dependencies between APIs [48] and DLLs [34].", "startOffset": 0, "endOffset": 7}, {"referenceID": 39, "context": "[44, 2] from the hex code, or extracting different structural characteristics from the PE header, such as dependencies between APIs [48] and DLLs [34].", "startOffset": 132, "endOffset": 136}, {"referenceID": 25, "context": "[44, 2] from the hex code, or extracting different structural characteristics from the PE header, such as dependencies between APIs [48] and DLLs [34].", "startOffset": 146, "endOffset": 150}, {"referenceID": 33, "context": "Some other works [42] also explored the analysis of metadata such as the number of bitmaps, the size of import and export address table besides PE header\u2019s content.", "startOffset": 17, "endOffset": 21}, {"referenceID": 16, "context": "Moreover, we implemented an algorithm, inspired by the forward stepwise feature selection algorithm [25], to combine the most relevant feature categories to feed the classifier, and show the trade-off between the number of features and accuracy.", "startOffset": 100, "endOffset": 104}, {"referenceID": 20, "context": "To better exploit both the richness of the available information, in the number of the malware samples for training the classifier, and the number of features used to represent the samples, we resorted to ensemble techniques such as bagging [29].", "startOffset": 241, "endOffset": 245}, {"referenceID": 36, "context": "One way to observe the behavior of a program is to monitor the interactions of the program with the operating system through the analysis of the system calls [45, 37].", "startOffset": 158, "endOffset": 166}, {"referenceID": 28, "context": "One way to observe the behavior of a program is to monitor the interactions of the program with the operating system through the analysis of the system calls [45, 37].", "startOffset": 158, "endOffset": 166}, {"referenceID": 0, "context": "In order to devise an effective and more robust system, some approaches considered additional semantic information like the sequence of the system calls [9], and the use of graph representations [27, 20, 26].", "startOffset": 153, "endOffset": 156}, {"referenceID": 18, "context": "In order to devise an effective and more robust system, some approaches considered additional semantic information like the sequence of the system calls [9], and the use of graph representations [27, 20, 26].", "startOffset": 195, "endOffset": 207}, {"referenceID": 11, "context": "In order to devise an effective and more robust system, some approaches considered additional semantic information like the sequence of the system calls [9], and the use of graph representations [27, 20, 26].", "startOffset": 195, "endOffset": 207}, {"referenceID": 17, "context": "In order to devise an effective and more robust system, some approaches considered additional semantic information like the sequence of the system calls [9], and the use of graph representations [27, 20, 26].", "startOffset": 195, "endOffset": 207}, {"referenceID": 12, "context": "These approaches monitor the program\u2019s behaviour by analyzing the temporal order of the API calls, and the effect of API calls on registers [21], or by extracting a behavioural graph based on the dependency between API call parameters.", "startOffset": 140, "endOffset": 144}, {"referenceID": 21, "context": "[30] proposed an access activity model that captures the generalized interactions of benign applications with operating system resources, such as files and the registry, and then detects the malware with very a very low false positive rate.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "A recent survey on 36 research papers on dynamic analysis techniques [38] pointed out that the common shortcomings of dynamic analysis techniques are the problematic and somewhat obscure assumptions regarding the use of execution-driven datasets, and the lack of details and motivation on the security precautions that have been taken during the experimental phase.", "startOffset": 69, "endOffset": 73}, {"referenceID": 27, "context": "Moreover, recent malware is shipped with dynamic anti-analysis defenses that hide the malicious behaviour in the case a dynamic analysis environment is detected [36] and the lack of code coverage, as dynamic analysis is not designed to explore all or, at least, multiple execution paths of an executable [32].", "startOffset": 161, "endOffset": 165}, {"referenceID": 23, "context": "Moreover, recent malware is shipped with dynamic anti-analysis defenses that hide the malicious behaviour in the case a dynamic analysis environment is detected [36] and the lack of code coverage, as dynamic analysis is not designed to explore all or, at least, multiple execution paths of an executable [32].", "startOffset": 304, "endOffset": 308}, {"referenceID": 8, "context": "SAFE [17] and SAVE [43] have been among the most influential approaches in heuristic static malware detection, as these works inspired many researchers in this", "startOffset": 5, "endOffset": 9}, {"referenceID": 34, "context": "SAFE [17] and SAVE [43] have been among the most influential approaches in heuristic static malware detection, as these works inspired many researchers in this", "startOffset": 19, "endOffset": 23}, {"referenceID": 39, "context": "[48] X API \u2212 Itemset 2009 PE-Miner [42] X STC STC \u2212 2009 Tabish et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[48] X API \u2212 Itemset 2009 PE-Miner [42] X STC STC \u2212 2009 Tabish et al.", "startOffset": 35, "endOffset": 39}, {"referenceID": 35, "context": "[44] X BYT BYT N-gram 2009 Griffin et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[22] X BYT BYT Sequence 2009 Hu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[23] X \u2212 FC Graph 2010 Sami et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[39] X API \u2212 Itemset", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[35] X BYT BYT \u2212 2012 Jacob et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[24] X STC BYT N-gram 2013 Santos et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[40] X \u2212 OP Sequence 2014 Nissim et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[2] X BYT BYT N-gram 2015 DLLMiner [34] X X DLL \u2212 Tree", "startOffset": 35, "endOffset": 39}, {"referenceID": 35, "context": "Analysis is further carried out either directly on the bytecode [44, 2], or by disassembling the code and extracting opcodes and other relevant detailed information on the content of the program [40].", "startOffset": 64, "endOffset": 71}, {"referenceID": 31, "context": "Analysis is further carried out either directly on the bytecode [44, 2], or by disassembling the code and extracting opcodes and other relevant detailed information on the content of the program [40].", "startOffset": 195, "endOffset": 199}, {"referenceID": 38, "context": "[47].", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Static techniques have been also employed to assess if a malware detected in the wild is similar to a previously-seen variant, without actually performing the costly task of unpacking [24, 34].", "startOffset": 184, "endOffset": 192}, {"referenceID": 25, "context": "Static techniques have been also employed to assess if a malware detected in the wild is similar to a previously-seen variant, without actually performing the costly task of unpacking [24, 34].", "startOffset": 184, "endOffset": 192}, {"referenceID": 32, "context": "The task of disassembling a binary executable into its sequence of assembly instructions can be performed by two main techniques, namely by the linear sweep algorithm, and the recursive traversal algorithm [41].", "startOffset": 206, "endOffset": 210}, {"referenceID": 22, "context": "Entropy: Entropy (ENT) is a measure of the amount of disorder, and can be used to detect the possible presence of obfuscation [31, 10].", "startOffset": 126, "endOffset": 134}, {"referenceID": 1, "context": "Entropy: Entropy (ENT) is a measure of the amount of disorder, and can be used to detect the possible presence of obfuscation [31, 10].", "startOffset": 126, "endOffset": 134}, {"referenceID": 26, "context": "Image representation: An original way to represent a malware sample is to visualize the byte code by interpreting each byte as the gray-level of one pixel in an image [35].", "startOffset": 167, "endOffset": 171}, {"referenceID": 24, "context": "Although the implementation of calls depends both on the architecture, and on the optimal decision of compiler, indirect calls may reveal some information on data location obfuscation [33].", "startOffset": 184, "endOffset": 188}, {"referenceID": 5, "context": "frequent use in malicious applications [14], and measure the frequency of them in each malware sample.", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "While instruction replacement techniques can be used to evade detection [18], their effects on malware classification tasks is limited, both for its rare use, and, consequently, for its negligible contribution to the computation of the statistics.", "startOffset": 72, "endOffset": 76}, {"referenceID": 9, "context": "Register: Most of the processor registers in x86 architecture are used for dedicated tasks, but in some cases register renaming is used to make the analysis harder [18].", "startOffset": 164, "endOffset": 168}, {"referenceID": 16, "context": "One approach is the best subset selection technique [25] that can be summarized as follows.", "startOffset": 52, "endOffset": 56}, {"referenceID": 10, "context": "However, recently some researchers evaluated the performances of about 180 classifiers arising from different families, using various datasets, and they concluded that random forests and SVM are the two classification mechanisms that have the highest likelihood to produce good performances [19].", "startOffset": 291, "endOffset": 295}, {"referenceID": 6, "context": "In addition, we also use bagging [15] to boost our single model, which is simple, classifier independent, and yet an efficient method to improve the classification quality.", "startOffset": 33, "endOffset": 37}, {"referenceID": 7, "context": ", the mean decrease accuracy, and the mean decrease impurity [16].", "startOffset": 61, "endOffset": 65}, {"referenceID": 2, "context": "The proposed method has not yet been tested for robustness against evasion attacks [11, 28] or poisoning attacks [13, 12] because these kinds of attacks are more frequent against malware detectors rather than against malware classifiers.", "startOffset": 83, "endOffset": 91}, {"referenceID": 19, "context": "The proposed method has not yet been tested for robustness against evasion attacks [11, 28] or poisoning attacks [13, 12] because these kinds of attacks are more frequent against malware detectors rather than against malware classifiers.", "startOffset": 83, "endOffset": 91}, {"referenceID": 4, "context": "The proposed method has not yet been tested for robustness against evasion attacks [11, 28] or poisoning attacks [13, 12] because these kinds of attacks are more frequent against malware detectors rather than against malware classifiers.", "startOffset": 113, "endOffset": 121}, {"referenceID": 3, "context": "The proposed method has not yet been tested for robustness against evasion attacks [11, 28] or poisoning attacks [13, 12] because these kinds of attacks are more frequent against malware detectors rather than against malware classifiers.", "startOffset": 113, "endOffset": 121}], "year": 2017, "abstractText": "Modern malware is designed with mutation characteristics, namely polymorphism and metamorphism, which causes an enormous growth in the number of variants of malware samples. Categorization of malware samples on the basis of their behaviors is essential for the computer security community in order to group samples belonging to same family. Microsoft released a malware classification challenge in 2015 with a huge dataset of near 0.5 terabytes of data, containing more than 20K malware samples. The analysis of this dataset inspired the development of a novel paradigm that is effective in categorizing malware variants into their actual family groups. This paradigm is presented and discussed in the present paper, where emphasis has been given to the phases related to the extraction, and selection of a set of novel features for the effective representation of malware samples. Features can be grouped according to different characteristics of malware behavior, and their fusion is performed according to a per-class weighting paradigm. The proposed method achieved a very high accuracy (\u2248 0.998) on the Microsoft Malware Challenge dataset.", "creator": "LaTeX with hyperref package"}}}