{"id": "1511.06306", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Robust Convolutional Neural Networks under Adversarial Noise", "abstract": "recent studies have shown that convolutional neural networks ( cnns ) are vulnerable to a small numerical perturbation of input called \" adversarial examples \". in this work, we propose a new feedforward cnn that improves feedback robustness in the presence of associated adversarial noise. our model uses stochastic additive noise added to the input image and posterior to the cnn models. the proposed model operates in conjunction with a cnn trained with is standard backpropagation algorithm. in so particular, convolution, max - weight pooling, and relu layers are modified to benefit from the noise model. our sampling model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture. the proposed feature model outperforms the earlier standard cnn by 13. 12 % on imagenet and 7. 37 % on cifar - 10 under adversarial noise at the expense of 0. 28 % of accuracy drop when used in the original dataset - - with no added noise.", "histories": [["v1", "Thu, 19 Nov 2015 18:51:08 GMT  (423kb,D)", "https://arxiv.org/abs/1511.06306v1", "10 pages"], ["v2", "Thu, 25 Feb 2016 16:30:04 GMT  (86kb,D)", "http://arxiv.org/abs/1511.06306v2", "8 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["jonghoon jin", "aysegul dundar", "eugenio culurciello"], "accepted": false, "id": "1511.06306"}, "pdf": {"name": "1511.06306.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["ADVERSARIAL NOISE", "Jonghoon Jin", "Aysegul Dundar", "Eugenio Culurciello"], "emails": ["jhjin@purdue.edu", "adundar@purdue.edu", "euge@purdue.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Convolutional neural networks (CNNs) (LeCun et al., 1998) have shown great success in visual and semantic understanding. They have been applied to solve visual recognition problems, where hard-to-describe objects or multiple semantic concepts are present in images.\nGiven the global widespread use of cameras on mobile phones, CNNs are already a candidate to perform categorization of user photos. Device manufacturers use various types of cameras, each with very different sensor noise statistics (Tian, 2000). Also, recent phone cameras can record a video at hundreds of frames per second, where more frames per second translates into higher image noise (Tian, 2000). Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014). This problem arises because standard CNNs are discriminative models. This work provides a solution to improve instability of CNNs, for example in security applications.\nWhile Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al. (2015) used adversarial perturbation during training but not has been applied to natural images or more challenging image classification tasks. Similarly, Gu & Rigazio (2014) proposed a denoising model for adversary using auto-encoders.\nThe main contribution of this work is to propose a robust feedforward CNN model under adversarial noise; a noise that affects the performance the most. In order to achieve this, we add stochasticity to the CNN models with the assumption that the perturbation can be seen as a sample drawn from a white Gaussian noise. Our model takes advantage of a parametric model, which makes our method possible to scale up and apply to a large-scale dataset such as ImageNet."}, {"heading": "2 CONVOLUTIONAL NEURAL NETWORKS WITH NOISE MODEL", "text": "The proposed feedforward model uses a noise distribution applied to each pixel. The following subsections explain the stochastic operation of each layer, including convolution, pooling, and nonlinear activation. Also, the rest of operators used in standard CNNs can be found in appendix B.\nar X\niv :1\n51 1.\n06 30\n6v 2\n[ cs\n.L G\n] 2\n5 Fe\nb 20\n16"}, {"heading": "2.1 INPUT NOISE MODEL", "text": "We add an uncertainty to input images so the CNN output in hyperspace becomes a cloud with uncertainty information instead of a vector. We hypothesize that referring to the marginal data during classification helps CNNs to be robust toward adversarial examples. As a result of our modeling, each pixel becomes a random variable X in R3 (channel, height, width) and follows a normal distribution with the mean of the original pixel value \u00b5Xijk and a constant variance of \u03c3 2 N\nXijk , \u00b5Xijk +N =\u21d2 Xijk \u223c N(\u00b5Xijk , \u03c32N ) (1) where all input pixels have the same noise power of \u03c32N . The conditional independence of noise, for given value \u00b5Xijk , among pixels in neighborhood helps us to simplify the model and make it scalable to deep networks. To clarify, we adopted the artificial noise distribution in order to improve the robustness of CNNs and it is unrelated to natural image statistics."}, {"heading": "2.2 CONVOLUTION LAYER", "text": "While CNN inputs are modeled as random variables, all remaining parameters such as weights and biases are fixed constants. Convolution is a weighted sum of random variables and its first and second order moments of output of convolution layer are shown in equation 2.\nE [Y ] = \u2211 \u03c9E [X] + b, V ar [Y ] = \u2211 \u03c92V ar [X] (2)\nX and Y corresponds to a single element of the input and output in the convolution layer respectively. \u03c9 and b are weights and biases, and pixel index i, j and k are omitted for conciseness. We are interested in the first and second order statistics since we want to stay with a parametric model throughout layers, which simplifies overall computations."}, {"heading": "2.3 RECTIFIED LINEAR UNIT LAYER", "text": "Rectified linear units (ReLU) (Krizhevsky et al., 2012) applies the non-linearity Y = max(X, \u03b8) in an element-wise manner. Then, as illustrated in appendix A, the distribution of the stochastic ReLU output Y is left-censored where Y = X forX > \u03b8 otherwise reported as a single value \u03b8. The mean and variance (Greene, 2008) of output Y for the given normal distribution of input X are:\nE [Y ] = E[Y |X = \u03b8]Pr(Y = \u03b8|X) + E[Y |X > \u03b8]Pr(Y > \u03b8|X) = \u03b8\u03a6(\u03b1) + (\u00b5X + \u03c3X\u03bb(\u03b1)) (1\u2212 \u03a6(\u03b1))\nV ar [Y ] = EX [V ar[Y |X]] + V arX [E[Y |X]] = \u03c32X(1\u2212\u03a6(\u03b1)) [ (1\u2212\u03b4(\u03b1))+(\u03b1\u2212\u03bb(\u03b1))2\u03a6(\u03b1) ] (3) where \u03b4(\u03b1) = \u03bb(\u03b1)(\u03bb(\u03b1) \u2212 \u03b1), \u03bb(\u03b1) = \u03c6(\u03b1)/(1 \u2212 \u03a6(\u03b1)), a standard score \u03b1 = (\u03b8 \u2212 \u00b5X)/\u03c3X , a standard normal density of \u03c6 and a cumulative normal distribution of \u03a6 are used. Outputs from the convolution layer followed by non-linearity are reasonably approximated to be Gaussians by the central limit theorem considering that an output neuron has more than few hundreds of connections in general. Stochastic ReLU operator allows to deliver tail information of the distribution to the higher layer of CNNs regardless of the neuron\u2019s activation, which is expected to contribute better decision making."}, {"heading": "2.4 MAX-POOLING LAYER", "text": "Prediction from stochastic max-pooling is calculated based on the exact distribution of the max of two normal distributions (Nadarajah & Kotz, 2008) whose variables are sampled from a set S with elements in the pooling window. The pairwise max operation in the equation 4 is iteratively applied until no element left in the set S.\nE[Y ] = \u00b5Xi\u03a6 (\u03b1) + \u00b5Xj\u03a6 (\u2212\u03b1) + \u03b8\u03c6 (\u03b1) V ar[Y ] = (\u03c32Xi + \u00b5 2 Xi)\u03a6 (\u03b1) + (\u03c3 2 Xj + \u00b5 2 Xj )\u03a6 (\u2212\u03b1) + (\u00b5Xi + \u00b5Xj )\u03b8\u03c6 (\u03b1)\u2212 E[Y ] 2 (4)\nwhere \u03b1 = (\u00b5Xi\u2212\u00b5Xj ) \u03b8 , \u03b8 = \u221a \u03c32Xi + \u03c3 2 Xj\n. By approximating the output to a normal parametric distribution (see appendix A), we trade off accuracy for the sake of scalability of this method. According to Sinha et al. (2007) and appendix E, the ordering of iterative max operation should be set in an ascending order by their means to minimize approximation error."}, {"heading": "3 EXPERIMENTAL RESULTS", "text": "We denote the proposed method as \u201cstochastic feedforward (FF)\u201d throughout the section. The stochastic FF was applied to the Network-in-Network (NIN) (Lin et al., 2013) and the single column AlexNet (Krizhevsky, 2014) with the latest technique including dropout and batch normalization (Ioffe & Szegedy, 2015). The networks were trained with either standard or adversarial training (Goodfellow et al., 2014) for comparison. Their performance under adversarial noise was evaluated on CIFAR-10 and ImageNet classification datasets (Krizhevsky & Hinton, 2009; Russakovsky et al., 2014). The gradient sign method (Goodfellow et al., 2014) was used to generate adversarial examples that are more likely to appear in natural environment.\nThe table 1 summarizes the best classification results obtained from our experiments. In the presense of adversarial noise, the stochastic FF provides extra accuracy gain regardless of training methods at the cost of little accuracy drop in normal configuration \u2014 no added noise. The gain is more visible when the task is difficult or the noise is stronger. In the ImageNet test, adversarial training converges to a lower accuracy than the standard training, but also the adversarial training with a noise intensity higher than 0.1 fails to reach to a meaningful score; better than random guessing. Considering a byte-precision pixel range [0, 255], the adversarial training is limited for use in a hard task whereas the stochastic FF combined with standard training is still effective in high noise condition.\nCNNs\u2019 decision boundary is constructed based on sparsely populated training samples (Nguyen et al., 2014) in a high-dimension. Adversarial examples used in this experiment are populated around the decision boundary, therefore, they are often indistinguishable from natural images if one uses point-wise prediction. In the stochastic FF, uncertainty around the input pixel is propagated throughout every layer of CNNs and provides marginal information. Instead of point-wise prediction, integrating such information increases a chance to make correct prediction for adversarial examples. Adding stronger noise drags the adversarial examples farther apart from the correct decision region thereby lowering the accuracy as in appendix D.\nA downside of the stochastic FF is accuracy loss due to mistuned input variance or numerical instability. For example, an input distribution with high variance makes it more likely to be uniform where the ambiguity causes performance degradation. Users will have to make a choice whether to prefer small loss of classification for large gain in the presence of noise. For near-zero variance, each pixel distribution is shaped to a Dirac delta function. Without uncertainty, the model is equivalent to the standard feedforward while near-zero division causes numerical instability.\nThe stochastic model may be ensembled with the standard CNN model in order to compensate its weakness under the absence of adversarial noise. the ensemble model on ImageNet is more robust to adversarial noise than the baseline model by 13.12% but with only 0.28% of accuracy loss under normal configuration (appendix D)."}, {"heading": "4 CONCLUSION", "text": "We present new feedforward CNN with stochastic input model that is robust to the adversarial noise. The proposed model outperforms other methods in the literature and the accuracy gain becomes more evident for difficult classification task or stronger adversarial noise. Our model takes advantage of a parametric model, which makes our method scalable to a deep architecture like AlexNet. This work provides a solution how to overcome CNNs\u2019 sensitivity to the adversarial noise so as to avoid potential security problems in CNN applications."}, {"heading": "APPENDIX TO ROBUST CONVOLUTIONAL NEURAL NETWORKS UNDER ADVERSARIAL NOISE", "text": "A INPUT-OUTPUT DISTRIBUTION\nAn example in the figure 1a illustrates the input and output distributions from a single neuron in the ReLU layer, where the stem at \u03b8 indicates point mass probability for the deactivated area with respect to the threshold \u03b8. The output from the ReLU layer is a censored distribution whose approximation causes error during feedforward computation.\nThe figure 1b illustrates the input, output and approximated output distributions from max-pooling layer simulated with only two variables. The output distribution is bell-shaped, but its mode is inclined to the right. When means of the two inputs are farther, the resulting distribution is likely to be a normal distribution. In other words, the error between the exact distribution P (Y ) and its approximated Gaussian P (Y\u0302 ) tends to increase as the difference of means increases."}, {"heading": "B OTHER STOCHASTIC OPERATIONS", "text": "Along with the main operations previously discussed, standard CNNs consist of other modules such as batch normalization (Ioffe & Szegedy, 2015), spatial average pooling (Lin et al., 2013), softmax (or log-softmax) and dropout (Hinton et al., 2012).\nThe spatial average pooling and the batch normalization are linear functions and they can be processed with the convolution layer model. The average pooling used in NIN architecture is equivalent to convolution layer whose weights and biases are replaced with averaging coefficients (1/n) and zeroes respectively. Also, the net operation of batch normalization in evaluation phase is an affine transformation (equation 5) where \u03b3 and \u03b2 are constants learned from training, therefore, the same convolution modeling can be applied to here without extra approximation.\nY = \u03b3 (X \u2212 \u00b5X)\u221a \u03c32X + + \u03b2 (5)\nThe softmax with deterministic input produces pseudo-probabilities whose highest activation predicts class category. The proposed method adopts Gaussians to model intermediate representations\nthroughout the network. The strongest activation among all class distributions can be easily distinguished by the mean values of Gaussians. Therefore, we process mean values without variances as like in the normal softmax layer. Dropout neurons are simply deactivated and work as identity functions during evaluation."}, {"heading": "C PARAMETER TUNING", "text": "C.1 ADVERSARIAL EXAMPLES\nPrior to the experiment, adversarial examples are being generated through the fast gradient sign method proposed in Goodfellow et al. (2014). The method generates adversarial noise on top of natural images whose direction is toward the opposite of a gradient. Though the difference between the original and adversarial sample is imperceptible to human eyes, the perturbation makes the samples cross the decision boundary therefore classified as different categories. The noise can be interpreted as an exceptional type of noise although such examples are hardly observed in the natural environment.\nConsidering that the pixels encoded in an 8-bit image are positive integers in the range of [0, 255], the smallest and effective pixel intensity of the sign should be a multiple of 1/\u03c3C where \u03c3C is a standard deviation used for channel-wise normalization during data preprocessing. We denote kadv/\u03c3C as a normalized intensity of adversarial noise and only tune the pixel intensity kadv throughout all experiments. However, we used a continuous range along with effective intensities in byte representation so that input-output relation is more apparent and easily observable.\nC.2 INPUT VARIANCE TUNING\nUpon the creation of stochastic input model, we need to choose a variance for input distributions. The uncertainty variable (or input variance) is the only parameter in this model. The stochastic input is artificial modeling and it is designed to take into account the possible range of adversarial noise. Therefore, it needs to be tuned differently based on the intensity of adversarial noise.\nUsing very small variance for input makes the method mathematically equivalent to the baseline CNN model. However, both ReLU and max-pooling layer with the stochastic input model requires division, which is exposed to numerical instability from near-zero denominators. We found of 1e\u221220 minimized the numerical error. The number is adopted for regularizing the denominators both on CIFAR-10 and ImageNet."}, {"heading": "D MORE RESULTS", "text": ""}, {"heading": "E APPROXIMATION ERROR", "text": "The stochastic method based on a parametric model simplified computation, but it accompanies approximation in max-pooling and ReLU layer, which is a limiting factor of the algorithm.\nFrom the earlier section, it is expected that the max-pooling with stochastic input model produces approximation error and its quantity depends on the ordering of elements. We tested accuracy due to the approximation error from the plain and ordered max-pooling to check the effectiveness of sorting in the context of CNNs. A single column AlexNet has more max-pooling layers with a larger pooling region than the NIN. Therefore, it is more vulnerable to approximation error and used to observe the effectiveness as reported in figure 5. We found that the sorted max-pooling gave higher accuracy most of time compared to the plain order. The plain max-pooling fails to draw accurate approximation toward the exact distribution for a high variance model due to its heavytailed distribution. In terms of computation, the cost of the sorting is negligible considering the fact that the pooling is employed at most on an 3\u00d7 3 array in the literature (Krizhevsky et al., 2012).\nThe ReLU operator often suffers from numerical instability. Intermediate representations in CNNs are generally sparse meaning that many values are populated around zero. From the equation 3, these near-zero values combined with tiny input variance produce non-trivial standard scores, which requires regularization. This regularization process makes the approximated value deviate from its true value.\nIn general, as CNNs become deeper, they are also sensitive to error accumulated during feedforward computation. Additionally, performance improvement has been achieved at the cost of additional computation and memory space. In the stochastic model, each input or intermediate value other than model parameters such as weights and biases is represented as a set of mean and variance. Therefore, it requires about two times of memory usage than the standard feedforward model."}], "references": [{"title": "Training with noise is equivalent to tikhonov regularization", "author": ["Chris M Bishop"], "venue": "Neural computation,", "citeRegEx": "Bishop.,? \\Q1995\\E", "shortCiteRegEx": "Bishop.", "year": 1995}, {"title": "Explaining and harnessing adversarial examples", "author": ["Ian J Goodfellow", "Jonathon Shlens", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1412.6572,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Econometric analysis", "author": ["William H Greene"], "venue": "Granite Hill Publishers,", "citeRegEx": "Greene.,? \\Q2008\\E", "shortCiteRegEx": "Greene.", "year": 2008}, {"title": "Towards deep neural network architectures robust to adversarial examples", "author": ["Shixiang Gu", "Luca Rigazio"], "venue": "arXiv preprint arXiv:1412.5068,", "citeRegEx": "Gu and Rigazio.,? \\Q2014\\E", "shortCiteRegEx": "Gu and Rigazio.", "year": 2014}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Learning with a strong adversary", "author": ["Ruitong Huang", "Bing Xu", "Dale Schuurmans", "Csaba Szepesv\u00e1ri"], "venue": "arXiv preprint arXiv:1511.03034,", "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy.", "year": 2015}, {"title": "One weird trick for parallelizing convolutional neural networks", "author": ["Alex Krizhevsky"], "venue": "arXiv preprint arXiv:1404.5997,", "citeRegEx": "Krizhevsky.,? \\Q2014\\E", "shortCiteRegEx": "Krizhevsky.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": "Computer Science Department,", "citeRegEx": "Krizhevsky and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Yann LeCun", "L\u00e9on Bottou", "Yoshua Bengio", "Patrick Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Exact distribution of the max/min of two gaussian random variables", "author": ["Saralees Nadarajah", "Samuel Kotz"], "venue": "Very Large Scale Integration (VLSI) Systems, IEEE Transactions on,", "citeRegEx": "Nadarajah and Kotz.,? \\Q2008\\E", "shortCiteRegEx": "Nadarajah and Kotz.", "year": 2008}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Anh Nguyen", "Jason Yosinski", "Jeff Clune"], "venue": "arXiv preprint arXiv:1412.1897,", "citeRegEx": "Nguyen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein"], "venue": "arXiv preprint arXiv:1409.0575,", "citeRegEx": "Russakovsky et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russakovsky et al\\.", "year": 2014}, {"title": "Advances in computation of the maximum of a set of gaussian random variables. Computer-Aided Design of Integrated Circuits and Systems", "author": ["Debjit Sinha", "Hai Zhou", "Narendra V Shenoy"], "venue": "IEEE Transactions on,", "citeRegEx": "Sinha et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sinha et al\\.", "year": 2007}, {"title": "Intriguing properties of neural networks", "author": ["Christian Szegedy", "Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus"], "venue": "arXiv preprint arXiv:1312.6199,", "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Noise analysis in CMOS image sensors", "author": ["Hui Tian"], "venue": "PhD thesis, Citeseer,", "citeRegEx": "Tian.,? \\Q2000\\E", "shortCiteRegEx": "Tian.", "year": 2000}, {"title": "ADVERSARIAL EXAMPLES Prior to the experiment, adversarial examples are being generated through the fast gradient sign method proposed in Goodfellow et al", "author": ["C PARAMETER TUNING C"], "venue": null, "citeRegEx": "C.1,? \\Q2014\\E", "shortCiteRegEx": "C.1", "year": 2014}], "referenceMentions": [{"referenceID": 10, "context": "Convolutional neural networks (CNNs) (LeCun et al., 1998) have shown great success in visual and semantic understanding.", "startOffset": 37, "endOffset": 57}, {"referenceID": 16, "context": "Device manufacturers use various types of cameras, each with very different sensor noise statistics (Tian, 2000).", "startOffset": 100, "endOffset": 112}, {"referenceID": 16, "context": "Also, recent phone cameras can record a video at hundreds of frames per second, where more frames per second translates into higher image noise (Tian, 2000).", "startOffset": 144, "endOffset": 156}, {"referenceID": 15, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 1, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 12, "context": "Unfortunately, CNNs are vulnerable to artificial noise and could be easily fooled by the noise of just few pixels (Szegedy et al., 2013; Goodfellow et al., 2014; Nguyen et al., 2014).", "startOffset": 114, "endOffset": 182}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al.", "startOffset": 6, "endOffset": 20}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al.", "startOffset": 6, "endOffset": 109}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al. (2015) used adversarial perturbation during training but not has been applied to natural images or more challenging image classification tasks.", "startOffset": 6, "endOffset": 130}, {"referenceID": 0, "context": "While Bishop (1995) showed that training with noise is equivalent to a regularizer, Goodfellow et al. (2014); Huang et al. (2015) used adversarial perturbation during training but not has been applied to natural images or more challenging image classification tasks. Similarly, Gu & Rigazio (2014) proposed a denoising model for adversary using auto-encoders.", "startOffset": 6, "endOffset": 298}, {"referenceID": 9, "context": "Rectified linear units (ReLU) (Krizhevsky et al., 2012) applies the non-linearity Y = max(X, \u03b8) in an element-wise manner.", "startOffset": 30, "endOffset": 55}, {"referenceID": 2, "context": "The mean and variance (Greene, 2008) of output Y for the given normal distribution of input X are: E [Y ] = E[Y |X = \u03b8]Pr(Y = \u03b8|X) + E[Y |X > \u03b8]Pr(Y > \u03b8|X) = \u03b8\u03a6(\u03b1) + (\u03bcX + \u03c3X\u03bb(\u03b1)) (1\u2212 \u03a6(\u03b1)) V ar [Y ] = EX [V ar[Y |X]] + V arX [E[Y |X]] = \u03c3 X(1\u2212\u03a6(\u03b1)) [ (1\u2212\u03b4(\u03b1))+(\u03b1\u2212\u03bb(\u03b1))\u03a6(\u03b1) ] (3)", "startOffset": 22, "endOffset": 36}, {"referenceID": 14, "context": "According to Sinha et al. (2007) and appendix E, the ordering of iterative max operation should be set in an ascending order by their means to minimize approximation error.", "startOffset": 13, "endOffset": 33}, {"referenceID": 5, "context": "4 LWA + BN (Huang et al., 2015) 89.", "startOffset": 11, "endOffset": 31}, {"referenceID": 1, "context": "3 \u2014 \u2014 \u2014 Adversarial training (Goodfellow et al., 2014) 88.", "startOffset": 29, "endOffset": 54}, {"referenceID": 7, "context": ", 2013) and the single column AlexNet (Krizhevsky, 2014) with the latest technique including dropout and batch normalization (Ioffe & Szegedy, 2015).", "startOffset": 38, "endOffset": 56}, {"referenceID": 1, "context": "The networks were trained with either standard or adversarial training (Goodfellow et al., 2014) for comparison.", "startOffset": 71, "endOffset": 96}, {"referenceID": 13, "context": "Their performance under adversarial noise was evaluated on CIFAR-10 and ImageNet classification datasets (Krizhevsky & Hinton, 2009; Russakovsky et al., 2014).", "startOffset": 105, "endOffset": 158}, {"referenceID": 1, "context": "The gradient sign method (Goodfellow et al., 2014) was used to generate adversarial examples that are more likely to appear in natural environment.", "startOffset": 25, "endOffset": 50}, {"referenceID": 12, "context": "CNNs\u2019 decision boundary is constructed based on sparsely populated training samples (Nguyen et al., 2014) in a high-dimension.", "startOffset": 84, "endOffset": 105}], "year": 2016, "abstractText": "Recent studies have shown that Convolutional Neural Networks (CNNs) are vulnerable to a small perturbation of input called \u201cadversarial examples\u201d. In this work, we propose a new feedforward CNN that improves robustness in the presence of adversarial noise. Our model uses stochastic additive noise added to the input image and to the CNN models. The proposed model operates in conjunction with a CNN trained with either standard or adversarial objective function. In particular, convolution, max-pooling, and ReLU layers are modified to benefit from the noise model. Our feedforward model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture. From CIFAR-10 and ImageNet test, the proposed model outperforms other methods and the improvement is more evident for difficult classification tasks or stronger adversarial noise.", "creator": "LaTeX with hyperref package"}}}