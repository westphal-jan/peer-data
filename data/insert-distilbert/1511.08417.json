{"id": "1511.08417", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2015", "title": "TGSum: Build Tweet Guided Multi-Document Summarization Dataset", "abstract": "the development of summarization research has been substantially significantly hampered by the costly acquisition of reference summaries. this milestone paper proposes an effective way to automatically collect large scales of news - related multi - document summaries with reference to predicting social media's reactions. we utilize two types of social labels in tweets, i. e., hashtags and hyper - links. hashtags are used to cluster documents into different topic sets. also, a tweet with a hyper - link often highlights certain key points of the corresponding document. we synthesize a linked document linked cluster to form a reference summary which can cover most key points. to this aim, we adopt the rouge metrics to measure the coverage ratio, and develop an integer posterior linear programming solution to discover the sentence set reaching the same upper bound of rouge. since we allow summary sentences to be selected from both documents and high - quality tweets, the generated reference summaries could be abstractive. both informativeness and readability of the collected summaries alone are verified by manual judgment. in addition, we furthermore train a support vector regression summarizer on duc generic multi - document summarization benchmarks. with the collected data as adding extra training resource, the performance of the objective summarizer improves a lot on all the test sets. we release this dataset for further research.", "histories": [["v1", "Thu, 26 Nov 2015 15:22:54 GMT  (64kb,D)", "http://arxiv.org/abs/1511.08417v1", "7 pages, 1 figure in AAAI 2016"]], "COMMENTS": "7 pages, 1 figure in AAAI 2016", "reviews": [], "SUBJECTS": "cs.IR cs.CL", "authors": ["ziqiang cao", "chengyao chen", "wenjie li", "sujian li", "furu wei", "ming zhou 0001"], "accepted": true, "id": "1511.08417"}, "pdf": {"name": "1511.08417.pdf", "metadata": {"source": "CRF", "title": "TGSum: Build Tweet Guided Multi-Document Summarization Dataset", "authors": ["Ziqiang Cao", "Chengyao Chen", "Wenjie Li", "Sujian Li", "Furu Wei", "Ming Zhou"], "emails": ["cswjli}@comp.polyu.edu.hk", "lisujian@pku.edu.cn", "mingzhou}@microsoft.com"], "sections": [{"heading": "Introduction", "text": "The rapid growth of on-line digital content calls for efficient automatic summarization systems. So far, the learningbased models have become the dominant summarization approaches. Despite decades of research, the quality of a machine generated summary is still far from satisfactory. A big bottleneck of supervised summarizers is the lack of human summaries used for training. For instance, the generic multi-document summarization task aims to summarize a cluster of documents telling the same topic. In this task, the most widely-used datasets are published by Document Understanding Conferences2 (DUC) in 01, 02 and\nCopyright c\u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\n1http://www4.comp.polyu.edu.hk/\u02dccszqcao/ 2http://duc.nist.gov/\n04. Totally, there are 139 document clusters with 376 human reference summaries. The limitation of labeled data forces a learning-based summarization system to heavily rely on well-designed features. Sometimes unsupervised approaches (e.g., (Rioux, Hasan, and Chali 2014)) even outperform supervised ones.\nBasically, there are two major factors restricting manual annotation. On the one hand, summarization is an extremely time consuming and labor-intensive process. Before writing a summary, annotators have to read and understand the whole document(s). On the other hand, it is very subjective. Even experts fail to reach a consensus. As a result, DUC has to provide multiple reference summaries in order to have a relatively objective evaluation. In this paper, we suggest an effective way to automatically collect large-scales of news multi-document summaries with reference to social media\u2019s reactions on Twitter. Previously, a series of NLP tasks have tried to utilize the social annotations like followers (Chen et al. 2014), emoticons (Zhao et al. 2012) and responses (Hu et al. 2014) etc. Here two kinds of common social labels, i.e., hyper-links and hashtags are leveraged for our purpose. A hashtag in the news area often serves for the brief description of an event. For example, given \u201c#BangkokBlast\u201d, we know the tweets with this hashtag all talk about the recent terrorist attack in Bangkok. Therefore, it is a nice indicator to cluster documents into the same topic. On the other hand, we take advantage of linked tweets (i.e., tweets with hyperlinks) to generate the optimal reference summary for a document cluster. From our observation, linked tweets hold the following properties: \u2022 A large proportion of linked tweets can highlight key\npoints of related news; \u2022 Tags such as \u201c#\u201d and \u201c@\u201d frequently appears in a linked\ntweet, bringing a large amount of noise; \u2022 Due to the length limitation, most tweets are shortened\nand describe only one aspect of related documents. The noise and incompleteness hamper a linked tweet to directly become a reference summary. Take the tweets in Table 1 as an example. This document describes how Greece\u2019s Crisis drowns the life of a sardine fisherman. Since the local fish industry owns the world first robotic sardine processing line, Tweet 1 is interested in how it works. Tweet 2 and 3 both describe the key points of this paper, like \u201cGreece\u201d,\nar X\niv :1\n51 1.\n08 41\n7v 1\n[ cs\n.I R\n] 2\n6 N\nov 2\n01 5\n\u201cfish industry\u201d and \u201ccrisis\u201d, but Tweet 2 can be used as the title while Tweet 3 tells author\u2019s writing experience. Although all the three tweets are able to indicate saliency, none of them is appropriate to be a part of the summary. Tweet 1 is shortened, Tweet 2 is not a complete sentence, and Tweet 3 contains many tags.\nNotably, sentences in the news documents are usually well-written. Therefore, we do not directly treat linked tweets as reference summaries. Instead, we select sentences from both the document cluster and high-quality tweets to form a reference summary which can cover most key points in tweets. This practice has the following advantages. First, the summary is far more readable than tweets and meanwhile provides a complete description of a news document cluster. Second, the length of a reference summary is controllable. A similar idea is adopted by (Filippova and Altun 2013). They use the highlight and the first news sentence to build the sentence compression pair. Also because the highlights are usually not the complete sentences, they utilize highlights to indicate which syntactical structures in the original sentences can be removed. In TGSum, we introduce the most widely-used summary evaluation metrics ROUGE (Lin 2004) to measure the coverage ratio of key points, and develop an Integer Linear Programming (ILP) solution to discover the sentence set which can reach the ROUGE upper bound.\nWithin one month, TGSum collects 4658 linked tweets in overall. Table 2 lists the basic information of TGSum and compares it with DUC datasets. On average, a document cluster in TGSum contains 23 tweets, ensuring to generate reference summaries in different generalization degrees. In terms of the cluster number, our dataset has already exceeded the scale of DUC datasets, and it is still growing every day. Once the reference summaries are generated, we conduct extensive experiments to verify the quality and effect of this dataset. About 30% summary sentences come from linked tweets, indicating summaries in TGSum are abstractive in certain degree. Manual judgment demonstrates that the majority of these summaries are informative and readable. In addition, we train a Support Vector Regression (SVR) summarizer on DUC generic multi-document summarization benchmarks. With the collected TGSum dataset as the extra training resource, the performance of SVR summarizer improves a lot on all test sets.\nThe contributions of this paper are listed as follows: 1. We propose to collect multi-document news summaries\nwith the help of social media\u2019s reactions; 2. We develop an ILP solution to generate summaries reach-\ning the upper bound of ROUGE; 3. We publish this dataset for further research."}, {"heading": "TGSum Construction", "text": "This section explains how we build TGSum, i.e., a multidocument summarization dataset guided by tweets. There are 4 main steps. The URL acquisition step catches proper news URLs. These URLs are in turn used in the data collection step to extract the linked tweets and news documents. Afterwards, news documents are clustered based on the hashtags embedded in tweets. Finally, for the news documents to be summarized, an Integer Linear Programming (ILP) solution is developed to generate reference summaries which cover as many key points provided in tweets as possible. Below is the detailed description of these steps."}, {"heading": "URL Acquisition", "text": "At the beginning, we have tried to directly extract linked tweets through searching trends on Twitter. However, most trends are concerned with the entertainment circle, referring people to the picture or video pages. It is thereby not appropriate for document summarization. Thus, we design an alternative strategy which firstly discovers news URLs. Specifically, through the Twitter search function, 74 active news accounts like New York Times, Reuters and CNN who have published tweets within a month are selected as seed users. All the DUC news providers are included to ensure the generated dataset is uniform with DUC. Next, by applying the Twitter user streaming API, we track all seed users\u2019 tweets from August 13th to September 13th. Despite many replications of news titles, these tweets provide the URLs of hot news published by the corresponding news accounts. We do not focus on a particular domain or type of news. From observation, the collected pieces of news come from a wide range of topics, including finance, politics, sports, disaster and so on. This open-domain dataset gives us the chance to learn summarization behavior in different genres."}, {"heading": "Data Collection", "text": "Given a news URL, we collect its document as well as linked tweets. The news content is retrieved with the open Python package newspaper3. We just reserve the main body of a document. Then we apply the Twitter term search API to extract linked tweets, and conduct careful preprocessing as below: \u2022 Discard retweets;\n3https://pypi.python.org/pypi/newspaper\n\u2022 Delete non-English tokens in a tweet; \u2022 Remove tweets which contains less than 5 tokens; \u2022 Merge identical tweets. At the end, we collect 13207 valid tweets from 4483 news documents."}, {"heading": "Cluster Formation", "text": "It is common that different newswires publish multiple versions of documents about the same news. These documents are clustered together to present a more complete description of an event. With regard to our dataset, hashtags provide a simple and accurate way to achieve this goal. After removing general hashtags such as #ThisWeek and #ICYMI (i.e., In Case You Missed It), the hashtags related to news are usually the key phrases of the event. For instance, #GreeceCrisis refers to the financial crisis of Greece. When we further restrict to cluster documents in the same day, it is very likely that the documents pointed by the same hashtag describe the identical news. For a document attached to no hashtag, we put it into an existing cluster if its TF cosine similarity with the cluster exceeds a threshold, e.g., 0.5 as we set. After removing clusters which have less than 3 documents or less than 8 linked tweets, we retain 1114 documents in 204 clusters."}, {"heading": "Reference Generation", "text": "As mentioned above, most tweets are incomplete and contain noises, which are not suitably included in a summary directly. Since the sentences in the original news documents are usually well-written, we decide to \u201csynthesize\u201d reference summaries by selecting sentences from both news documents and high-quality tweets as long as they are good representatives of the news information. We expect the generated reference summaries could cover most key points of tweets. Here we adopt ROUGE to measure the coverage ratio. Through the analysis of ROUGE, we develop an ILP based solution to sentence selection, making sure the generated reference summary reaching the upper bound of ROUGE.\nAnalysis of ROUGE Measurement ROUGE counts the overlapping units such as the n-grams, word sequences or word pairs between the two pieces of text. Take the widelyused ROUGE-2 as an example. The coverage score between a candidate summary and a linked tweet i is:\nROUGE \u2212 2i = \u2211\nbGaini(b)\u2211 b ntwti(b)\n(1)\nwhere b stands for a bi-gram, and ntwti(b) is the number of bi-gram b in the ith linked tweet. Gaini(b) is the maximum number of bi-gram co-occurring in the candidate summary and linked tweet:\nGaini(b) = min{ntwti(b), ncnd(b)} (2)\nGiven a linked tweet, its total bi-gram count is a fixed value. Therefore we can rewrite Eq. 1 to\nROUGE \u2212 2i = wb,twti \u2211\nb Gaini(b) (3)\nwherewb,twti = 1\u2211\nb ntwti (b) could be regarded as the weight\nfor the linked tweet. For a set of linked tweets, ROUGE averages their scores.\nROUGE \u2212 2 = 1 K \u2211K i=1 (wtwti \u2211 b Gaini(b)), (4)\nUse z(s) \u2208 {0, 1} to indicate whether or not a sentence s is selected in the candidate summary. We can represent the maximization of ROUGE-2 under the length constraint L as the following optimization function:\nmax \u2211K\ni=1 (wb,twti \u2211 b min{ntwti(b), ncnd(b)}) (5)\ns.t. ncnd(b) = \u2211\ns z(s)\u00d7 ns(b) (6)\u2211\ns z(s)\u00d7 |s| \u2264 L (7) z(s) \u2208 {0, 1}, \u2200s (8) where ns(b) is the frequency of b in sentence s. The meaning of each constraint as follows: Constraint 6 calculates the number of b in the current sum-\nmary. Constraint 7 satisfies the summary length limit. Constraint 8 defines a binary variable z(s).\nAll the above formulas are linear expect the gain function. Note the minimization problem can be computed as follows:\nGaini(b) \u2264 ntwti(b) (9) Gaini(b) \u2264 ncnd(b) (10)\nGaini(b) = ntwti(b) || Gaini(b) = ncnd(b) (11) Constraints 9 and 10 ensure Gaini(b) \u2264 min{ntwti(b), ncnd(b)}, while Constraint 11 can be solved by the big M formula or indicator constraints4. But there is a much simpler solution in this task. Since the objective function is maximization of Gaini(b), this constraint will be realized automatically. Finally, the whole linear programming formulas are listed below:\nmax \u2211K\ni=1 (wb,twti \u2211 b Gaini(b)) (12)\ns.t. ncnd(b) = \u2211\ns z(s)\u00d7 ns(b)\u2211\ns z(s)\u00d7 |s| \u2264 L\nz(s) \u2208 {0, 1} Gaini(b) \u2264 ntwti(b), \u2200b, i Gaini(b) \u2264 ncnd(b), \u2200b, i\nThe work of (Li, Qian, and Liu 2013) also proposes an linear programming function for the maximization of ROUGE. Based on the fact that min(a, x) = 0.5(\u2212|x\u2212 a|+ x+ a), they introduce auxiliary variables and convert the maximization of Eq. 1 into\nmax \u2211\nb (ncnd(b)\u2212 Ci(b))\ns.t. Ci(b) \u2265 ncnd(b)\u2212 ntwti(b), \u2200b, i Ci(b) \u2265 ntwti(b)\u2212 ncnd(b), \u2200b, i\n4http://www-01.ibm.com/support/docview. wss?uid=swg21400084\nwhere Ci(b) is an auxiliary variable equal to |ncnd(b) \u2212 ntwti(b)| in the solution. However, they do not provide details to tackle the case of multiple measurements. Compared with their approach, our model represents the gain function without transformation, which greatly speeds up the solution procedure. In the next section, we illustrate how to extend the model to multiple ROUGE variants.\nExtension to Multiple ROUGE Variants The abovementioned approach generates the optimal summary for ROUGE-2. Actually, other ROUGE variants such as ROUGE-1 are also very useful (Owczarzak et al. 2012). Our preliminary experiments also show that only 49% bi-grams in the linked tweets appear in the original documents, while over 83% uni-grams can be found. Thus we attempt to generate reference summaries that optimize both ROUGE-2 and ROUGE-1. We modify Objective Function 12 into\nmax (1\u2212 \u03bb) \u2211K\ni=1 (wb,twti \u2211 b Gaini(b))\n+ \u03bb \u2211K\ni=1 (wu,twti \u2211 u Gaini(u)), (13)\nwhere u stands for a uni-gram and \u03bb \u2208 [0, 1] is the trade-off between ROUGE-2 and ROUGE-1. When \u03bb comes close to 0 (e.g., 0.0001 in the experiment), we implement the effect that the selected summary is the optimum of ROUGE-2 and its ROUGE-1 is as large as possible.\nAlthough ILP is NP-hard in general, considerable researches have produced a number of effective solution tools. In this paper, we adopt the IBM CPLEX Optimizer5 which is a high-performance mathematical programming solver.\nTo ensure the sentence-level readability, we choose declarative sentences in the documents and tweets as candidate summary sentences, and then adopt Eq. 13 to generate reference summaries. In line with DUC, we set the summary length to 100 words."}, {"heading": "Experiment", "text": "Firstly, we inspect the content of the collected linked tweets. We check whether they really provide certain news key points. Then, we analyze the quality of the generated summaries. Both automatic and manual evaluations are conducted. Finally, we design a supervised summarization model to verify the effect of the TGSum dataset."}, {"heading": "Linked Tweet Analysis", "text": "During the data collection, we find that most linked tweets are simply the extraction of news titles, but still each document can receive three unique linked tweets on average. We categorize these unique tweets in accordance with the summarization task.\nExtraction: The tweet is directly extracted from original text.\nCompression: The same word sequence in a tweet can be found in a document sentence (except extraction).\n5http://www-01.ibm.com/software/commerce/ optimization/cplex-optimizer/\nAbstraction: Over 80% words of a tweet can be found in the news document, and located in more than one sentence.\nOther: The rest tweets. From our observation, most of them are comments.\nAn example is provided for each tweet type in Table 3. All the four tweets are from a news cluster describing #BangkokBlast. We use bold font to indicate the words appearing in the news. It is noteworthy that the original document uses the word \u201cbelieve\u201d whereas the abstraction tweet chooses its synonym \u201cthink\u201d. The second and third tweets are really salient and condensed, which demonstrates Twitter users are willing to summarize the documents. The proportions of different tweet types are shown in Fig. 1. Note that our definition makes some abstraction tweets misclassified into the Other type. Thus the real abstraction tweets should occupy a larger proportion. The direct extraction behavior (except title) in linked tweets seems to be rare. Users prefer adding tags to raise social communication. In total, over 70% of linked tweets are compression or abstraction, which shows its potential applications in learning the summary sentence generation models. In the generated reference summaries, we find 30% sentences come from linked tweets. Therefore TGSum provides the abstractive version of references to some extent."}, {"heading": "Quality of TGSum", "text": "ROUGE Evaluation Now we verify the accuracy of our ILP-based ROUGE upper bound generation algorithm. We choose \u03bb \u2208 0, 1, 0.0001, which means selecting sentences according to ROUGE-2, ROUGE-1 and their combination. We refer to the corresponding model summaries as UB-1, UB-2 and UB-Combination respectively. As a contrast, we design a baseline applying the greedy algorithm. It iteratively adds the sentence bringing the maximal ROUGE gain into the summary. Likewise, the summaries generated according to ROUGE-1 and ROUGE-2 are called GA-1 and GA-2. The ROUGE scores measured by linked tweets are shown in Table 4. Obviously, the ILP solution achieves much larger ROUGE scores than the greedy algorithm. Then we compare three types of summaries derived from different \u03bb values. It is noted that both UB-2 and UB-Combination reach the upper bound of ROUGE-2, but the ROUGE-1 score of UB-Combination is higher. We thereby include the\nsummaries generated by UB-Combination in TGSum as reference summaries.\nManual Evaluation We manually evaluate the sentence quality in the generated reference summaries. Two metrics are used, i.e., informativeness and readability. Since TGSum serves for learning-based summarization models, we do not consider the coherence of an entire summary. For each metrics, a summary sentence is classified into three levels, namely good, OK and bad. Linked tweets are also evaluated for comparison. The results are presented in Table 5. As seen, most sentences in the reference summaries are both informative and readable. The former owes to the saliency of most linked tweets, while the candidate sentence selection strategy brings the nice readability. Since a generated reference is the ROUGE upper bound measured by the set of linked tweets, a small amount of noised tweets will be excluded. Thus the number of unimportant sentences in reference summaries is much smaller than that in linked tweets. A bad case we find is the cluster about \u201c#BBCBizQuiz\u201d. All the tweets are questions. As a result, the reference summary fails to locate the salient sentences. With regard to readability, a large part of linked tweets are merely regarded as OK because they are not the complete sentences at all. By contrast, sentences in reference summaries are usually formal and readable. Quite a few summary sentences marked as OK are due to the splitting errors. For instance, sometimes a section title is attached to a sentence. Meanwhile, a pronoun at the beginning of a sentence brings the co-reference ambiguity problem."}, {"heading": "Effect of TGSum", "text": "To verify the effect of TGSum, we examine whether it can be used to improve the performance of summarization systems on DUC benchmarks. We design a supervised Support Vector Regression (SVR) summarizer (Li et al. 2007; Cao et al. 2015b). To be concrete, each sentence in the training set is scored by ROUGE-2. Then we extract the features such as TF (the averaged TF scores of the sentence), LENGTH (sentence length), and STOP-RATIO (the ratio of stopwords), and train SVR to measure the saliency of sentences. For testing, we follow the greedy algorithm (Li and Li 2014) to select salient sentences into a summary. According to (Cao et al. 2015b), the SVR summarizer achieves competing performance against the best participates in DUC. It is a standard learning-based summarization model, which is enough to emphasize the effect of training data. We train this summarizer on different datasets and test it on DUC. The ROUGE results are shown in Table 6. Here \u201cDUC\u201d stands for DUC datasets except the testing year, and \u201cTWT REF\u201d means the same documents as TGSum but directly use tweets as reference summaries. Seeing from this table, ROUGE scores always enjoy a considerable increase when adding TGSum as an extra training set. In addition, even only given the TGSum dataset for training, the summarizer can still achieve comparable performance, especially on DUC 02. Thus, the effect of TGSum references is similar to the manual annotations of DUC, although the former is generated according to tweets automatically. In comparison to TGSum, directly using tweets as references does not always improve the summarization performance. The noise in tweets may misguide the model learning. For example, when treating tweets as references, the feature STOP-\nRATIO holds extremely high positive weight. This improper feature weight can be ascribed to the informal writing style on Twitter, and it obviously fails to match the informativeness requirement."}, {"heading": "Related Work", "text": ""}, {"heading": "Summarization with Twitter", "text": "Most summarization work on Twitter try to directly summarize tweets in a given topic. Due to the lack of reference summaries, most researchers have to use unsupervised methods. (Sharifi, Hutton, and Kalita 2010a) detected important phrases in tweets with a graph-based algorithm. But soon, the authors (Sharifi, Hutton, and Kalita 2010b) developed a simpler \u201cHybrid TF-IDF\u201d method, which ranked tweet sentences using the TF-IDF scheme and produced even better results. A more complicated work was reported by (Liu, Liu, and Weng 2011), which relied on Integer Linear Programming to extract sentences with most salient n-grams. It is worth mentioning that this paper highlighted the use of documents linked to the tweet set. The saliency was measured according to TF in the documents, and their experiments demonstrated that allowing summary sentences to be selected from both tweets and documents achieved the best performance. Recently, some papers (Yang et al. 2011; Wei and Gao 2014) simultaneously conducted single-document and tweet summarization based on cross-media features.\nThe above researches focus on tweet summarization, where documents provide additional features. There are a limited number of papers about utilizing tweets to collect summarization data. The only work we know is (Lloret and Palomar 2013), who treated linked tweets as reference summaries and attempted to apply extractive summarization techniques to generate them. They found that linked tweets were informative but their writing quality was inferior to extracted sentences. This work is equivalent to our practice which synthesizes reference summaries on the basis of linked tweets. Moreover, their dataset only has 100 En-\nglish news documents and only suits single-document summarization. In contrast, we build a far larger dataset and apply it to multi-document summarization."}, {"heading": "ILP for Summarization", "text": "Integer Linear Programming has been widely applied in summarization because it can appropriately model item selection state. (McDonald 2007) originally introduced ILP in this area. He constructed summaries by maximizing the importance of the selected sentences and minimizing their pairwise similarity, which was the extension of a greedy approach called Maximum Marginal Relevance (MMR) (Carbonell and Goldstein 1998). Given N sentences, his model contains O(N2) binary variables. Thus it is quite inefficient when searching the optimal solution. Later, (Gillick and Favre 2009) proposed to treat summarization as concept coverage maximization, where redundancy was implicitly measured by benefiting from including each concept only once. They used bi-grams as the concept representation. The same idea was followed by many researches (Woodsend and Lapata 2012; Li, Qian, and Liu 2013). Recently, (Schluter and S\u00f8gaard 2015) reported that syntactic and semantic concepts might also be helpful, and some papers such as (Cao et al. 2015a) combined sentence and concept selection process. With heuristic rules, ILP can apply to compress (Gillick and Favre 2009; Berg-Kirkpatrick, Gillick, and Klein 2011) or even fuse (Bing et al. 2015)."}, {"heading": "Conclusion", "text": "This paper presents an effective way to automatically collect large-scales of news multi-document summaries with reference to social media\u2019s reactions. We use hashtags to cluster documents into different topic sets, and then \u201csynthesize\u201d reference summaries which are able to cover most important key points embedded in the linked tweets within the cluster. To measure the coverage ratio, we adopt ROUGE metrics and develop an ILP solution to discover its upper bound. Manual evaluation verifies the informativeness and readability of the collected reference summaries. In addition, we train a SVR summarizer on DUC generic multi-document summarization benchmarks. With the collected data as extra training resource, the performance of this summarizer improves significantly on all test sets.\nThe current work focuses on generic multi-document summarization. However, we believe our dataset can be used in many other scenarios. On the one hand, the compression type of linked tweets is an ideal source for learning sentence compression. On the other hand, we are interested in adapting our dataset to update summarization by tracking the same hashtag published on different dates.\nAcknowledgments The work described in this paper was supported by the grants from the Research Grants Council of Hong Kong (PolyU 5202/12E and PolyU 152094/14E) and the National Natural Science Foundation of China (61272291, 61273278 and 61572049). The correspondence authors of this paper are Wenjie Li and Sujian Li."}], "references": [{"title": "Jointly learning to extract and compress", "author": ["Gillick Berg-Kirkpatrick", "T. Klein 2011] BergKirkpatrick", "D. Gillick", "D. Klein"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume", "citeRegEx": "Berg.Kirkpatrick et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2011}, {"title": "Abstractive multi-document summarization via phrase selection and merging", "author": ["Bing"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Bing,? \\Q2015\\E", "shortCiteRegEx": "Bing", "year": 2015}, {"title": "Ranking with recursive neural networks and its application to multi-document summarization", "author": ["Cao"], "venue": "In Twenty-Ninth AAAI Conference on Artificial Intelligence", "citeRegEx": "Cao,? \\Q2015\\E", "shortCiteRegEx": "Cao", "year": 2015}, {"title": "Learning summary prior representation for extractive summarization", "author": ["Cao"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference", "citeRegEx": "Cao,? \\Q2015\\E", "shortCiteRegEx": "Cao", "year": 2015}, {"title": "The use of mmr, diversity-based reranking for reordering documents and producing summaries", "author": ["Carbonell", "J. Goldstein 1998] Carbonell", "J. Goldstein"], "venue": "In Proceedings of SIGIR,", "citeRegEx": "Carbonell et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Carbonell et al\\.", "year": 1998}, {"title": "Inferring topic-dependent influence roles of twitter users", "author": ["Chen"], "venue": "In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,", "citeRegEx": "Chen,? \\Q2014\\E", "shortCiteRegEx": "Chen", "year": 2014}, {"title": "Overcoming the lack of parallel data in sentence compression", "author": ["Filippova", "K. Altun 2013] Filippova", "Y. Altun"], "venue": null, "citeRegEx": "Filippova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Filippova et al\\.", "year": 2013}, {"title": "A scalable global model for summarization", "author": ["Gillick", "D. Favre 2009] Gillick", "B. Favre"], "venue": "In Proceedings of the Workshop on ILP for NLP,", "citeRegEx": "Gillick et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gillick et al\\.", "year": 2009}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hu,? \\Q2014\\E", "shortCiteRegEx": "Hu", "year": 2014}, {"title": "Query-focused multi-document summarization: Combining a topic model with graph-based semi-supervised learning", "author": ["Li", "Y. Li 2014] Li", "S. Li"], "venue": "In Proceedings of COLING,", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Multi-document summarization using support vector regression", "author": ["Li"], "venue": "In Proceedings of DUC", "citeRegEx": "Li,? \\Q2007\\E", "shortCiteRegEx": "Li", "year": 2007}, {"title": "Using supervised bigram-based ilp for extractive summarization", "author": ["Qian Li", "C. Liu 2013] Li", "X. Qian", "Y. Liu"], "venue": "In Proceedings of ACL,", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Lin", "C.-Y"], "venue": "In Proceedings of the ACL Workshop,", "citeRegEx": "Lin and C..Y.,? \\Q2004\\E", "shortCiteRegEx": "Lin and C..Y.", "year": 2004}, {"title": "Why is sxsw trending?: exploring multiple text sources for twitter topic summarization", "author": ["Liu Liu", "F. Weng 2011] Liu", "Y. Liu", "F. Weng"], "venue": "In Proceedings of the Workshop on Languages in Social Media,", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Towards automatic tweet generation: A comparative study from the text summarization perspective in the journalism genre. Expert Systems with Applications 40(16):6624\u20136630", "author": ["Lloret", "E. Palomar 2013] Lloret", "M. Palomar"], "venue": null, "citeRegEx": "Lloret et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lloret et al\\.", "year": 2013}, {"title": "An assessment of the accuracy of automatic evaluation in summarization", "author": ["Owczarzak"], "venue": "In Proceedings of Workshop on Evaluation Metrics and System Comparison for Automatic Summarization,", "citeRegEx": "Owczarzak,? \\Q2012\\E", "shortCiteRegEx": "Owczarzak", "year": 2012}, {"title": "Fear the reaper: A system for automatic multi-document summarization with reinforcement learning", "author": ["Hasan Rioux", "C. Chali 2014] Rioux", "S.A. Hasan", "Y. Chali"], "venue": "In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP),", "citeRegEx": "Rioux et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rioux et al\\.", "year": 2014}, {"title": "Unsupervised extractive summarization via coverage maximization with syntactic and semantic concepts", "author": ["Schluter", "N. S\u00f8gaard 2015] Schluter", "A. S\u00f8gaard"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International", "citeRegEx": "Schluter et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schluter et al\\.", "year": 2015}, {"title": "Summarizing microblogs automatically", "author": ["Hutton Sharifi", "B. Kalita 2010a] Sharifi", "M.A. Hutton", "J. Kalita"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Sharifi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sharifi et al\\.", "year": 2010}, {"title": "Experiments in microblog summarization", "author": ["Hutton Sharifi", "B. Kalita 2010b] Sharifi", "M.A. Hutton", "J.K. Kalita"], "venue": "In Social Computing (SocialCom),", "citeRegEx": "Sharifi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sharifi et al\\.", "year": 2010}, {"title": "Utilizing microblogs for automatic news highlights extraction. COLING", "author": ["Wei", "Z. Gao 2014] Wei", "W. Gao"], "venue": null, "citeRegEx": "Wei et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2014}, {"title": "Multiple aspect summarization using integer linear programming", "author": ["Woodsend", "K. Lapata 2012] Woodsend", "M. Lapata"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Woodsend et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Woodsend et al\\.", "year": 2012}, {"title": "Social context summarization", "author": ["Yang"], "venue": "In Proceedings of the 34th international ACM SIGIR confer-", "citeRegEx": "Yang,? \\Q2011\\E", "shortCiteRegEx": "Yang", "year": 2011}, {"title": "Moodlens: an emoticon-based sentiment analysis system for chinese tweets", "author": ["Zhao"], "venue": "In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Zhao,? \\Q2012\\E", "shortCiteRegEx": "Zhao", "year": 2012}], "referenceMentions": [], "year": 2015, "abstractText": "The development of summarization research has been significantly hampered by the costly acquisition of reference summaries. This paper proposes an effective way to automatically collect large scales of news-related multi-document summaries with reference to social media\u2019s reactions. We utilize two types of social labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to cluster documents into different topic sets. Also, a tweet with a hyper-link often highlights certain key points of the corresponding document. We synthesize a linked document cluster to form a reference summary which can cover most key points. To this aim, we adopt the ROUGE metrics to measure the coverage ratio, and develop an Integer Linear Programming solution to discover the sentence set reaching the upper bound of ROUGE. Since we allow summary sentences to be selected from both documents and highquality tweets, the generated reference summaries could be abstractive. Both informativeness and readability of the collected summaries are verified by manual judgment. In addition, we train a Support Vector Regression summarizer on DUC generic multi-document summarization benchmarks. With the collected data as extra training resource, the performance of the summarizer improves a lot on all the test sets. We release this dataset for further research.", "creator": "LaTeX with hyperref package"}}}