{"id": "1512.00573", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2015", "title": "Object-based World Modeling in Semi-Static Environments with Dependent Dirichlet-Process Mixtures", "abstract": "to accomplish tasks in human - primate centric indoor environments, robots need to represent and understand perfectly the world in terms of objects and their attributes. we refer to this attribute - method based representation as a world model, and most consider how to first acquire it via noisy perception and maintain it over time, especially as objects generated are added, changed, and removed in the world. previous work has framed this as multiple - target tracking problem, where objects are potentially in motion at all times. although this approach is general, it is computationally expensive. we argue that such semantic generality is not needed in typical world modeling tasks, where objects only inadvertently change state changes occasionally. more efficient approaches are enabled by restricting ourselves to such semi - static environments.", "histories": [["v1", "Wed, 2 Dec 2015 04:32:02 GMT  (2850kb,D)", "http://arxiv.org/abs/1512.00573v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG cs.RO", "authors": ["lawson l s wong", "thanard kurutach", "leslie pack kaelbling", "tom\\'as lozano-p\\'erez"], "accepted": false, "id": "1512.00573"}, "pdf": {"name": "1512.00573.pdf", "metadata": {"source": "CRF", "title": "Object-based World Modeling in Semi-Static Environments with Dependent Dirichlet-Process Mixtures", "authors": ["Lawson L.S. Wong", "Thanard Kurutach", "Leslie Pack Kaelbling", "Tom\u00e1s Lozano-P\u00e9rez"], "emails": ["}@csail.mit.edu"], "sections": [{"heading": null, "text": "We consider a previously-proposed clustering-based world modeling approach that assumed static environments, and extend it to semi-static domains by applying a dependent Dirichletprocess (DDP) mixture model. We derive a novel MAP inference algorithm under this model, subject to data association constraints. We demonstrate our approach improves computational performance in semi-static environments."}, {"heading": "1 Introduction", "text": "There are many situations in which it is important for an automated system to maintain an estimate of the state of a complex dynamical system. Many physical systems are well described in terms of a set of objects, attributes of those objects, and relations between them. The number and properties of the objects in the world may change over time, and they are only partially observable due to noise and occlusion in the observation process. Domains that are appropriately modeled this way include: a household robot, which must maintain an estimate of the contents of a refrigerator that is used by multiple other people based on partial views of its contents; a wildlife-monitoring drone, which must maintain an estimate of the number, age, and health of elephants in a herd based on a sequence of photos of the herd moving through a forest; a surveillance satellite, which must estimate the number, activity, and hostility of soldiers in an enemy camp based on photos capturing people only when they are outside of buildings.\nEstimating properties of individuals from noisy observations is a relatively simple statistical estimation problem if the observations are labeled according to which individual generated them. Even when the underlying attributes of the individual change over time, the problem of inferring the history of each individual\u2019s attributes can be reduced to a problem of inference in a hidden Markov model.\nar X\niv :1\n51 2.\n00 57\n3v 1\n[ cs\n.A I]\n2 D\nec 2\n01 5\nThe key difficulty in the problems described above is data association. We do not know which particular individual is responsible for each observation and so determining an appropriate association of observations to individuals is key. The only information we have to help make such associations are noisy and partial observations, which may contain errors both in attribute values and in number.\nWithin the context of world modeling, Cox and Leonard (1994) first identified this issue, and applied well-known multiple-hypothesis tracking (MHT) methods to resolve the issue (Reid, 1979; Bar-Shalom and Fortmann, 1988; Elfring et al., 2013). Recently, Oh et al. (2009) have pointed out drawbacks in using the MHT, which include inefficiency due to considering an exponential number of hypotheses, and the inability to revisit associations from previously-considered views (the MHT is essentially a forward filtering algorithm). Inspired by this, they and others (Dellaert et al., 2003; Pasula et al., 1999) have proposed different Markov-chain Monte Carlo (MCMC) methods for data association. See Wong et al. (2015) for in-depth coverage about previous work in semantic world modeling and data association.\nThe methods mentioned above were all formulated for multiple-target tracking problems, where the each target\u2019s state (typically location) changes between observations. However, if we consider applications such as tracking objects in a household, the dynamics are typically different: most objects tend to stay in the same state when they are not being actively used. In this paper, we study the world modeling problem in semi-static environments, where time is divided into known epochs, and within each epoch the world is stationary. It seems intuitive that data association should be easier within static periods, since there is no uncertainty arising from stochastic dynamics.\nAn alternative approach to data association is to perform inference over the entire time-series of observations and to think of it as a problem of clustering: we wish to group together similar detections over time, under the assumption that they will have been generated by the same individual. Bayesian nonparametric models, such as the Dirichlet-process mixture model (DPMM), can be used to model domains in which the number of individuals is unknown a priori ; in Wong et al. (2015), we found that a state-estimation technique based on DPMM clustering was effective for determining the number and type of objects in a static domain, given a sequence of images with partial views of the scene and significant occlusion.\nIn this paper, we apply the clustering approach to the much more difficult case of a dynamic domain in which the attributes of objects may change over time, new objects may appear, and old objects may permanently disappear. The DPMM is not an appropriate model for this problem, but an extension, the dependent Dirichlet process mixture model (DDPMM), which models dependencies between a collection of clusters, can be used effectively. In particular, we use a construction proposed by Lin et al. (2010) for a class of DDPs that can be represented as a Markov chain over DPs. In our case of semi-static world modeling, we model objects in each static epoch as clusters in a DPMM, and clusters between epochs are related by Markovian transitions, thus forming a DDPMM.\nIn the remainder, we will formalize the world modeling problem, review the DDP construction and apply it to our problem, and derive a novel maximum a posteriori (MAP) inference algorithm for the model. We show that this model yields computational advantages for tracking in semi-static environments, both in simulation and on real-world data."}, {"heading": "2 Problem Definition", "text": "In world modeling, we seek the state of the world, consisting an unknown finite number Kt of objects, which changes over time. Object k at epoch t has attribute values \u03b8kt. We sometimes decompose \u03b8kt into ( ak, xkt ) , where a is a vector of fixed attributes, and x is a vector of attributes that may change between epochs. The top row in Figure 1 illustrates the world state over three epochs for a simple domain.\nOur system obtains noisy, partial views of the world. Each view v produces a set of observations Otv = { otvi } , where otvi = ( btvi , y tv i ) , corresponding to the fixed attributes a and dynamic attributes xt of some (possibly non-existent) object1. Each view is also associated with a field of view V tv. The collection of views in a single epoch may fail to cover the entire world. The partial views and noisy observations are illustrated in the middle and bottom rows of Figure 1.\nThe world modeling problem can now be defined: Given observations O = { otvi } (t,v,i) and fields\nof view { V tv } (t,v) , determine the state of objects over time \u0398 = { \u03b8kt } (k,t) . The state includes not\n1 Superscripts in variables will generally refer to the \u2018context\u2019, such as object index k and time index t. Subscripts refer to the index in a list, such as oti = i\u2019th observation at time t.\nonly objects\u2019 attribute values, but also the total number of objects that existed at each epoch, and implicitly when objects were added and removed (if at all).\nThere is no definitive information in the observations that will allow us to know which particular observations correspond with which underlying objects in the world, or even how many objects were in existence at any time step. For example, in the views of t = 1 shown in Figure 1, the square detected in the left-most view may correspond to either (or neither) square in the center view. Also, despite there being only four objects in the world, there were five observations because of overlapping visible regions.\nThe critical piece of information that is missing is the association ztvi of an observation o tv i to an underlying object k. With this information, we can perform statistical aggregation of the observations assigned to the same object to recover its state. We will model the associations Z = { ztvi } (t,v,i) as latent variables in a Bayesian inference process."}, {"heading": "2.1 Observation noise model", "text": "The observation model describes how likely an observation o = (b, y) was generated from some given object state \u03b8 = (a, x) (if any), given by the probability f (o ; \u03b8). For a single object, let \u03b8c and \u03b8d be the true continuous and discrete attribute values respectively, and likewise oc and od for a single observation of the object. We typically consider observation noise models of the following form:\nf (o ; \u03b8) = \u03c6\u03b8d(od) N (oc ; \u03b8c, S) (1)\nHere \u03c6 represents a discrete confusion matrix, where \u03c6\u03b8d(od) is the probability of observing od given the true object has discrete attributes \u03b8d. The continuous-valued observation oc is the true value \u03b8c corrupted with zero-mean Gaussian noise, with fixed sensing covariance S. The noise on oc and od are assumed to be independent for simplicity.\nBesides errors in attribute values, Figure 1 also illustrates cases of false positives and false negatives. A false positive occurs when the observation did not originate from any true object. We assume that this occurs at a fixed rate \u03c1, depending on the perception system. When this occurs, od has noise distribution \u03c60, and oc is uniformly distributed over the field of view V . A false negative occurs when an object is within the sensor\u2019s field of view but failed to be detected. We assume that an object within the field of view V will be undetected with an attribute-dependent probability \u03b7(\u03b8)."}, {"heading": "2.2 Additional assumption: Cannot-link constraint (CLC)", "text": "Finally, there is an additional common domain assumption in target-tracking problems that is essential: within a single view, each visible object can generate at most one detection Bar-Shalom and Fortmann (1988). This implies that within a view, each observation must be assigned to a different hypothesized underlying object. Adopting the terminology of clustering, we refer to this as a \u2018\u2019cannot-link constraint\u201d (CLC). The constraint is powerful because it can reduce ambiguities when there are similar nearby objects. However, clustering algorithms typically cannot handle such constraints, and similar to the DPMM-based data association work of Wong et al. (2015), we will need to modify the DDP model and inference algorithms to handle the world modeling problem."}, {"heading": "3 A Clustering-Based Approach", "text": "We now specify a prior on how likely an assignment to a cluster is, and how clusters change over time. Since the number of clusters are unknown, we chose to use Bayesian nonparametric mixture models, which allow for an indefinite and unbounded number of mixture components. (although the number of instantiated components is limited by the data size).\nThe Dirichlet process (DP) (Teh (2010) provides a good overview), and its application to mixture modeling (Antoniak, 1974; Neal, 2000), is a widely-studied prior for density estimation and clustering. The DP\u2019s popularity stems from its simplicity and elegance. However, one major limitation is that clusters cannot change over time, a consequence of the fact that observations are assumed to be fully exchangeable. This assumption is violated for problems like ours, where the observed entities change over time and space. Indeed, the previous application of DPs to world modeling mentioned above required that the world is static, which is a significant limitation. Various generalizations of the DP that model temporal dynamics have thus been proposed (Zhu et al., 2005; Ahmed and Xing, 2008).\nMany of these generalizations belong to a broad class of stochastic models known as dependent Dirichlet processes (DDP) (MacEachern, 1999, 2000). We will adopt a theoretically-appealing instance of the DDP, based on a recently-proposed Poisson-process construction (Lin et al., 2010; Lin, 2012). This construction subsumes a number of existing algorithmically-motivated DP generalizations. Additionally, Lin\u2019s construction has the nice property that at each time slice, the prior over clusters is marginally a DP. Given a DP prior at time t, the construction specifies a dependent prior at time t + 1 (or another future time), which is shown to also be a DP. The construction therefore generates a Markov chain of DPs over time, which reflects temporal dynamics between epochs in our problem.\nWe now state one result of the DDP construction; see Appendix A, and Lin (2012) for details. The construction results in the following prior on parameter \u03b8t (to be assigned to a new observation), given past parameters \u0398<t and parameters \u0398t corresponding to clusters that have already been instantiated at the current epoch:\n\u03b80 | \u03980 \u221d \u03b1H ( \u03b80 ) + \u2211 k Nk0 I [ \u03b80 = \u03b8k0 ] (2)\n\u03b8t | \u0398\u2264t \u221d \u03b1H ( \u03b8t ) + \u2211\nk:Nkt>0\nNk,\u2264t I [ \u03b8t = \u03b8kt ] + \u2211 k:Nkt=0 q(\u03b8k,t\u22121) Nk,<t T ( \u03b8t ; \u03b8k,t\u22121 ) At the initial time step, clusters are formed as in a standard DPMM with concentration parameter \u03b1 and base distribution H. For later time steps, the prior distribution on \u03b8 is defined recursively. The first two terms are similar to the base case, for new clusters and already-instantiated clusters (in the current epoch) respectively. The third term corresponds to previously-existing clusters that may be removed with probability (1\u2212 q(\u03b8k,t\u22121)), and, if it survives, is moved with transition probability T ( \u00b7 ; \u03b8k,t\u22121 ) . Nk,\u2264t is the number of points that have been assigned to cluster k, for all time steps up to time t. This term is similar to that in the DP. Note that if q \u2261 1 and T (\u00b7 ; \u03b8) = \u03b4\u03b8, then the model is static, and Equation 2 is equivalent to the predictive distribution in the DP."}, {"heading": "3.1 Inference by forward sampling", "text": "As mentioned in the problem definition, our focus will be on determining latent assignments Z ={ zti } of observations O = { oti } to clusters with parameters \u0398 = { \u03b8kt } . In the generic DDP, views\ndo not exist yet; those will be introduced in Section 4. One way to explore the distribution of assignments is to sample repeatedly from the assignment\u2019s conditional distribution, given all other assignments Z\\ti , Z \\ { zti } :\nP ( zti = k \u2223\u2223 oti,\u0398, Z\\ti) = \u222b P (zti = k, \u03b8 \u2223\u2223 oti,\u0398, Z\\ti) d\u03b8 \u221d \u222b P ( oti \u2223\u2223 \u03b8)P(\u03b8 = \u03b8kt \u2223\u2223\u2223\u0398, Z\\ti) d\u03b8 (3)\nThe first term in the integrand is given by the observation noise model (Equation 1), and the second term is given by the DDP prior (Equation 2). If \u03b8kt already exists, then P ( \u03b8 \u2223\u2223\u0398, Z\\ti) = I [\u03b8 = \u03b8kt], and the integrand only has support for \u03b8 = \u03b8kt. Otherwise, we have to consider all possible settings of \u03b8kt, which has a prior distribution given by Equation 2. The expression in Equation 3 above can be decomposed into three cases, corresponding to terms in Equation 2:\nP ( zti = k \u2223\u2223\u2223 oti,\u0398\u2264t, Z\u2264t\\ti) \u221d  Nk,\u2264t\\ti f ( oti ; \u03b8 kt ) , k existing, instantiated at t q\u0303(\u03b8k\u03c4 ) Nk,<t\\ti \u222b f ( oti ; \u03b8 ) T\u0303 ( \u03b8 ; \u03b8k\u03c4 ) d\u03b8 , k existing, not instantiated at t \u03b1 \u222b f ( oti ; \u03b8 ) H (\u03b8) d\u03b8 ,\nk new\n(4)\nIn the DDPMM, clusters move around the parameter space during their lifetimes, and, depending on our chosen viewpoints, may not generate observations at some epochs. When cluster k has at least one time-t observation assigned to it, it becomes instantiated at time t. Any subsequent observations at time t that are assigned to cluster k must then share the same parameter \u03b8kt; this corresponds to the first case. The second case is for clusters not yet instantiated at time t, and we must infer \u03b8kt from the last known parameter for cluster k, at time \u03c4 < t. If t \u2212 \u03c4 > 1, we use generalized survival and transition expressions for our application:\nq\u0303(\u03b8k\u03c4 ) , [ q(\u03b8k\u03c4 ) ]t\u2212\u03c4 (5)\nT\u0303 ( \u03b8kt ; \u03b8k\u03c4 ) = I [ akt = ak\u03c4 ] N ( xkt ; xk\u03c4 , (t\u2212 \u03c4)R(ak) ) The third case is for new clusters that are added at time t. The first and third cases essentially have the same form as the Gibbs sampler for the (static) DP .\nIn general, since the cluster parameters \u0398 are also unknown, inference schemes need to alternate between sampling the cluster assignments (given parameters) as above, and sampling the parameters given the cluster assignments. The conditional distribution of each cluster\u2019s parameters { \u03b8kt } (for each cluster k, a sequence of parameters) can be found using Bayes\u2019 rule:\nP ({ \u03b8kt } \u2223\u2223\u2223O,Z) = P({\u03b8kt} \u2223\u2223\u2223 O|z=k , Z) \u221d \u220f zti=k P ( oti \u2223\u2223\u2223 \u03b8kt)  P({\u03b8kt}) (6)\nDepending on the choice of parameter priors and observation functions, the resulting conditional distributions can potentially be complicated to represent and difficult to sample from. With additional assumptions that will be presented next, we can find the parameter posterior distribution efficiently and avoid sampling the parameter entirely by \u201ccollapsing\u201d it."}, {"heading": "3.2 Application of DDPs to world modeling", "text": "We now apply the DDP mixture model (DDPMM) to our semi-static world modeling problem. For concreteness and simplicity, we consider an instance of the world modeling problem where the fixed attribute a is the discrete object type (from a finite list of known types), and the dynamic attribute x is the continuous pose in Rd (either 3-D location or 6-D pose). Despite these restrictions, our model and derivations below can be immediately applied to problems with any fixed attributes, and with any dynamic continuous attributes with linear-Gaussian dynamics. Arbitrary dynamic attributes can be represented in our model, but inference will likely be more challenging because in general we will not obtain closed-form expressions.\nFor our instance of the DDPMM, we assume:\n\u2022 Time steps in the DDP correspond to epochs in world modeling. This implies that each epoch is modeled as a static DPMM, similar to the problem in Wong et al. (2015) .\n\u2022 The survival rate only depends on the fixed attribute, i.e., q(\u03b8) = q(a). (For us, that means the likelihood of object removal is dependent on the object type but not its pose.)\n\u2022 Likewise, the detection probability only depends on the fixed attribute, i.e., \u03b7(\u03b8) = \u03b7(a).\n\u2022 The dynamic attribute (pose) follows a random walk with zero-mean Gaussian noise that depends on a (e.g., a mug likely travels farther per epoch than a table):\nxt+1 = xt + w, where w \u223c N (0, R(a)) (7)\nThis implies that the full transition distribution (of both object type and pose) is: T ( \u03b8t+1 ; \u03b8t ) = I [ at+1 = at ] N ( xt+1 ; xt, R(a) ) (8)\n\u2022 At each epoch, the DP base distribution has the following form:\nH (\u03b8) , \u03c0(a) N ( x ; \u00b50,\u03a30 ) (9)\nHere a (discrete) prior \u03c0 over the object type, and a normal distribution over the object pose. The initial covariance \u03a30 is large, in order to give reasonable likelihood of an object being introduced at any location. In fact, we will set \u03a30 = \u221eI and \u00b50 = 0, representing a noninformative prior over the location. Details can be found in Appendix B.\nThe above choices for the dynamics and base distribution implies that the parameter posterior and predictive distributions have closed-form expressions. The posterior distribution of the dynamic attribute is a mixture of Gaussians, with a component for each possible value of the fixed attribute a (since the process noise R(a) may be different), weighted by the posterior probability of a. In practice, we track the pose using only the dynamics of the most-likely object type. Thus, in our application, each cluster will maintain a discrete posterior distribution \u03d5(a) for the object type,\nand a single Kalman filter / Rauch-Tung-Striebel (RTS) smoother for the object pose distribution. The latter is represented as a sequence of means and covariances { \u00b5t,\u03a3t }\u03b6 t=\u03be over the cluster\u2019s\nlifetime t \u2208 [\u03be, \u03b6], with the interpretation that xt \u223c N ( \u00b5t,\u03a3t ) .\nAs mentioned previously, because we have compact representations of the parameter posterior distributions, we can analytically integrate them out sampling them. We first modify the forward sampling equation (Equation 4) to reflect this \u201ccollapsing\u201d operation. Since we can no longer condition on the parameters themselves, we instead need to condition on the other observations O\\ti and their current cluster assignments Z\\ti, and use posterior predictive likelihoods of the form\nP ( oti \u2223\u2223\u2223Ok\\ti) to evaluate the current observation oti: P ( zti = k\n\u2223\u2223\u2223 oti, O\u2264t\\ti, Z\u2264t\\ti) \u221d P(oti \u2223\u2223\u2223 zti = k,O\u2264t\\ti, Z\u2264t\\ti) P(zti = k \u2223\u2223\u2223O\u2264t\\ti, Z\u2264t\\ti) \u221d \u222b [ P ( oti \u2223\u2223\u2223 \u03b8kt) P(\u03b8kt \u2223\u2223\u2223Ok,\u2264t\\ti )] P(zti = k \u2223\u2223\u2223Z\u2264t\\ti) d\u03b8kt\n\u221d  Nk,\u2264t\\ti \u222b P ( oti \u2223\u2223 \u03b8kt) P(\u03b8kt \u2223\u2223\u2223Ok,\u2264t\\ti ) d\u03b8kt , k existing, instantiated at t Nk,<t\\ti \u222b P ( oti \u2223\u2223 \u03b8kt) [\u222b q\u0303(ak\u03c4 ) T\u0303 (\u03b8kt ; \u03b8k\u03c4) P(\u03b8k\u03c4 \u2223\u2223\u2223Ok,<t\\ti ) d\u03b8k\u03c4] d\u03b8kt , k existing, not instantiated at t \u03b1 \u222b P ( oti \u2223\u2223 \u03b8kt) H (\u03b8kt) d\u03b8kt ,\nk new\n(10)\nWe can now substitute the expressions for P ( oti \u2223\u2223 \u03b8kt), T\u0303 , and H, where properties of the normal distribution will help us evaluate the integrals. The derivations in Appendix B give the following expressions, as well as details for finding the posterior hyperparameters \u03d5, \u00b5kt, and \u03a3kt (recall \u03b8kt = (ak, xkt), oti = (b t i, y t i)):\nP ( zti = k \u2223\u2223\u2223 oti, O\u2264t\\ti, Z\u2264t\\ti)\n\u221d  Nk,\u2264t\\ti\n[\u2211 ak \u03c6 ak(bti) \u03d5(a k) ] N ( yti ; \u00b5 kt,\u03a3kt + S ) ,\nk existing, instantiated at t\nq\u0303(a\u0302k) Nk,<t\\ti [\u2211 ak \u03c6 ak(bti) \u03d5(a k) ] N ( yti ; \u00b5 k\u03c4 ,\u03a3k\u03c4 + (t\u2212 \u03c4)R(a\u0302k) + S ) ,\nk existing, not instantiated at t \u03b1 [\u2211\nak \u03c6 ak(bti) \u03c0(a\nk) ] Unif(vol(world)) ,\nk new\n(11)\nIn the second case, for tractability in filtering, we have assumed that a cluster\u2019s dynamics behaves according to its most-likely type a\u0302k; otherwise, the posterior is a mixture of Gaussians (over all possible transition densities). Also, the third case contains an approximation to avoid evaluating an improper probability density; see Appendix B for details."}, {"heading": "4 Incorporating World Modeling Constraints", "text": "So far, we have only applied a generic DDPMM to our observations, but have ignored the cannotlink constraint, as well as false positives and negatives. We now present modifications to the Gibbs sampler to handle these constraints; the modifications are similar to those from the static case in Wong et al. (2015) .\nThe cannot-link constraint (see Section 2.2; referred to as \u201cone measurement per object\u201d (OMPO) in Wong et al. (2015) ) couples together cluster assignments for observations within the same view, since we must ensure that no two observations can be assigned to the same existing cluster. For each view, all cluster assignments must be considered together as a joint correspondence vector, and the probability of choosing one such correspondence is proportional to the product of the individual cluster assignment probabilities given in Equation 11. Invalid correspondence vectors that violate the cannot-link constraint are assigned zero probability and hence are not considered; the remaining conditional probabilities are normalized. This can be interpreted as performing blocked Gibbs sampling, where blocks are determined by the joint constraints:\nP ( ztv \u2223\u2223otv, O\\tv, Z\\tv) \u221d [\u220f i P ( ztvi \u2223\u2223 otvi , O\\tv, Z\\tv) ] I [ ztv satisfies CLC ] (12)\nThe correspondence vector ztv is again the concatenation of the individual ztvi assignment variables, for all observation indices i made in view v at epoch t; the interpretation of otv is similar. The individual terms in the product are given by Equation 11 (with the appropriate case depending on the value of ztvi ), except now all observations within the same view are excluded (since their assignments are being sampled together) \u2013 O\\tv instead of O\\ti, and likewise for assignments Z\\tv and counts N\\tv.\nFor false positives, we essentially treat it as a special \u201ccluster\u201d that has no underlying parameter Instead, we assume that if an observation is generated from a false positive, it is generated from some spurious parameter drawn from the base distribution H, so the likelihood term is the same as that for drawing a new cluster. Like the other cases, we also multiply the likelihood by the number of points already assigned to the cluster, i.e., the number of false positives except for those in the current view. If there are currently no other false positives, then we multiply by the concentration parameter \u03b1 instead to ensure that it is always feasible to assign observations to the false positive \u201ccluster\u201d. Also, to incorporate the assumption that false positives are generated with a fixed rate \u03c1, we attach a Bernoulli probability to each case in the Gibbs sampler. The false positive conditional probability is multiplied by \u03c1, and all other cases are multiplied by (1\u2212 \u03c1). In summary, the conditional probability of an observation being a false positive (z = 0) is:\nP ( ztvi = 0 \u2223\u2223 otvi , O\\tv, Z\\tv) \u221d [\u2211 ak \u03c6a k (btvi ) \u03c0(a k) ] Unif(vol(world))\u00d7 { \u03c1N0\\tv , N 0 \\tv > 0 \u03c1\u03b1 , N0\\tv = 0 (13)\nThe normalizer depends on the other cases in Equation 11 (with additional (1\u2212 \u03c1) factors). Finally, for false negatives, recall that an object that is within the field of view fails to be detected with type-dependent probability \u03b7(ak). Let \u03b4tvk be 1 if cluster k is detected in view v at epoch t, and 0 otherwise. For a cluster k that is alive at epoch t (\u03bek \u2264 t \u2264 \u03b6k) with parameter \u03b8kt,\nthe probability of detection is therefore:\nP ( \u03b4tvk = 1 ) = [ 1\u2212 \u03b7(ak) ] P ( \u03b8kt \u2208 V tv ) = [ 1\u2212 \u2211 ak \u03b7(ak) \u03d5(ak) ] \u03a6\u0303 ( xkt \u2208 V tv ; \u00b5kt,\u03a3kt ) (14)\nThe \u03a6\u0303 function denotes the CDF of the multivariate normal distribution, with mean \u00b5kt and covariance \u03a3kt. For a particular view V tv, we only evaluate the above detection probability on clusters that are currently alive at epoch t. For each such cluster, there is a corresponding \u03b4tvk detection indicator variable, whose value is determined during sampling by the candidate joint correspondence vector ztv: if some element of ztv is assigned to cluster index k, then \u03b4tvk = 1; otherwise, \u03b4tvk = 0. The detection probability for the correspondence vector is:\nPD ( ztv \u2223\u2223O\\tv, Z\\tv) = \u220f\nk: \u03bek\u2264t\u2264\u03b6k\n[ P ( \u03b4tvk = 1 )]\u03b4tvk [1\u2212 P (\u03b4tvk = 1)]1\u2212\u03b4tvk (15) Putting everything together, we arrive at a constrained blocked collapsed Gibbs sampling in-\nference algorithm. The algorithm takes the observations O = { otvi } and visible regions { V tv }\nas input. As output, the algorithm produces samples from the posterior distribution over correspondence vectors { ztv }\n, from which we can compute the posterior parameter distributions ak \u223c \u03d5 and xkt \u223c N ( \u00b5kt,\u03a3kt ) . The sampling algorithm repeatedly iterates over epochs t and views v, each time sampling a new correspondence vector ztv from its constrained conditional distribution:\nPView ( ztv \u2223\u2223otv, O\\tv, Z\\tv) \u221d  \u220f i: ztvi 6=0 (1\u2212 \u03c1) P ( ztvi \u2223\u2223 otvi , O\\tv, Z\\tv)  \u00d7\n \u220f i: ztvi =0 \u03c1 [\u2211 ak \u03c6a k (btvi ) \u03c0(a k) ] 1 vol(world) \u00d7 { N0\\tv , N 0 \\tv > 0 \u03b1 , N0\\tv = 0  \u00d7\n \u220f k: \u03bek\u2264t\u2264\u03b6k [ P ( \u03b4tvk = 1 )]\u03b4tvk [1\u2212 P (\u03b4tvk = 1)]1\u2212\u03b4tvk \n\u00d7 I [ ztv satisfies CLC ] (16)\nThe probability terms in the first and third lines can be found in Equations 11 and 14 respectively. As in the static case, after incorporating the world modeling constraints, inference becomes inefficient because we now have to compute conditional probabilities for (and sample from) the joint space of correspondence vectors, which in general is exponential in the number of observations in a view. Using the same insights and ideas as in Wong et al. (2015) , however, we can adaptively factor the correspondence vector by initially decoupling all assignment variables, then coupling only those that violate the cannot-link constraint .\n5 Approximate Maximum a Posteriori (MAP) inference\nWe have now presented the entire Gibbs sampling algorithm for DDPMM-based world modeling. However, sampling-based inference can be slow, especially because of the cannot-link constraint\nthat couples together many latent variables, even if adaptive factoring is used. Although we are interested in maintaining an estimate of our uncertainty in the world, frequently just having the most-likely (maximum a posteriori \u2013 MAP) world state suffices. In general, even the MAP world model is hard to find (Bar-Shalom and Fortmann, 1988), and many approximate solutions have been proposed.\nIn the static case, Wong et al. (2015) adapted a hard-clustering algorithm, DP-means, and empirically found that it returned good clustering assignments for some hyperparameter settings . A similar analysis via small-variance asymptotics was performed recently for DDPs, where the mixture components were Gaussian distributions with isotropic noise, resulting in the Dynamic Means algorithm (Campbell et al., 2013). However, there is no simple and principled way to incorporate the additional information from Section 4. Additionally, even without such modifications, the Dynamic Means algorithm requires three free hyperparameters to be specified, which may be significantly harder to tune than the one in DP-means. Instead, we will use a much older idea that does not involve asymptotics, can incorporate all the world-modeling information and constraints, and produces an local optimization algorithm that is similar in spirit to Dynamic Means."}, {"heading": "5.1 Iterated conditional modes (ICM)", "text": "The iterated conditional modes (ICM) algorithm performs coordinate ascent on each variable\u2019s conditional distribution, and is guaranteed to converge to a local maximum (Besag, 1986). In particular, instead of iteratively sampling correspondence vectors from their conditional distributions in Gibbs sampling, we find the most-likely one, update parameters based on it, and repeat for each view. Since we are still dealing with the joint space of assignments for all observations in a given view, finding the maximizer still potentially requires searching through a combinatorial space. Fortunately, finding the most-likely correspondence can be formulated as a maximum weighted assignment problem, for which efficient algorithms such as the Hungarian algorithm exist (and have been previously used in data association).\nSuppose, for view v at epoch t, there are M observations {o1, . . . , oM} and K existing clusters (possibly not alive/instantiated). Then we wish to match each oi to an existing cluster, a new cluster, or a false positive. Any unmatched existing cluster must also be assigned the probability of missed detection. We can solve this as an assignment problem with the following payoff matrix:\nObs (M) FN (M +K) Clusters (K) logP (zi = k) + log(1\u2212 \u03c1) I [ \u03bek \u2264 t \u2264 \u03b6k ] logP (\u03b4k = 0)\n+ I [ \u03bek \u2264 t \u2264 \u03b6k ] logP (\u03b4k = 1)\nNew (M) logP (zi = new) + log(1\u2212 \u03c1) 0 FP (M) logP (zi = 0 (FP)) + log \u03c1 0\nThe payoff matrix has 2M +K entries (indicated in parentheses), to allow for the case that all observations are assigned to new clusters, and likewise that all are spurious. Any extra New/FP nodes are assigned to extra FN nodes, with zero payoff. The payoffs in the first column are: for an existing cluster, given by cases 1 and 2 in Equation 11, depending on whether or not the cluster has been instantiated yet; for a new cluster, given by case 3 in Equation 11; and for a false positive, given by Equation 13. Note that log probabilities are used to decompose the view\u2019s joint correspondence probability into a sum of individual terms. By construction, the cannot-link constraint is satisfied."}, {"heading": "5.2 A two-stage inference scheme", "text": "Although the ICM algorithm presented can find good clusters at a single epoch very quickly, we will see in experiments that it does not converge to good cluster trajectories. The issue is that ICM moves are local, in that it considers one view at a time. Suppose we have identified correctly all objects in epoch 1 using ICM. When we consider the first view in epoch 2, there may be significant changes present, and using the first view only, ICM decides whether or not to assign the new observations to existing clusters (by reviving them from the previous epoch). Since the uncertainty in the object states immediately after a transition is high, basing the cluster connectivity decisions on a single view is unreliable.\nThis suggests a two-level inference scheme. Since ICM can reliably find good clusters within single epochs, we first apply ICM to each epoch\u2019s data independently, treating them as unrelated static worlds. Next, we attempt to connect clusters between different epochs. This is essentially another tracking problem, although the likelihood function is somewhat different (depends on many underlying data points), and is much reduced in size. Since the problem is significantly smaller, traditional tracking methods such as MHT can be applied to this cluster-level tracking problem.\nWe present one such scheme in Algorithm 2(b), using MCMCDA (Algorithm 2(a); Oh et al. (2009)) to solve the cluster-level problem. We choose a batch-mode sampling algorithm such as MCMCDA because it can return samples from the posterior distribution, and has an attractive anytime property \u2013 we can terminate at any point and still return a list of valid samples. For inferring the MAP configuration, the best sample can be returned instead. Since we are sampling from the true posterior distribution, in the limit of infinite samples, the true MAP configuration will be found almost surely.\nTo apply MCMCDA, we need to evaluate the likelihood of a complete configuration Z, encompassing all epochs and views (line 4 in Algorithm 2(a)). To do so, we first find the posterior parameter distributions for the clusters/objects (as given by Z) using Appendix B, then combine\nthe observation likelihoods (Equation 36), as well as the false positive and false negative priors: P (O |Z)P (Z) = \u220f t \u220f v P ( otv \u2223\u2223 ztv) PFP (ztv) PFN (ztv)\n= \u220f t \u220f v {[\u220f i \u222b P ( oti \u2223\u2223\u2223 \u03b8kt, zti = k) P(\u03b8kt) d\u03b8kt ]\n\u00d7 Bin ( N tvz=0 \u2223\u2223N tv, \u03c1) \u00d7\n \u220f k: \u03bek\u2264t\u2264\u03b6k [ P ( \u03b4tvk = 1 )]\u03b4tvk [1\u2212 P (\u03b4tvk = 1)]1\u2212\u03b4tvk } (17)"}, {"heading": "6 Experiments", "text": "Approximate MAP inference for world modeling via ICM, MCMCDA, and the two-stage algorithm ICM-MCMC were tested on a simulated domain, and also on a sequence of real robot vision data constructed from the static scenes in Wong et al. (2015) . To perform MAP inference on MCMCDA and ICM-MCMC, the most-likely sample (as scored by Equation 17) was chosen, from 105 samples in MCMCDA, and 104 in the second stage of ICM-MCMC. In both experiments, ICM-MCMC significantly outperforms the other two methods, and even ICM performs better than MCMCDA."}, {"heading": "6.1 Simulation", "text": "Objects in our simulated domain had one of four fixed object types, a time-evolving location (x, y) \u2208 [0, 100] \u00d7 [0, 100], and a time-evolving velocity vector. Observations were made in 10 epochs of this domain, with 5 views per epoch (visible region is the entire domain). In total, 5 objects existed, each for some contiguous sub-interval of the elapsed time. Within each view, the number of false positives was generated from Poi(5), and the probability of a missed detection was 0.1. The correct object type was observed with probability 0.6, with equal likelihood (0.1) of being confused with the other 3 object types. Locations were observed with isotropic Gaussian noise, standard deviation 1.0. The object\u2019s velocity vector was maintained from the previous time step, with added Gaussian noise, standard deviation 5.0. Between epochs, the probability of survival was 0.9. The observed data (i.e., the algorithm input) and the true object states are shown in Figure 3.\nThe resulting MAP clusters found by ICM, MCMCDA, and ICM-MCMC are shown in Figure 4, along with their log-likelihood values (higher / less negative is better). ICM-MCMC clearly outperforms the other methods, and finds essentially the same clusters as given by the true association. The clusters found generally have tight covariance values, unlike those in ICM and MCMCDA. These two methods, especially MCMCDA, tend to find many more clusters than are truly present."}, {"heading": "6.2 Using robot data from static scenes", "text": "We also applied the same algorithms to the static robot vision data that were used in Wong et al. (2015) to evaluate DPMM methods. To convert static scenes into dynamic scenes, we choose static scenes that were reasonably similar, and simply concatenated their data together, as if each scene corresponded to a different epoch. One such example is shown in Figure 5.\nObjects in different scenes were all placed on the same tabletop of dimensions 1.2m\u00d7 0.6m; all data were placed in the table\u2019s frame of reference. Four object types were present, and typically each scene had 5\u201310 objects. Unlike the previous simulation, we do not assume objects have velocities; between epochs, we assume that the location changes with isotropic Gaussian noise, standard deviation 0.1. Since changes were significant between epochs, we assumed a relatively low 0.5 probability of survival. Object locations are sensed with Gaussian noise, standard deviation 0.03; the object type noise model and probability of detection is the same as before. The probability of false positives is much lower for this domain; we assumed the number of false positives had a Poi(0.1) distribution.\nFigure 5 shows the MAP associations found by ICM and ICM-MCMC, with lines connecting cluster states over epochs. Annotations were also added (in the form of three different line styles) to facilitate comparison between the ICM and ICM-MCMC results; see figure caption for details. ICM tends to suggest many more transitions than ICM-MCMC, many of which are actually implausible."}, {"heading": "A Background on dependent Dirichlet processes", "text": "Lin et al. (2010) exploited the fact that there exists a one-to-one correspondence between DPs over space \u2126 and spatial Poisson processes in the product space \u2126\u00d7R+. This means that an underlying Poisson process can be extracted from any DP, and vice versa. By considering transitions on the underlying Poisson processes, and restricting to transition steps where the Poisson process remains closed under transition (more fundamentally, by preserving complete randomness), we obtain a new spatial Poisson process at the next time step, which can be converted back to a new DP.\nAccording to the stick-breaking construction of the DP (Sethuraman, 1994), if Dt \u223c DP, then it can be expressed as infinite sum of weighted atoms: Dt = \u2211\u221e i=1wi\u03b4\u03b8i , where wi \u2208 R+, and \u03b8i \u2208 \u2126. Then the following DP-preserving transition steps are applied in order:\n\u2022 Subsampling (removal): Let q : \u2126 \u2192 [0, 1] be a parameter-dependent survival rate, i.e., q(\u03b8) specifies how likely some \u03b8 in the current time step survives in the next time step. For each atom \u03b8i, draw bi \u223c Ber (q(\u03b8i)), and retain atoms with bi = 1. Renormalizing the weights on the retained atoms gives a new DP D\u2032 = \u2211 i:bi=1 w\u2032i\u03b4\u03b8i (where \u2211 i:bi=1 w\u2032i = 1).\n\u2022 Point transition (movement): Let T (\u00b7 ; \u03b8) : \u2126 \u2192 R+ be a parameter-dependent transition function, i.e., T (\u03b8\u2032 ; \u03b8) specifies how likely some \u03b8 in the current time step moves to \u03b8\u2032 in the next time step, given that it survives. For each atom \u03b8i, draw \u03b8 \u2032 i \u223c T (\u00b7 ; \u03b8). Then\nD\u2032\u2032 = \u2211\ni:bi=1 w\u2032i\u03b4\u03b8\u2032i is a new DP.\n\u2022 Superposition (addition): Let \u2206 = \u2211\nj $j\u03b4\u03d1j be a new independent DP, and let (c, d) \u223c Dir (\u03b1\u2032\u2032, \u03b1), where \u03b1\u2032\u2032 and \u03b1 are the concentration parameters of D\u2032\u2032 and \u2206 respectively. Then the random convex combination Dt+1 = cD\u2032\u2032 + d\u2206 is a DP, and acts as the prior for the next time step.\nThe upshot of this DDP construction is that, if we marginalize out the DP prior, we get the following prior for \u03b8t+1, given the parameters from the previous time \u0398t:\n\u03b8t+1 | \u0398t \u221d \u03b1H ( \u03b8t+1 ) + \u2211 k q(\u03b8kt) Nk,\u2264t T ( \u03b8t+1 ; \u03b8kt ) (18)\nThe first term is for new atoms, drawn from a DP with base distribution H (\u03b8) and concentration parameter \u03b1.2 The second term corresponds corresponds to existing atoms that have undergone subsampling and transition steps; these steps affect the assignment probability, as indicated by the presence of q and T . Additionally, Nk,\u2264t is the number of points that have been assigned to cluster k, for all time steps up to time t. This term is similar to that in the DP. Notice that if q \u2261 1 and T ( \u00b7 ; \u03b8kt ) = \u03b4\u03b8kt , then we exactly get back the predictive distribution in the DP.\nSince \u03b8t+1 \u223c Dt+1, andDt+1 is a DP, we can find the predictive distribution of \u03b8t+1, conditioning also on parameters \u0398t+1 that have been instantiated at time (t+ 1):\n\u03b8t+1 | \u0398t \u221d \u03b1H ( \u03b8t+1 ) + \u2211 k:Nk,t+1>0 Nk,\u2264t+1 I [ \u03b8k,t+1 = \u03b8kt ] + \u2211 k:Nk,t+1=0 q(\u03b8kt) Nk,\u2264t T ( \u03b8t+1 ; \u03b8kt ) (19)\n2Technically, \u03b1 includes both the innovation process from the superposition step, as well as a subsampled and transitioned version of innovation processes from previous times; see Lin (2012).\nIn general, some atoms may not be observed for several time steps, but still affect the prior (with decayed weight and dispersed parameter values). Also, some clusters may already have been instantiated at the current time t, either newly drawn from the innovation process, or transitioned from existing atoms. The general form of the prior on \u03b8t is:\n\u03b8t | \u0398\u2264t \u221d \u03b1H ( \u03b8t ) + \u2211\nk:Nkt=0\nqkt Nk,\u2264\u03c4 T ( \u03b8t ; \u03b8k\u03c4 ) + \u2211 k:Nkt>0 Nk,\u2264t I [ \u03b8 = \u03b8kt ] (20)\nThe first two terms are similar to those in Equation 18 above, except the sum is only over clusters that have not been instantiated at time t (Nkt = 0). These existing clusters may be \u2018revived\u2019, but they are weighted by accumulated subsampling and transition terms, based on the previous time \u03c4 = \u03c4kt at which they were instantiated:\nqkt , [ q(\u03b8k\u03c4 ) ]t\u2212\u03c4 (21)\nT ( \u03b8t ; \u03b8k\u03c4 ) , \u222b \u00b7 \u00b7 \u00b7 \u222b t\u220f t\u2032=\u03c4+1 T ( \u03b8t \u2032 ; \u03b8t \u2032\u22121 ) d\u03b8\u03c4+1 \u00b7 \u00b7 \u00b7 d\u03b8t\u22121\nThe third term in Equation 20 corresponds to atoms that have been instantiated at the current time t. In this case, we know both that the atom survived and its current value, so q and T disappear. Also, the count Nk,\u2264t now includes cluster assignments at the current time t as well."}, {"heading": "B Derivation of closed-form inference expressions for application", "text": "of DDPs to world modeling (Section 3.2)\nIn this appendix, we derive closed-form expressions for the posterior and predictive distributions of the parameter \u03b8 = (a, x), under the assumptions specified in Section 3.2.\nThe expressions for the fixed attribute are the same as in Wong et al. (2015) , since it is static. For convenience, we reproduce the equations here. Given a set of observations {b}:\n\u03d5(a) , P (a | {b}) \u221d P ({b} | a) P (a) \u221d  \u220f bi\u2208{b} \u03c6a(bi)  \u03c0(a) (22) P ( b\u2032 \u2223\u2223 {b}) \u221d\u2211\na\nP ( b\u2032 \u2223\u2223 a) P (a | {b}) = \u2211\na\n\u03c6a(b\u2032) \u03d5(a) (23)\nGiven a set of observations {{ yti }Nt i=1 }\u03b6 t=\u03be of the dynamic attributes, we can find the posterior\ndistribution on { xt }\u03b6 t=\u03be by performing Kalman filtering and smoothing. Applying a generic Kalman\nfilter to the world modeling problem gives the following recursive filtering equations for ( \u00b5\u0303, \u03a3\u0303 ) , the\nhyperparameters in the forward direction (during filtering):\n\u00b5\u0302t = \u00b5\u0303t\u22121 , \u03a3\u0302t = \u03a3\u0303t\u22121 +R(a)\nKt = \u03a3\u0302t ( \u03a3\u0302t + SNt )\u22121 , N t > 0\n0 , N t = 0 (24)\n\u00b5\u0303t = \u00b5\u0302t +Kt ( y\u0304t \u2212 \u00b5\u0302t ) , \u03a3\u0303t = ( I \u2212Kt ) \u03a3\u0302t\nRecall that R(a) is the covariance per time step of the random walk on x, and S is the covariance of the measurement noise distribution. The \u201c\u02c6\u201d variables are the predicted parameters before incorporating observations, and the \u201c\u02dc\u201d variables are the parameters after incorporating observations (i.e., the Kalman filter output). Since there may be multiple observations of the pose in a single epoch, we have used an equivalent formulation involving the sample means y\u0304, by exploiting the fact that if each yti \u223c N ( xt, S ) , then the sample mean has distribution y\u0304t \u223c N ( xt, SNt ) . There may also be no observations at a given time, in which case the correction step has no effect (Kt = 0). The Kalman filter is initialized with a noninformative prior:\n\u00b50 = 0 , \u03a30 =\u221eI (25)\nIn practice, this implies that after the initial measurement(s) at time \u03be, x\u0303\u03be \u223c N ( y\u0304\u03be, S\nN\u03be\n) . To see\nthis, we can apply Equation 24 on ( \u00b50,\u03a30 ) :\nK\u03be = ( \u03a30 +R(a) )( \u03a30 +R(a) + S\nN \u03be\n)\u22121 (26)\n\u00b5\u0303\u03be = \u00b50 +K\u03be ( y\u0304\u03be \u2212 \u00b50 ) = K\u03be y\u0304\u03be (27)\n\u03a3\u0303\u03be = ( I \u2212K\u03be ) ( \u03a30 +R(a) ) (28)\nTo handle the infinite initial covariance, we interpret \u03a30 as limn\u2192\u221e nI. This leads to:\nK\u03be = lim n\u2192\u221e\n[ nI ( nI +R(a) + S\nN \u03be\n)\u22121 +R(a) ( nI +R(a) + S\nN \u03be\n)\u22121]\n= lim n\u2192\u221e\n[( I + R(a)\nn +\n1\nn\nS\nN \u03be\n)\u22121 + 1\nn R(a)\n( I + R(a)\nn +\n1\nn\nS\nN \u03be )\u22121] = I + 0 \u00b7R(a) \u00b7 I = I (29)\nHence \u00b5\u0303\u03be = K\u03be y\u0304\u03be = y\u0304\u03be. For the covariance:\n\u03a3\u0303\u03be = [ I \u2212 ( \u03a30 +R(a) )( \u03a30 +R(a) + S\nN \u03be\n)\u22121] ( \u03a30 +R(a)\n) = [( \u03a30 +R(a) + S\nN \u03be\n)( \u03a30 +R(a) + S\nN \u03be\n)\u22121 \u2212 ( \u03a30 +R(a) )( \u03a30 +R(a) + S\nN \u03be\n)\u22121] ( \u03a30 +R(a)\n) = S\nN \u03be\n( \u03a30 +R(a) + S\nN \u03be\n)\u22121 ( \u03a30 +R(a) ) = lim\nn\u2192\u221e\n[ S\nN \u03be\n( nI +R(a) + S\nN \u03be\n)\u22121 nI + S\nN \u03be\n( nI +R(a) + S\nN \u03be\n)\u22121 R(a) ]\n= lim n\u2192\u221e\n[ S\nN \u03be\n( I + R(a)\nn +\n1\nn\nS\nN \u03be\n)\u22121 + 1\nn\nS\nN \u03be\n( I + R(a)\nn +\n1\nn\nS\nN \u03be\n)\u22121 R(a) ]\n= S N \u03be \u00b7 I + 0 \u00b7 S N \u03be \u00b7 I \u00b7R(a) = S N \u03be (30)\nIn summary, choosing ( \u00b50,\u03a30 ) = (0,\u221eI) is equivalent to initializing the Kalman filter with(\n\u00b5\u03be,\u03a3\u03be ) = ( y\u0304\u03be, S\nN\u03be\n) , and proceeding for times \u03be < t \u2264 \u03b6.\nAfter proceeding forward in time, information from later observations should also be propagated backward in time via a smoothing operation. For example, for our application, the Rauch-TungStriebel (RTS) smoother runs the following recursive operations starting at time \u03b6:\n\u00b5\u03b6 = \u00b5\u0303\u03b6 , \u03a3\u03b6 = \u03a3\u0303\u03b6 (31) Ct = \u03a3\u0303t ( \u03a3\u0302t+1 )\u22121 = \u03a3\u0303t ( \u03a3\u0303t +R(a) )\u22121 (32)\n\u00b5t = \u00b5\u0303t + Ct ( \u00b5t+1 \u2212 \u00b5\u0302t+1 ) = \u00b5\u0303t + Ct ( \u00b5t+1 \u2212 \u00b5\u0303t ) (33)\n\u03a3t = \u03a3\u0303t + Ct ( \u03a3t+1 \u2212 \u03a3\u0302t+1 ) ( Ct )\u1d40 = \u03a3\u0303t + Ct ( \u03a3t+1 \u2212 \u03a3\u0303t \u2212R(a) ) ( Ct )\u1d40\n(34)\nRecall that \u201c\u02c6\u201d and \u201c\u02dc\u201d variables are the predicted and filtered parameters respectively. Parameters without such modifications are smoothed. Once the sequence of parameters { \u00b5t,\u03a3t }\u03b6 t=\u03be is inferred, we can use them to determine the log-likelihood of the observations (for scoring associations) and the predictive distributions (for determining cluster assignment in Gibbs sampling). We will repeatedly use the following fact:\nx \u223c N (\u00b5,\u03a3) , y|x \u223c N (x,\u039b) \u21d2 y \u223c \u222b P (y |x) P (x) dx = N (\u00b5,\u03a3 + \u039b) (35)\nFor example, we know that xt \u223c N ( \u00b5t,\u03a3t ) (hyperparameters obtained from Kalman smoothing),\nand from our modeling assumptions, yt \u2223\u2223xt \u223c N (xt, S). Hence the marginal distribution over the\npose observation (marginalized over all possible latent poses xt) is yt \u223c N ( \u00b5t,\u03a3t + S ) . From this we can immediately find the marginal likelihood of the observed data:\nP ({{ yti }Nt i=1 }\u03b6 t=\u03be ) = \u03b6\u220f t=\u03be Nt\u220f i=1 P ( yti ) = \u03b6\u220f t=\u03be Nt\u220f i=1 N ( yti ; \u00b5 t,\u03a3t + S )\n(36)\nThis likelihood expression is used to score potential association hypotheses. We can now derive the conditional probability expressions in the Gibbs sampler, shown in Equation 10. In collapsed Gibbs sampling, each observation\u2019s predictive likelihood P ( oti \u2223\u2223\u2223Ok\\ti) involves an integral over the latent parameters \u03b8kt = ( ak, xkt ) of the cluster. In forward sampling, assigning observation oti to cluster k has three cases:\n1. If cluster k exists and is instantiated (i.e., has other observations at time t assigned to it), the posterior distribution of the pose xkt is N ( \u00b5kt,\u03a3kt ) , and the posterior distribution of the\nfixed attribute is \u03d5(ak). Thus the predictive distribution is: P ( oti \u2223\u2223\u2223Ok\\ti) = \u222b P (oti \u2223\u2223 \u03b8) P(\u03b8 \u2223\u2223\u2223Ok\\ti) d\u03b8 =\n[\u2211 ak P ( bti \u2223\u2223\u2223 ak) \u03d5(ak)] \u222b P(yti \u2223\u2223\u2223xkt) N (xkt ; \u00b5kt,\u03a3kt) dxkt =\n[\u2211 ak \u03c6a k (bti) \u03d5(a k) ] N ( yti ; \u00b5 kt,\u03a3kt + S )\n(37)\nIn the final line, we used Equations 23 and 35 to simplify the predictive distributions.\n2. If cluster k exists, but it has not yet been instantiated, this implies that, in the forward case, that the time of the observation t is beyond the final observed time \u03c4 = \u03b6 associated with the cluster. Then instead of integrating over the posterior distribution of xkt, which does not exist yet, we need to integrate over its predictive distribution. This can be found by propagating the prediction step in the Kalman filter, starting from the final time step\u2019s distribution xk\u03c4 \u223c N ( \u00b5k\u03c4 ,\u03a3k\u03c4 ) :\n\u00b5kt = \u00b5k\u03c4 , \u03a3kt = \u03a3k\u03c4 + (t\u2212 \u03c4)R(ak) (38)\nThis is precisely the \u201cgeneralized\u201d transition distribution T\u0303 for the pose in the DDPMM. Hence xkt \u223c N ( \u00b5k\u03c4 ,\u03a3k\u03c4 + (t\u2212 \u03c4)R(ak) ) , and by a derivation similar to Equation 37:\nP ( oti \u2223\u2223\u2223Ok\\ti) = [\u2211 ak \u03c6a k (bti) \u03d5(a k) ] N ( yti ; \u00b5 k\u03c4 ,\u03a3k\u03c4 + (t\u2212 \u03c4)R(ak) + S )\n(39)\n3. If cluster k does not exist (and Ok\\ti = \u2205), then we should use the base distribution H (\u03b8) , \u03c0(a) N ( x ; \u00b50,\u03a30 ) instead of the posterior distribution. Then:\nP ( oti \u2223\u2223\u2223Ok\\ti) = P (oti) = \u222b P (oti \u2223\u2223 \u03b8) H (\u03b8) d\u03b8 =\n[\u2211 ak P ( bti \u2223\u2223\u2223 ak) \u03c0(ak)] \u222b P(yti \u2223\u2223\u2223xkt) N (xkt ; \u00b50,\u03a30) dxkt =\n[\u2211 ak \u03c6a k (bti) \u03c0(a k) ] N ( yti ; 0,\u221eI ) (40)\nHowever, this requires the evaluation of an improper normal distribution in the final term. Since the choice of this prior was motivated by an attempt to give all initial poses equal probability, the same effect can be achieved by using a uniform distribution over the total explored world volume. Thus, in practice during Gibbs sampling we evaluate the following:\nP ( oti \u2223\u2223\u2223Ok\\ti) = [\u2211 ak \u03c6a k (bti) \u03c0(a k) ] Unif(vol(world)) (41)\nNote that this is similar to the expression for the observation likelihood of false positives. If the observation is actually assigned to a new cluster, then we revert to the noninformative normal prior and perform Kalman smoothing, which is now no longer problematic since it does not require evaluation of improper densities."}], "references": [{"title": "Construction of dependent Dirichlet processes based on", "author": ["D. Lin", "E. Grimson", "J. Fisher"], "venue": null, "citeRegEx": "Lin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2012}, {"title": "Dependent Dirichlet processes", "author": ["S.N. MacEachern"], "venue": "Technical report, Ohio State University,", "citeRegEx": "1999", "shortCiteRegEx": "1999", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": ", 1999) have proposed different Markov-chain Monte Carlo (MCMC) methods for data association. See Wong et al. (2015) for in-depth coverage about previous work in semantic world modeling and data association.", "startOffset": 2, "endOffset": 117}, {"referenceID": 0, "context": ", 1999) have proposed different Markov-chain Monte Carlo (MCMC) methods for data association. See Wong et al. (2015) for in-depth coverage about previous work in semantic world modeling and data association. The methods mentioned above were all formulated for multiple-target tracking problems, where the each target\u2019s state (typically location) changes between observations. However, if we consider applications such as tracking objects in a household, the dynamics are typically different: most objects tend to stay in the same state when they are not being actively used. In this paper, we study the world modeling problem in semi-static environments, where time is divided into known epochs, and within each epoch the world is stationary. It seems intuitive that data association should be easier within static periods, since there is no uncertainty arising from stochastic dynamics. An alternative approach to data association is to perform inference over the entire time-series of observations and to think of it as a problem of clustering: we wish to group together similar detections over time, under the assumption that they will have been generated by the same individual. Bayesian nonparametric models, such as the Dirichlet-process mixture model (DPMM), can be used to model domains in which the number of individuals is unknown a priori ; in Wong et al. (2015), we found that a state-estimation technique based on DPMM clustering was effective for determining the number and type of objects in a static domain, given a sequence of images with partial views of the scene and significant occlusion.", "startOffset": 2, "endOffset": 1374}, {"referenceID": 0, "context": "In particular, we use a construction proposed by Lin et al. (2010) for a class of DDPs that can be represented as a Markov chain over DPs.", "startOffset": 49, "endOffset": 67}, {"referenceID": 0, "context": "We will adopt a theoretically-appealing instance of the DDP, based on a recently-proposed Poisson-process construction (Lin et al., 2010; Lin, 2012). This construction subsumes a number of existing algorithmically-motivated DP generalizations. Additionally, Lin\u2019s construction has the nice property that at each time slice, the prior over clusters is marginally a DP. Given a DP prior at time t, the construction specifies a dependent prior at time t + 1 (or another future time), which is shown to also be a DP. The construction therefore generates a Markov chain of DPs over time, which reflects temporal dynamics between epochs in our problem. We now state one result of the DDP construction; see Appendix A, and Lin (2012) for details.", "startOffset": 120, "endOffset": 727}], "year": 2015, "abstractText": "To accomplish tasks in human-centric indoor environments, robots need to represent and understand the world in terms of objects and their attributes. We refer to this attributebased representation as a world model, and consider how to acquire it via noisy perception and maintain it over time, as objects are added, changed, and removed in the world. Previous work has framed this as multiple-target tracking problem, where objects are potentially in motion at all times. Although this approach is general, it is computationally expensive. We argue that such generality is not needed in typical world modeling tasks, where objects only change state occasionally. More efficient approaches are enabled by restricting ourselves to such semi-static environments. We consider a previously-proposed clustering-based world modeling approach that assumed static environments, and extend it to semi-static domains by applying a dependent Dirichletprocess (DDP) mixture model. We derive a novel MAP inference algorithm under this model, subject to data association constraints. We demonstrate our approach improves computational performance in semi-static environments.", "creator": "LaTeX with hyperref package"}}}