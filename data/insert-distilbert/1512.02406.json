{"id": "1512.02406", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2015", "title": "Learning Discrete Bayesian Networks from Continuous Data", "abstract": "real data often contains a mixture of discrete and continuous variables, but many simple bayesian open network structure learning and inference algorithms assume all random variables are discrete. continuous variables are often discretized, but the choice of discretization policy mechanisms has significant impact on the subjective accuracy, speed, and interpretability predictions of the resulting models. this paper introduces explicitly a principled bayesian discretization method for all continuous variables in bayesian networks with quadratic complexity instead of the cubic complexity of other standard numerical techniques. empirical demonstrations overwhelmingly show that the proposed method is superior to the state of the art. in addition, this paper shows how to incorporate existing methods used into starting the structure / learning process to discretize all continuous variables and simultaneously finally learn independent bayesian network structures.", "histories": [["v1", "Tue, 8 Dec 2015 11:12:04 GMT  (780kb,D)", "https://arxiv.org/abs/1512.02406v1", "This work has been submitted to Machine Learning (Springer journal)"], ["v2", "Tue, 15 Dec 2015 08:00:55 GMT  (817kb,D)", "http://arxiv.org/abs/1512.02406v2", "This work has been submitted to Machine Learning (Springer journal)"]], "COMMENTS": "This work has been submitted to Machine Learning (Springer journal)", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["yi-chun chen", "tim allan wheeler", "mykel john kochenderfer"], "accepted": false, "id": "1512.02406"}, "pdf": {"name": "1512.02406.pdf", "metadata": {"source": "CRF", "title": "Learning Discrete Bayesian Networks from Continuous Data", "authors": ["Yi-Chun Chen", "Tim A. Wheeler", "Mykel J. Kochenderfer"], "emails": ["yichunc@stanford.edu", "wheelert@stanford.edu", "mykel@stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Bayesian networks (Pearl 1988; Koller and Friedman 2009) are often used to model uncertainty and causality, with applications ranging from decision-making systems (Kochenderfer et al. 2012) to medical diagnosis (Lustgarten et al. 2011). Bayesian networks provide an efficient factorization of the joint probability distribution over a set of random variables. It is common to assume that the random variables in a Bayesian network are discrete, since many Bayesian network learning and inference algorithms are unable to efficiently handle continuous variables. In addition, many of the commonly used Bayesian network software packages, such as Netica (Norsys 1992\u20132009), SMILearn (Druzdzel 1999), and bnlearn (Scutari 2010), are geared towards discrete variables. However, many applications require the use of continuous variables, such as position and velocity in dynamic systems (Kochenderfer et al. 2010).\n\u2217Electronic address: yichunc@stanford.edu \u2020Electronic address: wheelert@stanford.edu \u2021Electronic address: mykel@stanford.edu\nar X\niv :1\n51 2.\n02 40\n6v 2\n[ cs\n.A I]\n1 5\nThere are three common approaches to extending Bayesian networks to continuous variables. The first is to model the conditional probability density of each continuous variable using specific families of parametric distributions, and then to redesign Bayesian network learning and inference algorithms based on the parameterizations. One example of parametric continuous distributions in Bayesian networks is the Gaussian graphical model (Weiss and Freeman 2001).\nThe second approach is to use nonparametric distributions, such as particle representations and Gaussian processes (Ickstadt et al. 2010). Unlike parametric methods, nonparametric methods can often fit any underlying probability distribution given sufficient data. Parametric models have a fixed number of parameters, whereas the number of parameters in a nonparametric model grow with the amount of training data.\nThe third approach is discretization. Automated discretization methods have been studied in machine learning and statistics for many years (Dougherty et al. 1995; Kerber 1992; Holte 1993; Fayyad and Irani 1993), primarily for classification problems. These methods search for the best discretization policy for a continuous attribute by considering its interaction with a class variable. It is common to discretize all continuous variables before learning a Bayesian network structure to avoid having to consider variable interactions, as the interactions and dependencies between variables in Bayesian networks introduce complexity. Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks (Friedman et al. 1997), but only a few discretization methods for general Bayesian networks have been proposed (Friedman and Goldszmidt 1996; Kozlov and Koller 1997; Monti and Cooper 1998; Steck and Jaakkola 2004).\nA common discretization method for Bayesian networks is to split continuous variables into uniform-width intervals or by using field-specific expertise. A more principled method is the minimum description length (MDL) principle discretization (Friedman and Goldszmidt 1996). The MDL principle proposed by Rissanen (1978) states that the best model for a dataset is the one that minimizes the amount of information needed to describe it (Gru\u0308nwald 2007). MDL methods trade off goodness-of-fit against model complexity to reduce generalization error. In the context of Bayesian networks, Friedman and Goldszmidt (1996) applied the MDL principle to determine the optimal number of discretization intervals for continuous variables and the optimal positions of their discretization edges. Their approach selects a discretization policy that minimizes the sum of the description length of the discretized Bayesian network and the information necessary for recovering the continuous values from the discretized data.\nThe optimal discretization policy of a single continuous variable under MDL can be found using dynamic programming in cubic runtime with the number of data instances. For Bayesian networks with multiple continuous variables, MDL discretization can be iteratively applied to each continuous variable. Only one variable is treated as continuous at a time, while all other continuous variables are treated as discretized based on an initial discretization policy or the discretization result from a previous iteration.\nMDL discretization requires that the network structure be known in advance, but\nan iterative approach allows it to be incorporated into the structure learning process. Simultaneous structure learning and discretization alternates between traditional discrete structure learning and optimal discretization. Starting with some preliminary discretization policy, one first applies a structure learning algorithm to identify the locally optimal graph structure. One then refines the discretization policy based on the learned network. The cycle is repeated until convergence.\nResults in this work suggest that the MDL method suffers from low sensitivity to discretization edge locations and returns too few discretization intervals for continuous variables. This is caused by MDL\u2019s use of mutual information to measure the quality of discretization edges. Mutual information, which is composed of empirical probabilities computed using event count ratios, varies less significantly with the positions of discretization edges than the method we suggest in this article.\nMODL (Boulle\u0301 2006) is a Bayesian method for discretizing a continuous feature according to a class variable, which selects the model with maximum probability given the data. The MODL method uses dynamic programming to find the optimal discretization policy for a continuous variable given a discrete class variable, and has an O ( n3 + r \u00b7 n2\n) runtime, where r is the number of class variable instantiations. Lustgarten et al. (2011) suggest several formulations for the prior over models. The asymptotic equivalence between MDL and MODL on the single-variable, single-class problem was examined by Vita\u0301nyi and Li (2000).\nThis paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from Boulle\u0301 (2006) and Lustgarten et al. (2011). The proposed method optimizes the discretization policy relative to the network and takes parents, children, and spouse variables into account. The optimal single-variable discretization method is derived in Section 3, using a prior which reduces the discretization runtime to O ( r \u00b7 n2 ) without sacrificing optimality. Section 4 covers Bayesian networks with multiple continuous variables and Section 5 covers discretization while simultaneously learning network structure. The paper concludes with a comparison against the existing minimumdescription length (Friedman and Goldszmidt 1996) method on real-world datasets in Section 6."}, {"heading": "2 Preliminaries", "text": "This section covers the notation used throughout the paper to describe discretization policies. This section also provides a brief overview of Bayesian networks."}, {"heading": "2.1 Discretization Policies", "text": "Let X be a continuous variable and let x be a specific instance of X. A discretization policy \u039bX = \u3008e1 < e2 < . . . < ek\u22121\u3009 for X is a mapping from R to {1, 2, 3, . . . , k} such that\n\u039bX(x) =  1, if x < e1\ni, if ei\u22121 \u2264 x < ei k, otherwise.\n(1)\nThe discretization policy discretizes X into k intervals. Let the samples of X in a given dataset D be sorted in ascending order, x1:n = {x1 \u2264 x2 \u2264 . . . \u2264 xn}, and let the unique values be u1:m = {u1 < u2 < . . . < um}. The index of the last occurrence of ui in x1:n is denoted si.\nThe discretization edges e1:k\u22121 mark the boundaries between discretization intervals. In this paper, as with MODL, they are restricted to the midpoints between unique ascending instances of X. Thus, each edge ei equals (uj + uj+1)/2 for some j. Two useful integer representations of \u039bX can be written\n\u039bX = \u3008\u03bb1 < \u03bb2 < . . . < \u03bbk\u3009 \u2261 \u3008\u03b31, \u03b32, . . . , \u03b3k\u3009, (2) where \u03bb1 = s1, \u03bbi \u2208 s1:m, \u03b31 = \u03bb1, and \u03b3i = \u03bbi \u2212 \u03bbi\u22121. The \u03bb1:k representation is the number of instances before every discretization edge whereas the \u03b31:k representation is the number of instances within each discretization interval."}, {"heading": "2.2 Bayesian Networks", "text": "A Bayesian network B over N random variables X1:N is defined by a directed acyclic graph G whose nodes are the random variables and a conditional probability distribution for each node given its parents. The edges in a Bayesian network represent probabilistic dependencies among nodes and encode the Markov property: each node Xi is independent of its non-descendants given its parents paXi in G. The children of node Xi are denoted chXi .\nWhen discussing the discretization of a particular continuous variable X, let Pi be the ith parent of X, let Ci be the ith child of X, and let Si be the set of spouses of X associated with the ith child."}, {"heading": "3 Single Variable Discretization", "text": "This section covers the discretization of a single continuous variable X in a Bayesian network where all other variables are discrete. An optimal discretization policy for a dataset D maximizes P (\u039b) \u00b7 P (D | \u039b) for some prior P (\u039b) and likelihood P (D | \u039b)."}, {"heading": "3.1 Priors and Objective Function", "text": "Let DY be the subset of the training data corresponding to variable subset Y . Four principles for the optimal discretization policy enable the formulation of P (\u039b) and P (D\u2212X | \u039b), where D\u2212X is the subset of the dataset for all variables but X, and the probability of the data associated with the target variable, P (DX), is already captured\nin P (\u039b). The four principles, which can be considered an extension of the priors in MODL and Lustgarten et al. (2011) to Bayesian networks, are:\n1. The prior probability of a discretization edge between two consecutive unique values ui and ui+1 is proportional to their difference:\n1\u2212 exp ( \u2212L \u00b7 ui+1 \u2212ui\num \u2212u1\n) , (3)\nwhere L is the largest number of intervals among discrete variables in X\u2019s Markov blanket. This encourages edges between well-separated values over edges between closely packed samples.\n2. For a given discretization interval, every distribution over the parents of X is equiprobable.\n3. For each pair \u3008Ci,Si\u3009 and a given discretization interval, every distribution over Ci given an instance of Si is equiprobable.\n4. The distributions over X given each child, parent, and spouse instantiation are independent.\nFrom the first principle one obtains the prior over the discretization policy:\nP (\u039b) = k\u22121\u220f i=1 [ 1\u2212 exp ( \u2212L \u00b7 x\u03bbi+1 \u2212x\u03bbi xn \u2212x1 )] k\u220f i=1 [ exp ( \u2212L \u00b7 x\u03bbi \u2212x\u03bbi\u22121+1 xn \u2212x1 )] . (4)\nThe Bayesian network graph structure causes the likelihood term P (D\u2212X | \u039b) to factor according to X\u2019s Markov blanket:\nP (D\u2212X | \u039b) \u221d P ( DpaX | \u039b ) \u00b7 \u220f i P (DCi | \u039b, DSi). (5)\nFor example, in Figure 1, P (D\u2212X | \u039b) factors according to\nP (DP1,P2,P3 | \u039b) \u00b7 P (DC1 | \u039b, DS1) \u00b7 P (DC2 | \u039b, DS2). (6) The concept behind the factorization is also the motivation behind forward sampling in a Bayesian network. The parents of X are independent of the children given X. The parents are not necessarily individually independent, and thus the parental term P (DpaX | \u039b) cannot be factored further. The children of X are similarly independent given X and the corresponding spouses, leading to their factored product \u220f i P (DCi | \u039b, DSi). Each component in the decomposition can be evaluated given a discretization policy and a dataset.\n3.1.1 Evaluation of P ( DpaX | \u039b ) Let JP be the number of instantiations of the parents of X, and let n (P) i,j be the number of instances of X within the ith discretization interval of \u039b given the jth parental\ninstantiation. Note that \u03b3i = \u2211 j n (P) i,j . It follows that\nP ( DpaX | \u039b ) = Principle 4\ufe37\ufe38\ufe38\ufe37 k\u220f i=1 Principle 2\ufe37 \ufe38\ufe38 \ufe37 1( \u03b3i+JP\u22121 JP\u22121 ) 1 \u03b3i!\nn (P) i,1 ! n (P) i,2 ! \u00b7\u00b7\u00b7 n (P) i,JP !\n. (7)\nThe two factors on the right hand side come from the second principle: all distributions of values of the parents of X in a given interval are equiprobable. The fourth principle is that the distributions for each interval are independent, so the factors can be multiplied together.\n3.1.2 Evaluation of P (DCj | \u039b, DSj )\nLet JCj be the number of instantiations of the jth child of X, let J (j) S be the number of instantiations of the jth spouse set Sj , and let n (j) i,m,` be the number of instances of X in the ith discretization interval of \u039b given the mth instantiation of Cj and the `th instantiation of Sj . Let n (j) i,` = \u2211Jj m=1 n (j) i,m,`. Note that \u03b3i = \u2211 ` n (j) i,` for all j. It follows that\nP (DCj | \u039b, DSj ) = Principle 4\ufe37 \ufe38\ufe38 \ufe37 k\u220f i=1 J (j) S\u220f `=1 Principle 3\ufe37 \ufe38\ufe38 \ufe37 1(n(j)i,` +JCj\u22121\nJCj\u22121 ) 1n(j)i,` ! n (j) i,1,`! n (j) i,2,`! \u00b7\u00b7\u00b7 n\n(j) i,JCj ,`!\n. (8)\nThe two factors on the right hand side come from the third principle: all distribution of values of Cj in a given interval and with a given value of Sj are equiprobable. According to the fourth prior, these distributions are independent from each other, and one can thus take their product. If Sj = \u2205, then Equation 8 is equivalent to\nP (DCj | \u039b,Sj = \u2205) = Principle 4\ufe37\ufe38\ufe38\ufe37 k\u220f i=1 Principle 3\ufe37 \ufe38\ufe38 \ufe37 1(\u03b3i+JCj\u22121\nJCj\u22121 ) 1\u03b3i! n (j) i,1,\u2205! n (j) i,2,\u2205! \u00b7\u00b7\u00b7 n\n(j) i,JCj ,\u2205!\n, (9)\nwhere n (j) i,m,\u2205 is the number of instances of X in the ith discretization interval of \u039b given the mth instantiation of Cj . The objective function can be formulated given equations 4, 5, 7, 8 and 9. The log-inverse of P (\u039b) \u00b7 P (D\u2212X | \u039b) is minimized for computational convenience:\nk\u22121\u2211 i=1 \u2212 ln ( 1\u2212 exp ( \u2212L \u00b7 x\u03bbi+1 \u2212x\u03bbi xn \u2212x1 )) + k\u2211 i=1 L \u00b7 x\u03bbi \u2212x\u03bbi\u22121+1 xn \u2212x1 + k\u2211 i=1 ln(\u03b3i + JP \u2212 1 JP \u2212 1 ) + ln  \u03b3i! n (P) i,1 ! n (P) i,2 ! \u00b7 \u00b7 \u00b7 n (P) i,JP !\n+ nc\u2211 j=1 k\u2211 i=1 J (j) S\u2211 `=1 ln(n(j)i,` + JCj \u2212 1 JCj \u2212 1 ) + ln  n(j)i,` ! n (j) i,1,`! n (j) i,2,`! \u00b7 \u00b7 \u00b7 n (j) i,JCj ,` !  (10)"}, {"heading": "3.2 Single-Variable Discretization Algorithm", "text": "The procedure used to minimize the objective function involves dynamical programming. Note that because the objective function is cumulative over intervals, if a partition \u039b = \u3008\u03b31, \u03b32, . . . , \u03b3k\u3009 of X is an optimal discretization policy, then any subinterval is optimal for the corresponding subproblem. It follows that dynamic programming can be used to solve the optimization problem exactly.\nPrecomputation reduces runtime. Hence, h(u, v) is computed first for each interval \u03b3q starting from xu to xv for all u, v satisfying u \u2264 v:\nh(u, v) = ln ( \u03b3q + JP \u2212 1 JP \u2212 1 ) + ln  \u03b3q! n (P) q,1 !n (P) q,2 ! \u00b7 \u00b7 \u00b7n (P) q,Jp !  +\nnc\u2211 j=1 J (j) S\u2211 `=1 ln(n(j)i,` + JCj \u2212 1 JCj \u2212 1 ) + ln  n(j)i,` ! n (j) i,1,`! n (j) i,2,`! \u00b7 \u00b7 \u00b7 n (j) i,JCj ,` !  (11)\nThe calculation of h(u, v) for all u \u2264 v has a O ( nc \u00b7 Lns \u00b7 n2 + Lnp \u00b7 n2 ) runtime, where nc and np are the number of child and parent variables respectively, L is the largest cardinality of variables in X\u2019s Markov blanket, and ns = maxj |paCj |.\nThe optimization problem over Equation 10 can now be solved. The dynamic programming procedure is shown in Algorithm 1. It takes three inputs: X, the continuous variable; D, the joint data instances over all variables sorted in ascending order according to DX ; and G, the network structure. The runtime of Algorithm 1 is also O ( nc \u00b7 Lns \u00b7 n2 + Lnp \u00b7 n2 ) because the runtime of the dynamic programming procedure is less than the runtime for computing h(u, v). As will be discussed in Section 6, the MDL discretization method has a runtime of O ( n3 + (nc \u00b7 Lns + Lnp) \u00b7 n2 ) , which\nincludes an extra O ( n3 )\nterm. The Bayesian discretization method is quadratic in the sample count n, whereas the MDL discretization method is cubic.\nAlgorithm 1 is guaranteed to be optimal. For faster methods with suboptimal results, see Boulle\u0301 (2006).\nAlgorithm 1 Discretization of one continuous variable in a Bayesian network\nfunction DiscretizeOne(D, G, X) H \u2190 an n\u00d7 n matrix such that H[u, v] = h(u, v); can be precomputed L\u2190 the largest cardinality over all discrete variables in the Markov blanket of X\nS[i]\u2190 the optimal objective value computed over samples 1 to si 5: \u039b[i]\u2190 the discretization policy for the subproblem over samples 1 to si\nW [i]\u2190 \u2212 ln [ 1\u2212 exp ( \u2212L \u00b7 xsi+1\u2212xsi\num\u2212u1\n)] for i \u2208 [1,m\u2212 1] and W [m]\u2190 0\nfor v \u2190 1 to m do if v = 1 then\nS[v]\u2190 H(1, sv) + L[v] 10: \u039b[v]\u2190 {(uv + uv+1)/2}\nelse S\u0302, u\u0302\u2190\u221e, 0 DiscEdge\u2190\u221e for u\u2190 1 to v do\n15: if u = v then S\u0303 \u2190W [v] +H(1, sv) + L \u00b7 uv\u2212u1um\u2212u1\nelse S\u0303 \u2190W [v] +H(su + 1, sv) + L \u00b7 uv\u2212uu+1um\u2212u1 + S[u]\nif S\u0303 < S\u0302 then 20: S\u0302, u\u0302\u2190 S\u0303, u\nDiscEdge\u2190 (xsu + xsu+1)/2 S[v]\u2190 S\u0302 \u039b[v]\u2190 \u039b[u\u0302] \u222a {DiscEdge}\nreturn \u039b[m]"}, {"heading": "4 Multi-Variable Discretization", "text": "The single-variable discretization method can be extended to Bayesian networks with multiple continuous variables by iteratively discretizing individual variables. The discretization process for a single variable requires that all other variables be discrete. The iterative approach uses an initial discretization policy in order to start the process which assigns k equal-width intervals to each continuous variable, where k is the largest number of intervals of initially discrete variables in the network.\nAfter the initial discretization, the one-variable discretization method is iteratively applied over each continuous variable in reverse topoligical order, from the leaves to the root. Reverse topological order has the advantage of relying on fewer initial discretizations of the continuous variables during the first pass. For example, in the network of Figure 2, if S2 is the only discrete variable, then the discretization of P1 involves both P2 and X, whereas the discretization of C1 only involves X.\nThe algorithm is terminated when the number of discretization intervals and their associated edges converge for all variables, and a maximum number of complete passes is enforced to prevent infinite iterations when convergence does not occur. The algorithm typically converges within a few passes when tested on real-world data.\nThe pseudocode for the multi-variable discretization procedure is shown in Algorithm 2. It requires four inputs: D, a dataset of samples from the joint distribution; G, the fixed network structure; X, the set of all continuous variables in reverse topological order, and n\u0302cycle, an upper bound on the number of complete passes."}, {"heading": "5 Combining Discretization with Structure Learning", "text": "It is often necessary to infer the structure of a Bayesian network from data. Three common approaches to Bayesian network structure learning are constraint-based, scorebased, and Bayesian model averaging (see Koller and Friedman 2009, chap. 18). This work uses the K2 structure learning algorithm (Cooper and Herskovits 1992), a frequently used score-based structure learning method. Score-based structure learning\nAlgorithm 2 Discretization of multiple continuous variables\nfunction DiscretizeAll(D, G, X, n\u0302cycle) \u039bX \u2190 the discretization policies for each X in X D\u2217 \u2190 the dataset D discretized according to \u039bX k \u2190Max({|X| s.t. X does not have corresponding X in X})\n5: for (X, X) such that X \u2208X and X is the discretized version of X do \u039bX \u2190 equal-width discretization of X with k intervals D\u2217X \u2190 \u039bX(DX)\nncycle \u2190 0 while \u039bX has not converged and ncycle \u2264 n\u0302cycle do\n10: increment ncycle for (X, X) such that X \u2208X do\nD\u2217X \u2190 DX \u039bX \u2190 DiscretizeOne(D\u2217, G,X) D\u2217X \u2190 \u039bX(DX)\n15: return \u039bX\nmethods over discrete variables commonly evaluate candidate structures according to their likelihood against a dataset D. In practice, one maximizes the log-likelihood, also known as the Bayesian score, lnP (G | D) (Cooper and Herskovits 1992).\nFor a Bayesian network over N discrete and discretized variables X1:N , ri represents the number of instantiations of Xi, and qi represents the number of instantiations of the parents of Xi. If Xi has no parents, then qi = 1. The Bayesian score is:\nlnP (G | D) = lnP (G) + N\u2211 i=1 qi\u2211 j=1 ln\n \u0393 ( \u03b1 (0) ij ) \u0393 ( \u03b1 (0) ij + \u03b2 (0) ij ) + ri\u2211 k=1 ln \u0393 ( \u03b1 (k) ij + \u03b2 (k) ij ) \u0393 ( \u03b1 (k) ij ) , (12)\nwhere \u0393 is the gamma function, \u03b1 (k) ij is a Dirichlet parameter and \u03b2 (k) ij is the observed sample count for the kth instantiation of Xi and the jth instantiation of paXi . In the equation above,\n\u03b1 (0) ij = ri\u2211 k=1 \u03b1 (k) ij \u03b2 (0) ij = ri\u2211 k=1 \u03b2 (k) ij . (13)\nThe space of acyclic graphs is superexponential in the number of nodes; it is common to rely on heuristic search strategies (Koller and Friedman 2009). The K2 algorithm assumes a given topological ordering of variables and greedily adds parents to nodes to maximally increase the Bayesian score. A fixed ordering ensures acyclicity but does not guarantee a globally optimal network structure. K2 is typically run multiple times with different topological orderings, and the network with the highest likelihood is retained.\nTraditional Bayesian structure learning algorithms require discretized data, whereas the proposed discretization algorithm requires a known network structure. The dis-\ncretization methods can be combined with the K2 structure learning algorithm (Cooper and Herskovits 1992) to simultaneously perform Bayesian structure learning and discretization of continuous variables.\nThe proposed algorithm alternates between K2 structure learning and discretization. The dataset is initially discretized as was described in Section 4, and K2 is run to obtain an initial network structure. The affected continuous variables are rediscretized every time an edge is added by K2. The resulting discretization policies are used to update the discretized dataset, and the next step of the K2 algorithm is executed. This cycle is repeated until the K2 algorithm converges.\nThis procedure is given in Algorithm 3, and takes five inputs: D, a dataset of samples from the joint distribution; X, the set of all continuous variables; order, a permutation of the variables in D; n\u0302parent, an upper bound on the number of parents per node; and n\u0302cycle, an upper bound on the number of complete passes. The upper bound on the number of parents is common practice, and is used to prevent computing conditional distributions with excessively large parameter sets. The function g in Algorithm 3 computes a component of the Bayesian score (Equation 12):\ng ( Xi,paXi ) = qi\u2211 j=1 ln\n \u0393 ( \u03b1 (0) ij ) \u0393 ( \u03b1\n(0) ij + \u03b2 (0) ij\n) + ri\u2211\nk=1\nln\n\u0393 ( \u03b1 (k) ij + \u03b2 (k) ij ) \u0393 ( \u03b1\n(k) ij\n) . (14)\nIt is common practice to run K2 multiple times with different variable permutations and to then choose the structure with the highest score. As such, Algorithm 3 is run multiple times with different variable permutations and the discretized Bayesian network with the highest score is retained."}, {"heading": "6 Experiments", "text": "This section describes experiments conducted to evaluate the Bayesian discretization method. All experiments were run on datasets from the publically available University of California, Irvine machine learning repository (Lichman 2013). Variables are labeled alphabetically in the order given on the dataset information webpage. In the figures that follow, shaded nodes correspond to initially discrete variables and the subscripts indicate the number of discrete instantiations.\nTwo experiments were conducted on each dataset. The first experiment compares the performance of the Bayesian and MDL discretization methods on a known Bayesian network structure. The structure was obtained by discretizing each continuous variable into k uniform-width intervals, where k is the median number of instantiations of the discrete variables, and using the structure with the highest Bayesian score from 1000 runs of the K2 algorithm with random topological orderings. The second experiment compares the same methods applied when simultaneously discretizing and learning network structure.\nThe discretizations are compared using the mean cross validated log-likelihood of the data D given the Bayesian network B and discretization policies \u039bX. Note that\nAlgorithm 3 Learning a discrete-valued Bayesian network\nfunction Learn DVBN(D, X, order, n\u0302parent, n\u0302cycle) N \u2190 the number of variables in the Bayesian network k \u2190Max{\u2016v\u2016, v /\u2208 C} \u039bX \u2190 the discretization policies for each X in X\n5: D\u2217 \u2190 the dataset D discretized according to \u039bX G\u2190 the initially edgeless graph structure for (X, X) such that X \u2208X and X is the discretized version of X do\n\u039bX \u2190 equal-width discretization of X with k intervals D\u2217X \u2190 \u039bX(DX)\n10: for i\u2190 1 to N do Pold \u2190 g(Xi, paXi) (Equation 14) OKToProceed \u2190 true while OKToProceed and \u2016paXi \u2016 < n\u0302parent do Y \u2190 an element from the set order[1 : i]\\(paX) 15: Pnew \u2190 ( g(Xi, paXi ) \u222a (Y ))\nif Pnew > Pold then Pold \u2190 Pnew paXi \u2190 ( paXi ) \u222a (Y )\nX\u2032 \u2190 X sorted in reverse-topological order given G 20: \u039b\u2190 DiscretizeAll(D, G, X\u2032, n\u0302cycle) (see Algorithm 2)\nD\u2217 \u2190 \u039b(DX) else\nOKToProceed \u2190 false return G, \u039b\nall log-likelihoods shown have been normalized by the number of data samples. The log-likelihood has two components,\nln p(D | B,\u039bX) = lnP (D\u2217 | B) + ln p(D | \u039bX, D\u2217), (15) where D is the original test dataset and D\u2217 is the test dataset discretized according to \u039bX.\nThe log-likelihood of the discretized dataset given the Bayesian network is\nP (D\u2217 | B) = N\u220f i=1 qi\u220f j=1 ri\u220f k=1\n( \u03b1\n(k) ij + \u03b2 (k) ij\n\u03b1 (0) ij + \u03b2 (0) ij\n)\u03b2\u2217(k)ij , (16)\nwhere \u03b1 and \u03b2 are the Dirichlet prior counts and observed counts in the training set for B, and \u03b2\u2217 is the set of observed counts in the test set D\u2217. All experiments used a uniform Dirichlet prior of \u03b1ijk = 1 for all i, j, and k.\nThe log-likelihood of the original dataset given the discrete dataset is\nln p(D | \u039bX, D\u2217) = N\u2211 i=1 1{Xi\u2208X} \u00b7 ri\u2211 k=1 qi\u2211 j=1 \u03b2 \u2217(k) ij ln  1 e \u039bXi k \u2212 e \u039bXi k\u22121 . (17) Note that e\n\u039bXi 0 = Min(DXi) and e \u039bXi ri = Max(DXi). The mean cross-validated log-\nlikelihood is the mean log-likelihood on the witheld dataset among cross-validation folds, and acts as an estimate of generalization error. Ten folds were used in each experiment.\nThe method for computing the MDL discretization policy is similar to the method for the Bayesian method. For a Bayesian network with a single continuous variable X, the MDL objective function is\n1 2 ln(n) |paX|(|X| \u2212 1) + \u2211\nj,X\u2208paXj\n|paXj |(|Xj | \u2212 1) + ln(|X|) +(m\u2212 1)H ( |X| \u2212 1 m\u2212 1 ) \u2212 n \u00b7 I(X,paX) + \u2211 j,X\u2208paXj I(Xj ,paXj )  , (18)\nwhere I(A,B) is the mutual information between two discrete variable sets A and B, H(p) = \u2212p ln(p)\u2212 (1\u2212 p) ln(1\u2212 p), and X is the discretized version of X.\nThe global minimum of Equation 18 can be found using dynamic programming. For a given Bayesian network, the first three terms only depend on the number of discretization intervals |X| and the fourth term is cumulative over the intervals. Hence, if \u039b = \u3008\u03b31, \u03b32, . . . , \u03b3k\u3009 is a MDL optimal discretization policy with k intervals, then \u039b\u2032 = \u3008\u03b31, \u03b32, . . . , \u03b3k\u22121\u3009 is a MDL optimal discretization policy for the corresponding subproblem with k \u2212 1 intervals. This procedure takes runtime O ( n3 + (nc \u00b7 Lns + Lnp) \u00b7 n2 ) .\nAll variables are defined in Section 3.2. Therefore, the runtime of the proposed method in this paper is shorter than the MDL discretization method by O ( n3 ) , since the former has a more efficient form of dynamical programming. For faster methods of MDL discretization with suboptimal results, see Friedman and Goldszmidt (1996).\nNote that the preliminary discretization and the discretization order of variables can be arbitrary for the MDL discretization method, as stated in the original work (Friedman and Goldszmidt 1996). In order to make a fair comparison between the Bayesian and MDL method, the preliminary discretization and the discretization order follows the same procedure as in Section 4."}, {"heading": "6.1 Dataset 1: Auto MPG", "text": "The Auto MPG dataset contains variables related to the fuel consumption of automobiles in urban driving. The dataset has 392 samples over eight variables, not including six instances with missing data. Three variables are discrete: B, G, and H, with 5, 13, and 3 instantiations respectively."}, {"heading": "6.1.1 Discretization with Fixed Structure", "text": "The Bayesian and MDL discretization methods were tested on the Auto MPG data using the network shown in Figure 3. This structure was obtained by initially discretizing each continuous variable into five uniform-width intervals, where five is the median cardinality of the discrete variables, and then taking the structure with highest likelihood from 1000 runs of K2.\nTable 1 lists the discretization edges and mean log-likelihoods under 10-fold cross validation of the discrete Bayesian network resulting from the two discretization methods. The MDL method does not produce any discretization edges, assigning one continuous interval to each continuous variable, and produces the result with the lower likelihood. The reason why MDL produces fewer discretization edges is discussed in\nSection 6.4. Two examples that MDL produces comparble results to the Bayesian method are given in the Appendix.\nFigure 4 shows the marginal probability density for variables A and C under the Bayesian discretization policy overlaid with the original Auto MPG data. The resulting probability density is a good match to the original data."}, {"heading": "6.1.2 Discretization while Learning Structure", "text": "In this experiment, the network structure was not fixed in advance and was learned simultaneously with the discretization policies. Figure 5 shows a learned Bayesian network structure and the corresponding numbers of intervals after discretization for each continuous variable. This result was obtained by running Algorithm 3 fifty times using the Bayesian method and choosing the structure with the highest K2 score (Equation 12).\nFigure 6 compares the Bayesian discretizaton policy for variables A and C in the learned network with the original Auto MPG data. The color of a discretized region indicates the marginal probability density of a sample from P (A,C) being drawn from that region. Although there are fewer discretization edges for A and C in the learned network, the marginal distribution is still captured. The discretization policy will vary as the network structure changes, and it still produces high-quality discretizations."}, {"heading": "6.2 Dataset 2: Wine", "text": "The Wine dataset contains variables related to the chemical analysis of wines from three different Italian cultivars. The dataset has 178 samples over fourteen variables. Variable A is the only discrete variable and has three instantiations."}, {"heading": "6.2.1 Discretization with Fixed Structure", "text": "The Bayesian and MDL discretization methods were tested on the Wine data using the network shown in Figure 7. This structure was obtained by initially discretizing each continuous variable into three uniform-width intervals, where three is the median cardinality of the discrete variables, and then taking the structure with highest likelihood from 1000 runs of K2.\nTable 2 lists the discretization edges and mean log-likelihoods under 10-fold cross validation of the Bayesian network resulting from each discretization method. The Bayesian method outperforms the MDL method in likelihood by a significant margin.\nThe MDL method creates significantly fewer discretization edges. Some discretization edges appear in all three discretization methods, such as 1.42 and 2.35 for variable C and 0.785 for variable L. This indicates sufficiently MDL indeed can find some important discretization edges, but it is not sensitive to find more edges.\nFigure 8 compares the Bayesian and MDL discretizaton policies for variables E and K with the original Wine data. The discretization edges 17.9 for E and 34.6 for K appear in both plots. The MDL method does not use enough intervals for discretization. Relative sensitivities of each method to the input data is discussed in Section 6.4."}, {"heading": "6.2.2 Discretization while Learning Structure", "text": "Figure 9 is the discrete-valued Bayesian network learned from the Wine dataset, obtained by running Algorithm 3 fifty times. A comparison of Figures 9 and 7 show that the Bayesian network learned during the discretization process has more edges than the network learned on the initially discretized data. When a network is learned along with discretization, the algorithm has more freedom to adjust the structure and the discretization policy simultaneously to identify useful correlations and produce a denser structure.\nFigure 10 shows the discretization policy for variables E and K obtained with the Bayesian method. The discretization edge E = 17.9 also appears in both discretization policies from the fixed network (Figure 8). This suggests that discretization edges can be robust against network structure. Furthermore, the discretization edge at E = 23.5 in the fixed-structure case is missing in the learned structure. This is caused by E having twice as many parents in the learned network structure. The more parents\na variable has, the fewer discretization intervals it can to support, as the number of sufficient statistics required to define the resulting distribution increases exponentially with the number of parents."}, {"heading": "6.3 Dataset 3: Housing", "text": "The Housing dataset contains variables related to the values of houses in Boston suburbs. The dataset has 506 samples over fourteen variables. Only variables D and I are discrete-valued, with 2 and 9 instantiations, respectively. Despite their being continuous, several variables in the Housing dataset possess many repeated values. The following experiments were conducted with a maximum of three parents per variable to prevent running out of memory when running MDL."}, {"heading": "6.3.1 Discretization with Fixed Structure", "text": "The Bayesian network structure in Figure 11 was obtained by initially discretizing each continuous variable into five uniform-width intervals and then running the K2 algorithm 1000 times and choosing the network with the highest likelihood. Table 3 shows the numbers of interval after discretization for each continuous variable and the log-likelihood of the dataset based on each discretization method. MDL method does not produce any discretization edges for most variables. The relative weighting of each method\u2019s objective function will be discussed in Section 6.4.\nFigures 12 and 13 show the discretization policy learned using the Bayesian approach on the fixed network shown in Figure 11. The scatter points in Figure 12 were jittered to show the quantity of repeated values for variables C and E. Each repeated point forms a single discrete region, thereby encouraging discretization. In contrast, the samples for H are well spread out, resulting in fewer discretization regions and larger discretization intervals."}, {"heading": "6.3.2 Discretization while Learning Structure", "text": "Figure 14 shows a learned Bayesian network structure and the corresponding numbers of intervals after discretization for each continuous variable. Variable D is neighborless in both the learned and fixed networks. The continuous variables C, E, J and K, which are all connected through C, have many discretization intervals. Typically, when discretizing a variable, the expected number of discretization intervals is close to the highest cardinality among variables in its Markov blanket. This naturally leads to clusters of variables with many discretization intervals.\nFigures 15 and 16 show the discretization result for variables in the network shown in Figure 14. Again, variable C and E have many discretization edges due to repeated values. Although the number of intervals after discretization on H is less the number in Figure 13, it still captures the distribution of the raw data along with the discretization edges for E."}, {"heading": "6.4 Discussion", "text": "To qualitatively assess the sensitivity of each method to the number and position of discretization intervals, consider the Bayesian network in Figure 17, where X is continuous and P1 and P2 are discrete. If paX = {P1, P2} and DX = {1, 2, 3, . . . n}, then the corresponding objective functions for the discretization methods are:\nfMDL = Penalty Term\ufe37 \ufe38\ufe38 \ufe37 Z1 \u00b7 k + ln(k) + ln ( n+ k \u2212 1 k \u2212 1 ) + Edge Position Term\ufe37 \ufe38\ufe38 \ufe37 ln(n) \u00b7 I(X\u2217,paX)\nfBayesian = Z2 \u00b7 k + k\u2211 i=1 ln ( \u03b3i + JP \u2212 1 JP \u2212 1 ) \ufe38 \ufe37\ufe37 \ufe38\nPenalty Term\n+ k\u2211 i=1 ln\n( \u03b3i!\nnPi,1!n P i,2! \u00b7 \u00b7 \u00b7nPi,JP ! ) \ufe38 \ufe37\ufe37 \ufe38\nEdge Position Term\n, (19)\nwhere Z1 and Z2 are constant over discretizations, k is the number of discretization intervals, and I(A,B) = \u2211\na,b P\u0302 (a, b) ln P\u0302 (a,b)\nP\u0302 (a)P\u0302 (b) is the mutual information based on\nestimated probabilities. Note that the third term of fMDL had been approximated using H(p) (see Equation 18) in the original work by Friedman and Goldszmidt (1996), but it is written here without that approximation.\nThe penalty terms tend to increase with the number of discretization intervals; the edge position terms vary with the position and number of the discretization edges. A policy with a larger number of discretization edges is only optimal if the edge position term varies enough with respect to the penalty term in order to produce a local minimum of sufficiently low value.\nThe value of the edge position term for MDL is primarily determined by the mutual information, which varies less severely than the corresponding terms in the Bayesian method. The MDL term uses empirical probability distributions based off of ratios of counts, whereas the Bayesian method uses factorial terms, and thus the MDL method varies less. The MDL method is therefore less sensitive to the discretization edges. This sensitivity gives rise to the relative performance of the two methods in the experiments conducted above."}, {"heading": "7 Conclusion", "text": "This paper introduced a principled discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques. Empirical demonstrations show that the proposed method is superior to the state of the art. In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and\nsimultaneously learn Bayesian network structures. The proposed method was incorporated and its superior performance was empirically demonstrated. Future work will investigate edge positions at locations other than the midpoints between samples and will extend the approach to cluster categorical variables with very many levels. All software is publicly available at github.com/sisl/LearnDiscreteBayesNets.jl."}], "references": [{"title": "MODL: A Bayes optimal discretization method for continuous attributes", "author": ["Marc Boull\u00e9"], "venue": "Machine Learning,", "citeRegEx": "Boull\u00e9.,? \\Q2006\\E", "shortCiteRegEx": "Boull\u00e9.", "year": 2006}, {"title": "A Bayesian method for the induction of probabilistic networks from data", "author": ["Gregory F. Cooper", "Edward Herskovits"], "venue": "Machine Learning,", "citeRegEx": "Cooper and Herskovits.,? \\Q1992\\E", "shortCiteRegEx": "Cooper and Herskovits.", "year": 1992}, {"title": "Supervised and unsupervised discretization of continuous features", "author": ["J. Dougherty", "R. Kohavi", "M. Sahami"], "venue": "In International Conference on Machine Learning (ICML)", "citeRegEx": "Dougherty et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dougherty et al\\.", "year": 1995}, {"title": "SMILE: Structural modeling, inference, and learning engine and GeNIe: a development environment for graphical decision-theoretic models", "author": ["Marek J. Druzdzel"], "venue": "In National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Druzdzel.,? \\Q1999\\E", "shortCiteRegEx": "Druzdzel.", "year": 1999}, {"title": "Multi-interval discretization of continuous-valued attributes for classification learning", "author": ["U.M. Fayyad", "K.B. Irani"], "venue": "In International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Fayyad and Irani.,? \\Q1993\\E", "shortCiteRegEx": "Fayyad and Irani.", "year": 1993}, {"title": "Discretizing continuous attributes while learning Bayesian networks", "author": ["N. Friedman", "M. Goldszmidt"], "venue": "In International Conference on Machine Learning (ICML)", "citeRegEx": "Friedman and Goldszmidt.,? \\Q1996\\E", "shortCiteRegEx": "Friedman and Goldszmidt.", "year": 1996}, {"title": "Bayesian network classifiers", "author": ["N. Friedman", "D. Geiger", "M. Goldszmidt"], "venue": "Machine Learning,", "citeRegEx": "Friedman et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 1997}, {"title": "Minimum Description Length Principle", "author": ["P.D. Gr\u00fcnwald"], "venue": null, "citeRegEx": "Gr\u00fcnwald.,? \\Q2007\\E", "shortCiteRegEx": "Gr\u00fcnwald.", "year": 2007}, {"title": "Very simple classification rules perform well on most commonly used datasets", "author": ["R.C. Holte"], "venue": "Machine Learning,", "citeRegEx": "Holte.,? \\Q1993\\E", "shortCiteRegEx": "Holte.", "year": 1993}, {"title": "Nonparametric Bayesian network", "author": ["K. Ickstadt", "B. Bornkamp", "M. Grzegorczyk", "J. Wieczorek", "M.R. Sheriff", "H.E. Grecco", "E. Zamir"], "venue": "Bayesian Statistics,", "citeRegEx": "Ickstadt et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ickstadt et al\\.", "year": 2010}, {"title": "ChiMerge: Discretization of numeric attributes", "author": ["R. Kerber"], "venue": "In National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Kerber.,? \\Q1992\\E", "shortCiteRegEx": "Kerber.", "year": 1992}, {"title": "Airspace encounter models for estimating collision risk", "author": ["Mykel J. Kochenderfer", "Matthew W.M. Edwards", "Leo P. Espindle", "James K. Kuchar", "Daniel J. Griffith"], "venue": "AIAA Journal of Guidance, Control, and Dynamics,", "citeRegEx": "Kochenderfer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kochenderfer et al\\.", "year": 2010}, {"title": "Nextgeneration airborne collision avoidance system", "author": ["Mykel J. Kochenderfer", "Jessica E. Holland", "James P. Chryssanthacopoulos"], "venue": "Lincoln Laboratory Journal,", "citeRegEx": "Kochenderfer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kochenderfer et al\\.", "year": 2012}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "Koller and Friedman.,? \\Q2009\\E", "shortCiteRegEx": "Koller and Friedman.", "year": 2009}, {"title": "Nonuniform dynamic discretization in hybrid networks", "author": ["A.V. Kozlov", "D. Koller"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Kozlov and Koller.,? \\Q1997\\E", "shortCiteRegEx": "Kozlov and Koller.", "year": 1997}, {"title": "Application of an efficient Bayesian discretization method to biomedical data", "author": ["J.L. Lustgarten", "S. Visweswaran", "V. Gopalakrishnan", "G.F. Cooper"], "venue": "BMC Bioinformatics,", "citeRegEx": "Lustgarten et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lustgarten et al\\.", "year": 2011}, {"title": "A multivariate discretization method for learning Bayesian networks from mixed data", "author": ["S. Monti", "G.F. Cooper"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Monti and Cooper.,? \\Q1998\\E", "shortCiteRegEx": "Monti and Cooper.", "year": 1998}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": null, "citeRegEx": "Pearl.,? \\Q1988\\E", "shortCiteRegEx": "Pearl.", "year": 1988}, {"title": "Modeling by shortest data", "author": ["J. Rissanen"], "venue": "description. Automatica,", "citeRegEx": "Rissanen.,? \\Q1978\\E", "shortCiteRegEx": "Rissanen.", "year": 1978}, {"title": "Learning Bayesian networks with the bnlearn R package", "author": ["Marco Scutari"], "venue": "Journal of Statistical Software,", "citeRegEx": "Scutari.,? \\Q2010\\E", "shortCiteRegEx": "Scutari.", "year": 2010}, {"title": "Predictive discretization during model selection", "author": ["Harald Steck", "Tommi S Jaakkola"], "venue": "In Pattern Recognition,", "citeRegEx": "Steck and Jaakkola.,? \\Q2004\\E", "shortCiteRegEx": "Steck and Jaakkola.", "year": 2004}, {"title": "Minimum description length induction, Bayesianism, and Kolmogorov complexity", "author": ["Paul Vit\u00e1nyi", "Ming Li"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Vit\u00e1nyi and Li.,? \\Q2000\\E", "shortCiteRegEx": "Vit\u00e1nyi and Li.", "year": 2000}, {"title": "Correctness of belief propagation in gaussian graphical models of arbitrary topology", "author": ["Y. Weiss", "W.T. Freeman"], "venue": "Neural Computation,", "citeRegEx": "Weiss and Freeman.,? \\Q2001\\E", "shortCiteRegEx": "Weiss and Freeman.", "year": 2001}], "referenceMentions": [{"referenceID": 12, "context": "Bayesian networks (Pearl 1988; Koller and Friedman 2009) are often used to model uncertainty and causality, with applications ranging from decision-making systems (Kochenderfer et al. 2012) to medical diagnosis (Lustgarten et al.", "startOffset": 163, "endOffset": 189}, {"referenceID": 15, "context": "2012) to medical diagnosis (Lustgarten et al. 2011).", "startOffset": 27, "endOffset": 51}, {"referenceID": 11, "context": "However, many applications require the use of continuous variables, such as position and velocity in dynamic systems (Kochenderfer et al. 2010).", "startOffset": 117, "endOffset": 143}, {"referenceID": 9, "context": "The second approach is to use nonparametric distributions, such as particle representations and Gaussian processes (Ickstadt et al. 2010).", "startOffset": 115, "endOffset": 137}, {"referenceID": 2, "context": "Automated discretization methods have been studied in machine learning and statistics for many years (Dougherty et al. 1995; Kerber 1992; Holte 1993; Fayyad and Irani 1993), primarily for classification problems.", "startOffset": 101, "endOffset": 172}, {"referenceID": 6, "context": "Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks (Friedman et al. 1997), but only a few discretization methods for general Bayesian networks have been proposed (Friedman and Goldszmidt 1996; Kozlov and Koller 1997; Monti and Cooper 1998; Steck and Jaakkola 2004).", "startOffset": 111, "endOffset": 133}, {"referenceID": 2, "context": "Automated discretization methods have been studied in machine learning and statistics for many years (Dougherty et al. 1995; Kerber 1992; Holte 1993; Fayyad and Irani 1993), primarily for classification problems. These methods search for the best discretization policy for a continuous attribute by considering its interaction with a class variable. It is common to discretize all continuous variables before learning a Bayesian network structure to avoid having to consider variable interactions, as the interactions and dependencies between variables in Bayesian networks introduce complexity. Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks (Friedman et al. 1997), but only a few discretization methods for general Bayesian networks have been proposed (Friedman and Goldszmidt 1996; Kozlov and Koller 1997; Monti and Cooper 1998; Steck and Jaakkola 2004). A common discretization method for Bayesian networks is to split continuous variables into uniform-width intervals or by using field-specific expertise. A more principled method is the minimum description length (MDL) principle discretization (Friedman and Goldszmidt 1996). The MDL principle proposed by Rissanen (1978) states that the best model for a dataset is the one that minimizes the amount of information needed to describe it (Gr\u00fcnwald 2007).", "startOffset": 102, "endOffset": 1243}, {"referenceID": 2, "context": "Automated discretization methods have been studied in machine learning and statistics for many years (Dougherty et al. 1995; Kerber 1992; Holte 1993; Fayyad and Irani 1993), primarily for classification problems. These methods search for the best discretization policy for a continuous attribute by considering its interaction with a class variable. It is common to discretize all continuous variables before learning a Bayesian network structure to avoid having to consider variable interactions, as the interactions and dependencies between variables in Bayesian networks introduce complexity. Prior work exists for discretizing continuous variables in naive Bayesian networks and tree-augmented networks (Friedman et al. 1997), but only a few discretization methods for general Bayesian networks have been proposed (Friedman and Goldszmidt 1996; Kozlov and Koller 1997; Monti and Cooper 1998; Steck and Jaakkola 2004). A common discretization method for Bayesian networks is to split continuous variables into uniform-width intervals or by using field-specific expertise. A more principled method is the minimum description length (MDL) principle discretization (Friedman and Goldszmidt 1996). The MDL principle proposed by Rissanen (1978) states that the best model for a dataset is the one that minimizes the amount of information needed to describe it (Gr\u00fcnwald 2007). MDL methods trade off goodness-of-fit against model complexity to reduce generalization error. In the context of Bayesian networks, Friedman and Goldszmidt (1996) applied the MDL principle to determine the optimal number of discretization intervals for continuous variables and the optimal positions of their discretization edges.", "startOffset": 102, "endOffset": 1538}, {"referenceID": 0, "context": "MODL (Boull\u00e9 2006) is a Bayesian method for discretizing a continuous feature according to a class variable, which selects the model with maximum probability given the data. The MODL method uses dynamic programming to find the optimal discretization policy for a continuous variable given a discrete class variable, and has an O ( n3 + r \u00b7 n2 ) runtime, where r is the number of class variable instantiations. Lustgarten et al. (2011) suggest several formulations for the prior over models.", "startOffset": 6, "endOffset": 435}, {"referenceID": 0, "context": "MODL (Boull\u00e9 2006) is a Bayesian method for discretizing a continuous feature according to a class variable, which selects the model with maximum probability given the data. The MODL method uses dynamic programming to find the optimal discretization policy for a continuous variable given a discrete class variable, and has an O ( n3 + r \u00b7 n2 ) runtime, where r is the number of class variable instantiations. Lustgarten et al. (2011) suggest several formulations for the prior over models. The asymptotic equivalence between MDL and MODL on the single-variable, single-class problem was examined by Vit\u00e1nyi and Li (2000). This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from Boull\u00e9 (2006) and Lustgarten et al.", "startOffset": 6, "endOffset": 622}, {"referenceID": 0, "context": "MODL (Boull\u00e9 2006) is a Bayesian method for discretizing a continuous feature according to a class variable, which selects the model with maximum probability given the data. The MODL method uses dynamic programming to find the optimal discretization policy for a continuous variable given a discrete class variable, and has an O ( n3 + r \u00b7 n2 ) runtime, where r is the number of class variable instantiations. Lustgarten et al. (2011) suggest several formulations for the prior over models. The asymptotic equivalence between MDL and MODL on the single-variable, single-class problem was examined by Vit\u00e1nyi and Li (2000). This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from Boull\u00e9 (2006) and Lustgarten et al.", "startOffset": 6, "endOffset": 810}, {"referenceID": 0, "context": "MODL (Boull\u00e9 2006) is a Bayesian method for discretizing a continuous feature according to a class variable, which selects the model with maximum probability given the data. The MODL method uses dynamic programming to find the optimal discretization policy for a continuous variable given a discrete class variable, and has an O ( n3 + r \u00b7 n2 ) runtime, where r is the number of class variable instantiations. Lustgarten et al. (2011) suggest several formulations for the prior over models. The asymptotic equivalence between MDL and MODL on the single-variable, single-class problem was examined by Vit\u00e1nyi and Li (2000). This paper describes a new Bayesian discretization method for continuous variables in Bayesian networks, extending prior work on single-variable discretization methods from Boull\u00e9 (2006) and Lustgarten et al. (2011). The proposed method optimizes the discretization policy relative to the network and takes parents, children, and spouse variables into account.", "startOffset": 6, "endOffset": 839}, {"referenceID": 15, "context": "The four principles, which can be considered an extension of the priors in MODL and Lustgarten et al. (2011) to Bayesian networks, are:", "startOffset": 84, "endOffset": 109}, {"referenceID": 0, "context": "For faster methods with suboptimal results, see Boull\u00e9 (2006).", "startOffset": 48, "endOffset": 62}, {"referenceID": 5, "context": "For faster methods of MDL discretization with suboptimal results, see Friedman and Goldszmidt (1996). Note that the preliminary discretization and the discretization order of variables can be arbitrary for the MDL discretization method, as stated in the original work (Friedman and Goldszmidt 1996).", "startOffset": 70, "endOffset": 101}, {"referenceID": 5, "context": "Note that the third term of fMDL had been approximated using H(p) (see Equation 18) in the original work by Friedman and Goldszmidt (1996), but it is written here without that approximation.", "startOffset": 108, "endOffset": 139}], "year": 2015, "abstractText": "Real data often contains a mixture of discrete and continuous variables, but many Bayesian network structure learning and inference algorithms assume all random variables are discrete. Continuous variables are often discretized, but the choice of discretization policy has significant impact on the accuracy, speed, and interpretability of the resulting models. This paper introduces a principled Bayesian discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques. Empirical demonstrations show that the proposed method is superior to the state of the art. In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.", "creator": "TeX"}}}