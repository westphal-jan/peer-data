{"id": "1601.04038", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jan-2016", "title": "It's about time: Online Macrotask Sequencing in Expert Crowdsourcing", "abstract": "we introduce the problem of task assignment and sequencing ( replacing tas ), which adds thus the timeline perspective to expert crowdsourcing optimization. expert crowdsourcing involves macrotasks, like analog document writing, product design, or web development, which take more time than typical binary microtasks, require expert skills, assume varying degrees of knowledge over a topic, and require crowd workers to build on each other's contributions. current works only usually assume offline optimization models, which consider worker and task arrivals known and don't take into account the element of time. realistically however, time is critical : tasks have deadlines, expert workers are available only at specific time slots, and worker / task arrivals are definitely not known a - priori. our futures work method is the first to address the problem of optimal task sequencing for online, heterogeneous, time - constrained macrotasks. we propose tas - online, an online algorithm that aims to complete as countless many tasks as possible within budget, required quality and a given timeline, without future input information regarding job release dates or worker availabilities. results, comparing tas - based online to four typical benchmarks, show that it achieves more completed jobs, lower flow times and higher job quality. this work has practical implications for improving the quality of service of current crowdsourcing platforms, allowing them to properly offer cost, quality and time improvements for expert tasks.", "histories": [["v1", "Fri, 15 Jan 2016 19:26:04 GMT  (2309kb,D)", "http://arxiv.org/abs/1601.04038v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.AI", "authors": ["heinz schmitz", "ioanna lykourentzou"], "accepted": false, "id": "1601.04038"}, "pdf": {"name": "1601.04038.pdf", "metadata": {"source": "CRF", "title": "It\u2019s about time: Online Macrotask Sequencing in Expert Crowdsourcing", "authors": ["Heinz Schmitz", "Ioanna Lykourentzou"], "emails": ["h.schmitz@hochschule-trier.de", "ioanna.lykourentzou@list.lu"], "sections": [{"heading": null, "text": "We introduce the problem of Task Assignment and Sequencing (TAS), which adds the timeline perspective to expert crowdsourcing optimization. Expert crowdsourcing involves macrotasks, like document writing, product design, or web development, which take more time than typical binary microtasks, require expert skills, assume varying degrees of knowledge over a topic, and require crowd workers to build on each other\u2019s contributions. Current works usually assume offline optimization models, which consider worker and task arrivals known and do not take into account the element of time. Realistically however, time is critical: tasks have deadlines, expert workers are available only at specific time slots, and worker/task arrivals are not known a-priori. Our work is the first to address the problem of optimal task sequencing for online, heterogeneous, time-constrained macrotasks. We propose tas-online, an online algorithm that aims to complete as many tasks as possible within budget, required quality and a given timeline, without future input information regarding job release dates or worker avail-\nabilities. Results, comparing tas-online to four typical benchmarks, show that it achieves more completed jobs, lower flow times and higher job quality. This work has practical implications for improving the Quality of Service of current crowdsourcing platforms, allowing them to offer cost, quality and time improvements for expert tasks."}, {"heading": "1 Introduction", "text": "As the appeal of crowd work increases, there is a growing need to provide support for more complex tasks and workflows. Examples of such tasks include document editing, product design, social innovation and idea development, offered through dedicated platforms (upWorks1, crowdSpring2 etc.), or incorporated into traditional ones through complex workflows (e.g. the recently launched CrowdFlower Labs3). This type of crowdsourcing is often referred to as expert crowdsourcing, and the tasks that it involves are referred to as macrotasks [15]. Macrotasks differ from the typically crowdsourced micro-\n1https://www.upwork.com/ 2http://www.crowdspring.com/ 3http://www.crowdflower.com/blog/introducing-\ncrowdflower-labs\nar X\niv :1\n60 1.\n04 03\n8v 1\n[ cs\n.S I]\ntasks in that they require expert skills, assume varying degrees of knowledge over a topic, may take more worker time and often involve task dependency, i.e. workers building on each other\u2019s contributions.\nTogether with the demand for complex tasks and their supporting workflows, customers are increasingly interested in performance guarantees, i.e. the optimization of expert crowdsourcing in terms of cost, quality and timeliness. Recent studies that examine expert crowdsourcing optimization [2, 14] typically seek to find worker assignments per task such that the worker contributions add up to a required quality threshold within a given budget. Roughly speaking, the crowdsourced tasks play the roles of multiple knapsacks with some additional concepts like domain-specific expertise and wages per worker, different models of acceptance probabilities or types of quality aggregation. Unfortunately current studies do not take into account the aspect of time, for example in terms of task deadlines, worker time constraints, or time-dependent worker/task variability. As such these studies examine only the assignment part of the worker allocation problem (finding which worker should take which task), but not the sequencing part (identifying when each worker should contribute). Moreover they usually assume an offline setting, where the algorithms are provided with the complete worker/task input information at once. In a realistic crowdsourcing setting however, time is an inherent property : customers require the tasks to finish upon a certain deadline, expert workers are available only at specific time slots, and worker/task arrival or departure information is not a-priori known. Optimizing for time is thus crucial, and raises the need not only for worker-to-task assignment but also for sequencing. It also raises the need for online rather than index-based algorithms, which can take efficient sequencing decisions having access only to timedependent information that is available until their decision point.\nIn this paper we introduce the problem of crowdsourcing Task Assignment and Sequencing (TAS), which adds the timeline perspective to the crowdsourcing allocation optimization model: How can we find task assignments that can be rolled out in a realistic timeline, featuring unknown task release dates\nand worker availabilities, as it is the case for real platforms?\nTo the best of our knowledge, this is the first work that addresses the problem of assignment and sequencing optimization for expert crowdsourcing tasks. Overall, our three main contributions with this paper are:\n\u2022 We explicitly add the timeline perspective to task assignment modeling in expert crowdsourcing. That is, our models include not only the workerto-task-assignments, but also the rolling out of these assignments along a timeline under reasonable constraints. We call this problem modeling TAS and prove its strong NP hardness.\n\u2022 We propose a online algorithm, tas-online, which seeks to complete as many jobs as possible within budget, required quality and given timeline, by computing worker sequence-to-task matchings, and without any future input information regarding job release dates or worker availabilities.\n\u2022 We illustrate, through simulated and real-world experiments, that tas-online can achieve more completed jobs, lower flow times and higher quality compared to four typical benchmarks.\nThe rest of this paper is organized as follows. In section 2 we recapitulate the related literature on crowdsourcing optimization, starting from earlier works that focus on micro-tasks and reaching latest research efforts on knowledge-intensive macro-tasks. In section 3 we describe the characteristics of the expert crowdsourcing setting that this work applies and illustrate, through an example, why taking time into account matters in this particular setting. In this section we also formally model the TAS problem and prove its strong NP-hardness. Next, in section 4 we describe the proposed online algorithm (tas-online) for the solution of the TAS problem. In section 5, we present and discuss the experimental results, obtained on both simulated and real-world data. These results compare tas-online with four benchmarks found in the literature, and show that tas-online achieves higher numbers of completed jobs (both in\nterms of absolute value and as a percentage of the solution\u2019s upper bound), lower flow times (the time between a job\u2019s release date and the latest assignment on that job), better budget utilization and higher levels of quality, comparable only the respective tasoffline version for certain of the above measures. Finally, we discuss possible extensions of the TAS model and algorithm (section 6) and end with the paper\u2019s main findings and conclusions (section 7)."}, {"heading": "2 Related Work", "text": ""}, {"heading": "2.1 Crowdsourcing Optimization", "text": "Crowdsourcing optimization is a term used in various problem settings, including optimizing the selection of worker labor channels to improve performance [22], discovering the optimal worker wage [17], determining the optimal number of workers to undertake each task so as to maximize quality and minimize cost (a method referred to as \u201cplurality optimization\u201d and applicable on n-ary tasks with an objective \u201ctrue value\u201d) [34], or identifying the optimal set of tasks to forward to the crowd (for systems like database query execution ones, which are based partially on crowdsourcing and partially on automated methods) [12].\nThe family of optimization problems that our work falls into is allocation optimization, i.e. the identification of which worker should work on which task and when, in order to optimize one or more global performance metrics, which usually include cost, quality and number of acceptable tasks. This family of problems consists of two distinct optimization problems, task assignment and task sequencing. Task assignment examines which worker should be given which task. Task sequencing adds the element of time, examining when will the worker be given the task. Most existing works focus on the first problem, i.e. task assignment, either for microtasks or for macrotasks. Microtasks are tasks that require a small amount of worker time, accept binary (true/false) or n-ary (multiple choice) worker inputs, and the quality of which is determined through methods such as majority voting (assigning multiple workers per microtask). Macrotasks [15] require more worker time, accept open-ended continuous (rather than binary or\nn-ary) worker inputs and their quality is determined through external subjective evaluation (for example peer review)."}, {"heading": "2.2 Optimizing Task Assignments", "text": "Regarding microtask assignment optimization, Karger et al. [23] work with homogeneous microtasks (that all have the same level of difficulty and do no distinguish among task \u201ctopics\u201d), and propose a matching algorithm inspired by the standard belief propagation algorithm for approximating max marginals, which is order-optimal and minimizes cost. This study is among the first to show that the problem of task matching in crowdsourcing can be transformed to a bipartite graph design problem, where workers are one part of the graph, tasks are the other and the edges represent assignments of workers to tasks. Ho et al. [16] work with heterogeneous microtasks of n-ary classification quality on a model where worker skills per microtask are a-priori unknown, and propose a two phase exploration-exploitation assignment algorithm that seeks to maximize the total benefit of the requester and is competitive with respect to its counterpart of known worker skills. Yuen et al. [43, 44, 42] propose a matrix factorization approach that utilizes the workers\u2019 task performance and search history to derive their preferences and perform an improved task-to-worker matching. Regarding macrotask assignment optimization Goel et al. [14] and Roy et al. [2, 39] both propose task-to-worker assignment optimizations (the first using a mechanism design-based approach and the second through an index-based approach) on models that consider heterogeneous macrotasks and where the optimization goal is to maximize the utility of the requester while ensuring budget feasibility. Yue et al. [41] add to this model the element of team instead of individual worker assignments, and propose a heuristic genetic algorithm that optimizes for task budget and quality, taking into account worker pay expectations, skills and availability. Jabbari et al. [20] add another interesting facet to the heterogeneous task assignment model, by extending it to cover the online aspect of the problem (workers arrive online, no\nprior knowledge over arrivals), and they impose certain constraints that must be respected, such as declaring feasible tasks that workers can handle and the payment they require. The difference of the above works with ours is that their models do not consider the element of time, i.e., they focus only on the task assignment and not the task sequencing aspect of the problem."}, {"heading": "2.3 Optimizing Task Timing", "text": "Finally, a few studies focus precisely on time-sensitive optimization. Regarding time-sensitive microtasks, Yu et al. [40] optimize the number of tasks to recommend to each worker per time unit with the objective of maximizing the time average number of successful (i.e. of acceptable quality) jobs for a given time period. Their model assumes binary task quality, a pull-and-filter task selection model (workers select which tasks they want to work on and the system filters these selections according to its optimization objective) and performs task allocation on the basis of worker accuracy measured in a [0,1] scale using a heuristic algorithm of linearithmic complexity. Although this study does incorporate the element of time, it is different than ours in that the model it uses assumes binary, homogeneous tasks rather than heterogeneous tasks of continuous quality. The use of homogeneous tasks (all tasks have the same difficulty, no distinction of task topics) means that optimization needs to be performed in terms of the number of jobs per worker, rather in terms of allocating specific workers to specific jobs according to their skills. Bernstein et al. [4, 3] also work with homogeneous microtasks and propose a retainer model for pre-recruiting (reserving) the optimal number of workers, so as to minimize task completion latency. This work however does not take into account worker skills and subsequently does not seek to maximize task quality. On heterogeneous microtasks, Faridani et al. [13] and Minder et al. [33] add the element of pricing to the problem model, proposing task pricing algorithms that aim to maximize the number of tasks finishing on time (the first study), while respecting budget and quality constraints (the second study). Mechanism design [35, 36] and multi-armed bandit\nmechanism design [5] mechanisms have also been employed to manipulate the time behavior of the crowd towards an efficient execution of time-critical tasks. The above works are different from our work, in that they do not explicitly sequence the tasks to the workers but they rather seek to incentivize the crowd\u2019s timely responses in order to achieve the time-related task objective.\nIn regards to time-sensitive macrotasks Khazankin et al. [26] propose a mathematical optimization approach that learns the task selection behavior of workers and then executes tasks in a manner that optimizes for cost and considers deadlines. This approach does not consider task quality, yet it is one of the first attempts to sequence time-sensitive macrotasks. Finally, Boutsis and Kalogeraki [7] propose an multi-objective optimization approach which searches for Pareto-optimal solutions, seeking to identify the group of workers (among multiple candidate groups) with the highest probability of finishing the task on time. This approach is different than ours, in that it does not apply sequencing along a timeline, but rather makes one-shot assignments based on the worker probabilities of meeting the deadline.\nOverall, crowdsourcing optimization studies have so far examined mainly the assignment but not the sequencing aspect of the problem. The works that optimize for time-sensitive task characteristics are few and they either focus on binary/n-ary microtasks (which differ significantly from the expert macrotasks that we are interested in) or they do not sequence the worker-to-task assignments along a timeline. We address in our work the problem of optimal task sequencing for online, heterogeneous, time-constrained, macrotasks. As we will see in the following section, it is this type of tasks that expert crowsourcing consists of, and thus their optimization has significant impact on many recent platforms and applications.\n3 Task Assignment and Sequencing (TAS)\nIn this section we first describe, from a high-level viewpoint, the expert crowdsourcing task model which we target through this work. Then we provide an example to illustrate the importance of adding the timeline sequencing element into the above setting. Next we define the TAS problem model, in terms of the input data, feasible solutions, constraints and optimization goal. Finally we analyze this problem model in terms of complexity."}, {"heading": "3.1 Expert Crowdsourcing Setting", "text": "The expert crowdsourcing problem setting, at which this work is aimed, features some very particular characteristics that make it unique compared to other crowdsourcing problem settings:\n1. Heterogeneous rather than homogeneous tasks. We work with crowdsourcing tasks that require different skills and skill levels from the workers, and that belong to multiple \u201ctopics\u201d (rather than a single one). Workers in this setting possess a set of skills, and are less replaceable and less abundant than crowdsourcing settings that consider homogeneous tasks and skills (everyone can do every task).\n2. Macro- rather than microtasks. Whereas microtasks accept binary or n-ary (multiple choice) worker input, and their quality is defined by assigning multiple simultaneous workers on the task and then performing majority voting, macrotasks feature open-ended worker input (e.g. write a product description), and their quality is built by one worker contribution after the other (sequentially rather than simultaneously).\n3. Online rather than offline. Rather than working on a simplified offline setting, where the pool of workers and/or tasks are a-priori known, we consider an online setting, where workers demonstrate a dynamic flow of arrivals and departures and tasks arrive in an unpredictable\nmanner. Any sequencing decision must be made based on task/worker information available up to the specific point in time.\n4. Time-constrained rather than only cost/quality-constrained tasks. In addition to the need of achieving a certain utility metric (e.g. quality, number of acceptable tasks etc.) and the need to keep costs within budget, the online macrotasks of this setting have a deadline, i.e., they must also finish by a specific time point.\nApplication areas. Many tasks and platforms, especially recent ones, fit the above expert crowdsourcing setting and could benefit from its optimization. The first example are platforms such as upWork4 that work with freelancer experts on creative tasks such as web design and development, document writing, or coding. Social innovation platforms such as OpenIDEO5 or creative product design platforms like Quirky6, where users build on one another\u2019s ideas, could also directly benefit from the optimization of the above setting. Finally collaborative document editing applications, such as corporate wikis [29], where it is possible to sequence worker contributions along a timeline could significantly improve from our approach."}, {"heading": "3.2 The importance of the time element", "text": "Before giving the formal definition of the TAS optimization problem, we illustrate through an example the importance of adding the perspective of time, and how this addition has a significant on performance in expert crowdsourcing.\nExample. Suppose there are only two jobs given, both from the same knowledge domain. Each job j = (Q,C) has a quality threshold Q that needs to be reached, and a cost threshold C that must not be\n4https://www.upwork.com/ 5https://openideo.com/ 6https://www.quirky.com/\nexceeded. For this example suppose\nj0 = (5, 5) and j1 = (4, 4).\nOn the other hand, each worker i = (e, w) has an expertise e that increases the quality of a job, and a wage w that consumes this job\u2019s budget. Let us assume that three workers\ni0 = (2, 3), i1 = (3, 2) and i3 = (2, 1)\nare given. Then each job has two possible assignments within budget and with sufficient quality:\nj0 : {i0, i1} or {i1, i2} j1 : {i0, i2} or {i1, i2}\nFor both jobs the latter assignment seems to be preferable over the other since workers {i1, i2} provide more quality for less cost. Now we look at a sequencing period of three timeslots with limited worker availability as follows (both jobs are released immediately):\ntimeslot 0 1 2 i0 \u00d7 i1 \u00d7 i2 \u00d7 \u00d7\nSince worker i1 is available only at a single timeslot it is clear that at most one job can realize the preferable assignment mentioned above. So assume for the moment that we choose modestly j0 \u2190 {i0, i1} for j0. This gives us the following partial schedule for the workers:\ntimeslot 0 1 2 i0 j0 i1 j0 i2 \u00d7 \u00d7\nBut now none of the two feasible assignments for j1 can be realized since only worker i2 remains available. Although the assignment j1 \u2190 {i2} is within budget, it does not reach the needed quality, and j1 remains incomplete in this case.\nSo let us choose the alternative assignment j0 \u2190 {i1, i2} and set i2 on j0 at timeslot 0:\ntimeslot 0 1 2 i0 \u00d7 i1 j0 i2 j0 \u00d7\nNow j1 cannot be completed without violating the sequential working assumption w.r.t. this job. On the other hand, if we set i2 on j0 at timeslot 2, we can complete both jobs with the schedule\ntimeslot 0 1 2 i0 j1 i1 j0 i2 j1 j0\nwithout violating any constraints. To complete the discussion, note that if we choose j1 \u2190 {i1, i2} in the beginning, then j0 cannot be completed no matter what timeslot is used for i2 (end of example).\nThe example shows that not only the choice of an optimal worker-task assignment without consideration of time may be misleading, but also that the specific selection of timeslots is important.\n3.3 The TAS Problem Model\nWith the following definition we want to capture the interplay between task assignment and timeline sequencing within the same model, and add appropriate constraints. We refer to our problem description as task assignment and sequencing (TAS) in expert crowdsourcing."}, {"heading": "3.3.1 Input Data", "text": "Scheduling period. Suppose we look at t timeslots [t] = {0, 1, . . . , t \u2212 1}. Each timeslot d \u2208 [t] is also called a day but can be any fixed period of time.\nKnowledge domains. A finite set K of knowledge domains. Each k \u2208 K represents an area of knowledge or a knowledge topic.\nWorkers. A finite set U of users, hereby refered to as workers, participating in the crowdsourcing platform. Each worker i \u2208 U has the following characteristics7:\n7Note that in the context of this work the quantification of worker expertise, wage or speed are considered orthogonal\n\u2022 Expertise. An expertise vector ei of dimension |K|. The expertise eik of a worker denotes the added quality that the worker can bring to a job belonging to domain k.\n\u2022 Wage. A cost vector wi of dimension |K|. The amount wik is the monetary renumeration that the worker demands in order to perform a job belonging to domain k.\n\u2022 Availability. An availability vector ai of dimension t with entries aid = 1 if worker i is available on day d, and aid = 0 otherwise.\nJobs. A finite set J of knowledge-intensive jobs that are crowdsourced. A job j is assumed to have the following characteristics:\n\u2022 Domain. Each job belongs to exactly one domain kj \u2208 K.\n\u2022 Quality threshold. The amount Qj is the minimum quality that the job needs to achieve.\n\u2022 Cost threshold. The budget for job j is given by Cj as the maximum total amount of money that can be paid for the job.\n\u2022 Release date. Each job has a release date rj \u2208 [t] which means that job j enters the crowd system at timeslot rj (and never leaves the system).\nSequentiality. Finally our model assumes a sequential work mode along the timeline, according to which workers build on one another\u2019s contributions, at most one worker can be assigned to a task simultaneously, and each worker contributes at most to a single task at a time. Sequentiality is chosen for three reasons. First it is often imposed by the nature of expert crowdsourcing macrotasks, which are not easily decomposable to microtask level and as such they do not allow multiple simultaneous worker contributions (e.g. writing a document cannot be done by decomposing it to sentence level). Second, sequentiality allows building on the task\u2019s quality while not necessitating worker concurrency, which in practice is more\nto the studied assignment and sequencing problem. The interested reader is referred to [29, 8, 19] for available worker profile quantification techniques based on machine-learning, implicit evaluation or information theory.\ndifficult to achieve when specific worker skills (i.e. experts on a topic) are required. Third, sequentiality allows a more realistic coupling of our approach with worker skill evaluation mechanisms, making it easier to accurately evaluate the quality that each worker has brought once she has finished working on a task. Nevertheless, as also discussed in section 6 an extension of our model to include worker concurrency is feasible and we aim to examine it as part of our future work."}, {"heading": "3.3.2 Feasible Solutions, Constraints and Optimization Goal", "text": "A schedule needs to carry information about the resource allocation for each job in terms of workers and in terms of time: When does what worker contribute to which job?\nSolutions. In a solution for input data x = (t,K,U, J) we have for each job j \u2208 J a vector Uj of dimension t with entries from U \u222a{none}. If Ujd = i then worker i is assigned to job j and scheduled on day d, and if Ujd = none then there is no worker assignment for job j on day d.\nNote that we represent solutions hereby as job/timeslot-schedules with worker entries, whereas in the previous example we utilized an equivalent worker/timeslot-representation with job entries. So the successful schedule from the example in the present notation is\nU0 = (none, i1, i2)\nU1 = (i2, none, i0)\nConstraints. A solution is called feasible if and only if the following holds:\n(a) No worker is assigned to more than one job at a time, i.e., for all d \u2208 [t] and distinct j, j\u2032 \u2208 J it holds that Ujd 6= Uj\u2032d (unless both values are none).\n(b) No job is assigned to more than one worker at a time, i.e., for all j \u2208 J and d \u2208 [t] there is at most one worker stored in Ujd. This is ensured by the representation of Uj .\n(c) No worker is assigned more than once to the same job, i.e., for all j \u2208 J and distinct d, d\u2032 \u2208 [t] it holds that Ujd 6= Ujd\u2032 (unless both values are none).\n(d) No worker is scheduled on a day where she is not available, i.e., for all d \u2208 [t] and j \u2208 J it holds that if Ujd = i then aid = 1.\n(e) No job is worked on before its release date, i.e., for all j \u2208 J and d < rj it holds that Ujd = none.\n(f) No job exceeds its budget, i.e., for all j \u2208 J it holds that cj \u2264 Cj where cj is the cost of job j defined as cj = \u2211 i\u2208Uj wik if j has domain k.\nNote that there always exists a trivial feasible solution with Ujd = none for all j, d.\nObjective. In order to assess the quality of a feasible solution y = {j 7\u2192 Uj | j \u2208 J} we determine for each j with domain k the quality of job j w.r.t. this solution as qj = \u2211 i\u2208Uj eik. Note that in the context of this work we define task quality as the sum of expertises of the workers that participate in it, using the additive skill aggregation model that is often used for expert sequential macrotasks such as document editing [1, 31]. Other aggregation functions, including minimum, maximum or product [1] could also be used to compute a task\u2019s quality, however their full examination is out of the scope of this work.\nNow we set the measure for input x = (t,K,U, J) and solution y to\nm(x, y) = |{j \u2208 J | qj \u2265 Qj}|\nwhich we want to maximize. Therefore we count the number of jobs that reach their quality threshold within budget and that can be scheduled in a feasible way w.r.t. constraints (a) to (f). We call such jobs completed."}, {"heading": "3.4 TAS: An allocation problem with two aspects", "text": "The TAS optimization problem combines aspects of two well-studied problems of different nature, reflecting resource allocation of workers on one hand, and allocation of timeslots on the other."}, {"heading": "3.4.1 Allocation of Workers: The Multiple Knapsack perspective", "text": "If we look only at worker allocation in our model, we can understand each job j of domain k with budget Cj as a knapsack of this size that we need to fill with worker\u2019s expertises eik. Since the worker availabilities restrict the number of times a single worker can be packed, we have a bounded version of the multiple knapsack problem [25]. The difference to this classical problem is the optimization goal. While in TAS we want to maximize the number of completed jobs with respect to their individual quality thresholds Qj , the goal in multiple knapsack is to maximize the sum of all packed expertises, no matter how these spread over the different knapsacks."}, {"heading": "3.4.2 Allocation of time slots: The Openshop perspective", "text": "On the other hand, let us suppose a worker-taskassignment is already fixed such that all jobs reach their quality thresholds, and we need to schedule the selected workers along the timeline with respect to job releases and worker availabilities. Then we can understand this partial problem as a machinescheduling problem: Here workers play the role of machines and jobs need to be processes on these machines. Observe that the order of processing is immaterial in our model, that we demand sequentiality, and that the processing time of a job on a certain machine is either 0 or 1 per timeslot (depending on whether the respecting worker is assigned to this job or not). So this aspect of TAS is a unittime openshop problem with limited machine-availability and job release-dates [27]. Note that the adoption of a model also implies non-preemption, i.e. a worker cannot be interrupted once he/she has started working on a task. The goal of maximizing the number of completed jobs translates to minimizing the number of late jobs if we set t as the gobal deadline. We also want to mention that the sequencing of an already fixed worker-task-assignment can be reduced to the bipartite list edge-coloring problem [11]. Here jobs and workers form a bipartite graph with the worker-task-assignments as it\u2019s edges, and timeslots\nare represented by colors. Then we assign a list of colors to each edge (j, i) such that worker i is available on these timeslots and job j is already released. A proper coloring of all edges can be found if and only if the previously fixed worker-task-assignment can be sequenced on the timeline."}, {"heading": "3.4.3 TAS Complexity", "text": "Both aspects of TAS that we have pointed out above are NP-hard on their own, so is TAS as we show below. For an upper complexity bound note that the length of TAS-solutions is polynomially bounded in the input length and that the constraints can be checked in polynomial time if a solution is given, so TAS is an NP-optimization problem. Moreover, we observe that TAS is a large number problem, since it has knapsack as a subproblem (if there is only a single job and each worker is available on a different single day). So it is reasonable to consider strong NP-hardness.\nTheorem 1. TAS is a strongly NP-hard optimization problem.\nProof. We show NP-hardness with a polynomial-time many-one reduction from the NP-complete problem 3-Dimensional Matching [24]. For finite, disjoint sets X, Y and Z we say that M \u2286 X \u00d7 Y \u00d7 Z is a 3-dimensional matching if for all distinct triples (x1, y1, z1), (x2, y2, z2) \u2208M it holds that x1 6= x2, y1 6= y2 and z1 6= z2. It is known that 3-Dimensional Matching is NP-complete even in the special case when |X| = |Y | = |Z| = u and M has to be a perfect matching with |M | = u.\n3-Dimensional Matching (3-DM) Input: Finite and disjoint sets X,Y, Z with\n|X| = |Y | = |Z| and a subset W \u2286 X \u00d7 Y \u00d7 Z.\nQuestion: Is there a perfect 3-dimensional matching M \u2286W ?\nSuppose an instance of 3-DM is given with X = {xi | i \u2208 [u]}, Y = {yi | i \u2208 [u]}, Z = {zi | i \u2208 [u]} for some u \u2265 1 and W \u2286 X \u00d7 Y \u00d7 Z. The idea is to use constraint (a) (no worker is assigned to more that one job at a time) to achieve the needed matching condition. We take elements from X (Y , Z) as workers\navailable on day 0 (1, 2, resp.) and use domains to fix the given triples from W . More precisely, we define a corresponding TAS-instance (t,K,U, J) as follows:\n\u2022 The scheduling period has t = 3 timeslots.\n\u2022 There are |W | many different domains in K.\n\u2022 Each triple w \u2208W is encoded as a job jw, and all jobs have pairwise different domains. For all jobs jw we set quality and cost threshold to Qjw = Cjw = 3 and release date to rjw = 0.\n\u2022 Workers are defined as U = X \u222a Y \u222a Z. For x \u2208 X, y \u2208 Y and z \u2208 Z we set the availability to ax = (1, 0, 0), ay = (0, 1, 0) and az = (0, 0, 1), respectively. To fix expertise and wage, we consider each triple w = (x, y, z) \u2208 W and the corresponding job jw. If jw has domain k then we define exk = eyk = ezk = 1 and wxk = wyk = wzk = 1. All entries in expertise and wage vectors that are not addressed hereby are set to 0.\nFirst observe that a job jw with w = (x, y, z) reaches it\u2019s quality threshold if and only if we assign workers {x, y, z} to this job, since exactly these workers contribute to the job\u2019s domain.\nNow we argue that the given 3-DM instance has a perfect matching M if and only if the constructed TAS instance has a feasible solution with |M | = u completed jobs. If M \u2286 W is a 3-dimensional matching, then we consider the TAS-solution Ujw = (x, y, z) for all w = (x, y, z) \u2208 M . Since M is a matching all distinct solution vectors differ in all components, so constraint (a) is satisfied. All other constraints are easy to check, just note that each worker is available only on a single day, that all jobs are immediately released and that no job can exceed the budget. All jobs in this solution are completed due to our previous observation.\nConversely, note that if there is a feasible TASsolution with completed jobs jw and w = (x, y, z), then it must be that Ujw = (x, y, z). Since constraint (a) holds, the solution vectors for any two distinct jobs differ in all components. So M = {(x, y, z) | Ujw = (x, y, z) and jw completed} is a 3- dimensional matching and |M | = u.\nThe reduction function maps only to TASinstances where all integer values are polynomially bounded in the input length, so strong NP-hardness follows.\nThis rules out the possibility of pseudo-polynomial algorithms and the existence of fully polynomialtime approximation schemes for TAS unless P equals NP. Furthermore note that the reduction emphasizes the aspect of timeline sequencing, since workertask-assignments in the constructed TAS-instance are trivial (there is exactly one feasible workerassignment possible to reach the quality threshold of each job)."}, {"heading": "4 An Online Algorithm for", "text": "TAS\nDue to the dynamic nature of crowdsourcing systems, it seems not realistic to consider TAS as an offline problem where algorithms are provided with the complete input at once. In fact, worker availabilities are hardly predictable and it is usually not known in advance which jobs will enter the system at what time. So the problem of task assignment and sequencing is inherently online in nature and sequencing decisions have to be taken without complete information about the input data. We say that an algorithm for TAS has the online property, if it processes the input in a serial way w.r.t. the timeline d = 0, 1, . . . and in each step d the algorithm has to take its assignment decisions while having access only to the time-dependent information of the input for timeslots \u2264 d. These are the worker availabilities and the jobs released up to day d. For more background on the general concept of online algorithms we refer to [6].\nTo design such an algorithm we start with the following observation: Suppose a feasible solution y for TAS is given. If we look at a single day d in this solution then the assignments of workers to jobs for that day form a bipartite matching between the (uncompleted) jobs with (remaining) quality needs and budget on one hand, and the set of available workers for that day on the other hand. Constraints (a) and (b) form exactly this bipartite matching condition.\nSo conversely, if we proceed day by day with our online algorithm, we can try to compute a matching between the active (= released but incomplete) jobs J \u2032 in the system on that day, and the available workers U \u2032 for that day. Note that due to this choice of J \u2032 and U \u2032 we also immediately satisfy constraints (d) and (e). It remains to consider constraints (c) (no worker assignment to the same job twice) and (f) (no job exceeds it\u2019s budget). Both can be taken care of when we construct the edges of possible assignments in the bipartite graph between J \u2032 and U \u2032: If the remaining budget for a job is smaller than the wage of a worker in this domain, then the edge is omitted. The same is true if the worker has already been assigned to this job in the past. Both conditions can be checked when looking at the partial solution for timeslots < d. Together, this online procedure results in a series of matchings Md for d = 0, 1, . . . , t\u22121 that form a feasible solution y for TAS.\nMore than that, we want to choose a sequence of matchings that yields a large number of completed jobs. Among all possible matchings for each day d, which is the right one? We propose a greedy approach and compute in each step a matching, such that the sum of profits we get from the respective assignments for that day is maximized. More precisely, we construct for each day a weighted bipartite graph where each possible assignment (edge) claims a certain profit. In our algorithm, the profit is just the amount of expertise per wage unit (efficiency). The problem max weighted bipartite matching can be solved to optimality by known algorithms in polynomial time, e.g. if we apply the Hungarian Method this step has a running time proportional to O((|J \u2032| + |U \u2032|)2|E|) [28]. So we obtain the following online Algorithm 1 for TAS with polynomial running time O(t|J |3|U |3).\nThis algorithm can be viewed as an online schema that allows multiple extension, which we discuss in the last section after some experimental evaluation using the present basic version.\nAlgorithm 1 tas-online\nInput: A TAS-instance x = (t,K,U, J) Output: A feasible solution y for x.\n1: Set Ujd = none for all j \u2208 J and d \u2208 [t]. 2: for d = 0, 1, . . . , t\u2212 1 do . proceed day-by-day 3: J \u2032 = uncompleted jobs with rj \u2264 d . active jobs 4: U \u2032 = workers available on day d . active workers 5: E = \u2205 . edge set in bip. graph 6: for (j, i) \u2208 J \u2032 \u00d7 U \u2032 do 7: if i \u2208 Uj then pass . ensures (c) 8: if eikj == 0 then pass\n. i has no expertise in j\u2019s domain\n9: if wikj > Cj \u2212 cj then pass . ensures (f) 10: profit \u2190 eikj/wikj 11: E \u2190 (j, i, profit) 12: Md \u2190 MaxWeightedMatching(J \u2032, U \u2032, E) 13: for (j, i) \u2208Md do 14: Ujd = i . worker-task-assignment 15: return {j 7\u2192 Uj | j \u2208 J}"}, {"heading": "5 Experimental Evaluation", "text": "With the hardness result we have already seen that TAS has the KNAPSACK decision problem as a subproblem. It is known from literature that no competitive algorithm for the online version of KNAPSACK exists where items arrive one at a time [32]. An online algorithm is called competive if the ratio of it\u2019s performance and an optimal offline algorithm\u2019s performance can be bounded, a usual performance measure for online algorithms [6]. It follows that no competitive online algorithm for TAS exists as well. Therefore, in order to evaluate tas-online experimentally, we formulate alternative algorithms to compare with."}, {"heading": "5.1 Experimental Setup", "text": ""}, {"heading": "5.1.1 Benchmarks", "text": "We evaluate the performance of tas-online using four benchmarks, with each benchmark extending the previous with a new functionality. The first version of the algorithm (random) builds a feasible solution randomly and without any individual preferences of workers that usually appear in a fully self-organized system. We simply iterate over the available workers and pick a feasible job.\nAlgorithm 2 random\nInput: A TAS-instance x = (t,K,U, J) Output: A feasible solution y for x.\n1: Set Ujd = none for all j \u2208 J and d \u2208 [t]. 2: for d = 0, 1, . . . , t\u2212 1 do . proceed day-by-day 3: J \u2032 = uncompleted jobs with rj \u2264 d . active jobs 4: U \u2032 = workers available on day d . active workers 5: while U \u2032 6= \u2205 do 6: pick worker i \u2208 U \u2032 randomly, remove it 7: J \u2032i = feasible jobs for worker i 8: pick job j \u2208 J \u2032i randomly 9: Ujd = i . worker-task-assignment 10: if qj \u2265 Qj then remove j from J \u2032 . remove completed jobs 11: return {j 7\u2192 Uj | j \u2208 J}\nTo obtain the feasible jobs for i in line 7 we proceed as in lines 7 to 9 in tas-online and additionally check that j is still without worker assignment for that day.\nFor the next version of the algorithm (random egoistic) we assume that workers try to realize a larger wage with priority, thus modeling a typical crowdsourcing environment, where workers are selfappointed to tasks, trying to maximize their individual profit [37]. To do so, we substitute line 8 in the previous algorithm with the lines stated in Algorithm 3.\nIn the next step (random egoistic filter), we extend random egoistic with a filter that restricts\nAlgorithm 3 random egoistic\n80: let k0, k1, . . . be the domains sorted decr. by i\u2019s wage 81: for k = k0, k1, . . . do 82: J \u2032i = feasible jobs for worker i from domain k 83: if J \u2032i 6= \u2205 then 84: pick job j \u2208 J \u2032i randomly 85: break\nthe jobs that are offered to each worker based on expertise. This models the practice employed by many crowdsourcing platforms today, where workers can only access a task if they successfully pass a \u201cscreening\u201d (realized through the use of performance levels, golden data, reputation, or other means across the different platforms) [10, 21], which allows to expect a substantial contribution to the job\u2019s quality by these workers. This \u201cscreening threshold\u201d is expressed by an additional parameter 0 < factor < 1 which determines the minimal expertise needed. Therefore we additionally substitute line 7 with the following lines.\nAlgorithm 4 random egoistic filter 70: J \u2032i = feasible jobs for worker i 71: remove all j from J \u2032i with eik < (Qj \u00b7 factor)\nAs as last variation of Algorithm 2 we choose a job for some worker completely deterministically with a greedy rule: Job j is assigned to worker i if the marginal contribution in terms of quality is maximal among all feasible jobs for worker i. This amounts to replacing line 8 in Algorithm 2 by the following line (an leave line 7 unchanged).\nAlgorithm 5 online greedy 80: pick job j \u2208 J \u2032i such that eikj \u2212 qj is maximal\nNote that all algorithms so far have the online property for TAS. Finally, for reasons of comparison, we use an offline algorithm (Algorithm 6) that does not have to proceed day-by-day but has access to the complete input at once. So this clairvoyant algorithm knows in advance what workers will be available on\nwhat days of the scheduling period, and also what jobs will eventually enter the system. It proceeds job-by-job and treats each job as a knapsack that has to be packed with workers (items) that are available after the job\u2019s release date. To obtain such a packing, it calls an optimal algorithm for max knapsack that returns a packing with minimal cost such that the quality threshold is reached. Then, for the workers from this packing (= worker-task assignment), a sequencing on the timeline w.r.t. their availability is fixed, before the next job is considered.\nThe algorithm has two more parameters that influence the way workers are selected for input to the knapsack algorithm for a job j. With lookahead we specify the interval of timeslots [rj , rj + lookahead ] from which the available workers are chosen in order to control the maximum flow time of each job. Secondly, we use minavail to ensure that each worker has at least minavail -many free timeslots remaining in the above interval in order to facilitate the allocation of timeslots afterwards.\nAlgorithm 6 tas-offline\nInput: A TAS-instance x = (t,K,U, J) Output: A feasible solution y for x.\n1: Set Ujd = none for all j \u2208 J and d \u2208 [t]. 2: for j \u2208 J do . ordered by release dates 3: U \u2032j = feasible workers for j 4: for i \u2208 U \u2032j do 5: if notminavail in [rj , rj+lookahead ] then 6: remove i from U \u2032j 7: Wj \u2190 DynProgKnapsack(U \u2032j , Qj , Cj) 8: for i \u2208Wj do . sorted decr. by expertise 9: d = earliest available timeslot \u2265 rj for i 10: Ujd = i . worker-task-assignment 11: aid = 0 . set i unavailable on d 12: return {j 7\u2192 Uj | j \u2208 J}\nThe offline algorithm does not guarantee optimal solutions for TAS for various reasons. However, it is designed to complete as many jobs as possible by the particular use of offline information and by incorporating optimal solutions to the knapsack subproblems. Note that due to the standard dynamic-\nprogramming (DP) algorithm for max knapsack this is only a pseudo-polynomial time algorithm (the DP-table has dimension |U | \u00d7 Cj for each job) [25]. While we observe that this still yields tolerable runtimes for realistic input sizes, it is also possible to scale down the range of cost thresholds, or to use a fully polynomial-time approximation-scheme instead, if runtime becomes crucial."}, {"heading": "5.1.2 Evaluation Metrics and Experiments Overview", "text": "To evaluate our approach we compare the algorithms principally in terms of the objective function value (i.e. the metric that the TAS model is meant to optimize), both as an absolute number and as a percentage of the upper bound of completable jobs. We also use four auxiliary metrics, meant to provide more information on the algorithm\u2019s behavior: the number of assigned workers, flow time, budget utilization and quality reached.\nWe conduct two types of experiments: i) synthetic (sections 5.2 and 5.3), where we experiment with a known simulated crowdsourcing instance and its variations and ii) real-world (section 5.4), where we examine our model on an actual crowdsourcing platform."}, {"heading": "5.2 Synthetic Data Experiment", "text": ""}, {"heading": "5.2.1 Simulation parametrization", "text": "We first experiment with synthetic data, which were generated using the experimental result distributions reported in [2], where AMT workers worked on the complex task of news writing. For simplicity, all modeling elements were generated in the [0.1] scale. Worker expertise received a random value from a normal distribution with mean equal to 0.5 and a variance 0.15, while worker wage received a random value from a normal distribution with mean equal to 0.5 and variance 0.2. For this set of experiments worker acceptance was set equal to 1. Job quality threshold was modeled using a beta distribution with \u03b1 = 5, \u03b2 = 1, so that most jobs require a quality of at least 0.6 of 1 and higher with only a tail of jobs requiring\nless. Job cost threshold was then modeled as linearly related to job quality. Worker and job arrivals were modeled as Poisson processes with an average \u03bb = 200 worker/day, and \u00b5 = 20 jobs/day, respectively. Overall, we simulated a timeline of 30 days, during which 1000 workers (re)entered the system and 600 jobs were requested, belonging to 10 knowledge domains. So we have the following numbers in terms of our model:\nt |K| |U | |J |"}, {"heading": "30 10 1000 600", "text": ""}, {"heading": "5.2.2 Upper bound calculation", "text": "First we compute an upper bound on the number of ultimately completable jobs using the optimal DPalgorithm for max knapsack: Assume for each job that this job is the first for which we compute a worker-task assignment, i.e., all workers with at least one available timeslot \u2265 rj are possible knapsack items regardless of any other assignments. Now if the DP-algorithm does not find a packing within budget and above the quality threshold with this input data, then this job cannot be completed whatsoever. For the present instance, it turns out that at most 515 out of the 600 jobs can be completed."}, {"heading": "5.2.3 Quality experiments", "text": "We now conduct the quality experiments. In terms of the objective function, we observe that tas-online does not reach the number of completed jobs of our offline algorithm, but that it is significantly better that the other online algorithms (cf. Table 1).\nTo get a more precise picture, we want to compare these algorithms not only w.r.t. this single measure, but also look at other characteristics. Next we ask how many workers are assigned to each job, and how long the flow times are, i.e., the number of timeslots between release date rj and the latest assigned worker for j (cf. Table 2). In both cases we take the average values over all jobs in the system (not only the completed ones).\nIn cases where both values are the same, we only have compact assignments per job without any free slots in between. While tas-online seeks this type of assignments we note that tas-offline creates notable slack times, presumably a price to pay for larger number of completed jobs.\nNow we state how much budget is used with these assignments, and how much quality is reached, both relativ to the given thresholds and on average over all jobs in the system (cf. Table 3).\nDue to its greedy nature tas-online reaches very high quality values including for incompleted jobs\nand exploits the given budgets to a large extend. Finally, we show how the main performance measures develop over the time, see Fig. 1 for completed jobs and Fig. 2 for reached quality. Interestingly, we observe that the higher values in Fig. 1 for tasoffline appear towards the end of the scheduling period. A possible explanation is that the lookahead mechanism of this algorithms takes the end of the timeline into account."}, {"heading": "5.3 Scalability experiments", "text": "Next we perform a series of scalability experiments to examine the robustness of our proposed algorithm under varying conditions of the simulated instance. Given that worker volatility is the most uncontrollable factor in crowdsourcing, the two parameters that we vary are: the available expertise and the available number of workers. Each parameter is modified independently, while all the other parameters of the baseline instance presented in section 5.2 are kept the same. The variables that we measure are also the\nsame as those measured for the baseline instance and include the objective function, as well as budget utilization, total flow time, number of assigned workers per task and percentage of the average quality threshold reached.\nThe scalability experimental results are illustrated in Figures 3-5. For each of those figures the x axis corresponds to the varied parameter, the y axis to the measured variable and the vertical line at x = 1 corresponds to the results of the baseline instance reported in section 5.2.3."}, {"heading": "5.3.1 Overview of scalability experimental results", "text": "Two main remarks can be drawn as an overview of the scalability experiments. The first is about performance: tas-online is the highest performing among its online competitors, both regarding the value of the objective function, i.e. the metric that the algorithm is meant to optimize, and on quality, without significant compromises on any of the remaining\nmetrics. tas-online is the only algorithm among those examine to achieve this: whereas certain algorithms come close to its performance for certain metrics and parameter values, the same algorithms are significantly low-performing in other metrics and parametrizations. This result indicates that the proposed algorithm has a better \u2018value-for-money\u2019 compared to its competitors.\nThe second remark is about consistency : tasonline is not only more performant, but its performance is consistent across the varying values of the scalability experimental parameters. This result indicates that the performance of the algorithm as detailed in section 5.2.3 is not incidental but an inherent property of the algorithm, and reinforces trust in the algorithm\u2019s future usage. In the following we present a detailed analysis of the scalability experiments.\n5.3.2 Scalability effect on Objective Function: tas-online gets consistently more jobs done\nIn Figure 3 we measure the value of the objective function (i.e. the number of accomplished jobs) as we modify expertise availability, and higher y axis values are better. As we can observe, the tas family of algorithms (both the online and the offline version) are able to achieve and maintain higher performance than their competitive algorithms, at all expertise levels. For average expertise levels less than the baseline instance tas-offline is the best-performing algorithm, followed closely by tas-online, while for expertise levels slightly higher than the baseline tasonline takes and maintains precedence. As it can be expected, as the average worker expertise per knowledge domain drops, the performance of all algorithms drops steeply as well. Nevertheless, we can also observe that the tas algorithms are more robust, in the sense that they maintain their high performance when the other algorithms already start losing theirs (notice for example the almost unchanged performance of tas-online between x = 2 down to x = 1.2 compared to the steep performance drop of the other algorithms in the same range).\nA similar pattern can be observed when modifying the worker availability parameter (Figure 4). In this\ncase too, tas-online is by far the most performant of all the online algorithms, surpassed only by its offline version. In fact, the performance difference between tas-online and the rest of the algorithms is quite striking here, as tas-online reaches approximately 60% of the objective function value while the rest of the algorithms only reach 20%. A second interesting remark that can be derived is that worker availability seems to have little effect on the algorithms after a certain critical mass of crowd workers has been gathered (which for our simulation corresponds to x = 0.4, i.e. 40% of the population of the baseline instance). These two observations (superiority of the tas-online and small effect of worker availability after a certain critical mass) also hold when we measure the effect of the worker availability parameter on all other variables of the scalability experiment. Following this, and for reasons of brevity, we omit the rest of the scalability figures corresponding to the worker availability, and focus on the parameter of expertise availability which seems to have the highest effect.\n5.3.3 Scalability effect on Quality: tasonline achieves higher quality\nFigure 5 illustrates the average task quality (expressed as the percentage of the quality threshold reached) for every level of expertise of the crowdsourcing population, and higher y axis values are better. We observe that tas-online manages to achieve the highest quality levels, surpassing even its offline version, for all expertise levels. In fact, given a certain level of expertise (x = 1.2) and above, the algorithm manages to surpass the quality threshold set for the tasks. random-egoistic and online greedy are the second and third most performing algorithms respectively, but unlike tas-online they achieve their high quality results, at the cost of accomplishing too few jobs, as it can be seen by juxtaposing Figures 3 and 5.\n5.3.4 Scalability on other parameters: tasonline performs comparably to its competitors\nEffect on cost. We now examine the effect that the modification of expertise availability has on the budget used by the allocation algorithms (Figure 6, smaller y axis values are better). As we may observe, tas-online consumes most (\u2248 90%) of its available budget, at the same consumption level as the online greedy, random and random egoistic algorithms. The random egoistic filter and tas-offline algorithms seem to make a slightly better usage of their budget. Nevertheless, the extra cost consumed by tas-online is small, especially as expertise levels grow and more experts need to be paid (i.e. for x > 1.2). The significance of this extra cost gets even smaller considering what we gain in terms of the objective function (Figure 3), where tas-online consistently accomplishes more jobs (almost up to double for x = 1.2) than random egoistic filter. As such, tas-online has a much higher \u2018value-for-mone\u2019 (jobs done vs. cost ratio) compared to its competitors.\nEffect on Flow Time. Figure 7 shows the flow time of the algorithms for varying levels of expertise availability, and smaller y axis values are better. As we may observe, the proposed tas-online algorithm behaves similarly to the rest of the online algorithms. This shows that there is no trade-off of performance for time, i.e. our algorithm does not achieve its higher objective function values at the cost of flow time.\nEffect on Number of Assigned Workers. Figure 8 shows the change in the average number of workers per task, as we modify the availability of expertise, and lower values of the y axis are better. Here, and for most algorithms, we observe a very steep drop in the number of assigned workers, as the average expertise of the crowd worker population increases. This fact is to be expected, as the algorithms need to assign multiple workers to achieve the quality thresholds when expertise is scarce."}, {"heading": "5.4 Real Data Experiment", "text": "To examine the effectiveness of the proposed algorithm, we conducted a real world experiment. The platform we used for this was CrowdFlower8. The task we used was collaborative news article writing, where workers from an initial hiring pool were asked to build on each other\u2019s content sequentially, enriching a news article text on a given topic. In more detail, our experimental workflow consisted of three steps.\nIn the first step we recruited a pool of 60 workers and recorded their expertise, wage and availability. To measure expertise, we asked each worker to complete two short multiple choice tests, each comprising 10 questions and measuring the workers\u2019 knowledge skills on a particular topic of current interest, i.e. \u201dThe FIFA 2015 corruption scandal\u201d and \u201dSelfdriving cars\u201d respectively. Each one of these topics is considered a knowledge domain for the purposes of our experiment. We also gave workers an estimation of the effort that they would have to spend on the second round of the task and asked them to provide us with their required wage.\nIn the next round we split the hired pool of workers randomly into two parts, one to be used by the benchmark and one by the optimization algorithm during scheduling. We also created six Google documents for each algorithm, three per knowledge domain, which corresponded to the jobs that would have to be accomplished. The quality and cost thresholds, as well as the release date for each job were set according to the same job generation criteria used in the synthetic experiments, and they were the same for the jobs of the benchmark and the optimization algorithm. In regards to the algorithms to be compared we used random ego. filter as benchmark with factor = 0.3 (a worker was to be allowed to take a job only if his expertise was at least 30% of the target job quality) and tas-online as the optimization algorithm. Finally we set the scheduling period to t = 8 slots and the time unit to one day. Each day, one worker would be invited to contribute to each Google document, according to the benchmark and the optimized algorithm. At the end of that day the\n8http://www.crowdflower.com\ndocument would be locked for the particular worker and sent for evaluation by a crowd of 50 independent crowd workers (different than those used in the experiments) to evaluate the job\u2019s current quality. Then, if the job had not surpassed its quality threshold and not exhausted its budget, a new worker was invited to work on the document.\nAt the end of the scheduling period, the results were as follows: The benchmark algorithm achieved a successful completion of 3 out of 6 jobs, while the optimization algorithm achieved successful completion of 5 out of 6 jobs. As it was expected the benchmark algorithm either allowed workers of the minimum necessary expertise to take a job, thus delaying the jobs quality progress too much, or it starved the job of budget. On the other hand tas-online selected workers in such a way as to improve job completion within the given time period. As illustrated in Figures 9 and 10, similarly to the respective results of the synthetic experiments, tas-online achieved higher average job quality and job completion percentages than the benchmark."}, {"heading": "6 Discussion and Future Exten-", "text": "sions\nThe TAS model presented in this paper is the first concrete attempt to incorporate time-sensitive opti-\nmization in expert crowdsourcing. Our results, as presented in the previous, indicate that this model can improve the performance of crowdsourcing systems and help them utilize their human capital more effectively. Nonetheless, several challenges still lie ahead and many further extensions can be envisioned. In this final section we briefly discuss how the proposed TAS model and the tas-online algorithm can be adapted to address further challenging settings that may appear in practice.\nBudget flexibility. Our initial TAS model assumes a fixed budget per job, set by the customers before the job is launched. However certain commercial platforms, like CrowdFlower allow jobs to go above their initial budget, and this option could be used in order to recruit better qualified workers during the scheduling period. One simple approach for adapting the tas-online algorithm to the \u2018flexible budget option\u2019 is to recompute the daily matchings with alternating remaining budgets and explore their effects. A second adaptation is allowing edges to stay in the bipartite graph if the cost exceeds the remaining budget by a given fixed percentage, which can even be specified per job. Since we want to avoid that the algorithm makes too much use of the additional budgets we can reduce the profit of such edges accordingly. A multi-objective view of the optimiza-\ntion problem can also be useful to reveal these budget trade-offs.\nNon-Acceptance of Assignment. The initial TAS model assumes that worker availability does not change, once the workers declare themselves available for a specific day. An adapted version of this model could be that workers can decline a certain assignment or they may be marked as unavailable by the system after a certain period, waiting for their reaction, has timed-out. A natural adaptation of the tas-online algorithm to this problem is to perform a partial recomputation of the matching for the specific day, where all accepted assignments (workers and corresponding tasks) and all stalled workers are removed from the graph. Note that this also allows to bring in new workers and jobs that became available only very recently within the day.\nJob prioritizing. The current TAS model gives all jobs the same priority. However some jobs may become more urgent than others during the scheduling period, for example in crowdsourcing systems dealing with crisis response [18]. Job prioritization can be incorporated in the model based on a given deadline, on the quality left to reach the threshold (jobs close to threshold go first), or other criteria. Our tas-online algorithm uses a flexible profit function to rate all feasible assignments per day. Therefore if some jobs (or workers) become preferred over others, the profits on the respective edges can be easily changed. This change is possible for individual worker-task combinations and it can additionally be adjusted every day for a close progress control.\nQuality aggregation model. Like many relevant studies in the area (e.g. [14, 2]), our current TAS model uses a sum function to calculate job quality, assuming that a job\u2019s quality is the sum of expertise of the individual workers that have contributed to the job. Nevertheless, and depending on the context, this calculation mode may not always reflect correctly a job\u2019s quality. For instance in cases of highly subjective tasks the quality of contributions of the same worker may vary even on tasks belonging to the same\ntopic. In these cases, quality may need to be calculated in a different way, e.g. using crowd-based evaluations after each worker contribution, similarly to our real-world experiment. Here we need to distinguish two cases of adaptation for our algorithm. The first is incorporating a profit function that tries to forecast the benefit from a certain assignment, prior to that assignment. The second is incorporating an extra mechanism that is responsible for determining the quality reached per job, day and assignment. The extra costs associated with this mechanism can also form part of the profit function. Both these adaptation are feasible depending on the exact aggregation model needed.\nLearning. In our initial TAS model we consider expertise as an inherent, fixed property of each worker. For certain tasks however, like creative ones, the expertise of a certain individual can develop over time, and with the number of accomplished tasks, as workers \u2018learn by doing\u2019 [9, 38]. An improved version of the model could recognize this fact and perform an adjustment of worker expertise over time. According to this version, the expertise per worker needed by the tas-online during graph construction each day could be the outcome of a previous learning process (e.g. machine learning as in [29]). The online version of the TAS algorithm is particularly well suited for such an dynamic adjustment.\nOrder of workers per job. In our problem formulation the order in which the assigned workers per job are placed on the timeline is arbitrary (openshop model), to simulate the first-come first-served mode of functionality of typical crowdsourcing platforms. It could nonetheless be reasonable for certain applications to require a specific order of workers, e.g. in a decreasing order of expertise. A straightforward approach to adapt tas-online to such a request is to drop all the edges in the bipartite graph for each day such that the only workers that remain assignable are those that correspond to the order criteria. Again, this can be adopted over time such that, e.g., each job begins with an assignment of some workers with sufficient but relatively small expertise, to leave room\nand budget for enhancement.\nMultiple assignments per worker and timeslot. Constraint (a) of our examined TAS model allows only one task per worker and timeslot. It may be reasonable to relax this to some bounded number of tasks per worker and timeslot, which can also be changed over time, for instance to allow multiple assignments to more experienced workers. Currently tas-online relies on computing daily matchings, and the matching condition on the worker-side of the bipartite graph corresponds directly to constraint (a). However by taking a closer look at how the weighted matching are computed in terms of min-cost flow networks, we can observe that the capacities on sourceedges and sink-edges in the flow network are usually set to 1 to enforce the matching conditions. If we now allow larger values as capacities on sink edges we can also compute worker-task assignments for the relaxed condition of multiple assignments.\nThe above correspond to the main modifications that could be made to adapt the proposed TAS model and tas-online algorithm to multiple reallife situations, depending on the crowdsourcing platform, population and type of jobs at-hand. As such they could be used independently or in various combinations, as the starting points for further studies in this promising new field of expert crowdsourcing optimization."}, {"heading": "7 Conclusion", "text": "In this paper we present TAS, a model that adds the timeline and online perspective to task assignment optimization in expert crowdsourcing. Using a greedy scheduling algorithm, tas-online, we show that optimization under this model can significantly improve expert crowdsourcing performance. Future extensions to enable the TAS model to handle further challenging settings include: include adding budget flexibility, job and/or worker prioritizing, fine-tuning the job quality aggregation mechanism, worker performance variability over time, and multiple assignments per worker/timeslot."}, {"heading": "8 Acknowledgments", "text": "The work of Ioanna Lykourentzou in this paper has received funding support by the Luxembourg National Research Fund (FNR) under INTER Mobility grant #8734708. The present paper is an extension of the work first presented at the Third AAAI Conference on Human Computation and Crowdsourcing (HCOMP 2015) [30]."}], "references": [{"title": "Online team formation in social networks", "author": ["Aris Anagnostopoulos", "Luca Becchetti", "Carlos Castillo", "Aristides Gionis", "Stefano Leonardi"], "venue": "In Proceedings of the 21st International Conference on World Wide Web, WWW", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Task assignment optimization in knowledge-intensive crowdsourcing", "author": ["Senjuti Basu Roy", "Ioanna Lykourentzou", "Saravanan Thirumuruganathan", "Sihem Amer-Yahia", "Gautam Das"], "venue": "The VLDB Journal,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Crowds in two seconds: Enabling realtime crowd-powered interfaces", "author": ["Michael S. Bernstein", "Joel Brandt", "Robert C. Miller", "David R. Karger"], "venue": "In Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Analytic methods for optimizing realtime crowdsourcing", "author": ["Michael S. Bernstein", "David R. Karger", "Robert C. Miller", "Joel Brandt"], "venue": "CoRR, abs/1204.2995,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "A truthful budget feasible multi-armed bandit mechanism for crowdsourcing time critical tasks", "author": ["Arpita Biswas", "Shweta Jain", "Debmalya Mandal", "Y. Narahari"], "venue": "In Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Online Computation and Competitive Analysis", "author": ["Allan Borodin", "Ran El-Yaniv"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "On task assignment for real-time reliable crowdsourcing", "author": ["I. Boutsis", "V. Kalogeraki"], "venue": "In Distributed Computing Systems (ICDCS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Automatic assessment of document quality in web collaborative digital libraries", "author": ["Daniel Hasan Dalip", "Marcos Andr\u00e9 Gon\u00e7alves", "Marco Cristo", "P\u00e1vel Calado"], "venue": "J. Data and Information Quality,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Shepherding the crowd yields better work", "author": ["Steven Dow", "Anand Kulkarni", "Scott Klemmer", "Bj\u00f6rn Hartmann"], "venue": "In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work, CSCW", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "Are your participants gaming the system?: Screening mechanical turk workers", "author": ["Julie S. Downs", "Mandy B. Holbrook", "Steve Sheng", "Lorrie Faith Cranor"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "On the complexity of time table and multi-commodity flow problems", "author": ["S Even", "A Itai", "A Shamir"], "venue": "Foundations of Computer Science", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1975}, {"title": "Crowdop: Query optimization for declarative crowdsourcing systems", "author": ["J. Fan", "M. Zhang", "S. Kok", "M. Lu", "B. Ooi"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, PP(99):1\u2013 1", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "What\u2019s the right price? pricing tasks for finishing on time. In Human Computation, volume WS-11-11 of AAAI Workshops", "author": ["Siamak Faradani", "Bjoern Hartmann", "Panagiotis G. Ipeirotis"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Allocating tasks to workers with matching constraints: Truthful mechanisms for crowdsourcing markets", "author": ["Gagan Goel", "Afshin Nikzad", "Adish Singla"], "venue": "In Proceedings of the Companion Publication of the 23rd International Conference on World Wide Web Companion, WWW Companion", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Argonaut: Macrotask crowdsourcing for complex data processing", "author": ["Daniel Haas", "Jason Ansel", "Lydia Gu", "Adam Marcus"], "venue": "Proc. VLDB Endow.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Online task assignment in crowdsourcing markets", "author": ["Chien-Ju Ho", "Jennifer Wortman Vaughan"], "venue": "In Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, July 22-26,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "The labor economics of paid crowdsourcing", "author": ["John Joseph Horton", "Lydia B. Chilton"], "venue": "In EC", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Engineering crowdsourced stream processing systems", "author": ["Muhammad Imran", "Ioanna Lykourentzou", "Carlos Castillo"], "venue": "CoRR, abs/1310.5463,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Quizz: Targeted crowdsourcing with a billion (potential) users", "author": ["Panagiotis G. Ipeirotis", "Evgeniy Gabrilovich"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Online assignment of heterogeneous tasks in crowdsourcing markets", "author": ["S. Hsu J. Jabbari", "S. Assadi"], "venue": "In Third AAAI Conference on Human Computation and Crowdsourcing (HCOMP-2015),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "A survey of trust and reputation systems for online service provision", "author": ["Audun J\u00f8sang", "Roslan Ismail", "Colin Boyd"], "venue": "Decis. Support Syst.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Adaptive performance optimization over crowd labor channels", "author": ["Saraschandra Karanam", "Deepthi Chander", "L. Elisa Celis", "Koustuv Dasgupta", "Vaibhav Rajan"], "venue": "In Proceedings of the Seconf AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Budget-optimal task allocation for reliable crowdsourcing systems", "author": ["David R. Karger", "Sewoong Oh", "Devavrat Shah"], "venue": "CoRR, abs/1110.3564,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Reducibility among combinatorial problems", "author": ["R M Karp"], "venue": "Complexity of Computer Computations,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1972}, {"title": "Optimized execution of business processes on crowdsourcing platforms", "author": ["R. Khazankin", "B. Satzger", "S. Dustdar"], "venue": "In Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "On the complexity of minimizing the number of late jobs in unit time open shop", "author": ["Svetlana A Kravchenko"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2000}, {"title": "The Hungarian method for the assignment problem", "author": ["H W Kuhn"], "venue": "Naval research logistics quarterly", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1955}, {"title": "Corpwiki: A self-regulating wiki to promote corporate collective intelligence through expert peer matching", "author": ["Ioanna Lykourentzou", "Katerina Papadaki", "Dimitrios J. Vergados", "Despina Polemi", "Vassili Loumos"], "venue": "Information Sciences,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "An online approach to task assignment and sequencing 22  in expert crowdsourcing", "author": ["Ioanna Lykourentzou", "Heinz Schmitz"], "venue": "Third AAAI Conference on Human Computation and Crowdsourcing (HCOMP", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Improving wiki article quality through crowd coordination: A resource allocation approach", "author": ["Ioanna Lykourentzou", "Dimitrios J. Vergados", "Yannick Naudet"], "venue": "Int. J. Semant. Web Inf. Syst.,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Stochastic on-line knapsack problems", "author": ["A Marchetti-Spaccamela", "C Vercellis"], "venue": "Mathematical Programming,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1995}, {"title": "Crowdmanager-combinatorial allocation and pricing of crowdsourcing tasks with time constraints", "author": ["P. Minder", "S. Seuken", "A. Bernstein", "M. Zollinger"], "venue": "2nd Workshop on Social Computing and User Generated Content. ACM Conference on Electronic Commerce ", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2012}, {"title": "Optimizing plurality for human intelligence tasks", "author": ["Luyi Mo", "Reynold Cheng", "Ben Kao", "Xuan S. Yang", "Chenghui Ren", "Siyu Lei", "David W. Cheung", "Eric Loz"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2013}, {"title": "Mechanism design for time critical and cost critical task execution via crowdsourcing", "author": ["Swaprava Nath", "Pankaj Dayama", "Dinesh Garg", "Yadati Narahari", "James Zou"], "venue": "In Proceedings of the 8th International Conference on Internet and Network Economics,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "Crowdcontrol: An online learning approach for optimal task scheduling in a dynamic crowd platform", "author": ["V. Rajan", "S. Bhattacharya", "L. Celis", "D. Chander", "K. Dasgupta", "S. Karanam"], "venue": "ICML\u201913 Workshop: Machine Learning Meets Crowdsourcing. ACM Conference on Electronic Commerce ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "An assessment of intrinsic and extrinsic motivation on task performance in crowdsourcing markets", "author": ["Jakob Rogstadius", "Vassilis Kostakos", "Aniket Kittur", "Boris Smus", "Jim Laredo", "Maja  Vukovic"], "venue": "In Proceedings of the Fifth International Conference on Weblogs and Social Media,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2011}, {"title": "Crowds", "author": ["S.B. Roy", "I. Lykourentzou", "S. Thirumuruganathan", "S. Amer-Yahia", "G. Das"], "venue": "not drones: modeling human factors in interactive crowdsourcing. In Reynold Cheng, Anish Das Sarma, Silviu Maniu, and Pierre Senellart, editors, DBCrowd 2013 - VLDB Workshop on Databases and Crowdsourcing, volume CEUR Workshop Proceedings, pages 39\u201342. CEUR- WS", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimization in knowledgeintensive crowdsourcing", "author": ["Senjuti Basu Roy", "Ioanna Lykourentzou", "Saravanan Thirumuruganathan", "Sihem Amer-Yahia", "Gautam Das"], "venue": "CoRR, abs/1401.1302,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Bringing reputation-awareness into crowdsourcing", "author": ["Han Yu", "Zhiqi Shen", "C. Leung"], "venue": "In Information, Communications and Signal Processing (ICICS) 2013 9th International Conference on,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2013}, {"title": "An evolutionary and automated virtual team making approach for crowdsourcing platforms", "author": ["Tao Yue", "Shaukat Ali", "Shuai Wang"], "venue": "Crowdsourcing, Progress in IS,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}, {"title": "Task matching in crowdsourcing", "author": ["Man-Ching Yuen", "Irwin King", "Kwong-Sak Leung"], "venue": "In Proceedings of the 2011 International Conference on Internet of Things and 4th International Conference on Cyber, Physical and Social Computing, ITHINGSCPSCOM", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2011}, {"title": "Taskrec: probabilistic matrix factorization in task recommendation in crowdsourcing systems", "author": ["Man-Ching Yuen", "Irwin King", "Kwong-Sak Leung"], "venue": "In Proceedings of the 19th international conference on Neural Information Processing - Volume Part II,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2012}], "referenceMentions": [{"referenceID": 14, "context": "This type of crowdsourcing is often referred to as expert crowdsourcing, and the tasks that it involves are referred to as macrotasks [15].", "startOffset": 134, "endOffset": 138}, {"referenceID": 1, "context": "Recent studies that examine expert crowdsourcing optimization [2, 14] typically seek to find worker assignments per task such that the worker contributions add up to a required quality threshold within a given budget.", "startOffset": 62, "endOffset": 69}, {"referenceID": 13, "context": "Recent studies that examine expert crowdsourcing optimization [2, 14] typically seek to find worker assignments per task such that the worker contributions add up to a required quality threshold within a given budget.", "startOffset": 62, "endOffset": 69}, {"referenceID": 21, "context": "Crowdsourcing optimization is a term used in various problem settings, including optimizing the selection of worker labor channels to improve performance [22], discovering the optimal worker wage [17], determining the optimal number of workers to undertake each task so as to maximize quality and minimize cost (a method referred to as \u201cplurality optimization\u201d and applicable on n-ary tasks with an objective \u201ctrue value\u201d) [34], or identifying the optimal set of tasks to forward to the crowd (for systems like database query execution ones, which are based partially on crowdsourcing and partially on automated methods) [12].", "startOffset": 154, "endOffset": 158}, {"referenceID": 16, "context": "Crowdsourcing optimization is a term used in various problem settings, including optimizing the selection of worker labor channels to improve performance [22], discovering the optimal worker wage [17], determining the optimal number of workers to undertake each task so as to maximize quality and minimize cost (a method referred to as \u201cplurality optimization\u201d and applicable on n-ary tasks with an objective \u201ctrue value\u201d) [34], or identifying the optimal set of tasks to forward to the crowd (for systems like database query execution ones, which are based partially on crowdsourcing and partially on automated methods) [12].", "startOffset": 196, "endOffset": 200}, {"referenceID": 32, "context": "Crowdsourcing optimization is a term used in various problem settings, including optimizing the selection of worker labor channels to improve performance [22], discovering the optimal worker wage [17], determining the optimal number of workers to undertake each task so as to maximize quality and minimize cost (a method referred to as \u201cplurality optimization\u201d and applicable on n-ary tasks with an objective \u201ctrue value\u201d) [34], or identifying the optimal set of tasks to forward to the crowd (for systems like database query execution ones, which are based partially on crowdsourcing and partially on automated methods) [12].", "startOffset": 423, "endOffset": 427}, {"referenceID": 11, "context": "Crowdsourcing optimization is a term used in various problem settings, including optimizing the selection of worker labor channels to improve performance [22], discovering the optimal worker wage [17], determining the optimal number of workers to undertake each task so as to maximize quality and minimize cost (a method referred to as \u201cplurality optimization\u201d and applicable on n-ary tasks with an objective \u201ctrue value\u201d) [34], or identifying the optimal set of tasks to forward to the crowd (for systems like database query execution ones, which are based partially on crowdsourcing and partially on automated methods) [12].", "startOffset": 621, "endOffset": 625}, {"referenceID": 14, "context": "Macrotasks [15] require more worker time, accept open-ended continuous (rather than binary or n-ary) worker inputs and their quality is determined through external subjective evaluation (for example peer review).", "startOffset": 11, "endOffset": 15}, {"referenceID": 22, "context": "[23] work with homogeneous microtasks (that all have the same level of difficulty and do no distinguish among task \u201ctopics\u201d), and propose a matching algorithm inspired by the standard belief propagation algorithm for approximating max marginals, which is order-optimal and minimizes cost.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] work with heterogeneous microtasks of n-ary classification quality on a model where worker skills per microtask are a-priori unknown, and propose a two phase exploration-exploitation assignment algorithm that seeks to maximize the total benefit of the requester and is competitive with respect to its counterpart of known worker skills.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "[43, 44, 42] propose a matrix factorization approach that utilizes the workers\u2019 task performance and search history to derive their preferences and perform an improved task-to-worker matching.", "startOffset": 0, "endOffset": 12}, {"referenceID": 40, "context": "[43, 44, 42] propose a matrix factorization approach that utilizes the workers\u2019 task performance and search history to derive their preferences and perform an improved task-to-worker matching.", "startOffset": 0, "endOffset": 12}, {"referenceID": 13, "context": "[14] and Roy et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2, 39] both propose task-to-worker assignment optimizations (the first using a mechanism design-based approach and the second through an index-based approach) on models that consider heterogeneous macrotasks and where the optimization goal is to maximize the utility of the requester while ensuring budget feasibility.", "startOffset": 0, "endOffset": 7}, {"referenceID": 37, "context": "[2, 39] both propose task-to-worker assignment optimizations (the first using a mechanism design-based approach and the second through an index-based approach) on models that consider heterogeneous macrotasks and where the optimization goal is to maximize the utility of the requester while ensuring budget feasibility.", "startOffset": 0, "endOffset": 7}, {"referenceID": 39, "context": "[41] add to this model the element of team instead of individual worker assignments, and propose a heuristic genetic algorithm that optimizes for task budget and quality, taking into account worker pay expectations, skills and availability.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] add another interesting facet to the heterogeneous task assignment model, by extending it to cover the online aspect of the problem (workers arrive online, no", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[40] optimize the number of tasks to recommend to each worker per time unit with the objective of maximizing the time average number of successful (i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Their model assumes binary task quality, a pull-and-filter task selection model (workers select which tasks they want to work on and the system filters these selections according to its optimization objective) and performs task allocation on the basis of worker accuracy measured in a [0,1] scale using a heuristic algorithm of linearithmic complexity.", "startOffset": 285, "endOffset": 290}, {"referenceID": 3, "context": "[4, 3] also work with homogeneous microtasks and propose a retainer model for pre-recruiting (reserving) the optimal number of workers, so as to minimize task completion latency.", "startOffset": 0, "endOffset": 6}, {"referenceID": 2, "context": "[4, 3] also work with homogeneous microtasks and propose a retainer model for pre-recruiting (reserving) the optimal number of workers, so as to minimize task completion latency.", "startOffset": 0, "endOffset": 6}, {"referenceID": 12, "context": "[13] and Minder et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33] add the element of pricing to the problem model, proposing task pricing algorithms that aim to maximize the number of tasks finishing on time (the first study), while respecting budget and quality constraints (the second study).", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "Mechanism design [35, 36] and multi-armed bandit mechanism design [5] mechanisms have also been employed to manipulate the time behavior of the crowd towards an efficient execution of time-critical tasks.", "startOffset": 17, "endOffset": 25}, {"referenceID": 34, "context": "Mechanism design [35, 36] and multi-armed bandit mechanism design [5] mechanisms have also been employed to manipulate the time behavior of the crowd towards an efficient execution of time-critical tasks.", "startOffset": 17, "endOffset": 25}, {"referenceID": 4, "context": "Mechanism design [35, 36] and multi-armed bandit mechanism design [5] mechanisms have also been employed to manipulate the time behavior of the crowd towards an efficient execution of time-critical tasks.", "startOffset": 66, "endOffset": 69}, {"referenceID": 24, "context": "[26] propose a mathematical optimization approach that learns the task selection behavior of workers and then executes tasks in a manner that optimizes for cost and considers deadlines.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "Finally, Boutsis and Kalogeraki [7] propose an multi-objective optimization approach which searches for Pareto-optimal solutions, seeking to identify the group of workers (among multiple candidate groups) with the highest probability of finishing the task on time.", "startOffset": 32, "endOffset": 35}, {"referenceID": 27, "context": "Finally collaborative document editing applications, such as corporate wikis [29], where it is possible to sequence worker contributions along a timeline could significantly improve from our approach.", "startOffset": 77, "endOffset": 81}, {"referenceID": 27, "context": "The interested reader is referred to [29, 8, 19] for available worker profile quantification techniques based on machine-learning, implicit evaluation or information theory.", "startOffset": 37, "endOffset": 48}, {"referenceID": 7, "context": "The interested reader is referred to [29, 8, 19] for available worker profile quantification techniques based on machine-learning, implicit evaluation or information theory.", "startOffset": 37, "endOffset": 48}, {"referenceID": 18, "context": "The interested reader is referred to [29, 8, 19] for available worker profile quantification techniques based on machine-learning, implicit evaluation or information theory.", "startOffset": 37, "endOffset": 48}, {"referenceID": 0, "context": "Note that in the context of this work we define task quality as the sum of expertises of the workers that participate in it, using the additive skill aggregation model that is often used for expert sequential macrotasks such as document editing [1, 31].", "startOffset": 245, "endOffset": 252}, {"referenceID": 29, "context": "Note that in the context of this work we define task quality as the sum of expertises of the workers that participate in it, using the additive skill aggregation model that is often used for expert sequential macrotasks such as document editing [1, 31].", "startOffset": 245, "endOffset": 252}, {"referenceID": 0, "context": "Other aggregation functions, including minimum, maximum or product [1] could also be used to compute a task\u2019s quality, however their full examination is out of the scope of this work.", "startOffset": 67, "endOffset": 70}, {"referenceID": 25, "context": "So this aspect of TAS is a unittime openshop problem with limited machine-availability and job release-dates [27].", "startOffset": 109, "endOffset": 113}, {"referenceID": 10, "context": "We also want to mention that the sequencing of an already fixed worker-task-assignment can be reduced to the bipartite list edge-coloring problem [11].", "startOffset": 146, "endOffset": 150}, {"referenceID": 23, "context": "We show NP-hardness with a polynomial-time many-one reduction from the NP-complete problem 3-Dimensional Matching [24].", "startOffset": 114, "endOffset": 118}, {"referenceID": 5, "context": "For more background on the general concept of online algorithms we refer to [6].", "startOffset": 76, "endOffset": 79}, {"referenceID": 26, "context": "if we apply the Hungarian Method this step has a running time proportional to O((|J \u2032| + |U \u2032|)2|E|) [28].", "startOffset": 101, "endOffset": 105}, {"referenceID": 30, "context": "It is known from literature that no competitive algorithm for the online version of KNAPSACK exists where items arrive one at a time [32].", "startOffset": 133, "endOffset": 137}, {"referenceID": 5, "context": "An online algorithm is called competive if the ratio of it\u2019s performance and an optimal offline algorithm\u2019s performance can be bounded, a usual performance measure for online algorithms [6].", "startOffset": 186, "endOffset": 189}, {"referenceID": 35, "context": "For the next version of the algorithm (random egoistic) we assume that workers try to realize a larger wage with priority, thus modeling a typical crowdsourcing environment, where workers are selfappointed to tasks, trying to maximize their individual profit [37].", "startOffset": 259, "endOffset": 263}, {"referenceID": 9, "context": "This models the practice employed by many crowdsourcing platforms today, where workers can only access a task if they successfully pass a \u201cscreening\u201d (realized through the use of performance levels, golden data, reputation, or other means across the different platforms) [10, 21], which allows to expect a substantial contribution to the job\u2019s quality by these workers.", "startOffset": 271, "endOffset": 279}, {"referenceID": 20, "context": "This models the practice employed by many crowdsourcing platforms today, where workers can only access a task if they successfully pass a \u201cscreening\u201d (realized through the use of performance levels, golden data, reputation, or other means across the different platforms) [10, 21], which allows to expect a substantial contribution to the job\u2019s quality by these workers.", "startOffset": 271, "endOffset": 279}, {"referenceID": 1, "context": "We first experiment with synthetic data, which were generated using the experimental result distributions reported in [2], where AMT workers worked on the complex task of news writing.", "startOffset": 118, "endOffset": 121}, {"referenceID": 17, "context": "However some jobs may become more urgent than others during the scheduling period, for example in crowdsourcing systems dealing with crisis response [18].", "startOffset": 149, "endOffset": 153}, {"referenceID": 13, "context": "[14, 2]), our current TAS model uses a sum function to calculate job quality, assuming that a job\u2019s quality is the sum of expertise of the individual workers that have contributed to the job.", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "[14, 2]), our current TAS model uses a sum function to calculate job quality, assuming that a job\u2019s quality is the sum of expertise of the individual workers that have contributed to the job.", "startOffset": 0, "endOffset": 7}, {"referenceID": 8, "context": "For certain tasks however, like creative ones, the expertise of a certain individual can develop over time, and with the number of accomplished tasks, as workers \u2018learn by doing\u2019 [9, 38].", "startOffset": 179, "endOffset": 186}, {"referenceID": 36, "context": "For certain tasks however, like creative ones, the expertise of a certain individual can develop over time, and with the number of accomplished tasks, as workers \u2018learn by doing\u2019 [9, 38].", "startOffset": 179, "endOffset": 186}, {"referenceID": 27, "context": "machine learning as in [29]).", "startOffset": 23, "endOffset": 27}, {"referenceID": 28, "context": "The present paper is an extension of the work first presented at the Third AAAI Conference on Human Computation and Crowdsourcing (HCOMP 2015) [30].", "startOffset": 143, "endOffset": 147}], "year": 2016, "abstractText": "We introduce the problem of Task Assignment and Sequencing (TAS), which adds the timeline perspective to expert crowdsourcing optimization. Expert crowdsourcing involves macrotasks, like document writing, product design, or web development, which take more time than typical binary microtasks, require expert skills, assume varying degrees of knowledge over a topic, and require crowd workers to build on each other\u2019s contributions. Current works usually assume offline optimization models, which consider worker and task arrivals known and do not take into account the element of time. Realistically however, time is critical: tasks have deadlines, expert workers are available only at specific time slots, and worker/task arrivals are not known a-priori. Our work is the first to address the problem of optimal task sequencing for online, heterogeneous, time-constrained macrotasks. We propose tas-online, an online algorithm that aims to complete as many tasks as possible within budget, required quality and a given timeline, without future input information regarding job release dates or worker availabilities. Results, comparing tas-online to four typical benchmarks, show that it achieves more completed jobs, lower flow times and higher job quality. This work has practical implications for improving the Quality of Service of current crowdsourcing platforms, allowing them to offer cost, quality and time improvements for expert tasks.", "creator": "LaTeX with hyperref package"}}}