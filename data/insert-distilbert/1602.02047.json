{"id": "1602.02047", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Feb-2016", "title": "Utiliza\\c{c}\\~ao de Grafos e Matriz de Similaridade na Sumariza\\c{c}\\~ao Autom\\'atica de Documentos Baseada em Extra\\c{c}\\~ao de Frases", "abstract": "the internet increased the amount of information available. however, integrating the reading materials and understanding of this spatial information are costly tasks. in this scenario, the natural language processing ( nlp ) applications enable very important solutions, highlighting the automatic text summarization ( ats ), which produce a summary from one tablet or more source texts. automatically summarizing one or more texts, however, is a complex task also because of the difficulties inherent to the analysis and generation of this summary. this master's thesis describes the main techniques and methodologies ( nlp and heuristics ) to generate summaries. we have also addressed categories and thus proposed some heuristics based on graphs and similarity matrix to measure the relevance of judgments and to generate summaries by also extracting sentences. we used the two multiple constituent languages ( english, french and spanish ), cstnews ( brazilian portuguese ), rpm ( french ) and decoda ( french ) corpus to evaluate the developped systems. the results obtained were quite interesting.", "histories": [["v1", "Fri, 5 Feb 2016 14:54:57 GMT  (1804kb)", "http://arxiv.org/abs/1602.02047v1", "Dissertation, 83 pages, in Portuguese. in Disserta\\c{c}\\~ao de Mestrado, Universidade Federal do Cear\\'a, 2015"]], "COMMENTS": "Dissertation, 83 pages, in Portuguese. in Disserta\\c{c}\\~ao de Mestrado, Universidade Federal do Cear\\'a, 2015", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["elvys linhares pontes"], "accepted": false, "id": "1602.02047"}, "pdf": {"name": "1602.02047.pdf", "metadata": {"source": "CRF", "title": "Elvys Linhares Pontes UTILIZAC\u0327A\u0303O DE GRAFOS E MATRIZ DE SIMILARIDADE NA SUMARIZAC\u0327A\u0303O AUTOMA\u0301TICA DE DOCUMENTOS BASEADA EM EXTRAC\u0327A\u0303O DE FRASES", "authors": ["Elvys Linhares Pontes"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 2.\n02 04\n7v 1\n[ cs\n.C L\n] 5\nF eb\n2 01\n6\nUniversidade Federal do Cear\u00e1\nCampus de Sobral\nPrograma de P\u00f3s-Gradua\u00e7\u00e3o em Engenharia El\u00e9trica e de Computa\u00e7\u00e3o\nElvys Linhares Pontes\nUTILIZA\u00c7\u00c3O DE GRAFOS E MATRIZ DE\nSIMILARIDADE NA SUMARIZA\u00c7\u00c3O AUTOM\u00c1TICA DE\nDOCUMENTOS BASEADA EM EXTRA\u00c7\u00c3O DE FRASES\nSobral\n2015\nElvys Linhares Pontes\nUTILIZA\u00c7\u00c3O DE GRAFOS E MATRIZ DE SIMILARIDADE NA SUMARIZA\u00c7\u00c3O AUTOM\u00c1TICA DE DOCUMENTOS BASEADA EM EXTRA\u00c7\u00c3O DE FRASES\nDisserta\u00e7\u00e3o submetida \u00e0 coordena\u00e7\u00e3o do programa de P\u00f3s-Gradua\u00e7\u00e3o em Engenharia El\u00e9trica e de Computa\u00e7\u00e3o da Universidade Federal do Cear\u00e1, como requisito parcial para obten\u00e7\u00e3o do grau de mestre em Engenheiro El\u00e9trico e de Computa\u00e7\u00e3o.\nOrientadora: Profa. Dra. Andr\u00e9a Carneiro Linhares Co-orientador: Prof. Dr. Juan-Manuel Torres-Moreno\nSobral\n2015\nAGRADECIMENTOS\nAgrade\u00e7o primeiramente a Deus. A minha orientadora Andr\u00e9a e meu co-orientadorJuan-Manuel pela ajuda e paci\u00eancia no trabalho. \u00c0 FUNCAP pelo fomento e \u00e0 Universidade Federal do Cear\u00e1. A todos os meus professores, amigos e a minha querida fam\u00edlia. Em especial, eu quero agradecer a minha namorada Polyanna por sempre me apoiar e incentivar a enfrentar os obst\u00e1culos e aventuras da vida e super\u00e1-los.\nElvys Linhares.\nRESUMO\nA internet possibilitou o aumento da quantidade de informa\u00e7\u00e3o dispon\u00edvel. Entretanto,as pr\u00e1ticas de ler e compreender essas informa\u00e7\u00f5es s\u00e3o tarefas dispendiosas. Nesse cen\u00e1rio, as aplica\u00e7\u00f5es de Processamento de Linguagem Natural (PLN) possibilitam solu\u00e7\u00f5es muito importantes, destacando-se a Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos (SAT), que produz um resumo a partir de um ou mais textos-fontes. Resumir um ou mais textos de forma autom\u00e1tica, contudo, \u00e9 uma tarefa complexa devido \u00e0s dificuldades inerentes \u00e0 an\u00e1lise e gera\u00e7\u00e3o desse resumo. Esta disserta\u00e7\u00e3o descreve as principais t\u00e9cnicas e metodologias (PLN e heur\u00edsticas) para a gera\u00e7\u00e3o de sum\u00e1rios. S\u00e3o igualmente abordados e propostos alguns m\u00e9todos heur\u00edsticos baseados em Grafos e em Matriz de Similaridade para mensurar a relev\u00e2ncia das senten\u00e7as e gerar resumos por extra\u00e7\u00e3o de senten\u00e7as. Foram utilizados os corpus multi-idioma (Espanhol, Franc\u00eas e Ingl\u00eas), CSTNews (Portugu\u00eas do Brasil), RPM (Franc\u00eas) e DECODA (Franc\u00eas) para avaliar os sistemas desenvolvidos e os resultados assim obtidos foram bastante interessantes.\nPalavras-chave: Processamento da Linguagem Natural, Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos, Grafos, Matriz de Similaridade.\nABSTRACT\nThe internet increased the amount of information available. However, the readingand understanding of this information are costly tasks. In this scenario, the Natural Language Processing (NLP) applications enable very important solutions, highlighting the Automatic Text Summarization (ATS), which produce a summary from one or more source texts. Automatically summarizing one or more texts, however, is a complex task because of the difficulties inherent to the analysis and generation of this summary. This master\u2019s thesis describes the main techniques and methodologies (NLP and heuristics) to generate summaries. We have also addressed and proposed some heuristics based on graphs and similarity matrix to measure the relevance of judgments and to generate summaries by extracting sentences. We used the multiple languages (English, French and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA (French) corpus to evaluate the developped systems. The results obtained were quite interesting.\nKeywords: Natural Language Processing, Automatic Text Summarization, Graph, Similarity Matrix.\nLISTA DE FIGURAS\n1 Exemplo de compress\u00e3o de senten\u00e7as utilizando grafos [Filippova 2010]. . . 25 2 Estrutura para fus\u00e3o de senten\u00e7as similares. . . . . . . . . . . . . . . . . . 28 3 Arquitetura do sistema CSTSumm [Jorge, Pardo e Salgueiro 2010]. . . . . 29 4 Estrutura Multi-document Rhetorical Structure (MRS) [Xu et al. 2013]. . . 29 5 Exemplo de um grafo G (a) e seu complemento G\u0304 (b). . . . . . . . . . . . . 36 6 Exemplos de grafo conexo (a) e desconexo (b). . . . . . . . . . . . . . . . . 36 7 Exemplo de Clique. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 8 Exemplo de Subconjunto Independente de V\u00e9rtices (SIV) (a) e Subconjunto\nIndependente M\u00e1ximo (SIM) (b). . . . . . . . . . . . . . . . . . . . . . . . 37\n9 Modelo Espa\u00e7o Vetorial (MEV) do tema global. . . . . . . . . . . . . . . . 39 10 MEV do peso lexical. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 11 Funcionamento do sistema Cortex. . . . . . . . . . . . . . . . . . . . . . . 40 12 Funcionamento do sistema SASI. . . . . . . . . . . . . . . . . . . . . . . . 48 13 Sistema RAG. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 14 Sistema LIA-RAG. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 15 Funcionamento do sistema SUMMatrix. . . . . . . . . . . . . . . . . . . . . 53 16 Sistema SUMMatrix. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\nLISTA DE GR\u00c1FICOS\n7.1 Desempenho do sistema SASI para o corpus multi-idioma. . . . . . . . . . 67 7.2 Avalia\u00e7\u00e3o FRESA dos sistemas usando CSTNews. . . . . . . . . . . . . . . 69 7.3 Avalia\u00e7\u00e3o ROUGE dos sistemas usando CSTNews. . . . . . . . . . . . . . . 69 7.4 Avalia\u00e7\u00e3o ROUGE dos sistemas usando o corpus RPM. . . . . . . . . . . . 71\nLISTA DE TABELAS\n5.1 Texto integrando o cluster do corpus CSTNews [Dias et al. 2014]. . . . . 56 5.2 Relev\u00e2ncia das senten\u00e7as segundo o sistema RAG. . . . . . . . . . . . . . . 57 5.3 Diverg\u00eancia entre as frases dos textos T1 e T2. . . . . . . . . . . . . . . . . 57 5.4 Diverg\u00eancia entre as senten\u00e7as selecionadas e o cluster. . . . . . . . . . . . 57 5.5 Diverg\u00eancia entre as frases do Resumo Parcial e o texto T3. . . . . . . . . 57 5.6 Diverg\u00eancia entre as senten\u00e7as selecionadas e o cluster. . . . . . . . . . . . 58 5.7 Cluster com 3 textos de diferentes jornais relatando um mesmo acidente\nno Congo (corpus CSTNews [Dias et al. 2014]). . . . . . . . . . . . . . . . 59\n6.1 Estat\u00edstica do corpus DECODA. . . . . . . . . . . . . . . . . . . . . . . . . 61 7.1 N\u00edvel de similaridade relacionado \u00e0 diverg\u00eancia JS . . . . . . . . . . . . . . 66 7.2 Tamanho dos resumos obtidos para um conjunto de valores da DJS. . . . . 66 7.3 An\u00e1lise da precis\u00e3o dos resumos gerados automaticamente. . . . . . . . . . 67 7.4 Experimentos com o CSTNews para resumos sem refer\u00eancias. . . . . . . . . 68 7.5 Experimentos com o CSTNews usando resumos de profissionais. . . . . . . 68 7.6 Tempo de execu\u00e7\u00e3o dos sistemas usando o corpus CSTNews. . . . . . . . . 70 7.7 Avalia\u00e7\u00e3o ROUGE dos sistemas utilizando um \u00fanico cluster do RPM. . . . 70 7.8 Avalia\u00e7\u00e3o ROUGE dos sistemas utilizando dois clusters do RPM. . . . . . 71 7.9 Avalia\u00e7\u00e3o dos sistemas usando o corpus de treinamento DECODA. . . . . . 72 7.10 Avalia\u00e7\u00e3o dos sistemas usando o corpus de teste DECODA. . . . . . . . . . 72\nLISTA DE SIGLAS E ACR\u00d4NIMOS\nArtex Autre Resumeur TEXtuel\nCAS Chemical Abstracts Service\nCST Cross-document Structure Theory DVS Decomposi\u00e7\u00e3o de Valores Singulares FMN Fatoriza\u00e7\u00e3o de Matrizes N\u00e3o-negativas\nFRESA FRamework for Evaluating Summaries Automatically JS Jensen-Shannon\nISF Inverse Sentence Frequency KL Kullback-Leibler\nLSA Latent Semantic Analysis MEV Modelo Espa\u00e7o Vetorial\nMRS Multi-document Rhetorical Structure PCM Problema do Caminho M\u00ednimo PLI Programa\u00e7\u00e3o Linear Inteira PLN Processamento da Linguagem Natural\nRAG R\u00e9sumeur Avec de Graphes\nROUGE Recall-Oriented Understudy for Gisting Evaluation SASI Sumarizador Autom\u00e1tico baseado em Subconjunto Independente SAT Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos SIM Subconjunto Independente M\u00e1ximo SIV Subconjunto Independente de V\u00e9rtices\nSUMMatrix SUMmarizer based on Matrix model\nSVR Support Vector Regression\nTF Term Frequency\nTF-IDF Term Frequency - Inverse Document Frequency\nTF-ISF Term Frequency - Inverse Sentence Frequency\nVSM Vector Space Model\nS\u00cdMBOLOS E NOTA\u00c7\u00d5ES\nNesta se\u00e7\u00e3o s\u00e3o apresentados os s\u00edmbolos e as nota\u00e7\u00f5es utilizadas nesta disserta\u00e7\u00e3o.De forma geral, os escalares e os vetores ser\u00e3o representados por letras em it\u00e1lico e as matrizes por letras romanas mai\u00fasculas em negrito. Outras conven\u00e7\u00f5es s\u00e3o listadas a seguir:\nConjuntos e Espa\u00e7os Vetoriais R Conjunto dos n\u00fameros reais Vetores e Matrizes S Matriz de saco de palavras M Matriz de palavras Fun\u00e7\u00f5es e outros operadores logb (\u00b7) Fun\u00e7\u00e3o logar\u00edtmica de base b\nSUM\u00c1RIO\n1 Introdu\u00e7\u00e3o 14\n1.1 Processamento da Linguagem Natural . . . . . . . . . . . . . . . . . . . . . 16\n1.2 Justificativa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n1.3 Objetivos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n1.4 Estrutura . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"}, {"heading": "2 Estado da arte 21", "text": "2.1 Fatora\u00e7\u00e3o de Matrizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.2 Grafos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.3 M\u00e9todos Heur\u00edsticos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.4 Programa\u00e7\u00e3o Linear Inteira . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n2.5 Submodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.6 Sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o . . . . . . . . . . . . . . . . . . . . . . . . . . . 27"}, {"heading": "3 Modelagem do Problema 31", "text": "3.1 Saco de palavras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n3.2 Relev\u00e2ncia das palavras e frases . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.3 Similaridade . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\n3.3.1 Similaridade do cosseno . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.2 Similaridade de Jaccard . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.4 Diverg\u00eancia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.4.1 Diverg\u00eancia de Kullback-Leibler . . . . . . . . . . . . . . . . . . . . 34\n3.4.2 Diverg\u00eancia de Jensen-Shannon . . . . . . . . . . . . . . . . . . . . 34\n3.5 Grafos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.5.1 Conceitos gerais . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.5.2 Problema da Clique e do Subconjunto Independente . . . . . . . . . 36"}, {"heading": "4 Sistemas de Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos na Literatura 38", "text": "4.1 Artex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.2 Cortex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n4.3 Enertex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.4 GistSumm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.5 KLSumm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n4.6 LexRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.7 Programa\u00e7\u00e3o Linear Inteira . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n4.8 Submodular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.9 TextRank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45"}, {"heading": "5 Sistemas propostos 46", "text": "5.1 Sumarizador Autom\u00e1tico baseado em Subconjunto Independente (SASI) . 46\n5.1.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n5.1.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n5.2 R\u00e9sumeur Avec de Graphes (RAG) . . . . . . . . . . . . . . . . . . . . . . 49\n5.2.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5.2.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\n5.3 LIA-RAG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n5.3.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\n5.4 SUMmarizer based on Matrix model (SUMMatrix) . . . . . . . . . . . . . . 52\n5.4.1 Funcionamento . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n5.4.2 Exemplo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54"}, {"heading": "6 Corpus e m\u00e9todos de avalia\u00e7\u00e3o 60", "text": "6.1 Corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.1 Corpus multi-idioma . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.2 CSTNews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n6.1.3 RPM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n6.1.4 DECODA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n6.2 M\u00e9todos de avalia\u00e7\u00e3o . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n6.2.1 M\u00e9tricas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n6.2.2 ROUGE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n6.2.3 FRESA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64"}, {"heading": "7 Avalia\u00e7\u00e3o Experimental 65", "text": "7.1 Avalia\u00e7\u00e3o do sistema SASI (Corpus multi-idioma) . . . . . . . . . . . . . . 65\n7.2 Avalia\u00e7\u00e3o do sistema SUMMatrix (Corpus CSTNews) . . . . . . . . . . . . 68\n7.3 Avalia\u00e7\u00e3o do sistema RAG (Corpus RPM) . . . . . . . . . . . . . . . . . . 70\n7.4 Avalia\u00e7\u00e3o dos sistemas LIA-RAG e RAG (Corpus DECODA) . . . . . . . . 70\n7.5 An\u00e1lise geral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72"}, {"heading": "8 Conclus\u00e3o e Trabalhos Futuros 75", "text": "8.1 Trabalhos futuros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\nRefer\u00eancias Bibliogr\u00e1ficas 77\n14\nCAP\u00cdTULO 1\nINTRODU\u00c7\u00c3O\nO avan\u00e7o tecnol\u00f3gico possibilitou melhorar e aumentar a velocidade de comunica\u00e7\u00e3o mundial atrav\u00e9s da transmiss\u00e3o de v\u00eddeos, imagens e sons. Atualmente, grande parte dos livros possui uma vers\u00e3o digital ou \u00e1udio e a populariza\u00e7\u00e3o das redes sociais (como Facebook, Twitter, Youtube, entre outros) e s\u00edtios de not\u00edcias possibilitaram um grande aumento da quantidade de informa\u00e7\u00f5es trafegadas pela internet acerca dos mais diversos assuntos. Todos os dias, uma quantidade consider\u00e1vel de informa\u00e7\u00f5es \u00e9 adicionada em v\u00e1rios s\u00edtios com coment\u00e1rios, fotos, v\u00eddeos e \u00e1udio. Dessa forma, um acontecimento \u00e9 rapidamente divulgado na Web por diferentes fontes de not\u00edcias e formatos (\u00e1udio, imagem, texto e v\u00eddeo).\nO leitor, al\u00e9m de n\u00e3o possuir tempo h\u00e1bil para ler essa quantidade de informa\u00e7\u00f5es, n\u00e3o se interessa por todos os assuntos propostos e, geralmente, seleciona o conte\u00fado do seu interesse. Vale destacar que grande parte da informa\u00e7\u00e3o criada a todo momento \u00e9 pessoal como, por exemplo, coment\u00e1rios da vida cotidiana, fotos e v\u00eddeos pessoais divulgados em redes sociais e blogs. Assim, parte dessas informa\u00e7\u00f5es n\u00e3o \u00e9 importante para o p\u00fablico em geral. Por isso, os jornais, filmes, livros, revistas, sites e blogs possuem manchetes, sum\u00e1rios ou sinopses dos assuntos abordados. O leitor, ao ler as manchetes de um jornal, identifica o assunto de cada not\u00edcia e, ent\u00e3o, pode escolher qual delas ler na \u00edntegra. O processo \u00e9 similar para livros e filmes com suas sinopses e os destaques nos s\u00edtios e blogs. Dessa forma, o leitor identifica rapidamente o assunto de seu interesse para em seguida dar sequ\u00eancia \u00e0 leitura.\nAs manchetes e sinopses de livros e filmes (entre outros) s\u00e3o tipos de resumos. De forma geral, o \u201cresumo\u201d \u00e9 composto pela ideia principal apresentada no documento original de forma curta e objetiva. Para uma melhor compreens\u00e3o dessa palavra seguem algumas\n1 Introdu\u00e7\u00e3o 15\ndefini\u00e7\u00f5es existentes na literatura e em dicion\u00e1rios:\n\u25ee Condensa\u00e7\u00e3o em poucas palavras do que foi dito ou escrito mais extensamente1;\n\u25ee \u00c9 a abrevia\u00e7\u00e3o, representa\u00e7\u00e3o precisa do conte\u00fado do documento original,\npreferencialmente feita pelo autor do documento;\n\u25ee \u00c9 um produzido de um ou mais textos, que cont\u00e9m as informa\u00e7\u00f5es importantes do\ntexto original, e n\u00e3o pode ser maior que a metade do texto original.\nO resumo deve conter as principais informa\u00e7\u00f5es do texto original de forma clara e concisa possibilitando a compreens\u00e3o do mesmo. Ele pode ser criado utilizando diferentes estrat\u00e9gias. Entretanto, cada uma delas cria um resumo diferente com caracter\u00edsticas espec\u00edficas (boas ou ruins). O homem geralmente segue uma metodologia para criar um resumo. Inicialmente, ele l\u00ea o texto e seleciona as principais informa\u00e7\u00f5es. Com esses dados e seu conhecimento, ele constr\u00f3i novas frases de tamanho menor contendo as informa\u00e7\u00f5es relevantes e a ideia geral contida no texto original.\nOutra caracter\u00edstica fundamental do resumo \u00e9 o seu tamanho. O resumo pode ser produzido em diferentes tamanhos dependendo do fim almejado. Por exemplo, as manchetes de not\u00edcias de jornais e s\u00edtios possuem poucas palavras para chamar a aten\u00e7\u00e3o do leitor e transmitir a ideia chave da not\u00edcia. Entretanto, os textos mais longos necessitam um resumo mais extenso para o leitor compreender o assunto do texto, como \u00e9 o caso de livros, que necessitam resumos maiores que uma not\u00edcia do cotidiano para ter sua ideia geral transmitida. Uma forma de mensurar o tamanho do resumo \u00e9 analisar sua quantidade de palavras ou caracteres. Outra forma poss\u00edvel \u00e9 a taxa de compress\u00e3o tc, que \u00e9 respons\u00e1vel por definir o tamanho do resumo em rela\u00e7\u00e3o ao seu texto original. Ela \u00e9 definida pela equa\u00e7\u00e3o 1.1.\ntc = |resumo|\n|texto| (1.1)\nO resumo \u00e9 um processo de compress\u00e3o que remove o conte\u00fado n\u00e3o relevante e mant\u00e9m as informa\u00e7\u00f5es fundamentais do texto. Quanto menor o valor da tc, menor ser\u00e1 o tamanho do resumo do texto analisado. Essa redu\u00e7\u00e3o, at\u00e9 um certo n\u00edvel, melhora a qualidade do resumo pois ressalta as principais informa\u00e7\u00f5es do mesmo. Entretanto, a redu\u00e7\u00e3o exagerada do texto ocasiona a perda de informa\u00e7\u00f5es relevantes e de sua compreensibilidade. V\u00e1rios trabalhos analisaram a melhor taxa de compress\u00e3o do documento fonte para manter um\n1Dicion\u00e1rio Michaelis online: http://michaelis.uol.com.br"}, {"heading": "1.1 Processamento da Linguagem Natural 16", "text": "resumo pequeno com ideias claras e concisas. Segundo [Lin 1999], a taxa de compress\u00e3o variando entre 0, 15 e 0, 30 possibilita criar bons resumos sem perder as principais informa\u00e7\u00f5es do texto.\nAlguns resumos possuem estrutura e tamanho espec\u00edficos, como \u00e9 caso dos Twitter e SMS [Inouye e Kalita 2011], que cont\u00eam um limite de caracteres pr\u00e9-determinado e diferentes g\u00edrias e abrevia\u00e7\u00f5es. Nesses casos, \u00e9 necess\u00e1rio uma filtragem de express\u00f5es (hashtags, smilefaces, links, entre outros) e um novo vocabul\u00e1rio contendo-as para analisar as mensagens e criar os resumos utilizando-as.\nO resumo facilita e acelera a obten\u00e7\u00e3o de informa\u00e7\u00f5es relevantes para o leitor. Entretanto, a grande quantidade de textos e o custo elevado de resumidores profissionais tornam imposs\u00edvel resumir muitos documentos em tempo h\u00e1bil e com custo acess\u00edvel. Uma solu\u00e7\u00e3o para esse problema apresenta-se atrav\u00e9s da an\u00e1lise e da cria\u00e7\u00e3o autom\u00e1tica de resumos de textos."}, {"heading": "1.1 Processamento da Linguagem Natural", "text": "O Processamento da Linguagem Natural (PLN) \u00e9 uma \u00e1rea de pesquisa envolvendo Lingu\u00edstica, Intelig\u00eancia Artificial e Ci\u00eancias da Computa\u00e7\u00e3o, com o prop\u00f3sito de fazer a intera\u00e7\u00e3o entre a linguagem natural humana e das m\u00e1quinas. \u00c9 necess\u00e1rio um grande conhecimento dos idiomas e express\u00f5es corporais, orais e escritas para realizar a an\u00e1lise correta de um texto, imagem ou video. Os computadores ainda n\u00e3o conseguem realizar esse processo perfeitamente, pois a complexidade para representar e identificar completamente a estrutura sint\u00e1tica e sem\u00e2ntica de um documento \u00e9 elevada. O PLN necessita da [Dyer 1995]:\n\u25ee Representa\u00e7\u00e3o de conhecimentos abstratos;\n\u25ee Aprendizagem de m\u00f3dulos de processamento e troca de informa\u00e7\u00f5es entre eles;\n\u25ee Cria\u00e7\u00e3o e propaga\u00e7\u00e3o de liga\u00e7\u00f5es din\u00e2micas;\n\u25ee Manipula\u00e7\u00e3o de estruturas;\n\u25ee Aquisi\u00e7\u00e3o e acesso a mem\u00f3rias lexicais, sem\u00e2nticas e epis\u00f3dicas.\nO PLN possui diversos campos de estudo: an\u00e1lise do discurso, separa\u00e7\u00e3o morfol\u00f3gica, tradu\u00e7\u00e3o autom\u00e1tica, gera\u00e7\u00e3o e compreens\u00e3o da linguagem natural (mensagem escrita e"}, {"heading": "1.1 Processamento da Linguagem Natural 17", "text": "oral), reconhecimento de caracteres, reconhecimento de discurso e an\u00e1lise de sentimentos, etc. As principais aplica\u00e7\u00f5es do PLN s\u00e3o: Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos (SAT), tradu\u00e7\u00e3o autom\u00e1tica, reconhecimento de discurso, compress\u00e3o textual, corretor autom\u00e1tico e pergunta resposta.\nA SAT consiste em resumir um ou mais textos de forma autom\u00e1tica. Esses textos podem estar presentes em um banco de dados, reposit\u00f3rio local ou remoto. O sistema sumarizador analisa os textos identificando os dados relevantes e cria um novo texto baseado nessas informa\u00e7\u00f5es. Para isso, \u00e9 necess\u00e1rio reconhecer as palavras, a estrutura das senten\u00e7as e analisar a estrutura sint\u00e1tica das frases, verificando as palavras e seus significados em cada senten\u00e7a. Dessa forma, o sistema identifica os dados relevantes e cria um novo texto atrav\u00e9s de par\u00e1frases (ou extra\u00e7\u00e3o de frases) com o conte\u00fado dessas informa\u00e7\u00f5es.\nA tradu\u00e7\u00e3o autom\u00e1tica consiste no processo de traduzir um texto de qualquer idioma para outro. Essa tarefa \u00e9 bem complexa, pois \u00e9 necess\u00e1rio saber a sem\u00e2ntica e a gram\u00e1tica de cada idioma para compreender o texto com suas vari\u00e2ncias lingu\u00edsticas regionais e traduzir as senten\u00e7as para outro idioma. Dessa forma, \u00e9 poss\u00edvel traduzir um texto mantendo a sua coes\u00e3o e coer\u00eancia.\nA extra\u00e7\u00e3o de dados obt\u00e9m as informa\u00e7\u00f5es espec\u00edficas de um ou mais textos. Elas podem ser obtidas de forma simples ou atrav\u00e9s de sin\u00f4nimos, da reordena\u00e7\u00e3o de express\u00f5es ou da an\u00e1lise de express\u00f5es similares para identificar os dados desejados.\nO reconhecimento do discurso realiza o reconhecimento textual de uma mensagem por meio de uma conversa entre pessoas ou de um \u00e1udio. J\u00e1 a compress\u00e3o textual analisa um texto e reduz o seu conte\u00fado mantendo sua informatividade e gramaticalidade. Uma problem\u00e1tica dessa tarefa consiste em como definir mecanismos para avaliar as informa\u00e7\u00f5es mais importantes de um documento e reduzir o texto mantendo-o claro e conciso.\nO corretor autom\u00e1tico analisa o texto e verifica a gram\u00e1tica, concord\u00e2ncia verbal e nominal das senten\u00e7as identificando erros e sugerindo poss\u00edveis corre\u00e7\u00f5es. O sistema pergunta resposta analisa automaticamente os textos com o intuito de encontrar informa\u00e7\u00f5es sobre um determinado tema de uma pergunta e retorna uma resposta (com base nos textos analisados).\nDentre as aplica\u00e7\u00f5es de PLN citadas anteriormente, a SAT foi escolhida como problem\u00e1tica base desta disserta\u00e7\u00e3o. Atualmente, existem diversos sistemas sumarizadores autom\u00e1ticos de textos que analisam diferentes tipos de documentos e estruturas, e criam resumos em formatos distintos. [ARCHANA AB e SUNITHA C 2013]"}, {"heading": "1.2 Justificativa 18", "text": "classificam os sistemas sumarizadores como:\n\u25ee Os resumos s\u00e3o criados pelos processos de abstra\u00e7\u00e3o ou extra\u00e7\u00e3o de senten\u00e7as.\nA abstra\u00e7\u00e3o gera um resumo a partir da cria\u00e7\u00e3o de novas frases com base no texto original. Ela requer um conhecimento mais avan\u00e7ado da estrutura do idioma incluindo suas regras gramaticais e de constru\u00e7\u00e3o de senten\u00e7as. Ela possibilita ainda uma melhor an\u00e1lise do texto e da mensagem. A extra\u00e7\u00e3o geralmente utiliza menos recursos das linguagens e se concentra em criar resumos a partir das estruturas j\u00e1 existentes no texto. Usualmente, s\u00e3o utilizadas regras estat\u00edsticas para avaliar a relev\u00e2ncia das senten\u00e7as e o resumo \u00e9 criado a partir daquelas consideradas mais relevantes.\n\u25ee H\u00e1 sum\u00e1rios gen\u00e9ricos ou voltados a um tema espec\u00edfico. Os resumos gen\u00e9ricos\nn\u00e3o diferenciam o conte\u00fado abordado nos documentos e realizam o mesmo tipo de an\u00e1lise em todos os textos. Os direcionados a um tema possuem regras e conceitos mais avan\u00e7ados para uma \u00e1rea de an\u00e1lise. Por exemplo, os resumos voltados para a \u00e1rea da sa\u00fade necessitam e consideram conceitos e regras mais espec\u00edficos dos termos encontrados nesses documentos.\n\u25ee A cria\u00e7\u00e3o de resumos pode ser mono ou multidocumento. A sumariza\u00e7\u00e3o\nmonodocumento analisa um texto e cria o resumo com as principais informa\u00e7\u00f5es do mesmo. A multidocumento analisa geralmente um cluster de documentos. Esse cluster pode conter informa\u00e7\u00f5es similares (ou n\u00e3o) de uma mesma \u00e9poca (ou n\u00e3o).\n\u25ee Os resumos podem ser indicativos ou informativos. Os indicativos fornecem a\ninforma\u00e7\u00e3o geral do texto sem conter informa\u00e7\u00f5es espec\u00edficas. Os informativos fornecem a informa\u00e7\u00e3o geral do texto juntamente com dados espec\u00edficos do documento original.\n\u25ee O sum\u00e1rio pode conter somente as informa\u00e7\u00f5es-chave sem descrever dados b\u00e1sicos,\ncomo tamb\u00e9m pode conter dados b\u00e1sicos para auxiliar o leitor a compreender melhor o assunto descrito."}, {"heading": "1.2 Justificativa", "text": "Como mencionado anteriormente, a grande quantidade de informa\u00e7\u00e3o existente e o tempo limitado para ler os textos por uma pessoa se tornou um problema na sociedade moderna. A SAT \u00e9 uma ferramenta bastante \u00fatil a fim de propor solu\u00e7\u00f5es para esse"}, {"heading": "1.3 Objetivos 19", "text": "problema e agilizar o processo de identifica\u00e7\u00e3o e leitura de textos. Algumas facilidades e/ou vantagens em utilizar a sumariza\u00e7\u00e3o s\u00e3o [ARCHANA AB e SUNITHA C 2013]:\n\u25ee O resumo economiza o tempo de leitura possibilitando ao leitor identificar\nrapidamente o assunto principal do texto.\n\u25ee O resumo facilita a busca e a sele\u00e7\u00e3o de textos na literatura.\n\u25ee Melhora a qualidade de indexa\u00e7\u00e3o dos documentos.\n\u25ee Os algoritmos de sumariza\u00e7\u00e3o autom\u00e1tica n\u00e3o t\u00eam prefer\u00eancias sobre assuntos ou\ncoisas possibilitando a cria\u00e7\u00e3o de um resumo sem uma poss\u00edvel an\u00e1lise tendenciosa da opini\u00e3o de um resumidor profissional."}, {"heading": "1.3 Objetivos", "text": "Os principais objetivos desta disserta\u00e7\u00e3o s\u00e3o pesquisar e desenvolver sistemas de SAT por extra\u00e7\u00e3o de senten\u00e7as nos idiomas Franc\u00eas e Portugu\u00eas. Inicialmente, ser\u00e3o analisadas diferentes metodologias para criar resumos como, por exemplo, matriz de similaridade, conjunto est\u00e1vel e algoritmos em grafos. Ser\u00e3o explorados e analisados diversos sistemas sumarizadores na literatura a fim de estudar seus funcionamentos e utiliz\u00e1-los como refer\u00eancia para a avalia\u00e7\u00e3o qualitativa dos sistemas aqui propostos.\nSer\u00e3o desenvolvidos quatro sistemas sumarizadores independentes de idioma: RAG, LIA-RAG, SASI e SUMMatrix para sumarizar (multi)documentos em Franc\u00eas e Portugu\u00eas. O RAG, LIA-RAG e SASI utiliza a Teoria de Grafos e o SUMMatrix integra o uso de matrizes de similaridade. Outra parte do trabalho analisar\u00e1 os sistemas respons\u00e1veis pela an\u00e1lise qualitativa autom\u00e1tica de resumos. Ser\u00e3o estudados e utilizados os sistemas FRamework for Evaluating Summaries Automatically (FRESA) e Recall-Oriented Understudy for Gisting Evaluation (ROUGE) para avaliar a qualidade dos resumos atrav\u00e9s das m\u00e9tricas precis\u00e3o, cobertura e medida-f ."}, {"heading": "1.4 Estrutura", "text": "O restante desta disserta\u00e7\u00e3o est\u00e1 estruturado da seguinte forma:\n\u25ee O cap\u00edtulo 2 aborda o estado da arte envolvendo os trabalhos em SAT. S\u00e3o descritas\ndiferentes metodologias para analisar os textos e produzir seus respectivos resumos."}, {"heading": "1.4 Estrutura 20", "text": "\u25ee O cap\u00edtulo 3 descreve a modelagem matem\u00e1tica e as f\u00f3rmulas utilizadas para calcular\na relev\u00e2ncia, similaridade, diverg\u00eancia e identificar as senten\u00e7as principais dos textos.\n\u25ee O cap\u00edtulo 4 descreve o funcionamento dos principais tipos de sistemas de SAT na\nliteratura.\n\u25ee O cap\u00edtulo 5 analisa a estrutura e a metodologia dos sistemas propostos nesta\ndisserta\u00e7\u00e3o (LIA-RAG, RAG, SASI e SUMMatrix).\n\u25ee O cap\u00edtulo 6 detalha a estrutura e as caracter\u00edsticas de cada corpus2 utilizado na\navalia\u00e7\u00e3o dos sistemas.\n\u25ee O cap\u00edtulo 7 descreve os resultados obtidos para cada corpus e a an\u00e1lise geral dos\nsistemas.\n\u25ee O cap\u00edtulo 8 conclui esta disserta\u00e7\u00e3o destacando os pontos positivos e negativos dos\nresultados obtidos e os poss\u00edveis trabalhos futuros.\n2O corpus \u00e9 um conjunto estruturado de documentos com determinadas caracter\u00edsticas.\n21\nCAP\u00cdTULO 2\nESTADO DA ARTE\nOs primeiros trabalhos acerca da sumariza\u00e7\u00e3o autom\u00e1tica de documentos abordavam somente textos jornal\u00edsticos atrav\u00e9s de t\u00e9cnicas simples baseadas na frequ\u00eancia das palavras para avaliar a relev\u00e2ncia das frases [Luhn 1958]. Os resumos de profissionais possuem \u00f3tima qualidade em termos de informatividade e legibilidade. Entretanto, sua produ\u00e7\u00e3o \u00e9 mais lenta, cara e sujeita \u00e0 subjetividade do profissional. Em contrapartida, os resumos produzidos de modo autom\u00e1tico t\u00eam custo de produ\u00e7\u00e3o bem reduzido, inexist\u00eancia de problemas de subjetividade e de variabilidade observados nas proposi\u00e7\u00f5es dos resumidores profissionais, dentre outros. Verificou-se, assim, a necessidade de gerar resumos autom\u00e1ticos visando essas facilidades e a fim de lidar com o crescimento da quantidade de informa\u00e7\u00f5es.\n[Edmundson 1969] deu continuidade aos trabalhos de Luhn, adicionando ao processo\nde produ\u00e7\u00e3o de resumos considera\u00e7\u00f5es sobre posi\u00e7\u00e3o das frases e presen\u00e7a de palavras provenientes da estrutura do documento (por exemplo, t\u00edtulos, sub-t\u00edtulos, etc.). As pesquisas desenvolvidas em Chemical Abstracts Service (CAS) [Pollock e Zamora 1975], concernentes \u00e0 produ\u00e7\u00e3o de sum\u00e1rios a partir de artigos cient\u00edficos de Qu\u00edmica, permitiram validar a viabilidade das abordagens de extra\u00e7\u00e3o autom\u00e1tica de frases. Uma \u201climpeza\u201d das frases atrav\u00e9s de opera\u00e7\u00f5es de elimina\u00e7\u00e3o foi introduzida pela primeira vez. No intuito de adequar os resumos aos padr\u00f5es impostos pela CAS, uma normaliza\u00e7\u00e3o do vocabul\u00e1rio era efetuada. A normaliza\u00e7\u00e3o incluiu a substitui\u00e7\u00e3o de palavras/frases por suas abrevia\u00e7\u00f5es e uma padroniza\u00e7\u00e3o das variantes ortogr\u00e1ficas. Os estudos sobre SAT podem ser divididos em dois grupos, extra\u00e7\u00e3o e abstra\u00e7\u00e3o de texto. No primeiro grupo, h\u00e1 a identifica\u00e7\u00e3o das partes mais relevantes de um ou mais textos, atrav\u00e9s de t\u00e9cnicas de recupera\u00e7\u00e3o de informa\u00e7\u00e3o estat\u00edstica para mensurar a relev\u00e2ncia das frases e gerar o resumo atrav\u00e9s"}, {"heading": "2 Estado da arte 22", "text": "da concatena\u00e7\u00e3o das mesmas. O trabalho de [Wu, Hsu e Tan 1992] descreve v\u00e1rios m\u00e9todos estat\u00edsticos utilizados no processo de sumariza\u00e7\u00e3o de textos. A abstra\u00e7\u00e3o analisa o texto original de uma forma lingu\u00edstica profunda, interpreta o texto semanticamente em uma representa\u00e7\u00e3o formal, encontra novos conceitos mais concisos para descrev\u00ea-lo e, em seguida, gera um novo texto mais curto com o mesmo sentido do texto original com as informa\u00e7\u00f5es relevantes apresentadas de forma concisa (fus\u00e3o, par\u00e1frase, etc) [Hovy e Lin 1998].\nExistem diversos m\u00e9todos para analisar a relev\u00e2ncia das senten\u00e7as e construir um resumo. [SARANYAMOL CS e SINDHU L 2014] classificaram esses m\u00e9todos em: Term Frequency - Inverse Document Frequency (TF-IDF), Cluster, Teoria dos Grafos, Aprendizado de M\u00e1quina, Latent Semantic Analysis (LSA), Redes Neurais e L\u00f3gica Fuzzy. Normalmente, esses m\u00e9todos baseiam-se em c\u00e1lculos estat\u00edsticos para verificar a relev\u00e2ncia das senten\u00e7as. Por isso eles n\u00e3o analisam corretamente a estrutura e a sem\u00e2ntica do texto, ocasionando erros gramaticais e sint\u00e1ticos e reduzindo a coes\u00e3o e coer\u00eancia do resumo.\nDe forma geral, os trabalhos voltados \u00e0 extra\u00e7\u00e3o de frases utilizam a seguinte\nmetodologia de produ\u00e7\u00e3o de sum\u00e1rios:\n\u25ee Pr\u00e9-processamento do texto;\n\u25ee Identifica\u00e7\u00e3o das frases em destaque no documento;\n\u25ee Constru\u00e7\u00e3o do sum\u00e1rio por concatena\u00e7\u00e3o das frases extra\u00eddas.\nO pr\u00e9-processamento do texto ou do cluster geralmente se inicia com o processo de segmenta\u00e7\u00e3o do texto para identificar frases, palavras e pontua\u00e7\u00f5es. Em seguida, identifica-se qual \u00e9 o idioma do texto e realiza-se o processo de filtragem, em que s\u00e3o removidos os stopwords (palavras sem relev\u00e2ncia para o texto e para o conte\u00fado), e o processo de stemming, em que as palavras s\u00e3o reduzidas a seus radicais, evitando-se suas flex\u00f5es (singular e plural, masculino e feminino, deriva\u00e7\u00f5es de palavras e verbos).\nA identifica\u00e7\u00e3o das frases relevantes no texto \u00e9 normalmente feita atrav\u00e9s de uma pondera\u00e7\u00e3o que faz uso de m\u00e9todos estat\u00edsticos: an\u00e1lise da frequ\u00eancia das palavras nas senten\u00e7as e no texto em geral, determina\u00e7\u00e3o da energia textual das senten\u00e7as [Fern\u00c1ndez, SanJuan e Torres-Moreno 2007], modelagem das senten\u00e7as como vetores [Torres-Moreno 2012], grupos de v\u00e9rtices num grafo [Pontes, Linhares e Torres-Moreno 2014], entre outros.\nA parte final do processo de sumariza\u00e7\u00e3o \u00e9 a gera\u00e7\u00e3o de textos, que pode ser realizada atrav\u00e9s de diversas t\u00e9cnicas. Os m\u00e9todos de sumariza\u00e7\u00e3o por extra\u00e7\u00e3o geralmente utilizam"}, {"heading": "2.1 Fatora\u00e7\u00e3o de Matrizes 23", "text": "a abordagem de concatenar as senten\u00e7as relevantes [Torres-Moreno 2012,Pontes, Linhares e Torres-Moreno 2014]. Esse m\u00e9todo \u00e9 simples e r\u00e1pido, mas pode criar v\u00e1rios problemas de coes\u00e3o e coer\u00eancia devido \u00e0 possibilidade das frases selecionadas n\u00e3o apresentarem conex\u00e3o entre si e assim, incorrer na perda do fluxo e da compreens\u00e3o do texto.\nA abordagem por abstra\u00e7\u00e3o utiliza m\u00e9todos mais complexos e elaborados para gerar\nsenten\u00e7as (fus\u00e3o de senten\u00e7as, gera\u00e7\u00e3o de par\u00e1frases, etc) [Filippova 2010,Seno 2010].\nAnalisamos os trabalhos relacionados \u00e0s principais metodologias utilizadas na literatura para a sumariza\u00e7\u00e3o de textos com o intuito de analisar diferentes metodologias e compar\u00e1-las com os sistemas propostos nesta disserta\u00e7\u00e3o. As se\u00e7\u00f5es seguintes discorrem sobre: Fatora\u00e7\u00e3o de Matrizes (se\u00e7\u00e3o 2.1), Grafos (se\u00e7\u00e3o 2.2), M\u00e9todos Heur\u00edsticos (se\u00e7\u00e3o 2.3), Programa\u00e7\u00e3o Linear Inteira (PLI) (se\u00e7\u00e3o 2.4) e Submodular (se\u00e7\u00e3o 2.5). A se\u00e7\u00e3o 2.6 mostra alguns trabalhos de sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o de senten\u00e7as voltados ao Portugu\u00eas Brasileiro e Ingl\u00eas."}, {"heading": "2.1 Fatora\u00e7\u00e3o de Matrizes", "text": "A Decomposi\u00e7\u00e3o de Valores Singulares (DVS) \u00e9 um dos m\u00e9todos de fatoriza\u00e7\u00e3o de matrizes bem estudado na literatura. A DVS \u00e9 usada em \u00e1lgebra linear para minimizar erros computacionais em opera\u00e7\u00f5es com matrizes de grande porte [Lay 2011]. A decomposi\u00e7\u00e3o fatoriza a matriz M em tr\u00eas matrizes, I, A e X, de tal forma que M = I \u00d7A\u00d7XT . A matriz I \u00e9 uma matriz unit\u00e1ria de dimens\u00e3o m\u00d7n cujas colunas s\u00e3o vetores ortonormais. A matriz A \u00e9 uma matriz diagonal n\u00d7n, cujos elementos diagonais s\u00e3o valores singulares n\u00e3o negativos, ordenados de forma decrescente. Finalmente, a matriz transposta de X (XT ) \u00e9 uma matriz ortogonal de dimens\u00e3o n \u00d7 n, cujas colunas s\u00e3o chamadas de vetores singulares \u00e0 direita.\nA LSA \u00e9 um m\u00e9todo n\u00e3o supervisionado de obten\u00e7\u00e3o de espa\u00e7o vetorial representando a sem\u00e2ntica de um grande corpus de textos. Esse m\u00e9todo representa uma cole\u00e7\u00e3o de documentos atrav\u00e9s da distribui\u00e7\u00e3o dos termos do documento em uma matriz M. A LSA utiliza a DVS para decompor a matriz M e obter as matrizes I, A e X.\nOs primeiros (maiores) valores na diagonal da matriz A s\u00e3o postos a zero, resultando em uma esp\u00e9cie de an\u00e1lise de componentes principais. Esse processo reduz eficazmente a dimensionalidade das palavras para cada vetor [Landauer et al. 2007].\nNo contexto da aplica\u00e7\u00e3o em sumariza\u00e7\u00e3o autom\u00e1tica, o documento \u00e9 modelado como uma matriz M representando a ocorr\u00eancia dos termos por senten\u00e7a (i.e., uma matriz com"}, {"heading": "2.2 Grafos 24", "text": "m linhas, que representam os termos \u00fanicos, e com n colunas, que representam cada frase). A DVS \u00e9 utilizada para reduzir o n\u00famero de linhas (i.e., os termos correlacionados s\u00e3o agrupados em conceitos, capturando fen\u00f4menos como a sinon\u00edmia entre termos), preservando a estrutura de similaridade entre as colunas (i.e., entre as frases).\nUm algoritmo simples pode ser usado para selecionar a(s) melhor(es) frase(s), com base na decomposi\u00e7\u00e3o DVS e no uso da matriz de valores singulares \u00e0 direita XT . Cada senten\u00e7a i \u00e9 representada pelo vetor coluna [xj1, xj2, . . . , xjn]T da matriz XT . Uma abordagem simples \u00e9 selecionar o primeiro vetor singular direito da matriz XT e em seguida a(s) frase(s) que t\u00eam o maior valor \u00edndice no vetor. Ap\u00f3s isso, se necess\u00e1rio, efetua-se o mesmo processo para o segundo vetor singular direito da matriz, at\u00e9 se chegar ao n\u00famero desejado de frases a serem selecionadas para a constru\u00e7\u00e3o do sum\u00e1rio [Gong e Liu 2001].\nNa proposta original de [Lee e Seung 1999], a Fatoriza\u00e7\u00e3o de Matrizes N\u00e3o-negativas (FMN) decompunha uma matriz M em duas matrizes n\u00e3o-negativas Y e Z, de forma que M = Y\u00d7Z, onde Y \u00e9 uma matriz n\u00e3o-negativa de caracter\u00edsticas sem\u00e2nticas (i.e., a matriz dos termos) e Z \u00e9 uma matriz n\u00e3o negativa de vari\u00e1veis sem\u00e2nticas (i.e., a matriz das frases). Um dos algoritmos mais populares para encontrar decomposi\u00e7\u00f5es FMN \u00e9 baseado numa regra de atualiza\u00e7\u00e3o multiplicativa que atualiza iterativamente as matrizes Y e Z at\u00e9 obter a converg\u00eancia de uma fun\u00e7\u00e3o objetiva ou at\u00e9 o algoritmo exceder um determinado n\u00famero de passos."}, {"heading": "2.2 Grafos", "text": "Os m\u00e9todos relacionados \u00e0 Teoria dos Grafos consideram um grafo n\u00e3o-direcionado G = (V,E) composto por um conjunto de v\u00e9rtices V e um conjunto de arestas E. Existem diversas formas de modelizar o texto utilizando grafos. Filippova [Filippova 2010] utilizou cada palavra como um n\u00f3 no grafo e o fluxo das senten\u00e7as para determinar a exist\u00eancia de arcos entre os v\u00e9rtices. [Pontes, Linhares e Torres-Moreno 2014] consideram cada v\u00e9rtice representando uma senten\u00e7a no texto e as arestas representam a exist\u00eancia de similaridade entre dois v\u00e9rtices (senten\u00e7as). [Baralis et al. 2013] modelizam o texto utilizando grafos para representar os termos dos textos.\nMihalcea desenvolveu algoritmos de classifica\u00e7\u00e3o baseados em grafos, tais como PageRank [Mihalcea 2004]. Esses algoritmos foram utilizados com sucesso nas redes sociais, na an\u00e1lise do n\u00famero de cita\u00e7\u00f5es ou no estudo da estrutura da Web. Eles permitem"}, {"heading": "2.2 Grafos 25", "text": "tomar decis\u00f5es acerca da import\u00e2ncia de um v\u00e9rtice, baseando-se na informa\u00e7\u00e3o global advinda da an\u00e1lise recursiva do grafo completo e n\u00e3o na an\u00e1lise local do v\u00e9rtice. No \u00e2mbito da sumariza\u00e7\u00e3o autom\u00e1tica, observa-se que o documento \u00e9 representado por um grafo de unidades textuais (frases) conectadas entre si atrav\u00e9s de rela\u00e7\u00f5es oriundas de c\u00e1lculos de similaridade. As frases s\u00e3o em seguida selecionadas segundo crit\u00e9rios de centralidade ou de prest\u00edgio no grafo, e agrupadas a fim de produzir os extratos do texto [Ferreira et al. 2014].\nBaralis et al. tamb\u00e9m utilizaram a modelagem de grafos para sumarizar textos [Baralis et al. 2013]. Entretanto, sua metodologia \u00e9 composta por: processamento do texto, correla\u00e7\u00e3o do grafo, indexa\u00e7\u00e3o do grafo e sele\u00e7\u00e3o de senten\u00e7as. O processamento realiza a stemming e a remo\u00e7\u00e3o dos stopwords. A correla\u00e7\u00e3o do grafo \u00e9 feita a partir dos conjuntos de itens frequentes no texto. A indexa\u00e7\u00e3o do grafo d\u00e1-se atrav\u00e9s de um algoritmo baseado no PageRank para ponderar os n\u00f3s do grafo. A gera\u00e7\u00e3o do resumo seleciona as senten\u00e7as com melhor pondera\u00e7\u00e3o baseada na indexa\u00e7\u00e3o dos n\u00f3s.\nFilippova descreve outro m\u00e9todo atrav\u00e9s da fus\u00e3o multissenten\u00e7a, apoiado em uma estrutura de grafo para representar palavras e frases [Filippova 2010]. Os arcos do grafo s\u00e3o ponderados com a frequ\u00eancia de palavras e a posi\u00e7\u00e3o nas frases. A fus\u00e3o \u00e9 realizada atrav\u00e9s do c\u00e1lculo do menor caminho no grafo de palavras. A figura 1 exemplifica a fus\u00e3o utilizando v\u00e1rias senten\u00e7as similares para criar uma nova senten\u00e7a com o conte\u00fado que as representa.\nFigura 1 \u2013 Exemplo de compress\u00e3o de senten\u00e7as utilizando grafos [Filippova 2010].\nO trabalho de Pontes et al usa a Teoria dos Grafos concomitante com a diverg\u00eancia Jensen-Shannon (JS) para criar resumos multi-documentos por extra\u00e7\u00e3o [Pontes, Linhares"}, {"heading": "2.3 M\u00e9todos Heur\u00edsticos 26", "text": "e Torres-Moreno 2014]. O sistema representa o texto atrav\u00e9s de um grafo onde as frases correspondem aos v\u00e9rtices e as arestas representam a similaridade entre duas senten\u00e7as (v\u00e9rtices). Portanto, o grupo de v\u00e9rtices interligados no grafo representa senten\u00e7as com conte\u00fado similar. O sistema calcula o conjunto est\u00e1vel m\u00e1ximo do grafo visando criar o resumo com frases contendo informa\u00e7\u00f5es gerais do cluster e sem redund\u00e2ncia. Por isso, o sistema seleciona geralmente uma frase de cada grupo, reduzindo a quantidade de senten\u00e7as muito similares."}, {"heading": "2.3 M\u00e9todos Heur\u00edsticos", "text": "Torres desenvolveu v\u00e1rios m\u00e9todos heur\u00edsticos para sumariza\u00e7\u00e3o por extra\u00e7\u00e3o. Em [Torres-Moreno 2012], o texto \u00e9 representado como um Vector Space Model (VSM) e cada senten\u00e7a possui um vetor que descreve o tema do texto. A partir desse vetor, calcula-se a relev\u00e2ncia de cada frase para construir o resumo. O trabalho de [Boudin e Torres-Moreno 2007] utiliza diferentes c\u00e1lculos num\u00e9ricos para determinar a relev\u00e2ncia das senten\u00e7as. [Fern\u00c1ndez, SanJuan e Torres-Moreno 2007] calculam a energia textual das senten\u00e7as que representa a relev\u00e2ncia de cada uma delas com rela\u00e7\u00e3o ao texto. Esses m\u00e9todos ser\u00e3o melhores descritos no cap\u00edtulo 4."}, {"heading": "2.4 Programa\u00e7\u00e3o Linear Inteira", "text": "Uma forma de melhorar a qualidade do resumo \u00e9 maximizar a sele\u00e7\u00e3o das senten\u00e7as mais relevantes. A Programa\u00e7\u00e3o Linear Inteira (PLI) modela a sumariza\u00e7\u00e3o de textos de forma a maximizar a qualidade da extra\u00e7\u00e3o de senten\u00e7as por meio de an\u00e1lises do texto.\nA PLI consiste em maximizar ou minimizar uma fun\u00e7\u00e3o sujeita a um conjunto de restri\u00e7\u00f5es3. Mcdonald [Mcdonald 2006] considerou a informatividade e a redund\u00e2ncia das senten\u00e7as como pontos fundamentais para a SAT. Ele avalia a qualidade do resumo a partir da relev\u00e2ncia das frases com a inser\u00e7\u00e3o de uma penalidade para as senten\u00e7as redundantes do resumo.\n[Gillick e Favre 2009] basearam-se no modelo de Mcdonald para abordar o modelo de\nescalas de forma. Os autores tratam a redund\u00e2ncia das senten\u00e7as sem necessitar de um n\u00famero quadr\u00e1tico de vari\u00e1veis, facilitando a modelagem e resolu\u00e7\u00e3o do problema. Eles tamb\u00e9m modelam esse problema na formula\u00e7\u00e3o PLI realizando a compress\u00e3o e a sele\u00e7\u00e3o de senten\u00e7as simultaneamente.\n3A se\u00e7\u00e3o 4.7 descrever\u00e1 melhor a modelagem da PLI para a sumariza\u00e7\u00e3o de textos"}, {"heading": "2.5 Submodular 27", "text": "J\u00e1 [Galanis, Lampouras e Androutsopoulos 2012] adicionaram o modelo Support Vector Regression (SVR) para mensurar a relev\u00e2ncia das senten\u00e7as a partir do treinamento dos sistemas com resumos produzidos por humanos. Esse modelo avalia a relev\u00e2ncia das senten\u00e7as baseando-se em sua diversidade."}, {"heading": "2.5 Submodular", "text": "Seja B um conjunto finito e seja f uma fun\u00e7\u00e3o de partes de B em R. A fun\u00e7\u00e3o f \u00e9 submodular se, para quaisquer partes C e D de B, observa-se a rela\u00e7\u00e3o exposta na equa\u00e7\u00e3o 2.1.\nf(C \u222aD) + f(C \u2229D) \u2264 f(C) + f(D) (2.1)\nSeja um conjunto de objetos B e uma fun\u00e7\u00e3o f que retorna um valor real para qualquer subconjunto C \u2286 B. O objetivo \u00e9 escolher um subconjunto com tamanho limitado a um certo valor que maximize a fun\u00e7\u00e3o [Krause et al. 2008]. A SAT por extra\u00e7\u00e3o seleciona um subconjunto (conjunto de senten\u00e7as) C \u2286 B para representar o documento de tal forma que o resumo tenha o tamanho m\u00e1ximo de L palavras.\n[Lin e Bilmes 2011] projetaram uma classe de fun\u00e7\u00f5es submodulares voltadas \u00e0\ncompacta\u00e7\u00e3o de senten\u00e7as objetivando a diversidade e a representatividade do corpus. As fun\u00e7\u00f5es s\u00e3o n\u00e3o-decrescentes, mon\u00f3tonas e submodulares, possibilitando um desempenho ideal de fator constante. Outra possibilidade \u00e9 a aprendizagem supervisionada de fun\u00e7\u00f5es submodulares para a extra\u00e7\u00e3o de senten\u00e7as. [Sipos, Shivaswamy e Joachims 2012] aplicam esse m\u00e9todo de aprendizagem a diversos m\u00e9todos de compacta\u00e7\u00e3o submodulares e demonstram sua efic\u00e1cia com base na an\u00e1lise de v\u00e1rios conjuntos de dados."}, {"heading": "2.6 Sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o", "text": "A sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o geralmente usa m\u00e9todos mais complexos de an\u00e1lise, pois eles permitem verificar o conte\u00fado do documento e possibilitam que o sistema sumarizador possa \u201csaber\u201d quais informa\u00e7\u00f5es est\u00e3o presentes no mesmo. Possui uma abordagem baseada na estrutura e na sem\u00e2ntica. A abordagem estruturada codifica a informa\u00e7\u00e3o mais importante do documento por meio de esquemas cognitivos tais como modelos, regras de extra\u00e7\u00e3o, e estruturais, tais como conhecimento base e estrutura da frase. O m\u00e9todo sem\u00e2ntico, por sua vez, concentra-se na identifica\u00e7\u00e3o de frases nominais e verbais"}, {"heading": "2.6 Sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o 28", "text": "por meio de dados lingu\u00edsticos para que o sistema de gera\u00e7\u00e3o da linguagem natural possa criar o resumo do texto analisado.\nA sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o geralmente usa a fus\u00e3o de frases ou gera\u00e7\u00e3o de par\u00e1frases\npara revisar as informa\u00e7\u00f5es e evitar redund\u00e2ncias em um texto [Seno 2010].\nA fus\u00e3o por uni\u00e3o preserva a mensagem geral do cluster, enquanto a fus\u00e3o por interse\u00e7\u00e3o analisa as informa\u00e7\u00f5es redundantes presentes no mesmo. Seno prop\u00f4s um m\u00e9todo de fus\u00e3o de senten\u00e7as similares em Portugu\u00eas utilizando uma abordagem simb\u00f3lica e independente de dom\u00ednio (figura 2) [Seno 2010]. Esse m\u00e9todo permite mesclar as sumariza\u00e7\u00f5es por uni\u00e3o e interse\u00e7\u00e3o de um cluster de documentos. J\u00e1 no trabalho de [Seno e Nunes 2008] \u00e9 descrita uma metodologia para identificar informa\u00e7\u00f5es comuns entre frases em Portugu\u00eas usando o conhecimento lexical, sint\u00e1tico e regras sem\u00e2nticas de par\u00e1frase.\nFigura 2 \u2013 Estrutura para fus\u00e3o de senten\u00e7as similares.\nEm [Jorge, Pardo e Salgueiro 2010] \u00e9 desenvolvido um m\u00e9todo de compacta\u00e7\u00e3o multi-documento baseado no modelo Cross-document Structure Theory (CST). Esse m\u00e9todo analisa a redund\u00e2ncia, a complementaridade e a contradi\u00e7\u00e3o entre as diferentes fontes de informa\u00e7\u00e3o para calcular a relev\u00e2ncia das senten\u00e7as. Em seguida, os operadores s\u00e3o utilizados no aux\u00edlio do processo de repondera\u00e7\u00e3o das senten\u00e7as a fim de criar um resumo com algumas caracter\u00edsticas escolhidas pelo usu\u00e1rio. Por fim, o resumo \u00e9 gerado a partir das senten\u00e7as de maior pondera\u00e7\u00e3o (figura 3).\nO trabalho de [Xu et al. 2013] usa os conceitos de \u00e1rvore t\u00f3pica hier\u00e1rquica, ret\u00f3rica e rela\u00e7\u00e3o temporal para calcular as inter-rela\u00e7\u00f5es entre as unidades do texto. Ele utiliza ainda a estrutura Multi-document Rhetorical Structure (MRS) (figura 4) para representar o texto em diferentes n\u00edveis de granularidade (incluindo frases, par\u00e1grafos, se\u00e7\u00f5es e documentos). Seu algoritmo de extra\u00e7\u00e3o realiza etapas de pondera\u00e7\u00e3o e remo\u00e7\u00e3o de n\u00f3s a fim de selecionar as senten\u00e7as mais importantes. Primeiramente, ele executa o algoritmo de pondera\u00e7\u00e3o dos n\u00f3s para, em seguida, utilizar um algoritmo de clustering no intuito"}, {"heading": "2.6 Sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o 29", "text": "Figura 3 \u2013 Arquitetura do sistema CSTSumm [Jorge, Pardo e Salgueiro 2010].\nde identificar senten\u00e7as similares e remover as que s\u00e3o redundantes.\nFigura 4 \u2013 Estrutura MRS [Xu et al. 2013].\nBarzilay et al. desenvolveram um m\u00e9todo de gera\u00e7\u00e3o autom\u00e1tica de resumos atrav\u00e9s da identifica\u00e7\u00e3o e sintetiza\u00e7\u00e3o de elementos semelhantes em um conjunto de documentos [Barzilay, McKeown e Elhadad 1999]. Esse m\u00e9todo seleciona o conte\u00fado dos textos a partir da similaridade das frases relacionadas com o tema discutido a fim de criar um novo texto. No trabalho de [Barzilay e McKeown 2005] \u00e9 descrita uma abordagem para fusionar frases por meio da t\u00e9cnica de gera\u00e7\u00e3o text-to-text4 de modo a sintetizar informa\u00e7\u00f5es repetidas de v\u00e1rios documentos. Esse m\u00e9todo utiliza um alinhamento sint\u00e1tico nas frases para identificar informa\u00e7\u00f5es comuns \u00e0s mesmas. Ap\u00f3s a etapa de identifica\u00e7\u00e3o, as senten\u00e7as s\u00e3o processadas e um novo texto \u00e9 gerado mantendo a mesma ideia original.\nUma maneira de calcular a similaridade entre frases \u00e9 atrav\u00e9s da co-ocorr\u00eancia de 4A gera\u00e7\u00e3o text-to-text \u00e9 reconfigura\u00e7\u00e3o de um texto atrav\u00e9s da: reformula\u00e7\u00e3o, reorganiza\u00e7\u00e3o,\ncombina\u00e7\u00e3o ou divis\u00e3o das senten\u00e7as e elimina\u00e7\u00e3o do conte\u00fado."}, {"heading": "2.6 Sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o 30", "text": "palavras. Em [He et al. 2008] \u00e9 proposto um m\u00e9todo de fus\u00e3o usando m\u00e9tricas de similaridade, co-ocorr\u00eancia Skip-bigrama5 e densidade de informa\u00e7\u00e3o para calcular o valor das senten\u00e7as e selecionar os conte\u00fados mais relevantes. Hennig e Albayrak desenvolveram um modelo multi-documento para resumir um texto analisando a co-ocorr\u00eancia de termos e bigramas6 usando a diverg\u00eancia JS [Hennig e Albayrak 2010].\nHovy e Lin desenvolveram o sistema sumarizador SUMMARIST, que combina conhecimentos de conceitos do mundo (dicion\u00e1rios, ontologias e recursos similares) com PLN [Hovy e Lin 1998]. O SUMMARIST \u00e9 baseado na identifica\u00e7\u00e3o da tem\u00e1tica do documento e em sua interpreta\u00e7\u00e3o. Atrav\u00e9s de t\u00e9cnicas de recupera\u00e7\u00e3o de informa\u00e7\u00e3o e de dicion\u00e1rios, o sistema identifica os principais t\u00f3picos abordados no texto e faz a interpreta\u00e7\u00e3o dos dados atrav\u00e9s de t\u00e9cnicas estat\u00edsticas, psicologia cognitiva, l\u00e9xicos e dicion\u00e1rios. Por fim, o sum\u00e1rio \u00e9 criado atrav\u00e9s de m\u00e9todos de gera\u00e7\u00e3o de frases.\n5Skip-bigramas s\u00e3o quaisquer pares de palavras na ordem da frase. 6Bigramas s\u00e3o pares de palavras sequenciais em uma frase.\n31\nCAP\u00cdTULO 3\nMODELAGEM DO PROBLEMA\nEste cap\u00edtulo aborda a modelagem matem\u00e1tica utilizada nesta disserta\u00e7\u00e3o. A se\u00e7\u00e3o 3.1 descreve o modelo de saco de palavras para identificar as palavras e suas distribui\u00e7\u00f5es nos documentos analisados. A se\u00e7\u00e3o 3.2 descreve formas de avalia\u00e7\u00e3o da relev\u00e2ncia inicial de palavras e senten\u00e7as. A se\u00e7\u00e3o 3.3 e 3.4 discorrem sobre formas de calcular a similaridade e a diverg\u00eancia entre senten\u00e7as, respectivamente. Por fim, a se\u00e7\u00e3o 3.5 descreve os conceitos gerais e os problemas (abordados neste trabalho) envolvendo a Teoria de Grafos."}, {"heading": "3.1 Saco de palavras", "text": "Os m\u00e9todos propostos nesta disserta\u00e7\u00e3o s\u00e3o baseados em um pr\u00e9-tratamento espec\u00edfico de palavras e um modelo de saco de palavras para representar o texto. A modelagem de saco de palavras organiza e representa o modo como as palavras est\u00e3o distribu\u00eddas nas senten\u00e7as. Utiliza-se uma matriz representada por S[NS\u00d7NP ] constru\u00edda a partir do texto, onde NS \u00e9 o n\u00famero de senten\u00e7as e NP \u00e9 o n\u00famero de palavras distintas no documento. A c\u00e9lula Sij representa a frequ\u00eancia da palavra j na frase i (FPij).\nS =   S11 S12 . . . S1NP S21 S22 . . . S2NP ... ... ...\nSNS1 SNS2 . . . SNSNP\n  , Sij = { FPij, se \u2203 a palavra j na frase i 0, caso contr\u00e1rio (3.1)"}, {"heading": "3.2 Relev\u00e2ncia das palavras e frases 32", "text": ""}, {"heading": "3.2 Relev\u00e2ncia das palavras e frases", "text": "Uma forma de verificar a relev\u00e2ncia de uma palavra ou de uma frase em rela\u00e7\u00e3o ao texto \u00e9 atrav\u00e9s do Term Frequency - Inverse Sentence Frequency (TF-ISF) [Vodolazova et al. 2012], que \u00e9 uma varia\u00e7\u00e3o do TF-IDF7. Normalmente, as palavras mais frequentes representam ideias relevantes no texto. Entretanto, uma boa parte das mesmas s\u00e3o artigos, preposi\u00e7\u00f5es ou conjun\u00e7\u00f5es, e assim ser\u00e3o referenciadas como stopwords. Os stopwords n\u00e3o s\u00e3o relevantes para a compreens\u00e3o do texto e sua remo\u00e7\u00e3o auxilia sua an\u00e1lise. As palavras menos frequentes tamb\u00e9m podem ser relevantes. Ent\u00e3o, uma melhor forma de analisar as palavras \u00e9 atrav\u00e9s da TF-ISF. Essa m\u00e9trica analisa a frequ\u00eancia das palavras e sua distribui\u00e7\u00e3o nas senten\u00e7as. A relev\u00e2ncia de uma palavra w no texto, tfisf(w), \u00e9 dada pela equa\u00e7\u00e3o 3.2.\ntfisf(w) = tf(w)\u00d7 log NS\nnw , (3.2)\nonde tf(w) corresponde a frequ\u00eancia da palavra w, NS \u00e9 a quantidade de senten\u00e7as e nw \u00e9 a quantidade de senten\u00e7as que possuem a palavra w. Consequentemente, a relev\u00e2ncia de uma senten\u00e7a s, rel(s), \u00e9 determinada pela equa\u00e7\u00e3o 3.3.\nrel(s) = \u2211\nw\u2208s\ntfisf(w) (3.3)"}, {"heading": "3.3 Similaridade", "text": "A m\u00e9trica de similaridade de senten\u00e7as verifica a semelhan\u00e7a entre as mensagens transmitidas por cada senten\u00e7a. O processo de an\u00e1lise de similaridade verifica o significado sem\u00e2ntico das senten\u00e7as e analisa a semelhan\u00e7a das mensagens transmitidas. Entretanto, o processo de an\u00e1lise das senten\u00e7as exige uma verifica\u00e7\u00e3o complexa da estrutura sint\u00e1tica e sem\u00e2ntica das palavras.\nUma alternativa para avaliar a similaridade entre duas senten\u00e7as \u00e9 analisar as palavras em comum entre elas. A subse\u00e7\u00e3o 3.3.1 descreve o c\u00e1lculo da similaridade baseado na determina\u00e7\u00e3o do cosseno e a subse\u00e7\u00e3o 3.3.2 baseia-se nas palavras em comum para avaliar o n\u00edvel de similaridade. 7Term Frequency - Inverse Document Frequency (TF-IDF)"}, {"heading": "3.3 Similaridade 33", "text": ""}, {"heading": "3.3.1 Similaridade do cosseno", "text": "O m\u00e9todo da similaridade do cosseno baseia-se no c\u00e1lculo do cosseno do \u00e2ngulo entre dois vetores. Essa m\u00e9trica avalia duas senten\u00e7as e calcula o \u00e2ngulo entre dois vetores representados por elas. Sejam as senten\u00e7as P e Q com as palavras p1, p2, . . . , pn e q1, q2, . . . , qn, respectivamente. O produto escalar PQ \u00e9 dado pela equa\u00e7\u00e3o 3.4, em que pk \u00e9 1 quando a palavra pk existe na senten\u00e7a P , e, caso contr\u00e1rio, pk \u00e9 0. O mesmo ocorre para qk em rela\u00e7\u00e3o \u00e0 senten\u00e7a Q.\nP.Q = p1 \u00d7 q1 + p2 \u00d7 q2 + \u00b7 \u00b7 \u00b7+ pn \u00d7 qn (3.4)\nA norma da frase \u00e9 definida pela equa\u00e7\u00e3o 3.5.\n||P || = 2 \u221a\np21 + p 2 2 + \u00b7 \u00b7 \u00b7+ p 2 n (3.5)\nA similaridade do cosseno \u00e9 calculada segundo a equa\u00e7\u00e3o 3.6. Seu valor varia entre\n[0, 1]. Quanto maior for o valor do cosseno maior \u00e9 a semelhan\u00e7a entre as senten\u00e7as.\ncos(P,Q) = P.Q\n||P || \u00d7 ||Q|| (3.6)"}, {"heading": "3.3.2 Similaridade de Jaccard", "text": "O coeficiente de similaridade de Jaccard calcula a similaridade entre conjuntos de forma estat\u00edstica. Essa m\u00e9trica \u00e9 baseada na quantidade de elementos em comum entre dois conjuntos. Sejam duas senten\u00e7as P e Q cujos elementos s\u00e3o as palavras de cada uma delas. O coeficiente de similaridade de Jaccard, Jac(.), \u00e9 dado pela equa\u00e7\u00e3o 3.7 e o mesmo varia entre [0, 1], sendo 1 quando duas senten\u00e7as s\u00e3o iguais.\nJac(P,Q) = |P \u2229Q|\n|P \u222aQ| (3.7)\nOutra medida poss\u00edvel \u00e9 a dist\u00e2ncia de Jaccard, disJ(.), que calcula a dissimilaridade\nentre dois conjuntos atrav\u00e9s do complemento de Jaccard (equa\u00e7\u00e3o 3.8).\ndisJ(P,Q) = 1\u2212 Jac(P,Q) = |P \u222aQ| \u2212 |P \u2229Q|\n|P \u222aQ| (3.8)"}, {"heading": "3.4 Diverg\u00eancia 34", "text": ""}, {"heading": "3.4 Diverg\u00eancia", "text": "A m\u00e9trica de diverg\u00eancia tamb\u00e9m necessita da an\u00e1lise sem\u00e2ntica para avaliar corretamente o significado e a diferen\u00e7a entre duas senten\u00e7as. Por isso, foram analisados alguns m\u00e9todos estat\u00edsticos ( [Sogaard 2013, Torres-Moreno et al. 2010]) para avaliar a diverg\u00eancia entre conjuntos de probabilidades. As subse\u00e7\u00f5es 3.4.1 e 3.4.2 descrevem um m\u00e9todo assim\u00e9trico e outro sim\u00e9trico, respectivamente, para mensurar a diverg\u00eancia entre duas senten\u00e7as."}, {"heading": "3.4.1 Diverg\u00eancia de Kullback-Leibler", "text": "Sejam P , Q e W conjuntos de palavras, onde P e Q representam as palavras de duas senten\u00e7as de um documento e W \u00e9 formado por sua uni\u00e3o. Pr(P,w) representa a probabilidade da palavra w na senten\u00e7a P em rela\u00e7\u00e3o ao conjunto W . Respectivamente, Pr(Q,w) ser\u00e1 a probabilidade da palavra w na frase Q em rela\u00e7\u00e3o ao conjunto W .\nA diverg\u00eancia Kullback-Leibler (KL) determina a informa\u00e7\u00e3o perdida ao aproximar um conjunto de probabilidades do conjunto P em rela\u00e7\u00e3o ao conjunto de probabilidades do conjunto Q (equa\u00e7\u00e3o 3.9) [Sogaard 2013]. Ela permite calcular a diferen\u00e7a entre dois conjuntos de palavras distintas.\nDKL(P ||Q) = 1\n2\n\u2211\nw\u2208W\n( Pr(P,w) log Pr(P,w)\nPr(Q,w)\n) (3.9)\nEssa diverg\u00eancia \u00e9 assim\u00e9trica (DKL(P ||Q) 6= DKL(Q||P )), assumindo valores diferentes dependendo da an\u00e1lise realizada. Seu valor varia entre [0,\u221e) e suas probabilidades s\u00e3o semelhantes quando seus valores s\u00e3o pr\u00f3ximos a zero."}, {"heading": "3.4.2 Diverg\u00eancia de Jensen-Shannon", "text": "A diverg\u00eancia Jensen-Shannon (JS) \u00e9 uma vers\u00e3o sim\u00e9trica e suavizada da KL, fornecendo uma maneira mais est\u00e1vel para mensurar a diferen\u00e7a entre dois conjuntos de probabilidades (equa\u00e7\u00e3o 3.10) [Torres-Moreno et al. 2010, Saggion et al. 2010]. A diverg\u00eancia JS pode assumir a mesma varia\u00e7\u00e3o de valores que a KL."}, {"heading": "3.5 Grafos 35", "text": "DJS(P ||Q) = 1\n2\n\u2211\nw\u2208W\n( Pr(P,w) log\n2\u00d7 Pr(P,w)\nPr(P,w) + Pr(Q,w) + Pr(Q,w) log\n2\u00d7 Pr(Q,w)\nPr(P,w) + Pr(Q,w)\n)\n(3.10)\nNo caso de haver somente uma palavra em uma das frases analisadas, utiliza-se uma suaviza\u00e7\u00e3o para evitar valores nulos [Hiemstra 2009]. Se uma palavra w n\u00e3o est\u00e1 presente na frase Q, ent\u00e3o Pr(Q,w) \u00e9 calculada pela equa\u00e7\u00e3o 3.11, onde \u03b2 = 1.5 \u2217 voc, voc \u00e9 o n\u00famero de palavras distintas em W , \u03b3 controla a relev\u00e2ncia da palavra ausente na frase e NP \u00e9 a quantidade de palavras em W . Caso a palavra w esteja presente somente na frase Q, o c\u00e1lculo da probabilidade Pr(P,w) \u00e9 sim\u00e9trico a equa\u00e7\u00e3o 3.11.\nPr(Q,w) =\n( Pr(P,w) + \u03b3\nNP + \u03b3 \u00d7 \u03b2\n) (3.11)"}, {"heading": "3.5 Grafos", "text": "Esta se\u00e7\u00e3o descreve uma breve introdu\u00e7\u00e3o sobre a Teoria dos Grafos (subse\u00e7\u00e3o 3.5.1) e os problemas da clique e do subconjunto independente de v\u00e9rtices (subse\u00e7\u00e3o 3.5.2) abordados em alguns algoritmos utilizados nos sistemas desenvolvidos."}, {"heading": "3.5.1 Conceitos gerais", "text": "Considere um grafo G = (V,E), onde V \u00e9 o conjunto de v\u00e9rtices e E o conjunto de arestas n\u00e3o orientadas de G (ver figura 5.a). A cardinalidade (n) de um grafo \u00e9 definida pela quantidade de v\u00e9rtices e o complemento do grafo G\u0304 \u00e9 o grafo (V, {u, v} \u2208 (V \u00d7V )\\E : u 6= v) (figura 5.b8).\nO grafo G pode ser denso ou esparso. Ele \u00e9 denso quando o n\u00famero de arestas \u00e9 pr\u00f3ximo a n(n\u22121 2 ) (quando existe uma aresta entre todo par de v\u00e9rtices). Quando h\u00e1 poucas arestas, o grafo \u00e9 denominado esparso. A vizinhan\u00e7a de um conjunto de v\u00e9rtices U \u00e9 o conjunto de todos os v\u00e9rtices que possui em algum vizinho em U . O grau de um v\u00e9rtice v \u00e9 definido pela quantidade de arestas que ele possui.\nUm subgrafo de um grafoG \u00e9 qualquer grafoH tal que V (H) \u2286 V (G) e E(H) \u2286 E(G). O subgrafo de G induzido por um subconjunto U de V (G) \u00e9 o grafo (U, J), em que J \u00e9 o conjunto de todas as arestas de G que t\u00eam ambas as extremidades em U .\n8https://it.wikipedia.org/wiki/Grafo_complemento"}, {"heading": "3.5 Grafos 36", "text": "Figura 5 \u2013 Exemplo de um grafo G (a) e seu complemento G\u0304 (b).\n(a) (b)\nUm caminho (para o caso de um grafo simples9) com a origem no v\u00e9rtice vi e o fim no v\u00e9rtice vf \u00e9 definido por um conjunto finito de arestas consecutivas partindo do v\u00e9rtice vi e chegando ao v\u00e9rtice vf . Portanto, h\u00e1 um caminho entre os v\u00e9rtices v1 e v2 se existir um conjunto de arestas que interligue esses dois v\u00e9rtices diretamente ou indiretamente. Um grafo \u00e9 conexo se para qualquer par de v\u00e9rtices {v1, v2}, existe um caminho com in\u00edcio em v1 e t\u00e9rmino em v2. A figura 6 exemplifica um grafo conexo e outro desconexo.\nFigura 6 \u2013 Exemplos de grafo conexo (a) e desconexo (b).\n(a) Conexo (b) Desconexo"}, {"heading": "3.5.2 Problema da Clique e do Subconjunto Independente", "text": "Seja um grafo G = (V,E). A clique (ou subconjunto completo) \u00e9 qualquer conjunto de v\u00e9rtices dois a dois adjacentes. Um subconjunto U de v\u00e9rtices \u00e9 uma clique se o grafo induzido G[U ] \u00e9 completo (figura 7). O tamanho da clique \u00e9 definido pela sua cardinalidade e um dos problemas mais conhecidos \u00e9 o de identificar a maior clique existente em um grafo, denominado problema da Clique M\u00e1xima. Esse problema \u00e9 NP-Dif\u00edcil. 91-grafo, multiplicidade de arestas entre dois v\u00e9rtices igual a 1."}, {"heading": "3.5 Grafos 37", "text": "Figura 7 \u2013 Exemplo de Clique.\nUm Subconjunto Independente de V\u00e9rtices (SIV) (denotado dessa forma nesta disserta\u00e7\u00e3o) \u00e9 formado por um subconjunto dos v\u00e9rtices do grafo que n\u00e3o s\u00e3o adjacentes [Garey e Johnson 1990], ou seja, v\u00e9rtices que n\u00e3o possuem aresta interligando-os (figura 8). A Clique e o SIV s\u00e3o problemas complementares. Portanto, um conjunto U de v\u00e9rtices \u00e9 uma clique em um grafo G se e somente se U \u00e9 SIV no grafo complementar G\u0304.\nO Subconjunto Independente M\u00e1ximo (SIM) \u00e9 o subconjunto independente de v\u00e9rtices com maior cardinalidade no grafo. O SIM est\u00e1 presente em v\u00e1rias aplica\u00e7\u00f5es como colora\u00e7\u00e3o de grafos, agendamento de tarefas, atribui\u00e7\u00e3o de canais de r\u00e1dio, entre outras.\nFigura 8 \u2013 Exemplo de SIV (a) e SIM (b).\n(a) SIV (b) SIM\n[Butenko 2003] abordou a complexidade algor\u00edtmica e poss\u00edveis solu\u00e7\u00f5es para o SIM\nadaptadas \u00e0s caracter\u00edsticas do grafo. [Rossi e Smriglio 2001] desenvolveram um algoritmo branch-and-cut [Wolsey 1998] para solucionar o problema do SIM. Eles criaram restri\u00e7\u00f5es de estrutura geral a partir da execu\u00e7\u00e3o de algoritmos de separa\u00e7\u00e3o de clique sobre um grafo modificado obtido a partir da proje\u00e7\u00e3o das arestas.\n38\nCAP\u00cdTULO 4\nSISTEMAS DE SUMARIZA\u00c7\u00c3O AUTOM\u00c1TICA DE TEXTOS NA LITERATURA\nEste cap\u00edtulo aborda alguns sistemas baseline10 e da literatura para a sumariza\u00e7\u00e3o autom\u00e1tica de textos. Ser\u00e3o apresentados os sistemas Artex, Cortex, Enertex, GistSumm, KLSumm, baseados em PLI, LexRank e TextRank. Alguns deles ser\u00e3o comparados com os sistemas desenvolvidos nesta disserta\u00e7\u00e3o."}, {"heading": "4.1 Artex", "text": "Autre Resumeur TEXtuel (Artex) \u00e9 um sistema de sumariza\u00e7\u00e3o por extra\u00e7\u00e3o [Torres-Moreno 2012]. O pr\u00e9-tratamento \u00e9 o mesmo descrito no sistema SASI (se\u00e7\u00e3o 5.1). O sistema recebe a matriz de saco de palavras e cria o Modelo Espa\u00e7o Vetorial (MEV) que possibilita a constru\u00e7\u00e3o do vetor m\u00e9dio do documento (o \u201ct\u00f3pico global\u201d) de todos os vetores das senten\u00e7as. Ao mesmo tempo, obt\u00e9m-se o \u201cpeso lexical\u201d de cada senten\u00e7a, que \u00e9 o n\u00famero de palavras na senten\u00e7a. Analisa-se a similaridade entre as senten\u00e7as em rela\u00e7\u00e3o ao \u201cpeso lexical\"e o \u201ct\u00f3pico global\", a figura 9 descreve a MEV de um documento em que as senten\u00e7as vetoriais ~si e o vetor do t\u00f3pico global ~b s\u00e3o representados em um espa\u00e7o de palavras de dimens\u00e3o NP .\nA figura 10 descreve o peso lexical ~a em um MEV de senten\u00e7as com dimensionalidade de NS, sendo ~wi o vetor da frequ\u00eancia da palavra i nas NS senten\u00e7as. A relev\u00e2ncia das senten\u00e7as \u00e9 calculada baseada na proximidade do vetor de cada senten\u00e7a em rela\u00e7\u00e3o ao vetor de \u201ct\u00f3pico global\"e ao vetor de \u201cpeso lexical\". A relev\u00e2ncia ou o peso da senten\u00e7a\n10Sistemas baseline s\u00e3o sistemas simples que servem de compara\u00e7\u00e3o de desempenho em rela\u00e7\u00e3o a outros sistemas."}, {"heading": "4.2 Cortex 39", "text": "Figura 9 \u2013 MEV do tema global.\nsi, denominado score(si), \u00e9 calculada pela equa\u00e7\u00e3o 4.1.\nscore(si) = 1\nNS \u00d7NP\n( NP\u2211\nj=1\nnos(i, j)\u00d7 nod(j) ) \u00d7 ai; i = 1, 2, ..., NS; (4.1)\nsendo nos(i, j) \u00e9 o n\u00famero m\u00e9dio de ocorr\u00eancias da palavra j na senten\u00e7a i, nod(j) \u00e9 o n\u00famero m\u00e9dio de ocorr\u00eancias da palavra j nas NS senten\u00e7as e ai \u00e9 o n\u00famero m\u00e9dio de ocorr\u00eancias das NP palavras na senten\u00e7a i.\nFigura 10 \u2013 MEV do peso lexical.\nPor fim, o sistema gera o resumo composto pelas senten\u00e7as com os maiores scores."}, {"heading": "4.2 Cortex", "text": "O sistema Cortex \u00e9 um sistema de sumariza\u00e7\u00e3o autom\u00e1tica independente do idioma [Boudin e Torres-Moreno 2007]. O sistema aplica c\u00e1lculos num\u00e9ricos para ponderar frases e criar um resumo. Inicialmente, realiza-se o processo de pr\u00e9-tratamento descrito no sistema SASI (se\u00e7\u00e3o 5.1). O Cortex possui um sistema de decis\u00e3o que utiliza as m\u00e9tricas de similaridade, de overlap e score normalizadas (entre [0, 1]), combinadas a fim de calcular"}, {"heading": "4.2 Cortex 40", "text": "a pontua\u00e7\u00e3o de cada senten\u00e7a (figura 11).\nFigura 11 \u2013 Funcionamento do sistema Cortex.\nO algoritmo de decis\u00e3o avalia todas as m\u00e9tricas permitindo uma melhor avalia\u00e7\u00e3o da import\u00e2ncia das senten\u00e7as. Utiliza-se o cosseno de similaridade para medir o grau de similaridade entre dois vetores representando os documentos e os t\u00f3picos abordados.\nO overlap calcula a quantidade de informa\u00e7\u00e3o compartilhada de uma senten\u00e7a (conjunto de palavras P ) em rela\u00e7\u00e3o a um determinado t\u00f3pico (conjunto de palavras Q) a partir da quantidade de palavras comuns entre eles (equa\u00e7\u00e3o 4.2).\noverlap(P,Q) = |P \u2229Q|\n|Q| (4.2)\nAs m\u00e9tricas de similaridade e overlap s\u00e3o usadas para refinar o c\u00e1lculo do Cortex descrito no trabalho de Torres-Moreno et al [Torres-Moreno, Vel\u00e1zquez-Morales e Meunier 2002]. Assim, a pondera\u00e7\u00e3o final (score) de uma frase P com rela\u00e7\u00e3o a um documento (conjunto de palavras W ) e um t\u00f3pico Q \u00e9 definida pela equa\u00e7\u00e3o 4.3.\nscore(P ) = \u03b10 \u00d7 CORTEX(P,W ) + \u03b11 \u00d7 overlap(P,Q) + \u03b12 \u00d7 Sim(W,Q); \u2211\ni\n\u03b1i = 1\n(4.3)\nO resumo \u00e9 criado a partir das senten\u00e7as com maiores pontua\u00e7\u00f5es e sem redund\u00e2ncias.\nA redund\u00e2ncia das senten\u00e7as \u00e9 calculada a partir da similaridade de Dice [Dice 1945]."}, {"heading": "4.3 Enertex 41", "text": ""}, {"heading": "4.3 Enertex", "text": "O sistema Enertex avalia a energia textual das senten\u00e7as, que representa a relev\u00e2ncia das mesmas em rela\u00e7\u00e3o ao texto [Fern\u00c1ndez, SanJuan e Torres-Moreno 2007]. O sistema modela um texto como uma rede neural baseada no modelo de Hopfield e de Ising para calcular a energia textual das senten\u00e7as. O pr\u00e9-tratamento do texto \u00e9 o mesmo descrito no SASI (se\u00e7\u00e3o 5.1), com a cria\u00e7\u00e3o da matriz de palavras S[NS\u00d7NP ]. Em seguida, o Enertex utiliza a matriz S para analisar a intera\u00e7\u00e3o entre os termos do vocabul\u00e1rio do texto a partir da regra de Hebb (equa\u00e7\u00e3o 4.4).\nK = ST \u00d7 S, (4.4)\nonde ST \u00e9 a matriz transposta de S. Baseada nessa intera\u00e7\u00e3o, a energia textual (Energia) \u00e9 calculada atrav\u00e9s da equa\u00e7\u00e3o 4.5.\nEnergia = \u2212 1\n2 S\u00d7K\u00d7 ST ;Energiaij \u2208 EnergiaNS\u00d7NS (4.5)\nem que Energiaij representa a energia da intera\u00e7\u00e3o entre as senten\u00e7as i e j. A relev\u00e2ncia das senten\u00e7as \u00e9 calculada considerando sua energia textual e, por fim, cria-se o resumo (sem redund\u00e2ncias) a partir das frases consideradas mais relevantes pelo sistema."}, {"heading": "4.4 GistSumm", "text": "O sistema GistSumm [Pardo, Rino e Nunes 2003] baseia-se em encontrar a mensagem principal do documento para a cria\u00e7\u00e3o de seu resumo. O sistema segmenta o texto e calcula a relev\u00e2ncia das senten\u00e7as atrav\u00e9s das palavras-chaves e do TF-ISF das senten\u00e7as. Dessa forma, as senten\u00e7as com maior score s\u00e3o consideradas as mais relevantes para o documento. O sistema avalia a pontua\u00e7\u00e3o das senten\u00e7as determinando seus limiares e seleciona as senten\u00e7as que possuam palavras com radicais correspondentes \u00e0s palavras na senten\u00e7a principal e com um score acima do limiar."}, {"heading": "4.5 KLSumm", "text": "O algoritmo KLSumm baseia-se no c\u00e1lculo da diverg\u00eancia KL (se\u00e7\u00e3o 3.4.1) para analisar a diverg\u00eancia entre um sum\u00e1rio e seu texto original [Haghighi e Vanderwende"}, {"heading": "4.6 LexRank 42", "text": "2009]. O objetivo desse algoritmo \u00e9 tornar o sum\u00e1rio (conjuntos de palavras R) o mais similar poss\u00edvel do texto (conjunto de palavras O) respeitando o limite de caracteres do sum\u00e1rio (equa\u00e7\u00e3o 4.6). Dessa forma, o sistema seleciona as senten\u00e7as menos divergentes em rela\u00e7\u00e3o ao texto, conforme a equa\u00e7\u00e3o 4.6.\nResumo = min DKL(R||O) (4.6)"}, {"heading": "4.6 LexRank", "text": "O LexRank avalia estocasticamente a relev\u00e2ncia das senten\u00e7as [Erkan e Radev 2004]. O sistema utiliza um grafo de palavras constru\u00eddo a partir do texto e o modela como um grafo de senten\u00e7as. O sistema \u00e9 dividido em duas partes: similaridade das senten\u00e7as e centralidade de uma senten\u00e7a com rela\u00e7\u00e3o \u00e0s demais.\nO c\u00e1lculo da similaridade \u00e9 baseado no TF-ISF e no cosseno de similaridade (equa\u00e7\u00e3o 4.7), sendo tf(w, P ) a frequ\u00eancia da palavra w na senten\u00e7a P e idf(w) o valor inverse document frequency (inverso da frequ\u00eancia nos documentos) da palavra w.\nlexranksim(P,Q) =\n\u2211 w\u2208P,Q tf(w, P )\u00d7 tf(w,Q)\u00d7 [idf(w)] 2\n\u221a\u2211 pi\u2208P [tf(pi, P )\u00d7 idf(pi)]2 \u00d7 \u221a\u2211 qi\u2208Q [tf(qi, Q)\u00d7 idf(qi)]2\n(4.7)\nA partir da similaridade (lexranksim), calcula-se a relev\u00e2ncia (score) de cada senten\u00e7a baseada na centralidade das senten\u00e7as (equa\u00e7\u00e3o 4.8). A vari\u00e1vel d considera a pondera\u00e7\u00e3o inicial dos v\u00e9rtices.\np(u) = d\nNS + (1\u2212 d)\n\u2211\nv\u2208viz(u)\nlexranksim(u, v)\u2211 z\u2208viz(v) lexranksim(z, v) p(v) (4.8)\nonde p(u) \u00e9 a centralidade do v\u00e9rtice e viz(u) s\u00e3o os v\u00e9rtices vizinhos de u.\nO sistema criar\u00e1 um resumo com as senten\u00e7as de maior score e sem redund\u00e2ncia."}, {"heading": "4.7 Programa\u00e7\u00e3o Linear Inteira", "text": "[Mcdonald 2006] prop\u00f4s um modelo matem\u00e1tico para avaliar a qualidade do resumo\nbaseado na relev\u00e2ncia e similaridade das senten\u00e7as. Seja um conjunto de senten\u00e7as de um"}, {"heading": "4.8 Submodular 43", "text": "texto bfi indicar\u00e1 a exist\u00eancia da senten\u00e7a i no resumo do texto, Doc ser\u00e1 o conjunto de senten\u00e7as do documento, Redudij representar\u00e1 a redund\u00e2ncia entre as senten\u00e7as i e j e por sua vez Relevi representar\u00e1 a relev\u00e2ncia da senten\u00e7a i. Dessa forma, um resumo pode ser avaliado pela f\u00f3rmula descrita na equa\u00e7\u00e3o 4.9.\nResumo = \u2211\ni\u2208Doc\nRelevi \u00d7 bfi \u2212 \u2211\ni,j\u2208Doc\nRedudij \u00d7 bfi \u00d7 bfj (4.9)\nMcdonald modela o problema usando Programa\u00e7\u00e3o Linear, considerando L como o limite m\u00e1ximo de caracteres do resumo e li o tamanho da senten\u00e7a i. A an\u00e1lise da redund\u00e2ncia \u00e9 uma fun\u00e7\u00e3o quadr\u00e1tica, portanto \u00e9 necess\u00e1rio linearizar a ocorr\u00eancia simult\u00e2nea das frases i e j (rij = bfi \u00d7 bfj). Assim, a modelagem PLI utilizada por Mcdonald \u00e9 expressa pelas equa\u00e7\u00f5es 4.10, 4.11, 4.12, 4.13 e 4.14.\nMaximizar: \u2211\ni\u2208Doc\nRelevi \u00d7 bfi \u2212 \u2211\ni,j\u2208Doc\nRedudij \u00d7 rij (4.10)\nRestri\u00e7\u00f5es: \u2211\nj\u2208Doc\nlj \u00d7 bfj \u2264 L (4.11)\nrij \u2264 bfi rij \u2264 bfj \u2200i, j (4.12)\nbfi + bfj \u2212 rij \u2264 1 \u2200i, j (4.13)\nbfi \u2208 {0, 1} \u2200i (4.14)"}, {"heading": "4.8 Submodular", "text": "Seja B um conjunto finito e seja f uma fun\u00e7\u00e3o de partes de B em R. A fun\u00e7\u00e3o f \u00e9 submodular se para quaisquer partes C e D de B, observa-se a rela\u00e7\u00e3o expressa na equa\u00e7\u00e3o 4.15.\nf(C \u222aD) + f(C \u2229D) \u2264 f(C) + f(D) (4.15)\nCorrelacionando a fun\u00e7\u00e3o submodular com a extra\u00e7\u00e3o autom\u00e1tica, definiu-se B como o conjunto com todas as senten\u00e7as do documento, C \u00e9 resumo do texto e f \u00e9 a fun\u00e7\u00e3o de avalia\u00e7\u00e3o de qualidade do resumo. A sumariza\u00e7\u00e3o objetiva encontrar o conjunto de senten\u00e7as (conjunto C), que melhor represente o texto (conjunto B) e tenha um tamanho"}, {"heading": "4.8 Submodular 44", "text": "|C| \u2264 L (tamanho m\u00e1ximo do resumo) (equa\u00e7\u00e3o 4.16). Esse problema \u00e9 NP-Dif\u00edcil. Entretanto, \u00e9 poss\u00edvel determinar uma solu\u00e7\u00e3o aproximada atrav\u00e9s de um algoritmo guloso se a fun\u00e7\u00e3o f for submodular [Lin, Bilmes e Xie 2009].\nmax C\u2286B {f(C) : |C| \u2264 L} (4.16)\nO trabalho [Lin, Bilmes e Xie 2009] descreve quatro fun\u00e7\u00f5es submodulares para avaliar a qualidade de resumos autom\u00e1ticos. A primeira calcula a representatividade de um resumo com rela\u00e7\u00e3o ao texto (equa\u00e7\u00e3o 4.17) analisando a similaridade do resumo C com rela\u00e7\u00e3o ao texto B, sendo simij a similaridade entre as senten\u00e7as i e j.\nffac(C) = \u2211\ni\u2208B\nmax j\u2208C simij (4.17)\nA segunda m\u00e9trica utilizada, fcorte, avalia a similaridade das senten\u00e7as do resumo em rela\u00e7\u00e3o as demais senten\u00e7as do texto (equa\u00e7\u00e3o 4.18). A terceira m\u00e9trica, fpior, considera o caso de uma senten\u00e7a relevante n\u00e3o ser similar \u00e0s demais. Uma forma de avaliar esse caso \u00e9 atrav\u00e9s da maximiza\u00e7\u00e3o da similaridade da senten\u00e7a menos similar do resumo (equa\u00e7\u00e3o 4.19).\nfcorte(C) = \u2211\ni\u2208B\\C\n\u2211\nj\u2208C\nsimij (4.18)\nfpior(C) = min i\u2208B max j\u2208C simij (4.19)\nA \u00faltima m\u00e9trica, fpen, avalia a redund\u00e2ncia das senten\u00e7as do resumo. Um resumo deve ser conciso e pequeno. Desse modo, a presen\u00e7a de senten\u00e7as similares n\u00e3o adiciona um conte\u00fado interessante ao resumo. Portanto, pode-se evitar essa redund\u00e2ncia com a adi\u00e7\u00e3o de penalidades \u00e0s senten\u00e7as similares do resumo (equa\u00e7\u00e3o 4.20), em que \u03bb \u00e9 a taxa de penalidade caso haja redund\u00e2ncia de senten\u00e7as.\nfpen(C) = \u2211\ni\u2208B\\C\n\u2211\nj\u2208C\nsimij \u2212 \u03bb \u2211\ni,j\u2208C:i 6=j\nsimij , \u03bb \u2265 0 (4.20)"}, {"heading": "4.9 TextRank 45", "text": ""}, {"heading": "4.9 TextRank", "text": "O TextRank \u00e9 um algoritmo baseado em grafos para mensurar a relev\u00e2ncia das senten\u00e7as [Mihalcea e Tarau 2004]. O algoritmo baseia-se na recomenda\u00e7\u00e3o (ou relev\u00e2ncia) de cada v\u00e9rtice baseada nas liga\u00e7\u00f5es entre os mesmos. Portanto, quanto maior a quantidade de liga\u00e7\u00f5es associadas a um v\u00e9rtice, mais relevante ele ser\u00e1 para o texto.\nO algoritmo modela o texto como um grafo de senten\u00e7as e cria as arestas baseadas na\nsimilaridade entre as senten\u00e7as P e Q (equa\u00e7\u00e3o 4.21).\nsim(P,Q) = |{w|w \u2208 P & w \u2208 Q}|\nlog(|P |) + log(|Q|) (4.21)\nO TextRank mensura o score de cada v\u00e9rtice de forma recursiva utilizando a\nvizinhan\u00e7a dos v\u00e9rtices at\u00e9 seus valores se tornarem est\u00e1veis (equa\u00e7\u00e3o 4.22).\nRec(vi) = (1\u2212 p) + p\u00d7 \u2211\nvj\u2208viz(vi)\nsim(vj , vi)\u2211 vk\u2208viz(vj) sim(vj , vk) Rec(vj), (4.22)\nem que a vari\u00e1vel p \u00e9 um amortecimento ajustado entre 0 e 1, sim(vj , vi) \u00e9 a similaridade entre os v\u00e9rtices vj e vi, e viz(vi) representa o conjunto de v\u00e9rtices da vizinhan\u00e7a do v\u00e9rtice vi.\nFinalmente, o sistema cria o resumo com as senten\u00e7as de maior score.\n46\nCAP\u00cdTULO 5\nSISTEMAS PROPOSTOS\nEste cap\u00edtulo aborda os sistemas sumarizadores LIA-RAG, RAG, SASI e SUMMatrix. Os sistemas utilizam a Teoria de Grafos (LIA-RAG, RAG e SASI) e matrizes de similaridade (SUMMatrix) juntamente com m\u00e9tricas de similaridade para avaliar a diverg\u00eancia entre as senten\u00e7as e selecionar as principais informa\u00e7\u00f5es de um texto. Os sistemas desenvolvidos s\u00e3o sumarizadores gen\u00e9ricos, monodocumento e multidocumento, indicativos com as informa\u00e7\u00f5es-chaves e geram os resumos atrav\u00e9s da extra\u00e7\u00e3o de senten\u00e7as. Os sistemas nesta disserta\u00e7\u00e3o possuem caracter\u00edsticas particulares e assim, requereram o uso de corpus espec\u00edficos ao problema configurado. A se\u00e7\u00e3o 5.1 descreve a motiva\u00e7\u00e3o e o funcionamento geral dos sistemas SASI. As se\u00e7\u00f5es 5.2 e 5.3 descrevem o funcionamento dos sistemas RAG e LIA-RAG. Por fim, a se\u00e7\u00e3o 5.4 descreve o sistema SUMMatrix e suas caracter\u00edsticas."}, {"heading": "5.1 Sumarizador Autom\u00e1tico baseado em Subconjunto Independente (SASI)", "text": "Um texto \u00e9 composto por diversas senten\u00e7as, que podem ser agrupadas de acordo com o grau de similaridade entre elas. Cada grupo aborda uma etapa/ideia do texto. Considera-se neste trabalho que uma senten\u00e7a similar a todas (ou \u00e0 maioria) pertencentes ao seu grupo possui conte\u00fado \u201crelevante\u201d com rela\u00e7\u00e3o ao grupo. Dessa forma, \u00e9 poss\u00edvel criar um resumo com a ideia geral do texto utilizando as senten\u00e7as com maior similaridade identificadas em cada grupo. Uma outra abordagem poss\u00edvel consiste em obter resumos contendo apenas as informa\u00e7\u00f5es mais importantes, ou seja, analisar somente os maiores grupos de senten\u00e7as similares visto que suas informa\u00e7\u00f5es s\u00e3o constantemente discutidas no texto."}, {"heading": "5.1 Sumarizador Autom\u00e1tico baseado em Subconjunto Independente (SASI) 47", "text": "O sistema SASI analisa e cria grupos de senten\u00e7as similares do texto para identificar\ne gerar um resumo com as principais senten\u00e7as de cada grupo."}, {"heading": "5.1.1 Funcionamento", "text": "Inicialmente, executa-se o pr\u00e9-tratamento do documento realizando o processo de leitura e o reconhecimento de caracteres do texto. Em seguida, realiza-se a segmenta\u00e7\u00e3o das senten\u00e7as e palavras, a filtragem de stopwords e o processo de stemming a fim de remover palavras irrelevantes e reduzir as palavras \u00e0s suas ra\u00edzes. Por fim, cria-se uma matriz de palavras correlacionando sua frequ\u00eancia em cada senten\u00e7a. De posse dessa matriz de palavras, o SASI calcula a diverg\u00eancia das senten\u00e7as.\nRealiza-se, igualmente, uma filtragem das senten\u00e7as sem relev\u00e2ncia para o texto e verifica-se a diverg\u00eancia entre elas. Para isso, foi utilizada a abordagem descrita na se\u00e7\u00e3o 3.4. Ent\u00e3o, sempre dois conjuntos de palavras P e Q s\u00e3o analisados concomitantemente. Inicialmente, P e Q referenciam, respectivamente, o texto completo e cada frase isolada do mesmo. Dessa forma, calcula-se a diverg\u00eancia entre os conjuntos P e Q, DJS(P ||Q), para verificar se uma frase \u00e9 importante para o documento por meio da an\u00e1lise das palavras existentes:\n\u25ee Se a diverg\u00eancia da frase for grande em rela\u00e7\u00e3o ao texto completo, a frase ser\u00e1\ndescartada;\n\u25ee Se o documento possuir um t\u00edtulo: analisa-se a similaridade entre o t\u00edtulo e a\nfrase descartada, caso a diverg\u00eancia entre eles seja pequena, a frase far\u00e1 parte do documento novamente.\nEm seguida, o SASI cria um grafo G em que os v\u00e9rtices representam as senten\u00e7as inicialmente relevantes. Nesse caso, os conjuntos P e Q correspondem a pares de senten\u00e7as e sua diverg\u00eancia ser\u00e1 igualmente utilizada para a cria\u00e7\u00e3o e para a pondera\u00e7\u00e3o das arestas. Caso a diverg\u00eancia entre duas senten\u00e7as seja \u201cpequena\u201d (par\u00e2metro do algoritmo), uma aresta interligando-as ser\u00e1 inserida.\nA sumariza\u00e7\u00e3o objetiva a produ\u00e7\u00e3o de um resumo de tamanho pequeno e com as principais informa\u00e7\u00f5es do texto. Desse modo, o SASI dever\u00e1 escolher somente as senten\u00e7as com mais informa\u00e7\u00f5es adicionais para construir o resumo. Portanto, a escolha de v\u00e9rtices adjacentes implica na sele\u00e7\u00e3o de frases com conte\u00fado redundante, o que n\u00e3o \u00e9 interessante para esse tipo de resumo. O sistema dever\u00e1 selecionar as frases com conte\u00fado distinto"}, {"heading": "5.1 Sumarizador Autom\u00e1tico baseado em Subconjunto Independente (SASI) 48", "text": "entre si, descartando as senten\u00e7as repetitivas ou que trazem pouca informa\u00e7\u00e3o adicional ao resumo. A determina\u00e7\u00e3o de um Subconjunto Independente de V\u00e9rtices (SIV) do grafo fornece uma poss\u00edvel solu\u00e7\u00e3o para o problema devido suas caracter\u00edsticas de selecionar v\u00e9rtices n\u00e3o conectados entre si. Os v\u00e9rtices com maior grau tem prefer\u00eancia no resumo pois, teoricamente, s\u00e3o similares a um n\u00famero maior de senten\u00e7as e, portanto, s\u00e3o mais relevantes. Dessa forma, o sistema ordena os v\u00e9rtices de acordo com o grau deles em ordem decrescente. Em seguida, o SASI avalia os v\u00e9rtices nessa ordem e seleciona aqueles que mantenham as caracter\u00edsticas do SIV. O resumo \u00e9 composto pelas frases que comp\u00f5em o SIV excluindo as frases que s\u00e3o redundantes com base no coeficiente de Dice [Dice 1945] (figura 12).\nFigura 12 \u2013 Funcionamento do sistema SASI."}, {"heading": "5.1.2 Exemplo", "text": "O texto da tabela 5.1 retrata uma not\u00edcia sobre a pol\u00edtica brasileira. Inicialmente realiza-se os processos de segmenta\u00e7\u00e3o, filtragem, stemming e cria\u00e7\u00e3o da matriz de palavras. Os textos n\u00e3o possuem t\u00edtulos, ent\u00e3o todas as senten\u00e7as s\u00e3o consideradas"}, {"heading": "5.2 R\u00e9sumeur Avec de Graphes (RAG) 49", "text": "relevantes. O sistema recebe a matriz e cria um grafo de senten\u00e7as. O SASI calcula a diverg\u00eancia entre as senten\u00e7as e caso a diverg\u00eancia entre elas seja abaixo de 0, 20 (valor obtido de forma emp\u00edrica), adiciona-se uma aresta interligando os dois v\u00e9rtices, i.e., as duas senten\u00e7as. Em seguida, o sistema calcula o SIV privilegiando os v\u00e9rtices de maior grau. Por fim, o resumo do texto \u00e9 composto pela concatena\u00e7\u00e3o das senten\u00e7as selecionadas no SIV, sem redund\u00e2ncias. Nesse exemplo, o resumo com 100 palavras \u00e9 composto pelas frases: S \u2212 9, S \u2212 13, S \u2212 18, S \u2212 19 e S \u2212 21.\n5.2 R\u00e9sumeur Avec de Graphes (RAG)\nAs principais ideias de um texto s\u00e3o geralmente analisadas e discutidas v\u00e1rias vezes. No entanto, n\u00e3o \u00e9 necess\u00e1rio dispor de uma grande quantidade de senten\u00e7as similares para que elas tenham import\u00e2ncia. O RAG, que \u00e9 um sistema sumarizador autom\u00e1tico por extra\u00e7\u00e3o de senten\u00e7as, seleciona as principais senten\u00e7as de um texto baseado na similaridade entre as senten\u00e7as e na import\u00e2ncia das palavras."}, {"heading": "5.2.1 Funcionamento", "text": "Efetua-se o pr\u00e9-processamento dos textos e obt\u00e9m-se a matriz de saco de palavras, assim como descrito no funcionamento do sistema SASI (se\u00e7\u00e3o 5.1). O RAG calcula a relev\u00e2ncia de cada senten\u00e7a com base na m\u00e9trica TF-ISF (equa\u00e7\u00e3o 3.2) e seleciona as senten\u00e7as com maior score.\nO RAG cria um grafo G em que cada v\u00e9rtice representa uma senten\u00e7a selecionada anteriormente. O texto \u00e9 analisado e modelado como um grafo de senten\u00e7as (v\u00e9rtices). Com base na equa\u00e7\u00e3o 3.10, o RAG calcula a similaridade entre as senten\u00e7as. Se a diverg\u00eancia entre elas \u00e9 menor do que limiar (obtido por testes emp\u00edricos), ent\u00e3o o sistema criar\u00e1 uma aresta entre elas. Portanto, os v\u00e9rtices com maior grau ter\u00e3o o conte\u00fado mais analisado no texto. No entanto, algumas senten\u00e7as podem ter um grau pequeno e mesmo assim podem conter informa\u00e7\u00f5es importantes. O RAG combina o valor do TF-ISF e do grau das senten\u00e7as para analisar sua relev\u00e2ncia. A relev\u00e2ncia da senten\u00e7a i \u00e9 definida pela equa\u00e7\u00e3o 5.1, onde grau(i) \u00e9 o grau de v\u00e9rtice i e rel(i) \u00e9 a relev\u00e2ncia da senten\u00e7a i (equa\u00e7\u00e3o 3.3). Em seguida, o sistema cria um resumo de senten\u00e7as de pontua\u00e7\u00e3o mais elevada, excluindo frases similares (ou redundantes) com base no coeficiente de Dice [Dice 1945]. A figura 13 descreve o sistema RAG."}, {"heading": "5.2 R\u00e9sumeur Avec de Graphes (RAG) 50", "text": "score(i) = grau(i)\u00d7 rel(i) (5.1)\nFigura 13 \u2013 Sistema RAG."}, {"heading": "5.2.2 Exemplo", "text": "O exemplo aqui descrito considera o mesmo texto da tabela 5.1. Inicialmente realiza-se os processos de segmenta\u00e7\u00e3o, filtragem e stemming. Em seguida, uma matriz de saco de palavras \u00e9 criada a partir do texto. O RAG recebe essa matriz, calcula o TF-ISF das senten\u00e7as para remover as senten\u00e7as menos relevantes e modela o texto como um grafo de senten\u00e7as. Em seguida, o sistema calcula o score das senten\u00e7as (tabela 5.2) e s\u00e3o selecionadas as de maior pontua\u00e7\u00e3o. No exemplo considerado, o resumo contendo 100 palavras \u00e9 composto pelas senten\u00e7as: S-3, S-11, S-13, S-14 e S-18."}, {"heading": "5.3 LIA-RAG 51", "text": ""}, {"heading": "5.3 LIA-RAG", "text": "O \u00e1udio \u00e9 amplamente utilizado nas transmiss\u00f5es dos r\u00e1dios e na internet (em not\u00edcias, hist\u00f3rias, entrevistas ou conversas). Existem v\u00e1rias ferramentas para reconhecimento de voz (\u00e1udio sobre um assunto ou uma conversa entre duas ou mais pessoas).\nA tarefa de sumariza\u00e7\u00e3o de textos orais \u00e9 mais complexa e envolve a transcri\u00e7\u00e3o de \u00e1udios em textos. As reuni\u00f5es e conversas envolvem discuss\u00f5es entre v\u00e1rias pessoas e frequentemente suas vozes se sobrep\u00f5em. Essas transcri\u00e7\u00f5es possuem diversas problem\u00e1ticas associadas pois \u00e9 mais dif\u00edcil identificar os limites de uma senten\u00e7a, visto que a mesma pode ser fragmentada, conter rupturas e introduzir erros de reconhecimento de fala. A linguagem utilizada pode ser informal e as declara\u00e7\u00f5es podem ser parciais, fragment\u00e1rias, n\u00e3o gramaticais, al\u00e9m de possivelmente inclu\u00edrem muitas retic\u00eancias e pronomes. No entanto, a fala pode fornecer informa\u00e7\u00f5es adicionais que evidenciam uma parte espec\u00edfica do texto como, por exemplo, a pros\u00f3dia [Murray, Renals e Carletta 2005].\n[Mckeown et al. 2005] descreveram aplica\u00e7\u00f5es de t\u00e9cnicas de sumariza\u00e7\u00e3o autom\u00e1tica\nde um texto para a produ\u00e7\u00e3o de resumos de conversas orais. Eles analisaram alguns trabalhos sobre a produ\u00e7\u00e3o de resumos de not\u00edcias e reuni\u00f5es. [Murray, Renals e Carletta 2005] analisaram a sumariza\u00e7\u00e3o extrativa de reuni\u00f5es multipartid\u00e1rias. Eles descreveram a relev\u00e2ncia marginal m\u00e1xima e a an\u00e1lise sem\u00e2ntica latente para criar um resumo com base em caracter\u00edsticas pros\u00f3dicas e lexicais.\nO sistema LIA-RAG foi desenvolvido a fim de sumarizar textos de conversas atrav\u00e9s da extra\u00e7\u00e3o de senten\u00e7as. Esse sistema seleciona as principais senten\u00e7as da conversa transcrita baseado no sistema RAG e usa um p\u00f3s-processamento para remover os erros contidos em di\u00e1logos e tornar o texto mais conciso e compacto."}, {"heading": "5.3.1 Funcionamento", "text": "O LIA-RAG recebe um texto transcrito de uma conversa e realiza o pr\u00e9-processamento do mesmo, pois estas possuem diversas express\u00f5es para associar o pensamento e o modo de falar dos personagens. O sistema remove essas express\u00f5es e caracter\u00edsticas relacionadas aos participantes da conversa. Em seguida, ele analisa a relev\u00e2ncia das senten\u00e7as utilizando o sistema RAG, que fornece o resumo autom\u00e1tico da conversa.\nO processo de reconhecimento da voz produz um texto com v\u00e1rios problemas gramaticais (g\u00edrias, linguagens cotidianas, express\u00f5es e erros de reconhecimento da fala)."}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 52", "text": "Um algoritmo de resumo por extra\u00e7\u00e3o seleciona as frases relevantes. No entanto, as senten\u00e7as podem ter alguns problemas gramaticais. Assim, \u00e9 necess\u00e1rio realizar um tratamento desse resumo. Os principais aspectos analisados nesse processo s\u00e3o:\n\u25ee coloquialismos;\n\u25ee express\u00f5es da fala;\n\u25ee datas.\nAlgumas express\u00f5es da fala s\u00e3o usadas para conectar ideias ou conceitos em conversas orais. O sistema LIA-RAG realiza o p\u00f3s-processamento com o resumo gerado pelo RAG. O sistema remove essas express\u00f5es da fala porque muitas vezes elas s\u00e3o transcritas incorretamente (ru\u00eddo na conversa\u00e7\u00e3o). Al\u00e9m disso, o sistema elimina v\u00e1rios coloquialismos e palavras duplicadas, substitui algumas palavras erradas por sua forma correta e transforma as datas por extenso na forma \u201cdia/m\u00eas/ano\u201d. A figura 14 mostra a arquitetura do sistema LIA-RAG.\nFigura 14 \u2013 Sistema LIA-RAG.\n5.4 SUMmarizer based on Matrix model (SUMMatrix)\nAtualmente, h\u00e1 diferentes jornais e sites de not\u00edcias disponibilizando informa\u00e7\u00f5es sobre diferentes acontecimentos a todo momento. Entretanto, a an\u00e1lise de uma not\u00edcia a partir de uma \u00fanica fonte pode fornecer informa\u00e7\u00f5es imprecisas, duvidosas ou desnecess\u00e1rias. A diversidade dos meios de comunica\u00e7\u00e3o possibilita a identifica\u00e7\u00e3o de informa\u00e7\u00f5es tendenciosas (desnecess\u00e1rias ou erradas) e compreender corretamente um acontecimento a partir de diferentes perspectivas.\nA utiliza\u00e7\u00e3o de v\u00e1rias fontes de informa\u00e7\u00e3o nos auxilia na compreens\u00e3o de um evento. Entretanto, a enorme quantidade de not\u00edcias torna imposs\u00edvel sua leitura de maneira integral. Uma maneira de resolver esse problema \u00e9 selecionar as principais informa\u00e7\u00f5es"}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 53", "text": "contidas em todos os documentos e criar um resumo com as mesmas [Barzilay e McKeown 2005].\nO sistema SUMMatrix foi desenvolvido no intuito de analisar as senten\u00e7as de conjuntos de textos de conte\u00fado similar. O sistema cria um resumo por extra\u00e7\u00e3o independente do idioma do cluster, analisa as senten\u00e7as dos textos e calcula a diverg\u00eancia entre as mesmas a fim de mensurar sua relev\u00e2ncia. Em seguida, o resumo \u00e9 gerado atrav\u00e9s da concatena\u00e7\u00e3o das senten\u00e7as com maior pontua\u00e7\u00e3o. A figura 15 descreve resumidamente o funcionamento do SUMMatrix.\nFigura 15 \u2013 Funcionamento do sistema SUMMatrix."}, {"heading": "5.4.1 Funcionamento", "text": "O SUMMatrix analisa um cluster composto de textos relacionados a uma mesma not\u00edcia. Esses textos s\u00e3o similares e transmitem a mesma mensagem ou uma informa\u00e7\u00e3o similar. O c\u00e1lculo da similaridade utiliza unigramas e bigramas. O SUMMatrix \u00e9 iterativo pois analisa qualquer quantidade de documentos em um cluster. Ele analisa os textos em pares com o intuito de identificar as senten\u00e7as similares.\nO sistema SUMMatrix calcula a diverg\u00eancia a partir da diverg\u00eancia JS ou KL bem como a similaridade do cosseno. Para calcular a diverg\u00eancia, considera-se os conjuntos P e Q que referem-se, respectivamente, ao conjunto de palavras da senten\u00e7a do primeiro texto e da senten\u00e7a do segundo texto. Pr(P,w) \u00e9 a probabilidade da palavra w na senten\u00e7a P e Pr(Q,w) da senten\u00e7a Q. Al\u00e9m da diverg\u00eancia JS ou KL, o sistema avalia a similaridade do cosseno entre duas senten\u00e7as. Assim, a diverg\u00eancia entre duas senten\u00e7as F1 e F2, Div(F1, F2), \u00e9 calculada pela equa\u00e7\u00e3o 5.2 e seu valor varia entre 0 e \u221e. Portanto, quanto menor for o valor da diverg\u00eancia maior ser\u00e1 a similaridade entre as senten\u00e7as."}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 54", "text": "Div(F1, F2) = [1\u2212 cos(F1, F2)] +DJS(F1||F2) (5.2)\nO SUMMatrix analisa os dois primeiros textos, denominados T1 e T2, e verifica quais senten\u00e7as (em pares) s\u00e3o mais similares atrav\u00e9s do c\u00e1lculo da diverg\u00eancia descrito na equa\u00e7\u00e3o 5.2. O sistema cria uma matriz de diverg\u00eancia onde as linhas representam as senten\u00e7as do T1 e as colunas representam as senten\u00e7as do T2. O sistema seleciona, em seguida, o par de senten\u00e7as (sT1, sT2) com menor diverg\u00eancia e calcula a diverg\u00eancia entre ele e o cluster. As senten\u00e7as selecionadas de cada par s\u00e3o consideradas mais relevantes e adicionadas ao Resumo Parcial, o qual cont\u00e9m as principais senten\u00e7as dos textos considerados. Nesse momento, o sistema analisa o conjunto Resumo Parcial e o texto seguinte, denominado T3. O sistema cria uma nova matriz de diverg\u00eancia entre as senten\u00e7as dos mesmos. O SUMMatrix seleciona os pares de senten\u00e7as mais similares, calcula a diverg\u00eancia das senten\u00e7as em rela\u00e7\u00e3o ao cluster e acrescenta a senten\u00e7a mais similar em cada par de senten\u00e7as no novo conjunto Resumo Parcial. O sistema repete esse processo at\u00e9 que todos os textos tenham sido analisados. O conjunto Resumo Final ser\u00e1 composto pelas senten\u00e7as da \u00faltima vers\u00e3o do conjunto Resumo Parcial.\nO sistema analisa o conjunto Resumo Final e cria o resumo sem senten\u00e7as redundantes a partir da similaridade de Dice [Dice 1945] e da taxa de compress\u00e3o definida pelo usu\u00e1rio. A figura 16 apresenta a arquitetura desse sistema de maneira estruturada."}, {"heading": "5.4.2 Exemplo", "text": "O conjunto de textos descrito na tabela 5.7 discorre sobre um mesmo acidente de avi\u00e3o ocorrido no Congo. O processo de sumariza\u00e7\u00e3o inicia com o pr\u00e9-tratamento do texto e com a cria\u00e7\u00e3o da matriz de palavras. O SUMMatrix calcula a diverg\u00eancia entre pares de senten\u00e7as dos textos T1 e T2 e identifica aquelas com menor diverg\u00eancia (tabela 5.3).\nAs senten\u00e7as identificadas s\u00e3o comparadas com o cluster completo para analisar a diverg\u00eancia entre elas. A senten\u00e7a de cada par de frases mais similar ao cluster \u00e9 selecionada para constituir o Resumo Parcial dos textos T1 e T2. A tabela 5.4 mostra a diverg\u00eancia entre as frases selecionadas e o cluster. Assim, o resumo parcial da an\u00e1lise dos textos T1 e T2 \u00e9 composto pelas frases: T1\u2212 2, T1\u2212 4, T1\u2212 7, T2\u2212 1 e T2\u2212 3.\nEm seguida, inicia-se a an\u00e1lise do Resumo Parcial e o texto T3. \u00c9 criada uma nova matriz de diverg\u00eancia entre eles (tabela 5.5). O sistema calcula a diverg\u00eancia entre as frases e seleciona os pares de menor diverg\u00eancia. Novamente, analisa-se os pares de senten\u00e7as"}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 55", "text": "Figura 16 \u2013 Sistema SUMMatrix.\ncom menor diverg\u00eancia em rela\u00e7\u00e3o ao cluster. Verifica-se a diverg\u00eancia entre as frases e o cluster completo e seleciona-se as frases de cada par que forem mais similares ao cluster para compor o Resumo Final do grupo de textos (tabela 5.6). Finalmente, o Resumo Final \u00e9 composto pelas frases: T1\u2212 4, T2\u2212 1, T2\u2212 3, T3\u2212 2 e T3\u2212 3."}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 56", "text": "Tabela 5.1 \u2013 Texto integrando o cluster do corpus CSTNews [Dias et al. 2014].\nTexto S-1 Termina hoje, \u00e0s 20 horas, o prazo para que os deputados acusados de participar do esquema dos sanguessugas renunciem para escapar da abertura de processo por quebra de decoro parlamentar. S-2 A expectativa de lideran\u00e7as da C\u00e2mara e do Conselho de \u00c9tica \u00e9 que pouco mais de 10% dos 69 deputados denunciados no relat\u00f3rio parcial da CPI dos Sanguessugas abrir\u00e3o m\u00e3o de seus mandatos. S-3 Integrante da c\u00fapula da C\u00e2mara que, nos \u00faltimos dias, conversou com ao menos 30 parlamentares acusados no caso calcula que sete podem renunciar - Nilton Capixaba (PTB-RO), Marcelino Fraga (PMDB-ES), C\u00e9sar Bandeira (PFL-MA), Benedito Dias (PP-AP), Carlos Nader (PL-RJ), Jo\u00e3o Caldas (PL-AL) e Reginaldo Germano (PP-BA). S-4 Ex-l\u00edder do PP, Pedro Henry (MT) cogitou sair da fun\u00e7\u00e3o, mas teria desistido da ideia. S-5 At\u00e9 ontem, s\u00f3 Coriolano Sales (PFL-BA) havia apresentado ren\u00fancia. S-6 Ele n\u00e3o quis arriscar a chance de assumir a prefeitura de Vit\u00f3ria da Conquista. S-7 Segundo colocado em 2004, Sales processou seu advers\u00e1rio por abuso do poder econ\u00f4mico e aguarda resultado. S-8 \u201cN\u00e3o d\u00e1 para avaliar quantos v\u00e3o renunciar\u201d, disse ontem o presidente do Conselho de \u00c9tica, Ricardo Izar (PTB-SP). S-9 Ele vai instaurar o processo contra os deputados envolvidos com a m\u00e1fia dos sanguessugas amanh\u00e3, \u00e0s 10h30. S-10 Formalizada antes da abertura, a ren\u00fancia cessa o procedimento. S-11 Izar pretende que os casos dos 15 parlamentares que receberam dep\u00f3sito na pr\u00f3pria conta banc\u00e1ria ou na de parentes sejam os primeiros julgados pelo Conselho. S-12 \u201cVou instaurar todos os processos juntos, mas a ideia \u00e9 que os 15 casos mais graves, que t\u00eam provas contundentes, sejam julgados na frente\u201d, afirmou Izar. S-13 O hor\u00e1rio-limite para que o parlamentar renuncie - 20 horas - foi estabelecido pela dire\u00e7\u00e3o da C\u00e2mara a fim de que o ato seja oficializado com a sua publica\u00e7\u00e3o j\u00e1 no Di\u00e1rio Oficial do Congresso de amanh\u00e3. S-14 A maioria dos 69 deputados acusados de envolvimento com a m\u00e1fia dos sanguessugas \u00e9 candidato \u00e0 reelei\u00e7\u00e3o e, com a ren\u00fancia, tentar\u00e1 escapar do risco de cassa\u00e7\u00e3o e da perda dos direitos pol\u00edticos por oito anos. S-15 Outros parlamentares resistem \u00e0 ren\u00fancia por considerarem ter chance de n\u00e3o sofrer puni\u00e7\u00e3o. S-16 Segundo investiga\u00e7\u00f5es iniciadas pela Pol\u00edcia Federal, o esquema consistia no desvio de recursos p\u00fablicos por meio da apresenta\u00e7\u00e3o de emendas parlamentares para a compra superfaturada de ambul\u00e2ncias. S-17 Dois dos 69 deputados acusados s\u00e3o da Mesa Diretora, mas se afastaram das fun\u00e7\u00f5es. S-18 Contra Jo\u00e3o Caldas, por exemplo, pesam 12 pagamentos no total de R$ 136 mil, alguns dos quais em sua pr\u00f3pria conta. S-19 Ele, por\u00e9m, resiste \u00e0 ideia de abrir m\u00e3o do mandato. S-20 J\u00e1 Capixaba, acusado de ter recebido R$ 646 mil, considera seriamente a hip\u00f3tese de renunciar. S-21 No caso dos integrantes da Igreja Universal, a possibilidade de sa\u00edda do cargo est\u00e1 afastada, pois os envolvidos, entre eles Edna Macedo (PTB-SP), foram proibidos pela dire\u00e7\u00e3o da institui\u00e7\u00e3o de concorrer \u00e0 reelei\u00e7\u00e3o. S-22 Eleitos na esteira do deputado En\u00e9as Carneiro (Prona-SP), ex-integrantes do partido suspeitos, como Irapuan Teixeira (PTB-PR) e Ildeu Ara\u00fajo (PP-SP), tiveram vota\u00e7\u00e3o insignificante em 2002 e n\u00e3o t\u00eam chance de reelei\u00e7\u00e3o. S-23 Devem preferir manter o resto do mandato."}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 57", "text": "Tabela 5.2 \u2013 Relev\u00e2ncia das senten\u00e7as segundo o sistema RAG.\nSenten\u00e7as Relev\u00e2ncia Senten\u00e7as Relev\u00e2ncia Senten\u00e7as Relev\u00e2ncia S-1 93,7 S-9 89,1 S-17 26,5 S-2 84,4 S-10 71,6 S-18 134,0 S-3 113,4 S-11 127,9 S-19 92,9 S-4 78,0 S-12 83,4 S-20 63,2 S-5 47,8 S-13 157,8 S-21 65,0 S-6 86,1 S-14 115,1 S-22 53,7 S-7 0 S-15 28,9 S-23 31 S-8 99,1 S-16 104,5 \u2014\u2013 \u2014-\nTabela 5.3 \u2013 Diverg\u00eancia entre as frases dos textos T1 e T2.\nT2\u2212 1 T2\u2212 2 T2\u2212 3 T2\u2212 4 T2\u2212 5 T2\u2212 6 T2\u2212 7 T1\u2212 1 0,44 0,55 0,56 0,65 0,65 0,63 0,48 T1\u2212 2 0,51 0,66 0,51 0,52 0,43 0,64 0,40 T1\u2212 3 0,67 0,65 0,35 0,64 0,65 0,63 0,66 T1\u2212 4 0,55 0,44 0,62 0,60 0,68 0,67 0,43 T1\u2212 5 0,59 0,64 0,44 0,63 0,63 0,60 0,65 T1\u2212 6 0,38 0,66 0,69 0,65 0,65 0,63 0,57 T1\u2212 7 0,49 0,65 0,68 0,64 0,64 0,63 0,47 T1\u2212 8 0,54 0,65 0,61 0,63 0,64 0,61 0,55\nTabela 5.4 \u2013 Diverg\u00eancia entre as senten\u00e7as selecionadas e o cluster.\nT1\u2212 1 T2\u2212 1 T1\u2212 5 T2\u2212 3 Cluster 0,55 0,39 Cluster 0,60 0,43 T1\u2212 2 T2\u2212 7 T1\u2212 6 T2\u2212 1 Cluster 0,53 0,55 Cluster 0,55 0,39 T1\u2212 3 T2\u2212 3 T1\u2212 7 T2\u2212 7 Cluster 0,57 0,43 Cluster 0,54 0,55 T1\u2212 4 T2\u2212 7 T1\u2212 8 T2\u2212 1 Cluster 0,34 0,55 Cluster 0,58 0,39\nTabela 5.5 \u2013 Diverg\u00eancia entre as frases do Resumo Parcial e o texto T3.\nT3\u2212 1 T3\u2212 2 T3\u2212 3 T3\u2212 4 T3\u2212 5 T1\u2212 2 0,52 0,50 0,55 0,68 0,64 T1\u2212 4 0,63 0,55 0,15 0,27 0,67 T1\u2212 7 0,50 0,68 0,27 0,58 0,63 T2\u2212 1 0,01 0,64 0,51 0,68 0,66 T2\u2212 3 0,65 0,02 0,69 0,64 0,68"}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 58", "text": "Tabela 5.6 \u2013 Diverg\u00eancia entre as senten\u00e7as selecionadas e o cluster.\nT1\u2212 2 T3\u2212 2 Cluster 0,53 0,44 T1\u2212 4 T3\u2212 3 Cluster 0,34 0,44 T1\u2212 7 T3\u2212 3 Cluster 0,54 0,44 T2\u2212 1 T3\u2212 1 Cluster 0,39 0,40 T2\u2212 3 T3\u2212 2 Cluster 0,43 0,44"}, {"heading": "5.4 SUMmarizer based on Matrix model (SUMMatrix) 59", "text": "Tabela 5.7 \u2013 Cluster com 3 textos de diferentes jornais relatando um mesmo acidente no Congo (corpus CSTNews [Dias et al. 2014]).\nTexto T1: T1-1 Ao menos 17 pessoas morreram ap\u00f3s a queda de um avi\u00e3o de passageiros na Rep\u00fablica Democr\u00e1tica do Congo. T1-2 Segundo uma porta-voz da ONU, o avi\u00e3o, de fabrica\u00e7\u00e3o russa, estava tentando aterrissar no aeroporto de Bukavu em meio a uma tempestade. T1-3 A aeronave se chocou com uma montanha e caiu, em chamas, sobre uma floresta a 15 quil\u00f4metros de dist\u00e2ncia da pista do aeroporto. T1-4 Acidentes a\u00e9reos s\u00e3o frequentes no Congo, onde 51 companhias privadas operam com avi\u00f5es antigos principalmente fabricados na antiga Uni\u00e3o Sovi\u00e9tica. T1-5 O avi\u00e3o acidentado, operado pela Air Traset, levava 14 passageiros e tr\u00eas tripulantes. T1-6 Ele havia sa\u00eddo da cidade mineira de Lugushwa em dire\u00e7\u00e3o a Bukavu, numa dist\u00e2ncia de 130 quil\u00f4metros. T1-7 Avi\u00f5es s\u00e3o usados extensivamente para transporte na Rep\u00fablica Democr\u00e1tica do Congo, um vasto pa\u00eds no qual h\u00e1 poucas estradas pavimentadas. T1-8 Apenas uma manteve a permiss\u00e3o. Texto T2: T2-1 Um acidente a\u00e9reo na localidade de Bukavu, no leste da Rep\u00fablica Democr\u00e1tica do Congo (RDC), matou 17 pessoas na quinta-feira \u00e0 tarde, informou nesta sexta-feira um porta-voz das Na\u00e7\u00f5es Unidas. T2-2 As v\u00edtimas do acidente foram 14 passageiros e tr\u00eas membros da tripula\u00e7\u00e3o. T2-3 Todos morreram quando o avi\u00e3o, prejudicado pelo mau tempo, n\u00e3o conseguiu chegar \u00e0 pista de aterrissagem e caiu numa floresta a 15 quil\u00f4metros do aeroporto de Bukavu. T2-4 Segundo fontes aeroportu\u00e1rias, os membros da tripula\u00e7\u00e3o eram de nacionalidade russa. T2-5 O avi\u00e3o explodiu e se incendiou, acrescentou o porta-voz da ONU em Kinshasa, Jean-Tobias Okala. T2-6 \u201cN\u00e3o houve sobreviventes\u201d, disse Okala. T2-7 O porta-voz informou que o avi\u00e3o, um Soviet Antonov-28 de fabrica\u00e7\u00e3o ucraniana e propriedade de uma companhia congolesa, a Trasept Congo, tamb\u00e9m levava uma carga de minerais. Texto T3: T3-1 Um acidente a\u00e9reo na localidade de Bukavu, no leste da Rep\u00fablica Democr\u00e1tica do Congo, matou 17 pessoas na quinta-feira \u00e0 tarde, informou hoje um porta-voz das Na\u00e7\u00f5es Unidas. T3-2 As v\u00edtimas do acidente foram 14 passageiros e tr\u00eas membros da tripula\u00e7\u00e3o. T3-3 Todos morreram quando o avi\u00e3o, prejudicado pelo mau tempo, n\u00e3o conseguiu chegar \u00e0 pista de aterrissagem e caiu numa floresta a 15 Km do aeroporto de Bukavu. T3-4 O avi\u00e3o explodiu e se incendiou, acrescentou o porta-voz da ONU em Kinshasa, Jean-Tobias Okala. T3-5 \u201cN\u00e3o houve sobreviventes\u201d, disse Okala.\n60\nCAP\u00cdTULO 6\nCORPUS E M\u00c9TODOS DE AVALIA\u00c7\u00c3O\nEste cap\u00edtulo descreve os corpus utilizados nos testes descritos no cap\u00edtulo 7. Ser\u00e3o apresentadas suas caracter\u00edsticas e os m\u00e9todos utilizados para avaliar a qualidade dos sistemas desenvolvidos e dos referenciados na literatura. A se\u00e7\u00e3o 6.1 descreve os corpus e a se\u00e7\u00e3o 6.2 descreve as m\u00e9tricas para avaliar a qualidade dos resumos."}, {"heading": "6.1 Corpus", "text": "O corpus \u00e9 um conjunto de textos com caracter\u00edsticas espec\u00edficas. As subse\u00e7\u00f5es\nseguintes descrevem os corpus utilizados e suas caracter\u00edsticas."}, {"heading": "6.1.1 Corpus multi-idioma", "text": "O corpus multi-idioma \u00e9 composto por textos de jornais e revistas cient\u00edficas em ingl\u00eas, franc\u00eas e espanhol. Al\u00e9m dessas caracter\u00edsticas, os resumos dos textos selecionados est\u00e3o dispon\u00edveis na literatura para outros sistemas sumarizadores [Torres-Moreno, Vel\u00e1zquez-Morales e Meunier 2002,Fern\u00c1ndez, SanJuan e Torres-Moreno 2008]. O corpus utilizado \u00e9 composto por 13 textos de diferentes tamanhos e assuntos."}, {"heading": "6.1.2 CSTNews", "text": "O corpus CSTNews11 \u00e9 composto por textos jornal\u00edsticos em Portugu\u00eas. Esse corpus possui not\u00edcias sobre pol\u00edtica, esportes, acidentes, mundo, entre outros. Ele cont\u00e9m 50\n11Corpus CSTNews: http://www.icmc.usp.br/\u223ctaspardo/sucinto/cstnews.html"}, {"heading": "6.1 Corpus 61", "text": "clusters, cada qual possuindo 2 ou 3 textos relacionados ao mesmo acontecimento. Os textos s\u00e3o provenientes de diferentes ag\u00eancias de not\u00edcias online populares no pa\u00eds: Folha de S\u00e3o Paulo, Estad\u00e3o, O Globo, Jornal do Brasil e Gazeta do Povo. Os textos foram selecionados durante os meses de agosto e setembro de 2007 [Dias et al. 2014]. O CSTNews possui 40.839 palavras e 258.818 caracteres."}, {"heading": "6.1.3 RPM", "text": "O corpus RPM12 \u00e9 composto por 40 clusters em Franc\u00eas. O corpus possui 20 tem\u00e1ticas e cada uma delas possui 2 clusters. Ele \u00e9 composto por textos de assuntos similares que foram coletados em momentos distintos. Esse corpus possui resumos elaborados por profissionais em cada cluster. O RPM possui 143.881 palavras e 905.348 caracteres."}, {"heading": "6.1.4 DECODA", "text": "O corpus DECODA \u00e9 composto de conversas em franc\u00eas entre clientes e agentes que foram registradas em 2009 em um call center da autoridade de transporte p\u00fablico de Paris (tabela 6.1) [Bechet et al. 2012]. Os t\u00f3picos das conversas consistem em pedidos de itiner\u00e1rios, cronogramas, perdidos e achados e reclama\u00e7\u00f5es. Os di\u00e1logos foram gravados em condi\u00e7\u00f5es espont\u00e2neas e focados no objetivo do autor da chamada. Essas grava\u00e7\u00f5es s\u00e3o um grande desafio para o reconhecimento autom\u00e1tico da fala devido \u00e0s condi\u00e7\u00f5es ac\u00fasticas dif\u00edceis, tais como liga\u00e7\u00f5es de telefones celulares diretamente do metr\u00f4.\nTabela 6.1 \u2013 Estat\u00edstica do corpus DECODA.\nEstat\u00edsticas FR Conversas 100 Falas 7.905 Palavras 42.130 Tamanho m\u00e9dio 421,3 Tamanho l\u00e9xico 2.995 N\u00famero de resumos 212 Tamanho m\u00e9dio do resumo 23\nO corpus \u00e9 composto por 1.513 conversas (cerca de 70 horas de conversa\u00e7\u00e3o). 1.000 conversas foram distribu\u00eddas sem sinopses para a forma\u00e7\u00e3o do sistema sem supervis\u00e3o e 50 outras foram distribu\u00eddas com v\u00e1rias sinopses para formar at\u00e9 cinco anotadores. O conjunto de testes consiste de 47 conversas traduzidas manualmente e\n12Corpus RPM: http://lia.univ-avignon.fr/fileadmin/documents/rpm2/rpm2_resumes_fr.html"}, {"heading": "6.2 M\u00e9todos de avalia\u00e7\u00e3o 62", "text": "suas correspondentes sinopses, e 53 conversas traduzidas automaticamente assim como suas correspondentes sinopses [Gillick e Favre 2009]."}, {"heading": "6.2 M\u00e9todos de avalia\u00e7\u00e3o", "text": "Os cap\u00edtulos anteriores descreveram diferentes metodologias para criar resumos, seja por resumidores profissionais ou por algum tipo de sumarizador autom\u00e1tico. No entanto, \u00e9 fundamental analisar a qualidade desses resumos. As subse\u00e7\u00f5es seguintes descrevem as principais m\u00e9tricas e sistemas encontrados na literatura para avaliar a informatividade dos resumos produzidos."}, {"heading": "6.2.1 M\u00e9tricas", "text": "Uma forma de verificar a qualidade do resumo \u00e9 viabilizada atrav\u00e9s da an\u00e1lise de 3 m\u00e9tricas (precis\u00e3o, cobertura e medida-f), que representam a informatividade do resumo criado. Essas m\u00e9tricas possibilitam identificar o conte\u00fado do resumo e verificar se o assunto do mesmo refere-se ao conte\u00fado geral do texto original ou se ele aborda somente alguns dados aleat\u00f3rios.\nA avalia\u00e7\u00e3o manual considera diferentes caracter\u00edsticas no texto para a compreens\u00e3o e para a avalia\u00e7\u00e3o do resumo como gramaticalidade, informatividade e coer\u00eancia. A gramaticalidade \u00e9 a qualidade gramatical de um texto, ou seja, ela identifica se uma frase esta constru\u00edda corretamente. A informatividade representa a porcentagem das informa\u00e7\u00f5es principais transmitidas no texto. A coer\u00eancia \u00e9 a liga\u00e7\u00e3o ou conex\u00e3o entre os fatos e/ou as ideias de uma hist\u00f3ria. Entretanto, algumas dessas avalia\u00e7\u00f5es dependem do conhecimento e da opini\u00e3o, entre outros fatores, dos resumidores profissionais. Por isso, a avalia\u00e7\u00e3o de resumos pode variar entre diferentes profissionais. Geralmente pode-se obt\u00ea-la atrav\u00e9s da an\u00e1lise fornecida por diferentes avaliadores, o que requer tempo e dinheiro. O avaliador l\u00ea o texto e seleciona suas principais informa\u00e7\u00f5es. Ap\u00f3s a leitura dos resumos fornecidos, ele verifica se o texto \u00e9 coerente e conciso com rela\u00e7\u00e3o ao tema discutido no texto original. Outro ponto analisado \u00e9 a informatividade do texto.\nOutra forma de avalia\u00e7\u00e3o poss\u00edvel feita pelos avaliadores consiste na cria\u00e7\u00e3o de seus pr\u00f3prios resumos e compara\u00e7\u00e3o com os resumos candidatos (produzidos automaticamente). Geralmente, utiliza-se as m\u00e9tricas precis\u00e3o e cobertura para avaliar a qualidade dos resumos assim produzidos. A primeira calcula a fra\u00e7\u00e3o de senten\u00e7as do resumo que s\u00e3o relevantes para o texto. A cobertura avalia a fra\u00e7\u00e3o de senten\u00e7as relevantes"}, {"heading": "6.2 M\u00e9todos de avalia\u00e7\u00e3o 63", "text": "do texto que est\u00e3o presentes no resumo. Uma forma de unir essas duas m\u00e9tricas \u00e9 dada pela medida-f (equa\u00e7\u00e3o 6.1).\nmedida-f = 2\u00d7 precisa\u0303o\u00d7 cobertura\nprecisa\u0303o+ cobertura (6.1)"}, {"heading": "6.2.2 ROUGE", "text": "O sistema ROUGE \u00e9 um avaliador autom\u00e1tico de resumos desenvolvido por [Lin 2004] baseado no sistema BLUE [Papineni et al. 2002]. O ROUGE utiliza resumos de profissionais como refer\u00eancia para avaliar os demais resumos. Ele faz uso de diferentes m\u00e9tricas para determinar a similaridade entre os resumos dos profissionais e os resumos candidatos. Ser\u00e3o consideradas apenas as m\u00e9tricas ROUGE-N e ROUGE-SU nesta disserta\u00e7\u00e3o. A ROUGE-N avalia a co-ocorr\u00eancia de n-gramas. Em outras palavras, ela \u00e9 a recupera\u00e7\u00e3o de n-gramas entre um sum\u00e1rio candidato e um conjunto de resumos de refer\u00eancias (SumRef). Ela \u00e9 calculada atrav\u00e9s da equa\u00e7\u00e3o 6.2.\nROUGE-N =\n\u2211 S\u2208SumRef \u2211 n-gramas\u2208S Countmatch(n-gramas)\u2211\nS\u2208SumRef\n\u2211 n-gramas\u2208S Count(n-gramas)\n(6.2)\nA ROUGE-N ser\u00e1 utilizada para avaliar unigramas (ROUGE-1) e bigramas (ROUGE-2). A ROUGE-SU \u00e9 uma extens\u00e3o da ROUGE-S, que avalia tamb\u00e9m quaisquer pares de palavras na ordem das senten\u00e7as entre os resumos (skip-bigrama ou skip2). Dessa forma, a ROUGE-S calcula a precis\u00e3o (Pr), a cobertura (Cb) e a medida-f , conforme as equa\u00e7\u00f5es 6.3, 6.4 e 6.5, respectivamente.\nPrskip2 = SKIP2(P,Q)\nComb(m, 2) (6.3)\nCbskip2 = SKIP2(P,Q)\nComb(n, 2) (6.4)\nFskip2 = (1 + \u03b22)\u00d7 Cbskip2 \u00d7 Prskip2\nCbskip2 + \u03b22 \u00d7 Prskip2 (6.5)\nSKIP2(P,Q) \u00e9 a quantidade de skip-gramas iguais entre P e Q, \u03b2 controla a relev\u00e2ncia do Pskip2 e Rskip2, e Comb \u00e9 a fun\u00e7\u00e3o de combina\u00e7\u00f5es poss\u00edveis.\nEntretanto, a ROUGE-S n\u00e3o valoriza as senten\u00e7as dos resumos em que n\u00e3o h\u00e1 uma"}, {"heading": "6.2 M\u00e9todos de avalia\u00e7\u00e3o 64", "text": "co-ocorr\u00eancia das palavras do resumo candidato com rela\u00e7\u00e3o aos sum\u00e1rios de refer\u00eancia. Nesse caso, a ROUGE-SU adiciona a contagem de unigramas permitindo \u00e0s palavras isoladas uma certa relev\u00e2ncia no processo de avalia\u00e7\u00e3o."}, {"heading": "6.2.3 FRESA", "text": "Nem sempre tem-se recursos financeiros e tempo para a obten\u00e7\u00e3o de resumos de refer\u00eancia para os textos considerados. Nesse caso, o sistema FRESA apresenta-se como uma boa op\u00e7\u00e3o. FRESA \u00e9 um avaliador de resumos que analisa a qualidade dos mesmos sem necessitar de resumos de refer\u00eancia [Torres-Moreno et al. 2010]. Ele avalia a qualidade do texto a partir das distribui\u00e7\u00f5es de probabilidades P e Q, que representam a distribui\u00e7\u00e3o do resumo Res e o documento Doc, respectivamente. Ele calcula a DJS para unigramas, bigramas, bigramas-SU4 e suas combina\u00e7\u00f5es para P e Q (equa\u00e7\u00e3o 3.10). O FRESA utiliza as atribui\u00e7\u00f5es explicitas na equa\u00e7\u00e3o 6.6, onde FDocw \u00e9 a frequ\u00eancia da palavra w no documento, FResw \u00e9 a frequ\u00eancia da palavra w no resumo, NP \u00e9 o n\u00famero de palavras do resumo e do documento, \u03b2 \u00e9 1, 5\u00d7 voc, voc \u00e9 o vocabul\u00e1rio do resumo e do documento e \u03b3 \u00e9 par\u00e2metro de suaviza\u00e7\u00e3o. Dessa forma, o FRESA avalia a precis\u00e3o, a cobertura e a medida-f para cada resumo de acordo com o texto original.\nPw = FDocw |Doc| ;Qw =\n{ FResw |Res|\n, se w \u2208 Res FDocw +\u03b3 NP+\u03b3\u00d7\u03b2 , caso contr\u00e1rio\n} (6.6)\n65\nCAP\u00cdTULO 7\nAVALIA\u00c7\u00c3O EXPERIMENTAL\nOs testes foram realizados em um computador com processador i5@2.6 GHz e 4 GB de mem\u00f3ria RAM no sistema operacional GNU/Linux Ubuntu 15.04 64-bits. Os algoritmos que comp\u00f5em os sistemas LIA-RAG, RAG, SASI e SUMMatrix foram implementados na linguagem de programa\u00e7\u00e3o Perl. Foram desenvolvidos igualmente dois sistemas baselines (resumos produzidos aleatoriamente, base-rand, e contendo as primeiras senten\u00e7as, base-first, dos textos) para auxiliar na avalia\u00e7\u00e3o dos sistemas. As se\u00e7\u00f5es a seguir descrevem os resultados obtidos dos sistemas propostos nesta disserta\u00e7\u00e3o para cada corpus analisado, sendo que alguns sistemas foram testados com um corpus espec\u00edfico tendo em vista as particularidades do problema considerado (\u00e1udio ou texto, mono ou multi-documento, etc)."}, {"heading": "7.1 Avalia\u00e7\u00e3o do sistema SASI (Corpus multi-idioma)", "text": "O corpus multi-idioma foi utilizado para avaliar o desempenho do sistema SASI. Foram considerados na compara\u00e7\u00e3o dos resultados os valores fornecidos pelos sistemas sumarizadores Cortex, Enertex e REG. O REG modela o documento como um grafo e atribui uma pondera\u00e7\u00e3o \u00e0s arestas para gerar o resumo do texto [Torres-Moreno e Ram\u00edrez 2010].\nAs similaridades foram analisadas entre: duas frases (DFrase); uma frase e o t\u00edtulo (DT itulo); e uma frase e o documento (DTexto). A tabela 7.1 descreve o n\u00edvel de similaridade relacionado ao valor da diverg\u00eancia JS e aos valores selecionados (parametriza\u00e7\u00e3o) nos experimentos aqui descritos. Analisou-se o \u03b3 variando entre 0, 01 e 0, 20 e, a partir dos resultados obtidos, selecionou-se \u03b3 = 0, 1."}, {"heading": "7.1 Avalia\u00e7\u00e3o do sistema SASI (Corpus multi-idioma) 66", "text": "Tabela 7.1 \u2013 N\u00edvel de similaridade relacionado \u00e0 diverg\u00eancia JS\nPar\u00e2metros N\u00edvel de similaridade\nFraca M\u00e9dia Forte Selecionado DFrase JS > 0, 75 0, 25 < JS < 0, 75 JS < 0, 25 0,32 DT itulo JS > 0, 8 0, 4 < JS < 0, 8 JS < 0, 4 0,6 DTexto JS > 0, 95 0, 65 < JS < 0, 95 JS < 0, 65 0,9\nA tabela 7.2 mostra 4 textos13 extra\u00eddos do corpus multi-idioma e os resumos produzidos pelo SASI, ressaltando a quantidade de frases presentes nos resumos constru\u00eddos automaticamente para textos de diferentes tamanhos e valores do par\u00e2metro DFrase. Pode-se observar, a partir dos dados dessa tabela, que quanto maior o valor da DJS entre frases menor ser\u00e1 o resumo (n\u00famero de frases) fornecido pelo sistema. Portanto, esse valor depender\u00e1 do tamanho do resumo que se deseja obter. Deve-se considerar que quanto menor o resumo mais informa\u00e7\u00f5es ser\u00e3o omitidas e a informatividade poder\u00e1 ser reduzida.\nTabela 7.2 \u2013 Tamanho dos resumos obtidos para um conjunto de valores da DJS .\nTextos\nQuantidade de Frases\nTexto Original (frases) Resumos\nValor da DFrase 0,30 0,32 0,33 0,35 0,40\nMars 12 6 4 4 4 2 Puces 31 14 9 8 5 3 Lewinsky 32 13 7 7 5 3 Quebec 45 18 15 14 12 6\nO gr\u00e1fico 7.1 descreve o desempenho obtido em segundos pelo sistema SASI na produ\u00e7\u00e3o de resumos a partir dos textos da tabela 7.2, com a quantidade de palavras variando entre 11 e 214. Os sistemas obtiveram os seguintes tempos de execu\u00e7\u00e3o total para o corpus analisado: Cortex, 58,27 segundos; Enertex, 56,80 segundos; REG, 55,70 segundos; e SASI, 38,78 segundos.\nAnalisou-se, ainda, a qualidade dos resumos atrav\u00e9s da informatividade (tabela 7.3) calculada atrav\u00e9s da taxa de acerto das frases fornecidas pelos sistemas sumarizadores em rela\u00e7\u00e3o aos resumos dos profissionais. O SASI obteve o melhor resultado ao resumir o texto Quebec e um desempenho semelhante aos outros sistemas com rela\u00e7\u00e3o ao texto Puces. No caso dos textos Lewinsky e Mars, o SASI teve uma taxa de acerto inferior aos demais sistemas pois os SIV calculados n\u00e3o corresponderam aos SIM dos grafos analisados, o que\n13Textos dispon\u00edveis em: http://www.lia.univ-avignon.fr/chercheurs/torres/recherche/cortex e http://en.wikipedia.org/wiki/Quebec_sovereignty_movement;Monica_Lewinsky;Nazca_lines"}, {"heading": "7.1 Avalia\u00e7\u00e3o do sistema SASI (Corpus multi-idioma) 67", "text": "Gr\u00e1fico 7.1 \u2013 Desempenho do sistema SASI para o corpus multi-idioma.\n0 5 10 15 20 25 30 35 40 45 0\n0.5\n1\n1.5\nQuantidade de frases\nT em\npo (\nse gu\nnd os\n)\nimplica que a pondera\u00e7\u00e3o das frases n\u00e3o foi suficientemente significativa para selecionar outros elementos importantes dos textos. Nos demais textos do corpus, os resumos tiveram uma taxa de informatividade semelhante aos resultados obtidos com a sumariza\u00e7\u00e3o de Puces. Assim, apesar do SASI ter obtido um desempenho inferior em 69% com rela\u00e7\u00e3o aos textos analisados, a informatividade dos documentos foi preservada, o que \u00e9 extremamente importante na constru\u00e7\u00e3o de um resumo de forma autom\u00e1tica.\nTabela 7.3 \u2013 An\u00e1lise da precis\u00e3o dos resumos gerados automaticamente.\nTextos Sistemas SASI Cortex Enertex REG Mars 67% 100% 100% 100% Puces 63% 75% 63% 63%\nLewinsky 43% 57% 57% 57% Quebec 73% 55% 46% 55%\nO SASI \u00e9 uma ferramenta que tem por base uma heur\u00edstica simples e que se apoia em c\u00e1lculos estat\u00edsticos menos complexos do que outros sistemas utilizados no dom\u00ednio do PLN no \u00e2mbito da sumariza\u00e7\u00e3o autom\u00e1tica de documentos. A integra\u00e7\u00e3o de novas regras sint\u00e1ticas e sem\u00e2nticas para pr\u00e9-tratamento dos textos prover\u00e1 melhorias no desempenho do SASI. Al\u00e9m disso, com base nos testes realizados, o desenvolvimento de um m\u00e9todo mais refinado para c\u00e1lculo do SIV que assegure resultados mais pr\u00f3ximos de um SIM priorizando sempre um dos v\u00e9rtices de maior grau em cada grupo, impactar\u00e1 de maneira positiva na qualidade dos sum\u00e1rios produzidos, visto que ser\u00e1 escolhido um numero maior de \u201cfrases importantes\u201d do texto e com conte\u00fado distinto, o que evitar\u00e1 que frases relevantes sejam descartadas no processo."}, {"heading": "7.2 Avalia\u00e7\u00e3o do sistema SUMMatrix (Corpus CSTNews) 68", "text": ""}, {"heading": "7.2 Avalia\u00e7\u00e3o do sistema SUMMatrix (Corpus CSTNews)", "text": "Os resumos dos profissionais produzidos para os textos do corpus CSTNews foram usados como refer\u00eancia para avaliar a qualidade dos sistemas Artex, Cortex, Enertex, GistSumm, LexRank, SUMMatrix e base-rand.\nOs sistemas avaliadores FRESA e ROUGE foram utilizados para analisar a qualidade dos resumos produzidos automaticamente. Os resumos produzidos foram de qualidade m\u00e9dia e permitiram a compreens\u00e3o do texto. A tabela 7.4 mostra os resultados dos sistemas com a avalia\u00e7\u00e3o do FRESA usando o processo de stemming e uma taxa de compress\u00e3o de 20%. O sistema Cortex obteve os melhores resultados em todas as caracter\u00edsticas. O SUMMatrix obteve bons resultados e foi melhor que os sistemas baseline (base-rand), GistSumm e LexRank (gr\u00e1fico 7.2, os melhores sistemas est\u00e3o posicionados \u00e0 direita e no topo do gr\u00e1fico.).\nTabela 7.4 \u2013 Experimentos com o CSTNews para resumos sem refer\u00eancias.\nSistemas FRESA-1 FRESA-2 FRESA-4 Artex 0,70258 0,64898 0,64193 baseline 0,66725 0,60514 0,59671 Cortex 0,71277 0,65648 0,64892 Enertex 0,69969 0,64833 0,64121\nGistSumm 0,63873 0,59095 0,58714 LexRank 0,66545 0,60799 0,60106 SUMMatrix 0,68707 0,63087 0,62464\nA tabela 7.5 mostra a avalia\u00e7\u00e3o do sistema ROUGE usando as mesmas caracter\u00edsticas usadas na avalia\u00e7\u00e3o FRESA. Nessa avalia\u00e7\u00e3o, o SUMMatrix obteve os melhores resultados para todos os par\u00e2metros do ROUGE. O gr\u00e1fico 7.3 mostra a qualidade dos resumos descritos na tabela 7.5, baseado nas m\u00e9tricas ROUGE-2 e ROUGE-SU. Nesse caso, SUMMatrix foi o melhor sistema seguido por GistSumm e LexRank. Os sistemas Artex, Cortex e Enertex tiveram desempenho similares.\nTabela 7.5 \u2013 Experimentos com o CSTNews usando resumos de profissionais.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,43871 0,23515 0,16102 base-rand 0,42877 0,17859 0,15773 Cortex 0,44270 0,23586 0,16279 Enertex 0,43688 0,23853 0,16099\nGistSumm 0,44629 0,22395 0,19043 LexRank 0,46765 0,21586 0,18396 SUMMatrix 0,47749 0,25011 0,19141"}, {"heading": "7.2 Avalia\u00e7\u00e3o do sistema SUMMatrix (Corpus CSTNews) 69", "text": "Gr\u00e1fico 7.2 \u2013 Avalia\u00e7\u00e3o FRESA dos sistemas usando CSTNews.\nO tempo de execu\u00e7\u00e3o do SUMMatrix foi maior que o dos outros sistemas (tabela 7.6). Entretanto, ele obteve um excelente resultado quando avaliado com o ROUGE (teste mais relevante pois utiliza os resumos de refer\u00eancia) e bons resultados com o FRESA.\nGr\u00e1fico 7.3 \u2013 Avalia\u00e7\u00e3o ROUGE dos sistemas usando CSTNews.\nForam realizados, ainda, os mesmos testes com uma taxa de compress\u00e3o de 30%.\nNesse cen\u00e1rio, os resultados obtidos foram similares para o FRESA e para o ROUGE."}, {"heading": "7.3 Avalia\u00e7\u00e3o do sistema RAG (Corpus RPM) 70", "text": "Tabela 7.6 \u2013 Tempo de execu\u00e7\u00e3o dos sistemas usando o corpus CSTNews.\nArtex base-rand Cortex Enertex\n11,7s 10,5s 13,1s 12,4s GistSumm LexRank SUMMatrix\n50,765s 25,0s 242,4s"}, {"heading": "7.3 Avalia\u00e7\u00e3o do sistema RAG (Corpus RPM)", "text": "O sistema RAG foi utilizado para avaliar todos os clusters do corpus RPM e produzir automaticamente resumos com as principais informa\u00e7\u00f5es do grupo analisado. Para esse corpus, analisou-se os resultados (resumos) produzidos pelos sistemas Artex, Cortex, Enertex, LexRank, RAG, base-first e base-rand.\nPara avaliar a qualidade dos resumos, fez-se uso do sistema ROUGE (se\u00e7\u00e3o 6.2.2). A tabela 7.5 mostra os resultados dos sistemas com a avalia\u00e7\u00e3o ROUGE em que os resumos s\u00e3o compostos por 100 palavras para um cluster (tabela 7.7) e para dois clusters (tabela 7.8) de cada tem\u00e1tica. Considerando os dois casos, o sistema Enertex obteve os melhores resultados para os par\u00e2metros ROUGE-2 e ROUGE-SU. O sistema RAG obteve bons resultados e foi melhor que os sistemas Artex, base-first, base-rand, Cortex e LexRank.\nTabela 7.7 \u2013 Avalia\u00e7\u00e3o ROUGE dos sistemas utilizando um \u00fanico cluster do RPM.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,36406 0,10953 0,13532 base-first 0,33915 0,08126 0,11443 base-rand 0,31885 0,05697 0,09917 Cortex 0,36810 0,10605 0,13407 Enertex 0,37697 0,12057 0,14778 LexRank 0,38965 0,12201 0,14424 RAG 0,37852 0,11795 0,14490\nO gr\u00e1fico 7.4 sumariza os dados com rela\u00e7\u00e3o \u00e0 qualidade de cada resumo baseado nas m\u00e9tricas ROUGE-2 e ROUGE-SU com rela\u00e7\u00e3o aos resultados obtidos utilizando os dois clusters do corpus RPM."}, {"heading": "7.4 Avalia\u00e7\u00e3o dos sistemas LIA-RAG e RAG (Corpus DECODA)", "text": "\u201cMultiling \u00e9 uma iniciativa dirigida para sistemas de sumariza\u00e7\u00e3o multi-lingue\nbenchmarking, para incentivar a pesquisa e alavancar o estado da arte na \u00e1rea\u201d14. A iniciativa MultiLing 2015 possuiu as seguintes tarefas: Multilingual\n14http://multiling.iit.demokritos.gr/pages/view/1517/multiling-2015-call-for-participation"}, {"heading": "7.4 Avalia\u00e7\u00e3o dos sistemas LIA-RAG e RAG (Corpus DECODA) 71", "text": "Tabela 7.8 \u2013 Avalia\u00e7\u00e3o ROUGE dos sistemas utilizando dois clusters do RPM.\nSistemas ROUGE-1 ROUGE-2 ROUGE-SU Artex 0,36205 0,10420 0,13280 base-first 0,33805 0,08098 0,11592 base-rand 0,32138 0,06353 0,10082 Cortex 0,36432 0,10342 0,13279 Enertex 0,36867 0,11255 0,14112 LexRank 0,37139 0,11107 0,13654 RAG 0,36607 0,11119 0,13864\nMulti-document Summarization, Multilingual Single-document Summarization, Online Forum Summarization e Call Centre Conversation Summarization (CCCS). A tarefa piloto CCCS consiste em \u201ccriar sistemas que analisem conversas de call centers e gerem\nresumos textuais refletindo o motivo do cliente estar ligando, como o agente responde \u00e0s\nquest\u00f5es, os passos para solucionar os problemas e o estado de resolu\u00e7\u00e3o do problema\" [Gillick e Favre 2009].\nGr\u00e1fico 7.4 \u2013 Avalia\u00e7\u00e3o ROUGE dos sistemas usando o corpus RPM.\nFoi utilizado o corpus Franc\u00eas DECODA [Bechet et al. 2012]. Os sistemas devem produzir resumos com a ideia principal das conversas. \u201cOs t\u00f3picos das conversas variam entre itiner\u00e1rio e pedidos de hor\u00e1rios, perdidos e achados e reclama\u00e7\u00f5es \u201d [Gillick e Favre 2009]. Cada resumo tem 7% do n\u00famero de palavras de cada conversa transcrita. Comparou-se os sistemas LIA-RAG e RAG com os sistemas base-first, base-rand e os demais sistemas da competi\u00e7\u00e3o (NTNU:1, NTNU:2 e NTNU:3)."}, {"heading": "7.5 An\u00e1lise geral 72", "text": "O Multiling CCCS utilizou o sistema ROUGE15 para avaliar a qualidade dos sistemas. A tabela 7.9 exibe os resultados obtidos usando os sistemas citados anteriormente e o corpus de treinamento16. Ambas as vers\u00f5es do RAG foram melhores que os demais sistemas da competi\u00e7\u00e3o. O p\u00f3s-processamento do LIA-RAG permitiu melhorar os resultados do RAG por meio da redu\u00e7\u00e3o dos erros e produzir um resumo mais informativo e conciso.\nTabela 7.9 \u2013 Avalia\u00e7\u00e3o dos sistemas usando o corpus de treinamento DECODA.\nSistemas ROUGE-1 ROUGE-2 ROUGE-4 LIA-RAG:1 0,1893 0,0628 0,0683\nRAG 0,1833 0,0614 0,0654 base-first 0,1578 0,0556 0,0583 base-rand 0,1170 0,0310 0,0371\nO corpus Franc\u00eas de teste tem 100 conversas transcritas com 42.130 palavras e 212 resumos. A performance oficial ROUGE-2 para os sistemas participantes do CCCS \u00e9 exibida na tabela 7.10 [Gillick e Favre 2009]. O sistema LIA-RAG obteve os melhores resultados.\nTabela 7.10 \u2013 Avalia\u00e7\u00e3o dos sistemas usando o corpus de teste DECODA.\nSistemas ROUGE-2 LIA-RAG:1 0,037\nNTNU:1 0,035 NTNU:3 0,034 NTNU:2 0,027"}, {"heading": "7.5 An\u00e1lise geral", "text": "Os 4 sistemas (LIA-RAG, RAG, SASI e SUMMatrix) desenvolvidos nesta disserta\u00e7\u00e3o possuem diferentes abordagens e s\u00e3o mais indicados para certos tipos de corpus e aplica\u00e7\u00f5es. Cada corpus possui caracter\u00edsticas espec\u00edficas e, portanto, a metodologia de um sistema pode ser melhor que a de um outro para um dado corpus.\nO corpus multi-idioma \u00e9 muito vari\u00e1vel pois aborda diferentes temas em diversos idiomas. Essa caracter\u00edstica dificulta a identifica\u00e7\u00e3o da relev\u00e2ncia das senten\u00e7as. Os sistemas Cortex, Enertex e REG tiveram um desempenho melhor para os documentos de pequeno tamanho. Entretanto, o SASI obteve os melhores resultados \u00e0 medida em que\n15Os par\u00e2metros de execu\u00e7\u00e3o: ROUGE 1.5.5 -a -l 10000 -n 4 -x -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0 16O corpus de treinamento \u00e9 utilizado para configurar e testar o sistema para as caracter\u00edsticas\nespec\u00edficas do corpus de avalia\u00e7\u00e3o."}, {"heading": "7.5 An\u00e1lise geral 73", "text": "o tamanho dos documentos a serem resumidos aumentou. Portanto, o SASI conseguiu mensurar com efici\u00eancia e efic\u00e1cia a relev\u00e2ncia das senten\u00e7as em documentos de diferentes tem\u00e1ticas.\nO corpus CSTNews \u00e9 composto por grupos de not\u00edcias jornal\u00edsticas similares sobre um mesmo acontecimento. Textos jornal\u00edsticos normalmente possuem as principais informa\u00e7\u00f5es descritas nas primeiras senten\u00e7as e, frequentemente, as principais informa\u00e7\u00f5es est\u00e3o presentes em todas not\u00edcias. A caracter\u00edstica do SUMMatrix de identificar e priorizar as informa\u00e7\u00f5es que est\u00e3o presentes na maioria dos documentos permite produzir resumos com as informa\u00e7\u00f5es de destaque das not\u00edcias. O SUMMatrix n\u00e3o obteve os melhores resultados na avalia\u00e7\u00e3o FRESA. Entretanto, essa avalia\u00e7\u00e3o analisa o resumo com rela\u00e7\u00e3o ao texto integral de uma not\u00edcia, que n\u00e3o \u00e9 o mais importante para textos jornal\u00edsticos pois os mesmos podem conter informa\u00e7\u00f5es irrelevantes ou desnecess\u00e1rias sobre um acontecimento. A an\u00e1lise de textos jornal\u00edsticos foca-se na produ\u00e7\u00e3o de resumos com os dados mais relevantes. Assim, o sum\u00e1rio n\u00e3o precisa ser o melhor na an\u00e1lise do FRESA, mas deve ser o melhor na an\u00e1lise do sistema ROUGE, que compara o resumo candidato com os produzidos por humanos. Nesse cen\u00e1rio, o SUMMatrix obteve os melhores resultados no sistema ROUGE para o corpus CSTNews.\nO corpus RPM \u00e9 dividido em dois clusters por tem\u00e1tica. Os textos de cada cluster foram selecionados em diferentes per\u00edodos podendo envolver diferentes acontecimentos. O sistema RAG baseia-se na an\u00e1lise das palavras e na quantidade de senten\u00e7as similares entre si para avaliar a relev\u00e2ncia das mesmas no texto. Apesar das senten\u00e7as poderem referenciar acontecimentos diferentes, a tem\u00e1tica das senten\u00e7as pode ser similar e juntamente com a an\u00e1lise das palavras, \u00e9 poss\u00edvel identificar a import\u00e2ncia das senten\u00e7as com rela\u00e7\u00e3o ao cluster. Baseando-se nessa metodologia, o sistema RAG obteve o segundo melhor desempenho na maioria das m\u00e9tricas quando avaliado pelos sistemas FRESA e ROUGE.\nO corpus DECODA trata de conversas sobre um assunto espec\u00edfico em centrais de atendimento ao cliente. Os textos cont\u00e9m a narra\u00e7\u00e3o do problema ocorrido e uma poss\u00edvel solu\u00e7\u00e3o proposta (se foi disponibilizada durante a conversa). As express\u00f5es vocais e outros erros de conversas transcritas (por exemplo, \u201cbah\u201d, \u201chein\u201d, \u201cah\u201d, express\u00f5es sem relev\u00e2ncia para o texto, abrevia\u00e7\u00f5es erradas, falhas no reconhecimento de algumas palavras, entre outros erros) ocupam espa\u00e7o no resumo e n\u00e3o possuem import\u00e2ncia. Essas express\u00f5es reduzem a informatividade e seu tratamento propicia uma melhoria da qualidade dos resumos produzidos. Por isso, o sistema LIA-RAG gerou sum\u00e1rios leg\u00edveis e com as informa\u00e7\u00f5es mais pertinentes do texto. Os resultados do LIA-RAG foram melhores que"}, {"heading": "7.5 An\u00e1lise geral 74", "text": "os resultados dos sistemas NTNU da competi\u00e7\u00e3o Multiling CCCS.\n75\nCAP\u00cdTULO 8\nCONCLUS\u00c3O E TRABALHOS FUTUROS\nO Processamento da Linguagem Natural (PLN) se tornou fundamental para a sociedade devido \u00e0 quantidade de informa\u00e7\u00f5es presentes no cotidiano. Atualmente, h\u00e1 um grande investimento em todas os campos de estudo do PLN, com destaque para a \u00e1rea de Sumariza\u00e7\u00e3o Autom\u00e1tica de Textos (SAT). Empresas como a Google est\u00e3o investindo nesse dom\u00ednio e nas facilidades obtidas com sua utiliza\u00e7\u00e3o.\nOs sistemas desenvolvidos neste trabalho (LIA-RAG, RAG, SASI e SUMMatrix) conseguiram produzir resumos compreens\u00edveis com as principais senten\u00e7as dos documentos originais e em diferentes idiomas. Com rela\u00e7\u00e3o aos demais sistemas sumarizadores referenciados na literatura, os sistemas desenvolvidos tiveram excelente desempenho, posicionando-se entre os melhores (que fornecem resumos mais informativos).\nMesmo produzindo resumos com boa informatividade, os resumos por extra\u00e7\u00e3o s\u00e3o compostos por senten\u00e7as isoladas e nem sempre \u00e9 poss\u00edvel obter uma constru\u00e7\u00e3o sint\u00e1tica e sem\u00e2ntica coerente entre as senten\u00e7as. Os resumos por abstra\u00e7\u00e3o possuem uma melhor estrutura sint\u00e1tica e sem\u00e2ntica, mas sua dificuldade reside em construir resumos para um cen\u00e1rio multi-idioma."}, {"heading": "8.1 Trabalhos futuros", "text": "Os pr\u00f3ximos trabalhos visam desenvolver um sumarizador cross-lingue envolvendo os idiomas Espanhol, Franc\u00eas, Ingl\u00eas e Portugu\u00eas em contexto multicultural. A relev\u00e2ncia multicultural \u00e9 fundamental para analisar documentos de diferentes regi\u00f5es, pois palavras similares podem apresentar diferentes significados em regi\u00f5es distintas. Assim, pretende-se"}, {"heading": "8.1 Trabalhos futuros 76", "text": "analisar o idioma do utilizador do sistema de forma a produzir automaticamente um resumo adaptado \u00e0 sua l\u00edngua e cultura.\nCogita-se a utiliza\u00e7\u00e3o da representa\u00e7\u00e3o Word Embedding17 para analisar e representar um Big Data18 de documentos a fim de mensurar a relev\u00e2ncia das senten\u00e7as e seu significado em diferentes idiomas. Ser\u00e3o utilizados, igualmente, t\u00e9cnicas de sumariza\u00e7\u00e3o por abstra\u00e7\u00e3o no idioma do utilizador do sistema. As senten\u00e7as ser\u00e3o produzidas por meio dos processos de compress\u00e3o e fus\u00e3o multi-frases objetivando-se uma melhora na sua concis\u00e3o e informatividade. Concomitante a essas t\u00e9cnicas, pretende-se desenvolver alguns m\u00e9todos heur\u00edsticos/meta-heur\u00edsticos e h\u00edbridos buscando maximizar a informatividade e a legibilidade do resumo.\n17Word Embedding \u00e9 o conjunto de modelagens de um idioma e suas t\u00e9cnicas de aprendizagem em PLN, em que as palavras e as frases s\u00e3o mapeadas para vetores reais em um espa\u00e7o cont\u00ednuo de baixa dimensionalidade.\n18Big Data \u00e9 um conjunto de dados muito grande e/ou complexo.\n77\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS\nARCHANA AB; SUNITHA C. An overview of document summarization techniques. International Journal on Advanced Computer Theory and Engineering, p. 113\u2013118, 2013.\nBARALIS, E.; CAGLIERO, L.; MAHOTO, N. A.; FIORI, A. Graphsum: Discovering correlations among multiple terms for graph-based summarization. Inf. Sci., v. 249, p. 96\u2013109, 2013.\nBARZILAY, R.; MCKEOWN, K. R. Sentence fusion for multidocument news summarization. Comput. Linguist., MIT Press, v. 31, n. 3, p. 297\u2013328, 2005.\nBARZILAY, R.; MCKEOWN, K. R.; ELHADAD, M. Information fusion in the context of multi-document summarization. In: Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics. [S.l.]: Association for Computational Linguistics, 1999. (ACL \u201999), p. 550\u2013557.\nBECHET, F.; MAZA, B.; BIGOUROUX, N.; BAZILLON, T.; EL-BEZE, M.; MORI, R. D.; ARBILLOT, E. Decoda: a call-centre human-human spoken conversation corpus. In: CHAIR), N. C. C.; CHOUKRI, K.; DECLERCK, T.; DO\u011fAN, M. U.; MAEGAARD, B.; MARIANI, J.; MORENO, A.; ODIJK, J.; PIPERIDIS, S. (Ed.). Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC\u201912). Istanbul, Turkey: European Language Resources Association (ELRA), 2012. ISBN 978-2-9517408-7-7.\nBOUDIN, F.; TORRES-MORENO, J.-M. Neo-cortex: A performant user-oriented multi-document summarization system. In: GELBUKH, A. (Ed.). Computational Linguistics and Intelligent Text Processing. [S.l.]: Springer Berlin Heidelberg, 2007, (Lecture Notes in Computer Science, v. 4394). p. 551\u2013562. ISBN 978-3-540-70938-1.\nBUTENKO, S. Maximum Independent Set and Related Problems, with Applications. Tese (Doutorado), Gainesville, FL, USA, 2003. AAI3120100.\nDIAS, M. S.; GARAY, A. Y. B.; CHUMAN, C.; BARROS, C. D. de; MAZIERO, E. G.; NOBREGA, F. A. A.; SOUZA, J. W. d. C.; CABEZUDO, M. A. S.; DELEGE, M.; JORGE, M. L. D. R. C.; SILVA, N. L.; CARDOSO, P. C. F.; FILHO, P. P. B.; CONDORI, R. E. L.; FELIPPO, A. D.; NUNES, M. d. G. V.; PARDO, T. A. S. Enriquecendo o c\u00f3rpus cstnews - a cria\u00e7\u00e3o de novos sum\u00e1rios multidocumento. In: Proceedings of the I\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS 78\nWorkshop on Tools and Resources for Automatically Processing Portuguese and Spanish - ToRPorEsp. S\u00e3o Carlos-SP, Brazil: [s.n.], 2014. p. 1\u20138.\nDICE, L. R. Measures of the amount of ecologic association between species. Ecology, v. 26, n. 3, p. 297\u2013302, 1945.\nDYER, M. G. Connectionist natural language processing: A status report. In: SUN, R.; BOOKMAN, L. (Ed.). Computational Architectures Integrating Neural And Symbolic Processes. [S.l.]: Springer US, 1995, (The Springer International Series In Engineering and Computer Science, v. 292). p. 389\u2013429. ISBN 978-0-7923-9517-1.\nEDMUNDSON, H. P. New methods in automatic extracting. Journal of the ACM (JACM), p. 264\u2013285, 1969.\nERKAN, G.; RADEV, D. R. Lexrank: Graph-based lexical centrality as salience in text summarization. J. Artif. Int. Res., AI Access Foundation, USA, v. 22, n. 1, p. 457\u2013479, dez. 2004. ISSN 1076-9757. Dispon\u00edvel em: <http://dl.acm.org/citation.cfm?id=1622487.1622501>.\nFERN\u00c1NDEZ, S.; SANJUAN, E.; TORRES-MORENO, J.-M. Textual energy of associative memories: Performant applications of enertex algorithm in text summarization and topic segmentation. In: GELBUKH, A.; MORALES, A. K. (Ed.). MICAI 2007: Advances in Artificial Intelligence. [S.l.]: Springer Berlin Heidelberg, 2007, (Lecture Notes in Computer Science, v. 4827). p. 861\u2013871. ISBN 978-3-540-76630-8.\nFERN\u00c1NDEZ, S.; SANJUAN, E.; TORRES-MORENO, J. M. Enertex: un syst\u00e8me bas\u00e9 sur l\u2019\u00e9nergie textuelle. Traitement Automatique des Langues Naturelles, p. 99\u2013108, 2008.\nFERREIRA, R.; CABRAL, L. de S.; FREITAS, F. L. G. de; LINS, R. D.; SILVA, G. de Franca Pereira e; SIMSKE, S. J.; FAVARO, L. A multi-document summarization system based on statistics and linguistic treatment. Expert Syst. Appl., v. 41, n. 13, p. 5780\u20135787, 2014. Dispon\u00edvel em: <http://dx.doi.org/10.1016/j.eswa.2014.03.023>.\nFILIPPOVA, K. Multi-sentence compression: Finding shortest paths in word graphs. In: Proceedings of the 23rd International Conference on Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. (COLING\u201910), p. 322\u2013330. Dispon\u00edvel em: <http://dl.acm.org/citation.cfm?id=1873781.1873818>.\nGALANIS, D.; LAMPOURAS, G.; ANDROUTSOPOULOS, I. Extractive multi-document summarization with integer linear programming and support vector regression. In: COLING 2012. [S.l.: s.n.], 2012.\nGAREY, M. R.; JOHNSON, D. S. Computers and Intractability; A Guide to the Theory of NP-Completeness. New York, NY, USA: W. H. Freeman & Co., 1990.\nGILLICK, D.; FAVRE, B. A scalable global model for summarization. In: NAACL/HLT 2009 Workshop on Integer Linear Programming for Natural Language Processing. [S.l.: s.n.], 2009.\nGONG, Y.; LIU, X. Generic text summarization using relevance measure and latent semantic analysis. In: Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. New York, NY,\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS 79\nUSA: ACM, 2001. (SIGIR \u201901), p. 19\u201325. ISBN 1-58113-331-6. Dispon\u00edvel em: <http://doi.acm.org/10.1145/383952.383955>.\nHAGHIGHI, A.; VANDERWENDE, L. Exploring content models for multi-document summarization. In: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2009. (NAACL \u201909), p. 362\u2013370. ISBN 978-1-932432-41-1. Dispon\u00edvel em: <http://dl.acm.org/citation.cfm?id=1620754.1620807>.\nHE, T.; LI, F.; SHAO, W.; CHEN, J.; MA, L. A new feature-fusion sentence selecting strategy for query-focused multi-document summarization. In: Advanced Language Processing and Web Information Technology, 2008. ALPIT \u201908. International Conference on. [S.l.: s.n.], 2008. p. 81\u201386.\nHENNIG, L.; ALBAYRAK, S. Personalized multi-document summarization using n-gram topic model fusion. In: Proceedings of LREC\u201910, 1st Workshop on Semantic Personalized Information Management (SPIM 2010). Valletta, Malta: European Language Resources Association (ELRA), 2010. p. 28\u201334. ISBN 2-9517408-6-7. Dispon\u00edvel em: <http://www.lrec-conf.org/proceedings/lrec2010/workshops/W7.pdf>.\nHIEMSTRA, D. Probability smoothing. In: Encyclopedia of Database Systems, pp. 2169-2170, Springer. [S.l.: s.n.], 2009.\nHOVY, E.; LIN, C.-Y. Automated text summarization and the summarist system. In: Proceedings of a Workshop on Held at Baltimore, Maryland: October 13-15, 1998. Stroudsburg, PA, USA: Association for Computational Linguistics, 1998. (TIPSTER \u201998), p. 197\u2013214. Dispon\u00edvel em: <http://dx.doi.org/10.3115/1119089.1119121>.\nINOUYE, D.; KALITA, J. Comparing twitter summarization algorithms for multiple post summaries. In: Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (SocialCom), 2011 IEEE Third International Conference on. [S.l.: s.n.], 2011. p. 298\u2013306.\nJORGE, C.; PARDO, M. L. del R.; SALGUEIRO, T. A. Experiments with cst-based multidocument summarization. In: Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. p. 74\u201382.\nKRAUSE, A.; MCMAHAN, B.; GUESTRIN, C.; GUPTA, A. Robust submodular observation selection. Journal of Machine Learning Research (JMLR), v. 9, p. 2761\u20132801, December 2008.\nLANDAUER, T.; MCNAMARA, D.; DENNIS, S.; KINTSCH, W. Handbook of Latent Semantix Analysis. [S.l.]: NJ & London, 2007.\nLAY, D. C. Linear Algebra and Its Applications. [S.l.]: Pearson, 2011.\nLEE, D. D.; SEUNG, H. S. Learning the parts of objects by non-negative matrix factorization. Nature, Nature Publishing Group, v. 401, n. 6755, p. 788\u2013791, out. 1999. ISSN 0028-0836. Dispon\u00edvel em: <http://dx.doi.org/10.1038/44565>.\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS 80\nLIN, C.-Y. Training a selection function for extraction. In: Proceedings of the Eighth International Conference on Information and Knowledge Management. New York, NY, USA: ACM, 1999. (CIKM \u201999), p. 55\u201362. ISBN 1-58113-146-1. Dispon\u00edvel em: <http://doi.acm.org/10.1145/319950.319957>.\nLIN, C. Y. Rouge: A package for automatic evaluation of summaries. In: Proc. ACL workshop on Text Summarization Branches Out. [s.n.], 2004. p. 10. Dispon\u00edvel em: <http://research.microsoft.com/ cyl/download/papers/WAS2004.pdf>.\nLIN, H.; BILMES, J. A class of submodular functions for document summarization. In: IN THE 49TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (ACL-HLT. [S.l.: s.n.], 2011.\nLIN, H.; BILMES, J.; XIE, S. Graph-based Submodular Selection for Extractive Summarization. 2009.\nLUHN, H. P. The automatic creation of literature abstracts. IBM Journal of Research and Development, p. 159, 1958.\nMCDONALD, R. Discriminative sentence compression with soft syntactic constraints. In: In Proc. EACL. [S.l.: s.n.], 2006.\nMCKEOWN, K.; HIRSCHBERG, J.; GALLEY, M.; MASKEY, S. From text to speech summarization. In: ICASSP. 2005. Philadelphia, PA. [S.l.: s.n.], 2005.\nMIHALCEA, R. Graph-based ranking algorithms for sentence extraction, applied to text summarization. ACL 2004 on Interactive poster and demonstration sessions, p. 181\u2013184, 2004.\nMIHALCEA, R.; TARAU, P. TextRank: Bringing Order into Texts. In: Conference on Empirical Methods in Natural Language Processing. Barcelona, Spain: [s.n.], 2004. Dispon\u00edvel em: <http://acl.ldc.upenn.edu/acl2004/emnlp/pdf/Mihalcea.pdf>.\nMURRAY, G.; RENALS, S.; CARLETTA, J. Extractive summarization of meeting recordings. In: in Proceedings of the 9th European Conference on Speech Communication and Technology. [S.l.: s.n.], 2005. p. 593\u2013596.\nPAPINENI, K.; ROUKOS, S.; WARD, T.; ZHU, W.-J. Bleu: A method for automatic evaluation of machine translation. In: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2002. (ACL \u201902), p. 311\u2013318. Dispon\u00edvel em: <http://dx.doi.org/10.3115/1073083.1073135>.\nPARDO, T. A. S.; RINO, L. H. M.; NUNES, M. das G. V. Gistsumm: A summarization tool based on a new extractive method. In: MAMEDE, N. J.; BAPTISTA, J.; TRANCOSO, I.; NUNES, M. das G. V. (Ed.). PROPOR. [S.l.]: Springer, 2003. (Lecture Notes in Computer Science, v. 2721), p. 210\u2013218.\nPOLLOCK, J. J.; ZAMORA, A. Automatic abstracting research at chemical abstracts service. J. of Chemical Information and C. Sciences, p. 226\u2013232, 1975.\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS 81\nPONTES, E. L.; LINHARES, A. C.; TORRES-MORENO, J.-M. Sasi: sumarizador autom\u00e1tico de documentos baseado no problema do subconjunto independente de v\u00e9rtices. In: Proceedings of the XLVI Simp\u00f3sio Brasileiro de Pesquisa Operacional. [S.l.: s.n.], 2014.\nROSSI, F.; SMRIGLIO, S. A branch-and-cut algorithm for the maximum cardinality stable set problem. Operations Research Letters, v. 28, n. 2, p. 63 \u2013 74, 2001. ISSN 0167-6377. Dispon\u00edvel em: <http://www.sciencedirect.com/science/article/pii/S0167637700000602>.\nSAGGION, H.; TORRES-MORENO, J.-M.; CUNHA, I. da; SANJUAN, E. Multilingual summarization evaluation without human models. In: Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Stroudsburg, PA, USA: Association for Computational Linguistics, 2010. (COLING \u201910), p. 1059\u20131067. Dispon\u00edvel em: <http://dl.acm.org/citation.cfm?id=1944566.1944688>.\nSARANYAMOL CS; SINDHU L. A survey on automatic text summarization. International Journal of Computer Science and Information Technologies, v. 5, p. 7889\u20137893, 2014.\nSENO, E. R. M. Um m\u00e9todo para a fus\u00e3o autom\u00e1tica de senten\u00e7as similares em portugu\u00eas. Tese (Doutorado) \u2014 Instituto de Ci\u00eancias Matem\u00e1ticas e de Computa\u00e7\u00e3o, Universidade de S\u00e3o Paulo, S\u00e3o Carlos, 2010.\nSENO, E. R. M.; NUNES, M. das G. V. Some experiments on clustering similar sentences of texts in portuguese. In: Computational Processing of the Portuguese Language, 8th International Conference, PROPOR 2008, Aveiro, Portugal, September 8-10, 2008, Proceedings. [S.l.: s.n.], 2008. p. 133\u2013142.\nSIPOS, R.; SHIVASWAMY, P.; JOACHIMS, T. Large-margin learning of submodular summarization models. In: Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Stroudsburg, PA, USA: Association for Computational Linguistics, 2012. (EACL \u201912), p. 224\u2013233. ISBN 978-1-937284-19-0. Dispon\u00edvel em: <http://dl.acm.org/citation.cfm?id=2380816.2380846>.\nSOGAARD, A. Semi-supervised learning and domain adaptation in natural language processing. San Rafael: Morgan & Claypool, 2013. ISBN 1-608-45985-3. Dispon\u00edvel em: <http://opac.inria.fr/record=b1134947>.\nTORRES-MORENO, J. Artex is another text summarizer. CoRR, abs/1210.3312, 2012. Dispon\u00edvel em: <http://arxiv.org/abs/1210.3312>.\nTORRES-MORENO, J.-M.; RAM\u00edREZ, J. Reg : un algorithme glouton appliqu\u00e9 au r\u00e9sum\u00e9 automatique de texte. In: JADT. JADT. [S.l.], 2010.\nTORRES-MORENO, J.-M.; SAGGION, H.; CUNHA, I. da; VEL\u00c1ZQUEZ-MORALES, P.; SANJUAN, E. Evaluation automatique de r\u00e9sum\u00e9s avec et sans r\u00e9f\u00e9rence. Traitement Automatique des Langues Naturelles, 2010.\nTORRES-MORENO, J.-M.; SAGGION, H.; CUNHA, I. da; SANJUAN, E.; VEL\u00c1ZQUEZ-MORALES, P. Summary evaluation with and without references. Polibits, n. 42, p. 13\u201319, 2010.\nREFER\u00caNCIAS BIBLIOGR\u00c1FICAS 82\nTORRES-MORENO, J.-M.; VEL\u00e1ZQUEZ-MORALES, P.; MEUNIER, J.-G. Condens\u00e9s de textes par des m\u00e9thodes num\u00e9riques. In: JADT. JADT. [S.l.], 2002. v. 2, p. 723\u2013734.\nVODOLAZOVA, T.; LLORET, E.; MU\u00f1OZ, R.; PALOMAR, M. A comparative study of the impact of statistical and semantic features in the framework of extractive text summarization. In: TSD. [S.l.]: Springer, 2012. (Lecture Notes in Computer Science, v. 7499), p. 306\u2013313.\nWOLSEY, L. A. Integer Programming. [S.l.]: Wiley-Interscience, 1998.\nWU, Z. B.; HSU, L. S.; TAN, C. L. A survey on statistical approaches to natural language processing. 1992.\nXU, Y.-D.; ZHANG, X.-D.; QUAN, G.-R.; WANG, Y.-D. Mrs for multi-document summarization by sentence extraction. Telecommunication Systems, Springer US, v. 53, n. 1, p. 91\u201398, 2013."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "The internet increased the amount of information available. However, the reading and understanding of this information are costly tasks. In this scenario, the Natural Language Processing (NLP) applications enable very important solutions, highlighting the Automatic Text Summarization (ATS), which produce a summary from one or more source texts. Automatically summarizing one or more texts, however, is a complex task because of the difficulties inherent to the analysis and generation of this summary. This master\u2019s thesis describes the main techniques and methodologies (NLP and heuristics) to generate summaries. We have also addressed and proposed some heuristics based on graphs and similarity matrix to measure the relevance of judgments and to generate summaries by extracting sentences. We used the multiple languages (English, French and Spanish), CSTNews (Brazilian Portuguese), RPM (French) and DECODA (French) corpus to evaluate the developped systems. The results obtained were quite interesting.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}