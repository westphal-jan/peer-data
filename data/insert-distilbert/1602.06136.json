{"id": "1602.06136", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2016", "title": "Ordonnancement d'entit\\'es pour la rencontre du web des documents et du web des donn\\'ees", "abstract": "the advances benefits of the linked open data ( lod ) initiative are giving ripple rise credibility to a more structured web of data. indeed, a few datasets act as hubs ( e. g., dbpedia ) connecting many other datasets. they also made possible new web imaging services for entity detection inside plain text ( e. g., dbpedia spotlight ), thus allowing for new applications that will benefit from performing a combination of avoiding the web of documents and the web of data. to quickly ease the emergence of these new use - cases, we propose a query - biased algorithm for the ranking of entities detected inside a web page. our algorithm combine link spatial analysis with dimensionality loss reduction. we use crowdsourcing for actually building a publicly available and reusable dataset on which we compare our algorithm to the state of the art. finally, we use this algorithm for the construction of semantic snippets for which we evaluate the usability and the usefulness with a crowdsourcing - based approach.", "histories": [["v1", "Fri, 19 Feb 2016 13:05:42 GMT  (658kb,D)", "http://arxiv.org/abs/1602.06136v1", "in French, Revue des Sciences et Technologies de l'Information - S{\\'e}rie Document Num\\'erique, Lavoisier, 2015, Nouvelles approches en recherche d'information, 18 (2-3/2015 ), pp.123-154"]], "COMMENTS": "in French, Revue des Sciences et Technologies de l'Information - S{\\'e}rie Document Num\\'erique, Lavoisier, 2015, Nouvelles approches en recherche d'information, 18 (2-3/2015 ), pp.123-154", "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["mazen alsarem", "pierre-edouard portier", "sylvie calabretto", "harald kosch"], "accepted": false, "id": "1602.06136"}, "pdf": {"name": "1602.06136.pdf", "metadata": {"source": "CRF", "title": "Ordonnancement d\u2019entite\u0301s pour la rencontre du web des documents et du web des donne\u0301es", "authors": ["Mazen Alsarem", "Pierre-Edouard Portier", "Sylvie Calabretto", "Harald Kosch"], "emails": ["prenom.nom@insa-lyon.fr", "Prenom.Nom@uni-passau.de"], "sections": [{"heading": null, "text": "MOTS-CL\u00c9S : web des donn\u00e9es, ordonnancement d\u2019entit\u00e9s, snippets s\u00e9mantiques.\nKEYWORDS: web of data, entity ranking, semantic snippets.\nDOI:10.3166/DN.18.2-3.123-154 c\u00a9 2015 Lavoisier\nDocument num\u00e9rique \u2013 no 2-3/2015, 123-154\nar X\niv :1\n60 2.\n124 DN. Volume 18 \u2013 no 2-3/2015"}, {"heading": "1. Introduction", "text": "Dans ce travail, nous pr\u00e9sentons l\u2019algorithme LDRANK qui permet d\u2019ordonner les entit\u00e9s d\u2019un graphe issu du LOD (Linked Open Data) en fonction d\u2019un besoin d\u2019information exprim\u00e9 sous la forme d\u2019une requ\u00eate form\u00e9e d\u2019un ensemble de mots cl\u00e9s. L\u2019algorithme LDRANK s\u2019applique \u00e0 des graphes pour lesquels des donn\u00e9es textuelles descriptives peuvent \u00eatre associ\u00e9es aux n\u0153uds (c.\u00e0.d. aux entit\u00e9s). Nous appliquons cet algorithme \u00e0 des graphes issus de la d\u00e9tection automatique au sein d\u2019une page web d\u2019entit\u00e9s du LOD. Cette d\u00e9tection d\u2019entit\u00e9s peut \u00eatre r\u00e9alis\u00e9e gr\u00e2ce \u00e0 des services tels que DBpedia Spotlight (Mendes et al., 2011) (configurable par le biais de listes blanches et noires qui permettent de filtrer sur les types d\u2019entit\u00e9s tels que d\u00e9finis par la hi\u00e9rarchie des classes de l\u2019ontologie DBpedia, incluant une phase de d\u00e9sambigu\u00efsation contextuelle, et associant un score de confiance \u00e0 chaque r\u00e9sultat), AlchemyAPI 1 (similaire \u00e0 DBpedia Spotlight, mais faisant r\u00e9f\u00e9rence \u00e0 diff\u00e9rentes sources de donn\u00e9es du LOD et comportant donc une \u00e9tape de r\u00e9solution des cor\u00e9f\u00e9rences), OpenCalais 1, SemanticAPI de Ontos 1, etc. Les donn\u00e9es textuelles associ\u00e9es aux n\u0153uds du graphe proviennent alors du r\u00e9sum\u00e9 DBpedia de l\u2019entit\u00e9, ainsi que de passages de la page web centr\u00e9s sur les occurrences de l\u2019entit\u00e9. Afin de motiver la n\u00e9cessit\u00e9 de LDRANK, il est n\u00e9cessaire de rappeler bri\u00e8vement le rapport entre les approches classiques pour l\u2019ordonnancement de pages web et les approches existantes pour l\u2019ordonnancement d\u2019entit\u00e9s du web des donn\u00e9es.\nDans le contexte du web des documents, un hyperlien indique une relation entre des informations port\u00e9es par deux pages web. Bien que de telles relations soient g\u00e9n\u00e9ralement d\u2019une granularit\u00e9 assez grossi\u00e8re, elles forment cependant une composante essentielle des algorithmes d\u2019ordonnancement les plus reconnus (PageRank (Page et al., 1999), HITS (Kleinberg, 1999), SALSA (Lempel, Moran, 2001)).\nDans le contexte du web des donn\u00e9es, les liens (mat\u00e9rialis\u00e9s par des triplets sujet/pr\u00e9dicat/objet) repr\u00e9sentent des relations nomm\u00e9es dont les entit\u00e9s sources et cibles sont g\u00e9n\u00e9ralement d\u2019une granularit\u00e9 plus fine que pour le web des documents. La grande majorit\u00e9 des strat\u00e9gies existantes pour l\u2019ordonnancement d\u2019entit\u00e9s du web des donn\u00e9es (voir (Roa-Valverde, Sicilia, s. d.) et (Jindal et al., 2014) pour des \u00e9tats de l\u2019art r\u00e9cents) sont fond\u00e9es sur des adaptations du PageRank. Il existe \u00e9galement des approches du type apprendre-\u00e0-ordonner (learning-to-rank) appliqu\u00e9es au web des donn\u00e9es (par exemple (Dali et al., 2012)). Ces techniques d\u00e9pendent de la disponibilit\u00e9 des jugements de pertinence pour l\u2019apprentissage (bien que des mesures indirectes de quantit\u00e9s corr\u00e9l\u00e9es puissent parfois \u00eatre utilis\u00e9es, par exemple le nombre de fois qu\u2019un agent a acc\u00e9d\u00e9 \u00e0 la repr\u00e9sentation d\u2019une entit\u00e9).\nAvec l\u2019algorithme LDRANK, nous adoptons une strat\u00e9gie fond\u00e9e sur la combinaison consensuelle de plusieurs sources de connaissances afin de modifier un algorithme de type PageRank. Chaque source de connaissance permet de construire une distribution de probabilit\u00e9 sur les entit\u00e9s. Une telle distribution repr\u00e9sente l\u2019impor-\n1. www.alchemyapi.com ; www.opencalais.com ; www.ontos.com\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 125\ntance a priori de chaque entit\u00e9. Dans ce contexte, il faut entendre par connaissance a priori, toute forme de connaissance contextuelle qui ne d\u00e9pend pas de la connaissance de la structure du graphe mat\u00e9rialis\u00e9 par l\u2019ensemble de triplets RDF qui relient explicitement les entit\u00e9s entre elles. La prise en compte de cette structure de graphe se fait \u00e0 travers la convergence du processus de marche al\u00e9atoire du PageRank. Mais ce dernier processus est biais\u00e9 par la combinaison convexe de la matrice stochastique correspondant \u00e0 la structure explicite du graphe RDF, avec une matrice de rang 1 correspondant \u00e0 une combinaison consensuelle des distributions obtenues \u00e0 partir des diff\u00e9rentes sources de connaissance contextuelle \u00e0 disposition. L\u2019une de ces sources de connaissance a priori est obtenue \u00e0 partir d\u2019une analyse s\u00e9mantique latente it\u00e9r\u00e9e des donn\u00e9es textuelles associ\u00e9es aux entit\u00e9s. Cette derni\u00e8re strat\u00e9gie, ainsi que la proposition de combiner consensuellement plusieurs sources de connaissances a priori dans le contexte d\u2019un algorithme de type PageRank nous semblent former des contributions nouvelles par rapport \u00e0 l\u2019\u00e9tat de l\u2019art. Dans cet article, nous montrons que cette approche produit des ordonnancements d\u2019une qualit\u00e9 significativement meilleure \u00e0 celle des ordonnancements produits par les strat\u00e9gies de l\u2019\u00e9tat de l\u2019art bas\u00e9es sur des modifications du PageRank.\nFinalement, nous montrons \u00e9galement le potentiel de LDRANK en l\u2019appliquant \u00e0 un contexte de construction de snippets s\u00e9mantiques. Un snippet est un extrait d\u2019une page web calcul\u00e9 au moment de l\u2019analyse de la requ\u00eate et devant aider l\u2019utilisateur \u00e0 d\u00e9cider de la pertinence de la page web par rapport \u00e0 son besoin d\u2019information. Un snippet s\u00e9mantique vise \u00e0 am\u00e9liorer ce processus de d\u00e9cision et d\u2019exploration en rendant explicites les relations entre un besoin d\u2019information et les entit\u00e9s les plus pertinentes pr\u00e9sentes dans une page web. Pour ce faire, nous utilisons d\u2019abord l\u2019algorithme LDRANK pour d\u00e9tecter au sein d\u2019une page web les entit\u00e9s les plus susceptibles d\u2019aider l\u2019utilisateur \u00e0 r\u00e9pondre \u00e0 son besoin d\u2019information. Puis, nous adoptons une approche par apprentissage automatique pour associer \u00e0 chaque entit\u00e9 \u00e9lue par LDRANK les passages de la page web qui permettent le mieux de mettre en \u00e9vidence la relation entre l\u2019entit\u00e9 et le besoin d\u2019information.\nDans la section 2, nous introduisons dans un premier temps les travaux relatifs \u00e0 l\u2019am\u00e9lioration des snippets pour le web des documents et pour le web des donn\u00e9es, puis nous mentionnons \u00e9galement les diff\u00e9rentes strat\u00e9gies existantes pour l\u2019ordonnancement d\u2019entit\u00e9s d\u2019un graphe RDF. Dans la section 3, nous d\u00e9crivons la construction par crowdsourcing d\u2019un jeu de donn\u00e9es pour l\u2019\u00e9valuation de l\u2019ordonnancement guid\u00e9 par une requ\u00eate d\u2019entit\u00e9s LOD. Dans la section 4, nous pr\u00e9sentons l\u2019algorithme LDRANK et son \u00e9valuation comparative avec les approches de l\u2019\u00e9tat de l\u2019art. Dans la section 5, nous introduisons ENsEN (Enhanced Search Engine), le syst\u00e8me logiciel que nous avons d\u00e9velopp\u00e9 pour g\u00e9n\u00e9rer des snippets s\u00e9mantiques. Dans la section 6, nous d\u00e9crivons une approche par apprentissage automatique au c\u0153ur de ENsEN et permettant d\u2019associer aux entit\u00e9s du LOD les plus importantes (au sens du r\u00e9sultat de l\u2019ex\u00e9cution de LDRANK) les passages de la page web les plus \u00e0 m\u00eame d\u2019illustrer la relation s\u00e9mantique entre cette entit\u00e9 et le besoin d\u2019information de l\u2019utilisateur. Dans la section 7, nous pr\u00e9sentons les r\u00e9sultats d\u2019une \u00e9valuation par crowdsourcing du syst\u00e8me ENsEN, avant de conclure en section 8.\n126 DN. Volume 18 \u2013 no 2-3/2015"}, {"heading": "2. Travaux connexes", "text": "Nous mentionnons tout d\u2019abord des travaux qui g\u00e9n\u00e8rent des snippets \u00e0 partir de documents RDF natifs. Ge et al. et Penin et al. s\u2019int\u00e9ressent \u00e0 la g\u00e9n\u00e9ration de snippets pour la recherche d\u2019ontologies. Bai et al. g\u00e9n\u00e8rent des snippets pour un moteur de recherche s\u00e9mantique.\nDans (Penin et al., 2008), les auteurs commencent par identifier un sujet th\u00e9matique gr\u00e2ce \u00e0 un algorithme de clustering hi\u00e9rarchique hors-ligne. Ensuite, ils calculent une liste de triplets RDF (c.\u00e0.d. des ensembles de triplets RDF connect\u00e9s) s\u00e9mantiquement proches du th\u00e8me. Enfin, gr\u00e2ce \u00e0 une mesure de similarit\u00e9 fond\u00e9e sur Wordnet, ils classent les triplets RDF s\u00e9lectionn\u00e9s en consid\u00e9rant les propri\u00e9t\u00e9s structurelles du graphe RDF et les caract\u00e9ristiques lexicales des termes pr\u00e9sents dans l\u2019ontologie.\nDans (Ge et al., 2012), les auteurs commencent par transformer le graphe RDF en un graphe qui met en relation des paires de termes et pour lequel chaque ar\u00eate est associ\u00e9e \u00e0 un ensemble de triplets RDF. Leur objectif est de construire une repr\u00e9sentation compacte des relations qui existent entre les termes de la requ\u00eate. Ces relations sont \u00e0 trouver dans le graphe RDF. Pour ce faire, les auteurs d\u00e9composent le graphe d\u2019association des termes en composantes dont le rayon ne doit pas d\u00e9passer une valeur fix\u00e9e (c\u2019est un param\u00e8tre de l\u2019algorithme) afin d\u2019\u00e9viter la d\u00e9couverte de relations trop lointaines entre termes de la requ\u00eate. Il s\u2019agit ensuite de chercher au sein de ces composantes des sous-graphes connexes qui relient des termes de la requ\u00eate. Le snippet est alors une somme de ces sous-graphes connexes.\nDans (Bai et al., 2008), les auteurs commencent par attribuer un th\u00e8me au document RDF. Pour cela, ils utilisent un pr\u00e9dicat tel que p:primaryTopic s\u2019il existe, sinon ils s\u2019appuient sur une heuristique fond\u00e9e sur la comparaison des URIs des entit\u00e9s candidates pour repr\u00e9senter le th\u00e8me avec l\u2019URL du document RDF. Ensuite, ils ont propos\u00e9 un algorithme pour l\u2019ordonnancement des triplets RDF. A ce propos, il semble int\u00e9ressant de noter comment ils utilisent les propri\u00e9t\u00e9s : pour chaque propri\u00e9t\u00e9, ils d\u00e9finissent son importance par rapport aux autres propri\u00e9t\u00e9s d\u2019un sch\u00e9ma donn\u00e9, ils introduisent \u00e9galement les notions de propri\u00e9t\u00e9s corr\u00e9latives (par exemple foaf:name et foaf:family) et exclusives (par exemple foaf:name et foaf:surname). Enfin, ils utilisent cet algorithme d\u2019ordonnancement pour pr\u00e9senter \u00e0 l\u2019utilisateur un ensemble de relations entre les triplets proches de la requ\u00eate et les triplets proches du th\u00e8me du document RDF.\nPour r\u00e9sumer, comme Ge et al. nous pensons que poss\u00e9der des donn\u00e9es structur\u00e9es issues d\u2019un graphe RDF offre la possibilit\u00e9 de trouver des relations non triviales entre les termes de la requ\u00eate eux-m\u00eames, mais aussi entre les termes de la requ\u00eate et les concepts les plus importants du document. En outre, nous suivons \u00e9galement Penin et al. \u00e0 propos de la n\u00e9cessit\u00e9 de concevoir un algorithme d\u2019ordonnancement de triplets RDF qui tienne compte \u00e0 la fois de la structure du graphe et des propri\u00e9t\u00e9s lexicales des donn\u00e9es textuelles qui peuvent \u00eatre associ\u00e9es aux n\u0153uds ou aux ar\u00eates du graphe.\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 127\nLes travaux pr\u00e9c\u00e9dents exploitent des documents RDF natifs, mais en g\u00e9n\u00e9ral les entit\u00e9s du LOD peuvent provenir (i) soit d\u2019un jeu de donn\u00e9es du LOD (elles peuvent alors \u00eatre rassembl\u00e9es via par exemple des requ\u00eates SPARQL), (ii) soit des annotations s\u00e9mantiques int\u00e9gr\u00e9es \u00e0 une page web (par exemple, en utilisant RDFa, des microdonn\u00e9es, ou bien des microformats), ou bien (iii) de la d\u00e9tection automatique des entit\u00e9s dans le texte d\u2019une page web (au moyen par exemple de DBpedia Spotlight). Or, parmi les approches qui permettent d\u2019am\u00e9liorer les snippets pour le web des documents en utilisant le web des donn\u00e9es (Haas et al., 2011)(Steiner et al., 2010), aucune ne repose sur la d\u00e9tection automatique d\u2019entit\u00e9s : seules les annotations encapsul\u00e9es explicitement sont utilis\u00e9es. Haas et al. utilisent des m\u00e9tadonn\u00e9es structur\u00e9es (c.\u00e0.d. des donn\u00e9es encod\u00e9es gr\u00e2ce au formalisme RDFa, ou par le biais de microformats) ainsi que plusieurs techniques d\u2019extraction ad-hoc d\u2019information pour am\u00e9liorer les snippets avec des \u00e9l\u00e9ments multim\u00e9dias, des paires cl\u00e9 / valeur et des fonctionnalit\u00e9s interactives. Ainsi, en combinant les m\u00e9tadonn\u00e9es cr\u00e9\u00e9es par les \u00e9diteurs des documents avec des donn\u00e9es structur\u00e9es obtenues par des extracteurs ad-hoc con\u00e7us sp\u00e9cialement pour quelques sites populaires, les auteurs de ce travail sont capables de construire des snippets enrichis pour de nombreux r\u00e9sultats d\u2019une requ\u00eate. Ils ont choisi explicitement de ne pas utiliser directement le LOD afin d\u2019\u00e9viter le probl\u00e8me du transfert de confiance entre le web des documents et le web des donn\u00e9es. En effet, ils soutiennent que la qualit\u00e9 des processus \u00e9ditoriaux qui g\u00e9n\u00e8rent des parties du web des donn\u00e9es \u00e0 partir du web des documents (par exemple la transformation de Wikipedia en DBpedia) ne peut pas \u00eatre contr\u00f4l\u00e9e. Par cons\u00e9quent, de leur point de vue, utiliser le LOD \u00e0 travers un processus de d\u00e9tection automatique d\u2019entit\u00e9s pour enrichir des snippets s\u2019accompagnerait du risque jug\u00e9 trop important d\u2019introduire du bruit incontr\u00f4l\u00e9 dans les r\u00e9sultats. De plus, Google Rich Snippet (Steiner et al., 2010) est une initiative similaire qui s\u2019appuie exclusivement sur les m\u00e9tadonn\u00e9es structur\u00e9es r\u00e9dig\u00e9es par les \u00e9diteurs des pages web.\nEnfin, une \u00e9tude faite en 2012 (Bizer et al., 2013) sur plus de 40 millions de sites web du Corpus Common Crawl montre que seul 5,64 % des sites int\u00e8grent des donn\u00e9es structur\u00e9es. Cependant, pr\u00e8s de 50 % des 10 000 premiers sites de la liste Alexa des sites web les plus populaires poss\u00e9daient des donn\u00e9es structur\u00e9es. En outre, les auteurs de l\u2019\u00e9tude affirment que (nous traduisons) : \u201cLes sujets des donn\u00e9es [structur\u00e9es] [. . . ] semblent \u00eatre en majeure partie d\u00e9termin\u00e9s par les principaux consommateurs qui constituent la cible de ces donn\u00e9es : Google, Yahoo!, Bing\u201d. Ainsi, il nous semble qu\u2019il y a aujourd\u2019hui un besoin \u00e9vident pour un algorithme qui permette d\u2019exploiter les donn\u00e9es structur\u00e9es issues d\u2019un processus de d\u00e9tection automatique d\u2019entit\u00e9s dans une page web avec une confiance suffisante dans leur qualit\u00e9, et ce de mani\u00e8re \u00e0 permettre l\u2019\u00e9mergence d\u2019applications qui utilisent conjointement le web des donn\u00e9es et le web des documents. Dans ce travail, nous proposons une telle solution \u00e0 travers un algorithme d\u2019ordonnancement des entit\u00e9s d\u2019un graphe du web des donn\u00e9es. De plus, nous montrons l\u2019utilit\u00e9 de cet algorithme en l\u2019appliquant au contexte de la construction de snippets s\u00e9mantiques.\nLa majorit\u00e9 des approches existantes pour ordonner les entit\u00e9s d\u2019un graphe RDF provenant du web des donn\u00e9es sont fond\u00e9es sur une modification de l\u2019algorithme Pa-\n128 DN. Volume 18 \u2013 no 2-3/2015\ngeRank. Ainsi, OntologyRank (Ding et al., 2004) (utilis\u00e9 par Swoogle) modifie la matrice de t\u00e9l\u00e9portation pour prendre en compte les types de relations qui existent entre diff\u00e9rentes ontologies. D\u2019une mani\u00e8re similaire, PopRank (Nie et al., 2005) propose une version modifi\u00e9e du PageRank qui tient compte des diff\u00e9rents types de pr\u00e9dicats entre entit\u00e9s. Enfin, RareRank (Wei et al., 2011) modifie la matrice de t\u00e9l\u00e9portation pour mod\u00e9liser l\u2019influence de la proximit\u00e9 th\u00e9matique entre entit\u00e9s, proximit\u00e9 \u00e9valu\u00e9e gr\u00e2ce \u00e0 l\u2019introduction d\u2019une mesure de similarit\u00e9 s\u00e9mantique dont le calcul d\u00e9pend d\u2019ontologies disponibles pour le domaine consid\u00e9r\u00e9."}, {"heading": "3. Construction par crowdsourcing d\u2019un jeu de donn\u00e9es pour l\u2019\u00e9valuation de l\u2019ordonnancement guid\u00e9 par une requ\u00eate d\u2019entit\u00e9s d\u2019un sous-graphe du LOD", "text": "LDRANK appartient \u00e0 la classe des algorithmes d\u2019ordonnancement d\u2019entit\u00e9s d\u2019un graphe creux et h\u00e9t\u00e9rog\u00e8ne provenant du web des donn\u00e9es et accompagn\u00e9 de la repr\u00e9sentation d\u2019un besoin d\u2019information sous la forme d\u2019une requ\u00eate qui est une liste de mots cl\u00e9s. A notre connaissance, il n\u2019existe pas de jeu de donn\u00e9es adapt\u00e9 \u00e0 ce contexte (ce qui peut \u00eatre v\u00e9rifi\u00e9 par la lecture d\u2019un \u00e9tat de l\u2019art r\u00e9cent (Roa-Valverde, Sicilia, s. d.)). Ainsi, nous avons adopt\u00e9 une approche par crowdsourcing pour construire notre jeu de donn\u00e9es qui servira \u00e0 \u00e9valuer notre proposition et \u00e0 la comparer \u00e0 l\u2019\u00e9tat de l\u2019art (ce jeu de donn\u00e9es est accessible librement 2). Dans cette section, nous d\u00e9crivons comment nous avons construit ce jeu de donn\u00e9es."}, {"heading": "3.1. Collecte", "text": "Nous avons s\u00e9lectionn\u00e9 au hasard 30 requ\u00eates de la collection de requ\u00eates intitul\u00e9e \u201cYahoo! Search Query Tiny Sample\u201d propos\u00e9e dans le cadre du projet Yahoo! Webscope 3. Nous avons soumis chaque requ\u00eate au moteur de recherche Google et nous avons conserv\u00e9 les 5 premi\u00e8res pages web retourn\u00e9es. Pour chacun de ces 150 documents HTML, nous avons extrait le contenu textuel principal en appliquant l\u2019algorithme d\u00e9velopp\u00e9 par Kohlschtter, Frankhauser, et Nejdl (Kohlsch\u00fctter et al., 2010). En moyenne, le texte conserv\u00e9 pour chaque page web est fait de 467 mots. Nous avons ex\u00e9cut\u00e9 DBpedia Spotlight (Mendes et al., 2011) sur ces textes afin de d\u00e9tecter des entit\u00e9s. En moyenne, 81 entit\u00e9s ont \u00e9t\u00e9 d\u00e9tect\u00e9es pour chaque page web.\nPour chaque document, \u00e0 partir de ses entit\u00e9s associ\u00e9es, nous construisons un graphe RDF en \u00e9mettant des requ\u00eates SPARQL sur le jeu de donn\u00e9es de DBpedia afin de d\u00e9couvrir tous les triplets RDF qui lient ces entit\u00e9s. A chaque entit\u00e9 du graphe, nous associons un texte obtenu par concat\u00e9nation de son r\u00e9sum\u00e9 au sens de DBpedia (c\u2019est-\u00e0-dire, le n\u0153ud litt\u00e9ral destination du pr\u00e9dicat \u201cabstract\u201d), et d\u2019une fen\u00eatre de texte (300 caract\u00e8res) centr\u00e9e sur le (ou les) passages de la page web o\u00f9 l\u2019entit\u00e9 a \u00e9t\u00e9\n2. http://liris.cnrs.fr/drim/projects/ensen/ 3. http://webscope.sandbox.yahoo.com/catalog.php?datatype=1\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 129\nd\u00e9tect\u00e9e par DBpedia Spotlight. Nous avons supprim\u00e9 les mots vides et appliqu\u00e9 une \u00e9tape de racinisation \u00e0 ce texte."}, {"heading": "3.2. G\u00e9n\u00e9ration de micro-t\u00e2ches", "text": "\u00c9tant donn\u00e9e la longueur de chacun des 150 documents, la t\u00e2che qui consisterait \u00e0 \u00e9valuer la pertinence de toutes les entit\u00e9s associ\u00e9es \u00e0 une page web serait trop lourde pour pouvoir \u00eatre pr\u00e9sent\u00e9e comme un travail atomique dans le cadre d\u2019une approche par crowdsourcing. Ainsi, il nous faut diviser cette t\u00e2che en un ensemble de microt\u00e2ches. Dans notre cas, une micro-t\u00e2che consiste \u00e0 \u00e9valuer la pertinence des entit\u00e9s annot\u00e9es dans une seule phrase. Nous d\u00e9coupons le texte d\u2019une page web en phrases en appliquant l\u2019algorithme ICU BreakIterator 4. Il y a en moyenne 22 phrases par document. De plus, si une phrase contient plus de 10 entit\u00e9s annot\u00e9es, le travail est r\u00e9parti sur plusieurs micro-t\u00e2ches.\nNous avons utilis\u00e9 la plateforme de crowdsourcing CrowdFlower 5. Cette plateforme r\u00e9partit le travail aupr\u00e8s de plus de 5 millions de contributeurs r\u00e9partis dans 154 pays, tout en tenant \u00e0 jour des m\u00e9triques de qualit\u00e9 pour chaque contributeur. La conception d\u2019une micro-t\u00e2che se fait en CML, un idiome XML fourni par CrowdFlower. Pour chaque micro-t\u00e2che, nous proposons au contributeur des instructions sur comment r\u00e9aliser le travail (nous avons essay\u00e9 de nombreuses approches jusqu\u2019\u00e0 trouver une formulation qui soit comprise par tous les contributeurs). Nous fournissons au contributeur un th\u00e8me form\u00e9 d\u2019un titre (qui est en fait la requ\u00eate qui a permis d\u2019obtenir le document dont la phrase sur laquelle il travaille est extraite) et d\u2019un court texte (la phrase pour laquelle il doit juger de la pertinence des entit\u00e9s annot\u00e9es, accompagn\u00e9e de la phrase pr\u00e9c\u00e9dente et de la phrase suivante dans la page web qui permettent de mieux fixer le contexte). Pour chaque entit\u00e9 annot\u00e9e dans la phrase, le contributeur doit \u00e9valuer la correction et la pertinence de l\u2019annotation. Pour ce faire, nous avons utilis\u00e9 l\u2019\u00e9chelle ordinale introduite par J\u00e4rvelin et Kek\u00e4l\u00e4inen lorsqu\u2019ils propos\u00e8rent la m\u00e9trique DCG (Discounted Cumulative Gain) (J\u00e4rvelin, Kek\u00e4l\u00e4inen, 2000) : \u201cirrelevant\u201d (0), \u201cmarginally relevant\u201d (1), \u201cfairly relevant\u201d (2), et \u201chighly relevant\u201d (3). Par ailleurs, chaque question est associ\u00e9e \u00e0 un court texte qui d\u00e9crit l\u2019entit\u00e9 consid\u00e9r\u00e9e (viz. le d\u00e9but de son r\u00e9sum\u00e9 au sens du pr\u00e9dicat \u201cabstract\u201d de DBpedia). Nous avons propos\u00e9 chaque micro-t\u00e2che \u00e0 10 contributeurs. Ainsi, pour chaque micro-t\u00e2che nous avons 10 jugements. Chaque micro-t\u00e2che \u00e9tait r\u00e9mun\u00e9r\u00e9e $.01."}, {"heading": "3.3. Contr\u00f4le qualit\u00e9", "text": "Nous n\u2019avons accept\u00e9 que des contributeurs qui avaient d\u00e9j\u00e0 compl\u00e9t\u00e9 plus de 100 micro-t\u00e2ches, et dont la pr\u00e9cision des r\u00e9ponses, telle que mesur\u00e9e par la plateforme CrowdFlower, \u00e9tait \u00e9lev\u00e9e. Pour \u00e9valuer la pr\u00e9cision d\u2019un contributeur, CrowdFlower\n4. http://icu-project.org/apiref/icu4c/classicu_1_1BreakIterator.html 5. http://www.crowdflower.com/\n130 DN. Volume 18 \u2013 no 2-3/2015\nutilise la notion de question-test. Contrairement \u00e0 une question simple, une questiontest est accompagn\u00e9e de la r\u00e9ponse consid\u00e9r\u00e9e comme vraie par le concepteur de la question. Ainsi, lors de la conception d\u2019une t\u00e2che, l\u2019introduction d\u2019une question-test est consid\u00e9r\u00e9e comme une bonne pratique.\nNous avons donn\u00e9 au maximum 30 minutes \u00e0 un contributeur pour r\u00e9pondre \u00e0 une question. Par ailleurs, nous avons impos\u00e9 qu\u2019un contributeur passe au minimum 10 secondes sur une t\u00e2che avant de fournir une r\u00e9ponse.\nNous avons mesur\u00e9 l\u2019accord entre contributeurs gr\u00e2ce au coefficient alpha de Krippendorff (Krippendorff, 2012). Ce coefficient utilise par d\u00e9faut une distance binaire pour comparer deux r\u00e9ponses, mais il est con\u00e7u pour pouvoir utiliser \u00e9galement d\u2019autres distances. Pour tenir compte du fait que nous avons utilis\u00e9 une \u00e9chelle ordinale qui mod\u00e9lise \u00e0 la fois la correction et la pertinence, nous avons utilis\u00e9 la distance sym\u00e9trique d\u00e9crite par le tableau 1.\nTableau 1. Distance sym\u00e9trique pour le calcul de l\u2019alpha de Krippendorff\nd 0 1 2 3 0 0, 00 0, 50 0, 75 1, 00 1 0, 50 0, 00 0, 25 0, 50 2 0, 75 0, 25 0, 00 0, 25 3 1, 00 0, 50 0, 25 0, 00\nAvec ces param\u00e8tres, nous avons obtenu un alpha de 0, 22. Selon l\u2019\u00e9chelle interpr\u00e9tative de Landis et Koch (Landis, Koch, 1977) ce score peut \u00eatre consid\u00e9r\u00e9 comme un accord acceptable (l\u2019\u00e9chelle a \u00e9t\u00e9 con\u00e7ue pour le kappa de Fleiss, mais l\u2019alpha de Krippendorff est en tout point compatible avec le kappa). Cependant, par comparaison avec des travaux existants qui ont appliqu\u00e9 du crowdsourcing dans un contexte de recherche d\u2019information, nous pourrions esp\u00e9rer un alpha plus \u00e9lev\u00e9. Par exemple, Jeong et al. (Jeong et al., 2013) ont obtenu un kappa de Fleiss de 0, 41 (c\u2019est-\u00e0-dire, un accord mod\u00e9r\u00e9) pour un moteur de recherche qui fait appel \u00e0 la sagesse des foules pour r\u00e9pondre \u00e0 certaine requ\u00eates. Cependant, Alonso, Marshall et Najork (Alonso et al., 2014) ont obtenu un alpha de Krippendorff qui varie entre 0, 03 et 0, 19 dans le cadre d\u2019une t\u00e2che plus subjective : d\u00e9cider de l\u2019int\u00e9r\u00eat d\u2019un tweet. Ainsi, afin d\u2019am\u00e9liorer la qualit\u00e9 de notre jeu de donn\u00e9es, nous avons choisi d\u2019isoler les contributeurs qui \u00e9taient souvent en d\u00e9saccord avec la majorit\u00e9. En retirant les contributeurs qui sont en d\u00e9saccord avec la majorit\u00e9 dans plus de 41, 2% de leurs jugements, nous obtenons un alpha de 0, 46. Apr\u00e8s cette op\u00e9ration, 96, 5% des t\u00e2ches poss\u00e8dent au moins 3 jugements, 66% des t\u00e2ches poss\u00e8dent au moins 5 jugements, et seulement 0, 7% des t\u00e2ches ne poss\u00e8dent que 1 jugement."}, {"heading": "3.4. Agr\u00e9gation des r\u00e9sultats", "text": "Nous avons utilis\u00e9 le vote \u00e0 la majorit\u00e9 pour l\u2019agr\u00e9gation des r\u00e9sultats au sein d\u2019une phrase. Nous avons test\u00e9 deux approches diff\u00e9rentes pour s\u00e9parer les ex aequo :\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 131\n(i) le maximum de la moyenne de la pr\u00e9cision des contributeurs (la pr\u00e9cision d\u2019un contributeur est une m\u00e9trique propos\u00e9e par la plateforme CrowdFlower et que nous avons mentionn\u00e9e plus haut), (ii) la valeur la plus \u00e9lev\u00e9e. Nous avons pu constater a posteriori que ces deux choix donnaient des r\u00e9sultats tr\u00e8s similaires lorsque le jeu de donn\u00e9es est utilis\u00e9 pour comparer des algorithmes d\u2019ordonnancement d\u2019entit\u00e9s \u00e9tant donn\u00e9 un besoin d\u2019information exprim\u00e9 par une liste de mots cl\u00e9s. Nous avons utilis\u00e9 la m\u00eame strat\u00e9gie de vote \u00e0 la majorit\u00e9 pour agr\u00e9ger les r\u00e9sultats au niveau d\u2019une page web.\nDans la prochaine section, nous introduisons LDRANK, un algorithme pour l\u2019ordonnancement guid\u00e9 par une requ\u00eate d\u2019entit\u00e9s du LOD. Le jeu de donn\u00e9es dont nous venons de d\u00e9crire la construction sera utilis\u00e9 \u00e0 la section 4.6 pour \u00e9valuer LDRANK et le comparer \u00e0 l\u2019\u00e9tat de l\u2019art."}, {"heading": "4. LDRANK, un algorithme pour l\u2019ordonnancement guid\u00e9 par une requ\u00eate d\u2019entit\u00e9s du LOD", "text": ""}, {"heading": "4.1. Contexte", "text": "\u00c9tant donn\u00e9 la connaissance d\u2019un besoin d\u2019information exprim\u00e9 sous la forme d\u2019une requ\u00eate faite d\u2019un ensemble de mots cl\u00e9s, l\u2019algorithme LDRANK fournit un ordonnancement des entit\u00e9s d\u2019un graphe RDF pour lequel des donn\u00e9es textuelles sont associ\u00e9es aux n\u0153uds. Pour calculer cet ordonnancement, LDRANK utilise \u00e0 la fois la structure explicite du graphe et les relations implicites d\u00e9couvertes par analyse du texte associ\u00e9 aux entit\u00e9s. Gr\u00e2ce \u00e0 cette strat\u00e9gie double, il est particuli\u00e8rement adapt\u00e9 aux graphes creux et bruit\u00e9s (c\u2019est-\u00e0-dire, avec une proportion importante de n\u0153uds non pertinents selon le besoin d\u2019information exprim\u00e9 par la requ\u00eate). De tels graphes apparaissent en particulier suite \u00e0 l\u2019annotation automatique d\u2019une page web (par exemple, via DBpedia, AlchemyAPI,...). C\u2019est pourquoi nous avons construit le jeu de donn\u00e9es introduit \u00e0 la section pr\u00e9c\u00e9dente de cet article (voir en particulier la sous-section 3.1).\nLDRANK prend en compte la structure explicite du graphe \u00e0 travers un algorithme de type PageRank. De plus, il utilise les relations implicites qui peuvent \u00eatre inf\u00e9r\u00e9es \u00e0 partir du texte associ\u00e9 aux entit\u00e9s gr\u00e2ce \u00e0 une variante originale de l\u2019algorithme de d\u00e9composition en valeurs singuli\u00e8res (SVD). Enfin, LDRANK prend \u00e9galement en compte l\u2019ordonnancement des pages web au sein desquelles les entit\u00e9s ont \u00e9t\u00e9 d\u00e9tect\u00e9es gr\u00e2ce \u00e0 une fonction de score d\u2019abord introduite par Fafalios et Tzitzikas.\nPlus pr\u00e9cis\u00e9ment, l\u2019analyse textuelle fond\u00e9e, sur une application it\u00e9r\u00e9e de la d\u00e9composition en valeurs singuli\u00e8res, ainsi que l\u2019exploitation de l\u2019ordonnancement fourni par la page de r\u00e9sultats d\u2019un moteur de recherche du web, permettent chacune de construire un vecteur de probabilit\u00e9s exprimant une connaissance a priori (ou opinion) sur l\u2019importance relative des entit\u00e9s (voir les sections 4.2 et 4.3). Ensuite, ces vecteurs de probabilit\u00e9s sont rassembl\u00e9s gr\u00e2ce \u00e0 une strat\u00e9gie d\u2019agr\u00e9gation consensuelle lin\u00e9aire d\u2019opinions d\u2019abord introduite par Carvalho et Larson (voir section 4.4). Enfin, nous utilisons ces diff\u00e9rentes sources de connaissance a priori, agr\u00e9g\u00e9es en\n132 DN. Volume 18 \u2013 no 2-3/2015\nune unique distribution de probabilit\u00e9s sur les entit\u00e9s, pour influencer le processus de convergence d\u2019un algorithme de type PageRank vers une distribution de probabilit\u00e9 stable (au sens d\u2019un vecteur propre de valeur propre unit\u00e9 pour un processus de Markov) qui correspond \u00e0 l\u2019ordonnancement final des entit\u00e9s (voir section 4.5)."}, {"heading": "4.2. Connaissance a priori d\u00e9duite de l\u2019ordonnancement fourni par la page de r\u00e9sultats d\u2019un moteur de recherche du web", "text": "Algorithme H (Hit Score). Cet algorithme calcule un vecteur de probabilit\u00e9s (hitdistrib) qui repr\u00e9sente une connaissance a priori sur l\u2019importance des entit\u00e9s. Cette connaissance est d\u00e9duite de l\u2019ordonnancement des pages web au sein desquelles ces entit\u00e9s ont \u00e9t\u00e9 d\u00e9tect\u00e9es. L\u2019ordonnancement en question est celui retourn\u00e9 par un moteur de recherche du web \u00e0 partir du besoin d\u2019information de l\u2019utilisateur exprim\u00e9 sous la forme d\u2019un ensemble de mots cl\u00e9s. Cette strat\u00e9gie a \u00e9t\u00e9 introduite pour la premi\u00e8re fois par Fafalios et Tzitzikas.\nH1. A \u2190 la liste des meilleures pages web telles qu\u2019ordonn\u00e9es par un moteur de recherche du web en r\u00e9ponse \u00e0 une requ\u00eate form\u00e9e d\u2019un ensemble de mots cl\u00e9s.\nH2. E \u2190 l\u2019ensemble des entit\u00e9s d\u00e9tect\u00e9es dans ces pages web (par exemple, gr\u00e2ce \u00e0 l\u2019application de DBpedia Spotlight).\nH3. docs(e) \u2261 les documents de A au sein desquels l\u2019entit\u00e9 e a \u00e9t\u00e9 d\u00e9tect\u00e9e.\nH4. rank(a) \u2261 le rang du document a dans A.\nH5. hitscore(e) \u2261 \u2211\na\u2208docs(e)(size(A) + 1)\u2212 rank(a)\nH6. hitdistrib[e]\u2190 hitscore(e)/ \u2211\ne\u2032\u2208E hitscore(e \u2032)\nH7. [End.]"}, {"heading": "4.3. Connaissance a priori d\u00e9duite d\u2019une analyse s\u00e9mantique latente it\u00e9r\u00e9e des donn\u00e9es textuelles associ\u00e9es aux entit\u00e9s", "text": "Algorithme S (SVD it\u00e9ratif ). Cet algorithme calcule un vecteur de probabilit\u00e9s (svddistrib) qui repr\u00e9sente une connaissance a priori sur l\u2019importance des entit\u00e9s. Cette connaissance est fond\u00e9e sur une analyse du texte associ\u00e9 \u00e0 chaque entit\u00e9.\nS1. [Matrice initiale.] R \u2190 la matrice creuse entit\u00e9-terme (c\u2019est-\u00e0-dire, avec les entit\u00e9s en ligne, et les termes en colonnes) au format CCS (Compressed Column Storage) 6.\n6. http://netlib.org/linalg/html_templates/node92.html\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 133\nS2. [Initialisation des entit\u00e9s importantes.] info_need\u2190 un ensemble d\u2019entit\u00e9s qui est form\u00e9 de l\u2019union des entit\u00e9s d\u00e9tect\u00e9es dans le texte de la requ\u00eate et de l\u2019entit\u00e9 qui poss\u00e8de le meilleur hitscore (la pr\u00e9sence de cette derni\u00e8re entit\u00e9 est n\u00e9cessaire pour les cas o\u00f9 aucune entit\u00e9 ne serait d\u00e9tect\u00e9e \u00e0 partir des mots cl\u00e9s de la requ\u00eate). Nous supposons que ces entit\u00e9s sont probablement proches du besoin d\u2019information de l\u2019utilisateur.\nS3. [Premier SVD.] (U, S, V T ) \u2190 svdLAS2A(R,nb_dim) Calcule la d\u00e9composition en valeurs singuli\u00e8res (SVD) de R au rang k = nb_dim. Puisque R est tr\u00e8s creuse, nous utilisons l\u2019algorithme las2 d\u00e9velopp\u00e9 par Michael W. Berry (Berry, 1992) afin de calculer la d\u00e9composition : Rk = UkSkV Tk avec Uk et Vk des matrices orthogonales, Sk une matrice diagonale, telles que \u2016R\u2212Rk\u2016F soit minimis\u00e9e (c\u2019est-\u00e0-dire que du point de vue de la norme de Frobenius, Rk est la meilleure approximation au rang k de R).\nS4. [Coordonn\u00e9es des entit\u00e9s dans l\u2019espace r\u00e9duit.] SUT \u2190 SUT Dans le nouvel espace \u00e0 k dimensions, cette op\u00e9ration met \u00e0 l\u2019\u00e9chelle les coordonn\u00e9es des entit\u00e9s (c\u2019est-\u00e0-dire, les lignes de U ) gr\u00e2ce aux facteurs de contraction/dilatation correspondants de S. Ainsi, nous obtenons les coordonn\u00e9es des entit\u00e9s dans le nouvel espace r\u00e9duit (c\u2019est-\u00e0-dire, les colonnes de SUT ).\nS5. prev_norms\u2190 les normes euclidiennes des entit\u00e9s dans l\u2019espace r\u00e9duit.\nS6. [Matrice mise \u00e0 jour.] R\u2032 \u2190 R o\u00f9 les lignes correspondant aux entit\u00e9s de l\u2019ensemble info_need ont \u00e9t\u00e9 multipli\u00e9es par le param\u00e8tre stress (puisque R est au format CCS, il est plus pratique de faire cette op\u00e9ration sur la transpos\u00e9e de R).\nS7. [Second SVD.] (U \u2032, S\u2032, V \u2032T )\u2190 svdLAS2A(R\u2032, nb_dim)\nS8. [Mise \u00e0 jour des coordonn\u00e9es des entit\u00e9s dans l\u2019espace r\u00e9duit.] SUT \u2032 \u2190 S\u2032U \u2032T\nS9. norms\u2190 mise \u00e0 jour des normes euclidiennes des entit\u00e9s dans l\u2019espace r\u00e9duit.\nS10. [\u00c9loignement des entit\u00e9s par rapport \u00e0 l\u2019origine de l\u2019espace r\u00e9duit..] svdscore(e) \u2261 norms[e]\u2212 prev_norms[e].\nS11. svddistrib[e]\u2190 svdscore(e)/ \u2211\ne\u2032 svdscore(e \u2032)\nS12. [End.]\nNous pouvons maintenant introduire la propri\u00e9t\u00e9 de la d\u00e9composition en valeurs singuli\u00e8res sur laquelle repose l\u2019algorithme S. Pour une forte r\u00e9duction dimensionnelle (c.\u00e0.d. pour une faible valeur de k), la transformation SkUT tend \u00e0 placer les entit\u00e9s qui \u00e9taient orthogonales \u00e0 de nombreuses entit\u00e9s dans l\u2019espace des lignes de R proches de l\u2019origine de l\u2019espace k-dimensionnel r\u00e9sultant. En effet, comme vu plus haut, le SVD peut \u00eatre vu comme un algorithme d\u2019optimisation, or pour minimiser l\u2019erreur due \u00e0 l\u2019impossibilit\u00e9 pour une entit\u00e9 d\u2019\u00eatre orthogonale \u00e0 plus de k entit\u00e9s non colin\u00e9aires, cette entit\u00e9 doit \u00eatre plac\u00e9e aussi proche que possible de l\u2019origine de\n134 DN. Volume 18 \u2013 no 2-3/2015\nl\u2019espace r\u00e9duit. Un argument similaire peut \u00eatre utilis\u00e9 pour montrer qu\u2019une entit\u00e9 colin\u00e9aire \u00e0 de nombreuses entit\u00e9s dans l\u2019espace des lignes de R aura aussi tendance \u00e0 se trouver proche de l\u2019origine de l\u2019espace r\u00e9duit k-dimensionnel. Ainsi, et pour r\u00e9sum\u00e9, les entit\u00e9s \u00e9loign\u00e9es de l\u2019origine dans l\u2019espace r\u00e9duit ont tendance \u00e0 poss\u00e9der des relations \u201cint\u00e9ressantes\u201d avec d\u2019autres entit\u00e9s \u00e9loign\u00e9es de l\u2019origine. Par ailleurs, les entit\u00e9s qui sont dans la direction de plus grande variation des donn\u00e9es dans l\u2019espace initial sont les mieux align\u00e9es avec l\u2019axe correspondant \u00e0 la plus grande valeur singuli\u00e8re dans l\u2019espace r\u00e9duit (c.\u00e0.d. l\u2019axe qui a subi l\u2019extension la plus forte), elles ont donc tendance \u00e0 \u00eatre les plus \u00e9loign\u00e9es de l\u2019origine de l\u2019espace r\u00e9duit. Ainsi, le principe \u00e0 l\u2019\u0153uvre dans l\u2019algorithme S consiste \u00e0 augmenter artificiellement l\u2019importance des entit\u00e9s s\u00e9mantiquement proches de la requ\u00eate afin de les forcer dans la direction de plus grande variation des donn\u00e9es, et \u00e0 observer parmi les autres entit\u00e9s celles qui, suite \u00e0 cette op\u00e9ration, s\u2019\u00e9loignent le plus de l\u2019origine de l\u2019espace r\u00e9duit. Gr\u00e2ce \u00e0 l\u2019argument \u00e9nonc\u00e9 ci-dessus, ces derni\u00e8res entit\u00e9s peuvent ainsi \u00eatre qualifi\u00e9es de potentiellement proches du besoin d\u2019information.\nNous avons obtenu les meilleurs r\u00e9sultats exp\u00e9rimentaux avec une r\u00e9duction sur un espace uni-dimensionnel (c\u2019est-\u00e0-dire avec nb_dim = 1 aux \u00e9tapes S3 et S7 de l\u2019algorithme S), et avec un facteur de stress de 1000.0 (voir l\u2019\u00e9tape S6 de l\u2019algorithme S)."}, {"heading": "4.4. Strat\u00e9gie pour l\u2019agr\u00e9gation de plusieurs sources de connaissance a priori", "text": "Nous consid\u00e9rons hitdistrib (voir algorithme H), svddistrib (voir algorithme S), et la distribution \u00e9quiprobable (equidistrib) comme trois opinions expertes (ou trois sources de connaissance a priori) sur l\u2019importance des entit\u00e9s. Afin d\u2019agr\u00e9ger ces opinions, nous appliquons l\u2019algorithme de Carvalho et Larson (Carvalho, Larson, 2013) qui permet de d\u00e9terminer it\u00e9rativement une combinaison lin\u00e9aire optimale de plusieurs vecteurs de probabilit\u00e9s. A chaque pas de cet algorithme it\u00e9ratif, l\u2019expert i re-calcule la distribution repr\u00e9sentant son opinion sous la forme d\u2019une combinaison lin\u00e9aire des distributions de tous les experts. Dans cette combinaison lin\u00e9aire, le poids affect\u00e9 par l\u2019expert i \u00e0 la distribution de l\u2019expert j est proportionnel \u00e0 la distance s\u00e9parant ces deux distributions. Les auteurs de ce travail ont d\u00e9fini une distance telle que ce processus it\u00e9ratif converge toujours vers une unique distribution dite consensuelle. Nous appellerons le vecteur de probabilit\u00e9s consensuel r\u00e9sultant : finaldistrib."}, {"heading": "4.5. LDRANK", "text": "L\u2019algorithme PageRank (Page et al., 1999) transforme la matrice d\u2019adjacence (M ) d\u2019un r\u00e9seau de pages web en une matrice H qui est stochastique (c\u2019est-\u00e0-dire que la somme de chaque ligne de H vaut 1) et primitive (c\u2019est-\u00e0-dire qu\u2019il existe un entier k tel que Hk > 0), assurant ainsi l\u2019existence d\u2019un vecteur stationnaire (c\u2019est-\u00e0-dire, le vecteur propre positif correspondant \u00e0 la valeur propre 1). Ce vecteur stationnaire est un vecteur de probabilit\u00e9s qui peut \u00eatre interpr\u00e9t\u00e9 comme repr\u00e9sentant l\u2019importance de chaque page web en mod\u00e9lisant rigoureusement la proposition intuitive selon laquelle une page web importante est r\u00e9f\u00e9renc\u00e9e par des pages web importantes. De plus, cette\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 135\ndistribution stationnaire peut \u00eatre calcul\u00e9e de mani\u00e8re efficace gr\u00e2ce \u00e0 la m\u00e9thode dite de la puissance it\u00e9r\u00e9e tenant compte du fait que la matrice stochastique est creuse.\nDans la version originale de l\u2019algorithme PageRank, aucune hypoth\u00e8se n\u2019est faite sur la probabilit\u00e9 a priori de l\u2019importance d\u2019une page web avant que ne soit entam\u00e9e l\u2019analyse de la structure explicite du graphe. En d\u2019autres termes, M est d\u2019abord transform\u00e9e en une matrice stochastique S en rempla\u00e7ant chaque ligne vide par la distribution \u00e9quiprobable (equidistrib) ; puis S est transform\u00e9e en une matrice primitive H par combinaison convexe avec une matrice de rang 1 dite de t\u00e9l\u00e9portation (T ) : H = \u03b1S + (1 \u2212 \u03b1)T o\u00f9 chaque ligne de T est la distribution \u00e9quiprobable (equidistrib).\nPour l\u2019algorithme LDRANK, au lieu d\u2019utiliser la distribution \u00e9quiprobable, nous utilisons la distribution consensuelle (finaldistrib) introduite plus haut (voir section 4.4). Nous avons obtenu les meilleurs r\u00e9sultats exp\u00e9rimentaux pour 0.6 \u2264 \u03b1 \u2264 0.8. De plus, nous avons fix\u00e9 \u00e0 1E \u2212 10 la valeur de la pr\u00e9cision de convergence qui contr\u00f4le la terminaison de la m\u00e9thode de la puissance it\u00e9r\u00e9e utilis\u00e9e pour calculer le vecteur stationnaire.\nEnfin, LDRANK est disponible librement en ligne 7."}, {"heading": "4.6. \u00c9valuation de LDRANK", "text": "Nous comparons quatre strat\u00e9gies d\u2019ordonnancement. Chacune utilise une source de connaissance a priori diff\u00e9rente pour informer l\u2019algorithme PageRank : la version classique pour laquelle la connaissance a priori sur l\u2019importance des entit\u00e9s est nulle et correspond donc \u00e0 la distribution \u00e9quiprobable (nous appelons cette strat\u00e9gie EQUI) ; la version modifi\u00e9e avec l\u2019utilisation du hitscore comme source de connaissance a priori (cette version est due \u00e0 Fafalios et Tzitzikas voir section 4.2, nous nommons cette strat\u00e9gie HIT) ; la version modifi\u00e9e avec notre nouvelle source de connaissance a priori bas\u00e9e sur une utilisation it\u00e9r\u00e9e de la d\u00e9composition en valeurs singuli\u00e8res (voir section 4.3, nous nommons cette strat\u00e9gie SVD) ; et LDRANK qui utilise la combinaison consensuelle de trois sources diff\u00e9rentes de connaissance a priori.\nAfin de comparer les quatre strat\u00e9gies (EQUI, HIT, SVD et LDRANK), nous utilisons la m\u00e9trique NDCG (Normalized Discounted Cumulative Gain). Le DCG (Discounted Cumulative Gain) au rang r est d\u00e9fini ainsi : DCGr = rel1 + \u2211r i=1 reli log2i (avec reli repr\u00e9sentant la pertinence estim\u00e9e du r\u00e9sultat au rang i, la pertinence est repr\u00e9sent\u00e9e sur une \u00e9chelle discr\u00e8te qui contient g\u00e9n\u00e9ralement bien moins de valeurs que le nombre total de r\u00e9sultats \u00e0 ordonner, nous utilisons une \u00e9chelle \u00e0 quatre gradations, voir section 3). Le NDCG au rang r est \u00e9gal au DCG au rang r normalis\u00e9 par le DCG au rang r d\u2019un ordonnancement optimal.\n7. http://liris.cnrs.fr/drim/projects/ensen/\n136 DN. Volume 18 \u2013 no 2-3/2015\nLes r\u00e9sultats sont pr\u00e9sent\u00e9s sur la figure 1. Nous observons que les strat\u00e9gies SVD et HIT ont des performances comparables. Cependant, elles sont clairement surpass\u00e9es par leur combinaison consensuelle LDRANK. De plus, comme notre impl\u00e9mentation tient syst\u00e9matiquement compte du caract\u00e8re creux des matrices, nous obtenons \u00e9galement de bonnes performances en termes de temps d\u2019ex\u00e9cution (voir figure 2). La strat\u00e9gie SVD prend plus de temps que la strat\u00e9gie HIT puisqu\u2019elle n\u00e9cessite le calcul de la d\u00e9composition en valeurs singuli\u00e8res. Le temps suppl\u00e9mentaire pris par la strat\u00e9gie LDRANK s\u2019explique par le temps de convergence du processus it\u00e9ratif qui calcule la combinaison consensuelle des diff\u00e9rentes distributions. Enfin, nous avons men\u00e9 des exp\u00e9rimentations similaires en consid\u00e9rant toutes les ar\u00eates du graphe bidirectionnelles (en effet, le sens de l\u2019interpr\u00e9tation d\u2019un pr\u00e9dicat RDF est en pratique souvent arbitraire). Les performances relatives des algorithmes sont alors similaires, mais en valeur absolue les scores NDCG sont l\u00e9g\u00e8rement meilleurs.\nNotons qu\u2019\u00e0 travers ces exp\u00e9rimentations, en plus d\u2019introduire une nouvelle strat\u00e9gie d\u2019ordonnancement efficace bas\u00e9e sur une utilisation originale de la r\u00e9duction dimensionnelle par d\u00e9composition en valeurs singuli\u00e8res, nous montrons \u00e9galement que plusieurs strat\u00e9gies bas\u00e9es sur une modification de la matrice de t\u00e9l\u00e9portation de l\u2019algorithme PageRank peuvent \u00eatre avantageusement combin\u00e9es lorsqu\u2019elles sont envisag\u00e9es en tant que sources distinctes de connaissance a priori sur l\u2019importance des entit\u00e9s du graphe.\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 137\n138 DN. Volume 18 \u2013 no 2-3/2015"}, {"heading": "5. Pr\u00e9sentation de ENsEN pour la g\u00e9n\u00e9ration de snippets s\u00e9mantiques", "text": "Afin de convaincre de l\u2019utilit\u00e9 et de l\u2019efficacit\u00e9 de l\u2019algorithme LDRANK, nous l\u2019utilisons dans le contexte de ENsEN (Enhanced Search Engine), un syst\u00e8me que nous avons con\u00e7u pour construire des snippets s\u00e9mantiques (voir figure 3, une d\u00e9monstration live du syst\u00e8me est disponible en ligne, voir une pr\u00e9c\u00e9dente note de bas de page pour l\u2019URL). Nous pr\u00e9sentons maintenant le flux des donn\u00e9es et les traitements qui produisent un snippet s\u00e9mantique \u00e0 partir d\u2019une requ\u00eate, et ce afin de mettre en avant le r\u00f4le jou\u00e9 par l\u2019algorithme LDRANK dans ce processus.\n\u00c9tant donn\u00e9e une requ\u00eate, nous obtenons la page de r\u00e9sultats d\u2019un moteur de recherche du web (nous avons utilis\u00e9 Google pour nos exp\u00e9riences). Pour chaque page web r\u00e9sultat, nous utilisons le service de d\u00e9tection automatique d\u2019entit\u00e9s DBpedia Spotlight afin d\u2019obtenir un ensemble d\u2019entit\u00e9s. De la m\u00eame mani\u00e8re, nous trouvons les entit\u00e9s associ\u00e9es aux termes de la requ\u00eate. A partir de cet ensemble d\u2019entit\u00e9s et par l\u2019interm\u00e9diaire de requ\u00eates \u00e9mises aupr\u00e8s d\u2019un point d\u2019acc\u00e8s SPARQL de DBpedia, nous obtenons un graphe en trouvant toutes les relations qui existent entre ces entit\u00e9s dans le jeu de donn\u00e9es DBpedia.\nA chaque entit\u00e9 nous associons un texte obtenu par concat\u00e9nation de son r\u00e9sum\u00e9 DBpedia et de fen\u00eatres textuelles centr\u00e9es sur les occurrences de l\u2019entit\u00e9 dans la page web (nous utilisons des fen\u00eatres de 300 caract\u00e8res). De plus, nous supprimons les mots vides et appliquons un enracineur 8. Nous ex\u00e9cutons l\u2019algorithme LDRANK avec en entr\u00e9e ce graphe aux n\u0153uds d\u00e9cor\u00e9s de texte ainsi que les entit\u00e9s d\u00e9couvertes dans la requ\u00eate, et nous r\u00e9cup\u00e9rons un ordonnancement des entit\u00e9s. Pour chacune des meilleures entit\u00e9s, nous construisons des vignettes affich\u00e9es sur le snippet.\nA partir d\u2019un point d\u2019acc\u00e8s SPARQL de DBpedia, nous proc\u00e9dons \u00e0 une extension 1-hop des meilleures entit\u00e9s afin d\u2019augmenter le nombre de triplets parmi lesquels nous cherchons ensuite les plus importants en terme d\u2019une analyse des liens du graphe. Pour ce faire, nous construisons un tenseur d\u2019ordre 3 \u00e0 partir du graphe \u00e9tendu : chaque pr\u00e9dicat correspond \u00e0 une couche horizontale d\u2019ordre 2 qui repr\u00e9sente la matrice d\u2019adjacence pour la restriction du graphe \u00e0 ce pr\u00e9dicat. Nous calculons ensuite la d\u00e9composition PARAFAC du tenseur en une somme de facteurs (qui sont des tenseurs de rang 1 et d\u2019ordre 3), et nous l\u2019interpr\u00e9tons d\u2019une fa\u00e7on similaire \u00e0 Franz et al. (Franz et al., 2009) : pour chacune des meilleures entit\u00e9s (au sens du LDRANK), nous s\u00e9lectionnons les facteurs auxquels elle contribue le plus (en tant que sujet ou en tant qu\u2019objet), et pour chacun de ces facteurs, nous s\u00e9lectionnons les triplets qui ont les pr\u00e9dicats avec les meilleurs scores. Ainsi, nous sommes capables d\u2019associer \u00e0 chacune des meilleures entit\u00e9s un ensemble de triplets que nous faisons appara\u00eetre sur le snippet dans la description de l\u2019entit\u00e9.\n8. http://snowball.tartarus.org/\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 139\nEnfin, nous avons employ\u00e9 une approche par apprentissage automatique afin de s\u00e9lectionner de courts passages de la page web qui viennent accompagner la description de chaque entit\u00e9. Nous d\u00e9crivons plus avant cette approche dans la prochaine section."}, {"heading": "6. D\u00e9couverte par apprentissage automatique des passages d\u2019une page web \u00e0 associer \u00e0 une entit\u00e9", "text": ""}, {"heading": "6.1. Objectifs", "text": "Nous employons une approche par apprentissage automatique supervis\u00e9 afin d\u2019associer aux meilleurs entit\u00e9s, au sens de notre algorithme LDRANK, les passages de la page web les plus susceptibles de mettre en avant une relation int\u00e9ressante entre cette entit\u00e9 et le besoin d\u2019information de l\u2019utilisateur. Nous mod\u00e9lisons la d\u00e9couverte de ces associations entre une entit\u00e9 et des passages d\u2019une page web sous la forme d\u2019un probl\u00e8me de classification binaire. C\u2019est-\u00e0-dire qu\u2019\u00e9tant donn\u00e9e une entit\u00e9, pour chaque passage de la page web au sein duquel l\u2019entit\u00e9 a \u00e9t\u00e9 d\u00e9tect\u00e9e, il faut d\u00e9cider si ce passage illustre bien la relation entre cette entit\u00e9 et le besoin d\u2019information de l\u2019utilisateur.\nNous commencerons, en section 6.2, par introduire des travaux existants qui r\u00e9pondent \u00e0 des probl\u00e8mes similaires. Puis, en section 6.3, nous d\u00e9taillerons les diff\u00e9rentes variables que nous avons choisies d\u2019utiliser pour l\u2019apprentissage. En section 6.4, nous expliquerons comment nous avons construit le jeu de donn\u00e9es pour l\u2019apprentissage, et en section 6.5 nous montrerons comment nous avons r\u00e9-\u00e9quilibr\u00e9 le jeu d\u2019apprentissage pour rendre les classes comparables. En section 6.6, nous discuterons les r\u00e9sultats obtenus par diff\u00e9rents algorithmes d\u2019apprentissage lorsque toutes les variables sont conserv\u00e9es. Ensuite, en section 6.7, nous introduirons diff\u00e9rentes strat\u00e9gies pour r\u00e9duire le nombre de variables utilis\u00e9es pour la classification, et en section 6.8 nous discuterons les nouveaux r\u00e9sultats obtenus. Enfin, en section 6.9 nous synth\u00e9tiserons ces diff\u00e9rents r\u00e9sultats en soulignant l\u2019importance de LDRANK dans ce processus."}, {"heading": "6.2. Travaux connexes", "text": "Nous mentionnons maintenant quelques travaux qui adressent un probl\u00e8me comparable au n\u00f4tre : la s\u00e9lection d\u2019extraits d\u2019une page web \u00e9tant donn\u00e9e la connaissance d\u2019une requ\u00eate exprimant le besoin d\u2019information de l\u2019utilisateur. Notre contexte diff\u00e8re principalement par la pr\u00e9sence d\u2019une couche s\u00e9mantique issue de la d\u00e9tection d\u2019entit\u00e9s dans la page web et de leur ordonnancement par LDRANK. Mais les deux probl\u00e8mes restent suffisamment proches pour que nous puissions b\u00e9n\u00e9ficier d\u2019une \u00e9tude de l\u2019\u00e9tat de l\u2019art pour ce probl\u00e8me classique de la s\u00e9lection d\u2019extraits d\u2019une page web \u00e9tant donn\u00e9e une requ\u00eate. Ainsi, nous pr\u00e9sentons quelques travaux repr\u00e9sentatifs qui adoptent des strat\u00e9gies fond\u00e9es sur l\u2019apprentissage automatique.\n140 DN. Volume 18 \u2013 no 2-3/2015\nDans (Wang et al., 2007), les auteurs introduisent des variables qui prennent en compte \u00e0 la fois le contenu de la page web et \u00e9galement le contenu contextuel qui provient des textes d\u2019ancrage de liens qui pointent vers la page web. Dans ce travail, la granularit\u00e9 de l\u2019extrait est celle de la phrase. Les auteurs mod\u00e9lisent la pertinence par le d\u00e9compte du nombre de termes de la requ\u00eate pr\u00e9sent dans une phrase. Ils mod\u00e9lisent l\u2019importance par le d\u00e9compte normalis\u00e9 des termes qui sont les plus fr\u00e9quents dans la page et qui apparaissent dans la phrase consid\u00e9r\u00e9e, ainsi que par le d\u00e9compte des termes constitutifs du titre de la page , et enfin par le d\u00e9compte des termes qui apparaissent dans les textes d\u2019ancrage des liens qui pointent vers la page.\nLes auteurs exp\u00e9rimentent avec deux strat\u00e9gies d\u2019apprentissage dont ils comparent les performances. La premi\u00e8re strat\u00e9gie consiste \u00e0 mod\u00e9liser le probl\u00e8me de la s\u00e9lection de phrases comme un probl\u00e8me de classification binaire, ensuite r\u00e9solu par l\u2019entra\u00eenement d\u2019un classifieur SVM. Pour prendre en compte le d\u00e9s\u00e9quilibre entre le nombre d\u2019instances dans chacune des deux classes, les auteurs s\u00e9parent le param\u00e8tre qui r\u00e8gle la p\u00e9nalit\u00e9 pour les erreurs de classification en deux composantes avec un facteur diff\u00e9rent pour chacune des deux classes. La seconde strat\u00e9gie consiste \u00e0 adopter une approche du type \u201capprendre \u00e0 ordonner\u201d en apprenant une fonction d\u2019ordonnancement qui doit placer les phrases s\u00e9lectionn\u00e9es avant les phrases non s\u00e9lectionn\u00e9es au sein d\u2019une page donn\u00e9e du jeu d\u2019apprentissage (contrairement \u00e0 la premi\u00e8re strat\u00e9gie de type classification binaire o\u00f9 il s\u2019agissait de distinguer les phrases s\u00e9lectionn\u00e9es de celles non s\u00e9lectionn\u00e9es sur l\u2019ensemble des pages du jeu d\u2019apprentissage). Pour cette seconde strat\u00e9gie, les auteurs utilisent l\u2019algorithme Ranking SVM.\nLes auteurs de (Wang et al., 2007) exp\u00e9rimentent sur les donn\u00e9es de la Web Track de TREC-2003. Pour chaque requ\u00eate d\u2019une s\u00e9lection al\u00e9atoire de 10 requ\u00eates, ils ont retenu 10 pages pertinentes, 5 pages non pertinentes parmi les mieux class\u00e9es (du point de vue de l\u2019algorithme BM25), et 5 pages non pertinentes choisies al\u00e9atoirement. Deux \u00e9valuateurs humains ont construit manuellement des r\u00e9sum\u00e9s pour chacune des pages en s\u00e9lectionnant les meilleures phrases (le plus souvent trois d\u2019entre elles) \u00e9tant donn\u00e9e la requ\u00eate et son contexte (c\u2019est-\u00e0-dire la description d\u00e9taill\u00e9e pr\u00e9sente dans le jeu de donn\u00e9es TREC). Pour les deux strat\u00e9gies pr\u00e9sent\u00e9es ci-dessus, les auteurs utilisent pour le SVM un noyau Gaussien dont le param\u00e8tre de l\u2019\u00e9cart type est d\u00e9termin\u00e9 gr\u00e2ce \u00e0 une approche par validation crois\u00e9e avec une division en trois \u00e9chantillons. Les m\u00e9triques utilis\u00e9es pour l\u2019\u00e9valuation sont la pr\u00e9cision, le rappel, et le F1-score. Les auteurs obtiennent les meilleurs r\u00e9sultats en prenant en compte le contexte (\u00e0 travers les textes d\u2019ancrage) et en utilisant la strat\u00e9gie de type \u201capprendre \u00e0 ordonner\u201d.\nDans (Metzler, Kanungo, 2008), les auteurs m\u00e8nent un travail similaire \u00e0 celui que nous venons d\u2019introduire ((Wang et al., 2007)), aux diff\u00e9rences pr\u00e8s qu\u2019il comparent trois type d\u2019algorithmes d\u2019apprentissage adapt\u00e9s aux approches apprendre \u00e0 ordonner (Ranking SVM, Support Vector Regression, et Gradient Boosted Decision Trees), qu\u2019ils introduisent des variables ind\u00e9pendantes de la requ\u00eate (viz., la longueur de la phrase, et sa position dans la page web), et qu\u2019ils proc\u00e8dent \u00e0 des \u00e9valuation sur un\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 141\njeu de donn\u00e9es bien plus volumineux (viz., TREC Novelty Track 2002, 2003 et 2004). Les meilleurs r\u00e9sultats ont \u00e9t\u00e9 atteints par l\u2019algorithme GBDT.\nDans (Ageev et al., 2013), les auteurs suivent les r\u00e9sultats introduits ci-dessus ((Metzler, Kanungo, 2008)) et utilisent un algorithme de Gradient Boosting Regression Tree (GBRT). Cependant, ce travail se distingue par l\u2019introduction de variables suppl\u00e9mentaires de type comportementales (par exemple, le temps pass\u00e9 par le curseur de la souris sur un fragment de texte, le temps durant lequel un fragment de texte \u00e9tait visible sur l\u2019\u00e9cran, etc.). Pour construire un jeu de donn\u00e9es d\u2019apprentissage incluant ces nouvelles variables, les auteurs ont adopt\u00e9 une approche de type crowdsourcing \u00e0 travers la plateforme Amazon MTurk. Chaque participant devait effectuer des t\u00e2ches qui chacune consistait \u00e0 r\u00e9pondre \u00e0 une question. L\u2019exp\u00e9rience \u00e9tait pr\u00e9sent\u00e9e au participant comme un jeu pour lequel il s\u2019agissait de r\u00e9pondre correctement \u00e0 un maximum de questions en un temps imparti. Par ailleurs, pour permettre l\u2019enregistrement efficace des variables comportementales, les auteurs s\u00e9lectionnent d\u2019abord les phrases de la page web qui contiennent au moins un des termes de la requ\u00eate. Puis ils d\u00e9coupent ces phrases gr\u00e2ce \u00e0 une fen\u00eatre mouvante (dont la taille d\u2019au minimum 3 mots est un param\u00e8tre), et ne conservent que les fragments qui contiennent au moins un terme de la requ\u00eate.\nEnfin, dans (Lehmann et al., 2012), les auteurs proposent l\u2019algorithme DeFacto pour valider la v\u00e9racit\u00e9 d\u2019un triplet RDF du LOD par la d\u00e9couverte de fragments de pages web qui serviront de sources d\u2019information confirmant le fait exprim\u00e9 par le triplet. Au c\u0153ur de ce travail, se trouve \u00e0 nouveau une approche par apprentissage automatique supervis\u00e9. Ce travail se base sur le syst\u00e8me BOA issu de travaux ant\u00e9rieurs des m\u00eames auteurs. BOA permet d\u2019associer \u00e0 un pr\u00e9dicat RDF un pattern en langue naturelle. Les auteurs commencent par filtrer les phrases de la page web, et ne conservent que celles dans lesquelles apparaissent les labels associ\u00e9s au sujet et \u00e0 l\u2019objet du pr\u00e9dicat dont il s\u2019agit de v\u00e9rifier la v\u00e9racit\u00e9. Les variables utilis\u00e9es pour l\u2019apprentissage comprennent entre autres : la pr\u00e9sence d\u2019un pattern BOA dans la phrase, la distance s\u00e9parant les labels correspondant au sujet et \u00e0 l\u2019objet du triplet, etc. Par ailleurs, mentionnons qu\u2019une partie de ce travail consiste \u00e9galement en la proposition d\u2019un ensemble de m\u00e9triques pour quantifier la confiance \u00e0 accorder \u00e0 une page web \u00e9tant donn\u00e9 le triplet RDF qu\u2019il s\u2019agit de valider. Nous n\u2019entrons pas plus dans les d\u00e9tails de cette derni\u00e8re partie car elle n\u2019est pas li\u00e9e \u00e0 notre probl\u00e8me.\nDans la section suivante, nous d\u00e9crivons les variables utilis\u00e9es pour l\u2019apprentissage. Nos choix ont \u00e9t\u00e9 guid\u00e9s par l\u2019analyse des travaux connexes introduits ci-dessus."}, {"heading": "6.3. Choix des variables", "text": "La particularit\u00e9 de notre approche tient surtout \u00e0 l\u2019utilisation des entit\u00e9s du LOD d\u00e9tect\u00e9es dans une page web. Rappelons en pr\u00e9ambule qu\u2019\u00e0 chaque entit\u00e9 nous associons un label, un texte qui en r\u00e9sume la signification et qui est obtenu \u00e0 partir de DBpedia, une liste d\u2019entit\u00e9s voisines dans le graphe RDF construit \u00e0 partir des entit\u00e9s d\u00e9tect\u00e9es dans la page web, et enfin le score calcul\u00e9 par notre algorithme LDRANK.\n142 DN. Volume 18 \u2013 no 2-3/2015\nNous d\u00e9crivons maintenant les diff\u00e9rentes variables utilis\u00e9es pour apprendre \u00e0 s\u00e9lectionner les phrases d\u2019une page web les plus propices \u00e0 expliquer la relation qui existe entre une entit\u00e9 donn\u00e9e et le besoin d\u2019information de l\u2019utilisateur tel qu\u2019exprim\u00e9 par sa requ\u00eate. Nous proc\u00e9dons \u00e0 cette description en distinguant trois groupes de variables : celles ind\u00e9pendantes de la requ\u00eate et de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e, celles d\u00e9pendantes de la requ\u00eate mais ind\u00e9pendantes de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e, celles d\u00e9pendantes de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e, et enfin celles d\u00e9pendantes des entit\u00e9s annot\u00e9es (et non sp\u00e9cifiquement de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e)."}, {"heading": "6.3.1. Variables ind\u00e9pendantes de la requ\u00eate et de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e", "text": "\u2013 (LEN) La longueur de la phrase. \u2013 (SSS) Le nombre de parties de la phrase s\u00e9par\u00e9es par des signes de ponctuation et d\u2019une longueur inf\u00e9rieure \u00e0 quatre mots. \u2013 (SS,SE) La nature du premier caract\u00e8re (alphab\u00e9tique, num\u00e9rique, autre) et du dernier caract\u00e8re (point, points de suspension, etc.) de la phrase. \u2013 (HL) La pr\u00e9sence d\u2019hyperliens dans la phrase. \u2013 (D) La pr\u00e9sence d\u2019une date dans la phrase. \u2013 (SL) La position de la phrase dans la page web, normalis\u00e9e par le nombre total de phrases. \u2013 (LS) Est-ce la derni\u00e8re phrase ? (variable binaire) \u2013 (NCH) Le ratio des caract\u00e8res non-alphab\u00e9tiques sur les caract\u00e8res alphab\u00e9tiques au sein de la phrase."}, {"heading": "6.3.2. Variables d\u00e9pendantes de la requ\u00eate et ind\u00e9pendantes de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e", "text": "\u2013 (QT) Le nombre de termes partag\u00e9s par la requ\u00eate et la phrase. \u2013 (QR) Le nombre d\u2019entit\u00e9s annot\u00e9es partag\u00e9es par la requ\u00eate et la phrase. \u2013 (KTKR) Le nombre d\u2019entit\u00e9s class\u00e9es parmi les top-k par LDRANK et pr\u00e9sentes\ndans la phrase."}, {"heading": "6.3.3. Variables d\u00e9pendantes de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e", "text": "\u2013 (SEL) Le nombre de termes partag\u00e9s par le label de l\u2019entit\u00e9 et la phrase. \u2013 (SEA) Le nombre de termes partag\u00e9s par le r\u00e9sum\u00e9 de l\u2019entit\u00e9 et la phrase. \u2013 (SEN) Le nombre d\u2019entit\u00e9s voisines de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e et pr\u00e9sentes dans la phrase. \u2013 (SENL) Le nombre de termes partag\u00e9s par les labels des entit\u00e9s voisines de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e et la phrase. \u2013 (SEP) La position relative de l\u2019entit\u00e9 dans la phrase (normalis\u00e9e par la taille de la phrase). \u2013 (SES) Le score LDRANK de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e (normalis\u00e9 par le score LDRANK max obtenu par une entit\u00e9 de la m\u00eame page).\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 143"}, {"heading": "6.3.4. Variables d\u00e9pendantes des entit\u00e9s annot\u00e9es dans la phrase", "text": "\u2013 (AE) Le nombre d\u2019entit\u00e9s annot\u00e9es dans la phrase. \u2013 (TKE) Le nombre d\u2019entit\u00e9s class\u00e9es parmi les k premi\u00e8res par LDRANK. \u2013 (AET) Le nombre de termes partag\u00e9s par la phrase et les labels des entit\u00e9s annot\u00e9es dans la phrase. \u2013 (TEL) Le nombre de termes partag\u00e9s par la phrase et les labels des k meilleures entit\u00e9s au sens de LDRANK. \u2013 (AES) Le score LDRANK moyen des entit\u00e9s pr\u00e9sentes dans la phrase (normalis\u00e9 par le score LDRANK max obtenu par une entit\u00e9 de la m\u00eame page). \u2013 (AEL) Pour le graphe RDF construit \u00e0 partir de la page, le nombre d\u2019ar\u00eates reliant des entit\u00e9s annot\u00e9es dans la phrase."}, {"heading": "6.4. Construction du jeu de donn\u00e9es", "text": "Pour le jeu d\u2019apprentissage, nous avons utilis\u00e9 celui dont la construction par crowdsourcing a \u00e9t\u00e9 d\u00e9crite en section 3. Il nous suffit d\u2019interpr\u00e9ter ce dernier selon un nouveau point de vue : \u201cla pertinence d\u2019une entit\u00e9 dans le contexte d\u2019une phrase et d\u2019un besoin d\u2019information exprim\u00e9 par une requ\u00eate\u201d devient \u201cla propension pour une phrase de mettre en avant la relation entre une entit\u00e9 et le besoin d\u2019information\u201d. Par ailleurs, nous proc\u00e9dons \u00e0 une agr\u00e9gation des jugements pour obtenir un jeu de donn\u00e9es \u00e0 deux classes : le score 0 (i.e., irrelevant) signifie que la phrase n\u2019est pas s\u00e9lectionn\u00e9e, les autres scores (1 pour \u201cmarginally relevant\u201d, 2 pour \u201cfairly relevant\u201d, et 3 pour \u201chighly relevant\u201d) signifient tous que la phrase est s\u00e9lectionn\u00e9e. Remarquons que nous avons exp\u00e9riment\u00e9 avec d\u2019autres mani\u00e8res d\u2019agr\u00e9ger les jugements pour obtenir deux classes, mais c\u2019est avec celle d\u00e9crite ci-dessus que nous avons obtenu les meilleurs r\u00e9sultats exp\u00e9rimentaux."}, {"heading": "6.5. \u00c9quilibrage du jeu de donn\u00e9es d\u2019apprentissage", "text": "Le jeu d\u2019apprentissage comprend 15 841 instances d\u2019entit\u00e9s d\u00e9tect\u00e9es dans les pages web. 9 936 d\u2019entre elles appartiennent \u00e0 des phrases bien adapt\u00e9es pour illustrer la relation les liant au besoin d\u2019information, tandis que 5 905 d\u2019entre elles apparaissent dans des phrases qui ne sont pas pertinentes. Ainsi, la classe positive repr\u00e9sente 62, 7% du nombre totale d\u2019instances du jeu d\u2019apprentissage. Nous rem\u00e9dions \u00e0 ce l\u00e9ger d\u00e9s\u00e9quilibre en appliquant l\u2019algorithme SMOTE (Synthetic Minority OverSampling Technique) (Chawla et al., 2002) qui permet de faire cro\u00eetre la classe minoritaire gr\u00e2ce \u00e0 des donn\u00e9es synth\u00e9tiques, et \u00e9galement de r\u00e9duire la taille de la classe majoritaire."}, {"heading": "6.6. Premiers r\u00e9sultats", "text": "Nous avons exp\u00e9riment\u00e9 avec cinq algorithmes d\u2019apprentissage : r\u00e9gression logistique, naive Bayes (avec une distribution Gaussienne comme distribution condi-\n144 DN. Volume 18 \u2013 no 2-3/2015\ntionnelle pour les attributs num\u00e9riques), l\u2019impl\u00e9mentation J48 de l\u2019algorithme d\u2019arbre de d\u00e9cision C4.5, Radial Basis Function Network, et SVM (impl\u00e9mentation libSVM, avec un noyau de type Radial Basis Function pour la version nu-SVC de l\u2019algorithme, et avec 0.5 pour valeur du param\u00e8tre nu qui fixe une borne inf\u00e9rieure sur la fraction des erreurs de classification dues \u00e0 une marge trop large). Nous avons adopt\u00e9 une approche par validation crois\u00e9e sur 10 \u00e9chantillons. Par ailleurs, nous avons utilis\u00e9 la plateforme Weka (Hall et al., 2009). Nous avons utilis\u00e9 pour m\u00e9trique d\u2019\u00e9valuation le F1-score pour la classe positive (F-True), pour l\u2019ensemble des deux classes (F-All), et l\u2019aire sous la courbe ROC. Le tableau 2 pr\u00e9sente les r\u00e9sultats de cette exp\u00e9rimentation.\nTableau 2. R\u00e9sultats pour l\u2019apprentissage de la s\u00e9lection de phrases explicatives de la relation entre une entit\u00e9 et le besoin d\u2019information\nF-True F-All ROC Logistic Regression 0,802 0,588 0,658\nNaive Bayes 0, 759 0, 633 0, 644 J48 0, 772 0, 659 0, 652\nLIBSVM 0, 802 0, 537 0, 588 RBF 0, 802 0, 584 0, 631"}, {"heading": "6.7. Strat\u00e9gies pour la s\u00e9lection de variables", "text": "Apr\u00e8s l\u2019obtention de ces premiers r\u00e9sultats, nous aimerions r\u00e9duire le nombre de variables n\u00e9cessaires sans d\u00e9t\u00e9riorer la qualit\u00e9 de la pr\u00e9diction. Nous sommes int\u00e9ress\u00e9s par cette r\u00e9duction du nombre de variables \u00e0 plusieurs titres. D\u2019abord, avec moins de variables l\u2019ex\u00e9cution de l\u2019algorithme de pr\u00e9diction consommera moins de m\u00e9moire et pourra \u00eatre plus rapide. Ensuite, du temps d\u2019ex\u00e9cution au moment de la pr\u00e9diction pourra \u00e9galement \u00eatre gagn\u00e9 car le calcul des valeurs des variables peut parfois \u00eatre co\u00fbteux. Aussi, contraindre les algorithmes de pr\u00e9diction \u00e0 ne pouvoir utiliser qu\u2019un petit sous-ensemble des variables initiales peut r\u00e9duire les erreurs d\u2019estimation et \u00e9viter le sur-apprentissage. Enfin, nous sommes dans notre cas particuli\u00e8rement int\u00e9ress\u00e9s par v\u00e9rifier indirectement l\u2019efficacit\u00e9 de l\u2019algorithme LDRANK en d\u00e9terminant l\u2019importance des variables qui font appel \u00e0 son ordonnancement des entit\u00e9s.\nNous avons d\u2019abord utilis\u00e9 une approche de s\u00e9lection de variables par filtre. Il s\u2019agit de filtrer les variables en amont du processus d\u2019apprentissage supervis\u00e9. Ainsi, nous avons employ\u00e9 la m\u00e9trique du gain d\u2019information pour ordonner a priori les variables. Nous avons essay\u00e9 deux strat\u00e9gies : (i) conserver seulement les 10 meilleures variables, (ii) couper au niveau d\u2019un saut net (nosedive) dans l\u2019ordonnancement des variables par leur score de gain d\u2019information (ce qui nous a amen\u00e9 \u00e0 conserver 16 variables, voir la ligne \u201cInfogain (nosedive)\u201d du tableau 3).\nNous avons ensuite utilis\u00e9 une approche enveloppe pour la s\u00e9lection de variables. Dans ce cas, la s\u00e9lection utilise la m\u00e9thode d\u2019apprentissage comme une bo\u00eete noire et cherche \u00e0 optimiser explicitement le taux d\u2019erreur. Il s\u2019agit donc, a priori, d\u2019explorer tout l\u2019espace des sous-ensembles de variables de l\u2019ensemble initial, et pour chaque\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 145\npoint de cet espace d\u2019ex\u00e9cuter l\u2019apprentissage de l\u2019algorithme de pr\u00e9diction consid\u00e9r\u00e9. L\u2019avantage de ce type d\u2019approche est d\u2019\u00eatre adapt\u00e9 \u00e0 l\u2019algorithme d\u2019apprentissage et de prendre en compte des d\u00e9pendances entre variables. Mais, le co\u00fbt d\u2019une telle approche appliqu\u00e9e na\u00efvement serait prohibitif. Ainsi, cet espace de recherche sera souvent explor\u00e9 gr\u00e2ce \u00e0 une heuristique gloutonne. Deux strat\u00e9gies classiques sont \u00e0 consid\u00e9rer : (i) le mode avant (forward selection) pour lequel on part d\u2019un petit ensemble de variables que l\u2019on fait cro\u00eetre progressivement, et (ii) le mode arri\u00e8re (backward elimination) pour lequel, partant avec toutes les variables, on \u00e9limine une \u00e0 une les plus faibles. Nous avons test\u00e9 une strat\u00e9gie gloutonne na\u00efve (descente de gradient sans retour arri\u00e8re, voir la ligne \u201cWrapper back. greedy\u201d du tableau 3), et une strat\u00e9gie gloutonne avec possibilit\u00e9 de retour arri\u00e8re en autorisant le choix d\u2019au plus deux n\u0153uds cons\u00e9cutifs de l\u2019espace de recherche n\u2019am\u00e9liorant pas le taux d\u2019erreur (voir la ligne \u201cWrapper back. best-first\u201d du tableau 3).\nTableau 3. R\u00e9sultats de la s\u00e9lection de variables pour l\u2019approche par filtre avec m\u00e9trique InfoGain, et pour l\u2019approche par enveloppe avec deux strat\u00e9gies\nd\u2019exploration gloutonne de l\u2019espace des sous-ensembles des variables (les valeurs repr\u00e9sentent le score F1 pour la classe positive (F1-True))\nJ48 N.Bayes Logistic SVM RBF Toutes les var. 0, 772 0, 759 0,802 0, 802 0, 802 Infogain (top 10) 0, 799 0, 785 0,803 0, 799 0, 801 Infogain (nosedive) 0, 792 0, 771 0,803 0, 801 0, 801 Wrapper back. best-first 0, 772 0, 802 0,804 0, 802 0, 801 Wrapper back. greedy 0, 787 0, 802 0,802 0, 802 0, 802\nNous avons remarqu\u00e9 que, dans notre cas, l\u2019algorithme de r\u00e9gression logistique \u00e9tait celui qui se comportait le mieux pour la s\u00e9lection de variables. Ainsi, nous avons essay\u00e9 d\u2019appliquer pour cet algorithme une approche enveloppe en mode avant en faisant varier le nombre de variables initiales de 0 \u00e0 10 dans l\u2019ordre de leur ordonnancement par la m\u00e9trique de gain d\u2019information (voir le tableau 4).\nTableau 4. R\u00e9sultats de la s\u00e9lection de variables pour l\u2019approche enveloppe en mode avant avec l\u2019algorithme de r\u00e9gression logistique et en faisant varier le nombre de\nvariables initiales de 0 \u00e0 10 selon leur score de gain d\u2019information\nNb var init. 10 6 4 Nb var finales 16 13 19\nF-True 0, 804 0,804 0, 803 F-All 0, 588 0,587 0, 589 ROC 0, 658 0,658 0, 659"}, {"heading": "6.8. Analyse des r\u00e9sultats", "text": "Par cette strat\u00e9gie de s\u00e9lection de variables, nous parvenons finalement \u00e0 r\u00e9duire le nombre de variables \u00e0 13 :\n146 DN. Volume 18 \u2013 no 2-3/2015\n\u2013 (TEL) Le nombre de termes partag\u00e9s par la phrase et les labels des k meilleures entit\u00e9s au sens de LDRANK.\n\u2013 (SES) Le score LDRANK de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e (normalis\u00e9 par le score LDRANK max obtenu par une entit\u00e9 de la m\u00eame page).\n\u2013 (SEL) Le nombre de termes partag\u00e9s par le label de l\u2019entit\u00e9 et la phrase. \u2013 (SEA) Le nombre de termes partag\u00e9s par le r\u00e9sum\u00e9 de l\u2019entit\u00e9 et la phrase. \u2013 (SEN) Le nombre d\u2019entit\u00e9s voisines de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e et pr\u00e9sentes dans la phrase. \u2013 (SENL) Le nombre de termes partag\u00e9s par les labels des entit\u00e9s voisines de l\u2019entit\u00e9 s\u00e9lectionn\u00e9e et la phrase. \u2013 (SEP) La position relative de l\u2019entit\u00e9 dans la phrase (normalis\u00e9e par la taille de la phrase). \u2013 (SE) La nature du dernier caract\u00e8re (point, points de suspension, etc.) de la phrase. \u2013 (QT) Le nombre de termes partag\u00e9s par la requ\u00eate et la phrase. \u2013 (AE) Le nombre d\u2019entit\u00e9s annot\u00e9es dans la phrase. \u2013 (AET) Le nombre de termes partag\u00e9s par la phrase et les labels des entit\u00e9s annot\u00e9es dans la phrase. \u2013 (SL) La position de la phrase dans la page web, normalis\u00e9e par le nombre total de phrases. \u2013 (LS) Est-ce la derni\u00e8re phrase ? (variable binaire)\nNous remarquons que les variables construites sur LDRANK, ainsi que celles qui d\u00e9pendent d\u2019une connaissance ext\u00e9rieure apport\u00e9e par les entit\u00e9s sont toutes pr\u00e9sentes."}, {"heading": "6.9. Synth\u00e8se", "text": "En conclusion, nous avons choisi des variables bas\u00e9es sur la requ\u00eate, le texte de la page web, et l\u2019ordonnancement des entit\u00e9s produit par LDRANK. Nous avons mis en place un processus de s\u00e9lection de variables : nous avons utilis\u00e9 une m\u00e9trique de gain d\u2019information pour s\u00e9lectionner un petit ensemble de variables que nous avons ensuite utilis\u00e9 comme ensemble de d\u00e9part pour une approche enveloppe (en mode avant). Nous avons observ\u00e9 que les variables d\u00e9riv\u00e9es de l\u2019ordonnancement produit par le LDRANK appartiennent syst\u00e9matiquement aux variables conserv\u00e9es. Ceci nous semble fournir une preuve suppl\u00e9mentaire, m\u00eame si indirecte, de l\u2019utilit\u00e9 du LDRANK.\nDans la section suivante, nous d\u00e9crivons les r\u00e9sultats d\u2019une \u00e9valuation par crowdsourcing du syst\u00e8me ENsEN.\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 147"}, {"heading": "7. \u00c9valuation par crowdsourcing de ENsEN", "text": ""}, {"heading": "7.1. M\u00e9thodologie", "text": "Nous cherchons \u00e0 \u00e9valuer l\u2019efficacit\u00e9 et l\u2019utilit\u00e9 de notre syst\u00e8me de g\u00e9n\u00e9ration de snippets s\u00e9mantiques, ENsEN, en le comparant \u00e0 une interface de recherche traditionnelle, celle du moteur de recherche Google. Nous adoptons une approche par crowdsourcing gr\u00e2ce \u00e0 la plateforme CrowdFlower (voir la section 3 pour une description de cette plateforme).\nLa t\u00e2che centrale d\u2019un participant \u00e0 notre \u00e9valuation est de trouver les r\u00e9ponses \u00e0 des questions de recherche d\u2019information sur le web (par exemple, \u201cWhat division (weight) did the boxer Floyd Patterson win?\u201d). Pour un participant, une premi\u00e8re moiti\u00e9 de ses t\u00e2ches doit \u00eatre r\u00e9alis\u00e9e en utilisant Google, l\u2019autre moiti\u00e9 en utilisant ENsEN. Ensuite, nous demandons \u00e0 chaque participant d\u2019\u00e9valuer et de comparer les deux interfaces.\nChaque t\u00e2che est extraite du jeu de donn\u00e9es TREC 2004 QA. Nous avons choisi al\u00e9atoirement 8 th\u00e8mes (topics). Chacun est accompagn\u00e9 de trois questions pour lesquelles nous connaissons les r\u00e9ponses. Deux des questions sont factuelles, la troisi\u00e8me attend une r\u00e9ponse sous la forme d\u2019une liste. Par ailleurs, une t\u00e2che comprend \u00e9galement un court questionnaire servant \u00e0 d\u00e9terminer l\u2019expertise du participant pour le domaine de la recherche sur le web (avec des questions du type : \u201cPour trouver les pages qui comprennent une phrase exacte, faut-il : (i) entourer la phrase de guillemets, (ii) simplement saisir la phrase telle quelle, (iii) placer un ast\u00e9risque \u00e0 une extr\u00e9mit\u00e9 de la phrase ? ; voir figure 4 pour les r\u00e9sultats de cette enqu\u00eate). Enfin, nous collectons quelques donn\u00e9es sur l\u2019\u00e2ge des participants et leurs habitudes de recherche : fontils le plus souvent des requ\u00eates exploratoires, informationnelles, navigationnelles ou transactionnelles ? Voir les figures 5 et 6 pour les r\u00e9sultats de cette enqu\u00eate.\nNous avons obtenu 11 jugements pour chacun des 8 th\u00e8mes. Nous n\u2019acceptons que les jugements dont la r\u00e9ponse a \u00e9t\u00e9 fournie en moins de 30 min. Nous n\u2019avons gard\u00e9 que les meilleurs participants du point de vue d\u2019une m\u00e9trique propre \u00e0 CrowdFlower. Nous d\u00e9crivions bri\u00e8vement cette derni\u00e8re m\u00e9trique en section 3, elle se fonde sur l\u2019exploitation de t\u00e2ches tests dont les r\u00e9ponses ont \u00e9t\u00e9 fournies par le concepteur de la t\u00e2che au syst\u00e8me CrowdFlower. Ainsi, pour chacun des 8 th\u00e8mes, nous g\u00e9n\u00e9rons une t\u00e2che test pour laquelle le participant doit r\u00e9pondre en utilisant le moteur de recherche Google.\nAvant de pouvoir \u00eatre r\u00e9mun\u00e9r\u00e9 en r\u00e9pondant \u00e0 des questions, un participant doit passer par le mode dit \u201cquiz\u201d. A cette occasion, une t\u00e2che test lui est pr\u00e9sent\u00e9e. S\u2019il fait plus de 50 % d\u2019erreurs \u00e0 ce test, il se verra interdire l\u2019acc\u00e8s au mode normal r\u00e9mun\u00e9r\u00e9. En mode normal, un participant se voit pr\u00e9senter une page avec deux t\u00e2ches : l\u2019une demande d\u2019utiliser Google, l\u2019autre ENsEN. Le travail n\u00e9cessaire pour compl\u00e9ter une telle page faite de deux t\u00e2ches est r\u00e9mun\u00e9r\u00e9 $0.25.\n148 DN. Volume 18 \u2013 no 2-3/2015\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 149"}, {"heading": "7.2. Analyse des r\u00e9sultats", "text": "Tout d\u2019abord, nous remarquons que la pr\u00e9cision des r\u00e9ponse ne d\u00e9pend pas du niveau d\u2019expertise des participants pour le domaine de la recherche sur le web (voir figure 7).\nPar ailleurs, nous observons que la pr\u00e9cision des r\u00e9ponses est le plus souvent comparable pour les deux syst\u00e8me Google et ENsEN, sauf dans le cas des th\u00e8mes pour\n150 DN. Volume 18 \u2013 no 2-3/2015\nlesquels la pr\u00e9cision des r\u00e9ponses est la moins bonne (c\u2019est-\u00e0-dire les th\u00e8mes 1 et 7 qui sont sans doute plus difficiles) o\u00f9 ENsEN est significativement meilleur que Google (voir figure 8).\nAussi, pour les deux types de questions (c\u2019est-\u00e0-dire, (i) donner la bonne r\u00e9ponse, (ii) donner une liste de bonnes r\u00e9ponses), nous remarquons que si les utilisateurs pr\u00e9f\u00e8rent l\u2019interface homme-machine propos\u00e9e par Google, ils ont cependant l\u2019impression de trouver plus facilement la r\u00e9ponse correcte en utilisant ENsEN (voir figures 9 et 10).\nEnfin, lorsque nous demandons aux participants quels sont les \u00e9l\u00e9ments de l\u2019interface d\u2019ENsEN qui leur semblent les plus utiles, nous observons que les parties de\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 151\n152 DN. Volume 18 \u2013 no 2-3/2015\nl\u2019interface qui mettent en avant les meilleures entit\u00e9s d\u00e9couvertes par LDRANK sont tr\u00e8s appr\u00e9ci\u00e9es (voir figure 11)."}, {"heading": "8. Conclusion", "text": "Nous avons propos\u00e9 un nouvel algorithme, LDRANK, pour l\u2019ordonnancement des entit\u00e9s d\u2019un graphe du web des donn\u00e9es qui peut \u00eatre creux et bruit\u00e9, mais pour lequel des donn\u00e9es textuelles descriptives sont associ\u00e9es aux n\u0153uds, et avec connaissance d\u2019un besoin d\u2019information exprim\u00e9 sous la forme d\u2019un ensemble de mots cl\u00e9s. De tels graphes apparaissent en particulier suite \u00e0 un processus de d\u00e9tection automatique d\u2019entit\u00e9s du web des donn\u00e9es au sein d\u2019une page web (par exemple, \u00e0 travers l\u2019utilisation de DBpedia Spotlight). Notre approche se caract\u00e9rise par la prise en compte \u00e0 la fois de la structure explicite offerte par le web des donn\u00e9es, et des relations implicites qui peuvent \u00eatre trouv\u00e9es par analyse du texte de la page web.\nLDRANK construit des ordonnancements d\u2019une qualit\u00e9 significativement meilleure \u00e0 celle des ordonnancements produits par les approches de l\u2019\u00e9tat de l\u2019art. De plus, nous avons appliqu\u00e9 cet algorithme au cadre applicatif de la construction de snippets s\u00e9mantiques. Dans ce contexte, la bonne pr\u00e9cision de l\u2019algorithme LDRANK a permis d\u2019obtenir des snippets s\u00e9mantiques utiles et utilisables, ouvrant la voie \u00e0 de nouvelles applications qui pourront b\u00e9n\u00e9ficier des apports mutuels du web des donn\u00e9es et du web des documents. Par exemple, des travaux futurs \u00e9valueront le potentiel de cette approche pour la recherche d\u2019information exploratoire.\nOrdonnancement d\u2019entit\u00e9s \u00e0 l\u2019\u00e2ge des deux web 153\nBibliographie\nAgeev M., Lagun D., Agichtein E. (2013). Improving search result summaries by using searcher behavior data. In Proceedings of the 36th international acm sigir conference on research and development in information retrieval, p. 13\u201322.\nAlonso O., Marshall C., Najork M. (2014). Crowdsourcing a subjective labeling task: A human-centered framework to ensure reliable results. Rapport technique. MSR-TR-201491, http://research. microsoft. com/apps/pubs/default. aspx.\nBai X., Delbru R., Tummarello G. (2008). Rdf snippets for semantic web search engines. In On the move to meaningful internet systems: Otm 2008, p. 1304\u20131318. Springer.\nBerry M. W. (1992). Large-scale sparse singular value computations. International Journal of Supercomputer Applications, vol. 6, no 1, p. 13\u201349.\nBizer C., Eckert K., Meusel R., M\u00fchleisen H., Schuhmacher M., V\u00f6lker J. (2013). Deployment of rdfa, microdata, and microformats on the web\u2013a quantitative analysis. In The semantic web\u2013iswc 2013, p. 17\u201332. Springer.\nCarvalho A., Larson K. (2013). A consensual linear opinion pool. In Proceedings of the twenty-third international joint conference on artificial intelligence, p. 2518\u20132524.\nChawla N. V., Bowyer K. W., Hall L. O., Kegelmeyer W. P. (2002). Smote: synthetic minority over-sampling technique. Journal of artificial intelligence research, p. 321\u2013357.\nDali L., Fortuna B., Duc T. T., Mladenic\u0301 D. (2012). Query-independent learning to rank for rdf entity search. In The semantic web: Research and applications, p. 484\u2013498. Springer.\nDing L., Finin T., Joshi A., Pan R., Cost R. S., Peng Y. et al. (2004). Swoogle: a search and metadata engine for the semantic web. In Proceedings of the thirteenth acm international conference on information and knowledge management, p. 652\u2013659.\nFafalios P., Tzitzikas Y. (2014). Post-analysis of keyword-based search results using entity mining, linked data, and link analysis at query time.\nFranz T., Schultz A., Sizov S., Staab S. (2009). Triplerank: Ranking semantic web data by tensor decomposition. In The semantic web-iswc 2009, p. 213\u2013228. Springer.\nGe W., Cheng G., Li H., Qu Y. (2012). Incorporating compactness to generate term-association view snippets for ontology search. Information Processing & Management, p. 513-528.\nHaas K., Mika P., Tarjan P., Blanco R. (2011). Enhanced results for web search. In Proceedings of the 34th international acm sigir conference on research and development in information retrieval, p. 725\u2013734.\nHall M., Frank E., Holmes G., Pfahringer B., Reutemann P., Witten I. H. (2009). The weka data mining software: an update. ACM SIGKDD explorations newsletter, vol. 11, no 1, p. 10\u201318.\nJ\u00e4rvelin K., Kek\u00e4l\u00e4inen J. (2000). Ir evaluation methods for retrieving highly relevant documents. In Proceedings of the 23rd annual international acm sigir conference on research and development in information retrieval, p. 41\u201348.\nJeong J.-W., Morris M. R., Teevan J., Liebling D. J. (2013). A crowd-powered socially embedded search engine. In Icwsm.\nJindal V., Bawa S., Batra S. (2014). A review of ranking approaches for semantic search on web. Information Processing & Management, vol. 50, no 2, p. 416\u2013425.\n154 DN. Volume 18 \u2013 no 2-3/2015\nKleinberg J. M. (1999). Authoritative sources in a hyperlinked environment. Journal of the ACM (JACM), vol. 46, no 5, p. 604\u2013632.\nKohlsch\u00fctter C., Fankhauser P., Nejdl W. (2010). Boilerplate detection using shallow text features. In Proceedings of the third acm international conference on web search and data mining, p. 441\u2013450.\nKrippendorff K. (2012). Content analysis: An introduction to its methodology. Sage.\nLandis J. R., Koch G. G. (1977). The measurement of observer agreement for categorical data. biometrics, p. 159\u2013174.\nLehmann J., Gerber D., Morsey M., Ngomo A.-C. N. (2012). Defacto-deep fact validation. In The semantic web\u2013iswc 2012, p. 312\u2013327. Springer.\nLempel R., Moran S. (2001). Salsa: the stochastic approach for link-structure analysis. ACM Transactions on Information Systems (TOIS), vol. 19, no 2, p. 131\u2013160.\nMendes P. N., Jakob M., Garc\u00eda-Silva A., Bizer C. (2011). Dbpedia spotlight: shedding light on the web of documents. In Proceedings of the 7th international conference on semantic systems, p. 1\u20138.\nMetzler D., Kanungo T. (2008). Machine learned sentence selection strategies for query-biased summarization. In Sigir learning to rank workshop, p. 40\u201347.\nNie Z., Zhang Y., Wen J.-R., Ma W.-Y. (2005). Object-level ranking: bringing order to web objects. In Proceedings of the 14th international conference on world wide web, p. 567\u2013 574.\nPage L., Brin S., Motwani R., Winograd T. (1999). The pagerank citation ranking: Bringing order to the web.\nPenin T., Wang H., Tran T., Yu Y. (2008). Snippet generation for semantic web search engines. In The semantic web, p. 493\u2013507. Springer.\nRoa-Valverde A. J., Sicilia M.-A. (s. d.). A survey of approaches for ranking on the web of data. Information Retrieval, p. 1\u201331.\nSteiner T., Troncy R., Hausenblas M. (2010). How google is using linked data today and vision for tomorrow. Proceedings of Linked Data in the Future Internet, vol. 700.\nWang C., Jing F., Zhang L., Zhang H.-J. (2007). Learning query-biased web page summarization. In Proceedings of the sixteenth acm conference on conference on information and knowledge management, p. 555\u2013562.\nWei W., Barnaghi P., Bargiela A. (2011). Rational research model for ranking semantic entities. Information Sciences, vol. 181, no 13, p. 2823\u20132840."}], "references": [{"title": "Improving search result summaries by using searcher behavior data", "author": ["M. Ageev", "D. Lagun", "E. Agichtein"], "venue": "Proceedings of the 36th international acm sigir conference on research and development in information retrieval, p. 13\u201322.", "citeRegEx": "Ageev et al\\.,? 2013", "shortCiteRegEx": "Ageev et al\\.", "year": 2013}, {"title": "Crowdsourcing a subjective labeling task: A human-centered framework to ensure reliable results", "author": ["O. Alonso", "C. Marshall", "M. Najork"], "venue": "Rapport technique. MSR-TR-201491, http://research. microsoft. com/apps/pubs/default. aspx.", "citeRegEx": "Alonso et al\\.,? 2014", "shortCiteRegEx": "Alonso et al\\.", "year": 2014}, {"title": "Rdf snippets for semantic web search engines", "author": ["X. Bai", "R. Delbru", "G. Tummarello"], "venue": "On the move to meaningful internet systems: Otm 2008, p. 1304\u20131318. Springer.", "citeRegEx": "Bai et al\\.,? 2008", "shortCiteRegEx": "Bai et al\\.", "year": 2008}, {"title": "Large-scale sparse singular value computations", "author": ["W. Berry M."], "venue": "International Journal of Supercomputer Applications, vol. 6, no 1, p. 13\u201349.", "citeRegEx": "M.,? 1992", "shortCiteRegEx": "M.", "year": 1992}, {"title": "Deployment of rdfa, microdata, and microformats on the web\u2013a quantitative analysis", "author": ["C. Bizer", "K. Eckert", "R. Meusel", "H. M\u00fchleisen", "M. Schuhmacher", "J. V\u00f6lker"], "venue": "The semantic web\u2013iswc 2013, p. 17\u201332. Springer.", "citeRegEx": "Bizer et al\\.,? 2013", "shortCiteRegEx": "Bizer et al\\.", "year": 2013}, {"title": "A consensual linear opinion pool", "author": ["A. Carvalho", "K. Larson"], "venue": "Proceedings of the twenty-third international joint conference on artificial intelligence, p. 2518\u20132524.", "citeRegEx": "Carvalho and Larson,? 2013", "shortCiteRegEx": "Carvalho and Larson", "year": 2013}, {"title": "Smote: synthetic minority over-sampling technique", "author": ["V. Chawla N.", "W. Bowyer K.", "O. Hall L.", "P. Kegelmeyer W."], "venue": "Journal of artificial intelligence research, p. 321\u2013357.", "citeRegEx": "N. et al\\.,? 2002", "shortCiteRegEx": "N. et al\\.", "year": 2002}, {"title": "Query-independent learning to rank for rdf entity search", "author": ["L. Dali", "B. Fortuna", "T. Duc T.", "D. Mladeni\u0107"], "venue": "The semantic web: Research and applications, p. 484\u2013498. Springer.", "citeRegEx": "Dali et al\\.,? 2012", "shortCiteRegEx": "Dali et al\\.", "year": 2012}, {"title": "Swoogle: a search and metadata engine for the semantic web", "author": ["L. Ding", "T. Finin", "A. Joshi", "R. Pan", "S. Cost R.", "Y Peng"], "venue": "Proceedings of the thirteenth acm international conference on information and knowledge management, p. 652\u2013659.", "citeRegEx": "Ding et al\\.,? 2004", "shortCiteRegEx": "Ding et al\\.", "year": 2004}, {"title": "Post-analysis of keyword-based search results using entity mining, linked data, and link analysis at query time", "author": ["P. Fafalios", "Y. Tzitzikas"], "venue": null, "citeRegEx": "Fafalios and Tzitzikas,? \\Q2014\\E", "shortCiteRegEx": "Fafalios and Tzitzikas", "year": 2014}, {"title": "Triplerank: Ranking semantic web data by tensor decomposition", "author": ["T. Franz", "A. Schultz", "S. Sizov", "S. Staab"], "venue": "The semantic web-iswc 2009, p. 213\u2013228. Springer.", "citeRegEx": "Franz et al\\.,? 2009", "shortCiteRegEx": "Franz et al\\.", "year": 2009}, {"title": "Incorporating compactness to generate term-association view snippets for ontology search", "author": ["W. Ge", "G. Cheng", "H. Li", "Y. Qu"], "venue": "Information Processing & Management, p. 513-528.", "citeRegEx": "Ge et al\\.,? 2012", "shortCiteRegEx": "Ge et al\\.", "year": 2012}, {"title": "Enhanced results for web search", "author": ["K. Haas", "P. Mika", "P. Tarjan", "R. Blanco"], "venue": "Proceedings of the 34th international acm sigir conference on research and development in information retrieval, p. 725\u2013734.", "citeRegEx": "Haas et al\\.,? 2011", "shortCiteRegEx": "Haas et al\\.", "year": 2011}, {"title": "The weka data mining software: an update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "H. Witten I."], "venue": "ACM SIGKDD explorations newsletter, vol. 11, no 1, p. 10\u201318.", "citeRegEx": "Hall et al\\.,? 2009", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Ir evaluation methods for retrieving highly relevant documents", "author": ["K. J\u00e4rvelin", "J. Kek\u00e4l\u00e4inen"], "venue": "Proceedings of the 23rd annual international acm sigir conference on research and development in information retrieval, p. 41\u201348.", "citeRegEx": "J\u00e4rvelin and Kek\u00e4l\u00e4inen,? 2000", "shortCiteRegEx": "J\u00e4rvelin and Kek\u00e4l\u00e4inen", "year": 2000}, {"title": "A crowd-powered socially embedded search engine", "author": ["J.-W. Jeong", "R. Morris M.", "J. Teevan", "J. Liebling D."], "venue": "Icwsm.", "citeRegEx": "Jeong et al\\.,? 2013", "shortCiteRegEx": "Jeong et al\\.", "year": 2013}, {"title": "A review of ranking approaches for semantic search on web", "author": ["V. Jindal", "S. Bawa", "S. Batra"], "venue": "Information Processing & Management, vol. 50, no 2, p. 416\u2013425.", "citeRegEx": "Jindal et al\\.,? 2014", "shortCiteRegEx": "Jindal et al\\.", "year": 2014}, {"title": "Authoritative sources in a hyperlinked environment", "author": ["M. Kleinberg J."], "venue": "Journal of the ACM (JACM), vol. 46, no 5, p. 604\u2013632.", "citeRegEx": "J.,? 1999", "shortCiteRegEx": "J.", "year": 1999}, {"title": "Boilerplate detection using shallow text features", "author": ["C. Kohlsch\u00fctter", "P. Fankhauser", "W. Nejdl"], "venue": "Proceedings of the third acm international conference on web search and data mining, p. 441\u2013450.", "citeRegEx": "Kohlsch\u00fctter et al\\.,? 2010", "shortCiteRegEx": "Kohlsch\u00fctter et al\\.", "year": 2010}, {"title": "Content analysis: An introduction to its methodology", "author": ["K. Krippendorff"], "venue": "Sage.", "citeRegEx": "Krippendorff,? 2012", "shortCiteRegEx": "Krippendorff", "year": 2012}, {"title": "The measurement of observer agreement for categorical data", "author": ["R. Landis J.", "G. Koch G."], "venue": "biometrics, p. 159\u2013174.", "citeRegEx": "J. and G.,? 1977", "shortCiteRegEx": "J. and G.", "year": 1977}, {"title": "Defacto-deep fact validation", "author": ["J. Lehmann", "D. Gerber", "M. Morsey", "N. Ngomo A.-C."], "venue": "The semantic web\u2013iswc 2012, p. 312\u2013327. Springer.", "citeRegEx": "Lehmann et al\\.,? 2012", "shortCiteRegEx": "Lehmann et al\\.", "year": 2012}, {"title": "Salsa: the stochastic approach for link-structure analysis", "author": ["R. Lempel", "S. Moran"], "venue": "ACM Transactions on Information Systems (TOIS), vol. 19, no 2, p. 131\u2013160.", "citeRegEx": "Lempel and Moran,? 2001", "shortCiteRegEx": "Lempel and Moran", "year": 2001}, {"title": "Dbpedia spotlight: shedding light on the web of documents", "author": ["N. Mendes P.", "M. Jakob", "A. Garc\u00eda-Silva", "C. Bizer"], "venue": "Proceedings of the 7th international conference on semantic systems, p. 1\u20138.", "citeRegEx": "P. et al\\.,? 2011", "shortCiteRegEx": "P. et al\\.", "year": 2011}, {"title": "Machine learned sentence selection strategies for query-biased summarization", "author": ["D. Metzler", "T. Kanungo"], "venue": "Sigir learning to rank workshop, p. 40\u201347.", "citeRegEx": "Metzler and Kanungo,? 2008", "shortCiteRegEx": "Metzler and Kanungo", "year": 2008}, {"title": "Object-level ranking: bringing order to web objects", "author": ["Nie Z.", "Zhang Y.", "Wen J.-R.", "Ma W.-Y."], "venue": "Proceedings of the 14th international conference on world wide web, p. 567\u2013 574.", "citeRegEx": "Z. et al\\.,? 2005", "shortCiteRegEx": "Z. et al\\.", "year": 2005}, {"title": "The pagerank citation ranking: Bringing order to the web", "author": ["L. Page", "S. Brin", "R. Motwani", "T. Winograd"], "venue": null, "citeRegEx": "Page et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Page et al\\.", "year": 1999}, {"title": "Snippet generation for semantic web search engines", "author": ["T. Penin", "H. Wang", "T. Tran", "Y. Yu"], "venue": "The semantic web, p. 493\u2013507. Springer.", "citeRegEx": "Penin et al\\.,? 2008", "shortCiteRegEx": "Penin et al\\.", "year": 2008}, {"title": "How google is using linked data today and vision for tomorrow", "author": ["T. Steiner", "R. Troncy", "M. Hausenblas"], "venue": "Proceedings of Linked Data in the Future Internet, vol. 700.", "citeRegEx": "Steiner et al\\.,? 2010", "shortCiteRegEx": "Steiner et al\\.", "year": 2010}, {"title": "Learning query-biased web page summarization", "author": ["C. Wang", "F. Jing", "L. Zhang", "H.-J. Zhang"], "venue": "Proceedings of the sixteenth acm conference on conference on information and knowledge management, p. 555\u2013562.", "citeRegEx": "Wang et al\\.,? 2007", "shortCiteRegEx": "Wang et al\\.", "year": 2007}, {"title": "Rational research model for ranking semantic entities", "author": ["W. Wei", "P. Barnaghi", "A. Bargiela"], "venue": "Information Sciences, vol. 181, no 13, p. 2823\u20132840.", "citeRegEx": "Wei et al\\.,? 2011", "shortCiteRegEx": "Wei et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 26, "context": "Bien que de telles relations soient g\u00e9n\u00e9ralement d\u2019une granularit\u00e9 assez grossi\u00e8re, elles forment cependant une composante essentielle des algorithmes d\u2019ordonnancement les plus reconnus (PageRank (Page et al., 1999), HITS (Kleinberg, 1999), SALSA (Lempel, Moran, 2001)).", "startOffset": 196, "endOffset": 215}, {"referenceID": 16, "context": ") et (Jindal et al., 2014) pour des \u00e9tats de l\u2019art r\u00e9cents) sont fond\u00e9es sur des adaptations du PageRank.", "startOffset": 5, "endOffset": 26}, {"referenceID": 7, "context": "Il existe \u00e9galement des approches du type apprendre-\u00e0-ordonner (learning-to-rank) appliqu\u00e9es au web des donn\u00e9es (par exemple (Dali et al., 2012)).", "startOffset": 125, "endOffset": 144}, {"referenceID": 27, "context": "Dans (Penin et al., 2008), les auteurs commencent par identifier un sujet th\u00e9matique gr\u00e2ce \u00e0 un algorithme de clustering hi\u00e9rarchique hors-ligne.", "startOffset": 5, "endOffset": 25}, {"referenceID": 11, "context": "Dans (Ge et al., 2012), les auteurs commencent par transformer le graphe RDF en un graphe qui met en relation des paires de termes et pour lequel chaque ar\u00eate est associ\u00e9e \u00e0 un ensemble de triplets RDF.", "startOffset": 5, "endOffset": 22}, {"referenceID": 2, "context": "Dans (Bai et al., 2008), les auteurs commencent par attribuer un th\u00e8me au document RDF.", "startOffset": 5, "endOffset": 23}, {"referenceID": 12, "context": "Or, parmi les approches qui permettent d\u2019am\u00e9liorer les snippets pour le web des documents en utilisant le web des donn\u00e9es (Haas et al., 2011)(Steiner et al.", "startOffset": 122, "endOffset": 141}, {"referenceID": 28, "context": ", 2011)(Steiner et al., 2010), aucune ne repose sur la d\u00e9tection automatique d\u2019entit\u00e9s : seules les annotations encapsul\u00e9es explicitement sont utilis\u00e9es.", "startOffset": 7, "endOffset": 29}, {"referenceID": 28, "context": "De plus, Google Rich Snippet (Steiner et al., 2010) est une initiative similaire qui s\u2019appuie exclusivement sur les m\u00e9tadonn\u00e9es structur\u00e9es r\u00e9dig\u00e9es par les \u00e9diteurs des pages web.", "startOffset": 29, "endOffset": 51}, {"referenceID": 4, "context": "Enfin, une \u00e9tude faite en 2012 (Bizer et al., 2013) sur plus de 40 millions de sites web du Corpus Common Crawl montre que seul 5,64 % des sites int\u00e8grent des donn\u00e9es structur\u00e9es.", "startOffset": 31, "endOffset": 51}, {"referenceID": 8, "context": "Ainsi, OntologyRank (Ding et al., 2004) (utilis\u00e9 par Swoogle) modifie la matrice de t\u00e9l\u00e9portation pour prendre en compte les types de relations qui existent entre diff\u00e9rentes ontologies.", "startOffset": 20, "endOffset": 39}, {"referenceID": 30, "context": "Enfin, RareRank (Wei et al., 2011) modifie la matrice de t\u00e9l\u00e9portation pour mod\u00e9liser l\u2019influence de la proximit\u00e9 th\u00e9matique entre entit\u00e9s, proximit\u00e9 \u00e9valu\u00e9e gr\u00e2ce \u00e0 l\u2019introduction d\u2019une mesure de similarit\u00e9 s\u00e9mantique dont le calcul d\u00e9pend d\u2019ontologies disponibles pour le domaine consid\u00e9r\u00e9.", "startOffset": 16, "endOffset": 34}, {"referenceID": 18, "context": "Pour chacun de ces 150 documents HTML, nous avons extrait le contenu textuel principal en appliquant l\u2019algorithme d\u00e9velopp\u00e9 par Kohlschtter, Frankhauser, et Nejdl (Kohlsch\u00fctter et al., 2010).", "startOffset": 163, "endOffset": 190}, {"referenceID": 19, "context": "Nous avons mesur\u00e9 l\u2019accord entre contributeurs gr\u00e2ce au coefficient alpha de Krippendorff (Krippendorff, 2012).", "startOffset": 90, "endOffset": 110}, {"referenceID": 15, "context": "(Jeong et al., 2013) ont obtenu un kappa de Fleiss de 0, 41 (c\u2019est-\u00e0-dire, un accord mod\u00e9r\u00e9) pour un moteur de recherche qui fait appel \u00e0 la sagesse des foules pour r\u00e9pondre \u00e0 certaine requ\u00eates.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "Cependant, Alonso, Marshall et Najork (Alonso et al., 2014) ont obtenu un alpha de Krippendorff qui varie entre 0, 03 et 0, 19 dans le cadre d\u2019une t\u00e2che plus subjective : d\u00e9cider de l\u2019int\u00e9r\u00eat d\u2019un tweet.", "startOffset": 38, "endOffset": 59}, {"referenceID": 26, "context": "L\u2019algorithme PageRank (Page et al., 1999) transforme la matrice d\u2019adjacence (M ) d\u2019un r\u00e9seau de pages web en une matrice H qui est stochastique (c\u2019est-\u00e0-dire que la somme de chaque ligne de H vaut 1) et primitive (c\u2019est-\u00e0-dire qu\u2019il existe un entier k tel que H > 0), assurant ainsi l\u2019existence d\u2019un vecteur stationnaire (c\u2019est-\u00e0-dire, le vecteur propre positif correspondant \u00e0 la valeur propre 1).", "startOffset": 22, "endOffset": 41}, {"referenceID": 10, "context": "(Franz et al., 2009) : pour chacune des meilleures entit\u00e9s (au sens du LDRANK), nous s\u00e9lectionnons les facteurs auxquels elle contribue le plus (en tant que sujet ou en tant qu\u2019objet), et pour chacun de ces facteurs, nous s\u00e9lectionnons les triplets qui ont les pr\u00e9dicats avec les meilleurs scores.", "startOffset": 0, "endOffset": 20}, {"referenceID": 29, "context": "Dans (Wang et al., 2007), les auteurs introduisent des variables qui prennent en compte \u00e0 la fois le contenu de la page web et \u00e9galement le contenu contextuel qui provient des textes d\u2019ancrage de liens qui pointent vers la page web.", "startOffset": 5, "endOffset": 24}, {"referenceID": 29, "context": "Les auteurs de (Wang et al., 2007) exp\u00e9rimentent sur les donn\u00e9es de la Web Track de TREC-2003.", "startOffset": 15, "endOffset": 34}, {"referenceID": 29, "context": "Dans (Metzler, Kanungo, 2008), les auteurs m\u00e8nent un travail similaire \u00e0 celui que nous venons d\u2019introduire ((Wang et al., 2007)), aux diff\u00e9rences pr\u00e8s qu\u2019il comparent trois type d\u2019algorithmes d\u2019apprentissage adapt\u00e9s aux approches apprendre \u00e0 ordonner (Ranking SVM, Support Vector Regression, et Gradient Boosted Decision Trees), qu\u2019ils introduisent des variables ind\u00e9pendantes de la requ\u00eate (viz.", "startOffset": 109, "endOffset": 128}, {"referenceID": 0, "context": "Dans (Ageev et al., 2013), les auteurs suivent les r\u00e9sultats introduits ci-dessus ((Metzler, Kanungo, 2008)) et utilisent un algorithme de Gradient Boosting Regression Tree (GBRT).", "startOffset": 5, "endOffset": 25}, {"referenceID": 21, "context": "Enfin, dans (Lehmann et al., 2012), les auteurs proposent l\u2019algorithme DeFacto pour valider la v\u00e9racit\u00e9 d\u2019un triplet RDF du LOD par la d\u00e9couverte de fragments de pages web qui serviront de sources d\u2019information confirmant le fait exprim\u00e9 par le triplet.", "startOffset": 12, "endOffset": 34}, {"referenceID": 13, "context": "Par ailleurs, nous avons utilis\u00e9 la plateforme Weka (Hall et al., 2009).", "startOffset": 52, "endOffset": 71}], "year": 2016, "abstractText": "The advances of the Linked Open Data (LOD) initiative are giving rise to a more structured web of data. A few datasets act as hubs (e.g., DBpedia) connecting many other datasets. They also make possible new web services for entity detection inside plain text (e.g., DBpedia Spotlight), thus allowing for new applications that will benefit from a combination of the web of documents and the web of data. To ease the emergence of these new use-cases, we propose a query-biased algorithm for the ranking of entities detected within a web page. Our algorithm combines link analysis with dimensionality reduction. We use crowdsourcing for building a publicly available and reusable dataset on which we compare our algorithm to the state of the art. Finally, we use this algorithm for the construction of semantic snippets for which we evaluate the usability and the usefulness with a crowdsourcing-based approach. MOTS-CL\u00c9S : web des donn\u00e9es, ordonnancement d\u2019entit\u00e9s, snippets s\u00e9mantiques.", "creator": "TeX"}}}