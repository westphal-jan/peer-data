{"id": "1602.08610", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2016", "title": "Scalable Bayesian Rule Lists", "abstract": "we present an algorithm for building rule lists that is two square orders of magnitude faster than previous work. rule list algorithms are competitors for decision tree algorithms. nonetheless they are associative classifiers, in that they are built from perfectly pre - mined association rules. they have a logical structure that is consistently a sequence dependent of if - nor then rules, identical to a uniform decision list or no one - sided decision tree. instead of using greedy splitting and pruning like pure decision tree checking algorithms, we typically fully optimize over rule lists, striking further a practical balance between logical accuracy, interpretability, entropy and computational speed. the algorithm presented here uses a mixture of theoretical bounds ( tight enough to have practical implications as a screening or bounding procedure ), computational dictionary reuse, and highly tuned language libraries to achieve computational efficiency. currently, for many practical problems, this method achieves better rendering accuracy and sparsity than decision trees ; further, notably in many cases, the computational assembly time is practical and equally often less than that of decision trees.", "histories": [["v1", "Sat, 27 Feb 2016 16:29:24 GMT  (1106kb,D)", "http://arxiv.org/abs/1602.08610v1", "31 pages, 18 figures"], ["v2", "Mon, 3 Apr 2017 07:01:26 GMT  (943kb,D)", "http://arxiv.org/abs/1602.08610v2", "31 pages, 19 figures"]], "COMMENTS": "31 pages, 18 figures", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["hongyu yang", "cynthia rudin", "margo seltzer"], "accepted": true, "id": "1602.08610"}, "pdf": {"name": "1602.08610.pdf", "metadata": {"source": "CRF", "title": "Scalable Bayesian Rule Lists", "authors": ["Hongyu Yang", "Cynthia Rudin"], "emails": ["hongyuy@mit.edu", "rudin@mit.edu", "margo@eecs.harvard.edu"], "sections": [{"heading": "1. Introduction", "text": "Our goal is to build a competitor for decision tree algorithms in terms of accuracy, interpretability, and computational speed. Decision trees are widely used, particularly in industry, because of their interpretability. Their logical IF-THEN structure allows predictions to be explained to users. However, decision tree algorithms have the serious flaw that they are constructed using greedy splitting from the top down. They also use greedy pruning of nodes. They do not globally optimize any function, instead they are comprised entirely of local optimization heuristics. If the algorithm makes a mistake in the splitting near the top of the tree, it is difficult to undo it, and consequently the trees become long and uninterpretable, unless they are heavily pruned, in which case accuracy suffers. In general, decision tree algorithms are computationally tractable, not particularly accurate, and less sparse and interpretable than they could be. This leaves users with no good alternative if they desire an accurate yet sparse logical classifier.\nSeveral important ingredients provide the underpinning for our method including:\nar X\niv :1\n60 2.\n08 61\n0v 1\n[ cs\n.A I]\n2 7\n(i) A principled objective, which is the posterior distribution for the Bayesian Rule List (BRL) model of Letham et al.\u2019s (2015). We optimize this objective over rule lists. Our algorithm is called Scalable Bayesian Rule Lists (SBRL).\n(ii) A useful statistical approximation that narrows the search space. We assume that each leaf of the rule list contains (\u201ccaptures\u201d) a number of observations that is bounded below by zero. Because of this approximation, the set of conditions defining each leaf is a frequent pattern. This means the rule list is comprised of only frequent patterns. All of the possible frequent patterns can be pre-mined from the dataset using one of the standard frequent pattern mining methods. This leaves us with a much smaller optimization problem: we optimize over the set of possible pre-mined rules and their order to create the rule list.\n(iii) High performance language libraries to achieve computational efficiency. Optimization over rule lists can be solved by repeated low level computations that have the capacity to be sped up. At every iteration, we make a change to the rule list and need to evaluate the new rule list on the data. The high performance calculations speed up this evaluation.\n(iv) Computational reuse. When we evaluate a rule list on the data that has been modified from a previous rule list, we need only to change the evaluation of points below the change in the rule list. Thus we can reuse the computation above the change.\n(v) Analytical bounds on BRL\u2019s posterior that are tight enough to be used in practice for screening association rules and providing bounds on the optimal solution. These are provided in two theorems in this paper.\nThrough a series of controlled experiments, our experiments show over two orders of magnitude speedup over the previous best code for this problem.\nLet us provide some sample results. Figure 1 presents an example of a rule list that we learned for the UCI Mushroom dataset (see Bache & Lichman, 2013). This rule list is a predictive model for whether a mushroom is poisonous. It was created in about 10 seconds on a laptop and achieves perfect out-of-sample accuracy. Figure 2 presents a rule list for the UCI Adult dataset (see Bache & Lichman, 2013). We ran our SBRL algorithm for approximately 45 seconds on a laptop to produce this. The algorithm achieves a higher out-of-sample AUC (area under the ROC Curve) than that achieved if CART or C4.5 were heavily tuned on the test set itself."}, {"heading": "2. Previous Work: Review of Bayesian Rule Lists of Letham et al. (2015)", "text": "Scalable Rule Lists uses the posterior distribution of the Bayesian Rule Lists algorithm. Our training set is {(xi, yi)}ni=1 where the xi \u2208 X encode features, and yi are labels, which in our case are binary, either 0 or 1. A Bayesian decision list has the following form:\nif x obeys a1 then y \u223c Binomial(\u03b81), \u03b81 \u223c Beta(\u03b1 + N1) else if x obeys a2 then y \u223c Binomial(\u03b82), \u03b82 \u223c Beta(\u03b1 + N2) ...\nelse if x obeys am then y \u223c Binomial(\u03b8m), \u03b8m \u223c Beta(\u03b1 + Nm) else y \u223c Binomial(\u03b80), \u03b80 \u223c Beta(\u03b1 + N0).\nHere, the antecedents {aj}mj=1 are conditions on the x\u2019s that are either true or false, for instance, if x is a patient, aj is true when x\u2019s age is above 60 years old and x has diabetes, otherwise false. The vector \u03b1 = [\u03b11, \u03b10] has a prior parameter for each of the two labels. Values \u03b11 and \u03b10 are prior parameters, in the sense that each rule\u2019s prediction y \u223c Binomial(\u03b8j), and \u03b8j |\u03b1 \u223c Beta(\u03b1). The notation Nj is the vector of counts, where Nj,l is the number of observations xi that satisfy condition aj but none of the previous conditions a1, ..., aj\u22121, and that have label yi = l, where l is either 1 or 0. Nj is added to the prior parameters \u03b1 from the usual derivation of the posterior for the Beta-binomial. The\ndefault rule is at the bottom, which makes predictions for observations that are not satisfied by any of the conditions. When an observation satisfies condition aj but not a1, ..., aj\u22121 we say that the observation is captured by rule j. Formally:\nDefinition 1 Rule j captures observation i, denoted Captr(i) = j, when\nj = argmin j\u2032 such that aj\u2032(xi) = True.\nBayesian Rule Lists is an associative classification method, in the sense that the antecedents are first mined from the database, and then the set of rules and their order are learned. The rule mining step is fast, and there are fast parallel implementations available. Any frequent pattern mining method will suffice, since the method needs only to produce all conditions with sufficiently high support in the database. The support of antecedent aj is denoted supp(aj), which is the number of observations that obey condition aj . A condition is a conjunction of expressions \u201cfeature\u2208values,\u201d e.g., age\u2208[40-50] and color=white. The hard part is learning the rule list, which is what this paper focuses on.\nThe likelihood for the model discussed above is:\nLikelihood = p(y|x, d, \u03b1) \u221d m\u220f j=0 \u0393(Nj,0 + \u03b10)\u0393(Nj,1 + \u03b11) \u0393(Nj,0 +Nj,1 + \u03b10 + \u03b11) ,\nwhere d denotes the rules in the list and their order, d = (L, {aj , \u03b8j}mj=0). Intuitively, one can see that having more of one class and less of the other class will make the likelihood larger. To see this, note that if Nj,0 is large and Nj,1 is small (or vice versa) the likelihood for rule j is large.\nLet us discuss the prior. There are three terms in the prior, one governing the number of rules m in the list, one governing the size cj of each rule j (the number of conditions in the rule), and one governing the choice of antecedent condition aj of rule j given its size. Notation a<j includes the antecedents before j in the rule list if there are any, e.g. a<4 = {a1, a2, a3}. Also cj is the cardinality of antecedent aj , also written |aj |, as the number of conjunctive clauses in rule aj . E.g, for rule a being \u2019x1=green\u2019 and \u2019x2<50\u2019, this has cardinality 2. c<j includes the cardinalities of the antecedents before j in the rule list. Notation A is the set of pre-mined antecedents. The prior is:\nprior(d|A, \u03bb, \u03b7) = p(d|A, \u03bb, \u03b7) = p(m|A, \u03bb) m\u220f j=1 p(cj |c<j ,A, \u03b7)p(aj |a<j , cj ,A). (1)\nThe first term is the prior for the number of rules in the list. Here, the number of rules m is Poisson, truncated at the total number of pre-selected antecedents:\np(m|A, \u03bb) = (\u03bb m/m!)\u2211|A|\nj=0(\u03bb j/j!)\n, m = 0, . . . , |A|,\nwhere \u03bb is a hyper-parameter. The second term in the prior governs the number of conditions in each rule. The size of rule j is cj which is Poisson, truncated to remove values for which no rules are available with that cardinality:\np(cj |c<j ,A, \u03b7) = (\u03b7cj/cj !)\u2211\nk\u2208Rj\u22121(c<j ,A)(\u03b7 k/k!)\n, cj \u2208 Rj\u22121(c<j ,A),\nwhere Rj\u22121 is the set of cardinalities available after removing the first j \u2212 1 rules, and \u03b7 is a hyperparameter. The third term in the prior governs the choice of antecedent, given that we have determined its size through the second term. We simply have aj selected from a uniform distribution over antecedents in A of size cj , excluding those in a<j .\np(aj |a<j , cj ,A) \u221d 1, aj \u2208 Qcj = {a \u2208 A \\ {a1, a2, ..., aj\u22121} : |a| = cj}. (2)\nAs usual, the posterior is the likelihood times the prior.\np(d|x,y,A, \u03b1, \u03bb, \u03b7) \u221d p(y|x, d, \u03b1)p(d|A, \u03bb, \u03b7).\nThis is the full model, and the posterior p(d|x,y,A, \u03b1, \u03bb, \u03b7) is what we aim to optimize in order to obtain the best rule lists. The hyperparameter \u03bb is chosen by the user to be the desired size of the rule list, and \u03b7 is chosen as the desired number of terms in each rule. The parameters \u03b10 and \u03b11 are usually chosen as 1 in order not to favor one class label over another."}, {"heading": "3. Markov Chain Monte Carlo", "text": "Given the prior parameters \u03bb, which governs the length of the list, \u03b7, which governs the desired number of conditions in the list, and \u03b1, which provides a preference over labels (usually we set all the \u03b1\u2019s to 1), along with the set of pre-mined rules A, the algorithm must select which rules from A to use, along with their order. We start with a simple update scheme to iteratively maximize the posterior. This could be used for both inference (MCMC) and simulated annealing. We use only MCMC iterates in our experiments, but choose the MAP solution among the iterates. To define a rule list, the algorithm chooses a subset of antecedents from A, along with a permutation of antecedents.\nLet us define the neighborhood of a rule list, which is all rule lists that are edit distance 1 away from the initial list. The neighborhood of a rule list can be constructed by removing one rule, adding one rule from A into the list, or swapping a rule in the list with one that is in A. At each time t, we choose a neighboring rule list at random from the neighborhood by adding, removing, or moving a rule somewhere else within the list. The proposal probabilities for a list d\u2217 from the current list dt are: 1/[(|dt|)(|dt| \u2212 1)] if the proposal is to move a rule, 1/[(|A| \u2212 |dt|)(|dt|+ 1)] for a proposal to add a rule, and 1/|dt| for a proposal to remove a rule.\nAt each step, we need to evaluate the posterior function on each new rule list. Since this process is repeated many times during the algorithm, speeding up this particular subroutine can have a tremendous increase in computational speed. We improve the speed in three ways: we use high performance language libraries, computational reuse, and theoretical bounds."}, {"heading": "4. Implementation Techniques", "text": ""}, {"heading": "4.1 Expressing computation as bit vectors", "text": "The vast majority of the computational time spent constructing rule sets lies in determining which rules capture which observations in a particular rule ordering. As a reminder, for a\ngiven ordering of rules in a set, we say that the first rule for which an observation evaluates true captures that observation. The naive implementation of these operations calls for various set operations \u2013 checking whether a set contains an element, adding an element to a set, and removing an element from a set. However, set operations are typically slow, and hardware does little to help with efficiency.\nWe convert all set operations to logical operations on bit vectors, for which hardware support is readily available. The bit vector representation is both memory- and computationally- efficient. The vectors have length equal to the total number of data samples. Before beginning the algorithm, for each rule, we compute the bit vector representing the samples for which the rule generates a true value. For a one million sample data set (or more precisely up to 1,048,576 observations) each rule carries with it 128 KB vector (since a byte consists of 8 bits), which fits comfortably in most L2 caches."}, {"heading": "4.2 Representing Intermediate State as Bit Vectors", "text": "For each rule list we consider, we maintain similarly sized vectors for each rule in the set indicating which rule in the set captures which observation. Within a rule list, each observation is captured by one and only one rule \u2013 the first rule for which the condition evaluates true. Representing the rules and rule lists this way allows us to explore the rule list state space, reusing significant computation. For example, consider a rule list containing m rules. Imagine that we wish to delete rule k from the set. The naive implementation recomputes the \u201ccaptures\u201d vector for every rule in the set. Our implementation updates only rules j > k, using logical operators acting upon the rule list \u201ccaptures\u201d vector for k, and the rule\u2019s \u201ccaptures\u201d vector for each rule j > k. This shortens the run time of the algorithm in practice by approximately 50%."}, {"heading": "4.3 An Algebra for Computation Reuse", "text": "Our use of bit vectors transforms the large number of set operations performed in a traditional implementation into a set of boolean operations on bit vectors. These are summarized below. In our notation, the rule list contains n rules; k and j are used to represent particular rules in the rule list. Let k.captures refer to the captures vector for rule k and k.init refer to the original vector associated with each rule, indicating all observations for which the rule evaluates true. Note that k.captures \u2282 k.init. Below we show these bit vector operations for the possible MCMC steps.\n1. Remove rule k\nfor j = k + 1 to m do tmp\u2190 j.init\u2228 k.captures {Everything k used to capture that could be captured by rule j} j.captures \u2190 j.captures \u2227 tmp {Add things k use to capture that j can now capture} k.captures \u2190 k.captures \u2228 \u00actmp {Remove the newly captured items for j from k} end for\n2. Insert rule into the ruleset at position k\nm\u2190 m+ 1 shift rules k + 1 to m up one slot captured\u2190 { ~0m} for j = 1 to k \u2212 1 do captured\u2190 captured \u2227 j.captures end for for j = k to m do j.captures\u2190 j.init \u2228 \u00accaptured captured\u2190 j.captures \u2227 captured end for\n3. Swap consecutive rules k and j, where j = k + 1\ncaptured\u2190 { ~0n} for k = 1 to k \u2212 1 do captured\u2190 captured \u2227 k.captures end for j.captures\u2190 j.init \u2228 \u00accaptured k.captures\u2190 i.captures \u2228 \u00acj.init Swap rules k and j\n4. Generalized swap k and j\ncaptured\u2190 { ~0n} for t = k to j do captured\u2190 captured \u2227 k.captures end for swap rules k and j for t = k to j \u2212 1 do t.captures\u2190 captured \u2228 t.init captured\u2190 captured \u2228 \u00act.captures end for"}, {"heading": "4.4 High Performance Bit Manipulation", "text": "Having transformed expensive set operations into bit vector operations, we can now leverage both hardware vector instructions and optimized software libraries. We investigated three alternative implementations, each improving computational efficiency from the previous one.\n\u2022 First, we retained our python implementation with added bit operations.\n\u2022 Next, we used the python gmpy library to do the population count.\n\u2022 Then, we moved the implementation from Python to C, representing the bit vectors as packed arrays of longs and reusing the information from previous evaluation of the posteriors.\n\u2022 Finally, we employed GMP library which in practice is slow on small data sets, but faster on big data sets.\nTo evaluate how each of these steps improved the computation time of the algorithm, we conducted a controlled experiment where each version of the algorithm (corresponding to the three steps above) was given the same data (the UCI adult dataset, divided into three folds), same set of rules, and same number of MCMC iterations (20,000) to run. We created boxplots for the log of the run time over the different folds, which is shown in Figure 3. The code is over two orders of magnitude faster than the original optimized python code."}, {"heading": "5. Theoretical Bounds with Practical Implications", "text": "We prove two bounds. First we provide an upper bound on the number of rules in a maximum a posteriori rule list. This allows us to narrow our search space to rule lists below a certain size if desired.\nSecond we provide a branch and bound constraint that eliminates certain prefixes of rule lists if desired. This prevents our algorithm from searching in regions of the space that provably do not contain the maximum a posteriori rule list."}, {"heading": "5.1 Upper bound on the number of rules in the list", "text": "Given the number of features, the parameter \u03bb for the size of the list, and parameters \u03b10 and \u03b11, we can derive an upper bound for the size of a maximum a posteriori rule list. This formalizes how the prior on the number of rules is strong enough to overwhelm the likelihood.\nWe are considering binary rules and binary features, so the total number of possible rules of each size can be calculated directly. When creating the upper bound, within the proof, we hypothetically exhaust rules from each size category in turn, starting with the smallest sizes. We discuss this further below.\nLet |Qc| be the number of rules that remain in the pile that have c logical conditions. The sequence of b\u2019s that we define next is a lower bound for the possible sequence of |Qc|\u2019s. In particular, b represents the sequence of sizes of rules that would provide the smallest possible |Qc|. Intuitively, the sequence of b\u2019s arises when we deplete the rules of size 1, then deplete all of the rules of size 2, etc. The number of ways to do this is given exactly by the b values, computed as follows. Definition Let P be the number of features, and b = { b0, b1, b2, ...b2P\u22121 } be a vector of length P defined as follows:\nindex = 0 b0=1\nfor c = 0 to \u230a P 2 \u230b do\nfor j = ( P c ) down to 1 (using step size=-1) do\nindex = index + 1 bindex = j\nend for\nif (c+c != P ) then\nfor j = ( P P\u2212c )\ndown to 1 (using step size = -1) do index = index + 1 bindex = j\nend for end if\nend for\nFigure 4 is an illustration for the bj \u2019s when the number of features is P = 5. We will use the b\u2019s within the theorem below. In our notation, rule list d is defined by\nthe antecedents and the probabilities on the right side of the rules, d = (m, {al, \u03b8l}ml=1). Theorem 1 The size m\u2217 of any MAP rule list d\u2217 (with parameters \u03bb, \u03b7, and \u03b1 = (\u03b10, \u03b11)) obeys m\u2217 \u2264 mmax, where\nmmax = min 2P \u2212 1,max m\u2032 \u2208 Z+ : \u03bbm \u2032 m\u2032! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2032\u220f j=1 bj   . (3)\nIn the common parameter choice \u03b10 = 1 and \u03b11 = 1, this reduces to:\nmmax = min 2P \u2212 1,max m\u2032 \u2208 Z+ : \u03bbm \u2032 m\u2032! \u2265 \u0393(N\u2212 + 1)\u0393(N+ + 1) \u0393(N + 2) m\u2032\u220f j=1 bj   . (4)\nThe proof is in the appendix.\nFigure 5 illustrates the use of this theorem. In particular, we plotted the upper bound for m\u2217 from the Theorem 1 when the number of features P is 10 in Figure 5 (left) and we plotted the upper bound when the number of features is 15 in Figure 5 (right), with \u03bb = 3 and \u03b10 = \u03b11 = 1. For instance, when there are 10 features (left plot) and approximately 100 positive and 100 negative observations, there will be at most about 36 rules."}, {"heading": "5.2 Prefix Bound", "text": "We next provide a bound that eliminates certain regions of the rule space from consideration. Consider a rule list beginning with rules a1, .., ap. If the best possible rule list starting with a1, .., ap cannot beat the posterior of the best rule list we have found so far, then we know any rule list starting with a1, .., ap is suboptimal. In that case, we should stop exploring rule lists starting with a1, .., ap. This is a type of branch and bound strategy, in that we have now eliminated (bounded) the entire set of lists starting with a1, .., ap. We formalize this intuition below.\nDenote the rule list at iteration t by dt = (at1, a t 2, ..., a t mt , a0). The current best posterior\nprobability has value v\u2217t , that is\nv\u2217t = max t\u2032\u2264t Posterior(dt \u2032 , {(xi, yi)}ni=1).\nLet the current rule list be d = (a1, a2, ...am, a0). Let dp denote a prefix of length p of the rule list d, i.e., dp = (a1, a2, ...ap), where a1, a2, ..., ap is the same as the first p rules in d. Figure 6 illustrates this notation. We want to determine whether a rule list starting with dp could be better than the best we have seen so far. Define \u03a5(dp, {(xi, yi)}ni=1) as follows:\n\u03a5(dp, {(xi, yi)}ni=1)\n:= \u03bbmax (p,\u03bb)/(max (p, \u03bb))!\u2211|A|\nj=0(\u03bb j/j!)\n p\u220f j=1 p(cj |c<j ,A, \u03b7) 1 |Qcj | \u00d7  m\u220f j=0 \u0393(Nj,0 + 1)\u0393(Nj,1 + 1) \u0393(Nj,0 +Nj,1 + 2)  \u0393(1 +N0 \u2212\u2211pj=1Nj,0) \u0393(2 +N0 \u2212 \u2211p j=1Nj,0) \u0393(1 +N1 \u2212 \u2211p j=1Nj,1) \u0393(2 +N1 \u2212 \u2211p j=1Nj,1) .\nHere, Nj,0 is the number of points captured by rule j with label 0, and Nj,1 is the number of points captured by rule j with label 1,\nNj,0 = |{i : Captr(i) = j and yi = 0}|, Nj,1 = |{i : Captr(i) = j and yi = 1}|.\nThe result states that for a rule list with prefix dp, if the upper bound on the posterior, \u03a5(dp), is not as high as the posterior of the best rule list we have seen so far, then dp is a bad prefix, which cannot lead to a MAP solution. It tells us we no longer need to consider rule lists starting with dp.\nTheorem 2 For rule list d = {dp, ap+1, ..., am, a0}, if\n\u03a5(dp, {(xi, yi)}ni=1) < v\u2217t ,\nthen for \u03b10 = 1 and \u03b11 = 1, we have\nd 6\u2208 argmaxd\u2032Posterior(d\u2032, {(xi, yi)}ni=1). (5)\nTheorem 2 is implemented in our code in the following way: for each random restart, the initial rule in the list is checked against the bound of Theorem 2. If the condition \u03a5(d1) < v \u2217 t holds, we throw out this initial rule and choose a new one, because that rule provably cannot be the first rule in an optimal rule list. Theorem 2 provides a substantial computational speedup in finding high quality or optimal solutions. In some cases, it provides a full order of magnitude speedup. Because it has been so useful in practice, we provide illustrative examples."}, {"heading": "5.3 Demonstrations of Theorem 2", "text": "Demonstration 1: We use the Tic Tac Toe dataset from the UCI repository (see Bache & Lichman, 2013). Each observation is a tic tac toe board after the game has ended. If the X player wins, the label of the observation is 1, otherwise it is 0. Let us consider a rule list starting with the following two rules:\nIf\no\nthen ...\nelse if o then ...\nelse if ...\nThe first rule says that the board contains an \u201cO\u201d in the bottom middle spot, and the rule says nothing about other spots. Intuitively this is a particularly bad rule, since it captures a lot of possible tic tac toe boards, and on its own, cannot distinguish between winning and losing boards for the \u201cX\u201d player. Similarly, the second rule also does not discriminate well. Thus, we expect any rule list starting with these two rules to perform poorly. We can show this using the theorem. On one of three folds of the data, this rule list has a log posterior that is upper bounded at -272.51. From an earlier run of the algorithm, we know there is a rule list with a posterior of -105.012. (That rule list is provided in Table 2 and contains exactly one rule for each way the \u201cX\u201d player could have three X\u2019s in a row on the board.) Since the upper bound on the posterior for this rule list (-272.51) is less than -105.012, there does not exist an optimal rule list starting with these two rules.\nDemonstration 2: In contrast with Demonstration 1, a rule list starting as follows cannot be excluded.\nIf o o o then ...\nelse if\no o o\nthen ...\nelse if ...\nThese first two rules says that the \u201cO\u201d player has three O\u2019s in a row, which means the \u201cX\u201d player could not have won. This prefix has a log posterior that is upper bounded at -35.90, which is higher than than -105.012. Thus we cannot exclude this prefix as being part of an optimal solution. As it turns out, there are high posterior solutions starting with this prefix. One such solution is shown in Table 3 below."}, {"heading": "6. Experiments", "text": "We provide a comparison of algorithms along three dimensions: solution quality (AUC - area under the ROC curve), sparsity, and scalability. Sparsity will be measured as the number of leaves in a decision tree or as the number of rules in a rule list. Scalability will be measured in computation time. SBRL tends to achieve a useful balance between these three quantities.\nLet us describe the experimental setup. As baselines, we chose popular classification algorithms to represent the sets of uninterpretable methods and the set of \u201cinterpretable\u201d methods. To represent the class of uninterpretable methods, we chose logistic regression, SVM RBF, random forests (RF), and boosted decision trees (ADA). None of these methods are designed to yield sparse classifiers. They are designed to yield scalable and accurate classifiers. To represent the class of \u201cinterpretable\u201d greedy splitting algorithms, we chose CART and C4.5. CART tends to yield sparse classifiers, whereas C4.5 tends to be much less interpretable. Other experiments (see Letham et al., 2015; Wang & Rudin, 2015b) have accuracy/interpretability comparisons to Bayesian Rule Lists and Falling Rule Lists, so our main effort here will be to add the scalability component. We benchmark using publicly available datasets after some data pre-processing(for example, using quantiles instead of real-valued variables and merging some discrete levels together to avoid too many levels in one column):\n\u2022 the Tic Tac Toe dataset (see Bache & Lichman, 2013), where the goal is to determine whether the \u201cX\u201d player wins (this is easy for a human who would check for three X\u2019s in a row),\n\u2022 the Adult dataset (see Bache & Lichman, 2013), where we aim to predict whether an individual makes over $50K in a year,\n\u2022 the mushroom dataset (see Bache & Lichman, 2013), where the goal is to predict whether a mushroom is poisonous,\n\u2022 the nursery dataset (see Bache & Lichman, 2013), where the goal is to predict whether a child\u2019s application to nursey school will be in either the \u201cvery recommended\u201d or \u201cspecial priority\u201d categories,\n\u2022 the Telco customer churn dataset (see WatsonAnalytics), where the goal is to predict whether a customer will leave the service provider,\n\u2022 the Titanic dataset (see Bache & Lichman, 2013), where the goal is to predict who survived the sinking of the Titanic.\nEvaluations of prediction quality, sparsity, and timing were done using 3-fold cross validation.\nFor creating the random starting rule list, the initial rule length was set to 1 rule (not including the default rule). The minimum and maximum rule size for the rule-mining algorithm were set at 1 and 2, respectively, except for the Tic Tac Toe dataset, for which the maximum was set to 3. Because of the nature of the Tic Tac Toe dataset, it is more interpretable to include rules of size 3 than to exclude them. For rule mining, we chose the\nminimum support of rules from (5%, 10%, 15%, etc.) so that the total number of rules was approximately 300.\nThe prior parameters were fixed at \u03b7 = 1, and \u03b1 = (1, 1). For the \u03bb for each dataset, we first let \u03bb be 5, and ran SBRL once with the above parameters. Then we fixed \u03bb at the length of the returned rule list for that dataset. It is possible that the solution quality would increase if SBRL was run for a larger number of iterations. For the purpose of providing a controlled experiment, the number of iterations was fixed at 5,000 for each chain of the 11 chains of SBRL, which we ran in series on a laptop. For some of the datasets, we ran SBRL for 50,000 iterations (rather than 5,000) to illustrate additional solutions. Every time SBRL started a new rule list, we checked the initial rule in the list to see whether the upper-bound on its posterior (by Theorem 2) was greater than the best rule list we have found so far. If not, the rule was replaced until the condition was satisfied.\nResults for the Tic Tac Toe dataset are shown in Figure 7, Figure 8 and Table 1. Each observation in this dataset is a tic tac toe board after the game has finished. If there are 3 X\u2019s in a row, the label of the board is 1, otherwise 0. This should not be a difficult learning problem since there are solutions with perfect accuracy on the training set that generalize to the test set. However, none of the other machine learning methods can find one of these perfect solutions. All of the other methods make heavy approximations, whether it is linear approximations (logistic regression, boosting), or greedy splitting (random forests, CART, C4.5); experiments on this dataset show that sometimes there are severe sacrifice made for those approximations, whether it is in terms of accuracy or in terms of sparsity. Figure 7 shows the sacrifice in AUC made by CART and C4.5. The other methods (RF, SVM, logistic regression, ADA) do not give sparse solutions. In this figure, the algorithms were all used in their default modes, using their own internal cross-validation routines.\nFigure 8 delves further on the decision tree and SBRL models to illustrate the AUC/sparsity tradeoff. It shows a scatter plot of AUC vs. number of leaves, where each point represents an evaluation of one algorithm, on one fold, with one parameter setting. For SBRL, there was no parameter tuning, so there are are three points, one for each of the three folds. We tried many different parameter settings for CART (in blue), and many different parameter settings for C4.5 (in gray), none of which were able to achieve points on the efficient frontier defined by the SBRL method.\nThis is an example where the SBRL model far surpasses its competitors. Tables 2, 3, and 4 show the models from the 3 BRL folds. SBRL\u2019s run time was on average around 0.6 seconds.\nFor the Adult dataset, results are in Figure 9, Figure 10 and Table 5. Adult contains 45,121 observations and 12 features, where each observation is an individual, and the features are census data, including demographics, income levels, and other financial infor-\nRule-list Antecedent risk Test\nAccuracy\nif ( x3&x7&x5 ), 0.98 1.00 else if ( x1&x9&x5 ), 0.98 1.00 else if ( x8&x2&x5 ), 0.98 1.00 else if ( x6&x3&x9 ), 0.98 1.00 else if ( x4&x6&x5 ), 0.98 1.00 else if ( x2&x1&x3 ), 0.98 1.00 else if ( x8&x7&x9 ), 0.98 1.00 else if ( x4&x1&x7 ), 0.98 1.00 else ( default ), 0.0044 1.00\nTable 2: Example of rule list for Tic Tac Toe dataset, fold 1 (CV1).\nRule-list Antecedent risk Test\nAccuracy\nif ( o9&o1&o5 ), 0.03 1.00 else if ( o7&o3&o5 ), 0.026 1.00 else if ( o6&o9&o3 ), 0.037 1.00 else if ( o8&o2&o5 ), 0.036 1.00 else if ( o4&o6&o5 ), 0.04 1.00 else if ( o8&o9&o7 ), 0.04 1.00 else if ( o2&o1&o3 ), 0.03 1.00 else if ( o4&o7&o1 ), 0.04 1.00 else ( default ), 0.97 0.98\nTable 3: Example of rule list for Tic Tac Toe dataset, fold 2 (CV2).\nmation. Here, SBRL, which was untuned and forced to be sparse, performed only slightly worse than several of the uninterpretable methods. Its AUC performance dominated those of the CART and C4.5 algorithms. As the scatter plot shows, even if CART were tuned on the test set, it would have performed at around the same level, perhaps slightly worse than SBRL. The timing for SBRL was competitive, at 41 to 44 seconds, where 35 seconds were\nMCMC iterations. If the chains were computed in parallel rather than in series, it would speed up computation further. Figure 2 contains one of the rule lists we produced.\nFor the mushroom dataset, results are shown in Figure 11, Figure 12 and Table 6. Perfect AUC scores were obtained using all the methods we tried, with the exception of untuned CART. On the scatterplot within Figure 12, there are several solutions with perfect accuracy found by SBRL, tuned CART and and C4.5, of sizes between 9 and 22 rules. SBRL found a solution of size 9 after 5,000 iterations. CART also found a solution of size 10 after tuning. One thing worth mentioning is that using the original dataset without any data preprocessing, SBRL found a solution of size 7 after 50000 iterations and CART found a solution of size 6. The difference in posterior values between the perfect solutions of similar size was extremely small because of our choice of (untuned) \u03bb. (Tuning and smaller choices for \u03bb would improve computation.) Figure 1 contains one of the rule lists we produced. The CART tree and rule lists produced for this dataset look entirely different. This is because SBRL views each categorical feature as a separate binary variable, whereas CART does not; it can split arbitrarily on categorical variables without penalty. If we had done additional preprocessing on the features to create more splits, we could potentially get rule lists that look like CART\u2019s tree. What we got were totally different, yet almost equally perfect, solutions.\nThe results from the nursery dataset are shown in Figure 13, Figure 14 and Table 7. A similar story holds as for the previous datasets: SBRL is on the optimal frontier of accuracy/sparsity without tuning and with reasonable run time.\nFigure 15, Figure 16 and Table 8 show the results for the Telco dataset, which contains 7043 observations and 18 features. Similar observations hold for this dataset. The models from the three folds are provided in Tables 9, 10 and 11. These models illustrate that generally, rule lists are not the same between folds, but often tend to use similar rules.\nThe Titanic dataset evaluation results are in Figures 17, 18 and Table 12, which contains data about 2201 passengers and crew aboard the Titanic.\nThe results on all of these datasets are consistent. On each dataset, SBRL produces results that are reliable (unlike CART) and sparse (unlike C4.5). SBRL was used untuned\nthroughout these experiments. The quality of predictions was between the interpretable methods the best-in-hindsight black-box methods, almost always outperforming the interpretable methods, and often outperforming some of the uninterpretable methods. The run times are longer but still reasonable, and also adjustable since the user can pre-determine exactly how long to run the method."}, {"heading": "7. Related Works and Discussion", "text": "Rule lists are not very different from decision trees in capacity; any decision tree can be made into a decision list simply by placing a rule in the list to represent each leaf of the decision tree. Rule lists are automatically a type of decision tree. Thus this method is really a direct competitor for CART.\nThe algorithm proposed here strikes a balance between accuracy, scalability, and interpretability. Interpretability has long since been a fundamental topic in artificial intelligence (see Ru\u0308ping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014). Because the rule lists created by our method are designed to be interpretable, one would probably not want to boost them, or combine them in other ways to form more complicated models. This contrasts with, for instance, Friedman and Popescu (2008), who linearly combine pre-mined rules.\nThis work enables us to globally control decision trees in a sense, which could lead to more interesting styles of trees, and different forms of interpretability. For example, one cannot easily construct a Falling Rule List with a greedy splitting method, but can construct one with a global optimization approach. A Falling Rule List Wang and Rudin (2015b) is a decision list where the probabilities of success decrease as we descend along the list. This means we can target the highest probability subgroup by checking only a few conditions. A Causal Falling Rule List (CFRL) Wang and Rudin (2015a) is another such example. These model causal effects (conditional differences) rather than outcomes. The first rule in the list pinpoints the subgroup with the largest treatment effect. It is possible that many other exotic types of constrained models could be constructed in a computationally efficient way using the ideas in this paper. One could go beyond logical models and consider also mixed logical/linear models (see Wang, Fujimaki, & Motohashi, 2015a).\nRule lists and their variants are currently being used for text processing (King, Lam, & Roberts, 2014), discovering treatment regimes (Zhang, Laber, Tsiatis, & Davidian, 2015), and creating medical risk assessments (Letham et al., 2015; Souillard-Mandar, Davis, Rudin, Au, Libon, Swenson, Price, Lamar, & Penney, 2015), among other applications.\nThere are other subfields where one would pre-mine rules and use them in a classifier. Inductive logic programming (Muggleton & De Raedt, 1994), greedy top-down decision list algorithms (Rivest, 1987; Sokolova, Marchand, Japkowicz, & Shawe-Taylor, 2003; Anthony, 2005; Marchand & Sokolova, 2005; Rudin, Letham, & Madigan, 2013; Goessling & Kang, 2015), associative classification (Vanhoof & Depaire, 2010; Liu, Hsu, & Ma, 1998; Li, Han, & Pei, 2001; Yin & Han, 2003) and its Bayesian counterparts (McCormick, Rudin, & Madigan, 2012) all fall into this category. None of the methods in these fields follow the same general procedure as we do, where rules are fully optimized into an optimal tree using low-level\ncomputations, and where rules are eliminated based on theoretical motivation, as we have in Sections 5.\nTeleo-reactive programs (Nilsson, 1994) use a decision list structure and could benefit from learning this structure from data.\nThere are a series of works from the mid-1990\u2019s on finding optimal decision trees using dynamic programming and search techniques (e.g., Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the Na\u0308\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers. Nijssen and Fromont (2010) has the user pre-mine all possible leaves, enumerating all conditions leading to that leaf. (By contrast, in our work and in associative classification, we mine only small conjunctions, and their ordered combination creates leaves.) Nijssen and Fromont (2010) warn about issues related to running out of memory. As a possible extension, the work proposed here could be modified to handle regularized empirical risk minimization, in particular it could use the objective of Rudin and Ertekin (2015), which is a balance between accuracy and sparsity of rule lists. It could also be modified to handle disjunctive normal form classifiers, for which there are now Bayesian models analogous to the ones studied in this work (Wang, Rudin, Doshi, Liu, Klampfl, & MacNeille, 2015b). Bayesian tree models may also be able to be constructed using our setup, where one would mine rules and create a globally optimal tree (Dension, Mallick, & Smith, 1998; Chipman, George, & McCulloch, 2002, 2010). It may be logistically more difficult to code trees than lists in order to take advantage of the fast lower level computations, but this is worth further investigation.\nA theoretical result of Rudin et al. (2013) states that the VC (Vapnik-Chervonenkis) dimension of the set of rule lists created using pre-mined rules is exactly the size of the set of pre-mined rules. This provides a connection to linear models, whose complexity is the number of features plus 1. That is, the VC dimension of rule lists created from |A| predefined rules is essentially the same as that of linear models with |A| features. If some rules are eliminated (for instance based on the theorems in Section 5) then the VC dimension is the size of the set of rules that remain.\nConclusion\nWe finish by stating why/when one would want to use this particular method. SBRL is not meant as a competitor for black box classifiers like neural networks, support vector machines, gradient boosting or random forests. It is useful when machine learning tools are used as a decision aid to humans, who need to understand the model in order to trust it and make data-driven decisions. SBRL is not a greedy splitting/pruning procedure like decision tree algorithms (CART, C4.5), which means that it more reliably computes high quality solutions, at the possible expense of additional computation time. Many of the decision tree methods do not compute sparse trees, and do not provide interpretable models, as we\nhave seen with C4.5. Our code is a strict improvement over the original Bayesian Rule Lists algorithm if one is looking for a maximum a posteriori solution. It is faster because of careful use of low level computations and theoretical bounds."}, {"heading": "Acknowledgments", "text": "The authors would like to acknowledge partial funding provided by Philips, Wistron, and Siemens.\nCode\nCode for SBRL is available at the following link: https://github.com/Hongyuy/sbrlmod"}, {"heading": "Appendix: Proof of Theorem 1", "text": "To prove this, we will show that any rule list with more than mmax rules has a lower posterior than the trivial empty rule list. This means any rule list with more than mmax terms cannot be a MAP rule list. Denote \u03c6 as the trivial rule list with only the default rule. By definition\nof d\u2217 as a MAP rule list, it has a posterior at least as high as \u03c6.\nPosterior(d\u2217|A, X, Y, \u03b1, \u03bb, \u03b7) \u2265 Posterior(\u03c6|A, X, Y, \u03b1, \u03bb, \u03b7)\n(\u03bbm \u2217 /m\u2217!) |A|\u2211 j=0 (\u03bbj/j!)\nm\u2217\u220f j=0  (\u03b7cj/cj !)\u2211 k\u2208Rj\u22121(c<j ,A) (\u03b7k/k!) 1 |Qcj | \u0393(Nj,0 + \u03b10)\u0393(Nj,1 + \u03b11) \u0393(Nj,0 +Nj,1 + \u03b10 + \u03b11)  \u2265 \u03bb\n0/0! |A|\u2211 j=0 (\u03bbj/j!) \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11) \u0393(N + \u03b10 + \u03b11)\n\u03bbm \u2217\nm\u2217! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2217\u220f j=0\n \u2211 k\u2208Rj\u22121(c<j ,A) (\u03b7k/k!)\n(\u03b7cj/cj !) |Qcj |  m\u2217\u220f j=1 \u0393(Nj,0 +Nj,1 + \u03b10 + \u03b11) \u0393(Nj,0 + \u03b10)\u0393(Nj,1 + \u03b11)\n\u03bbm \u2217\nm\u2217! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2217\u220f j=1 (1\u00d7 |Qcj |) m\u2217\u220f j=1 1\n\u03bbm \u2217\nm\u2217! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2217\u220f j=1 |Qcj |.\nBy construction we have m\u2217\u220f j=1 |Qcj | \u2265 m\u2217\u220f j=1 bj , thus\n\u03bbm \u2217\nm\u2217! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2217\u220f j=1 bj .\nWe need only the first m terms of the bj \u2019s, the rest are not needed. Note that the left hand side decreases rapidly after m exceeds \u03bb. In addition to this inequality, there is an additional (trivial) upper limit for m, namely the value 2P \u2212 1, which corresponds to a rule list that includes all of the possible rules. So the length of the optimal rule list should satisfy the following upper bound:\nm\u2217 \u2264 mmax = min 2P \u2212 1,max m\u2032 \u2208 Z+ : \u03bbm \u2032 m\u2032! \u2265 \u0393(N\u2212 + \u03b10)\u0393(N+ + \u03b11)\n\u0393(N + \u03b10 + \u03b11)\nm\u2032\u220f j=1 bj   ."}, {"heading": "Appendix A. Appendix: Proof of Theorem 2", "text": "For rule list d = {dp, ap+1, ap+2, ..., am, a0}, consider the set of data points captured by rule j, Saj := {i : Captr(i) = j}. Again recall the definition of Nj,0 as the number of points captured by rule j with label 0, and Nj,1 as the number of points captured by rule j with label 1,\nNj,0 = |{i : Captr(i) = j and yi = 0}|, Nj,1 = |{i : Captr(i) = j and yi = 1}|.\nDefinition 2 For rule j, if either Nj,0 or Nj,1 equals zero, rule j is called a perfect rule with respect to d.\nA perfect rule correctly classifies all observations it captures.\nLemma 1 For rule list\nd = dp, ap+1, ap+2, ..., aj , ..., am, a0\nwhere aj is not a perfect rule, consider a hypothetical rule list\ndbetter = dp, ap+1, ap+2, ..., a j+ , aj \u2212 , ..., am, a0\nwhere aj + and aj \u2212\nare perfect rules with label 1\u2019s and 0\u2019s, respectively, that capture the same observations as rule j, so that Nj+,1 = Nj,1, Nj+,0 = 0, and Nj\u2212,1 = 0, Nj\u2212,0 = Nj,0. Then, for parameters \u03b10 = 1 and \u03b11 = 1,\nLikelihood(d, {(xi, yi)}ni=1) < Likelihood(dbetter, {(xi, yi)}ni=1).\n(Note that aj + and aj \u2212\nmay not exist in practice, but we create them in theory for the purposes of this proof.)\nIntuitively, Lemma 1 states that if rule j is not a perfect rule with respect to d, meaning Nj,0 \u2265 1 and Nj,1 \u2265 1, then replacing rule j with two perfect rules that capture the same data points would improve the likelihood.\nProof 1 We compare the likelihood ratio of the rule lists before and after splitting rule j into two perfect rules. Splitting the rule will not affect the data points captured by other rules. The likelihood of a rule list is a product of likelihoods for individual rules. Thus,\nLikelihood(dbetter, {(xi, yi)}ni=1) Likelihood(d, {(xi, yi)}ni=1)\n=\n\u0393(N0+1)\u0393(1) \u0393(N0+2) \u0393(1)\u0393(N1+1) \u0393(N1+2)\n\u0393(N0+1)\u0393(N1+1) \u0393(N0+N1+2)\n= (N0 +N1 + 1)!\n(N0 + 1)!(N1 + 1)! (eliminated common factors)\n=\n( N0+N1+1 N0+1 ) N1 + 1 ( using identity ( n k ) =\nn!\nk!(n\u2212 k)! ) = (N0+(N1\u22121)+1 N0+1 ) + ( N0+N1 N0 ) N1 + 1 ( using identity ( n k ) = ( n\u2212 1 k ) + ( n\u2212 1 k \u2212 1\n)) = (N0+(N1\u22121)+1 N0+1 ) + ( N0+N1 N1 ) N1 + 1 ( using identity ( n k ) = ( n n\u2212 k\n)) \u2265 ( N0+1 N0+1 ) + ( 1+N1 N1 ) N1 + 1 (because N0, N1 \u2265 1) = N1 + 2\nN1 + 1 > 1.\nLet us discuss the next result, Lemma 2. If j and k, where j \u2264 k are both perfect rules in d and capture data points with only label l\u2019s (where l is either 0 or 1), then replacing aj , ak with a single perfect rule akj that captures the same data points will improve the likelihood probability. Formally,\nLemma 2 For rule list\nd = dp, ap+1, ap+2, ..., ak, ..., aj , ...am, a0 (6)\nwhere k and j are both perfect rules and have the same label l, consider a hypothetical rule list\ndconsolidated = dp, ap+1, ap+2, ..., akj , ...am, a0 (7)\nwhere kj is a perfect rule that captures all the data points captured by k and j. Then\nLikelihood(d, {(xi, yi)}ni=1) < Likelihood(dconsolidated, {(xi, yi)}ni=1). (8)\nProof 2 :\nLikelihood(dconsolidated, {(xi, yi)}ni=1) Likelihood(d, {(xi, yi)}ni=1)\n=\n\u0393(Nj,l+Nk,l+\u03b1l)\u0393(\u03b1l) \u0393(Nj,l+Nk,l+2\u03b1l)\n\u0393(Nj,l+\u03b1l)\u0393(\u03b1l) \u0393(Nj,l+2\u03b1l) \u0393(Nk,l+\u03b1l)\u0393(\u03b1l) \u0393(Nk,l+2\u03b1l)\n(by definition)\n= 1\n\u0393(\u03b1l)\n(Nj,l + \u03b1l)(Nk,l + \u03b1l)\n(Nj,l +Nk,l + \u03b1l)\n(Nj,l + \u03b1l + 1)(Nk,l + \u03b1l + 1)\n(Nj,l +Nk,l + \u03b1l + 1) \u00b7 \u00b7 \u00b7 (Nj,l + 2\u03b1l \u2212 1)(Nk,l + 2\u03b1l \u2212 1) (Nj,l +Nk,l + 2\u03b1l \u2212 1)\n= 1\n\u0393(\u03b1l)\n[ Nj,lNk,l + \u03b1lNj,l + \u03b1lNk,l + \u03b1 2 l\nNj,l +Nk,l + \u03b1l\n] \u00b7 \u00b7 \u00b7 [ Nj,lNk,l + (2\u03b1l \u2212 1)Nj,l + (2\u03b1l \u2212 1)Nk,l + (2\u03b1l \u2212 1)2\nNj,l +Nk,l + (2\u03b1l \u2212 1) ] = 1\n\u0393(\u03b1l)\n[ \u03b1l +\nNj,lNk,l Nj,l +Nk,l + \u03b1l\n] \u00b7 \u00b7 \u00b7 [ 2\u03b1l \u2212 1 +\nNj,lNk,l Nj,l +Nk,l + (2\u03b1l \u2212 1) ] > 1\n\u0393(\u03b1l) [\u03b1l] [\u03b1l + 1] [\u03b1l + 2] \u00b7 \u00b7 \u00b7 [2\u03b1l \u2212 1]\n= \u03b1l 1 \u03b1l + 1 2 \u03b1l + 2 3 \u00b7 \u00b7 \u00b7 \u03b1l + 2\u03b1l \u2212 1\n\u03b1l \u2265 1.\nProof 3 (Of Theorem 2) Combining Lemma 1 and Lemma 2, we can get an upper bound for the posterior of rule list d in terms of the first few rules in the list. Lemma 1 tells us to separate each rule hypothetically into two perfect rules. Lemma 2 tells us to combine all perfect rules from the same class into a single rule. After doing this, there are only two rules left, a perfect rule for class label 0 and a perfect rule for class label 1. We conclude that the likelihood of the rule list d = {dp, ap+1, ap+2, ..., am, a0} is at most the likelihood of the rule list\ndhypothetical = {dp, ap0 , ap1 , a0},\nwhere p0 is an imaginary perfect rule in d hypothetical capturing all remaining data points with label 0\u2019s and p1 is an imaginary perfect rule in d hypothetical capturing all remaining data points with label 1\u2019s. That is:\nLikelihood(d, {(xi, yi)}ni=1)) \u2264 Likelihood(dhypothetical, {(xi, yi)}ni=1)).\nWe compress notation slightly to remove explicit dependence on the data, so we write Likelihood(d) = Likelihood(d, {(xi, yi)}ni=1). Also note that the likelihood of the list can be decoupled into terms for each rule,\nLikelihood(d) = m\u220f j=1 \u0393(Nj,0 + \u03b10)\u0393(Nj,1 + \u03b11) Nj,0 +Nj,1 + \u03b10 + \u03b11 = m\u220f j=1 Likelihood(rule j),\nwhich means that the likelihood for rule list dhypothetical can be split into likelihood for the first p rules and likelihood for the other rules.\nLikelihood(dhypothetical, {(xi, yi)}ni=1) = Likelihood(dp, data captured by rules in dp)\u00d7 Likelihood(ap0 , data captured by ap0)\u00d7 Likelihood(ap1 , data captured by ap1)\u00d7 Likelihood(a0,no data).\nNext we show Posterior(d) \u2264 Posterior(dhypothetical) \u2264 \u03a5(dp, {(xi, yi)}ni=1). We compute:\nPosterior(d) = Prior(d)\u00d7 Likelihood(d) \u2264 Prior(d)\u00d7 Likelihood(dhypothetical) = Prior(number of rules in d)\u00d7 Prior(size of rules in d)\u00d7 Likelihood(dhypothetical) = Prior(m|\u03bb)\u00d7 Prior(size of rules in dp)\u00d7 Prior(size of rules in d\\dp)\u00d7\nLikelihood(dp)\u00d7 Likelihood(ap0)\u00d7 Likelihood(ap1)\u00d7 Likelihood(a0). (9)\nLet us handle each term of the expression above, starting with the term for the number of rules. The largest value of the prior occurs at the maximum of the Poisson distribution centered at \u03bb. That would happen if there were \u03bb total rules. This could happen if p \u2264 \u03bb. If p > \u03bb, then we cannot have a rule list of size \u03bb since we already have too many rules. In that case, we should not add more rules, and the maximum prior occurs when the size of the rule list is p. That is,\nPrior(m|\u03bb) \u2264 \u03bb max (p,\u03bb)/(max (p, \u03bb))!\u2211|A|\nj=0(\u03bb j/j!)\n.\nThe second term in (9) is an equality,\nPrior(size of rules in dp) =  p\u220f j=1 p(cj |c<j ,A, \u03b7) 1 |Qcj |  . The third term in (9) is trivially bounded by 1. The fourth term Likelihood(dp) can be calculated from the data as usual, simplifying with \u03b10 = \u03b11 = 1:\nLikelihood(dp) = p\u220f j=1 \u0393(Nj,0 + \u03b10)\u0393(Nj,1 + \u03b11) \u0393(Nj,0 +Nj,1 + \u03b10 + \u03b11) = p\u220f j=1 \u0393(Nj,0 + 1)\u0393(Nj,1 + 1) \u0393(Nj,0 +Nj,1 + 2)\nFor the terms for hypothetical rules ap0 and ap,1 we compute them as if those rules were real rules:\nLikelihood(ap,0) = \u0393(1 +N0 \u2212\n\u2211p j=1Nj,0)\n\u0393(2 +N0 \u2212 \u2211p j=1Nj,0)\nLikelihood(ap,1) = \u0393(1 +N1 \u2212\n\u2211p j=1Nj,1)\n\u0393(2 +N1 \u2212 \u2211p j=1Nj,1) .\nThe last term of (9) will be trivially upper bounded by 1. Multiplying all of these terms together to form an upper bound, we have precisely the definition of \u03a5(dp, {(xi, yi)}ni=1). Thus,\nPosterior(d) \u2264 \u03a5(dp, {(xi, yi)}ni=1).\nBy the assumption of Theorem 2, we know that for our rule list d,\nPosterior(d) \u2264 \u03a5(dp) < v\u2217t = max t\u2032\u2264t Posterior(dt \u2032 , {(xi, yi)}ni=1) \u2264 max d\u2032 Posterior(d\u2032),\nand more simply stated,\nPosterior(d) < max d\u2032\nPosterior(d\u2032).\nThus, there is no possible way that our current rule list d could be within argmaxd\u2032Posterior(d \u2032)."}], "references": [{"title": "Decision lists", "author": ["M. Anthony"], "venue": "Tech. rep., CDAM Research Report LSE-CDAM-2005-", "citeRegEx": "Anthony,? 2005", "shortCiteRegEx": "Anthony", "year": 2005}, {"title": "Theory and applications of agnostic pac-learning with small decision trees", "author": ["P. Auer", "R.C. Holte", "W. Maass"], "venue": null, "citeRegEx": "Auer et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Auer et al\\.", "year": 1995}, {"title": "UCI machine learning repository", "author": ["K. Bache", "M. Lichman"], "venue": null, "citeRegEx": "Bache and Lichman,? \\Q2013\\E", "shortCiteRegEx": "Bache and Lichman", "year": 2013}, {"title": "Optimal decision trees", "author": ["K.P. Bennett", "J.A. Blue"], "venue": "Tech. rep., R.P.I. Math Report No. 214,", "citeRegEx": "Bennett and Blue,? \\Q1996\\E", "shortCiteRegEx": "Bennett and Blue", "year": 1996}, {"title": "Machine learning: between accuracy and interpretability", "author": ["I. Bratko"], "venue": "Della Riccia, G., Lenz, H.-J., & Kruse, R. (Eds.), Learning, Networks and Statistics, Vol. 382 of International Centre for Mechanical Sciences, pp. 163\u2013177. Springer Vienna.", "citeRegEx": "Bratko,? 1997", "shortCiteRegEx": "Bratko", "year": 1997}, {"title": "Bayesian treed models", "author": ["H.A. Chipman", "E.I. George", "R.E. McCulloch"], "venue": "Machine Learning,", "citeRegEx": "Chipman et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Chipman et al\\.", "year": 2002}, {"title": "BART: Bayesian additive regression trees", "author": ["H.A. Chipman", "E.I. George", "R.E. McCulloch"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "Chipman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chipman et al\\.", "year": 2010}, {"title": "The robust beauty of improper linear models in decision making", "author": ["R.M. Dawes"], "venue": "American Psychologist, 34 (7), 571\u2013582.", "citeRegEx": "Dawes,? 1979", "shortCiteRegEx": "Dawes", "year": 1979}, {"title": "Induction of shallow decision trees", "author": ["D. Dobkin", "T. Fulton", "D. Gunopulos", "S. Kasif", "S. Salzberg"], "venue": null, "citeRegEx": "Dobkin et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Dobkin et al\\.", "year": 1996}, {"title": "A fast way to produce optimal fixeddepth decision trees", "author": ["A. Farhangfar", "R. Greiner", "M. Zinkevich"], "venue": "In International Symposium on Artificial Intelligence and Mathematics (ISAIM", "citeRegEx": "Farhangfar et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Farhangfar et al\\.", "year": 2008}, {"title": "Comprehensible classification models: a position paper", "author": ["A.A. Freitas"], "venue": "ACM SIGKDD Explorations Newsletter, 15 (1), 1\u201310.", "citeRegEx": "Freitas,? 2014", "shortCiteRegEx": "Freitas", "year": 2014}, {"title": "Predictive learning via rule ensembles", "author": ["J.H. Friedman", "B.E. Popescu"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "Friedman and Popescu,? \\Q2008\\E", "shortCiteRegEx": "Friedman and Popescu", "year": 2008}, {"title": "Beyond predictive accuracy: what", "author": ["C. Giraud-Carrier"], "venue": "Proceedings of the ECML98 Workshop on Upgrading Learning to Meta-Level: Model Selection and Data Transformation, pp. 78\u201385.", "citeRegEx": "Giraud.Carrier,? 1998", "shortCiteRegEx": "Giraud.Carrier", "year": 1998}, {"title": "Directional decision lists. ArXiv e-prints 1508.07643", "author": ["M. Goessling", "S. Kang"], "venue": null, "citeRegEx": "Goessling and Kang,? \\Q2015\\E", "shortCiteRegEx": "Goessling and Kang", "year": 2015}, {"title": "Very simple classification rules perform well on most commonly used datasets", "author": ["R.C. Holte"], "venue": "Machine Learning, 11 (1), 63\u201391.", "citeRegEx": "Holte,? 1993", "shortCiteRegEx": "Holte", "year": 1993}, {"title": "An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models", "author": ["J. Huysmans", "K. Dejaeger", "C. Mues", "J. Vanthienen", "B. Baesens"], "venue": "Decision Support Systems,", "citeRegEx": "Huysmans et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Huysmans et al\\.", "year": 2011}, {"title": "Computer-assisted keyword and document set discovery from unstructured text", "author": ["G. King", "P. Lam", "M. Roberts"], "venue": null, "citeRegEx": "King et al\\.,? \\Q2014\\E", "shortCiteRegEx": "King et al\\.", "year": 2014}, {"title": "Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model", "author": ["B. Letham", "C. Rudin", "T.H. McCormick", "D. Madigan"], "venue": "Annals of Applied Statistics,", "citeRegEx": "Letham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Letham et al\\.", "year": 2015}, {"title": "CMAR: accurate and efficient classification based on multiple class-association rules", "author": ["W. Li", "J. Han", "J. Pei"], "venue": "In IEEE International Conference on Data Mining,", "citeRegEx": "Li et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Li et al\\.", "year": 2001}, {"title": "Integrating classification and association rule mining", "author": ["B. Liu", "W. Hsu", "Y. Ma"], "venue": "In Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Liu et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Liu et al\\.", "year": 1998}, {"title": "Learning with decision lists of data-dependent features", "author": ["M. Marchand", "M. Sokolova"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Marchand and Sokolova,? \\Q2005\\E", "shortCiteRegEx": "Marchand and Sokolova", "year": 2005}, {"title": "Bayesian hierarchical rule modeling for predicting medical conditions", "author": ["T.H. McCormick", "C. Rudin", "D. Madigan"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "McCormick et al\\.,? \\Q2012\\E", "shortCiteRegEx": "McCormick et al\\.", "year": 2012}, {"title": "Inductive logic programming: Theory and methods", "author": ["S. Muggleton", "L. De Raedt"], "venue": "The Journal of Logic Programming,", "citeRegEx": "Muggleton and Raedt,? \\Q1994\\E", "shortCiteRegEx": "Muggleton and Raedt", "year": 1994}, {"title": "Optimal constraint-based decision tree induction from itemset lattices", "author": ["S. Nijssen", "E. Fromont"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "Nijssen and Fromont,? \\Q2010\\E", "shortCiteRegEx": "Nijssen and Fromont", "year": 2010}, {"title": "Teleo-reactive programs for agent control", "author": ["N.J. Nilsson"], "venue": "Journal of Artificial Intelligence Research, 1, 139\u2013158.", "citeRegEx": "Nilsson,? 1994", "shortCiteRegEx": "Nilsson", "year": 1994}, {"title": "Learning decision lists", "author": ["R.L. Rivest"], "venue": "Machine Learning, 2 (3), 229\u2013246.", "citeRegEx": "Rivest,? 1987", "shortCiteRegEx": "Rivest", "year": 1987}, {"title": "Learning optimized lists of classification rules", "author": ["C. Rudin", "S. Ertekin"], "venue": null, "citeRegEx": "Rudin and Ertekin,? \\Q2015\\E", "shortCiteRegEx": "Rudin and Ertekin", "year": 2015}, {"title": "Learning theory analysis for association rules and sequential event prediction", "author": ["C. Rudin", "B. Letham", "D. Madigan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Rudin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rudin et al\\.", "year": 2013}, {"title": "Learning interpretable models", "author": ["S. R\u00fcping"], "venue": "Ph.D. thesis, Universit\u00e4t Dortmund.", "citeRegEx": "R\u00fcping,? 2006", "shortCiteRegEx": "R\u00fcping", "year": 2006}, {"title": "To explain or to predict", "author": ["G. Shmueli"], "venue": "Statistical Science, 25 (3), 289\u2013310.", "citeRegEx": "Shmueli,? 2010", "shortCiteRegEx": "Shmueli", "year": 2010}, {"title": "The decision list machine", "author": ["M. Sokolova", "M. Marchand", "N. Japkowicz", "J. Shawe-Taylor"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sokolova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Sokolova et al\\.", "year": 2003}, {"title": "Learning classification models of cognitive conditions from subtle behaviors in the digital clock drawing test. Machine Learning, First Online, 1\u201349", "author": ["W. Souillard-Mandar", "R. Davis", "C. Rudin", "R. Au", "D.J. Libon", "R. Swenson", "C.C. Price", "M. Lamar", "D.L. Penney"], "venue": null, "citeRegEx": "Souillard.Mandar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Souillard.Mandar et al\\.", "year": 2015}, {"title": "Structure of association rule classifiers: a review", "author": ["K. Vanhoof", "B. Depaire"], "venue": "In Proceedings of the International Conference on Intelligent Systems and Knowledge Engineering,", "citeRegEx": "Vanhoof and Depaire,? \\Q2010\\E", "shortCiteRegEx": "Vanhoof and Depaire", "year": 2010}, {"title": "Making machine learning models interpretable", "author": ["A. Vellido", "J.D. Mart\u0301\u0131n-Guerrero", "P.J. Lisboa"], "venue": "In Proceedings of the European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning", "citeRegEx": "Vellido et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Vellido et al\\.", "year": 2012}, {"title": "Causal falling rule lists", "author": ["F. Wang", "C. Rudin"], "venue": null, "citeRegEx": "Wang and Rudin,? \\Q2015\\E", "shortCiteRegEx": "Wang and Rudin", "year": 2015}, {"title": "Falling rule lists", "author": ["F. Wang", "C. Rudin"], "venue": "In Proceedings of Artificial Intelligence and Statistics (AISTATS)", "citeRegEx": "Wang and Rudin,? \\Q2015\\E", "shortCiteRegEx": "Wang and Rudin", "year": 2015}, {"title": "Trading interpretability for accuracy: Oblique treed sparse additive models", "author": ["J. Wang", "R. Fujimaki", "Y. Motohashi"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Bayesian or\u2019s of and\u2019s for interpretable classification with application to context aware recommender systems", "author": ["T. Wang", "C. Rudin", "F. Doshi", "Y. Liu", "E. Klampfl", "P. MacNeille"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Cpar: classification based on predictive association rules", "author": ["X. Yin", "J. Han"], "venue": "In Proceedings of the 2003 SIAM International Conference on Data Mining,", "citeRegEx": "Yin and Han,? \\Q2003\\E", "shortCiteRegEx": "Yin and Han", "year": 2003}, {"title": "Using decision lists to construct interpretable and parsimonious treatment", "author": ["Y. Zhang", "E. Laber", "A. Tsiatis", "M. Davidian"], "venue": "regimes. ArXiv e-prints,", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 17, "context": "(i) A principled objective, which is the posterior distribution for the Bayesian Rule List (BRL) model of Letham et al.\u2019s (2015). We optimize this objective over rule lists.", "startOffset": 106, "endOffset": 129}, {"referenceID": 17, "context": "Previous Work: Review of Bayesian Rule Lists of Letham et al. (2015) Scalable Rule Lists uses the posterior distribution of the Bayesian Rule Lists algorithm.", "startOffset": 48, "endOffset": 69}, {"referenceID": 4, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 7, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 12, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 14, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 29, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 10, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014).", "startOffset": 84, "endOffset": 292}, {"referenceID": 17, "context": "Rule lists and their variants are currently being used for text processing (King, Lam, & Roberts, 2014), discovering treatment regimes (Zhang, Laber, Tsiatis, & Davidian, 2015), and creating medical risk assessments (Letham et al., 2015; Souillard-Mandar, Davis, Rudin, Au, Libon, Swenson, Price, Lamar, & Penney, 2015), among other applications.", "startOffset": 216, "endOffset": 319}, {"referenceID": 25, "context": "Inductive logic programming (Muggleton & De Raedt, 1994), greedy top-down decision list algorithms (Rivest, 1987; Sokolova, Marchand, Japkowicz, & Shawe-Taylor, 2003; Anthony, 2005; Marchand & Sokolova, 2005; Rudin, Letham, & Madigan, 2013; Goessling & Kang, 2015), associative classification (Vanhoof & Depaire, 2010; Liu, Hsu, & Ma, 1998; Li, Han, & Pei, 2001; Yin & Han, 2003) and its Bayesian counterparts (McCormick, Rudin, & Madigan, 2012) all fall into this category.", "startOffset": 99, "endOffset": 264}, {"referenceID": 0, "context": "Inductive logic programming (Muggleton & De Raedt, 1994), greedy top-down decision list algorithms (Rivest, 1987; Sokolova, Marchand, Japkowicz, & Shawe-Taylor, 2003; Anthony, 2005; Marchand & Sokolova, 2005; Rudin, Letham, & Madigan, 2013; Goessling & Kang, 2015), associative classification (Vanhoof & Depaire, 2010; Liu, Hsu, & Ma, 1998; Li, Han, & Pei, 2001; Yin & Han, 2003) and its Bayesian counterparts (McCormick, Rudin, & Madigan, 2012) all fall into this category.", "startOffset": 99, "endOffset": 264}, {"referenceID": 3, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014). Because the rule lists created by our method are designed to be interpretable, one would probably not want to boost them, or combine them in other ways to form more complicated models. This contrasts with, for instance, Friedman and Popescu (2008), who linearly combine pre-mined rules.", "startOffset": 103, "endOffset": 542}, {"referenceID": 3, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014). Because the rule lists created by our method are designed to be interpretable, one would probably not want to boost them, or combine them in other ways to form more complicated models. This contrasts with, for instance, Friedman and Popescu (2008), who linearly combine pre-mined rules. This work enables us to globally control decision trees in a sense, which could lead to more interesting styles of trees, and different forms of interpretability. For example, one cannot easily construct a Falling Rule List with a greedy splitting method, but can construct one with a global optimization approach. A Falling Rule List Wang and Rudin (2015b) is a decision list where the probabilities of success decrease as we descend along the list.", "startOffset": 103, "endOffset": 939}, {"referenceID": 3, "context": "Interpretability has long since been a fundamental topic in artificial intelligence (see R\u00fcping, 2006; Bratko, 1997; Dawes, 1979; Vellido, Mart\u0301\u0131n-Guerrero, & Lisboa, 2012; Giraud-Carrier, 1998; Holte, 1993; Shmueli, 2010; Huysmans, Dejaeger, Mues, Vanthienen, & Baesens, 2011; Freitas, 2014). Because the rule lists created by our method are designed to be interpretable, one would probably not want to boost them, or combine them in other ways to form more complicated models. This contrasts with, for instance, Friedman and Popescu (2008), who linearly combine pre-mined rules. This work enables us to globally control decision trees in a sense, which could lead to more interesting styles of trees, and different forms of interpretability. For example, one cannot easily construct a Falling Rule List with a greedy splitting method, but can construct one with a global optimization approach. A Falling Rule List Wang and Rudin (2015b) is a decision list where the probabilities of success decrease as we descend along the list. This means we can target the highest probability subgroup by checking only a few conditions. A Causal Falling Rule List (CFRL) Wang and Rudin (2015a) is another such example.", "startOffset": 103, "endOffset": 1182}, {"referenceID": 24, "context": "Teleo-reactive programs (Nilsson, 1994) use a decision list structure and could benefit from learning this structure from data.", "startOffset": 24, "endOffset": 39}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree.", "startOffset": 30, "endOffset": 276}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers.", "startOffset": 30, "endOffset": 593}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers. Nijssen and Fromont (2010) has the user pre-mine all possible leaves, enumerating all conditions leading to that leaf.", "startOffset": 30, "endOffset": 736}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers. Nijssen and Fromont (2010) has the user pre-mine all possible leaves, enumerating all conditions leading to that leaf. (By contrast, in our work and in associative classification, we mine only small conjunctions, and their ordered combination creates leaves.) Nijssen and Fromont (2010) warn about issues related to running out of memory.", "startOffset": 30, "endOffset": 996}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers. Nijssen and Fromont (2010) has the user pre-mine all possible leaves, enumerating all conditions leading to that leaf. (By contrast, in our work and in associative classification, we mine only small conjunctions, and their ordered combination creates leaves.) Nijssen and Fromont (2010) warn about issues related to running out of memory. As a possible extension, the work proposed here could be modified to handle regularized empirical risk minimization, in particular it could use the objective of Rudin and Ertekin (2015), which is a balance between accuracy and sparsity of rule lists.", "startOffset": 30, "endOffset": 1234}, {"referenceID": 14, "context": ", Bennett & Blue, 1996; Auer, Holte, & Maass, 1995; Dobkin, Fulton, Gunopulos, Kasif, & Salzberg, 1996), mainly working with only fixed depth trees. None of these works use the systems level techniques we use to speed up computation. Farhangfar, Greiner, and Zinkevich (2008) use a screening step that reduces the number of features, using the N\u00e4\u0131ve Bayes assumption that the features are independent, given the class, and then uses dynamic programming to construct an optimal fixed-depth tree. One particularly interesting work following this literature is that of Nijssen and Fromont (2010), which allows for pre-mined rules to form trees, but in a different way than our method or associative classifiers. Nijssen and Fromont (2010) has the user pre-mine all possible leaves, enumerating all conditions leading to that leaf. (By contrast, in our work and in associative classification, we mine only small conjunctions, and their ordered combination creates leaves.) Nijssen and Fromont (2010) warn about issues related to running out of memory. As a possible extension, the work proposed here could be modified to handle regularized empirical risk minimization, in particular it could use the objective of Rudin and Ertekin (2015), which is a balance between accuracy and sparsity of rule lists. It could also be modified to handle disjunctive normal form classifiers, for which there are now Bayesian models analogous to the ones studied in this work (Wang, Rudin, Doshi, Liu, Klampfl, & MacNeille, 2015b). Bayesian tree models may also be able to be constructed using our setup, where one would mine rules and create a globally optimal tree (Dension, Mallick, & Smith, 1998; Chipman, George, & McCulloch, 2002, 2010). It may be logistically more difficult to code trees than lists in order to take advantage of the fast lower level computations, but this is worth further investigation. A theoretical result of Rudin et al. (2013) states that the VC (Vapnik-Chervonenkis) dimension of the set of rule lists created using pre-mined rules is exactly the size of the set of pre-mined rules.", "startOffset": 30, "endOffset": 1936}], "year": 2017, "abstractText": "We present an algorithm for building rule lists that is two orders of magnitude faster than previous work. Rule list algorithms are competitors for decision tree algorithms. They are associative classifiers, in that they are built from pre-mined association rules. They have a logical structure that is a sequence of IF-THEN rules, identical to a decision list or one-sided decision tree. Instead of using greedy splitting and pruning like decision tree algorithms, we fully optimize over rule lists, striking a practical balance between accuracy, interpretability, and computational speed. The algorithm presented here uses a mixture of theoretical bounds (tight enough to have practical implications as a screening or bounding procedure), computational reuse, and highly tuned language libraries to achieve computational efficiency. Currently, for many practical problems, this method achieves better accuracy and sparsity than decision trees; further, in many cases, the computational time is practical and often less than that of decision trees.", "creator": "LaTeX with hyperref package"}}}