{"id": "1602.09076", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Feb-2016", "title": "Personalized and situation-aware multimodal route recommendations: the FAVOUR algorithm", "abstract": "route choice in multimodal trunk networks shows a considerable variation between different individuals as well as the current situational event context. personalization of recommendation algorithms are somewhat already common in many areas, e. g., online retail. however, most online routing applications still provide shortest distance or shortest travel - time using routes only, neglecting individual preferences as well effectively as the current situation. both cognitive aspects significantly are of really particular importance in a multimodal setting as attractivity of some transportation modes such as biking crucially depends on personal characteristics and not exogenous factors like the weather. ^ this 2015 paper introduces the favourite route recommendation ( favour ) approach to provide personalized, situation - aware route proposals based commercially on three steps : first, at the initialization stage, being the leading user provides limited information ( home location, work place, mobility options, sociodemographics ) used to visually select one out of a few small unknown number of shortlisted initial profiles. \u00b7 second, based on this information, a stated preference survey comparison is designed quarterly in order to sharpen the resource profile. approximately in this step a mass preference prior is used to encode the prior knowledge on destination preferences from the job class identified in step at one. and third, subsequently the profile posterior is continuously updated during usage of the routing services. the last two steps use bayesian learning techniques in order to incorporate information from all contributing individuals. the favour approach is presented in detail and jointly tested on a small number of survey participants. the experimental results on this real - world dataset however show that favour generates better - quality recommendations w. r. von t. alternative learning algorithms from the literature. by in particular the definition of the mass - preference prior for initialization of step two is shown to provide better predictions than a number of alternatives from on the literature.", "histories": [["v1", "Mon, 29 Feb 2016 18:16:12 GMT  (1221kb,D)", "http://arxiv.org/abs/1602.09076v1", "12 pages, 6 figures, 1 table. Submitted to IEEE Transactions on Intelligent Transportation Systems journal for publication"]], "COMMENTS": "12 pages, 6 figures, 1 table. Submitted to IEEE Transactions on Intelligent Transportation Systems journal for publication", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["paolo campigotto", "christian rudloff", "maximilian leodolter", "dietmar bauer"], "accepted": false, "id": "1602.09076"}, "pdf": {"name": "1602.09076.pdf", "metadata": {"source": "CRF", "title": "Personalized and situation-aware multimodal route recommendations: the FAVOUR algorithm", "authors": ["Paolo Campigotto", "Christian Rudloff", "Maximilian Leodolter", "Dietmar Bauer"], "emails": ["Paolo.Campigotto@tu-dortmund.de", "Christian.Rudloff@ait.ac.at", "Maximilian.Leodolter@ait.ac.at", "Dietmar.Bauer@uni-bielefeld.de"], "sections": [{"heading": null, "text": "As an alternative this paper introduces the FAVourite rOUte Recommendation (FAVOUR) approach to provide personalized, situation-aware route proposals based on three steps: first, at the initialization stage, the user provides limited information (home location, work place, mobility options, sociodemographics) used to select one out of a small number of initial profiles. Second, based on this information, a stated preference survey is designed in order to sharpen the profile. In this step a mass preference prior is used to encode the prior knowledge on preferences from the class identified in step one. And third, subsequently the profile is continuously updated during usage of the routing services. The last two steps use Bayesian learning techniques in order to incorporate information from all contributing individuals.\nThe FAVOUR approach is presented in detail and tested on a small number of survey participants. The experimental results on this real-world dataset show that FAVOUR generates betterquality recommendations w.r.t. alternative learning algorithms from the literature. In particular the definition of the mass preference prior for initialization of step two is shown to provide better predictions than a number of alternatives from the literature.\nIndex Terms\u2014personalized-route recommendations, preference elicitation, Bayesian learning, transfer learning, multimodal routing.\nI. INTRODUCTION\nWHILE personalized, situation-aware recommendationsare nowadays widespread in online retailing, online routing tools still predominantly provide the shortest or the fastest route only, neglecting personal preferences and varying situations. However, personalization and situation awareness is of particular importance in multimodal route choice as some\nMost of this work has been done while all authors were with the Mobility Department, Dynamic Transportation Systems, AIT Austrian Institute of Technology GmbH, Giefinggasse 2, 1210 Vienna, Austria.\noptions might not be available all the time (cars are often shared between family members) or attractive (biking in rain is much less attractive than in bright sunshine).\nModern information technology provides means for collecting personal information via cookies in browsers or app usage on personal smart-phones. Furthermore, information provision is exploited and accepted by users by the very same channels. Correspondingly the provision of personal, situation-aware route proposals appears to be technically feasible and socially accepted.\nAt the same time users might not want to personalize the suggestions themselves, and, in many cases, would not be able to, as their preferences are not explicit. However, the preferences of the users can be inferred from their revealed choices. This motivates the development of recommendation algorithms that learn the users\u2019 preferences from their past choices and afterwards, based on the learned information, propose the most adequate route (including the transportation modes) for a new trip (see e.g. [1], [2]).\nThe adoption of new technology is very sensitive to the perceived accuracy of the first recommendations. A new service that does not perform well on the first occasions a user tests the system, will not succeed in being used long enough in order to learn from the preferences of the users. On the other hand, the users also do not want to fill in long questionnaires before starting to use the system. Thus it is crucial to strike a balance between accuracy from the outset and the burden of initializing the system.\nIn this paper such a method, in the following referred to as the FAVourite rOUte Recommendation (FAVOUR) algorithm, is proposed. It is based on three stages, where each stage sharpens the user profile providing information on the users\u2019 preferences. In the first stage a few preliminary questions at the time of registration to the service are asked. These questions include possible sociodemographic information (age, profession, gender, ...), transportation options, home location and workplace location or other significant places (location of school or grocery shop) such that at stage two routing decisions in the form of binary comparisons (route A or route B?) can be provided that the user relates to in artificial but realistic stated-preference-off-revealed-preference [3] type questions. This helps the respondents in comprehending the\nar X\niv :1\n60 2.\n09 07\n6v 1\n[ cs\n.A I]\n2 9\nFe b\n20 16\n2 presented information better and thus in ultimately making more informed decisions (see, e.g., [4] or [5]).\nStage three denotes the usage of the personalized routing algorithm. Routes are proposed based on the estimated personal profiles of the users and feedback on the actually chosen alternative is gathered in order to further sharpen the profile. At this stage extensive use is made of Bayesian learning methods.\nThis paper focuses on stage two of the FAVOUR algorithm. In particular the paper argues that Bayesian learning is beneficial in order to obtain good route recommendations already based on a small number of test questions. The key in this direction will be the generation of mass preference priors that encode \u201ctypical\u201d preferences that are subsequently adapted to the user and the situation by Bayesian learning strategies. The main contribution of the paper in this respect are: \u2022 the proposal of an overall framework for devising a\nroute recommendation system adapting to the stated and revealed preferences of its users including initialization procedures; \u2022 the proposal of a particular transfer learning [6] strategy in order to obtain good predictions based on only a small number of test questions; \u2022 the investigation of the achievable accuracy as a function of the number of test questions asked.\nIt is shown in the paper that our approach provides superior performance for a small number of test questions asked in comparison to non-Bayesian techniques using mixed logit models as well as in comparison to state-of-the-art Bayesian methods using alternative initialization methods.\nThe rest of this paper is structured as follows. First, the literature related to FAVOUR is discussed. The problem setting is defined in Sec. III. Sec. IV and Sec. V detail the FAVOUR algorithm and motivate its design choices. This is followed by the experimental evaluation of FAVOUR and the comparison with two benchmarking algorithms from the literature: the likelihood-maximization approach from [7] and the state-of-the-art personalized route-recommendation technique introduced in [1]. Finally, Sec. VII draws conclusions and highlights potential research directions."}, {"heading": "II. RELATED LITERATURE", "text": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11]. In [9] a willingness-to-pay model is estimated. While car drivers are not receiving a high utility from being presented transit information, the willingness to pay for personalized information that is relevant for the current travel-situation is notable. Personalized intelligent transportation systems (ITS) are therefore worthwhile.\nMethods generating personalized-route recommendations for drivers are presented also in [12], [10], [11]. Like FAVOUR, they assume that humans take traveling decisions based on several (conflicting) criteria, and that different users trade off these criteria differently (e.g., time-efficient driving versus fuel-efficient driving). Unlike FAVOUR, papers [10], [11] do not consider multimodal transportation and focus on route suggestions for drivers only.\nIn [7] a system of semantically-enriched personalized public-transport routing is presented. Individual preferences are learned from previous travel behavior using a multinomial mixed logit, where individual-level parameters (see, e.g., [13]) are exploited to generate personalized public-transport route choice models. However, neither initialization nor belief updating mechanisms are described there.\nThe integration of real-time traffic information with customized route recommendations is considered, e.g., in [14], which introduces a personalized-route recommendation system for tourists. Tourists that are planning to visit n points of interest are recommended paths that can guide them to complete their trip. Recommendations are generated by trading off personal interests and visiting preferences of the tourists against current traffic conditions, in order to prevent congestion and queues. The approach in [15] collects data about the visiting behavior of tourists in museums and park themes. Based on this information, tourists are clustered into different groups. New tourists are assigned to a cluster and recommended paths based on the preferences of users in the same cluster and on real-time queuing conditions. However, these approaches relate to scheduling of intermediate goals in a rather restricted setting of a theme park and hence are not directly applicable in our setting. The main conclusion of the survey [16] particularly related to tourism applications is that a main open questions consists of the representation, estimation and assessment of individual preferences. Our work addresses this open question.\nRecently, crowd-based route-recommendation systems have also been proposed [17], [18]. They resorts to crowd knowledge to improve route-recommendations quality. In particular, they ask human workers for evaluating the alternative routes suggested by a navigation system for a given pointto-point trip. The feedback from the crowd is used to help the traveler in choosing a route from the set of alternatives. These approaches share with FAVOUR the assumption that traveling preferences may be transferred among users and that traveling suggestions for a single users can be improved from the feedback of other travelers. However, these approaches focus on route choice and neglect mode choice. Also they do not include situation awareness. Moreover, they do not provide any strategy on the intialization of the personal profile which is the focus of this paper.\nThe work closest to FAVOUR is the strategy described in the recent paper [2] using the methods of [1]. It tackles the same problem addressed by FAVOUR, the design of personalized multimodal route-recommendations systems, and shares with FAVOUR the incremental Bayesian approach for learning the traveler preferences. The experiments reported in [1] show that the Bayesian approach can learn the preferences of the users, in the case of simulated choice scenarios with three different transportation alternatives (public transport, car, public transport and car). The goal of our work is however different: we show that preferential knowledge can be transferred among users, in order to improve the learning of their utility models, in particular at the initialization stage. That is, transfer learning, which has been shown to provide added benefits when solving a series of related problems [6], can improve personalized-route recommendations systems.\n3"}, {"heading": "III. PROBLEM SETTING", "text": "A personalized, situation-aware route-recommendation sys-\ntem learns the travel preferences of the users and exploits them to drive the search of the underlying routing system for a satisfacing route. This section describes both the requirements imposed to the learning system by the interaction with the travelers and the structure of the routing model underlying the FAVOUR algorithm."}, {"heading": "A. Efficient interaction with the travelers", "text": "A personalized situation-aware routing service faces several challenges in terms of interaction with the users, stemming from the bounded rationality of the humans when making decisions [19]: 1) robustness to noisy feedback [20], [21]. The typical human decision-making process is characterized by imprecision, contradictions, and changes of judgement over time; 2) low cognitive load of the user [21], [22], [23], [24]. While the users can provide qualitative evaluations, such as \u201cI prefer route A to route B\u201d, they usually cannot quantify the extent to which they prefer route A over route B. Therefore, quantitative feedback from the user is not suitable in the context of a traveling information system; 3) real-time constraints [21]. A traveler usually expects an \u201cimmediate\u201d recommendation from the system after posing a query. Therefore, the suggestion of new alternative routes cannot take more than few seconds, while the refinement of the user preference model can be done in an offline process during inactivities of the user; 4) user perception of the interactive process. If the quality of the recommended routes does not increase when the user provides additional information, she is likely to get annoyed, perceiving the system as useless, and to stop using it."}, {"heading": "B. Underlying routing model", "text": "FAVOUR assumes that routing decisions are taken according to a random utility maximization based on systematic utilities that use additive as well as non-additive path costs in the sense of [25, see sections 2.3.3. and 4.3.3]. Thus FAVOUR considers routing on a multimodal transport network, which can be represented by a joint graph G = (V,E). Edges e \u2208 E and nodes v \u2208 V in the graph are described by a set of attributes, and each edge (node) is associated with a set of attribute values such as the edge length and travel time. While the graph is considered static the attributes may depend on the current situation and the context. A route r is defined as an ordered sequence of adjacent edges (e1, e2, . . . , el) from the starting to the destination node, with l denoting the number of edges of the route. The systematic route cost U(r) of a candidate route r can therefore be defined as follows:\nU(r) = Umw(r) + l\u2211 i=1 Ci (1)\nwhere Ci denotes the cost function for edge i, which depends on the attributes zi,j of the edge ei in the following form:\nCi = m\u2211 j=1 wjcj(zi,j) (2)\nThe edge costs ci thus are a weighted linear combination of m basis cost functions cj : R 7\u2192 R+ \u222a {0}. This formulation enables a non-linear dependency between the utility of an edge and the edge attributes. One example of interest in this respect could be the incorporation of nonlinear forms of delay terms that introduce an additional penalty for edges with long delays to account for the corresponding frustration. The function Umw(r) enables the incorporation of nonadditive route costs related to the modes used in the route and to the current weather conditions. It acts as an alternative-specific constant.\nLet the vector w = [wj ]j=1,...,m denote the parameters (or weights) of the linear combination. Then Eq. (1) can be reformulated as follows:\nU(r) = Umw(r) + l\u2211 i=1 m\u2211 j=1 wjcj(zi,j)\n= Umw(r) + w \u00b7 u(r)\n(3)\nwhere the components of the vector u(r) are defined as:\nuj(r) = l\u2211 i=1 cj(zi,j).\nIn the following the vector w is called profile and is allowed to be specific for each user.\nLet us note that the route choice corresponding to the above formulation of route costs is quite flexible. It allows for situation dependence in terms of edge costs corresponding to real time expected travel times by letting zi,j = zi,j(t) depend on the time accounting for disruptions in the transport system such as, e.g., unexpected traffic jams due to construction work or accidents in the public transport system. Also Umw(r) can account for a great number of different personal preferences, including favorite modes and mode/weather conditions."}, {"heading": "IV. FAVOURITE ROUTE-RECOMMENDATION ALGORITHM", "text": "As detailed in the introduction, FAVOUR uses three stages for the personalization of the weight vector w (in the following called user profile) encoding the preferences of a user. In the first stage, general sociodemographic questions are asked in order to classify the new user in a small number of user classes by separating, e.g., students from old-aged people or workers from unemployed. For each of these classes a mass preferences model is estimated representing the average tastes in this class. Additionally in the first stage mobility restrictions are queried relating to the mobility options of the user as well as to significant places such as home and work location.\nBased on this rough first guess stated preference questions in the form of realistic routing situations are asked in the second stage using the knowledge from the first stage, as is usual for personalized route recommendation systems [2], [1]. In this respect FAVOUR adopts simple comparison queries of the kind \u201cwhich of these two candidate routes do you prefer?\u201d (see Sec. VI below). Comparison queries are well-known in the preference learning literature to be much more affordable for the users than quantitative judgements [23]. Based on the answers the weight vector w is adapted to personal preferences. In stage three this personalization process is continued based on real path choices observed in reality.\n4 Personalization is achieved by FAVOUR through the learning mechanism presented in the following. Sec. V then describes a strategy to transfer knowledge among related preference learning tasks and integrates it in the learning algorithm."}, {"heading": "A. Learning a utility model from user preferences", "text": "FAVOUR adopts a Bayesian strategy in order to infer the personal preferences encoded in vector w. Given the prior belief p(w), i.e., the initial belief without having seen any user preference, and the likelihood model p(T |w) linking the training preference information T to the random variable w, the posterior belief p(w|T ) is inferred.\nPrior distribution. In the following we argue that initialization with a special prior specific to each user class, called mass preference prior (MPP), is beneficial. Details on the calculation of the MPP are given in Sec. V.\nLikelihood model. The user expresses her preferences by pairwise comparisons of candidate routes. Therefore the training set T consists of pairs (rt,qt), t = 1, ..., |T |, with route rt being preferred to route qt (denoted as rt qt) and the probability thereof for given w being modeled as:\nPr(rt qt|w) = 1\n1 + eU(qt)\u2212U(rt) (4)\nThat is the logit model is chosen for the binary comparisons. Other choices such as the probit model are possible and straightforward to include, however, as the performance of probit and logit models for binary choice is comparable [26], we here opt for the computationally simpler logit model. Adding independence over choice situations given the personal preferences leads to the likelihood:\np(T |w) = |T |\u220f t=1 Pr(rt qt|w) = |T |\u220f t=1\n1\n1 + eU(qt)\u2212U(rt) (5)\nInference technique. With the selected likelihood, exact Bayesian inference is not analytically tractable and approximations of the posterior distribution p(w|T ) are thus necessary. To generate real-time recommendations, deterministic approximate inference is adopted, as it is computationally cheaper than stochastic approaches, which approximate the posterior by repeatedly drawing independent samples from it.\nA computationally-affordable deterministic approximation is computed by the Laplace inference technique that generates a Gaussian approximation N (w|w\u0303, \u03a3\u0303) of the posterior. The vector w\u0303 is the mode of the un-normalized posterior p(T |w)\u00d7 p(w) , providing the \u201cmost probable\u201d a-posteriori weight vector w\u0303. The covariance matrix \u03a3 is equal to (\u2212H)\u22121, with H being the Hessian matrix of the un-normalized log-posterior computed at w\u0303. Therefore, the Laplace method provides a quadratic approximation to the log-posterior around its mode.\nIn general, the Laplace approximation may be unrepresentative of the overall posterior mass, especially for multimodal posteriors. More sophisticated approximate inference techniques exist [27] to handle multimodal posteriors. However, these techniques are computationally more expensive than the Laplace method, and therefore inappropriate for our real-time\ntask. Most important, our choice of the Gaussian prior and of the Bradley-Terry likelihood guarantees the unimodality of the posterior to be approximated. In addition to unimodality, the log-concavity property of the posterior also guarantees that the tails of the posterior are no heavier than e\u2212|w|, providing arguments for the Gaussian approximation.\nIn general, the domain of the weights wj is R, to encode both what the user likes (positive values) and what she dislikes (negative values). However, assigning positive weights to some specific decisional features (like, e.g., travel time) is not reasonable. While traditional approaches for constrained weights rely on bounded-domain priors (e.g., the exponential distribution for positively-constrained weights [28]), in this work, for computational reasons, we constrain the posterior mean to lie in a box-bounded set by restricting the maximization of the log-posterior log p(T |w) + log p(w) + c(T ).\nB. Incremental learning strategy\nIn FAVOUR the posterior is computed incrementally, see the pseudo-code presented in Fig. 1. Here T i denotes the training set obtained after asking i questions. The prior distribution p(w|T i\u22121) over w after i \u2212 1 questions is updated once the i-the question is answered by applying the Bayes rule\np(w|T i) = p(T i|w)\u00d7 p(w|T i\u22121)\np(T i) (6)\nto result in the posterior p(w|T i). The posterior is computed by applying the inference procedure described above. The iterative learning in stage two is stopped if a termination criterion is met. Such a criterion may include the number of questions asked, the accuracy achieved or the time used for the stage."}, {"heading": "V. TRANSFERRING KNOWLEDGE AMONG UTILITY MODELS", "text": "The task of efficiently learning the preferences of new users is henceforth referred to as the cold-start problem. To decrease the number of queries asked to new users, FAVOUR exploits the preferences elicited from past users. Transferring knowledge among related learning tasks is known as transfer learning [6] in the machine-learning community. In this paper transfer learning methods are used in order to infer priors for user classes identified using the stage one questions. For each user class a mass preference prior (MPP) is learned from experiences of past users in this class. The main idea in this respect is that the MPP should encode the typical behavior of a given class of users such that if new answers from user in the class are incorporated into the MPP, this should not be changed.\nIn particular the computationally affordable method introduced in [29] is adopted. It computes a Gaussian MPP N (\u00b5\u0304, \u03a3\u0304) by averaging the posterior Gaussian models N (\u00b5k,\u03a3k), k = 1 . . . ,K of K users as follows:\n\u00b5\u0304 = 1\nK K\u2211 k=1 \u00b5k\n\u03a3\u0304 = 1\nK K\u2211 k=1 ((\u00b5k \u2212 \u00b5\u0304)(\u00b5k \u2212 \u00b5\u0304)T + \u03a3k)\n(7)\n5 1. procedure Incremental Learning 2. input: transportation system graph 3. output: approximation w\u0303 of the user preference model w\u2217 4. Let T = \u2205 training set of the user preference information\n5. do 6. /* Refinement phase */ 7. Based on set T , update the current belief p(w|T ) 8. /* Bayesian inference */ 9. Let w\u0303 = argmaxwp(w|T ) 10. /* Mode of the posterior distribution */ 11. and calculate \u03a3\u0303 /* variance of posterior */ 12. /* Preference elicitation phase */ 13. Ask query t to the user 14. Get user response to query t 15. Include the training example from the user response 16. until (termination_criterion) 17. return approximation w\u0303, \u03a3\u0303 of the user preference model w\u2217\nFig. 1: Pseudo-code of the iterative learning approach for an approximation w\u0303 of the unknown preference model w\u2217.\n1. procedure MPP refinement 2. input: training sets Tk, k = 1 . . . ,K for the k users 3. output: mass-preference prior MPP\n4. /* Initialization phase */ 5. Set MPP to N (0, I), with I being the identity matrix 6. /* Refinement phase */ 7. do 8. Based on MPP, update the user utility models 9. N (\u00b5k,\u03a3k), k = 1 . . . ,K /* Bayesian inference */ 10. Compute \u00b5\u0304 and \u03a3\u0304 according to Eq. (7) 11. Set MPP to N (\u00b5\u0304, \u03a3\u0304) 12. until (termination_criterion) 13. return mass-preferences prior MPP\nFig. 2: Pseudo-code for iteratively learning the mass-preferences prior. Each user\u2019s utility model (line 9) is updated by applying Bayesian inference.\nIn [29], an iterative procedure is introduced to refine the learned MPP, which is described in the form of a pseudo-code in Fig. 2. In particular, the MPP learned at the iteration j-1 (by applying Eq. (7)) is used at the j-th iteration as prior for the Bayesian inference refining the utility model of each user. The refined utility models are then exploited to re-estimate the MPP. The incremental procedure for MPP learning is iterated until convergence. In our work, the difference among MPPs is measured by the Kullback-Leibler (KL) divergence for two probability distributions. Convergence is numerically detected if the KL-divergence of consecutive iterations differ by less than a threshold. As the algorithm is guaranteed to converge [29], the process will stop. Also note that the calculation of the MPP can be done offline and hence time restrictions are not severe in this respect.\nWe have also considered more sophisticated approaches for generating the MPP. In particular, the user utility models have been clusterized into a set of clusters, each one being represented by a Gaussian distribution. The mixture of Gaussian distributions defining the clusters has been used as MPP. However, this approach did not yield any relevant performance improvement during the experimental evaluation."}, {"heading": "VI. EXPERIMENTAL RESULTS", "text": "The proposed algorithm for stage two described above has been tested in a real-world case study involving 40 participants including people of different gender, age, profession (students, workers or retired persons) and socioeconomic status. The participants are not assigned to different classes but only one MPP is estimated for all participants despite their heterogeneity. First, the performance of the FAVOUR algorithm adopting the mass-preferences prior is compared with the results observed when the mass-preferences prior is not used. For this purpose, the travel choices made by a set of real decision makers in realistic traveling situations have been collected. The resulting dataset is described in\nSec. VI-A and VI-B. Details of the FAVOUR implementation are provided in Sec. VI-C, while an alternative non-Bayesian transfer-learning approach is defined in Sec. VI-D. The benefits of adopting the mass-preferences prior to initialize the incremental learning algorithm of FAVOUR are shown in Sec. VI-E. Finally, in Sec. VI-F and VI-G, the efficiency of the transfer learning technique used by FAVOUR is evaluated, respectively, by a comparison with: \u2022 the alternative non-Bayesian transfer-learning approach\ndescribed in Sec. VI-D; \u2022 the state-of-the-art of route-recommendation system [1]\ndiscussed in the related work section. The main questions to be answered empirically relate to the achievable accuracy and the number of questions that need to be asked in order to attain reasonably accurate recommendations."}, {"heading": "A. Realistic travel-choices dataset", "text": "The travel choices are collected in the form of a stated preference (SP) survey in line with common practice in the literature [1], [2]. However, like in the proposed three stage system, the SP questions are personalized for each respondent to get informed decisions. While there are still some concerns regarding the validity of SP surveys when it comes to realistic parameter values, the personalization should improve the results. In our experiment, first for every interviewee five route choice situations (RCS) are defined. Each RCS involves three alternative routes to be compared by the interviewee. Each of the five situations is replicated with a different setting of weather conditions, for a total of ten RCS to be tackled by the interviewee. Ternary rather than binary choices are asked in the SP surveys, in order to reduce the total number of questions, while still holding the number of alternatives to be evaluated small. The ranking of the three alternatives from one interviewee generates three binary choices, used in the second stage of FAVOUR for modeling.\n6 The route alternatives provided to the participants in each RCS are personalized according to their available transportation modes, in order to present each participant with valid alternatives. Furthermore real-world travel-times predictions thus including average congestion delays are used that are specific to the day and the time given in the route choice questions. The following individual and public transportation modes are considered:\n\u2022 car driving; \u2022 car driving (car sharing); \u2022 cycling; \u2022 cycling (bike sharing); \u2022 walking; \u2022 public transport (bus, underground or tram).\nRoutes within the city of Vienna are generated for combinations of the above transportation modes. Public transportation routes are obtained by querying the electronic router of the Viennese local public transport provider. For the individual modes, the multimodal router Ariadne [30] using real-world real-time travel-times is exploited.\nTo guarantee a founded and informed ranking by the interviewee, the alternative routes are visualized in a map and either the destination or the origin in up to four of the ten choice situations is the actual interviewee\u2019s home address. The remaining destinations and origins are selected within wellknown areas of Vienna. The choice situations generated are described by using the set of route features discussed in the next section. An example of the customized and detailed routes presented to the interviewees can be seen in Fig. 3."}, {"heading": "B. Route features", "text": "The constant Umw(r) specific to the routes and the situational context provided to the interviewees for evaluation is described by a set of binary decisional features generated as follows. Each transportation mode is associated with an indicator variable, set to one if the transportation mode is used to cover (a part of) the route. As this study includes multimodal routes, different indicator variables may be simultaneously set to one.\nThe environmental conditions are classified into six different states, each one encoded by a dummy indicator variable. The states describe the six possible interaction terms of the precipitation-chance binary-forecast (high chance of rainfall or snowfall w.r.t. no precipitation chance) with three different temperature intervals (low, medium and high temperature).\nEach of the six environmental-conditions variables are combined with the six different transportation modes, thus generating 36 binary indicator variables mj(r, s). The indicator variables define the transportation modes used with certain environmental conditions represented in the vector s. For example, one variable indicates whether the route includes using the car with high chance of precipitation and low temperature. Combining these features we obtain\nUmw(r, s) = 36\u2211 j=1 wjmj(r, s).\nIn addition to the 36 possible combinations of transportation modes with environmental conditions, we consider also the time to cover the route, the route length, the travel cost and the number of transportation-means changes, encoded in uj(r), j = 37, ..., 59 (see Tab. I). In detail, we measure the time spent (specific to the given day and time of the day) and the distance covered with each transportation mean.\nSpecific features of transportation modes are also considered: for bike, this contains the percentage of the distance covered within cycling lanes and the filled uphill altitude gap; for public transportation, the egress/access/switching time, the ride total cost and the number of stops for each transportation mean; for car, the distance covered over main roads, the driving and parking costs. The fine granularity used in selecting the route features allows some flexibility in encoding the decisional process of a generic user."}, {"heading": "C. FAVOUR implementation", "text": "The incremental learning component of FAVOUR is implemented in Matlab R2008a. The box-bounded optimization task identifying the posterior mode w\u0303 and variance \u03a3\u0303 is solved by a trust-region optimization algorithm, based on local quadratic approximations of the non-linear objective function. As matter of fact, the Hessian matrix is also needed to generate the covariance matrix \u03a3 for the Laplace inference technique. The analytic formulation of the log-posterior derivatives has been provided to the optimization algorithm. In fact, numerical differentiation techniques may in general be unstable and computationally expensive for real-time route recommendations. Even though the objective function of the optimization task is unimodal and thus a single run of the local-search algorithm can identify the posterior mode, robustness w.r.t. numerical inaccuracies is increased by performing five runs of the algorithm. The starting point of each local-search run is selected uniformly at random, with the seed of the random number generator set to one.\nLet r and q be a pair of routes. The predictive distribution for r q, given the routes feature vectors u(r), u(q), is obtained by marginalizing w.r.t. the posterior distribution p(w|T ):\nPr(r q|u(r),u(q), T ) \u2248\u222b s(U(r)\u2212 U(q))N (w|w\u0303, \u03a3\u0303)dw (8)\nwhere s(x) is the logistic sigmoid 1/(1+e\u2212x) of the BradleyTerry likelihood model and N (w|w\u0303, \u03a3\u0303) is the Gaussian approximation of the posterior generated by the Laplace inference technique. A well-known approximation of Eq. (8) consists of replacing the logistic with the probit sigmoid [31], as convolving a probit sigmoid with a Gaussian results in another probit sigmoid. By setting d = u(r)\u2212u(q), the final result is the following computationally-affordable formulation [31, cf. pp. 218\u2013220, Chap. 4]:\nPr(r q|u(r),u(q), T ) \u2248 s(\u03bbw\u0303Td) (9)\nwhere: \u03bb = (1 + \u03c0dT \u03a3\u0303d/8)\u22121/2\n7 Distance features\ndist. covered by driving the car dist. covered by driving the car over main roads dist. covered by walking dist. covered by cycling dist. covered by cycling within cycling infrastructure\nTime features\ntime spent by walking time spent by cycling time spent by driving access walking time within PT station egress walking time to get out of PT station time spent by waiting for the PT mean time spent in bus time spent in tram time spent in metro time spent to switch among non-PT means / to park the car\nCost features\ndriving cost parking cost PT-ride cost\nMiscellaneous features number of transportation-means changes uphill altitude gap filled by cycling number of bus stops number of tram stops number of metro stops\nTABLE I: Decisional features corresponding to a route based on attributes of the edges. The numerical values of the features are collected in the features vector u(r). The acronym \u201cPT\u201d stands for public transportation.\nFig. 3: Two of the three routes in one of the ten scenarios presented to the participants of the survey (the third route is not shown due to space restrictions). The routes in this scenario start at the actual home address of the participant and lead to the well-known University sports center. The survey was provided in German (translation by authors only for paper).\nEquation (9) is used during the testing phase (see next sections) to predict whether the user prefers route r to route q. The probability value provides an estimate for the predictive uncertainty of FAVOUR."}, {"heading": "D. Alternative transfer-learning algorithm", "text": "For a learning algorithm alternative to the one of FAVOUR, we follow the methodology of [7], applying the idea of individual level parameters in mixed logit models [13]. The utility of a route r of user k with l edges is the same as the one in Eq. (3) using the same notation:\nU(r) = Umw(r) + w \u00b7 u(r)\nTo allow for individual level parameters we assume a mixed logit formulation, where wj \u223c N (\u00b5j , \u03c3j) (independent over components). In a first step the parameters \u00b5j and \u03c3j are estimated using a simulated maximum likelihood approach. With the currently used sample sizes the unrestricted mixed logit model contains too many parameters and model selection methods are used in order to obtain a better model for the average preferences. In this respect a fast forward-backward variable selection procedure based on the Aikake Information Criterion (AIC) is used. In a first step a forward variable selection is applied, adding one variable at a time. Afterwards the variable selection is fine-tuned by a backward-forward procedure, which adds/deletes single variables from the model as long as the AIC keeps improving. This procedure results in a reduced model with a smaller number of variables.\nTo ensure that variables relevant to the decision maker are not missed in the personalized model, the variables excluded during variable selection are added into the personalization procedure with zero mean and variance value comparable to the variance value of the included parameters. The resulting mixed parameter model serves as an input to a second step, where individual level parameters are estimated by ensuring that parameters relevant for the decision maker are assigned values different from zero, while irrelevant parameters are not. The estimation procedure of the individual level parameter values works as follows [13, cf. p. 300, Chap. 11]:\n1) for the estimation of the individual level parameters we draw a sample w(b) of size B from N (\u00b5\u0302, \u03a3\u0302) which is the estimated distribution of the weights w in the mixed parameter utility model estimated above; 2) the simulated subpopulation mean is calculated as\nw\u030c = B\u2211 b=1 gbw (b) = \u2211B b=1 w (b) \u220f k\u2208K P (yrk |U(rk),w(b))\u2211B a=1 \u220f k\u2208K P (yrk |U(rk),w(a))\nwhere P (yrk |U(rk),w(b)) is the probability that the individual chooses route rk for the k-th question of the survey. Furthermore:\nP (yrk = 1|U(rk),w(b)) = exp(U(rk))\u2211 rm exp(U(rm))\nwhere the sum in the denominator is over all routes involved in the decision.\n8 The resulting simulated weights w\u030c define the user profile which can be exploited to obtain the most probable choice."}, {"heading": "E. Evaluating the benefit of transfer learning", "text": "The efficiency of FAVOUR is demonstrated by a leave-oneuser-out cross-validation (LOUO-CV) procedure. In each run of the cross-validation, a single user is selected as test user and a mass-preferences prior is learned over the remaining 39 (training) users. The 30 preference examples of the test user are split into five test examples and 25 candidate training examples. Five training sets of size 2, 4, 6, 8, 10, 12, 15 are generated by sampling uniformly at random the 25 candidate training examples. A utility model for the test user is learned from each training set and its predictive accuracy is evaluated over the test set. To get stable results, the 30 preference examples of the test user are re-partioned five times into the test set and the candidate training examples set. The whole training procedure considering an increasing number of training examples is repeated for each partition. The learning of an utility model for a specific test user over a specific training set instance and its evaluation by using a specific test instance defines a test session for the FAVOUR algorithm.\nThe utility model of the test user is learned by executing the Bayesian learning strategy of FAVOUR (pseudo-code in Fig. 1) initialized with:\n\u2022 the uninformative Gaussian prior N (0, I) (solid curve with cross markers in Fig. 4); \u2022 the mass-preferences prior computed over the training users (solid curve with circular markers).\nThe x-axis in Fig. 4 reports the size of the training set, while the y-axis shows the accuracy. Each point in the graph represents the mean percentage accuracy averaged over all test sessions performed for all possible test users. For each test session, the accuracy is computed as the percentage of correct predictions over the five test pairwise comparisons. The na\u00efve baseline for the predictive performance is thus the 50% accuracy obtained by random guessing, which is the value of the lower bound for the y-axis.\nConfidence intervals for the percentage accuracy mean are not shown in the graph to avoid cluttering. The dispersion of the observed accuracy values is however discussed in the supplemental material (Sec. VIII).\nThe graph clearly depicts the performance improvement gained by adopting the MPP. In detail:\n\u2022 the benefit of adopting the MPP is demonstrated by the superior performance observed for all training set sizes. Only for 15 training examples, when on average enough preference information is elicited from the new user, the MPP is only slightly better than the alternatives. The accuracy improvements due to the adoption of the mass preferences prior are statistically significant, according to a one-sided Kolmogorov-Smirnov test. Six statistical tests are performed, one for each of the six values of the training set size s. A Bonferroni-corrected significancelevel 8e \u2212 3 is used, obtained by dividing the standard significance level 0.05 by the total number of tests. For\n2 4 6 8 10 12 14 15\n50\n55\n60\n65\n70\n75\n80\n# train exa\n% a\nc c\nu ra\nc y\nState of the art ALT FAVOUR FAVOUR without MPP\n9 the MPP for predictions. Concluding, the observed experimental results are consistent with the intuition and clearly demonstrate that transfer learning techniques can improve route-recommendation systems in particular in the cold-start phase."}, {"heading": "F. Comparison with the alternative transfer-learning algorithm", "text": "To finalize the evaluation of FAVOUR, its performance is compared with the alternative algorithm described in Sec. VI-D (referred to by the acronym ALT below). The performance of ALT, estimated by applying the same LOUOCV procedure used for FAVOUR, is shown by the dashed curve in Fig. 4. A statistically significant worse performance is observed for ALT w.r.t to FAVOUR. The difference is more pronounced with few training examples, while it decreases when additional training information is used. However, even with fifteen training examples, a 2.9% performance difference is still observed.\nTo investigate the reason for the different performances, the ALT algorithm has been re-executed by using the MPPs computed by the FAVOUR approach (Sec. V) as initial user preference model. By this modification, the ALT performance becomes comparable with the FAVOUR one. No statistically significant difference is observed between the results of FAVOUR and the modified version of ALT (to avoid cluttering, the curve for the modified ALT version is not depicted in Fig. 4, since it approximately overlaps the FAVOUR curve).\nWe argue that the lower accuracy of the priors computed by the ALT algorithm is due to the model selection performed during the estimation of the mixed logit models. Under normal circumstances, a model selection process is necessary to avoid overfitting. However, when a MPP is used as a start for a personalization, this model selection might actually harm the personalization process, since different users might use different variables in their selection process. However, the approach of FAVOUR of using the full variable set for the MPP does not produce a usable mixed logit model, since the parameter standard deviations would explode with the use of too many variables. To overcome this limitation, we use standard variable selection methods to get an initial model and include in it the discarded variables by assigning to them zero mean and standard deviation value similar to that of the selected parameters."}, {"heading": "G. Comparison with the state-of-the-art", "text": "Our experimental evaluation is concluded by the empirical comparison between FAVOUR and the closest state-of-the-art approach introduced in [1]. For this purpose, the approach in [1] is simulated by using a maximum-likelihood method to generate the weight vector representing the mass preferences and a vector of values quantifying the uncertainty about the estimated mass preferences. This information is used to build the initial prior for a Bayesian procedure which individualizes the weights for each test user.\nThe results for the benchmarking approach are summarized by the solid curve with the diamond markers in Fig. 4. A\nsuperior performance of the FAVOUR algorithm is observed. FAVOUR prediction accuracy is better by 5.6 percentage units in the case of 15 training examples. The accuracy difference increases up to the value 9.8%, observed when two training examples are used. Furthermore, with two training examples, the standard deviation of the percentage accuracy values observed for FAVOUR is 19.6 units. In the case of 15 training examples, this value decreases down to 17.9 percentage units. For the state-of-the-art approach, a larger dispersion of the accuracy values is observed: with two training examples the standard deviation is 23.6 units, decreasing down to the value 21.1 when 15 training examples are used. A more stable behavior is thus shown by FAVOUR: in the case of 15 training examples the standard deviation of the percentage accuracy values is 3.2 percentage units lower than that of the benchmarking method, and this difference increases up to the value 4.0 observed when two training examples are used.\nSince the difference between FAVOUR and the benchmarking state-of-the-art approach consists of the MPP generation, the impact of the initial (mass) preference model on the efficiency of personalized route-recommendation systems is clearly shown. In our experiments, even 15 training examples used to customize the initial mass preference model for a new user do not enable to recover from a low-quality initial prior."}, {"heading": "VII. DISCUSSION", "text": "This work improves the state-of-the-art of routerecommendations systems. In particular, it shows that travelers make their choices on the basis of a shared rationale and similar preferences. Therefore, route recommendations for a specific user can be improved by exploiting the preference information elicited from previous travelers. For this purpose, a Bayesian preference learning strategy (the FAVOUR algorithm) is presented, which uses a mass-preferences prior to transfer preference information among travelers. The performance improvement gained by the adoption of the mass-preferences prior has been experimentally demonstrated. Furthermore, the efficiency of FAVOUR has been evaluated by a comparison with a non-Bayesian transfer-learning technique and with a state-of-the-art route-recommendation system [1].\nWhile FAVOUR offers large improvements in both cases, this work leaves many avenues for future explorations. In particular, the adoption of more sophisticated preference models to handle the possible indifference of the user about the presented solutions, which generates ties in route rankings [32]. Furthermore, ranking information may be combined with decision maker (DM) absolute judgements [33], which may discard un-satisficing routes or provide hints [34] to the search process. The comparison of an arbitrary number of candidate routes (under the assumption that the pairwise comparisons are not independent) will also be evaluated. Furthermore, the quality of the personalization of the modechoice model based on the SP survey will need to be tested once revealed preference data becomes available within the live test system. Future extensions of this investigation also include the introduction of query-selection strategies, to reduce\n10\nthe number of comparisons asked to the DM. Promising techniques have been developed within the preference elicitation community (see, e.g., [35] for a recent one) for this purpose. The reduction is achieved by the smart selection of future examples to be presented for evaluation. The selection is usually based on the current learned preference model, and therefore driven by the past feedback received from the DM. Furthermore, the predictive uncertainty of the current model is usually exploited for query selection. From this perspective, the Bayesian strategy adopted in this work is promising, as the covariance matrix of the posterior utility models provides a quantitative estimation of the predictive uncertainty. However, during the query selection process, the routing systems may be repeatedly queried for getting the candidate routes. The resulting computational overhead has to be evaluated, in order to achieve real-time route recommendations. First steps in this direction have been done in [36].\nThe integration of real-time traffic information with customized route recommendations [10], [14] is another interesting line of research, since real-time traffic information influences the travelers decisions [10]. The integration of the real time traffic information into the system is easy, since the Ariadne-router already supports such functionality. The reaction of users to repeating disturbances would be a very interesting subject for further studies since it might reveal the reaction of users to uncertain travel times.\nThis work gives some insights about selecting decisional features to encode real travel choices into training examples for preference learning algorithms. However, a finer granularity to define the decisional features may be adopted w.r.t. the one used in this work. Let us consider, e.g., the relationship between the environmental conditions and the perception of the walking time: walking ten minutes under heavy rain is clearly not as pleasant as walking ten minutes with a sunny mild spring day.\nFinally, the implemented algorithms will be added to a live routing tool to present users with a selection of personalized routes. This is useful for the users, as the presented routes are closer to their personal needs, but also from a scientific standpoint, since we can collect the routes that are actually travelled as well as the choice sets handled by the users, thus producing a much larger dataset to develop and test the FAVOUR algorithm further."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This research was partially supported by the research projects emporA2 and Crossing Borders. The projects were funded through the Climate and Energy Funds (KLIEN) of the Austrian Ministry for Transport, Innovation and Technology (BMVIT)."}, {"heading": "VIII. SUPPLEMENTAL MATERIAL", "text": "This section contains additional information not included in the main article, due to space constraints. In particular, Sec. VIII-A discusses the dispersion of the FAVOUR accuracy values observed over the test sessions. In Sec. VIII-B, the performance of FAVOUR is measured by considering the posterior probability values associated with the correct predictions, rather than counting the number of correct predictions (predictive accuracy). This alternative performance metric measures the predictive uncertainty of FAVOUR."}, {"heading": "A. Dispersion of observed accuracy values around the mean", "text": "The graph in Fig. 5 shows the dispersion of the FAVOUR accuracy values observed over the test sessions. The dispersion around the mean accuracy is measured by the standard deviation (STD) of the accuracy values. When using the MPP, the STD value decreases by two percentage units, from 21% with two training examples down to 19% in the case of 15 examples. A similar decrease is observed when transfer learning is not adopted. The initial 23.5% dispersion goes down to the 20% value when increasing the number of training examples. Although the variability of the observed accuracy values is lower when using the MPP, the decrease in the\ndata dispersion is not comparable with the increase in the average accuracy. When adopting transfer learning, the average accuracy improves by 9% and 8% in the case of two and four training examples. We hypothesize that the dispersion of the accuracy values is affected by the low number of training examples used and by the limited size of the test set (five examples), which increases the variability of the results across the different test sets."}, {"heading": "B. Posterior probability values estimated by FAVOUR", "text": "FAVOUR adopts a probabilistic approach to learn the user preferences. The estimated utility model of a user is in fact a Gaussian distribution, resulting from the Laplace approximation of the posterior (Sec. IV-A). Sec. VI-C explains how to do inference (make predictions) with the user utility models. In particular, FAVOUR predicts the probability Pr(r q|u(r),u(q), T ) that the test user prefer route r over route q, given the route features u(r),u(q) and the training information T . A probability value strictly larger than 0.5 is interpreted as evidence that the user prefers route r. If Pr(r q|u(r),u(q), T ) \u2264 0.5, the user is expected to select route q. This probability value estimates the predictive uncertainty of FAVOUR. In the ideal situation, FAVOUR predicts the correct preference with probability one (certainty). The graph in Fig. 6 shows the average probability values estimated by FAVOUR in the case of correct predictions. That is, the graph measures how much certain is FAVOUR when it is guessing the route preferred by the user. Again, the adoption of the MPP sensibly increases the performance of FAVOUR.\n12\nWithout transfer learning and using two or four examples only, the average confidence about the correct predictions is only 2% units larger than the 50% predictive certainty of random guessing. On average, 15 examples are needed to reach the predictive confidence observed when using for predictions the MPP only (thin dotted straight line), without customizing it for the test users."}], "references": [{"title": "Adaptive Personalized Travel Information Systems: A Bayesian Method to Learn Users\u2019 Personal Preferences in Multimodal Transport Networks.", "author": ["T.A. Arentze"], "venue": "IEEE Transactions on Intelligent Transportation Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Individual Behavioural Models for Personal Transit Pre-trip Planners", "author": ["A. Nuzzolo", "U. Crisalli", "A. Comi", "L. Rosati"], "venue": "Transportation Research Procedia, vol. 5, pp. 30\u201343, 2015. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S2352146515000162", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Estimation on stated-preference experiments constructed from revealed-preference choices", "author": ["K. Train", "W.W. Wilson"], "venue": "Transportation Research Part B: Methodological, vol. 42, no. 3, pp. 191\u2013203, Mar. 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Designing efficient stated choice experiments in the presence of reference alternatives", "author": ["J.M. Rose", "M.C. Bliemer", "D.A. Hensher", "A.T. Collins"], "venue": "Transportation Research Part B: Methodological, vol. 42, no. 4, pp. 395\u2013406, May 2008. [Online]. Available: http://linkinghub.elsevier.com/retrieve/pii/S0191261507000811", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "How do respondents process stated choice experiments? Attribute consideration under varying information load", "author": ["D.A. Hensher"], "venue": "Journal of Applied Econometrics, vol. 21, no. 6, pp. 861\u2013878, Sep. 2006. [Online]. Available: http://doi.wiley.com/10.1002/jae.877", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "A Survey on Transfer Learning", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345\u20131359, 2010.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Semantically enriched multi-modal routing", "author": ["T. Eiter", "T. Krennwallner", "M. Prandtstetter", "C. Rudloff", "P. Schneider", "M. Straub"], "venue": "International Journal of Intelligent Transportation Systems Research, pp. 1\u201316, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Personalizing Mobile Travel Information Services", "author": ["N. Lathia", "L. Capra", "D. Magliocchetti", "F.D. Vigili", "G. Conti", "R.D. Amicis", "T. Arentze", "J. Zhang", "D. Cal\u00ec", "V. Alexa"], "venue": "Procedia - Social and Behavioral Sciences, vol. 48, no. 0, pp. 1195 \u2013 1204, 2012, transport Research Arena 2012.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Personal intelligent travel assistants", "author": ["C. Chorus", "H. Timmermans"], "venue": "A handbook of transport Economics, A. Palma, R. Lindsey, E. Quinet, and R. Vickerman, Eds. Edward Elgar Publishing, 2011, pp. 604\u2013623.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Toward personalized, context-aware routing", "author": ["B. Yang", "C. Guo", "Y. Ma", "C.S. Jensen"], "venue": "The International Journal on Very Large Data Bases, vol. 24, no. 2, pp. 297\u2013318, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Personalized route recommendation using big trajectory data", "author": ["J. Dai", "B. Yang", "C. Guo", "Z. Ding"], "venue": "31st IEEE International Conference on Data Engineering, ICDE 2015, Seoul, South Korea, April 13-17, 2015. IEEE, 2015, pp. 543\u2013554.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Adaptive route choice model for intelligent route guidance using a rule-based approach", "author": ["K. Park", "M. Bell", "I. Kaparias", "K. Bogenberger"], "venue": "Transportation Research Record, vol. 2000, no. 1, pp. 88\u201397, Jan. 2007.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2000}, {"title": "Discrete Choice Models with simulation", "author": ["K. Train"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "A real-time personalized route recommendation system for self-drive tourists based on vehicle to vehicle communication", "author": ["L. Liu", "J. Xu", "S.S. Liao", "H. Chen"], "venue": "Expert Systems with Applications, vol. 41, no. 7, pp. 3409 \u2013 3417, 2014.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Mobile recommender systems in tourism", "author": ["D. Gavalas", "C. Konstantopoulos", "K. Mastakas"], "venue": "vol. 39, pp. 319\u2013333, 2014.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Where to: Crowd-aided Path Selection", "author": ["C.J. Zhang", "Y. Tong", "L. Chen"], "venue": "Proceedings of the Very Large Data Bases (VLDB) Endowment, vol. 7, no. 14, pp. 2005\u20132016, Oct. 2014.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Crowd- Planner: A crowd-based route recommendation system", "author": ["H. Su", "K. Zheng", "J. Huang", "T. Liu", "H. Wang", "X. Zhou"], "venue": "IEEE 30th International Conference on Data Engineering, Chicago, ICDE 2014, IL, USA, March 31 - April 4, 2014. IEEE, 2014, pp. 1178\u20131181.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Bounded Rationality, Ambiguity, and the Engineering of Choice", "author": ["J.G. March"], "venue": "The Bell Journal of Economics, vol. 9, no. 2, pp. 587\u2013608, 1978.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1978}, {"title": "Adapting to a Realistic Decision Maker: Experiments towards a Reactive Multi-objective Optimizer", "author": ["P. Campigotto", "A. Passerini"], "venue": "Learning and Intelligent Optimization, 4th International Conference, LION 4, Venice, Italy, January 18-22, 2010. Selected Papers, 2010, pp. 338\u2013341.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Real-time Multiattribute Bayesian Preference Elicitation with Pairwise Comparison Queries", "author": ["S. Guo", "S. Sanner"], "venue": "Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2010, Chia Laguna Resort, Sardinia, Italy, May 13-15, 2010, 2010, pp. 289\u2013296.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Brain-Computer Evolutionary Multiobjective Optimization: A Genetic Algorithm Adapting to the Decision Maker", "author": ["R. Battiti", "A. Passerini"], "venue": "IEEE Transactions on Evolutionary Computation, vol. 14, no. 5, pp. 671\u2013687, 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Eliciting Single-Peaked Preferences Using Comparison Queries", "author": ["V. Conitzer"], "venue": "Journal of Artificial Intelligence Research (JAIR), vol. 35, pp. 161\u2013191, 2009.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Making Rational Decisions Using Adaptive Utility Elicitation", "author": ["U. Chajewska", "D. Koller", "R. Parr"], "venue": "Proceedings of the Seventeenth  11 National Conference on Artificial Intelligence and Twelfth Conference on on Innovative Applications of Artificial Intelligence. AAAI Press / The MIT Press, 2000, pp. 363\u2013369.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Transport Systems Analysis: Model and Applications, ser", "author": ["E. Cascetta"], "venue": "Optimization and Its Applications. Springer,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "How to Analyze Paired Comparison Data", "author": ["K. Tsukida", "M.R. Gupta"], "venue": "Washington University, Dep. of Electrical Engineering, Seattle, USA, Tech. Rep. No. UWEETR-2011- 004, May 2011, (as of July 2014). [Online]. Available: http://www.ee.washington.edu/research/guptalab/publications/ PairedComparisonTutorialTsukidaGuptaUWTechReport2011.pdf", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Bayesian and L1 Approaches for Sparse Unsupervised Learning", "author": ["S. Mohamed", "K. Heller", "Z. Ghahramani"], "venue": "Proceedings of the 29th International Conference on Machine Learning (ICML-12), ser. ICML \u201912, J. Langford and J. Pineau, Eds. New York, NY, USA: Omnipress, July 2012, pp. 751\u2013758.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficiently learning the preferences of people", "author": ["A. Birlutiu", "P. Groot", "T. Heskes"], "venue": "Machine Learning, pp. 1\u201328, May 2012.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2012}, {"title": "On the way to a multimodal energy-efficient route", "author": ["M. Prandtstetter", "M. Straub", "J. Puchinger"], "venue": "Industrial Electronics Society, IECON 2013-39th Annual Conference of the IEEE. IEEE, 2013, pp. 4779\u20134784.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2006}, {"title": "Ties in paired-comparison experiments: A generalization of the Bradley-Terry model", "author": ["P.V. Rao", "L.L. Kupper"], "venue": "Journal of the American Statistical Association, vol. 62, pp. 194\u2013204, 1967.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1967}, {"title": "Combining preference and absolute judgements in a crowd-sourced setting", "author": ["Peng Ye", "D. Doermann"], "venue": "June 2013, ICML\u201913 workshop: Machine Learning Meets Crowdsourcing.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning from Hints", "author": ["Y.S. Abu-Mostafa"], "venue": "Journal of Complexity, vol. 10, no. 1, pp. 165 \u2013 178, 1994. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0885064X84710077", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1994}, {"title": "Preference Elicitation For General Random Utility Models", "author": ["L.X. Hossein Azari Soufiani", "David C. Parkes"], "venue": "Proceedings of the Twentyeighth Conference on Uncertainty in Artificial Intelligence (UAI-13), Bellevue, WA, USA, 2013, pp. 596\u2013605.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "[1], [2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1], [2]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 2, "context": "), transportation options, home location and workplace location or other significant places (location of school or grocery shop) such that at stage two routing decisions in the form of binary comparisons (route A or route B?) can be provided that the user relates to in artificial but realistic stated-preference-off-revealed-preference [3] type questions.", "startOffset": 337, "endOffset": 340}, {"referenceID": 3, "context": ", [4] or [5]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 4, "context": ", [4] or [5]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 5, "context": "\u2022 the proposal of an overall framework for devising a route recommendation system adapting to the stated and revealed preferences of its users including initialization procedures; \u2022 the proposal of a particular transfer learning [6] strategy in order to obtain good predictions based on only a small number of test questions; \u2022 the investigation of the achievable accuracy as a function of the number of test questions asked.", "startOffset": 229, "endOffset": 232}, {"referenceID": 6, "context": "This is followed by the experimental evaluation of FAVOUR and the comparison with two benchmarking algorithms from the literature: the likelihood-maximization approach from [7] and the state-of-the-art personalized route-recommendation technique introduced in [1].", "startOffset": 173, "endOffset": 176}, {"referenceID": 0, "context": "This is followed by the experimental evaluation of FAVOUR and the comparison with two benchmarking algorithms from the literature: the likelihood-maximization approach from [7] and the state-of-the-art personalized route-recommendation technique introduced in [1].", "startOffset": 260, "endOffset": 263}, {"referenceID": 1, "context": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11].", "startOffset": 134, "endOffset": 137}, {"referenceID": 7, "context": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11].", "startOffset": 139, "endOffset": 142}, {"referenceID": 8, "context": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11].", "startOffset": 144, "endOffset": 147}, {"referenceID": 9, "context": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11].", "startOffset": 149, "endOffset": 153}, {"referenceID": 10, "context": "The quest for personalized routing systems based on traveler preferences has been highlighted in the transportation system literature [2], [8], [9], [10], [11].", "startOffset": 155, "endOffset": 159}, {"referenceID": 8, "context": "In [9] a willingness-to-pay model is estimated.", "startOffset": 3, "endOffset": 6}, {"referenceID": 11, "context": "Methods generating personalized-route recommendations for drivers are presented also in [12], [10], [11].", "startOffset": 88, "endOffset": 92}, {"referenceID": 9, "context": "Methods generating personalized-route recommendations for drivers are presented also in [12], [10], [11].", "startOffset": 94, "endOffset": 98}, {"referenceID": 10, "context": "Methods generating personalized-route recommendations for drivers are presented also in [12], [10], [11].", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "Unlike FAVOUR, papers [10], [11] do not consider multimodal transportation and focus on route suggestions for drivers only.", "startOffset": 22, "endOffset": 26}, {"referenceID": 10, "context": "Unlike FAVOUR, papers [10], [11] do not consider multimodal transportation and focus on route suggestions for drivers only.", "startOffset": 28, "endOffset": 32}, {"referenceID": 6, "context": "In [7] a system of semantically-enriched personalized public-transport routing is presented.", "startOffset": 3, "endOffset": 6}, {"referenceID": 12, "context": ", [13]) are exploited to generate personalized public-transport route", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": ", in [14], which introduces a personalized-route recommendation system for tourists.", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "The main conclusion of the survey [16] particularly related to tourism applications is that a main open questions consists of the representation, estimation and assessment of individual preferences.", "startOffset": 34, "endOffset": 38}, {"referenceID": 15, "context": "Recently, crowd-based route-recommendation systems have also been proposed [17], [18].", "startOffset": 75, "endOffset": 79}, {"referenceID": 16, "context": "Recently, crowd-based route-recommendation systems have also been proposed [17], [18].", "startOffset": 81, "endOffset": 85}, {"referenceID": 1, "context": "The work closest to FAVOUR is the strategy described in the recent paper [2] using the methods of [1].", "startOffset": 73, "endOffset": 76}, {"referenceID": 0, "context": "The work closest to FAVOUR is the strategy described in the recent paper [2] using the methods of [1].", "startOffset": 98, "endOffset": 101}, {"referenceID": 0, "context": "The experiments reported in [1] show that the Bayesian approach can learn the preferences of the users, in the case of simulated choice scenarios with three different transportation alternatives (public transport, car, public trans-", "startOffset": 28, "endOffset": 31}, {"referenceID": 5, "context": "That is, transfer learning, which has been shown to provide added benefits when solving a series of related problems [6], can improve", "startOffset": 117, "endOffset": 120}, {"referenceID": 17, "context": "A personalized situation-aware routing service faces several challenges in terms of interaction with the users, stemming from the bounded rationality of the humans when making decisions [19]: 1) robustness to noisy feedback [20], [21].", "startOffset": 186, "endOffset": 190}, {"referenceID": 18, "context": "A personalized situation-aware routing service faces several challenges in terms of interaction with the users, stemming from the bounded rationality of the humans when making decisions [19]: 1) robustness to noisy feedback [20], [21].", "startOffset": 224, "endOffset": 228}, {"referenceID": 19, "context": "A personalized situation-aware routing service faces several challenges in terms of interaction with the users, stemming from the bounded rationality of the humans when making decisions [19]: 1) robustness to noisy feedback [20], [21].", "startOffset": 230, "endOffset": 234}, {"referenceID": 19, "context": "The typical human decision-making process is characterized by imprecision, contradictions, and changes of judgement over time; 2) low cognitive load of the user [21], [22], [23], [24].", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "The typical human decision-making process is characterized by imprecision, contradictions, and changes of judgement over time; 2) low cognitive load of the user [21], [22], [23], [24].", "startOffset": 167, "endOffset": 171}, {"referenceID": 21, "context": "The typical human decision-making process is characterized by imprecision, contradictions, and changes of judgement over time; 2) low cognitive load of the user [21], [22], [23], [24].", "startOffset": 173, "endOffset": 177}, {"referenceID": 22, "context": "The typical human decision-making process is characterized by imprecision, contradictions, and changes of judgement over time; 2) low cognitive load of the user [21], [22], [23], [24].", "startOffset": 179, "endOffset": 183}, {"referenceID": 19, "context": "Therefore, quantitative feedback from the user is not suitable in the context of a traveling information system; 3) real-time constraints [21].", "startOffset": 138, "endOffset": 142}, {"referenceID": 1, "context": "Based on this rough first guess stated preference questions in the form of realistic routing situations are asked in the second stage using the knowledge from the first stage, as is usual for personalized route recommendation systems [2], [1].", "startOffset": 234, "endOffset": 237}, {"referenceID": 0, "context": "Based on this rough first guess stated preference questions in the form of realistic routing situations are asked in the second stage using the knowledge from the first stage, as is usual for personalized route recommendation systems [2], [1].", "startOffset": 239, "endOffset": 242}, {"referenceID": 21, "context": "Comparison queries are well-known in the preference learning literature to be much more affordable for the users than quantitative judgements [23].", "startOffset": 142, "endOffset": 146}, {"referenceID": 24, "context": "Other choices such as the probit model are possible and straightforward to include, however, as the performance of probit and logit models for binary choice is comparable [26], we here opt for the computationally simpler logit model.", "startOffset": 171, "endOffset": 175}, {"referenceID": 25, "context": "More sophisticated approximate inference techniques exist [27] to handle multimodal posteriors.", "startOffset": 58, "endOffset": 62}, {"referenceID": 26, "context": ", the exponential distribution for positively-constrained weights [28]), in this work, for computational reasons, we constrain the posterior mean to lie in a box-bounded set by restricting the maximization of the log-posterior log p(T |w) + log p(w) + c(T ).", "startOffset": 66, "endOffset": 70}, {"referenceID": 5, "context": "learning [6] in the machine-learning community.", "startOffset": 9, "endOffset": 12}, {"referenceID": 27, "context": "troduced in [29] is adopted.", "startOffset": 12, "endOffset": 16}, {"referenceID": 27, "context": "In [29], an iterative procedure is introduced to refine the learned MPP, which is described in the form of a pseudo-code in Fig.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "As the algorithm is guaranteed to converge [29], the process will stop.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "VI-D; \u2022 the state-of-the-art of route-recommendation system [1] discussed in the related work section.", "startOffset": 60, "endOffset": 63}, {"referenceID": 0, "context": "preference (SP) survey in line with common practice in the literature [1], [2].", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "preference (SP) survey in line with common practice in the literature [1], [2].", "startOffset": 75, "endOffset": 78}, {"referenceID": 28, "context": "For the individual modes, the multimodal router Ariadne [30] using real-world real-time travel-times is exploited.", "startOffset": 56, "endOffset": 60}, {"referenceID": 29, "context": "(8) consists of replacing the logistic with the probit sigmoid [31], as convolving a probit sigmoid with a Gaussian results in another probit sigmoid.", "startOffset": 63, "endOffset": 67}, {"referenceID": 6, "context": "For a learning algorithm alternative to the one of FAVOUR, we follow the methodology of [7], applying the idea of individual level parameters in mixed logit models [13].", "startOffset": 88, "endOffset": 91}, {"referenceID": 12, "context": "For a learning algorithm alternative to the one of FAVOUR, we follow the methodology of [7], applying the idea of individual level parameters in mixed logit models [13].", "startOffset": 164, "endOffset": 168}, {"referenceID": 0, "context": "4: Learning curves for the different algorithms: the FAVOUR algorithm with MPP (solid curve, \u2018o\u2019) or without (solid curve, \u2018x\u2019), the mixed logit model (ALT, dashed curve), and the simulation of the algorithm [1] (solid curve, diamond markers).", "startOffset": 208, "endOffset": 211}, {"referenceID": 0, "context": "Our experimental evaluation is concluded by the empirical comparison between FAVOUR and the closest state-of-the-art approach introduced in [1].", "startOffset": 140, "endOffset": 143}, {"referenceID": 0, "context": "For this purpose, the approach in [1] is simulated by using a maximum-likelihood method to generate the weight vector representing the mass preferences and a vector of values quantifying the uncertainty about the", "startOffset": 34, "endOffset": 37}, {"referenceID": 0, "context": "by a comparison with a non-Bayesian transfer-learning technique and with a state-of-the-art route-recommendation system [1].", "startOffset": 120, "endOffset": 123}, {"referenceID": 30, "context": "the presented solutions, which generates ties in route rankings [32].", "startOffset": 64, "endOffset": 68}, {"referenceID": 31, "context": "Furthermore, ranking information may be combined with decision maker (DM) absolute judgements [33], which may discard un-satisficing routes or provide hints [34] to the search process.", "startOffset": 94, "endOffset": 98}, {"referenceID": 32, "context": "Furthermore, ranking information may be combined with decision maker (DM) absolute judgements [33], which may discard un-satisficing routes or provide hints [34] to the search process.", "startOffset": 157, "endOffset": 161}, {"referenceID": 33, "context": ", [35] for a recent one) for this purpose.", "startOffset": 2, "endOffset": 6}, {"referenceID": 9, "context": "The integration of real-time traffic information with customized route recommendations [10], [14] is another interesting line of research, since real-time traffic information influences the travelers decisions [10].", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "The integration of real-time traffic information with customized route recommendations [10], [14] is another interesting line of research, since real-time traffic information influences the travelers decisions [10].", "startOffset": 93, "endOffset": 97}, {"referenceID": 9, "context": "The integration of real-time traffic information with customized route recommendations [10], [14] is another interesting line of research, since real-time traffic information influences the travelers decisions [10].", "startOffset": 210, "endOffset": 214}], "year": 2016, "abstractText": "Route choice in multimodal networks shows a considerable variation between different individuals as well as the current situational context. Personalization and situation awareness of recommendation algorithms are already common in many areas, e.g., online retail. However, most online routing applications still provide shortest distance or shortest traveltime routes only, neglecting individual preferences as well as the current situation. Both aspects are of particular importance in a multimodal setting as attractivity of some transportation modes such as biking crucially depends on personal characteristics and exogenous factors like the weather. As an alternative this paper introduces the FAVourite rOUte Recommendation (FAVOUR) approach to provide personalized, situation-aware route proposals based on three steps: first, at the initialization stage, the user provides limited information (home location, work place, mobility options, sociodemographics) used to select one out of a small number of initial profiles. Second, based on this information, a stated preference survey is designed in order to sharpen the profile. In this step a mass preference prior is used to encode the prior knowledge on preferences from the class identified in step one. And third, subsequently the profile is continuously updated during usage of the routing services. The last two steps use Bayesian learning techniques in order to incorporate information from all contributing individuals. The FAVOUR approach is presented in detail and tested on a small number of survey participants. The experimental results on this real-world dataset show that FAVOUR generates betterquality recommendations w.r.t. alternative learning algorithms from the literature. In particular the definition of the mass preference prior for initialization of step two is shown to provide better predictions than a number of alternatives from the literature.", "creator": "TeX"}}}