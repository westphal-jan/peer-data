{"id": "1603.01067", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2016", "title": "Modeling the Sequence of Brain Volumes by Local Mesh Models for Brain Decoding", "abstract": "we represent the sequence of fmri ( functional magnetic resonance imaging ) brain volumes recorded during a initial cognitive stimulus by a graph which consists of a set of local meshes. the corresponding cognitive process, encoded in the brain, is then represented by these meshes each of which is estimated assuming a linear relationship among the voxel time series in assessing a predefined locality. first, we define the concept equation of locality in two neighborhood systems, namely, the spatial and functional neighborhoods. then,, we construct spatially and functionally autonomous local meshes around each voxel, called seed voxel, by basically connecting it either to its spatial or functional p - nearest neighbors. the directional mesh formed around a voxel is a directed sub - graph with a star topology, where the gradient direction of the edges is taken towards the seed voxel at the center of the mesh. we represent the time series recorded at each seed voxel in terms of linear combination of the time series each of its p - nearest neighbors in the mesh. the relationships between a seed voxel and its neighbors are represented by the edge weights of each mesh, and are estimated by solving properly a linear regression equation. the estimated mesh edge weights lead to a better representation of information in the brain for encoding and decoding of the cognitive tasks. we test our model on a visual object recognition and emotional memory retrieval experiments using support vector machines that are trained using the mesh edge weights as features. in the experimental analysis, we observe that the edge weights of the spatial and functional meshes perform better than the state - of - the - art brain decoding models.", "histories": [["v1", "Thu, 3 Mar 2016 12:06:00 GMT  (6690kb,D)", "http://arxiv.org/abs/1603.01067v1", "13 pages, 10 figures, submitted to JSTSP Special Issue on Advanced Signal Processing in Brain Networks"]], "COMMENTS": "13 pages, 10 figures, submitted to JSTSP Special Issue on Advanced Signal Processing in Brain Networks", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["itir onal", "mete ozay", "eda mizrak", "ilke oztekin", "fatos t yarman vural"], "accepted": false, "id": "1603.01067"}, "pdf": {"name": "1603.01067.pdf", "metadata": {"source": "CRF", "title": "Modeling the Sequence of Brain Volumes by Local Mesh Models for Brain Decoding", "authors": ["Itir Onal", "Eda Mizrak", "Ilke Oztekin", "Fatos T. Yarman"], "emails": ["itir@ceng.metu.edu.tr", "vural@ceng.metu.edu.tr", "ozay.mete.b4@tohoku.ac.jp", "ioztekin}@ku.edu.tr"], "sections": [{"heading": null, "text": "First, we define the concept of locality in two neighborhood systems, namely, the spatial and functional neighborhoods. Then, we construct spatially and functionally local meshes around each voxel, called seed voxel, by connecting it either to its spatial or functional p-nearest neighbors. The mesh formed around a voxel is a directed sub-graph with a star topology, where the direction of the edges is taken towards the seed voxel at the center of the mesh. We represent the time series recorded at each seed voxel in terms of linear combination of the time series of its p-nearest neighbors in the mesh. The relationships between a seed voxel and its neighbors are represented by the edge weights of each mesh, and are estimated by solving a linear regression equation. The estimated mesh edge weights lead to a better representation of information in the brain for encoding and decoding of the cognitive tasks. We test our model on a visual object recognition and emotional memory retrieval experiments using Support Vector Machines that are trained using the mesh edge weights as features. In the experimental analysis, we observe that the edge weights of the spatial and functional meshes perform better than the state-of-the-art brain decoding models.\nKeywords\u2014fMRI; voxel connectivity; brain decoding; object recognition; classification\nI. INTRODUCTION\nFunctional Magnetic Resonance Imaging (fMRI) is used as the primary modality to capture neural activations in the brain due to its high spatial resolution and reasonable temporal resolution [1]. It measures the Blood Oxygenation Level Dependent (BOLD) responses to a stimulus for about 10-12 seconds in an event-related design experiment. This approach generates a brain volume for approximately each time instance. The smallest unit of this volume, called voxel, consists of the time series of intensity values which approximate the hemodynamic response (HDR).\nThe techniques employed to learn the brain activity patterns from the BOLD signals are called Multi Voxel Pattern Analysis\nI. Onal and F. T. Yarman Vural are with the Department of Computer Engineering, Middle East Technical University, Ankara, Turkey. e-mails: {itir,vural}@ceng.metu.edu.tr\nM. Ozay is with Graduate School of Information Sciences,Tohoku University,Sendai, Miyagi, Japan. e-mail: ozay.mete.b4@tohoku.ac.jp\nE. Mizrak and I. Oztekin are with Department of Psychology, Koc University, Istanbul, Turkey. e-mails: {emizrak, ioztekin}@ku.edu.tr\n(MVPA). Following the pioneering study of Haxby et al. [2], machine learning techniques have been used for MVPA for diagnosing disorders [3], [4], hypothesis validation [5] and classifying cognitive states which is a method for predicting cognitive states called brain decoding. In the context of machine learning, encoding the brain activities is formalized by training a classifier using a training set of fMRI measurements, whereas a cognitive state is decoded by assigning a label to a test fMRI measurement recorded during one of the prescribed cognitive stimuli.\nIn state-of-the-art MVPA approaches, cognitive states are usually represented by concatenating the selected voxel intensity values to construct a vector in a feature space. The time series recorded for each voxel can be represented by various methods, such as computing maximal or mean values. Also, some of the inactive voxels can be eliminated by Principal Component Analysis, Independent Component Analysis, Searchlight and GLM analysis to reduce the dimension of the feature space. Then, a classifier such as Support Vector Machine (SVM), k-Nearest Neighbor (k-NN) or Naive Bayes is employed using the feature vectors.\nWhile some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding. A popular method for extracting a spatial feature for brain decoding from fMRI data is computing the average BOLD response for each voxel to represent a stimulus [6], [7], [8]. A recent work, suggested by [9], [10], considers each brain volume as a sample. On the other hand, Mitchell et al. [11] and Ng et al. [12] concatenate the BOLD responses within the same trial to extract features that include spatio-temporal information.\nIn order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions. Among these studies, Pantazatos et al. [13] model temporal relationships by using pairwise correlations between brain regions as features for brain decoding. Moreover, Richiardi et al. [14] model a functional connectivity graph using the pairwise correlations between brain regions, and they decode the brain states using graph matching algorithms. Also, edge weights of their proposed brain graphs are generally selected using the correlation between pairs of selected voxels, and vertices or edge weights of these brain graphs are used as features for cognitive state classification [18]. Contrary to the coarse-level functional connectivity, Firat\nar X\niv :1\n60 3.\n01 06\n7v 1\n[ cs\n.L G\n] 3\nM ar\n2 01\n6\n2 et al. [15] use pairwise correlations of voxels as features while Baldassano et al. [16] extract the functional connectivity structures by modeling pairwise connectivity among voxels. Also, a minimum spanning tree of a graph structure defined using a functional connectivity matrix is employed using all voxels for each stimulus for brain decoding [17]. Note that, the aforementioned temporal methods are designed to model only the pairwise relationships between voxels and employ these relationships for brain decoding. Although these methods represent the spatio-temporal information to a certain degree, none of them propose a model to formalize the relationships among the brain volumes, recorded along the time course of a cognitive stimulus. In other words, spatial models mostly lack the temporal information while the temporal ones lose the spatial relationships among the voxel BOLD responses.\nThe major motivation of this study follows the observations of the functional and spatial similarities of voxel BOLD responses in a pre-defined locality. As an example, Bazargani et al. [19] state that neighboring voxels belonging to a homogeneous ROI have Hemodynamic Response Function (HRF) with the same shape, possibly with slightly varying amplitude. In other words, spatially close voxels tend to give similar BOLD responses to the same stimuli. Moreover, Kriegeskorte et al. [20] report that a univariate model of activations fails to benefit from local spatial combination of signals, and performs worse than Searchlight methods for detection of informative regions. They observe that spatially remote voxels may also exhibit functionally similar time series.\nFurthermore, Ozay et al. [21] observe that the voxel time series do not differ significantly to discriminate the different cognitive states, but there exist slight variations among the voxel intensity values of voxels located in a spatial neighborhood. They propose a set of Local Meshes (LMM) to model the relationship among the spatially close voxels. They show that the LMM features perform better than the voxel intensity values for the classification of cognitive states. However, in [21], only the brain volume which is obtained 6 seconds after the stimulus presentation is used for the construction of a model while the remaining ones are discarded under the canonical HRF assumption.\nFinally, Firat et al. [22] propose a Functional Mesh Model (FMM) which is used to construct a set of local meshes by selecting the nearest neighbors of voxels defined within a functional neighborhood. Their experimental results show that their features are more discriminative than the features obtained within a spatial neighborhood. Yet, they also estimate the mesh weights using only a single intensity value for each voxel.\nIn none of the above mentioned models, the time series recorded at all the voxels are fully employed to represent the spatial relationships among the voxels of the fMRI data. The available approaches either use the active voxels, the most crucial time instances or both. Although these approaches smooth the noise in voxel time series, and represent the huge amount of data in a more compact way, it may result in losing important information embedded in time series of brain volumes, recorded under a stimulus.\nThe massively interconnected and dynamic nature of human\nbrain cannot be represented by considering only a collection of selected voxels and/or time instances which are obtained from fMRI data. In addition, the above mentioned studies indicate that the relationship among the voxels is more informative than the information provided by the individual voxels. Therefore, it is desirable to develop a model which represents the relationship among the brain volumes, recorded during a stimulus. Furthermore, if this model incorporates the local similarities among the voxel time series, then it is possible to represent the sequence of brain volumes, recorded during a cognitive stimulus, by a graph which consists of a set of subgraphs each of which is represented by a local linear regression model.\nIn this study, we employ the voxel time series measured during a cognitive task to create a local mesh around each voxel which models the relationship among the BOLD responses. The concept of locality is defined over a neighborhood system. In this study, we introduce two types of neighborhoods, namely, spatial and functional neighborhoods. The local mesh around each voxel is constructed by using either a spatial [23] or functional neighborhood system to generate a set of spatially or functionally local meshes. We form a local mesh around each voxel by connecting the voxel to its p-nearest neighbors under a star topology. In each mesh, BOLD response of a voxel is represented by a weighted linear combination of BOLD responses of its spatially or functionally nearest neighbors. The weights are estimated by solving a linear regression equation, and are assigned to the edges of the mesh. The mesh edge weights estimated for each voxel enable us to represent the fMRI brain volumes recorded during a stimulus by a directed graph which consists of an ensemble of local meshes.\nThe proposed local mesh models are different from the connectivity models defined over pairwise similarities between voxels and/or regions in the sense that the connectivity is defined over a local neighborhood of voxels. We employ the estimated weights of mesh edges as features to train and test the state-of-the-art Support Vector Machines (SVM) for encoding and decoding a set of cognitive processes measured by fMRI signals.\nOur approach is employed for modeling the sequence of fMRI brain volumes, recorded during an event-related design experiment. We assume that the voxel time series approximate the hemodynamic response for each stimulus. Unfortunately, block design lacks this information due to the overlaps between consecutive hemodynamic responses. Therefore, we test our approach in two event-related design experiments namely visual object recognition and emotional memory retrieval experiments. We observe that the classifiers which employ the proposed local mesh ensembles outperform the state of the art MVPA models.\nIn Fig. 1, the steps of the proposed method are summarized. First, we preprocess the fMRI measurements and obtain voxel intensity values. Then, we select voxels or ROI to eliminate the redundant voxels and to reduce the noise in our dataset. After that, we define spatial and functional neighborhood systems, and construct meshes, accordingly. Finally, we estimate edge weights of meshes, and employ them as features for cognitive state classification.\n3 fMRI Measurement\nROI selection\nConstruction of\nspatial meshes\nConstruction of\nfunctional meshes\nEstimation of edge\nweights of meshes\nCognitive state classification\nusing edge weights\nPreprocessing\nVoxel selection\nfMRI Dataset\n(BOLD Responses)\nDefinition of spatial\nneighborhood\nDefinition of functional\nneighborhood\nFig. 1: The flowchart of the proposed approach for obtaining local meshes and classification of cognitive states."}, {"heading": "II. NEUROIMAGING DATA COLLECTION", "text": "A. Visual Recognition Experiment\nIn this experiment, fMRI measurements wee recorded while participants performed a one-back repetition detection task. The stimuli consisted of gray-scale images belonging to two categories, namely, birds and flowers. Each stimulus was presented for 4 seconds, and followed by a rest period of 8 seconds."}, {"heading": "B. Emotional Memory Retrieval Experiment", "text": "In this experiment, the stimuli consisted of two neutral (Kitchen utensils and Furniture) and two emotional (Fear and Disgust) categories of images. Each trial started with a 12 seconds fixation period followed by a 6 seconds encoding period. In the encoding period, participants were presented with 5 images from the same category, each image lasting 1200 on the screen. Following the fifth image, a 12 seconds delay period was presented in which participants solved three math problems consisting of addition or subtraction of two randomly selected two-digit numbers. Following the third math problem, a 2 seconds retrieval period started in which participants were presented with a test image from the same category and indicated whether the image was a member of the current study list or not. For a similar experimental setting, please refer to [24]. For classification, we employed measurements obtained during the encoding and retrieval phase as our training and test data, respectively."}, {"heading": "III. PRE-PROCESSING OF ANALYSIS OF NEUROIMAGING DATA", "text": "SPM8 was used for pre-processing and data analysis1. Preprocessing of images consisted of (a) correction of slice acquisition timing across slices, (b) realigning the images to the first volume in each fMRI run to correct for head movement, (c) normalization of functional and anatomical images to a standard template EPI provided by SPM2, and (d) smoothing images with a 6-mm full-width half-maximum isotropic Gaussian kernel. Finally, we extract 116 Automated Anatomical Labeling (AAL) regions [25] using Marsbar [26]. For the visual object recognition experiment, active voxels were identified using the General Linear Model implemented in SPM and occipital lobe was selected as our region of interest (ROI). The task engaged visual cortex activity, where pattern analyses were employed. For the emotional memory retrieval experiment we selected first 3000 most discriminative voxels from the whole brain analysis, using ReliefF [27].\nIn the visual object recognition experiment, 36 measurements are recorded in each of the 6 runs, and there are 216 samples. We design our datasets by taking the first 12 samples per each class from each run for training, and the last 6 samples per each class from each run for validation and testing. On the other hand, for the emotional memory retrieval experiment, 35 measurements are recorded within each run. Measurements recorded during the encoding phase are employed as training data and the ones obtained during retrieval phase are used as validation and test data."}, {"heading": "IV. SPATIAL AND FUNCTIONAL LOCAL MESHES", "text": "The local mesh model proposed in this study is constructed using a collection of voxels located within a neighborhood of each voxel. For this purpose, first we make a formal definition of locality. This task is achieved by defining spatial and functional neighborhood systems. Then, we define two types of local meshes, namely, spatial and functional meshes.\nIn the following sub-sections, we provide the formal definition of neighborhood systems and local meshes."}, {"heading": "A. Neighborhood Systems", "text": "One of the most important tasks of this study is to construct a linear relationship among the BOLD responses of voxels by employing \u201clocality\u201d properties of the voxels. In order to achieve this goal, we define two types of neighborhood systems, namely, spatial and functional neighborhoods.\nDefinition 1: Spatial Neighborhood: Let V = {vj} be a set of nodes each of which corresponds to a voxel located at a coordinate l\u0304j . Spatially nearest neighbor of a voxel vj is defined as the voxel vk which has the smallest Euclidean distance to the seed voxel vj , as given below:\n\u03b7spat1 [vj ] = {vk : \u2016l\u0304j \u2212 l\u0304k\u2016 \u2264 \u2016l\u0304j \u2212 l\u0304o\u2016,\u2200l\u0304o}. (1)\n1http://www.fil.ion.ucl.ac.uk/spm/\n4 (a) An ensemble of spatially local meshes. (b) An ensemble of functionally local meshes.\nFig. 2: Ensemble of meshes formed using (a) spatial neighbors and (b) functional neighbors of seed voxels. In both of the ensembles, the voxels denoted with red color are the seed voxels. Orange voxels denote the spatially nearest neighbors of the red voxel in (a), and the functionally nearest neighbors of the red voxel in (b). Green voxels are the spatially nearest neighbors of the corresponding orange voxels in (a), and functionally nearest neighbors of the corresponding orange voxels in (b). Only the highest edge weights are displayed for simplicity.\np-spatially nearest neighbors of voxel vj located at l\u0304j are defined recursively as\n\u03b7spatp [vj ] = {vk \u222a \u03b7 spat p\u22121 [vj ] : \u2016l\u0304j \u2212 l\u0304k\u2016 \u2264 \u2016l\u0304j \u2212 l\u0304o\u2016,\n\u2200vo \u2208 \u03b7spatp\u22121 [vj ]c}, (2)\nwhere \u03b7spatp\u22121 [vj ] c is the set complement of the set \u03b7spatp\u22121 [vj ].\nIn the above definition of p-spatially nearest neighborhood, when p = 6, 6-nearest neighbors of a voxel correspond to the adjacent voxels at the right, left, up, down, front and back of that voxel (see Fig. 2a). As we increase p, the set of the neighboring voxels gets larger. The voxels which are adjacent to the nearest neighbors are included recursively, with an increasing p.\nDefinition 2: Functional Neighborhood: Let R(vj) denote the vector with the entries of BOLD signal measurements at voxel vj which are recorded as the response of a series of stimulus during the entire experiment. A functionally nearest neighbor of a voxel vj , is defined as the voxel vk when the vector R(vk) is maximally correlated with R(vj) measured at voxel vj . In order to find the functionally nearest neighbor of a voxel vj , Pearson correlation between R(vj) and R(vk) is computed for all the voxels vk in the brain volume using the following criterion:\ncor(R(vj), R(vk)) = cov(R(vj), R(vk))\n\u03c3(R(vj))\u03c3(R(vk)) , (3)\nwhere covariance between responses R(vj) and R(vk) is,\ncov(R(vj), R(vk)) = 1\nN \u2217D \u2217\u2211\n\u2200i,d\n( v(si, td, l\u0304j)\u2212 \u00b5(R(vj)) ) \u2217 ( v(si, td, l\u0304k)\u2212 \u00b5(R(vk)) ) .\n(4)\nand standard deviation of response \u03c3(R(vj)) is defined as\n\u03c3(R(vj)) = \u221a\u2211 \u2200i,d ( v(si, td, l\u0304j)\u2212 \u00b5(R(vj) )2 ; (5)\nand mean of response \u00b5(R(vj) is defined as\n\u00b5(R(vj)) = 1 N \u2217D \u2211 \u2200i,d v(si, td, l\u0304j); (6)\nThen, a functionally nearest neighbor of a voxel vj is defined as:\n\u03b7func1 [vj ] = {vk : cor(R(vj), R(vk)) \u2264 cor(R(vj), R(vo)), \u2200vo}. (7)\nFinally, p-functionally nearest neighbors of the voxel vj is recursively defined as follows;\n\u03b7funcp [vj ] = {vk \u222a \u03b7 func p\u22121 [vj ] :\ncor(R(vj), R(vk)) \u2264 cor(R(vj), R(vo)),\u2200vo \u2208 \u03b7funcp\u22121 [vj ]c}. (8)\nTo this end, we select the functional neighbors of the voxel vj as the voxels having p of the highest Pearson correlation with that voxel.\nNote that functionally p-nearest neighbors of a voxel may or may not be the same as the spatially p-nearest neighbors. Practical evidence indicates that most of the spatially close voxels are also functionally close, i.e., they are highly correlated. However, some of the voxel pairs are spatially far apart, yet they are functionally close to each other (see Fig. 2b)."}, {"heading": "B. Construction of Local Meshes", "text": "Based upon the neighborhood systems introduced in the previous section, the concept of locality is represented by\n5\na set of meshes defined over a sequence of brain volumes. For this purpose, two types of meshes, namely, spatially and functionally local meshes, are established.\nBoth types of meshes are constructed around each voxel of the brain volume using a predefined neighborhood system. Once we select the neighborhood system, we form a local mesh around each voxel by connecting the voxel to its pnearest neighboring voxels in a star topology. The voxel located at the center of a mesh is called the seed voxel. If a voxel resides within the neighborhood of a seed voxel, then we connect it to the seed voxel with an edge, directed towards the seed voxel. As the name implies, the spatially local meshes are constructed by using the p-spatially nearest neighbors, whereas the functionally local meshes are constructed by using the pfunctional nearest neighbors of the seed voxels. Since we form the meshes around all of the voxels in the brain volume, the meshes defined over a neighborhood system may overlap. A seed voxel in a mesh may become a neighboring voxel of a seed voxel in a different mesh.\nThe formal definition of the local meshes are given below: Definition 3: Spatially Local Meshes (SLM): For each voxel vj in the brain volume, a spatially local mesh, formed around that voxel, called the seed voxel, is defined as a directed graphMspatj = (V spat j , E spat jk ) where V spat j = {vj\u222a\u03b7spatp [vj ]} represents a set of the nodes of the mesh, and\nEspatj = {ejk : \u2200vk \u2208 \u03b7 spat p [vj ]}\nrepresents the edges formed between the seed voxel vj of the mesh Mspatj and its p-spatially nearest neighbors. The\ndirection of the edges is taken towards the seed voxel (see Fig. 3).\nDefinition 4: Functionally Local Meshes (FLM): For each voxel vj in the brain volume, a functionally local mesh which is constructed around that voxel is defined as a directed graph Mfuncj = (V func j , E func jk ) where V func j = {vj \u222a \u03b7funcp [vj ]} represents a set of the nodes of the mesh, and\nEfuncj = {ejk : \u2200vk \u2208 \u03b7 func p [vj ]}\nrepresents the edges formed between vj and its p-functionally nearest neighbors (see Fig. 4).\nNotice that, for both neighborhood systems, a seed voxel located at the center of a mesh becomes a neighboring voxel in another mesh. Therefore, there may be two directed edges between two neighboring voxels, vj and vk, in opposite directions. The edge weights in each mesh are estimated by minimizing the mean square error of a linear model, as will be explained in the next section. In the proposed linear model, the seed voxel is represented in terms of linear combination of its p-nearest neighbors. The same star topology is defined for all meshes and employed in the experiments with a fixed mesh size p. In other words, the voxels and the edges formed between them in a mesh do not change in time. However, the weights of nodes which correspond to the intensity values measured for each entry of the time-series representing the BOLD response, change in time. Since we estimate a set of edge weights for each cognitive stimulus, the edges remain the same for the duration of a stimulus and only changes across the stimuli.\n6\nThe size of each mesh is defined by the order of the neighborhood system, p. As p gets larger, the size of a mesh constructed around each voxel increases, resulting in more and more overlaps among the meshes. Therefore, p can be considered as a measure of the degree of locality of the proposed mesh model where we represent the BOLD response of a seed voxel as the linear combination of the BOLD responses of the neighboring voxels of the seed voxel.\nOnce we define a mesh around each voxel, we address the problem of estimating the edge weights. The proposed edge estimation method is explained next."}, {"heading": "C. Estimation of Edge Weights of Meshes", "text": "Suppose that we record the BOLD response at each voxel vj that is located at coordinate l\u0304j during a stimulus si in order to measure the brain activation for a predefined cognitive state with label c. We denote each intensity value of the BOLD response measured at a voxel vj at time instance td for a stimulus si as v(si, td, l\u0304j). For each stimulus presentation, we record D measurements at each voxel, where d = 1, 2, . . . , D.\nFor a given stimulus si, let us denote weight of an edge ej,k as wi(ejk). We approximate the weight of an edge wi(ejk) directed from a voxel vk to vj for stimulus si by estimating the value ai,j,k when vj is considered as the seed voxel of a mesh.\nWe estimate the edge weights for both spatially and functionally local meshes in the same way. First, we obtain a BOLD response vector r\u0304(si, l\u0304j) \u2208 RD by concatenating the\nvoxel intensity values v(si, td, l\u0304j), for all time instances that are recorded during a single stimulus, si, such that:\nr\u0304(si, l\u0304j) = [v(si, t1, l\u0304j), v(si, t2, l\u0304j), . . . , v(si, tD, l\u0304j)] T , (9)\nwhere d = 1, 2, . . . , D. When we concatenate the BOLD responses of all the stimuli, we obtain a vector of BOLD responses measured from a voxel vj for all training samples as follows;\nR(vj) = [r\u0304(s1, l\u0304j), r\u0304(s2, l\u0304j), . . . , r\u0304(sNtr , l\u0304j)], (10)\nwhere N tr denotes the number of training samples. Notice that R(vj) is used to find the p-functionally nearest neighbors (see (3)).\nWe estimate the edge weights of a mesh formed around a voxel vj located at coordinate lj for a stimulus si by a linear model formed among the BOLD response of a seed voxel of the mesh r\u0304(si, l\u0304j), and the BOLD responses of its p-nearest neighbors {r\u0304(si, l\u0304k) : vk \u2208 \u03b7p[vj ]} as follows;\nr\u0304(si, l\u0304j) = \u2211\nvk\u2208\u03b7p[vj ]\nai,j,k r\u0304(si, l\u0304k) + \u03b5\u0304i,j , (11)\nwhere \u03b5\u0304i,j is an error vector defined as\n\u03b5\u0304i,j = (\u03b5i,1,j , \u03b5i,2,j , . . . , \u03b5i,K,j) T . (12)\nNotice that \u03b7p corresponds to \u03b7spatp if BOLD meshes are formed considering spatial neighborhood, and corresponds to \u03b7funcp if the meshes are formed considering functional neighborhood.\n7 In (11), a BOLD response obtained from a seed voxel, r\u0304(si, l\u0304j), is modeled using a weighted linear combination of the BOLD responses obtained from its p-nearest neighbors. A weight ai,j,k represents the relationship between responses obtained from a seed voxel vj and a neighboring voxel at vk. In addition, each entry v(si, td, l\u0304j) of r\u0304(si, l\u0304j) is represented by the same weighted combination of its neighboring entries v(si, td, l\u0304k) of r\u0304(si, l\u0304k) in (11). Therefore, (11) can be equivalently represented as follows:\n v(si, t1, l\u0304j) v(si, t2, l\u0304j)\n... v(si, tD, l\u0304j)\n = \u2211 l\u0304b\u2208\u03b7p ai,j,k  v(si, t1, l\u0304k) v(si, t2, l\u0304k)\n... v(si, tD, l\u0304k)\n+  \u03b5i,1,j \u03b5i,2,j\n... \u03b5i,D,j  . (13)\nThe weights ai,j,k of a mesh edge ej,k, \u2200vk \u2208 \u03b7p[vj ], are estimated by minimizing the expected square error defined as\nE ( (\u03b5\u0304i,j) 2 ) = E  r\u0304(si, l\u0304j)\u2212 \u2211\nvk\u2208\u03b7p\nai,j,k r\u0304(si, l\u0304k) 2  , (14)\nwhere E(\u00b7) is the expectation operator applied over the time elapse of a BOLD response corresponding to a stimulus period D. We compute an edge vector a\u0304i,j = [ai,j,1, ai,j,2, . . . , ai,j,p] using ridge regression as\na\u0304i,j = (Q T i,jQi,j + \u03bbI) \u22121QTi,j r\u0304(si, l\u0304j), (15)\nwhere \u03bb \u2208 R is a regularization parameter which is estimated during the training phase, and Qi,j is a D\u00d7p matrix consisting of BOLD responses obtained from p-nearest neighbors of a seed voxel vj during the presentation of sample si such that\nQi,j = [r\u0304(si, l\u0304k)], \u2200vk \u2208 \u03b7p[vj ]. (16)\nOne of the crucial tasks of forming local meshes is the identification of the degree of locality for each mesh. The number of the nearest neighbors, p, defines the size of each mesh. \u2022 For a spatially local mesh, when p is small, the seed voxel\nof the mesh is related only to a few very spatially close voxels. As we increase p, the mesh includes larger areas in the brain volume to take into account the contribution of distant voxels to the seed. \u2022 On the other hand, for a functionally local BOLD mesh, small p implies that only a few most correlated voxels are related to the seed voxel. As we increase the mesh size, we include the contribution of the voxels that are relatively less correlated to the seed voxel.\nIdentification of the \u201coptimal\u201d mesh size, p, is a crucial issue. In this study we optimize the mesh size using a validation set. This task can also be achieved by using an Information Theoretic function, such as Akaike\u2019s information criterion (AIC) [28], Bayesian Information Criterion (BIC) [29] or Rissannen\u2019s Minimum Description Length (MDL) [30] to estimate the model order. It is possible to define a different mesh size for each seed voxel by using one of the approaches mentioned above. The interested reader is referred to [31]. In\nthis study, we select a fixed mesh size for the entire brain volume, for each stimulus."}, {"heading": "V. CLASSIFICATION OF COGNITIVE STATES FOR BRAIN DECODING", "text": "The representation power of the proposed mesh ensemble is analyzed in the fMRI recordings during brain encoding and decoding tasks. For this purpose, we employ machine learning methods where encoding of a cognitive state is represented by the training phase and the decoding state corresponds to the recognition phase of a classification algorithm. The major question is then how well a cognitive state can be represented by the ensemble of meshes? The answer to this question can be partly observed from the performance of the classifier.\nRecall that for each cognitive stimulus si with a label c, we record a sequence of brain volumes, where the number of brain volumes D, in this sequence depends on the duration of the stimulus. This sequence of brain volumes is considered as one sample with a label c, in the training set. In order to represent a cognitive state corresponding to a stimulus si by the mesh ensembles, we estimate the edge weights of all local meshes extracted from the corresponding sequence of the brain volumes. The sequence of brain volumes recorded during the stimulus si is then represented by a brain graph, which consists of the ensemble of local meshes. Finally, each sample in the dataset is represented by a vector with the entries of the estimated mesh arc weights in the input space of a classifier.\nFormally speaking, for each sample si with label c, the edge weights a\u0304i,j \u2208 R1\u00d7p are used to construct a feature vector Fi = [a\u0304i,1, a\u0304i,2, . . . , a\u0304i,M ] by concatenating all edge vectors a\u0304i,j , \u2200j = 1, 2, . . . ,M , where M is the number of voxels. We denote a feature vector of a sample si belonging to training set as F tri , while F te i is a feature vector of a sample s \u2032 i belonging to test set. Then, we construct a set of features of training samples Str = {F tri }N tr\ni=1 and a set of features of test samples Ste = {F tei }N te\ni=1 to train and test the classifiers for classification of cognitive states."}, {"heading": "VI. BRAIN DECODING EXPERIMENTS PERFORMED ON THE FMRI DATASETS", "text": "In order to observe the validity of the proposed mesh models, we perform two groups of experiments. In the first group, we train and test a Support Vector Machine (SVM) classifier by using the labeled fMRI data recorded using the experimental setups explained in Section II. In this group of experiments, we examine the power of the models for representing brain encoding and decoding tasks. In the second group of experiments, we analyze the validity of the local meshes by exploring the similarities among the voxel time series in each mesh, and the distribution of the error of the proposed linear regression model."}, {"heading": "A. Comparison of the Spatial and Functional Mesh Models with State-of-the-Art Methods", "text": "In order to compare the proposed spatial and functional meshes with the state-of-the-art MVPA methods, we measure\n8\nthe encoding and decoding performances of the models. The encoding process is performed by training an SVM classifier with linear kernel, and decoding process corresponds to classification of an unknown stimulus with class label c. We perform seven sets of computer experiments on two different groups of fMRI datasets:\n\u2022 In the first and second set of experiments, we represent a cognitive stimulus using the spatial and functional meshes. The classification performances are measured by using the edge weights obtained using the spatially (SLM) and functionaly local mesh (FLM) models. \u2022 In the third and fourth set of experiments, we tested the classification performances by employing Local Mesh Model (LMM) and Functional Mesh Model(FMM). Recall that both LMM and FMM keep only a single value from the BOLD response for each voxel omitting the rest of the signals measured during a stimulus. \u2022 In the fifth group of experiments, we test the performance of SVM classifiers which employ features that are computed using pairwise Pearson correlation (FC-mesh). First, we compute the pairwise correlations between the voxel BOLD responses given by seed voxels and each of their p-nearest neighbors for each stimulus. In other words, first meshes are constructed around seed voxels, and then pairwise correlations are computed between voxel pairs within meshes instead of estimating the edge weights within a neighborhood. Then, we form our feature vector by concatenating the correlation values within all meshes. Note that, we obtain feature vectors whose sizes are equal to that of SLM and FLM by concatenating only the distances within meshes to make a fair comparison. \u2022 In the sixth set of experiments, we analyze the classification performance of the classifiers for the state-of-the-art MVPA methods in which raw voxel intensity values are used as features to train and test classifiers. For MVPApeak, we only used the third instance v(si, t3, l\u0304j) of a BOLD response r\u0304(si, l\u0304j) following our assumption that if a voxel becomes active, then its HRF reaches to its peak value after 5-6 seconds (around t3). On the other hand, MVPA-mean depicts the case where we employed the average of d measurements of r\u0304(si, l\u0304j). We also concatenate each of the d measurements of BOLD response {v(si, td, l\u0304j)}Dd=1 to obtain results for MVPA-all. The dimension of a feature vector constructed for MVPApeak and MVPA-mean equals to 1254 for visual object recognition experiment, and 3000 for emotional memory retrieval experiment. Moreover, since we concatenate all measurements for MVPA-all, the size of the feature vectors used for MVPA-all equals to d times the size of features vectors for MVPA-mean and MVPA-peak. \u2022 In the seventh set of experiments, we selected the surrounding voxels in the mesh as the random voxels to test the importance of locality. In LM-rand, we form meshes defined over a sequence of brain volumes with random voxels."}, {"heading": "B. Classification Results for Brain Decoding", "text": "We perform intra-subject classification using SVM classifiers, and features that are extracted from samples collected in the proposed visual object recognition experiment for five participants, and emotional memory retrieval experiment for thirteen participants. The same mesh size is used for each mesh that was computed using the data collected for the same participant.\nVisual Object Recognition Experiment: Table I provides the classification performance of SVM using the models described in the previous subsection. The regularization parameter \u03bb is selected experimentally as \u03bb = 0.5. We computed meshes using various mesh sizes p \u2208 P = {2, 3, . . . , 30}. In order to optimize the mesh size within this interval, we randomly split a part of test data as our validation set. We ensured that our validation and test sets are balanced. We selected the optimal mesh sizes as the ones that maximizes the validation performances.\nClassification results of visual object recognition experiment are given in Table I. Additionally, the performances obtained on test set using the optimal mesh size p\u0302 obtained from validation sets are given in Table I for each method employed by each classifier and for each participant. For example, we obtain 93% accuracy for FLM when the mesh size p\u0302 is 16 for the first participant P1. It can be observed that, the mesh size p\u0302 which leads to the maximum performance varies for different participants and methods. In addition, classifiers which employ the features extracted for FLM and SLM perform the best among others, where the features extracted for FLM perform slightly better than the features extracted for SLM. Note that, selecting random voxels in LM-rand performs worse than employing spatial or functional neighbors.\nEmotional Memory Retrieval Experiment: We provided results for 2-class and 4-class classification experiments. In these experiments, \u03bb is selected experimentally as \u03bb = 4, and we computed meshes with mesh sizes p \u2208 S = {5, 6, . . . , 15}. In the first case, we provided two-class classification results where classes correspond to neutral and emotional categories (see Table II). In the second case, four classes correspond to kitchen utensil, furniture, fear and disgust, where kitchen utensil and furniture belong to the neutral category, and fear and disgust belong to the emotional category (see Table III).\n9\nTABLE III: Classification performance (%) of SVM classifier computed in emotional memory retrieval experiment (4-class).\nP1 P2 P3 P4 P5 P6 P7 P8 P9 P10 P11 P12 P13 Avg\nFLM 59(6) 54(10) 62(6) 68(13) 60(6) 66(6) 75(9) 59(15) 67(5) 74(13) 64(7) 62(14) 58(5) 63.7 SLM 58(13) 53(13) 63(8) 67(14) 63(8) 62(5) 78(11) 62(5) 75(5) 74(9) 58(9) 58(12) 57(12) 63.7 FMM-mean 38(5) 42(8) 46(14) 44(14) 49(10) 42(5) 74(15) 36(5) 57(7) 52(6) 42(9) 32(5) 35(7) 45.1 FMM-peak 42(10) 46(6) 44(9) 54(15) 40(14) 46(5) 58(7) 37(12) 58(11) 57(7) 58(13) 43(14) 45(13) 48.3 LMM-mean 38(11) 46(6) 50(8) 47(12) 47(14) 42(5) 68(12) 42(6) 51(8) 52(7) 38(7) 35(5) 38(6) 45.7 LMM-peak 42(9) 36(12) 44(12) 45(11) 47(15) 48(7) 58(11) 32(8) 61(15) 57(7) 47(10) 46(11) 47(10) 47.0 LM-rand 37 43 37 42 40 40 63 44 59 51 39 45 39 44.6 FC-mesh 31 35 26 33 32 30 36 34 31 39 38 41 33 33.7 MVPA-mean 37 40 44 45 45 37 67 41 58 40 40 33 34 43.2 MVPA-peak 49 45 44 55 41 51 64 41 57 49 57 52 46 50.1 MVPA-all 43 41 40 44 34 43 57 39 53 41 35 38 42 42.4\n40\n50\n60\n70\n80\n90\n1 2 3 4 5\nC la\nss if\nic at\nio n\nP e\nrf o\nrm an\nce\nParticipants\nFLM SLM FMM-peak LMM-peak FMM-mean LMM-mean\nFig. 5: Mean and standard deviation of classification performances of SVM compute din visual object recognition experiment.\nSimilar to visual object recognition experiment, optimal mesh sizes are selected as the ones that maximize validation set accuracy within the interval S. Table II and Table III provide classification performance obtained using the optimal mesh sizes. The results of 2-class and 4-class classification experiments show that we obtain significantly better performance using features extracted for FLM and SLM than the other features. Employing random voxels in LM-rand performs significantly worse than employing spatial or functional neighbors. We have also observed that we obtain better performance using the features extracted by the employment of the peak values of BOLD responses than using the features extracted by computing the average of BOLD responses. In other words, we\nobtain better performance for FMM-peak, LMM-peak and MVPA-peak than for FMM-mean, LMM-mean and MVPAmean, respectively.\nFirst of all, the results show that employing a set of BOLD responses for the computation of meshes provides the most discriminate representations of cognitive states. Moreover, we observe that estimating functional relationships within a neighborhood provides better performance than using pairwise functional relationships as utilized for FC-mesh. Features extracted for FC-mesh perform the worst among the others since computation of correlation among voxels using only a few voxel intensity values for each stimulus presentation is not enough to represent the real correlation among voxels computed considering the whole dataset. Therefore, we obtain better classification performance by computing a single functional connectivity matrix for all training data, and using the matrix to select functionally nearest neighbors, instead of computing the functional connectivity matrices for each sample and using their elements as features. Finally, we obtained worse classification performance using the classifiers which employ MVPA features consisting of individual voxel intensity values compared to our proposed methods.\nWe have provided the mean and standard deviations of classification performances using different meshes that are constructed with p \u2208 P for visual object recognition experiment in Fig. 5, and with p \u2208 S for emotional memory retrieval experiment in Fig. 6 and Fig. 7. In Fig. 5, bars represent the mean classification performance averaged over all p \u2208 P , whereas in Fig. 6 and Fig. 7, bars represent the mean classification performance averaged over all p \u2208 S . In\n10\nthese figures, each error bar represents standard deviations of the corresponding performance value. For each participant, the first two bars depict performances of the methods that employ functional and spatial meshes, whereas the last four bars depict performances obtained using mesh models which do not consider whole BOLD responses. We have observed that standard deviation of performance values obtained using various mesh sizes decreases when temporal measurements are considered\n11\nfor statistical learning of the models. In other words, the methods employing temporal measurements recorded within neighborhoods are more robust to changes of mesh size p than the methods which do not employ temporal measurements."}, {"heading": "C. Analysis of Local Meshes", "text": "In the proposed local mesh models, we assume that the BOLD responses of voxels that are located in a neighborhood are similar to each other so that a BOLD response of a voxel can be represented by a linear combination of the BOLD responses of its nearest neighbors. In other words, we assume that the error of a linear regression model is small enough such that a cognitive stimulus can be represented by a set of local meshes, where the edge weights of the meshes can be estimated by minimizing the expected square error.\n1) Statistical Analysis of Correlations of Voxels: In order to understand how voxels within a neighborhood behave, and how their behavior differs from the behavior of random voxel sets, we plot a seed voxel with i) a set of randomly selected voxels (Fig. 8a), ii) its ten spatially (Fig. 8b) and iii) ten functionally (Fig. 8c) nearest neighbors. We observe that, sample voxels located within spatial and functional neighborhoods perform similar under presentation of the same stimuli.\nIn the analysis, Pearson correlation is used to compute pairwise relationship (i.e. correlation) between the seed voxels and the surrounding voxels. In our analysis, surrounding voxels are selected as (a) random voxels, (b) spatially nearest neighbors of seed voxels and (c) functionally nearest neighbors\nof seed voxels. First, we compute correlations between ten surrounding voxels and the seed voxel. Then, we depict the histograms of all correlations computed for all voxels with their surrounding voxels in meshes.\nWe observe that if meshes are formed with random voxels, then the mean of distribution of correlations lie around 0.4 (see Fig. 9a), in other words, the randomly selected voxels may not have a statistically significant linear relationship with each other. On the other hand, the results show that correlation values of the voxels observed with the highest frequency are close to 0.9 when the histograms are computed for meshes formed using spatially (see Fig. 9b) and functionally (Fig. 9c) close voxels. These observations indicate that the voxels modeled in the same mesh have better statistical relationship with each other than the randomly selected meshes. Therefore, one may expect that the linear relationship among the BOLD responses observed in voxels located in a proposed neighborhood system provides a reasonable fit to the data.\n2) Statistical Analysis of Models: Recall that, we represent the voxel intensity values each voxel as a linear combination of those values of its p-nearest neighbors in our models. Yet, we obtain a regression error for each mesh for the estimation of seed voxels considering its neighbors. In the next set of experiments, we analyze how well the seed voxels are represented in terms of their nearest neighbors by exploring the model estimation error of the proposed representation.\nFor this purpose, we employ a goodness of fit measure called R2 defined as one minus the residual variation divided\n12\nby total variation, where residual variation (SSr) is the summation of square errors obtained from regression model, and total variation (SSt) is the variance of the distribution of the actual data.\nMore precisely, we compute the residual variation as,\nSSri,j = D\u2211 d=1 \u03b52i,d,j , (17)\nwhere \u03b5i,d,j denotes the error in (13), and D represents the number of measurements recorded during each stimulus representation. On the other hand, total variance is computed as\nSSti,j = D\u2211 d=1 v(si, td, l\u0304j) 2. (18)\nThen, the R2 is computed as\nR2i,j = 1\u2212 ( SSri,j SSti,j ) . (19)\nNotice that the R2 measure takes values between 0 and 1 such that the values closer to one represent better fit of models. In the analysis, we computed R2 values for all meshes of a participant formed for all samples and around all voxels. In Fig. 10, we plot the histograms for R2 values computed when the meshes are formed using (a) random voxels, (b) spatially nearest voxels, and (c) functionally nearest voxels.\nIn the experiments, if seed voxels of meshes formed using spatial or functional neighbors are represented in terms of their neighbors, then we observe that the mean values of histograms for R2 are 0.57 and 0.54, respectively (Fig. 10.b and c). On the other hand, if we represent seed voxels in terms of random voxels, then we observe larger estimation errors, and the mean value reduces to 0.29 (Fig. 10.a). Therefore, employing spatial or functional neighbors during the construction of meshes results in better model fit compared to selecting random voxels."}, {"heading": "VII. CONCLUSION", "text": "In this study, we propose a method which maps a sequence of brain volumes, recorded during a cognitive stimulus to a brain graph consisting of a set of local meshes. The proposed model, called ensemble of local meshes, defines two types\nof local meshes around each voxel, namely spatially local mesh (SLM) and functionally local mesh (FLM). While SLM models the relationship among voxel BOLD responses in a spatial neighborhood system, FLM models the relationship among voxel BOLD responses in functional neighborhood defined by Pearson correlation. We have observed that are considering the whole BOLD responses recording during a cognitive stimulus for the employment of spatial and functional relationship among voxels enables us to model the discriminative information in fMRI data. When we represent the brain encoding and decoding precess by a machine learning algorithm, namely Support Vector Machines (SVM), we observe that FLM features perform substantially better among the features that use the state-of-the-art MVPA models.\nWe have observed that classification performances of SVM depend on the mesh size p, and varies for each participant. We have also observed that employment of temporal measurements for modeling of mesh edge weights results in less standard deviation over various mesh sizes. Therefore, models which employ temporal measurements are more robust to the effect of using different mesh sizes for the extraction and classification of features. A future research direction will be the development of algorithms to generalize the ensemble of local meshes to model resting state or disease fMRI data."}, {"heading": "ACKNOWLEDGMENT", "text": "We thank Orhan Firat, Baris Nasir, Arman Afrasiyabi, Burak Velioglu, Hazal Mogultay, Emre Aksan and Sarper Alkan for insightful discussions and fMRI data gathering. We also thank UMRAM for fMRI recordings. This work is supported by TUBITAK under the grant number 112E315."}], "references": [{"title": "Semispatiotemporal fmri brain decoding", "author": ["M. Kefayati", "H. Sheikhzadeh", "H. Rabiee", "A. Soltani-Farani"], "venue": "PRNI, Philadelphia, PA, USA, June 2013, pp. 182\u2013185.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Distributed and overlapping representations of faces and objects in ventral temporal cortex", "author": ["J.V. Haxby", "M.I. Gobbini", "M.L. Furey", "A. Ishai", "J.L. Schouten", "P. Pietrini"], "venue": "Science, vol. 293, no. 5539, pp. 2425 \u2013 2429, 2001.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Diagnostic neuroimaging across diseases", "author": ["S. Kloppel", "A. Abdulkadir", "C.R. Jack", "N. Koutsouleris", "J. Mourao- Miranda", "P. Vemuri"], "venue": "NeuroImage, vol. 61, no. 2, pp. 457 \u2013 463, 2012.  13", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Using support vector machine to identify imaging biomarkers of neurological and psychiatric disease: A critical review", "author": ["G. Orru", "W. Pettersson-Yeo", "A.F. Marquand", "G. Sartori", "A. Mechelli"], "venue": "Neurosci. Biobehav. Rev., vol. 36, no. 4, pp. 1140 \u2013 1152, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed patterns of brain activity that lead to forgetting.", "author": ["I. Oztekin", "D. Badre"], "venue": "Front Hum Neurosci,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Functional magnetic resonance imaging (fmri) brain reading: detecting and classifying distributed patterns of fmri activity in human visual cortex", "author": ["D.D. Cox", "R.L. Savoy"], "venue": "NeuroImage, vol. 19, no. 2, pp. 261 \u2013 270, 2003.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "Decoding the visual and subjective contents of the human brain", "author": ["Y. Kamitani", "F. Tong"], "venue": "Nat Neurosci, vol. 8, no. 5, pp. 679 \u2013 685, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Generalized sparse classifiers for decoding cognitive states in fmri", "author": ["B. Ng", "A. Vahdat", "G. Hamarneh", "R. Abugharbieh"], "venue": "MLMI, Beijing, China, 2010, vol. 6357, pp. 108\u2013115.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Generalized group sparse classifiers with application in fmri brain decoding", "author": ["B. Ng", "R. Abugharbieh"], "venue": "CVPR, Colorado Springs, USA, 2011, pp. 1065\u20131071.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning to decode cognitive states from brain images", "author": ["T.M. Mitchell", "R. Hutchinson", "R. Niculescu", "F. Pereira", "X. Wang", "M. Just", "S. Newman"], "venue": "Machine Learning, vol. 57, no. 1-2, pp. 145\u2013175, 2004.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Modeling spatiotemporal structure in fmri brain decoding using generalized sparse classifiers", "author": ["B. Ng", "R. Abugharbieh"], "venue": "PRNI, Korea, Seoul, 2011, pp. 65\u201368.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Decoding unattended fearful faces with whole-brain correlations: An approach to identify condition-dependent large-scale functional connectivity", "author": ["S.P. Pantazatos", "A. Talati", "P. Pavlidis", "J. Hirsch"], "venue": "PLoS Comput Biol, vol. 8, no. 3, p. e1002441, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Decoding brain states from fmri connectivity graphs", "author": ["J. Richiardi", "H. Eryilmaz", "S. Schwartz", "P. Vuilleumier", "D.V.D. Ville"], "venue": "NeuroImage, vol. 56, no. 2, pp. 616 \u2013 626, 2011.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Large scale functional connectivity for brain decoding", "author": ["O. Firat", "I. Onal", "E. Aksan", "B. Velioglu", "I. Oztekin", "F.T.Y. Vural."], "venue": "BioMed, Zurich, Switzerland, 2014.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Voxellevel functional connectivity using spatial regularization", "author": ["C. Baldassano", "M.C. Iordan", "D.M. Beck", "L. Fei-Fei"], "venue": "NeuroImage, vol. 63, no. 3, pp. 1099 \u2013 1106, 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Representation of cognitive processes using the minimum spanning tree of local meshes", "author": ["O. Firat", "M. Ozay", "I. Onal", "I. Oztekin", "F. Yarman Vural"], "venue": "EMBC, Osaka, Japan, July 2013, pp. 6780\u20136783.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Machine learning with brain graphs: Predictive modeling approaches for functional imaging in systems neuroscience", "author": ["J. Richiardi", "S. Achard", "H. Bunke", "D.V. de Ville"], "venue": "IEEE Signal Process. Mag, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Joint maximum likelihood estimation of activation and hemodynamic response function for fmri", "author": ["N. Bazargani", "A. Nosratinia"], "venue": "Med Image Anal, vol. 18, no. 5, pp. 711 \u2013 724, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Information-based functional brain mapping", "author": ["N.Kriegeskorte", "R. Goebel", "P. Bandettini"], "venue": "PNAS, vol. 103, no. 10, pp. 3863 \u2013 3868, 2006.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Mesh learning for classifying cognitive processes", "author": ["M. Ozay", "I. Oztekin", "U. Oztekin", "F.T. Yarman-Vural"], "venue": "CoRR, vol. abs/1205.2382, 2012.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Functional mesh learning for pattern analysis of cognitive processes", "author": ["O. Firat", "M. Ozay", "I. Onal", "I. Oztekiny", "F. Vural"], "venue": "ICCI*CC, New York City, USA, July 2013, pp. 161\u2013167.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Modeling voxel connectivity for brain decoding", "author": ["I. Onal", "M. Ozay", "F. Yarman Vural"], "venue": "PRNI, Stanford, CA, USA, 2015, pp. 5 \u2013 8.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Relationship between emotion and forgetting", "author": ["E. Mizrak", "I. Oztekin"], "venue": "Emotion, 2015.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Automated anatomical labeling of activations in spm using a macroscopic anatomical parcellation of the mni mri single-subject brain", "author": ["N. Tzourio-Mazoyer", "B. Landeau", "D. Papathanassiou", "F. Crivello", "O. Etard", "N. Delcroix", "B. Mazoyer", "M. Joliot"], "venue": "NeuroImage, vol. 15, pp. 273\u2013289, 2002.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2002}, {"title": "Region of interest analysis using an spm toolbox", "author": ["M. Brett", "J.-L. Anton", "R. Valabregue", "J.-B. Poline."], "venue": "8th International Conference on Functional Mapping of the Human Brain, Sendai, Japan, 2002.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2002}, {"title": "Theoretical and empirical analysis of relieff and rrelieff", "author": ["M. Robnik-Sikonja", "I. Kononenko"], "venue": "Machine Learning, vol. 53, pp. 23 \u2013 69, 2003.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2003}, {"title": "Information theory and an extension of the maximum likelihood principle", "author": ["H. Akaike"], "venue": "ISIT, Budapest, Hungary, 1973, pp. 267 \u2013 281.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1973}, {"title": "Estimating the dimension of a model", "author": ["G.E. Schwarz"], "venue": "Ann. Stat, vol. 6, no. 2, pp. 461 \u2013 464, 1978.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1978}, {"title": "Modeling by shortest data description", "author": ["J. Rissanen"], "venue": "Automatica, vol. 14, no. 5, pp. 465 \u2013 471, 1978.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1978}, {"title": "Modeling the brain connectivity for pattern analysis", "author": ["I. Onal", "E. Aksan", "B. Velioglu", "O. Firat", "M. Ozay", "I. Oztekin", "F.T. Yarman Vural"], "venue": "ICPR, Stockholm, Sweden, 2014.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Functional Magnetic Resonance Imaging (fMRI) is used as the primary modality to capture neural activations in the brain due to its high spatial resolution and reasonable temporal resolution [1].", "startOffset": 190, "endOffset": 193}, {"referenceID": 1, "context": "[2], machine learning techniques have been used for MVPA for diagnosing disorders [3], [4], hypothesis validation [5] and classifying cognitive states which is a method for predicting cognitive states called brain decoding.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[2], machine learning techniques have been used for MVPA for diagnosing disorders [3], [4], hypothesis validation [5] and classifying cognitive states which is a method for predicting cognitive states called brain decoding.", "startOffset": 82, "endOffset": 85}, {"referenceID": 3, "context": "[2], machine learning techniques have been used for MVPA for diagnosing disorders [3], [4], hypothesis validation [5] and classifying cognitive states which is a method for predicting cognitive states called brain decoding.", "startOffset": 87, "endOffset": 90}, {"referenceID": 4, "context": "[2], machine learning techniques have been used for MVPA for diagnosing disorders [3], [4], hypothesis validation [5] and classifying cognitive states which is a method for predicting cognitive states called brain decoding.", "startOffset": 114, "endOffset": 117}, {"referenceID": 5, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 43, "endOffset": 46}, {"referenceID": 6, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 48, "endOffset": 51}, {"referenceID": 7, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 150, "endOffset": 154}, {"referenceID": 10, "context": "While some of the state-of-the-art methods [6], [7], [8], [9], [10] are designed to extract only spatial patterns from the BOLD responses, the others [11], [12] focus on modeling temporal information to form features for brain decoding.", "startOffset": 156, "endOffset": 160}, {"referenceID": 5, "context": "A popular method for extracting a spatial feature for brain decoding from fMRI data is computing the average BOLD response for each voxel to represent a stimulus [6], [7], [8].", "startOffset": 162, "endOffset": 165}, {"referenceID": 6, "context": "A popular method for extracting a spatial feature for brain decoding from fMRI data is computing the average BOLD response for each voxel to represent a stimulus [6], [7], [8].", "startOffset": 167, "endOffset": 170}, {"referenceID": 7, "context": "A recent work, suggested by [9], [10], considers each brain volume as a sample.", "startOffset": 28, "endOffset": 31}, {"referenceID": 8, "context": "A recent work, suggested by [9], [10], considers each brain volume as a sample.", "startOffset": 33, "endOffset": 37}, {"referenceID": 9, "context": "[11] and Ng et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] concatenate the BOLD responses within the same trial to extract features that include spatio-temporal information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "In order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions.", "startOffset": 81, "endOffset": 85}, {"referenceID": 12, "context": "In order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions.", "startOffset": 87, "endOffset": 91}, {"referenceID": 13, "context": "In order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions.", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "In order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions.", "startOffset": 99, "endOffset": 103}, {"referenceID": 15, "context": "In order to extract the temporal information from the fMRI data, various studies [13], [14], [15], [16], [17] compute the pairwise correlations between the responses of voxels or brain regions.", "startOffset": 105, "endOffset": 109}, {"referenceID": 11, "context": "[13] model temporal relationships by using pairwise correlations between brain regions as features for brain decoding.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] model a functional connectivity graph using the pairwise correlations between brain regions, and they decode the brain states using graph matching algorithms.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Also, edge weights of their proposed brain graphs are generally selected using the correlation between pairs of selected voxels, and vertices or edge weights of these brain graphs are used as features for cognitive state classification [18].", "startOffset": 236, "endOffset": 240}, {"referenceID": 13, "context": "[15] use pairwise correlations of voxels as features while Baldassano et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] extract the functional connectivity structures by modeling pairwise connectivity among voxels.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Also, a minimum spanning tree of a graph structure defined using a functional connectivity matrix is employed using all voxels for each stimulus for brain decoding [17].", "startOffset": 164, "endOffset": 168}, {"referenceID": 17, "context": "[19] state that neighboring voxels belonging to a homogeneous ROI have Hemodynamic Response Function (HRF) with the same shape, possibly with slightly varying amplitude.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[20] report that a univariate model of activations fails to benefit from local spatial combination of signals, and performs worse than Searchlight methods for detection of informative regions.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] observe that the voxel time series do not differ significantly to discriminate the different cognitive states, but there exist slight variations among the voxel intensity values of voxels located in a spatial neighborhood.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "However, in [21], only the brain volume which is obtained 6 seconds after the stimulus presentation is used for the construction of a model while the remaining ones are discarded under the canonical HRF assumption.", "startOffset": 12, "endOffset": 16}, {"referenceID": 20, "context": "[22] propose a Functional Mesh Model (FMM) which is used to construct a set of local meshes by selecting the nearest neighbors of voxels defined within a functional neighborhood.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "The local mesh around each voxel is constructed by using either a spatial [23] or functional neighborhood system to generate a set of spatially or functionally local meshes.", "startOffset": 74, "endOffset": 78}, {"referenceID": 22, "context": "For a similar experimental setting, please refer to [24].", "startOffset": 52, "endOffset": 56}, {"referenceID": 23, "context": "Finally, we extract 116 Automated Anatomical Labeling (AAL) regions [25] using Marsbar [26].", "startOffset": 68, "endOffset": 72}, {"referenceID": 24, "context": "Finally, we extract 116 Automated Anatomical Labeling (AAL) regions [25] using Marsbar [26].", "startOffset": 87, "endOffset": 91}, {"referenceID": 25, "context": "For the emotional memory retrieval experiment we selected first 3000 most discriminative voxels from the whole brain analysis, using ReliefF [27].", "startOffset": 141, "endOffset": 145}, {"referenceID": 26, "context": "This task can also be achieved by using an Information Theoretic function, such as Akaike\u2019s information criterion (AIC) [28], Bayesian Information Criterion (BIC) [29] or Rissannen\u2019s Minimum Description Length (MDL) [30] to estimate the model order.", "startOffset": 120, "endOffset": 124}, {"referenceID": 27, "context": "This task can also be achieved by using an Information Theoretic function, such as Akaike\u2019s information criterion (AIC) [28], Bayesian Information Criterion (BIC) [29] or Rissannen\u2019s Minimum Description Length (MDL) [30] to estimate the model order.", "startOffset": 163, "endOffset": 167}, {"referenceID": 28, "context": "This task can also be achieved by using an Information Theoretic function, such as Akaike\u2019s information criterion (AIC) [28], Bayesian Information Criterion (BIC) [29] or Rissannen\u2019s Minimum Description Length (MDL) [30] to estimate the model order.", "startOffset": 216, "endOffset": 220}, {"referenceID": 29, "context": "The interested reader is referred to [31].", "startOffset": 37, "endOffset": 41}], "year": 2016, "abstractText": "We represent the sequence of fMRI (Functional Magnetic Resonance Imaging) brain volumes recorded during a cognitive stimulus by a graph which consists of a set of local meshes. The corresponding cognitive process, encoded in the brain, is then represented by these meshes each of which is estimated assuming a linear relationship among the voxel time series in a predefined locality. First, we define the concept of locality in two neighborhood systems, namely, the spatial and functional neighborhoods. Then, we construct spatially and functionally local meshes around each voxel, called seed voxel, by connecting it either to its spatial or functional p-nearest neighbors. The mesh formed around a voxel is a directed sub-graph with a star topology, where the direction of the edges is taken towards the seed voxel at the center of the mesh. We represent the time series recorded at each seed voxel in terms of linear combination of the time series of its p-nearest neighbors in the mesh. The relationships between a seed voxel and its neighbors are represented by the edge weights of each mesh, and are estimated by solving a linear regression equation. The estimated mesh edge weights lead to a better representation of information in the brain for encoding and decoding of the cognitive tasks. We test our model on a visual object recognition and emotional memory retrieval experiments using Support Vector Machines that are trained using the mesh edge weights as features. In the experimental analysis, we observe that the edge weights of the spatial and functional meshes perform better than the state-of-the-art brain decoding models. Keywords\u2014fMRI; voxel connectivity; brain decoding; object recognition; classification", "creator": "LaTeX with hyperref package"}}}