{"id": "1603.02488", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2016", "title": "Extracting Arabic Relations from the Web", "abstract": "the goal of this research is to extract a large list or table from properly named entities and binary relations in a specific domain. a small set of a handful of instance relations is required as input from the user. the system exploits summaries from google search engine as a source text. these instances words are used to similarly extract patterns. the raw output analysis is mostly a set of new entities and their relations. the results from four experiments show that average precision and recall varies closely according to relation type. precision count ranges from normally 0. 61 to 0. 75 while recall ranges from 0. 71 to 0. 83. the best result is obtained for ( player, club ) relationship, 0. 72 item and 0. 83 for precision and link recall respectively.", "histories": [["v1", "Tue, 8 Mar 2016 11:47:35 GMT  (472kb)", "http://arxiv.org/abs/1603.02488v1", "18 pages, 5 figure,7 tables in International Journal of Computer Science &amp; Information Technology (IJCSIT) Vol 8, No 1, February 2016"]], "COMMENTS": "18 pages, 5 figure,7 tables in International Journal of Computer Science &amp; Information Technology (IJCSIT) Vol 8, No 1, February 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shimaa m abd el-salam", "enas m f el houby", "a k al sammak", "t a el-shishtawy"], "accepted": false, "id": "1603.02488"}, "pdf": {"name": "1603.02488.pdf", "metadata": {"source": "CRF", "title": "EXTRACTING ARABIC RELATIONS FROM THE WEB", "authors": ["Shimaa M. Abd El-salam", "Enas M.F. El Houby"], "emails": [], "sections": [{"heading": null, "text": "DOI:10.5121/ijcsit.2016.8107 85\nThere is a vast amount of unstructured Arabic information on the Web, this data is always organized in semi-structured text and cannot be used directly. This research proposes a semi-supervised technique that extracts binary relations between two Arabic named entities from the Web. Several works have been performed for relation extraction from Latin texts and as far as we know, there isn\u2019t any work for Arabic text using a semi-supervised technique. The goal of this research is to extract a large list or table from named entities and relations in a specific domain. A small set of a handful of instance relations are required as input from the user. The system exploits summaries from Google search engine as a source text. These instances are used to extract patterns. The output is a set of new entities and their relations. The results from four experiments show that precision and recall varies according to relation type. Precision ranges from 0.61 to 0.75 while recall ranges from 0.71 to 0.83. The best result is obtained for (player, club) relationship, 0.72 and 0.83 for precision and recall respectively.\nKEYWORDS\nRelation Extraction, Information Extraction, Pattern Extraction, Semi-Supervised, Arabic language & Web Mining."}, {"heading": "1. INTRODUCTION", "text": "There has been a growing interest in techniques for automatically extracting information from text. Specifically, Information Extraction (IE) [1, 2] is a process which takes texts as input and put them in a structured format, unambiguous data as output. The major research directions of IE are Named Entity Recognition (NER) such as (person, organization, location and so on) and Relations Extraction (RE) among them. Relation extraction has become in the last few years an interesting research domain. It is a very important for several applications, such as Web mining, Information retrieval, Questions answering, Social relationship network and Automatic summarization. RE is the task of recognizing the assertion of a particular relationship between two or more entities in text. Most relation extraction system focus on binary relation such as (is-a, part-of). The functional relation can be explicit or implicit. The explicit relation is indicated by a special word or sequence of words in the text, the implicit relation is a relation what can be mined from the text using the context [8].\nbased on bootstrapping. Semi-supervised learning has become an important topic in computational linguistics. For many languages processing tasks including relation extraction, there is an abundance of unlabeled data, where labeled data is lacking and too expensive to create in large quantities, therefore making bootstrapping techniques is desirable. The input is a small seed instance relations (e1, e2) and retrieved summaries from Google search engine as a source text. Each seed instance pair is used with the data source to generate patterns. Then, those patterns are used to extract new entity instances of the same relation as the seed instances. An instance with a high credibility score will be used as a seed instance in the next iteration, and then will be used to construct a structured relation set. This iterative process will be terminated if extracted instances reached to the number that determined by the user. For simplicity, only binary relations are taken into account in this paper and the target language is Arabic. The main features of this work are as follows:\n\u2022 The work is the first semi-supervised system that extracts binary relation instances from Arabic text using open source web contents.\n\u2022 The Google search engine summaries are used as a corpus resource. \u2022 The system is generic; it can be used in different domains based on the type of seed\ninstances.\n\u2022 The system detects Named Entities automatically through analysis of extracted patterns. Therefore, the system doesn\u00a1\u00a6t need specially prepared Named Entities dictionaries.\n\u2022 The syntactic analysis is made for Arabic text to increase the efficiency of the results.\nThe remaining of the paper is organized as follow: Section 2 introduces the previous works that were used to extract relations from text. Section 3 describes the challenges of the Arabic language. Section 4 describes components of the proposed system in details. Section 5 presents experiments and results. Section 6 contains conclusions."}, {"heading": "2. RELATED WORK", "text": "In this section, methods that extract semantic relations from texts will be reviewed. There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13]. These works were grouped according to the used technique into four categories [4, 8] rule-based, supervised, unsupervised and semi-supervised methods.\nRule-based methods utilize predefined linguistic (syntactic and semantic) rules written manually to extract relationships based on part of speech information. It is very interesting for a restricted domain and has a good quality of analysis. The major drawback of this approach is the disability to perform well in dealing with a wide range or new domain data. This is due to two reasons: rules should be rewritten for different tasks or when the application is enlarged to different domains and finding rules manually is very hard and time-consuming [15]. Ben Hamadou et al., [8] extracted functional relations between Arabic person names and organizations for Arabicnamed entities using the NOOJ platform; they applied their experiment on a journalistic test corpus. Belkacem and Badr [9] presented some aspects to identify entities and relationships in Arabic text. They translated the Arabic sentences into a first order logic. Then, they used entities\ndeveloped a prototype for Arabic text spatial relations (topological relations, directional relations, and distance relations). It used a rule library which consists of a set of grammatical rules and lexico-syntactic patterns. These rules are applied to raw Arabic text to extract the spatial relations. The pattern-specific regular expressions were applied over the pre-processed sentences to verify that the pattern indeed occurs in the sentence.\nSupervised methods relation extraction depends on a classification task and use large corpus such as Ines Boujelben et al. [12] presented a tool called \u201cRelANE\u201d that detect all the semantic binary relations. For each word in the sentence, it uses its morphological, contextual and semantic features of entity types. Mohammed G.H. and Qasem [17] proposed a methodology that can extract ontological relationships. It can extract semantic features of Arabic text; propose syntactic patterns of relationships among concepts, and a formal model of extracting ontological relations. It has been designed to analyze Arabic text using lexical semantic patterns of the Arabic language according to a set of features.\nUnsupervised methods use clustering techniques and similarities between features or context words such as Hasegawa [18] assumed that pairs occurring in similar contexts share the same type of relation, they can be clustered together, then named entity recognition is applied to identify the entities of interest. Zhang M. et al., [19] proposed a tree-similarity-based unsupervised learning method to extract relations between named entities from a large raw corpus. They modified tree kernels on relation extraction to estimate the similarity between parse trees more efficiently. Then, the hierarchical clustering algorithm was used to group entity pairs into different clusters. Finally, each cluster is labeled by an indicative word and unreliable clusters are pruned out.\nSemi-supervised methods (weakly supervised) take a sample of patterns or some target relation instances for the purpose to acquire more basics until discovering all target relations such as Brin [20] proposed relation extraction system DIPRE, which starts with a small set of seed facts for one or more relations of interest. Then it looked for a pattern in sources as indicators of facts. Finally, it utilized these patterns to extract new facts. Agichtein and Gravano [21] proposed a system called Snowball, which adopted the similar strategy with DIPRE. However, Snowball didn\u2019t use exact match, but a similarity function to group similar patterns instead. Snowball\u2019s flexible matching system allows for slight variations in token or punctuation, it used NER to identify all organization and location entities. Ravichandran and Hovy [22] extracted simple surface patterns for extracting binary relations from The Web. It started with only a few examples of (question, answer) pairs. It focused on efficiency issues for scaling relation extraction to terabytes of data. It gave good results on specific relations such as birthdates, however, it had low precision on generic ones like (is-a) relation and (part-of) relation. Pennacchiotti and Panel [23] proposed a system called Espresso for extracting binary semantic relations. It started with a small set of seed instances for a particular relation, the system learned lexical patterns and then used the Web to filter and expand the instances. Rozenfeld and Feldman [24] implemented SRES (SelfSupervised Relation Extraction System). SRES took input names of the target relations and the types of their arguments. It then used a large set of unlabeled documents downloaded from the Web in order to learn the extraction patterns. SRES was related to the KnowItAll system which was developed by Oren Etzioni et al. [25]. Chao Chen et al. [5] developed REV (Relation Extraction with Verification). It extracted relations in Chinese text from World Wide Web, it just required a seed instances with the form of (e1, e2, keyword) as input and World Wide Web was used as data source. Yang et al. [6] proposed a tuple refinement method based on relationship\nentity relation keyword, and then crawl the co-occurrence of entity and relation keywords by the redundant web information; it saved the highest statistical value of candidate entities as the second entity based on the principle of proximity and the predefined entity type. David S. et al. [16] proposed a bootstrapping system for relation extraction based on word embedding. It achieved better results when used related words to find similar relationships than with similarities between weighted vectors. It extracted four types of relationships from a collection of newswire documents."}, {"heading": "3. THE CHALLENGES OF ARABIC LANGUAGE", "text": "In fact, the extracting relation from Arabic text is not an easy task due to challenges related to the Arabic language. Arabic language [14] is a language which different from Indo-European languages syntactically, semantically and morphologically.\nThe research progress of Arabic relation extraction is relatively limited. This limitation might be due to the nature of the Arabic language beside the lack of available linguistic resources. Actually, the accessible corpora are not annotated with named entities, and the relations do not include a sufficient number of annotated examples can be exploited for learning approaches. Arabic is a Semitic language that presents interesting morphological and orthographic challenges that could complicate the extraction of relations between NEs. In addition to the problems that are related to Arabic NE recognition and relation extraction task poses some specific challenges listed in [8, 12] some of these challenges are:\n1) Multiple relations may be occurred between the same NEs. 2) Implicit Relations: that is not directly recognized by words in the text. They are mined from the text using contextual elements, for example relation is Belong-to. 3) It is necessary to use the previous context of the relation to know the missing element involved in the relation. 4) Interference between implicit relation and discontinuity. 5) The omission of one element of the relation between named entities NE (NE1, R, ?) or (?, R, NE2) or (NE1, ?, NE2). These challenges which are listed above should be considered to achieve an efficient system for extracting relations."}, {"heading": "4. THE PROPOSED SYSTEM", "text": "In this section, the proposed semi-supervised system for Arabic relations extraction will be illustrated. The purpose of the proposed system is to extract instances of binary semantic relations that lie in the same line of the Arabic text. The system extracts relation between two named entities (e1, e2); e1 should be a person named entity and e2 any other named entity. The input to the proposed system is a small seed instance of the target relation and Google search result summaries as the source text. The output is a list of instances relations, i/e., named entities and the relation between them. The algorithm of the proposed system is shown in Figure 1.\nThe proposed system is an iterative process; each iteration consists of two phases 1) Pattern Extraction, 2) Instances Extraction. Each phase will be introduced in details in the following subsections."}, {"heading": "4.1. Phase 1: Pattern Extraction", "text": "The input to this phase is examples of seed instance pairs, and the output is a set of their patterns. The algorithm of this phase is shown in figure 2."}, {"heading": "4.1.1. Input Instances", "text": "Similar to several semi-supervised methods such as DIPRE [20] and Snowball [21], the system starts with a small samples of the input initial seed instances (e1, e2) where e1 and e2 represent \u201cnamed entity\u201d. In our proposed system, named entity can be person name, book title, organization name, etc. These initial instances pairs which stored in input table are used to start patterns extraction in the first iteration. The initial instances are given by the user and it can vary\ncase of using a list of four initial seed is better than one or two or three seed to discover the many different patterns. Figure 3 shows that the greater the number of seed instances greater the number of extracted pattern, since the candidate patterns refer to all patterns with repetition and pattern extraction refer to the patterns without repetition. For example, using one seed instances it will give 13 candidate pattern 5 of them non-repeated patterns and then lifted slightly with 2, 3 seeds. But when using four seeds, extracted patterns will a significant increase increasingly so it was decided to use four seed instances as input."}, {"heading": "4.1.2. Candidate Pattern Sentences", "text": "Candidate pattern sentences are Arabic sentences which are retrieved from the web when searching with instances. The proposed system searches for Arabic texts on the web with seed instances and using Google search engine. For each input instance (e1, e2); it retrieves the first 20 top summaries results that contain the two terms e1 and e2. It was found that results above the 20 summaries contain unrelated or repeated results. Therefore, increasing the number collected above 20 summaries, does not affect the number of extracted patterns. So, choosing 20 top summaries for each pair is suitable. Then all these sentences are downloaded into a text file."}, {"heading": "4.1.3. Preprocessing", "text": "The system deals with candidate pattern sentences line by line. Candidate pattern sentences string may contain non-Arabic letters and numbers which should be removed. The preprocessing task includes two steps: normalization and sentence segmentation. Normalization is the process in which the text is converted to UTF-8 character and any punctuation marks and non-Arabic letters are removed. Also, some Arabic letters are normalized such as\" \u0625 \", \"\u0623 \", and \u201c\u0622\u201dwhich are replaced with\" \u0627 \", and\" \"\u0649 is replaced with \"\u064a\" and \"\u0647\" is replaced with \" \" \u0629 and so on. Closed set of Arabic words related to internet web pages ex. (\u201c \u201d free, \u201c \u201d site, \u201c \u201d download, and so on.) are\nwritten language into sentence\u2019s components."}, {"heading": "4.1.4. Sentence Extraction Validation", "text": "Candidate sentences may contain noisy results; therefore, checking a validity of the extracted sentences is very important to remove unrelated sentences. The sentence is marked as valid, if it suits the following criteria:-\ni. Sentences must contain both entities (e1, e2) in the same line. ii. A maximum number of words between the two entities should not exceed 3 words."}, {"heading": "4.1.5. Pattern Discovery", "text": ""}, {"heading": "4.1.5.1. Pattern Construction", "text": "The extracted valid sentences are analyzed and tokenized to prefix phrase, middle phrase, suffix phrase and order. They are analyzed according to an occurrence which consists of 6-dimension tuples:\n(prefix, e1, middle, e2, suffix, order)\nWhere \u201cprefix\u201d consists of the n words preceding e1 if e1 was the first or preceding e2 if e2 was the first, \u201cmiddle\u201d is all words between the e1 and e2, \u201ce1\u201d is the first entity such as person name, \u201ce2\u201d is the second entity such as organization name and \u201csuffix\u201d consists of the m words following e2 if e2 was the second entity or following e1 if e1 was the second. \u201cOrder\u201d corresponds to the order of e1 and e2 in the text, where order is a Boolean value. The following criteria are considered to extract candidate patterns:\n1. Verify that the maximum number of word in the middle between two entities is three words. 2. Check that number of words in each of prefix and suffix, if it is more than two words, then take only two words which before first entity e1 as prefix and three words after second entity as a suffix. 3. If any of prefix, suffix and middle context haven\u2019t any word; set it = null. 4. Order takes \u201ctrue\u201d if e1 occurred before e2, otherwise, order takes \u201cfalse\u201d."}, {"heading": "4.1.5.2. Pattern Validation", "text": "The purpose of this stage is to remove duplicated extracted patterns. It depends on the similarity between the set of candidate patterns from the previous stage.\nFor instance, consider two occurrences O1 and O2 as follow: O1 (occurrence) = p1{w11, w12},e1, m1{ w11, w12, w13}, e2, s1{w11, w12} O2 (occurrence) = p2{w21, w22}, e1, m2{ w21, w22, w23}, e2, s2{w21, w22}\nWhereas \u201cO\u201d refers to the occurrence, \u201cw\u201d refers to word, \u201cp\u201d refers to a prefix, \u201cm\u201d refers to middle, and \u201cs\u201d refers to a suffix. The criteria of matching processes are as follows:\npatterns, then save this pattern as extraction pattern with a number of repetition =1. 2. If prefix, middle words and order are the same but suffix contains different words in two occurrences; then save this pattern as extraction pattern with suffix = null, and the number of repetition equal number of matched patterns. 3. Verify prefix and middle words similarity. if not but there are some words similar, then calculate intersection between words in the prefix pi or middle mi for example if w12(p1)= w22(p2) and if w11 (m1)= w23 (m2); then a pattern will be P = p(w12), m(w11), s(null) and order = 1 (because e1 take places before e2) and number of repetition =2."}, {"heading": "4.2. Phase 2: Instance Extraction", "text": "In this phase, the system takes the patterns extracted from phase1 as input and retrieves a set of newly extracted instances that match these patterns as output. Algorithm of phase 2 is shown in figure 4."}, {"heading": "4.2.1. Candidate Instance Sentences", "text": "Candidate instance sentences are Arabic sentences which retrieved from the web when searching with pattern. The system ignores patterns that do not contain two parts of search. A query is generated for extracted patterns that contain both prefix and middle words. Prefix and middle words are used to retrieve the top 20 results for each pattern query. For each pattern, the query of search string takes the form:\nSearch pattern query: \u201c+prefix words+e1+middle words+ e2+\u201d\nFor example; \u201c+*+ +*+ \u0627+ \u062c +\u0644 \u0627 +\u201d\nThe retrieved candidate instance sentences for each searched pattern are collected together in a text file. Candidate instance sentences may contain non-Arabic letter and numbers. To overcome extracted noisy occurrences, the output of the search engine is validated against used patterns. It must be preprocessed similar to procedures illustrated in section 4.1.3 to remove any noise."}, {"heading": "4.2.2. Instance Extraction", "text": "The system reads extracted sentences line by line from a text file. It use match method between each pattern with all extracted sentences to extract new instances pair (e1, e2). Each pattern consist\nmatched the pattern into 5 parts according to extracted pattern; where prefix, middle, and suffix are known, e1 and e2 are required. Finally, the system can detect all the potential instances. For example; extracted pattern is:\nThis pattern matches sentences such as:\nThen the extracted instances are:"}, {"heading": "4.2.3. Instance Validation", "text": "The goal of the instance validation stage is to filter the list of new extracted instances, keeping the correct instances and removing mistakes that may occur from patterns. The observations after extracting instances are that some instances are repeated many times. Moreover, in some instances name of a person may be duplicated with different format for the same second entity, because name of a person may be written by two or three words, so the goal of this step is to filter the list of extracted instances. Some constraints have been set to control new instance generation. Some filtering rules have been used instead of using Named Entities Recognition to minimize retrieving noise in extracted instances. The purpose of these rules is to evaluate and filter new instance to obtain correct instances which will be used in next iteration. These rules are:-\n1. Remove one of the duplicated instances which are common in the two entities (e1, e2). 2. Remove one of the duplicated instances if two pairs of instances (e1, e2) and (e1*, e2*) have\nsimilar words such as e2, e2* are the same words but words of e1*may exceed frome1with other words, then they will be described by intersected part. For example: e1\u201d \u201dand e1*\u201c \u0627\u0644\u0644\u0647 \" \u201d will be represented as\u201d \u201d. 3. The maximum length of e1is 3 words except if the third word is \u201c \" \u201d or \"#\u0628\" or \u201c \u0628\u0627\u201d. Only one more word will be considered in this case because it is incorrect to end a person name\nwith \u201c \" \u201d or \"#\u0628\" or \u201c \u0628\u0627\u201d according to the Arabic language. For example, after \u201c \" \u201d one word such as (\u201d\u0627\u0644\u0644\u0647\u201d, \u201c\u062d &' \u0627\u201d,\u201d (' ) \u201dand so on\u2026) is allowed. 4. It is invalid instances if named entity formed from one word such as (\u201c*+\u201d,\u201d# \u201d, \u201d \u201d) except if the word starts with \u201c\u0644\u0627\u201dex. \u201c\u0649 \", \u0627\u201d,\u201d*\"\u0637 . \u0627\u201d will be considered valid instances."}, {"heading": "4.3. End Condition", "text": "The system will continue repeating the procedure and the results of extracted instances will be added to instances table at each iteration. After adding the results to the table of instances, the system will remove duplication for instances. The system uses only new instances as input to the next iteration in case of not reaching the end condition. Some other systems can be terminated\nmany pairs have been returned such as in [20].\nIn our proposed system, we decided to terminate the iterations when reached to the number that is satisfactory for the user or when total numbers of extracted instances in the table reaches to \u2265 \u201ca threshold value\u201d. This threshold value is set to 100 instances. We choose this value to terminate\nthe iterations to be even easy for us to measure the performance of our system."}, {"heading": "5. EXPERIMENTS AND RESULTS", "text": ""}, {"heading": "5.1. Experimental Setting", "text": "In this section, we will talk about source of text that is used and our experiments. The proposed\nsystem uses World Wide Web and search engine as the source of text. In our experiments all of\nthe sentences (candidate pattern sentences and candidate instance sentences) are extracted from\nGoogle search engine since the data source is open. Our system used Jsoup (Java Web Crawler)\n[16] for retrieving Google search results. Figure 5 shows the operation that fetches results from\nGoogle.\nWe have performed four relations to evaluate the performance of the proposed system. Four\ncommon relations which are the author-of (person, book) relation, president-of (person, country)\nrelation, play-in (person, club) relation and CEO-of or chairman (person, company) relation are\nselected. Table 1 shows the sample of initial seed instance for each relation type. As described\nabove, each system started with just 4 different seed instances for each relation to obtain the high\ncoverage of extracted patterns."}, {"heading": "5.2. Assessment Methods", "text": "To evaluate the quality of our system we measured the performance by several methods. The first evaluation of extracted instances to measure their correctness, after that, the extracted pattern can be evaluated by its ability to extract correct instances."}, {"heading": "5.2.1. Evaluating Instances", "text": "Instances can be evaluated by two methods the first is by human judges after that by calculating precision, recall and F-Measure.\nWe asked the human judge for each relation domain (political, sport, business and the literature).\nThey should have good Arabic language skills and knowledge about these domains. We presented\nto them printed form that contains output extracted instances to judge and evaluate the correctness\nof new instances after terminating iterations. They evaluated manually using the internet. For\neach instance pair, we asked human judges to assign a score of 1 for correct, 0 for incorrect. After\nthat, we computed numbers of instances (correct - incorrect) for each pattern to evaluate pattern\nin the next step. As different relation extract a different number of instances, in order to assess the\nexperiment result, we use three common evaluation measures: Precision P, Recall R and F-\nMeasure for all extracted instances of each relation. We measure the correctness of extracted\ninstances according to existing correct ones using a recall metric, measuring the ability of our\nproposed methodology to extract instances with respect to all information using a precision\nmetric, and finally, applied an F-measure that denotes the overall accuracy.\nGiven numbers of correctly classified extracted instances, denoted as Nc and actual number of correct instances concepts, denoted as A = Nc + Uc. Where Uc represents undetected instances, Uc were discovered manually by human judge for all text file and T represents the total number of extracted instances.\nThese metrics are defined as follows:\nPatterns can be evaluated by calculating confidence for each pattern with its extracted instances\nwhich were extracted from it. Patterns may be too general, thus they generate invalid instances.\nThe probability of pattern in generating valid instances is calculated by the confidence of the\nextracted patterns for relations as Agichtein and Gravano [21]. The confidence of a pattern P is:-\nWhere positive is the number of correct instances for P and negative is the number of incorrect instances. Table 2 shows that samples of confidence for some patterns.\nFor example, if this pattern P matches three Arabic sentences as shown:\nThe sentence S1 generates instance pair ( 01\u0627 \u0627\u0638 ' , ( ,+ #\u0628\u0627 3\u0631) and sentence S2 generates ( \u062d\u0648 \u0627 \u0629\u062f ,7 8 \u0627 9 + ) which are correct instances, so the first 2 sentences are considered as positive instances. The third sentence S3 generates instance ( #: ;. \u0627 # \u0628 , <=> \u0627 ) which are incorrect\ninstances, so it is considered as a negative instance. Conf P =\n= 0.66. This result is\nsatisfactory, where Conf P > 0.5 and then extracted pattern is mostly reliable. To measure the reliability for patterns;\n1. Calculate confidence for each pattern, if Conf P \u2265 0.5 it is a reliable pattern. 2. Calculate the number of instances that each pattern can extract or detect. 3. Check for new pattern if already exists in previous iterations. Then, this pattern is more reliable."}, {"heading": "5.3. Experimental Results and Analysis", "text": "In this section, we will represent the experimental results of the proposed system. As described above, each experiment started with just 4 different seed instances for each relation type. We will discuss each experiment in details.\nExperiment 1 is author-of (person, book) relation; in the first iteration, our proposed system extracted 23 patterns. Only 9 patterns of them extracted instances. These patterns detected 66 (author, title) pairs of instances, 2 instances were repeated from the input seeds. Due to total extracted instances did not reach the threshold value so it moved to next iteration and this output was added to the table of instances. New extracted instances will be used as input to next iteration. In the second iteration, the system extracted 92 patterns only 24 patterns of them detected instances. These patterns detected 145 pairs of instances. After adding these instances to the table of instances, We found that 25 instances are repeated. Then total extracted instances without repetition were 186 so system terminates iterations after the second iteration. After evaluating these instances, we found 52 incorrect instances and 45 instances were undetected by our system.\nExperiment 2 is president-of (person, country) relation; in the first iteration, our system extracted 10 patterns. Only 3 patterns of them extracted instances. These patterns detected 13 pairs of extracted instances 2 instances were repeated from the input seeds. After adding this output to the instances table, it was found that a total number of extracted instances did not reach a threshold value so it moved to next iteration. In the second iteration, the system extracted 30 patterns only 6 patterns of them extracted instances. These patterns detected 27 pairs of instances. After adding these instances to instances table, it was found that 3 instances were repeated. Then total extracted instances without repetition were 37 so our system went to next iteration due to total extracted instances did not reach a threshold value. In the third iteration, 38 patterns were extracted only 21 patterns of them detected instances. These patterns detected 74 instances, 63 pairs of instances were new instances. After adding these instances to the table of instances, it was found that 11 instances were repeated. Then total extracted instances without repetition were\nfound that 39 incorrect instances and 14 instances were undetected by our system.\nExperiment 3 is play-in (person, club) relation; in the first iteration, our system extracted 17 patterns. Only 12 patterns of them extracted instances. These patterns detected 52 pairs of instances, in which 3 instances were repeated from the input seed. Due to total extracted instances did not get to a threshold value so it moved to next iteration and this output was added to the input table. In the second iteration, the system extracted 111 patterns only 56 patterns of them detected instances. These patterns detected 110 pairs of instances. After adding these instances to the table of instances, we found that 15 instances are repeated. Then total extracted instances without repetition were 147 so system terminates iterations after the second iteration. After evaluating these instances, we found that 41 incorrect instances and 21 instances were undetected by our system.\nExperiment 4 is CEO-of or chairman-of (person, company) relation; in the first iteration, our system extracted 14 patterns. Only 8 patterns of them extracted instances. These patterns detected 37 pairs of instances, in which 4 instances are repeated from the input seed. Due to total extracted instances did not reach a threshold value so it moved to next iteration and this output was added to the input table. In the second iteration, the system extracted 34 patterns only 18 patterns of them were detected instances. These patterns detected 96 pairs of instances. After adding these instances to the table of instances, we found that 18 instances were repeated. Then total extracted instances without repetition were 115 so system terminates iterations after the second iteration. After evaluating all these instances, we found that 29 incorrect instances and 25 instances were undetected by our system.\nAfter applying our proposed system on four different relations types, we observed that the results of some patterns when searched in Google it gives English text results (summaries), we found that, the patterns which contain keywords about relation on prefix or middle give correct instances than the patterns that do not contain any keywords in prefix or middle. We found also that those patterns which are more general extracted incorrect instances and those patterns which are more specific extracted a small number of instances.\nThe results for all experiments are summarized in tables (3 and 4). It can be observed that three types of relations reached a threshold value of extracted instances after the second iteration and one relation \u201cpresident-of\u201d needed to the third iteration to reach this value as shown in table 3 Where \u201cT\u201d represents total number of extracted instances, \u201cN\u201d the number of newly extracted instances and R represents repeated instances in last iterations. R in the first iteration represents a number of instances repeated from input seed instances.\nof patterns that could extract instances. It was observed that Pdetect does not exceed one-third to half from the Ptotal.\nBy evaluating all extracted instances for each relation type after terminating the iterations we found that; the performance of proposed system nearly different from relation type to another as shown in table 5 where \u201cNC\u201d represents correct instances, \u201cI\u201d represents incorrect instances and \u201cUC\u201d represents undetected instances.\nAfter evaluating each extracted patterns by measuring confidences, the average confidence for different iterations was calculated for four relations types as shown in Table 6. The average confidence ranges from 0.6 to 0.8. This means that extracted patterns are accurate.\nand f-measure is shown in Table 7. It can be observed that the best results have been achieved for\n(player, club) relation, whereas results for (president, country) relation are the lowest ones. The\noverall performance for the system is satisfactory."}, {"heading": "6. CONCLUSIONS AND FUTURE WORKS", "text": "In this paper, we introduced a semi-supervised system to extract binary semantic relations for Arabic text from the Web. It only needed a few seed instances as input. Google search engine was used as a source of text. Our system depended on the pattern-based system. The system extracted patterns then searched with these patterns in Google search engine to extract new instances. These new instances were filtered to avoid a noise. Only new unrepeated instances are used as input instances for the next iteration. This iterative process was terminated after a total number of extracted instances reached a threshold value that determined by the user. We performed four experiments for four relations to evaluate the performance of the proposed system. Four common relations were the author-of (person, book) relation, president-of (person, country) relation, playin (person, club) relation and CEO-of or chairman (person, company) relation. Our system was evaluated by four human judges to measure the correctness for extracted instances. The quality of patterns was evaluated after terminating the system by calculating confidence for each pattern with its extracted instances. After that, we measured the performance of the system by calculating Precision, Recall, and F-Measure for extracted instances for each relation type, the result was different from domain to domain. The system can be applied on other domains such as movies (director\u2019s name, film\u2019s name), music (singer, song), political (head\u2019s name, political party) and so on.\nOur future work will focus on the improvement of rules of filtering to obtain corrected instances. And this work will be applied on another dataset to compare its results with results of Google search. Finally, we would like to extract complex relation."}], "references": [{"title": "Automatic Extraction of Hierarchical Relations from Text", "author": ["T.Wang", "Yaoyong Li", "K. Bontcheva", "H. Cunningham", "J. Wang"], "venue": "In Springer-Verlag Berlin Heidelberg IJCNLP", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Information Extraction: Techniques and Challenges", "author": ["R. Grishman"], "venue": "SCIE 1997. LNCS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "A review of relation extraction", "author": ["N. Bach", "S. Badaskar"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "A review on relation extraction with an eye on Portuguese", "author": ["S.C. Abreu", "T.L. Bonamigo", "R. Vieira"], "venue": "In Journal of the Brazilian Computer Society 19,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "REV: Extracting Entity Relations from World Wide Web", "author": ["Chao Chen", "Liang He", "Xin Lin"], "venue": "In proceeding of ACM,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Extracting and Visualizing Semantic Relationships from Chinese Biomedical Text", "author": ["Qingliang Miao", "Shu Zhang", "Bo Zhang", "Yao Meng", "Hao Yu"], "venue": "In proceeding of ACM 26th Pacific Asia Conference on Language, Information and Computation", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Multilingual Extraction of functional relations between Arabic Named Entities using NooJ platform", "author": ["Abdelmajid Ben Hamadou", "Odile Piton", "H\u00e9la Fehri"], "venue": "In Hal-00547940,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Extracting Entities and Relationships from Arabic Text for Information System", "author": ["K. Belkacem", "A. Badr"], "venue": "In Journal of Emerging Trends in Computing and Information Sciences (CIS). VOL", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Extraction of Spatial Relation in Arabic Text Using Rule-Based Approach", "author": ["Fatma Ali Alnairia", "Nazlia Omar", "Mohammed Albared"], "venue": "In proceeding International Journal of Advancements in Computing Technology (IJACT) Volume4,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Extracting relations between Arabic named entities", "author": ["A. Alotayq"], "venue": "In proceeding: TSD2013. Springer-Verlag, Berlin Heidelberg, Pilsen,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "RelANE: Discovering Relations between Arabic Named Entities", "author": ["aInes Boujelben", "Salma Jamoussi", "Abdelmajid Ben Hamadou"], "venue": "In Proceedings for Springer International Publishing Switzerland. (Eds.): TSD 2014,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "A hybrid method for extracting relations between Arabic named entities", "author": ["bInes Boujelben", "Salma Jamoussi", "Abdelmajid Ben Hamadou"], "venue": "In Journal of King Saud University \u2013 Computer and Information Sciences, available online", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Building a WordNet for Arabic", "author": ["S. Elkateb", "W. Black", "H. Rodriguez", "M. Alkhalifa", "P. Vossen", "A. Pease", "C. Fellbaum"], "venue": "In Proceedings of the Fifth International Conference on Language Resources and Evaluation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Extraction of Family Relations between Entities", "author": ["D. Santos", "N. Mamede", "J. Baptista"], "venue": "In proceedings INForum 2010 - II Simp \u0301osio de Inform", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Automatic extraction of ontological relations from Arabic text", "author": ["Mohammed G.H. Al Zamil", "Qasem Al-Radaideh"], "venue": "In Journal of King Saud University \u2013 Computer and Information Sciences", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Discovering relations among named entities from large corpora", "author": ["T. Hasegawa", "S. Sekine", "R. Grishman"], "venue": "In Proceedings of Association for Computational Linguistics", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Discovering Relations between Named Entities from a Large Raw Corpus Using Tree Similarity-Based Clustering", "author": ["Zhang M", "J. Su", "Wang", "G.D.Zhou", "Tan", "C.L"], "venue": "In Proceeding of IJCNLP \u201905, LNAI,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Extracting patterns and relations from the world wide web", "author": ["S. Brin"], "venue": "In WebDB. LNCS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1998}, {"title": "Snowball: Extracting relations from large plain-text collections", "author": ["E. Agichtein", "L. Gravano"], "venue": "In Proceedings of the 5th ACM International Conference on Digital Libraries", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Learning surface text patterns for a question answering system", "author": ["Deepak Ravichandran", "Eduard H. Hovy"], "venue": "In proceeding of the 40th annual meeting of the ACL- July,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "A bootstrapping algorithm for automatically harvesting semantic relations", "author": ["Marco Pennacchiotti", "Patrick Pantel"], "venue": "In Proceedings of Inference in Computational Semantics", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2006}, {"title": "Self-supervised relation extraction from the web", "author": ["Benjamin Rozenfeld", "Ronen Feldman"], "venue": "In proceeding of Knowledge and Information Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "unsupervised named-entity extraction from the Web: an experimental study", "author": ["Oren Etzioni", "Michael Cafarella", "Doug Downey", "Ana-Maria Popescu Tal Shaked", "Stephen Soderland", "Daniel S.Weld", "Alexander Yates"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "Specifically, Information Extraction (IE) [1, 2] is a process which takes texts as input and put them in a structured format, unambiguous data as output.", "startOffset": 42, "endOffset": 48}, {"referenceID": 1, "context": "Specifically, Information Extraction (IE) [1, 2] is a process which takes texts as input and put them in a structured format, unambiguous data as output.", "startOffset": 42, "endOffset": 48}, {"referenceID": 6, "context": "The explicit relation is indicated by a special word or sequence of words in the text, the implicit relation is a relation what can be mined from the text using the context [8].", "startOffset": 173, "endOffset": 176}, {"referenceID": 2, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 93, "endOffset": 96}, {"referenceID": 4, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 142, "endOffset": 151}, {"referenceID": 5, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 142, "endOffset": 151}, {"referenceID": 3, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 200, "endOffset": 203}, {"referenceID": 6, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 7, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 8, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 9, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 10, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 11, "context": "There are several works have been done for RE in English text, some of them were reviewed in [3], also there are some works for RE in Chinese [5, 6, 7], and other works in Portuguese were reviewed in [4] and as far as we know, very few works have been done for RE from Arabic text, it started from 2010 till now such as [8, 9, 10, 11, 12, 13].", "startOffset": 320, "endOffset": 342}, {"referenceID": 3, "context": "These works were grouped according to the used technique into four categories [4, 8] rule-based, supervised, unsupervised and semi-supervised methods.", "startOffset": 78, "endOffset": 84}, {"referenceID": 6, "context": "These works were grouped according to the used technique into four categories [4, 8] rule-based, supervised, unsupervised and semi-supervised methods.", "startOffset": 78, "endOffset": 84}, {"referenceID": 13, "context": "This is due to two reasons: rules should be rewritten for different tasks or when the application is enlarged to different domains and finding rules manually is very hard and time-consuming [15].", "startOffset": 190, "endOffset": 194}, {"referenceID": 6, "context": ", [8] extracted functional relations between Arabic person names and organizations for Arabicnamed entities using the NOOJ platform; they applied their experiment on a journalistic test corpus.", "startOffset": 2, "endOffset": 5}, {"referenceID": 7, "context": "Belkacem and Badr [9] presented some aspects to identify entities and relationships in Arabic text.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": ", [10] developed a prototype for Arabic text spatial relations (topological relations, directional relations, and distance relations).", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "[12] presented a tool called \u201cRelANE\u201d that detect all the semantic binary relations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "and Qasem [17] proposed a methodology that can extract ontological relationships.", "startOffset": 10, "endOffset": 14}, {"referenceID": 15, "context": "Unsupervised methods use clustering techniques and similarities between features or context words such as Hasegawa [18] assumed that pairs occurring in similar contexts share the same type of relation, they can be clustered together, then named entity recognition is applied to identify the entities of interest.", "startOffset": 115, "endOffset": 119}, {"referenceID": 16, "context": ", [19] proposed a tree-similarity-based unsupervised learning method to extract relations between named entities from a large raw corpus.", "startOffset": 2, "endOffset": 6}, {"referenceID": 17, "context": "Semi-supervised methods (weakly supervised) take a sample of patterns or some target relation instances for the purpose to acquire more basics until discovering all target relations such as Brin [20] proposed relation extraction system DIPRE, which starts with a small set of seed facts for one or more relations of interest.", "startOffset": 195, "endOffset": 199}, {"referenceID": 18, "context": "Agichtein and Gravano [21] proposed a system called Snowball, which adopted the similar strategy with DIPRE.", "startOffset": 22, "endOffset": 26}, {"referenceID": 19, "context": "Ravichandran and Hovy [22] extracted simple surface patterns for extracting binary relations from The Web.", "startOffset": 22, "endOffset": 26}, {"referenceID": 20, "context": "Pennacchiotti and Panel [23] proposed a system called Espresso for extracting binary semantic relations.", "startOffset": 24, "endOffset": 28}, {"referenceID": 21, "context": "Rozenfeld and Feldman [24] implemented SRES (SelfSupervised Relation Extraction System).", "startOffset": 22, "endOffset": 26}, {"referenceID": 22, "context": "[25].", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] developed REV (Relation Extraction with Verification).", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Arabic language [14] is a language which different from Indo-European languages syntactically, semantically and morphologically.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "In addition to the problems that are related to Arabic NE recognition and relation extraction task poses some specific challenges listed in [8, 12] some of these challenges are:", "startOffset": 140, "endOffset": 147}, {"referenceID": 10, "context": "In addition to the problems that are related to Arabic NE recognition and relation extraction task poses some specific challenges listed in [8, 12] some of these challenges are:", "startOffset": 140, "endOffset": 147}, {"referenceID": 17, "context": "Similar to several semi-supervised methods such as DIPRE [20] and Snowball [21], the system starts with a small samples of the input initial seed instances (e1, e2) where e1 and e2 represent \u201cnamed entity\u201d.", "startOffset": 57, "endOffset": 61}, {"referenceID": 18, "context": "Similar to several semi-supervised methods such as DIPRE [20] and Snowball [21], the system starts with a small samples of the input initial seed instances (e1, e2) where e1 and e2 represent \u201cnamed entity\u201d.", "startOffset": 75, "endOffset": 79}, {"referenceID": 18, "context": "94 when no new candidate pairs are extracted such as in [21], or when a human observer decides many pairs have been returned such as in [20].", "startOffset": 56, "endOffset": 60}, {"referenceID": 17, "context": "94 when no new candidate pairs are extracted such as in [21], or when a human observer decides many pairs have been returned such as in [20].", "startOffset": 136, "endOffset": 140}, {"referenceID": 18, "context": "The probability of pattern in generating valid instances is calculated by the confidence of the extracted patterns for relations as Agichtein and Gravano [21].", "startOffset": 154, "endOffset": 158}], "year": 2016, "abstractText": "There is a vast amount of unstructured Arabic information on the Web, this data is always organized in semi-structured text and cannot be used directly. This research proposes a semi-supervised technique that extracts binary relations between two Arabic named entities from the Web. Several works have been performed for relation extraction from Latin texts and as far as we know, there isn\u2019t any work for Arabic text using a semi-supervised technique. The goal of this research is to extract a large list or table from named entities and relations in a specific domain. A small set of a handful of instance relations are required as input from the user. The system exploits summaries from Google search engine as a source text. These instances are used to extract patterns. The output is a set of new entities and their relations. The results from four experiments show that precision and recall varies according to relation type. Precision ranges from 0.61 to 0.75 while recall ranges from 0.71 to 0.83. The best result is obtained for (player, club) relationship, 0.72 and 0.83 for precision and recall respectively.", "creator": "PScript5.dll Version 5.2.2"}}}