{"id": "1603.04416", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Mar-2016", "title": "Criteria of efficiency for conformal prediction", "abstract": "we study optimal conformity measures for various criteria sets of efficiency in an idealized setting. this leads to an important class of criteria of efficiency ratings that we call probabilistic ; it turns out that the most standard criteria of efficiency terms used in literature information on software conformal prediction are not probabilistic.", "histories": [["v1", "Mon, 14 Mar 2016 19:49:07 GMT  (21kb,D)", "https://arxiv.org/abs/1603.04416v1", "16 pages"], ["v2", "Wed, 14 Sep 2016 12:57:51 GMT  (38kb,D)", "http://arxiv.org/abs/1603.04416v2", "31 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["vladimir vovk", "ilia nouretdinov", "valentina fedorova", "ivan petej", "alex gammerman"], "accepted": false, "id": "1603.04416"}, "pdf": {"name": "1603.04416.pdf", "metadata": {"source": "CRF", "title": "Criteria of efficiency for conformal prediction\u2217", "authors": ["Vladimir Vovk", "Ilia Nouretdinov", "Valentina Fedorova", "Ivan Petej", "Alex Gammerman"], "emails": ["volodya.vovk@gmail.com", "alushaf@gmail.com", "ivan.petej@gmail.com", "ilia@cs.rhul.ac.uk", "alex@cs.rhul.ac.uk"], "sections": [{"heading": null, "text": "The conference version of this paper has been published in the Proceedings of COPA 2016."}, {"heading": "1 Introduction", "text": "Conformal prediction is a method of generating prediction sets that are guaranteed to have a prespecified coverage probability; in this sense conformal predictors have guaranteed validity. Different conformal predictors, however, widely differ in their efficiency, by which we mean the narrowness, in some sense, of their prediction sets. Empirical investigation of the efficiency of various conformal predictors is becoming a popular area of research: see, e.g., [1, 14] (and the COPA Proceedings, 2012\u20132016). This paper points out that the standard criteria of efficiency used in literature have a serious disadvantage, and we define a class of criteria of efficiency, called \u201cprobabilistic\u201d, that do not share this disadvantage. In two recent papers [3, 5] two probabilistic criteria have been introduced, and in this paper we introduce two more and argue that probabilistic criteria should be used in place of more standard ones. We concentrate on the case of classification only (the label space is finite).\n\u2217A preliminary version of this paper was published as Working Paper 11 of the On-line Compression Modelling project (New Series), http://alrw.net, in April 2014.\nar X\niv :1\n60 3.\n04 41\n6v 2\n[ cs\n.L G\n] 1\nSurprisingly few criteria of efficiency have been used in literature, and even fewer have been studied theoretically. We can speak of the efficiency of individual predictions or of the overall efficiency of predictions on a test sequence; the latter is usually (in particular, in this paper) defined by averaging the efficiency over the individual test examples, and so in this introductory section we only discuss the former. This section assumes that the reader knows the basic definitions of the theory of conformal prediction, but they will be given in Section 2 (and Section 8 for the label-conditional version), which can be consulted now.\nThe two criteria for efficiency of a prediction that have been used most often in literature (in, e.g., the references given above) are:\n\u2022 The confidence and credibility of the prediction (see, e.g., [19], p. 96; introduced in [16]). This criterion does not depend on the choice of a significance level .\n\u2022 Whether the prediction is a singleton (the ideal case), multiple (an inefficient prediction), or empty (a superefficient prediction) at a given significance level . This criterion was introduced in [13], Section 7.2, and used extensively in [19].\nThe other two criteria that had been used before the publication of the conference version [18] of this paper are the sum of the p-values for all potential labels (this does not depend on the significance level) and the size of the prediction set at a given significance level: see the papers [3] and [5].\nIn this paper we introduce six other criteria of efficiency: see Section 2. We then discuss (in Sections 3\u20135) the conformity measures that optimise each of the ten criteria when the data-generating distribution is known; this sheds light on the kind of behaviour implicitly encouraged by the criteria even in the realistic case where the data-generating distribution is unknown. As we point out in Section 5, probabilistic criteria of efficiency are conceptually similar to \u201cproper scoring rules\u201d in probability forecasting [2, 4], and this is our main motivation for their detailed study in this paper. In Section 6 we prove the results of Section 5. After that we briefly illustrate the empirical behaviour of two of the criteria for standard conformal predictors and a benchmark data set (Section 7). Sections 2\u20137 discuss the most standard unconditional conformal predictors. Section 8 defines label-conditional conformal predictors and discusses the analogues of the results of the previous sections for label-conditional predictors. Finally, Section 9 gives some directions of further research.\nA version (with a different treatment of empty observations) of one of the new non-probabilistic criteria of efficiency that we discuss in this paper (the one that we call the E criterion) has been introduced independently in [15].\nWe only consider the case of randomised (\u201csmoothed\u201d) conformal predictors: the case of deterministic predictors may lead to combinatorial problems without an explicit solution (this is the case, e.g., for the N criterion defined below). The situation here is analogous to the Neyman\u2013Pearson lemma: cf. [8], Section 3.2."}, {"heading": "2 Criteria of Efficiency for Conformal Predic-", "text": "tors and Transducers\nLet X be a measurable space (the object space) and Y be a finite set equipped with the discrete \u03c3-algebra (the label space); the example space is defined to be Z := X \u00d7Y. We will always assume that the label space Y is non-empty, and will usually assume that its size is at least 2. A conformity measure is a measurable function A that assigns to every finite sequence (z1, . . . , zn) \u2208 Z\u2217 of examples a same-length sequence (\u03b11, . . . , \u03b1n) of real numbers and that is equivariant with respect to permutations: for any n and any permutation \u03c0 of {1, . . . , n},\n(\u03b11, . . . , \u03b1n) = A(z1, . . . , zn) =\u21d2 ( \u03b1\u03c0(1), . . . , \u03b1\u03c0(n) ) = A ( z\u03c0(1), . . . , z\u03c0(n) ) .\nThe conformal predictor determined by A is defined by\n\u0393 (z1, . . . , zl, x) = \u0393 (z1, . . . , zl, x, \u03c4) := {y | py > } , (1)\nwhere (z1, . . . , zl) \u2208 Z\u2217 is a training sequence, x is a test object, \u2208 (0, 1) is a given significance level, for each y \u2208 Y the corresponding p-value py is defined by\npy = py(z1, . . . , zl, xl+1) := 1\nl + 1 \u2223\u2223{i = 1, . . . , l + 1 | \u03b1yi < \u03b1yl+1}\u2223\u2223 + \u03c4\nl + 1 \u2223\u2223{i = 1, . . . , l + 1 | \u03b1yi = \u03b1yl+1}\u2223\u2223 , (2) \u03c4 is a random number distributed uniformly on the interval [0, 1] (even conditionally on all the examples), and the corresponding sequence of conformity scores is defined by\n(\u03b1y1 , . . . , \u03b1 y l , \u03b1 y l+1) := A(z1, . . . , zl, (x, y)). (3)\nNotice that the system of prediction sets (1) output by a conformal predictor is decreasing in , or nested.\nThe conformal transducer determined by A outputs the system of p-values (py | y \u2208 Y) defined by (2) for each training sequence (z1, . . . , zl) of examples and each test object x. (This is just a different representation of the conformal predictor.)\nNotice that the p-values (2) (and, therefore, the corresponding conformal predictors and transducers) only depend on the conformity order corresponding to the given conformity measure: namely, on the way that the elements of a sequence (z1, . . . , zn) are ordered by the values (\u03b11, . . . , \u03b1n) (with zi zj defined to be \u03b1i \u2264 \u03b1j). Therefore, to define conformal predictors and transducers we may define their conformity orders rather than conformity measures.\nThe standard property of validity for conformal transducers is that the pvalues py are distributed uniformly on [0, 1] when the examples z1, . . . , zl, (x, y)\nare generated independently from the same probability distribution Q on Z and \u03c4 is generated independently from the uniform probability distribution on [0, 1] (see, e.g., [19], Proposition 2.8). This implies that the probability of error, y /\u2208 \u0393 (z1, . . . , zl, x), for conformal predictors is at any significance level .\nSuppose we are given a test sequence (zl+1, . . . , zl+k) and would like to use it to measure the efficiency of the predictions derived from the training sequence (z1, . . . , zl). (Informally, by the efficiency of conformal predictors we mean that the prediction sets they output tend to be small, and by the efficiency of conformal transducers we mean that the p-values they output tend to be small.) For each test example zi = (xi, yi), i = l+ 1, . . . , l+ k, we have a nested family (\u0393 i | \u2208 (0, 1)) of subsets of Y, where\n\u0393 i := \u0393 (z1, . . . , zl, xi),\nand a system of p-values (pyi | y \u2208 Y), where pyi := p y(z1, . . . , zl, xi).\nIn this paper we will discuss ten criteria of efficiency for such a family or a system, but some of them will depend, additionally, on the observed label yi of the test example. We start from the prior criteria, which do not depend on the observed test labels."}, {"heading": "2.1 Basic criteria", "text": "We will discuss two kinds of criteria: those applicable to the prediction sets \u0393 i and so depending on the significance level and those applicable to systems of p-values (pyi | y \u2208 Y) and so independent of . The simplest criteria of efficiency are:\n\u2022 The S criterion (with \u201cS\u201d standing for \u201csum\u201d) measures efficiency by the average sum\n1\nk l+k\u2211 i=l+1 \u2211 y pyi (4)\nof the p-values; small values are preferable for this criterion. It is -free.\n\u2022 The N criterion uses the average size\n1\nk l+k\u2211 i=l+1 |\u0393 i |\nof the prediction sets (\u201cN\u201d stands for \u201cnumber\u201d: the size of a prediction set is the number of labels in it). Small values are preferable. Under this criterion the efficiency is a function of the significance level .\nBoth these criteria are prior. The S criterion was introduced in [3] and the N criterion was introduced independently in [5] and [3], although the analogue of the N criterion for regression (where the size of a prediction set is defined to be its Lebesgue measure) had been used earlier in [11] (whose arXiv version was published in 2012)."}, {"heading": "2.2 Other prior criteria", "text": "A disadvantage of the basic criteria is that they look too stringent. Even for a very efficient conformal transducer, we cannot expect all p-values py to be small: the p-value corresponding to the true label will not be small with high probability; and even for a very efficient conformal predictor we cannot expect the size of its prediction set to be zero: with high probability it will contain the true label. The other prior criteria are less stringent. The ones that do not depend on the significance level are:\n\u2022 The U criterion (with \u201cU\u201d standing for \u201cunconfidence\u201d) uses the average unconfidence\n1\nk l+k\u2211 i=l+1 min y max y\u2032 6=y py \u2032 i (5)\nover the test sequence, where the unconfidence for a test object xi is the second largest p-value miny maxy\u2032 6=y p y\u2032\ni ; small values of (5) are preferable. The U criterion in this form was introduced in [3], but it is equivalent to using the average confidence (one minus unconfidence), which is very common. If two conformal transducers have the same average unconfidence, the criterion compares the average credibilities\n1\nk l+k\u2211 i=l+1 max y pyi , (6)\nwhere the credibility for a test object xi is the largest p-value maxy p y i ; smaller values of (6) are preferable. (Intuitively, a small credibility is a warning that the test object is unusual, and since such a warning presents useful information and the probability of a warning is guaranteed to be small, we want to be warned as often as possible.)\n\u2022 The F criterion uses the average fuzziness\n1\nk l+k\u2211 i=l+1 (\u2211 y pyi \u2212maxy p y i ) , (7)\nwhere the fuzziness for a test object xi is defined as the sum of all pvalues apart from a largest one, i.e., as \u2211 y p y i \u2212maxy p y i ; smaller values of (7) are preferable. If two conformal transducers lead to the same average fuzziness, the criterion compares the average credibilities (6), with smaller values preferable.\nTheir counterparts depending on the significance level are:\n\u2022 The M criterion uses the percentage of objects xi in the test sequence for which the prediction set \u0393 i at significance level is multiple, i.e., contains\nmore than one label. Smaller values are preferable. As a formula, the criterion prefers smaller\n1\nk l+k\u2211 i=l+1 1{|\u0393 i |>1}, (8)\nwhere 1E denotes the indicator function of the event E (taking value 1 if E happens and 0 if not). When the percentage (8) of multiple predictions is the same for two conformal predictors (which is a common situation: the percentage can well be zero when the data is clean and is not too demanding), the M criterion compares the percentages\n1\nk l+k\u2211 i=l+1 1{\u0393 i=\u2205} (9)\nof empty predictions (larger values are preferable). This is a widely used criterion; in particular, it was used in [19] and papers preceding it.\n\u2022 The E criterion (where \u201cE\u201d stands for \u201cexcess\u201d) uses the average (over the test sequence, as usual) amount the size of the prediction set exceeds 1. In other words, the criterion gives the average number of excess labels in the prediction sets as compared with the ideal situation of one-element prediction sets. Smaller values are preferable for this criterion. As a formula, the criterion prefers smaller\n1\nk l+k\u2211 i=l+1 (|\u0393 i | \u2212 1) + ,\nwhere t+ := max(t, 0). When these averages coincide for two conformal predictors, we compare the percentages (9) of empty predictions; larger values are preferable.\nA criterion that is very similar to the M and E criteria is used by Lei in [9] (Section 2.2); that paper considers the binary case, in which the difference between the M and E criteria disappears. The difference of the criterion used in [9] is that it prohibits empty predictions (an intermediate approach would be to prefer smaller values for the number (9) of empty predictions). Lei\u2019s criterion is extended to the multi-class case in [15], which proposes a modification of the E criterion with a different treatment of empty predictions."}, {"heading": "2.3 Observed criteria", "text": "The prior criteria discussed in the previous subsection treat the largest p-value, or prediction sets of size 1, in a special way. The corresponding criteria of this subsection attempt to achieve the same goal by using the observed label.\nThese are the observed counterparts of the non-basic prior -free criteria:\n\u2022 The OU (\u201cobserved unconfidence\u201d) criterion uses the average observed unconfidence\n1\nk l+k\u2211 i=l+1 max y 6=yi pyi\nover the test sequence, where the observed unconfidence for a test example (xi, yi) is the largest p-value p y i for the false labels y 6= yi. Smaller values are preferable for this test.\n\u2022 The OF (\u201cobserved fuzziness\u201d) criterion uses the average sum of the pvalues for the false labels, i.e.,\n1\nk l+k\u2211 i=l+1 \u2211 y 6=yi pyi ; (10)\nsmaller values are preferable.\nThe counterparts of the last group depending on the significance level are:\n\u2022 The OM criterion uses the percentage of observed multiple predictions\n1\nk l+k\u2211 i=l+1 1{\u0393 i\\{yi}6=\u2205}\nin the test sequence, where an observed multiple prediction is defined to be a prediction set including a false label. Smaller values are preferable.\n\u2022 The OE criterion (OE standing for \u201cobserved excess\u201d) uses the average number\n1\nk l+k\u2211 i=l+1 |\u0393 i \\ {yi}|\nof false labels included in the prediction sets at significance level ; smaller values are preferable.\nThe ten criteria used in this paper are given in Table 1. Half of the criteria depend on the significance level , and the other half are the respective -free versions.\nIn the case of binary classification problems, |Y| = 2, the number of different criteria of efficiency in Table 1 reduces to six: the criteria not separated by a vertical or horizontal line (namely, U and F, OU and OF, M and E, and OM and OE) coincide."}, {"heading": "3 Idealised Setting", "text": "Starting from this section we consider the limiting case of infinitely long training and test sequences (and we will return to the realistic finitary case only in Section 7, where we describe our empirical studies). To formalise the intuition of an\ninfinitely long training sequence, we assume that the prediction algorithm is directly given the data-generating probability distribution Q on Z instead of being given a training sequence. Instead of conformity measures we will use idealised conformity measures: functions A(Q, z) of Q \u2208 P(Z) (where P(Z) is the set of all probability measures on Z) and z \u2208 Z. We will fix the data-generating distribution Q for the rest of the paper, and so write the corresponding conformity scores as A(z). The idealised conformal predictor corresponding to A outputs the following prediction set \u0393 (x) for each object x \u2208 X and each significance level \u2208 (0, 1). For each potential label y \u2208 Y for x define the corresponding p-value as\npy = p(x, y) = pA(x, y) = pA(x, y, \u03c4) := Q{z \u2208 Z | A(z) < A(x, y)} + \u03c4Q{z \u2208 Z | A(z) = A(x, y)} (11)\n(it would have been more correct to write A((x, y)) and Q({. . .}), but we often omit pairs of parentheses when there is no danger of ambiguity), where \u03c4 is a random number distributed uniformly on [0, 1]. (The same random number \u03c4 is used in (11) for all (x, y).) The prediction set is\n\u0393 (x) = \u0393 A(x) = \u0393 A(x, \u03c4) := {y \u2208 Y | p(x, y) > } . (12)\nThe idealised conformal transducer corresponding to A outputs for each object x \u2208 X the system of p-values (py | y \u2208 Y) defined by (11); in the idealised case we will usually use the alternative notation p(x, y) for py.\nWe could have used the idealised conformity order when defining the pvalues (11): z z\u2032 is defined to mean A(z) \u2264 A(z\u2032). Let us say that two idealised conformity measures are equivalent if they lead to the same idealised conformity order; in other words, A and B are equivalent if, for all z, z\u2032 \u2208 Z, A(z) \u2264 A(z\u2032)\u21d4 B(z) \u2264 B(z\u2032).\nThe standard properties of validity for conformal transducers and predictors mentioned in the previous section simplify in this idealised case as follows:\n\u2022 If (x, y) is generated from Q and \u03c4 \u2208 [0, 1] is generated from the uniform\ndistribution independently of (x, y), p(x, y) is distributed uniformly on [0, 1].\n\u2022 Therefore, at each significance level the idealised conformal predictor makes an error with probability .\nThe test sequence being infinitely long is formalised by replacing the use of a test sequence in the criteria of efficiency by averaging with respect to the datagenerating probability distribution Q. In the case of the top two and bottom two criteria in Table 1 (the ones set in italics) this is done as follows. An idealised conformity measure A is:\n\u2022 S-optimal if, for any idealised conformity measure B,\nEx,\u03c4 \u2211 y\u2208Y pA(x, y) \u2264 Ex,\u03c4 \u2211 y\u2208Y pB(x, y), (13)\nwhere the notation Ex,\u03c4 refers to the expected value when x and \u03c4 are independent, x \u223c QX, and \u03c4 \u223c U ; QX is the marginal distribution of Q on X, and U is the uniform distribution on [0, 1];\n\u2022 N-optimal if, for any idealised conformity measure B and any significance level ,\nEx,\u03c4 |\u0393 A(x)| \u2264 Ex,\u03c4 |\u0393 B(x)| ;\n\u2022 OF-optimal if, for any idealised conformity measure B,\nE(x,y),\u03c4 \u2211 y\u2032 6=y pA(x, y \u2032) \u2264 E(x,y),\u03c4 \u2211 y\u2032 6=y pB(x, y \u2032),\nwhere the lower index (x, y) in E(x,y),\u03c4 refers to averaging over (x, y) \u223c Q (with (x, y) and \u03c4 independent);\n\u2022 OE-optimal if, for any idealised conformity measure B and any significance level ,\nE(x,y),\u03c4 |\u0393 A(x) \\ {y}| \u2264 E(x,y),\u03c4 |\u0393 B(x) \\ {y}| .\nWe will define the idealised versions of the other six criteria listed in Table 1 in Section 5."}, {"heading": "4 Probabilistic Criteria of Efficiency", "text": "Our goal in this section is to characterise the optimal idealised conformity measures for the four criteria of efficiency that are set in italics in Table 1. We will assume in the rest of the paper that the set X is finite (from the practical point of view, this is not a restriction); since we consider the case of classification, |Y| < \u221e, this implies that the whole example space Z is finite. Without loss of generality, we also assume that the data-generating probability distribution\nQ satisfies QX(x) > 0 for all x \u2208 X (we often omit curly braces in expressions such as QX({x})): we can always omit the xs for which QX(x) = 0.\nThe conditional probability (CP) idealised conformity measure is\nA(x, y) = Q(y | x) = QY|X(y | x) := Q(x, y)\nQX(x) . (14)\n(In this paper, we will invariably use the shorter notation Q(y | x) instead of the more precise QY|X(y | x); we will never need QX|Y, which could be defined analogously.) This idealised conformity measure was introduced by an anonymous referee of the conference version of [3], but its non-idealised analogue in the case of regression had been used in [11] (following [10] and literature on minimum volume prediction). We say that an idealised conformity measure A is a refinement of an idealised conformity measure B if\nB(z1) < B(z2) =\u21d2 A(z1) < A(z2) (15)\nfor all z1, z2 \u2208 Z. Let R(CP) be the set of all refinements of the CP idealised conformity measure. If C is a criterion of efficiency (one of the ten criteria in Table 1), we let O(C) stand for the set of all C-optimal idealised conformity measures.\nTheorem 1. O(S) = O(OF) = O(N) = O(\u0152) = R(CP). We say that an efficiency criterion is probabilistic if the CP idealised conformity measure is always optimal for it. We will also use two modifications of this definition: an efficiency criterion is strongly probabilistic if any refinement of the CP idealised conformity measure is optimal for it, and it is weakly probabilistic if some refinement of the CP idealised conformity measure is optimal for it. We will say that it is BW probabilistic (or binary-weakly probabilistic) if some refinement of the CP idealised conformity measure is optimal for it whenever |Y| = 2. Theorem 1 shows that four of our ten criteria are strongly probabilistic, namely S, N, OF, and OE (they are set in italics in Table 1). In the next section we will see that in general the other six criteria are not probabilistic (they are only BW probabilistic). The intuition behind probabilistic criteria will be briefly discussed also in the next section.\nProof of Theorem 1. We start from proving R(CP) = O(N). Let A be any idealised conformity measure. Fix for a moment a significance level . For each example (x, y) \u2208 Z, let P (x, y) be the probability that the idealised conformal predictor based on A makes an error on the example (x, y) at the significance level , i.e., the probability (over \u03c4) of y /\u2208 \u0393 A(x). It is clear from (11) and (12) that P takes at most three possible values (0, 1, and an intermediate value) and that \u2211\nx,y\nQ(x, y)P (x, y) = (16)\n(which just reflects the fact that the probability of error is ). Vice versa, any P satisfying these properties will also satisfy\n\u2200(x, y) : P (x, y) = P\u03c4 (y /\u2208 \u0393 A(x, \u03c4))\nfor some A, P\u03c4 standing for the probability when \u03c4 \u223c U . Let us see when we will have A \u2208 O(N) (A is an N-optimal idealised conformity measure). Define Q\u2032 to be the probability measure on Z such that Q\u2032X = QX and Q\n\u2032(y | x) = 1/ |Y| does not depend on y. The N criterion at significance level for A can be evaluated as\nEx,\u03c4 |\u0393 A(x)| = |Y| 1\u2212 \u2211 (x,y)\u2208Z Q\u2032(x, y)P (x, y)  ; (17) this expression should be minimised, i.e., \u2211 (x,y)Q \u2032(x, y)P (x, y) should be maximised, under the restriction (16). Let us apply the Neyman\u2013Pearson fundamental lemma ([8], Sect. 3.2, Theorem 1) using Q as the null and Q\u2032 as the alternative hypotheses. We can see that Ex,\u03c4 |\u0393 A(x)| takes its minimal value if and only if there exist thresholds k1 = k1( ), k2 = k2( ), and k3 = k3( ) such that:\n\u2022 Q{(x, y) | Q(y | x) < k1} < \u2264 Q{(x, y) | Q(y | x) \u2264 k1},\n\u2022 k2 < k3,\n\u2022 A(x, y) < k2 if Q(y | x) < k1,\n\u2022 k2 < A(x, y) < k3 if Q(y | x) = k1,\n\u2022 A(x, y) > k3 if Q(y | x) > k1.\nThis will be true for all if and only if Q(y | x) is a function of A(x, y) (meaning that there exists a function F such that, for all (x, y), Q(y | x) = F (A(x, y))). This completes the proof of R(CP) = O(N).\nNext we show that O(N) = O(S). The chain of equalities\n\u2211 y\u2208Y p(x, y) = \u2211 y\u2208Y \u222b 1 0 1{p(x,y)> } d\n= \u222b 1 0 \u2211 y\u2208Y 1{p(x,y)> } d = \u222b 1 0 |\u0393 (x)| d (18)\n(which will be used as the model in several other proofs in the rest of this paper) implies, by Fubini\u2019s theorem,\nEx,\u03c4 \u2211 y\u2208Y p(x, y) = \u222b 1 0 Ex,\u03c4 |\u0393 (x)| d . (19)\nWe can see that A \u2208 O(S) whenever A \u2208 O(N): indeed, any N-optimal idealised conformity measure minimises the expectation Ex,\u03c4 |\u0393 (x)| on the right-hand side of (19) for all simultaneously, and so minimises the whole right-hand-side, and so minimises the left-hand-side. On the other hand, A /\u2208 O(S) whenever\nA /\u2208 O(N): indeed, if an idealised conformity measure fails to minimise the expectation Ex,\u03c4 |\u0393 (x)| on the right-hand side of (19) for some , it fails to do so for all in a non-empty open interval (because of the right-continuity of Ex,\u03c4 |\u0393 (x)| in , which is proved in Lemma 1(b) below), and therefore, it does not minimise the right-hand side of (19) (any N-optimal idealised conformity measure, such as the CP idealised conformity measure, will give a smaller value), and therefore, it does not minimise the left-hand side of (19).\nThe equality O(S) = O(OF) follows from\nEx,\u03c4 \u2211 y p(x, y) = E(x,y),\u03c4 \u2211 y\u2032 6=y p(x, y\u2032) + 1 2 ,\nwhere we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [19]).\nFinally, we notice that O(N) = O(\u0152). Indeed, for any significance level ,\nEx,\u03c4 |\u0393 (x)| = E(x,y),\u03c4 |\u0393 (x) \\ {y}|+ (1\u2212 ),\nagain using the fact that p(x, y) is distributed uniformly on [0, 1] and so P(x,y),\u03c4 (y \u2208 \u0393 (x)) = 1 \u2212 , where P(x,y),\u03c4 refers to the probability when (x, y) \u223c Q and \u03c4 \u223c U are independent.\nThe following lemma was used in the proof of Theorem 1.\nLemma 1. (a) The function \u0393 (x) = \u0393 (x, \u03c4) of is right-continuous for fixed x and \u03c4 . (b) The function Ex,\u03c4 |\u0393 (x)| is right-continuous in .\nProof. Let us first check (a). We have (i) p(x, y, \u03c4) > for all y \u2208 \u0393 (x, \u03c4), and (ii) p(x, y, \u03c4) \u2264 for all y /\u2208 \u0393 (x, \u03c4). If we increase , (ii) will be still satisfied, and if the increase is sufficiently small, (i) will be also satisfied and, therefore, \u0393 (x, \u03c4) will not change. As for (b), the right-continuity of \u0393 (x, \u03c4) in implies the right-continuity of |\u0393 (x, \u03c4)| in , which implies the right-continuity of Ex,\u03c4 |\u0393 (x, \u03c4)| in by the Lebesgue dominated convergence theorem.\nRemark. The statement O(S) = R(CP) of Theorem 1 can be generalised to the criterion S\u03c6 preferring small values of\n1\nk l+k\u2211 i=l+1 \u2211 y \u03c6(pyi ) or Ex,\u03c4 \u2211 y \u03c6(p(x, y))\n(instead of (4) or (13), respectively), where \u03c6 : [0, 1]\u2192 R is a fixed continuously differentiable strictly increasing function, not necessarily the identity function. Namely, we still have O(S\u03c6) = R(CP). Indeed, we can assume, without loss of generality, that \u03c6(0) = 0 and \u03c6(1) = 1 and replace (18) by\n\u2211 y\u2208Y \u03c6(p(x, y)) = \u2211 y\u2208Y \u222b 1 0 1{\u03c6(p(x,y))> } d = \u222b 1 0 \u2211 y\u2208Y 1{p(x,y)>\u03c6\u22121( )} d\n= \u222b 1 0 \u2223\u2223\u2223\u0393\u03c6\u22121( )(x)\u2223\u2223\u2223 d = \u222b 1 0 \u2223\u2223\u2223\u0393 \u2032(x)\u2223\u2223\u2223\u03c6\u2032( \u2032) d \u2032, where \u03c6\u2032 is the (continuous) derivative of \u03c6, and then use the same argument as before."}, {"heading": "5 Criteria of Efficiency that are not Probabilis-", "text": "tic\nNow we define the idealised analogues of the six criteria that are not set in italics in Table 1. An idealised conformity measure A is:\n\u2022 U-optimal if, for any idealised conformity measure B, we have either\nEx,\u03c4 min y max y\u2032 6=y\npA(x, y \u2032) < Ex,\u03c4 min\ny max y\u2032 6=y\npB(x, y \u2032) (20)\nor both Ex,\u03c4 min\ny max y\u2032 6=y\npA(x, y \u2032) = Ex,\u03c4 min\ny max y\u2032 6=y\npB(x, y \u2032) (21)\nand Ex,\u03c4 max\ny pA(x, y) \u2264 Ex,\u03c4 max y pB(x, y); (22)\n\u2022 M-optimal if, for any idealised conformity measure B and any significance level , we have either\nPx,\u03c4 (|\u0393 A(x)| > 1) < Px,\u03c4 (|\u0393 B(x)| > 1) (23)\nor both Px,\u03c4 (|\u0393 A(x)| > 1) = Px,\u03c4 (|\u0393 B(x)| > 1) (24)\nand Px,\u03c4 (|\u0393 A(x)| = 0) \u2265 Px,\u03c4 (|\u0393 B(x)| = 0); (25)\n\u2022 F-optimal if, for any idealised conformity measure B, we have either\nEx,\u03c4 (\u2211\ny\npA(x, y)\u2212max y\npA(x, y) ) < Ex,\u03c4 (\u2211 y pB(x, y)\u2212max y pB(x, y) )\n(26) or both\nEx,\u03c4 (\u2211\ny\npA(x, y)\u2212max y\npA(x, y) ) = Ex,\u03c4 (\u2211\ny\npB(x, y)\u2212max y\npB(x, y) )\n(27) and (22);\n\u2022 E-optimal if, for any idealised conformity measure B and any significance level , we have either\nEx,\u03c4 ( (|\u0393 A(x)| \u2212 1) +) < Ex,\u03c4 ( (|\u0393 B(x)| \u2212 1) +) (28)\nor both Ex,\u03c4 ( (|\u0393 A(x)| \u2212 1) +) = Ex,\u03c4 ( (|\u0393 B(x)| \u2212 1) +) (29)\nand (25);\n\u2022 OU-optimal if, for any idealised conformity measure B,\nE(x,y),\u03c4 max y\u2032 6=y\npA(x, y \u2032) \u2264 E(x,y),\u03c4 max\ny\u2032 6=y pB(x, y\n\u2032); (30)\n\u2022 OM-optimal if, for any idealised conformity measure B and any significance level ,\nP(x,y),\u03c4 (\u0393 A(x) \\ {y} 6= \u2205) \u2264 P(x,y),\u03c4 (\u0393 B(x) \\ {y} 6= \u2205). (31)\nIn the following three definitions we follow [19], Chapter 3. The predictability of x \u2208 X is\nf(x) := max y\u2208Y\nQ(y | x). (32)\nA choice function y\u0302 : X\u2192 Y is defined by the condition\n\u2200x \u2208 X : f(x) = Q(y\u0302(x) | x). (33)\nDefine the signed predictability idealised conformity measure corresponding to y\u0302 by\nA(x, y) :=\n{ f(x) if y = y\u0302(x)\n\u2212f(x) if not;\na signed predictability (SP) idealised conformity measure is the signed predictability idealised conformity measure corresponding to some choice function.\nFor the following two theorems we will need to modify the notion of refinement. Let R\u2032(SP) be the set of all idealised conformity measures A such that there exists an SP idealised conformity measure B that satisfies both (15) and\nB(x, y1) = B(x, y2) =\u21d2 A(x, y1) = A(x, y2)\nfor all x \u2208 X and y1, y2 \u2208 Y.\nTheorem 2. O(U) = O(M) = R\u2032(SP).\nTheorems 2\u20134 will be proved in Section 6 below. Define the MCP (modified conditional probability) idealised conformity mea-\nsure corresponding to a choice function y\u0302 by\nA(x, y) := { Q(y | x) if y = y\u0302(x) Q(y | x)\u2212 1 if not;"}, {"heading": "S: CP (Theorem 1) N: CP (Theorem 1)", "text": "an MCP idealised conformity measure is an idealised conformity measure corresponding to some choice function; R(MCP) is defined analogously to R(CP) but using MCP idealised conformity measures rather than the CP idealised conformity measure.\nTheorem 3. O(F) = O(E) = R(MCP).\nOf course, Theorems 2 and 3 are equivalent when |Y| = 2. The modified signed predictability (MSP) idealised conformity measure is\ndefined by\nA(x, y) :=  f(x) if f(x) > 1/2 and y = y\u0302(x)\n0 if f(x) \u2264 1/2 \u2212f(x) if f(x) > 1/2 and y 6= y\u0302(x),\nwhere f is the predictability function (32); notice that this definition is unaffected by the choice of the choice function. Let R\u2032\u2032(MSP) be the set of all refinements A of the MSP idealised conformity measure such that, for all x \u2208 X and all y1, y2 \u2208 Y:\nf(x) \u2265 0.5 & Q(y1 | x) < 0.5 & Q(y2 | x) < 0.5 =\u21d2 A(x, y1) = A(x, y2) f(x) < 0.5 =\u21d2 A(x, y1) = A(x, y2).\nTheorem 4. O(OU) = O(OM) = R\u2032\u2032(MSP).\nTable 2 summarises the results given above. For each of the criteria listed in Table 1 it gives an optimal idealised conformity measure and cites the result asserting the optimality of that idealised conformity measure.\nTheorems 2\u20134 show that the six criteria that are not set in italics in Table 1 are not probabilistic (however, we will see in Corollary 1 below that they are BW probabilistic). These are simple explicit examples (inevitably involving label spaces Y with |Y| > 2) showing that they are not even weakly probabilistic:\n\u2022 Let X = {1}, Y = {1, 2, 3}, and\nQX(1) = 1 Q(1 | 1) = 0.2 Q(2 | 1) = 0.3 Q(3 | 1) = 0.5. (34)\n(Remember that, in this paper, Q(y | x) always means QY|X(y | x).) In this case, all refinements of the CP idealised conformity measure are equivalent. The U criterion is not probabilistic since the expression\nEx,\u03c4 min y max y\u2032 6=y\np(x, y\u2032) (35)\n(cf. (20)) is 0.35 for the CP idealised conformity measure and is smaller, 0.25, for the SP idealised conformity measure. The M criterion is not probabilistic since at significance level = 0.2 the CP idealised conformity measure gives the predictor \u0393 (1) = {2, 3} (a.s.), and so\nPx,\u03c4 (|\u0393 CP(x)| > 1) = 1 > 0.6 = Px,\u03c4 (|\u0393 SP(x)| > 1)\n(cf. (23)).\n\u2022 Let X = {1, 2}, Y = {1, 2, 3}, and, for a small \u03b4 > 0,\nQX(1) = 0.5 Q(1 | 1) = 1/3\u2212 \u03b4 Q(2 | 1) = 1/3 Q(3 | 1) = 1/3 + \u03b4 QX(2) = 0.5 Q(1 | 2) = 1/3\u2212 5\u03b4 Q(2 | 2) = 1/3 + 2\u03b4 Q(3 | 2) = 1/3 + 3\u03b4.\nThe CP idealised conformity measure again has only equivalent refinements. The F criterion is not probabilistic since the expression\nEx,\u03c4 (\u2211\ny\np(x, y)\u2212max y\np(x, y) )\n(36)\n(cf. (26)) is 3/4 + O(\u03b4) for the CP idealised conformity measure and is smaller (provided \u03b4 is sufficiently small), 2/3+O(\u03b4), for the MCP idealised conformity measure (which is unique). The E criterion is not probabilistic since at significance level = 2/3 the CP idealised conformity measure has a larger expected excess (for small \u03b4) than the MCP idealised conformity measure (whose expected excess is zero):\nEx,\u03c4 ( (|\u0393 CP(x)| \u2212 1) +) = 0.5 +O(\u03b4) > 0 = Ex,\u03c4 ( (|\u0393 MCP(x)| \u2212 1) +) (cf. (28)).\n\u2022 Let us again set X = {1} and Y = {1, 2, 3}, and define Q by (34). The OU criterion is not probabilistic since the expression\nE(x,y),\u03c4 max y\u2032 6=y\np(x, y\u2032) (37)\n(cf. (30)) is 0.55 for the CP idealised conformity measure and is smaller, 0.5, for the MSP idealised conformity measure. The OM criterion is not probabilistic since at significance level = 0.2 the CP idealised conformity measure gives the predictor \u0393 (1) = {2, 3} (a.s.), and so\nP(x,y),\u03c4 (\u03930.2CP(x) \\ {y} 6= \u2205) = 1 > 0.8 = P(x,y),\u03c4 (\u03930.2MSP(x) \\ {y} 6= \u2205)\n(cf. (31)).\nCorollary 1. All ten criteria of efficiency in Table 1 are BW probabilistic.\nProof. Criteria S, N, OF, and OE are BW probabilistic by Theorem 1. Criteria OU and OM are identical to OF and OE, respectively, in the binary case, and so are also BW probabilistic. Criteria F and E are identical to U and M, respectively, in the binary case, and so our task reduces to proving that U and M are BW probabilistic. By Theorem 2, it suffices to checkR(CP)\u2229R\u2032(SP) 6= \u2205, which is obvious: SP is in both R(CP) and R\u2032(SP) when |Y| = 2.\nCriteria of efficiency that are not probabilistic are somewhat analogous to \u201cimproper scoring rules\u201d in probability forecasting (see, e.g., [2] and [4]). The optimal idealised conformity measures for the criteria of efficiency given in this paper that are not probabilistic have clear disadvantages, such as:\n\u2022 They depend on the arbitrary choice of a choice function. In many cases there is a unique choice function, but the possibility of non-uniqueness is still awkward.\n\u2022 They encourage \u201cstrategic behaviour\u201d (such as ignoring the differences, which may be very substantial, between potential labels other than y\u0302(x) for a test object x when using the M criterion in the case |Y| > 2).\nHowever, we do not use the terminology \u201cproper/improper\u201d in the case of criteria of efficiency for conformal prediction since it is conceivable that some non-probabilistic criteria of efficiency may still turn out to be useful."}, {"heading": "6 Proofs of Theorems 2\u20134", "text": "The proofs in this section will be slightly less formal than the proof of Theorem 1; in particular, all references to the Neyman\u2013Pearson lemma will be implicit."}, {"heading": "6.1 Proof of Theorem 2", "text": "We start from checking that O(M) = R\u2032(SP) (essentially reproducing the argument given in the second parts of the proofs of Propositions 3.3 and 3.4 in [19]). We will analyze the requirements imposed by being M-optimal on the prediction set \u0393 starting from small values of \u2208 (0, 1). (In this paper we only consider in the interval (0, 1), even if this restriction is not mentioned explicitly.)\nLet f1 > f2 > \u00b7 \u00b7 \u00b7 > fn > 0 be the list of the predictabilities (see (32)) of all objects x \u2208 X, with all duplicates removed and the remaining predictabilities sorted in the decreasing order. It is clear that an M-optimal idealised conformity measure will assign the lowest conformity to the group of examples (x, y) with f(x) = f1 and y 6= y\u0302(x) for some choice function y\u0302 (see (33)). The conformity of such examples can be different unless they contain the same object (in which case it must be the same); the conformity of any example in any other group must be higher than the conformity of the examples in this first group. If these\nconditions are satisfied for some idealised conformity measure A, A will satisfy (23) or (24) for any idealised conformity measure B and any\n\u2208 (0, Q {(x, y) | f(x) = f1 & y 6= y\u0302(x)}] .\nThe second least conforming group of examples consists of (x, y) with f(x) = f2 and y 6= y\u0302(x) for some choice function y\u0302. The conformity of examples in the second group can again be different unless they contain the same object. These and previous conditions ensure that A will satisfy (23) or (24) for any\n\u2208 (0, Q {(x, y) | f(x) \u2265 f2 & y 6= y\u0302(x)}] .\nContinuing in such a way, we will obtain a choice function y\u0302 and the conformity ordering for the examples whose label is not chosen by that choice function y\u0302. All these examples are divided into n groups, and each elements of the ith group is coming before each element of the jth group when i < j; in the end we will get 2n groups satisfying this property. The first n groups take care of\n\u2208 (0, Q {(x, y) | y 6= y\u0302(x)}] .\nThe next, (n+ 1)th, group of examples are (x, y\u0302(x)) \u2208 Z with f(x) = fn; they can be ordered in any way between themselves. If the conditions listed so far are satisfied for an idealised conformity measure A, A will satisfy (23)\u2013(25) for any idealised conformity measure B and any\n\u2208 (0, Q {(x, y) | y 6= y\u0302(x) or (y = y\u0302(x) & f(x) = fn)}] .\nThe following, (n + 2)th, group consists of (x, y\u0302(x)) \u2208 Z with f(x) = fn\u22121. Continuing in the same way until all examples are exhausted, we will obtain a refinement of the SP idealised conformity measure that belongs to R\u2032(SP).\nThis proof of O(M) = R\u2032(SP) demonstrates the following property of Moptimal idealised conformity measures.\nCorollary 2. If A \u2208 O(M),\nPx,\u03c4 (|\u0393 A(x)| > 1)Px,\u03c4 (|\u0393 A(x)| = 0) = 0\nat each significance level .\nLet us now check that O(U) = O(M). Analogously to (18) and (19), we have, for a given idealised conformity measure A (omitted from our notation),\nEx,\u03c4 min y max y\u2032 6=y\np(x, y\u2032, \u03c4) = Ex,\u03c4 \u222b 1\n0\n1{miny maxy\u2032 6=y p(x,y\u2032,\u03c4)> } d = Ex,\u03c4 \u222b 1\n0\n1{|\u0393 (x)|>1} d = \u222b 1 0 Px,\u03c4 (|\u0393 (x)| > 1) d . (38)\nSimilarly, we have\nEx,\u03c4 max y\np(x, y, \u03c4) = Ex,\u03c4 \u222b 1\n0\n1{maxy p(x,y,\u03c4)> } d = Ex,\u03c4 \u222b 1\n0\n1{|\u0393 (x)|>0} d = \u222b 1 0 Px,\u03c4 (|\u0393 (x)| > 0) d\n= 1\u2212 \u222b 1\n0\nPx,\u03c4 (|\u0393 (x)| = 0) d . (39)\nOur argument will also use the following continuity property for idealised conformal predictors. (For now, we only need parts (a) and (b).)\nCorollary 3. The functions\n(a) Px,\u03c4 (|\u0393 (x)| > 1)\n(b) Px,\u03c4 (|\u0393 (x)| = 0) (c) Ex,\u03c4 ( (|\u0393 (x)| \u2212 1)+ )\n(d) P(x,y),\u03c4 (\u0393 (x) \\ {y} 6= \u2205)\nare right-continuous in .\nProof. All these statements can be deduced from part (a) of Lemma 1 in the same way as in the proof of part (b) of that lemma. The right-continuity of the function \u0393 (x, \u03c4) implies the right-continuity of 1{|\u0393 (x)|>1} (remember that |\u0393 (x)| takes only integer values). Therefore, the right-continuity of Px,\u03c4 (|\u0393 (x)| > 1) follows by the Lebesgue dominated convergence theorem. This proves (a), and proofs of (b)\u2013(d) are analogous.\nFirst suppose that A is M-optimal. Let B be any idealised conformity measure. From (38), it is clear that (20) holds with < replaced by \u2264. If, furthermore, we have (21): by Corollary 3 we also have (24) for all ; therefore, we also have (25) for all ; in combination with (39), we obtain (22). Therefore, A is U-optimal.\nNow suppose that A is U-optimal. Let B be the SP idealised conformity measure, which we know to be not only M-optimal but also U-optimal (as shown in the previous paragraph). By the definition ((20)\u2013(22)) of U-optimality, we have (21) and (22) with = in place of \u2264. This implies that (24) holds for all (had the equality been violated for some \u2208 (0, 1), it would have been violated for a range of by Corollary 3, which would have contradicted (21)). In the same way, it implies that (25) holds (even with = in place of \u2265) for all . Therefore, A is M-optimal."}, {"heading": "6.2 Proof of Theorem 3", "text": "Our argument for O(E) = R(MCP) will be similar to the argument for O(M) = R\u2032(SP) given in the previous subsection; we will again analyze the requirements imposed by being E-optimal starting from small values of \u2208 (0, 1).\nLet g1 < g2 < \u00b7 \u00b7 \u00b7 < gn be the list of the conditional probabilities Q(y | x) of all examples (x, y) \u2208 Z, with all duplicates removed and the remaining conditional probabilities sorted in the increasing order. All examples will be split into 2n groups, with the examples in the ith and (n + i)th groups satisfying Q(y | x) = gi, i = 1, . . . , n. Initially the ith group, i = 1, . . . , n, contains all examples satisfying Q(y | x) = gi, and the other groups are empty. (Later some of the examples will be moved into the groups numbered n+1, n+2, . . ., and as a result some of the first n groups may become empty.) It will be true that each element of the ith group will be coming before each element of the jth group when 1 \u2264 i < j \u2264 2n.\nAny F-optimal idealised conformity measure will assign the lowest conformity to the first group of examples, perhaps except for examples (x, y) for which Q(y | x) = maxy\u2032 Q(y\u2032 | x). If for some x \u2208 X, the first group contains (x, y) with Q(y | x) = maxy\u2032 Q(y\u2032 | x), we choose one such (x, y) for each such x and move it to the (n + 1)th group. The rest of the examples in the group can be ordered in their conformity in any way (with ties allowed). The examples in the (n + 1)th group can also be ordered arbitrarily. Process the 2nd, 3rd,. . . , nth groups in the same way. It is clear that in the end we will obtain a refinement of an MCP idealised conformity measure.\nNext we prove O(E) = O(F). Defining a p-choice function y\u0303 : X \u2192 Y (for a given idealised conformity measure) by the requirement\np(x, y\u0303(x)) = max y p(x, y),\nwe have the following analogue of (18):\u2211 y\u2208Y p(x, y)\u2212max y\u2208Y p(x, y) = \u2211 y\u2208Y\\{y\u0303(x)} p(x, y) = \u2211 y\u2208Y\\{y\u0303(x)} \u222b 1 0 1{p(x,y)> } d\n= \u222b 1 0 \u2211 y\u2208Y\\{y\u0303(x)} 1{p(x,y)> } d = \u222b 1 0 (|\u0393 (x)| \u2212 1)+ d .\nThis implies, similarly to (19),\nEx,\u03c4 \u2211 y\u2208Y p(x, y)\u2212max y\u2208Y p(x, y)  = \u222b 1 0 Ex,\u03c4 ( (|\u0393 (x)| \u2212 1)+ ) d . (40)\nSuppose that A is E-optimal, and let B be any idealised conformity measure. From (40), it is clear that (26) holds with < replaced by \u2264. If, furthermore, we have (27): by Corollary 3(c) we also have (29) for all ; therefore, we also have (25) for all ; in combination with (39), we obtain (22). Therefore, A is F-optimal.\nNow suppose that A is F-optimal. Let B be any MCP idealised conformity measure, which we know to be both E-optimal and F-optimal. By the definition of F-optimality, we have (27) and (22) with = in place of \u2264. As in the previous subsection, this implies that (29) holds for all , and also implies that (25) holds (even with = in place of \u2265) for all . Therefore, A is E-optimal."}, {"heading": "6.3 Proof of Theorem 4", "text": "The proof is similar to the proofs in the previous two subsections. First we check that O(OM) = R\u2032\u2032(MSP), analyzing the requirement of OM-optimality starting from small values of \u2208 (0, 1). Let f1 > f2 > \u00b7 \u00b7 \u00b7 > fn > 0.5 be the list of the predictabilities of all objects x \u2208 X whose predictability exceeds 0.5, with all duplicates removed and the remaining predictabilities sorted in the decreasing order. All examples are split into 2n+ 1 groups (perhaps some of them empty) in such a way that each element of the ith group is coming before each element of the jth group when 1 \u2264 i < j \u2264 2n+ 1. The ith group, i = 1, . . . , n, contains all examples (x, y) with predictability fi and Q(y | x) < 1/2, the (n+1)th group contains all examples with predictability 0.5 or less, and the (n+1+ i)th group, i = 1, . . . , n, contains all examples (x, y) with Q(y | x) = fi (there is, however, at most one such example); it is possible that n = 0.\nAny OM-optimal idealised conformity measure will assign the lowest conformity to the first group of examples (assuming n \u2265 1), and those examples can be ordered arbitrarily in their conformity, except that any examples sharing their objects should have the same conformity. This group takes care of the values\n\u2208 (0, Q {(x, y) | f(x) = f1 & Q(y | x) 6= f1}] .\nProceed in the same way through groups 2, . . . , n. The (n+ 1)th group is most complicated (when non-empty). It contains the following kinds of examples:\n\u2022 Examples whose predictability is less than 0.5. All such examples should have the same conformity if they share the same object.\n\u2022 Examples (x, y) whose predictability is exactly 0.5 and which satisfy Q(y | x) < 0.5. All such examples should have the same conformity if they share the same object.\n\u2022 Examples (x, y) whose predictability is exactly 0.5 and which satisfy Q(y | x) = 0.5.\nOtherwise, the examples in the (n + 1)th group can be ordered arbitrarily in their conformity. Groups n+ 2, . . . , 2n+ 1 are singletons or empty and do not cause any problems. Therefore, an idealised conformity measure is OM-optimal if and only if it is in R\u2032\u2032(MSP).\nNext we check that O(OU) = O(OM). Similarly to (38), we have, for a given idealised conformity measure,\nE(x,y),\u03c4 max y\u2032 6=y\np(x, y\u2032, \u03c4) = E(x,y),\u03c4 \u222b 1\n0\n1{maxy\u2032 6=y p(x,y\u2032,\u03c4)> } d = E(x,y),\u03c4 \u222b 1\n0\n1{\u0393 (x)\\{y}6=\u2205} d = \u222b 1 0 Px,\u03c4 (\u0393 (x) \\ {y} 6= \u2205) d . (41)\nBy (41), OM-optimality immediately implies OU-optimality.\nNow suppose that A is OU-optimal. Let B be the MSP idealised conformity measure, which is both OM-optimal and OU-optimal. If (31) is violated for some , it is violated for a range of (by Corollary 3(d)), which, by (41), contradicts the OU-optimality of A. Therefore, A is OM-optimal."}, {"heading": "7 Empirical Study", "text": "In this section we demonstrate differences between two of our -free criteria, OF (probabilistic) and U (standard but not probabilistic) on the USPS data set of hand-written digits ([7]; examples of such digits are given in Figure 1, which is a subset of Figure 2 in [7]). We use the original split of the data set into the training and test sets. Our programs are written in R, and the results presented in the figures below are for the seed 0 of the R random number generator; however, we observe similar results in experiments with other seeds.\nThe problem is to classify hand-written digits, the labels are elements of {0, . . . , 9}, and the objects are elements of R256, where the 256 numbers represent the brightness of pixels in 16 \u00d7 16 pictures. We normalise each object by applying the same affine transformation (depending on the object) to each of its pixels making the mean brightness of the pixels in the picture equal to 0 and making its standard deviation equal to 1. The sizes of the training and test sets are 7291 and 2007, respectively.\nWe evaluate six conformal predictors using the two criteria of efficiency. Fix a metric on the object space R256; in our experiments we use tangent distance (as implemented by Daniel Keysers) and Euclidean distance. Given a sequence of examples (z1, . . . , zn), zi = (xi, yi), we consider the following three ways of computing conformity scores: for i = 1, . . . , n,\n\u2022 \u03b1i := \u2211K j=1 d 6= j / \u2211K j=1 d = j , where d 6= j are the distances, sorted in the in-\ncreasing order, from xi to the objects in (z1, . . . , zn) with labels different from yi (so that d 6= 1 is the smallest distance from xi to an object xj with yj 6= yi), and d=j are the distances, sorted in the increasing order, from xi to the objects in (z1, . . . , zi\u22121, zi+1, . . . , zn) labelled as yi (so that d = 1 is the smallest distance from xi to an object xj with j 6= i and yj = yi). We refer to this conformity measure as the KNN-ratio conformity measure; it has one parameter, K, whose range is {1, . . . , 50} in our experiments (so that we always have K n).\n\u2022 \u03b1i := Ni/K, where Ni is the number of objects labelled as yi among the K nearest neighbours of xi (when dK = dK+1 in the ordered list d1, . . . , dn\u22121 of the distances from xi to the other objects, we choose the nearest neighbours randomly among zj with yj = yi and with xj at a distance of dK from xi). This conformity measure is a KNN counterpart of the CP idealised conformity measure (cf. (14)), and we will refer to it as the KNN-CP conformity measure; its parameter K is in the range {2, . . . , 50} in our experiments.\n\u2022 finally, we define fi := maxy(Nyi /K), where N y i is the number of objects\nlabelled as y among the K nearest neighbours of xi, y\u0302i \u2208 arg maxy(Nyi /K) (chosen randomly from arg maxy(N y i /K) if |arg maxy(N y i /K)| > 1), and\n\u03b1i :=\n{ fi if yi = y\u0302i\n\u2212fi otherwise;\nthis is the KNN-SP conformity measure.\nThe three kinds of conformity measures combined with the two metrics (tangent and Euclidean) give six conformal predictors.\nFigure 2 gives the average unconfidence (5) (top panel) and the average observed fuzziness (10) (bottom panel) over the test sequence (so that k = 2007) for a range of the values of the parameter K. Each of the six lines corresponds to one of the conformal predictors, as shown in the legends; in black-and-white the lines of the same type (dotted, solid, or dashed) corresponding to Euclidean and tangent distances can always be distinguished by their position: the former is above the latter.\nThe best results are for the KNN-ratio conformity measure combined with tangent distance for small values of the parameter K. For the two other types of conformity measures their relative evaluation changes depending on the kind of a criterion used to measure efficiency: as expected, the KNN-CP conformal predictors are better under the OF criterion, whereas the KNN-SP conformal predictors are better under the U criterion (cf. Theorems 1 and 2), if we ignore small values of K (when the probability estimates Nyi /K are very unreliable).\nOur conclusion is that whereas some conformal predictors (such as the KNNratio ones in our experiments) can perform well under different criteria of efficiency, the performance of other conformal predictors depends very much on the criterion of efficiency used to evaluate it."}, {"heading": "8 Efficiency of Label-conditional Conformal", "text": "Predictors and Transducers\nConformal predictors, as defined in Section 2, only guarantee the overall coverage probability, averaged over all labels. Sometimes we want to have a guarantee for the coverage probability for each label y \u2208 Y separately, and in this case\none should use label-conditional conformal predictors, which are studied in this section."}, {"heading": "8.1 Label-conditional conformal predictors and transducers", "text": "The label-conditional conformal predictor determined by a conformity measure A is defined by (1) where the label-conditional p-values py are defined by\npy := (\u2223\u2223{i = 1, . . . , l | yi = y & \u03b1yi < \u03b1yl+1}\u2223\u2223\n+ \u03c4 \u2223\u2223{i = 1, . . . , l | yi = y & \u03b1yi = \u03b1yl+1}\u2223\u2223+ \u03c4)\n/ (|{i = 1, . . . , l | yi = y}|+ 1) (42)\n(instead of (2)); as before, \u03c4 is a random number distributed uniformly on the interval [0, 1] (conditionally on all the examples), and the conformity scores are defined by (3).\nThe label-conditional conformal transducer determined by A outputs the system of p-values (py | y \u2208 Y) defined by (42) for each training sequence (z1, . . . , zl) of examples and each test object x. The property of validity for label-conditional conformal predictors and transducers is that the p-values py are distributed uniformly on [0, 1] given y when the examples z1, . . . , zl, (x, y) are generated independently from the same probability distribution Q on Z (see, e.g., [19], Proposition 4.10). This implies that the conditional probability of error, y /\u2208 \u0393 (z1, . . . , zl, x), given y is at any significance level .\nThe p-values (42), and the corresponding conformal predictors and transducers, only depend on the conformity order within each class: now we define (xi, yi) (xj , yj) to mean yi = yj and \u03b1i \u2264 \u03b1j (with (xi, yi) and (xj , yj) such that yi 6= yj being incomparable).\nThe definitions of all ten criteria of efficiency introduced in Section 2 and listed in Table 1 carry over to the case of label-conditional conformal transducers and predictors."}, {"heading": "8.2 Idealised setting", "text": "As before, we assume that the object space X is finite and QX(x) > 0 for all x \u2208 X. We also assume QY(y) > 0 for all y \u2208 Y, where QY is the marginal distribution of Q on the label space Y.\nLet A be an idealised conformity measure. For each potential label y \u2208 Y for an object x define the corresponding label-conditional p-value as\npy = p(x, y) := Q{(x\u2032, y) \u2208 Z | A(x\u2032, y) < A(x, y)}\nQY(y)\n+ \u03c4 Q{(x\u2032, y) \u2208 Z | A(x\u2032, y) = A(x, y)}\nQY(y) , (43)\nanalogously to (11), with the same random number \u03c4 \u2208 [0, 1] used for all (x, y). The label-conditional idealised conformal predictor is defined by (12) for the new definition of p(x, y) and the label-conditional idealised conformal transducer corresponding to the idealised conformity measure A outputs for each object x \u2208 X the system of p-values (py | y \u2208 Y) defined by (43).\nThe idealised p-values (43), and the corresponding idealised conformal predictors and transducers, also depend only on the conformity order within each class: we can define (x, y) (x\u2032, y\u2032) to mean y = y\u2032 and A(x, y) \u2264 A(x\u2032, y\u2032). Two idealised conformity measures are equivalent within classes if they lead to the same order ; in this section we will consider only this notion of equivalence (without mentioning it explicitly).\nThe properties of validity now become conditional:\n\u2022 If (x, y) is generated from Q and \u03c4 is generated independently from the uniform probability distribution on [0, 1], p(x, y) is distributed uniformly on [0, 1] even if we condition on y.\n\u2022 Therefore, at each significance level the idealised conformal predictor makes an error with conditional probability given y."}, {"heading": "8.3 Probabilistic criteria of efficiency", "text": "Label-conditionally S-optimal, N-optimal, OF-optimal, and OE-optimal idealised conformity measures are defined exactly as S-optimal, N-optimal, OF-optimal, and OE-optimal idealised conformity measures at the end of Section 3 but with the label-conditional definitions of the p-values and prediction sets.\nLet us say that an idealised conformity measure A is a label-conditional refinement of an idealised conformity measure B if\nB(x1, y) < B(x2, y) =\u21d2 A(x1, y) < A(x2, y)\nfor all x1, x2 \u2208 X and all y \u2208 Y. Notice that the notion of label-conditional refinement is weaker than that of refinement (as defined by (15)): if A is a refinement of B, then A is a label-conditional refinement of B (but not vice versa, in general). Let Rlc(CP) be the set of all label-conditional refinements of the CP idealised conformity measure. If C is a criterion of efficiency (one of the ten criteria in Table 1), we let Olc(C) stand for the set of all labelconditionally C-optimal idealised conformity measures. We have the following simple corollary of Theorem 1.\nTheorem 5. Olc(S) = Olc(OF) = Olc(N) = Olc(\u0152) = Rlc(CP).\nProof. The proof is a modification of the proof of Theorem 1. In the case of Olc(N), for each label y \u2208 Y we have a separate optimization problem. Now the constraint becomes \u2211\nx\nQ(x, y)P (x, y) = QY(y)\n(in place of (16)), and the objective becomes to maximise \u2211 xQ \u2032(x, y)P (x, y) (since maximising the sum over (x, y) in (17) can be achieved by maximizing the sum over x for each y separately). Now an application of the Neyman\u2013Pearson lemma, as in the proof of Theorem 1, shows that Olc(N) = Rlc(CP).\nThe same argument as in the proof of Theorem 1 (the last three paragraphs) shows that Olc(N) = Olc(S) = Olc(OF) = Olc(\u0152), and so we have the formula in Theorem 5.\nWe say that an efficiency criterion is label-conditionally probabilistic if the CP idealised conformity measure is label-conditionally optimal for it; we add the qualifier weakly if this is true for some (label-conditional) refinement of CP and strongly if this is true for an arbitrary (label-conditional) refinement of CP. We can see that the four criteria that are set in italics in Table 1 are still optimal in the label-conditional setting."}, {"heading": "8.4 Other criteria of efficiency", "text": "Using the label-conditional definitions of the p-values and prediction sets, we define label-conditionally U-optimal, M-optimal, F-optimal, E-optimal, OUoptimal, and OM-optimal idealised conformity measures in exactly the same way as their unconditional counterparts at the beginning of Section 5. The label-conditional U and M criteria are standard, and the label conditional E criterion (with a different treatment of empty observations) has been introduced and explored in [15].\nWe do not give label-conditional analogues of Theorems 2\u20134, since the labelconditionally U-, M-, F-, E-, OU-, and OM-optimal idealised conformity measures are unlikely to have explicit expressions (cf. our remark about deterministic conformal predictors on p. 2), unless |Y| = 2. The following theorem says that all of these criteria are BW probabilistic (and the examples that we will give after its proof will show that they are not probabilistic).\nTheorem 6. If |Y| = 2, each of the sets\nOlc(U),Olc(M),Olc(F),Olc(E),Olc(OU),Olc(OM) (44)\ncontains a refinement of the CP idealised conformity measure.\nProof. Assume, without loss of generality, that Y = {0, 1}. And let us assume, for simplicity, that the values Q(1 | x) are all different for different x \u2208 X (if this condition is not satisfied, the theorem still holds, but finding a suitable refinement becomes, in general, a difficult combinatorial problem). In this case it is easy to see that each of the sets in (44) is the equivalence class of the CP idealised conformity measure: we can construct the optimal idealised conformity measure gradually starting from small values of , as in the proofs of Theorems 2\u20134.\nThe following examples show that none of the criteria considered in this subsection is probabilistic (or even weakly probabilistic):\n\u2022 Let X = {1, 2}, Y = {1, 2, 3, 4}, and\nQX(1) = 0.5 Q(1 | 1) = 0.2 Q(2 | 1) = 0.3 Q(3 | 1) = 0.2 Q(4 | 1) = 0.3 QX(2) = 0.5 Q(1 | 2) = 0.3 Q(2 | 2) = 0.2 Q(3 | 2) = 0.3 Q(4 | 2) = 0.2 (45) (Q(y | x) meaning QY|X(y | x), as usual). All refinements of the CP idealised conformity measure are equivalent (as for different labels y the two conditional probabilities Q(y | x), x = 1, 2, are different), and so all of them will lead to the same p-values. Let A be any idealised conformity measure that makes all observations containing object 1 less conforming than all observations containing object 2. The U criterion is not probabilistic since the expression (35) is 0.7 for the CP idealised conformity measure and is smaller, 0.55, for the idealised conformity measure A. The M criterion is not probabilistic since at significance level = 0.4 the CP idealised conformity measure gives the predictor \u0393 (1) = {2, 4} and \u0393 (2) = {1, 3} (a.s.), and so\nPx,\u03c4 (|\u0393 CP(x)| > 1) = 1 > 2/3 = Px,\u03c4 (|\u0393 A(x)| > 1)\n(cf. (23)).\n\u2022 Let X = {1, 2, 3}, Y = {1, 2, 3}, and, for a small \u03b4 > 0,\nQX(1) = 1/3 Q(1 | 1) = 1/3 + \u03b4 Q(2 | 1) = 1/3\u2212 2\u03b4 Q(3 | 1) = 1/3 + \u03b4 QX(2) = 1/3 Q(1 | 2) = 1/3\u2212 \u03b4 Q(2 | 2) = 1/3 + 2\u03b4 Q(3 | 2) = 1/3\u2212 \u03b4 QX(3) = 1/3 Q(1 | 3) = 1/3 Q(2 | 2) = 1/3 Q(3 | 3) = 1/3.\nAll refinements of the CP idealised conformity measure are equivalent, and so the choice of the refinement does not affect the p-values. Let A be an idealised conformity measure satisfying\nA(1, 2) < A(2, 1) = A(2, 3) < A(3, 1) = A(3, 2)\n< A(1, 1) = A(1, 3) < A(2, 2) < A(3, 3)\n(in other words, A is the CP idealised conformity measure modified in such a way that that it assigns to (3, 3) the highest conformity score). The F criterion is not probabilistic since the expression (36) is 7/9+O(\u03b4) for the CP idealised conformity measure and is smaller (for sufficiently small \u03b4), 2/3+O(\u03b4), for A. The E criterion is not probabilistic since at significance level = 2/3 the idealised conformity measure A gives a predictor whose excess is always 0, whereas the CP idealised conformity measure will have expected excess 1/3 +O(\u03b4).\n\u2022 Let X = {1, 2}, Y = {1, 2, 3, 4}, and Q be defined by (45). Let A be any idealised conformity measure that makes all observations containing object 1 less conforming than all observations containing object 2. The OU\ncriterion is not probabilistic since the expression (37) is 0.7 for the CP idealised conformity measure and is smaller, 0.55, for the idealised conformity measure A. The OM criterion is not probabilistic since at significance level = 0.4 the CP idealised conformity measure produces an observed multiple prediction a.s., whereas the idealised conformity measure A produces an observed multiple prediction with probability 2/3."}, {"heading": "9 Conclusion", "text": "This paper investigates properties of various criteria of efficiency of conformal prediction in the case of classification. It would be interesting to transfer, to the extent possible, this paper\u2019s results to the cases of:\n\u2022 Regression. The sum of p-values (as used in the S criterion) now becomes the integral of the p-value as function of the label y of the test example, and the size of a prediction set becomes its Lebesgue measure (considered, as already mentioned, in [11] in the non-idealised case). Whereas the latter is typically finite, ensuring the convergence of the former is less straightforward.\n\u2022 Anomaly detection. A first step in this direction is made in [17], which considers the average p-value as its criterion of efficiency.\n\u2022 Infinite, including non-discrete, object spaces X.\n\u2022 Non-idealised conformal predictors.\n\u2022 Significance levels = y that depend on the label y \u2208 Y in the labelconditional case.\nThe main part of this paper merely mentions what we called \u201ccombinatorial problems\u201d (see pages 2 and 26). It would be interesting to explore them systematically. As an example, let us consider the N criterion of efficiency for deterministic idealised conformal predictors (with \u03c4 set to 1 rather than being random) in the case |Y| = 1 (which we did not allow in the main part of the paper; in this case, there is no difference between unconditional and label-conditional idealised conformal predictors). The problem of finding an N-optimal idealised conformity measure then becomes the Subset-Sum Problem, known to be NP-hard: see, e.g., [12], Chapter 4 (a special case of this problem, Partition, was already one of Karp\u2019s original 21 NP-complete problems [6]). There are, however, efficient polynomial approximation schemes for this problem. It would be interesting, in particular, to find such schemes for general deterministic idealised conformal predictors and transducers and for smoothed idealised conformal predictors and transducers for non-probabilistic criteria of efficiency in the label-conditional case."}, {"heading": "Acknowledgments", "text": "We are grateful to the reviewers of the conference version of this paper for their helpful comments. This work was partially supported by EPSRC (grant EP/K033344/1), the Air Force Office of Scientific Research (grant \u201cSemantic Completions\u201d), and the EU Horizon 2020 Research and Innovation programme (grant 671555)."}], "references": [{"title": "Conformal Prediction for Reliable Machine Learning: Theory, Adaptations, and Applications", "author": ["Vineeth N. Balasubramanian", "Shen-Shyang Ho", "Vladimir Vovk", "editors"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Probability forecasting", "author": ["A. Philip Dawid"], "venue": "Encyclopedia of Statistical Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Conformal prediction under hypergraphical models", "author": ["Valentina Fedorova", "Alex Gammerman", "Ilia Nouretdinov", "Vladimir Vovk"], "venue": "Artificial Intelligence Applications and Innovations. Second Workshop on Conformal Prediction and Its Applications (COPA", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Strictly proper scoring rules, prediction, and estimation", "author": ["Tilmann Gneiting", "Adrian E. Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Evolved decision trees as conformal predictors", "author": ["Ulf Johansson", "Rikard K\u00f6nig", "Tuve L\u00f6fstr\u00f6m", "Henrik Bostr\u00f6m"], "venue": "Proceedings of the 2013 IEEE Conference on Evolutionary Computation,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Reducibility among combinatorial problems", "author": ["Richard M. Karp"], "venue": "Complexity of Computer Computations,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1972}, {"title": "Handwritten digit recognition with a back-propagation network", "author": ["Yann Le Cun", "Bernhard E. Boser", "John S. Denker", "Donnie Henderson", "R.E. Howard", "Wayne E. Hubbard", "Lawrence D. Jackel"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1990}, {"title": "Testing Statistical Hypotheses", "author": ["Erich L. Lehmann"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1986}, {"title": "Classification with confidence", "author": ["Jing Lei"], "venue": "Biometrika, 101:755\u2013769,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Distribution free prediction sets", "author": ["Jing Lei", "James Robins", "Larry Wasserman"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Distribution free prediction bands for nonparametric regression", "author": ["Jing Lei", "Larry Wasserman"], "venue": "Journal of the Royal Statistical Society B,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Knapsack Problems: Algorithms and Computer Implementations", "author": ["Silvano Martello", "Paolo Toth"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1990}, {"title": "Comparing the Bayes and typicalness frameworks", "author": ["Thomas Melluish", "Craig Saunders", "Ilia Nouretdinov", "Vladimir Vovk"], "venue": "Proceedings of the Twelfth European Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2001}, {"title": "Special Issue of the Annals of Mathematics and Artificial Intelligence on Conformal Prediction and its Applications, volume 74(1\u20132)", "author": ["Harris Papadopoulos", "Alex Gammerman", "Vladimir Vovk", "editors"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Least ambiguous set-valued classifiers with bounded error levels", "author": ["Mauricio Sadinle", "Jing Lei", "Larry Wasserman"], "venue": "Technical Report arXiv:1609.00451v1 [stat.ME],", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Transduction with confidence and credibility", "author": ["Craig Saunders", "Alex Gammerman", "Vladimir Vovk"], "venue": "Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1999}, {"title": "Anomaly detection of trajectories with kernel density estimation by conformal prediction", "author": ["James Smith", "Ilia Nouretdinov", "Rachel Craddock", "Charles Offer", "Alexander Gammerman"], "venue": "AIAI Workshops, COPA 2014,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Criteria of efficiency for conformal prediction", "author": ["Vladimir Vovk", "Valentina Fedorova", "Ilia Nouretdinov", "Alex Gammerman"], "venue": "Proceedings of the Fifth International Symposium on Conformal and Probabilistic Prediction with Applications (COPA 2016),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Algorithmic Learning in a Random World", "author": ["Vladimir Vovk", "Alex Gammerman", "Glenn Shafer"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": ", [1, 14] (and the COPA Proceedings, 2012\u20132016).", "startOffset": 2, "endOffset": 9}, {"referenceID": 13, "context": ", [1, 14] (and the COPA Proceedings, 2012\u20132016).", "startOffset": 2, "endOffset": 9}, {"referenceID": 2, "context": "In two recent papers [3, 5] two probabilistic criteria have been introduced, and in this paper we introduce two more and argue that probabilistic criteria should be used in place of more standard ones.", "startOffset": 21, "endOffset": 27}, {"referenceID": 4, "context": "In two recent papers [3, 5] two probabilistic criteria have been introduced, and in this paper we introduce two more and argue that probabilistic criteria should be used in place of more standard ones.", "startOffset": 21, "endOffset": 27}, {"referenceID": 18, "context": ", [19], p.", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": "96; introduced in [16]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 12, "context": "This criterion was introduced in [13], Section 7.", "startOffset": 33, "endOffset": 37}, {"referenceID": 18, "context": "2, and used extensively in [19].", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "The other two criteria that had been used before the publication of the conference version [18] of this paper are the sum of the p-values for all potential labels (this does not depend on the significance level) and the size of the prediction set at a given significance level: see the papers [3] and [5].", "startOffset": 91, "endOffset": 95}, {"referenceID": 2, "context": "The other two criteria that had been used before the publication of the conference version [18] of this paper are the sum of the p-values for all potential labels (this does not depend on the significance level) and the size of the prediction set at a given significance level: see the papers [3] and [5].", "startOffset": 293, "endOffset": 296}, {"referenceID": 4, "context": "The other two criteria that had been used before the publication of the conference version [18] of this paper are the sum of the p-values for all potential labels (this does not depend on the significance level) and the size of the prediction set at a given significance level: see the papers [3] and [5].", "startOffset": 301, "endOffset": 304}, {"referenceID": 1, "context": "As we point out in Section 5, probabilistic criteria of efficiency are conceptually similar to \u201cproper scoring rules\u201d in probability forecasting [2, 4], and this is our main motivation for their detailed study in this paper.", "startOffset": 145, "endOffset": 151}, {"referenceID": 3, "context": "As we point out in Section 5, probabilistic criteria of efficiency are conceptually similar to \u201cproper scoring rules\u201d in probability forecasting [2, 4], and this is our main motivation for their detailed study in this paper.", "startOffset": 145, "endOffset": 151}, {"referenceID": 14, "context": "A version (with a different treatment of empty observations) of one of the new non-probabilistic criteria of efficiency that we discuss in this paper (the one that we call the E criterion) has been introduced independently in [15].", "startOffset": 226, "endOffset": 230}, {"referenceID": 7, "context": "[8], Section 3.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "\u03c4 is a random number distributed uniformly on the interval [0, 1] (even conditionally on all the examples), and the corresponding sequence of conformity scores is defined by (\u03b1 1 , .", "startOffset": 59, "endOffset": 65}, {"referenceID": 0, "context": "The standard property of validity for conformal transducers is that the pvalues p are distributed uniformly on [0, 1] when the examples z1, .", "startOffset": 111, "endOffset": 117}, {"referenceID": 0, "context": "are generated independently from the same probability distribution Q on Z and \u03c4 is generated independently from the uniform probability distribution on [0, 1] (see, e.", "startOffset": 152, "endOffset": 158}, {"referenceID": 18, "context": ", [19], Proposition 2.", "startOffset": 2, "endOffset": 6}, {"referenceID": 2, "context": "The S criterion was introduced in [3] and the N criterion was introduced independently in [5] and [3], although the analogue of the N criterion for regression (where the size of a prediction set is defined to be its Lebesgue measure) had been used earlier in [11] (whose arXiv version was published in 2012).", "startOffset": 34, "endOffset": 37}, {"referenceID": 4, "context": "The S criterion was introduced in [3] and the N criterion was introduced independently in [5] and [3], although the analogue of the N criterion for regression (where the size of a prediction set is defined to be its Lebesgue measure) had been used earlier in [11] (whose arXiv version was published in 2012).", "startOffset": 90, "endOffset": 93}, {"referenceID": 2, "context": "The S criterion was introduced in [3] and the N criterion was introduced independently in [5] and [3], although the analogue of the N criterion for regression (where the size of a prediction set is defined to be its Lebesgue measure) had been used earlier in [11] (whose arXiv version was published in 2012).", "startOffset": 98, "endOffset": 101}, {"referenceID": 10, "context": "The S criterion was introduced in [3] and the N criterion was introduced independently in [5] and [3], although the analogue of the N criterion for regression (where the size of a prediction set is defined to be its Lebesgue measure) had been used earlier in [11] (whose arXiv version was published in 2012).", "startOffset": 259, "endOffset": 263}, {"referenceID": 2, "context": "The U criterion in this form was introduced in [3], but it is equivalent to using the average confidence (one minus unconfidence), which is very common.", "startOffset": 47, "endOffset": 50}, {"referenceID": 18, "context": "This is a widely used criterion; in particular, it was used in [19] and papers preceding it.", "startOffset": 63, "endOffset": 67}, {"referenceID": 8, "context": "A criterion that is very similar to the M and E criteria is used by Lei in [9] (Section 2.", "startOffset": 75, "endOffset": 78}, {"referenceID": 8, "context": "The difference of the criterion used in [9] is that it prohibits empty predictions (an intermediate approach would be to prefer smaller values for the number (9) of empty predictions).", "startOffset": 40, "endOffset": 43}, {"referenceID": 14, "context": "Lei\u2019s criterion is extended to the multi-class case in [15], which proposes a modification of the E criterion with a different treatment of empty predictions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "}), but we often omit pairs of parentheses when there is no danger of ambiguity), where \u03c4 is a random number distributed uniformly on [0, 1].", "startOffset": 134, "endOffset": 140}, {"referenceID": 0, "context": "The standard properties of validity for conformal transducers and predictors mentioned in the previous section simplify in this idealised case as follows: \u2022 If (x, y) is generated from Q and \u03c4 \u2208 [0, 1] is generated from the uniform", "startOffset": 195, "endOffset": 201}, {"referenceID": 0, "context": "distribution independently of (x, y), p(x, y) is distributed uniformly on [0, 1].", "startOffset": 74, "endOffset": 80}, {"referenceID": 0, "context": "where the notation Ex,\u03c4 refers to the expected value when x and \u03c4 are independent, x \u223c QX, and \u03c4 \u223c U ; QX is the marginal distribution of Q on X, and U is the uniform distribution on [0, 1]; \u2022 N-optimal if, for any idealised conformity measure B and any significance level , Ex,\u03c4 |\u0393 A(x)| \u2264 Ex,\u03c4 |\u0393 B(x)| ; \u2022 OF-optimal if, for any idealised conformity measure B, E(x,y),\u03c4 \u2211", "startOffset": 183, "endOffset": 189}, {"referenceID": 2, "context": ") This idealised conformity measure was introduced by an anonymous referee of the conference version of [3], but its non-idealised analogue in the case of regression had been used in [11] (following [10] and literature on minimum volume prediction).", "startOffset": 104, "endOffset": 107}, {"referenceID": 10, "context": ") This idealised conformity measure was introduced by an anonymous referee of the conference version of [3], but its non-idealised analogue in the case of regression had been used in [11] (following [10] and literature on minimum volume prediction).", "startOffset": 183, "endOffset": 187}, {"referenceID": 9, "context": ") This idealised conformity measure was introduced by an anonymous referee of the conference version of [3], but its non-idealised analogue in the case of regression had been used in [11] (following [10] and literature on minimum volume prediction).", "startOffset": 199, "endOffset": 203}, {"referenceID": 7, "context": "Let us apply the Neyman\u2013Pearson fundamental lemma ([8], Sect.", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "where we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [19]).", "startOffset": 69, "endOffset": 75}, {"referenceID": 18, "context": "where we have used the fact that p(x, y) is distributed uniformly on [0, 1] when ((x, y), \u03c4) \u223c Q\u00d7 U (see [19]).", "startOffset": 105, "endOffset": 109}, {"referenceID": 0, "context": "again using the fact that p(x, y) is distributed uniformly on [0, 1] and so P(x,y),\u03c4 (y \u2208 \u0393 (x)) = 1 \u2212 , where P(x,y),\u03c4 refers to the probability when (x, y) \u223c Q and \u03c4 \u223c U are independent.", "startOffset": 62, "endOffset": 68}, {"referenceID": 0, "context": "(instead of (4) or (13), respectively), where \u03c6 : [0, 1]\u2192 R is a fixed continuously differentiable strictly increasing function, not necessarily the identity function.", "startOffset": 50, "endOffset": 56}, {"referenceID": 18, "context": "In the following three definitions we follow [19], Chapter 3.", "startOffset": 45, "endOffset": 49}, {"referenceID": 1, "context": ", [2] and [4]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 3, "context": ", [2] and [4]).", "startOffset": 10, "endOffset": 13}, {"referenceID": 18, "context": "4 in [19]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 6, "context": "In this section we demonstrate differences between two of our -free criteria, OF (probabilistic) and U (standard but not probabilistic) on the USPS data set of hand-written digits ([7]; examples of such digits are given in Figure 1, which is a subset of Figure 2 in [7]).", "startOffset": 181, "endOffset": 184}, {"referenceID": 6, "context": "In this section we demonstrate differences between two of our -free criteria, OF (probabilistic) and U (standard but not probabilistic) on the USPS data set of hand-written digits ([7]; examples of such digits are given in Figure 1, which is a subset of Figure 2 in [7]).", "startOffset": 266, "endOffset": 269}, {"referenceID": 0, "context": "(instead of (2)); as before, \u03c4 is a random number distributed uniformly on the interval [0, 1] (conditionally on all the examples), and the conformity scores are defined by (3).", "startOffset": 88, "endOffset": 94}, {"referenceID": 0, "context": "The property of validity for label-conditional conformal predictors and transducers is that the p-values p are distributed uniformly on [0, 1] given y when the examples z1, .", "startOffset": 136, "endOffset": 142}, {"referenceID": 18, "context": ", [19], Proposition 4.", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "analogously to (11), with the same random number \u03c4 \u2208 [0, 1] used for all (x, y).", "startOffset": 53, "endOffset": 59}, {"referenceID": 0, "context": "The properties of validity now become conditional: \u2022 If (x, y) is generated from Q and \u03c4 is generated independently from the uniform probability distribution on [0, 1], p(x, y) is distributed uniformly on [0, 1] even if we condition on y.", "startOffset": 161, "endOffset": 167}, {"referenceID": 0, "context": "The properties of validity now become conditional: \u2022 If (x, y) is generated from Q and \u03c4 is generated independently from the uniform probability distribution on [0, 1], p(x, y) is distributed uniformly on [0, 1] even if we condition on y.", "startOffset": 205, "endOffset": 211}, {"referenceID": 14, "context": "The label-conditional U and M criteria are standard, and the label conditional E criterion (with a different treatment of empty observations) has been introduced and explored in [15].", "startOffset": 178, "endOffset": 182}, {"referenceID": 10, "context": "The sum of p-values (as used in the S criterion) now becomes the integral of the p-value as function of the label y of the test example, and the size of a prediction set becomes its Lebesgue measure (considered, as already mentioned, in [11] in the non-idealised case).", "startOffset": 237, "endOffset": 241}, {"referenceID": 16, "context": "A first step in this direction is made in [17], which considers the average p-value as its criterion of efficiency.", "startOffset": 42, "endOffset": 46}, {"referenceID": 11, "context": ", [12], Chapter 4 (a special case of this problem, Partition, was already one of Karp\u2019s original 21 NP-complete problems [6]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 5, "context": ", [12], Chapter 4 (a special case of this problem, Partition, was already one of Karp\u2019s original 21 NP-complete problems [6]).", "startOffset": 121, "endOffset": 124}], "year": 2016, "abstractText": "We study optimal conformity measures for various criteria of efficiency of classification in an idealised setting. This leads to an important class of criteria of efficiency that we call probabilistic; it turns out that the most standard criteria of efficiency used in literature on conformal prediction are not probabilistic unless the problem of classification is binary. We consider both unconditional and label-conditional conformal prediction. The conference version of this paper has been published in the Proceedings of COPA 2016.", "creator": "LaTeX with hyperref package"}}}