{"id": "1603.06067", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2016", "title": "Adaptive Joint Learning of Compositional and Non-Compositional Phrase Embeddings", "abstract": "we present a novel method for jointly utilizing learning compositional and non - compositional irregular phrase embeddings by adaptively weighting both types of embeddings using a compositionality scoring function. the scoring function method is used to quantify the level of compositionality of each phrase, and the parameters of the ratings function are jointly optimized with the objective for learning phrase embeddings.... in experiments, we apply the adaptive joint learning method component to the task of efficiently learning embeddings of transitive compound verb phrases, measuring and show that the compositionality scores have strong correlation with multiple human ratings averages for verb - object morphological compositionality, substantially outperforming the previous state of the art. moreover, our embeddings improve favorably upon the previous best model on obtaining a transitive verb disambiguation task. we certainly also show that a simple ensemble technique further effectively improves the results for both regression tasks.", "histories": [["v1", "Sat, 19 Mar 2016 08:53:29 GMT  (156kb)", "http://arxiv.org/abs/1603.06067v1", null], ["v2", "Tue, 22 Mar 2016 07:24:51 GMT  (91kb,D)", "http://arxiv.org/abs/1603.06067v2", null], ["v3", "Wed, 8 Jun 2016 07:46:27 GMT  (93kb,D)", "http://arxiv.org/abs/1603.06067v3", "Accepted as a full paper at the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016)"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kazuma hashimoto", "yoshimasa tsuruoka"], "accepted": true, "id": "1603.06067"}, "pdf": {"name": "1603.06067.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hassy@logos.t.u-tokyo.ac.jp", "tsuruoka@logos.t.u-tokyo.ac.jp"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 3.\n06 06\n7v 1\n[ cs\n.C L\n] 1\n9 M\nar 2\n01 6"}, {"heading": "1 Introduction", "text": "Representing words and phrases in a vector space has proven effective in a variety of language processing tasks (Pham et al., 2015; Sutskever et al., 2014). In most of the previous work, phrase embeddings are computed from word embeddings by using various kinds of composition functions. Such composed embeddings are called compositional embeddings. An alternative way of computing phrase embeddings is to treat phrases as single units and assigning a unique embedding to each candidate phrase (Mikolov et al., 2013; Yazdani et al., 2015). Such embeddings are called\nnon-compositional embeddings. Relying solely on non-compositional embeddings has the obvious problem of data sparsity (i.e. rare or unknown phrase problems). At the same time, however, using compositional embeddings is not always the best option since some phrases are inherently non-compositional. For example, the phrase \u201cbear fruits\u201d means \u201cto yield results\u201d1 but it is hard to infer its meaning by composing the meanings of \u201cbear\u201d and \u201cfruit\u201d. Treating all phrases as compositional also has a negative effect in learning the composition function because the words in those idiomatic phrases are not just uninformative but can serve as noisy samples in the training. These problems have motivated us to adaptively combine both types of embeddings.\nMost of the existing methods for learning phrase embeddings can be divided into two approaches. One approach is to learn compositional embeddings by regarding all phrases as compositional (Pham et al., 2015; Socher et al., 2012). The other approach is to learn both types of embeddings separately and use the better ones (Kartsaklis et al., 2014; Muraoka et al., 2014). Kartsaklis et al. (2014) show that non-compositional embeddings are better suited for a phrase similarity task, whereas Muraoka et al. (2014) report the opposite results on other tasks. These results suggest that we should not stick to either of the two types of embeddings unconditionally and could learn better phrase embeddings by considering the compositionality levels of the individual phrases in a more flexible fashion.\nIn this paper, we propose a method that jointly learns compositional and non-compositional embeddings by adaptively weighting both types of phrase embeddings using a compositionality scor-\n1The definition is found at http://idioms.thefreedictionary.com/bear+fruit.\ning function. The scoring function is used to quantify the level of compositionality of each phrase and learned in conjunction with the target task for learning phrase embeddings. In experiments, we apply our method to the task of learning transitive verb phrase embeddings and demonstrate that it allows us to achieve state-of-the-art performance on standard datasets for compositionality detection and verb disambiguation."}, {"heading": "2 Method", "text": "In this section, we describe our approach in the most general form, without specifying the function to compute the compositional embeddings or the target task for optimizing the embeddings.\nFigure 1 shows the overview of our proposed method. At each iteration of the training (i.e. gradient calculation) of a certain target task (e.g. language modeling, machine translation, or sentiment analysis), our method first computes a compositionality score for each phrase. Then the score is used to weight the compositional and noncompositional embeddings of the phrase in order to compute the expected embedding of the phrase which is to be used in the target task. Some examples of the compositionality scores are also shown in the figure."}, {"heading": "2.1 Compositional Phrase Embeddings", "text": "The compositional embedding c(p) \u2208 Rd\u00d71 of a phrase p = (w1, \u00b7 \u00b7 \u00b7 , wL) is formulated as\nc(p) = f(v(w1), \u00b7 \u00b7 \u00b7 ,v(wL)), (1)\nwhere d is the dimensionality, L is the phrase length, v(\u00b7) \u2208 Rd\u00d71 is a word embedding, and f(\u00b7) is a composition function. The function can be simple ones such as element-wise addition or multiplication (Mitchell and Lapata, 2008). More complex ones such as recurrent neural networks (Sutskever et al., 2014) are also commonly\nused. The word embeddings and the composition function are jointly learned on a certain target task. Since compositional embeddings are built on word-level (i.e. unigram) information, they are less prone to the data sparseness problem."}, {"heading": "2.2 Non-Compositional Phrase Embeddings", "text": "In contrast to the compositional embedding, the non-compositional embedding of a phrase n(p) \u2208 Rd\u00d71 is independently parameterized, i.e., the phrase p is treated just like a single word. Mikolov et al. (2013) show that noncompositional embeddings are preferable when dealing with idiomatic phrases. Some recent studies (Kartsaklis et al., 2014; Muraoka et al., 2014) have discussed the (dis)advantages of using compositional or non-compositional embeddings. However, in most cases, a phrase is neither completely compositional nor completely noncompositional. To the best of our knowledge, there is no method that allows us to jointly learn compositional and non-compositional phrase embeddings by incorporating the levels of compositionality of the phrases as real-valued scores."}, {"heading": "2.3 Adaptive Joint Learning", "text": "To simultaneously consider both compositional and non-compositional aspects of each phrase, we compute a phrase embedding v(p) by adaptively weighting c(p) and n(p) as follows:\nv(p) = \u03b1(p)c(p) + (1\u2212 \u03b1(p))n(p), (2)\nwhere \u03b1(\u00b7) is a scoring function that quantifies the compositionality levels, and outputs a real value ranging from 0 to 1. What we expect from the scoring function is that large scores indicate high levels of compositionality. In other words, when \u03b1(p) is close to 1, the compositional embedding is mainly considered, and vice versa. For example, we expect \u03b1(buy car) to be large and \u03b1(bear fruit) to be small as shown in Figure 1.\nWe parameterize the scoring function \u03b1(p) as logistic regression:\n\u03b1(p) = \u03c3(W \u00b7 \u03c6(p)), (3)\nwhere \u03c6(p) \u2208 RN\u00d71 is a feature vector of the phrase p, W \u2208 RN\u00d71 is a weight vector, N is the number of features, and \u03c3(\u00b7) is the logistic function. The weight vector W is jointly optimized in conjunction with the objective J for the target task of learning phrase embeddings v(p).\nUpdating the model parameters Given the partial derivative \u03b4p = \u2202J\u2202v(p) \u2208 R\nd\u00d71 for the target task, we can compute the partial derivative for updating W as follows:\n\u03b4\u03b1 = \u03b1(p)(1 \u2212 \u03b1(p)){\u03b4p \u00b7 (c(p)\u2212n(p))} (4)\n\u2202J\n\u2202W = \u03b4\u03b1\u03c6(p). (5)\nIf \u03c6(p) is not constructed by static features but is computed by a feature learning model such as neural networks, we can propagate the error term \u03b4\u03b1 into the feature learning model by the following equation:\n\u2202J\n\u2202\u03c6(p) = \u03b4\u03b1W . (6)\nWhen we use only static features, as in this work, we can simply compute the partial derivatives of J with respect to c(p) and n(p) as follows:\n\u2202J\n\u2202c(p) = \u03b1(p)\u03b4p (7)\n\u2202J\n\u2202n(p) = (1\u2212 \u03b1(p))\u03b4p. (8)\nAs mentioned above, Eq. (7) and (8) show that the non-compositional embeddings are mainly updated when \u03b1(p) is close to 0, and vice versa. The partial derivative \u2202J\n\u2202c(p) is used to update the model parameters in the composition function via the backpropagation algorithm. Any differentiable composition functions can be used in our method.\nExpected behavior of our method The training of our method depends on the target task; that is, the model parameters are updated so as to minimize the cost function as described above. More concretely, \u03b1(p) for each phrase p is adaptively adjusted so that the corresponding parameter updates contribute to minimizing the cost function. As a result, different phrases will have different \u03b1(p) values depending on their compositionality. If the size of the training data were almost infinitely large, \u03b1(p) for all phrases would become nearly zero, and the non-compositional embeddings n(p) are dominantly used (since that would allow the model to better fit the data). In reality, however, the amount of the training data is limited, and thus the compositional embeddings c(p) are effectively used to overcome the data sparseness problem."}, {"heading": "3 Learning Verb Phrase Embeddings", "text": "This section describes a particular instantiation of our approach presented in the previous section, fo-\ncusing on the task of learning the embeddings of transitive verb phrases."}, {"heading": "3.1 Word and Phrase Prediction in Predicate-Argument Relations", "text": "Acquisition of selectional preference using embeddings has been widely studied, where word and/or phrase embeddings are learned based on syntactic links (Bansal et al., 2014; Hashimoto and Tsuruoka, 2015; Levy and Goldberg, 2014; Van de Cruys, 2014). As with language modeling, these methods perform word (or phrase) prediction using (syntactic) contexts.\nIn this work, we focus on verb-object relationships and employ a phrase embedding learning method presented in Hashimoto and Tsuruoka (2015). The task is a plausibility judgment task for predicate-argument tuples. They extracted Subject-Verb-Object (SVO) and SVO-Preposition-Noun (SVOPN) tuples using a probabilistic HPSG parser, Enju (Miyao and Tsujii, 2008), from the training corpora. Transitive verbs and prepositions are extracted as predicates with two arguments. For example, the extracted tuples include (S, V, O) = (\u201cimporter\u201d, \u201cmake\u201d, \u201cpayment\u201d) and (SVO, P, N) = (\u201cimporter make payment\u201d, \u201cin\u201d, \u201ccurrency\u201d). The task is to discriminate between observed and unobserved tuples, such as the (S, V, O) tuple mentioned above and (S, V\u2019, O) = (\u201cimporter\u201d, \u201ceat\u201d, \u201cpayment\u201d), which is generated by replacing \u201cmake\u201d with \u201ceat\u201d. The (S, V\u2019, O) tuple is unlikely to be observed.\nFor each tuple (p, a1, a2) observed in the training data, a cost function is defined as follows:\n\u2212 log \u03c3(s(p, a1, a2))\u2212 log \u03c3(\u2212s(p \u2032, a1, a2))\n\u2212 log \u03c3(\u2212s(p, a\u20321, a2)) \u2212 log \u03c3(\u2212s(p, a1, a \u2032 2)), (9)\nwhere s(\u00b7) is a plausibility scoring function, and p, a1 and a2 are a predicate and its arguments, respectively. Each of the three unobserved tuples (p\u2032, a1, a2), (p, a\u20321, a2), and (p, a1, a \u2032\n2) is generated by replacing one of the entries with a random sample.\nIn their method, each predicate p is represented with a matrix M(p) \u2208 Rd\u00d7d and each argument a with an embedding v(a) \u2208 Rd\u00d71. The matrices and embeddings are learned by minimizing the cost function using AdaGrad (Duchi et al., 2011).\nThe scoring function is parameterized as\ns(p, a1, a2) = v(a1) \u00b7 (M(p)v(a2)), (10)\nand the VO and SVO embeddings are computed as\nv(V O) = M(V )v(O) (11)\nv(SV O) = v(S)\u2299 v(V O), (12)\nas proposed by Kartsaklis et al. (2012). The operator \u2299 denotes element-wise multiplication. In summary, the scores are computed as\ns(V, S,O) = v(S) \u00b7 v(V O) (13)\ns(P, SV O,N) = v(SV O) \u00b7 (M(P )v(N)). (14)\nWith this method, the word and composed phrase embeddings are jointly learned based on co-occurrence statistics of predicateargument structures. Using the learned embeddings, they achieved state-of-the-art accuracy on a transitive verb disambiguation task (Grefenstette and Sadrzadeh, 2011)."}, {"heading": "3.2 Applying the Adaptive Joint Learning", "text": "In this section, we apply our proposed method, the adaptive joint learning, to the task described in Section 3.1. We here redefine the computation of v(V O) by first replacing v(V O) in Eq. (11) with c(V O) as,\nc(V O) = M(V )v(O), (15)\nand then assigning V O to p in Eq. (2) and (3):\nv(V O) = \u03b1(V O)c(V O) + (1\u2212 \u03b1(V O))n(V O), (16)\n\u03b1(V O) = \u03c3(W \u00b7 \u03c6(V O)). (17)\nThe v(V O) in Eq. (16) is used in Eq. (12) and (13). We assume that the candidates of the phrases are given in advance. For the phrases not included in the candidates, we set v(V O) = c(V O). This is analogous to the way a human guesses the meaning of an idiomatic phrase she does not know. We should note that \u03c6(V O) can be computed for phrases not included in the candidates, using partial features among the features described below. If any features do not fire, \u03c6(V O) becomes 0.5 according to the logistic function.\nFor the feature vector \u03c6(V O), we use the following simple binary and real-valued features:\n\u2022 indices of V, O, and VO\n\u2022 frequency and Pointwise Mutual Information (PMI) values of VO.\nMore concretely, the first set of the features (indices of V, O, and VO) is the concatenation of traditional one-hot vectors. The second set of features, frequency and PMI (Church and Hanks, 1990) features, have proven effective in detecting the compositionality of transitive verbs in McCarthy et al. (2007) and Venkatapathy and Joshi (2005). Given the training corpus, the frequency feature for a VO pair is computed as\nfreq(V O) = log(count(V O)), (18)\nwhere count(V O) counts how many times the VO pair appears in the training corpus, and the PMI feature is computed as\nPMI(V O) = log count(V O)count(\u2217)\ncount(V )count(O) , (19)\nwhere count(V ), count(O), and count(\u2217) are the counts of the verb V , the object O, and all VO pairs in the training corpus, respectively. We normalize the frequency and PMI features so that their maximum absolute value becomes 1."}, {"heading": "4 Experimental Settings", "text": ""}, {"heading": "4.1 Training Data", "text": "As the training data, we used two datasets, one small and one large: the British National Corpus (BNC) (Leech, 1992) and the English Wikipedia. More concretely, we used the publicly available data2 preprocessed by Hashimoto and Tsuruoka (2015). The BNC data consists of 1.38 million SVO tuples and 0.93 million SVOPN tuples. The Wikipedia data consists of 23.6 million SVO tuples and 17.3 million SVOPN tuples. Following the provided code3, we used exactly the same train/development/test split (0.8/0.1/0.1) for training the overall model. As the third training data, we also used the concatenation of the two data, which is hereafter referred to as BNC-Wikipedia.\nWe applied our adaptive joint learning method to verb-object phrases observed more than K times in each corpus. K was set to 10\n2http://www.logos.t.u-tokyo.ac.jp/\u02dchassy/publications/cvsc2015/ 3 https://github.com/hassyGo/SVOembedding\nfor the BNC data and 100 for the Wikipedia and BNC-Wikipedia data. Consequently, the non-compositional embeddings were assigned to 17,817, 28,933, and 30,682 verb-object phrase types in the BNC, Wikipedia, and BNC-Wikipedia data, respectively."}, {"heading": "4.2 Training Details", "text": "The model parameters consist of d-dimensional word embeddings for nouns, non-compositional phrase embeddings, d \u00d7 d-dimensional matrices for verbs and prepositions, and a weight vector W for \u03b1(V O). All the model parameters are jointly optimized. We initialized the embeddings and matrices with zero-mean gaussian random values with a variance of 1\nd and 1 d2 , respectively, and\nW with zeros. Initializing W with zeros forces the initial value of each \u03b1(V O) to be 0.5 since we use the logistic function to compute \u03b1(V O).\nThe optimization was performed via minibatch AdaGrad (Duchi et al., 2011). We fixed d to 25 and the mini-batch size to 100. We set candidate values for the learning rate to {0.01, 0.02, 0.03, 0.04, 0.05}. For the weight vector W , we employed L2-norm regularization and set the strength to {10\u22123, 10\u22124, 10\u22125, 10\u22126, 0}. For selecting the hyperparameters, each training process was stopped when the evaluation score on the development split decreased. Then the best performing hyperparameters were selected for each training dataset. Once the training is finished, we can use the learned embeddings and the scoring function in downstream target tasks."}, {"heading": "5 Evaluation on the Compositionality Detection Function", "text": ""}, {"heading": "5.1 Evaluation Settings", "text": "Datasets First, we evaluated the learned compositionality detection function on two compositionality detection datasets, VJ\u2019054 and MC\u2019075, provided by Venkatapathy and Joshi (2005) and McCarthy et al. (2007), respectively. VJ\u201905 consists of 765 verb-object pairs with human ratings for the compositionality. MC\u201907 is a subset of VJ\u201905 and consists of 638 verb-object pairs. For example, the rating of \u201cbuy car\u201d is 6, which is the highest score, indicating the phrase is highly compositional. The rating of \u201cbear fruit \u201d is 1, which\n4http://www.dianamccarthy.co.uk/downloads/SVAJ2005compositionality_rating.txt 5 http://www.dianamccarthy.co.uk/downloads/emnlp2007data.txt\nis the lowest score, indicating the phrase is highly non-compositional.\nEvaluation metric and ensembles The evaluation was performed by calculating Spearman\u2019s rank correlation scores6 between the averaged human ratings and the learned compositionality scores \u03b1(V O). We also produced the result by employing an ensemble technique. More concretely, we used the averaged compositionality scores from the results of the BNC and Wikipedia data for the ensemble result."}, {"heading": "5.2 Results and Discussion", "text": ""}, {"heading": "5.2.1 Result Overview", "text": "Table 1 shows our results and the state of the art. Our method outperforms the previous state of the art in all settings. The result denoted as Ensemble is the one that employs the ensemble technique, and achieves the strongest correlation with the human-annotated datasets. Even without the ensemble technique, our method performs better than all of the previous methods.\nKiela and Clark (2013) used window-based cooccurrence vectors and improved their score using WordNet hypernyms. By contrast, our method does not rely on such external resources, and only needs parsed corpora. We should note that Kiela and Clark (2013) reported that their score did not improve when using parsed corpora. Our method also outperforms DSPROTO+, which used a small amount of the labeled data, while our method is fully unsupervised."}, {"heading": "5.2.2 Analysis of Compositionality Scores", "text": "Figure 2 shows how \u03b1(V O) changes for the seven phrases during the training on the BNC data. As shown in the figure, starting from 0.5, \u03b1(V O) for\n6We used the Scipy 0.12.0 implementation in Python.\neach phrase converges to its corresponding value. The differences in the trends indicate that our method can adaptively learn compositionality levels for the phrases. Table 2 shows the learned compositionality scores for the three groups of the examples along with the gold-standard scores given by the annotators. The group (A) is considered to be consistent with the gold-standard scores, the group (B) is not, and the group (C) shows examples for which the difference between the compositionality scores of our results is large.\nCharacteristics of light verbs The verbs \u201ctake\u201d, \u201cmake\u201d, and \u201chave\u201d are known as light verbs 7, and the scoring function tends to assign low scores to light verbs. In other words, our method can recognize that the light verbs are frequently used to form idiomatic (i.e. noncompositional) phrases. To verify the assumption, we calculated the average compositionality score\n7In Section 5.2.2 in Newton (2006), the term light verb is used to refer to verbs which can be used in combination with some other element where their contribution to the meaning of the whole construction is reduced in some way.\nfor each verb by averaging the compositionality scores paired with its candidate objects. Here we used 135 verbs which take more than 30 types of objects in the BNC data. Table 3 shows the 10 highest and lowest average scores with the corresponding verbs. We see that relatively low scores are assigned to the light verbs as well as other verbs which often form idiomatic phrases. As shown in the group (B) in Table 2, however, light verb phrases are not always non-compositional. Despite this, the learned function assigns low scores to compositional phrases formed by the light verbs. These results suggest that using a more flexible scoring function may further strengthen our method.\nContext dependence Both our method and the two datasets, VJ\u201905 and MC\u201907, assume that the compositionality score can be computed for each phrase with no contextual information. However, in general, the compositionality level of a phrase depends on its contextual information. For example, the meaning of the idiomatic phrase \u201cbear fruit\u201d can be compositionaly interpreted as \u201cto yield fruit\u201d for a plant or tree. We manually inspected the BNC data to check whether the phrase \u201cbear fruit\u201d is used as the compositional mean-\ning or the idiomatic meaning (\u201cto yield results\u201d). As a result, we have found that most of the usage was its idiomatic meaning. In the model training, our method is affected by the majority usage and fits the evaluation datasets where the phrase \u201cbear fruit\u201d is regarded as highly non-compositional. Incorporating contextual information into the compositionality scoring function is a promising direction of future work."}, {"heading": "5.2.3 Effects of Ensemble", "text": "We used the two different corpora for constructing the training data, and our method achieves the state-of-the-art results in all settings. To inspect the results on VJ\u201905, we calculated the correlation score between the outputs from our results of the BNC and Wikipedia data. The correlation score is 0.674 and that is, the two different corpora lead to reasonably consistent results, which indicates the robustness of our method. However, the correlation score is still much lower than perfect correlation; in other words, there are disagreements between the outputs learned with the corpora. The group (C) in Table 2 shows such two examples. In these cases, the ensemble technique is helpful in improving the results as shown in the examples.\nAnother interesting observation in our results is that the result of the ensemble technique outperforms that of the BNC-Wikipedia data as shown in Table 1. This shows that separately using the training corpora of different nature and then performing the ensemble technique can yield better results. By contrast, many of the previous studies on embedding-based methods combine different corpora into a single dataset, or use multiple corpora just separately and compare them (Hashimoto and Tsuruoka, 2015; Muraoka et al., 2014; Pennington et al., 2014). It would be worth investigating whether the results in the previous work can be improved by ensemble techniques."}, {"heading": "6 Evaluation on the Phrase Embeddings", "text": ""}, {"heading": "6.1 Evaluation Settings", "text": "Dataset Next, we evaluated the learned embeddings on the transitive verb disambiguation dataset GS\u2019118 provided by Grefenstette and Sadrzadeh (2011). GS\u201911 consists of 200 pairs of transitive verbs and each verb pair takes the same subject and object. For\n8 http://www.cs.ox.ac.uk/activities/compdistmeaning/GS2011data.txt\nexample, the transitive verb \u201crun\u201d is known as a polysemous word and this task requires one to identify the meanings of \u201crun\u201d and \u201coperate\u201d as similar to each other when taking \u201cpeople\u201d as their subject and \u201ccompany\u201d as their object. In the same setting, however, the meanings of \u201crun\u201d and \u201cmove\u201d are not similar to each other. Each pair has multiple human ratings indicating how similar the phrases of the pair are.\nEvaluation metric and ensembles The evaluation was performed by calculating Spearman\u2019s rank correlation scores between the human ratings and the cosine similarity scores of v(SV O) in Eq. (12). Following the previous studies, we used the gold-standard ratings in two ways: averaging the human ratings for each SVO tuple (GS\u201911a) and treating each human rating separately (GS\u201911b). We used the same ensemble technique described in Section 5.1. In this task we produced two ensemble results: Ensemble A and Ensemble B. The former used the averaged cosine similarity from the results of the BNC and Wikipedia data, and the latter further incorporated the result of the BNC-Wikipedia data."}, {"heading": "6.2 Results and Discussion", "text": ""}, {"heading": "6.2.1 Result Overview", "text": "Table 4 shows our results and the state of the art, and our method outperforms all of the previous methods in all settings. The scores in Hashimoto and Tsuruoka (2015) have been the best to date and are equivalent to those with \u03b1(V O) = 1 in our method. We see that our method significantly improves the baseline scores by adaptively combining compositional and noncompositional embeddings. Along with the results in Table 1, these results show that our method allows us to improve the composition function by jointly learning non-compositional embeddings and the scoring function for compositionality detection. Again, the ensemble technique further improves the results, and overall, Ensemble B performs the best."}, {"heading": "6.2.2 Analysis of the Learned Embeddings", "text": "We inspected the effects of adaptively weighting the compositional and non-compositional embeddings. Table 5 shows the five closest neighbor phrases in terms of the cosine similarity for the three idiomatic phrases \u201ctake toll\u201d, \u201ccatch eye\u201d, and \u201cbear fruit\u201d. The examples trained with the\nWikipedia data are shown for our method and the baseline, i.e., \u03b1(V O) = 1. As shown in Table 2, the compositionality levels of the three phrases are low and their non-compositional embeddings are dominantly used to represent their meaning.\nOne observation with \u03b1(V O) = 1 is that head words (i.e. verbs) are emphasized in the shown examples except \u201ctake toll\u201d. As with other embedding-based methods, the compositional embeddings are highly affected by their component words. As a result, the phrases consisting of the same verb and the similar objects are often listed as the closest neighbors. By contrast, our method flexibly allows us to adaptively omit the information about the component words. Therefore, our method puts more weight on capturing the idiomatic aspects of the example phrases by adaptively using the non-compositional embeddings."}, {"heading": "7 Related Work", "text": "Learning embeddings of words and phrases has been widely studied in the field of natural language processing. The phrase embeddings have proven effective in many language processing tasks, such as machine translation (Cho et al., 2014; Sutskever et al., 2014), sentiment analysis and semantic textual similarity (Tai et al., 2015). Most of the phrase embeddings are constructed by word-level information via various kinds of composition functions like long short-term memory (Hochreiter and Schmidhuber, 1997) recurrent neural networks. Such composition functions should be powerful enough to efficiently encode information about all the words into the phrase embeddings. By simultaneously considering the compositionality of the phrases, our method would be helpful in saving the composition models from having to be powerful enough to perfectly encode the non-compositional phrases. As a first step towards this purpose, in this paper we have shown the effectiveness of our method on the task of learning verb phrase embeddings.\nMany studies have focused on detecting the compositionality of a variety of phrases (Lin, 1999), including the ones on verb phrases (Diab and Bhutada, 2009; McCarthy et al., 2003) and compound nouns (Farahmand et al., 2015; Reddy et al., 2011; Yazdani et al., 2015). Compared to statistical featurebased methods (McCarthy et al., 2007; Venkatapathy and Joshi, 2005), recent methods use word and phrase embeddings (Kiela and Clark, 2013; Yazdani et al., 2015). The embedding-based methods assume that word embeddings are given in advance and as a post-processing step, and learn or simply employ composition functions to compute phrase embeddings. In other words, there is no distinction between compositional and non-compositional phrases. Yazdani et al. (2015) further proposed to incorporate latent annotations (binary labels) for the compositionality of the phrases. However, binary judgments cannot consider numerical scores of the compositionality. By contrast, our method adaptively weights the compositional and non-compositional embeddings using the compositionality scoring function."}, {"heading": "8 Conclusion and Future Work", "text": "We have presented a method for adaptively learning compositional and non-compositional phrase embeddings by jointly detecting compositionality levels of phrases. Our method achieves the state of the art on a compositionality detection task of verb-object pairs, and also improves upon the previous state-of-the-art method on a transitive verb disambiguation task. In future work, we will apply our method to other kinds of phrases and tasks."}, {"heading": "Acknowledgments", "text": "This work was supported by CREST, JST."}, {"heading": "2011 Conference on Empirical Methods in Natural", "text": "Language Processing, pages 1394\u20131404.\n[Hashimoto and Tsuruoka2015] Kazuma Hashimoto and Yoshimasa Tsuruoka. 2015. Learning Embeddings for Transitive Verb Disambiguation by Implicit Tensor Factorization. In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, pages 1\u201311.\n[Hashimoto et al.2014] Kazuma Hashimoto, Pontus Stenetorp, Makoto Miwa, and Yoshimasa Tsuruoka. 2014. Jointly Learning Word Representations and Composition Functions Using Predicate-Argument Structures. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1544\u20131555.\n[Hochreiter and Schmidhuber1997] Sepp Hochreiter and Ju\u0308rgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation, 9(8):1735\u20131780.\n[Kartsaklis et al.2012] Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, and Stephen Pulman. 2012. A Unified Sentence Space for Categorical DistributionalCompositional Semantics: Theory and Experiments. In Proceedings of the 24th International Conference on Computational Linguistics, pages 549\u2013558.\n[Kartsaklis et al.2014] Dimitri Kartsaklis, Nal Kalchbrenner, and Mehrnoosh Sadrzadeh. 2014. Resolving Lexical Ambiguity in Tensor Regression Models of Meaning. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 212\u2013217.\n[Kiela and Clark2013] Douwe Kiela and Stephen Clark. 2013. Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1427\u20131432.\n[Leech1992] Geoffrey Leech. 1992. 100 Million Words of English: the British National Corpus. Language Research, 28(1):1\u201313.\n[Levy and Goldberg2014] Omer Levy and Yoav Goldberg. 2014. Dependency-Based Word Embeddings. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 302\u2013308.\n[Lin1999] Dekang Lin. 1999. Automatic Identification of Non-compositional Phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 317\u2013324.\n[McCarthy et al.2003] Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a Continuum of Compositionality in Phrasal Verbs. In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 73\u201380.\n[McCarthy et al.2007] Diana McCarthy, Sriram Venkatapathy, and Aravind Joshi. 2007. Detecting Compositionality of Verb-Object Combinations using Selectional Preferences. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 369\u2013379.\n[Mikolov et al.2013] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. In Advances in Neural Information Processing Systems 26, pages 3111\u2013 3119.\n[Milajevs et al.2014] Dmitrijs Milajevs, Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, and Matthew Purver. 2014. Evaluating Neural Word Representations in Tensor-Based Compositional Settings. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 708\u2013719.\n[Mitchell and Lapata2008] Jeff Mitchell and Mirella Lapata. 2008. Vector-based Models of Semantic Composition. In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 236\u2013 244.\n[Miyao and Tsujii2008] Yusuke Miyao and Jun\u2019ichi Tsujii. 2008. Feature Forest Models for Probabilistic HPSG Parsing. Computational Linguistics, 34(1):35\u201380, March.\n[Muraoka et al.2014] Masayasu Muraoka, Sonse Shimaoka, Kazeto Yamamoto, Yotaro Watanabe, Naoaki Okazaki, and Kentaro Inui. 2014. Finding The Best Model Among Representative Compositional Models. In Proceedings of the 28th Pacific Asia Conference on Language, Information, and Computation, pages 65\u201374.\n[Newton2006] Mark Newton. 2006. Basic English Syntax with Exercises. Bo\u0308lcse\u0301sz Konzorcium.\n[Pennington et al.2014] Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global Vectors for Word Representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532\u20131543.\n[Pham et al.2015] Nghia The Pham, Germa\u0301n Kruszewski, Angeliki Lazaridou, and Marco Baroni. 2015. Jointly optimizing word representations for lexical and sentential tasks with the C-PHRASE model. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 971\u2013981.\n[Polajnar et al.2014] Tamara Polajnar, Laura Rimell, and Stephen Clark. 2014. Using Sentence Plausibility to Learn the Semantics of Transitive Verbs.\nIn Proceedings of Workshop on Learning Semantics at the 2014 Conference on Neural Information Processing Systems.\n[Polajnar et al.2015] Tamara Polajnar, Laura Rimell, and Stephen Clark. 2015. An Exploration of Discourse-Based Sentence Spaces for Compositional Distributional Semantics. In Proceedings of the First Workshop on Linking Computational Models of Lexical, Sentential and Discourse-level Semantics, pages 1\u201311.\n[Reddy et al.2011] Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An Empirical Study on Compositionality in Compound Nouns. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 210\u2013218.\n[Socher et al.2012] Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic Compositionality through Recursive Matrix-Vector Spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1201\u20131211.\n[Sutskever et al.2014] Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to Sequence Learning with Neural Networks. In Advances in Neural Information Processing Systems 27, pages 3104\u20133112.\n[Tai et al.2015] Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015. Improved Semantic Representations From Tree-Structured Long ShortTerm Memory Networks. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1556\u20131566.\n[Van de Cruys2014] Tim Van de Cruys. 2014. A Neural Network Approach to Selectional Preference Acquisition. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 26\u201335.\n[Venkatapathy and Joshi2005] Sriram Venkatapathy and Aravind Joshi. 2005. Measuring the Relative Compositionality of Verb-Noun (V-N) Collocations by Integrating Features. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 899\u2013906.\n[Yazdani et al.2015] Majid Yazdani, Meghdad Farahmand, and James Henderson. 2015. Learning Semantic Composition to Detect Noncompositionality of Multiword Expressions. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1733\u20131742."}], "references": [{"title": "Tailoring Continuous Word Representations for Dependency Parsing", "author": ["Bansal et al.2014] Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Bansal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Transla", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Word Association Norms, Mutual Information and Lexicography", "author": ["Church", "Hanks1990] Kenneth Church", "Patrick Hanks"], "venue": "Computational Linguistics,", "citeRegEx": "Church et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Church et al\\.", "year": 1990}, {"title": "Verb Noun Construction MWE Token Classification", "author": ["Diab", "Bhutada2009] Mona Diab", "Pravin Bhutada"], "venue": "In Proceedings of the Workshop on Multiword Expressions: Identification,", "citeRegEx": "Diab et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Diab et al\\.", "year": 2009}, {"title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "author": ["Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "A Multiword Expression Data Set: Annotating NonCompositionality and Conventionalization for English Noun Compounds", "author": ["Aaron Smith", "Joakim Nivre"], "venue": null, "citeRegEx": "Farahmand et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Farahmand et al\\.", "year": 2015}, {"title": "Experimental Support for a Categorical Compositional Distributional Model of Meaning", "author": ["Grefenstette", "Mehrnoosh Sadrzadeh"], "venue": null, "citeRegEx": "Grefenstette et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Grefenstette et al\\.", "year": 2011}, {"title": "Learning Embeddings for Transitive Verb Disambiguation by Implicit Tensor Factorization", "author": ["Hashimoto", "Tsuruoka2015] Kazuma Hashimoto", "Yoshimasa Tsuruoka"], "venue": "In Proceedings of the 3rd Workshop on Continuous Vector Space Models", "citeRegEx": "Hashimoto et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2015}, {"title": "Jointly Learning Word Representations and Composition Functions Using Predicate-Argument Structures", "author": ["Pontus Stenetorp", "Makoto Miwa", "Yoshimasa Tsuruoka"], "venue": "In Proceedings of the 2014 Conference", "citeRegEx": "Hashimoto et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2014}, {"title": "Long Short-Term Memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "A Unified Sentence Space for Categorical DistributionalCompositional Semantics: Theory and Experiments", "author": ["Mehrnoosh Sadrzadeh", "Stephen Pulman"], "venue": "In Proceedings of the 24th International Conference", "citeRegEx": "Kartsaklis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kartsaklis et al\\.", "year": 2012}, {"title": "Resolving Lexical Ambiguity in Tensor Regression Models of Meaning", "author": ["Nal Kalchbrenner", "Mehrnoosh Sadrzadeh"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Kartsaklis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kartsaklis et al\\.", "year": 2014}, {"title": "Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models", "author": ["Kiela", "Clark2013] Douwe Kiela", "Stephen Clark"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural", "citeRegEx": "Kiela et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kiela et al\\.", "year": 2013}, {"title": "Dependency-Based Word Embeddings", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Automatic Identification of Non-compositional Phrases", "author": ["Dekang Lin"], "venue": "In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Lin.,? \\Q1999\\E", "shortCiteRegEx": "Lin.", "year": 1999}, {"title": "Detecting a Continuum of Compositionality in Phrasal Verbs", "author": ["Bill Keller", "John Carroll"], "venue": "In Proceedings of the ACL 2003 Workshop on Multiword Expressions:", "citeRegEx": "McCarthy et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McCarthy et al\\.", "year": 2003}, {"title": "Detecting Compositionality of Verb-Object Combinations using Selectional Preferences", "author": ["Sriram Venkatapathy", "Aravind Joshi"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods", "citeRegEx": "McCarthy et al\\.,? \\Q2007\\E", "shortCiteRegEx": "McCarthy et al\\.", "year": 2007}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Evaluating Neural Word Representations in Tensor-Based Compositional Settings", "author": ["Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh", "Matthew Purver"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods", "citeRegEx": "Milajevs et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Milajevs et al\\.", "year": 2014}, {"title": "Vector-based Models of Semantic Composition", "author": ["Mitchell", "Lapata2008] Jeff Mitchell", "Mirella Lapata"], "venue": "In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Feature Forest Models for Probabilistic HPSG Parsing", "author": ["Miyao", "Tsujii2008] Yusuke Miyao", "Jun\u2019ichi Tsujii"], "venue": "Computational Linguistics,", "citeRegEx": "Miyao et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Miyao et al\\.", "year": 2008}, {"title": "Finding The Best Model Among Representative Compositional Models", "author": ["Sonse Shimaoka", "Kazeto Yamamoto", "Yotaro Watanabe", "Naoaki Okazaki", "Kentaro Inui"], "venue": "In Proceedings of the 28th Pa-", "citeRegEx": "Muraoka et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Muraoka et al\\.", "year": 2014}, {"title": "Basic English Syntax with Exercises. B\u00f6lcs\u00e9sz Konzorcium", "author": ["Mark Newton"], "venue": null, "citeRegEx": "Newton.,? \\Q2006\\E", "shortCiteRegEx": "Newton.", "year": 2006}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Richard Socher", "Christopher Manning"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Jointly optimizing word representations for lexical and sentential tasks with the C-PHRASE model", "author": ["Pham et al.2015] Nghia The Pham", "Germ\u00e1n Kruszewski", "Angeliki Lazaridou", "Marco Baroni"], "venue": null, "citeRegEx": "Pham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pham et al\\.", "year": 2015}, {"title": "Using Sentence Plausibility to Learn the Semantics of Transitive Verbs", "author": ["Laura Rimell", "Stephen Clark"], "venue": null, "citeRegEx": "Polajnar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Polajnar et al\\.", "year": 2014}, {"title": "An Exploration of Discourse-Based Sentence Spaces for Compositional Distributional Semantics", "author": ["Laura Rimell", "Stephen Clark"], "venue": "In Proceedings of the First Workshop on Linking Computational Mod-", "citeRegEx": "Polajnar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Polajnar et al\\.", "year": 2015}, {"title": "An Empirical Study on Compositionality in Compound Nouns", "author": ["Reddy et al.2011] Siva Reddy", "Diana McCarthy", "Suresh Manandhar"], "venue": "In Proceedings of 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Reddy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2011}, {"title": "Semantic Compositionality through Recursive Matrix-Vector Spaces", "author": ["Brody Huval", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural", "citeRegEx": "Socher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Sequence to Sequence Learning with Neural Networks", "author": ["Oriol Vinyals", "Quoc V Le"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Improved Semantic Representations From Tree-Structured Long ShortTerm Memory Networks", "author": ["Tai et al.2015] Kai Sheng Tai", "Richard Socher", "Christopher D. Manning"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Compu-", "citeRegEx": "Tai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tai et al\\.", "year": 2015}, {"title": "Measuring the Relative Compositionality of Verb-Noun (V-N) Collocations by Integrating Features", "author": ["Venkatapathy", "Joshi2005] Sriram Venkatapathy", "Aravind Joshi"], "venue": "In Proceedings of Human Language Technology", "citeRegEx": "Venkatapathy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Venkatapathy et al\\.", "year": 2005}, {"title": "Learning Semantic Composition to Detect Noncompositionality of Multiword Expressions", "author": ["Meghdad Farahmand", "James Henderson"], "venue": "In Proceedings of the 2015 Conference on Empiri-", "citeRegEx": "Yazdani et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yazdani et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 24, "context": "tor space has proven effective in a variety of language processing tasks (Pham et al., 2015; Sutskever et al., 2014).", "startOffset": 73, "endOffset": 116}, {"referenceID": 29, "context": "tor space has proven effective in a variety of language processing tasks (Pham et al., 2015; Sutskever et al., 2014).", "startOffset": 73, "endOffset": 116}, {"referenceID": 17, "context": "An alternative way of computing phrase embeddings is to treat phrases as single units and assigning a unique embedding to each candidate phrase (Mikolov et al., 2013; Yazdani et al., 2015).", "startOffset": 144, "endOffset": 188}, {"referenceID": 32, "context": "An alternative way of computing phrase embeddings is to treat phrases as single units and assigning a unique embedding to each candidate phrase (Mikolov et al., 2013; Yazdani et al., 2015).", "startOffset": 144, "endOffset": 188}, {"referenceID": 24, "context": "One approach is to learn compositional embeddings by regarding all phrases as compositional (Pham et al., 2015; Socher et al., 2012).", "startOffset": 92, "endOffset": 132}, {"referenceID": 28, "context": "One approach is to learn compositional embeddings by regarding all phrases as compositional (Pham et al., 2015; Socher et al., 2012).", "startOffset": 92, "endOffset": 132}, {"referenceID": 11, "context": "and use the better ones (Kartsaklis et al., 2014; Muraoka et al., 2014).", "startOffset": 24, "endOffset": 71}, {"referenceID": 21, "context": "and use the better ones (Kartsaklis et al., 2014; Muraoka et al., 2014).", "startOffset": 24, "endOffset": 71}, {"referenceID": 10, "context": "and use the better ones (Kartsaklis et al., 2014; Muraoka et al., 2014). Kartsaklis et al. (2014) show that non-compositional embeddings are better suited for a phrase similarity task, whereas Muraoka et al.", "startOffset": 25, "endOffset": 98}, {"referenceID": 10, "context": "and use the better ones (Kartsaklis et al., 2014; Muraoka et al., 2014). Kartsaklis et al. (2014) show that non-compositional embeddings are better suited for a phrase similarity task, whereas Muraoka et al. (2014) report the opposite results on other tasks.", "startOffset": 25, "endOffset": 215}, {"referenceID": 29, "context": "More complex ones such as recurrent neural networks (Sutskever et al., 2014) are also commonly used.", "startOffset": 52, "endOffset": 76}, {"referenceID": 11, "context": "Some recent studies (Kartsaklis et al., 2014; Muraoka et al., 2014) have discussed the (dis)advantages of using compositional or non-compositional embeddings.", "startOffset": 20, "endOffset": 67}, {"referenceID": 21, "context": "Some recent studies (Kartsaklis et al., 2014; Muraoka et al., 2014) have discussed the (dis)advantages of using compositional or non-compositional embeddings.", "startOffset": 20, "endOffset": 67}, {"referenceID": 15, "context": "Mikolov et al. (2013) show that noncompositional embeddings are preferable when dealing with idiomatic phrases.", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "Acquisition of selectional preference using embeddings has been widely studied, where word and/or phrase embeddings are learned based on syntactic links (Bansal et al., 2014; Hashimoto and Tsuruoka, 2015; Levy and Goldberg, 2014; Van de Cruys, 2014).", "startOffset": 153, "endOffset": 249}, {"referenceID": 0, "context": "Acquisition of selectional preference using embeddings has been widely studied, where word and/or phrase embeddings are learned based on syntactic links (Bansal et al., 2014; Hashimoto and Tsuruoka, 2015; Levy and Goldberg, 2014; Van de Cruys, 2014). As with language modeling, these methods perform word (or phrase) prediction using (syntactic) contexts. In this work, we focus on verb-object relationships and employ a phrase embedding learning method presented in Hashimoto and Tsuruoka (2015). The task is a plausibility judgment task for predicate-argument tuples.", "startOffset": 154, "endOffset": 497}, {"referenceID": 4, "context": "The matrices and embeddings are learned by minimizing the cost function using AdaGrad (Duchi et al., 2011).", "startOffset": 86, "endOffset": 106}, {"referenceID": 10, "context": "as proposed by Kartsaklis et al. (2012). The operator \u2299 denotes element-wise multiplication.", "startOffset": 15, "endOffset": 40}, {"referenceID": 15, "context": "The second set of features, frequency and PMI (Church and Hanks, 1990) features, have proven effective in detecting the compositionality of transitive verbs in McCarthy et al. (2007) and Venkatapathy and Joshi (2005).", "startOffset": 160, "endOffset": 183}, {"referenceID": 15, "context": "The second set of features, frequency and PMI (Church and Hanks, 1990) features, have proven effective in detecting the compositionality of transitive verbs in McCarthy et al. (2007) and Venkatapathy and Joshi (2005). Given the training corpus, the frequency feature for a VO pair is computed as", "startOffset": 160, "endOffset": 217}, {"referenceID": 4, "context": "The optimization was performed via minibatch AdaGrad (Duchi et al., 2011).", "startOffset": 53, "endOffset": 73}, {"referenceID": 15, "context": "provided by Venkatapathy and Joshi (2005) and McCarthy et al. (2007), respectively.", "startOffset": 46, "endOffset": 69}, {"referenceID": 16, "context": "420 DSPROTO+ (McCarthy et al., 2007) 0.", "startOffset": 13, "endOffset": 36}, {"referenceID": 16, "context": "454 n/a DSPROTO (McCarthy et al., 2007) 0.", "startOffset": 16, "endOffset": 39}, {"referenceID": 16, "context": "398 n/a PMI (McCarthy et al., 2007) 0.", "startOffset": 12, "endOffset": 35}, {"referenceID": 16, "context": "274 n/a Frequency (McCarthy et al., 2007) 0.", "startOffset": 18, "endOffset": 41}, {"referenceID": 22, "context": "2 in Newton (2006), the term light verb is used to refer to verbs which can be used in combination with some other element where their contribution to the meaning of the whole construction is reduced in some way.", "startOffset": 5, "endOffset": 19}, {"referenceID": 21, "context": "By contrast, many of the previous studies on embedding-based methods combine different corpora into a single dataset, or use multiple corpora just separately and compare them (Hashimoto and Tsuruoka, 2015; Muraoka et al., 2014; Pennington et al., 2014).", "startOffset": 175, "endOffset": 252}, {"referenceID": 23, "context": "By contrast, many of the previous studies on embedding-based methods combine different corpora into a single dataset, or use multiple corpora just separately and compare them (Hashimoto and Tsuruoka, 2015; Muraoka et al., 2014; Pennington et al., 2014).", "startOffset": 175, "endOffset": 252}, {"referenceID": 16, "context": "574 n/a Milajevs et al. (2014) 0.", "startOffset": 8, "endOffset": 31}, {"referenceID": 16, "context": "574 n/a Milajevs et al. (2014) 0.456 n/a Polajnar et al. (2014) n/a 0.", "startOffset": 8, "endOffset": 64}, {"referenceID": 7, "context": "370 Hashimoto et al. (2014) 0.", "startOffset": 4, "endOffset": 28}, {"referenceID": 7, "context": "370 Hashimoto et al. (2014) 0.420 0.340 Polajnar et al. (2015) n/a 0.", "startOffset": 4, "endOffset": 63}, {"referenceID": 7, "context": "370 Hashimoto et al. (2014) 0.420 0.340 Polajnar et al. (2015) n/a 0.330 Grefenstette and Sadrzadeh (2011) n/a 0.", "startOffset": 4, "endOffset": 107}, {"referenceID": 1, "context": "The phrase embeddings have proven effective in many language processing tasks, such as machine translation (Cho et al., 2014; Sutskever et al., 2014), sentiment analysis and semantic textual similarity (Tai et al.", "startOffset": 107, "endOffset": 149}, {"referenceID": 29, "context": "The phrase embeddings have proven effective in many language processing tasks, such as machine translation (Cho et al., 2014; Sutskever et al., 2014), sentiment analysis and semantic textual similarity (Tai et al.", "startOffset": 107, "endOffset": 149}, {"referenceID": 30, "context": ", 2014), sentiment analysis and semantic textual similarity (Tai et al., 2015).", "startOffset": 60, "endOffset": 78}, {"referenceID": 14, "context": "Many studies have focused on detecting the compositionality of a variety of phrases (Lin, 1999), including the ones on verb phrases (Diab and Bhutada, 2009; McCarthy et al.", "startOffset": 84, "endOffset": 95}, {"referenceID": 15, "context": "Many studies have focused on detecting the compositionality of a variety of phrases (Lin, 1999), including the ones on verb phrases (Diab and Bhutada, 2009; McCarthy et al., 2003) and compound nouns (Farahmand et al.", "startOffset": 132, "endOffset": 179}, {"referenceID": 5, "context": ", 2003) and compound nouns (Farahmand et al., 2015; Reddy et al., 2011; Yazdani et al., 2015).", "startOffset": 27, "endOffset": 93}, {"referenceID": 27, "context": ", 2003) and compound nouns (Farahmand et al., 2015; Reddy et al., 2011; Yazdani et al., 2015).", "startOffset": 27, "endOffset": 93}, {"referenceID": 32, "context": ", 2003) and compound nouns (Farahmand et al., 2015; Reddy et al., 2011; Yazdani et al., 2015).", "startOffset": 27, "endOffset": 93}, {"referenceID": 16, "context": "Compared to statistical featurebased methods (McCarthy et al., 2007; Venkatapathy and Joshi, 2005), re-", "startOffset": 45, "endOffset": 98}, {"referenceID": 32, "context": "embeddings (Kiela and Clark, 2013; Yazdani et al., 2015).", "startOffset": 11, "endOffset": 56}, {"referenceID": 32, "context": "Yazdani et al. (2015)", "startOffset": 0, "endOffset": 22}], "year": 2017, "abstractText": "We present a novel method for jointly learning compositional and noncompositional phrase embeddings by adaptively weighting both types of embeddings using a compositionality scoring function. The scoring function is used to quantify the level of compositionality of each phrase, and the parameters of the function are jointly optimized with the objective for learning phrase embeddings. In experiments, we apply the adaptive joint learning method to the task of learning embeddings of transitive verb phrases, and show that the compositionality scores have strong correlation with human ratings for verb-object compositionality, substantially outperforming the previous state of the art. Moreover, our embeddings improve upon the previous best model on a transitive verb disambiguation task. We also show that a simple ensemble technique further improves the results for both tasks.", "creator": "LaTeX with hyperref package"}}}