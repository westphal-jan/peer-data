{"id": "1603.06677", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2016", "title": "Learning Executable Semantic Parsers for Natural Language Understanding", "abstract": "for building question answering systems and natural - language interfaces, semantic parsing has emerged as an important and powerful paradigm. semantic parsers map natural language into logical forms, the classic representation for comparing many important linguistic phenomena. the modern twist is that we are interested in learning semantic parsers from data, which clearly introduces a new layer of combined statistical and computational issues. then this article lays out the unique components of a layered statistical semantic parser, quickly highlighting the key challenges. we will see that semantic parsing is a potential rich online fusion of the logical and the statistical world, and that this fusion will play an integral role in the projected future of existing natural language understanding systems.", "histories": [["v1", "Tue, 22 Mar 2016 05:07:16 GMT  (136kb,D)", "http://arxiv.org/abs/1603.06677v1", "Accepted to the Communications of the ACM"]], "COMMENTS": "Accepted to the Communications of the ACM", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["percy liang"], "accepted": false, "id": "1603.06677"}, "pdf": {"name": "1603.06677.pdf", "metadata": {"source": "CRF", "title": "Learning Executable Semantic Parsers for Natural Language Understanding", "authors": ["Percy Liang"], "emails": ["pliang@cs.stanford.edu"], "sections": [{"heading": null, "text": "Categories and Subject Descriptors I.2.7 [Artificial Intelligence]: Natural Language Processing\u2014Language parsing and understanding"}, {"heading": "1. INTRODUCTION", "text": "A long-standing goal of artificial intelligence (AI) is to build systems capable of understanding natural language. To focus the notion of \u201cunderstanding\u201d a bit, let us say that the system must produce an appropriate action upon receiving an input utterance from a human. For example:\nContext: knowledge of mathematics Utterance: What is the largest prime less than 10?\nAction: 7\nContext: knowledge of geography Utterance: What is the tallest mountain in Europe?\nAction: Mt. Elbrus\nContext: user\u2019s calendar Utterance: Cancel all my meetings after 4pm tomorrow.\nAction: (removes meetings from calendar)\nWe are interested in utterances such as the ones above, which require deep understanding and reasoning. This arti-\ncle focuses on semantic parsing, an area within the field of natural language processing (NLP), which has been growing over the last decade. Semantic parsers map input utterances into semantic representations called logical forms that support this form of reasoning. For example, the first utterance above would map onto the logical form max(primes \u2229 (\u2212\u221e, 10)). We can think of the logical form as a program that is executed to yield the desired behavior (e.g., answering 7). The second utterance would map onto a database query; the third, onto an invocation of a calendar API.\nSemantic parsing is rooted in formal semantics, pioneered by logician Richard Montague [25], who famously argued that there is \u201cno important theoretical difference between natural languages and the artificial languages of logicians.\u201d Semantic parsing, by residing in the practical realm, is more exposed to the differences between natural language and logic, but it inherits two general insights from formal semantics: The first idea is model theory, which states that expressions (e.g., primes) are mere symbols which only obtain their meaning or denotation (e.g., {2, 3, 5, . . . }) by executing the expression with respect to a model, or in our terminology, a context. This property allows us to factor out the understanding of language (semantic parsing) from world knowledge (execution). Indeed, one can understand the utterance \u201cWhat is the largest prime less than 10?\u201d without actually computing the answer. The second idea is compositionality, a principle often attributed to Gottlob Frege, which states that the denotation of an expression is defined recursively in terms of the denotations of its subexpressions. For example, primes denotes the set of primes, (\u2212\u221e, 10) denotes the set of numbers smaller than 10, and so primes\u2229 (\u2212\u221e, 10) denotes the intersection of those two sets. This compositionality is what allows us to have a succinct characterization of meaning for a combinatorial range of possible utterances.\nEarly systems. Logical forms have played a foundational role in natural language understanding systems since their genesis in the 1960s. Early examples included LUNAR, a natural language interface into a database about moon rocks [34], and SHRDLU, a system that could both answer questions and perform actions in a toy blocks world environment [32]. For their time, these systems were significant achievements. They were able to handle fairly complex linguistic phenomena and integrate syntax, semantics, and reasoning in an end-to-end application. For example, SHRDLU was able to process \u201cFind a block which is taller than the one you are holding and put it into the box.\u201d However, as the systems were based on hand-crafted rules, it became increasingly dif-\nar X\niv :1\n60 3.\n06 67\n7v 1\n[ cs\n.C L\n] 2\n2 M\nar 2\n01 6\nficult to generalize beyond the narrow domains and handle the intricacies of general language.\nRise of machine learning. In the early 1990s, influenced by the successes of statistical techniques in the neighboring speech recognition community, the field of NLP underwent a statistical revolution. Machine learning offered a new paradigm: Collect examples of the desired input-output behavior and then fit a statistical model to these examples. The simplicity of this paradigm coupled with the increase in data and computation allowed machine learning to prevail.\nWhat fell out of favor was not only rule-based methods, but also the natural language understanding problems. In the statistical NLP era, much of the community\u2019s attention turned to tasks\u2014documentation classification, part-ofspeech tagging, and syntactic parsing\u2014which fell short of full end-to-end understanding. Even question answering systems relied less on understanding and more on a shallower analysis coupled with a large collection of unstructured text documents [10], typified by the TREC competitions.\nStatistical semantic parsing. The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19]. A variety of different semantic representations and learning algorithms were employed, but all of these approaches relied on having a labeled dataset of natural language utterances paired with annotated logical forms, for example:\nUtterance: What is the largest prime less than 10? Logical form: max(primes \u2229 (\u2212\u221e, 10))\nWeak supervision. Over the last few years, two exciting developments have really spurred interest in semantic parsing. The first is reducing the amount of supervision from annotated logical forms to answers [13, 21]:\nUtterance: What is the largest prime less than 10? Action: 7\nThis form of supervision is much easier to obtain via crowdsourcing. Although the logical forms are not observed, they are still modeled as latent variables, which must be inferred from the answer. This results in a more difficult learning problem, but [21] showed that it is possible to solve it without degrading accuracy.\nScaling up. The second development is the scaling up of semantic parsers to more complex domains. Previous semantic parsers had only been trained on limited domains such as US geography, but the creation of broad-coverage knowledge bases such as Freebase [8] set the stage for a new generation of semantic parsers for question answering. Initial systems required annotated logical forms [11], but soon, systems became trainable from answers [4, 18, 5]. Semantic parsers have even been extended beyond fixed knowledge bases to semi-structured tables [26]. With the ability to learn semantic parsers from question-answer pairs, it is easy to collect datasets via crowdsourcing. As a result, semantic parsing datasets have grown by an order of magnitude.\nIn addition, semantic parsers have been applied to a number of applications outside question answering: robot navigation\n[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.\nOutlook. Today, the semantic parsing community is a vibrant field, but it is still young and grappling with the complexities of the natural language understanding problem. Semantic parsing poses three types of challenges:\n\u2022 Linguistic: How should we represent the semantics of natural language and construct it compositionally from the natural language?\n\u2022 Statistical: How can we learn semantic parsers from weak supervision and generalize well to new examples?\n\u2022 Computational: How do we efficiently search over the combinatorially large space of possible logical forms?\nThe rest of the paper is structured as follows: We first present a general framework for semantic parsing, introducing the key components (Section 2). The framework is pleasantly modular, with different choices of the components corresponding to existing semantic parsers in the literature (Section 3). We describe the datasets (Section 4) and then conclude (Section 5)."}, {"heading": "2. FRAMEWORK", "text": "Natural language understanding problem. In this article, we focus on the following natural language understanding problem: Given an utterance x in a context c, output the desired action y. Figure 1 shows the setup for a question answering application, in which case x is a question, c is a knowledge base, and y is the answer. In a robotics application, x is a command, c represents the robot\u2019s environment, and y is the desired sequence of actions to be carried by the robot [29]. To build such a system, assume that we are given a set of n examples {(xi, ci, yi)}ni=1. We would like to use these examples to train a model that can generalize to new unseen utterances and contexts.\nSemantic parsing components. This article focuses on a statistical semantic parsing approach to the above problem, where the key is to posit an intermediate logical form z that connects x and y. Specifically, z captures the semantics of the utterance x, and it also executes to the action y (in the context of c). In our running example, z would be max(primes \u2229 (\u2212\u221e, 10)). Our semantic parsing framework consists of the following five components (see Figure 2):\n1. Executor: computes the denotation (action) y = JzKc given a logical form z and context c. This defines the semantic representation (logical forms along with their denotations).\n2. Grammar: a set of rules G that produces D(x, c), a set of candidate derivations of logical forms.\n3. Model: specifies a distribution p\u03b8(d | x, c) over derivations d parameterized by \u03b8.\n4. Parser: searches for high probability derivations d under the model p\u03b8.\n5. Learner: estimates the parameters \u03b8 (and possibly rules in G) given training examples {(xi, ci, yi)}ni=1.\nWe now instantiate each of these components for our running example: \u201cWhat is the largest prime less than 10?\u201d\nExecutor. Let the semantic representation be the language of mathematics, and the executor is the standard interpretation, where the interpretations of predicates (e.g., primes) are given by c. With c(primes) = {2, 3, 5, 7, 11, . . . , }, the denotation is Jprimes \u2229 (\u2212\u221e, 10)Kc = {2, 3, 5, 7}.\nGrammar. The grammarG connects utterances to possible derivations of logical forms. Formally, the grammar is a set of rules of the form \u03b1 \u21d2 \u03b2.1 Here is a simple grammar for our running example:\n(R1) prime \u21d2 NP[primes] (R2) 10 \u21d2 NP[10] (R3) less than NP[z] \u21d2 QP[(\u2212\u221e, z)] (R4) NP[z1] QP[z2] \u21d2 NP[z1 \u2229 z2] (R5) largest NP[z] \u21d2 NP[max(z)] (R6) largest NP[z] \u21d2 NP[min(z)] (R7) What is the NP[z]? \u21d2 ROOT[z]\nWe start with the input utterance and repeatedly apply rules in G. A rule \u03b1 \u21d2 \u03b2 can be applied if some span of the utterance matches \u03b1, in which case a derivation over the same span with a new syntactic category and logical form according to \u03b2 is produced. Here is one possible derivation (call it d1) for our running example:\n1 The standard way context-free grammar rules are written is \u03b2 \u2192 \u03b1. Because our rules build logical forms, reversing the arrow is more natural.\nWhat is the largest prime less than 10 ? (R1) (R2)\nNP[primes] NP[10] (R3)\nQP[(\u2212\u221e, 10)] (R4)\nNP[primes \u2229 (\u2212\u221e, 10)] (R5)\nNP[max(primes \u2229 (\u2212\u221e, 10))] (R7)\nROOT[max(primes \u2229 (\u2212\u221e, 10))] (1)\nFor example, applying (R3) produces category QP and logical form (\u2212\u221e, 10) over span [5 :7] corresponding to\u201cless than 10\u201d. We stop when we produce the designated ROOT category over the entire utterance. Note that we could have also applied (R6) instead of (R5) to generate the (incorrect) logical form min(primes\u2229 (\u2212\u221e, 10)); let this derivation be d2. We have D(x, c) = {d1, d2} here, but in general, there could be exponentially many derivations, and multiple derivations can generate the same logical form. In general, the grammar might contain nonsense rules (R6) that do not reflect ambiguity in language but are rather due to model uncertainty prior to learning.\nModel. The model scores the set of candidate derivations generated by the grammar. A common choice used by virtually all existing semantic parsers are log-linear models (generalizations of logistic regressions). In a log-linear model, define a feature vector \u03c6(x, c, d) \u2208 RF for each possible derivation d. We can think of each feature as casting a vote for various derivations d based on some coarse property of the derivation. For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].\nNext, let \u03b8 \u2208 RF denote the parameter vector, which defines a weight for each feature representing how reliable that feature is. Their weighted combination score(x, c, d) = \u03c6(x, c, d) \u00b7 \u03b8 represents how good the derivation is. We can exponentiate and normalize these scores to obtain a distribution over derivations:\np\u03b8(d | x, c) = exp(score(x, c, d))\u2211\nd\u2032\u2208D(x,c) exp(score(x, c, d \u2032)) . (2)\nIf \u03b8 = [0, 0, 0, 0,+1,\u22121, 0], then p\u03b8 would assign probability exp(1) exp(1)+exp(\u22121) \u2248 0.88 to d1 and \u2248 0.12 to d2.\nParser. Given a trained model p\u03b8, the parser (approximately) computes the highest probability derivation(s) for an utterance x under p\u03b8. Assume the utterance x is represented as a sequence of tokens (words). A standard approach is to use a chart parser, which recursively builds derivations for each span of the utterance. Specifically, for each category A and span [i : j] (where 0 \u2264 i < j \u2264 length(x)), we loop over the applicable rules in the grammar G and apply each one to build new derivations of category A over [i : j]. For binary rules\u2014those of the form BC \u21d2 A such as (R4), we loop over split points k (where i < k \u2264 j), recursively compute derivations B[z1] over [i : k] and C[z2] over [k : j], and\ncombine them into a new derivation A[z] over [i :j], where z is determined by the rule; for example, z = z1 \u2229 z2 for (R4). The final derivations for the utterance are collected in the ROOT category over span [0 : length(x)].\nThe above procedure would generate all derivations, which could be exponentially large. Generally, we only wish to compute compute the derivations with high probability under our model p\u03b8. If the features of p\u03b8 were to decompose as a sum over the rule applications in d\u2014that is, \u03c6(x, c, d) =\u2211\n(r,i,j)\u2208d \u03c6rule(x, c, r, i, j), then we could use dynamic programming: For each categoryA over [i :j], compute the highest probability derivation. However, in executable semantic parsing, feature decomposition isn\u2019t sufficient, since during learning, we also need to incorporate the constraint that the logical form executes to the true denotation (I[Jd.zKc = y]); see (6) below. To maintain exact computation in this setting, the dynamic programming state would need to include the entire logical form d.z, which is infeasible, since there are exponentially many logical forms. Therefore, beam search is generally employed, where we keep only the K sub-derivations with the highest model score based on only features of the sub-derivations. Beam search is not guaranteed to return the K highest scoring derivations, but it is often an effective heuristic.\nLearner. While the parser turns parameters into derivations, the learner solves the inverse problem. The dominant paradigm in machine learning is to set up an objective function and optimize it. A standard principle is to maximize the likelihood of the training data {(xi, ci, yi)}ni=1. An important point is that we don\u2019t observe the correct derivation for each example, but only the action yi, so we must consider all derivations d whose logical form d.z satisfy Jd.zKci = yi. This results in the log-likelihood of the observed action yi:\nOi(\u03b8) def = log \u2211 d\u2208D(xi,ci) Jd.zKci=yi p\u03b8(d | xi, ci). (3)\nThe final objective is then simply the sum across all n training examples:\nO(\u03b8) def= n\u2211 i=1 Oi(\u03b8), (4)\nThe simplest approach to maximize O(\u03b8) is to use stochastic gradient descent (SGD), an iterative algorithm that takes multiple passes (e.g., say 5) over the training data and makes the following update on example i:\n\u03b8 \u2190 \u03b8 + \u03b7\u2207Oi(\u03b8), (5)\nwhere \u03b7 is a step size that governs how aggressively we want to update parameters (e.g., \u03b7 = 0.1). In the case of log-linear models, the gradient has a nice interpretable form:\n\u2207Oi(\u03b8) = \u2211\nd\u2208D(xi,ci)\n(q(d)\u2212 p\u03b8(d | xi, ci))\u03c6(xi, ci, d), (6)\nwhere q(d) \u221d p\u03b8(d | xi, ci)I[Jd.zKci = yi] is the model distribution p\u03b8 over derivations d, but restricted to ones consistent with yi. The gradient pushes \u03b8 to put more probability mass on q and less on p\u03b8. For example, if p\u03b8 assigns probabilities [0.2, 0.4, 0.1, 0.3] to four derivations and the middle two derivations are consistent, then q assigns probabilities [0, 0.8, 0.2, 0].\nThe objective functionO(\u03b8) is not concave, so SGD is at best guaranteed to converge to a local optimum, not a global one. Another problem is that we cannot enumerate all derivations D(xi, ci) generated by the grammar, so we approximate this set with the result of beam search, which yieldsK candidates (typically K = 200); p\u03b8 is normalized over this set. Note that this candidate set depends on the current parameters \u03b8, resulting a heuristic approximation of the gradient \u2207Oi.\nSummary. We have covered the components of a semantic parsing system. Observe that the components are relatively loosely coupled: The executor is concerned purely with what we want to express independent of how it would be expressed in natural language. The grammar describes how candidate logical forms are constructed from the utterance but does not provide algorithmic guidance nor specify a way to score the candidates. The model focuses on a particular derivation and defines features that could be helpful for predicting accurately. The parser and the learner provide algorithms largely independent of semantic representations. This modularity allows us to improve each component in isolation."}, {"heading": "3. REFINING THE COMPONENTS", "text": "Having toured the components of a semantic parsing system, we now return to each component and discuss the key design decisions and possibilities for improvement."}, {"heading": "3.1 Executor", "text": "By describing an executor, we are really describing the language of the logical form. A basic textbook representation of language is first-order logic, which can be used to make quantified statements about relations between objects. For example, \u201cEvery prime greater than two is odd.\u201d would be expressed in first-order logic as \u2200x.prime(x) \u2227 more(x, 2)\u2192 odd(x). Here, the context c is a model (in the model theory sense), which maps predicates to sets of objects or object pairs. The execution of the above logical form with respect to the standard mathematical context would be true. [7] gives a detailed account on how first-order logic is used for natural language semantics.\nFirst-order logic is reasonably powerful, but it fails to capture some common phenomena in language. For example, \u201cHow many primes are less than 10?\u201d requires constructing a set and manipulating it and thus goes beyond the power of first-order logic. We can instead augment firstorder logic with constructs from lambda calculus. The logical form corresponding to the above question would be count(\u03bbx.prime(x)\u2227 less(x, 10)), where the \u03bb operator can be thought of as constructing a set of all x that satisfy the condition; in symbols, J\u03bbx.f(x)Kc = {x : Jf(x)Kc = true}. Note that count is a higher-order functions that takes a function as an argument.\nAnother logical language, which can be viewed as syntactic sugar for lambda calculus, is lambda dependency-based semantics (DCS) [20]. In lambda DCS, the above logical form would be count(prime u (less.10)), where the constant 10 represent \u03bbx.(x = 10), the intersection operator z1 u z2 represents \u03bbx.z1(x)\u2227z2(x), and the join operator r.z represents \u03bbx.\u2203y.r(x, y) \u2227 z(y).\nLambda DCS is\u201clifted\u201d in the sense that operations combine functions from objects to truth values (think sets) rather\nthan truth values. As a result, lambda DCS logical forms partially eliminate the need for variables. Noun phrases in natural language (e.g., \u201cprime less than 10\u201d) also denote sets. Thus, lambda DCS arguably provides a transparent interface with natural language.\nFrom a linguistic point of view, the logical language seeks primarily to model natural language phenomena. From an application point of view, the logical language dictates what actions we support. It is thus common to use applicationspecific logical forms, for example, regular expressions [17]. Note that the other components of the framework are largely independent of the exact logical language used."}, {"heading": "3.2 Grammar", "text": "Recall that the goal of the grammar in this article is just to define a set of candidate derivations for each utterance and context. Note that this is in contrast to a conventional notion of a grammar in linguistics, where the goal is to precisely characterize the set of valid sentences and interpretations. This divergence is due to two factors: First, we will learn a statistical model over the derivations generated by the grammar anyway, so the grammar can be simple and coarse. Second, we might be interested in application-specific logical forms. In a flight reservation domain, the logical form we wish to extract from \u201cI\u2019m in Boston and would like to go to Portland\u201d is flight u from.Boston u to.Portland, which is certainly not the full linguistic meaning of the utterance, but suffices for the task at hand. Note that the connection here between language and logic is less direct compared to \u201cprime less than 10\u201d\u21d2 prime u (less.10).\nCCG. One common approach to the grammar in semantic parsing is combinatory categorial grammar (CCG) [28], which had been developed extensively in linguistics before it was first used for semantic parsing [37]. CCG is typically coupled with logical forms in lambda calculus. Here is an example of a CCG derivation:\nprime less than 10\nN[\u03bbx.prime(x)] (N\\N)/NP[\u03bby.\u03bbf.\u03bbx.f(x) \u2227 less(x, y) NP[10] (>)\nN\\N[\u03bbf.\u03bbx.f(x) \u2227 less(x, 10)] (<)\nN[\u03bbx.prime(x) \u2227 less(x, 10)] (7)\nSyntactic categories in CCG include nouns (N) denoting sets and noun phrases (NP) denoting objects. Composite categories ((N\\N)/NP) represent functions of multiple arguments, but where the directionality of the slashes indicate the location of the arguments. Most rules in CCG are lexical (e.g., [prime \u21d2 N[\u03bbx.prime(x)]), which mention particular words. The rest of the rules are glue; for example, we have a forward application (>) and backward application (<) rule:\n(>) A/B[f ] B[x] \u21d2 A[f(x)] (<) B[x] A\\B[f ] \u21d2 A[f(x)]\nIt is common to use other combinators which both handle more complex linguistic phenomena such as NP coordination \u201cintegers that divide 2 or 3\u201d as well as ungrammatical\nlanguage [38], although these issues can also be handled by having a more expansive lexicon [19].\nCrude rules. In CCG, the lexical rules can become quite complicated. An alternative approach that appears mostly in work on lambda DCS is to adopt a much cruder grammar whose rules correspond directly to the lambda DCS constructions, join and intersect. This results in the following derivation:\nprime less than 10\nN[prime] N|N[less] N[10] (join)\nN[less.10] (intersect)\nN[prime u less.10]\n(8)\n(join) N|N[r] N[z] \u21d2 N[r.z] (intersect) N[z1] N[z2] \u21d2 N[z1 u z2]\nThe lack of constraints permits the derivation of other logical forms such as 10 u less.prime, but these incorrect logical forms can be ruled out statistically via the model. The principle is to keep the lexicon simple and lean more heavily on features (whose weights are learned from data) to derive drive the selection of logical forms.\nFloating rules. While this new lexicon is simpler, the bulk of the complexity comes from having it in the first place. Where does the rules [prime \u21d2 N|N : prime] and [less than \u21d2 N|N : less] come from? We can reduce the lexicon even further by introducing floating rules [\u2205 \u21d2 N|N : prime] and [\u2205 \u21d2 N|N : less], which can be applied in the absence of any lexical trigger. This way, the utterance \u201cprimes smaller than 10\u201d would also be able to generate prime u less.10, where the predicates prime and less are not anchored to any specific words.\nWhile this relaxation may seem linguistically blasphemous, recall that the purpose of the grammar is to merely deliver a set of logical forms, so floating rules are quite sensible provided we can keep the set of logical forms under control. Of course, since the grammar is so flexible, even more nonsensical logical forms are generated, so we must lean heavily on the features to score the derivations properly. When the logical forms are simple and we have strong type constraints, this strategy can be quite effective [5, 30, 26].\nThe choice of grammar is arguably the most important component of a semantic parser, as it most directly governs the tradeoff between expressivity and statistical/computational complexity. We have explored three grammars, from a tightlyconstrained CCG to a very laissez faire floating grammar. CCG is natural for capturing complex linguistic phenomena in well-structured sentences, whereas for applications where the utterances are noisy but the logical forms are simple, more flexible grammars are appropriate. In practice, one would probably want to mix and match depending on the domain."}, {"heading": "3.3 Model", "text": "At the core of a statistical model is a function score(x, c, d) that judges how good a derivation d is with respect to the\nutterance x and context c. In Section 2, we described a simple log-linear model (2) in which score(x, c, d) = \u03c6(x, c, d) \u00b7\u03b8, and with simple rule features. There are two ways to improve the model: use more expressive features and and use a non-linear scoring function.\nMost existing semantic parsers stick with a linear model and leverage more targeted features. One simple class of features {\u03c6a,b} is equal to the number of times word a appears in the utterance and predicate b occurs in the logical form; if the predicate b is generated by a floating rule, then a is allowed to range over the entire utterance; otherwise, it must appear in the span of b.\nThe above features are quite numerous, which provides flexibility but require a lot of data. Note that logical predicates (e.g., birthplace) and the natural language (e.g., born in) often share a common vocabulary (English words). One can leverage this structure by defining a few features based on statistics from large corpora, external lexical resources, or simply string overlap. For example, \u03c6match might be the number of word-predicate pairs with that match almost exactly. This way, the lexical mapping need not be learned from scratch using only the training data [4, 18].\nA second class of useful features are based on the denotation Jd.zKc of the predicted logical form. For example, in a robot control setting, a feature would encode whether the predicted actions are valid in the environment c (picking up a cup requires the cup to be present). These features make it amply clear that semantic parsing is not simply a natural language problem but one that involves jointly reasoning about the non-linguistic world. In addition, we typically include type constraints (features with weight \u2212\u221e) to prune out ill-formed logical forms such as birthplace.4 that are licensed the grammar.\nOne could also adopt a non-linear scoring function, which does not require any domain knowledge about semantic parsing. For example, one could use a simple one-layer neural network, which takes a weighted combination of m nonlinear basis functions: score(x, c, d) = \u2211m i=1 \u03b1i tanh(\u03c6(x, c, d)\u00b7 wi). The parameters of the model that we would learn are then the m top-level weights {\u03b1i} and the mF bottomlevel weights {wij}; recall that F is the number of features (\u03c6(x, c, d) \u2208 RF ). With more parameters, the model becomes more powerful, but also requires more data to learn."}, {"heading": "3.4 Parsing", "text": "Most semantic parsing algorithms are based on chart parsing, where we recursively generate a set of candidate derivations for each syntactic category (e.g., NP) and span (e.g., [3 :5]). There are two disadvantages of chart parsing: First, it does not easily support incremental contextual interpretation: The features of a span [i : j] can only depend on the sub-derivations in that span, not on the derivations constructed before i. This makes anaphora (resolution of \u201cit\u201d) difficult to model. A solution is to use shift-reduce parsing rather than chart parsing [40]. Here, one parses the utterance from left to right, and new sub-derivations can depend arbitrarily on the sub-derivations constructed thus far.\nA second problem is that the chart parsing generally builds derivations in some fixed order\u2014e.g., of increasing span size.\nThis causes the parser to waste equal resources on nonpromising spans which are unlikely to participate in the final derivation that is chosen. This motivates agenda-based parsing, in which derivations that are deemed more promising by the model are built first [6]."}, {"heading": "3.5 Learner", "text": "In learning, we are given examples of utterance-contextresponse triples (x, c, y). There are two aspects of learning: inducing the grammar rules and estimating the model parameters. It is important to remember that practical semantic parsers do not do everything from scratch, and often the hard-coded grammar rules are as important as the training examples. First, some lexical rules that map named entities (e.g., [paris \u21d2 ParisFrance]), dates, and numbers are generally assumed to be given [37], though we need not assume that these rules are perfect [21]. These rules are also often represented implicitly [21, 4].\nHow the rest of the grammar is handled varies across approaches. In CCG-style approach, inducing lexical rules is an important part of learning. In [37], a procedure called GENLEX is used to generate candidate lexical rules from a utterance-logical form pair (x, z). A more generic induction algorithm based on higher-order unification does not require any initial grammar [19]. [33] use machine translation ideas to induce a synchronous grammar (which can also be used to generate utterances from logical forms). However, all these lexicon induction methods require annotated logical forms z. In approaches that learn from denotations y [21, 4], an initial crude grammar is used to generate candidate logical forms, and rest of the work is done by the features.\nAs we discussed earlier, parameter estimation can be performed by stochastic gradient descent on the log-likelihood; similar objectives based on max-margin are also possible [22]. It can be helpful to also add an L1 regularization term \u03bb\u2016\u03b8\u20161, which encourages feature weights to be zero, which produces a more compact model that generalizes better [5]. In addition, one can use AdaGrad [14], which maintains a separate step size for each feature. This can improve stability and convergence."}, {"heading": "4. DATASETS AND RESULTS", "text": "In a strong sense, datasets are the main driver of progress for statistical approaches. We will now survey some of the existing datasets, describe their properties, and discuss the state-of-the-art.\nThe Geo880 dataset [36] drove nearly a decade of semantic parsing research. This dataset consists of 880 questions and database queries about US geography (e.g., \u201cwhat is the highest point in the largest state?\u201d). The utterances are compositional, but the language is clean and the domain is limited. On this dataset, learning from logical forms [18] and answers [21] both achieve around 90%\nThe ATIS-3 dataset [38] consists of 5418 utterances paired with logical forms (e.g., \u201cshow me information on american airlines from fort worth texas to philadelphia\u201d). The utterances contain more disfluencies and flexible word order compared with Geo880, but they are logically simpler. As a result, slot filling methods have been a successful paradigm in the spoken language understanding community for this\ndomain since the 1990s. The best reported result is based on semantic parsing and obtains 84.6%\nThe Regexp824 dataset [17] consists of 824 natural language and regular expression pairs (e.g., \u201cthree letter word starting with \u2019X\u2019\u201d). The main challenge here is that there are many logically equivalent regular expressions, some aligning better to the natural language than others. [17] uses semantic unification to test for logical form equivalence and obtains 65.6%\nThe Free917 dataset [11] consists of 917 examples of questionlogical form pairs that can be answered via Freebase, e.g. \u201chow many works did mozart dedicate to joseph haydn?\u201d The questions are logically less complex than those in the semantic parsing datasets above, but introduces the new challenge of scaling up to many more predicates (but is in practice manageable by assuming perfect named entity resolution and leveraging the strong type constraints in Freebase). The state-of-the-art accuracy is 68%\nWebQuestions [4] is another dataset on Freebase consisting of 5810 question-answer pairs (no logical forms) such as \u201cwhat do australia call their money?\u201d Like Free917, the questions are not very compositional, but unlike Free917, they are real questions asked by people on the Web independent from Freebase, so they are more realistic and more varied. Because the answers are required to come from a single Freebase page, a noticeable fraction of the answers are imperfect. The current state-of-the-art is 52.5%\nThe goal of WikiTableQuestions [26] is to extend question answering beyond Freebase to HTML tables on Wikipedia, which are semi-structured. The dataset consists of 22033 question-table-answer triples (e.g., \u201chow many runners took 2 minutes at the most to run 1500 meters?\u201d), where each question can be answered by aggregating information across the table. At test time, we are given new tables, so methods must learn how to generalize to new predicates. The result on this new dataset is 37.1%\n[30] proposed a new recipe for quickly using crowdsourcing to generate new compositional semantic parsing datasets consisting of question-logical form pairs. Using this recipe, they created eight new datasets in small domains consisting of 12602 total question-answer pairs, and achieved an average accuracy on across datasets of 58.8%\n[12] introduced a dataset of 706 navigation instructions (e.g., \u201cfacing the lamp go until you reach a chair\u201d) in a simple grid world. Each instruction sequence contains multiple sentences with various imperative and context-dependent constructions not found in previous datasets. [2] obtained 65.3%"}, {"heading": "5. DISCUSSION", "text": "We have presented a semantic parsing framework for the problem of natural language understanding. Going forward, the two big questions are (i) how to represent the semantics of language and (ii) what supervision to use to learn the semantics from.\nAlternative semantic representations. One of the main difficulties with semantic parsing is the divergence between the structure of the natural language and the logical forms\u2014\npurely compositional semantics will not work. This has led to some efforts to introduce an intermediate layer between utterances and logical forms. One idea is to use general paraphrasing models to map input utterances to the \u201ccanonical utterances\u201d of logical forms [5, 30]. This reduces semantic parsing to a text-only problem for which there is much more data and resources.\nOne could also use domain-general logical forms that capture the basic predicate-argument structures of sentences [18]. Abstract meaning representation (AMR) [3] is one popular representation backed by an extension linguistic annotation effort. Multiple AMR parsers have been developed, including one based on CCG [1]. While these representations offer broad coverage, solving downstream understanding tasks still require additional work (e.g., inferring that \u201cpopulation of X \u201d is synonymous with \u201cnumber of people living in X \u201d). In contrast, executable semantic parsing operates on the full pipeline from utterance to task output, but compromises on domain-generality. This is partially inevitable, as any understanding task requires some domain-specific knowledge or grounding. Designing the best general representation that supports many downstream tasks remains an open challenge.\nAlternative supervision. Much of the progress in semantic parsing has been due to being able to learn from weaker supervision. In the framework we presented, this supervision are the desired actions y (e.g., answers to questions). One can use a large corpus of text to exploit even weaker supervision [16, 27]. More generally, one can think about language interpretation in a reinforcement learning setting [9], where an agent who presented with an utterance in some context performs some action, and receives a corresponding reward signal. This framework highlights the importance of context-dependence in language interpretation [39, 2].\nDue to their empirical success, there has been a recent surge of interest in using recurrent neural networks and their extensions for solving NLP tasks such as machine translation and question answering [35, 31]. These methods share the same spirit of end-to-end utterance-to-behavior learning as executable semantic parsing, but they do not explicitly separate parsing from execution. This makes them architecturally simpler than semantic parsers, but they are more data hungry and it is unclear whether they can learn to perform complex logical reasoning in a generalizable way. Nonetheless, it is quite likely that these methods will play an important role in the story of language understanding.\nOutlook. This is an exciting time for semantic parsing and natural language understanding. As natural language interfaces (e.g., Siri) become more ubiquitous, the demand for deep understanding will continue to grow. At the same time, there is a fresh wave of ambition pushing the limits of what can be machine learnable. The confluence of these two factors will likely generate both end-user impact as well as new insights into the nature of language and learning."}, {"heading": "6. REFERENCES", "text": "[1] Y. Artzi and K. L. L. Zettlemoyer. Broad-coverage CCG\nsemantic parsing with AMR. In Empirical Methods in Natural Language Processing (EMNLP), 2015.\n[2] Y. Artzi and L. Zettlemoyer. Weakly supervised learning of semantic parsers for mapping instructions to actions.\nTransactions of the Association for Computational Linguistics (TACL), 1:49\u201362, 2013.\n[3] L. BanaRescu, C. B. S. Cai, M. Georgescu, K. Griffitt, U. Hermjakob, K. Knight, P. Koehn, M. Palmer, and N. Schneider. Abstract meaning representation for sembanking. In 7th Linguistic Annotation Workshop and Interoperability with Discourse, 2013. [4] J. Berant, A. Chou, R. Frostig, and P. Liang. Semantic parsing on Freebase from question-answer pairs. In Empirical Methods in Natural Language Processing (EMNLP), 2013. [5] J. Berant and P. Liang. Semantic parsing via paraphrasing. In Association for Computational Linguistics (ACL), 2014. [6] J. Berant and P. Liang. Imitation learning of agenda-based semantic parsers. Transactions of the Association for Computational Linguistics (TACL), 0, 2015. [7] P. Blackburn and J. Bos. Representation and Inference for Natural Language: A First Course in Computational Semantics. CSLI Publishers, 2005. [8] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In International Conference on Management of Data (SIGMOD), pages 1247\u20131250, 2008. [9] S. Branavan, H. Chen, L. S. Zettlemoyer, and R. Barzilay. Reinforcement learning for mapping instructions to actions. In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP), pages 82\u201390, 2009.\n[10] E. Brill, S. Dumais, and M. Banko. An analysis of the AskMSR question-answering system. In Association for Computational Linguistics (ACL), pages 257\u2013264, 2002. [11] Q. Cai and A. Yates. Large-scale semantic parsing via schema matching and lexicon extension. In Association for Computational Linguistics (ACL), 2013. [12] D. L. Chen and R. J. Mooney. Learning to interpret natural language navigation instructions from observations. In Association for the Advancement of Artificial Intelligence (AAAI), pages 859\u2013865, 2011. [13] J. Clarke, D. Goldwasser, M. Chang, and D. Roth. Driving semantic parsing from the world\u2019s response. In Computational Natural Language Learning (CoNLL), pages 18\u201327, 2010. [14] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. In Conference on Learning Theory (COLT), 2010. [15] J. Krishnamurthy and T. Kollar. Jointly learning to parse and perceive: Connecting natural language to the physical world. Transactions of the Association for Computational Linguistics (TACL), 1:193\u2013206, 2013. [16] J. Krishnamurthy and T. Mitchell. Weakly supervised training of semantic parsers. In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 754\u2013765, 2012. [17] N. Kushman and R. Barzilay. Using semantic unification to generate regular expressions from natural language. In Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL), pages 826\u2013836, 2013. [18] T. Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer. Scaling semantic parsers with on-the-fly ontology matching. In Empirical Methods in Natural Language Processing (EMNLP), 2013. [19] T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, and M. Steedman. Inducing probabilistic CCG grammars from logical form with higher-order unification. In Empirical Methods in Natural Language Processing (EMNLP), pages 1223\u20131233, 2010. [20] P. Liang. Lambda dependency-based compositional semantics. arXiv, 2013. [21] P. Liang, M. I. Jordan, and D. Klein. Learning dependency-based compositional semantics. In Association\nfor Computational Linguistics (ACL), pages 590\u2013599, 2011. [22] P. Liang and C. Potts. Bringing machine learning and\ncompositional semantics together. Annual Reviews of Linguistics, 1(1):355\u2013376, 2015.\n[23] C. Matuszek, N. FitzGerald, L. Zettlemoyer, L. Bo, and D. Fox. A joint model of language and perception for grounded attribute learning. In International Conference on Machine Learning (ICML), pages 1671\u20131678, 2012. [24] S. Miller, D. Stallard, R. Bobrow, and R. Schwartz. A fully statistical approach to natural language interfaces. In Association for Computational Linguistics (ACL), pages 55\u201361, 1996. [25] R. Montague. The proper treatment of quantification in ordinary English. In Approaches to Natural Language, pages 221\u2013242, 1973. [26] P. Pasupat and P. Liang. Compositional semantic parsing on semi-structured tables. In Association for Computational Linguistics (ACL), 2015. [27] S. Reddy, M. Lapata, and M. Steedman. Large-scale semantic parsing without question-answer pairs. Transactions of the Association for Computational Linguistics (TACL), 2(10):377\u2013392, 2014. [28] M. Steedman. The Syntactic Process. MIT Press, 2000. [29] S. Tellex, T. Kollar, S. Dickerson, M. R. Walter, A. G.\nBanerjee, S. J. Teller, and N. Roy. Understanding natural language commands for robotic navigation and mobile manipulation. In Association for the Advancement of Artificial Intelligence (AAAI), 2011.\n[30] Y. Wang, J. Berant, and P. Liang. Building a semantic parser overnight. In Association for Computational Linguistics (ACL), 2015. [31] J. Weston, S. Chopra, and A. Bordes. Memory networks. In International Conference on Learning Representations (ICLR), 2015. [32] T. Winograd. Understanding Natural Language. Academic Press, 1972. [33] Y. W. Wong and R. J. Mooney. Learning synchronous grammars for semantic parsing with lambda calculus. In Association for Computational Linguistics (ACL), pages 960\u2013967, 2007. [34] W. A. Woods, R. M. Kaplan, and B. N. Webber. The lunar sciences natural language information system: Final report. Technical report, BBN Report 2378, Bolt Beranek and Newman Inc., 1972. [35] W. Yih, M. Chang, X. He, and J. Gao. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Association for Computational Linguistics (ACL), 2015. [36] M. Zelle and R. J. Mooney. Learning to parse database queries using inductive logic programming. In Association for the Advancement of Artificial Intelligence (AAAI), pages 1050\u20131055, 1996. [37] L. S. Zettlemoyer and M. Collins. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Uncertainty in Artificial Intelligence (UAI), pages 658\u2013666, 2005. [38] L. S. Zettlemoyer and M. Collins. Online learning of relaxed CCG grammars for parsing to logical form. In Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 678\u2013687, 2007. [39] L. S. Zettlemoyer and M. Collins. Learning context-dependent mappings from sentences to logical form. In Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP), 2009. [40] K. Zhao and L. Huang. Type-driven incremental semantic parsing with polymorphism. In North American Association for Computational Linguistics (NAACL), 2015."}], "references": [{"title": "Broad-coverage CCG semantic parsing with AMR", "author": ["Y. Artzi", "K.L.L. Zettlemoyer"], "venue": "Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Weakly supervised learning of semantic parsers for mapping instructions to actions", "author": ["Y. Artzi", "L. Zettlemoyer"], "venue": " Transactions of the Association for Computational Linguistics (TACL), 1:49\u201362", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Abstract meaning representation for sembanking", "author": ["L. BanaRescu", "C.B.S. Cai", "M. Georgescu", "K. Griffitt", "U. Hermjakob", "K. Knight", "P. Koehn", "M. Palmer", "N. Schneider"], "venue": "7th Linguistic Annotation Workshop and Interoperability with Discourse", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["J. Berant", "A. Chou", "R. Frostig", "P. Liang"], "venue": "Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Semantic parsing via paraphrasing", "author": ["J. Berant", "P. Liang"], "venue": "Association for Computational Linguistics (ACL)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Imitation learning of agenda-based semantic parsers", "author": ["J. Berant", "P. Liang"], "venue": "Transactions of the Association for Computational Linguistics (TACL), 0", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Representation and Inference for Natural Language: A First Course in Computational Semantics", "author": ["P. Blackburn", "J. Bos"], "venue": "CSLI Publishers", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "International Conference on Management of Data (SIGMOD), pages 1247\u20131250", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Reinforcement learning for mapping instructions to actions", "author": ["S. Branavan", "H. Chen", "L.S. Zettlemoyer", "R. Barzilay"], "venue": "Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP), pages 82\u201390", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "An analysis of the AskMSR question-answering system", "author": ["E. Brill", "S. Dumais", "M. Banko"], "venue": "Association for Computational Linguistics (ACL), pages 257\u2013264", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Large-scale semantic parsing via schema matching and lexicon extension", "author": ["Q. Cai", "A. Yates"], "venue": "Association for Computational Linguistics (ACL)", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning to interpret natural language navigation instructions from observations", "author": ["D.L. Chen", "R.J. Mooney"], "venue": "Association for the Advancement of Artificial Intelligence (AAAI), pages 859\u2013865", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Driving semantic parsing from the world\u2019s response", "author": ["J. Clarke", "D. Goldwasser", "M. Chang", "D. Roth"], "venue": "Computational Natural Language Learning (CoNLL), pages 18\u201327", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "Conference on Learning Theory (COLT)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Jointly learning to parse and perceive: Connecting natural language to the physical world", "author": ["J. Krishnamurthy", "T. Kollar"], "venue": "Transactions of the Association for Computational Linguistics (TACL), 1:193\u2013206", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Weakly supervised training of semantic parsers", "author": ["J. Krishnamurthy", "T. Mitchell"], "venue": "Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 754\u2013765", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Using semantic unification to generate regular expressions from natural language", "author": ["N. Kushman", "R. Barzilay"], "venue": "Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL), pages 826\u2013836", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["T. Kwiatkowski", "E. Choi", "Y. Artzi", "L. Zettlemoyer"], "venue": "Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Inducing probabilistic CCG grammars from logical form with higher-order unification", "author": ["T. Kwiatkowski", "L. Zettlemoyer", "S. Goldwater", "M. Steedman"], "venue": "Empirical Methods in Natural Language Processing (EMNLP), pages 1223\u20131233", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Lambda dependency-based compositional semantics", "author": ["P. Liang"], "venue": "arXiv", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning dependency-based compositional semantics", "author": ["P. Liang", "M.I. Jordan", "D. Klein"], "venue": "Association  for Computational Linguistics (ACL), pages 590\u2013599", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Bringing machine learning and compositional semantics together", "author": ["P. Liang", "C. Potts"], "venue": "Annual Reviews of Linguistics, 1(1):355\u2013376", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "A joint model of language and perception for grounded attribute learning", "author": ["C. Matuszek", "N. FitzGerald", "L. Zettlemoyer", "L. Bo", "D. Fox"], "venue": "International Conference on Machine Learning (ICML), pages 1671\u20131678", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "A fully statistical approach to natural language interfaces", "author": ["S. Miller", "D. Stallard", "R. Bobrow", "R. Schwartz"], "venue": "Association for Computational Linguistics (ACL), pages 55\u201361", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1996}, {"title": "The proper treatment of quantification in ordinary English", "author": ["R. Montague"], "venue": "Approaches to Natural Language, pages 221\u2013242", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1973}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["P. Pasupat", "P. Liang"], "venue": "Association for Computational Linguistics (ACL)", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Large-scale semantic parsing without question-answer pairs", "author": ["S. Reddy", "M. Lapata", "M. Steedman"], "venue": "Transactions of the Association for Computational Linguistics (TACL), 2(10):377\u2013392", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "The Syntactic Process", "author": ["M. Steedman"], "venue": "MIT Press", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2000}, {"title": "Understanding natural language commands for robotic navigation and mobile manipulation", "author": ["S. Tellex", "T. Kollar", "S. Dickerson", "M.R. Walter", "A.G. Banerjee", "S.J. Teller", "N. Roy"], "venue": "Association for the Advancement of Artificial Intelligence (AAAI)", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2011}, {"title": "Building a semantic parser overnight", "author": ["Y. Wang", "J. Berant", "P. Liang"], "venue": "Association for Computational Linguistics (ACL)", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "International Conference on Learning Representations (ICLR)", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "Understanding Natural Language", "author": ["T. Winograd"], "venue": "Academic Press", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1972}, {"title": "Learning synchronous grammars for semantic parsing with lambda calculus", "author": ["Y.W. Wong", "R.J. Mooney"], "venue": "Association for Computational Linguistics (ACL), pages 960\u2013967", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2007}, {"title": "The lunar sciences natural language information system: Final report", "author": ["W.A. Woods", "R.M. Kaplan", "B.N. Webber"], "venue": "Technical report, BBN Report 2378, Bolt Beranek and Newman Inc.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1972}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["W. Yih", "M. Chang", "X. He", "J. Gao"], "venue": "Association for Computational Linguistics (ACL)", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["M. Zelle", "R.J. Mooney"], "venue": "Association for the Advancement of Artificial Intelligence (AAAI), pages 1050\u20131055", "citeRegEx": "36", "shortCiteRegEx": null, "year": 1996}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["L.S. Zettlemoyer", "M. Collins"], "venue": "Uncertainty in Artificial Intelligence (UAI), pages 658\u2013666", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2005}, {"title": "Online learning of relaxed CCG grammars for parsing to logical form", "author": ["L.S. Zettlemoyer", "M. Collins"], "venue": "Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 678\u2013687", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning context-dependent mappings from sentences to logical form", "author": ["L.S. Zettlemoyer", "M. Collins"], "venue": "Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP)", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2009}, {"title": "Type-driven incremental semantic parsing with polymorphism", "author": ["K. Zhao", "L. Huang"], "venue": "North American Association for Computational Linguistics (NAACL)", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 24, "context": "Semantic parsing is rooted in formal semantics, pioneered by logician Richard Montague [25], who famously argued that there is \u201cno important theoretical difference between natural languages and the artificial languages of logicians.", "startOffset": 87, "endOffset": 91}, {"referenceID": 33, "context": "Early examples included LUNAR, a natural language interface into a database about moon rocks [34], and SHRDLU, a system that could both answer questions and perform actions in a toy blocks world environment [32].", "startOffset": 93, "endOffset": 97}, {"referenceID": 31, "context": "Early examples included LUNAR, a natural language interface into a database about moon rocks [34], and SHRDLU, a system that could both answer questions and perform actions in a toy blocks world environment [32].", "startOffset": 207, "endOffset": 211}, {"referenceID": 9, "context": "Even question answering systems relied less on understanding and more on a shallower analysis coupled with a large collection of unstructured text documents [10], typified by the TREC competitions.", "startOffset": 157, "endOffset": 161}, {"referenceID": 35, "context": "The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19].", "startOffset": 95, "endOffset": 115}, {"referenceID": 23, "context": "The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19].", "startOffset": 95, "endOffset": 115}, {"referenceID": 32, "context": "The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19].", "startOffset": 95, "endOffset": 115}, {"referenceID": 36, "context": "The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19].", "startOffset": 95, "endOffset": 115}, {"referenceID": 18, "context": "The spirit of deep understanding was kept alive by researchers in statistical semantic parsing [36, 24, 33, 37, 19].", "startOffset": 95, "endOffset": 115}, {"referenceID": 12, "context": "The first is reducing the amount of supervision from annotated logical forms to answers [13, 21]:", "startOffset": 88, "endOffset": 96}, {"referenceID": 20, "context": "The first is reducing the amount of supervision from annotated logical forms to answers [13, 21]:", "startOffset": 88, "endOffset": 96}, {"referenceID": 20, "context": "This results in a more difficult learning problem, but [21] showed that it is possible to solve it without degrading accuracy.", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "Previous semantic parsers had only been trained on limited domains such as US geography, but the creation of broad-coverage knowledge bases such as Freebase [8] set the stage for a new generation of semantic parsers for question answering.", "startOffset": 157, "endOffset": 160}, {"referenceID": 10, "context": "Initial systems required annotated logical forms [11], but soon, systems became trainable from answers [4, 18, 5].", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "Initial systems required annotated logical forms [11], but soon, systems became trainable from answers [4, 18, 5].", "startOffset": 103, "endOffset": 113}, {"referenceID": 17, "context": "Initial systems required annotated logical forms [11], but soon, systems became trainable from answers [4, 18, 5].", "startOffset": 103, "endOffset": 113}, {"referenceID": 4, "context": "Initial systems required annotated logical forms [11], but soon, systems became trainable from answers [4, 18, 5].", "startOffset": 103, "endOffset": 113}, {"referenceID": 25, "context": "Semantic parsers have even been extended beyond fixed knowledge bases to semi-structured tables [26].", "startOffset": 96, "endOffset": 100}, {"referenceID": 28, "context": "[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.", "startOffset": 0, "endOffset": 7}, {"referenceID": 1, "context": "[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.", "startOffset": 0, "endOffset": 7}, {"referenceID": 22, "context": "[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.", "startOffset": 40, "endOffset": 48}, {"referenceID": 14, "context": "[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.", "startOffset": 40, "endOffset": 48}, {"referenceID": 16, "context": "[29, 2], identifying objects in a scene [23, 15], converting natural language to regular expressions [17], and many others.", "startOffset": 101, "endOffset": 105}, {"referenceID": 28, "context": "In a robotics application, x is a command, c represents the robot\u2019s environment, and y is the desired sequence of actions to be carried by the robot [29].", "startOffset": 149, "endOffset": 153}, {"referenceID": 9, "context": "(R1) prime \u21d2 NP[primes] (R2) 10 \u21d2 NP[10] (R3) less than NP[z] \u21d2 QP[(\u2212\u221e, z)] (R4) NP[z1] QP[z2] \u21d2 NP[z1 \u2229 z2] (R5) largest NP[z] \u21d2 NP[max(z)] (R6) largest NP[z] \u21d2 NP[min(z)] (R7) What is the NP[z]? \u21d2 ROOT[z]", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "NP[primes] NP[10]", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 130, "endOffset": 151}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 0, "context": "For example, define F = 7 features, each counting the number of times a given grammar rule is invoked in d, so that \u03c6(x, c, d1) = [1, 1, 1, 1, 1, 0, 1] and \u03c6(x, c, d2) = [1, 1, 1, 1, 0, 1, 1].", "startOffset": 170, "endOffset": 191}, {"referenceID": 6, "context": "[7] gives a detailed account on how first-order logic is used for natural language semantics.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "Another logical language, which can be viewed as syntactic sugar for lambda calculus, is lambda dependency-based semantics (DCS) [20].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "It is thus common to use applicationspecific logical forms, for example, regular expressions [17].", "startOffset": 93, "endOffset": 97}, {"referenceID": 27, "context": "One common approach to the grammar in semantic parsing is combinatory categorial grammar (CCG) [28], which had been developed extensively in linguistics before it was first used for semantic parsing [37].", "startOffset": 95, "endOffset": 99}, {"referenceID": 36, "context": "One common approach to the grammar in semantic parsing is combinatory categorial grammar (CCG) [28], which had been developed extensively in linguistics before it was first used for semantic parsing [37].", "startOffset": 199, "endOffset": 203}, {"referenceID": 9, "context": "f(x) \u2227 less(x, y) NP[10]", "startOffset": 20, "endOffset": 24}, {"referenceID": 37, "context": "It is common to use other combinators which both handle more complex linguistic phenomena such as NP coordination \u201cintegers that divide 2 or 3\u201d as well as ungrammatical language [38], although these issues can also be handled by having a more expansive lexicon [19].", "startOffset": 178, "endOffset": 182}, {"referenceID": 18, "context": "It is common to use other combinators which both handle more complex linguistic phenomena such as NP coordination \u201cintegers that divide 2 or 3\u201d as well as ungrammatical language [38], although these issues can also be handled by having a more expansive lexicon [19].", "startOffset": 261, "endOffset": 265}, {"referenceID": 9, "context": "N[prime] N|N[less] N[10]", "startOffset": 20, "endOffset": 24}, {"referenceID": 4, "context": "When the logical forms are simple and we have strong type constraints, this strategy can be quite effective [5, 30, 26].", "startOffset": 108, "endOffset": 119}, {"referenceID": 29, "context": "When the logical forms are simple and we have strong type constraints, this strategy can be quite effective [5, 30, 26].", "startOffset": 108, "endOffset": 119}, {"referenceID": 25, "context": "When the logical forms are simple and we have strong type constraints, this strategy can be quite effective [5, 30, 26].", "startOffset": 108, "endOffset": 119}, {"referenceID": 3, "context": "This way, the lexical mapping need not be learned from scratch using only the training data [4, 18].", "startOffset": 92, "endOffset": 99}, {"referenceID": 17, "context": "This way, the lexical mapping need not be learned from scratch using only the training data [4, 18].", "startOffset": 92, "endOffset": 99}, {"referenceID": 39, "context": "A solution is to use shift-reduce parsing rather than chart parsing [40].", "startOffset": 68, "endOffset": 72}, {"referenceID": 5, "context": "This motivates agenda-based parsing, in which derivations that are deemed more promising by the model are built first [6].", "startOffset": 118, "endOffset": 121}, {"referenceID": 36, "context": ", [paris \u21d2 ParisFrance]), dates, and numbers are generally assumed to be given [37], though we need not assume that these rules are perfect [21].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": ", [paris \u21d2 ParisFrance]), dates, and numbers are generally assumed to be given [37], though we need not assume that these rules are perfect [21].", "startOffset": 140, "endOffset": 144}, {"referenceID": 20, "context": "These rules are also often represented implicitly [21, 4].", "startOffset": 50, "endOffset": 57}, {"referenceID": 3, "context": "These rules are also often represented implicitly [21, 4].", "startOffset": 50, "endOffset": 57}, {"referenceID": 36, "context": "In [37], a procedure called GENLEX is used to generate candidate lexical rules from a utterance-logical form pair (x, z).", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "A more generic induction algorithm based on higher-order unification does not require any initial grammar [19].", "startOffset": 106, "endOffset": 110}, {"referenceID": 32, "context": "[33] use machine translation ideas to induce a synchronous grammar (which can also be used to generate utterances from logical forms).", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "In approaches that learn from denotations y [21, 4], an initial crude grammar is used to generate candidate logical forms, and rest of the work is done by the features.", "startOffset": 44, "endOffset": 51}, {"referenceID": 3, "context": "In approaches that learn from denotations y [21, 4], an initial crude grammar is used to generate candidate logical forms, and rest of the work is done by the features.", "startOffset": 44, "endOffset": 51}, {"referenceID": 21, "context": "As we discussed earlier, parameter estimation can be performed by stochastic gradient descent on the log-likelihood; similar objectives based on max-margin are also possible [22].", "startOffset": 174, "endOffset": 178}, {"referenceID": 4, "context": "It can be helpful to also add an L1 regularization term \u03bb\u2016\u03b8\u20161, which encourages feature weights to be zero, which produces a more compact model that generalizes better [5].", "startOffset": 168, "endOffset": 171}, {"referenceID": 13, "context": "In addition, one can use AdaGrad [14], which maintains a separate step size for each feature.", "startOffset": 33, "endOffset": 37}, {"referenceID": 35, "context": "The Geo880 dataset [36] drove nearly a decade of semantic parsing research.", "startOffset": 19, "endOffset": 23}, {"referenceID": 17, "context": "On this dataset, learning from logical forms [18] and answers [21] both achieve around 90%", "startOffset": 45, "endOffset": 49}, {"referenceID": 20, "context": "On this dataset, learning from logical forms [18] and answers [21] both achieve around 90%", "startOffset": 62, "endOffset": 66}, {"referenceID": 37, "context": "The ATIS-3 dataset [38] consists of 5418 utterances paired with logical forms (e.", "startOffset": 19, "endOffset": 23}, {"referenceID": 16, "context": "The Regexp824 dataset [17] consists of 824 natural language and regular expression pairs (e.", "startOffset": 22, "endOffset": 26}, {"referenceID": 16, "context": "[17] uses semantic unification to test for logical form equivalence and obtains 65.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "The Free917 dataset [11] consists of 917 examples of questionlogical form pairs that can be answered via Freebase, e.", "startOffset": 20, "endOffset": 24}, {"referenceID": 3, "context": "WebQuestions [4] is another dataset on Freebase consisting of 5810 question-answer pairs (no logical forms) such as \u201cwhat do australia call their money?\u201d Like Free917, the questions are not very compositional, but unlike Free917, they are real questions asked by people on the Web independent from Freebase, so they are more realistic and more varied.", "startOffset": 13, "endOffset": 16}, {"referenceID": 25, "context": "The goal of WikiTableQuestions [26] is to extend question answering beyond Freebase to HTML tables on Wikipedia, which are semi-structured.", "startOffset": 31, "endOffset": 35}, {"referenceID": 29, "context": "[30] proposed a new recipe for quickly using crowdsourcing to generate new compositional semantic parsing datasets consisting of question-logical form pairs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] introduced a dataset of 706 navigation instructions (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] obtained 65.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "One idea is to use general paraphrasing models to map input utterances to the \u201ccanonical utterances\u201d of logical forms [5, 30].", "startOffset": 118, "endOffset": 125}, {"referenceID": 29, "context": "One idea is to use general paraphrasing models to map input utterances to the \u201ccanonical utterances\u201d of logical forms [5, 30].", "startOffset": 118, "endOffset": 125}, {"referenceID": 17, "context": "One could also use domain-general logical forms that capture the basic predicate-argument structures of sentences [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 2, "context": "Abstract meaning representation (AMR) [3] is one popular representation backed by an extension linguistic annotation effort.", "startOffset": 38, "endOffset": 41}, {"referenceID": 0, "context": "Multiple AMR parsers have been developed, including one based on CCG [1].", "startOffset": 69, "endOffset": 72}, {"referenceID": 15, "context": "One can use a large corpus of text to exploit even weaker supervision [16, 27].", "startOffset": 70, "endOffset": 78}, {"referenceID": 26, "context": "One can use a large corpus of text to exploit even weaker supervision [16, 27].", "startOffset": 70, "endOffset": 78}, {"referenceID": 8, "context": "More generally, one can think about language interpretation in a reinforcement learning setting [9], where an agent who presented with an utterance in some context performs some action, and receives a corresponding reward signal.", "startOffset": 96, "endOffset": 99}, {"referenceID": 38, "context": "This framework highlights the importance of context-dependence in language interpretation [39, 2].", "startOffset": 90, "endOffset": 97}, {"referenceID": 1, "context": "This framework highlights the importance of context-dependence in language interpretation [39, 2].", "startOffset": 90, "endOffset": 97}, {"referenceID": 34, "context": "Due to their empirical success, there has been a recent surge of interest in using recurrent neural networks and their extensions for solving NLP tasks such as machine translation and question answering [35, 31].", "startOffset": 203, "endOffset": 211}, {"referenceID": 30, "context": "Due to their empirical success, there has been a recent surge of interest in using recurrent neural networks and their extensions for solving NLP tasks such as machine translation and question answering [35, 31].", "startOffset": 203, "endOffset": 211}], "year": 2016, "abstractText": "For building question answering systems and natural language interfaces, semantic parsing has emerged as an important and powerful paradigm. Semantic parsers map natural language into logical forms, the classic representation for many important linguistic phenomena. The modern twist is that we are interested in learning semantic parsers from data, which introduces a new layer of statistical and computational issues. This article lays out the components of a statistical semantic parser, highlighting the key challenges. We will see that semantic parsing is a rich fusion of the logical and the statistical world, and that this fusion will play an integral role in the future of natural language understanding systems.", "creator": "LaTeX with hyperref package"}}}