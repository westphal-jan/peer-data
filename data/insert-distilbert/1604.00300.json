{"id": "1604.00300", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2016", "title": "A SAT model to mine flexible sequences in transactional datasets", "abstract": "traditional pattern mining algorithms generally suffer from a lack of flexibility. in this aforementioned paper, we propose a sat formulation of the problem to successfully mine frequent flexible sequences ; occurring both in transactional datasets. our sat - based approach can easily be thoroughly extended with small extra constraints specified to address a broad range of pattern mining applications. to demonstrate verify this claim, we formulate and add several several constraints, such as gap and span constraints, respectively to our model in order to extract more specific patterns. yet we also use interactive solving to perform important derived tasks, such as dense closed pattern mining or maximal pattern mining. finally, together we prove the practical feasibility of our general sat model by running experiments on two real datasets.", "histories": [["v1", "Fri, 1 Apr 2016 15:49:51 GMT  (45kb,D)", "http://arxiv.org/abs/1604.00300v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["r\\'emi coletta", "benjamin negrevergne"], "accepted": false, "id": "1604.00300"}, "pdf": {"name": "1604.00300.pdf", "metadata": {"source": "CRF", "title": "A SAT model to mine flexible sequences in transactional datasets", "authors": ["Remi Coletta", "Benjamin Negrevergne"], "emails": ["coletta@lirmm.fr", "benjamin.negrevergne@inria.fr"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nPattern mining, now both an important research topic and a broadly-used analysis tool, aims at extracting recurring patterns in large datasets. Since seminal work by Agrawal and Srikant on frequent itemset mining [1], a large number of new pattern mining tasks have been proposed to extract more structured patterns, such as sequence, tree or graph patterns. While structured patterns are usually more informative, they are also harder to extract.\nThe sequence mining problem is a variation of the itemset mining problem, in which both transactions and patterns are ordered. Given a set of ordered transactions, the goal is to find all the sequences that are embedded in more than a given number of transactions. The complexity of the task stems from the fact that we allow sequences to be embedded in the transactions with variable-length gaps. See Figure 1 for an illustration.\nThis problem has been given multiple names in the literature: depending on the application, it has been called\nSequence mining, as well as other pattern mining tasks, was first developped by writing algorithms in classical imperative languages such as C or C++. In order to handle large datasets, most of these algorithms were optimized for specific mining applications. As a result, they are unable to capture small variations. This is a major drawback for users, whose needs may substantially vary from one application to the other. For example, text analysts generally have grammar constraints, whereas biologists usually require very specific, per-character constraints.\nTo solve this problem, Guns et al. in [4] have recently proposed using CP modeling techniques and CP solvers to address various itemset mining tasks. In contrast with imperative programs, CP models can easily be extended to efficiently perform a variety of specific mining tasks, while remaining more or less performant on the basic mining task. However, to date, most of the published works have focused on modeling and solving set-based structures, which are natively supported by solvers or easy to encode as boolean vectors. Nevertheless, the question of the usability of ... needs to be further examined. Whether the same solvers can be used to mine more structured patterns, such as sequences, trees or graphs using generic solvers, remains an open question.\na) Contribution of this paper: In this paper, we demonstrate that the sequence mining problem can be expressed as a purely boolean SAT formula, and solved using off-the-shelf SAT solvers.\nTo extend the basic problem and address more specific needs, we formulate several constraints commonly used in sequence mining. We show how these additional constraints can be easily incorporated into our SAT formula and without previous SAT knowledge. This is a critical benefit for users, who can now arbitrarily combine sets of constraints without concern for the soundness of their results. In addition, our experiments on real datasets establish that, contrary to specialized algorithms, SAT solvers take advantage of these\nar X\niv :1\n60 4.\n00 30\n0v 1\n[ cs\nnew constraints to further prune the search space and increase efficiency.\nLastly, we demonstrate that, in addition to enumerating all frequent sequences, our model also allows us to perform important derived mining tasks such as the closed pattern and the maximal pattern mining tasks using interactive solving. These two tasks aim to reduce redundancy among result sets and have been extensively studied in the pattern mining community.\nThe remainder of this paper is organized as follows: we formally state the problem in Section II. We then present our SAT model to mine flexible sequences in Section III and formulate several user constraints in Section IV. We propose our solution to mine maximal and closed patterns in Section V, and present our experiments in Section VI. Finally, we discuss related work in Section VII and offer our conclusions in Section VIII."}, {"heading": "II. FREQUENT SEQUENCE MINING: FORMAL PROBLEM", "text": "STATEMENT\nGiven: 1) a vocabulary V : {v0, . . . , v|V |} 2) a set of transactions T = {T1, . . . , T|T |} where each\ntransaction Ti is a sequence of characters in V ; we use the projection notation Ti[j] to denote the jth character of the transaction Ti; and 3) a minimum frequency threshold minsup, the sequence mining problem consists in enumerating all the sequences that are embedded in at least minsup transactions.\nIn the standard sequence mining problem, we say that a sequence S of n characters is embedded in a transaction T if there exist j1, . . . , jn integers such that:\nj1 < . . . < jn,\u2200i \u2208 1, . . . , n s.t. S[i] = T [ji]\nThe list of positions e = (j1, . . . , jn) is called an embedding. To express that e is an embedding of S in T , we note S ve T . We also note S v T if there exists at least one embedding e such that S ve T .\nWe now define the coverage of a sequence S as the set of transactions for which there exists an embedding of S:\ncover(S, T ) = {Ti \u2208 T : S v Ti}\nUsing these notations, the problem of mining all frequent sequences in a set of transactions can be formalized as follows: Given a vocabulary V , a set of transactions T and a minimum threshold minsup, enumerate all sequences S such that:\n|cover(S, T )| \u2265 minsup"}, {"heading": "III. SAT ENCODING OF THE BASE MODEL", "text": "In this section, we present the variables and constraints of our SAT model. We then show how to slightly modify the SAT solver in order to generate all the frequent sequences.\nA. Variables\nIn frequent sequence mining, patterns (i.e., frequent sequences) can have varied lengths, whereas constraint-based solvers usually require a fixed number of variables. Therefore, one must first compute an upper bound for the size of the patterns. Obviously, a pattern cannot be longer than the longest transaction, but we may compute a tighter bound: to be frequent, a pattern has to be covered by at least minsup transactions. Therefore, the maximal size K of a pattern is the size of the minsup longest transactions in T . We then define every possible pattern S as a sequence of exactly K characters and introduce an extra character in the vocabulary V to encode shorter patterns. V = V \u222a { }. For example, if K = 4, the pattern ab will be represented as S = ab .\nWe can now build our formulation around 3 sets of variables: the m, c and t variables. See Figure 2.\nm variables: For each position k \u2264 K in the pattern S and for each character v of the vocabulary V , we introduce a literal mk,v , which is true if and only if the kth character of the pattern is equal to v:\nmk,v = > \u21d4 S[k] = v\nc variables: For each transaction Ti, we add a literal ci, which is true only if the transaction Ti is covered by the pattern:\nci = > \u21d2 S v Ti t variables: For each transaction Ti, for each position j in Ti and for each position k \u2264 j in S, we add a literal ti,j,k, which is true if the jth character of the transaction Ti is used as support for the kth character of S. If ci = >, there exists, by definition an embedding e such that S ve Ti. If S ve Ti then ti,j,k = > only if e[k] = j.\nti,j,k = > \u2227 S ve Ti \u21d2 e[k] = j\nNote that we use an implication rather than an equivalence because there may be multiple matches for the character S[k] in the transaction Ti. In Section ??, we explain how extra user constraints prevent us from selecting matches a priori."}, {"heading": "B. Constraints", "text": "b) Well-formed pattern: The two following constraints encode the fact that each position k in the pattern can only be assigned exactly one character from the vocabulary. Constraint (1) imposes that at least one character is assigned per position\nsince constraint (2) imposes that at the most one character is assigned per position:\n\u2200k \u2208 1..K, (mk, \u2228mk,1 \u2228 . . . \u2228mk,|V |) (1)\n\u2200k \u2208 1..K, \u2200v \u2208 1..V -1, \u2200v\u2032 \u2208 v+1..V, (mk,v \u2228mk,v\u2032) (2)\nTo avoid pattern symmetries, we discard every solution in which at least one character does not appear at the end of the sequence. In other words, we forbid solutions in which is followed by any character c \u2208 V \\ { }.\n\u2200k \u2208 1..K-1, (mk, \u2228mk+1, ) (3) c) Support compatibility: This constraint imposes that positions in the pattern can only be mapped to the positions in the transaction if the characters are equal.\n\u2200i \u2208 1..|T |,\u2200j \u2208 1..|Ti|, \u2200k \u2208 1..i (ti,j,k \u2228mk,v), where v = Ti[j] (4)\nd) Coverage constraint: For each transaction Ti, S ve Ti is covered by the pattern (ci = >) only if, for each position k of the pattern, either S[k] = (mk, = >) or there exists a position j such that e[k] = j.\n\u2200i \u2208 1..n,\u2200k \u2208 1..K-1, (ci \u2228mk, \u2228 ti,k,k \u2228 . . . \u2228 ti,|Ti|,k) (5)\nTo avoid symmetries in embeddings, each character in the pattern can match only once in the transaction.\n\u2200i \u2208 1..n, \u2200k \u2208 1..K-1, \u2200j \u2208 1..|Ti|-1,\u2200j\u2032 \u2208 j+1..|Ti|, (ti,j,k \u2228 ti,j\u2032,k) (6)\ne) Order preservation constraint: For each transaction Ti, for each position k of the pattern, position j is a valid support for S[k] (ti,j,k = >) only if it exists k \u2212 1 \u2264 j\u2032 < j s.t. position j\u2032 is a valid support for S[k\u2212 1] (ti,j\u2032,k\u22121 = >):\n\u2200i \u2208 1..n, \u2200j \u2208 1..|Ti|,\u2200k \u2208 1..j, (ti,j,k \u2228 ti,k\u22121,k\u22121 \u2228 ti,k,k\u22121 \u2228 . . . \u2228 ti,j\u22121,k\u22121) (7)\nf) Cardinality constraint: The last constraint of the sequence mining problem is the minimum frequency threshold minsup. To ensure that pattern S is frequent enough, we need to encode the requirement that at least minsup transactions Ti \u2208 T are covered (ci = >).\natLeast(minsup, [c1, . . . , c|T |]) (8)\nThis constraint appears in numerous industrial applications, and several decompositions in CNF have been proposed in the literature. Bailleux and Boufkhad [5] proposed a network-based decomposition using O(|T |.log2(|T |)) extra literals. This number of extra literals was later reduced to O(|T |.log2(minsup)) in [6], and proved optimal. More recently, Abio and Stuckey [7] have proposed a technique to improve the efficiency of the cardinality constraint, by taking into account two tricky internal mechanisms of a CDCL SAT solver. Specifically, the authors suggested using the\nexplanation of conflicts and the activity of variables after the restarts. However, in some variants of our problems (presented in Section IV), the cardinality between minsup and |T | must be preserved. And because of the logarithmic formulation, there is no simple way to express sub-cardinalities in these approaches. We therefore used the formulation initially proposed by Coquery et al. in [8]. Although this decomposition involves more variables O(|T |2), it allows the simple expression of cardinality. Indeed, when building the decomposition for |T |, we obtain a literal cardt per value t \u2208 minsup..|T |, stating that if cardt is true, there exist at least t literals among c1, . . . , c|T | which are true."}, {"heading": "C. Solving", "text": "We solve our SAT formula using the Glucose CDCL solver [9]. Truc et Machin have shown in [10] that branching over decision variables confuses the clause-learning system and ultimately reduces the solving performances. Therefore, we do not provide any hint for the search strategy and use the solver as a black box.\nEach model of our SAT formula (i.e., each solution) is a frequent sequence of the input dataset. As a result, outputting all the frequent sequences can be done by enumerating all the models that satisfy the formula.\nAlgorithm 1: COMPUTE ALL FREQUENT PATTERNS 1 while F is solvable do 2 model\u2190 nextModel(F ) 3 F \u2190 F \u2227 ( \u2228 mk,v s.t. model[mk,v] = > \u2227 v 6= )\nHowever, more specifically, only the literals mk,v of the model correspond to a frequent sequence; indeed, literals ci represent the set of covered transactions, and literals ti,j,k an embedding of this sequence in each covered transaction. Since each covered transaction may have several embeddings, the number of solutions for our SAT formula may be exponentially larger than the number of frequent sequences.\nTo eliminate this potential issue, we propose Algorithm 1 as a simple way to enumerate all the models: we first solve the formula and find a model (line 2); we then restrict the model to literals encoding the frequent sequence, and subsequently post the negation of the restricted model as a new clause (line 3). The process is repeated until no additional model can be found (line 1)."}, {"heading": "IV. EXTENDING THE MODEL WITH USER CONSTRAINTS", "text": "Enumerating all frequent sequences may yield an overwhelming number of sequences. (See second column in Table II.) Some of them may be deemed redundant and/or irrelevant by the user. In this section, we formulate various user constraints that can be added to the base model in order to extract fewer and more specific sequences. The following is not an exhaustive list of useful user constraints, but rather a series of examples that demonstrate the flexibility of the SAT formulation."}, {"heading": "A. Constraints on the way a pattern is embedded", "text": "g) Sequence mining with maximum gap constraint: With the maximum gap constraint, transactions are covered only if the characters of the sequence occur in the transaction with a gap of at most \u03b3 characters. We define the max-gap predicate over an embedding e = (k1, . . . , kn) as follows:\nmax-gap\u03b3(e) \u2261 \u2200i \u2208 1 . . . n-1, (ki+1 \u2212 ki) \u2264 \u03b3 (9)\nTo expand the standard sequence mining problem with this constraint, we only have to append the following constraint to the formula.\nThis constraint imposes that the distance between indices j and j\u2032 of ti,j,k and ti,j\u2032,k is smaller than \u03b3:\n(ti,j,k \u2228 ti,max(k\u22121,j\u2212\u03b3),k\u22121 \u2228 . . . \u2228 ti,j\u22121,k\u22121) (10)\nh) Remark on the gap constraint: Due to its usefulness, the gap constraint has already been implemented in LCMseq algorithms [11]. Unfortunately, though correct, this implementation is not complete. The gap constraint seems to be checked only on the first embedding of the sequence in each transaction. We illustrate this shortcoming with the following dataset, using minsup = 2 and max-gap = 2: T1 : ACCBAB T2 : AB In this dataset, LCMseq is unable to find AB as a frequent sequence because the first embedding of AB in T1 (A1B6) does not satisfy the gap constraint.\nIndeed, counting all the transactions that contain at least one embedding satisfying the gap constraint (as formulated in Equation 9) requires a more complex algorithm.This short example points out the difficulty to integrate extra constraints in a traditionnal mining algorithms.\nIn contrast, our approach, based on an SAT solver, tackles this issue in a sound and complete way.\ni) Sequence mining with dependent gap constraint: With the generalized gap constraint, transactions are covered only if the two consecutive sequence characters occur in the transaction separated by a gap depending on the position in the sequence and/or the character preceding the gap. More formally, given a function gap : (K \u00d7V )\u2192 [1..l] , we define the gen-gap predicate over an embedding e = (k1, . . . , kn) as follows:\ngen-gapgap(e) \u2261 \u2200i \u2208 1 . . . n-1, (ki+1 \u2212 ki) \u2264 gap(i, S[i])\nThis constraint may be enforced by the following clause:\n(ti,j,k \u2228 (mk,v \u2228 ti,max(k\u22121,j\u2212gap(k,v)),k\u22121 \u2228 . . . \u2228 ti,j\u22121,k\u22121)\nj) Sequence mining with maximum span constraint: With the maximum span constraint, transactions are covered only if the first and last characters of the sequence occur in the transaction separated by at most \u03b3 characters. More formally, we define the max-span predicate over an embedding e = (k1, . . . , kn) as follows:\nmax-span\u03b3(e) \u2261 \u2200i \u2208 1 . . . n-1, (kn \u2212 k1) \u2264 \u03b3\nTo encode this constraint, we define two additional literals per character in each transaction: fi,j points to the position of the support for the first character of S, and ui,j is true for each position j in the transaction Ti between the support for the first and the last character of S. fi,j and ui,j are subjected to the following constraints: \u2200i \u2208 1..|T |, \u2200j \u2208 1..|Ti|, (ti,j,0 \u2228 fi,j) \u2227 (ti,j,0 \u2228 fi,j) (i) \u2200i \u2208 1..|T |, \u2200j \u2208 1..|Ti|, \u2200k \u2208 1..j(ti,j,k \u2228 fi,j) (ii) \u2200i \u2208 1..|T |, \u2200j \u2208 1..|Ti|, (ui,j \u2228 fi,j \u2228 ui,j\u22121 (iii) \u2200i \u2208 1..|T |, \u2200j \u2208 1..|Ti| \u2212 span, (ci \u2228 ui,j \u2228 ui,j+span) (iv)\nClauses (i) ensure that if Ti[j] is used as the support for the first position of sequence (ti,j,0 = >), then is marked as the first support fi,j = >; clauses (ii) mark any position k in the sequence (\u2200ti,j,k = >, we have ui,j = >); clauses (iii) enforces positions i\u2032, which are not used as a support themselves but located between the first support fi,j and support and another support, to also satisfy ui\u2032,j . Finally, (iv) enforces a gap of at most span characters between the support of the first and the last character of S."}, {"heading": "B. Constraints over the pattern itself", "text": "In many application fields, interesting sequences can be distinguished from irrelevant ones by specifying syntactic constraints on the pattern itself. For example, the authors of [12] designed an algorithm to mine frequent sequences that satisfy regular expressions specified by the user. The resulting algorithm is applied to biological datasets.\nWe now explain how to address this type of constraint in our SAT formulation. In [13], Pesant proposed the regular global constraint for CP systems. Indeed, this constraint is satisfied if a sequence of values belongs to a given regular language. More recently, in [14], [15], the authors extended this work to the context-free languages with the introduction of grammar global constraints. Furthermore, Quimper and Walsh [16] and by Katsirelos et al. [17] have shown how to decompose regular and grammar constraints into SAT formulae. Based on their work, we can easily incorportate expression and grammar constraints into our SAT formulation."}, {"heading": "V. MAXIMAL AND CLOSED PATTERN MINING", "text": "In our SAT formulation and in other CP/SAT formulations of pattern mining problems (e.g., [4]), each solution represents a pattern. Usually, in classical SAT or CP applications, satisfiability (i.e., finding one solution only) is the main concern. Conversely, pattern mining users are not interested in finding a single solution, but multiples ones. In Section III-C, we showed how to enumerate all the solutions with minor modifications in the SAT solver.\nHowever, the set of all patterns is usually highly redundant. To overcome this issue, condensed representations were introduced. For example, closed pattern mining [18] aims at extracting a subset of patterns from which it is possible to derive all other patterns. Machin et Truc [19] later showed that expressing closedness as a constraint can lead to ambiguous problem definition. In this section, we address closed and maximal pattern mining [20] by using interactive SAT solving.\nk) Closed sequence mining: This was first introduced by Pasquier et al. for itemset mining ([18]).\nGiven the frequent sequence S = v1v2 . . . vn, we say that S is closed if there is no character v\u2032 such that S\u2032 = v1v2 . . . vnv\u2032 has the same coverage.\nclosed(S, T ) \u2261\n@v\u2032 \u2208 V s.t. cover(S, T ) = cover(Sv\u2032, T )\nIn our base formulation, constraints 4 and 7 prevent the validity of supports ti,j,k due to the compatibility and the order of supports. Then, constraint 5 prevents the ci from being satisfied, due to the validity of supports ti,j,k (ci only appears as a negative literal). The only constraint that mandates that ci be satisfied is the frequency constraint 8. As a result, given a pattern S, if |cover(S, T )| > minsup, there may exist transactions Ti such that S v Ti but ci = \u22a5. This is captured by the definition of ci given in Section III. Unfortunately, the definition of closed(S) requires the maximization of |cover(S, T )|, which would only be possible if we had ci = > \u21d4 S v Ti instead of ci = > \u21d2 S v Ti. However, coverage, order preservation and other user-defined constraints (see Sections IV-B and IV-A) only impose restrictions on supports. Having ci = > \u21d4 S v Ti would require that we combine the negation of each of these constraints, then build a DNF; this would result in an exponential number of clauses.\nTo avoid this constraint negation requirement, we now propose to use the incremental SAT solving paradigm [21]. Algorithm 2 performs several calls to the SAT solver of formulae sharing the same set of clauses, but with a different set of assumptions.\nThe main advantage of SAT solving under assumptions is that the clauses learned during a solving procedure under a given set of assumptions are kept for later solving. The learned clauses are removed only if they involve a literal that occurs in an assumption that is also removed.\nSince nested loops (lines 1 and 2) ensure that for any pair of patterns S1 and S2 found, with S1 found before S2, we have either covers(S1, T ) \u2282 covers(S2, T ) or covers(S1, T ) = covers(S2, T ) and |S1| \u2265 |S2|. For each pattern S found, line 4 adds no-goods corresponding to each subsequence S\u2032 v S to avoid generating S\u2032 in a future resolution.\nAlgorithm 2: COMPUTE ALL CLOSED PATTERNS Stack : A\u2190 {cardminsup+1, . . . , card|T |}\n1 do Stack : A\u2032 \u2190 {m1, , . . . ,mK, }; 2 do 3 while F is solvable under assumption(A \u2227A\u2032) do model\u2190 nextModel(F ); 4 foreach pattern \u2208 P(mk,v s.t. model[mk,v ] =\n> and v 6= }) do F \u2190 F \u2227 ( \u2228 mk,v\u2208pattern mk,v \u2228m|pattern|, )\nA\u2032.pop() while A\u2032 6= \u2205; A.pop()\nwhile A 6= \u2205;\nl) Maximal sequence mining: Mining maximal sequences aims to extract only the largest sequences that remain frequent. This further reduces the number of generated sequences, but the set of all frequent sequences cannot be derived from the set of maximal sequences.\nmaximal(S, T ) \u2261\n@v\u2032 \u2208 V s.t. |cover(S.v\u2032, T )| \u2265 minsup\nWe address the problem of finding maximal sequences with a minor modification in Algorithm 2 by only removing the external loop; indeed, we are not concerned with maximizing the number of supported transactions as we were for closed patterns."}, {"heading": "VI. EXPERIMENTS", "text": "After presenting our experimental setting in Section VI-A, we now compare our approach to specialized algorithms designed to mine closed frequent sequences. Subsequently, we demonstrate, that unlike specialized algorithms, our SATbased approach is able to take advantage of extra constraints to further prune the search space."}, {"heading": "A. Experimental setting", "text": "We run our experiments on two real datasets called Gazelle and JMLR. Gazelle is a dataset of web clicks data, in which each transaction represents the sequence of page views by a single user. JMLR consists in a set of paper abstracts from the Journal of Machine Learning Research in which each transaction is the abstract of a publication. Both datasets were previously used to evaluate sequence mining algorithms, for example in [22] or in [3]. Since our approach is currently unable to tackle the entire datasets, we derive smaller datasets by taking the first n transactions. For example, the JMLR500 dataset consists of the 500 first transactions of JMLR. This approach is preferable to synthetic datasets, which usually exhibit very different properties than real datasets. As shown in Table I, the properties of JMLR-500 and Gazelle-500 are similar to the ones of JMLR and Gazelle respectively.\nWhen the frequency threshold is lower, the number of sequences to enumerate is larger. To solve our SAT formulation, we use the Glucose[9] SAT solver modified as explained in Algorithm 2. We only mine for closed sequences, since nonclosed sequences can be derived from closed ones. We run all our experiments on a Linux host with an Intel Core i7-2600 CPU at 3.40GHz and 16 GiB of memory."}, {"heading": "B. Enumerating all closed frequent sequences", "text": "Specialized algorithms such as LCMseq [11] or Bide [22] have been designed to efficiently enumerate all closed frequent sequences. Run times for these algorithms are presented in Table II.\nOur SAT-based approach does not purport to be faster than algorithms designed and optimized specifically for this basic task. Even then, it is worth noting that the number of closed frequent sequences grows quickly and makes the manual interpretation of the results almost impossible. (See Table II, second column). In this case, reducing the number of results by adding constraints is the only option offered to the user.\nIn some cases, post-processing the set of closed frequent sequences may be an alternative to using our constraintbased sequence mining framework. However, this option is not always available, and, when available, not always efficient.\nFor example, post-processing the pattern set in order to eliminate all the sequences that do not satisfy a max-gap constraint is non-trivial: one needs to compute all the embeddings in the input dataset, and then check whether there exists one embedding satisfying the max-gap constraint. Since the number of embeddings for a pattern is combinatorial with the number of valid matches for each character, there is no guarantee that this can be done in a reasonable amount of time.\nFurthermore, the set of closed frequent sequences is not guaranteed to be a superset of closed frequent sequences satisfying a given constraint. As pointed by [19], this is true only for anti-monotonic constraints. In short, a frequent pattern that is not closed may become closed if a constraint discards its closed superset from the solution set. In this case, post-processing is simply impossible and existing sequence algorithms cannot be used."}, {"heading": "C. Solving sequence mining with extra user constraints", "text": "Next, we demonstrate that, unlike specialized algorithms, the SAT solver is able take advantage of extra user constraints to reduce mining time. To do so, we compare run times based on various constraints:\n\u2022 max-gap and max-span constraints, which regulate the embedding of sequences in the transactions; \u2022 regular constraints: for example, in the JMLR dataset, we extract the sequences matching the regular expression:\n\u201d?machine ? learning?\u201d1; \u2022 a combination of the above constraints.\nThe total run times are presented in Figure 3 for JMLR-500 and Figure 5 for Gazelle-500.\nIt is important to note that, from the solver\u2019s point of view, adding constraints harden the problem but also reduces the number of required solver calls (Algorithm 1, line 3). In order to demonstrate that each individual call to the solver performs faster, we also measure the average solving time per run. The average solving times are presented in Figure 4 for JMLR-500 and Figure 6 for Gazelle-500.\nWe first observe that, on JMLR-500, the gap constraint is very effective at reducing the total run time and the average solving time. However, on Gazelle-500, the gap and the span constraints have low impact. Indeed, the vast majority of sequences in Gazelle-500 are very small in size (c.f. Table I). As a consequence, gap and span constraints do not reduce the number of solutions. Clearly, however, the addition of extra constraints does not negatively impact performance.\n1 Note this very simple regular constraint only make sense when they are combined with other constraints such as gap constraints. Otherwise a simple pre-processing removing all the transactions not containing the characters would be sufficient.\nThe combination of the regular constraints with the 2-gap constraints is very effective, allowing the solver to drastically reduce mining times."}, {"heading": "VII. RELATED WORK", "text": "Research on sequence mining was initiated by Agrawal et al.[23], who proposed an Apriori-derived algorithm to mine frequent sequences of itemsets (as opposed to mining frequent sequences of single characters, which is the issue that we address in this paper). The problem of mining sequences of single characters was introduced by Mannila et al. in [24] as the problem of serial episode mining. The authors proposed an Apriori-based algorithm with a depth-first search strategy. However, depth-first search level wise pattern mining algorithms usually require great memory capacity, because of the need to store all the patterns of size n before enumerating patterns of size n+1. An important improvement was therefore proposed by Wang et al. in [22] with the first depth-first search BIDE algorithm. In addition, these authors proposed a definition of closed patterns for sequence mining. The techniques introduced by BIDE enabled it to perform faster and to lower memory requirements by several orders of magnitude.\nAttempts to improve the flexibility of existing sequence mining algorithms have been few. In [12], the authors mine sequences that satisfy a regular expression. The LCMseq algorithm ([11]) also deserves mention: It was extended by its authors to address different variations of the sequence mining task, such as maximal sequences and sequences with gap constraints. Unfortunatelly, it was proven incorrect (Section IV). Moreover, the above approaches for mining sequences with extra user constraints suffer from an important limitation: they can only support a small set of built-in constraints, and they fail to propose a general framework for the addition of extra constraints.\nA more flexible approach was proposed by Guns et al. ([4]). In their work, these authors demonstrated that CP solvers and CP modeling techniques can be used to efficiently address various types of itemset mining problems. Since then, data mining and SAT/CP experts have obtained more results in the same vein. For example, Metivier et al. have proposed a constraint-based language for itemset mining ([25]). More recently, in [8], Coquerry et al. have proposed to perform simple sequence mining tasks using a SAT formulation.To the best of our knowledge, this represents the first attempt to address the sequence mining problem with the use of a SAT solver. However, this formulation is based on a set encoding of sequences proposed by Arimura and Uno ([26]) and cannot be extended to more complex mining tasks such as flexible sequences."}, {"heading": "VIII. CONCLUSION & PERSPECTIVES", "text": "In this paper, we first proposed SAT encoding to adress the sequence mining problem. Second, we formulated several constraints, such as gap or span constraints, which are relevant to mining in various application fields. third, we proposed a sound methodology for addressing complex mining tasks, such as closed and maximal pattern mining. Further, we implemented this methodology with the Glucose SAT solver using interactive SAT solving.\nTo date, while state-of-the-art sequence mining algorithms are faster at generating all the frequent sequences, this approach is not scalable: since the number of sequences grows exponentially with the size of the dataset, unconstrained mining of sequences is bound to intractability. Our study and our experiments not only demonstrate the feasibility of using SAT for solving sequence mining problems, but also highlight several important benefits for data-mining users, including the ability to combine any arbitrary constraints.\nIn [27], the authors showed that highly optimized pattern mining algorithms are inherently difficult to parallelize due to the large number of instances of memory access. Using a SAT solver to tackle mining problems is a very different approach involving different algorithmic behavior and memory access patterns. Studying how our SAT-based approach may resolve the memory access problem presents an interesting research challenge."}], "references": [{"title": "Fast algorithms for mining association rules in large database", "author": ["R. Agrawal", "R. Srikant"], "venue": "VLDB, vol. 1215, 1994, pp. 487\u2013499.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "An efficient, versatile and scalable pattern growth approach to mine frequent patterns in unaligned protein sequences", "author": ["K. Ye", "W.A. Kosters", "A.P. IJzerman"], "venue": "Bioinformatics, vol. 23, no. 6, pp. 687\u2013693, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "The long and the short of it: summarising event sequences with serial episodes", "author": ["N. Tatti", "J. Vreeken"], "venue": "KDD, 2012, pp. 462\u2013470.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Constraint programming for itemset mining", "author": ["L.D. Raedt", "T. Guns", "S. Nijssen"], "venue": "KDD, 2008, pp. 204\u2013212.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient cnf encoding of boolean cardinality constraints", "author": ["O. Bailleux", "Y. Boufkhad"], "venue": "CP, 2003, pp. 108\u2013122.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Towards an optimal cnf encoding of boolean cardinality constraints", "author": ["C. Sinz"], "venue": "CP, 2005, pp. 827\u2013831.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Conflict directed lazy decomposition", "author": ["I. Ab\u0131\u0301o", "P.J. Stuckey"], "venue": "CP, 2012, pp. 70\u201385.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "A sat-based approach for discovering frequent, closed and maximal patterns in a sequence", "author": ["E. Coquery", "S. Jabbour", "L. Sa\u0131\u0308s", "Y. Salhi"], "venue": "ECAI, 2012, pp. 258\u2013263.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Predicting learnt clauses quality in modern sat solvers", "author": ["G. Audemard", "L. Simon"], "venue": "IJCAI, 2009, pp. 399\u2013404.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Dependent and independent variables in propositional satisfiability", "author": ["E. Giunchiglia", "M. Maratea", "A. Tacchella"], "venue": "JELIA, 2002, pp. 296\u2013307.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2002}, {"title": "Efficient serial episode mining with minimal occurrences.", "author": ["H. Ohtani", "T. Kida", "T. Uno", "H. Arimura"], "venue": "ICUIMC,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "A framework for frequent sequence mining under generalized regular expression constraints", "author": ["H. Albert-Lorincz", "J.-F. Boulicaut"], "venue": "Workshop on Knowledge Discovery in Inductive Databases (KDID- 2003), 2003, p. 2.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "A regular language membership constraint for finite sequences of variables", "author": ["G. Pesant"], "venue": "CP, 2004, pp. 482\u2013495.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "Global grammar constraints", "author": ["C.-G. Quimper", "T. Walsh"], "venue": "CP, ser. Lecture Notes in Computer Science, F. Benhamou, Ed., vol. 4204. Springer, 2006, pp. 751\u2013755.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2006}, {"title": "The theory of grammar constraints", "author": ["M. Sellmann"], "venue": "CP, ser. Lecture Notes in Computer Science, F. Benhamou, Ed., vol. 4204. Springer, 2006, pp. 530\u2013544.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Decompositions of grammar constraints", "author": ["C.-G. Quimper", "T. Walsh"], "venue": "AAAI, D. Fox and C. P. Gomes, Eds. AAAI Press, 2008, pp. 1567\u2013 1570.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2008}, {"title": "Reformulating global grammar constraints", "author": ["G. Katsirelos", "N. Narodytska", "T. Walsh"], "venue": "CPAIOR, 2009, pp. 132\u2013147.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2009}, {"title": "Discovering frequent closed itemsets for association rules", "author": ["N. Pasquier", "Y. Bastide", "R. Taouil", "L. Lakhal"], "venue": "ICDT99, pp. 398\u2013416, 1999.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "On closed constrained frequent pattern mining", "author": ["F. Bonchi", "C. Lucchese"], "venue": "ICDM. IEEE, 2004, pp. 35\u201342.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficiently mining long patterns from databases", "author": ["R. Bayardo"], "venue": "ACM SIGMOD, 1998, pp. 85\u201393.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Efficient sat solving under assumptions", "author": ["A. Nadel", "V. Ryvchin"], "venue": "SAT, A. Cimatti and R. Sebastiani, Eds., 2012, pp. 242\u2013255.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2012}, {"title": "Bide: Efficient mining of frequent closed sequences", "author": ["J. Wang", "J. Han"], "venue": "ICDE. IEEE, 2004, pp. 79\u201390.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2004}, {"title": "Mining sequential patterns", "author": ["R. Agrawal", "R. Srikant"], "venue": "ICDE. IEEE, 1995, pp. 3\u201314.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1995}, {"title": "Discovery of frequent episodes in event sequences", "author": ["H. Mannila", "H. Toivonen", "A. Inkeri Verkamo"], "venue": "DMKD, vol. 1, no. 3, pp. 259\u2013289, 1997.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1997}, {"title": "A constraint-based language for declarative pattern discovery", "author": ["J. Metivier", "P. Boizumault", "B. Cr\u00e9milleux", "M. Khiari", "S. Loudni"], "venue": "Data Mining Workshops (ICDMW). IEEE, 2011, pp. 1112\u20131119.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Polynomial-delay and polynomial-space algorithms for mining closed sequences, graphs, and pictures in accessible set systems", "author": ["H. Arimura", "T. Uno"], "venue": "ICDM, 2009, pp. 1087\u20131098.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Para miner: a generic pattern mining algorithm for multi-core architectures", "author": ["B. Negrevergne", "A. Termier", "M.-C. Rousset", "J.-F. M\u00e9haut"], "venue": "Data Mining and Knowledge Discovery, pp. 1\u201341, 2013.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "Principles and Practice of Constraint Programming - CP", "author": ["F. Benhamou", "Ed"], "venue": "Proceedings, ser. Lecture Notes in Computer Science,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Since seminal work by Agrawal and Srikant on frequent itemset mining [1], a large number of new pattern mining tasks have been proposed to extract more structured patterns, such as sequence, tree or graph patterns.", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": ",[2]).", "startOffset": 1, "endOffset": 4}, {"referenceID": 2, "context": ",[3]).", "startOffset": 1, "endOffset": 4}, {"referenceID": 3, "context": "in [4] have recently proposed using CP modeling techniques and CP solvers to address various itemset mining tasks.", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "Bailleux and Boufkhad [5] proposed a network-based decomposition using O(|T |.", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "log(minsup)) in [6], and proved optimal.", "startOffset": 16, "endOffset": 19}, {"referenceID": 6, "context": "More recently, Abio and Stuckey [7] have proposed a technique to improve the efficiency of the cardinality constraint, by taking into account two tricky internal mechanisms of a CDCL SAT solver.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "in [8].", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": "We solve our SAT formula using the Glucose CDCL solver [9].", "startOffset": 55, "endOffset": 58}, {"referenceID": 9, "context": "Truc et Machin have shown in [10] that branching over decision variables confuses the clause-learning system and ultimately reduces the solving performances.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "h) Remark on the gap constraint: Due to its usefulness, the gap constraint has already been implemented in LCMseq algorithms [11].", "startOffset": 125, "endOffset": 129}, {"referenceID": 11, "context": "For example, the authors of [12] designed an algorithm to mine frequent sequences that satisfy regular expressions specified by the user.", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": "In [13], Pesant proposed the regular global constraint for CP systems.", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "More recently, in [14], [15], the authors extended this work to the context-free languages with the introduction of grammar global constraints.", "startOffset": 18, "endOffset": 22}, {"referenceID": 14, "context": "More recently, in [14], [15], the authors extended this work to the context-free languages with the introduction of grammar global constraints.", "startOffset": 24, "endOffset": 28}, {"referenceID": 15, "context": "Furthermore, Quimper and Walsh [16] and by Katsirelos et al.", "startOffset": 31, "endOffset": 35}, {"referenceID": 16, "context": "[17] have shown how to decompose regular and grammar constraints into SAT formulae.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": ", [4]), each solution represents a pattern.", "startOffset": 2, "endOffset": 5}, {"referenceID": 17, "context": "For example, closed pattern mining [18] aims at extracting a subset of patterns from which it is possible to derive all other patterns.", "startOffset": 35, "endOffset": 39}, {"referenceID": 18, "context": "Machin et Truc [19] later showed that expressing closedness as a constraint can lead to ambiguous problem definition.", "startOffset": 15, "endOffset": 19}, {"referenceID": 19, "context": "In this section, we address closed and maximal pattern mining [20] by using interactive SAT solving.", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "for itemset mining ([18]).", "startOffset": 20, "endOffset": 24}, {"referenceID": 20, "context": "To avoid this constraint negation requirement, we now propose to use the incremental SAT solving paradigm [21].", "startOffset": 106, "endOffset": 110}, {"referenceID": 21, "context": "Both datasets were previously used to evaluate sequence mining algorithms, for example in [22] or in [3].", "startOffset": 90, "endOffset": 94}, {"referenceID": 2, "context": "Both datasets were previously used to evaluate sequence mining algorithms, for example in [22] or in [3].", "startOffset": 101, "endOffset": 104}, {"referenceID": 8, "context": "To solve our SAT formulation, we use the Glucose[9] SAT solver modified as explained in Algorithm 2.", "startOffset": 48, "endOffset": 51}, {"referenceID": 10, "context": "Specialized algorithms such as LCMseq [11] or Bide [22] have been designed to efficiently enumerate all closed frequent sequences.", "startOffset": 38, "endOffset": 42}, {"referenceID": 21, "context": "Specialized algorithms such as LCMseq [11] or Bide [22] have been designed to efficiently enumerate all closed frequent sequences.", "startOffset": 51, "endOffset": 55}, {"referenceID": 18, "context": "As pointed by [19], this is true only for anti-monotonic constraints.", "startOffset": 14, "endOffset": 18}, {"referenceID": 22, "context": "[23], who proposed an Apriori-derived algorithm to mine frequent sequences of itemsets (as opposed to mining frequent sequences of single characters, which is the issue that we address in this paper).", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "in [24] as the problem of serial episode mining.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "in [22] with the first depth-first search BIDE algorithm.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In [12], the authors mine sequences that satisfy a regular expression.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "The LCMseq algorithm ([11]) also deserves mention: It was extended by its authors to address different variations of the sequence mining task, such as maximal sequences and sequences with gap constraints.", "startOffset": 22, "endOffset": 26}, {"referenceID": 3, "context": "([4]).", "startOffset": 1, "endOffset": 4}, {"referenceID": 24, "context": "have proposed a constraint-based language for itemset mining ([25]).", "startOffset": 62, "endOffset": 66}, {"referenceID": 7, "context": "More recently, in [8], Coquerry et al.", "startOffset": 18, "endOffset": 21}, {"referenceID": 25, "context": "However, this formulation is based on a set encoding of sequences proposed by Arimura and Uno ([26]) and cannot be extended to more complex mining tasks such as flexible sequences.", "startOffset": 95, "endOffset": 99}, {"referenceID": 26, "context": "In [27], the authors showed that highly optimized pattern mining algorithms are inherently difficult to parallelize due to the large number of instances of memory access.", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "Traditional pattern mining algorithms generally suffer from a lack of flexibility. In this paper, we propose a SAT formulation of the problem to successfully mine frequent flexible sequences occurring in transactional datasets. Our SAT-based approach can easily be extended with extra constraints to address a broad range of pattern mining applications. To demonstrate this claim, we formulate and add several constraints, such as gap and span constraints, to our model in order to extract more specific patterns. We also use interactive solving to perform important derived tasks, such as closed pattern mining or maximal pattern mining. Finally, we prove the practical feasibility of our SAT model by running experiments on two real datasets.", "creator": "LaTeX with hyperref package"}}}