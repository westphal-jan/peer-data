{"id": "1604.00921", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2016", "title": "A Review of Theoretical and Practical Challenges of Trusted Autonomy in Big Data", "abstract": "despite the emerging advances made in artificial intelligence, software agents, and robotics, there is that little we see today that we can truly call a fully autonomous belief system. we conjecture that undoubtedly the main inhibitor capability for advancing autonomy is lack avoidance of trust. trusted autonomy is pushing the scientific and engineering field to establish the foundations and ground work necessary for developing robust trusted autonomous systems ( robotics and software agents ) that can be used in our daily life, and can be integrated with humans seamlessly, naturally and efficiently.", "histories": [["v1", "Wed, 16 Mar 2016 11:00:23 GMT  (595kb,D)", "http://arxiv.org/abs/1604.00921v1", null]], "reviews": [], "SUBJECTS": "cs.CY cs.AI cs.HC", "authors": ["hussein a abbass", "george leu", "kathryn merrick"], "accepted": false, "id": "1604.00921"}, "pdf": {"name": "1604.00921.pdf", "metadata": {"source": "CRF", "title": "A Review of Theoretical and Practical Challenges of Trusted Autonomy in Big Data", "authors": ["Hussein A. Abbass", "George Leu", "Kathryn Merrick"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus the paper on the \u2018trust\u2019 component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three sub-topics: (1) reviewing and positioning the trust modelling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enables trusted autonomous systems to become a reality. The paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.\nIndex Terms\nBig Data, Cognitive Cyber Symbiosis, Trusted Cyborg Swarm, Trust Bus, Trusted Autonomy, Trusted Autonomous Systems\nI. INTRODUCTION\nTrusted Autonomous Systems (TAS) are one of the grand challenges in this century. The proliferation of autonomous systems (AS) is a natural consequence of the opportunities they create for industry, health, education and the economy as a whole. These opportunities arrive with new technological and social challenges. TAS can be seen as a fusion of these challenges and acts as the umbrella that couples underneath it both objectives and challenges concurrently. Trusted Autonomy is the wider scientific endeavor to establish the science and engineering required to develop TAS.\nFor most of the literature, trust is seen as a human endeavor. It is seen to be owned by fields such as psychology [1], [2], social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8]. Technologists and computational scientists have been modelling trust for a few decades [9], [10], [11], [12]. TAS brings this large spectrum of research together in the face of a new challenge: the creation of mutual trust between a human and a machine.\nThe above challenge carries forward classic research in human factors, automation, human computer interaction, and human robotic interaction to tackle the problem of how to get a human to trust a machine. However, in addition to this one-sided view of trust, the challenge is raising a more fundamental complex question on the other side of the equation: how can a machine trust a human?\nThis latter question is a socio-technological question on modelling complex systems, and forms the context of this paper. For a machine to trust a human, it needs to be able to \u2018proactively\u2019 sense the human, extract meaning and cues during sensing, manage identity to ensure it is dealing with the right human, estimate and manage human intent, and make an informed judgement on the level of trustworthiness of the human in a particular context in time and space.\nFinding technological solutions to address this question is a complex endeavor that is compounded even more with the dynamic and possible chaotic nature of a trusting relationship. The slightest change in context may cause a dramatic change in trust estimation with a profound impact on trust dynamics. For example, a slight change in the security level of the communication channel between the human and the machine can cause a dramatic change in trust estimation.\nTo put it more succinctly, TAS require the machine to possess a high level of intelligence extending beyond the level of the task it is performing to include the level of the interaction it is involved with, the environment it is \u2018situated\u2019 and \u2018embodied\u2019 within, and to be aware of its own states, actions, motives, goals, and action production mechanisms. TAS require smart technologies for the machine to manage the interaction with humans; not just to convince the human that the machine is trustworthy, but to be \u2018self-aware\u2019 of trust to the extent of making its own decisions on the varying degree of trustworthiness of the human operators/users themselves during the interaction and based on context.\nDesigning the Artificial Intelligence (AI) models to manage the interaction between the human and the machine in the way explained above requires some fundamental building blocks. We structure this paper into three main sections.\nAuthors are with the School of Engineering & IT, University of New South Wales, Canberra-Australia, (e-mail: {h.abbass,g.leu,k.merrick}@adfa.edu.au).\nar X\niv :1\n60 4.\n00 92\n1v 1\n[ cs\n.C Y\n] 1\n6 M\nar 2\n01 6\n2\nThe first section (Section II) focuses on trust as the fundamental differentiator between classic AS research and TAS. We first start with the layers needed to define trust, then contrast how trust is modelled in the literature with these layers to offer two conceptual models: one is a computational structure model of trust and the other is a trust-based multi-agent architecture. We then define the \u2018trust aware\u2019 agent and present the concept of \u2018Trust Bus\u2019, which carries the information resultant from action production within the agent to the actuators. we adopt the term \u2019bus\u2019 in its computer architecture sense as in its classic use in computer architecture and service oriented architectures. The lens of the Trust Bus scopes the big data problem within this context to particular set of data and sensors. This scoping is essential as it guides the selection of sensors to be reviewed in the next section.\nThe second section (Section III) focuses on introducing big data to emphasize that the word \u2018big\u2019 is a relative concept defined in relation to the amount of processing available. We then review the sensor technologies available today that can facilitate the flow of information between humans and machines and augment the review with an overview of different processing concepts available to process these information. We conclude this section with a discussion on why the human-machine relationship is a big data problem.\nIn the third section (Section IV), we extend the discussion to the concept of autonomy and discuss the layers of autonomy. We then conclude this section by bringing together the first two sections and, first, offer the architecture required for an autonomous entity to exhibit both autonomy and trust, then second discuss the challenges associated with TAS from big data perspective.\nII. COMPUTATIONS FOR AND BY TRUST"}, {"heading": "A. The Road to Trust", "text": "Trust is a multi-dimensional concept. Research has established many facets and influential factors [12], [11] for trust dynamics [13]. We will discuss these facets and factors incrementally as each factor requires the list of factors listed before it to have a meaningful evolution of a trusting relationship.\nThe evolution model of trust presented in Figure 1 starts with the concept of reliability. A trustor requires the trustee to be reliable; that is, the trustee needs to be consistent in its actions, values, and objectives during the lifetime of the relationship and stable in its performance. Fundamentally, a trusting relationship carries with it a level of risk; that is, the risk that the trustee will default. Reliability increases the confidence level associated with predictability. Therefore, it offers a better estimate of the risk a trustor is exposed to during the trusting relationship.\nOnce reliability is established, trust improves through privacy. The order is a very important factor in this model. In the absence of any contextual information, a trustee that maintains privacy but not reliability is a high risk trustee. The reverse is not necessarily true as it depends on context. The trustor requires assurance that private information in the trusting relationship are protected.\nPrivacy is a distinct concept from security. When a trustor trusts a trustee, the trusting relationship involves transfer of certain data. For example, the trustee may need to know the identity of the trustor and vice-versa. These data are communicated between parties for the purpose of fulfilling the trusting relationship. Any misuse of these data outside terms of the trusting contract is a breach of privacy.\nSecurity, however, is more related to what is known as the CIA triad [14]: Confidentiality, Integrity and Availability. Confidentiality carries an element of privacy. A security breach where the database held by the trustee is broken into by an unauthorized third part can also be a breach of privacy. Maybe the third party only stole the trustee\u2019s data because it is not interested in the trustor\u2019s data per se; thus, the trustor data may not have been compromised. In this case, there is no privacy breach from the trustor perspective but a clear security breach that may compromise the trustor confidence in the trusting relationship.\nIntegrity breaches can be unintentional. A simple error in a piece of code can cause a deletion or modification of data and compromising the accuracy and validity of information. Availability is a function of the reliability of the IT service such that access is guaranteed whenever it is required and access control such that only authorized actors can access the data.\n3 The above discussion can be seen from a reliability lens, where the concept of reliability discussed above is focused on reliability for delivering the service while the privacy and security elements relate to the reliability of the information assurance process.\nThe fourth factor is related to safety [15]. A trustor needs to be safe in a trusting relationship. In a safety critical system, like air traffic management, the air traffic controller issues commands to pilots to ensure that the aircraft are separated (separation assurance). The pilot plays the trustor since the pilot does not have access to all information related to the airspace and needs to trust the air traffic controller judgement. The air traffic controller is the trustee. The trustee is highly trained and reliable. The communication channel and data within this safety critical system are subject to strict information assurance procedures. But what will happen if the working environment for the air traffic controller is not safe? For example, there is a high possibility for a fire hazard, loss of power, etc. In this case, safety, or lack of in this example, can alter reliability of service and information assurance.\nThe four factors discussed so far are related to what we will call, technological imperfection. They are imperfect because we can\u2019t guarantee a 100% reliability, privacy, security and safety in any situation. Regardless of how much we will invest, the laws of dimensioning return would prevail.\nThe remaining three factors are related to what we will call \u2018cognitive imperfection\u2019 and start coming into play. The first factor is related to the complexity of the context for the trustor and trustee. A trustor would normally enter a trusting relationship to manage some level of complexity. Trust is a form of educated delegation. A trustor would delegate to a trustee when the trustor \u2018needs to\u2019; that is, there is a benefit for the trustor in trusting than self-performing the job. This delegation needs to reduce some form of complexity, be it, the technical complexity associated with performing the task, the time pressure on the trustor to complete the task, or the increase in mental and cognitive complexity on the trustor if the trustor chooses to perform the task. As the level of complexity increases, the degree with which a trustor trusts a trustee increases.\nThe second factor of cognitive imperfection is related to risk. As we mentioned before, a trusting decision involves a level of uncertainty associated with the possibility that the trustee defects [11], [13]. Risk within a trusting decision is both negative and positive. The expectations from the trustor towards the good behavior of the trustee is a positive risk. It carries with it the negative risk resultant from the trustee defecting in the relationship. Taking high risk is an indication of high trust, while the reverse is not necessarily true.\nThe last factor in the evolutionary timeline of trust is \u2018free-will\u2019; the fact that the trustor is making the trusting decision not because of a necessity forced by an external actor who is attempting to exert its influence on the trustor. With free-will arises full autonomy. An actor that is fully autonomous acts because it has the freedom to act. This freedom is not unbounded since social ties, social rules and norms, and interdependencies among actors in terms of resources and objectives limit the behavior of an actor. Free-will is the ability of the actor to make a decision within this bounded space autonomously and at its own discretion. This discussion begs the question of what is autonomy?"}, {"heading": "B. Computational Trust", "text": "In multi-agent systems, agents can cooperate to achieve goals that may not be attainable by individual agents. However, agents must manage the risk associated with interacting with others who may have different objectives, or who may fail to fulfil their commitments during a cooperative scenario. Models of trust offer a mechanism for reasoning about the reliability, honesty, veracity etc. of other agents, to provide a basis for determining whether cooperation is worthwhile. This section is a selective survey of computational models of trust that have been used in multi-agent systems, including the types of trust models, the agent-models in which they have been used, the type of cooperation achieved and the applications in which trusting agents have been used.\nA number of existing surveys of computational trust have been made [16], [10], [17], [18]. Sabater and Sierra [16] classify trust and reputation models firstly as either cognitive or game theoretic. They also consider the information sources for trust, including direct experiences, indirect witness information and sociological information.\nThis section also considers these dimensions of trust models, but goes beyond this to survey the types of agent models in which trust models have been embedded, the applications for which they have been used and techniques for evaluating trust models. We also look beyond the scope of traditional agent-based systems literature to consider trust models from mathematical optimisation. The rest of this subsection is divided into two parts: trust modelling and computations by trust.\n1) Trust Modelling: Computational models of trust are essentially mathematical functions that aim to represent certain aspects of philosophical or psychological theories of trust. The earliest computational models date back to the 1990s and are relatively simple statistical functions taking into account factors such as the situation of an agent, the utility of the situation and the importance of the situation. Later models have emerged in time with the development of more complex machine learning paradigms.\nWe first take the approach of Josang et al. [17], dividing the basic trust models into categories for statistical models, Bayesian analysis, discrete models, belief models, fuzzy models and flow models. However, we also extend this set of categories with a discussion of trust-regions from the literature of mathematical optimisation and computer networks. \u2022 Statistical Models: An early approach to modelling trust was proposed by Marsh [19]. Marsh presents several definitions\nof trust that take into account different factors. First, he defines \u201cthe amount x trusts y\u201d by Tx(y). Tx(y) has a value in\n4 the interval [\u22121; 1) (i.e., \u22121 \u2264 Tx(y) < 1). In his model, 0 means no trust, and \u22121 represents total distrust. He argues that the two are not the same since, the situation of \u2018no trust\u2019 occurs when the trustor has little or no information about the trustee, or is indifferent. In contrast, \u2018total distrust\u2019 is a proactive measure, requiring that the trustor reason about what it is doing. Marsh does not permit a value of 1 for trust, arguing that \u2018blind trust\u2019 implies that the trustor does not reason about the situation, and this violates philosophical definitions of trust. In a second definition, Marsh includes the notion of a situation \u03b1. A situation is a point or points in time relative to a specific agent. The importance of the situation to an agent x is written Ix(\u03b1). Ix(\u03b1) has a value in (\u22121, 1). The utility (cost or benefit) of a situation to an agent x is written Ux(\u03b1) also with a value in (\u22121, 1). The \u201csituational trust\u201d of agent x for agent y in situation \u03b1 is then defined as:\nTx(y, \u03b1) = Tx(y)Ux(\u03b1)Ix(\u03b1) (1)\nEstimates for each of these terms must then be obtained. Marsh assumes that values of Ux(\u03b1) and Ix(\u03b1) can be determined from the domain. Marsh suggests that the amount x trusts y at time t, might be determined as an average of situational trust values at previous times. Because agent memory is assumed to be bounded, one challenge is to decide which situations should be included in this average. Alternatives include all the situations the agent remembers or only situations that were similar to the current situation and so on. Different choices will clearly result in different trust values. Other models have built on the work of Marsh, and maintain the idea of trust as a scalar value. Griffiths and Luck [20] define the trust in an agent y, to be a value from the interval between 0 and 1: Ty \u2208 [0, 1]. These numbers represent comparative values, and are not considered meaningful in themselves. Values approaching 0 are defined to represent complete distrust, and values approaching 1 represent complete or \u2018blind\u2019 trust. This is thus a simplified model, compared to that proposed by Marsh. \u2022 Bayesian Analysis: More recent models take a Bayesian approach to modelling trust [21]. Rather than using \u2018situations\u2019 as the basis for calculation, binary valued interactions form the input for the trust calculation. An interaction Ox,y takes a value of 1 if y fulfilled a contract with x, and 0 otherwise. \u2018Interactions\u2019 by this definition thus have a more constrained structure compared to Marsh\u2019s situations. The tendency of an agent y to fulfil or default on its obligations is governed by its behaviour, which is represented as a variable Bx,y \u2208 [0, 1]. Bx,y specifies the intrinsic probability that x will fulfil its obligations during an interaction with y. That is, Bx,y = Pr(Ox,y = 1). The level of trust Tx,y is defined as the expected value of Bx,y given a set of K outcomes O1:Kx,y . That is:\nTxy = E(Bx,y|O1:Kx,y ) (2)\nIn order to determine this expected value, a probability distribution defined by a probability density function (PDF) is used to model the relative probability that Bx,y will have a certain value. An example is a beta PDF (see Equation 10 for example). \u2022 Discrete Models: Other models stipulate a finite, discrete set of trust categories [22], [23]. For example, the model proposed by Abdul-Rahman and Hailes [22] stipulates four categories: very trustworthy, trustworthy, untrustworthy and very untrustworthy. An agent\u2019s trust degree is represented as a tuple, rather than a scalar value:\nT = {vt, t, u, vu} (3)\nTrust is equal to the trust degree with the highest value. One agent\u2019s x belief in another agent y\u2019s trustworthiness in a given context \u03b1 is represented as:\nbeliefx(y, \u03b1, T ) (4)\nAn agent maintains this information for each other agent and context. \u2022 Belief Models: A variation on discrete models is belief-based model such as those proposed by Josang [24]. In their\nmodel, trust is modelled as an opinion held by x about another agent y:\n\u03c9xy = (b, d, u, a), b, d, u, a \u2208 [0, 1] (5)\nwhere b represents belief, d disbelief and u uncertainty. a is the base-rate probability in the absence of evidence. \u2022 Fuzzy Models: Fuzzy models provide another way to deal with the uncertainty associated with trust [25], [26]. A fuzzy\nset is a pair (X,m) where X is a set and m : X \u2192 [0, 1] is a membership function that specifies the grade of membership of x in (X,m). For each x \u2208 X , then x is not included in (X,m) if m(x) = 0. Conversely it is fully included in (X,m) if m(x) = 1. If we maintain our definition of x as an agent, then a fuzzy set (X,m) may be defined as very trusted agents, trusted agents, untrusted agents and so on. \u2022 Flow Models: Josang et al. [17] define flow models as those that compute trust by transitive iteration through looped or arbitrarily long chains. The Advogato maximum flow trust metric [27], for example, computes trust of individuals in a group V relative to a \u2018seed\u2019 s of highly trusted group members. The input of the trust calculation are an integer number n, which represents the number of group members to trust, as well as the trust seed s. The output is a characteristic function that maps each member to a boolean value indicating trustworthiness:\nT : 2V \u00d7 N+0 \u2192 (V \u2192 {true, false}) (6)\n5 The trust model underlying Advogato does not provide support for weighted trust relationships. Hence, trust edges extending from individual x to y express blind trust of x in y. Other examples of flow based metrics include the Appleseed trust metric [28]. A characteristic component of flow models is the seed (also called the trust root). The seeds of trust, are the positive assumptions about specific entities made by all entities in some community. The label authority is often applied to an entity that is the subject of a trust root. Models with formally modelled trust seeds may be termed centralized and those without may be termed distributed [29]. \u2022 Optimisation Models: Another approach to modelling trust has been used in mathematical optimisation [30]. This this field, a \u2018trust region\u2019 denotes the part of an objective function for which there is a good approximate model function. An example of a model function here is a quadratic surface. Algorithms that incorporate trust region methods are known as restricted step methods, and broadly take the following approach [31]: If a \u2018good\u2019 model of the objective function is found within the trust region, then the region is expanded. Conversely, if the model is poor, then the region is contracted. The quality of the model is evaluated by comparing the ratio of expected improvement from the model approximation with the actual improvement observed in the objective function. Thresholding of this ratio can be used as the criterion for expansion and contraction of the trust region. The model function is then \u2019trusted\u2019 only in the region where it provides a good approximation.\nThe models discussed above assume that trust is the same for all agents, essentially an objective model of trust. However, alternative models, such as that proposed by Marsh [19], discuss the role of the disposition of the trustor in computing trust. This interprets trust as a subjective concept. Marsh presents a spectrum of dispositions from optimists to pessimists. Optimists are more likely to trust, while pessimists are less likely to trust. In contrast to the generic, average-based definition of trust described above, he defines optimists to compute trust as in Equation 7, while pessimists compute trust as in Equation 8:\nTx(y) = max\u03b1\u2208A(Tx(y, \u03b1)) (7)\nTx(y) = min\u03b1\u2208A(Tx(y, \u03b1)) (8)\nAgain, the choice of which situations to include will influence the value of trust. Griffiths and Luck [20] use dispositions as a way of initialising trust values. In their model, trust values are initially inferred according to an agent\u2019s disposition: optimistic agents infer high values, while pessimists infer low values. Disposition also assumed to determine how trust is updated after interactions in their model.\nAn assumption of the models above is that trust values depend on factors such as the agent\u2019s disposition and its personal experiences with the trustee. When assessing trust in an individual with whom an agent has no personal experience, information must be obtained in another way. One method is to consult \u2019witnesses\u2019 to develop a collective opinion. This collective opinion is often referred to as \u2019reputation\u2019, and can be used as a factor in the assessment of trustworthiness. The following is a short review of computational models of trust that take this approach: \u2022 Statistical Models: A simple model permits witnesses to report on a transaction by assigning one of three possible values\n1 (positive), 0 neutral or \u22121 (negative). Reputation is computed simply as the sum or an average of all reported values over a certain time period [16]. More complex variants of this approach weight recent witness reports more highly than older reports, or stipulate different rates of reputation change depending on the current reputation of an agent [32]. \u2022 Bayesian Analysis: Still more complex variants take into account specific details of interactions between individuals to compute reputation. One such model [21] represents x\u2019s opinion of y\u2019s reputation as:\nRtx,y = (m t x,y, n t x,y) (9)\nwhere mtx,y is the number of successful interactions (interactions where Ox,y = 1) and n t x,y is the number of unsuccessful interactions (interactions where Ox,y = 0) experienced by x. x may communicate this opinion with a third agent z. The communicated opinion R\u0302tx,y may be distinguished from the true opinion R t x,y as is possible that x may not report accurately for a range of reasons. z can develop a collective opinion of y by summing values of m\u0302tx,y and n\u0302 t x,y collected from multiple other agents x and using these values to calculate the shape parameters for a beta distribution, as in Equation 10.\nNz,y = \u2211 x n\u0302x,y and Mz,y = \u2211 x m\u0302x,y\n\u03b1 = Mz,y + 1 and \u03b2 = Nz,y + 1\nf(Bz,y|\u03b1, \u03b2) = (Bz,y) \u03b1\u22121(1\u2212Bz,y)\u03b2\u22121 1\u222b 0 u\u03b1\u22121(1\u2212 u)\u03b2\u22121du\n(10)\nThe final value for trust is calculated by applying the standard equation for the expected value of a beta distribution to these parameter settings: T tz,y = E(Bz,y|\u03b1, \u03b2) = \u03b1\u03b1+\u03b2 . Then, z may also include their own opinion in the trust calculation\n6 if such data exists. If all agents have complete information about the true opinions of all other agents, then it is said that a global or objective measure of trust results. Otherwise, trust remains local or subjective [28]. \u2022 Network Models: Another set of trust models based on witness data have been proposed for use in computer networks, and peer-to-peer computing, particularly in applications where multi-agent systems are responsible for transporting valuable data over a network. Examples of trust models for computer networks include PeerTrust [33], FCTrust [34] and SFTrust [35]. Other models build on this work [33]. They use parameters such as the feedback a peer obtains from other peers (also called satisfaction); feedback scope (such as the total number of transactions a peer has with other peers); the credibility factor for the feedback source; the transaction context factor for discriminating critical from less critical transactions; and the community context factor for addressing community-related characteristics and vulnerabilities. An example of a network trust metric based on these parameters is:\nT (x) = \u03b1 I(x)\u2211 i=1 S(x, i)Cr[p(x, i)]TF (x, i) + \u03b2CF (x) (11)\nI(x) denotes the total number of transactions performed by peer x with all other peers. p(x, i) denotes the other participating peer in peer x\u2019s ith transaction. S(x, i) denotes the normalised satisfaction peer x receives from peer p(x, i) in its ith transaction. Cr(.) denotes the credibility of feedback, TF (x, i) denotes the adaptive transaction context factor for peer x\u2019s ith transaction. CF (x) denotes the community context factor. \u03b1 and \u03b2 denote the normalise weight factors for the collective evaluation and the community context factors.\nThe models we discussed thus far are static, that is, they do not model the change in trust over time. Marsh [19] also presented a notation for change in trust as an update function for Equation 1:\nTx(y, \u03b1) t+1 = Tx(y, \u03b1) t + \u2206 (12)\nMarsh [19] considered change in trust over time as a result of different dispositions. For optimists, \u2206 is a large positive number in response to situations with positive utility, but a small negative number in response to situations with negative utility. In contrast, for pessimists \u2206 is a small positive number in response to situations with a positive utility, but a large negative number in response to situations with negative utility. Different types of optimists and pessimist can be created by varying the choices of \u2206. Jonker and Treur [36] expand on the two trust dispositions by distinguishing six types of trust dynamics: blindly positive; blindly negative; slow positive + fast negative; balanced slow; balanced fast; and slow negative + fast positive. Other models also assume that trust may change over time due to progressive accumulation of experiences. In this case, Equation 2 becomes:\nTx(x, y) t = E(Bx,y|O1:tx,y) (13)\nChange in trust over time, is generally assumed to be a result of information gathering \u2018experiences\u2019. A parallel concept that is often discussed as a result of such experiences is confidence [20], [21], [25]. The intuition is that the more evidence used to compute trust should result in higher confidence in computed trust values. Confidence is thus not a direct measure of trust, but an associated concept that tells an agent something about its trust calculation.\nAn example of a confidence metric that can be derived from a Bayesian definition of trust defines confidence \u03b3x,y as the posterior probability that the actual value of Bx,y lies within an acceptable margin of error about Tx,y . That is:\n\u0393x,y =\nTx,y+ \u222b Tx,y\u2212 w\u03b1\u22121(1\u2212 w)\u03b2\u22121dw\n1\u222b 0 u\u03b1\u22121(1\u2212 u)\u03b2\u22121du (14)\nAn alternative, simpler definition of confidence used in a fuzzy setting is a simple sum of the number of experiences (positive and negative) encountered by the agent [25].\nReliability is an associated concept with trust and confidence. Reliability theory is the study of the performance of a system of failure-prone elements [29]. Reliability is studied in many contexts, including software reliability, network reliability, hardware reliability and so on. Reliability is concerned with the ability of computer systems to carry out a desired operation. Reliability has been understood in different ways by different researchers with respect to trust. Some researchers have equated reliability with trust [29], while others make the weaker assumption that reliability influences trust [37].\nIn summary, different trust models have been proposed over the last two decades, with new models emerging in line with new developments in machine learning theory. The next section examines the agent architectures in which these models have been used.\n7 2) Computations by Trust: Agents are entities that sense their environments using sensors, reason about data so obtained using one or more reasoning processes, then act to change their environment using effectors. While some theoretical work on trust models trust in the absence of a specific agent architecture, there are some common agent frameworks that have been used to examine the models. Much of the literature on trusted agents makes the assumptions that agents are part of an open multi-agent system (MAS), in which individual agents are self-interested. That is, each agent has a goal or goals, but agents in the MAS do not necessarily share a common goal. This is considered a key reason for the necessity of trust. Aside from the assumptions of goals and self-interest, trust models have been used in a range of agent architectures, including belief-desire-intention (BDI) agents, reinforcement learning agents and motivated agents. These architectures, and the way in which they incorporate aspects of trust, are reviewed as follows: \u2022 Belief-Desire-Intention Agents: The BDI model [38] enables the definition of intelligent agents that have:\n\u2013 Beliefs about the world, \u2013 Desires that they would like to achieve, \u2013 Intentions, subsets of desires to which they have made some commitment, \u2013 Plans that, if successful, will achieve intentions.\nThe BDI architectures is one of the longest-standing models of intelligent agency used in MASs. It has thus been a popular target for the exploration of trust models [39], [40], [41]. One example is the ability-belief-commitment-desire (ABCD) model of trust [39], which integrates with the logic of rational agents (LORA) BDI agent theory. Koster et al. [41] provide a methodology for incorporating multiple different trust models BDI agents. \u2022 Motivated Agents: Griffiths and Luck [20] extend a BDI framework with motivations. In addition to the traditional components of the BDI model however, Griffiths and Luck [20] argue that motivation is an extra component required to achieve true autonomy in such agents. Motivations are high-level desires that characterise an agent; they guide behaviour and, at a fundamental level, control reasoning. They argue that short-term teams are not appropriate since motivations are too dynamic when considered over a short period of time, i.e. over a small number of tasks; in the short-term agents\u2019 motivations may be out of step resulting in agents\u2019 failure to share common goals at the same time. Similarly, long-term coalitions are unsuitable since although a given agent has a fixed set of motivations, the general trend of which motivations are active may change. \u2022 Learning Agents: Learning agents can modify their internal structures in such a way to improve their performance with respect to some task. Different approaches to learning existing, including learning from examples (supervised learning) and learning from reward and punishment in response to interactions with an environment (reinforcement learning). Many agents that incorporate models of trust are learning agents, because they accumulate experiences (examples) and change their interaction partners over time to improve their performance at some task. However, some approaches also use secondary learning algorithms to augment the trust model. Aref and Tran [26], for example, describe a fuzzy trust model in a Q-learning reinforcement learning framework to help trust evaluating agents select beneficial trustees for interaction in uncertain, open, dynamic, and untrusted MASs. Experimental results indicate that the proper augmentation of a fuzzy trust subsystem to Q-learning can be useful for trust evaluating agents, and the resulting model can respond to dynamic changes in the environment. \u2022 Multi-Agent Optimisation: Trust has also been studied in optimisation settings such as particle swarm optimisation (PSO). In PSO, agents (particles) represent solutions to a problem. Agents move around in a search space attempting to discover and converge on optimal solutions to the problem in question. Xu et al. [42] proposed a variation of the PSO algorithm for trust path selection in networks. They do not define a model of trust, but rather a novel PSO algorithm that can embed a given model of trust. Huang et al. [43] propose a different variation of PSO for incorporating trust to solve grid task scheduling. PSO algorithms are also particularly compatible with the trust-region formalism, and examples of algorithms that incorporate trust-regions with PSO have been proposed [44].\nThe examples above demonstrate that trust models have been developed across a number of different agent frameworks. These include learning, optimisation and planning architectures. Trust models have been particularly well studied in BDI agents. Currently we see that the trend is to develop different kinds of trust models for use in different settings. That is, there is currently no universally accepted trust model appropriate for a range of different types of agent frameworks. However, there are some trust models that have been used and adapted in several different settings. Marsh\u2019s early work [19] is one such example. These models are general enough for adaptation to specific agent frameworks or application domains.\nApplications of trust models include a range of abstract scenarios modelled in simulation, as well as a number of well known, real-world applications. Abstract applications include delegation, cooperation and detection of deceitful agents. Real world applications include a range of internet mediated service providers. A number of applications are discussed below \u2022 Delegation: Trust models can be used to determine whether a task should be delegated to another agent. That is, trust is\nused by agent x to decide if it should allocate a certain task to agent y [45]. \u2022 Cooperation in Multi-Agent Systems: Trust can also be used to determine whether multiple agents should cooperate.\nGriffiths and Luck [20] describe different types of cooperative groups that can occur between agents: \u2013 Teams: short-term cooperative groups formed to achieve a specific goal. Agents hold a common goal at the time of\n8 forming the team, and expect immediate benefit from achieving the goal. \u2013 Clans: medium-term cooperative groups that enhance individual goal achievement, with increased group performance\na useful side effect. \u2013 Coalitions: long-term cooperative groups formed to achieve a specific goal, which can be broken into sub-goals.\nAgents may have different preferences for these sub-goals, but are willing to forgo immediate individual benefit in the interests of long-term benefit for the coalition.\nMarsh [9] outlines different ways in which trust plays a part in the formation of cooperative groups: \u2013 Trust may influence whether an individual desires to join a group. \u2013 Trust may influence whether a group desires an individual to join them. \u2013 Trust may influence how members of different groups interact with members of other groups.\n\u2022 Detecting Deceitful Agents: Deceit is considered commonplace in certain industries such as trade [46], [47], [48], [49], computer networks [50] and online communities [33]. Understanding deceit is vital for detecting it, and for the design of governance mechanisms to discourage deceit. Observed regularities related to trust can be used to form the basis of models for deceit. This can assist with the detection of deceit in trade scenarios [46], [47], [48], [49], or malicious behaviour on computer networks [33], [50]. \u2022 Reputation: Reputation models are increasingly ubiquitous among internet mediated service providers [17]. For example, eBay (www.eBay.com) uses a reputation model to rate the trustworthiness of sellers. AirBnB (www.airbnb.com.au), use reputation models to rate the trustworthiness of hosts.\nAn appropriate use of trust models necessitates mechanisms for evaluating the performance of these models. Yu et al. [18] include in their survey of trust models a survey of performance assessment methods for such models. They note two major approaches used in the literature:\n1) Simulation-based evaluation; and 2) Evaluation through real world datasets. The approaches have been applied either individually or in combinations by researchers. They found that the most widely used evaluation method is via simulations. An example of a simulation testbed is the agent reputation and trust (ART) testbed [51], which simulates painting appraisers with varying levels of expertise in different artistic eras. Clients request appraisals for paintings from different eras. Appraising agents may also request opinions from other appraising agents. Appraisers receive more clients, and thus higher profits, for producing more accurate appraisals. The testbed assesses the quality of appraisers\u2019 trust-based decisions objectively by the profits they achieve, as well as the accuracy and consistency of their appraisals.\nSimulations permit researchers to vary experimental conditions. For example, they may simulate different ways in which a trust model may be exploited. In contrast, real world data may enable researchers to have a better idea of how their models would work under realistic environment conditions. However, because many datasets are not specifically collected for the purpose of evaluating trust models, they may lack the ground truth about the user behaviour to facilitate more in-depth analysis of the performance of proposed trust models [18].\n9"}, {"heading": "C. Synthesis of Computational Trust", "text": "This section has considered four aspects of trust models: \u2022 The inputs, processing types and outputs of trust models, \u2022 The agent architectures in which trust models have been used, \u2022 Applications of computational trust, \u2022 Techniques for the evaluation of trust models. Regarding the inputs, processing types and outputs of trust models, a key division is the direct and indirect input types. Indirect input is frequently indicative of a reputation based model of trust. Trust has been incorporated extensively in BDI agent architectures, but has also been examined in motivated agents and learning agents. Abstract applications include delegation, cooperation and detecting deceit in MASs. Concrete applications occur particularly in internet mediated service industries, which tend to make use of reputation models and computer networks for security purposes.\nFigure 2 presents a compilation of the literature on trust modelling that was reviewed in the previous section. This diagram clearly identifies the four main inputs to a trust model. One input depends on the trustor\u2019s initial belief about the level of trust it holds towards the trustee. One input depends on direct and indirect experience encounters with the trustee. Two inputs depend on context and represent the importance and value of the context.\nThe trustor needs to obtain two indicators from the trust model: the updated level of trust and the model confidence in this update. The trustor may choose to ignore an estimate with low confidence.\nThis model is intuitive, simple and basically captures the basic building blocks from across the wide literature on modelling trust. Variations can exist by expanding some of the elements. For example, how to calculate the importance of a situation or what personal attributes of the trustor and trustee we can use for trust update. Another example is related to the risk appetite and attitude of the trustor, which may influence the trustor\u2019s trust-update functions. All these are possible, with their utility dependant on data availability and the cost-benefit trade-off that needs to be taken into account when deciding on how complex a trust-model should be.\nTrust production is the set of mechanisms needed to make a trusting decision. Figure 2 conceptually depicted one input-andoutput view of a trust production system. It is equally important to know where trust sits within the wider agent architecture. We will start with the BDI architecture since we reviewed it above, but we will then move high up in the abstraction hierarchy to offer system-level architectures that integrate trust production more profoundly than the simple equation model used in almost all of the literature we reviewed on trust.\nThe amalgamation of trust production with BDI necessitates a new perspective on BDI that explicitly acknowledges the complexity of trust production instead of merely reducing it to the equation-based approach. We compile the above discussions\n10\ninto the Belief-Desire-Intention-Trust-Motivation (BDI-TM) architecture as shown in Figure 3. This architecture acknowledges two additional components to BDI; these are: Trust Bus and motivation adaptor. The Trust Bus interacts with the belief component to estimate trustworthiness of trustees but also produces information which are essential for the belief update mechanism: the primary learning mechanism in a BDI architecture. The Trust Bus acts as the message passing interface that learns \u2013 through automatic knowledge acquisition methods [52] \u2013 from and modifies massages as they get transferred from one system module to another.\nThe second component is related to motivation, which acts as an adaptor to desires. We prefer in this architecture to make motivation as a stand-alone component, simply because it is an adaptor to the overall desire production box, not just the desires themselves and can influence, and be influenced with, trust production as well. Beliefs memory and trust need to get fused with motives before motives adapts desires.\nThe previous discussion begs question on the constituents of the Trust Bus, and whether this bus is a simple message-passing interface or does it do more than that?\nFigure 4 expands the Trust Bus into its constituents: Actors and Entities Memory, Trust Production, Identity Management, Intent Management, Emotion Management, Complexity Management and Risk Management. Each of these components deserves a brief overview below.\nThe literature on trust implicitly emphasized the need to be aware of the actors in the environment (at least the trustee) and other entities. The Actors and Entities memory maintains the information stored on these actors and entities for retrieval when needed. The identity management module is responsible for identification of actors and continuous authentication of their identities while interacting with the system. This is a critical component underpinning the mechanisms needed to manage reputation, reliability of information, privacy and security.\nThe intent management module acts as a smart engine to objectively estimates actors intents and use these estimates to offer informed advice to the trust production module on the reliability and value of these intents. It also offers what-if services to the trust production module to explore the space of possible implications of trust.\nThe three remaining modules represent the cornerstones for trust in psychology and social science research and were elicited in our previous work [11], [13], [12]. These are emotion, risk, and complexity. Emotion management models and learns affective states of other actors in the environment. An advanced version of this module can manage the emotion states expressed by the AI when needed. The risk management module maintains a risk registry, analyzes uncertainties and offer what-if services to the trust production module. The complexity management module estimates the cognitive and task complexities in the context of other agents and the trustor. The literature on trust shows that complexity is a critical driver for trusting decisions. The trustor can get exposed to a level of complexity forcing unwise trusting decisions if this complexity is taken for grant. The complexity management module analyses the complexity surrounding the agent in a given situation, including the complexity surrounding other actors in the environment and their abilities to manage it.\nThe Trust Bus is used to scope the discussion on the nature and types of sensor technologies required by the Trust Bus to estimate human and group states. The Big Data nature of this problem warrants a special treatment and raises both theoretical and practical challenges. This topic will be the context of the next section.\n11\nIII. BIG DATA AT THE HUMAN-MACHINE INTERFACE The machine needs to be able to sense humans, their behavioral attributes, cognitive states, actions and decisions, and even the rational and explanations they make about their own judgements. This sensing is key for the machine to acquire the necessary information it needs to make a judgement about a human. It is very similar to human-to-human interaction, where humans actively and subconsciously sense each others facial expressions, body language, voice tone, and even skin temperature during a hand shake or a hug. With today\u2019s technologies, such as wearable devices, the machine can access even more information about the human\u2019s psychophysiological states that the humans themselves may not be conscious of. Today, Google applications can map out humans\u2019 daily routines, food and cloth preferences based on their shopping style, estimating probability of heart attacks based on their life style, social networks based on people in their social circuit, similar locations at night, similar routes, and more.\nIn addition to sensing the human, the machine needs to sense the environment. A change in human body temperature can simply be attributed to changes in the air conditioning setting. A change in a human voice signal can be attributed to the temperature in the environment, interferences between something in the environment and the microphone, or simply a result of a long speech or fatigue. Without sensing the environment, the machine is unable to attribute changes in the signal that it is sensing to different possible human states.\nSensing is a pre-requisite for any modelling that a machine needs to estimate a human\u2019s trust level. This section covers this topic through a Big Data lens. Before we regress further, we start the discussion with how big is a big data problem."}, {"heading": "A. How Big is Big", "text": "How big is big? This is usually the question that gets asked by those who are skeptical about the word \u2018big\u2019 in big data. However, the word \u2018big\u2019 is not merely about volume. It reflects the size of different characteristics that together form the basic features that one can use to characterize a problem as a big data problem.\nThe common characteristics for big data are summarized in different words that start with the letter \u2018V\u2019. This generated an evolution of these characteristics starting with the 3Vs model representing volume, velocity, and variety, then the 5Vs with the addition of veracity and value, and finally the 6Vs with the addition of variability [53], [54], [55].\nEach of the Vs represent one characteristics that by itself, the problem may get called a big data problem, but the challenge gets more complex when multiple Vs coexist together. Naturally the first V represents the volume or size of the data. A big data problem may have a significantly large number of features or simply terabytes or petabytes files.\nThe second V stands for velocity, or the speed with which the data change. Such changes may cause movements of the decision boundaries for a decision tree, alterations of the degree of nonlinearity in a regression model, or variation in the prototypes and numbers of clusters in a clustering problem.\nVariety, or heterogeneity, refers to the distributed nature of the data. A customer may have different forms of records across different databases. Some of the records may take the form of buying patterns, while others may take the form of voice signatures to authenticate the customer during online banking, or unstructured data collected during an interview with the customer.\nVeracity is related to the amount of noise that may exist in the data and the level of trustworthiness of the source. Veracity can further be divided into accidental veracity and intentional veracity. The former represents the classic noise in a communication channel associated with natural and/or physical causes. The latter represents intentional noise caused by a malicious act. These two factors play an important role in the validity and authenticity of any conclusion drawn from a dataset.\nThe second last V is the value characteristic; capturing the value for money and worthiness of the decision or conclusion drawn from the data. This is a cost-benefit-analysis question. Low cost data can generate high benefits, while high cost data may be too costly for the benefits they generate.\nLast, but not least, variability represents the dynamic nature of most IT infrastructure. Data exchange protocols change. The architecture of a database changes. The data format received from third parties change. These changes are necessary as we optimize the databases, customize the data differently for different customers, and so forth. Nevertheless, these changes impose major challenges in big data. The more variability that exists in the problem at hand, the harder the big data problem is.\nAutonomous systems are at the heart of the Big Data problem. The problem of autonomy is that it can generate unpredictability in the environment. As a software robot moves from one computer to another, protocols may change, data format may change, data worthiness may change, source reliability may change, and so forth. An autonomous entity has limited processing power relative to the data it encounters during its operations. Autonomy is a challenge for big data, and equally though, big data is a challenge in autonomy.\nAdding trust to the equation creates the biggest challenge overall. Trust glues autonomous systems. This glue is not a one-off glue. Trust is dynamic and requires dynamic strategies to manage it in an autonomous system."}, {"heading": "B. Sensors: What can they offer the human machine problem", "text": "Sensing is what allows a system to interact with its environment in a flexible and non-deterministic way, as apposed to performing preprogrammed actions based on a set of scheduled functions and/or rule sets [56]. In other words, sensing is a\n12\nfundamental mechanism and condition for a system to be able to operate autonomously in order to fulfil its purpose. Recent years have marked unprecedented advances in sensor technology, making available miniaturised, highly portable, accurate and reliable sensors, with high throughput and low cost [57]. This allowed the resultant sensor-based autonomous systems to embed more sensors, which in turn allowed them to operate in more complex and more dynamic environments. On the one hand, one can consider that the better the sensing is, the more data the system gathers from the environment, and further, the more informed and accurate the resultant decision is. However, on the other hand, as the amount of data generated by sensors grows, so do (1) the amount of processing the system needs to perform in order to generate a useful decision, and (2) the difficulty of taking the decision given the increased amount of choice. Rich data coming from numerous and high quality sensors could be simultaneously an enabling and a disabling factor for the operation of autonomous systems, with respect to the processing power available to the system.\nWe can give the example of an autonomous unmanned vehicle, which must deal with data coming from the activity of human agents served by the vehicle (e.g. passengers of an autonomous car, or passengers of an aircraft), and also from the surrounding technological agents (internal interaction with own mechanical sub-systems or external interaction with other vehicles participant in traffic). Another example can be an autonomous system for patient diagnosis and monitoring in a hospital. This needs real-time and historical data from the respective patient and historical data from numerous other patients in order to ensure statistical validity of the decision. Also, it needs data from the various machines and equipment operating in the hospital.\nRegardless of the source and type of activity, modern sensors operate in a digital manner, and generate data through sampling of their sensing. While sensing and processing of sensory information are taken for grant for biological agents (e.g. a human observer/decision-maker), it is not the case with artificial autonomous systems, which operate through digital computation and perceive everything as data. Thus, it becomes essential to have a clear view of the existing sensor technologies especially with a focus on the amount of data they generate as part of their normal operation. At the same time, it is essential to have a clear view on the existing processing/computing technologies and architectures in order to understand the potential limitations the autonomous systems can experience when they deal with the big data coming from their sensory-subsystem.\n1) Sensing human activity: Human activity sensors have undergone unprecedented development in recent years. Sensors and sensing systems that were once reserved for clinical or research applications are now easily accessible to the general public; are manufactured and commercialised on a large scale; and are being used across multiple domains in versatile and low cost applications. Patel et al. [58] identified the key facilitators that enabled this explosion of achievements in sensing human activity. The authors discuss the sensing systems in terms of three essential building blocks: (1) the sensors, i.e. sensing and data collection system (2) the communication system needed to transfer data to the processing centre, and (3) the data analysis techniques that extract the relevant information from the raw data. A refinement of the three component view presented in [58] was later discussed by Mukhopadhyay [59], who considers eight components where sensing research should concentrate for improving the overall performance of human activity wearable sensing systems: (1) types of sensors to be used, (2) type of communication protocols to be employed, (3) type of activities to be monitored, (4) techniques for extracting important features from activities, (5) design and development of small, light-weight, powerful and low-cost smart sensor nodes, (6) harvesting of energy for normal operation and communication, (7) ability to be used with the present day mobile devices, (8) potential to be reconfigured for new applications/users.\nBoth studies, [58], [59], note how each of these components have been on a path of miniaturisation, where the advances in micro/nano-electronics and related technologies allowed the resultant systems to become smaller and more powerful, and in the same time more energy efficient. These technological advances further allowed the emergence of fully wearable sensing systems that provide versatility and flexibility in both design and operation; in addition, they allow long-term non-intrusive monitoring and data collection. In [59] the author states that this surge of wearable sensing will continue to expand towards more and more domains, and cites industry reports concluding that the penetration of research advances towards the consumer market will lead to an estimated market growth to a value of over $20 billion by 2017. Wearable sensing systems have been extensively used in domains such as sports and recreation [60], human-computer interaction, work-space and ergonomics, games and entertainment, and last but not least, education.\nNumerous reviews discussed sensors and sensing systems in all these domains from the points of view of their component blocks and subsequent technology, with a focus on the aspects that allowed miniaturisation and wearability. Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65]. However, the resultant amount of data was not discussed so far in the literature. In the following, we describe the most common types of sensing systems used in monitoring human activity [59], and we focus our discussion on the sampling rate and the subsequent data resulting from their operation. \u2022 Body temperature: Body temperature is one of the most common physiological parameters used for monitoring human\nactivity, usually measured by wearable sensors attached to the skin. The body temperature in different parts of the body, and variations of it can give an indication of symptoms of medical stress that signal the existence, or the possibility of acquiring various health conditions. Body temperature monitoring can be used either for determining the respective physiological/medical conditions or for classifying and storing for further use historical physiological activity data, or even for harvesting energy from body heat [59]. Traditional measurement of body temperature was in the form of oneoff measurements, for clinical purposes. However, continuous monitoring is nowadays common, especially as part of\n13\nwearable activity monitoring devices and systems. In Table V all devices listed as incorporating temperature sensors, refer to skin temperature, and operate through contact to skin tissues typically in the wrist area, where wristband or watch type activity monitors are attached. Contact technologies such as thermocouples, resistive temperature detection, and organic diodes have been proposed over time [66]. Recently, contactless temperature sensors based on infra-red waves have been developed for accurate and hygienic monitoring of temperature in various parts of the body, such as FT90 contactless clinical thermometer from Beurer [67]. \u2022 Heart rate: Heart rate (HR) is also one of the most common physiological parameters monitored using wearable sensors for various purposes. Heart rate is a precisely regulated variable that is critical for diagnosing various medical conditions and disease of human, however its monitoring is also essential in sports and entertainment. A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature. Historically, the early wearable HR monitoring devices were pressure-based and used chest-straps to attach to upper body, e.g. Garmin HRM-Tri and HRM-Swim [73] dedicated to triathlon and swimming athletes, respectively. Recently, the due to the high demand on the wearable consumer market, technology migrated towards optic-based devices, which are currently implemented on all wristband, smartwatch, pendant or garment activity sensors. In Table V all activity sensing devices that include HR monitoring are LED-enabled optic-based sensors. An in-depth discussion on the differences between the two technologies, and the trends in wearable HR devices is provided in [74]. \u2022 Electroencephalography: Electroencephalography (EEG) is an electrophysiological sensing method that captures brain activity in the form of brainwaves coming from the aggregation of the electrical neural impulses; thus, EEG is based on electromagnetic wave sensing. Typical EEG sensing systems consist of several electrodes that measure in different regions of the brain the voltage fluctuations resulting from ionic current within the neurons. The sensing can be invasive, where the electrodes are implanted under the scalp, or non-invasive, where the electrodes are placed on the scalp either individually or as part of customised caps [75] in which the electrodes are precisely positioned. However, with the recent advances in the transducing elements of EEG devices, intrusive methods are now less and less used, while wearable caps and the very recent dry sensing headsets are becoming more common. EEG sensing was traditionally used in clinical applications, such as the traditional diagnose method for epilepsy, but also in supporting the diagnosis, monitoring, and treatment of other brain conditions, such as sleep disorders, coma, encephalopathy, brain death, etc. Research applications are especially in the fields of cognitive science and engineering [76], and human/brain-computer interaction [77], where the high temporal resolution of EEG sensing brings valuable information about real-time brain activity, capturing changes in cognitive load and states. High temporal resolution is the main advantage of EEG over a number of other brain imaging and brain activity sensing methods, which include magnetic resonance imaging (MRI) and functional MRI, singlephoton and positron emission tomography, magnetoencephalography (MEG), nuclear magnetic resonance spectroscopy, electrocorticography, near-infrared spectroscopy, and event-related optical signaling. Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution. However, while this temporal resolution is the main advantage of EEG sensing, it is also one of the challenges for using it in realtime applications, given that EEG systems can record in parallel on as many as 256 channels. In Table I we summarise the main EEG equipment available to date, and list for each of them the essential sensing data-generator features. \u2022 Eye movement sensing: Sensor systems that capture eye movement are used in clinical contexts primarily in ophthalmological diagnosis and in research contexts for eye tracking applications mainly related to human factor, cognitive science and engineering, and human-computer and brain-computer applications. The common eye movement sensing systems are either based on electric sensing or optical sensing. The most common electric sensing method is Electrooculography, which measures the corneo-retinal standing potential existing between the front and the back of the human eye. To measure eye movement, pairs of electrodes are placed at the opposite sides of the eyes (i.e. either above and below the eye or to the left and right of the eye). If the eye moves from centre position toward one of the two electrodes, this electrode \u201csees\u201d the positive side of the retina and the opposite electrode \u201csees\u201d the negative side. The resulting signal is called electrooculogram, in which the difference in potential occurring between the electrodes is recorded as a measure of the eye\u2019s position. EOG captures eye movement only, while more complex electric sensing methods, such as the Electroretinogram, can also capture and monitor eye response to individual visual stimuli. The optical eye movement sensing typically consists of eye-tracking systems based on specialised video cameras that capture retinal reflection and refraction as result of eye\u2019s exposure to visual stimuli. \u2022 Electrocardiography: Heart activity can be also measured and monitored using sensing systems. The typical sensing method for heart activity monitoring is electrocardiography (ECG), which uses electrical sensing for detecting the electrical changes that arise from the heart muscle depolarising during each heartbeat. These changes are captured on subject\u2019s skin using electrodes placed on relevant locations on the body. Typical ECG systems, used in clinical contexts, consist of ten electrodes placed on patient\u2019s limbs and chest, which capture over various periods of time the overall magnitude of the heart\u2019s electrical potential from twelve different polarisation angles, also known as \u201cleads\u201d. The output of the sensing\n14\n15\n2) Sensing machine agent activity: Surrounding technological systems are also one of the vital sources of data for autonomous systems. An autonomous unmanned road vehicle, for example, will gather data from various machine agents (i.e. peertechnology sources) that can be internal or external in relation to the vehicle. Internally, numerous sensors monitor the mechanical sub-systems involved in the normal operation of the vehicle, such as propulsion (e.g. crankshaft, camshaft, torque, oxygen, temperature sensors, etc.), breaking (ABS - Anti-lock Break System, EBD - Electronic Break Distribution), safety (impact, light, rain, proximity sensors), etc. Externally, numerous other sensors monitor the interaction of the vehicle with the environment, such as GPS for positioning, long and short range radar for obstacle detection, cameras for vision, etc. The\n16\nsituation becomes even more complex when speaking about the operation of an aircraft, or about the operation of a whole aircraft fleet, or an even more complex example, the operation of an autonomous air traffic control system, which actually handles an entire airspace. The resultant sensing mechanism is an overall equivalent sensor of very high complexity, which provides a fused global image of the data coming from the numerous internal and external sources.\nIn the previous section we discussed human activity sensing by considering the main categories of biophysical activity sensors separately. That discussion was pertinent because humans are identical from the perspective of the activity data they produce, thus autonomous systems need to embed a unique set of sensors in order to interact with different humans. However, in the case of sensing the activity of technical systems, there is a variety of sources the autonomous system may encounter during its operation. Thus, it becomes pertinent to discuss fusion sensing rather than the separate types of sensors. Sensor fusion [166] is the process of combining the sensory data coming from disparate sources in a way that (1) reduces the uncertainty resulting from separate treatment of the sources and/or (2) unveils properties of the sensed environment that were not obvious when using separate sources. Sensor fusion is receiving increasing attention from the research community, as the sensor technologies improve, together with the subsequent autonomous systems. Several thorough discussions can be found in the literature, proposing fusion methods with application in various fields of activity, such as control systems [167], thermal engineering [168], wearable robotics [169], or 3D computer vision [170].\nOver time, numerous sensor fusion architectures have been proposed and categorised differently by different studies. From a project management perspective, in [166], the author describes abstract, generic and rigid architectures. The abstract ones constitute as ways to describe or explain the operation of a fusion system without guiding the engineers toward the actual implementation. Their importance lies in that they provide the initial understanding of the fusion problem. Generic architectures describe how to implement the system, but without specifying the technology (i.e. operating system, software and hardware, communication system). They are important for providing the engineers with complete know-how, while still leaving them the freedom to adapt their solutions to specific problems. Rigid architectures provide detailed design and implementation of the fusion system, guiding the engineers step-by-step in a strict manner. They are important when sensing systems are embedded in critical infrastructures or safety critical applications, where rework or re-implementations of the systems are not only unnecessary, but actually strongly avoided.\nAnother classification proposed in the literature [171], [172], [173] takes a conceptual approach and discusses four main\n17\ncategories - centralised, hierarchical, distributed (or autonomous), and decentralised - from which various hybrid architectures can be further generated [172]. This classification is perhaps the most popular for both researchers and practitioners, becoming in time a fundamental part of the undergraduate control engineering curriculum [171].\nIn centralised fusion architectures raw sensor data are transmitted to a central site, where they are aggregated to generate the information needed to produce a single fused description of the state/dynamics of the environment. In general, centralised fusion needs high processing power and data buses with high band-width in order to handle the high amount of raw data generated by sensors; thus, scaling up to complex systems may became a problem.\nIn hierarchical fusion, the lowest level processing elements transmit information upwards, through successive levels, where the information is combined and refined at each level, until it reaches the top level, where the full view of the state/dynamics of the environment is made available. Hierarchical fusion involves a certain processing capability on each level, and thus the load on the centralised (highest level) processor is reduced. In the same time the need of communication is reduced, since transmission of data/information is strictly controlled and limited to adjacent layers. However, while useful in general, this can be also a disadvantage due to the inability of data/information sources to communicate over more than one layer.Another major disadvantage of hierarchical fusion is that changes in a certain layer imply changes in all related sub-layers; this usually prevents the sensing system to be extended to incorporate more sensors.\nDistributed fusion was meant to mitigate the drawbacks of centralised and hierarchical fusion, by providing autonomy to various sensing entities. In there architectures expert sensing agents with own processing capabilities make available to the system the output of their operation through a communication platform, often known as a \u201cblackboard\u201d from the architecture with the same name [172]. The obvious advantage of this approach is the distributed processing, with no central processing unit or layer. However, problems may arise due to the use of common communication/memory resource, i.e. the blackboard. Another disadvantage may be a potential loss in the accuracy of the global picture of the environment, due to the fact the picture is now dependant on simple agents with various processing capabilities.\nDecentralised data fusion abandon completely all commonality aspects. A decentralised system consists of a network of sensor nodes, each with its own processing facility, and no central or common communication facility. In this case, fusion happens in each node, locally, by the sensor unit using local observations and information communicated from neighbouring nodes. Advantages of the decentralised approach are high scalability and modularity, where dynamic changes of the sensor number and structure are easily supported. Thus, the resultant sensing systems are highly resilient to loss of nodes. However, due to the lack of global communication or knowledge, the accuracy of the fused picture of the environment is highly dependant on the network features, i.e. topological features like centralities, entropy and other statistical metrics.\nNumerous architectures have been proposed over time, from as early as 1960s to present days, for each of the four (plus the hybrid approaches). The interested reader can find thorough reviews of the general fusion architectures in a number of studies from different historical periods [174], [166], [172], [173]. However, it is outside of the scope of this study to provide insights in the individual architectures, since our purpose was to bring into attention the complexity that a sensor-based autonomous system must handle, in terms of the amount and variety of sensory data coming from the surrounding technological systems. Thus, we emphasize once more on the idea that big sensory data can be in the same time an enabling and a disabling factor in the operation of the autonomous systems."}, {"heading": "C. Computers", "text": "Once data-driven and model-driven information become available, processing starts. Be it in the form of signal processing, feature selection, clustering, classification, or any form of processing that is needed to make a judgement, the machine needs to rely on its processing abilities to process these information. Processing today extends beyond the classic Von Neuman computer architecture to other forms of processing.\nIn the most general understanding, a computer is an entity that conveniently alters a set of inputs to generate a set of desired outputs. Since digital computers started to be used on large scale, and became indispensable to modern life, the general perception of a computer narrowed to its digital incarnation, where inputs are reduced to binary data and alteration towards the desired output is made through binary calculation. However, computing was and is not limited to digital manipulation of binary input data, since numerous entities exist that can perform the computing analogically if talking about machine entities (e.g. mechanical, electrical, optical, electronic) or biologically if talking about natural entities, such as the neural sensory processing in animals with a central nervous system [175], [176]. Given that in this study we discuss autonomous systems considering the big sensory data they have to process during their normal operation, it is natural to bring into attention mostly the digital computing machines available to date, with a focus on their ability to deal with these data. However, we consider useful to discuss the other two categories, analog computing and neural-inspired computing, in order to offer a more comprehensive and integrated view on the ways that are open to autonomous systems.\n1) Analog computing: Analog computers use the continuously changeable aspects of a physical phenomenon of interest to alter the inputs towards the desirable output. Virtually, any physical process that models some computation can be seen as an analog computer, including finding the shortest path between two points by stretching a string between them. They have been heavily used in scientific and industrial applications in classic automation and control systems of the pre-digital era, when\n18\ndigital computers of the time lacked sufficient performance. However, they have been less and less used, becoming eventually obsolete as the digital computers came into place and became more powerful and versatile. There are still domains where they are still in use in some specific applications, where classic automation is required due to operation costs and environmental conditions. Extensive historical views on analog computers can be found in [177], and also in a special issue of IEEE Control Systems dedicated to the history of analog computers, from which we cite here the editorial article [178] signed by Lundberg.\nExamples of analog computers can go from the ancient nomographs and sextants, to slide rules, and further to complex contemporary automation and control systems such as navigation systems, analog auto-pilot systems for vehicle navigation, military weapon system controllers, analog signal processors, etc. In essence, virtually all industrial process control systems in the pre-digital era used analog computers, known at the time as controllers, to automatically regulate temperature, flow, pressure, or other process variables and parameters. The technology of these controllers ranged from purely mechanical systems to emulation of physical phenomena through electronic analog components, and later through analog integrated circuits.\nThe strongest point the analog computers make when compared to their digital counterparts is the computation speed; i.e. the analog computers operate in real-time once they have been set up. The computation in analog computers is not explicit like in digital computers, but rather implicit, inherently contained in the materials or phenomena they use as computation mean; thus the delivery of the output based on the input is virtually instantaneous. For example, an integrator can be built as an electric circuit by conveniently placing a resistor and a capacitor in a feedback loop, so that the output delivers a steadily changing voltage for a constant input voltage.\nA major disadvantage is that analog computers are designed for performing calculation in particular contexts outside of which they cannot function properly. Their setup involves choosing (1) the scale and limits for the inputs and outputs given the material or phenomena used for computation, (2) the set of pre-operational (initial) and operational conditions, and (3) the mechanism or physical structure (i.e. interconnection of computing elements) of the computation in order to assure proper solving of the given problem. When launched into operation variables cannot exceed computer\u2019s predefined operational conditions. For example, if the above mentioned integrator is to be used in humidity and temperature conditions that exceed the limits established during design stage based on the material/electrical tolerances indicated by manufacturer for the component elements (resistor, capacitor etc.), then, unacceptable calculation errors may occur. Also, if the integrator is to be used as a differentiator, this can be done only by changing the physical arrangement of the resistor and capacitor in the feedback loop, together with their values. In other words, a different circuit - that is, a different analog computer - is needed.\nAnalog computers can be found or imagined virtually anywhere and in anything in nature, however, the literature mostly speaks about the mechanical and electronic versions, due to the fact they account for the majority of the modern time achievements in both industry and research in pre-digital era. Both categories stand out due to their theoretical importance at the time or due to the popularity they gained in practical industrial applications. In the following we briefly discuss them in order to create a complete image of the analog computing field. \u2022 Mechanical analog computers: Mechanical analog computers used over the years were able to implement the usual\narithmetic, trigonometric, and geometric operations, and also complex analytic and algebraic transformations or arbitrary functions by conveniently combining various mechanical elements, such as rotating shafts, discs and gears, racks and pinions, cables and pulleys, springs, differential mechanisms, etc. For example, addition and subtraction have been implemented using precision bevel-gear differentials. Integration was implemented with a rotating disk (integrator variable) and a pickoff wheel positioned on the disc at a radius proportional to the integrated variable. Also, coordinate conversion from polar to rectangular was implemented with two coaxial discs and a sliding block with a pin on it. While these examples are important for analog computers, they are certainly not exhaustive. Extensive reviews of these computers can be found in the literature of the 1960s and 1970s [179], and more recently in [176]. \u2022 Electronic analog computers: Electronic analog computers emerged as a result of the similarities between the equationbased mathematical models of mechanical components, and those of the electrical components. Complex and heavyweight mechanical computational devices were gradually replaced with their electrical equivalents which could be constructed with operational amplifiers and other linear (resistors, capacitors, inductors) and non-linear (diodes, transistors) passive components. The resultant electronic analog computers were less expensive to construct, safer, and easier to modify for new problems in comparison with the mechanical counterparts. Gradually, more and more technological and natural phenomena could be represented through analogy by using electronic circuits, which could easily perform a wide variety of simulations. For example, an application would be to integrate a signal representing water flow, producing an output signal representing total quantity of water that has passed through a flow-meter. Voltage can be the analogy of water pressure and electric current the analogy of flow-rate in terms of volume/second. Then, the integrator can provide the total accumulated volume of liquid, using an input current proportional to the flow rate. Electronic analog computers contain may contain, depending on their purpose, tens, hundreds or thousands of operational amplifiers combined with relevant passive components in various feedback schemes, in order to implement mathematical operations and functions. The core operations and functions are: addition, subtraction and comparison; differentiation and integration; multiplication, division and inversion; exponentiation and logarithm. More complex arbitrary non-linear functions have been also implemented, however, they had limited precision (typically three to four digits) and were difficult to implement, requiring laborious and complicated feedback loops with combinations of linear and non-linear components\n19\nin the feedback loops of operational amplifiers. An in-depth discussion on electronic analog computers can be found in [180]. The major disadvantages of the electrical analogy are (1) the limited dynamic range, i.e. electronic components can represent limited variation ranges of the variables they emulate (compared for example with the virtually infinite dynamic range of the floating-point representation used by digital computers), and (2) the noise levels introduced by the electronic components and circuits. In general, electronic analog computers are limited by non-ideal effects induced by the undesired deviations of the core variables of the electric signals: DC and AC amplitudes, frequency, and phase due to material and environmental limitations [181]. The limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. \u2022 Revival of analog computing: Analog computation certainly went into an eclipse in the last few decades, due to the rise of digital computers, however recently more and more authors acknowledge that analog computation is inherent to most of the existing natural systems [182]. In [175] the author even note that some digital computing paradigms are actually unsuited and unnatural (pun intended) to natural computation. Thus, recently new iterations of analog computers have been proposed, especially in their electronic version. Recent development of semiconductors and very large scale integration went mostly in the direction of integrating digital circuits. However, recently, several analog VLSI circuits have been proposed, implementing energy efficient and instantaneous complex mathematical calculation. Cowan and colleagues [183] proposed a single-chip VLSI analog computer with 80 integrators and 336 other programmable linear and nonlinear circuits manufactured in 250nm CMOS technology. The chip was intended for use as an analog mathematical coprocessor for general purpose digital processors, and was rated by authors with a consumption of only 300mW . Later, Schell and Tsividis [184] proposed a hybrid signal processor where fixed sampling and clock rates of a conventional DSP were eliminated to create a clock-less digital signal processor. The processing unit was manufactured in 90nm CMOS technology and operated in continuous time with a power source of 1 Volt, offering no aliasing, and very fast transient performance in power electronics due to lack of sampling. Recently Guo and colleagues [185] demonstrated a continuous-time hybrid computing unit in 65nm CMOS technology, capable of solving nonlinear differential equations up to 4th order, and scalable to higher orders. The authors rate the energy efficiency of the processor at 12mW , and demonstrate the use of the unit in a low-power cyber-physical systems application, where the problem is solved in 0.84\u00b5s.\n2) Digital computing: In general, analog computers, analog signals or other analog processes implicitly involve an analogy or a systematic relation with the physical processes they model or simulate. They have inherent advantages, as discussed in previous section, such as speed and low energy consumption, given by the fact they operate on continuous representations of real processes by using continuous processes analog to real ones. However, the analogy itself also creates one of the most important drawbacks, that is the lack of flexibility, since a signal that was found to be analog to a physical process typically cannot be used with ease for another process. Digital computers, on the opposite, operate on discrete representations of real processes by means of discrete steps. Thus, real processes are represented by strings of binary symbols that do not have an explicit or direct physical relationship to the modelled processes. In [176] the author notes that in a digital computer the relationship, i.e. analogy, is more abstract than simple proportionality. This extra abstraction steps made the digital computers extremely versatile, in that the discrete modelling and operation allow their use in a large variety of applications, virtually without any hardware change. With this important advantage, doubled by a rapid increase in speed and energy efficiency, the digital computing eclipsed the analog ones, despite a number of disadvantages. Some of these advantages, which we mention here for completeness reasons, are as follows: (1) sampled signals used in digital computing suffer from aliasing effect, which leads to power dissipation on superior harmonics of the digitised signals and to the need of precise filtering; (2) digital signals may present important undesired behaviour in the transient domain; (3) discrete representation can lead to latency when data are transferred between various internal components of the processing architecture.\nToday, digital computers reached an unprecedented diversity, with their performance measured with respect to certain attributes that make them fit-for-purpose, rather than a unique performance metric. In general, digital computing is subject to a trade-off in which multiple aspects are involved, such as processing-related features (e.g. energy consumption, memory capacity, throughout, latency, etc.), operational features (e.g. size, weight, reliability, expandability, etc.) on top of which there are of course the financial costs of acquisition and operation. Thus, the overall performance of a digital computer can be measured using numerous metrics depending on its purpose. For example, a computer can be CPU bound - heavily used for raw computation, input-output (I/O) bound - mainly used as a server, or memory bound - mainly used for memory intensive tasks such as video editing. From the point of view of autonomous systems though, two aspects are essential: raw processing power and energy efficiency. We discussed earlier in the sensors section how portability and miniaturisation are the engines that propelled the sensors field to nowadays advances, which are unprecedented in the history of human kind. Thus, the autonomous systems making use of sensors must fall in the same philosophy of fast processing of data versus high portability.\nProcessing power was first associated with processor\u2019s clock rate, that is, the frequency (number of cycles per second) of the main clock of the CPU. However, this turned misleading as digital computing evolved and processors became able to execute more and more instructions at every processor cycle. Thus, a higher clocked processor may have a lower throughput\n20\nthan a lower clocked processor if the latter can execute significantly more instructions per cycle. Thus, another measure of the processing speed was the number of instructions per cycle, which in conjunction with processor\u2019s clock rate could give a better estimate of the speed with at which a certain task can be processed. However, this was also subject to ambiguities since different processor architectures can embed different sets of instructions, and/or can implement similar instructions differently. Perhaps the most accepted speed metric for modern processors is related to the amount of work done per unit time, i.e. the throughout, and is measured as the number of floating point operations per second (FLOPS).\nEnergy efficiency is the other vital aspect in the operation of autonomous systems, mostly for portability reasons, especially because the usual perception of an autonomous system involves embodiment and mobility. Disembodied autonomous systems can be brought into discussion, like autonomous decision-making systems hosted on mainframes of fixed computing facilities, in which case the energy consumption may be important from a cost perspective. However, in a sensing-based autonomous system, mobile embodiment is the pertinent form of existence, which leads to high importance of the energy efficiency offered by the processing units. \u2022 Classic processing-storage digital computing: Computers in this category generally refer to architectures in which\nmemory is conceptually separated from the processing unit, and data to be processed are permanently exchanged between the two. In general, the processing-storage architectures describe digital computers consisting of a processing unit, memory units that store programs (instructions) and data, input-output mechanisms, and external mass storage. Several architectures have been proposed over time, which differ through the way the exchange takes place within the component elements of the architecture. Of these, von Neumann, Harvard and modified-Harvard architectures are those that provided the majority of the digital computers available to date [186]. The von Neumann architecture proposed a design in which both data and instructions are stored in a unique memory, and thus they share one data bus for communication with the processing unit. The architecture was simple, through the use of only one data bus and one memory, but also introduced a major disadvantage, known as von Neumann bottleneck. The bottleneck consisted in the impossibility to fetch instructions and operate on data in the same time due to the shared bus that could only handle one type of memory items at a time. This led to limitations of the overall throughput (processing power), especially in data intensive applications, due to the fact the CPU was continually forced to wait for data to be transferred to or from memory. Several methods to overcome this bottleneck have been proposed over time, and included sole or combine use of: a cache between CPU and memory, separate caches for data and instructions between CPU and memory, separate access paths (bus) for data and instructions, on-chip single- or multi-layer CPU cache, pipeline mechanisms with prediction algorithms for data/instruction transfer, etc. The Harvard architecture was one of the most successful improvements proposed for overcoming von Neumann bottleneck. The architecture introduces a design with physically separate storage and transfer for instructions and data, thus the design features dedicated data memory and instruction memory, as well as dedicated data bus and instruction bus. Thus, in computers build on Harvard architecture, the CPU can read an instruction and operate a data transfer at the same time, leading to higher processing speed without using memory cache. In addition, since data and instructions are completely separated (storage and transfer path) their features and implementation can be different, such as different word size, different timing, different implementation technology, or different memory address structure, as well as different data transfer standards. The main use of Harvard design, is in applications where the energy saving and implementation costs, so that processor cache must be avoided, while still keeping a high processing speed. In signal processing, the digital signal processors (DSP) generally execute small, highly optimised processing algorithms, hence their memory usage is well determined, so that memory cache is not needed. In the same time, DSP applications need high parallelism, so multiple address spaces must be used, that usually need to be addressed in parallel. Thus, some DSPs feature multiple data memories in distinct address spaces to facilitate paralel processing approaches like Very-Long-Instruction-Word (VLIW) and SingleInstruction-Multiple-Data (SIMD). An example is the Texas Instruments TMS320 C55x processor family, which includes five parallel data buses two for writing and three for reading, and one instruction bus. Micro-controllers are another category of computing units implemented in Harvard architecture. They are typically used in embedded systems, where the applications need small amounts of program (instructions) and data memory, but need high speed processing with low energy consumption. Thus, designs with concurrent instruction and data access and no cache are preferred by most manufacturers, such as Atmel\u2019s AVR family or Microchip\u2019s PIC family. However, while providing high processing speed and low energy consumption for a range of applications like RISC or embedded systems, the architecture was not appropriate for full-sized modern processors used in general-purpose computing, such as personal computers and laptops, and more recently tablets and smart-phones. This happened especially due to the unbalanced development of various elements of the computing architecture, where for example the speed of CPU, memory, bus and external storage experienced very different growth pace. Thus, various improvements of Harvard architecture have been proposed, all known under the umbrella of modified Harvard design. In essence the modified versions are still Harvard architectures through that the CPU is able to access\n21\ndata and instructions separately, but in the same time they resemble von Neumann design by storing both in a unique memory. The use of split-cache system is the most common modification, used in most modern general-use processor families from INTEL, AMD, ARM, Motorola, IBM, SUN, etc. In this design, separate instruction and data caches are used by CPU to access a common address space. When the CPU executes from caches the computer falls onto the standard Harvard design, and when it accesses the common memory it falls onto the von Neumann design. \u2022 Highly parallel processing on GPUs: A significant step towards increasing processing speed was made during the mid 2000s, when general-purpose computing tasks started to be ported from CPUs onto graphic processing units (GPU) [187], [188]. GPUs are specialised processing units designed to accelerate the creation of images in a frame buffer (that is further output-ed to a display) through a multi-core structure that is able to process large blocks of visual data in parallel. GPUs operate in general at lower clock frequencies compared to CPUs, but embed very high numbers of simple cores working in parallel, overpassing overall the capabilities of even the fastest multi-core CPUs available today. However, the limitation of GPUs was that their simple cores were designed for handling graphics data only. Early GPUs embedded specialised cores were used for texture mapping and polygon rendering, with later additions that included various geometric calculations, e.g. rotation/translation of vertices into different coordinate systems. More recent GPUs added programmable shaders which for manipulating vertices and textures, oversampling and interpolation techniques for anti-aliasing, and very highprecision color spaces. Today, typical specialised cores in modern GPUs are pixel shaders and vertex shaders (recently combined in \u201cunified shader architecture\u201d), texture mapping units, and render output units. Since most graphical computations involve vector and matrix manipulation, researchers and practitioners have increasingly studied the use of GPUs for non-graphical calculations. Since the graphic cores were unable to process general-use data, the usual CPU applications had to be transformed into graphical forms in order to be processed by GPUs. Thus, early attempts to perform general-purpose computing on GPUs focused on reformulating at conceptual level the general computation problems in terms of graphics primitives, in order to be compatible with OpenGL or DirectX [189], the two major APIs available at the time. This difficult translation was later abandoned with the emergence of the GPU computing ecosystems (API + SDK), such as the proprietary CUDA from nVidia [190], which was the first API to allow the transfer of C, C++ and Fortran code (and later Matlab, Python and C#) straight to GPU, with no assembly language required. Later, in 2007, AMD-ATI released its own proprietary ecosystem Stream, which followed the ATI developed Close-To-Metal and further evolved into the recent Accelerated Parallel Processing (APP) ecosystem that offers support for newest AMD\u2019s Heterogeneous System Architecture, in which CPU and GPU cores are designed to work together in a single accelerated processing unit (APU) [191]. Recently, hardware-independent platforms have been released, such as the proprietary DirectCompute from Microsoft as part of DirectX API [189], and the open-source OpenCL [192]. Through these, the general-purpose applications can be run through and benefit of GPU speed without requiring conversion of the data into graphic form. CUDA and Stream/APP ecosystems remained bond to nVidia and AMD GPUs, respectively. nVidia GPUs starting with GeForce 8 series were by default hardware enabled for CUDA, while AMD\u2019s GPUs starting with Radeon500 family were by default hardware enabled for Stream (and later for APP). Recently, the open source platform-independent OpenCL, developed by Khronos Group [192] became popular for that it allows development of code for both GPUs and CPUs, and received support from all major chip manufacturers, Intel, AMD, Nvidia, and ARM, whose most recent chips are OpenCL-enabled. \u2022 Reconfigurable processing: Apart from the processing power and energy consumption, another aspect becomes more and more important in the context of sensor-enabled autonomous systems. Since the nature of these systems, as we explained in earlier in the paper, is to operate in dynamic environments, it becomes important to be able to adapt not only the decision making, but also the processing itself to the task of interest. However, while this is possible on general use computers through software, it is not possible at lower hardware level. Thus, an increased interest have been shown for the use of FPGAs (Field-Programable Gate Array), which by design have the potential to be reprogrammed at runtime, being in essence computing units that can reconfigure themselves to suit the task of interest [193]. Typically, FPGAs contain arrays of programmable logic blocks, and a hierarchy of reconfigurable interconnects that allow the blocks to be connected conveniently to perform a variety of operations, from simple logical operations like XOR, to complex combinatorial functions, mathematical functions or even emulate whole processors. Historically, they have been used as \u201cbreadboards\u201d for low cost prototyping, in order to avoid the high non-recurring engineering costs of ASIC (ApplicationSpecific Integrated Circuit) development. Thus, chip manufacturers could develop their hardware on standard FPGAs, and then manufacture at large scale their final version as an ASIC that could not be modified once the final commitment to a design has been done. For the same reason, FPGAs were also preferred for designing and manufacturing of chips, in applications where the volume of production was small and the development of ASICS was not worthy at all. Initial FPGAs were bond to these purposes also because of their low performance, combined with large physical dimension and high energy consumption [194]. However, with the recent advances in semiconductor technology, transistor gates and memories, the latest FPGAs can rival not only with their ASIC counterparts, but also with full-sized processors in multiple respects, such as speed, dimension, energy efficiency and cost, while having the advantage of reconfigurability. Recent FPGAs began to take over larger and larger functions to the point where they are even able to implement so-called \u201csoft\n22\nprocessors\u201d that emulate the operation of powerful computers, either in ASIC domain or in general-computing domain. FPGA-based soft processors can be seen in various reconfigurable System-On-Chip (SoC) solutions, which incorporate in the FPGA fabric a variety of elements, such as ARM cores, networking modules, radio modules, DAC/ADC converters, and other peripherals. Examples of these FPGA are those from the major chip manufacturers, such as Microsemi SmartFusion series, Xilinx Zynq series, or Altera Arria series. A detailed review of the high speed FPGA SoC and soft processors can be found in [195]. Due to these technological advances, FPGAs are used today in complex applications that include digital signal processing, software-defined radio, medical imaging, computer vision, speech recognition, cryptography, bio-informatics, computer hardware emulation, radio astronomy, metal detection and a growing range of other areas. Another recent use of FPGAs is hardware acceleration, where FPGAs are used as coprocessors, to assist a general-use processors in acceleration of certain parts a task or algorithm [196]. Recent use of FPGA coprocessors was announced by Microsoft and Google, who started to use FPGAs to accelerate high-performance, computationally intensive data centres that operate their search engines, i.e. Bing and Google respectively.\n3) Neuromorphic computing: Neuromorphic engineering, also known as neuromorphic computing, has its roots in the analogic nature of natural biological computation and is based on the transfer of the morphology of individual into electronic circuits. In essence, the resultant computing architectures and implementations are analog computers which contain circuits that mimic the electrical activity of neuro-biological nervous system, that is, described by the spiking neuron models. From the point of view of a sensor-based autonomous system, neuro-morphic computing seems like the obvious way to go, since the sensor-based operation is the essence of life, and thus any existing digital artificial sensor-based system, no matter how fast or sophisticated it is, is still far from what biological sensory processing can offer.\nMost of the efforts in neuromorphic computing concentrated on the formal spiking models, with some notable instantiations of the theoretical models proposed in the last decade.\nIn 2006, researchers at Georgia Institute of Technology published the details of a field programmable neural array [197]. The chip was the first in a line of many increasingly complex arrays of floating gate transistors that allowed programmability of charge on the gates of MOSFETs to model the channel-ion characteristics of neurons in the brain and was one of the first cases of a silicon programmable array of neurons. The authors describe the chip as an analog circuit capable of accurately emulating large complex cells, or multiple less complex ones. They note its analogy to an FPGA in which the binary transistor gates were replaced by biologically relevant circuit components including active channels, dendrites, and synapses. A routing capability was added to these elements in order to transfer outputs from cells to individual synapses.\nIn 2012, Spintronic Rand Purdue University [198] announced a neuromorphic chip that used lateral spin valves and memristors. Their design was a hybrid structure in which a programming current passing through heavy metal generates spin-orbit torque to modulate the spintronic device conductance, creating a nanoelectronic synapse. The spintronic synapse was then interfaced with CMOS neurons operating in transistor subthreshold region in order to form a network of spiking neurons. The authors claim that the architecture can emulate the operation of biological neurons and reproduce various brain-like processing abilities with significantly lower energy consumption than conventional digital chips.\nSpiNNaker [199], proposed by the neuromorphic engineering research group at Manchester university, is a massively parallel, low power, neuromorphic computing board designed to model very large, biologically realistic, spiking neural networks in real time. The board consists of 65,536 identical 18-core processors, meaning 1,179,648 cores in total. Each processor has an on-board router to form links with its neighbours, as well as its own 128 MB of memory to hold synaptic weights. Each core is an ARM968 chip manufactured using a 130 nm process. The resultant chip is not a purely hardware neuromorphic computer, but rather a massively parallel digital computer, with over one million cores, which can simulate one thousand neurons per core, leading to a total of one billion simulated neurons.\nIn 2014 Stanford University announced Neurogrid [200] structure. Neurogrid is a 6.5x7.5 square inch circuit board composed of 16 custom designed chips, referred to as NeuroCores. Each NeuroCore\u2019s analog circuitry covers 12x14 square millimetres and is designed to emulate 65536 neurons, thus the board can model a total of over one million neurons, and 6 billion synapses implemented in a binary tree with links, with operates at a total of 80 million spikes per second. The authors claim a consumption of only 5 watt at full processing load.\nPerhaps the most advanced neuromorphic chip is TrueNorth proposed by IBM [201]. TrueNorth is built in CMOS technology and consists of 4096 hardware cores, each of them embedding 256 programmable hardware silicon neurons, which in turn have 256 programmable synapses. Over all the chip embeds over a million neurons, with a total of over 268 million synapses, on a physical CMOS wafer containing 5.4 billion transistors in 28 nm technology. The authors claim an energy consumption of less than 100mW/chip, meaning less then 20mW/cm2, or 26pJ per synaptic event. They also claim that the chip implements the first fully event driven digital mixed synchronous-asynchronous neuromorphic architecture. Applications of the chip in real tasks showed a consumption of 70mW while a recurrent network at biological real-time, and 65mW in a multi-object detection and classification application, with 240x400-pixel 3-color video input at 30 frames-per-second. TrueNorth is claimed to be the first neuromorphic implementation that distances entirely from the classic processing-storage paradigm, through the fact the neurons are silicon based not emulated by conventional gates. Thus, the classic thinking of how to program a computer also cannot be applied any more, since concepts like memory access, data buses or CPU do not exist in TrueNorth design.\n23\nThe authors designed for this reason an end-to-end ecosystem complete with a custom simulator and a new programming language for composing networks of neurosynaptic cores, called corelet [202] implemented in Matlab code. With this, IBM also offers an integrated programming environment with corelet libraries, conventional algorithms and applications ported into the neuromorphic paradigm, and a teaching curriculum called \u201cSyNAPSE University\u201d."}, {"heading": "D. Human-Machine Interface Big Data Problems", "text": "In our discussion of the sensor technologies to connect humans to machines, we avoided some of the classic and data intensive sensors such as different types of cameras and microphones. The Psychophysiological sensors reviewed are not too data intensive. The maximum EEG sampling rate was 20kHz. With a maximum of 256 sensors, we can have a 5mHz information flow from the human scalp. ECG and other sensors are not worth discussing from a big data perspective. Thus, it seems that the three most demanding data sources are imagines, EEG and sound in order of the complexity of data that can be acquired through these channels.\nTo process these data, clearly neuromorphic chips can offer a leap forward in the ability of artificial AS to perform real-time complex sensing and processing tasks. However, it is still too early stage for this technology and is very unlikely that the technology will be available in large scale and with a general-consumer accessible strategy in the near future. As such, we are back to the von Neuman and Harvard architectures, as the most feasible processing to be used today. This also includes GPUs and reconfigurable chips such as FPGAs.\nFrom the 6 different Vs defining a big data problem, we comment in what follows on how the human-machine interface problem is a big data problem. The issue of volume arises specifically when dealing with video, EEG and voice. However, the main big data challenges within the context of this paper are more centred on the other Vs, which are all apparent in this context. The timeseries nature of most of these data, along with the chaotic nature of human mental processing, makes the problem to be susceptible to high velocity and high veracity. The multi-modality required to triangulate different sources of data to understand human mental states make the problem susceptible to high variety and variability features. The use of these data to make informed trusting decisions and facilitate human-machine interaction in TAS may depend on the application and context, but in general we expect it to have clear high value.\nIn summary, TAS bring big data challenges that need to be considered when designing these systems.\nIV. TRUSTED AUTONOMOUS SYSTEMS: THE BIG DATA CHALLENGE REVEALED\nThis section concludes the paper with the big data open challenges for trusted autonomy. In Sub-section IV-A, we will discuss autonomy to contextualise the discussion for the reader. This is followed by bringing together the discussion on Trust and the discussion on autonomy under the common objective of this paper: trust-aware autonomous systems in Sub-section IV-B. Sub-section IV-C offers some insight into some open challenges and future research directions."}, {"heading": "A. The Road to Autonomy", "text": "The evolution of autonomy in Figure 5 follows similar principles to the evolution of trust. Autonomy is not a binary concept. The concept exists on a wide scale with complete absence of autonomy at the one end and full autonomy at the other.\nWe will explain autonomy using the WH-clauses: How (strategy), When/Where/Whom (context), What (goal), and Why (rationality). These questions are incremental in nature. Without the ability to develop strategies, an actor can\u2019t manage and/or survive a context. Without the ability to manage contexts, the actor can\u2019t deal with goals. Without the ability to manage goals,\n24\nthe actor can\u2019t explain and/or reason about its own behavior. The abilities to develop strategy, manage context, manage goals, and explain and reason can be hard-wired within an actor. When the actor is able to develop these abilities by itself, it develops \u2018self\u2019 and it rises up in the hierarchy of autonomy. This ability to develop \u2018self\u2019 does not happen in vacuum. It is another set of algorithms that work on a higher level of abstraction. Similar to learning to learn, we still need to use learning techniques, but with an appropriate representation, we can develop learning techniques that are able to learn on their own.\nThe left hand side of the diagram starts with a zero-autonomy; a dictatorship master-slave relationship, where zero autonomy is equivalent to a slave with full obedience to its master. An example we will use here to demonstrate the concept is in the case of a bicycle. As a machine, it does not do anything unless an external force (human or environment) exerts a force on it.\nLet us add an electrical motor to the bicycle. The human may press a button and it will start to move. The motor offers a control without being aware of context. It will move in the same manner independent of whether it is night or day, moving on a road or in mud, and whether it is operated by an adult or a child. Once we add sensors and increase the level of intelligence in the controller, the machine starts to be \u2018context-sensitive\u2019. It will behave differently in different contexts. We will follow a similar philosophy to Abowd et.al. [203] to differentiate between sensitivity to context; that is, the machine is using context information, and what we will discuss later on as \u2018context aware\u2019. For now, this machine is not \u2018context aware\u2019 yet.\nWe can continue to improve the automation of the machine by adding a planner and a GPS system to offer it an opportunity to decide on goals. The human may ask the machine to go to a restaurant and the machine will choose the restaurant, plan the route, and take the human to a restaurant of its choice. The human may then need to ask the \u2018why\u2019 question; that is, why a certain route was chosen. In this case, we need to use the planner within the machine or add another layer of reasoning to offer the human an explanation of the choices made by the machine.\nWhile we do have a smart machine that automatically decides on a route, adapts its control strategy to the information it is sensing from the environment on terrain and driver characteristics, is able to plan automatically, and reason about its action, the level of autonomy of this machine is still very limiting. What we have up to now is smart automation, with little autonomy. Taking this level of intelligence to autonomy is the vision of \u2018autonomic computing\u2019 that was first introduced by Paul Horn [204] in his 2001 keynote address to the National Academy of Engineers at Harvard University.\nThe ultimate aim of autonomic computing, or what is known now as \u2018self-X\u2019, is to have a self-governed system. This created a list of characteristics to make this dream a reality including: the system needs to have its own identity, be able to self-configure, self-optimize, self-heal, self-protect, and become self-aware. We will depart from some of these characteristics as we see the evolutionary steps we will discuss for autonomy to subsume some of them.\nAutonomy starts to increase incrementally as we add more self-x capabilities with the ultimate goal to achieve total selfgoverning. The first feature is \u2018self healing\u2019, the ability to recognize problems (self-diagnosis) and recover automatically. The system needs to be able to be equipped with the mechanisms for it to discover its own strategies towards maintaining its health level and functionality at the right level.\nMoving in the hierarchy from context-sensitive to context aware, the system needs to extend its ability to sense the environment surrounding it to an ability where it senses the user\u2019s tasks, user\u2019s intents, and know how to contribute to the optimization of this task. This definition is consistent with Abowd et.al. [203] who refer to a system as context-aware \u201cif it uses context to provide relevant information and/or services to the user, where relevancy depends on the users task.\u201d\nA context aware system with the ability to do self-healing is already too advanced in the autonomy hierarchy but still unable to exercise full autonomy. It needs to have the ability to autonomously generate its own goals through self-motivation and to reason in its own way through self-reasoning. These features allow the system to decide for itself what it needs to do and develop its own rationale for the how, when, where and what.\nWith the above self-X capabilities, a system becomes fully autonomous when it is able to integrate across these capabilities to form a self-governed whole. Here, autonomy reaches its maximum horizon."}, {"heading": "B. Trust-Aware Autonomous Systems", "text": "The road to trusted autonomy is not a simple addition of trust to autonomy. A trusted autonomous system (TAS) does not operate in a vacuum. It interacts with other TASs and within an overall context. It needs to take into account the complex interaction of the two concepts, trust and autonomy, and the multi-actor environment they operate within.\nEach actor has its own objectives, goals, behavioral attributes, capabilities, and resources. While these actors individually may be trusted, the system as a whole may not be. The simple example is counterintuitive and can better be explained with the statement: if everyone does the right thing, it does not mean that the group is doing the right thing. The challenge in this statement lies within the boundary of the word \u2018right\u2019: right for whom and from whose perspective, and who has the authority to define what is right? What is right from an individual actor perspective may not be what is right from a system perspective. An actor may wish to operate optimally (e.g. a robot would like to reduce energy consumption to extend battery life), but the system may need the task to be completed as quickly as possible, which may result in a non-efficient use of the robot\u2019s battery. These sorts of conflicting objectives between the individuals and the group, the groups and the supergroups, and the supergroups and the society create a level of interdependency that complicates the concept of trust in social dynamics.\n25\nFor a TAS to be trusted from a system-level perspective, it needs to be self-aware of system-level objectives and work collaboratively with other trusted-autonomous systems towards achieving these objectives.\nThe dynamics associated with the interaction require continuous sensing, processing, acting on, and verifying the environment it is operating within and other autonomous systems, including humans, in this environment. Verification [205], in particular, raises more challenges and requires a significant amount of data in real-time operations.\nFigure 6 attempts to capture the key building blocks to form a TAS. The visual decomposition of these building blocks is primarily for ease of understanding and is not meant to imply that these building blocks can be designed or developed independently. It is a conceptual functional decomposition of the system, but it is not a proposal for a modular decomposition because of complexities that are outside the scope of this paper.\nIt might seem counterintuitive to separate action production from all modules that are focusing on self-management and selfawareness. This is intentional conceptually because action production mechanisms present a toolbox that any of the individual building blocks can use and adopt when needed and as the situation dictates. One can see action production as a service that gets called upon by all other modules.\nSecondly, we adopt a convention that self-management will require self-awareness. We define self-awareness here as the system\u2019s ability to map out and represent all its components virtually (ie. software wise), continuously measure their states, and is able to identify if a component has been spoofed. This is a stricter definition of self-awareness than some of the general discussions of the concept in the literature. However, we take it that a definition need to be self-encompassing, while systems can exhibits different degrees of the concept being defined.\nThe following sub-section will highlight the big data challenges for trusted autonomy.\n26"}, {"heading": "C. Big Data Challenges for TAS Revealed", "text": "Trusted autonomy creates a series of big data challenges. We will highlight below the six most prominent challenges that we have identified.\n1) Moving Sensor Network Challenge: An autonomous system is a moving sensor network that collects data continuously, pro-actively, and in many instances intentionally to improve its performance and achieve its mission\u2019s objectives. We will put aside the resource-constrained environment of an autonomous platform \u2013 be it a hardware or a software agent, since this will be the challenge we will discuss next. For now, we will focus on the relationship between the agent\u2019s sensors and the environment. Many sensors will need to operate continuously. They can be operating even when they are not used by the system. This is particularly the case when a group of sensors are operating on the same switch; thus, switching one of them off would simply switch every sensor connected to the switch off. This raises an attractive offer for the wider context that the autonomous agent is operating within to leverage these data. For example, while a Google car is moving, it may have a temperature sensor to adjust the air conditioning system inside the car. If the air conditioning system is switched off, this temperature sensor can still be useful to transmit to the intelligent transportation network localised temperature information that can be integrated across the network to offer a real-time environmental picture of the transportation network. The above example imposes a big data challenge, when to allow for this data to be transmitted and when to prohibit transmission? On the one hand, transmitting the data benefits the wider system. On the other hand, it overloads the car\u2019s battery as a result of the extra energy required to transmit these data. Moreover, it opens trust challenges. The local temperature of the car may get seen by some as a not-threatening privacy data and get transmitted to third parties. A situation that can create security and privacy hazards, whereby the localised temperature can be used as a heat-signature for tracking the car by an entity that does have a privilege to do so and may not be allowed to recieve GPS information from the car. A second factor to consider in this challenge is related to the words \u2018pro-actively and intentionally\u2019. The autonomous agent needs to decide which data is useful for its own context. In a dynamic environment where the situation is changing continuously, to decide which data is more useful to get, the autonomous entity needs to continuously be listening to all its sensors, processing the information and making a decision on the \u2018value\u2019 of the data so that it is able to pro-actively decide which sensor needs to be targeted for more data and to intentionally decide which decision is a higher priority at this point of time and the data needed for this decision. The problem above is very complex. To allow the system to continuously monitor all of its sensors, the system may need to reduce the sample rate for those sensors that may not be important at one point of time, then dynamically adjust the sampling rate as they become important. This is a very challenging problem. To automatically adapt the data acquisition strategy in a sensor network raises all sorts of big data problems, from the fact that the data arrives with different level of noise, the environment is dynamic and concepts change over time, to issues of sensor reliability and the trust-level associated with each sensor. 2) Load-Balancing and Value Challenge: Almost all TASs would have physical constraints in terms of memory and processing capacity. This resource-constrained environment compounds the complexity of too much available data, and the too little knowledge that we can draw out of it. A TAS, similar to a human, encounters data as it is operating that may not be useful for itself, but for others in the environment. Imagine two robots, one is collecting tomatoes and the other is collecting weeds. The robot collecting the tomatoes may sense the existence of weeds. Whether or not it should send this information to the other robot or not would depend on many factors. However, even the decision itself raises the question of how to balance the load on its memory, processing capacity, and battery life in these situations? The above question is a classic question in autonomous systems, but big data makes the question even more demanding. The data the TAS collects, even unintentionally, may hide a great deal of values to the system. The amount of processing and resources to be allocated for this task necessitate a level of processing that can threaten the survivability of the system in a harsh operating environment. Nevertheless, ignoring this information can threaten even more the survivability of this system. 3) Trust-Awareness Cognitive Challenge: For an autonomous system to be trusted, it can\u2019t focus purely on its primary mission as it needs to make every interaction it is involved within as part of its mission. This increases the data load on the system and creates higher than ever demands on the system to process these data in real-time. The primary challenge here is related to velocity, veracity and value. An agent that is acting in a real-time environment needs to mine the data it is receiving very quickly so that its actions take into account any patterns that have arisen in the moments before actions are made. A real-time situation is dynamic by nature. The changing situation needs to integrate its current states with new information. This integration process can be very expensive. On the one level it is a classic information fusion and belief update problem. On another level, it can trigger the activation of almost every component of a self-governing system. For example, the system may realise it needs to self-optimize in response to a\n27\nself-diagnosed failure in one of its sensors, while simultaneously the self-healing module is attempting to recover the data through self-organising the rest of the sensor network. The synchronization of process and action in real-time is one of the grand challenges of TAS. 4) Trusted Swarm Challenge: A TAS does not work in isolation of other autonomous systems in the environment. Trust offer a path for autonomous systems to manage the complexities discussed above in the same way trust reduces complexity in a social system. It allows for delegation as a mechanism to manage complexity and distribute load among the system\u2019s components. In the previous challenge, we discussed an example which involved two types of complexity that the agent is faced with. One is related to the amount of processing an agent needs to do to synchronise its action production with a fast interaction. The second is related to loss of information as a result of sensor failure or a conscious decision by the agent. In any of these situations, if the autonomous system trusts another autonomous system, the former can use the latter to overcome some of these challenges, assuming that the latter can do the job. The above example focuses on a two-entity interaction, but the true benefits from trust becomes clearer when it happens within a swarm, whereby a whole lot of delegations can occur in the system among the trusted autonomous agents so that overall mission success is maximized. An example of this would be apparent in the mining industry where a swarm of machines need to cooperate to maximize the probability of discovering a suitable place to mine. The degree of coordination and delegation that occur in this example dramatically increase the data flow among the agents, whether these data are communicated directly through direct communications channels or indirectly through behavioural changes to signal a need for help. Again, this problem raises big data challenges because of value, velocity and veracity. There is a significant value add for the agents to cooperate in situations such as those described above to maximize the overall mission success of the swarm. These interactions are not free of complexity as the situation can be changing fast introducing a great deal of velocity challenges, and the fast sampling rate can be an extreme source of veracity which can cause instability in any inferring mechanism used in the system. 5) Trusted Cyborg Challenge: An artificial TAS \u2013 such as a software agent or a robot \u2013 is expected to work in harmony with humans. With appropriate use of advanced AI techniques, the artificial and human entities need to work as a single entity, an interdependency that is known as symbiosis. The challenges arises on how to make the silicon and biological agents work together as one; that is, establishing a truly symbiotic relationship to allow the machine and the human to meld as one entity. The coupling of the two creates a new type of agents, a Cyborg (human-machine coupled computational decision making engine). The machine needs to understand the human. However, the complexity arising from the diversity of human attitudes and personalities is huge. One possible mechanism to manage this complexity is to directly obtain objective data on the human to manage the ambiguity that comes with human communication. The data needs to be collected through mechanisms that do not interfere with the performance of the human on the job. The use of body sensors and passive external sensors such as cameras and microphones can offer an unprecedented amount of data to allow this integration to occur. The Cyborg\u2019s brain needs to have efficient interfaces between the biological and silicon brains so that both human and machine work seamlessly together as a single entity. We are not suggesting here to connect human brains to silicon or any type of science fiction. The suggestion is to integrate the decision making between the two in the same way two close friends work together to solve a problem. The Cyborg\u2019s brain needs on-board data processing. The real-time and volume of the data necessitate a very efficient use of the hardware. Technologies similar to those discussed in Section III such as neuromorphic computing, FPGA and other implementations of neural networks on chips can be very attractive. Equally important here is the need for real-time signal processing techniques capable of sensing the context to improve signal cleaning, and adapt sampling rate when and as needed, with appropriate dynamic calibration models that can fuse different sources of data from the human and dynamically adapt the parameters and structure of the model in response to changes in the environment. 6) Trusted Cyborg Swarm Challenge: A group of Cyborgs make a Cyborg swarm. The complexity of a network of Cyborg swarms, an extension of a problem we called in our previous research as Cognitive Cyber Symbiosis (CoCyS) [12], [55], needs to be managed to allow this decision network of Cyborgs to operate efficiently. CoCyS is a decision network of humans and machines. A Cyborg swarm is a network where each node is a Cyborg\u2019s brain. A Cyborg swarm is the next generation swarm intelligence system, where each human can look after a swarm of artificial TASs, and the Cyborg population works together as a swarm to solve far reaching complex. Take for example a situation like a post-disaster recovery, where a tsunami has destroyed a village. Each site may have a Cyborg consisting of a human and a swarm of artificial TASs. The Cyborg network needs to coordinate activities, share information, and work as one team to assist the village in recovery. Such a network should recover from the disaster a few orders of magnitude faster than what we do today, as a result of the close integration of human and machine. The challenges of forming such a network define scientific frontiers of this century. On the one hand, we have computational challenges to design appropriate AI systems that can handle this level of distributed control and complex and dynamic context. On the other hand, the amount of data in a Cyborg swarm is huge. These data are not just useful for\n28\nthe swarm to make decisions for recovery. They are also useful for future disaster situations, where it is important that these data get collected from the swarm as well.\nPutting the six challenges above together, theoretical and practical aspects of the big data challenges for trusted autonomy draw a roadmap for the research needed to overcome these problems in practice.\nREFERENCES [1] M. R. Delgado, R. H. Frank, and E. A. Phelps, \u201cPerceptions of moral character modulate the neural systems of reward during the trust game,\u201d Nature\nneuroscience, vol. 8, no. 11, pp. 1611\u20131618, 2005. [2] M. Deutsch, The resolution of conflict: Constructive and destructive processes. Yale University Press, 1977. [3] \u2014\u2014, \u201cCooperation and trust: Some theoretical notes.\u201d in Proceedings of Nebraska Symposium on Motivation, M. R. Jones, Ed. Univer. Nebraska\nPress, 1962. [4] N. Luhmann, H. Davis, J. Raffan, and K. Rooney, Trust; and, Power: two works by Niklas Luhmann. Wiley Chichester, 1979. [5] C. Wells, \u201cTrust, gender, and race in the workplace,\u201d Journal of Social Behavior and Personality, vol. 16, no. 1, pp. 115\u2013126, 2001. [6] D. S. Reina and M. L. Reina, \u201cTrust and betrayal in the workplace building effective relationships in your organization,\u201d Advances in Developing\nHuman Resources, vol. 2, no. 1, pp. 121\u2013121, 2000. [7] E. M. Whitener, S. E. Brodt, M. A. Korsgaard, and J. M. Werner, \u201cManagers as initiators of trust: An exchange relationship framework for understanding\nmanagerial trustworthy behavior,\u201d Academy of management review, vol. 23, no. 3, pp. 513\u2013530, 1998. [8] M. D. Spector and G. E. Jones, \u201cTrust in the workplace: Factors affecting trust formation between team members,\u201d The Journal of social psychology,\nvol. 144, no. 3, pp. 311\u2013321, 2004. [9] S. Marsh, \u201cFormalising trust as a computational concept,\u201d PhD Thesis, 1994.\n[10] I. Pinyol and J. Sabater-Mir, \u201cComputational trust and reputation models for open multi-agent systems: a review,\u201d Artificial Intelligence Review, vol. 40, pp. 1\u201325, 2013. [11] E. Petraki and H. Abbass, \u201cOn trust and influence: A computational red teaming game theoretic perspective,\u201d in Computational Intelligence for Security and Defense Applications (CISDA), 2014 Seventh IEEE Symposium on. IEEE, 2014, pp. 1\u20137. [12] H. A. Abbass, E. Petraki, K. Merrick, J. Harvey, and M. Barlow, \u201cTrusted autonomy and cognitive cyber symbiosis: Open challenges,\u201d Cognitive Computation, pp. 1\u201324, 2015. [13] H. Abbass, G. Greenwood, and E. Petraki, \u201cThe n-player trust game and its replicator dynamics,\u201d Evolutionary Computation, IEEE Transactions on, To Appear. [14] F. F. Alruwaili and T. A. Gulliver, \u201cSecsdlc: A practical life cycle approach for cloud-based information security,\u201d IJRCCT, vol. 4, no. 2, pp. 095\u2013107, 2015. [15] J. Hinchman, M. Clark, J. Hoffman, B. Hulbert, A. Subcontractor, and C. Snyder, \u201cTowards safety assurance of trusted autonomy in air force flight critical systems,\u201d in Computer Security Applications Conference, Layered Assurance Workshop, 2012. [16] J. Sabater and C. Sierra, \u201cReview on computational trust and reputation models,\u201d Artificial Intelligence Review, vol. 24, no. 1, pp. 33\u201360, 2005. [17] A. Josang, R. Ismail, and C. Boyd, \u201cA survey on trust and reputation systems for online service provision,\u201d Decision Support Systems, vol. 43, no. 2,\npp. 618\u2013644, 2007. [18] H. Yu, Z. Shen, C. Leung, C. Miao, and V. Lesser, \u201cA survey of multi-agent trust management systems,\u201d IEEE Access, vol. 1, pp. 35\u201350, 2013. [19] S. Marsh, \u201cOptimism and pessimism in trust.\u201d The Ibero-American Conference on Artificial Intelligence, 1994, Conference Paper. [20] N. Griffiths and M. Luck, \u201cCoalition formation through motivation and trust.\u201d AAMAS 2003, 2003, Conference Paper, pp. 17\u201324. [21] W. T. Luke Teacy, J. Patel, N. Jennings, and M. Luck, \u201cTravos: trust and reputation in the context of inaccurate information sources,\u201d Autonomous\nAgents and Multi Agent Systems, vol. 12, pp. 183\u2013198, 2006. [22] A. Abdul-Rahman and S. Hailes, \u201cSupporting trust in virtual communities.\u201d The Hawaii International Conference on System Sciences, 2000, Conference\nPaper. [23] V. Cahill, E. Gray, M. Seigneur, C. Jensen, Y. Chen, B. Shand, N. Dimmock, A. Twigg, J. Bacon, C. English, W. Wagealla, S. Terzis, P. Nixon,\nG. di Marzo Serugendo, C. Bryce, M. Carbone, K. Krukow, and M. Nielsen, \u201cUsing trust for secure collaboration in uncertain environments,\u201d Pervasive Computing, vol. 2, no. 3, pp. 52\u201361, 2003. [24] A. Josang, \u201cTrust-based decision making for electronic transactions.\u201d The Fourth Nordic Workshop on Secure Computer Systems, 1999, Conference Paper. [25] N. Griffiths, \u201cA fuzzy approach to reasoning with trust, distrust and insufficient trust.\u201d CIA 2006, 2006, Conference Paper, pp. 360\u2013374. [26] A. Aref and T. Tran, \u201cUsing fuzzy logic and q-learning for trust modelling in multi-agent systems.\u201d The 2014 Federated Conference on Computer\nScience and Information Systems, 2014, Conference Paper, pp. 59\u201366. [27] R. Levien, Attack-resistant trust metrics, 2009, pp. 121\u2013132. [28] C. N. Ziegler and G. Lausen, \u201cSpreading activation models for trust propagation.\u201d The 2004 IEEE International Conference on e-Technology,\ne-Commerce and e-Service, 2004, Conference Paper, pp. 83\u201397. [29] G. Mahoney, W. Myrvold, and G. Shoja, \u201cGeneric reliability trust model,\u201d in The Third Annual Conference on Privacy, Security and Trust, 2005. [30] A. Conn, N. Gould, and P. Toint, Trust-region methods. Philadelphia, PA: Society for Industrial and Applied Mathematics and Mathematical\nProgramming Society, 2000. [31] Y. Yuan, \u201cA review of trust region algorithms for optimisation.\u201d Edinburgh: The Fourth International Congress on Industrial and Applied Mathematics,\n1999. [32] Z. Giorgos, \u201cCollaborative reputation mechanisms for online communities,\u201d Masters Thesis, 1999. [33] L. Xiong and L. Liu, \u201cPeertrust: Supporting reputation-based trust for peer-to-peer electronic communities,\u201d IEEE Transactions on Knowledge and\nData Engineering, vol. 16, pp. 843\u2013857, 2004. [34] J. Hu, Q. Wu, and B. Zhou, \u201cFctrust: A robust and efficient feedback credibility-based distributed p2p trust model,\u201d in The Ninth IEEE International\nConference for Young Computer Scientiests, 2008. [35] Y. Zhang, S. Chen, and G. Yang, \u201cSftrust: a double trust metric based trust model in unstructured p2p systems,\u201d in The IEEE International Symposium\non Parallel and Distributed Processing, 2009. [36] C. M. Jonker and J. Treur, \u201cFormal analysis of models for the dynamics of trust based on experiences.\u201d MAAMAW 99, 1999, Conference Paper, pp.\n120\u2013130. [37] X. Fan, S. Oh, M. McNeese, J. Yen, H. Cuevas, L. Strater, and M. Endsley, \u201cThe influence of agent reliability on trust in human-agent collaboration,\u201d\nin The fifteenth european conference on cognitive ergonomics, 2008. [38] M. Wooldridge, Reasoning about rational agents. Cambridge, MA: The MIT Press, 2000. [39] B. Jarvis and L. Jain, \u201cTrust in lora: towards a formal definition of trust in bdi agents.\u201d KES 2006, 2006, Conference Paper, pp. 458\u2013463. [40] T. Taibi, \u201cIncorporating trust into the bdi architecture,\u201d International Journal of Artificial Intelligence and Soft Computing, vol. 2, no. 3, pp. 223\u2013230,\n2010.\n29\n[41] A. Koster, M. Scholrlemmer, and J. Sabater-Mir, \u201cOpening the black box of trust: reasoning about trust models in a bdi agent,\u201d Journal of Logic and Computation, vol. 23, no. 1, pp. 25\u201358, 2013. [42] G. Xu, C. Xu, X. Tian, L. Zhang, X. Li, and W. Li, \u201cPso-tps: An optimal trust path selection algorithm based on particle swarm optimisation in small world network,\u201d in The Second International Conference on Cloud and Green Computing, 2012. [43] W. Huang, Z. Deng, R. Li, and X. Tang, \u201cTrust-based particle swarm optimisation for grid task scheduling,\u201d Applied Mechanics and Materials, vol. 239-240, pp. 1331\u20131335, 2013. [44] K. Merrick and M. L. Maher, Motivated reinforcement learning: curious characters for multiuser games. Berlin: Springer, 2009. [45] C. Burnett, T. Norman, and K. Sycara. The 22nd International Joint Conference on Artificial Intelligence, 2011, Conference Paper, pp. 115\u2013120. [46] C. M. Jonker, S. Meijer, D. Tykhonov, and T. Verwaart, \u201cModelling and simulation of selling and deceit for the trust and tracing game.\u201d The Trust\nin Agent Societies Workshop, 2005, Conference Paper, pp. 78\u201390. [47] Z. Sun, G. Finnie, and J. Barker, \u201cTrust and deception in multi-agent trading systems: a logical viewpoint.\u201d The 11th Americas Conference on\nInformation Systems, 2005, Conference Paper, pp. pp 1020\u20131026. [48] G. J. Hofstede, C. M. Jonker, S. Meijer, and T. Verwaart, \u201cModelling trade and trust across cultures.\u201d The Fourth International Conference on Trust\nManagement and iTrust, 2006, Conference Paper, pp. 120\u2013134. [49] G. J. Hofstede, C. M. Jonker, and T. Verwaart, \u201cA multi-agent model of deceit and trust in intercultural trust.\u201d The International Conference on\nComputational Collective Intelligence, 2009, Conference Paper. [50] A. Das, M. M. Islam, and G. Sorwar, \u201cDynamic trust model for reliable transactions in multi-agent systems,\u201d in The Thirteenth International Conference\non Advanced Communication Technology, 2011. [51] K. Fullam, T. Klos, G. Muller, J. Sabater, A. Scholosser, Z. Topol, S. Barber, J. Rosenschein, L. Vercouter, and M. Voss, \u201cA specification of the agent\nreputation and trust (art) testbed: experimentation and competitition for trust in agent societies.\u201d Autonomous Agents and Multi Agent Systems, 2005, Conference Paper, pp. 512\u2013518. [52] G. Leu and H. A. Abbass, \u201cA multi-disciplinary review of knowledge acquisition methods: From human to autonomous eliciting agents,\u201d KnowledgeBased Systems, To Appear. [53] P. Russom et al., \u201cBig data analytics,\u201d TDWI Best Practices Report, Fourth Quarter, 2011. [54] Y. Jin and B. Hammer, \u201cComputational intelligence in big data [guest editorial],\u201d Computational Intelligence Magazine, IEEE, vol. 9, no. 3, pp. 12\u201313,\n2014. [55] H. Abbass, Computational Red Teaming: Risk Analytics of Big-Data-to-Decisions Intelligent Systems. Springer Verlag, 2015. [56] C. Moron, C. Cabrera, A. Moron, A. Garcia, and M. Gonzalez, \u201cMagnetic sensors based on amorphous ferromagnetic materials: A review,\u201d Sensors,\nvol. 15, no. 11, pp. 28 340\u201328 366, 2015. [57] C. Bisdikian, \u201cOn sensor sampling and quality of information: A starting point,\u201d in Pervasive Computing and Communications Workshops, 2007.\nPerCom Workshops \u201907. Fifth Annual IEEE International Conference on, March 2007, pp. 279\u2013284. [58] S. Patel, H. Park, P. Bonato, L. Chan, and M. Rodgers, \u201cA review of wearable sensors and systems with application in rehabilitation,\u201d Journal of\nNeuroEngineering and Rehabilitation, vol. 9, no. 1, pp. 1\u201317, 2012. [Online]. Available: http://dx.doi.org/10.1186/1743-0003-9-21 [59] S. C. Mukhopadhyay, \u201cWearable sensors for human activity monitoring: A review,\u201d Sensors Journal, IEEE, vol. 15, no. 3, pp. 1321\u20131330, March 2015. [60] Athos. (2016, 02) The world\u2019s first smart fitness apparel that measures muscle activity and heart rate all in real time. accessed 24.02.2016. [Online].\nAvailable: https://www.liveathos.com/ [61] H. Banaee, M. U. Ahmed, and A. Loutfi, \u201cData mining for wearable sensors in health monitoring systems: A review of recent trends and challenges,\u201d\nSensors, vol. 13, no. 12, pp. 17 472\u201317 500, 2013. [Online]. Available: http://www.mdpi.com/1424-8220/13/12/17472 [62] M. Mirzaei and M. Sawan, \u201cMicroelectronics-based biosensors dedicated to the detection of neurotransmitters: A review,\u201d Sensors, vol. 14, no. 10,\npp. 17 981\u201318 008, 2014. [Online]. Available: http://www.mdpi.com/1424-8220/14/10/17981 [63] A. J. Bandodkar and J. Wang, \u201cNon-invasive wearable electrochemical sensors: a review,\u201d Trends in Biotechnology, vol. 32, no. 7, pp. 363 \u2013 371,\n2014. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0167779914000699 [64] M. Stoppa and A. Chiolerio, \u201cWearable electronics and smart textiles: A critical review,\u201d Sensors, vol. 14, no. 7, p. 11957, 2014. [Online]. Available:\nhttp://www.mdpi.com/1424-8220/14/7/11957 [65] S. Sprager and M. B. Juric, \u201cInertial sensor-based gait recognition: A review,\u201d Sensors, vol. 15, no. 9, p. 22089, 2015. [Online]. Available:\nhttp://www.mdpi.com/1424-8220/15/9/22089 [66] J. Jeon, H.-B.-R. Lee, and Z. Bao, \u201cFlexible wireless temperature sensors based on ni microparticle-filled binary polymer composites,\u201d Advanced\nMaterials, vol. 25, no. 6, pp. 850\u2013855, 2013. [67] Beurer. (2016) Ft90 - contactless temperature sensor. accessed 26.02.2016. [Online]. Available: https://www.beurer.com/web/en/products/body\ntemperature/body temperature/FT-90 [68] F. Kovacs, M. Torok, and I. Habermajer, \u201cA rule-based phonocardiographic method for long-term fetal heart rate monitoring,\u201d Biomedical Engineering,\nIEEE Transactions on, vol. 47, no. 1, pp. 124\u2013130, Jan 2000. [69] Q. Zhu, J. Spinelli, and G. Carlson, \u201cAccelerometer-based heart sound detection for autocapture,\u201d Nov. 18 2003, uS Patent 6,650,940. [Online].\nAvailable: http://www.google.com/patents/US6650940 [70] A. Alzahrani, S. Hu, V. Azorin-Peris, L. Barrett, D. Esliger, M. Hayes, S. Akbare, J. Achart, and S. Kuoch, \u201cA multi-channel opto-electronic\nsensor to accurately monitor heart rate against motion artefact during exercise,\u201d Sensors, vol. 15, no. 10, p. 25681, 2015. [Online]. Available: http://www.mdpi.com/1424-8220/15/10/25681 [71] S. M. A. Salehizadeh, D. Dao, J. Bolkhovsky, C. Cho, Y. Mendelson, and K. H. Chon, \u201cA novel time-varying spectral filtering algorithm for reconstruction of motion artifact corrupted heart rate signals during intense physical activities using a wearable photoplethysmogram sensor,\u201d Sensors, vol. 16, no. 1, p. 10, 2016. [Online]. Available: http://www.mdpi.com/1424-8220/16/1/10 [72] J.-H. Park, D.-G. Jang, J. W. Park, and S.-K. Youm, \u201cWearable sensing of in-ear pressure for heart rate monitoring with a piezoelectric sensor,\u201d Sensors, vol. 15, no. 9, p. 23402, 2015. [Online]. Available: http://www.mdpi.com/1424-8220/15/9/23402 [73] S. Garmin. (2016) accessed 24.02.2016. [Online]. Available: http://www.dcrainmaker.com/2015/11/garmin-hrm-swimtri-review.html [74] RAF. (2016) Optical wrist based heart rate versus chest straps. accessed 24.02.2016. [Online]. Available: http://www.shutuplegs.org/\noptical-hr-versus-chest-strap/ [75] G. EGI. (2016, 02) Clinical geodesic eeg system 400. accessed 22.02.2016. [Online]. Available: http://www.egi.com/clinical-division/\nclinical-division-clinical-products/ges-400-series [76] H. A. Abbass, J. Tang, R. Amin, M. Ellejmi, and S. Kirby, \u201cAugmented cognition using real-time eeg-based adaptive strategies for air traffic control,\u201d\nProceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 58, no. 1, pp. 230\u2013234, 2014. [77] H. A. Abbass, J. Tang, M. Ellejmi, and S. Kirby, \u201cVisual and auditory reaction time for air traffic controllers using quantitative electroencephalograph\n(qeeg) data,\u201d Brain Informatics, vol. 1, no. 1, pp. 39\u201345, 2014. [78] I. Emotiv. (2016, 02) Emotiv insight - brain activity tracker. accessed 22.02.2016. [Online]. Available: https://emotiv.com/insight.php [79] E. Emotiv. (2016, 02) A high resolution, multi-channel eeg system. accessed 22.02.2016. [Online]. Available: https://emotiv.com/epoc.php [80] T. Nihonkohden. (2016, 02) Trackit - mobile long-term eeg. accessed 22.02.2016. [Online]. Available: http://www.nihonkohden.de/products/neurology/\neeg/mobile-long-term-eeg/trackit.html?L=1 [81] S. Compumedics. (2016, 02) Synamps 2/rt 256-channel eeg/ep/erp. accessed 22.02.2016. [Online]. Available: http://compumedicsneuroscan.com/\nsynamps-rt-256-channel-eegeperp/\n30\n[82] eegoMylab antNeuro. (2016, 02) eego mylab - the new frontier in multimodal brain research. accessed 22.02.2016. [Online]. Available: http://www.ant-neuro.com/products/eego mylab [83] G. Compumedics. (2016, 02) Grael 32-channel eeg/erp amplifier. accessed 22.02.2016. [Online]. Available: http://compumedicsneuroscan.com/ grael-eegerp-amplifier/ [84] N. MindMedia. (2016) Nexus-32 multimodal qeeg system. accessed 04.03.2016. [Online]. Available: http://www.mindmedia.info/CMS2014/products/ systems/nexus-32 [85] Mitsar. (2016, 02) Mitsar eeg 201/202 compare. accessed 22.02.2016. [Online]. Available: http://www.mitsar-medical.com/eeg-machine/ eeg-amplifier-compare/ [86] N. Nohonkohden. (2016, 02) Neurofax eeg-1200. accessed 22.02.2016. [Online]. Available: http://www.nihonkohden.de/products/neurology/eeg/ research/eeg-1200.html?L=1 [87] B. Neurovirtual. (2016, 02) Bwiii eeg plus icu brain monitor. accessed 22.02.2016. [Online]. Available: http://neurovirtual.com/equipment/ bwiii-eeg-plus-ltmicu/ [88] T. Neuroconn. (2016, 02) Measuring and modulating brain activity. accessed 22.02.2016. [Online]. Available: http://www.neuroconn.de/thera prax q-eeg en/ [89] G. EGI. (2016, 02) Clinical geodesic eeg mobile (gem) 100. accessed 22.02.2016. [Online]. Available: http://www.egi.com/clinical-division/ clinical-division-clinical-products/clinical-division-geodesic-eeg-mobile-100 [90] encephalan Medicom. (2016, 02) High-quality eeg recording and freedom of movement. accessed 22.02.2016. [Online]. Available: http://www.medicom-mtd.com/eng/Products/eegr.htm [91] Neurowerk. (2016, 02) Neurowerk eeg systems. accessed 22.02.2016. [Online]. Available: http://www.neurowerk.de/fileadmin/user upload/downloads english/NEUROWERK EEG EN.pdf [92] nuamps compumedics. (2016, 02) Nuamps 40-channel eeg/erp amplifier. accessed 22.02.2016. [Online]. Available: http://compumedicsneuroscan.com/ nuamps-eegerp-amplifier/ [93] T. Deymed. (2016, 02) Advanced eeg system built for demanding clinical and research use. accessed 22.02.2016. [Online]. Available: http://www.deymed.com/products-a-services/truscan-eeg/product-info [94] eegoSports antNeuro. (2016, 02) eego sports - the total mobility solution. accessed 22.02.2016. [Online]. Available: http://www.ant-neuro.com/ products/eego sports [95] B. Neurovirtual. (2016, 02) Bwmini ambulatory eeg. accessed 22.02.2016. [Online]. Available: http://neurovirtual.com/equipment/ bwmini-ambulatory-eeg/ [96] M. NeuroSky. (2016, 02) Neurosky mindwave mobile headset kit. accessed 22.02.2016. [Online]. Available: http://neurosky.com/biosensors/eeg-sensor/ [97] M. Louwerse and S. Hutchinson, \u201cNeurological evidence linguistic processes precede perceptual simulation in conceptual processing,\u201d Frontiers in\nPsychology, vol. 3, no. 385, 2012. [Online]. Available: http://www.frontiersin.org/cognitive science/10.3389/fpsyg.2012.00385/abstract [98] T. Fraga, M. Pichiliani, and D. Louro, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for\neInclusion. Berlin, Heidelberg: Springer Berlin Heidelberg, 2013, ch. Experimental Art with Brain Controlled Interface, pp. 642\u2013651. [99] B. Macrotellect. (2016, 02) accessed 22.02.2016. [Online]. Available: http://o.macrotellect.com/en/brainlink/principle.aspx\n[100] S. Charara. (2015, 04) Muse review: The brain sensing headband that knows you\u2019re stressed. accessed on 22.02.2016. www.wearable.com. [Online]. Available: http://www.wareable.com/wearable-tech/muse-brain-sensing-headband-review-938 [101] M. Interaxon. (2016, 02) Muse - the brain sensing headband. accessed on 22.02.2016. [Online]. Available: http://www.choosemuse.com/ what-does-muse-measure/ [102] Somnomedics. (2016, 02) Technical data - somnoscreen eeg 32. accessed 22.02.2016. [Online]. Available: http://somnomedics.eu/products/ neurologic-applications-up-to-58-channels/technical-data-somnoscreentm-plus-eeg-32/ [103] Neurosoft. (2016, 02) Neuron spectrum am - ambulatory wireless eeg/psg recorder. accessed 22.02.2016. [Online]. Available: http: //neurosoft.com/en/catalog/view/id/2107/sid/1 [104] B. Deymed. (2016, 02) Clinical grade neurofeedback system dedesign for clinicians wishing to use the highigh standard for neurotherapy. accessed 22.02.2016. [Online]. Available: http://www.deymed.com/products-a-services/bfb-pro/specifications [105] A. Cardio02line. (2016, 02) Portable electrocardiograph with thermal printing system. accessed 22.02.2016. [Online]. Available: http: //eng.cardioline.com/prodotti-cardioline/ar600adv/ [106] T. Cardioline. (2016, 02) Cardioline touchecg tablet hd+. accessed 22.02.2016. [Online]. Available: http://eng.cardioline.com/prodotti-cardioline/ touchecg-tablet-hd/ [107] U. TSE. (2016, 02) Electrocardiograph ucard - 200. accessed 22.02.2016. [Online]. Available: http://www.tse.cz/images/stories/download/9.pdf [108] S. Nasan. (2016, 02) Pc based ecg machine with simultaneous acquisition. accessed 22.02.2016. [Online]. Available: http://www.nasanmedical.com/ simul-g.html [109] E. Longfian. (2016, 02) Monochrome 12 channel ecg. accessed 22.02.2016. [Online]. Available: http://www.longfian.com/en/product/product37.html [110] E.-G. Nasan. (2016, 02) Dsp based single channel ecg machine. accessed 22.02.2016. [Online]. Available: http://www.nasanmedical.com/esy-g1.html [111] A. Nasan. (2016, 02) 3 channel ecg machine with measurement interpretation. accessed 22.02.2016. [Online]. Available: http://www.nasanmedical. com/a-saan-1003.html [112] R. Nasiff. (2016, 02) Nasiff cardiocard pc based resting ecg system. accessed 22.02.2016. [Online]. Available: https://nasiff.com/resting.html [113] C. SpaceLab. (2016, 02) Cardiodirect 12 usb. accessed 22.02.2016. [Online]. Available: http://www.spacelabshealthcare.com/diagnostic-cardiology/ resting-ecg/cardiodirect-12-usb#.VsrctmoViOV [114] C. Customed. (2016, 92) Custocardio 100/110 usb. accessed 22.02.2016. [Online]. Available: https://www.customed.de/includes/customed% 20documents/TFL/TFL-0007-custo-cardio-100-110-USB-24-03-2010-DK-0963-DE-004-LEN.pdf [115] K. Kalamed. (2016, 02) High-end 12-channel electrocardiograph for resting and stress ecg. accessed 22.02.2016. [Online]. Available: http://www.kalamed.de/en-us/produkte/ekg/kes-121l.aspx [116] \u2014\u2014. (2016, 02) High quality 12-ch ecg-recorder with usb or wifi connection to pc or android app. accessed 22.02.2016. [Online]. Available: http://www.kalamed.de/en-us/produkte/pc-ekg/kec-1000.aspx [117] Labtech. (2016, 02) Ec-12rm - resting smartphone-based wireless electrocardiograph. accessed 22.02.2016. [Online]. Available: http: //www.labtech.hu/products/netecg/ec-12rm [118] C. Customed02. (2016) Custo cardio 200 usb/bt. accessed 22.02.2016. [Online]. Available: https://www.customed.de/includes/customed%20documents/ TFL/TFL-0011-custo-cardio-200-USB-BT-24-03-2010-DK-0967-DE-004-LEN.pdf [119] E.-V. Eccosur. (2016, 02) Sistema de registro electrocardiografico de esfuerzo de 12 derivaciones basado en pc. accessed 23.02.2016. [Online]. Available: http://www.eccosur.com/product.php?inc=er [120] T. Thor. (2016, 02) Thoriax - pc ecg. accessed 23.02.2016. [Online]. Available: http://thorlabor.com/en/products/cardiac-medical-devices/thoriax-pc-ecg/ [121] C. SpaceLab. (2016, 02) Cardiodirect 12s. accessed 22.02.2016. [Online]. Available: http://www.spacelabshealthcare.com/diagnostic-cardiology/ stress-testing/cardiodirect-12s#.VsrfQWoViOV [122] C. Cardioline. (2016, 02) Cubestress hd+ series. accessed 22.02.2016. [Online]. Available: http://eng.cardioline.com/prodotti-cardioline/ system-cubestress-hd-mit/ [123] C. Cardionics. (2016, 02) The cartouch. accessed 23.02.2016. [Online]. Available: http://www.cardionics.eu/English/cartouchE.html\n31\n[124] E.-R. Labtech. (2016, 02) Ec-12rs 12 channel resting and stress test ecg system. accessed 23.02.2016. [Online]. Available: http: //www.labtech.hu/products/resting-and-stress-ecg-systems/ec-12r-s.html [125] C. Amedtec. (2016, 02) Cardiopart 12 blue/blue-p. accessed 23.02.2016. [Online]. Available: http://www.amedtec.de/downloads/CardioPart%2012% 20Blue en.pdf [126] T. Thor. (2016, 02) Thoriax home ecg - portable ecg monitor. accessed 23.02.2016. [Online]. Available: http://thorlabor.com/en/products/ cardiac-medical-devices/thoriax-home-ecg/ [127] W. Boucsein, Electrodermal activity. Springer Science & Business Media, 2012. [128] R. W. Picard, S. Fedor, and Y. Ayzenberg, \u201cMultiple arousal theory and daily-life electrodermal activity asymmetry,\u201d Emotion Review, vol. 8, no. 1, pp. 62\u201375, 2016. [Online]. Available: http://emr.sagepub.com/content/8/1/62.abstract [129] Thoughttechnology. (2016, 02) Technical note series - skin conductance sensor (sa9309m). accessed 23.02.2016. [Online]. Available: http: //www.thoughttechnology.com/sciencedivision/media/pdf/STN0008-00%20-%20%20SA9309M%20Skin%20Conductance%20Technical%20Notes.pdf [130] W. B. Mendes, Assessing autonomic nervous system activity. Guilford Press, 2009, pp. 118\u2013147. [131] Empatica. (2016, 02) The embrace journey - from the idea through the crowdfunding to the final product. [Online]. Available: https://www.empatica.com/embrace-watch-about [132] Neulog. (2016, 02) Neulog - gsr logger sensor nul-217. accessed 23.02.2016. [Online]. Available: https://neulog.com/gsr/ [133] Shimmersensing. (23.02.2016, 02) Shimmer3 gsr+ unit. [Online]. Available: http://www.shimmersensing.com/shop/shimmer3-wireless-gsr-sensor# specifications-tab [134] Mindmedia. (2016, 02) Skin conductance sensor. accessed 23.02.2016. [Online]. Available: http://www.mindmedia.info/CMS2014/products/sensors/ skin-conductance-sensor [135] G. TMSI. (2016, 02) Gsr sensor. accessed 23.02.2016. [Online]. Available: http://www.tmsi.com/products/accessories/item/gsr-sensor [136] Mindfield. (2016, 02) Mindfield esense skin response. accessed 23.02.2016. [Online]. Available: https://www.mindfield.de/en/biofeedback/products/ esense/esense-skin-response [137] Angelsensor. (2016, 02) Angelsenros. accessed 24.02.2016. [Online]. Available: http://angelsensor.com/ [138] A. Apple. (2016, 02) To wear it is to love it. accessed 24.02.2016. [Online]. Available: http://www.apple.com/watch/?cid=w-wa-us-kwg-watch-com [139] B. Mybasis. (2016, 02) Basis peak - the ultimate fitness and sleep tracker. accessed 24.02.2016. [Online]. Available: http://www.mybasis.com/ [140] E. series Empatica. (2014) The e4 wristband is a wearable wireless device designed for continuous, real-time data acquisition in daily life. accessed 24.02.2016. [Online]. Available: https://www.empatica.com/e4-wristband [141] Z. Fitbit. (2016, 02) Zip - wireless activity tracker. accessed 24.02.2016. [Online]. Available: https://www.fitbit.com/zip [142] W. Fitbit. (2016, 02) The power of heart rate on your wrist. accessed 24.02.2016. [Online]. Available: https://www.fitbit.com/au/chargehr [143] \u2014\u2014. (2016, 02) The ultimate fitness super watch. accessed 24.02.2016. [Online]. Available: https://www.fitbit.com/au/surge [144] O. Fitbug. (2016, 02) Orb - fitness, sleep and activity tracker. accessed on 24.02.2016. [Online]. Available: https://www.fitbug.com/g/orb?lng=en UK [145] Garmin. (2016, 02) Meet the wearables that help you move a little more each day. accessed 24.02.2016. [Online]. Available: http://explore.garmin.com/en-US/vivo-fitness/ [146] A. Google. (2016, 02) Android wearable devices. accessed 24.02.2016. [Online]. Available: http://www.android.com/wear/ [147] iHealth. ihealth edge - take your fitness to the edge and beyond with this activity + sleep tracker. accessed 24.02.2016. [Online]. Available: https://ihealthlabs.com/fitness-devices/ihealth-edge/ [148] U. Jawbone. (2016) Up is a revolutionary system that guides you every step of the way to a better, healthier you. accessed 24.02.2016. [Online]. Available: https://jawbone.com/up [149] L. LG. (2016, 02) Lg lifeband touch activity tracker - make the world your workout. accessed 24.02.2016. [Online]. Available: http://www.lg.com/au/fitness-and-wearables/lg-FB84-BM [150] S. LG. (2016, 02) Lg g watch (w100) black titan - information when you need it most. accessed 24.02.2016. [Online]. Available: http://www.lg.com/au/fitness-and-wearables/lg-G-WATCH-W100-Black-Titan [151] V. Medisana. (2016) Activity and sleep tracker in one. accessed 24.02.2016. [Online]. Available: http://www.medisana.com/en/Sport/Activity-Tracker/ ViFit-touch-Activity-Tracker-black.html [152] B. Microsoft. (2016) Live healthier and achieve more. accessed 24.02.2016. [Online]. Available: https://www.microsoft.com/microsoft-band/en-au [153] Misfit. (2016, 02) Fitness and sleep monitor. accessed 24.02.2016. [Online]. Available: http://misfit.com/ [154] F. Nike. (2016, 02) Connect and go with nike+. accessed 24.02.2016. [Online]. Available: https://secure-nikeplus.nike.com/plus/products/fuelband/ [155] Pebble. (2016, 02) Pebble smartwasmart series. accessed 24.02.2016. [Online]. Available: https://www.pebble.com/compare [156] N. Razerone. (2016, 02) Survive your world with the razer nabu. accessed 24.02.2016. [Online]. Available: http://www.razerzone.com/nabu [157] W. Razerone. (2016, 02) Nabu watch - live smarter. accessed 24.02.2016. [Online]. Available: http://www.razerzone.com/nabu-watch [158] L. Salutron. (2016) Achieve your health and fitness goals with lifetrak. accessed 24.02.2016. [Online]. Available: http://lifetrakusa.com/ [159] G. Samsung. (2016) accessed 24.02.2016. [Online]. Available: http://www.samsung.com/au/gear-s2/ [160] \u2014\u2014. (2016) accessed 24.02.2016. [Online]. Available: http://www.samsung.com/au/consumer/mobile-phone/wearables/gear/SM-R3500ZKAXSA [161] Sensoriafitness. (2016, 02) A smarter way to run - improve speed, pace, cadence, foot landing and compare your shoes ? all with a sock! accessed 24.02.2016. [Online]. Available: http://www.sensoriafitness.com/ [162] S. Sony. (2016, 02) Live smarter with smartwear. accessed 24.02.2016. [Online]. Available: http://www.sonymobile.com/us/products/smartwear/ [163] F. Striiv. (2016, 02) Striiv - fusion series. accessed 24.02.2016. [Online]. Available: https://www.striiv.com/ [164] P. Withings. (2016) accessed 24.02.2016. [Online]. Available: http://www.withings.com/us/en/products/pulse? [165] G. Withings. (2016) accessed 24.02.2016. [Online]. Available: http://www.withings.com/us/en/products/go [166] W. Elmenreich, Software Technologies for Embedded and Ubiquitous Systems: 5th IFIP WG 10.2 International Workshop, SEUS 2007, Santorini\nIsland, Greece, May 2007. Revised Papers. Berlin, Heidelberg: Springer Berlin Heidelberg, 2007, ch. A Review on System Architectures for Sensor Fusion Applications, pp. 547\u2013559. [Online]. Available: http://dx.doi.org/10.1007/978-3-540-75664-4 57\n[167] S. A. Khamseh, A. K. Sedigh, B. Moshiri, and A. Fatehi, \u201cControl performance assessment based on sensor fusion techniques,\u201d Control Engineering Practice, vol. 49, pp. 14 \u2013 28, 2016. [168] C. Jiang, Y. C. Soh, and H. Li, \u201cSensor and {CFD} data fusion for airflow field estimation,\u201d Applied Thermal Engineering, vol. 92, pp. 149 \u2013 161, 2016. [169] D. Novak and R. Riener, \u201cA survey of sensor fusion methods in wearable robotics,\u201d Robotics and Autonomous Systems, vol. 73, pp. 155 \u2013 170, 2015, wearable Robotics. [170] D. Tansky, A. Fischer, B. M. Colosimo, L. Pagani, and Y. B. Shabat, \u201cMulti-sensor multi-resolution data fusion modeling,\u201d Procedia {CIRP}, vol. 21, pp. 151 \u2013 158, 2014, 24th {CIRP} Design Conference. [171] H. Durrant-White. (2002) Introduction to sensor data fusion. accessed 25.02.2016. [Online]. Available: http://www.acfr.usyd.edu.au/pdfs/training/ IntroDataFusionSlides.pdf [172] A. R. Mirza, \u201cData fusion architectures for sensor platforms,\u201d in Aerospace Conference, 2008 IEEE, March 2008, pp. 1\u201313. [173] E. Azimirad, J. Haddadnia, and A. Izadipour, \u201cA comprehensive review of the multi-sensor data fusion architectures,\u201d Journal of Theoretical and Applied Information Technology, vol. 71, no. 1, January 2015. [Online]. Available: http://www.jatit.org/volumes/Vol71No1/4Vol71No1.pdf [174] B. V. Dasarathy, \u201cSensor fusion potential exploitation-innovative architectures and illustrative applications,\u201d Proceedings of the IEEE, vol. 85, no. 1,\npp. 24\u201338, Jan 1997.\n32\n[175] B. J. MacLennan, \u201cNatural computation and non-turing models of computation,\u201d Theoretical Computer Science, vol. 317, no. 1 - 3, pp. 115 \u2013 145, 2004, super-Recursive Algorithms and Hypercomputation. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0304397503006352 [176] \u2014\u2014, Encyclopedia of Complexity and Systems Science. New York, NY: Springer New York, 2009, ch. Analog Computation, pp. 271\u2013294. [Online]. Available: http://dx.doi.org/10.1007/978-0-387-30440-3 19 [177] J. S. Small, \u201cGeneral-purpose electronic analog computing: 1945-1965,\u201d Annals of the History of Computing, IEEE, vol. 15, no. 2, pp. 8\u201318, 1993. [178] K. H. Lundberg, \u201cThe history of analog computing: introduction to the special section,\u201d Control Systems, IEEE, vol. 25, no. 3, pp. 22\u201325, June 2005. [179] A. E. Rogers and T. W. Connelly, Analog computation in engineering design. New York : Mcgraw-Hill, 1960. [180] J. S. Small, The analogue alternative: The electronic analogue computer in Britain and the USA, 1930-1975. Routledge, 2001, vol. 15. [181] P. Wambacq and W. Sansen, Distortion analysis of analog integrated circuits. Springer Science & Business Media, 1998, vol. 451. [182] R. Daniel, J. R. Rubens, R. Sarpeshkar, and T. K. Lu, \u201cSynthetic analog computation in living cells,\u201d Nature, vol. 497, no. 7451, pp. 619\u2013623, 2013. [Online]. Available: http://dx.doi.org/10.1038/nature12148 [183] G. E. R. Cowan, R. C. Melville, and Y. Tsividis, \u201cA vlsi analog computer/math co-processor for a digital computer,\u201d in Solid-State Circuits Conference, 2005. Digest of Technical Papers. ISSCC. 2005 IEEE International, Feb 2005, pp. 82\u2013586 Vol. 1. [184] B. Schell and Y. Tsividis, \u201cA clockless adc/dsp/dac system with activity-dependent power dissipation and no aliasing,\u201d in Solid-State Circuits Conference, 2008. ISSCC 2008. Digest of Technical Papers. IEEE International, Feb 2008, pp. 550\u2013635. [185] N. Guo, Y. Huang, T. Mai, S. Patil, C. Cao, M. Seok, S. Sethumadhavan, and Y. Tsividis, \u201cContinuous-time hybrid computation with programmable nonlinearities,\u201d in European Solid-State Circuits Conference (ESSCIRC), ESSCIRC 2015 - 41st, Sept 2015, pp. 279\u2013282. [186] M. P. Singh and M. K. Jain, \u201cArticle: Evolution of processor architecture in mobile phones,\u201d International Journal of Computer Applications, vol. 90, no. 4, pp. 34\u201339, March 2014. [187] A. R. Brodtkorb, T. R. Hagen, and M. L. Saetra, \u201cGraphics processing unit (gpu) programming strategies and trends in {GPU} computing,\u201d Journal of Parallel and Distributed Computing, vol. 73, no. 1, pp. 4 \u2013 13, 2013, metaheuristics on {GPUs}. [188] H. Khatter and V. Aggarwal, \u201cEfficient parallel processing by improved cpu-gpu interaction,\u201d in Issues and Challenges in Intelligent Computing Techniques (ICICT), 2014 International Conference on, Feb 2014, pp. 159\u2013161. [189] M. Microsoft. (2016, 02) Directx graphics and gaming. accessed on 19.02.2016. Micrisoft. [Online]. Available: https://msdn.microsoft.com/en-us/ library/ee663274(v=vs.85).aspx [190] nVidia. (2016, 02) Cuda parallel computing platform. accessed on 19.02.2016. [Online]. Available: http://www.nvidia.com/object/cuda home new.html [191] A. AMD. (2016, 02) Amd compute cores. accessed on 19.02.2016. [Online]. Available: http://www.amd.com/en-us/innovations/software-technologies/ processors-for-business/compute-cores [192] O. Khronos. (2016, 02) The open standard for parallel programming of heterogeneous systems. accessed on 19.02.2016. [Online]. Available: https://www.khronos.org/opencl/ [193] R. Cumplido, E. de la Torre, C. Feregrino-Uribe, and M. Wirthlin, \u201cIntroduction to special issue on reconfigurable computing and {FPGAs},\u201d Microprocessors and Microsystems, vol. 39, no. 7, pp. 541 \u2013 542, 2015. [194] H. Hassan and M. Anis, \u201cChapter 3 - power estimation in {FPGAs},\u201d in Low-Power Design of Nanometer {FPGAs}, ser. Systems on Silicon, H. Hassan and M. Anis, Eds. Boston: Morgan Kaufmann, 2010, pp. 41 \u2013 83. [195] R. Lysecky and F. Vahid, \u201cA study of the speedups and competitiveness of fpga soft processor cores using dynamic hardware/software partitioning.\u201d Design Automation and Test in Europe, pp. 18\u201323, March 2005. [Online]. Available: http://www.cs.ucr.edu/\u223cvahid/pubs/date05 warp microblaze.pdf [196] P. Ekas and B. Jentz, \u201cDeveloping and integrating fpga coprocessors,\u201d Embedded computing design, 2003. [Online]. Available: http: //embedded-computing.com/pdfs/Altera.Fall03.pdf [197] E. Farquhar, C. Gordon, and P. Hasler, \u201cA field programmable neural array,\u201d in Circuits and Systems, 2006. ISCAS 2006. Proceedings. 2006 IEEE International Symposium on, May 2006, pp. 4 pp.\u20134117. [198] A. Sengupta, A. Banerjee, and K. Roy. (2015) Hybrid spintronic-cmos spiking neural network with on-chip learning: Devices, circuits and systems. accessed 26.02.2016. [Online]. Available: http://arxiv.org/pdf/1510.00432.pdf [199] spiNNaker. (2016) spinnaker project. accessed 26.02.2016. [Online]. Available: http://apt.cs.manchester.ac.uk/projects/SpiNNaker/ [200] B. V. Benjamin, P. Gao, E. McQuinn, S. Choudhary, A. R. Chandrasekaran, J. M. Bussat, R. Alvarez-Icaza, J. V. Arthur, P. A. Merolla, and K. Boahen,\n\u201cNeurogrid: A mixed-analog-digital multichip system for large-scale neural simulations,\u201d Proceedings of the IEEE, vol. 102, no. 5, pp. 699\u2013716, May 2014.\n[201] IBM. (2015) Introducing a brain-inspired computer - truenorth\u2019s neurons to revolutionize system architecture. accessed 26.02.2016. [Online]. Available: http://www.research.ibm.com/articles/brain-chip.shtml [202] A. Amir, P. Datta, W. P. Risk, A. S. Cassidy, J. A. Kusnitz, S. K. Esser, A. Andreopoulos, T. M. Wong, M. Flickner, R. Alvarez-Icaza, E. McQuinn, B. Shaw, N. Pass, and D. S. Modha. (2015) Cognitive computing programming paradigm: A corelet language for composing networks of neurosynaptic cores. accessed 26.02.2016. [Online]. Available: https://dl.dropboxusercontent.com/u/91714474/Papers/020.IJCNN2013.Corelet.pdf? cm mc uid=24791255049214564895444&cm mc sid 50200000=1456489544 [203] G. D. Abowd, A. K. Dey, P. J. Brown, N. Davies, M. Smith, and P. Steggles, \u201cTowards a better understanding of context and context-awareness,\u201d in Handheld and ubiquitous computing. Springer, 1999, pp. 304\u2013307. [204] P. Horn, \u201cAutonomic computing: Ibm\\\u2019s perspective on the state of information technology,\u201d 2001. [205] X. Zhang, M. Clark, K. Rattan, and J. Muse, \u201cController verification in adaptive learning systems towards trusted autonomy,\u201d in Proceedings of the\nACM/IEEE Sixth International Conference on Cyber-Physical Systems. ACM, 2015, pp. 31\u201340."}], "references": [{"title": "Perceptions of moral character modulate the neural systems of reward during the trust game", "author": ["M.R. Delgado", "R.H. Frank", "E.A. Phelps"], "venue": "Nature neuroscience, vol. 8, no. 11, pp. 1611\u20131618, 2005.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2005}, {"title": "The resolution of conflict: Constructive and destructive processes", "author": ["M. Deutsch"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1977}, {"title": "Trust; and, Power: two works by Niklas Luhmann", "author": ["N. Luhmann", "H. Davis", "J. Raffan", "K. Rooney"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1979}, {"title": "Trust, gender, and race in the workplace", "author": ["C. Wells"], "venue": "Journal of Social Behavior and Personality, vol. 16, no. 1, pp. 115\u2013126, 2001.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Trust and betrayal in the workplace building effective relationships in your organization", "author": ["D.S. Reina", "M.L. Reina"], "venue": "Advances in Developing Human Resources, vol. 2, no. 1, pp. 121\u2013121, 2000.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2000}, {"title": "Managers as initiators of trust: An exchange relationship framework for understanding managerial trustworthy behavior", "author": ["E.M. Whitener", "S.E. Brodt", "M.A. Korsgaard", "J.M. Werner"], "venue": "Academy of management review, vol. 23, no. 3, pp. 513\u2013530, 1998.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1998}, {"title": "Trust in the workplace: Factors affecting trust formation between team members", "author": ["M.D. Spector", "G.E. Jones"], "venue": "The Journal of social psychology, vol. 144, no. 3, pp. 311\u2013321, 2004.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Formalising trust as a computational concept", "author": ["S. Marsh"], "venue": "PhD Thesis, 1994.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1994}, {"title": "Computational trust and reputation models for open multi-agent systems: a review", "author": ["I. Pinyol", "J. Sabater-Mir"], "venue": "Artificial Intelligence Review, vol. 40, pp. 1\u201325, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "On trust and influence: A computational red teaming game theoretic perspective", "author": ["E. Petraki", "H. Abbass"], "venue": "Computational Intelligence for Security and Defense Applications (CISDA), 2014 Seventh IEEE Symposium on. IEEE, 2014, pp. 1\u20137.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Trusted autonomy and cognitive cyber symbiosis: Open challenges", "author": ["H.A. Abbass", "E. Petraki", "K. Merrick", "J. Harvey", "M. Barlow"], "venue": "Cognitive Computation, pp. 1\u201324, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "The n-player trust game and its replicator dynamics", "author": ["H. Abbass", "G. Greenwood", "E. Petraki"], "venue": "Evolutionary Computation, IEEE Transactions on, To Appear.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 0}, {"title": "Secsdlc: A practical life cycle approach for cloud-based information security", "author": ["F.F. Alruwaili", "T.A. Gulliver"], "venue": "IJRCCT, vol. 4, no. 2, pp. 095\u2013107, 2015.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards safety assurance of trusted autonomy in air force flight critical systems", "author": ["J. Hinchman", "M. Clark", "J. Hoffman", "B. Hulbert", "A. Subcontractor", "C. Snyder"], "venue": "Computer Security Applications Conference, Layered Assurance Workshop, 2012.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Review on computational trust and reputation models", "author": ["J. Sabater", "C. Sierra"], "venue": "Artificial Intelligence Review, vol. 24, no. 1, pp. 33\u201360, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "A survey on trust and reputation systems for online service provision", "author": ["A. Josang", "R. Ismail", "C. Boyd"], "venue": "Decision Support Systems, vol. 43, no. 2, pp. 618\u2013644, 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "A survey of multi-agent trust management systems", "author": ["H. Yu", "Z. Shen", "C. Leung", "C. Miao", "V. Lesser"], "venue": "IEEE Access, vol. 1, pp. 35\u201350, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Optimism and pessimism in trust.", "author": ["S. Marsh"], "venue": "The Ibero-American Conference on Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1994}, {"title": "Travos: trust and reputation in the context of inaccurate information sources", "author": ["W.T. Luke Teacy", "J. Patel", "N. Jennings", "M. Luck"], "venue": "Autonomous Agents and Multi Agent Systems, vol. 12, pp. 183\u2013198, 2006.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Supporting trust in virtual communities.", "author": ["A. Abdul-Rahman", "S. Hailes"], "venue": "The Hawaii International Conference on System Sciences,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Using trust for secure collaboration in uncertain environments", "author": ["V. Cahill", "E. Gray", "M. Seigneur", "C. Jensen", "Y. Chen", "B. Shand", "N. Dimmock", "A. Twigg", "J. Bacon", "C. English", "W. Wagealla", "S. Terzis", "P. Nixon", "G. di Marzo Serugendo", "C. Bryce", "M. Carbone", "K. Krukow", "M. Nielsen"], "venue": "Pervasive Computing, vol. 2, no. 3, pp. 52\u201361, 2003.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2003}, {"title": "Trust-based decision making for electronic transactions.", "author": ["A. Josang"], "venue": "The Fourth Nordic Workshop on Secure Computer Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1999}, {"title": "A fuzzy approach to reasoning with trust, distrust and insufficient trust.", "author": ["N. Griffiths"], "venue": "Conference Paper,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Using fuzzy logic and q-learning for trust modelling in multi-agent systems.", "author": ["A. Aref", "T. Tran"], "venue": "The 2014 Federated Conference on Computer Science and Information Systems,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Spreading activation models for trust propagation.", "author": ["C.N. Ziegler", "G. Lausen"], "venue": "IEEE International Conference on e-Technology, e-Commerce and e-Service,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2004}, {"title": "Generic reliability trust model", "author": ["G. Mahoney", "W. Myrvold", "G. Shoja"], "venue": "The Third Annual Conference on Privacy, Security and Trust, 2005.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2005}, {"title": "Trust-region methods. Philadelphia, PA: Society for Industrial and Applied Mathematics and Mathematical Programming", "author": ["A. Conn", "N. Gould", "P. Toint"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2000}, {"title": "A review of trust region algorithms for optimisation.", "author": ["Y. Yuan"], "venue": "Edinburgh: The Fourth International Congress on Industrial and Applied Mathematics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "Collaborative reputation mechanisms for online communities", "author": ["Z. Giorgos"], "venue": "Masters Thesis, 1999.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1999}, {"title": "Peertrust: Supporting reputation-based trust for peer-to-peer electronic communities", "author": ["L. Xiong", "L. Liu"], "venue": "IEEE Transactions on Knowledge and Data Engineering, vol. 16, pp. 843\u2013857, 2004.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2004}, {"title": "Fctrust: A robust and efficient feedback credibility-based distributed p2p trust model", "author": ["J. Hu", "Q. Wu", "B. Zhou"], "venue": "The Ninth IEEE International Conference for Young Computer Scientiests, 2008.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2008}, {"title": "Sftrust: a double trust metric based trust model in unstructured p2p systems", "author": ["Y. Zhang", "S. Chen", "G. Yang"], "venue": "The IEEE International Symposium on Parallel and Distributed Processing, 2009.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Formal analysis of models for the dynamics of trust based on experiences.", "author": ["C.M. Jonker", "J. Treur"], "venue": "MAAMAW 99,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1999}, {"title": "The influence of agent reliability on trust in human-agent collaboration", "author": ["X. Fan", "S. Oh", "M. McNeese", "J. Yen", "H. Cuevas", "L. Strater", "M. Endsley"], "venue": "The fifteenth european conference on cognitive ergonomics, 2008.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2008}, {"title": "Reasoning about rational agents", "author": ["M. Wooldridge"], "venue": null, "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2000}, {"title": "Trust in lora: towards a formal definition of trust in bdi agents.", "author": ["B. Jarvis", "L. Jain"], "venue": "Conference Paper,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2006}, {"title": "Incorporating trust into the bdi architecture", "author": ["T. Taibi"], "venue": "International Journal of Artificial Intelligence and Soft Computing, vol. 2, no. 3, pp. 223\u2013230, 2010.  29", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2010}, {"title": "Opening the black box of trust: reasoning about trust models in a bdi agent", "author": ["A. Koster", "M. Scholrlemmer", "J. Sabater-Mir"], "venue": "Journal of Logic and Computation, vol. 23, no. 1, pp. 25\u201358, 2013.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2013}, {"title": "Pso-tps: An optimal trust path selection algorithm based on particle swarm optimisation in small world network", "author": ["G. Xu", "C. Xu", "X. Tian", "L. Zhang", "X. Li", "W. Li"], "venue": "The Second International Conference on Cloud and Green Computing, 2012.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2012}, {"title": "Trust-based particle swarm optimisation for grid task scheduling", "author": ["W. Huang", "Z. Deng", "R. Li", "X. Tang"], "venue": "Applied Mechanics and Materials, vol. 239-240, pp. 1331\u20131335, 2013.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2013}, {"title": "Motivated reinforcement learning: curious characters for multiuser games", "author": ["K. Merrick", "M.L. Maher"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2009}, {"title": "Trust and deception in multi-agent trading systems: a logical viewpoint.", "author": ["Z. Sun", "G. Finnie", "J. Barker"], "venue": "The 11th Americas Conference on Information Systems,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2005}, {"title": "Dynamic trust model for reliable transactions in multi-agent systems", "author": ["A. Das", "M.M. Islam", "G. Sorwar"], "venue": "The Thirteenth International Conference on Advanced Communication Technology, 2011.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2011}, {"title": "A specification of the agent reputation and trust (art) testbed: experimentation and competitition for trust in agent societies.", "author": ["K. Fullam", "T. Klos", "G. Muller", "J. Sabater", "A. Scholosser", "Z. Topol", "S. Barber", "J. Rosenschein", "L. Vercouter", "M. Voss"], "venue": "Autonomous Agents and Multi Agent Systems,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2005}, {"title": "A multi-disciplinary review of knowledge acquisition methods: From human to autonomous eliciting agents", "author": ["G. Leu", "H.A. Abbass"], "venue": "Knowledge- Based Systems, To Appear.", "citeRegEx": "52", "shortCiteRegEx": null, "year": 0}, {"title": "Big data analytics", "author": ["P. Russom"], "venue": "TDWI Best Practices Report, Fourth Quarter, 2011.", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2011}, {"title": "Computational intelligence in big data [guest editorial", "author": ["Y. Jin", "B. Hammer"], "venue": "Computational Intelligence Magazine, IEEE, vol. 9, no. 3, pp. 12\u201313, 2014.", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2014}, {"title": "Computational Red Teaming: Risk Analytics of Big-Data-to-Decisions Intelligent Systems", "author": ["H. Abbass"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2015}, {"title": "Magnetic sensors based on amorphous ferromagnetic materials: A review", "author": ["C. Moron", "C. Cabrera", "A. Moron", "A. Garcia", "M. Gonzalez"], "venue": "Sensors, vol. 15, no. 11, pp. 28 340\u201328 366, 2015.", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2015}, {"title": "On sensor sampling and quality of information: A starting point", "author": ["C. Bisdikian"], "venue": "Pervasive Computing and Communications Workshops, 2007. PerCom Workshops \u201907. Fifth Annual IEEE International Conference on, March 2007, pp. 279\u2013284.", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "A review of wearable sensors and systems with application in rehabilitation", "author": ["S. Patel", "H. Park", "P. Bonato", "L. Chan", "M. Rodgers"], "venue": "Journal of NeuroEngineering and Rehabilitation, vol. 9, no. 1, pp. 1\u201317, 2012. [Online]. Available: http://dx.doi.org/10.1186/1743-0003-9-21", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2012}, {"title": "Wearable sensors for human activity monitoring: A review", "author": ["S.C. Mukhopadhyay"], "venue": "Sensors Journal, IEEE, vol. 15, no. 3, pp. 1321\u20131330, March 2015.", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2015}, {"title": "Data mining for wearable sensors in health monitoring systems: A review of recent trends and challenges", "author": ["H. Banaee", "M.U. Ahmed", "A. Loutfi"], "venue": "Sensors, vol. 13, no. 12, pp. 17 472\u201317 500, 2013. [Online]. Available: http://www.mdpi.com/1424-8220/13/12/17472", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2013}, {"title": "Microelectronics-based biosensors dedicated to the detection of neurotransmitters: A review", "author": ["M. Mirzaei", "M. Sawan"], "venue": "Sensors, vol. 14, no. 10, pp. 17 981\u201318 008, 2014. [Online]. Available: http://www.mdpi.com/1424-8220/14/10/17981", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2014}, {"title": "Non-invasive wearable electrochemical sensors: a review", "author": ["A.J. Bandodkar", "J. Wang"], "venue": "Trends in Biotechnology, vol. 32, no. 7, pp. 363 \u2013 371, 2014. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0167779914000699", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2014}, {"title": "Wearable electronics and smart textiles: A critical review", "author": ["M. Stoppa", "A. Chiolerio"], "venue": "Sensors, vol. 14, no. 7, p. 11957, 2014. [Online]. Available: http://www.mdpi.com/1424-8220/14/7/11957", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2014}, {"title": "Inertial sensor-based gait recognition: A review", "author": ["S. Sprager", "M.B. Juric"], "venue": "Sensors, vol. 15, no. 9, p. 22089, 2015. [Online]. Available: http://www.mdpi.com/1424-8220/15/9/22089", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2015}, {"title": "Flexible wireless temperature sensors based on ni microparticle-filled binary polymer composites", "author": ["J. Jeon", "H.-B.-R. Lee", "Z. Bao"], "venue": "Advanced Materials, vol. 25, no. 6, pp. 850\u2013855, 2013.", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2013}, {"title": "A rule-based phonocardiographic method for long-term fetal heart rate monitoring", "author": ["F. Kovacs", "M. Torok", "I. Habermajer"], "venue": "Biomedical Engineering, IEEE Transactions on, vol. 47, no. 1, pp. 124\u2013130, Jan 2000.", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2000}, {"title": "Accelerometer-based heart sound detection for autocapture", "author": ["Q. Zhu", "J. Spinelli", "G. Carlson"], "venue": "Nov. 18 2003, uS Patent 6,650,940. [Online]. Available: http://www.google.com/patents/US6650940", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2003}, {"title": "A multi-channel opto-electronic sensor to accurately monitor heart rate against motion artefact during exercise", "author": ["A. Alzahrani", "S. Hu", "V. Azorin-Peris", "L. Barrett", "D. Esliger", "M. Hayes", "S. Akbare", "J. Achart", "S. Kuoch"], "venue": "Sensors, vol. 15, no. 10, p. 25681, 2015. [Online]. Available: http://www.mdpi.com/1424-8220/15/10/25681", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2015}, {"title": "A novel time-varying spectral filtering algorithm for reconstruction of motion artifact corrupted heart rate signals during intense physical activities using a wearable photoplethysmogram sensor", "author": ["S.M.A. Salehizadeh", "D. Dao", "J. Bolkhovsky", "C. Cho", "Y. Mendelson", "K.H. Chon"], "venue": "Sensors, vol. 16, no. 1, p. 10, 2016. [Online]. Available: http://www.mdpi.com/1424-8220/16/1/10", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2016}, {"title": "Wearable sensing of in-ear pressure for heart rate monitoring with a piezoelectric sensor", "author": ["J.-H. Park", "D.-G. Jang", "J.W. Park", "S.-K. Youm"], "venue": "Sensors, vol. 15, no. 9, p. 23402, 2015. [Online]. Available: http://www.mdpi.com/1424-8220/15/9/23402", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2015}, {"title": "Clinical geodesic eeg system 400. accessed 22.02.2016", "author": ["G. EGI"], "venue": null, "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2016}, {"title": "Augmented cognition using real-time eeg-based adaptive strategies for air traffic control", "author": ["H.A. Abbass", "J. Tang", "R. Amin", "M. Ellejmi", "S. Kirby"], "venue": "Proceedings of the Human Factors and Ergonomics Society Annual Meeting, vol. 58, no. 1, pp. 230\u2013234, 2014.", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2014}, {"title": "Visual and auditory reaction time for air traffic controllers using quantitative electroencephalograph (qeeg) data", "author": ["H.A. Abbass", "J. Tang", "M. Ellejmi", "S. Kirby"], "venue": "Brain Informatics, vol. 1, no. 1, pp. 39\u201345, 2014.", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2014}, {"title": "2016, 02) Emotiv insight - brain activity tracker", "author": ["I. Emotiv"], "venue": null, "citeRegEx": "78", "shortCiteRegEx": "78", "year": 2016}, {"title": "A high resolution, multi-channel eeg system", "author": ["E. Emotiv"], "venue": null, "citeRegEx": "79", "shortCiteRegEx": "79", "year": 2016}, {"title": "Trackit - mobile long-term eeg. accessed 22.02.2016", "author": ["T. Nihonkohden"], "venue": "[Online]. Available: http://www.nihonkohden.de/products/neurology/", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 2016}, {"title": "Synamps 2/rt 256-channel eeg/ep/erp. accessed 22.02.2016", "author": ["S. Compumedics"], "venue": "[Online]. Available: http://compumedicsneuroscan.com/", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 2016}, {"title": "Grael 32-channel eeg/erp amplifier. accessed 22.02.2016", "author": ["G. Compumedics"], "venue": null, "citeRegEx": "83", "shortCiteRegEx": "83", "year": 2016}, {"title": "Nexus-32 multimodal qeeg system. accessed 04.03.2016", "author": ["N. MindMedia"], "venue": null, "citeRegEx": "84", "shortCiteRegEx": "84", "year": 2016}, {"title": "Bwiii eeg plus icu brain monitor. accessed 22.02.2016", "author": ["B. Neurovirtual"], "venue": null, "citeRegEx": "87", "shortCiteRegEx": "87", "year": 2016}, {"title": "Measuring and modulating brain activity. accessed 22.02.2016", "author": ["T. Neuroconn"], "venue": "[Online]. Available: http://www.neuroconn.de/thera prax q-eeg en/", "citeRegEx": "88", "shortCiteRegEx": "88", "year": 2016}, {"title": "Clinical geodesic eeg mobile (gem) 100. accessed 22.02.2016", "author": ["G. EGI"], "venue": null, "citeRegEx": "89", "shortCiteRegEx": "89", "year": 2016}, {"title": "High-quality eeg recording and freedom of movement. accessed 22.02.2016", "author": ["encephalan Medicom"], "venue": null, "citeRegEx": "90", "shortCiteRegEx": "90", "year": 2016}, {"title": "Advanced eeg system built for demanding clinical and research use. accessed 22.02.2016", "author": ["T. Deymed"], "venue": null, "citeRegEx": "93", "shortCiteRegEx": "93", "year": 2016}, {"title": "2016, 02) eego sports - the total mobility solution. accessed 22.02.2016", "author": ["eegoSports antNeuro"], "venue": null, "citeRegEx": "94", "shortCiteRegEx": "94", "year": 2016}, {"title": "Bwmini ambulatory eeg", "author": ["B. Neurovirtual"], "venue": null, "citeRegEx": "95", "shortCiteRegEx": "95", "year": 2016}, {"title": "Neurosky mindwave mobile headset kit", "author": ["M. NeuroSky"], "venue": null, "citeRegEx": "96", "shortCiteRegEx": "96", "year": 2016}, {"title": "Neurological evidence linguistic processes precede perceptual simulation in conceptual processing", "author": ["M. Louwerse", "S. Hutchinson"], "venue": "Frontiers in Psychology, vol. 3, no. 385, 2012. [Online]. Available: http://www.frontiersin.org/cognitive science/10.3389/fpsyg.2012.00385/abstract", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2012}, {"title": "Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion", "author": ["T. Fraga", "M. Pichiliani", "D. Louro"], "venue": "ch. Experimental Art with Brain Controlled Interface,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 2013}, {"title": "Muse review: The brain sensing headband that knows you\u2019re stressed. accessed on 22.02.2016", "author": ["S. Charara"], "venue": "www.wearable.com. [Online]. Available:", "citeRegEx": "100", "shortCiteRegEx": "100", "year": 2016}, {"title": "Muse - the brain sensing headband. accessed on 22.02.2016", "author": ["M. Interaxon"], "venue": null, "citeRegEx": "101", "shortCiteRegEx": "101", "year": 2016}, {"title": "Clinical grade neurofeedback system dedesign for clinicians wishing to use the highigh standard for neurotherapy", "author": ["B. Deymed"], "venue": null, "citeRegEx": "104", "shortCiteRegEx": "104", "year": 2016}, {"title": "Portable electrocardiograph with thermal printing system. accessed 22.02.2016", "author": ["A. Cardio02line"], "venue": null, "citeRegEx": "105", "shortCiteRegEx": "105", "year": 2016}, {"title": "Cardioline touchecg tablet hd+", "author": ["T. Cardioline"], "venue": null, "citeRegEx": "106", "shortCiteRegEx": "106", "year": 2016}, {"title": "Electrocardiograph ucard - 200. accessed 22.02.2016", "author": ["U. TSE"], "venue": null, "citeRegEx": "107", "shortCiteRegEx": "107", "year": 2016}, {"title": "Pc based ecg machine with simultaneous acquisition. accessed 22.02.2016", "author": ["S. Nasan"], "venue": null, "citeRegEx": "108", "shortCiteRegEx": "108", "year": 2016}, {"title": "Monochrome 12 channel ecg", "author": ["E. Longfian"], "venue": null, "citeRegEx": "109", "shortCiteRegEx": "109", "year": 2016}, {"title": "2016, 02) 3 channel ecg machine with measurement interpretation. accessed 22.02.2016", "author": ["A. Nasan"], "venue": "[Online]. Available: http://www.nasanmedical", "citeRegEx": "111", "shortCiteRegEx": "111", "year": 2016}, {"title": "Nasiff cardiocard pc based resting ecg system. accessed 22.02.2016", "author": ["R. Nasiff"], "venue": null, "citeRegEx": "112", "shortCiteRegEx": "112", "year": 2016}, {"title": "Cardiodirect 12 usb. accessed 22.02.2016", "author": ["C. SpaceLab"], "venue": "[Online]. Available: http://www.spacelabshealthcare.com/diagnostic-cardiology/", "citeRegEx": "113", "shortCiteRegEx": "113", "year": 2016}, {"title": "High-end 12-channel electrocardiograph for resting and stress ecg. accessed 22.02.2016", "author": ["K. Kalamed"], "venue": null, "citeRegEx": "115", "shortCiteRegEx": "115", "year": 2016}, {"title": "Custo cardio 200 usb/bt. accessed 22.02.2016", "author": ["C. Customed"], "venue": "[Online]. Available:", "citeRegEx": "118", "shortCiteRegEx": "118", "year": 2016}, {"title": "Thoriax - pc ecg", "author": ["T. Thor"], "venue": null, "citeRegEx": "120", "shortCiteRegEx": "120", "year": 2016}, {"title": "Cubestress hd+ series. accessed 22.02.2016", "author": ["C. Cardioline"], "venue": null, "citeRegEx": "122", "shortCiteRegEx": "122", "year": 2016}, {"title": "The cartouch. accessed 23.02.2016", "author": ["C. Cardionics"], "venue": null, "citeRegEx": "123", "shortCiteRegEx": "123", "year": 2016}, {"title": "Cardiopart 12 blue/blue-p. accessed 23.02.2016", "author": ["C. Amedtec"], "venue": "[Online]. Available: http://www.amedtec.de/downloads/CardioPart%2012% 20Blue en.pdf", "citeRegEx": "125", "shortCiteRegEx": "125", "year": 2012}, {"title": "Thoriax home ecg - portable ecg monitor. accessed 23.02.2016", "author": ["T. Thor"], "venue": null, "citeRegEx": "126", "shortCiteRegEx": "126", "year": 2016}, {"title": "Multiple arousal theory and daily-life electrodermal activity asymmetry", "author": ["R.W. Picard", "S. Fedor", "Y. Ayzenberg"], "venue": "Emotion Review, vol. 8, no. 1, pp. 62\u201375, 2016. [Online]. Available: http://emr.sagepub.com/content/8/1/62.abstract", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2016}, {"title": "Assessing autonomic nervous system activity", "author": ["W.B. Mendes"], "venue": null, "citeRegEx": "130", "shortCiteRegEx": "130", "year": 2009}, {"title": "2016, 02) To wear it is to love it. accessed 24.02.2016", "author": ["A. Apple"], "venue": null, "citeRegEx": "138", "shortCiteRegEx": "138", "year": 2016}, {"title": "Basis peak - the ultimate fitness and sleep tracker. accessed 24.02.2016", "author": ["B. Mybasis"], "venue": null, "citeRegEx": "139", "shortCiteRegEx": "139", "year": 2016}, {"title": "Zip - wireless activity tracker", "author": ["Z. Fitbit"], "venue": null, "citeRegEx": "141", "shortCiteRegEx": "141", "year": 2016}, {"title": "The power of heart rate on your wrist. accessed 24.02.2016", "author": ["W. Fitbit"], "venue": null, "citeRegEx": "142", "shortCiteRegEx": "142", "year": 2016}, {"title": "Orb - fitness, sleep and activity", "author": ["O. Fitbug"], "venue": "tracker. accessed on 24.02.2016", "citeRegEx": "144", "shortCiteRegEx": "144", "year": 2016}, {"title": "2016, 02) Android wearable devices. accessed 24.02.2016", "author": ["A. Google"], "venue": null, "citeRegEx": "146", "shortCiteRegEx": "146", "year": 2016}, {"title": "2016) Up is a revolutionary system that guides you every step of the way to a better, healthier you. accessed 24.02.2016", "author": ["U. Jawbone"], "venue": "https://jawbone.com/up", "citeRegEx": "148", "shortCiteRegEx": "148", "year": 2016}, {"title": "2016, 02) Lg lifeband touch activity tracker - make the world your workout. accessed 24.02.2016", "author": ["L. LG"], "venue": null, "citeRegEx": "149", "shortCiteRegEx": "149", "year": 2016}, {"title": "2016, 02) Lg g watch (w100) black titan - information when you need it most. accessed 24.02.2016", "author": ["S. LG"], "venue": null, "citeRegEx": "150", "shortCiteRegEx": "150", "year": 2016}, {"title": "Activity and sleep tracker in one. accessed 24.02.2016", "author": ["V. Medisana"], "venue": null, "citeRegEx": "151", "shortCiteRegEx": "151", "year": 2016}, {"title": "Live healthier and achieve more", "author": ["B. Microsoft"], "venue": null, "citeRegEx": "152", "shortCiteRegEx": "152", "year": 2016}, {"title": "Connect and go with nike+", "author": ["F. Nike"], "venue": null, "citeRegEx": "154", "shortCiteRegEx": "154", "year": 2016}, {"title": "Survive your world with the razer nabu", "author": ["N. Razerone"], "venue": null, "citeRegEx": "156", "shortCiteRegEx": "156", "year": 2016}, {"title": "Nabu watch - live smarter", "author": ["W. Razerone"], "venue": null, "citeRegEx": "157", "shortCiteRegEx": "157", "year": 2016}, {"title": "Achieve your health and fitness goals with lifetrak", "author": ["L. Salutron"], "venue": null, "citeRegEx": "158", "shortCiteRegEx": "158", "year": 2016}, {"title": "Live smarter with smartwear", "author": ["S. Sony"], "venue": null, "citeRegEx": "162", "shortCiteRegEx": "162", "year": 2016}, {"title": "Striiv - fusion series", "author": ["F. Striiv"], "venue": null, "citeRegEx": "163", "shortCiteRegEx": "163", "year": 2016}, {"title": "Software Technologies for Embedded and Ubiquitous Systems: 5th IFIP WG", "author": ["W. Elmenreich"], "venue": "SEUS", "citeRegEx": "166", "shortCiteRegEx": "166", "year": 2007}, {"title": "Control performance assessment based on sensor fusion techniques", "author": ["S.A. Khamseh", "A.K. Sedigh", "B. Moshiri", "A. Fatehi"], "venue": "Control Engineering Practice, vol. 49, pp. 14 \u2013 28, 2016.", "citeRegEx": "167", "shortCiteRegEx": null, "year": 2016}, {"title": "Sensor and {CFD} data fusion for airflow field estimation", "author": ["C. Jiang", "Y.C. Soh", "H. Li"], "venue": "Applied Thermal Engineering, vol. 92, pp. 149 \u2013 161, 2016.", "citeRegEx": "168", "shortCiteRegEx": null, "year": 2016}, {"title": "A survey of sensor fusion methods in wearable robotics", "author": ["D. Novak", "R. Riener"], "venue": "Robotics and Autonomous Systems, vol. 73, pp. 155 \u2013 170, 2015, wearable Robotics.", "citeRegEx": "169", "shortCiteRegEx": null, "year": 2015}, {"title": "Multi-sensor multi-resolution data fusion modeling", "author": ["D. Tansky", "A. Fischer", "B.M. Colosimo", "L. Pagani", "Y.B. Shabat"], "venue": "Procedia {CIRP}, vol. 21, pp. 151 \u2013 158, 2014, 24th {CIRP} Design Conference.", "citeRegEx": "170", "shortCiteRegEx": null, "year": 2014}, {"title": "Introduction to sensor data fusion. accessed 25.02.2016", "author": ["H. Durrant-White"], "venue": null, "citeRegEx": "171", "shortCiteRegEx": "171", "year": 2002}, {"title": "Data fusion architectures for sensor platforms", "author": ["A.R. Mirza"], "venue": "Aerospace Conference, 2008 IEEE, March 2008, pp. 1\u201313.", "citeRegEx": "172", "shortCiteRegEx": null, "year": 2008}, {"title": "A comprehensive review of the multi-sensor data fusion architectures", "author": ["E. Azimirad", "J. Haddadnia", "A. Izadipour"], "venue": "Journal of Theoretical and Applied Information Technology, vol. 71, no. 1, January 2015. [Online]. Available: http://www.jatit.org/volumes/Vol71No1/4Vol71No1.pdf", "citeRegEx": "173", "shortCiteRegEx": null, "year": 2015}, {"title": "Sensor fusion potential exploitation-innovative architectures and illustrative applications", "author": ["B.V. Dasarathy"], "venue": "Proceedings of the IEEE, vol. 85, no. 1, pp. 24\u201338, Jan 1997.  32", "citeRegEx": "174", "shortCiteRegEx": null, "year": 1997}, {"title": "Natural computation and non-turing models of computation", "author": ["B.J. MacLennan"], "venue": "Theoretical Computer Science, vol. 317, no. 1 - 3, pp. 115 \u2013 145, 2004, super-Recursive Algorithms and Hypercomputation. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0304397503006352", "citeRegEx": "175", "shortCiteRegEx": null, "year": 2004}, {"title": "General-purpose electronic analog computing: 1945-1965", "author": ["J.S. Small"], "venue": "Annals of the History of Computing, IEEE, vol. 15, no. 2, pp. 8\u201318, 1993.", "citeRegEx": "177", "shortCiteRegEx": null, "year": 1993}, {"title": "The history of analog computing: introduction to the special section", "author": ["K.H. Lundberg"], "venue": "Control Systems, IEEE, vol. 25, no. 3, pp. 22\u201325, June 2005.", "citeRegEx": "178", "shortCiteRegEx": null, "year": 2005}, {"title": "Analog computation in engineering design", "author": ["A.E. Rogers", "T.W. Connelly"], "venue": "New York : Mcgraw-Hill,", "citeRegEx": "179", "shortCiteRegEx": "179", "year": 1960}, {"title": "Distortion analysis of analog integrated circuits", "author": ["P. Wambacq", "W. Sansen"], "venue": "Springer Science & Business Media,", "citeRegEx": "181", "shortCiteRegEx": "181", "year": 1998}, {"title": "Synthetic analog computation in living cells", "author": ["R. Daniel", "J.R. Rubens", "R. Sarpeshkar", "T.K. Lu"], "venue": "Nature, vol. 497, no. 7451, pp. 619\u2013623, 2013. [Online]. Available: http://dx.doi.org/10.1038/nature12148", "citeRegEx": "182", "shortCiteRegEx": null, "year": 2013}, {"title": "A vlsi analog computer/math co-processor for a digital computer", "author": ["G.E.R. Cowan", "R.C. Melville", "Y. Tsividis"], "venue": "Solid-State Circuits Conference, 2005. Digest of Technical Papers. ISSCC. 2005 IEEE International, Feb 2005, pp. 82\u2013586 Vol. 1.", "citeRegEx": "183", "shortCiteRegEx": null, "year": 2005}, {"title": "A clockless adc/dsp/dac system with activity-dependent power dissipation and no aliasing", "author": ["B. Schell", "Y. Tsividis"], "venue": "Solid-State Circuits Conference, 2008. ISSCC 2008. Digest of Technical Papers. IEEE International, Feb 2008, pp. 550\u2013635.", "citeRegEx": "184", "shortCiteRegEx": null, "year": 2008}, {"title": "Continuous-time hybrid computation with programmable nonlinearities", "author": ["N. Guo", "Y. Huang", "T. Mai", "S. Patil", "C. Cao", "M. Seok", "S. Sethumadhavan", "Y. Tsividis"], "venue": "European Solid-State Circuits Conference (ESSCIRC), ESSCIRC 2015 - 41st, Sept 2015, pp. 279\u2013282.", "citeRegEx": "185", "shortCiteRegEx": null, "year": 2015}, {"title": "Article: Evolution of processor architecture in mobile phones", "author": ["M.P. Singh", "M.K. Jain"], "venue": "International Journal of Computer Applications, vol. 90, no. 4, pp. 34\u201339, March 2014.", "citeRegEx": "186", "shortCiteRegEx": null, "year": 2014}, {"title": "Graphics processing unit (gpu) programming strategies and trends in {GPU} computing", "author": ["A.R. Brodtkorb", "T.R. Hagen", "M.L. Saetra"], "venue": "Journal of Parallel and Distributed Computing, vol. 73, no. 1, pp. 4 \u2013 13, 2013, metaheuristics on {GPUs}.", "citeRegEx": "187", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient parallel processing by improved cpu-gpu interaction", "author": ["H. Khatter", "V. Aggarwal"], "venue": "Issues and Challenges in Intelligent Computing Techniques (ICICT), 2014 International Conference on, Feb 2014, pp. 159\u2013161.", "citeRegEx": "188", "shortCiteRegEx": null, "year": 2014}, {"title": "The open standard for parallel programming of heterogeneous systems. accessed on 19.02.2016", "author": ["O. Khronos"], "venue": null, "citeRegEx": "192", "shortCiteRegEx": "192", "year": 2016}, {"title": "Introduction to special issue on reconfigurable computing and {FPGAs", "author": ["R. Cumplido", "E. de la Torre", "C. Feregrino-Uribe", "M. Wirthlin"], "venue": "Microprocessors and Microsystems, vol. 39, no. 7, pp. 541 \u2013 542, 2015.", "citeRegEx": "193", "shortCiteRegEx": null, "year": 2015}, {"title": "Chapter 3 - power estimation in {FPGAs", "author": ["H. Hassan", "M. Anis"], "venue": "Low-Power Design of Nanometer {FPGAs}, ser. Systems on Silicon, H. Hassan and M. Anis, Eds. Boston: Morgan Kaufmann, 2010, pp. 41 \u2013 83.", "citeRegEx": "194", "shortCiteRegEx": null, "year": 2010}, {"title": "A study of the speedups and competitiveness of fpga soft processor cores using dynamic hardware/software partitioning.", "author": ["R. Lysecky", "F. Vahid"], "venue": "Design Automation and Test in Europe,", "citeRegEx": "195", "shortCiteRegEx": "195", "year": 2005}, {"title": "Developing and integrating fpga coprocessors", "author": ["P. Ekas", "B. Jentz"], "venue": "Embedded computing design, 2003. [Online]. Available: http: //embedded-computing.com/pdfs/Altera.Fall03.pdf", "citeRegEx": "196", "shortCiteRegEx": null, "year": 2003}, {"title": "A field programmable neural array", "author": ["E. Farquhar", "C. Gordon", "P. Hasler"], "venue": "Circuits and Systems, 2006. ISCAS 2006. Proceedings. 2006 IEEE International Symposium on, May 2006, pp. 4 pp.\u20134117.", "citeRegEx": "197", "shortCiteRegEx": null, "year": 2006}, {"title": "Hybrid spintronic-cmos spiking neural network with on-chip learning: Devices, circuits and systems. accessed 26.02.2016", "author": ["A. Sengupta", "A. Banerjee", "K. Roy"], "venue": null, "citeRegEx": "198", "shortCiteRegEx": "198", "year": 2015}, {"title": "Neurogrid: A mixed-analog-digital multichip system for large-scale neural simulations", "author": ["B.V. Benjamin", "P. Gao", "E. McQuinn", "S. Choudhary", "A.R. Chandrasekaran", "J.M. Bussat", "R. Alvarez-Icaza", "J.V. Arthur", "P.A. Merolla", "K. Boahen"], "venue": "Proceedings of the IEEE, vol. 102, no. 5, pp. 699\u2013716, May 2014.", "citeRegEx": "200", "shortCiteRegEx": null, "year": 2014}, {"title": "Cognitive computing programming paradigm: A corelet language for composing networks of neurosynaptic cores. accessed 26.02.2016", "author": ["A. Amir", "P. Datta", "W.P. Risk", "A.S. Cassidy", "J.A. Kusnitz", "S.K. Esser", "A. Andreopoulos", "T.M. Wong", "M. Flickner", "R. Alvarez-Icaza", "E. McQuinn", "B. Shaw", "N. Pass", "D.S. Modha"], "venue": null, "citeRegEx": "202", "shortCiteRegEx": "202", "year": 2015}, {"title": "Towards a better understanding of context and context-awareness", "author": ["G.D. Abowd", "A.K. Dey", "P.J. Brown", "N. Davies", "M. Smith", "P. Steggles"], "venue": "Handheld and ubiquitous computing. Springer, 1999, pp. 304\u2013307.", "citeRegEx": "203", "shortCiteRegEx": null, "year": 1999}, {"title": "Autonomic computing: Ibm\\\u2019s perspective on the state of information technology", "author": ["P. Horn"], "venue": "2001.", "citeRegEx": "204", "shortCiteRegEx": null, "year": 2001}, {"title": "Controller verification in adaptive learning systems towards trusted autonomy", "author": ["X. Zhang", "M. Clark", "K. Rattan", "J. Muse"], "venue": "Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems. ACM, 2015, pp. 31\u201340.", "citeRegEx": "205", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "It is seen to be owned by fields such as psychology [1], [2],", "startOffset": 52, "endOffset": 55}, {"referenceID": 1, "context": "It is seen to be owned by fields such as psychology [1], [2],", "startOffset": 57, "endOffset": 60}, {"referenceID": 1, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 21, "endOffset": 24}, {"referenceID": 2, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 26, "endOffset": 29}, {"referenceID": 3, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 57, "endOffset": 60}, {"referenceID": 4, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 62, "endOffset": 65}, {"referenceID": 5, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 67, "endOffset": 70}, {"referenceID": 6, "context": "social sciences [3], [2], [4], and organization sciences [5], [6], [7], [8].", "startOffset": 72, "endOffset": 75}, {"referenceID": 7, "context": "Technologists and computational scientists have been modelling trust for a few decades [9], [10], [11], [12].", "startOffset": 87, "endOffset": 90}, {"referenceID": 8, "context": "Technologists and computational scientists have been modelling trust for a few decades [9], [10], [11], [12].", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "Technologists and computational scientists have been modelling trust for a few decades [9], [10], [11], [12].", "startOffset": 98, "endOffset": 102}, {"referenceID": 10, "context": "Technologists and computational scientists have been modelling trust for a few decades [9], [10], [11], [12].", "startOffset": 104, "endOffset": 108}, {"referenceID": 10, "context": "Research has established many facets and influential factors [12], [11] for trust dynamics [13].", "startOffset": 61, "endOffset": 65}, {"referenceID": 9, "context": "Research has established many facets and influential factors [12], [11] for trust dynamics [13].", "startOffset": 67, "endOffset": 71}, {"referenceID": 11, "context": "Research has established many facets and influential factors [12], [11] for trust dynamics [13].", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Security, however, is more related to what is known as the CIA triad [14]: Confidentiality, Integrity and Availability.", "startOffset": 69, "endOffset": 73}, {"referenceID": 13, "context": "The fourth factor is related to safety [15].", "startOffset": 39, "endOffset": 43}, {"referenceID": 9, "context": "As we mentioned before, a trusting decision involves a level of uncertainty associated with the possibility that the trustee defects [11], [13].", "startOffset": 133, "endOffset": 137}, {"referenceID": 11, "context": "As we mentioned before, a trusting decision involves a level of uncertainty associated with the possibility that the trustee defects [11], [13].", "startOffset": 139, "endOffset": 143}, {"referenceID": 14, "context": "A number of existing surveys of computational trust have been made [16], [10], [17], [18].", "startOffset": 67, "endOffset": 71}, {"referenceID": 8, "context": "A number of existing surveys of computational trust have been made [16], [10], [17], [18].", "startOffset": 73, "endOffset": 77}, {"referenceID": 15, "context": "A number of existing surveys of computational trust have been made [16], [10], [17], [18].", "startOffset": 79, "endOffset": 83}, {"referenceID": 16, "context": "A number of existing surveys of computational trust have been made [16], [10], [17], [18].", "startOffset": 85, "endOffset": 89}, {"referenceID": 14, "context": "Sabater and Sierra [16] classify trust and reputation models firstly as either cognitive or game theoretic.", "startOffset": 19, "endOffset": 23}, {"referenceID": 15, "context": "[17], dividing the basic trust models into categories for statistical models, Bayesian", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "\u2022 Statistical Models: An early approach to modelling trust was proposed by Marsh [19].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "Griffiths and Luck [20] define the trust in an agent y, to be a value from the interval between 0 and 1: Ty \u2208 [0, 1].", "startOffset": 110, "endOffset": 116}, {"referenceID": 18, "context": "\u2022 Bayesian Analysis: More recent models take a Bayesian approach to modelling trust [21].", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "The tendency of an agent y to fulfil or default on its obligations is governed by its behaviour, which is represented as a variable Bx,y \u2208 [0, 1].", "startOffset": 139, "endOffset": 145}, {"referenceID": 19, "context": "\u2022 Discrete Models: Other models stipulate a finite, discrete set of trust categories [22], [23].", "startOffset": 85, "endOffset": 89}, {"referenceID": 20, "context": "\u2022 Discrete Models: Other models stipulate a finite, discrete set of trust categories [22], [23].", "startOffset": 91, "endOffset": 95}, {"referenceID": 19, "context": "For example, the model proposed by Abdul-Rahman and Hailes [22] stipulates four categories: very trustworthy, trustworthy, untrustworthy and very untrustworthy.", "startOffset": 59, "endOffset": 63}, {"referenceID": 21, "context": "\u2022 Belief Models: A variation on discrete models is belief-based model such as those proposed by Josang [24].", "startOffset": 103, "endOffset": 107}, {"referenceID": 0, "context": "\u03c9 y = (b, d, u, a), b, d, u, a \u2208 [0, 1] (5)", "startOffset": 33, "endOffset": 39}, {"referenceID": 22, "context": "\u2022 Fuzzy Models: Fuzzy models provide another way to deal with the uncertainty associated with trust [25], [26].", "startOffset": 100, "endOffset": 104}, {"referenceID": 23, "context": "\u2022 Fuzzy Models: Fuzzy models provide another way to deal with the uncertainty associated with trust [25], [26].", "startOffset": 106, "endOffset": 110}, {"referenceID": 0, "context": "A fuzzy set is a pair (X,m) where X is a set and m : X \u2192 [0, 1] is a membership function that specifies the grade of membership of x in (X,m).", "startOffset": 57, "endOffset": 63}, {"referenceID": 15, "context": "[17] define flow models as those that compute trust by transitive iteration through looped or arbitrarily long chains.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "Other examples of flow based metrics include the Appleseed trust metric [28].", "startOffset": 72, "endOffset": 76}, {"referenceID": 25, "context": "Models with formally modelled trust seeds may be termed centralized and those without may be termed distributed [29].", "startOffset": 112, "endOffset": 116}, {"referenceID": 26, "context": "\u2022 Optimisation Models: Another approach to modelling trust has been used in mathematical optimisation [30].", "startOffset": 102, "endOffset": 106}, {"referenceID": 27, "context": "Algorithms that incorporate trust region methods are known as restricted step methods, and broadly take the following approach [31]: If a \u2018good\u2019 model of the objective function is found within the trust region, then the region is expanded.", "startOffset": 127, "endOffset": 131}, {"referenceID": 17, "context": "However, alternative models, such as that proposed by Marsh [19], discuss the role of the disposition of the trustor in computing trust.", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "over a certain time period [16].", "startOffset": 27, "endOffset": 31}, {"referenceID": 28, "context": "More complex variants of this approach weight recent witness reports more highly than older reports, or stipulate different rates of reputation change depending on the current reputation of an agent [32].", "startOffset": 199, "endOffset": 203}, {"referenceID": 18, "context": "One such model [21] represents x\u2019s opinion of y\u2019s reputation as:", "startOffset": 15, "endOffset": 19}, {"referenceID": 24, "context": "Otherwise, trust remains local or subjective [28].", "startOffset": 45, "endOffset": 49}, {"referenceID": 29, "context": "Examples of trust models for computer networks include PeerTrust [33], FCTrust [34] and SFTrust [35].", "startOffset": 65, "endOffset": 69}, {"referenceID": 30, "context": "Examples of trust models for computer networks include PeerTrust [33], FCTrust [34] and SFTrust [35].", "startOffset": 79, "endOffset": 83}, {"referenceID": 31, "context": "Examples of trust models for computer networks include PeerTrust [33], FCTrust [34] and SFTrust [35].", "startOffset": 96, "endOffset": 100}, {"referenceID": 29, "context": "Other models build on this work [33].", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "Marsh [19] also", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "Marsh [19] considered change in trust over time as a result of different dispositions.", "startOffset": 6, "endOffset": 10}, {"referenceID": 32, "context": "Jonker and Treur [36] expand on the two trust dispositions by distinguishing six types of trust dynamics: blindly positive; blindly negative; slow positive + fast negative; balanced slow; balanced fast; and slow negative + fast positive.", "startOffset": 17, "endOffset": 21}, {"referenceID": 18, "context": "A parallel concept that is often discussed as a result of such experiences is confidence [20], [21], [25].", "startOffset": 95, "endOffset": 99}, {"referenceID": 22, "context": "A parallel concept that is often discussed as a result of such experiences is confidence [20], [21], [25].", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "An alternative, simpler definition of confidence used in a fuzzy setting is a simple sum of the number of experiences (positive and negative) encountered by the agent [25].", "startOffset": 167, "endOffset": 171}, {"referenceID": 25, "context": "failure-prone elements [29].", "startOffset": 23, "endOffset": 27}, {"referenceID": 25, "context": "Some researchers have equated reliability with trust [29], while others make the weaker assumption that reliability influences trust [37].", "startOffset": 53, "endOffset": 57}, {"referenceID": 33, "context": "Some researchers have equated reliability with trust [29], while others make the weaker assumption that reliability influences trust [37].", "startOffset": 133, "endOffset": 137}, {"referenceID": 34, "context": "\u2022 Belief-Desire-Intention Agents: The BDI model [38] enables the definition of intelligent agents that have:", "startOffset": 48, "endOffset": 52}, {"referenceID": 35, "context": "popular target for the exploration of trust models [39], [40], [41].", "startOffset": 51, "endOffset": 55}, {"referenceID": 36, "context": "popular target for the exploration of trust models [39], [40], [41].", "startOffset": 57, "endOffset": 61}, {"referenceID": 37, "context": "popular target for the exploration of trust models [39], [40], [41].", "startOffset": 63, "endOffset": 67}, {"referenceID": 35, "context": "One example is the ability-belief-commitment-desire (ABCD) model of trust [39], which integrates with the logic of rational agents (LORA) BDI agent theory.", "startOffset": 74, "endOffset": 78}, {"referenceID": 37, "context": "[41] provide a methodology for incorporating multiple different trust models BDI agents.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Aref and Tran [26], for example, describe a fuzzy trust model", "startOffset": 14, "endOffset": 18}, {"referenceID": 38, "context": "[42] proposed a variation of the PSO algorithm for trust path selection in networks.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "[43] propose a different variation of PSO for incorporating trust to solve grid task scheduling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "PSO algorithms are also particularly compatible with the trust-region formalism, and examples of algorithms that incorporate trust-regions with PSO have been proposed [44].", "startOffset": 167, "endOffset": 171}, {"referenceID": 17, "context": "Marsh\u2019s early work [19] is one such example.", "startOffset": 19, "endOffset": 23}, {"referenceID": 7, "context": "Marsh [9] outlines different ways in which trust plays a part in the formation of cooperative groups:", "startOffset": 6, "endOffset": 9}, {"referenceID": 41, "context": "\u2022 Detecting Deceitful Agents: Deceit is considered commonplace in certain industries such as trade [46], [47], [48], [49], computer networks [50] and online communities [33].", "startOffset": 105, "endOffset": 109}, {"referenceID": 42, "context": "\u2022 Detecting Deceitful Agents: Deceit is considered commonplace in certain industries such as trade [46], [47], [48], [49], computer networks [50] and online communities [33].", "startOffset": 141, "endOffset": 145}, {"referenceID": 29, "context": "\u2022 Detecting Deceitful Agents: Deceit is considered commonplace in certain industries such as trade [46], [47], [48], [49], computer networks [50] and online communities [33].", "startOffset": 169, "endOffset": 173}, {"referenceID": 41, "context": "This can assist with the detection of deceit in trade scenarios [46], [47], [48], [49], or malicious behaviour on computer networks [33], [50].", "startOffset": 70, "endOffset": 74}, {"referenceID": 29, "context": "This can assist with the detection of deceit in trade scenarios [46], [47], [48], [49], or malicious behaviour on computer networks [33], [50].", "startOffset": 132, "endOffset": 136}, {"referenceID": 42, "context": "This can assist with the detection of deceit in trade scenarios [46], [47], [48], [49], or malicious behaviour on computer networks [33], [50].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "\u2022 Reputation: Reputation models are increasingly ubiquitous among internet mediated service providers [17].", "startOffset": 102, "endOffset": 106}, {"referenceID": 16, "context": "[18] include in their survey of trust models a survey of performance assessment methods for such models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 43, "context": "An example of a simulation testbed is the agent reputation and trust (ART) testbed [51], which simulates painting appraisers with varying levels of expertise in different artistic eras.", "startOffset": 83, "endOffset": 87}, {"referenceID": 16, "context": "However, because many datasets are not specifically collected for the purpose of evaluating trust models, they may lack the ground truth about the user behaviour to facilitate more in-depth analysis of the performance of proposed trust models [18].", "startOffset": 243, "endOffset": 247}, {"referenceID": 44, "context": "The Trust Bus acts as the message passing interface that learns \u2013 through automatic knowledge acquisition methods [52] \u2013 from and modifies massages as they get transferred from one system module to another.", "startOffset": 114, "endOffset": 118}, {"referenceID": 9, "context": "The three remaining modules represent the cornerstones for trust in psychology and social science research and were elicited in our previous work [11], [13], [12].", "startOffset": 146, "endOffset": 150}, {"referenceID": 11, "context": "The three remaining modules represent the cornerstones for trust in psychology and social science research and were elicited in our previous work [11], [13], [12].", "startOffset": 152, "endOffset": 156}, {"referenceID": 10, "context": "The three remaining modules represent the cornerstones for trust in psychology and social science research and were elicited in our previous work [11], [13], [12].", "startOffset": 158, "endOffset": 162}, {"referenceID": 45, "context": "addition of veracity and value, and finally the 6Vs with the addition of variability [53], [54], [55].", "startOffset": 85, "endOffset": 89}, {"referenceID": 46, "context": "addition of veracity and value, and finally the 6Vs with the addition of variability [53], [54], [55].", "startOffset": 91, "endOffset": 95}, {"referenceID": 47, "context": "addition of veracity and value, and finally the 6Vs with the addition of variability [53], [54], [55].", "startOffset": 97, "endOffset": 101}, {"referenceID": 48, "context": "Sensing is what allows a system to interact with its environment in a flexible and non-deterministic way, as apposed to performing preprogrammed actions based on a set of scheduled functions and/or rule sets [56].", "startOffset": 208, "endOffset": 212}, {"referenceID": 49, "context": "years have marked unprecedented advances in sensor technology, making available miniaturised, highly portable, accurate and reliable sensors, with high throughput and low cost [57].", "startOffset": 176, "endOffset": 180}, {"referenceID": 50, "context": "[58] identified the key facilitators that enabled this explosion of achievements in sensing human activity.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "[58] was later discussed by Mukhopadhyay [59], who considers eight components where sensing research should concentrate for improving the overall performance of human activity wearable sensing systems: (1) types of sensors to be used, (2) type of communication protocols to be employed, (3) type of activities to be monitored, (4) techniques for extracting important features from activities, (5) design and development of small, light-weight, powerful and low-cost smart sensor nodes, (6) harvesting of energy for normal operation and communication, (7) ability to be used with the present day mobile devices, (8) potential to be reconfigured for new applications/users.", "startOffset": 0, "endOffset": 4}, {"referenceID": 51, "context": "[58] was later discussed by Mukhopadhyay [59], who considers eight components where sensing research should concentrate for improving the overall performance of human activity wearable sensing systems: (1) types of sensors to be used, (2) type of communication protocols to be employed, (3) type of activities to be monitored, (4) techniques for extracting important features from activities, (5) design and development of small, light-weight, powerful and low-cost smart sensor nodes, (6) harvesting of energy for normal operation and communication, (7) ability to be used with the present day mobile devices, (8) potential to be reconfigured for new applications/users.", "startOffset": 41, "endOffset": 45}, {"referenceID": 50, "context": "Both studies, [58], [59], note how each of these components have been on a path of miniaturisation, where the advances in", "startOffset": 14, "endOffset": 18}, {"referenceID": 51, "context": "Both studies, [58], [59], note how each of these components have been on a path of miniaturisation, where the advances in", "startOffset": 20, "endOffset": 24}, {"referenceID": 51, "context": "In [59] the author states that this surge of wearable sensing will continue to expand towards more and more domains, and cites industry reports concluding that the penetration of research advances towards the consumer", "startOffset": 3, "endOffset": 7}, {"referenceID": 50, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 50, "endOffset": 54}, {"referenceID": 52, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 56, "endOffset": 60}, {"referenceID": 53, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 62, "endOffset": 66}, {"referenceID": 54, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 68, "endOffset": 72}, {"referenceID": 55, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 74, "endOffset": 78}, {"referenceID": 51, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 80, "endOffset": 84}, {"referenceID": 56, "context": "Extensive and very recent reviews can be found in [58], [61], [62], [63], [64], [59] and [65].", "startOffset": 89, "endOffset": 93}, {"referenceID": 51, "context": "In the following, we describe the most common types of sensing systems used in monitoring human activity [59], and we focus our discussion on the sampling rate and the subsequent data resulting from their operation.", "startOffset": 105, "endOffset": 109}, {"referenceID": 51, "context": "Body temperature monitoring can be used either for determining the respective physiological/medical conditions or for classifying and storing for further use historical physiological activity data, or even for harvesting energy from body heat [59].", "startOffset": 243, "endOffset": 247}, {"referenceID": 57, "context": "Contact technologies such as thermocouples, resistive temperature detection, and organic diodes have been proposed over time [66].", "startOffset": 125, "endOffset": 129}, {"referenceID": 58, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 108, "endOffset": 112}, {"referenceID": 59, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 114, "endOffset": 118}, {"referenceID": 60, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 156, "endOffset": 160}, {"referenceID": 61, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 162, "endOffset": 166}, {"referenceID": 62, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 185, "endOffset": 189}, {"referenceID": 51, "context": "A variety of sensor modalities are available for heart rate measurement and monitoring, such as sound based [68], [69], optics (photoplethysmography) based [70], [71] or pressure based [72]; also monitoring by visual cues such as the face colour [59] have been also reported in the literature.", "startOffset": 246, "endOffset": 250}, {"referenceID": 63, "context": "The sensing can be invasive, where the electrodes are implanted under the scalp, or non-invasive, where the electrodes are placed on the scalp either individually or as part of customised caps [75] in which the electrodes are precisely positioned.", "startOffset": 193, "endOffset": 197}, {"referenceID": 64, "context": "Research applications are especially in the fields of cognitive science and engineering [76], and human/brain-computer interaction [77], where the high temporal resolution of EEG sensing brings valuable information about real-time brain activity, capturing changes in cognitive load and states.", "startOffset": 88, "endOffset": 92}, {"referenceID": 65, "context": "Research applications are especially in the fields of cognitive science and engineering [76], and human/brain-computer interaction [77], where the high temporal resolution of EEG sensing brings valuable information about real-time brain activity, capturing changes in cognitive load and states.", "startOffset": 131, "endOffset": 135}, {"referenceID": 66, "context": "Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution.", "startOffset": 86, "endOffset": 90}, {"referenceID": 67, "context": "Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution.", "startOffset": 92, "endOffset": 96}, {"referenceID": 68, "context": "Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution.", "startOffset": 98, "endOffset": 102}, {"referenceID": 69, "context": "Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution.", "startOffset": 202, "endOffset": 206}, {"referenceID": 70, "context": "Classic clinical EEG sensing systems operate at sampling rates between 100 and 256 Hz [78], [79], [80], while some of the latest EEG systems are capable of recording at sampling rates as high as 20 kHz [81], [82], [83], that is, a sub-millisecond temporal resolution.", "startOffset": 214, "endOffset": 218}, {"referenceID": 63, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 149, "endOffset": 153}, {"referenceID": 71, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 203, "endOffset": 207}, {"referenceID": 69, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 405, "endOffset": 409}, {"referenceID": 72, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 475, "endOffset": 479}, {"referenceID": 68, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 540, "endOffset": 544}, {"referenceID": 73, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 604, "endOffset": 608}, {"referenceID": 74, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Reference [Hz] [Hz] EGI Geodesic 400 clinical fixed N/A 32-256 EEG 1000 [75] Mindmedia Nexus32 research fixed N/A 24 EEG 2048 [84] Mitsar EEG-202 series research fixed 0-150 24-31 EEG 2000 [85] Nihon Kohden Neuroxax 1200 research fixed 0-1200 256 EEG, 16 DC 10000 [86] Compumedics GraelHD research fixed 0-3500 4 \u00d7 64 EEG 20000 [81] Neurovirtual BW series clinical fixed 0-500 25-50 EEG, 8 DC 2000 [87] Nihon Kohden Trackit clinical mobile 0-100 32 EEG, 4 DC 200 [80] NeuroConn Thera Prax research mobile 0-1200 22 EEG 32-4000 [88] EGI Geodesic 100 clinical mobile N/A 32 EEG 1000 [89] Medicom MTD encephalan EEGR clinical mobile 0.", "startOffset": 658, "endOffset": 662}, {"referenceID": 75, "context": "016-70 20 EEG 2000 [90] Neurowerk Neurowerk DB series clinical mobile N/A 21-25 EEG 128-512 [91] Compumedics GraelHD clinical mobile 0-580 32 EEG 16000 [83] Compumedics Nuamps clinical mobile 0-260 40 EEG 1000 [92] antNeuro eego mylab clinical mobile N/A 32-256 EEG 16000 [82] Deymed TruScan series research mobile 0.", "startOffset": 19, "endOffset": 23}, {"referenceID": 70, "context": "016-70 20 EEG 2000 [90] Neurowerk Neurowerk DB series clinical mobile N/A 21-25 EEG 128-512 [91] Compumedics GraelHD clinical mobile 0-580 32 EEG 16000 [83] Compumedics Nuamps clinical mobile 0-260 40 EEG 1000 [92] antNeuro eego mylab clinical mobile N/A 32-256 EEG 16000 [82] Deymed TruScan series research mobile 0.", "startOffset": 152, "endOffset": 156}, {"referenceID": 76, "context": "16-450 24-256 EEG 4000 [93] Neurowerk Neurowerk EEG mobile clinical wearable N/A 16 EEG 128-512 [91] antNeuro eego sports clinical wearable N/A 32-64 EEG 2000 [94] Neurovirtual BWmini clinical wearable 0-500 33 EEG, 2 DC 1000 [95] NeuroSky BrainWave research wearable 0-100 1 EEG 512 [96] Mitsar EEG-201 series clinical wearable 0.", "startOffset": 23, "endOffset": 27}, {"referenceID": 77, "context": "16-450 24-256 EEG 4000 [93] Neurowerk Neurowerk EEG mobile clinical wearable N/A 16 EEG 128-512 [91] antNeuro eego sports clinical wearable N/A 32-64 EEG 2000 [94] Neurovirtual BWmini clinical wearable 0-500 33 EEG, 2 DC 1000 [95] NeuroSky BrainWave research wearable 0-100 1 EEG 512 [96] Mitsar EEG-201 series clinical wearable 0.", "startOffset": 159, "endOffset": 163}, {"referenceID": 78, "context": "16-450 24-256 EEG 4000 [93] Neurowerk Neurowerk EEG mobile clinical wearable N/A 16 EEG 128-512 [91] antNeuro eego sports clinical wearable N/A 32-64 EEG 2000 [94] Neurovirtual BWmini clinical wearable 0-500 33 EEG, 2 DC 1000 [95] NeuroSky BrainWave research wearable 0-100 1 EEG 512 [96] Mitsar EEG-201 series clinical wearable 0.", "startOffset": 226, "endOffset": 230}, {"referenceID": 79, "context": "16-450 24-256 EEG 4000 [93] Neurowerk Neurowerk EEG mobile clinical wearable N/A 16 EEG 128-512 [91] antNeuro eego sports clinical wearable N/A 32-64 EEG 2000 [94] Neurovirtual BWmini clinical wearable 0-500 33 EEG, 2 DC 1000 [95] NeuroSky BrainWave research wearable 0-100 1 EEG 512 [96] Mitsar EEG-201 series clinical wearable 0.", "startOffset": 284, "endOffset": 288}, {"referenceID": 80, "context": "2-45 14 EEG, 2 ref 128 [97], [98], [79] Emotiv Epoc+ research wearable 0.", "startOffset": 23, "endOffset": 27}, {"referenceID": 81, "context": "2-45 14 EEG, 2 ref 128 [97], [98], [79] Emotiv Epoc+ research wearable 0.", "startOffset": 29, "endOffset": 33}, {"referenceID": 67, "context": "2-45 14 EEG, 2 ref 128 [97], [98], [79] Emotiv Epoc+ research wearable 0.", "startOffset": 35, "endOffset": 39}, {"referenceID": 67, "context": "16-43 14 EEG, 2 ref 256 [79] Emotiv Insight hobby wearable N/A 5 EEG, 2 ref 128 [78] Macrotellect BrainLink hobby wearable 8-30 N/A N/A [99] Interaxon Muse hobby wearable N/A 7 EEG N/A [100], [101] Somnomedics SOMNOsecren EEG 32 research wearable N/A 25 EEG 4-512 [102] Neurosoft Neuron Spectrum AM clinical wearable N/A 21 EEG 1000 [103] Deymed TruScan wireless research wearable 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 66, "context": "16-43 14 EEG, 2 ref 256 [79] Emotiv Insight hobby wearable N/A 5 EEG, 2 ref 128 [78] Macrotellect BrainLink hobby wearable 8-30 N/A N/A [99] Interaxon Muse hobby wearable N/A 7 EEG N/A [100], [101] Somnomedics SOMNOsecren EEG 32 research wearable N/A 25 EEG 4-512 [102] Neurosoft Neuron Spectrum AM clinical wearable N/A 21 EEG 1000 [103] Deymed TruScan wireless research wearable 0.", "startOffset": 80, "endOffset": 84}, {"referenceID": 82, "context": "16-43 14 EEG, 2 ref 256 [79] Emotiv Insight hobby wearable N/A 5 EEG, 2 ref 128 [78] Macrotellect BrainLink hobby wearable 8-30 N/A N/A [99] Interaxon Muse hobby wearable N/A 7 EEG N/A [100], [101] Somnomedics SOMNOsecren EEG 32 research wearable N/A 25 EEG 4-512 [102] Neurosoft Neuron Spectrum AM clinical wearable N/A 21 EEG 1000 [103] Deymed TruScan wireless research wearable 0.", "startOffset": 185, "endOffset": 190}, {"referenceID": 83, "context": "16-43 14 EEG, 2 ref 256 [79] Emotiv Insight hobby wearable N/A 5 EEG, 2 ref 128 [78] Macrotellect BrainLink hobby wearable 8-30 N/A N/A [99] Interaxon Muse hobby wearable N/A 7 EEG N/A [100], [101] Somnomedics SOMNOsecren EEG 32 research wearable N/A 25 EEG 4-512 [102] Neurosoft Neuron Spectrum AM clinical wearable N/A 21 EEG 1000 [103] Deymed TruScan wireless research wearable 0.", "startOffset": 192, "endOffset": 197}, {"referenceID": 76, "context": "01-1200 32-256 EEG 6000 [93] Deymed BFB clinical wearable 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 84, "context": "3-70 2 EEG 256 [104]", "startOffset": 15, "endOffset": 20}, {"referenceID": 85, "context": "05-300 12 1000 [105] Cardioline AR600 series clinical mobile 0.", "startOffset": 15, "endOffset": 20}, {"referenceID": 86, "context": "05-150 12 500-1000 [106] TSE UCARD200 clinical mobile 0.", "startOffset": 19, "endOffset": 24}, {"referenceID": 87, "context": "05-150 12 1600 [107] Nasan Simul-G clinical mobile 0.", "startOffset": 15, "endOffset": 20}, {"referenceID": 88, "context": "05-150 12 N/A [108] Longfian ECG-1112 clinical mobile 0.", "startOffset": 14, "endOffset": 19}, {"referenceID": 89, "context": "05-160 12 1000 [109] Nasan ESY-G1 clinical mobile 0.", "startOffset": 15, "endOffset": 20}, {"referenceID": 90, "context": "05-150 3 (12 serial) N/A [111] Nasiff CardioCard clinical mobile 0.", "startOffset": 25, "endOffset": 30}, {"referenceID": 91, "context": "05-150 12 250-1000 [112] SpaceLab CardioDirect 12 clinical mobile 0-15 12 2000 [113] CustoMed CustoCardio 100 series clinical mobile 0-500 12 1000-4000 [114] Kalamed KES121 series clinical mobile 0.", "startOffset": 19, "endOffset": 24}, {"referenceID": 92, "context": "05-150 12 250-1000 [112] SpaceLab CardioDirect 12 clinical mobile 0-15 12 2000 [113] CustoMed CustoCardio 100 series clinical mobile 0-500 12 1000-4000 [114] Kalamed KES121 series clinical mobile 0.", "startOffset": 79, "endOffset": 84}, {"referenceID": 93, "context": "05-165 12 2000 [115] Kalamed KES1000 hobby wearable 0.", "startOffset": 15, "endOffset": 20}, {"referenceID": 51, "context": "For example, in [59] the author mentions a compact plaster sensor designed for wearable low cost cardiac healthcare, which uses a low power high resolution thoracic impedance variance for ECG monitoring.", "startOffset": 16, "endOffset": 20}, {"referenceID": 100, "context": "a variety of psycho-physiological conditions [128].", "startOffset": 45, "endOffset": 50}, {"referenceID": 94, "context": "Producer Model Grade Mobility Frequency range Channels Sampling rate/channel Encoding Reference [Hz] [Hz] [bits/sample] CustoMed CustoCardio 200 series clinical mobile 0-500 12 1000-4000 [118] Kalamed KES121 series clinical mobile 0.", "startOffset": 187, "endOffset": 192}, {"referenceID": 93, "context": "05-165 12 2000 [115] Eccosur ECG-View clinical mobile 0.", "startOffset": 15, "endOffset": 20}, {"referenceID": 95, "context": "05-100 12 256-600 [119] Thor Thoriax PC clinical mobile N/A 12 2000 12 [120] SpaceLab CardioDirect 12S clinical wearable 0-150 12 2000 [121] Cardioline CubeStress HD+ clinical wearable 0.", "startOffset": 71, "endOffset": 76}, {"referenceID": 96, "context": "05-300 6+6 or 12, AVG 1000 [122] Cardionics CarTouch clinical wearable N/A 12 1000 16 [123] Labtech EC12RS clinical wearable 0.", "startOffset": 27, "endOffset": 32}, {"referenceID": 97, "context": "05-300 6+6 or 12, AVG 1000 [122] Cardionics CarTouch clinical wearable N/A 12 1000 16 [123] Labtech EC12RS clinical wearable 0.", "startOffset": 86, "endOffset": 91}, {"referenceID": 98, "context": "05-150 12 1000 [124] Amedtec CardioPart 12 Blue clinical wearable 0-150 12 8000 [125] Thor Thoriax Home hobby wearable 0.", "startOffset": 80, "endOffset": 85}, {"referenceID": 99, "context": "5-40 1 (differential) N/A 12 [126]", "startOffset": 29, "endOffset": 34}, {"referenceID": 101, "context": "Modern EDA sensing is largely used for capturing complex emotional and cognitive states [130], [128], in contexts like anxiety monitoring and control, stress detection, monitoring epileptic patients with drug resistance, or as part of polygraph equipment for lie detection in conjunction with other biofeedback sensors such as heart rate and blood pressure [131], or respiratory rate.", "startOffset": 88, "endOffset": 93}, {"referenceID": 100, "context": "Modern EDA sensing is largely used for capturing complex emotional and cognitive states [130], [128], in contexts like anxiety monitoring and control, stress detection, monitoring epileptic patients with drug resistance, or as part of polygraph equipment for lie detection in conjunction with other biofeedback sensors such as heart rate and blood pressure [131], or respiratory rate.", "startOffset": 95, "endOffset": 100}, {"referenceID": 56, "context": "An thorough review on inertial sensors for human activity monitoring, with a focus on wearability can be found in [65].", "startOffset": 114, "endOffset": 118}, {"referenceID": 102, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 192, "endOffset": 197}, {"referenceID": 103, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 264, "endOffset": 269}, {"referenceID": 104, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 466, "endOffset": 471}, {"referenceID": 105, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 564, "endOffset": 569}, {"referenceID": 106, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 690, "endOffset": 695}, {"referenceID": 107, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 920, "endOffset": 925}, {"referenceID": 108, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1057, "endOffset": 1062}, {"referenceID": 109, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1133, "endOffset": 1138}, {"referenceID": 110, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1196, "endOffset": 1201}, {"referenceID": 111, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1269, "endOffset": 1274}, {"referenceID": 112, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1354, "endOffset": 1359}, {"referenceID": 113, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1581, "endOffset": 1586}, {"referenceID": 114, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1687, "endOffset": 1692}, {"referenceID": 115, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1734, "endOffset": 1739}, {"referenceID": 116, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 1797, "endOffset": 1802}, {"referenceID": 117, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 2031, "endOffset": 2036}, {"referenceID": 117, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 2087, "endOffset": 2092}, {"referenceID": 118, "context": "Producer Model Mobility Format Inertial sensors Other bio-sensors Reference Angelsensor Classic/M1 wearable wristband A, G HR, skin temperature, oximeter [137] Apple Watch wearable watch A HR [138] Basis BasisPeak wearable watch 3 axis A HR, GSR, skin temperature [139] Empatica E series wearable wristband 3 axis A HR, GSR, skin temperature [140] Empatica E series wearable wristband 3 axis A, G HR, GSR, skin temperature [131] Fitbit Zip wearable pendant 3 axis A [141] Fitbit One/Flex/Charge/Alta wearable wristband unspecified motion sensor HR, simplified ECG [142] Fitbit Blaze/Surge wearable watch unspecified motion sensor HR, simplified ECG [143] Fitbug Orb wearable watch 3 axis A [144] Garmin VivoFit/VivoSmart series wearable wristband unspecified motion sensor [145] Garmin VivoActive series wearable watch unspecified motion sensor [145] Google Android-Wear wearable watch market dependant market dependant [146] iHealth Edge wearable wristband unspecified motion sensor [147] Jawbone UP series wearable wristband 3 axis A HR, GSR, respiration [148] LG Lifeband Touch series wearable wristband unspecified motion sensor [149] LG watch series wearable watch unspecified motion sensor [150] Medisana ViFit series wearable wristband unspecified motion sensor [151] Microsoft Band wearable wristband 3 axis A, 3 axis G HR, GSR, skin temperature [152] Misfit Shine/Ray series wearable watch 3 axis A [153] Misfit Flash wearable watch 3 axis A [153] Misfit Ray wearable pendant 3 axis A [153] Misfit Link wearable button 3 axis A [153] Nike Fuelband wearable watch 3 axis A [154] Pebble SmartWatch series wearable watch 3 axis A [155] Razer Nabu/NabuX wearable wristband 3 axis A [156] Razer Nabu Watch wearable watch 3 axis A [157] Salutron LifeTrak series wearable watch 3 axis A HR, ECG [158] Samsung GearS series wearable watch A, G HR [159] Samsung GearFit series wearable wristband A, G HR [160] Sensoria SensoriaFitness wearable smart sock 3 axis A 3 pressure sensors [161] Sony Smartband series wearable wristband A [162] Sony Smartwatch series wearable watch 3 axis A, G [162] Striiv Fusion series wearable wristband/watch 3D accelerometer [163] Withings Pulse O2 wearable pendant 3 axis A heart rate, oximeter [164] Withings Go wearable pendant 3 axis A [165]", "startOffset": 2156, "endOffset": 2161}, {"referenceID": 119, "context": "Sensor fusion [166] is the process of combining the sensory data coming from disparate sources in a way that (1) reduces the", "startOffset": 14, "endOffset": 19}, {"referenceID": 120, "context": "Several thorough discussions can be found in the literature, proposing fusion methods with application in various fields of activity, such as control systems [167], thermal engineering [168], wearable robotics [169], or 3D computer vision [170].", "startOffset": 158, "endOffset": 163}, {"referenceID": 121, "context": "Several thorough discussions can be found in the literature, proposing fusion methods with application in various fields of activity, such as control systems [167], thermal engineering [168], wearable robotics [169], or 3D computer vision [170].", "startOffset": 185, "endOffset": 190}, {"referenceID": 122, "context": "Several thorough discussions can be found in the literature, proposing fusion methods with application in various fields of activity, such as control systems [167], thermal engineering [168], wearable robotics [169], or 3D computer vision [170].", "startOffset": 210, "endOffset": 215}, {"referenceID": 123, "context": "Several thorough discussions can be found in the literature, proposing fusion methods with application in various fields of activity, such as control systems [167], thermal engineering [168], wearable robotics [169], or 3D computer vision [170].", "startOffset": 239, "endOffset": 244}, {"referenceID": 119, "context": "From a project management perspective, in [166], the author describes abstract, generic and rigid architectures.", "startOffset": 42, "endOffset": 47}, {"referenceID": 124, "context": "Another classification proposed in the literature [171], [172], [173] takes a conceptual approach and discusses four main", "startOffset": 50, "endOffset": 55}, {"referenceID": 125, "context": "Another classification proposed in the literature [171], [172], [173] takes a conceptual approach and discusses four main", "startOffset": 57, "endOffset": 62}, {"referenceID": 126, "context": "Another classification proposed in the literature [171], [172], [173] takes a conceptual approach and discusses four main", "startOffset": 64, "endOffset": 69}, {"referenceID": 125, "context": "can be further generated [172].", "startOffset": 25, "endOffset": 30}, {"referenceID": 124, "context": "This classification is perhaps the most popular for both researchers and practitioners, becoming in time a fundamental part of the undergraduate control engineering curriculum [171].", "startOffset": 176, "endOffset": 181}, {"referenceID": 125, "context": "with the same name [172].", "startOffset": 19, "endOffset": 24}, {"referenceID": 127, "context": "The interested reader can find thorough reviews of the general fusion architectures in a number of studies from different historical periods [174], [166], [172], [173].", "startOffset": 141, "endOffset": 146}, {"referenceID": 119, "context": "The interested reader can find thorough reviews of the general fusion architectures in a number of studies from different historical periods [174], [166], [172], [173].", "startOffset": 148, "endOffset": 153}, {"referenceID": 125, "context": "The interested reader can find thorough reviews of the general fusion architectures in a number of studies from different historical periods [174], [166], [172], [173].", "startOffset": 155, "endOffset": 160}, {"referenceID": 126, "context": "The interested reader can find thorough reviews of the general fusion architectures in a number of studies from different historical periods [174], [166], [172], [173].", "startOffset": 162, "endOffset": 167}, {"referenceID": 128, "context": "mechanical, electrical, optical, electronic) or biologically if talking about natural entities, such as the neural sensory processing in animals with a central nervous system [175], [176].", "startOffset": 175, "endOffset": 180}, {"referenceID": 129, "context": "Extensive historical views on analog computers can be found in [177], and also in a special issue of IEEE Control Systems dedicated to the history of analog computers, from which we cite here the editorial article [178] signed by Lundberg.", "startOffset": 63, "endOffset": 68}, {"referenceID": 130, "context": "Extensive historical views on analog computers can be found in [177], and also in a special issue of IEEE Control Systems dedicated to the history of analog computers, from which we cite here the editorial article [178] signed by Lundberg.", "startOffset": 214, "endOffset": 219}, {"referenceID": 131, "context": "Extensive reviews of these computers can be found in the literature of the 1960s and 1970s [179], and more recently in [176].", "startOffset": 91, "endOffset": 96}, {"referenceID": 132, "context": "environmental limitations [181].", "startOffset": 26, "endOffset": 31}, {"referenceID": 133, "context": "\u2022 Revival of analog computing: Analog computation certainly went into an eclipse in the last few decades, due to the rise of digital computers, however recently more and more authors acknowledge that analog computation is inherent to most of the existing natural systems [182].", "startOffset": 271, "endOffset": 276}, {"referenceID": 128, "context": "In [175] the author even note that some digital computing paradigms are actually", "startOffset": 3, "endOffset": 8}, {"referenceID": 134, "context": "Cowan and colleagues [183] proposed a single-chip VLSI analog", "startOffset": 21, "endOffset": 26}, {"referenceID": 135, "context": "Later, Schell and Tsividis [184] proposed a hybrid signal processor where fixed sampling and clock rates of a conventional DSP were eliminated to create a clock-less digital signal processor.", "startOffset": 27, "endOffset": 32}, {"referenceID": 136, "context": "Recently Guo and colleagues [185] demonstrated a continuous-time hybrid computing unit in 65nm CMOS technology, capable of solving nonlinear differential equations up to 4th order, and scalable to higher orders.", "startOffset": 28, "endOffset": 33}, {"referenceID": 137, "context": "Of these, von Neumann, Harvard and modified-Harvard architectures are those that provided the majority of the digital computers available to date [186].", "startOffset": 146, "endOffset": 151}, {"referenceID": 138, "context": "\u2022 Highly parallel processing on GPUs: A significant step towards increasing processing speed was made during the mid 2000s, when general-purpose computing tasks started to be ported from CPUs onto graphic processing units (GPU) [187],", "startOffset": 228, "endOffset": 233}, {"referenceID": 139, "context": "[188].", "startOffset": 0, "endOffset": 5}, {"referenceID": 140, "context": "Recently, hardware-independent platforms have been released, such as the proprietary DirectCompute from Microsoft as part of DirectX API [189], and the open-source OpenCL [192].", "startOffset": 171, "endOffset": 176}, {"referenceID": 140, "context": "Recently, the open source platform-independent OpenCL, developed by Khronos Group [192] became popular for that it allows development of code for both GPUs and CPUs,", "startOffset": 82, "endOffset": 87}, {"referenceID": 141, "context": "Thus, an increased interest have been shown for the use of FPGAs (Field-Programable Gate Array), which by design have the potential to be reprogrammed at runtime, being in essence computing units that can reconfigure themselves to suit the task of interest [193].", "startOffset": 257, "endOffset": 262}, {"referenceID": 142, "context": "FPGAs were bond to these purposes also because of their low performance, combined with large physical dimension and high energy consumption [194].", "startOffset": 140, "endOffset": 145}, {"referenceID": 143, "context": "A detailed review of the high speed FPGA SoC and soft processors can be found in [195].", "startOffset": 81, "endOffset": 86}, {"referenceID": 144, "context": "Another recent use of FPGAs is hardware acceleration, where FPGAs are used as coprocessors, to assist a general-use processors in acceleration of certain parts a task or algorithm [196].", "startOffset": 180, "endOffset": 185}, {"referenceID": 145, "context": "In 2006, researchers at Georgia Institute of Technology published the details of a field programmable neural array [197].", "startOffset": 115, "endOffset": 120}, {"referenceID": 146, "context": "In 2012, Spintronic Rand Purdue University [198] announced a neuromorphic chip that used lateral spin valves and memristors.", "startOffset": 43, "endOffset": 48}, {"referenceID": 147, "context": "In 2014 Stanford University announced Neurogrid [200] structure.", "startOffset": 48, "endOffset": 53}, {"referenceID": 148, "context": "The authors designed for this reason an end-to-end ecosystem complete with a custom simulator and a new programming language for composing networks of neurosynaptic cores, called corelet [202] implemented in Matlab code.", "startOffset": 187, "endOffset": 192}, {"referenceID": 149, "context": "[203] to differentiate between sensitivity to context; that is, the machine is using context", "startOffset": 0, "endOffset": 5}, {"referenceID": 150, "context": "Taking this level of intelligence to autonomy is the vision of \u2018autonomic computing\u2019 that was first introduced by Paul Horn [204] in his 2001 keynote address to the National Academy of Engineers at Harvard University.", "startOffset": 124, "endOffset": 129}, {"referenceID": 149, "context": "[203] who refer to a system as context-aware \u201cif it uses context to provide relevant information and/or services to the user, where relevancy depends on the users task.", "startOffset": 0, "endOffset": 5}, {"referenceID": 151, "context": "Verification [205], in particular, raises more challenges and requires a significant amount of data in real-time operations.", "startOffset": 13, "endOffset": 18}, {"referenceID": 10, "context": "The complexity of a network of Cyborg swarms, an extension of a problem we called in our previous research as Cognitive Cyber Symbiosis (CoCyS) [12], [55],", "startOffset": 144, "endOffset": 148}, {"referenceID": 47, "context": "The complexity of a network of Cyborg swarms, an extension of a problem we called in our previous research as Cognitive Cyber Symbiosis (CoCyS) [12], [55],", "startOffset": 150, "endOffset": 154}], "year": 2016, "abstractText": "Despite the advances made in artificial intelligence, software agents, and robotics, there is little we see today that we can truly call a fully autonomous system. We conjecture that the main inhibitor for advancing autonomy is lack of trust. Trusted autonomy is the scientific and engineering field to establish the foundations and ground work for developing trusted autonomous systems (robotics and software agents) that can be used in our daily life, and can be integrated with humans seamlessly, naturally and efficiently. In this paper, we review this literature to reveal opportunities for researchers and practitioners to work on topics that can create a leap forward in advancing the field of trusted autonomy. We focus the paper on the \u2018trust\u2019 component as the uniting technology between humans and machines. Our inquiry into this topic revolves around three sub-topics: (1) reviewing and positioning the trust modelling literature for the purpose of trusted autonomy; (2) reviewing a critical subset of sensor technologies that allow a machine to sense human states; and (3) distilling some critical questions for advancing the field of trusted autonomy. The inquiry is augmented with conceptual models that we propose along the way by recompiling and reshaping the literature into forms that enables trusted autonomous systems to become a reality. The paper offers a vision for a Trusted Cyborg Swarm, an extension of our previous Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in a harmonious, seamless, and coordinated manner.", "creator": "LaTeX with hyperref package"}}}