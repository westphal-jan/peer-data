{"id": "1605.02129", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-May-2016", "title": "Adobe-MIT submission to the DSTC 4 Spoken Language Understanding pilot task", "abstract": "the dialog state tracking capacity challenge 4 ( dstc 4 ) proposes several pilot tasks. in this paper, we focus on the spoken language understanding pilot vocabulary task, which therefore consists of tagging a given utterance with speech acts and semantic slots. we compare different classifiers : achieving the best system obtains { 0. 52 and 0. 67 + f1 - scores anywhere on the test set for speech act recognition for the tourist and the guide observer respectively, and 0. 52 f1 - score for semantic tagging for both the driving guide and only the tourist.", "histories": [["v1", "Sat, 7 May 2016 01:55:51 GMT  (68kb)", "http://arxiv.org/abs/1605.02129v1", "Paper accepted at IWSDS 2016"]], "COMMENTS": "Paper accepted at IWSDS 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["franck dernoncourt", "ji young lee", "trung h bui", "hung h bui"], "accepted": false, "id": "1605.02129"}, "pdf": {"name": "1605.02129.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Franck Dernoncourt", "Ji Young Lee", "Trung H. Bui", "Hung H. Bui"], "emails": ["francky@mit.edu", "jjylee@mit.edu", "bui@adobe.com", "hubui@adobe.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 5.\n02 12\n9v 1\n[ cs\n.C L\n] 7\nM ay\n2 01\n6\npaper, we focus on the spoken language understanding pilot task, which consists of tagging a given utterance with speech acts and semantic slots. We compare different classifiers: the best system obtains 0.52 and 0.67 F1-scores on the test set for speech act recognition for the tourist and the guide respectively, and 0.52 F1-score for semantic tagging for both the guide and the tourist."}, {"heading": "1 Speech act recognition", "text": "Recognizing the speech acts of the current utterance is one of the two goals of the spoken language understanding pilot task. In the training and development sets, each utterance is annotated with one speech act. One speech act is composed of zero, one or two speech act categories. Each speech act category has in turn zero, one or two speech act attributes. There are 4 speech act categories, and 22 speech act attributes. [6] and [7] give further details on the task. The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].\nWe submitted 5 systems. Systems 3 and 5 were the best performing ones. System 3 is based on a support vector machine (SVM) classifier to recognize the speech acts: the features are the 5000 most common unigrams, bigrams, trigrams, as well as a binary feature indicating whether the current speaker is different from the speaker in the last utterance. To account for the history, each feature is computed for both the current and the previous utterance. Two SVM classifiers were trained: one for each speaker. The kernel function as well as the penalty parameter of the error term were both optimized with 5-fold cross-validation. System 5 is similar, but with logistic regression as the classifier; moreover, it uses one single speaker-independent model instead of one model per speaker, as it slightly improves the results on the development set. Systems 3 and 5 assume that each utterance contains exactly one speech act category and one speech act attribute: they are therefore multiclass, monolabel classifiers, with 88 possible classes (4 speech act categories\u00d722 speech act attributes).\nFranck Dernoncourt Adobe Research, San Jose, CA, USA and MIT, Cambridge, MA, USA e-mail: francky@mit.edu\nJi Young Lee Massachusetts Institute of Technology, Cambridge, MA, USA e-mail: jjylee@mit.edu\nTrung H. Bui Adobe Research, San Jose, CA, USA e-mail: bui@adobe.com\nHung H. Bui Adobe Research, San Jose, CA, USA e-mail: hubui@adobe.com\n1\nSystem 4 is based on a random forest classifier and has only 4 features: the number of question marks (discrete value), whether the current speaker is different from the speaker in the last utterance, whether the current speaker is different from the speaker in the second to previous utterance, and whether the current speaker is the guide or the tourist. System 4 was designed to predict the speech act categories, but not the speech act attributes. System 2 is the same as System 4, except that System 4\u2019s features are computed on the current and previous utterances, while System 2\u2019s features are computed on the current, previous and second-to-previous utterances.\nSystem 1 is a rule-based classifier consisting of set of around 10 simple rules (e.g. if the preceding utterance is predicted as a question, then the current utterance is a response): it was designed to be used as a baseline. Table 1 presents the results."}, {"heading": "2 Semantic tagging", "text": "Semantic tagging is the second goal of the SLU pilot task. A tagged entity comprises one or several words. A tag includes one of 8 main categories, and may contain a subcategory, a relative modifier, and a from-to modifier. The ontology contains the list of subcategories, relative modifiers, and from-to modifiers that are present in each main category. [6] and [7] give further details on the task. The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].\nOur semantic tagging system is based on conditional random fields (CRFs) implemented by the CRFsuite library [13] and uses the following features computed on 7 consecutive words (the current word, the 3 previous words, and the 3 following words): case-insensitive unigrams, the last 3 characters of the word, whether the first letter of the word is an uppercase, whether all the letters of the word are uppercases, whether the word contains a digit, the coarse-grained part-of-speech of the word, and the fine-grained part-of-speech of the word. Four CRFs are trained independently, one for each of the 4 types of attributes: main category, subcategory, relation, and from-to. To combine the output of each CRF, a semantic tag is first generated for each sequence of words tagged by the main category CRF. The other thee attributes are included in the semantic tag if these words are tagged by the corresponding CRFs with a value that is present in the main category according to the ontology. Table 1 presents the results.\nAcknowledgements The authors would like to warmly thank the DSTC 4 team for organizing the challenge and being so prompt to respond to emails. The authors are also grateful to the anonymous reviewers as well as to Walter Chang for their valuable feedback."}], "references": [{"title": "Automatic dialog act segmentation and classification in multiparty meetings", "author": ["J. Ang", "Y. Liu", "E. Shriberg"], "venue": "In ICASSP", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Use of kernel deep convex networks and end-to-end learning for spoken language understanding", "author": ["L. Deng", "G. Tur", "X. He", "D. Hakkani-Tur"], "venue": "In Spoken Language Technology Workshop (SLT), 2012 IEEE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Machine learning techniques in dialogue act recognition", "author": ["M. Fi\u0161el"], "venue": "Eesti Rakenduslingvistika U\u0308hingu aastaraamat,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Joint semantic utterance classification and slot filling with recursive neural networks", "author": ["D. Guo", "G. Tur", "W.-t. Yih", "G. Zweig"], "venue": "In Spoken Language Technology Workshop (SLT),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Dialog act tagging using graphical models", "author": ["G. Ji", "J. Bilmes"], "venue": "In ICASSP", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "The Fourth Dialog State Tracking Challenge", "author": ["S. Kim", "L.F. D\u2019Haro", "R.E. Banchs", "J. Williams", "M. Henderson"], "venue": "In Proceedings of the 7th International Workshop on Spoken Dialogue Systems (IWSDS),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Chunking with support vector machines. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pages 1\u20138", "author": ["T. Kudo", "Y. Matsumoto"], "venue": "Association for Computational Linguistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F.C. Pereira"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2001}, {"title": "Tagging of speech acts and dialogue games in spanish call home", "author": ["L. Levin", "K. Ries", "A. Thyme-Gobbel", "A. Lavie"], "venue": "In Workshop: Towards Standards and Tools for Discourse Tagging,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1999}, {"title": "Using recurrent neural networks for slot filling in spoken language understanding", "author": ["G. Mesnil", "Y. Dauphin", "K. Yao", "Y. Bengio", "L. Deng", "D. Hakkani-Tur", "X. He", "L. Heck", "G. Tur", "D. Yu"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding", "author": ["G. Mesnil", "X. He", "L. Deng", "Y. Bengio"], "venue": "In INTERSPEECH,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "CRFsuite: a fast implementation of Conditional Random Fields (CRFs)", "author": ["N. Okazaki"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "Generative and discriminative algorithms for spoken language understanding", "author": ["C. Raymond", "G. Riccardi"], "venue": "In INTERSPEECH,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Hmm and neural network based speech act detection", "author": ["K. Ries"], "venue": "In Acoustics, Speech, and Signal Processing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1999}, {"title": "Flsa: Extending latent semantic analysis with features for dialogue act classification", "author": ["R. Serafin", "B. Di Eugenio"], "venue": "In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2004}, {"title": "Dialogue act modeling for automatic tagging and recognition of conversational speech", "author": ["A. Stolcke", "K. Ries", "N. Coccaro", "E. Shriberg", "R. Bates", "D. Jurafsky", "P. Taylor", "R. Martin", "C. Van Ess-Dykema", "M. Meteer"], "venue": "Computational linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2000}, {"title": "Spoken language understanding using long short-term memory neural networks", "author": ["K. Yao", "B. Peng", "Y. Zhang", "D. Yu", "G. Zweig", "Y. Shi"], "venue": "In Spoken Language Technology Workshop (SLT), 2014 IEEE,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Toward joint segmentation and classification of dialog acts in multiparty meetings", "author": ["M. Zimmermann", "Y. Liu", "E. Shriberg", "A. Stolcke"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}], "referenceMentions": [{"referenceID": 5, "context": "[6] and [7] give further details on the task.", "startOffset": 8, "endOffset": 11}, {"referenceID": 13, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 0, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 15, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 4, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 14, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 17, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 8, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 2, "context": "The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3].", "startOffset": 51, "endOffset": 80}, {"referenceID": 5, "context": "[6] and [7] give further details on the task.", "startOffset": 8, "endOffset": 11}, {"referenceID": 6, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 7, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 12, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 10, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 16, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 3, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 9, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 1, "context": "The main approaches for this task are presented in [8, 9, 14, 12, 18, 4, 11, 2].", "startOffset": 51, "endOffset": 79}, {"referenceID": 11, "context": "Our semantic tagging system is based on conditional random fields (CRFs) implemented by the CRFsuite library [13] and uses the following features computed on 7 consecutive words (the current word, the 3 previous words, and the 3 following words): case-insensitive unigrams, the last 3 characters of the word, whether the first letter of the word is an uppercase, whether all the letters of the word are uppercases, whether the word contains a digit, the coarse-grained part-of-speech of the word, and the fine-grained part-of-speech of the word.", "startOffset": 109, "endOffset": 113}], "year": 2016, "abstractText": "The Dialog State Tracking Challenge 4 (DSTC 4) proposes several pilot tasks. In this paper, we focus on the spoken language understanding pilot task, which consists of tagging a given utterance with speech acts and semantic slots. We compare different classifiers: the best system obtains 0.52 and 0.67 F1-scores on the test set for speech act recognition for the tourist and the guide respectively, and 0.52 F1-score for semantic tagging for both the guide and the tourist. 1 Speech act recognition Recognizing the speech acts of the current utterance is one of the two goals of the spoken language understanding pilot task. In the training and development sets, each utterance is annotated with one speech act. One speech act is composed of zero, one or two speech act categories. Each speech act category has in turn zero, one or two speech act attributes. There are 4 speech act categories, and 22 speech act attributes. [6] and [7] give further details on the task. The main approaches for this task are presented in [15, 1, 17, 5, 16, 19, 10, 3]. We submitted 5 systems. Systems 3 and 5 were the best performing ones. System 3 is based on a support vector machine (SVM) classifier to recognize the speech acts: the features are the 5000 most common unigrams, bigrams, trigrams, as well as a binary feature indicating whether the current speaker is different from the speaker in the last utterance. To account for the history, each feature is computed for both the current and the previous utterance. Two SVM classifiers were trained: one for each speaker. The kernel function as well as the penalty parameter of the error term were both optimized with 5-fold cross-validation. System 5 is similar, but with logistic regression as the classifier; moreover, it uses one single speaker-independent model instead of one model per speaker, as it slightly improves the results on the development set. Systems 3 and 5 assume that each utterance contains exactly one speech act category and one speech act attribute: they are therefore multiclass, monolabel classifiers, with 88 possible classes (4 speech act categories\u00d722 speech act attributes). Franck Dernoncourt Adobe Research, San Jose, CA, USA and MIT, Cambridge, MA, USA e-mail: francky@mit.edu Ji Young Lee Massachusetts Institute of Technology, Cambridge, MA, USA e-mail: jjylee@mit.edu Trung H. Bui Adobe Research, San Jose, CA, USA e-mail: bui@adobe.com Hung H. Bui Adobe Research, San Jose, CA, USA e-mail: hubui@adobe.com", "creator": "LaTeX with hyperref package"}}}