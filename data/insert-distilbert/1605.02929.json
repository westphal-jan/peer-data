{"id": "1605.02929", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-May-2016", "title": "Function-Described Graphs for Structural Pattern Recognition", "abstract": "we present in this article the model mathematical function - described graph ( fdg ), which is a type of compact representation of a set of attributed graphs ( ags ) that borrow from random graphs the capability of probabilistic modelling of structural and attribute information. we define the fdgs, their features definition and two distance measures between ags ( unclassified patterns ) and fdgs ( models or classes ) and we also publicly explain an efficient matching algorithm. two applications of derived fdgs programs are presented : in neither the former, fdgs functions are used for concurrent modelling and matching 3d - objects 3d described by multiple views, whereas deeper in the latter, they are used for representing and recognising human faces, described also by several views.", "histories": [["v1", "Tue, 10 May 2016 10:30:06 GMT  (1183kb)", "http://arxiv.org/abs/1605.02929v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["francesc serratosa"], "accepted": false, "id": "1605.02929"}, "pdf": {"name": "1605.02929.pdf", "metadata": {"source": "CRF", "title": "FUNCTION-DESCRIBED GRAPHS FOR STRUCTURAL PATTERN RECOGNITION", "authors": ["Francesc Serratosa"], "emails": [], "sections": [{"heading": "UNIVERSITAT POLIT\u00c8CNICA DE CATALUNYA", "text": "Programa de doctorat:\nAUTOMATITZACI\u00d3 AVAN\u00c7ADA I ROB\u00d2TICA\nTesi doctoral"}, {"heading": "FUNCTION-DESCRIBED GRAPHS", "text": ""}, {"heading": "FOR", "text": ""}, {"heading": "STRUCTURAL PATTERN RECOGNITION", "text": "Francesc Serratosa i Casanelles\nDirector: Alberto Sanfeliu Cort\u00e9s\nInstitut d\u2019Organitzaci\u00f3 i Control de Sistemes Industrials\nJuny de 2000\nTo my wife, Fina."}, {"heading": "Preface", "text": "We propose a new representation of an ensemble of attributed graphs for structural pattern recognition called Function-Described Graphs (FDGs), where not only the semantic information is preserved, but also part of the structure of the AGs. We also describe some optimal and efficient algorithms for computing the distance and a suboptimal distance, respectively, between an unknown object and a class. The clustering of attributed graphs and the synthesis of FDGs is also presented.\nFDGs are applied in a 3D-object recognition problem due to the importance of considering or not the structural relations. FDGs are generated by a set of attributed graphs representing some views of the model. Results show that FDGs preserves the semantic and structural information of the objects.\nThe main ideas, methods and algorithms have been previously published in various congresses, workshops, technical reports and publications. FDGs were first presented in (Serratosa and Sanfeliu, 1997(a); Serratosa and Sanfeliu, 1997(b)) and compared with random graphs in (Serratosa, Sanfeliu and Alqu\u00e9zar (a), 1999; Serratosa, Sanfeliu and Alqu\u00e9zar (b), 1999). Some ideas about the synthesis process were reported in (Alqu\u00e9zar et al., 1998) and the unsupervised clustering of AGs using FDGs was proposed in (Ria\u00f1o and Serratosa, 1999; Sanfeliu et al., 2000). The distances between AGs and FDGs were presented in (Serratosa et al., 1998; Alqu\u00e9zar et al., 2000) and the graph matching algorithms that compute these distances in (Serratosa, Alqu\u00e9zar and Sanfeliu (c), 1999; Serratosa, Alqu\u00e9zar and Sanfeliu, 2000; Serratosa, Alqu\u00e9zar and Sanfeliu (a), 1999; Serratosa, Alqu\u00e9zar and Sanfeliu (b), 1999). Finally, the methods and algorithms in these papers were tested on random graphs, face recognition (Verg\u00e9s et al., 1999) or 3D object recognition.\nChapter 1 summarises the state of the art in structural pattern recognition. Nevertheless, the approaches that deserve special attention are discussed in separate sections or in the introduction to the chapters. Chapter 2 and 3 deal with attributed graphs and random graphs (Wong et al.), respectively. FDGs are presented in detail in chapters 4 to 8. An experimental validation and a real application of FDGs are presented in chapters 9 and 10. Finally, conclusions and further work are outlined in chapter 11. There is an appendix which shows some tables and figures obtained from the test in chapters 9 and 10.\nMost of this work has been partially funded by the Spanish CICYT under the projects TAP96-0629-C04-02 and TAP98-0473."}, {"heading": "Abstract", "text": "A fundamental problem in pattern recognition is selecting suitable representations for objects and classes. In the decision-theoretic approach to pattern recognition, a pattern is represented by a set of numerical values, which forms a feature vector. Although, in many tasks, objects can be recognised successfully using only global features such as size and compactness, in some applications it is helpful to describe an object in terms of its basic parts and the relations between them. Nevertheless, there are two major problems that practical applications using structural pattern recognition are confronted with. The first problem is the computational complexity of comparing two structures. The time required by any of the optimal algorithms may in the worst case become exponential in the size of the graphs. The approximate algorithms, on the other hand, have only polynomial time complexity, but do not guarantee to find the optimal solution. For some of the applications, this may not be acceptable. The second problem is the fact that there is more than one model graph that must be matched with an input graph, then the conventional graph matching algorithms must be applied to each model-input pair sequentially. As a consequence, the performance is linearly dependent on the size of the database of model graphs. For applications dealing with large database, this may be prohibitive. Function-described graphs (FDGs) are a compact representation of a set of attributed graphs. They have borrowed from \u201crandom graphs\u201d proposed by Wong et al. the ability to probabilistically model structural attribute information, while improving the capacity to record structural relationships that consistently appear throughout the data. They do this by incorporating qualitative knowledge of the second-order probabilities of the elements that are expressed as relations (Boolean functions) between pairs of vertices and pairs of arcs in the FDGs. Four approaches and algorithms for building FDGs from an ensemble of attributed graphs are presented. The first synthesises an FDG in a\nsupervised manner. The other three use the supervised clustering algorithms: dynamic, complete and single clustering. The problem of matching attributed graphs (AGs) to FDGs for recognition or classification purposes is studied from a Bayesian perspective. A distance measure between AGs and FDGs is derived from the principle of maximum likelihood, but robustness is enforced by considering only locally the effects of extraneous and missing elements. A second measure is also given in which the second-order constraints are incorporated as additional costs. A branch-and-bound algorithm is proposed to compute these distance measures together with their corresponding optimal labelling. Because of the exponential cost of this algorithm, three efficient algorithms are also proposed and compared to compute sub-optimal distances between AGs and FDGs. Two of them are based on a probabilistic relaxation approach, and the other does not have an iterative technique. Some experimental tests are presented in random graphs and a 3D-object recognition problem. In the 3D-object recognition application, an FDG model is synthesised (in a supervised and an unsupervised method) for each object from a set of views (AGs). The second-order information in FDGs is shown so that the recognition ration is better than when the first-order probability distributions are only used. Results of efficient algorithms show that there is an important decrease in the run time although there is only a slight decrease in effectiveness."}, {"heading": "Acknowledgements", "text": "Many people have helped me either directly or indirectly in this study. I am grateful to all of them.\nI would like to thank Professor Alberto Sanfeliu and Professor Ren\u00e9 Alqu\u00e9zar. I would never have finished this thesis without their support and guidance. The novel ideas presented here and many more that could not be pursued due to lack of time had their origins in the talks and meetings we had.\nI should also acknowledge my colleagues Maria Ferr\u00e9 and David Ria\u00f1o for their scientific contribution. The former helped me to generate the 3D objects. The latter introduced me to clustering algorithms. I also thank Albert Larr\u00e9 for his unconditional technical support and for helping me to prepare the laboratory sessions of my students when time flew faster than I would have liked. Furthermore, I Acknowledge Jaume Verg\u00e9s-Lah\u00ed, he helped me in the segmentation module in the application tests.\nLast but not least, I would like to acknowledge my parents, brothers and sisters, for encouraging me to study and for giving me everything I need to be able to work in the profession that I have always wanted.\nThank you, Fina, for giving me self-confidence, hope and unconditional support."}, {"heading": "Contents", "text": ""}, {"heading": "1. INTRODUCTION....................................................................................... 19", "text": "1.1. Structural pattern recognition ..................................................................................................19\n1.1.1. Graph and sub-graph isomorphism............................................................. 21 1.1.2. Error-correcting sub-graph isomorphism ................................................... 24 1.1.3. Pre-processing structures ............................................................................ 26\n1.2. New approaches to structural pattern recognition..................................................................27\n1.3. Organisation ...............................................................................................................................29"}, {"heading": "2. ATTRIBUTED GRAPHS (AGS)................................................................ 33", "text": "2.1. Basic definitions about AGs ......................................................................................................33\n2.2. Distance measure between AGs based on edit operations ......................................................35"}, {"heading": "3. RANDOM GRAPHS (RGS)....................................................................... 37", "text": "3.1. General random graphs.............................................................................................................37\n3.2. First-order random graphs (FORGs).......................................................................................38\n3.3. Distance measure between first-order random graphs...........................................................40\n3.4. Example of the distance between first-order random graphs ................................................41"}, {"heading": "4. FUNCTION-DESCRIBED GRAPHS (FDGS)............................................ 45", "text": "4.1. FDGs versus FORGs as prototypes of a set of AGs.................................................................45\n4.2. Formal definition of FDGs ........................................................................................................51\n4.3. Relationships between functions of FDGs................................................................................55\n4.3.1. Non-conditional probabilities of arc attributes ........................................... 55 4.3.2. Second-order functions and joint probabilities of the null value................ 57 4.3.3. Second-order effects of first-order information.......................................... 60 4.3.4. Symmetry of second-order functions and the co-occurrence relation ........ 61\n4.4. Synthesis of FDGs from AGs with a common labelling ..........................................................62\n4.5. Synthesis of FDGs from FDGs with a common labelling........................................................65\n4.6. Experimental results ..................................................................................................................68"}, {"heading": "5. DISTANCE MEASURES FOR MATCHING AGS TO FDGS .................... 77", "text": "5.1. Distance measure and the Bayesian theory framework..........................................................77\n5.2. Distance measure between AGs and FDGs using restrictions................................................81\n5.2.1. Definition of restrictions on the valid morphisms ...................................... 81 5.2.2. Individual costs of matching elements ....................................................... 87 5.2.3. Comparison with edit-operation distances ................................................. 88\n5.3. Distance between AGs and FDGs relaxing 2 nd order constraints ..........................................92\n5.4. Example of the distances between AGs and FDGs..................................................................96"}, {"heading": "6. ALGORITHMS FOR COMPUTING THE DISTANCE MEASURES ........ 101", "text": "6.1. Branch and bound technique ..................................................................................................101\n6.2. Computation of the distance measure using restrictions ......................................................103\n6.3. Computation of the distance relaxing second-order constraints..........................................108\n6.4. Complexity of distance computation ......................................................................................112\n6.5. Experimental results ................................................................................................................115"}, {"heading": "7. EFFICIENT ALGORITHMS FOR COMPUTING SUB-OPTIMAL", "text": "DISTANCES................................................................................................... 119\n7.1. Probabilistic relaxation schemes.............................................................................................119\n7.2. Splitting the graphs into sub-units..........................................................................................120\n7.3. Expanded Vertices ...................................................................................................................122\n7.4. Distance measure between expanded vertices .......................................................................123\n7.5. A fast algorithm for computing the distance between expanded vertices ...........................124\n7.6. A non-iterative sub-optimal method for computing the distance between AGs and FDGs\n126\n7.7. Probabilistic relaxation methods to compute the distance between AGs and FDGs..........128\n7.8. Experimental results ................................................................................................................128"}, {"heading": "8. CLUSTERING OF AGS USING FDGS................................................... 131", "text": "8.1. Incremental (dynamic) clustering of AGs ..............................................................................132\n8.2. Hierarchical (agglomerative) clustering of AGs....................................................................135\n8.3. Experimental results ................................................................................................................139"}, {"heading": "9. EXPERIMENTAL VALIDATION OF FDGS USING ARTIFICIAL 3D", "text": "OBJECTS ...................................................................................................... 143\n9.1. The set of samples.....................................................................................................................144\n9.2. Effects of second-order relations.............................................................................................145\n9.2.1. Recognition by FDG classifier ................................................................. 145 9.2.2. Recognition by the nearest neighbour classifier....................................... 146 9.2.3. Results ...................................................................................................... 146\n9.3. Efficient algorithms..................................................................................................................147\n9.4. Clustering..................................................................................................................................149\n9.4.1. Supervised clustering................................................................................ 149 9.4.2. Unsupervised clustering ........................................................................... 151"}, {"heading": "10. APPLICATION OF FDGS TO 3D OBJECTS.......................................... 153", "text": "10.1. Segmentation of the images ................................................................................................154\n10.2. Calibration process..............................................................................................................155\n10.3. Practical results ...................................................................................................................156"}, {"heading": "11. CONCLUSIONS AND FUTURE WORK ................................................. 163", "text": "12. REFERENCES........................................................................................ 167\n- 15 -"}, {"heading": "List of Figures", "text": "1. An AG with 3 vertices and 3 arcs and its 4-extension...................35 2. Example of First order random graph taken from (Wong and You, 1985)....39 3. Example of structures of Random Graphs.................................41 4. Example of Random graphs...............................................42 5. Joint probability of two vertices split into four regions..............49 6. Examples of joint probability..........................................50 7. An example of FDG......................................................52 8. Example of joint probability that defines a co-occurrence relation.....53 9. Synthesis of FDGs from AGs with a common labelling.....................63 10. Random generation of the reference and test sets......................69 11. Number of vertices of the FDG.........................................71 12. Number of antagonisms.................................................73 13. Number of occurrences.................................................74 14. Number of existences..................................................75 15. Sixteen combinations of the joint probability.........................98 16. Labelling between graphs.............................................113 17. Search tree for two graphs...........................................114 18. Average of the number of vertices and antagonisms in the FDGs........116 19. Correctness in the branch and bound algorithm........................117 20. Run time in the branch and bound algorithm...........................118 21. Expanded vertex of an AG (a) and an FDG (b)..........................123 22. Basic scheme of algorithm 3 for sub-optimal distance computation.....127 23. Correctness and run time obtained by the non-iterative algorithm.....129 24. Correctness and run time. P.ini. by the dist. between exp. Vertices..130 25. Correctness and run time. P.ini. by the distance between vertices....130 26. Number of elements in the FDGs applying different clustering methods.140 27. Ratio of correctness applying different clustering methods...........140 28. Run time applying different clustering methods.......................141 29. The AG that represents views 203 and 206.............................144 30. A view of the four objects in the application........................162\n- 17 -"}, {"heading": "List of Tables", "text": "1. An example of attribute values of three AGs............................42 2. An example of attribute values of Random Graphs........................43 3. An example of attribute values of Random Graphs........................44 4. Antagonism relation between null or non-null elements..................54 5. Occurrence relation between null or non-null elements. ................54 6. Existence relation between null or non-null elements. .................55 7. Parameters of the first experiments. ..................................70 8. Cost with restrictions on the 15 combinations of two vertices..........99 9. Cost relaxing restrictions on the 15 th combinations of two vertices....100 10. Parameters of the second experiments.................................116 11. Parameters of the third experiments..................................129 12. Parameters of the fourth experiments.................................139 13. Correctness obtained by the FDG and the nearest-neighbour classifiers147 14. Correctness obtained by the FDG classifier with different thresholds.147 15. Computational costs (normalised run times)...........................148 16. Number of vertices of the FDGs generated by different clusterings....150 17. Correctness obtained by the FDG classifier (supervised clustering)...151 18. Correctness obtained by the FDG classifier (unsupervised clustering).151 19. Calibration parameters in the application............................155 20. Vertex attributes in the calibration AGs.............................156 21. Number of FDG graph elements in the application......................156 22. Correctness and run time of the efficient alg. in the application....157 23. Classification results in the application............................158 24. Distance between AGs using Sanfeliu and Fu alg. in the application...160\n- 19 -"}, {"heading": "1. Introduction", "text": "This chapter presents the state of the art of the structural pattern recognition as well as the main methods and algorithms proposed from the beginnings in the early seventies until our days. We introduce our new method with the aim of overcoming as much as possible the problems that involves working with graphs. Finally, we present the organisation of this document.\n1.1. Structural pattern recognition\nA fundamental problem in pattern recognition is selecting suitable representations for objects and classes. In the decision-theoretic approach to pattern recognition, a pattern is represented by a set of numerical values, which forms a feature vector (Meisel, 1972). Although, in many tasks, objects can be recognised successfully using only global features such as size and compactness, in some applications it is helpful to describe an object in terms of its basic parts and the relations between them (Bunke and Sanfeliu, 1990). Hence, in the syntactic and structural approach to pattern recognition, an object is decomposed into a set of pattern primitives and a structure relating these primitives. In the syntactic methods, the structure of an object is described as a syntactic pattern (a sentence in some formal language) whereas the classes of objects are represented by grammars. However, a more powerful way of representing pattern structure, which has been given considerable attention in the literature, is the use of graphs. A graph consists of a set of vertices representing pattern primitives and a set of edges representing relations between the primitives. In order to incorporate more semantic information about the properties of both the parts and the relations, Attributed Graphs (AGs) were proposed by Tsai and Fu (Tsai and Fu, 1979). AGs have been widely used in the literature of pattern recognition ever since. There are numerous applications in which the comparison between graphs plays a relevant role. In fact, many of the algorithms described below have been developed with a particular application in mind. One of the earliest applications was in the field of chemical documentation and the\n- 20 -\nanalysis of chemical structures (Bouvray and Balaban, 1979). More recently, graph matching has also been proposed for the retrieval of cases in case-based reasoning (Poole, 1993) and for the analysis of semantic networks in combination with graph grammars (Ehrig, 1992). In machine learning, graph matching is used for the learning common sub-structures of different concepts (Bhanu and Ming, 1988; Fisher, 1987; Cook and Holder, 1994). However, most applications of graph matching have been documented in the fields of pattern recognition and computer vision. For example, the sub-graph detection was successfully applied to Chinese character recognition (Lu, Ren and Suen, 1991), the interpretation of schematic diagrams (Bunke and Allerman, 1983; Lee, Kim and Groen, 1990; Messmer and Bunke, 1996), seal verification (Lee and Kim, 1989) or it was combined with evident based systems for shape analysis (Pearce, Caelli and Bischof, 1994). In computer vision, it was mainly used for the localisation and identification of three-dimensional objects (Bmuer and Bunke, 1990; Horaud and Skordas, 1988; Wong, 1990; Cheng and Huang, 1981; Wong, Lu and Rioux, 1989; cho and Kim, 1992; Wong, 1992). In (Wallace, 1987) there is a comparison of methods of high-level interpretation of two-dimensional segmented images. The reviews by Bunke and Messmer (Bunke, 1993; Bunke and Messmer, 1997) reported these applications and additional ones are described in (Walischewski, 1997; Shearer, 1998; Lourens, 1998). A hypergraph is a type of graph that was introduced by (Berge, 1970) and it has been considered as a useful tool to analyse the structure of a system and to represent a partition (Lee-Kwang and C.H. Cho, 1996). Recently, the concept of hypergraphs has been extended to the fuzzy hypergraphs to represent fuzzy partitions (Lee-Kwang and K.M Lee, 1995; S.M. Chen, 1997). Typically, graphs are used to represent known models from a database and unknown input patterns. The recognition task, therefore, turns into a graph-matching problem. That is, the database is searched for models that are similar to the unknown input graph. Standard algorithms for graph matching include graph isomorphism, sub-graph isomorphism, and maximum common graph search (Corneil and Gotlieb, 1970; Levi, 1972; Berztiss 1973; Ullman, 1976; Barrow, 1976; Schmidt and Druffel, 1976; McGregor, 1982). When matching two graphs iG and jG by means of graph isomorphism, we are looking for a bijective mapping between the vertices and arcs of\n- 21 -\niG and jG such that the structure of the graphs is preserved by the mapping function. When such a mapping function can be found then iG and jG are isomorphic. If one of the graphs involved in the matching process is larger than the other, i.e. jG contains more vertices than iG , then we are looking for a sub-graph isomorphism from iG to jG . That is, we are interested in finding a sub-graph S of jG such that iG and S are isomorphic. However, in real world applications we cannot always expect a perfect match between the input graph and one of the graphs in the database. Therefore, what is needed is an algorithm for error-tolerant graph matching (etgm), which computes a measure of similarity between two given graphs. Notice that the definition of an error model is strongly application dependent. One of the drawbacks of graph matching is its computational complexity. For the graph isomorphism problem it is up to this days an open question whether it belongs to the complexity class P or NP (Garey and Johnson, 1979; Booth and Colbourn, 1979). All algorithms that have been developed so far for the general graph isomorphism problem require in the worst case exponential time. For the sub-graph isomorphism problem and also the error-correcting sub-graph isomorphism problem it is well known that it is NPcomplete (Garey and Johnson, 1979). Consequently, no algorithm could be constructed that guarantees to find error-correcting sub-graph isomorphisms in polynomial time. However, research in the past twenty years has shown that there are methods for graph matching that behave reasonably well on the average in terms of performance and become computationally intractable only in few cases. Moreover, if the constraints of graph matching are loosened, then it is possible to find solutions in polynomial time by using approximate methods. In the following, an overview of the methods for graph, sub-graph and error-correcting sub-graph isomorphism detection that have been proposed by various authors in the past is given.\n1.1.1. Graph and sub-graph isomorphism\nThe graph and sub-graph isomorphism problem has been the focus of intensive research since the seventies (Read and Corneil, 1977; Gati, 1979). There are basically two approaches that have been taken to solve the graph isomorphism problem: One is based on the backtracking search and the other is based on the idea of building a so-called\n- 22 -\nassociation graph. Due to the fact that it is not yet known whether the graph isomorphism problem is P or NP, there is another approach to solve the graph isomorphism problem in addition to the two above commented. This approach is based on the group-theoretic concepts. All the algorithms described so far are optimal algorithms. That is, they are guaranteed to find all graph and sub-graph isomorphisms from a given graph iG to another graph jG . The main problem of these algorithms, however, is that for large graphs they may require exponential time. To solve this problem the discrete relaxation methods are proposed, which compute sub-optimal distances in polynomial time.\nThe backtracking search approach is practically oriented. It aims directly at constructing graph or sub-graphs isomorphisms in a procedural manner. One of the best known methods for graph and sub-graph isomorphism detection is based on depth-first backtracking search, first described in (Corneil and Gotlieb, 1970). Informally speaking, the method works as follows. Given two graphs iG and jG , the vertices of iG are mapped one after the other onto the vertices of jG and after each mapping, it is checked whether the arc structure of iG is preserved in jG by the mapping. If all the vertices of iG are successfully mapped onto vertices of jG and, iG and jG are of equal size then a graph isomorphism is found. If iG is smaller than jG then a sub-graph isomorphism from iG to jG is found. Although this method performs well for small graphs, the number of required steps explodes combinatorially when the graphs grows. Hence, Ullman proposed in (Ullman, 1976) to combine backtracking with forward cheking procedure which greatly reduces the number of backtracking steps. A comprehensive analysis of the performance of different forward-checking and looking-ahead procedures for backtracking is given in (Haralick and Elliot, 1980).\nThe association graph approach described in (Falkenhainer, Forbus and Gentner, 1990; Myaeng and Lopez-Lopez, 1992; Horaud and Skordas, 1989) is based on the idea of building a so-called association graph in which each consistent vertex to vertex mapping is represented by a vertex in the association graph and each locally consistent\n- 23 -\npair of vertex to vertex mappings is represented by an edge between the corresponding vertices in the association graph. Graph or sub-graph isomorphisms are found by searching for maximal cliques in the association graph.\nThe group-theoretic concepts aims at classifying the adjacency matrices of graphs into permutation groups. With this, it was possible to prove that there exists a moderately exponential bound for the general graph isomorphism problem (Babi, 1981). Notice that the group-theoretic methods are only applicable for graph isomorphism but not subgraph isomorphism. Furthermore, by imposing certain restrictions on the graphs, it was possible to derive algorithms that have polynomially bounded complexity. For example, (Hoffman, 1982) describe a polynomially bounded method for the isomorphism detection of graph with bounded valence. For the special case of the trivalent graph isomorphism, it was shown in (Hoffman, 1982; Luks, 1982) that algorithms with a computational complexity of ( )4nO exist. In (Hopcroft and Wong, 1974) a method for the computation of the isomorphism of planar graphs is proposed that requires time that is only linear in the size of the graphs. Although these methods are very interesting from a theoretical point of view, they are usually not applicable in practice due to a large constant overhead.\nThe discrete relaxation methods were first presented in (Rosenfeld et al., 1976; Kitchen and Rosenfeld, 1979; Zucker et al., 1977; Peleg and Rosenfeld, 1978; O\u2019learly and Peleg, 1983; Hummel and Zucker, 1983). These methods do not always find the optimal solution but they have the advantage that they require only polynomial time and that they are easily parallelised. However, because only local consistency is checked, ambiguities must be resolved in the end by applying again a backtracking procedure. Discrete relaxation methods aim to gradually reduce the number of possible mappings for each vertex of iG onto vertices of jG by only allowing vertex to vertex mappings that are locally consistent. More recent work is presented in (Hancock and Kittler, 1990; Kim and Kak, 1991; Wilson and Hancock, 1997; Cross and Hancock, 1998).\n- 24 -\n1.1.2. Error-correcting sub-graph isomorphism\nOne of the requirements of error-correcting sub-graph isomorphism is the definition of the errors that are to be taken into account. Most of the optimal algorithms proposed so far are based on the A* algorithm (Nilsson, 1980). An optimal algorithm guarantees to find all graph an sub-graph isomorphisms from a given graph iG to another graph jG . The main problem of these algorithms, however, is that for large graphs they may require exponential time. Approximate or continuous optimisation algorithms, on the other hand, do not always find the optimal solution but require only polynomial time. These methods generate solutions that are as close as possible to graph or subgraph isomorphism. Hence, these approximate methods are usually a first step towards the optimal algorithms."}, {"heading": "Optimal approaches", "text": "The A* algorithms compute the error-correcting sub-graph isomorphism in the following manner. Given a graph iG and a possibly distorted graph jG a search tree is expanded such that each state in the tree corresponds to a partial mapping of the vertices of iG onto vertices in jG . At the top of the search tree, the first vertex of iG is mapped onto every vertex of jG . Each such mapping and its corresponding cost is a state in the search tree. The generation of successor states is then guided by the cost of the mappings. That is, the vertex mapping with the least cost is extended by mapping a new vertex of iG onto every vertex of jG that has not yet been used. Eventually, all vertices of iG are mapped onto vertices of jG and an error-correcting sub-graph isomorphism is found. The performance of such an algorithm strongly depends on the number of states that are expanded in the search tree. By introducing a heuristic future cost estimation function, the size of the search tree can be greatly reduced. In (Wong, You and Chan, 1990; Tsai and Fu, 1979; Eshera and Fu, 1984; Sanfeliu and Fu, 1983; Shapiro and Haralick, 1981) various heuristic functions have been proposed for errorcorrecting sub-graph isomorphism detection based on the A* algorithm. The most common used is based on graph edit operations (Sanfeliu and Fu, 1983).\n- 25 -"}, {"heading": "Graph edit operations", "text": "Probably the best known error correction model for graph matching is similar to the model used in string edit distance (Wagner and Fischer, 1974). It is based on the idea of introducing graph edit operations (Sanfeliu and Fu, 1983). For each possible error type a corresponding graph edit operation is defined. In order to model the fact that certain error types are more likely than others, cost functions are assigned to the edit operations. The definition of the cost functions is strongly application dependent. The graph edit operations are then used to correct errors in the graphs. Thus, informally speaking, an error-correcting sub-graph isomorphism is defined as a sequence of edit operations with minimal cost that must be applied to one of the graphs such that a subgraph isomorphism exists. This approach is described in section 2.2 and proposed as a distance between attributed graph in the 3D object application in chapter 10."}, {"heading": "Approximate approaches", "text": "Various approximate methods have been proposed for the error-correcting graph isomorphism. In (Kittler, Christmas and Petrou, 1992; Christmas, Kittler and Petrou; 1995) a method based on probabilistic relaxation is described. The basic idea is that each vertex to vertex mapping is assigned a certain probability that reflects the cost of the mapping and the local consistency of the mapping. Similar to discrete relaxation, the probabilities of each mapping are then corrected until a maximum probability for a set of vertex to vertex mapping results. The method was tested on fairly large graphs and interesting results were obtained. However, as expected, the optimal solution was missed in some cases. Another continuous optimisation approach is based on neural networks. In (Feng, Laumy and Dhome, 1994; Metha and Fulop, 1990) it was proposed to solve the errorcorrecting problem by representing each vertex to vertex mapping by a neurone in a Hopfield network and optimise the output of the network. Another method using Kohonen network was also presented in (Xu and Oja, 1990). In (Herault, Horaud, Veillon and Niez, 1990) an approximate algorithm based on relaxation and simulated annealing is presented.\n- 26 -\nIn (De Jong and Spears, 1989; Brown, Huntley and Spillane, 1989; Ford and Zhang, 1991), it is proposed to encode sequences of vertex to vertex mappings as chromosomes. A genetic algorithm is then used to optimise the pool of chromosomes such that the encoded vertex to vertex mappings represent perfect or close to perfect graph or sub-graph isomorphisms. A special case of error-correcting graph matching is the weighted graph matching problem in which two completely connected graphs of equal size with weights assigned to the edges must be matched onto each other such that the weight differences in the edges are minimised. A linear programming method providing an approximate solution to this problem is presented in (Almohamad and Duffuaa, 1993). The method was originally designed for problems in the domain of operations research. Finally, in (Umeyama, 1988) an algorithm based on the eigen-decomposition of the adjacency matrices of the weighted graphs is proposed. While this method is very fast, it can only be applied to graphs with completely different eigen-values. Furthermore, only small distortions in the input graph can be handled.\n1.1.3. Pre-processing structures\nIn addition, some attempts have been made to try to reduce the computational time of matching the unknown input patterns to the whole set of models from the database. The basic assumption is that the models in the database are not completely dissimilar. Two different approaches for reducing computational time are mentioned below. In the approach by Messmer and Bunke (Messmer and Bunke, 1994; Bunke, 1998), the model graphs are pre-processed and generate a symbolic data structure called network of models. This network is a compact representation of the models in the sense that multiple occurrences of the same sub-graph are represented only once. Consequently, such sub-graphs will be matched only once with the input and the computational effort will be reduced. In the other approach, AGs are extended in several ways to include either probabilistic or fuzzy information. Thus, random graphs were defined by Wong et al. for modelling classes of patterns described by AGs through a joint probability space of random variables, but due to the computational intractability of general random graphs, first-\n- 27 -\norder random graphs (FORGs) were proposed for real applications (Wong and You, 1985; Wong, Constant and You, 1990). Likewise, Chan proposed the fuzzy attributed graphs (FAGs) and the hard FAGs to represent objects and templates, respectively (Chan 1996). Several studies have been carried out to solve the three-dimensional object recognition problem by the use of structures. For instance (Bamieh and Figueiredo, 1986; Chen and Kak, 1989) presented some structures based on attributed graphs to represent the objects. Likewise, aspect graphs is one of the approaches to representing a 3D shape for the purposes of object recognition. In this approach, the viewing space of an object is partitioned into regions such that in each region the topology of the line drawing of the object does not change. Vertices represent regions and arcs path from one region to another. Several papers have been presented to compute and represent aspect graphs and others to match one view to the 3D object (Bowyer and Dyer, 1990; Gigus and Malik, 1990; Gigus et al., 1991; Laurentini, 1995).\n1.2. New approaches to structural pattern recognition\nThere are two major problems that practical applications using exact or error-correcting graph matching are confronted with. The first problem is the computational complexity of graph matching. As mentioned before, the time required by any of the optimal algorithms listed above may in the worst case become exponential in the size of the graphs. The approximate algorithms, on the other hand, have only polynomial time complexity, but do not guarantee to find the optimal solution. For some of the applications described in section 1.1, this may not be acceptable. The second problem is the fact that there is more than one model graph that must be matched with an input graph, then the conventional graph matching algorithms must be applied to each modelinput pair sequentially. As a consequence, the performance is linearly dependent on the size of the database of model graphs. For applications dealing with large database, this may be prohibitive. The preprocessing structures such as Random graphs or Fuzzy attributed graphs represent the cluster of graphs with only one \u201crepresenting structure\u201d and so the performance is linearly dependent on the number of clusters and not on the number of model graphs. Nevertheless, these structures do not guarantee to keep the\n- 28 -\nstructural knowledge of the ensemble of graphs and this also may not be acceptable for some applications.\nIn this thesis, we propose a new approach, called Function-Described Graphs (FDGs) to error-tolerant graph matching that is particularly efficient with regard to the problems mentioned at the end of the previous paragraph. There are two common assumptions and a common idea behind our approach. The first assumption is that the graphmatching problem always involves one or several graphs, so-called model graphs, that are a priori known model graphs to the input graph. This approach is especially designed for applications dealing with large databases of model graphs. The other assumption is that model graphs that belong to the same cluster have a certain degree of similarity between each other. That is, they share part of their sub-graphs. The common idea of our approach is to compute a special representation of the ensemble of the model graphs that belong to the same cluster in the learning process without loosening, as much as possible, the structural information of the ensemble of attributed graphs. This representation is then used in the recognition process in order to efficiently detect the distances between the input graph and the clusters and reduce, as far as possible the computational time required to recognise the input graph.\nFunction-Described Graphs are computed in the learning process and used in the recognition process to represent a cluster of model graphs. An FDG is a prototype structure that contains, on one hand, probabilistic functions which represent the semantic information of the local parts of the patterns and, on the other, binary functions to maintain, as much as possible, the local features of the attributed graphs that belong to the class and also to reject the graphs that do not belong to it. In general, an FDG can be derived by synthesising a cluster or set of individual attributed graphs. For the generation of FDGs, we present three different methods which build the FDGs from the ensemble of AGs and minimises the distances between them. In the first two methods, we know a priori in which clusters the model graphs belong to. (supervised clustering). In the first, there is a given common labelling between the vertices and arcs of the attributed graphs (supervised synthesis) and in the second, the\n- 29 -\nlabelling has to be computed (non-supervised synthesis). In the last method, the cluster of graph models and the labellings between the graph elements of these graphs have to be computed (non-supervised synthesis and non-suprevised clustering). Likewise, we present two well-founded distance measures, which use the Bayesian theory framework, between unknown patterns (AGs) and classes (FDGs). The first is tested to be useful in a non-noisy environment, the second is more practically oriented. These distances are computed by an error tolerant graph-matching algorithm based on the A* algorithm with a future cost estimation function. Although the estimation function reduces considerably the expansion of the search tree, the computational complexity still remains exponential. To shorten the time required, we also propose an efficient method for reducing the search space or our branch-and-bound algorithm. This method initially discards mappings between vertices and is based on the distance between the sub-units of the graphs.\n1.3. Organisation\nThis thesis is organised in the following manner. Chapter 2 (Attributed Graphs) gives some basic definitions of attributed graphs and summarises the fundamental information about the distance measure between AGs proposed by (Sanfeliu and Fu, 1983). This information will be useful in chapter 5 where the properties of the distance measures between AGs and FDGs are discussed. Moreover, one of the parameters of the clustering process is a distance measure between AGs. In our application we have chosen the Sanfeliu distance. Chapter 3 (Random Graphs) describes general random graphs and first order random graphs (Wong et al.) as an example of a representation of an ensemble of AGs. The distance measure between first order random graphs is presented and a simple example is given, which shows that the statistical independence between vertices or arcs leads to an excessive generalisation of the sample graphs. Chapter 4 (Function-Described Graphs) presents and studies FDGs in depths. First, FDGs are compared with Random Graphs as prototypes of a set of AGs and then they are formally defined before the properties of the information represented are studied. Finally, FDGs are built from a set of AGs or a set of FDGs using a supervised synthesis.\n- 30 -\nThese approaches are used in chapter 8 in the clustering algorithms. Some experiments are added in order to examine the behaviour of the new representation. Chapter 5 (Distance measures for matching AGs to FDGs) explains two robust and well-founded distance measures between AGs and FDGs. In one, the structural information (2ond order relations) of FDGs are used to constraint the allowed labellings between graph elements of both graphs. Nevertheless, the spurious elements that appear in real applications would lead to a coarse measure. Thus, in the other distance, second order constraints are relaxed and used to apply a cost on the distance value. An example is included. Chapter 6 (Algorithms for computing the distance measures) presents an A* algorithm for computing the distance measures and their associated optimal morphisms. The search space is reduced by a branch and bound technique, which uses semantic and structural knowledge of both graphs and also the second order constraints. Finally, the complexity of the distance computation is outlined. Some experimental results with random graphs are added in order to examine the behaviour of the matching algorithms. Chapter 7 (Efficient algorithms for computing sub-optimal distance measures) presents three different efficient algorithms. One of the drawbacks of optimal distance measures between graphs is that they are computationally expensive. We propose some methods that reduce further the search space of our branch and bound algorithm by initially discarding mappings between vertices. Some experimental results with random graphs are added in order to examine the relation between the efficiency and effectiveness of the efficient matching algorithms. Chapter 8 (Clustering of AGs using FDGs) presents two algorithms for the nonsupervised clustering. The incremental clustering and the hierarchical clustering. The advantages and disadvantages of both methods are discussed. Some experimental results with random graphs are added in order to examine the behaviour of the clustering and synthesis algorithms (learning process). Chapter 9 (Experimental validation of FDGs using artificial 3D objects) reports some experimental tests on artificial data for assessing how capable FDGs are of representing an ensemble of AGs, how efficient the sub-optimal distance algorithm is and how good the proposed approach is at classification.\n- 31 -\nChapter 10 (Application of FDGs to recognise office objects) presents an application on real tree-dimensional objects. Some 2D images are taken from some office objects and segmented using a neural-network method. From each view, an attributed graph is extracted and from all the views of an object, an FDGs is automatically synthesised. Chapter 11 (Conclusions) summarises the advantages of the new structure and its related algorithms and it draws the relevant conclusions. Possibilities for future research are also discussed. Appendix 1 and Appendix 2 provide some data from the experimental validation (chapter 9) and the application (chapter 10). They show different views of the objects, the structure and attributes of the AGs and the structure of the FDGs.\n- 33 -"}, {"heading": "2. Attributed Graphs (AGs)", "text": "This section gives some basic definitions about attributed graphs and recalls the distance measure between AGs proposed by Sanfeliu and Fu (Sanfeliu and Fu, 1983). AGs need to be defined to explain the supervised synthesis of FDGs (sections 4.4 and 4.5) and the distance between AGs and FDGs (section 5). Moreover, a comparison to the Sanfeliu and Fu measure will be useful so that the properties of the dissimilarity measures between AGs and FDGs presented in Section 5 can be discussed. The clustering algorithms (section 8) are parameterised by any distance measure between AGs, but in our application (chapter 9) we use the Sanfeliu distance.\n2.1. Basic definitions about AGs\nLet ( )evH \u03a3\u03a3= , be a directed graph structure of order n where { }nkvkv ,...,1==\u03a3 is a\nset of vertices (or nodes) that represents basic parts of an object and { }{ }jinjieije \u2260\u2208=\u03a3 ,,...,1, is a set of edges (or arcs), which represents relationships\nbetween parts, where the arc ije connects vertices iv and jv from iv to jv . We use the\nterm graph element to refer to either a vertex or an edge. Let { }tizZ iv ,...,1== be a nonempty finite set of names for the attributes in a vertex,\nand for each iz in vZ let viD denote the corresponding domain of attribute values. Similarly, let { }sizZ ie ,...,1' == be a nonempty finite set of names for the attributes in\nan arc, and let eiD denote the domain of attribute values for iz' . In this way, a set of attribute-value pairs { }viiviii DaZzaz \u2208\u2208 ,),( in which each attribute appears at most\nonce can be associated with a vertex, and a set { }eiieiii DbZzbz \u2208\u2208 ,'),'( satisfying the\nsame restriction can be associated with an arc. However, a set of attribute-value pairs can be listed always in the same order and the attribute names suppressed, provided that a generic null value \u03c6 is given to any attribute not appearing in the set. Hence, a set of\nattribute-value pairs can be transformed into a t-tuple of values for a vertex or an s-tuple\n- 34 -\nof values for an arc, where { }\u03c6\u03c6 \u2260\u2203\u2264\u2264\u222a\u2208=\u2206 iviitiv aitiDaaaa :,1},{),...,...,( 1 is the\nglobal domain of possible values for non-null attributed vertices and { }\u03c6\u03c6 \u2260\u2203\u2264\u2264\u222a\u2208=\u2206 ieiisie bisiDbbbb :,1},{),...,...,( 1 is the global domain of possible\nvalues for non-null attributed arcs. A null graph element is a vertex or an arc in which all the attributes are instantiated to the null value \u03c6 . The value of these elements is represented by \u03a6 , where ( )\u03c6\u03c6 ,...,=\u03a6 .\nDefinition 1 (Attributed graph): An attributed graph G over ( )ev \u2206\u2206 , with an underlying graph structure ( )evH \u03a3\u03a3= , is defined as a pair ( )AV , in which ( )vvV \u03b3,\u03a3= is an attributed vertex set and ( )eeA \u03b3,\u03a3= is called an attributed arc set.\nThe mappings \u03c9\u03b3 \u2206\u2192\u03a3vv : and \u03b5\u03b3 \u2206\u2192\u03a3ee : , which assign attribute values to graph elements, are called vertex interpreter and arc interpreter, respectively, where { }\u03a6\u222a\u2206=\u2206 e\u03b5 and { }\u03a6\u222a\u2206=\u2206 v\u03c9 . A complete AG is an AG with a complete graph structure H (vertices are totally connected by arcs, but may include null elements). Definition 2 (k-extension of an AG): An attributed graph ( )AVG ,= of order n can be\nextended to form a complete AG ( )','' AVG = of order nkk \u2265, , by adding vertices and\narcs with null attribute values \u03a6 . We call 'G the k-extension of G . The matching scheme discussed in Sections 5 and 6 formally needs the two graphs to be structurally isomorphic and complete. To this end, an extending process is carried out on both graphs, which may be of different orders, to make them complete and with the same order. The AG before the extending process is called initial graph and the AG obtained after the process is called extended graph (Figure 1). However, both the initial and the extended graph provide exactly the same information about an object. Note that two different domains have been defined for the vertices ( )v\u2206\u2206 ,\u03c9 and for the arcs ( )e\u2206\u2206 ,\u03b5 . This is because it is sometimes helpful to distinguish whether an element is allowed to take the null value \u03a6 or not. It is supposed that initial AGs do not contain any null element, and therefore, their attribute assignment mappings of vertices and\n- 35 -\nedges could range over v\u2206 and e\u2206 , respectively. However, there are null elements in extended AGs and, therefore, their attribute mappings range necessarily over the\ndomains \u03c9\u2206 and \u03b5\u2206 .\n2.2. Distance measure between AGs based on edit operations\nDistance measures between structures based on edit operations are in the heart of transforming one structure into another. The three basic structures are strings (Levenshtein, 1966; Tanaka and Kasai, 1976), trees (Fu and Bhargava, 1973; Tai, 1979; Lu, 1984) and graphs (Tanaka, 1977; Sanfeliu and Fu, 1983). The distance measure between AGs proposed by Sanfeliu and Fu (Sanfeliu and Fu, 1983) requires computing the minimum number of transformations needed to convert\nan input AG 1G into another 2G using six common edit operations: 1) vertex insertion and 2) arc insertion (a new vertex or arc is inserted into 1G with a given attribute value); 3) vertex deletion and 4) arc deletion (a vertex or arc is deleted from 1G ); 5) vertex substitution and 6) arc substitution (an attribute value in 1G is substituted by an attribute value in 2G ). There is a fixed cost associated with each edit operation and, thus, the global cost of a transformation is the sum of the costs of the edit operations involved. Let\nviN , eiN , vdN , edN , vsN and esN be the number of insertions of vertices and arcs,\ndeletions of vertices and arcs and substitutions of vertices and arcs, respectively. Let\n- 36 -\nviC , eiC , vdC , edC , vsC and esC be the individual costs or weights of the corresponding edit operations; these values are generally found heuristically. Then, the Sanfeliu\u2019s distance measure between AGs is given as\n( ) { }esesvsvsededvdvdeieivivi ionsconfigurat CNCNCNCNCNCNminGGd \u2217+\u2217+\u2217+\u2217+\u2217+\u2217=21, (1)\nwhere configurations represent the set of allowed chains of edit operations that transform one AG into another. Note that the exact computation of this distance measure is a combinatorial problem for which there is no known solution of polynomial complexity.\n- 37 -"}, {"heading": "3. Random graphs (RGs)", "text": "A random graph, defined by Wong et al. (Wong and You, 1985; Wong, Constant and You, 1990), is a graph structure with randomly varying vertex and arc attribute values. Put in another way, it is a graph, together with a set of jointly distributed random variables, some (one for each vertex) ranging over pattern primitives and others (one for each arc) ranging over relations. Any AG obtained by instantiating all random vertices and random arcs is called an outcome graph of the random graph. Hence, a random graph represents the set of all possible AGs that can be outcome graphs of it, according to an associated probability distribution. Below we review the definitions of general random graphs (section 3.1) and first-order random graphs (FORGs) (section 3.2) proposed in (Wong and You, 1985). We have adapted the notation to our convenience. Then we define the distance between two FORGs (section 3.3) and give a simple example (section 3.4) which shows that this probabilistic approach is not enough to represent an ensemble of AGs and that structural information has to be incorporated.\n3.1. General random graphs\nDefinition 3 (General random graphs): A random graph R over ( )ev \u2206\u2206 , with an underlying graph structure ( )\u03b5\u03c9 \u03a3\u03a3= ,H is defined as a tuple ( )PBW ,, where ( )\u03c9\u03c9 \u03b3,\u03a3=W , ( )\u03b5\u03b5 \u03b3,\u03a3=B , \u03c9\u03c9\u03c9\u03b3 \u2126\u2192\u03a3: , \u03b5\u03b5\u03b5\u03b3 \u2126\u2192\u03a3: . \u03c9\u2126 is a set of random variables with values in { }\u03a6\u222a\u2206 v (random vertices), \u03b5\u2126 is a set of random variables with values in { }\u03a6\u222a\u2206 e (random arcs) and, finally, P is a joint probability distribution\n( )mnP \u03b2\u03b2\u03b1\u03b1 ,,,,, 11 KK of all the random vertices { }niiii \u2264\u2264= 1),(\u03c9\u03b3\u03b1\u03b1 \u03c9 and all the\nrandom arcs { }mjkljj \u2264\u2264= 1),(\u03b5\u03b3\u03b2\u03b2 \u03b5 .\nFor each outcome graph G of a random graph R, a probability measure [ ]( )GPR of obtaining any AG completely isomorphic to G, [ ]G , is given by the sum of the joint\nprobabilities of random vertices and arcs over all instantiations that produce G, and any\n- 38 -\nsuch instantiation is associated with a structural isomorphism RG \u2192':\u00b5 , where 'G is\nthe extension of G to the order of R. Let G be oriented with respect to R by isomorphism \u00b5 ; for each vertex i\u03c9 in R, let ( )( )ivi \u03c9\u00b5\u03b3 1\u2212=a be the corresponding\nattribute value in G\u2019, and similarly, for each arc kl\u03b5 in R (associated with random variable j\u03b2 ) let ( )( )klej \u03b5\u00b5\u03b3 1\u2212=b be the corresponding attribute value in G\u2019. Then the\nprobability of G according to (or given by) the orientation \u00b5 , denoted by ( )\u00b5GPR , is\ndefined as\n( ) ( ) ( ) ( )mnjjm j ii n i R PGP bbaaba ,,,,,Pr 11 11 KK=     =\u2227== == \u2227\u2227 \u03b2\u03b1\u00b5\n(2)\nIt is easy to show that the probability [ ]( )GPR can be expressed as the following sum,\n[ ]( ) ( ) [ ] \u2211= \u00b5 \u00b5GPGP RR (3)\nwhere [ ]\u00b5 denotes the class of isomorphisms that are equivalent to \u00b5 (two such\nisomorphisms are considered equivalent whenever one composed with the inverse of the other yields a complete automorphism of G\u2019) and ( )\u00b5GPR is then the probability of\nG according to any member \u00b5 of the class.\n3.2. First-order random graphs (FORGs)\nGeneral random graphs are absolutely impractical due to the difficulty of estimating and handling the high-order joint probability distribution P. Consequently, a strong simplification must be made so that random graphs can be used in practical cases. This is done by introducing suppositions about the probabilistic independence between vertices and/or arcs. Wong and You (Wong and You, 1985) proposed the class of First Order Random Graphs (FORGs) for real applications. They assumed the following: 1) The random vertices are mutually independent; 2) The random arcs are independent given values for the random vertices;\n- 39 -\n3) The arcs are independent of the vertices except for the vertices that they connect. Definition 4 (First order random graph or FORG): A first order random graph R over ( )ev \u2206\u2206 , with an underlying graph structure ( )\u03b5\u03c9 \u03a3\u03a3= ,H is a random graph that satisfies the assumptions 1, 2 and 3 shown above. Based on these assumptions, for a FORG R, the probability ( )\u00b5GPR becomes\n( ) ( ) ( )\u220f\u220f ==\n= m\nj\njjjj\nn\ni iiR qpGP 1 21 1 ,aaba\u00b5 (4)\nwhere ( ) ( ) ,1,Pr\u02c6 nip ii \u2264\u2264== aa \u03b1 and ( ) ( ),,Pr\u02c6, 221121 jjjjjjjjq aabaab ==== \u03b1\u03b1\u03b2\n,1 mj \u2264\u2264 are independent probability density functions for vertices and arcs,\nrespectively, and 21, jj \u03b1\u03b1 refer to the random vertices for the endpoints of the random\narc j\u03b2 . Note, on the other hand, that a general random graph is defined through a joint\nprobability P of all the graph elements without any supposition about probabilistic independence.\nFigure 2. Example of first order random graph taken from (Wong and You, 1985).\nFigure 2 shows a simple example of a first order random graph taken from (Wong and You, 1985). On the left there is the structure with three vertices and three arcs. It can be deduced that the attributed graphs used to synthesise it have one attribute in the vertices in the domain { }fedcbav ,,,,,=\u2206 and one attribute in the arcs in the domain { }zyxwvue ,,,,,=\u2206 . The probabilities related to the vertices are shown inside them, but\n- 40 -\nthe probabilities related to the arcs are shown in the table on the right because they depend on the values of the extreme vertices. First order random graphs were applied to represent and recognise hand written characters in (Wong and You, 1985).\n3.3. Distance measure between first-order random graphs\nA FORG can be derived by synthesising a set of individual attributed graphs or a set of previous FORGs once a common labelling is established. The (weighted) increment of entropy in the synthesis of two FORGs has properties that render it a distance measure between the random graphs involved. The entropy of a FORG reflects the variability in the structural and attribute values of its outcome AGs, and it can be calculated as the sum of the entropy of its random elements (vertices and arcs) from their probability density functions. Let ( )\u00b5,, 21 RRR += denote the synthesis of the FORGs 1R and 2R under a common labelling established by a given morphism \u00b5 , and let 1r and 2r be a priori probabilities associated with 1R and 2R respectively. So the weighted increment of entropy\n( )( )\u00b5,,'' 21 RRH + in the synthesis of random graph R from 1R and 2R according to \u00b5\nis defined as the sum of the weighted increments of entropy in the synthesis of all the random elements of R, i.e.\n( )( ) ( ) ( ) ( ) ( )( )( )\u2211 \u2208 +\u2212=+ R HrHrHdRRH \u03b3 \u03b3\u03b3\u03b3\u03b3\u03b3\u00b5 22112121 ,,,'' (5)\nwhere ( )\u00b5\u03b3\u03b3\u03b3 ,, 21+= denotes the synthesis of the random elements 1\u03b3 and 2\u03b3 in\n1R and 2R , respectively, according to \u00b5 ; ( )21 ,\u03b3\u03b3d is a distance between the random\nelements 1\u03b3 and 2\u03b3 which acts as a weight and which is based on the difference between their probability density functions; and ( )\u03b3H is the entropy of the random\nelement \u03b3 defined as,\n- 41 -\n( ) ( ) ( )( )\u2211 \u2208 =\u2217=\u2212= \"\" PrlogPr \u03b3 \u03b3\u03b3\u03b3 ofrangea aaH\n(6)\nA distance measure between the two FORGs 1R and 2R is defined as the minimum weighted increment of entropy in their synthesis over the set of possible morphisms \u00b5 ,\ni.e.\n( ) ( )( )( )\u00b5 \u00b5 ,,'', 2121 RRHminRRd += (7)\nSince an AG can be treated as a special case of a FORG, the above distance can be applied to two AGs or one AG and one FORG or two FORGs. These distance measures can be used to perform various tasks in structural pattern recognition such as learning and classification.\n3.4. Example of the distance between first-order random graphs\nFigure 3 shows the structure of random graphs 1A and 2A , which have been synthesised from a single AG, and the structure of G , which has been synthesised from 1A and 2A and an optimal labelling.\n2v 4v\n1v 3v\n2v\n5v\n1v 3v\n2v 4v\n1v 3v\n5vRG: A1 RG: A2 RG: G\n(a) (b) (c)\nFigure 3. Structure of random graphs 1A , 2A and G .\nTable 1 shows the attribute values of 1A , 2A and G . The domain of the attribute in the vertices is { }edcba ,,,, and in the arcs it is { }KLZYX ,,,, . The non-existence of graph\n- 42 -\nelements (vertices or arcs) is represented by \u03a6 . The entropy of a random graph synthesised from only one AG is always zero. Thus, ( ) 01 =AH and ( ) 02 =AH . On the other hand, the entropy of G is ( ) ( ) 25.0log*5.0*4 2 =\u2212=GH .\nGraph element 1A 2A ( )optAAG \u00b5,, 21+=\nFigure 4 shows the structure of three other random graphs 1G , 2G and 3G , and Table 2 shows the attribute values of these graphs. Note that 1G is a sub-graph of 1A or 2A , 2G is exactly 1A , and 3G is the union of both 1A and 2A .\n2v 4v\n1v 3v\n2v\n1v 3v\n2v 4v\n1v 3v\n5v RG: G2RG: G1 RG: G3\nFigure 4. Random graphs 1G , 2G and 3G .\n- 43 -\nWe wish to obtain and compare the distances between G and 1G , 2G and 3G . First, the RGs ( )optGGG 111 ,,' \u00b5+= , ( )optGGG 222 ,,' \u00b5+= and ( )optGGG 333 ,,' \u00b5+= have to be synthesised. They have the same structure as G and the attribute values presented in Table 3. From the probabilities in Table 3, it can be deduced that the three random graphs have the same entropy, which is\n( ) ( ) ( ) 838.1333.0log*333.0*2666.0log*666.0*2' 22 =\u2212\u2212=iGH\nand therefore, the distance measure between each of the three iG and G is\n( ) ( ) ( ) ( ) 505.00.2 3\n2 838.1\n3\n1\n3\n2 ', =\u2212=\n     +\u2212= iii GHGHGHGGd\nTo conclude, the distance is the same although the structure of 1G , 2G and 3G is different. This is because first-order random graphs are probabilistic structures that do not keep any information about the global structure of the graphs used in the synthesis.\n- 44 -\nFor this reason the distance measure does not distinguish whether 1G , 2G and 3G are a\nsub-graph of 1A or 2A or the union of them.\n- 45 -"}, {"heading": "4. Function-described graphs (FDGs)", "text": "Function-described graphs or FDGs are proposed here for modelling classes of patterns described by attributed graphs. An FDG is a prototype structure that contains, on one hand, probabilistic functions which represent the semantic information of the local parts of the patterns and, on the other, binary functions to maintain, as much as possible, the local features of the AGs that belong to the class and also to reject the AGs that do not belong to it. In general, an FDG can be derived, like random graphs, by synthesising a cluster or set of individual AGs. Section 4.1 compares FDGs and FORGs and describes the novel features of FDGs that represent a set of AGs. Then section 4.2 gives a formal definition of an FDG and section 4.3 presents some technical details about FDG functions. Finally, sections 4.4 and 4.5 discuss the synthesis of an FDG from a set of AGs and from a set of FDGs with given common labellings of their vertices and arcs. Some experiments with random graphs are added in section 4.6.\n4.1. FDGs versus FORGs as prototypes of a set of AGs\nIn order to attain a compact representation of a set of AGs by means of a prototype, the ensemble needs to be described probabilistically so that the variations in the structural patterns of the reference set or sample can be accounted for. As has been mentioned in Section 3, random graphs (RGs) provide such a representation. Nevertheless, when estimating the probability distribution of the structural patterns from an ensemble of AGs, it is impractical to consider the high order probability distribution where all the graph elements are taken jointly. The creators of random graphs believed -and so do we- that general RGs cannot be used in real applications, and so, they proposed firstorder random graphs (FORGs). Although the FORG approach simplifies the representation considerably, it is still difficult to apply in real problems in which AGs have a large number of vertices and attributes with an extensive domain. The main cause of this problem is that the attributes of the arc depend on the attributes of the vertices that the arc connects\n- 46 -\n(assumption 3 in Section 3.2). Although this supposition is useful to constrain the generalisation of the given set of AGs, a huge amount of data is required to estimate the probability density functions and the computational cost is high. On the other hand, because of the probability independence assumptions 1 and 2 in section 3.2, FORGs have the considerable drawback that the structural information in a sample of AGs is not well preserved in the FORG which is synthesised from them. That is to say, a FORG represents an over-generalised prototype that may cover graph structures quite different from those in the sample. For example, if C is a set of AGs describing different perspective views of an object O, many of the outcome graphs of the FORG synthesised from C will represent impossible views of O (just from the topological point of view, without further consideration of the attributes of primitives and relations). Function-described graphs (FDGs) defined below, aim to offer a more practical approach and can be seen as a different type of simplification of general random graphs. They also adopt a different approximation of the joint probability P of the random elements. On one hand, some independence assumptions are considered, but on the other hand, some useful functions are included that permit to constrain the generalisation of the structure. We decided not to maintain the conditional probabilities of the arcs in the FDGs due to space and time restrictions. This means that the third assumption in the FORGs is replaced by the assumption that the arcs are independent except for the existence of the extreme vertices which is mandatory for structural coherence. Hence, the arc conditional probability density functions ( ) =\u0302, 21 jjjq aab\n( ) ,1,,Pr 2211 mjjjjjj \u2264\u2264=== aab \u03b1\u03b1\u03b2 in FORGs are converted into marginal\nprobability density functions ( ) ( ) ,1,,Pr\u02c6 21 mjq jjjj \u2264\u2264\u03a6\u2260\u03a6\u2260== \u03b1\u03b1\u03b2 bb in FDGs.\nThe underlying hypothesis is that the probability of any outcome of a random arc is the same regardless of the actual non-null outcomes of the endpoints. In order to tackle the problem of the over-generalisation of the sample, we introduce the antagonism, occurrence and existence relations into FDGs, which apply to pairs of graph elements. In this way, both random vertices and arcs are not assumed to be\n- 47 -\nmutually independent, at least with regards to the structural information. These secondorder relations, that involve a small increase in the amount of data to be stored in the prototype, are useful for two reasons: they constrain the set of outcome graphs covered by the prototype, thus tending to cut down the structural over-generalisation quite considerably, and, they reduce the size of the search space of the AG-to-FDG matching algorithm, thus decreasing the overall time of the recognition process (see Section 5.1). Let us now explain in more detail the kind of simplification made in FDGs with respect to General RGs. Let us begin with the independence assumptions: 1) The attributes in the vertices are independent of the other vertices and also of the\narcs.\n2) The attributes in the arcs are independent of the other arcs and also of the vertices.\nHowever, it is mandatory that all non-null arcs be linked to a non-null vertex at each extreme in every AG covered by an FDG. In other words, any outcome AG of the FDG has to be structurally consistent. With these assumptions, the probability density functions are themselves independent since the attributes in the arcs do not depend on the attributes in the vertices that they connect, but only on the existence of the extreme vertices. Consequently, associated with each graph element in an FDG, there is a random variable that represents the distribution of the semantic information of the corresponding graph elements in the set of outcome AGs. A random variable has a probability density function defined over the same attribute domains of the AGs, including the null value \u03a6 , that denotes the noninstantiation of an FDG graph element in an outcome AG. It is interesting to emphasise that the attribute domain of each AG element is in general a tuple. For this reason, the random variables are associated with joint probability density functions which depend on the whole set of attributes in the tuple. However, in real applications, the tuple elements are usually considered mutually independent which avoids the spatial cost of representing a joint density function in each graph element. Hence, the joint probability of an AG element can be estimated as the product of the probabilities of all the attributes in the tuple. The probability density functions are not represented analytically in practice, but nonparametrically. Thus, any type of function can be defined, whether discrete or\n- 48 -\ncontinuous. If the attributes are discrete, the representation is simple, just by storing the frequencies of each possible value. When the values are continuous, we use a discretisation process to represent the density function computationally, although a parametric model (e.g. mixture of Gaussians) could be estimated alternatively. The supposition of independence between graph elements can involve an excessive generalisation of the set of patterns used to build the FDG, because objects that do not belong to the target class will be covered. To improve the representation capability, second order probability information (i.e. the joint probabilities of two graph elements) could be added. But since it is extremely difficult in practice to estimate and handle these joint probabilities, only qualitative information of the second order probability functions is added. Hence, in FDGs, the marginal (first order) probability functions are complemented by second order Boolean functions (relations), which provide this qualitative second order information.\nSuppose two vertices in the FDG, 1\u03c9 and 2\u03c9 , the attributes of which are two random elements 1\u03b1 and 2\u03b1 in the domain { }\u03a6\u222a\u2206=\u2206 vw , where v\u2206 is the domain of the attributes of the AGs that the FDG represents and \u03a6 represents the non-existence of vertices in the AG. By definition, the sum of the joint probabilities of these two\nelements of an FDG over their attribute domain \u03c9\u2206 equals 1,\n( ) 1Pr 21 ==\u2227=\u2211 \u2211 \u2206\u2208 \u2206\u2208\u03c9 \u03c9 \u03b1\u03b1 x y yx\n(8)\nMoreover, the domain \u03c9\u03c9 \u2206\u00d7\u2206 can be split into four regions (Figure 5 shows these four regions for the vertices). The first one is composed of the points that belong to the\nCartesian product of the sets of actual attributes of the two elements v\u2206 , corresponding to the cases in which both elements are defined in the initial non-extended AG and so their value is not null. The second and third regions are both straight lines in which only one of the elements has the null value. This covers the cases when one of the two elements does not belong to the initial AG and has been added in the extending process. Finally, the fourth region is the single point where both elements have the null value\n- 49 -\n( \u03a6=\u2227\u03a6= yx ) and, therefore, this includes the cases in which none of them appear in\nthe initial AG.\n2\u03b1\nv\u2206\nv\u2206\n1\u03b1\n\u03a6\n\u03a6\n\u03a6=\u2227\u03a6= 21 \u03b1\u03b1 \u03a6=\u2227\u2206\u2208 21 \u03b1\u03b1 v\nv\u2206\u2208\u2227\u03a6= 21 \u03b1\u03b1vv \u2206\u2208\u2227\u2206\u2208 21 \u03b1\u03b1\nFigure 5. Joint probability of two vertices split into four regions.\nThe sum of joint probabilities is composed of four terms according to these four regions as follows,\n( ) ( ) ( ) ( ) 1 PrPr PrPr\n2121 2121 =      \u03a6=\u2227\u03a6=+\u03a6=\u2227\u03a6\u2260 +\u03a6\u2260\u2227\u03a6=+\u03a6\u2260\u2227\u03a6\u2260 \u03b1\u03b1\u03b1\u03b1 \u03b1\u03b1\u03b1\u03b1\n(9)\nThis last equation is used to implement a qualitative approximation of the joint probability function of two elements represented through the antagonism, occurrence and existence functions in the FDGs. In the case that the probabilities in the first region are all zero, ( ) 0Pr 21 =\u03a6\u2260\u2227\u03a6\u2260 \u03b1\u03b1 , we say the two graph elements of the FDG are antagonistic, which means that, although they are included in the prototype as different elementary parts of the covered patterns, they have never taken place together in any AG of the reference set used to synthesise the FDG. On the other hand, if the joint probability function equals zero in the second region, ( ) 0Pr 21 =\u03a6=\u2227\u03a6\u2260 \u03b1\u03b1 , it is possible to assure that if the element 1\u03b1 appears in any AG of the reference set then the element 2\u03b1 must also appear. So, there is a structural dependence of the element 2\u03b1 on the element 1\u03b1 . That is called an occurrence relation. The case of the third region is analogous to\n- 50 -\nthe second one, with the only difference that the elements are swapped. Finally, if ( ) 0Pr 21 =\u03a6=\u2227\u03a6= \u03b1\u03b1 , all the objects in the class described by the FDG have at least one of the two elements, and we say that there is an existence relation between them.\nFigure 6 shows three possible joint probabilities of the vertices i\u03c9 and j\u03c9 . In case (a),\nthey are defined as antagonistic, whereas in case (b), there is an occurrence relation\nfrom i\u03c9 to j\u03c9 , and in case (c), there is an existence relation between i\u03c9 and j\u03c9 .\nj\u03b1\nv\u2206\nv\u2206\ni\u03b1\n\u03a6\n\u03a6\n( )jiP \u03b1\u03b1 \u2227\nFigure 6.a. Example of joint probability that defines an antagonistic relation.\nj\u03b1\nv\u2206\nv\u2206\ni\u03b1\n\u03a6\n\u03a6\n( )jiP \u03b1\u03b1 \u2227\nFigure 6.b. Example of joint probability that defines an occurrence relation.\n- 51 -\nj\u03b1\nv\u2206\nv\u2206\ni\u03b1\n\u03a6\n\u03a6\n( )jiP \u03b1\u03b1 \u2227\nFigure 6.c. Example of joint probability that defines an existence relation.\n4.2. Formal definition of FDGs\nDefinition 5 (Function-described graph or FDG): A function-described graph F over ( )ev \u2206\u2206 , with an underlying graph structure ( )\u03b5\u03c9 \u03a3\u03a3= ,H is defined as a tuple ( )RPBW ,,, such that\n1. ( )\u03c9\u03c9 \u03b3,\u03a3=W is a random vertex set and \u03c9\u03c9\u03c9\u03b3 \u2126\u2192\u03a3: is a mapping that associates each vertex \u03c9\u03c9 \u03a3\u2208i with a random variable ( )ii \u03c9\u03b3\u03b1 \u03c9= with values in \u03c9\u2206 . 2. ( )\u03b5\u03b5 \u03b3,\u03a3=B is a random arc set and \u03b5\u03b5\u03b5\u03b3 \u2126\u2192\u03a3: is a mapping that associates each arc \u03b5\u03b5 \u03a3\u2208kl with a random variable ( )klj \u03b5\u03b3\u03b2 \u03b5= with values in \u03b5\u2206 .\n3. ( )\u03b5\u03c9 PPP ,= are two sets of marginal (or first-order) probability density functions for random vertices and edges, respectively. That is, { }nipP i \u2264\u2264= 1),(a\u03c9 and\n{ }mjqP j \u2264\u2264= 1),(b\u03b5 (being m the number of edges), where )Pr()( aa =\u2261 iip \u03b1 for all\n\u03c9\u2206\u2208a and )Pr()( 21 \u03a6\u2260\u2227\u03a6\u2260=\u2261 jjjjq \u03b1\u03b1\u03b2 bb for all \u03b5\u2206\u2208b such that 21, jj \u03b1\u03b1 refer\nto the random variables for the endpoints of the random arc associated with j\u03b2 .\n4. ( )\u03b5\u03c9\u03b5\u03c9\u03b5\u03c9 EEOOAAR ,,,,,= is a collection of Boolean functions defined over pairs of graph elements (i.e. relations on the sets of vertices and arcs) that allow qualitative\nsecond-order probability information to be incorporated. \u03c9A and \u03b5A are the so-called vertex antagonism and arc antagonism functions, respectively, where\n- 52 -\n{ }1,0: \u2192\u03a3\u00d7\u03a3 \u03c9\u03c9\u03c9A is defined by ( ) ( ) 0Pr1, =\u03a6\u2260\u2227\u03a6\u2260\u21d4= jijiA \u03b1\u03b1\u03c9\u03c9\u03c9 , and\nsimilarly, { }1,0: \u2192\u03a3\u00d7\u03a3 \u03b5\u03b5\u03b5A is defined by ( ) ( ) 0Pr1, =\u03a6\u2260\u2227\u03a6\u2260\u21d4= jipqklA \u03b2\u03b2\u03b5\u03b5\u03b5 , where ( )kli \u03b5\u03b3\u03b2 \u03b5= and ( )pqj \u03b5\u03b3\u03b2 \u03b5= . The above functions can be seen alternatively as\nsymmetric binary relations on the sets \u03c9\u03a3 and \u03b5\u03a3 , respectively. In addition, \u03c9O and\n\u03b5O are the so-called vertex occurrence and arc occurrence functions, where { }1,0: \u2192\u03a3\u00d7\u03a3 \u03c9\u03c9\u03c9O is defined by ( ) ( ) 0Pr1, =\u03a6=\u2227\u03a6\u2260\u21d4= jijiO \u03b1\u03b1\u03c9\u03c9\u03c9 , and { }1,0: \u2192\u03a3\u00d7\u03a3 \u03b5\u03b5\u03b5O is defined by ( ) ( ) 0Pr1, =\u03a6=\u2227\u03a6\u2260\u21d4= jipqklO \u03b2\u03b2\u03b5\u03b5\u03b5 , where ( )kli \u03b5\u03b3\u03b2 \u03b5= and ( )pqj \u03b5\u03b3\u03b2 \u03b5= . These last functions can be seen alternatively as\nreflexive and transitive relations (partial orders) on the sets \u03c9\u03a3 and \u03b5\u03a3 , respectively.\nFinally, \u03c9E and \u03b5E are the so-called vertex existence and arc existence functions, where { }1,0: \u2192\u03a3\u00d7\u03a3 \u03c9\u03c9\u03c9E is defined by ( ) ( ) 0Pr1, =\u03a6=\u2227\u03a6=\u21d4= jijiE \u03b1\u03b1\u03c9\u03c9\u03c9 , and\n{ }1,0: \u2192\u03a3\u00d7\u03a3 \u03b5\u03b5\u03b5E is defined by ( ) ( ) 0Pr1, =\u03a6=\u2227\u03a6=\u21d4= jipqklE \u03b2\u03b2\u03b5\u03b5\u03b5 , where ( )kli \u03b5\u03b3\u03b2 \u03b5= and ( )pqj \u03b5\u03b3\u03b2 \u03b5= . These two last functions can be seen alternatively as\nsymmetric binary relations on the sets \u03c9\u03a3 and \u03b5\u03a3 , respectively. Figure 7 shows a simple FDG with an underlying graph structure composed by 4\nvertices and 6 arcs. There is also an antagonistic relation between vertices 1\u03c9 and\n3\u03c9 and an occurrence relation from arc 2,4\u03b5 to arc 2,3\u03b5 .\n- 53 -\nBecause of the structural consistency requirements, there is no need to store the\nconditional probabilities )Pr( 21 \u03a6=\u2228\u03a6== jjj \u03b1\u03b1\u03b2 b in the structure of the FDGs,\nsince, by definition, an arc cannot exist or has to be defined as null if one of the connecting vertices does not exist or is null, that is,\n1)Pr( 21 =\u03a6=\u2228\u03a6=\u03a6= jjj \u03b1\u03b1\u03b2 .\nFurthermore, two graph elements (of the same type) are co-occurrent if and only if the occurrence relation applies to them in both directions. Figure 8 shows a joint probability\nof two vertices that defines a co-occurrence relation. \u03c9C and \u03b5C are the so-called vertex co-occurrence and arc co-occurrence functions, where { }1,0: \u2192\u03a3\u00d7\u03a3 \u03c9\u03c9\u03c9C is defined by ( ) ( )+\u03a6=\u2227\u03a6\u2260\u21d4= jijiC \u03b1\u03b1\u03c9\u03c9\u03c9 Pr1, ( ) 0Pr =\u03a6\u2260\u2227\u03a6= ji \u03b1\u03b1 , and { }1,0: \u2192\u03a3\u00d7\u03a3 \u03b5\u03b5\u03b5C is defined by ( ) \u21d4=1, pqklC \u03b5\u03b5\u03b5 ( ) ( ) 0PrPr =\u03a6\u2260\u2227\u03a6=+\u03a6=\u2227\u03a6\u2260 jiji \u03b2\u03b2\u03b2\u03b2 , where ( )kli \u03b5\u03b3\u03b2 \u03b5= and ( )pqj \u03b5\u03b3\u03b2 \u03b5= . It\nfollows that co-occurrence of vertices or arcs are symmetric binary relations on the sets\n\u03c9\u03a3 and \u03b5\u03a3 , respectively. The co-occurrence relations are not stored in the FDGs since they can be easily deduced from the occurrence relations.\nA random element \u03b4 of an FDG is a null random element if its probability of instantiation to the null value is one, 1)Pr( =\u03a6=\u03b4 . This means that all the values in the\nattribute tuple of every instance of a null random element are the null value \u03c6 .\n- 54 -\nA complete FDG is an FDG with a complete graph structure H (but which may include null elements). The FDG extending process, needed for calculating the distance between an AG and an FDG, adds null graph elements to make an FDG complete and with a desired order (greater or equal than the original one). These null graph elements are used to signify a missing element in the \u201cinitial FDG\u201d that represents the prototype. It is important to note that the initial FDG and the extended FDG share the same semantic and structural information, thus representing exactly the same prototype.\nDefinition 6 (k-extension of an FDG): A function-described graph ( )RPBWF ,,,= of\norder n can be extended to form a complete FDG ( )',',','' RPBWF = of order nkk \u2265, ,\nby adding null vertices and null arcs and extending appropriately both the set of probability density functions and the Boolean functions that relate graph elements. We call 'F the k-extension of F . As a result of defining the antagonism, occurrence and existence functions of the FDGs, the value of these functions in an extended FDG is as shown in Tables 4, 5 and 6,\nrespectively, where i\u03b4 and j\u03b4 are the random variables associated with elements i\u03b3 and\n- 55 -\n4.3. Relationships between functions of FDGs\nThe following sections discuss some interesting properties of the information represented in an FDG. These properties relate some of the aforementioned functions. Particular mention is made of the relations between first and second order probabilities the antagonism, occurrence and existence relations and the joint probability of the null value.\n4.3.1. Non-conditional probabilities of arc attributes\nConcerning the information stored in the arcs, the first-order probabilities depend only on the existence of the extreme vertices, whereas in the antagonism, occurrence and existence relations, this conditional constraint is not taken in consideration (definition 5, FDG). This is because the imposition of this constraint alone on the first-order probabilities is sufficient to guarantee that the outcome AGs of an FDG are structurally coherent. Hence, it is interesting to observe the relation between non-conditional probabilities in the arcs and the first-order probability density functions defined in the FDGs. There are two cases: the probability of the null value and the probability of a non-null value. The relations that follow are taken into account in the study of both the second-order Boolean functions and the distance between AGs and FDGs. Let us consider the non-conditional probability of the null value, ( )\u03a6=i\u03b2Pr , which can be calculated as the sum of the following four terms:\n- 56 -\n( )\n( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )      \n\n\n      \n\n\u03a6\u2260\u2227\u03a6\u2260\u03a6\u2260\u2227\u03a6\u2260\u03a6=\n+\u03a6=\u2227\u03a6\u2260\u03a6=\u2227\u03a6\u2260\u03a6=\n+\u03a6\u2260\u2227\u03a6=\u03a6\u2260\u2227\u03a6=\u03a6=\n+\u03a6=\u2227\u03a6=\u03a6=\u2227\u03a6=\u03a6=\n=\u03a6=\n2121\n2121\n2121\n2121\nPr*Pr\nPr*Pr\nPr*Pr\nPr*Pr\nPr\niiiii\niiiii\niiiii\niiiii\ni\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b2\n(10)\nSince the FDG describes structurally coherent AGs, the arc conditional probability of the null value when one of the extreme vertices is also null is 1, by definition. Moreover, since the attributes in the vertices are regarded as independent, the second order probabilities in the vertices can be approximated as the product of the first order probabilities. Thus,\n( )\n( ) ( ) ( ) ( ) ( ) ( )\n( ) ( ) ( )    \n\n\n     \n\n\u03a6\u2260\u03a6\u2260\u03a6\u2260\u2227\u03a6\u2260\u03a6=\n+\u03a6=\u03a6\u2260\u2217\n+\u03a6\u2260\u03a6=\u2217\n+\u03a6=\u03a6=\u2217\n=\u03a6=\n2121\n21\n21\n21\nPr*Pr*Pr\nPr*Pr1\nPr*Pr1\nPr*Pr1\nPr\niiiii\nii\nii\nii\ni\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\n\u03b1\u03b1\n\u03b1\u03b1\n\u03b2\n(11)\nTherefore, the non-conditional probability of the null value, ( )\u03a6=i\u03b2Pr , can be expressed in terms of the marginal probabilities of both extreme vertices ( )\u03a61ip and\n( )\u03a62ip and the arc conditional probability ( )\u03a6iq , which are stored in the FDG, as\nfollows,\n( )\n( ) ( ) ( ) ( )( )\n( )( ) ( ) ( ) ( )( ) ( )( )\n    \n\n    \n\n\u03a6\u2212\u03a6\u2212\u03a6\n+\u03a6\u03a6\u2212\n+\u03a6\u2212\u03a6\n+\u03a6\u03a6\n=\u03a6=\n21\n21\n21\n21\n1*1*\n*1\n1*\n*\nPr\niii\nii\nii\nii\ni\nppq\npp\npp\npp\n\u03b2\n(12)\nFinally, after some manipulation of the equation, we arrive at the final expression\n( ) ( )( ) ( )( ) ( )( )\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2212=\u03a6\u2260\u2212=\u03a6= 21 1*1*11)Pr(1Pr iiiii ppq\u03b2\u03b2 (13)\n- 57 -\nLet us now consider the non-conditional probability of a specific non-null value, ( )b=i\u03b2Pr , where e\u2206\u2208b , which can be obtained as the sum\n( )\n( ) ( ) ( ) ( ) ( ) ( ) ( ) ( )      \n\n\n      \n\n\u03a6\u2260\u2227\u03a6\u2260\u03a6\u2260\u2227\u03a6\u2260=\n+\u03a6=\u2227\u03a6\u2260\u03a6=\u2227\u03a6\u2260=\n+\u03a6\u2260\u2227\u03a6=\u03a6\u2260\u2227\u03a6==\n+\u03a6=\u2227\u03a6=\u03a6=\u2227\u03a6==\n==\n2121\n2121\n2121\n2121\nPr*Pr\nPr*Pr\nPr*Pr\nPr*Pr\nPr\niiiii\niiiii\niiiii\niiiii\ni\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b1\u03b1\u03b1\u03b1\u03b2\n\u03b2\nb\nb\nb\nb\nb\n(14)\nSince the FDG describes structurally coherent AGs, the arc conditional probability of a non-null value when one of the extreme vertices is null is 0, by definition. Thus,\n( ) ( ) ( )\u03a6\u2260\u2227\u03a6\u2260\u03a6\u2260\u2227\u03a6\u2260=== 2121 Pr*PrPr iiiiii \u03b1\u03b1\u03b1\u03b1\u03b2\u03b2 bb (15)\nDue to the independence among vertices, it turns out that\n( ) ( ) ( ) ( )\u03a6\u2260\u03a6\u2260\u03a6\u2260\u2227\u03a6\u2260=== 2121 Pr*Pr*PrPr iiiiii \u03b1\u03b1\u03b1\u03b1\u03b2\u03b2 bb (16)\nand, using the first-order probabilities stored in the FDG, the final equation shows again a dependence on the extreme vertices,\n( ) ( ) ( )( ) ( )( )\u03a6\u2212\u2217\u03a6\u2212\u2217== 21 11Pr iiii ppq bb\u03b2 (17)\n4.3.2. Second-order functions and joint probabilities of the null\nvalue\nAntagonism, occurrence and existence functions are defined independently in FDGs. However, we prove here that there is dependence among them through the first and second order probabilities of the null value. Since first order information is explicitly stored in FDGs, we will see that to find out whether two graph elements have an antagonism, occurrence or existence relation it is only necessary to know the joint\n- 58 -\nprobability of these two graph elements being null, ( )\u03a6=\u2227\u03a6= ji \u03b1\u03b1Pr . In a computer\nimplementation, these relations (and the co-occurrence, if needed) can be maintained directly as relations or easily calculated, by using the equations shown below and storing the joint probability of the null value. If we take into account that ( ) ( ) 0Pr1Pr =\u03a6\u2260\u2227\u03a6\u2260\u21d4=\u03a6=\u2228\u03a6= jiji \u03b1\u03b1\u03b1\u03b1 , the\nantagonism in the vertices can be given by\n( ) ( ) 1Pr1, =\u03a6=\u2228\u03a6=\u21d4= jijiA \u03b1\u03b1\u03c9\u03c9\u03c9 (18)\nUsing the first and second order probabilities, this is equivalent to\n( ) ( ) ( ) ( ) 1PrPrPr1, =\u03a6=\u2227\u03a6=\u2212\u03a6=+\u03a6=\u21d4= jijijiA \u03b1\u03b1\u03b1\u03b1\u03c9\u03c9\u03c9 (19)\nHence, we obtain a new equation of the antagonism relation in the vertices that depends on the marginal probabilities defined in the FDG and also on the joint probabilities of the null value.\n( ) ( ) ( ) ( ) 1Pr1, =\u03a6=\u2227\u03a6=\u2212\u03a6+\u03a6\u21d4= jijiji ppA \u03b1\u03b1\u03c9\u03c9\u03c9 (20)\nThe antagonism function in the arcs can be expressed in a similar way. Let ( ) iab \u03b2\u03b5\u03b3 \u03b5 = and ( ) jcd \u03b2\u03b5\u03b3 \u03b5 = be two random arc elements. Firstly, we note that\n( ) ( ) 1Pr1, =\u03a6=\u2228\u03a6=\u21d4= jicdabA \u03b2\u03b2\u03b5\u03b5\u03b5 (21)\nand then by using the first and second order probabilities,\n( ) ( ) ( ) ( ) 1PrPrPr1, =\u03a6=\u2227\u03a6=\u2212\u03a6=+\u03a6=\u21d4= jijicdabA \u03b2\u03b2\u03b2\u03b2\u03b5\u03b5\u03b5 (22)\nThis last equation can be rewritten using the first order probabilities of vertices and arcs stored in the FDG together with the arc joint probabilities of the null value,\n- 59 -\n( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( )\n( )    \n\n\n    \n\n=\u03a6=\u2227\u03a6=\n\u2212\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2212\n+\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2212\n\u21d4=\n1Pr\n1*1*11\n1*1*11\n1, 21\n21\nji\njjj\niii\ncdab ppq\nppq\nA\n\u03b2\u03b2\n\u03b5\u03b5\u03b5\n(23)\nRestructuring the equation, the final expression is\n( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( )\n( )    \n\n\n    \n\n=\u03a6=\u2227\u03a6=\n+\u03a6\u2212\u03a6\u2212\u03a6\u2212\n+\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u21d4=\n1Pr\n1*1*1\n1*1*1\n1, 21\n21\nji\njjj\niii\ncdab ppq\nppq\nA\n\u03b2\u03b2\n\u03b5\u03b5\u03b5\n(24)\nNow let us consider the occurrence functions between vertices. They can be rewritten using the first and second order probabilities of the null value as follows\n( ) ( ) ( ) 0PrPr1, =\u03a6=\u2227\u03a6=\u2212\u03a6=\u21d4= jijjiO \u03b1\u03b1\u03b1\u03c9\u03c9\u03c9 (25)\nHence, replacing the first order probabilities by the associated FDG functions, we obtain\n( ) ( ) ( ) 0Pr1, =\u03a6=\u2227\u03a6=\u2212\u03a6\u21d4= jijji pO \u03b1\u03b1\u03c9\u03c9\u03c9 (26)\nThe occurrence relations between arcs can be restated in a similar way,\n( ) ( ) ( ) 0PrPr1, =\u03a6=\u2227\u03a6=\u2212\u03a6=\u21d4= jijcdabO \u03b2\u03b2\u03b2\u03b5\u03b5\u03b5 (27)\nand using the FDG probability density functions we obtain\n( ) ( )( ) ( )( ) ( )( )\n( )   \n\n  \n\n=\u03a6=\u2227\u03a6=\u2212\n\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2212 \u21d4=\n0Pr\n1*1*11 1, 21\nji\njjj\ncdab\nppq O\n\u03b2\u03b2 \u03b5\u03b5\u03b5\n(28)\nFinally, the equation is simplified as\n- 60 -\n( ) ( )( ) ( )( ) ( )( )\n( )   \n\n  \n\n=\u03a6=\u2227\u03a6=+\n\u03a6\u2212\u03a6\u2212\u03a6\u2212 \u21d4=\n1Pr\n1*1*1 1, 21\nji\njjj\ncdab\nppq O\n\u03b2\u03b2 \u03b5\u03b5\u03b5\n(29)\nThere is no need to mention here the existence relations on the vertices or arcs as they are directly defined through the second order probabilities of the null value (see Section 4.2).\n4.3.3. Second-order effects of first-order information\nFrom equations (20) and (26) it is easily derived that\n( ) ( ) ( ) 11,1, =\u03a6\u21d4=\u2227= ijiji pOA \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 (30)\nwhich is to say that only null vertices are both antagonistic and occurrent to all the other vertices of the graph, and moreover, a null vertex will always be antagonistic with and occurrent to the remaining vertices. A similar equation is found for the arcs in equations (24) and (29),\n( ) ( ) ( ) 1Pr1,1, =\u03a6=\u21d4=\u2227= icdabcdab OA \u03b2\u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 (31)\nSome cases satisfy both antagonism and occurrence between two elements but this is contrary to the common sense. In these cases, there is one artificially inserted element. That is, it makes no sense to say that the two elements cannot appear together (antagonism) and, at the same time, that one of them must appear whenever the other does (occurrence). On the other hand, from equation (26) and the definition of vertex existence function, we also have that\n( ) ( ) ( ) 01,1, =\u03a6\u21d4=\u2227= jjiji pOE \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 (32)\nwhich is to say that only strict non-null vertices are both existent and occurrent from all the other vertices of the graph, and moreover, a strict non-null vertex will always be\n- 61 -\nexistent with and occurrent from the remaining vertices. The equation is similar for the arcs in equation (27). The final equation for the definition of arc existence function is,\n( ) ( ) ( ) 0Pr1,1, =\u03a6=\u21d4=\u2227= jcdabcdab OE \u03b2\u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 (33)\nEquations (30) to (33) show the second-order effects of purely first-order events. For example, a single graph element is always absent or present for extended null elements and strict non-null elements, respectively, in the FDG. These effects should be taken into account when using second-order constraints to match AGs with FDGs (see Sections 5.1 and 5.2).\n4.3.4. Symmetry of second-order functions and the co-occurrence\nrelation\nThe antagonism and existence relations are symmetric as can be seen directly from their definitions: that is ( ) ( )ijji AA \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 ,, = , ( ) ( )abcdcdab AA \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 ,, = , ( ) =jiE \u03c9\u03c9\u03c9 ,\n( )ijE \u03c9\u03c9\u03c9 , and ( ) ( )abcdcdab EE \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 ,, = .\nThe occurrence relation is clearly non-symmetric, but in some cases another symmetric relation, the co-occurrence of nodes or arcs, may be of interest. A Boolean cooccurrence function of pairs of vertices can be defined in terms of the corresponding occurrence functions as\n( ) ( ) ( ) 1,1,1, =\u2227=\u21d4= ijjiji OOC \u03c9\u03c9\u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9\u03c9 (34)\nSimilarly, we can define the co-occurrence function of pairs of arcs as\n( ) ( ) ( ) 1,1,1, =\u2227=\u21d4= abcdcdabcdab OOC \u03b5\u03b5\u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5\u03b5 (35)\nIt is readily proved that these co-occurrence relations are also reflexive and transitive and therefore they are equivalence relations.\n- 62 -\n4.4. Synthesis of FDGs from AGs with a common labelling\nLet { }zGGD ,,1 K= be a set of AGs defined over a common attribute domain ( )ev \u2206\u2206 , . Let ( )ggg AVG ,= where ( )gvgvgV \u03b3,\u03a3= and ( )gegegA \u03b3,\u03a3= , for zg \u2264\u22641 . Assume that there are given labelling schemes ( ) zgLL egegevgvgvg ,,1,:,: K=\u2192\u03a3\u03a8\u2192\u03a3\u03a8=\u03a8 ,\nwhere gv\u03a8 is an injective mapping from the underlying structural vertex set of gG to a\ncommon set of vertex labels { }nLv ,,1K= and g e\u03a8 similarly labels arcs with labels from { })1(,,1 \u2212= nnLe K . The labelling schemes g\u03a8 can be extended to bijective mappings ( )egegevgvgvg LL \u2192\u03a3\u03a8\u2192\u03a3\u03a8=\u03a8 ':',':'' , zg ,,1K= , if each AG gG is\npreviously extended to a complete graph gG' of order n. The arc labellings are also\nassumed to be consistent across all graphs in D, i.e. the arc from the vertex labelled k to\nthe vertex labelled l has the same label eLjnlknumberarcj \u2208= ),,,(_ , in all graphs. For instance, let the function ),,(_ nlknumberarc be defined as follows:\n   >\u2212+\u2212\u2212 <+\u2212\u2212 = kllnk kllnk nlknumberarc if1)1)(1( if)1)(1( ),,(_ Under this assumption, it is important to note that arc labellings ge'\u03a8 are merely introduced for notational convenience, since all the information required is contained in the node labellings gv'\u03a8 .\n- 63 -\nAn FDG ( )RPBWF ,,,= over ( )ev \u2206\u2206 , can be synthesised from D and '\u03a8 in a straightforward manner (figure 9). F includes a complete underlying graph structure\n( )\u03b5\u03c9 \u03a3\u03a3= ,H with a set of n vertices { }n\u03c9\u03c9\u03c9 ,,1 K=\u03a3 and a set of )1( \u2212nn arcs { }lknlkkl \u2260\u2264\u2264=\u03a3 ,,1|\u03b5\u03b5 . The random vertex set ( )\u03c9\u03c9 \u03b3,\u03a3=W associates each vertex \u03c9\u03c9 \u03a3\u2208i with a random variable ( )ii \u03c9\u03b3\u03b1 \u03c9= with values in { }\u03a6\u222a\u2206=\u2206 v\u03c9 and the random arc set ( )\u03b5\u03b5 \u03b3,\u03a3=B associates each arc \u03b5\u03b5 \u03a3\u2208kl with a random variable\n( )klj \u03b5\u03b3\u03b2 \u03b5= with values in { }\u03a6\u222a\u2206=\u2206 e\u03b5 , where ),,(_ nlknumberarcj = .\nNow, let ( )ev LL \u2192\u03a3\u2192\u03a3= \u03b5\u03b5\u03c9\u03c9 \u03d5\u03d5\u03d5 :,: be a labelling scheme on F defined simply by ( ) ii =\u03c9\u03d5\u03c9 and ( ) ),,(_ nlknumberarckl =\u03b5\u03d5\u03b5 . From labellings '\u03a8 and \u03d5 , we can determine a set of bijective mappings ( ){ }zggegegvgvg \u2264\u2264\u03a3\u2192\u03a3\u03a3\u2192\u03a3= 1,':,': \u03b5\u03c9 \u00b5\u00b5\u00b5 from the AGs in D to the\nsynthesised FDG such that gv g v \u00b5\u03d5\u03c9 o=\u03a8' and g e g e \u00b5\u03d5\u03b5 o=\u03a8 ' , for zg ,,1K= . The probability density functions, ( )\u03b5\u03c9 PPP ,= , { }nipP i ,,1),( K== a\u03c9 of individual random vertices and { })1(,,1),( \u2212== nnjqP j Kb\u03b5 of individual random arcs (given\nnon-null endpoints), can be estimated separately, in the maximum likelihood sense,\n- 64 -\nusing frequencies of attributes and null values in D. Let ( )i g v g iv \u03c9\u00b5 1\u2212 = and\n( ) 2121\n1\njj\ng e g jje \u03b5\u00b5 \u2212 = be, respectively, the node labelled i and the edge labelled j in the\nattributed graph gG' . Then,\nz\nvzgg p\ng i g\nv ii\na aa =\u2264\u2264 === )(:1:# )Pr()( \u03b3 \u03b1\n(36)\nfor all possible values \u03c9\u2206\u2208a of i\u03b1 , including \u03a6 , and\nj\ng jj g e g j g v g j g v\njjjj\nu\nevvzgg\nq\nb\nbb\n=\u2227\u03a6\u2260\u2227\u03a6\u2260\u2264\u2264 =\n=\u03a6\u2260\u2227\u03a6\u2260==\n)()()(:1:#\n)Pr()(\n2121\n21\n\u03b3\u03b3\u03b3\n\u03b1\u03b1\u03b2\n(37)\nwhere ju is the number of AGs, which has both vertices g jv 1 and g jv 2 .\n\u03a6\u2260\u2227\u03a6\u2260\u2264\u2264= )()(:1:# 21\ng jvg g jvgj vvzggu \u03b3\u03b3\n(38)\nThe binary relations ( )\u03b5\u03c9\u03b5\u03c9\u03b5\u03c9 EEOOAAR ,,,,,= in the synthesised FDG can be\ncomputed as follows. The vertex antagonism function \u03c9A and the arc antagonism\nfunction \u03b5A are given by\n( ) ( )     \u03a6\u2260\u2227\u03a6\u2260\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , g jvg g ivg ji vvzgg A \u03b3\u03b3 \u03c9\u03c9\u03c9\n(39)\n( ) ( )     \u03a6\u2260\u2227\u03a6\u2260\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , 2121 2121 g jjeg g iieg jjii eezgg A \u03b3\u03b3 \u03b5\u03b5\u03b5\n(40)\nThe vertex occurrence function \u03c9O and the arc occurrence function \u03b5O are given by\n- 65 -\n( ) ( )     \u03a6=\u2227\u03a6\u2260\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , g jvg g ivg ji vvzgg O \u03b3\u03b3 \u03c9\u03c9\u03c9\n(41)\n( ) ( )     \u03a6=\u2227\u03a6\u2260\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , 2121 2121 g jjeg g iieg jjii eezgg O \u03b3\u03b3 \u03b5\u03b5\u03b5\n(42)\nAnd, finally, the vertex existence function \u03c9E and the arc existence function \u03b5E are given by\n( ) ( )     \u03a6=\u2227\u03a6=\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , g jvg g ivg ji vvzgg E \u03b3\u03b3 \u03c9\u03c9\u03c9\n(43)\n( ) ( )     \u03a6=\u2227\u03a6=\u00ac\u2264\u2264\u2200 = otherwise0 )()(:1: if1 , 2121 2121 g jjeg g iieg jjii eezgg E \u03b3\u03b3 \u03b5\u03b5\u03b5\n(44)\nThe vertex co-occurrence function \u03c9C and the arc co-occurrence function \u03b5C may always be evaluated as ( ) ( ) ( )ijjiji OOC \u03c9\u03c9\u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9\u03c9 ,,, \u2227= and ( ) =2121 , jjiiC \u03b5\u03b5\u03b5\n( ) ( ) 21212121 ,, iijjjjii OO \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 \u2227 , respectively.\n4.5. Synthesis of FDGs from FDGs with a common labelling\nLet { }hFFD ,,1 K= be a set of FDGs independently synthesised from disjoint subsets of a class of AGs with common homogenous domains for attributed vertices and arcs. Let ( )kkkkk RPBWF ,,,= , for hk \u2264\u22641 , defined over a common attribute domain\n( )ev \u2206\u2206 , . For each FDG kF , the number of AGs from which it is formed, kz , is stored. For each random arc kj\u03b2 of kF , the number of these AGs kju , which have both\nconnecting vertices is also stored (See equation 38). Assume that there are given labelling schemes ( )\u03b5\u03b5\u03b5\u03c9\u03c9\u03c9 LL kkkkk \u2192\u03a3\u03a8\u2192\u03a3\u03a8=\u03a8 :,: , hk ,,1K= , mapping the vertices and arcs of the FDGs kF into common label sets\n- 66 -\n{ }nL ,,1K=\u03c9 and { })1(,,1 \u2212= nnL K\u03b5 , such that all k \u03c9\u03a8 and k \u03b5\u03a8 are injective and all\narc labellings are consistent throughout the set D . If the order of some FDG kF is less than n , then kF can be extended to an isomorphic complete FDG kF ' of order n by adding null vertices and arcs. Therefore, the labelling schemes k\u03a8 can be extended to bijective mappings ( )\u03b5\u03b5\u03b5\u03c9\u03c9\u03c9 LL kkkkk \u2192\u03a3\u03a8\u2192\u03a3\u03a8=\u03a8 ':',':'' , hk ,,1K= , whenever each FDG kF is previously extended to a complete FDG kF ' of order n. As in the synthesis of FDGs from AGs, the arc labellings are also assumed to be consistent across all FDGs in D, i.e. the arc from the vertex labelled t to the vertex\nlabelled l has the same label \u03b5Ljnltnumberarcj \u2208= ),,,(_ , in all FDGs. An FDG ( )RPBWF ,,,= over ( )ev \u2206\u2206 , can be synthesised from D and the common labelling '\u03a8 as follows. F includes a complete underlying graph structure\n( )\u03b5\u03c9 \u03a3\u03a3= ,H with a set of n vertices { }n\u03c9\u03c9\u03c9 ,,1 K=\u03a3 and a set of )1( \u2212nn arcs { }ltnlttl \u2260\u2264\u2264=\u03a3 ,,1|\u03b5\u03b5 . The random vertex set ( )\u03c9\u03c9 \u03b3,\u03a3=W associates each vertex \u03c9\u03c9 \u03a3\u2208i with a random variable ( )ii \u03c9\u03b3\u03b1 \u03c9= with values in { }\u03a6\u222a\u2206=\u2206 v\u03c9 and the random arc set ( )\u03b5\u03b5 \u03b3,\u03a3=B associates each arc \u03b5\u03b5 \u03a3\u2208tl with a random variable\n( )tlj \u03b5\u03b3\u03b2 \u03b5= with values in { }\u03a6\u222a\u2206=\u2206 e\u03b5 , where ),,(_ nltnumberarcj = .\nNow, let ( )\u03b5\u03b5\u03b5\u03c9\u03c9\u03c9 \u03d5\u03d5\u03d5 LL \u2192\u03a3\u2192\u03a3= :,: be a labelling scheme on F defined simply by ( ) ii =\u03c9\u03d5\u03c9 and ( ) ),,(_ nltnumberarctl =\u03b5\u03d5\u03b5 . From labellings '\u03a8 and \u03d5 , we can determine a set of bijective mappings ( ){ }hkkkkkk \u2264\u2264\u03a3\u2192\u03a3\u03a3\u2192\u03a3= 1,':,': \u03b5\u03b5\u03b5\u03c9\u03c9\u03c9 \u00b5\u00b5\u00b5 from the FDGs in D to the\nsynthesised FDG such that kk \u03c9\u03c9\u03c9 \u00b5\u03d5 o=\u03a8' and kk \u03b5\u03b5\u03b5 \u00b5\u03d5 o=\u03a8' , for hk ,,1K= . Let\n( )i kk i \u03c9\u00b5\u03c9 \u03c9 1\u2212 = and ( ) 2121 1 jj kk jj \u03b5\u00b5\u03b5 \u03b5 \u2212 = be, respectively, the vertex labelled i and the edge labelled j in the FDG kF ' . The probability density functions, ( )\u03b5\u03c9 PPP ,= , { }nipP i ,,1),( K== a\u03c9 of individual random vertices and { })1(,,1),( \u2212== nnjqP j Kb\u03b5 of individual random arcs (given\n- 67 -\nnon-null endpoints) can be estimated separately, using the corresponding probabilities in kP\u03c9 and kP\u03b5 together with the values kz and kju , hk ,...,1= .\nLet kt be the normalised number of AGs used to synthesise the FDG kF .\nhk\nz\nz t\nh\ng\ng\nk k \u2264\u2264=\n\u2211 =\n1;\n1\n(45)\nAnd let kjr be the normalised number of k ju for each kF (See equation 38).\n( )11;1;\n1\n\u2212\u2264\u2264\u2264\u2264=\n\u2211 =\nnnjhk\nu\nu r\nh\ng\ng j\nk\njk j\n(46)\nThen, for all possible values \u03c9\u2206\u2208a of random vertex i\u03b1 including \u03a6 , we have that\n( )\u2211 =\n\u2217=== h\nk\nk i k\nii ptp 1 )Pr()( aaa \u03b1 (47)\nand for all possible values \u03b5\u2206\u2208b of j\u03b2 , including \u03a6 .\n( )\u2211 =\n\u2217=\u03a6\u2260\u2227\u03a6\u2260== h\nk\nk j k\njjjjj qrq 1 )Pr()( 21 bbb \u03b1\u03b1\u03b2\n(48)\nThe binary relations ( )\u03b5\u03c9\u03b5\u03c9\u03b5\u03c9 EEOOAAR ,,,,,= in the synthesised FDG are all readily calculated, since they are given by the logical and of the corresponding functions in the\nFDGs kF . The vertex antagonism function \u03c9A and the arc antagonism function \u03b5A are given by\n( ) ( )kjkik h\nk ji AA \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 ,, 1= \u039b=\n(49)\n- 68 -\n( ) ( )k jjkiik h\nk jjii AA 2112121 ,, 1 \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 = \u039b=\n(50)\nThe vertex occurrence function \u03c9O and the arc occurrence function \u03b5O are given by\n( ) ( )kjkik h\nk ji OO \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 ,, 1= \u039b=\n(51)\n( ) ( )k jjkiik h\nk jjii OO 2112121 ,, 1 \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 = \u039b=\n(52)\nAnd, finally, the vertex existence function \u03c9E and the arc existence function \u03b5E are given by\n( ) ( )kjkik h\nk ji EE \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 ,, 1= \u039b=\n(53)\n( ) ( )k jjkiik h\nk jjii EE 2112121 ,, 1 \u03b5\u03b5\u03b5\u03b5 \u03b5\u03b5 = \u039b=\n(54)\n4.6. Experimental results\nIn order to examine the behaviour of the new representation, we performed a number of experiments with randomly generated AGs. The algorithms presented here were implemented in visual C++ and run on a Pentium II (350Mhz). AGs were generated by a random graph generator process with the following parameters: - nFDG : Number of models. - NT : Number of AGs in the test set. - NR : Number of AGs in the reference set for each model (FDG). - nv : Number of vertices of the initial AGs.\n- 69 -\n- ne : Number of arcs of the initial AGs. - nd : Number of deleted vertices of the initial AGs. - nl : Number of distorted vertices of the initial AGs. We randomly generated nFDG initial attributed graphs, one for each model, based on the parameters nv and ne . From these graphs, the reference and test sets were derived in the following way (figure 10). For each initial AG, a reference set ofNRAGs was built by changing the attribute of nd vertices to the null value (that is to say, they were deleted) and replacing the attribute of nl vertices by another integer number (0 to 999).\nAlso, for each initial AG, a test set of nFDGNT AGs was constructed in the same\nway. Thus, the whole test set was composed of NT AGs and the whole reference set was composed of nFDG subsets of NR AGs. The FDGs were synthesised from the AGs in the corresponding reference sets using the method \u201cFDG synthesis from AGs with a common labelling\u201d (section 4.4).\n- 70 -\nTable 7. Parameters of the first experiments.\nFigure 11 shows the number of vertices of the synthesised FDG when the number of vertices of the AGs (nv \u2019) and the number of AGs in the reference set (NR ) are varied. Figures 11.a to 11.d show the results from different number of vertices of the initial graphs, nv . Figure 11.e shows three different combinations of the values nv and nv \u2019. The number of vertices of the FDG increases while the number of AGs remains small until it reaches the correct value. Furthermore, the bigger the AGs are, the faster the number of FDG vertices reaches the maximum value. When 1=NR the number of FDG vertices is the same than the number of AG vertices, nv \u2019.\n- 71 -\nFigure 11.d shows the number of vertices when the initial graph have 36 vertices. In the cases that the AGs are very small 3'=nv and 6'=nv , the maximum value is not reached which means that the FDG is not totally covered by the AGs. For instance, in\n- 72 -\nthe case that the number of AG vertices is 3, and 20 AGs are used to synthesise the FDG, only 30 vertices are generated instead of 36. Figure 12 shows the number of antagonisms in the synthesised FDG. We observe that the maximum value of the number of antagonisms increases when the number of vertices in the AGs (nv \u2019) decreases. Moreover, for a given nv \u2019, the number of antagonisms is zero when the FDG has been synthesised with only one AG, that is\n1=NR . This is because, the whole vertices of the FDG appear in the same AG and so\nthere are not antagonistic. Furthermore, the number of antagonisms increases when NR increases until reaching a maximum value and then it decreases monotonically if NR is further increased. In all the tests, the maximum number of antagonisms is reached once the maximum number of FDG vertices (nv ) is reached (see figure 11). This is due to the fact that when new vertices are added to the FDG structure new antagonisms between them and the other vertices are added. Whereas, for a fixed graph structure (the number of FDG vertices is not modified), second-order relations can only be removed but not added when more outcome AGs are introduced in the reference set or update the FDG.\nFunction-Described Graph (nv=9)\n0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n1 3 5 7 9 11 13 15 17 19\nNR\nN u\nm b\ne r\no f\na n\nta g\no n\nis m\ns\nnv'=3 nv'=6\nFunction-Described Graphs (nv=18)\n0\n20\n40\n60\n80\n100\n120\n1 3 5 7 9 11 13 15 17 19\nNR\nN u\nm b\ne r\no f\na n\nta g\no n\nis m\ns\nnv'=3 nv'=6 nv'=9 nv'=12\n(a) nv=9 (b) nv=18\n- 73 -\nFigure 12.d shows the case in which 36=nv . In the cases that nv \u2019 is greater than 6, the maximum value is reached when the number of vertices also reaches the maximum value (see figure 11). In the cases 3'=nv and 6'=nv , the maximum number of vertices is not reached and neither the maximum number of antagonisms. Figure 13 shows the number of occurrences of the synthesised FDG. Unlike the antagonism function, for a fixed NR , the number of occurrences increases when the number of vertices in the AGs (nv \u2019) also increases. Bigger are the AGs, more occurrence functions appear between the FDG vertices. When the number of vertices of the AGs is very small the FDG is partially covered by \u201csmall pieces\u201d and so, there are few occurrences. And also, when 1=NR the whole FDG vertices are mutually occurrent. As in the antagonism case, the number of occurrences increases when NR\nincreases until reaching a maximum value and then decreases when NR is further\n- 74 -\nincreased. The explanation of these results is similar than of the results on the antagonisms. Nevertheless, in the occurrence case, the maximum value is reached before the number of FDG vertices reaches the maximum value.\nFigure 14 shows the number of existences of the synthesised FDG. The average of the number of existences is a monotonically decreasing function due to when new AGs are included the existence relations only can be removed. As in the occurrence case, when 1=NR the whole FDG vertices have existence relations.\n- 75 -\n- 77 -"}, {"heading": "5. Distance measures for matching AGs to FDGs", "text": "This chapter presents the distance measure between AGs and FDGs. In the first section, the distance is introduced by means of Bayesian theory. Then, the distance measure between AGs and FDGs is presented using restrictions and it is compared with the Sanfeliu distance measure (Sanfeliu and Fu, 1983) in section 5.2. However, spurious elements mean that this distance becomes too coarse in real applications. Therefore section 5.3 proposes another distance in which the second order constraints (constraints on the antagonism, occurrence and existence relations) are relaxed. Finally, in section 5.4, a simple example of both distances is outlined.\n5.1. Distance measure and the Bayesian theory framework\nTo study the matching between an AG G (data graph) and an FDG F (prototype graph) we use the Bayesian theory framework, as in (Wilson, 1997). The distance measures that will be proposed to match AGs with FDGs are somehow related to the maximum a posteriori probability ( )GhP of a labelling function FGh \u2192: given the\nmeasurements on the data graph G. The type of labelling function that is considered matches graph elements (vertices and arcs) of the AG with those of the FDG. The particular definition of the distance measure d and how it is obtained from the most\nprobable (or least costly) labelling function dh will be specified later depending on the type of constraints.\nIn any case, we should attempt to minimise the cost hC of the matching assignment with respect to a set H of valid labelling functions h. Theoretically, the optimal\napproach would be to compute the cost hC as a monotonic decreasing function of the a posteriori probability, ( )( )GhPfuncCh = . But, in practice, a well-founded approach,\nwhich also leads to optimal matching if uniform a priori probabilities (within H) are assumed, is to take the cost as a monotonic decreasing function of the conditional probability of the data graph given the labelling function, ( )( )hGPfuncCh = .\n- 78 -\nTo illustrate this, let us apply the Bayes theorem to the a posteriori probability, which gives\n( ) ( ) ( ) ( )GP hPhGP GhP \u2217 =\n(55)\nwhere the three probabilities in the right hand side of the equation deserve some comments. First of all, the joint overall probability of the graph G, ( )GP , is fixed\nindependently of the match h and therefore it is not taken into account in the definition of the cost hC . The joint conditional probability ( )hGP models the probability of the\nknown measurements given a match or configuration. Since these measurements (attribute values) on the vertices and arcs are considered independent to each other we can factorise the joint conditional probability as\n( ) ( ) ( )( )\u220f \u2200 === x yxhxyhGP )(Pr \u03b3\u03b3 (56)\nwhere x and y are graph elements in the AG and the FDG respectively, ( )y\u03b3 is the\nrandom variable associated with y, ( )x\u03b3 is the attribute value in x, and all the elements\nof both graphs have to appear in the productory (possibly by extending the domain and range of the mapping with null elements). Finally, the a priori probability ( )hP\nrepresents the configuration probability, which, unlike the previous one, models the structural aspects of the AG and the FDG being matched, and defines the allowable configurations in H . In some approaches, the structure that is inconsistent is immediately rejected because the configuration probability is defined as a binary distribution: ( ) chP = , 0>c , if Hh\u2208 , i.e. when the labelling represents a function in\nwhich all structural constraints are fully satisfied; and ( ) 0=hP when Hh\u2209 . The\npositive constant c is merely introduced here for normalisation purposes. In summary, the Bayes theorem maximises the product ( ) ( )hPhGP \u2217 not the posterior\nprobability ( )GhP and reaches the optimal matching dh . Assuming a uniform\n- 79 -\nprobability distribution among the valid labelling functions, the problem is reduced to that of filtering the invalid mappings and maximising ( )hGP within the remaining set\nH . This approach is at the heart of graph search algorithms, such as the subgraph\nisomorphism and maximal clique finding methods. The above framework, however, fails to tackle adequately one of the fundamental problems in computer vision and other pattern recognition fields: namely, that data extracted from the information sources (e.g. images) is noisy, incomplete or uncertain. For this reason, both the posterior probability and the conditional probability mentioned above might sometimes provide a coarse measure of the quality of a match. For example, if an extraneous element is added to a perfectly matched data graph the instantiation probability is zero, i.e. ( ) 0=hGP . We must therefore admit that there may\nbe both extraneous and missing elements in the data graphs. As a consequence, inconsistent matches should no longer be discarded as incorrect since they could be the result of graph corruption (Wilson, 1997). For our purposes, we require a fine but robust matching cost that not only makes powerful use of the measurement information in the data graphs (attribute values) and in the prototypes (random variable distributions) but is also effective way of constraining the possible matches, if we want the system to be able to discern between prototypes. The matching measure must be soft for two reasons: first, because it is assumed that in real applications the patterns are distorted by noise, and second, because a prototype has to represent not only the objects in the reference set but also the ones that are \u201cnear\u201d them. First of all, and for the sake of robustness, the mapping h is not defined from the initial AG that represents the pattern to the initial FDG that represents the class, but from the k-extended AG to the k-extended FDG. In this way, it accepts that there may be some missing graph elements or some extraneous graph elements introduced by noisy effects. A missing element in the AG will be represented by a null element in the extended AG, and an extraneous element in the AG should be mapped to a null element in the extended FDG. Since it is desired to allow a priori all the isomorphisms, the number of vertices k in the extended graphs is set to the sum of the number of vertices in both\n- 80 -\ninitial graphs. Hence, the limit situations in which all the graph elements in the FDG are missing in the AG or all the graph elements in the AG are extraneous are covered. Let 'G be a k-extension of the AG G and 'F be a k-extension of the FDG F . Then, 'G and 'F are structurally isomorphic and complete with the same number of vertices k . They also share a common attribute domain ( )ev \u2206\u2206 , . Now, the labelling function is defined as a mapping '': FGh \u2192 , and the a priori configuration probability of h is\nassumed to be ( ) chP = if Hh\u2208 , and ( ) 0=hP if Hh\u2209 , where the set H is to be\ndetermined and c is a positive constant (in theory, Hc 1= ). Since graphs do not have\nany predetermined orientation and each orientation is given by a morphism h , a global\ncost hC is associated with each h in a set of valid mappings H , and the measure of similarity is defined as the minimum of all such costs,\n{ }h\nHh Cmind \u2208 =\n(57)\nIn addition, an optimal labelling dh is given by\n{ }h Hh d Cminh \u2208 = arg (58)\nWe wish the global cost hC to provide a quantitative idea of the match quality through the mapping h . This cost is based on the joint conditional probability that the AG is generated from the FDG given labellingh , that is, ( )( )hGPfuncCh = . For instance,\n( )( )hGPCh ln\u2212= would be a possible choice, but it is not the most appropriate because\nof its high sensitivity to noise. If only one of the probabilities were to be zero, then the distance obtained would be \u221e . Note that the joint probability ( )hGP cannot be\nestimated directly and has to be approximated by the product of the first-order probabilities of the elements. In this case, the previous choice is equivalent to\n( ) ( )( )( )\u2211 \u2200 ==\u2212= x h yxhxyC )(Prln \u03b3\u03b3 (59)\n- 81 -\nHowever, if only one graph element were to have a probability of zero, the joint\nprobability would be zero and hC would be infinite. Since this may happen due to the noisy presence of an unexpected element (insertion) or the absence of a prototype element (deletion), if only one graph element were not properly mapped due to clutter, the involved graphs would be wrongly considered to be completely different.\n5.2. Distance measure between AGs and FDGs using restrictions\nWe have shown that it is better to decompose the global cost hC into the sum of bounded individual costs associated with the element matches. Although this cost has the major flaw that the joint probability is not considered as a whole, it has the advantage that clutter affects the global cost only locally. An individual cost ),( yxC\nrepresents the dissimilarity between two mapped elements x and y, and it could even be based on the first-order probabilities of the elements, ( ) ( )( )( )yxhxyfuncyxC === )(Pr),( \u03b3\u03b3 , even though it is bounded by some fixed\nconstant, Max),( \u2264yxC , for instance 1),( \u2264yxC .\nThe global cost is therefore computed as the sum of the individual costs of all the matches between graph elements,\n))(,( xhxCC x h \u2211 \u2200 =\n(60)\nThe main concepts underlying the definition of the distance measures between AGs and FDGs have been introduced above. To define the different specific measures, it is only needed to define the set of valid mappings H and the individual costs ),( yxC .\n5.2.1. Definition of restrictions on the valid morphisms\nThe basic elements in the distance which uses graph elements fd are vertices and arcs.\nFor this reason, the configuration probability is defined on a morphism f from G\u2019 with\nan underlying structure ( )ev \u03a3\u03a3 , to F\u2019 with an underlying structure ( )\u03b5\u03c9 \u03a3\u03a3 , . This morphism labels graph elements. It is assumed that the extended AG G\u2019 and the\n- 82 -\nextended FDG F\u2019 are complete and contain the same number of vertices (same order). Since vertices and arcs represent two different kinds of information, the global morphism is actually defined as a pair of morphisms ( )ev fff ,= , where wvvf \u03a3\u2192\u03a3:\nis a mapping defined on the vertices (the basic parts of the object) and \u03b5\u03a3\u2192\u03a3eef : is a mapping defined on the arcs (the relations between these basic parts). The set 0F is composed of all the possible morphisms ( )ev fff ,= . However, if the structural information of the graphs is to be used, some restrictions have to be imposed to attain a valid morphism, which will depend on the particular application. Let ( )fRi denote that f fulfils a certain constraint iR and let iF denote the set of configurations f such that ( )fRi . Next, five types of constraints are defined together with the set of functions that satisfy them. Thus, depending on the nature of the\napplication, the set of valid mappings H is defined as a mapping of the iF or as the intersection of two or more mappings.\nConstraint 1R : The morphisms vf and ef are both defined as bijective functions.\n( ) ( )( ) ( ) ( )( )pqijpqeijejijviv eeefefvvvfvf =\u21d4=\u2227=\u21d4= (61)\nWhen this constraint is applied, the basic elements and their relations in the pattern appear once and only once in the prototype (monomorphism). For instance, if the pattern is a chair, different feet of the chair have to be mapped with different feet of the prototype chair. In addition, since the domain and the range of each mapping have the same cardinality, the above constraint guarantees a structural isomorphism. Constraint 2R : The morphism ( )ev fff ,= has to be coherent structurally.\n( ) ( )( ) ( )( )pqijeqjvpiv efvfvf \u03b5\u03c9\u03c9 =\u21d2=\u2227= (62)\nIf a pair of vertices of G\u2019 are mapped with a pair of vertices of F\u2019, then the arcs in G\u2019 and F\u2019 that connect these vertices have to be mapped together. An arc in the graph is a\n- 83 -\nrelation between two basic elements in the object or in the prototype, therefore, since a\nrelation depends directly on their linking elements, ef is regarded to be dependent on\nvf . Hence, the global morphism f is totally determined by the morphism between\nvertices vf .\nConstraint 3R : The second-order constraints in the vertices have to be fulfilled (except for second-order constraints induced by FDG extended vertices).\nThe satisfaction of constraint 3R means satisfying the antagonism, occurrence and existence relations between vertices. However, the relations that include FDG null vertices should not be taken into account, since they are artificially introduced in the extension of the FDG (see tables 4 - 6). If two vertices are antagonistic, they do not appear together in any of the AGs used to synthesise the FDG. The joint probability of these two vertices both having a non-null value is considered to be zero. The mapping from two vertices of G\u2019 to two antagonistic vertices of F\u2019 is allowed only if at least one of the vertices involved is null. This means that what has been added to be matched is an extended vertex. Thus, the first condition\nof constraint 3R can be expressed as the rule\n( ) ( ) ( )( ) ( ) ( )( )1Pr1Pr 1, =\u03a6=\u2228=\u03a6=\u2228\u03a6=\u2228\u03a6= \u21d2=\u2227=\u2227=\nqpji\nqjvpivqp vfvfA\n\u03b1\u03b1\n\u03c9\u03c9\u03c9\u03c9\u03c9\naa (63)\nwhich, using the first-order probability density functions included in the FDGs, is\n( ) ( ) ( )( ) ( ) ( )( )11 1, =\u03a6\u2228=\u03a6\u2228\u03a6=\u2228\u03a6= \u21d2=\u2227=\u2227=\nqpji\nqjvpivqp\npp\nvfvfA aa \u03c9\u03c9\u03c9\u03c9\u03c9\n(64)\nThe two rightmost terms in the consequent of the above rule make it possible to match a non-null vertex of the AG to an extended (null) vertex of the FDG. Otherwise, due to the second-order effect shown in table 4, the FDG null vertices would never be matched to actual vertices in the AG and, consequently, they would be of no help in bringing some flexibility to the matching process.\n- 84 -\nNow, if a vertex is occurrent to another, and provided that the former has appeared in an AG used to synthesise the FDG, the latter will also have appeared. This means that the joint probability of these two vertices is zero when the second vertex is a null element and the first one is not. If it is considered desirable to keep the same dependence in the matched AG, when two vertices of the AG are mapped to two occurrent vertices of the FDG, the morphism is allowed in two situations. The first one is when the vertex of the AG mapped to the first element in the occurrence relation is null or the vertex of the AG mapped to the second element is non-null (occurrence satisfaction). The second one is when at least one of the FDG vertices is null, i.e. an extended vertex. This also allows a non-null vertex of the AG to be matched to an extended vertex of the FDG (insertion).\nThus, the second condition of constraint 3R is given by\n( ) ( ) ( )( ) ( )( )1Pr 1, =\u03a6=\u2228\u03a6\u2260\u2228\u03a6= \u21d2=\u2227=\u2227=\npji\nqjvpivqp vfvfO\n\u03b1\n\u03c9\u03c9\u03c9\u03c9\u03c9\naa (65)\nwhich, using the probability density functions defined in the FDGs, is\n( ) ( ) ( )( ) ( )( )1 1, =\u03a6\u2228\u03a6\u2260\u2228\u03a6= \u21d2=\u2227=\u2227=\npji\nqjvpivqp\np\nvfvfO aa \u03c9\u03c9\u03c9\u03c9\u03c9\n(66)\nNote that the term 1)( =\u03a6qp is not included in the consequent of the above rule because it would be totally redundant, since ( ) 1)(1)(1, =\u03a6\u21d2=\u03a6\u2227= pqqp ppO \u03c9\u03c9\u03c9 .\nIn other words, we could restate the rule as \u201ceither the occurrence relation is satisfied or at least one of the FDG vertices is null\u201d. Finally, if an existence relation between two FDG vertices holds, at least one of the AG vertices mapped to them should be non-null, i.e. included in the original AG. However, as in the cases of the previous relations, the existence constraint is defined to be fulfilled as well when one of the FDG vertices is null (this may only happen if the other FDG\nvertex is a strict non-null vertex). Thus, the third condition of constraint 3R is given by\n- 85 -\n( ) ( ) ( )( ) ( ) ( )( )1Pr1Pr 1, =\u03a6=\u2228=\u03a6=\u2228\u03a6\u2260\u2228\u03a6\u2260 \u21d2=\u2227=\u2227=\nqpji\nqjvpivqp vfvfE\n\u03b1\u03b1\n\u03c9\u03c9\u03c9\u03c9\u03c9\naa (67)\nwhich, using the probability density functions defined in the FDGs, is\n( ) ( ) ( )( ) ( ) ( )( ).11 1, =\u03a6\u2228=\u03a6\u2228\u03a6\u2260\u2228\u03a6\u2260 \u21d2=\u2227=\u2227=\nqpji\nqjvpivqp\npp\nvfvfE aa \u03c9\u03c9\u03c9\u03c9\u03c9\n(68)\nConstraint 4R : The second-order constraints in the arcs have to be fulfilled (except for second-order constraints induced by FDG null arcs). The reasons and explanations are similar to the vertex case, but the use of the arc conditional probabilities stored in the FDG has to be considered. For notational purposes, let ( ) mije e b=\u03b3 and ( ) nkte e b=\u03b3 be, respectively, the attribute values of the\narcs ije and kte in the AG, and let ( ) gab \u03b2\u03b5\u03b3 \u03b5 = and ( ) fcd \u03b2\u03b5\u03b3 \u03b5 = be, respectively, the\nrandom variables associated with arcs ab\u03b5 and cd\u03b5 in the FDG. The antagonism constraint on the arcs can be expressed as the rule\n( ) ( ) ( )( ) ( ) ( )( )1Pr1Pr 1, =\u03a6=\u2228=\u03a6=\u2228\u03a6=\u2228\u03a6= \u21d2=\u2227=\u2227=\nfgnm\ncdkteabijecdab efefA\n\u03b2\u03b2\n\u03b5\u03b5\u03b5\u03b5\u03b5\nbb (69)\nwhich, taking into account equation (13) given in Section 4.3.1 and using the probability density functions represented in the FDG, is equivalent to the rule\n( ) ( ) ( )( ) ( )( ) ( )( ) ( )( )\n( )( ) ( )( ) ( )( )  \n\n\n  \n\n=\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2228=\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2228\u03a6=\u2228\u03a6=\n\u21d2=\u2227=\u2227=\n01*1*1\n01*1*1\n1,\ndcf\nbagnm\ncdkteabijecdab\nppq\nppq\nefefA\nbb\n\u03b5\u03b5\u03b5\u03b5\u03b5\n(70)\nThe occurrence constraint on the arcs is given by\n( ) ( ) ( )( ) ( )( )1Pr 1, =\u03a6=\u2228\u03a6\u2260\u2228\u03a6= \u21d2=\u2227=\u2227=\ngnm\ncdkteabijecdab efefO\n\u03b2\n\u03b5\u03b5\u03b5\u03b5\u03b5\nbb (71)\n- 86 -\nAs in the antagonism case, equation (13), the arc occurrence constraint can be expressed using the FDG probability density functions as\n( ) ( ) ( )( ) ( )( ) ( )( ) ( )( )( )01*1*1 1, =\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2228\u03a6\u2260\u2228\u03a6= \u21d2=\u2227=\u2227=\nbagnm\ncdkteabijecdab\nppq\nefefO bb \u03b5\u03b5\u03b5\u03b5\u03b5\n(72)\nFinally, the existence constraint on the arcs is given by\n( ) ( ) ( )( ) ( ) ( )( )1Pr1Pr 1, =\u03a6=\u2228=\u03a6=\u2228\u03a6\u2260\u2228\u03a6\u2260 \u21d2=\u2227=\u2227=\nfgnm\ncdkteabijecdab efefE\n\u03b2\u03b2\n\u03b5\u03b5\u03b5\u03b5\u03b5\nbb (73)\nor, with the FDG probability density functions, by\n( ) ( ) ( )( ) ( )( ) ( )( ) ( )( )\n( )( ) ( )( ) ( )( )  \n\n\n  \n\n=\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2228=\u03a6\u2212\u03a6\u2212\u03a6\u2212\u2228\u03a6\u2260\u2228\u03a6\u2260\n\u21d2=\u2227=\u2227=\n01*1*1\n01*1*1\n1,\ndcf\nbagnm\ncdkteabijecdab\nppq\nppq\nefefE\nbb\n\u03b5\u03b5\u03b5\u03b5\u03b5\n(74)\nConstraint 5R : The relative order between non-null arcs in planar graphs has to be preserved when a structural isomorphism is applied.\nLet tr be the number of arcs departing from a node t in G and let { } vtt rn \u03a3\u2192,,1: K be\na function that represents an ordering of these arcs. Similarly, let dr be the number of\narcs departing from a node d in F and let { } \u03c9\u03a3\u2192dd rn ,,1: K be an ordering function\nof these arcs. Then, the planar graph constraint is given by\n( ) ( ) ( ) ( )( ) ( ) ( )( )( )         <\u2228<\u2227<\u2228<< \u21d2=\u2227=\u2227=\u2227=\n\u2264<<\u2264\u2200\nbacbaccba\nefefefvf\nrkjikjit\ncdnktnebdnjtneadnitnedtv\nt\ndtdtdt )()()()()()(\n:1:,,,\n\u03b5\u03b5\u03b5\u03c9\n(75)\nNote that a rotational shift is permitted in the above expression.\n- 87 -\n5.2.2. Individual costs of matching elements\nWe now turn our attention to the individual cost of matching a pair of elements, one from an AG and one from an FDG. The cost is defined as a normalised function which depends on the dissimilarity between the two mapped elements, as given by the negative logarithm of the probability of instantiating the random element of the FDG to the corresponding attribute value in the AG. That is\n( )\n( )( ) ( )\n( )\n  \n  \n \u2265==\n\u2212\n==\u2212\n=\notherwise1\n)()()(Prif ln\n)()()(Prln\n, Pr Pr\nKyxfxy K\nyxfxy\nyxC\n\u03b3\u03b3 \u03b3\u03b3\n(76)\nwhere the cost ( )yxC , is bounded by [ ]1,0 , and the positive constant [ ]1,0Pr \u2208K is a threshold on low probabilities that is introduced to prevent the case ( )0ln , which gives\nnegative infinity. Hence, ( ) 1, =yxC will be the cost of matching a null element of the\nFDG to a non-null element of the AG or of matching an FDG element to an AG element whose attribute value has a very low probability of instantiation. That is to say, ( ) Pr)()()(Pr Kyxfxy \u2264== \u03b3\u03b3 .\nThe individual cost of the vertices is defined using the probabilities stored in the FDG as\n( )\n( )( ) ( )\n( )\n  \n  \n \u2265\n\u2212\n\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKp K\np\nvC iq\niq\nqifv\na a\n\u03c9\n(77)\nThe individual cost of the arcs is defined using the arc conditional probabilities as follows. Let ( ) mije e b=\u03b3 in the AG arc and let ( ) nab \u03b2\u03b5\u03b3 \u03b5 = in the matched FDG arc.\nThen, in general,\n- 88 -\n( )\n( )( ) ( )\n( )\n  \n \n \u2265\n\u2212\n\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKq K\nq\neC mn\nmn\nabijfe\nb b\n\u03b5\n(78)\nHowever, if either iv or jv is a null extended vertex in the AG, then the conditional\nprobability ( )mnq b is not applicable, since it depends on the existence of the two extreme vertices, and must be replaced by the conditional probability ( )\u03a6=\u2228\u03a6== bamn \u03b1\u03b1\u03b2 bPr , which is 1 if \u03a6=mb and 0 otherwise.\nFinally, the total cost of a given mapping f is calculated as\n( )( ) ( )( )ijeij Ge fivi Gv ff efeCKvfvCKC eij e vi v ,, 'of 2 'of 1 \u2211\u2211 \u03a3\u2208\u2200\u03a3\u2208\u2200 \u2217+\u2217=\n(79)\nThe two terms are weighted by non-negative constants 1K and 2K , to compensate for the different number of elements in the additions. Thus, the distance measure between an AG and an FDG is defined as the minimum cost achieved by a valid morphism f,\n{ }f Hf f Cmind \u2208 =\n(80)\n5.2.3. Comparison with edit-operation distances\nSanfeliu and Fu\u2019s classical framework for comparing graphs (Sanfeliu and Fu, 1983) is based on the idea that the distance between two structures is the lowest global cost of transforming one into the other using edit operations (see section 2.2). Six edit operations are used in graphs: deletion, insertion and substitution of vertices and arcs. There is a certain cost associated with each edit operation, and thus, the global cost is the sum of the costs of the edit operations involved. However, in our approach, all these edit operations can be viewed as substitutions and, more importantly, the individual costs depend on the attribute values and the probability density functions of the random elements and are therefore variable. There are four type of matches on the vertices and arcs. They depend on whether the elements belong to the\n- 89 -\ninitial graphs G and F or whether they have been added while extending the graphs to G\u2019 and F\u2019, respectively.\nLet us first study the match between vertices iv and q\u03c9 by analysing the four possible\ncases: 1) Both vertices belong to the initial graphs. The cost, therefore, depends on the probability of the attribute value in the vertex of G, ( )iqp a , and it can be seen as a\nsubstitution cost which depends on the semantic information,\n( )\n( )( ) ( )\n( )\n  \n  \n \u2265\n\u2212\n\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKp K\np\nvC iq\niq\nqifv\na a\n\u03c9\n(81)\n2) The vertex of the AG belongs to the initial graph G and the vertex of the FDG is a null element (added during the extension process). The probability in the null elements of the FDG F\u2019 is 0 for any actual attribute value in the vertex of G, that is to say,\n( ) 0=iqp a , and therefore,\n( ) 1, =qif vC v \u03c9 (82)\nThis case can be regarded as an insertion operation with a constant cost.\n3) The vertex of the AG G\u2019 is a null element (added during the extension process) and the vertex of the FDG belongs to the initial graph F. The cost depends on the probability of the null value in the random vertex of the FDG,\n( )\n( )( ) ( )\n( )\n  \n  \n \u2265\u03a6\n\u2212\n\u03a6\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKp K\np\nvC q\nq\nqifv \u03c9\n(83)\n- 90 -\nThis case can be considered as a deletion operation, but it is important to emphasise that the cost is not constant but variable and dependent on the probability of the null value. Suppose this probability is high, as most of the AGs used to synthesise this FDG do not contain this vertex. Then, the cost will be low and, therefore, this individual match will not substantially increase the distance value. On the contrary, if most of the AGs used to synthesise the FDG include this vertex, then the probability of the null value will be low and the cost high. 4) Both vertices have been added during the extension process. It is not desirable that this match should influence the global cost, as an arbitrary number of null elements can be generated independently of the initial graphs. Bearing in mind that in this situation\n( ) 1=\u03a6qp (by definition) then this case can be regarded as a substitution operation with\nzero cost.\n( ) ( ) ( ) 0 ln 1ln ,\nPr\n= \u2212\n\u2212 =\nK vC qifv \u03c9\n(84)\nWe move on to study the match between the arcs ije and ab\u03b5 . For convenience we assume that ( ) mije e b=\u03b3 and that ( ) nab \u03b2\u03b5\u03b3 \u03b5 = . We should point out that the first-order\nprobability functions stored in the arcs of F\u2019 are conditioned to the existence of the corresponding extreme vertices in G. As before, the following four cases must be analysed: 1) Both arcs belong to the initial graphs. It is a substitution operation but we have to\ndistinguish whether the vertices connected by ab\u03b5 in F have been matched to vertices that belong to the initial graph G or to null vertices. In the first situation, the probability ( )meq b is applicable and the cost depends on the semantic knowledge,\n( )\n( )( ) ( )\n( )\n  \n  \n \u2265\n\u2212\n\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKq K\nq\neC mn\nmn\nabijfe\nb b\n\u03b5\n(85)\n- 91 -\nIn the second situation, which cannot occur if the morphism belongs to 2F since it is a\nnon-coherent match, one of the endpoints of ab\u03b5 is matched to a null vertex. Bearing in mind that ( ) 0Pr =\u03a6=\u2228\u03a6=\u03a6\u2260 ban \u03b1\u03b1\u03b2 , the substitution cost applied is the highest\none,\n( ) 1, =abijf eC e \u03b5 (86)\n2) The arc of the AG belongs to the initial graph (it is non-null) but the arc of the FDG is a null element. In this case we have an insertion cost that is constant and maximum.\nNevertheless, it can be reached in two different ways. If nq is applicable because the extreme vertices of ab\u03b5 are matched to non-null vertices of G\u2019, then ( ) 0=mnq b for all\n\u03a6\u2260mb . On the contrary, if nq is not applicable because the extreme vertices of ab\u03b5 are matched to null vertices of G\u2019, then ( ) 0Pr =\u03a6=\u2228\u03a6=\u03a6\u2260 ban \u03b1\u03b1\u03b2 , and thus,\n( ) 1, =abijf eC e \u03b5 (87)\n3) The AG arc is a null element and the FDG arc belongs to the initial F (deletion operation). Here, as in the first case, we have to distinguish whether the vertices connected by the arc of F have been matched to vertices of G or to null vertices. In the first situation, ( )mnq b is applicable and the cost depends on the probability of the null value,\n( )\n( )( ) ( )\n( )\n  \n \n \u2265\u03a6\n\u2212\n\u03a6\u2212\n=\notherwise1\nif ln\nln\n, Pr Pr\nKq K\nq\neC n\nn\nabijfe \u03b5\n(88)\n- 92 -\nIn the second situation, which is also a perfectly coherent match, because an extreme vertex of a null arc can be a null vertex in a morphism belonging to 2F , ( )mnq b does not apply but ( ) 1Pr =\u03a6=\u2228\u03a6=\u03a6= ban \u03b1\u03b1\u03b2 , and therefore\n( ) ( ) ( ) 0 ln 1ln ,\nPr\n= \u2212\n\u2212 =\nK eC abijfe \u03b5\n(89)\n4) Finally, the case in which both arcs are null elements in their respective graphs. As in the vertex case, the total cost should not be influenced by this match, so the individual\ncost is zero in the two possible cases. The first, when the extreme vertices of ab\u03b5 have been matched to null elements, nq is not defined but ( ) 1Pr =\u03a6=\u2228\u03a6=\u03a6= ban \u03b1\u03b1\u03b2 .\nThe second, when the extreme vertices of ab\u03b5 have been matched to non-null elements, nq is defined as ( ) 1=\u03a6nq . In both cases it turns out that\n( ) ( ) ( ) 0 ln 1ln ,\nPr\n= \u2212\n\u2212 =\nK eC abijfe \u03b5\n(90)\n5.3. Distance between AGs and FDGs relaxing 2nd order constraints\nSecond order relations of are useful for constraining the set of possible labellings\nbetween AGs and FDGs through restrictions 3R and 4R . The aimed of this constraint is to obtain the best labelling function f, taking into account, as much as possible, the structure of the cluster of AGs that was used to synthesise the FDG. Nevertheless, in real applications, AGs can be distorted by external noise and, therefore, the constraints\n3R and 4R associated to the second order relations have to be relaxed to prevent a noisy\nAG being misclassified due to non-fulfilment of any of these constraints. For instance, due to the second-order effect shown in equation (32) (section 4.3.3), the deletion of a strict non-null vertex of the FDG will almost always involve the non-fulfilment of some of the existence or occurrence constraints induced by that strict non-null vertex.\n- 93 -\nTo gain more flexibility and robustness, instead of applying hard binary constraints, some local non-negative costs may be added to the global cost of the labelling depending on the second-order probabilities of the graph elements. Equations (91) to (93) show how to define these costs for the vertices. They assume that ( ) piv vf \u03c9= and\n( ) qjv vf \u03c9= . These equations cover the three following qualitative cases: \u03c9AC represents\nthe presence of both vertices in the AG, \u03c9O C represents the presence of only one of them, and \u03c9E C the absence of both vertices. Note that, as in the definition of restriction\n3R , the second-order costs induced artificially by FDG null vertices are not taken into\naccount.\n( ) ( ) ( ) ( )    \n\n  \n\n  \n\n\u2260\u03a6\u2227\u2260\u03a6\n\u2227\u03a6\u2260\u2227\u03a6\u2260 \u03a6\u2260\u2227\u03a6\u2260\u2212\n=\notherwise0\n11 Pr1\n,,, qp\nji\nqp qpjiA pp\nif vvC\naa \u03b1\u03b1\n\u03c9\u03c9 \u03c9\n(91)\n( ) ( ) ( )    \n\n  \n\n  \n\n\u2260\u03a6\n\u2227\u03a6=\u2227\u03a6\u2260 \u03a6=\u2227\u03a6\u2260\u2212\n=\notherwise0\n1 Pr1\n,,, p\nji\nqp qpjiO p\nif vvC\naa \u03b1\u03b1\n\u03c9\u03c9 \u03c9\n(92)\n( ) ( ) ( ) ( )    \n\n  \n\n  \n\n\u2260\u03a6\u2227\u2260\u03a6\n\u2227\u03a6=\u2227\u03a6= \u03a6=\u2227\u03a6=\u2212\n=\notherwise0\n11 Pr1\n,,, qp\nji\nqp qpjiE pp\nif vvC\naa \u03b1\u03b1\n\u03c9\u03c9 \u03c9\n(93)\nEquations (94) to (96) show the corresponding three types of second-order costs in the case of the arcs, assuming ( ) mije e b=\u03b3 and ( ) nkte e b=\u03b3 as well as ( ) eab \u03b2\u03b5\u03b3 \u03b5 = and\n( ) fcd \u03b2\u03b5\u03b3 \u03b5 = for convenience. As in the definition of restriction 4R , the second-order\ncosts induced by FDG null arcs are not taken into account.\n- 94 -\n( ) ( ) ( ) ( )\n  \n  \n\n   \n\n   \n\n\u2260\u03a6=\n\u2227\u2260\u03a6=\n\u2227\u03a6\u2260\u2227\u03a6\u2260\n\u03a6\u2260\u2227\u03a6\u2260\u2212 =\notherwise0\n1Pr\n1PrPr1 ,,,\nf\ne\nnm\nfe cdabktijA\nif eeC\n\u03b2\n\u03b2\u03b2\u03b2 \u03b5\u03b5\n\u03b5\nbb\n(94)\n( ) ( ) ( )    \n\n        \u2260\u03a6= \u2227\u03a6=\u2227\u03a6\u2260 \u03a6=\u2227\u03a6\u2260\u2212 =\notherwise0 1Pr\nPr1 ,,,\ne\nnm\nfe cdabktijO if eeC \u03b2 \u03b2\u03b2 \u03b5\u03b5\n\u03b5\nbb\n(95)\n( ) ( ) ( ) ( )\n  \n  \n\n   \n\n   \n\n\u2260\u03a6=\n\u2227\u2260\u03a6=\n\u2227\u03a6=\u2227\u03a6=\n\u03a6=\u2227\u03a6=\u2212 =\notherwise0\n1Pr\n1PrPr1 ,,,\nf\ne\nnm\nfe cdabktijE\nif eeC\n\u03b2\n\u03b2\u03b2\u03b2 \u03b5\u03b5\n\u03b5\nbb\n(96)\nSince the second-order probabilities are not actually stored in the FDGs, they are replaced by the second-order relations, and the costs are therefore coarser. That is to say, some second-order non-negative costs are added to the global cost of the labelling when second-order constraints (antagonism, occurrence, existence) are broken. Equations (97) to (102) show the final second-order costs, which can only be 1 or 0, associated to the three relations of antagonism, occurrence and existence between pairs of vertices and pairs of arcs, respectively. The cost of the antagonism on the vertices and arcs,\n( ) ( ) ( ) ( )    \n\n  \n\n  \n\n\u2260\u03a6\u2227\u2260\u03a6\n\u2227\u03a6\u2260\u2227\u03a6\u2260\n=\notherwise0\n11 ,\n,,, qp\nji\nqp qpjiA pp\nifA vvC\naa \u03c9\u03c9\n\u03c9\u03c9 \u03c9 \u03c9\n(97)\n( ) ( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( )\n  \n  \n\n   \n\n   \n\n\u2260\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2227\u2260\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2227\u03a6\u2260\u2227\u03a6\u2260\n=\notherwise0\n01*1*1\n01*1*1, ,,,\ndcf\nbae\nnm\ncdab cdabktijA\nppq\nppqifA eeC\nbb\n\u03b5\u03b5 \u03b5\u03b5 \u03b5\n\u03b5\n(98)\n- 95 -\nThe cost of the occurrences on the vertices and arcs,\n( ) ( ) ( )    \u2260\u03a6\u2227\u03a6=\u2227\u03a6\u2260 = otherwise0 1, ,,, pjiqpqpjiO pifO vvC aa\u03c9\u03c9 \u03c9\u03c9 \u03c9 \u03c9\n(99)\n( ) ( ) ( )( ) ( )( ) ( )( )\n  \n  \n\n   \n\n   \n\n\u2260\u03a6\u2212\n\u03a6\u2212\u03a6\u2212\n\u2227\u03a6=\u2227\u03a6\u2260\n=\notherwise0\n01\n*1*1, ,,,\nb\nae\nnm\ncdab cdabktijO\np\npqifO eeC\nbb\n\u03b5\u03b5 \u03b5\u03b5 \u03b5\n\u03b5\n(100)\nAnd the cost of the existence on the vertices and arcs,\n( ) ( ) ( ) ( )    \n\n  \n\n  \n\n\u2260\u03a6\u2227\u2260\u03a6\n\u2227\u03a6=\u2227\u03a6=\n=\notherwise0\n11 ,\n,,, qp\nji\nqp qpjiE pp\nifE vvC\naa \u03c9\u03c9\n\u03c9\u03c9 \u03c9 \u03c9\n(101)\n( ) ( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( ) ( )( )\n  \n  \n\n   \n\n   \n\n\u2260\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2227\u2260\u03a6\u2212\u03a6\u2212\u03a6\u2212\n\u2227\u03a6=\u2227\u03a6=\n=\notherwise0\n01*1*1\n01*1*1, ,,,\ndcf\nbae\nnm\ncdab cdabktijE\nppq\nppqifE eeC\nbb\n\u03b5\u03b5 \u03b5\u03b5 \u03b5\n\u03b5\n(102)\nNow, the global cost on the labelling function R\nfC is redefined with the two original\nterms that depend on the first-order probability information, and six more terms that depend on the second-order constraints:\n( )( ) ( )( )\n( ) ( )( ) ( ) ( )( )\n( ) ( )( ) ( ) ( )( )\n( ) ( )( ) ( ) ( )( )     \n    \n\n+\u2217+\u2217\n+\u2217+\u2217\n+\u2217+\u2217\n+\u2217+\u2217\n=\n\u2211\u2211\n\u2211\u2211\n\u2211\u2211\n\u2211\u2211\n\u03a3\u2208\u2200\u03a3\u2208\u2200\n\u03a3\u2208\u2200\u03a3\u2208\u2200\n\u03a3\u2208\u2200\u03a3\u2208\u2200\n\u03a3\u2208\u2200\u03a3\u2208\u2200\n'of, 8 'of, 7\n'of, 6 'of, 5\n'of, 4 'of, 3\n'of 2 'of 1\n,,,,,,\n,,,,,,\n,,,,,,\n,,\nGee\nkteijektijE\nGvv\njvivjiE\nGee\nkteijektijO\nGvv\njvivjiO\nGee\nkteijektijA\nGvv\njvivjiA\nijeij\nGe\nfivi\nGv\nf\nR f\nektijvji\nektijvji\nektijvji\neij\ne\nvi\nv\nefefeeCKvfvfvvCK\nefefeeCKvfvfvvCK\nefefeeCKvfvfvvCK\nefeCKvfvCK\nC\n\u03b5\u03c9\n\u03b5\u03c9\n\u03b5\u03c9\n(103)\n- 96 -\nThe eight terms are weighted by non-negative constants 1K to 8K , to compensate for the different number of elements in the additions and to balance the influence of second-order costs with respect to first-order costs in the overall value. Finally, the distance measure between an AG and an FDG using both first-order and second-order\ncosts R\nfd is defined as the minimum cost achieved by a valid morphism f :\n{ }Rf Hf R f Cmind \u2208 =\n(104)\nNote that f R f dd = if \u221e====== 876543 KKKKKK and 43 FFH \u2229\u2282 .\n5.4. Example of the distances between AGs and FDGs\nSection 4.1 proposes that the domain of the joint probability of vertices 1\u03c9 and 2\u03c9 be split into four regions (Figure 3). Assuming that the probability of each region can be zero or greater than zero, there are 16 different combinations of the joint probability. Nevertheless, since the sum of the joint probability throughout the four regions equals 1 (Equation 9), the probabilities of the four regions cannot all be zero (the FDG would be incorrect). Figure 15.b shows the 16 combinations. The joint probability domain is on the left. An X is written in one of the four regions if and only if the sum of the probabilities in that region is greater than zero. The only possible structure obtained\nfrom the corresponding joint probability composed of the vertices 1\u03c9 and 2\u03c9 and some second order relations is on the right (Figure 15.a). Note that it is not \u201clogical\u201d for both occurrence and antagonism relations to be satisfied at the same time between two elements (Equation 31, Section 4.3.3.). If two elements cannot exist in the same AG (antagonism) one of them cannot always exists when the other exists (occurrence). This combination only appears in cases in which one of the elements is null (cases 1 to 5); that is, it is synthetically created element. Moreover, the 16th combination is impossible in a correct FDG and, therefore, the four second-order relations cannot appear between two graph elements at the same time.\n- 97 -\n1)\n1\u03b1\n2\u03b1 X 1\u03c9 2\u03c9\n2)\n1\u03b1\n2\u03b1 X X\n1\u03c9 2\u03c9\n3)\n1\u03b1\n2\u03b1 X 1\n\u03c9 2\u03c9\n4)\n1\u03b1\n2\u03b1\nX\nX 1\u03c9 2\u03c9\n5)\n1\u03b1\n2\u03b1\nX\n1\u03c9 2\u03c9\n6)\n1\u03b1\n2\u03b1 X\nX\n1\u03c9 2\u03c9\n7)\nX\n1\u03b1\n2\u03b1\nX\n1\u03c9 2\u03c9\n8)\nX\n1\u03b1\n2\u03b1 1\u03c9 2\u03c9\n9)\n1\u03b1\n2\u03b1 X\nX\nX 1\u03c9 2\u03c9\n10)\nX\n1\u03b1\n2\u03b1\nX\nX 1\u03c9 2\u03c9\n11)\nX\n1\u03b1\n2\u03b1 X\nX\n1\u03c9 2\u03c9\n12)\n1\u03b1\n2\u03b1 X\nX\n1\u03c9 2\u03c9\n- 98 -\n13)\nX\n1\u03b1\n2\u03b1 X 1\u03c9 2\u03c9\n14)\nX\n1\u03b1\n2\u03b1 X\nX\nX 1\u03c9 2\u03c9\n15)\n1\u03b1\n2\u03b1 X\nX\nX 1\u03c9 2\u03c9\n16)\n1\u03b1\n2\u03b1 1\u03c9 2\u03c9\nFigure 15. Sixteen combinations of the joint probability.\nTables 8 and 9 show the cost of matching the AG vertices 1v and 2v to the FDG vertices 1\u03c9 and 2\u03c9 , respectively, in the 15 possible combinations of the FDG vertices. The costs in Table 8 are computed by applying the distance measure with restrictions\nfC (Section 5.2), whereas the costs in Table 9 are computed by applying the distance\nmeasure in which the second order constraints have been relaxed RfC (Section 5.3).\nThe first order probability costs 1C , [ ]1,01\u2208C , and 2C , [ ]1,02 \u2208C , depend on the attribute values and are not specified. Unlike edit distances (Sanfeliu and Fu, 1983), a strict deletion (d1 for the mapping ( )11,\u03c9v or d2 for the mapping ( )22 ,\u03c9v ) appears when a null AG vertex is matched to an FDG vertex with zero probability of being null. An insertion (i1 for the mapping ( )11,\u03c9v or i2 for the mapping ( )22 ,\u03c9v ) appears when a non-null AG vertex is matched to a null FDG vertex. Non-allowed labellings in the distance with restrictions are represented by the symbol \u221e in Table 8. The costs associated with the second order relations in the distance relaxing constraints are\nrepresented by AC (antagonism), EC (existence) and OC (occurrence) in Table 9.\n- 99 -\nThe distance in which the 2nd order constraints have been relaxed has been introduced to prevent the labelling from being rejected due to a strict deletion or to the non-fulfilment of a second-order constraint. For instance, in case 8 (both vertices appear in all the AGs which are used to synthesise the FDG), when both labelled AG vertices are non-null,\nthe cost is 21 CC + in both distances. Nevertheless, if one of the AG vertices is null, then the labelling is not allowed in the distance with second order restrictions but only one cost is added in the distance in which the 2nd order constraints have been relaxed,\nOCC ++11 .\n- 100 -\n- 101 -"}, {"heading": "6. Algorithms for computing the distance measures", "text": "A reasonable choice for the set of valid morphisms is to take 21 FFH \u2229= , i.e. a oneto-one mapping is required between the vertices of the extended graphs, and the arc mapping is determined from the vertex mapping assuming structural coherence. In\naddition, constraint 5R (the relative order between arcs has to be preserved) should be\nincorporated if the application deals with planar graphs; in this case, 521 FFFH \u2229\u2229= .\nThe second-order constraints 3R and 4R may be applied as hard restrictions, i.e.\n54321 FFFFFH \u2229\u2229\u2229\u2229= , or relaxed into second-order costs, as discussed before.\nThe branch and bound technique applied on the FDG problem is first presented in section 6.1. The computation of the distance with second order restrictions and the distance relaxing these restrictions is studied in Sections 6.2 and 6.3, respectively. The complexity of the distance computation is presented in section 6.4. Section 6.5 shows some experiments with random graphs in which the matching algorithms are used.\n6.1. Branch and bound technique\nThe distance and the optimal morphism between an AG and an FDG are calculated by an algorithm for error-tolerant graph matching. Our approach is based on a tree search by the A* algorithm, where the search space is reduced by a branch and bound technique. The algorithm searches a tree where the nodes represent possible mappings between vertices of both graphs and branches represent combinations of pairs of graph vertices that satisfy the labelling constraints. Hence, the path from the root to the leaves represent allowed labellings f, which belong to H. The distance measure has been theoretically defined so that both graphs are extended to have the same number of elements and to be complete. Nevertheless, in practice, our algorithm only needs the FDG to be extended with one null vertex, because the different permutations of the null vertices are regarded as equivalent labellings. Thus, the AG spurious vertices are possibly matched (through an actually non-injective mapping) to this unique null FDG vertex. On the other hand, the FDG graph elements that remain\n- 102 -\nunmatched when arriving at a leaf are considered to be matched with null AG vertices\n\u03a6v or null AG arcs \u03a6e . Consequently, a final cost of deleting these elements is added to the cost of the labelling in the leaves of the search tree.\nThe constraint 1R (f has to be bijective) is fulfilled by constructing the search tree for all the vertices except for the null vertex of the FDG which has been introduced. The\nnull vertex is permitted to be the image of several AG vertices. The restriction 2R (f has to be coherent structurally) is intrinsically fulfilled since ef is determined by vf ,\nwhich is given by the current path. The constraint 5R (the relative order between arcs has to be preserved) is easily verified by applying its definition at each node of the\nsearch tree. Finally, the verification of the second-order constraints 3R and 4R is discussed in Section 6.2. In general, solving a branch and bound problem requires a branch evaluation function and a global evaluation function. The former assigns a cost to the branch incident to a node N of the tree, which is the cost of the new match (or pair) appended. The latter is used to guide the search at a node N and refers to the cost of the best complete path through N (i.e. including the pairs of vertices already matched when arriving at N). In our case, we also must define the deleting function, which evaluates the cost of deleting the unmatched graph elements of the FDG when a leaf is reached. The cost of a labelling f is given by the value of the FDG global evaluation function in\nthe corresponding leaf, fT , of the search tree. For the distance measure which uses\nrestrictions,\n( ) fHf TlC *=\u2208 (105)\nand, for the distance measure which relaxes second-order constraints,\n( ) f RR Hf TlC *=\u2208\n(106)\n- 103 -\nThe global evaluation function *l (see section 6.2), is a function which is reminiscent of the one presented in (Wong, You and Chan, 1990), and in which some terms have been redefined using our notation and others have been updated to solve the FDG matching problem. The global evaluation function *Rl , which is described in Section 6.3, also takes into account the second-order costs coming from the non-fulfilment of the FDG Boolean functions of antagonism, occurrence and existence.\n6.2. Computation of the distance measure using restrictions\nEach node N of the search tree at level 0>p is described by a collection of pairs of vertices of the graphs, ( ){ } iqi vN \u03c9,= , where pi ,...,2,1= corresponds to the vertex\nindices of the vertices in the AG iv and iq are the various vertex indices of the vertices\nin the FDG iq \u03c9 such that ( ) iqiv vf \u03c9= . We also define the sets { }pv vvvN ,...,, 21= and\n{ } pqqq N \u03c9\u03c9\u03c9\u03c9 ,...,, 21= of vertices that have already been matched between both graphs,\nand the sets { }nppv vvvM ,...,, 21 ++= and { }\u03c9\u03c9 \u03c9\u03c9 NM jj \u2209= of vertices that have not been matched yet. Assume that ( ) ( ) ( ){ } pqpqq vvvN \u03c9\u03c9\u03c9 ,,...,,,, 21 21 = indicates the only path from the root to a tree node N and ( ) ( ) ( ){ } nqnqq vvvT \u03c9\u03c9\u03c9 ,,...,,,, 21 21 = indicates the only path from the root to a leaf T. The branch evaluation function K is defined as the cost of the new match between vertices plus the cost of all the arcs related to these two vertices. This match involves\nvertices from vN and \u03c9N . Thus, the cost assigned to the branch incident to N is given by\n( ) ( ) ( ) ( )( )\u2211 \u2212\n=\n+\u2217+\u2217= 1\n1 21 ,,,,\np\ns\nqqspeqqpseqpfqp pssppvp eCeCKvCKvK \u03b5\u03b5\u03c9\u03c9\n(107)\nwhere ( )\u03b5,eCe is the cost of matching the arc e in the AG to the arc \u03b5 in the FDG, which is computed depending on the existence of both arcs as follows\n- 104 -\n( ) ( ) ( ) ( ) ( ) \n\n  \n\n\u03a3\u2209\u2227\u03a3\u2209=\n\u03a3\u2208\u2227\u03a3\u2209\n\u03a3\u2209\u2227\u03a3\u2208=\n\u03a3\u2208\u2227\u03a3\u2208\n=\n\u03a6\u03a6\n\u03a6\n\u03a6\n\u03b5\n\u03b5\n\u03b5\n\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\nef\nef\nef\nef\ne\neifeC\neifeC\neifeC\neifeC\neC\ne\ne\ne\ne\n0,\n,\n1,\n,\n, (108)\nThe global evaluation function ( )Nl \u2217 at a node N of level p is defined as the cost\n( )Ng \u2217 of an optimal path from the root to the node N plus the cost ( )Nh\u2217 of an optimal\npath from the node N to a leaf ( ){ }nivT iqi ,...,2,1, == \u03c9 constrained to be reached through the node N:\n( ) ( ) ( )NhNgNl *** += (109)\n( ) ( )\u2211 =\n= p\ni\nqi i vKNg\n1 * ,\u03c9 (110)\n( ) ( ) ( )       += \u2211 += n pi qi t TdvKminNh i 1 * ,\u03c9 (111)\nwhere t denotes a feasible path from N to T, and ( )Td is the deleting function, which\ncomputes the cost of deleting the FDG vertices that have not been matched in a leaf,\n( ) ( )\u2211 \u2208\u2200 \u03a6\u2217= \u03c9\u03c9 \u03c9 M jf j v vCKTd ,1\n(112)\nNote that the arcs ij\u03b5 in which one of the extreme vertices is not matched, \u03c9\u03c9 Mi \u2208 or\n\u03c9\u03c9 Mj \u2208 , are not considered in the deleting function, since the cost of deleting these\narcs is always zero.\n- 105 -\nThe global evaluation function is then defined in a leaf T as the cost ( )Tg\u2217 of an\noptimal path from the root to the leaf plus the cost of deleting the unmatched graph elements ( )Td ,\n( ) ( ) ( )TdTgTl += **\n(113)\nMoreover, the global evaluation function ( )Nl\u2217 is unknown in an inner node N, since\n( )Nh\u2217 is also unknown, and can only be approximated by a consistent lower-bounded\nestimate. For that purpose, let ( )jivK \u03c9,' be the cost of adding a pair of vertices to N, where\nvi Mv \u2208 and \u03c9\u03c9 Mj \u2208 , defined as\n( ) ( ) ( ) ( )( )\u2211 =\n+\u2217+\u2217= p\ns\njqsiejqisejifji ssv eCeCKvCKvK 1 21 ,,,,' \u03b5\u03b5\u03c9\u03c9\n(114)\nThen, for each unmatched vertex vi Mv \u2208 , a corresponding vertex \u03c9\u03c9 Mj \u2208 can be associated so that the cost ( )jivK \u03c9,' is minimised. Next, from the sum of the minimal\n'K for all the unmatched vertices, a consistent lower bounded estimate ( )Nh of ( )Nh\u2217\nis yielded,\n( ) ( ){ }\u2211 += \u2208\u2200 =\nn\npi\nji M vKminNh j1 ,' \u03c9 \u03c9\u03c9\n(115)\nFinally, the heuristic function ( )Nl that estimates ( )Nl\u2217 in a node N is given by\n( ) ( ) ( )NhNgNl += *\n(116)\nNote that, in a leaf T, ( ) 0=Th , and therefore, ( ) ( )TlTl *\u2264 . It is also interesting to\nobserve that the function ( )Nh does not include a term for estimating the value of the\n- 106 -\ndeleting function ( )Td , since it is hard to give a consistent lower bounded estimate of it\n(other than zero).\nWe move on to study the satisfaction of the second-order restrictions 3R and 4R by a\nlabelling function. When the algorithm arrives at any leaf T, if \u03c9\u03c9 Ni \u2208 then it is sure\nthat i\u03c9 has been matched to a non-null AG vertex with a certain attribute value \u03a6\u2260ia ;\nhowever, if \u03c9\u03c9 Mi \u2208 then it is considered to be matched to a null AG vertex \u03a6v (with\n\u03a6=\u03a6a ). After these considerations, the labelling f does not belong to 3F (it does not\nsatisfy 3R , that is, it does not satisfy equation (64)) if the following rule is fulfilled at\nthe corresponding leaf fT :\n( )( ) ( )( ) ( )( )\n3\n1,\n1,\n1,\n:, Ff\nEMM\nOMN\nANN\njiwjwi\njiwjwi\njiwjwi\nji \u2209\u21d2\n  \n \n\n \n \n\n=\u2227\u2208\u2227\u2208\n\u2228=\u2227\u2208\u2227\u2208\n\u2228=\u2227\u2208\u2227\u2208\n\u03a3\u2208\u2200\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\n\u03c9\n\u03c9\n\u03c9\n(117)\nLikewise, the labelling f does not belong to 4F (it does not satisfy 4R , that is, it does not satisfy equation (70)) if the following rule is fulfilled at fT :\n( )( ) ( )( ) ( )( ) 4 1,'' 1,' 1, :, Ff Eee Oee Aee\npqijeecdeeab\npqijeecdeab\npqijecdeab\npqij \u2209\u21d2\n  \n \n\n \n \n\n=\u2227\u03a3\u2212\u03a3\u2208\u2227\u03a3\u2212\u03a3\u2208\n\u2228=\u2227\u03a3\u2212\u03a3\u2208\u2227\u03a3\u2208\n\u2228=\u2227\u03a3\u2208\u2227\u03a3\u2208\n\u03a3\u2208\u2200\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\n\u03b5\n\u03b5\n\u03b5\n(118)\nwhere ( ) ijabe ef \u03b5= , ( ) pqcde ef \u03b5= , and ee \u03a3\u2212\u03a3' is the set of null arcs in the extended AG.\nIf \u03c9\u03c9 N\u2208 in a tree node then \u03c9\u03c9 N\u2208 in a leaf of the same path but, if \u03c9\u03c9 M\u2208 in a tree\nnode, then it is not possible to know if \u03c9\u03c9 M\u2208 or \u03c9\u03c9 N\u2208 in a leaf of the same path.\nFor this reason only the conditions that involve vertices that belong to \u03c9N can be evaluated in the tree nodes while the other conditions have to be evaluated in the leaves. Hence, some antagonism constraints can be evaluated in the inner nodes and therefore\n- 107 -\nmay be useful for pruning the search tree. The occurrence and existence constraints can only be evaluated in the leaves, and therefore are not helpful for pruning purposes. Therefore, at any inner node N, the following decision is taken about the satisfaction of the second-order constraints on the vertices by the partially defined function f,\n( ) otherwiseFf ANNifFf jiwjwi\n3\n3 1,\n\u2208\n=\u2227\u2208\u2227\u2208\u2209 \u03c9\u03c9\u03c9\u03c9 \u03c9\n(119)\nFor the second-order restrictions on the arcs, however, the decision rule is\n( ) otherwiseFf Aee\nNNNN ifFf\npqijecdeab\nwqwpwjwi\n4\n4 1,\n\u2208\n  \n\n  \n\n=\u2227\u03a3\u2208\u2227\u03a3\u2208\n\u2227\u2208\u2227\u2208\u2227\u2208\u2227\u2208 \u2209\n\u03b5\u03b5\n\u03c9\u03c9\u03c9\u03c9\n\u03b5\n(120)\nwhere ( ) ijabe ef \u03b5= and ( ) pqcde ef \u03b5= are already included in the partially defined\nfunction f when the four vertices qpji \u03c9\u03c9\u03c9\u03c9 ,,, belong to wN .\nFinally, at any leaf T reached, the conditions (66), (68), (72), (74) are checked to\nestablish whether the complete function f satisfies both 3R and 4R or not. It is only at that moment that the occurrence and existence constraints are verified.\nAlgorithm 1 computes the distance measure fd and the corresponding optimal labelling\nHfopt \u2208 between a given AG and a given FDG. It only invokes the recursive procedure\nTreeSearch at the root node.\nAlgorithm 1: Distance-measure-between-AG-and-FDG Inputs: G and F : A given AG and a given FDG. Outputs: The distance measure fd and the optimal labelling Hfopt \u2208 . Begin\nBigNumber:=fd ; \u2205=:optf ;\n( )optf fdvFG ,,,0,,,TreeSearch 1\u2205 ; End-algorithm\n- 108 -\nProcedure ( )optfi fdvgfFG ,,*,,,,TreeSearch Input parameters: G and F : An AG and an FDG;\nf : Optimal path (or labelling) from the root to the current node; *g : Minimum value from the root to the current node;\niv : Current AG vertex to be matched;\nInput/Output parameters: The best measure fd and the corresponding labelling Hfopt \u2208 obtained so far from the leaves already visited during the tree search. Begin For each vertex j\u03c9 of the FDG F not used yet in f or \u03a6\u03c9 do\n( ) jivfFGK: \u03c9,,,,function-evaluation-Branch=\n( ){ }( )jivffFGh: \u03c9=\u222a= ,,function-estimate-Bound ; hKgl ++= *: ; {Heuristic function of *l } If ( ){ } Hvff ji \u2208=\u222a \u03c9 and fdl < then If ni < then {there is another vertex of the AG still not matched}\n( ){ }( )optfiji fdvKgvffFG ,,,*,,,TreeSearch 1++=\u222a \u03c9 ; Else {all the vertices of the AG have been matched}\n( ){ }( )jivffFGd: \u03c9=\u222a= ,,function-Deleting ;\nIf dKgd f ++> * then dKgd f ++= *: ; ( ){ }jiopt vfff \u03c9=\u222a=: ; End-if\nEnd-if\nEnd-if\nEnd-for End-procedure\n6.3. Computation of the distance relaxing second-order constraints\nThe FDG second-order functions affect the value of this distance measure, not by constraining the labelling but by increasing its cost. For this reason, three functions used in the branch-and-bound approach must be redefined: the branch evaluation function,\n( )NK R ; the cost of adding a pair of vertices in a tree node, ( )NK R' ; and the cost of\n- 109 -\ndeleting the unmatched FDG vertices at a leaf, ( )Td R . When they are redefined, the set\nof valid labellings is 521 FFFH \u2229\u2229= or 21 FFH \u2229= depending on whether the planar graph condition is imposed or not.\nThe branch evaluation function is redefined by adding two more terms, 3C and 4C , which refer to the second-order costs on the vertices and the arcs, respectively,\n( ) ( ) ( ) ( ) pppp qpqpqpqp R vCvCvKvK \u03c9\u03c9\u03c9\u03c9 ,,,, 43 ++= (121)\nThe term 3C takes into account the possible second-order relations between the FDG\nvertex pq w mapped in the tree node N and all the FDG vertices mapped in the tree\nnodes from the root to N ,\n( ) ( ) ( ) ( ) ( )\u2211 \u2212 =  \n\n\n  \n\n+\n++ = 1\n1 55\n73\n3 ,,,*,,,*\n,,,*,,,* , p\ns qqpsOqqspO\nqqspEqqspA\nqp\npssp\nspsp\np vvCKvvCK\nvvCKvvCK vC\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9 \u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n(122)\nConsidering that \u03a6\u2260pa and 11: \u2212\u2264\u2264\u03a6\u2260 psas , since the AG has not been\nextended, then the costs associated with the occurrence relations (equation 99) and existence relations (equation 101) are always zero, and therefore,\n( ) ( )\u2211 \u2212\n=\n= 1\n1 33 ,,,*,\np\ns\nqqspAqp spp vvCKvC \u03c9\u03c9\u03c9 \u03c9\n(123)\nSimilarly, the term 4C takes into account the possible second-order relations between those FDG arcs that connect pq w and mapped vertices in the tree nodes from the root to\nN and those FDG arcs in which both extremes have also been mapped in the tree nodes\nfrom the root to N ,\n- 110 -\n( )\n( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) \u2211 \u2212 =      \n\n\n      \n\n+\n++\n++\n++\n= 1\n1,,\n66\n66\n88\n44\n4\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n, p\nrts\nqqqqsptrOqqqqpstrO\nqqqqrtspOqqqqtrpsO\nqqqqtrspEqqqqtrpsE\nqqqqtrspAqqqqtrpsA\nqp\npsrtsprt\ntrpsrtsp\nrtpsrtsp\nrtpsrtsp\np\neeCKeeCK\neeCKeeCK\neeCKeeCK\neeCKeeCK\nvC\n\u03b5\u03b5\u03b5\u03b5\n\u03b5\u03b5\u03b5\u03b5\n\u03b5\u03b5\u03b5\u03b5\n\u03b5\u03b5\u03b5\u03b5\n\u03c9\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n\u03b5\u03b5\n(124)\nwhich can be simplified by eliminating the null terms (equations 100 and 102) as\n( ) ( ) ( ) rtpsrtspp qqqqtrspA\np\nrts\nqqqqtrpsAqp eeCeeCKvC \u03b5\u03b5\u03b5\u03b5\u03c9 \u03b5\u03b5 ,,,,,,*, 1\n1,, 44 += \u2211\n\u2212\n= (125)\nThe cost of adding a pair of vertices to N is redefined by adding two more terms, 3'C\nand 4'C ,\n( ) ( ) ( ) ( ) jijijiji R vCvCvKvK \u03c9\u03c9\u03c9\u03c9 ,',',',' 43 ++= (126)\nThe term involving the second-order costs on the vertices, 3'C , is defined as\n( ) ( ) ( ) ( ) ( )\u2211=  \n\n\n  \n\n+\n++ = p\ns jqisOqjsiO\nqjsiEqjsiA\nji\nss\nss\nvvCKvvCK\nvvCKvvCK vC\n1 55\n73\n3 ,,,*,,,*\n,,,*,,,* ,'\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9 \u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n(127)\nand, considering that the AG vertices involved (non-null elements) have been matched to null or non-null FDG vertices and equations 99 and 101, this can be simplified as\n( ) ( )\u2211 =\n= p\ns\nqjsiAji s vvCKvC 1 33 ,,,*,' \u03c9\u03c9\u03c9 \u03c9\n(128)\nSimilarly, the term involving the second-order costs on the arcs, 4'C , adds the costs between arcs whose external vertices have already been matched. After simplification, this term is given by\n( ) ( ) ( ) rtsrts qqjqtrsiA\np\nrts qqjqtrisAji eeCeeCKvC \u03b5\u03b5\u03b5\u03b5\u03c9 \u03b5\u03b5 ,,,,,,*,' 1,, 44 += \u2211 = (129)\n- 111 -\nWith RK ' defined, the consistent lower bounded estimate is computed as\n( ) ( ){ }\u2211 += \u2208\u2200 =\nn\npi\nji\nR\nM R vKminNh j1 ,' \u03c9 \u03c9\u03c9\n(130)\nFinally, the second order costs of the relations between the unmatched elements in a\nleaf (that is to say, being \u03c9\u03c9 Mi \u2208 in T), have to be added to the cost of deleting the\nunmatched elements of the FDG. Recall that if \u03c9\u03c9 Mi \u2208 in a leaf then it is considered\nthat it is matched to a null AG vertex \u03a6v (with \u03a6=\u03a6a ).\n( ) ( ) ( ) ( )TCTCTdTd R 43 '''' ++= (131)\nwhere ( )TC 3'' is the cost on the vertices defined as\n( )\n( ) ( ) ( ) ( )\n( ) ( ) ( ) ( )\n( ) ( ) ( ) ( )        \n       \n\n  \n\n  \n\n+\n++\n+   \n\n  \n\n+\n++\n+   \n\n  \n\n+\n++\n=\n\u2211\n\u2211\n\u2211\n< \u2208\u2200\n\u2208\u2200 \u03a6\u03a6\n\u03a6\u03a6\n<\n\u2208\u2200 \u2208\u2200 \u03a6\u03a6\n\u03a6\u03a6\n< \u2208\u2200 \u03a6\u03a6\u03a6\u03a6\n\u03a6\u03a6\u03a6\u03a6\njqi\nN\nM qjiOjqiO\njqiEjqiA\nqji\nN M iqjOqijO\nqijEqijA\nji\nM ijOjiO\njiEjiA\niq\nj ii\nii\njq\ni jj\njj\nji\nvvCKvvCK\nvvCKvvCK\nvvCKvvCK\nvvCKvvCK\nvvCKvvCK\nvvCKvvCK\nTC\n\u03c9\u03c9 \u03c9\u03c9\n\u03c9\u03c9 \u03c9\u03c9\n\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n,,,*,,,*\n''\n55\n73\n55\n73\n, 55\n73\n3\n(132)\nThis can be reduced to the following equation by considering equations (97), (99) and (101),\n- 112 -\n( )\n( ) ( )\n( )    \n   \n\n+\n+\n=\n\u2211\n\u2211\u2211\n< \u2208\u2200\n\u2208\u2200\n\u03a6\n<\n\u2208\u2200 \u2208\u2200\n\u03a6\n< \u2208\u2200\n\u03a6\u03a6\njqi\nN\nM\njqiO\nqji\nN M\niqjO\nji\nM\njiE\niq\nj\ni\njq\ni\nj\nji\nvvCK\nvvCKvvCK\nTC\n\u03c9\u03c9 \u03c9\u03c9\n\u03c9\u03c9 \u03c9\u03c9\u03c9\u03c9\u03c9\n\u03c9\u03c9\n\u03c9\u03c9\u03c9\u03c9\n\u03c9\n\u03c9\u03c9\n,,,*\n,,,*,,,*\n''\n5\n5 , 7\n3\n(133)\nThe cost on the arcs, ( )TC 4'' , has to consider all the combinations between matched and non-matched vertices that the arcs connect. After a simplification step, in which equations (98), (100) and (102) are considered, the cost is given by\n( )\n( ) ( )\n( )    \n   \n\n+\n+\n=\n\u2211\n\u2211\u2211\n<\u2227=\u2228<\n\u2208\u2200 \u2208\u2200\n\u03a6\n<\u2227=\u2228< \u2208\u2200\n\u2208\u2200\n\u03a6\n<\u2227=\u2228<\n\u2208       \u2200\n\u03a6\u03a6\n)( , ,\n6\n)( , ,\n6\n)( , ,\n8\n4\n,,,*\n,,,*,,,*\n''\ntjkiki\nN M\nktqqijO\ntjkiki\nN\nM\nijqqktO\ntjkiki\nM\nktijE\njqiq\ntk\nji\ntqkq\nji\ntk\ntk\nji\neeCK\neeCKeeCK\nTC\n\u03c9\u03c9\u03c9 \u03c9\u03c9\u03c9\n\u03c9\u03c9\u03c9 \u03c9\u03c9\u03c9\u03c9 \u03c9\u03c9 \u03c9\u03c9\n\u03b5\u03b5\n\u03b5\u03b5\u03b5\u03b5\n\u03b5\n\u03b5\u03b5\n(134)\nAlgorithm 1 can be used to compute the distance measure Rfd and the corresponding\noptimal labelling Hf Ropt \u2208 . It does so by modifying the three functions Branch-\nevaluation-function, Bound-estimate-function and Deleting-function in the procedure\nTreeSearch and removing the verification of 3Ff \u2208 and 4Ff \u2208 when Hf \u2208 is evaluated. The above three functions have to be modified to compute RK , ( )NhR , and\n( )Td R , respectively.\n6.4. Complexity of distance computation\nTaking into account the set of all possible labelling combinations of the vertices within\nthe set of allowable mappings 21 FFH \u2229= , and regarding the different permutations of the null vertices as equivalent labellings, the number of possible matches between the extended graphs increases to\n- 113 -\n)!(\n!\n!)!(\n!\ninm\nm\niin\nn V\ni\nn m\nin +\u2212\u2212 =      \u2212\n(135)\nwhere m and n are the number of vertices in the original graphs and i is the number of AG vertices that are matched to the null FDG vertex. The extended graphs are assumed\nto have nm + vertices.       i n denotes the combinations of the in \u2212 matched vertices and\nm\ninV \u2212 denotes the combinations of the i vertices matched to the null vertex, that is, the variations of m elements taken in groups of n-i elements (see figure 16).\nIf we first consider the case mn \u2265 , the minimum number of vertices matched to the null one is mn \u2212 and the maximum is n , so, the number of labellings is\nmnifV i\nn Q min\nn\nmni mn \u2265      = \u2212 \u2212= \u2211, (136)\nand considering equation (135),\nmnif inmiin\nmn Q\nn\nmni\nmn \u2265 +\u2212\u2212 = \u2211 \u2212= )!(!)!(\n!! ,\n(137)\nwhich can be rewritten by,\n- 114 -\nmnif kkmmnk\nmnQ m\nk\nmn \u2265 \u2212\u2212+ = \u2211 =0 , !!)()!(\n1 !!\n(138)\nwhere mnik +\u2212= . If the case mn < is now considered, the minimum number of vertices matched to the null one is 0 and the maximum is n , so, the number of labellings is\nmnifV k\nn Q mkn\nn\nk mn <      = \u2212 = \u2211 0 ,\n(139)\nConsidering equation (135) and reorganising the above one, the final expression is,\nmnif kknnmk\nmnQ n\nk\nmn < \u2212\u2212+ = \u2211 =0 , !!)()!(\n1 !!\n(140)\nTherefore, if an exhaustive search algorithm such as backtracking were used to compute the distance by evaluating the cost of each possible match and finding the minimum, the\nnumber of possible labellings would be mnQ , . Figure 17 shows a possible search tree.\nNote that the number of siblings is reduced when the father is a vertex from the graph but it is kept unmodified if the father is the null vertex and also, that the number of labellings is the number of leaves.\n- 115 -\nNevertheless, the time complexity of the computation of the distance does not depend on the number of labellings but on the number of nodes in the tree search. Therefore, it is defined by\nmnvmn AOT ,, =\n(141)\nwhere vO is the time complexity of processing one node and mnA , is the number of\nnodes of the tree search, which is computed by,\n\u2211 =\n= n\ni mimn QA 0 ,,\n(142)\nBy incorporating additional constraints, such as the planar graph constraint 5R and the\nsecond-order constraints 3R and 4R (i.e. 54321 FFFFFH \u2229\u2229\u2229\u2229= ), the search tree can be somewhat pruned, although the combinatorial complexity remains. In real applications, the best way of pruning the search tree and still calculating the distance measure and the optimal labelling is by means of some sort of branch and bound algorithm (Wong, You and Chan, 1990) such as the one presented in Section 6.2. A good heuristic function in the branch and bound algorithm may prune the search tree quite considerably and speed up the process of finding the optimal solution impressively (Larrosa et al., 1999). However, even in this case, the worst-case complexity remains non-polynomial. Efficient algorithms that compute sub-optimal approximations of the given distance measure are presented in the next chapter.\n6.5. Experimental results\nIn order to examine the performance of the new matching algorithm in practice, we carried out a number of experiments with randomly generated graphs. The random graph generator was the same as the one explained in section 4.6 with the following parameter values:\n- 116 -\nThe number of FDGs was set to 10, 10=nFDG , and the number of AGs in the test set to 100, 100=NT . The number of AGs in the reference set for each FDG, NR , was set to 1, 3, 6, 9, 12, 15 and 18. We were interested in measuring the ability of the branch and bound algorithm to prune the decision tree while applying different cost values to the antagonisms on the vertices. The reason why we did not test occurrence and existence relations is because they are not useful for pruning the search tree (Section 6.2). Hence, the weights on the costs\nwere 121 == KK , 087654 ===== KKKKK and 3K varied for different tests. In the\nfirst tests, no antagonisms were considered, 03 =K ; in the second tests, the distance\nrelaxing second order constraints were applied with 13 =K ; and in the last tests, the\ndistance with constraints were applied with numberBigK _3 = . Figure 18 shows the average of the number of vertices and antagonisms of the synthesised FDGs throughout the number of AGs. These results have been extracted from figures 11 and 12.\nFigure 19 shows the ratio of correctness. We observe that the correctness increases when the number of AGs used to synthesise the FDGs also increases. The best results appear when the antagonisms are considered with a cost. When there are few\n- 117 -\nantagonisms (figure 18.b), the distance that considers the antagonisms as strict relations obtains better results than without considering the antagonisms. Nevertheless, when the number of antagonisms increases, the strict second-order relations discards too many labellings and so it is better not to consider them. Moreover, the ratio is always better when the antagonisms are applied with a cost\n13 =K than when they are not applied ( 03 =K ) or strictly applied\n( numberBigK _3 = ). In the extreme values of NR (low or high) there are few antagonisms (figure 18) and so there is less difference between using the antagonisms or not but, in the values of NR that the maximum number of antagonisms is obtained, the difference on the correctness applying or not the antagonisms is also maximum.\nFigure 20 shows the run time of the above experiments. The antagonism relations are useful to prune the search tree and decrease the run time. The maximum difference between the case in which the antagonisms are not used, 03 =K , and the other two appear when the maximum number of antagonisms is obtained ( 12=NR ). The fastest tests are the ones in which numberBigK _3 = . This is because the branch and bound prunes more paths in the tree search. Nevertheless, since the correctness is lower, some of these paths were the optimal labellings.\n- 118 -\n- 119 -"}, {"heading": "7. Efficient algorithms for computing sub-optimal distances", "text": "We propose a method which further reduces the search space of our branch and bound algorithm by initially discarding mappings between vertices. The match of a pair of vertices is discarded if the obtained degree of similarity between their related sub-units is lower than a threshold. Thus, the graphs are broken down into manageable sub-units that overlap, so that two adjacent sub-units contain information about each other through the mutual graph elements they contain. A classical probabilistic relaxation scheme is presented in section 7.1. Then, the above commented sub-units are presented and defined in section 7.2 and 7.3, respectively. Moreover, a distance measure between sub-units and a matching algorithm to compute this distance are proposed in sections 7.4 and 7.5. We propose two techniques to compute a sub-optimal distance between AGs and FDGs. In the first, section 7.6, a noniterative method is proposed to discard non-probable matches. In the second, section 7.7, two relaxation schemes are presented. The difference between them is the initialisation of the probabilities. Section 7.8 presents some results with random graphs.\n7.1. Probabilistic relaxation schemes\nRelaxation schemes are optimisation techniques in which the variables of the scheme are iteratively updated in order to approach a stationary point of the update equations. They can be used to optimise a matching criterion which has a maximum at the stationary point. A classic probabilistic relaxation scheme is due to Rosenfeld, Hummel and Zucker (Rosenfeld et al., 1976), and was conceived as an object labelling algorithm. Since it\u2019s conception, the approach has been widely used for image processing tasks including graph matching.\nWe will denote the probability that the AG vertex iv matches to the FDG vertex a\u03c9 at the iteration t as ( )aP ti . The Rosenfeld et al. Scheme specifies that the probabilities at iteration 1+t should be given by\n- 120 -\n( ) ( ) ( )( )\n( ) ( )( )\u2211 \u03a3\u2208\n+\n+\n+ =\n\u03c9\u03c9 '\n'1'\n11\na\naQaP\naQaP aP\nt i t i\nt i t it\ni\n(143)\nwhere ( )aQ ti is called the support function. The numerator in the update formula can be viewed as the product of two evidential factors; the probability ( )aP ti just described which represents the local information and the support function ( )aQ ti which represents\nthe probability of the surrounding matches given that iv matches a\u03c9 . The denominator\nsimply ensures the normalisation of the probabilities, i.e. that ( ) 1=\u2211 \u03a3\u2208 \u03c9\u03c9a aPti . This step is necessary since the support functions are not true probabilities. Rosenfeld et al. define the support function as\n( ) ( ) ( )\u2211 \u2211 \u2208 \u2208 = )( )( ,, , ij abvNv N\nt\njjiji\nt\ni bPbardaQ \u03c9\u03c9 (144)\nwhere ( )bar ji ,, is called the compatibility function and ( )ivN and ( )aN \u03c9 are the set of\nvertices which are connected to iv and a\u03c9 , respectively. The coefficients jid , are used to make ( )aQ ti be in the range [ ]1,1\u2212 , provided that 1 )( , =\u2211 \u2208 ij vNv jid .\nIn the original form, the ( )bar ji ,, are purely arbitrary, application dependent and no method for their specification is offered. The initial probabilities, ( )aPi 0 , are also application dependent.\n7.2. Splitting the graphs into sub-units\nThe larger the topological structure of the sub-units is, the more effective the scheme is at discarding unacceptable labellings. In these terms, small structural units perform badly and the contextual information of the matching process is impoverished. For instance, in the relaxation methods described in (Rosenfeld et al., 1976; Feng et al., 1994; O'leary and S. Peleg , 1983; Christmas et al., 1995), the sub-units are composed of a pair of vertices and their connecting arcs, and the support function does not\n- 121 -\nconsider that the labelling has to be bijective (constraint 1R ), or that the relative order between arcs has to be preserved (constraint 5R ). If, on the other hand, the structural sub-units are too large, then those constraints can be fulfilled but the computational requirements of the matching process become excessively cumbersome; the limitation stems from the need to explore the space of mappings between these sub-units. As a compromise between representational power and computational requirements, Wilson and Hancock proposed splitting the graphs into sub-units which are structured by a central vertex and all the adjacent vertices are connected to it by an arc (Wilson and Hancock, 1997). For convenience we refer to these sub-units as expanded vertices (Figure 21). Their probabilistic approach has the main drawback that the semantic information is used only in the initialisation step while the support function is only based on symbolic information. We present here three different approaches. The first approach takes the distance between expanded vertices with semantic knowledge as an informative heuristic for selecting a reduced set of configurations prior to the computation of an approximation to the distance measure through the branch and bound algorithm. In order to provide a good selection (which hopefully includes the optimal labelling) and reduce the intrinsically used heuristics, the distance measure between expanded vertices is taken to be the same as the one defined between the whole graphs. The main drawback of this approach is that the selection of a vertex is based only on local information. To solve this problem, two other approaches are presented which are based on the Rosenfeld relaxation method (Rosenfeld et al.). The advantage of this relaxation method is that the global information flows through the probabilities in each iteration of the algorithm. Nevertheless, the structural sub-units are too small to keep the structural knowledge. The difference between both approaches is how they initialise the probabilities. In the first, it is used the distance between expanded vertices, thus, the initial probabilities are located using some structural information. In the second, it is only used the distance between vertices.\n- 122 -\n7.3. Expanded Vertices\nAn AG expanded vertex (Figure 21.a) or an FDG expanded vertex (Figure 21.b) are an AG or an FDG, respectively, with a specific structure formed by a central vertex and all the adjacent vertices, called external vertices, which are connected to it by an outgoing arc. More formally, an AG expanded vertex iEV over ( )ev \u2206\u2206 , with an underlying graph structure ( )evH \u03a3\u03a3= , is defined as an AG ( )AVEVi ,= where the vertices belong to a finite set { }niv vvv ,...,...,1=\u03a3 that contains a given vertex iv and the arcs belong to a finite set { }niiiiiie eeee ,1,1,1, ,...,,..., +\u2212=\u03a3 formed by all the arcs departing from iv in the AG. The\nvertex iv is called the central vertex and the vertices njjiv j \u2264\u2264\u2260 1,: are called the\nexternal vertices. An AG G of order k over the domain ( )ev \u2206\u2206 , with structure ( )evH \u03a3\u03a3= , can be represented as a set of expanded vertices { }iEV , such that U ki iEVG ..1= = , where iv is the central vertex of vii vEV \u03a3\u2208\u2200, . It should be noted that when the whole underlying structure H of the AG is described by a set of expanded vertices, each arc appears just once (each arc belongs to just one expanded vertex) but vertices are possibly included more than once (each vertex is a central vertex of an expanded vertex and also an external vertex of as many expanded vertices as input arcs it receives)."}, {"heading": "An FDG expanded vertex", "text": "iEW over ( )ev \u2206\u2206 , with an underlying graph structure\n( )\u03b5\u03c9 \u03a3\u03a3= ,H is defined as an FDG ( )RPBWEWi ,,,= with a finite set of vertices { }mi \u03c9\u03c9\u03c9\u03c9 ,...,...,1=\u03a3 that contains a given vertex i\u03c9 and a finite set of arcs { }niiiiii ,1,1,1, ,...,,..., \u03b5\u03b5\u03b5\u03b5\u03b5 +\u2212=\u03a3 formed by all the arcs departing from i\u03c9 in the FDG. Again,\nthe vertex i\u03c9 is called the central vertex and the vertices mjjij \u2264\u2264\u2260 1,:\u03c9 are called the\nexternal vertices.\n- 123 -\nAn FDG F can be partially represented in distributed form as the set of its expanded vertices { }iEW , where i\u03c9 is the central vertex of \u03c9\u03c9 \u03a3\u2208\u2200 iiEW , . We note that the whole underlying structure of an FDG is included in this new representation; the arcs appear once but vertices may be included more than once. However, the antagonism, occurrence and existence relations of the original FDG cannot be represented entirely: those that involve two graph elements belonging to the same expanded vertex are included, but this is not possible when the related graph elements belong to different expanded vertices.\n7.4. Distance measure between expanded vertices\nThe distance between an AG expanded vertex and an FDG expanded vertex is the same as the distance defined between an AG and an FDG. This is possible because expanded vertices can be seen as graphs with a specific structure. However, when both expanded vertices are non-null, the mapping f between graph elements of expanded vertices iEV and jEW is constrained to satisfy the obvious requirement ( ) jivf \u03c9= , i.e. the central vertices are mapped to one another. Bearing this in mind, and not including the second-order costs, the maximum distance maxd obtained between two non-null expanded vertices is\n- 124 -\n   <\u2212+ \u2265\u2212 = mnmn mnn dmax if1 if12\n(145)\nwhere n and m are the number of vertices of the AG expanded vertex and the FDG expanded vertex, respectively. If mn \u2265 then the maximum distance value is the cost of substituting 1\u2212m arcs and m vertices plus the cost of inserting mn \u2212 arcs and vertices. However, if mn < , the maximum value is the cost of substituting 1\u2212n arcs and n vertices plus the cost of deleting nm \u2212 AG vertices. The cost of deleting the AG arcs is zero when the external vertices have been deleted. This maximum value is used in section 7.6 to normalise the distances between vertices.\n7.5. A fast algorithm for computing the distance between expanded\nvertices\nAlgorithm 2 calculates the distance between non-null expanded vertices with a computational cost ( )mnO \u22c52 where n and m are the number of vertices of the AG and\nFDG expanded vertices, respectively. It is based on the idea that if the labelling function has to be structurally coherent and the order between arcs has to be maintained, then the external vertices and their arcs can be regarded as a cyclic string where each element is a pair (arc, external vertex). Thus, the distance between expanded vertices is computed as the cost of matching the central vertices plus the distance between both cyclic strings. Gregor and Thomason showed that the distance between two cyclic strings can be obtained as the minimum of the distances between one orientation of the first string and all possible orientations of the second one (Gregor and Thomason, 1996). In the case of an AG expanded vertex iEV , the string is defined as ( ) ( ){ })'()'()1()1( ,,...,, niniiii veveS = where { })'()1( ,..., nii vv is an ordered set of external vertices of\niEV , kjiikji vvee =\u21d4= )()( and n\u2019 is the number of external vertices, n\u2019=n-1. Similarly,\nthe string related to an FDG expanded vertex jEW is defined as ( ) ( ){ })'()'()1()1( ,,...,, mimiiijS \u03c9\u03b5\u03c9\u03b5= where { })'()1( ,..., mii \u03c9\u03c9 is an ordered set of external vertices\nof jEW , kjiikji \u03c9\u03c9\u03b5\u03b5 =\u21d4= )()( and m\u2019=m-1.\n- 125 -\nAlgorithm 2: Distance-between-expanded-vertices Inputs: iEV : AG expanded vertex.\njEW : FDG expanded vertex.\nOutput: The distance fd between iEV and jEW . Begin Let iS and jS be the cyclic strings of iEV and jEW , respectively. \u221e=:fd ( ) jif vCKD v \u03c9,:)0,0( 1 \u2217= . { 0:)0,0( =D in the Levenshtein algorithm} For s:=0 to n\u2019-1 do {orientation of the AG expanded vertex}\nFor l:=1 to n\u2019 do\n( ) ( )\u03a6+\u03a6+ \u2217+\u2217+\u2212= \u03b5\u03c9 ,,)0,1(:)0,( )(,2)(1 sliifslif eCKvCKlDlD ev\nend-for For k:=1 to m\u2019 do\n( ) ( ))(,2)(1 ,,)1,0(:),0( kjjfkjf eCKvCKkDkD ev \u03b5\u03c9 \u03a6\u03a6 \u2217+\u2217+\u2212= end-for For l:=1 to n\u2019 do\nFor k:=1 to m\u2019 do\n( ) ( ))(,)(,2)()(11 ,,)1,1(: kjjsliifkjslif eCKvCKklDm ev \u03b5\u03c9 ++ \u2217+\u2217+\u2212\u2212= {Subs. in Levenshtein alg.} ( ) ( )\u03a6+\u03a6+ \u2217+\u2217+\u2212= \u03b5\u03c9 ,,),1(: )(,2)(12 sliifslif eCKvCKklDm ev {Insertion in Levenshtein alg.} ( ) ( ))(,2)(13 ,,)1,(: kjjfkjf eCKvCKklDm ev \u03b5\u03c9 \u03a6\u03a6 \u2217+\u2217+\u2212= {Deletion in Levenshtein alg.} ( )321 ,,min:),( mmmklD =\nend-for\nend-for if fdmnD <)','( then\n)','(: mnDd f =\nend-if\nend-for end-algorithm\n- 126 -\nFor each possible orientation of one of the expanded vertices (subscript s in the algorithm), the distance between the strings iS and jS is computed by a method\nreminiscent of the Levenshtein algorithm (Levenshtein, 1966; Tanaka and Kasai, 1976; Bunke and Sanfeliu (Eds.), 1990), with the difference that the cost of inserting or deleting string elements is obtained by substituting these elements with null vertices and arcs. Moreover, since the minimal expanded vertex is formed by only one central vertex, the cost of substituting the central vertices is initially applied independently of the string alignment cost caused by arcs and external vertices. An algorithm to search the distance between two cyclic strings is proposed in (Maes, 1990) with a computational cost ( ))log(mmnO \u22c5\u22c5 . Nevertheless we decided to use the Levenshtein\nalgorithm applied n times for its simplicity and considering that the average number of output arcs for each vertex is not usually very big. The Maes algorithm is going to be applied in a future work.\nR\nf ,\n^ , and\nalso, the best labelling reached Hf \u2208^ . Obviously, ( ) ( )FGdFGd Rf R f ,, ^ \u2265 , since some\nlabelling functions, which belong to H, are discarded due to the constraints derived from the distances between expanded vertices. The scheme of the algorithm consists of three main modules. The first one computes all the distances between expanded vertices using the distance measure without second order costs, ( )jif EWEVd , . The thresholding\nmodule decides which vertex matches are discarded using an externally imposed threshold \u03c4 , [ ]1,0\u2208\u03c4 . If the normalised distance between expanded vertices is higher\nthan \u03c4 the mapping is considered unlikely and it is forbidden.\n- 127 -\n( )\n( )\n( )\n    \n   \n\n<\u2227> \u2212+\n\u2265\u2227> \u2212\n=\notherwise\n1\n, if\n12\n, if\n,\nFalse\nmn mn\nEWEVd True\nmn n\nEWEVd True\nvForbid ji ji\njif\nji\ni\njif\nji \u03c4\n\u03c4\n\u03c9\n(146)\nwhere in and jm represent the number of vertices of the expanded vertices iEV and\njEW , respectively. The last module computes the sub-optimal distance ( )FGd Rf , ^ using the branch and\nbound algorithm presented in chapter 6 but only on the set of vertex mappings allowed by the thresholding module, the ones for which ( ) FalsevForbid FjGi =\u03c9, .\nNote that, given a set of distances between expanded vertices, the lower \u03c4 is, the more restrictions are imposed. Therefore, the branch and bound algorithm has to explore fewer possible morphisms and therefore, the measure is more approximated and the process is faster. If 1=\u03c4 , the combinatorial algorithm explores the whole set of possible morphisms and the output is exactly ( )FGd Rf , . However, if 0=\u03c4 , only the matches of\ntotally isomorphic subunits are not discarded, and the combinatorial algorithm explores few (or no) morphisms, in which case ( )FGd Rf , ^ is \u201cvery sub-optimal\u201d.\n- 128 -\n7.7. Probabilistic relaxation methods to compute the distance\nbetween AGs and FDGs\nWe apply the Rosenfeld et al. approach to compute two sub-optimal distances between AGs and FDGs in this section. The efficient algorithms are composed by three main modules similar as the one proposed in section 7.6 (figure 22). The first module computes the probability matrix and the second module decides which mappings are accepted depending on these probabilities. The third module is similar as the one in section 7.6. The compatibility function is defined as follows,\n( ) ( ) ( ) ( )( )abijefbjvfaivf eCvCvCji ebar \u03b5\u03c9\u03c9 ,,, , , ++\u2212 =\n(147)\nIn the first relaxed algorithm, the initial probabilities are calculated depending on the distance between vertices,\n( ) ( )\n( ) \u2211\n\u03a3\u2208\n\u2212\n\u2212\n=\n\u03c9\u03c9\n\u03c9\n\u03c9\n'\n',\n, 0\na\naivf\naivf\nvC\nvC\ni e\ne aP\n(148)\nIn the second relaxed algorithm, they are defined depending on the distance between expanded vertices,\n( ) ( )\n( ) \u2211\n\u03a3\u2208\n\u2212\n\u2212\n=\n\u03c9\u03c9 '\n',\n, 0\na\naif\naif\nEWEVd\nEWEVd\ni e\ne aP\n(149)\nThe aim of the second option is to establish the initial probabilities nearer to the stationary point than the first option although the computational cost is higher. This is achieved by taking into account the plannar graph restriction, 5R .\n7.8. Experimental results\nIn order to examine the performance of the efficient matching algorithms in practice, we carried out a number of experiments with randomly generated graphs. The parameter values of the random graph generator were:\n- 129 -\nSimilarly than the second experiments, the number of FDGs was set to 10 and synthesised in a supervised manner and the number of AGs in the test set to 100. The number of AGs in the reference set for each FDG to 1, 3, 6, 9, 12, 15 and 18. The aim of the experiments in this section is to compare the three proposed efficient algorithms. As in the experiments in section 6.5, the branch and bound module\ncomputed the distance with the following weights on the costs: 121 == KK , == 75 KK\n0864 === KKK . The weight on the vertex antagonism was 13 =K as it was the value\nin which the best results were obtained. Figures 23, 24 and 25 show the correctness and run time in the recognition process obtained by the three efficient algorithms. Figure 23 shows the results of the non-iterative algorithm. In the case 1=T , the optimal distance is obtained and the first module of the algorithm is not used. Figure 24 shows the results of the relaxed algorithm in which the probabilities were initialised by the distance between expanded vertices. Figure 25 shows the results of the relaxed algorithm in which the probabilities were initialised by the distance between vertices. In the case\n0=pT , the optimal distance is obtained and the first module of the algorithm is not\nused.\n- 130 -\nThe relaxation algorithm in which the probabilities are initialised by the distance between expanded vertices obtains better correctness and less run time than the algorithm in which the probabilities are initialised by the distance between vertices. It is because the initial probabilities are set closer to the stationary point and the time spent to compute the distance between the expanded vertices compensates the efficiency in pruning of the search tree. The run time is almost constant throughout the NR axis in the tests in which the probabilities are initialised with the distance between vertices but there is slight increase when the probabilities are initialised with the distance between vertices. This is not the case of the non-iterative algorithm in which the run time increases when the number of AGs increases.\n- 131 -"}, {"heading": "8. Clustering of AGs using FDGs", "text": "Given a set of AGs, which are initially supposed to belong to the same class, we do not, in general, have any way of synthesising an FDG that represents the ensemble unless we can first establish a common labelling of their vertices. However, given a set of isomorphisms applied to a common underlying structure, an FDG can be generated from the ensemble using the process FDG-synthesis-from-labelled-AGs presented in section 4.4. We want to choose the common labelling which will minimise the measures of dissimilarity between the given AGs and the resulting FDGs. This global optimisation problem does not lead to a computationally practical method for choosing the labelling, because there are too many possible orientations to consider, especially when the number and order of the AGs is high. Therefore, we propose two sub-optimal methods for synthesising FDGs from a set of unlabelled AGs. In one of them, the FDGs are updated by the AGs, which are sequentially introduced as in (Seong et al., 1993). The advantage of this method is that the learning and recognition processes can be interleaved, i.e. the recognition does not need to wait for all the input instances, but is available after each AG has been processed. The main drawback of this incremental approach is that different FDGs can be synthesised from a set of unlabelled AGs depending on the order of presentation of the AGs. To infer some unique FDGs, we propose a hierarchical method, which is carried out by successively merging pairs of FDGs with minimal distance, as in (Wong and You, 1985). The drawback here is that the full ensemble of AGs is needed to generate the FDGs. Since a distance measure between FDGs has not been presented, the original distances between the AGs of the ensemble are used in this second approach. The hierarchy of AGs (dendogram) can be computed by a complete method or by a single method, depending on whether the similarity of an object to a cluster is taken as its similarity to the farthest or to the closest member within the cluster, respectively (Gordon, 1987; Fisher, 1987; Wallance and Kanade, 1990). When the ensemble of patterns is composed of several classes and the assignment of patterns to classes is unknown (unclassified AGs), we need a clustering process to\n- 132 -\nsynthesise an FDG for each class. Thus, a distance measure threshold \u03b1d is introduced to determine the splitting condition. Nevertheless, if the given AGs are considered to belong to the same class and a single FDG is desired, the clustering process can be applied using a large distance threshold such that the splitting condition is never fulfilled and, therefore, only one FDG is synthesised. Below, we present the Incremental-clustering-of-AGs (section 8.1) and the Hierarchical-clustering-of-AGs (section 8.2) methods to cluster a set of AGs and synthesise the corresponding FDG for each class. Moreover, some experiments are included in section 8.3.\n8.1. Incremental (dynamic) clustering of AGs\nAlgorithm 4 computes the Incremental-clustering-of-AGs. It generates some clusters from a sequence of AGs and synthesises a set of FDGs, one for each cluster. The algorithm uses two previously described procedures: FDG-synthesis-from-labelled-AGs (section 4.4), to transform an AG into an equivalent FDG, and FDG-synthesis-fromlabelled-FDGs (section 4.5) to build an FDG from two FDGs with a given labelling. Moreover, the procedure Extend-labelling-AG-FDG extends the AG and the FDG with null elements to make them structurally isomorphic and also extends the given labelling accordingly. And also, the procedure Update-an-FDG-with-an-AG synthesises an FDG from a previous FDG, a new AG, and a labelling between them. The clustering method\nrelies on (and is parameterised by) a distance threshold \u03b1d and a matching algorithm\n( )FGM , that is supposed to return an optimal (or a \u201cgood\u201d suboptimal) labelling\nbetween an AG G and an FDG F, according to an appropriate distance measure. This distance measure is parameterised by the weights on the costs on the first and second-\norder relations (section 5.3). The weights on the first-order relations, 1K for the vertices and 2K for the arcs, are application dependent and therefore they also are parameters in the clustering algorithm. The other weights, from 3K to 8K , for the antagonisms, occurrences and existences on the vertices and arcs, are useful to keep the structural information through the labelling. Since this FDG structure has to be updated, and more\n- 133 -\ngraph elements have to be included into it, we do not consider this knowledge and so they are set to zero.\nAlgorithm 4: Incremental-clustering-of-AGs Inputs: A sequence of AGs G Gm1 ,... , m \u2265 1 , over a common domain. A matching algorithm ( )FGM , between an AG and an FDG that finds an optimal or sub-optimal labelling\naccording to the weights 1K and 2K . A threshold \u03b1d on the distance between an AG and an FDG. Output: A set of FDGs 'FC that represents the clusters of G Gm1 ,... . Begin 1:=n\nnF := FDG-synthesis-from-labelled-AGs( 1G ) {build the first FDG from 1G using the method in sec. 4.4}\nfor 2:=i to m do\nfor 1:=j to n do\nlet \u211c\u2192jij FGd ,: and jij FG \u2192:\u00b5 be the distance and labelling found by ( )ji FGM , let { }jkdmind kx \u2264\u2264= 1:\nend-for if \u03b1dd x \u2264 then\n( )xxi FG ',',' \u00b5 :=Extend-labelling-AG-FDG ( )xxi FG \u00b5,, {described next}\nxF := Update-an-FDG-with-an-AG ( )xxi FG ',',' \u00b5 {described next}\nelse\n1+nF := FDG-synthesis-from-labelled-AGs( iG ) {build 1+nF from iG using the synthesis sec. 4.4}\n1: += nn end-if\nend-for Let { }n F FFFC ,...,, 21 ' = end-algorithm\nThe synthesis process given a common labelling (section 4.4) needs the AGs and the common labelling be structurally isomorphics. For this reason, the procedure Extendlabelling-AG-FDG extends the labelling and both graphs in the following way. First, both graphs are extended with null vertices, as many as the number of non-labelled\n- 134 -\nvertices of the other graph. Thus, the updated graphs have the same number of vertices. And second, the original vertices that had not have been labelled, are labelled now with the null vertices created in the extended graphs.\nProcedure Extend-labelling-AG-FDG ( )\u00b5,,FG returns ( )',',' \u00b5FG\nif \u00b5 is not bijective then\nLet '':' FG \u2192\u00b5 be a bijective mapping that extends \u00b5 by extending G to 'G and F to 'F\nwith null vertices and arcs appropriately\nelse\n\u00b5\u00b5 =:' ; GG =:' ; FF =:'\nend-if end-procedure\nAnd the last procedure updates an FDG using two procedures described in previous sections. This procedure is carried out in two steps since we have not formally defined the synthesis of an FDG using another FDG and an AG. For this reason, the AG is first transformed into an FDG and then the returned FDG is built by the synthesis from two FDGs.\nProcedure Update-an-FDG-with-an-AG ( )',',' \u00b5FG returns F\n{build H from 'G using the method described in section 4.4}\nH := FDG-synthesis-from-labelled-AGs( 'G )\nlet HG \u2192':\u03b3 be a bijective mapping used in the previous synthesis.\nlet ': FH \u2192\u03d5 be the bijective mapping determined by the composition \u03b3\u03d5\u00b5 o='\nF := FDG-synthesis-from-labelled-FDGs ( )\u03d5,',FH {build F using synthesis in sec. 4.5 with 2 FDGs} end-procedure\n- 135 -\n8.2. Hierarchical (agglomerative) clustering of AGs\nAlgorithm 5 computes the Hierarchical-clustering-of-AGs. It generates some clusters from a set of AGs by a single or complete agglomerative method and synthesises the FDGs that describe the classes obtained. The clustering method is parameterised by a\nmatching algorithm between AGs, ( )',GGM , a distance threshold \u03b1d , and a Boolean value, which indicates the type of agglomerative method. The algorithm uses four main procedures, which are described below.\nAlgorithm 5: Hierarchical-clustering-of-AGs Inputs: A set of AGs { }m G GGC ,...,1= , 1\u2265m , over a common domain. A matching algorithm ( )M G G, ' between AGs that finds an optimal or good sub-optimal labelling according to a distance between AGs. A threshold \u03b1d on the distance between AGs. A Boolean value complete which is true or false depending on whether a complete or a single agglomerative method is desired. Output: A set of FDGs 'FC that represents the clusters of\nmGG ,...,1 .\nBegin\n{Find the set of distances between AGs { }jimjidC jid <\u2264\u2264= :,1:, and the associated labellings { }jimjifC jif <\u2264\u2264= :,1:, }\n( )df CC , :=Labelling-and-distance-between-AGs ( )MCG , {Define the set of FDGs consisting of one AG { }miFC i F \u2264\u2264= 1:\nand the labellings between FDGs { }jimjiC ji <\u2264\u2264= :,1:,\u03d5\u03d5 }\n( )\u03d5CC F , :=Initial-FDGs-and-labellings ( )fG CC ,\n{Build the FDGs 'FC by a single or complete hierarchical method}\n'FC :=Agglomerative-clustering-of-FDGs ( )complete,,,, \u03b1\u03d5 dCCC dF\nend-algorithm\nIn the first procedure, called Labelling-and-distance-between-AGs, the distance measures and labellings between AGs are obtained. Note that the whole set of AGs has\n- 136 -\nnot to be structurally isomorphic and so, the computed labellings may not be bijective. This is because, a global common labelling between AGs is not obtained.\nProcedure Labelling-and-distance-between-AGs ( )MCG , returns ( )df CC , for all G\nji CGG \u2208,\nLet f G Gi j i j, : \u2192 and d G Gi j i j, : , \u2192 \u211c found by ( )M G Gi j, end-for-all Let { }jimjifC jif <\u2264\u2264= ;,1:, ; Let { }jimjidC jid <\u2264\u2264= ;,1:, end-procedure\nIn the second procedure, called Initial-FDGs-and-labellings, the AGs and labellings are transformed into equivalent FDGs and their corresponding labellings. At this point, the initial patterns are described in FDGs, which represent only one AG. The distance between them is the one obtained between the AGs. Their labellings are obtained as a composition of the labellings between their equivalent AGs.\nProcedure Initial-FDGs-and-labellings ( )fG CC , returns ( )\u03d5CC F , for all G\ni CG \u2208\nFi := FDG-synthesis-from-labelled-AGs( iG ) {build the FDG Fi from iG using the synth. in sec. 4.4}\nlet iii FG \u2192:\u03b3 be the bijective mapping used in the previous synthesis\nend-for-all for all jimjiFF ji <\u2264\u2264 :,1:,\nlet \u03d5i j i jF F, : \u2192 be a mapping defined by 1 ,, ' \u2212= ijijji f \u03b3\u03b3\u03d5 oo\nend-for-all Let { }jimjiC ji <\u2264\u2264= ;,1:,\u03d5\u03d5 Let { }miFC i F \u2264\u2264= 1: end-procedure\n- 137 -\nIn the third procedure, called Agglomerative-clustering-of-FDGs, a set of FDGs is generated by a complete or single method. The new feature of this procedure is that the merging of two clusters redefines not only the distance measures but also the labelling between the clusters. Note that it is not possible to use an average clustering method (Gordon, 1987) since an \u201caverage labelling\u201d between two FDGs cannot be defined. As in the incremental approach, the procedures FDG-synthesis-from-labelled-AGs and FDG-synthesis-from-labelled-FDGs are used as well.\n- 138 -\nProcedure Agglomerative-clustering-of-FDGs ( )complete,,,, \u03b1\u03d5 dCCC dF returns 'FC Let { }miFC i F \u2264\u2264= 1: ; Let FF CC =' Let { }jimjiC ji <\u2264\u2264= ;,1:,\u03d5\u03d5 Let { }jimjidC jid <\u2264\u2264= ;,1:, for 1:=i to m do\n\u221e=:,iid\nend-for Let dx y, be the minimum distance in d C\nwhile \u03b1dd yx \u2264, do\n( ) yxyx FF ,',',' \u03d5 :=Extend-labelling-FDG-FDG ( )yxyx FF ,,, \u03d5 {described next} Fy := FDG-synthesis-from-labelled-FDGs ( )yxyx FF ,',',' \u03d5 {described in section 4.5} Remove Fx from 'FC for all d\nxiix Cdd \u2208,, , do\nif complete then { complete-method }\nif yixi dd ,, > then\nd di y i x, ,:= ; xiyxyi ,,, : \u03d5\u03d5\u03d5 o= ; \u221e=:,xid\nend-if if iyix dd ,, > then\nixiy dd ,, := ; xyixiy ,,, : \u03d5\u03d5\u03d5 o= ; \u221e=:,ixd\nend-if\nelse { single-method }\nif yixi dd ,, < then\nd di y i x, ,:= ; xiyxyi ,,, : \u03d5\u03d5\u03d5 o= ; \u221e=:,xid\nend-if if iyix dd ,, < then\nixiy dd ,, := ; xyixiy ,,, : \u03d5\u03d5\u03d5 o= ; \u221e=:,ixd\nend-if\nend-if\nend-for-all\nend-while end-procedure\n- 139 -\nThe synthesis process from FDGs given a common labelling (section 4.5) needs the FDGs and the common labelling be structurally isomorphics as it was commented in the incremental clustering. The procedure Extend-labelling-FDG-FDG extends the labelling and both FDGs similarly than the procedure Extend-labelling-AG-FDG.\nProcedure Extend-labelling-FDG-FDG ( )\u03d5,,HF returns ( )',',' \u03d5HF if '\u03d5 is not bijective then Let HF \u2192:\u03d5 be a bijective mapping that extends '\u03d5 by extending 'F to F and 'H to H\nwith null vertices and arcs appropriately\nelse\n': \u03d5\u03d5 = ; ': FF = ; ': HH =\nend-if end-procedure\n8.3. Experimental results\nIn order to examine the ability of these algorithms to synthesise the FDGs in practice, we performed a number of experiments with randomly generated AGs. The random AGs were generated as in section 6.5 or 7.8, that is, 10=nFDG , 100=NT and\nFrom each set of AGs representing one cluster in the reference set, an FDG was synthesised by one of the four different methods proposed to generate the FDGs. The three clustering methods with unsupervised labelling commented above are the incremental or also called dynamic method, the hierarchical complete (or agglomerative complete) and the hierarchical single (or agglomerative single). These methods have an\n- 140 -\ninput parameter that is the distance threshold. We have given to this parameter a big number to obtain only one FDG from each cluster. The fourth method is the synthesis method with a given labelling described in section 4.4. In the classification process, the branch-and-bound algorithm was used to compute the\noptimal distance. The weights on the costs were 121 == KK , === 654 KKK\n087 == KK and 3K had the values 03 =K or 13 =K . Each experimental run was\nrepeated ten times and the average of the results was recorded as a result. Figure 26 shows the average of the number of vertices and antagonism in the FDGs in which the four methods were applied. We observe that in small and medium number of AGs, the non-supervised methods obtain less number of vertices. It is because vertices in different AGs, which represent different basic parts in the original object, are merged in only one FDG vertex when the labelling was not given. We also note that when there are many AGs, the number of generated vertices using the dynamic clustering is bigger than the number of vertices of the original AGs, nv . We think that the spurious elements are not matched to other vertices and so, they remain as different ones. The hierarchical methods obtain less vertices than the dynamic method. This is because some AGs that represent different parts of the original AG have nearly similar structural and semantic information and so, the distance between them is small. In the hierarchical methods, these AGs are merged in the first steps of the clustering algorithms and so their vertices and arcs are mapped although representing different parts of the original AG. In the incremental (dynamic) method, the order of merging the AGs is imposed. If two AGs, which represent different parts of the original AG, have to be merged in the first iterations of the algorithm then the synthesised FDG does not have the same structure than the \u201coriginal AG\u201d since vertices and arcs that represent different parts may be merged in only one FDG vertex or arc. When new AGs are introduced in the synthesis process, the matching algorithm cannot completely recognise the structure and so, it generates more vertices. We also observe that the dynamic method generates more second-order relations than the other methods when the number of AGs is big. We have checked that the most of these second-order relations appear between few elements and also, that some of these\n- 141 -\nelements have similar semantic information than another FDG vertex. Therefore these elements represent the same element in the original AG but, due to the order of presenting the AGs, they have been generated as different elements. In a postprocessing step used to reduce the FDGs or delete the spurious elements, the secondorder relations could be useful to discern which vertices delete from the FDGs.\nFigure 28 shows the average run time of the classification process in logarithmic scale. In all the cases the time spent to classify the AGs decreases when the antagonisms are used. We can also observe that the biggest difference appear when the number of\nantagonism is big, for instance, in the supervised method and 9=NR .\nRun time (nv=27, nv'=6, K3=0)\n0.1\n1\n10\n100\n1000\n1 3 6 9 12 15 18\nNR\nS e\nc o\nn d\ns\nDynamic Complete Single Supervised\nRun time (nv=27, nv'=6, K3=1)\n0.1\n1\n10\n100\n1000\n1 3 6 9 12 15 18\nNR\nS e c o\nn d\ns\nDynamic Complete Single Supervised\n- 143 -"}, {"heading": "9. Experimental validation of FDGs using artificial 3D objects", "text": "We present an illustrative example of FDGs, which is based on artificially created 3D objects with planar faces. We designed five objects by a CAD program and then, we defined five sets of views from these objects. Furthermore, we built an attributed graph from each view in which the vertices represent the planar faces and the arcs represent the edges between faces. The exact value of the area of the face and the length of the edges are the only attributes of the vertices and the arcs. Instead of applying the projective distortion on the area of the faces and the distance of the edges, we have modified the attribute values of the vertices and arcs by Gausian noise. Moreover, some vertices and arcs are deleted and inserted. We wanted the attributes on the vertices and arcs be invariant but with some degree of noise. For this reason, the initial values of the attributes were set to the area and the distance instead of a random value although we are aware of they are not invariant to the projective distortion. Moreover, the Gausian noise and the insertion and deletion of some graph elements represent the noise on the measurement of the data. This experiment is only useful to make a first validation and test of the algorithms and methods presented in this thesis since it does not use real images and the extraction of the attributed graphs is not made automatically. A real application is presented in the next chapter. The advantage of this experiment is that we can use the synthesis of FDG given a common labelling (section 4.4) since we know which vertices from the AGs represent the same planar face of the object. Thus, we can discern the effects of computing the optimal and sub-optimal distance between AGs and FDGs using different costs on the second-order relations in the recognition process and the clustering algorithms in the classification process. Section 9.1 explains the set of samples. In sections 9.2 and 9.3, FDGs are synthesised with a given common labelling. The former assesses the effects of applying second-order relations in the computation of both distances between AGs, i.e. with hard restrictions and with relaxed second-order costs. The latter studies the balance between effectiveness and efficiency in the classification process when the efficient algorithm was applied. Finally, section 9.4\n- 144 -\nshows the capability of FDGs to represent an ensemble of AGs when a supervised and unsupervised clustering was applied.\n9.1. The set of samples\nThe original data was composed of 101 AGs, which represent the semantic and structural information of the views taken of five objects (appendix 1.1, views 101 to 121 of object 1, views 201 to 221 of object 2, views 301 to 312 of object 3, views 401 to 424 of object 4 and views 501 to 523 of object 5).\nVertices in the AGs represent the faces with one attribute, which is the area of the face\n(average of the areas 11.0). Arcs represent the edges between faces, with one attribute, which is the length of the edge (average of the lengths 3.0). appendix 1.2 shows the visible faces for each 3D-object. Appendix 1.3 shows the semantic and structural information of the AGs with the following structure,\nNumber of vertices (n) Attribute vertex 1 Attribute vertex 2 ... Attribute vertex n Attribute edge 1,1 Attribute edge 1,2 ... Attribute edge 1,n Attribute edge 2,1 Attribute edge 2,2 ... ... Attribute edge n,1 Attribute edge n,2 ... Attribute edge n,n\nNote that some AGs are similar although the views are different, for instance AGs 203 and 206 in figure 29. This particularity of the reference set has an important effect on the recognition and clustering process. The AGs are planar graphs that have between one and nine vertices. When the visible faces are not touching in the object, the graph can be disjoint (Figure 29).\n- 145 -\nThe AGs in the test set and the reference set are the AGs obtained from the views and modified by some structural or semantic noise. The results in the following tables are the average of computing the test 20 times. The semantic noise, which is added to the attribute values of the vertices and arcs, is obtained by a random number generation with a median of 0.0 and a standard deviation: 0.0, 2.0, 4.0, 8.0 and 12.0. The structural noise, also obtained by a random number generator, deletes or includes 0, 1 or 2 vertices, which represent 0%, 20% and 40% of the average structure, respectively.\n9.2. Effects of second-order relations\nThe aim of the first test is to assess how the antagonism and occurrence relations between vertices affect the computation of the distance with second-order restrictions or relaxing them. Results are compared with the nearest neighbour classifier in which the Sanfeliu distance (section 2.2) is used as a dissimilarity measure between elements.\n9.2.1. Recognition by FDG classifier\nFive FDGs were built from the AGs that represent their views using the supervised method synthesis-of-FDGs-from-AGs-with-a-common-labelling (see section 4.4). In this method the labelling function between graph elements is imposed using the information taken from the views and tables in appendix 1.2. Vertices and arcs in the FDGs represent planar faces and edges between faces, respectively, as in the AG case. Moreover, the number of vertices of the FDGs is similar to the number of faces of the objects. There is an antagonism relation between two graph elements when these elements are never seen together in the same view. Moreover, an occurrence relation appears when a face is visible whenever another face is also visible in all the views. For instance, in a concave object, there is an occurrence between the faces around a hole and the faces on the bottom of it. There is no existence relation because there is no pair of faces such that at least one of the two faces is visible in all views. Appendix 1.4 shows the structure of these FDGs. Valid mappings must be coherent structurally and consistent with the planar graph\nrestriction; that is, they must belong to 521 FFFH \u2229\u2229= when both distances are\n- 146 -\napplied, in the recognition task. The second-order relations on the vertices, 3R , are used\nin some tests. Furthermore, the second-order relations on the arcs, 4R , are not used since there is a geometrical relationship between the antagonisms and occurrences in the vertices and arcs. The weights in the distance relaxing second-order relations were set\nas follows: 11 =K (vertices), 2/12 =K (arcs), 13 =K (second-order relations on the\nvertices), and 04 =K (second order relations on the arcs). When one attempts to recognise a three-dimensional object from one view, the occluded parts of the object should not have an influence on the distance value. In our method, this is carried out by considering the cost of mapping a null element of the AG to an element of the FDG to be zero.\n9.2.2. Recognition by the nearest neighbour classifier\nIn this test, the nearest neighbour classifier was used with a neighbourhood of 5 and the Sanfeliu distance, described in section 2.2, was used as the dissimilarity measure between elements. The labellings between graph elements were constrained to be bijective, structurally coherent and consistent with the planar graph restriction,\n521 FFFH \u2229\u2229= . The weight of the insertion and deletion of nodes and arcs were\ndefined as a constant: 1=viW , 1=eiW , 1=vdW and 1=edW . The weights of the substitution operations were defined according to the attribute values of the graph elements of both graphs. For the vertices, ( ) 1', =jivs vvW if ( ) aji Kaa >\u2212 2' and ( ) 0', =jivs vvW otherwise, where iv and jv' are two vertices of both graphs and\n0.4=aK is a threshold on the noise of the attribute value. For the arcs, assuming that mb and nb' are the attribute values of the arcs jie , and tke ,' , ( ) 1', ,, =tkjies eeW if\n( ) bnm Kbb >\u2212 2' and ( ) 0', ,, =tkjies eeW otherwise, where 0.4=bK is a noise threshold.\n9.2.3. Results\nTable 13 shows the recognition ratio throughout different levels of semantic (standard deviation) and structural noise (number of vertices deleted or inserted) to the test and reference set. The FDG classifier was used with the distance with hard second-order\n- 147 -\nconstraints and the distance relaxing second-order constraints and the Nearest neighbour classifier. When the distance with second-order restrictions is used and the semantic or structural noise is low, the classification correctness is higher when the antagonism and occurrence relations are applied. Nevertheless, when the noise increases, best results appear when no relations are applied. However, if the distance relaxing second-order restrictions is used, the classification correctness is always higher when the antagonisms and occurrences are taken into account. The FDG classifier gives worse results than the nearest-neighbour classifier only when the structural or semantic noise is very low.\n- 148 -\nThe aim of the following tests was to study the balance between effectiveness and efficiency in the classification process in which the non-iterative efficient algorithm is used. The distance relaxing second-order relations is shown to be the one that gives best results with different levels of noise in the above section. So, this distance is used in the efficiency tests. Furthermore, the AGs and FDGs are obtained as mentioned in sections 9.1 and 9.2.1, respectively. Table 14 shows the recognition ratio applying different levels of semantic (standard deviation) and structural noise (number of vertices deleted or inserted) in the test set and different thresholds in the sub-optimal distance relaxing 2nd order relations.\nTable 15 shows the computational costs associated with the results of Table 15. All the values are normalised by the time spent to compute the classification according to the optimal distance, that is 1=\u03c4 , and without noise.\nIn the cases where 1=\u03c4 , all the mappings are allowed and the first and second steps are not computed, so their run times are saved. For this reason if 1<\u03c4 the run time may be higher than when 1=\u03c4 . The efficiency of this application does not improve without a corresponding loss in classification correctness. We believe that there are two basic reasons for this. One is that some combinations that the first step forbids may be removed by the branch and bound technique. The other is that, the AGs are small (five vertices on average), and so\n- 149 -\nthe cost of computing the first step is equivalent to the cost of the third, considering the branch and bound technique.\n9.4. Clustering\nThe last tests were carried out to show how capable FDGs are at representing an ensemble of AGs when a supervised or unsupervised clustering process is applied. First, we used a supervised clustering; that is, the FDGs were synthesised using the AGs that belong to the same 3D object (tables 16 and 17). And second, we applied an unsupervised clustering; the FDGs were automatically generated using the whole reference set of AGs. That is, independently of the view or of the 3D object from which were extracted (table 18). In this case, we considered that the FDG belongs to the 3D object that the most of the AGs used to synthesise it belong to.\n9.4.1. Supervised clustering\nIn the first experiments, we used four different methods. In the first one, the labellings were manually determined from the original data and the FDGs were synthesised as explained in section 9.2.1. The number of vertices of the FDGs, shown in the first column of table 16, is similar to the number of faces of the objects. In the rest of the\nmethods, there is no a-priori information of the labellings. The distance threshold \u03b1d was set to a big number, such that, only one FDG was synthesised for each reference set. In the second one, the FDGs were obtained by the procedure Incrementalclustering-of-AGs (section 8.1). The number of FDG vertices is shown in the fourth column of table 16. The AGs were presented to the algorithm as the point of view rotated around the object. Therefore, the new faces are gradually introduced to the system, which minimises the effect of merging different faces in only one FDG vertex. The third and fourth methods use the Hierarchical-clustering-of-FDGs algorithm (section 8.2), with a complete and single agglomerative technique, respectively. The Sanfeliu distance measure (section 2.2) was used to find the distance and the optimal labelling between AGs. Note that in the clustering methods such that the labelling is not given the number of vertices of the FDGs were reduced (2nd, 3rd and 4th column of Table 16). This means\n- 150 -\nthat more than one face of the object is represented by one vertex in the FDG. This is partly due to the fact that some faces of these objects are similar and thus, the matching algorithm between AGs matches their corresponding vertices. So, the clustering process considers these faces as the same vertex in the FDG.\nSynthesis from\nHierarchical-\nHierarchical-\nIncremental\nTable 17 shows the ratio of correctness of the FDG classifier and the nearest neighbour classifier that applies the Sanfeliu distance measure between AGs as a distance between elements. The test set was obtained from the reference set by applying a zero-mean Gaussian noise that modifies the semantic information with a standard deviation of 8.0. The structure was also modified by inserting or deleting one of the vertices. The results of the nearest neighbour classifier were only better than the FDG classifier when the single method was used. On the contrary of the results obtained in the experimental results, figure 27 right, the complete clustering gave lower results than the incremental clustering. It is the author\u2019s believe that it is because the order of presenting the new graphs to the incremental synthesis is of crucial importance. In the random graph experiments, the order was also random, without considering the similarity between the introduced graphs.\n- 151 -\n9.4.2. Unsupervised clustering\nTable 18 shows the clustering and classifying results using the FDG unsupervised clustering methods and the Nearest-neighbour classifier. The synthesis with labelled AGs cannot be used since in these experiments the FDGs can be synthesised with AGs from different 3D objects and so the FDG vertices can represent faces from different objects. Moreover, the order of presenting the AGs to the incremental method was defined randomly to try not to influence on the synthesised FDGs. The distance threshold \u03b1d was set to obtain five classes in all the methods. There is a decrease in the correctness in all the methods except the complete clustering. We also show the average of the number of vertices of the FDGs. The classification using the complete method obtains the best results and also it is the only method that the correctness increases respect the supervised clustering (table 17). In these tests, we show again that the order of introducing the AGs in the incremental method is very important. Again, the nearest neighbour classifier only obtains better results than the single method.\n- 153 -"}, {"heading": "10. Application of FDGs to 3D objects", "text": "We present a real application of FDGs to recognise coloured objects using 2D images. The tests presented here are the first ones obtained in the Spanish project TAP98-0473. The aim of this project is to design a robot that has to recognise objects in a given environment, for instance, in an office. The recognition process is implemented by the FDG approach with a high number of objects and views. During the learning process, the robot is guided to move around the 3D objects and to take images from different perspectives. These images are segmented by the method outlined in the next section, which extracts the AGs. An FDG is synthesised from the set of AGs providing from each object. In this test, we took sixteen views from each object. In each view, the angle was incremented 22.5 degrees (appendix 2.2). The views taken with the angles 0, 45, 90, 135, 180, 225, 270 and 315 were used to synthesise the FDGs in the learning process. The other views, 22.5, 67.5, 115.5, 157.5, 202.5, 247.5, 292.5 and 337.5 compose the test set. In the validation of the FDGs, chapter 9, the incremental synthesis obtains better results than the hierarchical synthesis in the supervised clustering when a proper sequence of presenting the AGs is given. Moreover, the incremental synthesis has the advantage that the learning and recognition process can be interleaved and also that the synthesis complexity is only lineal on the number of AGs. For these reasons, in this project we prefer the incremental synthesis to generate the FDGs that represent the objects to be recognised. The main problems in real applications provide from the segmentation module. From the structural point of view, if a region is not detected (their pixels are merged with a near region) then there is a missing vertex in the AGs. Furthermore, if a region is split into two, then there is a spurious vertex. And also, from the semantic point of view, there is always some degree of uncertainty in obtaining the attribute values. To solve, as much as possible these problems, first, it is useful to use redundancy data and for this\n- 154 -\nreason, some of the visible faces in the image are also visible in other images. Second, it is needed a calibration process to extract the kind of regions that the user desires. The remainder of this chapter is as follows, section 10.1 outlines the method used to segment the images, section 10.2 describes the calibration process and section 10.3 presents some of the obtained results.\n10.1. Segmentation of the images\nSegmentation is the first essential and important step of low-level vision. Segmentation is a process of partitioning the image into some regions such that each region is homogeneous and the union of two adjacent regions is not homogeneous. Hundreds of segmentation techniques are present in the literature (Pal and Pal, 1993). In this application, we have selected the graph-theoretical approach to cope with image segmentation because it has good mathematical basements and some segmentation problems are easily translated into graph-related problems by analogy. Moreover, in the graph theoretical approach, image region extraction and finding region edges are dual problems. The worst disadvantage of this approach, as can be seen in (Wu and Leahy, 1993; Vlachos and Constantinides, 1993; Xu and Uberbacher, 1997), is that these sort of algorithms are very time consuming, which makes their implementation prohibitive in some real applications. For this reason, we have chosen the greedy algorithm for graph partition proposed in (Felzenswalb and Huttenlocher, 1998). This algorithm makes decisions based on local properties of image, as could be pixel differences, and also global properties of the image such as not over-segmentation and not subsegmentation. It was implemented and compared to other approaches in (Verg\u00e9s-Llah\u00ed and Sanfeliu, 2000). The input of our segmentation algorithm is a view of the object and the output is an attributed graph. The vertices of the AG represent regions which have similar colour and there is an arc between adjacent regions. The attribute on the vertices is the hue of the colour and the attribute on the arcs is the difference between the hues of the connecting vertices. The hue is not well defined when the colour tends to the grey, that is, the colour is not saturated. For this reason, the neighbourhoods of non-saturated pixels are merged into regions independently of their colour. The attribute on the node\n- 155 -\nis represented by the average of the hue. Figure 30 (page 162) shows the four objects, the segmented views and their corresponding AGs. Appendix 2.3 and 2.4 show the segmented images of the objects and the computed AGs. The input parameters of the algorithm are: Threshold on the colour difference: If the colour between two adjacent pixels is lower than this threshold, then they belong to the same region. Threshold on the number of pixels: The regions that have less number of pixels than this threshold are merged into their adjacent regions. Threshold on the compactness: The thin regions are deleted if their compactness is greater than this threshold. It is useful the delete the regions that appear in the edges of the faces. Threshold on the saturation: If the saturation of the pixel colour is lower than this threshold, then the pixel belongs to a non-saturated region. Threshold on the average size: This is a global feature used to control the average size of the regions.\n10.2. Calibration process\nTo calibrate the segmentation module we used four monochrome objects. From each object we took four images varying the angle (appendix 2.1.1). We wanted that the segmented images had only one region (appendix 2.1.2) and that the AGs computed from these views had only one vertex (appendix 2.1.3). The parameters were set as follows:\nMoreover, an FDG was synthesised using the four AGs that belong to the same object. These FDGs had to have two vertices. One vertex represents the object and the other\n- 156 -\none represents the background. In the recognition process, the 16 AGs had to be correctly classified. As it was commented in section 4.1, the probability density functions in the FDGs are represented non-parametrically and we use a discretisation process to represent them computationally. The discretisation of the hue plays an important rule on the number of graph elements in the FDGs. If it is discretised in few intervals and these intervals are large, then only one FDG vertex is synthesised but the AGs are not properly classified. On the contrary, if the hue is discretised in many intervals and these intervals are small, then more than two vertices are generated in the FDGs. The values of the hue obtained in the segmentation are:\nView 1 View 2 View 3 View 4\nBlue object 43 42 43 43\nGreen object 153 147 150 149 Yellow object 3 4 4 4\nRed object 96 92 95 96\nTable 20. Value of the vertex attributes in the calibration AGs\nWe discretised the hue in intervals of 10. Moreover, the probabilities were computed as follows,\n( )( ) ( )( ) ( )( )aRaRaRp \u2212+ ++= Pr 4\n1 Pr\n4\n1 Pr\n2\n1 )(a\n(150)\nwhere )(aR represents the interval that a belongs to and )(a+R and )(a\u2212R are the\nprevious and the next intervals.\n10.3. Practical results\nTable 21 shows the number of graph elements of the synthesised FDGs using the incremental method. The AGs were presented as the observer was rotating around the objects and the optimal distance was computed between the AGs and the FDGs (any relaxation method was applied).\n- 157 -\n- 158 -\n- 159 -\nTables 24.a and 24.b show the distances between AGs in the reference set and the AGs in the test set using the Sanfeliu and Fu algorithm (section 2.2). The minimum distance is shown in the column headed by md and also in bold in the table. There is a \u201c+\u201d or a \u201c*\u201d if the AG was correctly classified using the 1 nearest neighbours and the 3 nearest neighbours, respectively. The costs on the insertions, deletions and substitutions of vertices and arcs have been set as follows:\nThe costs on the insertion and deletion take all the same value: === vdeivi CCC\n1=edC . The cost on the substitution is:\n( ) ( )\n( )\n \n\n<\n\u2265\u2265\n>\n=\n5,0\n10,52/1\n10,1\nbaabsif\nbaabsif\nbaabsif\nCs (151)\nwhere sC represents vsC if a and b are attribute values of two vertices and esC if they are attribute values of two arcs. The average time spent to classify each AG in the test set was 1.93 seconds. The correctness using the 1-NN is 56% and using the 3-NN is 59%. FDGs obtain better results than the 1 nearest neighbour or the 3 nearest neighbours. Given a test view, the most similar views in the reference set have to be the previous and next views in the rotating sequence of the same object. Nevertheless, the distance is usually greater than zero because the different topology and the variation on the colour. In the FDG classifier, these variations are compensated by the structural and probabilistic knowledge of the whole object. Moreover, the FDG method classifies the views faster than the nearest neighbours. Although the FDGs are bigger than the AGs, the secondorder relations prune the search tree. In addition, only one comparison for class is needed in the FDGs and sixteen in the nearest neighbours.\n- 160 -\n- 161 -\n- 162 -\n- 163 -"}, {"heading": "11. Conclusions and future work", "text": "Function-described graphs (FDGs) are a type of compact representation of a set of attributed graphs (AGs) that borrow from random graphs the capability of probabilistic modelling of structural and attribute information, while improving the capacity of firstorder random graphs to record structural relationships that consistently appear through the data. This is achieved by incorporating qualitative knowledge of the second-order probabilities of the elements that are expressed as relations (Boolean functions) between pairs of vertices and pairs of arcs in the FDG. If only the relations between vertices are considered, the space complexity of the FDG representation is not greater than that of a first-order random graph, 2n , since all the relations defined (antagonism, occurrence, existence) can be obtained easily from the first-order marginal probabilities and just one second-order probability for each pair of vertices (namely, the probability of both vertices being null at the same time). However, if arc relations are considered as well, the space complexity obviously increases to 2a , where a is the number of arcs. For dense graphs, this involves a storage (and a time complexity for creation, maintenance and verification of the arc relations) of order 4n instead of 2n , which can be a severe drawback in practice. In this doctoral thesis, we have studied the problem of matching an AG to an FDG for recognition or classification purposes from a Bayesian perspective. A distance measure between AGs and FDGs was derived from the principle of maximum likelihood, but robustness was assured because the effects of extraneous and missing elements were considered only locally. In this first measure, the set of valid mappings which have to be explored can be reduced by imposing the second-order relations as hard restrictions to be fulfilled. A second and more robust distance measure has also been given, in which second-order constraints are relaxed into local costs, at the expense of losing the theoretical link with the maximum likelihood source. A branch-and-bound algorithm, adapted from (Wong, You and Chan, 1990), has been proposed for computing both distance measures together with their corresponding\n- 164 -\noptimal labellings. We have seen that the antagonism relations are useful for pruning the search tree and also for increasing the correctness in the recognition process. However, the tree\u2019s computational complexity is non-polynomial, and therefore, alternative efficient methods which can provide good sub-optimal measures and labellings have also been presented. The aim of these methods is to reduce the number of possible vertex mappings before the branch and bound algorithm is run to compute the distance measure. The synthesis of an FDG from a set of commonly labelled AGs has been described in detail. This synthesis can be regarded as a supervised learning method because all the AGs in the sample require a given common labelling. We have also reported two methods for synthesising FDGs from a set of unlabelled AGs and for clustering, in a non-supervised manner, a set of AGs into a set of FDGs representing subclasses. The former is based on an incremental process, which has the advantage that the learning and classification process can be interleaved. The latter is based on a hierarchical process. The whole ensemble of samples is needed to build the FDGs but the process does not depend on the order of presentation of the AGs as in the first method.\nThree different experimental tests were carried out to asses the usefulness of our new representation and the algorithms presented here. The first type of tests is presented in the last section in chapters 4, 6, 7 and 8. These tests are performed with randomly generated attributed graphs with the aim of validating the approaches presented in each chapter independently, as much as possible, of the other approaches. In section 4.6 we presented the structure of the FDGs (the number of vertices, antagonisms, occurrences and existences) depending on the number of attributed graphs used to generate it and the number of elements of these graphs. We realise that the number of FDG elements depend on the nature of the attributed graphs and we obtained some results of the number of antagonisms and vertices useful to understand other results presented in the following chapters. In section 6.5, we show the correctness and run time of the recognition process varying the cost on the antagonism. The best correctness appears when the antagonisms are relaxed (the cost of antagonisms is 1) although the fastest comparison is performed when the antagonisms are considered\n- 165 -\nas strict restrictions (the cost of antagonism is a big number). The run time is much bigger when the antagonisms are not considered, therefore we conclude that the antagonisms are useful, not only for increasing the correctness but also for decreasing the run time. In section 7.8, we studied the balance between the run time and the correctness of the efficient algorithms and the optimal algorithm. We show that it is worth to initialise the probabilities by the distance between expanded vertices although this process is more expensive than initialising them by the distance between vertices. The non-iterative algorithm is not useful when the number of AGs used to synthesise the FDGs is medium or big since the run time is higher and the correctness lower than the iterative algorithms. Finally, in section 8.3, we compared the clustering algorithms. The best results are obtained using the complete method. We observed that this is not the case in the experimental validation that is commented in the previous section. We observed that spurious vertices in the FDGs are connected to the other vertices by antagonisms. Therefore, antagonisms not always are useful for decreasing the run time and increasing the correctness in the recognition process, but also they are useful for locating the spurious elements and deleting them from the FDGs in the learning process. The second type of tests is an experimental validation of the FDGs. The attributed graphs are obtained from some artificially created 3D objects. The aim of these tests is to enforce the usefulness of our method by studying the algorithms and methods as a whole. The advantage of using artificial data is that we can perform the synthesis given a labelling described in section 4.4. There is any surprising result except for the clustering algorithms. We observe that, on the contrary of the results obtained in the above experiments, in the supervised clustering, the incremental (or dynamic) method obtains better results than the complete method. Nevertheless, when the unsupervised clustering is used, the complete method again obtains the best results. The last tests are performed using real data. Some images were taken from four objects and segmented by analysing the colour. The problems providing from the segmentation step, such as the non-recognition of a region, the extraction of the attributes or the appearance of a spurious graph element are solved satisfactorily by the use of FunctionDescribed Graphs. Therefore, we conclude that they are a useful tool for structural pattern recognition applied to computer vision.\n- 166 -\nIn a practical point of view, further investigation is needed to compare the performance of FDGs with the other approaches in different applications and also to study the performance of the segmentation module. We are working in a middle and long-term project. Results presented in chapter 10 are only the first experiments of this project using real data. Now, we will work with office objects (tables, columns, chairs, telephones, ...). In a theoretical point of view, second order relations can be substituted by second order probabilities since they are a coarse approximation of them. Thus, the distance relaxing second order costs would have a finer value. Nevertheless, the relation between the increase in correctness in the classification process and the increase in computational and storage cost would have to be considered. The application of relaxation techniques in the first module of our efficient algorithm needs to be studied in depth since the run time and the correctness is of capital importance in our present project. A new support function needs to be defined that includes structural and first and second order information. Finally, it would be interesting to study a learning method with positive and negative samples. The negative samples would influence the synthesis algorithms (learning process). Moreover, a process of reduction of the FDG could be studied. The main idea is to delete the graph elements that are considered not important in the representation of the model or to merge, by a clustering process, some of these graph elements.\n- 167 -"}, {"heading": "12. References", "text": "1. H. A. Almohamad and S.O. Duffuaa, \u201cA linear programming approach for the\nweighted graph matching problem\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 15, pp. 522-525, 1993. 2. R. Alqu\u00e9zar, A. Sanfeliu and F. Serratosa, \u201cSynthesis of Function-Described\nGraphs\u201d, Advances in Pattern Recognition, Proc. Joint IAPR Int. Workshops SSPR\u201998 and SPR\u201998, Sydney, Australia, Springer LNCS-1451, pp. 112-121, 1998. 3. R. Alqu\u00e9zar, F. Serratosa and A. Sanfeliu, \u201cDistance measures between Attributed\nGraphs and Function-Described Graphs relaxing 2nd order constraints\u201d, Syntactic and Structural Pattern Recognition, SSPR\u20192000 , Alicante, Spain, 2000. 4. L. Babai, \u201cModerately exponential boud for graph isomorphism\u201d, F. Gecseg, editor,\nLecture notes in computer sicence: Fundamentals of computation theory, Springer Verlag, pp: 34-50, 1981. 5. B. Bamieh and R.J.P. De Figueiredo, \u201cA general momement-invariants/Attributed-\nGraph method for three-dimensional object recognition from single image\u201d, IEEE Journal of Robotics and Automation, vol. 2, pp. 31-41, 1986. 6. H.G. Barrow and R.M Burstall, \u201cSubgraph isomorphism, matching relational\nstructures and maximal cliques\u201d, Information Processing Letters, vol. 4, pp. 83-84, 1976. 7. A.T. Berztiss, \u201cA Backtracking procedure for isomorphism of directed graphs\u201d,\nJournal of the Association for computing machinery, vol. 20, pp. 365-377, 1973.\n8. B. Bhanu and J.C. Ming, \u201cTRIPLE: A multi-strategy machine learning approach to\ntarget recognition\u201d, Image understanding workshop, pp: 537-547, 1988.\n9. R.E. Blake, \"Partitioning graph matching with constraints\", Pattern Recognition,\nvol. 27, pp. 439-446, 1994.\n10. K.W. Bowyer and C.R. Dyer, \u201cAspect graph: an introduction and survey of recent\nresults\u201d, International Journal Imaging System and Technology, vol. 2, pp. 315-328, 1990.\n- 168 -\n11. D.E. Brown, C.L. Huntley and A.R. Spillane, \u201cA parallel genetic heuristic for the\nquadratic assignment problem\u201d, J.D. Schaffer, editor, Genetic algorithms, Morgan Kaufmann, pp: 406-415, 1989. 12. H. Bunke, \u201cStructural and syntactic pattern recognition\u201d, Handbook of Pattern\nRecognition and Computer Vision, World Scientific Publ. Co., Singapore, pp. 163- 209, 1993. 13. H. Bunke, \u201cError-tolerant graph matching: a formal framework and algorithms\u201d.\nAdvances in Pattern Recognition, Proceedings Joint IAPR Int. Workshops SSPR\u201998 and SPR\u201998, Sydney, Australia, Springer LNCS-1451, pp. 1-14, 1998. 14. H. Bunke and G. Allerman, \u201cInexact graph matching for structural pattern\nrecognition\u201d, Patter recognition letters, vol. 1, pp: 245-253, 1983.\n15. H. Bunke and B. Messmer, \u201cRecent advances in graph matching\u201d. International\nJournal in Pattern Recognition and Artificial Intelligence, vol. 11, pp. 169-203, 1997. 16. H. Bunke and A. Sanfeliu (Editors), \u201cSyntactic and structural pattern recognition\u201d.\nSeries in computer science, World Scientific, vol. 7, 1990.\n17. K.P. Chan, \u201cLearning templates from fuzzy examples in structural pattern\nrecognition\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 26, pp. 118-123, 1996. 18. S.M Chen, \u201cInterval-valued fuzzy hypergraphs and fuzzy partition\u201d, IEEE\nTransactions on Systems, Man and Cybernetics, vol. 27, pp. 725-732, 1997.\n19. C.H. Chen and A.C. Kak, \u201cA robot vision system for recognising 3D objects in low-\norder polynomial time\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 19, pp. 1535-1536, 1989. 20. J.K. Cheng and T.S. Huang. \u201cImage recognition by matching relational structures\u201d,\nIEEE Conference on Pattern Recognition and Image Processing, pp: 542-547, 1981. 21. C.J. Cho and J.J. Kim, \u201cRecognising 3-D objects by forward checking constrained\ntree search\u201d, Pattern Recognition Letters, vol. 13, pp: 587-597, 1992.\n- 169 -\n22. W.J. Christmas, J. Kittler and M. Petrou, \u201cStructural matching in computer vision\nusing probabilistic relaxation\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 17, pp. 749-764, 1995. 23. L. Cinque, D. Yasuda, L.G. Shapiro, S. Tanimoto and B. Allen, \u201cAn improved\nalgorithm for relational distance graph matching\u201d, Pattern Recognition, vol. 29, pp. 349-359, 1996. 24. D.J. Cook and L.B. Holder, \u201cSub-structure discovery using minimum description\nlength and background knowledge\u201d, Journal of Artificial Intelligence Research, pp: 231-255, 1994. 25. D.G. Corneil and C.C. Gotlieb, \u201cAn efficient algorithm for graph isomorphism\u201d,\nJournal of the Association for computing machinery, vol. 17, pp. 51-64, 1970.\n26. A. Cross, and E. Hancock, \u201cGaph matching with a dual-step EM algorithm\u201d, IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol. 20 pp. 1236-1253, 1998. 27. A. Cross, R. Wilson and E. Hancock, \u201cGenetic search for structural matching\u201d,\nComputer Vision- FCCV\u201996, Lecture notes in computer sicence 1064, Springer Verlag, pp. 514-525, 1996. 28. K. A. De Jong and W.M. Spears, \u201cUsing genetic algorithms to solve NP-complete\nproblems\u201d, J.D. Schaffer editor, Genetic Algorithms, Morgan Kaufmann, pp: 124- 132, 1989. 29. F. Depiero, M. Trivedi and S. Serbin, \"Graph matching using a direct classification\nof node attendance\", Pattern Recognition, vol. 29, pp. 1031-1048, 1996.\n30. H. Ehrig, \u201cIntroduction to graph grammars with applications to semantic networks\u201d,\nComputers and Mathematics with Applications, vol. 23, pp: 557-572, 1992.\n31. M.A. Eshera and K.S. Fu, \"A graph distance measure for image analysis\", IEEE\nTransactions on Systems, Man and Cybernetics, vol. 14, pp. 398-408, 1984.\n32. B. Falkhenhainer, K.D. Forbus and D. Gentner, \u201cThe structure-mapping engine:\nAlgorithms and examples\u201d, Artificial Intelligence, vol. 41, pp: 1-63, 1990.\n33. O.D. Faugeras and K.E. Price, \"Semantic labelling of Aerial Images using\nStochastic Relaxation\", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 13, pp. 633-642, 1981.\n- 170 -\n34. P.F. Felzenswalb and D.P. Huttenlocher, \u201cImage Segmentation Using Local\nVariation\u201d, Proc. of the IEEE Computer Soc. Conf. on Computer Vision and Pattern Recognition, pp. 98-104, 1998. 35. J. Feng, M. Laumy and M. Dhome, \"Inexact matching using neural networks\",\nPattern recognition in practice IV: Multiple paradigms, comparative studies and hybrid systems, pp. 177-184, 1994. 36. D.H. Fisher, \"Knowledge acquisition via incremental conceptual clustering\",\nMachine learning, vol. 2, pp. 139-172, 1987.\n37. G.P. Ford and J. Zhang, \u201cA structural graph matching approach to image\nunderstanding\u201d, SPIE, Intelligent robots and computer vision X: Algorithms and techniques 1607, pp: 559-569, 1991. 38. K.S. Fu and B.K. Bhargava, \"Tree systems for syntactic pattern recognition\", IEEE\nTransactions on Computers, vol. 22, pp. 1087-1099, 1973.\n39. M.R. Garey and D.S. Johnson, \"Computers and intractability: A guide to the theory\nof NP-Completeness\", Freeman and Company, 1979.\n40. G. Gati, \u201cFurther annotated bibliography on the isomorphism disease\u201d, Journal of\nGraph Theory, pp: 96-109, 1979.\n41. Z. Gigus and J.F. Cany and R. Seidel, \u201cEfficient computing and representing aspect\ngraph of polyhedral objects\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 13, pp. 442-451, 1991. 42. Z. Gigus and J. Malik, \u201cComputing the aspect graph for line drawings of polyhedral\nobjects\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 12, pp. 113-122, 1990. 43. E. Gmuer and H. Bunke, \u201c3D object recognition based on sub-graph matching in\npolynomial time\u201d, R. Mohr, T. Pavlidis and A. Sanfeliu editors, Structural Pattern Analysis, World Scientific, pp: 131-147, 1990. 44. S. Gold and A. Rangarajan, \u201cA graduated assignment algorithm for graph\nmathcing\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 18, pp. 377-387, 1996.\n- 171 -\n45. J. Gregor and M.G. Thomason, \"Efficient dynamic programming alignment of\ncyclic strings by shift elimination\", Pattern Recognition, vol. 29, pp. 1179-1183, 1996. 46. E.R. Hancock and J. Kittler, \"Discrete relaxation\", Pattern Recognition, vol. 23, pp.\n711-733, 1990.\n47. R.M. Haralick, \"An interpretation for probabilistic relaxation\", Computer vision,\nGraphics and Image Processing, vol. 22, pp. 388-395, 1983.\n48. R.M. Haralick and G.L. Elliot, \u201cIncreasing tree search efficiency for constraint\nsatisfaction problems\u201d, Artificial Intelligence, Elveiser, vol. 14, pp: 263-313, 1980.\n49. L. Herault, R. Horaud, F. Veillon and J.J. Niez, \"Symbolic image matching by\nsimulated annealing\", British machine vision conference, Oxford, pp. 319-324, 1990. 50. C.M. Hoffman, \u201cGroup-theoretic algorithms and graph isomorphism\u201d, Springer\nVerlag, 1982.\n51. J.E. Hopcroft and J.K. Wong, \u201cLinear time algorithm for isomorphism of planar\ngraphs\u201d, Annual ACM syposium on theory of computing, pp: 172-184, 1974.\n52. R. Horaud and T. Skordas, \u201cStructural matching for stereo vision\u201d, 9th Internatinal\nConference on Pattern Recognition, pp: 439-445, 1988.\n53. R. Horaud and T. Skordas, \u201cStereo correspondence through feature grouping and\nmaximal cliques\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 11, pp. 1168-1179, 1989. 54. R. Horaud, F. Veillon and T. Skordas, \u201cFinding geometric and relational structures\nin an image\u201d, Proceedings of 1rst European Conference on Computer Vision, pp. 374-384, 1990. 55. R.A. Hummel and S.W. Zucker, \"On the foundations of relaxation labelling\nprocesses\", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 5, pp. 267-286, 1983. 56. W.Y. Kim and A.C. Kak, \"3D-object recognition using bipartite matching\nembedded in discrete relaxation\", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 13, pp. 224-251, 1991.\n- 172 -\n57. L. Kitchen and A. Rosenfeld, \"Discrete relaxation for matching relational\nstructures\", IEEE Transactions on Systems, Man and Cybernetics, vol. 1, pp. 84-90, 1979. 58. J. Kittler, W.J. Christmas and M. Petrou, \"Probabilistic relaxation for matching\nproblems in machine vision\", Proceedings 4th International Conference on Computer Vision, pp. 666-674, 1993. 59. J. Kittler and E.R. Hancock, \"Combining evidence in probabilistic relaxation\",\nInternational Journal of Pattern Recognition and Artificial Intelligence, vol. 3, pp. 29-51, 1989. 60. J. Larrosa, P. Meseguer and T. Schiex, \u201cMaintaining reversible DAC for Max-\nCSP\u201d, Artificial Intelligence, vol. 107, pp.149-163, 1999.\n61. A. Laurentini, \u201cIntroducing the reduced aspect graphs\u201d, Pattern Recognition Letters,\nvol. 16, pp.43-48, 1995.\n62. S.W. Lee and J.H. Kim, \u201cAttributed stroke graph matching for seal imprint\nverification\u201d, Pattern Recognition Letters, vol. 9, pp: 137-145, 1989.\n63. S.W. Lee, J.H. Kim and F.C.A. Groen, \u201cTranslation-rotation-and scale invariant\nrecognition of hand-drawn symbols in schematic diagrams\u201d, International Journal of Pattern Recognition and Artificial Intelligence, vol. 4, pp: 1-15, 1990. 64. H. Lee-Kwang and C.H. Cho, \u201cHierarchical reduction and partition of\nhypergraphs\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 26, pp. 340-344, 1996. 65. V.I. Levenshtein, \"Binary codes capable of correcting deletions, insertions and\nreversals\", Soviet Physics Doklady, Cybernetics and Control Theory, vol. 10, pp. 707-710, 1966. 66. G. Levi, \"A note on the derivation of maximal common subgraphs of two directed\nor indirected graphs\", Calcolo, vol. 9, pp. 341-354, 1972.\n67. T. Lourens, \u201cA biologically plausible model for corner based object recognition\nfrom colour images\u201d, PhD thesis, University of Groningen, The Netherlands, 1998.\n68. S.Y. Lu, \"A tree-matching algorithm based on node splitting and merging\", IEEE\nTransactions on Pattern Analysis and Machine Intelligence, vol. 6, pp. 249-256, 1984.\n- 173 -\n69. S.W. Lu, Y. Ren and C.Y. Suen, \u201cHierarchical attributed graphs representation and\nrecognition of handwritten Chinese characters\u201d, Pattern Recognition, vol. 24. pp: 617-632, 1991. 70. E.M. Luks, \u201cIsomorphism of graphs of bounded valence can be tested in polynomial\ntime\u201d, Journal of computer ans system sciences, pp: 42-65, 1982.\n71. M. Maes, \u201cOn a cyclic string-to-string correction problem\u201d, Information Processing\nLetters, vol. 35, pp. 73-78, 1990.\n72. F. Mc Gregor, \"Backtrack search algorithms and the maximal common subgraph\nproblem\", Software-Practice and Experience, vol. 12, pp. 23-34, 1982.\n73. S. Mehta and L. Fulop, \u201cA neural algorithm to solve the graph matching problem\u201d,\nProceedings of International neural network conference, vol. 1, pp. 262-266, 1990.\n74. W.S. Meisel, \u201cComputer oriented approaches to pattern recognition\u201d, Academic\npress, 1972.\n75. B.T. Messmer and H. Bunke, \u201cEfficient error-tolerant subgraph isomorphism\ndetection\u201d, Shape, Structure and Pattern Recognition, D.Dori and A. Bruckstein (eds.), World Scientific, 1994. 76. B.T. Messmer and H. Bunke, \u201cAutomatic learning and recognition of graphical\nsymbols in engineering drawings\u201d, K. Tombre and R. Kasturi editors, Graphics recognition, Lecutre notes in computes science 1072, Springer Verlag, pp: 123-134, 1996. 77. S.H. Myaeng and A. Lopez-Lopez, \u201cConceptual graph matching: A flexible\nalgorithm and experiments\u201d, Journal of experimental and theoretical artificial intelligence, vol. 4, pp: 107-126, 1992. 78. D.P. O'leary and S. Peleg, \"Analysis of relaxation processes: The two-node label\ncase\", IEEE Transactions on Systems, Man and Cybernetics, vol. 13, pp. 618-623, 1983. 79. N.K. Pal and S.K. Pal, \u201cA Review on Image Segmentation Techniques\u201d, Pattern\nRecognition, Vol. 26, No. 9, pp. 1277-1294, 1993.\n80. A. Pearce, T. Caelli and W.F. Bischof, \u201cRulegraphs for graph matching in pattern\nrecognition\u201d, Pattern Recognition, vol. 27, pp: 1231-1246, 1994.\n- 174 -\n81. S. Peleg and A. Rosenfeld, \u201cDetermining compatibility coefficients for curve\nenchancement relaxation processes\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 8, pp. 548-555, 1978. 82. J. Poole, \u201cSimilarity in legal case based reasoning as degree of matching in\nconceptual graphs\u201d, M.M. Richter, S. Wess, K.D. Althoff and F. Maurer, editors, pp: 54-58, 1993. 83. R.C. Read and D.G. Corneil, \u201cThe graph isomorphism disease\u201d, Journal of Graph\nTheory, vol. 1, pp: 339-363, 1977.\n84. D. Ria\u00f1o and F. Serratosa, \u201cUnsupervised synthesis of Function-Described Graphs\u201d,\nProceedings of the 2 ond Workshop on Graph Based Representations, Vienna, Austria, 1999. 85. A. Rosenfeld, R.A. Hummel and S.W. Zucker, \u201cScene labeling by relaxation\noperators\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 6, pp. 420- 443, 1976. 86. D.H. Rouvray and A.T. Balaban, \u201cChemical applications of graph theory\u201d, R.J.\nWilson and L.W. Beineke, editors, Applications of Graph Theory, Academic Press, pp: 177-221, 1979. 87. A. Rosenfeld, R.A. Hummel and S.W. Zucker, \u201cScene labelling by relaxation\noperations\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 6, pp. 420- 433, 1976. 88. A. Sanfeliu and K. Fu, \u201cA distance measure between attributed relational graphs for\npattern recognition\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 13, pp. 353-362, 1983. 89. A. Sanfeliu, F. Serratosa and R. Alqu\u00e9zar, \"Clustering of attributed graphs and\nunsupervised synthesis of function-described graphs\", 15th International Conference on Pattern Recognition, ICPR\u20192000, Barcelona, Spain, 2000. 90. D.C. Schmidt and L.E. Druffel, \u201cA fast backtracking algorithm to test directed\ngraphs for isomorphism using distance matrices\u201d, Journal of the Association for computing machinery, vol. 23, pp. 433-445, 1976. 91. D.S. Seong, H.S. Kim & K.H. Park, \u201cIncremental Clustering of Attributed Graphs\u201d,\nIEEE Transactions on Systems, Man and Cybernetics, vol. 23, pp. 1399-1411, 1993.\n- 175 -\n92. F. Serratosa, R. Alqu\u00e9zar and A. Sanfeliu (b), \u201cFunction-Described Graphs for\nstructural pattern recognition\u201d, Technical report DEIM-RR-99-006, Universitat Rovira i Virgili, Tarragona, Spain, 1999. 93. F. Serratosa, R. Alqu\u00e9zar and A. Sanfeliu (c), \u201cFunction-Described Graphs for\nstructural pattern recognition\u201d, Submitted to Transactions on Pattern Analysis and Machine Intelligence, 1999. 94. F. Serratosa, R. Alqu\u00e9zar and A. Sanfeliu (d), \u201cFunction-Described Graphs: A fast\nalgorithm to compute a sub-optimal matching measure\u201d, Proceedings of the 2ond Workshop on Graph Based Representations, Vienna, Austria, 1999. 95. F. Serratosa, R. Alqu\u00e9zar and A. Sanfeliu (a), \u201cEfficient algorithms for matching\nattributed graphs and function-described graphs\u201d, In Proceedings 15th International Conference on Pattern Recognition, ICPR\u20192000, Barcelona, Spain, 2000. 96. F. Serratosa and A. Sanfeliu (a), \u201cFunction-Described Graphs applied to 3D object\nrecognition\u201d. Proceedings ICIAP\u201997, 9th Int. Conf. Image Analysis and Processing, Firenze, Italy, Vol. I, pp. 701-708, 1997. 97. F. Serratosa and A. Sanfeliu (b), \u201cFunction-Described Graphs\u201d. Proceedings\nNSPRIA\u201997, 7 th National Symposium on Pattern Recognition and Image Analysis, Barcelona, Spain, Vol. I, pp. 37-42, 1997. 98. F. Serratosa, A. Sanfeliu and R. Alquezar, \u201cFunction-described graphs: Distance\nand matching\u201d. Technical Report IRI-DT-9803, Universitat Polit\u00e8cnica de Catalunya, Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona, 1998. 99. F. Serratosa, A. Sanfeliu, and R. Alqu\u00e9zar (a), \u201cFunction-Described Graphs: A\nmeasure of similarity based on probabilities\u201d. Proceedings NSPRIA\u201999, 8th National Symposium on Pattern Recognition and Image Analysis, Bilbao, Spain, Vol. I, pp. 421-428, 1999. 100. F. Serratosa, A. Sanfeliu and R. Alqu\u00e9zar (b), \u201cFunction-described graphs: an\nimprovement on random graphs\u201d. Proceedings SIARP\u201999, IV Simposium Iberoamericano de Reconocimiento de Patrones, La Habana, Cuba, pp. 655-665, 1999.\n- 176 -\n101. L. Shapiro and R.M. Haralick, \u201cA metric for comparing relational descriptions\u201d,\nIEEE Transactions on Pattern Analysis and Machine Intelligence, vol 7, pp. 90-94, 1985. 102. K.R. Shearer, \u201cIndexing and retrieval of video using spatial reasoning\ntechniques\u201d, PhD thesis, Curtin University of Technology, Perth, Australia, 1998.\n103. K.C. Tai, \"The tree to tree correction problem\", Journal of the Association for\nComputing Machinery, vol. 26, pp. 422-433, 1979.\n104. E. Tanaka and T. Kasai, \"Synchronisation and substitution error-correcting\ncodes for the Levenshtein metric\", IEEE Transactions on Information Theory, vol. 22, pp. 156-162, 1976. 105. E. Tanaka, \u201cA metric on graphs and its applications\u201d, IEE Japan, IP-77-55, vol.\n31, 1977.\n106. W.H. Tsai and K.S. Fu, \u201cError-correcting isomorphism of attributed relational\ngraphs for pattern analysis\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 9, pp. 757-768, 1979. 107. J.R. Ullman, \u201cAn algorithm for sub-graph isomorphism\u201d, Journal of the\nAssociation for Computing Machinery, vol. 23, pp. 31-42, 1976.\n108. S. Umeyama, \u201cAn eigendecomposition approach to wighted graph matching\nproblems\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 10, pp: 695-703, 1988. 109. J. Verg\u00e9s-Lah\u00ed, A. Sanfeliu, F. Serratosa and R. Alqu\u00e9zar, \u201cFace recognition:\nGraph matching versus neural techniques\u201d. In Proceedings NSPRIA\u201999, 8th National Symposium on Pattern Recognition and Image Analysis, Bilbao, Spain, Vol. I, pp. 259-266, 1999. 110. J. Verg\u00e9s-Lah\u00ed and A. Sanfeliu, \u201cColour image segmentation solving hard-\nconstraints on graph partitioning greedy algorithms\u201d. In Proceedings 15th International Conference on Pattern Recognition, ICPR\u20192000, Barcelona, Spain, 2000. 111. T. Vlachos and A.G. Constantinides, \u201cGraph-Theoretical Approach to Colour\nPicture Segmentation and Contour Classification\u201d, IEE Proceedings, Part I, Vol. 140, No. 1, pp. 36-45, 1993.\n- 177 -\n112. R.A. Wagner and M.J. Fischer, \u201cThe string-to-string correction problem\u201d,\nJournal of Association for Computing Machinery, vol. 21, pp: 168-173, 1974.\n113. H. Walischewski, \u201cAutomatic knowledge acquisition for spatial document\ninterpretation\u201d, Proceedings of 4th ICDAR, Ulm, pp. 243-247, 1997.\n114. A.M. Wallace, \u201cA comparison of approaches to high-level image interpretation\u201d,\nPattern Recognition, vol. 21, pp. 241-259, 1988.\n115. R.S. Wallace and T. Kanade, \u201cFinding natural clusters having minimum\ndescription length\u201d, Proceedings in pattern recognition, pp. 438-442, 1990.\n116. Y.K. Wang, K.C. Fan and J.T. Horng, \u201cGenetic-based search for error-correcting\ngraph isomorphism\u201d, IEEE Transactions on Systems Man and Cybernetics, vol. 27, pp. 588-597, 1997. 117. R.C. Wilson, Inexact graph matching using symbolic constraints, Ph.D. thesis\ndissertation, University of York, 1997.\n118. R.C. Wilson and E.R. Hancock, \u201cStructural matching by discrete relaxation\u201d,\nIEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 19, pp. 634- 648, 1997. 119. E.K. Wong, \u201cThree-dimensional object recognition by attributed graphs\u201d, H.\nBunke and A. Sanfeliu, editors, Syntactic and Structural Pattern RecognitionTheory and Applications, World Scientific, pp: 381-414, 1990. 120. E.K. Wong, \u201cModel matching in robot vision by sub-graph isomorphism\u201d,\nPattern Recognition, vol. 25, pp: 287-304, 1992.\n121. A.K.C. Wong, J. Constant and M. You, \u201cRandom Graphs\u201d, Syntactic and\nStructural Pattern Recognition: Theory and Applications, H.Bunke and A.Sanfeliu (eds.), World Scientific, pp. 197-234, 1990. 122. A.W. Wong, S.W. Lu and M. Rioux, \u201cRecognition and shape synthesis of 3D\nobjects based on attributed graphs\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 11, pp: 279-290, 1989. 123. A.K.C. Wong and M. You, \u201cEntropy and distance of random graphs with\napplication to structural pattern recognition\u201d, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 7, pp. 599-609, 1985.\n- 178 -\n124. A.K.C. Wong, M. You and S.C. Chan, \u201cAn algorithm for graph optimal\nmonomorphism\u201d, IEEE Transactions on Systems, Man and Cybernetics, vol. 20, pp. 628-636, 1990. 125. Z. Wu and R. Leahy, \u201cAn Optimal Graph Theoretic Approach to Data\nClustering: Theory and Its Application to Image Segmentation\u201d, IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol. 15, No. 11, pp. 1101-1113, 1993. 126. L. Xu and E. Oja, \u201cImproved Simulated annealing, Botzmann machine and\nattributed graph matching\u201d, Lecture notes in computer science, Almeida editor, vol. 412, pp. 151-161, 1990. 127. Y. Xu and E.C. Uberbacher, \u201c2D Image segmentation Using Minimum\nSpanning Trees\u201d, Image and Vision Computing, No. 15, pp. 47-57, 1997.\n128. S.W. Zucker, R.A. Hummel and A. Rosenfeld, \u201cAn application of relaxation\nlabelling to line and curve enhancement\u201d, IEEE Transactions on Computers, vol. 26, pp. 394-403, 1977."}], "references": [{"title": "Duffuaa, \u201cA linear programming approach for the weighted graph matching problem", "author": ["S.O.H.A. Almohamad"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Synthesis of Function-Described Graphs", "author": ["R. Alqu\u00e9zar", "A. Sanfeliu", "F. Serratosa"], "venue": "Advances in Pattern Recognition, Proc. Joint IAPR Int. Workshops SSPR\u201998 and SPR\u201998,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Distance measures between Attributed Graphs and Function-Described Graphs relaxing 2 order constraints", "author": ["R. Alqu\u00e9zar", "F. Serratosa", "A. Sanfeliu"], "venue": "Syntactic and Structural Pattern Recognition,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Moderately exponential boud for graph isomorphism", "author": ["L. Babai"], "venue": "Lecture notes in computer sicence: Fundamentals of computation theory,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1981}, {"title": "A general momement-invariants/AttributedGraph method for three-dimensional object recognition from single image", "author": ["B. Bamieh", "R.J.P. De Figueiredo"], "venue": "IEEE Journal of Robotics and Automation,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1986}, {"title": "Subgraph isomorphism, matching relational structures and maximal cliques", "author": ["H.G. Barrow", "R.M Burstall"], "venue": "Information Processing Letters,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1976}, {"title": "A Backtracking procedure for isomorphism of directed graphs", "author": ["A.T. Berztiss"], "venue": "Journal of the Association for computing machinery,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1973}, {"title": "TRIPLE: A multi-strategy machine learning approach to target recognition", "author": ["B. Bhanu", "J.C. Ming"], "venue": "Image understanding workshop,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1988}, {"title": "Partitioning graph matching with constraints", "author": ["R.E. Blake"], "venue": "Pattern Recognition,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "Aspect graph: an introduction and survey of recent results", "author": ["K.W. Bowyer", "C.R. Dyer"], "venue": "International Journal Imaging System and Technology,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1990}, {"title": "Spillane, \u201cA parallel genetic heuristic for the quadratic assignment problem", "author": ["D.E. Brown", "A.R.C.L. Huntley"], "venue": "Genetic algorithms,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1989}, {"title": "Structural and syntactic pattern recognition\u201d, Handbook of Pattern Recognition and Computer Vision, World", "author": ["H. Bunke"], "venue": "Scientific Publ. Co., Singapore,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1993}, {"title": "Error-tolerant graph matching: a formal framework and algorithms", "author": ["H. Bunke"], "venue": "Advances in Pattern Recognition, Proceedings Joint IAPR Int. Workshops SSPR\u201998 and SPR\u201998,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Recent advances in graph matching", "author": ["H. Bunke", "B. Messmer"], "venue": "International Journal in Pattern Recognition and Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1997}, {"title": "Learning templates from fuzzy examples in structural pattern recognition", "author": ["K.P. Chan"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Interval-valued fuzzy hypergraphs and fuzzy partition", "author": ["S.M Chen"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1997}, {"title": "A robot vision system for recognising 3D objects in loworder polynomial time", "author": ["C.H. Chen", "A.C. Kak"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1989}, {"title": "Image recognition by matching relational structures", "author": ["J.K. Cheng", "T.S. Huang"], "venue": "IEEE Conference on Pattern Recognition and Image Processing,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1981}, {"title": "Recognising 3-D objects by forward checking constrained tree search", "author": ["C.J. Cho", "J.J. Kim"], "venue": "Pattern Recognition Letters,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1992}, {"title": "Structural matching in computer vision using probabilistic relaxation", "author": ["W.J. Christmas", "J. Kittler", "M. Petrou"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "An improved algorithm for relational distance graph matching", "author": ["L. Cinque", "D. Yasuda", "L.G. Shapiro", "S. Tanimoto", "B. Allen"], "venue": "Pattern Recognition,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1996}, {"title": "Sub-structure discovery using minimum description length and background knowledge", "author": ["D.J. Cook", "L.B. Holder"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1994}, {"title": "An efficient algorithm for graph isomorphism", "author": ["D.G. Corneil", "C.C. Gotlieb"], "venue": "Journal of the Association for computing machinery,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1970}, {"title": "Gaph matching with a dual-step EM algorithm", "author": ["A. Cross", "E. Hancock"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1998}, {"title": "Genetic search for structural matching\u201d, Computer Vision- FCCV\u201996, Lecture notes in computer sicence 1064", "author": ["A. Cross", "R. Wilson", "E. Hancock"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1996}, {"title": "Spears, \u201cUsing genetic algorithms to solve NP-complete problems\u201d, J.D", "author": ["W.M.K.A. De Jong"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1989}, {"title": "Graph matching using a direct classification of node attendance", "author": ["F. Depiero", "M. Trivedi", "S. Serbin"], "venue": "Pattern Recognition,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}, {"title": "Introduction to graph grammars with applications to semantic networks", "author": ["H. Ehrig"], "venue": "Computers and Mathematics with Applications,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1992}, {"title": "A graph distance measure for image analysis", "author": ["M.A. Eshera", "K.S. Fu"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1984}, {"title": "The structure-mapping engine: Algorithms and examples", "author": ["B. Falkhenhainer", "K.D. Forbus", "D. Gentner"], "venue": "Artificial Intelligence,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1990}, {"title": "Price, \"Semantic labelling of Aerial Images using Stochastic Relaxation", "author": ["K.E.O.D. Faugeras"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1981}, {"title": "Image Segmentation Using Local Variation", "author": ["P.F. Felzenswalb", "D.P. Huttenlocher"], "venue": "Proc. of the IEEE Computer Soc. Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1998}, {"title": "Inexact matching using neural networks\", Pattern recognition in practice IV: Multiple paradigms, comparative studies and hybrid systems", "author": ["J. Feng", "M. Laumy", "M. Dhome"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1994}, {"title": "Knowledge acquisition via incremental conceptual clustering", "author": ["D.H. Fisher"], "venue": "Machine learning,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1987}, {"title": "A structural graph matching approach to image understanding\u201d, SPIE, Intelligent robots and computer vision X: Algorithms and techniques 1607", "author": ["G.P. Ford", "J. Zhang"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1991}, {"title": "Tree systems for syntactic pattern recognition", "author": ["K.S. Fu", "B.K. Bhargava"], "venue": "IEEE Transactions on Computers,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1973}, {"title": "Computers and intractability: A guide to the theory of NP-Completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1979}, {"title": "Further annotated bibliography on the isomorphism disease", "author": ["G. Gati"], "venue": "Journal of Graph Theory,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1979}, {"title": "Efficient computing and representing aspect graph of polyhedral objects", "author": ["Z. Gigus", "J.F. Cany", "R. Seidel"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1991}, {"title": "Computing the aspect graph for line drawings of polyhedral objects", "author": ["Z. Gigus", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1990}, {"title": "3D object recognition based on sub-graph matching in polynomial time", "author": ["E. Gmuer", "H. Bunke"], "venue": "Structural Pattern Analysis, World Scientific,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1990}, {"title": "A graduated assignment algorithm for graph mathcing", "author": ["S. Gold", "A. Rangarajan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1996}, {"title": "Efficient dynamic programming alignment of cyclic strings by shift elimination", "author": ["J. Gregor", "M.G. Thomason"], "venue": "Pattern Recognition,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1996}, {"title": "Discrete relaxation", "author": ["E.R. Hancock", "J. Kittler"], "venue": "Pattern Recognition,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1990}, {"title": "An interpretation for probabilistic relaxation", "author": ["R.M. Haralick"], "venue": "Computer vision, Graphics and Image Processing,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1983}, {"title": "Increasing tree search efficiency for constraint satisfaction problems", "author": ["R.M. Haralick", "G.L. Elliot"], "venue": "Artificial Intelligence, Elveiser,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 1980}, {"title": "Niez, \"Symbolic image matching by simulated annealing", "author": ["L. Herault", "R. Horaud", "J.J.F. Veillon"], "venue": "British machine vision conference,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1990}, {"title": "Group-theoretic algorithms and graph isomorphism", "author": ["C.M. Hoffman"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1982}, {"title": "Linear time algorithm for isomorphism of planar graphs", "author": ["J.E. Hopcroft", "J.K. Wong"], "venue": "Annual ACM syposium on theory of computing,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1974}, {"title": "Structural matching for stereo vision", "author": ["R. Horaud", "T. Skordas"], "venue": "Internatinal Conference on Pattern Recognition,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1988}, {"title": "Stereo correspondence through feature grouping and maximal cliques", "author": ["R. Horaud", "T. Skordas"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1989}, {"title": "Skordas, \u201cFinding geometric and relational structures in an image", "author": ["R. Horaud", "T.F. Veillon"], "venue": "Proceedings of 1 European Conference on Computer Vision,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1990}, {"title": "On the foundations of relaxation labelling processes", "author": ["R.A. Hummel", "S.W. Zucker"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1983}, {"title": "3D-object recognition using bipartite matching embedded in discrete relaxation", "author": ["W.Y. Kim", "A.C. Kak"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 1991}, {"title": "Discrete relaxation for matching relational structures", "author": ["L. Kitchen", "A. Rosenfeld"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 1979}, {"title": "Probabilistic relaxation for matching problems in machine vision", "author": ["J. Kittler", "W.J. Christmas", "M. Petrou"], "venue": "Proceedings 4 International Conference on Computer Vision,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 1993}, {"title": "Combining evidence in probabilistic relaxation", "author": ["J. Kittler", "E.R. Hancock"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 1989}, {"title": "Maintaining reversible DAC for MaxCSP", "author": ["J. Larrosa", "P. Meseguer", "T. Schiex"], "venue": "Artificial Intelligence, vol. 107,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 1999}, {"title": "Introducing the reduced aspect graphs", "author": ["A. Laurentini"], "venue": "Pattern Recognition Letters, vol. 16,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 1995}, {"title": "Attributed stroke graph matching for seal imprint verification", "author": ["S.W. Lee", "J.H. Kim"], "venue": "Pattern Recognition Letters,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 1989}, {"title": "Translation-rotation-and scale invariant recognition of hand-drawn symbols in schematic diagrams", "author": ["S.W. Lee", "J.H. Kim", "F.C.A. Groen"], "venue": "International Journal of Pattern Recognition and Artificial Intelligence,", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 1990}, {"title": "Hierarchical reduction and partition of hypergraphs", "author": ["H. Lee-Kwang", "C.H. Cho"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 1996}, {"title": "Binary codes capable of correcting deletions, insertions and reversals", "author": ["V.I. Levenshtein"], "venue": "Soviet Physics Doklady, Cybernetics and Control Theory,", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1966}, {"title": "A note on the derivation of maximal common subgraphs of two directed or indirected graphs", "author": ["G. Levi"], "venue": "Calcolo, vol", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 1972}, {"title": "A biologically plausible model for corner based object recognition from colour images", "author": ["T. Lourens"], "venue": "PhD thesis,", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 1998}, {"title": "A tree-matching algorithm based on node splitting and merging", "author": ["S.Y. Lu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 1984}, {"title": "Hierarchical attributed graphs representation and recognition of handwritten Chinese characters", "author": ["S.W. Lu", "Y. Ren", "C.Y. Suen"], "venue": "Pattern Recognition,", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 1991}, {"title": "Isomorphism of graphs of bounded valence can be tested in polynomial time", "author": ["E.M. Luks"], "venue": "Journal of computer ans system sciences,", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 1982}, {"title": "On a cyclic string-to-string correction problem", "author": ["M. Maes"], "venue": "Information Processing Letters,", "citeRegEx": "71", "shortCiteRegEx": "71", "year": 1990}, {"title": "Backtrack search algorithms and the maximal common subgraph problem", "author": ["F. Mc Gregor"], "venue": "Software-Practice and Experience,", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 1982}, {"title": "A neural algorithm to solve the graph matching problem", "author": ["S. Mehta", "L. Fulop"], "venue": "Proceedings of International neural network conference,", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 1990}, {"title": "Computer oriented approaches to pattern recognition", "author": ["W.S. Meisel"], "venue": "Academic press,", "citeRegEx": "74", "shortCiteRegEx": "74", "year": 1972}, {"title": "Efficient error-tolerant subgraph isomorphism detection\u201d, Shape, Structure and Pattern Recognition, D.Dori and A", "author": ["B.T. Messmer", "H. Bunke"], "venue": "Bruckstein (eds.), World Scientific,", "citeRegEx": "75", "shortCiteRegEx": "75", "year": 1994}, {"title": "Automatic learning and recognition of graphical symbols in engineering drawings", "author": ["B.T. Messmer", "H. Bunke"], "venue": "Graphics recognition, Lecutre notes in computes science", "citeRegEx": "76", "shortCiteRegEx": "76", "year": 1996}, {"title": "Conceptual graph matching: A flexible algorithm and experiments", "author": ["S.H. Myaeng", "A. Lopez-Lopez"], "venue": "Journal of experimental and theoretical artificial intelligence,", "citeRegEx": "77", "shortCiteRegEx": "77", "year": 1992}, {"title": "Analysis of relaxation processes: The two-node label case", "author": ["D.P. O'leary", "S. Peleg"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "78", "shortCiteRegEx": "78", "year": 1983}, {"title": "A Review on Image Segmentation Techniques", "author": ["N.K. Pal", "S.K. Pal"], "venue": "Pattern Recognition,", "citeRegEx": "79", "shortCiteRegEx": "79", "year": 1993}, {"title": "Rulegraphs for graph matching in pattern recognition", "author": ["A. Pearce", "T. Caelli", "W.F. Bischof"], "venue": "Pattern Recognition,", "citeRegEx": "80", "shortCiteRegEx": "80", "year": 1994}, {"title": "Determining compatibility coefficients for curve enchancement relaxation processes", "author": ["S. Peleg", "A. Rosenfeld"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "81", "shortCiteRegEx": "81", "year": 1978}, {"title": "Similarity in legal case based reasoning as degree of matching in conceptual graphs", "author": ["J. Poole"], "venue": null, "citeRegEx": "82", "shortCiteRegEx": "82", "year": 1993}, {"title": "The graph isomorphism disease", "author": ["R.C. Read", "D.G. Corneil"], "venue": "Journal of Graph Theory,", "citeRegEx": "83", "shortCiteRegEx": "83", "year": 1977}, {"title": "Unsupervised synthesis of Function-Described Graphs", "author": ["D. Ria\u00f1o", "F. Serratosa"], "venue": "Proceedings of the 2  ond Workshop on Graph Based Representations, Vienna,", "citeRegEx": "84", "shortCiteRegEx": "84", "year": 1999}, {"title": "Scene labeling by relaxation operators", "author": ["A. Rosenfeld", "R.A. Hummel", "S.W. Zucker"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 1976}, {"title": "Chemical applications of graph theory", "author": ["D.H. Rouvray", "A.T. Balaban"], "venue": "editors, Applications of Graph Theory,", "citeRegEx": "86", "shortCiteRegEx": "86", "year": 1979}, {"title": "Scene labelling by relaxation operations", "author": ["A. Rosenfeld", "R.A. Hummel", "S.W. Zucker"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "87", "shortCiteRegEx": "87", "year": 1976}, {"title": "A distance measure between attributed relational graphs for pattern recognition", "author": ["A. Sanfeliu", "K. Fu"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "88", "shortCiteRegEx": "88", "year": 1983}, {"title": "Druffel, \u201cA fast backtracking algorithm to test directed graphs for isomorphism using distance matrices", "author": ["L.E.D.C. Schmidt"], "venue": "Journal of the Association for computing machinery,", "citeRegEx": "90", "shortCiteRegEx": "90", "year": 1976}, {"title": "Function-Described Graphs for structural pattern recognition", "author": ["F. Serratosa", "R. Alqu\u00e9zar", "A. Sanfeliu (c"], "venue": "Submitted to Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "93", "shortCiteRegEx": "93", "year": 1999}, {"title": "a), \u201cEfficient algorithms for matching attributed graphs and function-described graphs", "author": ["F. Serratosa", "R. Alqu\u00e9zar", "A. Sanfeliu"], "venue": "In Proceedings 15 International Conference on Pattern Recognition,", "citeRegEx": "95", "shortCiteRegEx": "95", "year": 2000}, {"title": "Function-Described Graphs applied to 3D object recognition", "author": ["F. Serratosa", "A. Sanfeliu"], "venue": "Proceedings ICIAP\u201997, 9 Int. Conf. Image Analysis and Processing, Firenze, Italy,", "citeRegEx": "96", "shortCiteRegEx": "96", "year": 1997}, {"title": "Function-described graphs: Distance and matching", "author": ["F. Serratosa", "A. Sanfeliu", "R. Alquezar"], "venue": "Technical Report IRI-DT-9803, Universitat Polite\u0300cnica de Catalunya, Institut de Robo\u0300tica i Informa\u0300tica Industrial,", "citeRegEx": "98", "shortCiteRegEx": "98", "year": 1998}, {"title": "Function-Described Graphs: A measure of similarity based on probabilities", "author": ["F. Serratosa", "A. Sanfeliu", "R. Alqu\u00e9zar"], "venue": "Proceedings NSPRIA\u201999,", "citeRegEx": "99", "shortCiteRegEx": "99", "year": 1999}, {"title": "A metric for comparing relational descriptions", "author": ["L. Shapiro", "R.M. Haralick"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "101", "shortCiteRegEx": "101", "year": 1985}, {"title": "Indexing and retrieval of video using spatial reasoning techniques", "author": ["K.R. Shearer"], "venue": "PhD thesis, Curtin University of Technology, Perth, Australia,", "citeRegEx": "102", "shortCiteRegEx": "102", "year": 1998}, {"title": "The tree to tree correction problem", "author": ["K.C. Tai"], "venue": "Journal of the Association for Computing Machinery,", "citeRegEx": "103", "shortCiteRegEx": "103", "year": 1979}, {"title": "Synchronisation and substitution error-correcting codes for the Levenshtein metric", "author": ["E. Tanaka", "T. Kasai"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "104", "shortCiteRegEx": "104", "year": 1976}, {"title": "A metric on graphs and its applications", "author": ["E. Tanaka"], "venue": "IEE Japan,", "citeRegEx": "105", "shortCiteRegEx": "105", "year": 1977}, {"title": "Error-correcting isomorphism of attributed relational graphs for pattern analysis", "author": ["W.H. Tsai", "K.S. Fu"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "106", "shortCiteRegEx": "106", "year": 1979}, {"title": "An algorithm for sub-graph isomorphism", "author": ["J.R. Ullman"], "venue": "Journal of the Association for Computing Machinery,", "citeRegEx": "107", "shortCiteRegEx": "107", "year": 1976}, {"title": "An eigendecomposition approach to wighted graph matching problems", "author": ["S. Umeyama"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "108", "shortCiteRegEx": "108", "year": 1988}, {"title": "Colour image segmentation solving hardconstraints on graph partitioning greedy algorithms", "author": ["J. Verg\u00e9s-Lah\u00ed", "A. Sanfeliu"], "venue": "In Proceedings 15 International Conference on Pattern Recognition,", "citeRegEx": "110", "shortCiteRegEx": "110", "year": 2000}, {"title": "Graph-Theoretical Approach to Colour Picture Segmentation and Contour Classification", "author": ["T. Vlachos", "A.G. Constantinides"], "venue": "IEE Proceedings, Part I,", "citeRegEx": "111", "shortCiteRegEx": "111", "year": 1993}, {"title": "The string-to-string correction problem", "author": ["R.A. Wagner", "M.J. Fischer"], "venue": "Journal of Association for Computing Machinery,", "citeRegEx": "112", "shortCiteRegEx": "112", "year": 1974}, {"title": "Automatic knowledge acquisition for spatial document interpretation", "author": ["H. Walischewski"], "venue": "Proceedings of 4 ICDAR,", "citeRegEx": "113", "shortCiteRegEx": "113", "year": 1997}, {"title": "A comparison of approaches to high-level image interpretation", "author": ["A.M. Wallace"], "venue": "Pattern Recognition,", "citeRegEx": "114", "shortCiteRegEx": "114", "year": 1988}, {"title": "Finding natural clusters having minimum description length", "author": ["R.S. Wallace", "T. Kanade"], "venue": "Proceedings in pattern recognition,", "citeRegEx": "115", "shortCiteRegEx": "115", "year": 1990}, {"title": "Genetic-based search for error-correcting graph isomorphism", "author": ["Y.K. Wang", "K.C. Fan", "J.T. Horng"], "venue": "IEEE Transactions on Systems Man and Cybernetics,", "citeRegEx": "116", "shortCiteRegEx": "116", "year": 1997}, {"title": "Inexact graph matching using symbolic constraints", "author": ["R.C. Wilson"], "venue": "Ph.D. thesis dissertation, University of York,", "citeRegEx": "117", "shortCiteRegEx": "117", "year": 1997}, {"title": "Structural matching by discrete relaxation", "author": ["R.C. Wilson", "E.R. Hancock"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "118", "shortCiteRegEx": "118", "year": 1997}, {"title": "Three-dimensional object recognition by attributed graphs", "author": ["E.K. Wong"], "venue": "Syntactic and Structural Pattern RecognitionTheory and Applications, World Scientific,", "citeRegEx": "119", "shortCiteRegEx": "119", "year": 1990}, {"title": "Model matching in robot vision by sub-graph isomorphism", "author": ["E.K. Wong"], "venue": "Pattern Recognition,", "citeRegEx": "120", "shortCiteRegEx": "120", "year": 1992}, {"title": "Recognition and shape synthesis of 3D objects based on attributed graphs", "author": ["A.W. Wong", "S.W. Lu", "M. Rioux"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "122", "shortCiteRegEx": "122", "year": 1989}, {"title": "Entropy and distance of random graphs with application to structural pattern recognition", "author": ["A.K.C. Wong", "M. You"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "123", "shortCiteRegEx": "123", "year": 1985}, {"title": "An algorithm for graph optimal monomorphism", "author": ["A.K.C. Wong", "M. You", "S.C. Chan"], "venue": "IEEE Transactions on Systems, Man and Cybernetics,", "citeRegEx": "124", "shortCiteRegEx": "124", "year": 1990}, {"title": "An Optimal Graph Theoretic Approach to Data Clustering: Theory and Its Application to Image Segmentation", "author": ["Z. Wu", "R. Leahy"], "venue": "IEEE Trans. on Pattern Analysis and Machine Intelligence,", "citeRegEx": "125", "shortCiteRegEx": "125", "year": 1993}, {"title": "Improved Simulated annealing, Botzmann machine and attributed graph matching", "author": ["L. Xu", "E. Oja"], "venue": "Lecture notes in computer science, Almeida editor,", "citeRegEx": "126", "shortCiteRegEx": "126", "year": 1990}, {"title": "Uberbacher, \u201c2D Image segmentation Using Minimum Spanning Trees", "author": ["E.C.Y. Xu"], "venue": "Image and Vision Computing,", "citeRegEx": "127", "shortCiteRegEx": "127", "year": 1997}], "referenceMentions": [], "year": 2007, "abstractText": "A fundamental problem in pattern recognition is selecting suitable representations for objects and classes. In the decision-theoretic approach to pattern recognition, a pattern is represented by a set of numerical values, which forms a feature vector. Although, in many tasks, objects can be recognised successfully using only global features such as size and compactness, in some applications it is helpful to describe an object in terms of its basic parts and the relations between them. Nevertheless, there are two major problems that practical applications using structural pattern recognition are confronted with. The first problem is the computational complexity of comparing two structures. The time required by any of the optimal algorithms may in the worst case become exponential in the size of the graphs. The approximate algorithms, on the other hand, have only polynomial time complexity, but do not guarantee to find the optimal solution. For some of the applications, this may not be acceptable. The second problem is the fact that there is more than one model graph that must be matched with an input graph, then the conventional graph matching algorithms must be applied to each model-input pair sequentially. As a consequence, the performance is linearly dependent on the size of the database of model graphs. For applications dealing with large database, this may be prohibitive. Function-described graphs (FDGs) are a compact representation of a set of attributed graphs. They have borrowed from \u201crandom graphs\u201d proposed by Wong et al. the ability to probabilistically model structural attribute information, while improving the capacity to record structural relationships that consistently appear throughout the data. They do this by incorporating qualitative knowledge of the second-order probabilities of the elements that are expressed as relations (Boolean functions) between pairs of vertices and pairs of arcs in the FDGs. Four approaches and algorithms for building FDGs from an ensemble of attributed graphs are presented. The first synthesises an FDG in a supervised manner. The other three use the supervised clustering algorithms: dynamic, complete and single clustering. The problem of matching attributed graphs (AGs) to FDGs for recognition or classification purposes is studied from a Bayesian perspective. A distance measure between AGs and FDGs is derived from the principle of maximum likelihood, but robustness is enforced by considering only locally the effects of extraneous and missing elements. A second measure is also given in which the second-order constraints are incorporated as additional costs. A branch-and-bound algorithm is proposed to compute these distance measures together with their corresponding optimal labelling. Because of the exponential cost of this algorithm, three efficient algorithms are also proposed and compared to compute sub-optimal distances between AGs and FDGs. Two of them are based on a probabilistic relaxation approach, and the other does not have an iterative technique. Some experimental tests are presented in random graphs and a 3D-object recognition problem. In the 3D-object recognition application, an FDG model is synthesised (in a supervised and an unsupervised method) for each object from a set of views (AGs). The second-order information in FDGs is shown so that the recognition ration is better than when the first-order probability distributions are only used. Results of efficient algorithms show that there is an important decrease in the run time although there is only a slight decrease in effectiveness.", "creator": "PScript5.dll Version 5.2.2"}}}