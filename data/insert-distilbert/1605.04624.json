{"id": "1605.04624", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "Learning to Rank Personalized Search Results in Professional Networks", "abstract": "where linkedin search is deeply personalized - for only the same queries, different searchers expect completely identical different results. this paper presents our approach to achieving half this by mining various complementary data sources available in linkedin to infer searchers'intents ( such as hiring, job mobility seeking, etc. ), as well as extending the concept description of homophily to capture the searcher - result similarities on many aspects. then, learning - to - rank ( ltr ) is eventually applied to combine these signals with non standard google search features.", "histories": [["v1", "Mon, 16 May 2016 00:59:07 GMT  (531kb,D)", "http://arxiv.org/abs/1605.04624v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["viet ha-thuc", "shakti sinha"], "accepted": false, "id": "1605.04624"}, "pdf": {"name": "1605.04624.pdf", "metadata": {"source": "CRF", "title": "Learning to Rank Personalized Search Results in Professional Networks", "authors": ["Viet Ha-Thuc", "Shakti Sinha"], "emails": ["vhathuc@linkedin.com", "ssinha@linkedin.com"], "sections": [{"heading": "1. INTRODUCTION", "text": "LinkedIn has evolved over past few years to become a platform containing various professional information sources - including 400+ million member profiles, 6+ million active jobs, millions of professional groups and 18+ million presentations. As the number of sources and their document volumes increase, the problem of serving the right results to fulfill each individual information need becomes increasingly challenging. Moreover, compared to typical information retrieval systems (such as generic Web search), LinkedIn search is deeply personalized. For instance, if a member enters the query \u201csoftware engineer\u201d, depending on whether he or she is a recruiter, job seeker or professional content consumer, the member expects to see very different results: software engineers\u2019 profiles, software engineer jobs or slideshows on the topic, respectively. Even within a single vertical like Job search, for the query above, if the searcher happens to be an information retrieval expert, he or she is much more likely to be interested in software engineer jobs related to the field rather than software engineer jobs focusing on, say, software QA. For these reasons, we use rich information from the professional network - such as the searchers\u2019 identity, profile, network and behavior - to understand their interests and intent, and serve a deeply personalized, relevant search experience.\nWith this context, we present our approach to personalize search ranking, leveraging the information available on\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). SIGIR \u201916 July 17-21, 2016, Pisa, Italy c\u00a9 2016 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-4069-4/16/07.\nDOI: http://dx.doi.org/10.1145/2911451.2927018\nLinkedIn. At the vertical level, we extend the concept of homophily to construct personalized features. Traditionally, the main idea of homophily is that in a social network, people tend to connect or interact with similar people. In the context of LinkedIn, we hypothesize that searchers tend to be interested in results similar or related to them. For example, in People search, searchers are often interested in people in the same or similar industries or companies and people with similar expertise. In Job search, searchers are usually interested in jobs at similar companies, jobs at nearby locations and jobs requiring expertise similar to their own. In particular, for expertise homophily, we propose an approach incorporating members\u2019 profiles, skill-endorsement graphs and skill co-occurrence patterns to estimate their expertise scores for the skills listed on their profiles, as well as the skills we infer they have. To combine these personalized features with traditional IR features, we apply LTR techniques to learn ranking functions.\nGiven results from multiple verticals, a federated model blends them into a single search result page. To personalize the federated model, we mine members\u2019 profiles and their recent activities at a large scale to understand their intents, such as, hiring intent, job seeking intent or content consuming intent, etc. Then, the federated model is learnt to couple this insight with other signals, including the ones from verticals, to select verticals and to aggregate vertical results into a single ranking that is personally relevant to each of our members."}, {"heading": "2. SEARCH RANKING", "text": ""}, {"heading": "2.1 Expertise Homophily", "text": "On LinkedIn, skills are an integral part of members\u2019 profiles that showcase their expertise. A challenge on estimating member expertise is that many members do not explicitly list all skills they have. To overcome this, we employ a two-step approach (Figure 1). In the first step, we use a supervised learning algorithm combining various signals on LinkedIn, such as skill-endorsement graph page rank, skillprofile textual similarity, member seniority, etc., to estimate the expertise scores, i.e., p(expert|member, skill). After this step, the expertise matrix (E0) is very sparse since we can be certain about expertise scores only for a small percentage of the pairs. In the second step, we factorize the matrix into member and skill matrices in K-dimensional latent space. Then, we compute the dot-product of the matrices to fill in the \u201cunknown\u201dcells. The intuition for this can be illustrated as follows: if a member has \u201cmachine learning\u201d and \u201cinfor-\nar X\niv :1\n60 5.\n04 62\n4v 1\n[ cs\n.I R\n] 1\n6 M\nay 2\n01 6\nmation retrieval\u201dskills, based on skill co-occurrence patterns from all of our member base, we could infer that the member is likely to also know \u201clearning-to-rank\u201d. Interested readers can refer to our recent work [3, 2] for more details. The expertise homophily is then estimated by the cosine similarity between the searcher\u2019s and results\u2019 scores."}, {"heading": "2.2 Learning", "text": "We apply an LTR approach to combine expertise homophily with more traditional search features. In deeply personalized settings like LinkedIn search, editorial judgement does not work well since result relevance strongly depends on individual searchers. Labels derived from search logs containing searchers\u2019 actions on results, on the other hand, are personalized by nature. However, the logs have both position and sample selection biases. To avoid position bias, we collect labels from a small traffic fraction that randomizes top-K results. The labeled data is then augmented with easy negatives, which are sampled from the tails of rankings to reduce sample bias. The labeled data collection approach is described in [2]."}, {"heading": "3. FEDERATION", "text": ""}, {"heading": "3.1 Overall Framework", "text": "Given a pair of (query, searcher), the federator selects a primary vertical and a set of secondary verticals, then ranks the primary individual results and the secondary vertical blocks in a single ranked list. The overall framework is described in Figure 2. When a member issues a query q, the query is passed to verticals and triggers the corresponding vertical search engines to get the top K results for each. In preliminary vertical selection phase, the federated scorer extracts features and computes a relevance score for each of the verticals. The top vertical is selected as the primary and the rest are selected as candidates for secondary verticals. Then, in aggregation phase, these candidates compete with individual results in the primary vertical to form the final ranking. Note that these candidates are not guaranteed to show up in the ranking. Instead, depending on queries, searchers and vertical results, all, some or none of these candidates could be selected. A critical feature used in the federated scorer is searcher intent, which is described in the next subsection."}, {"heading": "3.2 Searcher Intent", "text": "LinkedIn searchers\u2019 information needs constitute a very diverse set of intents. For instance, members actively looking\nfor jobs are likely to be more interested in job results than other verticals. Similarly, members hiring new employees should consider people results to be more important. Given this, we personalize search federation by using the searcher\u2019s profile and past activity to infer their intents. If a member\u2019s job title is recruiter, he is likely to have hiring intent. If a member recently searched for or applied to jobs, he is likely to have job seeking intent. We train machine-learned models combining all of the signals to predict intents for all searchers daily. It is worth noting that a member could have multiple intents at the same time.\nThe impact of the intents can vary significantly between different verticals. For example, knowing that a searcher has job seeking intent has much more importance for results that are jobs. We address this variation by constructing composite features, capturing both searcher intent and result type. In the example below, the feature is activated only if the searcher has job seeking intent and the result is job. We create combinations of all intents and result categories and learn their weights in our models. In essence, we let the learning algorithm associate evidence with the verticals, and normalize across all verticals from training data. More details can be found in [1].\nf =  1 if searcher has job seeking intentAND the result type is job0 otherwise"}, {"heading": "4. CONCLUSIONS", "text": "We have described how vastly differing intents for the same query arising from different searchers makes LinkedIn search unique and presented the approaches we use to personalize both vertical ranking and federation to deliver a relevant experience to all our searchers."}, {"heading": "5. REFERENCES", "text": "[1] D. Arya, V. Ha-Thuc, , and S. Sinha. Personalized\nfederated search at linkedin. In ACM CIKM, 2015.\n[2] V. Ha-Thuc, G. Venkataraman, M. Rodriguez, S. Sinha, S. Sundaram, and L. Guo. Personalized expertise search at linkedin. In IEEE Big Data, 2015.\n[3] V. Ha-Thuc, Y. Xu, S. P. Kanduri, X. Wu, V. Dialani, Y. Yan, A. Gupta, and S. Sinha. Search by ideal candidates: Next generation of talent search at linkedin. In ACM WWW, 2016."}], "references": [{"title": "Personalized federated search at linkedin", "author": ["D. Arya", "V. Ha-Thuc", "S. Sinha"], "venue": "In ACM CIKM,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Personalized expertise search at linkedin", "author": ["V. Ha-Thuc", "G. Venkataraman", "M. Rodriguez", "S. Sinha", "S. Sundaram", "L. Guo"], "venue": "In IEEE Big Data,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Search by ideal candidates: Next generation of talent search at linkedin", "author": ["V. Ha-Thuc", "Y. Xu", "S.P. Kanduri", "X. Wu", "V. Dialani", "Y. Yan", "A. Gupta", "S. Sinha"], "venue": "In ACM WWW,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "Interested readers can refer to our recent work [3, 2] for more details.", "startOffset": 48, "endOffset": 54}, {"referenceID": 1, "context": "Interested readers can refer to our recent work [3, 2] for more details.", "startOffset": 48, "endOffset": 54}, {"referenceID": 1, "context": "The labeled data collection approach is described in [2].", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "More details can be found in [1].", "startOffset": 29, "endOffset": 32}], "year": 2016, "abstractText": "LinkedIn search is deeply personalized for the same queries, different searchers expect completely different results. This paper presents our approach to achieving this by mining various data sources available in LinkedIn to infer searchers\u2019 intents (such as hiring, job seeking, etc.), as well as extending the concept of homophily to capture the searcher-result similarities on many aspects. Then, learning-to-rank (LTR) is applied to combine these signals with standard search features.", "creator": "LaTeX with hyperref package"}}}