{"id": "1605.07144", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-May-2016", "title": "Actively Learning Hemimetrics with Applications to Eliciting User Preferences", "abstract": "motivated by an application of eliciting users'preferences, we investigate the complexity problem of learning hemimetrics, i. e., pairwise distances among a set of $ n $ items that satisfy triangle inequalities and non - negativity constraints. in our application, the ( asymmetric ) distances quantify private costs a user somehow incurs when substituting one item by another. we aim to learn these distances ( costs ) by asking the users whether they are ever willing to switch from one item to another for a given incentive offer. without exploiting structural constraints of the hemimetric polytope, learning the distances between each pair of items requires $ \\ theta ( n ^ 2 ) $ queries. we propose an inexpensive active learning algorithm that theoretically substantially reduces this sample complexity by exploiting the structural constraints on the version space of hemimetrics. our proposed algorithm achieves provably - optimal sample complexity for various instances of the task. for example, when the items are embedded into $ 240 k $ tight clusters, the sample complexity analysis of our algorithm reduces to $ \u00bd o ( nk ) $. extensive experiments on a restaurant recommendation data set support the conclusions consequences of our theoretical variance analysis.", "histories": [["v1", "Mon, 23 May 2016 19:21:35 GMT  (1280kb,D)", "https://arxiv.org/abs/1605.07144v1", "Extended version of ICML'16 paper"], ["v2", "Fri, 27 May 2016 17:45:26 GMT  (2585kb,D)", "http://arxiv.org/abs/1605.07144v2", "Extended version of ICML'16 paper"]], "COMMENTS": "Extended version of ICML'16 paper", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["adish singla", "sebastian tschiatschek", "andreas krause 0001"], "accepted": true, "id": "1605.07144"}, "pdf": {"name": "1605.07144.pdf", "metadata": {"source": "META", "title": "Actively Learning Hemimetrics  with Applications to Eliciting User Preferences", "authors": ["Adish Singla", "Sebastian Tschiatschek", "Andreas Krause"], "emails": ["ADISH.SINGLA@INF.ETHZ.CH", "SEBASTIAN.TSCHIATSCHEK@INF.ETHZ.CH", "KRAUSEA@ETHZ.CH"], "sections": [{"heading": "1 Introduction", "text": "Learning a distance function over a set of items or a data manifold plays a crucial role in many real-world applications. In machine learning algorithms, the distances serve as a notion of similarity (or dissimilarity) between data points and are important for various tasks such as clustering (Xing et al., 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.1 In economics, the distance function can encode the\n1We refer the interested reader to the survey by Bellet et al. (2013) for a detailed discussion of various applications. Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).\npreferences of users (e.g., buyers or sellers in a marketplace) for different items (e.g., from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; Va\u0301zquez-Gallo et al., 2014). Motivating applications. We are interested in learning the preferences of users across different choices available in a marketplace \u2014 these choices are given in the form of n (types of) items. For instance, in a restaurant recommendation system such as Yelp, the item types could correspond to restaurants abstracted by attributes such as cuisine, locality, reviews and so on. Consider a user who seeks recommendations from the system and has chosen item i (e.g., \u201cMexican restaurant in Manhattan with over 50 reviews\u201d). However, to incentivize exploration and maximize its overall utility, the marketplace may consider offering a discount to the user to instead choose item j (e.g., \u201cNewly opened fastfood restaurant in New Jersey with 0 reviews\u201d), e.g., to gather more reviews for item j. The price of the offer would clearly depend on how similar or dissimilar the choices i and j are. In general, a high dissimilarity would require the system to offer higher incentives (larger discounts). Distance function quantifying private costs. We capture the above-mentioned notion of dissimilarity by a pairwise distanceDi,j \u2014 the distanceDi,j corresponds to the private cost of a user incurred by switching from her default choice of item i to item j. We assume that the distance function D is a hemimetric, i.e., a relaxed form of a metric, satisfying only non-negativity constraints and triangle inequalities. The asymmetry in the distances (i.e., Di,j 6= Dj,i) is naturally required in our application setting \u2014 it may arise from various factors such as the underlying quality of the items (e.g., switching between a highly rated and an unreviewed restaurant). Our goal is to efficiently learn the distance functionD via interactions with the users, without assuming any knowledge of the underlying attributes that affect the users\u2019 preferences. User query and active learning. In our setting, the interactions with the users take the form of a binary labeling query, i.e., given two items i and j, and a proposed value c, the user ar X iv :1 60 5. 07 14 4v 2 [ st at .M L ] 2 7 M ay\n2 01\nprovides a positive response iff value c is at least the underlying distance Di,j , and a negative response otherwise. This query is motivated by the posted-price model used in marketplaces (Abernethy et al., 2015; Singla & Krause, 2013), where users are offered a take-it-or-leave-it price by the system, and they can accept by providing a positive response, or reject by providing a negative response. However, we are not considering the economic aspects of the query, and each query has unit cost for the algorithm. Such a feedback setting is realistic and often employed by online marketplaces where queries are posted to the users in form of surveys to seek feedback or the users who accept are awarded the actual monetary offer via a lottery. This paper is concerned with the sample complexity, i.e., the number of queries required to learnD."}, {"heading": "1.1 Our Approach and Main Contributions", "text": "A naive approach to this problem is to learn each of the n2 pairwise distances independently. However, the sample complexity of this approach is \u0398(n2). Our goal is to reduce the sample complexity by exploiting the structural constraints on the version space of hemimetrics. The main contributions of this paper are as follows: Novel metric learning framework. We propose a new learning problem in the framework of metric learning, motivated by the applications to eliciting users\u2019 preferences. The key distinctive features of our setting are: (i) the specific modality of the user queries (with natural motivation from economics), and (ii) the asymmetry of the distances learnt. Exploiting structural constraints. We develop a novel active learning algorithm LEARNHM that substantially reduces the sample complexity by exploiting the structural constraints of the hemimetric polytope. We provide tight theoretical guarantees on the sample complexity of the proposed algorithm for several natural problem instances. Practical extensions. Our algorithm extends to various important practical settings, including: (i) the online setting where the n items are not known beforehand, and rather appear over time, and (ii) the noisy setting that reflects the stochastic nature of acceptance of offers by the users."}, {"heading": "2 Problem Statement", "text": "We now formalize the problem addressed in this paper. Items A. There are n items (or types of items), denoted by the set A = {1, 2, . . . , n}. For instance, in a restaurant recommendation system such as Yelp, A could consist of types of restaurants distinguished by high-level attributes such as cuisine, locality, reviews and so on. HemimetricD\u2217. LetD be the set of bounded hemimetrics, i.e., matricesD \u2208 Rn\u00d7n that satisfy\nDi,i = 0 \u2200 i \u2208 [n], (1) Di,j \u2265 0 \u2200 i, j \u2208 [n], (2) Di,j \u2264 r \u2200 i, j \u2208 [n], and (3) Di,j \u2264 Di,k +Dk,j \u2200 i, j, k \u2208 [n], (4)\nwhere [n] = {1, 2, . . . , n} and r is the upper bound on the value. We assume that user preferences are represented by an underlying unknown hemimetric D\u2217 \u2208 D. The (asymmetric) distanceD\u2217i,j quantifies the private costs of the user for switching from item i to j. Our goal is to learnD\u2217 via interactions with the users, without assuming any knowledge of the underlying attributes that affect the user preferences. User query. A query x \u2208 X := {(i, j, c) | i, j \u2208 [n], c \u2208 [0, r]} to the user is characterized by the tuple (i, j, c), where item i denotes the choice of the user, item j denotes the alternative suggested by the algorithm, and c denotes the monetary incentives offer. Note that the notion of user as used in this paper is rather generic, and could correspond to one single user or a crowd / cohort of users. User response. The response to a query (also called label) is denoted as y = Y (x), where Y : X 7\u2192 {0, 1}. A label y = 1 indicates acceptance, while y = 0 indicates rejection. We denote a labeled datapoint by z = (x, y), where x \u2208 X , and y = Y (x). In our setting the acceptance function is stochastic. It is characterized by P(Y (x) = y) and is required to satisfy the following two mild conditions related to the decision boundary atD\u2217i,j and monotonicity:\nP(Y ((i, j, c)) = 1) \u2265 0.5 iff c \u2265 D\u2217i,j , and P(Y ((i, j, c)) = 1) \u2265 P(Y ((i, j, c\u2032)) = 1) for c \u2265 c\u2032.\nFor ease of exposition of our main results, we focus on a deterministic noise-free setting in the main paper \u2014 treatment of the (more realistic) stochastic acceptance function is presented in Appendix A. In this noise-free setting, the acceptance function reduces to the threshold function\nY ((i, j, c)) = { 1 if c \u2265 D\u2217i,j , 0 otherwise.\n(5)\nObjective. This paper is concerned with the sample complexity, i.e., the number of queries required for learning the unknown hemimetric D\u2217. We consider a PAC-style setting, i.e., we aim to design an algorithm that, given positive constants ( , \u03b4), determines a hemimetric D\u0302 \u2208 D, such that with probability at least 1\u2212 \u03b4 it holds that\n\u2016D\u0302 \u2212D\u2217\u2016\u221e \u2264 , (6) i.e., |D\u0302i,j \u2212D\u2217i,j | \u2264 \u2200 i, j \u2208 [n].\nOur objective is to achieve the desired ( , \u03b4)-PAC guarantee while minimizing the number of user queries."}, {"heading": "3 Warmup: Overview of our Approach", "text": "We now present the high-level ideas behind our approach."}, {"heading": "3.1 Independent Learning: INDGREEDY", "text": "One possible way to tackle our learning problem is to learn each of the n2 pairwise distances independently. Let us fix a particular pair of items (i, j) \u2208 [n]2. Given the query modality considered in our framework, the goal of learning the distanceD\u2217i,j up to precsion is equivalent to learning a thresh-\nold function in the active-learning setting (Castro & Nowak, 2006; Settles, 2012). In terms of sample complexity, this is most effectively achieved by perfoming a binary-search over the range [0, r]. More formally, at iteration t = 0, we initialize a lower bound of D\u2217i,j to L t i,j = 0 and an upper bound to U ti,j = r. At any t > 0, we pick a value c t = 12 (L t\u22121 i,j + U t\u22121i,j ) and issue the queryx t = (i, j, ct). Then, based on the returned label yt, we update U ti,j = c t if yt = 1, otherwise we update Lti,j = c t if yt = 0. We continue querying until (U ti,j \u2212 Lti,j) \u2264 , and then output any D\u0302i,j \u2208 [Lti,j , U ti,j ] as the estimated distance. The number of queries required in the noise-free setting is given by dlog( r )e. As there are n 2 pairwise distance learning problems, the total sample complexity of this approach is n2dlog( r )e. Such an algorithm, based on independently learning the pairwise distances, also needs to pick a pair (it, jt) to query at iteration t. One policy inspired by uncertainty sampling (Settles, 2012) is to pick the pair (it, jt) with maximum uncertainty quantified by (U t\u22121i,j \u2212L t\u22121 i,j ). This policy can also be seen as to greedily minimize our objective stated in Equation 6. We call this query policy QGREEDY. At any iteration, it issues the query xt = (it, jt, ct) according to\n(it, jt) = arg max (i,j)\u2208[n]2 (U t\u22121i,j \u2212 L t\u22121 i,j ), and (7)\nct = 12 (L t\u22121 it,jt + U t\u22121 it,jt). (8)\nWe refer to the independent learning algorithm employing query policy QGREEDY as INDGREEDY."}, {"heading": "3.2 Exploiting Structural Constraints: LEARNHM", "text": "We now present our algorithm LEARNHM in Algorithm 12. Our algorithm depends on three functions LU-PROJ, QCLIQUE and GETUSERRESPONSE. A high-level description of these functions is given as follows: LU-PROJ shrinks the search space of hemimetrics by updating the lower and upper bounds from L\u0303t, U\u0303 t toLt, U t. Details are provided in Section 4. QCLIQUE is the query policy that determines the next query xt = (it, jt, ct) at iteration t given the current state of the learning process as determined by Lt\u22121 and U t\u22121. Details are provided in Section 5. GETUSERRESPONSE returns the label yt for query xt. In the deterministic noise-free setting, this label is determined by Equation 5. We also develop a robust noise-tolerant variant of GETUSERRESPONSE for the stochastic setting, discussed in Appendix A."}, {"heading": "4 LU-PROJ: Updating Bounds", "text": "We now present the details of our function LU-PROJ. The proof of Theorem 1 is given in Appendix F and the proof of Theorem 2 is given in Appendix G.\n2Algorithm 1 reduces to INDGREEDY if QCLIQUE is replaced by QGREEDY and LU-PROJ(L\u0303t, U\u0303 t) simply returns L\u0303t, U\u0303 t.\nAlgorithm 1 Our Algorithm: LEARNHM 1: Input: setA of n items, range r, error parameters ( , \u03b4) 2: Output: hemimetric D\u0302 3: Initialize:\niteration t = 0; labeled dataZt = \u2205 lower bounds: Lti,j = 0 \u2200 i, j \u2208 [n] upper bounds: U ti,j = r \u2200 i, j \u2208 [n]\nU ti,i = 0 \u2200 i \u2208 [n] 4: while \u2203i, j : (U ti,j \u2212 Lti,j) > do 5: t = t+ 1 6: xt = (it, jt, ct)\u2190 QCLIQUE(Lt\u22121, U t\u22121) 7: zt = ((it, jt, ct), yt) \u2190 GETUSERRESPONSE(xt) // ct = ct in the noise-free setting 8: U\u0303 t = U t\u22121, L\u0303t = Lt\u22121\n9: if yt = 1 then 10: update U\u0303 tit,jt = c t 11: else 12: update L\u0303tit,jt = c t 13: Lt, U t \u2190 LU-PROJ(L\u0303t, U\u0303 t) 14: Zt = Zt\u22121 \u222a {zt} 15: D\u0302 \u2190 U t 16: Return: hemimetric D\u0302"}, {"heading": "4.1 Valid Bounds", "text": "We begin by defining minimal conditions for the lower and upper bounds returned by LU-PROJ to be valid in terms of the version space. Let us start by formally defining the version space for our setting. In Algorithm 1, the labeled data at iteration t is given by Zt = {z1, . . . , zt} where zl = (xl, yl) for l \u2208 [t]. Then, the version space at iteration t is defined as Dt := {D \u2208 D | \u2200 l \u2208 [t] : D(xl) = yl}, (9) where D(xl) = 1(cl \u2265 Dil,jl); here 1(\u00b7) denotes the indicator function. That is,Dt \u2286 D is the set of hemimetrics at iteration t that are consistent with the labeled dataZt. Also, for given lower bounds L and upper bounds U , we define the set of hemimetrics satisfying these bounds as D(L,U) := {D \u2208 D |L \u2264 D \u2264 U}, (10) where the inequalities are understood component-wise, i.e., Li,j \u2264 Di,j \u2264 Ui,j \u2200 i, j \u2208 [n]. The bounds Lt, U t at iteration t are valid, iff D(Lt, U t) \u2287 Dt. Validity of the bounds ensures thatD\u2217 is always contained inD(Lt, U t)."}, {"heading": "4.2 Updating Bounds via Projection", "text": "We formalize the problem of obtaining the bounds Lt, U t as the solution of the following optimization problem: min U,L \u2016U \u2212 L\u20161 (P1)\ns.t. D(L,U) \u2287 Dt, where the entry-wise `1-norm of a matrix is defined as \u2016M\u20161 = \u2211 i,j |Mi,j |. The intuitive idea behind this problem is to decrease the gap between upper and lower bounds as much as possible while ensuring that the resulting bounds are valid.\nIt turns out, cf. Theorem 1, that Problem P1 can be solved in a two step process by solving the following two problems:\nU\u2217t = arg min U\u2208 D s.t. U\u2264U\u0303t \u2016U \u2212 U\u0303 t\u20161 (P2)\nL\u2217t = arg min L\u2208 L(U\u2217t) s.t. L\u2265L\u0303t \u2016L\u2212 L\u0303t\u20161, (P3)\nwhere L\u0303t, U\u0303 t are obtained by Algorithm 1 in lines 8\u201312. Here, the set L parameterized by the upper bound matrix U \u2208 D is defined as\nL(U) := {L \u2208 Rn\u00d7n | Li,i = 0, 0 \u2264 Li,j \u2264 Ui,j , (11) Li,j \u2265 max (Li,k \u2212 Uj,k, Lk,j \u2212 Uk,i) \u2200 i, j, k \u2208 [n]}.\nAdditional details and a formal development of these sets are given in Appendix E. While the set of upper bound matrices corresponds to the setD of bounded hemimetrics, the set L(U) represents more complex dependencies. It turns out that the setL cannot be constrained to contain only hemimetrics. In fact, we provide a counter-example in Appendix E. We can now state one of our main theoretical results:\nTheorem 1. The optimal solution of Problem P1 is unique and is given byL\u2217t, U\u2217t (defined in Problems P3 and P2)."}, {"heading": "4.3 Function LU-PROJ: Tightening Bounds", "text": "We now present an efficient solver for the optimization Problem P1 given by the function LU-PROJ in Algo-\n1: Input: L\u0303t, U t; Output: Lt 2: Initialize: Lt = L\u0303t 3: for k = 1 to n do 4: for i = 1 to n do 5: for j = 1 to n do 6: Lti,j = max ( Lti,j , L t i,k \u2212 U tj,k, Ltk,j \u2212 U tk,i\n) 7: Return: Lt\nrithm 2. The algorithm is invoked with inputs L\u0303t, U\u0303 t \u2014 its optimality is ensured by the following theorem.\nTheorem 2. The lower and upper bounds Lt, U t returned by LU-PROJ is the unique optimal solution of Problem P1.\nWe now briefly describe the function LU-PROJ. It first invokes the function U-PROJ shown in Algorithm 3 to compute U t \u2014 which in fact equals the optimal solution of Problem P2 (refer to the proof of the theorem). Then, it invokes the function L-PROJ shown in Algorithm 4 to compute Lt \u2014 which in fact equals the optimal solution of Problem P3 (again, refer to the proof of the theorem). Both U-PROJ and L-PROJ can be seen as iterating over the constraints of the sets D and L, updating variables that violate constraints. U-PROJ is in fact equivalent to the Floyd-Warshall algorithm for solving the all-pair shortest paths problem in a graph (Floyd, 1962). Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. The function L-PROJ operates in similar fashion as U-PROJ. However, additional challenges in the interpretation and analysis of the solution of L-PROJ arise from the fact that the class L is not a set of hemimetrics and has more complex dependencies. Figure 1 provides a geometric interpretation of the constraints imposed by the sets D (Equation 4) and L (Equation 11) exploited by U-PROJ and L-PROJ in line 6."}, {"heading": "4.4 Geometric Interpretation ofL\u2217t andU\u2217t", "text": "In this section we provide a geometric interpretation of the optimal solution to Problem P1. Consider the space Rn2 . Let us define \u03c00 to be the set of inequalities\n{Di,i = 0, 0 \u2264 Di,j \u2264 r, Di,j \u2264 Di,k +Dk,j \u2200 i, j, k \u2208 [n]}.\nThus, the subset of Rn2 described by \u03c00 corresponds to the set of bounded hemimetrics. At iteration t, we get a new labeled datapoint zt = ((it, jt, ct), yt) and update the set of inequalities as follows:\n\u03c0t = { \u03c0t\u22121 \u222a {ct \u2265 Dit,jt} if yt = 1, \u03c0t\u22121 \u222a {ct < Dit,jt} if yt = 0.\nNow, consider the polytope \u039bt defined by \u03c0t in Rn2 . Furthermore, consider the hypercube in Rn2 described by any lower and upper bounds L,U \u2014 the extent of the hypercube in dimension (i, j) is given by [Li,j , Ui,j ]. Then, the optimal solution to Problem P1 describes the unique tightest hypercube containing the polytope \u039bt."}, {"heading": "5 QCLIQUE: Proposing Queries", "text": "We first show the limitations of a greedy myopic policy QGREEDY for proposing queries, and then design our query policy QCLIQUE that overcomes these limitations."}, {"heading": "5.1 Myopic Policy QGREEDY", "text": "The policy QGREEDY is inspired by the idea of shrinking the gap (U t\u22121i,j \u2212 L t\u22121 i,j ) of pair (i\nt, jt) with maximum uncertainty. As already mentioned, this policy can be seen as myopic (greedy) in terms of minimizing the objective \u2016D\u0302 \u2212 D\u2217\u2016\u221e. However, this policy may turn out to be suboptimal in terms of exploiting the structural constraints of hemimetrics. In particular, consider a simple instance with n items belonging to a single tight cluster, i.e., \u2200i, j \u2208 [n] : D\u2217i,j = 0. Clearly, given the 2n distances D\u22171,j , D \u2217 j,1 for j \u2208 [n], one can infer all other distances because of the tightness of the triangle inequalities. For this example, INDGREEDY will, in every iteration t, half the largest upper bound maxi,j U ti,j . Thus, in iteration t, all upper bounds U ti,j are in the range [\u03b1/2, \u03b1] where \u03b1 = r \u00b7 2\u2212bt/(n2 \u2212 n)c and all lower bounds Lti,j = 0. Here, invoking LU-PROJ cannot exploit the structural constraints, i.e., it would simply return (L\u0303t, U\u0303 t)."}, {"heading": "5.2 Non-myopic Policy QCLIQUE", "text": "We now present an alternative policy QCLIQUE that proposes pairs (it, jt) in a non-myopic way in Algorithm 5. Instead of greedily minimizing \u2016D\u0302 \u2212 D\u2217\u2016\u221e, we aim to learn distances in a systematic way such that we can exploit the structural constraints of the hemimetrics more effectively. Note that in this section, we assume a fixed ordering of the items indexed by 1, . . . , n. The high level idea behind QCLIQUE is to maintain a clique of items for which all pairwise distances are already learnt. It proposes queries in a systematic way to grow the clique\nAlgorithm 5 Query Policy: QCLIQUE\n1: Input: Lt\u22121, U t\u22121; Output: query (it, jt, ct) 2: C = {i|\u2200j < i : U t\u22121i,j \u2212L t\u22121 i,j \u2264 \u2227 U t\u22121 j,i \u2212L t\u22121 j,i \u2264 } 3: a = max C + 1 4: b = minimal i \u2208 C s.t. (U t\u22121a,i \u2212 L t\u22121 a,i > \u2228 U t\u22121 i,a \u2212\nLt\u22121i,a > )\n5: ifU t\u22121a,b \u2212 L t\u22121 a,b > then 6: Return: (a, b, 12 (La,b + Ua,b)) 7: else 8: Return: (b, a, 12 (Lb,a + Ub,a))\nitem by item according to the assumed ordering. In more detail, the policy works as follows:\n1. At iteration t, the policy maintains a clique C = {1, . . . , |C|} \u2286 A of items \u2014 see line 2 of Algorithm 5. For any pair of items (i, j) \u2208 C it holds thatU t\u22121i,j \u2212 L t\u22121 i,j \u2264 . 2. It then identifies the next item to be added to the clique, denoted as a in line 3. 3. Now, it picks an item b \u2208 C for which the distance to a is not learnt up to precision in line 4, and returns the next query.\nOnline model. In many practical scenarios, the n items are not known beforehand, and rather appear over time. Let us denote by Am = {1, . . . ,m} \u2286 A the set of items present at timem. When a new item arrives at timem+ 1 we could learn a hemimetric solution from scratch. However, it would be desirable to make use of the hemimetric solution forAm and extend it. In fact, LEARNHM together with QCLIQUE can be readily applied to this scenario. We can identify the clique C with the itemsetAm, wherem = |C|, for which the hemimetric solution is known. The idea of adding a to C in Algorithm 5, is then equivalent to extending the hemimetric solution forAm toAm+1. By this equivalence, the sample complexity of growing the hemimetric solution item by item up to size n is the same as that of computing the hemimetric solution for all n items at once."}, {"heading": "6 Performance Analysis", "text": "In this section we analyze the sample complexity and runtime of our proposed algorithm LEARNHM. All proofs are provided in Appendix D."}, {"heading": "6.1 Sample Complexity", "text": "Motivated by our preference elicitation application (see Section 7), we analyze sample complexity under a clusteredness assumption. In particular, we say the hypothesis D\u2217 is (rin,K)-clustered, if the following condition holds: The items are partitioned into K clusters, such that for any pair of items (i, j) their distance is D\u2217i,j \u2208 [0, rin] if i and j are from the same cluster and D\u2217i,j \u2208 [rin, r] otherwise. Note that K and rin are unknown to the algorithm. For this\nsetting, the sample complexity of LEARNHM is bounded by the following theorem.\nTheorem 3. If D\u2217 is (rin,K)-clustered, the sample complexity of LEARNHM is upper bounded by\n2nK \u2308 log (r )\u2309 + n2 \u2308 log (2rin + 3 )\u2309 .\nIn real-world applications, the distances D\u2217i,j might correspond to monetary incentives and are, therefore, naturally quantized to some precision \u2206 (monetary incentives are multiples of the smallest currency unit, e.g., one cent). In this setting, the learning algorithms can learn D\u2217 exactly, i.e., D\u0302 = D\u2217, with a bounded number of queries. The idea is that both, INDGREEDY and LEARNHM, can collapse the gap U ti,j \u2212 Lti,j to zero whenever U ti,j \u2212 Lti,j < \u2206. Hence, by invoking these algorithms with any < \u2206, we learn D\u2217 exactly. We then obtain the following corollary for this interesting special case.\nCorollary 1. If D\u2217 is (0,K)-clustered, and assuming all distancesD\u2217i,j are quantized to precision \u2206 > 0, the sample complexity of LEARNHM to exactly learn D\u2217 is upper bounded by 2nK \u2308 log ( r \u2206 )\u2309 . This matches the lower bound of \u2126(nK).\nNote that our algorithm LEARNHM does not perform more queries than INDGREEDY for any instance. In fact, the hardest instance for our algorithm is given by D\u2217 where all distances D\u2217i,j = r/2. In this case, LU-PROJ cannot exploit any structural constraints \u2014 the number of queries performed by LEARNHM exactly equals that of INDGREEDY (equal to n2dlog( r )e).\nStochastic responses. We can also bound the sample complexity for the more realistic case in which query responses are stochastic. Here, we briefly introduce our noise model \u2014 a more detailed description is given in Appendix A. Our noise model is parametrized by the variance matrix \u03c3 \u2208 Rn,n+ unknown to the algorithm. The acceptance functionP(Y ((i, j, c)) = 1) is given by the CDF of a normal distributionN (D\u2217i,j , \u03c3i,j) truncated to [D\u2217i,j\u2212\u03b2i,j , D\u2217i,j+\u03b2i,j ] where \u03b2i,j = min{D\u2217i,j , r \u2212D\u2217i,j}. Note that in our model the noise is unbounded, i.e., at c = D\u2217i,j the acceptance function P(Y ((i, j, c)) = 1) = 0.5. In order to deal with this, we develop a robust noise-tolerant variant of GETUSERRESPONSE which ensures that the maximum noise experienced by the algorithm is bounded by\n\u03b7max = 1 2 \u2212 \u222b /3 0 e \u2212 w2 2maxi,j \u03c3 2 i,j dw\u222b r/2\n\u2212r/2 e \u2212 w2 2maxi,j \u03c3 2 i,j dw\n.\nThe sample complexity bounds are characterized by the quantity \u03b3 = ( 3 ln(3n2/\u03b4) (0.5\u2212\u03b7max)2 ) \u2014 the theoretical results corresponding to the settings in Theorem 3 and Corollary 1 are given as follows.\nTheorem 4. With probability 1 \u2212 \u03b4, LEARNHM learns D\u2217 with precision and the sample complexity is upper bounded by3\nO\u0303 ( \u03b3 ( 2nK \u2308 log (3r )\u2309 + n2 \u2308 log (6rin + 9 )\u2309)) .\nCorollary 2. Consider the case D\u2217 is (0,K)-clustered, and assume all distances D\u2217i,j are quantized to precision \u2206 > 0. With probability 1 \u2212 \u03b4, LEARNHM learns D\u2217 exactly and the sample complexity is upper bounded by\nO\u0303 ( \u03b32nK \u2308 log (3r\n\u2206\n)\u2309) ."}, {"heading": "6.2 Runtime Analysis and Speeding Up LEARNHM", "text": "We now begin by analyzing the runtime of LEARNHM. The algorithm LEARNHM invokes LU-PROJ after every query \u2014 there are \u0398(n2 log( r )) calls to LU-PROJ in the worst case. The runtime of LU-PROJ is \u0398(n3), resulting in a total runtime \u0398(n5 log( r )) \u2014 this is prohibitively expensive for most realistic problem instances. The key idea for speeding up LEARNHM is that we can choose the constraints that should be exploited instead of exploiting all the constraints after every query (line 6 in U-PROJ & L-PROJ). If the constraints to be exploited are selected carefully, we can still get reasonable benefits from tightening lower and upper bounds. For LEARNHM, this can be achieved as follows:\n\u2022 First, we do not need to invoke LU-PROJ after every query (this is equivalent to not exploiting any violated constraint). At any iteration t, LEARNHM invokes LU-PROJ only if U\u0303 tit,jt \u2212 L\u0303tit,jt \u2264 . Otherwise, it simply sets (Lt, U t)\u2190 (L\u0303t, U\u0303 t).\n\u2022 Second, when LEARNHM invokes LU-PROJ at iteration twe only consider the 2n constraints which involve it, jt\nin lines 4 and 5 of Algorithms 3 and 4.\nDetails of this idea are presented in Appendix B. LEARNHM implementing this idea invokes LU-PROJ at most n2 times each with a runtime of 4n. Hence, the total runtime of the speeded up LEARNHM is \u0398(n3). Most importantly, the sample complexity bounds from the previous section still apply."}, {"heading": "7 Experimental Evaluation", "text": ""}, {"heading": "7.1 Benchmarks", "text": "We compare the performance of the speeded up LEARNHM against the baseline INDGREEDY. We also compare against a second baseline INDGREEDY-SIT (INDGREEDY with side information of triplet comparisons). This baseline utilizes a low-dimensional embedding of the items as a preprocessing step. Following the work of Jamieson & Nowak (2011a), using n2 log n triplet queries, i.e., for a triplet (i, j, k) such a query returns 1(D\u2217i,j \u2264 D\u2217i,k), one can\n3The O\u0303(\u00b7) notation is used to omit factors logarithmic in the factors present explicitly.\ncompute a low-dimensional embedding of the items. Using this embedding, one can infer the response to all possiblen3 triplet queries \u2014 this is the side information that we supply to INDGREEDY-SIT. This side information can be exploited by INDGREEDY-SIT as follows. For a given triplet, 1(D\u2217i,j \u2264 D\u2217i,k) = 1 implies two constraints on the lower and the upper bounds \u2014Ui,j \u2264 Ui,k and Li,k \u2265 Li,j . After every query, INDGREEDY-SIT first updates an upper or lower bound according to the response. Then it exploits these two constraints for n3 triplets to tighten the bounds on every pair of items. We will report the sample complexity of INDGREEDY-SIT as the total number of queries for computing the low-dimensional embedding and for learning all distances up to precision ."}, {"heading": "7.2 Experimental Setup", "text": "Yelp dataset. We use the recently proposed Yelp Dataset Challenge (round 7) data for our experiments.4 This data contains information about 77K businesses located across 10 cities around the world. We looked into businesses belonging to the category Restaurants and being located in the city of Pittsburgh, PA. In particular, we extracted information for all 290 restaurants offering food from the cuisines Mexican (50), Thai (26), Chinese (53), Mediterranean (75), Italian (86). For each of these restaurants we also collected the review count and coordinates (longitude and latitude). We discretized the review count into High (popular, 166 restaurants) when there were more than 25 reviews and into Low (unpopular, 124 restaurants) otherwise. The collected data is visualized in Figure 3. User preference models. We simulate user preference models from this data by creating the underlying hemimetricD\u2217 as follows. For notational ease, we use the shorthands cuisinei, reviewi, lati, longi to refer to the above mentioned attributes for item i. We quantify the distance between item i and j by Wi,j = w1W cuisine i,j + w2W review i,j + w3W geo i,j + w4W random i,j , where W cuisinei,j = r1(cuisinei 6= cuisinej), W reviewi,j = r1(reviewi > reviewj), W geoi,j is the great-circle distance based on the latitude and longitude coordinates normalized to lie in [0, r], and W randomi,j is drawn uniformly at random from [0, r]. Recall, r is the upper bound on the distance. The weights w1, . . . , w4 \u2208 R+ sum up to 1. We compute D\u2217 as the closest metric toW according to Brickell et al. (2008). For different weights w1, . . . , w4, we can instantiate different user preference modelsD\u2217. In particular, we instantiate the following two models. In the first model (YelpM1), we use w1 = 0.9, w4 = 0.1 and w2 = w3 = 0 \u2014 this corresponds to the setting we considered in Theorem 3 with K = 5 and intra cluster distance rin \u2264 w4 \u00b7 r. The sec-\n4https://www.yelp.com/dataset challenge/"}, {"heading": "8 Related Work", "text": "8.1 Metric Learning & Low-dimensional Embeddings Learning distances to capture notions of similarity or dissimilarity plays a central role in many machine learning\napplications. We refer the reader to the detailed surveys by Yang & Jin (2006); van der Maaten et al. (2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework \u2014 for a triplet (i, j, k) it queries1(Di,j \u2264 Di,k) \u2014 has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses \u2014 they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation."}, {"heading": "8.2 Exploiting Structural Constraints", "text": "Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach pro-\nposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries. While similar in spirit, their approach is based on triplet-based queries, and differs from our methodology of exploiting the structural constraints."}, {"heading": "8.3 Learning User Preferences", "text": "Another relevant line of research is concerned with eliciting user preferences. Specifically, we seek to learn private costs of a user for switching from her default choice of item i to instead choose item j. This type of preferences can be used in marketing applications, e.g., for persuading users to change their decisions (Kamenica & Gentzkow, 2009). Singla et al. (2015) considered similar preferences in the context of balancing a bike-sharing system by incentivizing users to go to alternate stations for pickup or dropoff of bikes. Abernethy et al. (2015) considered the application of purchasing data from users, and quantified the prices that should be offered to them. One key difference of our approach is that we are interested in jointly learning the preferences between n items, i.e., tackling n2 learning problems jointly."}, {"heading": "8.4 Active Learning", "text": "Our problem formulation shares the goal of reducing sample complexity with other instances of active learning (Settles, 2012). Our goal to specifically exploit the structural constraints of the hemimetric polytope is along the lines of research in structured active learning where the hypotheses or the output label space have some inherent structure that can be utilized, e.g., the structure of part-of-speech tagging of the sentence (Roth & Small, 2006)."}, {"heading": "9 Conclusions", "text": "We investigated the novel problem of actively learning hemimetrics. The two key techniques used in the construction of our algorithm LEARNHM are novel projection techniques for tightening the lower and upper bounds on the solution space and a non-myopic (non-greedy) query policy. Our algorithm can be readily applied to the online setting allowing one to extend the hemimetric solution over time. We provided a thorough analysis of the sample complexity and runtime of our algorithm. Our experiments on Yelp data showed substantial improvements over baseline algorithms in line with our theoretical findings.\nAcknowledgements. This research is supported in part by SNSF grant 200020 159557 and the Nano-Tera.ch program as part of the Opensense II project."}, {"heading": "A Robust Noise-tolerant Algorithms", "text": "In this section, we introduce our noise model and the corresponding stochastic acceptance function. Furthermore, we present a robust noise-tolerant variant of GETUSERRESPONSE for this stochastic setting.\nA.1 Noise Model Our noise model is parametrized by the variance matrix \u03c3 \u2208 Rn,n+ which is unknown to the algorithm. The acceptance function P(Y ((i, j, c)) = 1) is given by the CDF of a normal distribution N (D\u2217i,j , \u03c3i,j) truncated to [ai,j , bi,j ] = [D \u2217 i,j \u2212 \u03b2i,j , D\u2217i,j + \u03b2i,j ] where \u03b2i,j = min{D\u2217i,j , r \u2212D\u2217i,j}, i.e.,\nP(Y ((i, j, c)) = 1) =  0 0 \u2264 c < ai,j , 1 bi,j < c \u2264 r, \u03a6 ( c\u2212D\u2217i,j \u03c3i,j ) \u2212\u03a6 (ai,j\u2212D\u2217i,j \u03c3i,j ) \u03a6 ( bi,j\u2212D\u2217i,j\n\u03c3i,j\n) \u2212\u03a6 (ai,j\u2212D\u2217i,j\n\u03c3i,j ) otherwise. Here, \u03a6(\u00b7) denotes the CDF of the standard normal distribution. Equivalently, the acceptance function could have been defined as\nP(Y ((i, j, c)) = y) = { 1\u2212 \u03b7((i, j, c)) if y = 1(c \u2265 D\u2217(i,j)) \u03b7((i, j, c)) otherwise ,\nwhere \u03b7((i, j, c)) corresponds to the noise rate and is given as\n\u03b7((i, j, c)) =  0 0 \u2264 c < ai,j , 0 bi,j < c \u2264 r, \u03a6 ( c\u2212D\u2217i,j \u03c3i,j ) \u2212\u03a6 (ai,j\u2212D\u2217i,j \u03c3i,j ) \u03a6 ( bi,j\u2212D\u2217i,j \u03c3i,j ) \u2212\u03a6 (ai,j\u2212D\u2217i,j \u03c3i,j ) ai,j \u2264 c < D\u2217i,j , 1\u2212 \u03a6 ( c\u2212D\u2217i,j \u03c3i,j ) \u2212\u03a6 (ai,j\u2212D\u2217i,j \u03c3i,j ) \u03a6 ( bi,j\u2212D\u2217i,j\n\u03c3i,j\n) \u2212\u03a6 (ai,j\u2212D\u2217i,j\n\u03c3i,j ) D\u2217i,j \u2264 c \u2264 bi,j . Note that in our model, for the caseD\u2217i,j = 0 the noise rate is zero and every offer is accepted; and for the caseD \u2217 i,j = r the noise rate is also zero and all offers less than r are rejected.\nThe noise rate in our model is unbounded, i.e., at c = D\u2217i,j the acceptance function P(Y ((i, j, c)) = 1) = 0.5.\nA.2 Robust GETUSERRESPONSE We now develop a robust variant of the function GETUSERRESPONSE for our noise model. The key idea is to ensure that the maximum noise \u03b7max experienced by the function satisfies \u03b7max < 0.5. In this way, the noise actually experienced is bounded and we can easily extend the function GETUSERRESPONSE from the noise-free case by issuing repeated queries and deciding on the final label via majority voting \u2014 this approach has been extensively studied in the active learning literature (Ka\u0308a\u0308ria\u0308inen, 2006; Jamieson & Nowak, 2011b; Castro & Nowak, 2006).\nGETUSERRESPONSE for bounded noise. Our function GETUSERRESPONSE for bounded noise is shown in Algorithm 6 \u2014 adopted from (Ka\u0308a\u0308ria\u0308inen, 2006). For a query x = (i, j, c) with underlying unknown noise rate \u03b7(x), the number of queries to the user is\nO\u0303\n( ln(n 2\n\u03b4 )\n(0.5\u2212 \u03b7(x))2\n) .\nGETUSERRESPONSE for unbounded noise. The sample complexity of the repeated query approach depends on the noiserate \u03b7(x). In particular, the complexity is a function of \u03b3\u2032 = 1(0.5\u2212\u03b7(x))2 . Thus, as long as the noise-rate is bounded away from 0.5, the repeated query approach can be used. However, in our noise model, the noise-rate is 0.5 at c = D\u2217i,j . The key idea to deal with this challenge is, given a query x = (i, j, c), to actually issue three queries in \u201cparallel\u201d: x\u2212 = (i, j,max(0, c \u2212 \u03b1 )), x = (i, j, c), x+ = (i, j,min(r, c + \u03b1 )), where \u03b1 \u2208 (0, 0.5). One of these queries has noise rate strictly less than 0.5. The repeated query algorithm GETUSERRESPONSE for unbounded noise is shown in Algorithm 7.\nAlgorithm 6 GETUSERRESPONSE for bounded noise\n1: Input: xt = (it, jt, ct), LEARNHM parameters (n, r), error parameters ( , \u03b4) 2: Output: label yt 3: Initialize:\niteration l = 0; probabilities pl1 = p l 0 = 1 2 ; counts n l 1 = n l 0 = 0 \u03b4\u2032 = \u03b4/ ( n2 log r ) // needed for the PAC guarantees 4: while TRUE do 5: l = l + 1 6: y \u2190 get response from user for query xt 7: update nl1 = n l\u22121 1 + 1(y = 1); n l 0 = n l\u22121 0 + 1(y = 0) 8: update pl1 = nl1 l ; p l 0 = nl0 l\n9: \u03b2l = \u221a\n1 2l\u0307\nln ( \u03c02l2\n3\u03b4\u2032 ) 10: if pl1 \u2212 \u03b2l \u2265 0.5 then 11: Return: yt = 1 12: if pl1 + \u03b2l < 0.5 then 13: Return: yt = 0\nFor a query x = (i, j, c), the number of queries to the user is\nO\u0303\n( 3 ln(3n 2\n\u03b4 )\n(0.5\u2212min{\u03b7(x\u2212), \u03b7(x), \u03b7(x+)})2\n) .\nThe largest noise rate \u03b7max(i, j) experienced by GETUSERRESPONSE for pair (i, j) is bounded by \u03b7max(i, j) = min{\u03b7(i, j,D\u2217i,j), \u03b7(i, j,max(0, D\u2217i,j \u2212 \u03b1 )), \u03b7(i, j,min(r,D\u2217i,j + \u03b1 ))}. We can now define the largest noise rate \u03b7max experienced by GETUSERRESPONSE as \u03b7max = maxi,j\u2208[n] \u03b7max(i, j). Using the parameters of the noise model we can bound \u03b7max in terms of the largest variance \u03c3max = maxi,j\u2208[n] \u03c3i,j by\n\u03b7max \u2264 \u03a6 ( \u2212\u03b1 \u03c3max ) \u2212 \u03a6 ( \u2212r/2 \u03c3max ) \u03a6 ( r/2 \u03c3max ) \u2212 \u03a6 ( \u2212r/2 \u03c3max\n) = \u222b \u2212\u03b1 \u2212r/2 e\n\u2212 w2 2\u03c32max dw\u222b r/2\n\u2212r/2 e \u2212 w2 2\u03c32max dw\n= 1 2 \u2212 \u222b \u03b1 0 e \u2212 w2\n2\u03c32max dw\u222b r/2 \u2212r/2 e \u2212 w2 2\u03c32max dw .\nThe worst case number of queries to the user is characterized by the quantity\n\u03b3 = 3 ln( 3n\n2\n\u03b4 )\n(0.5\u2212 \u03b7max)2 ."}, {"heading": "B Speeding up LEARNHM", "text": "The key idea for speeding up LEARNHM is that we can choose the constraints that should be exploited instead of exploiting all the constraints after every query (line 6 in U-PROJ & L-PROJ). If the constraints to be exploited are selected cleverly, we can still get reasonable benefits from tightening lower and upper bounds. For LEARNHM this can be achieved as follows:\n\u2022 First, we do not need to invoke LU-PROJ after every query (this is equivalent to not exploiting any violated constraint). At any iteration t, LEARNHM invokes LU-PROJ only if U\u0303 tit,jt \u2212 L\u0303tit,jt \u2264 . Otherwise, it simply sets (Lt, U t)\u2190 (L\u0303t, U\u0303 t). \u2022 Second, when LEARNHM invokes LU-PROJ at iteration t we only consider the 2n constraints which involve it, jt in lines 4 and 5 of Algorithms 3 and 4.\nThe faster variant of LU-PROJ is given by the function in Algorithm 8, which in turn calls the faster variant of U-PROJ (Algorithm 9) and the faster variant of L-PROJ (Algorithm 10). The function LU-PROJ in Algorithm 8 has the additional inputs Pivots,STpairs. By calling LU-PROJ with Pivots = \u2205,STpairs = \u2205, this is\nAlgorithm 7 GETUSERRESPONSE for unbounded noise\n1: Input: xt = (it, jt, ct), LEARNHM parameters (n, r), error parameters ( , \u03b4) 2: Output: data point zt = ((it, jt, ct), yt) 3: Initialize: \u03b4\u2032\u2032 = \u03b43 log( r )\nlog( r (1\u22122\u03b1) ) // needed for the PAC guarantees\n\u03b1 = 13 xt1 = (i\nt, jt, ct) xt2 = (i\nt, jt,max(0, ct \u2212 \u03b1 )) xt3 = (i\nt, jt,min(r, ct + \u03b1 )) iteration l = 0;\n4: while TRUE do 5: l = l + 1 6: Invoke GETUSERRESPONSE in Algorithm 6 for xt1, x t 2 and x t 3 with noise parameters ( , \u03b4\n\u2032\u2032) in parallel; terminate execution once any of these invocations terminated \u2014 letm be the index of the invocation that terminated first and let yt be its returned label\n7: Return: data point zt = (xtm, yt)\nAlgorithm 8 Faster variant of LU-PROJ\n1: Input: L\u0303t, U\u0303 t, Pivots,STpairs 2: Output: Lt, U t 3: U t \u2190 U-PROJ(U\u0303 t,Pivots,STpairs) 4: Lt \u2190 L-PROJ(L\u0303t, U t,Pivots,STpairs) 5: Return: Lt, U t\nAlgorithm 9 Faster variant of U-PROJ\n1: Input: U\u0303 t, Pivots,STpairs 2: Output: U t 3: Initialize: U t = U\u0303 t 4: for k \u2208 Pivots do 5: for (i, j) \u2208 STpairs do 6: U ti,j = min ( U ti,j , U t i,k + U t k,j\n) 7: Return: U t\nAlgorithm 10 Faster variant of L-PROJ\n1: Input: L\u0303t, U t, Pivots,STpairs 2: Output: Lt 3: Initialize: Lt = L\u0303t 4: for k \u2208 Pivots do 5: for (i, j) \u2208 STpairs do 6: Lti,j = max ( Lti,j , L t i,k \u2212 U tj,k, Ltk,j \u2212 U tk,i\n) 7: Return: Lt\nequivalent to not exploiting any violated constraint. At iteration t, after LEARNHM invoked the query (it, jt, ct) proposed by QCLIQUE and updated the local bounds, LEARNHM invokes LU-PROJ (when U\u0303 tit,jt \u2212 L\u0303tit,jt \u2264 ) with STpairs = ({max(it, jt)} \u00d7 C) \u222a (C \u00d7 {max(it, jt}) and sets Pivots = {min(it, jt)}.\nLEARNHM implementing this idea invokes LU-PROJ at most n2 times with a runtime of 4n. Hence, the total runtime of LEARNHM is \u0398(n3). Most importantly, the sample complexity bounds from the previous section still apply. In fact, the proofs for the sample complexity bounds analyze the speeded up variant of LEARNHM because of ease of analysis.\nFurthermore, we can make the following observations:\n\u2022 The function LU-PROJ in Algorithm 8 is a strict generalization of Algorithm 2 \u2014 by passing Pivots =\n[n],STpairs = [n]2, it reduces to Algorithm 2. \u2022 The resulting outputLt andU t may not be the optimal solutions to the Problems P3 and P2, respectively."}, {"heading": "C Experimental Results for Stochastic Settings", "text": "We perform two sets of experiments for the stochastic setting. In the stochastic setting with bounded noise rate (i.e., the algorithm knows that the noise rate is bounded away from 0.5), LEARNHM uses the function GETUSERRESPONSE for bounded noise in Algorithm 6. In our noise model (i.e., the algorithm makes no assumption about the bound on the noise rate), LEARNHM uses the function GETUSERRESPONSE for unbounded noise in Algorithm 7. Figures 4 (a-c) show results for the stochastic setting with bounded noise rate parameterized by (\u03b7BN, \u03c3). Then, we present results for our noise model in Figures 4 (d-f) parameterized by \u03c3. We used the same value of variance for all the pairs, i.e., \u2200i, j \u2208 [n] : \u03c3i,j = \u03c3max. The PAC-parameters are set to ( = 0.01, \u03b4 = 0.05). The other parameters are set similar to the noise-free setting, i.e., n = 100, r = 1.\nStochastic acceptance function. Figure 4d shows the acceptance function for \u03c3max = 0.1 when D\u2217i,j = 0.6. Figure 4a shows the corresponding acceptance function for the bounded noise setting with the noise rate \u03b7BN = 0.3. Results for bounded noise rate. Figure 4b and Figure 4c show the results for bounded noise rate on the two preference models YelpM1 and YelpM2 respectively. We vary the bound on the noise rate \u03b7BN, and the value of \u03c3max is fixed to 0.1. We observe that the sample complexity increases drastically for all the algorithms as \u03b7BN approaches 0.5. LEARNHM outperforms INDGREEDY for both user preference models, though the relative gain of sample complexity improvements of LEARNHM in comparison to INDGREEDY decreases with increasing \u03b7BN. Note that as \u03b7BN increases, the cost of repeated querying near the threshold boundary dominates the sample complexity and tends to infinity. Results for our noise model. Figure 4e and Figure 4f show the results for our noise model by varying the variance \u03c3max, on YelpM1 and YelpM2 respectively. GETUSERRESPONSE for unbounded noise in Algorithm 7 ensures that the sample complexity stays bounded away from\u221e. As we increase \u03c3max, the CDF eventually resembles the uniform noise setting, and the sample complexity curve saturates.\nMost importantly, LEARNHM constantly outperforms INDGREEDY across different noise settings and different user preference models."}, {"heading": "D Sample Complexity Analysis", "text": "Proof of Theorem 3. Consider the current clique C, and a new item a \u2208 A \\ C that should be added to C. In order to do so, the policy needs to learn all distances between a and all items in C. During this process of learning all distances between a\nand all items in C, let us say that LEARNHM / QCLIQUE has already learnt all distances between a and items C\u2032 \u2282 C, and is now learning the distance between a and b \u2208 C \\ C\u2032. That is, LEARNHM / QCLIQUE is growing C\u2032 until C\u2032 = C, and then item awill be added. We will consider the following cases:\nC1 b is the first item of its cluster that will be added to C\u2032. C2 Another item e from the same cluster as b is already part of C\u2032.\nC2.1 b belongs to the same cluster as a C2.2 b belongs to a different cluster as a\nC1: In order to learn the distances between (a, b) and (b, a), the number of queries is bounded by\u2308 log (r )\u2309 .\nC2.1: In order to learn the distance between (a, b) or (b, a), the number of queries is bounded by\u2308 log (2rin + 2 )\u2309 .\nTo see this, note that Ua,b \u2264 Ua,e + Ue,b\n\u2264 (rin + ) + (rin + ) = 2rin + 2 .\nSince La,b \u2265 0, and our goal is to shrink the gap Ua,b \u2212 La,b to at most , we need at most the above numbers of queries. The same argument clearly also holds for shrinkingUb,a \u2212 Lb,a to at most . C2.2: In order to learn distance between (a, b) or (b, a), the number of queries is bounded by\u2308 log (2rin + 3 )\u2309 .\nTo see this, note that we can subtract the inequalities Ua,b \u2264 Ua,e + Ue,b and La,b \u2265 La,e \u2212 Ub,e to get Ua,b \u2212 La,b \u2264 (Ua,e \u2212 La,e) + Ue,b + Ub,e. We bound the resulting inequality as follows:\nUa,b \u2212 La,b \u2264 (Ua,e \u2212 La,e) + Ue,b + Ub,e \u2264 ( ) + (rin + ) + (rin + ) = 2rin + 3 .\nSince La,b \u2265 0, and our goal is to shrink the gap Ua,b \u2212 La,b to at most , we need at most the above numbers of queries. A similar argument holds for shrinkingUb,a \u2212 Lb,a to at most .\nCase C1 can only occur min{|C| \u2212 1,K} times. Case C2.1, and C2.2 can occur up to |C| times. Hence, the total cost of adding item a to C is bounded by\n2 min{|C| \u2212 1,K} \u2308 log (r )\u2309 + 2|C| \u2308 log (max{2rin + 2 , 2rin + 3 } )\u2309 .\nGiven that we will add n items to C, the total sample complexity of LEARNHM is n\u22121\u2211 |C|=1 2 min{|C| \u2212 1,K} log (r ) + 2|C| log (max{2rin + 2 , 2rin + 3 } )\n\u2264 n\u22121\u2211 |C|=1 2 min{|C| \u2212 1,K} \u2308 log (r )\u2309 + 2|C| \u2308 log (2rin + 3 )\u2309 .\nThis gives us the bound on the sample complexity from Theorem 3, i.e., 2nK \u2308 log (r )\u2309 + n2 \u2308 log (2rin + 3 )\u2309 .\nProof of Corollary 1. This proof follows the same lines as that of Theorem 3. Therefore, we only show the differences in the proof. Since we invoked the algorithm with < \u2206, we can for any i, j \u2208 [n] collapse the gap Ui,j \u2212 Li,j to zero wheneverUi,j \u2212 Li,j < \u2206.\nC1: In order to learn the distances between (a, b) and (b, a), the number of queries is bounded by\u2308 log ( r\n\u2206\n)\u2309 .\nC2.1: In this setting, the number of queries is actually zero. To see this, note that Ua,b \u2264 Ua,e + Ue,b\n\u2264 0 + 0 = 0.\nC2.2: In this setting, the number of queries is again zero. To see this, note that Ua,b \u2212 La,b \u2264 (Ua,e \u2212 La,e) + Ue,b + Ub,e\n\u2264 0 + 0 + 0 = 0.\nThis leads to the total sample complexity\n2nK \u2308 log ( r\n\u2206\n)\u2309 .\nTo this end, we prove a lower bound on the sample complexity. Therefore, consider a more powerful algorithm which knows that there areK clusters, as well as one item from every cluster. We assume that the clusters are balanced equally. Now, given an item i, learning all the distances to all the other items, is equivalent to assigning the item i to its cluster. On average K2 queries are need to perform this for item i, giving a lower bound of \u2126(nK) \u2014 even for this powerful variant of the algorithm with additional information.\nProof of Theorem 4. Note that we introduced \u03b3 = 3 ln(\n3n2\n\u03b4 )\n(0.5\u2212\u03b7max)2 in Appendix A which quantifies the maximum number of queries to the user in the unbounded noise case when using the function GETUSERRESPONSE in Algorithm 7.\nThe only key insight that is missing to prove this theorem is to bound the number of invocations of GETUSERRESPONSE with parameter\u03b1 needed to shrink a gap g0 := Ui,j \u2212Li,j to be at most . For this, note that one invocation to GETUSERRESPONSE with ct = 12 (Li,j + Ui,j) may not return the label for c but for c \u00b1 \u03b1 . Thus, after updating the bounds, the gap g 1 is in the worst-case g 0\n2 + \u03b1 . Thus, to ensure that the gap is shrunk below , at most dlog g0\n(1\u22122\u03b1)e invocations of GETUSERRESPONSE are necessary \u2014 in contrast, using binary search in the noise-free case, at most dlog g 0 e invocations are neeeded.\nTo finish the proof, consider the sample complexity from Theorem 3 from the noise-free setting and set \u03b1 = 13 . We have to adopt it as follows:\n\u2022 All terms quantifying the numbers of invocations of GETUSERRESPONSE to shrink a gap g to at most , i.e., dlog( g )e, are replaced by dlog 3g e.\n\u2022 Each invocation has a cost of O\u0303(\u03b3).\nThus, with probability 1\u2212 \u03b4, LEARNHM learnsD\u2217 to precision and has sample complexity O\u0303 ( \u03b3 ( 2nK \u2308 log (3r )\u2309 + n2 \u2308 log (6rin + 9 )\u2309)) .\nProof of Corollary 2. Apply the same arguments from Theorem 4 to Corollary 1.\nE SetL for Lower Bounds andD for Upper Bounds We now provide a formal reasoning for using the sets L andD as the lower bounds L and upper bounds U for projection in Problems P3 and P2, respectively.\nIn order to formally get the setD for upper bounds, for any i, j, k \u2208 [n], we can state: D\u2217i,j \u2264 D\u2217i,k +D\u2217k,j \u2264 Ui,k + Uk,j\n=\u21d2 D\u2217i,j \u2264 min k\u2032\u2208[n] (Ui,k\u2032 + Uk\u2032,j)\n=\u21d2 Ui,j = min k\u2032\u2208[n] (Ui,k\u2032 + Uk\u2032,j)\n=\u21d2 Ui,j \u2264 Ui,k + Uk,j \u2200k \u2208 [n] (12)\nUsing Equation 12, we define the set of matrices for the upper bounds as follows. Note that this corresponds to the set of hemimetricsD (Equation 4). Remember,\nD := {U \u2208 Rn\u00d7n | Ui,i = 0, 0 \u2264 Ui,j \u2264 r, Ui,j \u2264 Ui,k + Uj,k \u2200 i, j, k \u2208 [n]}.\nIn order to formally get the setL for lower bounds, for any i, j, k \u2208 [n], we can state: D\u2217i,k \u2264 D\u2217i,j +D\u2217j,k\n=\u21d2 D\u2217i,j \u2265 D\u2217i,k \u2212D\u2217j,k \u2265 Li,k \u2212 Uj,k =\u21d2 D\u2217i,j \u2265 max\nk\u2032\u2208[n] (Li,k\u2032 \u2212 Uj,k\u2032) (13)\nSimilarly, we can state: D\u2217k,j \u2264 D\u2217k,i +D\u2217i,j\n=\u21d2 D\u2217i,j \u2265 D\u2217k,j \u2212D\u2217k,i \u2265 Lk,j \u2212 Uk,i =\u21d2 D\u2217i,j \u2265 max\nk\u2032\u2208[n] (Lk\u2032,j \u2212 Uk\u2032,i) (14)\nCombining Equations 13, 14 from above, we get: D\u2217i,j \u2265 max\nk\u2032\u2208[n]\n( max (Li,k\u2032 \u2212 Uj,k\u2032 , Lk\u2032,j \u2212 Uk\u2032,i) ) =\u21d2 Li,j = max\nk\u2032\u2208[n]\n( max (Li,k\u2032 \u2212 Uj,k\u2032 , Lk\u2032,j \u2212 Uk\u2032,i) ) =\u21d2 Li,j \u2265 max (Li,k \u2212 Uj,k, Lk,j \u2212 Uk,i) \u2200k \u2208 [n] (15)\nUsing Equation 15, we define the setL parameterized by the upper bound matrixU \u2208 D as follows: L(U) := {L \u2208 Rn\u00d7n |Li,i = 0, 0 \u2264 Li,j \u2264 Ui,j , Li,j \u2265 max (Li,k \u2212 Uj,k, Lk,j \u2212 Uk,i \u2200 i, j, k \u2208 [n])}\nWhile the set of upper bounds corresponds to the setD of bounded hemimetrics, the set L(U) represents more complex dependencies. It turns out that the setL(U) cannot be constrained to contain only hemimetrics. We provide a counter-example below.\nCounter-example. Here, we provide an example to demonstrate that if we restrict the setL(U) to hemimetrics only, we may obtain invalid lower bounds.\nConsider the following underlying hemimetricD\u2217:\nD\u2217 =  0 1 0.51 0 0.5 0.5 0.5 0  At iteration t = 0, we haveZ0 = \u2205. The lower boundsL0 and upper boundsU0 are defined as follows:\nL0 = 0 0 00 0 0 0 0 0 \nU0 = 0 1 11 0 1 1 1 0  At iteration t = 1, let us consider that the algorithm picks the query x1 = (1, 2, 0.5) and receives the label y1 = 0. Let us see how to update the bounds to incorporate this labeled datapoint z1 = (x1, y1).\nWe haveU1 = U\u03031 = U0. We initialize L\u03031 = L0, and update L\u030311,2 = 0.5. We get:\nL\u03031 = 0 0.5 00 0 0 0 0 0  Now if we restrict the classL to be of set of hemimetricsD, then the projection of L\u03031 to setD will give us the followingL1:\nL1 = 0 0.5 a0 0 0 0 0.5\u2212 a 0  where a \u2208 [0, 0.5].\nFirst of all, it is clear that the updated lower boundL1 is not unique as any a \u2208 [0, 0.5] represents a corresponding solutionL1.\nSecondly, the boundsL1, U1 after the update are not valid anymore. Consider the following hemimetricD\u2032, where b \u2208 [0, 1], given below:\nD\u2032 = 0 1 b1 0 1 1 1\u2212 b 0  D\u2032 is in the version space for all b, i.e.,D\u2032 \u2208 D1. However:\n\u2022 If a > 0, then allD\u2032 with b \u2208 [0, a) are excluded, i.e.,D\u2032 /\u2208 D(L1, U1). \u2022 Otherwise, if a = 0, then allD\u2032 with b \u2208 (0.5, 1] are excluded, i.e.,D\u2032 /\u2208 D(L1, U1)."}, {"heading": "F Proof of Theorem 1", "text": "In this section we provide the proof of Theorem 1. The proof builds upon three lemmas, which are presented first.\nLemma 1. Assume Lt\u22121 and U t\u22121 satisfy D(Lt\u22121, U t\u22121) = cl(Dt\u22121), where cl(\u00b7) denotes the closure. Then, L\u0303t, U\u0303 t obtained by the local updates in Algorithm 1 (lines 9\u201312) after querying xt = (it, jt, ct) and observing response yt, satisfy D(L\u0303t, U\u0303 t) = cl(Dt).\nProof. Note that Dt can be written as Dt = D \u2229 \u03a0t, where \u03a0t \u2286 Rn\u00d7n is the intersection of half-spaces defined by the constraints of the labeled datapoints. Formally,\n\u03a0t = {D \u2208 Rn\u00d7n | 1(ct \u2032 \u2265 Dit\u2032 ,jt\u2032 ) = y t\u2032 \u2200t\u2032 \u2264 t} = \u22c2 t\u2032\u2264t {D \u2208 Rn\u00d7n | 1(ct \u2032 \u2265 Dit\u2032 ,jt\u2032 ) = y t\u2032}\n= \u22c2 t\u2032\u2264t {D \u2208 Rn\u00d7n | ct \u2032 \u2265 Dit\u2032 ,jt\u2032 if y t\u2032 = 1, or ct \u2032 < Dit\u2032 ,jt\u2032 if y t\u2032 = 0}.\nConsequently, it follows from an easy geometric argument that cl(Dt) = D \u2229\u03a0t, where \u03a0 t = \u22c2 t\u2032\u2264t {D \u2208 Rn\u00d7n | ct \u2032 \u2265 Dit\u2032 ,jt\u2032 if y t\u2032 = 1, or ct \u2032 \u2264 Dit\u2032 ,jt\u2032 if y t\u2032 = 0}.\nIt is now easy to see the claimed equivalence ofD(L\u0303t, U\u0303 t) and cl(Dt). Consider the following two cases:\n\u2022 C1: The response is given as yt = 1. In this case U\u0303 t is updated to U\u0303 t = ct in Algorithm 1 (lines 9\u201312). Hence, D(L\u0303t, U\u0303 t) consists of all hypothesis D \u2208 D(Lt\u22121, U t\u22121) = cl(Dt\u22121) that satisfy ct \u2265 Dit,jt . Also, cl(Dt) = cl(Dt\u22121) \u2229 {D \u2208 Rn\u00d7n | ct\u2032 \u2265 Dit\u2032 ,jt\u2032}, i.e., the same hypotheses are in cl(Dt). \u2022 C2: The response is given as yt = 0. In this case L\u0303t is updated to L\u0303t = ct in Algorithm 1 (lines 9\u201312). Hence, D(L\u0303t, U\u0303 t) consists of all hypothesis D \u2208 D(Lt\u22121, U t\u22121) = cl(Dt\u22121) that satisfy ct \u2264 Dit,jt . Also, cl(Dt) = cl(Dt\u22121) \u2229 {D \u2208 Rn\u00d7n | ct\u2032 \u2264 Dit\u2032 ,jt\u2032}, i.e., the same hypotheses are in cl(Dt).\nLemma 2. Problem P2 has a unique optimal solution U\u2217t that is given by U\u2217ti,j = maxD\u2208D(L\u0303t,U\u0303t)Di,j and satisfies D(L\u0303t, U\u2217t) = D(L\u0303t, U\u0303 t).\nProof. Let us define D\u0303tmax \u2208 Rn\u00d7n via D\u0303tmax;i,j = max\nD\u2208D(L\u0303t,U\u0303t) Di,j \u2200i, j \u2208 [n].\nNote that D\u0303tmax \u2208 Rn\u00d7n is feasible for Problem P2:\n\u2022 D\u0303tmax \u2264 U\u0303 t is obvious from the definition. \u2022 To see that D\u0303tmax \u2208 D, fix i, j \u2208 [n]. Then, there existsD \u2208 D such that D\u0303tmax;i,j = Di,j . SinceD is a hemimetric, we\nhave D\u0303tmax;i,j = Di,j \u2264 Di,k +Dk,j \u2264 D\u0303tmax;i,k + D\u0303tmax;k,j .\nWe now show that U\u2217ti,j = maxD\u2208D(L\u0303t,U\u0303t)Di,j , which also implies uniqueness of the optimal solution. Consider the following two cases:\n\u2022 Assume U\u2217t \u2264 D\u0303tmax. If U\u2217t = D\u0303tmax, then we are done. Otherwise, this violates optimality of U\u2217t as D\u0303tmax is a better solution. \u2022 Otherwise, assume \u2203i, j \u2208 [n] : U\u2217ti,j > D\u0303tmax;i,j . To show a contradiction, defineM \u2208 Rn\u00d7n via\nMi,j = max ( U\u2217ti,j , D\u0303 t max;i,j ) \u2200i, j \u2208 [n]. (16)\nThe matrixM has strictly smaller objective value for Problem P2 thanU\u2217t. By showing thatM is feasible for Problem P2, we reach a contradiction to the optimality ofU\u2217t. Clearly,M \u2264 U\u0303 t. To see thatM \u2208 D consider the following two cases for i, j \u2208 [n]: \u2013 CaseMi,j = U\u2217ti,j . From this we get\nMi,j = U \u2217t i,j \u2264 U\u2217ti,k + U\u2217tk,j \u2264Mi,k +Mk,j ,\nwhere the first inequality holds becauseU\u2217t is a hemimetric and the second inequality holds by definition ofM . \u2013 CaseMi,j = D\u0303tmax;i,j . Here we have\nMi,j = D\u0303 t max;i,j \u2264 D\u0303tmax;i,k + D\u0303tmax;k,j \u2264Mi,k +Mk,j ,\nwhere the first inequality holds because D\u0303max is a hemimetric and the second inequality again holds by definition ofM . This shows thatM is feasible \u2014 we reach a contradiction, and we must haveU\u2217t = D\u0303tmax.\nNext, we show that D(L\u0303t, U\u2217t) = D(L\u0303t, U\u0303 t). Observe that D(L\u0303t, U\u2217t) \u2286 D(L\u0303t, U\u0303 t) is obvious. On the other hand, any metric D \u2208 D(L\u0303t, U\u0303 t) is also in D(L\u0303t, U\u2217t) because U\u2217t = D\u0303tmax is by definition element-wise larger than any metric in D(L\u0303t, U\u0303 t, ) . Hence, D(L\u0303t, U\u2217t) = D(L\u0303t, U\u0303 t). Informally, this implies that replacing the upper bound U\u0303 t on the solution space byU\u2217t does not remove any hypotheses.\nLemma 3. Problem P3 has a unique solution L\u2217t that is given by L\u2217ti,j = minD\u2208D(L\u0303t,U\u2217t)Di,j and satisfies D(L\u2217t, U\u2217t) = D(L\u0303t, U\u2217t).\nProof. This proof essentially follows the lines of the proof of Lemma 2. Let us define D\u0303tmin \u2208 Rn\u00d7n via D\u0303tmin;i,j = min\nD\u2208D(L\u0303t,U\u2217t) Di,j \u2200i, j \u2208 [n].\nNote that D\u0303tmin \u2208 Rn\u00d7n is feasible for Problem P3:\n\u2022 D\u0303tmin \u2265 L\u0303t is obvious from the definition. \u2022 To see that D\u0303tmin \u2208 L(U t\u2217), fix i, j \u2208 [n]. Then, there exists D \u2208 D(L\u0303t, U\u2217t) such that D\u0303tmin;i,j = Di,j . Since D is a\nhemimetric, we have D\u0303tmin;i,j = Di,j \u2265 Di,k\u2212Dj,k \u2265 D\u0303tmin;i,k\u2212U\u2217tj,k sinceDj,k \u2264 U\u2217tj,k. (D\u0303tmin;i,j \u2265 D\u0303tmin;k,j \u2212U\u2217tk,i follows analogously)\nWe now show that L\u2217ti,j = minD\u2208D(L\u0303t,U\u2217t)Di,j , which also implies uniqueness of the optimal solution. Consider the following two cases:\n\u2022 AssumeL\u2217t \u2265 D\u0303tmin. IfL\u2217t = D\u0303tmin, then we are done. Otherwise this violates the optimality ofL\u2217t, as D\u0303tmin is a better solution. \u2022 Otherwise, assume \u2203i, j \u2208 [n] : L\u2217ti,j < D\u0303tmin;i,j . To show a contradiction, defineM \u2208 Rn\u00d7n via\nMi,j = min ( L\u2217ti,j , D\u0303 t min;i,j ) \u2200i, j \u2208 [n].\nThe matrixM has strictly smaller objective value for Problem P3 thanL\u2217t. By showing thatM is feasible for Problem P3, we reach a contradiction to the optimality of L\u2217t. Clearly,M \u2265 L\u0303t. To see thatM \u2208 L(U t\u2217) consider the following two cases for i, j \u2208 [n]: \u2013 CaseMi,j = L\u2217ti,j . AsL\u2217ti,j \u2208 L(U\u2217t), we have that\nMi,j = L \u2217t i,j \u2265 L\u2217ti,k \u2212 U\u2217tj,k \u2265Mi,k \u2212 U\u2217tj,k,\nwhere the first second inequality follows from the definition ofM . (Mi,j \u2265Mk,j \u2212 U\u2217tk,i follows analogously) \u2013 CaseMi,j = D\u0303tmin;i,j . From this we get that there is someD \u2208 D(L\u0303t, U\u2217t) such thatDi,j = D\u0303tmin;i,j . As above, this\ngives Mi,j = Di,j \u2265 Di,k \u2212Dj,k \u2265Mi,k \u2212 U\u2217tj,k, where the first inequality follows becauseD is a hemimetric and the seconds inequality follows by the definition ofM and the fact thatDj,k \u2264 U\u2217tj,k. (Mi,j \u2265Mk,j \u2212 U\u2217tk,i follows analogously)\nThis shows thatM is feasible \u2014 we reach a contradiction, and we must haveL\u2217t = D\u0303tmin.\nNext we show thatD(L\u2217t, U\u2217t) = D(L\u0303t, U\u2217t). Observe thatD(L\u2217t, U\u2217t) \u2286 D(L\u0303t, U\u2217t) is obvious. On the other hand, any metric D \u2208 D(L\u0303t, U\u2217t) is also in D(L\u2217t, U\u2217t) because L\u2217t = D\u0303tmin is by definition element-wise smaller than any metric inD(L\u0303t, U\u2217t, ) . Hence,D(L\u2217t, U\u2217t) = D(L\u0303t, U\u2217t).\nWe can now prove the theorem.\nProof of Theorem 1. LetL\u2032, U \u2032 be an optimal solution of Problem P1. ThusD(L\u2032, U \u2032) \u2287 Dt.\nDefine Dmin and Dmax as the element-wise minimum and maximum of all D \u2208 cl(Dt), respectively. Thus, by using Lemmas 1, 2 and 3 we have that L\u2217t = Dmin and U\u2217t = Dmax. Consequently,D(L\u2217t, U\u2217t) = cl(Dt) \u2287 Dt, i.e., L\u2217t, U\u2217t are feasible for Problem P1.\nWe now show thatL\u2217t = L\u2032 andU\u2217t = U \u2032. IfL\u2217t = L\u2032 andU\u2217t = U \u2032, then we are done. Otherwise,L\u2217t 6= L\u2032 orU\u2217t 6= U \u2032 contradicts either the optimality or feasibility ofL\u2032, U \u2032\u2014 consider the following two cases:\n\u2022 LetU\u2217t 6= U \u2032. \u2013 If U\u2217t \u2264 U \u2032 and \u2203i, j \u2208 [n] : U\u2217ti,j < U \u2032i,j , then U \u2032 cannot be optimal because L\u2032, U\u2217t is a feasible solution with\nsmaller objective value. \u2013 If on the other hand, \u2203i, j \u2208 [n] : U\u2217ti,j > U \u2032i,j , then U \u2032 cannot be feasible because it rules out all hemimetrics that\ncoincide withU\u2217t on the (i, j)th value. \u2022 For the caseL\u2217t 6= L\u2032, similar arguments as above hold.\nHence,L\u2032 = L\u2217t,U \u2032 = U\u2217t is the unique optimal solution for Problem P1."}, {"heading": "G Proof of Theorem 2", "text": "The proof of Theorem 2 builds upon Lemma 4 and Lemma 5.\nU-PROJ is in fact equivalent to the Floyd-Warshall algorithm for solving the all-pair shortest paths problem in a graph (Floyd, 1962). Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. Brickell et al. (2008) used a similar result as Lemma 4, however they directly used the interpretation of shortest-path problem. We will give an algebric proof for completeness which also helps us develop similar proof for Lemma 5\nLemma 4. The function U-PROJ in Algorithm 3 with input parameters U\u0303 t returns U t \u2208 D with the following property: for all i, j \u2208 [n] it holds that ( EitherU ti,j = U\u0303 t i,j; OR \u2203k s.t. U ti,j = U ti,k + U tk,j ) .\nProof of Lemma 4. For ease of notation, let us define M0 = U\u0303 t. During an iteration of the outer loop of pivots k \u2208 [n] for U-PROJ, we updateMki,j = min ( Mk\u22121i,j ,M k\u22121 i,k +M k\u22121 j,k ) . At the end of execution, we have k = n, and the output of U-PROJ isMn. We will prove the following properties ofMk at the end of every iteration k \u2208 [n] and \u2200a, b \u2208 [n]: \u2200k\u2032 \u2208 [k]Mka,b \u2264Mka,k\u2032 +Mkk\u2032,b (17) Either Mka,b = M 0 a,b OR \u2203k\u2032 \u2208 [k] s.t. Mka,b = Mka,k\u2032 +Mkk\u2032,b (18)\nNote that the conditions hold trivially at the start since the range of k\u2032 is \u2205. Also, the claim of the lemma is equivalent to the statement that the two conditions above hold at the end when k = n. We will now prove this by induction.\nBase case forM0,M1: Conditions in Equations 17, 18 hold trivially for M0 since the range of k\u2032 is \u2205. Conditions in Equations 17,18 hold for M1\nsince the range of k\u2032 is [1], and \u2200a, b \u2208 [n] updateM1a,b = min ( M0a,b,M 0 a,1 +M 0 1,b ) ensures that the conditions hold.\nInduction hypothesis: At k \u2212 1,Mk\u22121 satisfies the conditions in Equations 17, 18.\nInductive step: Prove thatMk satisfies the conditions in Equations 17, 18 after we make the following update at iteration k:\n\u2200a, b \u2208 [n] updateMka,b = min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) Consider any a, b \u2208 [n]. We consider the following 3 cases depending on the type of update toMka,b.\nC1: Mka,b = M k\u22121 a,k +M k\u22121 k,b C2: Mka,b = M k\u22121 a,b\nC2.1: Mk\u22121a,b = M 0 a,b C2.2: Mk\u22121a,b = M k\u22121 a,e +M k\u22121 e,b where e \u2208 [k \u2212 1]\nNote that the cases C1, C2.1 and C2.2 are exhaustive given the update rule at k and the induction hypothesis forMk\u22121.\nProving that the condition of Equation 17 holds forMk. Let us first prove that the condition of Equation 17 holds forMk. The proof is same for all the three cases C1, C2.1 and C2.2.\nFor k\u2032 = k. Then, Mka,k\u2032 +M k k\u2032,b = M k\u22121 a,k +M k\u22121 k,b\n\u2265 min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after the update, we haveMka,k\u2032 = M k\u22121 a,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,b . Then,\nMka,k\u2032 +M k k\u2032,b = M k\u22121 a,k\u2032 +M k\u22121 k\u2032,b\n\u2265Mk\u22121a,b \u2265 min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after the update, we haveMka,k\u2032 = M k\u22121 a,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,k +M k\u22121 k,b . Then,\nMka,k\u2032 +M k k\u2032,b = M k\u22121 a,k\u2032 +M k\u22121 k\u2032,k +M k\u22121 k,b\n\u2265Mk\u22121a,k +M k\u22121 k,b \u2265 min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after the update, we haveMka,k\u2032 = M k\u22121 a,k +M k\u22121 k,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,b . Then,\nMka,k\u2032 +M k k\u2032,b = M k\u22121 a,k +M k\u22121 k,k\u2032 +M k\u22121 k\u2032,b\n\u2265Mk\u22121a,k +M k\u22121 k,b \u2265 min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after the update, we haveMka,k\u2032 = M k\u22121 a,k +M k\u22121 k,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,k +M k\u22121 k,b . Then,\nMka,k\u2032 +M k k\u2032,b = M k\u22121 a,k +M k\u22121 k,k\u2032 +M k\u22121 k\u2032,k +M k\u22121 k,b\n\u2265Mk\u22121a,k +M k\u22121 k,b \u2265 min ( Mk\u22121a,b ,M k\u22121 a,k +M k\u22121 k,b ) = Mka,b\nProving that the condition of Equation 18 holds forMk. We will do this analysis case by case for the three cases C1, C2.1 and C2.2.\nFor case C1, i.e. Mka,b = M k\u22121 a,k +M k\u22121 k,b . Then,\nMka,b = M k\u22121 a,k +M k\u22121 k,b\n= Mka,k +M k k,b\nHence the condition of Equation 18 holds.\nFor case C2.1, i.e. Mka,b = M k\u22121 a,b = M 0 a,b. Then,\nMka,b = M k\u22121 a,b\n= M0a,b Hence the condition of Equation 18 holds.\nFor case C2.2, i.e. Mka,b = M k\u22121 a,b = M k\u22121 a,e +M k\u22121 e,b where e \u2208 [k\u2212 1]. Then, ifMk\u22121a,e +M k\u22121 e,b = M k a,e +M k e,b, we have:\nMka,b = M k\u22121 a,e +M k\u22121 e,b\n= Mka,e +M k e,b\nHence, assuming Mk\u22121a,e + M k\u22121 e,b = M k a,e + M k e,b, the condition of Equation 18 holds. We conclude by showing that Mk\u22121a,e +M k\u22121 e,b = M k a,e +M k e,b holds for C2.2. We show this by contradiction as follows. For the sake of contradiction, let us assume thatMk\u22121a,e +M k\u22121 e,b > M k a,e +M k e,b. Then,\nMka,b = M k\u22121 a,b = M k\u22121 a,e +M k\u22121 e,b\n> Mka,e +M k e,b\n=\u21d2 Mka,b > Mka,e +Mke,b This is a contradiction to the proof we did above showing that Mk satisfies Equation 17. Hence, it holds that Mka,b = M k a,e +M k e,b.\nNow, putting this all together, we have proved thatMk satisfies the conditions of Equations 17, 18. Hence by induction, the final output Mn of the algorithm U-PROJ satisfies these conditions as well, which is exactly equivalent to the claim of the lemma we want to prove.\nLemma 5. The function L-PROJ in Algorithm 4 with input parameters L\u0303t, U t returns Lt \u2208 L(U t) with the following property: for all i, j \u2208 [n] it holds that ( EitherLti,j = L\u0303 t i,j; OR \u2203k s.t. Lti,j = max ( Lti,k \u2212 U tj,k, Ltk,j \u2212 U tk,i )) .\nProof of Lemma 5. The proof follows similar ideas as in Lemma 4, however requires much more algebraic manipulations and cases for complete analysis. Furthermore, there is no direct analogue to shortest-path problem that existed for Lemma 4.\nFor ease of notation, let us defineM0 = L\u0303t. And, during an iteration of the outer loop of pivotsk \u2208 [n] for L-PROJ, we update Mki,j = max ( Mk\u22121i,j ,M k\u22121 i,k \u2212 U t j,k,M k\u22121 k,j \u2212 U t k,i ) At the end of execution, we have k = n, and the output of L-PROJ isMn. We will prove following properties ofMk at the end of every iteration k \u2208 [n] for \u2200a, b \u2208 [n]:\n\u2200k\u2032 \u2208 [k]Mka,b \u2265 max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) (19) Either Mka,b = M 0 a,b OR \u2203k\u2032 \u2208 [k] s.t. Mka,b = max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) (20)\nNote that the conditions hold trivially at the start since the range of k\u2032 is \u2205. Also, the claim of the lemma is equivalent to the statement that the two conditions above hold at the end when k = n. We will now prove this by induction.\nBase case forM0,M1: Conditions in Equations 19, 20 hold trivially for M0 since the range of k\u2032 is \u2205. Conditions in Equations 19,20 hold for M1\nsince the range of k\u2032 is [1], and \u2200a, b \u2208 [n] updateM1a,b = max ( M0a,b,M 0 a,1 \u2212 U tb,1,M01,a \u2212 U t1,b ) ensures that conditions hold.\nInduction hypothesis: At k \u2212 1,Mk\u22121 satisfies the conditions in Equations 19, 20.\nInductive step: Prove thatMk satisfies the conditions in Equations 19, 20 after we make the following update at iteration k:\n\u2200a, b \u2208 [n] updateMka,b = max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a ) Consider any a, b \u2208 [n]. We consider the following 3 cases depending on the type of update toMka,b.\nC1: Mka,b = max ( Mk\u22121a,k \u2212 U tb,k,M k\u22121 k,b \u2212 U tk,a ) C2: Mka,b = M k\u22121 a,b\nC2.1: Mk\u22121a,b = M 0 a,b C2.2: Mk\u22121a,b = max ( Mk\u22121a,e \u2212 U tb,e,M k\u22121 e,b \u2212 U te,a ) where e \u2208 [k \u2212 1]\nNote that the cases C1, C2.1 and C2.2 are exhaustive given the update rule at k and the induction hypothesis forMk\u22121.\nProving that the condition of Equation 19 holds forMk. Let us first prove that the condition of Equation 19 holds forMk. The proof is same for all the three cases C1, C2.1 and C2.2.\nFor k\u2032 = k. Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a ) \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after update, we haveMka,k\u2032 = M k\u22121 a,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,b . Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k\u2032 \u2212 U t b,k\u2032 ,M k\u22121 k\u2032,b \u2212 U t k\u2032,a ) \u2264Mk\u22121a,b \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after update, we haveMka,k\u2032 = M k\u22121 a,k\u2032 andM k k\u2032,b = M k\u22121 k\u2032,k \u2212 U tb,k. Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k\u2032 \u2212 U t b,k\u2032 ,M k\u22121 k\u2032,k \u2212 U t b,k \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k\u2032 \u2212 U t b,k\u2032 ,M k\u22121 k\u2032,k \u2212 U t k\u2032,a \u2212 U tb,k )\n\u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k ) \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after update, we haveMka,k\u2032 = M k\u22121 a,k\u2032 andM k k\u2032,b = M k\u22121 k,b \u2212 U tk,k\u2032 . Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k\u2032 \u2212 U t b,k\u2032 ,M k\u22121 k,b \u2212 U t k,k\u2032 \u2212 U tk\u2032,a ) \u2264 max ( Mk\u22121a,k\u2032 \u2212 U t b,k\u2032 ,M k\u22121 k,b \u2212 U t k,a\n) \u2264 max ( Mk\u22121a,b ,M k\u22121 k,b \u2212 U t k,a\n) \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after update, we haveMka,k\u2032 = M k\u22121 a,k \u2212 U tk\u2032,k andMkk\u2032,b = M k\u22121 k\u2032,b . Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121a,k \u2212 U t k\u2032,k \u2212 U tb,k\u2032 ,Mk\u22121k\u2032,b \u2212 U t k\u2032,a ) \u2264 max ( Mk\u22121a,k \u2212 U t b,k,M k\u22121 k\u2032,b \u2212 U t k\u2032,a\n) \u2264 max ( Mk\u22121a,k \u2212 U t b,k,M k\u22121 a,b\n) \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. If, after update, we haveMka,k\u2032 = M k\u22121 k,k\u2032 \u2212 U tk,a andMkk\u2032,b = M k\u22121 k\u2032,b . Then, max ( Mka,k\u2032 \u2212 U tb,k\u2032 ,Mkk\u2032,b \u2212 U tk\u2032,a ) = max ( Mk\u22121k,k\u2032 \u2212 U t k,a \u2212 U tb,k\u2032 ,Mk\u22121k\u2032,b \u2212 U t k\u2032,a ) = max ( Mk\u22121k,k\u2032 \u2212 U t b,k\u2032 \u2212 U tk,a,Mk\u22121k\u2032,b \u2212 U t k\u2032,a\n) \u2264 max ( Mk\u22121k,b \u2212 U t k,a,M k\u22121 a,b\n) \u2264 max ( Mk\u22121a,b ,M k\u22121 a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a\n) = Mka,b\nFor k\u2032 \u2208 [k], k\u2032 6= k. We need to consider following four more possibilities after update:\n\u2022 Mka,k\u2032 = M k\u22121 a,k \u2212 U tk\u2032,k andMkk\u2032,b = M k\u22121 k\u2032,k \u2212 U tb,k \u2022 Mka,k\u2032 = M k\u22121 a,k \u2212 U tk\u2032,k andMkk\u2032,b = M k\u22121 k,b \u2212 U tk,k\u2032 \u2022 Mka,k\u2032 = M k\u22121 k,k\u2032 \u2212 U tk,a andMkk\u2032,b = M k\u22121 k\u2032,k \u2212 U tb,k \u2022 Mka,k\u2032 = M k\u22121 k,k\u2032 \u2212 U tk,a andMkk\u2032,b = M k\u22121 k,b \u2212 U tk,k\u2032\nThese four possibilities follow exactly the same arguments as used above.\nProving that the condition of Equation 20 holds forMk. We will do this analysis case by case for the three cases C1, C2.1 and C2.2.\nFor case C1, i.e. Mka,b = max ( Mk\u22121a,k \u2212 U tb,k,M k\u22121 k,b \u2212 U tk,a ) . Then,\nMka,b = max ( Mk\u22121a,k \u2212 U t b,k,M k\u22121 k,b \u2212 U t k,a ) = max ( Mka,k \u2212 U tb,k,Mkk,b \u2212 U tk,a\n) Hence the condition of Equation 20 holds.\nFor case C2.1, i.e. Mka,b = M k\u22121 a,b = M 0 a,b. Then,\nMka,b = M k\u22121 a,b\n= M0a,b Hence the condition of Equation 20 holds.\nFor case C2.2, i.e. Mka,b = M k\u22121 a,b = max ( Mk\u22121a,e \u2212 U tb,e,M k\u22121 e,b \u2212 U te,a ) where e \u2208 [k \u2212 1]. Then, if we assume that\nmax ( Mk\u22121a,e \u2212 U tb,e,Mk\u22121e,b \u2212 U t e,a ) = max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a ) ,\nwe have: Mka,b = max ( Mk\u22121a,e \u2212 U tb,e,Mk\u22121e,b \u2212 U t e,a ) = max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a\n) Hence the condition of Equation 20 holds. We conclude by showing that the above assumption must be true for C2.2. We show this by contradiction as follows. For the sake of contradiction, let us assume that\nmax ( Mk\u22121a,e \u2212 U tb,e,Mk\u22121e,b \u2212 U t e,a ) < max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a ) Then,\nMka,b = max ( Mk\u22121a,e \u2212 U tb,e,Mk\u22121e,b \u2212 U t e,a ) < max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a\n) =\u21d2 Mka,b < max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a\n) This is a contradiction to the proof we did above showing that Mk satisfies Equation 19. Hence, it holds that Mka,b = max ( Mka,e \u2212 U tb,e,Mke,b \u2212 U te,a ) .\nNow, putting this all together, we have proved thatMk satisfies the conditions of Equations 19, 20. Hence by induction, the final output Mn of the algorithm L-PROJ satisfies these conditions as well, which is exactly equivalent to the claim of the lemma we want to prove.\nProof of Theorem 2. We want to prove that the lower and upper boundsLt, U t returned by LU-PROJ are the unique optimal solution of Problem P1. Given the results from Theorem 1, it is enough to show that the upper bound matrixU t is the optimal solution of Problem P2 and the lower bound matrixLt is the optimal solution of Problem P3.\nWe will prove this statement of optimality separately for U t and for Lt. The approach to prove optimality of upper bounds U t is similar in spirit to that of Brickell et al. (2008) who showed the optimality of downward-only projection for the metric-nearness problem. For our optimality proofs, we will use the specific properties of U t and Lt from Lemmas 4 and Lemma 5, respectively.\nProof of optimality of upper boundsU t. We will prove by contradiction. Consider the optimal solution of Problem P2 given byU\u2217t. Let us assume thatU t is not an optimal solution. Let us sort the indices (i, j) \u2208 [n]2 in order of increasing values ofU ti,j . For the sake of contradiction, let (a, b) be the first pair of indices in this sorted order such thatU\u2217ta,b > U t a,b. We will show that no such pair of indices (a, b) can exist.\nBy Lemma 4, we know thatU t returned by U-PROJ satisfies either:\nC1: U ta,b = U\u0303 ta,b or C2: \u2203k \u2208 [n] s.t. U ta,b = U ta,k + U tk,b Considering the case C1, we have the following contradiction:\nU ta,b = U\u0303 t a,b \u2265 U\u2217ta,b\nConsidering the case C2, we have the following contradiction: U ta,b = U t a,k + U t k,b \u2265 U\u2217ta,k + U\u2217tk,b \u2265 U\u2217ta,b, where the first inequality holds because of the considered order on the pair of indices.\nHence, we must haveU t \u2265 U\u2217t showing thatU t is an optimal solution. In fact, given the uniqueness of the optimal solution U\u2217t for Problem P2 which follows from results of Lemma 2, we haveU t = U\u2217t.\nProof of optimality of lower boundsLt. The ideas are similar as those used above for proving the optimality of U t. Again, we will prove by contradiction. Consider the optimal solution of Problem P3 given by L\u2217t. Let us assume that Lt is not an optimal solution. Let us sort the indices (i, j) \u2208 [n]2 in order of decreasing values of Lti,j . For the sake of contradiction, let (a, b) be the first pair of indices in this sorted order such thatL\u2217ta,b < L t a,b. By will show that it is not possible for this pair of indices (a, b) to exist.\nBy Lemma 5, we know thatLt returned by L-PROJ satisfies either:\nC1: Lta,b = L\u0303ta,b or C2: \u2203k \u2208 [n] s.t. Lta,b = max ( Lta,k \u2212 U tb,k, Ltk,b \u2212 U tk,a ) Considering the case C1, we have the following contradiction:\nLta,b = L\u0303 t a,b \u2264 L\u2217ta,b\nConsidering the case C2, we have the following contradiction: Lta,b = max ( Lta,k \u2212 U tb,k, Ltk,b \u2212 U tk,a ) \u2264 max ( L\u2217ta,k \u2212 U tb,k, L\u2217tk,b \u2212 U tk,a\n) = max ( L\u2217ta,k \u2212 U\u2217tb,k, L\u2217tk,b \u2212 U\u2217tk,a\n) \u2264 L\u2217ta,b,\nwhere the first inequality holds because of the considered order on the pair of indices.\nHence, we must have Lt \u2264 L\u2217t showing that Lt is an optimal solution. In fact, given the uniqueness of optimal solution L\u2217t for Problem P3 which follows from results of Lemma 3, we haveLt = L\u2217t."}], "references": [{"title": "Low-cost learning via active data procurement", "author": ["J. Abernethy", "Y. Chen", "C. Ho", "B. Waggoner"], "venue": "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,", "citeRegEx": "Abernethy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2015}, {"title": "Multiview triplet embedding: Learning attributes in multiple maps", "author": ["E. Amid", "A. Ukkonen"], "venue": "In ICML, pp", "citeRegEx": "Amid and Ukkonen,? \\Q2015\\E", "shortCiteRegEx": "Amid and Ukkonen", "year": 2015}, {"title": "A survey on metric learning for feature vectors and structured data", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "arXiv preprint arXiv:1306.6709,", "citeRegEx": "Bellet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2013}, {"title": "Learning what\u2019s going on: Reconstructing preferences and priorities from opaque transactions", "author": ["A. Blum", "Y. Mansour", "J. Morgenstern"], "venue": "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,", "citeRegEx": "Blum et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2015}, {"title": "The metric nearness problem", "author": ["J. Brickell", "I.S. Dhillon", "S. Sra", "J.A. Tropp"], "venue": "SIAM Journal on Matrix Analysis and Applications,", "citeRegEx": "Brickell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Brickell et al\\.", "year": 2008}, {"title": "Upper and lower error bounds for active learning", "author": ["Castro", "Rui M", "Nowak", "Robert D"], "venue": "In Allerton,", "citeRegEx": "Castro et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Castro et al\\.", "year": 2006}, {"title": "Learning user preferences for sets of objects", "author": ["M. Desjardins", "E. Eaton", "K.L. Wagstaff"], "venue": "In ICML, pp", "citeRegEx": "Desjardins et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Desjardins et al\\.", "year": 2006}, {"title": "Using the triangle inequality to accelerate k-means", "author": ["C. Elkan"], "venue": "In ICML,", "citeRegEx": "Elkan,? \\Q2003\\E", "shortCiteRegEx": "Elkan", "year": 2003}, {"title": "Learning local invariant mahalanobis distances", "author": ["E. Fetaya", "S. Ullman"], "venue": "In ICML,", "citeRegEx": "Fetaya and Ullman,? \\Q2015\\E", "shortCiteRegEx": "Fetaya and Ullman", "year": 2015}, {"title": "Algorithm 97: shortest path", "author": ["Floyd", "Robert W"], "venue": "Communications of the ACM,", "citeRegEx": "Floyd and W.,? \\Q1962\\E", "shortCiteRegEx": "Floyd and W.", "year": 1962}, {"title": "Manifoldranking based image retrieval", "author": ["J. He", "M. Li", "H. Zhang", "H. Tong", "C. Zhang"], "venue": "In Proceedings of the 12th annual ACM International Conference on Multimedia,", "citeRegEx": "He et al\\.,? \\Q2004\\E", "shortCiteRegEx": "He et al\\.", "year": 2004}, {"title": "At what quality and what price?: Eliciting buyer preferences as a market design problem", "author": ["J.J. Horton", "R. Johari"], "venue": "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,", "citeRegEx": "Horton and Johari,? \\Q2015\\E", "shortCiteRegEx": "Horton and Johari", "year": 2015}, {"title": "Logeuclidean metric learning on symmetric positive definite manifold with application to image set classification", "author": ["Z. Huang", "R. Wang", "S. Shan", "X. Li", "X. Chen"], "venue": "In ICML,", "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Low-dimensional embedding using adaptively selected ordinal data", "author": ["K.G. Jamieson", "R.D. Nowak"], "venue": "In Allerton,", "citeRegEx": "Jamieson and Nowak,? \\Q2011\\E", "shortCiteRegEx": "Jamieson and Nowak", "year": 2011}, {"title": "Active ranking using pairwise comparisons", "author": ["Jamieson", "Kevin G", "Nowak", "Robert"], "venue": "In NIPS, pp", "citeRegEx": "Jamieson et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jamieson et al\\.", "year": 2011}, {"title": "Active learning in the non-realizable case", "author": ["K\u00e4\u00e4ri\u00e4inen", "Matti"], "venue": "In ALT, pp", "citeRegEx": "K\u00e4\u00e4ri\u00e4inen and Matti.,? \\Q2006\\E", "shortCiteRegEx": "K\u00e4\u00e4ri\u00e4inen and Matti.", "year": 2006}, {"title": "Bayesian persuasion", "author": ["E. Kamenica", "M. Gentzkow"], "venue": "Technical report, National Bureau of Economic Research,", "citeRegEx": "Kamenica and Gentzkow,? \\Q2009\\E", "shortCiteRegEx": "Kamenica and Gentzkow", "year": 2009}, {"title": "Efficient learning of mahalanobis metrics for ranking", "author": ["D. Lim", "G. Lanckriet"], "venue": "In ICML, pp. 1980\u20131988,", "citeRegEx": "Lim and Lanckriet,? \\Q2014\\E", "shortCiteRegEx": "Lim and Lanckriet", "year": 2014}, {"title": "Similarity learning for high-dimensional sparse data", "author": ["Liu", "Kuan", "Bellet", "Aur\u00e9lien", "Sha", "Fei"], "venue": "In AISTATS, pp", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Margin-based active learning for structured output spaces", "author": ["Roth", "Dan", "Small", "Kevin"], "venue": "In ECML,", "citeRegEx": "Roth et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2006}, {"title": "Active learning", "author": ["B. Settles"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "Settles,? \\Q2012\\E", "shortCiteRegEx": "Settles", "year": 2012}, {"title": "Truthful incentives in crowdsourcing tasks using regret minimization mechanisms", "author": ["A. Singla", "A. Krause"], "venue": "In WWW, pp", "citeRegEx": "Singla and Krause,? \\Q2013\\E", "shortCiteRegEx": "Singla and Krause", "year": 2013}, {"title": "Incentivizing users for balancing bike sharing systems", "author": ["A. Singla", "M. Santoni", "G. Bart\u00f3k", "P. Mukerji", "M. Meenen", "A. Krause"], "venue": "In AAAI,", "citeRegEx": "Singla et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Singla et al\\.", "year": 2015}, {"title": "Adaptively learning the crowd kernel", "author": ["O. Tamuz", "C. Liu", "S. Belongie", "O. Shamir", "A.T. Kalai"], "venue": "In ICML,", "citeRegEx": "Tamuz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tamuz et al\\.", "year": 2011}, {"title": "Dimensionality reduction: A comparative review", "author": ["van der Maaten", "Laurens JP", "Postma", "Eric O", "van den Herik", "H Jaap"], "venue": null, "citeRegEx": "Maaten et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2009}, {"title": "Active learning and dynamic pricing policies", "author": ["M. V\u00e1zquez-Gallo", "M. Est\u00e9vez", "S. Egido"], "venue": "American Journal of Operations Research,", "citeRegEx": "V\u00e1zquez.Gallo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "V\u00e1zquez.Gallo et al\\.", "year": 2014}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "M.I. Jordan", "S. Russell", "A.Y. Ng"], "venue": "In NIPS, pp", "citeRegEx": "Xing et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Xing et al\\.", "year": 2002}, {"title": "Distance metric learning: A comprehensive survey", "author": ["Yang", "Liu", "Jin", "Rong"], "venue": "Michigan State Universiy,", "citeRegEx": "Yang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 26, "context": "In machine learning algorithms, the distances serve as a notion of similarity (or dissimilarity) between data points and are important for various tasks such as clustering (Xing et al., 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al.", "startOffset": 172, "endOffset": 191}, {"referenceID": 10, "context": ", 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.", "startOffset": 82, "endOffset": 119}, {"referenceID": 12, "context": ", 2002), object ranking (Lim & Lanckriet, 2014), image retrieval / classification (He et al., 2004; Huang et al., 2015), etc.", "startOffset": 82, "endOffset": 119}, {"referenceID": 6, "context": ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; V\u00e1zquez-Gallo et al., 2014).", "startOffset": 95, "endOffset": 190}, {"referenceID": 3, "context": ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; V\u00e1zquez-Gallo et al., 2014).", "startOffset": 95, "endOffset": 190}, {"referenceID": 25, "context": ", from a catalogue of products) to improve product recommendation and dynamic pricing of goods (Desjardins et al., 2006; Horton & Johari, 2015; Blum et al., 2015; V\u00e1zquez-Gallo et al., 2014).", "startOffset": 95, "endOffset": 190}, {"referenceID": 2, "context": "1 In economics, the distance function can encode the We refer the interested reader to the survey by Bellet et al. (2013) for a detailed discussion of various applications.", "startOffset": 101, "endOffset": 122}, {"referenceID": 0, "context": "This query is motivated by the posted-price model used in marketplaces (Abernethy et al., 2015; Singla & Krause, 2013), where users are offered a take-it-or-leave-it price by the system, and they can accept by providing a positive response, or reject by providing a negative response.", "startOffset": 71, "endOffset": 118}, {"referenceID": 20, "context": "old function in the active-learning setting (Castro & Nowak, 2006; Settles, 2012).", "startOffset": 44, "endOffset": 81}, {"referenceID": 20, "context": "One policy inspired by uncertainty sampling (Settles, 2012) is to pick the pair (i, j) with maximum uncertainty quantified by (U t\u22121 i,j \u2212L t\u22121 i,j ).", "startOffset": 44, "endOffset": 59}, {"referenceID": 4, "context": "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections.", "startOffset": 38, "endOffset": 61}, {"referenceID": 4, "context": "We compute D\u2217 as the closest metric toW according to Brickell et al. (2008). For different weights w1, .", "startOffset": 53, "endOffset": 76}, {"referenceID": 18, "context": "Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015).", "startOffset": 205, "endOffset": 223}, {"referenceID": 23, "context": "Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a).", "startOffset": 155, "endOffset": 239}, {"referenceID": 20, "context": "4 Active Learning Our problem formulation shares the goal of reducing sample complexity with other instances of active learning (Settles, 2012).", "startOffset": 128, "endOffset": 143}, {"referenceID": 16, "context": "We refer the reader to the detailed surveys by Yang & Jin (2006); van der Maaten et al. (2009); Bellet et al.", "startOffset": 74, "endOffset": 95}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following.", "startOffset": 8, "endOffset": 29}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation.", "startOffset": 8, "endOffset": 207}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework \u2014 for a triplet (i, j, k) it queries1(Di,j \u2264 Di,k) \u2014 has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses \u2014 they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality.", "startOffset": 8, "endOffset": 1749}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework \u2014 for a triplet (i, j, k) it queries1(Di,j \u2264 Di,k) \u2014 has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses \u2014 they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections.", "startOffset": 8, "endOffset": 1935}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework \u2014 for a triplet (i, j, k) it queries1(Di,j \u2264 Di,k) \u2014 has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses \u2014 they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach proposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries.", "startOffset": 8, "endOffset": 2360}, {"referenceID": 1, "context": "(2009); Bellet et al. (2013). Some of the key distinctions of our formulation from the existing research are described in the following. Supervised metric learning. In their seminal work, Xing et al. (2002) introduced the supervised metric learning framework for learning Mahalanobis distance functions via a convex formulation. In contrast to our setting, they assume that the algorithm has access to the feature space of the input data. Furthermore, this framework and its variants are restricted to recover symmetric distance functions. Another line of research considers learning asymmetric distances, for instance by learning local invariant Mahalanobis distances (Fetaya & Ullman, 2015) or by learning general bilinear similarity matrices (Liu et al., 2015). However, this line of work is not directly applicable to our setting because it also requires access to the feature space of the input data. Learning embeddings. Another line of research is that of learning low-dimensional embeddings for a set of items respecting the observed geometric relations between these items (Amid & Ukkonen, 2015; Tamuz et al., 2011; Cox & Cox, 2000; Jamieson & Nowak, 2011a). For applications involving human subjects, a triplet-based queries framework \u2014 for a triplet (i, j, k) it queries1(Di,j \u2264 Di,k) \u2014 has been employed. However the distances recovered from these approaches are merely optimized to respect the observed relations seen in the data from query responses \u2014 they are symmetric and importantly do not have an actual quantitative (economic) interpretation as we seek in our formulation. 8.2 Exploiting Structural Constraints Our approach of exploiting the structural constraints of the hemimetrics polytope is in part inspired by Elkan (2003), who acceleratesK-means by exploiting the triangle inequality. By maintaining bounds on the distances, he efficiently reduces the number of distance computations. Brickell et al. (2008) study the problem of projecting a non-metric matrix to a metric matrix, and consider a specific class of decrease-only projections. Our approach towards updating upper bounds via decrease-only projections is similar in spirit. However, the main technical difficulties arise in maintaining and updating the lower bounds, for which we develop novel techniques. The active-learning approach proposed by Jamieson & Nowak (2011a) exploits the geometry of the embedding space to minimize the sample complexity using triplet-based queries. While similar in spirit, their approach is based on triplet-based queries, and differs from our methodology of exploiting the structural constraints. 8.3 Learning User Preferences Another relevant line of research is concerned with eliciting user preferences. Specifically, we seek to learn private costs of a user for switching from her default choice of item i to instead choose item j. This type of preferences can be used in marketing applications, e.g., for persuading users to change their decisions (Kamenica & Gentzkow, 2009). Singla et al. (2015) considered similar preferences in the context of balancing a bike-sharing system by incentivizing users to go to alternate stations for pickup or dropoff of bikes.", "startOffset": 8, "endOffset": 3024}, {"referenceID": 0, "context": "Abernethy et al. (2015) considered the application of purchasing data from users, and quantified the prices that should be offered to them.", "startOffset": 0, "endOffset": 24}, {"referenceID": 4, "context": "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections.", "startOffset": 38, "endOffset": 61}, {"referenceID": 4, "context": "Similar equivalence has been shown by Brickell et al. (2008) while studying the problem of projecting a non-metric matrix to a metric via decrease-only projections. Brickell et al. (2008) used a similar result as Lemma 4, however they directly used the interpretation of shortest-path problem.", "startOffset": 38, "endOffset": 188}, {"referenceID": 4, "context": "The approach to prove optimality of upper bounds U t is similar in spirit to that of Brickell et al. (2008) who showed the optimality of downward-only projection for the metric-nearness problem.", "startOffset": 85, "endOffset": 108}], "year": 2016, "abstractText": "Motivated by an application of eliciting users\u2019 preferences, we investigate the problem of learning hemimetrics, i.e., pairwise distances among a set of n items that satisfy triangle inequalities and non-negativity constraints. In our application, the (asymmetric) distances quantify private costs a user incurs when substituting one item by another. We aim to learn these distances (costs) by asking the users whether they are willing to switch from one item to another for a given incentive offer. Without exploiting structural constraints of the hemimetric polytope, learning the distances between each pair of items requires \u0398(n) queries. We propose an active learning algorithm that substantially reduces this sample complexity by exploiting the structural constraints on the version space of hemimetrics. Our proposed algorithm achieves provably-optimal sample complexity for various instances of the task. For example, when the items are embedded into K tight clusters, the sample complexity of our algorithm reduces to O(nK). Extensive experiments on a restaurant recommendation data set support the conclusions of our theoretical analysis.", "creator": "LaTeX with hyperref package"}}}