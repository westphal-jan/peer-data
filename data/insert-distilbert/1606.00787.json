{"id": "1606.00787", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2016", "title": "Post-Inference Prior Swapping", "abstract": "while many bayesian methods alone are praised for their ability to incorporate useful prior knowledge, usually in practice, priors that allow insights for computationally convenient or tractable inference are more commonly used. in this paper, we investigate the discussed following question : for a given model, is it possible to entirely use any convenient prior to infer upon a false posterior, and afterwards, given somehow some true prior of interest, quickly transform this result into the true posterior?", "histories": [["v1", "Thu, 2 Jun 2016 18:20:35 GMT  (743kb,D)", "http://arxiv.org/abs/1606.00787v1", null], ["v2", "Wed, 12 Jul 2017 18:01:17 GMT  (878kb,D)", "http://arxiv.org/abs/1606.00787v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG stat.CO stat.ME", "authors": ["willie neiswanger", "eric p xing"], "accepted": true, "id": "1606.00787"}, "pdf": {"name": "1606.00787.pdf", "metadata": {"source": "CRF", "title": "Prior Swapping for Data-Independent Inference", "authors": ["Willie Neiswanger", "Eric P. Xing"], "emails": ["WILLIE@CS.CMU.EDU", "EPXING@CS.CMU.EDU"], "sections": [{"heading": null, "text": "We present a procedure to carry out this task: given an inferred false posterior and true prior, our algorithm generates samples from the true posterior. This transformation procedure, which we call \u201cprior swapping\u201d works for arbitrary priors. Notably, its cost is independent of data size. It therefore allows us, in some cases, to apply significantly less-costly inference procedures to more-sophisticated models than previously possible. It also lets us quickly perform any additional inferences, such as with updated priors or for many different hyperparameter settings, without touching the data. We prove that our method can generate asymptotically exact samples, and demonstrate it empirically on a number of models and priors."}, {"heading": "1. Introduction", "text": "There are many cases in Bayesian modeling where a certain choice of prior distribution allows for computationally simple or tractable inference. For example,\n\u2022 Conjugate priors yield posteriors with a known parametric form and therefore allow for noniterative, exact inference [9, 14].\n\u2022 Certain priors yield models with tractable conditional or marginal distributions, which allows efficient approximate inference algorithms to be applied (e.g. Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).\n\u2022 Simple parametric priors (e.g. the normal distribution) allow for computationally cheap density queries, maximization, and sampling [2], which can allow for easier use in iterative inference algorithms (e.g. Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).\n\u2022 Certain priors mitigate issues of identifiability, and allow for simpler posteriors without multiple modes [43].\nHowever, more sophisticated priors that provide a better depiction of observed or expert knowledge do not, in general, allow for the above inference techniques. Instead, researchers must resort to more general and computationally expensive inference methods. This can encourage the use of convenient priors in practice, rather than priors that might yield a more realistic or accurate inference, which is a criticism of Bayesian methods [15].\nIn this paper, we investigate the following question: for a given model, is it possible to use any convenient prior to infer a false posterior, and afterwards, given some true prior of interest, quickly transform this result into the true posterior?\nar X\niv :1\n60 6.\n00 78\n7v 1\n[ st\nat .M\nL ]\n2 J\nun 2\nIntuitively, our strategy is the following: for a given model, we first choose any computationally convenient false prior, and perform inference, which returns the false posterior. We then use our inferred false posterior, a true prior of interest, and the false prior, to efficiently produce samples from the true posterior via a method we call prior swapping.\nOne key attribute of prior swapping is that it runs without touching any data. Existing general inference algorithms are iterative and data-dependent: parameter updates at each iteration involve data, and the computational complexity or quality of each update depends on the amount of data used. Thus, inference on larger datasets takes more time. Furthermore, in practice, we often want to perform inference for a number of different priors or hyperparameter settings; for each, some data-dependent inference algorithm must be run to compute a new result.\nIn contrast, prior swapping algorithms are data-independent\u2014i.e. parameter updates do not involve data, and neither the complexity nor quality of each update depends on data size. We therefore advocate doing difficult inference in two steps: first, perform data-dependent inference using the most computationally convenient prior for a given model, and then, for all future priors of interest (e.g. complex priors or a range of prior hyperparameter settings), perform quick, data-independent prior swapping. We summarize the advantages of this approach:\n1. There often exists some false posterior that can be computed more efficiently than the true posterior; in some cases, we can therefore apply significantly less-costly inference procedures to more-sophisticated models than previously possible.\n2. The prior swapping procedure runs independently of the data; this can allow for considerable speed-ups when doing inference on large datasets or ranges of hyperparameter values.\n3. We can often maintain theoretical guarantees of existing approximate inference algorithms; e.g. when inferring the false posterior with an asymptotically-exact method (such as sampling), prior swapping can return asymptotically-exact true posterior samples.\n4. We can update our prior, or incorporate new prior information, in an online fashion, without redoing data-dependent inference.\n5. This is a black box procedure, which can be run directly on the output of most existing inference methods to add richer prior information to inference results."}, {"heading": "2. Prior Swapping", "text": "Suppose we have a dataset of n real, finite-dimensional vectors xn = {x1, . . . , xn} \u2282 Rm, and we are interested in a family of models specified by the likelihood function fx |\u03b8 (xn|\u03b8), parameterized by a real, d-dimensional vector \u03b8 \u2208 Rd . Suppose we have a prior distribution over the space of model parameters \u03b8 , with probability density function (PDF) f\u03b8 (\u03b8). The likelihood and prior define a joint model given by the PDF f\u03b8 ,x(\u03b8 , xn) = f\u03b8 (\u03b8) fx |\u03b8 (xn|\u03b8). In Bayesian inference, we are interested in computing the posterior distribution\u2014i.e. a conditional distribution of this joint model\u2014with PDF\nf\u03b8 |x(\u03b8 |xn) = f\u03b8 (\u03b8) fx |\u03b8 (xn|\u03b8) \u222b\nf\u03b8 (\u03b8) fx |\u03b8 (xn|\u03b8) d\u03b8 =\n1 Z f\u03b8 (\u03b8) fx |\u03b8 (x n|\u03b8). (1)\nSuppose we\u2019ve chosen a different prior distribution f\u03c6(\u03b8), which we refer to as a false prior (while we refer to f\u03b8 (\u03b8) as the true prior). We can now can define a new joint model f\u03c6,x(\u03b8 , xn) = f\u03c6(\u03b8) fx |\u03b8 (xn|\u03b8), with posterior (conditional) PDF f\u03c6|x(\u03b8 |xn) = 1 Z\nf\u03c6(\u03b8) fx |\u03b8 (xn|\u03b8). We refer to this second posterior distribution as a false posterior.\nThe goal of our method is to first infer a false posterior and then leverage it to infer a true posterior. To carry out this transformation, we use the prior swap function f\neps, which we define as the false posterior density multiplied by the true prior density and divided by the false prior density, i.e.\nf eps(\u03b8) = f\u03c6|x(\u03b8 |xn) f\u03b8 (\u03b8) f\u03c6(\u03b8) \u221d f\u03c6(\u03b8) fx |\u03b8 (xn|\u03b8) f\u03b8 (\u03b8) f\u03c6(\u03b8) \u221d f\u03b8 |x(\u03b8 |xn). (2)\nNote that f eps is proportional to the true posterior density f\u03b8 |x . However, depending on how we\nrepresent the false posterior f\u03c6|x , f eps can have a much simpler analytic representation than f\u03b8 |x , which is typically defined via a likelihood function (which is a function of the data; see Eq. 1). It is therefore often possible to apply existing inference algorithms to f\neps, instead of f\u03b8 |x , to perform quicker inference. We will use fps to denote the prior swap density, i.e. fps = 1 Z f eps.\nOur strategy is to first compute some expression for f\u03c6|x , and then infer the true posterior using fps as a target density. This can be done with various types of inference for f\u03c6|x , including closed form (exact) computations, sampling-based methods (such as Markov chain Monte Carlo), and other approximate inference strategies such as variational inference and expectation propagation methods. We illustrate prior swapping in Fig. 1.\nFixed-complexity false posterior. As a first case, suppose that we have computed an analytic expression f \u2217\n\u03c6|x for the false posterior density with a fixed-complexity parametric form (i.e. the complexity of the expression does not grow as inference proceeds). For example, this is the case if we\n\u2022 Compute f\u03c6|x exactly (in a closed form) via a conjugate prior.\n\u2022 Generate samples from f\u03c6|x , via MCMC or other sampling methods, then use these samples to compute a parametric density estimate f\u0302 p\n\u03c6|x .\n\u2022 Apply optimization-based approximate inference methods, such as variational inference or expectation propagation, that return analytic approximate posteriors f\u0302 VI\n\u03c6|x or f\u0302 EP \u03c6|x .\nIn each case, while we use some data-dependent algorithm to infer the false posterior, our resulting expression f \u2217\n\u03c6|x is not a function of the data. Given this expression, consider the functions\nf \u2217 eps(\u03b8) =\nf \u2217 \u03c6|x(\u03b8) f\u03b8 (\u03b8)\nf\u03c6(\u03b8) (3) and \u2207\u03b8 log f \u2217 eps(\u03b8) =\u2207\u03b8 log f \u2217\u03c6|x(\u03b8) + log f\u03b8 (\u03b8)\u2212 log f\u03c6(\u03b8) . (4)\nWe can use these to draw posterior samples extremely efficiently with a variety of standard MCMC algorithms. At each iteration in MCMC, to draw a new parameter, we must evaluate a target function associated with the posterior density. For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]). Due to the likelihood function in f\u03b8 |x , these target functions are data-dependent.\nIn prior swapping, we instead evaluate f \u2217 eps(\u03b8) (Eq. 3) in MH, or \u2207\u03b8 log f \u2217 eps(\u03b8) (Eq. 4) in LD, HMC, or gradient ascent optimization to a MAP point estimate (see appendix for detailed algorithm pseudocode). Here, each iteration only requires evaluating a few simple analytic expressions, and thus has O(1) complexity with respect to data size.\nConsistent false posterior. Suppose our false posterior inference procedure yields a set of samples {e\u03b8t}Tt=1 \u223c f\u03c6|x . Above, we proposed the strategy of computing a fixed-complexity parametric density estimate f\u0302 p\n\u03c6|x , and plugging this into the prior swap function (which we will denote f\u0302 p eps). This f\u0302 p \u03c6|x is,\nin general, an inconsistent estimate of f\u03c6|x , and using it in prior swapping yields asymptotically-biased samples from f\u03b8 |x . Here, we aim to answer the question: given samples from f\u03c6|x , can we develop an efficient method that returns asymptotically-exact samples from f\u03b8 |x?\nSuppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate. We will prove (Sec. 2.1) that plugging a consistent estimate for f\u03c6|x into the prior swap function yields asymptotically-exact samples. However, the cost of these consistent estimates grows with the number of samples T ; typically, evaluating their PDF or gradient has a complexity of O(T). Using these estimates for f\u03c6|x in the above prior swapping procedure therefore has a complexity of O(T ) per iteration, which is costly for large T .\nWe instead propose the following prior swapping method, which still yields asymptoticallyexact samples from f\u03b8 |x , yet does not require a significant increase in computation: first generate approximate posterior samples using f\u0302 p\neps (as above), and then correct these samples via algorithms from the parallel MCMC literature (described below), designed to sample from the product of densities.\nTo motivate this method, we choose a a consistent semiparametric false posterior estimate f\u0302 s \u03c6|x (see [18] for background and consistency guarantees), which can be viewed as the product of a parametric density estimate f\u0302 p\n\u03c6|x and a nonparametric correction function. This is written\nf\u0302 s\u03c6|x(\u03b8) = 1\nT\nT \u2211\nt=1\n\n \n1\nhd K \u2016\u03b8 \u2212 e\u03b8t\u2016 h\n! f\u0302 p \u03c6|x(\u03b8)\nf\u0302 p \u03c6|x( e\u03b8t)\n\n  , (5)\nwhere we use K to denote a probability density kernel, with bandwidth h, where h\u2192 0 as T \u2192\u221e (see [58] for details on probability density kernels and bandwidth selection). A general parametric family for f\u0302 p\n\u03c6|x that we can use in nearly all cases is the family of false prior distributions. These are typically simple parametric distributions over the correct parameter space, which contain parameterizations in a broad vicinity of f\u03c6|x , and for which there exist efficient parameter estimation algorithms. Given f\u0302 s \u03c6|x , we write the semiparametric prior swap function as\nf\u0302 s eps(\u03b8) =\nf\u0302 s \u03c6|x(\u03b8) f\u03b8 (\u03b8)\nf\u03c6(\u03b8) =\n1\nT\nT \u2211\nt=1\n1 hd K \u2016\u03b8\u2212e\u03b8t\u2016 h f\u0302 p \u03c6|x(\u03b8) f\u03b8 (\u03b8)\nf\u0302 p \u03c6|x( e\u03b8t) f\u03c6(\u03b8) (6)\n=\n\n\nf\u0302 p \u03c6|x(\u03b8) f\u03b8 (\u03b8)\nf\u03c6(\u03b8)\n\n\n\n  \n1\nT\nT \u2211\nt=1\nK \u2016\u03b8\u2212e\u03b8t\u2016 h\nf\u0302 p \u03c6|x( e\u03b8t)hd\n\n   = h f\u0302 p eps(\u03b8) i\n\n\n1\nT\nT \u2211\nt=1\nwt K \u2016\u03b8 \u2212 e\u03b8t\u2016 h\n!\n .\nHence, the prior swap function is proportional to the product of two densities: the parametric prior swap density, and a correction density. We can easily generate samples from both of the densities that comprise f\u0302 s\neps\u2014the former with (fixed-complexity) parametric prior swapping and the latter by sampling from components in the correction density with frequency proportional to the components\u2019 weights.\nAlgorithm 1: Asymptotically-exact prior swapping\nInput: False posterior samples {e\u03b8t}Tt=1 \u223c f\u03c6|x(\u03b8 |x n). Output: Samples {\u03b8t}Tt=1 \u223c f\u0302 s ps(\u03b8) T\u2192\u221e\u2212\u2192 f\u03b8 |x(\u03b8 |xn).\n1 Estimate f\u0302 p \u03c6|x using {e\u03b8t} T t=1 . parametric estimate. 2 Sample {\u03b8 1t } T t=1 \u223c f\u0302 p ps(\u03b8 ) . parametric prior swapping.\n3 Sample {\u03b8 2t } T t=1 \u223c 1 T \u2211T t=1 f\u0302 p \u03c6|x( e\u03b8t)\u22121K \u2016\u03b8\u2212e\u03b8t\u2016 h . 4 Sample {\u03b8t}Tt=1 \u223c f\u0302 s ps(\u03b8) via Prod {\u03b8 1t } T t=1, {\u03b8 2 t } T t=1 .\nWe therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42]. Given two sets of samples {\u03b8 1t } T t=1 \u223c f1(\u03b8) and {\u03b8 2 t } T t=1 \u223c f2(\u03b8), these algorithms aim to return Prod({\u03b8 1t1} T t=1, {\u03b8 2 t2 }Tt=1) = {\u03b8t} T t=1 \u223c 1 Z\nf1 f2(\u03b8). These methods are efficient because each density product sample can be generated without iterating through either set of T input samples; typically, only a single sample from each input density is required. Each sample can therefore be produced with constant O(1) complexity. We summarize the full asymptotically-exact prior swapping procedure in Alg. 1. In the appendix, we give pseudocode for the density product sample combination algorithms, summarize the complexity of all methods, and also discuss how this semiparametric prior swapping method allows for easy incorporation of observed prior information.\nThis setting also has some relation to importance sampling (IS) [2]. For example, one could use the false posterior as an IS proposal (i.e. simply reweight and then use samples from f\u03c6|x). However, in practice, performance would only be adequate for false posteriors that are very similar to the true posterior (and not for arbitrary f\u03c6|x), especially in high dimensions [35, 54]. We show this empirically by comparing against this strategy in Sec. 3."}, {"heading": "2.1 Theoretical Guarantees", "text": "Here we give theoretical guarantees about the correctness of the samples generated via prior swapping. First, note that if we have an exact analytic expression f \u2217\n\u03c6|x for the false posterior, the prior swap function is proportional to the true posterior, i.e. f \u2217\neps = f eps \u221d f\u03b8 |x . Using f \u2217 eps in standard MCMC\nalgorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].\nIn the second setting, to prove that we generate asymptotically-exact samples given a consistent false posterior estimator, we need to show, as T \u2192\u221e, that f\u0302 sps is consistent for fps and that Alg. 1 indeed draws samples from f\u0302 sps.\nTheorem 2.1. Given false posterior samples {e\u03b8t}Tt=1 \u223c f\u03c6|x and h T \u22121/(4+d), the estimator f\u0302 s\neps (Eq. 6) is consistent for f\neps, i.e. its mean-squared error satisfies\nsup fps\u2208P(2,L)\nE \u222b\nf\u0302 s eps(\u03b8)\u2212 f eps(\u03b8)\n2 d\u03b8 < c\nT 4/(4+d)\nfor some c > 0 and 0< h\u2264 1.\nTheorem 2.2. The procedure given in Alg. 1 generates samples from f\u0302 sps (Eq. 6) as T \u2192\u221e.\nProofs for both theorems and definition of P(2, L) are given in the appendix."}, {"heading": "3. Empirical Results", "text": "We show empirical results on Bayesian generalized linear models (including linear and hierarchical logistic regression) with sparsity and heavy tailed priors, on latent factor models (including mixture models and topic models) with relational priors over factors (e.g. diversity-encouraging, agglomerateencouraging, etc.), and feedforward neural networks, where we show hyperparameter tuning of weight-decay L2 regularization via prior swapping with normal priors. We aim to demonstrate empirically that prior swapping allows us to apply less-costly inference algorithms to more-complex models than was previously possible, and that it efficiently yields correct samples. We compare the following inference procedures:\n\u2022 MCMC on the true posterior: MCMC sampling algorithms run directly on f\u03b8 |x .\n\u2022 VI on the true posterior: variational inference algorithms run directly on f\u03b8 |x .\n\u2022 False posterior: using the inferred false posterior f\u03c6|x .\n\u2022 Importance sampling with false posterior proposal: using f\u03c6|x as a proposal density and running importance sampling.\n\u2022 Prior swapping (fixed-complexity): prior swapping using a fixed-complexity expression f \u2217 \u03c6|x ,\nincluding exactly-computed f\u03c6|x , parametric estimates f\u0302 p \u03c6|x , and approximations f\u0302 VI \u03c6|x .\n\u2022 Prior swapping (consistent): prior swapping via Alg. 1 using a semiparametric f\u0302 s \u03c6|x .\n\u2022 Prior swapping to MAP: optimization, using the prior swap function, to a MAP point estimate.\n\u2022 False-true hybrid prior prior swapping on f\u03c6|x(\u03b8) f\u03b8 (\u03b8) without dividing out the false prior.\n\u2022 Normal approximation: prior swapping using normal approximations for f\u03c6|x , f\u03b8 , and f\u03c6 .\nTo assess performance, we use two metrics: posterior error and test error. To compute posterior error, we run a single chain of MCMC on the true posterior for one million steps, and use these samples as groundtruth (after removing the first quarter as burn in). We then compare these groundtruth samples with those returned by our inference methods. Specifically, we compute the Euclidean distance between the means of both sets of samples, the Euclidean distance between the variances of both sets of samples, and the estimated L2 distance between the groundtruth density f and a sampled posterior density f\u0302 : d2( f , f\u0302 ) = \u2016 f \u2212 f\u0302 \u20162 = ( \u222b\n( f (\u03b8)\u2212 f\u0302 (\u03b8))2)1/2. Posterior error is the normalized average of these three computations. Test error, which we report for classification models, is the proportion of misclassified held-out (test) data. For timing plots, to assess performance at a given time point, we collect samples drawn before this time point, remove the first quarter as burn in, and compute the above metrics."}, {"heading": "3.1 Sparsity Inducing and Heavy Tailed Priors in Generalized Linear Models", "text": "Sparsity-encouraging regularizers have gained a high level of popularity over the past decade due to their ability to produce models with greater interpretability, predictive accuracy, and parsimony. For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6]. In a Bayesian setting, inference given a sparsity prior can be difficult, and researchers often resort to computationally intensive methods (such as Hamiltonian Monte Carlo) or biased posterior approximations (e.g. expectation propagation [31]) that make factorization or parametric assumptions [49, 16]. We provide a cheap yet accurate solution: first use a more-tractable prior (such as a normal prior, in which closed form inference is possible), and then use prior swapping to quickly convert the result to the posterior given a sparsity prior.\nOur first set of experiments are on sparse Bayesian linear regression models [49, 30], which we can write as yi = X i\u03b8+\u03b5, \u03b5\u223cN (0,\u03c32), \u03b8 \u223c f\u03b8 , i = 1,...,n. For f\u03b8 , we compute results on on Laplace, Student\u2019s t, and VerySparse (with PDF VerySparse(\u03c3) =\n\u220fd i=1 1 2\u03c3 exp{\u2212|\u03b8i |0.4/\u03c3} [49]) priors. Here, a normal f\u03c6 is conjugate and allows for exact inference. Our second set of experiments are on a hierarchical Bayesian logistic regression model [20, 13], which we write as yi \u223c Bern(pi), pi = logistic(X i\u03b8 ), \u03b8 \u223c f\u03b8 , i = 1,...,n. We will consider a hierarchical f\u03b8 =N (0,\u03b1\u22121 I), \u03b1\u223c Gamma(\u03b3, 1).\nHere, we also use a normal f\u03c6 (see [20, 1] for examples of convenient inference in Bayesian logistic regression under normal priors). In these experiments, we generate synthetic data from the models in order to show results under varying n and d. For comparison methods, we use MH for MCMC, and a mean field approximation [13] for VI.\nIn Fig. 2 we show results for sparse linear models, with n=10,000 observations, and d=20 dimensions. In (a) and (b) we show convergence plots and see that prior swapping performs faster inference (by a few orders of magnitude) than MCMC. We also see that semiparametric prior swapping (Alg. 1) achieves nearly identical performance as prior swapping on the exactly computed f\u03c6|x . The other comparison methods yield posteriors that are incorrect or very slow to converge. In (b) we halve the variance of our false prior, which hurts performance of the comparison methods, but leaves prior swapping unchanged. In (c) we show 1-d density marginals as we increase the prior sparsity, and in (d) we show prior swapping results for different sparsity priors.\nIn Fig. 3, we show results for hierarchical logistic regression. In (a) and (b) we vary the number of observations (n=10-120,000) and see that prior swapping has a constant wall time while the wall times of both MCMC and VI increase with n. In (b) we see that the prior swapping methods achieve the same test error as the standard inference methods. In (c) and (d) we vary the number of dimensions (d=1-40). In this case, all methods have increasing wall time, and again the test errors match. In (e), (f), and (g), we vary the prior hyperparameter (\u03b3=1-1.05). For prior swapping, we infer a single f\u03c6|x (using \u03b3= 1.025) with both MCMC and VI, and compute all other hyperparameter results using this f\u03c6|x . This demonstrates that prior swapping can quickly infer correct results over a range of hyperparameters. Here, the asymptotically-exact semiparametric prior swapping method matches the test error of MCMC slightly better than the parametric method."}, {"heading": "3.2 Relational Priors over Factors in Latent Variable Models", "text": "Many latent variable models in machine learning\u2014such as mixture models, topic models, probabilistic matrix factorization, and various others\u2014involve a set of latent factors (e.g. components or topics). Often, we\u2019d like to use priors that encourage interesting behaviors among the factors. For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64]. Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].\nHowever, when conjugate priors are placed over the factor parameters, collapsed Gibbs sampling can be applied. In this method, the factor parameters are integrated out, leaving only a subset of variables; on these, the conditional distributions can be computed analytically, which allows for Gibbs sampling over these variables. Afterwards, samples of the collapsed factor parameters can be computed.\nHence, we propose the following strategy: first, assign a prior for the factor parameters that allows for collapsed Gibbs sampling; afterwards, reconstruct the factor samples and apply prior swapping for more complex relational priors over the factors. We can thus perform convenient inference in the collapsed model, yet apply more-sophisticated priors to variables in the uncollapsed model.\nWe first show results on a Gaussian mixture model (GMM) [27, 51], written x i \u223cN (\u00b5zi ,\u03a3zi ), zi \u223c Dir(\u03b1), {\u00b5m}Mm=1 \u223c f\u03b8 , i = 1,...,n. Using a normal f\u03c6 over {\u00b5m} M m=1 allows for collapsed Gibbs sampling. We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]). Here, using a Dirichlet f\u03c6 over topics allows for collapsed Gibbs sampling. For mixture models, we generate synthetic data from the above model (n=10,000, d=2, M=9), and for topic models, we use the Simple English Wikipedia\u2217 corpus (n=27,443 documents, vocab=10,192 words) [36], and set M=400 topics.\nIn Fig. 4 we show results for mixture and topic models. In (a) we show inferred posteriors over GMM components for a number of relational priors, which we define in (b). In (c), we apply the diversity-promoting prior to LDA, to separate redundant topics. Here, we show two topic-clusters (\u201cgeography\u201d and \u201cfamily\u201d) in f\u03c6|x , which are separated into thematically-similar yet distinct topics after prior swapping. In (a) and (c) we also show wall times of the inference methods.\n\u2217. https://simple.wikipedia.org/"}, {"heading": "3.3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks", "text": "Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17]. Since the prior swap function can be used as an objective for optimization to a MAP estimate, we aim to use prior swapping for quick hyperparameter tuning of weight decay in neural networks. We will compare this to finding the optimal weight decay via stochastic gradient descent [4] and stochastic gradient Langevin dynamics [59], two popular methods for learning and inference in neural networks. These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity. Furthermore, note that we can use stochastic gradient inference methods in conjunction with prior swapping (i.e. to compute f\u03c6|x , which we will do here).\nWe run our experiment on an eight-layer fully connected deep neural network with 400 nodes per layer, yielding a model with 1,280,410 dimensions. For data, we use the MNIST\u2020 handwritten digits classification dataset (n=60,000, d=784) [25]. We consider a family of true priors f\u03b8 = N (0,\u03c32 I) over neural network parameters (for weight decay), and aim to compute MAP point esti-\nmates over a range of hyperparameters \u03c32. Due to the high dimensionality, we make a parametric approximation f\u0302 p\n\u03c6|x for the false posterior, which we assume to be normal with a diagonal covariance\nmatrix. We use SGLD to infer f\u0302 p \u03c6|x (choosing a single \u03c3 2 to parameterize f\u03c6). For prior swapping, we use this f\u0302 p \u03c6|x to learn MAP estimates for all other \u03c3 2 values in the range.\nIn Fig 5 we show wall time and test error for the comparison methods over the set of weight decay parameters (\u03c32=50-10,000). For prior swapping, we perform gradient ascent optimization using the gradient log prior swap function (Eq. 4). We see in (c) that all methods yield the same optimal parameter (\u03c32=550) with the lowest test error. However, in (a) and (b) we see that prior swapping takes less time than SGD and SGLD."}, {"heading": "4. Conclusion", "text": "We have presented procedures to carry out the task of prior swapping: given any false posterior (computed using some convenient false prior) and a true prior of interest, our algorithms generate samples from the true posterior. Empirically, we have demonstrated prior swapping on a number of models and priors, and have shown that it can (1) quickly generate correct samples, (2) allow for less-costly data-dependent inference algorithms to be applied to more-complex models than previously possible, (3) allow for quick model selection or hyperparameter tuning, and (4) be used directly on top of existing inference algorithms to add richer prior information to pre-computed inference results, without having to revisit the data. Theoretically, we have shown that, given a stream of false posterior samples, this strategy can be used to generate asymptotically exact samples from the true posterior.\nWe furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26]. Since prior swapping does not require tuning and can be applied directly to the output of inference yielded by these frameworks, it has potential to aid in general purpose automated inference with more-realistic and difficult priors.\n\u2020. http://yann.lecun.com/exdb/mnist/"}, {"heading": "Appendix A. Proofs of Theoretical Guarantees", "text": "Here, we prove the two theorems stated in Sec. 2.1. Throughout this analysis, we assume that we have T samples {e\u03b8t}Tt=1 \u2282 X \u2282 R\nd from the falseposterior f\u03c6|x , and that h \u2208 R+ denotes the bandwidth of our semiparametric false-posterior density estimator f\u0302 s\n\u03c6|x . Let H\u00f6lder class \u03a3(2, L) on X be defined as the set of all `= b2c times differentiable functions f : X \u2192 R whose derivative f (l) satisfies\n| f (`)(\u03b8)\u2212 f (`)(\u03b8 \u2032)| \u2264 L \u03b8 \u2212 \u03b8 \u2032 2\u2212` for all \u03b8 ,\u03b8 \u2032 \u2208 X .\nWe also define the class of densities P(2, L) to be\nP(2, L) = \u00a8 f \u2208 \u03a3(2, L) f \u2265 0, \u222b f (\u03b8)d\u03b8 = 1 \u00ab .\nWe also assume that the false-posterior density f\u03c6|x is bounded, i.e. that there exists some b > 0 such that f\u03c6|x(\u03b8)\u2264 b for all \u03b8 \u2208 Rd .\nTheorem 2.1. Given false posterior samples {\u03b8\u0303t}Tt=1 \u223c f\u03c6|x and h T \u22121/(4+d), the estimator f\u0302 s\neps (Eq. 6) is consistent, i.e. its mean-squared error satisfies\nsup fps\u2208P(2,L)\nE \u222b\nf\u0302 s eps(\u03b8)\u2212 f eps(\u03b8)\n2 d\u03b8 < c\nT 4/(4+d)\nfor some c > 0 and 0< h\u2264 1.\nProof. To prove mean-square consistency of our semiparametric prior swap estimator f\u0302 s eps, we give a bound on the mean-squared error (MSE), and show that it tends to zero as we increase the number of samples drawn from the false-posterior. To prove this, we bound the bias and variance of the estimator, and use this to bound the MSE.\nWe first bound the bias of our semiparametric prior swap estimator. For any fps \u2208 P(2, L), we can write the bias as\nE h\nf\u0302 s eps\ni\n\u2212 f eps = E f\u0302 s\u03c6|x f\u03b8 f\u03c6 \u2212 f\u03c6|x f\u03b8 f\u03c6\n= f\u03b8 f\u03c6 E h f\u0302 s\u03c6|x i \u2212 f\u03c6|x\n= c\u0303 E h f\u0302 s\u03c6|x i \u2212 f\u03c6|x\n\u2264 ch2\nfor some c > 0, where we have used the fact that E h\nf\u0302 s \u03c6|x\ni\n\u2212 f\u03c6|x \u2264 c\u0303h2 for some c\u0303 > 0 (given in [18, 58]).\nWe next bound the variance of our semiparametric prior swap estimator. For any fps \u2208 P(2, L), we can write the variance of our estimator as\nVar h\nf\u0302 s eps\ni\n= Var f\u0302 s\u03c6|x f\u03b8 f\u03c6 = f 2\u03b8 f 2 \u03c6 Var h f\u0302 s\u03c6|x i \u2264 c\nThd\nfor some c > 0, where we have used the facts that Var h\nf\u0302 s \u03c6|x\ni\n\u2264 c Thd\nfor some c > 0 and E h\nf\u0302 s \u03c6|x\ni2 \u2264 c\u0303\nfor some c\u0303 > 0 (given in [18, 58]). Next, we will use these two results to bound the mean-squared error of our semiparametric prior swap estimator, which shows that it is mean-square consistent. We can write the mean-squared error as the sum of the variance and the bias-squared, and therefore,\nE \u222b\nf\u0302 s eps(\u03b8)\u2212 f eps(\u03b8)\n2 d\u03b8 \u2264 c1h2 + c2\nThd\n= c\nT 4/(4+d)\nfor some c > 0, using the fact that h T\u22121/(4+d).\nTheorem 2.2. The procedure given in Alg. 1 generates samples from f\u0302 sps (Eq. 6) as T \u2192\u221e.\nProof. In Alg. 1, note that line 2 is equivalent to standard MCMC (such as Metropolis-Hastings or Hamiltonian Monte Carlo) run on a posterior target function proportional to f\u0302 p\neps, and thus yields\nsamples from f\u0302 pps as T \u2192\u221e (see [8, 2, 34] for MCMC guarantees).\nIn line 3, we can sample from 1 T \u2211T t=1 f\u0302 p \u03c6|x( e\u03b8t)\u22121K \u2016\u03b8\u2212e\u03b8t\u2016 h exactly via the following procedure:\nFor each sample s,\n1. Draw an index i \u2208 {1, . . . , T}: i \u223c Cat n f\u0302 p \u03c6|x( e\u03b8t)\u22121 oT\nt=1\n.\n2. Draw the sample \u03b8s: \u03b8s \u223c K \u2016\u03b8\u2212e\u03b8i\u2016 h .\nWe thus have two streams of asymptotically-exact samples, which is exactly the setting of the product density sample combination procedures [48, 37, 42], which run on the output of MCMC algorithms to generate asymptotically-exact samples from the distribution with PDF proportional to the product of the PDFs of the Markov chains\u2019 stationary distributions (see [37], Sec. 5). We give pseudocode for these sample combination procedures in the \u201cSample Combination Algorithm Pseudocode\u201d section of the appendix. Therefore, as T \u2192 \u221e, line 4 of Alg. 1 yields samples from f\u0302 sps \u221d h f\u0302 pps i 1 T \u2211T t=1 f\u0302 p \u03c6|x( e\u03b8t)\u22121K \u2016\u03b8\u2212e\u03b8t\u2016 h ."}, {"heading": "Appendix B. Computational Complexity Summary", "text": "Here we summarize the complexity of our prior swapping algorithms. Assume that we have run an existing inference algorithm to compute either a fixed-complexity analytic expression for the false-posterior density, or to draw T false-posterior samples, given some dataset of n observations. Suppose that we wish to compute S samples from the true-posterior.\nGiven a fixed-complexity analytic expression for the false-posterior, each step (i.e. generating each sample) in an MCMC algorithm requires a constant O(1) number of operations, and drawing S samples via our procedure therefore requires O(S) operations.\nGiven T samples from the false-posterior, the asymptotically-exact (semiparametric) procedure in Alg. 1 must perform the fixed-complexity prior swapping procedure on a parametric false posterior f\u03c6|x (O(S) operations for S samples), draw S samples from the correction density (O(T) operations to compute component weights and O(S) operations to draw S samples, for a total complexity of O(S+ T )), then apply a density product sample combination algorithm [48, 37, 42] (O(S) operations for S samples). Therefore, the asymptotically-exact (semiparametric) procedure has a total complexity of O(S+ T ) to draw S samples.\nIn general, given the false-posterior inference result, none of the prior swapping algorithms depend on the number of data points n."}, {"heading": "Appendix C. Prior Swapping Pseudocode (for Fixed-Complexity f\u03c6|x)", "text": "Here we give pseudocode for the prior swapping procedure, given a fixed-complexity (parametric) false posterior expression f \u2217\n\u03c6|x , using the prior swap functions f \u2217 eps and \u2207\u03b8 log f \u2217 eps (Eqs. 3 and 4).\nIn Alg. 2, we show prior swapping via the Metropolis-Hastings algorithm, which makes use of f \u2217 eps. In Alg. 3 we show prior swapping via Hamiltonian Monte Carlo, which makes use of \u2207\u03b8 log f \u2217 eps. A special case of Alg. 3, which occurs when we set the number of simulation steps to L = 1 (in line 6), is prior swapping via Langevin dynamics.\nAlgorithm 2: Prior swapping via Metropolis-Hastings. Input: Prior swap function f \u2217\neps, and proposal q.\nOutput: Samples {\u03b8t}Tt=1 \u223c f \u2217 ps \u221d f\u03b8 |x as T \u2192\u221e.\n1 Initialize \u03b80. . Initialize Markov chain. 2 for t = 1, . . . , T do 3 Draw \u03b8s \u223c q(\u03b8s | \u03b8t\u22121). . Propose new sample. 4 Draw u\u223c Unif([0, 1]).\n5 if u<min 1, f \u2217 eps(\u03b8s)q(\u03b8t |\u03b8s)\nf \u2217 eps(\u03b8t )q(\u03b8s |\u03b8t )\nthen\n6 Set \u03b8t \u2190 \u03b8s. . Accept proposed sample. 7 else 8 Set \u03b8t \u2190 \u03b8t\u22121. . Reject proposed sample.\nAlgorithm 3: Prior swapping via Hamiltonian Monte Carlo. Input: Prior swap function f \u2217\neps, its gradient log \u2207\u03b8 log f \u2217 eps, and step-size \u03b5.\nOutput: Samples {\u03b8t}Tt=1 \u223c f \u2217 ps \u221d f\u03b8 |x as T \u2192\u221e.\n1 Initialize \u03b80. . Initialize Markov chain. 2 for t = 1, . . . , T do 3 Draw rt \u223cN (0, I). 4 Set (e\u03b80,er0)\u2190 (\u03b8t\u22121, rt\u22121) 5 Set er0\u2190 er0 + \u03b5 2 \u2207\u03b8 log f \u2217\neps(e\u03b80) . . Propose new sample (next 4 lines). 6 for l = 1, . . . , L do 7 Set e\u03b8l \u2190 e\u03b8l\u22121 + \u03b5erl\u22121. 8 Set erl \u2190 erl\u22121 + \u03b5\u2207\u03b8 log f \u2217 eps(e\u03b8l).\n9 Set erL \u2190 erL + \u03b5 2 \u2207\u03b8 log f \u2217 eps(e\u03b8L) . 10 Draw u\u223c Unif([0, 1]).\n11 if u<min 1, f \u2217 eps( e\u03b8L)er>L erL\nf \u2217 eps(\u03b8t\u22121)r > t\u22121 rt\u22121\nthen\n12 Set \u03b8t \u2190 b\u03b8L . . Accept proposed sample. 13 else 14 Set \u03b8t \u2190 \u03b8t\u22121. . Reject proposed sample."}, {"heading": "Appendix D. Sample Combination Algorithm Pseudocode", "text": "Here we give pseudocode for a product density sample combination algorithm [48, 37, 42]. We will write this algorithm for our setting (i.e. for generating samples from the product of two densities) though these algorithms are typically more general. We mainly follow Alg. 1 from [37].\nThe intuitive idea behind these algorithms is the following: given two sets of samples {\u03b8 1t } T t=1\n\u223c f1(\u03b8) and {\u03b8 2t } T t=1 \u223c f2(\u03b8), they aim to return Prod({\u03b8 1 t1 }Tt=1, {\u03b8 2 t2 }Tt=1) = {\u03b8t} T t=1 \u223c 1 Z f1 f2(\u03b8). At each iteration in this algorithm, four steps are carried out:\n1. Choose one of the two input sample sets (uniformly at random).\n2. Re-draw a sample from the chosen sample set.\n3. Accept this drawn sample, or reject it and keep the previously drawn sample.\n4. Save a noisy average of the two current samples (one from each sample set). We give the pseudocode for this procedure in Alg. 4.\nAlgorithm 4: Density product sample combination (Prod) algorithm [37].\nInput: {\u03b8 1t } T t=1 \u223c f1(\u03b8) and {\u03b8 2 t } T t=1 \u223c f2(\u03b8). Output: {\u03b8t}Tt=1 \u223c 1 Z f1 f2(\u03b8) as T \u2192\u221e.\n1 Draw (k1, k2) iid\u223c Unif({1, . . . , T}). . Initialize sample indices. 2 Set h\u2190 T\u22121/(4+d). 3 for s = 1, . . . , T do 4 Set (c1, c2)\u2190 (k1, k2). 5 Draw m\u223c Unif({1,2}). . Choose an input sample set. 6 Draw cm \u223c Unif({1, . . . , T}). . Draw sample index from chosen set. 7 Draw u\u223c Unif([0, 1]). 8 if u< N (\u03b81c1 |\u03b8 2 c2 ,h2 I)\nN (\u03b81k1 |\u03b8 2 k2\n,h2 I) then\n9 Set (k1, k2)\u2190 (c1, c2). . Accept chosen sample.\n10 Draw \u03b5\u223cN 0, h 2\n2 I .\n11 Set \u03b8s \u2190 1 2 \u03b8 1k1 + \u03b8 2k2 + \u03b5. . Compute an output sample."}, {"heading": "Appendix E. Incorporating observed prior information", "text": "The asymptotically-exact method for prior swapping allows for a related way to more easily incorporate observed prior information. Often, instead of (or in addition to) an analytic expression for our prior beliefs, we have prior observations, such as previously observed outcomes of what we aim to infer. Incorporating information such as this can lead to better data-driven priors. Here, we will extend our asymptotically-exact prior swapping procedure to this setting.\nSuppose that we only have access to samples {e\u03b8 1t } T t=1 from the true-prior f\u03b8 , in addition to falseposterior samples {e\u03b8 2t } T t=1 from f\u03c6|x . In this case, we can apply a density product sample combination algorithm [48, 37, 42] (described in the \u201cSample Combination Algorithm Pseudocode\u201d section of the appendix) to generate samples {e\u03b8t}Tt=1 from fpsnum \u221d f\u03c6|x f\u03b8 , and then construct a semiparametric estimate [18] of this density (the same one used in defining the asympotically-exact prior swapping method), written\nf\u0302 spsnum(\u03b8) = 1\nT\nT \u2211\nt=1\n1 hd K \u2016\u03b8\u2212e\u03b8t\u2016 h f\u0302 ppsnum(\u03b8)\nf\u0302 ppsnum(e\u03b8t) . (7)\nWe then define the prior swap function for observed prior samples, f\u0302 o eps, to be\nf\u0302 o eps(\u03b8) =\nf\u0302 spsnum(\u03b8)\nf\u03c6(\u03b8) =\n1\nT\nT \u2211\nt=1\n1 hd K \u2016\u03b8\u2212e\u03b8t\u2016 h f\u0302 ppsnum(\u03b8)\nf\u0302 ppsnum(e\u03b8t) f\u03c6(\u03b8) (8)\n=\n\n\nf\u0302 ppsnum(\u03b8)\nf\u03c6(\u03b8)\n\n\n\n\n1\nT\nT \u2211\nt=1\nw\u2032t K \u2016\u03b8 \u2212 e\u03b8t\u2016 h\n!\n , (9)\nwhere we\u2019ve defined w\u2032t = f\u0302 ppsnum( e\u03b8t)hd\n\u22121 . As in the asymptotically-exact prior swapping procedure,\nf\u0302 o eps is proportional to the product of two densities, both of which we can easily sample from (note that we can sample from f\u0302 ppsnum/ f\u03c6 using the fixed-complexity parametric prior swapping method). As before, we then apply the density product sample combination methods to generate samples from f\u0302 ops. We summarize this full procedure in Alg 5.\nAlgorithm 5: Asymptotically-exact prior swapping (observed prior samples)\nInput: Samples {e\u03b8 1t } T t=1 \u223c f\u03b8 (\u03b8) and {e\u03b8 2 t } T t=1 \u223c f\u03c6|x(\u03b8 |x n). Output: Samples {\u03b8t}Tt=1 \u223c f\u0302 o ps(\u03b8)\u2192 f\u03b8 |x(\u03b8 |x N ) as T \u2192\u221e.\n1 Sample {e\u03b8t}Tt=1 \u223c fpsnum(\u03b8) via Prod {e\u03b8 1t } T t=1, {e\u03b8 2 t } T t=1 . 2 Estimate f\u0302 ppsnum using { e\u03b8t}Tt=1 . parametric estimate. 3 Sample {\u03b8 1t } T t=1 \u223c f\u0302 p psnum (\u03b8) . parametric prior swapping. 4 Sample {\u03b8 2t } T t=1 \u223c 1 T \u2211T t=1 w \u2032 t K \u2016\u03b8\u2212e\u03b8t\u2016 h . 5 Sample {\u03b8t}Tt=1 \u223c f\u0302 o ps(\u03b8) via Prod {\u03b8 1t } T t=1, {\u03b8 2 t } T t=1 ."}], "references": [{"title": "Bayesian analysis of binary and polychotomous response data", "author": ["James H Albert", "Siddhartha Chib"], "venue": "Journal of the American statistical Association,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "An introduction to mcmc for machine learning", "author": ["Christophe Andrieu", "Nando De Freitas", "Arnaud Doucet", "Michael I Jordan"], "venue": "Machine learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L\u00e9on Bottou"], "venue": "In Proceedings of COMP- STAT\u20192010,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Stan: a probabilistic programming language", "author": ["Bob Carpenter", "Andrew Gelman", "Matt Hoffman", "Daniel Lee", "Ben Goodrich", "Michael Betancourt", "Marcus A Brubaker", "Jiqiang Guo", "Peter Li", "Allen Riddell"], "venue": "Journal of Statistical Software,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Handling sparsity via the horseshoe", "author": ["Carlos M Carvalho", "Nicholas G Polson", "James G Scott"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Stochastic gradient hamiltonian monte carlo", "author": ["Tianqi Chen", "Emily B Fox", "Carlos Guestrin"], "venue": "arXiv preprint arXiv:1402.4102,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Understanding the metropolis-hastings algorithm", "author": ["Siddhartha Chib", "Edward Greenberg"], "venue": "The american statistician,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "Conjugate priors for exponential families", "author": ["Persi Diaconis", "Donald Ylvisaker"], "venue": "The Annals of statistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1979}, {"title": "Estimation of finite mixture distributions through bayesian sampling", "author": ["Jean Diebolt", "Christian P Robert"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1994}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["Nan Ding", "Youhan Fang", "Ryan Babbush", "Changyou Chen", "Robert D Skeel", "Hartmut Neven"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "On sequential monte carlo sampling methods for bayesian filtering", "author": ["Arnaud Doucet", "Simon Godsill", "Christophe Andrieu"], "venue": "Statistics and computing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Variational bayesian inference for linear and logistic regression", "author": ["Jan Drugowitsch"], "venue": "arXiv preprint arXiv:1310.5438,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "A compendium of conjugate priors", "author": ["Daniel Fink"], "venue": "See http://www.people.cornell.edu/pages/ df36/CONJINTRnewTEX.pdf,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Objections to bayesian statistics", "author": ["Andrew Gelman"], "venue": "Bayesian Analysis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Bayesian inference for generalized linear models for spiking neurons", "author": ["Sebastian Gerwinn", "Jakob H Macke", "Matthias Bethge"], "venue": "Frontiers in Computational Neuroscience,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Keeping neural networks simple", "author": ["Geoffrey E Hinton", "Drew van Camp"], "venue": "In ICANN\u201993,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Nonparametric density estimation with a parametric start", "author": ["Nils Lid Hjort", "Ingrid K Glad"], "venue": "The Annals of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo", "author": ["Matthew D Hoffman", "Andrew Gelman"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Efficient simulation of bayesian logistic regression models", "author": ["C Holmes", "Leonhard Knorr-Held"], "venue": "Technical report, Discussion papers/Sonderforschungsbereich 386 der Ludwig-Maximilians-Universita\u0308t Mu\u0308nchen,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Review papers: recent developments in nonparametric density estimation", "author": ["Alan Julian Izenman"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1991}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Nonparametric bayesian sparse factor models with application to gene expression modeling", "author": ["David Knowles", "Zoubin Ghahramani"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Priors for diversity in generative latent variable models", "author": ["James T Kwok", "Ryan P Adams"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "The mnist database of handwritten digits", "author": ["Yann LeCun", "Corinna Cortes", "Christopher JC Burges"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash Mansinghka", "Daniel Selsam", "Yura Perov"], "venue": "arXiv preprint arXiv:1404.0099,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Bayesian modelling and inference on mixtures of distributions", "author": ["Jean-Michel Marin", "Kerrie Mengersen", "Christian P Robert"], "venue": "Handbook of statistics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Sparse latent factor models with interactions: Analysis of gene expression data", "author": ["Vinicius Diniz Mayrink", "Joseph Edward Lucas"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Equation of state calculations by fast computing machines", "author": ["Nicholas Metropolis", "Arianna W Rosenbluth", "Marshall N Rosenbluth", "Augusta H Teller", "Edward Teller"], "venue": "The journal of chemical physics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1953}, {"title": "Bayesian linear regression", "author": ["Thomas Minka"], "venue": "Technical report, Citeseer,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2000}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["Thomas P Minka"], "venue": "In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "Bayesian and l1 approaches to sparse unsupervised learning", "author": ["Shakir Mohamed", "Katherine Heller", "Zoubin Ghahramani"], "venue": "arXiv preprint arXiv:1106.1157,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "A simple weight decay can improve generalization", "author": ["J Moody", "S Hanson", "Anders Krogh", "John A Hertz"], "venue": "Advances in neural information processing systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1995}, {"title": "MCMC using hamiltonian dynamics", "author": ["R Neal"], "venue": "Handbook of Markov Chain Monte Carlo,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Annealed importance sampling", "author": ["Radford M Neal"], "venue": "Statistics and Computing,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Modeling citation networks using latent random offsets", "author": ["Willie Neiswanger", "Chong Wang", "Qirong Ho", "Eric P Xing"], "venue": "In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Asymptotically exact, embarrassingly parallel mcmc", "author": ["Willie Neiswanger", "Chong Wang", "Eric Xing"], "venue": "In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "The dependent dirichlet process mixture of objects for detection-free tracking and object modeling", "author": ["Willie Neiswanger", "Frank Wood", "Eric P Xing"], "venue": "In The Seventeenth International Conference on Artificial Intelligence and Statistics (AISTATS", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images", "author": ["Bruno A Olshausen"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1996}, {"title": "A compilation target for probabilistic programming languages", "author": ["Brooks Paige", "Frank Wood"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1935}, {"title": "Asynchronous anytime sequential monte carlo", "author": ["Brooks Paige", "Frank Wood", "Arnaud Doucet", "Yee Whye Teh"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Variational consensus monte carlo", "author": ["Maxim Rabinovich", "Elaine Angelino", "Michael I Jordan"], "venue": "arXiv preprint arXiv:1506.03074,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Identifiability of parameters in mcmc bayesian inference of phylogeny", "author": ["Bruce Rannala"], "venue": "Systematic Biology,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2002}, {"title": "On variance reduction in stochastic gradient descent and its asynchronous variants", "author": ["Sashank J Reddi", "Ahmed Hefny", "Suvrit Sra", "Barnab\u00e1s P\u00f3czos", "Alex J Smola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Simple conditions for the convergence of the gibbs sampler and metropolis-hastings algorithms", "author": ["Gareth O Roberts", "Adrian FM Smith"], "venue": "Stochastic processes and their applications,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1994}, {"title": "Brownian dynamics as smart monte carlo simulation", "author": ["PJ Rossky", "JD Doll", "HL Friedman"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1978}, {"title": "Deep learning in neural networks: An overview", "author": ["J\u00fcrgen Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Bayes and big data: The consensus monte carlo algorithm", "author": ["Steven L. Scott", "Alexander W. Blocker", "Fernando V. Bonassi"], "venue": "In Bayes 250,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2013}, {"title": "Bayesian inference and optimal design for the sparse linear model", "author": ["Matthias W Seeger"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2008}, {"title": "Bayesian computation via the gibbs sampler and related markov chain monte carlo methods", "author": ["Adrian FM Smith", "Gareth O Roberts"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1993}, {"title": "Bayesian inference of gaussian mixture models with noninformative priors", "author": ["Colin J Stoneking"], "venue": "arXiv preprint arXiv:1405.4895,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2014}, {"title": "A collapsed variational bayesian inference algorithm for latent dirichlet allocation", "author": ["Yee W Teh", "David Newman", "Max Welling"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2006}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1996}, {"title": "Importance sampling: a review", "author": ["Surya T Tokdar", "Robert E Kass"], "venue": "Wiley Interdisciplinary Reviews: Computational Statistics,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2010}, {"title": "Collaborative topic modeling for recommending scientific articles", "author": ["Chong Wang", "David M Blei"], "venue": "In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2011}, {"title": "Variational inference in nonconjugate models", "author": ["Chong Wang", "David M Blei"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2013}, {"title": "Variance reduction for stochastic gradient optimization", "author": ["Chong Wang", "Xi Chen", "Alex Smola", "Eric Xing"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2013}, {"title": "All of nonparametric statistics", "author": ["Larry Wasserman"], "venue": "Springer Science & Business Media,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2006}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["Max Welling", "Yee W Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2011}, {"title": "A non-parametric bayesian method for inferring hidden causes", "author": ["Frank Wood", "Thomas Griffiths", "Zoubin Ghahramani"], "venue": "arXiv preprint arXiv:1206.6865,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2012}, {"title": "A new approach to probabilistic programming inference", "author": ["Frank Wood", "Jan Willem van de Meent", "Vikash Mansinghka"], "venue": "In Proceedings of the 17th International conference on Artificial Intelligence and Statistics,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2014}, {"title": "Latent variable modeling with diversity-inducing mutual angular regularization", "author": ["Pengtao Xie", "Yuntian Deng", "Eric Xing"], "venue": "arXiv preprint arXiv:1512.07336,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2015}, {"title": "Diversity-promoting bayesian learning of latent variable models", "author": ["Pengtao Xie", "Jun Zhu", "Eric Xing"], "venue": "In Proceedings of the 33st International Conference on Machine Learning", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2016}, {"title": "Bayesian learning in sparse graphical factor models via variational mean-field annealing", "author": ["Ryo Yoshida", "Mike West"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2010}], "referenceMentions": [{"referenceID": 8, "context": "For example, \u2022 Conjugate priors yield posteriors with a known parametric form and therefore allow for noniterative, exact inference [9, 14].", "startOffset": 132, "endOffset": 139}, {"referenceID": 13, "context": "For example, \u2022 Conjugate priors yield posteriors with a known parametric form and therefore allow for noniterative, exact inference [9, 14].", "startOffset": 132, "endOffset": 139}, {"referenceID": 49, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 15, "endOffset": 27}, {"referenceID": 9, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 15, "endOffset": 27}, {"referenceID": 59, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 51, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 37, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 55, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 106, "endOffset": 114}, {"referenceID": 51, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 106, "endOffset": 114}, {"referenceID": 1, "context": "the normal distribution) allow for computationally cheap density queries, maximization, and sampling [2], which can allow for easier use in iterative inference algorithms (e.", "startOffset": 101, "endOffset": 104}, {"referenceID": 28, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 7, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 33, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 49, "endOffset": 53}, {"referenceID": 11, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 81, "endOffset": 89}, {"referenceID": 40, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 81, "endOffset": 89}, {"referenceID": 42, "context": "\u2022 Certain priors mitigate issues of identifiability, and allow for simpler posteriors without multiple modes [43].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "This can encourage the use of convenient priors in practice, rather than priors that might yield a more realistic or accurate inference, which is a criticism of Bayesian methods [15].", "startOffset": 178, "endOffset": 182}, {"referenceID": 28, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 93, "endOffset": 100}, {"referenceID": 7, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 93, "endOffset": 100}, {"referenceID": 45, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 188, "endOffset": 192}, {"referenceID": 33, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 224, "endOffset": 232}, {"referenceID": 18, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 224, "endOffset": 232}, {"referenceID": 58, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 264, "endOffset": 271}, {"referenceID": 6, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 264, "endOffset": 271}, {"referenceID": 57, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 94, "endOffset": 102}, {"referenceID": 20, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 94, "endOffset": 102}, {"referenceID": 17, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 121, "endOffset": 125}, {"referenceID": 17, "context": "To motivate this method, we choose a a consistent semiparametric false posterior estimate f\u0302 s \u03c6|x (see [18] for background and consistency guarantees), which can be viewed as the product of a parametric density estimate f\u0302 p \u03c6|x and a nonparametric correction function.", "startOffset": 104, "endOffset": 108}, {"referenceID": 57, "context": "\uf8fb , (5) where we use K to denote a probability density kernel, with bandwidth h, where h\u2192 0 as T \u2192\u221e (see [58] for details on probability density kernels and bandwidth selection).", "startOffset": 105, "endOffset": 109}, {"referenceID": 47, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 36, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 41, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 1, "context": "This setting also has some relation to importance sampling (IS) [2].", "startOffset": 64, "endOffset": 67}, {"referenceID": 34, "context": "However, in practice, performance would only be adequate for false posteriors that are very similar to the true posterior (and not for arbitrary f\u03c6|x), especially in high dimensions [35, 54].", "startOffset": 182, "endOffset": 190}, {"referenceID": 53, "context": "However, in practice, performance would only be adequate for false posteriors that are very similar to the true posterior (and not for arbitrary f\u03c6|x), especially in high dimensions [35, 54].", "startOffset": 182, "endOffset": 190}, {"referenceID": 7, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 44, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 36, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 52, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 76, "endOffset": 84}, {"referenceID": 38, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 76, "endOffset": 84}, {"referenceID": 52, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 48, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 31, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 5, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 30, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 24, "endOffset": 28}, {"referenceID": 48, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 80, "endOffset": 88}, {"referenceID": 15, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 80, "endOffset": 88}, {"referenceID": 48, "context": "Our first set of experiments are on sparse Bayesian linear regression models [49, 30], which we can write as yi = X i\u03b8+\u03b5, \u03b5\u223cN (0,\u03c32), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 77, "endOffset": 85}, {"referenceID": 29, "context": "Our first set of experiments are on sparse Bayesian linear regression models [49, 30], which we can write as yi = X i\u03b8+\u03b5, \u03b5\u223cN (0,\u03c32), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 77, "endOffset": 85}, {"referenceID": 48, "context": "4/\u03c3} [49]) priors.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "Our second set of experiments are on a hierarchical Bayesian logistic regression model [20, 13], which we write as yi \u223c Bern(pi), pi = logistic(X i\u03b8 ), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 87, "endOffset": 95}, {"referenceID": 12, "context": "Our second set of experiments are on a hierarchical Bayesian logistic regression model [20, 13], which we write as yi \u223c Bern(pi), pi = logistic(X i\u03b8 ), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 87, "endOffset": 95}, {"referenceID": 19, "context": "Here, we also use a normal f\u03c6 (see [20, 1] for examples of convenient inference in Bayesian logistic regression under normal priors).", "startOffset": 35, "endOffset": 42}, {"referenceID": 0, "context": "Here, we also use a normal f\u03c6 (see [20, 1] for examples of convenient inference in Bayesian logistic regression under normal priors).", "startOffset": 35, "endOffset": 42}, {"referenceID": 12, "context": "For comparison methods, we use MH for MCMC, and a mean field approximation [13] for VI.", "startOffset": 75, "endOffset": 79}, {"referenceID": 62, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 23, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 61, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 27, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 22, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 63, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 62, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 22, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 63, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 26, "context": "We first show results on a Gaussian mixture model (GMM) [27, 51], written x i \u223cN (\u03bczi ,\u03a3zi ), zi \u223c Dir(\u03b1), {\u03bcm} m=1 \u223c f\u03b8 , i = 1,.", "startOffset": 56, "endOffset": 64}, {"referenceID": 50, "context": "We first show results on a Gaussian mixture model (GMM) [27, 51], written x i \u223cN (\u03bczi ,\u03a3zi ), zi \u223c Dir(\u03b1), {\u03bcm} m=1 \u223c f\u03b8 , i = 1,.", "startOffset": 56, "endOffset": 64}, {"referenceID": 2, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 73, "endOffset": 76}, {"referenceID": 2, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 125, "endOffset": 132}, {"referenceID": 54, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 125, "endOffset": 132}, {"referenceID": 35, "context": "For mixture models, we generate synthetic data from the above model (n=10,000, d=2, M=9), and for topic models, we use the Simple English Wikipedia\u2217 corpus (n=27,443 documents, vocab=10,192 words) [36], and set M=400 topics.", "startOffset": 197, "endOffset": 201}, {"referenceID": 46, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 32, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 16, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 3, "context": "We will compare this to finding the optimal weight decay via stochastic gradient descent [4] and stochastic gradient Langevin dynamics [59], two popular methods for learning and inference in neural networks.", "startOffset": 89, "endOffset": 92}, {"referenceID": 58, "context": "We will compare this to finding the optimal weight decay via stochastic gradient descent [4] and stochastic gradient Langevin dynamics [59], two popular methods for learning and inference in neural networks.", "startOffset": 135, "endOffset": 139}, {"referenceID": 21, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 56, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 43, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 10, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 24, "context": "For data, we use the MNIST\u2020 handwritten digits classification dataset (n=60,000, d=784) [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 4, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 60, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 39, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 25, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}], "year": 2017, "abstractText": "While Bayesian methods are praised for their ability to incorporate useful prior knowledge, in practice, priors that allow for computationally convenient or tractable inference are more commonly used. In this paper, we investigate the following question: for a given model, is it possible to use any convenient prior to infer a false posterior, and afterwards, given some true prior of interest, quickly transform this result into the true posterior? We present a procedure to carry out this task: given an inferred false posterior and true prior, our algorithm generates samples from the true posterior. This transformation procedure, which we call \u201cprior swapping\u201d works for arbitrary priors. Notably, its cost is independent of data size. It therefore allows us, in some cases, to apply significantly less-costly inference procedures to more-sophisticated models than previously possible. It also lets us quickly perform any additional inferences, such as with updated priors or for many different hyperparameter settings, without touching the data. We prove that our method can generate asymptotically exact samples, and demonstrate it empirically on a number of models and priors.", "creator": "LaTeX with hyperref package"}}}