{"id": "1606.03832", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2016", "title": "Evidential Label Propagation Algorithm for Graphs", "abstract": "community detection has attracted considerable attention crossing many areas as it can hopefully be used for discovering the structure and features of complex networks. with the increasing size of social networks in real world, community detection approaches should be both fast and accurate. the label propagation algorithm ( lpa ) is known essentially to be one of the near - linear solutions and benefits of easy implementation, thus it forms a good basis for efficient community detection methods. in this paper, we extend the update rule and propagation criterion of lpa in the framework of belief functions. a new community detection approach, called evidential label propagation ( elp ), is proposed as an enhanced improved version of conventional lpa. the largest node influence is first defined to guide the sample propagation process. the plausibility is used to determine the domain label of each node. the update order of nodes is discussed to improve the algorithms robustness of the method. elp hash algorithm will converge after the domain labels of all the nodes become unchanged. the mass assignments are calculated finally as memberships of nodes. lastly the overlapping nodes and outliers can be detected simultaneously through the proposed method. the experimental results below demonstrate the effectiveness of elp.", "histories": [["v1", "Mon, 13 Jun 2016 06:58:34 GMT  (201kb,D)", "http://arxiv.org/abs/1606.03832v1", "19th International Conference on Information Fusion, Jul 2016, Heidelber, France"]], "COMMENTS": "19th International Conference on Information Fusion, Jul 2016, Heidelber, France", "reviews": [], "SUBJECTS": "cs.AI cs.SI", "authors": ["kuang zhou", "arnaud martin", "quan pan", "zhun-ga liu"], "accepted": false, "id": "1606.03832"}, "pdf": {"name": "1606.03832.pdf", "metadata": {"source": "CRF", "title": "Evidential Label Propagation Algorithm for Graphs", "authors": ["Kuang Zhoua", "Arnaud Martinb", "Quan Pana", "Zhun-ga Liua"], "emails": [], "sections": [{"heading": null, "text": "Index Terms\u2014Label propagation, theory of belief functions, outliers, community detection.\nI. INTRODUCTION\nWith the development of computer and Internet technologies, networks are everywhere in our common life. Graph models are useful in describing and analyzing many different kinds of relationships and interdependencies. In order to have a better understanding of organizations and functions in realworld networked systems, community structure of graphs is a primary feature that should be taken into consideration. Communities, also called clusters or modules, are groups of nodes (vertices) which probably share common properties and/or play similar roles within the graph. They can extract specific structures from complex networks, and consequently community detection has attracted considerable attention crossing many areas from physics, biology, and economics to sociology, where systems are often represented as graphs.\nRecently, significant progress has been achieved in this research field and several popular algorithms for community detection have been devised. One of the most popular type of classical methods partitions networks by optimizing some criteria such as the modularity measure (usually denoted by Q) [1]. But recent researches have found that the modularity based algorithms could not detect communities smaller than a certain size. This problem is famously known as the resolution limit [2]. Another family of approaches considers hierarchical clustering techniques. It merges or splits clusters according to a topological measure of similarity between the nodes and tries\nto build a hierarchical tree of partitions [3]. Some other popular community detection approaches using spectral clustering [4] or partitional clustering methods [5] can be found.\nAs the size of analyzed networks grows rapidly, the complexity of community detection algorithms needs to be kept close to linear. The Label Propagation Algorithm (LPA), which was first investigated in [6], has the benefits of nearly-linear running time and easy implementation, thus it forms a good basis for efficient community detection methods. It only uses the network structure and requires neither optimization of a predefined objective function nor prior information about the communities. In this model every node is initialized with a unique label. Afterwards each node adopts the label that most of its neighbors currently have at every step. In this iterative process densely connected groups of nodes form a consensus on a unique label to form communities.\nThe behavior of LPA is not stable because of the randomness. Different communities may be detected in different runs over the same network. Moreover, by assuming that a node always adopts the label of the majority of its neighbors, LPA ignores any other structural information existing in the neighborhood of this node. Another drawback for LPA is that it can only handle disjoint and non-overlapping communities. However, in real cases, one member in a network might span multiple communities. For instance, one may naturally belong to several social groups like friends, families, and schoolmates.\nAlthough most of the nodes in a graph follow a common community distribution pattern, some certain objects may deviate significantly from the pattern. It is of great value to detect such outliers in networks for de-noising data thereby improving the quality of the detected community structure and also for further analysis. Finding community outliers is an important problem but has not received enough attention in the field of social network analysis.\nThe theory of belief functions, also called Dempster\u2013Shafer Theory (DST), offers a mathematical framework for modeling uncertainty and imprecise information [7]. It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17]. Belief functions are defined on the power set of the frame which greatly enriches the expression power. The compound sets of the frame can be used to describe the uncertain information and our ignorance.\nIn this paper, we enhance the original LPA by introducing new update and propagation strategies. A novel Evidential Label Propagation (ELP) algorithm is presented to detect\nar X\niv :1\n60 6.\n03 83\n2v 1\n[ cs\n.A I]\n1 3\nJu n\n20 16\ncommunities. The main contribution of this work can be summarized as: \u2022 The influence of each node to a target is defined consid-\nering both the similarities and local densities. The larger the influence of one node to the target node is, the easier its label can be propagated to the target. \u2022 Based on the node influence, a new label propagation algorithm, named ELP, is proposed for graphs. The method for determining the update order of nodes is devised to improve the robustness of ELP. \u2022 The Basic Belief Assignments (bbas) of nodes are defined for each detected communities in the framework of belief functions. The overlapping nodes and outliers can be detected simultaneously through the obtained bbas.\nThe remainder of this paper is organized as follows. In Section II, some basic knowledge is briefly introduced. The ELP algorithm is presented in detail in Section III. In order to show the effectiveness of the proposed community detection approach, in Section IV we test the ELP algorithm on different graph data sets and make comparisons with related methods. Conclusions are drawn in the final section."}, {"heading": "II. BACKGROUND", "text": "In this section some related preliminary knowledge will be presented. Some basis of belief function theory will be recalled first, then two existing algorithms related to the proposed method will be briefly described."}, {"heading": "A. Theory of belief functions", "text": "Let \u2126 = {\u03c91, \u03c92, . . . , \u03c9c} be the finite domain of X , called the discernment frame. The belief functions are defined on the power set 2\u2126 = {A : A \u2286 \u2126}.\nThe function m : 2\u2126 \u2192 [0, 1] is said to be the Basic Belief Assignment (bba) on 2\u2126, if it satisfies:\u2211\nA\u2286\u2126\nm(A) = 1. (1)\nEvery A \u2208 2\u2126 such that m(A) > 0 is called a focal element. The credibility and plausibility functions are defined in Eqs. (2) and (3) respectively:\nBel(A) = \u2211\nB\u2286A,B 6=\u2205\nm(B) \u2200A \u2286 \u2126, (2)\nPl(A) = \u2211\nB\u2229A6=\u2205\nm(B), \u2200A \u2286 \u2126. (3)\nEach quantity Bel(A) measures the total support given to A, while Pl(A) represents potential amount of support to A. The two functions are linked by the following relation:\nPl(A) = 1\u2212Bel(A), \u2200A \u2286 \u2126, (4)\nwhere A denotes the complementary set of A in \u2126. The function pl : \u2126\u2192 [0, 1] that maps each element \u03c9i in \u2126 to its plausibility pl(\u03c9i) = Pl({\u03c9i}) is called the contour function associated to m.\nA belief function on the credal level can be transformed into a probability function by Smets method [18], where the mass m(A) is equally distributed among the elements of A. This leads to the concept of pignistic probability, BetP , defined by\nBetP (\u03c9i) = \u2211\n\u03c9i\u2208A\u2286\u2126\nm(A)\n|A|(1\u2212m(\u2205)) , (5)\nwhere |A| is the number of elements of \u2126 in A. How to combine efficiently several bbas coming from distinct sources is a major information fusion problem in the belief function framework. Many rules have been proposed for such a task. When the information sources are reliable, several distinct bodies of evidence characterized by different bbas can be combined using Dempster-Shafer (DS) rule [7]. If bbas mj , j = 1, 2, \u00b7 \u00b7 \u00b7 , S describing S distinct items of evidence on \u2126, the DS rule of combination of S bbas can be mathematically defined as\n(m1 \u2295m2 \u2295 \u00b7 \u00b7 \u00b7 \u2295mS)(X) = 0 if X = \u2205,\u2211 Y1\u2229\u00b7\u00b7\u00b7\u2229YS=X \u220fS j=1mj(Yj) 1\u2212 \u2211\nY1\u2229\u00b7\u00b7\u00b7\u2229YS=X\n\u220fS j=1mj(Yj) otherwise. (6)\nB. EK-NNclus clustering\nRecently, a new decision-directed clustering algorithm for relational data sets is put forward based on the evidential K nearest-neighbor (EK-NN) rule [19]. Starting from an initial partition, the algorithm, called EK-NNclus, iteratively reassigns objects to clusters using the EK-NN rule [8], until a stable partition is obtained. After convergence, the cluster membership of each object is described by a Dempster-Shafer mass function assigning a mass to each specific cluster and to the whole set of clusters."}, {"heading": "C. Label propagation", "text": "Let G(V,E) be an undirected network, V is the set of N nodes, E is the set of edges. Each node v(v \u2208 V ) has a label cv . Denote by Nv the set of neighbors of node v. The Label Propagation Algorithm (LPA) uses the network structure alone to guide its process. It starts from an initial configuration where every node has a unique label. Then at every step one node (in asynchronous version) or each node (in a synchronous version) updates its current label to the label shared by the maximum number of its neighbors. For node v, its new label can be updated to \u03c9j with\nj = arg max l {|u : cu = l, u \u2208 Nv|}, (7)\nwhere |X| is the cardinality of set X , and Nv is the set of node v\u2019s neighbors. When there are multiple maximal labels among the neighbors labels, the new label is picked randomly from them. By this iterative process densely connected groups of nodes form consensus on one label to form communities, and each node has more neighbors in its own community than in any of other community. Communities are identified as a group of nodes sharing the same label."}, {"heading": "III. APPROACH", "text": "Inspired from LPA and EK-NNclus, we propose here the ELP algorithm for community detection. After an introduction of the concept of node influence, the whole ELP algorithm will be presented in detail. Consider the network G(V,E). Let the degree of node i be di, and A = (aij)N\u00d7N denote the adjacency matrix, where aij = 1 indicates that there is a direct edge between nodes i and j."}, {"heading": "A. The influence of nodes", "text": "Definition 1. The local density of node i in graph G can be defined as\n\u03c1i = di\nN \u2212 1 , i = 1, 2, \u00b7 \u00b7 \u00b7 , N, (8)\nwhere N = |V | is the number of nodes in the graph. The value of \u03c1i describes the importance of node i to some extent. The nodes that are playing central roles in the network have relatively large local densities. Definition 2. Denote the influence of the node v to its neighbor node u by \u03b4uv .\n\u03b4uv = sim(u, v) ( \u03c1v \u03c1u )\u03b7 , (9)\nwhere sim(u, v) denotes the similarity between nodes u and v. Parameter \u03b7 is adjustable and it can be set to 1 by default. Many similarity measures can be adopted here. In this paper, the simple Jaccard Index is adopted:\nsim(u, v) = |Nu \u2229Nv| |Nu \u222aNv| , (10)\nwhere Nx = {w \u2208 V \\ x : a(w, x) = 1} denotes the set of vertices that are adjacent to node x.\nIt should be noticed that the value of \u03b4uv is not equal to \u03b4vu. In fact, we want to model the label propagation process according to \u03b4uv . The larger the influence of node v to node u is, the larger possibility that node u will adopt the label of node v. It is similar to the information propagation on social networks, where we are more likely to believe an authority who is usually a center or an important member in the community."}, {"heading": "B. Evidential label propagation", "text": "In the original LPA, when updating the label of node i, the number of neighbors belonging to each class is counted, and the label with maximal frequency is adopted. In this case, the importance of each node in the neighborhood is considered equal in the updating process. In our view, the propagation of labels is similar to information spreading. The more similar the two nodes are, the larger possibility that they share the same opinion (label). In addition, the information is much easier to be propagated from experts to common people, and not vice versa. That is to say, the label of an important node which may play a central role in the network should be more likely to be retained in the updating process. Here we assume that community centers are surrounded by neighbors with lower local densities and they have a relatively low similarity with\ncenters of other communities. Then the node influence can be used to guide the propagation.\nIf the influence of node j to i, \u03b4ij , is large, the mass given to the position that \u201cnode i adopts the labels of node j\u201d should be large. Suppose the set of neighbors of node i is Ni, we then compute\n\u03b1ij = { \u03d5(\u03b4ij) if j \u2208 Ni, 0 otherwise,\n(11)\nwhere \u03d5 is a non-decreasing mapping from [0, 1] to [0, 1]. We suggest to choose \u03d5 as\n\u03d5(\u03b4ij) = \u03b10 exp\n( \u2212 \u03b3 1\u2212 \u03b4ij\n\u03b4ij\n) , (12)\nwhere \u03b10 and \u03b3 are constants. Parameter \u03b10 is a weight factor, and it can be set 1 by default. Coefficient \u03b3 can be fixed as follows [19]:\n\u03b3 = 1/median ({( 1\u2212 \u03b4ij \u03b4ij )2 , i = 1, 2, \u00b7 \u00b7 \u00b7 , n, j \u2208 Ni }) . (13) If node j is a member of community \u03c9j , then node j\u2019s influence to node i is a piece of evidence that can be represented by the following mass function on \u2126:\nmj({\u03c9j}) = \u03b1ij , mj(\u2126) = 1\u2212 \u03b1ij . (14)\nLet the number of elements in Ni be qi, and assume the influence from the qi nodes in the graph as independent pieces of evidence, the qi mass function mj can be then combined using the DS rule:\nm = m1 \u2295m2 \u2295 \u00b7 \u00b7 \u00b7 \u2295mqi . (15)\nThe fused mass m is a credal membership of node i. The difference between this kind of membership and fuzzy membership is that there is a mass assigned to the ignorant set \u2126 in bba m. It is used to describe the probability that the node is an outlier of the graph. The domain label of node i can be defined as\nDli = arg max \u03c9j {m({\u03c9j}), \u03c9j \u2208 \u2126}. (16)\nSince the focal elements of the bbas here are the singletons and set \u2126, Eq. (16) is equal to\nDli = arg max \u03c9j {pl(\u03c9j), \u03c9j \u2208 \u2126}, (17)\nwhere pl is the contour function associative with m. As explained in [19], to obtain the domain label of each node, it is not necessary to compute the combined mass function m explicitly. For each node i, we first compute the logarithms of the plausibilities that node i belongs to cluster \u03c9k \u2208 \u2126 (up to an additive constant) as\nuik = \u2211 j\u2208Ni vijsjk, i = 1, 2, \u00b7 \u00b7 \u00b7 , N, j = 1, 2, \u00b7 \u00b7 \u00b7 , c (18)\nwhere vij = \u2212 log(1\u2212 \u03b1ij), (19)\nand sik is a logical variable indicating whether the domain label of node i is \u03c9k. Especially, if a node has more than one dominant label, we randomly choose a label from them as its dominant label. The domain label of node i can be set to \u03c9k\u2217 with\nk\u2217 = arg max y {uiy}. (20)\nThen the variables sik can be updated as\nsik = { 1 if k = k\u2217, 0 otherwise.\n(21)\nThe labels of each node are updated iteratively in ELP until the maximum iteration number is reached or all labels are stable. Finally, the overlapping and non-overlapping communities are returned. The ELP algorithm can be summarized in Algorithm 1.\nAlgorithm 1 : ELP algorithm Input: Graph G(V,E). Parameters: \u03b7: the parameter to adjust the node influence in Eq. (9) T : the maximum number of iteration steps \u03b10, \u03b3: the parameters in Eq. (12) to define mass functions Initialization: (1). Calculate the influence of node j to node i, \u03b4ij . (2). Initialize a unique label of each node in the network. The matrix S = {sij} is initially set to be an identity matrix.\nrepeat (1). Arrange the nodes in the network in a random order and save them in set \u03c3 orderly. (2). Update the label of node i one by one according to the order in \u03c3. One can then assign node i to the community \u03c9k with the highest plausibility and update the matrix S using Eqs. (20) and (21). until the maximum iteration number is reached or all domain labels become stable. Output: For each node, calculate the bba mi according to the labels of each node i, and output the bba matrix M = {mi}."}, {"heading": "C. Update order", "text": "In ELP, the labels of nodes are updated in a random order \u03c3. Therefore, we may detect different communities with different arrangements of nodes (i.e., different \u03c3s), which leads to a stability concern. Like LPA, ELP updates nodes\u2019 labels asynchronously. Benefiting from the asynchronous strategy, nodes which update labels earlier with stable labels will have a positive impact on the ones updated later [20].\nIn order to find a good update order, we first introduce the concept of influence variance as\nVi =\n\u2211 j\u2208Ni abs ( \u03b4\u2217ij \u2212 1|Ni| \u2211 t\u2208Ni \u03b4\u2217it ) |Ni| , (22)\nwhere abs(x) is the absolute value of x, |Ni| is the number of elements in set Ni, and\n\u03b4\u2217ij = \u03b4ij\u2211\nt\u2208Ni \u03b4it . (23)\nWe call \u03b4\u2217ij the normalized influence. From the definition of influence variance, it can be seen that Vi is small if the influence values of node i\u2019s neighbors do not spread out very much from the average. Hence, we can conclude that if node i\u2019s influence variance Vi is large, there must be some neighbors with very large values of normalized influence. According to the label propagation strategy, the label of node i is more likely to updated to the same one as the most influential neighbor. Therefore, the larger the influence variance of a node is, the easier the node updates its label.\nIn the label propagation strategy of ELP, the labels of central nodes will be easily adopted by border nodes. Thus if we set the labels of the border nodes as the same one with the nearest centers first and the central nodes are updated later, the result of label propagation will be the same as the natural community of the network. The central nodes generally have large local densities. That is to day, the nodes with small local density should be updated first.\nBased on the above analysis, in order to identify the correct community structure, the nodes can be ordered based on \u03b2 index which can be defined as\n\u03b2i = vi\u2211 i vi + 1 \u03c1i\u2211 i 1 \u03c1i . (24)\nWe arrange nodes in a descending order of value \u03b2, and denote this order by \u03c3\u2217."}, {"heading": "IV. EXPERIMENTS", "text": "In this section, several experiments will be conducted on graphs. The results will be compared with LPA and EKNNclus. It should be noted that EK-NNclus is for relational data sets with given dissimilarities. To apply EK-NNclus on graph data sets, the following distance measure associative with the similarity in Eq. (9) is considered:\ndij = \u03b4ij\n1\u2212 \u03b4ij . (25)\nWe adopt the Normalized Mutual Information (NMI) [21] to evaluate the quality of detected communities. The NMI of two partitions A and B of the graph, NMI(A,B), can be calculated by\nNMI(A,B) = \u22122 \u2211CA i=1 \u2211CB j=1Nij log( Nijn Ni\u00b7N\u00b7j\n)\u2211CA i=1Ni\u00b7 log( Ni\u00b7 n ) + \u2211CB j=1N\u00b7j log( N\u00b7j n ) ,\n(26) where CA and CB denote the numbers of communities in partitions A and B respectively. The notation Nij denotes the element of matrix (N)CA\u00d7CB , representing the number of nodes in the ith community of A that appear in the jth community of B. The sum over row i of matrix N is denoted\nby Ni\u00b7 and that over column j by N\u00b7j . If A and B are the same partitions, the NMI value is equal to one, i.e.,\nNMI(A,B) = 1.\nExample 1. The network displayed in Fig. 1\u2013a contains ten nodes belonging to two communities. Node 1 serves as a bridge between the nodes of two groups.\nLet \u03b7 = 1. We run ELP 50 times with different update order \u03c3s. By partitioning each node to the community with maximal plausibility value, the hard partition of all the nodes in the network can be got. Nodes 2, 3, 4, 5 and nodes 6, 7, 8, 9 are correctly divided into two groups all the time. But the community labels for nodes 1 and 10 are different using different update order. It indicates that it is difficult to determine the specific labels of nodes 1 and 10 based on the simple topological graph structure.\nThe optimal update order of nodes by Eq. (24) is\n\u03c3\u2217 = {4, 8, 3, 6, 2, 7, 1, 5, 9, 10}.\nThe iterative update process of ELP with \u03c3\u2217 is illustrated in Table I. Initially, each node is assigned with a unique label which is the same as its ID. And then the nodes update their own labels orderly. The ith column of the table shows the label of each node after the ith update step. The bold element of each column in the table indicates the node whose label is updated in this step. As can be seen, the nodes located in the border are updated first. Based on the definition of node influence and the label propagation strategy, the labels of central nodes are more easily adopted by the border nodes. If the update order is set to be \u03c3\u2217, the obtained hard partition is as that shown in Fig. 1\u2013b. The corresponding basic belief assignments for each node are shown in Fig. 2\u2013a. As can be seen from the figure, the masses of node 1 assigned to the two communities are equal, indicating that node 1 serves as a bridge in the network. For node 10, the maximum mass is given to the ignorant set \u2126. Here \u2126 is the set for outliers which are very different from their neighbors. From the original graph, we can see that node 10 has two neighbors, nodes 4 and 8. But neither of them shares a common neighbor with node 10. Therefore, node 10 can be regarded as an outlier of the graph. From the mass\nassignments, it is easy to see that the plausibilities of nodes 1 and 10 for two communities are equal. Consequently it is difficult to determine their specific domain labels.\nIn ELP, pignistic probabilities can also be obtained as a by-product, which can be regarded as fuzzy memberships of nodes. From Fig. 2\u2013b we can see that both node 1 and node 10 have similar memberships for the two communities. But the positions of the two nodes in the graph are different. Node 1 is in the central part while node 10 is in the border. This is the deficiency brought by the restriction that the probabilities over the frame should be sum to 1. Consequently, it could not distinguish outliers from overlapping nodes. Although the mass values assigned to the two communities are also equal, but those to set \u2126 are different. The mass given to \u2126 for node 1 is almost 0 while for node 10 it is approaching to 1. It illustrates one of the advantages of ELP that the overlapping nodes and outliers can be detected simultaneously with the help of bbas. For one node, if the maximal mass is given to the ignorant set \u2126, it is likely to be an outlier. On the contrary, when a node has large equal mass assignments for more than one community, it probably locates in the overlap.\nWe evoke LPA many times on this simple graph. Nodes 1 and 10 are divided into different communities in different runs. LPA could detect neither the overlapping nodes nor the outliers. Before applying EK-NNclus algorithm, the number of nearest neighbors, K, should be fixed. The results by EKNNclus with K = 3 and K = 4 are shown in Tables II and III respectively. It can be seen that five communities are detected by EK-NNclus. Nodes 10 and 6 are specially partitioned into two special small groups respectively. Node 1 is regarded as an outlier when K = 3, while no outlier is detected when K = 4. In graphs, different nodes have different number of neighbors, thus it is not reasonable to use the same K for all the nodes. This may be the reason that the performance of EK-NNclus is not as good as that of ELP. The NMI values are not listed in this experiment as there is no ground-truth for this illustrative graph. Example 2. Here we test on a widely used benchmark in detecting community structures, \u201cKarate Club\u201d, studied by Wayne Zachary [22]. The network consists of 34 nodes and 78 edges representing the friendship among the members of the club (see Fig. 3). During the development, a dispute\narose between the club\u2019s administrator and instructor, which eventually resulted in the club split into two smaller clubs (one marked with pink squares, and the other marked with yellow circles), centered around the administrator and the instructor respectively.\nLet \u03b7 = 1, and evoke ELP many times with different update order \u03c3s. We find that we can get two different results. Most\nof the time, ELP could detect two communities and find two outliers. The bbas of nodes in the two groups are illustrated in Figs. 5\u2013a and 5\u2013b respectively. It is showed in the figures that this network has strong class structures, since for each node the mass values assigned to different classes are significantly different. Nodes 10 and 12 are two outliers in their own communities. From the original graph, node 12 only connects with node 1. For node 10, it has two neighbors, nodes 3 and 34, but it has no connection with the neighbors of the two nodes. Neither node 10 nor node 12 has close relationship with other nodes in the network. Therefore, it is very intuitive that they are detected as outliers. It is noted here that with update order \u03c3\u2217, we can get the above clustering result with two communities and two outliers.\nWith some \u03c3s, a special small community can been found by ELP. As shown in Fig. 4\u2013b, a group containing nodes 5, 6, 7, 11, 17 has been separated from community \u03c91. This seems reasonable as these nodes have no connections with other nodes in class \u03c91 except the central node (node 1). The bbas of these five nodes are illustrated in Fig. 6. It can be seen that nodes 5 and 11 have large mass values for community \u03c91 and \u03c93, which can be regarded as bridges of the two communities. Nodes 10 and 12 are still regarded as outliers in this case.\nTo compare the accuracy and robustness of different methods, each algorithm (ELP, LPA and EK-NNclus with K = 3, 4, 5, 6) is repeated 50 times with a random update order each time. The minimum, maximum, average and the standard deviation of NMI values are listed in Table IV. To get NMI values of the detected results of ELP, we should get the domain label of each node by assigning each node to the community with maximum plausibility. It should be noted that node 10 has a equal plausibility for community \u03c91 and \u03c92, that is,\npl(\u03c91) = pl(\u03c92).\nWe randomly set a label as its dominant label. From the table we can find that ELP has good robustness as well as accuracy. EK-NNclus is stable when K is relatively large, but the accuracy is not as good as that in ELP. The performance of LPA is worst in terms of stability and average accuracy.\nExample 3. The network we investigate in this experiment is the world of American college football games between Division IA colleges during regular season Fall 2000. The vertices in the network represent 115 teams, while the links denote 613 regular-season games between the two teams they connect. The teams are divided into 12 conferences containing around 8-12 teams each and generally games are more frequent between members from the same conference than between those from different conferences. The original network is displayed in Fig. 7\u2013a.\nEach of the algorithms ELP, LPA, and EK-NNclus is repeated 50 times with different update order \u03c3s, the statistical properties of the corresponding NMI values are listed in Table V. As can be seen, the maximal value of NMI is almost the same by LPA and ELP. However, the minimum and average by ELP are significantly larger than those by LPA. These results further demonstrate the robustness of ELP.\nNow we fix the update order and let \u03c3 = \u03c3\u2217. The NMI value of the detected communities is 0.9102. It is very close to the maximum 0.9269. The clustering result of ELP with \u03c3\u2217 is presented in Fig. 7\u2013b. As shown in the figure, six conferences are exactly identified.\nExample 4. In this experiment, we will test on three other real-world graphs: Dolphins network, Lesmis network and Political books network [22]. For one data set, each algorithm is evoked 50 times with a random \u03c3 each time. The statistical characteristics of the evaluation results in terms of NMI on the three data sets are illustrated in Tables VI \u2013 VIII respectively. As shown in the tables, ELP is much more stable than other approaches as the standard deviation is quite small. The average performance of ELP is best among all the methods."}, {"heading": "V. CONCLUSION", "text": "In this paper, a new community detection approach, named ELP, is presented. The proposed approach is inspired from the conventional LPA and EK-NNclus clustering algorithm. By the introduction of node influence, a new evidential label propagation strategy is devised. After the propagation process, the domain label of each node is determined according to its plausibilities. The experimental results illustrate the advantages of ELP. It can be used to detect the overlapping nodes and outliers at the same time. To define the influence of each node, different similarity measures can be adopted. Specially, if there are some attributes describing the features of nodes, a similarity index considering both the topological graph structure and the attribute information is a better choice. Therefore, we intend to discuss the effects of different similarity measures on ELP and the application of ELP on graphs with attribute information in our future research work."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by the National Natural Science Foundation of China (Nos.61135001, 61403310)."}], "references": [{"title": "Finding and evaluating community structure in networks", "author": ["M.E. Newman", "M. Girvan"], "venue": "Physical review E, vol. 69, no. 2, p. 026113, 2004.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Resolution limit in community detection", "author": ["S. Fortunato", "M. Barthelemy"], "venue": "Proceedings of the National Academy of Sciences, vol. 104, no. 1, pp. 36\u201341, 2007.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Detecting overlapping and hierarchical communities in complex network using interaction-based edge clustering", "author": ["P. Kim", "S. Kim"], "venue": "Physica A: Statistical Mechanics and its Applications, vol. 417, pp. 46\u2013 56, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Spectral methods for community detection and graph partitioning", "author": ["M.E. Newman"], "venue": "Physical Review E, vol. 88, no. 4, p. 042822, 2013.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "A similarity-based community detection method with multiple prototype representation", "author": ["K. Zhou", "A. Martin", "Q. Pan"], "venue": "Physica A: Statistical Mechanics and its Applications, vol. 438, pp. 519\u2013531, 2015.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Near linear time algorithm to detect community structures in large-scale networks", "author": ["U.N. Raghavan", "R. Albert", "S. Kumara"], "venue": "Physical Review E, vol. 76, no. 3, p. 036106, 2007.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2007}, {"title": "A mathematical theory of evidence", "author": ["G. Shafer"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1976}, {"title": "A k-nearest neighbor classification rule based on dempstershafer theory", "author": ["T. Den\u0153ux"], "venue": "Systems, Man and Cybernetics, IEEE Transactions on, vol. 25, no. 5, pp. 804\u2013813, 1995.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "A new incomplete pattern classification method based on evidential reasoning", "author": ["Z.-g. Liu", "Q. Pan", "G. Mercier", "J. Dezert"], "venue": "Cybernetics, IEEE Transactions on, vol. 45, no. 4, pp. 635\u2013646, 2015.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "ECM: An evidential version of the fuzzy c-means algorithm", "author": ["M.-H. Masson", "T. Den\u0153ux"], "venue": "Pattern Recognition, vol. 41, no. 4, pp. 1384\u20131397, 2008.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2008}, {"title": "Evidential relational clustering using medoids", "author": ["K. Zhou", "A. Martin", "Q. Pan", "Z.-G. Liu"], "venue": "Information Fusion (Fusion), 2015 18th International Conference on. IEEE, 2015, pp. 413\u2013420.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "ECMdd: Evidential cmedoids clustering with multiple prototypes", "author": ["K. Zhou", "A. Martin", "Q. Pan", "Z.-g. Liu"], "venue": "Pattern Recognition, doi: 10.1016/j.patcog.2016.05.005, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Identifying influential nodes in weighted networks based on evidence theory", "author": ["D. Wei", "X. Deng", "X. Zhang", "Y. Deng", "S. Mahadevan"], "venue": "Physica A: Statistical Mechanics and its Applications, vol. 392, no. 10, pp. 2564\u20132575, 2013.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Evidential communities for complex networks", "author": ["K. Zhou", "A. Martin", "Q. Pan"], "venue": "Information Processing and Management of Uncertainty in Knowledge-Based Systems. Springer, 2014, pp. 557\u2013566.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Median evidential c-means algorithm and its application to community detection", "author": ["K. Zhou", "A. Martin", "Q. Pan", "Z.-g. Liu"], "venue": "Knowledge- Based Systems, vol. 74, pp. 69\u201388, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Maximum likelihood estimation from uncertain data in the belief function framework", "author": ["T. Den\u0153ux"], "venue": "Knowledge and Data Engineering, IEEE Transactions on, vol. 25, no. 1, pp. 119\u2013130, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Evidential-EM algorithm applied to progressively censored observations", "author": ["K. Zhou", "A. Martin", "Q. Pan"], "venue": "Information Processing and Management of Uncertainty in Knowledge-Based Systems. Springer, 2014, pp. 180\u2013189.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Decision making in the TBM: the necessity of the pignistic transformation", "author": ["P. Smets"], "venue": "International Journal of Approximate Reasoning, vol. 38, no. 2, pp. 133\u2013147, 2005.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "EK-NNclus: A clustering procedure based on the evidential k-nearest neighbor rule", "author": ["T. Den\u0153ux", "O. Kanjanatarakul", "S. Sriboonchitta"], "venue": "Knowledge-Based Systems, vol. 88, pp. 57\u201369, 2015.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Label propagation based evolutionary clustering for detecting overlapping and non-overlapping communities in dynamic networks", "author": ["K. Liu", "J. Huang", "H. Sun", "M. Wan", "Y. Qi", "H. Li"], "venue": "Knowledge-Based Systems, vol. 89, pp. 487\u2013496, 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Comparing community structure identification", "author": ["L. Danon", "A. Diaz-Guilera", "J. Duch", "A. Arenas"], "venue": "Journal of Statistical Mechanics: Theory and Experiment, vol. 2005, no. 09, p. P09008, 2005.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "One of the most popular type of classical methods partitions networks by optimizing some criteria such as the modularity measure (usually denoted by Q) [1].", "startOffset": 152, "endOffset": 155}, {"referenceID": 1, "context": "This problem is famously known as the resolution limit [2].", "startOffset": 55, "endOffset": 58}, {"referenceID": 2, "context": "It merges or splits clusters according to a topological measure of similarity between the nodes and tries to build a hierarchical tree of partitions [3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 3, "context": "Some other popular community detection approaches using spectral clustering [4] or partitional clustering methods [5] can be found.", "startOffset": 76, "endOffset": 79}, {"referenceID": 4, "context": "Some other popular community detection approaches using spectral clustering [4] or partitional clustering methods [5] can be found.", "startOffset": 114, "endOffset": 117}, {"referenceID": 5, "context": "The Label Propagation Algorithm (LPA), which was first investigated in [6], has the benefits of nearly-linear running time and easy implementation, thus it forms a good basis for efficient community detection methods.", "startOffset": 71, "endOffset": 74}, {"referenceID": 6, "context": "The theory of belief functions, also called Dempster\u2013Shafer Theory (DST), offers a mathematical framework for modeling uncertainty and imprecise information [7].", "startOffset": 157, "endOffset": 160}, {"referenceID": 7, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 75, "endOffset": 78}, {"referenceID": 8, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 80, "endOffset": 83}, {"referenceID": 9, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 101, "endOffset": 105}, {"referenceID": 10, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 107, "endOffset": 111}, {"referenceID": 11, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 113, "endOffset": 117}, {"referenceID": 12, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 143, "endOffset": 147}, {"referenceID": 13, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 149, "endOffset": 153}, {"referenceID": 14, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 155, "endOffset": 159}, {"referenceID": 15, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 187, "endOffset": 191}, {"referenceID": 16, "context": "It has been widely employed in various fields, such as data classification [8], [9], data clustering [10], [11], [12], social network analysis [13], [14], [15] and statistical estimation [16], [17].", "startOffset": 193, "endOffset": 197}, {"referenceID": 0, "context": "The function m : 2 \u2192 [0, 1] is said to be the Basic Belief Assignment (bba) on 2, if it satisfies: \u2211 A\u2286\u03a9 m(A) = 1.", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "The function pl : \u03a9\u2192 [0, 1] that maps each element \u03c9i in \u03a9 to its plausibility pl(\u03c9i) = Pl({\u03c9i}) is called the contour function associated to m.", "startOffset": 21, "endOffset": 27}, {"referenceID": 17, "context": "A belief function on the credal level can be transformed into a probability function by Smets method [18], where the mass m(A) is equally distributed among the elements of A.", "startOffset": 101, "endOffset": 105}, {"referenceID": 6, "context": "When the information sources are reliable, several distinct bodies of evidence characterized by different bbas can be combined using Dempster-Shafer (DS) rule [7].", "startOffset": 159, "endOffset": 162}, {"referenceID": 18, "context": "EK-NNclus clustering Recently, a new decision-directed clustering algorithm for relational data sets is put forward based on the evidential K nearest-neighbor (EK-NN) rule [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 7, "context": "Starting from an initial partition, the algorithm, called EK-NNclus, iteratively reassigns objects to clusters using the EK-NN rule [8], until a stable partition is obtained.", "startOffset": 132, "endOffset": 135}, {"referenceID": 0, "context": "Suppose the set of neighbors of node i is Ni, we then compute \u03b1ij = { \u03c6(\u03b4ij) if j \u2208 Ni, 0 otherwise, (11) where \u03c6 is a non-decreasing mapping from [0, 1] to [0, 1].", "startOffset": 147, "endOffset": 153}, {"referenceID": 0, "context": "Suppose the set of neighbors of node i is Ni, we then compute \u03b1ij = { \u03c6(\u03b4ij) if j \u2208 Ni, 0 otherwise, (11) where \u03c6 is a non-decreasing mapping from [0, 1] to [0, 1].", "startOffset": 157, "endOffset": 163}, {"referenceID": 18, "context": "Coefficient \u03b3 can be fixed as follows [19]: \u03b3 = 1/median ({( 1\u2212 \u03b4ij \u03b4ij )2 , i = 1, 2, \u00b7 \u00b7 \u00b7 , n, j \u2208 Ni }) .", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": "As explained in [19], to obtain the domain label of each node, it is not necessary to compute the combined mass function m explicitly.", "startOffset": 16, "endOffset": 20}, {"referenceID": 19, "context": "Benefiting from the asynchronous strategy, nodes which update labels earlier with stable labels will have a positive impact on the ones updated later [20].", "startOffset": 150, "endOffset": 154}, {"referenceID": 20, "context": "(25) We adopt the Normalized Mutual Information (NMI) [21] to evaluate the quality of detected communities.", "startOffset": 54, "endOffset": 58}], "year": 2016, "abstractText": "Abstract\u2014Community detection has attracted considerable attention crossing many areas as it can be used for discovering the structure and features of complex networks. With the increasing size of social networks in real world, community detection approaches should be fast and accurate. The Label Propagation Algorithm (LPA) is known to be one of the near-linear solutions and benefits of easy implementation, thus it forms a good basis for efficient community detection methods. In this paper, we extend the update rule and propagation criterion of LPA in the framework of belief functions. A new community detection approach, called Evidential Label Propagation (ELP), is proposed as an enhanced version of conventional LPA. The node influence is first defined to guide the propagation process. The plausibility is used to determine the domain label of each node. The update order of nodes is discussed to improve the robustness of the method. ELP algorithm will converge after the domain labels of all the nodes become unchanged. The mass assignments are calculated finally as memberships of nodes. The overlapping nodes and outliers can be detected simultaneously through the proposed method. The experimental results demonstrate the effectiveness of ELP.", "creator": "LaTeX with hyperref package"}}}