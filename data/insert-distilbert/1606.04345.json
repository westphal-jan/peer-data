{"id": "1606.04345", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Digits that are not: Generating new types through deep neural nets", "abstract": "for an artificial creative agent, an necessarily essential driver of computing the search for novelty is a value function which is less often provided by the system designer or application users. we argue that an intrinsic important barrier stone for progress in creativity research is the inability of these systems to develop their own notion of value functional for novelty. we propose a notion of knowledge - driven creativity that circumvent the need for obtaining an externally imposed value argument function, allowing the system to explore based on on what it has learned from grasping a set of referential objects. the idea concept is illustrated variously by a specific knowledge model provided by a deep software generative autoencoder. using the described system, we train a knowledge model on a set of digit images and we use the same model to build coherent sets named of new digits that don't belong to known digit types.", "histories": [["v1", "Tue, 14 Jun 2016 13:29:13 GMT  (1692kb,D)", "http://arxiv.org/abs/1606.04345v1", "preprint ICCC'16, International Conference on Computational Creativity"]], "COMMENTS": "preprint ICCC'16, International Conference on Computational Creativity", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ak{\\i}n kazak\\c{c}{\\i}and mehdi cherti", "bal\\'azs k\\'egl"], "accepted": false, "id": "1606.04345"}, "pdf": {"name": "1606.04345.pdf", "metadata": {"source": "CRF", "title": "Digits that are not: Generating new types through deep neural nets", "authors": ["Ak\u0131n Kazak\u00e7\u0131", "Mehdi Cherti", "Bal\u00e1zs K\u00e9gl"], "emails": ["akin.kazakci@mines-paristech.fr", "balazs.kegl}@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "It is a widely accepted view in creativity research that creativity is a process by which novel and valuable combinations of ideas are produced (Runco and Jaeger 2012). This view bears a tension, the essence of which can be expressed by the following question: how to determine the value of novelty? If a new object is substantially different of the previous objects in its category, it might be hard to determine its value. On the contrary, if the value of an object can be readily determined, it might be the case that the object is not genuinely new. Indeed, there exist experimental results positing that novelty is a better predictor of creativity than the value (Diedrich et al. 2015) and that the brain processes novelty in a particular way (Beaucousin et al. 2011), suggesting that the relationship is far from trivial.\nIn art, the difficulty in determining the value of an object is omnipresent. An emblematic example is Le Grand Verre by Marcel Duchamp. The artist worked on this singular project from 1915 to 1923 and produced a groundbreaking yet enigmatic piece of art, which the critiques still continue to interpret in various ways. In 1934, Duchamp built La bo\u0131\u0302te verte, a green box containing preparatory material (notes, drawings, photographs) he produced for Le Grand Verre. Considered as a piece of art in its own right, the box was intended to assist and to explain Le Grand Verre, as would an exhibition catalog (Breton 1932).\nIn product design, there exist less enigmatic but still emblematic cases, where the value of an innovation could not\nbe easily determined. For instance, the first smartphone received significant criticism regarding its usability (e.g., no stylus was provided), and it was deemed to be less evolved than its counterparts. Beyond such problems related to the reception of novelty, the sheer difficulty in discovering new value has led companies to seek alternative approaches, such as input from lead users (Von Hippel 1986).\nThe difficulty in determining the value of novelty has particular implications from a computational perspective. How would a creative agent drive its search process towards novelty if its evaluation function has been predetermined? In practical implementations, we can find various manifestations of such fixed evaluation functions such as fitness functions or quantitative aesthetics criteria. These implementations fixate the kind of value the system can seek, once and for all in the beginning of the process. The creative outcome, if any, comes from an output whose perception was unexpected or unpredictable.\nTheoretically, it may be argued that this can be solved by allowing the creative agent to change its own evaluation rules (Wiggins 2006; Jennings 2010). This implies that the system would be able to develop a preference for unknown and novel types of objects (Kazakc\u0327\u0131 2014). In practice, this is implemented by interactive systems that use external feedback (e.g., the preferences of an expert) to guide the search process. Such systems explore user preferences about novelty rather than building their own value system. This is a shortcoming from the point of view of creativity (Kazakc\u0327\u0131 2014).\nAn alternative approach might be to force the system to systematically explore unknown objects (Hatchuel and Weil 2009). This requires the system to function in a differential mode, where there is a need to define a reference of known objects. In other words, new kinds of values might be searched by going-out-of-the-box mechanisms which require the system to develop knowledge about a referential set of objects. In the absence of knowledge about such a set, creativity is reduced either to a combinatorial search or to a rule-based generative inference, both of which explore boundaries confined by the creator of the system and not the system itself. When such knowledge exists, the system can explore new types of objects by tapping into the blind spots of the knowledge model (Kazakci et al. 2010).\nIn this paper, we use a deep generative neural network\nar X\niv :1\n60 6.\n04 34\n5v 1\n[ cs\n.A I]\n1 4\nJu n\n20 16\nto demonstrate knowledge-driven creativity. Deep nets are powerful tools that have been praised for their capacity of producing useful and hierarchically organized representations from data. While the utility of such representations have been extensively demonstrated in the context of recognition (i.e., classification) far less work exists on exploring the generative capacity of such tools.\nIn addition, the goal of the little work on generative deep nets is to generate objects of known types, and the quality of the generator is judged by the visual or quantified similarity with existing objects (e.g., an approximate likelihood) (Theis, Oord, and Bethge 2015). In contrast, we use deep nets to explore their generative capacity beyond known types by generating unseen combinations of extracted features, the results of which are symbols that are mostly unrecognizable but seemingly respecting some implicit semantic rules of compositionality (Figure 1). What we mean by features is a key concept of the paper: they are not decided by the (human) designer, rather learned by an autoassociative codingdecoding process.\nThe novelty of our approach is two-fold. With respect to computational creativity models, our model aims at explicitly generating new types. We provide an experimental framework for studying how a machine can develop its own value system for new types of objects. With respect to statistical sample-based generative models, rather than a technical contribution, we are introducing a new objective: generate objects that are, in a deep sense, similar to objects in the domain, but which use learned features of these objects to generate new objects which do not have the same type. In our case, we attempt to generate images that could be digits (e.g., in another imaginary culture), but which are not.\nSection 2 describes our positioning with respect to some of the fundamental notions in creativity research in previous works. Section 3 presents details about data-driven generative models and deep neural nets relevant to our implementation. Section 4 describes our approach for exploring novelty through generation of new types, presents examples and comments. Section 5 discusses links with related research and points to further research avenues. Section 6 concludes."}, {"heading": "2 Generative models for computational creativity", "text": ""}, {"heading": "2.1 The purpose of a generative model", "text": "In the computational creativity literature, exploration of novelty has often been considered in connection with art (Boden and Edmonds 2009; McCormack et al. 2014). Despite various debates and nuances on terminology, such work has generally been categorized under the term generative art (or generative models). As defined by (Boden and Edmonds 2009), a generative model is essentially a rulebased system, albeit one whose output is not known in advance, for instance, due to non-determinism or to many degrees of freedom in the parameters of the systems (see also (Galanter 2012)). A large variety of such systems has been built, starting as early as the 90s (Todd and Latham 1991; Sims 1991), based on even earlier foundations (Nees 1969; Edmonds 1969). The definition, the complexity, and the capabilities offered by such models evolved consistently. To date, several such models, including L-systems, cellular automata, or artificial life simulations, have been used in various contexts for the generation of new objects (i.e., drawings, sounds, or 3D printings) by machine. Such systems achieve an output, perceived as creative by their users, by opportunistically exploiting existing formal approaches that have been invented in other disciplines and for other purposes. Within this spirit, computational creativity research has produced a myriad of successful applications on highly complex objects, involving visual and acoustic information content.\nIn contrast, this work considers much simpler objects since we are interested, above all, in the clarification of notions such as novelty, value, or type, and in linking such notions with the solid foundations of statistics and machine learning. These notions underlie foundational debates on creativity research. Thus, rather than producing objects that might be considered as artistic by a given audience, our purpose is to better define and explicate a minimalist set of notions and principles that would hopefully lead to a better understanding of creativity and enable further experimental studies."}, {"heading": "2.2 The knowledge of a generative system", "text": "The definition of a generative model as a rule-based system (Boden and Edmonds 2009) induces a particular relationship with knowledge. It is fair to state that such formalized rules are archetypes of consolidated knowledge. If such rules are hard-coded into the creative agent by the system designer, the system becomes an inference engine rather than a creativity engine. By their very nature, rules embed knowledge about a domain and its associated value system that comes from the system designer instead of being discovered by the system itself.\nAllowing the system to learn its own rule system by examining a set of objects in a given domain resolves part of this problem: the value system becomes dependent on the learning algorithm (instead of the system designer). In our system, we use a learning mechanism where the creative agent is forced to learn to disassemble and reconstruct the examples it has seen. This ensures that the utility of the features and the transformations embedded within the rules learned by the system are directly linked to a capacity to construct objects. As we shall see, the particular deep neural net architecture we are using is not only able to reconstruct known objects: it can also build new and valuable objects using their hierarchically organized set of induced transformations."}, {"heading": "2.3 Knowledge-driven exploration of value", "text": "Today, more often than not, generative models of computational creativity involve some form of a biological metaphor, the quintessence of which is evolutionary computation (McCormack 2013). Contrary to human artists who are capable of exploring both novelty and the value of novelty, such computational models often consider the generation of novelty for a value function that is independent of the search process. Either they operate based on a fixed set of evaluation criteria or they defer evaluation to outside feedback. For the former case, a typical example would be a traditional fitness function. For the later case, a typical example would be an interactive genetic algorithm (Takagi 2001) where the information about value is provided by an oracle (e.g., a human expert). In both cases, the system becomes a construction machine where the generation of value is handled by some external mechanism and not by the system itself. This can be considered as a fundamental barrier for computational creativity research (Kazakc\u0327\u0131 2014) that we shall call fitness function barrier.\n(Parikka 2008) summarizes the stagnation that this approach causes for the study of art through computers: \u201c. . . if one looks at several of the art pieces made with genetic algorithms, one gets quickly a feeling of not \u2018nature at work\u2019 but a Designer that after a while starts to repeat himself. There seems to be a teleology anyhow incorporated into the supposed forces of nature expressed in genetic algorithms practice \u2018a vague feeling of disappointment surrounds evolutionary art\u2019\u201d.\nThe teleology in question is a direct consequence of fitness function barrier and the hard-coded rules. In our system, we avoid both issues by using a simple mechanism that enables the system to explore novel objects with novel values. Given a set of referential objects D = {x1, .., xn}\nwhose types T = {t1, ..., tk} are known (or can be determined by a statistical procedure such as clustering), the system is built in such a way that it generates objects D\u2032 = {x\u20321, . . . , x\u2032m} with types T \u2032 = {t\u20321, . . . , t\u2032`} such that D\u2032 6\u2282 D and T \u2032 6\u2282 T . In other words, the system builds a set of new objects, some of which have new types. While the current system does not develop a preference function over the novelty it generates, the current setup provides the necessary elements to develop and experiment with what might be a value function for the unknown types. At any rate, the generation of unknown types of objects is an essential first step for a creative system to develop its own evaluation function for novelty and to become a designer itself."}, {"heading": "3 Learning to generate", "text": ""}, {"heading": "3.1 Data-driven generative models", "text": "In contrast to computational creativity research that aims to generate new object descriptions, disciplines such as statistics and machine learning strive to build solid foundations and formal methods for modeling a given set of object descriptions (i.e., data). These disciplines do not consider the generation of data as a scientific question: the data generating process is considered fixed (given) but unknown. Nevertheless, these fields have developed powerful theoretical and practical formal tools that are useful to scientifically and systematically study what it means to generate novelty.\nIn fact, generative models have a long and rich history in these fields. The goal of generative models in statistics and machine learning is to sample from a fixed but unknown probability distribution p(x). It is usually assumed that the algorithm is given a sample D = {x1, . . . , xn}, generated independently (by nature or by a simulator) from p(x). There may be two goals. In classical density estimation the goal is to estimate p in order to evaluate it later on any new object x. Typical uses of the learned density are classification (where we learn the densities p\u03021 and p\u03022 from samples D1 and D2 of two types of objects, then compare p\u03021(x) and p\u03022(x) to decide the type of x), or novelty (or outlier) detection (where the goal is to detect objects from a stream which do not look like objects in D by thresholding p\u0302(x)).\nThe second goal of statistical generative models is to sample objects from the generative distribution p. If p is known, this is just random number generation. If p is unknown, one can go through a first density estimation step to estimate p\u0302, then sample from p\u0302. The problem is that when x is highdimensional (e.g., text, images, music, video), density estimation is a hard problem (much harder than, e.g., classification). A recent line of research (Hinton, Osindero, and Teh 2006; Salakhutdinov and Hinton 2009) attempts to generate from p without estimating it, going directly from D to novel examples. In this setup, a formal generative model g is a function that takes, as input, a random seed r, and generates an object x = g(r). The learning (a.k.a, training or building) process is a (computational) function A that takes, as input, a data set D, and outputs the generative model g = A(D).\nThe fundamental problem of this latter approach is very similar to the main question we raised about computational creativity: what is the value function? When the goal is den-\nsity estimation, the value of p\u0302 is formally \u2211\nx\u2208D\u2032 log p\u0302(x), the so-called log-likelihood, where D\u2032 is a second data set, independent from D which we used to build (or, in machine learning terminology, to train) p\u0302. When p is unknown, evaluating the quality of a generated object x = g(r) or the quality of a sample D\u0302 = {g(r1), . . . , g(rn)} is an unsolved research question in machine learning as well.\nThere are a few attempts to formalize a quantitative goal (Goodfellow et al. 2014), but most of the time the sample D\u0302 is evaluated visually (when x is an image) or by listening to the generated piece of music. And this is tricky: it is trivial to generate exact objects from the training setD (by random sampling), so the goal is to generate samples that are not in D, but which look like coming from the type of objects in D. By contrast, our goal is to generate images that look like digits but which do not come from digit types present in D."}, {"heading": "3.2 Deep neural networks", "text": "In the machine learning literature, the introduction of deep neural networks (DNNs) is considered a major breakthrough (LeCun, Bengio, and Hinton 2015). The fundamental idea of a DNN is to use of several hidden layers. Subsequent layers process the output of previous layers to sequentially transform the initial representation of objects. The goal is to build a specific representation useful for some given task (i.e., classification). Multi-layered learning has dramatically improved the state of the art in many high-impact application domains, such as speech recognition, visual object recognition, and natural language processing.\nAnother useful attribute of deep neural nets is that they can learn a hierarchy of representations, associated to layers of the net. Indeed, a neural net with L layers can be formalized as a sequence of coders (c1, . . . , cL). The representation in the first layer is y1 = c1(x), and for subsequent layers 1 < ` \u2264 L it is y` = c`(y`\u22121). The role of the output layer is then to map the top representation yL onto a final target y\u0302 = d(yL), for example, in the case of classification, onto a finite set of object types. In what follows, we will denote the function that the full net implements by f . With this notation, y\u0302 = d(yL) = d ( cL(yL\u22121) ) = . . . = f(x).\nThe formal training setup is the following. We are given a training setD = {x1, . . . , xn}, a set of learning targets (e.g., object types) {y1, . . . , yn}, and a score function s(y, y\u0302) representing the error (negative value) of the prediction y\u0302 with respect to the real target y. The setup is called supervised because both the targets of the network yi and the value of its output s is given by the designer. We train the network fw, where w is the vector of all the parameters of the net, by classical stochastic gradient descent (modulo technical details): we cycle through the training set, reconstruct y\u0302i = fw(xi), compute the gradient \u03b4i = \u2202s(yi, y\u0302i)/\u2202w, and move the weights w by a small step in the direction of \u2212\u03b4i."}, {"heading": "3.3 Autoassociative neural nets (autoencoders)", "text": "Formally, an autoencoder is a supervised neural network whose goal is to predict the input x itself. Such neural networks are composed of an encoder part and a decoder part. In a sense, an autoencoder learns to disassemble then\nto reassemble the object x. Our approach is based on a particular the technique described in (Bengio et al. 2013). We first learn about the input space by training an autoassociative neural net (a.k.a. autoencoder) f using objects D = {x1, . . . , xn}, then apply a technique that designs a generative function (simulator) g based on the trained net f .\nAutoencoders are convenient because they are designed to learn a representation y = c(x) of the object x and a decoder x\u2032 = d(y) such that x is close to x\u2032 in some formal sense, and y is concise or simple. In the classical information theoretical paradigm, both criteria can be formalized: we want the code length of y (the number of bits needed to store y) to be small while keeping the distortion (e.g., the Euclidean distance) between x and x\u2032 also small. In (neural) representation learning, the goals are somewhat softer. The distortion measure is usually the same as in information theory, but simplicity of y is often formalized implicitly by using various regularization operators. The double goal of these operators is to prevent the algorithm to learn the identity function for the coder c, and to learn a y that uses elements (\u201ccode snippets\u201d) that agree with our intuition of what object components are.\nThe decoder d takes the top representation yL and reconstructs x\u2032 = d(yL). The goal is to minimize a score s(x, x\u2032), also called distortion, that measures how close the input image x is to the reconstructed image x\u2032. Throughout this paper, we will use the Euclidean squared distance in the pixel space s(x, x\u2032) = \u2016x\u2212 x\u2032\u201622.\nWe are using a particular variant of autoencoders, called sparse convolutional autoencoders (Makhzani and Frey 2015) with L = 3 coding layers and a single decoding layer. Convolutional layers are neural net building blocks designed specifically for images: they are essentially small (e.g., 5 \u00d7 5) filters that are repeated on the full image (in other words, they share the same set of weights, representing the filter). The sparse regularizer penalizes dense activations, which results in a sparse representation: at any given layer, for any given image x, only a small number of units (\u201cobject parts\u201d, elements of y`) are turned on. This results in an interesting structure: lower layer representations are composed of small edgelets (detected by Gabor-filter like coders), followed by small object parts \u201cassembled\u201d from the low-level features. The convolutional filters themselves are object parts that were extracted from the objects of the training set. The sparsity penalty and the relatively small number of filters force the net to extract features that are general across the population of training objects."}, {"heading": "4 Generating from the learned model", "text": "In this section we present and comment some experimental results. First, we provide some illustrations providing an insight regarding the usefulness of the representations extracted by a deep net for searching for novelty. Then, we present the method we use to generate novel image objects, based on the formal approach described in Section 3."}, {"heading": "4.1 Searching for new types: with and without knowledge", "text": "We argued in previous sections that combinatorial search over the objects has disadvantages over a search process driven by a knowledge over the same set of objects obtained by the system itself. When the learning is implemented through a deep neural net, this knowledge is encoded in the form of multiple levels of representations and transformations from layer to layer. To demonstrate the effect of knowledge over these search procedures, instead of searching in the original object space of x, we have applied simple perturbation operations on the representation space y.\nFigure 3 illustrates the results of these perturbations. In the original representation space, crossover and mutation operators create noisy artifacts, and the population quickly becomes unrecognizable, which, unless the sought effect is precisely the noise, is not likely to produce novel objects (let alone types) unless a fitness function that drives the search is given (which is what we are trying to avoid). In comparison, the same operators applied to the code y produced by the deep nets produce less noisy and seemingly more coherent forms. In fact, some novel symbols that go beyond the known digits seem to have already emerged and can be consolidated by further iteration through the model. Overall, combinatorial search in the representation space provided by the deep net seems more likely to generate meaningful combinations in the absence of a given evaluation function, thus, making it more suitable for knowledge-driven creativity."}, {"heading": "4.2 Method for generating new objects from a learned model", "text": "To generate new objects in a knowledge-driven fashion, we first train a generative autoencoder to extract features that are useful for constructing such objects. To train the autoencoder f , we use the MNIST (Lecun and Cortes 2012) data set (Figure 4) containing gray-scale hand-written digits. It contains 70 000 images of size 28 \u00d7 28. Once the model learned to construct objects it has seen, it has also learned useful transformations that can be queried to generate new objects.\nAutoassociative networks exist since the 80s (Rumelhart, Hinton, and Williams 1986; Baldi and Hornik 1989; Kramer 1991), nevertheless, it was discovered only recently that they can be used to generate new objects (Bengio et al. 2013;\nKamyshanska and Memisevic 2013). The procedure is the following. We start from a random image x0 = r, and reconstruct it x1 = f(x) using the trained network f . Then we plug the reconstructed image back to the net and repeat xk = f(xk\u22121) until convergence. Figure 2 illustrates the process. At each step, the net is forced to generate an image which is easier to reconstruct than its input. The random seed r initializes the process. From the first iteration on, we can see familiar object parts and compositions rules, but the actual object is new. The net converges to a fixed point (an image that can be reconstructed without an error).\nIt can be observed that, although this kind of generative procedure generates new objects, the first generation of images obtained by random input (second column of Figure 2) look noisy. This can be interpreted as the model has created a novelty, but has not excelled yet at constructing it adequately. However, feeding this representation back to the model and generating a new version improves the quality. Repeating this step multiple times enables the model to converge effectively towards fixed points of the model, that are more precise (i.e., visually). Their novelty, in terms of typicallity, can be checked using clustering methods and visualised as in Figure 5."}, {"heading": "4.3 Generating new types", "text": "When the generative approach is repeated starting from multiple random images {r1, . . . , rn}, the network generates different objects {x1, . . . , xn}. When projecting these objects (with the original MNIST images) into a twodimensional space using stochastic neighbor embedding\n(van der Maaten and Hinton 2008), the space is not filled uniformly: it has dense clusters, meaning that structurally similar objects tend to regroup; see Figure 5. We recover these clusters quantitatively using k-means clustering in the feature space {y1, . . . , yn}. Figure 6 contains excerpts from these clusters. They are composed of similar symbols that form a coherent set of objects, which can be perceived as new types."}, {"heading": "5 Discussion and perspectives", "text": "It is possible to compare our work with several other published results. To start with, the generation of novelty through the use of neural nets is an old idea (Todd 1992; Todd 1989; Thaler 1998). There are two main differences between our approach and theirs. First, our emphasis is on studying how an artificial agent can generate novelty that does not fit into learned categories, rather than creating objects with artistic value. This experimental setup is intended to provide means for studying how a creative agent can build an evaluation function for new types of objects. Second, we explicitly aim at establishing a bidirectional link between generative models for computational creativity and generative models within statistics and machine learning. Beyond the use of techniques and tools developed in these disciplines, we wish to raise research questions about creative reasoning that would also be interesting in statistics and machine learning.\nIn fact, some recent work has already started exploring\nthe creative potential of deep neural networks. For instance, (Mordvintsev, Olah, and Tyka 2015) uses a deep net to project the input that would correspond to a maximal activation of a layer back onto an image in an iterative fashion. The images are perceived as dreamy objects that are both visually confusing and appealing. Another work (Gatys, Ecker, and Bethge 2015) uses correlations of activations in multiple layers of a deep net to extract style information from one picture and to transpose it to another. Finally, (Nguyen, Yosinski, and Clune 2015) uses a trained net as a fitness function for an evolutionary approach (see also (Machado, Romero, and Manaris 2008) for a similar application with shallow nets). These successful approaches demonstrate the potential of deep nets as an instrument for creativity research and for generating effects that can be deemed as surprising, even creative. The present approach and the points the paper puts forward are significantly different. Compared to the architectures used in these studies, ours is the only one that uses a generative deep autoassociative net. The reason for this choice is twofold. First, we aim at using and understanding the generative capacity of deep nets. Second, we are interested in the deconstruction and reconstruction our architecture provides since our aim is to build objects through the net (not to create an effect that modifies existing objects). Once again, thinking about and experimenting with these foundational aspects of generative deep nets provide a medium through which notions of creativity research can be clarified through statistical notions. This is not among the declared objectives of previous works.\nThe novelty-seeking behavior of our system can also be compared to the recent novelty-driven search approaches in the evolutionary computing literature (Mouret and Doncieux 2012; Lehman and Stanley 2011). These approaches, like ours, seek to avoid objective functions and push the system to systematically generate novelty in terms of system behavior (e.g., novelty in the output). Our system is akin to such methods in spirit with one main difference: we believe that knowledge plays a fundamental role in creative endeavor and the decision of the system regarding the search for novelty should come from its own knowledge model. Note that this does not exclude a more general system where several systems such as ours can compete to differentiate themselves from the observed behavior of others, effectively creating a community of designers.\nOur system provides a step towards an experimental study of how an artificial agent can drive its search based on knowledge. Furthermore, it can effectively create new types of objects preserving abstract and semantic properties of a domain. However, we have not fully addressed the question of how such an agent can build its own value function about novelty. Nevertheless, the system enables numerous ways to experiment with various possibilities. An obvious next step would be to hook our system to an external environment, where the system can receive feedback about value (Clune and Lipson 2011; Secretan et al. 2008). To avoid the fitness function barrier, this should be done in such a way that the system can build its own value system rather than only learning the ones in its environment."}, {"heading": "6 Summary", "text": "We provided an experimental setup based on a set of principles that we have described. The pinnacle of these principles is that artificial creativity can be driven by knowledge that a machine extracts itself from a set of objects defining a domain. Given such knowledge, a creative agent can explore new types of objects and build its own value function about novelty. This principle is in contrast with existing systems where the system designer or audience imposes a value function to the system, for example, by some fitness function.\nWe argued that when an artificial creative agent extracts its own domain knowledge in the form of features that are useful to reconstruct the objects of the domain, it becomes able to explore novelties beyond the scope of what it has seen by exploring systematically unknown types. We have demonstrated the idea by using a deep generative network trained on a set of digits. We proposed a compositional sampling approach that yielded a number of new types of digits.\nWhile our setup provides a basis for further exploring how an agent can develop its own value function, it is also a bridge with the powerful theories and techniques developed within the statistics and machine learning communities. A colossal amount of work has already been published on deep neural networks with significant breakthroughs in many domains. Deep learning will be all the more valuable if it offers an evolution of the machine learning paradigm towards machine creativity."}, {"heading": "7 Acknowledgments", "text": "We thank our anonymous referees for helpful comments. This work was partially supported by the HPC Center of Champagne-Ardenne ROMEO.This work has been funded by the P2IO LabEx (ANR-10-LABX-0038) in the framework Investissements dAvenir (ANR-11-IDEX-0003-01) managed by the French National Research Agency (ANR)."}], "references": [{"title": "and Hornik", "author": ["P. Baldi"], "venue": "K.", "citeRegEx": "Baldi and Hornik 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Erp evidence of a meaningfulness impact on visual global/local processing: when meaning captures attention", "author": ["Beaucousin"], "venue": null, "citeRegEx": "Beaucousin,? \\Q2011\\E", "shortCiteRegEx": "Beaucousin", "year": 2011}, {"title": "Generalized denoising auto-encoders as generative models", "author": ["Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bengio,? \\Q2013\\E", "shortCiteRegEx": "Bengio", "year": 2013}, {"title": "E", "author": ["M.A. Boden", "Edmonds"], "venue": "A.", "citeRegEx": "Boden and Edmonds 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Lipson", "author": ["J. Clune"], "venue": "H.", "citeRegEx": "Clune and Lipson 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "A", "author": ["J. Diedrich", "M. Benedek", "E. Jauk", "Neubauer"], "venue": "C.", "citeRegEx": "Diedrich et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "A", "author": ["Gatys, L.A.", "Ecker"], "venue": "S.; and Bethge, M.", "citeRegEx": "Gatys. Ecker. and Bethge 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow", "year": 2014}, {"title": "and Weil", "author": ["A. Hatchuel"], "venue": "B.", "citeRegEx": "Hatchuel and Weil 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "G", "author": ["Hinton"], "venue": "E.; Osindero, S.; and Teh, Y.-W.", "citeRegEx": "Hinton. Osindero. and Teh 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "K", "author": ["Jennings"], "venue": "E.", "citeRegEx": "Jennings 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "and Memisevic", "author": ["H. Kamyshanska"], "venue": "R.", "citeRegEx": "Kamyshanska and Memisevic 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Simulation of design reasoning based on ck theory: a model and an example application", "author": ["Kazakci"], "venue": "In DS 60: Proceedings of DESIGN", "citeRegEx": "Kazakci,? \\Q2010\\E", "shortCiteRegEx": "Kazakci", "year": 2010}, {"title": "M", "author": ["Kramer"], "venue": "A.", "citeRegEx": "Kramer 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "and Cortes", "author": ["Y. Lecun"], "venue": "C.", "citeRegEx": "Lecun and Cortes 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "K", "author": ["J. Lehman", "Stanley"], "venue": "O.", "citeRegEx": "Lehman and Stanley 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Experiments in computational aesthetics", "author": ["Romero Machado", "P. Manaris 2008] Machado", "J. Romero", "B. Manaris"], "venue": "In The art of artificial evolution", "citeRegEx": "Machado et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Machado et al\\.", "year": 2008}, {"title": "B", "author": ["A. Makhzani", "Frey"], "venue": "J.", "citeRegEx": "Makhzani and Frey 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Ten questions concerning generative computer art", "author": ["McCormack"], "venue": null, "citeRegEx": "McCormack,? \\Q2014\\E", "shortCiteRegEx": "McCormack", "year": 2014}, {"title": "Inceptionism: Going deeper into neural networks", "author": ["Olah Mordvintsev", "A. Tyka 2015] Mordvintsev", "C. Olah", "M. Tyka"], "venue": "Google Research Blog. Retrieved June", "citeRegEx": "Mordvintsev et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mordvintsev et al\\.", "year": 2015}, {"title": "and Doncieux", "author": ["Mouret", "J.-B."], "venue": "S.", "citeRegEx": "Mouret and Doncieux 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "A", "author": ["Nguyen"], "venue": "M.; Yosinski, J.; and Clune, J.", "citeRegEx": "Nguyen. Yosinski. and Clune 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "R", "author": ["D.E. Rumelhart", "G.E. Hinton", "Williams"], "venue": "J.", "citeRegEx": "Rumelhart. Hinton. and Williams 1986", "shortCiteRegEx": null, "year": 1986}, {"title": "G", "author": ["M.A. Runco", "Jaeger"], "venue": "J.", "citeRegEx": "Runco and Jaeger 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "G", "author": ["R. Salakhutdinov", "Hinton"], "venue": "E.", "citeRegEx": "Salakhutdinov and Hinton 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "K", "author": ["J. Secretan", "N. Beato", "D.B. D Ambrosio", "A. Rodriguez", "A. Campbell", "Stanley"], "venue": "O.", "citeRegEx": "Secretan et al. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "S", "author": ["Thaler"], "venue": "L.", "citeRegEx": "Thaler 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "A", "author": ["Theis, L.", "Oord"], "venue": "v. d.; and Bethge, M.", "citeRegEx": "Theis. Oord. and Bethge 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "and Latham", "author": ["S. Todd"], "venue": "W.", "citeRegEx": "Todd and Latham 1991", "shortCiteRegEx": null, "year": 1991}, {"title": "P", "author": ["Todd"], "venue": "M.", "citeRegEx": "Todd 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "P", "author": ["Todd"], "venue": "M.", "citeRegEx": "Todd 1992", "shortCiteRegEx": null, "year": 1992}, {"title": "Visualizing data using t-SNE", "author": ["van der Maaten", "L. Hinton 2008] van der Maaten", "G. Hinton"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "G", "author": ["Wiggins"], "venue": "A.", "citeRegEx": "Wiggins 2006", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [], "year": 2016, "abstractText": "For an artificial creative agent, an essential driver of the search for novelty is a value function which is often provided by the system designer or users. We argue that an important barrier for progress in creativity research is the inability of these systems to develop their own notion of value for novelty. We propose a notion of knowledge-driven creativity that circumvent the need for an externally imposed value function, allowing the system to explore based on what it has learned from a set of referential objects. The concept is illustrated by a specific knowledge model provided by a deep generative autoencoder. Using the described system, we train a knowledge model on a set of digit images and we use the same model to build coherent sets of new digits that do not belong to known", "creator": "LaTeX with hyperref package"}}}