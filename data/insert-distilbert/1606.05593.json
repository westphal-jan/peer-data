{"id": "1606.05593", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Introspective Agents: Confidence Measures for General Value Functions", "abstract": "agents practicing of general intelligence deployed in real - world scenarios must adapt to ever - changing complicated environmental conditions. while such adaptive agents may already leverage engineered knowledge, obviously they will require the capacity to construct futures and evaluate knowledge themselves from expressing their own experience in a bottom - up, constructivist fashion. this position development paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions. prior work has focused on learning predictions internally about potential externally derived signals about a precise task location or environment ( e. g. battery level, joint position ). here we advocate that detecting the agent should instinctively also predict internally generated signals regarding its own learning process - for them example, an agent's confidence in its learned predictions. finally, we suggest how such information would be deemed beneficial in creating an introspective agent intelligence that is able to learn to make good decisions in a complex, changing world.", "histories": [["v1", "Fri, 17 Jun 2016 17:24:36 GMT  (65kb,D)", "http://arxiv.org/abs/1606.05593v1", "Accepted for presentation at the Ninth Conference on Artificial General Intelligence (AGI 2016), 4 pages, 1 figure"]], "COMMENTS": "Accepted for presentation at the Ninth Conference on Artificial General Intelligence (AGI 2016), 4 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["craig sherstan", "adam white", "marlos c machado", "patrick m pilarski"], "accepted": false, "id": "1606.05593"}, "pdf": {"name": "1606.05593.pdf", "metadata": {"source": "CRF", "title": "Introspective Agents: Confidence Measures for General Value Functions", "authors": ["Craig Sherstan", "Adam White", "Marlos C. Machado", "Patrick M. Pilarski"], "emails": ["pilarski@ualberta.ca"], "sections": [{"heading": null, "text": "Predictive Knowledge. The ability to autonomously construct knowledge directly from experience produced by an agent interacting with the world is a key requirement for general intelligence. One particularly promising form of knowledge that is grounded in experience is predictive knowledge\u2014here defined as a collection of multi-step predictions about observable outcomes that are contingent on different ways of behaving. Much like scientific knowledge, predictive knowledge can be maintained and updated by making a prediction, executing a procedure, and observing the outcome and updating the prediction\u2014a process completely independent of human intervention. Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2].\nA value function from the field of reinforcement learning is one way of representing predictive knowledge. Value functions are a learned or computed mapping from state to the long-term expectation of future reward. Sutton et al. recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1]. These general value functions (GVFs), specify a prediction target as the expected discounted sum of future signals of interest (cumulants) observed while the agent selects actions according to some decision making policy. Temporal discounting is also generalized in GVFs from the conventional exponential weighting of future cumulants to an arbitrary, stateconditional weighting of future cumulants. This enables GVFs to specify a rich\nar X\niv :1\n60 6.\n05 59\n3v 1\n[ cs\n.A I]\n1 7\nJu n\n20 16\n2 class of predictive questions where discounting acts as a stochastic termination function [2]. A single GVF specifies a predictive question, and the answer takes the form of an approximate GVF that can be learned by temporal-difference (TD) learning algorithms solely from unsupervised interaction with the world. A collection of GVFs contributes to the agent\u2019s knowledge of the world.\nUltimately, the purpose of acquiring knowledge is to improve the agent\u2019s ability to achieve its goals. The agent\u2019s collection of GVFs are only useful to the extent that they help with reward maximization. While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4]. In this paper we take the next step by specifying GVFs whose cumulants are internal signals defined by the agent\u2019s own learning process.\nPredicting Internal Signals. GVFs have been previously used to specify predictions about signals external to the agent\u2014signals in the agent\u2019s sensorimotor stream of interactions. However, agents also have access to a set of internal signals not previously considered as cumulants for GVFs. Specifically, there are a number of signals available to an agent that relate to the agent\u2019s own learning mechanisms\u2014for example, its predictions\u2019 errors, weight changes, and other time-varying meta-parameters. There are also a range of signals that quantify the agent\u2019s interactions with its sensorimotor stream\u2014for example, statistics about state or feature-space visitation and statistical properties of input signals. Integrating predictions of these internal signals should improve an agent\u2019s decision making abilities towards human-level intelligence [5].\nOne representative class of internal signals relates to an agent\u2019s certainty in its own predictions. An agent might make better use of its knowledge given some sense of how much each approximate GVF is to be trusted. That is, given a GVF, how confident is the agent that the learned prediction is accurate and precise? Methods such as confidence intervals or ensemble forecasting are used in many domains and may also be appropriate here [6]. For our purposes, we desire an approach that is compatible with function approximation and supports online and incremental prediction and learning with only linear complexity (in the size of the input features). GVFs and TD methods used to approximate them satisfy these criteria and are therefore a promising approach to incorporating confidence measures. Indeed, this presents an appealing architecture where both predictive questions and measures of their confidence are represented in a single form.\nFurther, we propose that an agent\u2019s decision making process can be improved by using several confidence measures, rather than solely relying on a single value of confidence. Each measure can then provide a different perspective on the accuracy of an approximate GVF, enabling the agent to make more informed decisions. Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].\nWhile there are many measures that could be useful for an agent in determining confidence [11], we here provide three examples which are readily represented as GVFs (see Figure 1 for examples). The first is visitation. A measure of state\nvisitation can be expressed as a GVF by simply using a constant valued cumulant. An agent might reasonably decide to only trust a prediction in states that have been visited many times. The second is prediction error. On each time step, a temporal-difference error is used to update each approximate GVF [1]; this TD error can itself be used as the cumulant of another GVF. Such a prediction gives an agent an expectation of how much each approximate GVF will differ from the true outcome specified by the corresponding GVF. The third is variance. The variance of a cumulant or an approximate GVF can easily be represented as the difference between two GVFs, although the process for approximating these nonstationary cumulants is somewhat more involved [12].\nExample: Exploration with Confidence Measures. A collection of approximate GVFs, combined with their corresponding confidence measures provide the agent with a way to measure how much it should trust what it knows. In a safe environment an agent might view low confidence as an opportunity to learn more about its world [7,13]. In a dangerous environment, low confidence\n4 might be a strong indicator to proceed with caution or not at all. Further, confidence itself can be a goal for an agent\u2019s behavior. That is, an agent could choose to seek out predictability (high confidence) or novelty (low confidence). This naturally plays a role in the trade off between exploration and exploitation.\nConcluding remarks: Predictive knowledge is essential to a generally intelligent agent in maximizing its reward. We advocate that internal measures relating to prediction learning can and should also be represented as GVFs and learned in the same way. These new predictions provide additional knowledge that enables an agent to improve its decision making abilities. GVFs present a novel approach to the general problem of introspection within intelligent agents."}], "references": [{"title": "Horde: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction Categories and Subject Descriptors", "author": ["R.S. Sutton", "J. Modayil", "M. Delp", "T. Degris", "P.M. Pilarski", "A. White", "D. Precup"], "venue": "Int. Conf. on Autonomous Agents and Multi-Agent Systems, pp. 761\u2013768", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-Timescale Nexting in a Reinforcement Learning Robot", "author": ["J. Modayil", "A. White", "R.S. Sutton"], "venue": "Adapt. Behav. 22, pp. 146\u2013160", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Application of real-time machine learning to myoelectric prosthesis control: A case series in adaptive switching", "author": ["A.L. Edwards", "M.R. Dawson", "J.S. Hebert", "C. Sherstan", "R.S. Sutton", "K.M. Chan", "P.M. Pilarski"], "venue": "Prosthet. Orthot. Int., published online ahead of print, pp. 1\u20139", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "A Collaborative Approach to the Simultaneous Multi-joint Control of a Prosthetic Arm", "author": ["C. Sherstan", "J. Modayil", "P.M. Pilarski"], "venue": "Int. Conf. on Rehabilitation Robotics, pp. 13\u201318, Singapore, Singapore", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Surfing Uncertainty: Prediction, Action, and the Embodied Mind", "author": ["A. Clark"], "venue": "Oxford University Press", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Ensemble algorithms in reinforcement learning", "author": ["M.A. Wiering", "H. van Hasselt"], "venue": "IEEE Trans. Syst. Man, Cybern. Part B Cybern. 38, 4, pp. 930\u2013936", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Developing a predictive approach to knowledge", "author": ["A. White"], "venue": "PhD Thesis. University of Alberta", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Using predictive representations to improve generalization in reinforcement learning", "author": ["E.J. Rafols", "M.B. Ring", "R.S. Sutton", "B. Tanner"], "venue": "Int. Joint Conf. on Artificial Intelligence, pp. 835\u2013840", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2005}, {"title": "Better Generalization with Forecasts", "author": ["T. Schaul", "M. Ring"], "venue": "Int. Joint Conf. on Artificial Intelligence, pp. 1656\u20131662, Beijing, China", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Predictive Representations of State", "author": ["M.L. Littman", "R.S. Sutton", "S. Singh"], "venue": "Advances in Neural Information Processing Systems 14, pp. 1555\u20131561", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards Prosthetic Arms as Wearable Intelligent Robots", "author": ["C. Sherstan"], "venue": "MSc Thesis. University of Alberta", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Interval Estimation for Reinforcement-Learning Algorithms in Continuous-State Domains", "author": ["M. White", "A. White"], "venue": "Advances in Neural Information Processing Systems 23, pp. 2433\u20132441", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Curious model-building control systems", "author": ["J. Schmidhuber"], "venue": "IEEE Int. Joint Conf. on Neural Networks. pp. 1458\u20131463, Singapore, Singapore", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2].", "startOffset": 176, "endOffset": 181}, {"referenceID": 1, "context": "Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2].", "startOffset": 176, "endOffset": 181}, {"referenceID": 0, "context": "recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "class of predictive questions where discounting acts as a stochastic termination function [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 191, "endOffset": 196}, {"referenceID": 3, "context": "While GVFs are relatively new, there have been several recent demonstrations of their usefulness in robot tasks, from reflexive action in mobile robots [2], to the control of prosthetic arms [3,4].", "startOffset": 191, "endOffset": 196}, {"referenceID": 4, "context": "Integrating predictions of these internal signals should improve an agent\u2019s decision making abilities towards human-level intelligence [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 5, "context": "That is, given a GVF, how confident is the agent that the learned prediction is accurate and precise? Methods such as confidence intervals or ensemble forecasting are used in many domains and may also be appropriate here [6].", "startOffset": 221, "endOffset": 224}, {"referenceID": 6, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 121, "endOffset": 124}, {"referenceID": 7, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 179, "endOffset": 184}, {"referenceID": 8, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 179, "endOffset": 184}, {"referenceID": 9, "context": "Encoding these measures as GVFs enables these internal predictions to participate in the agent\u2019s representation of state [7], which can lead to more efficient reward maximization [8,9] and more accurate prediction [10].", "startOffset": 214, "endOffset": 218}, {"referenceID": 10, "context": "While there are many measures that could be useful for an agent in determining confidence [11], we here provide three examples which are readily represented as GVFs (see Figure 1 for examples).", "startOffset": 90, "endOffset": 94}, {"referenceID": 0, "context": "On each time step, a temporal-difference error is used to update each approximate GVF [1]; this TD error can itself be used as the cumulant of another GVF.", "startOffset": 86, "endOffset": 89}, {"referenceID": 11, "context": "The variance of a cumulant or an approximate GVF can easily be represented as the difference between two GVFs, although the process for approximating these nonstationary cumulants is somewhat more involved [12].", "startOffset": 206, "endOffset": 210}, {"referenceID": 6, "context": "In a safe environment an agent might view low confidence as an opportunity to learn more about its world [7,13].", "startOffset": 105, "endOffset": 111}, {"referenceID": 12, "context": "In a safe environment an agent might view low confidence as an opportunity to learn more about its world [7,13].", "startOffset": 105, "endOffset": 111}], "year": 2016, "abstractText": "Agents of general intelligence deployed in real-world scenarios must adapt to ever-changing environmental conditions. While such adaptive agents may leverage engineered knowledge, they will require the capacity to construct and evaluate knowledge themselves from their own experience in a bottom-up, constructivist fashion. This position paper builds on the idea of encoding knowledge as temporally extended predictions through the use of general value functions. Prior work has focused on learning predictions about externally derived signals about a task or environment (e.g. battery level, joint position). Here we advocate that the agent should also predict internally generated signals regarding its own learning process\u2014for example, an agent\u2019s confidence in its learned predictions. Finally, we suggest how such information would be beneficial in creating an introspective agent that is able to learn to make good decisions in a complex, changing world. Predictive Knowledge. The ability to autonomously construct knowledge directly from experience produced by an agent interacting with the world is a key requirement for general intelligence. One particularly promising form of knowledge that is grounded in experience is predictive knowledge\u2014here defined as a collection of multi-step predictions about observable outcomes that are contingent on different ways of behaving. Much like scientific knowledge, predictive knowledge can be maintained and updated by making a prediction, executing a procedure, and observing the outcome and updating the prediction\u2014a process completely independent of human intervention. Experience-grounded predictions are a powerful resource to guide decision making in environments which are too complex or dynamic to be exhaustively anticipated by an engineer [1,2]. A value function from the field of reinforcement learning is one way of representing predictive knowledge. Value functions are a learned or computed mapping from state to the long-term expectation of future reward. Sutton et al. recently introduced a generalization of value functions that makes it possible to specify general predictive questions [1]. These general value functions (GVFs), specify a prediction target as the expected discounted sum of future signals of interest (cumulants) observed while the agent selects actions according to some decision making policy. Temporal discounting is also generalized in GVFs from the conventional exponential weighting of future cumulants to an arbitrary, stateconditional weighting of future cumulants. This enables GVFs to specify a rich ar X iv :1 60 6. 05 59 3v 1 [ cs .A I] 1 7 Ju n 20 16", "creator": "LaTeX with hyperref package"}}}