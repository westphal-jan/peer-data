{"id": "1606.05611", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2016", "title": "Data-driven HR - R\\'esum\\'e Analysis Based on Natural Language Processing and Machine Learning", "abstract": "recruiters usually spend less than a clear minute looking at each r \\'esum \\'e when deciding whether it's fundamentally worth continuing the rigorous recruitment process with the candidate. recruiters focus best on keywords, and it's almost impossible to just guarantee a fair process of candidate selection. the main scope of this paper is to tackle this selection issue by introducing a data - driven approach that shows how to process r \\'esum \\'es automatically and give recruiters more time to only examine promising candidates. furthermore, we show how to leverage machine learning and natural language processing in order to extract all required information from the r \\'esum \\'es. once the information is extracted, a ranking score is approximately calculated. the score describes how well the candidates fit based on their education, work experience and skills. later this paper illustrates a prototype application that shows how this novel approach solution can increase the productivity of recruiters. the application enables them to filter and rank candidates based on predefined job descriptions. guided by the feedback ranking, recruiters can get deeper positive insights from candidate profiles and validate why and how the application ranked them. this application shows how to improve the hiring process by giving an unbiased hiring decision support.", "histories": [["v1", "Fri, 17 Jun 2016 17:52:31 GMT  (908kb,D)", "https://arxiv.org/abs/1606.05611v1", "Research Prototype, Technical Report"], ["v2", "Tue, 21 Jun 2016 20:48:05 GMT  (908kb,D)", "http://arxiv.org/abs/1606.05611v2", "Research Prototype, Technical Report"]], "COMMENTS": "Research Prototype, Technical Report", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["tim zimmermann", "leo kotschenreuther", "karsten schmidt"], "accepted": false, "id": "1606.05611"}, "pdf": {"name": "1606.05611.pdf", "metadata": {"source": "CRF", "title": "Data-driven HR Re\u0301sume\u0301 Analysis Based on Natural Language Processing and Machine Learning", "authors": ["Tim Zimmermann", "Hasso Plattner", "Leo Kotschenreuther", "Karsten Schmidt"], "emails": ["tim.zimmermann@student.hpi.de", "l.kotschenreuther@sap.com", "karsten.schmidt01@sap.com"], "sections": [{"heading": null, "text": "Index Terms\u2014Computer Science, Machine Learning, Natural Language Processing, Human Resources"}, {"heading": "1. Motivation", "text": "Data-driven HR is the current trend in HR departments to replace the outdated notion of support function and turning HR into a pro-active counselor and education partner within a corporate environment. Especially, the \u2018war for talent\u2019 and the amount of applications for open positions lead to new dimensions in processing candidate profiles and finding the best match [1]. Recruiters and hiring managers can easily be biased or accidentally applying \u2018filters\u20191 on candidates without having a full 360\u25e6 view on an individual candidate. Moreover, when having multiple profiles and multiple positions to fill, the problem of matching internal and external candidates is multiplying the necessary efforts. Candidates can easily flood recruiting inboxes via online\n1. E.g., only looking for a specific keyword or degree; and missing domain knowledge for a position to fill\nchannels. This is important, because according to Erica Breuer, tailored re\u0301sume\u0301s are still the most effective way to apply for a job [2]. This information flooding is maybe one of the reasons, why recruiters often ignore candidates that did not explicitly apply for a position instead of actively seeking them2. Having the right tools to objectively judge and rank candidates could help to a) find the best match and b) process more potential candidates.\nIn this research prototype, we leveraged current stateof-the-art technology in natural language processing (NLP) and machine learning (ML) to demonstrate how data-driven HR can significantly improve the quality and speed of the whole recruiting process."}, {"heading": "2. From Document to Information", "text": "Most external3 job seekers have to provide multiple documents to prove their education, their work eligibility, language certificates, formal trainings, and a re\u0301sume\u0301 stating prior work experience, education, awards, skills and more. We observed that most re\u0301sume\u0301s are provided as a PDF document and leveraged their typical structured nature. Because, simple text extraction (e.g., xpdf\u2019s pdf2text [3]) may result\n2. Job hunting on online portals, such as linkedin is mostly focusing on professionals\n3. External - outside of an organization\nar X\niv :1\n60 6.\n05 61\n1v 2\n[ cs\n.C L\n] 2\n1 Ju\nn 20\nin mixed segments (see Fig 1), leveraging layout information is crucial. To correctly identify all entities in a re\u0301sume\u0301, we employed segment-specific processors. For instance, once we identified the personal section or skill section, we instruct the processing pipeline accordingly. For the segmentation we identify headlines, extract font information, positioning, keywords, and spaces. Once the re\u0301sume\u0301 is split a pre-trained classifier4 helps to correctly identify a section and route it to the right processor.\nEach processor is using Named Entity Recognition (NER) to label locations, institutes, names, titles, and date information. Given the huge variety of date spellings, a separate regular expression step is necessary to normalize them. For instance, \u2018Summer 2015\u2019, \u2018Present/Now\u2019 or \u20182004,10 - 2005,9\u2019 are some of the non-standard instances which will be replaced with a normalized form \u2018mm/dd/yyyy\u2019 or a duration type, respectively.\nWhen inspecting segments like work experience, we reapply the segmentation logic to split into individual career steps before labeling employer, dates, and role.\nTo ensure consistent quality, a combination of NLP/ML and well-defined rules helps to label education experience. The degree identification is based on a normalized bachelor, master, doctoral degree ranking with a certain spelling variation tolerance. Contrary, the segment identification is solely ML classification based.\n4. We used various SVM, RF, DT models and compared their performance\nEventually, the skills section requires a customized processing, too. We pre-trained a skill co-occurrence model using word-embedding [4] based on a large corpus of 800 k profiles. For an easy validation and visualization we reduced the high dimensionality from hundred down to two using Stochastic Neighborhood Embedding (t-SNE [5]) and automatically identified clusters (see Fig 2) of related skills.\nThe whole pre-processing pipeline transforms a re\u0301sume\u0301 document into a set of structured information entities that can easily be processed."}, {"heading": "3. From Information to Knowledge", "text": "The goal is to get a complete picture of a candidate\u2019s fit to a specific job position. Thus, we need to combine multiple dimensions of information, such as skills, education, and work experience. In this section we will show how we measure fit on each dimension and how we can merge them to gain a final ranking score representing a candidate\u2019s fit."}, {"heading": "3.1. Scoring", "text": "In our prototype, each candidate is assigned a score between 0 and 100 indicating its match to a given job description. The score is the weighted average of the three categories: education, work experience, and skills. By default, the skills score is twice as important as the other two."}, {"heading": "3.2. Education", "text": "The education score is based on academic degree as well as the university\u2019s ranking. For university ranking we used: Times Higher Education [6] and QS [7]. Both of them include a score between 0 and 100, with 100 being the best5. We use the average of both scores. If a university is not listed in one of these rankings, its score for that ranking is considered to be 0. We know that this may be unfair, but almost all universities we checked for our prototype were present in at least one of the rankings. By default, the degree score is a constant number: 20 (Bachelor), 35 (Master) or 50 (Doctoral). The sum of degree score and university ranking score leads to the final education score. Note, that for scoring only the most recent university and degree are taken into account instead of previous ones. One of the reasons is that certain school types, e.g., High Schools, are not considered for university rankings which would result in 0 scoring. Eventually, candidates with multiple entries may have a couple of low (or zero) scores. An alternative would be to have a more fine-grained weighting based on duration/degree and even courses taken if available or to only consider the \u2018top\u2019 scorer. Nevertheless, the goal of the prototype is to show how external data can objectively improve judgment about education qualities."}, {"heading": "3.3. Work Experience", "text": "Our second score is for work experience that depends on duration of employment as well as on an employer score. Additionally, the more recent the employment the more this employment contributes to the work experience score. For simplification, each month of experience is worth one point.\nIt is extremely difficult to rank employers. Not only because the lack of data for each and every company out there (especially start-ups and SMEs), but also because there is not a single criteria to rank them. Moreover, how much does a ranking criteria such as \u2018revenue\u2019 or \u2018number of employees\u2019 support an individual\u2019s fit and level of experience. In order to have at least some employer \u2018quality\u2019 metric in our ranking, we relied on employer\u2019s prior selectivity on hiring. We used the training set of 800 k profiles introduced in Section 2 in order to evaluate the career progress of employees based on their current employer. Since we don\u2019t have enough data to take the complete career into account, we take the average education score of its employees as employer score. The final score is the sum of the experience points and the average of the weighted employer scores. It is limited to 100 points."}, {"heading": "3.4. Skills", "text": "The skill score is the average scores of all desired skills. To calculate a specific skill score, we match the skill to the skill set of the candidate. For each candidate skill, the distance (see Section 2) to the desired skill is calculated and\n5. For THE 100 means \u2018perfect\u2019 and for QS 100 means \u2018first\u2019\nthe skill with the shortest distance is identified. The score for this desired skill is calculated as follows:\nscore = scorematch \u2212 \u03b1 \u2217 distance (1)\nWhereas scorematch is a constant, which reflects the score for exact matching skills of distance zero. Other skills are based on distance punishment regulated by the \u03b1 parameter."}, {"heading": "4. Prototype Application", "text": "To experience the potential of our application, we built a prototype that allows for filtering, ranking, and comparison of candidates. In [8] we made a screencast available showing all major capabilities."}, {"heading": "4.1. Ranking Candidates", "text": "Candidates are assigned multiple scores as described in Section 3.1. These scores are used to sort them based on ranking in various visualizations (see Section 4.3) of candidates. Either a weighted overall ranking can be applied or a fine-grained focused ranking based on individual skills, education, or work experience."}, {"heading": "4.2. Filtering Candidates", "text": "To filter candidates, the user6 has different options (see Figure 3). One option is to filter by required degree(s). Another option is to specify the minimum number of years of work experience. Note, filtering does not affect the scoring, it just helps to reduce the pool size of candidates.\nThe user can also select any ensemble of skills to specify a desired candidate profile. Skill selection is supported by\n6. Recruiter or hiring manager\nan auto-complete list, which is based on the large corpus of 800 k profiles described in Section 2.\nNote, skill scoring and ranking relies on the cooccurrence model on our training profiles. The benefit of that is that new skills automatically appear and mapped as long as new skill profiles are added. The downside is that we may experience a slight delay of new skills being correctly mapped, because it requires some occurrences of these new skills.\nAdditionally, users can add related skills at any time and even start by using pre-defined job templates."}, {"heading": "4.3. Comparing Candidates", "text": "The tool gives the user multiple ways of displaying the candidate pool.\n4.3.1. Cards. The default way of displaying the candidates is the card view shown in Figure 4 A. Every candidate is represented by a card containing the most important aspects, such as name, score, and most recent degree.\nEach card also has a chart that shows the score broken down in the three categories (education, work experience, and skills). The user can quickly see which category a candidate excels in or falls behind. Generally, the bigger the\narea of the triangle in the chart, the better the candidate\u2019s score is relative to all other candidates.\nConvenience features, like bookmarking of candidates or direct contact options are present as well.\n4.3.2. Scores. A tabular view of scores is depicted in Figure 4 B. This view lets the user quickly evaluate how a candidate fits w.r.t. specific skills. There is a column for each of the three main categories as well as all the desired skills. To highlight the top scorers for each score, the top ten percentage is colored green. The user also has the option to sort by a specific category or skill.\n4.3.3. Score Chart. The score chart (see Figure 4 C) displays the overall skill scores and overall work experience scores of the candidates. It is ordered decreasingly by the skill scores. If two candidates have the same skill score, the candidate with the better work experience score comes first. The advantage of this view is that the user can visually compare how candidates perform in the mentioned score parts in particular. For instance, the example shows that skill fit is fairly similar for all the candidates, but the score for work experience is quite different. This helps to navigate candidate filtering by visually guiding towards distinctive dimensions."}, {"heading": "4.4. Inspecting Candidates", "text": "One of the main features of the application is to analyze and explain the match between candidate skill set and job profile requirements. On the profile page (see Figure 5), the original re\u0301sume\u0301 is embedded on the left, while the extracted information is grouped in cards on the right.\n4.4.1. Context. Hovering over an item of the extracted information cards, e.g., a skill, all occurrences of that skill are highlighted in the original re\u0301sume\u0301. This provides the user with the ability to easily validate and learn more about the context of that skill. For instance, projects or classes this skill was applied in.\n4.4.2. Related Skills - Desired Skills Card. Not only does the desired skills card visualize skill match quality for job profile skills, but each skill can also be expanded to show the top similar skills and the degree of similarity. For instance, Scilab is only a 90 % match. Since this skill is not explicitly mentioned in the re\u0301sume\u0301, contributing skills, i.e., similar skills indicate knowledge in this area and based on our skill mapping technique a matching score below 100 % can be calculated.\n4.4.3. Match - Job Scores Card. This card lists the top job profiles for this candidate based on our scoring fit measure. This is especially helpful for candidates who avoid applying for too many positions at the same time and recruiters who struggle to find the best candidate for a job. This card emphasizes if this candidate would be even a better fit for another job she has not applied for."}, {"heading": "5. Summary and next Steps", "text": "This research prototype shows how to use a data-driven approach including multiple datasources in order to guide a user in matching candidates and jobs. Using ML and NLP, it is possible to build a pipeline that first extracts all the relevant information from re\u0301sume\u0301s and provides them in a structured way. Once re\u0301sume\u0301s are processed, external data for employers and educational institutes are included as well to calculate candidate matches. Recruiters can tailor their search and filtering to specific job roles. Additionally, there are several options and dimensions to compare candidates. Eventually, the application allows for a detailed analysis of the re\u0301sume\u0301 to validate ranking and matching recommendations.\nHowever, because we developed a prototype, there are potential next steps and areas to further improve. First of all, weights to calculate scores are not optimized yet. More specifically, user research is necessary to evaluate various configurations. Secondly, in this work, we focused on extracting the most important information from re\u0301sume\u0301s. In fact, there are much more qualities to collect and to assess, e.g., awards, courses, job details, and languages. In addition, assessing career performance could be extremely beneficial. Other criteria to take into account could be costs of hiring candidates, relocation, or training to fill the gaps. When hiring people it is important to know whether they are going to fit into the team and can adapt to the corporate culture. Given all the data points that are available today, there are many more extensions of our prototype presented in this work."}, {"heading": "Acknowledgments", "text": "The authors would like to thank the team from SAP Innovation Center, Palo Alto: Frank Blechschmidt, Fredrick Chew, Pascal Crenzin, Stephan Haarmann, Michael Janke, Jaeyoon Jung, Roger Li, Bhumi Patel, Stefan Selent and Rene\u0301 Springer."}], "references": [{"title": "Don\u2019t just copy and paste: 4 things to put on LinkedIn but not your r\u00e9sum\u00e9, http://mashable.com/2016/03/27/ differences-linkedin-resume", "author": ["Erica Breuer"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "This is important, because according to Erica Breuer, tailored r\u00e9sum\u00e9s are still the most effective way to apply for a job [2].", "startOffset": 123, "endOffset": 126}], "year": 2016, "abstractText": "Recruiters usually spend less than a minute looking at each r\u00e9sum\u00e9 when deciding whether it\u2019s worth continuing the recruitment process with the candidate. Recruiters focus on keywords, and it\u2019s almost impossible to guarantee a fair process of candidate selection. The main scope of this paper is to tackle this issue by introducing a data-driven approach that shows how to process r\u00e9sum\u00e9s automatically and give recruiters more time to only examine promising candidates. Furthermore, we show how to leverage Machine Learning and Natural Language Processing in order to extract all required information from the r\u00e9sum\u00e9s. Once the information is extracted, a ranking score is calculated. The score describes how well the candidates fit based on their education, work experience and skills. Later this paper illustrates a prototype application that shows how this novel approach can increase the productivity of recruiters. The application enables them to filter and rank candidates based on predefined job descriptions. Guided by the ranking, recruiters can get deeper insights from candidate profiles and validate why and how the application ranked them. This application shows how to improve the hiring process by giving an unbiased hiring decision support.", "creator": "LaTeX with hyperref package"}}}