{"id": "1606.06274", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2016", "title": "A Data-Driven Approach for Semantic Role Labeling from Induced Grammar Structures in Language", "abstract": "semantic roles play an important role in extracting knowledge from text. current proposed unsupervised approaches can utilize features from grammar structures, thought to induce semantic expressive roles. the dependence on these grammars, \" however, makes it greatly difficult to adapt to noisy and new languages. since in pursuing this recent paper we develop a data - driven approach to identifying any semantic roles, the approach is entirely unsupervised up to the point where rules need to be poorly learned to identify the position the semantic role occurs. specifically we develop a modified - adios algorithm based generally on adios solan et al. ( 2005 ) meaning to learn grammar structures, and use these grammar structures to learn the rules for identifying precisely the semantic roles based on the context in which the grammar structures had appeared. the results obtained are comparable with demonstrating the current state - of - art models that are inherently dependent on human annotated word data.", "histories": [["v1", "Mon, 20 Jun 2016 19:53:53 GMT  (308kb,D)", "http://arxiv.org/abs/1606.06274v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["vivek datla", "david lin", "max louwerse", "abhinav vishnu"], "accepted": false, "id": "1606.06274"}, "pdf": {"name": "1606.06274.pdf", "metadata": {"source": "CRF", "title": "A Data-Driven Approach for Semantic Role Labeling from Induced Grammar Structures in Language", "authors": ["Vivek Datla", "David Lin", "Max Louwerse", "Abhinav Vishnu"], "emails": ["vivek.datla@philips.com,", "davidlin@baylor.edu,", "maxlouwerse@tilburg.edu,", "abhinav.vishnu@pnnl.gov"], "sections": [{"heading": "Introduction", "text": "For speakers and hearers to understand the meaning of the message, they need to understand the \u201cwho-did-whatto-whom\u201d, the semantic roles within a sentence. These semantic roles are used to denote the underlying relationship between various constituents of a sentence, mostly with the main predicate (verb) of the sentence. For example, in the sentence \u201cJohn kissed Mary\u201d, we denote \u201cJohn\u201d as the \u201cAgent\u201d and \u201cMary\u201d as the \u201cPatient\u201d with respect to the relation to main verb \u201ckissed\u201d.\nSemantic roles play a crucial role in a variety of NLP applications because they provide crucial information to the meaning of the individual words. The role of \u201cMary\u201d is different when Mary is a Patient (\u201cJohn kissed Mary\u201d) or an Agent (\u201cMary kissed John\u201d). Note that the syntactic Subject or Object might be different while the Agent and Patient may remain the same (e.g., \u201cJohn kissed Mary\u201d and \u201cMary was kissed by John\u201d). NLP applications in which semantic roles are frequently used include information extraction , question answering , automatic summarization , and many more.\nOne can view SRL as a two-step process: 1) Identifying the slots in a sentence that are most likely to contain the semantic roles, and 2) Selecting a specific semantic role that mostly likely fits those slots. Computationally both these problems are framed as machine learning models.\nCopyright c\u00a9 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nWhile there has been a lot of work on supervised SRL methods, supervision does have its limitations:\n\u2022 Annotating gold standard data is a slow and resource intensive process\n\u2022 Dealing with novel words or novel word combinations can create problems (\u201cI googled about pizza today\u201d); current models cannot handle mixed languages, making it easy for existing models to become obsolete item SRL models trained in one domain usually do not perform well in other domains Pradhan et al. (2005).\nExploring the effectiveness of using unsupervised learning methods for SRL is, therefore, a worthwhile exercise.\nSeveral unsupervised approaches have been developed to extract semantic roles from text (see Table 1). These studies apply methodologies to exploit the structure of the language to extract semantic roles. The structures are built using syntactic parsers built from large human annotated corpora. Similar semantic roles tend to appear in the same part of the dependency tree, and unsupervised semantic role labeling models exploit this phenomenon. However, even though these methods do not need a large corpus for role labeling, they do require (large) human annotated data for building the structures (e.g. dependency tree, part-of-speech and constituent labels) for the labeling task. The current methods for unsupervised semantic role labeling still suffer from the limitations above. Table 1 indicates the supervised, unsupervised and semi-supervised components in various parts of semantic role labeling. ar X\niv :1\n60 6.\n06 27\n4v 1\n[ cs\n.C L\n] 2\n0 Ju\nn 20\n16\nThe main goal of the current paper is to build a model that extracts semantic roles present in language using bottom-up or data-driven approaches, without the need of human annotated data for structure building. Our method starts out by learning patterns of the language using re-occurring phrases within a context. We learn more complex patterns by increasing the context on existing patterns, and we cluster the patterns into groups based on word overlap among patterns. Specialization increases the content inside patterns and generalization helps to find equivalent patterns in a given context. Since patterns are learned from language, and patterns are organized hierarchically, identifying the semantic role in one of the patterns would help us percolate the semantic information to all parents of the pattern. This organization of patterns gives us the additional advantage of needing only a relatively small training set of known semantic roles (e.g. proportional to the number of patterns) for an effective SRL model.\nFigure 1 illustrates our method. Starting with a sentence \u201cJohn is eating a pie\u201d, we build a pattern of \u201cX is Y a Z\u201d where X, Y, Z are slots that contain multiple terms that appear in sentences in our unannotated corpus that share the pattern. Here we can see the location of the agent and patient on the relation in that structure does not change. This consistency in the structure allows us to learn the semantic roles based on the patterns.\nWe modeled our pattern learning method based on a modified version of ADIOS algorithm Solan et al. (2005), one of the few algorithms that model the learning of language as bottom-up machine learning process. Following the description of the process how to create the patterns and how to use them for SRL process, we will present a computational study showing the success of our methods that do not require a large annotated corpus compared to alternative methods."}, {"heading": "Data-driving SRL procedure", "text": "Our proposed semantic role labeling model consists of\ntwo steps:\n\u2022 Extracting patterns and rules from the text: The first step is to take a unannotated corpus of text and discover common patterns and structures embedded in them. As mentioned, a pattern is not only a recurrence of statements but also adherence to a form. For example \u201cX Y a Z\u201d represents a form where the letters denote set of terms that can appear in that location. The terms may be a single word (e.g. X=John, Y=eats, Z=pie) or they can also be other patterns (e.g. Z = U made in V, where U=pie, V=France). Thus, the patterns are inherently organized to form hierarchical structures. Once we extract the patterns and struc-\ntures, they are transformed into (production) rules. These rules are then used later for the parsing of the text in the SRL task.\n\u2022 Semantic role learning/labeling: We use the rules learned to parse sentences of a given training set, generate features from the parsed sentences and use those features to train a classifier for identifying semantic roles. We use a small set of human annotated data to train the classifier.\nThe following sections present these steps in detail.\nExtracting patterns and rules via Modified ADIOS(m-ADIOS)\nTo extract patterns and structures from the text, we apply a modified version of the Automatic Distillation of Structure (ADIOS) algorithm Solan et al. (2005). The algorithm builds generative rules based on the symbolic sequential information (i.e. language input as text).\nIn the ADIOS algorithm, a corpus is represented by a directed multigraph, where each vertex denotes a word. Each sentence is represented by a path connecting these words. If a phrase (e.g. John is) appears in multiple sentences, each occurrence will contribute a separate edge between the words (hence the multi-graph). Each sentence is complemented by a \u201cbegin\u201d and an \u201cend\u201d vertex. The multigraph representation helps to identify those vertices that are thickly connected. They inherently represent the sequences that frequently appear in the corpus.\nThe algorithm iteratively picks a path (say v1, . . . , vn), and determines the part of the sentence that qualifies as a significant pattern. For each term (vi) in the path, we calculate the conditional probability that a path from v1 to vi\u22121 will continue to vi (denoted as PR(v1, vi)), and use a statistical test to detect the most significant drop in PR(v1, vi). This determines the right end of the pattern. A similar construct PL(vn, vi) \u2013 the conditional probability that sentences go from vn to vi+1 would have come from vi is used to find the left end of the pattern. Once the significant pattern is found, it is replaced by a single vertex and the graph is rewired.\nNote that the new vertex does not replace the vertices in the path, but only consolidates all the paths represented by the pattern into a vertex \u2013 for example, if v2, v3, v4 forms a significant pattern, then a vertex P is used to represent all paths that pass through the three vertices. v2, v3, v4 are not removed, if there are other alternate routes between v2, v3, v4 and other vertices. The single vertex that represents the pattern can also be looked at as a hierarchical structure. These hierarchical structures (new vertices) appear in a context. Consequently, we search through all the paths in which this vertices appear and select a significant path and generalize on the vertices that appear in the same context.\nFurthermore, a generalization process of the patterns allows for consolidation of the patterns. If two patterns differ by only one vertex, we put all vertices into one class called the Equivalence class and replace all the vertices inside the equivalence class by a single vertex.\nThese steps are repeated until all the paths are iterated and no other significant patterns are formed. The output of\nthis process consists of rules that are similar to context-free grammar(CFG) rules that will be used in subsequent steps.\nSome modifications are made to the ADIOS algorithm. First we consolidate the representation of the graph by using a simple directed graph, but with edge labels denoting the various sentence corresponds to each edge. This modification in the structure makes the graph scalable. For example, Figure 2 shows the graph built on a corpus of four sentences, John likes to run, John hates to eat, John hates to dance, and Mary hates eating.\nThe ADIOS model generalizes greedily and allows for structures with variable sizes to be represented as one structure. This leads to phrases of various sizes not occurring in the same context to be considered as one structure, there by creating unwanted ambiguity in the grammar. Our goal here is not to produce a very compact grammar but a nonambiguous grammar. We, therefore, modified the ADIOS algorithm to learn only the structures that occur within a context and have a very strict method for generalization.\nWe first create an equivalence class with all words that share the same left and right context. Then merge the equivalence class, and the respective left and right context to a single pattern. For example, in Figure 2 if \u201cJohn likes to\u201d is significant then in the context of \u201cJohn\u201d and \u201cto\u201d we find that \u201clikes\u201d and \u201chates\u201d can be merged into one equivalence class. We merge both vertices and make an implicit note in our grammar tree that make the tokens\u201clikes\u201d and \u201chates\u201d fall into the same equivalence class. Vertices \u201cJohn\u201d, \u201cequivalence class\u201d and \u201cto\u201d are then merged into a single vertex. The pattern learned from the text is shown in Figure 3.\nIt is important to note that we only replace these three vertices and two links and do not change any other vertices in the graph.\nAfter finding a significant pattern, we check if we can find equivalent middle words for the same left and right context. By finding the middle words, which share the same context, we are more likely to find words which if interchanged also form syntactically correct sentences. After finding the middle words that share the same left and right context, we put them into a group called equivalence class.\nNext, we check for the equivalence of a pattern. The\nequivalence of a pattern is defined as the maximal overlap of the pattern with the existing patterns. Since each pattern consists of a left context, a right context, and an equivalence class, we consider two patterns to be equivalent if two of the three components match.\nEvery time we find a pattern we check if we can find an equivalence of that pattern to find structures that are replaceable. We repeat the process until we have covered all the paths and can no longer find any additional significant patterns. By following the above methodology, we end up with several equivalence classes that can be made up of patterns, words or other equivalence classes. A pattern can consist of words, equivalence classes and also other patterns.\nWe also generalize the equivalent patterns if they share at least left or right context and have more than \u03c3 overlap,\ni.e. size(Ei\n\u22c2 Ej)\nsize(Ei \u22c3 Ej) \u2265 \u03c3. The algorithm 2 shows the steps followed for generalizing the equivalent classes. After finding the patterns, we consolidate all rules that we learned in the form of hierarchical structures. These hierarchical structures have the base patterns as leaf nodes, and patterns that use the base structures as parents of the base patterns and so on. As we move up the tree, we would be increasing the information in the pattern, as the size of the pattern keeps increasing as it subsumes the information from the nodes below. Even though the information increases, the nodes that are subsumed by this parent node would have the same dependency structure as the original base nodes. Since the structure is the same, identifying the semantic role slots in the base nodes would also be the slots for semantic roles in the parent nodes.\nAlgorithm 1 Build a sparse directed graph G = (V,E) where each Sentence si \u2208 C is a path\nInput: Sentences from Corpus C Output: Sparse directed graph G for each sentence si \u2208 C do\nfor each word wn \u2208 si do if wn /\u2208 G then\nadd wn to G end if if wn+1 /\u2208 G then\nadd wn+1 to G end if if An edge exists between wn and wn+1 then\nAdd sentenceID and linkID to the edge list. else\nAdd directed edge from wn \u2192 wn+1 in Graph G Add sentenceID and linkID to the edge list.\nend if end for\nend for\nAt the end of m-ADIOS, the patterns and classes take the form of a hierarchical structure. For us to use them in subsequent steps, we would derive rules from them, so that we can then parse any statement through the rules for the semantic role labeling task. Each rule contains a node of the tree on\nAlgorithm 2 Generalization of Equivalence Patterns Ei = Pi \u2192 LiEiRi Ej = Pj \u2192 LjEjRj if (Li = Lj) AND Equivalence class overlap (Ei, Ej) \u2265 \u03c3 then\nBuild new Equivalence Class Ek = Ri \u22c3 Rj Merge Equivalence Patterns Ei and Ej \u2192 Ei,j Build new Pattern Li, Ei,j , Ek \u2192 P\nend if if (Ri = Rj) AND Equivalence class overlap (Ei, Ej) \u2265 \u03c3 then\nBuild new Equivalance Class Ek = Li \u22c3 Lj Merge Equivalence Patterns Ei and Ej \u2192 Ei,j Build new Pattern Ek, Ei,j , Ri \u2192 P\nend if if (Li = Lj) AND (Ri = Rj) then\nMerge Equivalence Patterns Ei and Ej \u2192 Ei,j Build new Pattern Li, Ei,j , Ri \u2192 P\nend if\nthe left and all its children in sequential fashion on the right. Table 2 shows an example of CFG like rules created using patterns, equivalent classes, and reduced paths in the graph."}, {"heading": "Semantic role labeling", "text": "The semantic role labeling task involves learning from a corpus of sentences annotated with semantic roles. We treat each sentence as a single unit (as semantic roles relate terms from a sentence). We first parse each sentence, using the hierarchical structure rules learned from the m-ADIOS algorithm. After parsing the sentences, we locate patterns and collect contextual information around them. This information will be used as features for a classifier supporting learning and labeling purposes.\nData: Propbank We illustrate this process by using PropBank Kingsbury and Palmer (2002) as our corpus. PropBank annotated text from the Penn Treebank and the Wall Street Journal Corpus. PropBank is based on predicates, in the majority of the cases they are verbs. Each predicate has a set of arguments that is associated (from ARG0 to ARG5) associated to it. Arguments come with types such as location (LOC), temporal (TMP), manner (MNR), etc. The first two arguments, ARG0, and ARG1, are similar to prototypical agent and patient respectively. For the current purposes of the paper, we use only those sentences fewer than ten words. After filtering all 10600 sentences, we end up with 2249 sentences. The 2249 sentences from PropBank includes 4892\nunique words which occur 20148 times(on average each word occurs 4.12 times (SD= 51.05)). In the current work, we concentrate only on the agent-patient-relation. Relation represents the verb for which agent and patient are semantic roles.\nFigure 4 shows an example of an annotated sentence by PropBank, and also simplified annotation for our learning task. <arg n =\u201c0\u201d> represents an Agent present in the sentence, we identify this information using the tag \u201cAgent\u201d, <arg n=\u201c1\u201d> represents the Patient, we identify this information using the tag \u201cPatient\u201d, <arg n=\u201c2\u201d>, <arg n=\u201c3\u201d>, <arg n = \u201c4\u201d> and <arg m> represent meta tags, which add or modify information to Agent or Patient, we identify this information using the tag \u201cOther\u201d and <rel> indicates the relation or the action present in the sentence, we identify this information using the tag \u201cRelation\u201d.\nFeature extraction To annotate the data, we take each sentence of the Propbank annotated sentence, and then parse the sentences based on the rules generated in the previous step\nFor illustration purposes lets\u0301 look at the sentence \u201cJohn FedExed his package to his mother\u201d. This sentence when parsed gives us a tree shown in Figure 5. The syntactic tree using rules derived from language deviates from the parse done using Stanford parser Socher et al. (2013) (see Figure 6) which is considered a state-of-art parser. Even though it does not match the output of a standard parser, rules learned from language consistently parse similar sentences the same way. This has the advantage that - we can use the rules to train model for identifying semantic roles.\nOnce we parsed the sentence, we extract various features of the parse tree and use them as our features for the classification. The features we have used are shown in Table 3.\nTwo words before and after the pattern are used to capture the context of the pattern. Pattern labeling is analogous to the head word, words inside the pattern are analogous to the path between the semantic roles, and length of the pattern gives information about the span of the pattern. The use of surface features of the parse tree to identify semantic roles is a standard practice in several supervised and unsupervised methodologies of semantic role labeling.\nLabeling the data Since patterns and equivalent classes learned using the m-ADIOS algorithm does not have control over phrase boundaries, there are cases in which multiple semantic roles can be encompassed inside a pattern. For example, Figure 7 shows that \u201cPattern_118\u201d encodes \u201cPatient\u201d and partially encodes \u201cOther\u201d. For simplifying the task, we assume that we encapsulate the semantic role even if we encapsulate a single word inside the semantic role. So we give the label \u201cPatient_Other\u201d for \u201cPattern_118\u201d.\nIn this study we focused on identifying agent, patient and relation, we simplify our class labels by considering them as a triplet of boolean decisions. The triplet is made of \u201c<Agent, Patient, Relation>\u201d, so the class label for \u201cPattern_118\u201d would be \u201c<false,true,false>\u201d . The classification task using the above triplet \u201c<Agent, Patient, Relation>\u201d is an 8 class classification with possibility of each entity being true or false.\nBased on seven features shown in Table 3, and the class label given to each instance of the patterns, we do a classification via a 10-fold cross validation using Bayes, Naive Bayes, and Random Forest classifiers using Weka Hall et al. (2009)."}, {"heading": "Summary of Dataset Creation", "text": "To test the performance of m-ADIOS in the generating structure which encodes semantic roles, we use sentences in PropBank and parsed sentences obtained after parsing sentences using rules learned from the language. Let us look at the example closely, the sentence \u201cjohn fedexed his package to his mother\u201d, is parsed using the rules generated from the PropBank corpus. After parsing, we end up with a tree like structure, which is represented using a bracketing scheme.\nFigure 5 shows tree representation of the same bracketing scheme. Figure 6 represents the structure using the Stanford parser. We can observe that patterns take the role of \u201chead\u201d similar to that of Noun Phrase (\u201cNP\u201d), Verb Phrase (\u201cVP\u201d) etc. Patterns learnt from the grammar rules do not have correct phrase boundaries in contrast to the strict adherence to phrase boundaries in traditional parsers (Figure 6).\nSince PropBank follows strict phrase boundaries, which adheres to Penn-tree bank annotations, our patterns transgress the defined phrase boundaries. As a result of these transgressions we some times have more than one role inside the pattern.\nIn step 3 in the Figure 7 we capture the semantic roles encapsulated by the patterns. Here we can see that \u201cPattern_118\u201d encodes \u201cPatient\u201d and partially encodes \u201cOther.\u201d For simplifying the task, we assume that we encapsulate the semantic role even if we encapsulate a single word inside the semantic role. So we give the label \u201cPatient_Other\u201d for \u201cPattern_118\u201d.\nWe perform these four steps on all the sentences for which we have learned rules using the m-ADIOS. The classification task using the above triplet \u201c<Agent, Patient, Relation>\u201d is an 8 class classification with a possibility of each entity being true or false. To summarize, given a pattern we would predict whether it encodes an agent or a patient or a relation or any combination of them."}, {"heading": "Results and Discussion", "text": "Based on the 7 features shown in Table 3, and the class label given to each instance of the patterns following Section , we did a classification via a 10-fold cross validation using Bayes, Naive Bayes and Random Forest models. We report all the results using the measures precision P = No. of correct constituents identifiedToal no. of constituents identified ; recall R = No. of correct constituents identified\nTotal no. of correct constituents ; f-measure F = 2\u00d7PR P+R and inter-rater reliability using Cohens\u0301 kappa K. Table 4 shows the classification results. As expected the accuracy is reasonably high given that the chance of finding the correct tag is only 0.125. The classification is done with a great amount of confidence as well (k > 0.6). These can be attributed to the sparsity in the patterns obtained from the language.\nSemantic roles are defined by order and kind of words present in the sentence, gave us the motivation to explore\nthe distributional information around the words, and hierarchical relations among them. We further developed the m-ADIOS algorithm inspired from ADIOS Solan et al. (2005). In the m-ADIOS algorithm, the structural information learned is strictly dependent on the left and the right context in which words appear. We generalized this by assuming that only when two patterns have a perfect overlap on the right and left context or when there is a match with a left or right context of the two patterns and a significant overlap in their equivalent structures thereby reducing the ambiguity in the grammar.\nLang and Lapata (2010, 2011) used dependency trees from PropBank to extract features like predicate-lemma, argument-lemma, argument part-of-speech, and part-ofspeech of left and rightmost child of argument to cluster the semantic roles in the sentences. Table 5 shows the baseline accuracies of current state-of-art unsupervised srl models. Even though their accuracy is high, their latent dependence of human annotated data dependency parsers, part-of-speech taggers makes it pseudo-unsupervised. Several other unsupervised models of semantic role labeling (see Table 1) also share the same issues.\nOur results show that we can learn structure from language, in a data-driven fashion, and with little training we were able to identify the presence and absence of semantic roles. Even though the precision and recall scores may be lower when compared to existing unsupervised models, by not being dependent on human annotated data the proposed method would help to identify semantic roles for languages for which syntactic parsers developed from human annotated data are unavailable."}, {"heading": "Future Work", "text": "The strict generalization in our model allows patterns that share a strong overlap in their context to be termed equivalent. After learning the rules, we convert them to grammar rules and parse the sentences from which we have learned the rules. In theory, these rules can be extended to any other sentences, which have the same words. But in practice this becomes a major drawback as we have the problem of sparsity simply because many words can occur in different contexts, and the order they appear in makes a big difference on the forming of patterns. To overcome this problem we plan to the method used by Datla, Lin, and Louwerse (2014) to induce pseudo parts of speech, and learn structures based on\nthe induces parts of speech. In future we would like to extend our model for other languages, and also to the languages that are resource constraint."}], "references": [{"title": "Unsupervised argument identification for semantic role labeling", "author": ["O. Abend", "R. Reichart", "A. Rappoport"], "venue": "Proceedings of the IJCNLP, ACL \u201909, 28\u201336. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Abend et al\\.,? 2009", "shortCiteRegEx": "Abend et al\\.", "year": 2009}, {"title": "Part of speech induction from distributional features: Balancing vocabulary and context", "author": ["V.V. Datla", "K.-I. Lin", "M.M. Louwerse"], "venue": "Proceedings of the FLAIRS.", "citeRegEx": "Datla et al\\.,? 2014", "shortCiteRegEx": "Datla et al\\.", "year": 2014}, {"title": "Unsupervised semantic role induction with global role ordering", "author": ["N. Garg", "J. Henderson"], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL \u201912, 145\u2013149. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Garg and Henderson,? 2012", "shortCiteRegEx": "Garg and Henderson", "year": 2012}, {"title": "Unsupervised discovery of a statistical verb lexicon", "author": ["T. Grenager", "C.D. Manning"], "venue": "Proceedings of EMNLP, EMNLP \u201906, 1\u20138. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Grenager and Manning,? 2006", "shortCiteRegEx": "Grenager and Manning", "year": 2006}, {"title": "The weka data mining software: An update", "author": ["M. Hall", "E. Frank", "G. Holmes", "B. Pfahringer", "P. Reutemann", "I.H. Witten"], "venue": "SIGKDD Explor. Newsl. 11(1):10\u201318.", "citeRegEx": "Hall et al\\.,? 2009", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "From treebank to propbank", "author": ["P. Kingsbury", "M. Palmer"], "venue": "Proceedings of LREC.", "citeRegEx": "Kingsbury and Palmer,? 2002", "shortCiteRegEx": "Kingsbury and Palmer", "year": 2002}, {"title": "Unsupervised induction of semantic roles", "author": ["J. Lang", "M. Lapata"], "venue": "Proceedings of ACL-HLT, 939\u2013947. ACL.", "citeRegEx": "Lang and Lapata,? 2010", "shortCiteRegEx": "Lang and Lapata", "year": 2010}, {"title": "Unsupervised semantic role induction via split-merge clustering", "author": ["J. Lang", "M. Lapata"], "venue": "Proceedings of the ACL-HLT, HLT \u201911, 1117\u20131126. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Lang and Lapata,? 2011", "shortCiteRegEx": "Lang and Lapata", "year": 2011}, {"title": "Unsupervised induction of frame-semantic representations", "author": ["A. Modi", "I. Titov", "A. Klementiev"], "venue": "Proceedings of NAACL-HLT, WILS \u201912, 1\u20137. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Modi et al\\.,? 2012", "shortCiteRegEx": "Modi et al\\.", "year": 2012}, {"title": "Support vector learning for semantic argument classification", "author": ["S. Pradhan", "K. Hacioglu", "V. Krugler", "W. Ward", "J.H. Martin", "D. Jurafsky"], "venue": "Mach. Learn. 60(13):11\u201339.", "citeRegEx": "Pradhan et al\\.,? 2005", "shortCiteRegEx": "Pradhan et al\\.", "year": 2005}, {"title": "Parsing with compositional vector grammars", "author": ["R. Socher", "J. Bauer", "C.D. Manning", "N. Andrew Y."], "venue": "Proceedings of ACL, 455\u2013465. Sofia, Bulgaria: ACL.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Unsupervised learning of natural languages", "author": ["Z. Solan", "D. Horn", "E. Ruppin", "S. Edelman"], "venue": "Proceedings of the National Academy of Sciences of the United States of America 102(33):11629\u201311634.", "citeRegEx": "Solan et al\\.,? 2005", "shortCiteRegEx": "Solan et al\\.", "year": 2005}, {"title": "A bayesian model for unsupervised semantic parsing", "author": ["I. Titov", "A. Klementiev"], "venue": "Proceedings of ACLHLT, HLT \u201911, 1445\u20131455. Stroudsburg, PA, USA: ACL.", "citeRegEx": "Titov and Klementiev,? 2011", "shortCiteRegEx": "Titov and Klementiev", "year": 2011}], "referenceMentions": [{"referenceID": 11, "context": "algorithm based on ADIOS Solan et al. (2005) to learn gram-", "startOffset": 25, "endOffset": 45}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 72}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 108}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 141}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 172}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 215}, {"referenceID": 2, "context": "Abend, Reichart, and Rappoport (2009) Y Y Y N Garg and Henderson (2012) Y Y Y N Grenager and Manning (2006) Y Y Yp Yp Lang and Lapata (2010) Y Y Y N Lang and Lapata (2011) Y Y Y N Modi, Titov, and Klementiev (2012) Y Y Y N Titov and Klementiev (2011) Y Y Y N our method N N Yp Yp", "startOffset": 46, "endOffset": 251}, {"referenceID": 9, "context": "\u2022 Dealing with novel words or novel word combinations can create problems (\u201cI googled about pizza today\u201d); current models cannot handle mixed languages, making it easy for existing models to become obsolete item SRL models trained in one domain usually do not perform well in other domains Pradhan et al. (2005).", "startOffset": 290, "endOffset": 312}, {"referenceID": 11, "context": "We modeled our pattern learning method based on a modified version of ADIOS algorithm Solan et al. (2005), one of the few algorithms that model the learning of language as bottom-up machine learning process.", "startOffset": 86, "endOffset": 106}, {"referenceID": 11, "context": "To extract patterns and structures from the text, we apply a modified version of the Automatic Distillation of Structure (ADIOS) algorithm Solan et al. (2005). The algorithm builds generative rules based on the symbolic sequential information (i.", "startOffset": 139, "endOffset": 159}, {"referenceID": 5, "context": "Data: Propbank We illustrate this process by using PropBank Kingsbury and Palmer (2002) as our corpus.", "startOffset": 60, "endOffset": 88}, {"referenceID": 10, "context": "The syntactic tree using rules derived from language deviates from the parse done using Stanford parser Socher et al. (2013) (see Figure 6) which is considered a state-of-art parser.", "startOffset": 104, "endOffset": 125}, {"referenceID": 4, "context": "Based on seven features shown in Table 3, and the class label given to each instance of the patterns, we do a classification via a 10-fold cross validation using Bayes, Naive Bayes, and Random Forest classifiers using Weka Hall et al. (2009).", "startOffset": 223, "endOffset": 242}, {"referenceID": 9, "context": "We further developed the m-ADIOS algorithm inspired from ADIOS Solan et al. (2005). In the m-ADIOS algorithm, the structural information learned is strictly dependent on the left and the right context in which words appear.", "startOffset": 63, "endOffset": 83}], "year": 2016, "abstractText": "Semantic roles play an important role in extracting knowledge from text. Current unsupervised approaches utilize features from grammar structures, to induce semantic roles. The dependence on these grammars, however, makes it difficult to adapt to noisy and new languages. In this paper we develop a data-driven approach to identifying semantic roles, the approach is entirely unsupervised up to the point where rules need to be learned to identify the position the semantic role occurs. Specifically we develop a modified-ADIOS algorithm based on ADIOS Solan et al. (2005) to learn grammar structures, and use these grammar structures to learn the rules for identifying the semantic roles based on the context in which the grammar structures appeared. The results obtained are comparable with the current state-of-art models that are inherently dependent on human annotated data.", "creator": "LaTeX with hyperref package"}}}