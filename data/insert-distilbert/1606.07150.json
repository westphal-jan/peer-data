{"id": "1606.07150", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2016", "title": "Adaptive and Scalable Android Malware Detection through Online Learning", "abstract": "it is well - known that malware worm constantly evolves so as to evade detection and even this causes the entire malware population to be automatically non - stationary. contrary to this fact, prior works on machine learning tree based robust android malware detection have assumed that the distribution of the observed malware characteristics ( i. e., features ) do surely not change over time. in this work, we address the functional problem of malware population drift and propose a whole novel online machine learning based framework, named global droidol to handle it and subsequently effectively detect malware. perhaps in order to perform accurate detection, security - sensitive behaviors are captured from apps in the form of inter - procedural automatic control - flow sub - graph features using a state - of - the - art graph kernel. in order to perform scalable detection and to permanently adapt to the drift and propagation evolution in malware population, an online native passive - aggressive classifier proxy is normally used.", "histories": [["v1", "Thu, 23 Jun 2016 01:08:10 GMT  (264kb,D)", "https://arxiv.org/abs/1606.07150v1", null], ["v2", "Mon, 26 Sep 2016 10:07:11 GMT  (264kb,D)", "http://arxiv.org/abs/1606.07150v2", null]], "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["annamalai narayanan", "liu yang", "lihui chen", "liu jinliang"], "accepted": false, "id": "1606.07150"}, "pdf": {"name": "1606.07150.pdf", "metadata": {"source": "CRF", "title": "Adaptive and Scalable Android Malware Detection through Online Learning", "authors": ["Annamalai Narayanan", "Liu Yang", "Lihui Chen"], "emails": ["annamala002@e.ntu.edu.sg,", "elhchen}@ntu.edu.sg,", "liuj0081@e.ntu.edu.sg"], "sections": [{"heading": null, "text": "In a large-scale comparative analysis with more than 87,000 apps, DroidOL achieves 84.29% accuracy outperforming two state-of-the-art malware techniques by more than 20% in their typical batch learning setting and more than 3% when they are continuously re-trained. Our experimental findings strongly indicate that online learning based approaches are highly suitable for real-world malware detection.\nkeywords \u2014 Online Learning, Graph Kernels, Malware Detection\nI. INTRODUCTION Recently, malware detection for mobile platforms such Android has evolved as one of the challenging problems in the field of cyber-security. The number of new Android malware applications (apps for short) and their capabilities have grown tremendously in recent years. For instance, Kaspersky reports [1] detecting 4 million malware infections in 2015 which is a 216% increase over 2014. The sheer volume and growth rate of Android malware highlights an imperative need for developing sound and scalable automated malware detection process [2]\u2013[7, 12].\nMalware detection using Machine Learning (ML) techniques is predominant in various platforms (such as Windows, Android and the web) for more than a decade [2]\u2013[7, 12]. This is because, these methods automatically learn the characteristics that distinguish malware, when trained using a collection of malware and benign samples making them amenable for automated detection. ML based approaches extract features from an apps\u2019 behaviors and apply standard ML algorithms to perform binary classification. These approaches typically use semantic features such as system calls/Application Programming Interfaces (APIs) invoked, resources and privileges used, control- and data-flows inside apps\u2019 execution to detect malicious behavior patterns [2]\u2013[7, 12].\nMost of these malware detection techniques are based on batch-learning classifiers. Meaning, the detection model is\nbuilt using a batch of labelled benign and malware samples and is subsequently used to predict whether a given new sample is benign or malicious. These batch-learning based methods are typically plagued by two challenges that make them unsuitable for real-world large-scale malware detection: \u2022 Population drift. Though batch-learning based solutions\nare promising, their success is predicated on an important assumption that may not hold for the malware detection problem. That is, they assume that the malware population (i.e., training data) used to build the detection model does not change over time. However, malware does not fit this profile. The entire population of malware is constantly evolving due to various reasons such as exploiting new vulnerabilities, and evading novel detection techniques. This evolution has a profound impact on malware characteristics and thereby on malware features. This makes the collection of malware identified today not a representative of the ones generated in the future. This phenomenon is an epitome of population drift [17]. Since new malware features emerge and importances of features change over time, this population drift leads to concept drift [17, 18]. \u2022 Volume. As noted before, malware grows at an alarming rate and hence a scalable classifier is of paramount importance to practical large-scale malware detection. In order to keep abreast with drifting population, batch learners have to be frequently re-trained with huge volumes of data. Hence they pose severe scalability issues when used in the Android malware detection context where we have millions of samples already and thousands streaming in every day. Retraining frequently with such a volume renders them computationally impractical. Our Approach. We take these two challenges into consideration and propose DroidOL, an accurate, adaptive and scalable malware detection framework based on online learning, where we continuously retrain the model upon receiving each labeled sample and make prediction of a new sample using the updated model. We demonstrate that online learning based solutions are better suited for practical large-scale automated malware detection for two reasons: \u2022 The detection model needs to adapt to changes in malware\nfeatures over time, automatically. \u2022 Online learning based solution can process large numbers\nof apps more efficiently than batch methods. DroidOL\u2019s achieves superior accuracy through extracting high quality features from inter-procedural control-flow graphs (ICFGs) of apps, which are known to be robust against evasion\nar X\niv :1\n60 6.\n07 15\n0v 2\n[ cs\n.C R\n] 2\n6 Se\np 20\n16\nand obfuscation techniques adopted by malware [2, 5]. To this end, we use the Weisfeiler-Lehman (WL) graph kernel [13] that supports explicit feature vector representation of graphs to extract semantic features from ICFGs. DroidOL\u2019s adaptiveness and scalability are achieved through use of online learning.\nHence, the primary contribution of our paper is the successful application of online learning algorithms to the problem of Android malware detection. To the best of our knowledge, we are the first to propose such a framework and demonstrate its capabilities to handle population drift.\nExperiments. DroidOL is evaluated through large-scale experiments on a recent real-world dataset of more than 87,000 apps. It is compared against two state-of-the-art batch-learning based Android malware detection techniques. DroidOL achieves 84.29% accuracy outperforming state-ofthe-art techniques by more than 24% in their typical batchlearning and more than 3% when they are re-trained. Subsequently, we show that continuous retraining over newly emerging features is crucial for adapting the detection model to detect new or evolving malware.\nIn summary, our paper\u2019s contributions are as follows: \u2022 We propose and develop DroidOL, an accurate, scalable and\nadaptive Android malware detection framework which is based on online learning, where we do not assume that the malware population is stationary (in \u00a7III). \u2022 We conduct and report a large-scale comparative analysis of our framework against several re-trained variants of two state-of-the-art malware detection solutions on a sizable dataset of more than 87,000 apps (in \u00a7VI and VII). The paper is organized as follows. We begin by discussing the related works on malware detection and also present our motivations in \u00a7II. The DroidOL framework is introduced in \u00a7III. Implementation details are discussed in \u00a7IV. DroidOL\u2019s evaluation, comparative analysis and relevant discussions are presented in sections V, VI and VII. Conclusions are presented in section VIII."}, {"heading": "II. RELATED WORK & MOTIVATION", "text": "ML based approaches are popular over the past decade for malware detection. Many existing works have successfully applied ML techniques for malware detection on various platforms such as Windows, Android and the web."}, {"heading": "A. Related Work - Android Malware Detection", "text": "1) Primitive Approaches: In the case of Android, Crowdroid [11], Drebin [4] and DroidAPIMiner [8] are noticeable among the early approaches on ML based malware detection. These methods were designed to detect malware operating on the initial versions of Android, performing simpler attacks such as making premium-rated calls/SMS. Hence, they leveraged on primitive features such as system calls, Android APIs and permissions. These techniques detect malware through identifying suspicious usage patterns of the aforesaid features. In particular, Crowdroid [11] uses Linux system call sequences as features. Drebin [4] uses APIs, permissions, components, accessed URLs and Intent filters as features. DroidAPIMiner [8] considers sensitive APIs along with parameters and package level information as features. Even though these features are good enough for detecting simpler malware, they are easily\nevaded by modern malware that perform sophisticated attacks [7, 9].\n2) Robust Approaches: In order to detect stealthy malware, recent approaches leverage on two type of detection: (1) information-flow based detection and (2) graph based structural detection.\nInformation-flow based detection. These methods track the flow of sensitive information inside the apps\u2019 execution and detect malware by spotting suspicious flows. Even though these methods are highly precise, they exhibit poor scalability due to the expensive data-flow analysis they leverage on. Hence such methods are not suitable for practical large-scale malware detection [3, 4]. Mudflow [10], is a prototypical example of these types of detection methods.\nGraph based structural detection. Graphs offer a natural way to model the sequence of activities that take place in a program. Hence they serve as amenable data-structures for detecting malware through identifying suspicious activity sequences. For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12]. In the case of Android, DroidMiner [9] and Allix et al. [5] proposed to use control-flow graph based features to perform structural malware detection. DroidSIFT [7] and AppContext [2] proposed a more robust approach by including the contextual information of security-sensitive activities (i.e., whether or not the user is aware of such an activity) along with structural information captured through graphs.\nThese solutions are plagued by two limitations: (1) Loss of expressiveness: These solutions follow a na\u0131\u0308ve approach to vectorise the graphs such as taking only individual nodes into consideration without their neighborhood. This leads to loosing the expressiveness of graphs. (2) Poor efficiency: Many classic graph mining based approaches (e.g., [12]) are NP hard and have severe scalability issues, making them impractical for real-world malware detection [3].\nGraph Kernels for malware detection. Recently, efficient and expressive graph kernels such as WL kernel [13] have been proposed and widely adopted in many application areas (e.g, bio- and chemo-informatics, computer vision, etc.). Some of these kernels also support building explicit feature vector representations of graphs. Taking notice of such a development, two approaches, Adagio [3] and Sahs et al. [6] used graph kernels to perform structural detection of Android malware."}, {"heading": "B. Motivation", "text": "While all the above mentioned works focus on engineering robust features that can detect malware effectively, they do not address a key practical aspect of malware detection problem\u2014malware evolution. As discussed in \u00a7I, many analytical studies such as [17, 21] have clearly highlighted that malware evolves in terms of its characteristics for various reasons. The evolution inevitably leads to profound changes in the malware features over time i.e., concept drift. This poses two challenges: (C1) the detection model has to automatically adapt to the\nExplanation\nSignificant Features\nconcept drift. (C2) the detection model has to consider and account for new features that emerge over time.\nMalware detection as a data-stream classification problem. While none of the existing Android malware detection techniques address this concept drift, we get a clear motivation to do so. While all the existing works consider malware detection as a static classification problem with a fixed training and test set, we note that this is against the real-world situation. Hence, we model it as a data stream classification problem. As for the two aforementioned challenges, we address the first challenge (C1) through the use of an online learning classifier which adapts itself to the drift in characteristics of samples that stream in and for the second challenge (C2), we use a dynamic feature space, where the number of features keeps growing over time (see \u00a7VI-C for a detailed explanation).\nWhile we note that there a few approaches in the past that have adopted online learning to tackle concept drift in malware for other platforms such as Windows [20], we are the first to do so for Android.\nFeatures. As discussed in the previous subsection II-A, graph based features have been proven effective and robust to several evasion strategies followed by malware and hence we use them. While choosing a particular graph representation, we note that building data-flow and data-dependency graphs is not scalable and call-graphs are too coarse-grained to capture the program semantics perfectly. Hence, we use ICFG representation as they efficiently capture finer program semantics.\nGraph Kernel. Since WL graph kernel [13] is the current state-of-the-art graph kernel, known for its expressiveness and efficiency, we use it to extract semantic features from ICFGs."}, {"heading": "III. DROIDOL - FRAMEWORK OVERVIEW", "text": "The overview of DroidOL framework which performs accurate, adaptive and scalable malware detection using online learning is presented in Fig. 1. DroidOL has three phases. We begin by performing static analysis on a given set of apps to get their ICFG representations. Subsequently, ICFG subgraph features are extracted using the WL kernel and the apps are represented as feature vectors. Finally, an online PA classifier is trained with these vectors to detect malware. Each of the phases is described in detail below. 1) Abstraction. Our malware detection approach considers\nnode-labeled ICFG sub-graphs as features. To extract these features, we first perform Android-specific static analysis to transform all the apps into their corresponding ICFG\nAlgorithm 1 WL kernel \u2014 extracting vocabulary for feature vector representation of ICFGs Input: G = {ICFG1, ICFG2, ..., ICFGK}: A set of K ICFGs (one for each of the K apps in the dataset.) h: Degree of neighborhood to be considered for label enrichment Output: \u03a3: Vocabulary of sub-graph features present across all graphs in G\n1: procedure EXTRACT VOCAB(G, h) 2: \u03a3\u2190 \u03c6 3: for ICFG = (N,E, \u03bb0) \u2208 G do 4: for i = 0 to h do 5: for n \u2208 N do 6: if i = 0 then 7: \u03bb0(n)\u2190 \u03bb(n) 8: else 9: N (n)\u2190 {m | (n,m) \u2208 E}\n10: Mi(n)\u2190 {\u03bbi\u22121(m) | m \u2208 N (n)} 11: \u03bbi(n)\u2190 \u03bbi\u22121(n)\u2295 sort(Mi(n)) 12: end if 13: \u03a3\u2190 \u03a3 \u222a \u03bbi(n) 14: end for 15: end for 16: end for 17: return \u03a3 18: end procedure\nrepresentations. Subsequently, the ICFG nodes are labeled with security sensitive APIs1 that they access. Formally, ICFG = (N,E, \u03bb) is a directed graph where N is a set of nodes and each node n \u2208 N denotes an instruction in the disassembled format. E \u2286 (N \u00d7N) is a set of edges and each edge e(n1, n2) \u2208 E denotes the control-flow from n1 to n2. \u03bb is the set of security-sensitive Android APIs and ` : N \u2192 \u03bb, is a labeling function which assigns an API as label to each node. 2) Feature Extraction & Representation. Once the ICFGs are constructed, (rooted) sub-graphs in these ICFGs that represent the security-sensitive behaviors in every app are extracted using the WL graph kernel [13]. Subsequently, ICFGs are represented as feature vectors. WL kernel. The WL kernel works by augmenting the labels of every node n with its neighborhood (up to a certain degree) in a given graph, G. The frequency of these enriched node labels which denote sub-graphs around every node in G are used as features to facilitate an explicit feature vector representation of G. Thus the process of obtaining feature vector representation of ICFGs in our dataset using WL kernel involves two steps: (1) Building a vocabulary, \u03a3 of sub-graph features present across all ICFGs, (2) Transforming every ICFG into a feature vector with |\u03a3| dimensions. Step (1) is presented in detail in Algorithm 1. Algorithm Explanation. The inputs to Algorithm 1 are G, a set of K ICFGs (one for each of the K apps in the dataset) and h, the degree of sub-graphs to be considered for feature extraction. The output is a vocabulary set \u03a3 that contains the unique sub-graphs upto degree h present 1PScout [19], an existing research work identifies and lists the securitysensitive Android APIs. These APIs are used for labeling our ICFG nodes.\nacross all ICFGs in G. In each iteration i of the algorithm (lines 4 to 15), the neighborhood up to degree i around a node n is captured and condensed in the form of a neighborhood label, \u03bbi(n). These neighborhood label is what we refer to as sub-graph features. For every ICFGk \u2208 G, the following process is adopted to obtain these neighborhood labels. For the initial iteration i = 0 no neighborhood information needs to be considered. Hence the neighborhood label \u03bb0(n) is same as the original node label \u03bb(n) (line 7). For i > 0, the following procedure is used for label enrichment: Firstly, for a node n \u2208 N , all of its neighboring nodes are obtained and stored in N (n) (line 9). For each node m \u2208 N (n) the neighborhood label up to degree i \u2212 1 is obtained and stored in multiset Mi(n) (line 10). Subsequently, \u03bbi\u22121(n), neighborhood label of n till degree i\u22121 is concatenated to the sorted value of Mi(n) to obtain the current neighborhood label, \u03bbi(n) (line 11). Finally, the neighborhood label \u03bbi(n) representing the ith degree neighborhood around n is added to the vocabulary of subgraph features \u03a3 (line 13). Once the vocabulary \u03a3 is obtained, we transform every ICFG \u2208 G into its corresponding vector representation by counting the frequency of every feature from \u03a3 in ICFGk. This procedure falls under the well-known Bagof-Features (BoF) representation model [13], where every ICFG is considered as a bag of sub-graphs. 3) Online Learning. Once the feature vectors of all the apps in the training-set are built, we train an online PA classifier with these vectors to detect malware. PA classifier\u2019s training and update procedures are as explained below with relevant notations. Denote the features of an app (both benign and malware) as a vector x = [x(1), x(2), ..., x(d)]T , and its label as y \u2208 {\u22121,+1}, where \u22121 indicates benign and +1 indicates malicious apps. The PA classifier receives a number of samples, xi, and their labels, yi, and trains using this labeled data. Given a new unseen sample, x, the goal of PA classifier is to predict the label, y, of this new sample based on its trained model. PA being a linear classifier fits a linear decision boundary (i.e., hyperplane) between the positive and negative class samples. That is, the model is a weight vector, w = [w(1), w(2), ..., w(d)]T which indicates the weight (i.e. relative importance) of each of the features used to predict the output label y. The predicted label, y\u0302, is the sign of the inner product between x and w:\ny\u0302 = sign(x \u00b7 w) (1)\nPA incrementally build the models in rounds. In round t, PA receives a sample, xt and predicts its label y\u0302t using the current model; it then receives yt, the true label of xt and updates its model based on the sample-label pair: (xt, yt), if it makes a wrong prediction. That is, w is updated if the predicted label, y\u0302t and the true label, yt of the sample xt are not the same. The goal of the PA algorithm is to update the model w as minimal as possible to correct for any mistakes it commits. PA solves the following optimization with each\ngiven sample:\nwt+1 \u2190 argmin w\n1 2 ||wt \u2212 w||2 (2)\nsubject to yi(w \u00b7 xt) \u2265 1 Updates occur only when yt(wt \u00b7xt) < 1., The closed-form update for all samples is as follows:\nwt+1 \u2190 wt + \u03b1tytxt (3)\nwhere \u03b1t = max{ 1\u2212yt(wt\u00b7xt)||xt||2 , 0} (we refer the reader to the original work at [15] for this derivation and further details on PA algorithm). Once the PA classifier in DroidOL is trained with all these samples it is ready to perform malware detection at scale. It is important to note that since DroidOL is trained in an online fashion, it performs malware detection and simultaneously adapts to the changing trends in malware features by retraining on every sample it misclassifies. Alternatives. As practitioners involved in building an online malware detection framework, we do not have any vested interest in a particular algorithm for online learning. Ultimately, we wish to determine the algorithm that scales well to problems of our size and yields the best performance. To that end, we experimented with other well-known online learning algorithms such as Online Perceptron (OP) and Stochastic Gradient Descent learning based Logistic Regression (LRSGD) along with PA. Since PA offered the best results in terms of accuracy, it is used in DroidOL. We believe this is because OP and LRSGD do not imbibe the notion of classification confidence and treat all misclassifications equally, unlike PA. PA, on the other hand, updates more aggressively when the margin of error is large and less aggressively in when it is small. While we note that evolving classifiers such as pClass [22] could be used for handling concept drift, we prefer PA over such methods, as it offers better efficiency.\nIV. IMPLEMENTATION & COMPARATIVE ANALYSIS\nWe implemented the DroidOL framework in approximately 15,600 lines of Python and Java code. Soot2, a popular Android static analysis workbench is used for constructing the ICFGs of the apps in our dataset. Scikit-learn3 toolbox is used for all our ML functionalities.\nWe compare our online learning based detection against two state-of-the-art Android malware detection solutions, namely Drebin [4] and Allix et. al.\u2019s [5]. It is noted that both these methods use batch learning classifiers.\nDrebin [4] is well-known for its scalable and explainable detection. It extracts light-weight features such as APIs, permissions, URLs accessed, names of components from apps and subsequently, trains a linear SVM classifier to distinguish malware from benign apps.\nAllix et al. [5] recently proposed another scalable approach using structural features, namely CFG signatures. Therefore, we refer to this technique as CFG-Signature Based Detection (CSBD) in the reminder of the paper. CSBD constructs CFGs of individual methods and encodes them as text-signatures.\n2http://sable.github.io/soot 3http://scikit-learn.org"}, {"heading": "13, 2014", "text": "Subsequently, a Random Forest classifier is trained with these signatures to detect malware."}, {"heading": "V. DATA COLLECTION", "text": "We evaluate our approach on a recent large-scale realworld dataset of 87,257 apps collected in-the-wild. These apps are collected from seven different Android markets4, namely, Google Play, Anzhi, AppChina, SlideMe, HiApk, FDroid and Angeeks, in 2014. Following the common practice in software security research, we use the Virus Total5 web portal which hosts malware detection services from more than 40 Anti-virus scanners to determine the ground-truth labels of the apps. We infer that dataset contained 44,347 benign and 42,910 malware apps. The composition of the dataset is presented in Table I. It is noted that this is a subset of a large collection of apps used in [23].\nThe date of creation of these apps fall in a span of 224 days starting from 1 Jan\u201914 to 13 Aug\u201914. We intend to sort these apps according to their date of creation and emulate a live feed of apps to the malware detectors considered in our experiments to examine how they cope up with the drift in the malware characteristics over time. To this end, we divide all the apps in the dataset (both benign and malware) into batches according to their date of creation. Hence we have 224 batches, one for each day. The resulting time-line based distribution of the two datasets are presented in Fig. 2."}, {"heading": "VI. EVALUATION", "text": "In this section, we evaluate DroidOL\u2019s accuracy and adaptiveness using the emulated live feed of apps. To this end, we 4Google Play: https://play.google.com/store, Anzhi: www.anzhi.com, AppChina: www.appchina.com, SlideMe: www.SlideME.org, HiApk: www.hiapk.com, FDroid: www.fdroid.org and Angeeks: http://apk.angeeks.com\n5https://www.virustotal.com/\naddress the following questions: (1) Does DroidOL\u2019s online learning provide any benefit over batch learning for malware detection? (2) How does DroidOL\u2019s accuracy compare to light-weight state-of-the-art malware detection techniques? (3) Is there a particular training regimen that fully realizes the potential of online classifier?"}, {"heading": "A. Advantages of Online Learning", "text": "We start by evaluating the benefit of using online over batch learning for the problem of malware detection in terms of detection accuracy \u2014 in particular, whether the benefit of DroidOL\u2019s efficiency comes at the expense of accuracy. Specifically, we compare DroidOL\u2019s PA based classification against four different training configurations of a canonical batch learning classifier. We used Linear SVM as our canonical batch learner. It is noted that evaluations with other batch algorithms such as logistic regression yielded similar results.\nBatch Learning Configurations. For SVM, we experiment with the following variants: SVM-Once, SVM-Daily, SVMMultiOnce, and SVM-MultiDaily. For SVM-Once, SVM classifier is trained only once on the apps from Day 1 (1 Jan\u201914). This model is tested on all other days without retaining. For SVM-Daily, the classifier is retrained after every day; however, only one previous day\u2019s samples are used for every retraining \u2014 e.g., 11 Jan\u201914 results reflect training on the apps created on 10 Jan\u201914, and testing on 11 Jan\u201914 apps. SVM-MultiOnce is similar to SVM-Once and SVM-MultiDaily is similar to SVM-Daily, however, with the size of the batch for training and retraining covers 10 days instead of 1. In summary, for Once and MultiOnce variants, the model is never re-trained and for Daily and Multi-Daily, the model is re-trained in a sliding window fashion over the batches of data. The size of MultiDaily training sets is determined to be 10-day batches based on the data that our evaluation machine with 32 GB RAM can handle.\nFigs. 3 (a) shows the cumulative error rates of DroidOL in comparison to the aforementioned variants of SVM. The following observations are made from Fig. 3 (a):\n\u2022 Updating the detection models over time is essential to detect new malware as shown by SVM-MultiDaily and SVM-Daily outperforming SVM-MultiOnce and SVMOnce, respectively. \u2022 Training on significantly more data improves the performance, as illustrated by SVM-MultiDaily and SVMMultiOnce outperforming SVM-Daily and SVM-Once, respectively. However, it is noted that there is a fundamental limit on the amount of data a batch-learning technique could train on because of the storage, memory and time requirements. \u2022 Third, DroidOL consistently outperforms all the batch learnt variants. In particular, it outperforms the best retrained variant of SVM by more than 4% cumulative error rate. This is because DroidOL is able to adapt to the changes in the malware characteristics instantaneously as well as retain significantly useful information from the past."}, {"heading": "B. Comparison with state-of-the-art Malware Detectors", "text": "The above-mentioned SVM variants use the same features as DroidOL and hence it is sufficient to compare online and batch learning paradigms. However, this does not reflect the significance of DroidOL as a practical malware detector in the context of current state-of-the-art malware detection techniques. In order to study this, we compare DroidOL with two state-of-the-art malware detectors, namely, Drebin [4] and CSBD [5].\nFor this comparison, we follow the same batch learning configurations described in \u00a7VI-A to arrive at the four variants of these techniques: Drebin/CSBD-Once, Drebin/CSBD-Daily, Drebin/CSBD-MultiOnce and Drebin/CSBD-MultiDaily.\nThe results of this comparison are presented in Fig 3 (b) and (c). From these figures we make the following inferences: \u2022 For both these methods, the trends in performance of all\nfour variants are similar to those of the SVM variants. Hence the observations made in \u00a7VI-A on frequently updating the models and training with more data, hold. The error rates of best-performing variants of these methods are comparable to that of SVM-MultiDaily. \u2022 DroidOL consistently outperforms the best performing variants of both the methods. Particularly, it outperforms Drebin-MultiDaily by more than 5% and CSBDMultiDaily by more than 3%. This reaffirms the suitability of online learning for practical large-scale malware detection."}, {"heading": "C. Training Regimen", "text": "Since DroidOL\u2019s feature extraction using WL kernel is based on BoF model, our number of features grows as the samples stream in. Fig. 4 shows the cumulative number of features for each day of the evaluations in our dataset, representing the feature space growth. Each day\u2019s total includes new features introduced that day and all the old features from previous days. We obtained a total of 13,655 features from the malware and benign samples encountered on Day 1 (1 Jan\u201914).\nThe dimensionality grows quickly as we extract new subgraph features from samples encountered every day and while reaching the final day (13 Aug\u201914), we have accumulated 1,653,496 features. This phenomenon of feature space growth is common across many techniques including Drebin and CSBD. This is because Android apps evolve over time for various reasons such as capability enhancements, bug fixes, using newly introduced Android functionalities and adapting to changes in Android framework APIs [2, 7]. This evolution results in newly observed characteristics which translate into\nnew features from a ML view point. Now, we are posed with the question: should we consider these new features that emerge every day? To address this, we devise two types of training regimen, namely, variable featureset training and fixed feature-set training. Fixed feature-set training regimen. Under the fixed featureset regimen, we train using a pre-determined set of features for all evaluation days. That is, we fix the features to those encountered up to Day 1, then we use those 13,655 features for the whole experiment. Variable feature-set training regimen. Under the variable feature-set regimen, we allow the dimensionality of our PA classifier to grow with the number of new features encountered; on the last day, for instance, we classify with more than 1.6 million features. Implicitly, examples that were introduced before a feature i was first encountered will have value 0 for feature i.\nFig. 5 shows the importance of using variable featureset training over fixed feature-set training. We see that the performance for fixed feature regimen is significantly and consistently inferior to the variable feature regimen. The latter regimen has a 3.3% lesser cumulative error rate. This reveals that, continuous retraining with a variable feature-set allows a model to successfully adapt to new data and new features on a sub-day granularity. This adaptiveness is critical to realize the full benefits of online learning. This indicates that choosing the right training regimen can be just as important as choosing the right classifier. The aforementioned training regimens can help online algorithms stay abreast of changing trends in malware and benign apps\u2019 features."}, {"heading": "VII. UNDERSTANDING THE PERFORMANCE", "text": "In this section we seek to get deeper insights into the superior performances of DroidOL\u2019s online learning and to understand how characteristics of the Android malware detection task affects its performances. Specifically, we evaluate and quantify the importance of long term memory and fast model update. To this end, we pose the following question: Why does DroidOL outperform batch-learning solutions in detecting malware, even when they are re-trained?\nDataset. In order to provide insights into our results, we need the notion of similarity among the malware samples. More specifically, we need the malware to be grouped according to their families. Malware familial analysis and grouping is currently a manual process [2, 4]. It is impractical to group apps from our large-scale dataset according to their families. Hence we use a well-known benchmark dataset that has malware readily grouped according to their family, namely, Drebin5k6 [4]. Drebin5K contains a total of 5560 malicious Android apps belonging to 179 malware families. The date of creation of these samples lie in the range: Mar\u201909 to Oct\u201912.\nFamilial similarity and Notations. We now introduce the notion of familial similarity between a pair of malicious apps. We consider two malware m1 and m2 as variants, denoted by m1 \u223c m2, if they belong to the same malware family. For instance, Drebin5K dataset contains 965 samples belonging to\n6In order to distinguish the dataset provided by Drebin authors from the Drebin malware detection technique discussed in \u00a7VI, we refer to the dataset as Drebin5K.\nthe FakeInstaller family. We consider each of pair of them as variants. This stems from the fact that malware belonging to the same family exhibit similar malicious characteristics, making them exhibit similar semantic features from a ML view point.\nSubsequently, for each malware m, set M contains all the malware belonging to the same family as m. We calculate the time difference between the creation of m and every other malware, m\u2032 \u2208 M , denoted as 4(m,m\u2032). We call the minimum delay between another variant of the same family as m as minimum variant delay, denoted by4min(m). Similarly, we call the maximum delay between another variant of the same family as m as maximum variant delay, denoted by 4max(m).\nIf there are no variants of for a malware m, its default values for 4min(m) and 4max(m) are 0 and D, respectively, where D is the difference between the date of creation of m and that of the latest app in Drebin5K dataset.\nImportance of fast model update. Fig. 6 depicts the head of the cumulative distribution function (CDF) of the minimum variant delay of the malware samples in the Drebin5K dataset. It is clear that nearly 80% malware have a minimum variant delay of zero days. Meaning, for a given malware sample, at least one other variant of the same of family is built (and probably released) on the same day itself. This is understandable as malware authors aim to maximize their gains by launching several polymorphic variants of their malware, around the same time, leveraging on techniques such as obfuscation. Hence in order to keep abreast with quick-succession releases batchlearning solutions have to be updated at least daily (ideally, they have to be updated continuously). This explains why retraining SVM/Drebin/CSBD solutions every day yields higher classification accuracy in sections VI-A and VI-B. Therefore, unless the detector is updated continuously to reflect the most recent features present in the last malware, it will not be able\nto effectively detect a majority of its variants. Importance of long term memory. Fig. 7 depicts the head of the complementary cumulative distribution function (CCDF) of the maximum variant delay of all the malware samples in the Drebin5K dataset. We observe that more than 40% of malware have a maximum variant delay of more than a year. Which means, a significant number of malware families keep evolving for a few years. This is understandable as malware authors make new variants either to evade known detection techniques or to improve/enhance their attacks for a prolonged period of time.\nTherefore, if the batch size is limited to a few days or months, these 40% of malware would not have many similar variants in the batch. This leads to a significant reduction the detection accuracy because the detection model, has not yet learned enough on malware that is similar to these malware by the time it needs to classify them. In general, Fig. 7 demonstrates that classifying malware require long term memory. This explains why extending SVM/Drebin/CSBD batch sizes yielded better classification performance in sections VI-A and VI-B. However, when using batch-learning based detection solutions, the batch size is limited by the amount of available memory. Particularly, for a problem such as Android malware detection where we have millions of samples in a year and typical ML solutions extracting thousands of features, having a batch size of more than a year is not practical. On the other hand, online learning algorithms do not have this limitation. They retain significant useful information from all of the malware that they have seen. In other words, online algorithms operate with effectively infinite batch size. This explains why they have an edge over batch-learning solutions in our experiments.\nSummary. From figures 6 and 7 it is clear that to perform reasonably accurate and adaptive malware detection, the batchlearning solutions should re-train every day with a batch size of at least a year. This strategy is highly expensive in terms of computation time and resources, rendering it impractical. Hence, we can confidently conclude, online learning based methods which do not have such computational limitations and inherently adaptive are better suited for Android malware detection."}, {"heading": "VIII. CONCLUSIONS", "text": "In this paper, we present DroidOL, an accurate, adaptive and scalable Android malware detection framework. DroidOL\u2019s unique feature is its ability to handle population drift in Android malware through the use of online learning. DroidOL exhibits high accuracy, as it extracts effective structural features from apps using a state-of-the-art graph kernel. Further, DroidOL adapts automatically to the drift in malware characteristics over time and exhibits high scalability, making it suitable for real-world malware detection.\nOur large-scale evaluations on a real-world dataset demonstrates that DroidOL outperforms state-of-the-art malware detectors. DroidOL achieves 84.29% accuracy outperforming existing techniques by more than 20% in their typical batchlearning setting. This superior performance make DroidOL, in particular, and online learning based solutions, in general, better candidates for practical large-scale malware detection."}, {"heading": "ACKNOWLEDGMENT", "text": "We thank the authors of [4] and [5], for their suggestions and discussions that helped us re-implement their methods. We thank Kevin Allix for sharing the dataset used in [23]."}], "references": [{"title": "Appcontext: Differentiating malicious and benign mobile app behaviors using context.", "author": ["Yang", "Wei"], "venue": "Proc. of the International Conference on Software Engineering (ICSE)", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Structural detection of android malware using embedded call graphs.", "author": ["Gascon", "Hugo"], "venue": "Proceedings of the 2013 ACM workshop on Artificial intelligence and security. ACM,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Drebin: Effective and explainable detection of android malware in your pocket.", "author": ["Arp", "Daniel"], "venue": "Proceedings of the Annual Symposium on Network and Distributed System Security (NDSS)", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Empirical assessment of machine learning-based malware detectors for Android.", "author": ["Allix", "Kevin"], "venue": "Empirical Software Engineering", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "A machine learning approach to android malware detection.", "author": ["Sahs", "Justin", "Latifur Khan"], "venue": "Intelligence and Security Informatics Conference (EISIC), 2012 European", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Semantics-aware Android malware classification using weighted contextual API dependency graphs.", "author": ["Zhang", "Mu"], "venue": "Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security. ACM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "DroidAPIMiner: Mining API-level features for robust malware detection in android.", "author": ["Aafer", "Yousra", "Wenliang Du", "Heng Yin"], "venue": "Security and Privacy in Communication Networks. Springer International Publishing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Droidminer: Automated mining and characterization of fine-grained malicious behaviors in android applications.", "author": ["Yang", "Chao"], "venue": "Security-ESORICS", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Mining apps for abnormal usage of sensitive data.", "author": ["Avdiienko", "Vitalii"], "venue": "Software Engineering (ICSE),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Crowdroid: behavior-based malware detection system for android.", "author": ["Burguera", "Iker", "Urko Zurutuza", "Simin Nadjm-Tehrani"], "venue": "Proceedings of the 1st ACM workshop on Security and privacy in smartphones and mobile devices. ACM,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Synthesizing near-optimal malware specifications from suspicious behaviors.", "author": ["Fredrikson", "Matt"], "venue": "Security and Privacy (SP),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2010}, {"title": "Weisfeiler-lehman graph kernels.", "author": ["Shervashidze", "Nino"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Online passive-aggressive algorithms.", "author": ["Crammer", "Koby"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "On-line algorithms in machine learning", "author": ["Blum", "Avrim"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1998}, {"title": "Tracking concept drift in malware families.", "author": ["Singh", "Anshuman", "Andrew Walenstein", "Arun Lakhotia"], "venue": "Proceedings of the 5th ACM workshop on Security and artificial intelligence. ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Identifying suspicious URLs: an application of largescale online learning.", "author": ["Ma", "Justin"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Pscout: analyzing the android permission specification.", "author": ["Au", "Kathy Wain Yee"], "venue": "Proceedings of the 2012 ACM conference on Computer and communications security. ACM,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Cloud-based malware detection for evolving data streams.", "author": ["Masud", "Mohammad M"], "venue": "ACM Transactions on Management Information Systems (TMIS)", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Dissecting android malware: Characterization and evolution.", "author": ["Zhou", "Yajin", "Xuxian Jiang"], "venue": "Security and Privacy (SP),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "pClass: an effective classifier for streaming examples.", "author": ["Pratama", "Mahardhika"], "venue": "Fuzzy Systems, IEEE Transactions on 23.2", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Challenges and Outlook in Machine Learningbased Malware Detection for Android.", "author": ["Allix", "Kevin"], "venue": "(Doctoral dissertation). Retrieved from URL", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "rate of Android malware highlights an imperative need for developing sound and scalable automated malware detection process [2]\u2013[7, 12].", "startOffset": 124, "endOffset": 127}, {"referenceID": 5, "context": "rate of Android malware highlights an imperative need for developing sound and scalable automated malware detection process [2]\u2013[7, 12].", "startOffset": 128, "endOffset": 135}, {"referenceID": 10, "context": "rate of Android malware highlights an imperative need for developing sound and scalable automated malware detection process [2]\u2013[7, 12].", "startOffset": 128, "endOffset": 135}, {"referenceID": 0, "context": "Malware detection using Machine Learning (ML) techniques is predominant in various platforms (such as Windows, Android and the web) for more than a decade [2]\u2013[7, 12].", "startOffset": 155, "endOffset": 158}, {"referenceID": 5, "context": "Malware detection using Machine Learning (ML) techniques is predominant in various platforms (such as Windows, Android and the web) for more than a decade [2]\u2013[7, 12].", "startOffset": 159, "endOffset": 166}, {"referenceID": 10, "context": "Malware detection using Machine Learning (ML) techniques is predominant in various platforms (such as Windows, Android and the web) for more than a decade [2]\u2013[7, 12].", "startOffset": 159, "endOffset": 166}, {"referenceID": 0, "context": "These approaches typically use semantic features such as system calls/Application Programming Interfaces (APIs) invoked, resources and privileges used, control- and data-flows inside apps\u2019 execution to detect malicious behavior patterns [2]\u2013[7, 12].", "startOffset": 237, "endOffset": 240}, {"referenceID": 5, "context": "These approaches typically use semantic features such as system calls/Application Programming Interfaces (APIs) invoked, resources and privileges used, control- and data-flows inside apps\u2019 execution to detect malicious behavior patterns [2]\u2013[7, 12].", "startOffset": 241, "endOffset": 248}, {"referenceID": 10, "context": "These approaches typically use semantic features such as system calls/Application Programming Interfaces (APIs) invoked, resources and privileges used, control- and data-flows inside apps\u2019 execution to detect malicious behavior patterns [2]\u2013[7, 12].", "startOffset": 241, "endOffset": 248}, {"referenceID": 14, "context": "This phenomenon is an epitome of population drift [17].", "startOffset": 50, "endOffset": 54}, {"referenceID": 14, "context": "Since new malware features emerge and importances of features change over time, this population drift leads to concept drift [17, 18].", "startOffset": 125, "endOffset": 133}, {"referenceID": 15, "context": "Since new malware features emerge and importances of features change over time, this population drift leads to concept drift [17, 18].", "startOffset": 125, "endOffset": 133}, {"referenceID": 0, "context": "and obfuscation techniques adopted by malware [2, 5].", "startOffset": 46, "endOffset": 52}, {"referenceID": 3, "context": "and obfuscation techniques adopted by malware [2, 5].", "startOffset": 46, "endOffset": 52}, {"referenceID": 11, "context": "To this end, we use the Weisfeiler-Lehman (WL) graph kernel [13] that supports explicit feature vector representation of graphs to extract semantic features from ICFGs.", "startOffset": 60, "endOffset": 64}, {"referenceID": 9, "context": "1) Primitive Approaches: In the case of Android, Crowdroid [11], Drebin [4] and DroidAPIMiner [8] are noticeable among the early approaches on ML based malware detection.", "startOffset": 59, "endOffset": 63}, {"referenceID": 2, "context": "1) Primitive Approaches: In the case of Android, Crowdroid [11], Drebin [4] and DroidAPIMiner [8] are noticeable among the early approaches on ML based malware detection.", "startOffset": 72, "endOffset": 75}, {"referenceID": 6, "context": "1) Primitive Approaches: In the case of Android, Crowdroid [11], Drebin [4] and DroidAPIMiner [8] are noticeable among the early approaches on ML based malware detection.", "startOffset": 94, "endOffset": 97}, {"referenceID": 9, "context": "In particular, Crowdroid [11] uses Linux system call sequences", "startOffset": 25, "endOffset": 29}, {"referenceID": 2, "context": "Drebin [4] uses APIs, permissions, components, accessed URLs and Intent filters as features.", "startOffset": 7, "endOffset": 10}, {"referenceID": 6, "context": "DroidAPIMiner [8] considers sensitive APIs along with parameters and package level information as features.", "startOffset": 14, "endOffset": 17}, {"referenceID": 5, "context": "Even though these features are good enough for detecting simpler malware, they are easily evaded by modern malware that perform sophisticated attacks [7, 9].", "startOffset": 150, "endOffset": 156}, {"referenceID": 7, "context": "Even though these features are good enough for detecting simpler malware, they are easily evaded by modern malware that perform sophisticated attacks [7, 9].", "startOffset": 150, "endOffset": 156}, {"referenceID": 1, "context": "Hence such methods are not suitable for practical large-scale malware detection [3, 4].", "startOffset": 80, "endOffset": 86}, {"referenceID": 2, "context": "Hence such methods are not suitable for practical large-scale malware detection [3, 4].", "startOffset": 80, "endOffset": 86}, {"referenceID": 8, "context": "Mudflow [10], is a prototypical example of these types of detection methods.", "startOffset": 8, "endOffset": 12}, {"referenceID": 0, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 1, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 3, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 5, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 7, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 10, "context": "For this reason, graph representations such as callgraphs, control- and data-flow graphs, control-, data- and program-dependency graphs have been widely used for malware detection in conjunction with graph mining techniques [2, 3, 5, 7, 9, 12].", "startOffset": 224, "endOffset": 243}, {"referenceID": 7, "context": "In the case of Android, DroidMiner [9] and Allix et al.", "startOffset": 35, "endOffset": 38}, {"referenceID": 3, "context": "[5] proposed to use control-flow graph based features to perform structural malware detection.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "DroidSIFT [7] and AppContext [2] proposed a more robust approach by including the contextual information of security-sensitive activities (i.", "startOffset": 10, "endOffset": 13}, {"referenceID": 0, "context": "DroidSIFT [7] and AppContext [2] proposed a more robust approach by including the contextual information of security-sensitive activities (i.", "startOffset": 29, "endOffset": 32}, {"referenceID": 10, "context": ", [12]) are NP hard and have severe scalability issues, making them impractical for real-world malware detection [3].", "startOffset": 2, "endOffset": 6}, {"referenceID": 1, "context": ", [12]) are NP hard and have severe scalability issues, making them impractical for real-world malware detection [3].", "startOffset": 113, "endOffset": 116}, {"referenceID": 11, "context": "and expressive graph kernels such as WL kernel [13] have been proposed and widely adopted in many application areas (e.", "startOffset": 47, "endOffset": 51}, {"referenceID": 1, "context": "Taking notice of such a development, two approaches, Adagio [3] and Sahs et al.", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "[6] used graph kernels to perform structural detection of Android malware.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "As discussed in \u00a7I, many analytical studies such as [17, 21] have clearly highlighted that malware", "startOffset": 52, "endOffset": 60}, {"referenceID": 18, "context": "As discussed in \u00a7I, many analytical studies such as [17, 21] have clearly highlighted that malware", "startOffset": 52, "endOffset": 60}, {"referenceID": 17, "context": "While we note that there a few approaches in the past that have adopted online learning to tackle concept drift in malware for other platforms such as Windows [20], we are the first to do so for Android.", "startOffset": 159, "endOffset": 163}, {"referenceID": 11, "context": "Since WL graph kernel [13] is the current state-of-the-art graph kernel, known for its expressiveness and efficiency, we use it to extract semantic features from ICFGs.", "startOffset": 22, "endOffset": 26}, {"referenceID": 11, "context": "Once the ICFGs are constructed, (rooted) sub-graphs in these ICFGs that represent the security-sensitive behaviors in every app are extracted using the WL graph kernel [13].", "startOffset": 168, "endOffset": 172}, {"referenceID": 16, "context": "1PScout [19], an existing research work identifies and lists the securitysensitive Android APIs.", "startOffset": 8, "endOffset": 12}, {"referenceID": 11, "context": "This procedure falls under the well-known Bagof-Features (BoF) representation model [13], where every ICFG is considered as a bag of sub-graphs.", "startOffset": 84, "endOffset": 88}, {"referenceID": 12, "context": "where \u03b1t = max{ 1\u2212yt(wt\u00b7xt) ||xt|| , 0} (we refer the reader to the original work at [15] for this derivation and further details on PA algorithm).", "startOffset": 85, "endOffset": 89}, {"referenceID": 19, "context": "While we note that evolving classifiers such as pClass [22] could be used for handling concept drift, we prefer PA over such methods, as it offers better efficiency.", "startOffset": 55, "endOffset": 59}, {"referenceID": 2, "context": "We compare our online learning based detection against two state-of-the-art Android malware detection solutions, namely Drebin [4] and Allix et.", "startOffset": 127, "endOffset": 130}, {"referenceID": 3, "context": "\u2019s [5].", "startOffset": 3, "endOffset": 6}, {"referenceID": 2, "context": "Drebin [4] is well-known for its scalable and explainable detection.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "[5] recently proposed another scalable approach", "startOffset": 0, "endOffset": 3}, {"referenceID": 20, "context": "It is noted that this is a subset of a large collection of apps used in [23].", "startOffset": 72, "endOffset": 76}, {"referenceID": 2, "context": "In order to study this, we compare DroidOL with two state-of-the-art malware detectors, namely, Drebin [4] and CSBD [5].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "In order to study this, we compare DroidOL with two state-of-the-art malware detectors, namely, Drebin [4] and CSBD [5].", "startOffset": 116, "endOffset": 119}, {"referenceID": 0, "context": "using newly introduced Android functionalities and adapting to changes in Android framework APIs [2, 7].", "startOffset": 97, "endOffset": 103}, {"referenceID": 5, "context": "using newly introduced Android functionalities and adapting to changes in Android framework APIs [2, 7].", "startOffset": 97, "endOffset": 103}, {"referenceID": 0, "context": "is currently a manual process [2, 4].", "startOffset": 30, "endOffset": 36}, {"referenceID": 2, "context": "is currently a manual process [2, 4].", "startOffset": 30, "endOffset": 36}, {"referenceID": 2, "context": "has malware readily grouped according to their family, namely, Drebin5k [4].", "startOffset": 72, "endOffset": 75}, {"referenceID": 2, "context": "We thank the authors of [4] and [5], for their suggestions and discussions that helped us re-implement their methods.", "startOffset": 24, "endOffset": 27}, {"referenceID": 3, "context": "We thank the authors of [4] and [5], for their suggestions and discussions that helped us re-implement their methods.", "startOffset": 32, "endOffset": 35}, {"referenceID": 20, "context": "We thank Kevin Allix for sharing the dataset used in [23].", "startOffset": 53, "endOffset": 57}], "year": 2016, "abstractText": "It is well-known that malware constantly evolves so as to evade detection and this causes the entire malware population to be non-stationary. Contrary to this fact, prior works on machine learning based Android malware detection have assumed that the distribution of the observed malware characteristics (i.e., features) do not change over time. In this work, we address the problem of malware population drift and propose a novel online machine learning based framework, named DroidOL to handle it and effectively detect malware. In order to perform accurate detection, the security-sensitive behaviors are captured from apps in the form of inter-procedural control-flow sub-graph features using a state-of-the-art graph kernel. In order to perform scalable detection and to adapt to the drift and evolution in malware population, an online passiveaggressive classifier is used. In a large-scale comparative analysis with more than 87,000 apps, DroidOL achieves 84.29% accuracy outperforming two state-of-the-art malware techniques by more than 20% in their typical batch learning setting and more than 3% when they are continuously re-trained. Our experimental findings strongly indicate that online learning based approaches are highly suitable for real-world malware detection. keywords \u2014 Online Learning, Graph Kernels, Malware Detection", "creator": "LaTeX with hyperref package"}}}