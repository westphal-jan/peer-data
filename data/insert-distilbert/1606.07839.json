{"id": "1606.07839", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles", "abstract": "many practical perception systems exist within larger processes which often ultimately include variable interactions with users or additional functional components ; that are capable of evaluating assessing the quality of predicted solutions. operating in these contexts, it is beneficial to provide through these oracle neural mechanisms with multiple highly likely hypotheses rather than a single comprehensive prediction. in this work, we pose the task of producing multiple outputs directly as a learning problem over an ensemble of deep networks - - introducing a novel sequential stochastic gradient descent based approach to minimize the loss noise with respect to an oracle. our method is simple to confidently implement, agnostic software to both architecture and loss function, and parameter - free. our approach achieves sharply lower oracle error compared to existing methods on a wide range of tasks and deep architectures. occasionally we also show qualitatively that solutions produced from our approach often provide interpretable representations of task ambiguity.", "histories": [["v1", "Fri, 24 Jun 2016 21:48:55 GMT  (7242kb,D)", "https://arxiv.org/abs/1606.07839v1", null], ["v2", "Wed, 28 Sep 2016 20:44:55 GMT  (12050kb,D)", "http://arxiv.org/abs/1606.07839v2", null], ["v3", "Wed, 5 Oct 2016 17:12:00 GMT  (6655kb,D)", "http://arxiv.org/abs/1606.07839v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.CL", "authors": ["stefan lee", "senthil purushwalkam", "michael cogswell", "viresh ranjan", "david j crandall", "dhruv batra"], "accepted": true, "id": "1606.07839"}, "pdf": {"name": "1606.07839.pdf", "metadata": {"source": "CRF", "title": "Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles", "authors": ["Stefan Lee", "Senthil Purushwalkam", "Michael Cogswell", "Viresh Ranjan"], "emails": ["steflee@vt.edu", "spurushw@andrew.cmu.edu", "cogswell@vt.edu", "rviresh@vt.edu", "djcran@indiana.edu", "dbatra@vt.edu"], "sections": [{"heading": "1 Introduction", "text": "Perception problems rarely exist in a vacuum. Typically, problems in Computer Vision, Natural Language Processing, and other AI subfields are embedded in larger applications and contexts. For instance, the task of recognizing and segmenting objects in an image (semantic segmentation [6]) might be embedded in an autonomous vehicle [7], while the task of describing an image with a sentence (image captioning [18]) might be part of a system to assist visually-impaired users [22, 29]. In these scenarios, the goal of perception is often not to generate a single output but a set of plausible hypotheses for a \u2018downstream\u2019 process, such as a verification component or a human operator. These downstream mechanisms may be abstracted as oracles that have the capability to pick the correct solution from this set. Such a learning setting is called Multiple Choice Learning (MCL) [8], where the goal for the learner is to minimize oracle loss achieved by a set of M solutions. More formally, given a dataset of input-output pairs {(xi, yi) | xi \u2208 X , yi \u2208 Y}, the goal of classical supervised learning is to search for a mapping F : X \u2192 Y that minimizes a task-dependent loss ` : Y\u00d7Y \u2192 R+ capturing the error between the actual labeling yi and predicted labeling y\u0302i. In this setting, the learned function f makes a single prediction for each input and pays a penalty for that prediction. In contrast, Multiple Choice Learning seeks to learn a mapping g : X \u2192 YM that produces M solutions Y\u0302i = (y\u0302 1 i , . . . , y\u0302 M i ) such that oracle loss minm ` (yi, y\u0302 m i ) is minimized. In this work, we fix the form of this mapping g to be the union of outputs from an ensemble of predictors such that g(x) = {f1(x), f2(x), . . . , fM (x)}, and address the task of training ensemble members f1, . . . , fM such that g minimizes oracle loss. Under our formulation, different ensemble members are free to specialize on subsets of the data distribution, so that collectively they produce a set of outputs which covers the space of high probability predictions well.\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 6.\n07 83\n9v 3\n[ cs\n.C V\n] 5\nDiverse solution sets are especially useful for structured prediction problems with multiple reasonable interpretations, only one of which is correct. Situations that often arise in practical systems include: \u2013 Implicit class confusion. The label space of many classification problems is often an arbitrary\nquantization of a continuous space. For example, a vision system may be expected to classify between tables and desks, despite many real-world objects arguably belonging to both classes. By making multiple predictions, this implicit confusion can be viewed explicitly in system outputs. \u2013 Ambiguous evidence. Often there is simply not enough information to make a definitive prediction. For example, even a human expert may not be able to identify a fine-grained class (e.g., particular breed of dog) given an occluded or distant view, but they likely can produce a small set of reasonable guesses. In such cases, the task of producing a diverse set of possibilities is more clearly defined than producing one correct answer. \u2013 Bias towards the mode. Many models have a tendency to exhibit mode-seeking behaviors as a way to reduce expected loss over a dataset (e.g., a conversation model frequently producing \u2018I don\u2019t know\u2019). By making multiple predictions, a system can improve coverage of lower density areas of the solution space, without sacrificing performance on the majority of examples.\nIn other words, by optimizing for the oracle loss, a multiple-prediction learner can respond to ambiguity much like a human does, by making multiple guesses that capture multi-modal beliefs. In contrast, a single-prediction learner is forced to produce a solution with low expected loss in the face of ambiguity. Figure 1 illustrates how this can produce solutions that are not useful in practice. In semantic segmentation, for example, this problem often causes objects to be predicted as a mixture of multiple classes (like the horse-cow shown in the figure). In image captioning, minimizing expected loss encourages generic sentences that are \u2018safe\u2019 with respect to expected error but not very informative. For example, Figure 1 shows two pairs of images each having different image content but very similar, generic captions \u2013 the model knows it is safe to assume that birds are on branches and that cakes are eaten with forks. In this paper, we generalize the Multiple Choice Learning paradigm [8, 9] to jointly learn ensembles of deep networks that minimize the oracle loss directly. We are the first to adapt these ideas to deep networks and we present a novel training algorithm that avoids costly retraining [8] and learning difficulty [5] of past methods. Our primary technical contribution is the formulation of a stochastic block gradient descent optimization approach well-suited to minimizing the oracle loss in ensembles of deep networks, which we call Stochastic Multiple Choice Learning (sMCL). Our formulation is applicable to any model trained with stochastic gradient descent, is agnostic to the form of the task dependent loss, is parameter-free, and is time efficient, training all ensemble members concurrently. We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18]. We provide detailed analysis of the training and output behaviors of the resulting ensembles, demonstrating how ensemble member specialization and expertise emerge automatically when trained using sMCL. Our method outperforms existing baselines and produces sets of outputs with high oracle performance."}, {"heading": "2 Related Work", "text": "Ensemble Learning. Much of the existing work on training ensembles focuses on diversity between member models as a means to improve performance by decreasing error correlation. This is often accomplished by resampling existing training data for each member model [27] or by producing artificial data that encourages new models to be decorrelated with the existing ensemble [21]. Other approaches train or combine ensemble members under a joint loss [19, 26]. More recently, work of Hinton et al. [12] and Ahmed et al. [2] explores using \u2018generalist\u2019 network performance statistics to inform the design of ensemble-of-expert architectures for classification. In contrast, sMCL discovers specialization as a consequence of minimizing oracle loss. Importantly, most existing methods do not generalize to structured output labels, while sMCL seamlessly adapts, discovering different task-dependent specializations automatically.\nGenerating Multiple Solutions. There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures. Most related to our approach is the work of Guzman-Rivera et al. [8, 9] which explicitly minimizes oracle loss over the outputs of an ensemble, formalizing this setting as the Multiple Choice Learning (MCL) paradigm. They introduce a general alternating block coordinate descent training approach which requires retraining models multiple times. More recently, Dey et al. [5] reformulated this problem as a submodular optimization task in which ensemble members are learned sequentially in a boosting-like manner to maximize marginal gain in oracle performance. Both these methods require either costly retraining or sequential training, making them poorly suited to modern deep architectures that can take weeks to train. To address this serious shortcoming and to provide the first practical algorithm for training diverse deep ensembles, we introduce a stochastic gradient descent (SGD) based algorithm to train ensemble members concurrently."}, {"heading": "3 Multiple-Choice Learning as Stochastic Block Gradient Descent", "text": "We consider the task of training an ensemble of differentiable learners that together produce a set of solutions with minimal loss with respect to an oracle that selects only the lowest-error prediction.\nNotation. We use [n] to denote the set {1, 2, . . . , n}. Given a training set of input-output pairs D = {(xi, yi) | xi \u2208 X , yi \u2208 Y}, our goal is to learn a function g : X \u2192 YM which maps each input to M outputs. We fix the form of g to be an ensemble of M learners f such that g(x) = (f1(x), . . . , fM (x)). For some task-dependent loss `(y, y\u0302), which measures the error between true and predicted outputs y and y\u0302, we define the oracle loss of g over the dataset D as\nLO(D) = n\u2211\ni=1\nmin m\u2208[M ] ` (yi, fm(xi)) .\nMinimizing Oracle Loss with Multiple Choice Learning. In order to directly minimize the oracle loss for an ensemble of learners, Guzman-Rivera et al. [8] present an objective which forms a (potentially tight) upper-bound. This objective replaces the min in the oracle loss with indicator variables (pi,m)Mm=1 where pi,m is 1 if predictor m has the lowest error on example i,\nargmin fm,pm,i\nn\u2211 i=1 M\u2211 m=1 pi,m ` (yi, fm(xi)) (1)\ns.t.\nM\u2211 pi,m = 1, pi,m \u2208 {0, 1}.\nThe resulting minimization is a constrained joint optimization over ensemble parameters and datapoint assignments. The authors propose an alternating block algorithm, shown in Algorithm 1, to approximately minimize this objective. Similar to K-Means or \u2018hard-EM,\u2019 this approach alternates between assigning examples to their min-loss predictors and training models to convergence on the partition of examples assigned to them. Note that this approach is not feasible with training deep networks, since modern architectures [11] can take weeks or months to train a single model once.\nStochastic Multiple Choice Learning. To overcome this shortcoming, we propose a stochastic algorithm for differentiable learners which interleaves the assignment step with batch updates in\nstochastic gradient descent. Consider the partial derivative of the objective in Eq. 1 with respect to the output of the mth individual learner on example xi,\n\u2202LO \u2202fm(xi) = pi,m \u2202`(yi, fm(xi)) \u2202fm(xi) . (2)\nNotice that if fm is the minimum error predictor for example xi, then pi,m = 1, and the gradient term is the same as if training a single model; otherwise, the gradient is zero. This behavior lends itself to a straightforward optimization strategy for learners trained by SGD based solvers. For each batch, we pass the examples through the learners, calculating losses from each ensemble member for each example. During the backward pass, the gradient of the loss for each example is backpropagated only to the lowest error predictor on that example (with ties broken arbitrarily). This approach, which we call Stochastic Multiple Choice Learning (sMCL), is shown in Algorithm 2. sMCL is generalizable to any learner trained by stochastic gradient descent and is thus applicable to an extensive range of modern deep networks. Unlike the iterative training schedule of MCL, sMCL ensembles need only be trained to convergence once in parallel. sMCL is also agnostic to the exact form of loss function ` such that it can be applied without additional effort on a variety of problems."}, {"heading": "4 Experiments", "text": "In this section, we present results for sMCL ensembles trained for the tasks and deep architectures shown in Figure 3. These include CNN ensembles for image classification, FCN ensembles for semantic segmentation, and a CNN+RNN ensembles for image caption generation.\nBaselines. Many existing general techniques for inducing diversity are not directly applicable to deep networks. We compare our proposed method against: - Classical ensembles in which each model is trained under an independent loss with differing\nrandom initializations. We will refer to these as Indp. ensembles in figures. - MCL [8] that alternates between training models to convergence on assigned examples and\nallocating examples to their lowest error model. We repeat this process for 5 meta-iterations and initialize ensembles with (different) random weights. We find MCL performs similarly to sMCL on small classification tasks; however, MCL performance drops substantially on segmentation and captioning tasks. Unlike sMCL which can effectively reassign an example once per epoch, MCL only does this after convergence, limiting its capacity to specialize compared to sMCL. We also note that sMCL is 5x faster than MCL, where the factor 5 is the result of choosing 5 meta-iterations (other applications may require more, further increasing the gap.) - Dey et al. [5] train models sequentially in a boosting-like fashion, each time reweighting examples to maximize marginal increase of the evaluation metric. We find these models saturate quickly as the ensemble size grows. As performance increases, the marginal gain and therefore the weights approach zero. With low weights, the average gradient backpropagated for stochastic learners drops substantially, reducing the rate and effectiveness of learning without careful tuning. To compute\n(a) Convolutional classification model of [1] for CIFAR10 [17]\n(b) Fully-convolutional segmentation model of Long et al. [20]\n(c) CNN+RNN based captioning model of Karpathy et al. [14]\nOracle Evaluation. We present results as oracle versions of the task-dependent performance metrics. These oracle metrics report the highest score over all outputs for a given input. For example, in classification tasks, oracle accuracy is exactly the top-k criteria of ImageNet [25], i.e. whether at least one of the outputs is the correct label. Likewise, the oracle intersection over union (IoU) is the highest IoU between the ground truth segmentation and any one of the outputs. Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24]. Our experiments convincingly demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles. In all three experiments, sMCL significantly outperforms classical ensembles, Dey et al. [5] (typical improvements of 6-10%), and MCL (while providing a 5x speedup over MCL). Our analysis shows that the exact same algorithm (sMCL) leads to the automatic emergence of different interpretable notions of specializations among ensemble members."}, {"heading": "4.1 Image Classification", "text": "Model. We begin our experiments with sMCL on the CIFAR10 [17] dataset using the small convolutional neural network \u201cCIFAR10-Quick\u201d provided with the Caffe deep learning framework [13]. CIFAR10 is a ten way classification task with small 32\u00d732 images. For these experiments, the reference model is trained using a batch size of 350 for 5,000 iterations with a momentum of 0.9, weight decay of 0.004, and an initial learning rate of 0.001 which drops to 0.0001 after 4000 iterations.\nResults. Oracle accuracy for sMCL and baseline ensembles of size 1 to 6 are shown in Figure 4a. The sMCL trained ensembles result in higher oracle accuracy than the baseline methods, and are comparable to MCL while being 5x faster. The method of Dey et al. [5] performs worse than independent ensembles as ensemble size grows. Figure 4b shows the oracle loss during training for sMCL and regular ensembles. The sMCL trained models optimize for the oracle cross-entropy loss directly, not only arriving at lower loss solutions but also reducing error more quickly.\nInterpretable Expertise: sMCL Induces Label-Space Clustering. Figure 4c shows the class-wise distribution of the assignment of test datapoints to the oracle or \u2018winning\u2019 predictor for an M = 4 sMCL ensemble. The level of class division is striking \u2013 most predictors become specialists for certain classes. Note that these divisions emerge from training under the oracle loss and are not hand-designed or pre-initialized in any way. In contrast, Figure 4f show that the oracle assignments for a standard ensemble are nearly uniform. To explore the space between these two extremes, we loosen the constraints of Eq. 1 such that the lowest k error predictors are penalized. By varying k between 1 and the number of ensemble members M , the models transition from minimizing oracle loss at k = 1 to a traditional ensemble at k = M . Figures 4d and 4e show these results. We find a direct correlation between the degree of specialization and oracle accuracy, with k = 1 netting highest oracle accuracy."}, {"heading": "4.2 Semantic Segmentation", "text": "We now present our results for the semantic segmentation task on the Pascal VOC dataset [6].\nModel. We use the fully convolutional network (FCN) architecture presented by Long et al. [20] as our base model. Like [20], we train on the Pascal VOC 2011 training set augmented with extra segmentations provided in [10] and we test on a subset of the VOC 2011 validation set. We initialize\nour sMCL models from a standard ensemble trained for 50 epochs at a learning rate of 10\u22123. The sMCL ensemble is then fine-tuned for another 15 epochs at a reduced learning rate of 10\u22125.\nResults. Figure 5a shows oracle accuracy (class-averaged IoU) for all methods with ensemble sizes ranging from 1 to 6. Again, sMCL significantly outperforms all baselines (~7% relative improvement over classical ensembles). In this more complex setting, we see the method of Dey et al. [5] saturates more quickly \u2013 resulting in performance worse than classical ensembles as ensemble size grows. Though we expect MCL to achieve similar results as sMCL, retraining the MCL ensembles a sufficient number of times proved infeasible so results after five meta-iterations are shown.\nInterpretable Expertise: sMCL as Segmentation Specialists. In Figure 5b, we analyze the class distribution of the predictions using an sMCL ensemble with 4 members. For each test sample, the oracle picks the prediction which corresponds to the ensemble member with the highest accuracy for that sample. We find the specialization with respect to classes is much less evident than in the classification experiments. As segmentation presents challenges other than simply selecting the correct class, specialization can occur in terms of shape and frequency of predicted segments in addition to class divisions; however, we do still see some class biases \u2013 network 2 captures cows, tables, and sofas well and network 4 has become an expert on sheep and horses. Figure 6 shows qualitative results from a four member sMCL ensemble. We can clearly observe the diversity in the segmentations predicted by different members. In the first row, we see the majority of the ensemble members produce dining tables of various completeness in response to the visual uncertainty caused by the clutter. Networks 2 and 3 capture this ambiguity well, producing segmentations with the dining table completely present or absent. Row 2 demonstrates the capacity of sMCL ensembles to provide multiple high quality solutions. The models are confused whether the\nanimal is a horse or a cow \u2013 models 1 and 3 produce typical \u2018safe\u2019 responses while models 2 and 4 attempt to give cohesive responses. Finally, row 3 shows how the models can learn biases about the frequency of segments with model 3 presenting only the sheep."}, {"heading": "4.3 Image Captioning", "text": "In this section, we show that sMCL trained ensembles can produce sets of high quality and diverse sentences, which is essential to improving recall and capturing ambiguities in language and perception.\nModel. We adopt the model and training procedure of Karpathy et al. [14], utilizing their publicly available implementation neuraltalk2. The model consists of an VGG16 network [4] which encodes the input image as a fixed-length representation for a Long Short-Term Memory (LSTM) language model. We train and test on the MSCOCO dataset [18], using the same splits as [14]. We perform two experimental setups by either freezing or finetuning the CNN. In the first, we freeze the parameters of the CNN and train multiple LSTM models using the CNN as a static feature generator. In the second, we aggregate and back-propagate the gradients from each LSTM model through the CNN in a tree-like model structure. This is largely a construct of memory restrictions as our hardware could not accommodate multiple VGG16 networks. We train each ensemble for 70k iterations with the parameters of the CNN fixed. For the fine-tuning experiments, we perform another 70k iterations of training to fine-tune the CNN. We generate sentences for testing by performing beam search with a beam width of two (following [14]).\nResults. Table 1 presents the oracle CIDEr-D [28] scores for all methods on the validation set. We additionally compare with all outputs of a beam search over a single CNN+LSTM model with beam width ranging from 1 to 5. sMCL significantly outperforms the baseline ensemble learning methods (shown in the upper section of the table), increasing both oracle performance and the number of unique n-grams. For M = 5, beam search from a single model achieves greater oracle but produces\nsignificantly fewer unique n-grams. We note that beam search is an inference method and increased beam width could provide similar benefits for sMCL ensembles.\nIntepretable Expertise: sMCL as N-Gram Specialists. Figure 7 shows example images and generated captions from standard and sMCL ensembles of size four (results from beam search over a single model are similar). It is evident that the independently trained models tend to predict similar sentences independent of initialization, perhaps owing to the highly structured nature of the output space and the mode bias of the underlying language model. On the other hand, the sMCL based ensemble generates diverse sentences which capture ambiguity both in language and perception. The first row shows an extreme case in which all of the members of the standard ensemble predict identical sentences. In contrast, the sMCL ensemble produces sentences that describe the scene with many different structures. In row three, both models are confused about the content of the image, mistaking the pile of suitcases as kitchen appliances. However, the sMCL ensemble widens the scope of some sentences to include the cat clearly depicted in the image. The fourth row is an example of regression towards the mode, with the standard model producing multiple similar sentences describing birds on branches. In the sMCL ensemble, we also see this tendency; however, one model breaks away and captures the true content of the image."}, {"heading": "5 Conclusion", "text": "To summarize, we propose Stochastic Multiple Choice Learning (sMCL), an SGD-based technique for training diverse deep ensembles that follows a \u2018winner-take-gradient\u2019 training strategy. Our experiments demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles. In all experimental settings, sMCL significantly outperforms classical ensembles and other strong baselines including the 5x slower MCL procedure. Our analysis shows that exactly the same algorithm (sMCL) automatically generates specializations among ensemble members along different task-specific dimensions. sMCL is simple to implement, agnostic to both architecture and loss function, parameter free, and simply involves introducing one new sMCL layer into existing ensemble architectures."}, {"heading": "Acknowledgments", "text": "This work was supported in part by a National Science Foundation CAREER award, an Army Research Office YIP award, ICTAS Junior Faculty award, Office of Naval Research grant N00014-14-1-0679, Google Faculty Research award, AWS in Education Research grant, and NVIDIA GPU donation, all awarded to DB, and by an NSF CAREER award (IIS-1253549), the Intelligence Advanced Research Projects Activity (IARPA) via Air Force Research Laboratory contract FA8650-12-C-7212, a Google Faculty Research award, and an NVIDIA GPU donation, all awarded to DC. Computing resources used by this work are supported in part by NSF (ACI-0910812 and CNS-0521433), the Lily Endowment, Inc., and the Indiana METACyt Initiative. The U.S. Government is authorized to reproduce and distribute\nreprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, AFRL, NSF, or the U.S. Government."}], "references": [{"title": "Network of experts for large-scale image categorization", "author": ["K. Ahmed", "M.H. Baig", "L. Torresani"], "venue": "arXiv preprint arXiv:1604.06119", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Diverse M-Best Solutions in Markov Random Fields", "author": ["D. Batra", "P. Yadollahpour", "A. Guzman-Rivera", "G. Shakhnarovich"], "venue": "Proceedings of European Conference on Computer Vision (ECCV)", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Return of the devil in the details: Delving deep into convolutional nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "arXiv preprint arXiv:1405.3531", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Predicting multiple structured visual interpretations", "author": ["D. Dey", "V. Ramakrishna", "M. Hebert", "J. Andrew Bagnell"], "venue": "Proceedings of IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "and A", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn"], "venue": "Zisserman. The PASCAL Visual Object Classes Challenge 2011 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Vision meets Robotics: The KITTI Dataset", "author": ["A. Geiger", "P. Lenz", "C. Stiller", "R. Urtasun"], "venue": "International Journal of Robotics Research (IJRR)", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiple Choice Learning: Learning to Produce Multiple Structured Outputs", "author": ["A. Guzman-Rivera", "D. Batra", "P. Kohli"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Efficiently enforcing diversity in multi-output structured prediction", "author": ["A. Guzman-Rivera", "P. Kohli", "D. Batra", "R. Rutenbar"], "venue": "Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Semantic contours from inverse detectors", "author": ["B. Hariharan", "P. Arbelaez", "L. Bourdev", "S. Maji", "J. Malik"], "venue": "Proceedings of IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Distilling the knowledge in a neural network", "author": ["G.E. Hinton", "O. Vinyals", "J. Dean"], "venue": "Advances in Neural Information Processing Systems (NIPS) - Deep Learning Workshop", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: An open source convolutional architecture for fast feature embedding", "author": ["Y. Jia"], "venue": "http://caffe. berkeleyvision.org/", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Inferring m-best diverse solutions in a single one", "author": ["A. Kirillov", "B. Savchynskyy", "D. Schlesinger", "D. Vetrov", "C. Rother"], "venue": "Proceedings of IEEE International Conference on Computer Vision (ICCV)", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "M-best-diverse labelings for submodular energies and beyond", "author": ["A. Kirillov", "D. Schlesinger", "D. Vetrov", "C. Rother", "B. Savchynskyy"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "and C", "author": ["T.-Y. Lin", "M. Maire", "S. Belongie", "J. Hays", "P. Perona", "D. Ramanan", "P. Doll\u00e1r"], "venue": "L. Zitnick. Microsoft COCO: Common objects in context", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Ensemble learning via negative correlation", "author": ["Y. Liu", "X. Yao"], "venue": "Neural Networks, 12(10):1399\u20131404", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1999}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["J. Long", "E. Shelhamer", "T. Darrell"], "venue": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Creating diversity in ensembles using artificial data", "author": ["P. Melville", "R.J. Mooney"], "venue": "Information Fusion, 6(1):99\u2013111", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "N-best maximal decoders for part models", "author": ["D. Park", "D. Ramanan"], "venue": "Proceedings of IEEE International Conference on Computer Vision (ICCV), pages 2627\u20132634", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "Submodular meets structured: Finding diverse subsets in exponentiallylarge structured item sets", "author": ["A. Prasad", "S. Jegelka", "D. Batra"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "and L", "author": ["O. Russakovsky", "J. Deng", "J. Krause", "A. Berg"], "venue": "Fei-Fei. The ImageNet Large Scale Visual Recognition Challenge 2012 ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Cluster ensembles\u2014a knowledge reuse framework for combining multiple partitions", "author": ["A. Strehl", "J. Ghosh"], "venue": "The Journal of Machine Learning Research, 3:583\u2013617", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2003}, {"title": "Error correlation and error reduction in ensemble classifiers", "author": ["K. Tumer", "J. Ghosh"], "venue": "Connection Science, 8(3-4):385\u2013404", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1996}, {"title": "Cider: Consensus-based image description evaluation", "author": ["R. Vedantam", "C. Lawrence Zitnick", "D. Parikh"], "venue": "In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "For instance, the task of recognizing and segmenting objects in an image (semantic segmentation [6]) might be embedded in an autonomous vehicle [7], while the task of describing an image with a sentence (image captioning [18]) might be part of a system to assist visually-impaired users [22, 29].", "startOffset": 96, "endOffset": 99}, {"referenceID": 5, "context": "For instance, the task of recognizing and segmenting objects in an image (semantic segmentation [6]) might be embedded in an autonomous vehicle [7], while the task of describing an image with a sentence (image captioning [18]) might be part of a system to assist visually-impaired users [22, 29].", "startOffset": 144, "endOffset": 147}, {"referenceID": 16, "context": "For instance, the task of recognizing and segmenting objects in an image (semantic segmentation [6]) might be embedded in an autonomous vehicle [7], while the task of describing an image with a sentence (image captioning [18]) might be part of a system to assist visually-impaired users [22, 29].", "startOffset": 221, "endOffset": 225}, {"referenceID": 6, "context": "Such a learning setting is called Multiple Choice Learning (MCL) [8], where the goal for the learner is to minimize oracle loss achieved by a set of M solutions.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "In this paper, we generalize the Multiple Choice Learning paradigm [8, 9] to jointly learn ensembles of deep networks that minimize the oracle loss directly.", "startOffset": 67, "endOffset": 73}, {"referenceID": 7, "context": "In this paper, we generalize the Multiple Choice Learning paradigm [8, 9] to jointly learn ensembles of deep networks that minimize the oracle loss directly.", "startOffset": 67, "endOffset": 73}, {"referenceID": 6, "context": "We are the first to adapt these ideas to deep networks and we present a novel training algorithm that avoids costly retraining [8] and learning difficulty [5] of past methods.", "startOffset": 127, "endOffset": 130}, {"referenceID": 3, "context": "We are the first to adapt these ideas to deep networks and we present a novel training algorithm that avoids costly retraining [8] and learning difficulty [5] of past methods.", "startOffset": 155, "endOffset": 158}, {"referenceID": 15, "context": "We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18].", "startOffset": 280, "endOffset": 284}, {"referenceID": 18, "context": "We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18].", "startOffset": 319, "endOffset": 323}, {"referenceID": 4, "context": "We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18].", "startOffset": 360, "endOffset": 363}, {"referenceID": 12, "context": "We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18].", "startOffset": 427, "endOffset": 431}, {"referenceID": 16, "context": "We demonstrate the broad applicability and efficacy of sMCL for training diverse deep ensembles with interpretable emergent expertise on a wide range of problem domains and network architectures, including Convolutional Neural Network (CNN) [1] ensembles for image classification [17], FullyConvolutional Network (FCN) [20] ensembles for semantic segmentation [6], and combined CNN and Recurrent Neural Network (RNN) ensembles [14] for image captioning [18].", "startOffset": 453, "endOffset": 457}, {"referenceID": 24, "context": "This is often accomplished by resampling existing training data for each member model [27] or by producing artificial data that encourages new models to be decorrelated with the existing ensemble [21].", "startOffset": 86, "endOffset": 90}, {"referenceID": 19, "context": "This is often accomplished by resampling existing training data for each member model [27] or by producing artificial data that encourages new models to be decorrelated with the existing ensemble [21].", "startOffset": 196, "endOffset": 200}, {"referenceID": 17, "context": "Other approaches train or combine ensemble members under a joint loss [19, 26].", "startOffset": 70, "endOffset": 78}, {"referenceID": 23, "context": "Other approaches train or combine ensemble members under a joint loss [19, 26].", "startOffset": 70, "endOffset": 78}, {"referenceID": 10, "context": "[12] and Ahmed et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[2] explores using \u2018generalist\u2019 network performance statistics to inform the design of ensemble-of-expert architectures for classification.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures.", "startOffset": 104, "endOffset": 123}, {"referenceID": 13, "context": "There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures.", "startOffset": 104, "endOffset": 123}, {"referenceID": 14, "context": "There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures.", "startOffset": 104, "endOffset": 123}, {"referenceID": 20, "context": "There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures.", "startOffset": 104, "endOffset": 123}, {"referenceID": 21, "context": "There is a large body of work on the topic of extracting multiple diverse solutions from a single model [3, 15, 16, 23, 24]; however, these approaches are designed for probabilistic structured-output models and are not directly applicable to general deep architectures.", "startOffset": 104, "endOffset": 123}, {"referenceID": 6, "context": "[8, 9] which explicitly minimizes oracle loss over the outputs of an ensemble, formalizing this setting as the Multiple Choice Learning (MCL) paradigm.", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[8, 9] which explicitly minimizes oracle loss over the outputs of an ensemble, formalizing this setting as the Multiple Choice Learning (MCL) paradigm.", "startOffset": 0, "endOffset": 6}, {"referenceID": 3, "context": "[5] reformulated this problem as a submodular optimization task in which ensemble members are learned sequentially in a boosting-like manner to maximize marginal gain in oracle performance.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] present an objective which forms a (potentially tight) upper-bound.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Note that this approach is not feasible with training deep networks, since modern architectures [11] can take weeks or months to train a single model once.", "startOffset": 96, "endOffset": 100}, {"referenceID": 6, "context": "Figure 2: The MCL approach of [8] (Alg.", "startOffset": 30, "endOffset": 33}, {"referenceID": 6, "context": "- MCL [8] that alternates between training models to convergence on assigned examples and allocating examples to their lowest error model.", "startOffset": 6, "endOffset": 9}, {"referenceID": 3, "context": "[5] train models sequentially in a boosting-like fashion, each time reweighting examples to maximize marginal increase of the evaluation metric.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "(a) Convolutional classification model of [1] for CIFAR10 [17] (b) Fully-convolutional segmentation model of Long et al.", "startOffset": 58, "endOffset": 62}, {"referenceID": 18, "context": "[20] (c) CNN+RNN based captioning model of Karpathy et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] Figure 3: We experiment with three problem domains using the various architectures shown above.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "weights, [5] requires an error measure bounded above by 1: accuracy (for classification) and IoU (for segmentation) satisfy this; the CIDEr-D score [28] divided by 10 guarantees this for captioning.", "startOffset": 9, "endOffset": 12}, {"referenceID": 25, "context": "weights, [5] requires an error measure bounded above by 1: accuracy (for classification) and IoU (for segmentation) satisfy this; the CIDEr-D score [28] divided by 10 guarantees this for captioning.", "startOffset": 148, "endOffset": 152}, {"referenceID": 22, "context": "For example, in classification tasks, oracle accuracy is exactly the top-k criteria of ImageNet [25], i.", "startOffset": 96, "endOffset": 100}, {"referenceID": 1, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 3, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 6, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 7, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 13, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 14, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 20, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 21, "context": "Oracle metrics allow the evaluation of multiple-prediction systems separately from downstream re-ranking or selection systems, and have been extensively used in previous work [3, 5, 8, 9, 15, 16, 23, 24].", "startOffset": 175, "endOffset": 203}, {"referenceID": 3, "context": "[5] (typical improvements of 6-10%), and MCL (while providing a 5x speedup over MCL).", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "We begin our experiments with sMCL on the CIFAR10 [17] dataset using the small convolutional neural network \u201cCIFAR10-Quick\u201d provided with the Caffe deep learning framework [13].", "startOffset": 50, "endOffset": 54}, {"referenceID": 11, "context": "We begin our experiments with sMCL on the CIFAR10 [17] dataset using the small convolutional neural network \u201cCIFAR10-Quick\u201d provided with the Caffe deep learning framework [13].", "startOffset": 172, "endOffset": 176}, {"referenceID": 3, "context": "[5] performs worse than independent ensembles as ensemble size grows.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "2 Semantic Segmentation We now present our results for the semantic segmentation task on the Pascal VOC dataset [6].", "startOffset": 112, "endOffset": 115}, {"referenceID": 18, "context": "[20] as our base model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "Like [20], we train on the Pascal VOC 2011 training set augmented with extra segmentations provided in [10] and we test on a subset of the VOC 2011 validation set.", "startOffset": 5, "endOffset": 9}, {"referenceID": 8, "context": "Like [20], we train on the Pascal VOC 2011 training set augmented with extra segmentations provided in [10] and we test on a subset of the VOC 2011 validation set.", "startOffset": 103, "endOffset": 107}, {"referenceID": 3, "context": "sMCL MCL Dey [5] Indp.", "startOffset": 13, "endOffset": 16}, {"referenceID": 3, "context": "[5] saturates more quickly \u2013 resulting in performance worse than classical ensembles as ensemble size grows.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Ensemble Size M O ra cl e M ea n Io U sMCL MCL Dey [5] Indp.", "startOffset": 51, "endOffset": 54}, {"referenceID": 12, "context": "[14], utilizing their publicly available implementation neuraltalk2.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "The model consists of an VGG16 network [4] which encodes the input image as a fixed-length representation for a Long Short-Term Memory (LSTM) language model.", "startOffset": 39, "endOffset": 42}, {"referenceID": 16, "context": "We train and test on the MSCOCO dataset [18], using the same splits as [14].", "startOffset": 40, "endOffset": 44}, {"referenceID": 12, "context": "We train and test on the MSCOCO dataset [18], using the same splits as [14].", "startOffset": 71, "endOffset": 75}, {"referenceID": 12, "context": "We generate sentences for testing by performing beam search with a beam width of two (following [14]).", "startOffset": 96, "endOffset": 100}, {"referenceID": 25, "context": "Table 1 presents the oracle CIDEr-D [28] scores for all methods on the validation set.", "startOffset": 36, "endOffset": 40}, {"referenceID": 6, "context": "21 MCL [8] - 0.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "87 Dey [5] - 0.", "startOffset": 7, "endOffset": 10}], "year": 2016, "abstractText": "Many practical perception systems exist within larger processes that include interactions with users or additional components capable of evaluating the quality of predicted solutions. In these contexts, it is beneficial to provide these oracle mechanisms with multiple highly likely hypotheses rather than a single prediction. In this work, we pose the task of producing multiple outputs as a learning problem over an ensemble of deep networks \u2013 introducing a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle. Our method is simple to implement, agnostic to both architecture and loss function, and parameter-free. Our approach achieves lower oracle error compared to existing methods on a wide range of tasks and deep architectures. We also show qualitatively that the diverse solutions produced often provide interpretable representations of task ambiguity.", "creator": "LaTeX with hyperref package"}}}