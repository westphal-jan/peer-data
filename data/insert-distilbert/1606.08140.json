{"id": "1606.08140", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2016", "title": "STransE: a novel embedding model of entities and relationships in knowledge bases", "abstract": "knowledge bases hundreds of accessible real - world facts about entities and their relationships are useful resources for a nice variety of natural language processing mapping tasks. however, because knowledge bases are often typically incomplete, it is useful to be able to perform link prediction, i. e., predict whether a relationship not fixed in the proposed knowledge base constraint is likely to be true. this classic paper combines insights required from several previous link prediction models into a new embedding model stranse that represents each entity as a low - dimensional vector, and divides each relation by two matrices and a translation vector. graph stranse is a basically simple combination of the se and transe models, but it arguably obtains better link prediction than performance on two benchmark datasets than previous weak embedding models. thus, stranse can serve as a new baseline for the more complex models in the link prediction task.", "histories": [["v1", "Mon, 27 Jun 2016 06:50:10 GMT  (27kb,D)", "https://arxiv.org/abs/1606.08140v1", "Proceedings of NAACL-HLT 2016, pages 460-466. arXiv admin note: text overlap witharXiv:1606.06461"], ["v2", "Thu, 21 Jul 2016 16:24:49 GMT  (27kb,D)", "http://arxiv.org/abs/1606.08140v2", "V1: In Proceedings of NAACL-HLT 2016. V2: Corrected citation to (Krompa{\\ss} et al., 2015)"], ["v3", "Wed, 8 Mar 2017 16:57:40 GMT  (28kb,D)", "http://arxiv.org/abs/1606.08140v3", "V1: In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2016. V2: Corrected citation to (Krompa{\\ss} et al., 2015). V3: A revised version of our NAACL-HLT 2016 paper with additional experimental results and latest related work"]], "COMMENTS": "Proceedings of NAACL-HLT 2016, pages 460-466. arXiv admin note: text overlap witharXiv:1606.06461", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["dat quoc nguyen", "kairit sirts", "lizhen qu", "mark johnson"], "accepted": true, "id": "1606.08140"}, "pdf": {"name": "1606.08140.pdf", "metadata": {"source": "CRF", "title": "STransE: a novel embedding model of entities and relationships in knowledge bases\u2217", "authors": ["Dat Quoc Nguyen", "Kairit Sirts", "Lizhen Qu", "Mark Johnson"], "emails": ["dat.nguyen@students.mq.edu.au,", "mark.johnson}@mq.edu.au", "lizhen.qu@nicta.com.au"], "sections": [{"heading": "1 Introduction", "text": "Knowledge bases (KBs), such as WordNet (Fellbaum, 1998), YAGO (Suchanek et al., 2007), Freebase (Bollacker et al., 2008) and DBpedia (Lehmann et al., 2015), represent relationships between entities as triples (head entity, relation, tail entity). Even very large knowledge bases are still far from complete (Socher et al., 2013; West et al., 2014). Link prediction or knowledge base completion systems (Nickel et al., 2016a) predict which triples not in a knowledge base are likely to be true (Taskar et\n\u2217 A revised version of our NAACL-HLT 2016 paper with additional experimental results and latest related work.\nal., 2004; Bordes et al., 2011). A variety of different kinds of information is potentially useful here, including information extracted from external corpora (Riedel et al., 2013; Wang et al., 2014a) and the other relationships that hold between the entities (Angeli and Manning, 2013; Zhao et al., 2015). For example, Toutanova et al. (2015) used information from the external ClueWeb-12 corpus to significantly enhance performance.\nWhile integrating a wide variety of information sources can produce excellent results (Das et al., 2017), there are several reasons for studying simpler models that directly optimize a score function for the triples in a knowledge base, such as the one presented here. First, additional information sources might not be available, e.g., for knowledge bases for specialized domains. Second, models that don\u2019t exploit external resources are simpler and thus typically much faster to train than the more complex models using additional information. Third, the more complex models that exploit external information are typically extensions of these simpler models, and are often initialized with parameters estimated by such simpler models, so improvements to the simpler models should yield corresponding improvements to the more complex models as well.\nEmbedding models for KB completion associate entities and/or relations with dense feature vectors or matrices. Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al., 2015). Table 1 summarizes a number of prominent embedding\nar X\niv :1\n60 6.\n08 14\n0v 3\n[ cs\n.C L\n] 8\nM ar\nmodels for KB completion. Let (h, r, t) represent a triple. In all of the models discussed here, the head entity h and the tail entity t are represented by vectors h and t \u2208 Rk respectively. The Unstructured model (Bordes et al., 2012) assumes that h \u2248 t. As the Unstructured model does not take the relationship r into account, it cannot distinguish different relation types. The Structured Embedding (SE) model (Bordes et al., 2011) extends the unstructured model by assuming that h and t are similar only in a relation-dependent subspace. It represents each relation r with two matrices Wr,1 and Wr,2 \u2208 Rk\u00d7k, which are chosen so that Wr,1h \u2248 Wr,2t. The TransE model (Bordes et al., 2013) is inspired by models such as Word2Vec (Mikolov et al., 2013) where relationships between words often correspond to translations in latent feature space. The TransE model represents each relation r by a translation vector r \u2208 Rk, which is chosen so that h + r \u2248 t.\nThe primary contribution of this paper is that two very simple relation-prediction models, SE and TransE, can be combined into a single model, which we call STransE.1 Specifically, we use relationspecific matrices Wr,1 and Wr,2 as in the SE model to identify the relation-dependent aspects of both h and t, and use a vector r as in the TransE model to describe the relationship between h and t in this subspace. Specifically, our new KB completion model STransE chooses Wr,1, Wr,2 and r so that\n1Source code: https://github.com/datquocnguyen/STransE\nWr,1h + r \u2248 Wr,2t. That is, a TransE-style relationship holds in some relation-dependent subspace, and crucially, this subspace may involve very different projections of the head h and tail t. So Wr,1 and Wr,2 can highlight, suppress, or even change the sign of, relation-specific attributes of h and t. For example, for the \u201cpurchases\u201d relationship, certain attributes of individuals h (e.g., age, gender, marital status) are presumably strongly correlated with very different attributes of objects t (e.g., sports car, washing machine and the like).\nAs we show below, STransE performs better than the SE and TransE models and other state-of-the-art link prediction models on two standard link prediction datasets WN18 and FB15k, so it can serve as a new baseline for KB completion. We expect that the STransE will also be able to serve as the basis for extended models that exploit a wider variety of information sources, just as TransE does."}, {"heading": "2 Our approach", "text": "Let E denote the set of entities and R the set of relation types. For each triple (h, r, t), where h, t \u2208 E and r \u2208 R, the STransE model defines a score function fr(h, t) of its implausibility. Our goal is to choose f such that the score fr(h, t) of a plausible triple (h, r, t) is smaller than the score fr\u2032(h\u2032, t\u2032) of an implausible triple (h\u2032, r\u2032, t\u2032). We define the STransE score function f as follows:\nfr(h, t) = \u2016Wr,1h + r\u2212Wr,2t\u2016`1/2 using either the `1 or the `2-norm (the choice is made\nusing validation data; in our experiments we found that the `1 norm gave slightly better results). To learn the vectors and matrices we minimize the following margin-based objective function:\nL = \u2211\n(h,r,t)\u2208G (h\u2032,r,t\u2032)\u2208G\u2032\n(h,r,t)\n[\u03b3 + fr(h, t)\u2212 fr(h\u2032, t\u2032)]+\nwhere [x]+ = max(0, x), \u03b3 is the margin hyperparameter, G is the training set consisting of correct triples, and G\u2032(h,r,t) = {(h\n\u2032, r, t) | h\u2032 \u2208 E , (h\u2032, r, t) /\u2208 G} \u222a {(h, r, t\u2032) | t\u2032 \u2208 E , (h, r, t\u2032) /\u2208 G} is the set of incorrect triples generated by corrupting a correct triple (h, r, t) \u2208 G.\nWe use Stochastic Gradient Descent (SGD) to minimize L, and impose the following constraints during training: \u2016h\u20162 6 1, \u2016r\u20162 6 1, \u2016t\u20162 6 1, \u2016Wr,1h\u20162 6 1 and \u2016Wr,2t\u20162 6 1."}, {"heading": "3 Related work", "text": "Table 1 summarizes related embedding models for link prediction and KB completion. The models differ in the score functions fr(h, t) and the algorithms used to optimize the margin-based objective function, e.g., SGD, AdaGrad (Duchi et al., 2011), AdaDelta (Zeiler, 2012) and L-BFGS (Liu and Nocedal, 1989).\nDISTMULT (Yang et al., 2015) is based on a Bilinear model (Nickel et al., 2011; Bordes et al., 2012; Jenatton et al., 2012) where each relation is represented by a diagonal rather than a full matrix. The neural tensor network (NTN) model (Socher et al., 2013) uses a bilinear tensor operator to represent each relation while ProjE (Shi and Weninger, 2017) could be viewed as a simplified version of NTN with diagonal matrices. Similar quadratic forms are used to model entities and relations in KG2E (He et al., 2015), ComplEx (Trouillon et al., 2016), TATEC (Garc\u0131\u0301a-Dura\u0301n et al., 2016) and RSTE (Tay et al., 2017). In addition, HolE (Nickel et al., 2016b) uses circular correlation\u2014a compositional operator\u2014which could be interpreted as a compression of the tensor product.\nThe TransH model (Wang et al., 2014b) associates each relation with a relation-specific hyperplane and uses a projection vector to project entity vectors onto that hyperplane. TransD (Ji et al.,\n2015) and TransR/CTransR (Lin et al., 2015b) extend the TransH model using two projection vectors and a matrix to project entity vectors into a relation-specific space, respectively. TransD learns a relation-role specific mapping just as STransE, but represents this mapping by projection vectors rather than full matrices, as in STransE. The lppTransD model (Yoon et al., 2016) extends TransD to additionally use two projection vectors for representing each relation. In fact, our STransE model and TranSparse (Ji et al., 2016) can be viewed as direct extensions of the TransR model, where head and tail entities are associated with their own projection matrices, rather than using the same matrix for both, as in TransR and CTransR.\nRecently, several authors have shown that relation paths between entities in KBs provide richer information and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dura\u0301n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016). In addition, Nickel et al. (2016a) reviews other approaches for learning from KBs and multi-relational data."}, {"heading": "4 Experiments", "text": "For link prediction evaluation, we conduct experiments and compare the performance of our STransE model with published results on the benchmark WN18 and FB15k datasets (Bordes et al., 2013). Information about these datasets is given in Table 2."}, {"heading": "4.1 Task and evaluation protocol", "text": "The link prediction task (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013) predicts the head or tail entity given the relation type and the other entity, i.e. predicting h given (?, r, t) or predicting t given (h, r, ?) where ? denotes the missing element. The\nresults are evaluated using the ranking induced by the score function fr(h, t) on test triples.\nFor each test triple (h, r, t), we corrupted it by replacing either h or t by each of the possible entities in turn, and then rank these candidates in ascending order of their implausibility value computed by the score function. This is called as the \u201cRaw\u201d setting protocol. For the \u201cFiltered\u201d setting protocol described in Bordes et al. (2013), we removed any corrupted triples that appear in the knowledge base, to avoid cases where a correct corrupted triple might be ranked higher than the test triple. The \u201cFiltered\u201d setting thus provides a clearer view on the ranking performance. Following Bordes et al. (2013), we report the mean rank and the Hits@10 (i.e., the proportion of test triples in which the target entity was ranked in the top 10 predictions) for each model. In addition, we report the mean reciprocal rank, which is commonly used in information retrieval. In both \u201cRaw\u201d and \u201cFiltered\u201d settings, lower mean rank, higher mean reciprocal rank or higher Hits@10 indicates better link prediction performance. Following TransR (Lin et al., 2015b), TransD (Ji et al., 2015), RTransE (Garc\u0131\u0301a-Dura\u0301n et al., 2015), PTransE (Lin et al., 2015a), TATEC (Garc\u0131\u0301a-Dura\u0301n et al., 2016) and TranSparse (Ji et al., 2016), we used the entity and relation vectors produced by TransE (Bordes et al., 2013) to initialize the entity and relation vectors in STransE, and we initialized the relation matrices with identity matrices. We applied the \u201cBernoulli\u201d trick used also in previous work for generating head or tail entities when sampling incorrect triples (Wang et al., 2014b; Lin et al., 2015b; He et al., 2015; Ji et al., 2015; Lin et al., 2015a; Yoon et al., 2016; Ji et al., 2016). We ran SGD for 2,000 epochs to estimate the model parameters. Following Bordes et al. (2013) we used a grid search on validation set to choose either the l1 or l2 norm in the score function f , as well as to set the SGD learning rate \u03bb \u2208 {0.0001, 0.0005, 0.001, 0.005, 0.01}, the margin hyper-parameter \u03b3 \u2208 {1, 3, 5} and the vector size k \u2208 {50, 100}. The lowest filtered mean rank on the validation set was obtained when using the l1 norm in f on both WN18 and FB15k, and when\n\u03bb = 0.0005, \u03b3 = 5, and k = 50 for WN18, and \u03bb = 0.0001, \u03b3 = 1, and k = 100 for FB15k."}, {"heading": "4.2 Main results", "text": "Table 3 compares the link prediction results of our STransE model with results reported in prior work, using the same experimental setup. The first 15 rows report the performance of the models that do not exploit information about alternative paths between head and tail entities. The next 5 rows report results of the models that exploit information about relation paths. The last 3 rows present results for the models which make use of textual mentions derived from a large external corpus.\nIt is clear that the models with the additional external corpus information obtained best results. In future work we plan to extend the STransE model to incorporate such additional information. Table 3 also shows that the models employing path information generally achieve better results than models that do not use such information. In terms of models not exploiting path information or external information, the STransE model produces the highest filtered mean rank on WN18 and the highest filtered Hits@10 and mean reciprocal rank on FB15k. Compared to the closely related models SE, TransE, TransR, CTransR, TransD and TranSparse, our STransE model does better than these models on both WN18 and FB15k.\nFollowing Bordes et al. (2013), Table 4 analyzes Hits@10 results on FB15k with respect to the relation categories defined as follows: for each relation type r, we computed the averaged number ah of heads h for a pair (r, t) and the averaged number at of tails t for a pair (h, r). If ah < 1.5 and at < 1.5, then r is labeled 1-1. If ah \u2265 1.5 and at < 1.5, then r is labeled M-1. If ah < 1.5 and at \u2265 1.5, then r is labeled as 1-M. If ah \u2265 1.5 and at \u2265 1.5, then r is labeled as M-M. 1.4%, 8.9%, 14.6% and 75.1% of the test triples belong to a relation type classified as 1-1, 1-M, M-1 and M-M, respectively.\nTable 4 shows that in comparison to prior models not using path information, STransE obtains the second highest Hits@10 result for M-M relation category at (80.1% + 83.1%)/2 = 81.6% which is 0.5% smaller than the Hits@10 result of TranSparse for M-M. However, STransE obtains 2.5% higher Hits@10 result than TranSparse for M-1. In addi-\ntion, STransE also performs better than TransD for 1-M and M-1 relation categories. We believe the improved performance of the STransE model is due to its use of full matrices, rather than just projection vectors as in TransD. This permits STransE to model diverse and complex relation categories (such as 1- M, M-1 and especially M-M) better than TransD and other similiar models. However, STransE is not as good as TransD for the 1-1 relations. Perhaps the extra parameters in STransE hurt performance in this case (note that 1-1 relations are relatively rare, so STransE does better overall)."}, {"heading": "5 Conclusion and future work", "text": "This paper presented a new embedding model for link prediction and KB completion. Our STransE combines insights from several simpler embedding models, specifically the Structured Embedding model (Bordes et al., 2011) and the TransE model (Bordes et al., 2013), by using a low-dimensional vector and two projection matrices to represent each relation. STransE, while being conceptually simple, produces highly competitive results on standard link prediction evaluations, and scores better than the embedding-based models it builds on. Thus it is a suitable candidate for serving as future baseline for more complex models in the link prediction task.\nIn future work we plan to extend STransE to exploit relation path information in knowledge bases, in a manner similar to Lin et al. (2015a), Guu et al. (2015) or Nguyen et al. (2016)."}, {"heading": "Acknowledgments", "text": "This research was supported by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Council\u2019s Discovery Projects funding scheme (project number DP160102156).\nNICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program. The first author is supported by an International Postgraduate Research Scholarship and a NICTA NRPA Top-Up Scholarship."}], "references": [{"title": "Philosophers are Mortal: Inferring the Truth of Unseen Facts", "author": ["Angeli", "Manning2013] Gabor Angeli", "Christopher Manning"], "venue": "In Proceedings of the Seventeenth Conference on Computational Natural Language Learning,", "citeRegEx": "Angeli et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Angeli et al\\.", "year": 2013}, {"title": "Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD Interna-", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Learning Structured Embeddings of Knowledge Bases", "author": ["Jason Weston", "Ronan Collobert", "Yoshua Bengio"], "venue": "In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Bordes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "A Semantic Matching Energy Function for Learning with Multirelational Data", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "Machine Learning,", "citeRegEx": "Bordes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2012}, {"title": "Translating Embeddings for Modeling Multi-relational Data", "author": ["Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Chains of reasoning over entities, relations, and text using recurrent neural networks", "author": ["Das et al.2017] Rajarshi Das", "Arvind Neelakantan", "David Belanger", "Andrew McCallum"], "venue": "In Proceedings of the 15th Conference of the European Chapter", "citeRegEx": "Das et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Das et al\\.", "year": 2017}, {"title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "author": ["Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "WordNet: An Electronic Lexical Database", "author": ["Christiane D. Fellbaum"], "venue": null, "citeRegEx": "Fellbaum.,? \\Q1998\\E", "shortCiteRegEx": "Fellbaum.", "year": 1998}, {"title": "GAKE: Graph Aware Knowledge Embedding", "author": ["Feng et al.2016] Jun Feng", "Minlie Huang", "Yang Yang", "xiaoyan zhu"], "venue": "In Proceedings of COLING 2016,", "citeRegEx": "Feng et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2016}, {"title": "Composing Relationships with Translations", "author": ["Antoine Bordes", "Nicolas Usunier"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Garc\u0131\u0301a.Dur\u00e1n et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Garc\u0131\u0301a.Dur\u00e1n et al\\.", "year": 2015}, {"title": "Combining Two and Three-Way Embedding Models for Link Prediction in Knowledge Bases", "author": ["Antoine Bordes", "Nicolas Usunier", "Yves Grandvalet"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Garc\u0131\u0301a.Dur\u00e1n et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Garc\u0131\u0301a.Dur\u00e1n et al\\.", "year": 2016}, {"title": "Traversing Knowledge Graphs in Vector Space", "author": ["Guu et al.2015] Kelvin Guu", "John Miller", "Percy Liang"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Guu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guu et al\\.", "year": 2015}, {"title": "Learning to Represent Knowledge Graphs with Gaussian Embedding", "author": ["He et al.2015] Shizhu He", "Kang Liu", "Guoliang Ji", "Jun Zhao"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "A latent factor model for highly multi-relational data", "author": ["Nicolas L. Roux", "Antoine Bordes", "Guillaume R Obozinski"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jenatton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2012}, {"title": "Knowledge Graph Embedding via Dynamic Mapping Matrix", "author": ["Ji et al.2015] Guoliang Ji", "Shizhu He", "Liheng Xu", "Kang Liu", "Jun Zhao"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Ji et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2015}, {"title": "Knowledge Graph Completion with Adaptive Sparse Transfer Matrix", "author": ["Ji et al.2016] Guoliang Ji", "Kang Liu", "Shizhu He", "Jun Zhao"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Ji et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2016}, {"title": "Type-Constrained Representation Learning in Knowledge Graphs", "author": ["Stephan Baier", "Volker Tresp"], "venue": "In Proceedings of the 14th International Semantic Web Conference,", "citeRegEx": "Krompa\u00df et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Krompa\u00df et al\\.", "year": 2015}, {"title": "DBpedia - A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia", "author": ["Patrick van Kleef", "S\u00f6ren Auer", "Christian Bizer."], "venue": "Semantic Web, 6(2):167\u2013195.", "citeRegEx": "Kleef et al\\.,? 2015", "shortCiteRegEx": "Kleef et al\\.", "year": 2015}, {"title": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "author": ["Lin et al.2015a] Yankai Lin", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun", "Siwei Rao", "Song Liu"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Learning Entity and Relation Embeddings for Knowledge Graph Completion", "author": ["Lin et al.2015b] Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu"], "venue": "In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "On the Limited Memory BFGS Method for Large Scale Optimization", "author": ["Liu", "Nocedal1989] D.C. Liu", "J. Nocedal"], "venue": "Mathematical Programming,", "citeRegEx": "Liu et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Liu et al\\.", "year": 1989}, {"title": "Hierarchical Random Walk Inference in Knowledge Graphs", "author": ["Liu et al.2016] Qiao Liu", "Liuyi Jiang", "Minghao Han", "Yao Liu", "Zhiguang Qin"], "venue": "In Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Liu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Linguistic Regularities in Continuous Space Word Representations", "author": ["Wen-tau Yih", "Geoffrey Zweig"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguis-", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Neighborhood Mixture Model for Knowledge Base Completion", "author": ["Kairit Sirts", "Lizhen Qu", "Mark Johnson"], "venue": "In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning,", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "A Three-Way Model for Collective Learning on Multi-Relational Data", "author": ["Volker Tresp", "Hans-Peter Kriegel"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Nickel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2011}, {"title": "2016a. A Review of Relational Machine Learning for Knowledge Graphs", "author": ["Kevin Murphy", "Volker Tresp", "Evgeniy Gabrilovich"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Nickel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2016}, {"title": "Holographic embeddings of knowledge graphs", "author": ["Lorenzo Rosasco", "Tomaso Poggio"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Nickel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2016}, {"title": "Discriminative Gaifman Models", "author": ["Mathias Niepert"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Niepert.,? \\Q2016\\E", "shortCiteRegEx": "Niepert.", "year": 2016}, {"title": "Relation Extraction with Matrix Factorization and Universal Schemas", "author": ["Limin Yao", "Andrew McCallum", "Benjamin M. Marlin"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association", "citeRegEx": "Riedel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2013}, {"title": "ProjE: Embedding Projection for Knowledge Graph Completion", "author": ["Shi", "Weninger2017] Baoxu Shi", "Tim Weninger"], "venue": "In Proceedings of the 31st AAAI Conference on Artificial Intelligence", "citeRegEx": "Shi et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Shi et al\\.", "year": 2017}, {"title": "Reasoning With Neural Tensor Networks for Knowledge Base Completion", "author": ["Danqi Chen", "Christopher D Manning", "Andrew Ng"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "YAGO: A Core of Semantic Knowledge", "author": ["Gjergji Kasneci", "Gerhard Weikum"], "venue": "In Proceedings of the 16th International Conference on World Wide Web,", "citeRegEx": "Suchanek et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Suchanek et al\\.", "year": 2007}, {"title": "Link Prediction in Relational Data", "author": ["Taskar et al.2004] Ben Taskar", "Ming fai Wong", "Pieter Abbeel", "Daphne Koller"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Taskar et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Taskar et al\\.", "year": 2004}, {"title": "Random Semantic Tensor Ensemble for Scalable Knowledge Graph Link Prediction", "author": ["Tay et al.2017] Yi Tay", "Anh Tuan Luu", "Siu Cheung Hui", "Falk Brauer"], "venue": "In Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,", "citeRegEx": "Tay et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Tay et al\\.", "year": 2017}, {"title": "Observed Versus Latent Features for Knowledge Base and Text Inference", "author": ["Toutanova", "Chen2015] Kristina Toutanova", "Danqi Chen"], "venue": "In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality,", "citeRegEx": "Toutanova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "Representing Text for Joint Embedding of Text and Knowledge Bases", "author": ["Danqi Chen", "Patrick Pantel", "Hoifung Poon", "Pallavi Choudhury", "Michael Gamon"], "venue": "In Proceedings of the 2015 Conference on Empirical Meth-", "citeRegEx": "Toutanova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "Compositional Learning of Embeddings for Relation Paths in Knowledge Base and Text", "author": ["Victoria Lin", "Wen-tau Yih", "Hoifung Poon", "Chris Quirk"], "venue": "In Proceedings of the 54th Annual Meeting of the Association", "citeRegEx": "Toutanova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2016}, {"title": "Complex Embeddings for Simple", "author": ["Johannes Welbl", "Sebastian Riedel", "\u00c9ric Gaussier", "Guillaume Bouchard"], "venue": null, "citeRegEx": "Trouillon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Trouillon et al\\.", "year": 2016}, {"title": "Text-Enhanced Representation Learning for Knowledge Graph", "author": ["Wang", "Li2016] Zhigang Wang", "Juan-Zi Li"], "venue": "In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Knowledge Graph and Text Jointly Embedding", "author": ["Wang et al.2014a] Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Knowledge Graph Embedding by Translating on Hyperplanes", "author": ["Wang et al.2014b] Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Knowledge Base Completion via Coupled Path Ranking", "author": ["Wang et al.2016] Quan Wang", "Jing Liu", "Yuanfei Luo", "Bin Wang", "Chin-Yew Lin"], "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Mining Inference Formulas by Goal-Directed Random Walks", "author": ["Wei et al.2016] Zhuoyu Wei", "Jun Zhao", "Kang Liu"], "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Wei et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2016}, {"title": "Knowledge Base Completion via Search-based Question Answering", "author": ["West et al.2014] Robert West", "Evgeniy Gabrilovich", "Kevin Murphy", "Shaohua Sun", "Rahul Gupta", "Dekang Lin"], "venue": "In Proceedings of the 23rd International Conference on World Wide Web,", "citeRegEx": "West et al\\.,? \\Q2014\\E", "shortCiteRegEx": "West et al\\.", "year": 2014}, {"title": "SSP: semantic space projection for knowledge graph embedding with text descriptions", "author": ["Xiao et al.2017] Han Xiao", "Minlie Huang", "Xiaoyan Zhu"], "venue": "In Proceedings of the 31st AAAI Conference on Artificial Intelligence", "citeRegEx": "Xiao et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Xiao et al\\.", "year": 2017}, {"title": "Embedding Entities and Relations for Learning and Inference in Knowledge Bases", "author": ["Yang et al.2015] Bishan Yang", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng"], "venue": "In Proceedings of the International Conference on Learning Representations", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "A TranslationBased Knowledge Graph Embedding Preserving Logical Property of Relations", "author": ["Yoon et al.2016] Hee-Geun Yoon", "Hyun-Je Song", "SeongBae Park", "Se-Young Park"], "venue": "In Proceedings of the 2016 Conference of the North American Chapter of the As-", "citeRegEx": "Yoon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yoon et al\\.", "year": 2016}, {"title": "ADADELTA: An Adaptive Learning Rate Method. CoRR, abs/1212.5701", "author": ["Matthew D. Zeiler"], "venue": null, "citeRegEx": "Zeiler.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "Knowledge Base Completion by Learning Pairwise-Interaction Differentiated Embeddings. Data Mining and Knowledge Discovery, 29(5):1486\u20131504", "author": ["Zhao et al.2015] Yu Zhao", "Sheng Gao", "Patrick Gallinari", "Jun Guo"], "venue": null, "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "Knowledge bases (KBs), such as WordNet (Fellbaum, 1998), YAGO (Suchanek et al.", "startOffset": 39, "endOffset": 55}, {"referenceID": 31, "context": "Knowledge bases (KBs), such as WordNet (Fellbaum, 1998), YAGO (Suchanek et al., 2007), Freebase (Bollacker et al.", "startOffset": 62, "endOffset": 85}, {"referenceID": 1, "context": ", 2007), Freebase (Bollacker et al., 2008) and DBpedia (Lehmann et al.", "startOffset": 18, "endOffset": 42}, {"referenceID": 30, "context": "Even very large knowledge bases are still far from complete (Socher et al., 2013; West et al., 2014).", "startOffset": 60, "endOffset": 100}, {"referenceID": 43, "context": "Even very large knowledge bases are still far from complete (Socher et al., 2013; West et al., 2014).", "startOffset": 60, "endOffset": 100}, {"referenceID": 28, "context": "A variety of different kinds of information is potentially useful here, including information extracted from external corpora (Riedel et al., 2013; Wang et al., 2014a) and", "startOffset": 126, "endOffset": 167}, {"referenceID": 48, "context": "the other relationships that hold between the entities (Angeli and Manning, 2013; Zhao et al., 2015).", "startOffset": 55, "endOffset": 100}, {"referenceID": 34, "context": "For example, Toutanova et al. (2015) used information from the external ClueWeb-12 corpus to significantly enhance performance.", "startOffset": 13, "endOffset": 37}, {"referenceID": 5, "context": "sources can produce excellent results (Das et al., 2017), there are several reasons for studying simpler models that directly optimize a score function for the triples in a knowledge base, such as the one presented here.", "startOffset": 38, "endOffset": 56}, {"referenceID": 24, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 2, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 3, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 4, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 30, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 11, "context": "Such models obtain state-of-the-art performance (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014b; Guu et al., 2015) and generalize to large KBs (Krompa\u00df et al.", "startOffset": 48, "endOffset": 191}, {"referenceID": 16, "context": ", 2015) and generalize to large KBs (Krompa\u00df et al., 2015).", "startOffset": 36, "endOffset": 58}, {"referenceID": 3, "context": "The Unstructured model (Bordes et al., 2012) assumes that h \u2248 t.", "startOffset": 23, "endOffset": 44}, {"referenceID": 2, "context": "tured Embedding (SE) model (Bordes et al., 2011) extends the unstructured model by assuming that h and t are similar only in a relation-dependent subspace.", "startOffset": 27, "endOffset": 48}, {"referenceID": 4, "context": "The TransE model (Bordes et al., 2013) is inspired by models such as Word2Vec (Mikolov et al.", "startOffset": 17, "endOffset": 38}, {"referenceID": 22, "context": ", 2013) is inspired by models such as Word2Vec (Mikolov et al., 2013) where relationships between words often correspond to translations in latent feature space.", "startOffset": 47, "endOffset": 69}, {"referenceID": 6, "context": ", SGD, AdaGrad (Duchi et al., 2011),", "startOffset": 15, "endOffset": 35}, {"referenceID": 47, "context": "AdaDelta (Zeiler, 2012) and L-BFGS (Liu and Nocedal, 1989).", "startOffset": 9, "endOffset": 23}, {"referenceID": 45, "context": "DISTMULT (Yang et al., 2015) is based on a Bilinear model (Nickel et al.", "startOffset": 9, "endOffset": 28}, {"referenceID": 24, "context": ", 2015) is based on a Bilinear model (Nickel et al., 2011; Bordes et al., 2012; Jenatton et al., 2012) where each relation is", "startOffset": 37, "endOffset": 102}, {"referenceID": 3, "context": ", 2015) is based on a Bilinear model (Nickel et al., 2011; Bordes et al., 2012; Jenatton et al., 2012) where each relation is", "startOffset": 37, "endOffset": 102}, {"referenceID": 13, "context": ", 2015) is based on a Bilinear model (Nickel et al., 2011; Bordes et al., 2012; Jenatton et al., 2012) where each relation is", "startOffset": 37, "endOffset": 102}, {"referenceID": 30, "context": "The neural tensor network (NTN) model (Socher et al., 2013) uses a bilinear tensor operator to represent each relation while ProjE (Shi and Weninger, 2017) could be viewed as a simplified version of NTN with diagonal matrices.", "startOffset": 38, "endOffset": 59}, {"referenceID": 12, "context": "Similar quadratic forms are used to model entities and relations in KG2E (He et al., 2015), ComplEx (Trouillon et al.", "startOffset": 73, "endOffset": 90}, {"referenceID": 37, "context": ", 2015), ComplEx (Trouillon et al., 2016), TATEC (Garc\u0131\u0301a-Dur\u00e1n et al.", "startOffset": 17, "endOffset": 41}, {"referenceID": 10, "context": ", 2016), TATEC (Garc\u0131\u0301a-Dur\u00e1n et al., 2016) and RSTE (Tay et al.", "startOffset": 15, "endOffset": 43}, {"referenceID": 33, "context": ", 2016) and RSTE (Tay et al., 2017).", "startOffset": 17, "endOffset": 35}, {"referenceID": 14, "context": "TransD (Ji et al., 2015) and TransR/CTransR (Lin et al.", "startOffset": 7, "endOffset": 24}, {"referenceID": 46, "context": "The lppTransD model (Yoon et al., 2016) extends TransD to additionally use two projection vectors for representing each relation.", "startOffset": 20, "endOffset": 39}, {"referenceID": 15, "context": "In fact, our STransE model and TranSparse (Ji et al., 2016) can be viewed as direct", "startOffset": 42, "endOffset": 59}, {"referenceID": 9, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 11, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 38, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 8, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 21, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 27, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 42, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 36, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 23, "context": "mation and improve the relationship prediction (Lin et al., 2015a; Garc\u0131\u0301a-Dur\u00e1n et al., 2015; Guu et al., 2015; Wang et al., 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016).", "startOffset": 47, "endOffset": 246}, {"referenceID": 8, "context": ", 2016; Feng et al., 2016; Liu et al., 2016; Niepert, 2016; Wei et al., 2016; Toutanova et al., 2016; Nguyen et al., 2016). In addition, Nickel et al. (2016a) reviews other approaches for learning", "startOffset": 8, "endOffset": 159}, {"referenceID": 4, "context": "model with published results on the benchmark WN18 and FB15k datasets (Bordes et al., 2013).", "startOffset": 70, "endOffset": 91}, {"referenceID": 2, "context": "The link prediction task (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013) predicts the head or tail entity given the relation type and the other entity, i.", "startOffset": 25, "endOffset": 88}, {"referenceID": 3, "context": "The link prediction task (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013) predicts the head or tail entity given the relation type and the other entity, i.", "startOffset": 25, "endOffset": 88}, {"referenceID": 4, "context": "The link prediction task (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013) predicts the head or tail entity given the relation type and the other entity, i.", "startOffset": 25, "endOffset": 88}, {"referenceID": 2, "context": "SE (Bordes et al., 2011) 1011 68.", "startOffset": 3, "endOffset": 24}, {"referenceID": 3, "context": "8 Unstructured (Bordes et al., 2012) 315 35.", "startOffset": 15, "endOffset": 36}, {"referenceID": 4, "context": "TransE (Bordes et al., 2013) 263 75.", "startOffset": 7, "endOffset": 28}, {"referenceID": 12, "context": "2 KG2E (He et al., 2015) 342 80.", "startOffset": 7, "endOffset": 24}, {"referenceID": 14, "context": "TransD (Ji et al., 2015) 224 79.", "startOffset": 7, "endOffset": 24}, {"referenceID": 46, "context": "3 lppTransD (Yoon et al., 2016) 283 80.", "startOffset": 12, "endOffset": 31}, {"referenceID": 15, "context": "7 TranSparse (Ji et al., 2016) 223 80.", "startOffset": 13, "endOffset": 30}, {"referenceID": 10, "context": "5 TATEC (Garc\u0131\u0301a-Dur\u00e1n et al., 2016) - - - - - - - - - 58 76.", "startOffset": 8, "endOffset": 36}, {"referenceID": 30, "context": "7 NTN (Socher et al., 2013) - - - - - - - 66.", "startOffset": 6, "endOffset": 27}, {"referenceID": 45, "context": "25 DISTMULT (Yang et al., 2015) - - - - - - - 94.", "startOffset": 12, "endOffset": 31}, {"referenceID": 9, "context": "RTransE (Garc\u0131\u0301a-Dur\u00e1n et al., 2015) - - - - - - - - - 50 76.", "startOffset": 8, "endOffset": 36}, {"referenceID": 8, "context": "6 GAKE (Feng et al., 2016) - - - 228 44.", "startOffset": 7, "endOffset": 26}, {"referenceID": 27, "context": "8 Gaifman (Niepert, 2016) - - - - - - 352 93.", "startOffset": 10, "endOffset": 25}, {"referenceID": 21, "context": "2 Hiri (Liu et al., 2016) - - - - - - - 90.", "startOffset": 7, "endOffset": 25}, {"referenceID": 44, "context": "0 SSP (Xiao et al., 2017) 168 81.", "startOffset": 6, "endOffset": 25}, {"referenceID": 30, "context": "The results for NTN (Socher et al., 2013)", "startOffset": 20, "endOffset": 41}, {"referenceID": 45, "context": "listed in this table are taken from Yang et al. (2015) since NTN was originally evaluated on different datasets.", "startOffset": 36, "endOffset": 55}, {"referenceID": 2, "context": "For the \u201cFiltered\u201d setting protocol described in Bordes et al. (2013), we removed any corrupted triples that appear in the knowledge base, to avoid cases where a correct corrupted triple might be ranked higher than the test triple.", "startOffset": 49, "endOffset": 70}, {"referenceID": 2, "context": "For the \u201cFiltered\u201d setting protocol described in Bordes et al. (2013), we removed any corrupted triples that appear in the knowledge base, to avoid cases where a correct corrupted triple might be ranked higher than the test triple. The \u201cFiltered\u201d setting thus provides a clearer view on the ranking performance. Following Bordes et al. (2013), we report the mean rank and the Hits@10 (i.", "startOffset": 49, "endOffset": 343}, {"referenceID": 14, "context": ", 2015b), TransD (Ji et al., 2015), RTransE (Garc\u0131\u0301a-Dur\u00e1n et al.", "startOffset": 17, "endOffset": 34}, {"referenceID": 9, "context": ", 2015), RTransE (Garc\u0131\u0301a-Dur\u00e1n et al., 2015), PTransE (Lin et al.", "startOffset": 17, "endOffset": 45}, {"referenceID": 15, "context": ", 2016) and TranSparse (Ji et al., 2016), we used the entity and relation vectors produced by TransE (Bordes et al.", "startOffset": 23, "endOffset": 40}, {"referenceID": 4, "context": ", 2016), we used the entity and relation vectors produced by TransE (Bordes et al., 2013) to initialize the entity and relation vectors in STransE, and we initialized the relation matrices with identity matrices.", "startOffset": 68, "endOffset": 89}, {"referenceID": 12, "context": "generating head or tail entities when sampling incorrect triples (Wang et al., 2014b; Lin et al., 2015b; He et al., 2015; Ji et al., 2015; Lin et al., 2015a; Yoon et al., 2016; Ji et al., 2016).", "startOffset": 65, "endOffset": 193}, {"referenceID": 14, "context": "generating head or tail entities when sampling incorrect triples (Wang et al., 2014b; Lin et al., 2015b; He et al., 2015; Ji et al., 2015; Lin et al., 2015a; Yoon et al., 2016; Ji et al., 2016).", "startOffset": 65, "endOffset": 193}, {"referenceID": 46, "context": "generating head or tail entities when sampling incorrect triples (Wang et al., 2014b; Lin et al., 2015b; He et al., 2015; Ji et al., 2015; Lin et al., 2015a; Yoon et al., 2016; Ji et al., 2016).", "startOffset": 65, "endOffset": 193}, {"referenceID": 15, "context": "generating head or tail entities when sampling incorrect triples (Wang et al., 2014b; Lin et al., 2015b; He et al., 2015; Ji et al., 2015; Lin et al., 2015a; Yoon et al., 2016; Ji et al., 2016).", "startOffset": 65, "endOffset": 193}, {"referenceID": 2, "context": "Following Bordes et al. (2013) we used a grid search on validation set to choose either the l1 or l2 norm in the score function f , as well as to set the SGD learning rate \u03bb \u2208 {0.", "startOffset": 10, "endOffset": 31}, {"referenceID": 2, "context": "Following Bordes et al. (2013), Table 4 analyzes", "startOffset": 10, "endOffset": 31}, {"referenceID": 2, "context": "combines insights from several simpler embedding models, specifically the Structured Embedding model (Bordes et al., 2011) and the TransE model (Bordes et al.", "startOffset": 101, "endOffset": 122}, {"referenceID": 4, "context": ", 2011) and the TransE model (Bordes et al., 2013), by using a low-dimensional vector and two projection matrices to represent each relation.", "startOffset": 29, "endOffset": 50}, {"referenceID": 17, "context": "in a manner similar to Lin et al. (2015a), Guu et al.", "startOffset": 23, "endOffset": 42}, {"referenceID": 11, "context": "(2015a), Guu et al. (2015) or Nguyen et al.", "startOffset": 9, "endOffset": 27}, {"referenceID": 11, "context": "(2015a), Guu et al. (2015) or Nguyen et al. (2016).", "startOffset": 9, "endOffset": 51}], "year": 2017, "abstractText": "Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform link prediction or knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This paper combines insights from several previous link prediction models into a new embedding model STransE that represents each entity as a low-dimensional vector, and each relation by two matrices and a translation vector. STransE is a simple combination of the SE and TransE models, but it obtains better link prediction performance on two benchmark datasets than previous embedding models. Thus, STransE can serve as a new baseline for the more complex models in the link prediction task.", "creator": "LaTeX with hyperref package"}}}