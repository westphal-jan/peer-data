{"id": "1607.00186", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2016", "title": "Throwing fuel on the embers: Probability or Dichotomy, Cognitive or Linguistic?", "abstract": "prof. robert berwick's abstract for his forthcoming invited keynote talk at the acl2016 workshop on cognitive brain aspects of computational language learning revives an ancient debate. entitled \" why take a meaningful chance? \", berwick seems to refer implicitly to irving chomsky's critique of the statistical statistical approach of harris as well well as the currently dominant paradigms demonstrated in conll.", "histories": [["v1", "Fri, 1 Jul 2016 10:01:11 GMT  (30kb)", "http://arxiv.org/abs/1607.00186v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["david m w powers"], "accepted": false, "id": "1607.00186"}, "pdf": {"name": "1607.00186.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["David.Powers@flinders.edu.au"], "sections": [{"heading": null, "text": "ar X\niv :1\n60 7.\n00 18\n6v 1\n[ cs\n.C L\n] 1\nJ ul\n2 01\n6\nBerwick avoids Chomsky\u2019s use of \u201cinnate\u201d but states that \u201cthe debate over the existence of sophisticated mental grammars was settled with Chomsky\u2019s Logical Structure of Linguistic Theory (1957/1975)\u201d, acknowledging that \u201cthis debate has often been revived\u201d. Berwick does not in his abstract mention Gold\u2019s concerns about what it means to learn a language, or his concept of \u201cLanguage Identification in the Limit\u201d which is often juxtaposed against the idea of \u201cProbably Approximately Correct\u201d, but Berwick specifically questions the counterargument that \u201cdifferences in acceptability judgements can be closely approximated ... from probabilistic accounts\u201d. We discuss his recent critique of computational experiments that show acceptability judgements correlating with probabilities from simple computational models.\nThis paper agrees with the view that this debate has long since been settled, but with the opposite outcome! Given the embers have not yet died away, and the questions remain fundamental, perhaps it is appropriate to refuel the debate, so I would like to join Bob in throwing fuel on this fire!"}, {"heading": "1 Introduction", "text": "In a recent paper at GLOW16 and an invited talk to be given at CACLL, Berwick et al. (2016ab) make the strong claim that \u201cdebate of the existence of sophisticated mental grammars was settled with Chomsky\u2019s The Logical Structure of Linguistic Theory (1957/1975)... But this debate has often been revived.\u201d Yet if it has been \u201csettled\u201d that begs the question of why it keeps being \u201crevived\u201d. This conundrum reflects different views of the nature of science, and the nature of learning and cognition, as much as the nature of language.\nThe reason for these divergent views of the history of the theory of language learning may relate to the shifting ground on which the battle has been fought. In fact, it is not even clear whether the focus of the debate is what is innate, what is modular, what is universal, what is recursive, \u201cgradience\u201d of grammaticality, or validity of theories captured in terms of three letter acronyms: LAD, PoS, TGG, EST, P&P, G&B, etc.\nBut then there is also Chomsky\u2019s own (1986/1991/1993/1995) \u201cMinimalist Program\u201d (MP). Chomsky doesn\u2019t regard things as settled by his 1957-75 work and specifically critiques it. Of further concern is the frequent explanation that \u201cevolution did it\u201d or, more tongue-in-cheek, \u201cGod does it on Tuesdays\u201d(Fodor in Piatelli-Palmarini, 1979). For Computer Scientists and Computational Linguists, evolutionary and genetic methods are weak members of a broader set of Machine Learning algorithms. Claiming something cannot be learned with the full power of the machine learning arsenal, but has been learned with just the weaker evolutionary techniques, is oxymoronic. Alternatively it can be viewed as contradicting either the Church-Turing thesis or the assumption that the human brain is some kind of machine."}, {"heading": "2 Poverty of Science", "text": "While Pinker (1984, 1994, 1997) adheres to the Chomskian paradigm, defending an innate specialized modular account of our language capacity, he treats our scientific capacity within the same framework, thus making both our language and science evolutionary artefacts rather than ways to model the world. This blurs the distinction between folk biology/psychology/theory and science unless by applying this limited rationality we have managed to develop sound logics for argumentation, as perhaps expressed in formal mathematics, learning algorithms, and falsificationist accounts of science. Carruthers et al. (2002/2004) set out to explore the Pinker account and discount his negative conclusions about science. What distinguishes folk science from real science is that there is a logic of proof that requires evidence, while evidence that led to formation of our hypotheses, even unconsciously, or training data that was used to learn a model, even indirectly, cannot be used as evidence in support of a theory. This is particularly a problem for evolutionary theory.\nNagel (2012, p4) states: \u201cI would like to defend the untutored reaction of incredulity to the reductionist neo-Darwinian account of the origin and evolution of life... What is lacking... is a credible argument that the story has a nonnegligible probability of being true.\u201d Ironically some proponents of evolutionary accounts seem religious in reliance on prior beliefs and neglect of their status as assumptions or hypotheses, and Nagel seeks to find a dualist middle between religious extremes.\nThe issue is forgoing the scientific discipline of providing refutable predictions of the theory (Popper,1934/1959; Lakatos,1970,1976,1978ab). That is, an evolutionary just-so \u201cstory\u201d (Nagel,2012) or \u201cmyth\u201d (Popper,1963) is not sufficient in \u201cmaterialist naturalism\u201d or \u201creductionism\u201d or \u201cempiricism\u201d (Nagel,2012,p13f; Popper,1934,1965), the basis of the modern scientific revolution that goes back to Galileo and Descartes and explicitly leaves out appeals to human perception and intention (Nagel,2012,p35). Indeed Chomsky (1995) now avoids the word \u201ctheory\u201d for his Minimalist Program. Use of the word \u201cprogram\u201d following Lakatos (1970) implies a base of \u201cminimal\u201d \u201chard core\u201d assumptions that are assumed but not subject to falsification, which are assumed along with further auxiliary hypotheses that are subject to change in response to empirical evidence."}, {"heading": "3 Poverty of Evolution", "text": "It is clearly difficult to make provable predictions for evolutionary theories - Darwin\u2019s theory was an example of pseudoscience in Lakatos (1970). But there are ways, and in particular we can adopt the computational metaphor and treat evolution as an algorithm . To provide support for LAD versus its alternatives, its predictions need to differ from those that derive from alternate models of language acquisition, development and emergence, such as those provided by Cognitive Linguistics. A Computational Cognitive Linguistics model proposes mechanisms based on ideas of similarity (metaphor) within and across modalities (Powers,1997) that are important for survival (fitness) and which also predict other higher level phenomena (analogy, metaphor, metonymy, etc.), and provide accounts for superstitions and illusions. Chomsky (Piatelli-Palmarini, M., 1979) refused to be drawn on how \u201cevolution\u201d achieved his LAD, saying it was not his job as a linguist, which is divorcing linguistics from science.\nComputational Intelligence split off historically from Artificial Intelligence over inclusion of such \u2018non-logical\u2019 algorithms in our arsenal, although today evolutionary and genetic techniques, as well as others modeled on colonies, swarms, etc. are used regularly across individuals in combination with adaptive learning within the individual to try to develop the appropriate structure for behavioural learning that will maximize the fitness of the individual in the environment. Often this is done without forcing a strict non-communication of learned information to descendants as enshrined in both pre-genetic evolutionary theory (life before genes) and neo-Darwinian Mendelian evolutionary theory (strictly speaking genetic models).\nWhile excluded by Cartesian science (Nagel, 2012), Beliefs, Desires and Intentions (BDI) are specifically brought back in by a dominant approach to reasoning in Artificial Intelligence. Questions of consciousness are also explored both in Artificial Intelligence and Cognitive Science, and from the perspectives of language and learning, the \u201cacceptability judgements\u201d that Chomsky (1957) and Berwick (2016ab) appeal to depend on hidden variables (normally handled preconsciously) being brought to conscious attention - with the result that acceptability cannot be explained without appeal to theory, hypotheses and assumptions, and is self-reinforcing and biased."}, {"heading": "4 Poverty of Dichotomy", "text": "This begs the question of whether issues with acceptability are syntactic, semantic or pragmatic, and Berwick et al. (2016a) expect them to be syntactic and dichotomous rather than the gradient of gramaticality that Lau, Clark & Lappin (LCL:2014,2015) explore by correlation of human Likert-scale judgements with a statistical model. Berwick questions whether observed correlations are strong enough to warrant accepting that acceptability was a matter of probability (wrapping up a question about gradience of human judgements with a question about the probablistic nature of grammar). The fact that particular simplistic probabilistic or neural models don\u2019t correlate as well as would be liked with human judgements, with no competing LAD-PAP model constrasted with it, proves nothing about whether LAD-PAP is correct, language is probabilistic, or acceptability is graded (nor does it refute it clearly, given they suggest other causes for the small correlations seen). The fact that some correlation is observed in both the original and the replication study, provides some support for the graded probabilistic account as it is a prediction of the theory, but is not conclusive in that direction either.\nBerwick et al. (2016a) use data from the generative linguistics tradition, from papers in Linguistic Inquiry, two sets of examples of acceptable and unacceptable sentences from textbooks, plus 120 permutations of Chomsky\u2019s \u201cColorless green ideas sleep furiously\u201d (inspiring the title of the replication paper). LCL (2013-15) used examples from the British National Corpus (BNC) with \u201cinfelicities introduced by round trip machine translation\u201d. The Berwick results showed correlation, but weaker than in the original experiment. But, real sentences from a corpus of real English have a Zipfian distribution, can be well over 100 words long, and will thus tend to be much longer and more complicated than short textbook-style examples composed to make a particular point (and LCL made a point of examining length and normalizing for it). Also machine translation into English will produce a different distribution of \u201cinfelicities\u201d. Finally, much of the \u2018starring\u2019 of sentences in linguistic publications, particularly textbooks, is naive, while LCL dealt with a corpus of real English and occasionally focussed in on one of the most prevalent issues of ambiguity (past tense versus passive participle)."}, {"heading": "5 Poverty of Tagging", "text": "The most common reason for misstarring sentences is part of speech (POS) ambiguity, not recognizing the flexibility of English to coerce a word that is intrinsically or overwhelmingly one POS: a meaning may only be licenced in specific contexts so that the grammatical possibility is not salient otherwise. Some words have an auxiliary or modal role and a literal meaning (be, have, go, ...). A noun can in general be used to express an action involving that object (e.g. a body part - \u201cHe shoulders the player aside, heads the ball to a team mate, then legs it back to the goal.\u201d). This is explored by Entwisle (1997, 1998), leading to a critique of parsers and metrics that \u2018improve\u2019 by ignoring such choices and tagging with, or biasing to, the most frequent POS. Parsers trained and tested on handtagged subsets of a corpus then tag the whole corpus leading to unreliable tags, and even after attempts to patch them still have cases that fail systematically. BNC is used in the LSL (2013-15) studies, but its tags were ignored. They still exhibit problems (particularly when participles are involved, or words with concrete and abstract or functional usages). Of 278 instances of going to work in BNC, only 4 are ambiguous when viewed in context, and of the remaining 274, we find 107 are correctly tagged (78 of 88 nouns and 29 of 186 verbs) and 167 are incorrectly tagged (10 of 88 nouns and 157 of 186 verbs). This performance is not significantly different from chance (p > 0.1), with the probability of an informed tag for \u201cwork\u201d being 4.4% (Powers,2008, 2012).\nThe conclusions drawn by Berwick are unrealistic in expecting that an unsupervised word-level trigram model, or a simple RNN, should provide high performance: it is known that at each level of linguistic processing, both forward and backward context of two or more units is indicated as context necessary for correct interpretation (phonological/phonemic, morphological/semantic, grammatical/syntactic, ontological/pragmatic, etc.) and this multilevel multiunit multimodal information is routinely used in speech recognition, machine translation, parsing, etc. and higher order modeling has been shown to lead to better entropy estimates and evaluations. LCL have the opposite perspective, claiming only that simplistic models like theirs have predictive ability on real sentences, compared with Berwick et al.\u2019s (2016a) datasets that look like teaching examples."}, {"heading": "6 Poverty of Psychology/Biology", "text": "Chomsky is known for his political and philosophical arguments, and polemical style, as much as for his linguistic contributions, and his arguments in his linguistic writing often share this political, polemical and philosophical flavour. His debating style can in many places be characterized as \u201cintentionally obtuse for the purpose of scoring a debating point\u201d (Palmer,2006, p255; Piatelli-Palmarini, 1979). Indeed such discussions of -isms characterize the butting and abutting of disciplinary viewpoints that triggered the emergence of Cognitive Science generally, as well as Cognitive Linguistics specifically, as arguments spilled across disciplinary lines and researchers tried to synthesize interdisciplinary theories that were consistent across different forms of theory and evidence. Chomsky\u2019s (1959) \u201clinguist\u201d perspective on Skinner\u2019s (1957) \u201cbehaviourist\u201d treatment of language was in fact what really catapulted him to fame, although again here he was faulted both for his lack of understanding of \u201cbehaviourism\u201d and his \u201cseveral serious errors of logic\u201d (MacCorquodale,1970) and \u201crevealed misunderstandings so great that they undercut the credibility of the review substantially... a kind of ill-conceived dam in the progress of science, a rhetorically effective but conceptually flawed document that would eventually be overborne\u201d (Palmer,2006,p253; 2000).\nChomsky (1957) had no biological evidence that specific hypothesized parts of speech (Noun, Verb, etc.) and grammatical constructs (word, phrase, clause, sentence, etc.) or linguistic modules (phonology, morphology, etc.) actually exist in the mind of the native speaker in any sense. Even today, when modern neuroscience is starting to be able to look at what is happening during language processes, the maps do not correspond straightforwardly to specific linguistic predictions or theories, or show loci for words or POS (Pulvermuller,1999; Huth et al.,2016). However, we can do better now than just talk about Broca\u2019s area being near the motor areas presumably involved in producing speech and Wernicke\u2019s area being near the auditory areas presumably involved in understanding speech, with the observation that the disruption caused by damage to these areas affects more than just the nearby modality gives insights and a more sensorimotor foundation for a theory of language (Powers and Turk, 1989)."}, {"heading": "7 Poverty of Generative Linguistics", "text": "Chomsky is also attributed with bringing \u2018generative\u2019 formalism to Linguistics, but as Pullum (2011) points out Chomsky\u2019s first published book \u201cSyntactic Structures\u201d (SS: Chomsky (1957) did not address the question of whether English was a Finite State language, or propose an innate Language Acquisition Device (LAD) in the 1950s, and nor did he in \u201cThe Logical Structure of Linguistic Theory\u201d (LSLT) the draft typescript from 1955, updated in manuscipt in 1956, and cited by Berwick in the form in limited circulation in the US in 1957, nor even in the final severely revised form published in 1975. SS (Chomsky, 1957) does advocate Transformational Generative Grammar (TGG), building on an unformalized notion of transforms that Harris is suggested to have borrowed from Carnap, and which is used inconsistently giving incorrect results in SS with a treatment incompatible with LSLT (Pullum, 2011) .\nThe mathematical formalism behind the TGG, and indeed the so-called Chomsky hierarchy, goes back to Post, who in turn drew on Whitehead and Russel (Pullum, 2011). By the time LSLT (Chomsky, 1957/75) was published, the comprehensive review of Heny (1979) notes, Chomsky was already withdrawing his support from TGG and had reduced his number of proposed tranformations down to one or two. Eventually in the Minimalist Program (Chomsky, 1995), the distinction between deep structure and surface structure had been eliminated in favour of a more explicitly derivational approach, with X-bar theory devolving to pure phrase structure! Thus it is hard to see that anything was \u201csettled\u201d by LSLT in 1957.\nAnderson (2007/8) makes LSLT the title of a Presidential Address to LSA, and revisits many of these issues - hardly \u201csettled\u201d. Every year this debate has been \u201crevived\u201d in multiple papers and books and venues like Behavioural and Brain Sciences. It forced the founding of the Cognitive Linguistics Journal and associated societies: rather than generated from an internal LAD the CogL focus is on the metaphor-driven emergence of language from general mechanisms for understanding and interacting with our world (Lakoff and Johnson,1980,1987). Powers (1983,1991b,1997) connects this to the Psycholinguistic theory of Piaget (1923, 1936, 1950; Piatelli-Palmarini,1979) and the generalized Emic theory of Pike (1947, 1948,1954, 1955)."}, {"heading": "8 Poverty of Grammar", "text": "Powers and Turk\u2019s (1989) argument that Chomsky\u2019s approach is not neurologically or computationally plausible presents evidence of violating Chomsky\u2019s agreed assumptions (Hockett,1961), as well as discussing the implications of computational language learning models. We have a rich supply, with early models including Adriaans (1992ab,1993), Anderson (1975), Block (1975), Ellison(1993), Entwisle (1997), Finch (1993), Gold(1967), Horning(1969), Powers (1983, 1991a), Siklossy (1971) and Turk (1984,1988,1990) and extending beyond the reaches of grammar! It is worth noting that the phonology work of Bird and Ellison (1994) traces back to that of Goldsmith (1976) who framed his work (with some difficulty it seems) in the Chomskian framework, while the semantic directions relate specifically to the idea that language is impossible without what Hayes (1979) calls Naive Physics, Powers (1983, 1991ab) calls Ontology, Harnad (1990,1991) calls Symbol Grounding, or Feldman, Lakoff, Stolcke & Weber (1990) call L0.\nThis goes beyond dictionaries, thesauri, semantic nets and taxonomies to require multimodal neural connections between multiple sensory-motor modalities and thus establish real meaning in the physical world rather than just chasing words around a dictionary or its electronic equivalent. It provides an answer for debates around Searle\u2019s (1980) Chinese Room and Harnad\u2019s (1990) Total Turing Test, and the broader Connectionism vs Symbolism Debate (Powers,1992), and acknowledges the supervisory possibilities of multimodal learning (Powers and Turk, 1989) and memorybased anticipated correction (Turk, 1984, 1988, 1990). This also connects to Berwick and Chomsky\u2019s focus on so-called generative grammar - in fact, Powers and Turk (1989) discuss evidence of separate learning of language understanding models near sensory/hearing processing areas of the brain (e.g. Wernicke\u2019s area) and language generation models near motor/speech centres of the brain (Broca\u2019s area), as well as prediction of mirroring regions that connect what we hear and see with what we produce ourselves and others reflect (mothers mirror their babies more than vice versa).\nThis can be seen to predict the recent discovery of mirror neurons (Arbib, 2009), and builds on classic Piagetian treatment of reflection and imitation in learning (Piaget, 1923,1936,1950)."}, {"heading": "9 Poverty of the Stimulus", "text": "Mirror neurons fire not only when the subject performs an action, but when they see someone else perform the action. We subdivide imitation into three distinct paradigms: 2a. the child speaks and the parent echoes (mirroring), 2b. the parent speaks and the child echoes (echolalia), and 2c. the child speaks and is directly mirrored (via a physical mirror or a camera and monitor setup). These are listed in decreasing order of importance and commonality: the parent echoes the child much more than vice-versa (Oostenbroek et al.,2016), and this is enshrined in the kind of peek-a-boo games played with infants, as well as the encouragement and shaping of the child\u2019s protowords (Dada she said Dada!), on the other hand the mirror or camera is not usually available, and the child must actually learn to recognize herself, and the fascination with mirrors and cameras thus comes at a relatively late stage.\nIn the end the real problem with the Nativist and the Symbolist positions is that they rely only on explicit linguistic \u2018stimulus\u2019 - humans rely on connecting symbols with real world sensory input and motor output, as well as proprioceptive and mirrored signals that combine and relate sensory and motor information.\nThe Poverty of the Stimulus (PoS) argument focuses on syntax to the exclusion of semantics and pragmatics, experience and ontology. On the other hand Cognitive Linguistics emphasizes the role of similarity or metaphor in language, seeing patterns learned in the real world as models for those learned in language (e.g. Lakoff et al.,1980,1987; Goldberg,2006,2008), while Computational Intelligence emphasizes the role of similarity or correlation in learning so that multimodal similarity should be fundamental to Computational Cognitive Linguistic models of language learning and be consistent with physical limitations on memory and processing as well as the computational limitations on language that result, with (Powers,1997) proposing a variant blackboard model embedded in neural strata (shifting through the layers in time, with versions of grammar rules implicitly enshrined in each layer). Bod (as recently as 2009), commenting on Goldberg (2006,2008), decried the lack of a learning model, of a connection between Natural Language Learning and Cognitive Linguistics, emphasizing that it is important to make one."}, {"heading": "10 Poverty of the Poverty argument", "text": "Chomskian linguistics relies heavily on Gold (1967) in arguing for Poverty of the Stimulus (PoS), asserting that language can\u2019t be learned because babies do not receive negative information (stimulus) required for learning.\nHowever, the results of Gold (1967), Horning (1969) and Adriaans (1992ab) that superfinite languages can be learned without such explicit stimulus are ignored. Gold (1967) noted that his proof broke down if the input was ordered, for example if a simple usage of a construction was used before a recursive usage of the construction (calling this \u201canomalous text\u201d and opening the door to ignoring it). Horning (1969) generalized this to probabilistic information (viz. seeing clear non-recursive constructs sufficiently often to overcome the noise-like effects of overly complex constructs, consistent with psycholinguistic evidence that \u201cwe can only learn what we almost already know\u201d). Adriaans (1992ab) extended to a categorial grammar, showing that language learning from a corpus was possible in this context.\nBased on psycholinguistic evidence, Powers and Turk (1989) argue that \u201ca child only learns what they almost already know\u201d , that the criterion of \u201canomalous test\u201d can be met by a self-organized filter, and that the \u201canticipated correction\u201d is provided unsupervised (Turk,1984,1988,1990). This is the idea of \u201cacceptability\u201d applied to one\u2019s own speech! This is what a native speaker/learner would accept as normal sounding speech, and mixes up accent, phonetic exactitude, aptness of word choice, and other semantic and pragmatic aspects, with the pure syntactic idea of (grammatical) acceptability that Linguists employ, and illustrate with made-up sentences in text books.\nThus measuring acceptability based on written sentences is measuring acceptability in a language that is technically different from the \u2018evolved\u2019 Natural Language of untutored speech, as it is a \u2018prescriptive\u2019 language that is taught in schools, and we also show that it rises above the computability limitations on the complexity of natural speech that are imposed by the size of the human brain. Experiments with complex (e.g. centre-embedded) constructs do demonstrate that a higher complexity can be dealt with in writing compared with speech (and often the inability to deal with a construct is marked as unacceptability by the non-linguist)."}, {"heading": "11 Poverty of the Acceptability argument", "text": "It is important to observe that the Chomskian assumption that language is recursive is just an assumption (if part of the Minimalist Program). In terms of Theory of Computation, it is arguable that language is recurrent rather than recursive - that is there is a finite amount of real estate that is reallocated as needed, accepting sentences with a non-contracting Context Sensitive Grammar (CSG) rather than an unbounded \u2018stack\u2019 that grows as needed, generating sentences of unbounded length and complexity.\nDue to its finite size, the brain is a Finite State Automaton (FSA) not a Pushdown Automaton (PDA) or Turing Machine (TM). A generative Context Free Grammar (CFG) requires an unbounded stack to generate its full range of sentences, while a Regular Grammar (or FSA) is equivalent to iteration or recurrence and doesn\u2019t require an unbounded stack to generate sentences with full range complexity. Powers (1997) embedded a cycling blackboard model of cognition into a finite network where sensorimotor stimuli and responses are processed through layers of neurons. Analogous processing takes place over multiple layers and modalities, and the same CFG or CSG rule can be reflected while disallowing recursion.\nThe invention of writing, adds a stack of paper (so person+paper = PDA). Thus written language can exceed the bounds on spoken language and potentially prove the reality of recursion (except that those schooled in Reading, wRiting and aRithmetic have been schooled in the basics of prescriptive grammar, and thus should be using Recursive Rules they have been schooled in, rather than Natural Language - this effect of teaching of invented grammar rules is seen in the mangled constructions students, and teachers of English, come out with as they try to speak proper by applying the rules they paid for in their education).\nThe invention of the eraser, and the ability to go back and forward in our notes without destroying them, provides us with an essentially unlimited amount of Turing Machine tape we can move back and forwards on. More conveniently, today we use word-processors, with essentially unbounded file space, which allows us to go back and change what we have written. A person with a word processor, or pen+eraser+paper, is a Turing Machine. The Church-Turing thesis says there is nothing more powerful."}, {"heading": "12 Conclusion", "text": "Here we have treated in each column issues that are debated in other places at booklength, reviewing less accessible pre-web theses and books plus early work that \u201csettles\u201d against Chomsky (1957/75), as well as considering the recent contributions replicated with TGG examples by (Berwick et al., 2016a). Now we focus concluding remarks on Berwick\u2019s titles, emphasizing that the debate is anything but settled by Chomsky.\n\u201cWhy take a chance?\u201d\nAcceptability judgements are influenced by contextual factors (the PoS examples) as well as modality (spoken vs written) and of course register, dialect, idiolect, etc. (for the purposes of this paper we go along with the assumption that there is such a language as \u201cEnglish\u201d). With acceptability judgements we balance comprehensibility (I can figure out what was meant) with aptness (it could have been better expressed) with innovation (a new metaphor, metonymy, personification, figure of speech, or PoS-generalization has been used) with actual clear syntactic error - though their origin may be typos or substitutions not competence (Huang and Powers,2001; Powers,1997).\nFar from settling a debate, Chomsky\u2019s The Logical Structure of Linguistic Theory (1957/75) initiated a furore with an array of assumptions and assertions that many have thought dead and gone, including many that were discarded in Chomsky\u2019s Minimalist Program (1986/1991/1993/1995). If anything, since the emergence of Cognitive Science, Computational Cognitive Science, Cognitive Linguistics, Computational Psycholinguistics and their permutations, the various interdisciplinary communities have tended to settle strongly on the opposing side, opposing the idea of sophisticated innate language modules with a strictly immutable idea of grammatical acceptability implemented in a physical Language Aquisition Device \u201cas real as the heart or the liver\u201d (Chomsky in PiatelliPalmarini, M.,1979).\nAlthough Berwick (2016b) asks \u201cWhy take a chance?\u201d is it Berwick and Chomsky who are relying on chance in saying language is innate rather than learned, and relegating the problem to mysterious and unknowable processes of natural selection and evolution, rather than allowing for learning by far more powerful members of our computational learning arsenal?\n\u201cColorless green ideas sleep furiously\u201d\nIronically, Chomsky\u2019s grammatical but supposedly nonsensical sentence, reflected in Berwick et al. (2016a)\u2019s title and 120 permutation corpus, are used by their opponents to characterize this \u201csettled\u201d debate. They may think they have settled their baby to sleep, but many remain unimpressed by the unripe ideas of Chomsky (1957-1995), and their lack of ability to paint a realistic world picture that encompasses the rich multimodal technicolor of language and ontology and understanding and communication and interaction... within our world, our society and our culture. Perhaps we have let sleeping ideas lie too long. The dreams that we pursue so furiously as Linguistic and Psycholinguistic researchers are still shaped, one way or another, by the assumptive embers of this sleepy smouldering debate."}], "references": [{"title": "and E", "author": ["Pieter W. Adriaans", "S. Janssen"], "venue": "Nomden.", "citeRegEx": "Adriaans et al.1993", "shortCiteRegEx": null, "year": 1993}, {"title": "1992a. Bias in inductive language learning", "author": ["Pieter W. Adriaans"], "venue": "In Machine Learning Workshop on Biases in Inductive Learning", "citeRegEx": "Adriaans.,? \\Q1992\\E", "shortCiteRegEx": "Adriaans.", "year": 1992}, {"title": "Language Learning from a Categorial Perspective", "author": ["Pieter W. Adriaans"], "venue": "Ph.D. thesis,", "citeRegEx": "Adriaans.,? \\Q1992\\E", "shortCiteRegEx": "Adriaans.", "year": 1992}, {"title": "Computer simulation of a language acquisition system: A first report", "author": ["John R. Anderson"], "venue": null, "citeRegEx": "Anderson.,? \\Q1975\\E", "shortCiteRegEx": "Anderson.", "year": 1975}, {"title": "The logical structure of linguistic theory", "author": ["Stephen R. Anderson"], "venue": null, "citeRegEx": "Anderson.,? \\Q2008\\E", "shortCiteRegEx": "Anderson.", "year": 2008}, {"title": "Sandiway Fong", "author": ["Robert Berwick", "Beracah Yankama", "Sagar Indurkya"], "venue": "and Jon Sprouse.", "citeRegEx": "Berwick et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "2016", "author": ["Robert Berwick"], "venue": "Colorless green ideas still do sleep furiously. In GLOW", "citeRegEx": "Berwick2016", "shortCiteRegEx": null, "year": 2016}, {"title": "One-level phonology: Autosegmental representations and rules as finite automata", "author": ["Bird", "Ellison1994] Steven Bird", "T. Mark Ellison"], "venue": null, "citeRegEx": "Bird et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bird et al\\.", "year": 1994}, {"title": "and G", "author": ["H.D. Block", "J. Moulton"], "venue": "M. Robinson.", "citeRegEx": "Block et al.1975", "shortCiteRegEx": null, "year": 1975}, {"title": "Constructions at work or at rest", "author": ["Rens Bod"], "venue": "Cognitive Linguistics,", "citeRegEx": "Bod.,? \\Q2009\\E", "shortCiteRegEx": "Bod.", "year": 2009}, {"title": "and Michael Siegal", "author": ["Peter Carruthers", "Stephen Stich"], "venue": "editors.", "citeRegEx": "Carruthers et al.2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Linguistic nativism and the poverty of the stimulus", "author": ["Clark", "Shalom Lappin"], "venue": null, "citeRegEx": "Clark et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2010}, {"title": "Statistical representation of grammaticality judgements: The limits of n-gram models", "author": ["Clark et al.2013a] A. Clark", "G. Giorgolo", "S. Lappin"], "venue": "In August 2013 Sophia,", "citeRegEx": "Clark et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2013}, {"title": "2013b. towards a statistical model of grammaticality", "author": ["Clark et al.2013b] A. Clark", "G. Giorgolo", "S. Lappin"], "venue": "In Annual Conference of the Cognitive Science Society,", "citeRegEx": "Clark et al\\.,? \\Q2069\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2069}, {"title": "Machine Learning of Phonological Structure", "author": ["T. Mark Ellison"], "venue": "Ph.D. thesis, Univ. of Western Australia", "citeRegEx": "Ellison.,? \\Q1993\\E", "shortCiteRegEx": "Ellison.", "year": 1993}, {"title": "W", "author": ["Jim Entwisle", "David M"], "venue": "Powers.", "citeRegEx": "Entwisle and Powers1998", "shortCiteRegEx": null, "year": 1998}, {"title": "and Susan H", "author": ["Jerome A. Feldman", "George Lakoff", "Andreas Stolcke"], "venue": "Weber.", "citeRegEx": "Feldman et al.1990", "shortCiteRegEx": null, "year": 1990}, {"title": "Finding Structure in Language", "author": ["Steven P. Finch"], "venue": "Ph.D. thesis, Univ. of Edinburgh", "citeRegEx": "Finch.,? \\Q1993\\E", "shortCiteRegEx": "Finch.", "year": 1993}, {"title": "Language identification in the limit", "author": ["E. Mark Gold"], "venue": "Information and Control,", "citeRegEx": "Gold.,? \\Q1967\\E", "shortCiteRegEx": "Gold.", "year": 1967}, {"title": "Constructions at Work: The nature of generalization in language", "author": ["Adele E. Goldberg"], "venue": null, "citeRegEx": "Goldberg.,? \\Q2006\\E", "shortCiteRegEx": "Goldberg.", "year": 2006}, {"title": "Universal grammar? or prerequisites for natural language? Behavioral and Brain Sciences, 31(5):522\u2013523", "author": ["Adele E. Goldberg"], "venue": null, "citeRegEx": "Goldberg.,? \\Q2008\\E", "shortCiteRegEx": "Goldberg.", "year": 2008}, {"title": "and J", "author": ["Stevan Harnad", "S.J. Hanson"], "venue": "Lubin.", "citeRegEx": "Harnad et al.1991", "shortCiteRegEx": null, "year": 1991}, {"title": "Categorical perception: The groundwork of Cognition", "author": ["Stevan Harnad"], "venue": null, "citeRegEx": "Harnad.,? \\Q1987\\E", "shortCiteRegEx": "Harnad.", "year": 1987}, {"title": "The symbol grounding problem", "author": ["Stevan Harnad"], "venue": "Physica D,", "citeRegEx": "Harnad.,? \\Q1990\\E", "shortCiteRegEx": "Harnad.", "year": 1990}, {"title": "The naive physics manifesto. in Expert Systems in the Microelectronics Age, 1979:242\u2013270", "author": ["P.J. Hayes"], "venue": null, "citeRegEx": "Hayes.,? \\Q1979\\E", "shortCiteRegEx": "Hayes.", "year": 1979}, {"title": "A study of grammatical inference", "author": ["James Jay Horning"], "venue": "Ph.D. thesis,", "citeRegEx": "Horning.,? \\Q1969\\E", "shortCiteRegEx": "Horning.", "year": 1969}, {"title": "and Jack L", "author": ["Alexander G. Huth", "Wendy A. de Heer", "Thomas L. Griffiths", "Frederic E. Theunissen"], "venue": "Gallant.", "citeRegEx": "Huth et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Sensorimotor Cognition and Natural Language Syntax", "author": ["Alistair Knott"], "venue": null, "citeRegEx": "Knott.,? \\Q2012\\E", "shortCiteRegEx": "Knott.", "year": 2012}, {"title": "Proofs and Refutations", "author": ["Musgrave Lakatos"], "venue": null, "citeRegEx": "Lakatos.,? \\Q1976\\E", "shortCiteRegEx": "Lakatos.", "year": 1976}, {"title": "1978a. Mathematics, Science and Epistemology: Philosophical Papers Volume 2", "author": ["Musgrave Lakatos"], "venue": null, "citeRegEx": "Lakatos.,? \\Q1978\\E", "shortCiteRegEx": "Lakatos.", "year": 1978}, {"title": "The Methodology of Scientific Research Programmes: Philosophical Papers Volume 1", "author": ["Musgrave Lakatos"], "venue": null, "citeRegEx": "Lakatos.,? \\Q1978\\E", "shortCiteRegEx": "Lakatos.", "year": 1978}, {"title": "Metaphors We Live By", "author": ["Lakoff", "Johnson1980] George Lakoff", "Mark Johnson"], "venue": null, "citeRegEx": "Lakoff et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Lakoff et al\\.", "year": 1980}, {"title": "Women, Fire, and Dangerous Things: What Categories Reveal About the Mind", "author": ["George Lakoff"], "venue": null, "citeRegEx": "Lakoff.,? \\Q1987\\E", "shortCiteRegEx": "Lakoff.", "year": 1987}, {"title": "2014", "author": ["J.H. Lau", "A. Clark", "S. Lappin"], "venue": "Measuring gradience in speakers\u2019 grammaticality judgements. In 36th Annual Conference of the Cognitive Science Society, July", "citeRegEx": "Lau et al.2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Shalom Lappin", "author": ["Jey Han Lau"], "venue": "and Alexander Clark.", "citeRegEx": "Lau et al.2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Mind and Cosmos: Why the Materialist Neo-Darwinian Conception of Nature Is Almost Certainly False", "author": ["Thomas Nagel"], "venue": null, "citeRegEx": "Nagel.,? \\Q2012\\E", "shortCiteRegEx": "Nagel.", "year": 2012}, {"title": "Sally Clark", "author": ["Janine Oostenbroek", "Thomas Suddendorf", "Mark Nielsen", "Jonathan Redshaw", "Siobhan Kennedy-Costantini", "Jacqueline Davis"], "venue": "and Virginia Slaughter.", "citeRegEx": "Oostenbroek et al.2016", "shortCiteRegEx": null, "year": 2016}, {"title": "Chomsky\u2019s nativism: A critical review", "author": ["David C. Palmer"], "venue": "Analysis of Verbal Behavior,", "citeRegEx": "Palmer.,? \\Q2000\\E", "shortCiteRegEx": "Palmer.", "year": 2000}, {"title": "On chomsky\u2019s appraisal of skinner\u2019s verbal behavior: A half century of misunderstanding", "author": ["David C. Palmer"], "venue": "Behavior Analyst,", "citeRegEx": "Palmer.,? \\Q2006\\E", "shortCiteRegEx": "Palmer.", "year": 2006}, {"title": "Tenenbaum", "author": ["Amy Perfors", "Joshua B"], "venue": "and Terry Regier.", "citeRegEx": "Perfors et al.2006", "shortCiteRegEx": null, "year": 2006}, {"title": "The Language and Thought of the Child. Routledge and Kegan Paul, London. (1962 trans: Le langage et la pens chez l\u2019enfant)", "author": ["Jean Piaget"], "venue": null, "citeRegEx": "Piaget.,? \\Q1923\\E", "shortCiteRegEx": "Piaget.", "year": 1923}, {"title": "The Origins of Intelligence in the Child. Routledge and Kegan Paul, London. (1953 trans: La naissance de l\u2019intelligence chez l\u2019enfant)", "author": ["Jean Piaget"], "venue": null, "citeRegEx": "Piaget.,? \\Q1936\\E", "shortCiteRegEx": "Piaget.", "year": 1936}, {"title": "The construction of reality in the child", "author": ["Jean Piaget"], "venue": "Routledge and Kegan Paul, London", "citeRegEx": "Piaget.,? \\Q1950\\E", "shortCiteRegEx": "Piaget.", "year": 1950}, {"title": "Language and Learning: The Debate between Jean Piaget and Noam Chomsky", "author": ["M. Piatelli-Palmarini", "editor"], "venue": null, "citeRegEx": "Piatelli.Palmarini and editor.,? \\Q1979\\E", "shortCiteRegEx": "Piatelli.Palmarini and editor.", "year": 1979}, {"title": "Do people use language production to make prediction during comprehension", "author": ["Pickering", "Garrod2007] Martin J. Pickering", "Simon Garrod"], "venue": "Trends in Cognitive Science,", "citeRegEx": "Pickering et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pickering et al\\.", "year": 2007}, {"title": "Phonetics: A critical analysis of phonetic theory and a technic for the practical description of sounds", "author": ["Kenneth L. Pike"], "venue": null, "citeRegEx": "Pike.,? \\Q1943\\E", "shortCiteRegEx": "Pike.", "year": 1943}, {"title": "The intonation", "author": ["Kenneth L. Pike"], "venue": null, "citeRegEx": "Pike.,? \\Q1945\\E", "shortCiteRegEx": "Pike.", "year": 1945}, {"title": "Phonemics, A technique for reducing languages to writing", "author": ["Kenneth L. Pike"], "venue": null, "citeRegEx": "Pike.,? \\Q1947\\E", "shortCiteRegEx": "Pike.", "year": 1947}, {"title": "Tone Languages, A technique for determining the number and type of pitch contrasts in a language, with studies in tonemic substitution and fusion", "author": ["Kenneth L. Pike"], "venue": null, "citeRegEx": "Pike.,? \\Q1948\\E", "shortCiteRegEx": "Pike.", "year": 1948}, {"title": "Language in relation to a unified theory of the structure of human behaviour, part I", "author": ["Kenneth L. Pike"], "venue": "Summer Institute of Linguistics, Glendale CA", "citeRegEx": "Pike.,? \\Q1954\\E", "shortCiteRegEx": "Pike.", "year": 1954}, {"title": "Language in relation to a unified theory of the structure of human behaviour, part II. Summer Institute of Linguistics, Glendale CA", "author": ["Kenneth L. Pike"], "venue": null, "citeRegEx": "Pike.,? \\Q1955\\E", "shortCiteRegEx": "Pike.", "year": 1955}, {"title": "Language Learnability and Language Development", "author": ["Steve Pinker"], "venue": null, "citeRegEx": "Pinker.,? \\Q1984\\E", "shortCiteRegEx": "Pinker.", "year": 1984}, {"title": "The Logic of Scientific Discovery", "author": ["Karl Popper"], "venue": "Routledge. (1959 trans: Logik der Forschung)", "citeRegEx": "Popper.,? \\Q1934\\E", "shortCiteRegEx": "Popper.", "year": 1934}, {"title": "Conjectures and Refutations: The Growth of Scientific Knowledge", "author": ["Karl Popper"], "venue": null, "citeRegEx": "Popper.,? \\Q1963\\E", "shortCiteRegEx": "Popper.", "year": 1963}, {"title": "W", "author": ["M David"], "venue": "Powers and Chris Turk.", "citeRegEx": "Powers and Turk1989", "shortCiteRegEx": null, "year": 1989}, {"title": "W", "author": ["M David"], "venue": "Powers.", "citeRegEx": "Powers1983", "shortCiteRegEx": null, "year": 1983}, {"title": "Goals, issues and directions in machine learning of natural language and ontology", "author": ["David M.W. Powers"], "venue": "AAAI Spring Symposium on Machine Learning of Natural Language and Ontology,", "citeRegEx": "Powers.,? \\Q1991\\E", "shortCiteRegEx": "Powers.", "year": 1991}, {"title": "How far can self-organization go? results in unsupervised language learning", "author": ["David M.W. Powers"], "venue": "AAAI Spring Symposium on Machine Learning of Natural Language and Ontology,", "citeRegEx": "Powers.,? \\Q1991\\E", "shortCiteRegEx": "Powers.", "year": 1991}, {"title": "W", "author": ["M David"], "venue": "Powers.", "citeRegEx": "Powers1992", "shortCiteRegEx": null, "year": 1992}, {"title": "W", "author": ["M David"], "venue": "Powers.", "citeRegEx": "Powers1997", "shortCiteRegEx": null, "year": 1997}, {"title": "W", "author": ["M David"], "venue": "Powers.", "citeRegEx": "Powers2008", "shortCiteRegEx": null, "year": 2008}, {"title": "W", "author": ["M David"], "venue": "Powers.", "citeRegEx": "Powers2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Pullum and Barbara C", "author": ["K Geoffrey"], "venue": "Scholz.", "citeRegEx": "Pullum and Scholz2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Linguistic universals as evidence for empiricism", "author": ["Geoffrey Sampson"], "venue": null, "citeRegEx": "Sampson.,? \\Q1978\\E", "shortCiteRegEx": "Sampson.", "year": 1978}, {"title": "The \u2018Language Instinct", "author": ["Geoffrey Sampson"], "venue": "Debate. Continuum,", "citeRegEx": "Sampson.,? \\Q2005\\E", "shortCiteRegEx": "Sampson.", "year": 2005}, {"title": "Constructing a Language: A Usage-Based Theory of Language Acquisition", "author": ["Michael Tomasello"], "venue": null, "citeRegEx": "Tomasello.,? \\Q2003\\E", "shortCiteRegEx": "Tomasello.", "year": 2003}, {"title": "R", "author": ["C Christopher"], "venue": "Turk.", "citeRegEx": "Turk1984", "shortCiteRegEx": null, "year": 1984}, {"title": "R", "author": ["C Christopher"], "venue": "Turk.", "citeRegEx": "Turk1988", "shortCiteRegEx": null, "year": 1988}, {"title": "R", "author": ["C Christopher"], "venue": "Turk.", "citeRegEx": "Turk1990", "shortCiteRegEx": null, "year": 1990}], "referenceMentions": [], "year": 2016, "abstractText": "Prof. Robert Berwick\u2019s abstract for his forthcoming invited talk at the ACL2016 workshop on Cognitive Aspects of Computational Language Learning revives an ancient debate. Entitled \u201cWhy take a chance?\u201d, Berwick seems to refer implicitly to Chomsky\u2019s critique of the statistical approach of Harris as well as the currently dominant paradigms in CoNLL. Berwick avoids Chomsky\u2019s use of \u201cinnate\u201d but states that \u201cthe debate over the existence of sophisticated mental grammars was settled with Chomsky\u2019s Logical Structure of Linguistic Theory (1957/1975)\u201d, acknowledging that \u201cthis debate has often been revived\u201d. Berwick does not in his abstract mention Gold\u2019s concerns about what it means to learn a language, or his concept of \u201cLanguage Identification in the Limit\u201d which is often juxtaposed against the idea of \u201cProbably Approximately Correct\u201d, but Berwick specifically questions the counterargument that \u201cdifferences in acceptability judgements can be closely approximated ... from probabilistic accounts\u201d. We discuss his recent critique of computational experiments that show acceptability judgements correlating with probabilities from simple computational models. This paper agrees with the view that this debate has long since been settled, but with the opposite outcome! Given the embers have not yet died away, and the questions remain fundamental, perhaps it is appropriate to refuel the debate, so I would like to join Bob in throwing fuel on this fire!", "creator": "LaTeX with hyperref package"}}}