{"id": "1607.04660", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-May-2016", "title": "Identification of promising research directions using machine learning aided medical literature analysis", "abstract": "documenting the rapidly expanding corpus map of medical research literature arguably presents major challenges in addressing the understanding of previous work, the extraction of maximum information from collected data, retention and the identification of promising research alma directions. we present a case for the use of advanced machine learning techniques as an optimal aide in this task and introduce a novel methodology that is shown to be exceptionally capable of extracting meaningful information from large longitudinal corpora, and of tracking complex temporal changes within it.", "histories": [["v1", "Mon, 16 May 2016 12:55:36 GMT  (334kb,D)", "http://arxiv.org/abs/1607.04660v1", "arXiv admin note: substantial text overlap witharXiv:1512.08008"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1512.08008", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["victor", "rei", "ognjen arandjelovic"], "accepted": false, "id": "1607.04660"}, "pdf": {"name": "1607.04660.pdf", "metadata": {"source": "CRF", "title": "Identification of Promising Research Directions using Machine Learning Aided Medical Literature Analysis", "authors": ["Victor Andrei"], "emails": [], "sections": [{"heading": null, "text": "I. INTRODUCTION Recent years have witnessed a remarkable convergence of two broad trends. The first of these concerns information i.e. data \u2013 rapid technological advances coupled with an increased presence of computing in nearly every aspect of daily life, have for the first time made it possible to acquire and store massive amounts of highly diverse types of information. Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11]. Though it is undeniably wise to refrain from overly ambitious predictions regarding the type of knowledge which may be discovered in this manner, at the very least it is true that few domains of application of the aforesaid techniques hold as much promise and potential as that of medicine and health in general.\nLarge amounts of highly heterogeneous data types are pervasive in medicine. Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc. Much less discussed and yet arguably no less important realm where the amount of information presents a challenge to the medical field is the medical literature corpus itself. Namely, considering the overarching and global importance of health (to say nothing of practical considerations such as the availability of funding), it is not surprising to observe that the amount of published medical research is immense and its growth is only continuing to accelerate. This presents a clear challenge to a researcher. Even restricted to a specified field of research, the amount of published data and findings makes it impossible for a human to survey the entirety of relevant publications exhaustively which inherently leads to the question as to what kind of important information or insight may go unnoticed or\ninsufficiently appreciated. The premise of the present work is that advanced machine learning techniques can be used to assist a human in the analysis of this data. Specifically, we introduce a novel methodology based on Bayesian nonparametric inference that achieves this, as well as free software which researchers can use in the analysis of their corpora of interest.\n1) Previous work: A limitation of most models described in the existing literature lies in their assumption that the data corpus is static. Here the term \u2018static\u2019 is used to describe the lack of any associated temporal information associated with the documents in a corpus \u2013 the documents are said to be exchangeable [13]. However, research articles are added to the literature corpus in a temporal manner and their ordering has significance. Consequently the topic structure of the corpus changes over time [15], [9], [10]: new ideas emerge, old ideas are refined, novel discoveries result in multiple ideas being related to one another thereby forming more complex concepts or a single idea multifurcating into different \u2018sub-ideas\u2019 etc. The premise in the present work is that documents are not exchangeable at large temporal scales but can be considered to be at short time scales, thus allowing the corpus to be treated as temporally locally static."}, {"heading": "II. PROPOSED APPROACH", "text": "In this section we introduce our main technical contributions. We begin by reviewing the relevant theory underlying Bayesian mixture models, and then explain how the proposed framework employs these for the extraction of information from temporally varying document corpora."}, {"heading": "A. Bayesian mixture models", "text": "Mixture models are appropriate choices for the modelling of so-called heterogeneous data whereby heterogeneity is taken to mean that observable data is generated by more than one process (source). The key challenges lie in the lack of observability of the correspondence between specific data points and their sources, and the lack of a priori information on the number of sources [20].\nBayesian non-parametric methods place priors on the infinite-dimensional space of probability distributions and provide an elegant solution to the aforementioned modelling problems. Dirichlet Process (DP) in particular allows for the model to accommodate a potentially infinite number of mixture components [16]:\np (x|\u03c01:\u221e, \u03c61:\u221e) = \u221e\u2211 k=1 \u03c0kf (x|\u03c6k) . (1)\nar X\niv :1\n60 7.\n04 66\n0v 1\n[ cs\n.C L\n] 1\n6 M\nay 2\n01 6\nwhere DP (\u03b3,H) is defined as a distribution of a random probability measure G over a measurable space (\u0398,B), such that for any finite measurable partition (A1, A2, . . . , Ar) of \u0398 the random vector (G (A1) , . . . , G (Ar)) is a Dirichlet distribution with parameters (\u03b3H (A1) , . . . , \u03b3H (Ar)).\nOwing to the discrete nature and infinite dimensionality of its draws, the DP is a useful prior for Bayesian mixture models. By associating different mixture components with atoms \u03c6k, and assuming xi|\u03c6k\niid\u223c f (xi|\u03c6k) where f (.) is the kernel of the mixing components, a Dirichlet process mixture model (DPM) is obtained [18].\n1) Hierarchical DPMs: While the DPM is suitable for the clustering of exchangeable data in a single group, many realworld problems are more appropriately modelled as comprising multiple groups of exchangeable data. In such cases it is desirable to model the observations of different groups jointly, allowing them to share their generative clusters. This so-called \u201csharing of statistical strength\u201d emerges naturally when a hierarchical structure is implemented.\nThe DPM models each group of documents in a collection using an infinite number of topics. However, it is desired for multiple group-level DPMs to share their clusters. The hierarchical DP (HDP) [21] offers a solution whereby base measures of group-level DPs are drawn from a corpus-level DP. In this way the atoms of the corpus-level DP are shared across the documents; posterior inference is readily achieved using Gibbs sampling [21]."}, {"heading": "B. Modelling topic evolution over time", "text": "We now show how the described HDP based model can be applied to the analysis of temporal topic changes in a longitudinal data corpus.\nOwing to the aforementioned assumption of a temporally locally static corpus we begin by discretizing time and dividing the corpus into epochs. Each epoch spans a certain contiguous time period and has associated with it all documents with timestamps within this period. Each epoch is then modelled separately using a HDP, with models corresponding to different epochs sharing their hyperparameters and the corpus-level base measure. Hence if n is the number of epochs, we obtain n sets of topics \u03c6 = { \u03c6t1 , . . . ,\u03c6tn\n} where \u03c6t = {\u03b81,t, . . . , \u03c6Kt,t} is the set of topics that describe epoch t, and Kt their number.\n1) Topic relatedness: Our goal now is to track changes in the topical structure of a data corpus over time. The simplest changes of interest include the emergence of new topics, and the disappearance of others. More subtly, we are also interested in how a specific topic changes, that is, how it evolves over time in terms of the contributions of different words it comprises. Lastly, our aim is to be able to extract and model complex structural changes of the underlying topic content which result from the interaction of topics. Specifically, topics, which can be thought of as collections of memes, can merge to form new topics or indeed split into more nuanced memetic collections. This information can provide valuable insight into the refinement of ideas and findings in the scientific community, effected by new research and accumulating evidence.\nThe key idea behind our tracking of simple topic evolution stems from the observation that while topics may change significantly over time, changes between successive epochs are limited. Therefore we infer the continuity of a topic in one epoch by relating it to all topics in the immediately\nsubsequent epoch which are sufficiently similar to it under a suitable similarity measure \u2013 we adopt the well known Bhattacharyya distance (BHD). This can be seen to lead naturally to a similarity graph representation whose nodes correspond to topics and whose edges link those topics in two epochs which are related. Formally, the weight of the directed edge that links \u03c6j,t, the j-th topic in epoch t, and \u03c6k,t+1 is \u03c1BHD (\u03c6j,t, \u03c6k,t+1) where \u03c1BHD denotes the BHD.\nIn constructing a similarity graph a threshold to used to eliminate automatically weak edges, retaining only the connections between sufficiently similar topics in adjacent epochs. Then the disappearance of a particular topic, the emergence of new topics, and gradual topic evolution can be determined from the structure of the graph. In particular if a node does not have any edges incident to it, the corresponding topic is taken as having emerged in the associated epoch. Similarly if no edges originate from a node, the corresponding topic is taken to vanish in the associated epoch. Lastly when exactly one edge originates from a node in one epoch and it is the only edge incident to a node in the following epoch, the topic is understood as having evolved in the sense that its memetic content may have changed.\nA major challenge to the existing methods in the literature concerns the detection of topic merging and splitting. Since the connectedness of topics across epochs is based on their similarity what previous work describes as \u2018splitting\u2019 or indeed \u2018merging\u2019 does not adequately capture these phenomena. Rather, adopting the terminology from biological evolution, a more accurate description would be \u2018speciation\u2019 and \u2018convergence\u2019 respectively. The former is illustrated in Fig 1(a) whereas the latter is entirely analogous with the time arrow reversed. What the conceptual diagram shown illustrates is a slow differentiation of two topics which originate from the same \u2018parent\u2019. Actual topic splitting, which does not have a biological equivalent in evolution, and which is conceptually illustrated in Fig 1(b) cannot be inferred by measuring topic similarity. Instead, in this work we propose to employ the Kullback-Leibler divergence (KLD) for this purpose. This divergence is asymmetric can be intuitively interpreted as measuring how well one probability distribution \u2018envelops\u2019 another. KLD between two probability distributions p(i) and q(i) is defined as follows:\n\u03c1KLD = \u2211 i p(i) log p(i) q(i) (2)\nIt can be seen that a high penalty is incurred when p(i) is significant and q(i) is low. Hence, we use the BHD to track gradual topic evolution, speciation, and convergence, while the KLD (computed both in forward and backward directions) is used to detect topic splitting and merging.\n2) Automatic temporal relatedness graph construction: Another novelty of the work first described in this paper concerns the building of the temporal relatedness graph. We achieve this almost entirely automatically, requiring only one free parameter to be set by the user. Moreover the meaning of the parameter is readily interpretable and understood by a non-expert, making our approach highly usable.\nOur methodology comprises two stages. Firstly we consider all inter-topic connections present in the initial fully connected graph and extract the empirical estimate of the corresponding cumulative density function (CDF). Then we prune the graph based on the operating point on the relevant\nCDF. In other words if F\u03c1 is the CDF corresponding to a specific initial, fully connected graph formed using a particular similarity measure (BHD or KLD), and \u03b6 \u2208 [0, 1] the CDF operating point, we prune the edge between topics \u03c6j,t and \u03c6k,t+1 iff \u03c1(\u03c6j,t, \u03c6k,t+1) < F\u22121\u03c1 (\u03b6)."}, {"heading": "III. EVALUATION AND DISCUSSION", "text": "We now analyse the performance of the proposed frame-\nwork empirically on a large real world data set."}, {"heading": "A. Evaluation data", "text": "We used the PubMed interface to access the US National Library of Medicine and retrieve from it scholarly articles. We searched for publication on the metabolic syndrome (MetS) using the keyphrase\u201cmetabolic syndrome\u201d and collected papers written in English. The earliest publication found was that by Berardinelli et al. [8]. We collected all matching publications up to the final one indexed by PubMed on 10th Jan 2016, yielding a corpus of 31,706 publications.\n1) Pre-processing: The raw data collected from PubMed is in the form of free text. To prepare it for automatic analysis a series of \u2018pre-processing\u2019 steps are required. The goal is to remove words which are largely uninformative, reduce dispersal of semantically equivalent terms, and thereafter select terms which are included in the vocabulary over which topics are learnt.\nWe firstly applied soft lemmatization using the WordNetr lexicon [17] to normalize for word inflections. No stemming was performed to avoid semantic distortion often effected by heuristic rules used by stemming algorithms. After lemmatization and the removal of so-called stop-words, we obtained approximately 3.8 million terms in the entire corpus when repetitions are counted, and 46,114 unique terms. Constructing the vocabulary for our method by selecting the most frequent terms which explain 90% of the energy in a specific corpus resulted in a vocabulary containing 2,839 terms."}, {"heading": "B. Results", "text": "We stared evaluation by examining whether the two topic relatedness measures (BHD and KLD) are capturing different\naspects of relatedness. To obtain a quantitative measure we looked at the number of inter-topic connections formed in respective graphs both when the BHD is used as well as when the KLD is applied instead. The results were normalized by the total number of connections formed between two epochs, to account for changes in the total number of topics across time. Our results are summarized in Fig 2. A significant difference between the two graphs is readily evident \u2013 across the entire timespan of the data corpus, the number of Bhattacharyya distance based connections also formed through the use of the KLD is less than 40% and in most cases less than 30%. An even greater difference is seen when the proportion of the KLD connections is examined \u2013 it is always less than 25% and most of the time less than 15%.\nTo get an even deeper insight into the contribution of the two relatedness measures, we examined the corresponding topic graphs before edge pruning. The plot in Fig 3 shows the variation in inter-topic edge strengths computed using the BHD and the KLD (in forward and backward directions) \u2013 the former as the x coordinate of a point corresponding to a pair of topics, and the latter as its y coordinate. The scatter of data in the plot corroborates our previous observation that the two similarity measures indeed do capture different aspects of topic behaviour.\nWe performed extensive qualitative analysis which is necessitated by the nature of the problem at hand and the socalled \u2018semantic gap\u2019 that underlies it. In all cases we found that our algorithm revealed meaningful and useful information, as confirmed by an expert in the area of metabolic MetS research.\nOur final contribution comprises a web application which allows users to upload and analyse their data sets using the proposed framework. The application allows a range of powerful tasks to be performed quickly and in an intuitive manner. For example, the user can search for a given topic using keywords (and obtain a ranked list), trace the origin of a specific topic backwards in time, or follow its development in the forward direction, examine word clouds associated with topics, display a range of statistical analyses, or navigate the temporal relatedness graph."}, {"heading": "IV. SUMMARY AND CONCLUSIONS", "text": "In this work we presented a case for the importance of use of advanced machine learning techniques in the analysis and interpretation of medical literature. We described a novel framework based on non-parametric Bayesian techniques which is able to extract and track complex, semantically meaningful changes to the topic structure of a longitudinal document corpus. Moreover this work is the first to describe and present a method for differentiating between two types\nof topic structure changes, namely topic splitting and what we termed topic speciation. Experiments on a large corpus of medical literature concerned with the metabolic syndrome was used to illustrate the performance of our method. Lastly, we developed a web application which allows users such as medical researchers to upload their data sets and apply our method for their analysis; the application and its code will be made freely available following publication."}], "references": [{"title": "Assessing blinding in clinical trials", "author": ["O. Arandjelovi\u0107"], "venue": "Advances in Neural Information Processing Systems, 25:530\u2013538", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A new framework for interpreting the outcomes of imperfectly blinded controlled clinical trials", "author": ["O. Arandjelovi\u0107"], "venue": "PLOS ONE, 7(12):e48984", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Clinical trial adaptation by matching evidence in complementary patient sub-groups of auxiliary blinding questionnaire responses", "author": ["O. Arandjelovi\u0107"], "venue": "PLOS ONE, 10(7):e0131524", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Discovering hospital admission patterns using models learnt from electronic hospital records", "author": ["O. Arandjelovi\u0107"], "venue": "Bioinformatics, 31(24):3970\u2013 3976", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Prediction of health outcomes using big (health) data", "author": ["O. Arandjelovi\u0107"], "venue": "In Proc. International Conference of the IEEE Engineering in Medicine and Biology Society,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Sample-targeted clinical trial adaptation", "author": ["O. Arandjelovi\u0107"], "venue": "Proc. AAAI Conference on Artificial Intelligence, 3:1693\u20131699", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "On the discovery of hospital admission patterns \u2013 a clarification", "author": ["O. Arandjelovi\u0107"], "venue": "Bioinformatics", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "D", "author": ["W. Berardinelli", "J.G. Cordeiro"], "venue": "de Albuquerque, and A. Couceiro. A new endocrine-metabolic syndrome probably due to a global hyperfunction of the somatotrophin. Acta Endocrinologica, 12(1):69\u201380", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1953}, {"title": "Hierarchical Dirichlet process for tracking complex topical structure evolution and its application to autism research literature", "author": ["A. Beykikhoshk", "O. Arandjelovi\u0107", "D. Phung", "S. Venkatesh"], "venue": "Proc. Pacific-Asia Conference on Knowledge Discovery and Data Mining, 1:550\u2013562", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Overcoming data scarcity of Twitter: using tweets as bootstrap with application to autism-related topic content analysis", "author": ["A. Beykikhoshk", "O. Arandjelovi\u0107", "D. Phung", "S. Venkatesh"], "venue": "In Proc. IEEE/ACM International Conference on Advances in Social Network Analysis and Mining,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Data-mining Twitter and the autism spectrum disorder: a pilot study", "author": ["A. Beykikhoshk", "O. Arandjelovi\u0107", "D. Phung", "S. Venkatesh", "T. Caelli"], "venue": "Proc. IEEE/ACM International Conference on Advances in Social Network Analysis and Mining, pages 349\u2013356", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Using Twitter to learn about the autism community", "author": ["A. Beykikhoshk", "O. Arandjelovi\u0107", "D. Phung", "S. Venkatesh", "T. Caelli"], "venue": "Social Network Analysis and Mining, 5(1):5\u201322", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamic topic models", "author": ["D. Blei", "J. Lafferty"], "venue": "Proc. IMLS International Conference on Machine Learning, pages 113\u2013120", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Evaluating model-driven development for large-scale EHRs through the openEHR approach", "author": ["B. Christensen", "G. Ellingsen"], "venue": "Int J Med Inform, 89:43\u201354", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Is science mostly driven by ideas or by tools? Science", "author": ["F.J. Dyson"], "venue": "338(6113):1426\u20131427", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "A Bayesian analysis of some nonparametric problems", "author": ["T.S. Ferguson"], "venue": "The Annals of Statistics, pages 209\u2013230", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1973}, {"title": "WordNet: a lexical database for English", "author": ["G.A. Miller"], "venue": "Communications of the ACM, 38(11):39\u201341", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1995}, {"title": "Markov chain sampling methods for Dirichlet process mixture models", "author": ["M.N. Radford"], "venue": "Journal of Computational and Graphical Statistics, 9(2):249\u2013265", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "Report on the causes of death in India: 2001\u20132003", "author": ["RGI-CGHR Collaborators"], "venue": "Office of the Registrar General of India", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "On Bayesian analysis of mixtures with an unknown number of components (with discussion)", "author": ["S. Richardson", "P.J. Green"], "venue": "Journal of the Royal Statistical Society, 59(4):731\u2013792", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1997}, {"title": "Hierarchical Dirichlet processes", "author": ["Y.W. Teh", "M.I. Jordan", "M.J. Beal", "D.M. Blei"], "venue": "Journal of the American Statistical Association, 101(476):1566\u20131581", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Prediction of future hospital admissions \u2013 what is the tradeoff between specificity and accuracy? In Proc", "author": ["I. Vasiljeva", "O. Arandjelovi\u0107"], "venue": "International Conference on Bioinformatics and Computational Biology", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Towards sophisticated learning from EHRs: increasing prediction specificity and accuracy using clinically meaningful risk criteria", "author": ["I. Vasiljeva", "O. Arandjelovi\u0107"], "venue": "Proc. International Conference of the IEEE Engineering in Medicine and Biology Society", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 137, "endOffset": 140}, {"referenceID": 1, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 142, "endOffset": 145}, {"referenceID": 5, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 147, "endOffset": 150}, {"referenceID": 2, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 152, "endOffset": 155}, {"referenceID": 10, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 169, "endOffset": 173}, {"referenceID": 4, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 390, "endOffset": 393}, {"referenceID": 10, "context": "Concurrently and in no small part propelled by the environment just described, research in artificial intelligence \u2013 in machine learning [1], [2], [6], [3], data mining [11], and pattern recognition, in particular \u2013 has reached a sufficient level of methodological sophistication and maturity to process and analyse the collected data, with the aim of extracting novel and useful knowledge [5], [11].", "startOffset": 395, "endOffset": 399}, {"referenceID": 13, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 117, "endOffset": 121}, {"referenceID": 3, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 123, "endOffset": 126}, {"referenceID": 6, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 128, "endOffset": 131}, {"referenceID": 21, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 133, "endOffset": 137}, {"referenceID": 22, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 139, "endOffset": 143}, {"referenceID": 18, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 198, "endOffset": 202}, {"referenceID": 11, "context": "Usually the concept of so-called \u201cbig data\u201d in medicine is associated with the analysis of Electronic Health Records [14], [4], [7], [22], [23], large scale sociodemographic surveys of death causes [19], social media mining for health related data [12] etc.", "startOffset": 248, "endOffset": 252}, {"referenceID": 12, "context": "Here the term \u2018static\u2019 is used to describe the lack of any associated temporal information associated with the documents in a corpus \u2013 the documents are said to be exchangeable [13].", "startOffset": 177, "endOffset": 181}, {"referenceID": 14, "context": "Consequently the topic structure of the corpus changes over time [15], [9], [10]: new ideas emerge, old ideas are refined, novel discoveries result in multiple ideas being related to one another thereby forming more complex concepts or a single idea multifurcating into different \u2018sub-ideas\u2019 etc.", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "Consequently the topic structure of the corpus changes over time [15], [9], [10]: new ideas emerge, old ideas are refined, novel discoveries result in multiple ideas being related to one another thereby forming more complex concepts or a single idea multifurcating into different \u2018sub-ideas\u2019 etc.", "startOffset": 71, "endOffset": 74}, {"referenceID": 9, "context": "Consequently the topic structure of the corpus changes over time [15], [9], [10]: new ideas emerge, old ideas are refined, novel discoveries result in multiple ideas being related to one another thereby forming more complex concepts or a single idea multifurcating into different \u2018sub-ideas\u2019 etc.", "startOffset": 76, "endOffset": 80}, {"referenceID": 19, "context": "on the number of sources [20].", "startOffset": 25, "endOffset": 29}, {"referenceID": 15, "context": "Dirichlet Process (DP) in particular allows for the model to accommodate a potentially infinite number of mixture components [16]:", "startOffset": 125, "endOffset": 129}, {"referenceID": 17, "context": ") is the kernel of the mixing components, a Dirichlet process mixture model (DPM) is obtained [18].", "startOffset": 94, "endOffset": 98}, {"referenceID": 20, "context": "The hierarchical DP (HDP) [21] offers a solution whereby base measures of group-level DPs are drawn from a corpus-level DP.", "startOffset": 26, "endOffset": 30}, {"referenceID": 20, "context": "In this way the atoms of the corpus-level DP are shared across the documents; posterior inference is readily achieved using Gibbs sampling [21].", "startOffset": 139, "endOffset": 143}, {"referenceID": 0, "context": "In other words if F\u03c1 is the CDF corresponding to a specific initial, fully connected graph formed using a particular similarity measure (BHD or KLD), and \u03b6 \u2208 [0, 1] the CDF operating point, we prune the edge between topics \u03c6j,t and \u03c6k,t+1 iff \u03c1(\u03c6j,t, \u03c6k,t+1) < F\u22121 \u03c1 (\u03b6).", "startOffset": 158, "endOffset": 164}, {"referenceID": 7, "context": "[8].", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "We firstly applied soft lemmatization using the WordNetr lexicon [17] to normalize for word inflections.", "startOffset": 65, "endOffset": 69}], "year": 2016, "abstractText": "The rapidly expanding corpus of medical research literature presents major challenges in the understanding of previous work, the extraction of maximum information from collected data, and the identification of promising research directions. We present a case for the use of advanced machine learning techniques as an aide in this task and introduce a novel methodology that is shown to be capable of extracting meaningful information from large longitudinal corpora, and of tracking complex temporal changes within it.", "creator": "LaTeX with hyperref package"}}}