{"id": "1608.04428", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Aug-2016", "title": "TerpreT: A Probabilistic Programming Language for Program Induction", "abstract": "we study machine learning formulations of inductive program synthesis ; given input - output examples, we try to synthesize source derived code that maps inputs to corresponding outputs. our aims are to develop new machine learning approaches based on neural networks syntax and graphical models, and to specifically understand the capabilities of machine learning techniques found relative to traditional alternatives, such alternatives as those being based strongly on constraint solving from the programming languages community.", "histories": [["v1", "Mon, 15 Aug 2016 22:34:50 GMT  (5474kb,D)", "http://arxiv.org/abs/1608.04428v1", "50 pages, 20 figures, 4 tables"]], "COMMENTS": "50 pages, 20 figures, 4 tables", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.NE", "authors": ["alexander l gaunt", "marc brockschmidt", "rishabh singh", "nate kushman", "pushmeet kohli", "jonathan taylor", "daniel tarlow"], "accepted": false, "id": "1608.04428"}, "pdf": {"name": "1608.04428.pdf", "metadata": {"source": "CRF", "title": "TerpreT: A Probabilistic Programming Language for Program Induction", "authors": ["Alexander L. Gaunt", "Marc Brockschmidt", "Rishabh Singh", "Nate Kushman", "Pushmeet Kohli", "Jonathan Taylor", "Daniel Tarlow"], "emails": ["t-algaun@microsoft.com", "mabrocks@microsoft.com", "risin@microsoft.com", "nkushman@microsoft.com", "pkohli@microsoft.com", "jtaylor@perceptiveio.com", "dtarlow@microsoft.com"], "sections": [{"heading": null, "text": "Our key contribution is the proposal of TerpreT, a domain-specific language for expressing program synthesis problems. TerpreT is similar to a probabilistic programming language: a model is composed of a specification of a program representation (declarations of random variables) and an interpreter that describes how programs map inputs to outputs (a model connecting unknowns to observations). The inference task is to observe a set of input-output examples and infer the underlying program. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing proper like-to-like comparisons between different approaches to inference. From a single TerpreT specification we can automatically perform inference using four different back-ends that include machine learning and program synthesis approaches. These are based on gradient descent (thus each specification can be seen as a differentiable interpreter), linear program (LP) relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system.\nWe illustrate the value of TerpreT by developing several interpreter models and performing an extensive empirical comparison between alternative inference algorithms on a variety of program models. Our key, and perhaps surprising, empirical finding is that constraint solvers dominate the gradient descent and LP-based formulations. We conclude with some suggestions on how the machine learning community can make progress on program synthesis."}, {"heading": "1 Introduction", "text": "Learning computer programs from input-output examples, or Inductive Program Synthesis (IPS), is a fundamental problem in computer science, dating back at least to Summers (1977) and Biermann (1978). The field has produced many successes, with perhaps the most visible example being the FlashFill system in Microsoft Excel (Gulwani, 2011; Gulwani et al., 2012).\n\u2217Work done while author was at Microsoft Research.\nar X\niv :1\n60 8.\n04 42\n8v 1\n[ cs\n.L G\nLearning from examples is also studied extensively in the statistics and machine learning communities. Trained decision trees and neural networks could be considered to be synthesized computer programs, but it would be a stretch to label them as such. Relative to traditional computer programs, these models typically lack several features: (a) key functional properties are missing, like the ability to interact with external storage, (b) there is no compact, interpretable source code representation of the learned model (in the case of neural networks), and (c) there is no explicit control flow (e.g. while loops and if statements). The absence of a precise control flow is a particular hindrance as it can lead to poor generalization. For example, whereas natural computer programs are often built with the inductive bias to use control statements ensuring correct execution on inputs of arbitrary size, models like Recurrent Neural Networks can struggle to generalize from short training instances to instances of arbitrary length.\nSeveral models have already been proposed which start to address the functional differences between neural networks and computer programs. These include Recurrent Neural Networks (RNNs) augmented with a stack or queue memory (Giles et al., 1989; Joulin and Mikolov, 2015; Grefenstette et al., 2015), Neural Turing Machines (Graves et al., 2014), Memory Networks (Weston et al., 2014), Neural GPUs (Kaiser and Sutskever, 2016), Neural Programmer-Interpreters (Reed and de Freitas, 2016), and Neural Random Access Machines (Kurach et al., 2015). These models combine deep neural networks with external memory, external computational primitives, and/or built-in structure that reflects a desired algorithmic structure in their execution. Furthermore, they have been been shown to be trainable by gradient descent. However, they do not fix all of the absences noted above. First, none of these models produce programs as output. That is, the representation of the learned model is not interpretable source code. Instead, the program is hidden inside \u201ccontrollers\u201d composed of neural networks that decide which operations to perform, and the learned \u201cprogram\u201d can only be understood in terms of the executions that it produces on specific inputs. Second, there is still no concept of explicit control flow in these models.\nThese works raise questions of (a) whether new models can be designed specifically to synthesize interpretable source code that may contain looping and branching structures, and (b) whether searching over program space using techniques developed for training deep neural networks is a useful alternative to the combinatorial search methods used in traditional IPS. In this work, we make several contributions in both of these directions.\nTo address the first question we develop models inspired by intermediate representations used in compilers like LLVM (Lattner and Adve, 2004) that can be trained by gradient descent. These models address all of the deficiencies highlighted at the beginning of this section: they interact with external storage, handle non-trivial control flow with explicit if statements and loops, and, when appropriately discretized, a learned model can be expressed as interpretable source code. We note two concurrent works, Adaptive Neural Compilation (Bunel et al., 2016) and Differentiable Forth (Riedel et al., 2016), which implement similar ideas. Each design choice when creating differentiable representations of source code has an effect on the inductive bias of the model and the difficulty of the resulting optimization problem. Therefore, we seek a way of rapidly experimenting with different formulations to allow us to explore the full space of modelling variations.\nTo address the second question, concerning the efficacy of gradient descent, we need a way of specifying an IPS problem such that the gradient based approach can be compared to a variety of alternative approaches in a like-for-like manner. These alternative approaches originate from both a rich history of IPS in the programming languages community and a rich literature of techniques for inference in discrete graphical models in the machine learning community. To our knowledge, no such comparison has previously been performed.\nThese questions demand that we explore both a range of model variants and a range of search techniques on top of these models. Our answer to both of these issues is the same: TerpreT, a new probabilistic programming language for specifying IPS problems. TerpreT provides a means for describing an execution model (e.g., a Turing Machine, an assembly language, etc.) by defining a parameterization (a program representation) and an interpreter that maps inputs to outputs using the parametrized program. This TerpreT description is independent of any particular inference algorithm. The IPS task is to infer the execution model parameters (the program) given an execution model and pairs of inputs and outputs. To perform inference, TerpreT is automatically \u201ccompiled\u201d into an intermediate representation which can be fed to a particular inference algorithm. Interpretable source code can be obtained directly from the inferred model parameters. The driving design principle for TerpreT is to strike a subtle balance between the breadth of expression needed to precisely capture a range of execution models, and the\nrestriction of expression needed to ensure that automatic compilation to a range of different back-ends is tractable.\nTerpreT currently has four back-end inference algorithms, which are listed in Table 1: gradientdescent (thus any TerpreT model can be viewed as a differentiable interpreter), (integer) linear program (LP) relaxations, SMT, and the Sketch program synthesis system (Solar-Lezama, 2008). To allow all of these back-ends to be used regardless of the specified execution model requires some generalizations and extensions of previous work. For the gradient descent case, we generalize the approach taken by Kurach et al. (2015), lifting discrete operations to operate on discrete distributions, which then leads to a differentiable system. For the linear program case, we need to extend the standard LP relaxation for discrete graphical models to support if statements. In Section 4.3, we show how to adapt the ideas of gates (Minka and Winn, 2009) to the linear program relaxations commonly used in graphical model inference (Schlesinger, 1976; Werner, 2007; Wainwright and Jordan, 2008). This could serve as a starting point for further work on LP-based message passing approaches to IPS (e.g., following Sontag et al. (2008)).\nFinally, having built TerpreT, it becomes possible to develop understanding of the strengths and weaknesses of the alternative approaches to inference. To understand the limitations of using gradient descent for IPS problems, we first use TerpreT to define a simple example where gradient descent fails, but which the alternative back-ends solve easily. By studying this example we can better understand the possible failure modes of gradient descent. We prove that there are exponentially many local optima in the example and show empirically that they arise often in practice (although they can be mitigated significantly by using optimization heuristics like adding noise to gradients during training (Neelakantan et al., 2016b)). We then perform a comprehensive empirical study comparing different inference back-ends and program representations. We show that some domains are significantly more difficult for gradient descent than others and show results suggesting that gradient descent performs best when given redundant, overcomplete parameterizations. However, the overwhelming trend in the experiments is that the techniques from the programming languages community outperform the machine learning approaches by a significant margin.\nIn summary, our main contributions are as follows:\n\u2022 A novel \u2018Basic Block\u2019 execution model that enables learning programs with complex control flow (branching and loops).\n\u2022 TerpreT, a probabilistic programming language tailored to IPS, with back-end inference algorithms including techniques based on gradient descent, linear programming, and highly-efficient systems from the programming languages community (SMT and Sketch). TerpreT also allows \u201cprogram\nsketching\u201d, in which a partial solution is provided to the IPS system. For this, some parameters of an execution model can simply be fixed, e.g. to enforce control flow of a specified shape.\n\u2022 A novel linear program relaxation to handle the if statement structure that is common in execution models, and a generalization of the smoothing technique from Kurach et al. (2015) to work on any execution model expressible in TerpreT.\n\u2022 Analytic and experimental comparisons of different inference techniques for IPS and experimental comparisons of different modelling assumptions.\nThis report is arranged as follows: We briefly introduce the \u2018Basic Block\u2019 model in Section 2 to discuss what features TerpreT needs to support to allow modeling of rich execution models. In Section 3 we describe the core TerpreT language and illustrate how to use it to explore different modeling assumptions using several example execution models. These include a Turing Machine, Boolean Circuits, a RISC-like assembly language, and our Basic Block model. In Section 4 we describe the compilation of TerpreT models to the four back-end algorithms listed in Table 1. Quantitative experimental results comparing these back-ends on the aforementioned execution models is presented in Section 6. Finally, related work is summarized in Section 7 and we discuss conclusions and future work in Section 8."}, {"heading": "2 Motivating Example: Differentiable Control Flow Graphs", "text": "As an introductory example, we describe a new execution model that we would like to use for IPS. In this section, we describe the model at a high level. In later sections, we describe how to express the model in TerpreT and how to perform inference.\nControl flow graphs (CFGs) (Allen, 1970) are a representation of programs commonly used for static analysis and compiler optimizations. They consist of a set of basic blocks, which contain sequences of instructions with no jumps (i.e., straight-line code) followed by a jump or conditional jump instruction to transfer control to another block. CFGs are expressive enough to represent all of the constructs used in modern programming languages like C++. Indeed, the intermediate representation of LLVM is based on basic blocks.\nOur first model is inspired by CFGs but is limited to use a restricted set of instructions and does not support function calls. We refer to the model as the Basic Block model. An illustration of the model appears in Fig. 1. In more detail, we specify a fixed number of blocks B, and we let there be R registers that can take on values 0, . . . ,M \u2212 1. We are given a fixed set of instructions that implement basic\narithmetic operations, like ADD, INCREMENT, and LESS-THAN. An external memory can be written to and read from using special instructions READ and WRITE. There is an instruction pointer that keeps track of which block is currently being executed. Each block has a single statement parameterized by two argument registers, the instruction to be executed, and the register in which to store the output. After the statement is executed, a condition is checked, and a branch is taken. The condition is parameterized by a choice of register to check for equality to 0 (C-style interpretation of integers as booleans). Based upon the result, the instruction pointer is updated to be equal to the then block or the else block. The identities of these blocks are the parameterization of the branch decision.\nThe model is set up to always start execution in block 0, and a special end block is used to denote termination. The program is executed for a fixed maximum number of timesteps T . To represent inputoutput examples, we can set an initial state of external memory, and assert that particular elements in the final memory should have the desired value upon termination.\nThe job for TerpreT in this case is to precisely describe the execution model\u2014how statements are executed and the instruction pointer is updated\u2014in a way which can be translated into a fully differentiable interpreter for the Basic Block language or into an intermediate representation for passing to other back-ends. In the next sections, we describe in more detail how TerpreT execution models are specified and how the back-ends work."}, {"heading": "3 Front-end: Describing an IPS problem", "text": "One of our central aims is to disentangle the description of an execution model from the inference task so that we can perform like-for-like comparisons between different inference approaches to the same IPS task. For reference, the key components for solving an IPS problem are illustrated in Fig. 2. In the forward mode the system is analogous to a traditional interpreter, but in a reverse mode, the system infers a representation of source code given only observed outputs from a set of inputs. Even before devising an inference method, we need both a means of parameterizing the source code of the program, and also a precise description of the interpreter layer\u2019s forward transformation. This section describes how these modeling tasks are achieved in TerpreT.\n3.1 The TerpreT Probabilistic Programming Language The full grammar for syntactically correct TerpreT programs is shown in Fig. 3, and we describe the key semantic features of the language in the following sections. For illustration, we use a running example of a simple automaton shown in Fig. 4. In this example the \u2018source code\u2019 is parameterised by a 2\u00d7 2 boolean array, ruleTable, and we take as input the first two values on a binary tape of length T , {tape[0], tape[1]}. The forward execution of the interpreter could be described by the following simple Python snippet:\n1 for t in range(1, T \u2212 1): 2 tape[t + 1] = ruleTable[ tape[t \u2212 1], tape [t] ]\nGiven an observed output, tape[T \u2212 1], inference of a consistent ruleTable is very easy in this toy problem, but it is instructive to analyse the TerpreT implementation of this automaton in the following sections. These sections describe variable declaration, control flow, user defined functions and handling of observations in TerpreT."}, {"heading": "3.1.1 Declarations and Assignments", "text": "We allow declarations to give names to \u201cmagic\u201d constants, as in line 1 of Fig. 4. Additionally, we allow the declaration of parameters and variables, ranging over a finite domain 0, 1, . . . N \u2212 1 using Param(N) and Var(N), where N has to be a compile-time constant (i.e., a natural number or an expression over constants). Parameters are used to model the source code to be inferred, whereas variables are used to model the computation (i.e., intermediate values). For convenience, (multi-dimensional) arrays of variables can be declared using the syntax foo = Var(N)[dim1, dim2, ...], and accessed as foo[idx1, idx2, ...]. Similar syntax is available for Params. These arrays can be unrolled during compilation such that unique symbols representing each element are passed to an inference algorithm, i.e., they do not require special support in the inference backend. For this reason, dimensions dimi and indices idxi need to be compile-time constants. Example variable declarations can be seen in lines 6 and 11 of Fig. 4.\nAssignments to declared variables are not allowed via the usual assignment operator (var = expr) but are instead written as var.set to(expr), to better distinguish them from assignments to constant variables. Static single assignment (SSA) form is enforced, and it is only legal for a variable to appear multiple times as the target of set to statements if each assignment appears in different cases of a conditional block. Because of the SSA restriction, a variable can only be written once. However, note that programs that perform multiple writes to a given variable can always be translated to their corresponding SSA forms."}, {"heading": "3.1.2 Control flow", "text": "TerpreT supports standard control-flow structures such as if-else (where elif is the usual shorthand for else if) and for. In addition, TerpreT uses a unique with structure. The need for the latter is induced by our requirement to only use compile-time constants for accessing arrays. Thus, to set the 2nd element of tape in our toy example (i.e., the first step of the computation), we need code like the following to access the values of the first two values on the tape:\n1 if tape[1] == 0:\n2 if tape[0] == 0:\n3 tape[2].set to(ruleTable[0,0])\n4 elif tape[0] == 1:\n5 tape[2].set to(ruleTable[1,0])\n6 elif tape[1] == 1:\n7 if tape[0] == 0:\n8 tape[2].set to(ruleTable[0,1])\n9 elif tape[0] == 1:\n10 tape[2].set to(ruleTable[1,1])\nIntuitively, this snippet simply performs case analyses over all possible values of tape[1] and tape[0]. To simplify this pattern, we introduce the with var as id: stmt control-flow structure, which allows to automate this unrolling, or avoid it for back-ends that do not require it (such as Sketch). To this end, all possible possible values 0, . . . , N \u2212 1 of var (known from its declaration) are determined, and the with-statement is transformed into if id == 0 then: stmt[var/0]; elif id == 1 then: stmt[var/1]; ...elif id == n then: stmt[var/(N \u2212 1)];, where stmt[var/n] denotes the statement stmt in which\nall occurrences of the variable var have been replaced by n. Thus, the snippet from above can be written as follows.\n1 with tape[1] as x1:\n2 with tape[0] as x0:\n3 tape[2].set to(ruleTable[x0,x1])\nIn TerpreT, for loops may only take the shape for id in range(c1, c2): stmt, where c1 and c2 are compile-time constants. Similar to the with statement, we can unroll such loops explicitly during compilation, and thus if the values of c1 and c2 are n1 and n2, we generate stmt[id/n1]; stmt[id/(n1 +1)]; ...; stmt[id/(n2 \u2212 1)]. Using the with and for statements, we can thus describe the evaluation of our example automaton for const T timesteps as shown in lines 14-17 of Fig. 4."}, {"heading": "3.1.3 Operations", "text": "TerpreT supports user-defined functions to facilitate modelling interpreters supporting non-trivial instruction sets. For example, bar(arg1,. . .,argM) will apply the function bar to the arguments arg1,. . .,argM . The function bar: ZM \u2192 Z can be defined as a standard Python function with the additional decoration @CompileMe(in domains, out domain), specifying the domains of the input and output variables.\nTo illustrate this feature, Fig. 5 shows variation of the running example where the automaton updates the tape according to a ruleTable which depends only on the sum of the preceding two entries. This is\nimplemented using the function add in lines 3-6. Note that we use standard Python to define this function and leave it up to the compiler to present the function appropriately to the inference algorithm."}, {"heading": "3.1.4 Modelling Inputs and Outputs", "text": "Using statements from the preceding sections, an execution model can be fully specified, and we now connect this model to input/output observations to drive the program induction. To this end, we use the statements set to constant (resp. observe value) to model program input (resp. program output). Thus, a single input-output observation for the running example could be written in TerpreT as follows.\n1 # input\n2 tape[0].set to constant(1)\n3 tape[1].set to constant(0)\n4\n5 # output 6 tape[const T \u2212 1].observe value(1)\nTo keep the execution model and the observations separate, we store the observation snippets in a separate file and use preprocessor directives # IMPORT OBSERVED * to pull in the appropriate snippets before compilation (see lines 13 and 18 of Fig. 4). We also allow any constant literals to be stored separately from the TerpreT execution model, and we import these values using preprocessor directives of the form vc = # HYPERPARAM vc .\nIn general, we want to infer programs from nobs > 1 input-output examples. The simplest implementation achieves this by augmenting each Var declaration with an additional array dimension of size nobs and wrapping the execution model in a for loop over the examples. Examples of this are the outermost loops in the models in Appendix B."}, {"heading": "3.2 Example Execution Models", "text": "To illustrate the versatility of TerpreT, we use it to describe four example execution models. Broadly speaking, the examples progress from more abstract execution models towards models which closely resemble assembly languages for RISC machines.\nIn each case, we present the basic model and fill in three representative synthesis tasks in Table 2 to investigate. In addition, we provide the metrics for the \u201cdifficulty\u201d of each task calculated from the minimal computational resources required in a solution. Since the difficulty of a synthesis problem generally depends on the chosen inference algorithm these metrics are primarily intended to give a sense of the scale of the problem. The first difficulty metric, D, is the number of structurally distinct (but not necessarily functionally distinct) programs which would have to be enumerated in a worst-case brute-force search, and the second metric, T , is the unrolled length of all steps in the synthesized program."}, {"heading": "3.2.1 Automaton: Turing Machine", "text": "A Turing machine consists of an infinite tape of memory cells which each contain one of S symbols, and a head which moves over the tape in one of H + 1 states (one state is the special halt case). At each execution step, while the head is in an unhalted state ht, it reads the symbol st at its current position, xt, on the tape, then it writes the symbol newValue[st,ht] to position xt, moves in the direction specified by direction[st,ht] (one cell left or right or no move) and adopts a new state newState[st,ht]. The source code for the Turing machine is the entries of the control tables newValue, direction and newState, which can be in any of D = [3S(H + 1)]SH configurations.\nWe modify the canonical Turing machine to have a circular tape of finite length, L, as described in the TerpreT model in Appendix B.1. For each of our examples, we represent the symbols on the tape as {0, 1, blank}."}, {"heading": "3.2.2 Straight-line programs: Boolean Circuits", "text": "As a more complex model, we now consider a simple machine capable of performing a sequence of logic operations (AND, OR, XOR, NOT, COPY) on a set of registers holding boolean values. Each operation takes two registers as input (the second register is ignored in the NOT and COPY operation), and outputs to one register, reminiscent of standard three-address code assembly languages. To embed this example in a realworld application, analogies linking the instruction set to electronic logic gates and linking the registers to electronic wires can be drawn. This analogy highlights one benefit of interpretability in our model: the synthesized program describes a digital circuit which could easily be translated to real hardware (see e.g. Fig. 20). The TerpreT implementation of this execution model is shown in Appendix B.2.\nThere are D = HTR3T possible programs (circuits) for a model consisting of T sequential instructions (logic gates) each chosen from the set of H = 5 possible operations acting on R registers (wires)."}, {"heading": "3.2.3 Loopy programs 1: Basic block model", "text": "To build loopy execution models, we take inspiration from compiler intermediate languages (e.g., LLVM Intermediate Representation), modeling full programs as graphs of \u201cbasic blocks\u201d. Such programs operate on a fixed number of registers, and a byte-addressable heap store accessible through special instructions, READ and WRITE. Each block has an instructions of the form regout = instr regin1 regin2, followed by a branch decision if regcond > 0 goto blockthen else goto blockelse (see Fig. 1, and the TerpreT model in Appendix B.3). This representation can easily be transformed back and forth to higher-level program source code (by standard compilation/decompilation techniques) as well as into executable machine code.\nWe use an instruction set containing H = 9 instructions: ZERO, INC, DEC, ADD, SUB, LESSTHAN, READ, WRITE and NOOP. This gives D = [HR4(B + 1)2]B possible programs for a system with R registers and (B + 1) basic blocks (including a special stop block which executes NOOP and redirects to itself). We consider the case where registers and heap memory cells all store a single data type - integers in the range 0, ..,M \u2212 1, where M is the number of memory cells on the heap. This single data type allows both intermediate values and pointers into the heap to be represented in the registers and heap cells.\nWhile this model focuses on interpretability, it also builds on an observation from the results of Kurach et al. (2015). In NRAMs, a RNN-based controller chooses a short sequence of instructions to execute next based on observations of the current program state. However, the empirical evaluation reports that correctly trained models usually picked one sequence of instructions in the first step, and then repeated another sequence over and over until the program terminates. Intuitively, this corresponds to a loop initialization followed by repeated execution of a loop body, something which can naturally be expressed in the Basic Block model."}, {"heading": "3.2.4 Loopy programs 2: Assembly model", "text": "In the basic block model every expression is followed by a conditional branch, giving the model great freedom to represent rich control flow graphs. However, useful programs often execute a sequence of several expressions between each branch. Therefore, it may be beneficial to bias the model to create chains of sequentially ordered basic blocks with only occasional branching where necessary. This is achieved by replacing the basic blocks with objects which more closely resemble lines of assembly code. The instruction set is augmented with the jump statements jump-if-zero (JZ(regin1) : branchAddr), and jump-if-not-zero (JNZ(regin1) : branchAddr), the operation of which are shown in Fig. 6 (and in the TerpreT code in Appendix B.4). Each line of code acts like a conditional branch only if the assigned instr \u2208 {JZ, JNZ} otherwise it acts like a single expression which executes and passes control to the next line of code. This assembly model can express the same set of programs as the basic block model, and serves as an example of how the design of the model affects the success of program inference.\nIn addition, we remove NOOP from the instruction set (which can be achieved by a jump operation pointing to the next line) leaving H = 10 instructions, and we always include a special stop line as the (B + 1)th line of the program. The total size of the search space is then D = [HR3(B + 1)]B ."}, {"heading": "4 Back-ends: Solving the IPS problem", "text": "TerpreT is designed to be compiled to a variety of intermediate representations for handing to different inference algorithms. This section outlines the compilation steps for each of the back-end algorithms listed in Table 1.\nFor each back-end we present the compiler transfomation of the TerpreT primitives listed in Fig. 7. For some back-ends, we find it useful to present these transformations via an intermediate graphical representation resembling a factor graph, or more specifically, a gated factor graph (Minka and Winn, 2009), which visualises the TerpreT program. Below we describe gated factor graphs and provide the mapping from TerpreT syntax to primitives in these models. Then in Section 4.2 - 4.5 we show how to compile TerpreT for each back-end solver.\n4.1 TerpreT for Gated Factor Graph Description A factor graph is a means of representing the factorization of a complex function or probability distribution into a composition of simpler functions or distributions. In these graphs, inputs, outputs and intermediate results are stored in variable nodes linked by factor nodes describing the functional relationships between variables. A TerpreT model defines the structure of a factor graph, and an inference algorithm is used to populate the variable nodes with values consistent with observations.\nParticular care is needed to describe factor graphs containing conditional branches since the value of a variable Xi in conditions of the form Xi == c is not known until inference is complete. This means that we must explore all branches during inference. Gated factor graphs can be used to handle these if statements, and we introduce additional terminology to describe these gated models below. Throughout the next sections we refer to the TerpreT snippet shown in Fig. 8 for illustration.\nLocal unary marginal. We restrict attention to the case where each variable Xi is discrete, with finite domain Xi = {0, . . . , Ni \u2212 1}. For each variable we instantiate a local unary marginal \u00b5i(x) defined on the support x \u2208 Xi. In an integral configuration, we demand that \u00b5i(x) is only non-zero at a particular value x\u2217i , allowing us to interpret Xi = x\u2217i . Some inference techniques relax this constraint and consider a continuous model \u00b5i(x) \u2208 R \u2200x \u2208 Xi. In these relaxed models, we apply continuous optimization schemes which, if successful, will converge on an interpretable integral solution.\nGates. Following Minka and Winn (2009), we refer to if statements as gates. More precisely, an if statement consists of a condition (an expression that evaluates to a boolean) and a body (a set of assignments or factors). We will refer to the condition as the gate condition and the body as the gate body. In this work, we restrict attention to cases where all gate conditions are of the form Xi == ConstExpr. In future work we could relax this restriction.\nGraph element TerpreT representation Graphical representation\nRandom variable (intermediate) Xi = Var(N) xi\nRandom variable (inference target) Xi = Param(N) xi\nObserved variable (input) Xi.set to constant(x\u2217) xi x* Observed variable (output) Xi.observe value(x\u2217)\nFactor (copy) X0.set to(X1) x1x0 Copy\nFactor (general) X0.set to(f(X1,X2,. . .)) x0x2\nx1 f\nIn the example in Fig. 8, there is a nested gate structure. At the outer-most level, there are two gates with gate conditions (X0 == 0) (lines 16-20) and (X0 == 1) (lines 21-22). Inside the (X0 == 0) gate, there are two nested gates (corresponding to (X1 == 0) and (X1 == 1)).\nPath conditions. Each gate A has a path condition \u03c8A, which is a list of variables and values they need to take on in order for the gate body to be executed. For example, in Fig. 8, the path condition for the innermost gate body on lines 19-20 is (X0 = 0, X1 = 1), where commas denote conjunction. We will use the convention that the condition in the deepest gate\u2019s if statement is the last entry of the path condition. Gates belong to a tree structure, and if gate B with gate condition \u03c6B is nested inside gate A with path condition \u03c8A, then we say that A is a parent of B, and the path condition for B is \u03c8B = (\u03c8A, \u03c6B). We can equally speak of the path condition \u03c8j of a factor j, which is the path condition of the most deeply nested gate that the factor is contained in.\nActive variables. Define a variable X to be active in a gate A if both of the following hold:\n\u2022 X is used in A or one of its descendants, and\n\u2022 X is declared in A or one of its ancestors.\nThat is, X is active in A iff A is on the path between X\u2019s declaration and one of its uses. For each gate A in which a variable is active, we instantiate a separate local marginal annotated with the path condition of A (\u03c8A). For example, inside the gate corresponding to (X0 == 0) in Fig. 8, the\n1 2 # X4 = 0 if X0 == 0 and X1 == 0 3 # | X2 + 1 if X0 == 0 and X1 == 1 4 # | 2\u2217X2 if X0 == 1 5 #\nlocal marginal for Xi is \u00b5X0=0i (x).1 In the global scope we drop the superscript annotation and just use \u00b5i(x). We can refer to parent-child relationships between different local marginals of the same variable; the parent (child) of a local marginal \u00b5\u03c8Ai (\u00b7) is the local marginal for Xi in the parent (child) gate of A.\nGate marginals. Let the gate marginal of a gate A be the marginal of the gate\u2019s condition in the parent gate of A. In Fig. 8, the first outer gate\u2019s gate marginal is \u00b50(0), and the second outer gate\u2019s is \u00b50(1). In the inner gate, the gate marginal for the (X1 == 0) gate is \u00b5X0=01 (0)."}, {"heading": "4.2 Forward Marginals Gradient Descent (FMGD) Back-end", "text": "The factor graphs discussed above are easily converted into computation graphs representing the execution of an interpreter by the following operations.\n\u2022 Annotate the factor graph edges with the direction of traversal during forwards execution of the TerpreT program.\n\u2022 Associate executable functions fi with factor i operating on scope Si = {X, Y }. The function transforms the incoming variables X to the outgoing variable, Y = fi(X).\n1Strictly speaking, this notation does not handle the case where there are multiple gates with identical path conditions; for clearness of notation, assume that all gate path conditions are unique. However, the implementation handles repeated path conditions (by identifying local marginals according to a unique gate id).\nIn the FMGD approach, we initialize the source nodes of this directed graph by instantiating independent random variables Xp \u223c \u00b5p at each Param node, and variables Xi \u223c onehot(x\u2217i ) at nodes associated with input observations of the form Xi.set to constant(x\u2217i ). Here onehot(x\u2217i ) is a distribution over Xi with unit mass at x\u2217i . We then propagate these distributions through the computation graph using the FMGD approximation, described below, to obtain distributions \u00b5o at the output nodes associated with an observe value(x\u2217o) statement. This fuzzy system of distributions is fully differentiable. Therefore inference becomes an optimization task to maximize the weight \u00b5o(x\u2217o) assigned to the observations by updating the parameter distributions {\u00b5p} by gradient descent.\nThe key FMGD approximation arises whenever a derived variable, Y depends on several immediate input variables, X. In an ungated graph, this occurs at factor nodes where Y = fi(X). FMGD operates under the under the approximation that all X are independent. In this case, we imagine a local joint distribution \u00b5YX constructed according to the definition of fi and the independent unary marginal distributions for X. From this distribution we marginalize out all of the input variables to obtain the unary marginal \u00b5Y (see Section 4.2.1). Only \u00b5Y is propagated forward out of the factor node and correlations between Y and X (only captured by the full local joint distribution) are lost. In the next section we explicitly define these operations and extend the technique to allow for gates in the factor graph.\nIt is worth noting that there is a spectrum of approximations in which we form joint distributions for subgraphs of size ranging from single nodes (FMGD) to the full computation graph (enumerative search) with only independent marginal distributions propagated between subgraphs. Moving on this spectrum trades computational efficiency for accuracy as more correlations can be captured in larger subgraphs. An exploration of this spectrum could be a basis for future work."}, {"heading": "4.2.1 Forward Marginals...", "text": "Fig. 9 illustrates the transformation of each graphical primitive to allow a differentiable forward propagation of marginals through a factor graph. Below we describe more details of factor and gate primitives in this algorithm.\nFactors. The scope S of a factor function f contains the M immediate input variables Xi and the immediate output, Y . In this restricted environment, we enumerate the possible outputs Y from all\u220fM i=1 |Xi| possible input configurations xk of the form [xk]i \u2208 Xi for i \u2208 {1, ...,M}. We then marginalise over the configuration index, k, using weightings \u00b5i([xk]i) to produce \u00b5Y as follows:\n\u00b5Y (y) = \u2211 k 1{y = f(xk)}w(xk), (1)\nwhere 1 is an indicator function and the weighting function w is:\nw(xk) = M\u220f i=1 \u00b5i ([xk]i) . (2)\nNote that (1) and (2) can be implemented efficiently as a series of tensor contractions of the Mi + 1 dimensional binary tensor Iyx = 1{y = f(x)} with the Mi vectors [\u00b5i]x = \u00b5i(x).\nGates. We can include gates in the FMGD formulation as follows. Let B1, . . . , Bk be the set of child gates of A which are controlled by gate marginal \u00b5\u03c8AB (i) ; i \u2208 {1, ..., k}. Inside gate Bi, there is a subgraph Gi described by TerpreT code Ti which references a set of active variables Bi. We divide Bi into Li containing variables which are written-to during execution of Gi (i.e. appear on the left hand side of expressions in Ti), and Ri containing variables which are not written-to (i.e. appear only on the right hand side of expressions in Ti). In addition, we use A to refer to the active variables in A, and B+ \u2282 A to be variables used in the graph downstream of gates B1, . . . , Bk on paths which terminate at observed variables.\nOn entering gate Bi, we import references to variables in the parent scope, A, for all X \u2208 Ri \u2229 A:\n\u00b5 \u03c8Bi X = \u00b5 \u03c8A X . (3)\nWe then run Gi, to produce variables Li. Finally, when leaving a gate, we marginalise using the gate marginal to set variables Y \u2208 B+:\n\u00b5\u03c8AY (y) = k\u2211 i=1 \u00b5 \u03c8Bi Y (y)\u00b5 \u03c8A B (i). (4)\nRestrictions on factor functions. The description above is valid for any f : \u00d7Mi=1Xi \u2192 Y, subject to the condition that Y \u2286 Xout, where Xout is the domain of the variable which is used to store the output of f . One scenario where this condition could be violated is illustrated below:\n1 @CompileMe([4],2)\n2 def largeTest(x): return 1 if x >= 2 else 0 3 @CompileMe([4],4) 4 def makeSmall(x): return x \u2212 2 5\n6 X = Param(4) ; out = Var(4) ; isLarge = Var(2)\n7\n8 isLarge.set to(largeTest(X))\n9 if isLarge == 0:\n10 out.set to(X)\n11 elif isLarge == 1:\n12 out.set to(makeSmall(X))\nThe function makeSmall has a range Y = {\u22122, ..., 1} which contains elements outside Xout = {0, ..., 3}. However, deterministic execution of this program does not encounter any error because the path condition isLarge == 1 guarantees that the invalid cases Y \\Xout would never be reached. In general, it only makes\nsense to violate Y \u2286 Xout if we are inside a gate where the path condition ensures that the input values lie in a restricted domain X\u0303i \u2286 Xi such that f : \u00d7Mi=1X\u0303i \u2192 Xout. In this case a we can simply enforce the normalisation of \u00b5out to account for any leaked weight on values Y \\ Xout.\n\u00b5Y (y) = 1 Z \u2211 k 1{y = f(xk)}w(xk), where Z = \u2211 k,y\u2208Xout 1{y = f(xk)}w(xk). (5)\nWith this additional caveat, there are no further constraints on factor functions f : ZM \u2192 Z."}, {"heading": "4.2.2 ... Gradient Descent", "text": "Given a random initialization of marginals for the the Param variables Xp \u2208 P, we use the techniques above to propagate marginals forwards through the TerpreT model to reach all variables, Xo \u2208 O, associated with an observe value(x\u2217o) statement. Then we use a cross entropy loss, L, to compare the computed marginal to the observed value.\nL = \u2212 \u2211 Xo\u2208O log [\u00b5o(x\u2217o)] . (6)\nL reaches its lower bound L = 0 if each of the marginals \u00b5p(x) representing the Params put unit weight on a single value \u00b5p(x\u2217p) = 1 such that the assignments {Xp = x\u2217p} describe a valid program which explains the observations. The synthesis task is therefore an optimisation problem to minimise L, which we try to solve using backpropagation and gradient descent to reach a zero loss solution.\nTo preserve the normalisation of the marginals during this optimisation, rather than updating \u00b5p(x) directly, we update the log parameters mp(x) = [mp]x defined by \u00b5p(x) = softmax [mp(x)]. These are initialized according to\nexp(mp) \u223c Dirichlet(\u03b1), (7)\nwhere \u03b1 are hyperparameters."}, {"heading": "4.2.3 Optimization Heuristics", "text": "Using gradient information to search over program space is only guaranteed to succeed if all points with zero gradient correspond to valid programs which explain the observations. Since many different programs can be consistent with the observations, there can be many global optima (L = 0) points in the FMGD loss landscape. However, the FMGD approximation can also lead to local optima which, if encountered, stall the optimization at an uninterpretable point where \u00b5p(x\u2217p) assigns weight to several distinct parameter settings. For this reason, we try several different random initializations of mp(x) and record the fraction of initializations which converge at a global optimum. Specifically, we try two approaches for learning using this model:\n\u2022 Vanilla FMGD. Run the algorithm as presented above, with \u03b1i = 1 and using the RMSProp (Tieleman and Hinton, 2012) gradient descent optimization algorithm.\n\u2022 Optimized FMGD. Add the heuristics below, which are inspired by Kurach et al. (2015) and designed to avoid getting stuck in local minima, and optimize the hyperparameters for these heuristics by random search. We also include the initialization scale \u03b1i = \u03b1 and the gradient descent optimization algorithm in the random search (see Section 5.2 for more details). By setting \u03b1 = 1, parameters are initialized uniformly on the simplex. By setting \u03b1 smaller, we get peakier distributions, and by setting \u03b1 larger we get more uniform distributions.\nGradient clipping. The FMGD neural network depth grows linearly with the number of time steps. We mitigate the \u201cexploding gradient\u201d problem (Bengio et al., 1994) by globally rescaling the whole gradient vector so that its L2 norm is not bigger than some hyperparameter value C.\nNoise. We added random Gaussian noise to the computed gradients after the backpropagation step. Following Neelakantan et al. (2016b), we decay the variance of this noise during the training according to the following schedule:\n\u03c32t = \u03b7\n(1 + t)\u03b3 (8)\nwhere the values of \u03b7 and \u03b3 are hyperparameters and t is the epoch counter.\nEntropy. Ideally, the algorithm would explore the loss surface to find a global minimum rather than fixing on some particular configuration early in the training process, causing the network to get stuck in a local minimum from which it\u2019s unlikely to leave. To bias the network away from committing to any particular solution during early iterations, we add an entropy bonus to the loss function. Specifically, for each softmax distribution in the network, we subtract the entropy scaled by a coefficient \u03c1, which is a hyperparameter. The coefficient is exponentially decayed with rate r, which is another hyperparameter.\nLimiting the values of logarithms. FMGD uses logarithms in computing both the cost function as well as the entropy. Since the inputs to these logarithms can be very small, this can lead to very big values for the cost function and floating-point arithmetic overflows. We avoid this problem by replacing log(x) with log(max[x, ]) wherever a logarithm is computed, for some small value of .\nKurach et al. (2015) considered two additional tricks which we did not implement generally.\nEnforcing Distribution Constraints. Because of the depth of the networks, propagation of numerical errors can result in \u2211 x \u00b5i(x) 6= 1. Kurach et al. (2015) solve this by adding rescaling operations to ensure normalization. We find that we can avoid this problem by using 64-bit floating-point precision.\nCurriculum learning. Kurach et al. (2015) used a curriculum learning scheme which involved first training on small instances of a given problem, and only moving to train on larger instances once the error rate had reduced below a certain value. Our benchmarks contain a small number of short examples (e.g., 5-10 examples acting on memory arrays of up to 8 elements), so there is less room for curriculum learning to be helpful. We manually experimented with hand-crafted curricula for two hard problems (shift and adder), but it did not lead to improvements.\nTo explore the hyperparameters for these optimization heuristics we ran preliminary experiments to manually chose a distribution over hyperparameter space for use in random search over hyperparameters. The aim was to find a distribution that is broad enough to not disallow reasonable settings of hyperparameters while also being narrow enough so that runs of random search were not wasted on parameter settings that would never lead to convergence. This distribution over hyperparameters was then fixed for all random search experiments."}, {"heading": "4.3 (Integer) Linear Program Back-end", "text": "We now turn attention to the first alternative back-end to be compared with the FMGD. Casting the TerpreT program as a factor graph allows us to build upon standard practice in constructing LP relaxations for solving maximum a posteriori (MAP) inference problems in discrete graphical models (Schlesinger, 1976; Wainwright and Jordan, 2008). In the following sections we describe how to apply these techniques to the TerpreT models, and in particular, how to extend the methods to handle gates."}, {"heading": "4.3.1 LP Relaxation", "text": "The inference problem can be phrased as the task of finding the highest scoring configuration of a set of discrete variables X0, . . . , XD\u22121. The score is defined as the sum of local factor scores, \u03b8j , where \u03b8j : X j \u2192 R, and X j = \u00d7i\u2208SjXi is the joint configuration space of the variables x with indices Sj = (i0, . . . , iMj ) spanning the scope of factor j. In the simplest case (when we are searching for any valid\nsolution) the factor score at a node representing a function fj will simply measure the consistency of the inputs (x\\0) and output (x0) at that factor:\n\u03b8j(x) = 1{x0 = fj(x\\0)}. (9) Alongside these scoring functions, we can build a set of linear constraints and an overall linear objective function which represent the graphical model as an LP. The variables of this LP are the local unary marginals \u00b5i(x) \u2208 R as before, and new local factor marginals \u00b5Sj (x) \u2208 R for x \u2208 X j associated with each factor, j.\nIn the absence of gates, we can write the LP as:\nmax \u00b5 \u2211 j \u2211 x\u2208X j \u00b5Sj (x)\u03b8j(x)\ns.t. \u00b5i(x) \u2265 0 ; \u00b5Sj (x) \u2265 0\u2211 x\u2208Xi\n\u00b5i(x) = 1\u2211 x\u2208X j Xi=x \u00b5Sj (x) = \u00b5i(x), (10)\nwhere the final set of constraints say that when Xi is fixed to value x and all other variables are marginalized out from the local factor marginal, the result is equal to the value that the local marginal for Xi assigns to value x. This ensures that factors and their neighboring variables have consistent local marginals.\nIf all local marginals \u00b5(\u00b7) are integral, i.e., restricted to be 0 or 1, then the LP above becomes an integer linear program corresponding exactly to the original discrete optimization problem. When the local marginals are real-valued (as above), the resulting LP is not guaranteed to have equivalent solution to the original problem, and fractional solutions can appear. More formally, the LP constraints define what is known as the local polytope ML. which is an outer approximation to the convex hull of all valid integral configurations of the local marginals (known as the marginal polytopeM). In the case of program synthesis, fractional solutions are problematic, because they do not correspond to discrete programs and thus cannot be represented as source code or executed on new instances. When a fractional solution is found, heuristics such as rounding, cuts, or branch & bound search must be used in order to find an integral solution."}, {"heading": "4.3.2 Linear Constraints in Gated Models", "text": "We now extend the LP relaxation above to cater for models with gates. In each gate we instantiate local unary marginals \u00b5\u03c8i for each active variable and local factor marginals \u00b5 \u03c8 Sj\nfor each factor, where \u03c8 is the path condition of the parent gate.\nThe constraints in the LP are then updated to handle these gate specific marginals as follows:\nNormalization constraints. The main difference in the Gate LP from the standard LP is how normalization constraints are handled. The key idea is that each local marginal in gate A is normalized to sum to A\u2019s gate marginal. Thus the local marginal for Xi in the gate with path condition (\u03c8, Y = y) with gate marginal \u00b5Y is: \u2211\nx\u2208Xi\n\u00b5\u03c8,Y=yi (x) = \u00b5 \u03c8 Y (y). (11)\nFor local marginals in the global scope (not in any gate), the marginals are constrained to sum to 1, as in the standard LP.\nFactor local marginals. The constraint enforcing local consistency between the factor local marginals and the unary local marginals is augmented with path condition superscripts:\u2211\nx\u2208X j :Xi=x \u00b5\u03c8ASj (x) = \u00b5 \u03c8A i (x). (12)\nParent-child consistency. There needs to be a relationship between different local marginals for the same variable. We do this by enforcing consistency between parent-child local marginals. Let A be a parent gate of B, and let Xi be active in both A and B. Then we need to enforce consistency between \u00b5\u03c8Ai (x) and \u00b5 \u03c8B i (x). It is not quite as simple as setting these quantities equal; in general there are multiple children gates of A, and X may be active in many of them. Let B1, . . . , BK be the set of children gates of A, and suppose that X is active in all of the children. Then the constraint is\nK\u2211 k=1 \u00b5 \u03c8Bk i (x) = \u00b5 \u03c8A i (x) \u2200x \u2208 Xi. (13)\nThis can be thought of as setting a parent local marginal to be a weighted average of children local marginals, where the \u201cweights\u201d come from children marginals being capped at their corresponding gate marginal\u2019s value.\nGhost marginals. A problem arises if a variable is used in some but not all children gates. It may be tempting in this case to replace the above constraint with one that leaves out the children where the variable is inactive: \u2211\nk:Xi is active \u00b5 \u03c8Bk i (x) = \u00b5 \u03c8A i (x). (14)\nThis turns out to lead to a contradiction. To see this, consider X3 in Fig. 8. X3 is inactive in the (X0 == 1) gate, and thus the parent-child consistency constraints would be\n\u00b5X0=03 (x) = \u00b53(x) \u2200x. (15)\nHowever, the normalization constraints for these local marginals are\u2211 x\n\u00b5X0=03 (x) = \u00b50(0) (16)\u2211 x \u00b53(x) = 1. (17)\nThis implies that \u00b50(0) = 1, which means we must assign zero probability to the case when X3 is not active. This removes the possibility of X0 = 1 from consideration which is clearly undesirable, and if there are disjoint sets of variables active in the different children cases, then the result is an infeasible LP.\nThe solution is to instantiate ghost marginals, which are local marginals for a variable in the case where it is undefined (hence the term \u201cghost\u201d). We denote a ghost marginal with a path condition entry where the value is set to \u2205, as in \u00b5X0=\u22053 (x). Ghost marginals represent the distribution over values in all cases where a variable is not defined, so the normalization constraints are defined as follows:\u2211\nx\n\u00b5X0=\u2205i (x) = \u2211\nk:Xi is not active \u00b50(k). (18)\nFinally, we can fix the parent-child consistency constraints in the case where a variable is active in some children. The solution is to consider the ghost marginal as one of the child cases. In the example of X3, the constraint would be the following:\n\u00b53(x) = \u00b5X0=\u22053 (x) + \u2211\nk:X3 is active \u00b5X0=k3 (x) for all x \u2208 X3. (19)\nThe full set of constraints for solving TerpreT IPS problems using gated (integer) LPs is summarized in Fig. 10."}, {"heading": "4.4 SMT Back-end", "text": "At its core, an IPS problem in TerpreT induces a simple linear integer constraint system. To exploit mature constraint-solving systems such as Z3 (de Moura and Bj\u00f8rner, 2008), we have implemented a satisfiability modulo theories (SMT) back-end. For this, a TerpreT instance is translated into a set of constraints in the SMT-LIB standard (Barrett et al., 2015), after which any standard SMT solver can be called.\nTo this end, we have defined a syntax-guided transformation function J\u00b7KESMT that translates TerpreT expressions into SMT-LIB expressions over integer variables, shown in Fig. 11. We make use of the unrolling techniques discussed earlier to eliminate arrays, for loops and with statements. When encountering a function call as part of an expression, we use inlining, i.e., replace the call by the function definition in which formal parameters have been replaced by actual arguments. This means that some TerpreT statements have to be expressed as SMT-LIB expressions, and also means that the SMT back-end only supports a small subset of functions, namely those that are using only TerpreT (but not arbitrary Python) constructs.\nBuilding on J\u00b7KESMT, we then define the statement translation function J\u00b7KSMT shown in Fig. 12. Every statement is translated into a list of constraints, and a solution to the IPS problem encoded by a TerpreT program p is a solution to the conjunction of all constraints generated by JpKESMT. Together with the unrolling of loops for a fixed length, this approach is reminiscent of bounded model checking techniques (e.g. (Clarke et al., 2001)) which for a given program, search for an input that shows some behavior. Instead, we take the input as given, and search for a program with the desired behavior.\nharness void tripleSketch (int x){ int h = ??; // hole for unknown constant assert h * x == x + x + x;\n}\nFigure 13: A simple sketch example."}, {"heading": "4.5 Sketch Back-end", "text": "The final back-end which we consider is based on the Sketch (Solar-Lezama, 2008) program synthesis system, which allows programmers to write partial programs called sketches while leaving fragments unspecified as holes. The goal of the synthesizer is to automatically fill in these holes such that the completed program conforms to a desired specification. The Sketch system supports multiple forms of specifications such as input-output examples, assertions, reference implementation, etc.\nBackground. The syntax for the Sketch language is similar to the C language with only one additional feature \u2013 a symbol ?? that represents an unknown constant integer value. A simple example sketch is shown in Fig. 13, which represents a partial program with an unknown integer h and a simple assertion. The harness keyword indicates to the synthesizer that it should compute a value for h such that in the complete function, all assertions are satisfied for all input values x. For this example, the Sketch synthesizer computes the value h = 3 as expected.\nThe unknown integer values can be used to encode a richer hypothesis space of program fragments. For example, the sketch in Fig. 14 uses an integer hole to describe a space of binary arithmetic operations. The Sketch language also provides a succinct language construct to specify such expression choices : lhs {| + | - | * | / | % |} rhs.\nint chooseArithBinOp (int lhs , int rhs){ int c = ??; // unknown constant integer value assert c < 5; if(c == 0) return lhs + rhs; if(c == 1) return lhs - rhs; if(c == 2) return lhs * rhs; if(c == 3) return lhs / rhs; if(c == 4) return lhs % rhs;\n}\nFigure 14: Using unknown integer values to encode a richer set of unknown expressions.\nThe Sketch synthesizer uses a counter-example guided inductive synthesis algorithm (CEGIS) (SolarLezama et al., 2006) to efficiently solve the second order exists-forall synthesis constraint. The key idea of the algorithm is to divide the process into phases : i) a synthesis phase that computes the value of unknowns over a finite set of input-output examples, and ii) a verification phase that checks if the current solution conforms to the desired specification. If the current completed program satisfies the specification, it returns the program as the desired solution. Otherwise, it computes a counter-example input that violates the specification and adds it to the set of input-output examples and continues the synthesis phase. More details about the CEGIS algorithm in Sketch can be found in Solar-Lezama (2008).\nCompiling TerpreT to Sketch. In Fig. 15, we present a syntax-directed translation of the TerpreT language to Sketch. The key idea of the translation is to model Param variables as unknown integer constants (and integer arrays with constant values) such that the synthesizer computes the values of parameters to satisfy the observation constraints. For a Param(N) integer value, the translation creates corresponding unknown integer value ?? with an additional constraint that the unknown value should be less than N . Similarly, for the Param(N) array values, the translation creates a Sketch array with unknown integer values, where each value is constrained to be less than N . The set to statements are\ntranslated to assignment statements whereas the observe statements are translated to assert statements in Sketch. The user-defined functions are translated directly to corresponding functions in sketch, whereas the with statements are translated to corresponding assignment statements. The sketch translation of the TerpreT model in Fig. 4(a) is shown in Fig. 16."}, {"heading": "5 Analysis", "text": "One motivation of this work was to compare the performance of the gradient based FMGD technique for IPS with other back-ends. Below we present a task which all other back-ends solve easily, but FMGD is found to fail due to the prevalence of local optima."}, {"heading": "5.1 Failure of FMGD", "text": "Kurach et al. (2015) and Neelakantan et al. (2016b) mention that many random restarts and a careful hyperparameter search are needed in order to converge to a correct deterministic solution. Here we develop an understanding of the loss surface that arises using FMGD in a simpler setting, which we believe sheds some light on the local optima structure that arises when using FMGD more generally.\nLet x0, . . . , xK\u22121 be binary variables with x0 = 0 and all others unobserved. For each k = 0, . . . ,K\u22121, let yk = (xk + x(k+1) mod K) mod 2 be the parity of neighboring x variables connected in a ring shape. Suppose all yk are observed to be 0 and the goal is to infer the values of each xk. The TerpreT program is as follows, which we refer to as the Parity Chain model:\n1 const K = 5\n2 x = Param(2)[const K]\n3 y = Var(2)[const K]\n4\n5 @CompileMe([2,2], 2)\n6 def Parity(a,b): return (a + b) % 2\n7\n8 x[0].set to constant(0)\n9\n10 for k in range(K):\n11 y[k].set to(Parity(x[k], x[(k+1) % K]))\n12 y[k].observe value(0)\nClearly, the optimal configuration is to set all xk = 0. Here we show analytically that there are exponentially many suboptimal local optima that FMGD can fall into, and experimentally that the probability of falling into a suboptimal local optimum grows quickly in K.\nTo show that there are exponentially many local optima, we give a technique for enumerating them and show that the gradient is equal to 0 at each. Letting mi(a) for i \u2208 {0, . . .K \u2212 1}, a \u2208 {0, 1} be the model parameters and \u00b5i = expmi(1)expmi(0)+expmi(1) , the main observation is that locally, a configuration of [\u00b5i\u22121, \u00b5i, \u00b5i+1] = [0, .5, 1] or [\u00b5i\u22121, \u00b5i, \u00b5i+1] = [1, .5, 0] gives rise to zero gradient on mi\u22121(\u00b7),mi(\u00b7),mi+1(\u00b7), as does any configuration of [\u00b5i\u22121, \u00b5i, \u00b5i+1] = [0, 0, 0] or [\u00b5i\u22121, \u00b5i, \u00b5i+1] = [1, 1, 1]. This implies that any configuration of a sequence of \u00b5\u2019s of the form [0, .5, 1, 1, . . . , 1, .5, 0] also gives rise to zero gradients on all the involved m\u2019s. We then can choose any configuration of alternating \u00b5 (so e.g., \u00b52, \u00b54, \u00b56, . . . , \u00b5K \u2208 {0, 1}K/2), and then fill in the remaining values of \u00b51, \u00b53, . . . so as to create a local optimum. The rule is to set \u00b5i = .5 if \u00b5i\u22121 + \u00b5i+1 = 1 and \u00b5i = \u00b5i\u22121 = \u00b5i+1 otherwise. This will create \u201cislands\u201d of 1\u2019s, with the boundaries of the islands set to be .5. Each configuration of islands is a local optimum, and there are at least 2(K\u22121)/2 such configurations. A formal proof appears in Appendix A.\nOne might wonder if these local optima arise in practice. That is, if we initialize mi(a) randomly, will we encounter these suboptimal local optima? Experiments in Section 5.2 show that the answer is yes. The local optima can be avoided in small models by using optimization heuristics such as gradient noise, but\nint const_n = 5; int [2][2] ruleTable = (int [2][2]) ??; for(int i=0; i<2; i++){\nfor(int j=0; j<2; j++){ assert ruleTable [i][j] < 2;\n} } int[ const_n ] tape;\n// assignment statements for input initialisations\nfor(int t=1; t<const_n-1 ; t++){ int x1 = tape[t]; int x0 = tape[t-1 ]; tape[t+1] = ruleTable [x0 ,x1];\n}\n// assert statements for corresponding outputs\nFigure 16: The sketch translation for the TerpreT model shown in Fig. 4(a) .\nas the models grow larger (length 128), we were not able to find any configuration of hyperparameters that could solve the problem from a random initialization. The other inference algorithms will solve these problems easily. For example, the LP relaxation from Section 4.3 will lead to integral solutions for tree-structured graphical models, which is the case here."}, {"heading": "5.2 Parity Chain Experiments", "text": "Here we provide an empirical counterpart to the theoretical analysis in the previous section. Specifically, we showed that there are exponentially many local optima for FMGD to fall into in the Parity Chain model, but this does not necessarily mean that these local optima are encountered in practice. It is conceivable that there is a large basin of attraction around the global optimum, and smaller, negligible basins of attraction around the suboptimal local optima.\nTo answer this question, we run Vanilla FMGD (no optimization heuristics) with random initialization parameters chosen so that initial parameters are drawn uniformly from the simplex. Measuring the fraction of runs (from 100 random initializations) that converge to the global optimum then gives an estimate of the volume of parameter space that falls within the basin of attraction for the global optimum. Results for chain lengths of K = 4, 8, 16, 32, 64, 128 appear in the Vanilla FMGD row of Table 3. FMGD is able to solve very small instances reliably, but performance quickly falls off as K grows. This shows that the basins of attraction for the suboptimal local optima are large.\nNext, we try the optimization heuristics discussed in Section 4.2.3. For each chain length K, we draw 100 random hyperparameter settings from the manually chosen hyperparameter distribution. At each hyperparameter setting, we run 10 runs with different random seeds and measure the fraction of runs that converge to the global optimum. In the \u201cBest Hypers\u201d row of Table 3, we report the percentage of successes from the hyperparameter setting that yielded the best results. In the \u201cAverage Hypers\u201d row, we report the percentage of success across all 1000 runs.\nNote that the 80% success rate for Best Hypers on K = 64 is an anomaly, as it was able to find a setting of hyperparameters for which the random initialization had very little effect, and the successful runs followed nearly identical learning trajectories. See Fig. 17 for a plot of optimization objective versus epoch. Successful runs are colored blue while unsuccessful ones are in red. The large cluster of successful runs were all from the same hyperparameter settings."}, {"heading": "6 Experiments", "text": "We now turn attention to experimental results. Our primary aim is to better understand the capabilities of the different back-ends on a range of problems, and to establish some trends regarding the performance of the back-ends as problem properties are varied."}, {"heading": "6.1 Benchmarks Results", "text": "We now present the main results of this investigation: a benchmarking of all four inference techniques listed in Table 1 on all twelve synthesis tasks listed in Table 2. As described in Section 3.2, the tasks are split across four execution models of increasing practicality, with each model set three tasks of increasing difficulty. For any given task we ensure a fair test by presenting all four back-end compilers with the same TerpreT program (as listed in Appendix B) and the same set of input-output examples. Since the different back-ends use very different approaches to solve the tasks, the only comparable metric to record is the wall time to reach a solution.\nWith the exception of the FMGD algorithm, we set a timeout of 4 hours for each back-end on each task (excluding any compilation time), give each algorithm a single run to find a solution, and do not tune the algorithms to each specific task. For the FMGD algorithm we run both the Vanilla and the Optimized form. In the Vanilla case we report the fraction of 20 different random initializations which lead to a globally optimal solution and also the wall clock time for 1000 epochs of the gradient descent algorithm (which is the typical number of iterations required to reach convergence on a successful run). In the Optimized FMGD case, we follow a similar protocol as in the previous section but allow training to run for 2000 epochs. We use the same manually chosen distribution over hyperparameters to perform a random search, drawing 120 random settings of hyperparameters. For each setting we run the learning with 20 different random initializations. For the ListK tasks, the runtime was very long, so we ran for fewer settings of hyperparameters (28 for Assembly and 10 for Basic Block). As before, in the Optimized case we report the success rate for the best hyperparameters found and also for the average across all runs in the random search.\nOur results are compiled in Table 4, from which we can draw two high level conclusions:\nBack end algorithm. There is a clear tendency for traditional techniques employing constraint solvers (SMT and Sketch) to outperform the machine learning methods, with Sketch being the only system able to solve all of these benchmarks before timeout (see Section 6.3).\nNevertheless, the machine learning methods have qualitatively appealing properties. Firstly, they are primarily optimizers rather than solvers2, and additional terms could be added to the cost function of the optimization to find programs with desired properties (e.g. minimal length (Bunel et al., 2016) or resource usage). Secondly, FMGD makes the synthesis task fully differentiable, allowing its incorporation into a larger end-to-end differentiable system (Kurach et al., 2015). This encourages us to persevere with analysis of the FMGD technique, and in particular to study the surprising failure of this method on the simple boolean circuit benchmarks in Section 6.2.\nInterpreter models. Table 4 highlights that the precise formulation of the interpreter model can affect the speed of synthesis. Both the Basic Block and Assembly models are equally expressive, but the Assembly model is biased towards producing straight line code with minimal branching. In all cases where synthesis was successful the Assembly representation is seen to outperform the Basic Block model in terms of synthesis time. The only anomaly is that the Optimized FMGD algorithm is able to find a solution in the Decrement task using the Basic Block model, but not the Assembly model. This could be because the minimal solution to this program is shorter in the Basic Block architecture than in the Assembly model (T = 18 vs. 27 respectively). We observe in Section 6.2.2 that increasing the size of a model by adding superfluous resources can help the FMGD algorithm to converge on a global optimum. However, we generally find that synthesis is difficult if the minimal solution is already large.\n2Both Sketch and SMT (in the form of max-SMT) can also be configured to be optimizers\n29"}, {"heading": "6.2 Zooming in on FMGD Boolean Circuits", "text": "There is a stark contrast between the performance of FMGD and the alternatives on the Boolean Circuit problems. On the Controlled Shift and Full Adder benchmarks, each run of FMGD took 35\u2212 80\u00d7 as long as the SMT back-end. On top of this, we ran 120\u00d7 20 = 2400 runs during the random search. However, there were no successful runs."}, {"heading": "6.2.1 Slow convergence", "text": "While most runs converged to a local optimum during the 2000 epochs they were allocated, some cases had not. Thus, we decided to allocate the algorithm 5\u00d7 as many epochs (10,000) and run the random search over. This did produce some successes, although very few. For the Controlled Shift problem, 1 of 2400 runs converged, and for the Full Adder, 3 of 2400 runs converged. Thus it does appear that results could be improved somewhat by running FMGD for longer. However, given the long runtimes of FMGD relative to the SMT and Sketch back-ends, this would not change the qualitative conclusions from the previous section."}, {"heading": "6.2.2 Varying the problem dimension", "text": "We take inspiration from neural network literature which approaches the issue of stagnation in local minima by increasing the dimension of the problem. It has been argued that local optima become increasingly rare in neural network loss surfaces as the dimension of the hidden layers increase, and instead saddle points become increasingly common (Dauphin et al., 2014). Exchanging local minima for saddle points is beneficial because dynamic learning rate schedules such as RMSProp are very effective at handling saddle points and plateaus in the loss function.\nTo assess how dimensionality affects FMGD, we first take a minimal example in the boolean circuit domain: the task of synthesizing a NAND gate. The minimum solution for this task is shown in Fig. 18(a), along with an example configuration which resides at one local minimum of the FMGD loss surface. For a synthesis task involving two gates and two wires, there are a total of 14 independent degrees of freedom to be optimized, and there is only one global optimum. Increasing the available resources to three gates and three wires, gives an optimization problem over 30 dimensions and several global minima. The contrast between the learning trajectories in these two cases is shown in Fig. 18. We attempt to infer the presence of saddle points by exploring the loss surface with vanilla gradient descent and a small learning rate. Temporary stagnation of the learning is an indication of a saddle-like feature. Such features are clearly more frequently encountered in the higher dimensional case where we also observe a greater overall success rate (36% of 100 random initializations converge on a global optimum in the low dimensional case vs. 60% in the high dimensional case).\nThese observations are consistent with the intuition from Dauphin et al. (2014), suggesting that we will have more success in the benchmark tasks if we provide more resources (i.e. a higher dimensional problem) than required to solve the task. We perform this experiment on the full adder benchmark by varying the number of wires and gates used in the synthesized solution. The results in Fig. 19 show the expected trend, with synthesis becoming more successful as the number of redundant resources increases above the minimal 4 wires and 5 gates. Furthermore, we see no clear increase in the expected time for FMGD to arrive at a solution as we increase the problem size (calculated as the time for 1000 epochs divided by the success rate). This is dramatically different to the trend seen when applying constraint solvers to the synthesis problem, where broadly speaking, increasing the number of constraints in the problem increases the time to solution (see Fig. 19(c)).\nThis feature of FMGD is particularly interesting when the minimal resources required to solve a problem is not known before synthesis. Whereas over-provisioning resources will usually harm the other back-ends we consider, it can help FMGD. The discovered programs can then be post-processed to recover some efficiency (see Fig. 20)"}, {"heading": "6.3 Challenge Benchmark", "text": "Before leaving this section, we note that Sketch has so far solved all of the benchmark tasks. To provide a goal for future work, we introduce a final benchmark which none of the back-ends are currently able to\n(a) (b)\nAND NOT\nouta\nb\nAND NOT\nouta\nb\nNOT\na\nb\n0.5 0.5\nout\nsolve from 5 input-output examples even after 40 hours:\nASSEMBLY M R B log10 D T Description\nMerge 17 6 22 103 69 Merge two contiguous sorted lists into one contiguous sorted list. The first entries in the initial heap are heap0[0] = p1, heap0[1] = p2, heap0[2] = pout, where p1 (p2) is a pointer to the first (second) sorted sublist (terminated with a 0), and pout is a pointer to the head of the desired output list. All elements of the sorted sublists are larger than 0 and all unused cells in heap0 are initialized to 0."}, {"heading": "7 Related Work", "text": "Probabilistic Programming and Graphical Models There are now many probabilistic programming systems specialized to different use-cases. One dominant axis of variability is in the expressiveness of the language. Some probabilistic programming languages, exemplified by Church (Goodman et al., 2008), allow great freedom in the expressibility of the language, including constructs like recursion and higher order functions. The cost of the expressibility in the language is that the inference techniques cannot be as specialized, and thus these systems tend to use general Markov Chain Monte Carlo methods for inference. On the other end of the spectrum are more specialized systems like Infer.NET (Minka et al., 2014) and Stan (Carpenter, 2015; Stan Development Team, 2015). These systems restrict models to be constructed of predefined building blocks and do not support arbitrary program constructs like recursion and higher order functions. They do generally support basic loops and branching structure, however. In Infer.NET, for example, loops are unrolled, and if statements are handled via special constructs known as Gates (Minka and Winn, 2009). The result is that the program can be viewed as a finite gated factor graph, on which message passing inference can be performed.\nIn these terms, TerpreT is most similar to Infer.NET, and its handling of loops and if statements are inspired by Infer.NET. Compared to Infer.NET, TerpreT is far more extreme in the restrictions that it places upon modelling constructs. The benefit is that the restricted language allows us to support a broader range of back-ends. Looking forward, Infer.NET provides inspiration for how TerpreT might be extended to handle richer data types like real numbers and strings.\nAnother related line of work is in casting program synthesis as a problem of inference in probabilistic models. Gulwani and Jojic (2007) phrase program synthesis as inference in a graphical model and use\nbelief propagation inference. In future work, we would like to create a belief propagation-based back-end for TerpreT. The problem of inducing samplers for probability distributions has also been cast as a problem of inference in a probabilistic program (Perov and Wood, 2016). Lake et al. (2015) induce probabilistic programs by performing inference in a probabilistic model describing how primitives are composed to form types and instances of types.\nNeural Networks with Memory In common neural network architectures handling sequences of inputs, \u201cmemory\u201d only manifests itself as the highly compressed state of the network. This is problematic when the task at hand requires to relate inputs that are far apart from each other, which more recent models try to mitigate using tools such as Long Short-Term Memory (Hochreiter and Schmidhuber, 1997; Graves, 2013) and Gated Recurrent Units (Cho et al., 2014). However, such recurrent units do not entirely solve the problems with long-range interactions, and a range of additional techniques have been employed to improve results (e.g., (Mikolov et al., 2015; Koutn\u0301\u0131k et al., 2014)).\nAn alternative solution to this problem is to extend networks by providing access to external storage. Initial extensions provided a stack (Giles et al., 1989) or a scratch pad simplified to a stack (Mozer and Das, 1992), and the controlling network learned when to push data to and pop (load) data from that stack.3 Recently, similar ideas have been picked up again, leading to stack and queue-augmented recurrent nets (Joulin and Mikolov, 2015; Grefenstette et al., 2015), memory networks with freely addressable storage (Weston et al., 2014; Sukhbaatar et al., 2015), and extensions that additionally use registers for intermediate results (Kurach et al., 2015).\nNeural Networks Learning Algorithms Recurrent neural networks with access to memory are, essentially, learnable implementations of the Von Neumann architecture. A number of recent advances build on this observation to learn algorithms from input-output data (Graves et al., 2014; Joulin and Mikolov, 2015; Neelakantan et al., 2016a; Reed and de Freitas, 2016; Zaremba et al., 2016). While these approaches differ in (a) the underlying execution models (e.g., Turing Machines, Random Access Machines, Stack Automata), (b) learning methods (e.g., from input/output samples or action sequences, supervised or by reinforcement learning), and (c) program domains (arithmetic, simple data structure manipulation, image manipulation), they share the overall idea of training a deep neural network that learns to manipulate data by repeatedly calling deterministic \u201cmodules\u201d (or \u201cactions\u201d or \u201cinterfaces\u201d) from a predefined set. These models are able to learn and repeat simple algorithmic patterns, but are all not interpretable; what they have learned only becomes evident through actions on concrete inputs.\nVery recent work has improved on this aspect and is closest to our approach. To support adaptive neural compilation (Bunel et al., 2016), a machine model similar to our assembly model (cf. Section 3.2.4) was introduced. This allows a user to sketch a (partial) program as input, and then use deep learning methods to optimise it. The result is again a program in the chosen assembly language, and can be displayed easily. Differentiable Forth (Riedel et al., 2016) is a similar step in this direction, where the learning task is to fill in holes in a partial Forth program.\nProgram Synthesis The area of program synthesis has recently seen a renewed interest in the programming language community (Alur et al., 2015). There have been many synthesis techniques developed for a wide range of problems including data wrangling (Gulwani et al., 2012; Polozov and Gulwani, 2015), inference of efficient synchronization in concurrent programs, synthesizing efficient low-level code from partial programs (Solar-Lezama et al., 2005), compilers for low-power spatial architectures (Phothilimthana et al., 2014), efficient compilation of declarative specifications (Kuncak et al., 2010), statistical code completion (Raychev et al., 2016), and automated feedback generation for programming assignments (Singh et al., 2013). These techniques can be broadly categorized using three dimensions: i) specification mechanism, ii) complexity of hypothesis space, and iii) search algorithm. The different forms of specifications include input-output examples, partial programs, reference implementation, program traces etc. The hypothesis space of possible programs is typically defined using a domain-specific language, which is designed to be expressive enough to encode majority of desired tasks but at the same time concise enough for efficient\n3Interestingly enough, extracting an interpretable deterministic pushdown automaton from a trained stack-using recurrent network was already proposed in (Das et al., 1992).\nlearning. Finally, some of the common search algorithms include constraint-based symbolic synthesis algorithms (Solar-Lezama, 2008; Reynolds et al., 2015), smart enumerative algorithms with pruning (Udupa et al., 2013), version-space algebra based search algorithms (Gulwani et al., 2012; Gulwani, 2011), and stochastic search (Schkufza et al., 2013). There has also been some recent work on learning from inputs in addition to the input-output examples to guide the synthesis algorithm (Singh, 2016), and synthesizing programs without any examples by performing a joint inference over the program and the inputs to recover compressed encodings of the observed data (Ellis et al., 2015).\nIn this work, we are targeting specifications based on input-output examples as this form of specification is most natural to the work in the machine learning community. For defining the hypothesis space, we use our probabilistic programming language TerpreT, and we currently support compilation to intermediate representations for four inference (search) algorithms. The key difference between our work and most of the previous work in the program synthesis community is that our language is built to allow compilation to different inference algorithms (from both the machine learning community and programming languages community) which enables like-to-like comparison. We note that another recent effort SyGuS (Alur et al., 2015) aims to unify different program synthesis approaches using a common intermediate format based on context-free grammars so that different inferences techniques can be compared, but the TerpreT language allows for encoding richer programming models than SyGuS, and also allows for compilation to gradient-descent based inference algorithms."}, {"heading": "8 Discussion & Future Work", "text": "We presented TerpreT, a probabilistic programming language for specifying IPS problems. TerpreT can be used in combination with the FMGD back-end to produce differentiable interpreters for a wide range of program representations and languages. TerpreT has several other back-ends including one based on linear programming and two that are strong alternatives from the programming languages community.\nThe biggest take-away from the experimental results is that the methods from programming languages significantly outperform the machine learning approaches. We believe this is an important take-away for machine learning researchers studying program synthesis. However, we remain optimistic about the future of machine learning-based approaches to program synthesis, and we do not wish to discourage work in this area. Quite the opposite; we hope that this work stimulates further research in the area and helps to clarify how machine learning is likely to be useful. The setting in this work is a minimal version of the program synthesis problem, in which the main challenge is efficiently searching over program space for programs that meet a given input-output specification. The conclusion from our experiments is that gradient descent is inferior to constraint-based discrete search algorithms for this task.\nOur results also raise an interesting question when taken in comparison to (Kurach et al., 2015). The NRAM model is reported to solve problems that our FMGD approach was not able to. We would like to better understand what the source of this discrepancy is. The two main differences are in the execution model and in the program parameterization. In the NRAM execution model, all instructions are executed in all timesteps (possibly multiple times), and it is up to the controller to decide how to wire them up. This creates additional parallelism and redundancy relative to the Basic Block or Assembly models. We speculate that this makes it possible in the NRAM model for multiple hypotheses to be developed at once with little overlap in the memory locations used. This property may make the optimization easier. The other major difference is in the controller. The NRAM model uses a neural network controller that maps from the state of registers to the operations that are to be performed. In the Basic Block and Assembly models, this is done via the instruction pointer that is updated based upon control flow decisions in the program. We speculate that the neural network controller operates in a less constrained space (since a different operation may be performed at each timestep if the model pleases), and it offers some bias to the search. We suspect neural networks may be biased towards repeating circuits in the earlier stages of training due to their typical behavior of first predicting averages before specializing to make strongly input-dependent predictions. In future work we would like to explore these questions more rigorously, in hopes of finding general principles that can be used to develop more robust inference algorithms.\nIn future work, there are several extensions to TerpreT that we would like to develop. First, we would like to extend the TerpreT language in several ways. We would like to support non-uniform priors over program variables (which will require converting the SMT and Sketch back-ends to use max-SMT\nsolvers). There are several data types that we would like to support, including floating point numbers, strings, and richer data types. Second, we would like to continue to expand the number of back-ends. Natural next steps are back-ends based on local search or Markov Chain Monte Carlo, and on message passing inference in graphical models, perhaps taking inspiration from Sontag et al. (2008). Third, we would like to build higher level languages on top of TerpreT, to support more compact specification of common TerpreT programming patterns.\nMore generally, we believe the opportunities for IPS come not from improving discrete search in this setting, but in re-phrasing the program synthesis problem to be more of a pattern-matching and big-data problem, and in augmenting the specification beyond just input-output examples (for example, incorporating natural language). In these cases, the importance of the discrete search component decreases, and we believe there to be many opportunities for machine learning. As we move forward in these directions, we believe TerpreT will continue to be valuable, as it makes it easy to build a range of differentiable interpreters to be used in conjunction with larger learning systems."}, {"heading": "Acknowledgements", "text": "We thank several people for discussions that helped improve this report: Tom Minka for discussions related to the Gates LP relaxation; John Winn for several discussions related to probabilistic programming and gates; Ryota Tomioka for discussions related to the FMGD loss surface; Andy Gordon for pushing us towards the probabilistic programming formulation of TerpreT; Abdel-rahman Mohamed for discussions related to neural networks and program synthesis; Jack Feser for being the first non-author TerpreT user; Aditya Nori for helpful discussions about program synthesis; and Matej Balog for a critical reading of this manuscript."}, {"heading": "A Proof of Lemma 1", "text": "Lemma 1. All island structures have zero gradient.\nProof. Notationally, let s = {si(a) | i \u2208 {1, . . . ,K}, a \u2208 {0, 1}} be the free parameters, where si(a) is the unnormalized log probability that xi is equal to a. The probability over xi is then given by a softmax; i.e., p(xi = a) = \u00b5i(a) = exp si(a)exp si(0)+exp si(1) . Let \u00b5 be the set {\u00b5i(a) | i \u2208 {1, . . . ,K}, a \u2208 {0, 1}}. Let the objective o(s) be the log probability of the observations, i.e., o(s) = \u2211 i log p(yi = 0 | s) = \u2211 i log p(yi = 0 | \u00b5). The plan is to show that for each island structure described above, the partial derivative \u2202o(s)\u2202si(a) is 0 for every i and a. This can be done by computing the partial derivatives and showing that they are 0 for each possible local configuration that arises in an island structure.\nFirst, let us derive the gradient contribution from a single observation yi = 0. By the definition of parity and the FMGD model,\np(yi = 0 | \u00b5) = p(xi = 0)p(xi+1 = 0) + p(xi = 1)p(xi+1 = 1) (20) = \u00b5i(0)\u00b5i+1(0) + \u00b5i(1)\u00b5i+1(1). (21)\nThe partial derivative \u2202 log p(yi=0)\u2202sj(a) can be computed via the chain rule as\n\u2202 log p(yi = 0) \u2202sj(a) = \u2202 log p(yi = 0) \u2202p(yi = 0) \u2202p(yi = 0) \u2202sj(b) . (22)\nEach of these can be computed straight-forwardly. The partial derivative \u2202 log p(yi=0)\u2202p(yi=0) is 1 p(yi=0) . The partial derivative \u2202p(yi=0)\u2202sj(b) is as follows:\n\u2202p(yi = 0) \u2202sj(b) =  \u2202\u00b5i(0) \u2202si(b) \u00b5i+1(0) + \u2202\u00b5i(1) \u2202si(b) \u00b5i+1(1) if j = i \u00b5i(0)\u2202\u00b5i+1(0)\u2202si+1(b) + \u00b5i(1) \u2202\u00b5i+1(1) \u2202si+1(b) if j = i+ 1\n0 otherwise.\n(23)\nFinally, the partial derivative of the softmax is\n\u2202\u00b5i(b) \u2202si(a) = \u00b5i(b) \u2202 log\u00b5i(b) \u2202si(a)\n(24)\n= \u00b5i(b) \u2202\n\u2202si(a) [si(b)\u2212 log (exp si(0) + exp si(1))] (25)\n= \u00b5i(b) (1{a = b} \u2212 \u00b5i(a)) . (26)\nPutting these together, we get the full partial derivatives:\n\u2202 log p(yi = 0) \u2202sj(a) = 1 p(yi = 0) \u00b7  \u00b5i(0)\u00b5i+1(0) (1{a = 0} \u2212 \u00b5i(a)) + \u00b5i(1)\u00b5i+1(1) (1{a = 1} \u2212 \u00b5i(a)) if j = i \u00b5i(0)\u00b5i+1(0) (1{a = 0} \u2212 \u00b5i+1(a)) + \u00b5i(1)\u00b5i+1(1) (1{a = 1} \u2212 \u00b5i+1(a)) if j = i+ 1\n0 otherwise (27)\nEach sj(a) contributes to two terms in the objective: log p(yj\u22121 = 0) and log p(yj = 0). Thus the gradient on sj(a) is the sum of gradient contributions from these two terms:\n\u2202o(s) \u2202sj(a) = \u2202 log p(yj\u22121 = 0) \u2202sj(a) + \u2202 log p(yj = 0) \u2202sj(a) . (28)\nRestricting attention to a = 0 (the case where a = 1 follows similarly and is omitted), we can simplify further:\n\u2202o(s) \u2202sj(0) =\u2202 log p(yj\u22121 = 0) \u2202sj(0) + \u2202 log p(yj = 0) \u2202sj(0)\n(29)\n= 1 p(yj\u22121 = 0) (\u00b5j\u22121(0)\u00b5j(0)(1\u2212 \u00b5j(0)) + \u00b5j\u22121(1)\u00b5j(1)(\u2212\u00b5j(0))) (30)\n+ 1 p(yj = 0) (\u00b5j(0)\u00b5j+1(0) (1\u2212 \u00b5j(0)) + \u00b5j(1)\u00b5j+1(1)(\u2212\u00b5j(0))) (31)\n= 1 p(yj\u22121 = 0) (\u00b5j\u22121(0)\u00b5j(0)\u00b5j(1)\u2212 \u00b5j\u22121(1)\u00b5j(1)\u00b5j(0)) (32)\n+ 1 p(yj = 0) (\u00b5j(0)\u00b5j+1(0)\u00b5j(1)\u2212 \u00b5j(1)\u00b5j+1(1)\u00b5j(0)) (33)\n=\u00b5j(0)\u00b5j(1) ( \u00b5j\u22121(0)\u2212 \u00b5j\u22121(1)\np(yj\u22121 = 0) + \u00b5j+1(0)\u2212 \u00b5j+1(1) p(yj = 0)\n) (34)\nThe first note is that if \u00b5j(0) = 0 or \u00b5j(1) = 0, then the gradient for sj(0) is 0. Thus, we only need to consider triplets (\u00b5j\u22121(\u00b7), \u00b5j(\u00b7), \u00b5j+1(\u00b7)) where \u00b5j(a) = .5. The only two cases that arise in island structures are (0, .5, 1) and (1, .5, 0). Consider the first case, (0, .5, 1):\n= \u00b5j(0)\u00b5j(1) ( \u00b5j\u22121(0)\u2212 \u00b5j\u22121(1)\np(yj\u22121 = 0) + \u00b5j+1(0)\u2212 \u00b5j+1(1) p(yj = 0)\n) (35)\n= .5 \u00b7 .5 \u00b7 (\n1\u2212 0 .5 + 0\u2212 1 .5\n) (36)\n= .5 \u00b7 .5 \u00b7 (2\u2212 2) = 0. (37)\nThe second case (1, .5, 0) is similar:\n= \u00b5j(0)\u00b5j(1) ( \u00b5j\u22121(0)\u2212 \u00b5j\u22121(1)\np(yj\u22121 = 0) + \u00b5j+1(0)\u2212 \u00b5j+1(1) p(yj = 0)\n) (38)\n= .5 \u00b7 .5 \u00b7 (\n0\u2212 1 .5 + 1\u2212 0 .5\n) (39)\n= .5 \u00b7 .5 \u00b7 (\u22122 + 2) = 0. (40)\nThus, the gradients with respect to sj(a) are zero for all j and a when an island-structured configuration is given. The objective is clearly suboptimal (since some p(yi = 0) are less than 1 at the island boundaries). Thus, each island structure is a suboptimal local optimum."}, {"heading": "B Benchmark models", "text": "B.1 Turing Machine\n1 const nStateMem = # HYPERPARAM const nStateMem\n2 const nStateHead = # HYPERPARAM const nStateHead\n3 const nTimesteps = # HYPERPARAM const nTimesteps\n4 const tapeLength = # HYPERPARAM const tapeLength\n5 const nDir = 3\n6\n7 const nInstances = # HYPERPARAM const nInstances\n8\n9 @CompileMe([const tapeLength ,const nDir],const tapeLength)\n10 def move(pos, direction):\n11 if direction == 0: return pos\n12 elif direction == 1: return (pos + 1) % const tapeLength 13 elif direction == 2: return (pos \u2212 1) % const tapeLength 14 @CompileMe([const tapeLength , const tapeLength], 2)\n15 def equalityTestPos(a,b): return 1 if a == b else 0\n16 @CompileMe([const nStateHead , const nStateHead], 2)\n17 def equalityTestState(a,b): return 1 if a == b else 0\n18\n19 #######################################################\n20 # Source code parametrisation #\n21 #######################################################\n22 newValue = Param(const nStateMem)[const nStateHead , const nStateMem]\n23 direction = Param(const nDir)[const nStateHead , const nStateMem]\n24 newState = Param(const nStateHead)[const nStateHead , const nStateMem]\n25\n26 #######################################################\n27 # Interpreter model #\n28 #######################################################\n29 # Memory tape\n30 tape = Var(const nStateMem)[const nInstances , const nTimesteps , const tapeLength]\n31 # Machine head\n32 curPos = Var(const tapeLength)[const nInstances , const nTimesteps]\n33 curState = Var(const nStateHead)[const nInstances , const nTimesteps]\n34 isHalted = Var(2)[const nInstances , const nTimesteps]\n35 # Temporary values 36 tmpActiveCell = Var(2)[const nInstances , const nTimesteps \u2212 1, const tapeLength] 37 tmpMemState = Var(const nStateMem)[const nInstances , const nTimesteps \u2212 1] 38\n39 # IMPORT OBSERVED INPUTS\n40\n41 # Initialize machine head\n42 for n in range(const nInstances):\n43 curPos[n,0].set to constant(0)\n44 curState[n,0].set to constant(1)\n45 isHalted[n,0].set to constant(0)\n46\n47 # Run the Turing machine\n48 for n in range(const nInstances): # loop over I/O examples 49 for t in range(const nTimesteps \u2212 1): # loop over program timesteps 50\n51 # Carry forward unmodified tape and head if halted\n52 if isHalted[n,t] == 1:\n53 for m in range(const tapeLength):\n54 tape[n,t+1,m].set to(tape[n,t,m])\n55 curState[n,t+1].set to(curState[n,t])\n56 curPos[n,t+1].set to(curPos[n,t])\n57 isHalted[n,t+1].set to(isHalted[n,t])\n58\n59 # Perform Turing update if not halted\n60 elif isHalted[n,t] == 0:\n61 with curState[n,t] as s:\n62 with curPos[n,t] as x:\n63 with tape[n,t,x] as Tx:\n64 tmpMemState[n,t].set to(newValue[s,Tx])\n65 curPos[n,t+1].set to(move(x, direction[s,Tx]))\n66 curState[n,t+1].set to(newState[s,Tx])\n67\n68 # Machine halts if head enters state 0\n69 isHalted[n,t+1].set to(equalityTestState(0,curState[n,t+1]))\n70\n71 # Write temporary value to tape\n72 for m in range(const tapeLength):\n73 tmpActiveCell[n,t,m].set to(equalityTestPos(m, curPos[n,t]))\n74 if tmpActiveCell[n,t,m] == 1:\n75 tape[n,t+1,m].set to(tmpMemState[n,t])\n76 elif tmpActiveCell[n,t,m] == 0:\n77 tape[n,t+1,m].set to(tape[n,t,m])\n78\n79 # Machine must be halted at end of execution\n80 for n in range(const nInstances): 81 isHalted[n,const nTimesteps \u2212 1].observe value(1) 82\n83 # IMPORT OBSERVED OUTPUTS\nB.2 Boolean circuits\n1 const nGates = # HYPERPARAM const nGates\n2 const nWires = # HYPERPARAM const nWires\n3 const nGateTypes = 5\n4\n5 const nInstances = # HYPERPARAM const nInstances\n6\n7 @CompileMe([const two ,const two],const two)\n8 def AND(a,b): return int(a and b)\n9 @CompileMe([const two ,const two],const two)\n10 def OR(a,b): return int(a or b)\n11 @CompileMe([const two ,const two],const two)\n12 def XOR(a,b): return int(a ^ b)\n13 @CompileMe([const two],const two)\n14 def NOT(a): return int(not a)\n15 @CompileMe([const two],const two)\n16 def NOOP(a): return a\n17 @CompileMe([const nWires ,const nWires],const two)\n18 def equalityTest(a,b): return 1 if a == b else 0\n19\n20 #######################################################\n21 # Source code parametrisation #\n22 #######################################################\n23 gate = Param(const nGateTypes)[const nGates]\n24 in1 = Param(const nWires)[const nGates]\n25 in2 = Param(const nWires)[const nGates]\n26 out = Param(const nWires)[const nGates]\n27\n28 #######################################################\n29 # Interpreter model #\n30 #######################################################\n31 wires = Var(2)[const nInstances , const nGates + 1, const nWires]\n32 tmpOutput = Var(2)[const nInstances , const nGates]\n33 tmpDoWrite = Var(2)[const nInstances , const nGates , const nWires]\n34 tmpArg1 = Var(2)[const nInstances , const nGates]\n35 tmpArg2 = Var(2)[const nInstances , const nGates]\n36\n37 # IMPORT OBSERVED INPUTS\n38\n39 # Run the circuit\n40 for n in range(const nInstances): # loop over I/O examples\n41 for g in range(const nGates): # loop over sequential gates\n42\n43 # Load gate inputs\n44 with in1[g] as i1:\n45 with in2[g] as i2:\n46 tmpArg1[n,g].set to(wires[n,g,i1])\n47 tmpArg2[n,g].set to(wires[n,g,i2])\n48\n49 # Compute gate output\n50 if gate[g] == 0:\n51 tmpOutput[n,g].set to( AND(tmpArg1[n,g], tmpArg2[n,g]) )\n52 elif gate[g] == 1:\n53 tmpOutput[n,g].set to( OR(tmpArg1[n,g], tmpArg2[n,g]) )\n54 elif gate[g] == 2:\n55 tmpOutput[n,g].set to( XOR(tmpArg1[n,g], tmpArg2[n,g]) )\n56 elif gate[g] == 3:\n57 tmpOutput[n,g].set to( NOT(tmpArg1[n,g]) )\n58 elif gate[g] == 4:\n59 tmpOutput[n,g].set to( NOOP(tmpArg1[n,g]) )\n60\n61 # Write gate output\n62 for w in range(const nWires):\n63 tmpDoWrite[n,g,w].set to(equalityTest(out[g], w))\n64 if tmpDoWrite[n,g,w] == 1:\n65 wires[n,g + 1,w].set to(tmpOutput[n,g])\n66 elif tmpDoWrite[n,g,w] == 0:\n67 wires[n,g + 1,w].set to(wires[n,g,w])\n68\n69 # IMPORT OBSERVED OUTPUTS\nB.3 Basic-block model\n1 const nBlocks = # HYPERPARAM const nBlocks\n2 const nRegisters = # HYPERPARAM const nRegisters\n3 const nTimesteps = # HYPERPARAM const nTimesteps\n4 const maxInt = # HYPERPARAM const maxInt\n5 const nInstructions = 7\n6 const nActions = 2\n7 const nInstrPlusAct = const nInstructions + const nActions\n8 const noopIndex = const nInstructions\n9\n10 const nInstances = # HYPERPARAM const nInstances\n11\n12 @CompileMe([const nInstrPlusAct], 2)\n13 def isInstruction(a): return 1 if a < const nInstructions else 0 14 @CompileMe([const nInstrPlusAct], const nInstructions)\n15 def extractInstruction(a): return a\n16 @CompileMe([const nInstrPlusAct], const nActions) 17 def extractAction(a): return a \u2212 const nInstructions 18 @CompileMe([const maxInt , const maxInt], 2)\n19 def equalityTestValue(a,b): return 1 if a == b else 0\n20 @CompileMe([const nRegisters , const nRegisters], 2)\n21 def equalityTestReg(a, b): return 1 if a == b else 0\n22 @CompileMe([const maxInt], 2)\n23 def greaterThanZero(a): return 1 if a > 0 else 0 24\n25 @CompileMe([], const maxInt)\n26 def ZERO(): return 0\n27 @CompileMe([const maxInt], const maxInt)\n28 def INC(a): return (a + 1) % const maxInt\n29 @CompileMe([const maxInt], const maxInt) 30 def DEC(a): return (a \u2212 1) % const maxInt 31 @CompileMe([const maxInt , const maxInt], const maxInt)\n32 def ADD(a, b): return (a + b) % const maxInt\n33 @CompileMe([const maxInt , const maxInt], const maxInt) 34 def SUB(a, b): return (a \u2212 b) % const maxInt 35 @CompileMe([const maxInt , const maxInt], const maxInt)\n36 def LESSTHAN(a, b): return 1 if a < b else 0 37\n38 #######################################################\n39 # Source code parametrisation #\n40 #######################################################\n41 instructions = Param(const nInstrPlusAct)[const nBlocks]\n42 arg1s = Param(const nRegisters)[const nBlocks]\n43 arg2s = Param(const nRegisters)[const nBlocks]\n44 rOuts = Param(const nRegisters)[const nBlocks]\n45 thenBlocks = Param(const nBlocks)[const nBlocks]\n46 elseBlocks = Param(const nBlocks)[const nBlocks]\n47 rConds = Param(const nRegisters)[const nBlocks]\n48\n49 #######################################################\n50 # Interpreter model #\n51 #######################################################\n52 # Program pointer\n53 curBlocks = Var(const nBlocks)[const nInstances ,const nTimesteps]\n54 # Memory\n55 registers = Var(const maxInt)[const nInstances ,const nTimesteps ,const nRegisters]\n56 heap = Var(const maxInt)[const nInstances ,const nTimesteps ,const maxInt]\n57 # Temporary values 58 tmpIsInstr = Var(2)[const nInstances ,const nTimesteps\u22121] 59 tmpInstr = Var(const nInstructions)[const nInstances ,const nTimesteps\u22121] 60 tmpAction = Var(const nActions)[const nInstances ,const nTimesteps\u22121] 61 tmpArg1Val = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 62 tmpArg2Val = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 63 tmpOutput = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 64 tmpDoWrite = Var(2)[const nInstances ,const nTimesteps\u22121, const nRegisters] 65 tmpCondVal = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 66 tmpGotoThen = Var(2)[const nInstances ,const nTimesteps\u22121] 67 tmpWriteHeap = Var(2)[const nInstances ,const nTimesteps\u22121,const maxInt] 68\n69 # Initialize block 0 to a spining STOP block\n70 instructions[0].set to constant(const noopIndex)\n71 thenBlocks[0].set to constant(0)\n72 elseBlocks[0].set to constant(0)\n73\n74 # Initialize the program pointer to block 1 and the registers to 0\n75 for n in range(const nInstances):\n76 curBlocks[n,0].set to constant(1)\n77 for r in range(const nRegisters):\n78 registers[n,0,r].set to constant(0)\n79\n80 # IMPORT OBSERVED INPUTS\n81\n82 # Run the program\n83 for n in range(const nInstances): # loop over I/O examples 84 for t in range(const nTimesteps\u22121): # loop over program timesteps 85 with curBlocks[n,t] as pc:\n86\n87 # Load block inputs\n88 with arg1s[pc] as a1:\n89 tmpArg1Val[n,t].set to(registers[n,t,a1])\n90 with arg2s[pc] as a2:\n91 tmpArg2Val[n,t].set to(registers[n,t,a2])\n92\n93 # Determine whether block performs a heap ACTION or register INSTRUCTION\n94 tmpIsInstr[n,t].set to(isInstruction(instructions[pc]))\n95\n96 # Handle heap ACTIONS\n97 if tmpIsInstr[n,t] == 0:\n98 tmpAction[n,t].set to(extractAction(instructions[pc]))\n99\n100 # Actions affect the heap ...\n101 if tmpAction[n,t] == 0: # NOOP\n102 for m in range(const maxInt):\n103 heap[n,t+1,m].set to(heap[n,t,m])\n104 elif tmpAction[n,t] == 1: # WRITE\n105 for m in range(const maxInt):\n106 tmpWriteHeap[n,t,m].set to(equalityTestValue(tmpArg1Val[n,t], m))\n107 if tmpWriteHeap[n,t,m] == 1:\n108 heap[n,t+1,m].set to(tmpArg2Val[n,t])\n109 elif tmpWriteHeap[n,t,m] == 0:\n110 heap[n,t+1,m].set to(heap[n,t,m])\n111\n112 # ... and do not affect registers\n113 for r in range(const nRegisters):\n114 registers[n,t+1,r].set to(registers[n,t,r])\n115\n116 # Handle register INSTRUCTIONS\n117 elif tmpIsInstr[n,t] == 1:\n118 tmpInstr[n,t].set to(extractInstruction(instructions[curBlocks[n,t]]))\n119\n120 # Instructions affect registers ...\n121 if tmpInstr[n,t] == 0:\n122 tmpOutput[n,t].set to( ZERO() )\n123 elif tmpInstr[n,t] == 1:\n124 tmpOutput[n,t].set to( INC(tmpArg1Val[n,t]) )\n125 elif tmpInstr[n,t] == 2:\n126 tmpOutput[n,t].set to( DEC(tmpArg1Val[n,t]) )\n127 elif tmpInstr[n,t] == 3:\n128 tmpOutput[n,t].set to( ADD(tmpArg1Val[n,t],tmpArg2Val[n,t]) )\n129 elif tmpInstr[n,t] == 4:\n130 tmpOutput[n,t].set to( SUB(tmpArg1Val[n,t],tmpArg2Val[n,t]) )\n131 elif tmpInstr[n,t] == 5:\n132 tmpOutput[n,t].set to( LESSTHAN(tmpArg1Val[n,t],tmpArg2Val[n,t])\n133 elif tmpInstr[n,t] == 6: # READ\n134 with tmpArg1Val[n,t] as a1:\n135 tmpOutput[n,t].set to(heap[n,t,a1])\n136\n137 for r in range(const nRegisters):\n138 tmpDoWrite[n,t,r].set to(equalityTestReg(rOuts[pc], r))\n139 if tmpDoWrite[n,t,r] == 1:\n140 registers[n,t+1,r].set to(tmpOutput[n,t])\n141 elif tmpDoWrite[n,t,r] == 0:\n142 registers[n,t+1,r].set to(registers[n,t,r])\n143\n144 # ... and do not affect the heap\n145 for m in range(const maxInt):\n146 heap[n,t+1,m].set to(heap[n,t,m])\n147\n148 # Perform branching according to condition register\n149 with rConds[pc] as rc:\n150 tmpCondVal[n,t].set to(registers[n,t+1,rc])\n151\n152 tmpGotoThen[n,t].set to(greaterThanZero(tmpCondVal[n,t]))\n153 if tmpGotoThen[n,t] == 1:\n154 curBlocks[n,t+1].set to(thenBlocks[pc])\n155 elif tmpGotoThen[n,t] == 0:\n156 curBlocks[n,t+1].set to(elseBlocks[pc])\n157\n158 # Program must terminate in the STOP block\n159 for n in range(const nInstances): 160 curBlocks[n,const nTimesteps \u2212 1].observe value(0) 161 # IMPORT OBSERVED OUTPUTS\nB.4 Assembly Model\n1 const nLines = # HYPERPARAM const nBlocks\n2 const nRegisters = # HYPERPARAM const nRegisters\n3 const nTimesteps = # HYPERPARAM const nTimesteps\n4 const maxInt = # HYPERPARAM const maxInt\n5 const nInstructions = 7\n6 const nActions = 1\n7 const nBranches = 2\n8 const nInstrActBranch = const nInstructions + const nActions + const nBranches\n9\n10 const nInstances = # HYPERPARAM const nInstances\n11\n12 @CompileMe([const nInstrActBranch], 3)\n13 def instructionType(a):\n14 if a < const nInstructions: 15 return 0\n16 elif a < (const nInstructions + const nActions): 17 return 1\n18 else:\n19 return 2\n20 @CompileMe([const nInstrActBranch], const nInstructions)\n21 def extractInstruction(a): return a\n22 @CompileMe([const nInstrActBranch], const nBranches) 23 def extractBranch(a): return a \u2212 const nInstructions \u2212 const nActions 24 @CompileMe([const nRegisters , const nRegisters], 2)\n25 def equalityTestReg(a,b): return 1 if a == b else 0\n26 @CompileMe([const maxInt , const maxInt], 2)\n27 def equalityTestValue(a,b): return 1 if a == b else 0\n28 @CompileMe([const nLines , const nLines], 2)\n29 def equalityTestLine(a,b): return 1 if a == b else 0\n30 @CompileMe([const maxInt], 2)\n31 def valueEqualsZero(a): return 1 if a == 0 else 0\n32 @CompileMe([const nLines], const nLines)\n33 def incLine(a): return (a + 1) % const nLines\n34\n35 @CompileMe([], const maxInt)\n36 def ZERO(): return 0\n37 @CompileMe([const maxInt], const maxInt)\n38 def INC(a): return (a + 1) % const maxInt\n39 @CompileMe([const maxInt , const maxInt], const maxInt)\n40 def ADD(a, b): return (a + b) % const maxInt\n41 @CompileMe([const maxInt , const maxInt], const maxInt) 42 def SUB(a, b): return (a \u2212 b) % const maxInt 43 @CompileMe([const maxInt], const maxInt) 44 def DEC(a): return (a \u2212 1) % const maxInt 45 @CompileMe([const maxInt , const maxInt], const maxInt)\n46 def LESSTHAN(a,b): return 1 if a < b else 0 47\n48 #######################################################\n49 # Source code parametrisation #\n50 #######################################################\n51 instructions = Param(const nInstrActBranch)[const nLines]\n52 branchAddr = Param(const nLines)[const nLines]\n53 arg1s = Param(const nRegisters)[const nLines]\n54 arg2s = Param(const nRegisters)[const nLines]\n55 rOuts = Param(const nRegisters)[const nLines]\n56\n57 #######################################################\n58 # Interpreter model #\n59 #######################################################\n60 # Program pointer\n61 curLine = Var(const nLines)[const nInstances ,const nTimesteps]\n62 # Memory\n63 registers = Var(const maxInt)[const nInstances ,const nTimesteps ,const nRegisters]\n64 heap = Var(const maxInt)[const nInstances ,const nTimesteps ,const maxInt]\n65 # Temporary values 66 tmpInstrActBranch = Var(3)[const nInstances , const nTimesteps\u22121] 67 tmpInstr = Var(const nInstructions)[const nInstances ,const nTimesteps\u22121] 68 tmpBranch = Var(const nBranches)[const nInstances ,const nTimesteps\u22121] 69 tmpArg1Val = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 70 tmpArg2Val = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 71 tmpOutput = Var(const maxInt)[const nInstances ,const nTimesteps\u22121] 72 tmpDoWrite = Var(2)[const nInstances ,const nTimesteps\u22121, const nRegisters] 73 tmpBranchIsZero = Var(2)[const nInstances ,const nTimesteps\u22121] 74 tmpWriteHeap = Var(2)[const nInstances ,const nTimesteps\u22121,const maxInt] 75 isHalted = Var(2)[const nInstances , const nTimesteps \u2212 1] 76\n77 # Initialize the program pointer to block 1 and the registers to 0\n78 for n in range(const nInstances):\n79 curLine[n,0].set to constant(1)\n80 for r in range(const nRegisters):\n81 registers[n,0,r].set to constant(0)\n82\n83 # IMPORT OBSERVED INPUTS\n84\n85 # Run the program\n86 for n in range(const nInstances): # loop over I/O examples 87 for t in range(const nTimesteps\u22121): # loop over program timesteps 88 # Halt if we jump to line 0\n89 isHalted[n,t].set to(equalityTestLine(curLine[n,t],0))\n90\n91 # If not halted, execute current line\n92 if isHalted[n,t] == 0:\n93 with curLine[n,t] as pc:\n94 # Load line inputs\n95 with arg1s[pc] as a1:\n96 tmpArg1Val[n,t].set to(registers[n,t,a1])\n97 with arg2s[pc] as a2:\n98 tmpArg2Val[n,t].set to(registers[n,t,a2])\n99\n100 # Determine whether line performs a register INSTRUCTION , a heap ACTION or\n101 # a control flow BRANCH\n102 tmpInstrActBranch[n,t].set to(instructionType(instructions[pc]))\n103\n104 # Handle register INSTRUCTIONS\n105 if tmpInstrActBranch[n,t] == 0:\n106 tmpInstr[n,t].set to(extractInstruction(instructions[pc]))\n107\n108 # Instructions affect registers ...\n109 if tmpInstr[n,t] == 0:\n110 tmpOutput[n,t].set to( ZERO() )\n111 elif tmpInstr[n,t] == 1:\n112 tmpOutput[n,t].set to( INC(tmpArg1Val[n,t]) )\n113 elif tmpInstr[n,t] == 2:\n114 tmpOutput[n,t].set to( ADD(tmpArg1Val[n,t],tmpArg2Val[n,t]) )\n115 elif tmpInstr[n,t] == 3:\n116 tmpOutput[n,t].set to( SUB(tmpArg1Val[n,t],tmpArg2Val[n,t]) )\n117 elif tmpInstr[n,t] == 4:\n118 tmpOutput[n,t].set to( DEC(tmpArg1Val[n,t]) )\n119 elif tmpInstr[n,t] == 5:\n120 tmpOutput[n,t].set to( LESSTHAN(tmpArg1Val[n,t],tmpArg2Val[n,t]) )\n121 elif tmpInstr[n,t] == 6:\n122 with tmpArg1Val[n,t]:\n123 tmpOutput[n,t].set to(heap[n,t,tmpArg1Val[n,t]])\n124\n125 for r in range(const nRegisters):\n126 tmpDoWrite[n,t,r].set to(equalityTestReg(rOuts[pc], r))\n127 if tmpDoWrite[n,t,r] == 1:\n128 registers[n,t+1,r].set to(tmpOutput[n,t])\n129 elif tmpDoWrite[n,t,r] == 0:\n130 registers[n,t+1,r].set to(registers[n,t,r])\n131\n132 # ... and do not affect the heap\n133 for m in range(const maxInt):\n134 heap[n,t+1,m].set to(heap[n,t,m])\n135\n136 # Progress to the next line\n137 curLine[n,t+1].set to(incLine(pc))\n138\n139 # Handle heap ACTIONS\n140 elif tmpInstrActBranch[n,t] == 1:\n141 # The only action is to write to the heap\n142 for m in range(const maxInt):\n143 tmpWriteHeap[n,t,m].set to(equalityTestValue(tmpArg1Val[n,t],m))\n144 if tmpWriteHeap[n,t,m] == 1:\n145 heap[n,t+1,m].set to(tmpArg2Val[n,t])\n146 elif tmpWriteHeap[n,t,m] == 0:\n147 heap[n,t+1,m].set to(heap[n,t,m])\n148\n149 # Actions do not affect the registers\n150 for r in range(const nRegisters):\n151 registers[n,t+1,r].set to(registers[n,t,r])\n152\n153 # Progress to the next line\n154 curLine[n,t+1].set to(incLine(pc))\n155\n156 # Handle control flow BRANCHES\n157 elif tmpInstrActBranch[n,t] == 2: # Branch\n158 tmpBranch[n,t].set to(extractBranch(instructions[pc]))\n159 tmpBranchIsZero[n,t].set to(valueEqualsZero(tmpArg1Val[n,t]))\n160\n161 # BRANCHES affect the program counter ...\n162 if tmpBranch[n,t] == 0: # JZ\n163 if tmpBranchIsZero[n,t] == 1:\n164 curLine[n,t+1].set to(branchAddr[pc])\n165 elif tmpBranchIsZero[n,t] == 0:\n166 curLine[n,t+1].set to(incLine(pc))\n167 elif tmpBranch[n,t] == 1: # JNZ\n168 if tmpBranchIsZero[n,t] == 0:\n169 curLine[n,t+1].set to(branchAddr[pc])\n170 elif tmpBranchIsZero[n,t] == 1:\n171 curLine[n,t+1].set to(incLine(pc))\n172\n173 # ... and do not affect the registers and heap.\n174 for r in range(const nRegisters):\n175 registers[n,t+1,r].set to(registers[n,t,r])\n176 for m in range(const maxInt):\n177 heap[n,t+1,m].set to(heap[n,t,m])\n178\n179 # Carry forward unmodified registers and heap if halted\n180 elif isHalted[n,t] == 1:\n181 for r in range(const nRegisters):\n182 registers[n,t+1,r].set to(registers[n,t,r])\n183 for m in range(const maxInt):\n184 heap[n,t+1,m].set to(heap[n,t,m])\n185 curLine[n,t+1].set to(curLine[n,t])\n186\n187 # Program must terminate in the STOP line\n188 for n in range(const nInstances): 189 curLine[n,const nTimesteps\u22121].observe value(0) 190 # IMPORT OBSERVED OUTPUTS"}], "references": [{"title": "Control flow analysis", "author": ["Frances E Allen"], "venue": "In ACM Sigplan Notices,", "citeRegEx": "Allen.,? \\Q1970\\E", "shortCiteRegEx": "Allen.", "year": 1970}, {"title": "Syntax-guided synthesis", "author": ["Rajeev Alur", "Rastislav Bod\u0301\u0131k", "Eric Dallal", "Dana Fisman", "Pranav Garg", "Garvit Juniwal", "Hadas KressGazit", "P. Madhusudan", "Milo M.K. Martin", "Mukund Raghothaman", "Shamwaditya Saha", "Sanjit A. Seshia", "Rishabh Singh", "Armando Solar-Lezama", "Emina Torlak", "Abhishek Udupa"], "venue": "In Dependable Software Systems Engineering,", "citeRegEx": "Alur et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Alur et al\\.", "year": 2015}, {"title": "The SMT-LIB standard: Version 2.5", "author": ["Clark Barrett", "Pascal Fontaine", "Cesare Tinelli"], "venue": "Technical report, The University of Iowa,", "citeRegEx": "Barrett et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Barrett et al\\.", "year": 2015}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "IEEE transactions on neural networks,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "The inference of regular lisp programs from examples", "author": ["Alan W Biermann"], "venue": "IEEE transactions on Systems, Man, and Cybernetics,", "citeRegEx": "Biermann.,? \\Q1978\\E", "shortCiteRegEx": "Biermann.", "year": 1978}, {"title": "Adaptive neural compilation", "author": ["Rudy Bunel", "Alban Desmaison", "Pushmeet Kohli", "Philip H.S. Torr", "M. Pawan Kumar"], "venue": "CoRR, abs/1605.07969,", "citeRegEx": "Bunel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bunel et al\\.", "year": 2016}, {"title": "Stan: A probabilistic programming language", "author": ["Bob Carpenter"], "venue": "Journal of Statistical Software,", "citeRegEx": "Carpenter.,? \\Q2015\\E", "shortCiteRegEx": "Carpenter.", "year": 2015}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["KyungHyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": "CoRR, abs/1409.1259,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Bounded model checking using satisfiability solving", "author": ["Edmund Clarke", "Armin Biere", "Richard Raimi", "Yunshan Zhu"], "venue": "Formal Methods in System Design,", "citeRegEx": "Clarke et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Clarke et al\\.", "year": 2001}, {"title": "Using prior knowledge in a {NNPDA} to learn contextfree languages", "author": ["Sreerupa Das", "C. Lee Giles", "Guo-Zheng Sun"], "venue": "In Proceedings of the 5th Conference on Advances in Neural Information Processing Systems,", "citeRegEx": "Das et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Das et al\\.", "year": 1992}, {"title": "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", "author": ["Yann N Dauphin", "Razvan Pascanu", "Caglar Gulcehre", "Kyunghyun Cho", "Surya Ganguli", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Dauphin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dauphin et al\\.", "year": 2014}, {"title": "Z3: an efficient SMT solver", "author": ["Leonardo Mendon\u00e7a de Moura", "Nikolaj Bj\u00f8rner"], "venue": "Internal Conference on Tools and Algorithms for the Construction and Analysis of Systems,", "citeRegEx": "Moura and Bj\u00f8rner.,? \\Q2008\\E", "shortCiteRegEx": "Moura and Bj\u00f8rner.", "year": 2008}, {"title": "Unsupervised learning by program synthesis", "author": ["Kevin Ellis", "Armando Solar-Lezama", "Joshua B. Tenenbaum"], "venue": "In Advances in Neural Information Processing Systems NIPS,", "citeRegEx": "Ellis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ellis et al\\.", "year": 2015}, {"title": "Higher order recurrent networks and grammatical inference", "author": ["C. Lee Giles", "Guo-Zheng Sun", "Hsing-Hen Chen", "Yee-Chun Lee", "Dong Chen"], "venue": "In Advances in Neural Information Processing Systems 2, [NIPS Conference,", "citeRegEx": "Giles et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Giles et al\\.", "year": 1989}, {"title": "Church: a language for generative models", "author": ["Noah D. Goodman", "Vikash K. Mansinghka", "Daniel M. Roy", "Keith Bonawitz", "Joshua B. Tenenbaum"], "venue": "In Proc. of Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves"], "venue": "CoRR, abs/1308.0850,", "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Learning to transduce with unbounded memory", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Grefenstette et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Grefenstette et al\\.", "year": 2015}, {"title": "Automating string processing in spreadsheets using input-output examples", "author": ["Sumit Gulwani"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "Gulwani.,? \\Q2011\\E", "shortCiteRegEx": "Gulwani.", "year": 2011}, {"title": "Program verification as probabilistic inference", "author": ["Sumit Gulwani", "Nebojsa Jojic"], "venue": "In ACM SIGPLAN Notices,", "citeRegEx": "Gulwani and Jojic.,? \\Q2007\\E", "shortCiteRegEx": "Gulwani and Jojic.", "year": 2007}, {"title": "Spreadsheet data manipulation using examples", "author": ["Sumit Gulwani", "William Harris", "Rishabh Singh"], "venue": "Communications of the ACM,", "citeRegEx": "Gulwani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gulwani et al\\.", "year": 2012}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Inferring algorithmic patterns with stack-augmented recurrent nets", "author": ["Armand Joulin", "Tomas Mikolov"], "venue": "In Advances in Neural Information Processing Systems 2, [NIPS Conference,", "citeRegEx": "Joulin and Mikolov.,? \\Q1989\\E", "shortCiteRegEx": "Joulin and Mikolov.", "year": 1989}, {"title": "Neural gpus learn algorithms", "author": ["Lukasz Kaiser", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations.,", "citeRegEx": "Kaiser and Sutskever.,? \\Q2016\\E", "shortCiteRegEx": "Kaiser and Sutskever.", "year": 2016}, {"title": "A clockwork RNN", "author": ["Jan Kout\u0144\u0131k", "Klaus Greff", "Faustino J. Gomez", "J\u00fcrgen Schmidhuber"], "venue": "In Proceedings of the 31th International Conference on Machine Learning,", "citeRegEx": "Kout\u0144\u0131k et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kout\u0144\u0131k et al\\.", "year": 2014}, {"title": "Complete functional synthesis", "author": ["Viktor Kuncak", "Mika\u00ebl Mayer", "Ruzica Piskac", "Philippe Suter"], "venue": "In PLDI,", "citeRegEx": "Kuncak et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kuncak et al\\.", "year": 2010}, {"title": "Neural random-access machines", "author": ["Karol Kurach", "Marcin Andrychowicz", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations 2016,", "citeRegEx": "Kurach et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kurach et al\\.", "year": 2015}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Brenden M Lake", "Ruslan Salakhutdinov", "Joshua B Tenenbaum"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "Llvm: A compilation framework for lifelong program analysis & transformation", "author": ["Chris Lattner", "Vikram Adve"], "venue": "In Code Generation and Optimization,", "citeRegEx": "Lattner and Adve.,? \\Q2004\\E", "shortCiteRegEx": "Lattner and Adve.", "year": 2004}, {"title": "Learning longer memory in recurrent neural networks", "author": ["Tomas Mikolov", "Armand Joulin", "Sumit Chopra", "Micha\u00ebl Mathieu", "Marc\u2019Aurelio Ranzato"], "venue": "In Proceedings of the 3rd International Conference on Learning Representations", "citeRegEx": "Mikolov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2015}, {"title": "A connectionist symbol manipulator that discovers the structure of context-free languages", "author": ["Michael Mozer", "Sreerupa Das"], "venue": "In Advances in Neural Information Processing Systems 5, [NIPS Conference,", "citeRegEx": "Mozer and Das.,? \\Q1992\\E", "shortCiteRegEx": "Mozer and Das.", "year": 1992}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["Arvind Neelakantan", "Quoc V. Le", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations 2016,", "citeRegEx": "Neelakantan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "Adding gradient noise improves learning for very deep networks", "author": ["Arvind Neelakantan", "Luke Vilnis", "Quoc V Le", "Ilya Sutskever", "Lukasz Kaiser", "Karol Kurach", "James Martens"], "venue": "In Proceedings of the International Conference on Learning Representations 2015,", "citeRegEx": "Neelakantan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "Automatic sampler discovery via probabilistic programming and approximate bayesian computation", "author": ["Yura Perov", "Frank Wood"], "venue": "In International Conference on Artificial General Intelligence,", "citeRegEx": "Perov and Wood.,? \\Q2016\\E", "shortCiteRegEx": "Perov and Wood.", "year": 2016}, {"title": "Bod\u0301\u0131k. Chlorophyll: synthesis-aided compiler for low-power spatial architectures", "author": ["Phitchaya Mangpo Phothilimthana", "Tikhon Jelvis", "Rohin Shah", "Nishant Totla", "Sarah Chasins", "Rastislav"], "venue": "In PLDI,", "citeRegEx": "Phothilimthana et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Phothilimthana et al\\.", "year": 2014}, {"title": "Flashmeta: a framework for inductive program synthesis", "author": ["Oleksandr Polozov", "Sumit Gulwani"], "venue": "In OOPSLA,", "citeRegEx": "Polozov and Gulwani.,? \\Q2015\\E", "shortCiteRegEx": "Polozov and Gulwani.", "year": 2015}, {"title": "Learning programs from noisy data", "author": ["Veselin Raychev", "Pavol Bielik", "Martin T. Vechev", "Andreas Krause"], "venue": "In POPL,", "citeRegEx": "Raychev et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Raychev et al\\.", "year": 2016}, {"title": "Counterexampleguided quantifier instantiation for synthesis in SMT", "author": ["Andrew Reynolds", "Morgan Deters", "Viktor Kuncak", "Cesare Tinelli", "Clark W. Barrett"], "venue": "In CAV,", "citeRegEx": "Reynolds et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Reynolds et al\\.", "year": 2015}, {"title": "Programming with a differentiable forth interpreter", "author": ["Sebastian Riedel", "Matko Bosnjak", "Tim Rockt\u00e4schel"], "venue": "CoRR, abs/1605.06640,", "citeRegEx": "Riedel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2016}, {"title": "Stochastic superoptimization", "author": ["Eric Schkufza", "Rahul Sharma", "Alex Aiken"], "venue": "In ASPLOS, pages 305\u2013316,", "citeRegEx": "Schkufza et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schkufza et al\\.", "year": 2013}, {"title": "Syntactic analysis of two-dimensional visual signals in the presence of noise", "author": ["MI Schlesinger"], "venue": "Cybernetics and systems analysis,", "citeRegEx": "Schlesinger.,? \\Q1976\\E", "shortCiteRegEx": "Schlesinger.", "year": 1976}, {"title": "Blinkfill: Semi-supervised programming by example for syntactic string", "author": ["Rishabh Singh"], "venue": "transformations. PVLDB,", "citeRegEx": "Singh.,? \\Q2016\\E", "shortCiteRegEx": "Singh.", "year": 2016}, {"title": "Automated feedback generation for introductory programming assignments", "author": ["Rishabh Singh", "Sumit Gulwani", "Armando Solar-Lezama"], "venue": "In PLDI,", "citeRegEx": "Singh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2013}, {"title": "Program Synthesis By Sketching", "author": ["Armando Solar-Lezama"], "venue": "PhD thesis, EECS Dept., UC Berkeley,", "citeRegEx": "Solar.Lezama.,? \\Q2008\\E", "shortCiteRegEx": "Solar.Lezama.", "year": 2008}, {"title": "Programming by sketching for bit-streaming programs", "author": ["Armando Solar-Lezama", "Rodric Rabbah", "Rastislav Bodik", "Kemal Ebcioglu"], "venue": "In PLDI,", "citeRegEx": "Solar.Lezama et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Solar.Lezama et al\\.", "year": 2005}, {"title": "Combinatorial sketching for finite programs", "author": ["Armando Solar-Lezama", "Liviu Tancau", "Rastislav Bod\u0301\u0131k", "Sanjit A. Seshia", "Vijay A. Saraswat"], "venue": "In ASPLOS,", "citeRegEx": "Solar.Lezama et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Solar.Lezama et al\\.", "year": 2006}, {"title": "Tightening lp relaxations for map using message passing", "author": ["David Sontag", "Talya Meltzer", "Amir Globerson", "Tommi S Jaakkola", "Yair Weiss"], "venue": "In Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Sontag et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2008}, {"title": "End-to-end memory networks. In Advances in Neural Information Processing Systems", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus"], "venue": "Annual Conference on Neural Information Processing Systems", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "A methodology for lisp program construction from examples", "author": ["Phillip D Summers"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Summers.,? \\Q1977\\E", "shortCiteRegEx": "Summers.", "year": 1977}, {"title": "Lecture 6.5\u2014RmsProp: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman and Hinton.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman and Hinton.", "year": 2012}, {"title": "TRANSIT: specifying protocols with concolic snippets", "author": ["Abhishek Udupa", "Arun Raghavan", "Jyotirmoy V. Deshmukh", "Sela Mador-Haim", "Milo M.K. Martin", "Rajeev Alur"], "venue": "In PLDI,", "citeRegEx": "Udupa et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Udupa et al\\.", "year": 2013}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Martin J Wainwright", "Michael I Jordan"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Wainwright and Jordan.,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan.", "year": 2008}, {"title": "A linear programming approach to max-sum problem: A review", "author": ["Tomas Werner"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Werner.,? \\Q2007\\E", "shortCiteRegEx": "Werner.", "year": 2007}, {"title": "Learning simple algorithms from examples", "author": ["Wojciech Zaremba", "Tomas Mikolov", "Armand Joulin", "Rob Fergus"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Zaremba et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 17, "context": "The field has produced many successes, with perhaps the most visible example being the FlashFill system in Microsoft Excel (Gulwani, 2011; Gulwani et al., 2012).", "startOffset": 123, "endOffset": 160}, {"referenceID": 19, "context": "The field has produced many successes, with perhaps the most visible example being the FlashFill system in Microsoft Excel (Gulwani, 2011; Gulwani et al., 2012).", "startOffset": 123, "endOffset": 160}, {"referenceID": 44, "context": "1 Introduction Learning computer programs from input-output examples, or Inductive Program Synthesis (IPS), is a fundamental problem in computer science, dating back at least to Summers (1977) and Biermann (1978).", "startOffset": 178, "endOffset": 193}, {"referenceID": 4, "context": "1 Introduction Learning computer programs from input-output examples, or Inductive Program Synthesis (IPS), is a fundamental problem in computer science, dating back at least to Summers (1977) and Biermann (1978). The field has produced many successes, with perhaps the most visible example being the FlashFill system in Microsoft Excel (Gulwani, 2011; Gulwani et al.", "startOffset": 197, "endOffset": 213}, {"referenceID": 13, "context": "These include Recurrent Neural Networks (RNNs) augmented with a stack or queue memory (Giles et al., 1989; Joulin and Mikolov, 2015; Grefenstette et al., 2015), Neural Turing Machines (Graves et al.", "startOffset": 86, "endOffset": 159}, {"referenceID": 16, "context": "These include Recurrent Neural Networks (RNNs) augmented with a stack or queue memory (Giles et al., 1989; Joulin and Mikolov, 2015; Grefenstette et al., 2015), Neural Turing Machines (Graves et al.", "startOffset": 86, "endOffset": 159}, {"referenceID": 22, "context": ", 2014), Neural GPUs (Kaiser and Sutskever, 2016), Neural Programmer-Interpreters (Reed and de Freitas, 2016), and Neural Random Access Machines (Kurach et al.", "startOffset": 21, "endOffset": 49}, {"referenceID": 25, "context": ", 2014), Neural GPUs (Kaiser and Sutskever, 2016), Neural Programmer-Interpreters (Reed and de Freitas, 2016), and Neural Random Access Machines (Kurach et al., 2015).", "startOffset": 145, "endOffset": 166}, {"referenceID": 27, "context": "To address the first question we develop models inspired by intermediate representations used in compilers like LLVM (Lattner and Adve, 2004) that can be trained by gradient descent.", "startOffset": 117, "endOffset": 141}, {"referenceID": 5, "context": "We note two concurrent works, Adaptive Neural Compilation (Bunel et al., 2016) and Differentiable Forth (Riedel et al.", "startOffset": 58, "endOffset": 78}, {"referenceID": 37, "context": ", 2016) and Differentiable Forth (Riedel et al., 2016), which implement similar ideas.", "startOffset": 33, "endOffset": 54}, {"referenceID": 25, "context": "Technique name Family Optimizer/Solver Description FMGD (Forward marginals, gradient descent) Machine learning TensorFlow A gradient descent based approach which generalizes the approach used by Kurach et al. (2015). (I)LP ((Integer) linear programming) Machine learning Gurobi A novel linear program relaxation approach based on adapting standard linear program relaxations to support Gates (Minka and Winn, 2009).", "startOffset": 195, "endOffset": 216}, {"referenceID": 42, "context": "TerpreT currently has four back-end inference algorithms, which are listed in Table 1: gradientdescent (thus any TerpreT model can be viewed as a differentiable interpreter), (integer) linear program (LP) relaxations, SMT, and the Sketch program synthesis system (Solar-Lezama, 2008).", "startOffset": 263, "endOffset": 283}, {"referenceID": 39, "context": "3, we show how to adapt the ideas of gates (Minka and Winn, 2009) to the linear program relaxations commonly used in graphical model inference (Schlesinger, 1976; Werner, 2007; Wainwright and Jordan, 2008).", "startOffset": 143, "endOffset": 205}, {"referenceID": 51, "context": "3, we show how to adapt the ideas of gates (Minka and Winn, 2009) to the linear program relaxations commonly used in graphical model inference (Schlesinger, 1976; Werner, 2007; Wainwright and Jordan, 2008).", "startOffset": 143, "endOffset": 205}, {"referenceID": 50, "context": "3, we show how to adapt the ideas of gates (Minka and Winn, 2009) to the linear program relaxations commonly used in graphical model inference (Schlesinger, 1976; Werner, 2007; Wainwright and Jordan, 2008).", "startOffset": 143, "endOffset": 205}, {"referenceID": 25, "context": "For the gradient descent case, we generalize the approach taken by Kurach et al. (2015), lifting discrete operations to operate on discrete distributions, which then leads to a differentiable system.", "startOffset": 67, "endOffset": 88}, {"referenceID": 25, "context": "For the gradient descent case, we generalize the approach taken by Kurach et al. (2015), lifting discrete operations to operate on discrete distributions, which then leads to a differentiable system. For the linear program case, we need to extend the standard LP relaxation for discrete graphical models to support if statements. In Section 4.3, we show how to adapt the ideas of gates (Minka and Winn, 2009) to the linear program relaxations commonly used in graphical model inference (Schlesinger, 1976; Werner, 2007; Wainwright and Jordan, 2008). This could serve as a starting point for further work on LP-based message passing approaches to IPS (e.g., following Sontag et al. (2008)).", "startOffset": 67, "endOffset": 688}, {"referenceID": 25, "context": "\u2022 A novel linear program relaxation to handle the if statement structure that is common in execution models, and a generalization of the smoothing technique from Kurach et al. (2015) to work on any execution model expressible in TerpreT.", "startOffset": 162, "endOffset": 183}, {"referenceID": 0, "context": "Control flow graphs (CFGs) (Allen, 1970) are a representation of programs commonly used for static analysis and compiler optimizations.", "startOffset": 27, "endOffset": 40}, {"referenceID": 25, "context": "While this model focuses on interpretability, it also builds on an observation from the results of Kurach et al. (2015). In NRAMs, a RNN-based controller chooses a short sequence of instructions to execute next based on observations of the current program state.", "startOffset": 99, "endOffset": 120}, {"referenceID": 48, "context": "Run the algorithm as presented above, with \u03b1i = 1 and using the RMSProp (Tieleman and Hinton, 2012) gradient descent optimization algorithm.", "startOffset": 72, "endOffset": 99}, {"referenceID": 25, "context": "Add the heuristics below, which are inspired by Kurach et al. (2015) and designed to avoid getting stuck in local minima, and optimize the hyperparameters for these heuristics by random search.", "startOffset": 48, "endOffset": 69}, {"referenceID": 3, "context": "We mitigate the \u201cexploding gradient\u201d problem (Bengio et al., 1994) by globally rescaling the whole gradient vector so that its L2 norm is not bigger than some hyperparameter value C.", "startOffset": 45, "endOffset": 66}, {"referenceID": 30, "context": "Following Neelakantan et al. (2016b), we decay the variance of this noise during the training according to the following schedule: \u03c32 t = \u03b7 (1 + t)\u03b3 (8) where the values of \u03b7 and \u03b3 are hyperparameters and t is the epoch counter.", "startOffset": 10, "endOffset": 37}, {"referenceID": 25, "context": "Kurach et al. (2015) considered two additional tricks which we did not implement generally.", "startOffset": 0, "endOffset": 21}, {"referenceID": 25, "context": "Kurach et al. (2015) solve this by adding rescaling operations to ensure normalization.", "startOffset": 0, "endOffset": 21}, {"referenceID": 25, "context": "Kurach et al. (2015) used a curriculum learning scheme which involved first training on small instances of a given problem, and only moving to train on larger instances once the error rate had reduced below a certain value.", "startOffset": 0, "endOffset": 21}, {"referenceID": 39, "context": "Casting the TerpreT program as a factor graph allows us to build upon standard practice in constructing LP relaxations for solving maximum a posteriori (MAP) inference problems in discrete graphical models (Schlesinger, 1976; Wainwright and Jordan, 2008).", "startOffset": 206, "endOffset": 254}, {"referenceID": 50, "context": "Casting the TerpreT program as a factor graph allows us to build upon standard practice in constructing LP relaxations for solving maximum a posteriori (MAP) inference problems in discrete graphical models (Schlesinger, 1976; Wainwright and Jordan, 2008).", "startOffset": 206, "endOffset": 254}, {"referenceID": 2, "context": "For this, a TerpreT instance is translated into a set of constraints in the SMT-LIB standard (Barrett et al., 2015), after which any standard SMT solver can be called.", "startOffset": 93, "endOffset": 115}, {"referenceID": 8, "context": "(Clarke et al., 2001)) which for a given program, search for an input that shows some behavior.", "startOffset": 0, "endOffset": 21}, {"referenceID": 42, "context": "5 Sketch Back-end The final back-end which we consider is based on the Sketch (Solar-Lezama, 2008) program synthesis system, which allows programmers to write partial programs called sketches while leaving fragments unspecified as holes.", "startOffset": 78, "endOffset": 98}, {"referenceID": 42, "context": "More details about the CEGIS algorithm in Sketch can be found in Solar-Lezama (2008).", "startOffset": 65, "endOffset": 85}, {"referenceID": 25, "context": "1 Failure of FMGD Kurach et al. (2015) and Neelakantan et al.", "startOffset": 18, "endOffset": 39}, {"referenceID": 25, "context": "1 Failure of FMGD Kurach et al. (2015) and Neelakantan et al. (2016b) mention that many random restarts and a careful hyperparameter search are needed in order to converge to a correct deterministic solution.", "startOffset": 18, "endOffset": 70}, {"referenceID": 5, "context": "minimal length (Bunel et al., 2016) or resource usage).", "startOffset": 15, "endOffset": 35}, {"referenceID": 25, "context": "Secondly, FMGD makes the synthesis task fully differentiable, allowing its incorporation into a larger end-to-end differentiable system (Kurach et al., 2015).", "startOffset": 136, "endOffset": 157}, {"referenceID": 10, "context": "It has been argued that local optima become increasingly rare in neural network loss surfaces as the dimension of the hidden layers increase, and instead saddle points become increasingly common (Dauphin et al., 2014).", "startOffset": 195, "endOffset": 217}, {"referenceID": 10, "context": "It has been argued that local optima become increasingly rare in neural network loss surfaces as the dimension of the hidden layers increase, and instead saddle points become increasingly common (Dauphin et al., 2014). Exchanging local minima for saddle points is beneficial because dynamic learning rate schedules such as RMSProp are very effective at handling saddle points and plateaus in the loss function. To assess how dimensionality affects FMGD, we first take a minimal example in the boolean circuit domain: the task of synthesizing a NAND gate. The minimum solution for this task is shown in Fig. 18(a), along with an example configuration which resides at one local minimum of the FMGD loss surface. For a synthesis task involving two gates and two wires, there are a total of 14 independent degrees of freedom to be optimized, and there is only one global optimum. Increasing the available resources to three gates and three wires, gives an optimization problem over 30 dimensions and several global minima. The contrast between the learning trajectories in these two cases is shown in Fig. 18. We attempt to infer the presence of saddle points by exploring the loss surface with vanilla gradient descent and a small learning rate. Temporary stagnation of the learning is an indication of a saddle-like feature. Such features are clearly more frequently encountered in the higher dimensional case where we also observe a greater overall success rate (36% of 100 random initializations converge on a global optimum in the low dimensional case vs. 60% in the high dimensional case). These observations are consistent with the intuition from Dauphin et al. (2014), suggesting that we will have more success in the benchmark tasks if we provide more resources (i.", "startOffset": 196, "endOffset": 1673}, {"referenceID": 14, "context": "Some probabilistic programming languages, exemplified by Church (Goodman et al., 2008), allow great freedom in the expressibility of the language, including constructs like recursion and higher order functions.", "startOffset": 64, "endOffset": 86}, {"referenceID": 6, "context": ", 2014) and Stan (Carpenter, 2015; Stan Development Team, 2015).", "startOffset": 17, "endOffset": 63}, {"referenceID": 6, "context": ", 2014) and Stan (Carpenter, 2015; Stan Development Team, 2015). These systems restrict models to be constructed of predefined building blocks and do not support arbitrary program constructs like recursion and higher order functions. They do generally support basic loops and branching structure, however. In Infer.NET, for example, loops are unrolled, and if statements are handled via special constructs known as Gates (Minka and Winn, 2009). The result is that the program can be viewed as a finite gated factor graph, on which message passing inference can be performed. In these terms, TerpreT is most similar to Infer.NET, and its handling of loops and if statements are inspired by Infer.NET. Compared to Infer.NET, TerpreT is far more extreme in the restrictions that it places upon modelling constructs. The benefit is that the restricted language allows us to support a broader range of back-ends. Looking forward, Infer.NET provides inspiration for how TerpreT might be extended to handle richer data types like real numbers and strings. Another related line of work is in casting program synthesis as a problem of inference in probabilistic models. Gulwani and Jojic (2007) phrase program synthesis as inference in a graphical model and use", "startOffset": 18, "endOffset": 1186}, {"referenceID": 32, "context": "The problem of inducing samplers for probability distributions has also been cast as a problem of inference in a probabilistic program (Perov and Wood, 2016).", "startOffset": 135, "endOffset": 157}, {"referenceID": 26, "context": "Lake et al. (2015) induce probabilistic programs by performing inference in a probabilistic model describing how primitives are composed to form types and instances of types.", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "This is problematic when the task at hand requires to relate inputs that are far apart from each other, which more recent models try to mitigate using tools such as Long Short-Term Memory (Hochreiter and Schmidhuber, 1997; Graves, 2013) and Gated Recurrent Units (Cho et al.", "startOffset": 188, "endOffset": 236}, {"referenceID": 15, "context": "This is problematic when the task at hand requires to relate inputs that are far apart from each other, which more recent models try to mitigate using tools such as Long Short-Term Memory (Hochreiter and Schmidhuber, 1997; Graves, 2013) and Gated Recurrent Units (Cho et al.", "startOffset": 188, "endOffset": 236}, {"referenceID": 7, "context": "This is problematic when the task at hand requires to relate inputs that are far apart from each other, which more recent models try to mitigate using tools such as Long Short-Term Memory (Hochreiter and Schmidhuber, 1997; Graves, 2013) and Gated Recurrent Units (Cho et al., 2014).", "startOffset": 263, "endOffset": 281}, {"referenceID": 28, "context": ", (Mikolov et al., 2015; Kout\u0144\u0131k et al., 2014)).", "startOffset": 2, "endOffset": 46}, {"referenceID": 23, "context": ", (Mikolov et al., 2015; Kout\u0144\u0131k et al., 2014)).", "startOffset": 2, "endOffset": 46}, {"referenceID": 13, "context": "Initial extensions provided a stack (Giles et al., 1989) or a scratch pad simplified to a stack (Mozer and Das, 1992), and the controlling network learned when to push data to and pop (load) data from that stack.", "startOffset": 36, "endOffset": 56}, {"referenceID": 29, "context": ", 1989) or a scratch pad simplified to a stack (Mozer and Das, 1992), and the controlling network learned when to push data to and pop (load) data from that stack.", "startOffset": 47, "endOffset": 68}, {"referenceID": 16, "context": "3 Recently, similar ideas have been picked up again, leading to stack and queue-augmented recurrent nets (Joulin and Mikolov, 2015; Grefenstette et al., 2015), memory networks with freely addressable storage (Weston et al.", "startOffset": 105, "endOffset": 158}, {"referenceID": 46, "context": ", 2015), memory networks with freely addressable storage (Weston et al., 2014; Sukhbaatar et al., 2015), and extensions that additionally use registers for intermediate results (Kurach et al.", "startOffset": 57, "endOffset": 103}, {"referenceID": 25, "context": ", 2015), and extensions that additionally use registers for intermediate results (Kurach et al., 2015).", "startOffset": 81, "endOffset": 102}, {"referenceID": 52, "context": "A number of recent advances build on this observation to learn algorithms from input-output data (Graves et al., 2014; Joulin and Mikolov, 2015; Neelakantan et al., 2016a; Reed and de Freitas, 2016; Zaremba et al., 2016).", "startOffset": 97, "endOffset": 220}, {"referenceID": 5, "context": "To support adaptive neural compilation (Bunel et al., 2016), a machine model similar to our assembly model (cf.", "startOffset": 39, "endOffset": 59}, {"referenceID": 37, "context": "Differentiable Forth (Riedel et al., 2016) is a similar step in this direction, where the learning task is to fill in holes in a partial Forth program.", "startOffset": 21, "endOffset": 42}, {"referenceID": 1, "context": "Program Synthesis The area of program synthesis has recently seen a renewed interest in the programming language community (Alur et al., 2015).", "startOffset": 123, "endOffset": 142}, {"referenceID": 19, "context": "There have been many synthesis techniques developed for a wide range of problems including data wrangling (Gulwani et al., 2012; Polozov and Gulwani, 2015), inference of efficient synchronization in concurrent programs, synthesizing efficient low-level code from partial programs (Solar-Lezama et al.", "startOffset": 106, "endOffset": 155}, {"referenceID": 34, "context": "There have been many synthesis techniques developed for a wide range of problems including data wrangling (Gulwani et al., 2012; Polozov and Gulwani, 2015), inference of efficient synchronization in concurrent programs, synthesizing efficient low-level code from partial programs (Solar-Lezama et al.", "startOffset": 106, "endOffset": 155}, {"referenceID": 43, "context": ", 2012; Polozov and Gulwani, 2015), inference of efficient synchronization in concurrent programs, synthesizing efficient low-level code from partial programs (Solar-Lezama et al., 2005), compilers for low-power spatial architectures (Phothilimthana et al.", "startOffset": 159, "endOffset": 186}, {"referenceID": 33, "context": ", 2005), compilers for low-power spatial architectures (Phothilimthana et al., 2014), efficient compilation of declarative specifications (Kuncak et al.", "startOffset": 55, "endOffset": 84}, {"referenceID": 24, "context": ", 2014), efficient compilation of declarative specifications (Kuncak et al., 2010), statistical code completion (Raychev et al.", "startOffset": 61, "endOffset": 82}, {"referenceID": 35, "context": ", 2010), statistical code completion (Raychev et al., 2016), and automated feedback generation for programming assignments (Singh et al.", "startOffset": 37, "endOffset": 59}, {"referenceID": 41, "context": ", 2016), and automated feedback generation for programming assignments (Singh et al., 2013).", "startOffset": 71, "endOffset": 91}, {"referenceID": 9, "context": "The hypothesis space of possible programs is typically defined using a domain-specific language, which is designed to be expressive enough to encode majority of desired tasks but at the same time concise enough for efficient 3Interestingly enough, extracting an interpretable deterministic pushdown automaton from a trained stack-using recurrent network was already proposed in (Das et al., 1992).", "startOffset": 378, "endOffset": 396}, {"referenceID": 42, "context": "Finally, some of the common search algorithms include constraint-based symbolic synthesis algorithms (Solar-Lezama, 2008; Reynolds et al., 2015), smart enumerative algorithms with pruning (Udupa et al.", "startOffset": 101, "endOffset": 144}, {"referenceID": 36, "context": "Finally, some of the common search algorithms include constraint-based symbolic synthesis algorithms (Solar-Lezama, 2008; Reynolds et al., 2015), smart enumerative algorithms with pruning (Udupa et al.", "startOffset": 101, "endOffset": 144}, {"referenceID": 49, "context": ", 2015), smart enumerative algorithms with pruning (Udupa et al., 2013), version-space algebra based search algorithms (Gulwani et al.", "startOffset": 51, "endOffset": 71}, {"referenceID": 19, "context": ", 2013), version-space algebra based search algorithms (Gulwani et al., 2012; Gulwani, 2011), and stochastic search (Schkufza et al.", "startOffset": 55, "endOffset": 92}, {"referenceID": 17, "context": ", 2013), version-space algebra based search algorithms (Gulwani et al., 2012; Gulwani, 2011), and stochastic search (Schkufza et al.", "startOffset": 55, "endOffset": 92}, {"referenceID": 38, "context": ", 2012; Gulwani, 2011), and stochastic search (Schkufza et al., 2013).", "startOffset": 46, "endOffset": 69}, {"referenceID": 40, "context": "There has also been some recent work on learning from inputs in addition to the input-output examples to guide the synthesis algorithm (Singh, 2016), and synthesizing programs without any examples by performing a joint inference over the program and the inputs to recover compressed encodings of the observed data (Ellis et al.", "startOffset": 135, "endOffset": 148}, {"referenceID": 12, "context": "There has also been some recent work on learning from inputs in addition to the input-output examples to guide the synthesis algorithm (Singh, 2016), and synthesizing programs without any examples by performing a joint inference over the program and the inputs to recover compressed encodings of the observed data (Ellis et al., 2015).", "startOffset": 314, "endOffset": 334}, {"referenceID": 1, "context": "We note that another recent effort SyGuS (Alur et al., 2015) aims to unify different program synthesis approaches using a common intermediate format based on context-free grammars so that different inferences techniques can be compared, but the TerpreT language allows for encoding richer programming models than SyGuS, and also allows for compilation to gradient-descent based inference algorithms.", "startOffset": 41, "endOffset": 60}, {"referenceID": 25, "context": "Our results also raise an interesting question when taken in comparison to (Kurach et al., 2015).", "startOffset": 75, "endOffset": 96}, {"referenceID": 45, "context": "Natural next steps are back-ends based on local search or Markov Chain Monte Carlo, and on message passing inference in graphical models, perhaps taking inspiration from Sontag et al. (2008). Third, we would like to build higher level languages on top of TerpreT, to support more compact specification of common TerpreT programming patterns.", "startOffset": 170, "endOffset": 191}], "year": 2016, "abstractText": "We study machine learning formulations of inductive program synthesis; that is, given input-output examples, we would like to synthesize source code that maps inputs to corresponding outputs. Our aims in this work are to develop new machine learning approaches to the problem based on neural networks and graphical models, and to understand the capabilities of machine learning techniques relative to traditional alternatives, such as those based on constraint solving from the programming languages community. Our key contribution is the proposal of TerpreT, a domain-specific language for expressing program synthesis problems. TerpreT is similar to a probabilistic programming language: a model is composed of a specification of a program representation (declarations of random variables) and an interpreter that describes how programs map inputs to outputs (a model connecting unknowns to observations). The inference task is to observe a set of input-output examples and infer the underlying program. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing proper like-to-like comparisons between different approaches to inference. From a single TerpreT specification we can automatically perform inference using four different back-ends that include machine learning and program synthesis approaches. These are based on gradient descent (thus each specification can be seen as a differentiable interpreter), linear program (LP) relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system. We illustrate the value of TerpreT by developing several interpreter models and performing an extensive empirical comparison between alternative inference algorithms on a variety of program models. Our key, and perhaps surprising, empirical finding is that constraint solvers dominate the gradient descent and LP-based formulations. We conclude with some suggestions on how the machine learning community can make progress on program synthesis.", "creator": "LaTeX with hyperref package"}}}