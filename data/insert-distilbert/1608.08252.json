{"id": "1608.08252", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2016", "title": "Business Process Deviance Mining: Review and Evaluation", "abstract": "business process deviance fraud refers to the phenomenon whereby a subset of potentially the executions paths of a managed business process deviate, in a negative or positive way, with respect to its expected or environmentally desirable outcomes. deviant executions instances of a business process include those that violate applicable compliance rules, or executions that undershoot or exceed performance targets. deviance mining is concerned with uncovering the reasons for deviant executions by analyzing business process event logs. this article provides a systematic review and comparative evaluation of deviance mining approaches based merely on compiling a family of relational data mining techniques known as sequence classification. perhaps using real - life logs from multiple domains, lastly we evaluate a big range of related feature types and classification validation methods in terms of their ability to accurately discriminate between normal and deviant executions of a process. normally we also analyze the interestingness of the rule sets extracted using different methods. we observe that feature sets extracted using pattern mining techniques only slightly outperform unlike simpler feature sets sets based usually on counts of individual activity occurrences in a trace.", "histories": [["v1", "Mon, 29 Aug 2016 21:14:01 GMT  (2878kb)", "http://arxiv.org/abs/1608.08252v1", null]], "reviews": [], "SUBJECTS": "cs.AI cs.DB", "authors": ["hoang nguyen", "marlon dumas", "marcello la rosa", "fabrizio maria maggi", "suriadi suriadi"], "accepted": false, "id": "1608.08252"}, "pdf": {"name": "1608.08252.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n60 8.\n08 25\n2v 1\n[ cs\n.A I]\n2 9\nA ug\n2 01\n6\nA\nBusiness Process Deviance Mining: Review and Evaluation\nHOANG NGUYEN, Queensland University of Technology, Australia MARLON DUMAS, University of Tartu, Estonia MARCELLO LA ROSA, Queensland University of Technology, Australia FABRIZIO MARIA MAGGI, University of Tartu, Estonia SURIADI SURIADI, Queensland University of Technology, Australia\nBusiness process deviance refers to the phenomenon whereby a subset of the executions of a business process deviate, in a negative or positive way, with respect to its expected or desirable outcomes. Deviant executions of a business process include those that violate compliance rules, or executions that undershoot or exceed performance targets. Deviance mining is concerned with uncovering the reasons for deviant executions by analyzing business process event logs. This article provides a systematic review and comparative evaluation of deviance mining approaches based on a family of data mining techniques known as sequence classification. Using real-life logs from multiple domains, we evaluate a range of feature types and classification methods in terms of their ability to accurately discriminate between normal and deviant executions of a process. We also analyze the interestingness of the rule sets extracted using different methods. We observe that feature sets extracted using pattern mining techniques only slightly outperform simpler feature sets based on counts of individual activity occurrences in a trace.\nGeneral Terms: Process Mining, Business Process Deviance, Sequence Classification"}, {"heading": "1. INTRODUCTION", "text": "Process mining is a family of techniques to extract knowledge of business processes from event logs [van der Aalst 2011]. It encompasses, among others, techniques for automated discovery of process models from event logs, techniques for checking conformance between a given process model and an event log, as well as techniques for analyzing and predicting performance of business processes based on event logs. This paper deals with business process deviance mining \u2013 a family of process mining techniques aimed at analyzing event logs in order to explain the reasons why a business process deviates from its normal or expected execution. Such deviations may be of a negative or of a positive nature \u2013 cf. theory of positive deviance [Spreitzer and Sonenshein 2004]. Positive deviance corresponds to executions that lead to high process performance, such as achieving positive outcomes with low execution times, low resource usage or low costs. Negative deviance refers to the executions of the process with low process performance or with negative outcomes or compliance violations. The input of deviance mining is an event log consisting of a set of labelled traces (the so-called training set). Each trace represents the execution of one case of the business process under analysis. It consists of a sequence of events, where an event corresponds to the execution of an activity. Each trace is associated with a label indicating whether the trace is \u201cnormal\u201d or \u201cdeviant\u201d. Given this input, the problem of deviance mining is that of calculating a function (called a classifier) that takes as input a trace and outputs a class for this trace (normal or deviant). Such function must produce accurate labels, i.e. it should guess the correct class of a trace both for traces in the training set but also for other unseen traces. Furthermore, since the purpose of deviance mining techniques is to explain deviance, their output should be expressed in terms of patterns or rules that allow an analyst to extract useful insights regarding the sources of the observed deviance. Since traces consist of sequences of events, one family of techniques applicable for deviance mining is sequence classification [Xing et al. 2010]. The goal of sequence classification is to construct classifiers that discriminate between two or more classes of\nACM Transactions on Management Information Systems, Vol. V, No. N, Article A, Publication date: January YYYY.\n2 sequences. One key issue in sequence classification is that of extracting features from the sequences that can be given as input to standard classification techniques such as decision trees. Such features can be extracted for example using sequence mining techniques. Various such techniques have been studied in the context of business process deviancemining as discussed later. However, no comparative study has been conducted to assert which techniques are more suitable in this setting. This article presents a comparative evaluation of sequence classification techniques for business process deviance mining. Based on a review of the state of the art, the article identifies two families of techniques that have been employed for deviance mining \u2013 those based on frequent pattern mining and those based on discriminative pattern mining. Representatives of these two families are benchmarked using a battery of reallife event logs, covering situations where deviance is frequent (balanced datasets) and others where deviance is rare (unbalanced). These representative techniques are assessed in terms of accuracy and interestingness measures. The former measures serve to quantify the extent to which the extracted patterns correctly reflect the classification of cases into normal and deviance, whereas the latter measures serve as a proxy for the usefulness of the extracted patterns. This article is an extended version of a conference paper [Nguyen et al. 2014]. With respect to the conference paper, this article adds: (i) a systematic classification and review of deviance mining techniques; (ii) a refinement of the evaluated techniques using Fisher score for feature selection; (iii) an extended evaluation with three additional event logs; and (iv) an assessment of the interestingness of the extracted classifiers in addition to their accuracy. The paper is structured as follows. Section 2 discusses existing methods for business process deviance mining. Section 3 outlines the methods for feature extraction and for classification evaluated in this study. Next, Section 4 presents the experimental results in terms of classification accuracy while Section 5 presents the results in terms of rules interestingness. Section 6 summarizes the contribution and discusses directions for future work."}, {"heading": "2. STATE OF THE ART", "text": "To analyze the state of the art in the field of sequence mining for business process deviance mining, we started by conducting a literature search using the systematic review principles of [Kitchenham 2004]. The search process started by submitting queries to a well-known literature database, Google Scholar.1 with keywords associated with the scope of the paper. We constructed queries by combining the keyword \u201cbusiness process\u201d with the following keywords: \u201cdeviance mining\u201d (referring to the problem under study), \u201csequence mining\u201d (the broad class of solutions of interest) and \u201cdiscriminative patterns\u201d (the specific class of solutions of interest). Since the term \u201cworkflow\u201d is sometimes used as a quasi-synonym of \u201cbusiness process\u201d, we also included queries combining \u201cworkflow\u201d with the above keywords. For each query, we gathered the first 20 hits in Google Scholar. As we conducted the search, we noted additional terms appearing in the titles of relevant papers, namely \u201csequential patterns\u201d and \u201csignature patterns\u201d and also used such terms in the search. The search was performed in September 2015. It resulted in 200 hits. Based on title, we filtered out papers that were clearly out of scope and removed duplicates. This filtering reduced the number of candidate papers to 34. We then proceeded with an inspection of the references of each paper in order to find other papers related to the topic. This activity increased the number of candidate papers to 48.\n1http://scholar.google.com\n3 From these publications we could classify them into three main groups: (1) pattern mining papers which focus on discovery of certain interesting patterns from datasets, (2) classification papers which propose new techniques and algorithms to improve classification quality with regards to a target class variable, and (3) patternbased classification papers which involve mining patterns and evaluating the predictive power of the patterns with regards to a target class variable. Note that papers in all groups span related work within and outside the domain of business processes. Our review was then concentrated on the last group of 9 papers since we wanted to survey related techniques which have been evaluated in or can be applied for business processes. From this group, we selected two representative papers of automated pattern mining and classification evaluation. The first one is [Lo et al. 2009] which examined discriminative patterns in the field of software engineering, and the second one is [Bose and van der Aalst 2013] which examined different types of sequential patterns in business processes. In addition, based on our knowledge, we also added two case study papers which proposed manual but closely related approaches: [Suriadi et al. 2013] examined business process activities and their effects on the process duration, and [Swinnen et al. 2012] examined the predictive power of sets of activities. Consequently, our survey could identify a taxonomy (see Fig. 1) represented by four papers and consisted of three categories of techniques: (1) based on individual activities, (2) set-based, and (3) sequence-based. In addition sequence-based techniques could be further distinguished into sequential and discriminative.\nAll automated techniques for deviance mining (i.e. excludingmanual delta analysis), involve a pattern extraction phase where patterns are extracted from traces seen as sequences of simple symbols (tokens) representing activity occurrences, followed by a classifier construction phase, where each trace is abstracted as a vector of features, and these vectors are given as input to a classification method such as decision tree miner, which produces a classifier. The resulting classifier is then analyzed in order to extract individual patterns or rules combining multiple patterns, that explain a high percentage of the observed deviance. These patterns or rules are given as input to analysts to help them understand the sources of observed deviance in the process.\n4 Different techniques differ depending on the abstraction of the event logs used to define the features. The three ways of abstraction as shown on the taxonomy are described as follows.\n(1) Occurrence count of individual activities in a trace as in [Suriadi et al. 2013]. In this feature extraction method, each activity type appearing in the log (e.g. \u201cReceive Purchase Order Change\u201d, \u201cIssue Invoice\u201d, \u201cInvoice Paid\u201d) is treated as a numerical feature. For a given trace, the value of an activity feature is the number of times the activity in question occurs in the trace. For example if in a given trace, activity \u201cReceive Purchase Order Change\u201d appears 3 times, this is the value of the corresponding activity feature. This approach is quite straightforward with consideration that single or multiple activities may have significant influence on the case outcome. (2) Frequent set of trace attributes as in [Swinnen et al. 2012]. In this feature extraction method, frequent sets of activities are taken as a feature regardless of the order of their occurrence in the trace. A trace in this view follows the market basket data model in data mining. Frequent item set mining algorithms, such as Apriori [Agrawal et al. 1994], can then be applied to mine patterns that meet a support and/or confidence threshold. This approach takes interest in the association among activities regardless of their ordering. (3) Sequence of events that occurs multiple times in a trace or across traces. These features represent different way of event coordination such as loop, sub-processes or synchronization. We select two representative types of sequence-based features: one from [Bose and van der Aalst 2009] (called Sequential Patterns) and one from [Lo et al. 2009] (called Discriminative Patterns). (a) [Bose and van der Aalst 2009] proposes sequential patterns including Tandem\nRepeats, Alphabet Tandem Repeats, Maximal Repeats and Alphabet Maximal Repeats. These patterns capture different types of control-flow relations in a business process (loops, parallelism and subprocesses) and have been shown to be potentially suitable for analyzing business process deviance [Bose and van der Aalst 2013]. More specifically, tandem repeats mining searches for recurrent sequences of events within a trace which represent loops, whereas maximal repeats mining searches for any repetitive sequences in the whole log which represent sub-processes. An alphabet-type feature represents multiple tandem repeats or maximal repeats, respectively, if they share the same constituent activities (alphabet is the set of unique activities constituting a sequential pattern). Alphabet-based patterns, thus, capture variations in tandem repeats or maximal repeats due to parallelism. (b) [Lo et al. 2009] proposes iterative features consisting of consecutive or nonconsecutive events that have multiple occurrence within a trace or across traces. This technique is different to tandem/maximal repeats in the sense that the atomic events in an iterative feature do not necessarily occur close together, which captures synchronized behaviors among events. In addition, [Lo et al. 2009] uses feature selection technique to return only features that are strongly associated with the outcome classes (so called \u201dDiscriminative Patterns\u201d). This association is measured by a weight value, such as Fisher score [Duda et al. 2012].\nThe first method (individual activities) is in essence a baseline. Indeed, the occurrence of a single activity in a trace is the simplest form of feature one can extract from a sequence. In this work, we aim at evaluating how much added-value other feature extraction methods (i.e. set-based and sequence-based variations) could contribute on top of the individual activities. Thus, we study seven feature sets in the sequel: (i) individual activities (IA); (ii) maximal repeats (MR); (iii) alphabet maximal repeats\n5 (MRA); (iv) tandem repeats (TR); (v) alphabet tandem repeats (TRA); (vi) iterative patterns (IP); and (vii) set-based patterns (SET).\nDeviance mining is partially related to predictive monitoring of business processes [Maggi et al. 2013; Metzger et al. 2015]. Whereas deviance mining aims at explaining the reasons for deviant cases in post mortem manner, predictive monitoring aims at predicting whether or not an ongoing case will end up in a normal or a deviant category upon its completion \u2013 for example predicting whether or not an ongoing case will lead to a customer complaint or a deadline violation. Deviance mining and predictive monitoring techniques have overlapping inputs but distinct outputs. Deviance mining techniques take as input a set of traces classified into normal and deviant, and returns a set of rules that explain the deviance. Predictive process monitoring techniques additionally take as input the incomplete trace of a running case of the process, and they return a prediction of the outcome of this case. Given their overlapping inputs, predictive monitoring and deviance mining techniques have common concerns. Specifically, they both have to deal with the question of how to extract features from the set of historical traces in order to construct a classifier \u2013 with the difference that in predictive monitoring, one has to take into account the fact that the classification is done with respect to the trace prefix of an incomplete case, and thus the \u201cstate\u201d of execution of the current case needs to be taken into account. Not surprisingly, some of the feature extraction methods mentioned above can also be found in the context of predictive monitoring. For example, [Maggi et al. 2013] considers both individual activity features as well as frequent sequential patterns, whereas [Leontjeva et al. 2015] extends these features with others, including the index in the trace where a given activity occurs (e.g. does a given activity occur in the first or second position in the trace?) as well as other features extracted from hidden markov models constructed from the historical traces. [de Leoni et al. 2016] provides a framework for feature extraction that additionally considers the counts of individual activity occurrences and their index as possible features, as well as a range of other features related to the data-flow and the resource perspective (e.g. current value of a given variable of the process, and current workload of a given resource). Similar features are also employed in [Conforti et al. 2013; Conforti et al. 2015] to predict process risks. With respect to these latter two works, the present article focuses on studying the predictive power of control-flow features. On the other hand, it goes deeper by considering not only individual activity features but also set-based and sequence-based patterns as discussed above."}, {"heading": "3. EVALUATION SETUP", "text": "This section presents the evaluation setup. First, it describes the datasets used; next it outlines the methods used for feature extraction and for classification."}, {"heading": "3.1. Datasets", "text": "We used six datasets derived from five real-life event logs. We selected these datasets in order to cover classifications of \u201cnormal\u201d and \u201cdeviant\u201d cases based on temporal and non-temporal criteria. Note that case and trace are used interchangeably in this paper, as well as feature and pattern. In the former criterion, the difference between deviant and normal cases is made on the basis of the process duration w.r.t. a duration threshold (i.e. slow vs. normal processes); in the latter criterion, the difference between types of cases depend on an outcome attribute of the case (e.g. failing or successful outcome). The six logs fall into two sets. The first set (including the first two logs in Table I and II) is recorded software behaviors [Lo et al. 2009]. These two logs contain traces\nin which every event is a software command. Every trace can be viewed as a series of commands executed while using the software. The trace outcome is marked as \u201csuccessful\u201d when the execution has no errors, and \u201cfailing\u201d when the execution results in an error (deviant case). The Schedule log was obtained from a Siemens system and the MySQL log was obtained from the a MySQL database engine. These processes are machine-based and highly repeatable. By contrast, the second set (including the four remaining logs in Tables I and II), contains weakly structured processes with intensive human involvement. The Hospital1 log pertains to a chest pain patient flow in an emergency department of an Australian hospital. Traces are labelled as \u201cquick\u201d for cases that complete within a 180 minutes, and\u201cslow\u201d (or deviant) otherwise. The Hospital2 log is provided by another Australian hospital pertaining to the assessment process of mental health patients from the time the patients are referred to the hospital (as outpatients) to the time they are first assessed by qualified medical personnel. A case is labelled as \u201cquick\u201d if the assessment process is completed within 5 days, or \u201cslow\u201d (or deviant) otherwise. The Insurance1 log comes from an Australian insurance company and records an extract of the instances of a commercial insurance claims handling process. Also for this log, we used a temporal deviance criterion for classification, with \u201cquick\u201d being the label for those cases that complete within 30 days, and \u201cslow\u201d otherwise. Also in this case, slow cases are deviant cases. The Insurance2 log is extracted from the Insurance1 dataset to evaluate the relationship between individual activities and non-temporal outcome. The two outcome labels, \u201cmistake\u201d and \u201crejected\u201d, are non-temporal that reflect the final decision on cases (the latter is deviant). The two activities \u201cAuthorise Decline\u201d and \u201cConfirm Decline\u201d are also deliberately filtered out."}, {"heading": "3.2. Model construction", "text": "The model construction has two stages: pattern mining and model training/testing. Given a labeled event log (i.e. a log where each trace is labeled as \u201cnormal\u201d or \u201cdeviant\u201d), the first stage will mine and select features. The latter stage will then con-\n7 struct a classifier by transforming the training traces into a vector space and using standard classification techniques. In this context, a trace t is converted to a vector of features (\u3008 f1, ...fn \u3009, l), where fi(i = 1, 2, ..., n) is the value of the i\nth feature for trace t and l is the label (normal or deviant). The value is the frequency count of the feature in the trace. We use a feature selection technique as used in [Cheng et al. 2008] and [Lo et al. 2009]. This technique selects a feature based on a weight of its statistical correlation with the outcome classes. The weight can be, for example, information gain or Fisher score. Fisher score is used in this paper in the same way as [Lo et al. 2009]. Basically, in the first place, this technique selects an initial set of frequent features based on a support (frequency) level. Then, Fisher scores are computed for all features. Finally, it selects a final set of features by sequentially checking each feature from a high to low Fisher score ranking and selecting one that covers at least one trace from the trace database. In this technique, the number of features selected is controlled by two parameters: minimum support level and coverage threshold. According to [Cheng et al. 2008], the support level has an impact on the discriminative power. A minimum support level of 0.25 is used for all feature types. The coverage threshold \u03b8 is used in the final selection step, in the way that any trace covered by more than \u03b8 features will be excluded from being checked against the next features for coverage. The aim is the final feature set will contain high-score features that can cover as many traces as possible, without being overly concentrated on a small proportion of traces. A common coverage threshold of 5 is used for all feature types. In the second stage, to construct classifiers from the labeled samples, we can use a range of methods. Given that we seek an explainable classifier, a natural choice is decision tree learning, which produces trees from which human-readable rules can be extracted. This is the approach employed for example in [Suriadi et al. 2013; Bose and van der Aalst 2013; Sun et al. 2013]. Hence, we include decision trees (C4.5 method implemented in RapidMiner) as a baseline in the evaluation. We also include a k-NN (k-Nearest Neighbors) classification method in the evaluation as an example of a simple classification technique that does not construct an explicit classification model, but instead classifies a given sample based on its most similar samples. Specifically, given a sample, the k nearest neighbors are found and the class (normal or deviant) that is most common among neighbors in the training set is used to classify the given sample. We set the value of parameter k to 8, after initial trial-and-error to find a value yielding higher accuracy. Although no rules can be extracted from a k-NN classifier, the output of k-NN is explainable in the sense that given a trace t, one can show which \u201csimilar\u201d traces have been used to classify trace t as normal or deviant. Finally, we included neural networks in the evaluation as representative of a method that can adjust itself to the data and handle large feature sets [Zhang 2000] even though it does not produce explicit (understandable) rules as decision trees do. Different tools are used for feature mining and classification. Tandem/maximal repeats and their alphabet variants are mined using the Signature Discovery plug-in in ProM [Bose and van der Aalst 2013], while iterative pattern mining is based on the implementation in [Lo et al. 2009]. Set-based pattern mining is implemented using the FP-Growth algorithm for frequent item set mining [Han et al. 2000]. Tools for classification model training and testing are built on libraries and workflows of RapidMiner v6.0. Five-fold validation is used consistently from pattern mining to model training and testing. A log is randomly divided into five training and five testing datasets with 80/20 proportion of original traces, respectively. The class distribution in the training and testing data remains the same as that in the original data. The training\ndataset is only used for mining patterns and producing the classification model, and the testing dataset is only used for testing the trained model. This is, indeed, aligned with pattern-based comparative methods used in [Cheng et al. 2008], [Lo et al. 2009], [Deshpande et al. 2005] and [Lee et al. 2011]. The deviant class is usually rare in many datasets as compared to the non-deviant class. This skewed class distribution is unexpected because we want to discover deviant features and test their discriminative power. However, support-based frequent pattern mining tend to return only features of the dominant class; as a consequence, the training model built would be biased towards the dominant class. In this case, the prediction on the skewed data could be highly accurate but of little use in practice. To address this challenge, oversampling is used for training data to increase the population of the deviant class by randomly duplicating its traces. In this way, the training data of Schedule, MySQL and Hospital2 dataset have been balanced."}, {"heading": "4. ACCURACY EVALUATION", "text": "We measured classification accuracy in terms of the standard notion of accuracy defined as tp+tn\ntp+tn+fp+fn , where tp is the number of traces correctly classified as deviant\n(true positives), tn is the number of traces correctly classified as normal (true negatives), fp is the number of false positives and fn is the No. of false negatives. Additionally, we also report on the Area Under the ROC Curve (AUC) of each classifier. The AUC corresponds to the probability that a random negative sample is ranked higher than a random positive sample in the list of samples ranked from most likely to least likely to belong to the deviant class. AUC has been shown to be suitable for evaluating the accuracy of classification techniques both for balanced and unbalanced datasets [He and Garcia 2009]. This choice makes the results more comparable across the datasets. The prediction result is shown in Figure 2 - 5. For the Schedule dataset, the IP, TR and TRA patterns provide the highest result (from 88 to 90%). For the MySQL dataset, the MR and IP patterns score the best (100%). For the Insurance2 dataset, the IP and SET patterns provide a slight improvement over the IA baseline (85.45% vs. 84% and 0.937 vs. 0.916). However, for other datasets (Hospital1, Hospital2 and Insurance1), we observed that the composite patterns have virtually no improvement over the IA. Table III shows the average Fisher scores computed on the list of selected features for each feature type. Clearly, the features with better predictive power has higher av-\nerage Fisher score than others. This is evident in the case of IP/Schedule and MR &IP /MySQL (X/Y refers to a pair where X is the feature type and Y is the dataset). Likewise, IP/Insurance2 is highlighted with higher average Fisher score than the others. The list of selected features ranked by Fisher scores indeed supports that feature types with higher predictive accuracy do provide a number of highest scored features. For example, IP/Schedule has quite many patterns with high scores (see Figure 6) whereas IA/Hospital1 dominates the ranking (see Figure 7&7).\n1 0\n0\n0 .2\n0 .4\n0 .6\n0 .8 1\n1 .2\n364 198 361\n271 364 198 361\n271 198 361\n271 364 361\n364 198 361 354\n176 198 361\n176 364 361\n176 364 198 361\n290 364 198 361\n290 364 361\n290 198 361\n364 198 361 176\n271 364 210\n290 364 210\n176 364 210\n249 364 210\n290 364\n290 198\n290 361\n290 354\n290 210\n290 354 361 198 364\n290 354 361 198 210 364\n290 210 364\n290 361 210\n290 155 176\n290 210 213 364\n271 213 217 364\n271 354 361 198 210 213 217 364\n271 210 213 217 364\nF ig . 6 : S e le cte d F e a tu re s a n d F ish e r sco re s (IP /S ch e d u le ). E v e ry n u m b e r re p re se n ts o n e a ctiv ity, e .g . \u20183 6 4 \u2019 is o n e a ctiv ity. 0 0 .0 5 0 .1 0 .1 5 0 .2 0 .2 5 0 .3 0 .3 5 bD8 dF2 cP2 bX0 bJ4bD8 bJ4 cL1 bK3 aA1 aB4 bU4aB4 bN7bU4aB4 cY8 bJ4cY8 bM5 bD8aZ4 bD8aM4 cD2cL1 cD2bB0 bB0cD2 bN7bU4 cU9 aM4 aM4cU9 bB0 aZ4 bU4 bN7 F ig . 7 : S e le cte d F e a tu re s a n d F ish e r sco re s (M R /H o sp ita l1 ). T h e to p -ra n k in g e n co d e d fe a tu re s su ch a s b D 8 , cF 2 , cP 2 , a n d b x 0 re p re se n t in d iv id u a l a ctiv itie s.\nAnother observation is the composite patterns, i.e. non-IA, achieve higher accuracy than IA only when the case outcome is not temporal, e.g. Schedule and MySQL datasets. In other words, if the outcome is temporal, IA patterns likely carry most of the outcome-related signals since case duration is usually susceptible to the activity execution, i.e. the longer a case is, the more activities it has as observed in Hospital1, Hospital2 and Insurance1. Similarly, in the case of Insurance2, we deliberately use non-temporal outcome criterion and filter our related activities. As a result, the highest accurate feature type is SET. In conclusion, three observations arise from our experiments. First, IA capturesmost of the signals if the deviance outcome is temporal. Second, composite patterns are highly predictive in case of structured processes, e.g. Schedule and MySQL datasets. Finally, in case of less structured processes, composite patterns yield negligible improvement over IA, possibly because most of outcome-related signals have been captured by IAs or non-activity features, e.g. resource and data.\nExecution times. All experiments were executed on a laptop with 2.5GHz Intel CPU Dual Core, 8GB internal memory, and 64-bit Windows operating system. Fig. 9 shows the average feature mining runtime from five-fold iterations. In relation to the dataset characteristics presented in Table II, factors affecting mining performance are likely involved with the number of events per case, the number of event classes per case and\nthe data size (total number of cases). This is observed in case of the Schedule dataset with exceptionally long cases, Hospital2 with shortest average cases but largest data size, Insurance1 with quite large data size but low number of event classes per case. Mining techniques respond to different degrees to data characteristics. For example, it can be observed that MRA is highly sensitive to the number of events per case while IP is not; and SET is more susceptible to the number of event classes per case."}, {"heading": "5. RULES INTERESTINGNESS EVALUATION", "text": "We extracted rules from the six datasets across seven feature types using decision tree classifier. This technique takes the path from a leaf node of the tree to the top as a rule. All decision trees are trained with uniform input parameters. As a result, there are seven rulesets for each dataset, one per feature type. The rule has the form of A => B, where the antecedent A is a conjunction of multiple selectors in the form of attribute OP value with OP as relational operator, and the consequent B is the class label. For each dataset, we compare the quality of these rulesets on a number of selected measures and observe the effect of pattern types on the rules quality. The measures used in our evaluation include:\n\u2022Rule Length: the number of operators in the antecedent part of the rule. This is averaged from all rules of a ruleset. \u2022%Generalization [Gallion et al. 1993]: the generalizability based on the number of training examples and the number of rules.\n%Generalization = (1\u2212 #ofRules\n#ofT rainingExamples ) \u2217 100 (1)\n\u2022 Probability-based Objective Rule Interestingness Measures. [Geng and Hamilton 2006] evaluates 38 interestingness measures with reference to 12 desired properties. The authors ranked these measures in terms of how much they hold a property (Table V in [Geng and Hamilton 2006]). Based on this evaluation, we were able to select six top measures as listed below (noted that Yule\u2019s Q and Yule\u2019s Y are normalized variants of Odd Ratio [Tan et al. 2004]). Readers should refer to [Geng and Hamilton 2006] for a detailed discussion on these measures while a brief description is given below.\n13\n\u2014Collective Strength (CS ): proposed in [Aggarwal and Yu 1998] to replace the support-based paradigm in frequent itemset mining. The original idea is to mea-\nsure the collective strength of an itemset I as CS(I) = GoodEvents E[GoodEvents] \u2217 E[BadEvents] BadEvents] , where Good Events mean the items of the itemset are present in most of transactions and Bad Events are when they are not. In the context of rule evaluation, Good Events are when A and B are strongly correlated, and the opposite are Bad Events. The collective strength CS ranges from 0 to +\u221e. If CS = 0, A and B are mutually exclusive (perfect negative correlation). If CS = 1, A and B are totally independent. If CS increases to +\u221e, A and B are increasingly positively correlated.\nCS = P (AB) + P (\u00acB|\u00acA) P (A)P (B) + P (\u00acA)P (\u00acB) \u2217 1\u2212 P (A)P (B) \u2212 P (\u00acA)P (\u00acB) 1\u2212 P (AB)\u2212 P (\u00acB|\u00acA) (2)\n\u2014Two-Way Support (TWS ): proposed in [Yao and Liu 1997] to search for interesting knowledge in multiple databases. This measure ranges from \u2212\u221e to +\u221e. If it approaches +\u221e, the relation A => B increases and vice versa, the relation B => A increases when it approaches \u2212\u221e.\nTWS = P (AB) \u2217 log2 P (AB)\nP (A)P (B) (3)\n\u2014 \u03c6\u2212 Coefficient : this measure is based on Pearson correlation coefficient which ranges between -1 and +1. When it is greater than 0, A and B are positively correlated. When it equals 0, A and B are independent. When it is less than 0, A and B are negatively correlated.\n\u03c6\u2212 Coefficient = P (AB)\u2212 P (A)P (B) \u221a\nP (A)P (B)P (\u00acA)P (\u00acB) (4)\n\u2014Piatetsky-Shapiro (PS ): originally proposed in [Piatetsky-Shapiro 1991], this measure reflects the variance of probability when A and B are correlated and independent, with values ranging from -0.25 and 0.25. If PS is zero, A and B are totally independent. If PS is greater than 0, A and B are positively correlated, and vice versa, less than 0 when A and B are negatively correlated.\nPS = P (AB)\u2212 P (A)P (B) (5)\n\u2014Yule\u2019s Q (YuleQ): this is a normalized version of Odds Ratio (OR) [Mosteller 1968], and based on the contingency table involving A and B. Yule\u2019s Q ranges from -1 (perfect negative correlation) to +1 (perfect positive correlation).\nOR = P (AB)P (\u00acA\u00acB\nP (A\u00acB)P (\u00acAB) (6)\nYuleQ = OR \u2212 1\nOR + 1 (7)\n\u2014 Information Gain (IG): this measure is related to the Lift measure P (AB)\nP (A)P (B) , i.e.\nhow many times it needs to lift the confidence from the case when A and B are totally independentP (A)P (B) to the case whenA and B are statistically correlated P (AB). IG ranges from \u2212\u221e (negatively correlated) to +\u221e (positively correlated).\n14\nIG = log P (AB)\nP (A)P (B) (8)"}, {"heading": "5.1. Patterns and Rules", "text": "Across all datasets and feature types, we observe that patterns with high Fisher score are often chosen to form rules with high coverage based on the number of cases covered. This is justifiable because the Decision Tree would pick up these patterns as preferable splitting points based on their strong discriminative power (Gini index is used for Decision Tree in our experiment). The higher Fisher score a pattern has, the more rules they take part in and the higher coverage those rules are. Several representative examples are reviewed in details as follows. In particular, IP/Schedule provides a remarkable pattern: \u201d364 198 361\u201d (every number represents one activity). The related high-coverage rule is: IF \u201d364 198 361\u201d \u2265 0.500 THEN failing, meaning if this pattern occurs, the trace would have a failing outcome. Conversely, no IA-based rules are formed based on these three events, meaning activities individually do not carry any outcome-related signals. For the Hospital1, a remark is that most rules contain the \u201dNursing Progress Notes\u201d activity which has the top Fisher score. In this process, \u201dNursing Progress Notes\u201d seems to dominate the relationship with the duration-based outcome, i.e. if there are more \u201dNursing Progress Notes\u201d, the case would last longer. For the Insurance1, the IA-based rules basically have similar forms as the IP- and MR-based if composite patterns are broken down into individual activities. Although some IP- and MR-based patterns have slightly higher scores than the best of IAs, for example \u201d1 13 16\u201d (0.344 vs. 0.159) and \u201d1 16\u201d (0.292 vs. 0.159), but it is not substantial as in the case of the Schedule dataset. That\u2019s possibly the reason why IP has a better predictive result than other features but cannot surpass IA. For Insurance2, notably some IP- and SET-based patterns have higher Fisher scores than IA and others. Specifically, there is one remarkable IP-based rule: IF \u201dProcess Additional Information, Contact Customer\u201d\u2265 0.5 THEN Rejected Case (51% coverage), meaning if \u201dProcess Additional Information\u201d and \u201dContact Customer\u201d occur together, the case would be rejected. We observed that the IA also provides rules relating to \u201dProcess Additional Information\u201d and \u201dContact Customer\u201d but its rules are longer with other activities included. This is likely related to the fact that though \u201dProcess Additional Information\u201d and \u201dContact Customer\u201d rank very high in IA feature list, they are lower than the IP-based patterns. In this analysis, it is more evident that IAs likely carry most of the outcome-related signals in case of temporal outcome criterion (Hospital1 and Insurance1). Composite patterns, however, contribute some interesting rules (Schedule and Insurance2)."}, {"heading": "5.2. Rules Interestingness Measures", "text": "Differentmetrics are used to evaluate the quality of a ruleset. Rule Length is computed by averaging length of individual rules. %Generalization is computed according to formula (1). For probability-based measures, cumulative interestingness is computed by firstly sorting rules within a ruleset in decreasing order of the measure values, then accumulating these values from the highest to lowest. The cumulative measure for one feature type is visualized as an upward curve by the number of rules (Fig. 10,11,12). Our observation is summarized as follows with selected graphs for illustration due to space limitation. For the Schedule, the IP-based ruleset has consistently high interestingness over the others, except in \u03c6-Coefficient where the TR and TRA are the best (Fig. 10). Notably,\n15\nIP-based ruleset also achieves the highest predictive outcome, as well as TR and TRA. Rule Length and %Generalization are quite similar across feature types.\nFor the MySQL, similar to the Schedule dataset, IP-based and MR-based ruleset show the best cumulative interestingness, which accords with their high predictive strength (Fig. 11). They also have the shortest length and the greatest %Generalization (Rules were not generated for several feature types due to pruning parameters).\nFor the Hospital1, the MRA-based and IP-based ruleset have higher cumulative interestingness than others in all measures (Fig. 12). They also have high %Generalization after the IA-based. All rulesets are approximately equal in rule length. For the Hospital2 dataset, all rulesets are balanced across all measures, which corresponds to their equal predictive power and Fisher score as shown in section 4 and 5.1. For the Insurance1 dataset, similar to the Hospital1 dataset, the MRA-based and IP-based rulesets are higher than others in all interestingness measures. The IP-based and Set-based have slight improvement over others in Rule Length and %Generalization. For the Insurance2 dataset, the MRA-based cumulatively outperforms others in\nall measures except \u03c6-Coefficient, Yule\u2019s Q and Information Gain where the Set-based is the best. In summary, across all datasets, the IP-based, MRA-based and Set-based ruleset are often at the top of the cumulative interestingness measurement. The IP-based often results in shorter length and higher %Generalization. The IA-based ruleset is often below the others in most of the measures, except in Yule\u2019s Q and Information Gain where it improves after more rules are added to the ruleset. In short, rulesets based on composite patterns has higher interestingness than those based on IA."}, {"heading": "6. CONCLUSION", "text": "Our review of the state of the art has revealed that existing techniques for business process deviance mining are based on the extraction of patterns from business process execution traces using either individual activity frequency or frequent or discriminative pattern mining approaches. The empirical evaluation has unveiled evidence that, in the context of structured (predictable) business processes, pattern mining approaches clearly outperform the basic approach based on individual activity frequency in terms of accuracy. On the other hand, in the case of business processes with high level of variability, the accuracy improvement obtained by using pattern mining approaches is negligible. The latter observation suggests that when business processes have high variability, no clear composite patterns emerge, and thus such patterns do not add predictive power over simple activity counts. However, we observed that the use of composite patterns (be them frequent or discriminative ones) generally has a positive effect on the interestingness of the mined rule sets. In the case of processes with high variability, the maximum accuracy (AUC) achieved is around 80%, which might be insufficient in many practical applications. Underlying this limitation is the fact that the reviewed techniques for business process deviance mining treat the input as consisting of simple symbolic sequences, i.e. sequences of simple symbols (tokens) representing in our case activity or event occurrences. In some cases, including all six datasets used in this study, business process execution logs consist instead of temporal complex symbolic sequences, i.e. sequences of timestamped events, each event with a payload consisting of attribute-value pairs. Such logs can be extracted for example from appropriately instrumented information systems, such as patient management systems (in the case of healthcare processes) or claims handing systems (for insurance claims), or from mainstream Enterprise Resource Planning systems. It is likely that data payloads associated with events can convey significant\n17\ninformation regarding possible deviances and thus cannot be ignored as in the techniques evaluated in this paper. A direction for future work is thus to develop and apply techniques for extracting (discriminative) patterns from complex symbolic sequences \u2013 a non-trivial and open problem as noted in [Xing et al. 2010]. While tackling the problem of complex symbolic sequence mining in the general case is challenging, it may be possible to reduce the problem of business process deviance mining to well-scoped subsets of this problem, for example by taking advantage of information contained in available process models, such as which activities read/update which data attributes, which data attributes are used to make a decision in the process, etc., in order to prune the pattern search space.\nAcknowledgments This work is funded by the Estonian Research Council, ERDF via the Estonian Centre of Excellence Programme. This research is also supported by the Australian Centre for Health Services Innovation (#SG00009-000450) and by the Australian Research Council (#DP150103356)."}], "references": [{"title": "A new framework for itemset generation", "author": ["Charu C Aggarwal", "Philip S Yu."], "venue": "Proc. of PODS. ACM, 18\u201324.", "citeRegEx": "Aggarwal and Yu.,? 1998", "shortCiteRegEx": "Aggarwal and Yu.", "year": 1998}, {"title": "Abstractions in Process Mining: A Taxonomy of Patterns", "author": ["R.P. Jagadeesh Chandra Bose", "Wil M.P. van der Aalst."], "venue": "Proc. of BPM (LNCS), Vol. 5701. Springer, 159\u2013175.", "citeRegEx": "Bose and Aalst.,? 2009", "shortCiteRegEx": "Bose and Aalst.", "year": 2009}, {"title": "Discovering Signature Patterns from Event Logs", "author": ["R.P. Jagadeesh Chandra Bose andWil M.P. van der Aalst."], "venue": "Proc. of CIDM. IEEE, 111\u2013118.", "citeRegEx": "Aalst.,? 2013", "shortCiteRegEx": "Aalst.", "year": 2013}, {"title": "Direct Discriminative Pattern Mining for Effective Classification", "author": ["Hong Cheng", "Xifeng Yan", "Jiawei Han", "Philip S. Yu."], "venue": "Proceedings of ICDE. IEEE Computer Society, 169\u2013178.", "citeRegEx": "Cheng et al\\.,? 2008", "shortCiteRegEx": "Cheng et al\\.", "year": 2008}, {"title": "Supporting Risk-Informed Decisions during Business Process Execution", "author": ["R. Conforti", "M. de Leoni", "M. La Rosa", "W.M.P. van der Aalst."], "venue": "Proc. of CAiSE (LNCS), C. Salinesi, M.C. Norrie, and O. Pastor (Eds.), Vol. 7908. Springer, 116\u2013132.", "citeRegEx": "Conforti et al\\.,? 2013", "shortCiteRegEx": "Conforti et al\\.", "year": 2013}, {"title": "A recommendation system for predicting risks across multiple business process instances", "author": ["R. Conforti", "M. de Leoni", "M. La Rosa", "W.M.P. van der Aalst", "A.H.M. ter Hofstede."], "venue": "Decision Support Systems 69 (2015), 1\u201319. DOI:http://dx.doi.org/10.1016/j.dss.2014.10.006", "citeRegEx": "Conforti et al\\.,? 2015", "shortCiteRegEx": "Conforti et al\\.", "year": 2015}, {"title": "A general process mining framework for correlating, predicting and clustering dynamic behavior based on event logs", "author": ["Massimiliano de Leoni", "WilM.P. van der Aalst", "andMarcus Dees"], "venue": "Inf. Syst", "citeRegEx": "Leoni et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Leoni et al\\.", "year": 2016}, {"title": "Frequent substructurebased approaches for classifying chemical compounds", "author": ["Mukund Deshpande", "Michihiro Kuramochi", "Nikil Wale", "George Karypis."], "venue": "Knowledge and Data Engineering, IEEE Transactions on 17, 8 (2005), 1036\u20131050.", "citeRegEx": "Deshpande et al\\.,? 2005", "shortCiteRegEx": "Deshpande et al\\.", "year": 2005}, {"title": "Pattern classification", "author": ["Richard O Duda", "Peter E Hart", "David G Stork."], "venue": "John Wiley & Sons.", "citeRegEx": "Duda et al\\.,? 2012", "shortCiteRegEx": "Duda et al\\.", "year": 2012}, {"title": "Dynamic id3: A symbolic learning algorithm for many-valued attribute domains", "author": ["Roger Gallion", "Chaman L Sabharwal", "Daniel C St Clair", "William E Bond."], "venue": "Proceedings of the 1993 ACM/SIGAPP symposium on Applied computing: states of the art and practice. ACM, 14\u201320.", "citeRegEx": "Gallion et al\\.,? 1993", "shortCiteRegEx": "Gallion et al\\.", "year": 1993}, {"title": "Interestingness measures for data mining: A survey", "author": ["Liqiang Geng", "Howard J. Hamilton."], "venue": "ACM Comput. Surv. 38, 3 (2006), 9. DOI:http://dx.doi.org/10.1145/1132960.1132963", "citeRegEx": "Geng and Hamilton.,? 2006", "shortCiteRegEx": "Geng and Hamilton.", "year": 2006}, {"title": "Mining frequent patterns without candidate generation", "author": ["Jiawei Han", "Jian Pei", "Yiwen Yin."], "venue": "ACM SIGMOD Record, Vol. 29. ACM, 1\u201312.", "citeRegEx": "Han et al\\.,? 2000", "shortCiteRegEx": "Han et al\\.", "year": 2000}, {"title": "Learning from Imbalanced Data", "author": ["Haibo He", "Edwardo A. Garcia."], "venue": "IEEE Trans. Knowl. Data Eng. 21, 9 (2009), 1263\u20131284.", "citeRegEx": "He and Garcia.,? 2009", "shortCiteRegEx": "He and Garcia.", "year": 2009}, {"title": "Procedures for Undertaking Systematic Reviews", "author": ["Barbara A. Kitchenham."], "venue": "Technical Report. Computer Science Department, Keele University (TR/SE- 0401) and National ICT Australia Ltd. (0400011T.1).", "citeRegEx": "Kitchenham.,? 2004", "shortCiteRegEx": "Kitchenham.", "year": 2004}, {"title": "Mining discriminative patterns for classifying trajectories on road networks", "author": ["Jae-Gil Lee", "Jiawei Han", "Xiaolei Li", "Hong Cheng."], "venue": "Knowledge and Data Engineering, IEEE Transactions on 23, 5 (2011), 713\u2013726.", "citeRegEx": "Lee et al\\.,? 2011", "shortCiteRegEx": "Lee et al\\.", "year": 2011}, {"title": "Complex Symbolic Sequence Encodings for Predictive Monitoring of Business Processes", "author": ["Anna Leontjeva", "Raffaele Conforti", "Chiara Di Francescomarino", "Marlon Dumas", "Fabrizio Maria Maggi."], "venue": "Proc. of BPM. Springer, 297\u2013313. DOI:http://dx.doi.org/10.1007/978-3-319-23063-4", "citeRegEx": "Leontjeva et al\\.,? 2015", "shortCiteRegEx": "Leontjeva et al\\.", "year": 2015}, {"title": "Classification of Software Behaviours for Failure Detection: A Discriminative Pattern Mining Approach", "author": ["David Lo", "Hong Cheng", "Jiawei Han", "Siau-Cheng Khoo", "Chengnian Sun."], "venue": "Knowledge Discovery and Data Mining. ACM, 557\u2013566.", "citeRegEx": "Lo et al\\.,? 2009", "shortCiteRegEx": "Lo et al\\.", "year": 2009}, {"title": "Predictive Monitoring of Business Processes", "author": ["Fabrizio Maggi", "Chiara Di Francescomarino", "Marlon Dumas", "Chiara Ghidini."], "venue": "Proc. of CAiSE. Springer, 457\u2013472.", "citeRegEx": "Maggi et al\\.,? 2013", "shortCiteRegEx": "Maggi et al\\.", "year": 2013}, {"title": "Comparing and Combining Predictive Business Process Monitoring Techniques", "author": ["Andreas Metzger", "Philipp Leitner", "Dragan Ivanovic", "Eric Schmieders", "Rod Franklin", "Manuel Carro", "Schahram Dustdar", "Klaus Pohl."], "venue": "IEEE Trans. Systems, Man, and Cybernetics: Systems 45, 2 (2015), 276\u2013290.", "citeRegEx": "Metzger et al\\.,? 2015", "shortCiteRegEx": "Metzger et al\\.", "year": 2015}, {"title": "Association and estimation in contingency tables", "author": ["Frederick Mosteller."], "venue": "J. Amer. Statist. Assoc. 63, 321 (1968), 1\u201328.", "citeRegEx": "Mosteller.,? 1968", "shortCiteRegEx": "Mosteller.", "year": 1968}, {"title": "Mining Business Process Deviance: A Quest for Accuracy", "author": ["Hoang Nguyen", "Marlon Dumas", "Marcello La Rosa", "Fabrizio M. Maggi", "Suriadi Suriadi."], "venue": "Proc. of OTM (LNCS), Vol. 8841. Springer, 436\u2013 445.", "citeRegEx": "Nguyen et al\\.,? 2014", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "Discovery, analysis, and presentation of strong rules", "author": ["Gregory Piatetsky-Shapiro."], "venue": "Knowledge discovery in databases. AAI/MIT, 229\u2013238.", "citeRegEx": "Piatetsky.Shapiro.,? 1991", "shortCiteRegEx": "Piatetsky.Shapiro.", "year": 1991}, {"title": "Toward the Construct Definition of Positive Deviance", "author": ["Gretchen M. Spreitzer", "Scott Sonenshein."], "venue": "American Behavioral Scientist 47, 6 (2004), 828\u2013847.", "citeRegEx": "Spreitzer and Sonenshein.,? 2004", "shortCiteRegEx": "Spreitzer and Sonenshein.", "year": 2004}, {"title": "Mining explicit rules for software process evaluation", "author": ["Chengnian Sun", "Jing Du", "Ning Chen", "Siau-Cheng Khoo", "Ye Yang."], "venue": "Proc. of ICSSP. ACM, 118\u2013125.", "citeRegEx": "Sun et al\\.,? 2013", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Understanding Process Behaviours in a Large Insurance Company in Australia: A Case Study", "author": ["Suriadi Suriadi", "Moe Thandar Wynn", "Chun Ouyang", "Arthur H.M. ter Hofstede", "Nienke J. van Dijk."], "venue": "Proc. of CAiSE. Springer, 449\u2013464.", "citeRegEx": "Suriadi et al\\.,? 2013", "shortCiteRegEx": "Suriadi et al\\.", "year": 2013}, {"title": "A Process Deviation Analysis \u2013 A Case Study", "author": ["Jo Swinnen", "Beno\u0131\u0302t Depaire", "Mieke J. Jans", "Koen Vanhoof"], "venue": "In Proc. of BPM\u20192011", "citeRegEx": "Swinnen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Swinnen et al\\.", "year": 2012}, {"title": "Selecting the right objective measure for association analysis", "author": ["Pang-Ning Tan", "Vipin Kumar", "Jaideep Srivastava."], "venue": "Information Systems 29, 4 (2004), 293\u2013313.", "citeRegEx": "Tan et al\\.,? 2004", "shortCiteRegEx": "Tan et al\\.", "year": 2004}, {"title": "Process Mining - Discovery, Conformance and Enhancement of Business Processes", "author": ["Wil M.P. van der Aalst."], "venue": "Springer.", "citeRegEx": "Aalst.,? 2011", "shortCiteRegEx": "Aalst.", "year": 2011}, {"title": "A brief survey on sequence classification", "author": ["Zhengzheng Xing", "Jian Pei", "Eamonn J. Keogh."], "venue": "SIGKDD Explorations 12, 1 (2010), 40\u201348.", "citeRegEx": "Xing et al\\.,? 2010", "shortCiteRegEx": "Xing et al\\.", "year": 2010}, {"title": "Searching multiple databases for interesting complexes", "author": ["Jun Yao", "HUAN Liu."], "venue": "KDD: Techniques and Applications, World Scientific, Singapore 482 (1997), 484\u2013485.", "citeRegEx": "Yao and Liu.,? 1997", "shortCiteRegEx": "Yao and Liu.", "year": 1997}, {"title": "Neural Networks for Classification: A Survey", "author": ["G.P. Zhang."], "venue": "IEEE Trans. on Systems, Man, and Cybernetics, Part C: Applications and Reviews 30, 4 (2000), 451\u2013462.", "citeRegEx": "Zhang.,? 2000", "shortCiteRegEx": "Zhang.", "year": 2000}], "referenceMentions": [{"referenceID": 28, "context": "Since traces consist of sequences of events, one family of techniques applicable for deviance mining is sequence classification [Xing et al. 2010].", "startOffset": 128, "endOffset": 146}, {"referenceID": 20, "context": "This article is an extended version of a conference paper [Nguyen et al. 2014].", "startOffset": 58, "endOffset": 78}, {"referenceID": 16, "context": "The first one is [Lo et al. 2009] which examined discriminative patterns in the field of software engineering, and the second one is [Bose and van der Aalst 2013] which examined different types of sequential patterns in business processes.", "startOffset": 17, "endOffset": 33}, {"referenceID": 24, "context": "In addition, based on our knowledge, we also added two case study papers which proposed manual but closely related approaches: [Suriadi et al. 2013] examined business process activities and their effects on the process duration, and [Swinnen et al.", "startOffset": 127, "endOffset": 148}, {"referenceID": 25, "context": "2013] examined business process activities and their effects on the process duration, and [Swinnen et al. 2012] examined the predictive power of sets of activities.", "startOffset": 90, "endOffset": 111}, {"referenceID": 24, "context": "(1) Occurrence count of individual activities in a trace as in [Suriadi et al. 2013].", "startOffset": 63, "endOffset": 84}, {"referenceID": 25, "context": "(2) Frequent set of trace attributes as in [Swinnen et al. 2012].", "startOffset": 43, "endOffset": 64}, {"referenceID": 16, "context": "We select two representative types of sequence-based features: one from [Bose and van der Aalst 2009] (called Sequential Patterns) and one from [Lo et al. 2009] (called Discriminative Patterns).", "startOffset": 144, "endOffset": 160}, {"referenceID": 16, "context": "(b) [Lo et al. 2009] proposes iterative features consisting of consecutive or nonconsecutive events that have multiple occurrence within a trace or across traces.", "startOffset": 4, "endOffset": 20}, {"referenceID": 16, "context": "In addition, [Lo et al. 2009] uses feature selection technique to return only features that are strongly associated with the outcome classes (so called \u201dDiscriminative Patterns\u201d).", "startOffset": 13, "endOffset": 29}, {"referenceID": 8, "context": "This association is measured by a weight value, such as Fisher score [Duda et al. 2012].", "startOffset": 69, "endOffset": 87}, {"referenceID": 17, "context": "Deviance mining is partially related to predictive monitoring of business processes [Maggi et al. 2013; Metzger et al. 2015].", "startOffset": 84, "endOffset": 124}, {"referenceID": 18, "context": "Deviance mining is partially related to predictive monitoring of business processes [Maggi et al. 2013; Metzger et al. 2015].", "startOffset": 84, "endOffset": 124}, {"referenceID": 17, "context": "For example, [Maggi et al. 2013] considers both individual activity features as well as frequent sequential patterns, whereas [Leontjeva et al.", "startOffset": 13, "endOffset": 32}, {"referenceID": 15, "context": "2013] considers both individual activity features as well as frequent sequential patterns, whereas [Leontjeva et al. 2015] extends these features with others, including the index in the trace where a given activity occurs (e.", "startOffset": 99, "endOffset": 122}, {"referenceID": 4, "context": "Similar features are also employed in [Conforti et al. 2013; Conforti et al. 2015] to predict process risks.", "startOffset": 38, "endOffset": 82}, {"referenceID": 5, "context": "Similar features are also employed in [Conforti et al. 2013; Conforti et al. 2015] to predict process risks.", "startOffset": 38, "endOffset": 82}, {"referenceID": 16, "context": "The first set (including the first two logs in Table I and II) is recorded software behaviors [Lo et al. 2009].", "startOffset": 94, "endOffset": 110}, {"referenceID": 3, "context": "We use a feature selection technique as used in [Cheng et al. 2008] and [Lo et al.", "startOffset": 48, "endOffset": 67}, {"referenceID": 16, "context": "2008] and [Lo et al. 2009].", "startOffset": 10, "endOffset": 26}, {"referenceID": 16, "context": "Fisher score is used in this paper in the same way as [Lo et al. 2009].", "startOffset": 54, "endOffset": 70}, {"referenceID": 3, "context": "According to [Cheng et al. 2008], the support level has an impact on the discriminative power.", "startOffset": 13, "endOffset": 32}, {"referenceID": 24, "context": "This is the approach employed for example in [Suriadi et al. 2013; Bose and van der Aalst 2013; Sun et al. 2013].", "startOffset": 45, "endOffset": 112}, {"referenceID": 23, "context": "This is the approach employed for example in [Suriadi et al. 2013; Bose and van der Aalst 2013; Sun et al. 2013].", "startOffset": 45, "endOffset": 112}, {"referenceID": 16, "context": "Tandem/maximal repeats and their alphabet variants are mined using the Signature Discovery plug-in in ProM [Bose and van der Aalst 2013], while iterative pattern mining is based on the implementation in [Lo et al. 2009].", "startOffset": 203, "endOffset": 219}, {"referenceID": 11, "context": "Set-based pattern mining is implemented using the FP-Growth algorithm for frequent item set mining [Han et al. 2000].", "startOffset": 99, "endOffset": 116}, {"referenceID": 3, "context": "This is, indeed, aligned with pattern-based comparative methods used in [Cheng et al. 2008], [Lo et al.", "startOffset": 72, "endOffset": 91}, {"referenceID": 16, "context": "2008], [Lo et al. 2009], [Deshpande et al.", "startOffset": 7, "endOffset": 23}, {"referenceID": 7, "context": "2009], [Deshpande et al. 2005] and [Lee et al.", "startOffset": 7, "endOffset": 30}, {"referenceID": 14, "context": "2005] and [Lee et al. 2011].", "startOffset": 10, "endOffset": 27}, {"referenceID": 9, "context": "\u2022%Generalization [Gallion et al. 1993]: the generalizability based on the number of training examples and the number of rules.", "startOffset": 17, "endOffset": 38}, {"referenceID": 26, "context": "Based on this evaluation, we were able to select six top measures as listed below (noted that Yule\u2019s Q and Yule\u2019s Y are normalized variants of Odd Ratio [Tan et al. 2004]).", "startOffset": 153, "endOffset": 170}, {"referenceID": 28, "context": "A direction for future work is thus to develop and apply techniques for extracting (discriminative) patterns from complex symbolic sequences \u2013 a non-trivial and open problem as noted in [Xing et al. 2010].", "startOffset": 186, "endOffset": 204}], "year": 2016, "abstractText": "Business process deviance refers to the phenomenon whereby a subset of the executions of a business process deviate, in a negative or positive way, with respect to its expected or desirable outcomes. Deviant executions of a business process include those that violate compliance rules, or executions that undershoot or exceed performance targets. Deviance mining is concerned with uncovering the reasons for deviant executions by analyzing business process event logs. This article provides a systematic review and comparative evaluation of deviance mining approaches based on a family of data mining techniques known as sequence classification. Using real-life logs from multiple domains, we evaluate a range of feature types and classification methods in terms of their ability to accurately discriminate between normal and deviant executions of a process. We also analyze the interestingness of the rule sets extracted using different methods. We observe that feature sets extracted using pattern mining techniques only slightly outperform simpler feature sets based on counts of individual activity occurrences in a trace.", "creator": "LaTeX with hyperref package"}}}