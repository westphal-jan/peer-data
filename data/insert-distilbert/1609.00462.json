{"id": "1609.00462", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Sep-2016", "title": "A case study of algorithm selection for the traveling thief problem", "abstract": "many real - world problems are composed of actually several interacting components. in order to facilitate research on detecting such interactions, the traveling thief problem ( ttp ) was created in 2013 as expanding the combination of two well - understood basic combinatorial optimization problems.", "histories": [["v1", "Fri, 2 Sep 2016 04:03:22 GMT  (644kb,D)", "http://arxiv.org/abs/1609.00462v1", "23 pages, this article is underview"]], "COMMENTS": "23 pages, this article is underview", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["markus wagner", "marius lindauer", "mustafa misir", "samadhi nallaperuma", "frank hutter"], "accepted": false, "id": "1609.00462"}, "pdf": {"name": "1609.00462.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Markus Wagner", "Marius Lindauer", "Mustafa M\u0131s\u0131r", "Samadhi Nallaperuma", "Frank Hutter"], "emails": ["markus.wagner@adelaide.edu.au", "lindauer@informatik.uni-freiburg.de", "mmisir@nuaa.edu.cn", "s.nallaperuma@sheffield.ac.uk"], "sections": [{"heading": null, "text": "With this article, we contribute in four ways. First, we create a comprehensive dataset that comprises the performance data of 21 TTP algorithms on the full original set of 9720 TTP instances. Second, we define 55 characteristics for all TPP instances that can be used to select the best algorithm on a per-instance basis. Third, we use these algorithms and features to construct the first algorithm portfolios for TTP, clearly outperforming the single best algorithm. Finally, we study which algorithms contribute most to this portfolio.\nKeywords: Combinatorial optimization, instance analysis, algorithm portfolio"}, {"heading": "1 Introduction", "text": "The complexity of operations is increasing in most companies, with several interacting components having to be addressed at once. For example, the issue of scheduling production lines (e.g., maximizing the efficiency or minimizing the cost) has direct relationship with inventory costs, transportation costs, deliveryin-full-on-time to customers, and hence should not be considered in isolation.\n\u2217M. Wagner was supported by the Australian Research Council (DE160100850) and by a Priority Partner Grant by the University of Adelaide, Australia. M. Lindauer and F. Hutter were supported by the DFG (German Research Foundation) under Emmy Noether grant HU 1900/2-1. M. M\u0131s\u0131r was supported by the Nanjing University of Aeronautics and Astronautics Starter Research Fund. \u20201 Optimisation and Logistics Group, School of Computer Science, The University of Adelaide, Australia, markus.wagner@adelaide.edu.au 2 Institut fu\u0308r Informatik, Albert-Ludwigs-Universita\u0308t Freiburg, Germany, lindauer@informatik.uni-freiburg.de 3 Institute of Machine Learning and Computational Intelligence, Nanjing University of Aeronautics and Astronautics, China, mmisir@nuaa.edu.cn 4 Department of Computer Science, University of Sheffield, UK, s.nallaperuma@sheffield.ac.uk\nar X\niv :1\n60 9.\n00 46\n2v 1\n[ cs\n.A I]\n2 S\nep 2\nIn addition, optimizing one component of the operation may negatively impact activities in other components.\nThe academic traveling thief problem (TTP) [6] is quickly gaining attention as an NP-hard combinatorial optimization problem that combines two wellknown subproblems: the traveling salesperson problem (TSP) and the knapsack problem (KP). These two components have been merged in such a way that the optimal solution for each single one does not necessarily correspond to an optimal TTP solution. The motivation for the TTP is to allow the systematic investigation of interactions between two hard component problems, to gain insights that eventually help solve real-world problems more efficiently [8].\nSince the introduction of the TTP, many algorithms have been introduced for solving it. While the initial approaches were rather generic hill-climbers, researchers incorporated more and more domain knowledge into the algorithms. For example, this resulted in deterministic, constructive heuristics, in restart strategies, and also in problem-specific hill-climbers that try to solve the TTP holistically. While the use of insights typically resulted in an increase in the objective scores, the computational complexity also increased. Consequently, which one of the algorithms performs best is highly dependent on the TTP instance at hand. To exploit this complementarity of existing algorithms, here we study the applicability of algorithm selection [44] to this problem.\nSpecifically, after describing the TTP (Section 2) and the algorithm selection problem (Section 3), we make the following contributions:\n\u2022 We analyze the performance of 21 TTP algorithms on the original set of 9720 instances created by Polyakovskiy, Bonyadi, Wagner, Michalewicz, and Neumann [41] (Section 4);\n\u2022 We describe characteristics of TTP instances that can be used as \u201cfeatures\u201d for determining the best algorithm for the instance (Section 5);\n\u2022 We create the first algorithm portfolios for TTP, substantially improving performance over the best single TTP algorithm (Section 6); and\n\u2022 We analyze how complementary the algorithms in the portfolio are and which algorithms are most important for achieving good performance (Section 7)."}, {"heading": "2 The travelling thief problem (TTP)", "text": "The traveling thief problem (TTP) [6] is a recent attempt to provide an abstraction of multicomponent problems with dependency among components. It combines two problems and generates a new problem with two components. In particular, it combines the traveling salesperson problem (TSP) and the knapsack problem (KP), as both problems are well known and have been studied for many years in the field of optimization.\nIn this section, we motivate the TTP as an academic problem that addresses an important gap in research and then define it formally."}, {"heading": "2.1 Motivation", "text": "In contemporary business enterprises the complexity of real-world problems has to be perceived as one of the greatest obstacles in achieving effectiveness. Even relatively small companies are frequently confronted with problems of very high complexity. Some researchers investigated features of real-world problems that served to explain difficulties that Evolutionary Algorithms (EAs) experience in solving them. For example, Weise, Zapf, Chiong, and Nebro [48] discussed premature convergence, ruggedness, causality, deceptiveness, neutrality, epistasis, and robustness, which make optimization problems hard to solve. However, it seems that these reasons are either related to the landscape of the problem (such as ruggedness and deceptiveness) or to the optimizer itself (such as premature convergence and robustness) and do not focus on the nature of the problem. Michalewicz and Fogel [35] discussed a few different reasons behind the hardness of real-world problems, including problem size, presence of noise, multi-objectivity, and presence of constraints. Most of these features have been captured in different optimization benchmark sets, such as TSPlib [43], MIPlib [22] and OR-library [2].\nDespite decades of research efforts and many articles written on Evolutionary Computation (EC) in dedicated conferences and journals, still it is not that easy to find applications of EC in the real-world. Michalewicz [34] identified several reasons for this mismatch between academia and the real world. One of these reasons is that academic experiments focused on single component (single silo) benchmark problems, whereas real-world problems are often multi-component problems. In order to guide the community towards this increasingly important aspect of real-world optimization [8], the traveling thief problem was introduced [6] in order to illustrate the complexities that arise by having multiple interacting components.\nA related problem is the vehicle routing problem (VRP, for an overview see [3, 45]). The VRP is concerned with finding optimal routes for a fleet of vehicles delivering or collecting items from different locations [11, 24]. Over the years, a number of VRP variants have been proposed, such as variants with multiple depots or with capacity constraints. However, the insights gained there do not easily carry over to the academic TTP, as we consider in addition to the routing problem not only a load-dependent feature, but also the NP-hard optimisation problem of deciding which items are to be stolen by the thieves. For discussions on how the TTP differs from the VRP, we refer the interested reader to [6, 7].\nDespite being a challenging problem, it is often disputed whether the TTP is realistic enough because it only allows a single thief to travel across hundreds or thousands of cities to collect (steal) items. In addition, the thief is required to visit all cities, regardless of whether an item is stolen there or not. Chand and Wagner [10] discussed the shortcomings of the current formulation and presented a relaxed version of the problem which allows multiple thieves to travel across different cities with the aim of maximizing the group\u2019s collective profit. A number of fast heuristics were also proposed for solving the newly proposed multiple travelling thieves problem (MTTP). It was observed that having a\nsmall number of additional thieves could yield significant improvements of the objective scores in many cases."}, {"heading": "2.2 Formal Definition", "text": "We use the definition of the TTP by [41]. Given is a set of cities N = {1, . . . , n} and a set of items M = {1, . . . ,m} distributed among the cities. For any pair of cities i, j \u2208 N , we know the distance dij between them. Every city i, except the first one, contains a set of items Mi = {1, . . . ,mi}, M = \u222a\ni\u2208N Mi. Each item\nk positioned in city i is characterized by its profit pik and weight wik, thus the item Iik \u223c (pik, wik). The thief must visit all cities exactly once starting from the first city and returning back to it in the end. Any item may be selected in any city as long as the total weight of collected items does not exceed the specified capacity W . A renting rate R is to be paid per each time unit taken to complete the tour. \u03c5max and \u03c5min denote the maximal and minimum speeds that the thief can move. The goal is to find a tour, along with a packing plan, that results in the maximal profit.\nThe objective function uses a binary variable yik \u2208 {0, 1} that is equal to one when the item k is selected in the city i, and zero otherwise. Also, let Wi denote the total weight of collected items when the thief leaves the city i. Then, the objective function for a tour \u03a0 = (x1, . . . , xn), xi \u2208 N and a packing plan P = (y21, . . . , ynmi) has the following form:\nZ(\u03a0, P ) = n\u2211 i=1 mi\u2211 k=1 pikyik \u2212R\n( dxnx1\n\u03c5max \u2212 \u03bdWxn + n\u22121\u2211 i=1 dxixi+1 \u03c5max \u2212 \u03bdWxi\n)\nwhere \u03bd = \u03c5max\u2212\u03c5minW is a constant value defined by input parameters. The first term is the sum of all packed items\u2019 profits and the second term is the amount that the thief pays for the knapsack\u2019s rent (equal to the total traveling time along \u03a0 multiplied by R).\nNote that different values of the renting rate R result in different TTP instances that might be \u201charder\u201d or \u201ceasier\u201d to solve. For example, for small values of R (relative to the profits), the overall rent contributes little to the final objective score. In the extreme case R = 0, the best solution for a given TTP instance is equivalent to the best solution of the KP component, which means that there is no need to solve the TSP component at all. Similarly, high renting rates reduce the effect of the profits, and in the extreme case the best solution of the TTP is the optimum solution for the given TSP component.\nWe provide a brief example in the following (see Figure 1); full details are given by Polyakovskiy et al [41]. Each city but the first has an assigned set of items, e.g., city 2 is associated with item I21 of profit p21 = 20 and weight w21 = 2, and with item I22 of profit p22 = 30 and weight w22 = 3. Let us assume that the maximum weight W = 3, the renting rate R = 1 and \u03c5max and \u03c5min are set as 1 and 0.1, respectively. Then the optimum objective value is Z(\u03a0, P ) = 50 when to tour is \u03a0 = (1, 2, 4, 3, 1) and when items I32 and I33 are\npicked up (total profit of 80). As the thief\u2019s knapsack has a weight of 2 on the way from city 3 back to city 1, this reduces the speed and results in an increased cost of 15. Consequently, the final objective value is Z(\u03a0, P ) = 80\u221215\u221215 = 50."}, {"heading": "2.3 Algorithms for TTP", "text": "In the following, we provide a historical overview of approaches to the TTP. As we shall later see, none of these algorithms dominates all others.\nIn the original article in which the TTP is defined, Bonyadi et al [6] used exhaustive enumeration on instances with four cities and six items in order to demonstrate the interconnected components. A year later, Polyakovskiy et al [41] created a set of instances with up to almost 100,000 cities and 1,000,000 items, rendering exhaustive enumeration no longer feasible.\nIt were also Polyakovskiy et al [41] who proposed the first set of heuristics for solving the TTP. Their general approach was to solve the problem using two steps. The first step involved generating a good TSP tour by using the classical Chained Lin-Kernighan heuristic [1]. The second step involved keeping the tour fixed and applying a packing heuristic for improving the solution. Their first approach was a simple heuristic (SH) which constructed a solution by processing and picking items that maximized the objective value according to a given tour. Items were picked based on a score value that was calculated for each item to estimate how good it is according to the given tour. They also proposed two iterative heuristics, namely the Random Local Search (RLS) and (1+1)-EA, which probabilistically flipped a number of packing bits. After each iteration the solution was evaluated and if an improvement was noted, the changes were kept; otherwise they were ignored.\nBonyadi et al [7] experimentally investigated the interdependency between the TSP and knapsack components of the TTP. They proposed two heuristic approaches named Density-based Heuristic (DH) and CoSolver. DH is again a two-phased approach similar to SH from Polyakovskiy et al [41], and it also ignores any dependencies between the TSP and Knapsack components. In contrast to this, CoSolver is a method inspired by coevolution based approaches. It divides the problem into sub-problems where each sub-problem is solved by a different module of the CoSolver. The algorithm revises the solution through\nnegotiation between its modules. The communication between the different modules and sub-problems allows for the TTP interdependencies to be considered. A comparison across several benchmark problems showed the superiority of CoSolver over DH. This was especially evident for larger instances.\nMei, Li, and Yao [31] also investigated the interdependencies between the TSP and knapsack components. They analysed the mathematical formulation to show that the TTP problem is not additively separable. Since the objectives of the TSP and knapsack components are not fully correlated, one cannot expect to achieve competitive results by solving each component in isolation. The authors used two separate approaches for solving the TTP: a cooperative coevolution based approach similar to CoSolver, and a memetic algorithm called MATLS which attempts to solve the problem as a whole. The memetic algorithm, which considered the interdependencies in more depth, outperformed cooperative coevolution. Both works by Bonyadi et al [7] and Mei et al [31] highlight the importance of considering interdependencies between the TTP components as this will allow for the generation of more competitive solutions.\nFaulkner, Polyakovskiy, Schultz, and Wagner [12] investigated multiple operators and did a comprehensive comparison with existing approaches. They proposed a number of operators, such as Bitflip and PackIterative, for optimising the packing plan given a particular tour. They also proposed Insertion for iteratively optimising the tour given a particular packing. They combined these operators in a number of simple (S1\u2013S5) and complex (C1\u2013C6) heuristics that outperformed existing approaches. The main observation was that there does not yet seem to be a single best algorithmic paradigm for the TTP. Their individual operators, however, were quite beneficial in improving the quality of results. While the proposed operators seem to have certain benefits, the simple and complex heuristics did not consider the interdependencies between the TTP components, since all of these approaches were multi-step heuristics. Surprisingly, their best approach was a rather simple restart approach name S5 that combines good TSP tours with the fast PackIterative.\nWagner [47] recently investigated the use of swarm intelligence approaches with the so-called Max-Min Ant System (MMAS, by Stu\u0308tzle and Hoos [46]). Wagner investigated the impact of two different TSP-specific local search (ls) operators and of \u201cboosting\u201d TTP solutions using TTP-specific local search. The resulting approaches focus less on short TSP tours, but more on good TTP tours, which can be longer. This allowed them to outperform the previous best approaches MATLS and S5 on relatively small instances with up to 250 cities and 2000 items.\nYafrani and Ahiod [52] studied and compared different approaches for solving the TTP from a metaheuristics perspective. Two heuristic algorithms were proposed, including a memetic algorithm (MA2B) and one using simulated annealing (CS2SA). The results show that the new algorithms were competitive to S5 and MATLS on a range of larger TTP instances.\nLastly, we would like to mention that no efficient complete solver for the TTP is known. One of the reasons for this appears to be the fact that even when the tour is kept fixed, packing is NP-hard [40]."}, {"heading": "3 Algorithm Selection", "text": "As we shall see in Section 4, no algorithm dominates all other algorithms on all instances. One way to exploit this complementarity of the algorithms is to use algorithm selection [16, 44] to select a well-performing algorithm on a per-instance base."}, {"heading": "3.1 Problem Statement", "text": "The algorithm selection problem is to find a mapping from problem instances to algorithms. This is realized by computing numerical characteristics \u2013 socalled instance features \u2013 that describe a problem instance, and then learning a mapping from the resulting feature space to algorithms. Figure 2 shows the general workflow of algorithm selection.\nWe will describe instance features for the TTP later (in Section 5), but a simple feature is, e.g., the number of cities. Based on these instance features, we will select an algorithm from a portfolio of the 21 TTP algorithms we described in Section 4.2 to solve the instance at hand.\nThe selection step is typically realized with machine learning methods. Based on gathered training data (i.e., instance features and performance data on training instances), we learn a machine learning model that maps from instance features to a well-performing algorithm."}, {"heading": "3.2 Popular Algorithm Selection Approaches", "text": "One of the first successful algorithm selection procedures for satisfiability problems [4] was SATzilla [49]. It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each. SATzilla uses such a static schedule for \u201cpre-solving\u201d, to solve easy instances without the overhead of computing features.\nOther approaches include\n\u2022 classification models (e.g., ME-ASP by [28], 3S by [21], and CSHC by [27]) that directly learn a mapping from instance features to good algorithms;\n\u2022 pairwise classification models (e.g., the more recent version of SATzilla [50]), which learns a binary classifier for each pair of algorithms, weighting each training instance by the performance difference between the two algorithms (and thereby emphasizing instances for which the two algorithms\u2019 performances differ a lot);\n\u2022 unsupervised clustering (e.g., ISAC by [20]) to partition instances in the feature space into homogeneous subsets and then select the bestperforming algorithm of the cluster a new instance is closest to; and\n\u2022 recommender systems (e.g., [36]) to recommend an algorithm given only partial training data.\nFor a thorough overview on algorithm selection procedures, we refer the interested reader to [23].\nAs was shown in the 2015 ICON challenge on algorithm selection1, there currently exist two state-of-the-art algorithm selection approaches. The first is the pairwise classification version of SATzilla [50], which won the ICON Challenge. The second is the automatic algorithm selection method AutoFolio system [26]. AutoFolio uses the flexible FlexFolio framework [14], which combines several different algorithm selection methods, and searches for the best suited algorithm selection approach (and its hyperparameter settings) for a given algorithm selection scenario using algorithm configuration [17] via the model-based configurator SMAC [18]. For example, AutoFolio determines whether classification or a regression approach will perform better and in case of classification, how to set the hyperparameters of a random forest classifier [9]. As shown by [26], AutoFolio often chooses the pair-wise classification approach of SATzilla, but it is more robust than other algorithm selection approaches since it can also switch to other approaches if necessary. As a result, AutoFolio established state-of-the-art performance on several different domains in the algorithm selection library [5] and performed best on two out of three tracks of the ICON challenge."}, {"heading": "4 Benchmarking of TTP Algorithms", "text": "An important step toward the creation of algorithm portfolios is the conduct of experiments where one determines the performance of algorithms on the available problem instances. To this end, we introduce in this section the originally defined set of TTP instances, and we outline the experimental setup and the results.\n1http://challenge.icon-fet.eu/"}, {"heading": "4.1 Introduction of Benchmark Instances", "text": "For our investigations, we use the set of TTP instances defined by Polyakovskiy et al [41].2 In these instances, the two components of the problem have been balanced in such a way that the near-optimal solution of one sub-problem does not dominate over the optimal solution of another sub-problem.\nThe characteristics of the original 9,720 instances vary widely. We outline the most important ones in the following:3\n\u2022 The instances have 51 to 85,900 cities, based on instances from the TSPlib by [43];\n\u2022 For each TSP instance, there are three different types of knapsack problems: uncorrelated, uncorrelated with similar weights and bounded strongly correlated types, where the last type has been shown to be difficult for different types of knapsack solvers by [29, 41];\n\u2022 For each TSP and KP combination, the number of items per city (referred to as an item factor) is F \u2208 {1, 3, 5, 10}. Note that all cities of a single TTP instance have the same number of items, except for the first city (which is also the last city), where no items are available;\n\u2022 For each instance, the renting rate R that links both subproblems is chosen in such a way that at least one TTP solution with an objective value of zero exists;\n\u2022 Lastly, for each TTP configuration of the above-mentioned characteristics 10 different instances exist where the knapsack capacity is varied.\nThe sheer size of this original TTP instance set makes comprehensive experimental evaluations computationally expensive and the high-dimensional space of characteristics further complicates comparisons. For this reason, different researchers have selected different subsets, with each subset having (intentionally or unintentionally) a particular bias. For example, only the very first article by Polyakovskiy et al [41] considered the entire set of 9720 instances. Mei, Li, and Yao [30] focused on 30 larger instances with 11849 to 33810 cities. Faulkner et al [12] covered a wider range using 72 instances with 195 to 85900 cities, and Wagner [47] used 108 instances with 51 to 1000 cities. Based on these individual and incomplete glimpses at algorithm performance, it is difficult to grasp the full picture."}, {"heading": "4.2 Benchmark Results", "text": "In order to establish a reliable data set for the subsequent analyses, we run existing TTP algorithms on all 9720 instances. This has the benefit of creating\n2As available at the TTP project page: http://cs.adelaide.edu.au/~optlog/research/ ttp.php\n3For a more detailed description, we refer the interested reader to [41, 42].\nthe complete picture using the same hardware and other conditions for the experiments.\nAs code for most of the TTP algorithms outlined in Section 2.3 is available online, we can consider a wide range of different algorithms, which include constructive heuristics, hill-climbers, problem-agnostic and problem-specific heuristics, single-solution heuristics and cooperative coevolutionary approaches. In the following, we briefly list (in chronological order) the 21 considered algorithms with their original names (and, where applicable, abbreviated names in parentheses):\n\u2022 [41]: SH, RLS, EA\n\u2022 [7]: DH\n\u2022 [31]: MATLS\n\u2022 [12]: S1, S2, S3, S4, S5, C1, C2, C3, C4, C5, C6\n\u2022 [52]: CS2SA\n\u2022 [47]: MMASls3 (M3), MMASls4 (M4), MMASls3boost (M3B), MMASls4boost (M4B).\nWe run all algorithms for a maximum of 10 minutes per instance. All computations are performed on machines with Intel Xeon E5430 CPUs (2.66GHz) and Java 1.8.\nAs the encountered objective scores cover several orders of magnitude, as well as positive and negative scores, we assess the quality of the algorithms using the following approach. For each TTP instance, we determine the best and the worst objective scores; these two values define the boundaries of the interval of observed objective scores for each instance. We then map actual scores from this interval linearly to [0, 1], where the highest score is equivalent to 1. In case an algorithm did not produce a score for a particular instance, e.g. due to a time-out or crash, we assign to it the score of -1.\nWe report a performance overview across all 9720 instances in Figure 3. At first sight, it appears that many algorithms perform comparably, since 19 of 21 algorithms achieve an average scaled performance of > 0.8. However, this is largely because DH and SH often performed rather poorly and thus skew the scale. Figure 4 zooms into the remaining 19 algorithms\u2019 performance, showing that, on average, S5 and the algorithms starting with C and M perform well.\nThese figures provide only a first indication, since the instance set they are based on contains many small instances (which biases this performance comparison such that algorithms performing well on small instances are favored), and some algorithms do not finish (which reduces their average scores). In particular, the following algorithms did not always produce solutions given the time limit: MATLS (204 unsolved instances), M3 (721), M4 (720), M3B (1342), M4B (1316), and CS2SA (6284). To the best of our knowledge, the first five of these suffer from long subroutines that keep them from stopping after the\ntime limit is reached, while CS2SA crashes on these instances. We also note that the algorithms starting with M dominate on smaller instances, and that S5 performs well on larger instances. More detailed analyses will be presented later.\nWe have made the performance data set publicly available: CSV format at http://cs.adelaide.edu.au/~optlog/research/ttp.php."}, {"heading": "5 Instance Features for the TTP", "text": "For our approach to algorithm portfolio generation, we need in addition to algorithm performance data (see previous section) also data that describes problem instances. In total we consider 55 TTP instance features. Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339]. These fall into seven groups, which we outline in the following, with the number of features in parentheses.\nDistance Features (11). These are based on summary statistics of the edge cost distribution. Here, we consider the lowest, highest, mean and median edge costs, as well as the proportion of edges with distances shorter than the mean distance, the fraction of distinct distances (i.e. different distance levels), and\nthe standard deviation of the distance matrix. Also, we consider the mode frequency, quantity and mean. Finally, we used the expected tour length for a random tour, given by the sum of all edge costs multiplied by 2/(N-1).\nMode Features (1). As an additional feature characterizing the distribution of edge costs, we also include its number of modes as a feature.\nCluster Features (6). GDBSCAN is used for clustering where reachability distances of 0.01, 0.05 and 0.1 are chosen. Derived features are the number of clusters and the mean distances to the cluster centroids for each clusterization.\nNearest Neighbor Distance Features (6). Uniformity of an instance is reflected by the minimum, maximum, mean, median, standard deviation and the coefficient of variation of the normalized nearest-neighbor distances (nnd) of each node.\nCentroid Features (5). The x- and y-coordinates of the instance centroid together with the minimum, mean and maximum distance of the nodes from the centroid.\nMST Features (11). Statistics which characterize the depth and the distances of the minimum spanning tree (MST). The minimum, mean, median, maximum and the standard deviation of the depth and distance values of the MST as well as the sum of the distances on the MST (which we normalize by diving it by the sum of all pairwise distances).\nAngle Features (5). This feature group comprises statistics of the distribution of angles between a node and its two nearest neighbor nodes: the minimum, mean, median, maximum and standard deviation.\nConvex Hull Features (2). The area of the convex hull of the instance reflects the \u201cspread\u201d of the instance in the plane. Additionally, we compute the fraction of nodes which define the convex hull.\nIn addition to these known TSP-specific features, we considered the following eight features. The first four are features of the knapsack component and they include the capacity of the knapsack, the knapsack type, the total number of items, and the number of items per city. Next, we consider the number of cities as a feature. Lastly, as TTP-specific features we have the renting ratio, the minimum travel speed, and the maximum travel speed. It is important to note that these last eight do not require any processing, as they are part of the definition of the instances.\nFuture investigations should include additional TTP-specific features. A first step towards this has been taken by Polyakovskiy and Neumann [40] with their concept of \u201cprofitable/unprofitable\u201d items for the special case when tours\nare fixed. Since we are not considering this restriction, their concept does not easily carry over."}, {"heading": "6 Experimental Study of Algorithm Selection", "text": "on TTP\nWe follow the approach of [14] by studying the performance of different, wellknown algorithm selection approaches. In detail, we ran FlexFolio4 (using Python 2.7.6 and sklearn 0.14.1) with various approaches which simulate the behavior of existing systems: SATzilla\u201909 (regression approach), SATzilla\u201911 (cost-sensitive pairwise-classification), ISAC (clustering) and 3S (direct classification with k = 32 nearest neighbors). Since we do not optimize the runtime of our TTP algorithms but an objective score, we cannot directly apply (pre-solving) algorithm schedules for TTP and hence, we focus on the classical algorithm selection approach by selecting one algorithm per instance.\nTo this end, we created an algorithm selection benchmark scenario in the format of the algorithm selection library (ASlib; [5]) from our TTP benchmark data.5 It includes the performance values for all our algorithms and the instance features for each instance. Furthermore, our ASlib scenario also provides the splits for a 10-fold cross validation to obtain an unbiased performance estimate (i.e., the instances are randomly split into 10 equally sized sets and in each iteration, one of the splits is used as a test set to validate our algorithm selection procedure and all others are used to train the algorithm selector; the overall performance of an algorithm selection procedure is then the average performance across all iterations). With all this information saved, our ASlib scenario allows for hardware-independent reproducibility of our experiments.\nTable 1 shows the performance of the different approaches on TTP. Our baseline is the performance of the single best algorithm, i.e., always using the\n4http://www.ml4aad.org/flexfolio/ 5Our TTP-2016 ASlib scenario is in the \u201cnot verified\u201d branch of http://www.aslib.net.\nalgorithm that performs best across all instances. The single best algorithm with a performance of 0.958 is S5 (as previously shown in Section 4). Due to the scaling of the objective scores, the best possible score on each instance is 1. Therefore, the theoretical optimal performance of a perfect algorithm selection procedure (so-called oracle or virtual-best solver) is also 1 here, i.e., the algorithm selector would always select best performing algorithm for each instances.\nThe best-performing algorithm selection approaches are the ones of SATzilla\u201911 and 3S with a nearly optimal performance of above 0.99. This closes the performance gap between the single best solver and the oracle by almost 90%. SATzilla\u201909 and ISAC also outperformed the single best. One possible reason for the good performance of algorithm selection for this application is the large instance set. Most other instance sets studied in algorithm selection only consist of hundreds or a few thousand instances (cf. ASlib by [5]). The resulting availability of more data makes the machine learning problem easier.\nWe also ran the fully automated AutoFolio approach for a day of wallclock time on 4 cores to automatically determine a good portfolio. Since the best FlexFolio approach (i.e., SATzilla\u201911 ) already performed well, AutoFolio was only able to improve performance further by a very small margin in the 4th decimal. In fact, AutoFolio also decided for the SATzilla\u201911 approach and only changed the hyperparameters of the underlying random forest slightly."}, {"heading": "7 Analysis of Algorithm Complementarity with", "text": "Shapley Values\nA necessary requirement for algorithm selection to perform well is that the portfolio of algorithms is complementary on the used instances. A first indicator for the complementarity of the portfolio is the difference between the single best algorithm and the oralce performance (see Section 6). This difference of 0.041 in our benchmarks appears to be small, but we have to remember that 19 of 21 algorithms achieved average scaled objective scores of > 0.8.\nFigure 5 shows the performance correlation across instances (based on Spearman\u2019s rank coefficients) between all pairs of algorithms. This figure shows that the algorithms form clusters that reflect their historical development. For example, C* and S* fall into one cluster (all use the same fast packing heuristic), the ant-colony approaches M* form one cluster, and early hill-climbers EA with RLS in another one. The algorithms CS2SA, SH, DH and MATLS are complementary to all other algorithms. We note that this analysis only provides insights about similarity of algorithms, but it is not a sufficient indicator about the applicability of algorithm selection since one of the algorithms could still dominate all other algorithms.\nAnother approach of assessing complementarity of algorithms is the marginal contribution to the oracle performance [51], i.e., how much the oracle performance of an existing portfolio will be improved by adding a new algorithm to\nit. This approach has the disadvantage of being strongly dependent on a fixed portfolio. To get a broader overview of an algorithm\u2019s contribution, an extension of the marginal contribution analysis consists of using Shapley values [13], i.e., the marginal contribution of an algorithm to any subset of the algorithm portfolio.\nFigure 6 shows the ranking of the different algorithms based on their stan-\ndalone performance (i.e., running only one algorithm on all instances), the Shapley values, and the marginal contribution to the oracle performance.6 S5 has the highest standalone performance and the highest Shapley value, but surprisingly it is only ranked third on the marginal contribution. Hence, S5 is a very important algorithm as a standalone and in smaller portfolios, but does not contribute as much on top of the combination of the other algorithms as algorithm CS2SA (which has the lowest standalone performance and Shapley value but the highest marginal contribution). This demonstrates that CS2SA, despite its poor average performance, performs very well on a subset of instances \u2013 and reliably enough so for the algorithm portfolio to exploit. Once the algorithmic issues of CS2SA are fixed we expect to see significantly better average performances by this algorithm. The ant-colony approaches M* do not perform too well on average, but they can make useful contributions to algorithm portfolios since they perform very well on small instances. Lastly, on the low end of the performance spectrum are two constructive heuristics DH/SH and the two uninformed hill-climbers RLS/EA. While they performed reasonably well when they were introduced, they have since then been outclassed by more informed approaches. But even the slightly informed approaches S1/S2/S3/S4, which use good TSP tours and TTP-specific packing operators, are not competitive anymore when being compared to more recent developments.\nIn summary, we can see that well-performing algorithm portfolios include problem-solving approaches of different complexities in order to deal with the wide range of existing TTP instances: there are swarm-intelligence approaches for small instances, memetic and multi-step heuristics for mid-size instances, and the large instances the relatively simple restart approach S5 is a good choice."}, {"heading": "8 Analysis of Feature Importance and Their Cal-", "text": "culation Time\nAs the calculation of instance features forms an important step in the application of algorithm portfolios, we review the necessary calculation times in the following. In addition, we analyze which features are the most important ones for algorithm selection and we investigate how subsets of features impact computation time and portfolio performance.\nTo date, the established computation budget for TTP benchmarking is 10 minutes single-core CPU time per instance. For algorithm selection to be effective, and if only a single algorithm is to be run once, the calculation time of the instance features should not take up a large proportion of these 10 minutes. However, several of the features are computationally costly, for example, because of complete distance matrix has to be generated, or because a clustering algorithm needs to be run. As a consequence, the calculation time of all 55 features for a single given instance ranges from a few seconds for the smallest\n6The shown scores in Figure 6 are sums across all instances, plus an offset of \u201c+1\u201d to accommodate negative performance averages.\nTTP instances to hours for the largest ones; for example, the calculations for the eil51* instances take about 2 seconds, those for the pla7397* instances are approaching 10 minutes, and the calculations for the pla33810* instances even exceed 20 hours.\nTo investigate which features are actually needed, as this has the potential to save significant amounts of time that then becomes available for the optimizaiton algorithm, we compute for each of the 55 features the average Gini importance [9] across all pair-wise random forests models. The results are shown in Figure 7, revealing that only a small portion of the TTP features actually matter. Interestingly, these are mostly basic knapsack features:\n1. CAPACITYOFKNAPSACK: the KP feature defining the knapsack capacity.\n2. RENTINGRATIO: the TTP feature that connects the KP and the TSP.\n3. NUMBEROFITEMS: the KP feature stating the total number of available items.\n4. KNAPSACKDATATYPE: the KP feature stating the knapsack type.\n5. DIMENSION: the TSP feature stating the total number of cities.\nAs the previous portfolio investigations in Section 6 were done using all 55 features, we now repeat the algorithm selection experiment using only the most important features and our best-performing approach from SATzilla\u201911. The resulting performances are 0.977, 0.980, 0.986, 0.988, and 0.992 (going from\nusing only the most important feature to using the five most important ones). The results show that with just a small subset of the features we can achieve a portfolio performance comparable to the best one from Section 6 (0.993).\nRemarkably, all five features are given in the instance file\u2019s header, and are thus \u201ccomputable\u201d in constant time. Out of these five, CAPACITYOFKNAPSACK and RENTINGRATIO need to be defined by the instance. If NUMBEROFITEMS or DIMENSION are missing, then they can be computed by going through the instance file once and counting the total numbers of items or cities. KNAPSACKDATATYPE is not a computable feature, as it is a parameter that was used in the generation of the instance; for our considered instance set, however, this field is always provided. Even if it is not considered, for example when using only the three most important features, we still achieve a performance of 0.986, which is a substantial improvement over the baseline approach S5 (0.959).\nFrom these experiments we see that the exploitation of immediately available instance features results in a substantial average performance increase that is comparable to a significantly more time-consuming one that requires the calculation of all 55 features.\nThe question now is whether we can learn even more from these outcomes. The visualization and interpretation of the raw outputs of the portfolios is challenging due to the large numbers of instances, features, and randomized algorithms. Nevertheless, let us briefly consider as an example the portfolio when only the feature CAPACITYOFKNAPSACK is used. Let us sort the 9720 instances according to their CAPACITYOFKNAPSACK values, and let us now consider the list of algorithms as they are selected. As expected, this list contains long (but not always continuous) stretches where the same algorithms are selected; in particular, the M* algortihms dominate on the tiny instances, and S5 dominates on mid-sized and large instances. If we do the same ordering for the algorithm selector that uses the five most important features, then the overall picture changes slightly. On the smallest \u223c3000 instances, different complex algorithms dominate, and for the tiniest these are often the M* approaches which tend to generate the longest tours. The largest \u223c3000 instances are typically assigned to either CS2SA (a fast implementation of search operators) or S5 (resampling solutions), which are two very different approaches."}, {"heading": "9 Concluding Remarks", "text": "In this article, we presented the first study of algorithm portfolios for the TTP. We first studied the performance of 21 existing TTP algorithms on the full original set of 9720 TTP instances created by Polyakovskiy et al [41] and defined 55 instance features for TTP. Then, we studied various different approaches for the resulting algorithm selection problem, showing very substantial improvements over the single best algorithm and closing the gap between it and an omniscient oracle by 90%. Finally, we studied which algorithms contribute most to the portfolio, finding that the algorithms with best average performance (e.g.\nthe complex ones C3\u2013C6 and MATLS, and the swarm-intelligence approaches that start with M) were quite important for the portfolio because of their performance on small and mid-sized TTP instances. Interestingly, the relatively simple heuristic S5 continues to dominate in particular on the large TTP instances and thus is one of the most important contributors to well-performing portfolios. Despite this general trend, the algorithm with the worst average performance, CS2SA, added substantial benefit on top of all other algorithms. An analysis of the feature importance revealed that the values for the five most important features can be extracted from the instance definition in constant time. The resulting portfolio that uses only this subset has a performance comparable to the one that uses all 55 features that can take hours to compute.\nIn future work, we aim to study which features make TTP instances hard for which algorithm and why, and whether we can identify a smaller representative subset of TTP instances to speed up future benchmarking studies."}], "references": [{"title": "Chained Lin-Kernighan for large traveling salesman problems", "author": ["D Applegate", "WJ Cook", "A Rohe"], "venue": "Journal on Computing", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2003}, {"title": "Or-library: Distributing test problems by electronic mail", "author": ["EJ Beasley"], "venue": "Journal of the Operational Research Society", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1990}, {"title": "Ant colony optimization techniques for the vehicle routing problem. Advanced Engineering Informatics", "author": ["JE Bell", "PR McMullen"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Handbook of Satisfiability", "author": ["A Biere", "M Heule", "H van Maaren", "T Walsh"], "venue": "Frontiers in Artificial Intelligence and Applications,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "2016) ASlib: A benchmark library for algorithm selection", "author": ["B Bischl", "P Kerschke", "L Kotthoff", "M Lindauer", "Y Malitsky", "A Frech\u00e9tte", "H Hoos", "F Hutter", "K Leyton-Brown", "K Tierney", "J Vanschoren"], "venue": "Artificial Intelligence", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "The travelling thief problem: The first step in the transition from theoretical problems to realistic problems", "author": ["MR Bonyadi", "Z Michalewicz", "L Barone"], "venue": "Congress on Evolutionary Computation,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Socially inspired algorithms for the TTP", "author": ["MR Bonyadi", "Z Michalewicz", "MR Przybylek", "A Wierzbicki"], "venue": "Genetic and Evolutionary Computation Conference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Evolutionary computation for multicomponent problems: opportunities and future directions", "author": ["MR Bonyadi", "Z Michalewicz", "F Neumann", "M Wagner"], "venue": "CoRR abs/1606.06818,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Fast heuristics for the multiple traveling thieves problem", "author": ["S Chand", "M Wagner"], "venue": "Genetic and Evolutionary Computation Conference (GECCO),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "The truck dispatching problem", "author": ["GB Dantzig", "JH Ramser"], "venue": "Management Science", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1959}, {"title": "Approximate approaches to the traveling thief problem", "author": ["H Faulkner", "S Polyakovskiy", "T Schultz", "M Wagner"], "venue": "Genetic and Evolutionary Computation Conference,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Using the Shapley Value to Analyze Algorithm Portfolios", "author": ["A Frechette", "L Kotthoff", "T Rahwan", "H Hoos", "K Leyton-Brown", "T Michalak"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "claspfolio 2: Advances in algorithm selection for answer set programming", "author": ["H Hoos", "M Lindauer", "T Schaub"], "venue": "Theory and Practice of Logic Programming", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "aspeed: Solver scheduling via answer set programming", "author": ["H Hoos", "R Kaminski", "M Lindauer", "T Schaub"], "venue": "Theory and Practice of Logic Programming", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "An economic approach to hard computational problems", "author": ["B Huberman", "R Lukose", "T Hogg"], "venue": "Science", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "ParamILS: An automatic algorithm configuration framework", "author": ["F Hutter", "H Hoos", "K Leyton-Brown", "T St\u00fctzle"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Sequential model-based optimization for general algorithm configuration", "author": ["F Hutter", "H Hoos", "K Leyton-Brown"], "venue": "Coello C (ed) Proceedings of the Fifth International Conference on Learning and Intelligent Optimization (LION\u201911), Springer-Verlag, Lecture Notes in Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Algorithm runtime prediction: Methods and evaluation", "author": ["F Hutter", "L Xu", "H Hoos", "K Leyton-Brown"], "venue": "Artificial Intelligence", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "ISAC - instancespecific algorithm configuration", "author": ["S Kadioglu", "Y Malitsky", "M Sellmann", "K Tierney"], "venue": "Proceedings of the Nineteenth European Conference on Artificial Intelligence", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Algorithm selection and scheduling", "author": ["S Kadioglu", "Y Malitsky", "A Sabharwal", "H Samulowitz", "M Sellmann"], "venue": "In: Lee J (ed) Proceedings of the Seventeenth International Conference on Principles and Practice of Constraint Programming (CP\u201911),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Algorithm selection for combinatorial search problems: A survey", "author": ["L Kotthoff"], "venue": "AI Magazine", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "The vehicle routing problem: An overview of exact and approximate algorithms", "author": ["G Laporte"], "venue": "European Journal of Operational Research", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1992}, {"title": "Learning the empirical hardness of optimization problems: The case of combinatorial auctions. In: Hentenryck PV (ed) Principles and Practice of Constraint Programming - CP", "author": ["K Leyton-Brown", "E Nudelman", "Y Shoham"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Autofolio: An automatically configured algorithm selector", "author": ["M Lindauer", "H Hoos", "F Hutter", "T Schaub"], "venue": "Journal of Artificial Intelligence", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Algorithm portfolios based on cost-sensitive hierarchical clustering", "author": ["Y Malitsky", "A Sabharwal", "H Samulowitz", "M Sellmann"], "venue": "Rossi F (ed) Proceedings of the 23rd International Joint Conference on Artificial Intelligence", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "A multi-engine approach to answerset programming", "author": ["M Maratea", "L Pulina", "F Ricca"], "venue": "Theory and Practice of Logic Programming", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Dynamic programming and strong bounds for the 0-1 knapsack problem", "author": ["S Martello", "D Pisinger", "P Toth"], "venue": "Management Science", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1999}, {"title": "Improving efficiency of heuristics for the large scale traveling thief problem", "author": ["Y Mei", "X Li", "X Yao"], "venue": "Simulated Evolution and Learning, LNCS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}, {"title": "On investigation of interdependence between sub-problems of the TTP", "author": ["Y Mei", "X Li", "X Yao"], "venue": "Soft Computing", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2014}, {"title": "Local search and the traveling salesman problem: A featurebased characterization of problem hardness", "author": ["O Mersmann", "B Bischl", "J Bossek", "H Trautmann", "M Wagner", "F Neumann"], "venue": "Learning and Intelligent Optimization: 6th International Conference (LION", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2012}, {"title": "A novel feature-based approach to characterize algorithm performance for the traveling salesperson problem", "author": ["O Mersmann", "B Bischl", "H Trautmann", "M Wagner", "J Bossek", "F Neumann"], "venue": "Annals of Mathematics and Artificial Intelligence", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2013}, {"title": "Ubiquity symposium: Evolutionary computation and the processes of life: The emperor is naked: Evolutionary algorithms for real-world applications", "author": ["Z Michalewicz"], "venue": "Ubiquity", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2012}, {"title": "How to solve it - modern heuristics: second, revised and extended edition (2", "author": ["Z Michalewicz", "DB Fogel"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2004}, {"title": "Algorithm selection as a collaborative filtering problem", "author": ["M M\u0131s\u0131r", "M Sebag"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2013}, {"title": "Ant colony optimisation and the traveling salesperson problem: Hardness, features and parameter settings", "author": ["S Nallaperuma", "M Wagner", "F Neumann"], "venue": "Proceedings of the 15th Annual Conference Companion on Genetic and Evolutionary Computation,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2013}, {"title": "A feature-based comparison of local search and the christofides algorithm for the travelling salesperson problem", "author": ["S Nallaperuma", "M Wagner", "F Neumann", "B Bischl", "O Mersmann", "H Trautmann"], "venue": "Proceedings of the Twelfth Workshop on Foundations of Genetic Algorithms XII,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2013}, {"title": "Parameter prediction based on features of evolved instances for ant colony optimization and the traveling salesperson problem. In: Parallel Problem Solving from Nature", "author": ["S Nallaperuma", "M Wagner", "F Neumann"], "venue": "PPSN XIII, LNCS,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2014}, {"title": "Packing while traveling: Mixed integer programming for a class of nonlinear knapsack problems", "author": ["S Polyakovskiy", "F Neumann"], "venue": "Integration of AI and OR Techniques in Constraint Programming, LNCS,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2015}, {"title": "A comprehensive benchmark set and heuristics for the traveling thief problem", "author": ["S Polyakovskiy", "MR Bonyadi", "M Wagner", "Z Michalewicz", "F Neumann"], "venue": "Genetic and Evolutionary Computation Conference,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "TSPLIB - A Traveling Salesman Problem Library", "author": ["G Reinelt"], "venue": "ORSA Journal on Computing", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 1991}, {"title": "The algorithm selection problem", "author": ["J Rice"], "venue": "Advances in Computers", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1976}, {"title": "Ant colony optimization for real-world vehicle routing problems", "author": ["AE Rizzoli", "R Montemanni", "E Lucibello", "LM Gambardella"], "venue": "Swarm Intelligence", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2007}, {"title": "MAX-MIN ant system", "author": ["T St\u00fctzle", "HH Hoos"], "venue": "Journal of Future Generation Computer Systems", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2000}, {"title": "Stealing items more efficiently with ants: a swarm intelligence approach to the traveling thief problem", "author": ["M Wagner"], "venue": "Tenth International Conference on Swarm Intelligence (ANTS),", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2016}, {"title": "Why is optimization difficult? In: Chiong R (ed) Nature-Inspired Algorithms for Optimisation", "author": ["T Weise", "M Zapf", "R Chiong", "AJ Nebro"], "venue": null, "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2009}, {"title": "SATzilla: Portfoliobased algorithm selection for SAT", "author": ["L Xu", "F Hutter", "H Hoos", "K Leyton-Brown"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2008}, {"title": "Hydra-MIP: Automated algorithm configuration and selection for mixed integer programming. In: RCRA workshop on Experimental Evaluation of Algorithms for Solving Problems with Combinatorial Explosion", "author": ["L Xu", "F Hutter", "H Hoos", "K Leyton-Brown"], "venue": null, "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2011}, {"title": "Evaluating component solver contributions to portfolio-based algorithm selectors", "author": ["L Xu", "F Hutter", "H Hoos", "K Leyton-Brown"], "venue": "Proceedings of the Fifteenth International Conference on Theory and Applications of Satisfiability Testing (SAT\u201912),", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2012}, {"title": "Population-based vs. single-solution heuristics for the travelling thief problem", "author": ["ME Yafrani", "B Ahiod"], "venue": "Genetic and Evolutionary Computation Conference (GECCO),", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2016}], "referenceMentions": [{"referenceID": 5, "context": "The academic traveling thief problem (TTP) [6] is quickly gaining attention as an NP-hard combinatorial optimization problem that combines two wellknown subproblems: the traveling salesperson problem (TSP) and the knapsack problem (KP).", "startOffset": 43, "endOffset": 46}, {"referenceID": 7, "context": "The motivation for the TTP is to allow the systematic investigation of interactions between two hard component problems, to gain insights that eventually help solve real-world problems more efficiently [8].", "startOffset": 202, "endOffset": 205}, {"referenceID": 40, "context": "To exploit this complementarity of existing algorithms, here we study the applicability of algorithm selection [44] to this problem.", "startOffset": 111, "endOffset": 115}, {"referenceID": 38, "context": "\u2022 We analyze the performance of 21 TTP algorithms on the original set of 9720 instances created by Polyakovskiy, Bonyadi, Wagner, Michalewicz, and Neumann [41] (Section 4);", "startOffset": 155, "endOffset": 159}, {"referenceID": 5, "context": "The traveling thief problem (TTP) [6] is a recent attempt to provide an abstraction of multicomponent problems with dependency among components.", "startOffset": 34, "endOffset": 37}, {"referenceID": 44, "context": "For example, Weise, Zapf, Chiong, and Nebro [48] discussed premature convergence, ruggedness, causality, deceptiveness, neutrality, epistasis, and robustness, which make optimization problems hard to solve.", "startOffset": 44, "endOffset": 48}, {"referenceID": 32, "context": "Michalewicz and Fogel [35] discussed a few different reasons behind the hardness of real-world problems, including problem size, presence of noise, multi-objectivity, and presence of constraints.", "startOffset": 22, "endOffset": 26}, {"referenceID": 39, "context": "Most of these features have been captured in different optimization benchmark sets, such as TSPlib [43], MIPlib [22] and OR-library [2].", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "Most of these features have been captured in different optimization benchmark sets, such as TSPlib [43], MIPlib [22] and OR-library [2].", "startOffset": 132, "endOffset": 135}, {"referenceID": 31, "context": "Michalewicz [34] identified several reasons for this mismatch between academia and the real world.", "startOffset": 12, "endOffset": 16}, {"referenceID": 7, "context": "In order to guide the community towards this increasingly important aspect of real-world optimization [8], the traveling thief problem was introduced [6] in order to illustrate the complexities that arise by having multiple interacting components.", "startOffset": 102, "endOffset": 105}, {"referenceID": 5, "context": "In order to guide the community towards this increasingly important aspect of real-world optimization [8], the traveling thief problem was introduced [6] in order to illustrate the complexities that arise by having multiple interacting components.", "startOffset": 150, "endOffset": 153}, {"referenceID": 2, "context": "A related problem is the vehicle routing problem (VRP, for an overview see [3, 45]).", "startOffset": 75, "endOffset": 82}, {"referenceID": 41, "context": "A related problem is the vehicle routing problem (VRP, for an overview see [3, 45]).", "startOffset": 75, "endOffset": 82}, {"referenceID": 9, "context": "The VRP is concerned with finding optimal routes for a fleet of vehicles delivering or collecting items from different locations [11, 24].", "startOffset": 129, "endOffset": 137}, {"referenceID": 21, "context": "The VRP is concerned with finding optimal routes for a fleet of vehicles delivering or collecting items from different locations [11, 24].", "startOffset": 129, "endOffset": 137}, {"referenceID": 5, "context": "For discussions on how the TTP differs from the VRP, we refer the interested reader to [6, 7].", "startOffset": 87, "endOffset": 93}, {"referenceID": 6, "context": "For discussions on how the TTP differs from the VRP, we refer the interested reader to [6, 7].", "startOffset": 87, "endOffset": 93}, {"referenceID": 8, "context": "Chand and Wagner [10] discussed the shortcomings of the current formulation and presented a relaxed version of the problem which allows multiple thieves to travel across different cities with the aim of maximizing the group\u2019s collective profit.", "startOffset": 17, "endOffset": 21}, {"referenceID": 38, "context": "We use the definition of the TTP by [41].", "startOffset": 36, "endOffset": 40}, {"referenceID": 38, "context": "We provide a brief example in the following (see Figure 1); full details are given by Polyakovskiy et al [41].", "startOffset": 105, "endOffset": 109}, {"referenceID": 38, "context": "Figure 1: Illustrative example for a TTP instance (taken from [41], with permission)", "startOffset": 62, "endOffset": 66}, {"referenceID": 5, "context": "In the original article in which the TTP is defined, Bonyadi et al [6] used exhaustive enumeration on instances with four cities and six items in order to demonstrate the interconnected components.", "startOffset": 67, "endOffset": 70}, {"referenceID": 38, "context": "A year later, Polyakovskiy et al [41] created a set of instances with up to almost 100,000 cities and 1,000,000 items, rendering exhaustive enumeration no longer feasible.", "startOffset": 33, "endOffset": 37}, {"referenceID": 38, "context": "It were also Polyakovskiy et al [41] who proposed the first set of heuristics for solving the TTP.", "startOffset": 32, "endOffset": 36}, {"referenceID": 0, "context": "The first step involved generating a good TSP tour by using the classical Chained Lin-Kernighan heuristic [1].", "startOffset": 106, "endOffset": 109}, {"referenceID": 6, "context": "Bonyadi et al [7] experimentally investigated the interdependency between the TSP and knapsack components of the TTP.", "startOffset": 14, "endOffset": 17}, {"referenceID": 38, "context": "DH is again a two-phased approach similar to SH from Polyakovskiy et al [41], and it also ignores any dependencies between the TSP and Knapsack components.", "startOffset": 72, "endOffset": 76}, {"referenceID": 28, "context": "Mei, Li, and Yao [31] also investigated the interdependencies between the TSP and knapsack components.", "startOffset": 17, "endOffset": 21}, {"referenceID": 6, "context": "Both works by Bonyadi et al [7] and Mei et al [31] highlight the importance of considering interdependencies between the TTP components as this will allow for the generation of more competitive solutions.", "startOffset": 28, "endOffset": 31}, {"referenceID": 28, "context": "Both works by Bonyadi et al [7] and Mei et al [31] highlight the importance of considering interdependencies between the TTP components as this will allow for the generation of more competitive solutions.", "startOffset": 46, "endOffset": 50}, {"referenceID": 10, "context": "Faulkner, Polyakovskiy, Schultz, and Wagner [12] investigated multiple operators and did a comprehensive comparison with existing approaches.", "startOffset": 44, "endOffset": 48}, {"referenceID": 43, "context": "Wagner [47] recently investigated the use of swarm intelligence approaches with the so-called Max-Min Ant System (MMAS, by St\u00fctzle and Hoos [46]).", "startOffset": 7, "endOffset": 11}, {"referenceID": 42, "context": "Wagner [47] recently investigated the use of swarm intelligence approaches with the so-called Max-Min Ant System (MMAS, by St\u00fctzle and Hoos [46]).", "startOffset": 140, "endOffset": 144}, {"referenceID": 48, "context": "Yafrani and Ahiod [52] studied and compared different approaches for solving the TTP from a metaheuristics perspective.", "startOffset": 18, "endOffset": 22}, {"referenceID": 37, "context": "One of the reasons for this appears to be the fact that even when the tour is kept fixed, packing is NP-hard [40].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "One way to exploit this complementarity of the algorithms is to use algorithm selection [16, 44] to select a well-performing algorithm on a per-instance base.", "startOffset": 88, "endOffset": 96}, {"referenceID": 40, "context": "One way to exploit this complementarity of the algorithms is to use algorithm selection [16, 44] to select a well-performing algorithm on a per-instance base.", "startOffset": 88, "endOffset": 96}, {"referenceID": 3, "context": "One of the first successful algorithm selection procedures for satisfiability problems [4] was SATzilla [49].", "startOffset": 87, "endOffset": 90}, {"referenceID": 45, "context": "One of the first successful algorithm selection procedures for satisfiability problems [4] was SATzilla [49].", "startOffset": 104, "endOffset": 108}, {"referenceID": 17, "context": "It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each.", "startOffset": 73, "endOffset": 81}, {"referenceID": 22, "context": "It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each.", "startOffset": 73, "endOffset": 81}, {"referenceID": 13, "context": "It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each.", "startOffset": 244, "endOffset": 256}, {"referenceID": 19, "context": "It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each.", "startOffset": 244, "endOffset": 256}, {"referenceID": 45, "context": "It mainly used two concepts: (i) Learning an empirical performance model [19, 25] to predict the performance of an algorithm for a given instance and select the algorithm with the best predicted performance; and (ii) Static algorithm schedules [15, 21, 49], which run a sequence of algorithms with a runtime budget each.", "startOffset": 244, "endOffset": 256}, {"referenceID": 25, "context": ", ME-ASP by [28], 3S by [21], and CSHC by [27]) that directly learn a mapping from instance features to good algorithms;", "startOffset": 12, "endOffset": 16}, {"referenceID": 19, "context": ", ME-ASP by [28], 3S by [21], and CSHC by [27]) that directly learn a mapping from instance features to good algorithms;", "startOffset": 24, "endOffset": 28}, {"referenceID": 24, "context": ", ME-ASP by [28], 3S by [21], and CSHC by [27]) that directly learn a mapping from instance features to good algorithms;", "startOffset": 42, "endOffset": 46}, {"referenceID": 46, "context": ", the more recent version of SATzilla [50]), which learns a binary classifier for each pair of algorithms, weighting each training instance by the performance difference between the two algorithms (and thereby emphasizing instances for which the two algorithms\u2019 performances differ a lot);", "startOffset": 38, "endOffset": 42}, {"referenceID": 18, "context": ", ISAC by [20]) to partition instances in the feature space into homogeneous subsets and then select the bestperforming algorithm of the cluster a new instance is closest to; and", "startOffset": 10, "endOffset": 14}, {"referenceID": 33, "context": ", [36]) to recommend an algorithm given only partial training data.", "startOffset": 2, "endOffset": 6}, {"referenceID": 20, "context": "For a thorough overview on algorithm selection procedures, we refer the interested reader to [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 46, "context": "The first is the pairwise classification version of SATzilla [50], which won the ICON Challenge.", "startOffset": 61, "endOffset": 65}, {"referenceID": 23, "context": "The second is the automatic algorithm selection method AutoFolio system [26].", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "AutoFolio uses the flexible FlexFolio framework [14], which combines several different algorithm selection methods, and searches for the best suited algorithm selection approach (and its hyperparameter settings) for a given algorithm selection scenario using algorithm configuration [17] via the model-based configurator SMAC [18].", "startOffset": 48, "endOffset": 52}, {"referenceID": 15, "context": "AutoFolio uses the flexible FlexFolio framework [14], which combines several different algorithm selection methods, and searches for the best suited algorithm selection approach (and its hyperparameter settings) for a given algorithm selection scenario using algorithm configuration [17] via the model-based configurator SMAC [18].", "startOffset": 283, "endOffset": 287}, {"referenceID": 16, "context": "AutoFolio uses the flexible FlexFolio framework [14], which combines several different algorithm selection methods, and searches for the best suited algorithm selection approach (and its hyperparameter settings) for a given algorithm selection scenario using algorithm configuration [17] via the model-based configurator SMAC [18].", "startOffset": 326, "endOffset": 330}, {"referenceID": 23, "context": "As shown by [26], AutoFolio often chooses the pair-wise classification approach of SATzilla, but it is more robust than other algorithm selection approaches since it can also switch to other approaches if necessary.", "startOffset": 12, "endOffset": 16}, {"referenceID": 4, "context": "As a result, AutoFolio established state-of-the-art performance on several different domains in the algorithm selection library [5] and performed best on two out of three tracks of the ICON challenge.", "startOffset": 128, "endOffset": 131}, {"referenceID": 38, "context": "For our investigations, we use the set of TTP instances defined by Polyakovskiy et al [41].", "startOffset": 86, "endOffset": 90}, {"referenceID": 39, "context": "\u2022 The instances have 51 to 85,900 cities, based on instances from the TSPlib by [43];", "startOffset": 80, "endOffset": 84}, {"referenceID": 26, "context": "\u2022 For each TSP instance, there are three different types of knapsack problems: uncorrelated, uncorrelated with similar weights and bounded strongly correlated types, where the last type has been shown to be difficult for different types of knapsack solvers by [29, 41];", "startOffset": 260, "endOffset": 268}, {"referenceID": 38, "context": "\u2022 For each TSP instance, there are three different types of knapsack problems: uncorrelated, uncorrelated with similar weights and bounded strongly correlated types, where the last type has been shown to be difficult for different types of knapsack solvers by [29, 41];", "startOffset": 260, "endOffset": 268}, {"referenceID": 38, "context": "For example, only the very first article by Polyakovskiy et al [41] considered the entire set of 9720 instances.", "startOffset": 63, "endOffset": 67}, {"referenceID": 27, "context": "Mei, Li, and Yao [30] focused on 30 larger instances with 11849 to 33810 cities.", "startOffset": 17, "endOffset": 21}, {"referenceID": 10, "context": "Faulkner et al [12] covered a wider range using 72 instances with 195 to 85900 cities, and Wagner [47] used 108 instances with 51 to 1000 cities.", "startOffset": 15, "endOffset": 19}, {"referenceID": 43, "context": "Faulkner et al [12] covered a wider range using 72 instances with 195 to 85900 cities, and Wagner [47] used 108 instances with 51 to 1000 cities.", "startOffset": 98, "endOffset": 102}, {"referenceID": 38, "context": "php 3For a more detailed description, we refer the interested reader to [41, 42].", "startOffset": 72, "endOffset": 80}, {"referenceID": 38, "context": "\u2022 [41]: SH, RLS, EA", "startOffset": 2, "endOffset": 6}, {"referenceID": 6, "context": "\u2022 [7]: DH", "startOffset": 2, "endOffset": 5}, {"referenceID": 28, "context": "\u2022 [31]: MATLS", "startOffset": 2, "endOffset": 6}, {"referenceID": 10, "context": "\u2022 [12]: S1, S2, S3, S4, S5, C1, C2, C3, C4, C5, C6", "startOffset": 2, "endOffset": 6}, {"referenceID": 48, "context": "\u2022 [52]: CS2SA", "startOffset": 2, "endOffset": 6}, {"referenceID": 43, "context": "\u2022 [47]: MMASls3 (M3), MMASls4 (M4), MMASls3boost (M3B), MMASls4boost (M4B).", "startOffset": 2, "endOffset": 6}, {"referenceID": 0, "context": "We then map actual scores from this interval linearly to [0, 1], where the highest score is equivalent to 1.", "startOffset": 57, "endOffset": 63}, {"referenceID": 29, "context": "Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339].", "startOffset": 59, "endOffset": 74}, {"referenceID": 30, "context": "Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339].", "startOffset": 59, "endOffset": 74}, {"referenceID": 34, "context": "Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339].", "startOffset": 59, "endOffset": 74}, {"referenceID": 35, "context": "Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339].", "startOffset": 59, "endOffset": 74}, {"referenceID": 36, "context": "Of these, 47 are TSP features from previous studies on TSP [32, 33, 37\u201339].", "startOffset": 59, "endOffset": 74}, {"referenceID": 37, "context": "A first step towards this has been taken by Polyakovskiy and Neumann [40] with their concept of \u201cprofitable/unprofitable\u201d items for the special case when tours", "startOffset": 69, "endOffset": 73}, {"referenceID": 12, "context": "We follow the approach of [14] by studying the performance of different, wellknown algorithm selection approaches.", "startOffset": 26, "endOffset": 30}, {"referenceID": 4, "context": "To this end, we created an algorithm selection benchmark scenario in the format of the algorithm selection library (ASlib; [5]) from our TTP benchmark data.", "startOffset": 123, "endOffset": 126}, {"referenceID": 4, "context": "ASlib by [5]).", "startOffset": 9, "endOffset": 12}, {"referenceID": 47, "context": "Another approach of assessing complementarity of algorithms is the marginal contribution to the oracle performance [51], i.", "startOffset": 115, "endOffset": 119}, {"referenceID": 11, "context": "To get a broader overview of an algorithm\u2019s contribution, an extension of the marginal contribution analysis consists of using Shapley values [13], i.", "startOffset": 142, "endOffset": 146}, {"referenceID": 38, "context": "We first studied the performance of 21 existing TTP algorithms on the full original set of 9720 TTP instances created by Polyakovskiy et al [41] and defined 55 instance features for TTP.", "startOffset": 140, "endOffset": 144}], "year": 2016, "abstractText": "Many real-world problems are composed of several interacting components. In order to facilitate research on such interactions, the Traveling Thief Problem (TTP) was created in 2013 as the combination of two wellunderstood combinatorial optimization problems. With this article, we contribute in four ways. First, we create a comprehensive dataset that comprises the performance data of 21 TTP algorithms on the full original set of 9720 TTP instances. Second, we define 55 characteristics for all TPP instances that can be used to select the best algorithm on a per-instance basis. Third, we use these algorithms and features to construct the first algorithm portfolios for TTP, clearly outperforming the single best algorithm. Finally, we study which algorithms contribute most to this portfolio.", "creator": "LaTeX with hyperref package"}}}