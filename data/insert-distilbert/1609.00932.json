{"id": "1609.00932", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2016", "title": "Spectral Learning of Dynamic Systems from Nonequilibrium Data", "abstract": "observable generalized operator models ( ooms ) and related models are even one of now the most important and powerful tools for modeling and analyzing stochastic systems. they can exactly describe dynamics of finite - rank systems, and be efficiently learned from data by executing moment based compression algorithms. arguably almost all oom learning algorithms are developed immediately based on the assumption of equilibrium data which is very difficult to guarantee in real life, especially for emotionally complex processes with large time scales. elaborated in this paper, we derive a nonequilibrium learning algorithm for ooms, which dismisses this assumption and can effectively extract the equilibrium dynamics of a system from nonequilibrium observation data. in addition, we propose binless ooms for the application of nonequilibrium learning to continuous - valued systems. in ease comparison with the other ooms with continuous observations, binless ooms can achieve consistent estimation from nonequilibrium data with only linear computational complexity.", "histories": [["v1", "Sun, 4 Sep 2016 13:31:36 GMT  (576kb,D)", "http://arxiv.org/abs/1609.00932v1", "Accepted by 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Original title: Learning Observable Operator Models from Nonequilibrium Data"], ["v2", "Tue, 20 Jun 2017 20:30:33 GMT  (984kb,D)", "http://arxiv.org/abs/1609.00932v2", null]], "COMMENTS": "Accepted by 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Original title: Learning Observable Operator Models from Nonequilibrium Data", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.SY math.PR physics.data-an", "authors": ["hao wu", "frank no\u00e9"], "accepted": true, "id": "1609.00932"}, "pdf": {"name": "1609.00932.pdf", "metadata": {"source": "CRF", "title": "Spectral learning of dynamic systems from nonequilibrium data\u2217", "authors": ["Hao Wu"], "emails": ["hao.wu@fu-berlin.de", "frank.noe@fu-berlin.de", "Folding@home"], "sections": [{"heading": "1 Introduction", "text": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data. These models are largely similar and can be unified in a general learning framework of multiplicity automata, or equivalently sequential systems [9, 10]. We focus in this paper only on stochastic systems without control inputs. Because all of above mentioned models can be expressed in the form of OOMs for such systems, we will refer to them as OOMs below.\nIn contrast with the other commonly used models such as Markov models [11], Langevin models [12], traditional hidden Markov models (HMMs) [13] and recurrent neural networks [14], OOMs can exactly characterize the dynamics of a stochastic system without any a priori knowledge except the assumption of finite dynamical rank (i.e., the rank of Hankel matrix) [10], and the parameter estimation can be efficiently performed by the method of moments for discrete-valued systems without solving any intractable inverse or optimization problem.\nA major challenge for OOM based dynamical modeling approaches arises from nonequilibrium data. In most literature, the observation data are assumed to be equilibrium so that the expected values of observables associated with OOM learning can be reliably computed by simple averaging. However, the equilibrium assumption can be approximately satisfied only if most of observation data are generated after the system has mixed. In many practical situations, especially where metastable physical or chemical processes are involved, this assumption can be severely violated due to the\n\u2217Original title: Learning Observable Operator Models from Nonequilibrium Data\n29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n60 9.\n00 93\n2v 1\n[ cs\n.L G\n] 4\nS ep\nlimit of experimental technique or computational capacity. A notable example is the distributed computing project Folding@home [15], which explores protein folding processes that occur on the timescales of microseconds to milliseconds based on molecular dynamics simulations on the order of nanoseconds in length. In such a case, it is still unknown how to obtain promising estimates of OOMs from nonequilibrium data consisting of short trajectories. In [16], a hybrid estimation algorithm was proposed to improve OOM learning of large-time-scale processes by using both dynamic and static data, but it still requires assumption of equilibrium data. One solution to reduce the statistical bias caused by nonequilibrium data is to discard the observation data generated before the system reaches steady state, which is a common trick in applied statistics [17]. Obviously, this way suffers from substantial information loss and is infeasible when observation trajectories are shorter than mixing times. Another possible way would be to learn OOMs by likelihood-based estimation instead of moment-based estimation, but there is no effective maximum likelihood or Bayesian estimator of OOMs until now. The maximum pseudo-likelihood estimator of OOMs proposed in [18] demands high computational cost and its consistency is yet unverified.\nAnother difficulty for OOM based modeling approaches is learning with continuous data, where density estimation problems are involved. The density estimation can be performed by parametric methods such as the fuzzy interpolation [19] and the kernel density estimation [8]. But these methods would reduce the flexibility of OOMs for dynamical modeling because of their limited expressive capacity. Recently, a kernel embedding based OOM learning algorithm was proposed to cope with continuous data [20], which avoids explicit density estimation and learns OOMs in a nonparametric manner. However, the kernel embedding usually yields a very large computational complexity, which greatly limits practical applications of this algorithm to real-world systems.\nThe purpose of this paper is to address the challenge of nonequilibrium learning of OOMs due to the requirements of analysis of both discrete- and continuous-valued systems. We provide a modified moment-based method for discrete-valued stochastic systems which allows us to consistently estimate the equilibrium dynamics from nonequilibrium data, and then extend this method to OOM learning with continuous observations in a binless manner. In comparison with the existing learning methods for continuous OOMs, the proposed binless method does not rely on any density estimator, and can achieve consistent estimation with linear computational complexity in data size even if the equilibrium assumption of observations does not hold. Moreover, some numerical experiments are provided to demonstrate the capability of the proposed nonequilibrium learning methods."}, {"heading": "2 Preliminaries", "text": ""}, {"heading": "2.1 Notation", "text": "In this paper, we use P to denote probability distribution for discrete random variables and probability density for continuous random variables. The indicator function of event e is denoted by 1e and the dirac delta function centered at x is denoted by \u03b4x (\u00b7). For a given process {at}, we write the subsequence (ak, ak+1, . . . , ak\u2032) as ak:k\u2032 , and E\u221e[at] , limt\u2192\u221e E[at] means the expected value of at in equilibrium if the limit exists. In addition, the convergence in probability is denoted by p\u2192."}, {"heading": "2.2 Observable operator models", "text": "Anm-dimensional observable operator model (OOM) with observation spaceO can be represented by a tupleM = (\u03c9, {\u039e(x)}x\u2208O,\u03c3), which consists of an initial state vector \u03c9 \u2208 R1\u00d7m, an evaluation vector \u03c3 \u2208 Rm\u00d71 and an observable operator matrix \u039e(x) \u2208 Rm\u00d7m associated to each element x \u2208 O.M defines a stochastic process {xt} in O as\nP (x1:t|M) = \u03c9\u039e(x1:t)\u03c3 (1) with \u039e(x1:t) , \u039e(x1) . . .\u039e(xt). It is interesting to note that (1) can also be represented in the form of state space models as\n\u03c9t = (\u03c9t\u22121\u039e(xt)\u03c3) \u22121 \u03c9t\u22121\u039e(xt)\nP (xt+1|\u03c9t) = \u03c9t\u039e(xt+1)\u03c3 (2) Here the internal state \u03c9t in (2) is a sufficient statistics the process at each time t, which contains all the information needed to predict the future observations and is initialized by \u03c90 = \u03c9. It is clear that two OOMsM andM\u2032 are equivalent if and only if P (x1:t|M) \u2261 P (x1:t|M\u2032).\nAlgorithm 1 General procedure for OOM learning INPUT: Observation trajectories generated by a stochastic process {xt} in O OUTPUT: M\u0302 = (\u03c9\u0302, {\u039e\u0302(x)}x\u2208O, \u03c3\u0302) PARAMETER: m: dimension of the OOM. D1, D2: numbers of feature functions. L: order of\nfeature functions. 1: Construct feature functions \u03c61 = (\u03d51,1, . . . , \u03d51,D1) > and \u03c62 = (\u03d52,1, . . . , \u03d52,D2) >, where\neach \u03d5i,j is a mapping from OL to R and D1, D2 \u2265 m. 2: Approximate\n\u03c6\u03041 , E\u221e [\u03c61(xt+1:t+L)] , \u03c6\u03042 , E\u221e [\u03c62(xt+1:t+L)] (6) C1,2 , E\u221e [ \u03c61(xt\u2212L:t\u22121)\u03c62(xt:t+L\u22121) >] (7) C1,3 (x) , E\u221e [ 1xt=x \u00b7 \u03c61(xt\u2212L:t\u22121)\u03c62(xt+1:t+L)> ] , \u2200x \u2208 O (8)\nby their empirical means \u02c6\u0304\u03c61, \u02c6\u0304\u03c62, C\u03021,2 and C\u03021,3 (x) over observation data.\n3: Choose matrix F1 \u2208 RD1\u00d7m,F2 \u2208 RD2\u00d7m such that F>1 C\u03021,2F2 is invertible. 4: Compute\n\u03c3\u0302 = ( F>1 C\u03021,2F2 )\u22121 F>1 \u02c6\u0304\u03c61 (9)\n\u039e\u0302(x) = ( F>1 C\u03021,2F2 )\u22121 F>1 C\u03021,3(x)F2, \u2200x \u2208 O (10)\n\u03c9\u0302 = \u02c6\u0304\u03c6>2 F2 (11)"}, {"heading": "3 Learning OOMs using moments", "text": ""}, {"heading": "3.1 Algorithm", "text": "Here and hereafter, we only consider the case that the observation space O is a finite set. (Learning with continuous observations will be discussed in Section 5.) A large number of largely similar methods have been developed to learn OOMs from discrete data, and the generic learning procedure of these methods is summarized in Algorithm 1 by omitting details of algorithm implementation and parameter choice. For convenience of description and analysis, we specify in this paper the formula for calculating \u02c6\u0304\u03c61, \u02c6\u0304\u03c62, C\u03021,2 and C\u03021,3 (x) in Line 2 of Algorithm 1 as follows:\n\u02c6\u0304\u03c61 , 1\nN N\u2211 n=1 \u03c61(~s 1 n), \u02c6\u0304\u03c62 , 1 N N\u2211 n=1 \u03c61(~s 2 n) (3)\nC\u03021,2 , 1\nN N\u2211 n=1 \u03c61(~s 1 n)\u03c62(~s 2 n) > (4)\nC\u03021,3 (x) , 1\nN N\u2211 n=1 1s2n=x\u03c61(~s 1 n)\u03c62(~s 3 n) >, \u2200x \u2208 O (5)\nHere {(~s 1n , s2n, ~s 3n)}Ns=1 is the collection of all subsequences of length (2L+ 1) appearing in observation data (N = T \u2212 2L for a single observation trajectory of length T ). For instance, if an observation subsequence xt\u2212L:t+L is denoted by (~s 1n , s 2 n, ~s 3 n) with some n, then ~s 1 n = xt\u2212L:t\u22121 and ~s 3n = xt+1:t+L represents the prefix and suffix of xt\u2212L:t+L of length L, s 2 n = xt is the intermediate observation value, and ~s 2n = xt:t+L\u22121 is an \u201cintermediate part\u201d of the subsequence of length L starting from time t (see Fig. 1 for a graphical illustration).\nAlgorithm 1 is much more efficient than the commonly used likelihood-based learning algorithms and does not suffer from local optima issues. In addition, and more importantly, this algorithm can be shown to be consistent if the observation data are equilibrium so that empirical estimates of \u03c6\u03041, \u03c6\u03042, C1,2 and C1,3 (x) converge to their true values with increasing data size (see, e.g., [3, 8, 10] for\nrelated works). However, the consistent estimation of OOMs with nonequilibrium data is still an unsolved problem."}, {"heading": "3.2 Theoretical analysis", "text": "We now analyze statistical properties of the OOM learning algorithm without the assumption of equilibrium observations. Before stating our main result, some assumptions on observation data are listed as follows: Assumption 1. The observation data consists of I independent trajectories of length T produced by a stochastic process {xt}, and the data size tends to infinity with (i) I \u2192\u221e and T = T0 or (ii) T \u2192\u221e and I = I0. Assumption 2. {xt} is driven by an m-dimensional OOMM = (\u03c9, {\u039e(x)}x\u2208O,\u03c3), and satisfies\n1\nT \u2032 T \u2032\u2211 t=1 ft p\u2192 E\u221e [ft] = E\u221e [ft|x1:k] (12)\nas T \u2032 \u2192\u221e for all k, l, x1:k and ft = f (xt:t+l\u22121). Assumption 3. The limit of F>1 C\u03021,2F2 \u2208 Rm\u00d7m is invertible.\nNotice that we do not assume stationarity of processes as previously done in the literature, and Assumption 2 only states the asymptotic stationarity of {xt}. Therefore, estimates of \u03c6\u03041, \u03c6\u03042, C1,2 and C1,3 (x) obtained from empirical means may not be consistent if lengths of observation trajectories are kept at finite values (i.e., Case (i) in Assumption 1). Assumption 3 ensures that the limit of M\u0302 given by Algorithm 1 is well defined. Based on the above assumptions, we have the following theorem concerning the consistency of the OOM learning algorithm (see Appendix A.1 for proof):\nTheorem 1. Under Assumptions 1-3, the estimated OOM M\u0302 = (\u03c9\u0302, {\u039e\u0302(x)}x\u2208O, \u03c3\u0302) given by Algorithm 1 satisfies\n\u03c3\u0302 p\u2192 \u03c3eq, \u039e\u0302 (x) p\u2192 \u039eeq(x), \u2200x \u2208 O (13) whereMeq = (\u03c9eq, {\u039eeq(x)}x\u2208O,\u03c3eq) is an m-dimensional OOM equivalent toM.\nThis theorem is central in this paper, and implies that the moment based learning algorithm can achieve consistent estimation of all parameters of OOMs except initial state vectors even for nonequilibrium data. (\u03c9\u0302\np\u2192 \u03c9eq does not hold in most cases except when {xt} is stationary. See Appendix A.1 for details). It can be further generalized according to requirements in more complicated situations where, for example, the data set consists of both several long trajectories and many short trajectories or trajectories are not independent from each other. The following two generalizations are particularly worth mentioning due to their importance for practical applications:\n1. The i-th observation trajectories is generated by OOM M = (\u03c9i, {\u039e(x)}x\u2208O,\u03c3) for i = 1, . . . , I (i.e., observations are generated with multiple different initial conditions), and the mean value of {\u03c9i}Ii=1 tends to a constant in probability for I \u2192\u221e.\n2. Matrices F1 and F2 are not constant but given by the singular value decomposition of C\u03021,2 as in the spectral learning algorithm [21, 7, 22].\nWe show in Appendix A that the above two generalizations do not affect the consistency of \u039e\u0302 (x) and \u03c3\u0302. In fact, it can be proved by similar proofs that all theoretical conclusions in this paper hold for the two generalizations."}, {"heading": "4 Nonequilibrium learning of OOMs", "text": "According to the discussion in the previous section, the only remaining problem for learning OOMs from nonequilibrium data is how to estimate initial state vectors. Considering that the purpose of dynamical modeling is to predict properties of the system in equilibrium in many situations, here we only approximate equilibrium values of internal states of OOMs (see below) rather than actual initial state vectors, because the latter depend on initial conditions of data generation and the former are more physically interesting for analysis of equilibrium dynamics.\nGiven parameters ofMeq in Theorem 1, the equilibrium value of the internal state is defined as\n\u03c9\u0304eq = lim t\u2192\u221e\n\u03c9eq\u039eeq(O)t (14)\nif the limit exists, where \u039eeq(O) = \u2211 x\u2208O \u039eeq(x). Then the equilibrium dynamics of {xt} can be characterized as lim t\u2192\u221e P (xt+1:t+k = z1:k) = \u03c9\u0304eq\u039eeq(z1:k)\u03c3eq (15) From (14) and (15), we have{ \u03c9\u0304eq\u039eeq(O) = limt\u2192\u221e \u03c9eq\u039eeq(O)t+1 = \u03c9\u0304eq \u03c9\u0304eq\u03c3eq = limt\u2192\u221e \u2211 x\u2208O P (xt+1 = x) = 1 (16)\nThis motivates the following nonequilibrium learning algorithm for OOMs: Perform Algorithm 1 to get \u039e\u0302 (x) and \u03c3\u0302 and calculate \u03c9\u0302 by a quandratic programming problem\n\u03c9\u0302 = arg min w\u2208{w|w\u03c3\u0302=1} \u2225\u2225\u2225w\u039e\u0302(O)\u2212w\u2225\u2225\u22252 (17) (See Appendix A.4 for a closed-form expression of the solution to (17).)\nThe existence and uniqueness of \u03c9\u0304eq are shown in Appendix A.4, which yield the following theorem:\nTheorem 2. Under Assumptions 1-3, the estimated OOM M\u0302 provided by the nonequilibrium learning algorithm satisfies P ( x1:l = z1:l|M\u0302 ) p\u2192 lim t\u2192\u221e P (xt+1:t+l = z1:l) (18)\nfor all l and z1:l. Remark 1. Some OOM learning algorithms for equilibrium data [23] also calculate \u03c9\u0302 based on (16), where feature functions \u03c61,\u03c62 and matrices F1,F2 are specifically constructed so that \u03c9\u0302\u039e\u0302(O) = \u03c9\u0302, \u03c9\u0302\u03c3\u0302 = 1 can be exactly satisfied even if the statistical noise is considered. In comparison with these algorithms, the nonequilibrium learning algorithm does not require such a restriction, and is shown to be applicable to nonequilibrium data."}, {"heading": "5 Binless learning of OOMs", "text": "We now consider how to learn OOMs from continuous data. In the case of a real observation space O \u2282 Rd,M defines probability densities of paths of {xt} as in (1), and C1,3 (x) becomes a matrixvalued density function C1,3 (x) = 1dxE\u221e [ 1xt\u2208dx \u00b7 \u03c61(xt\u2212L:t\u22121)\u03c62(xt+1:t+L)> ] with general feature functions \u03c61,\u03c62 on Rd, which is difficult to approximate for each x \u2208 O. The existing continuous learning algorithms overcome this problem by using parametric methods [19, 8] or kernel embeddings [20], but none of them can achieve consistent estimation with a low computational complexity like discrete learning algorithms even for equilibrium data.\nHere we present a binless strategy to perform dynamical modeling with continuous and nonequilibrium data, which simply views each available observation as a discrete probability atom in the observation space and approximates C1,3 (x) by\nC\u03021,3 (x) = 1\nN N\u2211 n=1 \u03b4s2n (x)\u03c61(~s 1 n)\u03c62(~s 3 n) > (19)\ninstead of (5). Using this strategy, a binless OOM M\u0302 = (\u03c9\u0302, {\u039e\u0302(x)}x\u2208O, \u03c3\u0302) with the observable operator matrix \u039e\u0302(x) = \u2211 z\u2208X W\u0302z\u03b4z (x) supported on X = {s2n}Nn=1 can be constructed by\nAlgorithm 2 Nonequilibrium learning procedure of Binless OOMs INPUT: Observation trajectories generated by a stochastic process {xt} in O \u2282 Rd OUTPUT: Binless OOM M\u0302 = (\u03c9\u0302, {\u039e\u0302(x)}x\u2208O, \u03c3\u0302)\n1: Construct feature functions \u03c61 : RLd 7\u2192 RD1 and \u03c62 : RLd 7\u2192 RD2 with D1, D2 \u2265 m. 2: Calculate \u03c6\u03041, \u03c6\u03042,C1,2,C1,3 (x) by (3), (4) and (19). 3: Choose matrix F1 \u2208 RD1\u00d7m,F2 \u2208 RD2\u00d7m such that F>1 C\u03021,2F2 is invertible. 4: Compute \u03c3\u0302, \u03c9\u0302 and \u039e\u0302(x) = \u2211 z\u2208X W\u0302z\u03b4z (x) by (9), (17) and\nW\u0302s2n = 1\nN\n( F>1 C\u03021,2F2 )\u22121 F>1 \u03c61(~s 1 n)\u03c62(~s 3 n) >F2 (21)\nwhere \u039e\u0302(O) = \u00b4 dx \u039e\u0302(x) = \u2211 z\u2208X W\u0302z .\nnonequilibrium learning with computational complexity O (N) as in Algorithm 2, where feature functions can be selected as splines, radial basis functions or other commonly used activation functions for single-layer neural networks in practice in order to digest adequate dynamical information from observation data. Note the binless strategy can be applied to more general cases where observations are strings, graphs or other structured variables, and is very similar to that used in Monte Carlo integration or nonparametric maximum likelihood estimation [24]. Although we cannot use the binless OOM to evaluate path probability densities of {xt} as in (18), the equilibrium expectation of any observable gt = g (xt+1:t+r) of {xt} can be approximated as\nE\u221e [gt] \u2248 E [ gt|M\u0302 ] =\n\u2211 x1:r\u2208X r g (x1:r) \u03c9\u0302W\u0302z1 . . .W\u0302zr \u03c3\u0302 (20)\nBy adding a technical assumption, our previous result on consistency of nonequilibrium learning of OOMs can extended to the binless case as follows (see Appendix A.4 for proof): Assumption 4. The observation space O is a closed set in Rd and feature functions \u03c61,\u03c62 are bounded on OL. Theorem 3. Under Assumptions 1-4, the binless OOM provided by Algorithm 2 satisfies\nE [ g (x1:r) |M\u0302 ] p\u2192 E\u221e [g (xt+1:t+r)] (22)\n(i) for all continuous functions g : Or 7\u2192 R.\n(ii) for all bounded and Borel measurable functions g : Or 7\u2192 R, if there exist constants \u03be\u0304 and \u03be so that \u2016\u039e (x)\u2016 \u2264 \u03be\u0304 and limt\u2192\u221e P (xt+1:t+r = z1:r) \u2265 \u03be for all x \u2208 O and z1:r \u2208 Or.\nNote that we do not assume the observed dynamics coincides with a parametric model defined by feature functions in Theorem 3. This theorem shows that binless OOMs allow us to consistently and efficiently extract equilibrium histograms, principle components, time-cross correlations, etc., of a dynamical systems from nonequilibrium data, which is important especially for thermodynamic and kinetic analysis in computational physics and chemistry. Remark 2. The computational complexity of (20) is O (Nr), which is unaffordable for large data sets if r > 1. In this paper, we focus on estimation of specific observables in the forms of E\u221e [a (xt)] and E\u221e [a (xt) b (xt+k)] by binless OOMs, which only require O (N) time. The efficient estimation of E\u221e [g (xt+1:t+r)] for general g with is outside the scope of this paper and will be dealt with separately in another paper."}, {"heading": "6 Applications", "text": "In this section, we evaluate our algorithms on two stochastic systems driven by Brownian dynamics and the molecular dynamics of alanine dipeptide, and compare them to several alternatives. The detailed settings of simulations and algorithms are provided in Appendix B.\nBrownian dynamics Fig. 2(a) shows the potential function of a one-dimensional diffusion process {xt} on [0, 2] driven by Brownian dynamics, where the state space is discretized into two clusters I, II. It is obvious that the equilibrium probability of finding xt in I is smaller than that of xt \u2208 II, because the potential well contained in II is deeper than the other one. In this example, all simulations are performed by starting from a uniform distribution on [0, 0.2], which imples that simulations are highly nonequilibrium and it is difficult to accurately estimate the equilibrium probabilities ProbI = E\u221e [1xt\u2208I] and ProbII = E\u221e [1xt\u2208II] of I and II from the simulation data. We first utilize the traditional OOM learning, expectation\u2013maximization based HMM learning and the proposed nonequilibrium learning algorithm of OOMs to estimate ProbI and ProbII by assuming that we only know which cluster the xt is in for each time t, i.e., the observation space O = {I, II}. Fig. 2(b) summarizes the estimation results with different simulation lengths. It can be seen that estimates given by the traditional OOM and the HMM are far away from true values even for the largest simulation length T = 1000. In addition, it is worth pointing out that estimates given by the traditional OOM are very similar to empirical means of 1xt\u2208I and 1xt\u2208II because the OOM learning algorithm is essentially a moment matching algorithm and the estimated moments cannot be corrected in the traditional learning algorithm. (See Fig. 2(c). Note that the empirical estimates of ProbI and ProbII are the same for discrete and continuous observations.) In contrast to previous methods, the nonequilibrium learning based OOM effectively reduce the statistical bias in the nonequilibrium data, and achieves statistically correct estimation at T = 300.\nFigs. 2(c) and 2(d) plot estimates of the equilibrium state distribution given by the empirical estimator, HMM and binless OOM using nonequilibrium learning under the condition that the value of xt is exactly known and O = [0, 2], where the empirical estimator calculates statistics through averaging over all observations. The observation model of the HMM is constructed based on 100 uniform bins on the state space, where samples within the same bin are assumed to be independent. With such a fine discretization, the performance of the HMM is improved, but estimation errors of the HMM for short trajectory lengths are still large. Here, the proposed binless OOM significantly outperform the other methods, and its estimates are very close to true values even for extremely small short trajectories.\nFig. 3 provides an example of applying binless OOMs to kinetic analysis. The goal of this experiment is to perform the time-structure based independent component (TIC) analysis [25] of a two-dimensional Brownian dynamics based on nonequilibrium observation data. Fig. 3(b) displays the estimation errors of the coefficient vector of the first TIC obtained from different learning models, which also demonstrates the superiority of the proposed binless OOM method.\nAlanine dipeptide Alanine dipeptide is a small molecule which consists of two alanine amino acid units, and its configuration can be described by two backbone dihedral angles. Fig. 4(a) shows the potential profile of the alanine dipeptide with respect to the two angles, which contains five metastable states. We perform multiple short molecular dynamics simulations starting from the metastable state IV, where each simulation length is 10ns, and utilizes different methods to approximate the stationary distribution of the five metastable states. As shown in Fig. 4(b), the proposed binless OOM yields lower estimation error compared to each of the alternatives."}, {"heading": "7 Conclusion", "text": "In this paper, we investigated the statistical properties of the general OOM learning procedure for nonequilibrium data, and developed a general framework for learning dynamical models from nonequilibrium data. Under this framework, the existing learning approaches of OOMs and the other related models can be conveniently and efficiently applied to nonequilibrium (discrete or continuous) data by using the nonequilibrium learning technique and the binless learning technique. The main ideas of the two techniques are to correct the model parameters by the algebraic constraints under the equilibrium condition and to handle continuous observations in a binless manner. Interesting directions of future research include analysis of approximation error of nonequilibrium learning with finite data size and applications of nonequilibrium learning to controlled systems."}, {"heading": "A Proofs", "text": "A.1 Proof of Theorem 1\nFor convenience, here we define\n\u03c9\u2032(T ) = 1\nT \u2212 2L \u03c9 T\u22122L\u2211 t=1 \u039e(O)t\u22121\nand G\u03c3 = \u2211 z1:L \u03c62(z1:L)\u03c3 >\u039e(z1:L) > (A.1)\nPart (1) We first show the theorem in the case of T = T0 and I \u2192\u221e. Let\nG\u03c9 = \u2211 z1:L \u03c61(z1:L)\u03c9 \u2032(T0)\u039e(z1:L) (A.2)\nSince I \u2192\u221e, we have \u02c6\u0304\u03c61 p\u2192 E [ \u02c6\u0304\u03c61 ] = G\u03c9\u03c3\n\u02c6\u0304\u03c6>2 p\u2192 E [ \u02c6\u0304\u03c6>2 ] = \u03c9\u2032(T0)G > \u03c3\nC\u03021,2 p\u2192 E [ C\u03021,2 ] = G\u03c9G > \u03c3\nC\u03021,3 (x) p\u2192 E [ C\u03021,2 (x) ] = G\u03c9\u039e(x)G > \u03c3\nIn addition, we can obtain from Assumption 3 that rank (G\u03c9) = rank ( F>1 G\u03c9 ) = rank (G\u03c3) = rank ( G>\u03c3F2 ) = m\nTherefore, M\u0302 satisfies\n\u03c9\u0302 = \u02c6\u0304\u03c6>2 F2 p\u2192 \u03c9\u2032(T0)G\u03c3F2\n\u039e\u0302 (x) = ( F>1 C\u03021,2F2 )\u22121 F>1 C\u03021,3 (x) F2\np\u2192 ( F>1 G\u03c9G > \u03c3F2 )\u22121 F>1 G\u03c9\u039e(x)G > \u03c3F2\n= \u039eeq(x) \u03c3\u0302 = ( F>1 C\u03021,2F2 )\u22121 F>1 \u02c6\u0304\u03c61\np\u2192 ( F>1 G\u03c9G > \u03c3F2 )\u22121 F>1 G\u03c9\u03c3\n= \u03c3eq\nwhereMeq = (\u03c9eq, {\u039eeq(x)}x\u2208O,\u03c3eq) is an OOM which equivalent toM as\n\u03c9eq = \u03c9G > \u03c3F2 \u039eeq(x) = ( G>\u03c3F2 )\u22121 \u039e(x) ( G>\u03c3F2 ) \u03c3eq = ( G>\u03c3F2 )\u22121 \u03c3 (A.3)\nNote \u03c9\u0302 p\u2192 \u03c9eq does not hold in general cases.\nPart (2) We now consider the case of I = I0 and T \u2192\u221e. According to Assumption 2, the limit\nC\u03021,2 p\u2192 E\u221e [ \u03c61(xt\u2212L:t\u22121)\u03c62(xt:t+L\u22121) >] = lim\nk\u2192\u221e \u2211 z1:L \u03c61(z1:L)\u03c9\u039e (O) k \u039e(z1:L)G > \u03c3\nexists. Then\n\u02c6\u0304\u03c61 p\u2192 E\u221e [\u03c61(xt\u2212L:t\u22121)] = G\u03c9\u03c3\n\u02c6\u0304\u03c6>2 p\u2192 E\u221e [ \u03c62(xt:t+L\u22121) >] = lim k\u2192\u221e \u03c9\u039e (O)k G>\u03c3F2\nC\u03021,2 p\u2192 E\u221e [ C\u03021,2 ] = G\u03c9G > \u03c3\nC\u03021,3 (x) p\u2192 E\u221e [ C\u03021,2 (x) ] = G\u03c9\u039e(x)G > \u03c3\nwith G\u03c9 = lim\nk\u2192\u221e \u2211 z1:L \u03c61(z1:L)\u03c9\u039e (O) k \u039e(z1:L) (A.4)\nand we can get rank (G\u03c9) = rank ( F>1 G\u03c9 ) = rank (G\u03c3) = rank ( G>\u03c3F2 ) = m\naccording to Assumption 3.\nTherefore,\n\u03c9\u0302 p\u2192 lim k\u2192\u221e \u03c9\u039e (O)k G>\u03c3F2\n\u039e\u0302 (x) p\u2192 \u039eeq(x)\n\u03c3\u0302 p\u2192 \u03c3eq\nwhereMeq = (\u03c9eq, {\u039eeq(x)}x\u2208O,\u03c3eq) has the same definition as in (A.3). Note \u03c9\u0302 p\u2192 \u03c9eq does not hold in general cases where \u03c9\u039e (O) 6= \u03c9.\nA.2 Asymptotic correctness of nonequilibrium learning with different initial states\nIf the i-th observation trajectories is generated by OOMM = (\u03c9i, {\u039e(x)}x\u2208O,\u03c3) for i = 1, . . . , I , and\n\u03c9\u2032\u2032 =\n{ 1 I \u2211I i=1 \u03c9\ni, for T \u2192\u221e plimI\u2192\u221e 1 I \u2211I i=1 \u03c9 i, for I \u2192\u221e\nthe asymptotic correctness can also shown as in Appendix A.1 by setting G\u03c9 = \u2211 z1:L \u03c61(z1:L)\u03c9 \u2032(T0)\u039e(z1:L)\nwith\n\u03c9\u2032(T ) = 1\nT \u2212 2L \u03c9\u2032\u2032 T\u22122L\u2211 t=1 \u039e(O)t\u22121\nfor I \u2192\u221e, and G\u03c9 = lim\nk\u2192\u221e \u2211 z1:L \u03c61(z1:L)\u03c9 \u2032\u2032\u039e (O)k \u039e(z1:L)\nfor T \u2192\u221e.\nA.3 Asymptotic correctness of nonequilibrium learning based on the spectral learning algorithm\nIn the spectral learning algorithm, matrices F1 and F2 are given by singular value decomposition (SVD) as\nF1 = U, F2 = V\u03a3 \u22121 (A.5)\nwhere \u03a3 \u2208 Rm\u00d7m is a diagonal matrix contains the top m singular values of C\u03021,2, and U and V consist of the corresponding m left and right singular vectors of C\u03021,2. In this appendix, we will prove the following theorem:\nTheorem 4. Under Assumptions 1 and 2, for the estimated OOM M\u0302 = (\u03c9\u0302, {\u039e\u0302(x)}x\u2208O, \u03c3\u0302) given by Algorithm 1 with F1,F2 defined by (A.5), there exists an OOMM\u2032 = (\u03c9\u2032, {\u039e\u2032(x)}x\u2208O,\u03c3\u2032) which is equivalent to M\u0302 and satisfies\n\u039e\u2032(x) p\u2192 \u039eeq(x), \u2200x \u2208 O (A.6)\n\u03c3\u2032 p\u2192 \u03c3eq (A.7)\nwhereMeq = (\u03c9eq, {\u039eeq(x)}x\u2208O,\u03c3eq) is an m-dimensional OOM equivalent toM, if the rank of the limit of C\u03021,2 is not less than m.\nProof. According to Appendix A.1, the limit of C\u03021,2 can be expressed as\nC\u03021,2 p\u2192 G\u03c9G>\u03c3\nwhere G\u03c9 and G\u03c3 have the same definitions as in Appendix A.1. So the limit of C\u03021,2 has rank m. By the Eckart-Young-Mirsky Theorem, C\u0302trun1,2 = U\u03a3V\n> is the best rank m approximation to C\u03021,2 and therefore\nC\u0302trun1,2 p\u2192 G\u03c9G>\u03c3\nLet\nG\u03c9G > \u03c3 = U\u0303\u03a3\u0303V\u0303 >\nbe the SVD of G\u03c9G>\u03c3 ,\nF\u03031 = U\u0303, F\u03032 = V\u0303\u03a3\u0303 \u22121\nandMeq = (\u03c9eq, {\u039eeq(x)}x\u2208O,\u03c3eq) be an OOM which is equivalent toM with\n\u03c9eq = \u03c9G > \u03c3 F\u03032 \u039eeq(x) = ( G>\u03c3 F\u03032 )\u22121 \u039e(x) ( G>\u03c3 F\u03032 ) \u03c3eq = ( G>\u03c3 F\u03032 )\u22121 \u03c3\nWe can obtain from the Wedin Theorem and the continuity of singular values of matrice that\nmin R \u2225\u2225\u2225UR\u2212 U\u0303\u2225\u2225\u2225 = \u2225\u2225\u2225UU>U\u0303\u2212 U\u0303\u2225\u2225\u2225 p\u2192 0 min R\n\u2225\u2225\u2225VR\u2212 V\u0303\u2225\u2225\u2225 = \u2225\u2225\u2225VV>V\u0303 \u2212 V\u0303\u2225\u2225\u2225 p\u2192 0 \u03a3 p\u2192 \u03a3\u0303\nTherefore, we can construct an OOMM\u2032 = (\u03c9\u2032, {\u039e\u2032(x)}x\u2208O,\u03c3\u2032) with \u03c9\u2032 = \u03c9\u0302 ( \u03a3V>V\u0303\u03a3\u0303 \u22121) = \u02c6\u0304\u03c6>2 VV >V\u0303\u03a3\u0303 \u22121\n\u039e\u2032(x) = ( \u03a3V>V\u0303\u03a3\u0303 \u22121)\u22121 \u039e\u0302 (x) ( \u03a3V>V\u0303\u03a3\u0303 \u22121) = ( U\u0303>UU>C\u03021,2V\u0303\u03a3\u0303 \u22121)\u22121 U\u0303>UU>C\u03021,3 (x) VV >V\u0303\u03a3\u0303 \u22121\n\u03c3\u2032 = ( \u03a3V>V\u0303\u03a3\u0303 \u22121)\u22121 \u03c3\u0302\n= ( U\u0303>UU>C\u03021,2VV >V\u0303\u03a3\u0303 \u22121)\u22121 U\u0303>UU> \u02c6\u0304\u03c61\nwhich is equivalent to M\u0302 and satisfies\n\u039e\u2032(x) p\u2192 ( U\u0303>G\u03c9G > \u03c3 V\u0303\u03a3\u0303 \u22121)\u22121 U\u0303>G\u03c9\u039e(x)G > \u03c3 V\u0303\u03a3\u0303 \u22121\n= \u039eeq(x)\n\u03c3\u2032 p\u2192 ( U\u0303>G\u03c9G > \u03c3 V\u0303\u03a3\u0303 \u22121)\u22121 U\u0303>G\u03c9\u03c3\n= \u03c3eq\nIt is worth pointing out that we can also show conclusions of Theorems 2 and 3 with (A.5) by using similar proofs. The details proofs are omitted because they are trivial.\nA.4 Proof of Theorem 2\nPart (1) We first show that there is an OOM M\u0304eq = (\u03c9\u0304eq, {\u039eeq(x)}x\u2208O,\u03c3eq) which can describe the equilibrium dynamics of {xt}, where \u039eeq(x) and \u03c3eq are defined in (A.3). In the case of T = T0 and I \u2192\u221e, we can obtain from Assumptions 2 and 3 that\nlim k\u2192\u221e G\u03c9\u039e(O)kG>\u03c3 = lim k\u2192\u221e\n1\nT0 \u2212 2L T0\u22122L\u22121\u2211 t=0 E [ \u03c61 (xt+1:t+L)\u03c62 (xt+L+k+1:t+2L+k) > ]\n=\n( 1\nT0 \u2212 2L T0\u22122L\u22121\u2211 t=0 E [\u03c61 (xt+1:t+L)]\n)( E\u221e [ \u03c62 (xt+1:t+L) > ])\n= G\u03c9\u03c3 ( E\u221e [ \u03c62 (xt+1:t+L) > ])\n\u21d2 lim k\u2192\u221e \u039e(O)k = \u03c3\u03c9\u0304 (A.8)\nwith \u03c9\u0304 = ( E\u221e [ \u03c62 (xt+1:t+L) > ]) G+>\u03c3 (A.9)\nwhere G\u03c9 and G\u03c3 are defined by (A.2) and (A.1), and G+\u03c3 denotes the Moore-Penrose pseudoinverse of G\u03c3 . Then\nlim t\u2192\u221e P (xt+1:t+l = z1:l) = lim t\u2192\u221e \u03c9\u039e(O)t\u039e(z1:l)\u03c3\n= \u03c9\u039e(O)\u03c3\u03c9\u0304\u039e(z1:l)\u03c3 = \u03c9\u0304\u039e(z1:l)\u03c3\n= \u03c9\u0304eq\u039eeq(z1:l)\u03c3eq\nwith \u03c9\u0304eq = \u03c9\u0304G > \u03c3F2 (A.10)\nIn the case of T = T0 and I \u2192 \u221e, because rank (G\u03c9) = m for G\u03c9 defined by (A.4), there is a sufficiently large but finite T \u2032 so that rank (G\u2032\u03c9) = m with\nG\u2032\u03c9 = \u2211 z1:L \u03c61(z1:L)\u03c9\u039e (O) T \u2032 \u039e(z1:L)\nConsidering\nlim k\u2192\u221e G\u2032\u03c9\u039e(O)kG>\u03c3 = lim k\u2192\u221e\nE [ \u03c61 (xT \u2032+1:T \u2032+L)\u03c62 (xT \u2032+L+k+1:T \u2032+2L+k) > ]\n= G\u2032\u03c9\u03c3 ( E\u221e [ \u03c62 (xt+1:t+L) > ])\n\u21d2 lim k\u2192\u221e \u039e(O)k = \u03c3\u03c9\u0304 (A.11)\nwith \u03c9\u0304 defined by (A.9), we can also conclude that\nlim t\u2192\u221e\nP (xt+1:t+l = z1:l) = \u03c9\u0304eq\u039eeq(z1:l)\u03c3eq\nwith \u03c9\u0304eq defined by (A.10).\nNote in both cases, \u03c9\u0304eq satisfies \u03c9eq limk\u2192\u221e\u039e(O)k = \u03c9\u0304eq and\n\u03c9\u0304eq\u039eeq(O) = lim t\u2192\u221e \u03c9eq\u039eeq(O)t+1\n= \u03c9\u0304eq \u03c9\u0304eq\u03c3eq = \u03c9\u0304eq\u039eeq(O)\u03c3eq\n= lim t\u2192\u221e \u2211 x\u2208O P (xt = x) = 1\nPart (2) In this part, we show that\nw\u039eeq(O) = w, w\u03c3eq = 1\nhas a unique solution w = \u03c9\u0304eq.\nAccording to Appendix A.1 and (A.8), (A.11), if w\u039eeq(O) = w and w\u03c3eq = 1, we have\nw = lim k\u2192\u221e\nw\u039eeq(O)k\n= lim k\u2192\u221e\nw ( G>\u03c3F2 )\u22121 \u039e(O)k ( G>\u03c3F2 ) = w ( G>\u03c3F2 )\u22121 \u03c3\u03c9\u0304 ( G>\u03c3F2\n) = w\u03c3eq\u03c9\u0304eq = \u03c9\u0304eq\nPart (3) We now show Theorem 2.\nThe optimization problem (17) can be equivalently transformed into an unconstrained problem\n\u03c9\u0302 = min w \u2225\u2225\u2225wproj\u039e\u0302(O)\u2212wproj\u2225\u2225\u22252 + \u2225\u2225wproj \u2212w\u2225\u22252 where\nwproj = w ( I\u2212 \u03c3\u0302\u03c3\u0302+ ) + \u03c3\u0302+ (A.12)\ndenotes the projection of w on the space {w|w\u03c3\u0302 = 1}, I denotes the identity matrix of appropriate dimension, and \u03c9\u0304eq is the unique solution if \u039e\u0302(O) = \u039eeq(O) and \u03c3\u0302 = \u03c3eq according to the conclusion in Part (2). Then we can obtain that \u03c9\u0302\np\u2192 \u03c9\u0304eq according to Theorem 2.7 in [1], which yields the conclusion of Theorem 2.\nPart (4) We derive in this part the closed-form solution to (17).\nSince the projection of w on the space {w|w\u03c3\u0302 = 1} is wproj defined by(A.12), (17) can be equivalent transformed into\nmin w \u2225\u2225\u2225w (I\u2212 \u03c3\u0302\u03c3\u0302+) (\u039e\u0302(O)\u2212 I)+ \u03c3\u0302+ (\u039e\u0302(O)\u2212 I)\u2225\u2225\u22252 The solution to this problem is\nw\u2217 = \u2212\u03c3\u0302+ ( \u039e\u0302(O)\u2212 I )(( I\u2212 \u03c3\u0302\u03c3\u0302+ ) ( \u039e\u0302(O)\u2212 I ))+ which provides the optimal value of \u03c9\u0302 as\n\u03c9\u0302 = w\u2217 ( I\u2212 \u03c3\u0302\u03c3\u0302+ ) + \u03c3\u0302+\n= \u03c3\u0302+ \u2212 \u03c3\u0302+ ( \u039e\u0302(O)\u2212 I )(( I\u2212 \u03c3\u0302\u03c3\u0302+ ) ( \u039e\u0302(O)\u2212 I ))+ ( I\u2212 \u03c3\u0302\u03c3\u0302+ ) (A.13)\nA.5 Proof of Theorem 3\nHere we only consider the consistency of the binless OOM as I \u2192 \u221e. The proof can be easily to extended to the case of T \u2192 \u221e. In addition, we denote E\u221e[g(xt+1:t+r)] and E[g(x1:r)|M\u0302] by E\u221e[g] and EM\u0302[g] for convenience of notation.\nPart (1) We first show that Theorem 3 holds for g (xt+1:t+r) = 1xt+1:t+r\u2208Bi1\u00d7Bi2\u00d7...\u00d7Bir , where B1, . . . ,BK is a partition of O, i1:r \u2208 {1, . . . ,K}r, and 1e denotes the indicator function of event e. In this case, we can construct a discrete OOM with observation space {B1, . . . ,BK} by the nonequilibrium learning algorithm, which can provide the same estimate of E\u221e [g (xt+1:t+r)] as M\u0302. Therefore, we can show EM\u0302[g] p\u2192 E\u221e[g] by using the similar proof of Theorem 2.\nPart (2) We now consider the case that g is a continuous function. According to the Heine-Cantor theorem, g is also uniformly continuous. Then, for an abitrary > 0, we can construct a simple function\ng\u0302(xt+1:t+r) = \u2211\ni1,...,ir\nci1i2...ir1xt+1:t+r\u2208Bi1\u00d7...\u00d7Bir\nso that |g(z1:r)\u2212 g\u0302(z1:r)| \u2264 , \u2200z1:r \u2208 Or\nwhere {B1, . . . ,BK} is a partition of O. Then, we have\n|E\u221e[g]\u2212 E\u221e[g\u0302]| \u2264 E\u221e[|g \u2212 g\u0302|] \u2264\nand \u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 p\u2192 0 as I \u2192\u221e according to the conclusion of Part (1), where E\u221e[g] = E\u221e[g(xt+1:t+r)] and EM\u0302[g] = E[g(x1:r)|M\u0302]. It can be known from Assumption 4, there exists a constant \u03be such that\n1maxx\u2208X\u2016\u039e\u0302(x)\u2016<\u03be/|X | p\u2192 1 (A.14)\nUnder the condition that maxx\u2208X \u2225\u2225\u2225\u039e\u0302(x)\u2225\u2225\u2225 < \u03be/ |X |, we have\n\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 = \u03c9\u03020 ( \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u039e\u0302(z1:r) ) \u03c3\u0302\n\u2264 \u2016\u03c9\u03020\u2016 \u2016\u03c3\u0302\u2016 ( \u2211 z1:r\u2208X r \u03ber |X |r ) = \u2016\u03c9\u03020\u2016 \u2016\u03c3\u0302\u2016 \u03ber\nIn addition, considering that we can show as in Appendix A.1 that \u03c9\u0302 p\u2192 \u03c9\u0304eq and \u03c3\u0302 p\u2192 \u03c3eq, we can obtain\n1\u2016\u03c9\u0302\u2016\u2016\u03c3\u0302\u2016\u2264\u03be0 p\u2192 1 (A.15)\nand 1|EM\u0302[g\u0302]\u2212EM\u0302[g]|\u2264\u03be0\u03ber p\u2192 1\nwhere \u03be0 is a constant larger than \u2016\u03c9\u0304eq\u2016 \u00b7 \u2016\u03c3eq\u2016. Based on the above analysis and the fact that\u2223\u2223E\u221e[g]\u2212 EM\u0302[g]\u2223\u2223 = \u2223\u2223E\u221e[g]\u2212 E\u221e[g\u0302] + E\u221e[g\u0302]\u2212 EM\u0302[g\u0302] + EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223\n\u2264 |E\u221e[g]\u2212 E\u221e[g\u0302]|+ \u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223+ \u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223\nwe can get Pr (\u2223\u2223E\u221e[g]\u2212 EM\u0302[g]\u2223\u2223 \u2264 (\u03be0\u03ber + 2) ) \u2265 Pr (|E\u221e[g]\u2212 E\u221e[g\u0302]| \u2264 , \u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 \u2264 ,\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2264 \u03be0\u03ber )\n\u2192 1\nBecause this equation holds for all > 0, we can conclude that EM\u0302[g] p\u2192 E\u221e[g].\nPart (3) In this part, we prove the conclusion of the theorem in the case where g is a Borel measurable function and bounded with |g(z1:r)| < \u03beg for all z1:r \u2208 Or, and there exist constants \u03be\u0304 and \u03be so that \u2016\u039e (x)\u2016 \u2264 \u03be\u0304 and limt\u2192\u221e P (xt+1:t+r = z1:r) \u2265 \u03be for all x \u2208 O and z1:r \u2208 Or.\nAccording to Theorem 2.2 in [2], for an arbitrary > 0, there is a continuous function g\u0302\u2032 satisfies E\u221e[1xt+1:t+r\u2208K (g\u0302\u2032)] < , where K (g\u0302\u2032) = {z1:r|z1:r \u2208 Or, |g\u0302\u2032(z1:r)\u2212 g(z1:r)| > }. Define\ng\u0302(z1:r) = { g\u0302\u2032(z1:r), |g\u0302\u2032(z1:r)| \u2264 \u03beg \u2212\u03beg, g\u0302\u2032(z1:r) < \u2212\u03beg \u03beg, g\u0302 \u2032(z1:r) > \u03beg\nIt can be seen that g\u0302 is a continuous function which is also satisfies E\u221e[1xt+1:t+r\u2208K (g\u0302)] < and bounded with |g\u0302(z1:r)| < \u03beg . So the difference between E\u221e[g] and E\u221e[g\u0302] satisfies\n|E\u221e[g]\u2212 E\u221e[g\u0302]| \u2264 E\u221e [|g(xt+1:t+r)\u2212 g\u0302(xt+1:t+r)|] = E\u221e[1xt+1:t+r\u2208K (g\u0302)]E\u221e [|g(xt+1:t+r)\u2212 g\u0302(xt+1:t+r)| |xt+1:t+r \u2208 K (g\u0302)]\n+E\u221e[1xt+1:t+r /\u2208K (g\u0302)]E\u221e [|g(xt+1:t+r)\u2212 g\u0302(xt+1:t+r)| |xt+1:t+r /\u2208 K (g\u0302)] \u2264 \u00b7 2\u03beg + = (2\u03beg + 1)\nFor the difference between E\u221e[g\u0302] and EM\u0302[g\u0302], we can obtain from the above that \u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 p\u2192 0 as I \u2192\u221e by considering that g\u0302 is continuous, which implies that there is an I0 such that\nPr (\u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 > ) < , \u2200I > I0\nNext, let us consider the value of \u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223. Note that\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2264 \u2016\u03c9\u03020\u2016 \u2016\u03c3\u0302\u2016 \u2225\u2225\u2225\u2225\u2225 \u2211 z1:n\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u039e\u0302(z1:r)\n\u2225\u2225\u2225\u2225\u2225 < \u03be0\u03be r\n|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 under the condition that\n\u2225\u2225\u2225\u039e\u0302(x)\u2225\u2225\u2225 < \u03be/ |X | and \u2016\u03c9\u0302\u2016 \u2016\u03c3\u0302\u2016 \u2264 \u03be0. Therefore, there exists an I1 such that Pr\n(\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2265 \u03be0\u03ber|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 ) < , \u2200I > I1 (A.16)\ndue to (A.14) and (A.15). Let x\u20321:r denotes a random sample taken uniformly from X r. We can obtain that\nP (x\u20321:r) = P (x\u20321) . . .P (x\u2032r) \u2264 ( \u2016\u03c9\u2016 \u2016\u03c3\u2016 \u03beO \u03be\u0304 )r where \u03beO \u2265\n\u2225\u2225\u2225\u039e (O)k\u2225\u2225\u2225 for any k \u2265 0. Note \u03beO <\u221e because we can show the existing of the limit of { \u2225\u2225\u2225\u039e (O)0\u2225\u2225\u2225 ,\u2225\u2225\u2225\u039e (O)1\u2225\u2225\u2225 , . . .} by similar steps in Appendix A.4. Thus\nE\n[ 1\n|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 ] \u2264 E [E [|g\u0302(x\u20321:r)\u2212 g(x\u20321:r)| |X ]]\n= E [|g\u0302(x\u20321:r)\u2212 g(x\u20321:r)|] = E [ 1x\u20321:r\u2208K (g\u0302) ] E [|g\u0302(x\u20321:r)\u2212 g(x\u20321:r)| |x\u20321:r \u2208 K (g\u0302)]\n+E [ 1x\u20321:r /\u2208K (g\u0302) ] E [|g\u0302(x\u20321:r)\u2212 g(x\u20321:r)| |x\u20321:r /\u2208 K (g\u0302)]\n\u2264 \u03be\u00b5 \u00b7 2\u03beg + = (2\u03beg\u03be\u00b5 + 1) where \u03be\u00b5 = ( \u2016\u03c9\u2016 \u2016\u03c3\u2016 \u03beO \u03be\u0304 )r /\u03be. By the Markov\u2019s inequality, we have\nPr\n[ 1\n|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 \u2265 \u221a ] \u2264 (2\u03beg\u03be\u00b5 + 1) \u221a (A.17)\nCombining (A.16) and (A.17) leads to\nPr (\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2265 \u03be0\u03ber\u221a ) \u2264 Pr (\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2265 \u03be0\u03ber|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208Xr (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 )\n+ Pr\n( 1\n|X |r \u2223\u2223\u2223\u2223\u2223 \u2211 z1:r\u2208X r (g\u0302(z1:r)\u2212 g(z1:r)) \u2223\u2223\u2223\u2223\u2223 \u2265 \u221a )\n\u2264 + (2\u03beg\u03be\u00b5 + 1) \u221a\nfor all I > I1. From all the above, we have Pr (\u2223\u2223E\u221e[g]\u2212 EM\u0302[g]\u2223\u2223 \u2264 2(\u03beg + 1) + \u03be0\u03ber\u221a ) \u2265 Pr\n(\u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 \u2264 , \u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 \u2264 \u03be0\u03ber\u221a ) \u2265 1\u2212 Pr\n(\u2223\u2223E\u221e[g\u0302]\u2212 EM\u0302[g\u0302]\u2223\u2223 > )\u2212 Pr (\u2223\u2223EM\u0302[g\u0302]\u2212 EM\u0302[g]\u2223\u2223 > \u03be0\u03ber\u221a ) \u2265 1\u2212 2 \u2212 (2\u03beg\u03be\u00b5 + 1) \u221a\nfor all I > max{I0, I1}, which yields EM\u0302[g] p\u2192 E\u221e[g] due to the arbitrariness of ."}, {"heading": "B Settings in applications", "text": "B.1 Models\nThe diffusion processes in Section 6 are driven by the Brownian dynamics dxt = \u2212\u2207V (xt)dt+ \u221a\n2\u03b2\u22121dWt with \u03b2 = 0.3, sample interval 0.002s,\nV (x) =\n\u22115 i=1 (|x\u2212 ci|+ 0.001)\n\u22122 ui\u22115\ni=1 (|x\u2212 ci|+ 0.001) \u22122\nfor the one-dimensional process, and \u03b2 = 2, sample interval 0.01s,\nV (x) = \u2212 log ( 3\u2211 i=1 piN (x|\u00b5i,\u03a3i) ) for the two-dimensional process, where c1:5 = (\u22120.3, 0.5, 1, 1.5, 2.3), u1:5 = (21, 4, 8,\u22121, 20), p1:3 = (0.25, 0.25, 0.5), \u00b51 = (0,\u22120.5), \u00b52 = (\u22121, 0.5), \u00b53 = (1,\u22120.5). The simulation details of alanine dipeptide is given in [3].\nB.2 Algorithms\nThe parameters of discrete OOMs are chosen as: L = 3, m = 10, F1,F2 are given by the truncated SVD and \u03c61 = \u03c62 are indicator functions of all OL observation subsequences with length L. The parameters of binless OOMs are almost the same as discrete ones, except \u03c61 = \u03c62 are Gaussian activation functions with random weights of functional link neural networks with D1 = D2 = 100.\nThe number of hidden states of HMMs is 10. For continuous data, we partition the state space into 100 discrete bins k-mean clustering (except for the one-dimensional process), and then learn HMMs by the EM algorithm under the assumption that samples within the same bin are drawn independently."}], "references": [{"title": "Large sample estimation and hypothesis testing", "author": ["W.K. Newey", "D. McFadden"], "venue": "Handbook of Econometrics, vol. 4, pp. 2111\u20132245, 1994.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["K. Hornik", "M. Stinchcombe", "H.White"], "venue": "Neural Netw., vol. 2, no. 5, pp. 359\u2013366, 1989.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1989}, {"title": "Efficient estimation of rare-event kinetics", "author": ["B. Trendelkamp-Schroer", "F. No\u00e9"], "venue": "Phys. Rev. X, vol. 6, pp. 011009, 2016. 9", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 1, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 2, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 2, "context": ", [3, 8, 10] for", "startOffset": 2, "endOffset": 12}, {"referenceID": 1, "context": "(c) Estimates of the probability difference given by the empirical estimator, HMM and Binless OOM (BL-OOM) using nonequilibrium learning with O = [0, 2].", "startOffset": 146, "endOffset": 152}, {"referenceID": 1, "context": "2(a) shows the potential function of a one-dimensional diffusion process {xt} on [0, 2] driven by Brownian dynamics, where the state space is discretized into two clusters I, II.", "startOffset": 81, "endOffset": 87}, {"referenceID": 1, "context": "2(c) and 2(d) plot estimates of the equilibrium state distribution given by the empirical estimator, HMM and binless OOM using nonequilibrium learning under the condition that the value of xt is exactly known and O = [0, 2], where the empirical estimator calculates statistics through averaging over all observations.", "startOffset": 217, "endOffset": 223}], "year": 2016, "abstractText": "Observable operator models (OOMs) and related models are one of the most important and powerful tools for modeling and analyzing stochastic systems. They can exactly describe dynamics of finite-rank systems, and be efficiently learned from data by moment based algorithms. Almost all OOM learning algorithms are developed based on the assumption of equilibrium data which is very difficult to guarantee in real life, especially for complex processes with large time scales. In this paper, we derive a nonequilibrium learning algorithm for OOMs, which dismisses this assumption and can effectively extract the equilibrium dynamics of a system from nonequilibrium observation data. In addition, we propose binless OOMs for the application of nonequilibrium learning to continuous-valued systems. In comparison with the other OOMs with continuous observations, binless OOMs can achieve consistent estimation from nonequilibrium data with only linear computational complexity.", "creator": "LaTeX with hyperref package"}}}