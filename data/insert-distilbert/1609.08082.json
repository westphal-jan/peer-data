{"id": "1609.08082", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2016", "title": "An Ontology of Preference-Based Multiobjective Metaheuristics", "abstract": "user preference integration is of great importance in multiobjective optimization, in particular in developing many objective optimization. preferences have long been increasingly considered in traditional multicriteria decision making ( mcdm ) which is based tightly on mathematical programming and recently it is integrated in evolutionary multiobjective optimization ( emo ), resulting in focus on preferred parts forward of the embedded pareto front instead of the whole pareto front front. consistently the number of publications and results on preference - based multiobjective hybrid evolutionary algorithms ( pmoeas ) has increased rapidly over the past decade. there already exists a large variety of intelligent preference handling methods and emo methods, which have been combined in various architectural ways. this article proposes to use the web ontology language ( tagged owl ) to model and systematize the results recently developed in this field. an extensive review of updates the existing standardization work is provided, based on papers which an ontology is uniquely built and instantiated with new state of the art results. the owl spider ontology is consistently made public and open - to future patent extension. moreover, the usage capacity of the basque ontology is exemplified for different use - cases, including training new researchers into this knowledge domain, querying instances for methods that match an application classification problem in engineering optimization, checking existence of combinations of preference models specifically and emo techniques, and discovering opportunities for new research and open research questions.", "histories": [["v1", "Mon, 26 Sep 2016 17:16:54 GMT  (1899kb,D)", "https://arxiv.org/abs/1609.08082v1", "19 pages, 7 figures"], ["v2", "Fri, 10 Mar 2017 13:58:27 GMT  (3403kb,D)", "http://arxiv.org/abs/1609.08082v2", "submitted to European Journal of Operational Research"]], "COMMENTS": "19 pages, 7 figures", "reviews": [], "SUBJECTS": "cs.NE cs.AI", "authors": ["longmei li", "iryna yevseyeva", "vitor basto-fernandes", "heike trautmann", "ning jing", "michael emmerich"], "accepted": false, "id": "1609.08082"}, "pdf": {"name": "1609.08082.pdf", "metadata": {"source": "CRF", "title": "An Ontology of Preference-Based Multi-objective Metaheuristics", "authors": ["Longmei Lia", "Iryna Yevseyeva", "Vitor Basto-Fernandes", "Heike Trautmann", "Ning Jing", "Michael Emmerich"], "emails": ["longmeili@nudt.edu.cn", "iryna.yevseyeva@dmu.ac.uk", "vitor.basto.fernandes@iscte.pt", "trautmann@wi.uni-muenster.de", "ningjing@nudt.edu.cn", "m.t.m.emmerich@liacs.leidenuniv.nl"], "sections": [{"heading": null, "text": "User preference integration is of great importance in multi-objective optimization, in particular in many objective optimization. Preferences have long been considered in traditional multicriteria decision making (MCDM) which is based on mathematical programming. Recently, it is integrated in multi-objective metaheuristics (MOMH), resulting in focus on preferred parts of the Pareto front instead of the whole Pareto front. The number of publications on preference-based multiobjective metaheuristics has increased rapidly over the past decades. There already exist various preference handling methods and MOMH methods, which have been combined in diverse ways. This article proposes to use the Web Ontology Language (OWL) to model and systematize the results developed in this field. A review of the existing work is provided, based on which an ontology is built and instantiated with state-of-the-art results. The OWL ontology is made public and open to future extension. Moreover, the usage of the ontology is exemplified for different usecases, including querying for methods that match an engineering application, bibliometric analysis, checking existence of combinations of preference models and MOMH techniques, and discovering opportunities for new research and open research questions.\nKeywords: Evolutionary computations, Preferences, Multi-objective Metaheuristics (MOMH), Multicriteria decision making (MCDM), OWL Ontology"}, {"heading": "1. Introduction", "text": "Most real-world optimization problems involve multiple objectives (or criteria) to be considered simultaneously. The objectives are usually conflicting, which means improvement of one objective\n\u2217Corresponding author Email addresses: longmeili@nudt.edu.cn (Longmei Li), iryna.yevseyeva@dmu.ac.uk (Iryna Yevseyeva),\nvitor.basto.fernandes@iscte.pt (Vitor Basto-Fernandes), trautmann@wi.uni-muenster.de (Heike Trautmann), ningjing@nudt.edu.cn (Ning Jing), m.t.m.emmerich@liacs.leidenuniv.nl (Michael Emmerich)\nPreprint submitted to Journal of LATEX Templates March 13, 2017\nar X\niv :1\n60 9.\n08 08\n2v 2\n[ cs\n.N E\n] 1\ncannot be achieved without deteriorating other objective(s). This kind of problem is regarded as multi-objective optimization problems (MOPs). Unlike single objective optimization resulting in a single optimum, the result of MOPs consists of multiple trade-off solutions called Pareto optimal solutions, and the image in the objective space is referred to as Pareto front (PF).\nAs [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs. Here, conventional MCDM refers to methods focusing on mathematical programming, aimed at finding one solution that best fits the preferences of a decision maker (DM). In contrast, multi-objective evolutionary algorithms (MOEAs), which belong to multi-objective metaheuristics (MOMHs) [6], are population-based algorithms intended to find a set of solutions that best approximate the whole PF. Once the set is generated, it will be presented to the DM for selection of a single solution at the second step.\nThe two methodologies have both pros and cons as stated in [7]. Much synergy can be gained from the collaboration of MCDM and MOMH research areas. MCDM can help to shrink the set of alternative solutions obtained by MOMH, it is also good remedy for many-objective optimization problems (MaOPs) when selection based on Pareto optimal relation is not sufficient. MOMH can assist MCDM with difficult problems which mathematical programming cannot handle, such as nondifferentiable or discontinuous functions, nonconvexity conditions, etc. These motivations are the origin of preference-based multi-objective metaheuristics (PMOMHs). The 2004 and 2006 Dagstuhl seminars witnessed an initiation of many results in PMOMHs [8] when researchers in MOMH and MCDM fields gathered together to know each other and stimulate cooperation. Since then, large numbers of methods and algorithms have been proposed and published.\nGood review papers exist along with the development of PMOMHs [9\u201313]. Due to the variety of approaches and contexts where preference modelling is combined, to obtain a systematical view of PMOMHs becomes increasingly complex. PMOMHs can be classified by interaction moment with the DM [14] (a-priori, a-posteriori or interactively), by type of preference information used [15] (implicit preference or explicit preference), by ways preferences are integrated in (change of objectives or change of metaheuristics), by type of the internal preference model, etc. Overviews help researchers to figure out what has already been done, what are the relationships between different methods and what can be done in the future. Ontologies are currently the most suited way to formally describe knowledge in a standard way, by means of comprehensive notations and graphical representations, to help understand concepts and relationships in complex knowledge domains [16]. They have been widely investigated in knowledge management, semantic web, and electronic commerce, but underexplored for Metaheuristics and MCDM fields.\nThe ontology describes concepts, relationships, formal logic axioms and objects of a particular domain [17]. It allows for a shared and common understanding of the structure of information among people or software agents. It also enables reuse of domain knowledge. With the help of a PMOMH ontology, researchers can easily understand, learn and assess existing methods, discover potential combinations and seek an appropriate method for a specific problem or application. To the best of our knowledge, formal logic-based ontologies have not been used in the PMOMH domain yet. However, in [18] and [19] OWL ontologies were presented for diversity-oriented optimization and Evolutionary Computation respectively, revealing the suitability and relevance of this type of knowledge representation for the optimization algorithms research domain.\nIn this paper we propose a PMOMH ontology built with Prote\u0301ge\u0301 [20], a state-of-the-art ontology editor and framework. New contributions of this paper can be summarized as follows:\n(1) A comprehensive review of PMOMHs is given and the main characteristics of each algorithm\nare analyzed. (2) An OWL ontology of PMOMH is built with Prote\u0301ge\u0301 and made public for the research communities to comment, annotate, (re)use, extend and complement. (3) Use cases of the PMOMH ontology are provided for application-algorithm matching, bibliometric analysis, research results assessment, automatic classification and new research discovery. (4) The PMOMH ontology provides an overview and new perspective on this scientific area. Other ontologies can be built in related scientific areas that need a systematical view and shared conceptualization. The strength of this approach relies on its generalization and knowledge inference ability.\nThe rest of this paper is organized as follows. A review of state-of-the-art results in PMOMH field is given in section 2, scientific background of the OWL ontology is introduced in section 3. In section 4, the method and procedure of building the PMOMH ontology is described in detail. Use cases of the ontology are exemplified in section 5. Conclusions are drawn in section 6."}, {"heading": "2. Preference-based multi-objective metaheuristics", "text": ""}, {"heading": "2.1. Multi-objective Metaheuristics", "text": "A minimization MOP is defined as follows [4] without loss of generality: min f(x) = [f1(x), f2(x), \u00b7 \u00b7 \u00b7 fM (x)]T gj(x) \u2265 0 j = 1, 2, \u00b7 \u00b7 \u00b7 , P hk(x) = 0 k = 1, 2, \u00b7 \u00b7 \u00b7 , Q xLi \u2264 xi \u2264 xUi i = 1, 2, \u00b7 \u00b7 \u00b7 , n\n(1)\nin which solution x is an n-dimensional decision vector x = (x1, x2, \u00b7 \u00b7 \u00b7 , xn) \u2208 Rn. Each variable xi is bounded between lower bound x L i and upper bound x U i . fi is the i-th objective function and there are M objectives in total. P and Q specify the numbers of inequality and equality constraints, respectively. Alternatively, one might also consider combinatorial MOP in which case Rn is replaced by Zn or some other discrete search space.\nThe resolution of a MOP is a set of trade-off solutions, called non-dominated solutions or Pareto optimal solutions. The related definitions are as follows [2].\nA vector u = (u1, \u00b7 \u00b7 \u00b7 , uM )T is said to dominate another vector v = (v1, . . . , vM )T , denoted as u \u227a v, iff \u2200i \u2208 {1, . . . ,M}, ui \u2264 vi and u 6= v.\nA feasible solution x\u2217 \u2208 \u2126, where \u2126 is the decision space of problem (1), is called a Pareto optimal solution, iff \u00ac\u2203y \u2208 \u2126 such that F (y) \u227a F (x\u2217). The set of all Pareto optimal solutions is called Pareto set (PS) and the image of the PS in the objective space is called the Pareto front (PF).\nMetaheuristics are a broad family of non-deterministic optimization methods that may provide a sufficiently good solution to complex optimization problems [21]. MOMHs have demonstrated a great success in solving MOPs, such as MOEA (which are by far the most well-known and widely used MOMH), Particle Swarm Optimization (PSO), Artificial Immune System (AIS), Ant Colony Optimization (ACO), etc. Next, we identify the characteristics of various MOMHs and the possibilities to embrace preferences.\nThere are three main MOEA categories, i.e., Pareto-based, indicator-based and decompositionbased [22]. Pareto-based MOEAs use Pareto dominance as selection criterion, such as NSGA-II [23], SPEA2 [24], and so on. Fitness assignment and diversity methods are the key elements of algorithms\nin this category, where preference information can be integrated in. For example, Pareto front sorting method and crowding distance calculation in NSGA-II, fitness assignment and clustering method in SPEA2 could be modified to embed preferences. Indicator-based MOEAs use an indicator to guide the search, resulting in a set of solutions that maximize the indicator. SMS-EMOA [25], HypE [26], R2-EMOA [27] and POSEA [28] fall into this category. Computation of the indicator, e.g., Hypervolume, R2 indicator can be adjusted for the sake of preferences. Decomposition-based MOEAs transform a MOP into several single objective optimization problems. MOEA/D [29] and NSGA-III [30] are two representative algorithms. Preference information can be incorporated via weight vectors and reference points for MOEA/D and NSGA-III respectively, which are core elements of the algorithms. There are also other kinds of MOEAs, e.g., memetic MOEAs combine global search with local search, differential evolution (DE) algorithms adopt new reproduction strategies based on distribution of the solutions in the current population. Coevolution algorithms evolve multiple subpopulations simultaneously to handle a complicated problem, hybrid MOEAs may import techniques from other metaheuristics such as PSO, Simulated Annealing, or algorithms from mathematical programming, machine learning.\nPSO is a population-based stochastic optimization approach inspired by the behavior of bird flocking. The key idea in multi-objective PSO algorithms is how to select the global best and local best particles, which can be incorporated with preferences. AIS is a highly parallel intelligent system, able to learn and retrieve previous knowledge to solve MOPs. Clonal Selection mechanism is an important part in AIS-based MOMHs, preferences can be combined from here. ACO was inspired by the behavior of real ant colonies and is often used for discrete optimization problems. Probability matrix, or the pheromone model could be used to link preferences. Other metaheuristics such as Simulated Annealing (SA) and Tabu Search (TS), have also been extended to tackle MOPs, could also consider preference integration.\nApart from the specialty of each algorithm, there are also common elements for preference integration. For example, changing dominance relation is one of the most widely used methods in PMOMHs. Initialization, fitness evaluation, and termination criterion have also been used to incorporate preference information."}, {"heading": "2.2. Preference-based MOMH", "text": "The ultimate goal of multi-objective optimization is to help the DM choose the most preferred solution. Hence, the integration of MCDM approaches, which facilitate such choice, becomes indispensable. Embracement of the DM\u2019s preferences into MOMHs have attracted wide attention due to the following advantages:\n(1) It is difficult for EMO to handle MaOPs (when there are more than three objectives). Since almost all of the solutions tend to be non-dominated, selection pressure will be lost when many solutions belong to the PF. Having the preference information of the DM as a selection criterion is a good way to address this problem [31, 32].\n(2) Inspecting and choosing solutions from the whole PF is not a trivial task for the DM. The visualization of high-dimensional space further aggravates the difficulty. If the DM gives some (even vague) information about his/her preferences, then preferred parts of the PF will be emphasized, relieving the selection burden of the DM.\n(3) Taking into account preference information, MOMHs can only focus on searching regions favored by the DM, so that the preferred solutions will be obtained more quickly. In other words, computational efforts for finding unwanted solutions will be avoided.\nDue to these advantages, a large number of publications have focused on PMOMHs. There are several criteria to classify PMOMHs, such as interaction moment in [14]1 and preference information in [12]. Here, we adopt the taxonomy of [12] with slight changes. The categories are Reference point-based approaches, Reference direction-based approaches, Preference region-based approaches, Trade-off-based approaches, Objective comparison-based approaches, Solution comparison-based approaches, Outranking-based approaches, Knee point-based approaches."}, {"heading": "2.2.1. Reference point-based approaches", "text": "Compared to other articulation of preferences, reference point2, first proposed by Wierzbicki [34] in MCDM, is now among the most widely used methods in PMOMHs due to its natural and intuitive meaning. In general, a reference point is a user-defined point in objective space that represents the DM\u2019s aspiration level for each objective. The optimization search can stop once a point that dominates or equal to the reference point is found. When the reference point is infeasible, the closer a solution is to the reference point, the more it is preferred.\nThe earliest PMOMH is regarded to be multi-objective genetic algorithm (MOGA) [35] proposed by Fonseca and Fleming. A goal vector was used to define a new dominance relation that gives higher priority to objectives that do not satisfy the goals. This method was extended by Tan et al. [36] to incorporate hard/soft priority information and capable of dealing with multiple reference points. Utilizing the reference point to change dominance relation was also adopted in g-dominance [37] and r-dominance [38]. In g-dominance, solutions that satisfy all the aspiration levels or fulfill none of them are preferred over solutions that satisfy some of the aspiration levels. In r-dominance, solution x is referred to r-dominate solution y when x Pareto dominates y, or the weighted Euclidean distance between x and the reference point is smaller than the distance between y and the reference point to a predefined extent. g-dominance does not comply with the Pareto dominance, which means a dominated solution may be preferred to the solution that dominates it. Fortunately, r-dominance preserves the Pareto dominance. Tchebycheff preference relation [39] is another dominance relation changed by reference point. A Region Of Interest (ROI) is defined with reference point and a threshold, solutions in this ROI are compared by the classical Pareto dominance relation, while solutions outside of the ROI are compared by their Tchebycheff achievement function values.\nApart from dominance relation, reference point can also be used to change crowding distance, as it is done in R-NSGA-II [40]. Here, the original crowding distance is replaced by weighted Euclidean distance to the reference point. R-NSGA-II was later extended by Siegmund et al. [41] to speed up the search under a limited number of evaluations, and was also extended by Filatovas et al. [42] to consider several scalarizing functions simultaneously. In [43], a positive reference point and a negative reference point are integrated in crowding distance to form a new metric called similarity. The aim is to find Pareto optimal solutions that are close to the positive reference point and far away from the negative reference point.\nWeighting achievement scalarizing function genetic algorithm (WASF-GA) [44] applies an achievement scalarizing function (ASF) to classify the individuals into several fronts. The main purpose of this method is to generate a well-distributed set of non-dominated solutions approximating the ROI defined by a reference point. The authors also published the interactive version of WASF-GA [45].\n1MOMHs without preferences can be regarded as a-posteriori methods, so PMOMHs mainly focus on a-priori and interactive methods.\n2It is also called aspiration level or goal vector, or preference point in [33]. Not to be confused with reference point in Hypervolume\nMOEA/D [29] relies on a decomposition strategy such as weighted-sum or Tchebycheff approach to convert a multi-objective problem into single-objective problems. Reference point has also been imported to change weight vectors in [46, 47], for finding preferred solutions. NSGA-III [30] utilizes a number of well-spread reference points for MaOPs, it can also focus on preferred part of the PF using user-supplied reference points. Under such conditions, NSGA-III belongs to PMOMH.\nReference points have also been applied to indicator-based MOEAs. In PBEA [48], \u03b5-indicator has been modified to incorporate ASF values. Aspiration Set EMOA [49] considers a set of reference points to guide the search, with averaged Hausdorff distance as quality indicator. Preferences can be combined with R2-indicator by position of reference point, restriction of weight space and density of weight distribution [50]. R2-EMOA [27] aims at solutions maximizing the preference-based R2indicator.\nReference point-based PSO using a Steady-State approach (RPSO-SS) [51] proposes to use distance to reference points as selection criterion, for the sake of finding a set of solutions near the reference points. Multi-objective Differential Evolution and PSO (MDEPSO) [52] hybridizes two MCDM methods: reference point and light beam search [52]. In [53], g-dominance [37] is combined with memetic multi-objective ant colony optimization for solving a real industrial problem of assembly line balancing."}, {"heading": "2.2.2. Reference direction-based approaches", "text": "Reference direction method [54] and light beam search [55], which can be considered as extensions of reference point method in MCDM, are also integrated in MOMH. LBS-NSGA-II [56] and RD-NSGA-II [57] are the representative algorithms. Light beam search has also been considered in MOEA/D [58], multi-objective Differential Evolution and PSO (MDEPSO) [52] and multi-objective immune algorithm [59]. Branke and Deb proposed a biased crowding distance approach [60] to find a biased distribution on the PF. A direction vector should be provided by the DM to define an iso-utility function, the crowding distance in NSGA-II is modified to focus solutions parallel to this iso-utility function. This approach was regarded as an objective scaling method in [11]."}, {"heading": "2.2.3. Preference region-based approaches", "text": "Instead of using a single point to represent preferences, a preference region in the objective space favored by the DM is also popular. Usually, it is difficult for the DM to give a precise reference point. Hence, a vague range of candidate values for such point could be used as a reasonable alternative. Moreover, functions that reflect the objective values and DM\u2019s degree of satisfaction are included in this category, two representatives are Desirability Function and density function in the objective space1, as discussed next.\nDesirability functions (DFs) [61, 62] are widely investigated for its simple and intuitive meaning. DFs nonlinearly transform the objective values into the desirability domain [0, 1]. 0 stands for unacceptable and 1 represents fully satisfied. By changing the values of objectives corresponding to 0 and 1, the DF can focus the search on different regions of the PF. DFs have already been successfully introduced in combination with NSGA-II [63], MOPSO [64] and SMS-EMOA [65] on both benchmark problems and practical problems. In order to alleviate the computational burden of SMS-EMOA, Trautmann et al. proposed to use the desirability index (DI), which is a DF-based scalarization, as the second-level selection criterion in the non-dominated sorting [66].\n1We call it density function here, although originally it is referred to as weight function. As a weight we would rather consider an integral over the density function.\nAnother popular method to integrate preference is a density function in the objective space. In [33, 67, 68], weighted hypervolume is used to guide the search towards ROI by utilizing a variety of density functions in the objective space, including stressing one objective, one reference point, a rectangle region and so on. This kind of preferences can also be integrated with NSGA-II and SPEA2, as demonstrated in [69]. It can yield similar results compared to the hypervolume approach and requires less computational effort. Desirability Functions and density functions can be integrated. Emmerich et al. use Desirability Function to define a density in the objective space and provide a probabilistic interpretation for it [70].\nKarahan and Ko\u0308ksalan proposed a territory defining steady-state elitist evolutionary algorithm (TDEA) [71] which defines a territory around each individual solution to prevent crowding. They also introduced a preference-based approach, called prTDEA, to assign different sizes of territories for preferred regions and non-preferred regions. Preferred regions have smaller territories so that a denser coverage can be achieved around them. An interactive version of this method was proposed in [72]. A hyperplane in the objective space is constructed to articulate preferences in [73]. The DM can visually specify his/her preferences by center and spread vectors of Gaussian functions on the hyperplane. This preference model is embedded into the framework of NSGA-II and applied to many-objective knapsack problems [74]. A reference vector-guided EA (RVEA) for many-objective optimization was proposed recently [75]. It can not only find the whole PF as most a-posteriori methods do, but also target a preferred subset inside a ROI (which is defined by a central vector and a radius). In interactive preference-inspired co-evolutionary algorithm (iPICEA-g) [76], candidate solutions and goal vectors are co-evolved to focus on a ROI, which is defined by user-provided reference point, weight and search range. It also allows DM to brush ROI in the objective space, alleviating the burden of setting parameters. Yang et al. proposed a method for effectively approximating a preferred part of PF based on multi-objective efficient global optimization (EGO) [77]. It uses truncated expected hypervolume improvement (TEHVI) as infill criterion, making it possible to focus the search within user-supplied region. A hybrid multi-objective immune algorithm (HMIA) was devised with a new concept of dominance, called region-dominance [78]. It enables DM to obtain an efficient set of solutions in his/her preferred region without using any scalarizing function."}, {"heading": "2.2.4. Trade-off-based approaches", "text": "Trade-offs have been widely investigated in MCDM literature. According to Miettinen et al. [79], trade-offs can be objective or subjective. On the one hand, a trade-off that depends on the structure of the problem ( i.e., the change in one objective with respect to change of another one, when moving from a feasible solution to another), is objective trade-off. On the other hand, a trade-off that represents how much the DM is ready to sacrifice the value of some objectives in order to improve another objective(s), is called subjective trade-off. PMOMHs often deal with subjective trade-offs.\nIn the guided MOEA proposed by Branke et al. [80], subjective trade-offs are given by the DM in the form of statement: \u201cone unit improvement in objective i is worth at most aji units degradation in objective j \u201d . The basic idea of this approach is to modify the dominance relation: a solution x is preferred to a non-dominated solution y if it does not violate the specified subjective trade-offs.\nApart from dominance relation, trade-offs can also be employed to sort additional fronts in the best non-dominated set, just as pNSGA-II [81] did. In this method a set F0 is found which satisfies the acceptable trade-offs from the current best front F1. Solutions in this front are assigned with\nrank 0, which is better than the rank of F1. The remaining steps of pNSGA-II are the same as of NSGA-II.\nTrade-offs can also be integrated with set quality indicators. A concept of cone-based hypervolume indicators (CHI) is proposed and theoretically investigated in [82, 83]. The idea is to use a family of polyhedral cones with scalable opening angle \u03b3 to express preferences in the sense of trade-off constraints. Furthermore, the authors presented two searching algorithms to obtain solutions that are compatible with the given preference model, i.e., to find a subset of solutions that maximize the CHI."}, {"heading": "2.2.5. Objective comparison-based approaches", "text": "Objective comparison is referred to as statements of preference on objectives, such as \u201cprefer f1 to f2\u201d or classify objectives qualitatively as \u201cmost important, important, less important\u201d, or describe their importances quantitatively as weights.\nEarly researches focused on weights as preference articulation [84], but sometimes it is difficult for the DM to specify weights accurately. Vague values, or fuzzy preference became popular. Jin and Sendhoff transformed fuzzy preferences on objectives into weight intervals [85], this method is an extension of method proposed in [86]. Rachmawati and Srinivasan introduced relative importance of objectives, including strict preference, equality of importance, and incomparability between pairs of objectives [87]. An elicitation algorithm was also proposed to assist a human DM to construct a coherent overall preference model, which is then combined with NSGA-II to obtain a subset of PF. Brockhoff et al. utilized two preference articulation approaches in the interactive W-HypE [88]. One is to let the DM choose the most preferred solution from a set of alternative solutions (this approach belongs to \u201cSolution comparison-based approaches\u201d, see the next subsection). The other approach uses comparative preference statements, such as \u201cprefer f1 < 0.5 to f2 < 0.3\u201d [88]. This information is then transformed to parameters in the objective space density function used by W-HypE [68]. Preference information was provided by an objective pairwise comparison matrix and combined with fuzzy measure and fuzzy integral in [89]. This preference is coupled with multi-objective particle swarm optimization [89] and multi-objective quantum-inspired evolutionary algorithm [32]."}, {"heading": "2.2.6. Solution comparison-based approaches", "text": "Solution comparison is often used in interactive MOMHs where the DM does pairwise comparison, rank or grade a sample of representative solutions, or choose the best (and/or worst) solution(s) in a sample set. This information will guide the search to preferred part of the PF.\nPhelps and Ko\u0308ksalan proposed an interactive evolutionary metaheuristic for multi-objective combinatorial optimization [90]. They assumed a linear value function and used the DM\u2019s pairwise comparisons to determine the most discriminating function compatible with the preferences. A more flexible algorithm [91] was introduced by them for all cases between the two extremes of perfect information and no information. If the utility function of the DM is known precisely, the algorithm will result in the optimum for that function; if no preference information is given, the algorithm will find the whole PF.\nFowler et al. adopted a general quasi-concave utility function to represent the DM preferences [92]. The best and worst solutions in the sample set are selected by the DM and used to create convex preference cones in the objective space, which are utilized to identify inferior solutions. The Necessary-preference-enhanced Evolutionary multi-objective Optimizer (NEMO-I) [93] presented by Branke et al. is a combination of interactive evolutionary multi-objective optimization with\nrobust ordinal regression (ROR). At regular interactions, the DM is asked to compare some pairs of solutions in the current population. The whole set of additive value functions compatible with this preference information is utilized and integrated in a modified version of NSGA-II. To reduce the computational complexity, which is a main shortcoming of NEMO-I, the authors proposed NEMOII [94] which compares each solution to all other solutions as a set, instead of pairwise comparison. While NEMO-I and NEMO-II both consider whole sets of value functions compatible with the preference information, NEMO-0 [95] uses only the most representative value function. Similar preference model is used in PI-EMO-VF [96]. Once a most discriminating value function has been identified, it is combined in a new domination principle as well as a preference-based termination criterion. Sinha et al. proposed interactive EMO algorithm based on polyhedral cone (PI-EMOPC) [97], in which the cone is constructed according to DM\u2019s best selection in a set of alternative solutions, and it is used to eliminate a part of the search space for a more focused search. The construction and application of the polyhedral cone were extended for interval MOPs in [98].\nDominance-based Rough Set Approach (DRSA) is an MCDM approach based on \u201cif..., then...\u201d rules deduction [99]. It has been integrated in interactive EMO [100], where two schemes were proposed to collect user preference. One is to make the DM sort some solutions into \u201crelatively good\u201d and \u201cothers\u201d, the other requires pairwise comparison among representative solutions. Then, a set of decision rules is induced and used for ranking solutions in the current population.\nSome researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].\nCruz-Reyes et al. introduced the Hybrid-MultiCriteria Sorting Genetic Algorithm (H-MCSGA) [106], in which the selective pressure based on dominance is strengthened by assigning solutions into ordered categories. A reference set of solutions belonging to different categories is kept and updated to capture the preferences. The goal of this method is to find non-dominated solutions belonging to the best category.\nSolution comparison can also be incorporated with Pareto memetic algorithm [107], MOEA/D [108] and Indicator-based MOEA [109, 110]."}, {"heading": "2.2.7. Outranking-based approaches", "text": "An outranking relation is a binary relation S defined on the set of potential solutions (also called actions) A such that aSb if there are enough arguments to decide that a is at least as good as b, whereas there is no essential argument to refuse that statement [111]. Outranking relation is widely investigated in the MCDM field.\nFernandez et al. proposed a Non-outranking Sorting Genetic Algorithm (NOSGA) [112] to consider a binary fuzzy preference relation that expresses the degree of truth of predicate \u201cx is at least as good as y\u201d. Pareto dominance is replaced by outranking relation and it searches for the non-strictly outranked frontier which is a subset of the PF. The method is extended to increase the selective pressure towards the best compromise solution later in NOSGA-II [113]. A hybrid evolutionary simulated annealing (HESA) [114] was designed to improve Evolutionary Algorithm Based on an Outranking Relation (EvABOR) [115]. The DM\u2019s preferences are elicited and exploited using the principles of the outranking-based ELECTRE TRI method."}, {"heading": "2.2.8. Knee point-based approaches", "text": "Knee points of PF are characterized by the fact that a small improvement in one objective will arouse a large deterioration in other objectives. It is similar to trade-off-based approaches, but\nin trade-off-based approaches the trade-off constraint is explicitly provided by the DM, while in knee point-based approaches, no explicit preference is given, knee point (point with the maximal trade-off) is regarded as the most preferred by the DM.\nBechikh et al. proposed KR-NSGA-II [116] based on R-NSGA-II [40], in which mobile reference points are used to modify crowding distance in the traditional NSGA-II. In each generation, knee points in the current population are found and serve as reference points, the method can be used both a-priori and interactively. TKR-NSGA-II[117] is an enhanced version of KR-NSGA-II[116] where the approach to find knee points has been improved."}, {"heading": "3. Introduction to Ontologies", "text": "Ontologies are content theories (i.e., theories that explain the specific factors that motivate behavior) about the sorts of objects, properties of objects, and relations between objects that are possible in a specified domain of knowledge [118]. First addressed by the Knowledge Acquisition Community and aimed at \u201cknowledge modeling\u201d, ontology design and engineering is now an important research and application topic in many domains, such as the Semantic Web, knowledge management, e-Learning, e-Commerce, etc. The most widely accepted definition of ontology in this context is given by Gruber [119]: \u201cAn ontology is a formal explicit specification of a shared conceptualization for a domain of interest.\u201d It is formal logic-based, allowing for mathematical treatment and computational processing. It has explicit specification, because concepts, properties, functions and axioms are explicitly defined. It is shared with standard annotations, aiming at representation of consensual knowledge. In essence, it is conceptualization, or abstract model of some phenomena in the world.\nIn February 2004, the World Wide Web Consortium (W3C) announced the final approval of two key Semantic Web technologies. One of them is the Web Ontology Language (OWL) [120]. It makes use of the eXtensible Markup Language (XML) for the definition of text-based documents syntax/structure, by means of tags that can be added to parts of the text documents, promoting interoperability between applications that exchange machine-comprehensible information.\nOWL-DL (Description Logics) is a widely used sub-language of OWL. One of its key features is the capability of being processed by a reasoner. An OWL-DL ontology was built for the PMOMH knowledge domain and will be presented in the next sections of this paper.\nProte\u0301ge\u0301 is a free, open-source platform, which serves a growing number of users to construct domain models and knowledge-based applications with ontologies [20]. It was developed and maintained by Stanford Center for Biomedical Informatics Research (BMIR) and now has more than 300 thousand registered users. People from different backgrounds can publish and import OWL ontologies for research freely.\nAccording to Noy [121], the reasons to develop an ontology are given below: (1) To share common understanding of the structure of information among people or software agents. It is of high value and interest in a knowledge domain to share and use the same underlying ontology. Additionally, computer agents can extract and aggregate information from different sources, answer more complex user (or other computer systems) queries, as well as providing or using as input each others\u2019 knowledge basis. As PMOMH connects MCDM and MOMH communities, there are plenty of relevant shared concepts and relations between concepts in these domains. Hence, ontology can help to define a machine-interpretable vocabulary in this domain, based on which reasoning and further analysis can be done.\n(2) To enable reuse of domain knowledge. This is one of the main benefits of developing an ontology. If one group of researchers develops an ontology, others can reuse, compose and extend it for their domains. For example, PMOMH domain includes concepts such as preference information (including reference points, reference direction, etc.), MOPs and MOMHs. Preference information can be reused in MCDM community and detailed concepts in MOMHs or MOEAs can also be of interest in research domains of (single objective) metaheuristics or evolutionary algorithms.\n(3) To make domain assumptions explicit. Explicit specifications of domain knowledge are useful for new researchers who must learn the concepts and relations in the domain. In the scientific literature there are often synonyms such as reference point, reference vector and goal vector, they can be defined as identical individuals in the ontology to avoid confusion.\n(4) To separate domain knowledge from the operational knowledge. In some sense developing an ontology is like defining a set of data and their structure for other users or softwares to use. Different types of users, domain-independent applications and software agents use ontologies as input data. For instance, the PMOMH ontology might serve an automatic text-mining or literature retrieval system to understand the meaning of certain concepts or words (e.g., to identify synonyms or subsumption of keywords).\n(5) To analyze domain knowledge. Usually an ontology is not the ultimate goal in itself. More useful information can be gained by analyzing the ontology. By building the PMOMH ontology we can easily analyze what kind of preferences have been integrated in what kind of MOMH, through what kind of integration. We can also query for methods that can deal with a specific kind of problem, or find potential combinations of MCDM and MOMH for future research. One possible use is to extract building blocks that can be used as operators within different kinds of MOMHs and design new PMOMHs.\nThere are various ontology applications in different fields, such as Recommender Systems, eLearning, e-Commerce, Semantic Interoperability, Bioinformatics, etc. As far as we know, Evolutionary Computation (EC) ontology [19] and diversity-oriented optimization ontology [18] have been proposed recently, and their contributions were considered in the design of the PMOMH ontology. An ontology of preference-based multi-objective evolutionary algorithms (PMOEAs) was built and basic query examples were given [122]. In this paper we extend and improve the ontology, and provide more use cases to demonstrate the benefits of the provided ontology."}, {"heading": "4. Building the PMOMH Ontology", "text": "We follow a bottom up (or inductive) approach to build the ontology, by first looking at the existing work (as Section 2 does) and then structuring it into an ontology. An OWL ontology consists of classes, properties (including object properties and data properties) and individuals. For the sake of readability, in the remaining of this paper, class names are written in a font like this, object property names are in a font like this, data property names are in a font like this, individual names are in a font like this.\nA class describes a group of concepts with the same properties in the domain. For example, MOMH is the class of multi-objective metaheuristics. A class can have subclasses that represent concepts more specific than the superclass. For example, PMOMH is a subclass of MOMH which uses preferences to focus the search on preferred parts of the PF. Subclasses inherit all the properties of superclasses. An object property is a binary relation to relate classes or individuals. For instance, canSolve is an object property that can relate MOMH and MOP, which indicates the capability of one specific MOMH with regard to solving one specific problem. A data property\nrelates classes or individuals with a designed primitive data-type (e.g., integer, boolean, etc). For example, hasPublishingYear is a data property of MOMH with datatype \u201cinteger\u201d. Individuals represent objects, or class instances in the domain of interest, for instance R-NSGA-II [40] is an individual of PMOMH.\nAs suggested by Noy [121], there is no one \u201ccorrect\u201d way for developing ontologies. However, the guidelines provided in [121] represent a generalized set of steps, widely accepted in this area, which are adopted by us and presented in detail next."}, {"heading": "4.1. Determine the domain and scope of the ontology", "text": "The ontology we built addresses preference-based multi-objective metaheuristics, or PMOMHs. They utilize the preference information provided by the DM, a-priori or interactively, to guide the search towards the interesting parts of the PF instead of searching for the whole set.\nAccording to [123], at least two possible ways of integrating EMO and MCDM can be identified: \u201cevolutionary algorithm in MCDM\u201d and \u201cMCDM in EMO\u201d approaches. The former follows the main procedure of MCDM method and utilizes evolutionary algorithms to get intermediate solutions (such as PIE [123]), the latter, \u201cMCDM in EMO\u201d, or \u201cMCDM in MOMH\u201d more broadly, was the main scope in our study.\nWe collected related literature on this topic (see Table 6), analyzed it and derived the important features to form an ontology. In addition to concepts and knowledge representation from PMOMH itself, the ontology also intends to provide support for questions like \u201cWhat methods can deal with a specific type of problem?\u201d, \u201cWhat is the implementation language of that algorithm?\u201d, etc. Therefore, detailed knowledge related to MOP, as well as optimization software frameworks are also considered in the ontology."}, {"heading": "4.2. Consider using the existing ontologies", "text": "As far as we know, Evolutionary Computation (EC) Ontology [19], Diversity-Oriented Optimization Ontology [18] and Semantic MCDM (SeMCDM) [124] are related to the PMOMH ontology to some extent. Because they were designed with strong focus on specific domain knowledge operationalization, we can not reuse them directly, but some common concepts and vocabularies can still be adopted.\nSince the PMOMH, EC, SeMCDM and Diversity-Oriented Optimization ontologies define and use a subset of common concepts, this overlapping knowledge was taken into account in the PMOMH ontology design in two ways. The first way is to adopt the same naming for identical concepts, such as hasAuthor, hasPublishingYear, canSolve, UtilityFunction. The other way is to specify the relations between them using OWL relations: owl:sameAs, owl:equivalentProperty and owl:equivalentClass, to map identical individuals, properties and classes between ontologies, respectively. For example, SetQualityIndicator of the PMOMH ontology is owl:equivalentClass to Indicator of Diversity-Oriented Optimization Ontology."}, {"heading": "4.3. Enumerate important terms in the ontology", "text": "It is important to make a comprehensive list of terms related to the PMOMH domain, without thinking of the overlap between some concepts. They are modeled as classes and properties in the next three sections."}, {"heading": "4.4. Define the classes and the class hierarchy", "text": "The classes and class hierarchy of our ontology include the following, all of them are extendable if needed:\nMetaHeuristic class (Fig. 1) has MOMH (multi-objective metaheuristics) and SOMH (singleobjective metaheuristics) as subclasses. Preference based is the class of PMOMH. It is a subclass of MOMH. Other subclasses of MOMH include Pareto basedMOEA, Indicator basedMOEA, Decomposition basedMOEA, ParticleSwarmOptimization based, Coevolution based, Memetic basedMOEA, HybridMOEA, SimulatedAnnealing based, DifferentialEvolution based, TabuSearch based, AntColonyOptimization based, ArtificialImmuneSystem based . Note that there can be overlaps between classes, one individual can belong to several classes such as hybridMOEA individuals may also belong to, for example ParticleSwarmOptimization based or ArtificialImmuneSystem based. In order to keep the design transparent we opted for a flat structure. If a combination is not allowed, it can be added as a constraint using the \u201cdisjoint with\u201d property. One important property to link PMOMH and the other MOMH subclasses is hasSearchAlgorithm (can be found in Table 1), which indicates the searching method used by the PMOMH.\nMOP is the class of multi-objective optimization problem. Subclasses include Academic Problem and Realworld Problem. Academic Problem has subclasses DTLZ, Knapsack, WFG, ZDT, UF.\nInteractionTime class indicates the moment when the DM interacts with the optimization process, where a-priori, a-posteriori and progressive are individuals.\nPreferenceInformationFromDM class (Fig. 2) refers to the information provided by the DM to express his/her preferences. Subclasses include BudgetofDMcalls, SolutionComparison (SampleGrades, SampleRanks and SampleSorts are subclasses), ReferencePoint, PreferenceRegion (DesirabilityFunction and DistributionFunctionInObjectiveSpace are subclasses), ReferenceDirection,\nTrade-off, ObjectiveComparison, OutrankingParameters, ProblemSpecific. PreferenceIntegration class (Fig. 3) defines how the preference information is integrated in the search method, i.e., what is modified in the searching algorithm to accommodate preferences. Subclasses are the following: AlgorithmDependentComponents (such as crowding distance in NSGA-II, weights in MOEA/D), DominanceRelation, Objectives, SetQualityIndicator, Constraints, TerminationCriterion, Selection, Crossover, Mutation, Fitness, FrontSorting, Initialization.\nPreferenceModel class (Fig. 4) specifies the preference model used in the PMOMH. It is strongly related to PreferenceInformationFromDM, but it focuses on the internal model utilized by the al-\ngorithm, which DM does not care or know. PreferenceModel subclasses include AchievementScalarizingFunction, FuzzyLogic, DecisionRules, OutrankingRelation, PolyhedralConeBased, UtilityFunction (which has Linear, AdditivePiecewiseLinear, GeneralAdditive, ChoquetIntegral, Polynomial, Quasiconcave, Tchebycheff, Exponential as subclasses), PreferenceRegion ( DesirabilityFunction and WeightFunctionInObjectiveSpace are subclasses), LightBeamSearch, ReferencePointModel, KneePoint.\nLearningMethod class is used to indicate the learning method of some PMOMHs (usually interactive PMOMHs) for predicting the DM\u2019s preferences. LearningMethod subclasses include OrdinalRegression, LinearProgramming, QuadraticProgramming, SupportVectorMachine, NeuralNetwork, SuperisedLearning.\nResultType class defines the type of the result, which can be classified as OneSolution and SetOfSolutions. BiasedDistribution and PartialRegion are individuals of SetOfSolutions.\nResearcher class specifies the authors of the PMOMH papers. ImplementationLibrary class indicates the library or framework used by metaheuristics, such as jMetal, KanGAL, PISA, MOEAFramework. ProgrammingLanguage class specifies the language used for implementation."}, {"heading": "4.5. Define the relations between classes (Object Properties)", "text": "Object properties are binary relations on individuals (of classes), they determine how the classes are related to each other. For example, in the assertion \u201c R-NSGA-II hasPreferenceInformationFromDM ReferencePoint\u201d, hasPreferenceInformationFromDM is an object property whose domain is PMOMH and range is PreferenceInformationFromDM, indicating this property is from class PMOMH to class PreferenceInformationFromDM, not the other way around. The main object properties in our ontology are listed in Table 1. Note that one individual can be related to several individuals with the same object property, such as \u201c R-NSGA-II hasPreferenceInformationFromDM ReferencePoint\u201d and \u2018\u2018 R-NSGA-II hasPreferenceInformationFromDM weights\u201d hold at the same time.\nOntoGraf [125] is a (Prote\u0301ge\u0301 plugin) visualization tool that allows visual, interactive navigation of the relationships in OWL ontologies. As Fig.5 shows, all the classes that are related to PMOMH are rectangles and object properties are lines connecting the rectangles."}, {"heading": "4.6. Define the properties of classes (Data Properties)", "text": "Data properties link an individual to an XML Schema Datatype value or an RDF literal. In other words, they describe relationships between an individual and data values. For example, hasPublishingYear is a data property of R-NSGA-II with data type \u201dinteger\u201d, which indicates the year when R-NSGA-II was published. The main data properties defined in our ontology are listed in Table 2.\nThere are three data properties that describe the characteristics of PMOMH: hasMultipleRegionOfInterest indicates whether the method offers DM the ability to obtain more than one ROI in one run; hasSpreadControl describes whether the method allows the DM to control the spread of the obtained ROI; preservesParetoDominance shows whether the method preserves the order induced by Pareto dominance. These are important properties of PMOMH, which are also examined in [12]."}, {"heading": "4.7. Create Individuals", "text": "Individuals of PMOMH are algorithms named after the original paper or abbreviations of the method. We created every PMOMH individual by reading the paper and answering the following questions (answers are used for property in the parentheses):\n(1) What preference information should the DM provide? (hasPreferenceInformationFromDM) (2) When should s/he provide the preference information? (hasInteractionTime) (3) What is the preference model of this algorithm? (hasPreferenceModel) (4) Which MOMH is used in this method? (hasSearchAlgorithm) (5) How is the preference information integrated in the searching algorithm? (hasPreferenceIntegration) (6) If there is a learning method in this algorithm, what is it? (hasLearningMethod) (7) What type of result is obtained by the algorithm: one solution or set of solutions? (hasResultType) (8) Who introduced this algorithm and when? (hasAuthor, hasPublishingYear) (9) What problems are tested in the simulation experiments by this algorithm? (canSolve) (10) Can the algorithm deal with multiple ROI in one run? (hasMultipleRegionOfInterest) (11) Does the algorithm have spread control methodology if its result is part of the PF?\n(hasSpreadControl)\n(hasExtension, hasInteractiveVersion) (15) What library and programming language are used to implement this algorithm? (useLibrary, useLanguage) Fig.6 presents R-NSGA-II [40] as an example of PMOMH individual. Individuals of MOP, another important class in the proposed PMOMH ontology, were created by describing their data properties as shown in Table 2. Table 3 shows individual numbers of the most relevant classes in the current PMOMH ontology."}, {"heading": "4.8. Publish and reuse", "text": "We have uploaded our ontology into the WebProte\u0301ge\u0301 (http://webprotege.stanford.edu/ #Edit:projectId=8c2f9a29-82ff-4f4b-9d56-676741213d66). WebProte\u0301ge\u0301 is an ontology de-\nvelopment environment that makes it easy to create, upload, modify and share ontologies for collaborative viewing and editing. Interested researchers and other professionals can view, comment, edit (after permission) and download the ontology for reuse and research."}, {"heading": "5. Using the PMOMH Ontology", "text": "Since an ontology has been created, a lot of knowledge management tasks can be performed using the ontology together with other tools such as reasoners, DL Query and visualization tools. Reasoners can check the consistency of an ontology, perform subsumption checking (check if a concept is a subset of another concept) and infer relations that are not explicitly given by the user. DL Query is another important feature of Prote\u0301ge\u0301, which can help to access, analyze and explore the knowledge domain described in the ontology. Examples of reasoning and query are available in [122]. Based on these functions, we can use the PMOMH ontology for different purposes, which are given next."}, {"heading": "5.1. Finding the right method for an application", "text": "Application to real world problems is the ultimate goal of developing various PMOMHs. Different problems have diverse characteristics such as type of the decision variables used, e.g., continuous/discrete; or number of objectives, e.g., multi- or many-objectives; or shape of PF, e.g., convex, concave, disconnected. PMOMH ontology can help to find methods that suit a specific problem.\nFor example, a satellite task scheduling problem requires to optimize the execution plan for the satellite in order to achieve certain objectives. It can be modeled as a multi-objective combinatorial optimization problem similar to the well-known knapsack problem. The objectives to consider are maximizing the total profit and minimizing the total cost. If the DM would like to use pairwise comparison as preference articulation, then we can search the PMOMH ontology for a feasible algorithm for this problem. Fig. 7 shows that iPMA [107], IEM-CO [90] and EMAPS [91] have pairwise comparison as preference articulation and solve discrete problems in the experiment, which are reasonable suggestions for our application problem. We do not assume that other PMOMHs can not solve the satellite scheduling problem, but recommend the indicated approaches since they are easy to apply with regard to the specified preference type and problem type."}, {"heading": "5.2. Bibliomatric Analysis", "text": "Bragge et al. conducted bibliomatric analysis on Multiple Criteria Decision Making/Multiattribute Utility Theory (MCDM/MAUT) [126]. The statistical analysis shows the change in the number of publications over time, top-20 lists of countries, authors, journals, presenting a \u201cbig picture\u201d of MCDM/MAUT. Similar analysis can be conducted on PMOMH domain with the help of ontology. Fig. 8 shows the publishing year distribution of 86 PMOMH individuals. Table 4 and Table 5 reveal the top-5 most cited PMOMH individuals and top-5 researchers ranked by number of published PMOMH individuals regarding the 86 PMOMH individuals in the ontology."}, {"heading": "5.3. Reviewing and Research Assessment", "text": "With the help of DL Query, researchers can easily review and access the existing works. For example, they can find out whether a preference model or integration method has been applied before, which papers compared their developed method(s) to one specified method (e.g., who compared their proposed method with R-NSGA-II[40]?) They can query for methods that used one specific benchmark problem (e.g., ZDT1) if they want to compare results on the same problem. They can also query for relations of algorithms (e.g., extension and interactive version) or search for algorithms that use the same preference information (e.g., reference point)."}, {"heading": "5.4. Classification", "text": "There are various criteria to classify the PMOMHs, e.g., interaction time, preference information, search algorithm, to name a few. Prote\u0301ge\u0301 can add the results of a query to new classes, thus making classification easy and flexible. For example, we can query for PMOMHs that use reference point as preference information and add the results to a new class ReferencePoint-based PMOMH, which is a subclass of PMOMH. Any PMOMH to be added in the future that uses reference point will be automatically sorted into this subclass. Table 6 shows one classification of PMOMHs based on preference information and searching algorithms."}, {"heading": "5.5. Identification of promising research areas", "text": "Blank cells in the Table 6 may be identified as future research topics, to integrate preference articulation with MOMHs that such combination has not been considered before. Integration method and preference model can also be queried to find potential combinations. We can also notice the following:\n\u2022 Not all the MCDM methods are included in this ontology. Classification of objective functions, for example, is one category of interactive MCDM methods [79]. At each interaction phase, the DM is shown the current Pareto optimal solution and asked to classify the objectives into several categories, i.e., whose values should be improved (till some desired aspiration level), whose values can be impaired (till some upper bound), whose values are temporarily allowed to change freely. This kind of MCDM method has not been integrated in MOMH, which can be a topic to consider in the future.\n\u2022 Some PMOMH individuals have interactive version (such as W-HypE [33] and iW-HypE [88]) while some do not. In theory all a-priori methods can be converted into a progressive method if the preference information changes during the search. By interaction with the algorithm, the DM can better understand the problem and give more precise preference information. For example, a preference region can be used at early stages of the optimization to focus the search within this region. After interaction the DM may change the preference articulation to a precise reference point. New algorithms are needed to handle combined preference articulation.\n\u2022 Some PMOMH individuals use a new dominance relation to integrate preferences, such as g-dominance [37], r-dominance [38]. There are 13 DominanceRelation individuals in the PMOMH ontology, they can be coupled with any other MOMHs without changing the main structure of the algorithm, thus new algorithms can be designed.\n\u2022 Some PMOMH individuals were proposed based on the same preference information, for example reference point. A performance metric is needed to compare different algorithms with the same preference articulation. Related works can be found in [134, 135], which are all related to reference point-based approaches, other preference models should also be considered."}, {"heading": "5.6. Maintenance and Extension", "text": "The PMOMH ontology offers a structure, and is open for new classes/individuals to be added with the development of MCDM and MOMH fields. In WebProte\u0301ge\u0301 users can easily edit (e.g., revise properties, add comments), create (new individuals/classes/properties), delete (wrong/redundant individuals/classes/properties) and download the ontology (OWL file). For example, people may reckon that Decomposition basedMOEA should be named Aggregation basedMOEA as in [136], this can be added as a comment to the class. With the discussion and collaboration of researchers\nfrom the related domains, the ontology will be more trustworthy and robust. The value of the proposed ontology increases with the progressive accumulation of more information. MOMH researchers can help to extend the MOMH classes, MCDM researchers can assist with the preference information/model classes, MOP class can also be extended by adding more practical engineering applications. In a nutshell, PMOMH ontology helps to bring together researchers of different fields as well as practitioners who use the ontology. It provides a knowledge sharing platform for both academic research and real-world application."}, {"heading": "6. Conclusion", "text": "Preference-based multi-objective metaheuristics, or PMOMH, which combine MOMH and MCDM fields, are addressed in this paper. We proposed a novel method to systematize and manage the current knowledge in this field, by means of ontology design and engineering. For the first time, an ontology was designed and used in this field, showing high benefits and advantages for knowledge management in the MOMH and MCDM domains. After providing an overview of PMOMHs, we presented the process for building the PMOMH ontology using Prote\u0301ge\u0301, introduced typical use cases, including application-method matching, bibliomatric analysis, research assessment and new research opportunities discovery. The result of this article is representing the knowledge in a formal, computer-readable, way. This will allow other researchers to state specific queries. Moreover, we view the ontology as an evolving system and want to encourage integration of future research results.\nIt is believed that, the more attention and information PMOMH ontology attracts, the higher its value will be, not only for the research communities of MOMH and MCDM, but also for practitioners who are using the PMOMHs. Therefore, reuse and extension of the proposed PMOMH ontology are welcome to help its growth. In the future, new MCDM, MOMH and PMOMH individuals will be added to the ontology when they are found important. Meanwhile, benchmarks of practical applications, implementation source codes of PMOMHs will be collected and considered.\nAcknowledgement:. Longmei Li acknowledges financial support from China Scholarship Council (CSC). Heike Trautmann and Michael Emmerich acknowledge support by the European Research Center for Information Systems (ERCIS)."}], "references": [{"title": "A hybrid framework for evolutionary multi-objective optimization", "author": ["K. Sindhya", "K. Miettinen", "K. Deb"], "venue": "Evolutionary Computation, IEEE Transactions on 17 (4) ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonlinear multiobjective optimization", "author": ["K. Miettinen"], "venue": "Vol. 12, Springer Science & Business Media", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Multiobjective decision making: theory and methodology", "author": ["C. Vira", "Y.Y. Haimes"], "venue": "no. 8, North-Holland", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1983}, {"title": "Evolutionary algorithms for solving multi-objective problems", "author": ["C.C. Coello", "G.B. Lamont", "D.A. Van Veldhuizen"], "venue": "Springer Science & Business Media", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-objective optimization using evolutionary algorithms", "author": ["K. Deb"], "venue": "Vol. 16, John Wiley & Sons", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2001}, {"title": "Multi-objective meta-heuristics: An overview of the current state-of-the-art", "author": ["D.F. Jones", "S.K. Mirrazavi", "M. Tamiz"], "venue": "European journal of operational research 137 (1) ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2002}, {"title": "Guest editorial: Special issue on preference-based multiobjective evolutionary algorithms", "author": ["K. Deb", "M. K\u00f6ksalan"], "venue": "IEEE Transactions on Evolutionary Computation 14 (5) ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "Multiobjective optimization: interactive and evolutionary approaches", "author": ["J. Branke", "K. Deb", "K. Miettinen", "R. Slowi\u0144ski"], "venue": "Vol. 5252, Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Handling preferences in evolutionary multiobjective optimization: A survey", "author": ["C.A.C. Coello"], "venue": "in: Evolutionary Computation, 2000. Proceedings of the 2000 Congress on, Vol. 1, IEEE", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Preference incorporation in multi-objective evolutionary algorithms: A survey", "author": ["L. Rachmawati", "D. Srinivasan"], "venue": "in: Evolutionary Computation, 2006. CEC 2006. IEEE Congress on, IEEE", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2006}, {"title": "Consideration of partial user preferences in evolutionary multiobjective optimization", "author": ["J. Branke"], "venue": "in: Multiobjective optimization, Springer", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Chapter four-preference incorporation in evolutionary multiobjective optimization: A survey of the state-of-the-art", "author": ["S. Bechikh", "M. Kessentini", "L.B. Said", "K. Gh\u00e9dira"], "venue": "Advances in Computers 98 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "MCDA and multiobjective evolutionary algorithms", "author": ["J. Branke"], "venue": "in: Multiple Criteria Decision Analysis, Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "A review of hybrid evolutionary multiple criteria decision making methods", "author": ["R.C. Purshouse", "K. Deb", "M.M. Mansor", "S. Mostaghim", "R. Wang"], "venue": "in: Evolutionary Computation (CEC), 2014 IEEE Congress on, IEEE", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Metaheuristic design pattern: Preference", "author": ["H.J. Aljawawdeh", "C.L. Simons", "M. Odeh"], "venue": "in: Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation, ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Handbook on ontologies", "author": ["S. Staab", "R. Studer"], "venue": "Springer Science & Business Media", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "S", "author": ["D. Chaudhary", "P.K. Yadav", "R.K. Singh"], "venue": "Mishra, et al., Enriching the knowledgebase using unification techniques, in: Communication and Computing ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "A survey of diversity-oriented optimization", "author": ["V. Basto-Fernandes", "I. Yevseyeva", "M. Emmerich"], "venue": "EVOLVE 2013-A Bridge between Probability, Set Oriented Numerics, and Evolutionary Computing (2013) ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Evolutionary computation ontology: E-learning system", "author": ["G. Kaur", "D. Chaudhary"], "venue": "in: Reliability, Infocom Technologies and Optimization (ICRITO)(Trends and Future Directions), 2015 4th International Conference on, IEEE", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Structural design using multi-objective metaheuristics", "author": ["G. Zavala", "A.J. Nebro", "F. Luna", "C.A.C. Coello"], "venue": "comparative study and application to a real-world problem, Structural and Multidisciplinary Optimization 53 (3) ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Multiobjective evolutionary algorithms: A survey of the state of the art", "author": ["A. Zhou", "B.-Y. Qu", "H. Li", "S.-Z. Zhao", "P.N. Suganthan", "Q. Zhang"], "venue": "Swarm and Evolutionary Computation 1 (1) ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "A fast and elitist multiobjective genetic algorithm: NSGA-II", "author": ["K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan"], "venue": "Evolutionary Computation, IEEE Transactions on 6 (2) ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2002}, {"title": "L", "author": ["E. Zitzler", "M. Laumanns", "L. Thiele", "E. Zitzler", "E. Zitzler", "L. Thiele"], "venue": "Thiele, SPEA2: Improving the strength Pareto evolutionary algorithm ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2001}, {"title": "SMS-EMOA: Multiobjective selection based on dominated hypervolume", "author": ["N. Beume", "B. Naujoks", "M. Emmerich"], "venue": "European Journal of Operational Research 181 (3) ", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2007}, {"title": "HypE: An algorithm for fast hypervolume-based many-objective optimization", "author": ["J. Bader", "E. Zitzler"], "venue": "Evolutionary computation 19 (1) ", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "R2-EMOA: Focused multiobjective search using R2-indicator-based selection", "author": ["H. Trautmann", "T. Wagner", "D. Brockhoff"], "venue": "in: Learning and Intelligent Optimization, Springer", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2013}, {"title": "A portfolio optimization approach to selection in multiobjective evolutionary algorithms", "author": ["I. Yevseyeva", "A.P. Guerreiro", "M.T. Emmerich", "C.M. Fonseca"], "venue": "in: International Conference on Parallel Problem Solving from Nature, Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "MOEA/D: A multiobjective evolutionary algorithm based on decomposition", "author": ["Q. Zhang", "H. Li"], "venue": "Evolutionary Computation, IEEE Transactions on 11 (6) ", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "An evolutionary many-objective optimization algorithm using referencepoint-based nondominated sorting approach", "author": ["K. Deb", "H. Jain"], "venue": "part i: Solving problems with box constraints, IEEE Transactions on Evolutionary Computation 18 (4) ", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "An investigation on preference order ranking scheme for multiobjective evolutionary optimization", "author": ["F. Di Pierro", "S.-T. Khu", "D.A. Savic"], "venue": "Evolutionary Computation, IEEE Transactions on 11 (1) ", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}, {"title": "Preference-based solution selection algorithm for evolutionary multiobjective optimization", "author": ["J.-H. Kim", "J.-H. Han", "Y.-H. Kim", "S.-H. Choi", "E.-S. Kim"], "venue": "Evolutionary Computation, IEEE Transactions on 16 (1) ", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Articulating user preferences in many-objective problems by sampling the weighted hypervolume", "author": ["A. Auger", "J. Bader", "D. Brockhoff", "E. Zitzler"], "venue": "in: Proceedings of the 11th Annual conference on Genetic and evolutionary computation, ACM", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2009}, {"title": "The use of reference objectives in multiobjective optimization", "author": ["A.P. Wierzbicki"], "venue": "in: Multiple criteria decision making theory and application, Springer", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1980}, {"title": "P", "author": ["C.M. Fonseca"], "venue": "J. Fleming, et al., Genetic algorithms for multiobjective optimization: Formulation discussion and generalization., in: ICGA, Vol. 93, Citeseer", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1993}, {"title": "An evolutionary algorithm with advanced goal and priority specification for multi-objective optimization", "author": ["K.C. Tan", "E.F. Khor", "T.H. Lee", "R. Sathikannan"], "venue": "Journal of Artificial Intelligence Research ", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "A", "author": ["J. Molina", "L.V. Santana"], "venue": "G. Hern\u00e1ndez-D\u0131\u0301az, C. A. C. Coello, R. Caballero, g-dominance: Reference point based dominance for multiobjective metaheuristics, European Journal of Operational Research 197 (2) ", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2009}, {"title": "The r-dominance: a new dominance relation for interactive evolutionary multicriteria decision making", "author": ["L. Ben Said", "S. Bechikh", "K. Gh\u00e9dira"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (5) ", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2010}, {"title": "Preference incorporation to solve manyobjective airfoil design problems", "author": ["A.L. Jaimes", "A.A. Montano", "C.A.C. Coello"], "venue": "in: Evolutionary Computation (CEC), 2011 IEEE Congress on, IEEE", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}, {"title": "Reference point based multi-objective optimization using evolutionary algorithms", "author": ["K. Deb", "J. Sundar"], "venue": "in: Proceedings of the 8th annual conference on Genetic and evolutionary computation, ACM", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2006}, {"title": "Finding a preferred diverse set of Pareto-optimal solutions for a limited number of function calls", "author": ["F. Siegmund", "A.H. Ng", "K. Deb"], "venue": "in: 2012 IEEE Congress on Evolutionary Computation, IEEE", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "Synchronous R-NSGA-II: an extended preferencebased evolutionary algorithm for multi-objective optimization", "author": ["E. Filatovas", "O. Kurasova", "K. Sindhya"], "venue": "Informatica 26 (1) ", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2015}, {"title": "Bipolar preferences dominance based evolutionary algorithm for many-objective optimization", "author": ["Q. Fei-yue", "W. Yu-shi", "W. Li-ping", "J. Bo"], "venue": "in: 2012 IEEE Congress on Evolutionary Computation, IEEE", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2012}, {"title": "A preference-based evolutionary algorithm for multiobjective optimization: the weighting achievement scalarizing function genetic algorithm", "author": ["A.B. Ruiz", "R. Saborido", "M. Luque"], "venue": "Journal of Global Optimization 62 (1) ", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2015}, {"title": "An interactive evolutionary multiobjective optimization method: Interactive WASF-GA", "author": ["A.B. Ruiz", "M. Luque", "K. Miettinen", "R. Saborido"], "venue": "in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2015}, {"title": "Reference point based multi-objective optimization through decomposition", "author": ["A. Mohammadi", "M.N. Omidvar", "X. Li"], "venue": "in: Evolutionary Computation (CEC), 2012 IEEE Congress on, IEEE", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2012}, {"title": "Integrating user preferences and decomposition methods for many-objective optimization", "author": ["A. Mohammadi", "M.N. Omidvar", "X. Li", "K. Deb"], "venue": "in: 2014 IEEE Congress on Evolutionary Computation (CEC)", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2014}, {"title": "A preference-based evolutionary algorithm for multi-objective optimization", "author": ["L. Thiele", "K. Miettinen", "P.J. Korhonen", "J. Molina"], "venue": "Evolutionary computation 17 (3) ", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2009}, {"title": "An aspiration set EMOA based on averaged hausdorff distances", "author": ["H. Trautmann"], "venue": "in: Learning and Intelligent Optimization: 8th International Conference, Lion 8, Gainesville, FL, USA, February 16-21, 2014. Revised Selected Papers, Vol. 8426, Springer", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2014}, {"title": "Preference articulation by means of the r2 indicator", "author": ["T. Wagner", "H. Trautmann", "D. Brockhoff"], "venue": "in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2013}, {"title": "Reference point-based particle swarm optimization using a steady-state approach", "author": ["R. Allmendinger", "X. Li", "J. Branke"], "venue": "in: Simulated Evolution and Learning, Springer", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2008}, {"title": "Using a distance metric to guide PSO algorithms for manyobjective optimization", "author": ["U.K. Wickramasinghe", "X. Li"], "venue": "in: Proceedings of the 11th Annual conference on Genetic and evolutionary computation, ACM", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "Interactive preferences in multiobjective ant colony optimisation for assembly line balancing", "author": ["M. Chica", "\u00d3. Cord\u00f3n", "S. Damas", "J. Bautista"], "venue": "Soft Computing 19 (10) ", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2015}, {"title": "A visual interactive method for solving the multiple criteria problem", "author": ["P.J. Korhonen", "J. Laakso"], "venue": "European Journal of Operational Research 24 (2) ", "citeRegEx": "54", "shortCiteRegEx": null, "year": 1986}, {"title": "R", "author": ["A. Jaszkiewicz"], "venue": "S  lowi\u0144ski, The Light Beam Search approach\u2013an overview of methodology applications, European Journal of Operational Research 113 (2) ", "citeRegEx": "55", "shortCiteRegEx": null, "year": 1999}, {"title": "Light beam search based multi-objective optimization using evolutionary algorithms", "author": ["K. Deb", "A. Kumar"], "venue": "in: Evolutionary Computation, 2007. CEC 2007. IEEE Congress on, IEEE", "citeRegEx": "56", "shortCiteRegEx": null, "year": 2007}, {"title": "Interactive evolutionary multi-objective optimization and decision-making using reference direction method", "author": ["K. Deb", "A. Kumar"], "venue": "in: Proceedings of the 9th annual conference on Genetic and evolutionary computation, ACM", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "Y", "author": ["X. Ma", "F. Liu", "Y. Qi", "L. Li", "L. Jiao", "X. Deng", "X. Wang", "B. Dong", "Z. Hou"], "venue": "Zhang, et al., Moea/d with biased weight adjustment inspired by user preference and its application on multi-objective reservoir flood control problem, Soft Computing 20 (12) ", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2016}, {"title": "A preference multi-objective optimization based on adaptive rank clone and differential evolution", "author": ["R. Liu", "X. Wang", "J. Liu", "L. Fang", "L. Jiao"], "venue": "Natural Computing 12 (1) ", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2013}, {"title": "Integrating user preferences into evolutionary multi-objective optimization", "author": ["J. Branke", "K. Deb"], "venue": "in: Knowledge incorporation in evolutionary computation, Springer", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2005}, {"title": "Simultaneous optimization of several response variables", "author": ["G. Derringer", "R. Suich"], "venue": "Journal of quality technology 12 (4) ", "citeRegEx": "61", "shortCiteRegEx": null, "year": 1980}, {"title": "The desirability function", "author": ["E. Harrington"], "venue": "Industrial quality control 21 (10) ", "citeRegEx": "62", "shortCiteRegEx": null, "year": 1965}, {"title": "Preference-based Pareto optimization in certain and noisy environments", "author": ["H. Trautmann", "J. Mehnen"], "venue": "Engineering Optimization 41 (1) ", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2009}, {"title": "Preference-based multi-objective particle swarm optimization using desirabilities", "author": ["S. Mostaghim", "H. Trautmann", "O. Mersmann"], "venue": "in: Parallel Problem Solving from Nature, PPSN XI, Springer", "citeRegEx": "64", "shortCiteRegEx": null, "year": 2010}, {"title": "Integration of preferences in hypervolume-based multiobjective 26  evolutionary algorithms by means of desirability functions", "author": ["T. Wagner", "H. Trautmann"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (5) ", "citeRegEx": "65", "shortCiteRegEx": null, "year": 2010}, {"title": "Indicator-based selection in evolutionary multiobjective optimization algorithms based on the desirability index", "author": ["H. Trautmann", "T. Wagner", "D. Biermann", "C. Weihs"], "venue": "Journal of Multi- Criteria Decision Analysis 20 (5-6) ", "citeRegEx": "66", "shortCiteRegEx": null, "year": 2013}, {"title": "The hypervolume indicator revisited: On the design of Pareto-compliant indicators via weighted integration", "author": ["E. Zitzler", "D. Brockhoff", "L. Thiele"], "venue": "in: Evolutionary multi-criterion optimization, Springer", "citeRegEx": "67", "shortCiteRegEx": null, "year": 2007}, {"title": "Directed multiobjective optimization based on the weighted hypervolume indicator", "author": ["D. Brockhoff", "J. Bader", "L. Thiele", "E. Zitzler"], "venue": "Journal of Multi-Criteria Decision Analysis 20 (5-6) ", "citeRegEx": "68", "shortCiteRegEx": null, "year": 2013}, {"title": "Weighted preferences in evolutionary multi-objective optimization", "author": ["T. Friedrich", "T. Kroeger", "F. Neumann"], "venue": "in: AI 2011: Advances in Artificial Intelligence, Springer", "citeRegEx": "69", "shortCiteRegEx": null, "year": 2011}, {"title": "On reference point free weighted hypervolume indicators based on desirability functions and their probabilistic interpretation", "author": ["M.T. Emmerich", "A.H. Deutz", "I. Yevseyeva"], "venue": "Procedia Technology 16 ", "citeRegEx": "70", "shortCiteRegEx": null, "year": 2014}, {"title": "A territory defining multiobjective evolutionary algorithms and preference incorporation", "author": ["\u0130. Karahan", "M. K\u00f6ksalan"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (4) ", "citeRegEx": "71", "shortCiteRegEx": null, "year": 2010}, {"title": "An interactive territory defining evolutionary algorithm: iTDEA", "author": ["M. K\u00f6ksalan", "I. Karahan"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (5) ", "citeRegEx": "72", "shortCiteRegEx": null, "year": 2010}, {"title": "Preference representation using gaussian functions on a hyperplane in evolutionary multi-objective optimization", "author": ["K. Narukawa", "Y. Setoguchi", "Y. Tanigaki", "M. Olhofer", "B. Sendhoff", "H. Ishibuchi"], "venue": "Soft Computing ", "citeRegEx": "73", "shortCiteRegEx": null, "year": 2015}, {"title": "Preference-based NSGA-II for manyobjective knapsack problems", "author": ["Y. Tanigaki", "K. Narukawa", "Y. Nojima", "H. Ishibuch"], "venue": "in: Soft Computing and Intelligent Systems ", "citeRegEx": "74", "shortCiteRegEx": null, "year": 2014}, {"title": "A reference vector guided evolutionary algorithm for many-objective optimization", "author": ["R. Cheng", "Y. Jin", "M. Olhofer", "B. Sendhoff"], "venue": "IEEE Transactions on Evolutionary Computation 20 (5) ", "citeRegEx": "75", "shortCiteRegEx": null, "year": 2016}, {"title": "Whatever works best for you-a new method for a priori and progressive multi-objective optimisation", "author": ["R. Wang", "R.C. Purshouse", "P.J. Fleming"], "venue": "in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "76", "shortCiteRegEx": null, "year": 2013}, {"title": "Preference-based multiobjective optimization using truncated expected hypervolume improvement", "author": ["K. Yang", "L. Li", "A. Deutz", "T. Back", "M. Emmerich"], "venue": "in: Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), 2016 12th International Conference on, IEEE", "citeRegEx": "77", "shortCiteRegEx": null, "year": 2016}, {"title": "A hybrid multiobjective immune algorithm with region preference for decision makers", "author": ["L. Jiao", "W. Zhang", "R. Liu", "F. Liu"], "venue": "in: Evolutionary Computation (CEC), 2010 IEEE Congress on, IEEE", "citeRegEx": "78", "shortCiteRegEx": null, "year": 2010}, {"title": "Introduction to multiobjective optimization: interactive approaches", "author": ["K. Miettinen", "F. Ruiz", "A.P. Wierzbicki"], "venue": "in: Multiobjective Optimization, Springer", "citeRegEx": "79", "shortCiteRegEx": null, "year": 2008}, {"title": "Guidance in evolutionary multi-objective optimization", "author": ["J. Branke", "T. Kau\u00dfler", "H. Schmeck"], "venue": "Advances in Engineering Software 32 (6) ", "citeRegEx": "80", "shortCiteRegEx": null, "year": 2001}, {"title": "A framework for incorporating trade-off information using multi-objective evolutionary algorithms", "author": ["P.K. Shukla", "C. Hirsch", "H. Schmeck"], "venue": "in: Parallel Problem Solving from Nature, PPSN XI, Springer", "citeRegEx": "81", "shortCiteRegEx": null, "year": 2010}, {"title": "Cone-based hypervolume indica- 27  tors: Construction", "author": ["M. Emmerich", "A. Deutz", "J. Kruisselbrink", "P.K. Shukla"], "venue": "properties, and efficient computation, in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "82", "shortCiteRegEx": null, "year": 2013}, {"title": "A theoretical analysis of curvature based preference models", "author": ["P.K. Shukla", "M. Emmerich", "A. Deutz"], "venue": "in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "83", "shortCiteRegEx": null, "year": 2013}, {"title": "Preferences and their application in evolutionary multiobjective optimization", "author": ["D. Cvetkovic", "I.C. Parmee"], "venue": "IEEE Transactions on evolutionary computation 6 (1) ", "citeRegEx": "84", "shortCiteRegEx": null, "year": 2002}, {"title": "B", "author": ["Y. Jin"], "venue": "Sendhoff, Incorporation of Fuzzy Preferences into evolutionary multiobjective optimization., in: GECCO", "citeRegEx": "85", "shortCiteRegEx": null, "year": 2002}, {"title": "Use of preferences for ga-based multi-objective optimisation", "author": ["D. Cvetkovi\u0107", "I.C. Parmee"], "venue": "in: Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 2, Morgan Kaufmann Publishers Inc.", "citeRegEx": "86", "shortCiteRegEx": null, "year": 1999}, {"title": "Incorporating the notion of relative importance of objectives in evolutionary multiobjective optimization", "author": ["L. Rachmawati", "D. Srinivasan"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (4) ", "citeRegEx": "87", "shortCiteRegEx": null, "year": 2010}, {"title": "Using comparative preference statements in hypervolumebased interactive multiobjective optimization", "author": ["D. Brockhoff", "Y. Hamadi", "S. Kaci"], "venue": "in: Learning and Intelligent Optimization, Springer", "citeRegEx": "88", "shortCiteRegEx": null, "year": 2014}, {"title": "Multi-objective particle swarm optimization with preference-based sorting", "author": ["K.-B. Lee", "J.-H. Kim"], "venue": "in: Evolutionary Computation (CEC), 2011 IEEE Congress on, IEEE", "citeRegEx": "89", "shortCiteRegEx": null, "year": 2011}, {"title": "An interactive evolutionary metaheuristic for multiobjective combinatorial optimization", "author": ["S. Phelps", "M. K\u00f6ksalan"], "venue": "Management Science 49 (12) ", "citeRegEx": "90", "shortCiteRegEx": null, "year": 2003}, {"title": "An evolutionary metaheuristic for approximating preferencenondominated solutions", "author": ["M. K\u00f6ksalan", "S. Phelps"], "venue": "INFORMS Journal on Computing 19 (2) ", "citeRegEx": "91", "shortCiteRegEx": null, "year": 2007}, {"title": "Interactive evolutionary multi-objective optimization for quasi-concave preference functions", "author": ["J.W. Fowler", "E.S. Gel", "M.M. K\u00f6ksalan", "P. Korhonen", "J.L. Marquis", "J. Wallenius"], "venue": "European Journal of Operational Research 206 (2) ", "citeRegEx": "92", "shortCiteRegEx": null, "year": 2010}, {"title": "R", "author": ["J. Branke", "S. Greco"], "venue": "S lowi\u0144ski, P. Zielniewicz, Interactive evolutionary multiobjective optimization driven by robust ordinal regression, Bulletin of the Polish Academy of Sciences: Technical Sciences 58 (3) ", "citeRegEx": "93", "shortCiteRegEx": null, "year": 2010}, {"title": "R", "author": ["J. Branke", "S. Corrente", "S. Greco"], "venue": "S  lowi\u0144ski, P. Zielniewicz, Using choquet integral as preference model in interactive evolutionary multiobjective optimization, European Journal of Operational Research 250 (3) ", "citeRegEx": "94", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning value functions in interactive evolutionary multiobjective optimization", "author": ["J. Branke", "S. Greco", "R. Slowinski", "P. Zielniewicz"], "venue": "Evolutionary Computation, IEEE Transactions on 19 (1) ", "citeRegEx": "95", "shortCiteRegEx": null, "year": 2015}, {"title": "An interactive evolutionary multiobjective optimization method based on progressively approximated value functions", "author": ["K. Deb", "A. Sinha", "P.J. Korhonen", "J. Wallenius"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (5) ", "citeRegEx": "96", "shortCiteRegEx": null, "year": 2010}, {"title": "An interactive evolutionary multi-objective optimization method based on polyhedral cones", "author": ["A. Sinha", "P. Korhonen", "J. Wallenius", "K. Deb"], "venue": "in: Learning and Intelligent Optimization, Springer", "citeRegEx": "97", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolutionary algorithms with preference polyhedron for interval multi-objective optimization problems", "author": ["D. Gong", "J. Sun", "X. Ji"], "venue": "Information Sciences 233 ", "citeRegEx": "98", "shortCiteRegEx": null, "year": 2013}, {"title": "R", "author": ["S. Greco", "B. Matarazzo"], "venue": "S  lowi\u0144ski, Dominance-based rough set approach to interactive multiobjective optimization, in: Multiobjective optimization, Springer", "citeRegEx": "99", "shortCiteRegEx": null, "year": 2008}, {"title": "Interactive evolutionary multiobjective optimization using dominance-based rough set approach", "author": ["S. Greco", "B. Matarazzo", "R. Slowinski"], "venue": "in: Evolutionary Computation (CEC), 2010 IEEE Congress on, IEEE", "citeRegEx": "100", "shortCiteRegEx": null, "year": 2010}, {"title": "Brain\u2013computer evolutionary multiobjective optimization: a genetic algorithm adapting to the decision maker", "author": ["R. Battiti", "A. Passerini"], "venue": "Evolutionary Computation, IEEE Transactions on 14 (5) ", "citeRegEx": "101", "shortCiteRegEx": null, "year": 2010}, {"title": "Directed multiple objective search of design spaces using genetic algorithms and neural networks", "author": ["D.S. Todd", "P. Sen"], "venue": "in: Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 2, Morgan Kaufmann Publishers Inc.", "citeRegEx": "102", "shortCiteRegEx": null, "year": 1999}, {"title": "Decision-maker preference modeling in interactive multiobjective optimization", "author": ["L.R. Pedro", "R.H. Takahashi"], "venue": "in: International Conference on Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "103", "shortCiteRegEx": null, "year": 2013}, {"title": "INSPM: An interactive evolutionary multi-objective algorithm with preference model", "author": ["L.R. Pedro", "R.H. Takahashi"], "venue": "Information Sciences 268 ", "citeRegEx": "104", "shortCiteRegEx": null, "year": 2014}, {"title": "Interactive evolutionary multiobjective optimization for hydraulic valve controller parameters", "author": ["J. Krettek", "J. Braun", "F. Hoffmann", "T. Bertram", "T. Ewald", "H.-G. Schubert", "H. Lausch"], "venue": "in: 2009 IEEE/ASME International Conference on Advanced Intelligent Mechatronics, IEEE", "citeRegEx": "105", "shortCiteRegEx": null, "year": 2009}, {"title": "Preference incorporation into evolutionary multiobjective optimization using a multi-criteria evaluation method", "author": ["L. Cruz-Reyes", "E. Fernandez", "C. Gomez", "P. Sanchez"], "venue": "in: Recent Advances on Hybrid Approaches for Designing Intelligent Systems, Springer", "citeRegEx": "106", "shortCiteRegEx": null, "year": 2014}, {"title": "Interactive multiobjective optimization with the Pareto memetic algorithm", "author": ["A. Jaszkiewicz"], "venue": "Foundations of Computing and Decision Sciences 32 ", "citeRegEx": "107", "shortCiteRegEx": null, "year": 2007}, {"title": "Interactive MOEA/D for multi-objective decision making", "author": ["M. Gong", "F. Liu", "W. Zhang", "L. Jiao", "Q. Zhang"], "venue": "in: Proceedings of the 13th annual conference on Genetic and evolutionary computation, ACM", "citeRegEx": "108", "shortCiteRegEx": null, "year": 2011}, {"title": "On set-based multiobjective optimization", "author": ["E. Zitzler", "L. Thiele", "J. Bader"], "venue": "IEEE Transactions on Evolutionary Computation 14 (1) ", "citeRegEx": "109", "shortCiteRegEx": null, "year": 2010}, {"title": "An interactive simple indicator-based evolutionary algorithm (i-sibea) for multiobjective optimization problems", "author": ["T. Chugh", "K. Sindhya", "J. Hakanen", "K. Miettinen"], "venue": "in: International Conference on Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "110", "shortCiteRegEx": null, "year": 2015}, {"title": "Multiple criteria decision analysis: state of the art surveys", "author": ["J. Figueira", "S. Greco", "M. Ehrgott"], "venue": "Vol. 78, Springer Science & Business Media", "citeRegEx": "111", "shortCiteRegEx": null, "year": 2005}, {"title": "Evolutionary multiobjective optimization using an outranking-based dominance generalization", "author": ["E. Fernandez", "E. Lopez", "S. Bernal", "C.A.C. Coello", "J. Navarro"], "venue": "Computers & Operations Research 37 (2) ", "citeRegEx": "112", "shortCiteRegEx": null, "year": 2010}, {"title": "Increasing selective pressure towards the best compromise in evolutionary multiobjective optimization: The extended NOSGA method", "author": ["E. Fernandez", "E. Lopez", "F. Lopez", "C.A.C. Coello"], "venue": "Information Sciences 181 (1) ", "citeRegEx": "113", "shortCiteRegEx": null, "year": 2011}, {"title": "A hybrid evolutionary simulated annealing algorithm with incorporation of preferences", "author": ["E. Oliveira", "C.H. Antunes", "\u00c1. Gomes"], "venue": "in: Proceedings of the 15th annual conference companion on Genetic and evolutionary computation, ACM", "citeRegEx": "114", "shortCiteRegEx": null, "year": 2013}, {"title": "A comparative study of different approaches using an outranking relation in a multi-objective evolutionary algorithm", "author": ["E. Oliveira", "C.H. Antunes", "\u00c1. Gomes"], "venue": "Computers & Operations Research 40 (6) ", "citeRegEx": "115", "shortCiteRegEx": null, "year": 2013}, {"title": "Searching for knee regions in multi-objective optimization using mobile reference points", "author": ["S. Bechikh", "L. Ben Said", "K. Gh\u00e9dira"], "venue": "in: Proceedings of the 2010 ACM symposium on applied computing, ACM", "citeRegEx": "116", "shortCiteRegEx": null, "year": 2010}, {"title": "Searching for knee regions of the Pareto front using mobile reference points", "author": ["S. Bechikh", "L.B. Said", "K. Gh\u00e9dira"], "venue": "Soft Computing 15 (9) ", "citeRegEx": "117", "shortCiteRegEx": null, "year": 2011}, {"title": "V", "author": ["B. Chandrasekaran", "J.R. Josephson"], "venue": "R. Benjamins, et al., What are ontologies, and why 29  do we need them?, IEEE Intelligent systems 14 (1) ", "citeRegEx": "118", "shortCiteRegEx": null, "year": 1999}, {"title": "A translation approach to portable ontology specifications", "author": ["T.R. Gruber"], "venue": "Knowledge acquisition 5 (2) ", "citeRegEx": "119", "shortCiteRegEx": null, "year": 1993}, {"title": "D", "author": ["N.F. Noy"], "venue": "L. McGuinness, et al., Ontology development 101: A guide to creating your first ontology ", "citeRegEx": "121", "shortCiteRegEx": null, "year": 2001}, {"title": "Building and using an ontology of preference-based multiobjective evolutionary algorithms", "author": ["L. Li", "I. Yevseyeva", "V. Basto-Fernandes", "H. Trautmann", "N. Jing", "M. Emmerich"], "venue": "in: International Conference on Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "122", "shortCiteRegEx": null, "year": 2017}, {"title": "A preference based interactive evolutionary algorithm for multi-objective optimization: PIE", "author": ["K. Sindhya", "A.B. Ruiz", "K. Miettinen"], "venue": "in: Evolutionary Multi-Criterion Optimization, Springer", "citeRegEx": "123", "shortCiteRegEx": null, "year": 2011}, {"title": "Semantic multi-criteria decision making semcdm", "author": ["G. Mahmoudi", "C. Muller-Schloer"], "venue": "in: Computational intelligence in miulti-criteria decision-making, 2009. mcdm\u201909. ieee symposium on, IEEE", "citeRegEx": "124", "shortCiteRegEx": null, "year": 2009}, {"title": "Bibliometric analysis of multiple criteria decision making/multiattribute utility theory", "author": ["J. Bragge", "P. Korhonen", "H. Wallenius", "J. Wallenius"], "venue": "in: Multiple criteria decision making for sustainable energy and transportation systems, Springer", "citeRegEx": "126", "shortCiteRegEx": null, "year": 2010}, {"title": "A novel preference articulation operator for the evolutionary multi-objective optimisation of classifiers in concealed weapons detection", "author": ["S. Rostami", "D. OReilly", "A. Shenfield", "N. Bowring"], "venue": "Information Sciences 295 ", "citeRegEx": "127", "shortCiteRegEx": null, "year": 2015}, {"title": "Reservoir flood control operation using multi-objective evolutionary algorithm with decomposition and preferences", "author": ["Y. Qi", "J. Yu", "X. Li", "Y. Wei", "Q. Miao"], "venue": "Applied Soft Computing 50 ", "citeRegEx": "128", "shortCiteRegEx": null, "year": 2017}, {"title": "Preference-inspired coevolutionary algorithms for many-objective optimization", "author": ["R. Wang", "R.C. Purshouse", "P.J. Fleming"], "venue": "Evolutionary Computation, IEEE Transactions on 17 (4) ", "citeRegEx": "129", "shortCiteRegEx": null, "year": 2013}, {"title": "An r-dominance-based preference multi-objective optimization for many-objective optimization", "author": ["R. Liu", "X. Song", "L. Fang", "L. Jiao"], "venue": "Soft Computing ", "citeRegEx": "130", "shortCiteRegEx": null, "year": 2016}, {"title": "Clone selection algorithm to solve preference multiobjective optimization", "author": ["D. Yang", "L. Jiao", "M. Gong", "H. Yu"], "venue": "Journal of Software 21 (1) ", "citeRegEx": "131", "shortCiteRegEx": null, "year": 2010}, {"title": "An interactive evolutionary multi-objective optimization algorithm with a limited number of decision maker calls", "author": ["A. Sinha", "P. Korhonen", "J. Wallenius", "K. Deb"], "venue": "European Journal of Operational Research 233 (3) ", "citeRegEx": "132", "shortCiteRegEx": null, "year": 2014}, {"title": "J", "author": ["G.W. Greenwood", "X. Hu"], "venue": "G. D\u2019Ambrosio, Fitness functions for multiple objective optimization problems: Combining preferences with pareto rankings., in: FOGA, Vol. 96", "citeRegEx": "133", "shortCiteRegEx": null, "year": 1996}, {"title": "A new performance metric for user-preference based multi-objective evolutionary algorithms", "author": ["A. Mohammadi", "M.N. Omidvar", "X. Li"], "venue": "in: 2013 IEEE Congress on Evolutionary Computation, IEEE", "citeRegEx": "134", "shortCiteRegEx": null, "year": 2013}, {"title": "Towards Automatic Testing of Reference Point Based Interactive Methods", "author": ["V. Ojalehto", "D. Podkopaev", "K. Miettinen"], "venue": "in: International Conference on Parallel Problem Solving from Nature, Springer", "citeRegEx": "135", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "As [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs.", "startOffset": 3, "endOffset": 6}, {"referenceID": 1, "context": "As [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs.", "startOffset": 72, "endOffset": 78}, {"referenceID": 2, "context": "As [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs.", "startOffset": 72, "endOffset": 78}, {"referenceID": 3, "context": "As [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs.", "startOffset": 131, "endOffset": 137}, {"referenceID": 4, "context": "As [1] indicates, conventional multiple criteria decision making (MCDM) [2, 3] and evolutionary multi-objective optimization (EMO) [4, 5] are two main research fields dealing with MOPs.", "startOffset": 131, "endOffset": 137}, {"referenceID": 5, "context": "In contrast, multi-objective evolutionary algorithms (MOEAs), which belong to multi-objective metaheuristics (MOMHs) [6], are population-based algorithms intended to find a set of solutions that best approximate the whole PF.", "startOffset": 117, "endOffset": 120}, {"referenceID": 6, "context": "The two methodologies have both pros and cons as stated in [7].", "startOffset": 59, "endOffset": 62}, {"referenceID": 7, "context": "The 2004 and 2006 Dagstuhl seminars witnessed an initiation of many results in PMOMHs [8] when researchers in MOMH and MCDM fields gathered together to know each other and stimulate cooperation.", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "Good review papers exist along with the development of PMOMHs [9\u201313].", "startOffset": 62, "endOffset": 68}, {"referenceID": 9, "context": "Good review papers exist along with the development of PMOMHs [9\u201313].", "startOffset": 62, "endOffset": 68}, {"referenceID": 10, "context": "Good review papers exist along with the development of PMOMHs [9\u201313].", "startOffset": 62, "endOffset": 68}, {"referenceID": 11, "context": "Good review papers exist along with the development of PMOMHs [9\u201313].", "startOffset": 62, "endOffset": 68}, {"referenceID": 12, "context": "Good review papers exist along with the development of PMOMHs [9\u201313].", "startOffset": 62, "endOffset": 68}, {"referenceID": 13, "context": "PMOMHs can be classified by interaction moment with the DM [14] (a-priori, a-posteriori or interactively), by type of preference information used [15] (implicit preference or explicit preference), by ways preferences are integrated in (change of objectives or change of metaheuristics), by type of the internal preference model, etc.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "PMOMHs can be classified by interaction moment with the DM [14] (a-priori, a-posteriori or interactively), by type of preference information used [15] (implicit preference or explicit preference), by ways preferences are integrated in (change of objectives or change of metaheuristics), by type of the internal preference model, etc.", "startOffset": 146, "endOffset": 150}, {"referenceID": 15, "context": "Ontologies are currently the most suited way to formally describe knowledge in a standard way, by means of comprehensive notations and graphical representations, to help understand concepts and relationships in complex knowledge domains [16].", "startOffset": 237, "endOffset": 241}, {"referenceID": 16, "context": "The ontology describes concepts, relationships, formal logic axioms and objects of a particular domain [17].", "startOffset": 103, "endOffset": 107}, {"referenceID": 17, "context": "However, in [18] and [19] OWL ontologies were presented for diversity-oriented optimization and Evolutionary Computation respectively, revealing the suitability and relevance of this type of knowledge representation for the optimization algorithms research domain.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "However, in [18] and [19] OWL ontologies were presented for diversity-oriented optimization and Evolutionary Computation respectively, revealing the suitability and relevance of this type of knowledge representation for the optimization algorithms research domain.", "startOffset": 21, "endOffset": 25}, {"referenceID": 3, "context": "A minimization MOP is defined as follows [4] without loss of generality: \uf8f1\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3 min f(x) = [f1(x), f2(x), \u00b7 \u00b7 \u00b7 fM (x)] gj(x) \u2265 0 j = 1, 2, \u00b7 \u00b7 \u00b7 , P hk(x) = 0 k = 1, 2, \u00b7 \u00b7 \u00b7 , Q xi \u2264 xi \u2264 xi i = 1, 2, \u00b7 \u00b7 \u00b7 , n (1)", "startOffset": 41, "endOffset": 44}, {"referenceID": 1, "context": "The related definitions are as follows [2].", "startOffset": 39, "endOffset": 42}, {"referenceID": 19, "context": "Metaheuristics are a broad family of non-deterministic optimization methods that may provide a sufficiently good solution to complex optimization problems [21].", "startOffset": 155, "endOffset": 159}, {"referenceID": 20, "context": ", Pareto-based, indicator-based and decompositionbased [22].", "startOffset": 55, "endOffset": 59}, {"referenceID": 21, "context": "Pareto-based MOEAs use Pareto dominance as selection criterion, such as NSGA-II [23], SPEA2 [24], and so on.", "startOffset": 80, "endOffset": 84}, {"referenceID": 22, "context": "Pareto-based MOEAs use Pareto dominance as selection criterion, such as NSGA-II [23], SPEA2 [24], and so on.", "startOffset": 92, "endOffset": 96}, {"referenceID": 23, "context": "SMS-EMOA [25], HypE [26], R2-EMOA [27] and POSEA [28] fall into this category.", "startOffset": 9, "endOffset": 13}, {"referenceID": 24, "context": "SMS-EMOA [25], HypE [26], R2-EMOA [27] and POSEA [28] fall into this category.", "startOffset": 20, "endOffset": 24}, {"referenceID": 25, "context": "SMS-EMOA [25], HypE [26], R2-EMOA [27] and POSEA [28] fall into this category.", "startOffset": 34, "endOffset": 38}, {"referenceID": 26, "context": "SMS-EMOA [25], HypE [26], R2-EMOA [27] and POSEA [28] fall into this category.", "startOffset": 49, "endOffset": 53}, {"referenceID": 27, "context": "MOEA/D [29] and NSGA-III [30] are two representative algorithms.", "startOffset": 7, "endOffset": 11}, {"referenceID": 28, "context": "MOEA/D [29] and NSGA-III [30] are two representative algorithms.", "startOffset": 25, "endOffset": 29}, {"referenceID": 29, "context": "Having the preference information of the DM as a selection criterion is a good way to address this problem [31, 32].", "startOffset": 107, "endOffset": 115}, {"referenceID": 30, "context": "Having the preference information of the DM as a selection criterion is a good way to address this problem [31, 32].", "startOffset": 107, "endOffset": 115}, {"referenceID": 13, "context": "There are several criteria to classify PMOMHs, such as interaction moment in [14] and preference information in [12].", "startOffset": 77, "endOffset": 81}, {"referenceID": 11, "context": "There are several criteria to classify PMOMHs, such as interaction moment in [14] and preference information in [12].", "startOffset": 112, "endOffset": 116}, {"referenceID": 11, "context": "Here, we adopt the taxonomy of [12] with slight changes.", "startOffset": 31, "endOffset": 35}, {"referenceID": 32, "context": "Reference point-based approaches Compared to other articulation of preferences, reference point, first proposed by Wierzbicki [34] in MCDM, is now among the most widely used methods in PMOMHs due to its natural and intuitive meaning.", "startOffset": 126, "endOffset": 130}, {"referenceID": 33, "context": "The earliest PMOMH is regarded to be multi-objective genetic algorithm (MOGA) [35] proposed by Fonseca and Fleming.", "startOffset": 78, "endOffset": 82}, {"referenceID": 34, "context": "[36] to incorporate hard/soft priority information and capable of dealing with multiple reference points.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "Utilizing the reference point to change dominance relation was also adopted in g-dominance [37] and r-dominance [38].", "startOffset": 91, "endOffset": 95}, {"referenceID": 36, "context": "Utilizing the reference point to change dominance relation was also adopted in g-dominance [37] and r-dominance [38].", "startOffset": 112, "endOffset": 116}, {"referenceID": 37, "context": "Tchebycheff preference relation [39] is another dominance relation changed by reference point.", "startOffset": 32, "endOffset": 36}, {"referenceID": 38, "context": "Apart from dominance relation, reference point can also be used to change crowding distance, as it is done in R-NSGA-II [40].", "startOffset": 120, "endOffset": 124}, {"referenceID": 39, "context": "[41] to speed up the search under a limited number of evaluations, and was also extended by Filatovas et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 40, "context": "[42] to consider several scalarizing functions simultaneously.", "startOffset": 0, "endOffset": 4}, {"referenceID": 41, "context": "In [43], a positive reference point and a negative reference point are integrated in crowding distance to form a new metric called similarity.", "startOffset": 3, "endOffset": 7}, {"referenceID": 42, "context": "Weighting achievement scalarizing function genetic algorithm (WASF-GA) [44] applies an achievement scalarizing function (ASF) to classify the individuals into several fronts.", "startOffset": 71, "endOffset": 75}, {"referenceID": 43, "context": "The authors also published the interactive version of WASF-GA [45].", "startOffset": 62, "endOffset": 66}, {"referenceID": 31, "context": "2It is also called aspiration level or goal vector, or preference point in [33].", "startOffset": 75, "endOffset": 79}, {"referenceID": 27, "context": "MOEA/D [29] relies on a decomposition strategy such as weighted-sum or Tchebycheff approach to convert a multi-objective problem into single-objective problems.", "startOffset": 7, "endOffset": 11}, {"referenceID": 44, "context": "Reference point has also been imported to change weight vectors in [46, 47], for finding preferred solutions.", "startOffset": 67, "endOffset": 75}, {"referenceID": 45, "context": "Reference point has also been imported to change weight vectors in [46, 47], for finding preferred solutions.", "startOffset": 67, "endOffset": 75}, {"referenceID": 28, "context": "NSGA-III [30] utilizes a number of well-spread reference points for MaOPs, it can also focus on preferred part of the PF using user-supplied reference points.", "startOffset": 9, "endOffset": 13}, {"referenceID": 46, "context": "In PBEA [48], \u03b5-indicator has been modified to incorporate ASF values.", "startOffset": 8, "endOffset": 12}, {"referenceID": 47, "context": "Aspiration Set EMOA [49] considers a set of reference points to guide the search, with averaged Hausdorff distance as quality indicator.", "startOffset": 20, "endOffset": 24}, {"referenceID": 48, "context": "Preferences can be combined with R2-indicator by position of reference point, restriction of weight space and density of weight distribution [50].", "startOffset": 141, "endOffset": 145}, {"referenceID": 25, "context": "R2-EMOA [27] aims at solutions maximizing the preference-based R2indicator.", "startOffset": 8, "endOffset": 12}, {"referenceID": 49, "context": "Reference point-based PSO using a Steady-State approach (RPSO-SS) [51] proposes to use distance to reference points as selection criterion, for the sake of finding a set of solutions near the reference points.", "startOffset": 66, "endOffset": 70}, {"referenceID": 50, "context": "Multi-objective Differential Evolution and PSO (MDEPSO) [52] hybridizes two MCDM methods: reference point and light beam search [52].", "startOffset": 56, "endOffset": 60}, {"referenceID": 50, "context": "Multi-objective Differential Evolution and PSO (MDEPSO) [52] hybridizes two MCDM methods: reference point and light beam search [52].", "startOffset": 128, "endOffset": 132}, {"referenceID": 51, "context": "In [53], g-dominance [37] is combined with memetic multi-objective ant colony optimization for solving a real industrial problem of assembly line balancing.", "startOffset": 3, "endOffset": 7}, {"referenceID": 35, "context": "In [53], g-dominance [37] is combined with memetic multi-objective ant colony optimization for solving a real industrial problem of assembly line balancing.", "startOffset": 21, "endOffset": 25}, {"referenceID": 52, "context": "Reference direction method [54] and light beam search [55], which can be considered as extensions of reference point method in MCDM, are also integrated in MOMH.", "startOffset": 27, "endOffset": 31}, {"referenceID": 53, "context": "Reference direction method [54] and light beam search [55], which can be considered as extensions of reference point method in MCDM, are also integrated in MOMH.", "startOffset": 54, "endOffset": 58}, {"referenceID": 54, "context": "LBS-NSGA-II [56] and RD-NSGA-II [57] are the representative algorithms.", "startOffset": 12, "endOffset": 16}, {"referenceID": 55, "context": "LBS-NSGA-II [56] and RD-NSGA-II [57] are the representative algorithms.", "startOffset": 32, "endOffset": 36}, {"referenceID": 56, "context": "Light beam search has also been considered in MOEA/D [58], multi-objective Differential Evolution and PSO (MDEPSO) [52] and multi-objective immune algorithm [59].", "startOffset": 53, "endOffset": 57}, {"referenceID": 50, "context": "Light beam search has also been considered in MOEA/D [58], multi-objective Differential Evolution and PSO (MDEPSO) [52] and multi-objective immune algorithm [59].", "startOffset": 115, "endOffset": 119}, {"referenceID": 57, "context": "Light beam search has also been considered in MOEA/D [58], multi-objective Differential Evolution and PSO (MDEPSO) [52] and multi-objective immune algorithm [59].", "startOffset": 157, "endOffset": 161}, {"referenceID": 58, "context": "Branke and Deb proposed a biased crowding distance approach [60] to find a biased distribution on the PF.", "startOffset": 60, "endOffset": 64}, {"referenceID": 10, "context": "This approach was regarded as an objective scaling method in [11].", "startOffset": 61, "endOffset": 65}, {"referenceID": 59, "context": "Desirability functions (DFs) [61, 62] are widely investigated for its simple and intuitive meaning.", "startOffset": 29, "endOffset": 37}, {"referenceID": 60, "context": "Desirability functions (DFs) [61, 62] are widely investigated for its simple and intuitive meaning.", "startOffset": 29, "endOffset": 37}, {"referenceID": 0, "context": "DFs nonlinearly transform the objective values into the desirability domain [0, 1].", "startOffset": 76, "endOffset": 82}, {"referenceID": 61, "context": "DFs have already been successfully introduced in combination with NSGA-II [63], MOPSO [64] and SMS-EMOA [65] on both benchmark problems and practical problems.", "startOffset": 74, "endOffset": 78}, {"referenceID": 62, "context": "DFs have already been successfully introduced in combination with NSGA-II [63], MOPSO [64] and SMS-EMOA [65] on both benchmark problems and practical problems.", "startOffset": 86, "endOffset": 90}, {"referenceID": 63, "context": "DFs have already been successfully introduced in combination with NSGA-II [63], MOPSO [64] and SMS-EMOA [65] on both benchmark problems and practical problems.", "startOffset": 104, "endOffset": 108}, {"referenceID": 64, "context": "proposed to use the desirability index (DI), which is a DF-based scalarization, as the second-level selection criterion in the non-dominated sorting [66].", "startOffset": 149, "endOffset": 153}, {"referenceID": 31, "context": "In [33, 67, 68], weighted hypervolume is used to guide the search towards ROI by utilizing a variety of density functions in the objective space, including stressing one objective, one reference point, a rectangle region and so on.", "startOffset": 3, "endOffset": 15}, {"referenceID": 65, "context": "In [33, 67, 68], weighted hypervolume is used to guide the search towards ROI by utilizing a variety of density functions in the objective space, including stressing one objective, one reference point, a rectangle region and so on.", "startOffset": 3, "endOffset": 15}, {"referenceID": 66, "context": "In [33, 67, 68], weighted hypervolume is used to guide the search towards ROI by utilizing a variety of density functions in the objective space, including stressing one objective, one reference point, a rectangle region and so on.", "startOffset": 3, "endOffset": 15}, {"referenceID": 67, "context": "This kind of preferences can also be integrated with NSGA-II and SPEA2, as demonstrated in [69].", "startOffset": 91, "endOffset": 95}, {"referenceID": 68, "context": "use Desirability Function to define a density in the objective space and provide a probabilistic interpretation for it [70].", "startOffset": 119, "endOffset": 123}, {"referenceID": 69, "context": "Karahan and K\u00f6ksalan proposed a territory defining steady-state elitist evolutionary algorithm (TDEA) [71] which defines a territory around each individual solution to prevent crowding.", "startOffset": 102, "endOffset": 106}, {"referenceID": 70, "context": "An interactive version of this method was proposed in [72].", "startOffset": 54, "endOffset": 58}, {"referenceID": 71, "context": "A hyperplane in the objective space is constructed to articulate preferences in [73].", "startOffset": 80, "endOffset": 84}, {"referenceID": 72, "context": "This preference model is embedded into the framework of NSGA-II and applied to many-objective knapsack problems [74].", "startOffset": 112, "endOffset": 116}, {"referenceID": 73, "context": "A reference vector-guided EA (RVEA) for many-objective optimization was proposed recently [75].", "startOffset": 90, "endOffset": 94}, {"referenceID": 74, "context": "In interactive preference-inspired co-evolutionary algorithm (iPICEA-g) [76], candidate solutions and goal vectors are co-evolved to focus on a ROI, which is defined by user-provided reference point, weight and search range.", "startOffset": 72, "endOffset": 76}, {"referenceID": 75, "context": "proposed a method for effectively approximating a preferred part of PF based on multi-objective efficient global optimization (EGO) [77].", "startOffset": 132, "endOffset": 136}, {"referenceID": 76, "context": "A hybrid multi-objective immune algorithm (HMIA) was devised with a new concept of dominance, called region-dominance [78].", "startOffset": 118, "endOffset": 122}, {"referenceID": 77, "context": "[79], trade-offs can be objective or subjective.", "startOffset": 0, "endOffset": 4}, {"referenceID": 78, "context": "[80], subjective trade-offs are given by the DM in the form of statement: \u201cone unit improvement in objective i is worth at most aji units degradation in objective j \u201d .", "startOffset": 0, "endOffset": 4}, {"referenceID": 79, "context": "Apart from dominance relation, trade-offs can also be employed to sort additional fronts in the best non-dominated set, just as pNSGA-II [81] did.", "startOffset": 137, "endOffset": 141}, {"referenceID": 80, "context": "A concept of cone-based hypervolume indicators (CHI) is proposed and theoretically investigated in [82, 83].", "startOffset": 99, "endOffset": 107}, {"referenceID": 81, "context": "A concept of cone-based hypervolume indicators (CHI) is proposed and theoretically investigated in [82, 83].", "startOffset": 99, "endOffset": 107}, {"referenceID": 82, "context": "Early researches focused on weights as preference articulation [84], but sometimes it is difficult for the DM to specify weights accurately.", "startOffset": 63, "endOffset": 67}, {"referenceID": 83, "context": "Jin and Sendhoff transformed fuzzy preferences on objectives into weight intervals [85], this method is an extension of method proposed in [86].", "startOffset": 83, "endOffset": 87}, {"referenceID": 84, "context": "Jin and Sendhoff transformed fuzzy preferences on objectives into weight intervals [85], this method is an extension of method proposed in [86].", "startOffset": 139, "endOffset": 143}, {"referenceID": 85, "context": "Rachmawati and Srinivasan introduced relative importance of objectives, including strict preference, equality of importance, and incomparability between pairs of objectives [87].", "startOffset": 173, "endOffset": 177}, {"referenceID": 86, "context": "utilized two preference articulation approaches in the interactive W-HypE [88].", "startOffset": 74, "endOffset": 78}, {"referenceID": 86, "context": "3\u201d [88].", "startOffset": 3, "endOffset": 7}, {"referenceID": 66, "context": "This information is then transformed to parameters in the objective space density function used by W-HypE [68].", "startOffset": 106, "endOffset": 110}, {"referenceID": 87, "context": "Preference information was provided by an objective pairwise comparison matrix and combined with fuzzy measure and fuzzy integral in [89].", "startOffset": 133, "endOffset": 137}, {"referenceID": 87, "context": "This preference is coupled with multi-objective particle swarm optimization [89] and multi-objective quantum-inspired evolutionary algorithm [32].", "startOffset": 76, "endOffset": 80}, {"referenceID": 30, "context": "This preference is coupled with multi-objective particle swarm optimization [89] and multi-objective quantum-inspired evolutionary algorithm [32].", "startOffset": 141, "endOffset": 145}, {"referenceID": 88, "context": "Phelps and K\u00f6ksalan proposed an interactive evolutionary metaheuristic for multi-objective combinatorial optimization [90].", "startOffset": 118, "endOffset": 122}, {"referenceID": 89, "context": "A more flexible algorithm [91] was introduced by them for all cases between the two extremes of perfect information and no information.", "startOffset": 26, "endOffset": 30}, {"referenceID": 90, "context": "adopted a general quasi-concave utility function to represent the DM preferences [92].", "startOffset": 81, "endOffset": 85}, {"referenceID": 91, "context": "The Necessary-preference-enhanced Evolutionary multi-objective Optimizer (NEMO-I) [93] presented by Branke et al.", "startOffset": 82, "endOffset": 86}, {"referenceID": 92, "context": "To reduce the computational complexity, which is a main shortcoming of NEMO-I, the authors proposed NEMOII [94] which compares each solution to all other solutions as a set, instead of pairwise comparison.", "startOffset": 107, "endOffset": 111}, {"referenceID": 93, "context": "While NEMO-I and NEMO-II both consider whole sets of value functions compatible with the preference information, NEMO-0 [95] uses only the most representative value function.", "startOffset": 120, "endOffset": 124}, {"referenceID": 94, "context": "Similar preference model is used in PI-EMO-VF [96].", "startOffset": 46, "endOffset": 50}, {"referenceID": 95, "context": "proposed interactive EMO algorithm based on polyhedral cone (PI-EMOPC) [97], in which the cone is constructed according to DM\u2019s best selection in a set of alternative solutions, and it is used to eliminate a part of the search space for a more focused search.", "startOffset": 71, "endOffset": 75}, {"referenceID": 96, "context": "The construction and application of the polyhedral cone were extended for interval MOPs in [98].", "startOffset": 91, "endOffset": 95}, {"referenceID": 97, "context": "\u201d rules deduction [99].", "startOffset": 18, "endOffset": 22}, {"referenceID": 98, "context": "It has been integrated in interactive EMO [100], where two schemes were proposed to collect user preference.", "startOffset": 42, "endOffset": 47}, {"referenceID": 99, "context": "Some researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].", "startOffset": 115, "endOffset": 120}, {"referenceID": 100, "context": "Some researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].", "startOffset": 155, "endOffset": 164}, {"referenceID": 101, "context": "Some researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].", "startOffset": 155, "endOffset": 164}, {"referenceID": 102, "context": "Some researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].", "startOffset": 155, "endOffset": 164}, {"referenceID": 103, "context": "Some researchers use machine learning approaches to learn the value function, such as support vector machine (SVM) [101], Artificial Neural Networks (ANN) [102\u2013104], instance-based supervised online learning [105].", "startOffset": 208, "endOffset": 213}, {"referenceID": 104, "context": "introduced the Hybrid-MultiCriteria Sorting Genetic Algorithm (H-MCSGA) [106], in which the selective pressure based on dominance is strengthened by assigning solutions into ordered categories.", "startOffset": 72, "endOffset": 77}, {"referenceID": 105, "context": "Solution comparison can also be incorporated with Pareto memetic algorithm [107], MOEA/D [108] and Indicator-based MOEA [109, 110].", "startOffset": 75, "endOffset": 80}, {"referenceID": 106, "context": "Solution comparison can also be incorporated with Pareto memetic algorithm [107], MOEA/D [108] and Indicator-based MOEA [109, 110].", "startOffset": 89, "endOffset": 94}, {"referenceID": 107, "context": "Solution comparison can also be incorporated with Pareto memetic algorithm [107], MOEA/D [108] and Indicator-based MOEA [109, 110].", "startOffset": 120, "endOffset": 130}, {"referenceID": 108, "context": "Solution comparison can also be incorporated with Pareto memetic algorithm [107], MOEA/D [108] and Indicator-based MOEA [109, 110].", "startOffset": 120, "endOffset": 130}, {"referenceID": 109, "context": "An outranking relation is a binary relation S defined on the set of potential solutions (also called actions) A such that aSb if there are enough arguments to decide that a is at least as good as b, whereas there is no essential argument to refuse that statement [111].", "startOffset": 263, "endOffset": 268}, {"referenceID": 110, "context": "proposed a Non-outranking Sorting Genetic Algorithm (NOSGA) [112] to consider a binary fuzzy preference relation that expresses the degree of truth of predicate \u201cx is at least as good as y\u201d.", "startOffset": 60, "endOffset": 65}, {"referenceID": 111, "context": "The method is extended to increase the selective pressure towards the best compromise solution later in NOSGA-II [113].", "startOffset": 113, "endOffset": 118}, {"referenceID": 112, "context": "A hybrid evolutionary simulated annealing (HESA) [114] was designed to improve Evolutionary Algorithm Based on an Outranking Relation (EvABOR) [115].", "startOffset": 49, "endOffset": 54}, {"referenceID": 113, "context": "A hybrid evolutionary simulated annealing (HESA) [114] was designed to improve Evolutionary Algorithm Based on an Outranking Relation (EvABOR) [115].", "startOffset": 143, "endOffset": 148}, {"referenceID": 114, "context": "proposed KR-NSGA-II [116] based on R-NSGA-II [40], in which mobile reference points are used to modify crowding distance in the traditional NSGA-II.", "startOffset": 20, "endOffset": 25}, {"referenceID": 38, "context": "proposed KR-NSGA-II [116] based on R-NSGA-II [40], in which mobile reference points are used to modify crowding distance in the traditional NSGA-II.", "startOffset": 45, "endOffset": 49}, {"referenceID": 115, "context": "TKR-NSGA-II[117] is an enhanced version of KR-NSGA-II[116] where the approach to find knee points has been improved.", "startOffset": 11, "endOffset": 16}, {"referenceID": 114, "context": "TKR-NSGA-II[117] is an enhanced version of KR-NSGA-II[116] where the approach to find knee points has been improved.", "startOffset": 53, "endOffset": 58}, {"referenceID": 116, "context": ", theories that explain the specific factors that motivate behavior) about the sorts of objects, properties of objects, and relations between objects that are possible in a specified domain of knowledge [118].", "startOffset": 203, "endOffset": 208}, {"referenceID": 117, "context": "The most widely accepted definition of ontology in this context is given by Gruber [119]: \u201cAn ontology is a formal explicit specification of a shared conceptualization for a domain of interest.", "startOffset": 83, "endOffset": 88}, {"referenceID": 118, "context": "According to Noy [121], the reasons to develop an ontology are given below: (1) To share common understanding of the structure of information among people or software agents.", "startOffset": 17, "endOffset": 22}, {"referenceID": 18, "context": "As far as we know, Evolutionary Computation (EC) ontology [19] and diversity-oriented optimization ontology [18] have been proposed recently, and their contributions were considered in the design of the PMOMH ontology.", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "As far as we know, Evolutionary Computation (EC) ontology [19] and diversity-oriented optimization ontology [18] have been proposed recently, and their contributions were considered in the design of the PMOMH ontology.", "startOffset": 108, "endOffset": 112}, {"referenceID": 119, "context": "An ontology of preference-based multi-objective evolutionary algorithms (PMOEAs) was built and basic query examples were given [122].", "startOffset": 127, "endOffset": 132}, {"referenceID": 38, "context": "Individuals represent objects, or class instances in the domain of interest, for instance R-NSGA-II [40] is an individual of PMOMH.", "startOffset": 100, "endOffset": 104}, {"referenceID": 118, "context": "As suggested by Noy [121], there is no one \u201ccorrect\u201d way for developing ontologies.", "startOffset": 20, "endOffset": 25}, {"referenceID": 118, "context": "However, the guidelines provided in [121] represent a generalized set of steps, widely accepted in this area, which are adopted by us and presented in detail next.", "startOffset": 36, "endOffset": 41}, {"referenceID": 120, "context": "According to [123], at least two possible ways of integrating EMO and MCDM can be identified: \u201cevolutionary algorithm in MCDM\u201d and \u201cMCDM in EMO\u201d approaches.", "startOffset": 13, "endOffset": 18}, {"referenceID": 120, "context": "The former follows the main procedure of MCDM method and utilizes evolutionary algorithms to get intermediate solutions (such as PIE [123]), the latter, \u201cMCDM in EMO\u201d, or \u201cMCDM in MOMH\u201d more broadly, was the main scope in our study.", "startOffset": 133, "endOffset": 138}, {"referenceID": 18, "context": "As far as we know, Evolutionary Computation (EC) Ontology [19], Diversity-Oriented Optimization Ontology [18] and Semantic MCDM (SeMCDM) [124] are related to the PMOMH ontology to some extent.", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "As far as we know, Evolutionary Computation (EC) Ontology [19], Diversity-Oriented Optimization Ontology [18] and Semantic MCDM (SeMCDM) [124] are related to the PMOMH ontology to some extent.", "startOffset": 105, "endOffset": 109}, {"referenceID": 121, "context": "As far as we know, Evolutionary Computation (EC) Ontology [19], Diversity-Oriented Optimization Ontology [18] and Semantic MCDM (SeMCDM) [124] are related to the PMOMH ontology to some extent.", "startOffset": 137, "endOffset": 142}, {"referenceID": 11, "context": "These are important properties of PMOMH, which are also examined in [12].", "startOffset": 68, "endOffset": 72}, {"referenceID": 38, "context": "6 presents R-NSGA-II [40] as an example of PMOMH individual.", "startOffset": 21, "endOffset": 25}, {"referenceID": 119, "context": "Examples of reasoning and query are available in [122].", "startOffset": 49, "endOffset": 54}, {"referenceID": 105, "context": "7 shows that iPMA [107], IEM-CO [90] and EMAPS [91] have pairwise comparison as preference articulation and solve discrete problems in the experiment, which are reasonable suggestions for our application problem.", "startOffset": 18, "endOffset": 23}, {"referenceID": 88, "context": "7 shows that iPMA [107], IEM-CO [90] and EMAPS [91] have pairwise comparison as preference articulation and solve discrete problems in the experiment, which are reasonable suggestions for our application problem.", "startOffset": 32, "endOffset": 36}, {"referenceID": 89, "context": "7 shows that iPMA [107], IEM-CO [90] and EMAPS [91] have pairwise comparison as preference articulation and solve discrete problems in the experiment, which are reasonable suggestions for our application problem.", "startOffset": 47, "endOffset": 51}, {"referenceID": 33, "context": "1 MOGA [35] 4236 2 R-NSGA-II [40] 507 3 NSGA-III [30] 419 4 SIBEA [67] 325 5 G-MOEA [80] 228 Table 5: Top-5 researchers ranked by number of published PMOMH individuals", "startOffset": 7, "endOffset": 11}, {"referenceID": 38, "context": "1 MOGA [35] 4236 2 R-NSGA-II [40] 507 3 NSGA-III [30] 419 4 SIBEA [67] 325 5 G-MOEA [80] 228 Table 5: Top-5 researchers ranked by number of published PMOMH individuals", "startOffset": 29, "endOffset": 33}, {"referenceID": 28, "context": "1 MOGA [35] 4236 2 R-NSGA-II [40] 507 3 NSGA-III [30] 419 4 SIBEA [67] 325 5 G-MOEA [80] 228 Table 5: Top-5 researchers ranked by number of published PMOMH individuals", "startOffset": 49, "endOffset": 53}, {"referenceID": 65, "context": "1 MOGA [35] 4236 2 R-NSGA-II [40] 507 3 NSGA-III [30] 419 4 SIBEA [67] 325 5 G-MOEA [80] 228 Table 5: Top-5 researchers ranked by number of published PMOMH individuals", "startOffset": 66, "endOffset": 70}, {"referenceID": 78, "context": "1 MOGA [35] 4236 2 R-NSGA-II [40] 507 3 NSGA-III [30] 419 4 SIBEA [67] 325 5 G-MOEA [80] 228 Table 5: Top-5 researchers ranked by number of published PMOMH individuals", "startOffset": 84, "endOffset": 88}, {"referenceID": 122, "context": "conducted bibliomatric analysis on Multiple Criteria Decision Making/Multiattribute Utility Theory (MCDM/MAUT) [126].", "startOffset": 111, "endOffset": 116}, {"referenceID": 38, "context": ", who compared their proposed method with R-NSGA-II[40]?) They can query for methods that used one specific benchmark problem (e.", "startOffset": 51, "endOffset": 55}, {"referenceID": 61, "context": "Desirability Function DF-NSGA-II [63]", "startOffset": 33, "endOffset": 37}, {"referenceID": 64, "context": "DI-EMOA[66] DHI [70]", "startOffset": 7, "endOffset": 11}, {"referenceID": 68, "context": "DI-EMOA[66] DHI [70]", "startOffset": 16, "endOffset": 20}, {"referenceID": 63, "context": "DF-SMS-EMOA[65] DF-MOPSO[64]", "startOffset": 11, "endOffset": 15}, {"referenceID": 62, "context": "DF-SMS-EMOA[65] DF-MOPSO[64]", "startOffset": 24, "endOffset": 28}, {"referenceID": 34, "context": "Objective Comparison GPS-EA[36]", "startOffset": 27, "endOffset": 31}, {"referenceID": 83, "context": "FP-EMO[85]", "startOffset": 6, "endOffset": 10}, {"referenceID": 85, "context": "RIO-NSGA-II [87] iW-HypE[88] MQEA-PS[32] MOPSO-PS[89]", "startOffset": 12, "endOffset": 16}, {"referenceID": 86, "context": "RIO-NSGA-II [87] iW-HypE[88] MQEA-PS[32] MOPSO-PS[89]", "startOffset": 24, "endOffset": 28}, {"referenceID": 30, "context": "RIO-NSGA-II [87] iW-HypE[88] MQEA-PS[32] MOPSO-PS[89]", "startOffset": 36, "endOffset": 40}, {"referenceID": 87, "context": "RIO-NSGA-II [87] iW-HypE[88] MQEA-PS[32] MOPSO-PS[89]", "startOffset": 49, "endOffset": 53}, {"referenceID": 69, "context": "Preference Region/Distribution prTDEA[71]", "startOffset": 37, "endOffset": 41}, {"referenceID": 67, "context": "W-NSGA-II [69]", "startOffset": 10, "endOffset": 14}, {"referenceID": 67, "context": "W-SPEA2[69]", "startOffset": 7, "endOffset": 11}, {"referenceID": 71, "context": "GF-NSGA-II [73] SIBEA[67]", "startOffset": 11, "endOffset": 15}, {"referenceID": 65, "context": "GF-NSGA-II [73] SIBEA[67]", "startOffset": 21, "endOffset": 25}, {"referenceID": 31, "context": "W-HypE[33]", "startOffset": 6, "endOffset": 10}, {"referenceID": 66, "context": "W-HypE \u0301[68]", "startOffset": 8, "endOffset": 12}, {"referenceID": 75, "context": "TEHVI-EGO[77] iPICEA-G[76]", "startOffset": 9, "endOffset": 13}, {"referenceID": 74, "context": "TEHVI-EGO[77] iPICEA-G[76]", "startOffset": 22, "endOffset": 26}, {"referenceID": 73, "context": "RVEA[75] HMIA[78]", "startOffset": 4, "endOffset": 8}, {"referenceID": 76, "context": "RVEA[75] HMIA[78]", "startOffset": 13, "endOffset": 17}, {"referenceID": 35, "context": "Reference Point g-NSGA-II [37]", "startOffset": 26, "endOffset": 30}, {"referenceID": 34, "context": "GPS-EA[36]", "startOffset": 6, "endOffset": 10}, {"referenceID": 37, "context": "CP-NSGA-II [39]", "startOffset": 11, "endOffset": 15}, {"referenceID": 36, "context": "r-NSGA-II [38]", "startOffset": 10, "endOffset": 14}, {"referenceID": 38, "context": "R-NSGA-II [40]", "startOffset": 10, "endOffset": 14}, {"referenceID": 33, "context": "MOGA[35]", "startOffset": 4, "endOffset": 8}, {"referenceID": 41, "context": "2p-NSGA-II [43]", "startOffset": 11, "endOffset": 15}, {"referenceID": 40, "context": "SR-NSGA-II [42]", "startOffset": 11, "endOffset": 15}, {"referenceID": 39, "context": "ER-NSGA-II [41] AS-EMOA[49]", "startOffset": 11, "endOffset": 15}, {"referenceID": 47, "context": "ER-NSGA-II [41] AS-EMOA[49]", "startOffset": 23, "endOffset": 27}, {"referenceID": 46, "context": "PBEA[48]", "startOffset": 4, "endOffset": 8}, {"referenceID": 25, "context": "R2-EMOA[27] iPICEA-G[76]", "startOffset": 7, "endOffset": 11}, {"referenceID": 74, "context": "R2-EMOA[27] iPICEA-G[76]", "startOffset": 20, "endOffset": 24}, {"referenceID": 42, "context": "WASF-GA[44]", "startOffset": 7, "endOffset": 11}, {"referenceID": 43, "context": "iWASF-GA[45]", "startOffset": 8, "endOffset": 12}, {"referenceID": 123, "context": "WZ-MOEA/D[127]", "startOffset": 9, "endOffset": 14}, {"referenceID": 124, "context": "MOEA/D-PWA[128]", "startOffset": 10, "endOffset": 15}, {"referenceID": 44, "context": "R-MEAD[46]", "startOffset": 6, "endOffset": 10}, {"referenceID": 45, "context": "R-MEAD2[47]", "startOffset": 7, "endOffset": 11}, {"referenceID": 28, "context": "NSGA-III [30] RPSO-SS[51]", "startOffset": 9, "endOffset": 13}, {"referenceID": 49, "context": "NSGA-III [30] RPSO-SS[51]", "startOffset": 21, "endOffset": 25}, {"referenceID": 50, "context": "MDEPSO-RP[52]", "startOffset": 9, "endOffset": 13}, {"referenceID": 51, "context": "g-MOACO[53]", "startOffset": 7, "endOffset": 11}, {"referenceID": 55, "context": "Reference Direction RD-NSGA-II [57]", "startOffset": 31, "endOffset": 35}, {"referenceID": 54, "context": "LBS-NSGA-II [56]", "startOffset": 12, "endOffset": 16}, {"referenceID": 58, "context": "BCD-NSGA-II [60] R2-EMOA[27] iPICEA-G[129]", "startOffset": 12, "endOffset": 16}, {"referenceID": 25, "context": "BCD-NSGA-II [60] R2-EMOA[27] iPICEA-G[129]", "startOffset": 24, "endOffset": 28}, {"referenceID": 125, "context": "BCD-NSGA-II [60] R2-EMOA[27] iPICEA-G[129]", "startOffset": 37, "endOffset": 42}, {"referenceID": 56, "context": "pMOEA/D[58] MDEPSO-LBS[52]", "startOffset": 7, "endOffset": 11}, {"referenceID": 50, "context": "pMOEA/D[58] MDEPSO-LBS[52]", "startOffset": 22, "endOffset": 26}, {"referenceID": 126, "context": "r-PMOA[130]", "startOffset": 6, "endOffset": 11}, {"referenceID": 127, "context": "PRIMCSA[131]", "startOffset": 7, "endOffset": 12}, {"referenceID": 57, "context": "IPISA[59]", "startOffset": 5, "endOffset": 9}, {"referenceID": 78, "context": "Trade-off G-MOEA[80]", "startOffset": 16, "endOffset": 20}, {"referenceID": 79, "context": "pNSGA-II [81] CHI-SMS-EMOA[83]", "startOffset": 9, "endOffset": 13}, {"referenceID": 81, "context": "pNSGA-II [81] CHI-SMS-EMOA[83]", "startOffset": 26, "endOffset": 30}, {"referenceID": 80, "context": "CHI-EMOA[82]", "startOffset": 8, "endOffset": 12}, {"referenceID": 93, "context": "Pairwise Comparison NEMO-0[95]", "startOffset": 26, "endOffset": 30}, {"referenceID": 91, "context": "NEMO-I [93]", "startOffset": 7, "endOffset": 11}, {"referenceID": 92, "context": "NEMO-II [94]", "startOffset": 8, "endOffset": 12}, {"referenceID": 88, "context": "IEM-CO[90]", "startOffset": 6, "endOffset": 10}, {"referenceID": 98, "context": "DRSA-EMO-PCT[100]", "startOffset": 12, "endOffset": 17}, {"referenceID": 103, "context": "IEA-SOL[105]", "startOffset": 7, "endOffset": 12}, {"referenceID": 102, "context": "INSPM [104]", "startOffset": 6, "endOffset": 11}, {"referenceID": 89, "context": "EMAPS[91] iPMA[107]", "startOffset": 5, "endOffset": 9}, {"referenceID": 105, "context": "EMAPS[91] iPMA[107]", "startOffset": 14, "endOffset": 19}, {"referenceID": 95, "context": "Sample Ranks/Sorts PI-EMO-PC[97]", "startOffset": 28, "endOffset": 32}, {"referenceID": 128, "context": "PI-EMO-PC \u0301[132]", "startOffset": 11, "endOffset": 16}, {"referenceID": 70, "context": "iTDEA[72]", "startOffset": 5, "endOffset": 9}, {"referenceID": 99, "context": "BC-EMOA[101]", "startOffset": 7, "endOffset": 12}, {"referenceID": 94, "context": "PI-EMO-VF[96]", "startOffset": 9, "endOffset": 13}, {"referenceID": 96, "context": "IEA-PP[98]", "startOffset": 6, "endOffset": 10}, {"referenceID": 101, "context": "NN-DM-iTDEA[103]", "startOffset": 11, "endOffset": 16}, {"referenceID": 104, "context": "H-MCSGA[106]", "startOffset": 7, "endOffset": 12}, {"referenceID": 98, "context": "DRSA-EMO[100]", "startOffset": 8, "endOffset": 13}, {"referenceID": 100, "context": "MCGA-ANN [102]", "startOffset": 9, "endOffset": 14}, {"referenceID": 129, "context": "FFEA[133] iW-HypE[88]", "startOffset": 4, "endOffset": 9}, {"referenceID": 86, "context": "FFEA[133] iW-HypE[88]", "startOffset": 17, "endOffset": 21}, {"referenceID": 107, "context": "SPAM [109]", "startOffset": 5, "endOffset": 10}, {"referenceID": 108, "context": "I-SIBEA[110] iMOEA/D[108]", "startOffset": 7, "endOffset": 12}, {"referenceID": 106, "context": "I-SIBEA[110] iMOEA/D[108]", "startOffset": 20, "endOffset": 25}, {"referenceID": 90, "context": "iEMOA-QCVF[92]", "startOffset": 10, "endOffset": 14}, {"referenceID": 110, "context": "Outranking Parameters NOSGA[112]", "startOffset": 27, "endOffset": 32}, {"referenceID": 111, "context": "NOSGA-II [113] EvABOR-III [115]", "startOffset": 9, "endOffset": 14}, {"referenceID": 113, "context": "NOSGA-II [113] EvABOR-III [115]", "startOffset": 26, "endOffset": 31}, {"referenceID": 112, "context": "HESA[114]", "startOffset": 4, "endOffset": 9}, {"referenceID": 114, "context": "Knee Point KR-NSGA-II [116]", "startOffset": 22, "endOffset": 27}, {"referenceID": 115, "context": "TKR-NSGA-II [117]", "startOffset": 12, "endOffset": 17}, {"referenceID": 77, "context": "Classification of objective functions, for example, is one category of interactive MCDM methods [79].", "startOffset": 96, "endOffset": 100}, {"referenceID": 31, "context": "\u2022 Some PMOMH individuals have interactive version (such as W-HypE [33] and iW-HypE [88]) while some do not.", "startOffset": 66, "endOffset": 70}, {"referenceID": 86, "context": "\u2022 Some PMOMH individuals have interactive version (such as W-HypE [33] and iW-HypE [88]) while some do not.", "startOffset": 83, "endOffset": 87}, {"referenceID": 35, "context": "\u2022 Some PMOMH individuals use a new dominance relation to integrate preferences, such as g-dominance [37], r-dominance [38].", "startOffset": 100, "endOffset": 104}, {"referenceID": 36, "context": "\u2022 Some PMOMH individuals use a new dominance relation to integrate preferences, such as g-dominance [37], r-dominance [38].", "startOffset": 118, "endOffset": 122}, {"referenceID": 130, "context": "Related works can be found in [134, 135], which are all related to reference point-based approaches, other preference models should also be considered.", "startOffset": 30, "endOffset": 40}, {"referenceID": 131, "context": "Related works can be found in [134, 135], which are all related to reference point-based approaches, other preference models should also be considered.", "startOffset": 30, "endOffset": 40}], "year": 2017, "abstractText": "User preference integration is of great importance in multi-objective optimization, in particular in many objective optimization. Preferences have long been considered in traditional multicriteria decision making (MCDM) which is based on mathematical programming. Recently, it is integrated in multi-objective metaheuristics (MOMH), resulting in focus on preferred parts of the Pareto front instead of the whole Pareto front. The number of publications on preference-based multiobjective metaheuristics has increased rapidly over the past decades. There already exist various preference handling methods and MOMH methods, which have been combined in diverse ways. This article proposes to use the Web Ontology Language (OWL) to model and systematize the results developed in this field. A review of the existing work is provided, based on which an ontology is built and instantiated with state-of-the-art results. The OWL ontology is made public and open to future extension. Moreover, the usage of the ontology is exemplified for different usecases, including querying for methods that match an engineering application, bibliometric analysis, checking existence of combinations of preference models and MOMH techniques, and discovering opportunities for new research and open research questions.", "creator": "LaTeX with hyperref package"}}}