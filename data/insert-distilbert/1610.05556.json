{"id": "1610.05556", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Oct-2016", "title": "Identifiability and Transportability in Dynamic Causal Networks", "abstract": "in this paper we propose a causal analog to the purely observational dynamics dynamic bayesian networks, which we call dynamic causal networks. we provide a sound and complete algorithm for identification of genuine dynamic causal net - works, namely, for computing the effect of an intervention or experiment, based on passive observations arising only, whenever possible. we note the existence of two types of confounder of variables that affect in substantially different scale ways the iden - tification procedures, a distinction with no analog in either dynamic bayesian networks or standard causal activity graphs. next we further propose a procedure for examining the transportability of causal net effects in dynamic causal network settings, where the re - sult of causal experiments in a source domain may be used for the identification of causal factor effects in a target domain.", "histories": [["v1", "Tue, 18 Oct 2016 12:07:03 GMT  (157kb,D)", "http://arxiv.org/abs/1610.05556v1", "Presented at the 2016 ACM SIGKDD Workshop on Causal Discovery"]], "COMMENTS": "Presented at the 2016 ACM SIGKDD Workshop on Causal Discovery", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["gilles blondel", "marta arias", "ricard gavald\\`a"], "accepted": false, "id": "1610.05556"}, "pdf": {"name": "1610.05556.pdf", "metadata": {"source": "CRF", "title": "Identifiability and Transportability in Dynamic Causal Networks", "authors": ["Gilles Blondel", "Ricard Gavald\u00e0"], "emails": ["gillesblondel@yahoo.com", "marias@cs.upc.edu", "gavalda@cs.upc.edu"], "sections": [{"heading": null, "text": "Keywords Causal analysis \u00b7 Dynamic modeling"}, {"heading": "1 Introduction", "text": "Bayesian Networks (BN) are a canonical formalism for representing probability distributions over sets of variables and reasoning about them. A useful extension for modeling phenomena with recurrent temporal behavior are Dynamic Bayesian Networks (DBN). While regular BN are directed acyclic graphs, DBN may contain cycles, with some edges indicating dependence of a variable at time t + 1 on another variable at time t. The cyclic graph in fact compactly represents an infinite acyclic graph formed by infinitely many replicas of the\nG. Blondel Universitat Polite\u0300cnica de Catalunya E-mail: gillesblondel@yahoo.com\nM. Arias Universitat Polite\u0300cnica de Catalunya E-mail: marias@cs.upc.edu\nR. Gavalda\u0300 Universitat Polite\u0300cnica de Catalunya E-mail: gavalda@cs.upc.edu\ncyclic net, with some of the edges linking nodes in the same replica, and others linking nodes in consecutive replicas.\nBN and DBN model conditional (in)dependences, so they are restricted to observational, non-interventional data or, equivalently, model association, not causality. Pearl\u2019s causal graphical models and do-calculus [1] are a leading approach to modeling causal relations. They are formally similar to BN, as they are directed acyclic graphs with variables as nodes, but edges represent causality. A new notion is that of a confounder, an unobserved variable X that causally influences two variables Y and Z so that the association between Y and Z may erroneously be taken for causal influence. Confounders are unnecessary in BNs since the association between Y and Z represents their correlation, with no causality implied. Causal graphical models allow to consider the effect of interventions or experiments, that is, externally forcing the values of some variables regardless of the variables that causally affect them, and studying the results.\nThe do-calculus is an algebraic framework for reasoning about such experiments: An expression Pr(Y |do(X)) indicates the probability distribution of a set of variables Y upon performing an experiment on another set X . In some cases, the effect of such an experiment can be obtained from observational data only; this is convenient as some experiments may be impossible, expensive, or unethical to perform. When the expression Pr(Y |do(X)), for a given causal network, can be rewritten as an expression containing only observational probabilities, without a do operator, we say that it is identifiable. [2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.\nIn this paper we use a causal analog of DBNs to model phenomena where a finite set of variables evolves over time, with some variables causally influencing others at the same\nar X\niv :1\n61 0.\n05 55\n6v 1\n[ cs\n.A I]\n1 8\nO ct\n2 01\ntime t but also others at time t+ 1. The infinite DAG representing these causal relations can be folded, if regular enough, into a directed graph, with some edges indicating intra-replica causal effects and other indicating effect on variables in the next replica. Central to this representation is of course the intuitive fact that causal relations are directed towards the future, and never towards the past.\nExisting work on dynamic causal models focuses on the discovery of causal models from data and on causal reasoning given a causal model. Regarding the discovery of causal models in dynamic systems [4] and [5] propose an algorithm to establish an ordering of the variables corresponding to the temporal order of propagation of causal effects. Methods for the discovery of cyclic causal graphs from data have been proposed using independent component analysis [6] and using local d-separation criteria [7]. Existing algorithms for causal discovery from static data have been extended to the dynamic setting by [8] and [9]. [10,11,12] discuss the discovery of causal graphs from time series by including granger causality concepts into their causal models. Our paper does not address causal discovery from data. Given the formal description of a dynamic system under a set of assumptions, our paper proposes algorithms that identify the modified trajectory of the system over time, after an intervention.\nDynamic causal systems are often modeled with sets of differential equations. However [13] [14] [15] show the caveats of causal discovery of dynamic models based on differential equations which pass through equilibrium states, and how causal reasoning based on such models may fail. [16] propose an algorithm for discovery of causal relations based on differential equations while ensuring those caveats due to system equilibrium states are taken into account. Time scale and sampling rate at which we observe a dynamic system play a crucial role in how well the obtained data may represent the causal relations in the system. [17] discuss the difficulties of representing a dynamic system with a DAG built from discrete observations and [18] argue that under some conditions the discovery of temporal causal relations is feasible from data sampled at lower rate than the system dynamics. Our paper assumes that the observation time-scale is sufficiently small compared to the system dynamics, and that causal models include the non-equilibrium causal relations and not only those under equilibrium states. We assume that a stable set of causal dependencies exist which generate the system evolution along time. Our proposed algorithms take such models (and under these assumptions) as an input and predict the system evolution upon intervention on the system.\nRegarding causal reasoning given a dynamic causal model, one line of research is based on time series and granger causality concepts [19,20,21]. [22] use multivariate time series for identification of causal effects in traffic flow mod-\nels. [23] discuss intervention in dynamic systems in equilibrium, for several types of time-discreet and time-continuous generating processes with feedback. [24] uses local independence graphs to represent time-continuous dynamic systems and identify the effect of interventions by re-weighting involved processes.\nExisting work on causal models does not thoroughly address causal reasoning in dynamic systems using do-calculus. [19,20,21] discuss back-door and front-door criteria in timeseries but do not extend to the full power of do-calculus as a complete logic for causal identification. One of the advantages of do-calculus is its non-parametric approach so that it leaves the type of functional relation between variables undefined. Our paper extends the use of do-calculus to time series while requiring less restrictions than parametric causal analysis. Parametric approaches may require to differentiate the intervention impacts depending on the system state, non-equilibrium or equilibrium, while our non parametric approach is generic across system states.\nRequired work is to precisely define the notion and semantics of do-calculus and unobserved confounders in the dynamic setting and investigate whether and how existing do-calculus algorithms for identifiability of causal effects can be applied to the dynamic case.\nAs a running example (more for motivation than for its accurate modeling of reality), let us consider two roads joining the same two cities, where drivers choose every day to use one or the other road. The average travel delay between the two cities any given day depends on the traffic distribution among the two roads. Drivers choose between a road or another depending on recent experience, in particular how congested a road was last time they used it. Figure 1 indicates these relations: the weather(w) has an effect on traffic conditions on a given day (tr1, tr2) which affects the travel delay on that same day (d). Driver experience influences the road choice next day, impacting tr1 and tr2. To simplify, we assume that drivers have short memory, being influenced by the conditions on the previous day only. This infinite network can be folded into a finite representation as shown in Figure 2, where +1 indicates an edge linking two consecutive replicas of the DAG. Additionally, if one assumes the weather to be an unobserved variable then it becomes a confounder as it causally affects two observed variables, as shown in Figure 3. We call the confounders with causal effect over variables in the same time slice static confounders, and confounders with causal effect over variables at different time slices dynamic confounders. Our models allow for causal identification with both types of confounders, as will be discussed in Section 4.\nThis setting enables the resolution of causal effect identification problems where causal relations are recurrent over time. These problems are not solvable in the context of classic DBNs, as causal interventions are not defined in such\nmodels. For this we use causal networks and do-calculus. However, time dependencies can\u2019t be modeled with static causal networks. As we want to predict the trajectory of the system over time after an intervention, we must use a dynamic causal network. Using our example, in order to reduce travel delay traffic controllers could consider actions such as limiting the number of vehicles admitted to one of the two roads. We would like to predict the effect of such action on the travel delay a few days later, e.g. Pr(dt+\u03b1|do(tr1t)).\nOur contributions in this paper are:\n\u2013 We introduce Dynamic Causal Networks (DCN) as an analog of Dynamic Bayesian Networks for causal reasoning in domains that evolve over time. We show how to transfer the machinery of Pearl\u2019s do-calculus [1] to DCN. \u2013 We extend causal identification algorithms [25,2,26] to the identifiability of causal effects in DCN settings. Given the expression P (Yt+\u03b1|do(Xt)), the algorithms either compute an equivalent do-free formula or conclude that such a formula does not exist. In the first case, the new formula provides the distribution of variables Y at time t+ \u03b1 given that a certain experiment was performed on variables X at time t. For clarity, we present first an algorithm that is sound but not complete (Section 4), then give a complete one that is more involved to describe and justify (Section 5). \u2013 Unobserved confounder variables are central to the formalism of do-calculus. We observe a subtle difference between two types of unobserved confounder variables in DCN (which we call static and dynamic). This distinction is genuinely new to DCN, as it appears neither in DBN nor in standard causal graphs, yet the presence or absence of unobserved dynamic confounders has crucial impacts on the post-intervention evolution of the system over time and on the computational cost of the algorithms. \u2013 Finally, we extend from standard Causal Graphs to DCN the results by [27] on transportability, namely on whether causal effects obtained from experiments in one domain can be transferred to another domain with similar causal structure. This opens the way to studying relational knowledge transfer learning [28] of causal information in domains with a time component."}, {"heading": "2 Previous Definitions and Results", "text": "In this section we review the definitions and basic results on the three existing notions that are the basis of our work: DBN, causal networks, and do-calculus. New definitions introduced in this paper are left for Section 3.\nAll formalisms in this paper model joint probability distributions over a set of variables. For static models (regular\nBN and Causal Networks) the set of variables is fixed. For dynamic models (DBN and DCN), there is a finite set of \u201cmetavariables\u201d, meaning variables that evolve over time. For a metavariable X and an integer t, Xt is the variable denoting the value of X at time t.\nLet V be the set of metavariables for a dynamic model. We say that a probability distribution P is time-invariant if P (Vt+1|Vt) is the same for every t. Note that this does not mean that P (Vt) = P (Vt+1) for every t, but rather that the laws governing the evolution of the variable do not change over time. For example, planets do change their positions around the Sun, but the Kepler-Newton laws that govern their movement do not change over time. Even if we performed an intervention (say, pushing the Earth away from the Sun for a while), these laws would immediately kick in again when we stopped pushing. The system would not be time-invariant if e.g. the gravitational constant changed over time.\n2.1 Dynamic Bayesian Networks\nDynamic Bayesian Networks (DBN) are graphical models that generalize Bayesian Networks (BN) in order to model time-evolving phenomena. We rephrase them as follows.\nDefinition 1 A DBN is a directed graph D over a set of nodes that represent time-evolving metavariables. Some of the arcs in the graph have no label, and others are labeled \u201c+1\u201d. It is required that the sub-graph G formed by the nodes and the unlabeled edges must be acyclic, therefore forming a Directed Acyclic Graph (DAG). Unlabeled arcs denote dependence relations between metavariables within the same time step, and arcs labeled \u201c+1\u201d denote dependence between a variable at one time and another variable at the next time step.\nDefinition 2 A DBN with graph G represents an infinite Bayesian Network G\u0302 as follows. Timestamps t are the integer numbers; G\u0302 will thus be a biinfinite graph. For each metavariable X in G and each time step t there is a variable\nXt in G\u0302. The set of variables indexed by the same t is denoted Gt and called \u201cthe slice at time t\u201d. There is an edge from Xt to Yt iff there is an unlabeled edge from X to Y in G, and there is an edge from Xt to Yt+1 iff there is an edge labeled \u201c+1\u201d from X to Y in G. Note that G\u0302 is acyclic.\nThe set of metavariables in G is denoted V (G), or simply V when G is clear from the context. Similarly Vt(G) or Vt denote the variables in the t-th slice of G.\nIn this paper we will also use transition matrices to model probability distributions. Rows and columns are indexed by tuples assigning values to each variable, and the (v, w) entry of the matrix represents the probability P (Vt+1 = w|Vt = v). Let Tt denote this transition matrix. Then we have, in matrix notation, P (Vt+1) = Tt P (Vt) and, more in general, P (Vt+\u03b1) = ( \u220ft+\u03b1\u22121 i=t Ti)P (Vt). In the case of timeinvariant distributions, all Tt matrices are the same matrix T , so P (Vt+\u03b1) = T\u03b1P (Vt).\n2.2 Causality and Do-Calculus\nThe notation used in our paper is based on causal models and do-calculus [1,29].\nDefinition 3 (Causal Model) A causal model over a set of variables V is a tuple M = \u3008V,U, F, P (U)\u3009, where U is a set of random variables that are determined outside the model (\u201dexogenous\u201d or \u201dunobserved\u201d variables) but that can influence the rest of the model, V = {V1, V2, ...Vn} is a set of n variables that are determined by the model (\u201dendogenous\u201d or \u201dobserved\u201d variables), F is a set of n functions such that Vk = fk(pa(Vk), Uk, \u03b8k), pa(Vk) are the parents of Vk inM , \u03b8k are a set of constant parameters and P (U) is a joint probability distribution over the variables in U .\nIn a causal model the value of each variable Vk is assigned by a function fk which is determined by constant parameters \u03b8k, a subset of V called the \u201dparents\u201d of Vk (pa(Vk)) and a subset of U (Uk).\nA causal model has an associated graphical representation (also called the \u201dinduced graph of the causal model\u201d) in which each observed variable Vk corresponds to a vertex, there is one edge pointing to Vk from each of its parents, i.e. from the set of vertex pa(Vk) and there is a doublypointed edge between the vertex influenced by a common unobserved variable inU (see Figure 3). In this paper we call the unobserved variables in U \u201dunobserved confounders\u201d or \u201dconfounders\u201d for simplicity.\nCausal graphs encode the causal relations between variables in a model. The primary purpose of causal graphs is to help estimate the joint probability of some of the variables in the model upon controlling some other variables by forcing them to specific values; this is called an action, experiment\nor intervention. Graphically this is represented by removing all the incoming edges (which represent the causes) of the variables in the graph that we control in the experiment. Mathematically the do() operator represents this experiment on the variables. Given a causal graph where X and Y are sets of variables, the expression P (Y |do(X)) is the joint probability of Y upon doing an experiment on the controlled set X .\nA causal relation represented by P (Y |do(X)) is said to be identifiable if it can be uniquely computed from an observed, non-interventional, distribution of the variables in the model. In many real world scenarios it is impossible, impractical, unethical or too expensive to perform an experiment, thus the interest in evaluating its effects without actually having to perform the experiment.\nThe three rules of do-calculus [1] allow us to transform expressions with do() operators into other equivalent expressions, based on the causal relations present in the causal graph.\nFor any disjoint sets of variables X , Y , Z and W :\n1. P (Y |Z,W, do(X)) = P (Y |W,do(X)) if (Y \u22a5 Z|X,W )GX 2. P (Y |W,do(X), do(Z)) = P (Y |Z,W, do(X)) if (Y \u22a5 Z|X,W )GXZ 3. P (Y |W,do(X), do(Z)) = P (Y |W,do(X)) if (Y \u22a5 Z|X,W )G\nXZ(W )\nGX is the graph G where all edges incoming to X are removed. GZ is the graph G where all edges outgoing from Z are removed. Z(W) is the set of Z-nodes that are not ancestors of any W-nodes in GX .\nDo-calculus was proven to be complete [2,3] in the sense that if an expression cannot be converted into a do-free one by iterative application of the three do-calculus rules, then it is not identifiable.\n2.3 The ID Algorithm\nThe ID algorithm [2], and earlier versions by [30,31] implement an iterative application of do-calculus rules to transform a causal expressionP (Y |do(X)) into an equivalent expression without any do() terms in semi-Markovian causal\ngraphs (with confounders). This enables the identification of interventional distributions from non-interventional data in such graphs.\nThe ID algorithm is sound and complete [2] in the sense that if a do-free equivalent expression exists it will be found by the algorithm, and if it does not exist the algorithm will exit and provide an error.\nThe algorithm specifications are as follows. Inputs: causal graph G, variable sets X and Y , and a probability distribution P over the observed variables in G; Output: an expression for P (Y |do(X)) without any do() terms, or fail.\nRemark: In our algorithms of Sections 4 and 5, we may invoke the ID algorithm with a slightly more complex input: P (Y |Z, do(X)) (note the \u201cextra\u201d Z to the right of the conditioning bar). In this case, we can solve the identification problem for the more complex expression with two calls to the ID algorithm using the following identity (definition of conditional probability):\nP (Y |Z, do(X)) = P (Y, Z|do(X)) P (Z|do(X))\nThe expressionP (Y |Z, do(X)) is thus identifiable if and only if both P (Y,Z|do(X)) and P (Z|do(X)) are [2].\nAnother algorithm for the identification of causal effects is given in [26].\nThe algorithms we propose in this paper show how to apply existing causal identification algorithms to the dynamic setting. In this paper we will refer as \u201dID algorithm\u201d any existing causal identification algorithm."}, {"heading": "3 Dynamic Causal Networks and Do-Calculus", "text": "In this section we introduce the main definitions of this paper and state several lemmas based on the application of docalculus rules to DCNs.\nIn the Definition 3 of causal model the functions fk are left unspecified and can take any suitable form that best describes the causal dependencies between variables in the model. In natural phenomenon some variables may be time independent while others may evolve over time. However rarely does Pearl specifically treat the case of dynamic variables.\nThe definition of Dynamic Causal Network is an extension of Pearl\u2019s causal model in Definition 3, by specifying that the variables are sampled over time, as in [32].\nDefinition 4 (Dynamic Causal Network) A dynamic causal network D is a causal model in which the set F of functions is such that Vk,t = fk(pa(Vk,t), Uk,t\u2212\u03b1, \u03b8k); where Vk,t is the variable associated with the time sampling t of the observed process Vk; Uk,t\u2212\u03b1 is the variable associated with the time sampling t \u2212 \u03b1 of the unobserved process Uk; t and \u03b1 are discreet values of time.\nNote that pa(Vk,t) may include variables in any time sampling previous to t up to and including t, depending on the delays of the direct causal dependencies between processes in comparison with the sampling rate. Uk,t\u2212\u03b1 may be generated by a noise process or by an unobserved confounder. In the case of noise, we assume that all noise processes Uk are independent of each other, and that their influence to the observed variables happens without delay, so that \u03b1 = 0. In the case of unobserved confounders, we assume \u03b1 \u2265 0 as causes precede their effects.\nTo represent unobserved confounders in DCN, we extend to the dynamic context the framework developed in [33] on causal model equivalence and latent structure projections. Let\u2019s consider the projection algorithm [34], which takes a causal model with unobserved variables and finds an equivalent model (with the same set of causal dependencies), called a \u201ddependency-equivalent projection\u201d, but with no links between unobserved variables and where every unobserved variable is a parent of exactly two observed variables.\nThe projection algorithm in DCN works as follows. For each pair (Vm, Vn) of of observed processes, if there is a directed path from Vm,t to Vn,t+\u03b1 through unobserved processes then we assign a directed edge from Vm,t to Vn,t+\u03b1; however if there is a divergent path between them through unobserved processes then we assign a bidirected edge, representing an unobserved confounder.\nIn this paper we represent all DCN by their dependencyequivalent projection. Also we assume the sampling rate to be adjusted to the dynamics of the observed processes. However, both the directed edges and the unobserved confounder paths may be crossing several time steps depending on the delay of the direct causal dependencies in comparison with the sampling rate. We now introduce the concept of static and dynamic confounder.\nDefinition 5 (Static Confounder) Let D be a DCN. Let \u03b2 be the maximal number of time steps crossed by any of the directed edges in D. Let \u03b1 be the maximal number of time steps crossed by an unobserved confounder path. If \u03b1 \u2264 \u03b2 then the unobserved confounder is called Static.\nDefinition 6 (Dynamic Confounder) Let D, \u03b2 and \u03b1 be as in Definition 5. If \u03b1 > \u03b2 then the unobserved confounder is called Dynamic. More specifically, if \u03b2 < \u03b1 \u2264 2\u03b2 we call it \u201dfirst order\u201d Dynamic Confounder; if \u03b1 > 2\u03b2 we call it \u201dhigher order\u201d Dynamic Confounder.\nIn this paper, we consider three case scenarios in regards to DCN and their time-invariance properties. If a DCN D contains only static confounders we can construct a first order Markov process in discrete time, by taking \u03b2 (per Definition 5) consecutive time samples of the observed processes Vk in D. This does not mean the DCN generating functions\nfk in Definition 4 are time-invariant, but that a first order Markov chain can be built over the observed variables when marginalizing the static confounders over \u03b2 time samples.\nIn a second scenario, we consider DCN with first order dynamic confounders. We can still construct a first order Markov process in discrete time, by taking \u03b2 consecutive time samples. However we will see in later sections how the effect of interventions on this type of DCN has a different impact than on DCN with static confounders.\nFinally, we consider DCN with higher order dynamic confounders, in which case we may construct a first order Markov process in discrete time by taking a multiple of \u03b2 consecutive time samples.\nAs we will see in later sections, the difference between these three types of DCN is crucial in the context of identifiability. Dynamic confounders cause a time invariant transition matrix to become dynamic after an intervention, e.g. the post-intervention transition matrix will change over time. However, if we perform an intervention on a DCN with static confounders, the network will return to its previous timeinvariant behavior after a transient period. These differences have a great impact on the complexity of the causal identification algorithms that we present.\nConsidering that causes precede their effects, the associated graphical representation of a DCN is a DAG. All DCN can be represented as a biinfinite DAG with vertices Vk,t; edges from pa(Vk,t) to Vk,t; and confounders (bi-directed edges). DCN with static confounders and DCN with first order dynamic confounders can be compactly represented as \u03b2 time samples (a multiple of \u03b2 time samples for higher order dynamic confounders) of the observed processes Vk,t; their corresponding edges and confounders; and some of the directed and bi-directed edges marked with a \u201d+1\u201d label representing the dependencies with the next time slice of the DCN.\nDefinition 7 (Dynamic Causal Network identification) Let D be a DCN, and t, t+\u03b1 be two time slices of D. Let X be a subset of Vt and Y be a subset of Vt+\u03b1. The DCN identification problem consists of computing the probability distribution P (Y |do(X)) from the observed probability distributions in D, i.e. computing an expression for the distribution containing no do() operators.\nIn the definition above we always assume that X and Y are disjoint. In this version we only consider the case in which all intervened variables X are in the same time sample. It is not difficult to extend our algorithm to the general case.\nThe following lemma is based on the application of docalculus to DCN. Intuitively, future actions have no impact on the past.\nLemma 1 (Future actions) Let D be a DCN. Take any sets X \u2286 Vt and Y \u2286 Vt\u2212\u03b1, with \u03b1 > 0. Then for any set Z the following equalities hold:\n1. P (Y |do(X), do(Z)) = P (Y |do(Z)) 2. P (Y |do(X)) = P (Y ) 3. P (Y |Z, do(X)) = P (Y |Z) whenever Z \u2286 Vt\u2212\u03b2 with \u03b2 > 0.\nProof The first equality derives from rule 3 and the proof in [2] that interventions on variables which are not ancestors of Y in D have no effect on Y . The second is the special case Z = \u2205. We can transform the third expression using the equivalenceP (Y |Z, do(X)) = P (Y,Z|do(X))/P (Z|do(X)); since Y and Z precedeX inD, by rule 3 P (Y,Z|do(X)) = P (Y,Z) and P (Z|do(X)) = P (Z), and then the above equals P (Y,Z)/P (Z) = P (Y |Z). ut\nIn words, traffic control mechanisms applied next week have no causal effect on the traffic flow this week.\nThe following lemma limits the size of the graph to be used for the identification of DCNs.\nLemma 2 Let D be a DCN. Let G be the sub-graph of D\u0302 consisting of all time slices in between (and including) tx and ty . Let G\u2032 be the sub-graph G augmented with the time slice preceding it. If P (Y |do(X)) is identifiable in D then it is identifiable in G\u2032 and the identification provides the same result on both graphs.\nProof (sketch) By C-component factorization [25], we decompose the problem as that of identification of each Ccomponent in D and (if all C-components are identifiable) multiplying all identified quantities to obtain P (Y |do(X)). C-components are sets of variables linked by confounder edges in the graph D \\ X . An identifiable C-component is computed as the product of P (vi|V i\u22121\u03c0 ) for each variable vi in the C-component, where V i\u22121\u03c0 is the set of all variables preceding vi in some topological ordering \u03c0 [2,25]. The Ccomponent factorization involving all the variables preceding the setG leads to the joint distribution of these variables, and can be computed using the joint distribution of the time slice precedingG alone. Also, non-ancestors of Y can be ignored from the graph, by application of do-calculus rule 3, so time slices succeeding G can be discarded. Therefore the identification problem can be computed in the limited graph G\u2032.\nThis result is crucial to reduce the complexity of identification algorithms in dynamic settings. In order to describe the evolution of a dynamic system over time, after an intervention, we can run a causal identification algorithm over a limited number of time slices of the DCN, instead of the entire DCN. ut"}, {"heading": "4 Identifiability in Dynamic Causal Networks", "text": "In this section we analyze the identifiability of causal effects in the DCN setting. We first study DCNs with static confounders and propose a method for identification of causal effects in DCNs using transition matrices. Then we extend the analysis and identification method to DCNs with dynamic confounders. As discussed in Section 3, both the DCNs with static confounders and with dynamic confounders can be represented as a Markov chain. For graphical and notational simplicity, we represent these DCN graphically as recurrent time slices as opposed to the shorter time samples, on the basis that one time slice contains as many time samples as the maximal delay of direct causal influence among the processes. Also for notational simplicity we assume the transition matrix from one time slice to the next to be timeinvariant; however removing this restriction would not make any of the lemmas, theorems or algorithms invalid, as they are the result of graphical non-parametric reasoning.\nConsider a DCN under the above assumptions, and let T be its time invariant transition matrix from any time slice Vt to Vt+1. We assume that there is some time t0 such that the distribution P (Vt0) is known. Fix now tx > t0 and a set X \u2286 Vtx . We will now see how performing an intervention on X affects the distributions in D.\nWe begin by stating a series of lemmas that apply to DCNs in general.\nLemma 3 Let t be such that t0 \u2264 t < tx, with X \u2286 Vtx . Then P (Vt|do(X)) = T t\u2212t0P (Vt0). Namely, transition probabilities are not affected by an intervention in the future.\nProof By Lemma 1, (2), P (Vt|do(X)) = P (Vt) for all such t. By definition of T , this equals T P (Vt\u22121). Then induct on t with P (Vt0) = T 0P (Vt0) as base. ut\nLemma 4 Assume that an expression P (Vt+\u03b1|Vt, do(X)) is identifiable for some \u03b1 > 0. LetA be the matrix whose entriesAij correspond to the probabilities P (Vt+\u03b1 = vj |Vt = vi, do(X)). Then P (Vt+\u03b1|do(X)) = AP (Vt|do(X)).\nProof Case by case evaluation of A\u2019s entries. ut\n4.1 DCNs with Static Confounders\nStatic confounders impact sets of variables within one time slice only, and there are no confounders between variables at different time slices (see Figure 3).\nThe following three lemmas are based on the application of do-calculus to DCNs with static confounders. Intuitively, conditioning on the variables that cause time dependent effects d-separates entire parts (future from past) of the DCN (Lemmas 5, 6, 7).\nLemma 5 (Past observations and actions) LetD be a DCN with static confounders. Take any set X . Let C \u2286 Vt be the set of variables in Gt that are direct causes of variables in Gt+1. Let Y \u2286 Vt+\u03b1 and Z \u2286 Vt\u2212\u03b2 , with \u03b1 > 0 and \u03b2 > 0 (positive natural numbers). The following distributions are identical:\n1. P (Y |do(X), Z, C) 2. P (Y |do(X), do(Z), C) 3. P (Y |do(X), C)\nProof By the graphical structure of a DCN with static confounders, conditioning on C d-separates Y from Z. The three rules of do-calculus apply, and (1) equals (3) by rule 1, (1) equals (2) by rule 2, and also (2) equals (3) by rule 3. ut\nIn our example, we want to predict the traffic flow Y in two days caused by traffic control mechanisms applied tomorrow X , and conditioned on the traffic delay today C. Any traffic controls Z applied before today are irrelevant, because their impact is already accounted for in C.\nLemma 6 (Future observations) Let D, X and C be as in Lemma 5. Let Y \u2286 Vt\u2212\u03b1 and Z \u2286 Vt+\u03b2 , with \u03b1 > 0 and \u03b2 > 0, then:\nP (Y |do(X), Z, C) = P (Y |do(X), C)\nProof By the graphical structure of a DCN with static confounders, conditioning on C d-separates Y from Z and the expression is valid by rule 1 of do-calculus. ut\nIn our example, observing the travel delay today makes observing the future traffic flow irrelevant to evaluate yesterday\u2019s traffic flow.\nLemma 7 Let t > tx. ThenP (Vt+1|do(X)) = T P (Vt|do(X)). Namely, transition probabilities are not affected by intervention more than one time unit in the past.\nProof P (Vt+1|do(X)) = T \u2032 P (Vt|do(X)) where the elements of T \u2032 are P (Vt+1|Vt, do(X)). As Vt includes all variables in Gt that are direct causes of variables in Gt+1, conditioning on Vt d-separates X from Vt+1. By Lemma 5 we exchange the action do(X) by the observation X and so P (Vt+1|Vt, do(X)) = P (Vt+1|Vt, X). Moreover, Vt d-separates X from Vt+1, so they are statistically independent given Vt. Therefore,P (Vt+1|Vt, do(X)) = P (Vt+1|Vt, X) = P (Vt+1|Vt) which are the elements of matrix T as required. ut\nTheorem 1 Let D be a DCN with static confounders, and transition matrix T . Let X \u2286 Vtx and Y \u2286 Vty for two time points tx < ty . If the expression P (Vtx+1|Vtx\u22121, do(X)) is identifiable with corresponding transition matrix A, then P (Y |do(X)) is identifiable and\nP (Y |do(X)) = \u2211 Vty\\Y T ty\u2212(tx+1)AT tx\u22121\u2212t0P (Vt0).\nProof Applying Lemma 3, we obtain thatP (Vtx\u22121|do(X)) = T tx\u22121\u2212t0P (Vt0). We assumed that P (Vtx+1|Vtx\u22121, do(X)) is identifiable, therefore Lemma 4 guarantees that\nP (Vtx+1|do(X)) = AP (Vtx\u22121|do(X)) = AT tx\u22121\u2212t0P (Vt0).\nFinally, P (Vty |do(X)) = T (ty\u2212(tx+1))P (Vtx+1|do(X)) by repeatedly applying Lemma 7. P (Y |do(X)) is obtained by marginalizing variables in Vty \\Y in the resulting expression T ty\u2212(tx+1)AT tx\u22121\u2212t0P (Vt0). ut\nAs a consequence of Theorem 1, causal identification of D reduces to the problem of identifying the expression P (Vtx+1|Vtx\u22121, do(X)). The ID algorithm can be used to check whether this expression is identifiable and, if it is, compute its joint probability from observed data.\nNote that Theorem 1 holds without the assumption of transition matrix time-invariance by replacing powers of T with products of matrices Tt."}, {"heading": "4.1.1 DCN-ID Algorithm for DCNs with Static Confounders", "text": "The DCN-ID algorithm for DCNs with static confounders is given in Figure 4. Its soundness is immediate from Theorem 1, the soundness of the ID algorithm [2], and Lemma 2.\nTheorem 2 (Soundness) Whenever DCN-ID returns a distribution for P (Y |do(X)), it is correct. ut\nObserve that line 2 of the algorithm calls ID with a graph of size 4|G|. By the remark of Section 2.3, this means two calls but notice that in this case we can spare the call for the \u201cdenominator\u201d P (Vtx\u22121|do(X)) because Lemma 1 guarantees P (Vtx\u22121|do(X)) = P (Vtx\u22121). Computing transition matrix A on line 3 has complexity O((4k)(b+2)), where k is the number of variables in one time slice and b the number of bits encoding each variable. The formula on line 4 is the multiplication of P (Vt0) by n = (ty \u2212 t0) matrices, which has complexityO(n.b2). To solve the same problem with the ID algorithm would require running it on the entire graph of size n|G| and evaluating the resulting joint probability with\ncomplexityO((n.k)(b+2)) compared toO((4k)(b+2)+n.b2) with DCN-ID.\nIf the problem we want to solve is evaluating the trajectory of the system over time\n(P (Vtx+1), P (Vtx+2), P (Vtx+3), ...P (Vtx+n))\nafter an intervention at time slice tx, with ID we would need to run ID n times and evaluate the n outputs with overall complexity O((k)(b+2) + (2k)(b+2) + (3k)(b+2) + ... + (n.k)(b+2)). Doing the same with DCN-ID requires running ID one time to identify P (Vtx+1), evaluating the output and applying successive transition matrix multiplications to obtain the joint probability of the time slices thereafter, with resulting complexity O((4k)(b+2) + n.b2).\n4.2 DCNs with Dynamic Confounders\nWe now discuss the case of DCNs with dynamic confounders, that is, with confounders that influence variables in consecutive time slices.\nThe presence of dynamic confounders d-connects time slices, and we will see in the following lemmas how this may be an obstacle for the identifiability of the DCN.\nIn the presence of dynamic confounders, Lemma 7 does no longer hold since d-separation is no longer guaranteed. As a consequence, we cannot guarantee the DCN will recover its \u201cnatural\u201d (non-interventional) transition probabilities from one cycle to the next after the intervention is performed.\nOur statement of the identifiability theorem for DCNs with dynamic confounders is weaker and includes in its assumptions those conditions that can no longer be guaranteed.\nTheorem 3 LetD be a DCN with dynamic confounders. Let T be its transition matrix under no interventions. We further assume that:\n1. P (Vtx+1|Vtx\u22121, do(X)) is identifiable by matrix A 2. For all t > tx + 1, P (Vt|Vt\u22121, do(X)) is identifiable by\nmatrix Mt\nThen P (Y |do(X) is identifiable and computed by\nP (Y |do(X)) = \u2211 Vty\\Y\n[ ty\u220f\nt=tx+2\nMt ] AT tx\u22121\u2212t0P (Vt0).\nProof Similar to the proof of Theorem 1. By Lemma 3, we can compute the distribution up to time tx \u2212 1 as\nP (Vtx\u22121|do(X)) = T tx\u22121\u2212t0P (Vt0).\nUsing the first assumption in the statement of the theorem, by Lemma 4 we obtain\nP (Vtx+1|do(X)) = AT tx\u22121\u2212t0P (Vt0).\nThen, we compute the final P (Vty |do(X)) using the matrices Mt from the statement of the theorem that allows us to compute probabilities for subsequent time-slices. Namely,\nP (Vtx+2|do(X)) =Mtx+2AT tx\u22121\u2212t0P (Vt0), P (Vtx+3|do(X)) =Mtx+3Mtx+2AT tx\u22121\u2212t0P (Vt0),\nand so on until we find\nP (Vty |do(X)) =\n[ ty\u220f\nt=tx+2\nMt ] AT tx\u22121\u2212t0P (Vt0).\nFinally, the do-free expression of P (Y |do(X)) is obtained by marginalization over variables of Vty not in Y . ut\nAgain, note that Theorem 3 holds without the assumption of transition matrix time-invariance by replacing powers of T with products of matrices Tt."}, {"heading": "4.2.1 DCN-ID Algorithm for DCNs with Dynamic Confounders", "text": "Function DCN-ID(Y ,ty , X ,tx, G,C,C\u2032,T ,P (Vt0)) INPUT:\n\u2013 DCN defined by a causal graph G on a set of variables V and a set C \u2286 V \u00d7 V describing causal relations from Vt to Vt+1 for every t, and a set C\u2032 \u2286 V \u00d7 V describing confounder relations from Vt to Vt+1 for every t \u2013 transition matrix T for G derived from observational data \u2013 a set Y included in Vty \u2013 a set X included in Vtx \u2013 distribution P (Vt0) at the initial state,\nOUTPUT: The distribution P (Y |do(X)), or else FAIL\n1. let G\u2032 be the acyclic graph formed by joining Gtx\u22122, Gtx\u22121, Gtx , and Gtx+1 by the causal relations given by C and confounders given by C\u2032; 2. run the standard ID algorithm for expression P (Vtx+1|Vtx\u22121, do(X)) on G\u2032; if it returns FAIL, return FAIL; 3. else, use the resulting distribution to compute the transition matrix A, where Aij = P (Vtx+1 = vi|Vtx\u22121 = vj , do(X)); 4. for each t from tx + 2 up to ty : (a) let G\u2032\u2032 be the causal graph composed of time slices Gtx\u22121,\nGtx , . . . , Gt (b) run the standard ID algorithm on G\u2032\u2032 for the expression\nP (Vt|Vt\u22121, do(X)); if it returns FAIL, return FAIL; (c) else, use the resulting distribution to compute the transi-\ntion matrix Mt, where (Mt)ij = P (Vt = vi|Vt\u22121 = vj , do(X));\n5. return \u2211\nVty\\Y\n[ ty\u220f\nt=tx+2\nMt ] AT tx\u22121\u2212t0P (Vt0);\nFig. 5 The DCN-ID algorithm for DCNs with dynamic confounders\nThe DCN-ID algorithm for DCNs with dynamic confounders is given in Figure 5.\nIts soundness is immediate from Theorem 3, the soundness of the ID algorithm [2], and Lemma 2.\nTheorem 4 (Soundness) Whenever DCN-ID returns a distribution for P (Y |do(X)), it is correct. ut\nNotice that this algorithm is more expensive than the DCN-ID algorithm for DCNs with static confounders. In particular, it requires (ty \u2212 tx) calls to the ID algorithm with increasingly larger chunks of the DCN. To identify a single future effect P (Y |do(X) it may be simpler to invoke Lemma 2 and do a unique call to the ID algorithm for the expression P (Y |do(X) restricted to the causal graph formed by time-slices Gtx\u22121, ..., Gty . However, to predict the trajectory of the system over time after an intervention, the DCN-ID algorithm for dynamic confounders directly identifies the post-intervention transition matrix and its evolution. A system characterized by a time-invariant transition matrix\nbefore the intervention will be characterized by a time dependent transition matrix, given by the DCN-ID algorithm, after the intervention. This dynamic view offers opportunities for the analysis of the time evolution of the system, and conditions for convergence to a steady state."}, {"heading": "5 Complete DCN Identifiability", "text": "In this section we show that the identification algorithms as formulated in previous sections are not complete, and we develop complete algorithms for complete identification of DCNs. To prove completeness we use previous results [2]. It is shown there that the absence of a structure called \u2019hedge\u2019 in the graph is a sufficient and necessary condition for identifiability. We first define some graphical structures that lead to the definition of hedge, in the context of DCNs.\nDefinition 8 (C-component) Let D be a DCN. Any maximal subset of variables of D connected by bidirected edges (confounders) is called a C-component.\nDefinition 9 (C-forest) LetD be a DCN andC a C-component of D. If all variables in C have at most one child, then C is called a C-forest. The set R of variables in C that have no descendants is called the C-forest root, and the C-forest is called R-rooted.\nDefinition 10 (Hedge) Let X and Y be sets of variables in D. Let F and F \u2032 be two R-rooted C-forests such that F \u2032 \u2286 F , F \u2229X 6= \u2205, F \u2032 \u2229X = \u2205, R \u2282 An(Y )DX\u0304 . Then F and F \u2032 form a Hedge for P (Y |do(X)) in D.\nNotice that An(Y )DX\u0304 refers to those variables that are ancestors of Y in the causal network D where incoming edges to X have been removed. We may drop the subscript as in An(Y ) in which case we are referring to the ancestors of Y in the unmodified network D (in which case, the network we refer to should be clear from the context). Moreover, we overload the definition of the ancestor function and we use An(Z, V ) to refer to the ancestors of the union of sets Z and V , that is, An(Z, V ) = An(Z \u222a V ).\nThe presence of a hedge prevents the identifiability of causal graphs [2]. Also any non identifiable graph necessarily contains a hedge. These results applied to DCNs lead to the following lemma.\nLemma 8 (DCN complete identification) LetD be a DCN with confounders. Let X and Y be sets of variables in D. P (Y |do(X)) is identifiable iif there is no hedge in D for P (Y |do(X)).\nWe can show that the algorithms presented in the previous section, in some cases introduce hedges in the subnetworks they analyze, even if no hedges existed in the original expanded network.\nLemma 9 The DCN-ID algorithms for DCNs with static confounders (Section 4.1) and dynamic confounders (Section 4.2) are not complete.\nProof Let D be an DCN. Let X be such that D contains two R-rooted C-forests F and F \u2032, F \u2032 \u2286 F , F \u2229 X 6= 0, F \u2032 \u2229X = 0. Let Y be such that R 6\u2282 An(Y )DX\u0304 . The condition for Y implies that D does not contain a hedge, and is therefore identifiable by Lemma 8. Let the set of variables at time slice tx + 1 of D, Vtx+1, be such that R \u2282 An(Vtx+1)DX\u0304 . By Definition 10, D contains a hedge for P (Vtx+1|Vtx\u22121, do(X)). The identification of P (Y |do(X)) requires the DCN-ID algorithm to identifyP (Vtx+1|Vtx\u22121, do(X)) which fails. ut\nFigure 6 shows an identifiable DCN that DCN-ID fails to identify.\nThe proof of Lemma 9 provides the framework to build a complete algorithm for identification of DCNs.\n5.1 Complete DCN identification algorithm with Static Confounders\nThe DCN-ID algorithm can be modified so that no hedges are introduced if none existed in the original network. This is done at the cost of more complicated notation, because the fragments of network to be analyzed do no longer correspond to natural time slices. More delicate surgery is needed.\nLemma 10 Let D be a DCN with static confounders. Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx < ty . If there is a hedge H for P (Y |do(X)) in D then H \u2286 Vtx .\nProof By definition of hedge, F and F \u2032 are connected by confounders to X . As D has only static confounders F , F \u2032 and X must be within tx. ut\nLemma 11 Let D be a DCN with static confounders. Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx < ty .P (Y |do(X)) is identifiable if and only ifP (Vtx+1\u2229An(Y )|Vtx\u22121, do(X)) is identifiable.\nProof (if) By Lemma 8, if\nP (Vtx+1 \u2229An(Y )|Vtx\u22121, do(X))\n= P (Vtx+1 \u2229An(Y ), Vtx\u22121|do(X))\nP (Vtx\u22121)\nis identifiable then there is no hedge for this expression in D. By Lemma 10 if D has static confounders, a hedge must be within time slice tx. If time slice tx does not contain two R-rooted C-forests F and F \u2032 such that F \u2032 \u2286 F , F \u2229X 6= 0, F \u2032 \u2229 X = 0, then there is no hedge for any set Y so there is no hedge for the expression P (Y |do(X)) which makes it identifiable. Now let\u2019s assume time slice tx contains two R-rooted C-forests F and F \u2032 such that F \u2032 \u2286 F , F \u2229X 6= 0, F \u2032 \u2229 X = 0, then R 6\u2282 An(Vtx+1 \u2229 An(Y ), Vtx\u22121)DX\u0304 . As R is in time slice tx, this implies R 6\u2282 An(Y )DX\u0304 and so there is no hedge for the expression P (Y |do(X)) which makes it identifiable.\n(only if) By Lemma 8, if P (Y |do(X)) is identifiable then there is no hedge for P (Y |do(X)) in D. By Lemma 10 if D has static confounders, a hedge must be within time slice tx. If time slice tx does not contain two R-rooted Cforests F and F \u2032 such that F \u2032 \u2286 F , F \u2229X 6= 0, F \u2032\u2229X = 0, then there is no hedge for any set Y so there is no hedge for the expression\nP (Vtx+1 \u2229An(Y )|Vtx\u22121, do(X))\n= P (Vtx+1 \u2229An(Y ), Vtx\u22121|do(X))\nP (Vtx\u22121)\nwhich makes it identifiable. Now let\u2019s assume time slice tx contains two R-rooted C-forests F and F \u2032 such that F \u2032 \u2286 F , F \u2229X 6= 0, F \u2032 \u2229X = 0, then R 6\u2282 An(Y )DX\u0304 (if R \u2282 An(Y )DX\u0304 D would contain a hedge by definition). As R is in time slice tx, R 6\u2282 An(Y )DX\u0304 implies R 6\u2282 An(Vtx+1 \u2229 An(Y ))DX\u0304 and R 6\u2282 An(Vtx+1 \u2229 An(Y ), Vtx\u22121)DX\u0304 so there is no hedge forP (Vtx+1\u2229An(Y )|Vtx\u22121, do(X)) which makes this expression identifiable. ut\nLemma 12 Assume that an expression P (V \u2032t+\u03b1|Vt, do(X)) is identifiable for some \u03b1 > 0 and V \u2032t+\u03b1 \u2286 Vt+\u03b1. Let A be the matrix whose entries Aij correspond to the probabilities P (V \u2032t+\u03b1 = vj |Vt = vi, do(X)). Then P (V \u2032t+\u03b1|do(X)) = AP (Vt|do(X)).\nProof Case by case evaluation of A\u2019s entries. ut\nFunction cDCN-ID(Y ,ty , X ,tx, G,C,T ,P (Vt0)) INPUT:\n\u2013 DCN defined by a causal graph G on a set of variables V and a set C \u2286 V \u00d7 V describing causal relations from Vt to Vt+1 for every t \u2013 transition matrix T representing the probabilities P (Vt+1|Vt) derived from observational data \u2013 a set Y included in Vty \u2013 a set X included in Vtx \u2013 distribution P (Vt0) at the initial state, OUTPUT: The distribution P (Y |do(X)) if it is identifiable, or else FAIL\nLemma 13 Let D be a DCN with static confounders. Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx < ty . Then\nP (Y |do(X)) =\n[ ty\u220f\nt=tx+2 Mt\n] P (Vtx+1 \u2229 An(Y )|do(X))\nwhere Mt is the matrix whose entries correspond to the probabilities P (Vt \u2229An(Y ) = vj |Vt\u22121 \u2229An(Y ) = vi).\nProof For the identification of P (Y |do(X)) we can restrict our attention to the subset of variables in D that are ancestors of Y. Then we repeatedly apply Lemma 7 on this subset from t = tx + 2 to t = ty until we find P (Vty \u2229 An(Y )|do(X)) = P (Y |do(X)). ut\nTheorem 5 Let D be a DCN with static confounders and transition matrix T . Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx < ty . IfP (Y |do(X)) is identifiable thenP (Y |do(X)) =[\nty\u220f t=tx+2 Mt\n] AT tx\u22121\u2212t0P (Vt0) whereA is the matrix whose\nentriesAij correspond to P (Vtx+1\u2229An(Y )|Vtx\u22121, do(X)) and Mt is the matrix whose entries correspond to the probabilities P (Vt \u2229An(Y ) = vj |Vt\u22121 \u2229An(Y ) = vi).\nProof Applying Lemma 3, we obtain that\nP (Vtx\u22121|do(X)) = T tx\u22121\u2212t0P (Vt0).\nBy Lemma 11 P (Vtx+1 \u2229An(Y )|Vtx\u22121, do(X)) is identifiable so Lemma 12 guarantees thatP (Vtx+1\u2229An(Y )|do(X)) = AP (Vtx\u22121|do(X)) = AT tx\u22121\u2212t0P (Vt0). Then we apply\nLemma 13 and obtain the resulting expressionP (Y |do(X)) =[ ty\u220f\nt=tx+2 Mt\n] AT tx\u22121\u2212t0P (Vt0). ut\nThe cDCN-ID algorithm for identification of DCNs with static confounders is given in Figure 7.\nTheorem 6 (Soundness and completeness) The cDCN-ID algorithm for DCNs with static confounders is sound and complete.\nProof The completeness derives from Lemma 11 and the soundness from Theorem 5. ut\n5.2 Complete DCN identification algorithm with Dynamic Confounders\nWe now discuss the complete identification of DCNs with dynamic confounders. First we introduce the concept of dynamic time span from which we derive two lemmas.\nDefinition 11 (Dynamic time span) Let D be a DCN with dynamic confounders and X \u2286 Vtx . Let tm be the maximal time slice d-connected by confounders to X; tm \u2212 tx is called the dynamic time span of X in D.\nNote that the dynamic time span of X in D can be in some cases infinite, the simplest case being when X is connected by a confounder to itself at Vtx+1. In this paper we consider finite dynamic time spans only. We will label the dynamic time span of X as tdx.\nLemma 14 LetD be a DCN with dynamic confounders and X , Y sets of variables in D. Let tdx be the dynamic time span of X in D. If there is a hedge for P (Y |do(X)) in D then the hedge does not include variables at t > tx + tdx.\nProof By definition of hedge, F and F \u2032 are connected by confounders to X . The maximal time point connected by confounders to X is tx + tdx. ut\nFunction cDCN-ID(Y ,ty , X ,tx, G,C,C\u2032,T ,P (Vt0)) INPUT:\n\u2013 DCN defined by a causal graph G on a set of variables V and a set C \u2286 V \u00d7 V describing causal relations from Vt to Vt+1 for every t, and a set C\u2032 \u2286 V \u00d7 V describing confounder relations from Vt to Vt+1 for every t \u2013 transition matrix T for G derived from observational data \u2013 a set Y included in Vty \u2013 a set X included in Vtx \u2013 distribution P (Vt0) at the initial state, OUTPUT: The distribution P (Y |do(X)) if it is identifiable or else FAIL\nLemma 15 LetD be a DCN with dynamic confounders. Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx, ty . Let tdx be the dynamic time span of X in D and tx + tdx < ty . P (Y |do(X)) is identifiable if and only if P (Vtx+tdx+1 \u2229 An(Y )|Vtx\u22121, do(X)) is identifiable.\nProof Similarly to the proof of Lemma 11, but replacing \u201dstatic\u201d by \u201ddynamic\u201d, Vtx+1 by Vtx+tdx+1, Lemma 10 by Lemma 14, and \u201dtime slice tx\u201d by \u201dtime slices tx to tx + tdx\u201d. ut\nTheorem 7 LetD be a DCN with dynamic confounders and T be its transition matrix under no interventions. Let X \u2286 Vtx and Y \u2286 Vty for two time slices tx, ty . Let tdx be the dynamic time span of X in D and tx + tdx < ty . If P (Y |do(X)) is identifiable then:\n1. P (Vtx+tdx+1 \u2229An(Y )|Vtx\u22121, do(X)) is identifiable by matrix A 2. For all t > tx+tdx+1,P (Vt\u2229An(Y )|Vt\u22121\u2229An(Y ), do(X)) is identifiable by matrix Mt\n3. P (Y |do(X)) =\n[ ty\u220f\nt=tx+tdx+2 Mt\n] AT tx\u22121\u2212t0P (Vt0)\nProof We obtain the first statement from Lemma 15 and Lemma 12. Then if t > tx+tdx+1 the set (Vt\u2229An(Y ), Vt\u22121\u2229 An(Y )) has the same ancestors than Y within time slices tx to tx+tdx+1, so if P (Y |do(X)) is identifiable then P (Vt\u2229 An(Y )|Vt\u22121\u2229An(Y ), do(X)) is identifiable, which proves the second statement. Finally we obtain the third statement similarly to the proof of Theorem 3 but using statements 1 and 2 as proved instead of assumed. ut\nThe cDCN-ID algorithm for DCNs with dynamic confounders is given in Figure 8.\nTheorem 8 (Soundness and completeness) The cDCN-ID algorithm for DCNs with dynamic confounders is sound and complete.\nProof The completeness derives from the first and second statements of Theorem 7. The soundness derives from the third statement of Theorem 7. ut"}, {"heading": "6 Transportability in DCN", "text": "[27] introduced the sID algorithm, based on do-calculus, to identify a transport formula between two domains, where the effect in a target domain can be estimated from experimental results in a source domain and some observations on the target domain, thus avoiding the need to perform an experiment on the target domain.\nLet us consider a country with a number of alternative roads linking city pairs in different provinces. Suppose that the alternative roads are all consistent with the same causal model (such as the one in Figure 3, for example) but have different traffic patterns (proportion of cars/trucks, toll prices, traffic light durations...). Traffic authorities in one of the provinces may have experimented with policies and observed the impact on, say, traffic delay. This information may be usable to predict the average travel delay in another province for a given traffic policy. The source domain (province where the impact of traffic policy has already been monitored) and target domain (new province) share the same causal relations among variables, represented by a single DCN (see Figure 9).\nThe target domain may have specific distributions of the toll price and traffic signs, which are accounted for in the model by adding a set of selection variables to the DCN, pointing at variables whose distribution differs among the two domains. If the DCN with the selection variables is identifiable for the traffic delay upon increasing the toll price, then the DCN identification algorithm provides a transport formula which combines experimental probabilities from the source domain and observed distributions from the target domain. Thus the traffic authorities in the new province can\nevaluate the impacts before effectively changing traffic policies. This amounts to relational knowledge transfer learning between the two domains [28].\nConsider a DCN with static confounders only. We have demonstrated already that for identification of the effects of an intervention at time tx we can restrict our attention to four time slices of the DCN, tx \u2212 2, tx \u2212 1, tx, and tx + 1. Let M1 and M2 be two domains based on this same DCN, though the distributions of some variables in M1 and M2 may differ. Then we have\nPM2(Y |do(X)) = T ty\u2212(tx+1) M2 AM2T tx\u22121\u2212t0 M2 P (Vt0),\nwhere the entry ij of matrix AM2 corresponds to the transition probability PM2(Vtx+1 = vi|Vtx\u22121 = vj , do(X)).\nBy applying the identification algorithm sID, with selection variables, to the elements of matrixA we then obtain a transport formula, which combines experimental distributions in M1 with observational distributions in M2. The algorithm for transportability of causal effects with static confounders is given in Figure 10.\nFunction DCN-sID(Y ,ty , X ,tx, G,C,TM2 ,PM2(Vt0),IM1 ) INPUT:\n\u2013 DCN defined by a causal graph G (common to both source and target domains M1 and M2) over a set of variables V and a set C \u2286 V \u00d7 V describing causal relations from Vt to Vt+1 for every t \u2013 transition matrix TM2 for G derived from observational data in M2 \u2013 a set Y included in Vty \u2013 a set X included in Vtx \u2013 distribution PM2(Vt0) at the initial state in M2 \u2013 set of interventional distributions IM1 in M1 \u2013 set S of selection variables\nOUTPUT: The distribution PM2(Y |do(X)) in M2 in terms of TM2 , PM2(Vt0) and IM1 , or else FAIL\n1. let G\u2032 be the acyclic graph formed by joining Gtx\u22122, Gtx\u22121, Gtx , and Gtx+1 by the causal relations given by C; 2. run the standard sID algorithm for expression P (Vtx+1|Vtx\u22121, do(X)) on G\u2032; if it returns FAIL, return FAIL; 3. else, use the resulting transport formula to compute the transition matrix A, where Aij = P (Vtx+1 = vi|Vtx\u22121 = vj , do(X));\n4. return \u2211\nVty\\Y T ty\u2212(tx+1) AT tx\u22121\u2212t0 P (Vt0);\nFig. 10 The DCN-sID algorithm for the transportability in DCNs with static confounders\nFor brevity we omit the algorithm extension to dynamic confounders, and the completeness results, which follow the same confounder caveats already explained in the previous sections."}, {"heading": "7 Experiments", "text": "In this section we provide some numerical examples of causal effect identifiability in DCN, using the algorithms proposed in this paper.\nIn our first example, the DCN in Figure 3 represents how the traffic between two cities evolves. There are two roads and drivers choose every day to use one or the other road. Traffic conditions on either road on a given day (tr1, tr2) affect the travel delay between the cities on that same day (d). Driver experience influences the road choice next day, impacting tr1 and tr2. For simplicity we assume variables tr1, tr2 and d to be binary. Let\u2019s assume that from Monday to Friday the joint distribution of the variables follow transition matrix T1 while on Saturday and Sunday they follow transition matrix T2. These transition matrices indicate the traffic distribution change from the previous day to the current day. This system is a DCN with static confounders, and has a markov chain representation as in Figure 3.\nT1 =  0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3\n0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3\n0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3\n\nT2 =  0.1 0.0 0.3 0.1 0.2 0.2 0.0 0.1 0.1 0.0 0.3 0.1 0.2 0.2 0.0 0.1 0.1 0.0 0.3 0.1 0.2 0.2 0.0 0.1 0.1 0.0 0.3 0.1 0.2 0.2 0.0 0.1 0.0 0.2 0.1 0.0 0.1 0.3 0.3 0.0 0.0 0.2 0.1 0.0 0.1 0.3 0.3 0.0\n0.0 0.2 0.1 0.0 0.1 0.3 0.3 0.0\n0.0 0.2 0.1 0.0 0.1 0.3 0.3 0.0  The average travel delay d during a two week period is\nshown in Figure 11.\nNow let\u2019s perform an intervention by altering the traffic on the first road tr1 and evaluate the subsequent evolution of the average travel delay d. We use the algorithm for DCNs with static confounders. We trigger line 1 of the DCN-ID algorithm in Figure 7 and build a graph consisting of four time slices G\u2032 = (Gtx\u22122, Gtx\u22121, Gtx , Gtx+1) as shown in Figure 12.\nThe ancestors of any future delay at t = ty are all the variables in the DCN up to ty , so in line 2 we run the standard ID algorithm for\u03b1 = P (v10, v11, v12|v4, v5, v6, do(v7)) on G\u2032, which returns the expression \u03b1:\n\u2211 v1,v2,v3,v8,v9\nP (v1, v2, ...v12) \u2211 v7,v9\nP (v7, v8, v9|v4, v5, v6) P (v4, v5, v6) \u2211 v9 P (v7, v8, v9|v4, v5, v6)\nUsing this expression, line 3 of the algorithm computes the elements of matrix A. If we perform the intervention on a Thursday the matrices A for v7 = 0 and v7 = 1 can be evaluated from T1.\nAv7=0 =  0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1 0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1\n0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1\n0.0 0.4 0.0 0.3 0.0 0.2 0.0 0.1\n\nAv7=1 =  0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3 0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3\n0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3\n0.2 0.0 0.0 0.1 0.4 0.0 0.0 0.3  In line 4 we find that transition matricesMt are the same than for the DCN without intervention. Figure 13 shows the average travel delay without intervention, and with intervention on the traffic conditions of the first road.\nIn a second numerical example, we consider that the system is characterized by a unique transition matrix T and the delay d tends to a steady state. We measure d without intervention and with intervention on tr1 at t = 15. The system\u2019s transition matrix T is shown below:\nT =  0.02 0 0.03 0 0.26 0.13 0.34 0.22 0.02 0 0.03 0 0.26 0.13 0.34 0.22 0.02 0 0.03 0 0.26 0.13 0.34 0.22 0.02 0 0.03 0 0.26 0.13 0.34 0.22 0.34 0.1 0.24 0.21 0 0.02 0.09 0 0.34 0.1 0.24 0.21 0 0.02 0.09 0\n0.34 0.1 0.24 0.21 0 0.02 0.09 0\n0.34 0.1 0.24 0.21 0 0.02 0.09 0  Figure 14 shows the evolution of d with no intervention\nand with intervention.\nAs shown in the examples, the DCN-ID algorithm calls ID only once with a graph of size 4|G| and evaluates the elements of matrix A with complexity O((4k)(b+2), where k = 3 is the number of variables per slice and b = 1 is the number of bits used to encode the variables. The rest is the computation of transition matrix multiplications, which can be done with complexity O(n.b2), with n = 40\u2212 15 in example 2. To obtain the same result with the ID algorithm by brute force, we would require processing n times the identifiability of a graph of size 40|G|, with overall complexity O((k)(b+2) + (2k)(b+2) + (3k)(b+2) + ...+ (n.k)(b+2))."}, {"heading": "8 Conclusions and Future Work", "text": "This paper introduces dynamic causal networks and their analysis with do-calculus, so far studied thoroughly only in\nstatic causal graphs. We extend the ID algorithm to the identification of DCNs, and remark the difference between static vs. dynamic confounders. We also provide an algorithm for the transportability of causal effects from one domain to another with the same dynamic causal structure.\nFor future work, note that in the present paper we have assumed all intervened variables to be in the same time slice; removing this restriction may have some moderate interest. We also want to extend the introduction of causal analysis to a number of dynamic settings, including Hidden Markov Models, and study properties of DCNs in terms of Markov chains (conditions for ergodicity, for example). Finally, evaluating the distribution returned by ID is in general unfeasible (exponential in the number of variables and domain size); identifying tractable sub-cases or feasible heuristics is a general question in the area.\nAcknowledgements Research was partially funded by SGR2014-890 (MACDA) project of the Generalitat de Catalunya and MINECO project APCOM (TIN2014-57226- P)."}], "references": [{"title": "in Proceedings of the National Conference on Artificial Intelligence, vol", "author": ["I. Shpitser", "J. Pearl"], "venue": "21 (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press;", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1999}, {"title": "in Proceedings of the National Conference on Artificial Intelligence, vol", "author": ["Y. Huang", "M. Valtorta"], "venue": "21 (Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press;", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1999}, {"title": "Simon, in Readings in qualitative reasoning about physical systems", "author": ["H.A.Y. Iwasaki"], "venue": "(Morgan Kaufmann Publishers Inc.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1989}, {"title": "Information-based methods for neuroimaging: analyzing structure, function and dynamics", "author": ["D. Chicharro", "S. Panzeri"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Symbolic and Quantitative Approaches to Reasoning with Uncertainty (Springer", "author": ["D. Dash", "M. Druzdzel"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2001}, {"title": "Causality: statistical perspectives and applications", "author": ["M. Eichler"], "venue": "Wiley, Chichester pp", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Studies in causal reasoning and learning", "author": ["J. Tian"], "venue": "Ph.D. thesis,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2002}, {"title": "Knowledge and Data Engineering", "author": ["S.J. Pan", "Q. Yang"], "venue": "IEEE Transactions on 22(10),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2010}, {"title": "Causality: models, reasoning and inference, vol", "author": ["J. Pearl"], "venue": "29 (Cambridge Univ Press,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2000}, {"title": "On the identification of causal effects", "author": ["J. Tian", "J. Pearl"], "venue": "Tech. rep., Department of Computer Science,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2002}, {"title": "T", "author": ["J. Pearl"], "venue": "Verma, et al., A theory of inferred causation (Morgan Kaufmann San Mateo, CA,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1991}], "referenceMentions": [{"referenceID": 0, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[2,3] showed that a do-expression is identifiable if and only if it can be rewritten in this way with a finite number of applications of the three rules of docalculus, and [2] proposed the ID algorithm which performs this transformation if at all possible, or else returns fail indicating non-identifiability.", "startOffset": 172, "endOffset": 175}, {"referenceID": 2, "context": "Regarding the discovery of causal models in dynamic systems [4] and [5] propose an algorithm to establish an ordering of the variables corresponding to the temporal order of propagation of causal effects.", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "Existing algorithms for causal discovery from static data have been extended to the dynamic setting by [8] and [9].", "startOffset": 111, "endOffset": 114}, {"referenceID": 4, "context": "However [13] [14] [15] show the caveats of causal discovery of dynamic models based on differential equations which pass through equilibrium states, and how causal reasoning based on such models may fail.", "startOffset": 13, "endOffset": 17}, {"referenceID": 5, "context": "Regarding causal reasoning given a dynamic causal model, one line of research is based on time series and granger causality concepts [19,20,21].", "startOffset": 133, "endOffset": 143}, {"referenceID": 5, "context": "[19,20,21] discuss back-door and front-door criteria in timeseries but do not extend to the full power of do-calculus as a complete logic for causal identification.", "startOffset": 0, "endOffset": 10}, {"referenceID": 6, "context": "\u2013 We extend causal identification algorithms [25,2,26] to the identifiability of causal effects in DCN settings.", "startOffset": 45, "endOffset": 54}, {"referenceID": 0, "context": "\u2013 We extend causal identification algorithms [25,2,26] to the identifiability of causal effects in DCN settings.", "startOffset": 45, "endOffset": 54}, {"referenceID": 7, "context": "This opens the way to studying relational knowledge transfer learning [28] of causal information in domains with a time component.", "startOffset": 70, "endOffset": 74}, {"referenceID": 8, "context": "The notation used in our paper is based on causal models and do-calculus [1,29].", "startOffset": 73, "endOffset": 79}, {"referenceID": 0, "context": "Do-calculus was proven to be complete [2,3] in the sense that if an expression cannot be converted into a do-free one by iterative application of the three do-calculus rules, then it is not identifiable.", "startOffset": 38, "endOffset": 43}, {"referenceID": 1, "context": "Do-calculus was proven to be complete [2,3] in the sense that if an expression cannot be converted into a do-free one by iterative application of the three do-calculus rules, then it is not identifiable.", "startOffset": 38, "endOffset": 43}, {"referenceID": 0, "context": "The ID algorithm [2], and earlier versions by [30,31] implement an iterative application of do-calculus rules to transform a causal expressionP (Y |do(X)) into an equivalent expression without any do() terms in semi-Markovian causal", "startOffset": 17, "endOffset": 20}, {"referenceID": 9, "context": "The ID algorithm [2], and earlier versions by [30,31] implement an iterative application of do-calculus rules to transform a causal expressionP (Y |do(X)) into an equivalent expression without any do() terms in semi-Markovian causal", "startOffset": 46, "endOffset": 53}, {"referenceID": 0, "context": "The ID algorithm is sound and complete [2] in the sense that if a do-free equivalent expression exists it will be found by the algorithm, and if it does not exist the algorithm will exit and provide an error.", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "The expressionP (Y |Z, do(X)) is thus identifiable if and only if both P (Y,Z|do(X)) and P (Z|do(X)) are [2].", "startOffset": 105, "endOffset": 108}, {"referenceID": 10, "context": "To represent unobserved confounders in DCN, we extend to the dynamic context the framework developed in [33] on causal model equivalence and latent structure projections.", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "Proof The first equality derives from rule 3 and the proof in [2] that interventions on variables which are not ancestors of Y in D have no effect on Y .", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "Proof (sketch) By C-component factorization [25], we decompose the problem as that of identification of each Ccomponent in D and (if all C-components are identifiable) multiplying all identified quantities to obtain P (Y |do(X)).", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "An identifiable C-component is computed as the product of P (vi|V i\u22121 \u03c0 ) for each variable vi in the C-component, where V i\u22121 \u03c0 is the set of all variables preceding vi in some topological ordering \u03c0 [2,25].", "startOffset": 201, "endOffset": 207}, {"referenceID": 6, "context": "An identifiable C-component is computed as the product of P (vi|V i\u22121 \u03c0 ) for each variable vi in the C-component, where V i\u22121 \u03c0 is the set of all variables preceding vi in some topological ordering \u03c0 [2,25].", "startOffset": 201, "endOffset": 207}, {"referenceID": 0, "context": "Its soundness is immediate from Theorem 1, the soundness of the ID algorithm [2], and Lemma 2.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "Its soundness is immediate from Theorem 3, the soundness of the ID algorithm [2], and Lemma 2.", "startOffset": 77, "endOffset": 80}, {"referenceID": 0, "context": "To prove completeness we use previous results [2].", "startOffset": 46, "endOffset": 49}, {"referenceID": 0, "context": "The presence of a hedge prevents the identifiability of causal graphs [2].", "startOffset": 70, "endOffset": 73}, {"referenceID": 7, "context": "This amounts to relational knowledge transfer learning between the two domains [28].", "startOffset": 79, "endOffset": 83}], "year": 2016, "abstractText": "In this paper we propose a causal analog to the purely observational Dynamic Bayesian Networks, which we call Dynamic Causal Networks. We provide a sound and complete algorithm for identification of Dynamic Causal Networks, namely, for computing the effect of an intervention or experiment, based on passive observations only, whenever possible. We note the existence of two types of confounder variables that affect in substantially different ways the identification procedures, a distinction with no analog in either Dynamic Bayesian Networks or standard causal graphs. We further propose a procedure for the transportability of causal effects in Dynamic Causal Network settings, where the result of causal experiments in a source domain may be used for the identification of causal effects in a target domain.", "creator": "LaTeX with hyperref package"}}}