{"id": "1610.06490", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2016", "title": "An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data Stream Fuzzy Clustering", "abstract": "a new approach to data packet stream clustering with the help of an ensemble of adaptive neuro - fuzzy systems is proposed. the larger proposed ensemble is successfully formed with simplest adaptive neuro - fuzzy self - organizing kohonen maps in a parallel processing mode. a final outcome result is typically chosen by the best neuro - fuzzy self - organizing kohonen map.", "histories": [["v1", "Thu, 20 Oct 2016 16:30:25 GMT  (238kb)", "http://arxiv.org/abs/1610.06490v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["zhengbing hu", "yevgeniy v bodyanskiy", "oleksii k tyshchenko", "olena o boiko"], "accepted": false, "id": "1610.06490"}, "pdf": {"name": "1610.06490.pdf", "metadata": {"source": "CRF", "title": "An Ensemble of Adaptive Neuro-Fuzzy Kohonen Networks for Online Data Stream Fuzzy Clustering", "authors": ["Zhengbing Hu", "Yevgeniy V. Bodyanskiy", "Olena O. Boiko"], "emails": ["hzb@mail.ccnu.edu.cn", "yevgeniy.bodyanskiy@nure.ua", "lehatish@gmail.com,", "olena.boiko@ukr.net"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nMultidimensional data clustering is common in Data Mining tasks. Such application areas as Text Mining and Web Mining have become really widespread lately. A traditional approach to solving this sort of tasks assumes that each vector of a processed sequence may only belong to a single class. Although it\u2019s a more natural case when each specific observation may be attributed to several classes at the same time with different membership levels.\nThis situation is a subject under study for fuzzy cluster analysis [1, 2]. In this approach, the most effective and simplest methods are probabilistic fuzzy clustering procedures based on optimization of some objective functions. Initial data for a fuzzy clustering problem is a sample of observations which consists of N  1m  dimensional feature vectors         1 , 2 , , , nX x x x k x N R   , and a result of this clustering procedure is a partition of the initial data set into m overlapping classes with some membership levels  0 1ju k  of the k  th feature vector to the j  th cluster, 1, 2, ,j m  . Thus, the overwhelming majority of the well-known fuzzy clustering algorithms is designated for a batch mode processing which means that a sample volume N can\u2019t be changed while the data are processed.\nThere\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode. This task is rather typical for Web Mining when information is fed in a real time mode directly from the Internet.\nSelf-organizing maps (SOMs) by Kohonen proved its efficiency in clustering tasks. Their efficiency is defined by their computational simplicity and their ability to work in a real time mode for sequential data processing. These neural networks are learnt with the help of self-learning procedures based on the principles \u201cWinner takes all\u201d (WTA) and \u201cWinner takes more\u201d (WTM). It\u2019s previously assumed that a structure of processed data implies that formed clusters don\u2019t mutually intersect which means that it\u2019s possible to build a separating hyper-surface which clearly distinguish different classes during a learning procedure of a neural network.\nRecurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18]. It should be noted that the introduced procedures are structurally close to the Kohonen self-learning rule according to the principle \u00abWinner Takes More\u00bb. It allows\nintroducing a so-called \u00abfuzzy clustering Kohonen network\u00bb [19] which possesses a number of advantages comparing to a conventional self-organizing map.\nThe well-known and most commonly used fuzzy clustering algorithms can\u2019t be called fuzzy in the full sense, because their results are significantly defined by a value of a special parameter (also known as a fuzzifier  which is chosen empirically). A case when  belongs to an interval from 1 to  corresponds to a transition from crisp borders  1  , which are obtained with the help of the K-means procedure, to their complete blurriness     , when all observations belong to all clusters with the same membership level. We should note that 2  in most cases that corresponds to the fuzzy C-means procedure (FCM) by Bezdek [20].\nThere may be a situation while processing real-world data when one object belongs to different classes at the same time and these classes mutually intersect (overlap). Conventional SOMs don\u2019t take into consideration this occasion, but this problem can be considered with the help of fuzzy clustering techniques.\nThe remainder of this paper is organized as follows: Section 2 describes fuzzy clustering techniques with a variable fuzzifier. Section 3 describes an ensemble\u2019s architecture of adaptive neuro-fuzzy Kohonen networks. Section 4 gives some details on possibilistic fuzzy clustering with a variable fuzzifier. Section 5 presents a realworld application to be solved with the help of the proposed fuzzy clustering approach. Conclusions and future work are given in the final section.\nII. FUZZY CLUSTERING WITH A VARIABLE FUZZIFIER Algorithms based on goal functions are considered to be strict from a mathematical point of view among all clustering procedures. They solve a task of their optimization under different a priori assumptions. The most commonly used procedure in this situation is the probabilistic approach which is based on a goal function\u2019s minimization\n    2 1 1\n, ( ) N m\nj j j j k j E u c u k x k c     (1)\nunder constraints\n1\n( ) 1, m\nj j u k   (2)\n  1\n0 N\nj k u k N    (3)\nwhere   [0,1 ]ju k  is a membership level of a vector ( )x k to the j -th class, jc is a prototype of the j -th cluster,  is a non-negative fuzzification parameter (a fuzzifier) which actually determines a level of borders\u2019 blurriness\nbetween clusters, 1, 2, , k N  . A result of this clustering procedure is a  N m -matrix  ( )jU u k which is also called a fuzzy partition matrix.\nWe should notice that elements of the matrix U due to the constraint (2) may be considered as probabilities that data vectors belong to some definite clusters. Because of this fact, procedures based on the minimization (1) are called probabilistic fuzzy clustering algorithms. A number of clusters m is set beforehand and can\u2019t be changed during computation procedures.\nIntroducing the Lagrange function\n      \n   \n2\n1 1\n1 1\n, , ( )\n1\nN m\nj j j j k j\nN m\nj k j\nL u k c k u k x k c\nk u k\n\n\n \n \n  \n     \n \n\n  (4)\n(here ( )k is an undetermined Lagrange multiplier) and solving the Karush-Kuhn-Tucker system of equations, we can get a solution in the form\n    \n      \n   \n1 2 1\n1 2 1\n1\n1\n1 11\n12\n1\n,\n( )\n,\n,\nj\nj m\nll\nN jk\nj N jk\nm\nl l\nx k c u k\nx k c\nu k x k c\nu k\nk x k c\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n \n\n\n                                \n(5)\nwhich coincides with the Fuzzy C-Means algorithm (FCM) by J.Bezdek (when 2  ). And when 1  its results are close to results of the well-known conventional crisp clustering algorithm (Hard K-Means, HKM).\nAs an alternative to procedures that use a fuzzifier 1    , Klawonn and Hoeppner [21] offered an objective function for fuzzy probabilistic clustering\n      22 1 1\n, ( ) (1 ) ( ) N m\nj j j j j k j E u c u k u k x k c        (6) with the constraints (2) and (3), where 0 1  is an adjustable parameter which defines a nature of the obtained solution.\nIntroducing the Lagrange function\n            2 1 1 1 2 1 ( ) (1 ) ( ), , 1\nN m N m\nj j j j k l j k j jL u k c k x k c k uu k u k k      \n   \n         \nand solving the Karush-Kuhn-Tucker system of equations\n    \n        \n                   \n   \n2\n2\n1\n1\n, , 2 1 0,\n, , 2 1 0,\n, , 1 0,\nj\nj j j j\nj\nN\nc j j j j j k\nm j j\nj j\nL u k c k u k x k c k\nu k\nL u k c k u k u k x k c\nL u k c k u k\nk\n   \n  \n\n\n\n\n                          \nwe come to a solution\n     \n     \n2\n21\n2 1\n2 1\n111 2 , 2\n(1 ) ( ) ( ) .\n(1 ) ( )\nj\nm j\nl l\nN j jk\nj N j jk\nm u k\nx k c\nx k c\nu k u k x k c\nu k u k\n   \n \n \n\n\n\n \n   \n\n  \n               \n(7)\nIt\u2019s easy to notice that when 1  this procedure coincides with FCM. Thus, the procedure (7) can\u2019t be used for\nsolving Data Stream Mining tasks, because it can\u2019t process information in an online mode. Therefore, an adaptive modification of the expression (7) was introduced in [22]\n     \n             \n2\n21\n2\n111 21 , 2 1 ( )\n1 ( )\n1 ( ) 1 1 1 1 ( )\nj\nm j\nl l\nj j j j j\nm u k\nx k c k\nx k c k\nc k c k k u k u k x k c k\n   \n  \n\n \n     \n \n     \n    \n   \n \n\n (8)\nwhere ( )k is a learning rate parameter. It\u2019s easy to notice that the second recurrent expression (8) is the Kohonen self-learning rule according to the principle \u00abWinner Takes More\u00bb with a neighborhood function      2 1 1 1j ju k u k     .\nIII. AN ENSEMBLE OF ADAPTIVE NEURO-FUZZY KOHONEN NETWORKS Although a value of the parameter  in the formulas (7) and (8) lies in a much narrower range than a fuzzifier\n , but there are currently no formal rules how to choose it and to tune it. Therefore, while solving a concrete task in a batch mode, this task is usually repeatedly solved with the help of the expression (7) with different  values (from a very small quantity to 1). It\u2019s clear that such an approach can\u2019t solve tasks effectively in an online mode. It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others  value. This ensemble can be easily implemented with the help of adaptive neuro-fuzzy Kohonen networks [25]. They are two-layer architectures where prototypes are clarified in the Kohonen competitive layer (which contains m neurons KjN ) and membership levels\nare calculated in the output layer (which contains m neurons MjN ). There is an architecture of the two-layer adaptive neuro-fuzzy Kohonen network in Fig.1. There is also an ensemble formed by such networks in Fig.2. A self-learning algorithm for the p  th ensemble\u2019s member  1,2, ,p q  in an ensemble that contains q\nneuro-fuzzy networks can be written down in the form\nFig.1. An adaptive neuro-fuzzy Kohonen network (FSOM)\nFig.2. An architecture of an ensemble of adaptive neuro-fuzzy Kohonen networks\n             \n     \n2\n2\n21\n1 ( ) 1 1 ( ) ,\n1 1\n1 2 1\n2 1 ( )\n1 ( )\njp jp p jp p jp jp\np\np p jp\np m jp\nl lp\nc k c k k u k u k x k c k\nm u k\nx k c k\nx k c k\n  \n   \n\n      \n \n    \n \n\n    \n \n\n   \n\n(9)\nwherein the Kohonen layer is tuned with the help of the first ratio (9), and the output layer calculates membership levels  1jpu k  for each incoming observation  1x k  .\nClassification quality provided by each ensemble member may be estimated with the help of any fuzzy clustering index [2]. Wherein one of the simplest and most effective indexes is the so-called \u201cpartition coefficient\u201d (PC) which is a mean value of squared membership levels of all observations to each cluster:\n    1 2\n1 1\n11 . 1\nk m\np jp j PC k u k \n \n \n    (10)\nThis coefficient has a clear physical sense: the better clusters are expressed, the higher the value pPC is (a limit\nis 1pPC  ), its minimum ( 1 pPC m  ) is reached if data belong to all clusters evenly. But this phenomenon is\nobviously a worthless solution. This coefficient is convenient in the framework of the proposed system, because it allows online calculation.\nIt should be noticed that the expression (10) is closely related to the traditional FCM. This coefficient must be modified for a considered case in the form\n         1 2\n1 1\n11 1 1\nk m\np p jp p jp j PC k u u k \n    \n \n     \nwhich coincides with the expression (10) when 1p  .\nSo, clustering a data stream that is fed in an online mode is solved with the help of parallel working adaptive neuro-fuzzy Kohonen networks which differ from each other only by a value of the parameter p . Thus, the\nnetwork\u2019s results are applied to a maximum value  1pPC k  as a final result at any particular time point.\nIV. POSSIBILISTIC FUZZY CLUSTERING WITH A VARIABLE FUZZIFIER Basic problems that arise in fuzzy clustering have to do with constraints on a sum of membership values (they must be equal to 1). That\u2019s why algorithms that use the constraint (2) are called probabilistic fuzzy clustering algorithms. An existence of this constraint leads to the fact that an observation which doesn\u2019t belong to any class gets the same membership levels for all classes. One can avoid this drawback if the ideas of possibilistic fuzzy clustering are used [26]. These ideas are based on minimization of an objective function\n      2 1 1 1 1\n( ), 1 N m m N\nj j j j j k l k j j\nE u c x ku c u kk \n           where a scalar parameter 0j  defines a distance where a membership level takes on a value of 0.5 which means that if\n  2j jx k c   then\n  0.5.ju k  Introducing an objective function [22, 25] similarly to (6)\n         1\n2 2\n1 1\n2\n1 1, ( ) (1 ) ( ) ( )\nN m\nj j j j\nm N\njj j k j j k E u c u k u k x k c u k          \nand minimizing it by , ,j j ju c  , we come to a modified possibilistic procedure in the form\n      \n  \n               \n               \n1\n1\n2\n2\n2\n2\n22 1\n2 1\n1 ,\n2\n1\n1 ,\n1 .\n1\nN\nk j N\nk\nj j j\nj\nj j\nj j\nj j\nN j j jk\nj N j jk\nx k c u k\nx k c\nu k u k\nu k u k\nu k u k x k c\nu k u\nx k c\nk\n\n\n\n\n  \n \n\n\n \n \n\n\n\n    \n \n \n \n\n     \n \n \n         \n   \n \n(11)\nIt\u2019s interesting to note that this ratio for a prototype calculation in the formulas (7) and (11) completely\ncoincides. The expressions (11) can be written down for an adaptive case in the form\n            \n      \n                 \n                     \n2\n2\n2\n121 12 2 1 1\n1 1 1 ,\n2 1\n1 1 1 1 1\n1 1 1 1\n,\n.\nj j j\nj\nj j\nj j jj j\nk k j j j j j jp p\nk x k c k k u k\nx k c k k\nk k k u k u k x k c k\nk u p u p x p c k u p u p\nc c\n  \n \n \n  \n\n     \n      \n  \n       \n                           \n(12)\nAs one can see, the second recurrent ratio (12) is the WTM self-learning rule by Kohonen with the neighborhood function      2 1 1 1j ju k u k     . Although the possibilistic algorithm (12) is a little more complicated from a computational point of view than the probabilistic procedure (8), its advantage is the fact that new clusters may be detected with the help of the possibilistic approach during online data processing. If a membership level of a new incoming observation  1x k  to all classes turns out to be lower than some predefined threshold then we can assume that there\u2019s a new  1m   th cluster and its initial prototype coordinates are\n   1 0 1 .mc x k  \nThe algorithm (12) can be used as a learning procedure for the two-layer FSOM (Fig.1). Let\u2019s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams. Simplicity of the ensemble\u2019s (Fig.2) numerical implementation makes it possible to process data in a real time mode.\nV. EXPERIMENTS We have taken real-world data for our experiment. A data set describes students\u2019 knowledge status about the subject of Computer Science. The data set contains multivariate characteristics. It contains 302 instances with 5 attributes for each observation. Speaking of attribute information, the data set contains these attributes: - STG (a degree of study time for goal object materials); - SCG (a degree of a user\u2019s repetition number for goal object materials); - STR (a degree of user\u2019s study time for related objects with a goal object); - LPR (a user\u2019s exam performance for related objects with a goal object); - PEG (a user\u2019s exam performance for goal objects).\nWe chose 3 attributes (STR, LPR, PEG) for the sake of visualization.\nFig.3. The Result of Fuzzy Clustering (STR/PEG)\nFig.4. The Result of Fuzzy Clustering (PEG/ STR/LPR)\nAs it can be seen, the proposed method makes it possible to represent clusters in a rather compact form. A level of cluster overlapping is rather high (and it will keep on growing when a feature vector\u2019s dimensionality increases). An a parameter for the considered case belonged to an interval [0.3; 0.4].\nFig.5. The Result of Fuzzy Clustering (SCG/PEG)\nAs it can be seen from Fig.3, there are 3 fuzzy clusters. Generally speaking, students\u2019 current knowledge level should be determined with the help of real values (STG, SCG, PEG, STR, LPR).\nIt should be noted that there are some points in Fig.3 which are not likely to be in those regions. For example, a point belongs to a \u201cgreen\u201d class although all neighbor points in that region belong to some other (\u201cpink\u201d or \u201cyellow\u201d) class. Probably, this fact means that a student didn\u2019t actually spend much time on his exam preparation although he demonstrated a high level of performance (his PEG index is high). There may be another situation when a student spent much time on his preparation but his results aren\u2019t very good.\nSo, the clustering accuracy increases for fuzzy algorithms and worsens for crisp ones with the growth of a sample size; the clustering accuracy lessens with the growth of dimensionality of a feature space. Fuzzy procedures are preferable for those clustering tasks when every object belongs to several categories at the same time.\nVI. CONCLUSION The method for online fuzzy clustering multidimensional data sequences to be processed in a real time mode is proposed. The task is solved with the help of an ensemble of adaptive neuro-fuzzy Kohonen networks which differ from each other by a parameter\u2019s value that accounts for fuzziness of the received results. The proposed procedure has rather simple computational implementation and makes it possible to organize parallel computing to accelerate the system\u2019s processing speed (because it can process data in an online mode and this fact is really important for Web Mining and Data Stream Mining). The results may be successfully used in a wide class of Data Stream Mining, Dynamic Data Mining, Temporal Data Mining tasks and especially in such applied areas as Web Mining, Text Mining, Medical Data Mining etc.\nSo, the proposed ensemble of adaptive neuro-fuzzy self-organizing Kohonen maps has proved its efficiency for online Data Stream fuzzy clustering. A number of experiments demonstrated a high effectiveness of the proposed neuro-fuzzy system especially under conditions of clusters\u2019 overlapping.\nACKNOWLEDGMENT\nThe authors would like to thank anonymous reviewers for their careful reading of this paper and for their helpful comments.\nThis scientific work was supported by RAMECS and CCNU16A02015.\nREFERENCES [1] F. Hoeppner, F. Klawonn, R. Kruse, and T. Runkler, Fuzzy Clustering Analysis: Methods for Classification, Data Analysis\nand Image Recognition, Chichester: John Wiley & Sons, 1999. [2] R. Xu and D.C. Wunsch, Clustering (IEEE Press Series on Computational Intelligence), Hoboken: John Wiley & Sons,\n2009. [3] H. Bouchachia and E. Balaguer-Ballester, \u201cDELA: A Dynamic Online Ensemble Learning Algorithm\u201d, in Proc. 22nd\nEuropean Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN 2014), Apr. 2014, pp. 491-496. [4] D. Leite, P. Costa Jr., and F. Gomide, \u201cEvolving granular neural networks from fuzzy data streams\u201d, Neural Networks, vol. 38, 2013, pp. 1-16. [5] D. Leite, R. Ballini, Pyramo Costa Jr., and F. Gomide, \u201cEvolving fuzzy granular modeling from nonstationary fuzzy data streams\u201d, Evolving Systems, vol.3(2), 2012, pp. 65-79. [6] D. Leite, R. Ballini, Pyramo Costa Jr., and F. Gomide, \u201cEvolving fuzzy granular modeling from nonstationary fuzzy data streams\u201d, Evolving Systems, vol.3(2), 2012, pp. 65-79. [7] D. Kangin and P. Angelov, \u201cEvolving clustering, classification and regression with TEDA\u201d, in Proc. International Joint Conference on Neural Networks (IJCNN 2015), July 2015, pp. 1-8. [8] R. Hyde and P. Angelov, \u201cA new online clustering approach for data in arbitrary shaped clusters\u201d, in Proc. International Conference on Cybernetics (CYBCONF 2015), June 2015, pp. 228-233. [9] R.D. Baruah, P.P. Angelov, and D. Baruah, \u201cDynamically evolving clustering for data streams\u201d, in Proc. Evolving and Adaptive Intelligent Systems (EAIS 2014), June 2014, pp. 1-6. [10] R. Rosa, F.A.C. Gomide, D. Dovzan, I. Skrjanc, \u201cEvolving neural network with extreme learning for system modeling\u201d, in Proc. Evolving and Adaptive Intelligent Systems (EAIS 2014), June 2014, pp. 1-7. [11] D. Dovzan and I. Skrjanc, \u201cRecursive clustering based on a Gustafson-Kessel algorithm\u201d, Evolving Systems, vol. 2(1), 2011, pp. 15-24. [12] R.D. Baruah, P.P. Angelov, and D. Baruah, \u201cDynamically evolving fuzzy classifier for real-time classification of data streams\u201d, in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE 2014), July 2014, pp. 383-389. [13] R.D. Baruah and P.P. Angelov, \u201cOnline learning and prediction of data streams using dynamically evolving fuzzy approach\u201d, in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE 2013), July 2013, pp. 1-8. [14] A.P. Lemos, W.M. Caminhas, and F.A.C. Gomide, \u201cMultivariable Gaussian Evolving Fuzzy Modeling System\u201d, IEEE Trans. Fuzzy Systems, vol.19(1), 2011, pp. 91-104. [15] R.D. Baruah and P.P. Angelov, \u201cEvolving fuzzy systems for data streams: a survey\u201d, Data Mining and Knowledge Discovery, vol.1(6), 2011, pp. 461-476. [16] M. Pratama, S.G. Anavatti, M.J. Er, and E. Lughofer, \u201cpClass: An Effective Classifier for Streaming Examples\u201d, IEEE Trans. Fuzzy Systems, vol.23(2), 2015, pp. 369-386. [17] Ye. Bodyanskiy, V. Kolodyaznhiy, and A. Stephan, \u201cRecursive fuzzy clustering algorithms\u201d, in Proc. 10th East West Fuzzy Colloqium, Sept. 2002, pp. 276-283.\n[18] Ye. Bodyanskiy, \u201cComputational intelligence techniques for data analysis\u201d, Lecture Notes in Informatics, vol. P-72, 2005, pp. 15-36. [19] Ye. Gorshkov, V. Kolodyazhniy, and Ye. Bodyanskiy, \u201cNew recursive learning algorithms for fuzzy Kohonen clustering network\u201d, in Proc. 17th Int. Workshop on Nonlinear Dynamics of Electronic Systems, June 2009, pp. 58-61. [20] J.C. Bezdek, Pattern Recognition with Fuzzy Objective Function Algorithms, N.Y.: Plenum Press, 1981. [21] F. Klawonn and F. Hoeppner, \u201cWhat is fuzzy about fuzzy clustering? Understanding and improving the concept of the\nfuzzifier\u201d, Lecture Notes in Computer Science, vol. 2811, 2003, pp. 254-264. [22] B. Kolchygin and Ye. Bodyanskiy, \u201cAdaptive fuzzy clustering with a variable fuzzifier\u201d, Cybernetics and System Analysis,\nvol. 49, no. 3, 2013, pp.176-181. [23] A. Topchy, B. Minaei-Bidgali, A.K. Jain, and W.F. Punch, \u201cAdaptive clustering ensembles\u201d, in Proc.17th Int. Conf. on\nPattern Recognition \u201cICPR 2004\u201d, Aug. 2004, pp. 272 \u2013 275. [24] S. Vega-Pons and J. Ruiz-Shulcloper, \u201cA survey of clustering ensemble algorithms\u201d, Int. J. Pattern Recognition and\nArtificial Intelligence, vol. 25, no. 337, 2011, pp. 337-372. [25] Ye. Bodyanskiy, B. Kolchygin, and I. Pliss, \u201cAdaptive neuro-fuzzy Kohonen network with variable fuzzifier\u201d, Int. J.\nInformation Theories and Applications, vol. 18, no. 3, 2011, pp. 215-223. [26] R. Krishnapuram and J.M. Keller, \u201cA possibilistic approach to clustering\u201d, Fuzzy Systems, vol. 1, no. 2, pp. 98-110. [27] B.V. Kolchygin, \u201cEnsemble of neuro-fuzzy Kohonen networks for adaptive clustering\u201d, in Proc. 2nd Int. Sci. Conf. of\nStudents and Young Scientists \u201cTheoretical and Applied Aspects of Cybernetics\u201d, Nov. 2012, pp. 176-181. [28] Ye.V. Bodyanskiy, V.V. Volkova, and A.S. Yegorov, \u201cClustering of document collections based on the adaptive self-\norganizing neural network\u201d, Radio Electronics, Informatics, Control, vol.1(20), 2009, pp. 113-117."}], "references": [{"title": "Fuzzy Clustering Analysis: Methods for Classification, Data Analysis and Image Recognition", "author": ["F. Hoeppner", "F. Klawonn", "R. Kruse", "T. Runkler"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1999}, {"title": "Clustering (IEEE Press Series on Computational Intelligence), Hoboken", "author": ["R. Xu", "D.C. Wunsch"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "DELA: A Dynamic Online Ensemble Learning Algorithm", "author": ["H. Bouchachia", "E. Balaguer-Ballester"], "venue": "Proc. 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Evolving granular neural networks from fuzzy data streams", "author": ["D. Leite", "P. Costa Jr.", "F. Gomide"], "venue": "Neural Networks,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Evolving fuzzy granular modeling from nonstationary fuzzy data streams", "author": ["D. Leite", "R. Ballini", "Pyramo Costa Jr.", "F. Gomide"], "venue": "Evolving Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Evolving fuzzy granular modeling from nonstationary fuzzy data streams", "author": ["D. Leite", "R. Ballini", "Pyramo Costa Jr.", "F. Gomide"], "venue": "Evolving Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Evolving clustering, classification and regression with TEDA", "author": ["D. Kangin", "P. Angelov"], "venue": "Proc. International Joint Conference on Neural Networks (IJCNN", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "A new online clustering approach for data in arbitrary shaped clusters", "author": ["R. Hyde", "P. Angelov"], "venue": "in Proc. International Conference on Cybernetics (CYBCONF", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Dynamically evolving clustering for data streams", "author": ["R.D. Baruah", "P.P. Angelov", "D. Baruah"], "venue": "in Proc. Evolving and Adaptive Intelligent Systems (EAIS", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Evolving neural network with extreme learning for system modeling", "author": ["R. Rosa", "F.A.C. Gomide", "D. Dovzan", "I. Skrjanc"], "venue": "in Proc. Evolving and Adaptive Intelligent Systems (EAIS", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Recursive clustering based on a Gustafson-Kessel algorithm", "author": ["D. Dovzan", "I. Skrjanc"], "venue": "Evolving Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Dynamically evolving fuzzy classifier for real-time classification of data streams", "author": ["R.D. Baruah", "P.P. Angelov", "D. Baruah"], "venue": "in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Angelov, \u201cOnline learning and prediction of data streams using dynamically evolving fuzzy approach", "author": ["P.P.R.D. Baruah"], "venue": "in Proc. IEEE Int. Conf. on Fuzzy Systems (FUZZ-IEEE", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Multivariable Gaussian Evolving Fuzzy Modeling System", "author": ["A.P. Lemos", "W.M. Caminhas", "F.A.C. Gomide"], "venue": "IEEE Trans. Fuzzy Systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Angelov, \u201cEvolving fuzzy systems for data streams: a survey", "author": ["P.P.R.D. Baruah"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2011}, {"title": "pClass: An Effective Classifier for Streaming Examples", "author": ["M. Pratama", "S.G. Anavatti", "M.J. Er", "E. Lughofer"], "venue": "IEEE Trans. Fuzzy Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Recursive fuzzy clustering algorithms", "author": ["Ye. Bodyanskiy", "V. Kolodyaznhiy", "A. Stephan"], "venue": "in Proc. 10 East West Fuzzy Colloqium,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Computational intelligence techniques for data analysis", "author": ["Ye. Bodyanskiy"], "venue": "Lecture Notes in Informatics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Bodyanskiy, \u201cNew recursive learning algorithms for fuzzy Kohonen clustering network", "author": ["Ye. Gorshkov", "V. Kolodyazhniy", "Ye"], "venue": "in Proc. 17 Int. Workshop on Nonlinear Dynamics of Electronic Systems,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Pattern Recognition with Fuzzy Objective Function Algorithms, N.Y.", "author": ["J.C. Bezdek"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1981}, {"title": "What is fuzzy about fuzzy clustering? Understanding and improving the concept of the fuzzifier", "author": ["F. Klawonn", "F. Hoeppner"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2003}, {"title": "Bodyanskiy, \u201cAdaptive fuzzy clustering with a variable fuzzifier", "author": ["B. Kolchygin", "Ye"], "venue": "Cybernetics and System Analysis,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Adaptive clustering ensembles", "author": ["A. Topchy", "B. Minaei-Bidgali", "A.K. Jain", "W.F. Punch"], "venue": "Proc.17th Int. Conf. on Pattern Recognition \u201cICPR 2004\u201d,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "A survey of clustering ensemble algorithms", "author": ["S. Vega-Pons", "J. Ruiz-Shulcloper"], "venue": "Int. J. Pattern Recognition and Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Adaptive neuro-fuzzy Kohonen network with variable fuzzifier", "author": ["Ye. Bodyanskiy", "B. Kolchygin", "I. Pliss"], "venue": "Int. J. Information Theories and Applications,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Ensemble of neuro-fuzzy Kohonen networks for adaptive clustering", "author": ["B.V. Kolchygin"], "venue": "Proc. 2 Int. Sci. Conf. of Students and Young Scientists \u201cTheoretical and Applied Aspects of Cybernetics\u201d,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Yegorov, \u201cClustering of document collections based on the adaptive selforganizing neural network", "author": ["Ye.V. Bodyanskiy", "V.V. Volkova", "A.S"], "venue": "Radio Electronics, Informatics, Control,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "This situation is a subject under study for fuzzy cluster analysis [1, 2].", "startOffset": 67, "endOffset": 73}, {"referenceID": 1, "context": "This situation is a subject under study for fuzzy cluster analysis [1, 2].", "startOffset": 67, "endOffset": 73}, {"referenceID": 2, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 3, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 4, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 5, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 6, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 7, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 8, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 9, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 10, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 11, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 12, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 13, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 14, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 15, "context": "There\u2019s a wide class of tasks to be solved only with the help of the Data Stream Mining [3-16] approach when data are fed and processed in an online mode.", "startOffset": 88, "endOffset": 94}, {"referenceID": 16, "context": "Recurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18].", "startOffset": 168, "endOffset": 176}, {"referenceID": 17, "context": "Recurrent modifications of the fuzzy clustering algorithms (which make it possible to solve a task in an online mode) were introduced for sequential data processing in [17, 18].", "startOffset": 168, "endOffset": 176}, {"referenceID": 18, "context": "introducing a so-called \u00abfuzzy clustering Kohonen network\u00bb [19] which possesses a number of advantages comparing to a conventional self-organizing map.", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "We should note that 2 \uf062 \uf03d in most cases that corresponds to the fuzzy C-means procedure (FCM) by Bezdek [20].", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "\uf028 \uf029 1 0 N j k u k N \uf03d \uf0a3 \uf0a3 \uf0e5 (3) where \uf028 \uf029 [0,1 ] j u k \uf0ce is a membership level of a vector ( ) x k to the j -th class, j c is a prototype of the j -th cluster, \uf062 is a non-negative fuzzification parameter (a fuzzifier) which actually determines a level of borders\u2019 blurriness between clusters, 1, 2, , k N \uf03d \uf0bc .", "startOffset": 42, "endOffset": 48}, {"referenceID": 20, "context": "As an alternative to procedures that use a fuzzifier 1 \uf062 \uf03c \uf03c \uf0a5 , Klawonn and Hoeppner [21] offered an objective function for fuzzy probabilistic clustering", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "Therefore, an adaptive modification of the expression (7) was introduced in [22]", "startOffset": 76, "endOffset": 80}, {"referenceID": 22, "context": "It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others \uf061 value.", "startOffset": 94, "endOffset": 102}, {"referenceID": 23, "context": "It might be expedient to use an idea of an ensemble of parallel working clustering procedures [23, 24] in this situation, where each clustering procedure works with a different from others \uf061 value.", "startOffset": 94, "endOffset": 102}, {"referenceID": 24, "context": "This ensemble can be easily implemented with the help of adaptive neuro-fuzzy Kohonen networks [25].", "startOffset": 95, "endOffset": 99}, {"referenceID": 1, "context": "Classification quality provided by each ensemble member may be estimated with the help of any fuzzy clustering index [2].", "startOffset": 117, "endOffset": 120}, {"referenceID": 21, "context": "Introducing an objective function [22, 25] similarly to (6)", "startOffset": 34, "endOffset": 42}, {"referenceID": 24, "context": "Introducing an objective function [22, 25] similarly to (6)", "startOffset": 34, "endOffset": 42}, {"referenceID": 25, "context": "Let\u2019s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams.", "startOffset": 122, "endOffset": 130}, {"referenceID": 26, "context": "Let\u2019s notice that an ensemble of clustering neural networks with the help of the possibilistic approach was introduced in [27, 28], but its unwieldiness impedes its usage while processing data streams.", "startOffset": 122, "endOffset": 130}], "year": 2016, "abstractText": "A new approach to data stream clustering with the help of an ensemble of adaptive neuro-fuzzy systems is proposed. The proposed ensemble is formed with adaptive neuro-fuzzy self-organizing Kohonen maps in a parallel processing mode. Their learning procedure is carried out with different parameters that define a nature of cluster borders\u2019 blurriness. Clusters\u2019 quality is estimated in an online mode with the help of a modified partition coefficient which is calculated in a recurrent form. A final result is chosen by the best neuro-fuzzy self-organizing Kohonen map.", "creator": "PScript5.dll Version 5.2.2"}}}