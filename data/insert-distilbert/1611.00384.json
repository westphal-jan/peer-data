{"id": "1611.00384", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "The Deep Journey from Content to Collaborative Filtering", "abstract": "in recommender systems research, algorithms are often characterized similarly as either collaborative filtering ( cf ) or content based ( cb ). cf algorithms are trained using a dataset of user explicit or implicit preferences while cb algorithms are typically based on item profiles. these approaches harness very different data sources hence the weights resulting recommended items are generally also very different. this recently paper presents quite a novel model that serves as a bridge from items content into their cf representations. we introduce a multiple domain input deep regression model to predict the cf latent embedding vectors of items obtained based on having their textual description and metadata. we showcase the effectiveness of controlling the proposed model by predicting each the cf vectors of movies and apps based on their overlapping textual descriptions. finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.", "histories": [["v1", "Tue, 1 Nov 2016 20:48:34 GMT  (2221kb)", "http://arxiv.org/abs/1611.00384v1", null]], "reviews": [], "SUBJECTS": "cs.IR cs.CL cs.LG", "authors": ["oren barkan", "noam koenigstein", "eylon yogev"], "accepted": false, "id": "1611.00384"}, "pdf": {"name": "1611.00384.pdf", "metadata": {"source": "META", "title": "Microsoft Word - cb2cf_arxiv.docx", "authors": ["Oren Barkan", "Noam Koenigstein", "Eylon Yogev"], "emails": [], "sections": [{"heading": null, "text": "In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user explicit or implicit preferences while CB algorithms are typically based on item profiles. These approaches harness very different data sources hence the resulting recommended items are generally also very different. This paper presents a novel model that serves as a bridge from items content into their CF representations. We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata. We showcase the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their textual descriptions. Finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.\nKeywords Recommender Systems, Collaborative Filtering, Neural Embedding, Multi-view Representation Learning, Item2vec, SkipGram, Word2vec, Cold Start, Content Based Filtering, Item Similarity"}, {"heading": "1. INTRODUCTION", "text": "In Recommender Systems research, CF models are commonly used for a variety of personalization tasks [9]\u2013[11]. A common approach in CF is to learn a low-dimensional latent space that captures the user\u2019s preference patterns or \u201ctaste\u201d. For example, Matrix Factorization (MF) models [8] are commonly used to map users and items into a dense manifold using a dataset of usage patterns or explicit ratings. An alternative to the CF approach is the Content Based (CB) approach which uses item profiles such as metadata and item descriptions, etc. CF approaches are generally accepted to more accurate than CB approaches [32].\nOur goal is to predict the CF representation of items based on their CB profiles. The CB profiles are obtained from multiple sources such as item tags, numeric values and textual descriptions. Hence, the CB profiles are a mix of categorical, continuous and unstructured data. For example, the CB representation of a movie contains tags (genres, actors, director, languages), numeric values (release year) and textual description (plot summary). To obtain the CF representations, we have used the item2vec [12] algorithm.\nFinally, to learn a mapping from items CB representation to their CF representation, we propose a novel multiple input deep regression model that receives the CB representation as input and uses the CF latent vectors as labels.\nWe demonstrate the application of the proposed model for movies and apps recommender systems. We utilize a CNN on top of word2vec representation to learn a mapping from textual description of items (movie plots or app descriptions) to their CF latent vectors based on item2vec. We note that the approach in this paper is not restricted to item2vec and can be trivially extended to any CF algorithm that is based on a low-dimensional latent embedding such as most common MF models [8].\nBeyond the textual descriptions, the model can be enhanced by adding different types of structured metadata as input. This metadata can be used as additional input along the textual descriptions to produce a mapping which is more accurate than when using each information source separately.\nThis paper makes several contributions: First, we introduce a model for bridging the gap between items\u2019 CB profiles and their CF representations. This can be particularly useful for recommending new items where usage and preference data is not available (the items \u201ccold-start\u201d problem). Secondly, we present a multi-source architecture that supports a combination of categorical, continuous and unstructured data as an input. Finally, we investigate the contribution of each information source with respect to the ultimate CF prediction task.\nThe remainder of this paper is organized as follows: Section 2 describes related work and contrasts it with the current one. Section 3 explains the proposed model in detail. Section 4, presents the experimental setup, the datasets used in this paper and provides both quantitative and qualitative results. Finally, Section 5 concludes and discusses future research."}, {"heading": "2. RELATED WORK", "text": "Deep learning models are being applied in a growing number of machine learning applications. Considerable technological advancements have been achieved in the fields of computer vision [1] and speech recognition [2]. In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30]. Specifically, Skip-Gram with Negative Sampling (SGNS) [5], known also as word2vec, has drawn much attention for its versatile uses in several linguistic tasks.\nWord2vec maps a sparse 1-of-V encoding (where V is the size of the vocabulary) into a dense low-dimensional latent space which encodes semantic information. The resulting word representations span a manifold in which semantically related words are close to each other. A recent work by Kim [7] has further enhanced this approach by applying a convolutional neural network (CNN) on top Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.\nof the latent word representations to glean more information from unstructured textual data.\nThe first part of our model starts from a very similar architecture: First, a word2vec model is established in order to map words taken from the item descriptions into a latent semantic manifold. Then, a CNN model is placed in cascade in order to utilize the semantic information for predicting the CF representation of the items. Therefore, the model in this paper serves as a mapping between the content profiles of items and their CF representations.\nAn interesting observation is that the principle behind CF models such as MF models bears much similarity to SGNS models: both approaches work by \u201csummarizing\u201d a large dataset of sparse entities into a dense manifold that facilitates extraction of useful information. In the case of a word2vec model, the manifold encodes semantic information, while in MF the manifold encodes user preference information. Moreover, a simple neural network that maps a sparse 1-of-M encoding of users (where M is the number of users) into a sparse encoding of N items using a single hidden layer is in fact identical to a MF model: The weight parameters on the incoming and outgoing edges of the hidden layer are respectively equivalent to the user and items vectors of a MF model. The similarity of SGNS to MF has been thoroughly studied in [24].\nItem2vec [12] is a variant of the SGNS with a modified objective aimed at learning item representations for CF tasks. Training is performed using sets of items that were co-purchased or coconsumed by users. Unlike MF models, in item2vec the users are not modeled directly in the latent space. Instead, in item2vec, users are treated as sets of items that are analogous to sentences in word2vec \u2013 these users are the \u201cglue\u201d that indicates relevance between co-occurring items.\nMany attempts have been taken to leverage multiple views for representation learning. Ngiam et al. [25] proposed a \u2018split autoencoder\u2019 approach to extract a joint representation by reconstructing both views from a single view. Andrew et al. [26] introduce a deep variant of Canonical Correlation Analysis (CCA) [29] dubbed Deep CCA (DCCA). In DCCA, two deep neural networks were trained in order to extract representations for two views, where the canonical correlation between the representations is maximized. Other variants of DCCA are investigated in [27, 28].\nIn the context of Recommender Systems, Wang et al. [20] proposed a hierarchical Bayesian model for learning a joint representation for content information and collaborative filtering ratings. Djuric et al. [21] introduced hierarchical neural language models for joint representation of streaming documents and their content with application to personalized recommendations. Xiao and Quan [22] suggested a hybrid recommendation algorithm based on collaborative filtering and word2vec, where recommendations scores are computed by a weighted combination of CF and CB scores.\nThis paper differs from the aforementioned works by several aspects: first, we do not learn a joint representation for both CF and CB views nor do we optimize CCA variants. Instead, we learn a mapping from the CB view directly into the CF view. Second, we introduce a flexible model architecture that supports a combination of various types of input, simultaneously. Third, our model does not produce representation for users, as our task is to predict the CF representation of items. To the best of our knowledge, this is the first work to introduce such a setup, hence a direct comparison of these models is not valid."}, {"heading": "3. MULTIPLE INPUT DEEP REGRESSION", "text": "In this section we provide a detailed description of the proposed model. Our task is to predict the CF representation for each item from its content (textual description / metadata). Given an effective\nfinite set of items 1{ } K kI k == \u2282 \u2115 and co-occurrences matrix\n{0,1}K KA \u00d7\u2208 , we first employ item2vec [12] to produce a mapping\n: nCFM I \u2192\u211d from an item k to a CF vector v .\nThe CB profile of an item k is obtained by using different mappings for different information sources. For the textual descriptions (e.g. movie plot summaries), we consider two different mappings: 2 : l m w vM I \u00d7 \u2192 \u211d is a mapping from an item to a matrix\nthat consists of l rows, where each row is a m -dimensional word vector obtained by word2vec [5]. This matrix corresponds to the\nfirst l words in the textual description of the item. If the number of\nwords is less than l , we pad the matrix with zero rows. 2w vM is\nused to generate the input for the CNN-based text component (Section 3.1).\nThe second mapping for textual data maps an item to its bag of words (BOW) representation denoted by : [0,1]bBOWM I \u2192 . This\nmapping is obtained by first applying k-means clustering on the word2vec representations of the entire vocabulary. We denote the number of clusters by b. Then, given the item\u2019s description text, soft alignment is applied between each word vector in the text and the b centroids. The result is a histogram vector, which is then\nnormalized into probabilities to form the BOW representations. This approach is inspired by prominent BOW models in computer vision [15].\nFor CB information in the form of tags / categories we define a\nmapping : {0,1} T\ntags M I \u2192 from an item to binary vector in size\nT , where T is the size of available tags. Each entry in the binary vector corresponds to a different tag and the value indicates whether the tag related to the item or not.\nThe last mapping we applied is used for numerical inputs and denoted by : cnumM I \u2192 \u211d . This mapping maps an item to a c - dimensional vector, where each element corresponds to one of c continuous features. In the examples we have used, the only numeric feature was a movie\u2019s release year. Therefore, in this case\nnumM is reduced to :numM I \u2192\u2115 .\nIn order to harness the different information sources, we utilize a multiple input deep regression model consisting of three distinct types of components corresponding to each type of information source: textual, tags and numeric information. In what follows, we describe this architecture in detail."}, {"heading": "3.1 Text Components", "text": "The text components are designed to receive raw text as input and output a fixed size vector. In this work, we implement two different types of text components: dubbed \u2018CNN\u2019 and \u2018BOW\u2019 (marked red in Fig. 1). The CNN approach follows Kim\u2019s \u2018CNN non-static\u2019\nmodel from [7]. As explained earlier, using 2w vM , we map the\nsequence of words in the textual input to a matrix which serves as the input to a CNN network. An illustration of this approach (taken from [7]) appears in Fig. 1(d). We note that the backpropagation process continues through the CNN onto the initial word2vec representations allowing the word embedding to freely adjust with respect to the CF prediction task at hand. Hence, the initial mapping\n2w vM is fine-tuned throughout the training process.\nOur CNN consists of a single 1D convolutional layer with a filter length of 3 and L2 regularization on its weights. This is followed by a global max pooling layer (convolution and pooling are applied over the time axis) and an additional fully connected (FC) layer. In contrast to [7], we did not apply parallel convolutional layers with different filter lengths. We did experiment with multiple filter\nlengths (2-12), but these attempts failed to materialize into any gains with respect to our objective. A similar observation was also made in [31].\nWe applied a random dropout of words before feeding them into the CNN. This technique was instrumental in improving the model\u2019s generalization capability and avoiding overfitting. The probability for dropping words can be either fixed or proportional to the words\u2019 frequency. We found that both methods yield similar results and therefore resulted to using a fixed dropping probability of 0.2.\nWe considered several additional variants of CNN-based models as in [7]: (1) the \u2018CNN random\u2019 model learns the word\nrepresentation 2w vM from scratch by using random initialization of\nthe word vectors; (2) the \u2018CNN static\u2019 model that keeps the\nword2vec representation 2w vM fixed during the entire training\nprocess; (3) the \u2018CNN multichannel\u2019 model, which is a combination of both the \u2018non-static\u2019 and \u2018static\u2019 models. However, the \u2018CNN non-static\u2019 variant outperformed all the rest. In the remainder of this paper we refer to this variant as our CNN component.\nOur second approach for utilizing textual information is based on a Bag of Words (BOW) on top of the word2vec representations.\nThe BOW representation is computed by BOWM and is fed into a\nneural network with two FC layers and dropout in between. The BOW network architecture is presented in Fig. 1(c)."}, {"heading": "3.2 Tags Components", "text": "Beyond the textual information, it might be useful to utilize tags metadata which is associated with each item. The tags network component is a binary input vector in the dimension of number of tags and a single FC hidden layer with L2 regularization on its weights. No further improvement was gained by including additional layers. The input for the tags component is given by\ntags M . The tags component is illustrated in Fig 1(a).\nIn the movies examples, we used different tags components for different types of tags: genres, actors, directors and language tags. The hidden layer dimension is determined for each component according to the number of tags and their available combinations. For example, the actors component might be assigned with a higher output dimension than the language component. This is due to the fact that the number of actors is much larger than the number of languages. Moreover, movies usually contain multiple actors, but a single language."}, {"heading": "3.3 Numeric Components", "text": "Numeric components are designed to handle numeric structured data represented as a continuous feature vectors. In this work, the only numeric values available were the movies\u2019 release years. Therefore, the numeric component was simply chosen to be a network with a single input neuron (Fig. 1(b)). This input is given\nby numM .\nFigure 1: An illustration of components used in our model. Input, hidden and output layers are marked with \u2018x\u2019, \u2018h\u2019 and \u2018y\u2019, respectively. Note that each layer may contain different number of neurons. Black arrows symbol FC connections. (a) Tags components consist of an input layer in size of available tags and a single hidden layer. The input is given as a binary vector computed by . (b) The numeric component receives input using . (c) The BOW component\nreceives the BOW features that are extracted using and contains two hidden layers. (d) The CNN component\nreceives a matrix of row vectors obtained by the word2vec representation that correspond to the first words in the\ntextual description of the item. This matrix is computed by . The convolutional layer contains multiple filters (in\nour implementation all in size of ). A global max pooling operation is applied over the time axis and this is followed\nby an additional hidden layer. The CNN used in this work fine-tunes the initial word2vec representation. (e) The combiner component receives the outputs from several different components and fully connect them to a hidden layer that is followed by an output layer. The dimension of the output layer is the same as the dimension of the CF space ."}, {"heading": "3.4 A Combiner Component", "text": "The combiner component aims at combining multiple outputs from different components in order to predict into the CF space. The combiner component (illustrated in Fig. 1(e)) consists of a multiple input layers that are fully connected to a hidden layer with L2 regularization. This is followed by a final FC output layer with the same dimension of the CF space."}, {"heading": "3.5 The Full Model", "text": "The full model is illustrated in Fig. 2. In accordance with Fig. 1, tags, text and numeric components are colored in blue, red and green respectively. The combiner component is colored in yellow. Fig. 2 exemplifies the application of the presented model for the movie similarity task, specifically for the \u2018Pulp Fiction\u2019 movie. Genres, actors, directors and languages are modeled as tags components, the movie plot summary is modeled as text component. In this implementation, the text component can be either CNN or BOW network. The movie\u2019s release year is modeled as a numeric component. All of the components outputs are then fed into the combiner component that outputs a predicted CF vector. The loss function we use to train the model is the Mean Square Error (MSE), which is a common choice for regression tasks.\nReLU [1] activations are used in all of the model components. It is worth noting that we experimented with other types of activations such as sigmoid and hyperbolic tangent, however, these were found to perform worse. The only exception is the output layer of the combiner, where we use linear activations, which is a common practice for regression models.\nIt is important to emphasize that the propose model is extremely flexible in the sense that each component can be easily disconnected from the combiner and the extension for additional information sources is straightforward. For example, we can add the countries the movie was filmed and the movie duration as additional tags and numeric components, respectively.\nThe exact parameter and hyperparameter values we used in our\nexperiments are detailed in Section 4.3."}, {"heading": "4. EXPERIMENTAL SETUP AND RESULTS", "text": "The quantitative evaluation results in this paper are based on a 10- fold cross validation processes. We supplement these quantitative results with qualitative results to gain a better \u201cfeel\u201d of the model. Recall that our goal is to predict for each item its CF vector from its content profile. Hence, the CF representation is considered as the ground truth in all of our experiments. Furthermore, since our model and the experimental setup are substantially different from previous other work [20]-[22], a direct comparison between these models to ours cannot be made (as explained in Section 2).\nNext, we describe in detail the datasets, evaluated systems, parameter configurations, evaluation measures and present results."}, {"heading": "4.1 Datasets", "text": "We exemplify the model by mapping CB to CF in two domains: movie recommendations based on a public dataset and Windows Apps recommendations using a proprietary dataset."}, {"heading": "4.1.1 Word2vec dataset", "text": "We used a subset of the dataset from [14] in order to establish a word2vec model. Specifically, we kept only the top 50K most frequent words. We also mapped all numbers to the digit 9 and removed punctuation characters. Then, we randomly sampled 9.2M sentences that formed a total text length of 217M words for training the word2vec model according to [5]."}, {"heading": "4.1.2 Movies dataset", "text": "The movies dataset is publicly available and contains both CF and CB data for movies. The CF data is based on the latest MovieLens dataset [18] containing 22,884,377 ratings collected during 1995- 2016 from 247,753 users that watched 34,208 movies. The movies are rated using a 5-star scale with half-star increments (0.5 - 5.0). From each user\u2019s rating list, we consider all the movies with ratings above 3.5 as a set of co-occurring movies. We further discard all sets of size < 2. This results in 173,266 sets that contain 11,108 unique items (movies) as the effective training data for learning the item2vec model [12].\nFor each movie, we collected metadata from IMDB [33]. Three types of information sources are collected: movie plot (given as raw text), genres / actors / directors / languages (given as tags) and release year (given as a natural number). In the metadata tags, we filtered tags that with less than 5 occurrences resulting in a remainder of 23 genres, 1526 actors, 470 directors and 72 languages.\nWe created movie CB profiles as follows: First, we represented each movie\u2019s plot summary by taking the first 500 words with word2vec mapping. We used zero padding for the plot descriptions shorter than 500 words. Then, the metadata fields from above were added to the movie profiles. Note that some of the movies had missing information. In this case, we set the plot or the missing tags to a special word / tag \u2018n/a\u2019. Missing values for the release year are set to the mean year of all movies (1993)."}, {"heading": "4.1.3 Windows apps dataset", "text": "The second dataset is a propriety dataset containing CF and CB data for apps from the Microsoft Windows Store. We generated CF profiles for the items using a dataset of users activity containing 5M user sessions. Each user session contains a list of items that were clicked by the same user in the same activity session. This dataset consisted of 33K unique items (apps) which were used to procure an item2vec model of representative CF vectors.\nFor each app, we created textual profiles based on the app description in the same manner as we did with the movies data (first 500 words that have word2vec representation are saved for each app as its textual description). In this case, no further metadata was used beyond the textual descriptions."}, {"heading": "4.2 Evaluated Systems", "text": "In order to quantify the relative contribution of each data source in our model, we trained different configurations of the model, each time connecting a single component to the combiner and disconnecting all other components. For tags components we trained separate models for genres, actors, director and language. When presenting results, we intuitively dubbed each of these models according to their information sources i.e., \u2018Genres\u2019, \u2018Actors\u2019, \u2018Director\u2019 and \u2018Language\u2019 respectively. For the text components we trained separate models for CNN and BOW as explained above and dubbed them \u2018CNN\u2019 and \u2018BOW\u2019. For the numeric component we trained a separate model for the release year and dub it \u2018Year\u2019.\nIn order to quantify the relative contribution of each combination, we further trained models for the following combinations of components: \u2018Tags\u2019 \u2013 a combination of \u2018Genres\u2019, \u2018Actors\u2019,\u2018Director\u2019 and \u2018Language\u2019. \u2018Tags+Year\u2019 \u2013 a combination of \u2018Tags\u2019 and \u2018Year\u2019. \u2018Tags+CNN\u2019 \u2013 a combination of \u2018CNN\u2019 and \u2018Tags\u2019. \u2018CNN+Year\u2019 \u2013 a combination of \u2018CNN\u2019 and\u2019 Year\u2019. \u2018CNN+Tags+Year\u2019 \u2013 a combination of \u2018CNN\u2019, \u2018Tags\u2019 and \u2018Year\u2019, which is the \u2018full\u2019 model (Section 3.5). Note that we did not include the \u2018BOW\u2019 component in the combinations since we found its contribution to be marginal once \u2018CNN\u2019 is included."}, {"heading": "4.3 Parameter Configuration", "text": "The system parameters were determined according to a separate validation set.\nThe item2vec models (for both movies and apps) were trained for 100 epochs with a target dimension 40n = , negative to positive\nratio 15 and subsampling parameter 1e-4. The word2vec model was trained for 100 epochs with a target dimension 100m = , window size 4, subsampling parameter 1e-5\nand negative to positive ratio 15.\nFor the \u2018Genres\u2019, \u2018Actors\u2019, \u2018Director\u2019 and \u2018Language\u2019 components, we used hidden layers with dimensions 100, 100, 40 and 20, respectively.\nThe \u2018CNN\u2019 components (for both movies and apps) uses 300\nfilters with a length 3 (each filter\u2019s dimensions are in size of 3 100\u00d7\n). The input shape for the \u2018CNN\u2019 was set to a matrix in size of 500 100\u00d7 . This matrix contains the first 500 words from the movie\nplot / app description, where each word vector is in dimension 100. For the \u2018BOW\u2019 component, we used hidden layers of dimension 256. The number of centroids in k-means was set to b=250. For the combiner component, we used a hidden layer of dimension 256.\nEach system was trained to minimize the MSE loss function. We used the Adam optimizer [17] with a mini-batch size of 32 and applied an early stopping procedure [19]. When applied, the L2 regularization and dropout probability values were set to 1e-4 and 0.2, respectively."}, {"heading": "4.4 Evaluation Measures", "text": "The first evaluation measure used in this paper is the Mean Squared Error (MSE) as measured by the difference of the predicted CF vectors from their original (item2vec) CF vectors. Formally, MSE\nis measured as follows: = | | \u2211 \u2212 \u2208 , where is the set of all test set items, is the original CF vector, and is the predicted vector. Minimizing the MSE is the objective of all the systems in this paper. It quantifies the ability of the different systems to reconstruct the original CF vectors. However, MSE does not have any direct business interpretation with regard to the ultimate collaborative filtering task. Hence, our next evaluation measures are borrowed from the field of CF research and directly quantify the quality of the predicted vectors with regard to the CF task.\nOur second measure quantifies the quality of the predicted vectors in terms of item similarities in the CF latent manifold. For each predicted CF vector, we compute item similarities to all other items as well as to its own original CF vector. Then, we measure the Mean Percentile Rank (MPR) of the original item with respect to all other items. Formally, we denote by the ranked position of the original item, when measured against the other items based on similarity to the predicted vector. For a dataset of M items, the best possible rank is = 0 and the worst is = \u2212 1. The MPR\nmeasure is computed according to = | | \u2211 \u2208 . Note that 0 \u2264 \u2264 1, where = 0 is the optimal value and = 0.5 can be achieved by random predictions. Our final evaluation measure was chosen to quantify the ability of the predicted vectors to maintain the original item similarities. Specifically, we care more about the ability to find the most relevant item to each test item. Hence, we chose to use the Normalized Discounted Cumulative Gain for the top K most similar items or ! . This measure is computed by finding the K items most similar to the predicted vector, and summing their discounted relevance scores based on the original item vector. Formally, for the i\u2019th test item the Discounted Cumulative Gain at K is given by ! = \"# +\u2211 %& '\n()*+ ,-\n. ,/ , where \"# , is the\nrelevance score of the k\u2019th retrieved item to the i\u2019th test item. The relevance scores are simply the similarities of the retrieved items to the test item based on its original vector. Then, the normalized discounted commutative gain at K is computed by normalizing the item\u2019s ! score by its maximum possible value also known as the Ideal Discounted Commutative Gain at K or 0 ! . The 0 ! is achieved by ranking the items according to the original (item2vec) CF vector and taking the K most similar items. The final measure is computed by averaging over all the test set\n! \u2264 1 and ! = 1 indicates a \u201cperfect\u201d prediction for the top K most similar items."}, {"heading": "4.5 Quantitative Results", "text": ""}, {"heading": "4.5.1 Movies data", "text": "Table 1 depicts the MSE and MPR values and Fig. 3 depicts NDCG(K) for the systems described in Section 4.2. All values are averaged using 10 fold cross validation. In most cases, the three evaluation measures are highly correlated. In what follows, we identify common trends across all evaluation measures and provide interpretations to these trends.\nFirst, let us consider the \u2018BOW\u2019 vs. the \u2018CNN\u2019 systems. Both systems are based purely on the movie textual descriptions. Our results show that \u2018CNN\u2019 approach achieves better results than the \u2018BOW\u2019 approach. This showcases the ability of the \u2018CNN\u2019 model to benefit from the semantic information encoded in the word2vec representations as well as the ability of the \u2018CNN\u2019 filters to pick up the semantical context encoded by word propagation in the text. Next, we turn to consider the tags data. As explained in Section 3.2, there are four types of tags based systems: \u2018Genres\u2019, \u2018Actors\u2019, \u2018Directors\u2019, and \u2018Language\u2019 and we consider each system separately. Table 1 and Fig. 3 show that these systems were outperformed by \u2018CNN\u2019 across all measures. This indicates the ability of the \u2018CNN\u2019 system to utilize the textual information even beyond these very informative data sources.\nThe \u2018Year\u2019 system, based on movies release year, outperforms each of the previous systems including the \u2018CNN\u2019. Clearly, a movie\u2019s release year alone cannot make for a good recommender system. Nevertheless, it captures a key pattern in the MovieLens dataset, which is characterized by many users who watch movies with adjacent release dates. Typically, movies are heavily promoted during their release period and much of the viewing patterns recorded in the MovieLens dataset occur during that period. Many MovieLens users watch multiple movies with close release dates. Hence, a movie\u2019s release date explains a very dominant pattern in the dataset.\nFinally, we turn to consider systems in which different information sources are combined. We notice that each combined model generates a considerable performance boost over its respective systems. Ultimately, the \u2018CNN+Tags+Year\u2019 system (the \u2018full\u2019 model) outperforms all the rest by combining all these information sources together."}, {"heading": "4.5.2 Windows apps data", "text": "Table 2 presents MPR and NDCG values obtained by the \u2018CNN\u2019 system on the apps dataset. As we can see, the MPR value obtained by the \u2018CNN\u2019 model is significantly lower than the best result obtained by the \u2018full\u2019 model for the movies data (2.35 vs 5.4). We believe this is due to fact the apps dataset contains more training examples than the movies dataset (30K vs 11K) that enables a better fine-tuning of the word vectors with respect to the prediction task."}, {"heading": "4.6 Qualitative Results", "text": ""}, {"heading": "4.6.1 Movies data", "text": "Table 2 presents movie recommendations based on nearest neighbor search (with cosine similarity) in the CF and predicted space with respect to test queries. All queries contains items from the test set. The second column presents recommendations that were produced using the original CF vectors based on item2vec. The third column presents recommendations produced by the \u2018CNN+Tags+Year\u2019 system (the \u2018full\u2019 model) that utilizes all information sources. The last column presents recommendations produced by the \u2018CNN\u2019 system that leverages textual description of movies (plots) solely.\nThree well-known movies from the test set are considered: \u2018Shrek\u2019 (2001), \u2018The Hangover\u2019 (2011) and \u2018Gladiator\u2019 (2000). We notice the tendency of the CF based recommendations to prefer popular movies. The \u2018full\u2019 model tends to pick recommendations from adjacent years having the same genre / actors and with similar plots. The \u2018CNN\u2019 model produces recommendations that are not restricted to a specific year. Therefore, it contains the recommendations \u2018Shrek the Third\u2019 and \u2018Shrek Forever After\u2019 that are the third and fourth movies in the \u2018Shrek\u2019 series released in later years (2007 and 2010). The \u2018CNN\u2019 model exhibits the same behavior, when recommending the third movie in \u2018The Hangover\u2019 series. This showcases the ability of the \u2018CNN\u2019 model to accurately identify the movie type in the query by analyzing its plot and provide recommendations that are competitive with the other two models.\nIn the word2vec paper by Mikolov et al. [5], the authors illustrated the ability of their model to automatically organize word representations that capture semantical relations. For example, they showed that the relationship between a country and its capital is captured by the difference between their respective vector representations (Fig. 2 in [5]). Inspired by this work, we demonstrate the ability of our model to encode relationships between actors. Representations for actors are produced by setting the corresponding entry of the actor in the \u2018Actors\u2019 component to 1 and setting all other entries to 0.\nTable 4 presents the learned relationships. The left column presents a relationship between actors captured by the distance vector between their representations. In the right column, this relationship is applied to a new actor by adding the distance vector\nto a new origin. The closest artist is then retrieved (according to cosine similarity) and presented as the result of the summation.\nThe first example demonstrates a relationship based on a generational (~ 20 years) gap between actors that play in movies from the same genres. The second example demonstrates a transition from versatile actors to more comedy oriented actors in both genders. Finally, the third example demonstrates a transition from American to British actors across different genres.\nFigure 4 depicts a t-SNE [13] embedding of the original (item2vec) CF vectors (a) and the predicted vectors by our \u2018full\u2019 model (b) for a random pick of 900 movies from the top six genres in the test set. For movies with multiple genre tags, we depict the first tag as their genre. Figure 4 shows that genre clustering exists both in the original CF space and even more so in the predicted space.\nFigure 5 depicts a random pick of 1100 movies from the test set and the t-SNE embedding of their original CF vectors (a) and the vectors predicted by our model (b). This figure investigates the importance of a movie release dates in finding similar items. In accordance with the evaluation measures, Fig. 5 indicates that a release date is an important factor in the original CF similarities as well as in the resulting predictions."}, {"heading": "4.6.2 Windows apps data", "text": "Table 3 presents apps recommendations produced according to a similar setting as in Table 2. The second column presents recommendations that were produced using the original CF vectors based on item2vec. The third column presents recommendations produced by the \u2018CNN\u2019 system. As we can see, the \u2018CNN\u2019 system manages to provide accurate recommendations with respect to the given seed item based on textual description of apps solely."}, {"heading": "5. CONCLUSION AND FUTURE WORK", "text": "In this paper, we introduce a novel model that maps content based item information to its CF representation. We focus on movie and app recommendations and show a network architecture that maps movie structured metadata as well as unstructured textual descriptions into their latent CF representations. The textual\ndescriptions were processed using a word2vec model followed by a CNN that scans the text in a similar fashion to latest NLP models [7]. In our evaluation, we show the effectiveness of the system in predicting useful movie and app recommendations and explore the contribution of each of its components.\nIn the future, we plan to investigate additional directions. Specifically, we plan to train a model to predict both metadata tags and the CF representation, simultaneously, from textual descriptions. This model will use a hybrid loss function that consists of classification and regression losses. We also plan to expand the model presented in this paper to include additional information sources such as audio, image and video. We further plan to apply the same ideas to books and music datasets."}, {"heading": "6. REFERENCES", "text": "[1] A. Krizhevsky, I. Sutskever, and G. E. Hinton, \u201cImageNet Classification with Deep Convolutional Neural Networks,\u201d in Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1097\u20131105.\n[2] A. Graves, A. Mohamed, and G. E. Hinton, \u201cSpeech recognition with deep recurrent neural networks,\u201d in {IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2013, Vancouver, BC, Canada, May 26-31, 2013, 2013, pp. 6645\u2013 6649.\n[3] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin, \u201cA Neural Probabilistic Language Model,\u201d J. Mach. Learn. Res., vol. 3, pp. 1137\u20131155, Mar. 2003.\n[4] W. Yih, K. Toutanova, J. C. Platt, and C. Meek, \u201cLearning Discriminative Projections for Text Similarity Measures,\u201d in Proceedings of the Fifteenth Conference on Computational Natural Language Learning, 2011, pp. 247\u2013256.\n[5] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \u201cDistributed Representations of Words and Phrases and their Compositionality,\u201d in Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 3111\u20133119.\n[6] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa, \u201cNatural Language Processing (Almost) from Scratch,\u201d J. Mach. Learn. Res., vol. 12, pp. 2493\u20132537, Nov. 2011.\n[7] Y. Kim, \u201cConvolutional Neural Networks for Sentence Classification,\u201d Proc. 2014 Conf. Empir. Methods Nat. Lang. Process. (EMNLP 2014), pp. 1746\u20131751, 2014.\n[8] Y. Koren, R. Bell, and C. Volinsky, \u201cMatrix Factorization Techniques for Recommender Systems,\u201d Computer (Long. Beach. Calif)., vol. 42, no. 8, pp. 30\u201337, Aug. 2009.\n[9] J. Bennett and S. Lanning, \u201cThe Netflix Prize,\u201d in Proceedings of the KDD Cup Workshop 2007, 2007, pp. 3\u20136.\n[10] R. M. Bell and Y. Koren, \u201cLessons from the Netflix Prize Challenge,\u201d SIGKDD Explor. Newsl., vol. 9, no. 2, pp. 75\u201379, Dec. 2007.\n[11] G. Dror, N. Koenigstein, Y. Koren, and M. Weimer, \u201cThe Yahoo\u202f! Music Dataset and KDD-Cup \u2019 11,\u201d KDD Cup, pp. 8\u201318, 2012.\n[12] Barkan O., Koenigstein N., \u201cItem2Vec: Neural item embedding for collaborative filtering,\u201d arXiv: 1603.04259. 2016 Mar 14.\n[13] L. Van Der Maaten and G. Hinton, \u201cVisualizing Data using tSNE,\u201d JMLR., vol. 9, pp. 2579\u20132605, 2008.\n[14] Chelba C, Mikolov T, Schuster M, Ge Q, Brants T, Koehn P, Robinson T. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint arXiv:1312.3005. 2013 Dec 11.\n[15] Csurka, G., Dance, C., Fan, L., Willamowski, J., & Bray, C. (2004, May). Visual categorization with bags of keypoints. In Workshop on statistical learning in computer vision, ECCV (Vol. 1, No. 1-22, pp. 1-2).\n[16] Ramos, J. (2003, December). Using tf-idf to determine\nword relevance in document queries. In Proceedings of the first instructional conference on machine learning.\n[17] Kingma, D., & Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.\n[18] Harper, F. M., & Konstan, J. A. (2015). The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS), 5(4), 19.\n[19] Prechelt L. Automatic early stopping using cross validation: quantifying the criteria. Neural Networks. 1998 Jun 30;11(4):761-7.\n[20] Wang H, Wang N, Yeung DY. Collaborative deep learning for recommender systems. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 2015 Aug 10 (pp. 1235-1244). ACM.\n[21] Djuric N, Wu H, Radosavljevic V, Grbovic M, Bhamidipati N. Hierarchical neural language models for joint representation of streaming documents and their content. InProceedings of the 24th International Conference on World Wide Web 2015 May 18 (pp. 248-255). ACM.\n[22] Xiao, Yao, and Quan Shi. \"Research and Implementation of Hybrid Recommendation Algorithm Based on Collaborative Filtering and Word2Vec.\" 2015 8th International Symposium on Computational Intelligence and Design (ISCID). Vol. 2. IEEE, 2015.\n[23] Pennington J, Socher R, Manning CD. Glove: Global Vectors for Word Representation. In EMNLP 2014 Oct 25 (Vol. 14, pp. 1532-43).\n[24] Levy, O. and Goldberg, Y. (2014). Neural word embedding as implicit matrix factorization. In Advances in neural information processing systems (pp. 2177-2185).\n[25] Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., & Ng, A. Y. (2011). Multimodal deep learning. In Proceedings of the 28th international conference on machine learning (ICML-11) (pp. 689- 696).\n[26] Andrew, G., Arora, R., Bilmes, J. A., & Livescu, K. (2013, May). Deep Canonical Correlation Analysis. In ICML (pp. 1247- 1255).\n[27] Wang, W., Arora, R., Livescu, K., & Bilmes, J. A. (2015, April). Unsupervised learning of acoustic features via deep canonical correlation analysis. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 4590-4594). IEEE.\n[28] Wang, W., Arora, R., Livescu, K., & Bilmes, J. (2015). On deep multi-view representation learning. In Proc. of the 32st Int. Conf. Machine Learning (ICML 2015) (pp. 1083-1092).\n[29] Hotelling, H. Relations between two sets of variates. Biometrika, 28(3/4):321\u2013377, 1936.\n[30] Barkan, O. (2016). Bayesian Neural Word Embedding. arXiv preprint arXiv:1603.06571.\n[31] Zhang, Y. and Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification. arXiv preprint arXiv:1510.03820.\n[32] Slaney, M., 2011. Web-scale multimedia analysis: Does content matter?. IEEE MultiMedia, 18(2), pp.12-15.\n[33] http://www.imdb.com"}], "references": [{"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1097\u20131105.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G.E. Hinton"], "venue": "{IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP} 2013, Vancouver, BC, Canada, May 26-31, 2013, 2013, pp. 6645\u2013 6649.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "A Neural Probabilistic Language Model", "author": ["Y. Bengio", "R. Ducharme", "P. Vincent", "C. Janvin"], "venue": "J. Mach. Learn. Res., vol. 3, pp. 1137\u20131155, Mar. 2003.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning Discriminative Projections for Text Similarity Measures", "author": ["W. Yih", "K. Toutanova", "J.C. Platt", "C. Meek"], "venue": "Proceedings of the Fifteenth Conference on Computational Natural Language Learning, 2011, pp. 247\u2013256.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"], "venue": "Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 3111\u20133119.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Natural Language Processing (Almost) from Scratch", "author": ["R. Collobert", "J. Weston", "L. Bottou", "M. Karlen", "K. Kavukcuoglu", "P. Kuksa"], "venue": "J. Mach. Learn. Res., vol. 12, pp. 2493\u20132537, Nov. 2011.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "Proc. 2014 Conf. Empir. Methods Nat. Lang. Process. (EMNLP 2014), pp. 1746\u20131751, 2014.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Matrix Factorization Techniques for Recommender Systems", "author": ["Y. Koren", "R. Bell", "C. Volinsky"], "venue": "Computer (Long. Beach. Calif)., vol. 42, no. 8, pp. 30\u201337, Aug. 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "The Netflix Prize", "author": ["J. Bennett", "S. Lanning"], "venue": "Proceedings of the KDD Cup Workshop 2007, 2007, pp. 3\u20136.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Lessons from the Netflix Prize Challenge", "author": ["R.M. Bell", "Y. Koren"], "venue": "SIGKDD Explor. Newsl., vol. 9, no. 2, pp. 75\u201379, Dec. 2007.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "The Yahoo ! Music Dataset and KDD-Cup \u2019 11", "author": ["G. Dror", "N. Koenigstein", "Y. Koren", "M. Weimer"], "venue": "KDD Cup, pp. 8\u201318, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Item2Vec: Neural item embedding for collaborative filtering", "author": ["O. Barkan", "N. Koenigstein"], "venue": "arXiv: 1603.04259. 2016 Mar 14.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Visualizing Data using t- SNE", "author": ["L. Van Der Maaten", "G. Hinton"], "venue": "JMLR., vol. 9, pp. 2579\u20132605, 2008.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "One billion word benchmark for measuring progress in statistical language modeling", "author": ["C Chelba", "T Mikolov", "M Schuster", "Q Ge", "T Brants", "P Koehn", "T. Robinson"], "venue": "arXiv preprint arXiv:1312.3005", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "December). Using tf-idf to determine  word relevance in document queries", "author": ["J. Ramos"], "venue": "In Proceedings of the first instructional conference on machine learning", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["D. Kingma", "J. Ba"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "The MovieLens Datasets: History and Context", "author": ["F.M. Harper", "J.A. Konstan"], "venue": "ACM Transactions on Interactive Intelligent Systems (TiiS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Automatic early stopping using cross validation: quantifying the criteria", "author": ["L. Prechelt"], "venue": "Neural Networks", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "Collaborative deep learning for recommender systems", "author": ["H Wang", "N Wang", "DY. Yeung"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 2015 Aug", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Hierarchical neural language models for joint representation of streaming documents and their content", "author": ["N Djuric", "H Wu", "V Radosavljevic", "M Grbovic", "N. Bhamidipati"], "venue": "InProceedings of the 24th International Conference on World Wide Web 2015 May", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Research and Implementation of Hybrid Recommendation Algorithm Based on Collaborative Filtering and Word2Vec.\" 2015", "author": ["Xiao", "Yao", "Quan Shi"], "venue": "8th International Symposium on Computational Intelligence and Design (ISCID)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Glove: Global Vectors for Word Representation", "author": ["J Pennington", "R Socher", "CD. Manning"], "venue": "In EMNLP 2014 Oct 25 (Vol", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Neural word embedding as implicit matrix factorization. In Advances in neural information processing systems (pp. 2177-2185)", "author": ["O. Levy", "Y. Goldberg"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Multimodal deep learning", "author": ["J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "A.Y. Ng"], "venue": "In Proceedings of the 28th international conference on machine learning (ICML-11)", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Unsupervised learning of acoustic features via deep canonical correlation analysis", "author": ["W. Wang", "R. Arora", "K. Livescu", "Bilmes", "J. A", "April"], "venue": "In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 4590-4594)", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "On deep multi-view representation learning", "author": ["W. Wang", "R. Arora", "K. Livescu", "J. Bilmes"], "venue": "In Proc. of the 32st Int. Conf. Machine Learning (ICML", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": "Biometrika, 28(3/4):321\u2013377,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1936}, {"title": "Bayesian Neural Word Embedding", "author": ["O. Barkan"], "venue": "arXiv preprint arXiv:1603.06571", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification", "author": ["Y. Zhang", "B. Wallace"], "venue": "arXiv preprint arXiv:1510.03820", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Web-scale multimedia analysis: Does content matter", "author": ["M. Slaney"], "venue": "IEEE MultiMedia,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}], "referenceMentions": [{"referenceID": 8, "context": "In Recommender Systems research, CF models are commonly used for a variety of personalization tasks [9]\u2013[11].", "startOffset": 100, "endOffset": 103}, {"referenceID": 10, "context": "In Recommender Systems research, CF models are commonly used for a variety of personalization tasks [9]\u2013[11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 7, "context": "For example, Matrix Factorization (MF) models [8] are commonly used to map users and items into a dense manifold using a dataset of usage patterns or explicit ratings.", "startOffset": 46, "endOffset": 49}, {"referenceID": 29, "context": "CF approaches are generally accepted to more accurate than CB approaches [32].", "startOffset": 73, "endOffset": 77}, {"referenceID": 11, "context": "To obtain the CF representations, we have used the item2vec [12] algorithm.", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "We note that the approach in this paper is not restricted to item2vec and can be trivially extended to any CF algorithm that is based on a low-dimensional latent embedding such as most common MF models [8].", "startOffset": 202, "endOffset": 205}, {"referenceID": 0, "context": "Considerable technological advancements have been achieved in the fields of computer vision [1] and speech recognition [2].", "startOffset": 92, "endOffset": 95}, {"referenceID": 1, "context": "Considerable technological advancements have been achieved in the fields of computer vision [1] and speech recognition [2].", "startOffset": 119, "endOffset": 122}, {"referenceID": 2, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 125, "endOffset": 128}, {"referenceID": 5, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 129, "endOffset": 132}, {"referenceID": 27, "context": "In Natural Language Processing (NLP), deep learning methods have been mostly focused on learning word vector representations [3]-[6], [30].", "startOffset": 134, "endOffset": 138}, {"referenceID": 4, "context": "Specifically, Skip-Gram with Negative Sampling (SGNS) [5], known also as word2vec, has drawn much attention for its versatile uses in several linguistic tasks.", "startOffset": 54, "endOffset": 57}, {"referenceID": 6, "context": "A recent work by Kim [7] has further enhanced this approach by applying a convolutional neural network (CNN) on top Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.", "startOffset": 21, "endOffset": 24}, {"referenceID": 22, "context": "The similarity of SGNS to MF has been thoroughly studied in [24].", "startOffset": 60, "endOffset": 64}, {"referenceID": 11, "context": "Item2vec [12] is a variant of the SGNS with a modified objective aimed at learning item representations for CF tasks.", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "[25] proposed a \u2018split autoencoder\u2019 approach to extract a joint representation by reconstructing both views from a single view.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[26] introduce a deep variant of Canonical Correlation Analysis (CCA) [29] dubbed Deep CCA (DCCA).", "startOffset": 70, "endOffset": 74}, {"referenceID": 24, "context": "Other variants of DCCA are investigated in [27, 28].", "startOffset": 43, "endOffset": 51}, {"referenceID": 25, "context": "Other variants of DCCA are investigated in [27, 28].", "startOffset": 43, "endOffset": 51}, {"referenceID": 18, "context": "[20] proposed a hierarchical Bayesian model for learning a joint representation for content information and collaborative filtering ratings.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[21] introduced hierarchical neural language models for joint representation of streaming documents and their content with application to personalized recommendations.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Xiao and Quan [22] suggested a hybrid recommendation algorithm based on collaborative filtering and word2vec, where recommendations scores are computed by a weighted combination of CF and CB scores.", "startOffset": 14, "endOffset": 18}, {"referenceID": 11, "context": "{0,1} K A \u00d7 \u2208 , we first employ item2vec [12] to produce a mapping", "startOffset": 41, "endOffset": 45}, {"referenceID": 4, "context": "vector obtained by word2vec [5].", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "The second mapping for textual data maps an item to its bag of words (BOW) representation denoted by : [0,1] BOW M I \u2192 .", "startOffset": 103, "endOffset": 108}, {"referenceID": 6, "context": "model from [7].", "startOffset": 11, "endOffset": 14}, {"referenceID": 6, "context": "An illustration of this approach (taken from [7]) appears in Fig.", "startOffset": 45, "endOffset": 48}, {"referenceID": 6, "context": "In contrast to [7], we did not apply parallel convolutional layers with different filter lengths.", "startOffset": 15, "endOffset": 18}, {"referenceID": 28, "context": "A similar observation was also made in [31].", "startOffset": 39, "endOffset": 43}, {"referenceID": 6, "context": "We considered several additional variants of CNN-based models as in [7]: (1) the \u2018CNN random\u2019 model learns the word", "startOffset": 68, "endOffset": 71}, {"referenceID": 0, "context": "ReLU [1] activations are used in all of the model components.", "startOffset": 5, "endOffset": 8}, {"referenceID": 18, "context": "Furthermore, since our model and the experimental setup are substantially different from previous other work [20]-[22], a direct comparison between these models to ours cannot be made (as explained in Section 2).", "startOffset": 109, "endOffset": 113}, {"referenceID": 20, "context": "Furthermore, since our model and the experimental setup are substantially different from previous other work [20]-[22], a direct comparison between these models to ours cannot be made (as explained in Section 2).", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "We used a subset of the dataset from [14] in order to establish a word2vec model.", "startOffset": 37, "endOffset": 41}, {"referenceID": 4, "context": "2M sentences that formed a total text length of 217M words for training the word2vec model according to [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 16, "context": "The CF data is based on the latest MovieLens dataset [18] containing 22,884,377 ratings collected during 19952016 from 247,753 users that watched 34,208 movies.", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "This results in 173,266 sets that contain 11,108 unique items (movies) as the effective training data for learning the item2vec model [12].", "startOffset": 134, "endOffset": 138}, {"referenceID": 15, "context": "We used the Adam optimizer [17] with a mini-batch size of 32 and applied an early stopping procedure [19].", "startOffset": 27, "endOffset": 31}, {"referenceID": 17, "context": "We used the Adam optimizer [17] with a mini-batch size of 32 and applied an early stopping procedure [19].", "startOffset": 101, "endOffset": 105}, {"referenceID": 4, "context": "[5], the authors illustrated the ability of their model to automatically organize word representations that capture semantical relations.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "2 in [5]).", "startOffset": 5, "endOffset": 8}, {"referenceID": 12, "context": "Figure 4 depicts a t-SNE [13] embedding of the original (item2vec) CF vectors (a) and the predicted vectors by our \u2018full\u2019 model (b) for a random pick of 900 movies from the top six genres in the test set.", "startOffset": 25, "endOffset": 29}, {"referenceID": 6, "context": "The textual descriptions were processed using a word2vec model followed by a CNN that scans the text in a similar fashion to latest NLP models [7].", "startOffset": 143, "endOffset": 146}], "year": 2016, "abstractText": "In Recommender Systems research, algorithms are often characterized as either Collaborative Filtering (CF) or Content Based (CB). CF algorithms are trained using a dataset of user explicit or implicit preferences while CB algorithms are typically based on item profiles. These approaches harness very different data sources hence the resulting recommended items are generally also very different. This paper presents a novel model that serves as a bridge from items content into their CF representations. We introduce a multiple input deep regression model to predict the CF latent embedding vectors of items based on their textual description and metadata. We showcase the effectiveness of the proposed model by predicting the CF vectors of movies and apps based on their textual descriptions. Finally, we show that the model can be further improved by incorporating metadata such as the movie release year and tags which contribute to a higher accuracy.", "creator": "PScript5.dll Version 5.2.2"}}}