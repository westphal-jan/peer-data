{"id": "1611.01101", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Nov-2016", "title": "CogALex-V Shared Task: ROOT18", "abstract": "in producing this paper, we describe root 18, a classifier using the scores presented of several unsupervised orthogonal distributional measures as features to discriminate between semantically related fields and unrelated words, and then to classify the politically related pairs according to their semantic relation ( i. german e. synonymy, antonymy, hypernymy, part - whole meronymy ). our classifier participated in the cogalex - r v shared task, showing a solid performance on the first subtask, but a poor performance on the second subtask. judging the low scores subsequently reported on the second subtask might suggest statements that distributional measures are not sufficient criteria to discriminate between multiple conflicting semantic relations at once.", "histories": [["v1", "Thu, 3 Nov 2016 17:41:47 GMT  (17kb)", "http://arxiv.org/abs/1611.01101v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["emmanuele chersoni", "giulia rambelli", "enrico santus"], "accepted": false, "id": "1611.01101"}, "pdf": {"name": "1611.01101.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["emmanuelechersoni@gmail.com", "rambelligiulia@gmail.com", "esantus@gmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n61 1.\n01 10\n1v 1\n[ cs\n.C L\n] 3\nN ov\n2 01\n6"}, {"heading": "1 Introduction", "text": "The system described in this paper has been designed for the CogALex-V Shared Task, focusing on the corpus-based identification of semantic relations. Since Distributional Semantic Models (henceforth DSMs) were proposed as a special topic of interest for the current edition of the CogALex workshop, we decided to base our classifier on a number of distributional measures that have been used by past Natural Language Processing (NLP) research to discriminate between a specific semantic relation and other relation types.\nThe task is splitted into the following subtasks:\n\u2022 for each word pair, the participating systems have to decide whether the terms are semantically related or not (TRUE and FALSE are the only possible outcomes);\n\u2022 for each word pair, the participating systems have to decide which semantic relation holds between the terms of the pair. The five possible semantic relations are synonymy (SYN), antonymy (ANT), hypernymy (HYPER), meronymy (PART OF) and no semantic relation at all (RANDOM).\nOur system managed to achieve good results in discriminating between related and random pairs in the first subtask, but unfortunately it struggled in the second one, also due to the high difficulty of the task itself. In particular, the recall for some of the semantic relations of interest seems to be extremely low, suggesting that our unsupervised distributional measures do not provide sufficient information to characterize them, and that it could be probably useful to integrate such scores with other sources of evidence (e.g. information on lexical patterns of word co-occurrence).\nThe paper is organized as follows: in section 2, we summarize related works on the task of semantic relation identification; in section 3, we introduce our system, by describing the classifier and the features. Finally, in section 4 we present and discuss our results."}, {"heading": "2 The Task: Related Work", "text": "Distinguishing between related and unrelated words and, then, discriminating among semantic relations are very important tasks in NLP, and they have a wide range of applications, such as textual entailment, text summarization, sentiment analysis, ontology learning, and so on. For this reason, several systems\nThis work is licenced under a Creative Commons Attribution 4.0 International Licence. Licence details: http://creativecommons.org/licenses/by/4.0/\nover the last few years have been proposed to tackle this problem, using both unsupervised and supervised approaches (see the works of Lenci and Benotto (2012) and Shwartz et al. (2016) on hypernymy; Weeds et al. (2014) and Santus et al. (2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy). However, many of these works focus on a single semantic relation, e.g. antonymy, and describe methods or measures to set it apart from other relations. There have not been many attempts, at the best of our knowledge, to deal with corpus-based semantic relation identification in a multiclass classification task. Few exceptions include the works by Turney (2008) on similarity, antonymy and analogy, and by Pantel and Pernacchiotti (2006) on Espresso, a weakly supervised, pattern-based algorithm. Both these systems are based on patterns, which are known to be more precise than DSMs, even though they suffer from lower recall (i.e. they in fact require words to cooccur in the same sentence). DSMs, on the other hand, offer higher recall at the cost of lower precision: while they are strong in identifying distributionally similar words (i.e. nearest neighbors), they do not offer any principled way to discriminate between semantic relations (i.e. the nearest neighbors of a word are not only its synonyms, but they also include antonyms, hypernyms, and so on).\nThe attempts to provide DSMs with the ability of automatically identifying semantic relations include a large number of unsupervised methods (Weeds and Weir, 2003; Lenci and Benotto, 2012; Santus et al., 2014), which are unfortunately far from achieving the perfect accuracy. In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016). Many of them rely on distributional word vectors, either concatenated or combined through algebraic functions. Others use as features either patterns or scores from the above-mentioned unsupervised methods. While these systems generally obtain high performance in classification tasks involving a single semantic relation, they have rarely been used on multiclass relation classification. On top of it, some scholars have questioned their ability to really learn semantic relations (Levy et al., 2015), claiming that they rather learn some lexical properties from the word vectors they are trained with. This was also confirmed by an experiment carried out by Santus et al. (2016a), showing that up to 100% synthetic switched pairs (i.e. banana-animal; elephantfruit) are misclassified as hypernyms if the system is not provided with some of these negative examples during training.\nRecently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al. (2016)). On top of it, when combined with supervised methods, the low interpretability of their dimensions makes it even harder to understand what the classifiers actually learn (Levy et al., 2015).\nFinally, the recent attempt of Shwartz et al. (2016) of combining patterns and distributional information achieved extremely promising results in hypernymy identification."}, {"heading": "3 System description", "text": "Our system, ROOT18, is a Random Forest classifier (Breiman, 2001) and it is based on the 18 features described in the following subsections. The system in its best setting makes use of the Gini impurity index as the splitting criterion and has 10 as the maximum tree depth. The half of the total number of features were considered for each split."}, {"heading": "3.1 Data", "text": "Our data come from ukWaC (Baroni et al., 2009), a 2 billion tokens corpus of English built by crawling the .uk Internet domain. For the extraction of our features, we generated several distributional spaces, which differ according to the window size and to the statistical association measure that was used to weight raw co-occurrences. Since we obtained the best performances with window size 2 and Positive Pointwise Mutual Information (Church and Hanks, 1990), we report the results only for this setting."}, {"heading": "3.2 Features", "text": "Frequency It is a basic property of words and it is a very discriminative information. In this type of task, it proved to be competitive in identifying the directionality of pairs of hypernyms (Weeds and Weir, 2003), since we expect hypernyms to have higher frequency than hyponyms. For each pair, we computed three features: the frequency of each word (Freq1,2) and their difference (DiffFreq).\nCo-occurrence We compute the co-occurrence frequency (Cooc) between the two terms in each pair. This measure has been claimed to be particularly useful to spot antonyms (Murphy, 2003), since they are expected to occur in the same sentence more often than chance (e.g. Are you friend or foe?).\nEntropy In information theory, this score is related to the informativeness of a message: the lower its entropy, the higher its informativeness (Shannon, 1948). Moreover, subordinate terms tend to have higher amounts of informativeness than superordinate ones. We computed the entropy of each word in the pair (Entr1,2), plus the difference between entropies (DiffEntr).\nCosine similarity It is a standard measure in DSMs to compute similarity between words (Turney and Pantel, 2010). This measure is very useful to discriminate between related and unrelated terms.\nsim(~u,~v) = ~u \u00b7 ~v\n\u2016~u\u2016 \u00b7 \u2016~v\u2016\nLinSimilarity LinSimilarity (Lin, 1998) is a different similarity measure, computed as the ratio of shared context between u and v to the contexts of each word:\nLin(~u,~v) =\n\u2211 c\u2208~u\n\u22c2 ~v[~u[c] + ~v[c]\u2211\nc\u2208~u ~u[c] + \u2211 c\u2208~v ~v[c]\nDirectional similarity measures We extracted several directional similarity measures that were proposed to detect hypernyms, such as WeedsPrec, cosWeeds, ClarkeDe and invCL (for a review, see Lenci and Benotto (2012)). They are all based on the Distributional Inclusion Hypotesis, according to which if a word u is semantically narrower to v, then a significant number of the salient features of u will be included also in v.\nAPSyn This measure and the following APAnt do not rely on the full distribution of words, but on the top N most related contexts of the words according to some statistical association measure. APSyn (Santus et al., 2016b) computes a weighted intersection of the top N context of the target words:\nAPSyn(w1, w2) = \u2211\nf\u2208N(F1) \u22c2 N(F2)\n1\n(rank1(f) + rank2(f))/2\nThat is, for every feature f included in the intersection between the top N features of w1 and w2 (N(F1), N(F2) respectively), the measure adds 1 divided by the average rank of the feature in the rankings of the top N features of w1 and w2.\nAPAnt APAnt (Santus et al., 2014) is defined as the inverse of APSyn. This unsupervised measure tries to discriminate between synonyms and antonyms by relying on the hypothesis that words with similar distribution (i.e. high vector cosine) that do not share their most relevant contexts (i.e. what APSyn computes) are likely to be antonyms. For each pair, we computed APSyn and APAnt for the top 1000 and for the top 100 contexts.\nSame POS We realized that many of the random pairs in the data included words with different parts of speech. Therefore, we decided to add a boolean value to our set of features: 1 if the most frequent POS of the words in the pair were the same, 0 otherwise."}, {"heading": "3.3 Evaluation dataset", "text": "The task organizers provided a training and a test set extracted from EVALution 1.0, a resource that was specifically designed for evaluating systems on the identification of semantic relations (Santus et al., 2015). EVALution 1.0 was derived from WordNet (Fellbaum, 1998) and ConceptNet (Liu and Singh, 2004) and it consists of almost 7500 word pairs, instantiating several semantic relations.\nThe training and the test set included, respectively, 3054 and 4260 word pairs and they are lexical-split, that is, the two sets do not share any pair. Since words were not tagged, we performed POS-tagging with the TreeTagger (Schmid, 1995)."}, {"heading": "4 Results", "text": "As it can be seen from table 1, ROOT18 has a solid performance on the subtask 1, and it is quite accurate in separating related terms from unrelated ones. Generally speaking, we noticed that the classifier performs better when Gini impurity index is used as a splitting criterion instead of entropy. The model with 1000 estimators is our best performing one, with Precision = 0.823, Recall = 0.657 and F-score = 0.731. Concerning the contribution of the features, APSyn1000 and vector cosine have the highest relative importance, with respective contributions of 0.29 and 0.12 to the prediction function. This is not at all surprising, since APSyn and cosine already proved to be strong predictors of semantic similarity.\nResults are much less convincing for subtask 2. In particular, the recall values are extremely low, especially for some of the semantic relations: part of, for example, is often below 0.15. For such relation we have no dedicated features in our system, so the difficulty in identifying meronyms are not a surprise. On the other hand, ROOT18 showed the benefits of the inclusion of several measures targeting hypernymy, since the latter is the most accurately recognized relation (precision often > 0.4), recording also the higher recall (always > 0.3, even in the worst performing models).\nThe performance did not show any particular improvement by increasing the number of the decision trees, so that our best overall results are obtained by the model with 500 estimators (precision = 0.343, recall = 0.218 and F-score = 0.261). As for the contributions of the single features, APSyn1000 (0.19) and cosine (0.09) are still the top ones, followed by cosWeeds (0.07) and APAnt1000 (0.06).\nTable 4 describes the confusion matrix, which shows that randoms are properly working as distractors for the model, leading to a large number of misclassification. Synonyms are often confused with hypernyms and this might be due to the fact that the difference between the two is subtle. These results suggest that measures based on the Distributional Inclusion Hypothesis are not always efficient in discriminating between synonyms and hypernyms.\nAntonyms are confused with hypernyms and vice versa, which might be due to the fact that neither share their most relevant features, obtaining therefore similar APAnt scores (Santus et al., 2015b). Meronyms, finally, are mostly confused with hypernyms, which is almost surely due to the generality spread that characterize both relations and that is captured by both frequency and entropy in our system."}, {"heading": "4.1 Conclusions", "text": "Our results clearly highlight the difficulty of DSMs in discriminating between several semantic relations at once. Such models, in fact, rely on a vague definition of semantic similarity (i.e. distributional similarity) which does not offer any principled way to distinguish among different types of semantic relations.\nNonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Honde\u0300re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al. (2015b) \u2013 this measure has also a bias towards hypernyms, which explains why these are often confused. A possible solution, in our view, would be the integration of DSMs with pattern-based information, in a way that is already being shown by some of the current state-of-the-art systems (see, for example, Shwartz et al. (2016)). Such integration has the advantage of combining the precision of the patterns with the high recall of DSMs.\nFinally, we may assume that also the configuration of the original dataset could contribute to our results, since some pairs in the dataset have ambiguous words and the target relations hold for only one of the their meanings. Disambiguating the pairs, at least by Part-Of-Speech, would certainly help in improving the results. A simple method might consist in computing the vector cosine for the pairs with the target words declined in all possible POS (i.e. VV, NN, JJ) and then maintain in the dataset only the pair with the higher value."}, {"heading": "5 Acknowledgements", "text": "This work has been carried out thanks to the support of the A*MIDEX grant (n ANR-11-IDEX-0001-02) funded by the French Government \u201dInvestissements d\u2019Avenir\u201d program."}], "references": [{"title": "The WaCky wide web: a collection of very large linguistically processed web-crawled corpora", "author": ["Baroni et al.2009] Marco Baroni", "Silvia Bernardini", "Adriano Ferraresi", "Eros Zanchetta"], "venue": "Language resources and evaluation,", "citeRegEx": "Baroni et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2009}, {"title": "Don\u2019t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014] Baroni", "Marco", "Georgiana Dinu", "German Kruszewski"], "venue": "Proceedings of ACL,", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Word association norms, mutual information, and lexicography", "author": ["Church", "Hanks1990] Kenneth Ward Church", "Patrick Hanks"], "venue": "Computational linguistics,", "citeRegEx": "Church et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Church et al\\.", "year": 1990}, {"title": "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn\u2019t Proceedings of SRW@HLT-NAACL", "author": ["Anna Gladkova", "Aleksandr Drozd", "Satoshi Matsuoka"], "venue": null, "citeRegEx": "Gladkova et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gladkova et al\\.", "year": 2016}, {"title": "Deriving Boolean structures from distributional vectors", "author": ["Denis Paperno", "Marco Baroni"], "venue": "TACL,", "citeRegEx": "Kruszewski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kruszewski et al\\.", "year": 2015}, {"title": "Do Supervised Distributional Methods Really Learn Lexical Inference Relations", "author": ["Levy et al.2015] Omer Levy", "Steffen Remus", "Chris Biemann", "Ido Dagan"], "venue": "Proceedings of NAACL HLT", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Improving distributional similarity with lessons learned from word", "author": ["Levy et al.2015] Omer Levy", "Yoav Goldberg", "Ido Dagan"], "venue": "embeddings. TACL,", "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "An information-theoretic definition of similarity", "author": ["Dekang Lin"], "venue": null, "citeRegEx": "Lin.,? \\Q1998\\E", "shortCiteRegEx": "Lin.", "year": 1998}, {"title": "ConceptNet: a practical commonsense reasoning toolkit", "author": ["Liu", "Singh2004] Hugo Liu", "Push Singh"], "venue": "BT technology journal,", "citeRegEx": "Liu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2004}, {"title": "Computing Lexical Contrast", "author": ["Saif M. Mohammad", "Bonnie J. Dorr", "Graeme Hirst", "Peter D. Turney"], "venue": "Computational Linguistics,", "citeRegEx": "Mohammad et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammad et al\\.", "year": 2013}, {"title": "Semantic relations and the lexicon: Antonymy, synonymy and other paradigms", "author": ["Lynne G Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2003\\E", "shortCiteRegEx": "Murphy.", "year": 2003}, {"title": "Integrating Distributional Lexical Contrast into Word Embeddings for Antonym-Synonym Distinction", "author": ["Sabine Schulte im Walde", "Ngoc Thang Vu"], "venue": "Proceedings of ACL", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations", "author": ["Pantel", "Marco Pennacchiotti"], "venue": "Proceedings of COLING ACL:", "citeRegEx": "Pantel et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pantel et al\\.", "year": 2006}, {"title": "Inclusive yet Selective: Supervised Distributional Hypernymy Detection", "author": ["Katrin Erk", "Gemma Boleda"], "venue": "Proceedings of COLING:", "citeRegEx": "Roller et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2014}, {"title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment", "author": ["Roller", "Erk2016] Stephen Roller", "Katrin Erk"], "venue": "Proceedings of EMNLP", "citeRegEx": "Roller et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roller et al\\.", "year": 2016}, {"title": "Taking antonymy mask off in vector space", "author": ["Santus et al.2014] Enrico Santus", "Qin Lu", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of PACLIC", "citeRegEx": "Santus et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2014}, {"title": "EVALution 1.0: an Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models", "author": ["Santus et al.2015] Enrico Santus", "Frances Yung", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of the ACL Workshop on Linked Data in Linguistics:", "citeRegEx": "Santus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2015}, {"title": "Nine Features in a Random Forest to Learn Taxonomical Semantic Relations", "author": ["Alessandro Lenci", "Tin-Shing Chiu", "Qin Lu", "Chu-Ren Huang"], "venue": "Proceedings of LREC", "citeRegEx": "Santus et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "What a Nerd! Beating Students and Vector Cosine in the ESL and TOEFL Datasets", "author": ["Tin-Shing Chiu", "Qin Lu", "Alessandro Lenci", "Chu-Ren Huang"], "venue": "Proceedings of LREC", "citeRegEx": "Santus et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santus et al\\.", "year": 2016}, {"title": "Treetagger: a language independent part-of-speech tagger. Institut f\u00fcr Maschinelle Sprachverarbeitung, Universit\u00e4t Stuttgart", "author": ["Helmut Schmid"], "venue": null, "citeRegEx": "Schmid.,? \\Q1995\\E", "shortCiteRegEx": "Schmid.", "year": 1995}, {"title": "A Mathematical Theory of Communication", "author": ["Claude Shannon"], "venue": "Bell System Technical Journal,", "citeRegEx": "Shannon.,? \\Q1948\\E", "shortCiteRegEx": "Shannon.", "year": 1948}, {"title": "Improving hypernymy detection with an integrated path-based and distributional method", "author": ["Yoav Goldberg", "Ido Dagan"], "venue": "Proceedings of ACL", "citeRegEx": "Shwartz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shwartz et al\\.", "year": 2016}, {"title": "A uniform approach to analogies, synonyms, antonyms, and associations", "author": ["Peter Turney"], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics (Coling", "citeRegEx": "Turney.,? \\Q2008\\E", "shortCiteRegEx": "Turney.", "year": 2008}, {"title": "From frequency to meaning: Vector Space Models for semantics", "author": ["Turney", "Pantel2010] Peter Turney", "Patrick Pantel"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2010}, {"title": "A general framework for distributional similarity", "author": ["Weeds", "Weir2003] Julie Weeds", "David Weir"], "venue": "Proceedings of EMNLP:", "citeRegEx": "Weeds et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Weeds et al\\.", "year": 2003}, {"title": "Learning to Distinguish Hypernyms and Co-Hyponyms", "author": ["Weeds et al.2014] Julie Weeds", "Daoud Clarke", "Jeremy Reffin", "David J Weir", "Bill Keller"], "venue": "Proceedings of COLING:", "citeRegEx": "Weeds et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weeds et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "The attempts to provide DSMs with the ability of automatically identifying semantic relations include a large number of unsupervised methods (Weeds and Weir, 2003; Lenci and Benotto, 2012; Santus et al., 2014), which are unfortunately far from achieving the perfect accuracy.", "startOffset": 141, "endOffset": 209}, {"referenceID": 25, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 13, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 4, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 11, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 21, "context": "In order to achieve higher performance, supervised methods have been recently adopted, also thanks to their ease (Weeds et al., 2014; Roller et al., 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016).", "startOffset": 113, "endOffset": 266}, {"referenceID": 5, "context": "On top of it, some scholars have questioned their ability to really learn semantic relations (Levy et al., 2015), claiming that they rather learn some lexical properties from the word vectors they are trained with.", "startOffset": 93, "endOffset": 112}, {"referenceID": 1, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al.", "startOffset": 170, "endOffset": 191}, {"referenceID": 5, "context": "On top of it, when combined with supervised methods, the low interpretability of their dimensions makes it even harder to understand what the classifiers actually learn (Levy et al., 2015).", "startOffset": 169, "endOffset": 188}, {"referenceID": 7, "context": "over the last few years have been proposed to tackle this problem, using both unsupervised and supervised approaches (see the works of Lenci and Benotto (2012) and Shwartz et al. (2016) on hypernymy; Weeds et al.", "startOffset": 164, "endOffset": 186}, {"referenceID": 7, "context": "over the last few years have been proposed to tackle this problem, using both unsupervised and supervised approaches (see the works of Lenci and Benotto (2012) and Shwartz et al. (2016) on hypernymy; Weeds et al. (2014) and Santus et al.", "startOffset": 164, "endOffset": 220}, {"referenceID": 5, "context": "(2014) and Santus et al. (2016a) on hypernymy and co-hyponymy; Mohammad et al.", "startOffset": 11, "endOffset": 33}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al.", "startOffset": 38, "endOffset": 61}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy).", "startOffset": 38, "endOffset": 86}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy). However, many of these works focus on a single semantic relation, e.g. antonymy, and describe methods or measures to set it apart from other relations. There have not been many attempts, at the best of our knowledge, to deal with corpus-based semantic relation identification in a multiclass classification task. Few exceptions include the works by Turney (2008) on similarity, antonymy and analogy, and by Pantel and Pernacchiotti (2006) on Espresso, a weakly supervised, pattern-based algorithm.", "startOffset": 38, "endOffset": 463}, {"referenceID": 3, "context": "(2016a) on hypernymy and co-hyponymy; Mohammad et al. (2013) and Santus et al. (2014) on antonymy). However, many of these works focus on a single semantic relation, e.g. antonymy, and describe methods or measures to set it apart from other relations. There have not been many attempts, at the best of our knowledge, to deal with corpus-based semantic relation identification in a multiclass classification task. Few exceptions include the works by Turney (2008) on similarity, antonymy and analogy, and by Pantel and Pernacchiotti (2006) on Espresso, a weakly supervised, pattern-based algorithm.", "startOffset": 38, "endOffset": 539}, {"referenceID": 1, "context": ", 2014; Kruszewski et al., 2015; Roller and Erk, 2016; Santus et al., 2016a; Nguyen et al., 2016; Shwartz et al., 2016). Many of them rely on distributional word vectors, either concatenated or combined through algebraic functions. Others use as features either patterns or scores from the above-mentioned unsupervised methods. While these systems generally obtain high performance in classification tasks involving a single semantic relation, they have rarely been used on multiclass relation classification. On top of it, some scholars have questioned their ability to really learn semantic relations (Levy et al., 2015), claiming that they rather learn some lexical properties from the word vectors they are trained with. This was also confirmed by an experiment carried out by Santus et al. (2016a), showing that up to 100% synthetic switched pairs (i.", "startOffset": 8, "endOffset": 803}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al.", "startOffset": 171, "endOffset": 224}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al. (2016)).", "startOffset": 171, "endOffset": 442}, {"referenceID": 0, "context": "Recently, count based vectors have been substituted by prediction-based ones, which seem to slightly improve the performance in some tasks, such as similarity estimation (Baroni et al., 2014), even though Levy et al. (2015) demonstrated that these improvements were most likely due to the optimization of hyperparameters that were instead left unoptimized in count-based models (for an overview on word embeddings, see Gladkova et al. (2016)). On top of it, when combined with supervised methods, the low interpretability of their dimensions makes it even harder to understand what the classifiers actually learn (Levy et al., 2015). Finally, the recent attempt of Shwartz et al. (2016) of combining patterns and distributional information achieved extremely promising results in hypernymy identification.", "startOffset": 171, "endOffset": 687}, {"referenceID": 0, "context": "1 Data Our data come from ukWaC (Baroni et al., 2009), a 2 billion tokens corpus of English built by crawling the .", "startOffset": 32, "endOffset": 53}, {"referenceID": 10, "context": "This measure has been claimed to be particularly useful to spot antonyms (Murphy, 2003), since they are expected to occur in the same sentence more often than chance (e.", "startOffset": 73, "endOffset": 87}, {"referenceID": 20, "context": "Entropy In information theory, this score is related to the informativeness of a message: the lower its entropy, the higher its informativeness (Shannon, 1948).", "startOffset": 144, "endOffset": 159}, {"referenceID": 7, "context": "LinSimilarity LinSimilarity (Lin, 1998) is a different similarity measure, computed as the ratio of shared context between u and v to the contexts of each word:", "startOffset": 28, "endOffset": 39}, {"referenceID": 15, "context": "APAnt APAnt (Santus et al., 2014) is defined as the inverse of APSyn.", "startOffset": 12, "endOffset": 33}, {"referenceID": 16, "context": "0, a resource that was specifically designed for evaluating systems on the identification of semantic relations (Santus et al., 2015).", "startOffset": 112, "endOffset": 133}, {"referenceID": 19, "context": "Since words were not tagged, we performed POS-tagging with the TreeTagger (Schmid, 1995).", "startOffset": 74, "endOffset": 88}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al.", "startOffset": 129, "endOffset": 479}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al. (2015b) \u2013 this measure has also a bias towards hypernyms, which explains why these are often confused.", "startOffset": 129, "endOffset": 593}, {"referenceID": 15, "context": "Nonetheless, it is still feasible for traditional DSMs to achieve good performances on the recognition of taxonomical relations (Santus et al., 2016a), for which metrics can be defined on the basis of feature inclusion, of context informativeness etc. For other relations, such as antonymy and meronymy, it is not easy to define measures based on distributional similarity (for the latter relation, it is difficult even to find an univocal definition: see Morlane-Hond\u00e8re (2015)): APAnt works relatively well in discriminating antonyms from synonyms, but \u2013 as noticed by Santus et al. (2015b) \u2013 this measure has also a bias towards hypernyms, which explains why these are often confused. A possible solution, in our view, would be the integration of DSMs with pattern-based information, in a way that is already being shown by some of the current state-of-the-art systems (see, for example, Shwartz et al. (2016)).", "startOffset": 129, "endOffset": 913}], "year": 2016, "abstractText": "In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised distributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy). Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the second subtask. The low scores reported on the second subtask suggest that distributional measures are not sufficient to discriminate between multiple semantic relations at once.", "creator": "LaTeX with hyperref package"}}}