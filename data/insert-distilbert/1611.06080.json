{"id": "1611.06080", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Nov-2016", "title": "A Generalized Stochastic Variational Bayesian Hyperparameter Learning Framework for Sparse Spectrum Gaussian Process Regression", "abstract": "while much research effort has been dedicated to scaling up sparse gaussian process ( ld gp ) models based on inducing variables for big data, little attention is directly afforded to the other less explored class of low - rank gp map approximations that exploit the sparse graphical spectral representation of a gp kernel. thus this paper presents such an ample effort to advance the state formulation of the joint art of sparse spectrum gp models to achieve competitive predictive performance decisions for massive datasets. our expanding generalized framework of stochastic variational bayesian sparse scaled spectrum gp ( svbssgp ) models better addresses their shortcomings by adopting a bayesian treatment ensemble of the spectral frequencies to simultaneously avoid overfitting, modeling these frequencies conserved jointly in its variational distribution to enable predicting their respective interaction a posteriori, and exploiting local data populations for boosting the predictive performance. however, such structural improvements result in a variational lower bound that is intractable to be optimized. to resolve this, we exploit a variational parameterization trick to properly make inference it amenable related to stochastic optimization. interestingly, the resulting stochastic gradient regression has a defined linearly decomposable scaling structure that can be exploited to refine whether our stochastic optimization method to incur constant time per iteration while separately preserving its property of essentially being an unbiased estimator of the exact gradient of the variational lower bound. empirical evaluation paper on real - world datasets usually shows that svbssgp outperforms state - of - the - art stochastic implementations of sparse gp models.", "histories": [["v1", "Fri, 18 Nov 2016 14:00:48 GMT  (111kb,D)", "http://arxiv.org/abs/1611.06080v1", "31st AAAI Conference on Artificial Intelligence (AAAI 2017), Extended version with proofs, 11 pages"]], "COMMENTS": "31st AAAI Conference on Artificial Intelligence (AAAI 2017), Extended version with proofs, 11 pages", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["quang minh hoang", "trong nghia hoang", "kian hsiang low"], "accepted": true, "id": "1611.06080"}, "pdf": {"name": "1611.06080.pdf", "metadata": {"source": "META", "title": "A Generalized Stochastic Variational Bayesian Hyperparameter Learning Framework for Sparse Spectrum Gaussian Process Regression", "authors": ["Quang Minh Hoang", "Trong Nghia Hoang", "Kian Hsiang Low"], "emails": ["lowkh}@comp.nus.edu.sg,", "nghiaht@nus.edu.sg"], "sections": [{"heading": "1 Introduction", "text": "The machine learning community has recently witnessed the Gaussian process (GP) models gaining considerable traction in the research on kernel methods due to its expressive power and capability of performing probabilistic non-linear regression. However, a full-rank GP regression model incurs cubic time in the size of the data to compute its predictive distribution, hence limiting its use to small datasets. To lift this computational curse, a vast literature of sparse GP regression models (Quin\u0303onero-Candela and Rasmussen 2005; Titsias 2009) have exploited a structural assumption of conditional independence based on the notion of inducing variables for achieving linear time in the data size. To scale up these sparse GP regression models further for performing real-time predictions necessary in many time-critical applications and decision support systems (e.g., environmental sensing (Cao, Low, and Dolan 2013; Dolan et al. 2009;\nCopyright c\u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nLing, Low, and Jaillet 2016; Low, Dolan, and Khosla 2008; 2009; 2011; Low et al. 2012; Podnar et al. 2010; Zhang et al. 2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al. 2013; Hoang, Hoang, and Low 2016; Low et al. 2015) and (b) stochastic (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015) implementations of such models have been developed to, respectively, (a) reduce their time to train with all the data by a factor close to the number of machines and (b) train with a small, randomly sampled subset of data in constant time per iteration of stochastic gradient ascent update and achieve asymptotic convergence to their predictive distributions.\nOn the other hand, there is a less well-explored, alternative class of low-rank GP approximations that exploit sparsity in the spectral representation of a GP kernel (Gal and Turner 2015; La\u0301zaro-Gredilla et al. 2010) for gaining time efficiency and have empirically demonstrated competitive predictive performance for datasets of up to tens of thousands in size but, surprisingly, not received as much attention and research effort. In contrast to the above literature, such sparse spectrum GP regression models do not need to introduce an additional set of inducing inputs which is computationally challenging to be jointly optimized, especially with a large number of them that is necessary for accurate predictions. Unfortunately, the sparse spectrum GP (SSGP) model of La\u0301zaro-Gredilla et al. (2010) does not scale well to massive datasets due to its linear time in the data size and also finds a point estimate of the spectral frequencies of its kernel that risks overfitting. The recent variational SSGP (VSSGP) model of Gal and Turner (2015) has attempted to address both shortcomings of SSGP with a stochastic implementation and a Bayesian treatment of the spectral frequencies, respectively. However, VSSGP has imposed the following highly restrictive structural assumptions to facilitate analytical derivations but potentially compromise its predictive performance: (a) The spectral frequencies are assumed to be fully independent a posteriori in its variational distribution, and (b) every test output assumes a deterministic relationship with the spectral frequencies in its test conditional and is thus conditionally independent of the training data, including the local data \u201cclose\u201d to it (in the correlaar X iv :1 61 1. 06 08 0v 1\n[ st\nat .M\nL ]\n1 8\nN ov\n2 01\ntion sense). As such, open questions remain whether VSSGP can still perform competitively well with these highly restrictive structural assumptions for massive, million-sized datasets and, more importantly, whether these assumptions can be relaxed to improve the predictive performance while preserving scalability to big data.\nTo tackle these questions, this paper presents a novel generalized framework of stochastic variational Bayesian sparse spectrum GP (sVBSSGP) regression models which (a) enables the spectral frequencies to interact a posteriori by modeling them jointly in its variational distribution, and (b) spans a spectrum of test conditionals that can trade off between the contributions of the degenerate test conditional of VSSGP vs. the local SSGP model trained with local data (Section 2). However, such proposed structural improvements over VSSGP and SSGP to boost the predictive performance result in a variational lower bound that is intractable to be optimized. To overcome this computational difficulty, we exploit a variational parameterization trick to make the variational lower bound amenable to stochastic optimization, which still incurs linear time in the data size per iteration of stochastic gradient ascent update (Section 3). Interestingly, we can exploit the linearly decomposable structure of this stochastic gradient to refine our stochastic optimization method to incur only constant time per iteration while preserving its property of being an unbiased estimator of the exact gradient of the variational lower bound (Section 4). We empirically evaluate the predictive performance and time efficiency of sVBSSGP on three real-world datasets, one of which is millions in size (Section 5)."}, {"heading": "2 A Generalized Bayesian Sparse Spectrum Gaussian Process Regression Framework", "text": "Let X be a d-dimensional input space such that each input vector x \u2208 X is associated with a latent output fx and a noisy output yx , fx + generated by perturbing fx with a random noise \u223c N (0, \u03c32n) where \u03c32n is the noise variance. Let {fx}x\u2208X denote a Gaussian process (GP), that is, every finite subset of {fx}x\u2208X follows a multivariate Gaussian distribution. Then, the GP is fully specified by its prior mean E[fx] (i.e., assumed to be 0 for notational simplicity) and covariance k(x,x\u2032) , cov[fx, fx\u2032 ] for all x,x\u2032 \u2208 X , the latter of which can be defined by the commonly-used squared exponential kernel k(x,x\u2032) , \u03c32sexp(\u22120.5(x \u2212 x\u2032)>\u2206\u22121(x \u2212 x\u2032)) where \u2206 , diag[`21, `22, . . . , `2d] and \u03c32s are its squared length-scale and signal variance hyperparameters, respectively. Such a kernel can be expressed as the Fourier transform of a density function p(r) over the domain of frequency vector r whose coefficients form a set of trigonometric basis functions (La\u0301zaro-Gredilla et al. 2010): k(x,x\u2032) = Er\u223cp(r)[ \u03c32scos(2\u03c0r>(x\u2212 x\u2032)) ] (1) where p(r) , N ( 0, (4\u03c02\u2206)\u22121 ) . In the same spirit as that of La\u0301zaro-Gredilla et al. (2010), we approximate the kernel in (1) by its unbiased estimator constructed from m i.i.d. sampled spectral frequencies ri for i = 1, . . . ,m: k(x,x\u2032)' \u03c3 2 s\nm m\u2211 i=1 cos(2\u03c0r>i (x\u2212x\u2032))=\u03c6>\u03b8 (x)\u039b\u03c6\u03b8(x\u2032) (2)\nwhere \u03c6\u03b8(x) , [\u03c61\u03b8(x), \u03c6 2 \u03b8(x), . . . , \u03c6 2m \u03b8 (x)] > denotes a vector of basis functions \u03c62i\u22121\u03b8 (x) , cos(2\u03c0r > i x) and \u03c62i\u03b8 (x) , sin(2\u03c0r > i x) for i = 1, . . . ,m, \u039b , (\u03c3 2 s/m)I, and \u03b8 , vec(r1, r2, . . . , rm). Learning the length-scales in \u2206 of the original kernel is thus cast as optimizing \u03b8 in this alternative representation (2) of the kernel. Then, the induced covariance matrix K(X,X) for any finite subset X , {xi}ni=1 of training inputs can be written as K(X,X) , \u03a6>\u03b8 (X)\u039b\u03a6\u03b8(X) where \u03a6\u03b8(X) , [\u03c6\u03b8(x1) . . .\u03c6\u03b8(xn)].\nTo learn the optimal parameters of the distribution over \u03b8 (i.e., not known in advance) given by N (0, (4\u03c02\u2206\u03b8)\u22121) (i.e., derived from p(r) below (1)) where \u2206\u03b8 , I \u2297\u2206, we adopt the standard Bayesian treatment for \u03b8 by first imposing a prior distribution \u03b8 \u223c N (0,\u0398) for some covariance \u0398 designed a priori to reflect our knowledge about \u03b8 and then using training data to infer its posterior which is expected to closely approximate the optimal distribution. This signifies a key difference between our generalized framework and the sparse spectrum GP (SSGP) model of La\u0301zaro-Gredilla et al. (2010), the latter of which finds a point estimate of \u03b8 via maximum likelihood estimation that risks overfitting.\nAs shall be elucidated later in this paper, the finite trigonometric representation of the kernel (2) can be used to efficiently and scalably compute the predictive distribution of our framework by exploiting some mild structural assumptions. Specifically, we assume that for any finite subset X \u2282 X , a vector s of nuisance variables exists for which the joint distribution of f , [fx]>x\u2208X and s conditioned on \u03b8 is[ s f ] \u223c N ([ 0 0 ] , [ \u039b \u039b\u03a6\u03b8(X)\n\u03a6>\u03b8 (X)\u039b \u03a6 > \u03b8 (X)\u039b\u03a6\u03b8(X)\n]) . (3)\nIntuitively, s can be interpreted as the latent outputs of some imaginary inputs U , {uj}2mj=1 such that \u03c6i\u03b8(uj) , I(i = j). Using (2), it follows immediately that K(U,U) = \u039b, K(U,X) = \u039b\u03a6\u03b8(X), and K(X,U) = \u03a6>\u03b8 (X)\u039b which reproduce the covariance matrix in (3). Secondly, we assume that given \u03b1 , vec(\u03b8, s), any latent test output depends on only a small subset of local training data of fixed size: Supposing the input space is partitioned into p disjoint subspaces (i.e., X = \u22c3p i=1 Xi) which directly induce a partition\non the training inputs X = \u22c3p i=1 Xi such that Xi \u2282 Xi, p(fx\u2217 |y,\u03b1) = p(fx\u2217 |yk,\u03b1) for any test input x\u2217 \u2208 Xk and k = 1, . . . , p where y , [yx]>x\u2208X and yk , [yx] > x\u2208Xk . Then, the predictive distribution can be computed using p(fx\u2217 |y) = E\u03b1\u223cp(\u03b1|y)[ p(fx\u2217 |yk,\u03b1) ] (4) which reveals that it can be evaluated by deriving posterior distribution p(\u03b1|y) described later in Section 3, and the test conditional p(fx\u2217 |yk,\u03b1) consistent with the above structural assumption of s: Marginalizing out nuisance variables s from such a test conditional should yield p(fx\u2217 |yk,\u03b8), i.e., p(fx\u2217 |yk,\u03b8) = \u222b s p(fx\u2217 |yk,\u03b1) p(s|yk,\u03b8) ds where both p(fx\u2217 |yk,\u03b8) and p(s|yk,\u03b8) can be derived from (3), as shown in Appendix A.\nOur first result below derives a spectrum of consistent test conditionals in our generalized framework that trade off between the use of global information \u03b1 vs. local data (Xk,yk), albeit to varying degrees controlled by \u03b3:\nProposition 1 For all x\u2217 \u2208 Xk and |\u03b3| \u2264 1, define the test conditional p(fx\u2217 |yk,\u03b1) , N (\u00b5x\u2217(\u03b1), \u03c32x\u2217(\u03b1)) where\n\u00b5x\u2217(\u03b1) , \u03b3\u03c6 > \u03b8 (x\u2217)s + (1\u2212 \u03b3)\u03c6>\u03b8 (x\u2217)\u0393\u22121k \u03a6\u03b8(Xk)yk , \u03c32x\u2217(\u03b1) , (1\u2212 \u03b3 2)\u03c32n\u03c6 > \u03b8 (x\u2217)\u0393 \u22121 k \u03c6\u03b8(x\u2217) ,\nand \u0393k , \u03a6\u03b8(Xk)\u03a6>\u03b8 (Xk) + \u03c3 2 n\u039b \u22121. Then, p(fx\u2217 |yk,\u03b1) is consistent with the structural assumption of s in (3). Its proof is in Appendix A. Remark 1 The special case of \u03b3 = 1 recovers the degenerate test conditional p(fx\u2217 |\u03b1) = N (\u03c6>\u03b8 (x\u2217)s, 0) induced by the variational SSGP (VSSGP) model of Gal and Turner (2015) (see equation 4 and Section 3 therein) which reveals that it imposes a highly restrictive deterministic relationship between fx\u2217 and \u03b1 and also fails to exploit the local data (Xk,yk) (i.e., due to conditional independence between fx\u2217 and yk given \u03b1) that can potentially improve the predictive performance. Unfortunately, VSSGP cannot be trivially extended to span the entire spectrum since it relies on the induced deterministic relationship between fx\u2217 and\u03b1 to analytically derive its predictive distribution, which does not hold for \u03b3 6= 1. On the other hand, when \u03b3 = 0, the test conditional in Proposition 1 becomes independent of the nuisance variables s and reduces to the predictive distribution p(fx\u2217 |yk,\u03b8) of the SSGP model of La\u0301zaro-Gredilla et al. (2010) (see equation 7 therein) given its point estimate of the spectral frequencies \u03b8 but restricted to the local data (Xk,yk) corresponding to input subspaceXk. Hence, \u03b3 can also be perceived as a controlling parameter that trades off between the contributions of the degenerate test conditional of VSSGP vs. the local SSGP model to constructing a test conditional in our generalized framework. To investigate this trade-off, our experiments in Section 5 show that given the learned \u03b8, the predictive performance is maximized at \u03b3 = 0 when the test conditional p(fx\u2217 |yk,\u03b1) depends on local data (Xk,yk) but not s, which justifies viewing s as a \u201cnuisance\u201d to prediction despite its crucial role in scalable learning of \u03b8 via stochastic optimization (Section 4).\nIn the sections to follow, we will propose a novel stochastic optimization method for deriving a variationally optimal approximation to the posterior distribution p(\u03b1|y) that is used to marginalize out the global information \u03b1 from any test conditional p(fx\u2217 |yk,\u03b1) in Proposition 1 to yield an asymptotic approximation to the predictive distribution p(fx\u2217 |y) (4) regardless of the value of \u03b3 \u2208 [\u22121, 1]."}, {"heading": "3 Variational Inference for Bayesian Sparse Spectrum Gaussian Process Regression", "text": "This section presents a variational approximation q(\u03b1) of the posterior distribution p(\u03b1|y) achieved by using variational inference which involves choosing a parameterization for q(\u03b1) (Section 3.1) and optimizing its defining parameters (Section 3.2) to minimize its Kullback-Leibler (KL) distance DKL(q) , KL(q(\u03b1)\u2016p(\u03b1|y)) to p(\u03b1|y). The optimized q(\u03b1) can then be used as a tractably cheap surrogate of p(\u03b1|y) for marginalizing out\u03b1 from test conditional p(fx\u2217 |yk,\u03b1) in Proposition 1 to derive an approximation to predictive distribution p(fx\u2217 |y) (4) efficiently (Section 4)."}, {"heading": "3.1 Variational Parameterization", "text": "Specifically, we parameterize \u03b1 = vec(\u03b8, s) , Mz + b where the variational parameters \u03b7 , vec(M,b) are independent of (\u03b8, s), and z is distributed by an analytically tractable user-specified distribution \u03c8(z) ' p(z|y) that is straightforward to draw samples from (i.e., z \u223c \u03c8(z)). We assume that \u03c8(z) is analytically differentiable with respect to z and the affine matrix M is invertible such that z = M\u22121(\u03b1\u2212 b) exists. Then, q(\u03b8, s) can be expressed in terms of M, b, and \u03c8(z): Lemma 1 The variational distribution q(\u03b8, s) can be indirectly parameterized via \u03c8(z) by q(\u03b8, s) = q(\u03b1) = \u03c8(M\u22121(\u03b1\u2212 b))/|M| = \u03c8(z)/|M| where |M| denotes the absolute value of det(M). Lemma 1 follows directly from the change of variables theorem. Using the above parameterization of\u03b1, we can also express the prior p(\u03b8, s) in terms of variational parameters M and b. To see this, recall that p(\u03b8) = N (0,\u0398) and p(s) = N (0,\u039b) (see Section 2 and (3)). This implies p(\u03b1) = p(vec(\u03b8, s)) = p(\u03b8) p(s) = N (\u03b1|0,blkdiag[\u0398,\u039b]). Plugging in the expression of \u03b1 yields p(\u03b1) = N (Mz + b|0,blkdiag[\u0398,\u039b])1. At this time, the need to parameterize q(\u03b1) in Lemma 1 may not be obvious to a reader because it is motivated by a technical necessity to guarantee the asymptotic convergence of our stochastic optimization method (Remark 4) rather than a conceptual intuition. Remark 2 Our generalized framework enables both the spectral frequencies \u03b8 and the nuisance variables s to interact a posteriori by modeling them jointly in the variational distribution q(\u03b8, s), as detailed in Lemma 1, and still preserves scalability (Section 4). In contrast, the VSSGP model of Gal and Turner (2015) assumes r1, . . . , rm, and s to be statistically independent a posteriori in its variational distribution (see section 4 therein). Relaxing this assumption will cause VSSGP to lose its scalability as its induced variational lower bound will inevitably become intractable. Remark 3 Though the model of Titsias and La\u0301zaroGredilla (2014) has adopted a similar parameterization but only for the original GP hyperparameters, it incurs cubic time in the data size per iteration of gradient ascent update, as shown in its supplementary materials and experiments. A factorized marginal likelihood has to be further assumed for this parameterization to achieve scalability. Our framework does not require such a strong assumption and still scales well to million-sized datasets (Section 5). This is, perhaps surprisingly, achieved through introducing the nuisance variables s (Section 2), which interestingly embeds a linearly decomposable structure within the log-likelihood of data log p(y|\u03b1) instead of log p(y|\u03b8). As shown later in Theorem 1, such a structure is the key ingredient for developing our stochastic optimization method (Section 4)."}, {"heading": "3.2 Variational Optimization", "text": "To optimize q(\u03b1) (i.e., by minimizing DKL(q)), we first show that the log-marginal likelihood log p(y) can be de-\n1Note that \u03c8(z) is meant to approximate the posterior distribution of z given y instead of its prior distribution. So, it cannot be used to derive p(\u03b1) by applying the affine transformation on z.\ncomposed into a sum of a lower-bound functional L(q) and DKL(q): log p(y) = L(q) + DKL(q) where L(q) , E\u03b1\u223cq(\u03b1)[log p(y|\u03b1)\u2212 log(q(\u03b1)/p(\u03b1))], as detailed in Appendix B. So, minimizing DKL(q) is equivalent to maximizing L(q) with respect to the variational parameter \u03b7 = vec(M,b) of q(\u03b1) (Lemma 1) since log p(y) is a constant (i.e., independent of \u03b7). In practice, this is usually achieved by setting the derivative \u2202L/\u2202\u03b7 = 0 and solving for \u03b7, which is unfortunately intractable since its exact analytic expression is not known.\nTo sidestep this intractability issue, we instead adopt a stochastic optimization method that is capable of maximizing L(q) via iterative stochastic gradient ascent updates. However, this also requires the stochastic gradient \u2202L\u0302/\u2202\u03b7 (6) to be an analytically tractable and unbiased estimator of the exact gradient \u2202L/\u2202\u03b7. To derive this, we first exploit Lemma 1 to re-express L(q) as an expectation with respect to z \u223c \u03c8(z): L(q) = Ez\u223c\u03c8(z)[log p(y|\u03b1) \u2212 log(q(\u03b1)/p(\u03b1))] where \u03b1 = Mz + b, as shown in Appendix C. Then, taking the derivatives with respect to \u03b7 on both sides of the above equation yields \u2202L/\u2202\u03b7 = Ez\u223c\u03c8(z)[ \u2202(log p(y|\u03b1)\u2212 log(q(\u03b1)/p(\u03b1)))/\u2202\u03b7 ] (5) which reveals a simple, analytically tractable (proven in Appendix D using Lemma 1) choice for our stochastic gradient\n\u2202L\u0302/\u2202\u03b7 , \u2202(log p(y|\u03b1)\u2212 log(q(\u03b1)/p(\u03b1)))/\u2202\u03b7 . (6) Thus, Ez\u223c\u03c8(z)[\u2202L\u0302/\u2202\u03b7] = \u2202L/\u2202\u03b7 guarantees that \u2202L\u0302/\u2202\u03b7 is indeed an unbiased estimator of \u2202L/\u2202\u03b7. Remark 4 (5) reveals that parameterizing q(\u03b1) indirectly through \u03c8(z) in Lemma 1 is essential to enabling stochastic optimization in our generalized framework: Since \u03c8(z) does not depend on the variational parameters \u03b7 = vec(M,b), the derivative operator in (5) can be moved inside the expectation, which trivially reveals an unbiased stochastic estimate (6) of the exact gradient via sampling z. Otherwise, suppose that we attempt to derive a stochastic gradient for L(q) using the original expression L(q) = E\u03b1\u223cq(\u03b1)[log p(y|\u03b1)\u2212log(q(\u03b1)/p(\u03b1))] instead of (5) in the same manner with a direct parameterization of q(\u03b1) not exploiting \u03c8(z). Then, after differentiating both sides of the above expression with respect to \u03b7, the derivative operator on the RHS cannot be moved inside the expectation over \u03b1 \u223c q(\u03b1) since it depends on \u03b7, which suggests that deriving an unbiased estimator for \u2202L/\u2202\u03b7 has become non-trivial without using the parameterization of q(\u03b1) in Lemma 1.\nTo understand why \u2202L\u0302/\u2202\u03b7 (6) is analytically tractable, it suffices to show that both its derivatives \u2202 log p(y|\u03b1)/\u2202\u03b7 and \u2202 log(q(\u03b1)/p(\u03b1))/\u2202\u03b7 in (6) are analytically tractable, the latter of which is detailed in Appendix D. For the former, since the trigonometric basis functions {\u03c6i\u03b8(x)}2mi=1 (Section 2) are differentiable, it can be shown that \u2202 log p(y|\u03b1)/\u2202\u03b7 is analytically tractable by exploiting the following result giving a closed-form expression of log p(y|\u03b1) in terms of \u03b8 and s: Lemma 2 log p(y|\u03b1) = \u22120.5\u03c3\u22122n v>v \u2212 0.5n log(2\u03c0\u03c32n) where v , y \u2212\u03a6>\u03b8 (X)s.\nIts proof is in Appendix E. The above choice of \u2202L\u0302/\u2202\u03b7 (6) and Lemma 2 show that it is not only an unbiased estimator of the exact gradient but is also analytically tractable, which satisfies all the required conditions to guarantee the asymptotic convergence of our proposed stochastic optimization method. However, a critical issue remains that makes it scale poorly in practice: It can be derived from Lemma 2 that naively evaluating its derivative \u2202 log p(y|\u03b1)/\u2202\u03b7 in (6) in a straightforward manner incurs linear time in data size n per iteration of stochastic gradient ascent update, which is expensive for massive datasets."}, {"heading": "4 Stochastic Optimization", "text": "To overcome the issue of scalability in evaluating the stochastic gradient \u2202L\u0302/\u2202\u03b7 (6) (Section 3.2), we will show in Theorem 1 below that \u2202 log p(y|\u03b1)/\u2202\u03b7 is decomposable into a linear sum of analytically tractable terms, each of which depends on only a small subset of local data. Interestingly, since only the derivative \u2202 log p(y|\u03b1)/\u2202\u03b7 in (6) involves the training data (X,y), Theorem 1 implies a similar decomposition of \u2202L\u0302/\u2202\u03b7. As a result, we can derive a new stochastic estimate of the exact gradient \u2202L/\u2202\u03b7 that can be computed efficiently and scalably using only one or a few randomly sampled subset(s) of local data of fixed size and still preserves the property of being its unbiased estimator (Section 4.1). Computing this new stochastic gradient incurs only constant time in the data size n per iteration of stochastic gradient ascent update, which, together with Proposition 1 in Section 2, constitute the foundation of our generalized framework of stochastic variational Bayesian SSGP regression models for big data (Section 4.2)."}, {"heading": "4.1 Stochastic Gradient Revisited", "text": "To derive a computationally scalable and unbiased stochastic gradient, we rely on our main result below showing the decomposability of \u2202 log p(y|\u03b1)/\u2202\u03b7 in (6) into a linear sum of analytically tractable terms, each of which depends on only a small subset of local training data of fixed size:\nTheorem 1 Let vi , yi\u2212\u03a6>\u03b8 (Xi)s for i = 1, . . . , p. Then, \u2202 log p(y|\u03b1)/\u2202\u03b7 = \u2211p i=1 Fi(\u03b7,\u03b1) where Fi(\u03b7,\u03b1) , \u22120.5\u03c3\u22122n \u2207\u03b7(v>i vi) is analytically tractable. Its proof in Appendix F utilizes Lemma 2. Using Theorem 1 , the following linearly decomposable structure of \u2202L\u0302/\u2202\u03b7 (6) results:\n\u2202L\u0302/\u2202\u03b7 = Ei\u223cU(1,p)[ pFi(\u03b7,\u03b1)\u2212 \u2202 log(q(\u03b1)/p(\u03b1))/\u2202\u03b7 ] (7) where i is treated as a discrete random variable uniformly distributed over the set of partition indices {1, 2, . . . , p}. This interestingly reveals an unbiased estimator for the stochastic gradient \u2202L\u0302/\u2202\u03b7 which can be constructed stochastically by sampling i:\n\u2202L\u0303/\u2202\u03b7 , pFi(\u03b7,\u03b1)\u2212 \u2202 log(q(\u03b1)/p(\u03b1))/\u2202\u03b7\nsuch that substituting it into (7) yields Ei\u223cU(1,p)[\u2202L\u0303/\u2202\u03b7] = \u2202L\u0302/\u2202\u03b7. Then, taking the expectation over z \u223c \u03c8(z) on both sides of this equality gives Ez\u223c\u03c8(z)[Ei\u223cU(1,p)[\u2202L\u0303/\u2202\u03b7]] =\nEz\u223c\u03c8(z)[\u2202L\u0302/\u2202\u03b7] = \u2202L/\u2202\u03b7, which proves that \u2202L\u0303/\u2202\u03b7 is also an unbiased estimator of \u2202L/\u2202\u03b7 that can be constructed by sampling both i \u223c U(1, p) and z \u223c \u03c8(z) (Section 3.1) independently. Replacing \u2202L\u0302/\u2202\u03b7 with \u2202L\u0303/\u2202\u03b7 produces a highly efficient stochastic gradient ascent update that incurs constant time in the data size n per iteration since \u2202L\u0303/\u2202\u03b7 can be computed using only a single randomly sampled subset of local data (Xi,yi) of fixed size.\nInstead of utilizing just a single pair (i, z) of samples, the above stochastic gradient \u2202L\u0303/\u2202\u03b7 can be generalized to simultaneously process multiple pairs of independent samples and their corresponding sampled subsets of local data in one stochastic gradient ascent update (detailed in Appendix G), thereby improving the rate of convergence while preserving its property of an unbiased estimator of the exact gradient \u2202L/\u2202\u03b7. Asymptotic convergence of the estimate of \u03b7 (and hence the estimate of q(\u03b1)) is guaranteed if the step sizes are scheduled appropriately."}, {"heading": "4.2 Approximate Predictive Inference", "text": "In iteration t of stochastic gradient ascent update, an estimate qt(\u03b1) of the variationally optimal approximation q(\u03b1) can be induced from the current estimate \u03b7t = vec(Mt,bt) of its variational parameters \u03b7 using the parameterization in Lemma 1. As a result, using the law of iterated expectations, the predictive mean can be approximated by \u00b5\u0302x\u2217 = E\u03b1\u223cqt(\u03b1)[E[fx\u2217 |yk,\u03b1]] = E\u03b1\u223cqt(\u03b1)[\u00b5x\u2217(\u03b1)] =\u222b \u03b1 qt(\u03b1)\u00b5x\u2217(\u03b1)d\u03b1 where \u03b1 = vec(\u03b8, s) and \u00b5x\u2217(\u03b1) is previously defined in Proposition 1. However, since the integration over \u03b1 is not always analytically tractable, we approximate it by drawing i.i.d. samples \u03b11, . . . ,\u03b1r from qt(\u03b1) to estimate \u00b5\u0302x\u2217 ' r\u22121 \u2211r i=1 \u00b5x\u2217(\u03b1i). Similarly, using the variance decomposition formula and definition of variance, the predictive variance can be approximated by \u03c3\u03022x\u2217 = E\u03b1\u223cqt(\u03b1)[\u03c3 2 x\u2217(\u03b1)] + V\u03b1\u223cqt(\u03b1)[\u00b5x\u2217(\u03b1)] = E\u03b1\u223cqt(\u03b1)[\u03c32x\u2217(\u03b1)+\u00b5 2 x\u2217(\u03b1)]\u2212 \u00b5\u0302 2 x\u2217 ' r \u22121\u2211r i=1(\u03c3 2 x\u2217(\u03b1i)+ \u00b52x\u2217(\u03b1i))\u2212\u00b5\u0302 2 x\u2217 where \u03c3 2 x\u2217(\u03b1) is previously defined in Proposition 1 and the V\u03b1\u223cqt(\u03b1)[\u00b5x\u2217(\u03b1)] term arises due to the uncertainty of \u03b1. The samples \u03b11, . . . ,\u03b1r are in turn obtained by sampling z1, . . . , zr from \u03c8(z) and applying the parametric transformation in Lemma 1 with respect to the current estimates Mt and bt, that is, vec(\u03b8i, si) = \u03b1i = Mtzi+bt for i = 1, . . . , r. Computing the predictive mean \u00b5\u0302x\u2217 and variance \u03c3\u03022x\u2217 thus incurs constant time in the data size n, hence achieving efficient approximate predictive inference."}, {"heading": "5 Empirical Studies", "text": "This section empirically evaluates the predictive performance and time efficiency of our sVBSSGP model on three real-world datasets: (a) The AIMPEAK dataset (Chen et al. 2013) consists of 41800 traffic speed observations (km/h) along 775 urban road segments during the morning peak hours on April 20, 2011. Each observation features a 5- dimensional input vector of a road segment\u2019s length, number of lanes, speed limit, direction, and its recording time (i.e., discretized into 54 five-minute time slots), and a corresponding output measuring the traffic speed (km/h); (b) the benchmark AIRLINE dataset (Hensman, Fusi, and Lawrence\n2013; Hoang, Hoang, and Low 2015) contains 2000000 information records of US commercial flights in 2008. Each record features a 8-dimensional input vector of the aircraft\u2019s age (year), travel distance (km), the flight\u2019s total airtime, departure time, arrival time (min), and the date given by day of week, day of month, and month, and a corresponding output of the flight\u2019s delay time (min); and (c) the BLOG feedback dataset (Buza 2014) contains 60000 instances of blog posts. Each blog post features a fairly large 60-dimensional input vector associated with its first 60 attributes described at https://archive.ics.uci.edu/ml/datasets/BlogFeedback, and a corresponding output measuring the number of comments in the next 24 hours. The BLOG dataset is used to evaluate the robustness of sVBSSGP to overfitting which usually occurs in training with datasets of high input dimensions. All datasets are modeled using GPs with prior covariance defined in Section 2 and split into 95% training data and 5% test data. All experimental results are averaged over 5 random splits. For the AIMPEAK, AIRLINE, and BLOG datasets, we use, respectively, 2m = 40, 40, and 10 trigonometric basis functions to approximate the GP kernel (2) and sample z from N (0, I) (Section 3.1). All experiments are run on a Linux system with Intelr Xeonr E5-2670 at 2.6GHz with 96 GB memory.\nThe performance of sVBSSGP is compared against the state-of-the-art VSSGP (Gal and Turner 2015) and stochastic implementations of sparse GP models based on inducing variables such as DTC+ and PIC+ (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015) (i.e., run with their GitHub codes) using the following metrics: (a) Root mean square error (RMSE) {|X|\u22121 \u2211 x\u2217\u2208X(yx\u2217 \u2212 \u00b5\u0302x\u2217) 2}1/2 over the set X of test inputs, (b) mean neg-\native log probability (MNLP) 0.5|X|\u22121 \u2211\nx\u2217\u2208X{(yx\u2217 \u2212 \u00b5\u0302x\u2217) 2/\u03c3\u03022x\u2217 + log(2\u03c0\u03c3\u0302 2 x\u2217)}, and (c) training time. AIMPEAK Dataset. This dataset is evenly partitioned into p = 200 disjoint subsets using k-means (k = p). Fig. 1 shows results of RMSEs of sVBSSGP for \u03b3 = 0, 0.1, 0.2, 0.3 that rapidly decrease by 4- to 5-fold over 30 iterations. It can also be observed that increasing \u03b3 from 0 results in higher converged RMSEs. To further investigate this, Fig. 2a reveals that sVBSSGP indeed achieves the lowest converged RMSE at \u03b3 = 0 among all tested values of \u03b3. This confirms our hypothesis stated earlier in Remark 1 that given the learned spectral frequencies \u03b8, the information carried by s becomes a \u201cnuisance\u201d to prediction despite its interaction with \u03b8 in q(\u03b8, s) = q(\u03b1) during stochastic optimization. That is, when the influence of s on the test output is completely removed from the test conditional by setting \u03b3 = 0 in Proposition 1, the predictions are no longer inter-\nfered by the nuisance information of s, hence explaining the lowest RMSE achieved by sVBSSGP at \u03b3 = 0.\nFig. 2b and Table 1 show that sVBSSGP (\u03b3 = 0 and r = 20) significantly outperforms VSSGP, DTC+, and PIC+ (250 inducing variables) in terms of RMSE after 30 iterations. To explain this, DTC+ and PIC+ find point estimates of the kernel hyperparameters, which may have resulted in their poorer performance. Though VSSGP also adopts a Bayesian treatment of the spectral frequencies, it uses a degenerate test conditional corresponding to the case of \u03b3 = 1 in Proposition 1. As a result, VSSGP imposes a highly restrictive deterministic relationship between the test output and spectral frequencies and also fails to exploit the local data for prediction (see Remark 1). The results of the MNLP metric are similar and reported in Appendix H. AIRLINE Dataset. This dataset is partitioned into p = 2000 disjoint subsets using k-means. Fig. 2c and Table 1 show that sVBSSGP (\u03b3 = 0 and r = 5) significantly outperforms VSSGP, DTC+, and PIC+ (512 inducing variables) in terms of RMSE after 45 iterations, as explained previously. Fig. 2d shows that the total training time of sVBSSGP increases linearly with the number t of iterations, which highlights a principled trade-off between its predictive performance and time efficiency. The training time of sVBSSGP, though longer than DTC+ and PIC+, is only 43 sec. per iteration; the training time of VSSGP is not included since its GitHub code runs on GPU instead of CPU. The results of MNLP metric are similar to that for the AIMPEAK dataset. BLOG Dataset. This dataset is evenly partitioned into p = 200 disjoint subsets using k-means. Fig. 3 shows that with more samples drawn from qt(\u03b1) to compute predictive mean \u00b5\u0302x\u2217 (Section 4.2), sVBSSGP tends to converge faster and to\na lower RMSE, which suggests a greater robustness to overfitting by exploiting a higher degree of Bayesian model averaging. More interestingly, the effect of overfitting appears to be more pronounced for the BLOG dataset with a much larger input dimension of 60: When r = 1, sVBSSGP effectively reduces to a local SSGP model utilizing the sampled spectral frequencies as its point estimate (see Proposition 1, Remark 1, and Section 4.2) and converges to the poorest performance that stops improving after 10 iterations. It can also be observed that the performance gap between sVBSSGP\u2019s with different number r of samples is much wider at early iterations, thus highlighting the practicality of our Bayesian treatment in the case of limited data."}, {"heading": "6 Conclusion", "text": "This paper describes a novel generalized framework of sVBSSGP regression models that addresses the shortcomings of existing sparse spectrum GP models like SSGP (La\u0301zaro-Gredilla et al. 2010) and VSSGP (Gal and Turner 2015) by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling the spectral frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for improving the predictive performance while still being able to preserve its scalability to big data through stochastic optimization. As a result, empirical evaluation on real-world datasets (i.e., including the million-sized benchmark AIRLINE dataset) shows that our proposed sVBSSGP regression model can significantly outperform the existing sparse spectrum GP models like SSGP and VSSGP as well as the stochastic implementations of the sparse GP models based on inducing variables like DTC+ and PIC+ (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015). Acknowledgments. This research is supported by the National Research Foundation, Prime Minister\u2019s Office, Singapore under its International Research Centre in Singapore Funding Initiative and Campus for Research Excellence and Technological Enterprise (CREATE) programme."}, {"heading": "A Proof of Proposition 1", "text": "Since {fx}x\u2208X denotes a zero-mean Gaussian process with kernel k(x,x\u2032) and the noisy output yx = fx + is generated by perturbing fx with a random noise \u223c N (0, \u03c32n) (Section 2), p(fx\u2217 |yk,\u03b8) = N (E[fx\u2217 |yk,\u03b8],V[fx\u2217 |yk,\u03b8]) for x\u2217 \u2208 Xk where E[fx\u2217 |yk,\u03b8] , K(x\u2217,Xk)\u039ekyk , V[fx\u2217 |yk,\u03b8] , k(x\u2217,x\u2217)\u2212K(x\u2217,Xk)\u039ekK(Xk,x\u2217) , (8)\nand \u039ek , (K(Xk,Xk) + \u03c32nI) \u22121, which is essentially the standard GP predictive distribution of fx\u2217 given the noisy outputs yk for the training inputs Xk and the hyperparameters \u03b8. Using (2), \u039ek = (\u03a6>\u03b8 (Xk)\u039b\u03a6\u03b8(Xk) + \u03c3 2 nI) \u22121 = \u03c3\u22122n I\u2212\u03c3\u22124n \u03a6>\u03b8 (Xk)(\u03c3\u22122n \u03a6\u03b8(Xk)\u03a6>\u03b8 (Xk)+\u039b\u22121)\u22121\u03a6\u03b8(Xk) = \u03c3\u22122n (I\u2212\u03a6>\u03b8 (Xk)\u0393\u22121k \u03a6\u03b8(Xk)) where the second and third equalities are due to the matrix inversion lemma and the definition of \u0393k, respectively. Using (2), (8) can also be rewritten as\nE [fx\u2217 |yk,\u03b8] = \u03b3H\u00b5+ (1\u2212 \u03b3)H\u00b5 V [fx\u2217 |yk,\u03b8] = (1\u2212 \u03b32)H\u03a3H> + \u03b32H\u03a3H>\nfor all |\u03b3| \u2264 1 where H , \u03c6>\u03b8 (x\u2217), \u00b5 , \u039b\u03a6\u03b8(Xk)\u039ekyk\n= \u03c3\u22122n \u039b(I\u2212\u03a6\u03b8(Xk)\u03a6>\u03b8 (Xk)\u0393\u22121k )\u03a6\u03b8(Xk)yk = \u03c3\u22122n \u039b(I\u2212 (\u0393k \u2212 \u03c32n\u039b\u22121)\u0393\u22121k )\u03a6\u03b8(Xk)yk = \u0393\u22121k \u03a6\u03b8(Xk)yk\nwhere the third equality is due to the definition of \u0393k, and\n\u03a3 , \u039b\u2212\u039b\u03a6\u03b8(Xk)\u039ek\u03a6>\u03b8 (Xk)\u039b = \u039b\u2212 \u0393\u22121k \u03a6\u03b8(Xk)\u03a6 > \u03b8 (Xk)\u039b\n= \u039b\u2212 \u0393\u22121k (\u0393k \u2212 \u03c3 2 n\u039b \u22121)\u039b = \u03c32n\u0393 \u22121 k .\nUsing the Gaussian identity of affine transformation for marginalization,\np (fx\u2217 |yk,\u03b8) = \u222b s N ( fx\u2217 |\u00b5x\u2217(\u03b1), \u03c32x\u2217(\u03b1) ) N (s|\u00b5,\u03a3) ds\n(9) where \u00b5x\u2217(\u03b1) , \u03b3Hs + (1 \u2212 \u03b3)H\u00b5 and \u03c32x\u2217(\u03b1) , (1\u2212 \u03b32)H\u03a3H>. Also, marginalizing out [fx]>x\u2208X\\Xk from p(f , s|\u03b8) in (3) (Section 2) yields[\ns fk\n] \u223c N ([ 0 0 ] , [ \u039b \u039b\u03a6\u03b8(Xk)\n\u03a6>\u03b8 (Xk)\u039b K(Xk,Xk) ]) where fk , [fx]>x\u2208Xk . Consequently,[\ns yk\n] \u223c N ([ 0 0 ] , [ \u039b \u039b\u03a6\u03b8(Xk)\n\u03a6>\u03b8 (Xk)\u039b \u039e \u22121 k\n]) ,\nwhich allows us to derive an analytic expression for p(s|yk,\u03b8) = N (s|\u00b5,\u03a3) where \u00b5 and \u03a3 are defined as above. Plugging this expression into (9) yields\np (fx\u2217 |yk,\u03b8) = \u222b s N ( fx\u2217 |\u00b5x\u2217(\u03b1), \u03c32x\u2217(\u03b1) ) p(s|yk,\u03b8) ds .\n(10)\nAlternatively, p(fx\u2217 |yk,\u03b8) can be expressed in terms of p(fx\u2217 |yk, s,\u03b8) and p(s|yk,\u03b8) using marginalization:\np (fx\u2217 |yk,\u03b8) = \u222b s p (fx\u2217 |yk, s,\u03b8) p(s|yk,\u03b8) ds . (11)\nThen, subtracting (10) from (11) gives 0 = Es\u223cp(s|yk,\u03b8) [ p(fx\u2217 |yk, s,\u03b8)\u2212N ( fx\u2217 |\u00b5x\u2217(\u03b1), \u03c32x\u2217(\u03b1) ) ] .\nSince p(s|yk,\u03b8) > 0 for all s, the above equation suggests that p(fx\u2217 |yk, s,\u03b8) = N ( fx\u2217 |\u00b5x\u2217(\u03b1), \u03c32x\u2217(\u03b1) ) is a valid test conditional which is consistent with the structural assumption in (3). Finally, plugging in the above definitions of H, \u00b5, and \u03a3 reproduces the definitions of \u00b5x\u2217(\u03b1) and \u03c32x\u2217(\u03b1) in Proposition 1, thus completing our proof.\nB Derivation of L(q) For all \u03b1, p(y) = p(\u03b1,y)/p(\u03b1|y) which implies\nlog p(y) = log p(\u03b1,y)\np(\u03b1|y) . (12)\nThen, let q(\u03b1) denotes an arbitrary probability density function of \u03b1 (i.e., \u222b \u03b1 q(\u03b1)d\u03b1 = 1). Integrating both sides of (12) with q(\u03b1) gives\nlog p(y) = \u222b \u03b1 q(\u03b1) log p(\u03b1,y) p(\u03b1|y) d\u03b1 . (13)\nThen, plugging\nlog p(\u03b1,y)\np(\u03b1|y) = log\np(\u03b1,y)\nq(\u03b1) + log\nq(\u03b1)\np(\u03b1|y)\ninto the RHS of (13) yields\nlog p(y) = \u222b \u03b1 q(\u03b1) log p(\u03b1,y) q(\u03b1) d\u03b1+KL (q(\u03b1)\u2016p(\u03b1|y))\n= E\u03b1\u223cq(\u03b1) [ log p(\u03b1,y)\nq(\u03b1)\n] +DKL(q)\n(14) where the second equality is due to the definition ofDKL(q) in Section 3. Finally, plugging p(\u03b1,y) = p(y|\u03b1) p(\u03b1) into (14) yields\nlog p(y) = E\u03b1\u223cq(\u03b1) [ log p(y|\u03b1)\u2212 log q(\u03b1)\np(\u03b1)\n] +DKL(q)\n= L(q) +DKL(q) ,\nwhich concludes our proof.\nC Reparameterizing L(q) via \u03c8(z) To do this, let us first define the following function:\ng(\u03b1) , q(\u03b1) [ log p(y|\u03b1)\u2212 log q(\u03b1)\np(\u03b1)\n] , (15)\nwhich allows us to re-express L(q) as\nL(q) = \u222b \u03b1 g(\u03b1) d\u03b1 . (16)\nThen, applying the change of variables theorem to the RHS of (16) with respect to a sufficiently well-behaved function \u03b1 , \u03d5(z), which transforms a variable z into \u03b1, gives\nL(q) = \u222b z g(\u03d5(z)) |J\u03d5(z)|dz = \u222b z g(\u03b1) |J\u03d5(z)|dz (17)\nwhere |J\u03d5(z)| denotes the absolute value of det(J\u03d5(z)) , det(\u2202\u03d5(z)/\u2202z).\nSo, choosing \u03d5(z) , Mz + b yields |J\u03d5(z)| = |M| which can be plugged into (17) to give\nL(q) = \u222b z g(\u03b1) |M|dz\n= \u222b z q(\u03b1) |M| [ log p(y|\u03b1)\u2212 log q(\u03b1) p(\u03b1) ] dz (18)\nwhere the last equality follows from our definition of g(\u03b1) in (15). Now, using the parameterization in Lemma 1, q(\u03b1) = \u03c8(z)/|M| or, equivalently, \u03c8(z) = q(\u03b1)|M|. Thus, plugging this into (18) yields\nL(q) = \u222b z \u03c8 (z) [ log p(y|\u03b1)\u2212 log q(\u03b1) p(\u03b1) ] dz\n= Ez\u223c\u03c8(z) [ log p(y|\u03b1)\u2212 log q(\u03b1)\np(\u03b1)\n] ,\nwhich completes our proof."}, {"heading": "D Closed-Form Evaluation of \u2202L\u0302/\u2202\u03b7", "text": "To show that \u2202L\u0302/\u2202\u03b7 is analytically tractable, it suffices to show that both \u2202 log p(y|\u03b1)/\u2202\u03b7 and \u2202 log(q(\u03b1)/p(\u03b1))/\u2202\u03b7 are analytically tractable, the former of which is shown in Appendix F. To show the latter, note that \u03b7 = vec(M,b) (Section 3.1) implies\n\u2202\n\u2202\u03b7 log\nq(\u03b1) p(\u03b1) = vec\n( \u2202\n\u2202M log\nq(\u03b1) p(\u03b1) , \u2202 \u2202b log q(\u03b1) p(\u03b1)\n) ,\nwhich reveals that \u2202 log(q(\u03b1)/p(\u03b1))/\u2202\u03b7 can be analytically evaluated if \u2202 log(q(\u03b1)/p(\u03b1))/\u2202M and \u2202 log(q(\u03b1)/p(\u03b1))/\u2202b can be analytically evaluated, as detailed below.\nTo evaluate the derivative \u2202 log(q(\u03b1)/p(\u03b1))/\u2202M, note that \u2202 log(q(\u03b1)/p(\u03b1))/\u2202M = \u2202 log q(\u03b1)/\u2202M \u2212 \u2202 log p(\u03b1)/\u2202M. Then, using the parameterization of q(\u03b1) , \u03c8(z)/|M| in Lemma 1, it follows that log q(\u03b1) = log\u03c8(z) \u2212 log |M| which immediately implies \u2202 log q(\u03b1)/\u2202M = \u2212\u2202 log |M|/\u2202M = \u2212(M\u22121)>. Note that \u2202 log\u03c8(z)/\u2202M = 0 since the above derivatives are evaluated with respect to a sampled value of z, which effectively makes log\u03c8(z) a constant that does not depend on either M or b.\nAlso, since p(\u03b1) = N (\u03b1|0,blkdiag[\u0398,\u039b]) (Section 3.1), \u2202 log p(\u03b1)/\u2202\u03b1 = \u2212blkdiag[\u0398\u22121,\u039b\u22121]\u03b1. Let \u03b1 , [\u03b1k]>k , M , [Mij ]i,j , z , [zj ] > j , and b = [bk] > k . Then, by applying the chain rule of derivatives, it follows that \u2202 log p(\u03b1)/\u2202M = \u2211 k(\u2202\u03b1k/\u2202M)(\u2202 log p(\u03b1)/\u2202\u03b1k) where \u2202 log p(\u03b1)/\u2202\u03b1k corresponds to the k-th component of the gradient vector \u2202 log p(\u03b1)/\u2202\u03b1 and \u2202\u03b1k/\u2202M ,\n[\u2202\u03b1k/\u2202Mij ]i,j . Since \u03b1 = Mz + b (Section 3.1), \u03b1k =\u2211 jMkjzj + bk which implies \u2202\u03b1k/\u2202Mij = I(k = i)zj . Putting all of the above together therefore yields the following analytic expression for \u2202 log(q(\u03b1)/p(\u03b1))/\u2202M:\n\u2202\n\u2202M log\nq(\u03b1) p(\u03b1) = \u2212\n( M\u22121 )> \u2212\u2211 k \u2202\u03b1k \u2202M \u2202 log p(\u03b1) \u2202\u03b1k\nwhere \u2202 log p(\u03b1)/\u2202\u03b1 = \u2212blkdiag[\u0398\u22121,\u039b\u22121]\u03b1 and \u2202\u03b1k/\u2202M = [I(k = i)zj ]i,j are derived previously. So, \u2202 log(q(\u03b1)/p(\u03b1))/\u2202M is analytically tractable.\nLikewise, to derive the derivative \u2202 log(q(\u03b1)/p(\u03b1))/\u2202b, note that \u2202 log q(\u03b1)/\u2202b = 0 as log q(\u03b1) = log\u03c8(z) \u2212 log |M| does not depend on b since z is a sampled value that makes log\u03c8(z) a constant. Also, \u2202 log p(\u03b1)/\u2202b = (\u2202\u03b1/\u2202b)(\u2202 log p(\u03b1)/\u2202\u03b1) = \u2202 log p(\u03b1)/\u2202\u03b1 since \u2202\u03b1/\u2202b = I which is implied by the fact that \u03b1 = Mz + b (Section 3.1). Hence, \u2202 log(q(\u03b1)/p(\u03b1))/\u2202b = \u2212\u2202 log p(\u03b1)/\u2202\u03b1 is analytically tractable, as shown previously."}, {"heading": "E Proof of Lemma 2", "text": "Using a derivation similar to that in Appendix A,\np(y|\u03b8) = N ( y|0,\u03a6>\u03b8 (X)\u039b\u03a6\u03b8(X) + \u03c32nI ) =\n\u222b s N ( y|\u03a6>\u03b8 (X)s, \u03c32nI ) N(s|0,\u039b) ds\nwhere the last equality follows from the Gaussian identity of affine transformation for marginalization. Also, from (3), p(s) = N (s|0,\u039b) and hence\np(y|\u03b8) = \u222b s N ( y|\u03a6>\u03b8 (X)s, \u03c32nI ) p(s) ds . (19)\nOn the other hand, p(y|\u03b8) can also be expressed in terms of p(y|\u03b8, s) and p(s) using marginalization:\np(y|\u03b8) = \u222b s p(y, s|\u03b8)ds = \u222b s p(y|\u03b8, s)p(s|\u03b8)ds\n= \u222b s\np(y|\u03b8, s)p(s)ds (20)\nwhere the last equality of (20) follows from our setting in Section 2 and (3) that \u03b8 and s are statistically independent a priori. Subtracting both sides of (19) from that of (20) consequently yields\n0 = \u222b s ( p(y|\u03b8, s)\u2212N ( y|\u03a6>\u03b8 (X)s, \u03c32nI )) p(s) ds ,\nwhich directly implies p(y|\u03b8, s) = N (y|\u03a6>\u03b8 (X)s, \u03c32nI) since p(s) > 0 for all s. Then, since \u03b1 , vec(\u03b8, s) (Section 3.1), this result can be rewritten more concisely as p(y|\u03b1) = N (y|\u03a6>\u03b8 (X)s, \u03c32nI). Finally, taking the logarithm on both sides of this equation completes our proof of Lemma 2."}, {"heading": "F Proof of Theorem 1", "text": "Note that v>v = \u2211p i=1 v > i vi. Plugging this into Lemma 2 yields\nlog p(y|\u03b1) = \u22120.5\u03c3\u22122n p\u2211 i=1 v>i vi\u22120.5n log(2\u03c0\u03c32n) . (21)\nTaking derivatives with respect to \u03b7 on both sides of (21) gives\n\u2202\n\u2202\u03b7 log p(y|\u03b1) = \u22120.5\u03c3\u22122n p\u2211 i=1 \u2207\u03b7(v>i vi)\n= \u22120.5 p\u2211 i=1 ri = p\u2211 i=1 Fi(\u03b7,\u03b1)\nwhere the last two equalities follow from the definitions of ri and Fi(\u03b7,\u03b1) in Theorem 1. This completes our proof.\nClosed-Form Evaluation of Fi(\u03b7,\u03b1). To show that Fi(\u03b7,\u03b1) and hence \u2202 log p(y|\u03b1)/\u2202\u03b7 can be analytically evaluated, it suffices to show that \u2207\u03b7(v>i vi) is analytically tractable.\nTo understand this, note that \u2202vi/\u2202s and \u2202vi/\u2202\u03b8 are both analytically tractable since vi is linear in s while the trigonometric basis functions constituting \u03a6\u03b8(Xi) are analytically differentiable with respect to \u03b8. This therefore implies \u2202vi/\u2202\u03b1 is also analytically tractable since \u03b1 = vec(\u03b8, s).\nRecall from Appendix D that \u03b1 , [\u03b1k]>k . Then, by applying the chain rule of derivatives,\n\u2202vi \u2202M = \u2211 k \u2202\u03b1k \u2202M \u2202vi \u2202\u03b1k , \u2202vi \u2202b = \u2202\u03b1 \u2202b \u2202vi \u2202\u03b1\nwhere \u2202\u03b1k/\u2202M and \u2202\u03b1/\u2202b = I have previously been derived in Appendix D. Thus, \u2202vi/\u2202\u03b7 is analytically tractable, which shows that Fi(\u03b7,\u03b1) is indeed analytically tractable."}, {"heading": "G Generalized Stochastic Gradient", "text": "Let S , {I,Z} where I , {ik}ak=1 and Z , {zj}bj=1 denote the sets of i.i.d. random samples drawn from U(1, p) and \u03c8(z) (Section 3.1), respectively. Define the stochastic gradient of L(q) with respect to \u03b7 = vec(M,b) as\n\u2202L\u0303 \u2202\u03b7 , 1 ab a\u2211 k=1 b\u2211 j=1 ( pFik(\u03b7,\u03b1j)\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ) (22)\nwhere \u03b1j = Mzj + b. The result below shows that the generalized stochastic gradient \u2202L\u0303/\u2202\u03b7 (22) is an unbiased estimator of the exact gradient \u2202L/\u2202\u03b7:\nProposition 2 ES [ \u2202L\u0303/\u2202\u03b7 ] = \u2202L/\u2202\u03b7.\nProof Since I = {ik}ak=1 and Z = {zj}bj=1 are sampled independently,\nES\n[ \u2202L\u0303\n\u2202\u03b7\n] , EK,Z [ \u2202L\u0303\n\u2202\u03b7\n] = EZ [ EK [ \u2202L\u0303\n\u2202\u03b7\n]] . (23)\nAlso, since i1, . . . , ia are sampled independently from the same uniform distribution U(1, p) over a discrete set of partition indices {1, 2, . . . , p},\nEK\n[ \u2202L\u0303\n\u2202\u03b7\n]\n= 1\nab a\u2211 k=1 b\u2211 j=1 ( pEik\u223cU(1,p)[Fik(\u03b7,\u03b1j)]\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ) = 1\nab a\u2211 k=1 b\u2211 j=1 ( pEi\u223cU(1,p)[Fi(\u03b7,\u03b1j)]\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ) = 1\nb b\u2211 j=1 ( pEi\u223cU(1,p)[Fi(\u03b7,\u03b1j)]\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ) .\n(24) To simplify (24), Ei\u223cU(1,p)[Fi(\u03b7,\u03b1j)] can be re-expressed as\nEi\u223cU(1,p)[Fi(\u03b7,\u03b1j)] = p\u2211 i=1 U(1, p)Fi(\u03b7,\u03b1j)\n= 1\np p\u2211 i=1 Fi(\u03b7,\u03b1j)\n= 1\np\n\u2202\n\u2202\u03b7 log p(y|\u03b1j)\n(25)\nwhere the last equality follows directly from Theorem 1. Then, plugging (25) into (24),\nEK\n[ \u2202L\u0303\n\u2202\u03b7\n] = 1\nb b\u2211 j=1 ( \u2202 \u2202\u03b7 log p(y|\u03b1j)\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ) .\n(26) Hence, taking expectation over Z on both sides of (26) yields\nEK,Z\n[ \u2202L\u0303\n\u2202\u03b7\n]\n= 1\nb b\u2211 j=1 Ezj\u223c\u03c8(z) [ \u2202 \u2202\u03b7 log p(y|\u03b1j)\u2212 \u2202 \u2202\u03b7 log q(\u03b1j) p(\u03b1j) ] = 1\nb b\u2211 j=1 \u2202L \u2202\u03b7\n= \u2202L\n\u2202\u03b7 (27)\nwhere the first equality is due to the fact that z1, . . . , zb are sampled independently from the same distribution \u03c8(z) while the second equality follows from (5). Finally, plugging (27) into (23) shows that \u2202L\u0303/\u2202\u03b7 is an unbiased estimator of \u2202L/\u2202\u03b7, thereby completing our proof."}, {"heading": "H Supplementary Experiments", "text": ""}], "references": [{"title": "Feedback prediction for blogs", "author": ["K. Buza"], "venue": "Spiliopoulou, M.; Schmidt-Thieme, L.; and Janning, R., eds., Data Analysis, Machine Learning and Knowledge Discovery. Springer International Publishing. 145\u2013152.", "citeRegEx": "Buza,? 2014", "shortCiteRegEx": "Buza", "year": 2014}, {"title": "Multi-robot informative path planning for active sensing of environmental phenomena: A tale of two algorithms", "author": ["N. Cao", "K.H. Low", "J.M. Dolan"], "venue": "Proc. AAMAS.", "citeRegEx": "Cao et al\\.,? 2013", "shortCiteRegEx": "Cao et al\\.", "year": 2013}, {"title": "Decentralized data fusion and active sensing with mobile sensors for modeling and predicting spatiotemporal traffic phenomena", "author": ["J. Chen", "K.H. Low", "C.K.-Y. Tan", "A. Oran", "P. Jaillet", "J.M. Dolan", "G.S. Sukhatme"], "venue": "Proc. UAI, 163\u2013173.", "citeRegEx": "Chen et al\\.,? 2012", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Parallel Gaussian process regression with low-rank covariance matrix approximations", "author": ["J. Chen", "N. Cao", "K.H. Low", "R. Ouyang", "C.K.-Y. Tan", "P. Jaillet"], "venue": "Proc. UAI, 152\u2013161.", "citeRegEx": "Chen et al\\.,? 2013", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Gaussian process decentralized data fusion and active sensing for spatiotemporal traffic modeling and prediction in mobilityon-demand systems", "author": ["J. Chen", "K.H. Low", "P. Jaillet", "Y. Yao"], "venue": "IEEE T-ASE 12(3):901\u2013921.", "citeRegEx": "Chen et al\\.,? 2015", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Gaussian process-based decentralized data fusion and active sensing for mobility-on-demand system", "author": ["J. Chen", "K.H. Low", "C.K.-Y. Tan"], "venue": "Proc. RSS.", "citeRegEx": "Chen et al\\.,? 2013", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Cooperative aquatic sensing using the telesupervised adaptive ocean sensor fleet", "author": ["J.M. Dolan", "G. Podnar", "S. Stancliff", "K.H. Low", "A. Elfes", "J. Higinbotham", "J.C. Hosler", "T.A. Moisan", "J. Moisan"], "venue": "Proc. SPIE Conference on Remote Sensing of the Ocean, Sea Ice, and Large Water", "citeRegEx": "Dolan et al\\.,? 2009", "shortCiteRegEx": "Dolan et al\\.", "year": 2009}, {"title": "Improving the Gaussian process sparse spectrum approximation by representing uncertainty in frequency inputs", "author": ["Y. Gal", "R. Turner"], "venue": "Proc. ICML, 655\u2013664.", "citeRegEx": "Gal and Turner,? 2015", "shortCiteRegEx": "Gal and Turner", "year": 2015}, {"title": "Gaussian processes for big data", "author": ["J. Hensman", "N. Fusi", "N.D. Lawrence"], "venue": "Proc. UAI, 282\u2013290.", "citeRegEx": "Hensman et al\\.,? 2013", "shortCiteRegEx": "Hensman et al\\.", "year": 2013}, {"title": "Active learning is planning: Nonmyopic -Bayesoptimal active learning of Gaussian processes", "author": ["T.N. Hoang", "K.H. Low", "P. Jaillet", "M. Kankanhalli"], "venue": "Proc. ECML/PKDD Nectar Track, 494\u2013498.", "citeRegEx": "Hoang et al\\.,? 2014a", "shortCiteRegEx": "Hoang et al\\.", "year": 2014}, {"title": "Nonmyopic -Bayes-Optimal Active Learning of Gaussian Processes", "author": ["T.N. Hoang", "K.H. Low", "P. Jaillet", "M. Kankanhalli"], "venue": "Proc. ICML, 739\u2013747.", "citeRegEx": "Hoang et al\\.,? 2014b", "shortCiteRegEx": "Hoang et al\\.", "year": 2014}, {"title": "A unifying framework of anytime sparse Gaussian process regression models with stochastic variational inference for big data", "author": ["T.N. Hoang", "Q.M. Hoang", "K.H. Low"], "venue": "Proc. ICML, 569\u2013578.", "citeRegEx": "Hoang et al\\.,? 2015", "shortCiteRegEx": "Hoang et al\\.", "year": 2015}, {"title": "A distributed variational inference framework for unifying parallel sparse Gaussian process regression models", "author": ["T.N. Hoang", "Q.M. Hoang", "K.H. Low"], "venue": "Proc. ICML, 382\u2013391.", "citeRegEx": "Hoang et al\\.,? 2016", "shortCiteRegEx": "Hoang et al\\.", "year": 2016}, {"title": "Sparse spectrum Gaussian process regression", "author": ["M. L\u00e1zaro-Gredilla", "J. Qui\u00f1onero-Candela", "C.E. Rasmussen", "A.R. Figueiras-Vidal"], "venue": "JMLR 1865\u20131881.", "citeRegEx": "L\u00e1zaro.Gredilla et al\\.,? 2010", "shortCiteRegEx": "L\u00e1zaro.Gredilla et al\\.", "year": 2010}, {"title": "Gaussian process planning with Lipschitz continuous reward", "author": ["C.K. Ling", "K.H. Low", "P. Jaillet"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2016}, {"title": "Decentralized active robotic exploration and mapping for probabilistic field classification in environmental sensing", "author": ["K.H. Low", "J. Chen", "J.M. Dolan", "S. Chien", "D.R. Thompson"], "venue": "Proc. AAMAS, 105\u2013112.", "citeRegEx": "Low et al\\.,? 2012", "shortCiteRegEx": "Low et al\\.", "year": 2012}, {"title": "Recent advances in scaling up Gaussian process predictive models for large spatiotemporal data", "author": ["K.H. Low", "J. Chen", "T.N. Hoang", "N. Xu", "P. Jaillet"], "venue": "Proc. DyDESS.", "citeRegEx": "Low et al\\.,? 2014a", "shortCiteRegEx": "Low et al\\.", "year": 2014}, {"title": "Generalized online sparse Gaussian processes with application to persistent mobile robot localization", "author": ["K.H. Low", "N. Xu", "J. Chen", "K.K. Lim", "E.B. \u00d6zg\u00fcl"], "venue": "Proc. ECML/PKDD Nectar Track, 499\u2013503.", "citeRegEx": "Low et al\\.,? 2014b", "shortCiteRegEx": "Low et al\\.", "year": 2014}, {"title": "Parallel Gaussian process regression for big data: Low-rank representation meets Markov approximation", "author": ["K.H. Low", "J. Yu", "J. Chen", "P. Jaillet"], "venue": "Proc. AAAI.", "citeRegEx": "Low et al\\.,? 2015", "shortCiteRegEx": "Low et al\\.", "year": 2015}, {"title": "Adaptive multi-robot wide-area exploration and mapping", "author": ["K.H. Low", "J.M. Dolan", "P. Khosla"], "venue": "Proc. AAMAS, 23\u201330.", "citeRegEx": "Low et al\\.,? 2008", "shortCiteRegEx": "Low et al\\.", "year": 2008}, {"title": "Informationtheoretic approach to efficient adaptive path planning for mobile robotic environmental sensing", "author": ["K.H. Low", "J.M. Dolan", "P. Khosla"], "venue": "Proc. ICAPS.", "citeRegEx": "Low et al\\.,? 2009", "shortCiteRegEx": "Low et al\\.", "year": 2009}, {"title": "Active Markov information-theoretic path planning for robotic environmental sensing", "author": ["K.H. Low", "J.M. Dolan", "P. Khosla"], "venue": "Proc. AAMAS, 753\u2013760.", "citeRegEx": "Low et al\\.,? 2011", "shortCiteRegEx": "Low et al\\.", "year": 2011}, {"title": "Multirobot active sensing of non-stationary Gaussian processbased environmental phenomena", "author": ["R. Ouyang", "K.H. Low", "J. Chen", "P. Jaillet"], "venue": "Proc. AAMAS.", "citeRegEx": "Ouyang et al\\.,? 2014", "shortCiteRegEx": "Ouyang et al\\.", "year": 2014}, {"title": "Telesupervised remote surface water quality sensing", "author": ["G. Podnar", "J.M. Dolan", "K.H. Low", "A. Elfes"], "venue": "Proc. IEEE Aerospace Conference.", "citeRegEx": "Podnar et al\\.,? 2010", "shortCiteRegEx": "Podnar et al\\.", "year": 2010}, {"title": "A unifying view of sparse approximate Gaussian process regression", "author": ["J. Qui\u00f1onero-Candela", "C.E. Rasmussen"], "venue": "Journal of Machine Learning Research 6:1939\u20131959.", "citeRegEx": "Qui\u00f1onero.Candela and Rasmussen,? 2005", "shortCiteRegEx": "Qui\u00f1onero.Candela and Rasmussen", "year": 2005}, {"title": "Doubly stochastic variational Bayes for non-conjugate inference", "author": ["M.K. Titsias", "M. L\u00e1zaro-Gredilla"], "venue": "Proc. ICML, 1971\u20131979.", "citeRegEx": "Titsias and L\u00e1zaro.Gredilla,? 2014", "shortCiteRegEx": "Titsias and L\u00e1zaro.Gredilla", "year": 2014}, {"title": "Variational learning of inducing variables in sparse Gaussian processes", "author": ["M.K. Titsias"], "venue": "Proc. AISTATS.", "citeRegEx": "Titsias,? 2009", "shortCiteRegEx": "Titsias", "year": 2009}, {"title": "GP-Localize: Persistent mobile robot localization using online sparse Gaussian process observation model", "author": ["N. Xu", "K.H. Low", "J. Chen", "K.K. Lim", "E.B. \u00d6zg\u00fcl"], "venue": "Proc. AAAI, 2585\u20132592.", "citeRegEx": "Xu et al\\.,? 2014", "shortCiteRegEx": "Xu et al\\.", "year": 2014}, {"title": "Hierarchical Bayesian nonparametric approach to modeling and learning the wisdom of crowds of urban traffic route planning agents", "author": ["J. Yu", "K.H. Low", "A. Oran", "P. Jaillet"], "venue": "Proc. IAT, 478\u2013485.", "citeRegEx": "Yu et al\\.,? 2012", "shortCiteRegEx": "Yu et al\\.", "year": 2012}, {"title": "Near-optimal active learning of multi-output Gaussian processes", "author": ["Y. Zhang", "T.N. Hoang", "K.H. Low", "M. Kankanhalli"], "venue": "Proc. AAAI, 2351\u20132357.", "citeRegEx": "Zhang et al\\.,? 2016", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 24, "context": "To lift this computational curse, a vast literature of sparse GP regression models (Qui\u00f1onero-Candela and Rasmussen 2005; Titsias 2009) have exploited a structural assumption of conditional independence based on the notion of inducing variables for achieving linear time in the data size.", "startOffset": 83, "endOffset": 135}, {"referenceID": 26, "context": "To lift this computational curse, a vast literature of sparse GP regression models (Qui\u00f1onero-Candela and Rasmussen 2005; Titsias 2009) have exploited a structural assumption of conditional independence based on the notion of inducing variables for achieving linear time in the data size.", "startOffset": 83, "endOffset": 135}, {"referenceID": 2, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 4, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 9, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 16, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 22, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 27, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 28, "context": "2016), traffic monitoring (Chen et al. 2012; Chen, Low, and Tan 2013; Chen et al. 2015; Hoang et al. 2014a; 2014b; Low et al. 2014a; 2014b; Ouyang et al. 2014; Xu et al. 2014; Yu et al. 2012)), (a) distributed (Chen et al.", "startOffset": 26, "endOffset": 191}, {"referenceID": 3, "context": "2012)), (a) distributed (Chen et al. 2013; Hoang, Hoang, and Low 2016; Low et al. 2015) and (b) stochastic (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015) implementations of such models have been developed to, respectively, (a) reduce their time to train with all the data by a factor close to the number of machines and (b) train with a small, randomly sampled subset of data in constant time per iteration of stochastic gradient ascent update and achieve asymptotic convergence to their predictive distributions.", "startOffset": 24, "endOffset": 87}, {"referenceID": 18, "context": "2012)), (a) distributed (Chen et al. 2013; Hoang, Hoang, and Low 2016; Low et al. 2015) and (b) stochastic (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015) implementations of such models have been developed to, respectively, (a) reduce their time to train with all the data by a factor close to the number of machines and (b) train with a small, randomly sampled subset of data in constant time per iteration of stochastic gradient ascent update and achieve asymptotic convergence to their predictive distributions.", "startOffset": 24, "endOffset": 87}, {"referenceID": 7, "context": "On the other hand, there is a less well-explored, alternative class of low-rank GP approximations that exploit sparsity in the spectral representation of a GP kernel (Gal and Turner 2015; L\u00e1zaro-Gredilla et al. 2010) for gaining time efficiency and have empirically demonstrated competitive predictive performance for datasets of up to tens of thousands in size but, surprisingly, not received as much attention and research effort.", "startOffset": 166, "endOffset": 216}, {"referenceID": 13, "context": "On the other hand, there is a less well-explored, alternative class of low-rank GP approximations that exploit sparsity in the spectral representation of a GP kernel (Gal and Turner 2015; L\u00e1zaro-Gredilla et al. 2010) for gaining time efficiency and have empirically demonstrated competitive predictive performance for datasets of up to tens of thousands in size but, surprisingly, not received as much attention and research effort.", "startOffset": 166, "endOffset": 216}, {"referenceID": 7, "context": "On the other hand, there is a less well-explored, alternative class of low-rank GP approximations that exploit sparsity in the spectral representation of a GP kernel (Gal and Turner 2015; L\u00e1zaro-Gredilla et al. 2010) for gaining time efficiency and have empirically demonstrated competitive predictive performance for datasets of up to tens of thousands in size but, surprisingly, not received as much attention and research effort. In contrast to the above literature, such sparse spectrum GP regression models do not need to introduce an additional set of inducing inputs which is computationally challenging to be jointly optimized, especially with a large number of them that is necessary for accurate predictions. Unfortunately, the sparse spectrum GP (SSGP) model of L\u00e1zaro-Gredilla et al. (2010) does not scale well to massive datasets due to its linear time in the data size and also finds a point estimate of the spectral frequencies of its kernel that risks overfitting.", "startOffset": 167, "endOffset": 803}, {"referenceID": 7, "context": "On the other hand, there is a less well-explored, alternative class of low-rank GP approximations that exploit sparsity in the spectral representation of a GP kernel (Gal and Turner 2015; L\u00e1zaro-Gredilla et al. 2010) for gaining time efficiency and have empirically demonstrated competitive predictive performance for datasets of up to tens of thousands in size but, surprisingly, not received as much attention and research effort. In contrast to the above literature, such sparse spectrum GP regression models do not need to introduce an additional set of inducing inputs which is computationally challenging to be jointly optimized, especially with a large number of them that is necessary for accurate predictions. Unfortunately, the sparse spectrum GP (SSGP) model of L\u00e1zaro-Gredilla et al. (2010) does not scale well to massive datasets due to its linear time in the data size and also finds a point estimate of the spectral frequencies of its kernel that risks overfitting. The recent variational SSGP (VSSGP) model of Gal and Turner (2015) has attempted to address both shortcomings of SSGP with a stochastic implementation and a Bayesian treatment of the spectral frequencies, respectively.", "startOffset": 167, "endOffset": 1048}, {"referenceID": 13, "context": "Such a kernel can be expressed as the Fourier transform of a density function p(r) over the domain of frequency vector r whose coefficients form a set of trigonometric basis functions (L\u00e1zaro-Gredilla et al. 2010): k(x,x\u2032) = Er\u223cp(r)[ \u03c3 scos(2\u03c0r(x\u2212 x\u2032)) ] (1) where p(r) , N ( 0, (4\u03c02\u2206)\u22121 ) .", "startOffset": 184, "endOffset": 213}, {"referenceID": 13, "context": "Such a kernel can be expressed as the Fourier transform of a density function p(r) over the domain of frequency vector r whose coefficients form a set of trigonometric basis functions (L\u00e1zaro-Gredilla et al. 2010): k(x,x\u2032) = Er\u223cp(r)[ \u03c3 scos(2\u03c0r(x\u2212 x\u2032)) ] (1) where p(r) , N ( 0, (4\u03c02\u2206)\u22121 ) . In the same spirit as that of L\u00e1zaro-Gredilla et al. (2010), we approximate the kernel in (1) by its unbiased estimator constructed from m i.", "startOffset": 185, "endOffset": 352}, {"referenceID": 13, "context": "This signifies a key difference between our generalized framework and the sparse spectrum GP (SSGP) model of L\u00e1zaro-Gredilla et al. (2010), the latter of which finds a point estimate of \u03b8 via maximum likelihood estimation that risks overfitting.", "startOffset": 109, "endOffset": 139}, {"referenceID": 7, "context": "Remark 1 The special case of \u03b3 = 1 recovers the degenerate test conditional p(fx\u2217 |\u03b1) = N (\u03c6\u03b8 (x\u2217)s, 0) induced by the variational SSGP (VSSGP) model of Gal and Turner (2015) (see equation 4 and Section 3 therein) which reveals that it imposes a highly restrictive deterministic relationship between fx\u2217 and \u03b1 and also fails to exploit the local data (Xk,yk) (i.", "startOffset": 153, "endOffset": 175}, {"referenceID": 7, "context": "Remark 1 The special case of \u03b3 = 1 recovers the degenerate test conditional p(fx\u2217 |\u03b1) = N (\u03c6\u03b8 (x\u2217)s, 0) induced by the variational SSGP (VSSGP) model of Gal and Turner (2015) (see equation 4 and Section 3 therein) which reveals that it imposes a highly restrictive deterministic relationship between fx\u2217 and \u03b1 and also fails to exploit the local data (Xk,yk) (i.e., due to conditional independence between fx\u2217 and yk given \u03b1) that can potentially improve the predictive performance. Unfortunately, VSSGP cannot be trivially extended to span the entire spectrum since it relies on the induced deterministic relationship between fx\u2217 and\u03b1 to analytically derive its predictive distribution, which does not hold for \u03b3 6= 1. On the other hand, when \u03b3 = 0, the test conditional in Proposition 1 becomes independent of the nuisance variables s and reduces to the predictive distribution p(fx\u2217 |yk,\u03b8) of the SSGP model of L\u00e1zaro-Gredilla et al. (2010) (see equation 7 therein) given its point estimate of the spectral frequencies \u03b8 but restricted to the local data (Xk,yk) corresponding to input subspaceXk.", "startOffset": 153, "endOffset": 944}, {"referenceID": 7, "context": "In contrast, the VSSGP model of Gal and Turner (2015) assumes r1, .", "startOffset": 32, "endOffset": 54}, {"referenceID": 7, "context": "In contrast, the VSSGP model of Gal and Turner (2015) assumes r1, . . . , rm, and s to be statistically independent a posteriori in its variational distribution (see section 4 therein). Relaxing this assumption will cause VSSGP to lose its scalability as its induced variational lower bound will inevitably become intractable. Remark 3 Though the model of Titsias and L\u00e1zaroGredilla (2014) has adopted a similar parameterization but only for the original GP hyperparameters, it incurs cubic time in the data size per iteration of gradient ascent update, as shown in its supplementary materials and experiments.", "startOffset": 32, "endOffset": 390}, {"referenceID": 3, "context": "This section empirically evaluates the predictive performance and time efficiency of our sVBSSGP model on three real-world datasets: (a) The AIMPEAK dataset (Chen et al. 2013) consists of 41800 traffic speed observations (km/h) along 775 urban road segments during the morning peak hours on April 20, 2011.", "startOffset": 157, "endOffset": 175}, {"referenceID": 0, "context": "Each record features a 8-dimensional input vector of the aircraft\u2019s age (year), travel distance (km), the flight\u2019s total airtime, departure time, arrival time (min), and the date given by day of week, day of month, and month, and a corresponding output of the flight\u2019s delay time (min); and (c) the BLOG feedback dataset (Buza 2014) contains 60000 instances of blog posts.", "startOffset": 321, "endOffset": 332}, {"referenceID": 7, "context": "The performance of sVBSSGP is compared against the state-of-the-art VSSGP (Gal and Turner 2015) and stochastic implementations of sparse GP models based on inducing variables such as DTC+ and PIC+ (Hensman, Fusi, and Lawrence 2013; Hoang, Hoang, and Low 2015) (i.", "startOffset": 74, "endOffset": 95}, {"referenceID": 13, "context": "49 Table 1: RMSEs achieved by sVBSSGP, DTC+, PIC+, SSGP (L\u00e1zaro-Gredilla et al. 2010), and VSSGP after final convergence for AIMPEAK and AIRLINE datasets.", "startOffset": 56, "endOffset": 85}, {"referenceID": 13, "context": "This paper describes a novel generalized framework of sVBSSGP regression models that addresses the shortcomings of existing sparse spectrum GP models like SSGP (L\u00e1zaro-Gredilla et al. 2010) and VSSGP (Gal and Turner 2015) by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling the spectral frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for improving the predictive performance while still being able to preserve its scalability to big data through stochastic optimization.", "startOffset": 160, "endOffset": 189}, {"referenceID": 7, "context": "2010) and VSSGP (Gal and Turner 2015) by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling the spectral frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for improving the predictive performance while still being able to preserve its scalability to big data through stochastic optimization.", "startOffset": 16, "endOffset": 37}], "year": 2016, "abstractText": "While much research effort has been dedicated to scaling up sparse Gaussian process (GP) models based on inducing variables for big data, little attention is afforded to the other less explored class of low-rank GP approximations that exploit the sparse spectral representation of a GP kernel. This paper presents such an effort to advance the state of the art of sparse spectrum GP models to achieve competitive predictive performance for massive datasets. Our generalized framework of stochastic variational Bayesian sparse spectrum GP (sVBSSGP) models addresses their shortcomings by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling these frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for boosting the predictive performance. However, such structural improvements result in a variational lower bound that is intractable to be optimized. To resolve this, we exploit a variational parameterization trick to make it amenable to stochastic optimization. Interestingly, the resulting stochastic gradient has a linearly decomposable structure that can be exploited to refine our stochastic optimization method to incur constant time per iteration while preserving its property of being an unbiased estimator of the exact gradient of the variational lower bound. Empirical evaluation on real-world datasets shows that sVBSSGP outperforms stateof-the-art stochastic implementations of sparse GP models.", "creator": "TeX"}}}