{"id": "1611.07781", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2016", "title": "Adaptive Down-Sampling and Dimension Reduction in Time Elastic Kernel Machines for Efficient Recognition of Isolated Gestures", "abstract": "in the scope of gestural action recognition, the size of the feature vector representing movements is in general quite large especially when full grown body movements are considered. furthermore, this feature vector evolves during the movement performance so that a complete movement is fully perfectly represented by a matrix m of size dxt, whose element m i, j represents the value of feature i at timestamps j. many studies have addressed dimensionality reduction considering only the size of the feature vector lying in r d to reduce both the variability of gestural sequences expressed in the reduced space, and the computational complexity of their language processing. in return, very few of these methods have explicitly addressed the dimensionality reduction along the time shifting axis. yet this is a major issue when considering the use of multiple elastic distances and which are characterized by a quadratic complexity along the time axis. we present in this paper an evaluation of straightforward approaches aiming at reducing the dimensionality value of the matrix m for each movement, leading to consider both the dimensionality reduction of the feature vector as well as its reduction along the time axis. the dimensionality reduction of the feature vector is achieved by selecting remarkable joints in the skeleton performing the movement, basically the extremities of the articulatory chains composing the skeleton. the temporal dimen - sionality reduction is achieved using either a regular or adaptive geometric down - sampling that seeks to minimize the reconstruction error of the movements. elastic and euclidean kernels are then compared through support vector machine learning. two data sets 1 that are widely referenced in the domain of human gesture recognition, and quite distinctive in terms of quality of motion capture, are used for the experimental assessment of the proposed approaches. on these data sets we experimentally show that it is feasible, and possibly desirable, to significantly reduce simultaneously the size of the feature vector and the number of skeleton frames to represent body movements while maintaining a very good recognition rate. the method proves to give satisfactory results at a level currently reached by state - of - the - art methods on these data sets. we experimentally show that detecting the computational complexity reduction that is properly obtained makes this approach eligible for real - time applications.", "histories": [["v1", "Wed, 23 Nov 2016 13:18:17 GMT  (1196kb)", "http://arxiv.org/abs/1611.07781v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["pierre-fran\\c{c}ois marteau", "sylvie gibet", "cl\\'ement reverdy"], "accepted": false, "id": "1611.07781"}, "pdf": {"name": "1611.07781.pdf", "metadata": {"source": "CRF", "title": "Adaptive Down-Sampling and Dimension Reduction in Elastic Kernel Machines for Efficient Recognition of Isolated Gestures", "authors": ["Pierre-Francois Marteau"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n61 1.\n07 78\n1v 1\n[ cs\n.C V\n] 2\n3 N\nIn the scope of gestural action recognition, the size of the feature vector representing movements is in general quite large especially when full body movements are considered. Furthermore, this feature vector evolves during the movement performance so that a complete movement is fully represented by a matrix M of size DxT , whose element Mi, j represents the value of feature i at timestamps j. Many studies have addressed dimensionality reduction considering only the size of the feature vector lying in RD to reduce both the variability of gestural sequences expressed in the reduced space, and the computational complexity of their processing. In return, very few of these methods have explicitly addressed the dimensionality reduction along the time axis. Yet this is a major issue when considering the use of elastic distances which are characterized by a quadratic complexity along the time axis. We present in this paper an evaluation of straightforward approaches aiming at reducing the dimensionality of the matrix M for each movement, leading to consider both the dimensionality reduction of the feature vector as well as its reduction along the time axis. The dimensionality reduction of the feature vector is achieved by selecting remarkable joints in the skeleton performing the movement, basically the extremities of the articulatory chains composing the skeleton. The temporal dimensionality reduction is achieved using either a regular or adaptive down-sampling that seeks to minimize the reconstruction error of the movements. Elastic and Euclidean kernels are then compared through support vector machine learning. Two data sets\nPierre-Francois Marteau IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, email: firstname.nameATuniv-ubsDOTfr\nSylvie Gibet IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, email: firstname.nameATuniv-ubsDOTfr\nCl\u00e9ment Reverdy at IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, e-mail: firstname.nameATuniv-ubsDOTfr\n1\nthat are widely referenced in the domain of human gesture recognition, and quite distinctive in terms of quality of motion capture, are used for the experimental assessment of the proposed approaches. On these data sets we experimentally show that it is feasible, and possibly desirable, to significantly reduce simultaneously the size of the feature vector and the number of skeleton frames to represent body movements while maintaining a very good recognition rate. The method proves to give satisfactory results at a level currently reached by state-of-the-art methods on these data sets. We experimentally show that the computational complexity reduction that is obtained makes this approach eligible for real-time applications."}, {"heading": "1 Introduction", "text": "Gesture recognition is a challenging task in the computer vision community with numerous applications using motion data such as interactive entertainment, humanmachine interaction, automotive, or digital home. Recently, there is an increasing availability of large and heterogeneous motion captured data characterized by a various range of qualities, depending on the type and quality of the motion sensors. We thus separate (i) databases of high resolution and quality built from expensive capturing devices and requiring a particular expertise, (ii) and low resolution and noisier databases produced with cheap sensors that do not require any specific expertise. Such databases open new challenges for assessing the robustness and generalization capabilities of gesture recognition algorithms on diversified motion data sets. Besides the quality of recognition, the complexity of the algorithms and their computational cost is indeed a major issue, especially in the context of real-time interaction.\nWe address in this paper the recognition of isolated gestures from motion captured data. As motion data are generally represented by high-dimensional time series, many approaches have been developed to reduce their dimension, so that the recognition process is more efficient while being still accurate. Among them, low-dimensional embeddings of motion data have been proposed that enable to characterize and parameterize action sequences. Some of them are based on statistical descriptors [Hussein et al., 2013], rely on relevant meaningful trajectories [Ofli et al., 2013], or characterize the style[Hussein et al., 2013]. In this paper we focus on dimensionality reduction along two complementary axes: the spatial axis representing the configuration of the skeleton at each frame, and the temporal axis representing the evolution over time of the skeletal joints trajectories. With such an approach, two main challenges are combined simultaneously:\n\u2022 We use relevant trajectories (end-extremities) whose content may characterize complex actions; \u2022 Considering that the temporal variability is of primary importance when recognizing skilled actions and expressive motion, we apply an adaptive temporal down-sampling to reduce the complexity of elastic matching.\nThese low-dimensional dual-based representations will be coupled with appropriate recognition algorithms that we expect to be more tractable and efficient.\nOur recognition principle is based on a recent method that improves the performance of classical support vector machines when used with regularized elastic kernels dedicated to time series matching. Our objective is to show how the spatial and temporal dimensionality reductions, associated with such regularized elastic kernels significantly improve the efficiency, in terms of response time, of the algorithm while preserving the recognition rates.\nThe second section briefly presents the related works and state-of-the-art for isolated gesture recognition. In the third section we describe the nature of the motion data as well as the main pre-processing of the data. The fourth section gives the major keypoints of the method, positioning it in the context of multivariate sequential data classification. We present in the fifth part the evaluation of our algorithm carried out on two data sets with very distinct qualities and compare its performance with those obtained by some of the state-of-the-art methods. A final discussion is provided as well as some perspectives."}, {"heading": "2 Related work", "text": "In human gesture recognition, there are two main challenges to be addressed: dimension reduction closely linked to feature descriptors, and recognition models which cover different aspects of dynamic modeling, statistical and machine learning approaches. In this section, we give a brief and non-exhaustive overview of the literature associated with each challenge.\nDimension reduction The problem of dimensionality reduction (also called manifold learning) can be addressed with the objective to find a low-dimensional space that best represents the variance of the data without loosing too much information.Action descriptors have thus been defined for characterizing whole motion sequences, or punctual frames that need additional step of temporal modeling to achieve the recognition goal.\nNumerous method are available to carry out such dimensionality reduction, the most popular being linear approaches such as Principal Component Analysis (PCA, [Jolliffe, 1986], [Masoud and Papanikolopoulos, 2003]), Linear Discriminant Analysis (LDA, [McLachlan, 2004]), or linear projections preserving locally neighborhoods (Locality Preserving Projection) [He and Niyogi, 2003]. Among nonlinear approaches, Locally Linear Embeddings (LLE, [Roweis and Saul, 2000]), Metric Multidimensional Scaling (MDS, [Kruskal and Wish, 1978]) and variants like Laplacian Eigenmap [Belkin and Niyogi, 2002], Isomap [Tenenbaum et al., 2000] have been implemented to embed postures in low dimensional spaces in which a more efficient time warp (DTW, see section 5) algorithm can be used to classify movements. An extension of this method, called ST-Isomap, considers temporal relationships in local neighborhoods that can be propagated globally via a shortest-\npath mechanism [Jenkins and Mataric\u0301, 2004]. Models based on Gaussian processes with latent variables are also largely used, for instance a hierarchical version has been recently exploited for gesture recognition [Han et al., 2010].\nOther methods define discriminative features that best classify motion classes. This is the case in the work of [Yu and Aggarwal, 2009] that reduces the motion data to only five end-extremities of the skeleton (two feet, two hands and the head), thus giving some meaningful insight of the motion related to the action task. [Fothergill et al., 2012] and [Zhao et al., 2012] have in particular applied random forests to recognize actions, using a Kinect sensor, while [Ofli et al., 2013] recently proposed to automatically select the most informative skeletal joints to explain the current action. In the same line, [Hussein et al., 2013] use the covariance matrix for skeleton joint locations over time as a discriminative descriptor to characterize a movement sequence. Multiple covariance matrices are deployed over sub-sequences in a hierarchical fashion in order to encode the relationship between joint movement and time. In [Li et al., 2010] a simple bag of 3D points is used to represent and recognize gestural action. Similarly, in [Wang et al., 2012], actionlets are defined from Fourrier coefficients to characterize the most discriminative joints. Finally, it can be mentioned, among many existing applications that address the use of elastic distances into a recognition process, the recent work described in [Sempena et al., 2011], as well as the hardware acceleration proposed in [Hussain and Rashid, 2012]. However, to our knowledge, no work exploiting this type of distance has directly studied the question of data reduction along the time axis.\nGesture recognition Recognition methods essentially aim at modeling the dynamics of gestures. Some approaches, based on linear dynamic models [Veeraraghavan et al., 2004], have used autoregressive (AR) and autoregressive moving-average (ARMA) models to characterize the kinematics of movements, while other approaches, based on nonlinear dynamic models [Bissacco et al., 2007], have developed movement analysis and recognition scheme based on dynamical models controlled by Gaussian processes. [Mitra and Acharya, 2007] propose a synthesis of the major gesture recognition approaches relying on Hidden Markov Models (HMM). Histograms of oriented 4D normals have also been proposed in [Oreifej and Liu, 2013] for the recognition of gestural actions from sequences of depth images. [Wang et al., 2006] have exploited conditional random fields to model joint dependencies and thus increase the discrimination of HMM-like models. Recurrent neural network models have also been used [Martens and Sutskever, 2011]; among them, conditional restricted Boltzman\u2019s machines [Larochelle et al., 2012] have been studied recently in the context of motion captured data modeling and classification.\nIn this paper, we propose a new representation of human actions that results from a dual-based reduction method that occurs both spatially and temporally. We couple this representation to a SVM classification method associated with regularized elastic kernels."}, {"heading": "3 Motion representation", "text": "We are working on isolated human motions acquired through motion captured databases. In recent years, there is an increasing availability of these databases, some of them being captured by high resolution devices (infrared marker-tracking system), such as those provided by CMU [cmu mocap db, 2003], HDM05 [M\u00fcller et al., 2007], and other ones captured by low-cost devices, such as MSRAction3D captured with the Microsoft Kinect system. With the first type of sensors, the acquisition process is expensive, as it necessitates for capturing skilled motion with a good accuracy several cameras with many markers located on an actor, and a post-processing pipeline which is costly in time and expertise. Instead, with the second type of sensors, the data acquisition is affordable and necessitates less time and expertise, but with a loss of accuracy which remains acceptable for some tasks.\nAfter the recording, the captured data is filtered and reconstructed so that to eliminate most of the noise, data loss and labelling errors (markers inversion), and the output of this acquisition pipeline is generally a set of 3D-trajectories of the skeleton joints determined from the positions of markers. This kind of data is inherently noisy, mainly due to the quality of the sensors and the acquisition process, but also to approximations made during the reconstruction process. The modeling of the skeleton is indeed subject to some variation for different reasons: in particular the markers being positioned on cloths or on the skin of the actor\u2019s body, they can move during the capturing process, also the determination of the segment lengths, of the joints\u2019 centers and their associated rotation axis are not trivial and lead to modeling errors. To overcome these difficulties, the skeleton model is obtained through an optimization process such as the ones described in [de Aguiar et al., 2006], [O\u2019Brien et al., 2000], or [Shotton et al., 2011]. The techniques based on a skeleton model hence convert 3D sensor data into Cartesian or angular coordinates that define the state of the joints over time with various accuracies.\nFigure 1 presents two skeletons reconstructed from two very distinct capture systems. On the right, the skeleton is reconstructed from data acquired via the Microsoft Kinect, on the left from the Vicon-MX device used by the Max Planck Institute to produce the HDM05 datasets.\nThus, any skeletal-based model can be represented by a hierarchical tree-like structure composed of rigid segments (bones) connected by joints. A motion can be defined by a sequence of postures over time, formalized as a multivariate state vector describing a trajectory over time, i.e. a time series: {Yt \u2208 Rk}T1 = [Y1, ...,YT ], where the k spatial dimension (k= 3 \u00b7N, with N the number of joints) typically varies between 20 and 100 according to the capture devices and the considered task. As this state vector is obviously not composed of independent scalar dimensions, the spatiotemporal encoded redundancies open solutions for dimension reduction as well as noise reduction approaches. This is particularly relevant for motion recognition, as the objective is to aim at improving computation time and error rate."}, {"heading": "4 Dimension reduction of motion capture data", "text": "Using elastic distances or kernels for recognition problems has proved to be very accurate and efficient. However, one of the main difficulty of such methods with time series data is to deal with their computational cost, in general quadratic with the length of the time series and linear with the spatial dimension characterized by the number of degrees-of-freedom. This high computational complexity is potentially limiting their use, especially when large amounts of data have to be processed, or when real-time constraint is required. We therefore expect that a dual dimensionality reduction, both on the time and spatial axis is particularly relevant, especially when associated to these techniques. Hence, for motion recognition using elastic distances, we propose to show that there exists a spatio-temporal redundancy in motion data that can be exploited.\nConsidering the quite rich literature on motion recognition, it appears that while some studies have shown success with dimensionality reduction on the spatial axis, very few have directly addressed a dimensionality reduction along the time axis , and much less work by combining the two approaches. [Keogh and Pazzani, 2000] has however proposed a temporal sub-sampling associated with dynamic time warping in the context of time series mining, followed later by [Marteau, 2009]. We address herein after these two lines of research."}, {"heading": "4.1 Dimension reduction along the spatial axis", "text": "Dimension reduction (or manifold learning), is the process consisting of mapping high dimensional data to representations lying in a lower-dimensional manifold. This can be interpreted as mapping the data into a space characterized by a smaller dimension, from which most of the variability of the data can be reproduced.\nWe consider in this paper a more direct approach based on the knowledge of the mechanism underlying the production of motion data and the way human beings perceive and discriminate body movements. We make the assumption that the perception of human motion is better achieved in the so-called task-space represented by a selection of significant 3D joint trajectories. This hypothesis is supported by [Giese et al., 2008] who show that visual perception of body motion closely reflects physical similarities between joint trajectories. This is also consistent with the motor theory of motion perception presented in [Gibet et al., 2011]. Besides, we may reasonably accept that these joint trajectories embed sufficient discriminative information as inverse kinematics (widely used in computer animation and robotics) has shown to be very efficient and robust to reconstruct the whole skeleton movement from the knowledge of the end effector trajectories (hands, feet, head), possibly with the additional knowledge of mid-articulated joints trajectories (such as elbows and knees) and constraints. Hence a straightforward approach consists in constructing a motion descriptor that discards all joints information but the 3D positions of the mid and end effectors extremities. We thus select the 3D positions for the two wrists, the two ankles (the fingers and toes markers are less reliable in general), the two elbows, the two knees and the head. This leads to a time-varying descriptor lying in a 18D space, while a full body descriptor is embedded in a 60D, space for the Kinect sensor, significantly more for vicon settings in general."}, {"heading": "4.2 Dimension reduction along the time axis", "text": "The straightforward approach we are developing to explicitly reduce dimensionality along the time axis consists in sub-sampling the movement data such that each motion trajectories takes the form of a fixed-size sequence of L skeletal postures. Then it becomes easy to perform a classification or recognition task by using elastic kernel machines on such fixed-size sequences. With such an approach, performance rates depend on the chosen degree of sub-sampling. This approach seems coarse since long sequences are characterized with the same number of skeletal poses than short sequences. For very short sequences, whose lengths are shorter than L, if any, we over-sample the sequence to meet the fixed-size requirement. But we consider this case as very marginal since we seek a sub-sampling rate much lower than the average sequence of movement length. In the following, we will experiment and compare uniform and adaptive down-sampling."}, {"heading": "4.2.1 Uniform down-sampling", "text": "In order to explicitly reduce dimensionality along the time axis, our first straightforward approach here consists in down-sampling the motion data so that each motion trajectory takes the form of a fixed-size sequence of L skeletal postures, evenly distributed along the time axis. We refer to this approach as uniform down-sampling (UDS)."}, {"heading": "4.2.2 Adaptive down-sampling", "text": "The second approach is the so-called adaptive down-sampling (ADS) approach. Similarly to UDS, each motion trajectory takes the form of a fixed-size sequence of L skeletal postures, but these postures are not evenly distributed anymore along the time axis. They are selected such as to minimize a trajectory reconstruction criteria. Basically we follow the previous work by [Marteau and Gibet, 2006]. A data modeling approach is used to handle the adaptive sampling of the {Yt} multidimensional and discrete time series. More precisely, we are seeking an approximation Y\u03b8\u2217 of Y such as:\n\u03b8 \u2217 = ArgMin \u03b8 (E({Yt},{Y\u03b8 , t})) (1)\nwhere E is the RMS error between Y and Y\u03b8 selected among the set of piecewise linear approximations defined from Y . Since the optimal solution of the optimization problem defined by Eq. 1 is O(L.n2), where n is the length of the input time series,\nwe adopt a near to optimal solution as developed in [Marteau and M\u00e9nier, 2009] whose complexity is O(n). As an example, in figure 2 the human wrist 3D trajectory is down-sampled using 25 samples positioned along the trajectory by minimizing the piecewise linear approximation."}, {"heading": "5 Elastic kernels and their regularization", "text": "Dynamic Time Warping (DTW), [Velichko and Zagoruyko, 1970], [Sakoe and Chiba, 1971], by far the most used elastic measure, is defined as\nddtw(Xp,Yq) = d 2 E(x(p),y(q)) (2)\n+ Min\n\n\n ddtw(Xp\u22121,Yq) sup ddtw(Xp\u22121,Yq\u22121) sub ddtw(Xp,Yq\u22121) ins\nwhere dE(x(p),y(q) is the Euclidean distance (possibly the square of the Euclidean distance) defined on Rk between the two postures in sequences X and Y taken at times p and q respectively.\nWhen performed by a support vector machine (SVM) model, the optimization problem inherent to this type of learning algorithm is no longer quadratic. Moreover, the convergence towards the optimorum is no longer guaranteed, which, depending on the complexity of the task may be considered as detrimental.\nBesides the fact that the DTW measure does not respect the triangle inequality, it is furthermore not possible to directly define a positive definite kernel from it. Hence, the optimization problem, inherent to the learning of a kernel machine, is no longer quadratic which could, at least on some tasks, be a source of limitation.\nRegularized DTW: recent works [Cuturi et al., 2007], [Marteau and Gibet, 2014] allowed to propose new guidelines to regularize kernels constructed from elastic measures such as DTW. A simple instance of such regularized kernel, derived from [Marteau and Gibet, 2014] for time series of equal length, takes the following form, which relies on two recursive terms :\nKrdtw(Xp,Yq) = K xy rdtw(Xp,Yq)+K xx rdtw(Xp,Yq)\nKxydtw(Xp,Yq) = 1 3 e \u2212\u03bdd2E(x(p),y(q))\n\u2211\n\n\n h(p\u2212 1,q)Kxyrdtw(Xp\u22121,Yq) h(p\u2212 1,q\u2212 1)Kxyrdtw(Xp\u22121,Yq\u22121) h(p,q\u2212 1)Kxyrdtw(Xp,Yq\u22121)\nKxxrdtw(Xp,Yq) = 1 3\n\u2211\n\n \n \nh(p\u2212 1,q)Kxxrdtw(Xp\u22121,Yq)e \u2212\u03bdd2E (x(p),y(p)) \u2206p,qh(p,q)Kxxrdtw(Xp\u22121,Yq\u22121)e \u2212\u03bdd2E (x(p),y(q)) h(p,q\u2212 1)Kxxrdtw(Xp,Yq\u22121)e \u2212\u03bdd2E (x(q),y(q))\n(3)\nwhere \u2206p,q is the Kronecker\u2019s symbol, \u03bd \u2208R+ is a stiffness parameter which weights the local contributions, i.e. the distances between locally aligned positions, and dE(., .) is a distance defined on Rk.\nThe initialization is simply Kxyrdtw(X0,Y0) = K xx rdtw(X0,Y0) = 1.\nThe main idea behind this line of regularization is to replace the operators min and max (which prevent the symmetrization of the kernel) by a summation operator (\u2211). This leads to consider, not only the best possible alignment, but also all the best (or nearly the best) paths by summing up their overall cost. The parameter \u03bd is used to control what we call nearly-the-best alignment, thus penalizing more or less alignments too far from the optimal ones. This parameter can be easily optimized through a cross-validation."}, {"heading": "5.1 Normalization", "text": "As Krdtw evaluates the sum on all possible alignment paths of the products of local alignment costs e\u2212d 2 E (x(p),y(p))/(2.\u03c3\n2) \u2264 1, its values can be very small depending on the size of the time series and the selected value for \u03c3 . Hence, KDTW values tend to 0 when \u03c3 tends towards 0, except when the two compared time series are identical (the corresponding Gram matrix suffers from a diagonal dominance problem). As proposed in [Marteau and Gibet, 2014], a manner to avoid numerical troubles consists in using the following normalized kernel:\nK\u0303rdtw(., .) = exp\n(\n\u03b1 log(Krdtw(., .))\u2212 log(min(Krdtw)) log(max(Krdtw))\u2212min(Krdtw))\n)\nwhere max(Krdtw) and min(Krdtw) respectively are the max and min values taken by the kernel on the learning data set and \u03b1 > 0 a positive constant (\u03b1 = 1 by default). If we forget the proportionality constant, this leads to take the kernel Krdtw at a power \u03c4 = \u03b1/(log(max(Krdtw))\u2212 log(min(Krdtw))), which shows that the normalized ker-\nnel K\u0303rdtw \u221d K\u03c4rdtw is still positive definite ([Berg et al., 1984], Proposition 2.7).\nWe consider in this paper the non definite exponential kernel (Gaussian or Radial Basis Function (RBF) types) Kdtw = e\u2212ddtw(.,.)/(2.\u03c3\n2) constructed directly from the elastic measures ddtw, the normalized regularized elastic kernel K\u03c4rdtw, and the nonelastic kernel obtained from the Euclidean distance 1, i.e., KE(., .) = e\u2212d 2 E(.,.)/\u03c3 ."}, {"heading": "6 Experimentation", "text": "To estimate the robustness of the proposed approaches, we evaluate them on two motion capture databases of opposite quality, the first one, called HDM05, developed at the Max Planck Institute, the other one, called MSR-Action3D, at Microsoft research laboratories.\nHDM05 data set [M\u00fcller et al., 2007] consists of data captured at 120Hz by a Vicon MX system composed of a set of reflective optical markers followed by six high-definition cameras and configured to record data at 120hz. The movement sequences are segmented and transformed into sequences of skeletal poses consisting of N = 31 joints, each associated to a 3D position (x,y,z). In practice the position of the root of the skeleton (located near its center of mass) and its orientation serving as referential coordinates, only the relative positions of the remaining 30 joints are used, which leads to represent each position by a vector YT \u2208 Rk , with k = 90. We consider two recognition/classification tasks: HDM05-1 and HDM052 that are respectively those proposed in [Ofli et al., 2012] (also exploited in the work of [Hussein et al., 2013]) and [Ofli et al., 2013]. For both tasks, three subjects are involved during learning and two separate subjects are involved during testing. For task HDM05-1, 11 gestural actions are processed: {deposit floor, elbow to knee, grab high, hop both legs, jog, kick forward, lie down floor, rotate both arms backward, sneak, squat, and throw basketball}. This constitutes 249 motion sequences. For task HDM05-2 , the subjects are the same, but five additional gestural actions are considered in addition to the previous 11: {jump, jumping jacks, throw, sit down, and stand up}. For this task, the data set includes 393 movement sequences in total. For both tests, the lengths of the gestural sequences are between 56 and 901 postures (corresponding to a movement duration between 0.5-7.5 sec.) .\nMSR-Action3D data set: This database [Li et al., 2010] has recently been developed to provide a Kinect data benchmark. It consists of 3D depth image sequences (depth map) captured by the Microsoft Kinect sensor. It contains 20 typical interaction gestures with a game console that are labeled as follows high arm wave, horizontal arm wave, hammer, hand catch, forward punch, high throw, draw x, draw\n1 The Euclidean distance is usable only because a fixed number of skeletal positions is considered to characterize each movement, and this, irrespectively of their initial length\ntick, draw circle, hand clap, two hand wave, side-boxing, bend, forward kick, side kick, jogging, tennis swing, tennis serve, golf swing, pickup & throw . Each action was carried out by 10 subjects facing the camera, 2 or 3 times. This data set includes 567 motion sequences whose lengths vary from 14 to 76 skeletal poses. The 3D images of size 640\u00d7480 were captured at a frequency of 15hz. From each 3D image a skeletal posture has been extracted with N = 20 joints, each one being characterized by three coordinates. As for the previous data set, we characterize postures relatively to the referential coordinates located at the root of the skeleton, which leads to represent each posture by a vector Yt \u2208 Rk, with k = 3\u00d7 19 = 57. The task is to provide a cross-validation on the subjects, i.e. 5 subjects participating in learning and 5 subjects participating in testing, considering all possible configurations which represent 252 learning/testing pairs in total.\nHence, we perform three classification tasks: HDM05-1, HDM05-2 and MSRAction3D, with or without a spatial dimensionality reduction while simultaneously considering a down-sampling on the time axis:\n\u2022 The spatial dimensionality reduction is obtained by constructing a frame (skeletal pose) descriptor composed only with the end-effector trajectories in 3D (EED) comparatively to a full-body descriptor (FBD) that integrates all the joints trajectories that compose the skeleton. The FBD rests in a 90D space for HDM05 and in a 60D space for MSRAction3D. The EED rests in a 24D space (3D positions for 2 elbows, 2 hands, two knees and two feet) for the three tasks, leading to a data compression of 73% for HDM05 and 55% for MSRAction3D.\n\u2022 The dimensionality reduction on the time axis is obtained through either a uniform down-sampling (UDS) or an adaptive down-sampling (ADS) based on a piecewise approximation of the FBD or EED trajectories. The number of skeletal poses varies from 5 to 30 for each trajectories, leading to an average data compression of 97% for HDM05 and 74% for MSRAction3D."}, {"heading": "6.1 Results and analysis", "text": "For the three considered tasks, we present the results obtained using a SVM classifier built from the LIBSVM library [Chang and Lin, 2011], the elastic non definite kernel Kdtw = e\u2212ddtw(.,.)/(2.\u03c3 2), the elastic definite kernel K\u03c4rdtw, and as a baseline, the Euclidean RBF kernel, KE = e\u2212d 2 E (.,.)/(2.\u03c3 2).\nFigures 3, 4 and 5 present the classification accuracies for respectively the HDM05-1, HDM05-2 and MSRAction3D tasks for the test data when the number of skeletal postures selected after down-sampling varies between 5 and 30. For these three figures, the top sub-figure presents classification accuracies when the FBD (Full Body) descriptor associated to a uniform down sampling (UDS) are used, the middle sub-figure classification accuracies when the FBD (Full Body) descriptor associated to an adaptive down sampling (ADS) are used, and the bottom sub-figure gives classification accuracies when the EED (End Extremities) descriptor associated to an adaptive down sampling (ADS) is used.\nOn all three figures, we observe that the down-sampling does not degrade the classification accuracies when the number of poses is over 10, and for some tasks it may even significantly improves the accuracy. This is likely due to the noise filtering effect of the down-sampling. High levels of down-sampling (e.g. when 10 to 15 postures are retained to describe movements, which represents an average compression ratio of 97 % for HDM05 and 70 % on MSRAction3D) lead to very satisfactory results (90 to 98 % for the two HDM05 tasks: Figures 3 and 4, and 82 to 86 % for the MSRAction3D task: 5). Best results are obtained for a number of skeletal poses between 15 and 20, when the EED descriptor is used in conjunction with an adaptive down sampling. The SVM classifier constructed on the basis of the regularized kernel K\u03c4rdtw produces the best recognition rates (>= 96 % for the two HDM05 tasks). We note that the MSRAction3D task is much more difficult since it consists in a cross validation based on the performing subjects. Much lower performance are obtained for the SVM built on the basis of the Euclidean distance; in addition, if very good classification rate (96 %) is obtained on the training data, due to the noisy nature of Kinect data and the inter subject variability, the recognition rate on the test data falls down from 82 to 86 % .\nTable 1 gives for the MSRAction3D data set and for the SVM based on KE ,Kdtw and K\u03c4rdtw kernels, means and standard deviations, obtained on the training data (L) and testing data (T), of recognition rates (classification accuracies) when performing the cross-validation over the 10 subjects (5 train - 5 test splits leading to 252 tests), for the full body descriptor (FBD) and the end extremities descriptor (EED) associated either to a uniform down-sampling (UDS) or an adaptive Down Sampling (ADS). For this test, movements are represented as sequences of 15 skeletal postures. The drop of accuracies between learning and testing phases is due, on this dataset, to the large inter subjects variability of movement performances. Nevertheless, our experiment shows that the best average classification accuracies (obtained in general with minimal variance) are obtained for the most compact movement rep-\nresentation, i.e. when the EED descriptor is used associated to an adaptive downsampling. This is true both for the training and testing datasets.\nFor comparison, table 2 gives results obtained by different methods of the stateof-the-art and compare them with the performance of an SVM that exploits the regularized DTW kernel (K\u03c4rdtw) associated to the end extremity descriptor (EED) and an adaptive down-sampling (ADS) of 15 skeletal poses. To that end, we have reimplemented the Cov3DJ approach [Hussein et al., 2013] to get, for the MSRAction3D data set, the average result given by a 5-5 cross-validation on the subjects (252 tests). This comparative analysis shows that the SVM constructed from regularized DTW kernel provides results slightly above the current state-of-the-art for the considered data sets and tasks.\n2 according to our own implementation of Cov3DJ\nFinally, in Figure 6, we give the average CPU elapsed time for the processing of a single gestural MSRAction3D action when varying the number of retained skeletal poses. The test has been performed on an Intel Core i7-4800MQ CPU, 2.70GHz. Although the computational cost for the elastic kernel is quadratic, the latency for the classification of a single gestural action using a SVM-K\u03c4rdtw is less than 25 milliseconds when 15 poses are considered, which effectively meets easily real-time requirements."}, {"heading": "7 Conclusion and perspectives", "text": "In the context of isolated action recognition, where few studies explicitly consider dimension reduction along both the spatial and time axes simultaneously, we have presented a recognition model based on the dimensionality reduction of the skeletal pose descriptor and the down-sampling of motion sequences coupled to elastic kernel machines. Two ways of down-sampling have been considered: a uniform downsampling that evenly selects samples along the time axis and an adaptive downsampling based on a piecewise linear approximation model. The dimensionality reduction of the skeletal pose descriptor is straightforwardly obtained by considering only end effector trajectories, which is consistent with some sensorimotor perceptual evidence about the way human beings perceive and interpret motion. On the data sets and tasks that we have addressed, we have shown that, even when quite important down-sampling is considered, the recognition accuracy only slightly degrades. In any case, best accuracies are obtained when an adaptive down-sampling\nis used on the end effector 3D trajectories. The temporal redundancy is therefore high and apparently not critical for the discrimination of the selected movements and tasks. In return, the down-sampling benefits in terms of computational complexity is quadratic with the reduction of the number of skeletal postures kept along the time axis.\nFurthermore, the elasticity of the kernel provides a significant performance gain (comparatively to kernel based on the Euclidean distance) which is very important when the data are characterized by high variability. Our results show that a SVM based on a regularized DTW kernel is very competitive comparatively to the stateof-the-art methods applied on the two tested data sets, even when the dimension reduction on the time axis is important. The down-sampling and dimensionality reduction of the descriptor ensures that this approach meets the real-time constraint of gesture recognition.\nThis study opens perspectives to the use of elastic kernels constructed from more sophisticated time elastic distances [Marteau, 2009] that cope explicitly with time stamped data, associated to adaptive sampling techniques such the one developed in this paper or more sophisticated techniques capable of extracting the most significant and discriminant skeletal poses in movement sequences, based on semantic segmentation. We also aim at testing these powerful tools to more complex tasks, where skilled gestures are studied, or/and expressive variations are considered."}], "references": [{"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["Belkin", "Niyogi", "M. 2002. Belkin", "P. Niyogi"], "venue": "Neural Computation,", "citeRegEx": "Belkin et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Belkin et al\\.", "year": 2002}, {"title": "Harmonic Analysis on Semigroups: Theory of Positive Definite and Related Functions, volume 100 of Graduate Texts in Mathematics", "author": ["Berg et al", "C. 1984. Berg", "J.P.R. Christensen", "P. Ressel"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q1984\\E", "shortCiteRegEx": "al. et al\\.", "year": 1984}, {"title": "Classification and recognition of dynamical models: The role of phase, independent components, kernels and optimal transport", "author": ["Bissacco et al", "A. 2007. Bissacco", "A. Chiuso", "S. Soatto"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chang", "Lin", "2011. Chang", "C.-C", "C.-J"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "A Kernel for Time Series Based on Global Alignments", "author": ["Cuturi et al", "M. 2007. Cuturi", "Vert", "J.-P", "O. Birkenes", "T. Matsui"], "venue": "In Proceedings of ICASSP\u201907,", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Automatic learning of articulated skeletons from 3d marker trajectories", "author": ["de Aguiar et al", "E. 2006. de Aguiar", "C. Theobalt", "Seidel", "H.-P"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Instructing people for training gestural interactive systems", "author": ["Fothergill et al", "S. 2012. Fothergill", "H. Mentis", "P. Kohli", "S. Nowozin"], "venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Toward a motor theory of sign language perception", "author": ["Gibet et al", "S. 2011. Gibet", "Marteau", "P.-F", "K. Duarte"], "venue": "Gesture Workshop,", "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Metrics of the perception of body movement", "author": ["al. Giese et", "Giese M. A", "I.M. T"], "venue": "Journal of Vision,", "citeRegEx": "et et al\\.,? \\Q2008\\E", "shortCiteRegEx": "et et al\\.", "year": 2008}, {"title": "Discriminative human action recognition in the learned hierarchical manifold space", "author": ["Han et al", "L. 2010. Han", "X. Wu", "W. Liang", "G. Hou", "Y. Jia"], "venue": "Image Vision Comput.,", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Locality preserving projections", "author": ["He", "Niyogi", "X. 2003. He", "P. Niyogi"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "He et al\\.,? \\Q2003\\E", "shortCiteRegEx": "He et al\\.", "year": 2003}, {"title": "User independent hand gesture recognition by accelerated dtw", "author": ["Hussain", "Rashid", "S. 2012. Hussain", "A. Rashid"], "venue": "In Int. Conf. on Informatics, Electronics Vision (ICIEV),", "citeRegEx": "Hussain et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hussain et al\\.", "year": 2012}, {"title": "Human action recognition using a temporal hierarchy of covariance descriptors on 3d joint locations", "author": ["Hussein et al", "M.E. 2013. Hussein", "M. Torki", "M.A. Gowayyed", "M. El-Saban"], "venue": "In IJCAI", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "A spatio-temporal extension to isomap nonlinear dimension reduction", "author": ["Jenkins", "Matari\u0107", "O.C. 2004. Jenkins", "M.J. Matari\u0107"], "venue": "In Proceedings of the Twenty-first International Conference on Machine Learning,", "citeRegEx": "Jenkins et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Jenkins et al\\.", "year": 2004}, {"title": "Scaling up dynamic time warping for datamining applications", "author": ["Keogh", "Pazzani", "E.J. 2000. Keogh", "M.J. Pazzani"], "venue": "In Proc. of the Sixth ACM SIGKDD,", "citeRegEx": "Keogh et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Keogh et al\\.", "year": 2000}, {"title": "Learning algorithms for the classification restricted boltzmann machine", "author": ["Larochelle et al", "H. 2012. Larochelle", "M. Mandel", "R. Pascanu", "Y. Bengio"], "venue": "J. of Machine Learning Research,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Action recognition based on a bag of 3d points", "author": ["Li et al", "W. 2010. Li", "Z. Zhang", "Z. Liu"], "venue": "Proc. IEEE Int\u2019l Workshop on CVPR for Hum. Comm. Behav. Analysis,", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "Time warp edit distance with stiffness adjustment for time series matching", "author": ["Marteau", "P.F. 2009. Marteau"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Marteau and Marteau,? \\Q2009\\E", "shortCiteRegEx": "Marteau and Marteau", "year": 2009}, {"title": "Adaptive sampling of motion trajectories for discrete task-based analysis and synthesis of gesture", "author": ["Marteau", "Gibet", "2006. Marteau", "P.-F", "S. Gibet"], "venue": "Gesture in Human-Computer Interaction and Simulation,", "citeRegEx": "Marteau et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marteau et al\\.", "year": 2006}, {"title": "On Recursive Edit Distance Kernels with Application to Time Series Classification", "author": ["Marteau", "Gibet", "2014. Marteau", "P.-F", "S. Gibet"], "venue": "IEEE Trans. on Neural Networks and Learning Systems,", "citeRegEx": "Marteau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marteau et al\\.", "year": 2014}, {"title": "Speeding up simplification of polygonal curves using nested approximations", "author": ["Marteau", "M\u00e9nier", "2009. Marteau", "P.-F", "G. M\u00e9nier"], "venue": "Pattern Anal. Appl.,", "citeRegEx": "Marteau et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Marteau et al\\.", "year": 2009}, {"title": "Learning recurrent neural networks with hessian-free optimization", "author": ["Martens", "Sutskever", "J. 2011. Martens", "I. Sutskever"], "venue": "In ICML,", "citeRegEx": "Martens et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martens et al\\.", "year": 2011}, {"title": "A method for human action recognition", "author": ["Masoud", "Papanikolopoulos", "O. 2003. Masoud", "N. Papanikolopoulos"], "venue": "Image Vision Comput.,", "citeRegEx": "Masoud et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Masoud et al\\.", "year": 2003}, {"title": "Discriminant Analysis and Statistical Pattern Recognition", "author": ["McLachlan", "G. 2004. McLachlan"], "venue": null, "citeRegEx": "McLachlan and McLachlan,? \\Q2004\\E", "shortCiteRegEx": "McLachlan and McLachlan", "year": 2004}, {"title": "Gesture recognition: A survey", "author": ["Mitra", "Acharya", "S. 2007. Mitra", "T. Acharya"], "venue": "Trans. Sys. Man Cyber Part C,", "citeRegEx": "Mitra et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mitra et al\\.", "year": 2007}, {"title": "Documentation mocap database hdm05", "author": ["M\u00fcller et al", "M. 2007. M\u00fcller", "T. R\u00f6der", "M. Clausen", "B. Eberhardt", "B. Kr\u00fcger", "A. Weber"], "venue": "Technical Report CG-2007-2,", "citeRegEx": "al. et al\\.,? \\Q2007\\E", "shortCiteRegEx": "al. et al\\.", "year": 2007}, {"title": "Automatic joint parameter estimation from magnetic motion capture data", "author": ["O\u2019Brien et al", "J.F. 2000. O\u2019Brien", "R.E. Bodenheimer", "G.J. Brostow", "J.K. Hodgins"], "venue": "In Proceedings of Graphics Interface", "citeRegEx": "al. et al\\.,? \\Q2000\\E", "shortCiteRegEx": "al. et al\\.", "year": 2000}, {"title": "Sequence of the most informative joints (smij): A new representation for human skeletal action recognition", "author": ["Ofli et al", "F. 2012. Ofli", "R. Chaudhry", "G. Kurillo", "R. Vidal", "R. Bajcsy"], "venue": "In CVPR Workshops,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Sequence of the most informative joints (smij): A new representation for human skeletal action recognition", "author": ["Ofli et al", "F. 2013. Ofli", "R. Chaudhry", "G. Kurillo", "R. Vidal", "R. Bajcsy"], "venue": "Journal of Visual Communication and Image Representation,", "citeRegEx": "al. et al\\.,? \\Q2013\\E", "shortCiteRegEx": "al. et al\\.", "year": 2013}, {"title": "Hon4d: Histogram of oriented 4d normals for activity recognition from depth sequences", "author": ["Oreifej", "Liu", "O. 2013. Oreifej", "Z. Liu"], "venue": null, "citeRegEx": "Oreifej et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Oreifej et al\\.", "year": 2013}, {"title": "Nonlinear dimensionality reduction by locally linear embedding", "author": ["Roweis", "Saul", "S.T. 2000. Roweis", "L.K. Saul"], "venue": null, "citeRegEx": "Roweis et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Roweis et al\\.", "year": 2000}, {"title": "A dynamic programming approach to continuous speech recognition", "author": ["Sakoe", "Chiba", "H. 1971. Sakoe", "S. Chiba"], "venue": "In Proceedings of the 7th International Congress of Acoustic,", "citeRegEx": "Sakoe et al\\.,? \\Q1971\\E", "shortCiteRegEx": "Sakoe et al\\.", "year": 1971}, {"title": "Human action recognition using dynamic time warping", "author": ["Sempena et al", "S. 2011. Sempena", "N. Maulidevi", "P. Aryan"], "venue": "In Int. Conf. on Electrical Engineering and Informatics (ICEEI),", "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["Shotton et al", "J. 2011. Shotton", "A. Fitzgibbon", "M. Cook", "T. Sharp", "M. Finocchio", "R. Moore", "A. Kipman", "A. Blake"], "venue": "In Conf. on Computer Vision and Pattern Recognition,", "citeRegEx": "al. et al\\.,? \\Q2011\\E", "shortCiteRegEx": "al. et al\\.", "year": 2011}, {"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["Tenenbaum et al", "J.B. 2000. Tenenbaum", "V. de Silva", "J.C. Langford"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2000\\E", "shortCiteRegEx": "al. et al\\.", "year": 2000}, {"title": "Role of shape and kinematics in human movement analysis", "author": ["Veeraraghavan et al", "A. 2004. Veeraraghavan", "A.K.R. Chowdhury", "R. Chellappa"], "venue": null, "citeRegEx": "al. et al\\.,? \\Q2004\\E", "shortCiteRegEx": "al. et al\\.", "year": 2004}, {"title": "Automatic recognition of 200 words", "author": ["Velichko", "Zagoruyko", "V.M. 1970. Velichko", "N.G. Zagoruyko"], "venue": "International Journal of Man-Machine Studies,", "citeRegEx": "Velichko et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Velichko et al\\.", "year": 1970}, {"title": "Mining actionlet ensemble for action recognition with depth cameras", "author": ["Wang et al", "J. 2012. Wang", "Z. Liu", "Y. Wu", "J. Yuan"], "venue": "In IEEE int. conf. CVPR,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}, {"title": "Hidden conditional random fields for gesture recognition", "author": ["Wang et al", "S.B. 2006. Wang", "A. Quattoni", "L. Morency", "D. Demirdjian", "T. Darrell"], "venue": "In IEEE int. conf. CVPR,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Human action recognition with extremities as semantic posture representation", "author": ["Yu", "Aggarwal", "E. 2009. Yu", "J. Aggarwal"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops,", "citeRegEx": "Yu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2009}, {"title": "Real-time hand gesture detection and recognition by random forest", "author": ["Zhao et al", "X. 2012. Zhao", "Z. Song", "J. Guo", "Y. Zhao", "F. Zheng"], "venue": "Communications and Information Processing,", "citeRegEx": "al. et al\\.,? \\Q2012\\E", "shortCiteRegEx": "al. et al\\.", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "In the scope of gestural action recognition, the size of the feature vector representing movements is in general quite large especially when full body movements are considered. Furthermore, this feature vector evolves during the movement performance so that a complete movement is fully represented by a matrix M of size DxT , whose element Mi, j represents the value of feature i at timestamps j. Many studies have addressed dimensionality reduction considering only the size of the feature vector lying in RD to reduce both the variability of gestural sequences expressed in the reduced space, and the computational complexity of their processing. In return, very few of these methods have explicitly addressed the dimensionality reduction along the time axis. Yet this is a major issue when considering the use of elastic distances which are characterized by a quadratic complexity along the time axis. We present in this paper an evaluation of straightforward approaches aiming at reducing the dimensionality of the matrix M for each movement, leading to consider both the dimensionality reduction of the feature vector as well as its reduction along the time axis. The dimensionality reduction of the feature vector is achieved by selecting remarkable joints in the skeleton performing the movement, basically the extremities of the articulatory chains composing the skeleton. The temporal dimensionality reduction is achieved using either a regular or adaptive down-sampling that seeks to minimize the reconstruction error of the movements. Elastic and Euclidean kernels are then compared through support vector machine learning. Two data sets Pierre-Francois Marteau IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, email: firstname.nameATuniv-ubsDOTfr Sylvie Gibet IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, email: firstname.nameATuniv-ubsDOTfr Cl\u00e9ment Reverdy at IRISA (UMR 6074), Universit\u00e9 de Bretagne Sud Campus de Tohannic, 56000 Vannes, France, e-mail: firstname.nameATuniv-ubsDOTfr", "creator": "LaTeX with hyperref package"}}}