{"id": "1611.08773", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2016", "title": "Embedded Bandits for Large-Scale Black-Box Optimization", "abstract": "random embedding has been applied with empirical success to large - scale black - box optimization problems with low effective dimensions. this paper proposes the hierarchical embeddedhunter algorithm, which incorporates the technique in a hierarchical operational stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple - single run framework experiment in which random embedding has been conventionally applied since similar to functional stochastic computational black - box optimization solvers. our proposition is motivated by the bounded mean variation in the objective value for a low - dimensional point projected randomly into the decision space of lipschitz - continuous problems. in essence, the embeddedhunter algorithm expands optimistically a partitioning tree over a low - dimensional - - - equal to the effective dimension of the same problem - - - search space based on a bounded number of random embeddings of sampled points from the low - dimensional space. in contrast to the probabilistic theoretical guarantees of multiple - run random - embedding algorithms, the finite - time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm's number of iterations. furthermore, numerical experiments were conducted to validate its performance. the results show a clear performance gain pattern over overly recently proposed random embedding methods for large - scale problems, provided the intrinsic dimensionality is low.", "histories": [["v1", "Sun, 27 Nov 2016 02:18:09 GMT  (320kb,D)", "http://arxiv.org/abs/1611.08773v1", "To appear at AAAI 2017"]], "COMMENTS": "To appear at AAAI 2017", "reviews": [], "SUBJECTS": "cs.AI math.OC", "authors": ["abdullah al-dujaili", "sundaram suresh"], "accepted": true, "id": "1611.08773"}, "pdf": {"name": "1611.08773.pdf", "metadata": {"source": "CRF", "title": "Embedded Bandits for Large-Scale Black-Box Optimization", "authors": ["Abdullah Al-Dujaili", "S. Suresh"], "emails": ["aldujail001@e.ntu.edu.sg,", "ssundaram@ntu.edu.sg"], "sections": [{"heading": "Introduction", "text": "Problem. This paper is concerned with the large-scale black-box optimization problem given a finite number of function evaluations. Mathematically, the problem has the form:\nminimize f(x) subject to x \u2208 X , (1)\nwhere f : X \u2286 Rn \u2192 R and n 102. Without loss of generality, it is assumed that X = [\u22121, 1]n, and there exists at least one global optimizer x\u2217 whose objective value is denoted by f\u2217, i.e., minx\u2208X f(x) = f(x\u2217) = f\u2217. Solving the optimization problem (1) is notoriously difficult as the sole source of information about its objective function f is available through a black-box or an oracle, which one can query\nCopyright c\u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.\nfor the value of f at a specific solution (point ) x \u2208 X . Highorder information (e.g., derivatives) are unavailable symbolically nor numerically or are tedious to compute compared to zero-order information\u2014i.e., point-wise function evaluations. Thus, the task is to find the (or one) optimal solution x\u2217 \u2208 X to (1) or a good approximation using a finite number v of function evaluations, which is commonly referred to as the evaluation budget. The quality of the returned solution x(v) \u2208 X after v function evaluations, denoted by f\u2217v , is assessed by the regret,\nr(v) = f\u2217v \u2212 f\u2217 . (2) Besides the aforementioned challenging nature of black-box problems, the high dimensionality n of the decision space X poses another challenge towards finding the global optimum. Despite their witnessed success, the effectiveness of most black-box optimization algorithms is restricted to moderate dimensions (typically, n < 100) and they do not scale well to high-dimensional (say, n 102) problems. As the dimensionality increases, the number of evaluations (sampled points) required to cover X increases exponentially.\nDespite the curse of dimensionality, it has been noted that for artificial intelligence (AI) applications, most dimensions of certain classes of the associated optimization problems do not affect the objective function significantly. In other words, such problems have low effective dimensionality, e.g., hyper-parameter optimization for neural and deep belief networks (Bergstra and Bengio 2012).\nRelated Work. The literature on black-box optimization is huge and we only highlight here works that are closely related to the paper\u2019s contribution. The bulk of algorithmic work on large-scale black-box optimization has been following one of two approaches: decomposition and embedding.\nDecomposition algorithms break the problem into several subproblems, and solutions for the original problem are recognized in a coordinated manner. In (Kandasamy, Schneider, and Po\u0301czos 2015), Bayesian optimization was scaled to high-dimensional problems whose objectives have an additive structure. i.e., the function f is the sum of several sub-functions with smaller dimensions, such that no two sub-functions share one or more variables. On the other hand, Friesen and Domingos (2015) proposed to decompose the function into approximately locally independent sub-functions and optimize them separately. Chen et\nar X\niv :1\n61 1.\n08 77\n3v 1\n[ cs\n.A I]\n2 7\nN ov\n2 01\n6\nal. (2010) addressed interdependent sub-functions and proposed to consider all entries of the decision vector x independent and discover their relations gradually. In general, decomposition methods employ axis-aligned decomposability, which may limit their applicability.\nEmbedding algorithms exploit the assumption/empirical observation of low effective dimensionality. Chen, Krause, and Castro (2012) presented a variable selection method to discover the effective axis-aligned subspace, while Djolonga, Krause, and Cevher (2013) sought to learn the effective subspace using a low-rank matrix recovery technique. In (Carpentier, Munos, and others 2012), compressed sensing was applied to deal with linear-bandit problems with a high degree of sparsity. Recent works\u2014motivated by the empirical success of random search in leveraging low effective dimensionality without knowing which variables are important (Bergstra and Bengio 2012)\u2014presented random embedding techniques based on the random matrix theory (Wang et al. 2013; Kaban, Bootkrajang, and Durrant 2013) and provided probabilistic theoretical guarantees. In (Qian and Yu 2016), the Simultaneous Optimistic Optimization (SOO) algorithm (Munos 2011) was scaled via random embedding. Problems, whose all dimensions are effective but many of them have a small bounded effect, were addressed in (Qian, Hu, and Yu 2016) where the random embedding technique was incorporated in a sequential framework. In general, random embedding methods employ multiple runs to substantiate the probabilistic theoretical performance.\nOur Contributions. This paper aims to tackle large-scale black-box optimization (1) based on the random embedding technique. Previous propositions put the technique in a framework of multiple runs\u2014be it parallel (Qian and Yu 2016) or sequential (Qian, Hu, and Yu 2016)\u2014to maximize the performance guarantee. In this paper, we seek to break away from the multiple-run framework and follow the optimism in the face of uncertainty principle, or so-called optimistic optimization. To this end, we incorporate the random embedding technique in a stochastic hierarchical bandit setting and present EMBEDDEDHUNTER: an algorithmic instance of the sought approach. Similar to other optimistic methods, EMBEDDEDHUNTER iteratively expands a partitioning tree over a low-dimensional space Y based on randomly projecting sampled points to the original highdimensional space X once or more times. This approach is motivated by the proof that the mean variation in the objective function f value for a point y \u2208 Y projected randomly to f \u2019s decision spaceX is bounded for objective functions that are Lipschitz-continuous. EMBEDDEDHUNTER\u2019s regret (2) is upper bounded in terms of the number of iterations required to expand near-optimal nodes in the (effective) low-dimensional space based on the Lipschitz continuity assumption and that random embedding can preserve local distance.\nThe rest of the paper is organized as follows. First, a formal motivation is presented, followed by an introduction to EMBEDDEDHUNTER. Then, the algorithm\u2019s finite-time performance is studied and complemented by an empirical validation. Towards the end, the paper is concluded."}, {"heading": "Optimistic Optimization Meets Random Embeddings", "text": "Optimistic methods, i.e., methods that implement the optimism in the face of uncertainty principle have proved to be viable for black-box optimization. Such a principle finds its foundations in the machine learning field addressing the exploration-vs.-exploitation dilemma, known as the multi-armed bandit problem. Within the context of function optimization, optimistic approaches formulate the complex problem of optimization (1) over the space X as a hierarchy of simple bandit problems (Kocsis and Szepesva\u0301ri 2006) in the form of space-partitioning tree search. At step t, the algorithm optimistically expands a leaf node (partitions the corresponding subspace) that may contain the global optimum. Previous empirical studies have shown that optimistic methods\u2014e.g., SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016)\u2014are not suitable for problems with high dimensionality.\nRandom embedding has emerged as a practical tool for large-scale optimization with an experimental success and probabilistic theoretical guarantees. It assumes the problem (1) has an implicit low effective dimension d much lower than the explicit (original) dimension n. In essence, for an optimizer x\u2217 \u2208 X = [\u22121, 1]n and a random matrix A \u2208 Rn\u00d7d whose entries are sampled independently from a normal distribution, there exists a point y\u2217 \u2208 Y = [\u2212d/\u03b7, d/\u03b7]d such that its Euclidean random projection to X , PX (Ay\u2217), is x\u2217 with a probability at least 1 \u2212 \u03b7 where \u03b7 \u2208 (0, 1). That is to say, f(PX (Ay\u2217)) = f(x\u2217) = f\u2217. The Euclidean random projection of the ith coordinate [y]i to [X ]i is defined as follows.\n[PX (Ay)]i =   \n1, if [y]i \u2265 1; \u22121, if [y]i \u2264 \u22121; [Ay]i otherwise.\n(3)\nThe reader can refer to (Wang et al. 2013; Qian and Yu 2016) for more details and a formal treatment of the above.\nIt was shown that is possible to scale up optimistic methods via random embedding (Qian and Yu 2016; Qian, Hu, and Yu 2016). Nevertheless, one can observe that it has been applied in a multiple-run framework, where (multiple) M random embeddings are applied on the same lowdimensional search space Y in parallel or sequentially to increase the success rate 1 \u2212 \u03b7M , ignoring the relationship among the function f values at the multiple projections in X of a single point y \u2208 Y . In Theorem 1, we show that a relationship can be established for Lipschitz functions. Prior to that, let us introduce some notation and state the Lipschitz condition formally.\nNotation. Let N denote the Gaussian distribution with zero mean and 1/n variance, and {Ap}p \u2286 Rn\u00d7d, with d n, be a sequence of realization matrices of the random matrix A whose entries are sampled independently from N . Furthermore, let gP (y) be a random (stochastic) function such that gP (y) def = f(PX (Ay)) and gp(y) = f(PX (Apy)) is a realization (deterministic) function, where y \u2208 Y \u2286 Rd. On the other hand, let us define `(x1,x2) as L \u00b7 ||x1 \u2212 x2||,\nwhere || \u00b7 || denotes the L2-norm. The expectation of a random variable X is denoted by E[X]. Assumption 1. f is Lipschitz-continuous, i.e., \u2200x1,x2 \u2208 X , |f(x1)\u2212 f(x2)| \u2264 L \u00b7 ||x1 \u2212 x2|| , (4) where L > 0 is the Lipschitz constant.\nTheorem 1 (Mean absolute difference for gP (y)). \u2200y \u2208 Y \u2286 Rd, we have E[|gp(y)\u2212 gq(y)|] \u2264 \u221a 8 \u00b7 L \u00b7 ||y|| .\nProof. From Assumption 1, we have\nE[|gp(y)\u2212 gq(y)|] =E[|f(PX (Apy))\u2212 f(PX (Aqy))|] \u2264L \u00b7 E[||PX (Apy)\u2212 PX (Aqy)||] .\nFrom the definition of the Euclidean projection (3):\nE[|gp(y)\u2212 gq(y)|] \u2264L \u00b7 E[||Apy \u2212Aqy||]\nThus, from Cauchy\u2019s inequality, we have\nE[|gp(y)\u2212 gq(y)|] \u2264L \u00b7 ||y|| \u00b7 E[||Ap \u2212Aq||]\n\u2264L \u00b7 ||y|| \u00b7 \u221a 8\nn \u00b7 \u221a max(n, d) (5)\n\u2264 \u221a\n8 \u00b7 L \u00b7 ||y|| , where (5) is derived from (Hansen 1988).\nTheorem 1 says that the variation in the function f values at points in X projected randomly from the same lowdimensional point y \u2208 Y is bounded on the order of the point\u2019s norm ||y||. Indeed, the d-dimensional zero vector (center of Y) will always give the same function value (zero variation), regardless of the random matrix used. As a result, one is motivated to project a point y multiple times proportional to its norm in search for the optimal solution x\u2217. Next, we provide EMBEDDEDHUNTER: a novel scalable optimistic algorithm that exploits the above result."}, {"heading": "EMBEDDEDHUNTER", "text": "EMBEDDEDHUNTER is a space-partitioning tree-search algorithm that constructs iteratively finer and finer partitions of the (effective) low-dimensional space Y in a hierarchical fashion looking for the global optimum. The hierarchical partitioning can be represented by a K-ary tree T , where nodes of the same depth h correspond to a partition of Kh subspaces/cells. i.e., the ith node at depth h, denoted by (h, i), corresponds to the subspace/cell Yh,i such that Y = \u222a0\u2264i<KhYh,i. To each node (h, i), a base point yh,i (center of Yh,i) is assigned at which f is evaluated once or more times. That is to say, for every new evaluation of the node (h, i), yh,i is randomly projected to f \u2019s decision space X via a random matrix (3) and gets evaluated. To expand/split a node, the corresponding cell is partitioned into K subscells along one of Y\u2019s coordinates, one coordinate at a depth in a sequential manner. Moreover, let the set of leaf nodes of T be denoted as L. Furthermore, one can denote the algorithm\u2019s tree T at step t by Tt. Towards the detailed aspects of the algorithm, some assumptions are made about\nthe hierarchical partitioning in line with Assumption 1 and Theorem 1, relating variations in function f values using the same and different projection matrices, respectively.\nFunction values within the same projection. Based on the Johnson-Lindenstrauss Lemma (Achlioptas 2003; Vempala 2004); for a set of m points {yi}0\u2264i\u2264m \u2282 Y and their projections {xi}0\u2264i\u2264m \u2282 X via the same matrix, we have `(xi,xj) \u2264 (1 + )1/2 \u00b7 `(yi,yj), where \u2208 (0, 1/2] and n > 9 lnm/( 2 \u2212 3)\u2014see (Qian and Yu 2016, Lemma 3).\nIn other words, the random embedding can probably preserve local distance. Thus, from Assumption 1, the difference between the function f values of two points in the lowdimensional space Y\u2014using the same projection matrix\u2014is on the order of their distance in Y . The next assumption exploits the above observation with respect to the optimal cell (node), which is defined as follows. Definition 1 (Optimal cell). A cell Yh,i at depth h \u2265 0 is optimal if there exists a random matrix Ap whose entries are sampled independently from N such that miny\u2208Yh,i gp(y) = f(x\n\u2217), where x\u2217 is a global optimizer of f . We denote such a cell by Yh,i\u2217pand its node by (h, i\u2217p). Assumption 2 (Bounded intra-variation). There exists a decreasing sequence \u03b4 in h \u2265 0 such that for one (or more) optimal cell(s) Yh,i\u2217p at depth h, we have\n0 \u2264 sup q,y\u2208Yh,i\u2217p |gq(yh,i)\u2212 gq(y)| \u2264 \u03b4(h) .\nAs the hierachical partitioning is performed coordinatewise in a sequential manner, let us link the fact that the cell\u2019s shapes are not skewed in some dimensions with Assumption 2 through the next assumption. Assumption 3 (Well-shaped cells). \u2203 m > 0 such that \u2200(h, i) \u2208 T , Yh,i contains an `-ball of radius m\u03b4(h) centered in yh,i.\nFunction values among different projections. Now, we state another assumption about the optimal cell Yh,i\u2217p in line with Theorem 1. Assumption 4 (Bounded inter-variation). There exists two non-decreasing sequences \u03bb and \u03c4 in y and h, respectively, such that for any depth h \u2265 0, for any optimal cell Yh,i\u2217p ,\n0 \u2264 sup s,t |gs(yh,i\u2217p)\u2212 gt(yh,i\u2217p)| \u2264 \u03bb(yh,i\u2217p) ,\nand supi\u2217p \u03bb(yh,i\u2217p) \u2264 \u03c4(h) . Note that \u03bb being bounded by \u03c4 in h is due to the nature of the hierarchical partitioning: the maximum norm of base points at depth h is smaller than or equal to those at depth h+1. e.g., at depth h = 0, there is a single node (0, 0) whose base point is the d-dimensional zero vector centered inY . As the tree T goes deeper, more base points farther away from the center\u2014and hence greater norms\u2014are sampled.\nCombining Assumptions 2 and 4 implies that the values of function f , which the optimal node\u2019s base point yh,i\u2217p can have, are within \u03c4(h) + \u03b4(h) from the global optimum f\u2217.\nOne can therefore establish a lower confidence bound (commonly referred to as the b-value) on the f values within a cell. Let f\u2217h,i be the best function f value achieved among yh,i evaluations. Then, the b-value for (h, i) can be written as bh,i def = f\u2217h,i \u2212 \u03c4(h) \u2212 \u03b4(h) . With the knowledge of the sequences \u03c4 and \u03b4, we can expand nodes whose b-values lower bound f\u2217, discarding other nodes and striking an efficient balance in exploration-vs-exploitation based on the lowest \u03c4(h) + \u03b4(h) portion of the function space.\nHowever, the knowledge of such sequences (\u03b4, \u03bb, \u03c4 ) is not available/known in practice. Thus, we follow an optimistic approach and propose to simulate the knowledge of these sequences via two realization aspects of the algorithm. First, the tree T \u2019s nodes are visited based on their depths and their base points\u2019 norms: relating the depth-wise and norm-wise visits to the notion of intra-(same projection) and inter-(different projections) exploration-vs.-exploitation dilemmas, respectively. Second, as the tree T is swept across multiple depths and norms, a node (h, i) is expanded only if its f\u2217h,i is strictly smaller than those of nodes of higher depths and those of nodes at the same depth but of greater or equal base points\u2019 norms.\nBesides motivating the norm-wise traversal described above, Theorem 1 implies evaluating f at the nodes\u2019 base points multiple times\u2014each with a new random projection\u2014in proportion to their norms as larger improvement over the current f value is probable at points with greater norms. A tree T with an odd-numbered partition factorK can seamlessly accommodate this observation because the center child node (h + 1, j) of a node (h, i) shares the same base point as its parent (h, i). Therefore, one can decide whether to evaluate a newly created center child node based on the number of function evaluations that its base point had in its ancestor nodes in relation to its norm.\nIn summary, Algorithm 1 describes EMBEDDEDHUNTER. The algorithm takes four parameters: i). the maximum depth hmax up to which nodes can be expanded, it can be a function of the evaluation budget or the number of iterations similar to other optimistic methods; ii). the partition factor K, which has to be an odd number; iii). \u03b7 \u2208 (0, 1) to specify the bounds of the search space Y from the random projection theory; and iv). a multiplicative factor M to bound the number of past function evaluations at a base point yh,i such that it is not greater thanM \u00b7||yh,i||, simulating Theorem 1\u2019s bound, \u221a 8 \u00b7L \u00b7 ||yh,i||. Otherwise, no more evaluation is performed and the node retains its parent\u2019s best achieved function value (performed at Line 9 of the algorithm). For the sake of readability, the following definitions were used in Algorithm 1.\nLt,h def= {(h, i) | 0 \u2264 i < Kh, (h, i) \u2208 Lt} \u0393h,t def = {\u03b3 \u2208 R+0 | \u2203(h, i) \u2208 Lt,h such that \u03b3 = ||yh,i||}\nLjt,h def = {(h, i) | (h, i) \u2208 Lt,h, ||yh,i|| = the jth largest element \u2208 \u0393h,t} (6)\nAlgorithm 1 The EMBEDDEDHUNTER Algorithm Input:\nstochastic function gP , search space Y = [\u2212d/\u03b7, d/\u03b7]d, evaluation budget v.\nInitialization: t\u2190 1, T1 = {(0, 0)}, Evaluate gP (y0,0).\n1: while evaluation budget is not exhausted do 2: \u03bdmin \u2190\u221e 3: for l = 0 to min{depth(Tt), hmax} do 4: for j = 1 to |\u0393l,t| do 5: Select (l, o) = arg min(h,i)\u2208Ljt,l f \u2217 h,i 6: if f\u2217l,o < \u03bdmin then 7: \u03bdmin \u2190 f\u2217l,o 8: Expand (l, o) into its child nodes 9: Evaluate (l, o)\u2019s child nodes by gP\n10: Add (l, o)\u2019s child nodes to Tt 11: end if 12: end for 13: Tt+1 \u2190 Tt 14: t\u2190 t+ 1 15: end for 16: end while 17: return f\u2217v = min(h,i)\u2208Tt f\u2217h,i"}, {"heading": "Theoretical Analysis", "text": "In this section, we analyze the performance of the EMBEDDEDHUNTER algorithm and upper-bound its regret (2). To derive a bound on the regret, a measure of the quantity of near-optimal points is used, which is closely similar to those in (Bubeck et al. 2009; Al-Dujaili, Suresh, and Sundararajan 2016) and defined after introducing some terminology. For any > 0, define the set of -optimal points as Y def= {y \u2208 Y | minp gp(y) \u2264 f\u2217 + } and let g(Y ) def= {minp gp(y) | y \u2208 Y } = [f\u2217, f\u2217+ ]. Likewise, denote the set of -optimal nodes at depth h whose base points are in Y by I h def = {(h, i) \u2208 T | 0 \u2264 i < Kh,yh,i \u2208 Y }. After t iterations, one can denote the depth of the deepest expanded optimal node by h\u2217t , where one iteration represents executing the lines 4\u201314 of Algorithm 1, once.\nDefinition 2. The m-near-optimality dimension is the smallest dm \u2265 0 such that there exists C > 0 such that for any > 0, the maximum number of disjoint `-balls of radius m and center in Y is less than C \u2212dm .\nLet the considered depth after t\u22121 iterations be h and the depth of the deepest expanded optimal node h\u2217t\u22121 be h\u2212 1. At iteration t, EMBEDDEDHUNTER would expand at most |\u0393h,t| nodes. As the (any) optimal node at depth h is in one of the {Ljt,h}1\u2264j\u2264|\u0393h,t| sets, the optimal node at depth h is not expanded at iteration t if \u03bdmin \u2264 f\u2217h,i\u2217p or if there exists a node (h, i) \u2208 Lh,t such that ||yh,i|| \u2265 ||yh,i\u2217p || and f\u2217h,i \u2264 f\u2217h,i\u2217p . The latter condition implies f \u2217 h,i \u2212 f\u2217 \u2264 f\u2217h,i\u2217p \u2212 f \u2217 and by triangular inequality, we have f\u2217h,i \u2212 f\u2217 \u2264 |f\u2217h,i\u2217p \u2212 gp(yh,i\u2217p)|+|gp(yh,i\u2217p)\u2212f\u2217|. Hence, from Assumption 4 and\nAssumption 2, f\u2217h,i \u2212 f\u2217 \u2264 \u03c4(h) + \u03b4(h). Since \u03c4 and \u03b4 are non-decreasing and decreasing sequences in h, respectively. One can write \u03c4(h) as a multiple of \u03b4(h), that is, there exists mh \u2208 Z+ such that\nf\u2217h,i \u2212 f\u2217 \u2264\u03c4(h) + \u03b4(h) \u2264 mh \u00b7 \u03b4(h) . (7)\nPut it differently, when h\u2217t\u22121 = h \u2212 1, the base point of any node at depth h, that is later expanded prior to the optimal node at the same depth, is in the near-optimal space Ymh\u03b4(h). Now, if we assume that prior to any iteration at depth h, \u03bdmin \u2265 mh\u03b4(h), then by Algorithm 1, it takes at most the next |Imh\u03b4(h)h | iterations at depth h to expand the optimal cell Yh,i\u2217p . With this observation at hand, the next question follows naturally: how many iterations at other depths \u2208 {0, . . . , hmax} are required\u2014at most\u2014to expand the optimal cell Yh,i\u2217p , and with no assumption on \u03bdmin? In the following lemma, we show that the number of iterations required is upper bounded by the number of nodes in supersets of each of {Imh\u03b4(h)h }0\u2264h\u2264hmax . The reader can refer to the supplemental material for a pictorial explanation.\nLemma 1. Let depth h \u2208 {0, hmax}, m\u0302 = mhmax and\nth def = hmax ( |Im\u0302\u03b4(0)0 |+ |I m\u0302\u03b4(1) 1 |+ \u00b7 \u00b7 \u00b7+ |I m\u0302\u03b4(h) h | ) . (8)\nAfter t \u2265 th iterations, the depth of the deepest expanded optimal node is at least h, i.e., h\u2217t \u2265 h.\nProof. Refer to the supplemental material.\nLemma 1 quantifies the number of iterations required to expand an optimal node as a function of the number of m\u0302\u03b4(h)-optimal nodes. Based on Assumption 3, the following lemma upper bounds the cardinality of such nodes.\nLemma 2. Let depth h \u2208 {0, hmax}, we have |Im\u0302\u03b4(h)h | \u2264 C(m\u0302\u03b4(h))\u2212d\u0302, where d\u0302 is defined as the m/m\u0302-nearoptimality dimension and C the related constant.\nProof. Refer to the supplemental material.\nWith Lemmas 1 and 2 at hand, the finite-time regret (2) of the EMBEDDEDHUNTER algorithm can be linked to the number of iterations as presented in the next theorem.\nTheorem 2. Define h(t) as the smallest h \u2265 0 such that:\nChmax\nh(t)\u2211\nl=0\n(m\u0302\u03b4(l))\u2212d\u0302 \u2265 t , (9)\nwhere t is the number of iterations. Then EMBEDDEDHUNTER\u2019s regret is bounded as r(t) \u2264 min{\u03c4(h) + \u03b4(h) | h \u2264 min(h(t), hmax + 1)} .\nProof. Refer to the supplemental material."}, {"heading": "Empirical Analysis", "text": "In this section, the efficacy of the proposed method is empirically validated on a set of scalable functions from the literature: the Ellipsoid, FletcherPowell, Rosenbrock, and Ackley test functions (Molga and Smutnicki 2005), each of which reflects some challenges in black-box optimization, e.g., modality, separability, and conditioning. The proposed optimistic method is also compared with the scaled SOO optimistic algorithm (Munos 2011) within two recently presented methods in the random-embedding multiple-run framework, viz. the Simultaneous Optimistic Optimization with Random Embedding (RESOO) (Qian and Yu 2016) and Simultaneous Optimistic Optimization with Sequential Random Embedding (SRESOO) (Qian, Hu, and Yu 2016) algorithms. With the aim of fully characterizing the algorithms\u2019 performance, five experiments are conducted with respect to (w.r.t) the performance as listed in Table 1.\nExperiment Setup. The compared algorithms were implemented in Python and the test functions were imported from the Optproblems Python package (Wessing 2016). Each algorithm is run 20 times independently per an experiment configuration and the average performance is reported. The experiments were set up as listed in Table 1. The code/data/supplemental materials of this paper will be made available at the project\u2019s website: http://ash-aldujaili.github.io/eh-lsopt.\nResults & Discussion. Results from the five experiments on the four test functions are presented in Figure 1. One can easily appreciate EMBEDDEDHUNTER\u2019s performance w.r.t the compared algorithms.\nConvergence (v). Across all the tested functions, the performance gap between the algorithms grows larger with higher evaluation budget v. With more function evaluations, EMBEDDEDHUNTER is able to further refine its best achieved solution in comparison with the other algorithms.\nScalability (n). As expected, the best solution quality de-\nAlgorithms Problems RESOO SRESOO\nEmbeddedHunter\nEllipsoid ill-conditioned, uni-modal, separable\nFletcherPowell periodic search space, multi-modal, nonseparable\nRosenbrock non-convex, uni-modal, non-separable\nAckley |local minima| \u2208 O(en), non-separable\nE x p e ri m e n ts\nConvergence (v)\n101 102 103 104 105 101\n102\n103\n104\n105\n106\nv r e g r e t\n101 102 103 104 105\n104.5\n105\n105.5\nv\nr e g r e t\n101 102 103 104 105\n8.88\n8.9\n8.92\n8.94\n8.96\n8.98\n9\nv\nr e g r e t\n101 102 103 104 105\n100.7\n100.8\n100.9\n101\nv\nr e g r e t\nScalability (n)\n102 103 104 105\n102\n103\n104\n105\n106\nn\nr e g r e t\n102 103 104 105\n105\n106\nn\nr e g r e t\n102 103 104 105\n8.9\n8.92\n8.94\n8.96\nn\nr e g r e t\n102 103 104 105\n100.8\n100.9\nn\nr e g r e t\nEmbeddings Number (M)\n0 5 10 15 20\n102\n103\n104\n105\n106\nM\nr e g r e t\n0 5 10 15 20\n105\n106\nM\nr e g r e t\n0 5 10 15 20\n8.92\n8.94\n8.96\n8.98\nM\nr e g r e t\n0 5 10 15 20\n100.8\n100.9\nM\nr e g r e t\nEffective Dimension (d)\n0 20 40 60 80 101\n102\n103\n104\n105\n106\nd\nr e g r e t\n0 20 40 60 80\n103\n104\n105\n106\n107\n108\nd\nr e g r e t\n0 20 40 60 80\n10\u22121\n100\n101\n102\nd\nr e g r e t\n0 20 40 60 80\n100.7\n100.8\n100.9\n101\nd\nr e g r e t\nEffective Dimension Knowledge\n0 50 100 150 200 250\n100\n101\n102\n103\n104\n105\n106\nd\nr e g r e t\n0 50 100 150 200 250 100\n102\n104\n106\n108\nd\nr e g r e t\n0 50 100 150 200 250\n10\u22122\n10\u22121\n100\n101\n102\nd\nr e g r e t\n0 50 100 150 200 250\n100\n101\nd r e g r e t\nFigure 1: Empirical validation of the EMBEDDEDHUNTER algorithm on a set of commonly-used test optimization problems in comparison with recent large-scale techniques namely RESOO and SRESOO. Each data point of an algorithm\u2019s curve represents the mean performance of its 20 runs w.r.t. the experimental configuration considered.\ngrades with the problem\u2019s explicit dimensionality n. Nevertheless, the performance of SRESOO looks robust yet poorer than that of EMBEDDEDHUNTER and RESOO.\nEmbedding Number (M ). Allocating more independent runs seems to be effective for RESOO\u2019s and of lesser effect to SRESOO\u2019s performance. As M approaches v, both the algorithms act as random search optimizers. This is not the case for EMBEDDEDHUNTER, which uses M as a multiplicative factor to bound the number of evaluations a base point yh,i can have up to M \u00b7 ||yh,i||. EMBEDDEDHUNTER uses M as an estimate of Theorem 1\u2019s bound factor \u221a 8 \u00b7 L. Thus, there\u2019s a sweet-spot value for each function, which explains the regret\u2019s variations for each function in M .\nEffective Dimension (d). The results validate the assumption of low effective dimensionality for the suitability of random embedding technique for large-scale problems. It does\nnot scale well with higher effective dimensionality and the algorithms\u2019 performance gap reduces w.r.t. the same.\nKnowledge of the Effective Dimension. This experiment investigated the performance of low-dimensional embedding irrespective of the effective dimension\u2014be it higher or lower (see Table 1). As the mismatch between the two quantities increases, the performance degrades and the gap among the algorithms reduces."}, {"heading": "Conclusion", "text": "This paper has presented the EMBEDDEDHUNTER algorithm, a different approach to random embedding for largescale black-box optimization. While the bulk of random embedding techniques in the literature employ the multiple-run paradigm sampling a new random projection for each run to maximize the probabilistic guarantee of convergence to\nthe optimal solution, EMBEDDEDHUNTER looks for the optimal solution by building stochastic hierarchical bandits (socalled a tree) over a low-dimensional search space Y , where stochasticity has shown to be proportional on average with the norm of the nodes\u2019 base points.\nThe distinctive advantage of EMBEDDEDHUNTER is that its search tree implicitly ranks Y\u2019s regions via its depth/norm-wise visits and allocates the evaluation budget accordingly. Indeed, other algorithms (e.g., RESOO) may evaluate Y\u2019s center\u2013which is a zero vector\u2013M times in its M independent tree searches/projections. This is inefficient as M evaluations are spent generating the same function value, whereas EMBEDDEDHUNTER evaluates the zero vector once and reserves the rest (M \u2212 1) evaluations to points with greater norms, exploring more values in the function space.\nThe finite-time analysis of the algorithm has characterized its performance in terms of the regret as a function of the number of iterations. Besides its theoreticallyproven performance, the numerical experiments have validated EMBEDDEDHUNTER\u2019s efficacy and robustness with regard to recent random-embedding methods.\nAcknowledgments The research was partially supported by the ST Engineering - NTU Corporate Lab, Singapore, through the NRF corporate lab@universty scheme."}, {"heading": "A.3 On the Generality of Assumption 1", "text": "The class of functions that satisfies the Lipschitz condition is very broad. In fact, it has been shown in [2, 1] that among the Lipschitz-continuous functions are convex/concave functions over a closed domain and continuously differentiable functions.\nA.4 Visual Description and Proof of Lemma 1 Consider Figure 1, where all nodes at depth h = 0 have been expanded with out loss of generality. One can see that if all the nodes in Im1\u03b4(1)1 have been expanded, then in later iterations at depth h = 1 nodes from Lt,1 \\ Im1\u03b4(1)1 will be expanded. As a result, prior to iterations at depth h = 2, the minimum value, \u03bdmin can have, is f\u2217 +m1\u03b4(1). Since \u03c4 is non-decreasing in h, m1 \u2264 m2 and it is possible that there exists some node (h, i) in Im2\u03b4(2)2 such that \u03bdmin \u2264 f\u2217h,i \u2264 f\u2217 +m2\u03b4(2), and hence it will not be expanded. In other words, we are certain that all the nodes in Im2\u03b4(2)2 will be expanded if \u03bdmin\u2014prior to any iteration at depth h = 2\u2014is greater than f\u2217 + m2\u03b4(2). In the light of this observation, the following lemma is deduced.\nLemma 1. Let depth h \u2208 {0, hmax}, m\u0302 = mhmax and\nth def = hmax ( |Im\u0302\u03b4(0)0 |+ |I m\u0302\u03b4(1) 1 |+ \u00b7 \u00b7 \u00b7+ |I m\u0302\u03b4(h) h | ) . (1)\nAfter t \u2265 th iterations, the depth of the deepest expanded optimal node is at least h, i.e., h\u2217t \u2265 h. Proof. First, the lemma holds trivially for h = 0 as h\u2217t \u2265 0. For h > 0, the proof is presented by induction. To this end, let the lemma holds for all h \u2264 h\u0302 < hmax, and we need to show it holds for h\u0302 + 1. Assume that th\u0302+1 iterations have been performed, that is to say, the present iteration is t \u2265 th\u0302+1. As t \u2265 th\u0302+1 \u2265 th\u0302, the induction assumption implies that h\u2217t \u2265 h\u0302. Furthermore, the induction assumption implies that \u03bdmin > m\u0302\u03b4(h\u0302) prior to any iteration at depth h\u0302 + 1 because all the nodes in {Im\u0302\u03b4(h)h }0\u2264h\u2264h\u0302 have been expanded in previous iterations. From Eq. (7) of the main paper and the definition of Imh\u0302+1\u03b4(h\u0302+1)\nh\u0302+1 , we are certain that h\u2217t \u2265 h\u0302 + 1\nif all the nodes in Imh\u0302+1\u03b4(h\u0302+1) h\u0302\nhave expanded. To guarantee their expansions, we need an additional total number of iterations across all depths greater than or equal to\n|Im\u0302\u03b4(h\u0302+1) h\u0302+1 | \u2265 |Imh\u0302+1\u03b4(h\u0302+1) h\u0302+1 | (see Figure 1) times the tree depth hmax (one iteration per depth). In total, the number of iterations is equal to th\u0302+1 and thus h \u2217 t \u2265 h\u0302+ 1."}, {"heading": "A.5 Proof of Lemma 2", "text": "Lemma 2. Let depth h \u2208 {0, hmax}, we have |Im\u0302\u03b4(h)h | \u2264 C(m\u0302\u03b4(h))\u2212d\u0302, where d\u0302 is defined as the m/m\u0302-near-optimality dimension and C the related constant.\nProof. The proof is made by contradiction. To this end, assume there exists some h \u2208 {0, hmax} such that |Im\u0302\u03b4(h)h | > C(m\u0302\u03b4(h))\u2212d\u0302. On the one hand, the definition\n2\n3\nof Im\u0302\u03b4(h)h indicates that their base points are in Ym\u0302\u03b4(h). On the other hand, Assumption 3 of the main paper indicates that cells of nodes at depth h contain a ball of radius m\u03b4(h) = mm\u0302 \u00b7 m\u0302\u03b4(h). Since the cells are disjoint and from Definition 2 of the main paper, we have a contradiction with d\u0302 being the m/m\u0302-near-optimality dimension."}, {"heading": "A.6 Proof of Theorem 2", "text": "Theorem 2. (r(t) for EMBEDDEDHUNTER) Let us define h(t) as the smallest h \u2265 0 such that:\nChmax\nh(t)\u2211\nl=0\n(m\u0302\u03b4(l))\u2212d\u0302 \u2265 t (2)\nwhere t is the number of iterations. Then the regret of EMBEDDEDHUNTER is bounded as:\nr(t) \u2264 min{\u03c4(h) + \u03b4(h) | h \u2264 min(h(t), hmax + 1)} . (3)\nProof. From the definition of h(t) and Lemma 2, a bound on th(t)\u22121 of Eq. (1) can be written as follows.\nth(t)\u22121 = hmax\nh(t)\u22121\u2211\nl=0\n|Im\u0302\u03b4(l)l |\n\u2264 Chmax h(t)\u22121\u2211\nl=0\n(m\u0302\u03b4(l))\u2212d\u0302\n< t .\nThen, by Lemma 1 and the fact that EMBEDDEDHUNTER does not expand nodes beyond hmax, h\u2217t \u2265 min(h(t) \u2212 1, hmax). Thus, we know that the optimal branch of nodes {Yh,i\u2217p}0\u2264h\u2264min(h(t),hmax+1) have been visited and evaluated at least once and for which the best function value achieved among {f\u2217h,i\u2217p}0\u2264h\u2264min(h(t),hmax+1) is at most min{\u03c4(h) + \u03b4(h) | h \u2264 min(h(t), hmax + 1)} away from the optimal value f\u2217. Therefore, the regret of the algorithm is upper bounded as in Eq. 3."}], "references": [{"title": "Modifications of the Direct Algorithm", "author": ["J.M. Gablonsky"], "venue": "PhD thesis, North Carolina State University,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Global optimization in action: continuous and Lipschitz optimization: algorithms, implementations and applications, volume 6", "author": ["J\u00e1nos Pint\u00e9r"], "venue": "Springer Science & Business Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}], "referenceMentions": [], "year": 2016, "abstractText": "Random embedding has been applied with empirical success to large-scale black-box optimization problems with low effective dimensions. This paper proposes the EMBEDDEDHUNTER algorithm, which incorporates the technique in a hierarchical stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple-run framework in which random embedding has been conventionally applied similar to stochastic black-box optimization solvers. Our proposition is motivated by the bounded mean variation in the objective value for a low-dimensional point projected randomly into the decision space of Lipschitz-continuous problems. In essence, the EMBEDDEDHUNTER algorithm expands optimistically a partitioning tree over a low-dimensional\u2014equal to the effective dimension of the problem\u2014search space based on a bounded number of random embeddings of sampled points from the low-dimensional space. In contrast to the probabilistic theoretical guarantees of multiple-run randomembedding algorithms, the finite-time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm\u2019s number of iterations. Furthermore, numerical experiments were conducted to validate its performance. The results show a clear performance gain over recently proposed random embedding methods for large-scale problems, provided the intrinsic dimensionality is low. Introduction Problem. This paper is concerned with the large-scale black-box optimization problem given a finite number of function evaluations. Mathematically, the problem has the form: minimize f(x) subject to x \u2208 X , (1) where f : X \u2286 R \u2192 R and n 10. Without loss of generality, it is assumed that X = [\u22121, 1], and there exists at least one global optimizer x\u2217 whose objective value is denoted by f\u2217, i.e., minx\u2208X f(x) = f(x\u2217) = f\u2217. Solving the optimization problem (1) is notoriously difficult as the sole source of information about its objective function f is available through a black-box or an oracle, which one can query Copyright c \u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. for the value of f at a specific solution (point ) x \u2208 X . Highorder information (e.g., derivatives) are unavailable symbolically nor numerically or are tedious to compute compared to zero-order information\u2014i.e., point-wise function evaluations. Thus, the task is to find the (or one) optimal solution x\u2217 \u2208 X to (1) or a good approximation using a finite number v of function evaluations, which is commonly referred to as the evaluation budget. The quality of the returned solution x(v) \u2208 X after v function evaluations, denoted by f\u2217 v , is assessed by the regret, r(v) = f\u2217 v \u2212 f\u2217 . (2) Besides the aforementioned challenging nature of black-box problems, the high dimensionality n of the decision space X poses another challenge towards finding the global optimum. Despite their witnessed success, the effectiveness of most black-box optimization algorithms is restricted to moderate dimensions (typically, n < 100) and they do not scale well to high-dimensional (say, n 10) problems. As the dimensionality increases, the number of evaluations (sampled points) required to cover X increases exponentially. Despite the curse of dimensionality, it has been noted that for artificial intelligence (AI) applications, most dimensions of certain classes of the associated optimization problems do not affect the objective function significantly. In other words, such problems have low effective dimensionality, e.g., hyper-parameter optimization for neural and deep belief networks (Bergstra and Bengio 2012). Related Work. The literature on black-box optimization is huge and we only highlight here works that are closely related to the paper\u2019s contribution. The bulk of algorithmic work on large-scale black-box optimization has been following one of two approaches: decomposition and embedding. Decomposition algorithms break the problem into several subproblems, and solutions for the original problem are recognized in a coordinated manner. In (Kandasamy, Schneider, and P\u00f3czos 2015), Bayesian optimization was scaled to high-dimensional problems whose objectives have an additive structure. i.e., the function f is the sum of several sub-functions with smaller dimensions, such that no two sub-functions share one or more variables. On the other hand, Friesen and Domingos (2015) proposed to decompose the function into approximately locally independent sub-functions and optimize them separately. Chen et ar X iv :1 61 1. 08 77 3v 1 [ cs .A I] 2 7 N ov 2 01 6 al. (2010) addressed interdependent sub-functions and proposed to consider all entries of the decision vector x independent and discover their relations gradually. In general, decomposition methods employ axis-aligned decomposability, which may limit their applicability. Embedding algorithms exploit the assumption/empirical observation of low effective dimensionality. Chen, Krause, and Castro (2012) presented a variable selection method to discover the effective axis-aligned subspace, while Djolonga, Krause, and Cevher (2013) sought to learn the effective subspace using a low-rank matrix recovery technique. In (Carpentier, Munos, and others 2012), compressed sensing was applied to deal with linear-bandit problems with a high degree of sparsity. Recent works\u2014motivated by the empirical success of random search in leveraging low effective dimensionality without knowing which variables are important (Bergstra and Bengio 2012)\u2014presented random embedding techniques based on the random matrix theory (Wang et al. 2013; Kaban, Bootkrajang, and Durrant 2013) and provided probabilistic theoretical guarantees. In (Qian and Yu 2016), the Simultaneous Optimistic Optimization (SOO) algorithm (Munos 2011) was scaled via random embedding. Problems, whose all dimensions are effective but many of them have a small bounded effect, were addressed in (Qian, Hu, and Yu 2016) where the random embedding technique was incorporated in a sequential framework. In general, random embedding methods employ multiple runs to substantiate the probabilistic theoretical performance. Our Contributions. This paper aims to tackle large-scale black-box optimization (1) based on the random embedding technique. Previous propositions put the technique in a framework of multiple runs\u2014be it parallel (Qian and Yu 2016) or sequential (Qian, Hu, and Yu 2016)\u2014to maximize the performance guarantee. In this paper, we seek to break away from the multiple-run framework and follow the optimism in the face of uncertainty principle, or so-called optimistic optimization. To this end, we incorporate the random embedding technique in a stochastic hierarchical bandit setting and present EMBEDDEDHUNTER: an algorithmic instance of the sought approach. Similar to other optimistic methods, EMBEDDEDHUNTER iteratively expands a partitioning tree over a low-dimensional space Y based on randomly projecting sampled points to the original highdimensional space X once or more times. This approach is motivated by the proof that the mean variation in the objective function f value for a point y \u2208 Y projected randomly to f \u2019s decision spaceX is bounded for objective functions that are Lipschitz-continuous. EMBEDDEDHUNTER\u2019s regret (2) is upper bounded in terms of the number of iterations required to expand near-optimal nodes in the (effective) low-dimensional space based on the Lipschitz continuity assumption and that random embedding can preserve local distance. The rest of the paper is organized as follows. First, a formal motivation is presented, followed by an introduction to EMBEDDEDHUNTER. Then, the algorithm\u2019s finite-time performance is studied and complemented by an empirical validation. Towards the end, the paper is concluded. Optimistic Optimization Meets Random Embeddings Optimistic methods, i.e., methods that implement the optimism in the face of uncertainty principle have proved to be viable for black-box optimization. Such a principle finds its foundations in the machine learning field addressing the exploration-vs.-exploitation dilemma, known as the multi-armed bandit problem. Within the context of function optimization, optimistic approaches formulate the complex problem of optimization (1) over the space X as a hierarchy of simple bandit problems (Kocsis and Szepesv\u00e1ri 2006) in the form of space-partitioning tree search. At step t, the algorithm optimistically expands a leaf node (partitions the corresponding subspace) that may contain the global optimum. Previous empirical studies have shown that optimistic methods\u2014e.g., SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016)\u2014are not suitable for problems with high dimensionality. Random embedding has emerged as a practical tool for large-scale optimization with an experimental success and probabilistic theoretical guarantees. It assumes the problem (1) has an implicit low effective dimension d much lower than the explicit (original) dimension n. In essence, for an optimizer x\u2217 \u2208 X = [\u22121, 1] and a random matrix A \u2208 Rn\u00d7d whose entries are sampled independently from a normal distribution, there exists a point y\u2217 \u2208 Y = [\u2212d/\u03b7, d/\u03b7] such that its Euclidean random projection to X , PX (Ay\u2217), is x\u2217 with a probability at least 1 \u2212 \u03b7 where \u03b7 \u2208 (0, 1). That is to say, f(PX (Ay\u2217)) = f(x\u2217) = f\u2217. The Euclidean random projection of the ith coordinate [y]i to [X ]i is defined as follows.", "creator": "LaTeX with hyperref package"}}}