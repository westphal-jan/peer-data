{"id": "1612.00347", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2016", "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data", "abstract": "we present a useful method for inducing new dialogue systems from very small amounts entirely of unannotated dialogue data, showing readily how word - level exploration using reinforcement learning ( modeling rl ), combined with an incremental and semantic grammar - created dynamic syntax ( ds ) - allows systems to discover, generate, and understand many new dialogue variants. the method avoids the use of expensive and time - consuming dialogue act annotations, and supports more natural ( incremental ) dialogues networks than turn - based systems. here, language constraint generation and dialogue quality management are treated as a joint decision / optimisation problem, and the mdp model for rl is constructed automatically. with an implemented actor system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. the variants include question - answer pairs, over - and under - answering, self - and other - corrections, clarification interaction, split - utterances, and ellipsis. this generalisation property results from the structural knowledge and constraints present within the embedded ds grammar, and highlights some limitations of recent systems built using machine learning techniques only.", "histories": [["v1", "Thu, 1 Dec 2016 16:49:04 GMT  (488kb,D)", "http://arxiv.org/abs/1612.00347v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.HC", "authors": ["dimitrios kalatzis", "arash eshghi", "oliver lemon"], "accepted": false, "id": "1612.00347"}, "pdf": {"name": "1612.00347.pdf", "metadata": {"source": "CRF", "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data", "authors": ["Dimitris Kalatzis", "Arash Eshghi", "Oliver Lemon"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Recent data-driven machine learning approaches treat dialogue as a sequence-to-sequence generation problem, and train their models from large datasets, e.g. [13, 12, 11]. As a result, while these systems reproduce patterns found in training data, they do not exploit any structural knowledge about language encoded in grammars and formal models of dialogue. However, the interpretation of many context-dependent utterances in dialogue depends on the underlying structure and content of prior dialogue turns (see e.g. [10, 3] for how clarification requests are interpreted). In consequence, models that rely on surface features of the dialogue alone (i.e. words) may have limitations in handling such data (e.g. by providing a relevant response), even if they have observed the relevant sequences often. Furthermore, as these systems do not parse to logical forms (i.e. a compositional, interpretable representation), they do not allow for inference, and this further limits their application since such a system has no notion of why or how it acts the way it does, and so cannot explain its actions or reasoning.\nFor these reasons, we explore how formal grammars and dialogue models can be combined with machine learning methods, where linguistic knowledge is used to bootstrap new dialogue systems from very small amounts of unannotated data. This also has the important benefit of reducing\n\u2217This research is funded by the EPSRC, under grant number EP/M01553X/1 (BABBLE project: http:// sites.google.com/site/hwinteractionlab/babble). Eshghi and Lemon developed the overall method and wrote the paper. Eshghi is the main developer of DS-TTR and its integration with RL. Kalatzis integrated with Deep RL and ran the experiments.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n61 2.\n00 34\n7v 1\n[ cs\n.C L\n] 1\nD ec\n2 01\ndeveloper effort. In addition, we learn dialogue policies at the word-level, rather than turn level \u2013 producing more natural dialogues that are known to be preferred by users (e.g. [1], and see examples in figure 2)."}, {"heading": "2 Inducing Dialogue Systems", "text": "Our overall method combines incremental dialogue parsing and Reinforcement Learning for system utterance generation in context. We employ a Dynamic Syntax (DS) parser [8] for incremental language understanding and tracking of the dialogue state using Eshghi et al.\u2019s model of feedback in dialogue [3, 4], and a set of transcribed successful dialogues D in the target application domain.\nTo automatically construct a Markov Decision Process for D we induce it using DS as described in section 2.1. We define the state encoding function F : C \u2192 S , where any c \u2208 C is a DS context and s \u2208 S is a (binary) state vector. For more details see section 2.2. Finally we define the action set as the DS lexicon L (i.e. MDP actions are words) and the reward function R, which is described in section 2.4. We then use Reinforcement Learning to train a policy \u03c0 : S \u2192 L, where L is the DS Lexicon, and s = F(c) \u2208 S , where c is the (incrementally constructed) dialogue context as output by DS at any point in a dialogue. The system is trained in interaction with a (semantic) simulated user, also automatically built from the dialogue data \u2013 see section 2.3.\nThe resulting learned policy forms the combined (incremental) DM and NLG components of a dialogue system for D: i.e. a jointly optimised action selection mechanism for DM and NLG, with DS providing the language understanding component. We now go into the details of the above steps:"}, {"heading": "2.1 Inducing the MDP state space", "text": "We induce an MDP state space from the relevant semantic features in the dialogue data D by tracking all and only those semantic features which are relevant in that domain. These constitute the goal contexts reached in the dialogues in D, expressed as Record Types (RT) in Type Theory with Records [2]; where each feature is in the form of an atomic (i.e. non-decomposable) RT - usually a predicate, packaged together with its argument fields (see Fig 1 for example RT features). Importantly for us here, the standard subtype relation v can also be defined for RTs, and is used in the state encoding function (section 2.2).\nTo induce the MDP state space, we parse all di \u2208 D using DS, generating a set of final success contexts, {c1, . . . , cn}. We take the Maximally Specific Common Supertype (MCS \u2013 see [6]) and abstract out the domain \u2018slot values\u2019. This process has been dubbed \u2018delexicalization\u2019 in recent work [13, 5], but we note that while this has previously been done on the dialogue surface level, either by hand or via an external domain ontology, here we do it automatically.This results in the goal contexts for D, containing the semantic features to be tracked in the MDP state space. Finally, we proceed to decompose these into their constituent, atomic semantic features that will go on to be encoded by the state encoding function.\nFor example, the semantic RT features being tracked in Fig. 1 have resulted from automatically decomposing goal contexts of D in the consumer electronics domain. From left to right, these correspond roughly to the following: \u201cthere is something that\u2019s a brand\u201d; \u201cthere is a liking (or wanting, or all equivalents) event in the present tense\u201d; \u201cthere is something made by that brand\u201d; \u201cthe subject of the liking event is the user\u201d;\u201cthe object of the liking event is the thing by that brand\u201d."}, {"heading": "2.2 The state encoding function", "text": "As shown in figure 1 the MDP state is a binary vector of size 2 \u00d7 |\u03a6|, i.e. twice the number of the RT features. The first half of the state vector contains the grounded features (i.e. agreed by the participants) \u03c6i, while the second half contains the current semantics being incrementally built in the current dialogue utterance.\nFormally the state vector is given by: s = \u3008F1(c), . . . , Fm(c), F1(c), . . . , Fm(c)\u3009; where Fi(c) = 1 if c v \u03c6i, and 0 otherwise. (Recall that v is the RT subtype relation)."}, {"heading": "2.3 Semantic User Simulation", "text": "Unlike most other dialogue systems, ours isn\u2019t based on dialogue act representations, and is word-byword incremental. In this setup the notion of a dialogue turn has no clear definition. Turns are here defined by the user simulator that interrupts system generation according to boundaries encountered in the data. The rules for interrupting system generation and outputting a user utterance are extracted automatically from the unlabeled dialogue data (D) via incremental parsing using DS. Intermediate contexts and user utterances occurring in the dialogue are recorded for use by the simulator. As these rules are semantic, they generalise across different interactional variants by assigning user utterances to matched dialogue contexts. If the simulator cannot match the contexts, the system output is considered out-of-domain and is penalised. Formally, the extracted rules for the simulator are of the form: sem\u2192 {u1, . . . , un}; where sem is the current semantics of some prior system turn, and, the ui are the utterances (strings) output by the user in that context, as observed in D."}, {"heading": "2.4 Reinforcement Learning method", "text": "We have adapted and used Karpathy\u2019s [7] implementation of Mnih et al.\u2019s [9] Deep Q-Learning algorithm, to use a deep neural network to estimate the Q-function.\nThe Reward Function is: R(s) = \u22121.0 in the case of out-of-context, ungrammatical, or lengthy utterances; R(s) = 1.0 when the agent reaches the final (goal) context; and R(s) = 0.0 otherwise.\nWe have trained policies with this method which are able to successfully perform dialogues in the domain of electronics sales, see figure 2."}, {"heading": "3 Evaluation", "text": "We have bootstrapped a system using this method from only a single dialogue, showing that incremental dialogue systems can be automatically created from small amounts of transcribed dialogue data. Besides reducing development time and cost (since it requires no annotated data), our system discovers (and can process) many interactional variations not found in the training data. For example, figure 2, shows several structural dialogue variants that have been discovered by the system (via RL policy exploration), when it has been given only a single training dialogue. The training dialogue was: \u201cSYS \u2013 What would you like?; USR \u2013a phone; SYS\u2013 by which brand?; USR \u2013 by Apple.\u201d\nThe benefits of such incremental dialogue variants have been empirically established in prior work (e.g. [1]). Our work shows the additional benefits of combining linguistic knowledge with machine learning methods: minimising the role of the dialogue engineer, and rapid domain transfer. Ongoing\nwork involves integrating this method with an end-to-end spoken dialogue system framework, and more substantial evaluation with real users. We are also employing this method for the task of learning perceptually grounded language [14]."}], "references": [{"title": "Incremental dialogue system faster than and preferred to its nonincremental counterpart", "author": ["Gregory Aist", "James Allen", "Ellen Campana", "Carlos Gallo", "Scott Stoness", "Mary Swift", "Michael Tanenhaus"], "venue": "In Annual Conference of the Cognitive Science Society,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2007}, {"title": "Records and record types in semantic theory", "author": ["Robin Cooper"], "venue": "Journal of Logic and Computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2005}, {"title": "Feedback in conversation as incremental semantic update", "author": ["A. Eshghi", "C. Howes", "E. Gregoromichelaki", "J. Hough", "M. Purver"], "venue": "In Proceedings of the 11th International Conference on Computational Semantics (IWCS 2015),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "DS-TTR: An incremental, semantic, contextual parser for dialogue", "author": ["Arash Eshghi"], "venue": "In Proceedings of Semdial 2015 (goDial), the 19th workshop on the semantics and pragmatics of dialogue,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Pomdp-based dialogue manager adaptation to extended domains", "author": ["Millica Gas\u0306i\u0107", "C. Breslin", "M. Henderson", "D. Kim", "M. Szummer", "B. Thompson", "P. Tsiakoulis", "S. Young"], "venue": "In Proc. SIGDIAL,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Probabilistic type theory for incremental dialogue processing", "author": ["Julian Hough", "Matthew Purver"], "venue": "In Proc. EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "ConvNetJS: A javascript library for training deep learning models", "author": ["Andrej Karpathy"], "venue": "https://github.com/karpathy/convnetjs,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Dynamic Syntax: The Flow of Language Understanding", "author": ["Ruth Kempson", "Wilfried Meyer-Viol", "Dov Gabbay"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2001}, {"title": "Playing Atari with Deep Reinforcement Learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Alex Graves", "Ioannis Antonoglou", "Daan Wierstra", "Martin Riedmiller"], "venue": "In NIPS Deep Learning Workshop", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Clarifying noun phrase semantics", "author": ["Matthew Purver", "Jonathan Ginzburg"], "venue": "Journal of Semantics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le"], "venue": "arXiv, (1506.05869v3),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Multi-domain neural network language generation for spoken dialogue systems", "author": ["Tsung-Hsien Wen", "Milica Ga\u0161i\u0107", "Nikola Mrk\u0161i\u0107", "Lina M. Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Steve Young"], "venue": "In Proc. NAACL,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "A network-based end-to-end trainable task-oriented dialogue system", "author": ["Tsung-Hsien Wen", "David Vandyke", "Nikola Mrk\u0161i\u0107", "Milica Ga\u0161i\u0107", "Lina M. Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young"], "venue": "arXiv preprint:", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2016}, {"title": "Training an adaptive dialogue policy for interactive learning of visually grounded word meanings", "author": ["Yanchao Yu", "Arash Eshghi", "Oliver Lemon"], "venue": "In Proceedings of SIGDIAL 2016,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}], "referenceMentions": [{"referenceID": 12, "context": "[13, 12, 11].", "startOffset": 0, "endOffset": 12}, {"referenceID": 11, "context": "[13, 12, 11].", "startOffset": 0, "endOffset": 12}, {"referenceID": 10, "context": "[13, 12, 11].", "startOffset": 0, "endOffset": 12}, {"referenceID": 9, "context": "[10, 3] for how clarification requests are interpreted).", "startOffset": 0, "endOffset": 7}, {"referenceID": 2, "context": "[10, 3] for how clarification requests are interpreted).", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[1], and see examples in figure 2).", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "We employ a Dynamic Syntax (DS) parser [8] for incremental language understanding and tracking of the dialogue state using Eshghi et al.", "startOffset": 39, "endOffset": 42}, {"referenceID": 2, "context": "\u2019s model of feedback in dialogue [3, 4], and a set of transcribed successful dialogues D in the target application domain.", "startOffset": 33, "endOffset": 39}, {"referenceID": 3, "context": "\u2019s model of feedback in dialogue [3, 4], and a set of transcribed successful dialogues D in the target application domain.", "startOffset": 33, "endOffset": 39}, {"referenceID": 1, "context": "These constitute the goal contexts reached in the dialogues in D, expressed as Record Types (RT) in Type Theory with Records [2]; where each feature is in the form of an atomic (i.", "startOffset": 125, "endOffset": 128}, {"referenceID": 5, "context": "We take the Maximally Specific Common Supertype (MCS \u2013 see [6]) and abstract out the domain \u2018slot values\u2019.", "startOffset": 59, "endOffset": 62}, {"referenceID": 12, "context": "This process has been dubbed \u2018delexicalization\u2019 in recent work [13, 5], but we note that while this has previously been done on the dialogue surface level, either by hand or via an external domain ontology, here we do it automatically.", "startOffset": 63, "endOffset": 70}, {"referenceID": 4, "context": "This process has been dubbed \u2018delexicalization\u2019 in recent work [13, 5], but we note that while this has previously been done on the dialogue surface level, either by hand or via an external domain ontology, here we do it automatically.", "startOffset": 63, "endOffset": 70}, {"referenceID": 6, "context": "We have adapted and used Karpathy\u2019s [7] implementation of Mnih et al.", "startOffset": 36, "endOffset": 39}, {"referenceID": 8, "context": "\u2019s [9] Deep Q-Learning algorithm, to use a deep neural network to estimate the Q-function.", "startOffset": 3, "endOffset": 6}, {"referenceID": 0, "context": "[1]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "We are also employing this method for the task of learning perceptually grounded language [14].", "startOffset": 90, "endOffset": 94}], "year": 2016, "abstractText": "We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar Dynamic Syntax (DS) allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include questionanswer pairs, overand under-answering, selfand other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.", "creator": "LaTeX with hyperref package"}}}