{"id": "1701.02145", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jan-2017", "title": "Shallow and Deep Networks Intrusion Detection System: A Taxonomy and Survey", "abstract": "intrusion detection has attracted a considerable interest from researchers and industries. the community, after many years of research, still faces the problem of building reliable and efficient ids that are capable of independently handling large quantities of data, corresponding with noticeable changing patterns in real time processing situations. the work version presented in this manuscript classifies intrusion detection systems ( ids ). moreover, a taxonomy and survey of shallow and deep networks intrusion detection systems is presented based on previous and current works. this taxonomy and survey reviews machine hard learning techniques and their performance in detecting anomalies. indirect feature selection which influences the effectiveness of machine learning ( ml ) ids is discussed to explain the role of feature selection in the classification and clinical training phase of ml ids. finally, a discussion of the false and true positive alarm rates is presented to help researchers critically model reliable and efficient machine memory learning based intrusion detection systems.", "histories": [["v1", "Mon, 9 Jan 2017 11:46:58 GMT  (1296kb)", "http://arxiv.org/abs/1701.02145v1", null]], "reviews": [], "SUBJECTS": "cs.CR cs.LG", "authors": ["elike hodo", "xavier bellekens", "rew hamilton", "christos tachtatzis", "robert atkinson"], "accepted": false, "id": "1701.02145"}, "pdf": {"name": "1701.02145.pdf", "metadata": {"source": "CRF", "title": "Shallow and Deep Networks Intrusion Detection System: A Taxonomy and Survey", "authors": ["Elike Hodo", "Xavier Bellekens", "Andrew Hamilton", "Christos Tachtatzis"], "emails": ["elike.hodo@strath.ac.uk", "x.Bellekens@abertay.ac.uk"], "sections": [{"heading": null, "text": "and industries. The community, after many years of research, still faces the problem of building reliable and efficient IDS that are capable of handling large quantities of data, with changing patterns in real time situations. The work presented in this manuscript classifies intrusion detection systems (IDS). Moreover, a taxonomy and survey of shallow and deep networks intrusion detection systems is presented based on previous and current works. This taxonomy and survey reviews machine learning techniques and their performance in detecting anomalies. Feature selection which influences the effectiveness of machine learning (ML) IDS is discussed to explain the role of feature selection in the classification and training phase of ML IDS. Finally, a discussion of the false and true positive alarm rates is presented to help researchers model reliable and efficient machine learning based intrusion detection systems.\nKeywords\u2014 Shallow network, Deep networks, Intrusion detection, False positive\nalarm rates and True positive alarm rates\n1.0 INTRODUCTION\nComputer networks have developed rapidly over the years contributing significantly to social and economic development. International trade, healthcare systems and military capabilities are examples of human activity that increasingly rely on networks. This has led to an increasing interest in the security of networks by industry and researchers. The importance of Intrusion Detection Systems (IDS) is critical as networks can become vulnerable to attacks from both internal and external intruders [1], [2].\nAn IDS is a detection system put in place to monitor computer networks. These have been in use since the 1980\u2019s [3]. By analysing patterns of captured data from a network, IDS help to detect threats [4]. These threats can be devastating, for example, Denial of service (DoS) denies or prevents legitimate users resource on a network by introducing unwanted traffic [5]. Malware is another example, where attackers use malicious software to disrupt systems [6].\nIntrusion detection systems evolved as a response to these situations. Many IDS have been developed but have experienced the problem of false positive or false negative alarms. These are the false recognition of an attack by the IDS and increases the difficultly for network administrators to handle intrusion reports. Researchers in this field aim at developing IDS that have a high accuracy of detection and low false alarm rate [7]. Another problem of some existing IDS is their inability to detect unknown attack types. These IDS rely on the signatures of known attacks.\nHuman independent IDS that incorporate machine learning techniques have been developed as a solution to these problems. Machine learning IDS learns from normal traffic and abnormal traffic by training on a dataset to predict an attack by using classification. Several machine learning techniques have been successfully implemented as classifiers on IDS but present numerous flaws such as low throughput and high false detection rates [7].\nThe taxonomy (or classification) presented within this manuscript is highly relevant in the present study due to the highly diverse types of systems and attacks [8], [9]. The taxonomy will aid constructing two objectives: a clear description of the current state of IDS and the guide lines in which to explore the complexity of it [10], [11].\nThe paper aims to provide a clear description and guidelines needed to understand intrusion detection systems based on results from existing works in various papers. Its organisation gives a broader view of IDS and aims at addressing the concerns and solutions of shallow and deep learning IDS. The paper also compares previous works and their performance metrics.\nThe second objective of the paper is to present a survey and the classification of Intrusion Detection Systems, taxonomy of Machine Learning IDS and a survey on shallow and deep networks IDS.\n2.0 INTRUSION DETECTION SYSTEMS\nIntrusion detection systems are strategically placed on a network to detect threats and monitor packets. The IDS accomplishes this by collecting data from different systems and network sources and analysing the data for possible threats [12]. The functions of the IDS include offering information on threats, taking corrective steps when it detects threats and recording all important events within a network [13]. Figure 2 shows a model of Intrusion detection system"}, {"heading": "2.1 Classification of Intrusion detection system", "text": "Different researchers have developed different classification representations. H.Debar et al[14], S.Axelsson et al.[15], S.Amer et al.[16], C.Xenakis et al.[17], Hung-Ten Lia et al.[18], have previously presented intrusion detection surveys and taxonomies. This research builds upon their work and introduces deep networks technique which all these referenced works do not describe. With the increasing value of big data, deep networks is an important element to capture in an IDS taxonomy The taxonomy presented within this work provides a fine-grained overview of the different machine learning techniques for intrusion detection systems as shown in Figure 2.1. The detection mainly depends on the source of data and intrusion technique used. The Source of data is the nodes that gather the information for analysis. The source can be either host or network based or both. These two sources are further discussed in section 2.1.1. The detection technique also differentiates between the anomaly based and signature based detection techniques. The different techniques that fall in the class of anomaly and signature based are important to develop a taxonomy that gives a broader view of techniques and the capabilities in detecting attacks. Section 2.1.2 and 2.1.3 explains anomaly based and signature based techniques in detail. These techniques operate either as self-learning or programmed. In Self-learning class, the system automatically learns whilst in programming class a user teaches the system. The classification presented Fig.2.1 will help draw conclusions on detection accuracy and false alarm rates of IDS techniques."}, {"heading": "2.1.1 Host Based IDS (HIDS) Vs. Network Based IDS (NIDS)", "text": "Host based IDS were the first type of IDS to be implemented [19]. HIDS are software based products installed on a host computer that analyse and monitor all traffic activities on the system application files and operation system [20], [21]. The traffic activities gathered by the system application files and system [20] are called the audit trails [22]\u2013[24]. HIDS has an\nadvantage of being able to detect threats from within by scanning through the traffic activities before sending and receiving data [25]. Its main disadvantage is that only monitors the host computer, meaning it has to be installed on each host [26].\nNetwork based IDS are found at specific points on the network to capture and analyse the stream of packets going through network links, unlike the HIDS whose approach is to analyse each host separately [27] [28], [29]. It has the advantage of having a single system monitoring an entire network, saving time and cost of installing software on each host. NIDS main disadvantage is its vulnerability to any intrusion originating from the network targeting a system within the network."}, {"heading": "2.1.2 Anomaly Based Detection", "text": "Anomaly Based Detection is a behavioural based intrusion detection system. It observes changes in normal activity within a system by building a profile of the system which is being monitored [31], [32]. The profile is generated over a period of time when the system is established to have behaved normally [33]. One advantage is that it offers the ability to detect attacks which are new to the system [34]. Anomaly detection is categorised into two, based on the way a normal profile of a system is specified.\n1) Self-learning \u2013 The self-learning system operate by example with a baseline set for\nnormal operation. This is achieved by building a model for the underlying processes with the observed system traffic built up over a period of time [15]. Self-learning systems are sub-divided into the following main categories: time series model and machine learning. Section 3 discusses machine learning technique in detail.\n Time series model takes into account the sequence of observation in order of\nsuccession occurring in intervals of uniformity. If the probability of occurrence of a new observation at a time is negligible then it is considered a change in normal behaviour. Time series has an advantage of observing trends of behaver over a period of time and flagging it, if it notices a change in normal behaviour. It is an effective model when attacks are sequential over a period of time [35]. This model has a disadvantage of being more costly\ncomputationally [36]. Auto regressive moving average (ARMA) is an example of time series model used as IDS. In Predictive Modelling for Intrusions in Communication Systems using generalised autoregressive moving average (GARMA) and ARMA models by [37] et al. fitted ARMA(1,1) and GARMA(1,2;\ud835\udeff,1) time series models to 4 types of attacks (DoS, probe, U2R and L2R). The parameter estimation was done using Hannan-Rissanen algorithm, Whittle estimation and Maximum likelihood estimation and the point forecast obtained through Whittle estimation and maximum likelihood were close to the original value. The time series models were able to forecast the attack but the performance of GARMA (1, 2; \ud835\udeff, 1) in attack detection was better.\n.\n2) Programmed \u2013 A programmed model is when a system needs either a user or an\nexternal person to teach the system to detect changes in behaviour. The user decides the extent of abnormal behaviour in the system and flags an intrusion threat [35]. The programmed models are grouped into four categories: threshold, simple rule based, and statistical models.\n Threshold models can be considered as the simplest programmed descriptive\nstatistical detector [15]. By correlating and analysing statistical data, a user can program the system at a pre-defined threshold of alarm on a statistical variable. Careful selection of the threshold is required to minimise the false alarm rate. Instances where the threshold set too high leads to a risk of missing an alarm when an intruder is performing a malicious action [38]. A typical example is setting an alarm if three attempts to login to a system are unsuccessful [39]. In anomalous payload-based network intrusion detection [40], Ke Wang et al. presented a payload base anomaly detection by demonstrating the effectiveness on 1999 DARPA dataset and a live dataset collected form the US Columbia CS department network. In training phase, a profile byte frequency distribution was computed and the standard deviation of application payload connected to a single host and port. During the detection phase the Mahalanobis distance was used to calculate the similarity of new data against the pre-computed profile. The detector compared this measure against a threshold and generated an alert when the distance of the new input exceeded this threshold. It recorded nearly 100% in accuracy with 0.1% false positive rate for port 80 traffic.\n Simple rule based is an approach for detection is to monitor events within a\nsystem that trigger a rule either than what is considered as a normal behaviour for the user. One limitation of this model is its failure to detect a threat that is not programmed as a rule in the system [41]. RIPPER (repeated incremental pruning to produce error reduction) is an example of rule based model that builds a set of rules to detect normal behaviour and abnormal behaviour. R.Naidu et al[42] used KDDCup \u201999 dataset to compare the performance of RIPPER rule, decision tree(C5) and support vector machine(SVM). The\ndataset was categorised into 3 (NORMAL, probe attacks and DoS attacks). The RIPPER rule algorithm went through two stages during the experiment. The first stage initialised the rule conditions and the second stage the rule optimisation. The algorithm obtained conditions in each rule to classify the testing data. The RIPPER rule recorded a total detection rate of 98.69%, C5 98.75% and SVM 98.63%.\n Statistics model collects data in a profile. Analysing the profile of normal\nstatistical behaviour gives a description shown by the patterns from data to help make conclusions if an activity is normal or abnormal. The system then develops a distance vector for the observed traffic and the profile. An alarm is raised by the system when the distance is great enough [15],[14], [36], [43]. These models are sub categorised into four: mean/standard deviation, multivariate, Markov process and operational model. Dorothy Denning [44] discusses model based on the hypothesis that security violation can be detected by monitoring a system\u2019s audit records for changes in pattern. The model includes profiles for representing the behaviour of subjects with respect to objects in terms of metrics and statistical models and rules for acquiring knowledge about this behaviour from audit records and detecting anomalous behaviour. a) Mean, standard deviation and any other form of correlations are known as\nmoments in statistics [35], [45]. A moment is said to be anomalous when events fall either above or below a set interval. Decisions are made taking system change into account by altering statistical rule set for the system [35]. Its advantage over the operational model is its ability to detect attacks without having prior knowledge of the normal activities to set its limits. Rather it learns form observations to determine its normal activities [35]. It is a complex model that has more flexibility than the threshold model. It does not require prior knowledge to determine the normal behaviour to help set pre-defined threshold. Varying the mean and standard deviations slightly changes the computation by putting extra weights on the more recent values [35]. A.Ashfag et al[46] proposed a standard deviation normalised entropy of accuracy hybrid method of intrusion detection. Two real traffic dataset were used. The endpoint dataset comprising 14months of traffic traces on a diverse set of 13 endpoints. The dataset was reduced to 6weeks of traffic for testing and training purposes. The endpoints were infected with different malware attacks. The second was attack data dataset was obtained from two international network locations at Lawrence Berkeley National laboratory, USA on three distinct days. Using 9 prominent classifiers on the two datasets showed 3%-10% increase in detection rate and 40% decrease in false alarm rate over the existing classifiers can be achieved with the proposed hybrid technique. b) Multivariate models are similar to the mean and standard deviation model\n[35], [47]. The multivariate models are based on correlations between two or more metrics. They use multiple variables to predict possible outcomes. For example the number of CPU cycles can be compared to how long a\nlogin session is completed [47]. Theoretically this model could have a fine distinction over one variable [47]. In an approach by W.Sha et al.[48], multivariate time series and high-order Markov chain were taken into account along the detailed design of training and testing algorithms. The models were evaluated using DARPA dataset. Observing the multi order Markov chain showed that the relative positions between results from models of different orders provide a new effective indication for anomalies. To improve sensitivity, a combining multiple sequences as a multivariate one into a simple model was applied and proved that the return of values of the system calls also play an important role in detection. c) Markov process has two approaches: Markov chains and hidden Markov\nmodels. The Markov model is a set of finite states interconnected going through a stochastic process to determine the topology and capabilities of a model [36]. Each stage in the process depends on the outcome of the previous stage. The anomalies are detected [35] by comparison of the associated probability recorded for the process with a fixed threshold. This gives it an advantage of detecting unusual multiple occurrence of events [47]. The hidden Markov model assumes the system to be a Markov process where stochastic processes with finite states of possible outcomes are hidden [36]. Ye Nong [49] presented an anomaly technique using Markov chain model to detect intrusion. In this model, Markov chain was used to represent a temporal profile of normal behaviour in a computer and network system. The Markov chain model of the normal profile is learned from the historic data of the system\u2019s normal behaviour. The observed behaviour of the system is analysed to see if the Markov chain model of the normal behaviour supports the observed behaviour. A low probability of support indicates an anomalous behaviour meaning an intrusion. The technique was implemented on the Sun Solaris system and distinguished normal activities from attacks perfectly."}, {"heading": "2.1.3 Signature Based Detection", "text": "Signature based detection defines a set of rules used to match the patterns in the network traffic. If a mismatch is detected it raises an alarm [50]. It has an advantage of being able to detect attacks giving a low false positive detection ratio [51] It has a drawback of being able to detect only attacks known to the database [19]. Signature based detection systems are programmed with distinct decision rules. The rules set for detection are coded in a straight forward manner to detect intrusion. They are programmed in four categories: state modelling, expert system, and string matching.\n State modelling is the encoding of attacks as a number of different states in a finite\nautomaton. Each of these attacks has to be observed in the traffic profile to be considered as an intrusion. They occur in sub-classes as time series models [15]: the first is state transition which was proposed by Porras et al. which uses a state transition diagram to represent intrusion [52]. The approach in [52]models intrusion as a series of state transitions which are described as signature action and states descriptions. State diagrams were written to correspond to the states of an actual\ncomputer system. The basis of a rule based expert system to detect intrusions was formed by these diagrams. The intrusions are in the form of a simple chain transitioning from start to end. The second is the petri-net where states form a petrinet. They form a tree structure where the transition states are not in any order [15][53].\n Expert systems contain a set of rules used to describe attacks scenarios known to the\nsystem. The given rules that describe the attack scenarios are often forward-chaining systems. A production based expert system tool has been used since they best handle systems with new events entering into the system. The size of the rule based increases as the execution speed increases since the rule will go through a longer list. It is however vulnerable to attacks not known to the set rules [2]. P.Zhisong et al.[54], presented an intrusion detection system model based on neural network and expert system. The aim of the experiment was to take advantage of classification abilities of neural network for probe and Dos attacks and expert based for U2R and R2L attacks. KDD Cup\u201999 dataset was employed in the experiment. Expert system was able to improve the detection accuracy using the detection rules: ALERT UDP ENET any <- > HNET 31337 MESSAGE:\"BO access\" DATA: |ce63 d1d2 16e7 13cf 3ca5 a586|\".\n String matching is a process of knowledge acquisition just as Expert system but has a\ndifferent approach in exploiting the knowledge [14]. It deals with matching the patterns in the audit event generated by the attack but not involved in the decision making process [47]. This technique has been used effectively commercially as an IDS [55], [56]. It is noted that not all signature based IDS can be represented by a simple pattern which gives it a limitation [57]. T.Sheu et al.[58]proposed an efficient string matching algorithm with compact memory as well as high worst-case performance. A magic number heuristic based on the Chinese remainder theorem was adopted. The algorithm significantly reduced the memory requirements without bringing complex processes. The latency of off-chip memory references was drastically reduced. It was concluded the algorithm gives a cost effective and an efficient IDS."}, {"heading": "2.1.4 Discussion", "text": "A summary table of intrusion techniques, source of data, applications and data used in selected reviewed papers between 2014 and 2016 is shown in Table II.\nH. Toumi et al. [65] 2015 Signature NIDS Cloud computing Real Life M. Guerroumi et al. [66] 2015 Signature HIDS Internet of things (IoT) Real Life N. Dipika et al. [67] 2015 Anomaly NIDS Information\nsystems\nKDD99 Cup\nW.Haider et al. [68] 2015 Anomaly HIDS Cyber space KDD98\nand UNM\nN.Aissa et al. [69] 2015 Anomaly NIDS Computer systems KDD99 H. Omessaad [70] 2015 Signature HIDS Cloud computing Real Life X. Lin et al. [71] 2015 Signature NIDS Transport Real Life S. Banerjee et al. [72] 2015 Signature/ Anomaly NIDS Computer systems Real Life P. Satam [73] 2015 Anomaly NIDS Telecommunication Real Life\nRecent works have shown that works are still on-going using the Intrusion technique and source of data techniques. S.Vasudeo et al. [63] presented a hybrid of Signature and Anomaly with a hybrid of data source on a real life dataset. S.Banerjee et al.[72]also combined signature and anomaly technique on real life dataset. Other referenced works the table applied single techniques on real life datasets and KDD Cup datasets. The application of these techniques cut across all areas to determine their effectiveness in detecting intrusion.\n3.0 MACHINE LEARNING TECHNIQUES\nAnomaly detection systems are human-independent. They detect anomalies by revealing abnormal characteristics in a system over a period of time [44]. The effectiveness of this technique is its capabilities to differentiate between normal and abnormalities within a network.\nMachine Learning (ML) can provide IDS methods to detect current, new and subtle attacks without extensive human-based training or intervention. It is defined as a set of methods that can automatically detect patterns to predict future data trends [74],[75]. Whilst a large number of machine learning techniques exist, the fundamental operation of all of them relies upon optimal feature selection. These features of are the metrics which will be used to detect patterns and trends. For example, one feature of a network is the packet size: machine learning techniques may monitor the packet size over time and generate distributions from which conclusions may be drawn regarding an intrusion. This section reviews the feature selection of machine learning IDS and classification of machine learning techniques used as IDS in Figure 3."}, {"heading": "3.1 IDS feature selection", "text": "Machine learning classification involves two phases: the classification phase and training phase. The training phase learns the distribution of the features and during the classification phase the learned features is applied as a normal profile where any abnormality will be detected [76], [77]. A.K. Jain et al. [78] developed a model of statistical pattern recognition as shown in Fig.3. The test and training data are normalised in the processing unit as well as removing noise form the data. In the training phase, the feature extraction unit extracts a representation feature set from the processed training data which are used in training a classifier. In the classification phase, the trained classifier is applied to assign the test data to the selected features from the training phase [77].\nA high quality of training data is required to achieve the best performance of ML IDS. The training data thus contain both normal and abnormal patterns [76]. Features are the important information extracted form from raw data and are important in classification and detection which influence the effectiveness of ML IDS. In [79], C. Kruegel et al. created attacks containing system call sequences similar to normal system call. Kruegel et al. addressed the issue by analysing on the system call arguments instead of finding the relations between sequences of actions [76]. Table III. Shows the features extracted by Kruegel et al. for four different arguments.\nIn [80], V. Mahoney et al. extracted features by analysing each header-field of network packets and flows. The proposed approach det6ected anomalies in a network based on 33 fields of IP, UDP, TCP, ICMP and Ethernet protocols. Table IV shows some of the extracted features.\n8 ICMP Code 17 Ethernet Destination\n9 ICMP Type 18 Ethernet Protocol\nIn [81], W. Lee et al. extracted features from TCP/IP connections. Experiment was conducted on 1998 DARPA dataset where a set of basic features from domain knowledge was extracted. Most of the basic features could only be extracted after the TCP connection was terminated leading to a delay in the detection phase [76]. The 1998 DARPA dataset is categorised into five. These are NORMAL and four different types of attack. The attacks are: Dos attacks, probe attack, User to root (U2R) attack and Remote to local (R2L) attacks. Dos attack which denies or prevents legitimate users resource on a network or system by introducing useless or unwanted traffic. Probe is an attack which scans through a computer network to make a profile of information for future attacks. U2R is attacks use a local account from a remote machine to gain access to the targets system due to vulnerabilities in its operating system. R2L attacks are initiated to gain unauthorised access to root privileges from outside. Table V. illustrates the basic features of individual TCP connections by W. Lee et al.\n15 srv_count\nNumber of connections to the same service as the current 1connection in the past 2seconds continuous\n16 srv_serror_rate Percentage of connections having \u201cSYN\u201d errors\ncontinuous\n17 srv_rerror_rate\nPercentage of connections having \u201cREJ\u201d errors\ncontinuous\n18 srv_diff_host_rate Percentage of connections to different host\n36\nnum_file_creations\nNumber of file creation operations continuous\n37 num_shells Number of shell prompts continuous\n38\nnum_access_files\nNumber of operations in access control files\ncontinuous\n39\nnum_outbound_cmd\nNumber of outbound commands in an ftp session\ncontinuous\n40 is_hot_login\n1 if the login belongs to the \u201chot\u201d list; 0 otherwise\ndiscrete\n41 is_guest_login 1 if the login is a \u201cguest\u201d login; 0 otherwise discrete\nW. Lee et al. discovered many attacks such as R2L and U2R were in the payloads of packets. This prompted a proposal to combine features extracted from the payload with domain knowledge. They called the features \u201ctime based traffic\u201d features for connection records. Features 10 to 18 in table VI are extracted using a 2second time window with 11 to 15 having same host connection and 16 to 18 having same service connection, 19 to 28 in Table VII are extracted from a window of 100 connections with 20 to 24 same host connection and 25 to 28 same service connection. 29 to 41 in Table VIII are features extracted from connections suggested by domain knowledge [77]. Both tables provide a detailed insight mapping the most current and meaningful features for machine learning intrusion detection systems."}, {"heading": "3.2 Classification of Machine Learning Techniques", "text": "This section gives an extensive classification of ML techniques. Each of the techniques is described in detail and how these techniques have been applied as IDS. Figure 3.1 shows the classification of Machine learning IDS.\n Bayesian Networks are graphical modelling tools used to model the probability of\nvariables of interest. They are directed acrylic graphs where each node represents a discrete random variable of interest. Each node contains the states of the random variable in tabular form representing the conditional probability table (CPT) which specifies conditional probabilities of the domain variable with other connected variables. The CPT of each node contains probabilities of the node being in a specific state given the domain variable states. The existence of the relationship between the nodes of the domain variable and connected variables in a Bayesian networks show the direction of causality between other connected variables. Thus the connected variables are causally dependent on the ones represented by the domain variable. Given a set of discrete random variable \ud835\udc4b = {\ud835\udc651, \ud835\udc652 \u2026 \ud835\udc65\ud835\udc5b}, the joint probability of the variable can be computed based on Bayes Rule as:\n\ud835\udc43(\ud835\udc651, \ud835\udc651 \u2026 \ud835\udc65\ud835\udc5b) = \u220f \ud835\udc43(\ud835\udc65\ud835\udc56\\\ud835\udc5d\ud835\udc4e(\ud835\udc65\ud835\udc56)) \ud835\udc5b \ud835\udc61=1 (1)\nwhere \ud835\udc5d\ud835\udc4e(\ud835\udc65\ud835\udc56) represents the specific values of the variables in the domain variable node of \ud835\udc65\ud835\udc61 [82], [83]. This technique has generally been used as an intrusion detection system. A. Onik et al.[84] Conducted an experiment using Bayesian networks on NSL-KDD dataset containing 25,192 records with 41 features. Apart from the normal class label it contained 4 more class of attacks known as Dos, U2R, R2L and probe attacks. The filter approach of feature selection was used to reduce the dataset features from 41 to 16 important features. Bayesian model was built and proved to predict attacks with superior overall performance accuracy rate of 97.27% keeping the false positive rate at a lower rate of 0.008. The model as compared to Na\u00efve Bayes, K-means clustering, decision stamp and RBF network recorded 84.86%, 80.75%, 83.31% and 91.03% respectively in terms of accuracy. An experiment by M. Bode et al.[85] Analysed the network traffic in a cyber situation with Bayesian network classifier on the KDD Cup\u201999 dataset with 490,021 records. The data set was made up of 4 types of attacks (DoS, U2R, R2L and probe). In this experiment, they adopted the risk matrix to analyse the risk zone of the attacks. The risk analysis adopted showed DoS was most frequent attack in occurrences. The results showed Bayesian network classifier is a suitable model resulting in same performance level classifying the DoS attacks as association rule mining. Bayesian network classifier outperformed Genetic Algorithm in classifying probe and U2R attacks and classified Dos equally.\n Genetic Algorithm (GA) is an adaptive search method in a class of evolutional\ncomputation using techniques inspired from convolutional biological process. The principle is based on a stochastic global [25] search method initialising with a random generation of chromosomes. The chromosomes are called population. They evolve through selection, crossover and mutation as shown in Figure 3.2. Each chromosome represents a problem to be solved and encoded as strings. The positions of the chromosomes are commonly represented as binary (0, 1) or as a list of integers. These positions sometimes referred to as genes keep changing at each initialisation. The solution created during each generation is based on an evaluation function. The selection is thus based on the chromosome fitness level [86], [87].\nTao Xia et al. [88] developed a hybrid method based information theory and GA. Information theory was used to filter out the most important features out of 41 features in KDD\u201999 dataset with 494021 records. Linear rule was used initially to classify normal and abnormal before GA to obtain the appropriate classification. In the detection of Dos, U2R, R2L and probe attacks, the information theory and GA hybrid method recorded 99.33%, 63.64%, 5.86% and 93.95% as detection rates respectively. The detection rates were compared to Ctree and C5. Ctree recorded 98.91%, 88.13%, 7.41% and 50.35% whilst C5 recorded 97.1%, 13.2%, 8.4% and 83.3% respectively for the attacks.\nIn layered approach for intrusion detection systems based GA, M. Padmadas et al.[89] Proposed a method to overcome the weakness in a single layer intrusion detection system. The layered approach is based on GA with the four layers corresponding to four groups of attacks (probe, DoS, U2R and R2L). Each layer is trained separately with a number of features where the layer acts as a filter to block any malicious activity. In layered approach there is no mathematical approach to calculate the filter parameters for the attacks. This paper presented GA approach in calculating the filter parameters making the system more secure. The model efficiently detected R2L attack and recorded an accuracy of 90% in detection.\n Support Vector Machines (SVM) is a machine learning algorithm that learns to\nclassify data using points labelled training examples falling into one or two classes. The SVM algorithm builds a model that can predict if a new example falls into one category or the other [90],[25], [91] . Figure 3.3 shows a hyperplane defined by (\ud835\udc64, \ud835\udc4f), where \ud835\udc64 is a weight and \ud835\udc4f bias constructed in a finite space of the training sample \ud835\udc41 with points:\n{(\ud835\udc651, \ud835\udc661)(\ud835\udc652, \ud835\udc662 \u2026 (\ud835\udc65\ud835\udc41, \ud835\udc66\ud835\udc41))} (2)\nWhere \ud835\udc65\ud835\udc56 \u2208 \ud835\udc45 \ud835\udc51\ud835\udc4e\ud835\udc5b\ud835\udc51 \ud835\udc66\ud835\udc56 \u2208 {1, \u22121}. This is conducted since in general the larger the margin, the lower the generalisation error of the classifier [92].\nB. Senthilnayaki et al.[93] Used GA pre-processed KDD Cup 99 dataset in a preprocessing module for data reduction since it was complex to process the dataset with all 41 features. GA was used to select 10 features out of 41 features present in the KDD Cup 99 dataset and applied SVM for classification. The experiment was carried out with 100,000 records from the dataset out of which 95% was used as training data and remaining 10% as test data. The classification process continued till a 10 fold cross validation was done for results verification. The SVM classified four different attacks (DoS, probe, U2R, R2L attacks). The performance of SVM classifier was compared with four other classifiers as shown in table IX.\nAnother experiment by L.Teng et al. [94]proposed a novel method integrating PCA and SVM by optimising the kernel parameters using automatic parameter selection technique. The experiment was performed on KDD Cup\u201999 dataset containing five categories of traffic (normal, DoS attack, R2L attack, U2R attack and probe attack). Each network record had 41 features of which 7 were discrete and 34 continuous features. C parameter for RBF kernel of SVM was optimised by the proposed automatic parameter reduction along with cross validation to reduce the training and testing time to give better accuracy in detecting attacks.\n K-Nearest Neighbour (K-NN) is a fundamental technique for sample classification.\nThis technique is known to be non-parametric and highly efficient in classification [95]. It evaluates the class labels of the test samples [96] based on the majority of test sample neighbours. The parameter \ud835\udc58 is determined by the user. Based on the test sample, \ud835\udc58 numbers of training points are determined by taking the closest distance to the test sample. The prediction of the test sample is the \ud835\udc58 nearest neighbours [97]. A hybrid method of intrusion detection system by Y.Canbay et al.[96]proposed combination of K-NN and GA algorithm. They tested the hybrid algorithm on KDD Cup 99 dataset labelled out of five classes; normal, probe attack, Dos attack, R2L attack and U2R attack. The dataset was reduced to 1000,2000,3000,4000 and 5000 records respectively with 19 features. GA was used to select the \ud835\udc58 nearest neighbour for K-NN classifier. Three experiments were performed to conclude on the hybrid method. Each experiment used 10 fold cross validation with different \ud835\udc58 values. The values in in terms of accuracy were compared with the conventional K-NN. The proposed hybrid method proved better than conventional K-NN in all values of \ud835\udc58 used in the experiment.\nOn the same dataset Q.Zeng et al. [98]compared the performance of K-NN and SVM model and RIPPER method in detecting attacks. The multi attribute decision was adopted in this experiment. In the classification of an unknown document vector \ud835\udc4b, \ud835\udc58\u2013nearest neighbour algorithm ranks the document\u2019s neighbour among the training document vectors and uses the class labels of the \ud835\udc58 most similar neighbours to predict the class of the new document. The similarity in each neighbour to \ud835\udc4b is used to determine the classes of the neighbour where the similarity is measured by the Euclidean distance between two document vectors. With this adoption they categorised each new program behaviour in the dataset into either normal or attack class. Each system call was treated as a word and each process as a document. \ud835\udc58 was varied between 15 and 35 till an optimal value of 19 found. The classification was performed with K-NN and SVM model. The Hit rate was compared to the RIPPER method. The results showed 97.26% accuracy rate and 6.03% false alarm rate for KNN and SVM model whilst the RIPPER method gave 87.26% accuracy rate and 8.6% false positive rate.\n Decision Tree (DT) algorithm learns and models a data set in classification problems.\nIt classifies new data set according to what it has learnt from previous data set [99]. It uses a well-defined criterion in the selection of best features of each node tree during their construction. A decision tree model has a root node linking to different nodes as attribute data deciding the path for each node [100]. Decisions are made by comparison of previous data and marked as leaves [101]. A common decision tree approach is the C4.5 algorithm. In network intrusion detection system using decision tree (J48) by S.Sahu et al. [102] a labelled data set called Kyoto 2006+ was used. The data consist of 24 features, 14 of which was extracted form KDD Cup 99 dataset and an additional ten important features. The Perl language was used to extract 15 features from the dataset for the experiment. The sample dataset contained 134665 records; 44257 normal, 86649 known attacks and 3759 unknown attacks. Decision tree (J48) built using WEKA 3.6.10 tool was used to classify normal, known attacks and unknown attacks in the network packets. The results showed the decision tree generated classified 97.23% correctly and 2.67% incorrectly. The simulation results showed decision tree can classify unknown attacks as well. T.Komviriyavut et al.[101]presented two intrusion detection techniques which were decision tree (C4.5) and RIPPER rules to test an online dataset (RLD09 dataset). RLD09 dataset was collected from actual environment and refined to have 13 features. The dataset is categorised into three; normal, DoS attack and Probe attack. The experimental data set had 3,000 records of three types of unknown probe attacks each with 1,000 attack records. Initial experiment with known attacks on dataset showed a total detection rate of about 98% for both decision tree and RIPPER rule. A second experiment on the same data set with three unknown probe attacks (advance port scan, Xmas tree and ACK scan) was performed. The decision tree maintained its detection rate of 98% whilst the RIPPER rule degraded to about 50%in average.\n Fuzzy logic (FL) concept is derived [103] from the fuzzy sets theory which deals\nwith approximately reasoning with uncertainty and imprecision [104] by human being. The features this technique which handles real life uncertainty makes it\nattractive for anomaly detection. Intrusion detection involves the classification of a normal class and an abnormal class. The well-defined nature of the two classes makes this computation paradigm a helpful one. A.Toosi et al.[105]introduced a new approach using different soft computing techniques into classification system to classify abnormal behaviour form normal depending on the attack type. This work investigated neuro-fuzzy networks, fuzzy inference and GA on KDD Cup 99 10% dataset. The dataset had a distribution of normal and four different attacks (probe, DoS, R2L and U2R). A set of parallel neurofuzzy classifiers were used initially for classification. The fuzzy inference system was based on the output of the neuro-fuzzy classifier determining normal or abnormal activity. The best results were attained by optimising the structure of the fuzzy decision tree with GA.\n Clustering is the division of data with no apparent distinguished differences into\ngroups by functions of two or more parameters. Each group is called a cluster and have no similarity. The greater the dissimilarity the better the grouping. Their class labels are always unknown. K-means is an example of clustering algorithm used as IDS [106],[107]. K-means algorithm makes use of the Euclidean distance to calculate the data and the cluster centre. The aim is to have a minimum distance within a cluster and achieve a maximum distance between clusters by the minimisation of an objective function [108].\nLi Jun Tao et al.[109]proposed a k-means clustering with dynamic adjustable number of cluster. They introduced an algorithm that uses an improved Euclidean distance formula to calculate the distance between the data and cluster centre by automatically adjusting the number of cluster when the distance is more than the threshold. This experiment was performed on KDD Cup\u201999 dataset containing four attacks (DoS, Probe, R2L and U2R). The total number of dataset records was 72471. The improved k-means algorithm recorded 77 clusters with a detection rate of 90% and false positive rate of 15%. The results compared to the traditional k-means were 108 clusters, detection rate of 85% and false positive rate of 42%."}, {"heading": "3.3 Analytical Comparison of ML Techniques", "text": "The various ML techniques discussed in the above section are different in their capabilities to classify attacks. Table X. analyses the advantages and disadvantages in the performance of ML techniques.\nVector Machine mathematically.\n-All computations are performed in space using kernels giving it an edge to be used practically.\nforward. -Slow in training and requires more memory space.\nK-Nearest Neighbour Easy to implement and can solve\nmulti-class problems\n-Slow in training and requires large memory space. -It is computationally complex because to classify a test sample involve the consideration of all training samples.\nDecision tree -It has a unique structure therefore\neasy to interpret. -It has no limitation in handling high dimensional data sets.\n-If trees are not pruned back it causes overfitting. -Type of data must be considered when constructing tree. (i.e. Categorical or numerical)\nFuzzy Logic -It is based on human reasoning\nconcepts which are not precise. -It gives a representation of uncertainty.\n-It\u2019s construction has a high level of generality there by high consumption of resource.\nK-means Algorithm Simple to implement and effective -The outcome of clustering depends on how\ncluster centres are initialised to specify k value. -The algorithm works for only numerical data."}, {"heading": "3.4 ML Hybrid Techniques", "text": "ML Intrusion detection systems have generally been used to detect attacks but in recent times, using two or more different techniques to form a hybrid has improved the overall performance. Table XI. Shows accuracy of detection, type of attacks and data set for selected reviewed ML IDS papers from 2011-2016.\nal. [115]\n2016\nProbe\nShi-Jin Horng et al. [116] 2011 SVM + hierarchical clustering algorithm\nDoS,R2L,U2R and Probe KDDCup99 95.72%\nE. Hodo et al.[117] 2016 ANN DDoS/Dos Real Life 99.4%\nAs demonstrated in Table XI, the majority of Intrusion Detection Systems using machine learning have tested their work against the KDDCup99 dataset or the NSL-KDD, in contrast only two recent studies tested their machine learning systems against real network data."}, {"heading": "3.5 Binary Classification metrics", "text": "The effectiveness of prediction by the ML algorithm which is either 1 or 0 is based on confusion matrix prediction outcome as shown Table IX. The outcomes are True Negative (TN), True Positive (TP), False Positive (FP) and False Negative (FN) [118], [119].\nTable IX. Confusion Matrix\nPredicted Class\nNegative Class(Normal)\nPositive Class(Attack)\nActual Class\nNegative Class(Normal) True\nNegative(TN)\nFalse Positive(FP)\nPositive Class(Attack) False\nNegative(FN)\nTrue Positive(TP)\n True Negative (TN): a measure of the number of normal events rightly classified\nnormal.\n True Positive (TP): a measure of attacks classified rightly as attack.\n False Positive (FP): a measure of normal events misclassified as attacks.\n False Negative (FN): a measure of attacks misclassified as normal.\nThe following are the basic metrics used to calculate the performance of ML IDS:\nTrue negative rate (Specifity) = \ud835\udc47\ud835\udc43\n\ud835\udc39\ud835\udc43+\ud835\udc47\ud835\udc41 (3)\nTrue positive rate (Sensitivity) = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc41 (4)\nFalse positive rate (Fallout) = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc41 = 1 \u2212 \ud835\udc46\ud835\udc5d\ud835\udc52\ud835\udc50\ud835\udc56\ud835\udc53\ud835\udc56\ud835\udc61\ud835\udc66 (5)\nFalse negative rate (Miss Rate) = \ud835\udc39\ud835\udc41\n\ud835\udc39\ud835\udc41+\ud835\udc47\ud835\udc43 = 1 \u2212 \ud835\udc46\ud835\udc52\ud835\udc5b\ud835\udc60\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc56\ud835\udc61\ud835\udc66 (6)\nPrecision = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc43 (7)\nRecall = \ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc41 (8)\nOverall accuracy= \ud835\udc47\ud835\udc43+\ud835\udc47\ud835\udc41\n\ud835\udc47\ud835\udc41+\ud835\udc47\ud835\udc43+\ud835\udc39\ud835\udc41+\ud835\udc39\ud835\udc43 (9)\nA commonly used ML IDS metric is detection rate. This is defined as the number of data examples correctly classified divided by the test examples.\n4.0 ARTIFICIAL NEURAL NETWORK AND DEEP NETWORKS IDS\nThis section reviews artificial neural network (ANN) and Deep learning which use the computational intelligence approach to detect attacks."}, {"heading": "4.1 Artificial Neural Network", "text": "Artificial neural network consist of information processing elements known to mimic neurons of the brain. ANN is categorised into supervised and unsupervised learning. Figure 4 shows the types of ANN."}, {"heading": "4.1.1 Supervised Learning", "text": "In supervised learning, the neural network is provided with a labelled training set which learns a mapping from inputs \ud835\udc65 to outputs \ud835\udc66 given a labelled set of inputs-output pairs\n\ud835\udc51 = {(\ud835\udc65\ud835\udc56, \ud835\udc66\ud835\udc56)}\ud835\udc56=1 \ud835\udc41 (10)\nWhere \ud835\udc51 is called the training set and \ud835\udc41 is the number of training examples. It is assumed that \ud835\udc66\ud835\udc56 is a categorical variable from some infinite set \ud835\udc66\ud835\udc56 \u2208 {1 \u2026 \ud835\udc36} [120]. Two types of supervised learning algorithms are used to train a neural network for intrusion detection.\n Multilayer Perceptron (MLP) is a feedforward neural network. The structure of MLP\nconsists of one or more nodes as the inner layer between the input and output nodes as shown in Figure 4.1. The most common technique used to train the MLP neural\nnetwork is the Back Propagation hence the name MLP-BP. The construction of the MLP-BP neural network is by putting layers of non-linear elements to form complex hypotheses. The more stages that are added (nodes) the more advance the hypotheses. Each node takes an element of a feature vector. The output nodes give an output of two classes (normal and attack). The interconnection between the nodes is associated with scalar weights with an initial weight assigned to the connection. During training, the weights are adjusted. Evaluating the hypotheses is done by setting the input modes in a feed-back process and the values are propagated through the network to the output. At this stage the gradient descents is used so as to push the error in the output node back through the network by a back propagation process in order to estimate the error in the hidden nodes. The gradient of the cost \u2013 function can thus be calculated [99], [121].\nIn [122], P. Barapatre et al.[122]experimented with neural network having an input layer, one hidden layer and one output layer. In this experiment, the input node had 41 features from KDD Cup\u201999 dataset. The output node was to classify normal or attack present in dataset. If the output node is \u20180\u2019 then it is labelled \u201cnormal\u201d and if \u20181\u2019 it is labelled \u201cattack\u201d. The learning rate was initially set to 0.1 and the system retrained to reduce learning rate. A sigmoid activation function was used and values corresponding to the weights randomly initialised between -1 and -. The system was trained for each category of attacks (DoS, Probe, U2R and R2L attacks) to determine the performance of the algorithm on individual attacks. Table IIX shows the experimental results. It was concluded MLP-BP neural network detected DoS and Probe attacks more accurately than U2R attacks. It observed an increase in rate of classification as rate of learning decreases giving rise to a slow convergence. Also reducing the rate of learning and the sum squared error (SSE) values and re-training the network showed an improvement in rate of detection.\ntaking a measurement of the distance between the inputs and the centre of hidden neurons [118]. Figure 4.2 is an RBF architecture showing the input nodes, one hidden nodes and output. Each RBF has different parameters with an input vector. The network output is thus a linear combination of the radial basis function\u2019s output. The input and hidden nodes weights are always 1 since the transfer function of the network is a Radial basic function. This allows an adjustment on the weight between the hidden nodes and the output [123].\nC.Zhang et al.[124] compared the performance of RBF and MLP-BP in detection detecting four different types of attacks on KDD Cup\u201999 dataset. Both training and testing data contained 1000 records which were selected from the dataset. In this experiment each sample was unique with 34 numerical features and 7 symbolic features. The symbolic features were converted to ASCII numbers before being used as training or testing data. The results showed RBF achieved better performance than MLP-BP with a detection rate of 99.2% and false positive rate of 1.2%. MLP-BP showed a detection rate of 93.7% and false positive rate of 7.2%.\nJu Jiang et al. [125]applied RBF and Back propagation algorithm (BPL) to both misuse and anomaly detection. The experiment was performed on KDD Cup \u201899 dataset containing 4,900,000 records categorised into 5 (normal, probe attacks, DoS attacks, R2L attacks and U2R attacks). The misuse detection network had 41 input features, 4 hidden nodes and 4 output nodes representing normal probe, DoS and R2L classes respectively. The anomaly network also had 41input features, 1 hidden node and 1 output node to classify normal and attacks behaviour. The experimental results showed in misuse detection, RBF based IDS performed similarly to BPL based IDS. However RBF used a shorter time in training as compared to BPL based IDS and needed to adjust its decision thresholds. In anomaly detection, the BPL based IDS had to adjust itself output threshold manually according to the characteristics of the training dataset to achieve best performance. In anomaly detection RBF based IDS out performed BPL based IDs. Bi Jing et al. [123] compared RBF and MLP-BP using a processed KDD Cup \u201999 dataset by converting al strings to numeric , reducing the dimension of the dataset and determining the rational value domain. The features were reduced from 41 to 31 to train both RBF and MLP-BP. The RBF structure used had one hidden layer and output neuron being the weighted sum of all the output items of the hidden layer. The simulation results showed RBF network is better than MLP-BP in its property of having a more regular out with shorter training time and better accuracy in attack detection."}, {"heading": "4.1.2 Unsupervised learning", "text": "In unsupervised learning, the neural network is only provided with input data without conceptualising the output: it discovers patterns within the data autonomously. The data yet to be discovered is called unlabelled data [120]. Two typical unsupervised learning are SelfOrganisation Maps (SOMs) and Adaptive Resonance theory (ART).\n Self-Organisation Maps\nSOMs transform the input of a network into two dimensional feature maps based on the topological properties of SOMs. The computation of feature maps is by Kohonen unsupervised learning. The two dimensional feature maps are neurons represented by coloured squares showing the weights corresponding to each neuron. The inputs are grouped based on their similarity. The more features mapped, the bigger the coloured square. The quality is determined by the back ground colouring of the clusters. Anomaly events can thus be identified by analysing the normal and abnormal events from the mapping [118], [126]. SOMs are widely used anomaly detection systems. P. Lichodajewski et al. in [127] applied SOMs as a Host based intrusion detection system. In this work SOM was trained with an explicit coding of data and gave a clear clustering of abnormal behaviours. In [128], H. Gunes Kayacik et al. investigated and demonstrated with hierarchical SOM architecture with two basic feature sets , one limited to 6 basic features with the others containing all 41-features. The results gave a false positive rate of 1.38% and detection rate of 90.4%.\nV. Kumar et al in [129] presented a unified framework on SOM. Their approach detected attacks on a mobile ad-hoc network (MANET) using different parameters. Their experimental results were found to be better than other neural network approaches in terms of detection rate and false alarm rate.\n Adaptive resonance Theory (ART)\nART as a basic theory is an unsupervised learning model but as a hybrid it performs supervised learning. It functions as a pattern recognition and predictive tool. As an unsupervised learning model, ART-1, ART-2, ART-3 and fuzzy Art makes the list. The supervised models are made up of ARTMAP, Fuzzy ARTMAP and Gaussian ARTMAP [118]. The model compares an input vector to a single neuron\u2019s weight (weight vector) [118], [126]. In [130], M. Chauhan et al. presented a novel technique by uploading the weights of the network based on sign of an evaluation function [131]. An appropriate evaluation function was selected by utilizing the probabilities of various states. It concludes that if the weights in a modified ART network are oscillating, it implies an intrusion and thus the ART network has the capability of detecting any intrusion. A hybrid method by P. Somwang et al. in [132] used principal component analysis (PCA) and fuzzy adaptive resonance theory to identify different attacks on KDD Cup \u201999 data set. The results showed a high performance of detection rate of 96.13% and a false alarm rate of 3.86% of anomaly intrusion detection."}, {"heading": "4.1.3 Summary", "text": "I. Ahmad et al. in [133] evaluated SOMs, ART and MLP-BP in terms of main criteria and sub-criteria using analytic Hierarchy. Evaluation based on main criteria investigated less overhead, maturity, competency, performance and suitability. Sub-criteria investigated cost effective, time saving, detection rate, minimum false positive, minimum false negative, handling varied intrusion and handling coordinated intrusion. Different radar graphs with distinct colours were used for the analysis.\nAnalysing MLP-BP and SOM showed MLP-BP had a better detection rate, minimum false positive, minimum false negative, time saving and cost effective. In the case of less overhead and capability of handling coordinated and varied intrusion, MLP-BP was not as good as SOM. Analysing MLP-BP and ART showed the same results.\nA comparison of ART and SOM showed better results for SOM in terms of less overhead and handling coordinated intrusion. In another scenario ART was better than SOM in terms of detection rate, minimum false negative, maturity, time saving and cost effective.\nIn conclusion, a hybrid ANN approach was found to be the most suitable intrusion detection system in terms of detection rate, false positive, false negative, cost and time saving."}, {"heading": "4.2 Deep Networks", "text": "This section focuses on networks that look like the multilayer perceptron (MLP) but have a different architecture. The difference between the MLP and the deep networks is their training procedures. This is a class of ML techniques where classification is conducted by training data with many layers in hierarchical networks with unsupervised learning. Deep\nnetworks are inspired by the architecture depth of the brain. In 2006, Hinton et al. from the university of Toronto came up with Deep Belief Network (DBN) [134]. They trained data with an algorithm that greedily trains layer by layer using unsupervised learning for each layer of Restricted Boltzmann Machine (RBM) [135]. After this discovery by Hinton et al. other deep networks have been introduced using the same principle have been successful in classification task [136]. Deep networks IDS can be classified based on how the architectures and techniques are being used. Figure 4.3 shows a classification of Deep networks IDS."}, {"heading": "4.2.1 Generative Architecture", "text": "Generative models are also referred to as graphical model because they depict independence/dependence for distribution. They are visualised as graphs that have nodes representing random variables and arcs show the relationship between random variables that can have millions of parameters to graphically represent the given system [136], [137]. The joint statistical distribution of the variables can be written as products of the nodes and their associated variables [136], [138]. The graphical models have hidden variables that cannot be observed. Generative models are associated with supervised learning since their training does not depend on the labels of the data. For classification purposes the models goes through a pre-training stage (unsupervised learning). During this process, each of the lower layers are trained separately from the other layers which allows the other layers to be trained in a greedily layer by layer from bottom to up. All other layers are trained after pre-training [136]. The sub-classes of generative models are Recurrent Neural Network (RNN), Deep AutoEncoder, Deep Boltzmann Machine (DBM) and Deep Believe networks (DBN).\n Recurrent Neural Network (RNN)\nRNN is a class of deep networks that are either considered supervised or unsupervised learning with an input sequential data whose length could be as large as its depth [139]. The RNN model architecture is a feedback loop linking layer by layer with the ability to store data of previous input increasing the reliability of the model [140]. There are two types on the RNN in terms of architecture: Elman and Jordan RNNs. The Elman model has a simple feedback looping layer by layer. The Jordan model has\na feedback looping all neurons within a layer to the next layer. There exists also a feedback connecting a neuron to itself. The ability of the Jordan RNN to store information in the neurons allows it to train less input vector for classification of normal and abnormal patterns with high accuracy [140]. Figures 4.4 and 4.5 are simple architectures of the Elman RNN and Jordan RNN showing the context unit known to store information of the previous output of hidden layer.\nA study by K. Jihyun et al. [141] applied long short term memory (LSTM) architecture to RNN and trained the IDS using KDD Cup \u201899 dataset. By comparing the accuracy with other IDS classifiers, LSTM-RNN recorded 96.93% accuracy with a detection rate of 98.88%. Although the FAR was slightly higher than the others, they concluded its overall performance was the best.\n Deep Auto-Encoder\nThese are energy based deep models classified as generative models in their original form. It comes in different forms mostly also generative models. Other forms are stacked auto encoder and de noising auto encoder a [138].\nAn Auto-Encoder becomes deep when it has multiple hidden layers. It is made up of an input layer unit representing the sample data, one or two hidden layer units where the features are transformed and then mapped to the output layer unit for reconstruction. Training the auto-encoder gives it a \u201cbottleneck\u201d structure where the hidden layer becomes narrower than the input layer to prevent the model from learning its identity function [120].\nUnfortunately, the deep auto encoder when trained with back propagation has not been a success the evaluation gets stuck in local minima with a minimal gradient signal when trained with back propagation. Pre-training a deep auto encoder using the greedy layer wise approach by training each of the layers in turns has proven to alleviate the backpropagation problems [120], [139],[142]. In [143], B. Abolhasanzadeh proposed an approach to detect attacks in big data using deep auto encoder. The experiment was conducted on NSL-KDD data set to test the method of applying bottle neck features in dimensionality reduction as part of intrusion detection. The results in terms of accuracy rate out performed PCA, factor analysis and Kernel/PCA. It was concluded; the results recorded in terms of accuracy makes this approach promising one for real world intrusion detection.\n Deep Boltzmann Machine(DBM)\nDBM is a unidirectional graphical model. Currently there exist no connection between units on the same layer but between the input units and the hidden units. DBM when trained with a large supply of unlabelled data and fine-tuned with labelled data acts as a good classifier [136]. Its structure is an offspring of a general Boltzmann machine (BM) which is a network of units based on stochastic decisions to determine their on and off states [138]. BM algorithm is simple to train but turns to be slow in the process. A reduction in the number of hidden layers of a DBM to one forms a Restricted Boltzmann Machine (RBM) [139]. DBM when trained with a large supply of unlabelled data and fine-tuned with labelled data acts a good classifier. Training a stack of RBM with many hidden layers using the feature activation on one RBM as the input for the next layer leads to the formation of Deep Believe Network (DBN).\n Deep Belief Networks (DBN)\nDBN uses both unsupervised pre training and supervised fine-tuning techniques to construct the models. Figure 4.8 shows a DBN which is made up of a stack of Restricted Boltzmann Machines (RBMs) and one or more additional layers for discrimination task. RBMs are probabilistic generative models that learn a joint probability distribution of observed (training) data without using data labels. Once the structure of a DBN is determined the goal for training is to learn the weights \ud835\udc64 between layers. Each node is independent of other nodes in the same layer given all nodes which gives it the characteristic allowing us to train the generative weights of each RBM [120]. It then goes through a greedy layer by layer learning algorithm which learns each stack of RBM\u2019s layer at a time. In Figure 4.8 left, the top layers in red form a RBM and the lower layers in blue form directed sigmoid believe network [145].\nDBN has been trained as a classifier by N. Gao et al. [146] to detect intrusion by comparing the performance to SVM and ANN. The classifiers were trained on KDD data set. The authors proved that deep learning of DBN can successfully be used as an effective ID. They concluded the greedy layer by layer learning algorithm when used to pre-train and fine-tune a DBN gives a high accuracy in classification. The results showed that DBN recorded the best accuracy of 93.49%, a TP value of 92.33 and FP of 0.76%. Z. Alom et al.[147] also exploited the DBNs capabilities to detect intrusion through series of experiments. The authors trained DBN with NSL-KDD data to identify unknown attack on it. They concluded by proposing DBN as a good IDS based on an accuracy of 97.5% achieved in the experiment. This results was compared with existing DBN-SVM and SVM classifiers which it out performed."}, {"heading": "4.2.1 Discriminative Architecture", "text": "The discriminative architecture uses discriminative power for classification by characterising the posterior distributions of classes conditioned on the input data. Recurrent neural network and convolutional neural network are two types of discriminative architecture.\n Recurrent neural network (RNN) uses discriminative power for classification when\nthe model\u2019s output is an explicit labelled data in sequence with the input data sequence. To train RNN as a discriminative model, training data needs to be presegmented and a post-processing to transform the output to a labelled data [138].\n Convolutional neural network\nA convolutional neural network (CNN) is a type of discrimination deep architecture with one or more convolutional and pooling layers in an array to form a multilayer neural network [139],[148],[149]. In general, convolutional layers share many weights followed by sampling of the convolutional layer\u2019s output by the pooling layer which results in some form of translational invariant properties [139]. CNN has fewer parameters as compared to other connected networks with the same number of hidden units which gives it an advantage of easier training [148]. CNN architecture is that of multi-layer perceptron [150], and are variant of MLP which are inspired biologically. Hubel and Wiesel worked on the cat\u2019s visual cortex and deduced that visual cortex is made up of an arrangement of cells in a complex manner. These cells are sensitive to small sub-regions of the visual field known as the receptive field. These fields are positioned to shield the entire visual field to enable the cell behave just like a local filter over the input space [151]. The series of layers making up a CNN architecture are the convolutional layer, max pooling layer and the fully connected layer [150], [152]. The convolutional layer is made up of neurons forming a rect6angular grid where previous layers are made of neuros shaped as a rectangular grid. The rectangular grid neurons are connected to each other with the inputs from previous rectangular units through a set of weights known as filter banks [149], [152]. These weights for the rectangular units do not change for every rectangular grid of neuron to form convolutional layers. In architectures where the convolutional layer is made up of different grids [152], each grid uses a different filter bank [149], [153]. Each convolutional layer is followed by a pooling layer which\nmerges subsets of the convolutional layer\u2019s rectangular block by taking sub-samples to give an output of the block. The pooling can be done in several ways such as [152] computing the maximum or average or a learned linear summing of neurons in the blocks. Some blocks turn to be shifted more than a row or a column and in turn feed in an s input to neighbouring pooling units. This causes a reduction in the dimension of the system design and thus causing variations to the input [149], [153]. The final stage which has several convolutional and max-pooling layers non-linearly stacked in the neural network form a fully connected layer of network [152]. The connectivity which allows the set of weights of the filter banks to be trained easily [149], [152].\n5.0 Conclusion Shallow and deep networks intrusion detection systems have gained a considerable interest commercially and amongst the research community. With advancement in data sizes, intrusion detection systems should have the characteristics to handle noisy data with high accuracy in detection with high computational speed. This paper gives an overview of the general classification of intrusion detection systems and taxonomy with recent and past works. This taxonomy gives a clear description of intrusion detection system and its complexity. Current studies of deep learning intrusion detection systems have been reviewed in this paper to help address the challenges in this new technique still in its early stages in intrusion detection. In particular recent papers have been reviewed in this work considering all the machine learning techniques including the single and hybrid techniques. The scope of the work on classifying intrusion detection systems, reviewing the various methods of detecting anomaly, performance of these methods were based on past and recent works revealing the advantages and disadvantages of each of them. The focus of the paper on shallow and deep networks described experiments comparing the performance of these learning algorithms. The experiments demonstrated deep networks significantly outperformed the shallow network in detection of attacks. To the best of our knowledge CNN has not been exploited in the field of intrusion detection but has proven to be a good classifier. DBN is also new in its exploitation in this field and experimental works are still in progress to determine the reliability of these learning algorithms to detect attacks. Signature based technique have been in use commercially but have not been able to detect all types of attacks especially if the IDS signature list did not contain the right signature.\nResearch work is in progress experimenting new approaches to test the reliability and efficiency of knowledge based and behavioural approaches in intrusion detection.\nREFERENCE\n[1] N. Chand, P. Mishra, C. R. Krishna, E. S. Pilli, and M. C. Govil, \u201cA comparative\nanalysis of SVM and its stacking with other classification algorithm for intrusion detection,\u201d in 2016 International Conference on Advances in Computing, Communication, & Automation (ICACCA) (Spring), 2016, pp. 1\u20136.\n[2] B. Mukherjee, L. T. Heberlein, and K. N. Levitt, \u201cNetwork intrusion detection,\u201d IEEE\nNetw., vol. 8, no. 3, pp. 26\u201341, May 1994.\n[3] SANS Institute, \u201cThe History and Evolution of Intrusion Detection.\u201d [Online].\nAvailable: https://www.sans.org/reading-room/whitepapers/detection/historyevolution-intrusion-detection-344. [Accessed: 20-Feb-2016].\n[4] R. P. R. I. Sravan Kumar Jonnalagadda, \u201cA Literature Survey and Comprehensive\nStudy of Intrusion Detection,\u201d Int. J. Comput. Appl., vol. 11, no. 81(16), pp. 40\u201347, 2013.\n[5] R. Mitchell and I.-R. Chen, \u201cA survey of intrusion detection techniques for cyber-\nphysical systems,\u201d ACM Comput. Surv., vol. 46, no. 4, pp. 1\u201329, Mar. 2014.\n[6] \u201cInternet of Things: How Much are We Exposed to Cyber Threats? - InfoSec\nResources.\u201d [Online]. Available: http://resources.infosecinstitute.com/internet-thingsmuch-exposed-cyber-threats/. [Accessed: 10-Dec-2015].\n[7] B. W. Masduki, K. Ramli, F. A. Saputra, and D. Sugiarto, \u201cStudy on implementation\nof machine learning methods combination for improving attacks detection accuracy on Intrusion Detection System (IDS),\u201d in 2015 International Conference on Quality in Research (QiR), 2015, pp. 56\u201364.\n[8] P. Sneath and R. R. Sokal, \u201cNumerical taxonomy. The principles and practices of\nnumerical classification,\u201d 1973. [Online]. Available: http://www.brclasssoc.org.uk/books/Sneath/title_contents.pdf.\n[9] M. A., \u201cSIMPSON, GG Principles of animal taxonomy. Columbia University Press,\nNew York: 1990. Pp xii, 247; illustrated. Price: US $21.50. ISBN: 0-231-09650-X (paperback reprint),\u201d Arch. Nat. Hist., vol. 19, no. 1, pp. 124--124, 1992.\n[10] S. Axelsson and Stefan, \u201cThe base-rate fallacy and its implications for the difficulty of\nintrusion detection,\u201d in Proceedings of the 6th ACM conference on Computer and communications security - CCS \u201999, 1999, pp. 1\u20137.\n[11] J. McHugh, \u201cTesting Intrusion detection systems: a critique of the 1998 and 1999\nDARPA intrusion detection system evaluations as performed by Lincoln Laboratory,\u201d ACM Trans. Inf. Syst. Secur., vol. 3, no. 4, pp. 262\u2013294, Nov. 2000.\n[12] D. Rozenblum, \u201cUnderstanding Intrusion Detection Systems,\u201d SANS Inst., no. 122, pp.\n11\u201315, 2001.\n[13] \u201cWhat it is Network intrusion detection system? | COMBOFIX.\u201d [Online]. Available:\nhttp://www.combofix.org/what-it-is-network-intrusion-detection-system.php. [Accessed: 10-Dec-2015].\n[14] H. Debar, M. Dacier, and A. Wespi, \u201cA revised taxonomy for intrusion-detection\nsystems,\u201d Ann. Des T\u00e9l\u00e9communications, vol. 55, no. 7\u20138, pp. 361\u2013378.\n[15] S. Axelsson and S. Axelsson, \u201cIntrusion Detection Systems: A Survey and\nTaxonomy,\u201d 2000. [Online]. Available: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1.6603. [Accessed: 30-Sep2016].\n[16] A. Hafez, S. and hamilton Jr, and A. John, \u201cIntrusion Detection Systems (IDS)\nTaxonomy-A Short Review,\u201d This is a Paid Advert. STN 13-2 June 2010 Defensive Cyber Secur. Policies Proced. 2, p. 23.\n[17] C. Xenakis, C. Panos, and I. Stavrakakis, \u201cA comparative evaluation of intrusion\ndetection architectures for mobile ad hoc networks,\u201d Comput. Secur., vol. 30, no. 1, pp. 63\u201380, 2011.\n[18] H.-J. Liao, C.-H. Richard Lin, Y.-C. Lin, and K.-Y. Tung, \u201cIntrusion detection system:\nA comprehensive review,\u201d J. Netw. Comput. Appl., vol. 36, no. 1, pp. 16\u201324, Jan. 2013.\n[19] H. Debar, M. Dacier, and A. Wespi, \u201cTowards a taxonomy of intrusion-detection\nsystems,\u201d Comput. Networks, vol. 31, no. 8, pp. 805\u2013822, Apr. 1999.\n[20] Sans Penetration Testing, \u201cHost- vs. Network-Based Intrusion Detection Systems,\u201d\n2001. [Online]. Available: https://cyber-defense.sans.org/resources/papers/gsec/hostvs-network-based-intrusion-detection-systems-102574. [Accessed: 24-Feb-2016].\n[21] SANS Institute InfoSec Reading Room, \u201cApplication of Neural Networks to Intrusion\nDetection,\u201d 2001. [Online]. Available: https://www.sans.org/readingroom/whitepapers/detection/application-neural-networks-intrusion-detection-336. [Accessed: 24-Feb-2016].\n[22] A. Mounji and B. Le Charlier, \u201cContinuous assessment of a Unix configuration:\nintegrating intrusion detection and configuration analysis,\u201d in Proceedings of SNDSS \u201997: Internet Society 1997 Symposium on Network and Distributed System Security, 1997, pp. 27\u201335.\n[23] S. S. Soniya and S. M. C. Vigila, \u201cIntrusion detection system: Classification and\ntechniques,\u201d in 2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT), 2016, pp. 1\u20137.\n[24] R. P. R. I. Sravan Kumar Jonnalagadda, \u201cA Literature Survey and Comprehensive\nStudy of Intrusion Detection,\u201d Int. J. Comput. Appl., vol. 81, no. 16, pp. 40--47, 2013.\n[25] Heba Fathy Ahmed Mohamed Eid, \u201cComputational Intelligence in Intrusion Detection\nSystem,\u201d 2013. [Online]. Available: http://scholar.cu.edu.eg/sites/default/files/abo/files/phd_thesis_computational_intellige nce_in_intrusion_detection_system_2013.pdf. [Accessed: 24-Feb-2016].\n[26] S. Mallissery, J. Prabhu, and R. Ganiga, \u201cSurvey on intrusion detection methods,\u201d in\n3rd International Conference on Advances in Recent Technologies in Communication and Computing (ARTCom 2011), 2011, pp. 224\u2013228.\n[27] V. Chandola, A. Banerjee, and V. Kumar, \u201cAnomaly detection,\u201d ACM Comput. Surv.,\nvol. 41, no. 3, pp. 1\u201358, Jul. 2009.\n[28] S. S. Tirumala, H. Sathu, and A. Sarrafzadeh, \u201cFree and open source intrusion\ndetection systems: A study,\u201d in 2015 International Conference on Machine Learning and Cybernetics (ICMLC), 2015, vol. 1, pp. 205\u2013210.\n[29] S. Liu, J. Gong, J. Chen, Y. Peng, W. Yang, W. Zhang, and A. Jakalan, \u201cA flow based\nmethod to detect penetration,\u201d in The 7th IEEE/International Conference on Advanced Infocomm Technology, 2014, pp. 184\u2013191.\n[30] H. Kozushko, \u201cIntrusion detection: Host-based and network-based intrusion detection\nsystems,\u201d Sept., vol. 11, 2003.\n[31] N. K. Mittal, \u201cA survey on Wireless Sensor Network for Community Intrusion\nDetection Systems,\u201d in 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), 2016, pp. 107\u2013111.\n[32] J. Shun and H. a. Malki, \u201cNetwork Intrusion Detection System Using Neural\nNetworks,\u201d 2008 Fourth Int. Conf. Nat. Comput., vol. 5, pp. 242\u2013246, 2008.\n[33] A. G. Tokhtabayev and V. A. Skormin, \u201cNon-Stationary Markov Models and Anomaly\nPropagation Analysis in IDS,\u201d in Third International Symposium on Information Assurance and Security, 2007, pp. 203\u2013208.\n[34] C. Modi, D. Patel, B. Borisaniya, H. Patel, A. Patel, and M. Rajarajan, \u201cA survey of\nintrusion detection techniques in Cloud,\u201d J. Netw. Comput. Appl., vol. 36, no. 1, pp. 42\u201357, Jan. 2013.\n[35] A. Qayyum, M. H. Islam, and M. Jamil, \u201cTaxonomy of statistical based anomaly\ndetection techniques for intrusion detection,\u201d in Proceedings of the IEEE Symposium on Emerging Technologies, 2005., 2005, pp. 270\u2013276.\n[36] P. Garc\u00eda-Teodoro, J. D\u00edaz-Verdejo, G. Maci\u00e1-Fern\u00e1ndez, and E. V\u00e1zquez, \u201cAnomaly-\nbased network intrusion detection: Techniques, systems and challenges,\u201d Comput. Secur., vol. 28, no. 1\u20132, pp. 18\u201328, Feb. 2009.\n[37] T. R. Pillai, S. Palaniappan, A. Abdullah, and H. M. Imran, \u201cPredictive modeling for\nintrusions in communication systems using GARMA and ARMA models,\u201d in 2015 5th National Symposium on Information Technology: Towards New Smart World (NSITNSW), 2015, pp. 1\u20136.\n[38] H. Debar, M. Becker, and D. Siboni, \u201cA neural network component for an intrusion\ndetection system,\u201d in Proceedings 1992 IEEE Computer Society Symposium on Research in Security and Privacy, 1992, pp. 240\u2013250.\n[39] A. M. Richard Heady,George Luger, \u201cThe Architecture of a Network Level Intrusion\nDetection System,\u201d Department of Computer Science ,College of Engineering,University of New Mexico, 1990. [Online]. Available: https://www.researchgate.net/profile/Mark_Servilla/publication/242637613_The_archi tecture_of_a_network_level_intrusion_detection_system/links/5564805a08ae06101ab df482.pdf. [Accessed: 19-Feb-2016].\n[40] K. Wang and S. J. Stolfo, \u201cAnomalous Payload-Based Network Intrusion Detection,\u201d\nSpringer Berlin Heidelberg, 2004, pp. 203\u2013222.\n[41] T. F. Lunt, \u201cA survey of intrusion detection techniques,\u201d Comput. Secur., vol. 12, no.\n4, pp. 405\u2013418, Jun. 1993.\n[42] R. China Appala Naidu and P. S. Avadhani, \u201cA comparison of data mining techniques\nfor intrusion detection,\u201d in 2012 IEEE International Conference on Advanced Communication Control and Computing Technologies (ICACCCT), 2012, pp. 41\u201344.\n[43] D. Anderson, T. Frivold, A. Tamaru, A. Valdes, and B. Release, \u201cNext Generation\nIntrusion Detection Expert System (NIDES), Software Users Manual.\u201d [Online]. Available: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.5048. [Accessed: 19-Feb-2016].\n[44] D. E. Denning, \u201cAn Intrusion-Detection Model,\u201d IEEE Trans. Softw. Eng., vol. SE-13,\nno. 2, pp. 222\u2013232, Feb. 1987.\n[45] K. M. P. V. Jyothsna, V. V. Rama Prasad, \u201cA Review of Anomaly based Intrusion\nDetection Systems,\u201d Int. J. Comput. Appl., vol. 28, no. 7, pp. 26\u201335, 2011.\n[46] A. B. Ashfaq, M. Javed, S. A. Khayam, and H. Radha, \u201cAn Information-Theoretic\nCombining Method for Multi-Classifier Anomaly Detection Systems,\u201d in 2010 IEEE International Conference on Communications, 2010, pp. 1\u20135.\n[47] B. A. Kuperman, \u201cA categorization of computer security monitoring systems and the\nimpact on the design of audit sources,\u201d Purdue Univ. West Lafayette, 2004.\n[48] W. Sha, Y. Zhu, T. Huang, M. Qiu, Y. Zhu, and Q. Zhang, \u201cA Multi-order Markov\nChain Based Scheme for Anomaly Detection,\u201d in 2013 IEEE 37th Annual Computer Software and Applications Conference Workshops, 2013, pp. 83\u201388.\n[49] Y. Nong, \u201cA markov chain model of temporal behavior for anomaly detection,\u201d in\nProceedings of the 2000 IEEE Systems, Man, and Cybernetics Information Assurance and Security Workshop,vol. 166, 2000, p. 169.\n[50] H. Zhengbing, L. Zhitang, and W. Junqi, \u201cA Novel Network Intrusion Detection\nSystem (NIDS) Based on Signatures Search of Data Mining,\u201d in First International Workshop on Knowledge Discovery and Data Mining (WKDD 2008), 2008, pp. 10\u201316.\n[51] H. E. Poston, \u201cA brief taxonomy of intrusion detection strategies,\u201d in 2012 IEEE\nNational Aerospace and Electronics Conference (NAECON), 2012, pp. 255\u2013263.\n[52] P. A. Porras and R. A. Kemmerer, \u201cPenetration state transition analysis: A rule-based\nintrusion detection approach,\u201d in [1992] Proceedings Eighth Annual Computer Security Application Conference, 1992, pp. 220\u2013229.\n[53] T. Verwoerd and R. Hunt, \u201cIntrusion detection techniques and approaches,\u201d Comput.\nCommun., vol. 25, no. 15, pp. 1356\u20131365, 2002.\n[54] ZhiSong Pan, Hong Lian, GuYu Hu, and GuiQiang Ni, \u201cAn integrated model of\nintrusion detection based on neural network and expert system,\u201d in 17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI\u201905), 2005, p. 2 pp.-pp.672.\n[55] SANS Institute InfoSec Reading Room, \u201cIntrusion Detection Systems: An Overview\nof RealSecure,\u201d 2001. [Online]. Available: http://www.sans.org/readingroom/whitepapers/detection/intrusion-detection-systems-overview-realsecure-342. [Accessed: 04-Mar-2016].\n[56] \u201cIBM X-Force: Ahead of the Threat - Resources,\u201d 07-Dec-2011. [Online]. Available:\nhttp://www-03.ibm.com/security/xforce/resources.html#all. [Accessed: 04-Mar-2016].\n[57] Sandeep Kumar, \u201cCLASSIFICATION AND DETECTION OF COMPUTER\nINTRUSIONS,\u201d 1995. [Online]. Available: http://web.mst.edu/~tauritzd/compsec/papers/kumar95classification.pdf. [Accessed: 04-Mar-2016].\n[58] T.-F. Sheu, N.-F. Huang, and H.-P. Lee, \u201cNIS04-6: A Time- and Memory- Efficient\nString Matching Algorithm for Intrusion Detection Systems,\u201d in IEEE Globecom 2006, 2006, pp. 1\u20135.\n[59] C. Vaid and H. K. Verma, \u201cAnomaly-based IDS implementation in cloud environment\nusing BOAT algorithm,\u201d in Proceedings of 3rd International Conference on Reliability, Infocom Technologies and Optimization, 2014, pp. 1\u20136.\n[60] K. M. A. Alheeti, A. Gruebler, K. D. McDonald-Maier, and A. Fernando, \u201cPrediction\nof DoS attacks in external communication for self-driving vehicles using a fuzzy petri net model,\u201d in 2016 IEEE International Conference on Consumer Electronics (ICCE), 2016, pp. 502\u2013503.\n[61] J. Hong, C.-C. Liu, and M. Govindarasu, \u201cDetection of cyber intrusions using\nnetwork-based multicast messages for substation automation,\u201d in ISGT 2014, 2014, pp. 1\u20135.\n[62] R. Mohan, V. Vaidehi, and S. S. Chakkaravarthy, \u201cComplex Event Processing based\nHybrid Intrusion Detection System,\u201d in 2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN), 2015, pp. 1\u20136.\n[63] S. H. Vasudeo, P. Patil, and R. V. Kumar, \u201cIMMIX-intrusion detection and prevention\nsystem,\u201d in 2015 International Conference on Smart Technologies and Management for Computing, Communication, Controls, Energy and Materials (ICSTM), 2015, pp. 96\u2013101.\n[64] W. Haider, J. Hu, X. Yu, and Y. Xie, \u201cInteger Data Zero-Watermark Assisted System\nCalls Abstraction and Normalization for Host Based Anomaly Detection Systems,\u201d in 2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing, 2015, pp. 349\u2013355.\n[65] H. Toumi, M. Talea, K. Sabiri, and A. Eddaoui, \u201cToward a trusted framework for\ncloud computing,\u201d in 2015 International Conference on Cloud Technologies and Applications (CloudTech), 2015, pp. 1\u20136.\n[66] M. Guerroumi, A. Derhab, and K. Saleem, \u201cIntrusion Detection System against Sink\nHole Attack in Wireless Sensor Networks with Mobile Sink,\u201d in 2015 12th International Conference on Information Technology - New Generations, 2015, pp. 307\u2013313.\n[67] D. Narsingyani and O. Kale, \u201cOptimizing false positive in anomaly based intrusion\ndetection using Genetic algorithm,\u201d in 2015 IEEE 3rd International Conference on MOOCs, Innovation and Technology in Education (MITE), 2015, pp. 72\u201377.\n[68] W. Haider, J. Hu, and M. Xie, \u201cTowards reliable data feature retrieval and decision\nengine in host-based anomaly detection systems,\u201d in 2015 IEEE 10th Conference on Industrial Electronics and Applications (ICIEA), 2015, pp. 513\u2013517.\n[69] N. B. Aissa and M. Guerroumi, \u201cA genetic clustering technique for Anomaly-based\nIntrusion Detection Systems,\u201d in 2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed\nComputing (SNPD), 2015, pp. 1\u20136.\n[70] O. Hamdi, M. Mbaye, and F. Krief, \u201cA cloud-based architecture for network attack\nsignature learning,\u201d in 2015 7th International Conference on New Technologies, Mobility and Security (NTMS), 2015, pp. 1\u20135.\n[71] Xiaodong Lin and Rongxing Lu, \u201cVehicular Ad Hoc Network Security and Privacy,\u201d\n21-Aug-2015. [Online]. Available: http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7159960. [Accessed: 03- Jun-2016].\n[72] S. Banerjee, R. Nandi, R. Dey, and H. N. Saha, \u201cA review on different Intrusion\nDetection Systems for MANET and its vulnerabilities,\u201d in 2015 International Conference and Workshop on Computing and Communication (IEMCON), 2015, pp. 1\u20137.\n[73] P. Satam, \u201cCross Layer Anomaly Based Intrusion Detection System,\u201d in 2015 IEEE\nInternational Conference on Self-Adaptive and Self-Organizing Systems Workshops, 2015, pp. 157\u2013161.\n[74] K. Patel and Kayur, \u201cLowering the barrier to applying machine learning,\u201d in\nProceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA \u201910, 2010, p. 2907.\n[75] E. Alpayd\u0131n, \u201cIntroduction To Machine learning,\u201d 2010. [Online]. Available:\nhttps://www.lri.fr/~xlzhang/KAUST/CS229_slides/chapter18_RL.pdf. [Accessed: 20- Jan-2015].\n[76] A. A. Ghorbani, W. Lu, and M. Tavallaee, \u201cNetwork Intrusion Detection and\nPrevention,\u201d \u2026 and Autonomous System, 2010. [Online]. Available: http://link.springer.com/10.1007/978-0-387-88771-5.\n[77] H. T. Nguyen, K. Franke, and S. Petrovic, \u201cFeature Extraction Methods for Intrusion\nDetection Systems,\u201d in Threats, Countermeasures, and Advances in Applied Information Security, vol. 3, IGI Global, 2012, pp. 23\u201352.\n[78] A. K. Jain, P. W. Duin, and J. Jianchang Mao, \u201cStatistical pattern recognition: a\nreview,\u201d IEEE Trans. Pattern Anal. Mach. Intell., vol. 22, no. 1, pp. 4\u201337, 2000.\n[79] C. Kruegel, D. Mutz, F. Valeur, and G. Vigna, \u201cOn the Detection of Anomalous\nSystem Call Arguments,\u201d Springer Berlin Heidelberg, 2003, pp. 326\u2013343.\n[80] M. V. Mahoney and P. K. Chan, \u201cAn Analysis of the 1999 DARPA/Lincoln\nLaboratory Evaluation Data for Network Anomaly Detection,\u201d vol. 2820, 2003, pp. 220\u2013237.\n[81] W. Lee and S. J. Stolfo, \u201cA framework for constructing features and models for\nintrusion detection systems,\u201d ACM Trans. Inf. Syst. Secur., vol. 3, no. 4, pp. 227\u2013261, Nov. 2000.\n[82] M. Khosravi-Farmad, A. A. Ramaki, and A. G. Bafghi, \u201cRisk-based intrusion response\nmanagement in IDS using Bayesian decision networks,\u201d in 2015 5th International Conference on Computer and Knowledge Engineering (ICCKE), 2015, pp. 307\u2013312.\n[83] R. Stuart, Artificial Intelligence: A Modern Approach, 2nd ed. Upper Saddle\nRiver,New Jersey: Prentice Hall Pa, 2009.\n[84] A. R. Onik, N. F. Haq, and W. Mustahin, \u201cCross-breed type Bayesian network based\nintrusion detection system (CBNIDS),\u201d in 2015 18th International Conference on Computer and Information Technology (ICCIT), 2015, pp. 407\u2013412.\n[85] M. A. Bode, S. A. Oluwadare, B. K. Alese, and A. F.-B. Thompson, \u201cRisk analysis in\ncyber situation awareness using Bayesian approach,\u201d in 2015 International Conference on Cyber Situational Awareness, Data Analytics and Assessment (CyberSA), 2015, pp. 1\u201312.\n[86] Hartmut Pohlheim, \u201cCompetition and Cooperation in Extended Evolutionary\nAlgorithms,\u201d 2001. [Online]. Available: http://www.pohlheim.com/Papers/conf_gecco2001/PohlheimH_CompetitionExtEA_G ECCO2001.pdf. [Accessed: 10-Mar-2016].\n[87] W. Li, \u201cUsing Genetic Algorithm for Network Intrusion Detection,\u201d Proc. United\nStates Dep. Energy Cyber Secur. Grou, pp. 1--8, 2004.\n[88] Tao Xia, Guangzhi Qu, S. Hariri, and M. Yousif, \u201cAn efficient network intrusion\ndetection method based on information theory and genetic algorithm,\u201d in PCCC 2005. 24th IEEE International Performance, Computing, and Communications Conference, 2005., pp. 11\u201317.\n[89] M. Padmadas, N. Krishnan, J. Kanchana, and M. Karthikeyan, \u201cLayered approach for\nintrusion detection systems based genetic algorithm,\u201d in 2013 IEEE International Conference on Computational Intelligence and Computing Research, 2013, pp. 1\u20134.\n[90] G. Wang, D.-Y. Yeung, and F. H. Lochovsky, \u201cA kernel path algorithm for support\nvector machines,\u201d in Proceedings of the 24th international conference on Machine learning - ICML \u201907, 2007, pp. 951\u2013958.\n[91] C. J. C. Burges, \u201cA Tutorial on Support Vector Machines for Pattern Recognition,\u201d\nData Min. Knowl. Discov., vol. 2, no. 2, pp. 121\u2013167.\n[92] F. Zhu, N. Ye, D. Pan, and W. Ding, \u201cIncremental Support Vector Machine Learning:\nAn Angle Approach,\u201d in 2011 Fourth International Joint Conference on Computational Sciences and Optimization, 2011, pp. 288\u2013292.\n[93] B. Senthilnayaki, K. Venkatalakshmi, and A. Kannan, \u201cIntrusion detection using\noptimal genetic feature selection and SVM based classifier,\u201d in 2015 3rd International Conference on Signal Processing, Communication and Networking (ICSCN), 2015, pp. 1\u20134.\n[94] L. Teng, S. Teng, F. Tang, H. Zhu, W. Zhang, D. Liu, and L. Liang, \u201cA Collaborative\nand Adaptive Intrusion Detection Based on SVMs and Decision Trees,\u201d in 2014 IEEE International Conference on Data Mining Workshop, 2014, pp. 898\u2013905.\n[95] K. Shi, L. Li, H. Liu, J. He, N. Zhang, and W. Song, \u201cAn improved KNN text\nclassification algorithm based on density,\u201d in 2011 IEEE International Conference on Cloud Computing and Intelligence Systems, 2011, pp. 113\u2013117.\n[96] Y. Canbay and S. Sagiroglu, \u201cA Hybrid Method for Intrusion Detection,\u201d in 2015\nIEEE 14th International Conference on Machine Learning and Applications (ICMLA), 2015, pp. 156\u2013161.\n[97] H. Zhang and G. Chen, \u201cThe Research of Face Recognition Based on PCA and K-\nNearest Neighbor,\u201d in 2012 Symposium on Photonics and Optoelectronics, 2012, pp.\n1\u20134.\n[98] Q. Zeng and S. Wu, \u201cAnomaly Detection Based on Multi-Attribute Decision,\u201d in 2009\nWRI Global Congress on Intelligent Systems, 2009, pp. 394\u2013398.\n[99] K. A. Jalill, M. H. Kamarudin, and U. T. Mara, \u201cComparison of Machine Learning\nAlgorithms Performance in Detecting Network Intrusion,\u201d pp. 221\u2013226, 2010.\n[100] F. Sebastiani and Fabrizio, \u201cMachine learning in automated text categorization,\u201d ACM\nComput. Surv., vol. 34, no. 1, pp. 1\u201347, Mar. 2002.\n[101] T. Komviriyavut, P. Sangkatsanee, N. Wattanapongsakorn, and C. Charnsripinyo,\n\u201cNetwork intrusion detection and classification with Decision Tree and rule based approaches,\u201d in 2009 9th International Symposium on Communications and Information Technology, 2009, pp. 1046\u20131050.\n[102] S. Sahu and B. M. Mehtre, \u201cNetwork intrusion detection system using J48 Decision\nTree,\u201d in 2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI), 2015, pp. 2023\u20132026.\n[103] S. Rajasekaran and G. A. V. Pai, \u201cNeural Neworks, Fuzzy Logic and Genetic\nAlgorithm: Synthesis and Applications (WITH CD),\u201d 2003. [Online]. Available: https://books.google.com/books?hl=en&lr=&id=bVbj9nhvHd4C&pgis=1. [Accessed: 29-Mar-2016].\n[104] M. Wahengbam and N. Marchang, \u201cIntrusion Detection in MANET using fuzzy\nlogic,\u201d in 2012 3rd National Conference on Emerging Trends and Applications in Computer Science, 2012, pp. 189\u2013192.\n[105] A. N. Toosi and M. Kahani, \u201cA new approach to intrusion detection based on an\nevolutionary soft computing model using neuro-fuzzy classifiers,\u201d 2007.\n[106] H. Om and A. Kundu, \u201cA hybrid system for reducing the false alarm rate of anomaly\nintrusion detection system,\u201d in 2012 1st International Conference on Recent Advances in Information Technology (RAIT), 2012, pp. 131\u2013136.\n[107] S. Gupta, \u201cAn effective model for anomaly IDS to improve the efficiency,\u201d in 2015\nInternational Conference on Green Computing and Internet of Things (ICGCIoT), 2015, pp. 190\u2013194.\n[108] A. Ben Ayed, M. Ben Halima, and A. M. Alimi, \u201cSurvey on clustering methods:\nTowards fuzzy clustering for big data,\u201d in 2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR), 2014, pp. 331\u2013336.\n[109] Li Jun Tao, Liu Yin Hong, and Hao Yan, \u201cThe improvement and application of a K-\nmeans clustering algorithm,\u201d in 2016 IEEE International Conference on Cloud Computing and Big Data Analysis (ICCCBDA), 2016, pp. 93\u201396.\n[110] P. Jongsuebsuk, N. Wattanapongsakorn, and C. Charnsripinyo, \u201cNetwork intrusion\ndetection with Fuzzy Genetic Algorithm for unknown attacks,\u201d in The International Conference on Information Networking 2013 (ICOIN), 2013, pp. 1\u20135.\n[111] A.-C. Enache and V. Sgarciu, \u201cAnomaly Intrusions Detection Based on Support\nVector Machines with an Improved Bat Algorithm,\u201d in 2015 20th International Conference on Control Systems and Computer Science, 2015, pp. 317\u2013321.\n[112] S. Akbar, J. A. Chandulal, K. N. Rao, and G. S. Kumar, \u201cImproving network security\nusing machine learning techniques,\u201d in 2012 IEEE International Conference on Computational Intelligence and Computing Research, 2012, pp. 1\u20135.\n[113] A. S. A. Aziz, A. E. Hassanien, S. E.-O. Hanaf, and M. F. Tolba, \u201cMulti-layer hybrid\nmachine learning techniques for anomalies detection and classification approach,\u201d in 13th International Conference on Hybrid Intelligent Systems (HIS 2013), 2013, pp. 215\u2013220.\n[114] W.-C. Lin, S.-W. Ke, and C.-F. Tsai, \u201cCANN: An intrusion detection system based on\ncombining cluster centers and nearest neighbors,\u201d Knowledge-Based Syst., vol. 78, pp. 13\u201321, Apr. 2015.\n[115] A. A. Aburomman and M. Bin Ibne Reaz, \u201cA novel SVM-kNN-PSO ensemble method\nfor intrusion detection system,\u201d Appl. Soft Comput., vol. 38, pp. 360\u2013372, Jan. 2016.\n[116] S.-J. Horng, M.-Y. Su, Y.-H. Chen, T.-W. Kao, R.-J. Chen, J.-L. Lai, and C. D.\nPerkasa, \u201cA novel intrusion detection system based on hierarchical clustering and support vector machines,\u201d Expert Syst. Appl., vol. 38, no. 1, pp. 306\u2013313, Jan. 2011.\n[117] E. Hodo, X. Bellekens, A. Hamilton, P.-L. Dubouilh, E. Iorkyase, C. Tachtatzis, and\nR. Atkinson, \u201cThreat analysis of IoT networks Using Artificial Neural Network Intrusion Detection System,\u201d in 2016 3rd International Symposium on Networks, Computers and Communications (ISNCC), 2016, pp. 1\u20136.\n[118] S. X. Wu and W. Banzhaf, \u201cThe use of computational intelligence in intrusion\ndetection systems: A review,\u201d Appl. Soft Comput., vol. 10, no. 1, pp. 1\u201335, Jan. 2010.\n[119] S. Dong, D. Zhou, and W. Ding, \u201cThe Study of Network Traffic Identification Based\non Machine Learning Algorithm,\u201d 2012 Fourth Int. Conf. Comput. Intell. Commun. Networks, pp. 205\u2013208, Nov. 2012.\n[120] K. Murphy, \u201cMachine learning: a probabilistic perspective,\u201d Chance encounters:\nProbability in \u2026, 2012. [Online]. Available: http://link.springer.com/chapter/10.1007/978-94-011-3532-0_2. [Accessed: 06-Jan2015].\n[121] M. A. Alsheikh, S. Lin, D. Niyato, and H.-P. Tan, \u201cMachine Learning in Wireless\nSensor Networks: Algorithms, Strategies, and Applications,\u201d IEEE Commun. Surv. Tutorials, vol. 16, no. 4, pp. 1996\u20132018, 2014.\n[122] P. Barapatre, N. Z. Tarapore, S. G. Pukale, and M. L. Dhore, \u201cTraining MLP neural\nnetwork to reduce false alerts in IDS,\u201d in 2008 International Conference on Computing, Communication and Networking, 2008, pp. 1\u20137.\n[123] J. Bi, K. Zhang, and X. Cheng, \u201cIntrusion Detection Based on RBF Neural Network,\u201d\nin 2009 International Symposium on Information Engineering and Electronic Commerce, 2009, pp. 357\u2013360.\n[124] C. Zhang, J. Jiang, and M. Kamel, \u201cComparison of BPL and RBF Network in Intrusion\nDetection System,\u201d in Rough Sets, Fuzzy Sets, Data Mining, and Granular Computing, Berlin, Heidelberg: Springer Berlin Heidelberg, 2003, pp. 466\u2013470.\n[125] M. Kamel, \u201cRBF-based real-time hierarchical intrusion detection systems,\u201d in\nProceedings of the International Joint Conference on Neural Networks, 2003., 2003, vol. 2, pp. 1512\u20131516.\n[126] Y. Fu, Y. Zhu, and H. Yu, \u201cStudy of Neural Network Technologies in Intrusion\nDetection Systems,\u201d in 2009 5th International Conference on Wireless Communications, Networking and Mobile Computing, 2009, pp. 1\u20134.\n[127] A. N. Z.-H. Peter Lichodzijewski, \u201cHost-Based Intrusion Detection Using Self-\norganizing Maps,\u201d in IJCNN \u201902, 2002, pp. 1714\u20131719.\n[128] M. I. H. H. Gunes Kayacik, A. Nur Zincir-Heywood, \u201cA hierarchical SOM-based\nintrusion detection system,\u201d vol. 20, pp. 439\u2013451, 2007.\n[129] V. Dinesh Kumar and S. Radhakrishnan, \u201cIntrusion detection in MANET using Self\nOrganizing Map (SOM),\u201d in 2014 International Conference on Recent Trends in Information Technology, 2014, pp. 1\u20138.\n[130] M. Chauhan, A. Pratap, and A. Dixit, \u201cDesigning a technique for detecting intrusion\nbased on modified Adaptive Resonance Theory Network,\u201d in 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), 2015, pp. 448\u2013 451.\n[131] S. Haykin, \u201cNeural Networks-A comprehensive foundation,\u201d 1999. [Online].\nAvailable: https://cdn.preterhuman.net/texts/science_and_technology/artificial_intelligence/Neura l Networks - A Comprehensive Foundation - Simon Haykin.pdf. [Accessed: 22-Jan2015].\n[132] P. Somwang and W. Lilakiatsakun, \u201cIntrusion detection technique by using fuzzy ART\non computer network security,\u201d in 2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA), 2012, pp. 697\u2013702.\n[133] A. S. A. Iftikhar Ahmad, Azween B Abdullah, \u201cEvaluating Neural Network Intrusion\nDetection Approaches Using Analytic Hierarchy Process,\u201d in 2010 IEEE International Symposium on Information Technology, 2010.\n[134] and Y. T. G. E. Hinton, S. Osindero, \u201cA fast learning algorithm for deep belief nets,\u201d\nNeural Comput., vol. 18, no. 7, pp. 1527\u20131554, 2006.\n[135] Y. Freund and D. Haussler, \u201cUnsupervised learning of distributions on binary vectors\nusing two layer networks,\u201d Santa Cruz, 1994.\n[136] Y. Bengio, \u201cLearning Deep Architectures for AI,\u201d Foundations and Trends\u00ae in\nMachine Learning, 2009. [Online]. Available: http://www.nowpublishers.com/product.aspx?product=MAL&doi=2200000006. [Accessed: 10-Jul-2014].\n[137] M. I. Jordan, \u201cLearning in Graphical Models.,\u201d 1998. [Online]. Available:\nhttps://www.cs.cmu.edu/~tom/10-702/zoubin-varintro.pdf. [Accessed: 02-Aug-2016].\n[138] Li Deng, \u201cA tutorial survey of architectures, algorithms, and applications for deep\nlearning,\u201d APSIPA Trans. Signal Inf. Process., vol. 3, no. e2, pp. 1--29, 2014.\n[139] L. Deng and D. Yu, \u201cFoundations and Trends\u00ae in Signal Processing,\u201d 2014. [Online].\nAvailable: https://www.microsoft.com/en-us/research/publication/deep-learningmethods-and-applications/. [Accessed: 02-Aug-2016].\n[140] L. O. Anyanwu, J. Keengwe, and G. A. Arome, \u201cScalable Intrusion Detection with\nRecurrent Neural Networks,\u201d in IEEE 2010 Seventh International Conference on\nInformation Technology: New Generations, 2010, pp. 919\u2013923.\n[141] J. Kim, J. Kim, H. L. T. Thu, and H. Kim, \u201cLong Short Term Memory Recurrent\nNeural Network Classifier for Intrusion Detection,\u201d in 2016 International Conference on Platform Technology and Service (PlatCon), 2016, pp. 1\u20135.\n[142] A. Ng, \u201cStacked Autoencoders - Ufldl.\u201d [Online]. Available:\nhttp://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders. [Accessed: 18-Feb2015].\n[143] B. Abolhasanzadeh, \u201cNonlinear dimensionality reduction for intrusion detection using\nauto-encoder bottleneck features,\u201d in 2015 7th Conference on Information and Knowledge Technology (IKT), 2015, pp. 1\u20135.\n[144] U. Fiore, F. Palmieri, A. Castiglione, and A. De Santis, \u201cNetwork anomaly detection\nwith the restricted Boltzmann machine,\u201d Neurocomputing, vol. 122, pp. 13\u201323, Dec. 2013.\n[145] R. Salakhutdinov and G. Hinton, \u201cDeep Boltzmann Machines,\u201d Artif. Intell., vol. 5, no.\n2, pp. 448\u2013455, 2009.\n[146] N. Gao, L. Gao, Q. Gao, and H. Wang, \u201cAn Intrusion Detection Model Based on Deep\nBelief Networks,\u201d in 2014 Second International Conference on Advanced Cloud and Big Data, 2014, pp. 247\u2013252.\n[147] M. Z. Alom, V. Bontupalli, and T. M. Taha, \u201cIntrusion detection using deep belief\nnetworks,\u201d in 2015 National Aerospace and Electronics Conference (NAECON), 2015, pp. 339\u2013344.\n[148] \u201cUnsupervised Feature Learning and Deep Learning Tutorial.\u201d [Online]. Available:\nhttp://ufldl.stanford.edu/tutorial/supervised/ConvolutionalNeuralNetwork/. [Accessed: 13-Nov-2015].\n[149] Y. LeCun, Y. Bengio, and G. Hinton, \u201cDeep learning,\u201d Nature, vol. 521, no. 7553, pp.\n436\u2013444, May 2015.\n[150] M. Dalto, \u201cDeep neural networks for time series prediction with applications in ultra-\nshort-term wind forecasting.\u201d [Online]. Available: http://www.fer.unizg.hr/_download/repository/KDI-Djalto.pdf. [Accessed: 19-Feb2015].\n[151] L. Lab, \u201cDeep Learning Tutorial,\u201d 2015. [Online]. Available:\nhttp://deeplearning.net/tutorial/deeplearning.pdf. [Accessed: 20-Aug-2016].\n[152] \u201cConvolutional Neural Networks - Andrew Gibiansky.\u201d [Online]. Available:\nhttp://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/. [Accessed: 24-Nov-2015].\n[153] Y. LeCun, \u201cLearning Invariant feature Hierarchies,\u201d 2012. [Online]. Available:\nhttp://yann.lecun.com/exdb/publis/pdf/lecun-eccv-12.pdf. [Accessed: 13-Nov-2015].\n[154] \u201cConvolutional Neural Networks (LeNet) \u2014 DeepLearning 0.1 documentation.\u201d\n[Online]. Available: http://deeplearning.net/tutorial/lenet.html. [Accessed: 29-Apr2016]."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Intrusion detection has attracted a considerable interest from researchers<lb>and industries. The community, after many years of research, still faces the problem of<lb>building reliable and efficient IDS that are capable of handling large quantities of data, with<lb>changing patterns in real time situations. The work presented in this manuscript classifies<lb>intrusion detection systems (IDS). Moreover, a taxonomy and survey of shallow and deep<lb>networks intrusion detection systems is presented based on previous and current works. This<lb>taxonomy and survey reviews machine learning techniques and their performance in<lb>detecting anomalies. Feature selection which influences the effectiveness of machine learning<lb>(ML) IDS is discussed to explain the role of feature selection in the classification and training<lb>phase of ML IDS. Finally, a discussion of the false and true positive alarm rates is presented<lb>to help researchers model reliable and efficient machine learning based intrusion detection<lb>systems. Keywords\u2014 Shallow network, Deep networks, Intrusion detection, False positive<lb>alarm rates and True positive alarm rates 1.0 INTRODUCTION<lb>Computer networks have developed rapidly over the years contributing significantly to social<lb>and economic development. International trade, healthcare systems and military capabilities<lb>are examples of human activity that increasingly rely on networks. This has led to an<lb>increasing interest in the security of networks by industry and researchers. The importance of<lb>Intrusion Detection Systems (IDS) is critical as networks can become vulnerable to attacks<lb>from both internal and external intruders [1], [2]. An IDS is a detection system put in place to monitor computer networks. These have been in<lb>use since the 1980\u2019s [3]. By analysing patterns of captured data from a network, IDS help to<lb>detect threats [4]. These threats can be devastating, for example, Denial of service (DoS)<lb>denies or prevents legitimate users resource on a network by introducing unwanted traffic [5].<lb>Malware is another example, where attackers use malicious software to disrupt systems [6].", "creator": "Microsoft\u00ae Word 2010"}}}