{"id": "1701.08306", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Jan-2017", "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)", "abstract": "autonomous software agents operating in dynamic environments all need to constantly reason about actions in pursuit rather of solving their goals, while taking into consideration norms expectations which might be imposed necessarily on those actions. normative practical reasoning supports agents making decisions difficult about what is best for them to ( not ) do in a given situation. what makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. we offer simulations a modular formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. we compare plans based on decision - theoretic notions ( i. e. utility ) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. the set of optimal plans consists of plans that maximise the overall economic utility, each of which can be chosen by the agent to execute. we provide an implementation of our current proposal in answer set programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. the implementation is proven to be sound and complete.", "histories": [["v1", "Sat, 28 Jan 2017 17:55:04 GMT  (771kb,D)", "http://arxiv.org/abs/1701.08306v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["zohreh shams", "marina de vos", "julian padget", "wamberto w vasconcelos"], "accepted": false, "id": "1701.08306"}, "pdf": {"name": "1701.08306.pdf", "metadata": {"source": "CRF", "title": "Practical Reasoning with Norms for Autonomous Software Agents (Full Edition)", "authors": ["Zohreh Shamsa", "Marina De Vos", "Julian Padget", "Wamberto W. Vasconcelos"], "emails": ["z.shams@bath.ac.uk", "m.d.vos@bath.ac.uk", "j.a.padget@bath.ac.uk", "wvasconcelos@acm.org"], "sections": [{"heading": null, "text": "Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.\nKeywords: Intelligent Agents, Practical Reasoning, Norms, Goals\n\u2217Corresponding author. Email addresses: z.shams@bath.ac.uk (Zohreh Shams), m.d.vos@bath.ac.uk\n(Marina De Vos), j.a.padget@bath.ac.uk (Julian Padget), wvasconcelos@acm.org (Wamberto W. Vasconcelos)\n1Present Address: Computer Laboratory, University of Cambridge, UK (CB3 0FD)\nPreprint submitted to Engineering Applications of Artificial IntelligenceJanuary 31, 2017\nar X\niv :1\n70 1.\n08 30\n6v 1\n[ cs\n.A I]\n2 8"}, {"heading": "1. Introduction", "text": "Reasoning about what to do \u2013 known as practical reasoning \u2013 for an agent pursuing different goals is a complicated task. When conducting practical reasoning, the agents might exhibit undesirable behaviour that was not predicted. The necessity of controlling undesirable behaviour has given rise to the concept of norms that offer a way to define ideal behaviour for autonomous software agents in open environments. Such norms often define obligations and prohibitions that express what the agent is obliged to do and what the agent is prohibited from doing.\nDepending on their computational interpretation, norms can be regarded as soft or hard constraints. When modelled as hard constraints, the agent subject to the norms is said to be regimented, in which case the agent has no choice but blindly to follow the norms (Esteva et al., 2001). Although regimentation guarantees norm compliance, it greatly restricts agent autonomy. Moreover, having individual goals to pursue, self-interested agents might not want to or might not be able to comply with the norms imposed on them. Conversely, enforcement approaches, in which norms are modelled as soft constraints, leave the choice of complying with or violating the norms to the agent. However, in order to encourage norm compliance, there are consequences associated, namely a punishment when agents violate a norm (Lo\u0301pez y Lo\u0301pez et al., 2005; Pitt et al., 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (Lo\u0301pez y Lo\u0301pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals.\nExisting work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al. (2012); Oren et al. (2011)). We argue that in certain situations, an agent might be better off violating a norm which, if followed, would make it impossible for the agent to achieve an important goal or complying with a more important norm.\nIn this paper we set out an approach for practical reasoning that considers norms in both plan generation and plan selection. We extend current work on normative plan generation such that the agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal (Oren et al., 2011; Panagiotidi et al., 2012a). Such an extension is made on top of STRIPS (Fikes and Nilsson, 1971), the most established planning domain language that lays the foundation of many automated planning languages. Additionally, since in reality the actions are often non-atomic, our model allows for planning with durative actions that can be executed concurrently. Through our practical reasoning process agents consider all plans (i.e., sequences of actions), including those leading to norm compliance and violation; each plan gets an associated overall utility for its sequence of actions, goals satisfied, and norms followed/violated, and agents can decide which of them to pursue by comparing the relative importance of goals and norms via their utilities. The plan an agent chooses to follow is not necessarily norm-compliant; however, our mechanism guarantees that the decision will maximise the overall plan utility, and this justifies the occasional violation of norms as the plan is followed. Both plan generation and plan selection mechanisms proposed in this paper are implemented using Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988).\nASP is a declarative programming paradigm using logic programs under Answer Set semantics. In this paradigm the user provides a description of a problem and ASP works out how to solve the problem by returning answer sets corresponding to problem solutions. The existence of efficient solvers to generate the answers to the problems provided has increased the use of ASP in different domains of autonomous agents and multi-agent systems such as planning (Lifschitz, 2002) and normative reasoning (Cliffe et al., 2006; Panagiotidi et al., 2012b). Several action and planning languages such as event calculus (Kowalski and Sergot, 1986), A (and its descendants B and C (Gelfond and Lifschitz, 1998), Temporal Action Logics (TAL) (Doherty et al., 1998), have been implemented in ASP (Lee and Palla, 2012, 2014), indicating that ASP is appropriate for reasoning about actions. This provides motive and justification for an implementation of STRIPS (Fikes and Nilsson, 1971) that serves as the foundation of our model in ASP.\nThis paper is organised as follows. First we present a scenario in Section 2 which we use to illustrate the applicability of our approach. This is followed by the formal model and its semantics in Section 3. The computational\nimplementation of the model is provided in Section 4. After the discussion of related work in Section 5, we conclude in Section 6."}, {"heading": "2. Illustrative Scenario", "text": "To illustrate our approach and motivate the normative practical reasoning model in the next section, we consider a scenario in which a software agent acts as a supervisory system in a disaster recovery mission and supports human decision-making in response to an emergency. The software agent\u2019s responsibility is to provide humans with different courses of actions available and to help humans decide on which course of actions to follow. In our scenario, the agent is to plan for a group of human actors who are in charge of responding to an emergency caused by an earthquake. The agent monitors the current situation (e.g., contamination of water, detection of shocks, etc.) and devises potential plans to satisfy goals set by human actors. In our scenario we assume the following two goals:\n1. Running a hospital to help wounded people: this goal is fulfilled when medics are present to offer help and they have access to water and medicines. 2. Organising a survivors\u2019 camp: this is fulfilled when the camp\u2019s area is secured and a shelter is built. We also assume the two following norms that the agent has to consider while devising plans to satisfy the goals above:\n1. It is forbidden to built a shelter within 3 time units of detecting shocks. The cost of violating this norm is 5 units. 2. It is obligatory to stop water distribution for 2 time units once poison is detected in the water. The cost of violating this norm is 10 units.\nThe formulation of this scenario is provided in Appendix A."}, {"heading": "3. A Model for Normative Practical Reasoning", "text": "In this research, we take STRIPS (Fikes and Nilsson, 1971) as the basis of our normative practical reasoning model. In STRIPS, a planning problem is defined in terms of an initial state, a goal state and a set of operators (e.g. actions). Each operator has a set of preconditions representing the circumstances/context in which the operator can be executed, and a set of postconditions that result from applying the operator. Any sequence of actions that satisfies the goal is a solution to the planning problem. In order\nto capture the features of the normative practical reasoning problem that we are going to model, we extend the classical planning problem by:\n(i) replacing atomic actions with durative actions: often the nature of the actions is non-atomic, which means that although executed atomically in a state, the system state in which they finish executing is not necessarily the same in which they started (Nunes et al., 1997). Refinement of atomic actions to durative actions reflects the real time that a machine takes to execute certain actions, which is also known as \u201creal-time duration\u201d of actions (Bo\u0308rger and Sta\u0308rk, 2003). (ii) Allowing a set of potentially inconsistent goals instead of the conventional single goal: the issue of planning for multiple goals distributed among distinct agents is addressed in collaborative planning. We address this issue for a single agent when handling multiple conflicting goals. (iii) Factoring in norms: having made a case for the importance of norms in Section 1, we combine normative and practical reasoning. Just like goals, a set of norms is not necessarily consistent, making it potentially impossible for an agent to comply with all norms imposed on it.\nA solution for a normative practical reasoning problem that features (i), (ii) and (iii) is any sequence of actions that satisfies at least one goal. The agent has the choice of violating or complying with norms triggered by execution of a sequence of actions, while satisfying its goals. However, there may be consequences either way that the agent has to foresee.\nWe explain the syntax and semantics of the model in Sections 3.2\u20133.6. First, however, we present the architecture of our envisaged system in the next section."}, {"heading": "3.1. Architecture", "text": "The architecture, depicted in Figure 1, shows how re-planning can be considered if a plan in progress is interrupted due to a change in circumstances. This change can be the result of a change in the environment or unexpected actions of other agents in the system. As is customary in multi-agent systems, the agent will regularly check the viability of its plan. The frequency depends on the type of system the agent is operating in, the agent\u2019s commitment to its intentions, and the impact of re-computation on the agent\u2019s overall performance.\nWhen an agent decides that re-planning is in order, it will take the state in which the plan is interrupted as the initial state for the new plan and its\ncurrent goal set as the goals to plan towards. The current goal set does not have to be the same as the goal set the original plan was devised for. Goals can already be achieved in the interrupted plan, previous goals may no longer be relevant and others may have been added. Even if the goals remain the same, the resulting new optimal plan might change due to changes in the state of the system. Similarly, there might be new norms imposed on the agent that will have to be considered in replanning.\nWe cater for agents which need to create their own individual plans. However, in doing so, in multi-agent scenarios agents will inevitably interact and interfere with each other\u2019s plans. The overview of Figure 1 will cater for this in two ways: (i) agents will notice the states being changed by other agents (a way of indirect communication) and (ii) the \u201cObservations\u201d will also contain interactions among agents (direct communication). Although we do not explore these ideas in the present paper, we envisage that the outcome of the indirect and direct interactions among agents could be represented as norms, establishing, for instance, that a particular agent, in the current context (i.e., power or organisational relationships, description of capabilities and global goals, etc.), is forbidden or obliged to do something."}, {"heading": "3.2. Syntax", "text": "We start this section by describing an extended STRIPS planning problem, defined in (Shams, 2016), that accommodates (i) durative actions; (ii) multiple goals and (iii) multiple norms.\nDefinition 1 (Normative Practical Reasoning Problem). A normative practical reasoning problem is a tuple P = (FL,\u2206, A,G,N) where\n(i) FL is a set of fluents; (ii) \u2206 is the initial state;\n(iii) A is a finite, non-empty set of durative actions for the agent; (iv) G is the agent\u2019s set of goals; (v) N is a set of norms.\nWe describe in the ensuing sections each of the components of a normative practical reasoning problem."}, {"heading": "3.2.1. Fluents and Initial State", "text": "FL is a set of domain fluents describing the domain the agent operates in. A literal l is a fluent or its negation i.e. l = fl or l = \u00acfl for some fl \u2208 FL. For a set of literals L, we define L+ = {fl |fl \u2208 L} and L\u2212 = {fl | \u00acfl \u2208 L} to denote the set of positive and negative fluents in L respectively. L is well-defined if there exists no fluent fl \u2208 FL such that fl ,\u00acfl \u2208 L, i.e., if L+ \u2229 L\u2212 = \u2205.\nThe semantics of the normative practical reasoning problem is defined over a set of states \u03a3. A state s \u2286 FL is determined by set of fluents that hold true at a given time, while the other fluents (those that are not present) are considered to be false. A state s \u2208 \u03a3 satisfies fluent fl \u2208 FL, denoted s |= fl , if fl \u2208 s. It satisfies its negation s |= \u00acfl if fl 6\u2208 s. This notation can be extended to a set of literals as follows: set X is satisfied in state s, s |= X, when \u2200x \u2208 X, s |= x.\nThe set of fluents that hold at the initial state is denoted by \u2206 \u2286 FL."}, {"heading": "3.3. Durative Actions", "text": "The component A of our normative practical reasoning problem P = (FL,\u2206, A,G,N) is a set of durative actions. A durative action has pre- and post-conditions. The effects of an action (as captured by its post-conditions) are not immediate, that is, it takes a non-zero period of time for the effects of an action to take place.\nDefinition 2 (Durative Actions). A durative action a is a tuple \u3008pr , ps , d\u3009 where pr and ps are possibly empty and finite sets of well-defined literals representing respectively the pre- and post-conditions of the action, and d \u2208 N, d > 0, is the duration of the action.\nGiven an action a = \u3008pr , ps , d\u3009 we may also refer to its three components pr(a), ps(a) and da. Moreover, we use pr(a)\n+ and pr(a)\u2212 to refer to, respectively, the positive and negative literals in pr(a); similarly, we have ps(a)+ and ps(a)\u2212 to refer to respectively the positive and negative literals in ps(a). An action a can be executed in a state s if its preconditions hold in that state (i.e. s |= pr(a)). When modelling durative actions, there might be several states between the start and end state of the action, during which the action is said to be in progress. Some approaches take the view that it is sufficient for the preconditions of the action to hold at the start state and it does not matter whether they hold while the action is in progress (Knoblock, 1994), whereas others hold the view that the preconditions of an action should be satisfied while the action is in progress (Blum and Furst, 1997). Moreover, some planning languages, such as Planning Domain Description Language (PDDL) (Garrido et al., 2002; Fox and Long, 2003), distinguish between preconditions and those conditions that have to hold while the action is in progress. The latter conditions are referred to as invariant conditions. Having invariant conditions different from preconditions undoubtedly brings more expressiveness to the planning language; however it comes at the price of higher implementation complexity. In this paper we take the position that the invariant conditions are the same as preconditions, which implies that the preconditions have to be preserved throughout the execution of the action.\nThe postconditions of a durative action cause changes to the state s in which the action ends. These changes are: adding the positive postconditions ps(a)+ to s and deleting the negative postconditions ps(a)\u2212 from s. Thus, for a state s in which action a ends, we have: s |= ps(a)+ and s 6|= ps(a)\u2212.\nExample 1. Action \u201cbuildShelter\u201d is available to the agents in the scenario described in Section 2. To build a shelter the agent has to secure and evacuate the area and there is no Shock detected \u2013 these are represented as preconditions areaSecured, evacuated and \u00acShockDetected, respectively. Once the shelter is built the area does not have to remain evacuated. This is represented as the positive postcondition shelterBuilt , while the negative postcondition of this action is \u00acevacuated. In our scenario, we model this action as taking 4 units of time (that is, if it is executed in state sk, it will end in state sk+4,).\nbuildShelter = \u2329 areaSecured , evacuated ,\n\u00acShockDetected\n , { shelterBuilt , \u00acevacuated } , 4 \u232a\nsk\nareaSecured evacuated\nsk+4\nshelterBuilt\nbuildShelter"}, {"heading": "3.4. Goals", "text": "Goals identify the state of affairs in the world that an agent wants to achieve. Different types of goals and their characteristics have been classified in the literature (van Riemsdijk et al., 2008). Achievement goals are the most common type of goals modelled in the agent literature and have therefore received the most attention (van Riemsdijk et al., 2008; de Boer et al., 2002; Nigam and Leite, 2006; van Riemsdijk et al., 2002). goals for the purpose of this research are achievement goals.\nWe define below the elements of the set G of P = (FL,\u2206, A,G,N).\nDefinition 3 (Goals). A goal g \u2208 G is the pair \u3008r, v\u3009, where r is a possibly empty and finite set of well-defined literals representing the goal requirements, and v \u2208 N, v > 0, represents the utility/gain for achieving the goal.\nGoal g\u2019s requirements and value are denoted as r(g) and v(g), respectively.\nExample 2. The goals from our illustrative scenario are formulated as below:\nrunningHospital = \u2329 medicsPresent , waterSupplied ,\nmedicinesSupplied\n , 25 \u232a\norganiseSurvivorCamp = \u2329{ areaSecured , shelterBuilt } , 18 \u232a"}, {"heading": "3.5. Norms", "text": "In this section we specify what we refer to as a norm in this work. In order to provide a context for the norm specification we explain how our norm specification corresponds to the five elements identified by Criado (2012) that distinguish norm specification languages.\n1. Deontic Operators: We model a permissive society in which the agent has complete knowledge of the domain of actions available. Everything is permitted unless it is explicitly prohibited. The role of obligation is to motivate the agent to execute a specific action and the role of prohibition is to inhibit the agent from executing a particular action.\n2. Controls: Controls determine whether the deontic propositions operate on actions, states or both. In this work we focus on action-based norms. 3. Enforcement Mechanisms: We use the enforcement mechanism proposed by Shams et al. (2015) that is a combination of utility-based (e.g., Oren et al. (2011); Panagiotidi et al. (2012a)) and pressure-based (Lo\u0301pez y Lo\u0301pez et al., 2005) compliance methods. 4. Conditional Expressions: Similar to the control element, we use actions as conditional expressions. In other words, the norm condition is an action that once executed, the agent is obliged to or prohibited from executing the action that the norm targets. 5. Temporal Constraints: temporal constraints can be used to express norm activation, termination, deadline, etc. The temporal constraint we specify here is concerned with the deadline. The agent is expected to comply with an obligation (execute a certain action) or a prohibition (refrain from executing a specific action) before some deadline.\nHaving explained the properties of our norm specification language, we now define the element N of problem P = (FL,\u2206, A,G,N). N denotes a set of conditional norms to which the agent is subject:\nDefinition 4 (Norms). N is a set of norms, each of which is a tuple of the form n = \u3008d o, acon, asub, dl, c\u3009, where \u2022 d o \u2208 {o, f}2 is the deontic operator determining the type of norm,\nwhich can be an obligation or a prohibition; \u2022 acon \u2208 A is the durative action (cf. Def. 2) that activates the norm; \u2022 asub \u2208 A is the durative action (cf. Def. 2) that is the target of the\nobligation or prohibition; \u2022 dl \u2208 N is the norm deadline relative to the activation condition, which\nis the completion of the execution of the action acon; and \u2022 c \u2208 N is the penalty cost that will be applied if the norm is violated. c(n) denotes the penalty cost of norm n.\nAn obligation norm states that executing action acon obliges the agent to start/start and end the execution of asub within dl time units of the end of execution of acon. Such an obligation is complied with if the agent starts or\n2The symbols o and f are normally represented as respectively O and F in the Deontic logic literature. However we have used lower case letters to make these consistent with our implementation in the next section. Capital letters in the implementation language are reserved for variables.\nstarts and ends executing asub before the deadline and is violated otherwise. A prohibition norm expresses that executing action acon prohibits the agent from starting or starting and ending the execution of asub within dl time units of the end of execution of acon. Such a prohibition is complied with if the agent does not start or does not start and end executing asub before the deadline and is violated otherwise.\nExample 3. The norms in the illustrative scenario are formulated as below:\nn1 = \u3008f, detectShock, buildShelter, 3, 5\u3009 n2 = \u3008o, detectPoison, stopWater, 2, 10\u3009\nA norm can be activated multiple times in a sequence of action, generating different instances of the original norm. To make sure different instances are dealt with uniquely, we define instantiated norms. In each instance the deadline is updated relative to the end of execution of the action that is the condition of the norm.\nDefinition 5 (Instantiated Norm). An instantiation of norm n = \u3008d o, acon, asub, dl, c\u3009 is denoted as nins = \u3008d o, acon, asub, dlins, c\u3009 where dlins = dl + tacon + dacon. tacon is when action acon is executed and dacon is the duration of acon.\nWe also denote an instantiation of a norm ni as n \u2032 i.\nExample 4. Assume that in some sequence of action detectShock is executed at time 3 (i.e. tacon = 3) and that the duration of this action is 1 (i.e. dacon = 1). The instantiated version of norm\nn1 = \u3008f, detectShock , buildShelter , 3, 5\u3009\nin this sequence of actions is\nn\u20321 = \u3008f, detectShock , buildShelter , 7, 5\u3009\nWhere dlins is calculated based on Def. 5"}, {"heading": "3.6. Semantics", "text": "Having explained the syntax of the model, we now focus on the semantics. To this end, we need to describe given a normative practical reasoning problem P = (FL,\u2206, A,G,N):\n(i) What the possible courses of action for the agent are and what properties each course of action has. Properties are defined in terms of goals that a sequence of action satisfies, norms it complies with and the norms it violates. This item is discussed in Section 3.6.1. (ii) What different type of conflicts the agent can experience while trying to satisfy its goals and comply with the norms to which it is subject. In Section 3.6.2 we explore this item. (iii) What identifies a sequence of actions as a solution/plan for problem P . Plans are defined in Section 3.6.3."}, {"heading": "3.6.1. Sequences of Actions and their Properties", "text": "Let P = (FL,\u2206, A,G,N) be a normative practical reasoning problem. Also let \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 with ai \u2208 A and tai \u2208 Z+ be a sequence of actions ai executed at time tai . The pair (ai, tai) reads as action ai is executed at time tai \u2208 Z+ s.t. \u2200i < j, tai < taj . The total duration of a sequence of actions, Makespan(\u03c0), is defined in Equation 1.\nMakespan(\u03c0) = max (tai + dai) (1)\nActions in a sequence can be executed concurrently but they cannot start at the same time. This is because the planning problem is defined for a single agent and a single agent is not typically assumed to be able to start two actions at the exact same instant. Also actions in the sequence should not have concurrency conflicts, which are defined below. In our presentation we need to check for the occurrence of specific pairs in a sequence of actions \u03c0, and we thus define the operator \u201c\u2208\u0302\u201d as\n(a, ta) \u2208\u0302 \u03c0 iff  \u03c0 = \u3008(a, ta), . . . , (an, tn)\u3009 or \u03c0 = \u3008(a0, 0), . . . , (a, ta), . . . , (an, tn)\u3009 or \u03c0 = \u3008(a0, 0), . . . , (a, ta)\u3009\nTemporary conflicts prevent the agent from executing two actions under specific constraints, the most common one of which is time. Conflicts caused by time, known as concurrency conflicts between actions, prevent actions from being executed in an overlapping period of time. Blum and Furst (1997) define that two actions ai and aj cannot be executed concurrently, if at least one of the following holds:\n1. The preconditions of ai and aj contradict each other:\n\u2203r \u2208 pr(ai) s.t. \u00acr \u2208 pr(aj) or\n\u2203\u00acr \u2208 pr(ai) s.t. r \u2208 pr(aj) 2. The postconditions of ai and aj contradict each other:\n\u2203r \u2208 ps(ai)+ s.t. \u00acr \u2208 ps(aj)\u2212 or\n\u2203\u00acr \u2208 ps(ai)\u2212 s.t. r \u2208 ps(aj)+\n3. The postconditions of ai contradict the preconditions of aj:\n\u2203r \u2208 ps(ai)+ s.t. \u00acr \u2208 pr(aj) or\n\u2203\u00acr \u2208 ps(ai)\u2212 s.t. r \u2208 pr(aj) 4. The preconditions of ai are contradicted by the postconditions of aj:\n\u2203r \u2208 pr(ai) s.t. \u00acr \u2208 ps(aj)\u2212 or\n\u2203\u00acr \u2208 pr(ai) s.t. r \u2208 ps(aj)+\nWe summarise the four conditions above in Definition 6, where we define what are referred to as conflicting actions in the remainder of this work.\nDefinition 6 (Conflicting Actions). Actions ai and aj have a concurrency conflict if the pre- or post-conditions of ai contradict the pre- or post-conditions of aj. The set of conflicting actions is denoted as cf action :\ncf action = (ai, aj) \u2223\u2223\u2223\u2223\u2223\u2223 \u2203r \u2208 pr(ai) \u222a ps(ai)+,\u00acr \u2208 pr(aj) \u222a ps(aj)\u2212 or \u2203\u00acr \u2208 pr(ai) \u222a ps(ai)\u2212, r \u2208 pr(aj) \u222a ps(aj)+  (2) Example 5. Assume action evacuate with the following specification:\nevacuate =\n\u2329{ populated ,\nShockDetected ,\n} , { evacuated , \u00acpopulated } , 5 \u232a The pre- and post-conditions of this action are inconsistent with the pre- and post-conditions of action buildShelter defined in Example 1:\nbuildShelter = \u2329 areaSecured , evacuated ,\n\u00acShockDetected\n , { shelterBuilt , \u00acevacuated } , 4 \u232a\nTherefore, these two actions cannot be executed concurrently. However, action evacuate effectively contributes to the preconditions of buildShelter , which means they can indeed be executed consecutively.\nDefinition 7 (Sequence of States). Let \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 be a sequence of actions such that @(ai, tai), (aj, taj) \u2208 \u03c0 s.t. tai \u2264 taj < tai + dai , (ai, aj) \u2208 cf action and let m = Makespan(\u03c0). The execution of a sequence of actions \u03c0 from a given starting state s0 = \u2206 brings about a sequence of states S(\u03c0) = \u3008s0, \u00b7 \u00b7 \u00b7 sm\u3009 for every discrete time interval from 0 to m.\nThe transition relation between states is given by Def. 8. If action ai ends at time k, state sk results from removing delete post-conditions and adding add post-conditions of action ai to state sk\u22121. If there is no action ending at sk, the state sk remains the same as sk\u22121. We first define Ak as the set of action/time pairs such that the actions end at some specific state sk:\nAk = {(ai, tai) \u2208 \u03c0 | k = tai + dai} (3)\nNote that sk is always well-defined since two actions with inconsistent postconditions, according to Def. 6 belong to cf action so they cannot be executed concurrently and thus they cannot end at the same state.\nDefinition 8 (State Transition). Let \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 and let S(\u03c0) = \u3008s0, \u00b7 \u00b7 \u00b7 sm\u3009 be the sequence of states brought about by \u03c0:\n\u2200k > 0 : sk = (sk\u22121 \\ ( \u22c3 a\u2208Ak ps(a)\u2212) \u222a \u22c3 a\u2208Ak ps(ai) + Ak 6= \u2205\nsk\u22121 Ak = \u2205 (4)\nWe now turn our attention to the properties of each sequence of actions.\nDefinition 9 (Goal Satisfaction). Goal requirements should hold in order to satisfy the goal. A sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 (an, tan)\u3009 satisfies goal g if there is at least one state sk \u2208 S(\u03c0) that satisfies the goal:\n\u03c0 |= r(g) iff \u2203 sk \u2208 S(\u03c0) s.t. sk |= r(g) (5)\nThe set of goals satisfied by \u03c0 is denoted as G\u03c0:\nG\u03c0 = {g | \u03c0 |= r(g)} (6)\nDefinition 10 (Activated Norms). A norm n = \u3008do, acon, asub, dl, c\u3009 is instantiated in a sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 if its activation condition acon belongs to the sequence of actions. Let N\u03c0 be the set of instantiations of various norms in \u03c0 defined in Equation 7. Note that dlins is calculated based on Definition 5.\nN\u03c0 = {\u3008do, acon , asub , dl ins , c\u3009 | \u3008do, acon, asub, dl, c\u3009 \u2208 N, (acon, tacon) \u2208\u0302 \u03c0} (7)\nDefinition 11 (Obligation Compliance). A sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 complies with an obligation n = \u3008o, acon , asub , dl ins , c\u3009 if acon is executed in \u03c0 and asub, starts (cf. Eq. 8) or starts and ends (cf. Eq. 9) within the period when the condition holds and when the deadline expires:\n\u03c0 |= n iff (acon, tacon), (asub, tasub) \u2208\u0302 \u03c0 s.t. tasub \u2208 [tacon + dacon , dl ins) (8)\n\u03c0 |= n iff (acon, tacon), (asub, tasub) \u2208\u0302 \u03c0 s.t. [tasub , tasub + dasub ] \u2286 [tacon + dacon , dlins) (9)\nDefinition 12 (Obligation Violation). A sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 violates obligation nins = \u3008o, acon, asub, dlins, c\u3009 if acon is executed in \u03c0, but asub does not start (Equation 10), or does not start and end (Equation 11) in the period between the state when the condition holds and when the deadline expires.\n\u03c0 6|= n iff (acon, tacon) \u2208\u0302 \u03c0, (asub, tasub) \u03026\u2208 \u03c0 s.t. tasub \u2208 [tacon + dacon , dlins) (10)\n\u03c0 6|= n iff (acon, tacon) \u2208\u0302 \u03c0, (asub, tasub) \u03026\u2208 \u03c0 s.t. [tasub , tasub + dasub ] \u2286 [tacon + dacon , dlins) (11)\nExample 6. Let there be the following instantiated version\nn\u20322 = \u3008o, detectPoison, stopWater , 8, 10\u3009\nof norm n2 = \u3008o, detectPoison, stopWater , 2, 10\u3009\nfrom Example 3. The compliance period for this norm in displayed in the figure below. According to Def. 11 in its Eq. 8, if tstopWater belongs to this period, this norm instance is complied with; otherwise, according to Def. 12 in its Eq. 10, the norm is violated. This is illustrated by the following diagram:\n5 6 8 detectPoison compliance period\nExample 7. Let there be the following instantiated version\nn\u20323 = \u3008o, detectEarthquake, blockMainRoad , 7, 12\u3009\nof norm n3 = \u3008o, detectEarthquake, blockMainRoad , 5, 12\u3009\nwhich obliges the agent to have blocked the main road within 5 units of time after detecting an earthquake. Since the post-conditions of action blockMainRoad are brought about at the end of its execution, according to Def. 11 (Eq. 9), this norm is complied with if blockMainRoad starts and ends between time points 2 and 7. Otherwise, according to Def. 12 (Eq. 11) this norm is violated.\nDefinition 13 (Prohibition Compliance). A sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 complies with prohibition n = \u3008f, acon, asub, dlins, c\u3009 if acon, is executed and asub, does not start (Eq. 12) or does not start and end (Eq. 13) in the period when the condition holds and the deadline expires. Formally:\n\u03c0 |= n iff (acon, tacon) \u2208\u0302 \u03c0, (asub, tasub) \u03026\u2208 \u03c0 s.t. tasub \u2208 [tacon + dacon , dlins) (12)\n\u03c0 |= n iff (acon, tacon) \u2208\u0302 \u03c0, (asub, tasub) \u03026\u2208 \u03c0 s.t. [tasub , tasub + dasub ] \u2286 [tacon + dacon , dlins) (13)\nDefinition 14 (Prohibition Violation). A sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 violates prohibition n = \u3008f, acon, asub, dlins, c\u3009 iff acon, has occurred and asub starts (Eq. 14) or starts and ends (Eq. 15) in the period between when the condition holds and when the deadline expires. Formally:\n\u03c0 6|= n iff (acon, tacon), (asub, tasub) \u2208\u0302 \u03c0 s.t. tasub \u2208 [tacon + dacon , dlins) (14)\n\u03c0 6|= n iff (acon, tacon), (asub, tasub) \u2208\u0302 \u03c0 s.t. [tasub , tasub + dasub ] \u2286 [tacon + dacon , dlins) (15)\nExample 8. Let there be the following instantiated version\nn\u20321 = \u3008f, detectShock , buildShelter , 6, 5\u3009\nof norm n1 = \u3008f, detectShock , buildShelter , 3, 5\u3009\npresented in Ex. 3. The compliance period for this norm in displayed in the figure below. According to Def. 14 (Eq. 14), if tbuildShelter belongs to this period, this norm instance is violated; otherwise, according to Def. 13 (Eq. 12), it is complied with.\nExample 9. Let there be the following instantiated version\nn\u20324 = \u3008f, detectEarthquake, blockMainRoad , 7, 12\u3009\nof norm n4 = \u3008f, detectEarthquake, blockMainRoad , 5, 12\u3009\nwhich forbids the agent from blocking the main road within 5 units of time after detecting an earthquake. Since the post-conditions of action blockMainRoad are brought about at the end of its execution, according to Def. 13 (Eq. 13), this norm is violated if blockMainRoad starts and ends between time points 2 and 7. Otherwise, according to Def. 14 (Eq. 15) this norm is complied with. This is illustrated by the diagram below.\nThe set of norms complied with and violated in \u03c0 are denoted as Ncmp(\u03c0) and Nvol(\u03c0) respectively, and defined as follows:\nNcmp(\u03c0) = {nins \u2208 N\u03c0 | \u03c0 |= nins} (16)\nNvol(\u03c0) = {nins \u2208 N\u03c0 | \u03c0 6|= nins} (17)\nTo make sure there are no norms pending at m = Makespan(\u03c0), we assume that the norm deadlines are smaller than m. Therefore, all the activated norms in \u03c0 are either complied with or violated by time m:\nN\u03c0 = Ncmp(\u03c0) \u222aNvol(\u03c0) (18)\nAlternatively, it could be assumed that the norms that are pending (i.e. neither violated nor complied with) at m are all considered as complied with or violated."}, {"heading": "3.6.2. Conflict", "text": "In the previous section we defined when a sequence of actions satisfies a goal, complies with or violates a norm. A possible cause for not satisfying a certain goal is the conflict between the goal and another goal or norm. Likewise, violating a norm could help in reaching a goal or complying with another norm. In this work we do not concern ourselves directly with detecting or resolving conflicts, instead, we focus on the consequences of such conflicts on the agent behaviour. To make this work self-contained, however, we briefly review the causes of conflicts between goals, between norms and between goals and norms. We leave for future work the provision of agents with the capability to reason about the plans and consequently inferring the conflict between goals, between norms and between goals and norms.\nAn agent may pursue multiple goals or desires at the same time and it is likely that some of these goals conflict (van Riemsdijk et al., 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints. Rahwan and Amgoud (2006) on the other hand, define two desires as conflicting if the sets of beliefs that supports the achievement of desires are contradictory. Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.g. beliefs and norms) is required. Some (e.g., (Toniolo, 2013)) have adopted a static view on goal conflict, in which conflicting goals are mutually-exclusive, hence impossible to satisfy in the same plan regardless of the order or choice of actions in the plan. Limited and bounded resources (e.g. time, budget, etc.) are debated as another cause of conflict between goals (Thangarajah et al., 2002).\nLo\u0301pez y Lo\u0301pez et al. (2005) discuss conflict between goals and norms in terms of goals being hindered by norms or vice-versa. The same applies to the approach offered by Modgil and Luck (2008), suggesting a mechanism to resolve the conflicts between desires and normative goals. In this approach, norms are represented as system goals that may conflict with an agent\u2019s goals or desires. Social goals and individual goals do not need to conflict directly. Instead, conflict arises from the reward or punishment of complying with or violating a norm that may facilitate or hinder some of the agent\u2019s individual\ngoals. Shams et al. (2015) identify the conflict between norms and goals as follows. When an obligation forces the agent to take an action that has postconditions that are inconsistent with the requirements of a goal, they may come into conflict. On the other hand, when an action is prohibited, and the postconditions of that action contribute to a goal, they may conflict.\nConflict between norms have been studied in multi-agent systems (e.g., Vasconcelos et al. (2009)) as well as other domains such as legal reasoning (e.g., (Sartor, 1992)). When faced with conflicting norms, the agent cannot comply with both of them and hence one of the norms is violated. In terms of action-based norms, Shams et al. (2015) define two obligations conflicting if they oblige the agent to take two conflicting actions (cf. Def. 6) in an overlapping time interval. Likewise, an obligation and a prohibition cause conflict if they oblige and forbid the agent to execute the same action in an overlapping time interval.\nHaving defined sequences of actions and the properties and conflicts they can involve, we can now define which sequences of action can be identified as plans in the next section."}, {"heading": "3.6.3. Plans", "text": "In classical planning a sequence of actions \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tn)\u3009 is identified as a plan if all the fluents in the initial state, do hold at time 0 and for each i, the preconditions of action ai hold at time tai , and the goal of planning problem is satisfied in time m, where m = Makespan(\u03c0). However, extending the conventional planning problem by multiple potentially conflicting goals and norms requires defining extra conditions in order to make a sequence of actions a plan and a solution for P . In what follows, we define what is required to identify a sequence of actions as a plan.\nDefinition 15 (Plan). A sequence of actions \u03c0 = \u3008(a0, 0), . . . , (an, tan)\u3009 s.t. @ (ai, tai), (aj, taj) \u2208\u0302 \u03c0 s.t. tai \u2264 taj < tai + dai , (ai, aj) \u2208 cf action is a plan for the normative practical reasoning problem P = (FL,\u2206, A,G,N) if the following conditions hold: \u2022 fluents in \u2206 (and only those fluents) hold in the initial state: s0 = \u2206 \u2022 the preconditions of action ai holds at time tai and throughout the exe-\ncution of ai: \u2200k \u2208 [tai , tai + dai), sk |= pr(ai) \u2022 plan \u03c0 satisfies a non-empty subset of goals: G\u03c0 6= \u2205\nThe utility of a plan \u03c0 is defined by deducting the penalty costs of violated norms from the value gain of satisfying goals (Equation 19). The set of\noptimal plans, Opt , are those plans that maximise the utility. Utility(\u03c0) = \u2211 gi\u2208G\u03c0 v(gi)\u2212 \u2211 nj\u2208Nvol(\u03c0) c(nj) (19)\nExamples of calculating the utility of plans are in Appendix B. The set Opt is empty only if there are no plans for the planning problem. Otherwise, the utility function is guaranteed to terminate and find the optimal plans and hence populate the set Opt."}, {"heading": "4. Implementation", "text": "In this section, we demonstrate how a normative practical reasoning problem P = (FL,\u2206, A, G,N) (cf. Def. 1), can be implemented. Our implementation should be seen as a proof of concept that provides a computational realisation of all aspects of the formal model. We use Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988) to propose such an implementation. Recent work on planning in ASP (To et al., 2015) demonstrates that in terms of general planners ASP is a viable competitor. The Event Calculus (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative reasoning frameworks, such as those of Alrawagfeh and Meneguzzi (2014) and Artikis et al. (2009). Our proposed formal model is independent of language and could be translated to EC and hence to a computational model. However, the one-step translation to an ASP is preferred because the formulation of the problem is much closer to a computational model, thus there is a much narrower conceptual gap to bridge. Furthermore, the EC implementation language is Prolog, which although syntactically similar to ASP, suffers from non-declarative features such as clause ordering affecting the outcome and the cut (\u201c!\u201d) operator, jeopardising its completeness. Also, its query-based nature which focuses on one query at a time, makes it cumbersome to reason about all plans.\nIn what follows, we provide a brief introduction to ASP in Section 4.1, followed by the mapping of normative practical reasoning problem P = (FL,\u2206, A, G,N) (cf. Def. 1) into ASP in Section 4.2. In the latter section we show how P is mapped into an answer set program such that there is a one to one correspondence between solutions for the problem and the answer sets of the program. The mapping itself is provided in Figure 2. The explanation of the mapping is presented in Sections 4.2.1\u20134.2.6, with cross references to the code fragments listed in Figure 2."}, {"heading": "4.1. Answer Set Programming", "text": "ASP is a declarative programming paradigm using logic programs under Answer Set semantics (Lifschitz, 2008). Like all declarative paradigms it has the advantage of describing the constraints and the solutions rather than the writing of an algorithm to find solutions to a problem. A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003). There are several efficient solvers for AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al., 1999) are currently the most widely used.\nThe basic components of AnsProlog are atoms that are constructs to which one can assign a truth value. An atom can be negated, adopting negation as failure (naf), which establishes that a negated atom not a is true if there is no evidence to prove a. Literals are atoms a or negated atoms not a (referred to as naf-literals). Atoms and literals are used to create rules of the general form \u201ca :\u2212 b1, ..., bm, not c1, ..., not cn.\u201d where a, bi and cj are atoms. Intuitively, a rule means that if all atoms bi are known/true and no atom cj is known/true, then a must be known/true. We refer to a as the head of the rule and b1, ..., bm, not c1, ..., not cn as the body of the rule. A rule with an empty body is called a fact and a rule with an empty head is called a constraint, indicating that no solution should be able to satisfy the body. Another type of rules are called choice rules and are denoted as l{h0, \u00b7 \u00b7 \u00b7 , hk}u : \u2212 l1, \u00b7 \u00b7 \u00b7 , lm, not lm+1, \u00b7 \u00b7 \u00b7 , not ln., in which his and lis are atoms. l and u are integers and the default values for them are 0 and 1, respectively. A choice rule is satisfied if the number of atoms belonging to {h0, \u00b7 \u00b7 \u00b7 , hk} that are true/known is between the lower bound l and upper bound u. A program is a set of rules representing their conjunction. The semantics of AnsProlog is defined in terms of answer sets, i.e. assignments of true and false to all atoms in the program that satisfy the rules in a minimal and consistent fashion. A program may have zero or more answer sets, each corresponding to a solution. We refer to Appendix D and Baral (2003) for a formal treatment of the semantics of ASP."}, {"heading": "4.2. Translating the Normative Practical Reasoning Problem into ASP", "text": "Prior to describing the mapping (Figure 2) of normative practical reasoning problem P = (FL,\u2206, A, G,N) into ASP, we list the atoms that we use in the mapping in Table 1. The description of the mapping is presented in the following sections with references to Figure 2. Note that variables are in capitals and grounded variables are in small italics."}, {"heading": "4.2.1. States", "text": "In Section 3.6 we described the semantics P = (FL,\u2206, A,G,N) over a set of states. The facts produced by line 1 provide the program with all available states for plans of maximum length q. Currently, the length of the plans needs to be determined experimentally. We plan to automate this using incremental features of ASP solver clingo4 (Gebser et al., 2011). Line 2 encodes that the initial fluents, (x \u2208 \u2206) need to hold at state 0 which is achieved by the facts holdsat(x, 0). Fluents are inertial, they continue to hold unless they are terminated. Inertia is encoded in lines 3\u20134. Termination is modelled through the predicate terminated(X,S)."}, {"heading": "4.2.2. Actions", "text": "This section describes the details of encoding of actions. Each durative action is encoded as action(a, d) (line 5), where a is the name of the action and d is its duration. The preconditions pr(a) of action a hold in state s if s |= pr(a). This is expressed in line 6 using atom pre(a,S) In order to make the coding more readable we introduce the shorthand EX(X,S), where X is a set of fluents that should hold at state S. For all x \u2208 X, EX(X,S) is translated into holdsat(x,S) and for all \u00acx \u2208 X, EX(\u00acX,S) is translated into not EX(x,S) using negation as failure.\nThe agent has the choice to execute any of its actions in any state. This is expressed in the choice rule in line 7. Since no lower or upper bound is given for {executed(A,S)}, the default value of 0{executed(A,S)}1 is implied, meaning that the agent has the choice of whether or not to execute an action. Following the approach in Blum and Furst (1997), we assume that the preconditions of a durative action should be preserved when it is in progress. We first encode the description of an action in progress, followed by ruling out the possibility of an action being in progress in the absence of its preconditions. A durative action is in progress, inprog(A,S), from the state in which it starts up to the state in which it ends (lines 8\u20139). Line 10, rules out the execution of an action, when the preconditions of the action do not hold during its execution. A further assumption made is that the agent cannot start two actions at exactly the same time (line 11\u201312). Once an action starts, the result of its execution is reflected in the state where the action ends. This is expressed through (i) lines 13\u201314 that allow the add postconditions of the action to hold when the action ends, and (ii) line 15\u201316 that allow the termination of the delete postconditions. Termination takes place in the state before the end state of the action: the reason for this is the inertia of fluents that was expressed in lines 3\u20134. Thus delete post-conditions of an action are terminated in the state before the end state of the action, so that they will not hold in the following state, in which the action ends (i.e. they are deleted from the state)."}, {"heading": "4.2.3. Goals and Norms", "text": "Line 17 encodes goal g with value v as a fact. Goal g is satisfied in state s if s |= g. This is expressed in line 18, where g+ and g\u2212 are the positive and negative literals in the set g.\nFor the norms we note that, following Definitions 11\u201314, compliance and violation of a norm can be established based on the start state of action\u2019s\nCreating states: \u2200 k \u2208 [0, q] 1 state(k).\nSetting up the initial state: \u2200 x \u2208 \u2206 2 holdsat(x, 0).\nRule for fluent inertia\n3 holdsat(X,S2) :- holdsat(X,S1), not terminated(X,S1), 4 state(S1), state(S2), S2=S1+1.\nCreating the actions and their preconditions: \u2200a \u2208 A, a = \u3008pr, ps, d\u3009 5 action(a, d). 6 pre(a,S) :- EX(pr(a)+,S), not EX(pr(a)\u2212,S), state(S).\nCommon constraints on action execution\n7 {executed(A,S)} :- action(A,D), state(S). 8 inprog(A,S2) :- executed(A,S1), action(A,D), 9 state(S1), state(S2), S1 <=S2, S2<S1+D.\n10 :- inprog(A,S), action(A,D), state(S), not pre(A,S). 11 :- executed(A1,S), executed(A2,S), A1!=A2, 12 action(A1,D1), action(A2 ,D2), state(S).\nAdding positive postconditions of actions: ps(a)+ = X \u21d4 \u2200x \u2208 X\u00b7 13 holdsat(x,S2) :- executed(a,S1), action(a, d), 14 state(S1), state(S2), S2=S1+d.\nTerminating negative post conditions of actions: ps(a)\u2212 = X \u21d4 \u2200x \u2208 X\u00b7 15 terminated(x,S2) :- executed(a,S1), action(a, d), 16 state(S1), state(S2), S2=S1+d-1.\nCreating the goals: \u2200g \u2208 G 17 goal(g, v). 18 satisfied(g,S) :- EX(g+,S), not EX(g\u2212,S), state(S).\nCreating the norms: \u2200n = \u3008o|f, asub, acon, dl, c\u3009 \u2208 N 19 norm(n, c).\n\u2200n = \u3008o, asub, acon, dl, c\u3009 \u2208 N 20 holdsat(o(n,S1 ,asub, dl+S2),S2) :- executed(acon,S1), 21 action(acon, d), S2=S1+d,state(S1), state(S2). 22 cmp(o(n,S1,a,DL),S2) :- holdsat(o(n,S1 ,a,DL),S2), 23 executed(a,S2),action(a, d),state(S1),state(S2),S2!=DL. 24 terminated(o(n,S1,a,DL),S2) :- cmp(o(n,S1,a,DL),S2), 25 state(S1), state(S2). 26 vol(o(n,S1,a,DL),S2) :- holdsat(o(n,S1 ,a,DL),S2), DL=S2 , 27 state(S1), state(S2). 28 terminated(o(n,S1,a,DL),S2) :- vol(o(n,S1,a,DL),S2), 29 state(S1), state(S2).\n\u2200n = \u3008f, asub, acon, dl, c\u3009 \u2208 N 30 holdsat(f(n,S1 ,asub, dl+S2),S2) :- executed(acon,S1), 31 action(acon, d),S2=S1+d,state(S1), state(S2). 32 cmp(f(n,S1,a,DL),S2) :- holdsat(f(n,S1 ,a,DL),S2), 33 action(a, d), DL=S2 , state(S1), state(S2). 34 terminated(f(n,S1,a,DL),S2) :- cmp(f(n,S1,a,DL),S2), 35 state(S1), state(S2). 36 vol(f(n,S1,a,DL),S) :- holdsat(f(n,S1,a,DL),S2), 37 executed(a,S2),state(S1) state(S2), S2!=DL. 38 terminated(f(n,S1,a,DL),S2) :- vol(f(n,S1,a,DL),S2), 39 state(S1), state(S2).\nPlans need to satisfy at least one goal\nexecution that is the subject of the norm, or at the end state of action\u2019s execution. In the encoding we show an implementation of the former; the latter can be catered for in a similar fashion.\nLines 19\u201339 deal with obligations and prohibitions of the form n = \u3008d o, acon , asub , dl , c\u3009. Line 19 encodes norm n with penalty cost c upon violation. In order to implement the concepts of norm compliance and violation for instantiated norms, we introduce a normative fluent that holds over the compliance period. The compliance period begins from the state in which action acon \u2019s execution ends. The compliance period then ends within dl time units of the end of action acon , which is denoted as dl\n\u2032 in the normative fluent. For instance, fluent o(n1, s \u2032, asub , dl \u2032) expresses that the instance of norm n1 that was activated in state s \u2032, obliges the agent to execute action asub before deadline dl \u2032. The state in which the norm is activated is a part of the fluent to distinguish different activations of the same norm from one another. For example, fluent o(n1, s \u2032\u2032, asub , dl \u2032\u2032) refers to a different instance of norm n1 that was activated in s\u2032\u2032. An obligation fluent denotes that action asub \u2019s execution should begin before deadline dl\n\u2032 or be subject to violation, while prohibition fluent f(n2, s \u2032, asub , dl \u2032) denotes that action asub should not begin before deadline dl \u2032 or be subject to violation. Lines 20\u201321 and 30\u201331 establish respectively the obligation and prohibition fluents that hold for the duration of the compliance period.\nIn terms of compliance, if the obliged action starts during the compliance period in which the obligation fluent holds, the obligation is complied with (line 22\u201323). Compliance is denoted by the atom cmp. The obligation fluent is terminated in the same state that compliance is detected (lines 24\u201325). If the deadline expires and the obligation fluent still holds, it means that the compliance never occurred during the compliance period and the norm is therefore violated (lines 26\u201327). The atom vol denotes violation. The obligation fluent is terminated when the deadline expires and the norm is violated (lines 28\u201329).\nOn the other hand, a prohibition norm is violated if the forbidden action begins during the compliance period in which the prohibition fluent holds (lines 36\u201337). As with the obligation norms, after being violated, the prohibition fluent is terminated (lines 38\u201339). If the deadline expires and the prohibition fluent still holds, that means the prohibited action did not begin during the compliance period and the norm is therefore complied with (lines 32\u201333). The obligation fluent is terminated in the same state that compliance is detected (lines 34\u201335)."}, {"heading": "4.2.4. Mapping Answer Sets to Plans", "text": "Having implemented the components of P = (FL,\u2206, A,G,N), we now encode the criteria for a sequence of actions to be identified as a plan and a solution to P . The rule in line 41 is responsible for constraining the answer sets to those that fulfill at least one goal. This is done by excluding answers that do not satisfy any goal. The input for this rule is provided in line 40, where goals are marked as satisfied if they are satisfied in at least one state. Prevention of concurrent conflicting actions is achieved via lines 42\u201343 which establish that two such actions cannot be in progress simultaneously. This concludes the mapping of a formal planning problem to its computational counterpart in AnsProlog. For a problem P we refer to the program consisting of lines 1\u201343 as \u03a0PBase .\nAs mentioned in Section 2, the formulation of our Disaster scenario is provided in Appendix A. The mapping of the scenario to its computational model follows in Appendix B."}, {"heading": "4.2.5. Soundness and Completeness of Implementation", "text": "The following theorems state the correspondence between the solutions for problem P and answer sets of program \u03a0PBase.\nTheorem 1 (Soundness). Let P = (FL, I, A,G,N) be a normative practical reasoning problem with \u03a0PBase as its corresponding AnsProlog program. Let Ans be an answer set of \u03a0PBase, then a set of atoms of the form executed(ai, tai) \u2208 Ans encodes a solution to P .\nThe proof of this theorem is presented in Appendix C. This is a proof by structure that explains how the structure of \u03a0PBase satisfies the conditions that identifies a sequence of actions as a plan.\nTheorem 2 (Completeness). Let \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 be a plan for P = (FL, I, A,G,N). Then there exists an answer set of \u03a0PBase containing atoms executed(ai, tai) that correspond to \u03c0.\nThe proof of this theorem is presented in Appendix D. In this proof the program is first transformed to a program without any naf-literals and choice rules. We then take a candidate answer set for the program and show that it is a minimal model for the transformed program."}, {"heading": "4.2.6. Optimal Plans", "text": "In order to find optimal plans in Figure 3 we show how to encode the utility function defined by Eq. 19. The sum of values of goals satisfied in a plan is calculated in line 44, where we use an ASP built-in aggregate #sum. This aggregate is an operation on a set of weighted literals that evaluates to the sum of the weights of the literals. We first assign the value of goals as the weight of literals satisfied(G) and then use #sum to compute the sum of value of all goals satisfied.\nThe sum of costs of norms violated in a plan is calculated in line 47 using the same aggregate. However, the weight of the literal is the cost of punishment of the norms. The input for this line is given in lines 45 and 46, where violated norms are distinguished based on the combination of the norm id n and the state s in which they are instantiated. Having calculated value(TV) and cost(TC), the utility of a plan is computed in line 48, which is subject to a built-in optimisation statement in the final line. This optimisation statement identifies an answer set as optimal if the sum of weights of literals that hold is maximal with respect to all answer sets of the program. By assigning U as the weight of literal utility(U) we compute the answer set that maximises the utility.\nLet program \u03a0P = \u03a0PBase \u222a \u03a0\u2217P , where \u03a0\u2217P consists of lines 44\u201349. The following theorem states the correspondence between the plans for problem P and answer sets of program \u03a0P .\nTheorem 3. Given a normative practical reasoning problem P = (FL, I, A, G,N), for each answer set Ans of \u03a0 the set of atoms of the form executed(ai, tai) in Ans encodes an optimal solution to P . Conversely, each solution to the problem P corresponds to a single answer set of \u03c0.\nThis theorem follows immediately from Theorem 1 and 2 and the structure of program \u03a0\u2217P ."}, {"heading": "5. Related Work", "text": "In this section we first review a number of architectures aimed at incorporating normative reasoning into practical reasoning which we group into BDI (Section 5.1) and non-BDI (Section 5.2). Then in Section 5.3 we examine different classifications of these architectures according to the approaches taken. In the same section we also compare these approaches with the approach proposed here."}, {"heading": "5.1. BDI Architectures with Normative Reasoning", "text": "There is a substantial body of work on the integration of norms into the BDI architecture (Rao and Georgeff, 1995), but motivation, theory and practice vary substantially. A key assumption here is that a plan library (i.e. a set of pre-defined plans) exists and the agent uses normative considerations to choose and/or customise a provided plan, rather than generating a normcompliant plan. We review several normative BDI frameworks and compare them with the approach proposed here.\nThe BOID architecture (Broersen et al., 2001) extends BDI with the concept of obligation and uses agent types such as social, selfish, etc. to handle the conflicts between beliefs, desires, intentions and obligations. For example, selfish agents give priority to their desires in case of conflict, whereas social agents give priority to their obligations. Since beliefs, desires, intentions and obligations are all represented as a set of rules, priorities are assigned to rules and subsequently used to resolve the conflict. BOID\u2019s rich rule-based language makes for a very expressive system, but it is now of largely historical interest, since the implementation is complicated \u2013 no reference version is currently available \u2013 and has a high computational complexity.\nNoA (Kollingbaum, 2005) is a normative language and agent architecture. As a language it specifies the normative concepts of obligation, prohibition and permission to regulate a specific type of agent interaction called \u201csupervised interaction\u201d. As a practical reasoning agent architecture, it describes how agents select a plan from a pre-generated plan library such that the norms imposed on the agent at each point of time are observed. NoA agents do not have internal motivations such as goals or values that might conflict with norms, therefore the agent will always be norm compliant. Publications on NoA do not discuss its evaluation and validate the implementation using examples, which makes the status of the implementation unclear.\n\u03bd-BDI (Meneguzzi et al., 2015) enables BDI agents to perform normative reasoning for the purpose of customising pre-existing plans that ensure compliance with the set of norms imposed on the agent. That said, there are mechanisms in place to allow norm violation where goal achievement would not otherwise be possible. In contrast to BOID and NoA, much attention is paid to the practicality and computational efficiency of reasoning in \u03bd-BDI. This is evidenced by the complexity analysis of the algorithms for the norm management mechanism, complemented by empirical analysis, and which both report reasonable (sic) computational costs.\nN-2APL (Alechina et al., 2012) is a norm-aware agent programming language based on 2APL (Dastani, 2008) that supports representation of and reasoning about beliefs, goals, plans, norms, sanctions and deadlines. The N-2APL agents select plans to execute such that they fulfill obligations imposed on agents. The agent can also choose to suppress certain plans to avoid violating prohibitions. Scheduling of plans is conducted based on plan deadlines or possible sanctions associated with the plans. The scheduling does not concern itself with construction of interleaving plans, thus scheduling boils down to sequencing of plans. Norms in N-2APL are quite simple, being either obligations to carry out and prohibitions not to carry out a specified action. The norms are not conditional (i.e. there is no activation condition defined that triggers the norm) and unlike obligations the prohibitions do not have deadlines.\nN-Jason (Lee et al., 2014) sets out an extension of the Jason (Bordini et al., 2007) variant of the BDI architecture to account for norms in plan selection and to handle priorities in plan scheduling. Like N-2APL, N-Jason enables the underlying implementation of the BDI architecture to carry out norm-aware deliberation and provides a run-time norm execution mechanism, through which new unknown norms \u2013 as long as they pertain to known actions \u2013 are recognized and can trigger plans. To be able to process a norm such as an obligation, which includes a deadline, the agent architecture must be able to reason about deadlines and priorities, and choose between plans triggered by a particular norm. Consequently, N-Jason extends the syntax of the plan library to allow priority annotation, and the scheduling algorithm of AgentSpeak(RT) to operate in the context of Jason/AgentSpeak(L) and provide \u201creal-time agency\u201d."}, {"heading": "5.2. Non-BDI Architectures with Normative Reasoning", "text": "A second smaller group of research work considers the problem either from a non-BDI perspective or are agent-architecture agnostic. One result of not being tied to BDI is not necessarily relying on a pre-generated plan library, which raises issues of how to generate norm-compliant plans.\nOren et al. (2011) do utilise a pre-generated plan, like the list above, but take norms into consideration when deciding how to execute the plan with respect to the norms triggered by that plan. Specifically, the approach aims to adjust the chosen plan to account for the norms that govern the plan actions at each point in time, where the norm expresses constraints on the values that can be assigned to variables in a plan action. The adjustments of values in actions specify how the agent should execute a plan, such that the cost of violated norms is outweighed by the reward from norm compliance. The most preferred plan is therefore the one that maximises this metric.\nPanagiotidi et al. (2012a) take norms into account in plan generation where the planning problem is specified in PDDL 2.1 (Fox and Long, 2003). The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan. Although this mechanism enables an agent to cope with the dynamics of operating in an open environment, checking the normative position of an agent after each action imposes a high computational cost on the plan generation phase.\nShams et al. (2015) define an approach to practical reasoning that considers norms in both plan generation and plan selection. The agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal. The main contributions of Shams et al. (2015) are (i) the introduction of an enforcement approach that is a combination of utility-based and pressure-based compliance methods (Lo\u0301pez y Lo\u0301pez et al., 2005), and (ii) formalising the conflicts between goals, between norms, and between goals and norms. There is a penalty cost for norm violation regardless of the existence of conflict. Whenever a norm is triggered, outcomes of norm compliance and violation, and their impacts on the hinderance or facilitation of other goals and norms, are both generated and compared by utility. In those cases where there are no conflicts and no goals or norms are hindered by the punishment of violation, the loss of utility drives the agent towards compliance. Plans\nare selected based on the comparison of the utility of the goals satisfied and cost of norms violated in the entire plan."}, {"heading": "5.3. Normative Reasoning Mechanisms", "text": "We now consider the approaches accounting for norms in practical reasoning in order to uncover similarities across architectures. Not surprisingly, much work stems from planning and how to take account of norms in the plan identification or construction process. There are broadly three approaches:\n1. Choosing a plan that is norm compliant (e.g., NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan. Shams et al. (2015) attempt to balance compliance on the part of the agent (where the agent chooses a norm-compliant action in preference) with enforcement (where the agent is discouraged from non-norm-compliance via punishments for norm violation), but is not robust to plan failure. Furthermore, in Shams et al. (2015), conflict is formulated in advance by taking a static view about conflicts. For instance, two goals that are logically inconsistent, cannot be satisfied in the same plan, regardless of the order or choice of actions in a plan.\nIn contrast, in the work presented here, conflicts are not formulated in advance; instead, they are inferred from plans. Therefore, the agent might be able to schedule its actions such that two goals that are logically inconsistent are satisfied in the same plan at different points in time. As discussed in Section 3.6, the norm representation is extended to accommodate compliance and violation in the presence of durative actions more flexibly by allowing compliance to be defined as the start or end of the action that is the subject of the norm. Table 2 shows a summary of related framework to the framework proposed in this paper. For the current work, the parameters compared are the same as Shams et al. (2015). The majority of frameworks, including our framework, deal with obligations and prohibitions. Activation condition, however, varies in those that do support conditional norms. An activation condition presented as an action can be expressed as a state that satisfies the post-conditions of the action. Unlike many related frameworks, we have exploited the explicit representation of time in formal model to encode the norm de-activation condition as a time instant. As discussed in Section 3.5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper. Another important differentiation point between our work and the related ones\n3The de-activation condition only applies to obligations. Prohibitions do not have such a condition.\n4Operator w stands for power and indicates the capability of doing something in prohibitive societies, where actions are not allowed unless empowered and explicitly permitted.\nis that our model is capable of handling durative actions and their execution concurrently, as well as dealing with norm compliance and violation in the presence of durative actions."}, {"heading": "6. Conclusions and Future Work", "text": "An agent performing practical reasoning in an environment regulated by norms constantly needs to weigh up the importance of goals to be satisfied and norms with which to comply. This decision process is only possible when the agent has access to the set of all possible plans available and the agent can ascertain the impact of its decision on entire plans. This research offers means to capture and measure the impact via utility functions, offering numeric metrics, so that the decision problem can be reformulated as choosing a plan from a set of generated plans, which maximises its overall utility. While the literature we have surveyed contains practical reasoning frameworks that take into account normative considerations, they are limited in several ways, and we have contrasted them with our approach in this article.\nThe majority of these frameworks are limited to a specific type of agent architecture, mostly BDI, (e.g., (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)). In our research we do not assume any specific architecture. Instead, we adopt a realistic view that agents have capabilities (encoded as the actions they may perform), and they have internal motivations (encoded as the goals of a planning problem). This leaves the option of extending current work to a multi-agent setting where agents might not necessarily have the same architecture.\nIn the approaches set out in the literature the attitude agents have towards norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance, (e.g., (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)). We argue that in certain situations an agent might be better off violating a norm which, if followed, would make it impossible for the agent to achieve an important goal or complying with a more important norm; we enable agents to compare the relative importance of goals and norms via their utilities. Consequently, through our practical reasoning process agents consider all plans (i.e., sequences of actions), including those leading to norm compliance and violation; each plan gets an associated overall utility for its sequences of actions, and norms followed/violated, and agents can decide which of them to pursue. The plan an agent chooses to follow is not necessarily norm-\ncompliant, however, our mechanism guarantees that the decision will maximise the overall plan/norm utility, which justifies the occasional violation of norms as the plan is followed.\nWe see several interesting avenues for future work. Our research currently addresses normative practical reasoning in a single-agent setting, extending to a multi-agent setting seems a natural next step. This idea can be explored both when the agents are collaborating to fulfill common goals, as well as when they are competing to use resources to fulfill their individual goals. In the former case, the best course of action can be identified as one that maximises the overall utility of the system. In the latter, game-theoretic approaches can be utilised to identify a solution that ensure relative optimality for the individuals (e.g. A\u030agotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)).\nWe note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning. Also, the norm representation language can be extended to cater for deadlines that are expressed as reaching a state5 rather than a time instance. For instance, an obligation to open a dam on a river can come in force when the water level is above a certain point, and subsequently terminated when the water level drops below a certain level, regardless of how long it takes for that to happen. We would also like to include permission norms in addition to obligations and prohibitions. The modelling of permissions as exceptions to obligations and prohibitions has been used to justify violations under specific circumstances, (e.g. Oren et al. (2010); Criado (2012)). It is also used as a means to handle the uncertainty and incompleteness of the knowledge of the environment the agents operate in (Alrawagfeh and Meneguzzi, 2014).\n5In such cases the deadline is referred to as a norm termination condition.\nFinally, our implementation should be seen as a proof-of-concept that, apart from replanning, provides a provable computational realisation of all aspects of the formal model. In future, we aim at extending the implementation to accommodate replanning when a plan in progress is interrupted for any reason. The formal model is implementation language neutral so other implementation languages could be used."}, {"heading": "Appendix A. Formulation of the Disaster Scenario", "text": "We provide a formalisation of the scenario set out in Section 2. Let P = (FL,\u2206, A,G,N) be the normative practical reasoning problem for the disaster scenario such that:\n\u2022 FL =  shockDetected , poisonDetected ,waterSupplied , areaSecured , evacuated , shockDetected , shelterBuilt , populated ,wounded ,\nearthquakeDetected ,medicineSupplied , noAccess ,medicsPresent  \u2022 \u2206 = { earthquakeDetected ,medicsPresent , wounded , populated ,waterSupplied }\n\u2022 A = {\ndetectShock , detectPoison, stopWater , buildShelter , evacuate, getMedicine, secure\n} where\ndetectShock = \u3008{}, {shockDetected}, 1\u3009. detectPoison = \u3008{}, {poisonDetected}, 1\u3009.\nstopWater = \u2329{ poisonDetected , waterSupplied } , {\u00acwaterSupplied}, 1 \u232a\nbuildShelter = \u2329 areaSecured , evacuated ,\n\u00acshockDetected\n , { shelterBuilt , \u00acevacuated } , 4 \u232a\nevacuate =\n\u2329{ shockDetected ,\npopulated\n} , { evacuated , \u00acpopulated } , 5 \u232a getMedicine = \u2329{ earthquakeDetected ,\nwounded\n} , {medicine}, 3 \u232a secure = \u2329 {evacuated}, { areaSecured ,\nnoAccess\n} , 3 \u232a\n\u2022 G = {runningHospital , organiseSurvivorCamp}, where:\nrunningHospital = \u2329 medicsPresent , waterSupplied ,\nmedicineSupplied\n , 25 \u232a\norganiseSurvivorCamp = \u2329{ areaSecured , shelterBuilt } , 18 \u232a \u2022 N = {n1, n2}, where: n1 = \u3008f, detectShock , buildShelter , 3, 5\u3009 n2 = \u3008o, detectPoison, stopWater , 2, 10\u3009"}, {"heading": "Appendix B. Mapping of Our Disaster Scenario", "text": "The formal specification of our disaster scenario (Section2) as provided in the previous section can be mapped to its corresponding AnsProlog program following the rules given in Figure 2 on page 25. The corresponding program is shown in Figures B.4-B.8. Optimisation conditions are shown in Figure B.9. The visualisation of the three answer sets of the program is displayed in figures B.10\u2013B.12, where arcs show the actions in progress and the boxes below each state, show the fluents that hold in that state. The fluents in bold are the fluents that are added to the state, while the crossed fluents are the terminated ones. Norms violated in a state are highlighted in red and goals satisfied are highlighted in green. Applying the optimisation statements in Figure B.9, the utility of each plan presented by each answer set is calculated as below, making the plan presented by answer set 3 the optimal plan.\nUtility of plan presented by answer set 1, Figure B.10: Utility(\u03c0Ans1) = v(runningHospital) = 25\nUtility of plan presented by answer set 2, Figure B.11: Utility(\u03c0Ans2) = v(runningHospital) + v(organiseSurvivorCamp) \u2212 c(n1)\u2212 c(n1) = 25 + 18\u2212 5\u2212 5 = 33\nUtility of plan presented by answer set 3, Figure B.12: Utility(\u03c0Ans3) = v(runningHospital) + v(organiseSurvivorCamp) = 43"}, {"heading": "1 violated(n1,S1) :- vol(f(n1,S1,buildShelter ,DL),S2),", "text": "0 1\n2 3\n4 5\n6 7\n8\nea rt h q u a ke\nD et ec\nte d\nm ed\nic sP\nre se n t\np o p u la te d w a te rS u p p lie d w o u n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1 , 0 , b u ild\nS h el te r,\n4 )\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o ck\nD et ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1 , 1 , b u ild\nS h el te r,\n5 )\nf( n\n1, 0,\nb u\nild S\nh el\nte r, 4) m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1 , 2 , b u ild\nS h el te r,\n6 )\nf( n\n1, 1,\nb u\nild S\nh el\nte r, 5) f( n 1, 0, b u ild S h el te r, 4) m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 2, b u ild S h el te\nr, 6)\nf( n\n1, 1,\nb u\nild S\nh el\nte r, 5) f( n 1, 0, b u ild S h el te r, 4) m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 2, b u ild S h el te\nr, 6)\nf( n\n1, 1,\nb u\nild S\nh el\nte r, 5) m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 2, b u ild S h el te\nr, 6)\nm ed\nic in eS\nu p p lie d m ed ic sP re se n t p op u la te d sa ti sfi ed ru n n in gH\nos p\nit al\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nd et ec tS h o ck\nd et ec tS h o ck\nd et ec tS h o ck\nge tM\ned ic in e\nge tM\ned ic in e\n8 9\n1 0\n1 1\n1 2\n13\nea rt h q u ak eD\net ec te d\nm ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt h q u ak eD\net ec te d\nm ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt h q u ak eD\net ec te d\nm ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt h q u ak eD\net ec te d\nm ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt h q u ak eD\net ec te d\nf( n 1 , 1 1 , b u ild\nS h el te r,\n1 5 )\nm ed ic in eS u p p lie d m ed ic sP re se n t p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt h q u ak eD\net ec te d\nf( n 1,\n11 , b u ild S h el te r, 15 )\nm ed ic in eS u p p lie d m ed ic sP re se n t o (n 2 , 1 2 , st o p W\na te r,\n1 5 )\np o is o n D et ec te d p op u la te d ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nge tM\ned ic in e\nd et ec tS h o ck\nd et ec tP oi so n\nF ig\nu re\nB .1\n0 :\nV is\nu a li\nsa ti\no n\no f\na n\nsw er\nse t\n1\n0 1\n2 3\n4 5\n6\nea rt h q u a ke\nD et ec\nte d\nm ed\nic sP\nre se n t\np o p u la te d w a te rS u p p lie d w o u n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1 , 0 , b u ild\nS h el te r,\n4 )\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o ck\nD et ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev a cu a te d m ed ic in eS u p p lie d m ed ic sP re se n t sa ti sfi ed ru n n in gH\nos p\nit al\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nd et ec tS h o ck\nev ac u at e\nge tM\ned ic in e\n6 7\n8 9\n1 0\n11 12\n1 3\nea rt\nh q\nu ak\neD et\nec te d ev a cu a te d m ed ic in eS u p p lie d m ed ic sP re se n t sa ti sfi ed ru n n in gH\nos p\nit al\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t vi ol at ed n 1 ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed f( n 1 , 7 , b u ild\nS h el te r,\n1 1 )\nm ed\nic in\neS u\np p\nlie d\nm ed\nic sP\nre se\nn t\nvi ol\nat ed\nn 1\nru n\nn in\ngH os\np it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed f( n 1 , 8 , b u ild\nS h el te r,\n1 2 )\nf( n\n1, 7,\nb u\nild S\nh el\nte r,\n11 )\nm ed\nic in\neS u\np p\nlie d\nm ed\nic sP\nre se\nn t\nn o A cc es s ru n n in\ngH os\np it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s sa ti sfi ed or ga n is eS u\nrv iv\nor sC\nam p\nru n\nn in\ngH os\np it al se cu re d sh el te rB u ilt sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nse cu re\nd et ec tS h o ck\nd et ec tS h o ck\nb u ild S h el te r\nF ig\nu re\nB .1\n1 :\nV is\nu a li\nsa ti\no n\no f\na n\nsw er\nse t\n2\n0 1\n2 3\n4 5\n6\nea rt h q u a ke\nD et ec\nte d\nm ed\nic sP\nre se n t\np o p u la te d w a te rS u p p lie d w o u n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1 , 0 , b u ild\nS h el te r,\n4 )\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o ck\nD et ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d f( n 1, 0, b u ild S h el te\nr, 4)\nm ed\nic sP\nre se\nn t\np op\nu la\nte d\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic sP re se n t p op u la te d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev a cu a te d m ed ic in eS u p p lie d m ed ic sP re se n t sa ti sfi ed ru n n in gH\nos p\nit al\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nd et ec tS h o ck\nev ac u at e\nge tM\ned ic in e\n6 7\n8 9\n1 0\n11 12\n1 3\nea rt\nh q\nu ak\neD et\nec te d ev a cu a te d m ed ic in eS u p p lie d m ed ic sP re se n t sa ti sfi ed ru n n in gH\nos p\nit al\nsh o\nck D\net ec\nte d\nw at\ner S\nu p\np lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t ru n n in gH os p it al sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n o A cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d ev ac u at ed m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s ru n n in gH os p it al se cu re d sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nea rt\nh q\nu ak\neD et\nec te d m ed ic in eS u p p lie d m ed ic sP re se n t n oA cc es s sa ti sfi ed or ga n is eS u\nrv iv\nor sC\nam p\nru n\nn in\ngH os\np it al se cu re d sh el te rB u ilt sh o ck D et ec te d w at er S u p p lie d w ou n d ed\nse cu re\nb u ild S h el te r\nF ig\nu re\nB .1\n2 :\nV is\nu a li\nsa ti\no n\no f\na n\nsw er\nse t\n3"}, {"heading": "Appendix C. Proof of Theorem 1", "text": "Theorem (Soundness). Let P = (FL, I, A,G,N) be a normative practical reasoning problem with \u03a0PBase as its corresponding AnsProlog program. Let Ans be an answer set of \u03a0PBase, then a set of atoms of the form executed(ai, tai) \u2208 Ans encodes a solution to P .\nProof. We need to prove that program \u03a0PBase (Figure 2) generates all sequences of actions that meet the criteria that identifies a sequence of actions as a plan, as defined in Definition 15. This implies that the sequence of actions that is a part of the answer set satisfies all the criteria to be a solution to the encoded planning program.\nActions and more precisely the postconditions of actions are what cause the change from one state to another one. Line 7 generates all sequences of actions. Lines 13\u201314 changes a state in which some actions end by adding the add postconditions of those actions to the state. In contrast, Lines 15 and 16 terminate the delete postconditions of actions ending in the next state such that those postconditions do not hold in the following state. If there is no action ending in a state, the state remains unchanged as all the fluents are inertial and they hold in the next state unless they are terminated (Line 4). A sequence of actions \u03c0 = \u3008(a0, 0), . . . , (an, tan)\u3009 s.t. @ (ai, tai), (aj, taj) \u2208\u0302 \u03c0 s.t. tai \u2264 taj < tai + dai , (ai, aj) \u2208 cf action is a plan for the normative planning problem P = (FL,\u2206, A,G,N) if the following conditions hold: \u2022 fluents in \u2206 (and only those fluents) hold in the initial state: s0 = \u2206.\nLine 2 ensures that all fluents in \u2206 are added to the initial state s0. \u2022 the preconditions of action ai hold at time tai and throughout the ex-\necution of ai: \u2200k \u2208 [tai , tai + dai), sk |= pr(ai). Lines 10 guarantees that the preconditions of an action hold all through its execution. \u2022 plan \u03c0 satisfies a non-empty subset of goals: G\u03c0 6= \u2205.\nLine 41 indicates that a non-empty subset of goals has to be satisfied in a plan."}, {"heading": "Appendix D. Proof of Theorem 2", "text": "Theorem (Completeness). Let \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 be a plan for P = (FL, I, A,G,N). Then, there exists an answer set of \u03a0PBase containing atoms\nexecuted(ai, tai) that corresponds to \u03c0.\nFor the sake of making this proof self-contained, we first provide a formal definition of an answer set and explain the concept of reduct. As mentioned previously, a number of syntactic language representations for ASP exist. We use AnsProlog which is one of the most common classes of these languages. and it has the following elements (Baral, 2003): Term: A term is a constant or a variable or a n-ary function f(t1, \u00b7 \u00b7 \u00b7 , tn),\nwhere f is the function symbol and t1, \u00b7 \u00b7 \u00b7 , tn are terms. Constants start with a lower-case letter, whereas variables start with an uppercase level. A term is ground if no variable occurs in it.\nAtom: Atoms are the basic components of the language that can be assigned a truth value as true or false. An atom is a statement of form A(t1, \u00b7 \u00b7 \u00b7 , tn), where A is a predicate symbol and t1, \u00b7 \u00b7 \u00b7 , tn are terms. Literal: Literals are atoms or negated atoms. Atoms are negated using negation as failure (not). not a is true if there is no evidence proving the truth of a. An atom preceded by not is referred to as a naf-literal.\nThe Herbrand universe of language L denoted as HUL is the set of all ground terms which can be formed with the functions and constants in L. The set of all ground atoms which can be formed with the functions, constants and predicates in L is called Herbrand base of language L and is denoted using HBL.\nIn Section 4.1, we explained that an AnsProlog program (e.g. \u03a0) consists of a finite set of rules. In order to interpret a rule that contains variables, the rule has to be grounded. The grounding of each rule r in \u03a0 is then the set of all rules obtained from substitutions of elements of HU\u03a0 for the variables in the rule r. By grounding all r \u2208 \u03a0, we obtain ground(\u03a0).\nThe semantics of AnsProlog is defined in terms of answer sets. The answer sets of program \u03a0, are defined in terms of the answer sets of the ground program ground(\u03a0). An AnsProlog program without any naf-literal is denoted as Ansprolog\u2212not. An answer set of an AnsProlog\u2212not program \u03a0 is a minimal subset (with respect to subset ordering) S of HB that is closed under ground(\u03a0). The approach to define the answer sets of an AnsProlog program \u03a0 is to take a candidate answer set S of the program and transform \u03a0 with respect to S to obtain an Ansprolog\u2212not denoted by \u03a0S. S is an answer set of \u03a0 if S is the answer set of AnsProlog\u2212not program \u03a0S. This transformation is referred to as Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation.\nGiven an AnsProlog program \u03a0 and a set S of atoms from HB\u03a0, the\nGelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation \u03a0S is obtained by deleting:\n1. each rule that has a not L in its body with L \u2208 S, and 2. literals of form not L in the bodies of the remaining rules.\nThe transformation (reduct) of choice rules was not a part of original GelfondLifschitz transformation and was introduced later in (Lee et al., 2008). Recently a simplified reduct for programs including choice rules is proposed by Mark Law and Broda (2015) as follows. Given an AnsProlog program \u03a0 - with choice rules- and a set S of atoms from HB\u03a0, the transformation \u03a0\nS is constructed in the following 4 steps:\n1. Delete each rule that has a not L in its body with L \u2208 S. 2. Delete literals of form not L in the bodies of the remaining rules. 3. for any choice rule r, l{h0, \u00b7 \u00b7 \u00b7 , hk}u : \u2212 body(r), such that l \u2264 |S \u2229 {h0, \u00b7 \u00b7 \u00b7 , hk}| \u2264 u, replace r with the set of rules {hi : \u2212 body+(r)|hi \u2208 S \u2229 {h0, \u00b7 \u00b7 \u00b7 , hk}}. 4. for any remaining choice rules r, l{h0, \u00b7 \u00b7 \u00b7 , hk}u : \u2212 body(r), replace r with the constraint : \u2212 body+(r). After these transformation, the AnsProlog program \u03a0 is a program without any naf-literals and choice rules and it is therefore, an AnsProlog\u2212not, for which the answer sets are already defined.\nProof. Let the execution of sequence of actions in \u03c0 = \u3008(a0, 0), \u00b7 \u00b7 \u00b7 , (an, tan)\u3009 bring about the sequence of states \u3008s0, \u00b7 \u00b7 \u00b7 sq\u3009. Let Mt be the set of following atoms (and nothing else):\n\u2200k, 0 \u2264 k \u2264 q \u00b7Mt |= state(k) (D.1)\n\u2200k, 0 \u2264 k \u2264 q \u00b7 x \u2208 sk \u21d2Mt |= holdsat(x, k) (D.2)\n\u2200k, 0 \u2264 k < q \u00b7 x \u2208 (sk \\ sk+1)\u21d2Mt |= terminated(x, k) (D.3)\n\u2200a \u2208 A \u00b7Mt |= action(a, d) (D.4)\n\u2200k, 0 \u2264 k \u2264 q \u00b7 a \u2208 A, pr(a)+ \u2286 sk, pr(a)\u2212 6\u2208 sk \u21d2Mt |= pre(a, k) (D.5)\n\u2200k, 0 \u2264 k < q \u00b7 (a, k) \u2208\u0302 \u03c0 \u21d2Mt |= executed(a, k) (D.6)\n\u2200a.Mt |= executed(a, k), \u2200k, ta \u2264 k < ta + d(a) \u00b7Mt |= inprog(a, k) (D.7)\n\u2200a.Mt |= executed(a, k), \u2200x \u2208 ps(a)+ \u00b7Mt |= holdsat(x, k + d(a)) (D.8)\n\u2200a.Mt |= executed(a, k), \u2200x \u2208 ps(a)\u2212 \u00b7Mt |= terminated(x, k + d(a)\u2212 1) (D.9)\n\u2200g \u2208 G \u00b7Mt |= goal(g, v) (D.10)\n\u2200k, 0 \u2264 k \u2264 q \u00b7 g \u2208 G, g+ \u2286 sk, g\u2212 6\u2208 sk \u21d2Mt |= satisfied(g, k) (D.11)\n\u2200n \u2208 N \u00b7Mt |= norm(n, c) (D.12)\n\u2200n = \u3008o, acon, asub, dl\u3009 \u2208 N.Mt |= executed(acon, tacon), \u2200k, tacon + d(acon) \u2264 k \u2264 tacon + d(acon) + dl\u00b7\nMt |= holdsat(o(n, tacon , asub, tacon + d(acon) + dl), k) (D.13)\n\u2203k2, 0 \u2264 k < q \u00b7Mt |= holdsat(o(n, k1, a, dl\u2032), k2),Mt |= executed(a, k2), k2! = dl \u2032 \u21d2 Mt |= cmp(o(n, k1, a, dl\u2032), k2) (D.14)\n\u2203k2, 0 \u2264 k < q,Mt |= cmp(o(n, k1, a, dl\u2032), k2)\u21d2 Mt |= terminated(o(n, k1, a, dl\u2032), k2) (D.15)\n\u2203k2, k2 = dl\u2032,Mt |= holdsat(o(n, k1, a, dl\u2032), k2)\u21d2Mt |= vol(o(n, k1, a, dl\u2032), k2) (D.16)\n\u2203k2, 0 \u2264 k2 \u2264 q,Mt |= vol(o(n, k1, a, dl\u2032), k2)\u21d2 Mt |= terminated(o(n, k1, a, dl\u2032), k2) (D.17)\n\u2200n = \u3008f, acon, asub, dl\u2032\u3009 \u2208 N.Mt |= executed(acon, tacon), \u2200k, tacon + d(acon) \u2264 k \u2264 tacon + d(acon) + dl\u2032\u00b7\nMt |= holdsat(f(n, tacon , asub, tacon + d(acon) + dl\u2032), k) (D.18)\n\u2203k2, k2 = dl\u2032,Mt |= holdsat(f(n, k1, a, dl\u2032), k2)\u21d2 Mt |= cmp(f(n, k1, a, dl\u2032), k2) (D.19)\n\u2203k2, 0 \u2264 k2 \u2264 q,Mt |= cmp(f(n, k1, a, dl\u2032), k2)\u21d2 Mt |= terminated(f(n, k1, a, dl\u2032), k2) (D.20)\n\u2200k2, 0 \u2264 k2 < q \u00b7Mt |= holdsat(f(n, k1, a, dl\u2032), k2),Mt |= executed(a, k2)\u21d2 Mt |= vol(f(n, k1, a, dl\u2032), k2) (D.21)\n\u2203k2, 0 \u2264 k2 \u2264 q,Mt |= vol(f(n, k1, a, dl\u2032), k2)\u21d2 Mt |= terminated(f(n, k1, a, dl\u2032), k2) (D.22)\n\u2203k, 0 \u2264 k \u2264 q,Mt |= satisfied(g, k)\u21d2Mt |= satisfied(g) (D.23)\nWe need to prove that Mt is an answer set of \u03a0PBase. Therefore, we need to demonstrate that Mt is a minimal model for \u03a0 Mt PBase. Let r \u2208 \u03a0 Mt PBase be an applicable rule. In order for Mt to be a model of \u03a0 Mt PBase, we need to show that r is applied (i.e. Mt |= Head(r)). We will go through each rule in the same order in Lines 1\u201343. \u2022 r is of type rule in Line 1: fact and automatically applied. \u2022 r is of type rule in Line 2: fact and automatically applied. \u2022 r is of type rule in Lines 3\u20134: because of Gelfond-Lifschitz transfor-\nmation, we know that not terminated(x, s) is removed from this rule. Combination of D.2 and D.3 for x at k gives Mt |= holdsat(x, k + 1). \u2022 r is of type rule in Line 5: fact and automatically applied. \u2022 r is of type rule in Line 6: after Gelfond-Lifschitz transformation, from\nthe body and description of this rule we have a \u2208 A and pr(a)+ \u2208 sk and pr(a)\u2212 6\u2208 sk, which with D.5 implies that Mt |= pre(a, k). \u2022 r is of type rule in Line 7: any action a \u2208 A can be executed in a state.\nAfter the transformation for choice rules, we obtain \u2200(a, k) \u2208\u0302 \u03c0 we have executed(a, k) : \u2212 action(a, d), state(k). and \u2200(a, k) s.t. (a, k) \u03026\u2208 \u03c0 we have : \u2212 action(a, d), state(k). With D.6, we know that Mt |= executed(a, k). \u2022 r is of type rule in Lines 8\u20139: inprog atoms originate from execution\nof actions. From D.6 we know that \u2200(a, k) \u2208\u0302 \u03c0,Mt |= executed(a, k). Since a is executed with D.7 we have \u2200k, ta \u2264 k < ta + d(a),Mt |= inprog(a, k). \u2022 r is of type rule in Line 10: the head of this rule is empty. Since \u03c0 is\na plan and we have assumed the preconditions of actions in a plan are hold while the actions are in progress, this rule is applied. \u2022 r is of type rule in Lines 11\u201312: the head of this rule is empty. Because \u03c0 is a plan and we have assumed that two actions in a plan cannot have exactly the same start state, this rule is applied. \u2022 r is of type rule in Lines 13\u201314: the body of this rule implies that the\nadd postconditions of an executed action a hold in the state in which the action ends. Since \u2200(a, k) \u2208\u0302 \u03c0,Mt |= executed(a, k), with D.8 we have \u2200x \u2208 ps(a)+ \u00b7Mt |= holdsat(x, k + d(a)).\n\u2022 r is of type rule in Lines 15\u201316: the body of this rule implies that the delete postconditions of an executed action a are terminated in the state before the end state of the action. Since \u2200(a, k) \u2208\u0302 \u03c0,Mt |= executed(a, k), with D.9 we have \u2200x \u2208 ps(a)\u2212 \u00b7Mt |= terminated(x, k+ d(a)\u2212 1). \u2022 r is of type rule in Line 17: fact and automatically applied. \u2022 r is of type rule in Line 18: after Gelfond-Lifschitz transformation, from\nthe body and description of this rule we have g+ \u2208 sk and g\u2212 6\u2208 sk, which with D.11 implies that Mt |= satisfied(g, k). \u2022 r is of type rule in Line 19: fact and automatically applied. \u2022 r is of type rule in Lines 20\u201321: the body of the rule implies that\nnormative fluents for obligations hold over the compliance period if the action that is the condition of the norm is executed. If acon for an obligation norm belongs to \u03c0, then based on D.6 we know that Mt |= executed(acon, tacon). From D.6 and D.13 we know that Mt |= holdsat(o(n, k1, asub, tacon + d(acon) + dl\n\u2032), k2) over the period tacon + d(acon) \u2264 k2 \u2264 tacon + d(acon) + dl\u2032. \u2022 r is of type rule in Lines 22\u201323: this rule states that if the obliged action\nis executed while the normative fluent holds, the norm is complied with. If asub is executed in \u03c0 (Mt |= executed(acon, tacon)) while the normative fluent in D.13 holds, with D.14 we know that Mt models the compliance atom. \u2022 r is of type rule in Lines 24\u201325: complied obligations are terminated in\nthe compliance state. With D.14 we know that Mt models compliance atoms, and D.15 implies that they are terminated in the same state. \u2022 r is of type rule in Lines 26\u201327: if the obligation fluent still holds when\nthe deadline occurs, the obligation is violated. D.16 implies this is modelled by Mt. \u2022 r is of type rule in Line 28\u201329: violated obligations are terminated\nin the violation state. With D.16 we know that Mt models violation atoms, and D.17 implies that they are terminated. \u2022 r is of type rule in Lines 30\u201331: the body of the rule implies that\nnormative fluents for prohibition norms are hold over the compliance period if the action that is the condition of the norm is executed. If acon for a prohibition belongs to \u03c0, then based on D.6 we know that Mt |= executed(acon, tacon). From D.6 and D.18 we know that Mt |= holdsat(f(n, k1, asub, tacon + d(acon) + dl\n\u2032), k2) over the period tacon + d(acon) \u2264 k2 \u2264 tacon + d(acon) + dl\u2032.\n\u2022 r is of type rule in Lines 32\u201333: this rule states that if the normative fluent still holds at the end of compliance period, the prohibition is complied with. D.19 implies that Mt models the head of this rule. \u2022 r is of type rule in Line 34\u201335: complied prohibitions are terminated\nin the compliance state. With D.19 we know that Mt models compliance atoms, and D.20 implies that they are terminated and this rule is applied. \u2022 r is of type rule in Lines 36\u201337: this rule states that if the prohibited\naction is executed while the normative fluent holds, the norm is violated. If asub is executed in \u03c0 (Mt |= executed(asub, tasub)) while the normative fluent in D.18 holds, with D.21 we know that Mt models the violation atom. \u2022 r is of type rule in Line 38\u201339: violated prohibitions are terminated in\nviolation state. With D.21 we know that Mt models violation atoms, and D.22 implies that they are terminated. \u2022 r is of type rule in Line 40: this rule is applicable whenever a goal is\nsatisfied in a state. With D.11 and D.23 we can obtain this (Mt |= satisfied(g)). \u2022 r is of type rule in Line 41: the head of this rule is empty. Because \u03c0\nis a plan it has to satisfy at least one goal, so this rule is applied. \u2022 r is of type rule in Line 42\u201343: the head of this rule is empty. Because \u03c0 is a plan and a plan cannot contain concurrent execution of actions, this rule is applied. By showing that all the rules, apart from those not applicable, are applied, we have shown that Mt is a model for \u03a0 Mt PBase.\nNow, we need to show that Mt is minimal, which means that there exists no other model of \u03a0MtPBase that is a subset of Mt.\nLet M \u2282 Mt be a model for \u03a0MtPBase, then there must exist an atom s \u2208 (Mt \\M). If s is an atom that is generated because it is a fact, it must belong to M too and if that is not the case, then M cannot be a model. We now proceed with the rest of atoms that do not appear as facts: \u2022 s = executed(a, k): Mt |= s implies that r : executed(a, k) : \u2212 action(a, d), state(k)., r \u2208 \u03a0MtPBase. If M 6|= executed(a, k), then r was applicable but not applied, therefore, M is not a model. \u2022 s = holdsat(x, k): Mt |= s implies that one of the following four condi-\ntion must have occurred: \u2013 D.2: if this is the case then s was true in sk\u22121 (not terminated\nis removed from the body of this rule because of the Gelfond-\nLifschitz). In this case the construction of Mt guarantees Mt |= holdsat(x, k\u2212 1). If M 6|= holdsat(a, k) then rule in Lines 3\u20134 are applicable but not applied, so M cannot be a model. \u2013 D.8: if this is the case then we know Mt |= executed(a, k). Earlier we showed that if Mt |= executed(a, k), then M |= executed(a, k) too. Thus, if M 6|= holdsat(x, k + d(a)) for all x \u2208 ps(a)+, then rule in Lines 13\u201314 is applicable but not applied, so M cannot be a model. \u2013 D.13: if this is the case then x = o(n, k, asub, tacon + d(acon) + dl). Because Mt is a model then Mt |= executed(acon, tacon). So M |= executed(acon, tacon) too. Therefore, rule in Lines 20\u201321 is applicable and if M 6|= s then this rule is not applied and M cannot be a model. \u2013 D.18: if this is the case then x = f(n, k, asub, tacon + d(acon) + dl). Similar to reasoning above but instead of rule in Lines 20\u201321, rule in Lines 30\u201331 is applicable.\n\u2022 s = pre(a, k): Mt |= s implies that \u2200x \u2208 pr(a)+, x \u2208 sk and \u2200x \u2208 pr(a)\u2212, x 6\u2208 sk. If M is a model then according to the transformed version of rule 6, M |= pre(a, k). If that is not the case, then M is not a model. \u2022 s = inprog(a, k): Mt |= s implies that Mt |= executed(a, ta). There-\nfore, M |= executed(a, ta). That means the rule in Lines 8\u20139 is applicable and if \u2200ta \u2264 k < ta + d(a),M 6|= inprog(a, k) then this applicable rule is not applied. Therefore M cannot be a model. \u2022 s = cmp(o(n, k1, a, dl\u2032), k2): Mt |= s implies that Mt |= holdsat(o(n, k1, a, dl\u2032), k2) and also Mt |= executed(a, k2). Consequently, M |= holdsat (o(n, k1, a, dl\n\u2032), k2) and M |= executed(a, k2). As a result, rule in Lines 22\u201323 is applicable and if M 6|= s, the rule is not applied and M is not a model. \u2022 s = vol(o(n, k1, a, dl\u2032), k2): Mt |= s implies that Mt |= holdsat(o(n, k1, a, dl\u2032), k2) and also k2 = dl\n\u2032. Because M is a model we know that M |= holdsat(o(n, k1, a, dl\n\u2032), k2). As a result, rule in Line 27 is applicable and if M 6|= vol(o(n, k1, a, dl\u2032), k2), the rule is not applied and M is not a model. \u2022 s = cmp(f(n, k1, a, dl\u2032), k2): Mt |= s implies thatMt |= holdsat(f(n, k1, a, dl\u2032), k2) and also k2 = dl\n\u2032. Because M is a model we know that M |= holdsat(f(n, k1, a, dl\u2032), k2) too. As a result rule in Lines 32\u201333 is applicable and if M 6|= cmp(f(n, k1, a, dl\u2032), k2), the rule is not applied\nand M is not a model. \u2022 s = vol(f(n, k1, a, dl\u2032), k2): Mt |= s implies that Mt |= holdsat(f(n, k1, a, dl\u2032), k2) and also Mt |= executed(a, k2). Consequently, we know that M |= holdsat(f(n, k1, a, dl\u2032), k2) and M |= executed(a, k2). As a result rule in Lines 36\u201337 is applicable and if M 6|= vol(f(n, k1, a, dl\u2032), k2), the rule is not applied and M is not a model. \u2022 s = terminated(x, k): Mt |= s implies that one of the following five\nsituations hold: \u2013 D.9: if this is the case then Mt |= executed(a, k\u2212 d(a) + 1). If M\nis a model M |= executed(a, k\u2212 d(a) + 1). Thus, the rule in Lines 15\u201316 is applicable and if M 6|= terminated(s, k) then the rule is applicable but not applied, which means that M is not a model. \u2013 D.15 and D.17: if this is the case x = o(n, k2, a, dl \u2032) \u2208 sk, and\nMt |= cmp(o(n, k1, a, dl\u2032), k) or Mt |= vol(o(n, k1, a, dl\u2032), k). Since M is a model, then if Mt |= cmp(o(n, k1, a, dl\u2032), k) the same applies to M and if Mt |= vol(o(n, k1, a, dl\u2032), k) again the same applies to M . In either case, according to rule in Lines 24\u201325 and rule in Lines 28\u201329, M |= terminated(o(n, k1, a, dl\u2032), k) or M is not a model. \u2013 D.20 and D.22: if this is the case x = f(n, k1, a, dl \u2032) \u2208 sk, and\nMt |= cmp(f(n, k1, a, dl\u2032), k) or Mt |= vol(f(n, k1, a, dl\u2032), k). Since M is a model, if Mt |= cmp(f(n, k1, a, dl\u2032), k) the same applies to M and if Mt |= vol(f(n, k1, a, dl\u2032), k) again the same applies to M . In either case, according to rule in Lines 34\u201335 and rule in Lines 38\u201339, M |= terminated(f(n, k1, a, dl\u2032), k) or M is not a model.\n\u2022 s = satisfied(g, k): Mt |= s implies that \u2200x \u2208 g+, x \u2208 sk and \u2200x \u2208 g\u2212, x 6\u2208 sk. If M is a model then according to the transformed version of rule 18 M |= satisfied(g, k) and if that is not the case then M is not a model. \u2022 s = satisfied(g): Mt |= s because Mt |= satisfied(g, k). Since Mt |= satisfied(g, k), according to previous item M |= satisfied(g, k) too, therefore rule 40 is applicable and M |= satisfied(g) or it is not a model. The combination of these items demonstrates that M cannot be a model for \u03a0MtPBase if it differs from Mt. Mt is therefore a minimal model for \u03a0 Mt PBase and an answer set for \u03a0PBase."}], "references": [{"title": "Normative system games", "author": ["T. \u00c5gotnes", "W. van der Hoek", "M. Wooldridge"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "\u00c5gotnes et al\\.,? \\Q2007\\E", "shortCiteRegEx": "\u00c5gotnes et al\\.", "year": 2007}, {"title": "Operationalisation of norms for usage in electronic institutions", "author": ["H. Aldewereld", "F. Dignum", "A. Gar\u0107\u0131a-Camino", "P. Noriega", "J.A. Rod\u0155\u0131guezAguilar", "C. Sierra"], "venue": "International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "Aldewereld et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aldewereld et al\\.", "year": 2006}, {"title": "Programming norm-aware agents", "author": ["N. Alechina", "M. Dastani", "B. Logan"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "Alechina et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Alechina et al\\.", "year": 2012}, {"title": "Utilizing permission norms in BDI practical normative reasoning. In: International Workshop on Coordination, Organizations, Institutions, and Norms", "author": ["W. Alrawagfeh", "F. Meneguzzi"], "venue": null, "citeRegEx": "Alrawagfeh and Meneguzzi,? \\Q2014\\E", "shortCiteRegEx": "Alrawagfeh and Meneguzzi", "year": 2014}, {"title": "Specifying norm-governed computational societies", "author": ["A. Artikis", "M.J. Sergot", "J.V. Pitt"], "venue": "ACM Transactions on Computational Logic", "citeRegEx": "Artikis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Artikis et al\\.", "year": 2009}, {"title": "Knowledge Representation, Reasoning, and Declarative Problem Solving", "author": ["C. Baral"], "venue": null, "citeRegEx": "Baral,? \\Q2003\\E", "shortCiteRegEx": "Baral", "year": 2003}, {"title": "Fast planning through planning graph analysis", "author": ["A.L. Blum", "M.L. Furst"], "venue": "Artificial Intelligence", "citeRegEx": "Blum and Furst,? \\Q1997\\E", "shortCiteRegEx": "Blum and Furst", "year": 1997}, {"title": "Programming MultiAgent Systems in AgentSpeak using Jason", "author": ["R.H. Bordini", "M. Wooldridge", "J.F. H\u00fcbner"], "venue": null, "citeRegEx": "Bordini et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bordini et al\\.", "year": 2007}, {"title": "Asynchronous multi-agent asms. In: Abstract State Machines", "author": ["E. B\u00f6rger", "R. St\u00e4rk"], "venue": null, "citeRegEx": "B\u00f6rger and St\u00e4rk,? \\Q2003\\E", "shortCiteRegEx": "B\u00f6rger and St\u00e4rk", "year": 2003}, {"title": "The BOID architecture: Conflicts between beliefs, obligations, intentions and desires", "author": ["J. Broersen", "M. Dastani", "J. Hulstijn", "Z. Huang", "L. van der Torre"], "venue": "International Conference on Autonomous Agents", "citeRegEx": "Broersen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Broersen et al\\.", "year": 2001}, {"title": "Goal generation in the BOID architecture", "author": ["J. Broersen", "M. Dastani", "J. Hulstijn", "L. van der Torre"], "venue": "Cognitive Science Quarterly", "citeRegEx": "Broersen et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Broersen et al\\.", "year": 2002}, {"title": "Representing and monitoring social commitments using the event calculus", "author": ["F. Chesani", "P. Mello", "M. Montali", "P. Torroni"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "Chesani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chesani et al\\.", "year": 2013}, {"title": "Answer set programming for representing and reasoning about virtual institutions", "author": ["O. Cliffe", "M. De Vos", "J.A. Padget"], "venue": "International Workshop on Computational Logic in Multi-Agent", "citeRegEx": "Cliffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cliffe et al\\.", "year": 2006}, {"title": "Using norms to control open multi-agent systems", "author": ["N. Criado"], "venue": "Ph.D. thesis,", "citeRegEx": "Criado,? \\Q2012\\E", "shortCiteRegEx": "Criado", "year": 2012}, {"title": "A BDI architecture for normative decision making", "author": ["N. Criado", "E. Argente", "V.J. Botti"], "venue": "International Conference on Autonomous Agents and Multiagent Systems. IFAAMAS,", "citeRegEx": "Criado et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Criado et al\\.", "year": 2010}, {"title": "2APL: a practical agent programming language", "author": ["M. Dastani"], "venue": "Autonomous Agents and Multi-Agent Systems", "citeRegEx": "Dastani,? \\Q2008\\E", "shortCiteRegEx": "Dastani", "year": 2008}, {"title": "Agent programming with declarative goals. CoRR cs.AI/0207008", "author": ["F.S. de Boer", "K.V. Hindriks", "W. van der Hoek", "J.C. Meyer"], "venue": null, "citeRegEx": "Boer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Boer et al\\.", "year": 2002}, {"title": "Combining event-and state-based norms", "author": ["M. De Vos", "T. Balke", "K. Satoh"], "venue": "In: International conference on Autonomous Agents and MultiAgent Systems", "citeRegEx": "Vos et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vos et al\\.", "year": 2013}, {"title": "TAL: temporal action logics language specification and tutorial", "author": ["P. Doherty", "J. Gustafsson", "L. Karlsson", "J. Kvarnstr\u00f6m"], "venue": "Electronic Transactions on Artificial Intelligence (2),", "citeRegEx": "Doherty et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Doherty et al\\.", "year": 1998}, {"title": "The diagnosis frontend of the DLV system", "author": ["T. Eiter", "W. Faber", "N. Leone", "G. Pfeifer"], "venue": "AI Communications", "citeRegEx": "Eiter et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Eiter et al\\.", "year": 1999}, {"title": "On the formal specifications of electronic institutions", "author": ["M. Esteva", "J.A. Rod\u0155\u0131guez-Aguilar", "C. Sierra", "P. Garcia", "J.L. Arcos"], "venue": "Agent Mediated Electronic Commerce, The European AgentLink Perspective. Vol", "citeRegEx": "Esteva et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Esteva et al\\.", "year": 2001}, {"title": "Strips: A new approach to the application of theorem proving to problem solving", "author": ["R.E. Fikes", "N.J. Nilsson"], "venue": "International Joint Conference on Artificial Intelligence", "citeRegEx": "Fikes and Nilsson,? \\Q1971\\E", "shortCiteRegEx": "Fikes and Nilsson", "year": 1971}, {"title": "PDDL2.1: An extension to pddl for expressing temporal planning domains", "author": ["M. Fox", "D. Long"], "venue": "Artificial Intelligence Research", "citeRegEx": "Fox and Long,? \\Q2003\\E", "shortCiteRegEx": "Fox and Long", "year": 2003}, {"title": "A temporal planning system for durative actions of PDDL2.1", "author": ["A. Garrido", "M. Fox", "D. Long"], "venue": null, "citeRegEx": "Garrido et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Garrido et al\\.", "year": 2002}, {"title": "Verifying normative system specification containing collective imperatives and deadlines", "author": ["L. Gasparini", "T.J. Norman", "M.J. Kollingbaum", "L. Chen", "J.C. Meyer"], "venue": "International Conference on Autonomous Agents and Multiagent Systems", "citeRegEx": "Gasparini et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gasparini et al\\.", "year": 2015}, {"title": "Potassco: The Potsdam answer set solving collection", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "M. Ostrowski", "T. Schaub", "M. Schneider"], "venue": "AI Communications", "citeRegEx": "Gebser et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gebser et al\\.", "year": 2011}, {"title": "The stable model semantics for logic programming", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "International Conference and Symposium on Logic Programming", "citeRegEx": "Gelfond and Lifschitz,? \\Q1988\\E", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1988}, {"title": "The FF planning system: Fast plan generation through heuristic search", "author": ["J. Hoffmann", "B. Nebel"], "venue": "Artificial Intelligence Research,", "citeRegEx": "Hoffmann and Nebel,? \\Q2001\\E", "shortCiteRegEx": "Hoffmann and Nebel", "year": 2001}, {"title": "Combining goal generation and planning in an argumentation framework", "author": ["J. Hulstijn", "L.W.N. van der Torre"], "venue": "Non Monotonic Reasoning", "citeRegEx": "Hulstijn and Torre,? \\Q2004\\E", "shortCiteRegEx": "Hulstijn and Torre", "year": 2004}, {"title": "GOSU: computing goal support with commitments in multiagent systems", "author": ["\u00d6. Kafali", "A. G\u00fcnay", "P. Yolum"], "venue": "European Conference on Artificial Intelligence. Vol. 263 of Frontiers in Artificial Intelligence and Applications", "citeRegEx": "Kafali et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kafali et al\\.", "year": 2014}, {"title": "Generating parallel execution plans with a partialorder planner", "author": ["C.A. Knoblock"], "venue": "International Conference on Artificial Intelligence Planning Systems", "citeRegEx": "Knoblock,? \\Q1994\\E", "shortCiteRegEx": "Knoblock", "year": 1994}, {"title": "Norm-governed practical reasonig agents", "author": ["M. Kollingbaum"], "venue": "Ph.D. thesis,", "citeRegEx": "Kollingbaum,? \\Q2005\\E", "shortCiteRegEx": "Kollingbaum", "year": 2005}, {"title": "A logic-based calculus of events", "author": ["R. Kowalski", "M. Sergot", "Jan."], "venue": "New Generation Computing. 4(1), 67\u201395.", "citeRegEx": "Kowalski et al\\.,? 1986", "shortCiteRegEx": "Kowalski et al\\.", "year": 1986}, {"title": "A reductive semantics for counting and choice in answer set programming", "author": ["J. Lee", "V. Lifschitz", "R. Palla"], "venue": "International Conference on Artificial Intelligence. AAAI Press,", "citeRegEx": "Lee et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2008}, {"title": "N-Jason: Run-time norm compliance in AgentSpeak(L)", "author": ["J. Lee", "J. Padget", "B. Logan", "D. Dybalova", "N. Alechina"], "venue": "International Workshop in Engineering MultiAgent Systems. Vol. 8758 of Lecture Notes in Computer Science", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Reformulating temporal action logics in answer set programming", "author": ["J. Lee", "R. Palla"], "venue": "Conference on Artificial Intelligence", "citeRegEx": "Lee and Palla,? \\Q2012\\E", "shortCiteRegEx": "Lee and Palla", "year": 2012}, {"title": "Reformulating the situation calculus and the event calculus in the general theory of stable models and in answer set programming", "author": ["J. Lee", "R. Palla"], "venue": "CoRR abs/1401.4607", "citeRegEx": "Lee and Palla,? \\Q2014\\E", "shortCiteRegEx": "Lee and Palla", "year": 2014}, {"title": "Answer set programming and plan generation", "author": ["V. Lifschitz"], "venue": "Artificial Intelligence 138(1-2),", "citeRegEx": "Lifschitz,? \\Q2002\\E", "shortCiteRegEx": "Lifschitz", "year": 2002}, {"title": "What is answer set programming", "author": ["V. Lifschitz"], "venue": "International Conference on Artificial Intelligence", "citeRegEx": "Lifschitz,? \\Q2008\\E", "shortCiteRegEx": "Lifschitz", "year": 2008}, {"title": "A normative framework for agent-based systems. In: Normative Multi-Agent Systems (NORMAS)", "author": ["F. L\u00f3pez y L\u00f3pez", "M. Luck", "M. d\u2019Inverno"], "venue": null, "citeRegEx": "L\u00f3pez et al\\.,? \\Q2005\\E", "shortCiteRegEx": "L\u00f3pez et al\\.", "year": 2005}, {"title": "Simplified reduct for choice rules in ASP", "author": ["M. Law", "A. Russo", "Broda"], "venue": "Technical Report.,", "citeRegEx": "Law et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Law et al\\.", "year": 2015}, {"title": "BDI reasoning with normative considerations", "author": ["F. Meneguzzi", "O. Rodrigues", "N. Oren", "W.W. Vasconcelos", "M. Luck"], "venue": "Engineering Application of Artificial Intelligence", "citeRegEx": "Meneguzzi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Meneguzzi et al\\.", "year": 2015}, {"title": "Argumentation based resolution of conflicts between desires and normative goals", "author": ["S. Modgil", "M. Luck"], "venue": "Argumentation in Multi-Agent Systems. Vol. 5384 of Lecture Notes in Computer Science", "citeRegEx": "Modgil and Luck,? \\Q2008\\E", "shortCiteRegEx": "Modgil and Luck", "year": 2008}, {"title": "A dynamic logic programming based system for agents with declarative goals", "author": ["V. Nigam", "J. Leite"], "venue": "International Workshop on Declarative Agent Languages and Technologies", "citeRegEx": "Nigam and Leite,? \\Q2006\\E", "shortCiteRegEx": "Nigam and Leite", "year": 2006}, {"title": "Coordination durative actions", "author": ["I. Nunes", "J.L. Fiadeiro", "W.M. Turski"], "venue": "International Conference on Coordination Languages and Models. Vol. 1282 of Lecture Notes in Computer Science", "citeRegEx": "Nunes et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Nunes et al\\.", "year": 1997}, {"title": "Understanding permissions through graphical norms", "author": ["N. Oren", "M. Croitoru", "S. Miles", "M. Luck"], "venue": "Declarative Agent Languages and Technologies", "citeRegEx": "Oren et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Oren et al\\.", "year": 2010}, {"title": "Acting on norm constrained plans", "author": ["N. Oren", "W. Vasconcelos", "F. Meneguzzi", "M. Luck"], "venue": "Computational Logic in Multi-Agent Systems. Vol. 6814 of Lecture Notes in Computer Science. Springer,", "citeRegEx": "Oren et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Oren et al\\.", "year": 2011}, {"title": "Reasoning over norm compliance via planning", "author": ["S. Panagiotidi", "J. V\u00e1zquez-Salceda", "F. Dignum"], "venue": "International Workshop on Coordination, Organizations, Institutions, and Norms in Agent Systems. Vol. 7756 of Lecture Notes in Computer Science", "citeRegEx": "Panagiotidi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Panagiotidi et al\\.", "year": 2012}, {"title": "Contextual norm-based plan evaluation via answer set programming", "author": ["S. Panagiotidi", "J. V\u00e1zquez-Salceda", "W. Vasconcelos"], "venue": null, "citeRegEx": "Panagiotidi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Panagiotidi et al\\.", "year": 2012}, {"title": "Formal models of social processes: The pursuit of computational justice in self-organising multiagent systems", "author": ["J. Pitt", "D. Busquets", "R. Riveret", "Sept"], "venue": "In: International Conference on Self-Adaptive and SelfOrganizing Systems. pp. 269\u2013270.", "citeRegEx": "Pitt et al\\.,? 2013", "shortCiteRegEx": "Pitt et al\\.", "year": 2013}, {"title": "A goal deliberation strategy for BDI agent systems", "author": ["A. Pokahr", "L. Braubach", "W. Lamersdorf"], "venue": "German Conference on Multiagent System Technologies. Vol. 3550 of Lecture Notes in Computer Science", "citeRegEx": "Pokahr et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pokahr et al\\.", "year": 2005}, {"title": "An argumentation-based approach for practical reasoning", "author": ["I. Rahwan", "L. Amgoud"], "venue": "International Workshop on Argumentation in Multi-Agent Systems. Vol. 4766 of Lecture Notes in Computer Science", "citeRegEx": "Rahwan and Amgoud,? \\Q2006\\E", "shortCiteRegEx": "Rahwan and Amgoud", "year": 2006}, {"title": "BDI agents: From theory to practice", "author": ["A.S. Rao", "M.P. Georgeff"], "venue": "In: International Conference On Multi-Agent Systems", "citeRegEx": "Rao and Georgeff,? \\Q1995\\E", "shortCiteRegEx": "Rao and Georgeff", "year": 1995}, {"title": "Agent programming in dribble: From beliefs to goals with plans", "author": ["M.B. van Riemsdijk", "W. van der Hoek", "J.C. Meyer"], "venue": "Formal Approaches to Agent-Based Systems", "citeRegEx": "Riemsdijk et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2002}, {"title": "Goals in agent", "author": ["M.B. van Riemsdijk", "M. Dastani", "M. Winikoff"], "venue": null, "citeRegEx": "Riemsdijk et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2008}, {"title": "Goals in conflict", "author": ["M.B. van Riemsdijk", "M. Dastani", "J.C. Meyer"], "venue": "Agents and Multiagent Systems,", "citeRegEx": "Riemsdijk et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Riemsdijk et al\\.", "year": 2008}, {"title": "A generic approach to planning", "author": ["S.T. To", "T.C. Son", "E. Pontelli"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Normative conflict resolution in multi-agent systems", "author": ["W.W. Vasconcelos", "M.J. Kollingbaum", "T.J. Norman"], "venue": "Autonomous Agents and MultiAgent Systems", "citeRegEx": "Vasconcelos et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Vasconcelos et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 20, "context": "When modelled as hard constraints, the agent subject to the norms is said to be regimented, in which case the agent has no choice but blindly to follow the norms (Esteva et al., 2001).", "startOffset": 162, "endOffset": 183}, {"referenceID": 49, "context": "However, in order to encourage norm compliance, there are consequences associated, namely a punishment when agents violate a norm (L\u00f3pez y L\u00f3pez et al., 2005; Pitt et al., 2013) or a reward when agents comply with a norm (Aldewereld et al.", "startOffset": 130, "endOffset": 177}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006).", "startOffset": 51, "endOffset": 76}, {"referenceID": 1, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 3, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 46, "context": ", (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.", "startOffset": 2, "endOffset": 78}, {"referenceID": 46, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 14, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 41, "context": "(Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent.", "startOffset": 0, "endOffset": 91}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al.", "startOffset": 52, "endOffset": 963}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al. (2012); Oren et al.", "startOffset": 52, "endOffset": 987}, {"referenceID": 1, "context": ", 2013) or a reward when agents comply with a norm (Aldewereld et al., 2006). In some approaches (e.g., (Aldewereld et al., 2006; Alrawagfeh and Meneguzzi, 2014; Oren et al., 2011)) there is a utility gain/loss associated with respecting norm or not, whereas in the pressured norm compliance approaches (e.g., (L\u00f3pez y L\u00f3pez et al., 2005)), the choice to violate a norm or not is determined by how the norm affects the satisfaction or hindrance of the agent\u2019s goals. Existing work (e.g. (Oren et al., 2011; Panagiotidi et al., 2012a; Criado et al., 2010; Meneguzzi et al., 2015)) on normative practical reasoning using enforcement either consider plan generation or plan selection where there is a set of pre-generated plans available to the agent. In these works, the attitude agents have toward norms is often one of compliance, meaning that their plans are often selected or, in some approaches, customised, to ensure norm compliance (e.g., Kollingbaum (2005); Alechina et al. (2012); Oren et al. (2011)).", "startOffset": 52, "endOffset": 1007}, {"referenceID": 46, "context": "We extend current work on normative plan generation such that the agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal (Oren et al., 2011; Panagiotidi et al., 2012a).", "startOffset": 240, "endOffset": 286}, {"referenceID": 21, "context": "Such an extension is made on top of STRIPS (Fikes and Nilsson, 1971), the most established planning domain language that lays the foundation of many automated planning languages.", "startOffset": 43, "endOffset": 68}, {"referenceID": 26, "context": "Both plan generation and plan selection mechanisms proposed in this paper are implemented using Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988).", "startOffset": 125, "endOffset": 154}, {"referenceID": 37, "context": "The existence of efficient solvers to generate the answers to the problems provided has increased the use of ASP in different domains of autonomous agents and multi-agent systems such as planning (Lifschitz, 2002) and normative reasoning (Cliffe et al.", "startOffset": 196, "endOffset": 213}, {"referenceID": 12, "context": "The existence of efficient solvers to generate the answers to the problems provided has increased the use of ASP in different domains of autonomous agents and multi-agent systems such as planning (Lifschitz, 2002) and normative reasoning (Cliffe et al., 2006; Panagiotidi et al., 2012b).", "startOffset": 238, "endOffset": 286}, {"referenceID": 18, "context": "Several action and planning languages such as event calculus (Kowalski and Sergot, 1986), A (and its descendants B and C (Gelfond and Lifschitz, 1998), Temporal Action Logics (TAL) (Doherty et al., 1998), have been implemented in ASP (Lee and Palla, 2012, 2014), indicating that ASP is appropriate for reasoning about actions.", "startOffset": 181, "endOffset": 203}, {"referenceID": 21, "context": "This provides motive and justification for an implementation of STRIPS (Fikes and Nilsson, 1971) that serves as the foundation of our model in ASP.", "startOffset": 71, "endOffset": 96}, {"referenceID": 21, "context": "A Model for Normative Practical Reasoning In this research, we take STRIPS (Fikes and Nilsson, 1971) as the basis of our normative practical reasoning model.", "startOffset": 75, "endOffset": 100}, {"referenceID": 44, "context": "to capture the features of the normative practical reasoning problem that we are going to model, we extend the classical planning problem by: (i) replacing atomic actions with durative actions: often the nature of the actions is non-atomic, which means that although executed atomically in a state, the system state in which they finish executing is not necessarily the same in which they started (Nunes et al., 1997).", "startOffset": 397, "endOffset": 417}, {"referenceID": 8, "context": "Refinement of atomic actions to durative actions reflects the real time that a machine takes to execute certain actions, which is also known as \u201creal-time duration\u201d of actions (B\u00f6rger and St\u00e4rk, 2003).", "startOffset": 176, "endOffset": 200}, {"referenceID": 30, "context": "Some approaches take the view that it is sufficient for the preconditions of the action to hold at the start state and it does not matter whether they hold while the action is in progress (Knoblock, 1994), whereas others hold the view that the preconditions of an action should be satisfied while the action is in progress (Blum and Furst, 1997).", "startOffset": 188, "endOffset": 204}, {"referenceID": 6, "context": "Some approaches take the view that it is sufficient for the preconditions of the action to hold at the start state and it does not matter whether they hold while the action is in progress (Knoblock, 1994), whereas others hold the view that the preconditions of an action should be satisfied while the action is in progress (Blum and Furst, 1997).", "startOffset": 323, "endOffset": 345}, {"referenceID": 23, "context": "Moreover, some planning languages, such as Planning Domain Description Language (PDDL) (Garrido et al., 2002; Fox and Long, 2003), distinguish between preconditions and those conditions that have to hold while the action is in progress.", "startOffset": 87, "endOffset": 129}, {"referenceID": 22, "context": "Moreover, some planning languages, such as Planning Domain Description Language (PDDL) (Garrido et al., 2002; Fox and Long, 2003), distinguish between preconditions and those conditions that have to hold while the action is in progress.", "startOffset": 87, "endOffset": 129}, {"referenceID": 43, "context": "Achievement goals are the most common type of goals modelled in the agent literature and have therefore received the most attention (van Riemsdijk et al., 2008; de Boer et al., 2002; Nigam and Leite, 2006; van Riemsdijk et al., 2002).", "startOffset": 132, "endOffset": 233}, {"referenceID": 13, "context": "In order to provide a context for the norm specification we explain how our norm specification corresponds to the five elements identified by Criado (2012) that distinguish norm specification languages.", "startOffset": 142, "endOffset": 156}, {"referenceID": 44, "context": ", Oren et al. (2011); Panagiotidi et al.", "startOffset": 2, "endOffset": 21}, {"referenceID": 44, "context": ", Oren et al. (2011); Panagiotidi et al. (2012a)) and pressure-based (L\u00f3pez y L\u00f3pez et al.", "startOffset": 2, "endOffset": 49}, {"referenceID": 6, "context": "Blum and Furst (1997) define that two actions ai and aj cannot be executed concurrently, if at least one of the following holds: 1.", "startOffset": 0, "endOffset": 22}, {"referenceID": 43, "context": "An agent may pursue multiple goals or desires at the same time and it is likely that some of these goals conflict (van Riemsdijk et al., 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009).", "startOffset": 114, "endOffset": 240}, {"referenceID": 50, "context": "An agent may pursue multiple goals or desires at the same time and it is likely that some of these goals conflict (van Riemsdijk et al., 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009).", "startOffset": 114, "endOffset": 240}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints.", "startOffset": 8, "endOffset": 254}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints. Rahwan and Amgoud (2006) on the other hand, define two desires as conflicting if the sets of beliefs that supports the achievement of desires are contradictory.", "startOffset": 8, "endOffset": 439}, {"referenceID": 39, "context": ", 2002; Nigam and Leite, 2006; Pokahr et al., 2005; Thangarajah et al., 2003; van Riemsdijk et al., 2009). Conflict between the agent\u2019s goals or desires, especially for BDI agents, has been addressed by several authors. Hulstijn and van der Torre (2004) describe two goals as conflicting if achieving them requires taking two conflicting actions, where conflicting actions are encoded using integrity constraints. Rahwan and Amgoud (2006) on the other hand, define two desires as conflicting if the sets of beliefs that supports the achievement of desires are contradictory. Like Rahwan and Amgoud (2006), Broersen et al.", "startOffset": 8, "endOffset": 605}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.", "startOffset": 31, "endOffset": 54}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.g. beliefs and norms) is required. Some (e.g., (Toniolo, 2013)) have adopted a static view on goal conflict, in which conflicting goals are mutually-exclusive, hence impossible to satisfy in the same plan regardless of the order or choice of actions in the plan. Limited and bounded resources (e.g. time, budget, etc.) are debated as another cause of conflict between goals (Thangarajah et al., 2002). L\u00f3pez y L\u00f3pez et al. (2005) discuss conflict between goals and norms in terms of goals being hindered by norms or vice-versa.", "startOffset": 31, "endOffset": 569}, {"referenceID": 9, "context": "Like Rahwan and Amgoud (2006), Broersen et al. (2002) argue that for a set of goals not to be conflicting, a consistent mental attitude (e.g. beliefs and norms) is required. Some (e.g., (Toniolo, 2013)) have adopted a static view on goal conflict, in which conflicting goals are mutually-exclusive, hence impossible to satisfy in the same plan regardless of the order or choice of actions in the plan. Limited and bounded resources (e.g. time, budget, etc.) are debated as another cause of conflict between goals (Thangarajah et al., 2002). L\u00f3pez y L\u00f3pez et al. (2005) discuss conflict between goals and norms in terms of goals being hindered by norms or vice-versa. The same applies to the approach offered by Modgil and Luck (2008), suggesting a mechanism to resolve the conflicts between desires and normative goals.", "startOffset": 31, "endOffset": 734}, {"referenceID": 57, "context": ", Vasconcelos et al. (2009)) as well as other domains such as legal reasoning (e.", "startOffset": 2, "endOffset": 28}, {"referenceID": 57, "context": ", Vasconcelos et al. (2009)) as well as other domains such as legal reasoning (e.g., (Sartor, 1992)). When faced with conflicting norms, the agent cannot comply with both of them and hence one of the norms is violated. In terms of action-based norms, Shams et al. (2015) define two obligations conflicting if they oblige the agent to take two conflicting actions (cf.", "startOffset": 2, "endOffset": 271}, {"referenceID": 26, "context": "We use Answer Set Programming (ASP) (Gelfond and Lifschitz, 1988) to propose such an implementation.", "startOffset": 36, "endOffset": 65}, {"referenceID": 3, "context": "The Event Calculus (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative reasoning frameworks, such as those of Alrawagfeh and Meneguzzi (2014) and Artikis et al.", "startOffset": 148, "endOffset": 180}, {"referenceID": 3, "context": "The Event Calculus (EC) (Kowalski and Sergot, 1986) forms the basis for the implementation of some normative reasoning frameworks, such as those of Alrawagfeh and Meneguzzi (2014) and Artikis et al. (2009). Our proposed formal model is independent of language and could be translated to EC and hence to a computational model.", "startOffset": 148, "endOffset": 206}, {"referenceID": 38, "context": "Answer Set Programming ASP is a declarative programming paradigm using logic programs under Answer Set semantics (Lifschitz, 2008).", "startOffset": 113, "endOffset": 130}, {"referenceID": 5, "context": "A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003).", "startOffset": 71, "endOffset": 84}, {"referenceID": 25, "context": "There are several efficient solvers for AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al.", "startOffset": 67, "endOffset": 88}, {"referenceID": 19, "context": ", 2011) and DLV (Eiter et al., 1999) are currently the most widely used.", "startOffset": 16, "endOffset": 36}, {"referenceID": 5, "context": "A variety of programming languages for ASP exist, and we use AnsProlog (Baral, 2003). There are several efficient solvers for AnsProlog, of which Clingo (Gebser et al., 2011) and DLV (Eiter et al., 1999) are currently the most widely used. The basic components of AnsProlog are atoms that are constructs to which one can assign a truth value. An atom can be negated, adopting negation as failure (naf), which establishes that a negated atom not a is true if there is no evidence to prove a. Literals are atoms a or negated atoms not a (referred to as naf-literals). Atoms and literals are used to create rules of the general form \u201ca :\u2212 b1, ..., bm, not c1, ..., not cn.\u201d where a, bi and cj are atoms. Intuitively, a rule means that if all atoms bi are known/true and no atom cj is known/true, then a must be known/true. We refer to a as the head of the rule and b1, ..., bm, not c1, ..., not cn as the body of the rule. A rule with an empty body is called a fact and a rule with an empty head is called a constraint, indicating that no solution should be able to satisfy the body. Another type of rules are called choice rules and are denoted as l{h0, \u00b7 \u00b7 \u00b7 , hk}u : \u2212 l1, \u00b7 \u00b7 \u00b7 , lm, not lm+1, \u00b7 \u00b7 \u00b7 , not ln., in which his and lis are atoms. l and u are integers and the default values for them are 0 and 1, respectively. A choice rule is satisfied if the number of atoms belonging to {h0, \u00b7 \u00b7 \u00b7 , hk} that are true/known is between the lower bound l and upper bound u. A program is a set of rules representing their conjunction. The semantics of AnsProlog is defined in terms of answer sets, i.e. assignments of true and false to all atoms in the program that satisfy the rules in a minimal and consistent fashion. A program may have zero or more answer sets, each corresponding to a solution. We refer to Appendix D and Baral (2003) for a formal treatment of the semantics of ASP.", "startOffset": 72, "endOffset": 1837}, {"referenceID": 25, "context": "We plan to automate this using incremental features of ASP solver clingo4 (Gebser et al., 2011).", "startOffset": 74, "endOffset": 95}, {"referenceID": 6, "context": "Following the approach in Blum and Furst (1997), we assume that the preconditions of a durative action should be preserved when it is in progress.", "startOffset": 26, "endOffset": 48}, {"referenceID": 52, "context": "BDI Architectures with Normative Reasoning There is a substantial body of work on the integration of norms into the BDI architecture (Rao and Georgeff, 1995), but motivation, theory and practice vary substantially.", "startOffset": 133, "endOffset": 157}, {"referenceID": 9, "context": "The BOID architecture (Broersen et al., 2001) extends BDI with the concept of obligation and uses agent types such as social, selfish, etc.", "startOffset": 22, "endOffset": 45}, {"referenceID": 31, "context": "NoA (Kollingbaum, 2005) is a normative language and agent architecture.", "startOffset": 4, "endOffset": 23}, {"referenceID": 41, "context": "\u03bd-BDI (Meneguzzi et al., 2015) enables BDI agents to perform normative reasoning for the purpose of customising pre-existing plans that ensure compliance with the set of norms imposed on the agent.", "startOffset": 6, "endOffset": 30}, {"referenceID": 2, "context": "N-2APL (Alechina et al., 2012) is a norm-aware agent programming language based on 2APL (Dastani, 2008) that supports representation of and reasoning about beliefs, goals, plans, norms, sanctions and deadlines.", "startOffset": 7, "endOffset": 30}, {"referenceID": 15, "context": ", 2012) is a norm-aware agent programming language based on 2APL (Dastani, 2008) that supports representation of and reasoning about beliefs, goals, plans, norms, sanctions and deadlines.", "startOffset": 65, "endOffset": 80}, {"referenceID": 34, "context": "N-Jason (Lee et al., 2014) sets out an extension of the Jason (Bordini et al.", "startOffset": 8, "endOffset": 26}, {"referenceID": 7, "context": ", 2014) sets out an extension of the Jason (Bordini et al., 2007) variant of the BDI architecture to account for norms in plan selection and to handle priorities in plan scheduling.", "startOffset": 43, "endOffset": 65}, {"referenceID": 22, "context": "1 (Fox and Long, 2003).", "startOffset": 2, "endOffset": 22}, {"referenceID": 27, "context": "The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan.", "startOffset": 78, "endOffset": 104}, {"referenceID": 42, "context": "Oren et al. (2011) do utilise a pre-generated plan, like the list above, but take norms into consideration when deciding how to execute the plan with respect to the norms triggered by that plan.", "startOffset": 0, "endOffset": 19}, {"referenceID": 42, "context": "Oren et al. (2011) do utilise a pre-generated plan, like the list above, but take norms into consideration when deciding how to execute the plan with respect to the norms triggered by that plan. Specifically, the approach aims to adjust the chosen plan to account for the norms that govern the plan actions at each point in time, where the norm expresses constraints on the values that can be assigned to variables in a plan action. The adjustments of values in actions specify how the agent should execute a plan, such that the cost of violated norms is outweighed by the reward from norm compliance. The most preferred plan is therefore the one that maximises this metric. Panagiotidi et al. (2012a) take norms into account in plan generation where the planning problem is specified in PDDL 2.", "startOffset": 0, "endOffset": 702}, {"referenceID": 22, "context": "1 (Fox and Long, 2003). The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan. Although this mechanism enables an agent to cope with the dynamics of operating in an open environment, checking the normative position of an agent after each action imposes a high computational cost on the plan generation phase. Shams et al. (2015) define an approach to practical reasoning that considers norms in both plan generation and plan selection.", "startOffset": 3, "endOffset": 588}, {"referenceID": 22, "context": "1 (Fox and Long, 2003). The normative state of the agent is checked, using the planning tool MetricFF (Hoffmann and Nebel, 2001), after each individual action; then the planner decides if the agent should comply with a norm or not based on a linear cost function specified in terms of constraints on the states achieved during each plan. Although this mechanism enables an agent to cope with the dynamics of operating in an open environment, checking the normative position of an agent after each action imposes a high computational cost on the plan generation phase. Shams et al. (2015) define an approach to practical reasoning that considers norms in both plan generation and plan selection. The agent attempts to satisfy a set of potentially conflicting goals in the presence of norms, as opposed to conventional planning problems that generate plans for a single goal. The main contributions of Shams et al. (2015) are (i) the introduction of an enforcement approach that is a combination of utility-based and pressure-based compliance methods (L\u00f3pez y L\u00f3pez et al.", "startOffset": 3, "endOffset": 920}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated.", "startOffset": 6, "endOffset": 25}, {"referenceID": 46, "context": ", (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback.", "startOffset": 2, "endOffset": 21}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library.", "startOffset": 7, "endOffset": 918}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan.", "startOffset": 7, "endOffset": 1315}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan. Shams et al. (2015) attempt to balance compliance on the part of the agent (where the agent chooses a norm-compliant action in preference) with enforcement (where the agent is discouraged from non-norm-compliance via punishments for norm violation), but is not robust to plan failure.", "startOffset": 7, "endOffset": 1436}, {"referenceID": 31, "context": ", NoA (Kollingbaum, 2005)), which is a one-off process, that may fail delivering the best (where \u201cbest\u201d can be defined in various ways) plan available for the situation from those available, and which requires starting again when a plan step fails and the remainder of the plan is invalidated. The main points of difference between NoA and the work presented here are that (i) NoA agents are BDI specific, (ii) they do not have internal motivations such as goals or values that might conflict with norms, which therefore enables the NoA agent to always comply with norms (iii) plans are pre-existing rather than generated. 2. Customising a plan to make it norm compliant (e.g., (Oren et al., 2011)) is potentially more flexible in making use of available plans (also helping customize existing plans into optimal norm-compliant plans), but otherwise has the same replanning drawback. In common with Oren et al. (2011), we use the utility of the entire plan in the selection process, but differ in that we generate plans rather than use plans from a library. 3. Generating a plan that is norm compliant (e.g., (Panagiotidi et al., 2012a; Shams et al., 2015)). The former addresses on-going compliance and re-planning, putting a high computational overhead on each plan step. Of necessity, Panagiotidi et al. (2012a) can only compute utility on a step-by-step basis, whereas we consider the utility of the whole plan. Shams et al. (2015) attempt to balance compliance on the part of the agent (where the agent chooses a norm-compliant action in preference) with enforcement (where the agent is discouraged from non-norm-compliance via punishments for norm violation), but is not robust to plan failure. Furthermore, in Shams et al. (2015), conflict is formulated in advance by taking a static view about conflicts.", "startOffset": 7, "endOffset": 1737}, {"referenceID": 9, "context": "BOID (Broersen et al., 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al.", "startOffset": 5, "endOffset": 28}, {"referenceID": 31, "context": ", 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al.", "startOffset": 22, "endOffset": 41}, {"referenceID": 41, "context": ", 2001) o N/A N/A NoA (Kollingbaum, 2005) o, f, p state, action state, action \u03bd-BDI (Meneguzzi et al., 2015) o, f state state N-2APL (Alechina et al.", "startOffset": 84, "endOffset": 108}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al.", "startOffset": 32, "endOffset": 55}, {"referenceID": 34, "context": ", 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al.", "startOffset": 34, "endOffset": 52}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al.", "startOffset": 33, "endOffset": 153}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al. (2012a) o, f state state Shams et al.", "startOffset": 33, "endOffset": 193}, {"referenceID": 2, "context": ", 2015) o, f state state N-2APL (Alechina et al., 2012) o, f state state3 N-Jason (Lee et al., 2014) o, p, w4 N/A temporal constraint Oren et al. (2011) o, f N/A N/A Panagiotidi et al. (2012a) o, f state state Shams et al. (2015) o, f action temporal constraint This work o, f action temporal constraint", "startOffset": 33, "endOffset": 230}, {"referenceID": 11, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 29, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 24, "context": "5, associating a deadline with temporal properties is considered to be realistic and dynamic, in particular when the norms capture the requirements of realworld scenarios (Chesani et al., 2013; Kafali et al., 2014; Gasparini et al., 2015), such as the disaster scenario we have modelled in this paper.", "startOffset": 171, "endOffset": 238}, {"referenceID": 9, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 31, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 41, "context": ", (Broersen et al., 2001; Kollingbaum, 2005; Meneguzzi et al., 2015)).", "startOffset": 2, "endOffset": 68}, {"referenceID": 31, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 2, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 46, "context": ", (Kollingbaum, 2005; Alechina et al., 2012; Oren et al., 2011)).", "startOffset": 2, "endOffset": 63}, {"referenceID": 3, "context": "It is also used as a means to handle the uncertainty and incompleteness of the knowledge of the environment the agents operate in (Alrawagfeh and Meneguzzi, 2014).", "startOffset": 130, "endOffset": 162}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)).", "startOffset": 0, "endOffset": 22}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning.", "startOffset": 0, "endOffset": 770}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning. Also, the norm representation language can be extended to cater for deadlines that are expressed as reaching a state rather than a time instance. For instance, an obligation to open a dam on a river can come in force when the water level is above a certain point, and subsequently terminated when the water level drops below a certain level, regardless of how long it takes for that to happen. We would also like to include permission norms in addition to obligations and prohibitions. The modelling of permissions as exceptions to obligations and prohibitions has been used to justify violations under specific circumstances, (e.g. Oren et al. (2010); Criado (2012)).", "startOffset": 0, "endOffset": 1488}, {"referenceID": 0, "context": "\u00c5gotnes et al. (2007)). Another possibility to explore in a multi-agent setting is to infer conflicts between goals, between norms and between goals and norms by analysing the overall set of possible plans. The inferred conflicts can guide the process of re-engineering of the system toward a more social and norm compliant system (e.g. (Savarimuthu et al., 2013)). We note the relative limitations of our norm representation. Although our approach addressed action-based norms, we envisage how it can be extended and adapted to handle state-based norms. Our Def. 4 needs to cater for formulae to represent both the norm activation condition, acon, and the norm subject, asub, instead of actions. A combination of action- and statebased norms (e.g. De Vos et al. (2013)) enriches the norm representation as well as normative reasoning. Also, the norm representation language can be extended to cater for deadlines that are expressed as reaching a state rather than a time instance. For instance, an obligation to open a dam on a river can come in force when the water level is above a certain point, and subsequently terminated when the water level drops below a certain level, regardless of how long it takes for that to happen. We would also like to include permission norms in addition to obligations and prohibitions. The modelling of permissions as exceptions to obligations and prohibitions has been used to justify violations under specific circumstances, (e.g. Oren et al. (2010); Criado (2012)).", "startOffset": 0, "endOffset": 1503}, {"referenceID": 5, "context": "and it has the following elements (Baral, 2003): Term: A term is a constant or a variable or a n-ary function f(t1, \u00b7 \u00b7 \u00b7 , tn), where f is the function symbol and t1, \u00b7 \u00b7 \u00b7 , tn are terms.", "startOffset": 34, "endOffset": 47}, {"referenceID": 26, "context": "This transformation is referred to as Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation.", "startOffset": 56, "endOffset": 85}, {"referenceID": 26, "context": "Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation \u03a0 is obtained by deleting: 1.", "startOffset": 18, "endOffset": 47}, {"referenceID": 33, "context": "The transformation (reduct) of choice rules was not a part of original GelfondLifschitz transformation and was introduced later in (Lee et al., 2008).", "startOffset": 131, "endOffset": 149}, {"referenceID": 26, "context": "Gelfond-Lifschitz (Gelfond and Lifschitz, 1988) transformation \u03a0 is obtained by deleting: 1. each rule that has a not L in its body with L \u2208 S, and 2. literals of form not L in the bodies of the remaining rules. The transformation (reduct) of choice rules was not a part of original GelfondLifschitz transformation and was introduced later in (Lee et al., 2008). Recently a simplified reduct for programs including choice rules is proposed by Mark Law and Broda (2015) as follows.", "startOffset": 19, "endOffset": 469}], "year": 2017, "abstractText": "Autonomous software agents operating in dynamic environments need to constantly reason about actions in pursuit of their goals, while taking into consideration norms which might be imposed on those actions. Normative practical reasoning supports agents making decisions about what is best for them to (not) do in a given situation. What makes practical reasoning challenging is the interplay between goals that agents are pursuing and the norms that the agents are trying to uphold. We offer a formalisation to allow agents to plan for multiple goals and norms in the presence of durative actions that can be executed concurrently. We compare plans based on decision-theoretic notions (i.e. utility) such that the utility gain of goals and utility loss of norm violations are the basis for this comparison. The set of optimal plans consists of plans that maximise the overall utility, each of which can be chosen by the agent to execute. We provide an implementation of our proposal in Answer Set Programming, thus allowing us to state the original problem in terms of a logic program that can be queried for solutions with specific properties. The implementation is proven to be sound and complete.", "creator": "LaTeX with hyperref package"}}}