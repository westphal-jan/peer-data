{"id": "1702.07870", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2017", "title": "Online Learning with Many Experts", "abstract": "we study virtually the problem of prediction with expert advice needed when the aggregate number of experts in question may be extremely large or even infinite. we devise an algorithm that obtains a tight regret bound of $ \\ # widetilde { o } ( \\ > epsilon t + n + \\ sqrt { nt } ) $, where $ n $ is the empirical $ \\ epsilon $ - base covering number of the sequence of boundary loss functions generated by the environment. in mathematics addition, we present a nonlinear hedging beta procedure that allows us to find the optimal $ \\ epsilon $ in hindsight.", "histories": [["v1", "Sat, 25 Feb 2017 10:27:29 GMT  (18kb)", "http://arxiv.org/abs/1702.07870v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alon cohen", "shie mannor"], "accepted": false, "id": "1702.07870"}, "pdf": {"name": "1702.07870.pdf", "metadata": {"source": "CRF", "title": "Online Learning with Many Experts", "authors": ["Alon Cohen", "Shie Mannor"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 2.\n07 87\n0v 1\n[ cs\n.L G\n] 2\n5 Fe\nb 20\n17\n? NT q, where N is the empirical \u01eb-covering number of the\nsequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal \u01eb in hindsight.\nFinally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings."}, {"heading": "1 Introduction", "text": "In this paper we study the well known problem of prediction with expert advice, that can be seen as a game between a learner and an environment. At each round t \u201c 1, 2, . . . , T , a learner randomly decides to take the advice of an expert It from a predetermined set X of experts. Simultaneously, the environment chooses a loss function \u2113t : X \u00de\u00d1 r\u00b41, 1s and afterwards the learner incurs \u2113tpItq, the loss associated with that expert.\nThe goal of the learner throughout the T rounds of the game is to minimize her expected regret, defined as the expected difference between her cumulative loss and the cumulative loss of the best fixed expert in hindsight:\nRT \u201c E \u00ab T\u00ff\nt\u201c1\n\u2113tpItq \u00b4 inf iPX\nT\u00ff\nt\u201c1\n\u2113tpiq ff ,\nwhere the expectation is taken over the random choices of the learner. A fundamental result in the field of online learning states that, in the worst case, the best strategy for the learner incurs Op ? T logKq regret in the worst case (Cesa-Bianchi et al., 1997), where K is the number of experts. However, in many natural problems the number of experts may be extremely large, possibly infinite, albeit their advices may be highly \u201dcorrelated\u201d. In an extreme case, their advices may even be grouped together in a small number of clusters.\nAs a motivating application consider the problem of investment portfolio selection over a given set of stocks. These stocks may be categorized by a small number of parameters and each parameter may have a small number of possible values, but the overall number of combinations of these parameters can be very large. Thus every expert may advise on a different portfolio, but the portfolios themselves may give similar revenues due to the correlation resulted by the overlap in parametrization between the different stocks.\nAnother possible application is when the experts themselves arise from a reduction between another online learning problem and prediction with expert advice. This can occur, for example, in online supervised learning (Ben-David et al., 2009), adaptive algorithms (van Erven and Koolen,\n2016) and algorithms for tracking problems (Gyo\u0308rgy et al., 2005), in which the resulting number of experts can easily become exponentially large in the parameters of the problem.\nOur goal is to take advantage of such structure in order to achieve lower regret. In particular, we hope to be able to obtain regret bounds that are independent of the number of experts. We do so by constructing a cover of the sequence of loss functions generated by the environment. Namely, we find a small set of experts S such at least one of them has a similar cumulative loss as the best expert in hindsight.\nOur results are motivated by the stochastic case, in which the loss functions are sampled i.i.d. from a fixed distribution. In this case, a vast literature in the field of statistical machine learning shows that the regret is controlled by the covering number of the problem, giving a regret rate ofOp\u01ebT` ? T logNq whereN is the \u01eb-covering number (Shalev-Shwartz and Ben-David, 2014). Additionally, this bound is attained by a simple successive ERM algorithm that is oblivious to the structure of the problem (Hazan et al., 2016).\nQuite disappointingly, this is hardly the case in online learning, as even in extremely simple cases it is not possible to achieve logarithmic dependence on the covering number. This is due to the fact that as the game progresses the learner reveals more and more about the structure of the experts. However at any point in the game, this structure may develop in an exponentially large number of ways, depending on the whim of the environment and unbeknownst to the learner. In fact, in this setting any learner cannot do better that \u2126pT q regret in the worst case (for example, if the number of experts is exponential in T ), and yet against benign environments we can expect better performance."}, {"heading": "1.1 Our contributions", "text": "In this work we study the problem of prediction with expert advice when the number of experts is very large and even possibly infinite. We show an online learning algorithm that can obtain a regret bound of rOp\u01ebT `N p\u01eb, LT q` a TN p\u01eb, LT qq for a parameter \u01eb, where LT \u201c p\u21131, \u21132, . . . , \u2113T q is the sequence of loss functions generated by the environment and N p\u01eb, LT q is the \u01eb-covering number of LT under the infinity-norm. The algorithm does so by iteratively constructing a packing of the experts on LT as it is gradually revealed to the learner.\nAdditionally, we regard several applications and extensions of our algorithm. We explain how to find the optimal \u01eb automatically without any prior knowledge and discuss a few applications of our algorithm. In particular, we discuss the case of binary losses and an application of our algorithm to the low rank expert model. We also consider the interesting case of experts with bounded variation, in which it is possible to achieve a regret bound independent on the number of experts in the stochastic case. Surprisingly, the case of the online setting is drastically different."}, {"heading": "1.2 Related work", "text": "Covering and packing (Rogers, 1964) in compact metric spaces is a common discretization tool used in many fields of statistics. These include machine learning (Vapnik, 1998), empirical processes (Pollard, 1990) and information theory (Roman, 1992). Additionally, papers in a few different topics are related to ours.\nOnline combinatorial optimization. Online combinatorial optimization (Koolen et al., 2010) is a subset of online learning in which the learner\u2019s predictions form different kinds of combinatorial objects. These include the well known online shortest path problem (Takimoto and Warmuth, 2003), permutations (Helmbold and Warmuth, 2009) and many more.\nFor example, in the online shortest path problem, each expert corresponds to a path in a predetermined graph. At each round the environment sets losses to the edges of the graph, and the loss that corresponds to a path is simply the sum of the losses along the edges of the path.\nIn this case, even though the number of experts may be exponential in the number of vertices and edges of the graph, the losses of the experts are well structured. Indeed, if two paths share many of their edges then we can expect their losses to be similar.\nQuantile bounds. Quantile bounds (Chaudhuri et al., 2009; Chernov and Vovk, 2010) are bounds of the form Op a T logp1{\u01ebqq on the regret against the worst of a 1{\u01eb-fraction of the \u201dleading\u201d experts, in which by leading we mean experts with least cumulative loss. However, these methods cannot guarantee nontrivial regret against every expert without sufficient prior knowledge over the environment.1\nBranching experts. A conceptually similar setting to ours is that of branching experts (Gofer et al., 2013), in which the learner starts from a small number of experts, and where at any point in the game every expert can split into an arbitrary number of experts. This, for example, can be used to model a setting in which K potential experts are in fact only k distinct experts, but these k are not known by the learner in advance. In this case the authors prove that a regret of \u0398p ? kT q is tight (assuming k \u0103 log2N). Note that this is comparable to\n\u0398p ? T log kq obtained in the stochastic setting. This setting is different to ours since: first, they assume that the number of experts is finite but may be very large; Secondly, the experts themselves branch whenever their losses differ, whereas our algorithm is oblivious to this information. All our algorithm needs to know is if there is some expert that is not covered by our current packing. However, note that their lower bound of \u2126p ? kT q is still applicable in our case.\nLow rank experts. Hazan et al. (2016) consider the case where the losses of the experts reside in some unknown d-dimensional linear subspace. This is a special case of our setting in which the learning algorithm is much simpler and more intuitive. In particular they show a Opd ? T q regret bound in this setting.\nSimulatable experts. In the simulatable experts model (Cesa-Bianchi et al., 1999), the learner knows in advance the advices of all of the experts, as she attempts to learn a binary sequence chosen by the environment. At each round, the learner predicts a binary value at random and suffer a loss according to the absolute loss.\nThis model is one of improper learning, in the sense that the learner predicts a binary bit at each round rather than following the advice of a single expert. This allows the authors to obtain a tight characterization of the regret in terms of the Rademacher complexity of the expert class. As such, their bounds are very different than ours.\nSequential Rademacher complexity. Sequential Rademacher complexity (Rakhlin et al., 2010) is a useful tool for obtaining regret bounds. However, unlike the classic Rademacher Complexity of statistical learning theory, it is often difficult to use. This is added to the fact that the regret bounds obtained using this method are non-algorithmic in nature.\nAdaptive online algorithms. Most of the work previously done in prediction with expert advice revolves around attempting to improve the dependence on T under different assumptions. These include algorithms that can adapt to data that varies slowly (Cesa-Bianchi et al., 2007; Chiang et al., 2012; Hazan and Kale, 2010; Rakhlin and Sridharan, 2013), as well as algorithms that can adapt to stochastic i.i.d. losses (De Rooij et al., 2014; Sani et al., 2014). However, in our work we aim to improve the dependence on K even at the cost of possibly hindering the dependence on T .\n1More specifically, if the experts can be embedded into some function space, one needs to know the embedding\na-priori."}, {"heading": "2 Preliminaries and Main Results", "text": "In this section we provide some preliminary information, discussing the Exponential Weights algorithm as well as defining the notions of covering and packing. Thereafter, we give our main results."}, {"heading": "2.1 Exponential weights", "text": "Algorithm 1 Exponential Weights\nParameters: Number of experts K. Set: w1piq \u201c 1 for all i \u201c 1, 2, . . . ,K. for t = 1,2,. . . do\nDefine distribution pt by ptpiq 9 wtpiq. Predict It \u201e pt and suffer loss \u2113tpItq. Set: \u03b7t \u201c a 8 logpKq{t.\nUpdate: wt`1piq \u201c wtpiq expp\u00b4\u03b7t\u2113tpiqq for all i \u201c 1, 2, . . . ,K. end for\nExponential Weights (Littlestone and Warmuth, 1989; Vovk, 1995; Cesa-Bianchi et al., 1997), also named Hedge and Randomized Weighted Majority, is a celebrated algorithm for prediction with expert advice for a finite number of experts. The variant that we give here, depicted in Algorithm 1, has an adaptive learning rate and therefore the algorithm does not need to know the length of the game T in advance.\nThe algorithm assigns a weight for each expert that is initially set to 1. In each round, the algorithm chooses an expert at random from a distribution that is proportional to the weights of the experts, after which the weight of each expert is decreased according to her loss.\nWe have the following guarantee on the regret of the algorithm.\nLemma 1 (Cesa-Bianchi and Lugosi, 2006, Theorem 2.3). The expected regret of Algorithm 1 satisfies RT \u010f 4 ? T logK."}, {"heading": "2.2 Covering and packing", "text": "A cover of a sequence of loss functions is a small finite subset of experts, such that, intuitively, for any expert we can find an expert in the cover with similar losses.\nDefinition 1 (Cover). An \u01eb-cover of a sequence of loss functions LT \u201c p\u21131, \u21132, . . . , \u2113T q is a subset of experts S that satisfies the following: for every expert i (not necessarily in S) there is an expert j P S such that for all t \u201c 1, 2, . . . , T we have |\u2113tpiq \u00b4 \u2113tpjq| \u010f \u01eb. The \u01eb-covering number of LT , denoted N p\u01eb, LT q, is the size of the smallest \u01eb-cover of LT .\nAn important implication of the definition is that the covering number is monotonically decreasing in \u01eb. The following definition is in some sense the dual of a cover.\nDefinition 2 (Packing). An \u01eb-packing of a sequence of loss functions LT \u201c p\u21131, \u21132, . . . , \u2113T q is a subset of experts S that satisfies the following: for every different experts i, j P S there is a t P rT s such that |\u2113tpiq \u00b4 \u2113tpjq| \u0105 \u01eb. The \u01eb-packing number of LT , denoted Pp\u01eb, LT q, is the size of the largest \u01eb-packing of LT .\nThis next lemma is a well known result about duality between covering and packing, however for completeness we shall provide its proof in Appendix A.1.\nLemma 2. For any sequence of loss functions LT we have Pp2\u01eb, LT q \u010f N p\u01eb, LT q \u010f Pp\u01eb, LT q."}, {"heading": "2.3 Main results", "text": "We now state the main results of the paper. Our first result shows that there is an algorithm that obtains a regret bound that depends on the empirical covering number of the sequence of loss functions generated by the environment, with no direct dependence on the number of experts.\nTheorem 3. Let 0 \u0103 \u01eb \u010f 1. Suppose that the environment generates a sequence of loss functions LT \u201c p\u21131, \u21132, . . . , \u2113T q. Algorithm 2 described in Section 3 attains an expected regret of\nRT \u201c rO \u00b4 \u01ebT `N p\u01eb, LT q ` a TN p\u01eb, LT q \u00af\nUnlike Algorithm 1, our algorithm is applicable even when the number of experts is infinite. Nonetheless, note that if the number of experts is, say K, then the bound above becomes meaningful when N p\u01eb, LT q \u0103 logK. Finally, the bound of Theorem 3 is tight due to a matching lower bound found in Gofer et al. (2013, Lemma 10).\nOur next result handles the case where the optimal accuracy \u01eb is not known in advance. Luckily, there is a simple procedure that can guarantee the same regret bound as if the optimal \u01eb is known.\nCorollary 4. Suppose that the environment generates a sequence LT \u201c p\u21131, \u21132, . . . , \u2113T q of loss functions. There exists an online learning algorithm, described in Section 4, whose regret is bounded as follows.\nRT \u201c inf 0\u0103\u01eb\u010f1\nrO \u00b4 \u01ebT `N p\u01eb, LT q ` a TN p\u01eb, LT q \u00af\nAdditionally, in Section 5 we consider a number of applications of our algorithm. We remark on the case of binary losses, we show an application of our algorithm to the setting of low rank experts, discuss the case of losses from a sparse dictionary and consider the case of experts with bounded variation. For a sequence of loss functions \u21131, \u21132, . . . , \u2113T , let us define the variation of expert i as\nV piq \u201c T\u00b41\u00ff\nt\u201c1\n|\u2113t`1piq \u00b4 \u2113tpiq| .\nWe show that when the variation of all experts is at most V , even though in the stochastic i.i.d case it is possible to obtain Op ? V T q regret, this hardly the case in the online setting. In particular, even if V \u201c Op1q and the losses are binary \u2014 the loss of every expert only changes once during the game \u2014 the regret still grows with the number of experts in the worst case."}, {"heading": "3 Algorithm", "text": "Our algorithm is depicted in Algorithm 2. The algorithm starts with a set S containing one expert, and gradually builds a 2\u01eb-packing of experts on the sequence of loss functions generated by the environment. Namely, whenever there is an expert whose loss is more that 2\u01eb away from all of the experts in S, the algorithm adds her to S.\nThis produces two guarantees for us. The first, is that when S is not updated, the loss of any expert not in S is at most 2\u01eb apart from the loss of one of the experts in S. Second, as our regret bound will depend on the size of S, Lemma 2 entails that by the end of the game, the size of S is at most that of an \u01eb-cover of the sequence.\nAdditionally, when S is not updated the algorithm behaves exactly the same as Algorithm 1. Nonetheless whenever S is updated, the algorithm performs a restart: it resets the weights of the experts as well as the learning rate \u03b7t accordingly.\nAlgorithm 2 Exponential Weights for Many Experts\nParameters: Number of rounds T , accuracy \u01eb P p0, 1s. Set: \u03c41 \u201c 0, r \u201c 1,K1 \u201c 1, w1p1q \u201c 1 and let S contain an arbitrary expert. for t = 1,2,. . . ,T do\nDefine distribution pt by ptpiq 9 wtpiq. Predict It \u201e pt and suffer loss \u2113tpItq. while some expert j has |\u2113tpjq \u00b4 \u2113tpiq| \u0105 2\u01eb for all i P S do\nAdd j to S. end while if experts were added during this round then Let Kr`1 \u201c |S| be current number of experts. Set: wt`1piq \u201c 1 for all i P S (perform a restart), \u03c4r`1 \u00d0 t, r \u00d0 r ` 1. else\nSet: \u03b7t \u201c a\n8 logpKrq{pt\u00b4 \u03c4rq. Update: wt`1piq \u201c wtpiq expp\u00b4\u03b7t\u2113tpiqq for all i P S.\nend if\nend for Set: \u03c4r`1 \u201c T ` 1."}, {"heading": "3.1 Analysis", "text": "Proof of Theorem 3. First note that Algorithm 2 acts in p phases between restarts. This means that during each phase the algorithm behaves exactly like Algorithm 1 with the Kr \u201c |S| chosen experts.\nFor any expert i, consider the sequence i1, i2, . . . , ip of experts that cover i in each of the phases, namely within each phase r we have |\u2113tpirq\u00b4 \u2113tpiq| \u010f 2\u01eb. Note that Tr \u201c \u03c4r`1\u00b4 \u03c4r is the length of the r\u2019th phase, then by Lemma 1 the regret of the algorithm during this phase with respect to ir is:\nRr \u010f 4 a Tr logKr .\nAdditionally, during the phase the loss of expert i is at most 2\u01eb away from that of expert ir, and in-between phases we have a single round in which the instantaneous regret is at most 2. Therefore, the regret of Algorithm 2 with respect to i is bounded as follows:\nE\n\u00ab T\u00ff\nt\u201c1\n\u2113tpItq \u00b4 \u2113tpiq ff \u201c E \u00bb \u2014\u2013 p\u00ff\nr\u201c1\n\u03c4r`1\u00b41\u00ff\nt\u201c\u03c4r`1\n\u2113tpItq \u00b4 \u2113tpiq ` p\u00ff\nr\u201c2 \u2113\u03c4rpItq \u00b4 \u2113\u03c4rpiqlooooooomooooooon \u010f2\nfi ffifl\n\u010f p\u00ff\nr\u201c1\nE\n\u00ab \u03c4r`1\u00b41\u00ff\nt\u201c\u03c4r`1\n\u2113tpItq \u00b4 \u2113tpiq ff ` 2p , (1)\nand for each r we have\nE\n\u00ab \u03c4r`1\u00b41\u00ff\nt\u201c\u03c4r`1\n\u2113tpItq \u00b4 \u2113tpiq ff \u201c E \u00ab \u03c4r`1\u00b41\u00ff\nt\u201c\u03c4r`1\n\u2113tpItq \u00b4 \u2113tpirq ff\nlooooooooooooooomooooooooooooooon \u201cRr\n` \u03c4r`1\u00b41\u00ff\nt\u201c\u03c4r`1 \u2113tpirq \u00b4 \u2113tpiqloooooomoooooon \u010f2\u01eb\n\u010f Rr ` 2\u01ebp\u03c4r`1 \u00b4 \u03c4rq .\nSumming over all r \u201c 1, 2, . . . , p we get p\u00ff\nr\u201c1\nRr ` \u01ebp\u03c4r`1 \u00b4 \u03c4rq \u010f p\u00ff\nr\u201c1\n2 a Tr logKr ` 2\u01ebp\u03c4p`1 \u00b4 \u03c41q\n\u010f 4\ngffe p\u00ff\nr\u201c1\nTr\ngffe p\u00ff\nr\u201c1\nlogKr ` 2\u01ebT\n\u010f 8 a TKp logKp ` 2\u01ebT , (2)\nwhere the second inequality is by the Cauchy-Schwartz inequality and since K1,K2, . . . ,Kp is an increasing sequence. The third inequality is since \u0159p r\u201c1 Tr \u010f T and since \u0159p r\u201c1 logKr \u010f 2Kp logKp by Lemma 10 (technical). Finally, we notice that the Kp experts in S at end of the game form a 2\u01eb-packing of the sequence \u21131, \u21132, . . . , \u2113T . Indeed, let i, j P S be two experts, suppose that i is added to S before j, and let t be the round in which j is added to S. Then by the definition of the algorithm, we must have |\u2113tpiq \u00b4 \u2113tpjq| \u0105 2\u01eb. Thus by Lemma 2 we have Kp \u010f N . In addition, whenever the algorithm performs a restart it adds at least one expert to S, and therefore we have p \u010f Kp. Combining these facts with Eq. (1) and with Eq. (2) gives the desired result."}, {"heading": "4 Tuning \u01eb Automatically", "text": "In this section we prove Corollary 4. Suppose that we do not know what the optimal \u01eb is in advance. Looking at the regret bound of Theorem 3, we have a tradeoff \u2014 choosing a smaller \u01eb may decrease the \u01ebT term but may increase the covering number N p\u01eb, LT q. We would like to tune \u01eb to be the best possible in hindsight.\nIn this case we can run R \u201c rlog2 T s copies of our algorithm with exponentially decreasing accuracy parameters; for each algorithm r \u201c 1, 2, . . . , R we set \u01ebr \u201c 2\u00b4r`1. By treating these R algorithms themselves as experts, we can run a copy of Algorithm 1, such that whenever it chooses an algorithm r, we play the action chosen by algorithm r on this round. For this procedure we have the following analysis.\nProof of Corollary 4. Let Lr be the cumulative loss of algorithm r, let L be the cumulative loss of our procedure and L\u2039 be the cumulative loss of the best expert in hindsight. Then by Lemma 1 and Theorem 3 the regret of this procedure is bounded as follows.\nE rL\u00b4 L\u2039s \u201c E \u201e\u02c6\nL\u00b4 min rPrRs Lr\n\u02d9 ` \u02c6 min rPrRs Lr \u00b4 L\u2039 \u02d9\n\u010f E \u201e L\u00b4 min\nrPrRs Lr\n ` min\nrPrRs E rLr \u00b4 L\u2039s\n\u010f 4 a\nT log log T ` min rPrRs ! 4 \u00a8 2\u00b4rT ` 2N p2\u00b4r`1, LT q ` 8 a TN p2\u00b4r`1, LT q logN p2\u00b4r`1, LT q ) ,\nwhere the first inequality is due to Jensen\u2019s inequality. To complete the proof, we will show that\nmin rPrRs\n! 4 \u00a8 2\u00b4rT ` 2N p2\u00b4r`1, LT q ` 8 a TN p2\u00b4r`1, LT q logN p2\u00b4r`1, LT q )\n\u010f inf 0\u0103\u01eb\u010f1\n! 4\u01ebT ` 2N p\u01eb, LT q ` 8 a TN p\u01eb, LT q logN p\u01eb, LT q ) ` 2 .\nIndeed, consider any \u01eb P p0, 1s. If \u01eb \u0105 2\u00b4R`1, then let r\u2039 be maximal such that 2\u00b4r\u2039`1 \u011b \u01eb. In particular we have 2\u00b4r \u2039 \u0103 \u01eb. We get\nmin rPrRs\n! 4 \u00a8 2\u00b4rT ` 2N p2\u00b4r`1, LT q ` 8 a TN p2\u00b4r`1, LT q logN p2\u00b4r`1, LT q ) \u010f 4 \u00a8 2\u00b4r\u2039T ` 2N p2\u00b4r\u2039`1, LT q ` 8 a\nTN p2\u00b4r\u2039`1, LT q logN p2\u00b4r\u2039`1, LT q \u010f 4\u01ebT ` 2N p\u01eb, LT q ` 8 a TN p\u01eb, LT q logN p\u01eb, LT q ,\nwhere we have used the fact that the covering number is monotonically decreasing in \u01eb. On the other hand, if \u01eb \u010f 2\u00b4R`1 then\nmin rPrRs\n! 4 \u00a8 2\u00b4rT ` 2N p2\u00b4r`1, LT q ` 8 a TN p2\u00b4r`1, LT q logN p2\u00b4r`1, LT q ) \u010f 4 \u00a8 2\u00b4RT ` 2N p2\u00b4R`1, LT q ` 8 b\nTN p2\u00b4R`1, LT q logN p2\u00b4R`1, LT q \u010f 2` 2N p\u01eb, LT q ` 8 a TN p\u01eb, LT q logN p\u01eb, LT q ,\nthus reaching the desired conclusion."}, {"heading": "5 Applications", "text": "In this section we discuss a number of applications of Algorithm 2. First, we discuss the case of binary losses in which we can attain a regret bound that depends on the number of experts with distinct sequences of losses. We then discuss an application of our algorithm to the low rank experts model and a generalization of it in the form of experts whose losses are acquired from a sparse dictionary. Finally, we approach the interesting case of experts with bounded variation, in which we show a large gap between the regret of the stochastic and the online settings."}, {"heading": "5.1 Binary losses", "text": "Consider a setting in which the losses of the experts are binary, namely -1 or 1. In this case, we can obtain a regret bound that depends on the number experts with distinct sequences of losses, without paying for an additional term that depends linearly on T . The following is a direct consequence of Theorem 3.\nCorollary 5. Let N \u201c N p0, LT q be the 0-covering number of sequence LT \u201c p\u21131, \u21132, . . . , \u2113T q of binary loss functions generated by the environment. Then the regret of the Algorithm 2 satisfies\nRT \u010f N ` 8 a TN logN ."}, {"heading": "5.2 Low rank experts", "text": "Suppose that the number of experts K is finite but very large. Let L P r\u00b41, 1sT\u02c6K be the losses arranged in a matrix obtained in hindsight, and consider the model of Hazan et al. (2016) in which the environment plays a strategy in which the \u01eb-approximate rank of L is d. The approximate rank of a matrix L is defined as follows:\n\u01eb-rankpLq \u201c min rankpL1q : }L1 \u00b4 L}8 \u010f \u01eb ( ,\nnamely it is the lowest rank of any matrix that \u01eb-approximates L entry-wise. Under this setting, Hazan et al. (2016) give an online learning algorithm that gives Opd ? T q regret if L is of (0-)rank d. For the case of \u01eb-approximate rank, the authors give a regret bound of Op ? dT ` \u01eb ? T logKq for the stochastic case, and leave the problem of obtaining a similar bound in the online case as an open issue. In this section, we show an application of our algorithm to this latter setting, described by the following corollary.\nCorollary 6. Let 0 \u0103 \u01eb \u010f 1{4. Suppose that T \u010f K and \u01eb-rankpLq \u010f d, then Algorithm 2 applied to this setting with accuracy 4\u01eb gives a regret bound of\nRT \u201c rO \u02c6 \u01ebT ` pc{\u01ebqd ` b pc{\u01ebqdT \u02d9 ,\nfor an absolute constant c.\nNote that the bound above is only meaningful if it happens that \u03c9pT\u00b41{dq \u010f \u01eb \u010f op1q. The bound hints on an exponential decay in the dependence on the approximate rank d between the stochastic and online cases. Whether this gap can be removed using nontrivial algorithmic techniques remains an open issue and an interesting direction for future research.\nLet us turn to prove Corollary 6, but in order to do so we shall need the following theorem.\nTheorem 7 (Alon et al., 2013, Theorem 3.2). Let A be an K\u02c6K matrix with entries in r\u00b41, 1s and \u01eb-rankpAq \u201c d. Let \u2206 be the pK \u00b4 1q-dimensional probability simplex. There is a finite set S \u010e RK such that @x P \u2206, Dx\u0303 P S : }Ax\u00b4Ax\u0303}8 \u010f 2\u01eb , and |S| \u201c Op1{\u01ebqd.\nWe shall now continue with the proof of the corollary.\nProof of Corollary 6. Consider an application of Algorithm 2 with accuracy 4\u01eb in our problem, for which by Theorem 3 it suffices to bound the covering number N p4\u01eb, LT q.\nConsider padding the loss matrix L P r\u00b41, 1sT\u02c6K with K \u00b4 T rows of zero entries, in order to obtain a K \u02c6K matrix whose \u01eb-rank remains d. Since we can represent each expert i by a standard basis vector ei P RK , the vector Lei represents the losses of expert i. Thus, we can apply Theorem 7 to L and acquire a set S \u010e RK of size Op1{\u01ebqd with the following property:\n@i P rKs, Dx\u0303 P S : }Lei \u00b4 Lx\u0303}8 \u010f 2\u01eb .\nLet R be a maximal 4\u01eb-packing of LT . By Lemma 2 we have N pLT , 4\u01ebq \u010f |R| so that it suffices to show a one-to-one mapping \u03c0 : R \u00de\u00d1 S, that would imply |R| \u010f |S|. Indeed, define \u03c0 as follows: for each i P R let \u03c0piq \u201c argminx\u0303PS }Lei \u00b4 Lx\u0303}8 breaking ties arbitrarily. To show that it is one-to-one, let i, j P R such that \u03c0piq \u201c \u03c0pjq, then\n}Lei \u00b4 Lej}8 \u010f }Lei \u00b4 L\u03c0piq}8 ` }L\u03c0pjq \u00b4 Lej}8 \u010f 2\u01eb` 2\u01eb \u201c 4\u01eb .\nSince R is a 4\u01eb-packing it must be the case that i \u201c j, as required."}, {"heading": "5.3 Losses from a sparse dictionary", "text": "Sparse dictionary learning (Elad and Aharon, 2006), also known as sparse coding, is a widely used tool in machine learning, neuroscience and signal processing. Given an unlabeled dataset, this method approximates each data point by a linear combination of a small number of vectors from a set, called a dictionary. This modeling is motivated by the empirical success (Aharon et al., 2006; Lee et al., 2007), as well as evidence that, for example, the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997). In the following we assume that the environment plays a strategy in which the losses of the experts can be approximated by such a sparse representation.\nFormally, let the environment play a strategy that satisfies the following. Suppose that the loss matrix L P r\u00b41, 1sT\u02c6K can be approximated by a decomposition D \u00a8 V , namely that it satisfies }L\u00b4D \u00a8 V }8 \u010f \u01eb. Here D, the dictionary, is a T \u02c6 n matrix whose rows have 1-norm of at most 1. The matrix V is an n\u02c6K matrix in which each column i, associated with expert\ni, is a k-sparse2 vector vi such that }vi}8 \u010f 1. Note that both matrices D and V are unknown to the learner and chosen by the environment in an adversarial manner.\nThis assumption entails that there is an approximate sparse representation for the losses of each expert. Indeed, the vector of losses of expert i is \u01eb-approximated by Dvi, and since vi is k-sparse, Dvi is a linear combination of at most k of the columns of D. The dictionary D can be over-complete, which means that n \u011b T and that its columns are not necessarily orthogonal. This allows the vectors Dvi to lie in different, yet possibly overlapping, k-dimensional subspaces of RT . As such this setting is a generalization of the low rank experts model of the previous section.\nIn this setting we have the following guarantee for our algorithm.\nCorollary 8. Suppose that 0 \u0103 \u01eb \u010f 1{4. Algorithm 2 applied to the setting above with accuracy 4\u01eb gives a regret bound of\nRT \u201c rO \u02c6 \u01ebT ` p2n{\u01ebqk ` b p2n{\u01ebqkT \u02d9 .\nIn particular, note that the bound is meaningful when \u03c9pnT\u00b41{kq \u010f \u01eb \u010f op1q.\nProof of Corollary 8. Once again, in view of Theorem 3 it suffices to bound the covering number N p4\u01eb, LT q. As in the proof of Corollary 6, associate with each expert i the standard basis vector ei P RK and recall that Lei P r\u00b41, 1sT is the vector of losses associated with expert i. Let i, j be any two experts, then we have\n}Lei \u00b4 Lej}8 \u010f }Lei \u00b4Dvi}8looooooomooooooon \u010f\u01eb `}Dvi \u00b4Dvj}8looooooomooooooon \u010f}vi\u00b4vj}8 `}Dvj \u00b4 Lej}8looooooomooooooon \u010f\u01eb\n\u010f }vi \u00b4 vj}8 ` 2\u01eb ,\nwhere the last inequality is by our assumption that the rows of D have 1-norm of at most 1. Therefore, it suffices to 2\u01eb-cover S, the set of all k-sparse vectors v that satisfy }v}8 \u010f 1 .\nThe set S is a union of ` n k \u02d8 k-dimensional cubes of the form r\u00b41, 1sk . By a well known result on covering numbers, each such cube can be covered by at most p1 ` 1{\u01ebqk \u010f p2{\u01ebqk cubes of the form r\u00b42\u01eb, 2\u01ebsk. This entails that N p\u01eb, LT q \u010f ` n k \u02d8 p2{\u01ebqk \u010f p2n{\u01ebqk, and plugging the latter into the bound Theorem 3 gives the desired result."}, {"heading": "5.4 Experts with bounded variation", "text": "For this section, let us assume that the variation of all of the experts is bounded by V . Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while suffering only rOp ? V T q regret. However, the situation is drastically different in the online case.\nFor motivation consider the case of binary losses, then V {2 is a bound on the number of times the loss of an expert changes from -1 to 1 or vice versa, during the T rounds of the game. Therefore, the number of experts with distinct losses is 2 \u0159V {2\ni\u201c0 ` T\u00b41 i \u02d8 \u201c OpT V {2q. This entails\nthat by Corollary 5, we have the a guarantee of rOpT V {2q on the regret of Algorithm 2, which is trivial even for V \u201c 2! This leaves us with the following problem: does there exists an algorithm for online learning that attains rOp ? V T q regret when the variation of all experts is bounded by V ? We answer this question negatively. First note that the interesting regime is when T \u0103 logK, otherwise we can obtain a tight \u0398p ? V logKq bound of Hazan and Kale (2010). However, if T \u0103 logK, even if V \u201c Op1q we cannot expect the desired regret bound, as shown in the following result.\n2A k-sparse vector is one that has at most k nonzero entries.\nTheorem 9. Suppose T \u0103 log2K and that V piq \u010f 2 for every expert i. Then there is a randomized environment that forces any learner to obtain a regret of at least T in expectation.\nProof. Our construction is as following. We start from setting the loss of all experts to -1. At each round, we pick a subset of experts whose loss was -1 so far, set it to 1 and it will stay 1 for the remainder of the game. This will make sure that the variation of all experts is indeed at most 2.\nOn the first round we pick half of the experts uniformly at random and set their loss to 1. Therefore, on the first round, the loss of any learner is exactly 0 in expectation. In the second round, we pick half of the experts whose loss was -1 in the first round and set their loss to 1. Once again, any learner must suffer a loss of at least 0 in expectation on the second round. We keep doing so for the T rounds of the game.\nThus, the expected regret of the learner is at least T since her expected loss is at least 0, but there is at least one expert with a cumulative loss of \u00b4T ."}, {"heading": "6 Discussion and Open Problems", "text": "In this work we have shown an algorithm that obtains a regret bound that is independent of the number of experts. This dependence is replaced by a certain covering number that governs the complexity of the observed sequence of loss functions. We have also shown how to automatically tune the accuracy parameter of our algorithm. Finally, we have presented a number of applications of our algorithm, that include binary losses, low rank experts and experts with bounded variation.\nUnfortunately for many important applications, the covering number used by our algorithm can typically be very large. Given that ideally we would like to choose \u01eb \u201c op1q, it is an interesting direction for future work to try and to find a simple way to quantify which classes of environments produce small covering numbers for such values of \u01eb. In addition, comparing our result to that of Hazan et al. (2016) in their setting, our bound is exponentially worse in the dimension of the loss matrix. It remains an open problem to find an algorithm that has a tight regret bound in both cases.\nAnother interesting direction to explore is the connection between our setting and online compression. Indeed, by setting the losses into a matrix L P r\u00b41, 1sT\u02c6K our problem is equivalent to approximating this matrix with a small number of columns in an online fashion. Therefore any guarantee provided by an online compression algorithm that solves this problem, implies an improvement in guarantee over the regret."}, {"heading": "A Additional Proofs", "text": "A.1 Proof of Lemma 2\nProof of Lemma 2. For the lower bound let S be a 2\u01eb-packing of \u2113 and V be an \u01eb-cover of \u2113. Define the following distance function between experts:\ndpi, jq \u201c max tPrT s |\u2113tpiq \u00b4 \u2113tpjq| .\nNow, we define a mapping \u03c0 : S \u00de\u00d1 V by \u03c0piq \u201c argminjPV dpi, jq (breaking ties arbitrarily), namely for every expert i P S we take \u03c0piq to be the expert in V that is closest to i according to d.\nNote that it suffices for us to show that \u03c0 is one-to-one as this will show that |S| \u010f |V |. Indeed, suppose i, j P S are such that \u03c0piq \u201c \u03c0pjq and i \u2030 j. In particular we have |\u2113tpiq \u00b4 \u2113tp\u03c0piqq| \u010f \u01eb and |\u2113tpjq \u00b4 \u2113tp\u03c0pjqq| \u010f \u01eb for all t P rT s, and therefore\n|\u2113tpiq \u00b4 \u2113tpjq| \u010f |\u2113tpiq \u00b4 \u2113tp\u03c0piqq| ` |\u2113tp\u03c0pjqq \u00b4 \u2113tpjq| \u010f 2\u01eb .\nHowever, there exists t P rT s such that |\u2113tpiq \u00b4 \u2113tpjq| \u0105 2\u01eb, thus reaching contradiction. We now turn to prove the upper bound. Let S be a maximal \u01eb-packing, which we will show is also an \u01eb-cover. Suppose otherwise, then there is an expert i such that for every j P S we have dpi, jq \u0105 \u01eb. In particular i R S.\nConsider the set S1 \u201c S Y tiu obtained by adding i to S. This set is also an \u01eb-packing therefore reaching a contradiction.\nA.2 Technical Lemma\nLemma 10. Let 1 \u201c a1 \u0103 a2 \u0103 . . . \u0103 an be a sequence of n natural numbers. Then, n\u00ff\ni\u201c1\nlog ai \u010f 2an log an .\nProof. Consider the convex function fpxq \u201c x logpxq \u00b4 x. Then for any i \u201c 1, 2, . . . , n \u00b4 1 we have fpai`1q \u00b4 fpaiq \u011b f 1paiqpai`1 \u00b4 aiq \u201c logpaiqpai`1 \u00b4 aiq \u011b log ai . Summing,\nn\u00b41\u00ff\ni\u201c1\nlog ai \u010f n\u00b41\u00ff\ni\u201c1\nfpai`1q \u00b4 fpaiq \u201c fpanq \u00b4 fpa1q\n\u201c pan logpanq \u00b4 anq \u00b4 pa1 log a1 \u00b4 a1q \u010f an log an ,\nand thus n\u00ff\ni\u201c1\nlog ai \u010f an log an ` log an \u010f 2an log an ."}], "references": [{"title": "rmk-svd: An algorithm for designing overcomplete dictionaries for sparse representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "IEEE Transactions on signal processing,", "citeRegEx": "Aharon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aharon et al\\.", "year": 2006}, {"title": "The approximate rank of a matrix and its algorithmic applications: approximate rank", "author": ["N. Alon", "T. Lee", "A. Shraibman", "S. Vempala"], "venue": "In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,", "citeRegEx": "Alon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2013}, {"title": "Fat-shattering and the learnability of realvalued functions", "author": ["P.L. Bartlett", "P.M. Long", "R.C. Williamson"], "venue": "In Proceedings of the seventh annual conference on Computational learning theory,", "citeRegEx": "Bartlett et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 1994}, {"title": "Agnostic online learning", "author": ["S. Ben-David", "D. P\u00e1l", "S. Shalev-Shwartz"], "venue": "In COLT,", "citeRegEx": "Ben.David et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2009}, {"title": "How to use expert advice", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Cesa.Bianchi and Lugosi,? \\Q1997\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi", "year": 1997}, {"title": "Prediction with advice of unknown number of experts", "author": ["A. Chernov", "V. Vovk"], "venue": null, "citeRegEx": "Chernov and Vovk.,? \\Q2009\\E", "shortCiteRegEx": "Chernov and Vovk.", "year": 2009}, {"title": "Sparse coding with an overcomplete basis set: A strategy", "author": ["B.A. Olshausen", "D.J. Field"], "venue": "Computer Science,", "citeRegEx": "Olshausen and Field.,? \\Q1989\\E", "shortCiteRegEx": "Olshausen and Field.", "year": 1989}, {"title": "Statistical learning theory, volume 1", "author": ["V.N. Vapnik"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Vapnik.,? \\Q1998\\E", "shortCiteRegEx": "Vapnik.", "year": 1998}], "referenceMentions": [{"referenceID": 3, "context": "This can occur, for example, in online supervised learning (Ben-David et al., 2009), adaptive algorithms (van Erven and Koolen,", "startOffset": 59, "endOffset": 83}, {"referenceID": 7, "context": "These include machine learning (Vapnik, 1998), empirical processes (Pollard, 1990) and information theory (Roman, 1992).", "startOffset": 31, "endOffset": 45}, {"referenceID": 0, "context": "This modeling is motivated by the empirical success (Aharon et al., 2006; Lee et al., 2007), as well as evidence that, for example, the neurons of the V1 optical cortex use similar representations (Olshausen and Field, 1997).", "startOffset": 52, "endOffset": 91}, {"referenceID": 2, "context": "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.", "startOffset": 80, "endOffset": 103}, {"referenceID": 2, "context": "Well known results about the covering numbers of functions of bounded variation (Bartlett et al., 1994) show that in the stochastic i.i.d case, it is possible to learn such functions while suffering only r Op ? V T q regret. However, the situation is drastically different in the online case. For motivation consider the case of binary losses, then V {2 is a bound on the number of times the loss of an expert changes from -1 to 1 or vice versa, during the T rounds of the game. Therefore, the number of experts with distinct losses is 2 \u0159V {2 i\u201c0 ` T \u03011 i \u0306 \u201c OpT V {2q. This entails that by Corollary 5, we have the a guarantee of r OpT V {2q on the regret of Algorithm 2, which is trivial even for V \u201c 2! This leaves us with the following problem: does there exists an algorithm for online learning that attains r Op ? V T q regret when the variation of all experts is bounded by V ? We answer this question negatively. First note that the interesting regime is when T \u0103 logK, otherwise we can obtain a tight \u0398p ? V logKq bound of Hazan and Kale (2010). However, if T \u0103 logK, even if V \u201c Op1q we cannot expect the desired regret bound, as shown in the following result.", "startOffset": 81, "endOffset": 1056}], "year": 2017, "abstractText": "We study the problem of prediction with expert advice when the number of experts in question may be extremely large or even infinite. We devise an algorithm that obtains a tight regret bound of r Op\u01ebT `N ` ? NT q, where N is the empirical \u01eb-covering number of the sequence of loss functions generated by the environment. In addition, we present a hedging procedure that allows us to find the optimal \u01eb in hindsight. Finally, we discuss a few interesting applications of our algorithm. We show how our algorithm is applicable in the approximately low rank experts model of Hazan et al., 2016, and discuss the case of experts with bounded variation, in which there is a surprisingly large gap between the regret bounds obtained in the statistical and online settings.", "creator": "LaTeX with hyperref package"}}}