{"id": "1702.08217", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "A case study on English-Malayalam Machine Translation", "abstract": "in this paper there we present our work on a case study on statistical machine translation ( smt ) and rule based measurement machine translation ( rbmt ) for translation from english to malayalam and malayalam to english. one assessment of the motivations of our statistical study is to make a three way performance comparison, such as, a ) smt and rbmt b ) english to malayalam smt and malayalam to english smt c ) english to malayalam rbmt and malayalam to english rbmt. we describe the development of english to malayalam and malayalam to english baseline phrase based smt system and the evaluation of its performance compared against using the mandarin rbmt system. based on our study the observations are : a ) smt systems outperform rbmt systems, b ) in the case of smt, english - malayalam systems perform better than that amount of malayalam - english systems, c ) in the case rbmt, malayalam to english systems are performing better than english to malayalam systems. based on our evaluations and detailed error analysis, we describe analyzing the requirements of incorporating morphological processing into the linguistics smt to immensely improve the accuracy of translation.", "histories": [["v1", "Mon, 27 Feb 2017 10:09:46 GMT  (841kb)", "http://arxiv.org/abs/1702.08217v1", "This paper contains 10 pages with 4 figures and 10 tables"]], "COMMENTS": "This paper contains 10 pages with 4 figures and 10 tables", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sreelekha s", "pushpak bhattacharyya"], "accepted": false, "id": "1702.08217"}, "pdf": {"name": "1702.08217.pdf", "metadata": {"source": "CRF", "title": "A case study on English-Malayalam Machine Translation", "authors": ["Pushpak Bhattacharyya"], "emails": ["sreelekha@cse.iitb.ac.in", "pb@cse.iitb.ac.in"], "sections": [{"heading": null, "text": "In this paper we present our work on a case study on Statistical Machine Translation (SMT) and Rule based machine translation (RBMT) for translation from English to Malayalam and Malayalam to English. One of the motivations of our study is to make a three way performance comparison, such as, a) SMT and RBMT b) English to Malayalam SMT and Malayalam to English SMT c) English to Malayalam RBMT and Malayalam to English RBMT. We describe the development of English to Malayalam and Malayalam to English baseline phrase based SMT system and the evaluation of its performance compared against the RBMT system. Based on our study the observations are: a) SMT systems outperform RBMT systems, b) In the case of SMT, English - Malayalam systems perform better than that of Malayalam - English systems, c) In the case RBMT, Malayalam to English systems are performing better than English to Malayalam systems. Based on our evaluations and detailed error analysis, we describe the requirements of incorporating morphological processing into the SMT to improve the accuracy of translation."}, {"heading": "1 Introduction", "text": "In a large multi-lingual society like India, there is a great demand for translation of documents from one language to another. Most of the state governments work is in the respective regional languages whereas the Union Government's official documents and reports are in bilingual form (English/Hindi). In order to have a proper communication there is a need to translate these documents and reports in the respective regional languages. The newspapers in regional languages are required to translate news in English received from International News Agencies. With the limitations of human translators most of this reports and documents\nmachine assisted translation system or a translator's workstation would increase the efficiency of the human translators. As is clear from above, India is rich in linguistic divergence there are many morphologically rich languages which are quite different from English as well as from each other, there is a great need for machine translation between them.\nThere are many ongoing attempts to develop MT systems for regional languages using various approaches (Kunchukuttan et al., 2014). The approaches to machine translation are categorized as, Rule Based or Knowledge Driven approaches and Corpus Based or DataDriven approaches. The RBMT approaches are further classified into Transfer based MT, Interlingua MT and Dictionary based MT, while the Corpus Based approaches are classified into Example Based MT and SMT. In the case of English to Indian languages and Indian to Indian languages, there have been fruitful attempts with all approaches (Antony, 2013; Sreelekha et al., 2013; Sreelekha et al., 2014). This paper discusses various approaches used in English to Malayalam and Malayalam to English MT systems.\nThe rest of the paper is as follows, Section 2 deals with challenges in MT, Section 3 deals with approaches in MT, RBMT and SMT, Section 4 deals with Experiments conducted, Evaluations and Error analysis which concludes the main components of the paper."}, {"heading": "2. Challenges in English\u2013Malayalam MT", "text": "Major difficulties in Machine Translation are handling the structural difference between the two languages and handling the ambiguities.\n2.1 Challenge of Ambiguity There are three types of ambiguities: structural ambiguity, lexical ambiguity and semantic ambiguity.\n2.1.1 Lexical Ambiguity Words and phrases in one language often have multiple meaning in another language.\nFor example, the English sentence,\nEnglish- His view was good\nMalayalam\u0d05\u0d35\u0d28\u0d4d\u0d31\u0d46 \u0d05\u0d2d\u0d3f\u0d2a\u0d4d\u0d30\u0d3e\u0d2f\u0d02 \u0d28\u0d32\u0d4d\u0d32\u0d24\u0d3e\u0d2f\u0d3f\u0d30\u0d41\u0d28\u0d4d\u0d28\u0d41\n{ avante abhiprayam nallathayirunnu}\nHere in the above sentence \u201cview\u201d, has ambiguity in meaning. It is not clear that whether the word \u201cview\u201d, is used as the \u201copinion\u201d (\u201c\u0d05\u0d2d\u0d3f\u0d2a\u0d4d\u0d30\u0d3e\u0d2f\u0d02\u201d {abhiprayam} in\nMalayalam) sense or the \u201ceye sight\u201d (\u201c\u0d15\u0d3e\u0d34\u0d4d\u0d1a\u201d{kazhcha} in Malayalam) sense. This\nkind of ambiguity has to be identified from the context.\n2.1.2 Structural Ambiguity In this case, due to the structural order, there will be multiple meanings. For example,\nMalayalam\u0d05\u0d35\u0d3f\u0d31\u0d46 \u0d35\u0d23\u0d4d\u0d23\u0d2e\u0d41\u0d33\u0d4d\u0d33 \u0d30\u0d36\u0d41\u0d35\u0d41\u0d02 \u0d15\u0d3e\u0d33\u0d2f\u0d41\u0d02 \u0d09\u0d23\u0d4d\u0d1f\u0d3e\u0d2f\u0d3f\u0d30\u0d41\u0d28\u0d4d\u0d28\u0d41 {avide vannamulla pashuvum kalayum undayirunnu}\nEnglish- There were fat cows and buffalos there\nHere from the words \u201c\u0d35\u0d23\u0d4d\u0d23\u0d2e\u0d41\u0d33\u0d4d\u0d33 \u0d30\u0d36\u0d41\u0d35\u0d41\u0d02\n\u0d15\u0d3e\u0d33\u0d2f\u0d41\u0d02\u201d{vannamulla pashuvum kalayum} it is\nclear that, cows are fat but it is not clear that buffallos are fat, since in Malayalam to represent fat cows and buffalos only one word \u201c\u0d35\u0d23\u0d4d\u0d23\u0d2e\u0d41\u0d33\u0d4d\u0d33\u201d {vannamulla} {fat} is being used. It\ncan have two interpretations in English according to its structure. {There were fat cows and buffalos there}\nor\n{There were fat cows and fat buffalos there}\nTo handle this kind of structural ambiguity is\none of the big problems in Machine Translation.\n2.1.3 Semantic Ambiguity In this case, due to the understanding of the semantics, there will be multiple translations. For example, consider the English sentence, I eat with spoon and forks I eat with my friends Here this English sentence can be translated in Malayalam as, \u0d1e\u0d3e\u0d7b \u0d38\u0d4d\u0d30\u0d42\u0d23\u0d41\u0d02 \u0d2b \u0d3e\u0d7c\u0d15\u0d4d\u0d41\u0d02 \u0d35\u0d1a\u0d4d\u0d1a\u0d3e\u0d23\u0d4d \u0d15\u0d34\u0d3f\u0d15\u0d4d\u0d41\u0d28\u0d4d\u0d28\u0d24\u0d4d {njan spoonum forkum vachanu kazhikkunnathu}\n{I spoons forks with eat }\nor \u0d1e\u0d3e\u0d7b \u0d0e\u0d7b\u0d31\u0d46 \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d33\u0d41\u0d31\u0d46 \u0d15\u0d42\u0d31\u0d46\u0d2f\u0d3e\u0d23\u0d4d \u0d15\u0d34\u0d3f\u0d15\u0d4d\u0d41\u0d28\u0d4d\u0d28\u0d24\u0d4d {njan ente suhruthukkalude koodeyanu kazhikkunnathu}\n{ I my friends along with eat }\nHere, in the two English sentences \u201cwith\u201d gets translated to \u0d35\u0d1a\u0d4d\u0d1a\u0d3e\u0d23\u0d4d {vachanu} and \u0d15\u0d42\u0d1f\u0d46\u0d2f\u0d3e\u0d23\u0d4d\n{koodeyanu} respectively. This disambiguation requires knowledge to distinguish between spoon- forks and friends.\n2.2 Structural Differences There are word order differences between English and Malayalam such as, English language follows Subject -Verb- Object (SVO) and Malayalam language follows SubjectObject-Verb (SOV). The structural transfer between English- Malayalam is represented in figure 1.\nConsider an example for word ordering, English- Raman ate food\n(S) (V) (O)\nMalayalam- \u0d30\u0d3e\u0d2e\u0d7b \u0d2d\u0d15\u0d4d\u0d37\u0d23\u0d02 \u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41 {Raman bhakshanam kazhichu}\nFigure 1: Structural Transfer from English - Malayalam\n(S) (O) (V)\nIn addition, Malayalam is morphologically very rich as compared to English, wherein there are a lot of post-modifiers in the former as compared to the later.\nFor example, the word form \u201c\u0d15\u0d41\u0d1f\u0d4d\u0d1f\u0d3f\u0d2f\u0d41\u0d31\u0d46\u201d\n{kuttiyude} {of child} is derived by attaching \u201c\u0d2f\u0d41\u0d31\u0d46\u201d{yude}{of} as a suffix to the noun\n\u201c\u0d15\u0d41\u0d1f\u0d4d\u0d1f\u0d3f\u201d{kutti}{child} by undergoing an\ninflectional process. Malayalam exhibits agglutination of suffixes which is not present in English and therefore these suffixes has equivalents in the form of pre positions. For the above example, the English equivalent of the suffix \u201c\u0d2f\u0d41\u0d31\u0d46\u201d {yude} is the pre position\n\u201cof\u201dwhich is separated from the noun \u201cchild\u201d.\nThis kind of structural differences have to\nbe handled properly during translation.\n2.3 Vocabulary Difference Languages differ in the way they lexically divide the conceptual space and sometimes no direct equivalents can be found for a particular word or phrase of one language in another. Consider the sentence, \u0d28\u0d3e\u0d31\u0d33 \u0d15\u0d3e\u0d35\u0d46\u0d3f\u0d2f\u0d3e\u0d1f\u0d4d\u0d1f\u0d02 \u0d09\u0d23\u0d4d\u0d1f\u0d4d\n{ nale kavadiyattam undu}\n{tomorrow kavadiyattam is there}\nHere the word, \u201c\u0d15\u0d3e\u0d35\u0d46\u0d3f\u0d2f\u0d3e\u0d1f\u0d4d\u0d1f\u0d02\u201d\n{kavadiyattam} as a verb has no equivalent in\nEnglish, and this word have to be translated as \u201cthe dance performed especially for the god Muruka using kavadi\u201d. Hence the sentence will be translated in English as,\nTomorrow, the dance performed especially for\nthe god Muruka using kavadi is there.\nTranslating such language specific concepts pose additional challenges in machine translation."}, {"heading": "3. Approaches of MT", "text": "One of the central design questions in machine translation is the syntactic structural transfer, which is the conversion from a syntactic analysis structure of the source language to the structure of the target language. The Vacquois triangle in the figure 2 depicts three different types of Machine Translation namely, Transfer based, Interlingua based and Statistical. They differ in the amount of linguistic processing performed before transferring concepts and structure from the source side to the target side. As can be seen Interlingua requires complete processing, Transfer based requires some and Statistical (a type of direct translation) requires none. The base of the triangle indicates the distance between the two languages and linguistic processing helps bridge the gap.\nDirect translation is appropriate for structurally similar languages. Among the rule based approaches transfer based systems are more flexible and it can be easily extended to language pairs in a multilingual environment. The interlingua based systems can be used for multilingual translation since it used a language independent form. The Universal Networking Language has been proposed as the interlingua (Dave et al., 2002) for overcoming the language barrier."}, {"heading": "3.1 Rule Based Machine Translation", "text": "RBMT system (Sreelekha et..al. 2013) (Sunil et.al. 2011)(Latha et.al. 2012) requires a huge human effort to prepare the rules and linguistic resources, such as morphological analyzers, part-of-speech taggers and syntactic parsers, bilingual dictionaries, transfer rules, morphological generator and reordering rules etc. Specified rules for morphology play a major role in various stages of translation, such as syntactic processing, semantic interpretation and contextual processing of language. The transfer model involves three stages: analysis, transfer and generation. While translating a sentence RBMT system processes it word by word. The complete flow of translation of a word in the form of a pipeline is given in Figure 3."}, {"heading": "3.1.1 Analysis", "text": "During this phase, from the input text information about the morphology, parts of speech, shallow phrases, entity and word sense disambiguation information is extracted."}, {"heading": "3.1.2 Lexical transfer", "text": "The lexical transfer phase involves two parts namely word translation and grammar translation which is performed using high quality bilingual dictionary and transfer grammar rules."}, {"heading": "3.1.3 Generation phase", "text": "Generation involves correction of the genders of the translated words since certain words are masculine in the source language but feminine in the target and vice versa. This is followed by short distance and long-distance agreements performed by intra-chunk and the inter-chunk modules concluded by word generation."}, {"heading": "3.2 Statistical Machine Translation", "text": "Statistical models take the assumption that every word in the target language is a translation of the source language words with some probability (Brown et al., 1993). The words which have the highest probability will give the best translation. There are three different statistical approaches in MT, Wordbased Translation, Phrase-based Translation, and Hierarchical phrase based model.\nConsistent patterns of divergence between the languages (Dorr et al., 1994, Ramananthan et al., 2011, Kunchukuttan and Bhattacharyya 2012) when translating from one language to another, handling reordering divergence are one of the fundamental problems in MT.\nFigure 4 shows the functional flow diagram of a SMT system. During training, from the parallel aligned sentences, word alignments and phrase alignments are learned. This leads to the extraction of phrases and thereby the phrase table, Translational model, Language Model, Distortion table etcetera is modeled. During decoding (Och and Ney, 2001; Och and Ney, 2003; Knight, 1999) the trained models will be decoded to generate the target language translations."}, {"heading": "4 Experimental Discussion", "text": ""}, {"heading": "4.1 SMT System Experiments", "text": "We now describe the development of our English- Malayalam and Malayalam-English SMT System 1 . The experiments performed and the comparisons with the results of the Rule Based system in the form of an error analysis is described in section 3.1. We use Moses (Koehn et al., 2007) and Giza++ 2 for training and to generate the statistical models.\n1 http://www.cfilt.iitb.ac.in/SMT-EM/ 2 http://www.statmt.org/\nWe prepared a well aligned parallel corpus for training, testing and tuning as listed in the tables 1, 2, 3 and 4. As described in Figure 3 and section 2 English and Malayalam are structurally different there were difficulties during reordering. From experiments we\nobserved that SMT system fails to generate inflected word forms at many places since the system was unable to handle the rich morphology of Malayalam.\n4.1.1 English- Malayalam SMT\nConsider an English sentence, He ate food with his friends. The English to Malayalam SMT system translated it as, \u0d05\u0d35\u0d7b \u0d05\u0d35\u0d28\u0d4d\u0d31\u0d46 \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d4d \u0d06\u0d39\u0d3e\u0d30\u0d02 \u0d15\u0d34\u0d3f\u0d15\u0d4d\u0d41\u0d15 {avan avante suhruth aaharam kazhikkuka } {He his friend food ate} Even though the structural order was correct, here the SMT system is failed to generate the inflected form \u201cwith his friends\u201d as \u201c\u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d15\u0d33 \u0d3e\u0d1f\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02\u201d{suhruthukkalodoppam} , which is agglutinated with multiple suffixes, since these inflected word forms were absent in the training corpus. But the system translated \u201cate\u201d as \u201c\u0d15\u0d34\u0d3f\u0d15\u0d4d\u0d41\u0d15\u201d{eat} instead of the inflected past form \u201c\u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41\u201d{ate}.\nMoreover enumerating all possibilities of inflected word forms is not possible manually. Hence the morphology limits the flexibility of SMT systems.\n4.1.2 Malayalam to English SMT\nFor example, consider a Malayalam sentence, \u0d05\u0d35\u0d7b \u0d05\u0d35\u0d28\u0d4d\u0d31\u0d46 \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d2b\u0d33\u0d3e\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02 \u0d06\u0d39\u0d3e\u0d30\u0d02 \u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41 {avan avante suhruthukkalodoppam aaharam kazhichu}\n{He ate food along with his friends}\nThe Malayalam to English SMT system translated it as,\nHe his \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d2b\u0d33\u0d3e\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02 food. Here the system fails to translate the inflected form \u201c\u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d2b\u0d33\u0d3e\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02\u201d {suhruthukkalodoppam} {along with friends}. Also the system missed to translate the word \u201c\u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41\u201d {kazhichu} as \u201cate\u201d since it couldn\u2019t find a matching inflected form in phrase table."}, {"heading": "4.2 Rule-Based MT System Experiments", "text": "We have compared the SMT system translations with the RBMT system translations and the results are shown in the tables 5, 6, 7 and 8.\n4.2.1 Malayalam - English RBMT\nConsider the same Malayalam sentence, \u0d05\u0d35\u0d7b \u0d05\u0d35\u0d28\u0d4d\u0d31\u0d46 \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d2b\u0d33\u0d3e\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02 \u0d06\u0d39\u0d3e\u0d30\u0d02 \u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41.\n{avan avante suhruthukkalodoppam aaharam\nkazhichu}\nThe Malayalam to English RBMT system translated it as, He to along his friends ate food Here each of the words will be processed through the RBMT pipe line. As shown in figure 2, the important steps of the RB system flow for the word \"\u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41\"{kazhichu} {ate} is,\n1. Analysis: The morphological analyzer identifies the word \"\u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41\"{kazhichu} as a\nverb in past tense. After POS tagging, it is identified that the word is a Main Verb and the Chunker determines that it is a part of a Verb Group. After WSD the appropriate sense is determined. 2. Transfer: The lexical transfer module translates it to \"eat\". 3. Generation: Since the sentence is short the\nagreement phenomenon is not so significant. The word generator takes the information about \"past tense\" to give the final word form: \"ate\".\nHowever the translation is far from good, considering that the translation of \u0d38\u0d41\u0d39\u0d43\u0d24\u0d4d\u0d24\u0d41\u0d15\u0d4d\u0d2b\u0d33\u0d3e\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02 {suhruthukkalodoppam} {along with friends} is \u201cto along his friends,\u201d which is not accurate. Here the system is not able to accurately determine the correct translation sense of \u201c\u0d13\u0d31\u0d46\u0d3e\u0d2a\u0d4d\u0d2a\u0d02\u201d{odoppom}{along with}by splitting it into \u201c\u0d13\u0d1f\u0d4d\u201d {odu} {to} , \u201c\u0d12\u0d2a\u0d4d\u0d2a\u0d02\u201d {oppam}{along} leading to a poor lexical choice instead of \u201calong with\u201d.\nConsider the English sentence, He ate food along with his friends. The RBMT output for this sentence is,\n\u0d05\u0d35\u0d7b \u0d15\u0d34\u0d3f\u0d1a\u0d4d\u0d1a\u0d41 \u0d06\u0d39\u0d3e\u0d30\u0d02 \u0d15\u0d42\u0d1f\u0d4d\u0d1f\u0d41\u0d15\u0d3e\u0d30\u0d41\u0d31\u0d46 {avan kazhihcu aaharam koottukarude}\n{He ate food friend\u2019s}\nHere in the transfer stage \u201calong with\u201d is wrongly translated into \u201c\u0d15\u0d3e\u0d30\u0d41\u0d31\u0d46\u201d{karude} and\nit completely destroys the meaning of the sentence.\nWe observed that, although rule based\nMT was able to handle rich morphology, leading to meaning transfer, it was unable to effectively handle the appropriate translation\nand generation of function words and common word senses which are handled well by SMT, which improve fluency (Ahsan, et al. , 2010). As can be seen from the above described example, the translation of a single word requires a number of steps, each involving considerable linguistic inputs. Hence, RBMT process is extremely time consuming, difficult, and fails to analyze accurately and quickly a large corpus of unrestricted text due to inherent errors in the modules which are part of the system."}, {"heading": "4.3 Evaluation", "text": "We have used subjective evaluation to determine fluency (F), an indicator of correct grammatical constructions present in the translated sentence and adequacy (A), an indicator of the amount of meaning being carried over from the source to the target. We did consider BLEU scores (Papineni et al.) also for evaluation. For each translation we assigned scores between 1 and 5 depending on how much sense the translation made and its grammatical correctness. The basis of scoring is given below:\n 5: If the translations are perfect.\n 4: If there are one or two incorrect translations and mistakes.\n 3: If the translations are of average quality, barely making sense.\n 2: If the sentence is barely translated.\n 1: If the sentence is not translated or the translation is gibberish. Let S1, S2, S3, S4 and S5 be the counts of the number of sentences with scores from 1 to 5 and N be the total number of sentences evaluated. The formula (Bhosale et al., 2011) used for computing the scores is:\nWe consider only the sentences with scores above 3. Moreover we penalize the sentences with scores 4 and 3 by multiplying their count by 0.8 and 0.6 respectively so that the estimate of scores is much better. As these scores are subjective, they vary from person to person in which case an inter annotator agreement is required. Since we had only one evaluator we do not give these scores. The results of our evaluations are given in Table 4 and Table 6.\n4.4 Error Analysis\nWe have evaluated the translated outputs of both RBMT and SMT systems. The detailed error analysis for sentences exhibiting a variety of linguistic phenomena is shown in Tables 9 and 10. The result of BLEU score evaluation is displayed in Tables 5, 7 and the result of Subjective evaluation is displayed in Tables 6, 8. It is clear from the evaluations that SMT outperforms RBMT. The reason that the SMT system had a very high fluency was due to plentiful evidences of good quality phrase pairs recorded in the phrase table. Moreover\nthe language model used, helped in generating more natural translations. Also SMT which cannot split suffixes by itself was unable to handle the translation of suffix words in some cases. RBMT being able to use the morph analyzer, can easily separate the suffixes from the inflected words and generate translations inflected with correct gender number person, tense, aspect and mood (GNPTAM). However due to poor quality Word Sense Disambiguation incorrect translations are generated. This is mitigated by SMT since it records phrase translations with respect to frequency which acts as a more natural sense disambiguation mechanism.\nAlso we have observed that, the score of English-Malayalam translation quality is higher than that of Malayalam English translation. Malayalam is morphologically richer than English and Malayalam have more agglutinative suffixes attached as explained in Section 2.2, while in English it is not present. Therefore these Malayalam suffixes have English equivalents in the form of pre positions. English word can align to the words with agglutination in Malayalam easily, since it is a single word. But on the other hand while aligning form Malayalam -English the agglutinative word can map to a single word only, there is a chance to miss out the pre position or either the root word mapping, as it is separate words. Hence the translation quality of English - Malayalam SMT will be high as compared to Malayalam - English SMT.\nMoreover, Malayalam to English RBMT performs better than English to Malayalam\nRBMT. Since Malayalam-English require Morphology analysis and English to Malayalam RBMT requires Morphology Generation. During Malayalam Morphology Analysis, from a single inflected word, agglutinated suffixes are getting separated and it is easy to identify equivalent group words and to translate during lexical transfer. But on the other hand during Morphology generation while generating a single inflected Malayalam word from a group of English words, all words may not get properly formed. There is higher chance to get error in generation of equivalent Malayalam inflected form. Thus Malayalam to English RBMT can handle inflections more accurately than English to Malayalam RBMT."}, {"heading": "5 Conclusion", "text": "In this paper we have mainly focused on the comparative performance of Statistical Machine Translation and Rule- Based Machine Translation. Our major observations are,\n1. Translation quality of SMT is relatively high as compared to the\nRBMT system, considering that the efforts required to build RBMT systems is huge. 2. SMT perform better for English to Malayalam systems with a bleu score\nof 39.90 with a fluency of 87 % and adequacy of 77.23% comparing to Malayalam to English systems with a bleu score of 37.90, fluency of 85.34% and adequacy of 74.89%. 3. RBMT performs better for Malayalam to English with a bleu score of 29.9\nand an adequacy of 64.6%, fluency of 51%, as of English to Malayalam with a bleu score of 20.8 and adequacy of 55.6%, fluency of 47%.\nAs discussed in the experimental section, SMT, although lacks the ability to handle rich morphology, does not fall much behind RBMT. It has a staggering advantage over RBMT in terms of fluency and the ability to capture natural structure (Sreelekha et.al. 2013). This leads to the requirement of incorporating morphological processing into SMT for generating quality Machine Translations.\nOur future work will be focused on the integration of Morphological processing into the Statistical Machine Translation system and thereby develop a better MT system."}, {"heading": "Acknowledgments", "text": "This work is funded by Department of Science and Technology, Govt. of India under Women Scientist Scheme- WOS-A with the project code- SR/WOS-A/ET-1075/2014."}], "references": [{"title": "Clause-Based Reordering Constraints to Improve Statistical Machine Translation.IJCNLP", "author": ["Ananthakrishnan Ramananthan", "Pushpak Bhattacharyya", "Karthik Visweswariah", "Kushal Ladha", "Ankur Gandhe"], "venue": null, "citeRegEx": "Ramananthan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ramananthan et al\\.", "year": 2011}, {"title": "Partially modelling word reordering as a sequence labeling", "author": ["Anoop Kunchukuttan", "Pushpak Bhattacharyya"], "venue": null, "citeRegEx": "Kunchukuttan and Bhattacharyya.,? \\Q2012\\E", "shortCiteRegEx": "Kunchukuttan and Bhattacharyya.", "year": 2012}, {"title": "Machine Translation Approaches and Survey for Indian Languages, The Association for Computational Linguistics and Chinese Language Processing, Vol", "author": ["J. Antony P."], "venue": "18, No. 1, March 2013, pp. 47-78", "citeRegEx": "P.,? 2013", "shortCiteRegEx": "P.", "year": 2013}, {"title": "Coupling Statistical Machine Translation with Rule-based Transfer and Generation", "author": ["Arafat Ahsan", "Prasanth Kolachina", "Sudheer Kolachina", "Dipti Misra Sharma", "Rajeev Sangal."], "venue": "amta2010.amtaweb.org", "citeRegEx": "Ahsan et al\\.,? 2010", "shortCiteRegEx": "Ahsan et al\\.", "year": 2010}, {"title": "Machine Translation Divergences: A Formal Description and Proposed Solution.Computational", "author": ["Bonnie J. Dorr"], "venue": null, "citeRegEx": "Dorr.,? \\Q1994\\E", "shortCiteRegEx": "Dorr.", "year": 1994}, {"title": "A Systematic Comparison of Various Statistical Alignment Models", "author": ["Franz Josef Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och and Ney.,? \\Q2003\\E", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Statistical Multi Source Translation", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "MT Summit 2001.", "citeRegEx": "Och and Ney.,? 2001", "shortCiteRegEx": "Och and Ney.", "year": 2001}, {"title": "Processing of Participle (Krudanta) in Marathi", "author": ["Ganesh Bhosale", "Subodh Kembhavi", "Archana Amberkar", "Supriya Mhatre", "Lata Popale", "Pushpak Bhattacharyya."], "venue": "ICON 2011, Chennai, December, 2011.", "citeRegEx": "Bhosale et al\\.,? 2011", "shortCiteRegEx": "Bhosale et al\\.", "year": 2011}, {"title": "Decoding complexity in wordreplacement translation models", "author": ["Kevin Knight"], "venue": "Computational Linguistics,", "citeRegEx": "Knight.,? \\Q1999\\E", "shortCiteRegEx": "Knight.", "year": 1999}, {"title": "BLEU: a Method for Automatic Evaluation of Machine Translation, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": null, "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Design and Development of a Malayalam to English Translator- A Transfer based Approach", "author": ["Latha R. Nair", "David Peter S", "Renjith Ravindran"], "venue": "International Journal of Computational Linguistics,", "citeRegEx": "Nair et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2012}, {"title": "The Mathematics of Statistical Machine Translation: Parameter Estimationn", "author": ["Peter E Brown", "Robert L. Mercer"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Lexical Resources for Hindi \u2013 Marathi MT", "author": ["Sreelekha", "Pushpak Bhattacharyya", "Malathi D"], "venue": "WIDRE Proceedings,", "citeRegEx": "Sreelekha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sreelekha et al\\.", "year": 2014}, {"title": "Comparison of SMT and RBMT, The Requirement of Hybridization for Marathi ", "author": ["Sreelekha", "Raj Dabre", "Pushpak Bhattacharyya"], "venue": "Hindi MT ICON,", "citeRegEx": "Sreelekha et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sreelekha et al\\.", "year": 2013}, {"title": "Interlingua based EnglishHindi Machine Translation and Language Divergence", "author": ["Shachi Dave", "Jignashu Parikh", "Pushpak Bhattacharyya"], "venue": "JMT", "citeRegEx": "Dave et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dave et al\\.", "year": 2002}, {"title": "Development of Malayalam Text Generator for translation from English, India", "author": ["Sunil R", "Nimtha Manohar", "Jayan V", "KG Sulochana"], "venue": "Conference (INDICON),", "citeRegEx": "R et al\\.,? \\Q2011\\E", "shortCiteRegEx": "R et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 13, "context": "In the case of English to Indian languages and Indian to Indian languages, there have been fruitful attempts with all approaches (Antony, 2013; Sreelekha et al., 2013; Sreelekha et al., 2014).", "startOffset": 129, "endOffset": 191}, {"referenceID": 12, "context": "In the case of English to Indian languages and Indian to Indian languages, there have been fruitful attempts with all approaches (Antony, 2013; Sreelekha et al., 2013; Sreelekha et al., 2014).", "startOffset": 129, "endOffset": 191}, {"referenceID": 14, "context": "The Universal Networking Language has been proposed as the interlingua (Dave et al., 2002) for overcoming the language barrier.", "startOffset": 71, "endOffset": 90}, {"referenceID": 11, "context": "Statistical models take the assumption that every word in the target language is a translation of the source language words with some probability (Brown et al., 1993).", "startOffset": 146, "endOffset": 166}, {"referenceID": 6, "context": "During decoding (Och and Ney, 2001; Och and Ney, 2003; Knight, 1999) the trained models will be decoded to generate the target language translations.", "startOffset": 16, "endOffset": 68}, {"referenceID": 5, "context": "During decoding (Och and Ney, 2001; Och and Ney, 2003; Knight, 1999) the trained models will be decoded to generate the target language translations.", "startOffset": 16, "endOffset": 68}, {"referenceID": 8, "context": "During decoding (Och and Ney, 2001; Och and Ney, 2003; Knight, 1999) the trained models will be decoded to generate the target language translations.", "startOffset": 16, "endOffset": 68}, {"referenceID": 7, "context": "The formula (Bhosale et al., 2011) used for computing the scores is:", "startOffset": 12, "endOffset": 34}], "year": 2017, "abstractText": "In this paper we present our work on a case study on Statistical Machine Translation (SMT) and Rule based machine translation (RBMT) for translation from English to Malayalam and Malayalam to English. One of the motivations of our study is to make a three way performance comparison, such as, a) SMT and RBMT b) English to Malayalam SMT and Malayalam to English SMT c) English to Malayalam RBMT and Malayalam to English RBMT. We describe the development of English to Malayalam and Malayalam to English baseline phrase based SMT system and the evaluation of its performance compared against the RBMT system. Based on our study the observations are: a) SMT systems outperform RBMT systems, b) In the case of SMT, English Malayalam systems perform better than that of Malayalam English systems, c) In the case RBMT, Malayalam to English systems are performing better than English to Malayalam systems. Based on our evaluations and detailed error analysis, we describe the requirements of incorporating morphological processing into the SMT to improve the accuracy of translation.", "creator": "Microsoft\u00ae Office Word 2007"}}}