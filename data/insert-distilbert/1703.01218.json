{"id": "1703.01218", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "Learning Graphical Games from Behavioral Data: Sufficient and Necessary Conditions", "abstract": "in this scientific paper we obtain sufficient and necessary conditions on exactly the number of samples required for exact recovery of the pure - strategy nash equilibria ( psne ) set of a graphical game gamma from noisy observations of joint actions. we consider sparse linear influence games - - - a parametric class comparison of graphical games mixed with linear payoffs, selected and represented by directed graphs of n nodes ( players ) and in - degree of at most 9 k. we show simply that one can efficiently finally recover the psne set of a linear influence game g with $ o ( k ^ 2 \\ log n ) $ samples, under very general observation models. on the other hand, independently we show that $ \\ omega ( \u2264 k \\ log n ) $ samples are necessary for any procedure model to systematically recover the psne set from observations of transient joint actions.", "histories": [["v1", "Fri, 3 Mar 2017 15:55:16 GMT  (187kb,D)", "http://arxiv.org/abs/1703.01218v1", "Accepted to AISTATS 2017, Florida. arXiv admin note: substantial text overlap witharXiv:1607.02959"]], "COMMENTS": "Accepted to AISTATS 2017, Florida. arXiv admin note: substantial text overlap witharXiv:1607.02959", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["asish ghoshal", "jean honorio"], "accepted": false, "id": "1703.01218"}, "pdf": {"name": "1703.01218.pdf", "metadata": {"source": "CRF", "title": "Learning Graphical Games from Behavioral Data: Sufficient and Necessary Conditions", "authors": ["Asish Ghoshal"], "emails": ["jhonorio}@purdue.edu"], "sections": [{"heading": null, "text": "Learning Graphical Games from Behavioral Data: Sufficient and Necessary Conditions\nAsish Ghoshal and Jean Honorio Department of Computer Science\nPurdue University West Lafayette, IN - 47906\n{aghoshal, jhonorio}@purdue.edu\nIn this paper we obtain sufficient and necessary conditions on the number of samples required for exact recovery of the pure-strategy Nash equilibria (PSNE) set of a graphical game from noisy observations of joint actions. We consider sparse linear influence games \u2014 a parametric class of graphical games with linear payoffs, and represented by directed graphs of n nodes (players) and in-degree of at most k. We show that one can efficiently recover the PSNE set of a linear influence game with O ( k2 log n ) samples, under very general observation models. On the other hand, we show that \u2126 (k log n) samples are necessary for any procedure to recover the PSNE set from observations of joint actions."}, {"heading": "1. Introduction and Related Work", "text": "Non-cooperative game theory is widely considered as an appropriate mathematical framework for studying strategic behavior in multi-agent scenarios. In Non-cooperative game theory, the core solution concept of Nash equilibrium describes the stable outcome of the overall behavior of self-interested agents \u2014 for instance people, companies, governments, groups or autonomous systems \u2014 interacting strategically with each other and in distributed settings. Over the past few years, considerable progress has been made in analyzing behavioral data using game-theoretic tools, e.g. computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games. In political science for instance, Irfan and Ortiz [4] identified, from congressional voting records, the most influential senators in the U.S. congress \u2014 a small set of senators whose collective behavior forces every other senator to a unique choice of vote. Irfan and Ortiz [4] also observed that the most influential senators were strikingly similar to the gang-of-six senators, formed during the national debt ceiling negotiations of 2011. Further, using graphical games, Honorio and Ortiz [6] showed that Obama\u2019s influence on Republicans increased in the last sessions before candidacy, while McCain\u2019s influence on Republicans decreased. The problems in algorithmic game theory described above, i.e., computing the Nash equilibria, computing the price of anarchy or finding the most influential agents, require a known graphical game which is not available apriori in real-world settings. Therefore, Honorio and Ortiz [6]\nar X\niv :1\n70 3.\n01 21\n8v 1\n[ cs\n.L G\n] 3\nM ar\n2 01\n7\nproposed learning graphical games from behavioral data, using maximum likelihood estimation (MLE) and sparsity-promoting methods. On the other hand, Garg and Jaakkola [7] provide a discriminative approach to learn a class of graphical games called potential games. Honorio and Ortiz [6] and Irfan and Ortiz [4] have also demonstrated the usefulness of learning sparse graphical games from behavioral data in real-world settings, through their analysis of the voting records of the U.S. congress as well as the U.S. supreme court. In this paper, we obtain necessary and sufficient conditions for recovering the PSNE set of a graphical game in polynomial time. We also generalize the observation model from Ghoshal and Honorio [8], to arbitrary distributions that satisfy certain mild conditions. Our polynomial time method for recovering the PSNE set, which was proposed by Honorio and Ortiz [6], is based on using logistic regression for learning the neighborhood of each player in the graphical game, independently. Honorio and Ortiz [6] showed that the method of independent logistic regression is likelihood consistent; i.e., in the infinite sample limit, the likelihood estimate converges to the best achievable likelihood. In this paper we obtain the stronger guarantee of recovering the true PSNE set exactly. Finally, we would like to draw the attention of the reader to the fact that `1-regularized logistic regression has been analyzed by Ravikumar et. al. [9] in the context of learning sparse Ising models. Apart from technical differences and differences in proof techniques, our analysis of `1-penalized logistic regression for learning sparse graphical games differs from Ravikumar et. al. [9] conceptually \u2014 in the sense that we are not interested in recovering the edges of the true game graph, but only the PSNE set. Therefore, we are able to avoid some stronger conditions required by Ravikumar et. al. [9], such as mutual incoherence."}, {"heading": "2. Preliminaries", "text": "In this section we provide some background information on graphical games introduced by Kearns et. al. [10]."}, {"heading": "2.1. Graphical Games", "text": "A normal-form game G in classical game theory is defined by the triple G = (V,X ,U) of players, actions and payoffs. V is the set of players, and is given by the set V = {1, . . . , n}, if there are n players. X is the set of actions or pure-strategies and is given by the Cartesian product X def= \u00d7i\u2208V Xi, where Xi is the set of pure-strategies of the i-th player. Finally, U def = {ui}ni=1, is the set of payoffs, where ui : Xi \u00d7j\u2208V \\i Xj \u2192 R specifies the payoff for the i-th player given its action and the joint actions of the all the remaining players. An important solution concept in the theory of non-cooperative games is that of Nash equilibrium. For a non-cooperative game, a joint action x\u2217 \u2208 X is a pure-strategy Nash equilibrium (PSNE) if, for each player i, x\u2217i \u2208 argmaxxi\u2208Xi ui(xi,x \u2217 \u2212i), where x \u2217 \u2212i = {x\u2217j |j 6= i}. In other words, x\u2217 constitutes the mutual best-response for all players and no player has any incentive to unilaterally deviate from their optimal action x\u2217i given the joint actions of the remaining players x\u2217\u2212i. The set of all pure-strategy Nash equilibrium (PSNE) for a game G is defined as follows:\nNE(G) = { x\u2217 \u2223\u2223(\u2200i \u2208 V ) x\u2217i \u2208 argmax\nxi\u2208Xi ui(xi,x\n\u2217 \u2212i)\n} . (1)\nGraphical games, introduced by Kearns et al. [10], are game-theoretic analogues of graphical models. A graphical game G is defined by the directed graph, G = (V,E), of vertices and directed\nedges (arcs), where vertices correspond to players and arcs encode \u201cinfluence\u201d among players, i.e., the payoff of the i-th player only depends on the actions of its (incoming) neighbors."}, {"heading": "2.2. Linear Influence Games", "text": "Irfan and Ortiz [4] and Honorio and Ortiz [6], introduced a specific form of graphical games, called Linear Influential Games, characterized by binary actions, or pure strategies, and linear payoff functions. We assume, without loss of generality, that the joint action space X = {\u22121,+1}n. A linear influence game between n players, G(n) = (W,b), is characterized by (i) a matrix of weights W \u2208 Rn\u00d7n, where the entry wij indicates the amount of influence (signed) that the j-th player has on the i-th player and (ii) a bias vector b \u2208 Rn, where bi captures the prior preference of the i-th player for a particular action xi \u2208 {\u22121,+1}. The payoff of the i-th player is a linear function of the actions of the remaining players: ui(xi,x\u2212i) = xi(wT\u2212ix\u2212i \u2212 bi), and the PSNE set is defined as follows:\nNE(G(n)) = { x|(\u2200i) xi(wT\u2212ix\u2212i \u2212 bi) \u2265 0 } , (2)\nwhere w\u2212i denotes the i-th row of W without the i-th entry, i.e. w\u2212i = {wij |j 6= i}. Note that we have diag(W) = 0. Thus, for linear influence games, the weight matrix W and the bias vector b, completely specify the game and the PSNE set induced by the game. Finally, let G(n, k) denote a sparse game over n players where the in-degree of any vertex is at most k."}, {"heading": "3. Problem Formulation", "text": "Now we turn our attention to the problem of learning graphical games from observations of joint actions only. Let NE\u2217 def= NE(G\u2217(n, k)). We assume that there exists a game G\u2217(n, k) = (W\u2217,b\u2217) from which a \u201cnoisy\u201d data set D = {x(l)}ml=1 of m observations is generated, where each observation x(l) is sampled independently and identically from some distribution P. We will use two specific distributions Pg and Pl, which we refer to as the global and local noise model, to provide further intuition behind our results. In the global noise model, we assume that a joint action is observed from the PSNE set with probability qg \u2208 (|NE\u2217|/2n, 1), i.e.\nPg(x) = qg1 [x \u2208 NE\u2217] |NE\u2217| + (1\u2212 qg)1 [x /\u2208 NE\u2217] 2n \u2212 |NE\u2217| . (3)\nIn the above distribution, qg can be thought of as the \u201csignal\u201d level in the data set, while 1\u2212 qg can be thought of as the \u201cnoise\u201d level in the data set. In the local noise model we assume that the joint actions are drawn from the PSNE set with the action of each player corrupted independently by some Bernoulli noise. Then in the local noise model the distribution over joint actions is given as follows:\nPl(x) = 1 |NE\u2217| \u2211\ny\u2208NE\u2217 n\u220f i=1 q 1[xi=yi] i (1\u2212 qi) 1[xi 6=yi], (4)\nwhere qi > 0.5. While these noise models were introduced in [6], we obtain our results with respect to very general observation models, satisfying only some mild conditions. A natural question to ask then is that: \u201cGiven only the data set D and no other information, is it possible to recover the game graph?\u201d Honorio and Ortiz [6] showed that it is in general impossible to learn the true game G\u2217(n, k) from observations of joint actions only because multiple weight matrices\nW and bias vectors b can induce the same PSNE set and therefore have the same likelihood under the global noise model (3) \u2014 an issue known as non-identifiablity in the statistics literature. It is also easy to see that the same holds true for the local noise model. It is, however, possible to learn the equivalence class of games that induce the same PSNE set. We define the equivalence of two games G\u2217(n, k) and G\u0302(n, k) simply as :\nG\u2217(n, k) \u2261 G\u0302(n, k) iff NE(G\u2217(n, k)) = NE(G\u0302(n, k)).\nTherefore, our goal in this paper is efficient and consistent recovery of the pure-strategy Nash equilibria set (PSNE) from observations of joint actions only; i.e., given a data set D, drawn from some game G\u2217(n, k) according to the distribution P, we infer a game G\u0302(n, k) from D such that G\u0302(n, k) \u2261 G\u2217(n, k)."}, {"heading": "4. Method and Results", "text": "In order to efficiently learn games, we make a few assumptions on the probability distribution from which samples are drawn and also on the underlying game."}, {"heading": "4.1. Assumptions", "text": "The following assumption ensures that the distribution P assigns non-zero mass to all joint actions in X and that the signal level in the data set is more than the noise level.\nAssumption 1. There exists constants p\u0303min, p\u0303max and pmax such that the data distribution P satisfies the following:\n0 < p\u0303min 2n \u2212 |NE\u2217| \u2264 P(x) \u2264 p\u0303max 2n \u2212 |NE\u2217| ,\u2200x \u2208 X \\ NE\u2217,\np\u0303max 2n \u2212 |NE\u2217| < P(x) \u2264 pmax \u2264 1, \u2200x \u2208 NE\u2217.\nTo get some intuition for the above assumption, consider the global noise model. In this case we have that p\u0303min = p\u0303max = (1 \u2212 qg), pmax = qg/|NE\u2217|, and \u2200x \u2208 NE\u2217, P(x) = pmax. For the local noise model, consider, for simplicity, the case when there are only two joint actions in the PSNE set: NE\u2217 = {x1,x2}, such that x11 = +1, x21 = \u22121 and x1i = x2i = +1 for all i 6= 1. Then, p\u0303min = 0.5 \u00d7 (1 \u2212 q2) \u00d7 . . . \u00d7 (1 \u2212 qn) \u00d7 (2n \u2212 2), p\u0303max = 0.5 \u00d7 (1 \u2212 qj)( \u220f i/\u2208{j,1} qi) \u00d7 (2n \u2212 2), where qj = min{q2, . . . , qn}, and pmax = 0.5\u00d7 q2 \u00d7 . . . qn. Our next assumption concerns with the minimum payoff in the PSNE set.\nAssumption 2. The minimum payoff in the PSNE set, \u03c1min, is strictly positive, specifically:\nxi(w \u2217 \u2212i Tx\u2212i \u2212 bi) \u2265 \u03c1min > 5Cmin/Dmax (\u2200 x \u2208 NE\u2217),\nwhere Cmin > 0 and Dmax are the minimum and maximum eigenvalue of the expected Hessian and scatter matrices respectively.\nNote that as long as the minimum payoff is strictly positive, we can scale the parameters (W\u2217,b\u2217) by the constant 5Cmin/Dmax to satisfy the condition: \u03c1min > 5Cmin/Dmax, without changing the PSNE set. Indeed the assumption that the minimum payoff is strictly positive is is unavoidable for exact recovery of the PSNE set in a noisy setting such as ours, because otherwise this is akin to exactly recovering the parameters v for each player i. For example, if x \u2208 NE\u2217 is such that v\u2217Tx = 0, then it can be shown that even if \u2016v\u2217 \u2212 v\u0302\u2016\u221e = \u03b5, for any \u03b5 arbitrarily close to 0, then v\u0302Tx < 0 and therefore NE(W\u2217,b\u2217) 6= NE(W\u0302, b\u0302)."}, {"heading": "4.2. Method", "text": "Our main method for learning the structure of a sparse LIG, G\u2217(n, k), is based on using `1- regularized logistic regression, to learn the parameters (w\u2212i, bi) for each player i independently. We denote by vi(W,b) = (w\u2212i,\u2212bi) the parameter vector for the i-th player, which characterizes its payoff; by zi(x) = (xix\u2212i, xi) the \u201cfeature\u201d vector. In the rest of the paper we use vi and zi instead of vi(W,b) and zi(x) respectively, to simplify notation. Then, we learn the parameters for the i-th player as follows:\nv\u0302i = argmin vi `(vi,D) + \u03bb \u2016vi\u20161 (5)\n`(vi,D) = 1\nm m\u2211 l=1 log(1 + exp(\u2212vTi z (l) i )). (6)\nWe then set w\u0302\u2212i = [v\u0302i]1:(n\u22121) and b\u0302i = \u2212[v\u0302i]n, where the notation [.]i:j denotes indices i to j of the vector. We take a moment to introduce the expressions of the gradient and the Hessian of the loss function (6), which will be useful later. The gradient and Hessian of the loss function for any vector v and the data set D is given as follows:\n\u2207`(v,D) = 1 m m\u2211 l=1\n{ \u2212z(l)\n1 + exp(vT z(l))\n} (7)\n\u22072`(v,D) = 1 m m\u2211 l=1 \u03b7(vT z(l))z(l)z(l) T , (8)\nwhere \u03b7(x) = 1/(ex/2+e\u2212x/2)2. Finally, Hmi denotes the sample Hessian matrix with respect to the i-th player and the true parameter v\u2217i , and H \u2217 i denotes its expected value, i.e. H \u2217 i def = ED [Hmi ] =\nED [ \u22072`(v\u2217i ,D) ] . In subsequent sections we drop the notational dependence of H\u2217i and zi on i to simplify notation. We show that, under the aforementioned assumptions on the true game G\u2217(n, k) = (W\u2217,b\u2217),\nthe parameters W\u0302 and b\u0302 obtained using (6) induce the same PSNE set as the true game, i.e., NE(W\u2217,b\u2217) = NE(W\u0302, b\u0302)."}, {"heading": "4.3. Sufficient Conditions", "text": "In this section, we derive sufficient conditions on the number of samples for efficiently recovering the PSNE set of graphical games with linear payoffs. To start with, we make the following observation regarding the number of Nash equilibria of the game satisfying Assumption 2. The proof of the following proposition, as well as other missing proofs can be found in Appendix A.\nProposition 1. The number of Nash equilibria of a non-trivial game (|NE\u2217| \u2208 [1, 2n \u2212 1]) satisfying Assumption 2 is at most 2n\u22121.\nWe will denote the fraction of joint actions that are in the PSNE set by fNE\u2217 def = |NE\u2217|/2n\u22121. By proposition 1, fNE\u2217 \u2208 (0, 1]. Then, our main strategy for obtaining sufficient conditions for exact PSNE recovery guarantees is to first show that under any data distribution P that satisfies Assumption 1, the expected loss is smooth and strongly convex, i.e., the population Hessian matrix is positive definite and the population scatter matrix has eigenvalues bounded by a constant. Then using tools from random matrix theory, we show that the sample Hessian and scatter matrices are \u201cwell behaved\u201d, i.e., are positive definite and have bounded eigenvalues\nrespectively, with high probability. Then, we exploit the convexity properties of the logistic loss function to show that the weight vectors learned using penalized logistic regression are \u201cclose\u201d to the true weight vectors. By our assumption that the minimum payoff in the PSNE set is strictly greater than zero, we show that the weight vectors inferred from a finite sample of joint actions induce the same PSNE set as the true weight vectors. The following lemma shows that the expected Hessian matrices for each player is positive definite and the maximum eigenvalues of the expected scatter matrices are bounded from above by a constant.\nLemma 1. Let S be the support of the vector v, i.e., S def= {i| |vi| > 0}. There exists constant Cmin \u2265 \u03b7(\u2016v\u2217\u20161)2np\u0303min 2n\u2212|NE\u2217| > 0 and Dmax \u2264 2\nnpmax, such that we have \u03bbmin(H\u2217SS) = Cmin and \u03bbmax(Ex [ zSz T S ] ) = Dmax.\nProof.\n\u03bbmin(H \u2217 SS) = \u03bbmin ( Ex [ \u03b7(v\u2217T z)zSz T S ]) = \u03b7(\u2016v\u2217\u20161)\u03bbmin(Ex [ zSz T S ] ).\nLet Z def= {zS |x \u2208 X} and P def = Diag((P(x))x\u2208X ), where zS denotes the feature vector for the i-th player constrained to the support set S for some i. Note that Z \u2208 {\u22121, 1}2n\u00d7|S|; P \u2208 R2n\u00d72n and is positive definite by our assumption that the minimum probability p\u0303min2n\u2212|NE\u2217| > 0. Further note that the columns of Z are orthogonal and ZTZ = 2nI|S|, where I|S| is the |S| \u00d7 |S| identity matrix. Then we have that\n\u03bbmin(Ex [ zSz T S ] ) = min\n{y\u2208R|S||\u2016y\u20162=1} yTZTPZy\n= min {y\u2032\u2208R2n |y\u2032=Zy/\u221a2n\u2227y\u2208R|S|\u2227\u2016y\u20162=1}\n2n(y\u2032)TPy\u2032\n\u2265 min {y\u2032\u2208R2n |\u2016y\u2032\u20162=1}\n2n(y\u2032)TPy\u2032\n= 2n\u03bbmin(P) = 2np\u0303min\n2n \u2212 |NE\u2217|\nTherefore, the minimum eigenvalue of H\u2217SS is lower bounded as follows:\n\u03bbmin(H \u2217 SS) = Cmin \u2265 \u03b7(\u2016v\u2217\u20161)2npmin 2n \u2212 |NE\u2217| > 0.\nSimilarly, the maximum eigenvalue of Ex [ zSz T S ] can be bounded as \u03bbmax(Ex [ zSz T S ] ) = \u03bbmax(Z\nTPZ) \u2264 2npmax."}, {"heading": "4.3.1. Minimum and Maximum Eigenvalues of Finite Sample Hessian and Scatter Matrices", "text": "The following technical lemma shows that the eigenvalues conditions of the expected Hessian and scatter matrices, hold with high probability in the finite sample case.\nLemma 2. If \u03bbmin(H\u2217SS) \u2265 Cmin, \u03bbmax(Ex [ zSz T S ] ) \u2264 Dmax, then we have that\n\u03bbmin(H m SS) \u2265 Cmin 2 , \u03bbmax ( m\u2211 l=1 z (l) S z (l) S T ) \u2264 2Dmax\nwith probability at least 1\u2212 |S| exp ( \u2212mCmin\n2 |S|\n) and 1\u2212 |S| exp ( \u2212mp\u0303min\n4 |S| ) respectively.\nProof. Let\n\u00b5min def = \u03bbmin(H \u2217 SS) and \u00b5max def = \u03bbmax(Ex [ zSz T S ] ).\nFirst note that for all z \u2208 {\u22121,+1}n:\n\u03bbmax(\u03b7(v \u2217 S T zS)zSz T S ) \u2264 |S| 4 def = R\n\u03bbmax(zSz T S ) \u2264 |S| def = R\u2032.\nUsing the Matrix Chernoff bounds from Tropp [11], we have that\nPr {\u03bbmin(HmSS) \u2264 (1\u2212 \u03b4)\u00b5min} \u2264 |S| (\ne\u2212\u03b4\n(1\u2212 \u03b4)1\u2212\u03b4\n)m\u00b5min R\n.\nSetting \u03b4 = 1/2 we get that\nPr {\u03bbmin(HmSS) \u2264 \u00b5min/2} \u2264 |S|\n[\u221a 2\ne\n] 4m\u00b5min |S|\n\u2264 |S| exp ( \u2212mCmin\n2 |S|\n) .\nTherefore, we have Pr {\u03bbmin(HmSS) > Cmin/2} > 1\u2212 |S| exp ( \u2212mCmin\n2 |S|\n) .\nNext, we have that\n\u00b5max = \u03bbmax(Ex [ zSz T S ] )\n\u2265 \u03bbmin(Ex [ zSz T S ] ) \u2265 2\nnp\u0303min 2n \u2212 |NE\u2217|\nOnce again invoking Theorem 1.1 from [11] and setting \u03b4 = 1 we have that Pr {\u03bbmax \u2265 (1 + \u03b4)\u00b5max} \u2264 |S| [ e\u03b4\n(1 + \u03b4)1+\u03b4 ](m\u00b5max)/R\u2032 Pr {\u03bbmax \u2265 2\u00b5max} \u2264 |S| [ e 4\n](m\u00b5max)/|S| \u2264 |S| exp ( \u2212m\u00b5max\n4|S| ) \u2264 |S| exp ( \u2212 m2\nn\u22122p\u0303min |S|(2n\u2212|NE\u2217|) ) \u2264 |S| exp ( \u2212mp\u0303min\n4|S| ) Therefore, we have that\nPr {\u03bbmax < 2Dmax} > 1\u2212 |S| exp ( \u2212mp\u0303min\n4 |S|\n) ."}, {"heading": "4.3.2. Recovering the Pure Strategy Nash Equilibria (PSNE) Set", "text": "Before presenting our main result on the exact recovery of the PSNE set from noisy observations of joint actions, we first present a few technical lemmas that would be helpful in proving the main result. The following lemma bounds the gradient of the loss function (6) at the true vector v\u2217, for all players.\nLemma 3. With probability at least 1\u2212 \u03b4 for \u03b4 \u2208 (0, 1), we have that \u2016\u2207`(v\u2217,D)\u2016\u221e < \u03bd + \u221a 2\nm log\n2n\n\u03b4 ,\nwhere \u03ba = 1/(1+exp(\u03c1min)), \u03c1min \u2265 0 is the minimum payoff in the PSNE set, fNE\u2217 = |NE\u2217|/2n\u22121, and\n\u03bd def = \u03ba \u2211 x\u2208NE\u2217 P(x) + (p\u0303max \u2212 p\u0303min) 2\u2212 fNE\u2217 + fNE\u2217 p\u0303min 2\u2212 fNE\u2217\n(9)\nProof. Consider the i-th player. Let um def= \u2207`(v\u2217i ,D) and umj denote the j-th index of um. For any subset S \u2032 \u2282 X such that |S \u2032| = 2n\u22121 define the function g(S \u2032) as follows:\ng(S \u2032) def= \u2211 x\u2208S\u2032 P(x)f(x)\u2212 \u2211 x\u2208S\u2032c P(x)f(x),\nwhere S \u2032c denotes the complement of the set S \u2032 and f(x) = 1/1+exp(v\u2217i T zi(x)). For x \u2208 NE\u2217, f(x) \u2264 \u03ba, while for x /\u2208 NE\u2217 we have 1/2 \u2264 f(x) \u2264 1. Lastly, let Sij = {x \u2208 X |xixj = +1} and Si = {x \u2208 X |xi = +1}. From (7) we have that, for j 6= n, \u2223\u2223\u2223E [umj ]\u2223\u2223\u2223 = |g(Sij)|, while for j = n\u2223\u2223\u2223E [umj ]\u2223\u2223\u2223 = |g(Si)|. Thus we get \u2016um\u2016\u221e \u2264 maxS\u2032\u2282X||S\u2032|=2n\u22121 g(S \u2032) (10)\nLet S be the set that maximizes (10), A def= S \u2229NE\u2217 and B def= Sc \u2229NE\u2217. Continuing from above,\n|g(S)| = \u2223\u2223\u2223\u2211 x\u2208S\\A P(x)f(x) + \u2211 x\u2208A P(x)f(x)\n\u2212 \u2211\nx\u2208Sc\\B P(x)f(x)\u2212 \u2211 x\u2208B P(x)f(x) \u2223\u2223\u2223 \u2264 \u03ba\n\u2211 x\u2208NE\u2217 P(x) + \u2223\u2223\u2223\u2211 x\u2208S\\A P(x)f(x)\u2212 \u2211 x\u2208Sc\\B P(x)f(x) \u2223\u2223\u2223\nAssume that the first term inside the absolute value above dominates the second term, if not then we can proceed by reversing the two terms.\n|g(S)| \u2264 \u03ba \u2211\nx\u2208NE\u2217 P(x) + 2 n\u22121p\u0303max \u2212 (2n\u22121 \u2212 |NE\u2217|)p\u0303min 2n \u2212 |NE\u2217|\n= \u03ba \u2211\nx\u2208NE\u2217 P(x) + (p\u0303max \u2212 p\u0303min) + fNE \u2217 p\u0303min 2\u2212 fNE\u2217 = \u03bd\nAlso note that \u2223\u2223\u2223umj \u2223\u2223\u2223 \u2264 \u03bd \u2264 1. Finally, from Hoeffding\u2019s inequality [12] and using a union bound argument over all players, we have that:\nPr\n{ n\nmax j=1 \u2223\u2223umj \u2212 E [umj ]\u2223\u2223 < t} > 1\u2212 2ne\u2212mt2/2 =\u21d2 Pr {\u2016um \u2212 E [um]\u2016\u221e < t} > 1\u2212 2ne \u2212mt2/2\n=\u21d2 Pr {\u2016um\u2016\u221e \u2212 \u2016E [u m]\u2016\u221e < t} > 1\u2212 2ne\n\u2212mt2/2\n=\u21d2 Pr {\u2016um\u2016\u221e < \u03bd + t} > 1\u2212 2ne \u2212mt2/2.\nSetting 2n exp(\u2212mt2/2) = \u03b4, we prove our claim.\nTo get some intuition for the lemma above, consider the constant \u03bd as given in (9). First, note that \u03ba \u2264 1/2. Also, as the minimum payoff \u03c1min increases, \u03ba decays to 0 exponentially. Similarly, if the probability measure on the non-Nash equilibria set is close to uniform, meaning p\u0303max \u2212 p\u0303min \u2248 0, then the second term in (9) vanishes. Finally, if the fraction of actions that are in the PSNE set (fNE\u2217) is small, then the third term in (9) is small. Therefore, if the minimum payoff is high, the noise distribution, i.e., the distribution of the non-Nash equilibria joint actions, is close to uniform, and the fraction of joint actions that are in the PSNE set is small, then the expected gradient vanishes. In the following technical lemma we show that the optimal vector v\u0302 for the logistic regression problem is close to the true vector v\u2217 in the support set S of v\u2217. Next, in Lemma 5, we bound the difference between the true vector v\u2217 and the optimal vector v\u0302 in the non-support set. The lemmas together show that the optimal vector is close to the true vector.\nLemma 4. If the regularization parameter \u03bb satisfies the following condition:\n\u03bb \u2264 5C 2 min\n16 |S|Dmax \u2212 \u03bd \u2212\n\u221a 2\nm log\n2n\n\u03b4 ,\nthen\n\u2016v\u2217S \u2212 v\u0302S\u20162 \u2264 5Cmin 4 \u221a |S|Dmax ,\nwith probability at least 1\u2212 (\u03b4 + |S| exp((\u2212mCmin)/2|S|) + |S| exp(\u2212mp\u0303min/4|S|)).\nProof. The proof of this lemma follows the general proof structure of Lemma 3 in [9]. First, we reparameterize the `1-regularized loss function\nf(vS) = `(vS) + \u03bb \u2016vS\u20161\nas the loss function f\u0303 , which gives the loss at a point that is \u2206S distance away from the true parameter v\u2217S as : f\u0303(\u2206S) = `(v \u2217 S +\u2206S)\u2212 `(v\u2217S)+\u03bb(\u2016v\u2217S + \u2206S\u20161\u2212\u2016v \u2217 S\u20161), where \u2206S = vS\u2212v \u2217 S . Also note that the loss function f\u0303 is shifted such that the loss at the true parameter v\u2217S is 0, i.e., f\u0303(0) = 0. Further, note that the function f\u0303 is convex and is minimized at \u2206\u0302S = v\u0302S \u2212 v\u2217S , since v\u0302S minimizes f . Therefore, clearly f\u0303(\u2206\u0302S) \u2264 0. Thus, if we can show that the function f\u0303 is strictly positive on the surface of a ball of radius b, then the point \u2206\u0302S lies inside the ball i.e., \u2016v\u0302S \u2212 v\u2217S\u20162 \u2264 b. Using the Taylor\u2019s theorem we expand the first term of f\u0303 to get the following:\nf\u0303(\u2206S) = \u2207`(v\u2217S)T\u2206S + \u2206TS\u22072`(v\u2217S + \u03b8\u2206S)\u2206S + \u03bb(\u2016v\u2217S + \u2206S\u20161 \u2212 \u2016v \u2217 S\u20161), (11)\nfor some \u03b8 \u2208 [0, 1]. Next, we lower bound each of the terms in (11). Using the Cauchy-Schwartz inequality, the first term in (11) is bounded as follows:\n\u2207`(v\u2217S)T\u2206S \u2265 \u2212\u2016\u2207`(v\u2217S)\u2016\u221e \u2016\u2206S\u20161 \u2265 \u2212\u2016\u2207`(v\u2217S)\u2016\u221e \u221a |S| \u2016\u2206S\u20162\n\u2265 \u2212b \u221a |S| ( \u03bd + \u221a 2\nm log\n2n\n\u03b4\n) , (12)\nwith probability at least 1 \u2212 \u03b4 for \u03b4 \u2208 [0, 1]. It is also easy to upper bound the last term in equation 11, using the reverse triangle inequality as follows:\n\u03bb |\u2016v\u2217S + \u2206S\u20161 \u2212 \u2016v \u2217 S\u20161| \u2264 \u03bb \u2016\u2206S\u20161 .\nWhich then implies the following lower bound:\n\u03bb(\u2016v\u2217S + \u2206S\u20161 \u2212 \u2016v \u2217 S\u20161) \u2265 \u2212\u03bb \u2016\u2206S\u20161 \u2265 \u2212\u03bb \u221a |S| \u2016\u2206S\u20162\n= \u2212\u03bb \u221a |S|b. (13)\nNow we turn our attention to computing a lower bound of the second term of (11), which is a bit more involved.\n\u2206TS\u22072`(v\u2217S + \u03b8\u2206S)\u2206S \u2265 min\u2016\u2206S\u20162=b \u2206TS\u22072`(v\u2217S + \u03b8\u2206S)\u2206S\n= b2\u03bbmin(\u22072`(v\u2217S + \u03b8\u2206S)).\nNow,\n\u03bbmin(\u22072`(v\u2217S + \u03b8\u2206S)) \u2265 min \u03b8\u2208[0,1] \u03bbmin ( \u22072`(v\u2217S + \u03b8\u2206S) ) = min \u03b8\u2208[0,1] \u03bbmin ( 1 m m\u2211 l=1 \u03b7((v\u2217S + \u03b8\u2206S) T z (l) S )z (l) S (z (l) S ) T )\nAgain, using the Taylor\u2019s theorem to expand the function \u03b7 we get\n\u03b7((v\u2217S + \u03b8\u2206S) T z (l) S )\n= \u03b7((v\u2217S) T z (l) S ) + \u03b7 \u2032((v\u2217S + \u03b8\u0304\u2206S) T z (l) S )(\u03b8\u2206S) T z (l) S\n, where \u03b8\u0304 \u2208 [0, \u03b8]. Finally, from Lemma 2 we have, with probability at least 1\u2212|S| exp((\u2212mCmin)/2|S|): \u03bbmin ( \u22072`(v\u2217S + \u03b8\u2206S) ) \u2265 min \u03b8\u2208[0,1] \u03bbmin ( 1 m m\u2211 l=1 \u03b7((v\u2217S) T z (l) S )z (l) S (z (l) S ) T\n+ 1\nm m\u2211 l=1 \u03b7\u2032((v\u2217S + \u03b8\u0304\u2206S) T z (l) S )((\u03b8\u2206S) T z (l) S )z (l) S (z (l) S ) T )\n\u2265 \u03bbmin(HmSS)\u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2\n\u2265 Cmin 2 \u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2,\nwhere we have defined\nA(\u03b8) def =\n1\nm m\u2211 l=1 \u03b7\u2032((v\u2217S + \u03b8\u2206S) T z (l) S )\u00d7\n(\u03b8\u2206S) T z (l) S z (l) S (z (l) S ) T .\nNext, the spectral norm of A(\u03b8) can be bounded as follows:\n|||A(\u03b8)|||2\n\u2264 max \u2016y\u20162=1\n{ 1\nm m\u2211 l=1 \u2223\u2223\u2223\u03b7\u2032((v\u2217S + \u03b8\u2206S)T z(l)S )\u2223\u2223\u2223 \u2223\u2223\u2223((\u03b8\u2206S)T z(l)S )\u2223\u2223\u2223 \u00d7 yT (z(l)S (z (l) S ) T )y }\n< max \u2016y\u20162=1\n1\n(10m) m\u2211 l=1 \u2016(\u03b8\u2206S)\u20161 \u2225\u2225\u2225z(l)S \u2225\u2225\u2225\u221e yT (z(l)S (z(l)S )T )y\n\u2264 \u03b8 max \u2016y\u20162=1\n{ 1\n10m m\u2211 l=1 \u221a |S| \u2016\u2206S\u20162 y T (z (l) S (z (l) S ) T )y\n}\n= \u03b8b \u221a |S| \u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223 110m m\u2211 l=1 z (l) S (z (l) S ) T \u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223 \u2223\u2223\u2223\u2223\u2223 2\n\u2264 (b \u221a |S|Dmax)\n5 \u2264 Cmin 4 ,\nwhere in the second line we used the fact that \u03b7\u2032(.) < 1/10 and in the last line we assumed that (b \u221a |S|Dmax) 5 \u2264 Cmin/4 \u2014 an assumption that we verify momentarily. Having upper bounded the spectral norm of A(\u03b8), we have\n\u03bbmin ( \u22072`(v\u2217S + \u03b8\u2206S) ) \u2265 Cmin\n4 . (14)\nPlugging back the bounds given by (12), (13) and (14) in (11) and equating to zero we get\n\u2212b \u221a |S| ( \u03bd + \u221a 2\nm log\n2n\n\u03b4\n) + b2Cmin\n4 \u2212 \u03bb\n\u221a |S|b = 0\n=\u21d2 b = 4 \u221a |S|\nCmin\n( \u03bb+ \u03bd + \u221a 2\nm log\n2n\n\u03b4\n) .\nFinally, coming back to our prior assumption we have b = 4 \u221a |S|\nCmin\n( \u03bb+ \u03bd + \u221a 2\nm log\n2n\n\u03b4\n) \u2264 5Cmin\n4 \u221a |S|Dmax .\nThe above assumption holds if the regularization parameter \u03bb is bounded as follows:\n\u03bb \u2264 5C 2 min 16 |S|Dmax \u2212 \u221a 2 m log 2n \u03b4 \u2212 \u03bd.\nLemma 5. If the regularization parameter \u03bb satisfies the following condition: \u03bb \u2265 \u03bd + \u221a 2\nm log\n2n\n\u03b4 ,\nthen we have that\n\u2016v\u0302 \u2212 v\u2217\u20161 \u2264 5Cmin Dmax\nwith probability at least 1\u2212 (\u03b4 + |S| exp((\u2212mCmin)/2|S|) + |S| exp(\u2212mp\u0303min/4|S|)).\nNow we are ready to present our main result on recovering the true PSNE set.\nTheorem 1. If for all i, |Si| \u2264 k, the minimum payoff \u03c1min \u2265 5Cmin/Dmax, and the regularization parameter and the number of samples satisfy the following conditions:\n\u03bd +\n\u221a 2\nm log\n6n2\n\u03b4 \u2264 \u03bb \u2264 2K + \u03bd \u2212\n\u221a 2\nm log\n6n2\n\u03b4 (15)\nm \u2265 max\n{ 2\nK2 log\n( 6n2\n\u03b4\n) , 2k\nCmin log\n( 3kn\n\u03b4\n) ,\n4k\np\u0303min log\n( 3kn\n\u03b4\n)} , (16)\nwhere K def= 5C2min/32kDmax \u2212 \u03bd, then with probability at least 1\u2212 \u03b4, for \u03b4 \u2208 (0, 1), we recover the true PSNE set, i.e., NE(W\u0302, b\u0302) = NE(W\u2217,b\u2217).\nProof. From Cauchy-Schwartz inequality and Lemma 5 we have\u2223\u2223(v\u0302i \u2212 v\u2217i )T zi\u2223\u2223 \u2264 \u2016v\u0302i \u2212 v\u2217i \u20161 \u2016zi\u2016\u221e \u2264 5CminDmax . Therefore, we have that\n(v\u2217i ) T zi \u2212 5Cmin Dmax \u2264 v\u0302Ti zi \u2264 (v\u2217i )T zi + 5Cmin Dmax .\nNow, if \u2200 x \u2208 NE\u2217, (v\u2217i )T zi \u2265 5Cmin/Dmax, then v\u0302Ti zi \u2265 0. Using an union bound argument over all players i, we can show that the above holds with probability at least\n1\u2212 n(\u03b4 + k exp((\u2212mCmin)/2k) + k exp((\u2212mp\u0303min)/4k) (17)\nfor all players. Therefore, we have that NE(W\u0302, b\u0302) = NE\u2217 with high probability. Finally, setting \u03b4 = \u03b4\u2032/3n, for some \u03b4\u2032 \u2208 [0, 1], and ensuring that the last two terms in (17) are at most \u03b4\u2032/3n each, we prove our claim.\nTo better understand the implications of the theorem above, we instantiate it for the global and local noise model.\nRemark 1 (Sample complexity under global noise model). Recall that Dmax \u2264 min(k, 2npmax), and for the global noise model given by (3) pmax = qg/|NE\u2217|. If qg is constant, then Dmax = k. Then K = \u2126 (1/k2), and the sample complexity of learning sparse linear games grows as O ( k4 log n ) . However, if qg is small enough, i.e., qg = O (|NE\u2217|/2n), then Dmax is no longer a\nfunction of k and K = \u2126 (1/k). Hence, the sample complexity scales as O ( k2 log n ) for exact PSNE recovery.\nNext, we consider the implications of Theorem 1 under the local noise model given by (4). we consider the regime where the parameter q scales with the number of players n.\nRemark 2 (Sample complexity under local noise). In the local noise model if the number of Nash-equilibria is constant, then pmax = O (exp(\u2212n)), and once again Dmax becomes independent of k, which results in a sample complexity of O ( k2 log n ) .\nAlso, observe the dependence of the sample complexity on the minimum noise level p\u0303min. The number of samples required to recover the PSNE set increases as p\u0303min decreases. From the aforementioned remarks we see that if the noise level is too low, i.e., p\u0303min \u2192 0, then number of samples needed goes to infinity; This seems counter-intuitive \u2014 with reduced noise level, a learning problem should become easier and not harder. To understand this seemingly counterintuitive behavior, first observe that the constant Dmax/Cmin can be thought of as the \u201ccondition number\u201d of the loss function given by (6). Then, the sample complexity as given by Theorem 1 can be written as O ( k2D2max C2min log n ) . Hence, we have that as the noise level gets too low, the Hessian of the loss becomes ill-conditioned, since the data set now comprises of many repetitions of the few joint-actions that are in the PSNE set; thereby increasing the dependency (Dmax) between actions of players in the sample data set."}, {"heading": "4.4. Necessary Conditions", "text": "In this section we derive necessary conditions on the number of samples required to learn graphical games. Our approach for doing so is information-theoretic: we treat the inference procedure as a communication channel and then use the Fano\u2019s inequality to lower bound the estimation error. Such techniques have been widely used to obtain necessary conditions for model selection in graphical models, see e.g. [13, 14], sparsity recovery in linear regression [15], and many other problems. Consider an ensemble Gn of n-player games with the in-degree of each player being at most k. Nature picks a true game G\u2217 \u2208 G, and then generates a data set D of m joint actions. A decoder is any function \u03c8 : Xm \u2192 Gn that maps a data set D to a game, \u03c8(D), in Gn. The minimum estimation error over all decoders \u03c8, for the ensemble Gn, is then given as follows:\nperr def = min\n\u03c8 max G\u2217\u2208Gn\nPr {NE(\u03c8(D)) 6= NE(G\u2217)} , (18)\nwhere the probability is computed over the data distribution. Our objective here is to compute the number of samples below which PSNE recovery fails with probability greater than 1/2.\nTheorem 2. The number of samples required to learn graphical games over n players and indegree of at most k, is \u2126 (k log n).\nRemark 3. From the above theorem and from Theorem 1 we observe that the method of l1regularized logistic regression for learning graphical games, operates close to the fundamental limit of \u2126 (k log n).\nResults from simulation experiments for both global and local noise model can be found in Appendix B.\nConcluding Remarks. An interesting direction for future work would be to consider structured actions \u2014 for instance permutations, directed spanning trees, directed acyclic graphs among others \u2014 thereby extending the formalism of linear influence games to the structured prediction setting. Other ideas that might be worth pursuing are: considering mixed strategies, correlated equilibria and epsilon Nash equilibria, and incorporating latent or unobserved actions and variables in the model."}, {"heading": "Appendix A Detailed Proofs", "text": "Proof of Proposition 1. Let |NE\u2217| > 2n\u22121. Then by the pigeon hole principle there are at least two joint actions x and x\u2032 in NE\u2217 such that x = \u2212x\u2032. Since the payoff is strictly positive, it follows that the bias bi for each player must be 0. If the bias for all players is 0, then for each x \u2208 NE\u2217, \u2212x \u2208 NE\u2217. Therefore, |NE\u2217| = 2n. Since we have assumed that the game is non-trivial, we get a contradiction.\nProof of Lemma 5. Define \u2206 def= v\u0302 \u2212 v\u2217. Also for any vector y let the notation yS denote the vector y with the entries not in the support, S, set to zero, i.e.[\nyS ] i = { yi if i \u2208 S, 0 otherwise.\nSimilarly, let the notation ySc denote the vector y with the entries not in S c set to zero, where Sc is the complement of S. Having introduced our notation and since, S is the support of the true vector v\u2217, we have by definition that v\u2217 = v\u2217\nS . We then have, using the reverse triangle\ninequality,\n\u2016v\u0302\u20161 = \u2016v \u2217 + \u2206\u20161 = \u2225\u2225v\u2217 S + \u2206S + \u2206Sc \u2225\u2225 1\n= \u2225\u2225v\u2217\nS \u2212 (\u2212\u2206S) \u2225\u2225 1 + \u2225\u2225\u2206Sc\u2225\u22251\n\u2265 \u2016v\u2217\u20161 \u2212 \u2225\u2225\u2206S\u2225\u22251 + \u2225\u2225\u2206Sc\u2225\u22251 . (19)\nAlso, from the optimality of v\u0302 for the `1-regularized problem we have that\n`(v\u2217) + \u03bb \u2016v\u2217\u20161 \u2265 `(v\u0302) + \u03bb \u2016v\u0302\u20161 =\u21d2 \u03bb(\u2016v\u2217\u20161 \u2212 \u2016v\u0302\u20161) \u2265 `(v\u0302)\u2212 `(v \u2217). (20)\nNext, from convexity of `(.) and using the Cauchy-Schwartz inequality we have that\n`(v\u0302)\u2212 `(v\u2217) \u2265 \u2207`(v\u2217)T (v\u0302 \u2212 v\u2217) \u2265 \u2212\u2016\u2207`(v\u2217)\u2016\u221e \u2016\u2206\u20161\n\u2265 \u2212\u03bb 2 \u2016\u2206\u20161 , (21)\nin the last line we used the fact that \u03bb \u2265 \u2016\u2207`(v\u2217)\u2016\u221e. Thus, we have from (19), (20) and (21) that\n1 2 \u2016\u2206\u20161 \u2265 \u2016v\u0302\u20161 \u2212 \u2016v \u2217\u20161\n=\u21d2 1 2 \u2016\u2206\u20161 \u2265 \u2225\u2225\u2206Sc\u2225\u22251 \u2212 \u2225\u2225\u2206S\u2225\u22251 =\u21d2 1\n2 \u2225\u2225\u2206Sc\u2225\u22251 + 12 \u2225\u2225\u2206S\u2225\u22251 \u2265 \u2225\u2225\u2206Sc\u2225\u22251 \u2212 \u2225\u2225\u2206S\u2225\u22251 =\u21d2 3\n\u2225\u2225\u2206S\u2225\u22251 \u2265 \u2225\u2225\u2206Sc\u2225\u22251 . (22) Finally, from (22) and Lemma 4 we have that\n\u2016\u2206\u20161 = \u2225\u2225\u2206S\u2225\u22251 + \u2225\u2225\u2206Sc\u2225\u22251\n\u2264 4 \u2225\u2225\u2206S\u2225\u22251 \u2264 4\u221a|S|\u2225\u2225\u2206S\u2225\u22252 \u2264 5Cmin Dmax .\nProof of Theorem 2. First, we construct a restricted ensemble of games G\u0303 \u2282 G as follows. Each game G \u2208 G\u0303 contains k, randomly chosen, influential players. The game graph for G is then chosen to be a complete directed bipartite graph from the set of k influential players to the set of n\u2212 k non-influential players. The edge weights are all set to \u22121, the bias for the k influential players is set to +1, while the bias for the remaining n \u2212 k players is set to 0. Then it is clear that each game in G\u0303 induces a distinct size-one PSNE set. Specifically, for a game G \u2208 G\u0303, a joint action x \u2208 NE(G) is such that xi = \u22121 if player i is influential in G, otherwise xi = +1. Also, note that the minimum payoff in the PSNE set of each game in G\u0303 is strictly positive, and is precisely 1. Finally, we assume that the data set is drawn according to the global noise model (3), with q = 1/n. Now let G \u2208 G\u0303 be a uniformly-distributed random variable corresponding to the game that was picked by nature. From the Fano\u2019s inequality, we have that:\nperr \u2265 1\u2212 I(D;G) + log 2\nH(G) , (23)\nwhere I(.) denotes mutual information and H(.) denotes entropy. Since, G is uniformly distributed, we have that H(G) = log \u2223\u2223G\u0303\u2223\u2223 = log (nk) \u2265 k(log n \u2212 log k). Let PD|G=G1 be the conditional distribution of the data set given a game G1 \u2208 G\u0303. We bound the mutual information I(D;G) by a pairwise KL-based bound from [16] as follows:\nI(D;G) \u2264 1\u2223\u2223G\u0303\u2223\u2223 \u2211 G1\u2208G\u0303 \u2211 G2\u2208G\u0303 KL ( PD|G=G1 \u2225\u2225PD|G=G2) . (24) Now from the fact that data are sampled i.i.d , we get:\nKL ( PD|G=G1 \u2225\u2225PD|G=G2) = m \u2211 x\u2208X PD|G=G1(x) log\nPD|G=G1 (x) PD|G=G2 (x) = m { q log q(2\nn\u22121) 1\u2212q + 1\u2212q 2n\u22121 log 1\u2212q q(2n\u22121) } = m(2\nnq\u22121) 2n\u22121\n( log q \u2212 log ( 1\u2212q\n2n\u22121 )) \u2264 m log 2, (25)\nwhere the last line comes from the fact that q = 1/n. Putting together (23), (24) and (25), and setting perr = 1/2, we get\nm \u2264 k log n\u2212 k log k \u2212 2 log 2 2 log 2 .\nBy observing that learning the ensemble G is at least as hard as learning a subset of the ensemble G\u0303, we prove our main claim."}, {"heading": "Appendix B Experiments", "text": "In order to verify that our results and assumptions indeed hold in practice, we performed various simulation experiments. We generated random LIGs for n players and exactly k neighbors by first creating a matrix W of all zeros and then setting k off-diagonal entries of each row, chosen uniformly at random, to \u22121. We set the bias for all players to 0. We found that any odd value of k produces games with strictly positive payoff in the PSNE set. Therefore, for each value of k\nin {1, 3, 5}, and n in {10, 12, 15, 20}, we generated 40 random LIGs. For experiments involving the local noise model, we only used n \u2208 {10, 12, 15}. The parameter \u03b4 was set to the constant value of 0.01. For the global noise model, the parameters qg was set to 0.01, while for the local noise model we used q1 = . . . = qn = 0.6. The regularization parameter \u03bb was set according to Theorem 1 as some constant multiple of \u221a (2/m) log(2n/\u03b4). Figure 1 shows the probability of successful recovery of the PSNE, for various combinations of (n, k), where the probability was computed as the fraction of the 40 randomly sampled LIGs for which the learned PSNE set matched the true PSNE set exactly. For each experiment, the number of samples was computed as: b(C)(10c)(k2 log(6n2/\u03b4))c, where c is the control parameter and the constant C is 10000 for k = 1 and 1000 for k = 3 and 5. Thus, from Figure 1 we see that, the sample complexity of O ( k2 log n ) as given by Theorem 1 indeed holds in practice, i.e., there exists constants c and c\u2032 such that if the number of samples is less than ck2 log n, we fail to recover the PSNE set exactly with high probability, while if the number of samples is greater than c\u2032k2 log n then we are able to recover the PSNE set exactly, with high probability. Further, the scaling remains consistent as the number of players n is changed from 10 to 20."}], "references": [{"title": "A continuation method for Nash equilibria in structured games", "author": ["B. Blum", "C.R. Shelton", "D. Koller"], "venue": "Journal of Artificial Intelligence Research, vol. 25, pp. 457\u2013502, 2006.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Nash propagation for loopy graphical games", "author": ["L.E. Ortiz", "M. Kearns"], "venue": "Advances in Neural Information Processing Systems, 2002, pp. 793\u2013800.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2002}, {"title": "Multi-agent algorithms for solving graphical games", "author": ["D. Vickrey", "D. Koller"], "venue": "AAAI/IAAI, 2002, pp. 345\u2013351.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "On influence, stable behavior, and the most influential individuals in networks: A game-theoretic approach", "author": ["M.T. Irfan", "L.E. Ortiz"], "venue": "Artificial Intelligence, vol. 215, pp. 79\u2013119, 2014.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Local and global price of anarchy of graphical games", "author": ["O. Ben-Zwi", "A. Ronen"], "venue": "Theoretical Computer Science, vol. 412, no. 12, pp. 1196\u20131207, 2011.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning the structure and parameters of large-population graphical games from behavioral data", "author": ["J. Honorio", "L. Ortiz"], "venue": "Journal of Machine Learning Research, vol. 16, pp. 1157\u20131210, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning tree structured potential games", "author": ["V. Garg", "T. Jaakkola"], "venue": "Neural Information Processing Systems, vol. 29, 2016.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2016}, {"title": "From behavior to sparse graphical games: Efficient recovery of equilibria", "author": ["A. Ghoshal", "J. Honorio"], "venue": "arXiv preprint arXiv:1607.02959, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "High-dimensional Ising model selection using L1-regularized logistic regression", "author": ["P. Ravikumar", "M. Wainwright", "J. Lafferty"], "venue": "The Annals of Statistics, vol. 38, no. 3, pp. 1287\u20131319, 2010. [Online]. Available: http://arxiv.org/abs/1010.0311", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Graphical models for game theory", "author": ["M. Kearns", "M.L. Littman", "S. Singh"], "venue": "Proceedings of the Seventeenth conference on Uncertainty in Artificial Intelligence. Morgan Kaufmann Publishers Inc., 2001, pp. 253\u2013260.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2001}, {"title": "User-friendly tail bounds for sums of random matrices", "author": ["J.A. Tropp"], "venue": "Foundations of computational mathematics, vol. 12, no. 4, pp. 389\u2013434, 2012.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["W. Hoeffding"], "venue": "Journal of the American statistical association, vol. 58, no. 301, pp. 13\u201330, 1963.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1963}, {"title": "Information-theoretic limits of selecting binary graphical models in high dimensions", "author": ["N.P. Santhanam", "M.J. Wainwright"], "venue": "Information Theory, IEEE Transactions on, vol. 58, no. 7, pp. 4117\u2013 4134, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Information-theoretic bounds on model selection for Gaussian Markov random fields.", "author": ["W. Wang", "M.J. Wainwright", "K. Ramchandran"], "venue": "in ISIT. Citeseer,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Information-theoretic limits on sparsity recovery in the high-dimensional and noisy setting", "author": ["M.J. Wainwright"], "venue": "Information Theory, IEEE Transactions on, vol. 55, no. 12, pp. 5728\u20135741, 2009.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games.", "startOffset": 26, "endOffset": 35}, {"referenceID": 1, "context": "computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games.", "startOffset": 26, "endOffset": 35}, {"referenceID": 2, "context": "computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games.", "startOffset": 26, "endOffset": 35}, {"referenceID": 3, "context": "computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games.", "startOffset": 61, "endOffset": 64}, {"referenceID": 4, "context": "computing Nash equilibria [1, 2, 3], most influential agents [4], price of anarchy [5] and related concepts in the context of graphical games.", "startOffset": 83, "endOffset": 86}, {"referenceID": 3, "context": "In political science for instance, Irfan and Ortiz [4] identified, from congressional voting records, the most influential senators in the U.", "startOffset": 51, "endOffset": 54}, {"referenceID": 3, "context": "Irfan and Ortiz [4] also observed that the most influential senators were strikingly similar to the gang-of-six senators, formed during the national debt ceiling negotiations of 2011.", "startOffset": 16, "endOffset": 19}, {"referenceID": 5, "context": "Further, using graphical games, Honorio and Ortiz [6] showed that Obama\u2019s influence on Republicans increased in the last sessions before candidacy, while McCain\u2019s influence on Republicans decreased.", "startOffset": 50, "endOffset": 53}, {"referenceID": 5, "context": "Therefore, Honorio and Ortiz [6]", "startOffset": 29, "endOffset": 32}, {"referenceID": 6, "context": "On the other hand, Garg and Jaakkola [7] provide a discriminative approach to learn a class of graphical games called potential games.", "startOffset": 37, "endOffset": 40}, {"referenceID": 5, "context": "Honorio and Ortiz [6] and Irfan and Ortiz [4] have also demonstrated the usefulness of learning sparse graphical games from behavioral data in real-world settings, through their analysis of the voting records of the U.", "startOffset": 18, "endOffset": 21}, {"referenceID": 3, "context": "Honorio and Ortiz [6] and Irfan and Ortiz [4] have also demonstrated the usefulness of learning sparse graphical games from behavioral data in real-world settings, through their analysis of the voting records of the U.", "startOffset": 42, "endOffset": 45}, {"referenceID": 7, "context": "We also generalize the observation model from Ghoshal and Honorio [8], to arbitrary distributions that satisfy certain mild conditions.", "startOffset": 66, "endOffset": 69}, {"referenceID": 5, "context": "Our polynomial time method for recovering the PSNE set, which was proposed by Honorio and Ortiz [6], is based on using logistic regression for learning the neighborhood of each player in the graphical game, independently.", "startOffset": 96, "endOffset": 99}, {"referenceID": 5, "context": "Honorio and Ortiz [6] showed that the method of independent logistic regression is likelihood consistent; i.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "[9] in the context of learning sparse Ising models.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] conceptually \u2014 in the sense that we are not interested in recovering the edges of the true game graph, but only the PSNE set.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9], such as mutual incoherence.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10], are game-theoretic analogues of graphical models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Linear Influence Games Irfan and Ortiz [4] and Honorio and Ortiz [6], introduced a specific form of graphical games, called Linear Influential Games, characterized by binary actions, or pure strategies, and linear payoff functions.", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "Linear Influence Games Irfan and Ortiz [4] and Honorio and Ortiz [6], introduced a specific form of graphical games, called Linear Influential Games, characterized by binary actions, or pure strategies, and linear payoff functions.", "startOffset": 65, "endOffset": 68}, {"referenceID": 5, "context": "While these noise models were introduced in [6], we obtain our results with respect to very general observation models, satisfying only some mild conditions.", "startOffset": 44, "endOffset": 47}, {"referenceID": 5, "context": "A natural question to ask then is that: \u201cGiven only the data set D and no other information, is it possible to recover the game graph?\u201d Honorio and Ortiz [6] showed that it is in general impossible to learn the true game G\u2217(n, k) from observations of joint actions only because multiple weight matrices", "startOffset": 154, "endOffset": 157}, {"referenceID": 10, "context": "Using the Matrix Chernoff bounds from Tropp [11], we have that", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "1 from [11] and setting \u03b4 = 1 we have that", "startOffset": 7, "endOffset": 11}, {"referenceID": 11, "context": "Finally, from Hoeffding\u2019s inequality [12] and using a union bound argument over all players, we have that:", "startOffset": 37, "endOffset": 41}, {"referenceID": 8, "context": "The proof of this lemma follows the general proof structure of Lemma 3 in [9].", "startOffset": 74, "endOffset": 77}, {"referenceID": 0, "context": "for some \u03b8 \u2208 [0, 1].", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "with probability at least 1 \u2212 \u03b4 for \u03b4 \u2208 [0, 1].", "startOffset": 40, "endOffset": 46}, {"referenceID": 0, "context": "Now, \u03bbmin(\u2207`(v S + \u03b8\u2206S)) \u2265 min \u03b8\u2208[0,1] \u03bbmin ( \u22072`(v\u2217 S + \u03b8\u2206S) )", "startOffset": 33, "endOffset": 38}, {"referenceID": 0, "context": "= min \u03b8\u2208[0,1] \u03bbmin ( 1 m m \u2211", "startOffset": 8, "endOffset": 13}, {"referenceID": 0, "context": "\u2265 min \u03b8\u2208[0,1] \u03bbmin ( 1 m m \u2211", "startOffset": 8, "endOffset": 13}, {"referenceID": 0, "context": "\u2265 \u03bbmin(HSS)\u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2 \u2265 Cmin 2 \u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2,", "startOffset": 19, "endOffset": 24}, {"referenceID": 0, "context": "\u2265 \u03bbmin(HSS)\u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2 \u2265 Cmin 2 \u2212 max \u03b8\u2208[0,1] |||A(\u03b8)|||2,", "startOffset": 54, "endOffset": 59}, {"referenceID": 0, "context": "Finally, setting \u03b4 = \u03b4/3n, for some \u03b4\u2032 \u2208 [0, 1], and ensuring that the last two terms in (17) are at most \u03b4/3n each, we prove our claim.", "startOffset": 41, "endOffset": 47}, {"referenceID": 12, "context": "[13, 14], sparsity recovery in linear regression [15], and many other problems.", "startOffset": 0, "endOffset": 8}, {"referenceID": 13, "context": "[13, 14], sparsity recovery in linear regression [15], and many other problems.", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "[13, 14], sparsity recovery in linear regression [15], and many other problems.", "startOffset": 49, "endOffset": 53}], "year": 2017, "abstractText": "In this paper we obtain sufficient and necessary conditions on the number of samples required for exact recovery of the pure-strategy Nash equilibria (PSNE) set of a graphical game from noisy observations of joint actions. We consider sparse linear influence games \u2014 a parametric class of graphical games with linear payoffs, and represented by directed graphs of n nodes (players) and in-degree of at most k. We show that one can efficiently recover the PSNE set of a linear influence game with O ( k2 log n ) samples, under very general observation models. On the other hand, we show that \u03a9 (k log n) samples are necessary for any procedure to recover the PSNE set from observations of joint actions.", "creator": "LaTeX with hyperref package"}}}