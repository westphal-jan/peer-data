{"id": "1703.01963", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2017", "title": "A new belief Markov chain model and its application in inventory prediction", "abstract": "markov chain model is widely better applied in many fields, especially the field of prediction. the classical discrete - time markov chain ( dtmc ) is a widely used method particularly for cluster prediction. however, even the classical dtmc model has some time limitation when the system is complex with having uncertain information or state space is not discrete. to address it, a new belief markov chain model is proposed by combining dempster - shafer evidence assurance theory with markov chain. in our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability curve assignment ( bpa ) is generated based on the distance between interval numbers. the new belief markov chain model overcomes significantly the shortcomings of classical markov chain and has an efficient ability in dealing with uncertain information. assuming moreover, an example of inventory prediction and the comparison between our model and classical dtmc model can show the effectiveness and rationality of our proposed model.", "histories": [["v1", "Mon, 6 Mar 2017 16:43:13 GMT  (658kb)", "http://arxiv.org/abs/1703.01963v1", "32 pages"]], "COMMENTS": "32 pages", "reviews": [], "SUBJECTS": "cs.AI cs.CE", "authors": ["zichang he", "wen jiang"], "accepted": false, "id": "1703.01963"}, "pdf": {"name": "1703.01963.pdf", "metadata": {"source": "CRF", "title": "A new belief Markov chain model and its application in inventory prediction", "authors": ["Zichang He", "Wen Jiang"], "emails": ["jiangwen@nwpu.edu.cn,", "jiangwenpaper@hotmail.com"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 3.\n01 96\n3v 1\n[ cs\n.A I]\nMarkov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classi-\n\u2217Corresponding author at: School of Electronics and Information, Northwestern Polytechnical University, Xi\u2019an, Shaanxi 710072, China. Tel: (86-29)88431267. E-mail address: jiangwen@nwpu.edu.cn, jiangwenpaper@hotmail.com\nPreprint submitted to Elsevier March 7, 2017\ncal DTMC model can show the effectiveness and rationality of our proposed model. Keywords: Markov chain model; Dempster-Shafer evidence theory; New belief Markov chain; Interval number; Inventory prediction"}, {"heading": "1. Introduction", "text": "A Markov process can be used to model a random system that changes states according to a transition rule that only depends on the current state. And the Markov property is the most important property during Markov process, namely the conditional probability distribution of the future states of the process depends only upon the present state[23, 32, 34]. Markov chain is a stochastic process with Markov property[11]. It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.\nMakov chain is a powerful tool to study sequential data. It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc. Among these, DTMC model having the properties of both simplicity and effectiveness has a widely application in realistic programs[3, 36]. Classical DTMC does a great job in prediction when the discrete states are easy to distinguish. However, The uncertainty and vagueness exist in real world inevitably. The\napplication of DTMC model is limited when the states are not discrete or the realistic states are uncertain. For example, the states can not be determined according to the known data or the collected data may not be crisp. Fuzzy mathematics is a great tool to handle with uncertainty[10, 26, 59]. To address it, some modified models have been proposed like fuzzy Markov chain[4, 9] and fuzzy states based on Markov chain[12, 33]. These models introduce a certain subordinating degree function between the states distribution and the states description. However, considering the complexity of the realistic program, the certain function may be hard to build. Moreover, the evidential Markov chain[51, 52] and some generalized model models[14, 60] are also proposed.\nIn this paper, a new belief Markov chain is proposed. The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57]. The Dempster-shafer fusion can also be modelled in the Markov fields.[7, 45]. Interval number is a simple and efficient tool to handle the uncertain data[18, 25]. Considering the properties of interval number, the BPA is generated based on interval number in our model. Due to it, the uncertain data can be represented in the form of interval number. An application in inventory control shows that our proposed model can represent and handle with uncertainty effectively. The prediction result also agrees with the practical situation, which proves the correctness of our model.\nThe rest of this paper is organized as follows. The preliminaries of the basic theory employed are briefly presented in Section 2. And the shortcoming of DTMC model is illustrated in Section 3. Then our new belief Markov chain model is shown in Section 4. Section 5 uses a numerical example of inventory prediction to show the efficiency of our model. Finally, the paper is concluded in Section 6."}, {"heading": "2. Preliminaries", "text": "In this section, some preliminaries such as DTMC, Dempster-Shafer theory, Pignistic probability transformation(PPT) and interval number are briefly introduced."}, {"heading": "2.1. Discrete-time Markov chain", "text": "Definition 2.1. let {Xn : n > 0} be a random sequence defined in the probability space (\u2126, F, P ). P represents probability measure which is a function from set F to filed of real number R. Every event in F is given a probability value ranged from 0 to 1 by the function P . For arbitrary n \u2208 N+ and states i1, i2, . . ., when P {Xn = in, Xn\u22121 = in\u22121, . . . , X1 = i1} > 0 if satisfying\nP {Xn+1 = in+1|Xn = in, . . . , X1 = i1} = P {Xn+1 = in+1|Xn = in} (1) then the random sequence {Xn : n > 0} is called the Markov chain. Eq.(1) is called the Markov property.\nDefinition 2.2. Markov chain {Xn : n > 0} is homogeneous if meeting the following condition: Given arbitrarym, n and states i, j, meeting P {Xn = i} > 0 and P {Xm = i} > 0,\nP {Xn+1 = j|Xn = i} = P {Xm+1 = j|Xm = i} (2)\nDefinition 2.3. For homogeneous Markov chain, the following conditional probability\nPij (m,m+ n) = P {Xm+n = j|Xm = i} (3)\nis called the transition probability from the condition that m moment Markov chain is in state i to the condition that m+n moment Markov chain is in state j. And the matrix composed of transferring probability is called transferring probability matrix.\nThe following is some important properties of Markov chain. let E denote state space, P (k) ij denote the probability of state i transferring to state j through k steps. The k transferring probability of homogeneous Markov chain has the following properties:\nP (k) ij \u2265 0, \u2200i, j \u2208 E, k \u2265 0 (4)\n\u2211 j\u2208E P (k) ij = 1, \u2200i \u2208 E, k \u2265 0 (5)\nP (m+k) ij = \u2211\nr\u2208E\nP (m) ir P (k) rj , \u2200i, j \u2208 E, m, k \u2265 0 (6)"}, {"heading": "2.2. Dempster-Shafer evidence theory", "text": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information. The following is some basic concepts of D-S evidence theory.\nDefinition 2.4. Let U denote a finite set composed of the whole possible value of the random variable X. The elements of set U are mutually exclusive and U is called the frame of discernment. Let 2U denote the power set of U whose each element corresponds to a subset of the value of X.\nDefinition 2.5. Let U denote the frame of discernment. Given an arbitrary proposition(subset) A of U , a mass function called the basic probability assignment(BPA) is a mapping m : 2U \u2192 [0, 1], satisfying the following conditions:\n\u2211\nA\u22082U\nm (A) = 1 (7)\nand m (\u2205) = 0 (8) where m (A) reflects the evidence\u2019s supporting degree to the proposition A. A is called the focal element if satisfying m (A) > 0"}, {"heading": "2.3. Pignistic probability transformation", "text": "Since the evidence theory assigns the probability to all the subsets of the frame of discernment, the BPA usually relates to probability assignment of a multi-element subset rather than a singleton subset. It reflects the uncertainty of the real world. However, the decisions are uneasy to make by using BPA directly. The BPA is usually converted to probability and then the decision will be make based on the probability. Pignistic probability transformation(PPT) is a classical method to achieve it by averaging the BPA of a multi-element set into singleten sets.\nDefinition 2.6. Let U denote the frame of discernment and m be a BPA on U . A pignistic probability transformation function Bet U \u2192 [0, 1] is defined\nas:\nBet P (x) = \u2211\nx\u2286A,A\u2208U\nm (A)\n|A| (9)\nwhere |A| is the cardinality of proposition A."}, {"heading": "2.4. Interval number", "text": "Definition 2.7. An interval number a\u0303 is defined as a\u0303 = [a\u2212, a+] = {x|a\u2212 \u2264 x \u2264 a+} where a\u2212 and a+ are the lower limiting value and upper limiting value apparently while x \u2208 [0, 1]. Especially, interval number a\u2212 degenerates into a real number when a\u2212 = a+.\nDefinition 2.8. Let A = [a1, a2] and B = [b1, b2] be two interval numbers. The square of the distance between two interval numbers D2 (A,B) is calculated by [55]:\nD2 (A,B) = \u222b\n1 2\n\u2212 1\n2\n{[\n(a1+a2) 2 + x (a2 \u2212 a1) ] \u2212 [ (b1+b2) 2 + x (b2 \u2212 b1) ]}2 dx\n= [\n(a1+a2) 2 \u2212 (b1+b2) 2\n]2\n+ [(a2\u2212a1)+(b2\u2212b1)] 2\n12\n(10)"}, {"heading": "3. The shortcoming of DTMC model", "text": "In this section, a realistic example of inventory anticipation will show the detailed application of DTMC model and its main shortcoming.\nExample 3.1. Table 1 is one company\u2019s statistics of the inventory demand for Product E15 in 20 consecutive periods. Relying on these data, the number 21 periods\u2019 inventory can be anticipated by applying the traditional DTMC model.\nGenerally, the most significant step of prediction is to build a transition probability matrix. Then according to the original states probability assignment, the next period\u2019s probability of transferring to each state can be calculated. A larger transferring probability means it is more likely to be in the state. Consequently, the state of next period can be predicted.\nFirst of all, the states space of DTMC model needs to be determined. Based on the data in Table 1, the inventory demand of one period ranges from 137 to 229. If every integer in the interval is deemed as one state, the number of states will be overmuch and the state transferring condition will be hard to count. Considering the number of states should be rational and convenient for building transition probability matrix, the states need to be classified and the classified states are show in Table 2.\nLet Nij denote the times of transferring from the state i to state j. Then the\nfollowing data are obtained.\nN11 = 2, N12 = 3, N13 = 0;\nN21 = 2, N22 = 4, N23 = 2;\nN31 = 0, N32 = 2, N33 = 4.\nLet E denote the whole state space. Based on the following equation\nPij = Nij/ \u2211\nj\u2208E Nij (11)\nthe transfer probability matrix can be obtained as:\nP =\n\n   \n0.400 0.600 0.000 0.250 0.500 0.250 0.000 0.333 0.667\n\n   \nThe inventory of 20th period is 200 packages, belonging to the state medium. Based on the obtained transfer probability matrix, the state probability assignment of the next period is: (L,M,H) = (0.250, 0.500, 0.250) Thus, the 21st period\u2019s state is most likely to be medium with the probability of 0.500.\nHowever, a serious shortcoming exists in this model. If the inventory of the final period changes from 200 to 201 and the rest data keep the same, then the new transition probability matrix is obtained as:\nP =\n\n   \n0.400 0.600 0.000 0.250 0.500 0.250 0.000 0.167 0.833\n\n   \nBecause 201 belongs to the state high, the state probability assignment of 21st period turns into: (L,M,H) = (0.000, 0.167, 0.8333). And now the state high becomes the most likely one with a probability of 0.833, which is much lager than 0.500. The tiny change in the final period leads to a drastic change of the prediction, which is obviously irrational. The prediction result should be close whatever the final inventory is 200 or 201. The reason causing this situation is that the states are classified by a too crisp critical region. Each value belongs to a certain state with a probability of 1 completely. Thus, the prediction result may change drastically in the critical region.\nIn realistic programs, the value should not correspond to certain state completely. For example, 200 may belong to the state medium with a probability of 0.4 while to the state high with a probability of 0.6. Or the value can not be classified into certain, like it may belong to both medium and high, but the probability of belong to medium or high is uncertain. Besides, the data of the previous periods or the current period may be uncertain. In that case, the states may be hard to classified and the transferring probability matrix is difficult to build. To address these problems, a new belief Markov model is proposed."}, {"heading": "4. The new belief Markov chain model", "text": "The integrated process of building the new belief Markov model is as following:\nStep 1. Determine the state space based on the previous data. Make sure the number of states is rational and all the states form the frame of discernment U .\nStep 2. Calculate the BPA of the whole periods on the power set of the discernment 2U based on the distance between interval numbers.\nStep 3. Calculate the single-step transferring belief assignment Pij, i, j \u2208 2 U based on the obtained BPA, . And then the transition belief matrix [Pij ] is built. Pij represents the belief assignment of transferring from proposition i to proposition j:\nPij =\nn\u22121\u2211 t=1 (m(i)t\u00b7m(j)t+1)\n\u2211\nk\u22082U\nn\u22121\u2211 t=1\n(m(i)t\u00b7m(k)t+1) , i, j \u2208 2U (12)\nwhere m(i)t represents the assigned belief of proposition i in the t moment, n represents the length of the Markov chain.\nNote 4.1. In classical DTMC model, the transition takes place between basic states. While in new belief Markov chain model, the transition takes place between propositions. In other words, the probability is replaced with BPA. Hence, the original transition probability matrix is replaced with the transition belief matrix.\nStep 4. Let m = [m (i)] , i \u2208 2U be the BPA of the final period. Then the assignment of the next period can be obtained by:\nm\u2032 = m \u00b7 [Pij] (13)\nStep 5. Convert the obtained BPA of the next period m\u2032 into the states probability assignment [Pij ] , i \u2208 2 U by using PPT. And the final prediction result is obtained.\nIn our model, one of the most significant step is to generate BPA. The detailed process of generating BPA is shown in the following. First of all, the interval\nBPA need to be obtained. The fuzziness and uncertainty existed in realistic situation can be effectively represented in the form of interval number. And the crisp number can also be deemed as an interval number like 0.5 can be seen as [0.5,0.5].\nBy using Eq.(10), the distance between these interval numbers can be calculated.\nThen the similarity of the interval numbers can be obtained based on the distance.\nDefinition 4.1. Let A= [a1, a2] and B= [b1, b2] be two interval numbers. The\nsimilarity of the two interval numbers S (A,B) is defined as:\nS (A,B) = 1\n1 +D2 (A,B) (14)\nwhere D (A,B) is the distance between interval number A and B.\nWhen the interval number A equals to B, S (A,B) = 1. According to the definition, it is easy to know that the larger the difference between A and B is, the similarity is smaller.\nFinally, normalize the obtained similarity and the BPA of interval number is obtained. An example will show the process in the following.\nExample 4.1. Let state A range in the interval (0,5] and state B range in the interval (5,10]. Given an interval number C=[3,6] and \u03b1=3, the result of generated BPA is shown as Table 3."}, {"heading": "5. Numerical example", "text": "Inventory control is a common realistic problem[37, 42, 44]. In this section, the inventory prediction problem in Section 3 will still be taken as an example\nto show the effectiveness of our model. We assume that some uncertain information exist in the realistic statistics, some data of inventory demand are in the form of interval number. Table 4 is one company\u2019s statistics of the inventory demand for Product E15 in 20 consecutive periods. Following the steps described in Section 4, the new belief Markov model will be applied to do the prediction.\nAs shown in Table 4, the inventory of the whole 20 periods ranges in the interval number [137, 229]. All the values can be classified into three basic states: low(L), medium(M) and high(H). They constitute the frame of discernment U = {L,M,H}. Then the power set of the frame is consisted of {L}, {M}, {H}, {L,M}, {M,H}, {L,H}, {L,M,H} and the empty set \u2205. To assign the value of inventory into its according proposition, the correspondences between propositions and the value of inventory are determined as Table 5. Considering the realistic situation, the assessment of the inventory can not be both low and high, nor do the propositions {L,M,H} or empty set \u2205. So these propositions do not have a according inventory value. After assigning, the distribution of the 20 periods can be showed like Figure 5.\nGenerally speaking, given an inventory value, its according proposition is certain. However, in our model, it can be assigned to every proposition with\ndifferent probabilities. The probabilities of the assignment are unknown for now. The BPA cannot be obtained without a certain probability. Thus the following step is to calculate the probabilities of assignment.\nLet us take the inventory of 6th period [165,180] as an example. Based on Eq.(10), the distance among the inventory and all valid propositions can be obtained. Then by using Eq.(14), the similarity among the inventory and all valid propositions can also be obtained. Lastly, the BPA of 6th period can be obtained by normalizing the similarity. The results are shown in Table 6. And the BPA of 6th period is\nm ({L} , {L,M} , {M} , {M,H} , {H}) = [0.0324, 0.1422, 0.7033, 0.0964, 0.0257]\nRepeat the above process for 20 times, the BPA of each period can be obtained in Table 7.\nAs shown in Table 7, in this program every BPA is nonzero. Thus the Eq.(12) can be rewritten as following:\nPij =\nn\u22121\u2211 t=1 (m(i)t\u00b7m(j)t+1)\n\u2211\nk\u22082U\nn\u22121\u2211 t=1\n(m(i)t\u00b7m(k)t+1) =\nn\u22121\u2211 t=1\n(m(i)t\u00b7m(j)t+1) n\u22121\u2211\nt=1\nm(i) t\n, i, j \u2208 2U (15)\nBy using Eq.(15), the belief assignment of transferring from one proposition to another proposition can be calculated. For example, the belief assignment of transferring from proposition {L} to proposition {L,M} is calculated as:\nP12 =\nn\u22121 \u2211 t=1 ( m({L})t \u00b7m({L,M})t+1 )\nn\u22121 \u2211 t=1 m({L})t\n= 0.4208 (16)\nAll the obtained transferring belief assignments constitute a 5\u00d75 transition belief matrix [Pij] as following:\n\n          \n0.1369 0.4208 0.2914 0.1081 0.0427 0.1329 0.4712 0.2559 0.1046 0.0353 0.0923 0.3188 0.2250 0.2769 0.0870 0.0299 0.0938 0.1271 0.5199 0.2292 0.0228 0.0611 0.0895 0.4165 0.4100\n\n          \nThe next step is to predict the inventory of the 21st period based on the BPA of the 20th period and the matrix [Pij ]. As Table 7 shows, the BPA of the 20th is m (20) = (0.0228, 0.0611, 0.0895, 0.4165, 0.4100). By using the Eq.(13) the BPA of the 21st is calculated as:\nm (21) = m (20) \u00b7 [Pij] = (0.0379, 0.1214, 0.1368, 0.4792, 0.2247) (17)\nFinally, use Pignistic probability transformation(Eq.(9)) to transfer the obtained BPA to the probabilities of basic states.\nBet P (L) =0.0379 + 0.1214\n2 = 0.0986\nBet P (M) = 0.1214\n2 + 0.1368 +\n0.4792\n2 = 0.4371\nBet P (H)= 0.4792\n2 + 0.2247 = 0.4643\nThe result is (L,M,H) = (0.0986, 0.4371, 0.4643). Thus, the inventory of 21st period is most likely to be in stage high. The practical inventory demand for 21st is 223, which is in the state high. Thus, the prediction result confirms with the reality and is rational.\nWhen the inventory of the 20th inventory changes, the result of prediction also change fluently, which verifies the effectiveness and rationality of our model. As Figure 3 shows, when the inventory of the 20th period is less than 195, the prediction result is medium. On the contrary, the result is high when the inventory of the 20th is more than 196. And the line changes fluently. It reveals that the shortcoming of the classical Markov model mentioned in Section 3 can be effectively solved in our model. In addition, the comparison between the prediction and the real situation is shown in Table 8. The practical inventory of 20th is 200, thus the prediction result is in accord with the practical situation which prove the effectiveness of our model.\nIn the following, the comparison between our model and classical DTMC model is made. Compared with the classical model, the most significant\ndifference of our model is that the state is distributed into each possible state with a probability. Figure 4 illustrates the methods of state distribution in different models. The three different models are applied to predict the 21st inventory demand when the data of 20th fluctuates. As Figure 5 shows, along the 20th inventory demand changes, the sudden change will exist in prediction of classical Markov chain model.\nAs mentioned above, the classical DTMC model can not handle the uncertainty, especially a little change of data may lead to a drastic prediction result, which is obviously irrational. The increase in the state number may decrease the trouble caused by uncertainty of states in some degree. However, a larger data set will be needed to assure it and the problem of drastic change in prediction is still unavoidable. By contrast, our new belief Markov\nchain model can handle these shortcomings effectively. Moreover, the uncertain data like interval number can also be well handled, which proves our model\u2019s ability of handling uncertain information."}, {"heading": "6. Conclusion", "text": "In this paper, a new belief Markov chain model is proposed. The shortcomings of classical DTMC model are successfully overcame in this model. The main advantages of the new model are as following:\n1. Stability. The sudden change of prediction result is avoided, namely the prediction result will change fluently along the slight change of data.\n2. The ability of handling uncertain information. Either the uncertainty of\nstate or data can be effectively handled in our model.\n3. Flexibility. The different state distribution schemes and basic probability assignment distribution functions can lead to different results. The setting can be adjusted according to the realistic situation which reveals the flexibility of our model.\nA numerical example of inventory prediction is illustrated in the paper to show the application of our model. And the prediction result and comparison prove the effectiveness and rationality of our model."}, {"heading": "Acknowledgement", "text": "The work is partially supported by National Natural Science Foundation of China (Grant No. 61671384), Natural Science Basic Research Plan in Shaanxi Province of China (Program No. 2016JM6018), the Fund of SAST (Program No. SAST2016083), the Seed Foundation of Innovation and Creation for Graduate Students in Northwestern Polytechnical University (Program No. Z2016122)."}], "references": [{"title": "Markov decision processes: a tool for sequential decision making under uncertainty", "author": ["O. Alagoz", "A.J. Hsu HSchaefer", "M.S. Roberts"], "venue": "Medical Decision Making", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Twelve years of succession on sandy substrates in a post-mining landscape: a markov chain analysis", "author": ["B. Annett", "T. Sabine", "B. Helge"], "venue": "Ecological Applications A Publication of the Ecological Society of America", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Discrete-time markov chain approach to contact-based disease spreading in complex networks", "author": ["A. Arenas", "J. Borge-Holthoefer", "S. Meloni", "Y Moreno"], "venue": "EPL (Europhysics Letters)", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Fuzzy markov chains and decision-making", "author": ["K.E. Avrachenkov", "E. Sanchez"], "venue": "Fuzzy Optimization and Decision Making", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2002}, {"title": "Model-checking continuous-time markov chains", "author": ["A. Aziz", "K. Sanwal", "V. Singhal", "R. Brayton"], "venue": "ACM Transactions on Computational Logic (TOCL)", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Modelling uncertain implication rules in evidence", "author": ["A. Benavoli", "L. Chisci", "A. Farina", "B. Ristic"], "venue": "theory, in: Information Fusion,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Dempster-shafer fusion of evidential pairwise markov fields", "author": ["M.E.Y. Boudaren", "L. An", "W. Pieczynski"], "venue": "IEEE Transactions on Fuzzy Systems", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "Building a binary outranking relation in uncertain, imprecise and multi- 22  experts contexts: The application of evidence theory", "author": ["M.A. Boujelben", "Y. De Smet", "A. Frikha", "H. Chabchoub"], "venue": "International journal of approximate reasoning", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Fuzzy markov chains. Fuzzy Probabilities: New Approach and Applications", "author": ["J.J. Buckley"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "A generalized similarity measure for fuzzy numbers", "author": ["C.C. Chou"], "venue": "Journal of Intelligent & Fuzzy Systems", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2016}, {"title": "The first passage problem for a continuous markov process", "author": ["D.A. Darling", "A.J.F. Siegert"], "venue": "Annals of Mathematical Statistics", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1953}, {"title": "Expected transition costs based on a markov model having fuzzy states with an application to policy selection", "author": ["A. De Korvin", "R. Kleyle"], "venue": "Stochastic analysis and applications", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1998}, {"title": "Supplier selection using AHP methodology extended by d numbers", "author": ["X. Deng", "Y. Hu", "Y. Deng", "S. Mahadevan"], "venue": "Expert Systems with Applications", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Newborns prediction based on a belief markov chain model", "author": ["X. Deng", "Q. Liu", "Y. Deng"], "venue": "Applied Intelligence", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "D-cfpr: D numbers extended consistent fuzzy preference relations", "author": ["X. Deng", "X. Lu", "F.T.S. Chan", "R. Sadiq", "S. Mahadevan", "Y. Deng"], "venue": "Knowledge-Based Systems 73,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Generalized evidence theory", "author": ["Y. Deng"], "venue": "Applied Intelligence", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "A new fuzzy dempster mcdm method and its application in supplier selection", "author": ["Y. Deng", "F.T.S. Chan"], "venue": "Expert Systems with Applications", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "An interactive genetic algorithm with the interval arithmetic based on hesitation and its application to achieve customer collaborative product configuration design", "author": ["R. Dou", "C. Zong", "M. Li"], "venue": "Applied Soft Computing", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Markov stochastic technique to determine galactic cosmic ray sources distribution", "author": ["A. Farahat"], "venue": "Journal of Astrophysics and Astronomy", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Managing risk for business processes: A fuzzy based multi-agent system", "author": ["N. Feng", "X. Yu", "R. Dou", "B. Pan"], "venue": "Journal of Intelligent & Fuzzy Systems", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "On single station forecasting: Sunshine and rainfall markov chains", "author": ["K. Fraedrich", "K. Muller"], "venue": "Beitr. Phys. Atmos", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1983}, {"title": "A group evidential reasoning approach based on expert reliability", "author": ["C. Fu", "J.B. Yang", "S.L. Yang"], "venue": "European Journal of Operational Research 246,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Distribution theory of runs: A markov chain approach", "author": ["J.C. Fu", "M.V. Koutras"], "venue": "Journal of the American Statistical Association", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1994}, {"title": "A risk assessment approach for failure mode and effects analysis based on intuitionistic fuzzy sets and evidence theory", "author": ["J. Guo"], "venue": "Journal of Intelligent & Fuzzy Systems", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "A nonlinear interval number programming method for uncertain optimization problems", "author": ["C. Jiang", "X. Han", "G. Liu"], "venue": "European Journal of Operational Research", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "An improved method to rank generalized fuzzy numbers with different left heights and right heights", "author": ["W. Jiang", "Y. Luo", "X. Qin", "J. Zhan"], "venue": "Journal of Intelligent & Fuzzy Systems", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "2016a. An evidential sensor fusion method in fault diagnosis", "author": ["W. Jiang", "B. Wei", "C. Xie", "D. Zhou"], "venue": "Advances in Mechanical Engineering", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "2016b. A method to determine generalized basic probability assignment in the open world", "author": ["W. Jiang", "J. Zhan", "D. Zhou", "X. Li"], "venue": "Mathematical Problems in Engineering", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Phev power distribution fuzzy logic control strategy based on prediction", "author": ["Y. Jin", "Z. Xie", "J. Chen", "E. Chen"], "venue": "Journal of Zhejiang University of Technology", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Evaluating risk of water mains failure using a bayesian belief network model", "author": ["G. Kabir", "S. Tesfamariam", "A. Francisque", "R. Sadiq"], "venue": "European Journal of Operational Research", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Finite markov chain", "author": ["J.G. Kemeny", "J.L. Snell"], "venue": "American Mathematical Monthly", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1960}, {"title": "Transition probabilities for markov chains having fuzzy states", "author": ["R. Kleyle", "A. De Korvin"], "venue": "Stochastic analysis and applications 15,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1997}, {"title": "On ergodicity of some markov processes", "author": ["T. Komorowski", "T. Szarek"], "venue": "Annals of Probability", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2010}, {"title": "Predicting transmembrane protein topology with a hidden markov model: application to complete genomes", "author": ["A. Krogh", "B. Larsson", "G. Von Heijne", "E.L. Sonnhammer"], "venue": "Journal of molecular biology", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Discrete-time markov chains, in: Applied Probability", "author": ["K. Lange"], "venue": null, "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2010}, {"title": "Approximation Algorithms for Stochastic Inventory Control Models", "author": ["R. Levi", "M. Pl", "R. Roundy", "D.B. Shmoys"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2005}, {"title": "The improvement of ds evidence theory and its application in ir/mmw target recognition", "author": ["Y. Li", "J. Chen", "F. Ye", "D. Liu"], "venue": "Journal of Sensors", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2016}, {"title": "Study of rainfall prediction model based on gm (1, 1) - markov chain, in: Water Resource and Environmental Protection (ISWREP)", "author": ["C. Liu", "Y.M. Tian", "X.H. Wang"], "venue": "International Symposium on,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2011}, {"title": "Application of markov prediction method in the decision of insurance company", "author": ["Y. Lu", "M. Zhang", "T. Yu", "M. Qu"], "venue": null, "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2014}, {"title": "Probabilistic markov models in economic evaluation of health technologies: a practical guide", "author": ["J. Mar", "F. Anto?anzas", "R. Pradas", "A. Arrospide"], "venue": "Gaceta Sanitaria", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2010}, {"title": "Production Planning and Inventory Control in Automotive Supply Chain Networks", "author": ["A. Memari", "Rahim", "A.R.B.A", "R.B. Ahmad"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2014}, {"title": "Stochastic Humanitarian Inventory Control Model for Disaster Planning", "author": ["K. Ozbay", "E.E. Ozguven"], "venue": null, "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2007}, {"title": "Multisensor triplet markov fields and theory of evidence", "author": ["W. Pieczynski", "D. Benboudjema"], "venue": "Image & Vision Computing", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2006}, {"title": "Discrete-time markov chains, in: Understanding Markov Chains", "author": ["N. Privault"], "venue": null, "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2013}, {"title": "An introduction to hidden markov models", "author": ["L.R. Rabiner", "B.H. Juang"], "venue": "ASSP Magazine,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 1986}, {"title": "Enhancement of electric arc furnace reactive power compensation using grey-markov prediction method", "author": ["H. Samet", "A. Mojallal"], "venue": "Generation, Transmission & Distribution,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2014}, {"title": "A mathematical theory of evidence. volume 1. Princeton university press Princeton", "author": ["G Shafer"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 1976}, {"title": "Uncertainty measure for interval-valued belief structures", "author": ["Y. Song", "X. Wang", "L. Lei", "S. Yue"], "venue": "Measurement", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2016}, {"title": "An Evidential Measure of Risk in Evidential Markov Chains", "author": ["H. Soubaras"], "venue": null, "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2009}, {"title": "On evidential markov chains", "author": ["H. Soubaras"], "venue": "Studies in Fuzziness & Soft Computing", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2010}, {"title": "Combining dependent bodies of evidence", "author": ["X. Su", "S. Mahadevan", "W. Han", "Y. Deng"], "venue": "Applied Intelligence 44,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2016}, {"title": "Bayesian selection of continuous-time markov chain evolutionary models", "author": ["M.A. Suchard", "R.E. Weiss", "J.S. Sinsheimer"], "venue": "Molecular biology and evolution", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2001}, {"title": "Comparison of fuzzy numbers using a fuzzy distance measure", "author": ["L. Tran", "L. Duckstein"], "venue": "Fuzzy sets and systems", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2002}, {"title": "Classic works of the Dempster-Shafer theory of belief functions", "author": ["R.R. Yager", "L. Liu"], "venue": null, "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2008}, {"title": "A new distance-based total uncertainty measure in the theory of belief functions", "author": ["Y. Yang", "D. Han"], "venue": "Knowledge-Based Systems", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2016}, {"title": "An improved conflicting evidence combination approach based on a new supporting probability distance", "author": ["C. Yu", "J. Yang", "D. Yang", "X. Ma", "H. Min"], "venue": "Expert Systems with Applications", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2015}, {"title": "A novel system anomaly prediction system based on belief markov model and ensemble classification", "author": ["X. Zhou", "S. Li", "Z. Ye"], "venue": null, "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2013}], "referenceMentions": [{"referenceID": 22, "context": "And the Markov property is the most important property during Markov process, namely the conditional probability distribution of the future states of the process depends only upon the present state[23, 32, 34].", "startOffset": 197, "endOffset": 209}, {"referenceID": 30, "context": "And the Markov property is the most important property during Markov process, namely the conditional probability distribution of the future states of the process depends only upon the present state[23, 32, 34].", "startOffset": 197, "endOffset": 209}, {"referenceID": 32, "context": "And the Markov property is the most important property during Markov process, namely the conditional probability distribution of the future states of the process depends only upon the present state[23, 32, 34].", "startOffset": 197, "endOffset": 209}, {"referenceID": 10, "context": "Markov chain is a stochastic process with Markov property[11].", "startOffset": 57, "endOffset": 61}, {"referenceID": 0, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 38, "endOffset": 52}, {"referenceID": 1, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 38, "endOffset": 52}, {"referenceID": 18, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 38, "endOffset": 52}, {"referenceID": 38, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 82, "endOffset": 90}, {"referenceID": 45, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 82, "endOffset": 90}, {"referenceID": 20, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 119, "endOffset": 127}, {"referenceID": 37, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 119, "endOffset": 127}, {"referenceID": 28, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 147, "endOffset": 155}, {"referenceID": 39, "context": "It is widely used in many applications[1, 2, 19, 43], especially in the prediction[40, 48], such as rainfall prediction[21, 39], economy prediction[29, 41] and so on.", "startOffset": 147, "endOffset": 155}, {"referenceID": 43, "context": "It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc.", "startOffset": 158, "endOffset": 162}, {"referenceID": 4, "context": "It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc.", "startOffset": 192, "endOffset": 199}, {"referenceID": 51, "context": "It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc.", "startOffset": 192, "endOffset": 199}, {"referenceID": 33, "context": "It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc.", "startOffset": 220, "endOffset": 228}, {"referenceID": 44, "context": "It provides a bunch of models to analyze time series data and predict the variation tendencies of random processes, including discrete-time Markov chain(DTMC)[46], continuous-time Markov chain[5, 54], hidden Markov chain[35, 47], etc.", "startOffset": 220, "endOffset": 228}, {"referenceID": 2, "context": "Among these, DTMC model having the properties of both simplicity and effectiveness has a widely application in realistic programs[3, 36].", "startOffset": 129, "endOffset": 136}, {"referenceID": 34, "context": "Among these, DTMC model having the properties of both simplicity and effectiveness has a widely application in realistic programs[3, 36].", "startOffset": 129, "endOffset": 136}, {"referenceID": 9, "context": "Fuzzy mathematics is a great tool to handle with uncertainty[10, 26, 59].", "startOffset": 60, "endOffset": 72}, {"referenceID": 25, "context": "Fuzzy mathematics is a great tool to handle with uncertainty[10, 26, 59].", "startOffset": 60, "endOffset": 72}, {"referenceID": 3, "context": "To address it, some modified models have been proposed like fuzzy Markov chain[4, 9] and fuzzy states based on Markov chain[12, 33].", "startOffset": 78, "endOffset": 84}, {"referenceID": 8, "context": "To address it, some modified models have been proposed like fuzzy Markov chain[4, 9] and fuzzy states based on Markov chain[12, 33].", "startOffset": 78, "endOffset": 84}, {"referenceID": 11, "context": "To address it, some modified models have been proposed like fuzzy Markov chain[4, 9] and fuzzy states based on Markov chain[12, 33].", "startOffset": 123, "endOffset": 131}, {"referenceID": 31, "context": "To address it, some modified models have been proposed like fuzzy Markov chain[4, 9] and fuzzy states based on Markov chain[12, 33].", "startOffset": 123, "endOffset": 131}, {"referenceID": 48, "context": "Moreover, the evidential Markov chain[51, 52] and some generalized model models[14, 60] are also proposed.", "startOffset": 37, "endOffset": 45}, {"referenceID": 49, "context": "Moreover, the evidential Markov chain[51, 52] and some generalized model models[14, 60] are also proposed.", "startOffset": 37, "endOffset": 45}, {"referenceID": 13, "context": "Moreover, the evidential Markov chain[51, 52] and some generalized model models[14, 60] are also proposed.", "startOffset": 79, "endOffset": 87}, {"referenceID": 56, "context": "Moreover, the evidential Markov chain[51, 52] and some generalized model models[14, 60] are also proposed.", "startOffset": 79, "endOffset": 87}, {"referenceID": 46, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 120, "endOffset": 128}, {"referenceID": 53, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 120, "endOffset": 128}, {"referenceID": 5, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 178, "endOffset": 192}, {"referenceID": 7, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 178, "endOffset": 192}, {"referenceID": 47, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 178, "endOffset": 192}, {"referenceID": 54, "context": "The new model uses the basic probability assignment(BPA) to describe the uncertainty of states as Dempster-Shafer theory[49, 56] is an efficient tool to deal with the uncertainty[6, 8, 50, 57].", "startOffset": 178, "endOffset": 192}, {"referenceID": 6, "context": "[7, 45].", "startOffset": 0, "endOffset": 7}, {"referenceID": 42, "context": "[7, 45].", "startOffset": 0, "endOffset": 7}, {"referenceID": 17, "context": "Interval number is a simple and efficient tool to handle the uncertain data[18, 25].", "startOffset": 75, "endOffset": 83}, {"referenceID": 24, "context": "Interval number is a simple and efficient tool to handle the uncertain data[18, 25].", "startOffset": 75, "endOffset": 83}, {"referenceID": 15, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 72, "endOffset": 80}, {"referenceID": 55, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 72, "endOffset": 80}, {"referenceID": 50, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 113, "endOffset": 117}, {"referenceID": 27, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 167, "endOffset": 171}, {"referenceID": 26, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 220, "endOffset": 224}, {"referenceID": 12, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 251, "endOffset": 259}, {"referenceID": 16, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 251, "endOffset": 259}, {"referenceID": 14, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 276, "endOffset": 292}, {"referenceID": 21, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 276, "endOffset": 292}, {"referenceID": 36, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 276, "endOffset": 292}, {"referenceID": 19, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 343, "endOffset": 355}, {"referenceID": 23, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 343, "endOffset": 355}, {"referenceID": 29, "context": "Tough evidence theory has some open issues, such as conflict management [16, 58], dependent evidence combination [53] and determination of basic probability assignment[28], it has a wide applications like fault diagnosis[27], supplier chain management[13, 17], decision making[15, 22, 31, 38] and risk evaluation which matters a lot in reality[20, 24, 30], due to its efficiency to model and fuse uncertain information.", "startOffset": 343, "endOffset": 355}, {"referenceID": 0, "context": "Given an arbitrary proposition(subset) A of U , a mass function called the basic probability assignment(BPA) is a mapping m : 2 \u2192 [0, 1], satisfying the following conditions:", "startOffset": 130, "endOffset": 136}, {"referenceID": 0, "context": "A pignistic probability transformation function Bet U \u2192 [0, 1] is defined 6", "startOffset": 56, "endOffset": 62}, {"referenceID": 0, "context": "An interval number \u00e3 is defined as \u00e3 = [a, a] = {x|a \u2264 x \u2264 a} where a and a are the lower limiting value and upper limiting value apparently while x \u2208 [0, 1].", "startOffset": 151, "endOffset": 157}, {"referenceID": 52, "context": "The square of the distance between two interval numbers D (A,B) is calculated by [55]: D (A,B) = \u222b 1 2 \u2212 1 2 {[", "startOffset": 81, "endOffset": 85}, {"referenceID": 2, "context": "Given an interval number C=[3,6] and \u03b1=3, the result of generated BPA is shown as Table 3.", "startOffset": 27, "endOffset": 32}, {"referenceID": 5, "context": "Given an interval number C=[3,6] and \u03b1=3, the result of generated BPA is shown as Table 3.", "startOffset": 27, "endOffset": 32}, {"referenceID": 35, "context": "Inventory control is a common realistic problem[37, 42, 44].", "startOffset": 47, "endOffset": 59}, {"referenceID": 40, "context": "Inventory control is a common realistic problem[37, 42, 44].", "startOffset": 47, "endOffset": 59}, {"referenceID": 41, "context": "Inventory control is a common realistic problem[37, 42, 44].", "startOffset": 47, "endOffset": 59}], "year": 2017, "abstractText": "Markov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classi\u2217Corresponding author at: School of Electronics and Information, Northwestern Polytechnical University, Xi\u2019an, Shaanxi 710072, China. Tel: (86-29)88431267. E-mail address: jiangwen@nwpu.edu.cn, jiangwenpaper@hotmail.com Preprint submitted to Elsevier March 7, 2017 cal DTMC model can show the effectiveness and rationality of our proposed model.", "creator": "LaTeX with hyperref package"}}}