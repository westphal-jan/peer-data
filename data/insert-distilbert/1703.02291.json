{"id": "1703.02291", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Triple Generative Adversarial Nets", "abstract": "generative adversarial nets ( gans ) are good at generating realistic photographic images and have been extended for semi - supervised classification. however, under a two - player formulation, existing work shares competing roles of identifying fake samples and predicting labels via a single discriminator network, which can lead to undesirable incompatibility. we present triple generative adversarial net ( triple - gan ), a flexible game - theoretical framework appropriate for classification and parallel class - conditional generation in semi - supervised learning. triple - gan consists of three players - a generator, a discriminator and a classifier, where the generator and classifier characterize the conditional distributions positioned between images and labels, and the discriminator solely focuses on identifying fake image - label pairs. with designed utilities, the distributions characterized by the classifier and correlated generator both concentrate to the whole data distribution under nonparametric assumptions. we further propose unbiased regularization terms to make the same classifier and generator strongly coupled and some biased techniques to boost the performance of triple - gan in practice. our results on several datasets demonstrate the promise in semi - supervised learning, where triple - gan achieves comparable or superior performance than state - of - the - art classification results among dgms ; it is just also able to disentangle the associated classes and styles and safely transfer smoothly on the data level via interpolation on the latent space class - conditionally.", "histories": [["v1", "Tue, 7 Mar 2017 09:26:56 GMT  (6799kb,D)", "http://arxiv.org/abs/1703.02291v1", null], ["v2", "Mon, 3 Apr 2017 09:12:51 GMT  (6799kb,D)", "http://arxiv.org/abs/1703.02291v2", null], ["v3", "Fri, 2 Jun 2017 08:21:45 GMT  (6924kb,D)", "http://arxiv.org/abs/1703.02291v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["chongxuan li", "kun xu", "jun zhu", "bo zhang"], "accepted": true, "id": "1703.02291"}, "pdf": {"name": "1703.02291.pdf", "metadata": {"source": "META", "title": "Triple Generative Adversarial Nets", "authors": ["Chongxuan Li", "Kun Xu", "Jun Zhu", "Bo Zhang"], "emails": ["LICX14@MAILS.TSINGHUA.EDU.CN", "XU-K16@MAILS.TSINGHUA.EDU.CN", "DCSZJ@MAILS.TSINGHUA.EDU.CN", "DCSZB@MAILS.TSINGHUA.EDU.CN"], "sections": [{"heading": null, "text": "Generative adversarial nets (GANs) are good at generating realistic images and have been extended for semi-supervised classification. However, under a two-player formulation, existing work shares competing roles of identifying fake samples and predicting labels via a single discriminator network, which can lead to undesirable incompatibility. We present triple generative adversarial net (Triple-GAN), a flexible game-theoretical framework for classification and class-conditional generation in semisupervised learning. Triple-GAN consists of three players\u2014a generator, a discriminator and a classifier, where the generator and classifier characterize the conditional distributions between images and labels, and the discriminator solely focuses on identifying fake image-label pairs. With designed utilities, the distributions characterized by the classifier and generator both concentrate to the data distribution under nonparametric assumptions. We further propose unbiased regularization terms to make the classifier and generator strongly coupled and some biased techniques to boost the performance of Triple-GAN in practice. Our results on several datasets demonstrate the promise in semi-supervised learning, where Triple-GAN achieves comparable or superior performance than state-of-the-art classification results among DGMs; it is also able to disentangle the classes and styles and transfer smoothly on the data level via interpolation on the latent space class-conditionally."}, {"heading": "1. Introduction", "text": "Deep generative models (DGMs) can capture the underlying distributions of the input data and synthesize new samples. Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015). GAN is formulated as a two-player game, where the generator G takes a random noise z as input and produces a sampleG(z) in the data space while the discriminator D identifies whether a certain sample comes from the true data distribution p(x) or the generator. Both G and D are parameterized as deep neural networks and the training procedure is to solve a minimax problem:\nmin G max D U(D,G) = Ex\u223cp(x)[log(D(x)) ]\n+Ez\u223cpg(z)[log(1\u2212D(G(z)))],\nwhere pg(z) is a simple distribution (e.g., uniform or normal) and U(\u00b7) denotes the utilities. Given a generator and the defined distribution pg , the optimal discriminator is D(x) = p(x)pg(x)+p(x) under the assumption of infinite capacity, and the global equilibrium of this game achieves if and only if pg(x) = p(x) (Goodfellow et al., 2014), which is desired in terms of image generation.\nGANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al. (2016) augment the categorical discriminator with one more class, corresponding to the fake data generated by the generator. Salimans et al. (2016) further propose two alternative training objectives that work well for either semi-supervised classification or image generation, but not both. Specifically, the objective of feature matching works well in semi-supervised\nar X\niv :1\n70 3.\n02 29\n1v 1\n[ cs\n.L G\n] 7\nM ar\n2 01\nclassification but fails to generate indistinguishable samples (See Sec.4.2 for examples), while the other objective of minibatch discrimination is good at realistic image generation but cannot predict labels accurately.\nThis incompatibility essentially arises from their twoplayer formulation, where a single discriminator network has to play two competing roles\u2014identifying fake samples and predicting labels. Such a shared architecture can prevent the model from achieving a desirable equilibrium. Assume that both G and D converge finally and G concentrates to the true data distribution, namely p(x) = pg(x). Given a generated sample, as a discriminator, D should identify it as fake data with probability 12 ; while as a classifier, D should also predict it as the correct class confidently. Obviously, the two roles conflict, hence either G or D could not achieve its optimum. In addition, disentangling meaningful physical factors like object category from latent representations with limited supervision is of general interest (Yang et al., 2015). However, existing semisupervised GANs focus on the marginal distribution of data and hence G cannot generate data in a specific class.\nWe address these issues by presenting Triple-GAN, a flexible game-theoretical framework for both classification and class-conditional image generation in semi-supervised learning, where the data is characterized by a joint distribution p(x, y) of input x and label y. Based on the alternative factorizations p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), we build two separate conditional models\u2013a generator and a classifier, to characterize the conditional distributions p(x|y) and p(y|x), respectively. By mildly assuming that samples can be drawn from the marginal distributions p(x) and p(y), we can draw input-label pairs (x, y) from our generator and classifier. Then, we define an adversarial game by introducing a discriminator which has the single role of determining whether a sample (x, y) is from the model distribution or the data distribution. Consequently, we naturally arrive at a game with tripartite correlations of a generator, a classifier and a discriminator. In Triple-GAN, the shared discriminator enforces the mixture distributions defined by the classifier and generator to be similar to the true data distribution, and the equilibrium is unique under a proper regularizer with a supervised loss and a nonparametric assumption (See Sec. 3.2). Therefore, a good classifier will result in a good generator via teaching the common discriminator and vice versa. We further introduce some unbiased regularization terms and biased techniques to boost the performance of Triple-GAN. Especially, we propose a pseudo discriminative loss, which enforces the classifier to predict the generated images correctly, to improve the classifier via the generative model explicitly (See details in Sec. 3.3).\nOur results on the widely adopted MNIST (LeCun\net al., 1998), SVHN (Netzer et al., 2011) and CIFAR10 (Krizhevsky & Hinton, 2009) datasets demonstrate that Triple-GAN can make accurate predictions without sacrificing generation quality. We advance the state-of-theart semi-supervised classification results on MNIST and SVHN among DGMs. We further show that Triple-GAN is able to disentangle classes and styles and perform classconditional interpolation given partially labeled data."}, {"heading": "2. Related Work", "text": "Various approaches have been developed to learn DGMs, including MLE-based models such as Variational Autoencoders (VAEs) (Kingma & Welling, 2013; Rezende et al., 2014), Generative Moment Matching Networks (GMMNs) (Li et al., 2015; Dziugaite et al., 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al., 2014), which can be viewed as an instance of Noise Contrastive Estimation (NCE) (Gutmann & Hyva\u0308rinen, 2010). These criteria are systematically compared in (Theis et al., 2015).\nOne primal goal of DGMs is to generate realistic samples, for which GANs have proven effective. Specifically, LAPGAN (Denton et al., 2015) leverages a series of GANs to upscale the generated samples to high resolution images through the Laplacian pyramid framework (Burt & Adelson, 1983). DCGAN (Radford et al., 2015) adopts (fractionally) strided convolution networks and batch normalization (Ioffe & Szegedy, 2015) in GANs and generate realistic natural images. The architecture of DCGAN is widely adopted in various GANs, including ours.\nRecent work has introduced inference networks in GANs, which can infer latent variables given data and train the whole model jointly in an adversarial process. For instance, InfoGAN (Chen et al., 2016) learns interpretable latent codes from unlabeled data by regularizing the original GANs via variational mutual information maximization. In ALI (Dumoulin et al., 2016; Donahue et al., 2016), the inference network infers the latent variables from true data and the discriminator estimates the probability that a pair of latent variable and data comes from the inference network instead of the generator, which make the joint distributions defined by the generator and inference network to be same. We draw inspiration from the architecture of ALI but there exist two main differences in global equilibria and utilities: (1) Triple-GAN focuses on learning good generator and classifier given partially labeled data, while ALI aims to learn latent features from unlabeled data; (2) both the classifier (inference network) and generator attempt to fool the discriminator in Triple-GAN, while the discriminator would like to accept the samples from the inference network but reject samples from the generator in ALI.\nTo handle partially labeled data, the class-conditional VAE (Kingma et al., 2014) treats the missing labels\nas latent variables and infer them for unlabeled data. ADGM (Maal\u00f8e et al., 2016) introduces auxiliary variables to build a more expressive variational distribution and improve the predictive performance. The Ladder Network (Rasmus et al., 2015) employs lateral connections between a variation of denoising autoencoders and obtains excellent semi-supervised classification results. CatGAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function. Salimans et al. (2016) propose empirical techniques to stabilize the training of GANs and improve the performance on semi-supervised learning and image generation under incompatible learning criteria. Triple-GAN differs significantly from these methods, as stated in the introduction."}, {"heading": "3. Method", "text": "We consider learning deep generative models in the semisupervised setting,1 where we have a partially labeled dataset with x denoting input and y denoting the output label. The goal is to predict the labels y for unlabeled data as well as to generate new samples x. This is different from the unsupervised learning setting for pure generation, where the primary goal is to identify whether a sample x is generated from the true distribution p(x) of input or not; thus a two-player game with an input generator and a discriminator is sufficient to describe the process as in GANs. In our setting, as the label information y is incomplete (thus uncertain), our density model should characterize the uncertainty of both x and y, therefore a joint distribution p(x, y) of input-label pairs.\nA straightforward application of the two-player GAN is infeasible because of the missing values on y. Unlike the previous work on semi-supervised GANs (Springenberg, 2015; Salimans et al., 2016), which is restricted to the twoplayer framework and can lead to incompatible objectives, we build our game-theoretic objective based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interest for classification and class-conditional generation, respectively. To jointly estimate these conditional distributions, which are characterized by a class-conditional generator network and a classifier network, we define a single discriminator network which has the sole role of distinguishing whether a sample is from the true data distribution or the models. Hence, we naturally extend GANs to TripleGAN, a three-player game to characterize the process of semi-supervised classification and class-conditional generation, as detailed below.\n1Supervised learning is an extreme case, where the training set is fully labeled while the testing set is unlabeled."}, {"heading": "3.1. A Game with Three Players", "text": "Triple-GAN consists of three components: (1) a classifier C that (approximately) characterizes the conditional discriminative distribution pc(y|x) \u2248 p(y|x); (2) a classconditional generator G that (approximately) characterizes the conditional distribution in the other direction pg(x|y) \u2248 p(x|y); and (3) a discriminator D that distinguishes whether a pair of data (x, y) comes from the true distribution p(x, y). All the components are parameterized as neural networks. Our desired equilibrium is that the joint distributions defined by the classifier and generator will concentrate to the true data distributions. To this end, we design a game with compatible utilities for triple players as follows.\nWe make the mild assumption that the samples from both p(x) and p(y) can be easily obtained.2 In the game, after a sample x is drawn from p(x), the classifier C produces a pseudo label y given x following the conditional distribution pc(y|x). Hence, the pseudo input-label pair is a sample from the joint distribution pc(x, y) = p(x)pc(y|x). Similarly, a pseudo input-label pair can be sampled from the generator G by first drawing y \u223c p(y) and then drawing x|y \u223c pg(x|y); hence from the joint distribution pg(x, y) = p(y)pg(x|y). For pg(x|y), we assume that x is transformed by the latent style variables z given the label y, namely, x = G(y, z), z \u223c pg(z), where pg(z) is a simple distribution (e.g., uniform or standard normal). Then, the pseudo input-label pairs (x, y) generated by both C and G are sent to the single discriminator D for judgement. The discriminator D can also access the input-label pairs from the true data distribution as positive samples. The utilities can be formulated as a minimax game:\nmin C,G max D U(C,G,D) = E(x,y)\u223cp(x,y)[logD(x, y)]\n+(1\u2212 \u03b1)Ey\u223cp(y),z\u223cpg(z)[log(1\u2212D(G(y, z), y))] +\u03b1Ex\u223cp(x),y\u223cpc(y|x)[log(1\u2212D(x, y))], (1)\n2In semi-supervised learning, p(x) is the empirical distribution of inputs and p(y) is assumed same to the distribution of labels on labeled data, which is uniform in our experiment.\nwhere \u03b1 \u2208 (0, 1) is a constant that controls the relative importance of generation and classification. Note that pc(y|x) should be a deterministic mapping (or delta distribution) to allow the training signal from D back-propagated to C and we simply choose the label with the maximum probability instead of sampling one in our experiment.\nThe minimax game defined in Eqn. (1) achieves the equilibrium if and only if p(x, y) = (1\u2212\u03b1)pg(x, y)+\u03b1pc(x, y) (See details in Sec. 3.2). The equilibrium indicates that if one of C and G tends to the data distribution, the other will become better. However, unfortunately, it cannot guarantee that p(x, y) = pg(x, y) = pc(x, y) is the unique global optimum, which is not desirable. To address this problem, we add the standard supervised loss (i.e., cross-entropy loss) for the classifier C, RL = E(x,y)\u223cp(x,y)[\u2212 log pc(y|x)], which is equivalent to the KL-divergence between pc(x, y) and p(x, y). Consequently, we define the game as:\nmin C,G max D U\u0303(C,G,D) = E(x,y)\u223cp(x,y)[logD(x, y)]\n+(1\u2212 \u03b1)Ey\u223cp(y),z\u223cpg(z)[log(1\u2212D(G(y, z), y))] +\u03b1Ex\u223cp(x),y\u223cpc(y|x)[log(1\u2212D(x, y))] +RL. (2)\nIt will be proven that the game trained under U\u0303 has the unique global optimum for C and G. See Fig. 1 for an illustration of the whole model."}, {"heading": "3.2. Theoretical Analysis", "text": "We now provide a formal theoretical analysis of TripleGAN under nonparametric assumptions. For clarity of the main text, we defer the proof details to Appendix A.\nFirst, we can show that the optimalD balances between the true data distribution and the mixture distribution defined by C and G, as summarized in Lemma 3.1.\nLemma 3.1. For any fixed C and G, the optimal discriminator D of the game defined by the utility function U(C,G,D) is:\nD\u2217C,G(x, y) = p(x, y)\np(x, y) + p\u03b1(x, y) , (3)\nwhere p\u03b1(x, y) := (1 \u2212 \u03b1)pg(x, y) + \u03b1pc(x, y) is a valid distribution.\nGiven D\u2217C,G, we can omit the discriminator and reformulate the minimax game with value function U as:\nV (C,G) = max D U(C,G,D),\nwhose optimum is summarized as in Lemma 3.2.\nLemma 3.2. The global minimum value of V (C,G) is \u2212 log 4 and it is achieved if and only if p(x, y) = p\u03b1(x, y).\nWe can further show that C and G can at least capture the marginal distribution of data, especially for pg(x), even\nthere may exist multiple global equilibria, as summarized in Corollary A. Corollary 3.2.1. Given p(x, y) = p\u03b1(x, y), the marginal distributions are the same for any pairs of p, pc and pg .\nGiven the above result that p(x, y) = p\u03b1(x, y), C and G do not compete explicitly as in the two-player based formulation and it is easy to verify that p(x, y) = pc(x, y) = pg(x, y) is a global equilibrium point. However, it may not be unique and we should minimize an additional objective to ensure the uniqueness. In fact, this is true for the utility function U\u0303(C,G,D) in problem (2), as stated below. Theorem 3.3. The equilibrium of U\u0303(C,G,D) is achieved if and only if p(x, y) = pg(x, y) = pc(x, y) with D\u2217C,G(x, y) = 1 2 and the optimum value is \u2212 log 4.\nThe conclusion essentially motivates our design of TripleGAN, as we can ensure that both C and G will concentrate to the true data distribution if the model has been trained to achieve the optimum.\nWe can further show another nice property of U\u0303 , which allows us to regularize our model for stable and better convergence in practice without bias, as summarized below. Corollary 3.3.1. Any additional regularization on the distances between the marginal, conditional and joint distributions of any two players, will not change the global equilibrium of U\u0303 ."}, {"heading": "3.3. Unbiased Regularization", "text": "Despite the discriminative loss for the classifier, we add other unbiased regularization terms to boost the performance of our algorithm, following Corollary A.\nPseudo discriminative loss We treat the samples generated by the generator as labeled data and optimize the classifier on the pseudo data to make the generator and classifier strongly coupled. Intuitively, a good generator can provide meaningful labeled data beyond the training set as extra side information for the classifier, which will boost the predictive performance. We refer to this regularization as Pseudo discriminative loss and it is in the form:\nRP = Epg [\u2212 log pc(y|x)],\nand the right hand side can be rewritten as:\nDKL(pg(x, y)||pc(x, y))+Hpg (y|x)\u2212DKL(pg(x)||p(x)),\nwhere Hpg (y|x) denotes the conditional entropy over pg (See Appendix A for proof). Note that we do not train the generator to minimize this loss and the last two terms can be viewed as constants with respect to C. Therefore, minimizing RP is equivalent to minimizing the KL-divergence between pg(x, y) and pc(x, y); hence Corollary A applies to ensure that the global equilibrium is unchanged.\nAlgorithm 1 Minibatch stochastic gradient descent training of Triple-GAN in semi-supervised learning. for number of training iterations do \u2022 Sample a batch of labels yg \u223c p(y) and a batch of noise zg \u223c pg(z) of size mg , and generate pseudo data xg \u223c pg(x|y) = G(zg, yg). \u2022 Sample a batch of unlabeled data xc \u223c p(x) of size mc, and compute pseudo labels yc = arg maxy pc(y|x) for xc. \u2022 Sample a batch of labeled data (xl, yl) \u223c p(x, y) and a batch of unlabeled data xd \u223c p(x). \u2022 Get pseudo labels yd=arg maxy pc(y|x) for xd and concatenate (xl,yl) and (xd,yd) together as a batch of size md. \u2022 Update D by ascending along its stochastic gradient:\n\u2207\u03b8d  1 md ( \u2211\n(xl,yl)\nlogD(xl, yl) + \u2211\n(xd,yd)\nlogD(xd, yd))+ \u03b1\nmc \u2211 (xc,yc) log(1\u2212D(xc, yc))+ 1\u2212 \u03b1 mg \u2211 (xg,yg) log(1\u2212D(xg, yg))  . \u2022 Compute the unbiased estimators R\u0303L, R\u0303P and R\u0303U of the corresponding lossesRL,RP andRU respectively. \u2022 Update C by descending along its stochastic gradient:\n\u2207\u03b8c  \u03b1 mc \u2211 (xc,yc) log(1\u2212D(xc, yc)) + R\u0303L + \u03b1PR\u0303P + \u03b1UR\u0303U  . \u2022 Update G by descending along its stochastic gradient:\n\u2207\u03b8g 1\u2212 \u03b1 mg \u2211 (xg,yg) log(1\u2212D(xg, yg))  . end for\nRegularization on the generator It is natural to regularize the generator because it will in turn benefit the classifier. In our early experiment, we tried the maximum mean discrepancy loss (Gretton et al., 2012) between the marginal distributions pg(x) and p(x). However, we did not observe significant improvement and hence omited it for efficiency. Corollary A may explain this as Triple-GAN ensures that the players share same marginal distributions."}, {"heading": "3.4. Practical Techniques", "text": "In this subsection we introduce several practical techniques for Triple-GAN, which may lead to a biased solution theoretically but work well in practice.\nOne crucial problem of Triple-GAN in semi-supervised learning is that the discriminator may collapse to the delta distribution on the labeled data of small size, and reject other types of samples, which may come from the true data distribution indeed. Consequently, the generator would also concentrate to the empirical distribution and generate certain labeled data no matter what the latent variable is. To address this problem, we sample some unlabeled data and generate pseudo labels through the classifier and use these data as true labeled data for the training of the discriminator. Note that we just use pc(y|x) to approximate p(y|x) but do not train C to optimize this term. This approach introduces slight bias to Triple-GAN because the target distribution shifts a little towards pc(x, y). However, it remains that a good classifier will result in a good gener-\nator and this technique works well in practice.\nAs only C can leverage the unlabeled data directly, the performance of the whole system highly relies on the goodness of C. Consequently, it is necessary to regularize C heuristically as in recent advances (Springenberg, 2015; Laine & Aila, 2016) to make more accurate predictions. Note that the separated pathway of C and D in Triple-GAN provides extra freedom to regularize C biased or not without any negative effect on D intuitively. We consider two alternative losses on the unlabeled data as follows.\nConfidence and balance loss Springenberg (2015) minimizes the conditional entropy of pc(y|x) and the cross entropy between p(y) and pc(y), weighted by a hyperparameter \u03b1B, as follows:\nRU = Hpc(y|x) + \u03b1BEp [ \u2212 log pc(y) ] ,\nwhich encourages the classifier to make predictions confidently and be balanced on unlabeled data. The similar idea has been proven effective in (Li et al., 2016) with a large margin classifier.\nConsistency loss Laine & Aila (2016) penalize the network if it predicts the same unlabeled data inconsistently given different noise , e.g., dropout masks, as follows:\nRU \u2032 = Ex\u223cp(x)||pc(y|x, )\u2212 pc(y|x, \u2032)||2,\nwhere ||\u00b7||2 is the square of the l2-norm, which is chosen for its smoothness but can also be replaced with other choices.\nWe use the confidence and balance loss by default except on the CIFAR10 dataset because the consistency loss works better for complicated data. The whole training procedure of Triple-GAN is presented in Alg. 1."}, {"heading": "4. Experiments", "text": "We now present results on the widely adopted MNIST (LeCun et al., 1998), SVHN (Netzer et al., 2011), and CIFAR10 (Krizhevsky & Hinton, 2009) datasets. MNIST consists of 60,000 training samples and 10,000 testing samples of handwritten digits of size 28 \u00d7 28 pixels. SVHN consists of 73,257 training samples and 26,032 testing samples and each is a colored image of size 32\u00d732, containing a sequence of digits with various backgrounds. CIFAR10 consists of colored images distributed across 10 general classes\u2014airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. There are 50,000 training samples and 10,000 samples of size 32 \u00d7 32 in CIFAR10. We follow (Salimans et al., 2016) to rescale the pixels of SVHN and CIFAR10 data into (\u22121, 1). The labeled data is distributed equally across classes and the results are averaged over 10 times with different random splits of training data, following (Springenberg, 2015; Salimans et al., 2016).\nWe implement our method on Theano (Theano Development Team, 2016) and here we briefly summarize our experimental settings.3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E. We train G to maximize logD(G(y, z), y) instead of minimizing log(1 \u2212 D(G(y, z), y)) as suggested in (Goodfellow et al., 2014; Radford et al., 2015). We optimize all of our networks with Adam (Kingma & Ba, 2014) where the first order of momentum is 0.5 and others are default values. The model is trained for 1000 epochs with a global learning rate in {0.0003, 0.001}, which is annealed by a factor of 0.995 after 300 epochs. Each batch of data for C contains an equal number of labeled and unlabeled data for fast convergence. However, for the training of D, the unlabeled data (with labels generated by the classifier) is more than the labeled data in a batch to avoid collapsing and the ratio between them is nearly proportional to that of the whole dataset.\nFor the hyperparameters in the objectives, we simply set \u03b1 = 1/2, which means that D treats C and G equally. We refer (Li et al., 2016) to set \u03b1B = 1/300 and \u03b1U = 0.3 and fix them across all experiments if not mentioned. The pseudo discriminative loss is not applied until a threshold that the generator could generate meaningful data. The threshold is chosen from {200, 300} and \u03b1P is chosen from {0.1, 0.03}, depending on the data. We keep the moving\n3We will release our source code recently.\naverage of the parameters in the classifier for stable evaluation as in (Salimans et al., 2016). In our experiments, we find that these training techniques for the original twoplayer GANs are sufficient to stabilize the optimization of Triple-GAN and the convergence speed is comparable to previous work (Salimans et al., 2016)."}, {"heading": "4.1. Classification", "text": "We first evaluate our method with 20, 50, 100 and 200 labeled samples on MNIST for a systematical comparison with previous methods. We pretrain C solely with \u03b1B = 1 for 30 epochs to reduce the variance given no more than 100 labels. Table 1 summarizes the quantitative results. Given 100 labels, our method is competitive to the stateof-the-art among a large body of approaches. Under other settings, Triple-GAN consistently outperforms ImprovedGAN, as shown in the last two rows. Besides, we can see that Triple-GAN achieves more significant improvement as the number of labeled data decreases, suggesting the effectiveness of the pseudo discriminative loss. We also evaluate our Triple-GAN in supervised learning, where we omit all regularization terms and techniques except the pseudo discriminative loss. The result again confirms that the compatible utilities help Triple-GAN converge better than twoplayer GANs, as shown in the last column in Table 1.\nTable 2 presents the results on SVHN with 1,000 labels. For a fair comparison with previous GANs, we do not leverage the extra unlabeled data while some baselines (e.g., ADGM, SDGM and MMCVA) do. In this setting, Triple-GAN substantially outperforms the state-of-the-art methods (e.g., ALI and Improved-GAN).\nTable 3 compares the Triple-GAN with baselines on the CIFAR10 dataset with 4,000 labels. We perform ZCA whitening on the data for C following (Laine & Aila, 2016) but still generate and estimate the raw images using G and D. We found that the consistency loss used works better for Triple-GAN and we implement a simple version of the \u03a0 model in (Laine & Aila, 2016) with the learning rate annealing strategy mentioned in the general setting as the baseline, which achieves an error rate of 19.2%. The small margin between Triple-GAN and the baseline may indicate that the generator on CIFAR10 is far from optimal and cannot help the classifier as much as it does on MNIST and SVHN. Nevertheless, Triple-GAN is still competitive to the state-of-the-art DGMs."}, {"heading": "4.2. Generation", "text": "We demonstrate that Triple-GAN tends to achieve the desirable equilibrium by generating samples in various ways with the exact models used in the semi-supervised classification. The generative model and the number of labels are the same to the previous method (Salimans et al., 2016).\nTable 1. Error rates (%) on the (partially) labeled MNIST dataset.\nAlgorithm n = 20 n = 50 n = 100 n = 200 All M1+M2 (Kingma et al., 2014) 3.33 (\u00b10.14) 0.96 VAT (Miyato et al., 2015) 2.33 0.64 Ladder (Rasmus et al., 2015) 1.06 (\u00b10.37) 0.57 Conv-Ladder (Rasmus et al., 2015) 0.89 (\u00b10.50) ADGM (Maal\u00f8e et al., 2016) 0.96 (\u00b10.02) SDGM (Maal\u00f8e et al., 2016) 1.32 (\u00b10.07) MMCVA (Li et al., 2016) 1.24 (\u00b10.54) 0.31 CatGAN (Springenberg, 2015) 1.39 (\u00b10.28) 0.48 Improved-GAN (Salimans et al., 2016) 16.77 (\u00b14.52) 2.21 (\u00b11.36) 0.93 (\u00b10.07) 0.90 (\u00b10.04) Triple-GAN (ours) 5.40 (\u00b16.53) 1.59 (\u00b10.69) 0.92 (\u00b10.58) 0.66 (\u00b10.16) 0.32\nIn Fig. 6, we first compare the quality of images generated by Triple-GAN on SVHN and the Improved-GAN with feature matching (Salimans et al., 2016)4, which works well for semi-supervised classification. We can see that Triple-GAN outperforms the baseline by generating fewer meaningless samples and clearer digits. Furthermore, Triple-GAN avoids repeating to generate strange patterns as shown in the figure. The comparison on MNIST and CIFAR10 is presented in Appendix B. We also evaluate the samples on CIFAR10 quantitatively via inception score following (Salimans et al., 2016). The value of Triple-GAN\n4Though the Improved-GAN trained with minibatch discrimination (Salimans et al., 2016) can generate good samples, it fails to predict labels accurately.\n(a) Feature Matching (b) Triple-GAN\nFigure 2. (a) Samples generated from Improved-GAN trained with feature matching. The strange pattern labeled with the red rectangle appears four times in the generation. (b) Samples generated from Triple-GAN. We randomly sample equally distributed labels and unshared latent variables for fair comparison in vision.\nis 5.08 \u00b1 0.09 while that of the Improved-GAN trained without minibatch discrimination (Salimans et al., 2016) is 3.87\u00b1 0.03, which agrees with the visual comparison.\nThen, we show the ability of Triple-GAN to disentangle classes and styles in Fig. 3. It can be seen that Triple-GAN can generate realistic data in a specific class and the latent factors encode meaningful physical factors like: scale, intensity, orientation, color and so on. DCGAN (Radford et al., 2015) and ALI (Dumoulin et al., 2016) can generate data class-conditionally given full labels, while TripleGAN can do similar thing given incomplete label information. We illustrate images generated from four specific classes on CIFAR10 in Fig. 4 and see more in Appendix C. In most cases, Triple-GAN is able to generate meaningful images with correct semantics.\nFinally, we demonstrate the generalization capability of our Triple-GAN on class-conditional latent space interpolation as in Fig. 5. Triple-GAN can transit smoothly from one sample to another with totally different visual factors without losing label semantics, which proves that Triple-GANs can learn meaningful latent spaces class-conditionally instead of overfitting to the training data, especially labeled\ndata (See results on MNIST in Appendix D).\nOverall, these results confirm that Triple-GAN avoid the competition between C and G and can lead to a situation where both the generation and classification are good in semi-supervised learning."}, {"heading": "5. Conclusions", "text": "We present triple generative adversarial networks (TripleGAN), a unified game-theoretical framework with three players\u2014a generator, a discriminator and a classifier, to do semi-supervised learning with compatible utilities. The distributions characterized by the classifier and the classconditional generator concentrate to the data distribution under nonparametric assumptions. The classifier benefits from the generator by the enforce of the discriminator im-\nplicitly and the pseudo discriminative loss explicitly, and the generator generates images class-conditionally in semisupervised learning thanks to the classifier, which can infer the labels for unlabeled data. Our empirical results on several datasets demonstrate the promise\u2014Triple-GAN achieves comparable or superior classification performance than state-of-the-art DGMs, while retaining the capability to generate meaningful images when the label information is incomplete. Moreover, Triple-GAN can disentangle styles and classes and transfer smoothly on the data level via interpolation on the latent space."}, {"heading": "A. Detailed Theoretical Analysis", "text": "Lemma 3.1. For any fixed C and G, the optimal discriminator D of the game defined by the utility function U(C,G,D) is\nD\u2217C,G(x, y) = p(x, y)\np(x, y) + p\u03b1(x, y) , (4)\nwhere p\u03b1(x, y) := (1 \u2212 \u03b1)pg(x, y) + \u03b1pc(x, y) is a valid distribution .\nProof. Given the classifier and generator, the utility function can be rewritten as\nU(C,G,D) = \u222b\u222b p(x, y) logD(x, y)dydx\n+(1\u2212 \u03b1) \u222b\u222b p(y)pg(z) log(1\u2212D(G(z, y), y))dydz\n+\u03b1 \u222b\u222b p(x)pc(y|x) log(1\u2212D(x, y))dydx\n= \u222b\u222b p\u03b1(x, y) log(1\u2212D(x, y))dydx\n+ \u222b\u222b p(x, y) logD(x, y)dydx = f(D(x, y)).\nNote that the function f(D(x, y)) achieves the maximum at p(x,y)p(x,y)+p\u03b1(x,y) .\nLemma 3.2. The global minimum value of V (C,G) is \u2212 log 4 and it is achieved if and only if p(x, y) = p\u03b1(x, y).\nProof. GivenD\u2217C,G, we can reformulate the minimax game with value function U as:\nV (C,G)=max D U(C,G,D)\n= \u222b\u222b p(x, y) log\np(x, y)\np(x, y) + p\u03b1(x, y) dydx\n+ \u222b\u222b p\u03b1(x, y) log\np\u03b1(x, y)\np(x, y) + p\u03b1(x, y) dydx.\nFollowing the proof in GAN, the V (C,G) can be rewritten as\nV (C,G) = \u2212 log 4 + 2JSD(p(x, y)||p\u03b1(x, y)), (5)\nwhere JSD is the Jensen-Shannon divergence, which is always non-negative and the unique optimum is achieved if and only if p(x, y) = p\u03b1(x, y) = (1 \u2212 \u03b1)pg(x, y) + \u03b1pc(x, y).\nCorollary 3.2.1. Given p(x, y) = p\u03b1(x, y), the marginal distributions are the same for any pairs of p, pc and pg .\nProof. Remember that pg(x, y) = p(y)pg(x|y) and pc(x, y) = p(x)pc(y|x). Take integral with respect to x on both sides of p(x, y) = p\u03b1(x, y) to get\u222b\np(x, y)dx = (1\u2212 \u03b1) \u222b pg(x, y)dx+ \u03b1 \u222b pc(x, y)dx,\nwhich indicates that\np(y) = (1\u2212\u03b1)p(y) +\u03b1pc(y), i.e. pc(y) = p(y) = pg(y).\nSimilarly, it can be shown that pg(x) = p(x) = pc(x) by taking integral with respect to y.\nTheorem 3.3. The equilibrium of U\u0303(C,G,D) is achieved if and only if p(x, y) = pg(x, y) = pc(x, y) with D\u2217C,G(x, y) = 1 2 and the optimum value is \u2212 log 4.\nProof. According to the definition, U\u0303(C,G,D) = U(C,G,D) +RL, where\nRL = Ep[\u2212 log pc(y|x)],\nwhich can be rewritten as:\nDKL(p(x, y)||pc(x, y)) +Hp(y|x).\nNamely, minimizing RL is equivalent to minimizing DKL(p(x, y)||pc(x, y)), which is always non-negative and zero if and only if p(x, y) = pc(x, y). Besides, the previous lemmas can also be applied to U\u0303(C,G,D), which indicates that p(x, y) = p\u03b1(x, y) at the global equilibrium, concluding the proof.\nCorollary 3.3.1. Any additional regularization on the distances between the marginal, conditional and joint distributions of any two players, will not change the global equilibrium of U\u0303 .\nProof. This conclusion is straightforward derived by the global equilibrium point of V\u0303 .\nPseudo data loss We prove the equivalence of the two forms of pseudo data loss in the main text as follows:\nDKL(pg(x, y)||pc(x, y)) +Hpg (y|x)\u2212DKL(pg(x)||p(x))\n= \u222b\u222b pg(x, y) log pg(x, y)\npc(x, y) + pg(x, y) log\n1\npg(y|x) dxdy \u2212 \u222b pg(x) log pg(x)\np(x) dx\n= \u222b\u222b pg(x, y) log\npg(x, y)\npc(x, y)pg(y|x) dxdy \u2212 \u222b\u222b pg(x, y) log pg(x)\np(x) dxdy\n= \u222b\u222b pg(x, y) log\npg(x, y)p(x)\npc(x, y)pg(y|x)pg(x) dxdy\n=Epg [\u2212 log pc(y|x)].\nNote that the last equality holds as pc(x) = p(x)."}, {"heading": "B. Unconditional Generation", "text": "We compare the samples generated from Triple-GAN and Improved-GAN on the MNIST and CIFAR10 datasets as in Fig. 6, where Triple-GAN shares the same architecture of generator and number of labeled data with the baseline. It can be seen that Triple-GAN outperforms the GANs that are trained with the feature matching criterion on generating indistinguishable samples."}, {"heading": "C. Class-conditional Generation on CIFAR10", "text": "We show more class-conditional generation results on CIFAR10 in Fig. 7. Again, we can see that Triple-GAN can generate meaningful images in specific classes.\nD. Interpolation on the MNIST dataset We present the class-conditional interpolation on the MNIST dataset as in Fig. 8. We have the same conclusion as in main text that Triple-GAN is able to transfer smoothly on the data level with clear semantics."}, {"heading": "E. Detailed Architectures", "text": "We list the detailed architectures of Triple-GAN on MNIST, SVHN and CIFAR10 datasets in Table 4, Table 5\nand Table 6, respectively."}], "references": [{"title": "The Laplacian pyramid as a compact image code", "author": ["P. Burt", "E. Adelson"], "venue": "IEEE Transactions on communications,", "citeRegEx": "Burt and Adelson,? \\Q1983\\E", "shortCiteRegEx": "Burt and Adelson", "year": 1983}, {"title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["X. Chen", "Y. Duan", "R. Houthooft", "J. Schulman", "I. Sutskever", "P. Abbeel"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Deep generative image models using a Laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "R. Fergus"], "venue": "In NIPS,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Adversarial feature learning", "author": ["J. Donahue", "P. Kr\u00e4henb\u00fchl", "T. Darrell"], "venue": "arXiv preprint arXiv:1605.09782,", "citeRegEx": "Donahue et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Donahue et al\\.", "year": 2016}, {"title": "Adversarially learned inference", "author": ["V. Dumoulin", "I. Belghazi", "B. Poole", "A. Lamb", "M. Arjovsky", "O. Mastropietro", "A. Courville"], "venue": "arXiv preprint arXiv:1606.00704,", "citeRegEx": "Dumoulin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dumoulin et al\\.", "year": 2016}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani"], "venue": "arXiv preprint arXiv:1505.03906,", "citeRegEx": "Dziugaite et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dziugaite et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["M. Gutmann", "A. Hyv\u00e4rinen"], "venue": "In AISTATS,", "citeRegEx": "Gutmann and Hyv\u00e4rinen,? \\Q2010\\E", "shortCiteRegEx": "Gutmann and Hyv\u00e4rinen", "year": 2010}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy", "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling", "year": 2013}, {"title": "Semi-supervised learning with deep generative models", "author": ["D.P. Kingma", "S. Mohamed", "D.J. Rezende", "M. Welling"], "venue": "In NIPS,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Citeseer,", "citeRegEx": "Krizhevsky and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton", "year": 2009}, {"title": "Temporal ensembling for semisupervised learning", "author": ["S. Laine", "T. Aila"], "venue": "arXiv preprint arXiv:1610.02242,", "citeRegEx": "Laine and Aila,? \\Q2016\\E", "shortCiteRegEx": "Laine and Aila", "year": 2016}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Max-margin deep generative models for (semi-) supervised learning", "author": ["C. Li", "J. Zhu", "B. Zhang"], "venue": "arXiv preprint arXiv:1611.07119,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Generative moment matching networks", "author": ["Y. Li", "K. Swersky", "R.S. Zemel"], "venue": "In ICML,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Auxiliary deep generative models", "author": ["L. Maal\u00f8e", "C.K. S\u00f8nderby", "S.K. S\u00f8nderby", "O. Winther"], "venue": "arXiv preprint arXiv:1602.05473,", "citeRegEx": "Maal\u00f8e et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Maal\u00f8e et al\\.", "year": 2016}, {"title": "Distributional smoothing with virtual adversarial training", "author": ["T. Miyato", "Maeda", "S.-i", "M. Koyama", "K. Nakae", "S. Ishii"], "venue": "arXiv preprint arXiv:1507.00677,", "citeRegEx": "Miyato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Miyato et al\\.", "year": 2015}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Semi-supervised learning with generative adversarial networks", "author": ["A. Odena"], "venue": "arXiv preprint arXiv:1606.01583,", "citeRegEx": "Odena,? \\Q2016\\E", "shortCiteRegEx": "Odena", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Semi-supervised learning with ladder networks", "author": ["A. Rasmus", "M. Berglund", "M. Honkala", "H. Valpola", "T. Raiko"], "venue": "In NIPS,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "arXiv preprint arXiv:1401.4082,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Improved techniques for training GANs", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": "In NIPS,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Unsupervised and semi-supervised learning with categorical generative adversarial networks", "author": ["J.T. Springenberg"], "venue": "arXiv preprint arXiv:1511.06390,", "citeRegEx": "Springenberg,? \\Q2015\\E", "shortCiteRegEx": "Springenberg", "year": 2015}, {"title": "A note on the evaluation of generative models", "author": ["L. Theis", "Oord", "A. v. d", "M. Bethge"], "venue": "arXiv preprint arXiv:1511.01844,", "citeRegEx": "Theis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2015}, {"title": "Weaklysupervised disentangling with recurrent transformations for 3d view synthesis", "author": ["J. Yang", "S.E. Reed", "Yang", "M.-H", "H. Lee"], "venue": "In NIPS,", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 2, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 21, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 6, "context": "Given a generator and the defined distribution pg , the optimal discriminator is D(x) = p(x) pg(x)+p(x) under the assumption of infinite capacity, and the global equilibrium of this game achieves if and only if pg(x) = p(x) (Goodfellow et al., 2014), which is desired in terms of image generation.", "startOffset": 224, "endOffset": 249}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability.", "startOffset": 80, "endOffset": 101}, {"referenceID": 25, "context": "Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples.", "startOffset": 49, "endOffset": 69}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al.", "startOffset": 81, "endOffset": 459}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al. (2016) augment the categorical discriminator with one more class, corresponding to the fake data generated by the generator.", "startOffset": 81, "endOffset": 486}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al. (2016) augment the categorical discriminator with one more class, corresponding to the fake data generated by the generator. Salimans et al. (2016) further propose two alternative training objectives that work well for either semi-supervised classification or image generation, but not both.", "startOffset": 81, "endOffset": 627}, {"referenceID": 27, "context": "In addition, disentangling meaningful physical factors like object category from latent representations with limited supervision is of general interest (Yang et al., 2015).", "startOffset": 152, "endOffset": 171}, {"referenceID": 14, "context": "Our results on the widely adopted MNIST (LeCun et al., 1998), SVHN (Netzer et al.", "startOffset": 40, "endOffset": 60}, {"referenceID": 19, "context": ", 1998), SVHN (Netzer et al., 2011) and CIFAR10 (Krizhevsky & Hinton, 2009) datasets demonstrate that Triple-GAN can make accurate predictions without sacrificing generation quality.", "startOffset": 14, "endOffset": 35}, {"referenceID": 23, "context": "Various approaches have been developed to learn DGMs, including MLE-based models such as Variational Autoencoders (VAEs) (Kingma & Welling, 2013; Rezende et al., 2014), Generative Moment Matching Networks (GMMNs) (Li et al.", "startOffset": 121, "endOffset": 167}, {"referenceID": 16, "context": ", 2014), Generative Moment Matching Networks (GMMNs) (Li et al., 2015; Dziugaite et al., 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al.", "startOffset": 53, "endOffset": 94}, {"referenceID": 5, "context": ", 2014), Generative Moment Matching Networks (GMMNs) (Li et al., 2015; Dziugaite et al., 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al.", "startOffset": 53, "endOffset": 94}, {"referenceID": 6, "context": ", 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al., 2014), which can be viewed as an instance of Noise Contrastive Estimation (NCE) (Gutmann & Hyv\u00e4rinen, 2010).", "startOffset": 47, "endOffset": 72}, {"referenceID": 26, "context": "These criteria are systematically compared in (Theis et al., 2015).", "startOffset": 46, "endOffset": 66}, {"referenceID": 2, "context": "Specifically, LAPGAN (Denton et al., 2015) leverages a series of GANs to upscale the generated samples to high resolution images through the Laplacian pyramid framework (Burt & Adelson, 1983).", "startOffset": 21, "endOffset": 42}, {"referenceID": 21, "context": "DCGAN (Radford et al., 2015) adopts (fractionally) strided convolution networks and batch normalization (Ioffe & Szegedy, 2015) in GANs and generate realistic natural images.", "startOffset": 6, "endOffset": 28}, {"referenceID": 1, "context": "For instance, InfoGAN (Chen et al., 2016) learns interpretable latent codes from unlabeled data by regularizing the original GANs via variational mutual information maximization.", "startOffset": 22, "endOffset": 41}, {"referenceID": 4, "context": "In ALI (Dumoulin et al., 2016; Donahue et al., 2016), the inference network infers the latent variables from true data and the discriminator estimates the probability that a pair of latent variable and data comes from the inference network instead of the generator, which make the joint distributions defined by the generator and inference network to be same.", "startOffset": 7, "endOffset": 52}, {"referenceID": 3, "context": "In ALI (Dumoulin et al., 2016; Donahue et al., 2016), the inference network infers the latent variables from true data and the discriminator estimates the probability that a pair of latent variable and data comes from the inference network instead of the generator, which make the joint distributions defined by the generator and inference network to be same.", "startOffset": 7, "endOffset": 52}, {"referenceID": 11, "context": "To handle partially labeled data, the class-conditional VAE (Kingma et al., 2014) treats the missing labels", "startOffset": 60, "endOffset": 81}, {"referenceID": 17, "context": "ADGM (Maal\u00f8e et al., 2016) introduces auxiliary variables to build a more expressive variational distribution and improve the predictive performance.", "startOffset": 5, "endOffset": 26}, {"referenceID": 22, "context": "The Ladder Network (Rasmus et al., 2015) employs lateral connections between a variation of denoising autoencoders and obtains excellent semi-supervised classification results.", "startOffset": 19, "endOffset": 40}, {"referenceID": 25, "context": "CatGAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function.", "startOffset": 7, "endOffset": 27}, {"referenceID": 17, "context": "ADGM (Maal\u00f8e et al., 2016) introduces auxiliary variables to build a more expressive variational distribution and improve the predictive performance. The Ladder Network (Rasmus et al., 2015) employs lateral connections between a variation of denoising autoencoders and obtains excellent semi-supervised classification results. CatGAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function. Salimans et al. (2016) propose empirical techniques to stabilize the training of GANs and improve the performance on semi-supervised learning and image generation under incompatible learning criteria.", "startOffset": 6, "endOffset": 464}, {"referenceID": 25, "context": "Unlike the previous work on semi-supervised GANs (Springenberg, 2015; Salimans et al., 2016), which is restricted to the twoplayer framework and can lead to incompatible objectives, we build our game-theoretic objective based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interest for classification and class-conditional generation, respectively.", "startOffset": 49, "endOffset": 92}, {"referenceID": 24, "context": "Unlike the previous work on semi-supervised GANs (Springenberg, 2015; Salimans et al., 2016), which is restricted to the twoplayer framework and can lead to incompatible objectives, we build our game-theoretic objective based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interest for classification and class-conditional generation, respectively.", "startOffset": 49, "endOffset": 92}, {"referenceID": 25, "context": "Consequently, it is necessary to regularize C heuristically as in recent advances (Springenberg, 2015; Laine & Aila, 2016) to make more accurate predictions.", "startOffset": 82, "endOffset": 122}, {"referenceID": 25, "context": "Confidence and balance loss Springenberg (2015) minimizes the conditional entropy of pc(y|x) and the cross entropy between p(y) and pc(y), weighted by a hyperparameter \u03b1B, as follows:", "startOffset": 28, "endOffset": 48}, {"referenceID": 15, "context": "The similar idea has been proven effective in (Li et al., 2016) with a large margin classifier.", "startOffset": 46, "endOffset": 63}, {"referenceID": 14, "context": "We now present results on the widely adopted MNIST (LeCun et al., 1998), SVHN (Netzer et al.", "startOffset": 51, "endOffset": 71}, {"referenceID": 19, "context": ", 1998), SVHN (Netzer et al., 2011), and CIFAR10 (Krizhevsky & Hinton, 2009) datasets.", "startOffset": 14, "endOffset": 35}, {"referenceID": 24, "context": "We follow (Salimans et al., 2016) to rescale the pixels of SVHN and CIFAR10 data into (\u22121, 1).", "startOffset": 10, "endOffset": 33}, {"referenceID": 25, "context": "The labeled data is distributed equally across classes and the results are averaged over 10 times with different random splits of training data, following (Springenberg, 2015; Salimans et al., 2016).", "startOffset": 155, "endOffset": 198}, {"referenceID": 24, "context": "The labeled data is distributed equally across classes and the results are averaged over 10 times with different random splits of training data, following (Springenberg, 2015; Salimans et al., 2016).", "startOffset": 155, "endOffset": 198}, {"referenceID": 21, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 25, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 24, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 6, "context": "We train G to maximize logD(G(y, z), y) instead of minimizing log(1 \u2212 D(G(y, z), y)) as suggested in (Goodfellow et al., 2014; Radford et al., 2015).", "startOffset": 101, "endOffset": 148}, {"referenceID": 21, "context": "We train G to maximize logD(G(y, z), y) instead of minimizing log(1 \u2212 D(G(y, z), y)) as suggested in (Goodfellow et al., 2014; Radford et al., 2015).", "startOffset": 101, "endOffset": 148}, {"referenceID": 15, "context": "We refer (Li et al., 2016) to set \u03b1B = 1/300 and \u03b1U = 0.", "startOffset": 9, "endOffset": 26}, {"referenceID": 24, "context": "average of the parameters in the classifier for stable evaluation as in (Salimans et al., 2016).", "startOffset": 72, "endOffset": 95}, {"referenceID": 24, "context": "In our experiments, we find that these training techniques for the original twoplayer GANs are sufficient to stabilize the optimization of Triple-GAN and the convergence speed is comparable to previous work (Salimans et al., 2016).", "startOffset": 207, "endOffset": 230}, {"referenceID": 24, "context": "The generative model and the number of labels are the same to the previous method (Salimans et al., 2016).", "startOffset": 82, "endOffset": 105}, {"referenceID": 11, "context": "Algorithm n = 20 n = 50 n = 100 n = 200 All M1+M2 (Kingma et al., 2014) 3.", "startOffset": 50, "endOffset": 71}, {"referenceID": 18, "context": "96 VAT (Miyato et al., 2015) 2.", "startOffset": 7, "endOffset": 28}, {"referenceID": 22, "context": "64 Ladder (Rasmus et al., 2015) 1.", "startOffset": 10, "endOffset": 31}, {"referenceID": 22, "context": "57 Conv-Ladder (Rasmus et al., 2015) 0.", "startOffset": 15, "endOffset": 36}, {"referenceID": 17, "context": "50) ADGM (Maal\u00f8e et al., 2016) 0.", "startOffset": 9, "endOffset": 30}, {"referenceID": 17, "context": "02) SDGM (Maal\u00f8e et al., 2016) 1.", "startOffset": 9, "endOffset": 30}, {"referenceID": 15, "context": "07) MMCVA (Li et al., 2016) 1.", "startOffset": 10, "endOffset": 27}, {"referenceID": 25, "context": "31 CatGAN (Springenberg, 2015) 1.", "startOffset": 10, "endOffset": 30}, {"referenceID": 24, "context": "48 Improved-GAN (Salimans et al., 2016) 16.", "startOffset": 16, "endOffset": 39}, {"referenceID": 11, "context": "M1+M2 (Kingma et al., 2014) 36.", "startOffset": 6, "endOffset": 27}, {"referenceID": 18, "context": "10) VAT (Miyato et al., 2015) 24.", "startOffset": 8, "endOffset": 29}, {"referenceID": 17, "context": "63 ADGM (Maal\u00f8e et al., 2016) 22.", "startOffset": 8, "endOffset": 29}, {"referenceID": 17, "context": "86 \u2020 SDGM (Maal\u00f8e et al., 2016) 16.", "startOffset": 10, "endOffset": 31}, {"referenceID": 15, "context": "24)\u2020 MMCVA (Li et al., 2016) 4.", "startOffset": 11, "endOffset": 28}, {"referenceID": 24, "context": "18) \u2020 Improved-GAN (Salimans et al., 2016) 8.", "startOffset": 19, "endOffset": 42}, {"referenceID": 4, "context": "3) ALI (Dumoulin et al., 2016) 7.", "startOffset": 7, "endOffset": 30}, {"referenceID": 22, "context": "Ladder (Rasmus et al., 2015) 20.", "startOffset": 7, "endOffset": 28}, {"referenceID": 25, "context": "47) CatGAN (Springenberg, 2015) 19.", "startOffset": 11, "endOffset": 31}, {"referenceID": 24, "context": "58) Improved-GAN (Salimans et al., 2016) 18.", "startOffset": 17, "endOffset": 40}, {"referenceID": 4, "context": "32) ALI (Dumoulin et al., 2016) 18.", "startOffset": 8, "endOffset": 31}, {"referenceID": 24, "context": "6, we first compare the quality of images generated by Triple-GAN on SVHN and the Improved-GAN with feature matching (Salimans et al., 2016)4, which works well for semi-supervised classification.", "startOffset": 117, "endOffset": 140}, {"referenceID": 24, "context": "We also evaluate the samples on CIFAR10 quantitatively via inception score following (Salimans et al., 2016).", "startOffset": 85, "endOffset": 108}, {"referenceID": 24, "context": "Though the Improved-GAN trained with minibatch discrimination (Salimans et al., 2016) can generate good samples, it fails to predict labels accurately.", "startOffset": 62, "endOffset": 85}, {"referenceID": 24, "context": "09 while that of the Improved-GAN trained without minibatch discrimination (Salimans et al., 2016) is 3.", "startOffset": 75, "endOffset": 98}, {"referenceID": 21, "context": "DCGAN (Radford et al., 2015) and ALI (Dumoulin et al.", "startOffset": 6, "endOffset": 28}, {"referenceID": 4, "context": ", 2015) and ALI (Dumoulin et al., 2016) can generate data class-conditionally given full labels, while TripleGAN can do similar thing given incomplete label information.", "startOffset": 16, "endOffset": 39}], "year": 2017, "abstractText": "Generative adversarial nets (GANs) are good at generating realistic images and have been extended for semi-supervised classification. However, under a two-player formulation, existing work shares competing roles of identifying fake samples and predicting labels via a single discriminator network, which can lead to undesirable incompatibility. We present triple generative adversarial net (Triple-GAN), a flexible game-theoretical framework for classification and class-conditional generation in semisupervised learning. Triple-GAN consists of three players\u2014a generator, a discriminator and a classifier, where the generator and classifier characterize the conditional distributions between images and labels, and the discriminator solely focuses on identifying fake image-label pairs. With designed utilities, the distributions characterized by the classifier and generator both concentrate to the data distribution under nonparametric assumptions. We further propose unbiased regularization terms to make the classifier and generator strongly coupled and some biased techniques to boost the performance of Triple-GAN in practice. Our results on several datasets demonstrate the promise in semi-supervised learning, where Triple-GAN achieves comparable or superior performance than state-of-the-art classification results among DGMs; it is also able to disentangle the classes and styles and transfer smoothly on the data level via interpolation on the latent space class-conditionally.", "creator": "LaTeX with hyperref package"}}}