{"id": "1703.02622", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Online Convex Optimization with Unconstrained Domains and Losses", "abstract": "we propose an online convex optimization algorithm ( rescaledexp ) that achieves arbitrary optimal regret in the unconstrained setting } without prior knowledge consisting of any bounds on the loss functions. we repeatedly prove a lower relative bound showing an exponential separation between the partial regret of existing algorithms that both require a known bound on the loss functions and any algorithm that does not require merely such knowledge. overall rescaledexp matches this lower bound just asymptotically in the number of iterations. now rescaledexp is naturally hyperparameter - free data and we demonstrate empirically that it matches prior optimization algorithms that require hyperparameter optimization.", "histories": [["v1", "Tue, 7 Mar 2017 22:14:53 GMT  (392kb,D)", "http://arxiv.org/abs/1703.02622v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["ashok cutkosky", "kwabena a boahen"], "accepted": true, "id": "1703.02622"}, "pdf": {"name": "1703.02622.pdf", "metadata": {"source": "CRF", "title": "Online Convex Optimization with Unconstrained Domains and Losses", "authors": ["Ashok Cutkosky", "Kwabena Boahen"], "emails": ["ashokc@cs.stanford.edu", "boahen@stanford.edu"], "sections": [{"heading": "1 Online Convex Optimization", "text": "Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy, antagonistic or changing environments. The problem can be stated formally with the help of the following definitions:\nConvex Set: A setW is convex ifW is contained in some real vector space and tw+(1\u2212 t)w\u2032 \u2208W for all w,w\u2032 \u2208W and t \u2208 [0, 1].\nConvex Function: f :W \u2192 R is a convex function if f(tw + (1\u2212 t)w\u2032) \u2264 tf(w) + (1\u2212 t)f(w\u2032) for all w,w\u2032 \u2208W and t \u2208 [0, 1].\nAn OCO problem is a game of repeated rounds in which on round t a learner first chooses an element wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The regret of the learner with respect to some other u \u2208W is defined by\nRT (u) = T\u2211 t=1 `t(wt)\u2212 `t(u)\nThe objective is to design an algorithm that can achieve low regret with respect to any u, even in the face of adversarially chosen `t.\nMany practical problems can be formulated as OCO problems. For example, the stochastic optimization problems found widely throughout machine learning have exactly the same form, but with i.i.d. loss functions, a subset of the OCO problems. In this setting the goal is to identify a vector w? with low generalization error (E[`(w?)\u2212 `(u)]). We can solve this by running an OCO algorithm for T rounds and setting w? to be the average value of wt. By online-to-batch conversion results [3, 4], the generalization error is bounded by the expectation of the regret over the `t divided by T . Thus, OCO algorithms can be used to solve stochastic optimization problems while also performing well in non-i.i.d. settings.\n30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.\nar X\niv :1\n70 3.\n02 62\n2v 1\n[ cs\n.L G\n] 7\nM ar\n2 01\nThe regret of an OCO problem is upper-bounded by the regret on a corresponding Online Linear Optimization (OLO) problem, in which each `t is further constrained to be a linear function: `t(w) = gt \u00b7 wt for some gt. The reduction follows, with the help of one more definition:\nSubgradient: g \u2208W is a subgradient of f at w, denoted g \u2208 \u2202f(w), if and only if f(w)+ g \u00b7 (w\u2032\u2212 w) \u2264 f(w\u2032) for all w\u2032. Note that \u2202f(w) 6= \u2205 if f is convex.1\nTo reduce OCO to OLO, suppose gt \u2208 \u2202`t(wt), and consider replacing `t(w) with the linear approximation gt \u00b7 w. Then using the definition of subgradient,\nRT (u) = T\u2211 t=1 `t(wt)\u2212 `t(u) \u2264 T\u2211 t=1 gt(wt \u2212 u) = T\u2211 t=1 gtwt \u2212 gtu\nso that replacing `t(w) with gt \u00b7 w can only make the problem more difficult. All of the analysis in this paper therefore addresses OLO, accessing convex losses functions only through subgradients.\nThere are two major factors that influence the regret of OLO algorithms: the size of the space W and the size of the subgradients gt. When W is a bounded set (the \u201cconstrained\u201d case), then given B = maxw\u2208W \u2016w\u2016, there exist OLO algorithms [5, 6] that can achieve RT (u) \u2264 O ( BLmax \u221a T )\nwithout knowing Lmax = maxt \u2016gt\u2016. When W is unbounded (the \u201cunconstrained\u201d case), then given Lmax, there exist algorithms [7, 8, 9] that achieve RT (u) \u2264 O\u0303(\u2016u\u2016 log(\u2016u\u2016)Lmax \u221a T ) or\nRt(u) \u2264 O\u0303(\u2016u\u2016 \u221a log(\u2016u\u2016)Lmax \u221a T ), where O\u0303 hides factors that depend logarithmically on Lmax and T . These algorithms are known to be optimal (up to constants) for their respective regimes [7, 10]. All algorithms for the unconstrained setting to-date require knowledge of Lmax to achieve these optimal bounds.2 Thus a natural question is: can we achieve O(\u2016u\u2016 log(\u2016u\u2016)) regret in the unconstrained, unknown-Lmax setting? This problem has been posed as a COLT 2016 open problem [12], and is solved in this paper.\nA simple approach is to maintain an estimate of Lmax and double it whenever we see a new gt that violates the assumed bound (the so-called \u201cdoubling trick\u201d), thereby turning a known-Lmax algorithm into an unknown-Lmax algorithm. This strategy fails for previous known-Lmax algorithms because their analysis makes strong use of the assumption that each and every \u2016gt\u2016 is bounded by Lmax. The existence of even a small number of bound-violating gt can throw off the entire analysis.\nIn this paper, we prove that it is actually impossible to achieve regret\nO ( \u2016u\u2016 log(\u2016u\u2016)Lmax \u221a T + Lmax exp [( maxt \u2016gt\u2016 L(t) )1/2\u2212 ]) for any > 0 where Lmax\nand L(t) = maxt\u2032<t \u2016gt\u2032\u2016 are unknown in advance (Section 2). This immediately rules out the \u201cideal\u201d bound of O\u0303(\u2016u\u2016 \u221a log(\u2016u\u2016)Lmax \u221a T ) which is possible in the known-Lmax case. Secondly, we provide an algorithm, RESCALEDEXP, that matches our lower bound without prior knowledge of Lmax, leading to a naturally hyperparameter-free algorithm (Section 3). To our knowledge, this is the first algorithm to address the unknown-Lmax issue while maintaining O(\u2016u\u2016 log \u2016u\u2016) dependence on u. Finally, we present empirical results showing that RESCALEDEXP performs well in practice (Section 4).\n2 Lower Bound with Unknown Lmax\nThe following theorem rules out algorithms that achieve regret O(u log(u)Lmax \u221a T ) without prior knowledge of Lmax. In fact, any such algorithm must pay an up-front penalty that is exponential in T . This lower bound resolves a COLT 2016 open problem (Parameter-Free and Scale-Free Online Algorithms) [12] in the negative.\n1In full generality, a subgradient is an element of the dual space W \u2217. However, we will only consider cases where the subgradient is naturally identified with an element in the original space W (e.g. W is finite dimensional) so that the definition in terms of dot-products suffices.\n2There are algorithms that do not require Lmax, but achieve only regret O(\u2016u\u20162) [11]\nTheorem 1. For any constants c, k, > 0, there exists a T and an adversarial strategy picking gt \u2208 R in response to wt \u2208 R such that regret is:\nRT (u) = T\u2211 t=1 gtwt \u2212 gtu\n\u2265 (k + c\u2016u\u2016 log \u2016u\u2016)Lmax \u221a T log(Lmax + 1) + kLmax exp((2T ) 1/2\u2212 )\n\u2265 (k + c\u2016u\u2016 log \u2016u\u2016)Lmax \u221a T log(Lmax + 1) + kLmax exp [( max t \u2016gt\u2016 L(t) )1/2\u2212 ] for some u \u2208 R where Lmax = maxt\u2264T \u2016gt\u2016 and L(t) = maxt\u2032<t \u2016gt\u2032\u2016.\nProof. We prove the theorem by showing that for sufficiently large T , the adversary can \u201ccheckmate\u201d the learner by presenting it only with the subgradient gt = \u22121. If the learner fails to have wt increase quickly, then there is a u 1 against which the learner has high regret. On the other hand, if the learner ever does make wt higher than a particular threshold, the adversary immediately punishes the learner with a subgradient gt = 2T , again resulting in high regret.\nLet T be large enough such that both of the following hold: T 4 exp( T 1/2 4 log(2)c ) > k log(2) \u221a T + k exp((2T )1/2\u2212 ) (1)\nT 2 exp(\nT 1/2 4 log(2)c ) > 2kT exp((2T ) 1/2\u2212 ) + 2kT\n\u221a T log(2T + 1) (2)\nThe adversary plays the following strategy: for all t \u2264 T , so long as wt < 12 exp(T 1/2/4 log(2)c), give gt = \u22121. As soon as wt \u2265 12 exp(T 1/2/4 log(2)c), give gt = 2T and gt = 0 for all subsequent t. Let\u2019s analyze the regret at time T in these two cases.\nCase 1: wt < 12 exp(T 1/2/4 log(2)c) for all t:\nIn this case, let u = exp(T 1/2/4 log(2)c). Then Lmax = 1, maxt \u2016gt\u2016 L(t) = 1, and using (1) the learner\u2019s regret is at least\nRT (u) \u2265 Tu\u2212 T 1\n2 exp( T\n1/2\n4 log(2)c )\n= 12Tu = cu log(u) \u221a T log(2) + T4 exp( T 1/2 4 log(2)c ) > cu log(u)Lmax \u221a T log(Lmax + 1) + kLmax \u221a T log(Lmax + 1) + kLmax exp((2T ) 1/2\u2212 ) = (k + cu log u)Lmax \u221a T log(Lmax + 1) + kLmax exp [ (2T ) 1/2\u2212 ]\nCase 2: wt \u2265 12 exp(T 1/2/4 log(2)c) for some t:\nIn this case, Lmax = 2T and maxt \u2016gt\u2016 L(t) = 2T . For u = 0, using (2), the regret is at least\nRT (u) \u2265 T2 exp( T 1/2 4 log(2)c )\n\u2265 2kT exp((2T )1/2\u2212 ) + 2kT \u221a T log(2T + 1)\n= kLmax exp((2T ) 1/2\u2212 ) + kLmax \u221a T log(Lmax + 1) = (k + cu log u)Lmax \u221a T log(Lmax + 1) + kLmax exp [ (2T ) 1/2\u2212 ]\nThe exponential lower-bound arises because the learner has to move exponentially fast in order to deal with exponentially far away u, but then experiences exponential regret if the adversary provides a gradient of unprecedented magnitude in the opposite direction. However, if we play against an adversary that is constrained to give loss vectors \u2016gt\u2016 \u2264 Lmax for some Lmax that does not grow with time, or if the losses do not grow too quickly, then we can still achieve RT (u) = O(\u2016u\u2016 log(\u2016u\u2016)Lmax \u221a T ) asymptotically without knowing Lmax. In the following sections we describe an algorithm that accomplishes this."}, {"heading": "3 RESCALEDEXP", "text": "Our algorithm, RESCALEDEXP, adapts to the unknown Lmax using a guess-and-double strategy that is robust to a small number of bound-violating gts. We initialize a guess L for Lmax to \u2016g1\u2016. Then we run a novel known-Lmax algorithm that can achieve good regret in the unconstrained u setting. As soon as we see a gt with \u2016gt\u2016 > 2L, we update our guess to \u2016gt\u2016 and restart the known-Lmax algorithm. To prove that this scheme is effective, we show (Lemma 3) that our known-Lmax algorithm does not suffer too much regret when it sees a gt that violates its assumed bound.\nOur known-Lmax algorithm uses the Follow-the-Regularized-Leader (FTRL) framework. FTRL is an intuitive way to design OCO algorithms [13]: Given functions \u03c8t : W \u2192 R, at time T we play wT = argmin [ \u03c8T\u22121(w) + \u2211T\u22121 t=1 `t(w) ] . The functions \u03c8t are called regularizers. A large number of OCO algorithms (e.g. gradient descent) can be cleanly formulated as instances of this framework.\nOur known-Lmax algorithm is FTRL with regularizers \u03c8t(w) = \u03c8(w)/\u03b7t, where \u03c8(w) = (\u2016w\u2016+ 1) log(\u2016w\u2016+ 1)\u2212 \u2016w\u2016 and \u03b7t is a scale-factor that we adapt over time. Specifically, we set \u03b7\u22121t = k \u221a 2 \u221a Mt + \u2016g\u201621:t, where we use the compressed sum notations g1:T = \u2211T t=1 gt and \u2016g\u201621:T =\u2211T\nt=1 \u2016gt\u20162. Mt is defined recursively by M0 = 0 and Mt = max(Mt\u22121, \u2016g1:t\u2016/p \u2212 \u2016g\u201621:t), so that Mt \u2265Mt\u22121, and Mt + \u2016g\u201621:t \u2265 \u2016g1:t\u2016/p. k and p are constants: k = \u221a 2 and p = L\u22121max.\nRESCALEDEXP\u2019s strategy is to maintain an estimate Lt of Lmax at all time steps. Whenever it observes \u2016gt\u2016 \u2265 2Lt, it updates Lt+1 = \u2016gt\u2016. We call periods during which Lt is constant epochs. Every time it updates Lt, it restarts our known-Lmax algorithm with p = 1Lt , beginning a new epoch. Notice that since Lt at least doubles every epoch, there will be at most log2(Lmax/L1) + 1 total epochs. To address edge cases, we set wt = 0 until we suffer a non-constant loss function, and we set the initial value of Lt to be the first non-zero gt. Pseudo-code is given in Algorithm 1, and Theorem 2 states our regret bound. For simplicity, we re-index so that that g1 is the first non-zero gradient received. No regret is suffered when gt = 0 so this does not affect our analysis.\nAlgorithm 1 RESCALEDEXP Initialize: k \u2190 \u221a 2, M0 \u2190 0, w1 \u2190 0, t? \u2190 1 // t? is the start-time of the current epoch.\nfor t = 1 to T do Play wt, receive subgradient gt \u2208 \u2202`t(wt). if t = 1 then L1 \u2190 \u2016g1\u2016 p\u2190 1/L1\nend if Mt \u2190 max(Mt\u22121, \u2016gt?:t\u2016/p\u2212 \u2016g\u20162t?:t). \u03b7t \u2190 1\nk \u221a\n2(Mt+\u2016g\u20162t?:t) //Set wt+1 using FTRL update wt+1 \u2190 \u2212 gt?:t\u2016gt?:t\u2016 [exp(\u03b7t\u2016gt?:t\u2016)\u2212 1] // = argminw [ \u03c8(w) \u03b7t + gt?:tw ] if \u2016gt\u2016 > 2Lt then //Begin a new epoch: update L and restart FTRL Lt+1 \u2190 \u2016gt\u2016 p\u2190 1/Lt+1 t? \u2190 t+ 1 Mt \u2190 0 wt+1 \u2190 0 else Lt+1 \u2190 Lt\nend if end for\nTheorem 2. Let W be a separable real inner-product space with corresponding norm \u2016 \u00b7 \u2016 and suppose (with mild abuse of notation) every loss function `t :W \u2192 R has some subgradient gt \u2208W \u2217 at wt such that gt(w) = gt \u00b7w for some gt \u2208W . Let Mmax = maxtMt. Then if Lmax = maxt \u2016gt\u2016\nand L(t) = maxt\u2032<t \u2016gt\u2016, rescaledexp achieves regret: RT (u) \u2264 (2\u03c8(u) + 96) ( log2 ( Lmax L1 ) + 1 )\u221a Mmax + \u2016g\u201621:T\n+ 8Lmax ( log2 ( Lmax L1 ) + 1 ) min [ exp ( 8max t \u2016gt\u20162 L(t)2 ) , exp( \u221a T/2) ] = O ( Lmax log ( Lmax L1 )[ (\u2016u\u2016 log(\u2016u\u2016) + 2) \u221a T + exp ( 8max t \u2016gt\u20162 L(t)2\n)]) The conditions on W in Theorem 2 are fairly mild. In particular they are satisfied whenever W is finite-dimensional and in most kernel method settings [14]. In the kernel method setting, W is an RKHS of functions X \u2192 R and our losses take the form `t(w) = `t(\u3008w, kxt\u3009) where kxt is the representing element in W of some xt \u2208 X , so that gt = gtkxt where gt \u2208 \u2202`t(\u3008w, kxt\u3009).\nAlthough we nearly match our lower-bound exponential term of exp((2T )1/2\u2212 ), in order to have a practical algorithm we need to do much better. Fortunately, the maxt \u2016gt\u20162 L(t)2 term may be significantly smaller when the losses are not fully adversarial. For example, if the loss vectors gt satisfy \u2016gt\u2016 = t2, then the exponential term in our bound reduces to a manageable constant even though \u2016gt\u2016 is growing quickly without bound.\nTo prove Theorem 2, we bound the regret of RESCALEDEXP during each epoch. Recall that during an epoch, RESCALEDEXP is running FTRL with \u03c8t(w) = \u03c8(w)/\u03b7t. Therefore our first order of business is to analyze the regret of FTRL across one of these epochs, which we do in Lemma 3 (proved in appendix): Lemma 3. Set k = \u221a 2. Suppose \u2016gt\u2016 \u2264 L for t < T , 1/L \u2264 p \u2264 2/L, gT \u2264 Lmax and Lmax \u2265 L. Let Wmax = maxt\u2208[1,T ] \u2016wt\u2016. Then the regret of FTRL with regularizers \u03c8t(w) = \u03c8(w)/\u03b7t is:\nRT (u) \u2264 \u03c8(u)/\u03b7T + 96 \u221a MT + \u2016g\u201621:T + 2Lmax min [ Wmax, 4 exp ( 4 L2max L2 ) , exp( \u221a T/2) ]\n\u2264 (2\u03c8(u) + 96) \u221a\u221a\u221a\u221aT\u22121\u2211 t=1 L|gt|+ L2max + 8Lmax min [ exp ( 4L2max L2 ) , exp( \u221a T/2) ] \u2264 Lmax(2((\u2016u\u2016+ 1) log(\u2016u\u2016+ 1)\u2212 \u2016u\u2016) + 96) \u221a T + 8Lmax min [ e 4L2max L2 , e \u221a T/2\n] Lemma 3 requires us to know the value of L in order to set p. However, the crucial point is that it encompasses the case in which L is misspecified on the last loss vector. This allows us to show that RESCALEDEXP does not suffer too much by updating p on-the-fly.\nProof of Theorem 2. The theorem follows by applying Lemma 3 to each epoch in which Lt is constant.\nLet 1 = t1, t2, t3, \u00b7 \u00b7 \u00b7 , tn be the various increasing values of t? (as defined in Algorithm 1), and we define tn+1 = T + 1. Then define\nRa:b(u) = b\u22121\u2211 t=a gt(wt \u2212 u)\nso that RT (u) \u2264 \u2211n j=1Rtj :tj+1(u). We will bound Rtj :tj+1(u) for each j. Fix a particular j < n. Then Rtj :tj+1(u) is simply the regret of FTRL with k = \u221a 2, p = 1Ltj , \u03b7t = 1\nk \u221a\n2(Mt+\u2016g\u20162tj :t) and regularizers \u03c8(w)/\u03b7t. By definition of Lt, for t \u2208 [1, tj+1 \u2212 2] we have\n\u2016gt\u2016 \u2264 2Ltj . Further, if L = maxt\u2208[1,tj+1\u22122] \u2016gt\u2016 we have L \u2265 Ltj . Therefore, Ltj \u2264 L \u2264 2Ltj so that 1L \u2264 p \u2264 2 L . Further, we have \u2016gtj+1\u22121\u2016/Ltj \u2264 2maxt \u2016gt\u2016/L(t). Thus by Lemma 3 we\nhave Rtj :tj+1(u) \u2264 \u03c8(u)/\u03b7tj+1\u22121 + 96 \u221a Mtj+1\u22121 + \u2016g\u20162tj :tj+1\u22121\n+ 2Lmax min [ Wmax, 4 exp ( 4 \u2016gtj+1\u22121\u20162\nL2tj\n) , exp (\u221a tj+1 \u2212 tj\u221a\n2\n)]\n\u2264 \u03c8(u)/\u03b7tj+1\u22121 + 96 \u221a Mmax + \u2016g\u20162tj :tj+1\u22121 + 8Lmax min [ e 8maxt \u2016gt\u20162 L(t)2 , e \u221a T/2 ] \u2264 (2\u03c8(u) + 96) \u221a Mmax + \u2016g\u201621:T + 8Lmax min [ exp ( 8max\nt\n\u2016gt\u20162\nL(t)2\n) , exp( \u221a T/2) ] Summing across epochs, we have\nRT (u) = n\u2211 j=1 Rtj :tj+1(u)\n\u2264 n [ (2\u03c8(u) + 96) \u221a Mmax + \u2016g\u201621:T + 8Lmax min [ exp ( 8max\nt\n\u2016gt\u20162\nL(t)2\n) , exp (\u221a T/2 )]]\nObserve that n \u2264 log2(Lmax/L1) + 1 to prove the first line of the theorem. The big-Oh expression follows from the inequality: Mtj+1\u22121 \u2264 Ltj \u2211tj+1\u22121 t=tj \u2016gt\u2016 \u2264 Lmax \u2211T t=1 \u2016gt\u2016.\nOur specific choices for k and p are somewhat arbitrary. We suspect (although we do not prove) that the preceding theorems are true for larger values of k and any p inversely proportional to Lt, albeit with differing constants. In Section 4 we perform experiments using the values for k, p and Lt described in Algorithm 1. In keeping with the spirit of designing a hyperparameter-free algorithm, no attempt was made to empirically optimize these values at any time."}, {"heading": "4 Experiments", "text": ""}, {"heading": "4.1 Linear Classification", "text": "To validate our theoretical results in practice, we evaluated RESCALEDEXP on 8 classification datasets. The data for each task was pulled from the libsvm website [15], and can be found individually in a variety of sources [16, 17, 18, 19, 20, 21, 22]. We use linear classifiers with hinge-loss for each task and we compare RESCALEDEXP to five other optimization algorithms: ADAGRAD [5], SCALEINVARIANT [23], PISTOL [24], ADAM [25], and ADADELTA [26]. Each of these algorithms requires tuning of some hyperparameter for unconstrained problems with unknown Lmax (usually a scale-factor on a learning rate). In contrast, our RESCALEDEXP requires no such tuning.\nWe evaluate each algorithm with the average loss after one pass through the data, computing a prediction, an error, and an update to model parameters for each example in the dataset. Note that this is not the same as a cross-validated error, but is closer to the notion of regret addressed in our theorems. We plot this average loss versus hyperparameter setting for each dataset in Figures 1 and 2. These data bear out the effectiveness of RESCALEDEXP: while it is not unilaterally the highest performer on all datasets, it shows remarkable robustness across datasets with zero manual tuning."}, {"heading": "4.2 Convolutional Neural Networks", "text": "We also evaluated RESCALEDEXP on two convolutional neural network models. These models have demonstrated remarkable success in computer vision tasks and are becoming increasingly more popular in a variety of areas, but can require significant hyperparameter tuning to train. We consider the MNIST [18] and CIFAR-10 [27] image classification tasks.\nOur MNIST architecture consisted of two consecutive 5\u00d75 convolution and 2\u00d72 max-pooling layers followed by a 512-neuron fully-connected layer. Our CIFAR-10 architecture was two consecutive 5\u00d7 5 convolution and 3\u00d7 3 max-pooling layers followed by a 384-neuron fully-connected layer and a 192-neuron fully-connected layer.\nThese models are highly non-convex, so that none of our theoretical analysis applies. Our use of RESCALEDEXP is motivated by the fact that in practice convex methods are used to train these models. We found that RESCALEDEXP can match the performance of other popular algorithms (see Figure 3).\nIn order to achieve this performance, we made a slight modification to RESCALEDEXP: when we update Lt, instead of resetting wt to zero, we re-center the algorithm about the previous prediction point. We provide no theoretical justification for this modification, but only note that it makes intuitive sense in stochastic optimization problems, where one can reasonably expect that the previous prediction vector is closer to the optimal value than zero."}, {"heading": "5 Conclusions", "text": "We have presented RESCALEDEXP, an Online Convex Optimization algorithm that achieves regret O\u0303(\u2016u\u2016 log(\u2016u\u2016)Lmax \u221a T + exp(8maxt \u2016gt\u20162/L(t)2)) where Lmax = maxt \u2016gt\u2016 is unknown in advance. Since RESCALEDEXP does not use any prior-knowledge about the losses or comparison vector u, it is hyperparameter free and so does not require any tuning of learning rates. We also prove a lower-bound showing that any algorithm that addresses the unknown-Lmax scenario must suffer an exponential penalty in the regret. We compare RESCALEDEXP to prior optimization algorithms empirically and show that it matches their performance.\nWhile our lower-bound matches our regret bound for RESCALEDEXP in terms of T , clearly there is much work to be done. For example, when RESCALEDEXP is run on the adversarial loss sequence presented in Theorem 1, its regret matches the lower-bound, suggesting that the optimality gap could be improved with superior analysis. We also hope that our lower-bound inspires work in algorithms that adapt to non-adversarial properties of the losses to avoid the exponential penalty."}, {"heading": "A Follow-the-Regularized-Leader (FTRL) Regret", "text": "Recall that the FTRL algorithm uses the strategy wt+1 = argmin\u03c8t(w) + \u2211t t\u2032=1 `t\u2032(w), where the functions \u03c8t are called regularizers. Theorem 4. FTRL with regularizers \u03c8t and \u03c80(w1) = 0 obtains regret:\nRt(u) \u2264 \u03c8T (u) + T\u2211 t=1 \u03c8t\u22121(wt+1)\u2212 \u03c8t(wt+1) + `t(wt)\u2212 `t(wt+1) (3)\nFurther, if the losses are linear `t(w) = gt \u00b7 w and \u03c8t(w) = 1\u03b7t\u03c8(w) for some values \u03b7t and fixed function \u03c8, then the regret is\nRt(u) \u2264 1\n\u03b7T \u03c8(u) + T\u2211 t=1 ( 1 \u03b7t\u22121 \u2212 1 \u03b7t ) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1) (4)\nProof. The first part follows from some algebraic manipulations: T\u2211 t=1 `t(u) + \u03c8T (u) \u2265 \u03c8T (wT+1) + T\u2211 t=1 `t(wT+1)\n\u2212 T\u2211 t=1 `t(u) \u2264 \u03c8T (u)\u2212 \u03c8T (wT+1)\u2212 T\u2211 t=1 `t(wT+1)\nRT (u) = T\u2211 t=1 `t(wt)\u2212 T\u2211 t=1 `t(u)\n\u2264 \u03c8T (u)\u2212 \u03c8T (wT+1) + T\u2211 t=1 `t(wt)\u2212 `t(wT+1)\n= \u03c8T (u)\u2212 \u03c8T (wT+1) + `T (wT )\u2212 `T (wT+1) +RT\u22121(wT+1) \u2264 \u03c8T (u)\u2212 \u03c8T (wT+1) + `T (wT )\u2212 `T (wT+1)+\n+ T\u22121\u2211 t=1 \u03c8t(wt+2)\u2212 \u03c8t(wt+1) + `t(wt)\u2212 `t(wt+1)\n= \u03c8T (u) + `1(w1)\u2212 `1(w2)\u2212 \u03c81(w2)\n+ T\u2211 t=2 \u03c8t\u22121(wt+1)\u2212 \u03c8t(wt+1) + `t(wt)\u2212 `t(wt+1)\n= \u03c8T (u) + T\u2211 t=1 \u03c8t\u22121(wt+1)\u2212 \u03c8t(wt+1) + `t(wt)\u2212 `t(wt+1)\nwhere we\u2019re assuming \u03c80(w1) = 0 in the last step.\nNow let\u2019s specialize to the case of linear losses `t(w) = gt \u00b7 w and regularizers of the form \u03c8t(w) = 1\u03b7t\u03c8(w) for some fixed regularizer \u03c8 and varying scalings \u03b7t. Plugging this into the previous bound gives:\nRt(u) \u2264 1\n\u03b7T \u03c8(u) + T\u2211 t=1 ( 1 \u03b7t\u22121 \u2212 1 \u03b7t ) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1)\nWhile this formulation of the regret of FTRL is sufficient for our needs, our analysis is not tight. We refer the reader to [28] for a stronger FTRL bound that can improve constants in some analyses."}, {"heading": "B Proof of Lemma 3", "text": "We start off by computing the FTRL updates with regularizers \u03c8(w)/\u03b7t:\n\u2207\u03c8(w) = log(\u2016w\u2016+ 1) w\u2016w\u2016\nso that\nwT+1 = argmin 1\n\u03b7T \u03c8(w) + T\u2211 t=1 gt \u00b7 w\n= \u2212 g1:t\u2016g1:t\u2016 (exp(\u03b7T \u2016g1:T \u2016)\u2212 1)\nOur goal will be to show that the terms (\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1)+ gt \u00b7 (wt\u2212wt+1) in the sum in (4) are negative.\nIn particular, note that sequence of \u03b7t is non-increasing so that (\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) \u2264 0 for all t. Thus our\nstrategy will be to bound gt \u00b7 (wt \u2212 wt+1)."}, {"heading": "B.1 Reduction to one dimension", "text": "In order to bound (\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1), we first show that it suffices to consider the case\nwhen gt and g1:t\u22121 are co-linear.\nTheorem 5. Let W be a separable inner-product space and suppose (with mild abuse of notation) every loss function `t :W \u2192 R has some subgradient gt \u2208W \u2217 such that gtw = \u3008gt, w\u3009 for some gt \u2208W . Suppose we run an FTRL algorithm with regularizers 1\n\u03b7t \u03c8(\u2016w\u2016) on loss functions `t such that wt+1 = g1:t\u2016g1:t\u2016f(\u03b7t\u2016g1:t\u2016)\nfor some function f for all t where \u03b7t = c\u221a Mt+\u2016g\u201621:t for some constant c. Then for any gt with \u2016gt\u2016 = L, both (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8(\u2016wt+1\u2016) + gt(wt \u2212 wt+1) and gt(wt \u2212 wt+1) are maximized when gt is a scalar multiple of g1:t\u22121.\nProof. The proof is an application of Lagrange multipliers. Our Lagrangian for (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8(\u2016wt+1\u2016) + gt(wt \u2212 wt+1) is\nL = (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8(\u2016wt+1\u2016) + gt(wt \u2212 wt+1) + \u03bb\u2016gt\u20162/2\n= (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8(f(\u03b7t\u2016g1:t\u2016)) + gt ( wt \u2212\ng1:t \u2016g1:t\u2016\nf(\u03b7t\u2016g1:t\u2016) ) + \u03bb \u2016gt\u20162\n2\nFix a countable orthonormal basis of W . For a vector v \u2208W we let vi be the projection of v along the ith basis vector of our countable orthonormal basis. We denote the action of\u2207L on the ith basis vector by\u2207Li.\nThen we have\n\u2207Li = \u03bbgt,i + wt,i \u2212 wt+1,i \u2212 gt,i \u2016g1:t\u2016 f(\u03b7t\u2016g1:t\u2016)\n+ \u2211 j gt,j(g1:t)j \u2016g1:t\u20163 (g1:t)if(\u03b7t\u2016g1:t\u2016) \u2212 \u2211 j (g1:t)jgt,j \u2016g1:t\u2016 f \u2032(\u03b7t\u2016g1:t\u2016)  (g1:t)i\u03b7t \u2016g1:t\u2016 \u2212 \u2016g1:t\u2016c ( \u2202Mt \u2202gt,i + 2gt,i ) 2(Mt + \u2016g\u201621:t)3/2\n + (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8 \u2032(f(\u03b7t\u2016g1:t\u2016))f \u2032(\u03b7t\u2016g1:t\u2016)  (g1:t)i\u03b7t \u2016g1:t\u2016 \u2212 \u2016g1:t\u2016c ( \u2202Mt \u2202gt,i + 2gt,i ) 2(Mt + \u2016g\u201621:t)3/2\n \u2212 \u03c8(f(\u03b7t\u2016g1:t\u2016)) \u2202Mt \u2202gt,i + 2gt,i\n2c \u221a Mt + \u2016g\u201621:t\n= \u03bbgt,i + wt,i \u2212 wt+1,i +Agt,i +B(g1:t\u22121)i + C \u2202Mt \u2202gt,i\nwhere A, B and C do not depend on i. Since wt,i and wt+1,i are scalar multiples of g1:t\u22121 and g1:t respectively, we can reassign the variables A and B to write\n\u2207Li = Agt,i +B(g1:t\u22121)i + C \u2202Mt \u2202gt,i\nNow we compute\n\u2202Mt \u2202gt,i = \u2202max(Mt\u22121, \u2016g1:t\u2016/p\u2212 \u2016g\u201621:t) \u2202gt,i\n= { 0 :Mt =Mt\u22121 (g1:t)i p\u2016g1:t\u2016\n\u2212 2gt,i :Mt 6=Mt\u22121 Thus after again reassigning the variables A and B we have\n\u2207Li = Agt,i +B(g1:t\u22121)i\nTherefore we can only have\u2207L = 0 if gt is a scalar multiple of g1:t\u22121 as desired.\nFor gt(wt \u2212 wt+1), we apply exactly the same argument. The Lagrangian is L = gt(wt \u2212 wt+1) + \u03bb\u2016gt\u20162/2\n= gt ( wt \u2212\ng1:t \u2016g1:t\u2016\nf(\u03b7t\u2016g1:t\u2016) ) + \u03bb \u2016gt\u20162\n2\nand differentiating we have\n\u2207Li = \u03bbgt,i + wt,i \u2212 wt+1,i \u2212 gt,i \u2016g1:t\u2016 f(\u03b7t\u2016g1:t\u2016)\n+ \u2211 j gt,j(g1:t)j \u2016g1:t\u20163 (g1:t)if(\u03b7t\u2016g1:t\u2016) \u2212 \u2211 j (g1:t)jgt,j \u2016g1:t\u2016 f \u2032(\u03b7t\u2016g1:t\u2016)  (g1:t)i\u03b7t \u2016g1:t\u2016 \u2212 \u2016g1:t\u2016c ( \u2202Mt \u2202gt,i + 2gt,i ) 2(Mt + \u2016g\u201621:t)3/2\n = \u03bbgt,i + wt,i \u2212 wt+1,i +Agt,i +B(g1:t\u22121)i + C\n\u2202Mt \u2202gt,i\n= Agt,i +B(g1:t\u22121)i\nso that again we are done.\nWe make the following intuitive definition: Definition 6. For any vector v \u2208W , define sign(v) = v\u2016v\u2016 .\nIn the next section, we prove bounds on the quantity (\u03b7\u22121t\u22121 \u2212 \u03b7 \u22121 t )\u03c8(\u2016wt+1\u2016) + gt(wt \u2212 wt+1). By Theorem 5 this quantity is maximized when sign(gt) = \u00b1sign(g1:t\u22121) and so we consider only this case."}, {"heading": "B.2 One dimensional FTRL", "text": "In this section we analyze the regret of our FTRL algorithm with the end-goal of proving Lemma 3. We make heavy use of Theorem 5 to allow us to consider only the case sign(gt) = \u00b1sign(g1:t\u22121). In this setting we may identify the 1-dimensional space spanned by gt and g1:t\u22121 with R. Thus whenever we are operating under the assumption sign(gt) = sign(g1:t\u22121) we will use | \u00b7 | in place of \u2016 \u00b7 \u2016 and occasionally assume g1:t\u22121 > 0 as this holds WLOG. We feel that this notation and assumption aids intuition in visualizing the following results. Lemma 7. Suppose sign(gt) = sign(g1:t\u22121). Then\n|\u03b7t\u22121\u2016g1:t\u22121\u2016 \u2212 \u03b7t\u2016g1:t\u2016| \u2264 \u03b7t\u2016gt\u2016 (5) Suppose instead that sign(gt) = \u2212sign(g1:t\u22121) and also \u2016gt\u2016 \u2264 L. Then we still have:\n|\u03b7t\u22121\u2016g1:t\u22121\u2016 \u2212 \u03b7t\u2016g1:t\u2016| \u2264 ( 1 + pL\n2\n) \u03b7t\u2016gt\u2016 (6)\nProof. First, suppose sign(gt) = sign(g1:t\u22121). Then sign(g1:t) = sign(g1:t\u22121). WLOG, assume g1:t\u22121 > 0. Notice that \u03b7tg1:t is an increasing function of gt for gt > 0 because \u03b7tg1:t is proportional to either g1:t or \u221a g1:t depending on whether Mt =Mt\u22121 or not. Then since \u03b7t < \u03b7t\u22121 we have |\u03b7t\u22121g1:t\u22121 \u2212 \u03b7tg1:t| = \u03b7tg1:t \u2212 \u03b7t\u22121g1:t\u22121\n\u2264 \u03b7tg1:t \u2212 \u03b7tg1:t\u22121 = \u03b7t|gt|\nso that (5) holds.\nNow suppose sign(gt) = \u2212sign(g1:t\u22121) and \u2016gt\u2016 \u2264 L. We consider two cases.\nCase 1: \u03b7t|g1:t| \u2265 \u03b7t\u22121|g1:t\u22121|:\nSince \u03b7t\u22121 \u2265 \u03b7t, we have \u03b7t|g1:t| \u2265 \u03b7t\u22121|g1:t\u22121| \u03b7t|g1:t| \u2265 \u03b7t|g1:t\u22121| |g1:t| \u2265 |g1:t\u22121| |gt| \u2265 |g1:t|\nwhere the last line follows since sign(g1:t\u22121) = \u2212sign(gt). Therefore: |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|| \u2264 \u03b7t|g1:t| \u2264 \u03b7t|gt|\nso that we are done.\nCase 2: \u03b7t|g1:t| \u2264 \u03b7t\u22121|g1:t\u22121|:\nWhen gt < \u2212g1:t\u22121 and \u03b7t|g1:t| \u2264 \u03b7t\u22121|g1:t\u22121|, |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|| is a decreasing function of |gt| because \u03b7t|gt:1| is an increasing function of |gt| for gt < \u2212g1:t\u22121. Therefore it suffices to consider the case gt \u2265 \u2212g1:t\u22121, so that sign(g1:t) = sign(g1:t\u22121) and |g1:t| \u2264 |g1:t\u22121|:\nSince |g1:t| \u2264 |g1:t\u22121|, we have Mt =Mt\u22121 so that we can write: \u03b7t\u22121g1:t\u22121 \u2212 \u03b7tg1:t = \u2212gt\u03b7t + g1:t\u22121(\u03b7t\u22121 \u2212 \u03b7t)\n= |gt|\u03b7t + g1:t\u22121  1 k \u221a 2 \u221a Mt\u22121 + \u2016g\u201621:t\u22121 \u2212 1 k \u221a 2 \u221a Mt + \u2016g\u201621:t\u22121 + g2t  = |gt|\u03b7t + g1:t\u22121\nk \u221a 2  1\u221a Mt\u22121 + \u2016g\u201621:t\u22121 \u2212 1\u221a Mt\u22121 + \u2016g\u201621:t\u22121 + g2t  \u2264 |gt|\u03b7t + g1:t\u22121\nk \u221a 2 \u221a Mt + \u2016g\u201621:t\u22121 + g2t  \u221a Mt\u22121 + \u2016g\u201621:t\u22121 + g2t\u221a Mt\u22121 + \u2016g\u201621:t\u22121 \u2212 1  \u2264 |gt|\u03b7t + g1:t\u22121\u03b7t ( 1 +\ng2t 2(Mt\u22121 + \u2016g\u201621:t\u22121)\n\u2212 1 )\n\u2264 |gt|\u03b7t + \u03b7t g1:t\u22121g\n2 t\n2(Mt\u22121 + \u2016g\u201621:t\u22121)\n\u2264 |gt|\u03b7t(1 + pL\n2 ) we have used the identity \u221a X + g2t \u2264 \u221a X + g2t 2 \u221a X\nbetween lines 4 and 5, and the last line follows because |gt| \u2264 L and Mt\u22121 + \u2016g\u201621:t\u22121 \u2265 |g1:t\u22121|/p.\nLemma 8. If\n\u2016wT \u2016 \u2265 exp (\u221a pB\nk \u221a 2\n) \u2212 1\nthen \u2016g1:T\u22121\u2016 \u2265 B\nProof. First note that by definition of MT\u22121 and \u03b7T\u22121, \u03b7T\u22121\u2016g1:T\u22121\u2016 \u2264 \u221a p\u2016g1:T\u22121\u2016 k \u221a 2\n. The proof now follows from some algebra:\nexp\n(\u221a pB\nk \u221a 2\n) \u2264 \u2016wT \u2016+ 1\n= exp(\u03b7T\u22121\u2016g1:T\u22121\u2016)\n\u2264 exp (\u221a p\u2016g1:T\u22121\u2016 k \u221a 2 )\nTaking squares of logs and rearranging now gives the desired inequality.\nWe have the following immediate corollary:\nCorollary 9. Suppose sign(gt) = \u00b1sign(g1:t\u22121), \u2016gt\u2016 \u2264 L, and \u2016wt\u2016 \u2265 exp (\u221a pL\nk \u221a 2\n) \u2212 1\nThen sign(g1:t) = sign(g1:t\u22121).\nNow we begin analysis of the sum term in (4).\nLemma 10. Suppose sign(g1:t) = sign(g1:t\u22121) and |gt| \u2264 L. Then |wt \u2212 wt+1| \u2264 |gt|\u03b7t(|wt+1|+ 1) ( 1 + pL\n2\n) exp [ gt\u03b7t ( 1 + pL\n2 )] Proof. Since sign(g1:t) = sign(g1:t\u22121), we have:\n|wt \u2212 wt+1| = |sign(g1:t\u22121) [exp (\u03b7t\u22121|g1:t\u22121|)\u2212 1]\u2212 [sign(g1:t) exp (\u03b7t|g1:t|)\u2212 1]| = |exp (\u03b7t\u22121|g1:t\u22121|)\u2212 exp (\u03b7t|g1:t|)| = (|wt+1|+ 1) |exp (\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|)\u2212 1|\nwhere the last line uses the definition of wt+1 to observe that |wt+1|+ 1 = exp(\u03b7t|g1:t|). Now we consider two cases: either \u03b7t\u22121|g1:t\u22121| < \u03b7t|g1:t| or not.\nCase 1: \u03b7t\u22121|g1:t\u22121| < \u03b7t|g1:t|:\nBy convexity of exp, we have\n|wt \u2212 wt+1| \u2264 (|wt+1|+ 1) |exp (\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|)\u2212 1| \u2264 (|wt+1|+ 1) |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t||\n\u2264 (|wt+1|+ 1) ( 1 + pL\n2\n) \u03b7t|gt|\nso that the lemma holds.\nCase 2: \u03b7t\u22121|g1:t\u22121| \u2265 \u03b7t|g1:t|:\nAgain by convexity of exp we have\n|wt \u2212 wt+1| \u2264 (|wt+1|+ 1) |exp (\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|)\u2212 1| \u2264 (|wt+1|+ 1) |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|| exp (\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|)\n\u2264 (|wt+1|+ 1) ( 1 + pL\n2\n) exp [ \u03b7t|gt| ( 1 + pL\n2\n)] \u03b7t|gt|\nso that the lemma still holds.\nThe next lemma is the main workhorse of our regret bounds:\nLemma 11. Suppose \u2016gt\u2016 \u2264 L and either of the following holds:\n1. p \u2264 2 L\n, k = \u221a 2, and \u2016wt\u2016 \u2265 15.\n2. k = \u221a 2, pL \u2265 1, and \u2016wt\u2016 \u2265 4 exp(p2L2).\nThen ( 1\n\u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt(wt \u2212 wt+1) \u2264 0 (7)\nFurther, inequality (7) holds for any k and sufficiently large L if \u2016wt\u2016 \u2265 exp((pL)2).\nProof. By Theorem 5 it suffices to consider the case sign(gt) = \u00b1sign(g1:t\u22121), so that we may adopt our identification with R and use of | \u00b7 | throughout this proof.\nFor p \u2264 2 L\n, k = \u221a 2 we have 15 > exp( \u221a pL\nk \u221a 2 )\u2212 1 and for sufficiently large L, exp((pL)2) > exp(\n\u221a pL k \u221a 2 )\u2212 1.\nTherefore in all cases |wt| \u2265 exp( \u221a pL\nk \u221a 2 )\u2212 1 so that by Corollary 9 and Lemma 10 we have gt \u00b7 (wt \u2212 wt+1) \u2264 \u03b7tg2t (|wt+1|+ 1) ( 1 + pL\n2\n) exp [ \u03b7tgt ( 1 + pL\n2\n)] (8)\nFirst, we prove that (7) is guaranteed if the following holds:\n|wt+1|+ 1 \u2265 exp\n[ 1 + pL\n2\nk2 exp\n( \u03b7tgt ( 1 + pL\n2\n)) + 1 ] (9)\nThe previous line (9) is equivalent to: k2(log(|wt+1|+ 1)\u2212 1) \u2265 ( 1 + pL\n2\n) exp ( \u03b7tgt ( 1 + pL\n2\n)) (10)\nNotice that \u03c8(wt+1) = (|wt+1|+ 1)(log(|wt+1|+ 1)\u2212 1) + 1 \u2265 (|wt+1|+ 1)(log(|wt+1|+ 1)\u2212 1). Then multiplying (10) by \u03b7t|gt| we have\n(|wt+1|+ 1) ( 1 + pL\n2\n) exp [ \u03b7t|gt| ( 1 + pL\n2\n)] \u03b7t|gt| \u2264 k2\u03b7t|gt|\u03c8(wt+1) (11)\nCombining (8) and (11), we see that (9) implies\ngt \u00b7 (wt \u2212 wt+1) \u2264 k2\u03b7tg2t\u03c8(wt+1)\nNow we bound (\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1):\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n= k \u221a 2 (\u221a Mt\u22121 + \u2016g\u201621:t\u22121 \u2212 \u221a Mt + \u2016g\u201621:t\u22121 + g2t )\n\u2264 k \u221a 2 \u221aMt + \u2016g\u201621:t\u22121 + g2t \u2212 g2t +Mt \u2212Mt\u22121 2 \u221a Mt + \u2016g\u201621:t\u22121 + g2t \u2212\u221aMt + \u2016g\u201621:t\u22121 + g2t \n\u2264 \u2212k \u221a 2\ng2t 2 \u221a Mt + \u2016g\u201621:t\n= \u2212k2\u03b7tg2t\nThus when (9) holds we have( 1\n\u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt(wt \u2212 wt+1) \u2264 \u2212k2\u03b7tg2t\u03c8(wt+1) + k2\u03b72t g2t\u03c8(wt+1) \u2264 0\nTherefore our objective is to show that our conditions on wt imply the condition (9) on wt+1.\nFirst, we bound \u03b7tgt in terms of |wt|. Notice that\n|wt|+ 1 = exp  |g1:t\u22121| k \u221a 2 \u221a Mt\u22121 + \u2016g\u201621:t\u22121  \u2264 exp (\u221a p \u221a |g1:t\u22121\nk \u221a 2 ) 2k2 log2(|wt|+ 1)\np \u2264 |g1:t\u22121|\nUsing this we have:\n\u03b7tgt = gt k \u221a 2 \u221a Mt + \u2016g\u201621:t\n\u2264 gt k \u221a 2 \u221a Mt\u22121 + \u2016g\u201621:t\u22121 + g2t \u2264 gt \u221a p\nk \u221a 2 \u221a |g1:t\u22121|+ pg2t\n\u2264 L \u221a p k \u221a 2 \u221a 2k2\np log2(|wt|+ 1) + pL2\nso that we can conclude:\n\u03b7tgt \u2264 Lp k \u221a 2 \u221a 2k2 log2(|wt|+ 1) + p2L2 (12)\nFurther, by Lemma 7 we have\n|wt|+ 1 |wt+1|+ 1 = exp(\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|)\n\u2264 exp [ \u03b7tgt ( 1 + pL\n2 )] Therefore we have\n|wt+1|+ 1 \u2265 (|wt|+ 1) exp [ \u2212\u03b7tgt ( 1 + pL\n2\n)] (13)\nFrom (13), we see that (9) is guaranteed if we have |wt|+ 1 \u2265 exp [ \u03b7tgt ( 1 + pL\n2\n)] exp [ 1 + pL 2\nk2 exp\n( \u03b7tgt ( 1 + pL\n2\n)) + 1 ] (14)\nIf we use our expression (12) in (14), and assume |wt| \u2265 exp(L2), we see that there exists some constant C depending on p and k such that the RHS of (14) is O(exp(L)) and so (14) holds for sufficiently large L. For p = 2/L, k = \u221a 2, and wt \u2265 15 we can verify (14) numerically by plugging in the bound (12). For the case k = \u221a 2, |wt| \u2265 4 exp(p2L2), we notice that by using (12), we can write (14) entirely in terms of pL. Graphing both sides numerically as functions of pL then allows us to verify the condition.\nWe have one final lemma we need before we can start stating some real regret bounds. This lemma can be viewed as observing that \u03c8(w) is roughly 1\nD strongly-convex for |w| not much bigger than D.\nLemma 12. Suppose p \u2264 2/L, k = \u221a 2, \u2016wt\u2016 \u2264 D and \u2016gt\u2016 \u2264 L Then gt(wt \u2212 wt+1) \u2264 6(max(D + 1, exp(1/2)))g2t \u03b7t.\nProof. By Theorem 5 it suffices to consider sign(gt) = \u00b1sign(g1:t\u22121).\nWe show that |wt \u2212wt+1| \u2264 6(max(D + 1, exp(1/2)))|gt|\u03b7t so that the result follows by multiplying by |gt|. From Lemma 7, we have |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|| \u2264 \u03b7t|gt| ( 1 + pL\n2\n) \u2264 2\u03b7t|gt|. Further, note that \u03b7t|gt| \u2264\n1 k \u221a 2 = 1 2 . We consider two cases, either sign(g1:t) = sign(g1:t\u22121) or not.\nCase 1: sign(g1:t) = sign(g1:t\u22121):\n|wt \u2212 wt+1| = | exp(\u03b7t\u22121|g1:t\u22121|)\u2212 exp(\u03b7t|g1:t|)| = (|wt|+ 1)| exp(\u03b7t|g1:t| \u2212 \u03b7t\u22121|g1:t\u22121|)\u2212 1| \u2264 2(D + 1)\u03b7t|gt| exp(2\u03b7t|gt|)\n\u2264 2(D + 1)\u03b7t|gt| exp ( 2\nk \u221a 2 ) \u2264 6(D + 1)\u03b7t|gt|\nCase 2: sign(g1:t) 6= sign(g1:t\u22121): In this case, we must have |g1:t| \u2264 |gt|. Let X = max(\u03b7t|g1:t|, \u03b7t\u22121|g1:t\u22121|). Then by triangle inequality we have\n|wt \u2212 wt+1| \u2264 2max(|wt|, |wt+1|) \u2264 2(exp(X)\u2212 1) \u2264 2X exp(X) \u2264 2(max(|wt|, |wt+1|) + 1)X\nSince |\u03b7t\u22121|g1:t\u22121| \u2212 \u03b7t|g1:t|| \u2264 2\u03b7tgt, we have X \u2264 2\u03b7tgt + \u03b7t|g1:t| \u2264 3\u03b7t|gt| so that we have |wt \u2212 wt+1| \u2264 6(max(|wt|, |wt+1|) + 1)\u03b7t|gt|\nFinally, we have |wt+1|+ 1 = exp(\u03b7t|g1:t|) \u2264 exp(\u03b7t|gt|) \u2264 exp(1/2), so that\n|wt \u2212 wt+1| \u2264 6\u03b7t|gt|(max(|wt|, |wt+1|) + 1) \u2264 6max(D + 1, exp(1/2))\u03b7t|gt|\nNow we are finally in a position to prove Lemma 3, which we re-state below: Lemma 3. Set k = \u221a 2. Suppose \u2016gt\u2016 \u2264 L for t < T , 1/L \u2264 p \u2264 2/L, gT \u2264 Lmax and Lmax \u2265 L. Let Wmax = maxt\u2208[1,T ] \u2016wt\u2016. Then the regret of FTRL with regularizers \u03c8t(w) = \u03c8(w)/\u03b7t is:\nRT (u) \u2264 \u03c8(u)/\u03b7T + 96 \u221a MT + \u2016g\u201621:T + 2Lmax min [ Wmax, 4 exp ( 4 L2max L2 ) , exp( \u221a T/2) ]\n\u2264 (2\u03c8(u) + 96) \u221a\u221a\u221a\u221aT\u22121\u2211 t=1 L|gt|+ L2max + 8Lmax min [ exp ( 4L2max L2 ) , exp( \u221a T/2) ]\n\u2264 Lmax(2((\u2016u\u2016+ 1) log(\u2016u\u2016+ 1)\u2212 \u2016u\u2016) + 96) \u221a T + 8Lmax min [ e 4L2max L2 , e \u221a T/2 ]\nProof of Lemma 3. We combine Lemma 11 with Lemma 12: if |wt| \u2265 15 we have for all t < T :( 1\n\u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1) < 0\nand if |wt| \u2264 15 we have( 1\n\u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1) \u2264 gt \u00b7 (wt \u2212 wt+1)\n\u2264 6\u00d7 (15 + 1)\u03b7tg2t = 96\u03b7tg 2 t\nTherefore for all t < T we have (\n1 \u03b7t\u22121 \u2212 1 \u03b7t\n) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1) \u2264 96\u03b7tg2t .\nRT (u) \u2264 \u03c8(u)/\u03b7T + T\u2211 t=1 ( 1 \u03b7t\u22121 \u2212 1 \u03b7t ) \u03c8(wt+1) + gt \u00b7 (wt \u2212 wt+1)\n\u2264 \u03c8(u)/\u03b7T + 96 T\u2211 t=1 \u03b7tg 2 t + ( 1 \u03b7T\u22121 \u2212 1 \u03b7T ) \u03c8(wT+1) + gT \u00b7 (wT \u2212 wT+1)\nWe have ( 1\n\u03b7T\u22121 \u2212 1 \u03b7T\n) \u03c8(wT+1) < 0\nso that ( 1\n\u03b7T\u22121 \u2212 1 \u03b7T\n) \u03c8(wT+1) + gT \u00b7 (wT \u2212 wT+1) \u2264 2LmaxWmax\nFurther, again using Lemma 11 we have( 1\n\u03b7T\u22121 \u2212 1 \u03b7T\n) \u03c8(wT+1) + gT \u00b7 (wT \u2212 wT+1) < 0\nfor |wT | \u2265 4 exp(p2L2max) since k = \u221a 2.\nFinally, notice that by definition of \u03b7t and L, we must have |\u03b7tg1:t| \u2264 \u221a p|g1:t| k \u221a 2 \u2264 \u221a T/2, so that \u2016wt\u2016 \u2264\nexp (\u03b7t|g1:t|) \u2264 exp (\u221a T/2 )\n. Thus we have( 1\n\u03b7T\u22121 \u2212 1 \u03b7T\n) \u03c8(wT+1) + gT \u00b7 (wT \u2212 wT+1) \u2264 2Lmax min(Wmax, 4 exp(4L2max/L2), exp( \u221a 2T ))\nNow we make the following classic argument:\u221a Mt + \u2016g\u201621:t \u2212 \u221a Mt\u22121 + \u2016g\u201621:t\u22121 \u2265\ng2t +Mt \u2212Mt\u22121 2 \u221a Mt + \u2016g\u201621:t\n\u2265 g 2 t 2 \u221a Mt + \u2016g\u201621:t = \u03b7tg 2 t\nso that we can bound:\nRT (u) \u2264 \u03c8(u)/\u03b7T + 96 T\u2211 t=1 \u03b7tg 2 t + ( 1 \u03b7T\u22121 \u2212 1 \u03b7T ) \u03c8(wT+1) + gT \u00b7 (wT \u2212 wT+1)\n\u2264 \u03c8(u)/\u03b7T + 96 \u221a MT + \u2016g\u201621:T + 2Lmax min(Wmax, 4 exp(4L 2 max/L 2), exp( \u221a 2T ))\nTo show the remaining two lines of the theorem, we prove by induction that Mt + \u2016g\u201621:t \u2264 L \u2211t t\u2032=1 |gt\u2032 | for all t < T . The statement is clearly true for t = 1. Suppose it holds for some t. Then notice that |g1:t+1| \u2264 |gt+1|+ |g1:t|. So we have\nMt+1 + \u2016g\u201621:t+1 = max ( Mt + \u2016g\u201621:t+1,\n|g1:t+1| p ) \u2264 max ( Mt + \u2016g\u201621:t + L|gt+1|, L|g1:t+1|\n) \u2264 L\nt+1\u2211 t\u2032=1 |gt\u2032 |\nFinally, we observe that MT = max ( MT\u22121 + \u2016g\u201621:T\u22121 + g2T , |g1:T |p ) \u2264 L2max + L \u2211T\u22121 t=1 |gt\u2032 | and the last two lines of the theorem follow immediately."}, {"heading": "C Additional Experimental Details", "text": ""}, {"heading": "C.1 Hyperparameter Optimization", "text": "For the linear classification tasks, we optimized hyperparameters in a two-step process. First, we tested every power of 10 from 10\u22125 to 102. Second, if \u03bb was the best hyperparameter setting in step 1, we additionally tested \u03b2\u03bb for \u03b2 \u2208 {0.2, 0.4, 0.8, 2.0, 4.0, 6.0, 8.0}\nFor the neural network models, we optimized ADAM and ADAGRAD\u2019s learning rates by testing every power of 10 from 10\u22125 to 100. For stochastic gradient descent, we used an exponentially decaying learning rate schedule specified in Tensorflow\u2019s (https://www.tensorflow.org/) MNIST and CIFAR-10 example code."}, {"heading": "C.2 Coordinate-wise updates", "text": "We proved all our results in arbitrarily many dimensions, leading to a dimension-independent regret bound. However, it is also possible to achieve dimension-dependent bounds by running an independent version of our algorithm on each coordinate. Formally, for OLO we have\nRT (u) = T\u2211 t=1 gt(wt \u2212 u) = d\u2211 i=1 T\u2211 t=1 gt,i(wt,i \u2212 ui) = d\u2211 i=1 R1T (ui)\nwhere R1T is the regret of a 1-dimensional instance of the algorithm. This reduction can yield substantially better regret bounds when the gradients gt are known to be sparse (but can be much worse when they are not). We use this coordinate-wise update strategy for our linear classification experiments for RESCALEDEXP. We also considered coordinate-wise updates and non-coordinate wise updates for the other algorithms, taking the best-performing of the two.\nFor all algorithms in the linear classification experiments, we found that the difference between coordinate-wise and non-coordinate wise updates was not very striking. However, for the neural network experiments we found RESCALEDEXP performed extremely poorly when using coordinate-wise updates, and performed extremely well with non-coordinate wise updates. We hypothesize that this is due to a combination of non-convexity of the model and frequent resets at different times for each coordinate."}, {"heading": "C.3 Re-centering RESCALEDEXP", "text": "For the non-convex neural network tasks we used a variant of RESCALEDEXP in which we re-center our FTRL algorithm at the beginning of each epoch. Formally, the pseudo-code is provided below:\nAlgorithm 2 Re-centered RESCALEDEXP Initialize: k \u2190 \u221a 2, M0 \u2190 0, w1 \u2190 0, t? \u2190 1 , w? \u2190 0\nfor t = 1 to T do Play wt, receive subgradient gt \u2208 \u2202`t(wt). if t = 1 then L1 \u2190 \u2016g1\u2016 p\u2190 1/L1\nend if Mt \u2190 max(Mt\u22121, \u2016gt?:t\u2016/p\u2212 \u2016g\u20162t?:t). \u03b7t \u2190 1\nk \u221a\n2(Mt+\u2016g\u20162t?:t) wt+1 \u2190 w? + argminw [ \u03c8(w) \u03b7t + gt?:tw ] = w? \u2212 gt?:t\u2016gt?:t\u2016 [exp(\u03b7t\u2016gt?:t\u2016)\u2212 1] if \u2016gt\u2016 > 2Lt then Lt+1 \u2190 \u2016gt\u2016 p\u2190 1/Lt+1 t? \u2190 t+ 1 Mt \u2190 0 wt+1 \u2190 0 w? \u2190 wt\u22121 else Lt+1 \u2190 Lt\nend if end for\nSo long as \u2016w? \u2212 u\u2016 \u2264 \u2016u\u2016, this algorithm maintains the same regret bound as the non-re-centered version of RESCALEDEXP. While it is intuitively reasonable to expect this to occur in a stochastic setting, an adversary can easily subvert this algorithm."}, {"heading": "C.4 Aggregating Studies", "text": "It is difficult to interpret the results of a study such as our linear classification experiments (see Section 4) in which no particular algorithm is always the \u201cwinner\u201d for every dataset. In particular, consider the case of an analyst who wishes to run one of these algorithms on some new dataset, and doesn\u2019t have the either the resources or inclination to implement and tune each algorithm. Which should she choose? We suggest the following heuristic: pick the algorithm with the lowest loss averaged across datasets.\nThis heuristic is problematic because datasets in which all algorithms do very poorly will dominate the crossdataset average. In order address this issue and compare losses across datasets properly, we compute a normalized loss for each algorithm and dataset. The normalized loss for an algorithm on a dataset is given by taking the loss experienced by the algorithm on its best hyperparameter setting on that dataset divided by the lowest loss observed by any algorithm and hyperparameter setting on that dataset. Thus a normalized loss of 1 on a dataset indicates that an algorithm outperformed all other algorithms on the dataset (at least for its best hyperparameter setting). We then average the normalized loss for each algorithm across datasets to obtain the scores for each algorithm (see Table 1).\nThese data indicate that while ADAGRAD has a slight edge after tuning, RESCALEDEXP and ADADELTA do nearly equivalently well (4% and 6% worse performance, respectively). Therefore we suggest that if our intrepid analyst is willing to perform some hyperparameter tuning, then ADAGRAD may be slightly better, but her choice doesn\u2019t matter too much. On the other hand, using RESCALEDEXP will allow her to skip any tuning step without compromising performance."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "We propose an online convex optimization algorithm (RESCALEDEXP) that achieves<lb>optimal regret in the unconstrained setting without prior knowledge of any bounds<lb>on the loss functions. We prove a lower bound showing an exponential sep-<lb>aration between the regret of existing algorithms that require a known bound<lb>on the loss functions and any algorithm that does not require such knowledge.<lb>RESCALEDEXP matches this lower bound asymptotically in the number of itera-<lb>tions. RESCALEDEXP is naturally hyperparameter-free and we demonstrate empir-<lb>ically that it matches prior optimization algorithms that require hyperparameter<lb>optimization. 1 Online Convex Optimization Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy,<lb>antagonistic or changing environments. The problem can be stated formally with the help of the<lb>following definitions:<lb>Convex Set: A setW is convex ifW is contained in some real vector space and tw+(1\u2212 t)w\u2032 \u2208W<lb>for all w,w\u2032 \u2208W and t \u2208 [0, 1].<lb>Convex Function: f :W \u2192 R is a convex function if f(tw + (1\u2212 t)w\u2032) \u2264 tf(w) + (1\u2212 t)f(w\u2032)<lb>for all w,w\u2032 \u2208W and t \u2208 [0, 1]. An OCO problem is a game of repeated rounds in which on round t a learner first chooses an element<lb>wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The<lb>regret of the learner with respect to some other u \u2208W is defined by", "creator": "LaTeX with hyperref package"}}}