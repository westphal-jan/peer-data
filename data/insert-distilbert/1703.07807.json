{"id": "1703.07807", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2017", "title": "Learning to Partition using Score Based Compatibilities", "abstract": "we study the problem of learning to partition users into groups, where one must learn the compatibilities between the users to potentially achieve optimal groupings. we define four common natural objectives that optimize for average and worst case compatibilities and together propose new algorithms for adaptively learning optimal groupings. when we don't impose any structure on the compatibilities, we show that the group formation objectives considered are $ but np $ hard to solve and we either give approximation guarantees or prove inapproximability inconsistent results. we then introduce an elegant memory structure, namely that of \\ textit { intrinsic scores }, that makes many of these problems polynomial time solvable. we explicitly characterize the optimal groupings under this structure and show that the optimal solutions are related to \\ emph { homophilous } and \\ emph { heterophilous } partitions, well - studied in the psychology literature. for one of the four objectives, but we show $ np $ hardness under the score structure and give a $ \\ least frac { 1 } { 2 } $ approximation } algorithm for which no constant approximation was known thus far. finally, under the score structure, we propose an online low sample complexity pac algorithm for learning possibly the optimal partition. we demonstrate the efficacy of the proposed algorithm on synthetic and real world datasets.", "histories": [["v1", "Wed, 22 Mar 2017 18:30:10 GMT  (119kb,D)", "http://arxiv.org/abs/1703.07807v1", "Appears in the Proceedings of the 16th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2017)"]], "COMMENTS": "Appears in the Proceedings of the 16th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2017)", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["arun rajkumar", "koyel mukherjee", "theja tulabandhula"], "accepted": false, "id": "1703.07807"}, "pdf": {"name": "1703.07807.pdf", "metadata": {"source": "CRF", "title": "Learning to Partition using Score Based Compatibilities", "authors": ["Arun Rajkumar", "Koyel Mukherjee"], "emails": ["arun.rajkumar@conduent.com", "kmukherj@in.ibm.com", "tt@theja.org"], "sections": [{"heading": "1 Introduction", "text": "The problem of learning to partition users (or objects) into groups has numerous applications in ridesharing, health care groups, project groups etc. Effective grouping of users is critical in these applications as it determines how well the group can work together [27]. For instance, the success of ridesharing adoption depends on how the system assigns users to groups taking into account their source destination requirements as well as their personalities. A user who does not like making conversation would rate the ride-sharing experience low if they are in the same group as users who talk a lot. Here, the ridesharing company might be interested in maximizing the average happiness of the rideshare groups. In another instance, effectively allocating employees to teams for a critical project might influence the project\u2019s success [21]. Here the organization might want to be defensive and maximize the compatibility of the least compatible pair of employees in any team.\nThat effective grouping leads to improved outcomes has been extensively studied in the psychology literature [18]. In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others. While the social phenomemon of homophily and heterophily have been well studied [20] [1], it is not clear (more so from a formal standpoint) as to when one should prefer homophilous to heterophilous grouping in general.\nIn this work, we formalize the group formation problem by considering four concrete objectives that involve pairwise compatibility of users. We refer to the pairwise compatibility as the happiness\nar X\niv :1\n70 3.\n07 80\n7v 1\n[ cs\n.L G\n] 2\n2 M\nar 2\nof the pair of users. Under this happiness index, we study the following objectives: maximize (i) the average of average happiness across groups (AoA), (ii) minimum compatibility of any pair of users across groups (MoM), (iii) average of the minimum compatible pairs across groups (AoM) and (iv) minimum of the average happiness across all groups (MoA) (see Table 1 for formal definitions). The objectives cover most of the scenarios one may be interested in maximizing. While we do consider general pairwise compatibilities, we introduce and focus mainly on an elegant structure that we impose on them. Under this structure, each individual has an associated intrinsic score and the pairwise compatibility between two individuals depend on their corresponding scores. We will see that under this structure, the optimal solutions to these objectives naturally translate to homophilous and heterophilous groupings. The motivation of studying the score-based model, where the compatibility (or, preference towards each other) of a pair of users is determined by their relative scores, arises from the well-known Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952 [5]; Luce, 1959 [22]) in literature. The BTL model is often applied for pairwise comparisons, in order to determine the relative preferences. This led us to study the simpler case of score-based preferences, for which optimal polynomial algorithms can be provided in most cases, while the general case is either inapproximable or hard to approximate beyond a certain factor.\nWe list below the major contributions of this paper.\nOur Contributions\n\u2022 We show that all the objectives considered above are NP-hard (and hard to approximate beyond a factor) when we assume no structure on the pairwise compatibilities. We give polynomial algorithms under certain assumptions.\n\u2022 When the compatibilities are dictated by intrinsic scores of each individual, we show that three of the four objectives become solvable in polynomial time.\n\u2022 Under the intrinsic scores assumption, we explicitly characterize the structure of the optimal solution and show that they are related to the notion of hompohily and heterophily.\n\u2022 We show that the MoA objective is NP-hard to solve even under the intrinsic scores assumption.\n\u2022 We propose a greedy algorithm for the MoA objective and prove a 12 approximation guarantee for the same. This is a significant improvement on known algorithms, since no constant factor result was known thus far.\n\u2022 Under the intrinsic score structure, we propose a low sample complexity PAC learning algorithm to learn the scores (and hence the optimal groupings) provably.\nTable 2 summarizes some of the contributions of this paper."}, {"heading": "2 Related Work", "text": "Graph partitioning and clustering problems are well researched with several variants such as the disjoint clique problem, k-way partition problem, partition into triangles and many others [12]. Balanced or capacitated versions of such partitioning or clustering problems are related to our work. For instance, the AoA objective is the same as the k-equipartition problem [11] and is known to be NP-hard [14]. The Sum-Max partitioning problem [28] looks at minimizing the average of maximum weighted edge between pairs of groups and is close to, but not the same as the AoM objective. Min-max objectives similar to MoM and MoA objecives have been recently considered by Svitkina and Tardos [26] and Bansal et al. [3], where the problem is to create a k-way equipartition to minimize the maximum weight of edges leaving a single group. This is different from the MoM objective where we want to maximize the minimum of minimum weights across edges within each group.\nMany seemingly related problems such as the clique partition problem [16], the capacitated max-k-cut and min-k-cut problems [15] do not come with size restrictions or have objectives that do not capture homophily or heterophily. In the clustering domain, the work closest to ours is that of Zhu, Wang and Li [29], where heuristic algorithms for clustering with size constraints on the clusters are proposed, although for a majority of clustering applications such size constraints or information on the number of clusters is not pre-defined.\nThere is one class of graph partitioning problems that come with size restrictions, namely, the Graph Tree Partitioning Problem [7], where the objective is to partition a graph into equal size subsets, such that the weight of the spanning tree on each subset is either as high as possible (max-min) or as low as possible (min-max), or, the sum of the weights of the spanning trees are either as high (max-sum), or, as low (min-sum) as possible. Though these objectives are closely related to ours, they are not exactly the same problems.\nSome recent research in application areas such as team formation and ride-sharing study similar questions as us. Singla et al. [24] present online learning algorithms with PAC bounds in the context of learning the expertise of workers for team formation. The emphasis is on speeding up learning by exploiting similarities between workers and between tasks. In contrast to our work, their objective is to select an optimal subset of the workers after learning their expertise and there is no notion of forming groups. Bistaffa, Farinelli and Ramchurn [4] study an offline optimization problem of grouping users to minimize travel costs. This is formulated as a coalition formation problem,\nrestricted by a social network based compatibility graph that is assumed given. The groups are formed based on heuristics without any guarantees on optimality. Brindley, Blaschke and Walti [6] look at what factors impact the formation of effective learning groups through an empirical study.\nOur formulations and learning algorithms can also be applied in recurring sharing economy settings (e.g., AirBnB) as well as healthcare. In the latter setting, it has been observed that assigning patients of similar disease characteristics to groups often helps in effective treatment [8]."}, {"heading": "3 Preliminaries", "text": "Let [n] = {1, 2, . . . , n} be the set of items to be partitioned into groups. Let each group be of size k and let m = nk denote the number of groups\n1. A k-partition \u03a0(S1 . . .Sm) of [n] is denoted by a set of subsets {S1,S2 . . .Sm} where each Si \u2286 [n], |Si| = k with Si \u2229 Sj = \u2205 \u2200i 6= j and \u22c3 i Si = [n]. We will capture the relation between users/objects using a symmetric pairwise compatibitlity matrix W \u2208 Rn\u00d7n+ where Wij(= Wji) denotes the compatibility of users/objects i and j. Given a subset S \u2286 [n], we define the happiness of the subset with respect to W as H(S|W) = 1|S|2 \u2211 i,j\u2208SWij .\nProblem Definition: Given a pairwise compatibility matrix W \u2208 Rn\u00d7n+ , partition the n items into m groups in the best possible manner that maximizes each of the four objectives defined in Table 1.\nTowards this, we will first consider the case where we don\u2019t impose any conditions on the pairwise compatibilities. In the subsequent section, we consider the same problem by imposing a score structure."}, {"heading": "4 General Compatibility Matrices", "text": "We start by describing some results on the hardness of approximation of the four objectives in the general case.\nTheorem 1. (Approximability) For k \u2265 3, unless P = NP , the following are lower bounds on polynomial time approximability: (a) MoM: inapproximable, (b) AoM: ( 1\u2212 1m ) , (c) AoA: 1\u2212 1\n(k2)m\nand (d) MoA: 1\u2212 1 (k2) .\nProof. MoM: inapproximable. Consider an instance G = (V, E) of PartitionIntoTriangles [14], where |V| = 3q for some q \u2208 Z+. The decision question is whether V can be partitioned in to q disjoint sets of size 3 each, V1, . . . , Vq, such that each Vi, i \u2208 [q] forms a triangle in G. Create an instance of MoM, a weighted graph G\u2032 = (V \u2032, E \u2032,W \u2032) from G, where for every vertex v \u2208 V , we create a vertex v\u2032 \u2208 V \u2032, and for every edge e = (u, v) \u2208 E , we create an edge e\u2032 = (v\u2032, u\u2032) \u2208 E \u2032 between the corresponding vertices v\u2032 and u\u2032 in V \u2032, and set its weight we\u2032 = M , where M is a large number. Set k = 3 (group size) and m = q (number of groups). For any pair of vertices (p, q) \u2208 V, such that no edge exists between p and q in E , we create an edge e\u2032\u2032 = (p, q) \u2208 E \u2032 of weight we\u2032\u2032 = , where is a small number and add it to E \u2032. If there exists a partition of V in to q disjoint triangles, then there exists a solution to the MoM problem with objective function = M . The q disjoint triangles correspond to m groups in G\u2032, where in each group, every edge has weightM , since the corresponding edge exists in G. Similarly, if there does not exist any partition of V in to q disjoint triangles, then every solution to MoM on G\u2032 has value = . This is because any solution to the group formation\n1Assume k divides n or add dummy items if not.\nproblem with k = 3 and m = q on G\u2032, would result in at least one group where at least one edge has a weight , since the corresponding edge does not exist in G.\nTherefore, if there exists a polynomial time approximation algorithm with an approximation ratio > M , one would be able to distinguish between the Yes and No instances of PartitionIntoTriangles, by creating a corresponding instance of MoM and applying the algorithm. A Yes instance would result in MoM > , and similarly, a No instance would result in MoM \u2264 . Hence, unless P = NP , there can be no polynomial time approximation algorithm with an approximation ratio > M . For \u2192 0, and M \u2192 \u221e, we can make the ratio arbitrarily bad, \u2192 0. Hence, it is NP -hard to approximate the MoM problem in the general case.\nThe approximability proofs of MoA, AoA and AoM use the same reduction as above. Specifically, create a graph G\u2032 = (V \u2032, E \u2032,W \u2032), with k = 3 and m = q, from an instance of PartitionIntoTriangles, G = (V, E), where |V| = 3q. For a Yes instance of the PartitionIntoTriangles, the disjoint m groups in G\u2032 corresponding to the disjoint q triangles in G, will give a solution with MoA=AoA=AoM= M . On the other hand, for a No instance, any partition of G\u2032 into m disjoint groups would result in at least one group, with at least one edge of weight . Setting = 0, therefore, MoA \u2264 2M3 , AoA \u2264M ( 1\u2212 13m ) , and AoM \u2264M ( 1\u2212 1m ) .\nTherefore, if there exists a polynomial time approximation algorithm for any of the above three objectives with better approximation factors (MoA:23 , AoA: ( 1\u2212 13m ) , and AoM: ( 1\u2212 1m ) ), one can distinguish between the Yes and and No instances of PartitionIntoTriangles. The approximation guarantees can be extended to general k > 3, by similar reduction, replacing triangles by k-cliques."}, {"heading": "4.1 Polynomial Solvability for k = 2", "text": "While the general case is hard, for the case where k = 2, all the objectives become polynomial time solvable.\nTheorem 1. (Polynomial solvability for k = 2) When k = 2, all four objectives are polynomial time solvable.\nFor proving Theorem 1, we first prove the following claim.\nClaim 2. When k = 2, the optimal solution for MOA is the same as that of MOM, and the optimal solution for AoA is the same as the optimal solution for AoM.\nProof. We first prove that the optimal solution for MoA is the same as that for MoM when k = 2. Since group sizes are k = 2, every group has only one edge, that occurring between the pair of vertices in the group. Therefore, the average of the weight of edges in any group is determined simply by the weight of the single edge in the group. Hence, the minimum of the averages, namely MoA is the same as the minimum weight edge in any group, that is, MoM. We next argue that the optimal solution for AoA is the same as that for AoM when k = 2. Since every group has only a single edge each, the solution maximizing the average of the average weight of every group, namely, AoA, is the same as maximizing the average of the weight of the edge in every group, which corresponds to AoM for k = 2.\nNow, we discuss how Edmond\u2019s maximum weighed matching for general graphs solves AoA (and AoM) optimally in polynomial time for k = 2. We find a maximum weight matching in G using Edmond\u2019s algorithm [9]. This returns a partition of V in to n2 groups, maximizing the total weight of edges used in the matching. Suppose there is an optimal solution for AoA (also, AoM) for k = 2\nin G, that has a higher objective function value. That means that there exists a partition of V in to n k disjoint subsets, with each subset of size 2, hence including only one edge, such that the total weight of edges used in the subsets is higher than that returned by Edmond\u2019s algorithm. However, that contradicts the optimality of Edmond\u2019s algorithm, since we can use the solution to AoA (also, AoM) to find a higher weight matching. Similarly, suppose there is a higher weight matching than the objective function value of the optimal solution for AoA (also, AoM). Then, one can use the matching returned by Edmond\u2019s algorithm to find a higher value, feasible solution for AoA (also, AoM), thereby contradicting the optimality of the optimal value for AoA (also, AoM).\nFor MoA and MoM, we first prove the following property.\nLemma 2. Given a graph G, and an optimal solution value OPT for MoM (also, MoA), if we delete all edges of weight < OPT , and make the resultant graph G\u2032 unweighted, then there exists a perfect matching in G\u2032, corresponding to an optimal solution in G.\nProof. Consider the groups in an optimal solution for MoM (also, MoA) in G. Since the optimal solution has value OPT , there must exist a partition of the vertices in to groups of 2, such that the edge in each group has a weight \u2265 OPT . However, this corresponds to a matching in G, where every edge in the matching has a weight \u2265 OPT . Now, delete every edge of weight < OPT . The matching remains unperturbed, and corresponds to a perfect matching in G\u2032.\nNow, we give the algorithm for optimally solving MoM and MoA for k = 2. The algorithm for maximizing MoM (also, MoA) would involve ordering the distinct weights in W in non-decreasing order. For the next weight w in the list, delete all edges of weight we < w. Create an unweighted graph G\u2032 containing only the remaining edges in G (without considering their weights). Now, use Edmond\u2019s algorithm to find a maximum cardinality matching in G\u2032. The lowest weight w, after deleting which, G\u2032 does not have a perfect matching, is the optimal value for MoM (also, MoA). The optimality of this algorithm follows from Lemma 2 and the optimality of Edmond\u2019s maximum cardinality matching for general graphs, that runs in polynomial time. The polynomial time solvability also follows, hence.\nWe next study a linear time solvable special case."}, {"heading": "4.2 Transitive Compatibility: Optimal Linear Algorithm for any k", "text": "We next prove that under a transitivity like assumption on the compatibility matrix, there exists a linear time optimal algorithm. The assumption follows from the intuition that if user i is compatible with j, j is compatible with k, then i is compatible with k. Formally, the transitive property assumed is: \u2200i, j, k,Wij \u2265 min (Wik,Wkj). The following theorem follows from the fact that graphs obeying transitive compatibility would have a particular structure: a collection of disjoint cliques, and, a linear traversal of the graph would return the optimal solution.\nTheorem 3. Under the transitive compatibility property in G, there exists a linear time optimal algorithm for MoM.\nProof Sketch: We first argue that the graph G on which the transitive compatibility property holds has a certain structure. Specifically, it consists of disjoint connected components, where each connected component is a clique. To see this, consider a pair of vertices in G, u and v, between whom the happiness or compatibility is 0. In other words, no edge exists between them. We argue that in order to maintain the transitive property, any vertex p that u is adjacent to (i.e., Wu,p > 0), must necessarily have a 0 compatibility with v. This is because if there exists an edge between p and v, then with\nboth Wp,v > 0 and Wu,p > 0, the transitive property is violated by 0 = Wu,v < min (Wu,p,Wp,v). Therefore, if Wu,v = 0, then Wp,v = 0 for all p, such that Wu,p > 0. Similarly, any vertex p\u2032 that p is adjacent to cannot have any edge to v. Continuing in this manner, it can be seen that any vertex that u is connected to cannot have any edge to v. Therefore, u and v must be in disjoint connected components. Similarly, any pair of vertices that u is adjacent to, say, v1 and v2, must be adjacent to each other. Otherwise, it can be seen that the transitive compatibility property is violated.\nAnother property that transitive compatibility induces is that, in every clique, there can be at most one edge of higher weight, and all other edges must be of identical weight. To see this, note that if there are two edges of higher weight compared to the weight of all other edges in a clique, then there would be at least one triangle, where one edge is lower in weight than the other two, violating the transitive property.\nAny optimal solution would consider each clique separately (in other words, only the participants belonging to the same clique would be matched to one another), since otherwise the partitions would include edges of weight = 0. Moreover, in every grouping of the clique vertices, there can be at most one group with at most one edge of higher weight, and all other edges in all the groups would have identical lower weight, say w. Hence, replacing the higher weight edge by an edge of weight w would not change the MoM objective value. Hence, any partitioning of the vertices of a clique in to groups of size k 2 would be optimal. The algorithm is linear in the number of vertices, since one has to traverse at most all the vertices in all the cliques in order to get the partitions."}, {"heading": "5 Score Based Compatibility Matrices", "text": "In this section we consider a simple yet useful structure on the pairwise compatibility matrix under which three out of the four objectives introduced in Section 3 become poly-time solvable. Specifically, we consider the case of score based compatability matrices where every item i has an associated score si \u2208 R+ and the pairwise compatibility of items i and j is given by the product of their individual scores sisj . This is a natural assumption in several practical scenarios. For instance in study groups, the score could refer to the influence a student has on her peers which may depend on the GPA of the student. In ride sharing applications the score may indicate how introverted/extroverted a person is.\nWe begin by defining certain natural partitions induced by score vectors.\nDefinition 4. (Homophilous Partition) Let s \u2208 Rn and let \u03c3 = argsort(s)3. A k-partition \u03a0(S1, . . . ,Sm) corresponding to s is called homophilous w.r.t s if \u2200i \u2208 [m],Si = {\u03c3((i \u2212 1)k + 1, . . . , \u03c3((i\u2212 1)k + k)}\nDefinition 5. (Heterophilous Partition) Let s \u2208 Rn and let \u03c3 = argsort(s). A k-partition \u03a0(S1, . . . ,Sm) corresponding to s is called heterophilous if \u2200i \u2208 [m],Si = {\u03c3((i \u2212 1)(k \u2212 1) + 1), . . . , \u03c3((i\u2212 1)(k \u2212 1) + (k \u2212 1)), \u03c3(n+ 1\u2212 i))}\nAs an example, let \u03c3 = (1 2 3 4 5 6) and k = 2. The homophilous 2-partition corresponding to \u03c3 would be {S1 = (1 2),S2 = (3 4),S3 = (5 6)} whereas the heterophilous 2-partition would be {S1 = (1 6),S2 = (2 5),S3 = (3, 4)}. Our main results of this section explicitly characterize the optimal solutions for the objectives considered.\n2Without loss of generality, for any clique of size n\u2032, we add dummy vertices with edges of weight w incident on them, to make its cardinality, a multiple of k.\n3argsort(s) is the permutation obtained by sorting the values of score vector s in non-increasing order. Specifically, for \u03c3 = argsort(s), for any i, j, si > sj =\u21d2 \u03c3(i) < \u03c3(j).\nTheorem 6. (Homophilous Partition is Optimal for AoA and AoM) Let W \u2208 Rn\u00d7n be a score based compatibility matrix parametrized by the score vector s \u2208 Rn. The optimal solution to the average of averages (AoA) and the average of minimums (AoM) objectives w.r.t W is given by the homophilous partition of s.\nProof. Note that for any group S, if the compatibility matrix is score based, then the sum of weights of all pairs in the group is given by \u2211 i,j\u2208SWij = (\u2211 i\u2208S si )2 AoA Objective: Assume wlog the entries of s are sorted in descending order i.e., si > sj for all i < j. Let \u03a0 denote the homophilous k-partition corresponding to s. For the sake of contradiction let \u03a0\u0304 6= \u03a0 be the optimal k-partition. Let i be the minimum index such that both i and i+ 1 are in the same groups in \u03a0 whereas they are in different groups in \u03a0\u0304. Denote these groups by g1 and g2. We will show that by swapping specific elements from g1 and g2, one can obtain a partition which is at least as good as \u03a0\u0304. Let i \u2208 g1 and i+ 1 \u2208 g2. Notice that there must be at least one element x \u2208 g1 such that si+1 > sx (otherwise it contradicts the minimality of i). We will consider two cases depending on whether \u2211 j\u2208g1 sj > \u2211 j\u2208g2 sj or otherwise. Case 1: \u2211 j\u2208g1 sj > \u2211 j\u2208g2 sj .\nLet v1 = \u2211\nj\u2208g1;j 6=i,x sj , v2 = \u2211 j\u2208g2;j 6=i+1 sj . Then, using convexity of H(Si|W), we have\n(si + si+1 + v1) 2 + (sx + v2) 2 \u2265 (si + sx + v1)2 + (si+1 + v2)2 Case 2: \u2211 j\u2208g1 sj \u2264 \u2211\nj\u2208g2 sj In this case, there must be an element x \u2208 g2 such that sx < si. One can follow a similar proof as the previous case by swapping i \u2208 g1 and x \u2208 g2. In both the cases, we obtain a partition whose sum (average) of weights over the groups of the partition is at least as good as \u03a0\u0304. One can repeat the procedure with the new partition obtained until one reaches \u03a0. But this contradicts the fact that \u03a0\u0304 6= \u03a0 is optimal. AoM Objective: Assume wlog that the score vector s is such that s1 \u2264 s2 . . . \u2264 sn. We will show the result using induction on the number of groups m. Consider the base case where m = 2 i.e. n = 2k. In this case, we need to show:\ns1s2 + sk+1sk+2 \u2265 si1sj1 + si2sj2\nwhere (i1, j1) and (i2, j2) correspond to the minimum compatibile pairs in the two groups corresponding to some non-homophilous partition of s. If any of these pairs is same as (1, 2) then the result is obvious. Assume not. Then both 1 and 2 will contribute to the minimum compatible pairs. Thus it is enough to show that both of the below cases hold\ns1s2 + sk+1sk+2 \u2265 s1sk+2 + s2s3 and\ns1s2 + sk+1sk+2 \u2265 s1s3 + s2sk+2 as all other cases give rise to smaller objective values. But\nsk+2(s3 \u2212 s2) \u2265 s1(s3 \u2212 s2) =\u21d2 s1s2 + sk+1sk+2 \u2265 s1sk+2 + s2s3\nSimilarly one can show the result for the other case as well. This proves the base case. Now for a general k, assume that the induction hypothesis is true for m = k \u2212 1. For n = mk, apply the induction hypothesis to the bottom n\u2212 k items i.e, for the set {sk+1, . . . sn}. We need to show that with the newly added items {s1, s2, . . . , sk} the hypothesis is still satisfied. Assume not. Then there must exist index pairs (i1, j1), . . . (im, jm) such that\ns1s2 + sk+1sk+2 + . . . s(m\u22121)k+1s(m\u22121)k+2 < si1sj1 + si2sj2 + . . . simsjm .\nIf items 1 and 2 are in the same group, we arrive at a contradiction. Assume they are in different groups. Let (1, j1) and (2, j2) be the corresponding minimum pairs. By swapping 2 with j1, we can only increase the objective. We can iteratively swap items without decreasing the objective such that the first k items are in the first group. But this contradicts the induction hypothesis for the last n\u2212 k items.\nTheorem 7. (Heterophilous Partition is Optimal for MoM) Let W \u2208 Rn\u00d7n be a score based compatibility matrix parametrized by the score vector s \u2208 Rn. The optimal solution to the minimum of minimums (MoM) objective w.r.t W is given by the heterophilous partition of s.\nProof. We prove the base case for n = 4 and k = 2. Let the scores be given by s1 > s2 > s3 > s4. The three possible ways of partitioning this are given by {(1, 2)(3, 4)}, {(1, 3)(2, 4)}, {(1, 4)(2, 3)}. Note that we have s1s4 > s3s4 and s2s3 > s3s4. Thus,\nmin(s1s4, s2s3) > s3s4 = min(s1s2, s3s4)\nSimilarly, we have s1s4 > s2s4 and s2s3 > s2s4. Thus, min(s1s4, s2s3) > s2s4 = min(s1s3, s2s4). As the induction hypothesis, assume that the claim is true for some n and k. We will show that it is true for n + k. Let the new items added be x1, x2, . . . xk assume wlog that x1 > x2 > xk\u22121 > s1 > s2 > . . . sn > xk. We know from the induction hypothesis that the heterophilous partition corresponding to s is has the highest MoM objective value. For the sake of contradiction, assume that by adding the new k items, the heterophilous partition corresponding to the vector [x1 x2 . . . xk\u22121 s1 s2 . . . sn xk] is not optimal.\nCase 1: As x1, . . . xk\u22121 are larger than si \u2200i and xk, the only way any of them could be a part of the minimum pair is when all the items with scores x1, . . . xk\u22121 are in the same group. If xk is also in this group, we arrive at a contradiction. If item with score xk is not in this group, then we swap the item with some item with score sp to arrive at a contradiction.\nCase 2: The other case to consider is when none of the items with scores {x1, . . . xk\u22121} contribute to the minimum compatible pair in their respective groups. In this case, we start with the group g that contains at least one item with scores of {x1, . . . xk\u22121} and has the highest minimum compatible weight. We iteratively swap the remaining items with scores xi for some i which are not in g, with items from g with score sj for some j. This can be done without decreasing the MoM objective value. We then continue swapping iteratively to get to the partition where the group g consists of items with scores {x1, . . . , xk\u22121} along with some other item with score sp for some p. Now, we can use the argument from case 1 to arrive at the required contradiction.\nTheorem 8. (Hardness of MoA) Computing the optimal partition for the minimum of averages (MoA) objective for a score based compatibility matrix is NP-hard.\nProof. Consider an instance I of 3-Partition, with n = 3m items, each associated with a value; si is the value for the item i. The total sum of the values is \u2211 i\u2208I si = mB, and the size of each item is B4 < si < B 2 . The decision problem is whether there exists a partition of the items into m partitions, such that the sum of the values of items in each partition is exactly B. This is a strongly NP-hard problem.\nNow, construct an instance I \u2032 of the MoA problem, with k = 3, where we create an item in I \u2032 corresponding to every item in I, and the score associated with the item in I \u2032 is set to the value of the corresponding item in I. In the MoA problem our goal is to partition the items in I \u2032 in to m groups, each containing exactly k = 3 items, such that the total score of each group is as high as possible. In fact, the lowest total score determines MoA. The decision question we ask here is as\nfollows: does there exist a partitioning of the n items into m groups, each group containing exactly k = 3 items, such that the total score of each group is at least B?\nIf there exists a partition of the items into m groups, such that every group contains exactly 3 items, and the total score of every group is \u2265 B, then that corresponds to a YES instance of 3-Partition. Clearly, every group has to sum up to exactly B, since the total sum is mB. Alternately, if I corresponds to a YES instance of 3-Partition for a given value B, then note that the corresponding m partitions would have exactly 3 items because of the choice of the range of the values of the items (and hence, the range of the scores), and each partition would sum up to B. This would give a feasible solution for the MoA in I \u2032, with each group\u2019s score summing up to \u2265 B. This completes the reduction.\nWhile MoA is NP-Hard in general, we give a simple algorithm Greedy for the MoA objective given W \u2208 Rn\u00d7n, a score based compatibility matrix: Sort the objects/items by their scores in a non-increasing order. Take the next unassigned item from the list and assign it to the partition (or group) with the lowest total score thus far, as long as the partition is not full (i.e., it has < k vertices). Break ties arbitrarily. The best known approximation factor for this algorithm is max ( 2 k , 1 m ) ([17]). We prove a constant factor approximation below, a significant improvement.\nTheorem 9. (Greedy Algorithm is 12 approx for MoA) Algorithm Greedy produces a kpartition that is a 12 approximation for the MoA objective for score based compatibilities.\nProof. For the first m iterations, each group will receive one item each from the top of the sorted list. Define a Reduced Set R as a set of groups in the final solution obtained by the greedy algorithm, such that: (a) for any (p, q) \u2208 R, there is at least one iteration t of the greedy algorithm after the first m iterations when p is favored over q for assigning the next available item, while q is not full, and there is also at least one iteration t\u2032 > m when q receives an item while p is not full, (b) R has the maximum cardinality among all such sets of groups, (c) R includes the group j \u2208 [m] that receives the mth item in the sorted list as its first item.\nLet vj,i be the ith item added to the jth group with size sj,i, and the earliest iteration by which all groups in R get full be tR. Then it follows from the definition of R:\nObservation 3. Any group j /\u2208 R would receive all the items from from the second one to the kth one, that is, items {vj,2, . . . , vj,k} in iterations t > tR.\nThis follows from the definition of R. Suppose a group j\u2032 /\u2208 R received the item vj\u2032,2 in an iteration t\u2032 < tR. In that case, there exists at least one iteration, specifically, t\u2032, when j\u2032 is favored over each of the groups in R, and at least one iteration \u2264 tR, when each of the groups in R are favored over j\u2032, since by tR all groups in R get full. This implies, that j\u2032 should have been included in R, and R is not a maximal set.\nClaim 10. Let the items in the sorted list be {v1, v2, . . . , vn}, where s1 \u2265 s2 \u2265 . . . sn, (si is the score of item vi, the ith item in the sorted list). Let m\u2032 = m\u2212 |R|. The items vm\u2032+1, vm\u2032+2, . . . , vm\u2032+|R|k get assigned to groups in R.\nProof. Suppose an item in the sequence vm\u2032+r, r \u2208 {1, . . . , |R|k} gets assigned to a group j /\u2208 R. Case 1: vm\u2032+r, r \u2265 1 is the first item assigned to j. Now, there is at least one group j\u2032 \u2208 R, that receives an item earlier in the list than vm\u2032+r as its first item as the greedy algorithm assigns one item each to each of the groups, before assigning the second item to any group, and there are only m\u2032 groups outside R. Thus, once j\u2032 receives the second item, the total score of j\u2032 will be greater than that of j, and hence, j will receive at least one item before j\u2032 is chosen again. But from Observation 3, groups /\u2208 R do not receive their second item till all groups in R are full.\nCase 2: vm\u2032+r is the second item assigned to j /\u2208 R. Since from Observation 3, j receives its second item only after tR, and all groups receive at least one item before any group receives its second item, this is possible only if m\u2032+ r > |R|k+m\u2032. However, m\u2032+ r \u2264 |R|k+m\u2032 by assumption. Hence this is not possible either.\nFrom Claim 10, it follows that the m\u2032 groups /\u2208 R, receive the m\u2032 largest score items as their first items, specifically, items v1, . . . , vm\u2032 . Let us call these first m\u2032 items as large items, since the groups receiving them do not get their second item till all groups in R are full. Moreover, it also follows that any subset of |R|k items from V \\ {v1, . . . , vm\u2032} (that is, from the set of all items excluding the large items), would have a total score at most the total score of the items used to fill R. This can be seen from the fact that R gets the highest score |R|k items, excluding the large items.\nClaim 11. Denote the sum of scores of a set of items S as Sum(S). Then,\nmax ((S\u2282{V\\{v1,...,vm\u2032}})\u2229(|S|=|R|k)) Sum(S) \u2264 \u2211 j\u2208R \u2211 i\u2208[k] si,j .\nProof. This follows from Claim 10. Therefore, R gets the highest score |R|k items, excluding the large items. Claim 12. Let OPT be the optimal value of MoA for a given instance. Then OPT \u2264 \u2211 j\u2208R \u2211\ni\u2208[k] si,j |R|\nProof. There is a partition of the items into m groups, such that the sum of the scores of each group is \u2265 OPT . Let AV GR =\n\u2211 j\u2208R \u2211 i\u2208[k] si,j |R| . If |R| = m, then the claim is obvious. Suppose for\ncontradiction, that OPT > AV GR when 1 \u2264 |R| < m. We have m\u2032 = m\u2212 |R| groups outside the reduced set. Therefore, we only have m\u2032 large items, that can be distributed to at most m\u2032 groups in any optimal solution. The remaining \u2265 |R| groups in the optimal solution (that do not receive any large item) would each need to get k items, summing up to \u2265 OPT . Therefore, there must exist a subset of items, say S, of cardinality |R|k, excluding the large items, such that their score sums up to \u2265 |R|OPT . From Claim 11, therefore, AV GR|R| \u2265 Sum(S) \u2265 |R|OPT . However, this contradicts the assumption that AV GR < OPT . This completes the proof.\nHence, we conclude from Claim 12 that OPT \u2264 AV GR. Suppose the minimum total score is realized by a group r /\u2208 R. Clearly, sr,1 \u2265 \u2211 p\u2208[k\u22121] sq,p \u2200q \u2208 R. Since we assign the items in\nnon-increasing order of their scores, sq,k \u2264 \u2211 p\u2208[k\u22121] sq,p k\u22121 \u2200q \u2208 R, hence, sr,1 \u2265 ( 1\u2212 1k ) \u2211j\u2208R,i\u2208[k]si,j |R| .\nTherefore, sr,1 \u2265 ( 1\u2212 1k ) OPT . Hence, for k \u2265 2, the realized minimum total score in this case is \u2265 12OPT . Now, consider the case when the minimum total score is realized by some group in R. Let p and q be the groups with the lowest and highest sum of scores in R respectively. By definition of R, there exists at least one iteration after all the groups have received one item each (that is, some iteration > m), when the total score of q was lower than p, and hence q got assigned an item favored over p. Let k\u2032 \u2208 [2, . . . , k] be the highest index such that the q received the k\u2032th item while p was not full. Let p have k\u2032\u2032 < k items assigned at that time. Since q was favored over p, \u2211 i\u2208[k\u2032\u2032] sp,i \u2265 \u2211 j\u2208[k\u2032\u22121] sq,j . Also, sq,k\u2032 \u2264 sp,k\u2032\u2032 . After this, p received k \u2212 k\u2032\u2032 more items, before q received any of the items in {vq,k\u2032+1, . . . , vq,k}, if k\u2032 < k (otherwise, q would not receive any items after this). Clearly, sq,` \u2264 sp,k for ` \u2208 {k\u2032 + 1, . . . , k}. Hence, the total score of q is \u2211 i\u2208[k] sq,i \u2264 \u2211 i\u2208[k\u2032\u2032] sp,i + sp,k\u2032\u2032 + (k \u2212 k\u2032)sp,k.\nTherefore, \u2211 i\u2208[k] sq,i \u2264 \u2211\ni\u2208[k\u2032\u2032] sp,i + sp,k\u2032\u2032 + (k\u2212 k\u2032\u2032)sp,k + (k\u2032\u2032 \u2212 k\u2032)sp,k \u2264 Sp + sp,k\u2032\u2032 + (k\u2032\u2032 \u2212 k\u2032)sp,k. Now, k\u2032\u2032 \u2212 k\u2032 < k, and because we consider items in sorted order, sp,` \u2265 sp,k\u2200` \u2208 [k]. Hence,\nsp,k\u2032\u2032 + (k \u2032\u2032 \u2212 k\u2032)sp,k \u2264 sp,k\u2032\u2032 + \u2211 i\u2208{1,...,k}\\k\u2032\u2032 sp,i \u2264 Sp. Hence, Sq \u2264 2Sp. Since Sq \u2265 AV GR \u2265 OPT , the realized minimum total score Sp \u2265 OPT2 . This concludes the proof.\nAlgorithm 1 LEARNORDER Paramters: Number of users n, number of groups m, group size k, confidence \u03b4 Set \u03b4\u2217 as in Theorem 13 Generate a Erdos-Renyi random graph G \u223c G(n, log(n)n ) Let diam(G) be the diameter of G. Let E1, . . . E` be a partition of the edges of G into ` bins got using an (approximate) minimum edge coloring G. for i = 1 to ` do\nDivide Ei arbitrarily into bi := d|Ei|/me disjoint bins {Bi1, . . . Bib}. for j = 1 : bi do\nPlay k-partitions corresponding to Bij for O ( diam(G)2 \u22062 ln( 1\u03b4\u2217 ) ) rounds each.\nEstimate s\u0302p \u2212 s\u0302q for all edges (p, q) \u2208 Bij end for\nend for For each k, estimate s\u0302k by summing the estimates for s\u0302i \u2212 s\u0302j along the shortest path in G from 1 to k. If no path exists for node k, set s\u0302k = 0; Return \u03c3\u0302 = argsort(s\u0302)."}, {"heading": "6 Learning Score Vector and Guarantees", "text": "In this section, we propose an algorithm for adaptively learning the optimal ordering corresponding to the score vector of a pairwise compatibility matrix. The learning proceeds in rounds and for every group Sti in a chosen k-partition \u03a0(S t 1, . . . ,S t m) at round t, we assume that we receive a iid noisy version of the happiness of the group as the response i.e. H(Sti) + \u03b7 t i where \u2200t, i, \u03b7ti \u2208 [\u2212b, b] for some b > 0 and E(\u03b7ti) = 0. Our goal is to learn the ordering corresponding to the score vector s \u2208 Rn of the pairwise compatibility matrix W \u2208 Rn\u00d7n, by choosing groups adaptively for T (n, k, \u03b4) rounds. Here k is the size of groups chosen in each round, and \u03b4 is the failure probability for learning a wrong ordering. Once the ordering is learned, we can compute the optimal (or approximately optimal) partition for the various objectives by sorting the scores and invoking Theorems 6, 7 and 9.\nThe algorithm to learn the ordering is given in Algorithm 1. The Algorithm LearnOrder begins by generating a random Erdos-Renyi graph G where the probability of an edge being present is log(n)n . Thus the expected number of edges in the graph is n log(n). The edges of G are then partitioned into disjoint pieces using an approximate O(\u03a3) edge coloring where \u03a3 is the maximum degree of the G. For each of these pieces, for every edge (i, j) in the piece, groups {i,Sij} and {j,Sij} are chosen where Sij is a fixed k\u2212 1 sized set that does not contain i or j. The idea is that, by obtaining the un-normalized happiness values hi = (si + \u2211 l\u2208Sij sl) 2 + k2\u03b7i and hj = (sj + \u2211 l\u2208Sij sl) 2 + k2\u03b7j for these two groups over multiple rounds, one can compute a estimate of the difference of the corresponding scores si \u2212 sj with high confidence. As we only require the relative ordering to be correct, we can without loss of generality, set s\u03021 = 0 and compute the remaining scores using the following procedure: For node k, we find the shortest path in G that connects 1 and k and sum the differences along this path (w.h.p G is connected and so there exists at least one path connecting 1\nand k). Each of these differences are estimates and hence the confidence in the sum of the these estimates depend on the diameter of G. We formally state the guarantee for learnorder below.\nTheorem 13. (PAC guarantee for learnorder) Let W \u2208 Rn\u00d7n be a score based compatibility matrix with score vector s \u2208 Rn. Let \u2206min = min\ni 6=j |si \u2212 sj |, \u2206 = 2ksmin\u2206min \u2212 \u22062min and let \u03b4\u2217 = ( 1\u2212 ( exp(\u2212 \u03b4k ) )) /m. Then, algorithm LearnOrder (Algorithm 1) outputs a permutation \u03c3\u0302\nwhose ordering is same as that of s with probability at least 1\u2212 \u03b4 after O ( |E| m diam(G)2 \u22062 ln( 1\u03b4\u2217 ) ) rounds.\nProof Sketch: For a chosen edge pair (i, j), let hi and hj denote the unnormalized happiness values obtained by choosing the groups (i,Sij) and (j,Sij) where |Sij | = k \u2212 1 and i, j /\u2208 Sij . We have, \u221a\nhi \u2212 \u221a hj = \u221a (si + a)2 + k2\u03b7i \u2212 \u221a (sj + a)2 + k2\u03b7j\nwhere \u03b7i and \u03b7j correspond to the bounded random noise and a = \u2211 l\u2208Sij sl. If the noise \u03b7i, \u03b7j were not present, then the difference \u221a hi \u2212 \u221a hj = si \u2212 sj , which is what we want to estimate. Nevertheless,\nwe can control the noise by playing this pair of groups for O ( diam(G)2\n\u22062 ln( 1\u03b4\u2217 )\n) rounds as in the\nAlgorithm and averaging the happiness values obtained to obtain estimates s\u0302ij . In this case, after these many rounds, we have with probability at least 1\u2212 \u03b4\u2217,\n(si \u2212 sj)\u2212\u2206min diam(G) \u2264 s\u0302ij \u2264 (si \u2212 sj) + \u2206min diam(G) \u2200i, j\nWhen computing the estimate of a pair (s1, sk) not in the edge set E, the algorithm sums up the estimated weights on the shortest path from 1 to k. As the shortest path is at most diam(G) long by definition, we obtain estimates for all pairs of the form (s1, sk) such that all the estimated values s\u03021k satisfies with probability 1\u2212 \u03b4\u2217, |s\u03021k \u2212 s1k| \u2264 \u2206min \u2200k.\nThus under the above condition, if we fix s\u03021 = 0 and obtain values for all other vertices, we can sort them to produce an ordering. It is easy to see that this ordering will exactly correspond to the ordering of the actual score vector s.\nRemark: The sample complexity (i.e., the number of groups to be chosen) by the above Theorem depends on the diameter of the random graph G. It is known that for large enough n, diam(G) is concentrated sharply around 2 log(n)log(n/2) and the number of edges behaves as O(n log(n))."}, {"heading": "7 Experiments", "text": "We assess the quality of the LearnOrder algorithm using simulated and real data. The graph instances we chose were the following. (a) Random: for this synthetically generated dataset, we fixed the group size k = 4 and the graph size n = 16. We added uniform noise between [\u22121, 1] to the feedback in each round and the score for each item was drawn uniformly at random from {1, ..., 10}. And (b) Social network: a 16 node instance was sampled from the Facebook friendship graph, built from an existing anonymized dataset of Facebook users\u2019 data (Leskovec and Krevl 2014). The dataset has 4039 user nodes and 88234 unweighted edges. We used the Jaccard similarity coefficient of features such as education, hometown, language, etc to obtain scores for the users. The performance of LearnOrder is shown in Figure 1 (averaged over 30 runs), and is in terms of the normalized error between the estimated score vector and the true score vector. It decreases as the number of rounds t increases.\nIn addition to showing that the learning algorithm indeed converges, the experiments add empirical support to the fact that the number of rounds needed to learn the true scores within 10% normalized error is very practical (for instance 70 rounds for the Facebook subgraph of size 16). Since the weight matrix was filled using a pairwise similarity measure (using demographical and other user specific metadata) and no intrinsic score was assumed, the experiment shows that the weight matrix is naturally low rank (allowing us to learn the scores very well) for this dataset. As a consequence, for this dataset, we could infer that the users\u2019 intrinsic characteristics reasonably determine who they are friends with."}, {"heading": "8 Conclusions", "text": "We studied the problem of grouping a set of users using their pairwise compatibilities. We first showed hardness and inapproximability results when no assumptions on the pairwise compatibility values are made. We then studied the intrinsic score model for the compatibility, a model that is not only simple and straight forward but also very similar to the popular Bradley\u2013Terry\u2013Luce (BTL) model for pairwise comparisons. Under this model, we related the optimal groupings to homophilous and heterophilous groupings which are well studied in the psychology literature. We proposed the LearnOrder algorithm, which after choosing a small number of groups, adaptively learns the best ordering corresponding to the score vector of the pairwise compatibility matrix. Our experiments on both synthetic and real datasets demonstrate the efficacy of our algorithm.\nWe note that there may be several applications where the pairwise compatibilities between users/items may depend on multiple features (instead of one) and the pairwise compatibility matrix can in general be low rank (instead of being score based). In such cases, our framework can be slightly modified to incorporate a matrix completion subroutine to recover the low rank compatibility matrix. However, the results regarding the optimality of the homophilous/heterophilous partitions do not follow. The analysis of this is beyond the scope of the current work.\nIn the future, we would like to consider other relevant structures for the happiness index and develop algorithms for the same, possibly with statistical as well as computational guarantees."}], "references": [{"title": "Optimal heterophily and communication effectiveness: Some empirical findings", "author": ["M.I. Alpert", "W.T. Anderson"], "venue": "Journal of Communication, 23(3):328\u2013343", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1973}, {"title": "Homophily in peer groups", "author": ["M. Baccara", "L. Yariv"], "venue": "Available at SSRN 2045156", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Min-max graph partitioning and small set expansion", "author": ["N. Bansal", "U. Feige", "R. Krauthgamer", "K. Makarychev", "V. Nagarajan", "J. Naor", "R. Schwartz"], "venue": "FOCS, 2011, pages 17\u201326. IEEE", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Sharing rides with friends: a coalition formation algorithm for ridesharing", "author": ["F. Bistaffa", "A. Farinelli", "S.D. Ramchurn"], "venue": "AAAI", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Rank analysis of incomplete block designs: I", "author": ["R.A. Bradley", "M.E. Terry"], "venue": "the method of paired comparisons. Biometrika, 39(3/4):324\u2013345", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1952}, {"title": "Creating effective collaborative learning groups in an online environment", "author": ["J. Brindley", "L.M. Blaschke", "C. Walti"], "venue": "The International Review of Research in Open and Distributed Learning, 10(3)", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "On the complexity of graph tree partition problems", "author": ["R. Cordone", "F. Maffioli"], "venue": "Discrete Applied Mathematics, 134(1):51\u201365", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Research on group psychotherapy: Overview and clinical applications", "author": ["R. Dies"], "venue": "Group therapy in clinical practice, pages 473\u2013518", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1993}, {"title": "Paths", "author": ["J. Edmonds"], "venue": "trees, and flowers. Canadian Journal of mathematics, 17(3):449\u2013467", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1965}, {"title": "Grouping practices and reading outcomes for students with disabilities", "author": ["B. Elbaum", "S. Vaughn", "M. Hughes", "S. Moody"], "venue": "Exceptional children, 65(3):399", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Equipartitions of graphs", "author": ["D. Eppstein", "J. Feigenbaum", "C. Li"], "venue": "Discrete mathematics, 91(3):239\u2013248", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1991}, {"title": "Complexity of graph partition problems", "author": ["T. Feder", "P. Hell", "S. Klein", "R. Motwani"], "venue": "Proceedings of the thirty-first annual ACM STOC, pages 464\u2013472. ACM", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1999}, {"title": "Critical elements of classroom and small-group instruction promote reading success in all children", "author": ["B.R. Foorman", "J. Torgesen"], "venue": "Learning Disabilities Research & Practice, 16(4):203\u2013212", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2001}, {"title": "A guide to the theory of np-completeness", "author": ["M.R. Garey", "D.S. Johnson"], "venue": "WH Freemann", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1979}, {"title": "The capacitated max k-cut problem", "author": ["D.R. Gaur", "R. Krishnamurti", "R. Kohli"], "venue": "Mathematical Programming, 115(1):65\u201372", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "Facets of the clique partitioning polytope", "author": ["M. Gr\u00f6tschel", "Y. Wakabayashi"], "venue": "Mathematical Programming, 47(1-3):367\u2013387", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1990}, {"title": "\u03ba-partitioning problems for maximizing the minimum load", "author": ["Y. He", "Z. Tan", "J. Zhu", "E. Yao"], "venue": "Computers & Mathematics with Applications, 46(10):1671\u20131681", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "The compositional impact of team diversity on performance: Theoretical considerations", "author": ["S.K. Horwitz"], "venue": "Human resource development review, 4(2):219\u2013245", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2005}, {"title": "The effects of team diversity on team outcomes: A meta-analytic review of team demography", "author": ["S.K. Horwitz", "I.B. Horwitz"], "venue": "Journal of management, 33(6):987\u20131015", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2007}, {"title": "Friendship as a social process: A substantive and methodological analysis", "author": ["P.F. Lazarsfeld", "R.K. Merton"], "venue": "Freedom and control in modern society, 18(1):18\u201366", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1954}, {"title": "Effect of team diversity on software project performance", "author": ["T. Liang", "C. Liu", "T.-M. Lin", "B. Lin"], "venue": "Industrial Management & Data Systems, 107(5):636\u2013653", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Individual choice behavior: A theoretical analysis", "author": ["R.D. Luce"], "venue": "New York, 115:191\u2013243", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1959}, {"title": "Birds of a feather: Homophily in social networks", "author": ["M. McPherson", "L. Smith-Lovin", "J.M. Cook"], "venue": "Annual review of sociology, pages 415\u2013444", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning to hire teams", "author": ["A. Singla", "E. Horvitz", "P. Kohli", "A. Krause"], "venue": "arXiv:1508.02823", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "A look at the bright side of multicultural team diversity", "author": ["G.K. Stahl", "K. M\u00e4kel\u00e4", "L. Zander", "M.L. Maznevski"], "venue": "Scandinavian Journal of Management, 26(4):439\u2013447", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Min-max multiway cut", "author": ["Z. Svitkina", "\u00c9. Tardos"], "venue": "Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, pages 207\u2013218. Springer", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "A longitudinal field investigation of the impact of group composition on group performance and cohesion", "author": ["J.R. Terborg", "C. Castore", "J.A. DeNinno"], "venue": "J. Personality and Social Psychology, 34(5):782", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1976}, {"title": "On the sum-max graph partitioning problem", "author": ["R. Watrigant", "M. Bougeret", "R. Giroudeau", "J. K\u00f6nig"], "venue": "Theoretical Computer Science, 540:143\u2013155", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "Data clustering with size constraints", "author": ["S. Zhu", "D. Wang", "T. Li"], "venue": "Knowledge-Based Systems, 23(8):883\u2013889", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 26, "context": "Effective grouping of users is critical in these applications as it determines how well the group can work together [27].", "startOffset": 116, "endOffset": 120}, {"referenceID": 20, "context": "In another instance, effectively allocating employees to teams for a critical project might influence the project\u2019s success [21].", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "That effective grouping leads to improved outcomes has been extensively studied in the psychology literature [18].", "startOffset": 109, "endOffset": 113}, {"referenceID": 22, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 80, "endOffset": 87}, {"referenceID": 1, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 80, "endOffset": 87}, {"referenceID": 24, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 147, "endOffset": 151}, {"referenceID": 18, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 232, "endOffset": 236}, {"referenceID": 9, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 254, "endOffset": 262}, {"referenceID": 12, "context": "In particular, the effects of homophily (grouping similar individuals together) [23, 2] and heterophily (grouping dissimilar individuals together) [25] on desired outcomes have been documented in applications such as team formation [19] and study groups [10, 13] among others.", "startOffset": 254, "endOffset": 262}, {"referenceID": 19, "context": "While the social phenomemon of homophily and heterophily have been well studied [20] [1], it is not clear (more so from a formal standpoint) as to when one should prefer homophilous to heterophilous grouping in general.", "startOffset": 80, "endOffset": 84}, {"referenceID": 0, "context": "While the social phenomemon of homophily and heterophily have been well studied [20] [1], it is not clear (more so from a formal standpoint) as to when one should prefer homophilous to heterophilous grouping in general.", "startOffset": 85, "endOffset": 88}, {"referenceID": 4, "context": "The motivation of studying the score-based model, where the compatibility (or, preference towards each other) of a pair of users is determined by their relative scores, arises from the well-known Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952 [5]; Luce, 1959 [22]) in literature.", "startOffset": 246, "endOffset": 249}, {"referenceID": 21, "context": "The motivation of studying the score-based model, where the compatibility (or, preference towards each other) of a pair of users is determined by their relative scores, arises from the well-known Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952 [5]; Luce, 1959 [22]) in literature.", "startOffset": 262, "endOffset": 266}, {"referenceID": 11, "context": "Graph partitioning and clustering problems are well researched with several variants such as the disjoint clique problem, k-way partition problem, partition into triangles and many others [12].", "startOffset": 188, "endOffset": 192}, {"referenceID": 10, "context": "For instance, the AoA objective is the same as the k-equipartition problem [11] and is known to be NP-hard [14].", "startOffset": 75, "endOffset": 79}, {"referenceID": 13, "context": "For instance, the AoA objective is the same as the k-equipartition problem [11] and is known to be NP-hard [14].", "startOffset": 107, "endOffset": 111}, {"referenceID": 27, "context": "The Sum-Max partitioning problem [28] looks at minimizing the average of maximum weighted edge between pairs of groups and is close to, but not the same as the AoM objective.", "startOffset": 33, "endOffset": 37}, {"referenceID": 25, "context": "Min-max objectives similar to MoM and MoA objecives have been recently considered by Svitkina and Tardos [26] and Bansal et al.", "startOffset": 105, "endOffset": 109}, {"referenceID": 2, "context": "[3], where the problem is to create a k-way equipartition to minimize the maximum weight of edges leaving a single group.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "Many seemingly related problems such as the clique partition problem [16], the capacitated max-k-cut and min-k-cut problems [15] do not come with size restrictions or have objectives that do not capture homophily or heterophily.", "startOffset": 69, "endOffset": 73}, {"referenceID": 14, "context": "Many seemingly related problems such as the clique partition problem [16], the capacitated max-k-cut and min-k-cut problems [15] do not come with size restrictions or have objectives that do not capture homophily or heterophily.", "startOffset": 124, "endOffset": 128}, {"referenceID": 28, "context": "In the clustering domain, the work closest to ours is that of Zhu, Wang and Li [29], where heuristic algorithms for clustering with size constraints on the clusters are proposed, although for a majority of clustering applications such size constraints or information on the number of clusters is not pre-defined.", "startOffset": 79, "endOffset": 83}, {"referenceID": 6, "context": "There is one class of graph partitioning problems that come with size restrictions, namely, the Graph Tree Partitioning Problem [7], where the objective is to partition a graph into equal size subsets, such that the weight of the spanning tree on each subset is either as high as possible (max-min) or as low as possible (min-max), or, the sum of the weights of the spanning trees are either as high (max-sum), or, as low (min-sum) as possible.", "startOffset": 128, "endOffset": 131}, {"referenceID": 23, "context": "[24] present online learning algorithms with PAC bounds in the context of learning the expertise of workers for team formation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Bistaffa, Farinelli and Ramchurn [4] study an offline optimization problem of grouping users to minimize travel costs.", "startOffset": 33, "endOffset": 36}, {"referenceID": 5, "context": "Brindley, Blaschke and Walti [6] look at what factors impact the formation of effective learning groups through an empirical study.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "In the latter setting, it has been observed that assigning patients of similar disease characteristics to groups often helps in effective treatment [8].", "startOffset": 148, "endOffset": 151}, {"referenceID": 13, "context": "Consider an instance G = (V, E) of PartitionIntoTriangles [14], where |V| = 3q for some q \u2208 Z+.", "startOffset": 58, "endOffset": 62}, {"referenceID": 8, "context": "We find a maximum weight matching in G using Edmond\u2019s algorithm [9].", "startOffset": 64, "endOffset": 67}, {"referenceID": 16, "context": "The best known approximation factor for this algorithm is max ( 2 k , 1 m ) ([17]).", "startOffset": 77, "endOffset": 81}], "year": 2017, "abstractText": "We study the problem of learning to partition users into groups, where one must learn the compatibilities between the users to achieve optimal groupings. We define four natural objectives that optimize for average and worst case compatibilities and propose new algorithms for adaptively learning optimal groupings. When we do not impose any structure on the compatibilities, we show that the group formation objectives considered are NP hard to solve and we either give approximation guarantees or prove inapproximability results. We then introduce an elegant structure, namely that of intrinsic scores, that makes many of these problems polynomial time solvable. We explicitly characterize the optimal groupings under this structure and show that the optimal solutions are related to homophilous and heterophilous partitions, well-studied in the psychology literature. For one of the four objectives, we show NP hardness under the score structure and give a 12 approximation algorithm for which no constant approximation was known thus far. Finally, under the score structure, we propose an online low sample complexity PAC algorithm for learning the optimal partition. We demonstrate the efficacy of the proposed algorithm on synthetic and real world datasets.", "creator": "LaTeX with hyperref package"}}}