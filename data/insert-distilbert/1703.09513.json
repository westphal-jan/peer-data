{"id": "1703.09513", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Mar-2017", "title": "Mining Best Closed Itemsets for Projection-antimonotonic Constraints in Polynomial Time", "abstract": "the exponential explosion of the set of patterns is one of the main challenges in mixed pattern mining. this challenge is carefully approached by introducing a constraint for pattern selection. notably one dimension of the first constraints proposed in integrated pattern mining is persistent support ( frequency ) of a periodic pattern in a dataset. frequency is an anti - monotonic reinforcement function, i. e., given an infrequent pattern, although all its superpatterns are not frequent. however, nonetheless many other constraints for pattern selection are neither monotonic adaptive nor anti - monotonic, which makes it difficult to generate patterns satisfying these constraints.", "histories": [["v1", "Tue, 28 Mar 2017 11:40:44 GMT  (253kb,D)", "http://arxiv.org/abs/1703.09513v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["aleksey buzmakov", "sergei o kuznetsov", "amedeo napoli"], "accepted": false, "id": "1703.09513"}, "pdf": {"name": "1703.09513.pdf", "metadata": {"source": "CRF", "title": "Mining Best Closed Itemsets for Projection-antimonotonic Constraints in Polynomial Time", "authors": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "emails": ["avbuzmakov@hse.ru,", "skuznetsov@hse.ru,", "amedeo.napoli@loria.fr"], "sections": [{"heading": "1 Introduction", "text": "Interestingness measures were proposed to overcome the problem of combinatorial explosion of the number of valid patterns that can be discovered in a\n1\nar X\niv :1\n70 3.\n09 51\n3v 1\ndataset [VT14]. For example, pattern support, i.e., the number of transactions covered by the pattern, is one of the most famous measures of pattern quality. In particular, support satisfies the property of anti-monotonicity (aka \u201ca priori principle\u201d), i.e., the larger the pattern is the smaller the support is [MTV94, AS94]. Many other measures can be mentioned such as pattern stability [Kuz07, ROK08], margin closeness [MTU11], MCCS [SDB13], cosine interest [CWW14], pattern robustness [TMC14], etc.\nSome of these measures (e.g., support, robustness for generators [TMC14], or upper bound constraint of MCCS [SDB13]) are \u201cglobally anti-monotonic\u201d, i.e., for any two patterns X v Y (where v stays for containment or subsumption relation in the pattern language) we have M(X) \u2265 M(Y ), where M is a measure. When a measure is anti-monotonic, it is relatively easy to find patterns whose measure is higher than a certain threshold (e.g. patterns with a support higher than a threshold). In contrast some other measures are called \u201clocally anti-monotonic\u201d, i.e., for any pattern X there is an immediate subpattern Y \u227a X such that M(Y ) \u2265 M(X). The corresponding constraint induces an accessible system [BHPW10] in itemset data. Indeed, for any itemset selected by a locally anti-monotonic constraint, one can always find a smaller selected itemset different only in one item. The good strategy in this case is extension of a pattern Y only to patterns X such that M(X) \u2264 M(Y ). For example, cosine interest [CWW14] is \u201clocally anti-monotonic,\u201d some other examples can be found in [BHPW10].\nThe most difficult case is when a nonmonotonic measure is not even locally anti-monotonic. The valid patterns can be selected by postpruning, i.e., by finding a (large) set of patterns satisfying an anti-monotonic constraint and pruning them w.r.t. the chosen nonmonotonic measure [ROK08, MTU11, TMC14]. For that one can rely on certain heuristics such as the one used in leap search [YCHY08]. More elaborated approaches allow constructing a measure from (anti-)monotonic primitives [SC05, CRB08]. These approaches find a good anti-monotonic relaxation of the measure for the dataset in hand. Another interesting approach for dealing with non-monotonic constraints is search for a closure operator on the set of patterns adequate for the constraint in question [SC08].\nIn this paper we deal with a recently introduced algorithm \u03a3\u03bf\u03c6\u03b9\u03b1, i.e. Sofia, for \u201cSearching for Optimal Formal Intents Algorithm\u201d. \u03a3\u03bf\u03c6\u03b9\u03b1 was applied for an interval-tuple data [BKN15]. In this paper we apply \u03a3\u03bf\u03c6\u03b9\u03b1 for extracting the best itemsets w.r.t. a wide class of constraints. We introduce the polynomial version of the algorithm by accordingly adjusting the threshold and deeply studying the properties of the involved measures. Our algorithm is applicable to a class of measures called \u201cprojection-antimonotonic measures\u201d or more precisely \u201cmeasures anti-monotonic w.r.t. a chain of projections\u201d. This class includes globally anti-monotonic measures such as support, locally anti-monotonic measures such as cosine interest and some of the nonmonotonic measures such as stability or robustness of closed patterns. We should notice that this class of measures is not covered by the previously introduced approaches. In particular, for the primitive-based approaches [SC05, CRB08] it is not clear how one can\nexpress certain measures from our class, e.g., stability and robustness, by means of the primitives. On the other hand, the approach for finding adequate closure [SC08] could be applied for stability and robustness, but the number of classes of equivalences that should be enumerated is likely to be high and accordingly the efficiency of the approach is likely to be low. Furthermore, neither of these approaches ensure a polynomial complexity of the algorithm.\nIn the experimental part of the paper we show that \u03a3\u03bf\u03c6\u03b9\u03b1 can be efficiently used to mine itemesets w.r.t. a constraint based on \u0394-measure, a polynomially computable analog of stability and robustness. It significantly outperforms the postpruning approaches based on best known algorithms for mining closed itemsets. We should mention that comparison of \u03a3\u03bf\u03c6\u03b9\u03b1 with primitive-based approaches or with the approach for finding adequate closure is not possible since it requires a heavy study of efficiently expressing stability and robustness in terms of the primitives.\nIn the rest of the paper we work with itemsets and accordingly we use the word \u2019itemset\u2019 instead of \u2019pattern\u2019. The remainder of the paper is organized as follows. Since the lattice of closed itemsets (concept lattice) is of high importance for concise representation of itemsets [PBTL99], we use the language of Formal Concept Analysis (FCA) [GW99] and pattern structures [GK01] which are introduced in Section 2. Then, \u03a3\u03bf\u03c6\u03b9\u03b1 algorithm is detailed in Section 3 for projection-antimonotonic measures. In the next section we discuss cosine interest, robustness, and stability that are examples of such measures. Experiments and a discussion on \u03a3\u03bf\u03c6\u03b9\u03b1 efficiency are proposed in Section 5, before the conclusion."}, {"heading": "2 Preliminaries", "text": ""}, {"heading": "2.1 Binary Dataset", "text": "FCA is a very convenient formalism for describing models of itemset mining and knowledge discovery [GW99]. Since [PBTL99] lattices of closed itemsets (concept lattices) and closed descriptions are used for concise representation of association rules. FCA gives a formalism for itemset mining. For more complex data such as sequences, graphs, interval tuples, and logical formulas one can use an extension of the basic model, called pattern structures [GK01]. With pattern structures one defines closed descriptions that give a concise representation of association rules for different types of descriptions with a partial order of \u201cpartwhole\u201d (e.g., subgraph isomorphism order) or \u201cis a\u201d (e.g., \u201cclass-subclass\u201d) giving rise to a semilattical similarity operation u [KS05, KKN11].\nA binary dataset is a triple D = (T, I, R), where T is a set of transaction identifiers, I is a set of items and R \u2286 T \u00d7 I is incidence relation giving information about items related to every transaction. A pattern structure or a (general) dataset is a triple (T, (D,u), \u03b4), where (D,u) is a semilattice of \u201cdescriptions\u201d with similarity operation u inducing natural partial order (D,v) given by x v y \u21d4 x u y = x and \u03b4 : T \u2192 D is a mapping from transactions\nto their descriptions. Then, a binary dataset is (T, (2I ,\u2229), \u03b4), where u is \u2229, v is \u2286, and \u03b4(t) = {i \u2208 I | (t, i) \u2208 R}. We use the pattern structure representation in order to iteratively modify the pattern space which is discussed later. Any subset of T is called a tidset and any subset of I is called an itemset. An example of a dataset is given in Figure 1a.\nThe following mappings give a Galois connection between the powerset of transactions and the semilattice of descriptions, e.g. (2I ,\u2229).\nd(A) := l\nt\u2208A \u03b4(t), for A \u2286 T\nt(x) := {t \u2208 T | x v \u03b4(t)}, for x \u2208 D\nIn case of a binary dataset, the mapping d(A) returns the maximal itemset common to all transactions in A, while the mapping t(x) returns the set of all transactions whose descriptions are supersets of x. One can define closure operators and the corresponding closed tidsets and closed descriptions: ct := t \u25e6 d and cd := d\u25e6t are closure operators, while the closed tidset A and closed itemset x are given by ct(A) = A and cd(x) = x. As stated in [PBTL99], this type of closure (based on Galois connection and u operation) is equivalent for itemsets to the closure wrt. \u201ccounting inference\u201d, which is common in data mining. However, the former definition unifies very important notions of \u201cmaximal common part\u201d, closure, and lattices of closed patterns, so we shall keep to it in this paper.\nA concept of a dataset (T, (D,u), \u03b4) is a pair (A, x), where A \u2286 T , called extent and x \u2282 I, called intent, such that d(A) = x and t(x) = A. In this case both A and x are closed tidset and itemset, respectively. The set of concepts is partially ordered w.r.t. inclusion on extents, i.e., (A1, x1) \u2264 (A2, x2) iff A1 \u2286 A2 (or, equivalently, x2 v x1), forming a lattice. An example of a lattice corresponding to the binary dataset in Figure 1a is given in Figure 1b.\nIn the reminder we need some results from pattern structures for justifying our approach. Moreover, our approach is also applicable to more complex data given by general datasets (pattern structures). For example, \u03a3\u03bf\u03c6\u03b9\u03b1 was successfully applied to interval-tuple datasets [BKN15]."}, {"heading": "2.2 Projections of Datasets", "text": "The approach proposed in this paper is based on projections introduced for reducing complexity of computing with pattern structures [GK01].\nA projection \u03c8 : D \u2192 D is an \u201cinterior operator\u201d, i.e., it is (1) monotone (x v y \u21d2 \u03c8(x) v \u03c8(y)), (2) contractive (\u03c8(x) v x) and (3) idempotent (\u03c8(\u03c8(x)) = \u03c8(x)). A projected dataset \u03c8(D) = \u03c8((T, (D,u), \u03b4)) is a dataset (T, (D\u03c8,u\u03c8), \u03c8\u25e6 \u03b4), where \u03c8(D) = {x \u2208 D | \u2203x\u2217 \u2208 D : \u03c8(x\u2217) = x} is the fixed set of \u03c8 and \u2200x, y \u2208 D,x u\u03c8 y := \u03c8(x u y).\nIn the case of binary datasets projections correspond to removal of some items, with the respective change of the dataset (T, (2I ,\u2229), \u03b4). The projection of an itemset X \u2286 I corresponding to removal of a set of items Y \u2286 I is given by\n\u03c8(X) = X \u2229 (I \\ Y ) = X \\ Y. (1)\nGiven a projection \u03c8 we call \u03c8(D) = {x \u2208 D | \u03c8(x) = x} the fixed set of \u03c8. The fixed set contains those itemsets that contain no items from the set Y (the set of removed items). The projections are ordered w.r.t. inclusion of the fixed points (or by inclusion of the sets of removed items in the case of binary data), i.e., \u03c81 < \u03c82, if \u03c81(D) \u2286 \u03c82(D), we say that \u03c81 is simpler than \u03c82 or that \u03c82 is more detailed than \u03c81.\nOur algorithm is based on this order on projections. The simpler a projection \u03c8 is, the less itemsets we can find in \u03c8(D), and the less computational efforts one should take. Thus, we compute a set of itemsets for a simpler projection, then we remove unpromising itemsets, extend our dataset and the found itemsets with more items (to a more detailed projection). This allows us to reduce the size of the pattern space with a simpler projection and lower computational complexity."}, {"heading": "3 \u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm", "text": ""}, {"heading": "3.1 Anti-monotonicity w.r.t. a Projection", "text": "Our algorithm is based on the projection-antimonotonicity. Many interestingness measures for itemsets, e.g., stability [Kuz07], robustness of closed item-\nsets [TMC14], or cosine interest [CWW14], are not (anti-)monotonic w.r.t. inclusion order on itemsets. A measure M is called anti-monotonic if for two itemsets x v y, M(x) \u2265 M(y). For instance, support is an anti-monotonic measure w.r.t. itemset inclusion order and it allows for efficient generation of itemsets with support larger than a threshold [AS94, MTV94, PBTL99]. The projection-antimonotonicity is a generalization of standard anti-monotonicity and allows for efficient processing a larger set of interestingness measures.\nGiven a projection \u03c8 corresponding to the removal of items Y , preimages of an itemset X (we assume X \u2229 Y = \u2205) for \u03c8 is the set of itemsets {Z} such that \u03c8(Z) = X. It can be seen that the set of preimages is given by Preimages(Y) = {Z \u2286 I | X \u2286 Z \u2286 X \u222a Y }. In particular X is also a preimage of itself.\nAn anti-monotonic measure M w.r.t. projection \u03c8 (or just a projectionantimonotonic measure) is a measure which does not increase its value on any premiage of any itemset X for \u03c8. Since any preimage of X is a superset of X, then any anti-monotonic measure is also a projection-antimonotonic measure.\nExample 1. Let us consider the dataset in Figure 1a. If M is an interestingness measure w.r.t. a projection \u03c8 and \u03c8 removes item i5, then M({i3}) \u2265 M({i3, i5}). However it is not necessary that M({i3}) \u2265M({i3, i4}).\nThus, given a measure M anti-monotonic w.r.t. a projection \u03c8, if y is an itemset such that M\u03c8(y) < \u03b8, then M(x) < \u03b8 for any preimage x of y for \u03c8. Hence, if, given an itemset y of \u03c8(D), one can find all itemsets x of D such that \u03c8(x) = y, it is possible to find the itemsets in \u03c8(D) and then to prune them w.r.t. M\u03c8, and finally to compute the preimages of the pruned set of itemsets only. It allows one to earlier cut unpromising branches of the search space or adjust a threshold for finding only a limited number of best itemsets.\nHowever, given just one projection, it can be hard to efficiently discover the best itemsets, since the projection is either hard to compute or the number of unpromising itemsets that can be pruned is not high. Corespondingly we need a chain of projections \u03c80 < \u03c81 < \u00b7 \u00b7 \u00b7 < \u03c8k = 1, where concepts for \u03c80(D) can be easily computed and 1 is the identity projection, i.e., (\u2200x)1(x) = x. For example, to find frequent itemsets, we typically search for small frequent itemsets and then extend them to larger ones. It corresponds to the extension to a more detailed projection. In particular for binary dataset a chain of projections can be instantiated as a consequent update of a binary dataset with new items.\nChain of projections is a generalization of accessible system [BHPW10]. Given a set of items I and a subset of its powerset F \u2286 2I , the system (I,F) is accessible if \u2200X \u2208 F \\ {\u2205} there is i \u2208 I such that X \\ {i} \u2208 F . Any constraint (or measure) on 2I produces a system of sets. If this system is accessible, then the measure is locally anti-monotonic.\nProposition 1. A chain of projections can be represented as a sequence of systems (Ii,Fi) such that Ii \u2282 Ii+1 and any element x \u2208 Fi+1 is either (1) x \u2208 Fi, or (2) \u2203e \u2208 Ii+1 \\Ii such that (x\\{e}) \u2208 Fi, (3) or x accesible in Fi+1.\nData: A dataset D, a chain of projections \u03a8 = {\u03c80, \u03c81, \u00b7 \u00b7 \u00b7 , \u03c8k}, an anti-monotonic measure M for the chain \u03a8, and a threshold \u03b8 for M.\n1 Function ExtendProjection(i, \u03b8, Pi\u22121) Data: i is the projection number to which we should extend (0 < i \u2264 k), \u03b8 is a\nthreshold value for M, and Pi\u22121 is the set of itemsets for the projection \u03c8i\u22121.\nResult: The set Pi of all itemsets with the value of measure M higher than the threshold \u03b8 for \u03c8i.\n2 Pi \u2190\u2212 \u2205; 3 foreach p \u2208 Pi\u22121 do 4 Pi \u2190\u2212 Pi \u222a Preimages(i,p) 5 foreach p \u2208 Pi do 6 if M\u03c8i (p) \u2264 \u03b8 then 7 Pi \u2190\u2212 Pi \\ {p} 8 Function Algorithm \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1\nResult: The set P of all itemsets with a value of M higher than the threshold \u03b8 for D.\n9 P \u2190\u2212 FindPatterns(\u03b8, \u03c80); 10 foreach 0 < i \u2264 k do 11 P \u2190\u2212 ExtendProjection(i, \u03b8,P);\nAlgorithm 1: \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1\nProof. (1) by idempotency of projections, (2) by contractivity, (3) for deletion of several items."}, {"heading": "3.2 Algorithms", "text": "Data: A dataset D, a chain of projections \u03a8 = {\u03c80, \u03c81, \u00b7 \u00b7 \u00b7 , \u03c8k}, an anti-monotonic measure M for the chain \u03a8, and a threshold L for the maximal number of preserved itemsets.\n1 Function Algorithm \u03a3\u03bf\u03c6\u03b9\u03b1 Result: The threshold \u03b8 ensuring that the cardinality of the set P is bounded by\nL in any step of the algorithm. The set P of all itemsets with the value of measure M higher than the threshold \u03b8.\n2 \u03b8 \u2190\u2212 \u03b8minP \u2190\u2212 FindPatterns(\u03c80); 3 foreach 0 < i \u2264 k do 4 \u03b8 \u2190\u2212 AdjustTheta(\u03b8, L,P); 5 P \u2190\u2212 PrunePatterns(\u03b8,P); 6 P \u2190\u2212 ExtendProjection(i, \u03b8,P);\nAlgorithm 2: \u03a3\u03bf\u03c6\u03b9\u03b1 for finding itemsets in D with the bounded cardinality of the set P.\nGiven a dataset D and a measure anti-monotonic w.r.t. a chain of projections, if we are able to find all preimages of any element in the fixed set of a projection \u03c8i that belong to a fixed set of the next projection \u03c8i+1, then we can find all itemsets of the dataset D with a value ofM higher than a given threshold \u03b8. We call the respective algorithm \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 (Algorithm 1). In line 9 we find all itemsets for the dataset \u03c80(D) satisfying the constraint w.r.t. the measure M. Then in lines 10-11 we iteratively extend projections from simpler to more\ndetailed ones. The extension is done by constructing the set Pi of preimages of the set Pi\u22121 (lines 2-4) and then by removing the itemsets that do not satisfy the constraint from Pi (lines 5-7). This listing provides a sketch of the algorithm omitting possible engineering improvements for the sake of simplicity. Most of the known improvements are applicable here, i.e., the ones from [UKA05]. In particular, a canonical order on itemsets is used for mining closed pattern (the theoretical basis for such mining is given in next subsections).\nThe algorithm is sound and complete, since first, an itemset p is included into the set of preimages of p (since \u03c8(p) = p) and second, if M(p) < \u03b8, then we remove the itemset p from the set P and the measure value of any preimage of p is less than \u03b8 by the projection chain anti-monotonicity of M. The worst case time complexity for the general case of patterns of \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 algorithm is\nT(\u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1) = T(FindPatterns(\u03c80))+\n+ k \u00b7 max 0<i\u2264k |Pi| \u00b7 (T(Preimages) + T(M)), (2)\nwhere k is the number of projections in the chain, T(X ) is the time for computing the operation X . Since projection \u03c80 can be chosen to be very simple, in a typical case the complexity of FindPatterns(\u03b8, \u03c80) can be low or even constant. The complexities of Preimages and M depend on the measure, the chain of projections, and the kind of patterns. In many cases max\n0<i\u2264k |Pi| can\nbe exponential in the size of the input, because the number of patterns can be exponential. It can be a difficult task to define the threshold \u03b8 such that the maximal cardinality of Pi is not larger than a given number. Thus, we introduce \u03a3\u03bf\u03c6\u03b9\u03b1 algorithm (Algorithm 2), which automatically adjusts threshold \u03b8 ensuring that max\n0<i\u2264k |Pi| < L. Here L can be considered as a constraint on the\nmemory used by the algorithm. The only difference of \u03a3\u03bf\u03c6\u03b9\u03b1 w.r.t. \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 is that after performing an operation that changes the set P (lines 2 and 6 in Algorithm 2) it adjusts \u03b8 in such a way that the cardinality of P does not exceed the parameter L. It can be seen from (2) that \u03a3\u03bf\u03c6\u03b9\u03b1 has polynomial time complexity if M and Preimages are polynomial. Indeed, according to (1) if a projection removes only one item, the cardinality of Preimages is always 2. Thus, the worst case complexity for \u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1 is\nT(\u03b8-\u03a3\u03bf\u03c6\u03b9\u03b1binary) = |I| \u00b7 max0<i\u2264N|Pi| \u00b7 T(M). (3)\nWe notice that every Pi is a solution for the projected dataset. Thus, this algorithm has incremental polynomial delay. However, if we fix the available memory L, the complexity of \u03a3\u03bf\u03c6\u03b9\u03b1 for binary data is |I| \u00b7 L \u00b7 T(M), i.e., it becomes input polynomial modulo complexity of the measure.\nTo wrap up, in this subsection we have introduced an algorithm for finding top-K itemsets in polynomial time. It is important to notice that the found set of itemsets is exactly the best itemsets w.r.t. to \u0394-measure and should not be mixed up with an approximation.\nEfficiency Considerations\nRecently much work have been done in finding good strategies of enumerating (closed) patterns. Most of them start from the smallest patterns and then iteratively generate larger patterns. It can be naturally expressed as a chain of functions \u03c8i that are contractive (\u03c8i(X) v X) and idempotent (\u03c8i(\u03c8i(X)) = \u03c8i(X)). These functions can be ordered by inclusion of fixed sets because of idempotency. Since these functions are contractive, only patterns larger than a pattern X are preimages of X. Thus, most of the approaches for itemset mining can be formalized by means of a chain of such functions. However, in this work we require a chain of projections, i.e., functions \u03c8i, to be also monotonic. It allows us to efficiently mine robust and stable patterns discussed in Section 4. This additional monotonicity still allows one to formalize developed approaches for itemset mining as a chain of projections. However, in this work we does not discuss this formalization and focus on the efficient mining of patterns for nonmonotonic constraints."}, {"heading": "3.3 \u03a3\u03bf\u03c6\u03b9\u03b1 Algorithm for Closed Itemsets", "text": "Closed frequent itemsets are widely used as a condensed representation of all frequent itemsets since [PBTL99]. Here we show how one can adapt our algorithm for closed patterns. A closed pattern in \u03c8i\u22121(D) is not necessarily closed in \u03c8i(D). Indeed, if we take the example in Figure 1, the pattern {i1} is closed in (T, {i1, i2}, R2) but no more closed in (T, {i1, i2, i3}, R3). However, the extents (closed tidsets) of \u03c8(D) are extents of D [GK01]. Thus, we associate the closed patterns with extents, and then work with extents instead of patterns, i.e., a dataset D = (T, (2I ,\u2229), \u03b4) is transformed into DC = (T, (DC ,uC), \u03b4C), where DC = 2\nT . Moreover, for all a, b \u2208 DC we have a uC b = t(d(a) u d(b)), where t and d operators are computed in D and \u03b4C(t \u2208 T ) = {t}. Hence, every pattern p in DC corresponds to a closed pattern d(p) in 2\nI . A projection \u03c8 of D induces a projection \u03c8C of DC , given by \u03c8C(A \u2286 T ) = t(\u03c8(d(A))) with t and d computed for D.\nIn the next section we discuss some measures that are anti-monotonic w.r.t. a projection (rather than just anti-monotonic). In the end of the next section we provide an example of how \u03a3\u03bf\u03c6\u03b9\u03b1 works."}, {"heading": "4 Itemset Constraints", "text": ""}, {"heading": "4.1 Cosine Interest of an Itemset", "text": "The first projection-antimonotonic measure we consider is cosine interest [CWW14]. It is defined by\nCosine(X) = |t(X)| |X| \u221a\u220f\ni\u2208X |t({i})| , (4)\ni.e., a cosine interest of X is the support of X over the geometric mean of supports of single items from X. As the authors of [CWW14] have shown this measure is not (anti-)monotonic. Then, they also have shown that if we traverse the search space from less supported items to more supported items the cosine interest never decreases. Indeed, given an itemset X and an item i such that i 6\u2208 X and (\u2200j \u2208 X)|t({i})| \u2265 |t({j})|, we can see that Cosine(X) \u2265 Cosine(X \u222a {i}) since the itemset support cannot increase while the geometric mean cannot decrease in this case.\nTo work with cosine interest we can define a projection chain that adds items from less supported ones to more supported, i.e., \u03c81 corresponds to removal of all but the least frequent item from the dataset, \u03c82 corresponds to removal of all but two least frequent items and so on. Then, cosine interesting itemsets can be mined by \u03a3\u03bf\u03c6\u03b9\u03b1. However this measure is locally anti-monotonic, in the next subsection we consider two proper nonmonotonic measures."}, {"heading": "4.2 Stability and Robustness of an Itemset", "text": "Stability [Kuz07] and robustness [TMC14] are similar measures when applied to closed itemsets. They measure independence of an itemset w.r.t. subsampling. Stability can only be applied to closed itemsets, while robustness is defined for any type of itemset constraints (closed itemsets, generators, etc.). However, in case of closed itemsets neither of them is (anti-)monotonic. Indeed, when robustness is based on an anti-monotonic constraint, it is anti-monotonic. However, closedness of itemsets is not an anti-monotonic constraint. Since stability and robustness are similar, we define them on a similar basis.\nGiven a dataset D = (T, I, R), a triple (S, I, R) where S \u2286 T is called a subdataset of D. If we give a weight to every subdataset of D, then we can find the sum of weights of all subdatasets of D where an itemset X is closed. This sum gives us stability or robustness of the closed itemset X depending on how we define the weights of subdatasets.\nIn the case of stability the weights w of all subdatasets Ds of D are equal, i.e., w(Ds) = 2\u2212|T |. In this case we consider every subdataset equally probable and compute the probability that the itemset X is closed.\nExample 2. Consider example in Figure 1a. The set of concepts (the pattern of every concept is a closed itemset) is shown in Figure 1b. Stability of every closed itemset is shown in Table 1. Let us consider the highlighted itemset X = {i3}. There are 25 possible subdatasets. Only in the following 10 subdatasets X is not closed (only the set of transactions for every subdataset is given):\n\u2205, {t1}, . . . , {t5}, {t1, t5}, {t2, t5}, {t3, t5}, {t4, t5}. Thus, stability of X can be found as Stab(X) = 1\u2212 10 \u00b7 2\u22125 = 0.69.\nIt should be noticed that stability of all comparable itemsets in the lattice is smaller than stability of X, which highlights the nonmonotonicity of stability.\nIn the case of robustness the weights w of subdatasets are computed differently. These weights depend on a parameter 0 \u2264 \u03b1 \u2264 1 denoting the probability of a transaction to be retained in the dataset. The weight of a subdataset Ds = (S, I, R) of D = (T, I, R) corresponds to the probability of obtaining Ds by removing every single transaction from D with probability 1\u2212 \u03b1: w(Ds) = \u03b1|S| \u00b7 (1\u2212 \u03b1)|T |\u2212|S|.\nExample 3. Consider example in Figure 1a. Robustness for \u03b1 = 0.9 for every closed itemset is shown in Table 1. Let us consider the highlighted itemset X = {i3}. It is not closed in the same as above 10 subdatasets but their weights are different (the weights are shown in superscripts): \u2205w=10 \u22125 , {t1}w=9\u00b710 \u22125 , . . . , {t5}w=9\u00b710 \u22125 , {t1, t5}w=8.1\u00b710 \u22124 , {t2, t5}w=8.1\u00b710 \u22124 , {t3, t5}w=8.1\u00b710 \u22124 , {t4, t5}w=8.1\u00b710 \u22124 . Thus, robustness of X for \u03b1 = 0.9 is equal to Rbst\u03b1=0.9(X) = 0.9963. It can be verified that robustness is not an anti-monotonic measure.\nIt is not hard to show that independently of the weights w of subdatasets, stability and robustness are anti-monotonic measures w.r.t. any projection.\nProposition 2. Stability and robustness are anti-monotonic measures w.r.t. any projection.\nProof. Here we want to show that for any projection \u03c8 if a pattern X is closed in a subdataset Ds then \u03c8(X) is closed in \u03c8(Ds), where Ds = (S, I, R) is a subdataset of D = (T, I, R) with S \u2286 T . We note that if X is closed in Ds it is also closed in D. And since \u03c8(X) closed in \u03c8(D), then for projection \u03c8C from Section 3.3 we have d(\u03c8C(t(X))) = \u03c8(X). Hence, we can work with images of \u03c8 on closed patterns in order to find the corresponding images of \u03c8C .\nLet Y = d(t(\u03c8(X)) \u2229 S) be a closure of \u03c8(X) in Ds. Since \u03c8(X) v X, then t(\u03c8(X)) \u2287 t(X). Hence S \u2229 t(\u03c8(X)) \u2287 S \u2229 t(X). Then Y = d(S \u2229 t(\u03c8(X))) v d(S \u2229 t(X)) = X, since Y is the closure of \u03c8(X) in \u03c8(Ds) and X is the closure of X in Ds. Thus, we have Y v X and ct(Y ) v ct(X) = X. Because of monotonicity of projections one has \u03c8(ct(Y )) v \u03c8(X) and hence Y v \u03c8(X).\nSince Y is the closure of \u03c8(X) in Ds, then Y w \u03c8(X). Hence Y = \u03c8(X).\nEstimates of Stability and Robustness\nFor both stability and robustness it is shown that the corresponding constraint is NP-hard [Kuz07, TMC14]. Thus, for efficient mining, estimates of stability and robustness are essential. Here we introduce a fast computable estimate of robustness in the same way we did it for stability in [BKN14].\nLet us consider closed itemsets X and Y such that X \u2282 Y . Can we define the subdatasets where X is not closed? Let us define \u2206(X,Y ) as the cardinality of the set of transactions described by X but not by Y : \u2206(X,Y ) = t(X) \\ t(Y ).\nThis set is not empty since X 6= Y and they are closed. It is clear that X is not closed in any subdataset that removes all transactions from \u2206(X,Y ), since Y is a larger itemset with the same support. Then, Stab(X) \u2264 1\u2212 2\u2212\u2206(X,Y ) and Rbst(X) \u2264 1 \u2212 (1 \u2212 \u03b1)\u2206(X,Y ) for any closed itemset Y \u2283 X. In particular, we can put Y to the closest closed superitemset of X.\nIn the same way we can take all immediate closed superitemsets of X and take into account all the subdatasets where X is not closed. Since some of the subdatasets are probably counted several times we get the lower bound, i.e., Stab(X) \u2265 1\u2212\n\u2211 Y\u227aX 2\u2212\u2206(X,Y ) and Rbst(X) \u2265 1\u2212 \u2211 Y\u227aX (1\u2212 \u03b1)\u2206(X,Y ).\nProposition 3. Stability and robustness are bounded as follows, where X \u227a Y means that X is an immediate closed subitemset of Y :\n1\u2212 \u2211\nY\u227aX 2 \u2212\u2206(X,Y ) \u2264 Stab(X) \u2264 1\u2212 2\u2212\u2206(X,Y ) (5)\n1\u2212 \u2211\nY\u227aX (1\u2212 \u03b1)\u2206(X,Y ) \u2264 Rbst(X) \u2264 1\u2212 (1\u2212 \u03b1)\u2206(X,Y ) (6)\nIn particular we can see that when \u03b1 = 0.5 the estimates are exactly the same. As it is recently shown [BKN14], the estimate of stability is quite precise for the concepts with stability close to 1. Then, when \u03b1 > 0.5 the precision of the estimate of robustness is even more precise.\nThese estimates can be computed in polynomial time in contrast to stability and robustness. And thus we can use one of the bounds as a proxy to stability and robustness. It can be seen that the rankings based on the upper bound of stability and robustness are exactly the same as the ranking based on \u2206(X) = min Y\u227aX \u2206(X,Y ). Although for the lower bound of stability and robustness it is hard to show the projection anti-monotonicity, we can show it for the upper bound. In the following \u2206(X) is called \u0394-measure.\nProposition 4. \u0394-measure is an anti-monotonic measure w.r.t. any projection.\nProof. We remind that for dealing with closed patterns the tidsets are considered as patterns as discussed in Section 3.3. By properties of projections, if an extent (the tidset of a concept) is found in \u03c8(D), it is necessarily found in D [GK01]. Let us consider a tidset E of a concept and a tidset of its descendant Ec in \u03c8(D), where a descendant concept is a concept with a smaller tidset and larger itemset. Let us suppose that Ep is a preimage of E for the projection \u03c8. Since Ec and Ep are extents in D, the set Ecp = Ec \u2229 Ep is an extent in D (the intersection of two closed sets is a closed set). Since Ep is a preimage of E, then Ep 6\u2286 Ec (otherwise, Ep is a preimage of Ec and not of E). Then, Ecp 6= Ep and Ecp \u2286 Ep. Hence, \u2206(Ep) \u2264 |Ep \\Ecp| \u2264 |E \\Ec|. So, given a preimage Ep of E, (\u2200Ec < E)\u2206(Ep) \u2264 |E \\Ec|, i.e., \u2206(Ep) \u2264 \u2206(E). Thus, we can use \u0394-measure in combination with \u03a3\u03bf\u03c6\u03b9\u03b1 algorithm.\nExample 4. Consider example in Figure 1a. \u0394-measure for every closed itemset is shown in Table 1. Let us consider the highlighted itemset X = {i3} with support equal to 4. The closest superitemsets of X are {i1, i3}, {i2, i3}, {i3, i4},\nand {i3, i5}, all having support equal to one. Thus, \u0394-measure of X is equal to \u2206(X) = 4\u22121 = 3. It can be noticed that \u0394-measure is not an (anti-)monotonic measure.\n\u0394-measure is related to the work of margin-closeness of an itemset [MTU11]. In this work, given a set of patterns, e.g., frequent closed patterns, the authors rank them by the minimal distance in their support to the closest superpattern divided by the support of the pattern. In our case, the minimal distance is exactly the \u0394-measure of the pattern."}, {"heading": "4.3 Example of Stable Itemsets in Binary Data", "text": "Let us consider the example in Figure 1 and show how we can find all \u0394-stable itemsets with threshold \u03b8 = 2. We have a binary dataset D = (T, {i1, \u00b7 \u00b7 \u00b7 , i6}, R). Let us denote Ii = {i1, \u00b7 \u00b7 \u00b7 , ii}. The sets Ii correspond to a chain of projections.\nIn Table 2 all closed itemsets are given by the corresponding tidsets, i.e., by elements of DC . For simplicity we write 1234 instead of {t1, t2, t3, t4}. For every element \u0394-measure is shown for every Ii. A cell is shown in gray if the itemset is no more considered (the value of \u0394 is less than 2).\nFor example, in the transition from I2 to I3 the set 1234 is discovered with \u2206(1234) = 3, but \u2206(12345) = 5\u2212 4 = 1 which is less than \u03b8 = 2. Thus, itemset 12345 is discarded and highlighted gray. The global process is as follows (for the example in Figure 1). In the empty binary dataset (T, \u2205, R) the first itemset 12345 is considered. Then, in (T, {i1}, R) a possible preimage of 12345 can be either 12345 or 12345 \u2229 t({i1}) = 1. The set 12345 is \u0394-stable (\u2206(12345) = 4), while 1 is not \u0394-stable (\u2206(1) = 1) and is discarded. Then, the process continues with (T, {i1, i2}, R) and 12345 is kept while 12345 \u2229 t({i2}) = 2 is removed for the same reason as 1. After that, with (T, {i1, i2, i3}, R) two preimages are still considered, 12345 and 1234. This time \u2206(1234) = 3, while \u2206(12345) = 1\nand the set 12345 is discarded. The process continues in the same way with \u2206(1234) = 3 and all other possible elements are discarded."}, {"heading": "5 Experiments and Discussion", "text": ""}, {"heading": "5.1 Comparing Computational Efficiency", "text": "In the first experiment we show the computational efficiency of \u03a3\u03bf\u03c6\u03b9\u03b1 coded in C++1. We use public available big datasets from FIMI2, LUCS [Coe03], and UCI [FA10] repositories. The experiments are carried out on an \u201cIntel(R) Core(TM) i7-2600 CPU @ 3.40GHz\u201d computer with 8Gb of memory under Ubuntu 14.04.\nWe should note two points here. First, to the best of our knowledge \u03a3\u03bf\u03c6\u03b9\u03b1 is the first algorithm that computes top \u0394-stable and robust itemsets, so there are no direct competitors. Moreover, computing \u0394-measure for an itemset requires either a known partial order of itemsets or a search for its descendants (closed supersets). Thus, as an approximate competitors we decided to use two algorithms LCMv3 [UKA05] and Charm-L [ZH05]. The first one is one of the most efficient algorithm for itemset mining that should be followed by \u0394-measure computation for every concept. Charm-L is less efficient than LCMv3, but allows\n1 The implementation is available at https://github.com/AlekseyBuzmakov/FCAPS 2 http://fimi.ua.ac.be/data/\none to find the partial order of itemsets necessary for the fast computation of \u0394-measure.\nSecond, the current implementation of \u03a3\u03bf\u03c6\u03b9\u03b1 does not use most of the modern optimization techniques, e.g., like in LCMv3 [UKA05]. The current implementation relies only on the so-called conditional database, i.e., where for every tidset X the items that belong to all transactions from t(X) and the items that belong to neither transactions from t(X) are recorded [UKA05]. But nevertheless, the computation with the current implementation is efficient.\nThe experiment is organized as following. First, \u03a3\u03bf\u03c6\u03b9\u03b1 finds around the 1000 most \u0394-stable itemsets and the maximal support threshold ensuring to find all these the most \u0394-stable itemsets. Among them we find the most \u0394-stable itemset (or itemsets if they have the same value of\u0394-measure) and the corresponding support threshold. So LCMv3 and Charm-L are additionally provided with an oracle returning the required support thresholds. For these two thresholds we run LCMv3 and Charm-L algorithm and register the computation time. In addition for LCMv3 we register also the time needed for computing \u0394-measure, while for Charm-L this time is insignificant. In Table 3 for every dataset we give the results corresponding to every threshold, and the corresponding thresholds for support and \u0394-measure. For example, for dataset chess we run two experiments. In the first one we search for top-3 \u0394-stable itemsets having the same value (234) for \u0394-measure. The less frequent itemsets among these three has support equal to 1145, thus, LCMv3 and Charm-L should be run with this support threshold in order to enumerate all of these itemsets. LCMv3 finds the corresponding frequent closed itemset in 1.67 seconds, then it takes more than 100 seconds for computing \u0394-measure. Charm-L takes more than 100 seconds and \u03a3\u03bf\u03c6\u03b9\u03b1 requires only 0.03 seconds. In the second experiment for dataset chess we search for top-928 \u0394-stable itemsets, all of them have support at least 277 and \u0394-measure 98.\nWe boldify the computation time for an algorithm in Table 3, if it is better than the time of the competitors. We can see that even LCMv3 alone does not always beat \u03a3\u03bf\u03c6\u03b9\u03b1, while the additional time for LCMv3 for computing \u0394measure is always significant. There are only two cases when \u03a3\u03bf\u03c6\u03b9\u03b1 is slightly worse (FIMI-mushroom and LUCS-waveform). For both cases the most stable itemset has a very high support and only a couple of itemsets are frequent enough in both datasets. In contrast, if the frequency of the most \u0394-stable itemsets is not high, then \u03a3\u03bf\u03c6\u03b9\u03b1 is many times faster than even LCMv3 alone.\nIn these experiments we do not provide the found itemsets since the main focus of our paper is efficiency. However, we highlight that \u0394-stable patterns are not trivial and can be found deep in the lattice of patterns [MLB+15]."}, {"heading": "5.2 Scalability", "text": "We can study scalability of \u03a3\u03bf\u03c6\u03b9\u03b1 from different points of view. First, we can measure the time necessary for finding top-L concepts, i.e., how the memory limitation L changes the efficiency. It is shown in Table 4 for the same datasets. We can see that the computation time changes linearly w.r.t. the memory limitation L as it is expected from Eq. (3).\nFinally, we check how computation time depends on the size of the dataset. For that we run our experiments for L = 1000, and vary the number of transactions in a dataset. We permute several time the order of transactions of the dataset. For every permutation we construct datasets containing certain amount (the size of the dataset) of the first transactions from this permutation. The computation time is averaged over the permutations. Figure 2 shows the computation time necessary to process a certain fraction of transactions in the dataset. Time is given as a fraction of time for processing the whole dataset. We can see that computation time changes linearly w.r.t. the fraction of processed transactions. \u03a3\u03bf\u03c6\u03b9\u03b1 allows limiting the memory in use; thus, as long as the program fits within the memory, which is controllable, the scalability of our approach is linear w.r.t. to the size of the dataset, and consequently can be applied to very huge datasets."}, {"heading": "6 Conclusion", "text": "In this paper we have introduced a new class of interestingness measures, socalled projection-antimonotonic measures. This wide class of measures includes classical anti-monotonic, locally anti-monotonic, and some nonmonotonic measures. We have introduced algorithm \u03a3\u03bf\u03c6\u03b9\u03b1, which allows one to efficiently mine patterns w.r.t. projection-antimonotonic measures. We have studied stability and robustness, two projection-antimonotonic measures, and have introduced polynomial estimates of them, called \u0394-measure. Finally, in the experimental part we have showed that \u03a3\u03bf\u03c6\u03b9\u03b1 can find\u0394-stable itemsets much more efficiently than postpruning approaches.\nMany directions for future work are promising. First, we should work on adaptation of \u03a3\u03bf\u03c6\u03b9\u03b1 for dealing with different kinds of pattern structures, e.g., based on sequences or graphs [KS05]. Second, \u03a3\u03bf\u03c6\u03b9\u03b1 allows one to introduce new data mining approaches by means of projections of special kind, thus, it is interesting to study possible classes of projections. Finally, besides robustness\nand stability we a study of other projection-antimonotonic measures is important."}], "references": [{"title": "Fast algorithms for mining association rules", "author": ["Rakesh Agrawal", "Ramakrishnan Srikant"], "venue": "In Proc. 20th int. conf. very large data bases, VLDB,", "citeRegEx": "Agrawal and Srikant.,? \\Q1994\\E", "shortCiteRegEx": "Agrawal and Srikant.", "year": 1994}, {"title": "Listing closed sets of strongly accessible set systems with applications to data mining", "author": ["Mario Boley", "Tam\u00e1s Horv\u00e1th", "Axel Poign\u00e9", "Stefan Wrobel"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "Boley et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Boley et al\\.", "year": 2010}, {"title": "Scalable Estimates of Concept Stability", "author": ["Aleksey Buzmakov", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "Form. Concept Anal.,", "citeRegEx": "Buzmakov et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Buzmakov et al\\.", "year": 2014}, {"title": "The LUCS-KDD Discretised and normalised ARM and CARM Data Library", "author": ["F. Coenen"], "venue": "Department of Computer Science, The University of Liverpool,", "citeRegEx": "Coenen.,? \\Q2003\\E", "shortCiteRegEx": "Coenen.", "year": 2003}, {"title": "DataPeeler: Constraint-Based Closed Pattern Mining in n-ary Relations", "author": ["L\u00f6\u0131c Cerf", "C\u00e9line Robardet", "Jean-Fran\u00e7ois Boulicaut"], "venue": "In SDM\u201908 Proc. Eighth SIAM Int. Conf. Data Min.,", "citeRegEx": "Cerf et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cerf et al\\.", "year": 2008}, {"title": "Scaling up cosine interesting pattern discovery: A depth-first method", "author": ["Jie Cao", "Zhiang Wu", "Junjie Wu"], "venue": "Inf. Sci. (Ny).,", "citeRegEx": "Cao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2014}, {"title": "Pattern Structures and Their Projections", "author": ["Bernhard Ganter", "Sergei O. Kuznetsov"], "venue": "Concept. Struct. Broadening Base,", "citeRegEx": "Ganter and Kuznetsov.,? \\Q2001\\E", "shortCiteRegEx": "Ganter and Kuznetsov.", "year": 2001}, {"title": "Formal Concept Analysis: Mathematical Foundations", "author": ["Bernhard Ganter", "Rudolf Wille"], "venue": "Springer, 1st edition,", "citeRegEx": "Ganter and Wille.,? \\Q1999\\E", "shortCiteRegEx": "Ganter and Wille.", "year": 1999}, {"title": "Revisiting Numerical Pattern Mining with Formal Concept Analysis", "author": ["Mehdi Kaytoue", "Sergei O. Kuznetsov", "Amedeo Napoli"], "venue": "IJCAI", "citeRegEx": "Kaytoue et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kaytoue et al\\.", "year": 2011}, {"title": "Learning Closed Sets of Labeled Graphs for Chemical Applications", "author": ["Sergei O. Kuznetsov", "Mikhail V. Samokhin"], "venue": "Inductive Log. Program. SE - 12,", "citeRegEx": "Kuznetsov and Samokhin.,? \\Q2005\\E", "shortCiteRegEx": "Kuznetsov and Samokhin.", "year": 2005}, {"title": "On stability of a formal concept", "author": ["Sergei O. Kuznetsov"], "venue": "Ann. Math. Artif. Intell.,", "citeRegEx": "Kuznetsov.,? \\Q2007\\E", "shortCiteRegEx": "Kuznetsov.", "year": 2007}, {"title": "Discovering structural alerts for mutagenicity using stable emerging molecular patterns", "author": ["Jean-Philippe M\u00e9tivier", "Alban Lepailleur", "Aleksey Buzmakov", "Guillaume Poezevara", "Bruno Cr\u00e9milleux", "Sergei Kuznetsov", "J\u00e9r\u00e9mie Le Goff", "Am\u00e9d\u00e9o Napoli", "Ronan Bureau", "Bertrand Cuissart"], "venue": "J. Chem. Inf. Model.,", "citeRegEx": "M\u00e9tivier et al\\.,? \\Q2015\\E", "shortCiteRegEx": "M\u00e9tivier et al\\.", "year": 2015}, {"title": "Efficient mining of all margin-closed itemsets with applications in temporal knowledge discovery and classification by compression", "author": ["Fabian Moerchen", "Michael Thies", "Alfred Ultsch"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "Moerchen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Moerchen et al\\.", "year": 2011}, {"title": "Efficient Algorithms for Discovering Association Rules", "author": ["Heikki Mannila", "Hannu Toivonen", "A Inkeri Verkamo"], "venue": "In Knowl. Discov. Data Min.,", "citeRegEx": "Mannila et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Mannila et al\\.", "year": 1994}, {"title": "Efficient Mining of Association Rules Using Closed Itemset Lattices", "author": ["Nicolas Pasquier", "Yves Bastide", "Rafik Taouil", "Lotfi Lakhal"], "venue": "Inf. Syst.,", "citeRegEx": "Pasquier et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Pasquier et al\\.", "year": 1999}, {"title": "On succinct representation of knowledge community taxonomies with formal concept analysis", "author": ["Camille Roth", "Sergei A. Obiedkov", "Derrick G. Kourie"], "venue": "Int. J. Found. Comput. Sci.,", "citeRegEx": "Roth et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2008}, {"title": "Optimizing constraint-based mining by automatically relaxing constraints", "author": ["Arnaud Soulet", "Bruno Cr\u00e9milleux"], "venue": "In Proc. 5th IEEE Inter- Natl. Conf. Data Min. (ICDM", "citeRegEx": "Soulet and Cr\u00e9milleux.,? \\Q2005\\E", "shortCiteRegEx": "Soulet and Cr\u00e9milleux.", "year": 2005}, {"title": "Adequate condensed representations of patterns", "author": ["Arnaud Soulet", "Bruno Cr\u00e9milleux"], "venue": "Data Min. Knowl. Discov.,", "citeRegEx": "Soulet and Cr\u00e9milleux.,? \\Q2008\\E", "shortCiteRegEx": "Soulet and Cr\u00e9milleux.", "year": 2008}, {"title": "Interesting pattern mining in multi-relational data", "author": ["Eirini Spyropoulou", "Tijl De Bie", "Mario Boley"], "venue": "Data Min. Knowl. Discov.,", "citeRegEx": "Spyropoulou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Spyropoulou et al\\.", "year": 2013}, {"title": "Finding Robust Itemsets under Subsampling", "author": ["Nikolaj Tatti", "Fabian Moerchen", "Toon Calders"], "venue": "ACM Trans. Database Syst.,", "citeRegEx": "Tatti et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tatti et al\\.", "year": 2014}, {"title": "LCM Ver.3: Collaboration of Array, Bitmap and Prefix Tree for Frequent Itemset Mining", "author": ["Takeaki Uno", "Masashi Kiyomi", "Hiroki Arimura"], "venue": "In Proc. 1st Int. Work. Open Source Data Min. Freq. Pattern Min. Implementations,", "citeRegEx": "Uno et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Uno et al\\.", "year": 2005}, {"title": "Interesting Patterns", "author": ["Jilles Vreeken", "Nikolaj Tatti"], "venue": "Freq. Pattern Min.,", "citeRegEx": "Vreeken and Tatti.,? \\Q2014\\E", "shortCiteRegEx": "Vreeken and Tatti.", "year": 2014}, {"title": "Mining significant graph patterns by leap search", "author": ["Xifeng Yan", "Hong Cheng", "Jiawei Han", "Philip S. Yu"], "venue": "In Proc. 2008 ACM SIGMOD Int. Conf. Manag. data - SIGMOD", "citeRegEx": "Yan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Yan et al\\.", "year": 2008}, {"title": "Efficient algorithms for mining closed itemsets and their lattice structure", "author": ["Mohammed J. Zaki", "Ching-Jui Hsiao"], "venue": "IEEE Trans. Knowl. Data Eng.,", "citeRegEx": "Zaki and Hsiao.,? \\Q2005\\E", "shortCiteRegEx": "Zaki and Hsiao.", "year": 2005}], "referenceMentions": [], "year": 2017, "abstractText": "The exponential explosion of the set of patterns is one of the main challenges in pattern mining. This chalenge is approached by introducing a constraint for pattern selection. One of the first constraints proposed in pattern mining is support (frequency) of a pattern in a dataset. Frequency is an anti-monotonic function, i.e., given an infrequent pattern, all its superpatterns are not frequent. However, many other constraints for pattern selection are neither monotonic nor anti-monotonic, which makes it difficult to generate patterns satisfying these constraints. In order to deal with nonmonotonic constraints we introduce the notion of \u201cprojection antimonotonicity\u201d and \u03a3\u03bf\u03c6\u03b9\u03b1 algorithm that allow generating best patterns for a class of nonmonotonic constraints. Cosine interest, robustness, stability of closed itemsets, and the associated \u0394-measure are among these constraints. \u03a3\u03bf\u03c6\u03b9\u03b1 starts from light descriptions of transactions in dataset (a small set of items in the case of itemset description) and then iteratively adds more information to these descriptions (more items with indication of tidsets they describe). In the experiments, we compute best itemsets w.r.t. some measures and show the advantage of our approach over postpruning approaches.", "creator": "LaTeX with hyperref package"}}}