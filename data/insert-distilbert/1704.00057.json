{"id": "1704.00057", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2017", "title": "Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems", "abstract": "this paper presents when the frames dataset ( frames is available at", "histories": [["v1", "Fri, 31 Mar 2017 21:03:58 GMT  (102kb,D)", "https://arxiv.org/abs/1704.00057v1", null], ["v2", "Thu, 13 Apr 2017 18:22:49 GMT  (104kb,D)", "http://arxiv.org/abs/1704.00057v2", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["layla el asri", "hannes schulz", "shikhar sharma", "jeremie zumer", "justin harris", "emery fine", "rahul mehrotra", "kaheer suleman"], "accepted": false, "id": "1704.00057"}, "pdf": {"name": "1704.00057.pdf", "metadata": {"source": "CRF", "title": "GOAL-ORIENTED DIALOGUE SYSTEMS", "authors": ["Layla El Asri", "Hannes Schulz", "Shikhar Sharma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman"], "emails": ["first.last@microsoft.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "Goal-oriented, information-retrieving dialogue systems have traditionally been designed to help users find items in a database given a certain set of constraints (El Asri et al., 2014; Laroche et al., 2011; Raux et al., 2003; Singh et al., 2002). For instance, the LET\u2019S GO dialogue system finds a bus schedule given a bus number and a location (Raux et al., 2003).\nThese systems model dialogue as a sequential process: the system asks for constraints until it can query the database and return a few results to the user. Then, the user can ask for more information about a given result or ask for other possibilities. If the user wants to know about database items corresponding to a different set of constraints (e.g., another bus line), then these constraints simply overwrite the previous ones. As a consequence, users can neither compare results corresponding to different constraints, nor go back-and-forth between results.\nWe can assume users in the bus domain know exactly what they want. In contrast, user studies in e-commerce have shown that several information-seeking behaviours are encountered: users may come with a very well defined item in mind, but they may also visit an e-commerce website with the intent to compare items and explore different possibilities (Moe and Fader, 2001). Supporting this kind of decision-making process in conversational systems implies adding memory. Memory is necessary to track different items or preferences set by the user during the dialogue. For instance, consider product comparisons. If a user wants to compare different items using a dialogue system, then this system should be able to separately recall properties pertaining to each item.\nThis paper presents the Frames dataset, which comprises dialogues that require this type of memory. Frames is a corpus of 1369 human-human dialogues collected in a Wizard-of-Oz (WOz) setting \u2013 i.e., users were connected to humans, whom we refer to as the wizards, who were assuming the role of the dialogue system. The wizards had access to a database of vacation packages containing round-trip flights and a hotel. The users were asked to find packages based on a few constraints such as a destination and a budget.\nIn order to test the memory capabilities of conversational agents, we formalize a new task called frame tracking. In frame tracking, the agent must simultaneously track multiple semantic frames\n1Frames is available at http://datasets.maluuba.com/Frames.\nar X\niv :1\n70 4.\n00 05\n7v 2\n[ cs\n.C L\n] 1\n3 A\npr 2\nthroughout the dialogue. For example, two frames would be constructed and recalled while comparing two products \u2013 each containing the properties of a specific item. Frame tracking is a generalization of the state tracking task (Henderson, 2015). In state tracking, all the information summarizing a dialogue history is compressed into one semantic frame. In contrast, several frames are kept in memory during frame tracking, with each frame corresponding to a particular context, e.g., one or more vacation packages.\nAnother important property of human dialogue that we want to study with the Frames dataset is how to provide the user with information on the database. When a set of user constraints leads to no results, users would benefit from knowing that relaxing a given constraint (e.g., increasing the budget by a reasonable amount) would lead to results instead of navigating the database blindly. This recommendation behaviour is in accordance with Grice\u2019s cooperative principle (Grice, 1989): \u201cMake your contribution as informative as is required (for the current purposes of the exchange)\u201d. We study this by including suggestions when the database returns no results for a given user query.\nThis paper describes the Frames dataset in detail, formally defines the frame tracking task, and provides a baseline model for frame tracking. The next section discusses motivation for the Frames dataset. Section 3 explains the data collection process and Section 4 describes the dataset in detail. We describe the annotation scheme in Section 5. In Section 6, we identify the main research topics of the corpus and formalize the frame tracking task. The dialogue data format is described in Section 7. Section 8.1 proposes a baseline model for frame tracking. Finally, we conclude in Section 9 and suggest directions for future work."}, {"heading": "2 MOTIVATION", "text": "Much work has focused on spoken dialogue (Lemon and Pietquin, 2007; Walker et al., 1998; Williams and Zweig, 2016), since spoken dialogue systems are useful in many settings, including in hands-free environments such as cars (Lemon et al., 2006). A generation of voice assistants \u2013 such as SIRI, Cortana, and Google Voice \u2013 have popularized spoken dialogue systems. More recently, users have become familiar with chatbots. Many platforms for deploying chatbots are now available, such as Facebook Messenger, Slack, or Kik. Text offers advantages over voice such as privacy and the ability to avoid bad speech recognition in noisy environments. Chatbots provide a welcome alternative to downloading and installing applications, and make a lot of sense for everyday services such as ordering a cab or knowing the weather. Chatbots have been proposed for tasks that one would traditionally perform through Graphical User Interfaces (GUIs). For instance, many chatbots for booking a flight are now entering the market.\nIn most cases, as with current voice-based assistants, the conversation with a chatbot is very limited: asking for the weather and ordering a cab are accomplished with simple, sequential slot-filling. These tasks have in common the fact that in both cases the user knows exactly what she wants, i.e., the destination for the cab or the city for the weather. Booking a flight is a bit different. Flight booking requires specifying many parameters, and these are usually determined during the search process2. Technically, finding a weather forecast is only about reading a database: the task is to form a complete database query and then to verbalise the result to the user. The user might start with very few constraints and then refine her query given the database results. In the case of booking a flight, there is a decision-making process requiring comparison and backtracking.\nGUIs are not optimal on many levels when it comes to helping users through this decision-making process. A first point of friction is the limited visual space. Consider the example of e-commerce websites. A user is very likely to compare different options before picking an item to buy. This often results in a large number of open browser tabs among which the user must navigate. In order to avoid this situation, some websites provide a comparator that can be used to display several items on a single page. However, this option is not optimal for hierarchical objects such as vacation packages because these objects have global properties (dates of the trips) but are also composed of different modules (flights and hotel) which have different properties (e.g., seat class and hotel category). Optimally, the user should be able to define the properties for the different modules while being able to compare items corresponding to each set of properties. A text interface could\n2One can easily imagine a user changing from economy to business class if the price difference is small.\ncomplement a GUI by offering this flexibility while remembering the properties mentioned by the user and displaying comparisons when asked.\nWe propose the Frames dataset to support work on text-based conversational agents which help a user make a decision. The decision-making process is tightly coupled with the notion of memory. Indeed, if a user intends to compare different options in the course of defining the options, the system should follow the user\u2019s path and remember every option. In this paper, we formalize this aspect of conversation in the frame tracking task. This task is the main challenge of the Frames corpus, and Section 6 describes it in detail."}, {"heading": "3 DATA COLLECTION", "text": "We collected data over a period of 20 days and with 12 participants. To increase variation in the dialogues, 8 participants were hired for only one week each, and one participant was hired for one day. The three remaining participants participated in the entire data collection. The participants were paired up for each dialogue and interacted through a chat interface."}, {"heading": "3.1 WIZARD-OF-OZ DATA COLLECTION", "text": "Data collection for goal-oriented dialogue is challenging. To control the data such that specific aspects of the problem can be studied, it is common to collect dialogues using an automated system. This requires, e.g., a natural language understanding module that already performs well on the task, which implies possession of in-domain data or the ability to generate it (Henderson et al., 2014b; Raux et al., 2003). Another possibility, which permits even greater control, is to generate dialogues using a rule-based system (Bordes and Weston, 2016). These approaches are useful for studying specific modules and analysing the behaviour of different architectures. However, it is costly to generate new dialogues for each experiment and skills acquired on artificial data are not directly usable in real settings because of natural language understanding noise (Bordes and Weston, 2016).\nThe Wizard-of-Oz (WOz) approach offers a powerful alternative (Kelley, 1984; Rieser et al., 2005; Wen et al., 2016). In WOz data collection, one participant (the wizard) plays the role of the dialogue system. The wizard has access to a search interface connected to the database. She receives the user\u2019s input in text form and decides what to say next. This does not require preexisting dialogue system components, except potentially automatic speech recognition for transcribing the user\u2019s inputs. Dialogues collected in WOz settings can be used for studying and developing every part of a dialogue system, from language understanding to language generation. They are also essential for offline training of end-to-end dialogue systems (Bordes and Weston, 2016; Wen et al., 2016) on different domains, which may reduce costs from handcrafting new systems for each domain.\nWOz dialogues also have the considerable advantage of exhibiting realistic behaviours that cannot be supported by current (end-to-end or not) architectures. Since there is no dialogue system that incorporates the type of memory that we want to study with this dataset, we need to work directly on human-human dialogues. Our setting is a bit different from the usual WOz setting because, in our case, the users did not think they were interacting with a dialogue system but instead knew that they were talking to a human-being. We made the choice not to give templated answers to the wizards because, apart from studying memory, we also want to study information presentation and dialogue management. We have chosen to work on text-based dialogues because this allows a more controlled wizard behaviour, obviates handling time-sensitive turn-taking and speech recognition noise, and allows studying more complex dialogue flows."}, {"heading": "3.2 TASK TEMPLATES AND INSTRUCTIONS", "text": "Dialogues were performed on Slack3. We deployed a Slack bot named wozbot to pair up participants and record conversations. The participants in the user role indicated when they were available for a new dialogue through this bot. They were then assigned to an available wizard and received a new task. The tasks were built from templates such as the following:\n3www.slack.com\n\u201cFind a vacation between [START DATE] and [END DATE] for [NUM ADULTS] adults and [NUM CHILDREN] kids. You leave from [ORIGIN CITY]. You are travelling on a budget and you would like to spend at most $[BUDGET].\u201d\nEach template had a probability of success. The tasks were generated by drawing values (e.g., BUDGET) from the database. The generated tasks were then added to a pool. The values were drawn in order to comply with the template\u2019s probability of success. For example, if 20 tasks were generated at probability 0.5, about 10 tasks would be generated with successful database queries and the other 10 would be generated so the database returned no results for the constraints. This mechanism allowed us to emulate cases when a user would not find anything meeting her constraints. If a task was unsuccessful, the user either ended the dialogue or got an alternate task such as:\n\u201cIf nothing matches your constraints, try increasing your budget by $200.\u201d\nWe wrote 38 templates. 14 templates were generic such as the one presented above and the other 24 were written to encourage more role-playing from users. One example is:\n\u201cPokemon are now a worldwide currency. You are the best Pokemon hunter in the world. You have caught them all except for one Pokemon worth a fortune: Mewtwo. You heard it was spotted somewhere in [DESTINATION CITY] and [DESTINATION CITY]. You want to visit one of these cities, leaving from [ORIGIN CITY] and starting on or after [START DATE]. You are leaving with your hunting team and you will be a total of [NUM ADULTS] adults. You have a budget of [PRICE MAX]. You want to compare the packages between the different cities and book one, the one that will take you to your destiny.\u201d\nThese templates were meant to add variety to the dialogues. The generic templates were also important for the users to create their own character and personality. We found that the combination of the two types of templates prevented the task from becoming too repetitive. Notably, we distributed the role-playing templates throughout the data collection process to bring some novelty and surprise. We also asked the participants to write templates (13 of them) to keep them engaged in the task.\nTo control data collection, we gave a set of instructions to the participants. The users received the following instructions:\n\u2022 Do not use uncommon slang terms, but feel free to use colloquialisms. \u2022 Make up personalities. \u2022 Feel free to end the conversation at any time. \u2022 Try to spell things correctly. \u2022 You do not necessarily have to choose an option. \u2022 Try to determine what you can get for your money.\nThese instructions were meant to encourage a variety of behaviours from the users. As for the wizards, they were asked to only talk about the database results and the task-at-hand. This is necessary if one wants to build a dialogue system that emulates the wizards\u2019 behaviour in this corpus. The wizard instructions were as follows:\n\u2022 Be polite, and do not jump in on the role play of the users. \u2022 Vary the way you answer the user, sometimes you can say something that would be right at\nanother point in a dialogue. \u2022 Your knowledge of the world is limited by your database. \u2022 Try to spell things correctly.\nWe asked the wizards to sometimes act badly (second point in the list). It is interesting from a dialogue management point of view to have examples of bad behaviour and of how it impacts user satisfaction. At the end of each dialogue, the user was asked to provide a wizard cooperativity rating on a scale of 1 to 5. The wizard, on the other hand, was shown the user\u2019s task and was asked whether she thought the user had accomplished it."}, {"heading": "3.3 DATABASE SEARCH INTERFACE", "text": "Wizards received a link to a search interface every time a user was connected with them. The search interface was a simple GUI with all the searchable fields in the database (see Appendix A). For every search in the database, up to 10 results were displayed. These results were sorted by increasing price."}, {"heading": "3.4 SUGGESTIONS", "text": "When a database query returned no results, suggestions were sometimes displayed to the wizards. Suggestions were packages obtained by relaxing one or more constraints. It was up to the wizard to decide whether or not to use suggestions. Our goal with suggestions is not to learn a recommender system, but to learn the timing of recommendation, hence the randomness of the mechanism."}, {"heading": "4 STATISTICS OF THE CORPUS", "text": "We used the data collection process described in the previous section to collect 1369 dialogues. Figure 1a shows the distribution of dialogue length in the corpus. The average number of turns is 15, for a total of 19986 turns in the dataset. A turn is defined as a Slack message sent by either a user or a wizard. A user turn is always followed by a wizard turn and vice versa.\nFigure 1b shows the number of acts per dialogue turn. About 25% of the dialogue turns have more than one dialogue act. The turns with 0 dialogue act are turns where the user asked for something that the wizard could not provide, e.g., because it was not part of the database. An example in the dataset is: \u201cWould my room have a view of the city? How much would it cost to upgrade to a room with a view?\u201d. We left such user turns unannotated and they are usually followed up by the wizard saying she cannot provide the required information.\nFigure 1c shows the distribution of user ratings. More than 70% of the dialogues have the maximum rating of 5. Figure 1d shows the occurrences of dialogue acts in the corpus. The dialogue acts are described in Table 9 in Appendix B. We present the annotation scheme in the following section."}, {"heading": "5 DIALOGUE ANNOTATION SCHEME", "text": "We annotated the Frames dataset with three types of labels:\n1. Dialogue acts, slot types, slot values, and references to other frames for each utterance.\n2. The ID of the currently active frame.\n3. Frame labels which were automatically computed based on the previous two sets of labels."}, {"heading": "5.1 DIALOGUE ACTS, SLOT TYPES, AND SLOT VALUES", "text": "Most of the dialogue acts used for annotation are acts which are usually encountered in the goaloriented setting such as inform and offer. We also introduced dialogue acts which are specific to our frame tracking setting such as switch frame and request compare. The dialogue acts are listed in Table 9.\nOur annotation uses three sets of slot types. The first set, listed in Tables 7 and 8, corresponds to the fields of the database. The second set is listed in Table 10 and contains the slot types which we defined in order to describe specific aspects of the dialogue such as intent and action. An intent indicates whether or not the user wants to book a package, whereas an action indicates whether or not the wizard should, or did, book it. We also introduced several count slot types which were used most often by wizards to summarize information in the database, e.g., \u201cI have 2 hotels in Marseille\u201d. In this case, the wizard informs that the count for hotels is 2.\nThe remaining slot types in Table 10 were introduced to describe frames and cross-references between them. Before we discuss these slot types, we define frames more formally in the following section."}, {"heading": "5.2 FRAMES", "text": ""}, {"heading": "5.2.1 DEFINITION", "text": "Semantic frames form the core of our dataset. A semantic frame is defined by the following four components:\n\u2022 User requests: slots whose values the user wants to know for this frame. \u2022 User binary questions: user questions with slot types and slot values. \u2022 Constraints: slots which have been set to a particular value by the user or the wizard. \u2022 User comparison requests: slots whose values the user wants to know for this frame and\none or more other frames.\nSeveral of these labels are used in the Dialogue State Tracking Challenge (DSTC) (Williams et al., 2016). In DSTC, a semantic frame contains the constraints set by the user, the user requests, and the user\u2019s search method (e.g., by constraints or alternatives). In our case, constraints can also be set by the wizard when she suggests or offers a package. Any field in the database (see Tables 7 and 8 in Appendix A) can be constrained by the user or the wizard. The comparison requests and the binary questions were added after analysing the dialogues. The comparison requests correspond to the request compare dialogue act. This dialogue act is used to annotate turns when a user asks to compare different results, for instance: \u201cCould you tell me which of these resorts offers free wifi?\u201d. These questions relate to several frames. Binary questions are questions with slot types and slot values, e.g., \u201cIs this hotel in the downtown area of the city?\u201d (request act), or \u201cIs the trip to Marseille cheaper than to Naples?\u201d (request compare act), as well as all confirm acts. Binary questions concern one or several frames."}, {"heading": "5.2.2 CREATION AND ANNOTATION", "text": "Each dialogue starts in frame 1. New frames are introduced when the wizard offers or suggests something, or when the user modifies pre-established slots. Thus, all values discussed during the dialogue are recorded and the user can return to a previous set of constraints at any point. An example is given in Table 1. In this example, the frame number changes when the user modifies several slot values: the destination city, the number of adults for the trip, and the budget. Though frames are created for each offer or suggestion made by the wizard, the active frame can only be changed by the user so that the user has control over the dialogue. If the user asks for more information about a specific offer or suggestion, the active frame is changed to the frame introduced with that offer or suggestion. This change of frame is indicated by a switch frame act (see Appendix A). The rules for creating and switching frames are summarized in Table 2.\nUser Yes, how about going to Neverland from Caprica on August 13, 2 2016 for 5 adults. For this trip, my budget would be 1900. Wizard I checked the availability for those dates and there were no trips available. 2 Would you like to select some alternate dates?\nWe introduced specific slot types for recording the creation and modification of frames. These slot types are id, ref, read, and write (see Table 10 in Appendix B). The frame id is defined when the frame is created and is used to switch to this frame when the user decides to do so.\nThe other slot types \u2013 ref, read, and write \u2013 are used to annotate cross-references between frames, which are a crucial component of the recorded dialogues. A reference has two parts: the number of the frame it is referring to and the slots and values that are used to refer to that frame (if any). For instance, ref[1{name=Tropic}] means that frame 1 is being referred to by the hotel name Tropic. If anaphora is used to refer to a frame, we annotated this with the slot ref anaphora (e.g., \u201cThis is too long\u201d \u2013 inform(duration=too long,ref anaphora=this)). Inside an offer dialogue act, a ref means that the frame corresponding to the offer is derived from another frame. For example, here is an utterance from the corpus, written by a wizard:\n\u201cHere are a couple of options. The first option is a 3.0 star hotel (the Tropic), with a guest rating of 4.77/10 and a business class flight. The cost is 1002.27 USD. Or, if you prefer, you could choose the same 3.0 star hotel with a guest rating of 4.77/10 (the Tropic) and an economy flight, for 812.69.\u201d\nSwitching User Changing the value of a slot (it causes the dialogue to switch to that frame)\n50% 2092\nConsidering a wizard offer or suggestion 39% 1635 Switching to an earlier frame by mentioning its slot values 11% 458\nThis utterance is annotated with the following dialogue acts:\n\u2022 offer(category=3.0,name=Tropic,gst rating=4.77/10,id=6); \u2022 offer(ref=[6],seat=business,price=1002.27 USD,id=7); \u2022 and offer(ref=[6],seat=economy,price=812.69,id=8).\nHere, the frames corresponding to the last two offers are derived from the first one by inheriting all values.\nThe slot types read and write only occur inside a wizard\u2019s inform act and are used by the wizards to provide relations between offers or suggestions: read is used to indicate which frame the values are coming from (and which slots are used to refer to this frame, if any), while write indicates the frame where the slot values are to be written (and which slot values are used to refer to this frame, if any). If there is a read without a write, the current frame is assumed as the storage for the slot values. A slot type without a value indicates that the value is the same as in the referenced frame, but was not mentioned explicitly i.e., \u201cfor the same price\u201d.\nTable 3 gives an example of how these slot types are used in practice: inform( read=[7{dst city=Punta Cana, category=2.5}]means that the values 2.5 and Punta Cana are to be read from frame 7, and to be written in the current frame. At this turn of the dialogue, the wizard repeats information from frame 7.\nThe annotation inform(breakfast=False, write=[7{name=El Mar}]) means that the value False for breakfast is written in frame 7 and that frame 7 was identified in this utterance by the name of the hotel El Mar.\nThe average number of frames created per dialogue is 6.71 and the average number of frame switches is 3.58. Figure 2 shows boxplots for the number of frame creations and the number of frame changes in the corpus."}, {"heading": "6 RESEARCH TOPICS", "text": "Frames can be used to research many aspects of goal-oriented dialogue, from Natural Language Understanding (NLU) to natural language generation. In this section, we propose three topics that we believe are new and representative of this dataset."}, {"heading": "6.1 FRAME TRACKING", "text": ""}, {"heading": "6.1.1 DEFINITION", "text": "Frame tracking extends state tracking (Henderson, 2015; Williams et al., 2016) to a setting where several semantic frames are tracked simultaneously. In state tracking, the dialogue history is compressed into one semantic frame. Essentially, this implies that every new slot value overwrites the previous one, which prevents the user from comparing options or returning to an item discussed\nearlier. In frame tracking, a new value creates a new semantic frame. The frame tracking task is significantly harder as it requires, for each user utterance, identifying the active frame as well as all the frames modified by the utterance. Definition 1 (Frame Tracking). At each user turn t, we assume access to the full dialogue history H = {f1, ..., fnt\u22121}, where fi is a frame and nt\u22121 is the number of frames created so far in the dialogue. For a user utterance ut at time t, we provide the following NLU labels: dialogue acts, slot types, and slot values. The goal of frame tracking is to predict if a new frame is created and to predict for each dialogue act the ref labels (possibly none) and the ids of the frames referenced.\nPredicting the frame that is referenced by a dialogue act requires detecting if a new frame is created and recognizing a previous frame from the values mentioned by the user (potentially a synonym, e.g., NYC for New York), or by using the user utterance directly. It is necessary in many cases to use the user utterance directly because users do not always use slot values to refer to previous frames. An example in the corpus is a user asking: \u201cWhich package has the soonest departure?\u201d. In this case, the user refers to several frames (the packages) without ever explicitly describing which ones. This phenomenon is quite common for dialogue acts such as switch frame (979 occurrences in the corpus) and request compare (455 occurrences in the corpus). These cases can only be resolved by working on the text directly and solving anaphora."}, {"heading": "6.1.2 EVALUATION METRICS", "text": "We define two metrics: frame identification and frame creation. For frame identification, for each dialogue act, we compare the ground truth pair (key-value, frame) to that predicted by the frame tracker. We compute performance as the number of correct predictions over the number of pairs. A prediction is correct if and only if the frame, key, and value are the same in the ground truth and prediction. The frame is the id of the referenced frame. The key and value are respectively the type and the value of the slot used to refer to the frame (these can be null).\nFor frame creation, we compute the number of times the frame tracker correctly predicts that a frame is created or correctly predicts that a frame has not been created over the number of dialogue turns."}, {"heading": "6.1.3 RELATED WORK", "text": "Frame tracking is closely related to state tracking in that it extends the task from only tracking the current user goal to tracking all the user goals that occur during the dialogue.\nRecent approaches to state tracking have been suggested to go beyond the sequential slot-filling approach. An important contribution is the Task Lineage-based Dialog State Tracking (TL-DST) proposed by (Lee and Stent, 2016). TL-DST is a framework that allows keeping track of tasks across different domains. Similarly to frame tracking, Lee and Stent propose building a dynamic\nstructure of the dialogue containing different frames corresponding to different tasks. They defined different sub-tasks among which task frame parsing which is closely related to frame tracking except that they impose constraints on how a dialogue act can be assigned to a frame and a dialogue act can only relate to one frame. Because of the lack of data, Lee and Stent (2016) trained their tracking model on datasets released for DSTC (DSTC2 and DSTC3, Henderson et al., 2014a,b). As a result, they could artificially mix different tasks, e.g., looking for a restaurant and looking for a pub, but they could not study how human beings switch between topics. In addition, this framework can switch between different tasks but does not handle comparisons which is an important aspect of frame tracking.\nAnother related approach was proposed by (Perez and Liu, 2016) who framed the state tracking task as a question-answering task. Their state tracker is based on a memory network (Weston et al., 2014) and can answer questions about the user goal at the end of the dialogue. They also propose adding functionalities such as keeping a list of the constraints expressed by the user during the dialogue.\nWe propose the dataset in order to encourage more research on complex state tracking behaviours. In addition, we propose the frame tracking task as a principled way of modelling such behaviour in the case of decision-making but researchers are free to use this dataset for any task that they define."}, {"heading": "6.2 DIALOGUE MANAGEMENT", "text": "One of the notable aspects of this dataset is that memory is not only a matter of frame tracking. Most of the time, the wizard would speak about the current frame to ask or answer questions. However, sometimes, the wizard would talk about previous frames. We can see it as appealing to memories in a conversation. An example is given in Table 4. In the bold utterance in this dialogue, even though the active frame is frame 4, the wizard mentions a previous frame (frame 3). In order to reproduce this kind of behaviour, a dialogue manager would need to be able to identify potentially relevant frames for the current turn and to output actions for these frames.\nTable 4 also illustrates another novelty. In the utterance in italic, the wizard actually performs two actions. The first action consists of informing the user about the price of the regal resort and the second action consists of proposing another option, Hotel Globetrotter. Performing more than one action per turn is a challenge when using reinforcement learning (Fatemi et al., 2016; Gas\u030cic\u0301 et al.,\n2012; Pietquin et al., 2011) and, to our knowledge, this has only been done in a simulated setting (Laroche et al., 2009)."}, {"heading": "6.3 NATURAL LANGUAGE GENERATION", "text": "An interesting behaviour observed in our dataset is that wizards often tended to summarize database results. An example is the wizard saying: \u201cThe cheapest available flight is 1947.14USD.\u201d In this case, the wizard informs the user that the database has no cheaper result than the one she is proposing. To imitate this behaviour, a dialogue system would need to reason over the database and decide how to present the results to the user."}, {"heading": "7 DATASET FORMAT", "text": ""}, {"heading": "7.1 DIALOGUES", "text": "We provide the Frames dialogues in JSON format. Each dialogue has five main fields: turns, labels, user id, wizard id, and id. The ids are unique for each dialogue (id), each user (user id), and each wizard (wizard id).\nThe labels have two fields:\n\u2022 userSurveyRating user rating of wizard cooperativity on a scale of 1 to 5 (see Section 3). \u2022 wizardSurveyTaskSuccessful wizard\u2019s perceived task completion (see Section 3).\nThe turns have the following fields:\n\u2022 author \u201cuser\u201d or \u201cwizard\u201d. \u2022 text the author\u2019s utterance. \u2022 labels the id of the currently active frame (active frame) as well as a list of dialogue\nacts (acts) each with a name, and args (key-value pairs), and a list of dialogue acts without ref tags (acts without refs) for frame tracking. \u2022 timestamp timestamp for the message. \u2022 frames List of all frames after integrating the current turn. Each frame has the following\nlabels: \u2022 frame id id of the frame. \u2022 frame parent id id of the parent frame. \u2022 requests, binary questions, compare requests user questions (see\nSection 5.2.1). \u2022 info properties of the frame (see Section 5.2.1) Note that each slot can have multiple\nvalues, which accumulate as long as the frame does not change. For example, price can be both \u201c1000 USD\u201d and \u201ccheapest\u201d. Each value has a boolean property \u201cnegated\u201d, expressing whether the user negated the value of the corresponding slot, for instance \u201cI don\u2019t want to stay 3 days\u201d (negate(duration=3)), or negated an explicit confirmation question. When a user switches to a frame, we assume the user accepts all information provided by the wizard for that frame as \u201cconstraints\u201d. We drop these additional constraints when a constraint is modified by the user, or the user requests alternatives. Our motivation for this scheme is to make frames more distinguishable and encourage methods which correctly identify frame switches. Additionally to slots and their values, we added the following fields to keep track of specific aspects of the dialogue: \u2022 REJECTED a boolean value expressing if the user negated or affirmed an offer made\nby the wizard (corresponds to a negate act that does not follow a question). \u2022 MOREINFO a boolean value expressing whether the user wants to know more\nabout this frame, which happens if the wizard withholds detail information (see moreinfo act).\n\u2022 db (wizard turns only) list of search queries made by the wizard with the associated search results/suggestions."}, {"heading": "7.2 HOTELS", "text": "The vacation packages were generated randomly. A database of packages can be created by using the search results in the JSON files containing the dialogues. The hotels in these search results have all the fields listed in the Hotel Properties section of Table 8 in Appendix A. Note that amenities or points of interest in the vicinity of the hotel are only listed in a hotel\u2019s description if they are true. For instance, the field breakfast is only present for hotels proposing free breakfast. Figure 3 shows statistics for these boolean values."}, {"heading": "8 BASELINES", "text": ""}, {"heading": "8.1 NATURAL LANGUAGE UNDERSTANDING", "text": "We define the NLU task as dialogue act prediction and IOB (Inside, Outside, Beginning) tagging. The IOB tag format (Inside, Outside, Beginning) is a common word-level annotation format for natural language understanding. A word tagged with O means that this word is not part of any slot value. The B and I tags are used for slot values. Every word which is the beginning of a slot value is tagged with B and the I tag is used for subsequent words until the end of the slot value. For instance, \u201cI need to go to New York for business\u201d would be tagged as \u201cI (O) need (O) to (O) go (O) to (O) New (B) York (I) for (O) business (O)\u201d. We generated these word-level tags by matching the slot values in the manual annotations with the corresponding textual utterances. The act tags were also generated at the word level: for a given dialogue act with slot values, each word between the slot value that occurred first in the text and the one that occurred last in the text was tagged with the corresponding act. The other words were tagged with O.\nThe NLU model is illustrated in Fig. 4. The IOB tagging part operates on character trigrams and is based on the robust named entity recognition model (Arnold et al., 2016). We predict, for each word of the utterance, a pair of tags \u2013 one for the act and one for the slot. The model splits into two parts: one part is trained to predict dialogue acts and the other part is trained to predict slot types (at this stage, we predict either a slot type or an O tag). These two parts share an embedding matrix for the input character trigrams. Note that the model only predicts IOB tags for slots whose values can be found in the text. Therefore, the prediction for slots such as intent or vicinities and amenities is not evaluated for this simple baseline.\nThe two parts of the model are trained simultaneously, using a modified categorical crossentropy loss for either set of outputs. We modify the loss to ignore O labels that are already predicted correctly by the model. We introduce this modification because O labels are far more frequent than other labels, and not limiting their contribution to the loss causes the model to get stuck into a mode where it predicts O labels for every word. The loss for the two parts of the model are added together, and the combined objective is optimized using the ADAM optimizer (Kingma and Ba, 2014).\nWe provide F1 scores for acts and slots for this model in Table 5. We report average and standard deviation over ten leave-one-user-out splits of the Frames dataset. We had a total of 11 participants in the user role during data collection. Two participants performed significantly fewer dialogues than the others. We merged the dialogues generated by these two participants (ids U21E41CQP and U23KPC9QV). For each of the resulting 10 users, we randomly split the combined dialogues of the nine others into training (80%) and validation (20%), and then tested on the dialogues from the held-out user."}, {"heading": "8.2 FRAME TRACKING", "text": "The rule-based frame tracker takes as input the acts without refs annotation and the values set in the existing frames. We write f [k] to denote the value of slot k in frame f . According to handdesigned rules, the frame tracker predicts the ref tags (for frame identification, see Section 6.1.2) and frame creations. For an act a(k=v) in frame f , the following rules are used:\n\u2022 Create and switch to a new frame if a is inform and f [k] is set, but v does not match f [k]. \u2022 Switch to frame g if a is switch frame and g[k] matches v. If no match is found, switch to the\nmost recently created frame.4 \u2022 Assign ref to frame g if a can have a ref tag, and g[k] matches v. The most recently created\nframe is used in ambiguous cases. If no match is found, assign ref to the current frame.\nWe compare this baseline to random performance. For random performance, for each (dialogue act, slot type) combination, we computed priors on the corpus for each time the user would refer to the current frame vs a previous one. We sampled whether each slot was referring to the current frame or another one based on that prior, and if it referred to another frame, the frame number for that other frame was sampled uniformly from the list of frames created so far.\nTable 6 presents results for these baselines. We report results over 10 runs following the same method as for the NLU model. Table 6 shows that the rule-based baseline only performs slightly better than random on frame identification and performs similarly on frame creation. In general, these results suggest that simple rules are far from adequate for frame tracking and require more in-depth analysis of the user text."}, {"heading": "9 CONCLUSION AND FUTURE WORK", "text": "In this paper, we introduced the Frames dataset: a corpus of human-human dialogues for researching the role of memory in goal-oriented dialogue systems. We propose this dataset to study memory in goal-oriented dialogue systems. We formalized the frame tracking task, which extends the state tracking task to a setting where several semantic frames are simultaneously tracked throughout the dialogue. We proposed a baseline for this task and we showed that there is a lot of room for improvement. Finally, we showed that Frames can be used to research other interesting aspects of dialogue such as the use of memory for dialogue management and information presentation through natural language generation. We propose adding memory as a first milestone towards goal-oriented dialogue systems that support more complex dialogue flows. Future work will consist of proposing models for frame tracking as well as proposing a methodology to scale up data collection and annotation."}, {"heading": "A DATABASE OVERVIEW", "text": "Table 7: Searchable fields in the database of packages\nField Description\nPRICE MAX Maximum price the user is willing to pay PRICE MIN Minimum price defined by the user DESTINATION CITY Destination city MAX DURATION Maximum number of days for the trip NUM ADULTS Number of adults NUM CHILDREN Number of children START DATE Start date for the trip END DATE End date for the trip ARE DATES FLEXIBLE Boolean value indicating whether or not the user\u2019s dates are\nflexible. If True, then the search is broadened to 2 days before START DATE and 2 days after END DATE.\nORIGIN CITY Origin city\nTable 8: Non-searchable fields in the database of packages\nField Description\nGlobal Properties\nPRICE Price of the trip including flights and hotel DURATION Duration of the trip\nHotel Properties\nNAME Name of the hotel COUNTRY Country where the hotel is located CATEGORY Rating of the hotel (in number of stars) CITY City where the hotel is located GUEST RATING Rating of the hotel by guests (in number of stars) BREAKFAST,PARKING,WIFI,GYM,SPA Boolean value indicating whether or not the hotel offers this amenity. PARK,MUSEUM,BEACH,SHOPPING, MARKET,AIRPORT,UNIVERSITY,MALL, CATHEDRAL,DOWNTOWN,PALACE,THEATRE Boolean value indicating whether or not the hotel is in the vicinity of one of these.\nFlights Properties\nSEAT Seat type (economy or business) DEPARTURE DATE DEP Date of departure to destination DEPARTURE DATE ARR Date of return flight DEPARTURE TIME DEP Time of departure to destination ARRIVAL TIME DEP Time of arrival to destination DEPARTURE TIME ARR Time of departure from destination ARRIVAL TIME ARR Time of arrival to origin city DURATION DEP Duration of flight to destination DURATION ARR Duration of return flight"}, {"heading": "B DIALOGUE ACTS AND SLOT TYPES", "text": ""}], "references": [{"title": "Robust Named Entity Recognition in Idiosyncratic Domains", "author": ["S. Arnold", "F.A. Gers", "T. Kilias", "A. L\u00f6ser"], "venue": "In: arXiv: 1608.06757 [cs.CL].", "citeRegEx": "Arnold et al\\.,? 2016", "shortCiteRegEx": "Arnold et al\\.", "year": 2016}, {"title": "Learning End-to-End Goal-Oriented Dialog", "author": ["Bordes", "Antoine", "Jason Weston"], "venue": "In: arXiv: 1605.07683 [cs.CL].", "citeRegEx": "Bordes et al\\.,? 2016", "shortCiteRegEx": "Bordes et al\\.", "year": 2016}, {"title": "NASTIA: Negotiating Appointment Setting Interface", "author": ["El Asri", "Layla", "R\u00e9mi Lemonnier", "Romain Laroche", "Olivier Pietquin", "Hatim Khouzaimi"], "venue": "In: Proc. of LREC.", "citeRegEx": "Asri et al\\.,? 2014", "shortCiteRegEx": "Asri et al\\.", "year": 2014}, {"title": "Policy Networks with Two-Stage Training for Dialogue Systems", "author": ["Fatemi", "Mehdi", "Layla El Asri", "Hannes Schulz", "Jing He", "Kaheer Suleman"], "venue": "In: Proc. of SIGDIAL.", "citeRegEx": "Fatemi et al\\.,? 2016", "shortCiteRegEx": "Fatemi et al\\.", "year": 2016}, {"title": "Policy optimisation of POMDP-based dialogue systems without state space compression", "author": ["M. Ga\u0161i\u0107", "M. Henderson", "B. Thomson", "P. Tsiakoulis", "S. Young"], "venue": "In: Proc. of SLT.", "citeRegEx": "Ga\u0161i\u0107 et al\\.,? 2012", "shortCiteRegEx": "Ga\u0161i\u0107 et al\\.", "year": 2012}, {"title": "Studies in the Way of Words", "author": ["Grice", "Paul"], "venue": "In: Harvard University Press, Cambridge MA. Chap. Logic and Conversation.", "citeRegEx": "Grice and Paul,? 1989", "shortCiteRegEx": "Grice and Paul", "year": 1989}, {"title": "The Third Dialog State Tracking Challenge", "author": ["M. Henderson", "B. Thomson", "J. Williams"], "venue": "In: Proceedings of IEEE Spoken Language Technology.", "citeRegEx": "Henderson et al\\.,? 2014a", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Machine Learning for Dialog State Tracking: A Review", "author": ["Henderson", "Matthew"], "venue": "In: First International Workshop on Machine Learning in Spoken Language Processing.", "citeRegEx": "Henderson and Matthew,? 2015", "shortCiteRegEx": "Henderson and Matthew", "year": 2015}, {"title": "The Second Dialog State Tracking Challenge", "author": ["Henderson", "Matthew", "Blaise Thomson", "Jason D. Williams"], "venue": "In: Proc. of SIGDIAL.", "citeRegEx": "Henderson et al\\.,? 2014b", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "An iterative design methodology for user-friendly natural language office information applications", "author": ["Kelley", "John F."], "venue": "In: ACM Transaction on Information Systems.", "citeRegEx": "Kelley and F.,? 1984", "shortCiteRegEx": "Kelley and F.", "year": 1984}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["D. Kingma", "J. Ba"], "venue": "In: arXiv: 1412. 6980 [cs.LG].", "citeRegEx": "Kingma and Ba,? 2014", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Hybridisation of expertise and reinforcement learning in dialogue systems.", "author": ["Laroche", "Romain", "Ghislain Putois", "Philippe Bretier", "Bernadette Bouchon-Meunier"], "venue": "Proc. of Interspeech", "citeRegEx": "Laroche et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Laroche et al\\.", "year": 2009}, {"title": "Task Lineages: Dialog State Tracking for Flexible Interaction", "author": ["Lee", "Sungjin", "Amanda Stent"], "venue": "In: Proc. of SIGDIAL.", "citeRegEx": "Lee et al\\.,? 2016", "shortCiteRegEx": "Lee et al\\.", "year": 2016}, {"title": "Machine Learning for Spoken Dialogue Systems", "author": ["Lemon", "Oliver", "Olivier Pietquin"], "venue": "In: Proc. of Interspeech, pp. 2685\u20132688.", "citeRegEx": "Lemon et al\\.,? 2007", "shortCiteRegEx": "Lemon et al\\.", "year": 2007}, {"title": "An ISU Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-filling in the TALK In-car System", "author": ["Lemon", "Oliver", "Kallirroi Georgila", "James Henderson", "Matthew Stuttle"], "venue": "In: Proc. of EACL.", "citeRegEx": "Lemon et al\\.,? 2006", "shortCiteRegEx": "Lemon et al\\.", "year": 2006}, {"title": "Uncovering Patterns in Cybershopping", "author": ["Moe", "Wendy W.", "Peter S. Fader"], "venue": "In: California Management Review.", "citeRegEx": "Moe et al\\.,? 2001", "shortCiteRegEx": "Moe et al\\.", "year": 2001}, {"title": "Dialog state tracking, a machine reading approach using Memory Network", "author": ["Perez", "Julien", "Fei Liu"], "venue": "In: Proc. of EACL.", "citeRegEx": "Perez et al\\.,? 2016", "shortCiteRegEx": "Perez et al\\.", "year": 2016}, {"title": "Sample-efficient batch reinforcement learning for dialogue management optimization", "author": ["Pietquin", "Olivier", "Matthieu Geist", "Senthilkumar Chandramohan", "Herv\u00e9 Frezza-Buet"], "venue": "In: ACM Transaction on Speech and Language Processing 7.3, pp. 1\u201321.", "citeRegEx": "Pietquin et al\\.,? 2011", "shortCiteRegEx": "Pietquin et al\\.", "year": 2011}, {"title": "LET\u2019S GO: Improving Spoken Dialog Systems for the Elderly and Non-natives", "author": ["Raux", "Antoine", "Brian Langner", "Allan Black", "Maxine Eskenazi"], "venue": "In: Proc. of Eurospeech.", "citeRegEx": "Raux et al\\.,? 2003", "shortCiteRegEx": "Raux et al\\.", "year": 2003}, {"title": "A corpus collection and annotation framework for learning multimodal clarification strategies", "author": ["Rieser", "Verena", "Ivana Kruijff-Korbayov", "Oliver Lemon"], "venue": "In: Proc. of SIGDIAL.", "citeRegEx": "Rieser et al\\.,? 2005", "shortCiteRegEx": "Rieser et al\\.", "year": 2005}, {"title": "Optimizing dialogue management with reinforcement learning: experiments with the NJFun System", "author": ["Singh", "Satinder", "Michael Kearns", "Diane Litman", "Marilyn Walker"], "venue": "In: Journal of Artificial Intelligence Research 16, pp. 105\u2013133.", "citeRegEx": "Singh et al\\.,? 2002", "shortCiteRegEx": "Singh et al\\.", "year": 2002}, {"title": "Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email", "author": ["Walker", "Marilyn A.", "Jeanne C. Fromer", "Shrikanth Narayanan"], "venue": "In: Proc. of COLING/ACL, pp. 1345\u20131352.", "citeRegEx": "Walker et al\\.,? 1998", "shortCiteRegEx": "Walker et al\\.", "year": 1998}, {"title": "A Network-based End-to-End Trainable Taskoriented Dialogue System", "author": ["Wen", "Tsung-Hsien", "Milica Gasic", "Nikola Mrksic", "Lina Maria Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve J. Young"], "venue": "In: arXiv: 1604.04562 [cs.CL].", "citeRegEx": "Wen et al\\.,? 2016", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "Memory Networks", "author": ["Weston", "Jason", "Sumit Chopra", "Antoine Bordes"], "venue": "In: CoRR.", "citeRegEx": "Weston et al\\.,? 2014", "shortCiteRegEx": "Weston et al\\.", "year": 2014}, {"title": "End-to-end LSTM-based dialog control optimized with supervised and reinforcement learning", "author": ["Williams", "Jason D.", "Geoffrey Zweig"], "venue": "In: arXiv: 1606.01269 [cs.CL].", "citeRegEx": "Williams et al\\.,? 2016", "shortCiteRegEx": "Williams et al\\.", "year": 2016}, {"title": "The Dialog State Tracking Challenge Series: A Review", "author": ["Williams", "Jason D.", "Antoine Raux", "Matthew Henderson"], "venue": "In: Dialogue and Discourse.", "citeRegEx": "Williams et al\\.,? 2016", "shortCiteRegEx": "Williams et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 18, "context": "Goal-oriented, information-retrieving dialogue systems have traditionally been designed to help users find items in a database given a certain set of constraints (El Asri et al., 2014; Laroche et al., 2011; Raux et al., 2003; Singh et al., 2002).", "startOffset": 162, "endOffset": 245}, {"referenceID": 20, "context": "Goal-oriented, information-retrieving dialogue systems have traditionally been designed to help users find items in a database given a certain set of constraints (El Asri et al., 2014; Laroche et al., 2011; Raux et al., 2003; Singh et al., 2002).", "startOffset": 162, "endOffset": 245}, {"referenceID": 18, "context": "For instance, the LET\u2019S GO dialogue system finds a bus schedule given a bus number and a location (Raux et al., 2003).", "startOffset": 98, "endOffset": 117}, {"referenceID": 21, "context": "Much work has focused on spoken dialogue (Lemon and Pietquin, 2007; Walker et al., 1998; Williams and Zweig, 2016), since spoken dialogue systems are useful in many settings, including in hands-free environments such as cars (Lemon et al.", "startOffset": 41, "endOffset": 114}, {"referenceID": 14, "context": ", 1998; Williams and Zweig, 2016), since spoken dialogue systems are useful in many settings, including in hands-free environments such as cars (Lemon et al., 2006).", "startOffset": 144, "endOffset": 164}, {"referenceID": 8, "context": ", a natural language understanding module that already performs well on the task, which implies possession of in-domain data or the ability to generate it (Henderson et al., 2014b; Raux et al., 2003).", "startOffset": 155, "endOffset": 199}, {"referenceID": 18, "context": ", a natural language understanding module that already performs well on the task, which implies possession of in-domain data or the ability to generate it (Henderson et al., 2014b; Raux et al., 2003).", "startOffset": 155, "endOffset": 199}, {"referenceID": 19, "context": "The Wizard-of-Oz (WOz) approach offers a powerful alternative (Kelley, 1984; Rieser et al., 2005; Wen et al., 2016).", "startOffset": 62, "endOffset": 115}, {"referenceID": 22, "context": "The Wizard-of-Oz (WOz) approach offers a powerful alternative (Kelley, 1984; Rieser et al., 2005; Wen et al., 2016).", "startOffset": 62, "endOffset": 115}, {"referenceID": 22, "context": "They are also essential for offline training of end-to-end dialogue systems (Bordes and Weston, 2016; Wen et al., 2016) on different domains, which may reduce costs from handcrafting new systems for each domain.", "startOffset": 76, "endOffset": 119}, {"referenceID": 24, "context": "Several of these labels are used in the Dialogue State Tracking Challenge (DSTC) (Williams et al., 2016).", "startOffset": 81, "endOffset": 104}, {"referenceID": 24, "context": "Frame tracking extends state tracking (Henderson, 2015; Williams et al., 2016) to a setting where several semantic frames are tracked simultaneously.", "startOffset": 38, "endOffset": 78}, {"referenceID": 23, "context": "Their state tracker is based on a memory network (Weston et al., 2014) and can answer questions about the user goal at the end of the dialogue.", "startOffset": 49, "endOffset": 70}, {"referenceID": 11, "context": ", 2011) and, to our knowledge, this has only been done in a simulated setting (Laroche et al., 2009).", "startOffset": 78, "endOffset": 100}, {"referenceID": 0, "context": "The IOB tagging part operates on character trigrams and is based on the robust named entity recognition model (Arnold et al., 2016).", "startOffset": 110, "endOffset": 131}, {"referenceID": 10, "context": "The loss for the two parts of the model are added together, and the combined objective is optimized using the ADAM optimizer (Kingma and Ba, 2014).", "startOffset": 125, "endOffset": 146}], "year": 2017, "abstractText": "This paper presents the Frames dataset1, a corpus of 1369 human-human dialogues with an average of 15 turns per dialogue. We developed this dataset to study the role of memory in goal-oriented dialogue systems. Based on Frames, we introduce a task called frame tracking, which extends state tracking to a setting where several states are tracked simultaneously. We propose a baseline model for this task. We show that Frames can also be used to study memory in dialogue management and information presentation through natural language generation.", "creator": "LaTeX with hyperref package"}}}