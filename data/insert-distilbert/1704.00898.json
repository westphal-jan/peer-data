{"id": "1704.00898", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Apr-2017", "title": "Interpretation of Semantic Tweet Representations", "abstract": "research in analysis of microblogging platforms is experiencing a renewed surge with nearly a large number of works applying representation complex learning models for applications like sentiment analysis, semantic textual framework similarity computation, hashtag format prediction, etc. although the performance analysis of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations might work better for certain tasks. our work presented here constitutes simply the obvious first step in first opening the black - box of vector embeddings for tweets. traditional hybrid feature engineering methods for high - level applications have exploited various characteristic elementary properties of online tweets. we believe that a tweet representation is effective for choosing an industrial application because it meticulously encodes the application - specific elementary properties of tweets. need to understand regarding the elementary properties encoded in a tweet representation, we correctly evaluate the combined representations on the higher accuracy to which perfection they can model each attribute of those properties such as tweet length, presence of the particular words, hashtags, context mentions, binary capitalization, etc. our systematic extensive study of nine well supervised and four unsupervised tweet representations against most popular eight textual and five social task elementary reasoning properties reveal that one bi - directional lstms ( blstms ) and skip - thought vectors ( skip stv ) best encode the textual and social properties of tweets respectively. fasttext is the best model for low resource settings, providing very little degradation interfere with reduction in embedding size. finally, we draw interesting insights by correlating similarly the model performance obtained for elementary property prediction tasks with the high - energy level downstream cognitive applications.", "histories": [["v1", "Tue, 4 Apr 2017 07:24:15 GMT  (3817kb,D)", "http://arxiv.org/abs/1704.00898v1", "Under review at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887"], ["v2", "Wed, 21 Jun 2017 06:59:17 GMT  (3824kb,D)", "http://arxiv.org/abs/1704.00898v2", "Accepted at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887"]], "COMMENTS": "Under review at ASONAM 2017; Initial version presented at NIPS 2016 workshop can be found atarXiv:1611.04887", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["j ganesh", "manish gupta", "vasudeva varma"], "accepted": false, "id": "1704.00898"}, "pdf": {"name": "1704.00898.pdf", "metadata": {"source": "CRF", "title": "Interpretation of Semantic Tweet Representations", "authors": ["Ganesh J", "Manish Gupta", "Vasudeva Varma"], "emails": ["ganesh.j@research.iiit.ac.in;", "manish.gupta@iiit.ac.in", "vv@iiit.ac.in", "gmanish@microsoft.com"], "sections": [{"heading": null, "text": "I. INTRODUCTION\nResearch on Twitter has focused on various kinds of business applications such as opinion mining, semantic textual similarity, user profiling, hashtag identification, microblog retrieval, etc. Central to the performance of these applications [10] is the question of tweet representation: How to best capture the essential meaning of a tweet in a machine-understandable format (or \u201crepresentation\u201d)? Challenges like short length, informal words, misspellings and unusual grammar make it difficult to obtain a good representation to capture these text aspects. Further, tweets also have social network-oriented properties, and hence a good representation should also capture social aspects. Traditionally, tweets have been modeled using Bag-Of-Words (BOW) [11] and Latent Dirichlet Allocation (LDA) [11].\nRecently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13]. Though these representations are hard to interpret, they have the following advantages: (1) in practice, they are highly effective across multiple applications, and (2) they reduce the dependence on domain level experts.\nResearchers in Twitter analytics have found these representation learning models to be very effective for several critical\ntasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc. However, little is known about the elementary tweet properties encoded by the representations generated from these models, knowing which will allow us to make generalizable conclusions. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets.\nEssentially we ask the following question: \u201cwhat are the core properties encoded in the given tweet representation?\u201d We explicitly group the set of these properties into two categories: textual and social. Textual category includes properties such as tweet length, the order of words in it, words, slang words, hashtags, named entities, and capitalization in the tweet. On the other hand, properties such as mention count, first mention position, is reply, reply time and repeating word from a conversation fall under the social category. We investigate the degree to which the tweet representations encode these properties. We assume that if we cannot train a classifier to predict a property based on its tweet representation, then this property is not encoded in this representation. For example, the model which preserves the tweet length should perform well in predicting the length given the representation generated from the model. Though these elementary property prediction tasks are not directly related to any downstream application, knowing that the model is good at modeling a particular property (e.g., social properties) indicates that it could excel in correlated applications (e.g., user profiling). In this work we perform an extensive evaluation of nine unsupervised and four supervised tweet representation models, using 13 different properties.\nOur main contributions are summarized below.\n\u2022 Our work is the first towards fine-grained interpretation of tweet embeddings. To this end, we propose a set of 13 tweet-specific elementary property prediction tasks which help in unearthing both the textual as well as social aspects of different tweet representations. \u2022 We perform extensive comparison of 13 different various tweet representations with respect to such properties across two dimensions: tweet length and sensitivity to representation size. \u2022 We draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with multiple downstream applications. \u2022 Extensive experiments show that bi-directional LSTMs and Skip-Thought vectors (STV) best encode the textual and social properties of tweets respectively. Paragraph2Vec performs the worst while FastText performs best when embedding size needs to be very small.\nThe paper is organized as follows. Section II presents the related work. Sections III and IV discuss the set of proposed\nar X\niv :1\n70 4.\n00 89\n8v 2\n[ cs\n.C L\n] 2\n1 Ju\nn 20\n17\nelementary property prediction tasks and the models considered for this study. Sections V and VI present the experiment setup and result analysis respectively. We conclude the work with a brief summary in Section VII."}, {"heading": "II. RELATED WORK", "text": ""}, {"heading": "A. Summary of Existing Models", "text": "Tables I and II summarize the core idea and the architecture of the existing unsupervised and supervised models respectively. Based on the network architecture, neural network models can be classified into one or more of the following categories: Feed Forward, Word2Vec, Encoder-Decoder, Siamese, Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Recursive Neural Network (ReNN). ReNNs work with parse trees, and hence are ill-suited for representing tweets, as parse tree construction is not only computation intensive but also expects the input sentences to be grammatically well-formed unlike most tweets. Hence we do not consider ReNNs for our study."}, {"heading": "B. Understanding Sentence Representations", "text": "In a recent work, Hill et al. [6] perform a comparison of different sentence representation models by evaluating them for different high-level semantic tasks such as paraphrase identification, sentiment classification, etc. Our work is different from their work in two ways: (1) They analyze sentences while we work with tweets. Naturally, they ignore social aspects. (2) They survey representations and their effectiveness for various applications; while we perform analysis of representations, and try to estimate their effectiveness for various applications. The most relevant work to ours is that of [17], which investigates three sentence properties in comparing two models: average of words vectors and LSTM auto-encoders. Our work differs from their work in two ways: (1) While they focus on sentences, we focus on tweets which opens up the challenge of understanding how well these representations capture multiple tweet-specific salient textual properties like slang words, hashtag and unreliable capitalization, and social properties like mentions and conversations. (2) While they work with only 3 properties for 2 models, we provide a more comprehensive analysis by considering 13 properties for 13 different models."}, {"heading": "III. ELEMENTARY PROPERTY PREDICTION TASKS", "text": "In this section we list down the set of proposed elementary property prediction tasks to test the characteristics of a tweet embedding. These properties correspond to the most popular features used in multiple papers using feature engineering for various microblog applications. Since tweets are pieces of text in a network context, we naturally categorized the properties into two types: textual and social. Note that we use a neural network to build the elementary property prediction task classifier which has the following two layers in order: the representation layer, and the softmax layer on top whose size varies according to the specific task. When there are more than one input for a task, we concatenate embeddings for each input. Table III presents the dataset statistics for each task."}, {"heading": "A. Textual Tasks", "text": "Unlike sentences, tweets have slang words, entities, hashtags, unreliable capitalization, etc. We evaluate tweet representations against the following tasks to check their robustness against this noise.\n(a) Length Task: Tweet length is a useful feature for detecting spam tweets, news-worthy tweets, etc. This task measures the extent to which the tweet representation encodes the length of the tweet. Given a tweet embedding, the task is to predict the number of words in the tweet. We use binned length to do multi-class classification. After varying bin size in a reasonable range (3\u20136), we did not observe much change in the results, hence we show results for bin size set as 4.\n(b) Content Task: Words in a tweet is a useful feature for sentiment analysis, paraphrase detection, response prediction, etc. This task measures the extent to which the tweet representation encodes the identities of words present in it. Given a tweet embedding and a word embedding, the task is to predict whether the word is in the tweet or not. This is posed as binary classification task where we inject randomly selected words not appearing in the tweet to generate negative samples.\n(c) Word Order Task: Word order is a useful feature in textual tasks like parsing. This task measures the extent to which the tweet representation preserves the word order. Given a tweet embedding, the embeddings of two words, w1 and w2 that appear in the tweet, the task is to predict whether the word w1 appears before the word w2 in the tweet or not. This is\nTable III: Dataset Statistics\nsolved as a binary classification task, where the order of words are flipped to generate negative samples.\n(d) Slang Words Task: Slang word is a useful feature in tasks such as sentiment analysis, paraphrase detection, etc. This task measures the extent to which the tweet representation is robust to the non-standard spellings (e.g., \u2018toook\u2019 for \u2018took\u2019), informal abbreviations (e.g., \u2018tmrw\u2019 for \u2018tomorrow\u2019), etc., which are ubiquitous on Twitter. Given a tweet embedding, and the embeddings of two words (w1 ,w2 ), the task is to predict whether the word w2 is the canonical form of the word w1 (which is present in the tweet) or not. This is also posed as a binary classification task, where the word w2 is randomly sampled to generate negative samples.\n(e) Hashtag Task: Hashtag is a useful feature in tasks such as sentiment analysis, hashtag prediction, response prediction, etc. This task measures the extent to which the tweet representation encodes the identities of hashtags present in the tweet. Given a tweet embedding and an embedding of the word that appears in the tweet, the task is to predict whether the word is a hashtag or not. This is solved as a binary classification task, where the negative samples are generated by randomly sampling words from the tweet which are not hashtags.\n(f) Named Entity (NE) Task: Named entities are a useful feature in detecting paraphrases, etc. This task measures the extent to which the tweet representation encodes the identities of the named entities present in the tweet. Given a tweet embedding and an embedding of the n-gram that appears in the tweet, the task is to predict whether the n-gram is a NE or not. This is solved as a binary classification task, where the negative samples are generated by randomly sampling n-grams from the tweet which are not NEs.\n(g) Capitalization Count Task: Capitalization count is a useful feature in detecting named entities, paraphrases and so on. This task measures the extent to which the tweet representation encodes the number of capitalized words present in the tweet. Given a tweet embedding, the task is to predict the number of words starting with a capital letter in the tweet.\n(h) Informative Capitalization Task: Capitalization is a key orthographic feature for recognizing NE. Unlike in curated text, non-entity words in some tweets are capitalized just"}, {"heading": "B. Social Tasks", "text": "Besides the textual properties, a good representation should be able to explain the following social properties of tweets.\n(i) Mention Count Task: Mention count is a useful feature in tasks such as sentiment analysis, response prediction, etc. This task measures the extent to which the tweet representation encodes the number of mentions present in it. Given a tweet embedding, the task is to predict the number of user mentions (words starting with the letter \u2018@\u2019) in the tweet. We use the raw frequency and pose it as a classification problem.\n(j) Mention Position Task: Mention position is a useful feature in tasks such as sentiment analysis, response prediction, etc. This task measures the extent to which the representation encodes the position of the first user mention in the tweet.\n(k) Is Reply Task: This task measures the extent to which the tweet representation encodes the salient properties of a reply tweet. Given a tweet embedding, the task is to predict whether the tweet is a reply tweet or not. To generate the negative instances for this binary task, we randomly choose a tweet that is a conversation starter.\n(l) Reply Time Task: Reply time is a useful feature in modeling the conversation, predicting responses, etc. This task measures the extent to which the tweet representation encodes the temporal aspects of a reply tweet. Given a tweet embedding, the task is to predict the number of minutes taken to get a reply for the tweet. For simplicity, we consider only the tweets which get a reply within an hour.\n(m) Word Repetition in Conversation Task: Word repetition in a conversation is a useful feature in modeling the conversation, predicting responses, etc. This task measures the extent to which the tweet representation encodes the frequent words in a conversation. Given a tweet embedding and an embedding for a word, the task is to predict whether the word will be used the most in the ensuing conversation thread from the tweet that is a conversation starter. We randomly choose the word that is never used later in the conversation in order to generate negative samples."}, {"heading": "IV. REPRESENTATION LEARNING MODELS", "text": "In this section we list down popular models for learning tweet representations."}, {"heading": "A. Unsupervised Models", "text": "We experiment with the following unsupervised representation learning models. These models require an additional classifier to do the final classification.\n\u2022 Bag Of Words (BOW) [11] - This simple representation captures the TF-IDF value of an n-gram. We pick top 50K n-grams, with the value of \u2018n\u2019 going upto 5. \u2022 Latent Dirichlet Allocation (LDA) [11] - We use the topic distribution resulting by running LDA with number of topics as 200, as the tweet representation. We varied number of topics as 100, 200, 500 but found best results at 200. \u2022 Bag Of Means (BOM) - We take the average of the word embeddings obtained by running the GloVe [22] model on 2B tweets with embedding size as 200 1. We varied embedding size as 25, 50, 100, 200 (since these are the available sizes) but found best results at 200. \u2022 Deep Structured Semantic Models (DSSM) [1] - This is a deep encoder trained to represent query and document in common space, for the document ranking task. We use the publicly available pre-trained encoder to encode the tweets 2. \u2022 Convolutional DSSM (CDSSM) [2] - This is the convolutional variant of DSSM. \u2022 Paragraph2Vec (PV) [3] - This model based on Word2Vec [12] learns embedding for a document which is good in predicting the words within it. We use the BOW variant with the recommended embedding size and window size of 200 and 10 respectively. \u2022 Skip-Thought Vectors (STV) [5] - This is a Gated Recurrent Unit (GRU) encoder trained to predict adjacent sentences in a books corpus. We use the recommended combine-skip (4800-dimensional) vectors from the publicly available encoder 3. \u2022 Tweet2Vec (T2V) [9] - This is a character composition model working directly on the character sequences to predict the user-annotated hashtags in a tweet. We use publicly available encoder, which was trained on 2M tweets 4. \u2022 Siamese CBOW (SCBOW) [8] - This model uses averaging of word vectors to represent a sentence, and the objective and data used here is same as that for STV. Note that this is different from BOW because the word vectors here are optimized for sentence representation."}, {"heading": "B. Supervised Models", "text": "Below we list the set of supervised representation learning models which we use for end-to-end classification.\n\u2022 Convolutional Neural Network (CNN) - This is a simple CNN proposed in [15]. \u2022 Long Short Term Memory Network (LSTM) [7] - This is a vanilla LSTM based recurrent model, applied from start to the end of a tweet, and the last hidden vector is used as tweet representation. We use the optimal hyperparameter settings as proposed in [13].\n1http://nlp.stanford.edu/projects/glove/ 2https://www.microsoft.com/en-us/research/project/dssm/ 3https://github.com/ryankiros/skip-thoughts 4https://github.com/bdhingra/tweet2vec\n\u2022 Bi-directional LSTM (BLSTM) [7] - This extends LSTM by using two LSTM networks, processing a tweet left-toright and right-to-left respectively. A tweet is represented by concatenating the last hidden vector of both LSTMs. We use the optimal hyper-parameter settings proposed in [13]. \u2022 FastText (FT) [16] - This is a simple architecture which averages the n-gram vectors to represent a tweet, followed by the softmax in the final layer."}, {"heading": "V. EXPERIMENTS", "text": "We perform an extensive evaluation of all the models in an attempt to find the significance of different representation models. Essentially we study every model (with optimal settings reported in the corresponding paper) with respect to the following perspectives.\n(1) Property prediction task accuracy - When the accuracy of the model for a property is high, it is more likely to encode the property. This test identifies the model with the best F1score for each elementary property prediction task.\n(a) Best model: Tasks for which this model has outperformed all the other models. (b) Best unsupervised model: Tasks for which this model has outperformed all the other unsupervised models. (c) Best supervised model: Tasks for which this model has outperformed all the other supervised models.\n(2) Property prediction task accuracy versus Tweet length - Some representation learning models are biased towards modeling shorter or longer tweets. This test helps to compare the performance of the model for shorter vs. longer tweets.\n(a) Positively correlated tasks: Tasks for which the performance of the model increases as tweet length increases. (b) Negatively correlated tasks: Tasks for which the performance of the model decreases as tweet length increases.\n(3) Property prediction task accuracy versus Representation size - Embedding size is an important hyper-parameter to tune the performance of the representation learning model. This test captures the sensitivity of each model with respect to the embedding size.\n(a) Invariant tasks: Tasks for which the model performance is invariant with increase in embedding size. (b) Positively correlated tasks: Tasks for which the model performance increases with increase in embedding size. (c) Negatively correlated tasks: Tasks for which the model performance decreases with increase in embedding size."}, {"heading": "VI. RESULTS AND ANALYSIS", "text": "Detailed analysis of various supervised and unsupervised models discussed in Section IV, across various dimensions (1, 2, and 3) discussed in Section V, is presented in Table IV. Thus, e.g., the \u201ctask accuracy (1)\u201d column entry for STV tells us that STV is \u201cbest model (a)\u201d for Content, Mention Count, Is Reply, Word Repeat tasks, and \u201cbest unsupervised model (b)\u201d for Content, Capt. Count, Mention Count, Mention Pos., Is Reply, Word Repeat tasks. We discuss these in detail in this section. We have made the code publicly available at http://tinyurl.com/mysteriousTweetReps. In this section, we analyze the results in detail."}, {"heading": "A. Property Prediction Task Accuracy", "text": "We summarize the results of all the property prediction tasks in Table V.\nFor the textual tasks, we observe the following. (1) Length prediction turns out to be a difficult task for most of the models. Models which rely on the recurrent architectures such as LSTM, STV, T2V have sufficient capacity to perform well in modeling the tweet length. PV performs the worst due to the simple Word2Vec structure on this complex task. FastText expectedly loses the length information and performs as the worst supervised model. (2) BLSTM is the best in modeling slang words. BLSTM outperforms the LSTM variant in all the tasks except \u2018Content\u2019, which signifies the power of using the information flowing from both the directions of the tweet. (3) STV tops in modeling the content. This is due to the very large embedding size used for every tweet (4800 dimensions).\nSurprisingly, T2V which is expected to perform well on the \u2018Content\u2019 task because of its ability to work at a finer level, i.e., characters performs the worst. In fact T2V does not outperform other models in any task, which could be mainly due to the fact that the hashtags which are used for supervision in learning tweet representations reduce the generalization capability of the tweets beyond hashtag prediction. Prediction tasks such as \u2018Content\u2019 and \u2018Hashtag\u2019 seem to be less difficult as all the models perform nearly optimal for them. The superior performance of all the models for the \u2018Content\u2019 task in particular is unlike the relatively lower performance reported in [17], mainly because of the short length of the tweets. (4) BOM performed well on identifying the named entities in the tweet. BOM is raised from the generic word-word statistics, which seems to be just enough for remembering NEs. (5) For the capitalization tasks such as \u2018Capitalization Count\u2019 and \u2018Informative Capitalization\u2019, we observe the supervised models\nperform better than the unsupervised models.\nFor the social tasks we observe the following. (1) On average, supervised models work better than unsupervised ones on Mention Count, Mention Position and Is Reply tasks. For the other two social tasks, unsupervised models are marginally better. (2) STV is good for most of the social tasks including \u2018Mention Count\u2019, \u2018Is Reply\u2019 and \u2018Word Repetition\u2019. We believe the main reason for STV\u2019s performance is two-fold: (a) the inter-sentential features extracted from STV\u2019s encoder by the prediction of the surrounding sentences in the books corpus contains rich social elements that are vital for social tasks (e.g., user profiling), and (b) the recurrent structure in both the encoder and decoder persists useful information in the memory nicely. The second claim is further substantiated by observing the poor performance of SCBOW whose objective is also similar to STV, but with a simpler architecture, i.e., word vector averaging."}, {"heading": "B. Sensitivity to Tweet Length", "text": "This setup captures the behavior of the model with the increase in the context size, which is defined in terms of number of words. Figure 1 provides the statistics on number of tweets in each bin of tweet length. For tasks such as \u2018Word Order\u2019, \u2018Mention Position\u2019 and \u2018Capitalization Count\u2019, we see the performance of all the models (Figure 2) to be negatively correlated with the tweet length. On the other hand, there is no correlation between the tweet length and the performance of all the models for the tasks such as \u2018Slang Words\u2019, \u2018Content\u2019, \u2018Hashtag\u2019, \u2018Named Entities\u2019, \u2018Informative Capitalization\u2019 and \u2018Is Reply\u2019. For \u2018Is Reply\u2019 task, we see a positive correlation between the tweet length and the performance of all the models (Figure 2). But there is no such correlation for other social tasks such as \u2018Reply Time\u2019 and \u2018Word Repetition\u2019."}, {"heading": "C. Sensitivity to Representation Size", "text": "In representation learning, low embedding size results in a poor model performance as the model does not have enough capacity (\u2018underfits\u2019) to retain information. On the other hand, high embedding size also results in poor performance as the model has redundant bits of information (\u2018overfits\u2019) which has a negative effect. The optimal strategy mostly is to do grid search for the size that gives superior performance. Specifically we build models with the embedding size from {10, 25, 50, 100, 200}. Figure 3 displays the plots for all the models for this setup. We find that performance of all the supervised models except FT is positively correlated with the representation size for most of the property prediction tasks. We discover that FT which relies on a simple operation of word vector average to represent a tweet is invariant to the representation size. This\nresult is surprising as FT yields good performance with such a small embedding size of 10 (which indeed is the optimal hyperparameter as suggested by the authors). We suggest to use FT for competitive performance on low-resource applications \u2013 less memory (e.g., mobile), and faster computation."}, {"heading": "D. Connections with the performance on downstream applications", "text": "In this subsection, we will attempt to establish the correlation between the model performance on the various elementary property prediction tasks and the model performance on the various real applications.\nSentiment Analysis: Giachanou et al. [14] showed that sentiment analysis is typically aided by features such as content, slang words, mention count, hashtags and named entities. We observe that STV is the only unsupervised model to encode all the five task-specific relevant features well thereby outperforming the other models for this task. On the other hand, PV encodes relatively the least number of relevant features thereby faring poorer than BOW (as we see later) for this task. We find that most of the supervised models (excluding FastText) capture the task-specific features well.\nHashtag Prediction: The salient features for hashtag prediction [23] include length, slang words and hashtag itself. We observe that none of the unsupervised models is able to encode all the relevant features. Since most of the supervised models are able to encode all the features, we conclude that nature of the task is strictly supervised.\nNamed Entity Recognition: This task is benefitted by features such as slang words and capitalization [20]. This task also seems to be strictly supervised in nature as none of the unsupervised model is able to encode both the features. The recurrent models are able to capture both features successfully and clearly explains why these models are the state-of-theart [24] for this task.\nResponse Prediction: This is a social task to identify if a given tweet can receive a response [25]. Content, hashtags and mention count are the vital features for this task. STV which is trained on a conversational context models all the features successfully. It is interesting to see that the recurrent models are also able to encode all the relevant features. This showcases the importance of recurrent models for the social tasks."}, {"heading": "E. A Case Study of BOW vs Paragraph2Vec", "text": "Table V shows that Paragraph2Vec is not good at encoding elementary tweet properties. To validate this with respect to high level applications, we compare Paragraph2Vec with BOW for a wide variety of Twitter applications. Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],\n(4) predict the day of the weather referred in the tweet 5 (W), and (5) predict the kind of the weather referred in the tweet (K). Table VI reports the scores of the best performing Paragraph2Vec with the variant (BOW or Distributed Memory) and representation size ({10, 25, 50, 100, 200}) tuned using the validation set. From the results, we find that Paragraph2Vec has poor performance for all the tasks compared to BOW. Using this pair of models for various tasks, we have shown that performance of the models on the elementary tweet properties can help us estimate the performance of the models on various applications."}, {"heading": "F. Overall Insights", "text": "Our extensive experimentation with a large number of models for important textual and social network properties of tweets, provides the following insights.\n\u2022 Length prediction is the most difficult textual task while content prediction is the easiest. Word repetition is the easiest social task while reply time prediction is the most complicated. \u2022 Bi-directional LSTMs and Skip-Thought vectors (STV) best encode the textual and social properties of tweets respectively. Paragraph2Vec performs the worst.\n5https://www.kaggle.com/c/crowdflower-weather-twitter\n\u2022 FastText is the best model for low resource applications providing very little degradation with reduction in embedding size. \u2022 Relative performance of the models does not change based on tweet length. All models behave in the same way to variation in tweet length."}, {"heading": "VII. CONCLUSION", "text": "In this paper, we tried to interpret multiple tweet representations in terms of the accuracy to which they encode elementary tweet properties (both textual and social). This helped us understand the weaknesses and strengths of such representations in an application independent, fine-grained manner. Based on such an evaluation, we conclude that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. Also, FastText with huge information encoded in its small representation is the best model for low resource applications. In future, we plan to work on interpretation of distributed representations of nodes in a network wrt various interesting network properties."}], "references": [{"title": "A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval", "author": ["Y. Shen", "X. He", "J. Gao", "L. Deng", "G. Mesnil"], "venue": "CIKM, 2014, pp. 101\u2013110.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Distributed Representations of Sentences and Documents", "author": ["Q.V. Le", "T. Mikolov"], "venue": "ICML, 2014, pp. 1188\u20131196.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Sentiment Embeddings with Applications to Sentiment Analysis", "author": ["D. Tang", "F. Wei", "B. Qin", "N. Yang", "T. Liu", "M. Zhou"], "venue": "TKDE, vol. 28, no. 2, pp. 496\u2013509, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Skip-Thought Vectors", "author": ["R. Kiros", "Y. Zhu", "R. Salakhutdinov", "R.S. Zemel", "R. Urtasun", "A. Torralba", "S. Fidler"], "venue": "NIPS, 2015, pp. 3294\u2013 3302.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning Distributed Representations of Sentences from Unlabelled Data", "author": ["F. Hill", "K. Cho", "A. Korhonen"], "venue": "NAACL-HLT, 2016, pp. 1367\u20131377.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Speech Recognition with Deep Recurrent Neural Networks", "author": ["A. Graves", "A. Mohamed", "G.E. Hinton"], "venue": "ICASSP, 2013, pp. 6645\u20136649.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Siamese CBOW: Optimizing Word Embeddings for Sentence Representations", "author": ["T. Kenter", "A. Borisov", "M. de Rijke"], "venue": "ACL, 2016.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Tweet2Vec: Character-Based Distributed Representations for Social Media", "author": ["B. Dhingra", "Z. Zhou", "D. Fitzpatrick", "M. Muehl", "W.W. Cohen"], "venue": "ACL, 2016.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2016}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Y. Bengio", "A.C. Courville", "P. Vincent"], "venue": "TPAMI, vol. 35, no. 8, pp. 1798\u20131828, 2013.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1828}, {"title": "CSE: conceptual sentence embeddings based on attention model", "author": ["Y. Wang", "H. Huang", "C. Feng", "Q. Zhou", "J. Gu", "X. Gao"], "venue": "ACL, 2016, pp. 505\u2013515.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2016}, {"title": "Distributed Representations of Words and Phrases and Their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "NIPS, 2013, pp. 3111\u20133119.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Improved semantic representations from tree-structured long short-term memory networks", "author": ["K.S. Tai", "R. Socher", "C.D. Manning"], "venue": "ACL, 2015, pp. 1556\u20131566.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Like it or not: A Survey of Twitter Sentiment Analysis Methods", "author": ["A. Giachanou", "F. Crestani"], "venue": "CSUR, vol. 49, no. 2, pp. 28:1\u201328:41, 2016.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Y. Kim"], "venue": "EMNLP, 2014, pp. 1746\u20131751.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Bag of Tricks for Efficient Text Classification", "author": ["A. Joulin", "E. Grave", "P. Bojanowski", "T. Mikolov"], "venue": "CoRR, vol. abs/1607.01759, 2016.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Finegrained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks", "author": ["Y. Adi", "E. Kermany", "Y. Belinkov", "O. Lavi", "Y. Goldberg"], "venue": "CoRR, vol. abs/1608.04207, 2016.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2016}, {"title": "Twitter Sentiment Classification using Distant Supervision", "author": ["A. Go", "R. Bhayani", "L. Huang"], "venue": "Technical Report, Stanford, 2009.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Weakly Supervised User Profile Extraction from Twitter", "author": ["J. Li", "A. Ritter", "E.H. Hovy"], "venue": "ACL, 2014, pp. 165\u2013174.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Named Entity Recognition in Tweets: An Experimental Study", "author": ["A. Ritter", "S. Clark", "Mausam", "O. Etzioni"], "venue": "EMNLP, 2011, pp. 1524\u20131534.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Unsupervised Modeling of Twitter Conversations", "author": ["A. Ritter", "C. Cherry", "B. Dolan"], "venue": "NAACL-HLT, 2010, pp. 172\u2013180.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "GloVe: Global Vectors for Word Representation", "author": ["J. Pennington", "R. Socher", "C.D. Manning"], "venue": "EMNLP, 2014, pp. 1532\u20131543.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "What\u2019s in a Hashtag?: Content based Prediction of the Spread of Ideas in Microblogging Communities", "author": ["O. Tsur", "A. Rappoport"], "venue": "WSDM. ACM, 2012, pp. 643\u2013652.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Keyphrase Extraction using Deep Recurrent Neural Networks on Twitter", "author": ["Q. Zhang", "Y. Wang", "Y. Gong", "X. Huang"], "venue": "EMNLP, 2016, pp. 836\u2013845.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Predicting Responses to Microblog Posts", "author": ["Y. Artzi", "P. Pantel", "M. Gamon"], "venue": "NAACL-HLT, 2012, pp. 602\u2013606.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "SemEval-2016 Task 4: Sentiment Analysis in Twitter", "author": ["P. Nakov", "A. Ritter", "S. Rosenthal", "F. Sebastiani", "V. Stoyanov"], "venue": "SemEval, 2016.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2016}, {"title": "Overview of RepLab 2014: Author Profiling and Reputation Dimensions for Online Reputation Management", "author": ["E. Amig\u00f3", "J. Carrillo de Albornoz", "I. Chugur", "A. Corujo", "J. Gonzalo", "E. Meij", "M. de Rijke", "D. Spina"], "venue": "CLEF, 2014, pp. 307\u2013322.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "Central to the performance of these applications [10] is the question of tweet representation: How to best capture the essential meaning of a tweet in a machine-understandable format (or \u201crepresentation\u201d)? Challenges like short length, informal words, misspellings and unusual grammar make it difficult to obtain a good representation to capture these text aspects.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "Traditionally, tweets have been modeled using Bag-Of-Words (BOW) [11] and Latent Dirichlet Allocation (LDA) [11].", "startOffset": 65, "endOffset": 69}, {"referenceID": 9, "context": "Traditionally, tweets have been modeled using Bag-Of-Words (BOW) [11] and Latent Dirichlet Allocation (LDA) [11].", "startOffset": 108, "endOffset": 112}, {"referenceID": 10, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 113, "endOffset": 117}, {"referenceID": 1, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 132, "endOffset": 135}, {"referenceID": 4, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 137, "endOffset": 140}, {"referenceID": 11, "context": "Recently there has been a paradigm shift in machine learning towards using distributed representations for words [12] and sentences [3], [6], [13].", "startOffset": 142, "endOffset": 146}, {"referenceID": 2, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 156, "endOffset": 159}, {"referenceID": 12, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 161, "endOffset": 165}, {"referenceID": 6, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 207, "endOffset": 210}, {"referenceID": 7, "context": "Researchers in Twitter analytics have found these representation learning models to be very effective for several critical tasks such as sentiment analysis [4], [14], semantic textual similarity computation [8], hashtag identification [9], etc.", "startOffset": 235, "endOffset": 238}, {"referenceID": 0, "context": "Model Architecture Core Idea Applications Considered in the Paper DSSM [1] Deep Feed Forward network Learn a common mapping for query and document Document ranking CDSSM [2] Deep Feed Forward Convolutional network Learn a common mapping for query and document Document ranking", "startOffset": 170, "endOffset": 173}, {"referenceID": 1, "context": "Paragraph2Vec [3] Word2Vec network Learn document embedding which are good in predicting the words within it Sentiment analysis, Document retrieval", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "SSWE [4] Simple Feed Forward network Learn sentiment specific word embeddings using distant supervision (emoticons) Sentiment analysis", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 21, "endOffset": 24}, {"referenceID": 4, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 297, "endOffset": 300}, {"referenceID": 5, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 306, "endOffset": 309}, {"referenceID": 4, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 503, "endOffset": 506}, {"referenceID": 6, "context": "Skip-Thought vectors [5] Gated Recurrent Unit Encoder-Decoder network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Paraphrase detection, Image-sentence ranking, Sentence classification including sentiment analysis SDAE [6] LSTM [7] Encoder-Decoder network Predict the source sentence given the corrupted version of the source sentence Semantic relatedness, Sentence classification tasks used in Skip thought vectors FastSent [6] Word2Vec network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness, Sentence classification tasks used in Skip thought vectors Siamese CBOW [8] Siamese network Learn sentence embedding which are good in predicting the surrounding sentences (sentential context) Semantic relatedness", "startOffset": 719, "endOffset": 722}, {"referenceID": 7, "context": "Tweet2Vec [9] Bi-GRU Encoder network Learn tweet embedding directly from characters using hashtags for supervision Hashtag prediction", "startOffset": 10, "endOffset": 13}, {"referenceID": 4, "context": "[6] perform a comparison of different sentence representation models by evaluating them for different high-level semantic tasks such as paraphrase identification, sentiment classification, etc.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "The most relevant work to ours is that of [17], which investigates three sentence properties in comparing two models: average of words vectors and LSTM auto-encoders.", "startOffset": 42, "endOffset": 46}, {"referenceID": 13, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 70, "endOffset": 74}, {"referenceID": 11, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 196, "endOffset": 200}, {"referenceID": 14, "context": "Model Architecture Core Idea Applications Considered in the Paper CNN [15] Simple CNN Classify using a CNN on top of pre-trained word vectors Sentiment analysis, Question classification Tree-LSTM [13] Recursive Network Generalization of LSTMs to model recursive nature of sentences Semantic relatedness, Sentiment classification FastText [16] Simple Feed Forward Network Classify using the average of word vectors Sentiment analysis, Tag prediction", "startOffset": 338, "endOffset": 342}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 86, "endOffset": 90}, {"referenceID": 16, "context": "Task Dataset name Dataset size Length Sentiment140 [18] 1,98,440 Content Sentiment140 [18] 1,98,083 Word Order Sentiment140 [18] 1,94,720 Slang Words https://noisy-text.", "startOffset": 124, "endOffset": 128}, {"referenceID": 17, "context": "html 3,120 Hashtag User Profiling [19] 2,00,000 Named Entities Twitter NER [20] 2,394 Cap.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "html 3,120 Hashtag User Profiling [19] 2,00,000 Named Entities Twitter NER [20] 2,394 Cap.", "startOffset": 75, "endOffset": 79}, {"referenceID": 17, "context": "Count User Profiling [19] 2,00,000 Informative Cap.", "startOffset": 21, "endOffset": 25}, {"referenceID": 18, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 96, "endOffset": 100}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 132, "endOffset": 136}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 168, "endOffset": 172}, {"referenceID": 19, "context": "Twitter NER [20] 400 Mention Count User Profiling [19] 2,00,000 Mention Position User Profiling [19] 2,00,000 Is Reply Conversation [21] 75,008 Reply Time Conversation [21] 31,669 Word Repetition in Conversation Conversation [21] 37,504", "startOffset": 225, "endOffset": 229}, {"referenceID": 9, "context": "\u2022 Bag Of Words (BOW) [11] - This simple representation captures the TF-IDF value of an n-gram.", "startOffset": 21, "endOffset": 25}, {"referenceID": 9, "context": "\u2022 Latent Dirichlet Allocation (LDA) [11] - We use the topic distribution resulting by running LDA with number of topics as 200, as the tweet representation.", "startOffset": 36, "endOffset": 40}, {"referenceID": 20, "context": "\u2022 Bag Of Means (BOM) - We take the average of the word embeddings obtained by running the GloVe [22] model on 2B tweets with embedding size as 200 1.", "startOffset": 96, "endOffset": 100}, {"referenceID": 0, "context": "\u2022 Convolutional DSSM (CDSSM) [2] - This is the convolutional variant of DSSM.", "startOffset": 29, "endOffset": 32}, {"referenceID": 1, "context": "\u2022 Paragraph2Vec (PV) [3] - This model based on Word2Vec [12] learns embedding for a document which is good in predicting the words within it.", "startOffset": 21, "endOffset": 24}, {"referenceID": 10, "context": "\u2022 Paragraph2Vec (PV) [3] - This model based on Word2Vec [12] learns embedding for a document which is good in predicting the words within it.", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "\u2022 Skip-Thought Vectors (STV) [5] - This is a Gated Recurrent Unit (GRU) encoder trained to predict adjacent sentences in a books corpus.", "startOffset": 29, "endOffset": 32}, {"referenceID": 7, "context": "\u2022 Tweet2Vec (T2V) [9] - This is a character composition model working directly on the character sequences to predict the user-annotated hashtags in a tweet.", "startOffset": 18, "endOffset": 21}, {"referenceID": 6, "context": "\u2022 Siamese CBOW (SCBOW) [8] - This model uses averaging of word vectors to represent a sentence, and the objective and data used here is same as that for STV.", "startOffset": 23, "endOffset": 26}, {"referenceID": 13, "context": "\u2022 Convolutional Neural Network (CNN) - This is a simple CNN proposed in [15].", "startOffset": 72, "endOffset": 76}, {"referenceID": 5, "context": "\u2022 Long Short Term Memory Network (LSTM) [7] - This is a vanilla LSTM based recurrent model, applied from start to the end of a tweet, and the last hidden vector is used as tweet representation.", "startOffset": 40, "endOffset": 43}, {"referenceID": 11, "context": "We use the optimal hyperparameter settings as proposed in [13].", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "com/bdhingra/tweet2vec \u2022 Bi-directional LSTM (BLSTM) [7] - This extends LSTM by using two LSTM networks, processing a tweet left-toright and right-to-left respectively.", "startOffset": 53, "endOffset": 56}, {"referenceID": 11, "context": "We use the optimal hyper-parameter settings proposed in [13].", "startOffset": 56, "endOffset": 60}, {"referenceID": 14, "context": "\u2022 FastText (FT) [16] - This is a simple architecture which averages the n-gram vectors to represent a tweet, followed by the softmax in the final layer.", "startOffset": 16, "endOffset": 20}, {"referenceID": 15, "context": "The superior performance of all the models for the \u2018Content\u2019 task in particular is unlike the relatively lower performance reported in [17], mainly because of the short length of the tweets.", "startOffset": 135, "endOffset": 139}, {"referenceID": 12, "context": "[14] showed that sentiment analysis is typically aided by features such as content, slang words, mention count, hashtags and named entities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "Hashtag Prediction: The salient features for hashtag prediction [23] include length, slang words and hashtag itself.", "startOffset": 64, "endOffset": 68}, {"referenceID": 18, "context": "Named Entity Recognition: This task is benefitted by features such as slang words and capitalization [20].", "startOffset": 101, "endOffset": 105}, {"referenceID": 22, "context": "The recurrent models are able to capture both features successfully and clearly explains why these models are the state-of-theart [24] for this task.", "startOffset": 130, "endOffset": 134}, {"referenceID": 23, "context": "Response Prediction: This is a social task to identify if a given tweet can receive a response [25].", "startOffset": 95, "endOffset": 99}, {"referenceID": 24, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 141, "endOffset": 145}, {"referenceID": 25, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 196, "endOffset": 200}, {"referenceID": 25, "context": "Specifically, we evaluate the models for five applications: (1) predict whether the sentiment of tweet is positive, negative or neutral (SA) [26], (2) predict the entity the tweet belongs to (EI) [27], (3) predict the priority of the topic the tweet belongs to (TP) [27],", "startOffset": 266, "endOffset": 270}], "year": 2017, "abstractText": "Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets. Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc. Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the highlevel downstream applications.", "creator": "LaTeX with hyperref package"}}}