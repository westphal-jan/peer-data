{"id": "1704.01652", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2017", "title": "Greed is Good: Near-Optimal Submodular Maximization via Greedy Optimization", "abstract": "it is known that greedy methods perform well well for maximizing monotone submodular objective functions. presented at its the same target time, most such simpler methods perform poorly frequently in the constructive face of non - monotonicity. in this paper, we show - arguably, surprisingly - that invoking both the classical linear greedy algorithm $ ^ o ( \\ sqrt { k } ) $ - times leads to the ( currently ) fastest deterministic algorithm, called polynomial repeated greedy, for maximizing a general submodular function subject to $ k $ - independent system constraints. repeated greedy instead achieves $ ( 1 + o ( 1 / \\ sqrt { k } ) ) k $ approximation using $ o ( symmetric nr \\ sqrt { k } ) $ function evaluations ( here, $ % n $ and $ r $ | denote the probable size of the ground set and at the maximum size ratio of a complete feasible solution,, respectively ). we then show that by a careful sampling simulation procedure, we can run the ideal greedy algorithm only once and obtain the ( currently ) highest fastest randomized algorithm, called sample greedy, thus for maximizing over a submodular function subject to $ k $ - extendible system constraints ( a subclass vector of $ k $ - independent system constrains ). sample greedy achieves $ ( k + 3 ) $ - approximation with trivial only $ o ( nr / k ) $ 0 function evaluations. finally, we derive an almost matching lower bound, and would show that surprisingly no polynomial time algorithm can indeed have an approximation ratio smaller than $ k + 1 / 2 - \\ varepsilon $. to further support our theoretical results, we compare accurately the performance of repeated greedy and sample greedy with prior art in a concrete application ( movie recommendation ). we consistently observe that, while an sample greedy achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.", "histories": [["v1", "Wed, 5 Apr 2017 21:03:53 GMT  (2203kb,D)", "http://arxiv.org/abs/1704.01652v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["moran feldman", "christopher harshaw", "amin karbasi"], "accepted": false, "id": "1704.01652"}, "pdf": {"name": "1704.01652.pdf", "metadata": {"source": "CRF", "title": "Greed Is Good: Near-Optimal Submodular Maximization via Greedy Optimization", "authors": ["Moran Feldman", "Christopher Harshaw", "Amin Karbasi"], "emails": [], "sections": [{"heading": null, "text": "\u221a k)-times leads to the (currently) fastest deterministic algorithm, called REPEAT-\nEDGREEDY, for maximizing a general submodular function subject to k-independent system constraints. REPEATEDGREEDY achieves (1+O(1/ \u221a k))k approximation using O(nr \u221a k) function evaluations (here, n and r denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only once and obtain the (currently) fastest randomized algorithm, called SAMPLEGREEDY, for maximizing a submodular function subject to kextendible system constraints (a subclass of k-independent system constrains). SAMPLEGREEDY achieves (k+3)-approximation with only O(nr/k) function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than k + 1/2\u2212 \u03b5. To further support our theoretical results, we compare the performance of REPEATEDGREEDY and SAMPLEGREEDY with prior art in a concrete application (movie recommendation). We consistently observe that while SAMPLEGREEDY achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.\nKeywords: Submodular maximization, k-systems, k-extendible systems, approximation algorithms\nar X\niv :1\n70 4.\n01 65\n2v 1\n[ cs\n.L G"}, {"heading": "1 Introduction", "text": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints.\nIn this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity). In contrast, results for the maximization of non-monotone submodular functions subject to a k-system constraint were only obtained much more recently. Specifically, Gupta et al. [2010] showed that, by repeatedly executing the greedy algorithm and an algorithm for unconstrained submodular maximization, one can maximize a non-monotone submodular function subject to a k-system constraint up to an approximation ratio of roughly 3k using a time complexity of O(nrk)1. This was recently improved by Mirzasoleiman et al. [2016], who showed that the approximation ratio obtained by the above approach is in fact roughly 2k.\nThe algorithms we describe in this paper improve over the above mentioned results both in terms of the approximation ratio and in terms of the time complexity. Our first result is a deterministic algorithm, called REPEATEDGREEDY, which obtains an approximation ratio of (1 + O(1/ \u221a k))k for the maximization of a non-monotone submodular function subject to a k-system constraint using a time complexity of only O(nr \u221a k). REPEATEDGREEDY is structurally very similar to the algorithm of Gupta et al. [2010] and Mirzasoleiman et al. [2016]. However, thanks to a tighter analysis, it needs to execute the greedy algorithm and the algorithm for unconstrained submodular maximization much less often, which yields its improvement in the time complexity.\nOur second result is a randomized algorithm, called SAMPLEGREEDY, which manages to further push the approximation ratio and time complexity to (k + 1)2/k \u2264 k + 3 and O(n + nr/k), respectively. However, it does so at a cost. Specifically, SAMPLEGREEDY applies only to a subclass of k-system constraints known as k-extendible system constraints. We note, however, that the class of k-extendible constraints is still general enough to capture, among others, any constraint that can be represented as the intersection of multiple matroid and matching constraints. Interestingly, when the objective function is also monotone or linear\n1Here, and throughout the paper, n represents the size of the ground set of the submodular function and r represents the maximum size of any set satisfying the constraint.\nthe approximation ratio of SAMPLEGREEDY improves to k + 1 and k, respectively,2 which matches the best known approximation ratios for the maximization of such functions subject to a k-extendible system constraint [Fisher et al., 1978, Jenkyns, 1976, Mestre, 2006]. Previously, these ratio were obtained using the greedy algorithm whose time complexity is O(nr). Hence, our algorithm also improves over the state of the art algorithm for maximization of monotone submodular and linear functions subject to a k-extendible system constraint in terms of the time complexity.\nWe complement our algorithmic results with two inapproximability results showing that the approximation ratios obtained by our second algorithm are almost tight. Previously, it was known that no polynomial time algorithm can have an approximation ratio of k \u2212 \u03b5 (for any constant \u03b5 > 0) for the problem of maximizing a linear function subject to a k-system constraint [Badanidiyuru and Vondra\u0301k, 2014]. We show that this result extends also to k-extendible systems, i.e., that no polynomial time algorithm can have an approximation ratio of k\u2212 for the problem of maximizing a linear function subject to a k-extendible system constraint. Moreover, for monotone submodular functions we manage to get a slightly stronger inapproximability result. Namely, we show that no polynomial time algorithm can have an approximation ratio of 1/(1 \u2212 e\u2212k) \u2212 \u03b5 \u2264 k + 1/2 \u2212 \u03b5 for the problem of maximizing a monotone submodular function subject to a k-extendible system constraint. Note that the gap between the approximation ratio obtained by SAMPLEGREEDY (namely, (k + 3)) and the inapproximability result (namely, (k + 1/2 \u2212 \u03b5)) is very small. A short summary of all the results discussed above for non-monotone submodular objectives can be found in Table 1.\nFinally, we compare the performance of REPEATEDGREEDY and SAMPLEGREEDY against FATNOM, the current state of the art algorithm introduced by Mirzasoleiman et al. [2016]. We test these algorithms on a movie recommendation problem using the MovieLens dataset, which consists of over 20 million ratings of 27,000 movies by 138,000 users. We find that our algorithms provide solution sets of similar quality as FANTOM while running orders of magnitude faster. In fact, we observe that taking the best solution found by several independent executions of SAMPLEGREEDY clearly yields the best trade-off between solution quality and computational cost. Moreover, our experimental results indicate that our faster algorithms could be applied to large scale problems previously intractable for other methods.\nOrganization: Section 2 contains a brief summary of additional related work. A formal presentation of our main results and some necessary preliminaries are given in Section 3. Then, in Sections 4 and 5 we present and analyze our deterministic and randomized approximation algorithms, respectively. The above mentioned experimental results comparing our algorithms with previously known algorithms can be found in Section 6. Finally, our hardness results appear in\n2The improvement for linear objectives requires a minor modification of the algorithm.\nAppendix A."}, {"heading": "2 Related Works", "text": "Submodular maximization has been studied with respect to a few special cases of k-extendible system constraints. Lee et al. [2010] described a local search algorithm achieving an approximation ratio of k+ for maximizing a monotone submodular function subject to the intersection of any k matroid constraints, and explained how to use multiple executions of this algorithm to get an approximation ratio of k+1+ 1k+1 +\u03b5 for this problem even when the objective function is non-monotone. Later, Feldman et al. [2011b] showed, via a different analysis, that the same local search algorithm can also be used to get essentially the same results for the maximization of a submodular function subject to a subclass of k-extendible system constraints known as k-exchange system constraints (this class of constraints captures the intersection of multiple matching and strongly orderable matroid constraints). For k \u2265 4, the approximation ratio of [Feldman et al., 2011b] for the case of a monotone submodular objective was later improved by Ward [2012] to (k + 3)/2 + \u03b5.\nAn even more special case of k-extendible systems are the simple matroid constraints. In their classical work, Nemhauser et al. [1978] showed that the natural greedy algorithm gives an approximation ratio of 1 \u2212 1/e for maximizing a monotone submodular function subject to a uniform matroid constraint (also known as cardinality constraint), and Ca\u0306linescu et al. [2011] later obtained the same approximation ratio for general matroid constraints using the Continuous Greedy algorithm. Moreover, both results are known to be optimal [Nemhauser and Wolsey, 1978]. However, optimization guarantees for non-montone submodular maximization are much less well understood. After a long series of works [Vondra\u0301k, 2013, Gharan and Vondra\u0301k, 2011, Feldman et al., 2011a, Ene and Nguyen, 2016], the current best approximation ratio for maximizing a non-monotone submodular function subject to a matroid constraint is 0.385 [Buchbinder and Feldman, 2016a]. In contrast, the state of the art inapproximability result for this problem is 0.478 [Gharan and Vondra\u0301k, 2011].\nRecently, there has also been a lot of interest in developing fast algorithms for maximizing submodular functions. Badanidiyuru and Vondra\u0301k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log\n2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n). Independently, Buchbinder et al. [2015b] showed that a technique similar to Mirzasoleiman et al. [2015] can be used to get also (e\u22121\u2212 \u03b5)-approximation for maximizing a non-monotone submodular function subject to a cardinality constraint using a time complexity of O\u03b5(n). Buchbinder et al. [2015b] also described a different (1 \u2212 1/e \u2212 \u03b5)-approximation algorithm for maximizing a monotone submodular function subject to a general matroid constraint. The time complexity of this algorithm isO\u03b5(r2 +n \u221a r log2 n) for general matroids, and it can be improved to O\u03b5(r \u221a n log n+ n log2 n) for generalized partition matroids.\n3Badanidiyuru and Vondra\u0301k [2014] also describe a fast algorithm for maximizing a monotone submodular function subject to a knapsack constraint. However, the time complexity of this algorithm is exponential in 1/\u03b5, and thus, its contribution is mostly theoretical."}, {"heading": "3 Preliminaries and Main Results", "text": "In this section we formally describe our main results. However, before we can do that, we first need to present some basic definitions and other preliminaries."}, {"heading": "3.1 Preliminaries", "text": "For a setA and element e, we often write the unionA\u222a{e} asA+e for simplicity. Additionally, we say that f is a real-valued set function with ground set N if f assigns a real number to each subset of N . We are now ready to introduce the class of submodular functions.\nDefinition 1. Let N be a finite set. A real-valued set function f : 2N \u2192 R is submodular if, for all X,Y \u2286 N ,\nf(X) + f(Y ) \u2265 f(X \u2229 Y ) + f(X \u222a Y ) . (1)\nEquivalently, for all A \u2286 B \u2286 N and e \u2208 N \\B,\nf(A+ e)\u2212 f(A) \u2265 f(B + e)\u2212 f(B) . (2)\nWhile definitions (1) and (2) are equivalent, the latter one, which is known as the diminishing returns property, tends to be more helpful and intuitive in most situations. Indeed, the fact that submodular functions capture the notion of diminishing returns is one of the key reasons for the usefulness of submodular maximization in combinatorial optimization and machine learning. Due to the importance and usefulness of the diminishing returns property, it is convenient to define, for every e \u2208 N and S \u2286 N , \u2206f(e|S) := f(S + e) \u2212 f(S). In this paper we only consider the maximization of submodular functions which are non-negative (i.e., f(A) \u2265 0 for all A \u2286 N ).4\nAs explained above, we consider submodular maximization subject to two kinds of constraints: k-system and k-extendible system constraints. Both kinds can be cast as special cases of a more general class of constraints known as independence system constraints. Formally, an independence system is a pair (N , I), where N is a finite set and I is a non-empty subset of 2N having the property that A \u2286 B \u2286 N and B \u2208 I imply together A \u2208 I.\nLet us now define some standard terminology related to independence systems. The sets of I are called the independent sets of the independence system. Additionally, an independent set B contained in a subset X of the ground set N is a base of X if no other independent set A \u2286 X strictly contains B. Using this terminology we can now give the formal definition of k-systems.\nDefinition 2. An independence system (N , I) is called a k-system if for every set X \u2286 N the sizes of the bases of X differ by at most a factor of k. More formally, |B1|/|B2| \u2264 k for every two bases B1, B2 of X .\nAn important special case of k-systems are the k-extendible systems, which were first introduced by Mestre [2006]. We say that an independent set B is an extension of an independent set A if B strictly contains A.\nDefinition 3. An independence system (N , I) is k-extendible if for every independent set A \u2208 I, an extension B of this set and an element e /\u2208 A obeying A \u222a {e} \u2208 I there must exist a subset Y \u2286 B \\A with |Y | \u2264 k such that B \\ Y \u222a {e} \u2208 I.\n4See [Feige et al., 2011] for an explanation why submodular functions that can take negative values cannot be maximized even approximately.\nIntuitively, an independence system is k-extendible if adding an element e to an independent set A requires the removal of at most k other elements in order to keep the resulting set independent. As is shown by Mestre [2006], the intersection of k matroids defined on a common ground set is always a k-extendible system. The converse is not generally true (except in the case of k = 1, since every 1-system is a matroid)."}, {"heading": "3.2 Main Contributions", "text": "Our main contributions in this paper are two efficient algorithms for submodular maximization: one deterministic and one randomized. The following theorem formally describes the properties of our randomized algorithm. Recall that n is the size of the ground set and r is the size of the maximal feasible set.\nTheorem 1. Let f : 2N \u2192 R\u22650 be a non-negative submodular function, and let (N , I) be a k-extendible system. Then, there exists an O(n + nr/k) time algorithm for maximizing f over (N , I) whose approximation ratio is at least (k+1) 2\nk . Moreover, if the function f is also monotone or linear, then the approximation ratio of the algorithm improves to k + 1 and k, respectively (in the case of a linear objective, the improvement requires a minor modification of the algorithm).\nOur deterministic algorithm uses an algorithm for unconstrained submodular maximization as a subroutine, and its properties depend on the exact properties of this subroutine. Let us denote by \u03b1 the approximation ratio of this subroutine and by T (n) its time complexity given a ground set of size n. Then, as long as the subroutine is deterministic, our algorithm has the following properties.\nTheorem 2. Let f : 2N \u2192 R\u22650 be a non-negative submodular function, and let (N , I) be a k-system. Then, there exists a deterministic O((nr + T (r)) \u221a k) time algorithm for maximizing\nf over (N , I) whose approximation ratio is at least k + ( 1 + \u03b12 )\u221a k + 2 + \u03b12 +O(1/ \u221a k).\nBuchbinder et al. [2015a] provide a deterministic linear-time algorithm for unconstrained submodular maximization having an approximation ratio of 3. Using this deterministic algorithm as the subroutine, the approximation ratio of the algorithm guaranteed by Theorem 2 becomes k + 52 \u221a k + 72 + O(1/ \u221a k) and its time complexity becomes O(nr \u221a k). We note that Buchbinder and Feldman [2016b] recently came up with a deterministic algorithm for unconstrained submodular maximization having an optimal approximation ratio of 2. Using this algorithm instead of the deterministic algorithm of Buchbinder et al. [2015a] could marginally improve the approximation ratio guaranteed by Theorem 2. However, the algorithm of Buchbinder and Feldman [2016a] has a quadratic time complexity, and thus, it is less practical. It is also worth noting that Buchbinder et al. [2015a] also describe a randomized linear-time algorithm for unconstrained submodular maximization which again achieves the optimal approximation ratio of 2. It turns out that one can get a randomized algorithm whose approximation ratio is k + 2 \u221a k + 3 +O(1/ \u221a k) by plugging the randomized algorithm of [Buchbinder et al., 2015a] as a subroutine into the algorithm guaranteed by Theorem 2. However, the obtained randomized algorithm is only useful for the rare case of a k-system constraint which is not also a k-extendible system constraint since Theorem 1 already provides a randomized algorithm with a better guarantee for constraints of the later kind.\nWe end this section with our inapproximability results for maximizing linear and submodular functions over k-extendible systems. Recall that these inapproximability results nearly match the approximation ratio of the algorithm given by Theorem 1.\nTheorem 3. There is no polynomial time algorithm for maximizing a linear function over a k-extendible system that achieves an approximation ratio of k \u2212 \u03b5 for any constant \u03b5 > 0.\nTheorem 4. There is no polynomial time algorithm for maximizing a non-negative monotone submodular function over a k-extendible system that achieves an approximation ratio of (1 \u2212 e\u22121/k)\u22121 \u2212 \u03b5 for any constant \u03b5 > 0.\nWe note that the inapproximability results given by the last two theorems apply also to a fractional relaxation of the corresponding problems known as the multilinear relaxation. This observation has two implications. The first of these implications is that even if we were willing to settle for a fractional solution, still we could not get a better than (1/(1\u2212e\u2212k))-approximation for maximizing a monotone submodular function subject to a k-extendible system constraint. Interestingly, this approximation ratio can in fact be reached in the fractional case even for k-system constraints using the well known (computationally heavy) Continuous Greedy algorithm of Ca\u0306linescu et al. [2011]. Thus, we get the second implication of the above observation, which is that further improving our inapproximability results requires the use of new techniques since the current technique cannot lead to different results for the fractional and non-fractional problems."}, {"heading": "4 Repeated Greedy: An Efficient Deterministic Algorithm", "text": "In this section, we present and analyze the deterministic algorithm for maximizing a submodular function f subject to a k-system constraint whose existence is guaranteed by Theorem 2. Our algorithm works in iterations, and in each iteration it makes three operations: executing the greedy algorithm to produce a feasible set, executing a deterministic unconstrained submodular maximization algorithm on the output set of the greedy algorithm to produce a second feasible set, and removing the elements of the set produced by the greedy algorithm from the ground set. After the algorithm makes ` iterations of this kind, where ` is a parameter to be determined later, the algorithm terminates and outputs the best set among all the feasible sets encountered during its iterations. A more formal statement of this algorithm is given as Algorithm 1.\nAlgorithm 1: Repeated Greedy(N , f, I, `) 1 Let N1 \u2190 N . 2 for i = 1 to ` do 3 Let Si be the output of the greedy algorithm given Ni as the ground set, f as the objective and I as the constraint. 4 Let S\u2032i be the output of a deterministic algorithm for unconstrained submodular maximization given Si as the ground set and f as the objective. 5 Let Ni+1 \u2190 Ni \\ Si. 6 return the set T maximizing f among the sets {Si, S\u2032i}`i=1.\nObservation 1. The set T returned by Algorithm 1 is independent.\nProof. For every 1 \u2264 i \u2264 `, the set Si is independent because the greedy algorithm returns an independent set. Moreover, the set S\u2032i is also independent since (N , I) is an independence system and the algorithm for unconstrained maximization must return a subset of its independent ground set Si. The observation now follows since T is chosen as one of these sets.\nWe now begin the analysis of the approximation ratio of Algorithm 1. Let OPT be an independent set of (N , I) maximizing f , and let \u03b1 be the approximation ratio of the unconstrained submodular maximization algorithm used by Algorithm 1. The analysis is based on three lemmata. The first of these lemmata states properties of the sets Si and S\u2032i which follow immediately from the definition of \u03b1 and known results about the greedy algorithm.\nLemma 1. For every 1 \u2264 i \u2264 `, f(Si) \u2265 1k+1f(Si\u222a(OPT\u2229Ni)) and f(S \u2032 i) \u2265 f(Si\u2229OPT)/\u03b1.\nProof. The set Si is the output of the greedy algorithm when executed on the k-system obtained by restricting (N , I) to the ground set Ni. Note that OPT \u2229 Ni is an independent set of this k-system. Thus, the inequality f(Si) \u2265 1k+1f(Si \u222a (OPT \u2229 Ni)) is a direct application of Lemma 3.2 of [Gupta et al. [2010]] which states that the sets S obtained by running greedy with a k-system constraint must obey f(S) \u2265 1k+1f(S \u222a C) for all independent sets C of the k-system.\nLet us now explain why the second inequality of the lemma holds. Suppose that OPTi is the subset of Si maximizing f . Then,\nf(S\u2032i) \u2265 f(OPTi)/\u03b1 \u2265 f(Si \u2229 OPT)/\u03b1 ,\nwhere the first inequality follows since \u03b1 is the approximation ratio of the algorithm used for unconstrained submodular maximization, and the second inequality follows from the definition of OPTi.\nThe next lemma shows that the average value of the union between a set from {Si}`i=1 and OPT must be quite large. Intuitively this follows from the fact that these sets are disjoint, and thus, every \u201cbad\u201d element which decreases the value of OPT can appear only in one of them. Lemma 2. \u2211\u0300 i=1 f(Si \u222a OPT) \u2265 (`\u2212 1)f(OPT).\nProof. The proof is based on the following known result.\nClaim 1 (Lemma 2.2 of Buchbinder et al. [2014]). Let g : 2N \u2192 R\u22650 be non-negative and submodular, and let S a random subset of N where each element appears with probability at most p (not necessarily independently). Then, E[g(S)] \u2265 (1\u2212 p)g(\u2205).\nUsing this claim we can now prove the lemma as follows. Let S be a random set which is equal to every one of the sets {Si}`i=1 with probability 1` . Since these sets are disjoint, every element of N belongs to S with probability at most p = 1r . Additionally, let us define g : 2N \u2192 R\u22650 as g(T ) = f(T\u222aOPT) for every T \u2286 N . One can observe that g is non-negative and submodular, and thus, by Claim 1,\n1\n` \u2211\u0300 i=1 f(Si \u222a OPT) = E[f(S \u222a OPT)] = E[g(S)] \u2265 (1\u2212 p)g(\u2205) = ( 1\u2212 1 ` ) f(OPT) .\nThe lemma now follows by multiplying both sides of the last inequality by `.\nThe final lemma we need is the following basic fact about submodular functions.\nLemma 3. Suppose f is a non-negative submodular function over ground set N . For every three sets A,B,C \u2286 N , f(A \u222a (B \u2229 C)) + f(B \\ C) \u2265 f(A \u222aB).\nProof. Observe that\nf(A \u222a (B \u2229 C)) + f(B \\ C) \u2265 f(A \u222a (B \u2229 C) \u222a (B \\ C)) + f((A \u222a (B \u2229 C)) \u2229 (B \\ C)) \u2265 f(A \u222a (B \u2229 C) \u222a (B \\ C)) = f(A \u222aB) ,\nwhere the first inequality follows from the submodularity of f , and the second inequality follows from its non-negativity.\nHaving the above three lemmata, we are now ready to prove Theorem 2.\nProof of Theorem 2. Observe that, for every 1 \u2264 i \u2264 `, we have OPT \\ Ni = OPT \u2229 (N \\Ni) = OPT \u2229 ( \u222ai\u22121j=1Si ) = \u222ai\u22121j=1 (OPT \u2229 Sj) (3)\nwhere the first equality holds because OPT \u2286 N and the second equality follows from the removal of Si from the ground set in each iteration of Algorithm 1. Using the previous lemmata and this observation, we get\n(`\u2212 1)f(OPT) \u2264 \u2211\u0300 i=1 f(Si \u222a OPT) (Lemma 2)\n\u2264 \u2211\u0300 i=1 f(Si \u222a (OPT \u2229Ni)) + \u2211\u0300 i=1 f(OPT \\ Ni) (Lemma 3)\n= \u2211\u0300 i=1 f(Si \u222a (OPT \u2229Ni)) + \u2211\u0300 i=1 f ( \u222ai\u22121j=1(OPT \u2229 Sj) ) (Equality (3))\n\u2264 \u2211\u0300 i=1 f(Si \u222a (OPT \u2229Ni)) + \u2211\u0300 i=1 i\u22121\u2211 j=1 f(OPT \u2229 Sj) (submodularity) \u2264 (k + 1) \u2211\u0300 i=1 f(Si) + \u03b1 \u2211\u0300 i=1 i\u22121\u2211 j=1 f(S\u2032j) (Lemma 1) \u2264 (k + 1) \u2211\u0300 i=1 f(T ) + \u03b1 \u2211\u0300 i=1 i\u22121\u2211 j=1 f(T ) (T \u2019s definition)\n= [(k + 1)`+ \u03b1`(`\u2212 1)/2] f(T ) .\nDividing the last inequality by (k + 1)`+ \u03b1`(`\u2212 1)/2, we get\nf(T ) \u2265 `\u2212 1 (k + 1)`+ \u03b12 `(`\u2212 1) f(OPT) = 1\u2212 1` k + \u03b12 `+ 1\u2212 \u03b1 2 f(OPT) . (4)\nThe last inequality shows that the approximation ratio of Algorithm 1 is at most k+ \u03b1 2 `+1\u2212 \u03b1 2\n1\u2212 1` .\nTo prove the theorem it remains to show that, for an appropriate choice of `, this ratio is at most k + ( 1 + \u03b12 )\u221a k + 2 + \u03b12 + O(1/ \u221a k). It turns out that the right value of ` for us is d \u221a ke. Plugging this value into Inequality (4) we get that the approximation ratio of Algorithm 1 is at most\nk + \u03b12 `+ 1\u2212 \u03b1 2 1\u2212 1` \u2264 k + \u03b12 ( \u221a k + 1) + 1\u2212 \u03b12 1\u2212 1\u221a\nk\n= k + \u03b12\n\u221a k + 1\n1\u2212 1\u221a k \u2264 k + ( 1 + \u03b1\n2\n)\u221a k + 2 + \u03b1\n2 + 4 + \u03b1\u221a k ,\nwhere the last inequality holds because for k \u2265 4 it holds that[ k + ( 1 + \u03b1\n2\n)\u221a k + 2 + \u03b1\n2 + 4 + \u03b1\u221a k\n]( 1\u2212 1\u221a\nk\n) = k + \u03b1\n2\n\u221a k + 1 + 4 + \u03b1\n2 \u221a k \u2212 4 + \u03b1 k\n\u2265 k + \u03b1 2\n\u221a k + 1 ."}, {"heading": "5 Sample Greedy: An Efficient Randomized Algorithm", "text": "In this section, we present and analyze a randomized algorithm for maximizing a submodular function f subject to a k-extendible system constraint. Our algorithm is very simple: it first samples elements from N , and then runs the greedy algorithm on the sampled set. This algorithm is outlined as Algorithm 2.\nAlgorithm 2: Sample Greedy(N , f, I, k)\n1 Let N \u2032 \u2190 \u2205 and S \u2190 \u2205. 2 for u \u2208 N do 3 with probability (k + 1)\u22121 do 4 Add u to N \u2032.\n5 while there exists u \u2208 N \u2032 such that S + u \u2208 I and \u2206f(u|S) > 0 do 6 Let u \u2208 N \u2032 be the element of this kind maximizing \u2206f(u|S). 7 Add u to S.\n8 return S.\nAlgorithm 3: Equivalent Algorithm(N , f, I, k)\n1 Let N \u2032 \u2190 N , S \u2190 \u2205 and O \u2190 OPT . 2 while there exists an element u \u2208 N \u2032 such\nthat S + u \u2208 I and \u2206f(u|S) > 0 do 3 Let u \u2208 N \u2032 be the element of this kind maximizing \u2206f(u|S), and let Su \u2190 S. 4 with probability (k + 1)\u22121 do 5 Add u to S and O. 6 Let Ou \u2286 O \\ S be the smallest set such that O \\Ou \u2208 I. 7 otherwise 8 if u \u2208 O then Let Ou \u2190 {u}. 9 else Let Ou \u2190 \u2205.\n10 Remove the elements of Ou from O. 11 Remove u from N \u2032. 12 return S.\nTo better analyze Algorithm 2, we introduce an auxiliary algorithm given as Algorithm 3. It is not difficult to see that both algorithms have identical output distributions. The sampling of elements in Algorithm 2 is independent of the greedy maximization, so interchanging these two steps does not affect the output distribution. Moreover, the variables Su, O and Ou in Algorithm 3 do not affect the output S (and in fact, appear only for analysis purposes). Thus, the two algorithms are equivalent, and any approximation guarantee we can prove for Algorithm 3 immediately carries over to Algorithm 2.\nNext, we are going to analyze Algorithm 3. However, before doing it, let us intuitively explain the roles of the sets S, Su, O and Ou in this algorithm. We say that Algorithm 3 considers an element u in some iteration if u is the element chosen as maximizing \u2206f(u|S) at the beginning of this iteration. Note that an element is considered at most once, and perhaps not at all. As in Algorithm 2, S is the current solution. Likewise, Su is the current solution S at the beginning of the iteration in which Algorithm 3 considers u. The set O maintained in Algorithm 3 is an independent set which starts as OPT and changes over time, while preserving three properties:\nP1 O is an independent set.\nP2 Every element of S is an element of O.\nP3 Every element of O \\ S is an element not yet considered by Algorithm 3.\nBecause these properties need to be maintained throughout the excecution, some elements may be removed from O in every given iteration. The set Ou is simply the set of elements removed from O in the iteration in which u is considered. Note that Ou and Su are random sets, and Algorithm 3 defines values for them if it considers u at some point. In the analysis below we assume that both Su and Ou are empty if u is not considered by Algorithm 3 (which means that Algorithm 3 does not explicitly set values for them).\nWe now explain how the algorithm manages to maintain the above mentioned properties of O. Let us begin with properties P1 and P2. Clearly the removal of elements from O that do not belong to S cannot violate these properties, thus, we only need to consider the case that the algorithm adds an element u to S in some iteration. To maintain P2, u is also added to O. On the one hand, O + u might not be independent, and thus, the addition of u to O might violate P1. However, since O is an extension of S by P2, S + u is independent by the choice of u and (N , I) is a k-extendible system, the algorithm is able to choose a set Ou \u2286 O \\ S of size at most k whose removal restores the independence of O + u, and thus, also P1. It remains to see why the algorithm preserves also P3. Since the algorithm never removes from O an element of S, a violation of P3 can only occur when the algorithm considers some element of O \\ S. However, following this consideration one of two things must happen. Either u is also added to S, or u is placed in Ou and removed from O. In either case P3 is restored.\nFrom this point on, every expression involving S or O is assumed to refer to the final values of these sets. The following lemma provides a lower bound on f(S) that holds deterministically. Intuitively, this lemma follows from the observation that, when an element u is considered by Algorithm 3, its marginal contribution is at least as large as the marginal contribution of any element of OPT \\ S.\nLemma 4. f(S) \u2265 f(S \u222a OPT)\u2212 \u2211 u\u2208N |Ou \\ S|\u2206f(u|Su).\nProof. We first show that f(S) \u2265 f(O), then we lower bound f(O) to complete the proof. By P1 and P2, we have O \u2208 I and S \u2286 O, and thus, S + v \u2208 I for all v \u2208 O \\ S because (N , I) is an independence system. Consequently, the termination condition of Algorithm 3 guarantees that \u2206f(v|S) \u2264 0 for all v \u2208 O \\ S. To use these observations, let us denote the elements of O \\ S by v1, v2, . . . , v|O\\S| in an arbitrary order. Then\nf(O) = f(S) + |O\\S|\u2211 i=1 \u2206f ( vi|S \u222a {v1, . . . , v|O\\S|} ) \u2264 f(S) + |O\\S|\u2211 i=1 \u2206f (vi|S) \u2264 f(S) ,\nwhere the first inequality follows by the submodularity of f . It remains to prove the lower bound on f(O). By definition, O is the set obtained from OPT after the elements of \u222au\u2208NOu are removed and the elements of S are added. Additionally, an element that is removed from O is never added to O again, unless it becomes a part of S. This implies that the sets {Ou \\ S}u\u2208N are disjoint and that O can also be written as\nO = (S \u222a OPT) \\ \u222au\u2208N (Ou \\ S) . (5)\nDenoting the the elements of N by u1, u2, . . . , un in an arbitrary order, and using the above,\nwe get\nf(O) = f(S \u222a OPT)\u2212 n\u2211 i=1 \u2206f (Oui \\ S|(S \u222a OPT) \\ \u222a1\u2264j<i(Oui \\ S)) (Equality (5))\n\u2265 f(S \u222a OPT)\u2212 n\u2211 i=1 \u2206f(Oui \\ S|Sui)\n\u2265 f(S \u222a OPT)\u2212 n\u2211 i=1 \u2211 v\u2208Oui\\S \u2206f(v|Sui)\n= f(S \u222a OPT)\u2212 \u2211 u\u2208N \u2211 v\u2208Ou\\S \u2206f(v|Sui) ,\nwhere the first inequality follows from the submodularity of f because Sui \u2286 S \u2286 (S\u222aOPT)\\ \u222au\u2208N (Ou \\ S) and the second inequality follows from the submodularity of f as well.\nTo complete the proof of the lemma we need one more observation. Consider an element u for which Ou is not empty. Since Ou is not empty, we know that u was considered by the algorithm at some iteration. Moreover, every element of Ou was also a possible candidate for consideration at this iteration, and thus, it must be the case that u was selected for consideration because its marginal contribution with respect to Su is at least as large as the marginal contribution of every element of Ou. Plugging this observation into the last inequality, we get the following desired lower bound on f(O).\nf(O) \u2265 f(S \u222a OPT)\u2212 \u2211 u\u2208N \u2211 v\u2208Ou\\S \u2206f(v|Sui) \u2265 f(S \u222a OPT)\u2212 \u2211 u\u2208N \u2211 v\u2208Ou\\S \u2206f(u|Sui)\n= f(S \u222a OPT)\u2212 \u2211 u\u2208N |Ou \\ S|\u2206f(u|Sui) .\nWhile the previous lemma was true deterministically, the next two lemmas are statements about expected values. At this point, it is convenient to define a new random variable. For every element u \u2208 N , let Xu be an indicator for the event that u is considered by Algorithm 3 in one of its iterations. The next lemma gives an expression for the expected value of S.\nLemma 5. E[f(S)] \u2265 1k+1 \u2211 u\u2208N E[Xu\u2206f(u|Su)].\nProof. For each u \u2208 N , let Gu be a random variable whose value is equal to in the increase in the value of S when u is added to S by Algorithm 3. If u is never added to S by Algorithm 3, then the value of Gu is simply 0. Clearly,\nf(S) = f(\u2205) + \u2211 u\u2208N Gu \u2265 \u2211 u\u2208N Gu .\nBy the linearity of expectation, it only remains to show that\nE[Gu] = 1\nk + 1 E[Xu\u2206f(u|Su)] . (6)\nLet Eu be an arbitrary event specifying all random decisions made by Algorithm 3 up until the iteration in which it considers u if u is considered, or all random decisions made by Algorithm 3 throughout its execution if u is never considered. By the law of total probability, since these events are disjoint, it is enough to prove that Equality (6) holds when conditioned on\nevery such event Eu. If Eu is an event that implies that Algorithm 3 does not consider u, then, by conditioning on Eu, we obtain\nE[Gu|Eu] = 0 = 1\nk + 1 E[0 \u00b7\u2206f(u|Su)|Eu] =\n1\nk + 1 E[Xu\u2206f(u|Su)|Eu] .\nOn the other hand, if Eu implies that Algorithm 3 does consider u, then we observe that Su is a deterministic set given Eu. Denoting this set by S\u2032u, we obtain\nE[Gu|Eu] = Pr [u \u2208 S | Eu] \u2206f(u|S\u2032u) = 1\nk + 1 \u2206f(u|S\u2032u) =\n1\nk + 1 E[Xu\u2206f(u|Su)|Eu] .\nwhere the second equality hold since an element considered by Algorithm 3 is added to S with probability (k + 1)\u22121.\nThe next lemma relates terms appearing in the last two lemmata. Intuitively, this lemma shows that Ou is on average a small set.\nLemma 6. For every element u \u2208 N ,\nE[|Ou \\ S|\u2206f(u|Su)] \u2264 k\nk + 1 E[Xu\u2206f(u|Su)] . (7)\nProof. As in the proof of Lemma 5, let Eu be an arbitrary event specifying all random decisions made by Algorithm 3 up until the iteration in which it considers u if u is considered, or all random decisions made by Algorithm 3 throughout its execution if it never considers u. By the law of total probability, since these events are disjoint, it is enough to prove Inequality (7) conditioned on every such event Eu. If Eu implies that u is not considered, then both |Ou| and Xu are 0 conditioned on Eu, and thus, the inequality holds as an equality. Thus, we may assume in the rest of the proof that Eu implies that u is considered by Algorithm 3. Notice that conditioned on Eu the set Su is deterministic and Xu takes the value 1. Denoting the deterministic value of Su conditioned on Eu by S\u2032u, Inequality (7) reduces to\nE[|Ou \\ S| | Eu]\u2206f(u|S\u2032u) \u2264 k\nk + 1 \u2206f(u|S\u2032u) .\nSince u is being considered, it must hold that \u2206f(u|S\u2032u) > 0, and thus, the above inequality is equivalent to E[|Ou \\ S| | Eu] \u2264 kk+1 . There are now two cases to consider. If Eu implies that u \u2208 O at the beginning of the iteration in which Algorithm 3 considers u, then Ou is empty if u is added to S and is {u} if u is not added to S. As u is added to S with probability 1k+1 , this gives\nE[|Ou \\ S| | Eu] \u2264 1\nk + 1 \u00b7 |\u2205|+\n( 1\u2212 1\nk + 1\n) |{u}| = k\nk + 1 ,\nand we are done. Consider now the case that Eu implies that u 6\u2208 O at the beginning of the iteration in which Algorithm 3 considers u. In this case, Ou is always of size at most k by the discussion following Algorithm 3, and it is empty when u is not added to S. As u is, again, added to S with probability 1k+1 , we get in this case\nE[|Ou \\ S| | Eu] \u2264 1\nk + 1 \u00b7 k +\n( 1\u2212 1\nk + 1\n) |\u2205| = k\nk + 1 .\nWe are now ready to prove Theorem 1.\nProof of Theorem 1. We prove here that Algorithm 2 achieves the approximation ratios guaranteed by Theorem 1 for submodular and monotone submodular objectives. The approximation ratio guaranteed by Theorem 1 for linear objectives is obtained, using similar ideas, by a close variant of Algorithm 2; and we defer a more detailed discussion of this variant and its guarantee to Appendix B.\nAs discussed earlier, Algorithms 2 and 3 have identical output distributions, and so it suffices to show that Algorithm 3 achieves the desired approximation ratios. Note that\nE[f(S)] \u2265 E[f(S \u222a OPT)]\u2212 \u2211 u\u2208N E[|Ou \\ S|\u2206f(u|Su)] (Lemma 4)\n\u2265 E[f(S \u222a OPT)]\u2212 k k + 1 \u2211 u\u2208N E[Xu\u2206f(u|Su)] (Lemma 6)\n\u2265 E[f(S \u222a OPT)]\u2212 kE[f(S)] . (Lemma 5)\nIf f is monotone, then the proof completes by rearranging the above inequality and observing that f(S \u222a OPT ) \u2265 f(OPT ). Otherwise, let us define g : 2N \u2192 R\u22650 as g(T ) = f(T \u222a OPT) for every T \u2286 N . One can observe that g is non-negative and submodular. Since S contains every element with probability at most (k + 1)\u22121, we get by Claim 1\nE[f(S \u222a OPT)] = E[g(S)] \u2265 (\n1\u2212 1 k + 1\n) g(\u2205) = k\nk + 1 f(OPT) .\nThe proof now completes by combining the two above inequalities, and rearranging."}, {"heading": "6 Experimental Results", "text": "In this section, we present results of an experiment on real dataset comparing the performance of REPEATEDGREEDY and SAMPLEGREEDY with other competitive algorithms. In particular, we compare our algorithms to the greedy algorithm and FANTOM, an O(krn)-time algorithm for nonmonotone submodular optimization introduced in [Mirzasoleiman et al., 2016]. We also boost SAMPLEGREEDY by taking the best of four runs, denoted Max Sample Greedy. We test these algorithms on a personalized movie recommendation system, and find that while REPEATEDGREEDY and SAMPLEGREEDY return comparable solutions to FANTOM, they run orders of magnitude faster. These initial results indicate that SAMPLEGREEDY may be applied (without any loss in performance) to massive problem instances that were previously intractable.\nIn the movie recommendation system application, we observe movie ratings from users, and our objective is to recommend movies to users based on their reported favorite genres. In particular, given a user-specified input of favorite genres, we would like to recommend a short list of movies that are diverse, and yet representative, of those genres. The similarity score between movies that we use is derived from user ratings, as in [Lindgren et al., 2015].\nLet us now describe the problem setting in more detail. LetN be a set of movies, and G be the set of all movie genres. For a movie i \u2208 N , we denote the set of genres of i by G(i) (each movie may have multiple genres). Similarly, for a genre g \u2208 G, denote the set of all movies in that genre by N (g). Let si,j be a non-negative similarity score between movies i, j \u2208 N , and suppose a user u seeks a representative set of movies from genres Gu \u2286 G. Note that the set of movies from these genres is Nu = \u222ag\u2208GuN (g). Thus, a reasonable utility function for choosing a diverse yet representative set of movies S for u is\nfu(S) = \u2211 i\u2208S \u2211 j\u2208Nu si,j \u2212 \u03bb \u2211 i\u2208S \u2211 j\u2208S si,j (8)\nfor some parameter 0 \u2264 \u03bb \u2264 1. Observe that the first term is a sum-coverage function that captures the representativeness of S, and the second term is a dispersion function penalizing similarity within S. Moreover, for \u03bb = 1 this utility function reduces to the simple cut function.\nThe user may specify an upper limitm on the number of movies in his recommended set. In addition, he is also allowed to specify an upper limit mg on the number of movies from genre g in the set for each g \u2208 Gu (we call the parameter mg a genre limit). The first constraint corresponds to an m-uniform matroid over Nu, while the second constraint corresponds to the intersection of |Gu| partition matroids (each imposing the genre limit of one genre). Thus, our constraints in this movie recommendation corresponds to the intersection of 1 + |Gu| matroids, which is a (1 + |Gu|)-extendible system (in fact, a more careful analysis shows that it corresponds to a |Gu|-extendible system).\nFor our experiments, we use the MovieLens 20M dataset, which features 20 million ratings of 27,000 movies by 138,000 users. To obtain a similarity score between movies, we take an approach developed in [Lindgren et al., 2015]. First, we fill missing entries of an incomplete movie-user matrix M \u2208 Rn\u00d7m via low-rank matrix completion [Cande\u0301s and Recht, 2008, Hastie et al., 2015], then we randomly sample to obtain a matrix M\u0303 \u2208 Rn\u00d7k where k m and the inner products between rows is preserved. The similarity score between movies i and j is then defined as the inner product of their corresponding rows in M\u0303 . In our experiment, we set the total recommended movies limit to m = 10. The genre limits mg are always equal for all genres, and we vary them from 1 to 9. Finally, we set our favorite genres Gu as Adventure, Animation and Fantasy. For each algorithm and test instance, we record the function value of the returned solution S and the number of calls to f , which is a machine-independent measure of run-time.\nFigure 1(a) shows the value of the solution sets for the various algorithms. As we see\nfrom Figure 1(a), FANTOM consistently returns a solution set with the highest function value; however, REPEATEDGREEDY and SAMPLEGREEDY return solution sets with similarly high function values. We see that Max Sample Greedy, even for four runs, significantly increases the performance for more constrained problems. Note that for such more constrained problems, Greedy returns solution sets with much lower function values. Figure 1(b) shows the number of function calls made by each algorithm as the genre limit mg is varied. For each algorithm, the number of function calls remains roughly constant as mg is varied\u2014this is due to the lazy greedy implementation that takes advantage of submodularity to reduce the number of function calls. We see that for our problem instances, REPEATEDGREEDY runs about an order of magnitude faster than FANTOM and SAMPLEGREEDY runs roughly three orders of magnitude faster than FANTOM. Moreover, boosting SAMPLEGREEDY by executing it a few times does not incur a significant increase in cost.\nTo better analyze the tradeoff between the utility of the solution value and the cost of run time, we compare the ratio of these measurements for the various algorithms using FANTOM as a baseline. See Figure 1(c) and 1(d) for these ratio comparisons for genre limits mg = 1 and mg = 4, respectively. For the case of mg = 1, we see that boosted SAMPLEGREEDY provides nearly the same utility as FANTOM, while only incurring 1.09% of the computational cost. Likewise, for the case of mg = 4, REPEATEDGREEDY achieves the same utility as FANTOM, while incurring only a quarter of the cost. Thus, we may conclude that our algorithms provide solutions whose quality is on par with current state of the art, and yet they run in a small fraction of the time.\nWhile Greedy may get stuck in poor locally optimal solutions, REPEATEDGREEDY and SAMPLEGREEDY avoid this by greedily combing through the solution space many times and selecting random sets, respectively. Fortunately, the movie recommendation system has a very interpretable solution so we can observe this phenomenon. See Figure 2 for the movies recommended by the different algorithms. Because mg = 1, we are constrained here to have at most one movie from Adventure, Animation and Fantasy. As seen in Figure 2, FANTOM and SAMPLEGREEDY return maximum size solution sets that are both diverse and representative of these genres. On the other hand, Greedy gets stuck choosing a single movie that belongs to all three genres, thus, precluding any other choice of movie from the solution set."}], "references": [{"title": "Fast algorithms for maximizing submodular functions", "author": ["Ashwinkumar Badanidiyuru", "Jan Vondr\u00e1k"], "venue": "In SODA,", "citeRegEx": "Badanidiyuru and Vondr\u00e1k.,? \\Q2014\\E", "shortCiteRegEx": "Badanidiyuru and Vondr\u00e1k.", "year": 2014}, {"title": "Constrained submodular maximization via a nonsymmetric technique", "author": ["Niv Buchbinder", "Moran Feldman"], "venue": "CoRR, abs/1611.03253,", "citeRegEx": "Buchbinder and Feldman.,? \\Q2016\\E", "shortCiteRegEx": "Buchbinder and Feldman.", "year": 2016}, {"title": "Deterministic algorithms for submodular maximization problems", "author": ["Niv Buchbinder", "Moran Feldman"], "venue": "In SODA,", "citeRegEx": "Buchbinder and Feldman.,? \\Q2016\\E", "shortCiteRegEx": "Buchbinder and Feldman.", "year": 2016}, {"title": "Submodular maximization with cardinality constrains", "author": ["Niv Buchbinder", "Moran Feldman", "Joesph (Seffi) Naor", "Roy Schwartz"], "venue": "In SODA,", "citeRegEx": "Buchbinder et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Buchbinder et al\\.", "year": 2014}, {"title": "A tight linear time (1/2)approximation for unconstrained submodular maximization", "author": ["Niv Buchbinder", "Moran Feldman", "Joseph Naor", "Roy Schwartz"], "venue": "SIAM J. Comput.,", "citeRegEx": "Buchbinder et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Buchbinder et al\\.", "year": 2015}, {"title": "Comparing apples and oranges: Query tradeoff in submodular maximization", "author": ["Niv Buchbinder", "Moran Feldman", "Roy Schwartz"], "venue": "In SODA,", "citeRegEx": "Buchbinder et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Buchbinder et al\\.", "year": 2015}, {"title": "Maximizing a monotone submodular function subject to a matroid constraint", "author": ["Gruia C\u0103linescu", "Chandra Chekuri", "Martin P\u00e1l", "Jan Vondr\u00e1k"], "venue": "SIAM Journal on Computing,", "citeRegEx": "C\u0103linescu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "C\u0103linescu et al\\.", "year": 2011}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel J. Cand\u00e9s", "Benjamin Recht"], "venue": "In Foundations of Computational Mathematics,", "citeRegEx": "Cand\u00e9s and Recht.,? \\Q2008\\E", "shortCiteRegEx": "Cand\u00e9s and Recht.", "year": 2008}, {"title": "The tail of the hypergeometric distribution", "author": ["Va\u0161ek Chv\u00e1tal"], "venue": "Discrete Mathematics,", "citeRegEx": "Chv\u00e1tal.,? \\Q1979\\E", "shortCiteRegEx": "Chv\u00e1tal.", "year": 1979}, {"title": "Matroids and the greedy algorithm", "author": ["Jack Edmonds"], "venue": "Mathematical programming,", "citeRegEx": "Edmonds.,? \\Q1971\\E", "shortCiteRegEx": "Edmonds.", "year": 1971}, {"title": "Turning down the noise in the blogosphere", "author": ["Khalid El-Arini", "Gaurav Veda", "Dafna Shahaf", "Carlos Guestrin"], "venue": "In KDD,", "citeRegEx": "El.Arini et al\\.,? \\Q2009\\E", "shortCiteRegEx": "El.Arini et al\\.", "year": 2009}, {"title": "Constrained submodular maximization: Beyond 1/e", "author": ["Alina Ene", "Huy L. Nguyen"], "venue": "In FOCS,", "citeRegEx": "Ene and Nguyen.,? \\Q2016\\E", "shortCiteRegEx": "Ene and Nguyen.", "year": 2016}, {"title": "Maximizing non-monotone submodular functions", "author": ["Uriel Feige", "Vahab S. Mirrokni", "Jan Vondr\u00e1k"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Feige et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feige et al\\.", "year": 2011}, {"title": "A unified continuous greedy algorithm for submodular maximization", "author": ["Moran Feldman", "Joseph Naor", "Roy Schwartz"], "venue": "In FOCS,", "citeRegEx": "Feldman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2011}, {"title": "Improved approximations for k-exchange systems - (extended abstract)", "author": ["Moran Feldman", "Joseph Naor", "Roy Schwartz", "Justin Ward"], "venue": "In ESA,", "citeRegEx": "Feldman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2011}, {"title": "An analysis of approximations for maximizing submodular set functions\u2014II", "author": ["Marshall L. Fisher", "George L. Nemhauser", "Laurence A. Wolsey"], "venue": "Mathematical Programming,", "citeRegEx": "Fisher et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Fisher et al\\.", "year": 1978}, {"title": "Submodular functions and optimization", "author": ["Satoru Fujishige"], "venue": "Elsevier Science,", "citeRegEx": "Fujishige.,? \\Q2005\\E", "shortCiteRegEx": "Fujishige.", "year": 2005}, {"title": "Submodular maximization by simulated annealing", "author": ["Shayan Oveis Gharan", "Jan Vondr\u00e1k"], "venue": "In SODA,", "citeRegEx": "Gharan and Vondr\u00e1k.,? \\Q2011\\E", "shortCiteRegEx": "Gharan and Vondr\u00e1k.", "year": 2011}, {"title": "Near-optimal MAP inference for determinantal point processes", "author": ["Jennifer Gillenwater", "Alex Kulesza", "Ben Taskar"], "venue": "In NIPS,", "citeRegEx": "Gillenwater et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gillenwater et al\\.", "year": 2012}, {"title": "Inferring networks of diffusion and influence", "author": ["Manuel Gomez Rodriguez", "Jure Leskovec", "Andreas Krause"], "venue": "In KDD,", "citeRegEx": "Rodriguez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rodriguez et al\\.", "year": 2010}, {"title": "Near-optimal sensor placements in gaussian processes", "author": ["Carlos Guestrin", "Andreas Krause", "Ajit Paul Singh"], "venue": "In ICML,", "citeRegEx": "Guestrin et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Guestrin et al\\.", "year": 2005}, {"title": "Constrained nonmonotone submodular maximization: Offline and secretary algorithms", "author": ["Anupam Gupta", "Aaron Roth", "Grant Schoenebeck", "Kunal Talwar"], "venue": "In WINE,", "citeRegEx": "Gupta et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2010}, {"title": "Matrix completion and lowrank svd via fast alternating least squares", "author": ["Trevor Hastie", "Rahul Mazumder", "Jason D. Lee", "Rexa Zadeh"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Hastie et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2015}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Hoeffding.,? \\Q1963\\E", "shortCiteRegEx": "Hoeffding.", "year": 1963}, {"title": "The efficacy of the \u201cgreedy", "author": ["Tom A. Jenkyns"], "venue": "South Eastern Conference on Combinatorics, Graph Theory and Computing,", "citeRegEx": "Jenkyns.,? \\Q1976\\E", "shortCiteRegEx": "Jenkyns.", "year": 1976}, {"title": "Maximizing the spread of influence through a social network", "author": ["David Kempe", "Jon Kleinberg", "\u00c9va Tardos"], "venue": "In KDD,", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "Submodularity for data selection in statistical machine translation", "author": ["Katrin Kirchhoff", "Jeff Bilmes"], "venue": "In EMNLP,", "citeRegEx": "Kirchhoff and Bilmes.,? \\Q2014\\E", "shortCiteRegEx": "Kirchhoff and Bilmes.", "year": 2014}, {"title": "Submodular maximization over multiple matroids via generalized exchange properties", "author": ["Jon Lee", "Maxim Sviridenko", "Jan Vondr\u00e1k"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Lee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Cost-effective outbreak detection in networks", "author": ["Jure Leskovec", "Andreas Krause", "Carlos Guestrin", "Christos Faloutsos", "Jeanne Van Briesen", "Natalie Glance"], "venue": "In KDD,", "citeRegEx": "Leskovec et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2007}, {"title": "A class of submodular functions for document summarization", "author": ["Hui Lin", "Jeff Bilmes"], "venue": "In ACL,", "citeRegEx": "Lin and Bilmes.,? \\Q2011\\E", "shortCiteRegEx": "Lin and Bilmes.", "year": 2011}, {"title": "Sparse and greedy: Sparsifying submodular facility location problems", "author": ["Erik M. Lindgren", "Shanshan Wu", "Alexandros G. Dimakis"], "venue": "In NIPS Workshop on Optimization for Machine Learning,", "citeRegEx": "Lindgren et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lindgren et al\\.", "year": 2015}, {"title": "Greedy in approximation algorithms", "author": ["Juli\u00e1n Mestre"], "venue": "In ESA, pages 528\u2013539,", "citeRegEx": "Mestre.,? \\Q2006\\E", "shortCiteRegEx": "Mestre.", "year": 2006}, {"title": "Distributed submodular maximization: Identifying representative elements in massive data", "author": ["Baharan Mirzasoleiman", "Amin Karbasi", "Rik Sarkar", "Andreas Krause"], "venue": "In NIPS,", "citeRegEx": "Mirzasoleiman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mirzasoleiman et al\\.", "year": 2013}, {"title": "Lazier than lazy greedy", "author": ["Baharan Mirzasoleiman", "Ashwinkumar Badanidiyuru", "Amin Karbasi", "Jan Vondrak", "Andreas Krause"], "venue": "In AAAI,", "citeRegEx": "Mirzasoleiman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mirzasoleiman et al\\.", "year": 2015}, {"title": "Fast constrained submodular maximization: Personalized data summarization", "author": ["Baharan Mirzasoleiman", "Ashwinkumar Badanidiyuru", "Amin Karbasi"], "venue": "In ICML,", "citeRegEx": "Mirzasoleiman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mirzasoleiman et al\\.", "year": 2016}, {"title": "Best algorithms for approximating the maximum of a submodular set function", "author": ["George L. Nemhauser", "Laurence A. Wolsey"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Nemhauser and Wolsey.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser and Wolsey.", "year": 1978}, {"title": "An analysis of approximations for maximizing submodular set functions\u2014I", "author": ["George L. Nemhauser", "Laurence A. Wolsey", "Marshall L. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "Scaling the indian buffet process via submodular maximization", "author": ["Colorado Reed", "Zoubin Ghahramani"], "venue": "In ICML,", "citeRegEx": "Reed and Ghahramani.,? \\Q2013\\E", "shortCiteRegEx": "Reed and Ghahramani.", "year": 2013}, {"title": "Nearoptimally teaching the crowd to classify", "author": ["Adish Singla", "Ilija Bogunovic", "G\u00e1bor Bart\u00f3k", "Amin Karbasi", "Andreas Krause"], "venue": "In ICML,", "citeRegEx": "Singla et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Singla et al\\.", "year": 2014}, {"title": "Temporal corpus summarization using submodular word coverage", "author": ["Ruben Sipos", "Adith Swaminathan", "Pannaga Shivaswamy", "Thorsten Joachims"], "venue": "In CIKM,", "citeRegEx": "Sipos et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sipos et al\\.", "year": 2012}, {"title": "Hypergeometric tail inequalities: ending the insanity", "author": ["Matthew Skala"], "venue": "CoRR, abs/1311.5939,", "citeRegEx": "Skala.,? \\Q2013\\E", "shortCiteRegEx": "Skala.", "year": 2013}, {"title": "Symmetry and approximability of submodular maximization problems", "author": ["Jan Vondr\u00e1k"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Vondr\u00e1k.,? \\Q2013\\E", "shortCiteRegEx": "Vondr\u00e1k.", "year": 2013}, {"title": "A (k+3)/2-approximation algorithm for monotone submodular k-set packing and general k-exchange systems", "author": ["Justin Ward"], "venue": "In STACS,", "citeRegEx": "Ward.,? \\Q2012\\E", "shortCiteRegEx": "Ward.", "year": 2012}], "referenceMentions": [{"referenceID": 25, "context": "As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al.", "startOffset": 116, "endOffset": 136}, {"referenceID": 20, "context": ", 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al.", "startOffset": 52, "endOffset": 75}, {"referenceID": 10, "context": ", 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al.", "startOffset": 37, "endOffset": 60}, {"referenceID": 37, "context": ", 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al.", "startOffset": 32, "endOffset": 59}, {"referenceID": 32, "context": ", 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al.", "startOffset": 28, "endOffset": 56}, {"referenceID": 38, "context": ", 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al.", "startOffset": 24, "endOffset": 45}, {"referenceID": 18, "context": ", 2014], and MAP inference of determinental point process [Gillenwater et al., 2012].", "startOffset": 58, "endOffset": 84}, {"referenceID": 9, "context": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints. In this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity).", "startOffset": 22, "endOffset": 1755}, {"referenceID": 9, "context": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints. In this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity). In contrast, results for the maximization of non-monotone submodular functions subject to a k-system constraint were only obtained much more recently. Specifically, Gupta et al. [2010] showed that, by repeatedly executing the greedy algorithm and an algorithm for unconstrained submodular maximization, one can maximize a non-monotone submodular function subject to a k-system constraint up to an approximation ratio of roughly 3k using a time complexity of O(nrk)1.", "startOffset": 22, "endOffset": 2133}, {"referenceID": 9, "context": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints. In this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity). In contrast, results for the maximization of non-monotone submodular functions subject to a k-system constraint were only obtained much more recently. Specifically, Gupta et al. [2010] showed that, by repeatedly executing the greedy algorithm and an algorithm for unconstrained submodular maximization, one can maximize a non-monotone submodular function subject to a k-system constraint up to an approximation ratio of roughly 3k using a time complexity of O(nrk)1. This was recently improved by Mirzasoleiman et al. [2016], who showed that the approximation ratio obtained by the above approach is in fact roughly 2k.", "startOffset": 22, "endOffset": 2473}, {"referenceID": 9, "context": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints. In this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity). In contrast, results for the maximization of non-monotone submodular functions subject to a k-system constraint were only obtained much more recently. Specifically, Gupta et al. [2010] showed that, by repeatedly executing the greedy algorithm and an algorithm for unconstrained submodular maximization, one can maximize a non-monotone submodular function subject to a k-system constraint up to an approximation ratio of roughly 3k using a time complexity of O(nrk)1. This was recently improved by Mirzasoleiman et al. [2016], who showed that the approximation ratio obtained by the above approach is in fact roughly 2k. The algorithms we describe in this paper improve over the above mentioned results both in terms of the approximation ratio and in terms of the time complexity. Our first result is a deterministic algorithm, called REPEATEDGREEDY, which obtains an approximation ratio of (1 + O(1/ \u221a k))k for the maximization of a non-monotone submodular function subject to a k-system constraint using a time complexity of only O(nr \u221a k). REPEATEDGREEDY is structurally very similar to the algorithm of Gupta et al. [2010] and Mirzasoleiman et al.", "startOffset": 22, "endOffset": 3074}, {"referenceID": 9, "context": "Submodular functions [Edmonds, 1971, Fujishige, 2005], originated in combinatorial optimization and operations research, exhibit a natural diminishing returns property common in many well known objectives: the marginal benefit of any given element decreases as more and more elements are selected. As a result, submodular optimization has found numerous applications in machine learning, including viral marketing [Kempe et al., 2003], network monitoring [Leskovec et al., 2007, Gomez Rodriguez et al., 2010], sensor placement and information gathering [Guestrin et al., 2005], news article recommendation [El-Arini et al., 2009], nonparametric learning [Reed and Ghahramani, 2013], document and corpus summarization [Lin and Bilmes, 2011, Kirchhoff and Bilmes, 2014, Sipos et al., 2012], data summarization [Mirzasoleiman et al., 2013], crowd teaching [Singla et al., 2014], and MAP inference of determinental point process [Gillenwater et al., 2012]. The usefulness of submodular optimization in these settings stems from the fact that many such problems can be reduced to the problem of maximizing a submodular function subject to feasibility constraints, such as cardinality, knapsack, matroid or intersection of matroids constraints. In this paper, we consider the maximization of submodular functions subject to two important classes of constraints known as k-system and k-extendible system constraints. The class of k-system constraints is a very general class of constraints capturing, for example, any constraint which can be represented as the intersection of multiple matroid and matching constraints. The study of the maximization of monotone submodular functions subject to a k-system constraint goes back to the work of Fisher et al. [1978], who showed that the natural greedy algorithm achieves an approximation ratio of 1/(k+ 1) for this problem (k is a parameter of the k-system constraint measuring, intuitively, its complexity). In contrast, results for the maximization of non-monotone submodular functions subject to a k-system constraint were only obtained much more recently. Specifically, Gupta et al. [2010] showed that, by repeatedly executing the greedy algorithm and an algorithm for unconstrained submodular maximization, one can maximize a non-monotone submodular function subject to a k-system constraint up to an approximation ratio of roughly 3k using a time complexity of O(nrk)1. This was recently improved by Mirzasoleiman et al. [2016], who showed that the approximation ratio obtained by the above approach is in fact roughly 2k. The algorithms we describe in this paper improve over the above mentioned results both in terms of the approximation ratio and in terms of the time complexity. Our first result is a deterministic algorithm, called REPEATEDGREEDY, which obtains an approximation ratio of (1 + O(1/ \u221a k))k for the maximization of a non-monotone submodular function subject to a k-system constraint using a time complexity of only O(nr \u221a k). REPEATEDGREEDY is structurally very similar to the algorithm of Gupta et al. [2010] and Mirzasoleiman et al. [2016]. However, thanks to a tighter analysis, it needs to execute the greedy algorithm and the algorithm for unconstrained submodular maximization much less often, which yields its improvement in the time complexity.", "startOffset": 22, "endOffset": 3106}, {"referenceID": 31, "context": "Table 1: Summary of Results for Non-monotone Submodular Objectives Approximation Ratio Time Complexity SAMPLEGREEDY (randomized) (k + 1)/k \u2264 k + 3 O(n+ nr/k) REPEATEDGREEDY (deterministic) k +O( \u221a k) O(nr \u221a k) Mirzasoleiman et al. [2016] \u2248 2k O(nrk) Gupta et al.", "startOffset": 210, "endOffset": 238}, {"referenceID": 21, "context": "[2016] \u2248 2k O(nrk) Gupta et al. [2010] \u2248 3k O(nrk) Inapproximability (1\u2212 e\u2212k)\u22121 \u2212 \u03b5 \u2265 k + 1/2\u2212 \u03b5 \u2212", "startOffset": 19, "endOffset": 39}, {"referenceID": 0, "context": "Previously, it was known that no polynomial time algorithm can have an approximation ratio of k \u2212 \u03b5 (for any constant \u03b5 > 0) for the problem of maximizing a linear function subject to a k-system constraint [Badanidiyuru and Vondr\u00e1k, 2014].", "startOffset": 206, "endOffset": 238}, {"referenceID": 0, "context": "Previously, it was known that no polynomial time algorithm can have an approximation ratio of k \u2212 \u03b5 (for any constant \u03b5 > 0) for the problem of maximizing a linear function subject to a k-system constraint [Badanidiyuru and Vondr\u00e1k, 2014]. We show that this result extends also to k-extendible systems, i.e., that no polynomial time algorithm can have an approximation ratio of k\u2212 for the problem of maximizing a linear function subject to a k-extendible system constraint. Moreover, for monotone submodular functions we manage to get a slightly stronger inapproximability result. Namely, we show that no polynomial time algorithm can have an approximation ratio of 1/(1 \u2212 e\u2212k) \u2212 \u03b5 \u2264 k + 1/2 \u2212 \u03b5 for the problem of maximizing a monotone submodular function subject to a k-extendible system constraint. Note that the gap between the approximation ratio obtained by SAMPLEGREEDY (namely, (k + 3)) and the inapproximability result (namely, (k + 1/2 \u2212 \u03b5)) is very small. A short summary of all the results discussed above for non-monotone submodular objectives can be found in Table 1. Finally, we compare the performance of REPEATEDGREEDY and SAMPLEGREEDY against FATNOM, the current state of the art algorithm introduced by Mirzasoleiman et al. [2016]. We test these algorithms on a movie recommendation problem using the MovieLens dataset, which consists of over 20 million ratings of 27,000 movies by 138,000 users.", "startOffset": 207, "endOffset": 1250}, {"referenceID": 35, "context": "Moreover, both results are known to be optimal [Nemhauser and Wolsey, 1978].", "startOffset": 47, "endOffset": 75}, {"referenceID": 17, "context": "478 [Gharan and Vondr\u00e1k, 2011].", "startOffset": 4, "endOffset": 30}, {"referenceID": 16, "context": "Lee et al. [2010] described a local search algorithm achieving an approximation ratio of k+ for maximizing a monotone submodular function subject to the intersection of any k matroid constraints, and explained how to use multiple executions of this algorithm to get an approximation ratio of k+1+ 1 k+1 +\u03b5 for this problem even when the objective function is non-monotone.", "startOffset": 0, "endOffset": 18}, {"referenceID": 5, "context": "Later, Feldman et al. [2011b] showed, via a different analysis, that the same local search algorithm can also be used to get essentially the same results for the maximization of a submodular function subject to a subclass of k-extendible system constraints known as k-exchange system constraints (this class of constraints captures the intersection of multiple matching and strongly orderable matroid constraints).", "startOffset": 7, "endOffset": 30}, {"referenceID": 5, "context": "Later, Feldman et al. [2011b] showed, via a different analysis, that the same local search algorithm can also be used to get essentially the same results for the maximization of a submodular function subject to a subclass of k-extendible system constraints known as k-exchange system constraints (this class of constraints captures the intersection of multiple matching and strongly orderable matroid constraints). For k \u2265 4, the approximation ratio of [Feldman et al., 2011b] for the case of a monotone submodular objective was later improved by Ward [2012] to (k + 3)/2 + \u03b5.", "startOffset": 7, "endOffset": 559}, {"referenceID": 5, "context": "Later, Feldman et al. [2011b] showed, via a different analysis, that the same local search algorithm can also be used to get essentially the same results for the maximization of a submodular function subject to a subclass of k-extendible system constraints known as k-exchange system constraints (this class of constraints captures the intersection of multiple matching and strongly orderable matroid constraints). For k \u2265 4, the approximation ratio of [Feldman et al., 2011b] for the case of a monotone submodular objective was later improved by Ward [2012] to (k + 3)/2 + \u03b5. An even more special case of k-extendible systems are the simple matroid constraints. In their classical work, Nemhauser et al. [1978] showed that the natural greedy algorithm gives an approximation ratio of 1 \u2212 1/e for maximizing a monotone submodular function subject to a uniform matroid constraint (also known as cardinality constraint), and C\u0103linescu et al.", "startOffset": 7, "endOffset": 712}, {"referenceID": 0, "context": "[1978] showed that the natural greedy algorithm gives an approximation ratio of 1 \u2212 1/e for maximizing a monotone submodular function subject to a uniform matroid constraint (also known as cardinality constraint), and C\u0103linescu et al. [2011] later obtained the same approximation ratio for general matroid constraints using the Continuous Greedy algorithm.", "startOffset": 218, "endOffset": 242}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).", "startOffset": 0, "endOffset": 32}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n).", "startOffset": 0, "endOffset": 381}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n). Independently, Buchbinder et al. [2015b] showed that a technique similar to Mirzasoleiman et al.", "startOffset": 0, "endOffset": 577}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n). Independently, Buchbinder et al. [2015b] showed that a technique similar to Mirzasoleiman et al. [2015] can be used to get also (e\u22121\u2212 \u03b5)-approximation for maximizing a non-monotone submodular function subject to a cardinality constraint using a time complexity of O\u03b5(n).", "startOffset": 0, "endOffset": 640}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n). Independently, Buchbinder et al. [2015b] showed that a technique similar to Mirzasoleiman et al. [2015] can be used to get also (e\u22121\u2212 \u03b5)-approximation for maximizing a non-monotone submodular function subject to a cardinality constraint using a time complexity of O\u03b5(n). Buchbinder et al. [2015b] also described a different (1 \u2212 1/e \u2212 \u03b5)-approximation algorithm for maximizing a monotone submodular function subject to a general matroid constraint.", "startOffset": 0, "endOffset": 833}, {"referenceID": 0, "context": "Badanidiyuru and Vondr\u00e1k [2014] described algorithms that achieve an approximation ratio of 1 \u2212 1/e \u2212 \u03b5 for maximizing a monotone submodular function subject to uniform and general matroid constraints using time complexities of O\u03b5(n log k) and O\u03b5(nr log 2 n), respectively (O\u03b5 suppresses a polynomial dependence on \u03b5).3 For uniform matroid constraints, Mirzasoleiman et al. [2015] showed that one can completely get rid of the dependence on r, and get an algorithm with the same approximation ratio whose time complexity is only O\u03b5(n). Independently, Buchbinder et al. [2015b] showed that a technique similar to Mirzasoleiman et al. [2015] can be used to get also (e\u22121\u2212 \u03b5)-approximation for maximizing a non-monotone submodular function subject to a cardinality constraint using a time complexity of O\u03b5(n). Buchbinder et al. [2015b] also described a different (1 \u2212 1/e \u2212 \u03b5)-approximation algorithm for maximizing a monotone submodular function subject to a general matroid constraint. The time complexity of this algorithm isO\u03b5(r +n \u221a r log n) for general matroids, and it can be improved to O\u03b5(r \u221a n log n+ n log n) for generalized partition matroids. 3Badanidiyuru and Vondr\u00e1k [2014] also describe a fast algorithm for maximizing a monotone submodular function subject to a knapsack constraint.", "startOffset": 0, "endOffset": 1186}, {"referenceID": 31, "context": "An important special case of k-systems are the k-extendible systems, which were first introduced by Mestre [2006]. We say that an independent set B is an extension of an independent set A if B strictly contains A.", "startOffset": 100, "endOffset": 114}, {"referenceID": 12, "context": "4See [Feige et al., 2011] for an explanation why submodular functions that can take negative values cannot be maximized even approximately.", "startOffset": 5, "endOffset": 25}, {"referenceID": 31, "context": "As is shown by Mestre [2006], the intersection of k matroids defined on a common ground set is always a k-extendible system.", "startOffset": 15, "endOffset": 29}, {"referenceID": 1, "context": "We note that Buchbinder and Feldman [2016b] recently came up with a deterministic algorithm for unconstrained submodular maximization having an optimal approximation ratio of 2.", "startOffset": 13, "endOffset": 44}, {"referenceID": 1, "context": "We note that Buchbinder and Feldman [2016b] recently came up with a deterministic algorithm for unconstrained submodular maximization having an optimal approximation ratio of 2. Using this algorithm instead of the deterministic algorithm of Buchbinder et al. [2015a] could marginally improve the approximation ratio guaranteed by Theorem 2.", "startOffset": 13, "endOffset": 267}, {"referenceID": 1, "context": "We note that Buchbinder and Feldman [2016b] recently came up with a deterministic algorithm for unconstrained submodular maximization having an optimal approximation ratio of 2. Using this algorithm instead of the deterministic algorithm of Buchbinder et al. [2015a] could marginally improve the approximation ratio guaranteed by Theorem 2. However, the algorithm of Buchbinder and Feldman [2016a] has a quadratic time complexity, and thus, it is less practical.", "startOffset": 13, "endOffset": 398}, {"referenceID": 1, "context": "We note that Buchbinder and Feldman [2016b] recently came up with a deterministic algorithm for unconstrained submodular maximization having an optimal approximation ratio of 2. Using this algorithm instead of the deterministic algorithm of Buchbinder et al. [2015a] could marginally improve the approximation ratio guaranteed by Theorem 2. However, the algorithm of Buchbinder and Feldman [2016a] has a quadratic time complexity, and thus, it is less practical. It is also worth noting that Buchbinder et al. [2015a] also describe a randomized linear-time algorithm for unconstrained submodular maximization which again achieves the optimal approximation ratio of 2.", "startOffset": 13, "endOffset": 518}, {"referenceID": 6, "context": "Interestingly, this approximation ratio can in fact be reached in the fractional case even for k-system constraints using the well known (computationally heavy) Continuous Greedy algorithm of C\u0103linescu et al. [2011]. Thus, we get the second implication of the above observation, which is that further improving our inapproximability results requires the use of new techniques since the current technique cannot lead to different results for the fractional and non-fractional problems.", "startOffset": 192, "endOffset": 216}, {"referenceID": 21, "context": "2 of [Gupta et al. [2010]] which states that the sets S obtained by running greedy with a k-system constraint must obey f(S) \u2265 1 k+1f(S \u222a C) for all independent sets C of the k-system.", "startOffset": 6, "endOffset": 26}, {"referenceID": 3, "context": "2 of Buchbinder et al. [2014]).", "startOffset": 5, "endOffset": 30}, {"referenceID": 34, "context": "In particular, we compare our algorithms to the greedy algorithm and FANTOM, an O(krn)-time algorithm for nonmonotone submodular optimization introduced in [Mirzasoleiman et al., 2016].", "startOffset": 156, "endOffset": 184}, {"referenceID": 30, "context": "The similarity score between movies that we use is derived from user ratings, as in [Lindgren et al., 2015].", "startOffset": 84, "endOffset": 107}, {"referenceID": 30, "context": "To obtain a similarity score between movies, we take an approach developed in [Lindgren et al., 2015].", "startOffset": 78, "endOffset": 101}], "year": 2017, "abstractText": "It is known that greedy methods perform well for maximizing monotone submodular functions. At the same time, such methods perform poorly in the face of non-monotonicity. In this paper, we show\u2014arguably, surprisingly\u2014that invoking the classical greedy algorithm O( \u221a k)-times leads to the (currently) fastest deterministic algorithm, called REPEATEDGREEDY, for maximizing a general submodular function subject to k-independent system constraints. REPEATEDGREEDY achieves (1+O(1/ \u221a k))k approximation using O(nr \u221a k) function evaluations (here, n and r denote the size of the ground set and the maximum size of a feasible solution, respectively). We then show that by a careful sampling procedure, we can run the greedy algorithm only once and obtain the (currently) fastest randomized algorithm, called SAMPLEGREEDY, for maximizing a submodular function subject to kextendible system constraints (a subclass of k-independent system constrains). SAMPLEGREEDY achieves (k+3)-approximation with only O(nr/k) function evaluations. Finally, we derive an almost matching lower bound, and show that no polynomial time algorithm can have an approximation ratio smaller than k + 1/2\u2212 \u03b5. To further support our theoretical results, we compare the performance of REPEATEDGREEDY and SAMPLEGREEDY with prior art in a concrete application (movie recommendation). We consistently observe that while SAMPLEGREEDY achieves practically the same utility as the best baseline, it performs at least two orders of magnitude faster.", "creator": "LaTeX with hyperref package"}}}