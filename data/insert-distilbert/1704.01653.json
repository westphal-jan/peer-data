{"id": "1704.01653", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Apr-2017", "title": "Automatic Measurement of Pre-aspiration", "abstract": "pre - aspiration is defined as the period of glottal friction occurring in sequences of vocalic / consonantal stop sonorants and phonetically voiceless obstruents. highlighted in this paper, we propose two machine learning methods for automatic measurement of pre - aspiration duration : feedforward neural network, which works at the frame level ; and structured prediction model, which relies on manually designed feature functions, and works at analyzing the segment level. the input for both algorithms is a speech signal of an arbitrary length containing around a single obstruent, and the output is a pair of times which constitutes the pre - aspiration sentence boundaries. we train also both models on a set of manually calculated annotated examples. results suggest that the structured model is superior to even the frame - based model depicted as stating it yields higher accuracy in predicting the boundaries and generalizes to new speakers and new languages. finally, we demonstrate the applicability of our structured prediction algorithm by replicating linguistic analysis of pre - aspiration in aberystwyth english with high correlation.", "histories": [["v1", "Wed, 5 Apr 2017 21:10:07 GMT  (858kb,D)", "https://arxiv.org/abs/1704.01653v1", null], ["v2", "Sun, 28 May 2017 18:56:58 GMT  (859kb,D)", "http://arxiv.org/abs/1704.01653v2", null], ["v3", "Thu, 15 Jun 2017 09:47:26 GMT  (859kb,D)", "http://arxiv.org/abs/1704.01653v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yaniv sheena", "m\\'i\\v{s}a hejn\\'a", "yossi adi", "joseph keshet"], "accepted": false, "id": "1704.01653"}, "pdf": {"name": "1704.01653.pdf", "metadata": {"source": "CRF", "title": "Automatic Measurement of Pre-aspiration", "authors": ["Yaniv Sheena", "M\u0131\u0301\u0161a Hejn\u00e1", "Yossi Adi", "Joseph Keshet"], "emails": ["yaniv.sheena@live.biu.ac.il,", "misa.hejna@cc.au.dk,", "jkeshet@cs.biu.ac.il"], "sections": [{"heading": "1. Introduction", "text": "Pre-aspiration is a period of (primarily) glottal friction, which is found in the sequences of sonorants and phonetically voiceless obstruents prior to the release of the consonant, e.g., in Welsh English kit /khIhts/, miss /mIhs/, milk /mIl\n\u02da kh/, etc. Al-\nthough pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315]. Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].\nMost of the work on pre-aspiration has been based on subjective, labor-intensive manual annotation. The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].\nIn this paper we tackle the problem of automatic measurement of pre-aspiration duration. We propose two algorithms for this purpose. The first one is a feedforward neural network, which works at the frame-level, and the second algorithm is based on structured prediction techniques which rely on highly tuned feature maps which were specifically designed for the task, and which works at the segment level.\nAs far as we know this is the first attempt to automatically detect pre-aspiration. This work is based on our ongoing work on designing and developing machine learning algorithms for automatically measuring with high precision, phonetic properties of speech at the level of human inter-transcriber reliabil-\nity [22\u201326]. Our methods rely on several advances over existing computational systems: novel representations of the speech signal and new structured prediction and deep learning algorithms. These automatic methods allow for low-cost replication of phonetic studies and expand the range of empirical and theoretical issues we can address.\nThe code is available to used by the research community. It can be downloaded from https://github.com/ MLSpeech/AutoPreaspiration."}, {"heading": "2. Problem Setting", "text": "In the context of a typical phonological study, given a portion of an acoustic signal of an arbitrary length, the goal of an automatic pre-aspiration measurement algorithm is to predict the onset and offset times of pre-aspiration as accurate as possible. In this work we assume that the acoustic signal contains exactly one coded obstruent within a word and the signal starts before the expected pre-aspiration, i.e., during the previous phoneme.\nWe turn to describing the problem formally. Throughout the paper, scalars are denoted using lower case Latin letters, e.g., x, and vectors using bold face letters, e.g., x. A sequence of elements is denoted with a bar x\u0304 and its length is written as |x\u0304|.\nThe acoustic input is represented as a sequence of feature vectors, x\u0304 = (x1, . . . ,xT ), where each vector, xt, is Ddimensional vector which represents the acoustic content of the t-frame (1 \u2264 t \u2264 T ). The domain of the feature vectors is denoted as X \u2282 RD . The acoustic input is of an arbitrary length, hence the number of frames, T , is not fixed. We denote by X \u2217 the set of all finite-length sequences over X .\nEach acoustic input is associated with a timing pair: the onset of the pre-aspiration, ts \u2208 T , and the offset of the preaspiration, te \u2208 T , where T = {1, . . . , T}. To sum up, given the speech interval x\u0304, our goal is to learn a function f from the domain of all acoustic inputs X \u2217 to the domain of all possible onset offset pairs T 2. Our notation is depicted in Figure 1."}, {"heading": "3. Learning Apparatus", "text": "In this section, we describe how we learn the prediction function from a training set of examples. We denote the training set of\nar X\niv :1\n70 4.\n01 65\n3v 3\n[ cs\n.C L\n] 1\n5 Ju\nn 20\n17\nm examples by S = {(x\u0304i, tis, tie)}mi=1, where the i-th example is composed of a sequence of acoustic features x\u0304i labeled with an onset and offset pair, (tis, tie).\nLet us denote the predicted onset and offset pair by (t\u0302s, t\u0302e), namely (t\u0302s, t\u0302e) = f\u03b8(x\u0304), where \u03b8 denotes the set of parameters of the prediction function f . In order to assess the quality of the prediction we use a task loss function, \u03b3 ( (te, ts), (t\u0302e, t\u0302s) ) , which returns a real positive number that measures how the prediction pair (t\u0302s, t\u0302e) is close to the manually annotated pair (te, ts). Our goal in learning is to find the set of parameters \u03b8 so as to minimize the expected task loss.\nWe start by describing the acoustic features, and then two different machine learning algorithms that learn the parameters of function f . The first algorithm works at the frame level and hence cannot aim at minimizing a global task loss function, while the second algorithm is aimed directly at minimizing the expected task loss. These differences are reflected in the accuracy level of the different algorithms."}, {"heading": "3.1. Acoustic features", "text": "For both machine learning models, we extract the same set of features. Consider the acoustic input x\u0304 = (x1, . . . ,xT ) consisting of T frames, where each acoustic feature vector xt consists of D features. Similar to [22], we extract eight (D=8) acoustic features from the speech signal every 1 ms. The first four features refer to the total spectral energy (Etotal), energy between 50-1000 Hz (Elow), energy above 3000 Hz (Ehigh), and Wiener entropy (Hwiener) \u2014 all are based on the short-time Fourier transform (STFT) taken every 1 ms with a 5 ms Hamming window. The fifth feature, Pmax, is the maximum of the power spectrum calculated in a region from 6 ms before to 18 ms after the frame center. The sixth feature (Rl) is the pitch of the signal using a real-time pitch detector [27]. The seventh feature is the 0/1 output of a voicing detector based on the RAPT pitch tracker [28], smoothed with a 5 ms Hamming window (V ). The last feature is the number of zero crossings (ZC) in a 5 ms window around the frame center."}, {"heading": "3.2. Frame-based model", "text": "Our first model works at the frame level. We train a binary classifier such that given an input speech frame xt predicts whether or not it is associated with a pre-aspiration event. In order to take advantage of the local temporal context of each time-frame, the input of this binary classifier is based on five concatenated feature vectors (xt\u22122,xt\u22121,xt,xt+1,xt+2) rather than a single frame. We use a feedforward neural network. We tried several network architectures, and chose the one that performed best on a validation set. The network consists of an input layer of 40 units (recall that we extract D = 8 feature per frame, and have 5 consecutive frames), a hidden layer of 40 units with ReLU activation function and a dropout rate of 0.3, and one output unit followed by a sigmoid. The network was trained to minimize the binary cross entropy loss using the gradient descent optimization algorithm.\nAt inference time, we use the trained model sequentially over the input frames to produce a sequence of predictions. Since this sequence can be noisy, we smooth it out using a moving average, followed by a binary mapping that uses a threshold for each such average. In the final step, we search the longest subsequence of frames that were predicted as associated with pre-aspiration, and output its boundaries as the onset and offset of the pre-aspiration."}, {"heading": "3.3. Structured model", "text": "The second algorithm takes advantage of the input as a whole segment, hence we can introduce feature maps such as typical pre-aspiration duration, mean energy during the presumed preaspiration compared to the mean energy before or after the preaspiration. Similar to previous work in structured prediction [29, 30], the function f is constructed from a predefined set of N feature maps {\u03c6i}Ni=1, each of the form \u03c6i : X\u00d7T \u00d7T \u00d7 \u2192 RN , and a weight vector w \u2208 RN . The function is a linear predictor of the following form\n(t\u0302s, t\u0302e) = arg max (ts,te)\nw \u00b7 \u03c6(x\u0304, ts, te), (1)\nwhere we have used vector notation for the feature maps \u03c6 = (\u03c61, . . . , \u03c6N )\n>. This vector-valued function is used to map the variable length of input speech along with a presumed onsetoffset pair to an abstract vector space in RN (described in 3.4).\nThe algorithm presented here aims to find the weights w that minimize the expected task loss function \u03b3 which measures the distance between predicted and manually coded labels. In a similar manner to [22], we define the task loss function as follows:\n\u03b3 ( (te, ts), (t\u0302e, t\u0302s) ) = max{|(t\u0302e\u2212 t\u0302s)\u2212(te\u2212ts)|\u2212 , 0}. (2)\nThat is, only the differences between the predicted preaspiration and the manually labeled pre-aspiration that are greater than a threshold (in milliseconds), are penalized. This task loss function takes into account that manual measurements are not usually exact, and can be adjusted according to the level of measurement uncertainty in a dataset.\nThe weight vector w is learned using an iterative algorithm based on the Passive-Aggressive family of algorithms for structured prediction [31]. Let wt be the weight vector after the t-th iteration, and let w0 = 0. At each iteration a single example (x\u0304i, tis, t i e) is considered, and the current weight vector wt is updated by finding the solution to the following optimization problem:\nwt+1 = arg min w,\u03be\u22650\n1 2 \u2016w \u2212wt\u20162 + C\u03be\ns.t. w \u00b7 \u03c6(x\u0304i, tis, tie)\u2212w \u00b7 \u03c6(x\u0304i, t\u0303s, t\u0303e) \u2265 \u03b3i \u2212 \u03be , (3)\nwhere \u03b3i = \u03b3 ( (tis, t i e), (t\u0303s, t\u0303e) ) , C serves as a trade-off parameter between loss and regularization minimization, and \u03be is a non-negative slack variable.\nThe optimization problem tries to keep the new weight vector w close to the previous weight vector wt while satisfying the constraint that the score of the manually annotated onsetoffset pair w \u00b7 \u03c6(x\u0304i, tis, tie) will be higher than a different set of onset-offset, w \u00b7 \u03c6(x\u0304i, t\u0303s, t\u0303e), where the onset-offset pair (t\u0303s, t\u0303e) in the constraint is the most violated pair [30], namely:\n(t\u0303s, t\u0303e) = arg max (t\u0303s,t\u0303e)\nw \u00b7 \u03c6(x\u0304i, t\u0303s, t\u0303e) + \u03b3i. (4)"}, {"heading": "3.4. Feature maps for the structured model", "text": "The feature maps are built from local differences, cumulative mean and max over subsets features with respect to the preaspiration boundaries. They were chosen based on manual inspection of the values and the trends of the features in intervals\nnear ts and te, and they reflect the knowledge about the problem of pre-aspiration measurement, which in our case is based on [7].\nAs an example for such a feature map we considered the observation that when pre-aspiration is immediately followed by a silent interval in the context of plosives, we expect that high frequencies (above 3000 Hz) will decrease compared to the interval of pre-aspiration, which has high energy presence in these frequencies. In order to express this observation, we define feature maps that compute the differences of the means of Ehigh andHwiener over a post pre-aspiration interval (te, te+50) and the pre-aspiration interval (ts, te).\nAnother key observation is that ts usually comes right after a formant structure which becomes less distinct and usually indicates that voicing is ending. Hence a set of feature maps are based on the local differences of 5, 10 and 15 milliseconds over the acoustic features Pmax and V in order to allow our algorithm to capture these changes. A full specification of \u03c6 is shown in Table 1."}, {"heading": "4. Data Set", "text": "The data is composed of 5,297 examples of 16 speakers of English from the town of Aberystwyth within mid Wales. All of the speakers were born and raised in the town and are L1 Welsh speakers. The speakers presented are 10 females and 6 males, and their age range spans from 22\u201391 to allow for preliminary generational comparisons. The data itself consisted of a list of words that the participants read; each word contained a sequence of a vowel and a post-tonic plosive. Each word was read once in isolation and twice in a frame sentence. For more details on the segmental and prosodic characteristics of the tokens related to aspects such as vowel height, place and manner of articulation of the plosive, stress, and foot-position see [7]. The recordings were obtained with an H4 Zoom Handy Recorder (sampled at 44.1kHz) in conjunction with the headmounted AKG C520 Microphone, which was attached to the speaker\u2019s head and ensured a constant distance from the mouth, irrespective of the speaker\u2019s movements."}, {"heading": "5. Experiments", "text": "We evaluated the performance of our algorithms using three main methods. First, we compared the predictions of the framebased algorithm and of the structured algorithm to the manual annotations. Then we tested how the structured prediction algorithm, which was superior to the frame-based algorithm, generalizes on new set of speakers and languages. Finally, we replicated a linguistic study on the model predictions and compared it to the results obtained from the manually annotated data. All of the experiments in this section are based on models which\nwere trained using search windows of 50 ms before the labeled left boundary (ts) and 60 ms after the right boundary (te), where we tried several window-sizes and the effects were insignificant."}, {"heading": "5.1. Models performance", "text": "We evaluated both algorithms on the corpus described in the previous section using 5-fold cross-validation. For each fold, 15% of the data served as a validation set. We regularized both algorithms using early stopping. For the frame-based algorithm, we balanced the data by randomly dropping negative examples, as the amount of such examples was significantly greater than the amount of positive examples. For the structured model we used C = 50, which was chosen on a validation set, and in the task loss was set to 2 ms.\nWe compared the models by reporting the percentage of examples in the test set with automatic/manual differences which were less than a time tolerance, where we used tolerances of 5, 10, 15, and 20 ms. We also report the average error in the prediction of the onset and the offset. The results are given in Table 2. Results should read as follows: The percentage of correctly predicted pre-aspirations within a threshold of 2 ms was 43.3% for the frame-based algorithm and 56.2% for the structured algorithm. The mean difference between the predicted and manually-annotated onset was 4.4 ms for the frame-based algorithm and 2.6 ms for the structured algorithm.\nIn Table 3 we report the mean and the standard deviation of the manually annotated pre-aspiration duration and the predicted pre-aspiration duration for both algorithms.\nResults suggest that the structured algorithm is superior to the framed-based algorithm. This demonstrates the power of the structured algorithm, which uses a set of dedicated featuremaps each of which measures properties and trends of intervals surrounding the boundaries of the pre-aspiration, contrary to the frame-based method that is based on local windows. Henceforth, we conducted the rest of the experiments using only the structured algorithm."}, {"heading": "5.2. Generalization", "text": "In order to test our algorithm generalization on data produced by different sources, we conducted several experiments. First, we performed leave-one-speaker-out (LOSO) using the 16 speakers of Aberystwyth English, i.e., the utterances of each speaker were tested individually with a structured model trained on the rest of the speakers. The averaged results are summarized in the first row of Table 4. Note that the results are very similar to the results shown in the second row of Table 2, where the data was randomly partitioned using 5-fold cross-validation.\nNext, we evaluated our structured algorithm on a data set consisting of 607 speech intervals of the Welsh language (16 speakers from Bethesda, North Wales). The performance of the algorithm on the Welsh corpus using 4-fold cross-validation results are summarized in the second row of Table 4. Our goal was to compare the performance of the structured algorithm that was trained on one language on a different language. The last two rows in Table 4 outline the performance of the algorithm that trained on Aberystwyth English but was tested on Welsh and vice versa.\nIt is interesting to note that there are different performance drops when languages are mismatched. When training on the Aberystwyth data and testing on Welsh data results drop by 7.2% with a tolerance level of 10 ms. However, when tested on Aberystwyth data and training on the Welsh data we suffered only a 4.3% decrease in results, again with a 10 ms tolerance level."}, {"heading": "5.3. Linguistic analysis", "text": "As the purpose of the algorithm is to reliably measure preaspiration duration for linguistic and language-related analyses, we also carried out an analysis of what language-internal and language-external factors affect pre-aspiration duration measured manually as opposed to pre-aspiration duration measured automatically with the algorithm. The outputs of four Linear Mixed Effects Models were compared. These models differed only in the dependent variable, which was (i) manually coded raw pre-aspiration duration, (ii) automatically coded raw pre-aspiration duration, (iii) manually coded normalized preaspiration duration, and (iv) automatically coded normalized pre-aspiration duration. The normalization method expressed\nthe raw measurements as a percentage of the overall word duration.\nThe models shared the following independent variables: Age (continuous variable), Sex (with two levels: female and male), Vowel type (with eight levels: /a/ contrasted with /e/, /I/, /6, /U/, /2/, /A:/, and /o:/), Place of articulation of the plosive (with three levels: /p/, /t/, /k/), and Word position (with two levels: word-medial and word-final); Speaker and Word were selected as random effects. Forward difference coding was applied to the place of articulation.\nThe tests show the same results regarding language-internal variables, irrespective of whether normalized or raw data are used. In all cases, pre-aspiration intervals are longest with /a/ as opposed to the other vowels (p < 0.0001), with the exception of /6/, which does not differ from /a/ in the durations of pre-aspiration with which it is associated. Furthermore, the duration of pre-aspiration increases as we move further back in the oral cavity (/p/ < /t/ < /k/; p < 0.0001). In addition, preaspiration is longer foot-finally than medially (p< 0.0001). The models also yield the same results concerning the external variable of sex in that no effect is found (p = 0.06-0.39). The only difference across the models is related to the variable of age, which comes out as significant when the dependent variable is manually coded normalized pre-aspiration (< 0.05; as opposed to p = 0.06-1). Moreover, there is a very strong positive correlation between the predicted and the manually coded values (raw measurements: r = 0.87; normalized measured: r = 0.89; p < 0.0001; Pearson\u2019s product moment correlation) as shown in Figure 2."}, {"heading": "6. Discussion", "text": "We have presented a new trainable algorithm for automatic measurement of pre-aspiration. To our knowledge, this is the first attempt to develop an automatic tool for measuring pre-aspiration. We have shown that the structured algorithm outperforms the frame-based neural network algorithm. Furthermore, we reproduced the results of a linguistic analysis based on pre-aspiration, solely using our structured algorithm\u2019s predictions. Future work can involve extending the use of the algorithm to fricative context, automatically detecting whether there is pre-aspiration in a given interval, and applying the presented methods to lower quality data."}, {"heading": "7. Acknowledgements", "text": "We wish to thank Jon Morris for letting us use his Welsh data."}, {"heading": "8. References", "text": "[1] P. Helgason, \u201cPreaspiration in the Nordic Languages. Synchronic\nand Diachronic Aspects,\u201d Ph.D. dissertation, Department of Linguistics, Stockholm University, 2002.\n[2] D. Silverman, \u201cOn the rarity of pre-aspirated stops,\u201d Journal of Linguistics, vol. 39, pp. 575\u2013598, 2003.\n[3] M. Clayards and T. Knowles, \u201cProminence enhances voicelessness and not place distinction in English voiceless sibilants,\u201d in Proceedings of the 18th International Congress of Phonetic Sciences (ICPhS), Glasgow, 2015.\n[4] C. di Canio, \u201cThe phonetics of fortis and lenis consonants in Itunyoso Trique,\u201d International Journal of American Linguistics, vol. 78, no. 2, pp. 239\u2013272, 2012.\n[5] G. Docherty and P. Foulkes, \u201cDerby and Newcastle: instrumental phonetics and variationist studies,\u201d in Urban Voices: Accent Studies in the British Isles, P. Foulkes and G. Docherty, Eds. Routledge, 1999, pp. 47\u201371.\n[6] O. Gordeeva and J. Scobbie, \u201cPreaspiration as a correlate of wordfinal voice in Scottish English fricatives,\u201d in Turbulent Sounds: an Interdisciplinary Guide, 2010, pp. 167\u2013207.\n[7] M. Hejna\u0301, \u201cPreaspiration in Welsh English: A Case Study of Aberystwyth,\u201d Ph.D. dissertation, Department of Linguistics, University of Manchester, 2015.\n[8] M. Hejna\u0301 and J. Scanlon, \u201cNew laryngeal allophony in Manchester English,\u201d in Proceedings of the 18th International Congress of Phonetic Sciences (ICPhS), Glasgow, 2015.\n[9] J. J. Jones and C. Llamas, \u201cFricated pre-aspirated /t/ in Middlesbrough English: an acoustic study,\u201d in Proceedings of the 15th International Congress of Phonetic Sciences (ICPhS), Barcelona, 2003, pp. 655\u2013658.\n[10] T. Kettig, \u201cThe BAD-LAD Split: a Phonetic Investigation,\u201d Ph.D. dissertation, Department of Theoretical and Applied Linguistics, University of Cambridge, 2015.\n[11] M. Roos, \u201cPreaspiration in Western Yugur monosyllables,\u201d Turgologica, vol. 32, pp. 28\u201341, 1998.\n[12] M. Stevens, \u201cHow widespread is preaspiration in Italy? a preliminary acoustic phonetic overview,\u201d Lund University Centre for Languages and Literature Phonetics Working Papers, vol. 54, pp. 97\u2013102, 2010.\n[13] M. Stevens and J. Hajek, \u201cHow pervasive is preaspiration? investigating sonorant devoicing in Sienese Italian,\u201d Proceedings of the 10th Australian International Conference on Speech Science and Technology, pp. 334\u2013339, 2004.\n[14] K. Watson, \u201cThe Phonetics and Phonology of Plosive Lenition in Liverpool English,\u201d Ph.D. dissertation, University of Lancaster, Edge Hill College, 2007.\n[15] A. Dwyer, \u201cConsonantalization and obfuscation,\u201d Turgologica, vol. 46, pp. 423\u2013432, 2000.\n[16] C. Ringen and W. A. van Dommelen, \u201cQuantity and laryngeal contrasts in Norwegian,\u201d Journal of Phonetics, vol. 41, pp. 479\u2013 490, 2013.\n[17] C. Nance and J. Stuart-Smith, \u201cPre-aspiration and post-aspiration in Scottish Gaelic stop consonants,\u201d Journal of the International Phonetic Association, vol. 43, no. 2, pp. 129\u2013152, 2013.\n[18] M. Hejna\u0301, \u201cMultiplicity of the acoustic correlates of the fortislenis contrast: plosives in Aberystwyth English,\u201d in Proceeding of Interspeech, 2016, pp. 3147\u20133151.\n[19] P. Helgason and C. Ringen, \u201cVoicing and aspiration in Swedish stops,\u201d Journal of Phonetics, vol. 36, pp. 607\u2013628, 2008.\n[20] P. Helgason, \u201cThe perception of medial stop contrasts in Central Standard Swedish: a pilot study,\u201d Proceeding of FONETIK 2004, Stockholm, pp. 92\u201395, 2004.\n[21] W. A. van Dommelen, \u201cProduction and perception of preaspiration in Norwegian,\u201d in Proceeding of FONETIK 1998, Stockholm, 1998.\n[22] M. Sonderegger and J. Keshet, \u201cAutomatic measurement of voice onset time using discriminative structured prediction),\u201d The Journal of the Acoustical Society of America, vol. 132, no. 6, pp. 3965\u2013 3979, 2012.\n[23] Y. Adi, J. Keshet, E. Cibelli, E. Gustafson, C. Clopper, and M. Goldrick, \u201cAutomatic measurement of vowel duration via structured prediction,\u201d The Journal of the Acoustical Society of America, vol. 140, no. 6, pp. 4517\u20134527, 2016.\n[24] Y. Adi, J. Keshet, O. Dmitrieva, and M. Goldrick, \u201cAutomatic measurement of voice onset time and prevoicing using recurrent neural networks,\u201d in Proceeding of the 17th Annual Conference of the International Speech Communication Association (Interspeech), 2016.\n[25] Y. Dissen and J. Keshet, \u201cFormant estimation and tracking using deep learning,\u201d in Proceeings of the 17th Annual Conference of the International Speech Communication Association (Interspeech), 2016.\n[26] Y. Adi, J. Keshet, E. Cibelli, and M. Goldrick, \u201cSequence segmentation using joint RNN and structured prediction models,\u201d in Proceeding of the 42st IEEE International Conference in Acoustic, Speech and Signal Processing (ICASSP), 2017.\n[27] F. Sha and L. K. Saul, \u201cReal-time pitch determination of one or more voices by nonnegative matrix factorization,\u201d in Proceeding of NIPS, 2004, pp. 1233\u20131240.\n[28] D. Talkin, \u201cA robust algorithm for pitch tracking (RAPT),\u201d in Speech coding and synthesis, W. Kleijn and K. Paliwal, Eds. New York: Elsevier, 1995, pp. 495\u2013518.\n[29] B. Taskar, C. Guestrin, and D. Koller, \u201cMax-margin Markov networks,\u201d in Proceeding of NIPS, 2003.\n[30] I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun, \u201cSupport vector machine learning for interdependent and structured output spaces,\u201d in Proceeding of the 21st International Conference on Machine Learning (ICML), 2004.\n[31] K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer, \u201cOnline passive-aggressive algorithms,\u201d Journal of Machine Learning Resaerch, vol. 7, pp. 551\u2013585, 2006."}], "references": [{"title": "Preaspiration in the Nordic Languages. Synchronic and Diachronic Aspects", "author": ["P. Helgason"], "venue": "Ph.D. dissertation, Department of Linguistics, Stockholm University, 2002.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "On the rarity of pre-aspirated stops", "author": ["D. Silverman"], "venue": "Journal of Linguistics, vol. 39, pp. 575\u2013598, 2003.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2003}, {"title": "Prominence enhances voicelessness and not place distinction in English voiceless sibilants", "author": ["M. Clayards", "T. Knowles"], "venue": "Proceedings of the 18th International Congress of Phonetic Sciences (ICPhS), Glasgow, 2015.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "The phonetics of fortis and lenis consonants in Itunyoso Trique", "author": ["C. di Canio"], "venue": "International Journal of American Linguistics, vol. 78, no. 2, pp. 239\u2013272, 2012.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Derby and Newcastle: instrumental phonetics and variationist studies", "author": ["G. Docherty", "P. Foulkes"], "venue": "Urban Voices: Accent Studies in the British Isles, P. Foulkes and G. Docherty, Eds. Routledge, 1999, pp. 47\u201371.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1999}, {"title": "Preaspiration as a correlate of wordfinal voice in Scottish English fricatives", "author": ["O. Gordeeva", "J. Scobbie"], "venue": "Turbulent Sounds: an Interdisciplinary Guide, 2010, pp. 167\u2013207.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Preaspiration in Welsh English: A Case Study of Aberystwyth", "author": ["M. Hejn\u00e1"], "venue": "Ph.D. dissertation, Department of Linguistics, University of Manchester, 2015.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "New laryngeal allophony in Manchester English", "author": ["M. Hejn\u00e1", "J. Scanlon"], "venue": "Proceedings of the 18th International Congress of Phonetic Sciences (ICPhS), Glasgow, 2015.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2015}, {"title": "Fricated pre-aspirated /t/ in Middlesbrough English: an acoustic study", "author": ["J.J. Jones", "C. Llamas"], "venue": "Proceedings of the 15th International Congress of Phonetic Sciences (ICPhS), Barcelona, 2003, pp. 655\u2013658.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "The BAD-LAD Split: a Phonetic Investigation", "author": ["T. Kettig"], "venue": "Ph.D. dissertation, Department of Theoretical and Applied Linguistics, University of Cambridge, 2015.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Preaspiration in Western Yugur monosyllables", "author": ["M. Roos"], "venue": "Turgologica, vol. 32, pp. 28\u201341, 1998.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1998}, {"title": "How widespread is preaspiration in Italy? a preliminary acoustic phonetic overview", "author": ["M. Stevens"], "venue": "Lund University Centre for Languages and Literature Phonetics Working Papers, vol. 54, pp. 97\u2013102, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "How pervasive is preaspiration? investigating sonorant devoicing in Sienese Italian", "author": ["M. Stevens", "J. Hajek"], "venue": "Proceedings of the 10th Australian International Conference on Speech Science and Technology, pp. 334\u2013339, 2004.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2004}, {"title": "The Phonetics and Phonology of Plosive Lenition in Liverpool English", "author": ["K. Watson"], "venue": "Ph.D. dissertation, University of Lancaster, Edge Hill College, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Consonantalization and obfuscation", "author": ["A. Dwyer"], "venue": "Turgologica, vol. 46, pp. 423\u2013432, 2000.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2000}, {"title": "Quantity and laryngeal contrasts in Norwegian", "author": ["C. Ringen", "W.A. van Dommelen"], "venue": "Journal of Phonetics, vol. 41, pp. 479\u2013 490, 2013.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2013}, {"title": "Pre-aspiration and post-aspiration in Scottish Gaelic stop consonants", "author": ["C. Nance", "J. Stuart-Smith"], "venue": "Journal of the International Phonetic Association, vol. 43, no. 2, pp. 129\u2013152, 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Multiplicity of the acoustic correlates of the fortislenis contrast: plosives in Aberystwyth English", "author": ["M. Hejn\u00e1"], "venue": "Proceeding of Interspeech, 2016, pp. 3147\u20133151.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Voicing and aspiration in Swedish stops", "author": ["P. Helgason", "C. Ringen"], "venue": "Journal of Phonetics, vol. 36, pp. 607\u2013628, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "The perception of medial stop contrasts in Central Standard Swedish: a pilot study", "author": ["P. Helgason"], "venue": "Proceeding of FONETIK 2004, Stockholm, pp. 92\u201395, 2004.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2004}, {"title": "Production and perception of preaspiration in Norwegian", "author": ["W.A. van Dommelen"], "venue": "Proceeding of FONETIK 1998, Stockholm, 1998.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1998}, {"title": "Automatic measurement of voice onset time using discriminative structured prediction)", "author": ["M. Sonderegger", "J. Keshet"], "venue": "The Journal of the Acoustical Society of America, vol. 132, no. 6, pp. 3965\u2013 3979, 2012.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Automatic measurement of vowel duration via structured prediction", "author": ["Y. Adi", "J. Keshet", "E. Cibelli", "E. Gustafson", "C. Clopper", "M. Goldrick"], "venue": "The Journal of the Acoustical Society of America, vol. 140, no. 6, pp. 4517\u20134527, 2016.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2016}, {"title": "Automatic measurement of voice onset time and prevoicing using recurrent neural networks", "author": ["Y. Adi", "J. Keshet", "O. Dmitrieva", "M. Goldrick"], "venue": "Proceeding of the 17th Annual Conference of the International Speech Communication Association (Interspeech), 2016.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Formant estimation and tracking using deep learning", "author": ["Y. Dissen", "J. Keshet"], "venue": "Proceeings of the 17th Annual Conference of the International Speech Communication Association (Interspeech), 2016.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2016}, {"title": "Sequence segmentation using joint RNN and structured prediction models", "author": ["Y. Adi", "J. Keshet", "E. Cibelli", "M. Goldrick"], "venue": "Proceeding of the 42st IEEE International Conference in Acoustic, Speech and Signal Processing (ICASSP), 2017.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2017}, {"title": "Real-time pitch determination of one or more voices by nonnegative matrix factorization", "author": ["F. Sha", "L.K. Saul"], "venue": "Proceeding of NIPS, 2004, pp. 1233\u20131240.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2004}, {"title": "A robust algorithm for pitch tracking (RAPT)", "author": ["D. Talkin"], "venue": "Speech coding and synthesis, W. Kleijn and K. Paliwal, Eds. New York: Elsevier, 1995, pp. 495\u2013518.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1995}, {"title": "Max-margin Markov networks", "author": ["B. Taskar", "C. Guestrin", "D. Koller"], "venue": "Proceeding of NIPS, 2003.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2003}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "Proceeding of the 21st International Conference on Machine Learning (ICML), 2004.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2004}, {"title": "Online passive-aggressive algorithms", "author": ["K. Crammer", "O. Dekel", "J. Keshet", "S. Shalev-Shwartz", "Y. Singer"], "venue": "Journal of Machine Learning Resaerch, vol. 7, pp. 551\u2013585, 2006.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 55, "endOffset": 60}, {"referenceID": 1, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 55, "endOffset": 60}, {"referenceID": 2, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 3, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 4, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 5, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 6, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 7, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 8, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 9, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 10, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 11, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 12, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 13, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 14, "context": "Although pre-aspiration was previously considered rare [1,2], with the advances in recording technology it has been recently reported to occur in increasingly more languages and varieties thereof [3\u201315].", "startOffset": 196, "endOffset": 202}, {"referenceID": 0, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 86, "endOffset": 96}, {"referenceID": 6, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 86, "endOffset": 96}, {"referenceID": 15, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 86, "endOffset": 96}, {"referenceID": 16, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 122, "endOffset": 126}, {"referenceID": 4, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 155, "endOffset": 161}, {"referenceID": 6, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 155, "endOffset": 161}, {"referenceID": 16, "context": "Recent studies of pre-aspiration have revealed that the phenomenon is very individual [1, 7, 16], sensitive to sex/gender [17], and can be affected by age [5, 7] and the first language of the speaker [17].", "startOffset": 200, "endOffset": 204}, {"referenceID": 0, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 3, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 6, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 8, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 9, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 11, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 12, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 16, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 17, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 18, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 19, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 20, "context": "The vast majority of researchers have coded pre-aspiration manually by identifying its boundaries, usually based on a manual segmentation of the signal into segmental and subsegmental intervals [1, 4, 7, 9, 10, 12, 13, 17\u201321].", "startOffset": 194, "endOffset": 225}, {"referenceID": 21, "context": "ity [22\u201326].", "startOffset": 4, "endOffset": 11}, {"referenceID": 22, "context": "ity [22\u201326].", "startOffset": 4, "endOffset": 11}, {"referenceID": 23, "context": "ity [22\u201326].", "startOffset": 4, "endOffset": 11}, {"referenceID": 24, "context": "ity [22\u201326].", "startOffset": 4, "endOffset": 11}, {"referenceID": 25, "context": "ity [22\u201326].", "startOffset": 4, "endOffset": 11}, {"referenceID": 21, "context": "Similar to [22], we extract eight (D=8) acoustic features from the speech signal every 1 ms.", "startOffset": 11, "endOffset": 15}, {"referenceID": 26, "context": "The sixth feature (Rl) is the pitch of the signal using a real-time pitch detector [27].", "startOffset": 83, "endOffset": 87}, {"referenceID": 27, "context": "The seventh feature is the 0/1 output of a voicing detector based on the RAPT pitch tracker [28], smoothed with a 5 ms Hamming window (V ).", "startOffset": 92, "endOffset": 96}, {"referenceID": 28, "context": "Similar to previous work in structured prediction [29, 30], the function f is constructed from a predefined set of N feature maps {\u03c6i}i=1, each of the form \u03c6i : X\u00d7T \u00d7T \u00d7 \u2192 R , and a weight vector w \u2208 R .", "startOffset": 50, "endOffset": 58}, {"referenceID": 29, "context": "Similar to previous work in structured prediction [29, 30], the function f is constructed from a predefined set of N feature maps {\u03c6i}i=1, each of the form \u03c6i : X\u00d7T \u00d7T \u00d7 \u2192 R , and a weight vector w \u2208 R .", "startOffset": 50, "endOffset": 58}, {"referenceID": 21, "context": "In a similar manner to [22], we define the task loss function as follows:", "startOffset": 23, "endOffset": 27}, {"referenceID": 30, "context": "The weight vector w is learned using an iterative algorithm based on the Passive-Aggressive family of algorithms for structured prediction [31].", "startOffset": 139, "endOffset": 143}, {"referenceID": 29, "context": "The optimization problem tries to keep the new weight vector w close to the previous weight vector wt while satisfying the constraint that the score of the manually annotated onsetoffset pair w \u00b7 \u03c6(x\u0304, ts, te) will be higher than a different set of onset-offset, w \u00b7 \u03c6(x\u0304, t\u0303s, t\u0303e), where the onset-offset pair (t\u0303s, t\u0303e) in the constraint is the most violated pair [30], namely:", "startOffset": 367, "endOffset": 371}, {"referenceID": 21, "context": "F in row i and column j indicates that there is a feature map of type i for feature xj; \u2206 indicates that there are three feature maps of type i for the local difference of feature xj , evaluated at s = 5, 10, 15 [22].", "startOffset": 212, "endOffset": 216}, {"referenceID": 6, "context": "near ts and te, and they reflect the knowledge about the problem of pre-aspiration measurement, which in our case is based on [7].", "startOffset": 126, "endOffset": 129}, {"referenceID": 6, "context": "For more details on the segmental and prosodic characteristics of the tokens related to aspects such as vowel height, place and manner of articulation of the plosive, stress, and foot-position see [7].", "startOffset": 197, "endOffset": 200}], "year": 2017, "abstractText": "Pre-aspiration is defined as the period of glottal friction occurring in sequences of vocalic/consonantal sonorants and phonetically voiceless obstruents. We propose two machine learning methods for automatic measurement of pre-aspiration duration: a feedforward neural network, which works at the frame level; and a structured prediction model, which relies on manually designed feature functions, and works at the segment level. The input for both algorithms is a speech signal of an arbitrary length containing a single obstruent, and the output is a pair of times which constitutes the pre-aspiration boundaries. We train both models on a set of manually annotated examples. Results suggest that the structured model is superior to the frame-based model as it yields higher accuracy in predicting the boundaries and generalizes to new speakers and new languages. Finally, we demonstrate the applicability of our structured prediction algorithm by replicating linguistic analysis of pre-aspiration in Aberystwyth English with high correlation.", "creator": "LaTeX with hyperref package"}}}