{"id": "1704.03404", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2017", "title": "ENWalk: Learning Network Features for Spam Detection in Twitter", "abstract": "social medias are increasing their influence connecting with producing the vast public information leading to their active use for marketing by the companies and organizations. such marketing promotions are difficult to identify unlike entering the traditional medias like tv and newspaper. so, it is very much important to identify the promoters in the social media. although, there mainly are active ongoing researches, existing approaches are far from solving the problem. trying to identify yet such imposters, it is very much important to quickly understand their strategies of social circle creation and dynamics of content posting. are there any specific spammer types? how successful are each types? we analyze these questions in studying the light of social relationships in twitter. our analyses discover two types of spammers and their empirical relationships with the dynamics of content posts. our results here discover novel dynamics of spamming which are intuitive and arguable. we propose enwalk, a framework to detect the spammers by learning the feature representations of the users in the social media. we learn the feature representations using the random walks biased on the spam dynamics. experimental results on large - scale twitter network and the corresponding tweets show the effectiveness of our approach that outperforms the existing approaches", "histories": [["v1", "Tue, 11 Apr 2017 16:37:37 GMT  (313kb)", "http://arxiv.org/abs/1704.03404v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.SI", "authors": ["k c santosh", "suman kalyan maity", "arjun mukherjee"], "accepted": false, "id": "1704.03404"}, "pdf": {"name": "1704.03404.pdf", "metadata": {"source": "CRF", "title": "ENWalk: Learning Network Features for Spam Detection in Twitter", "authors": ["Santosh K C", "Suman Kalyan Maity", "Arjun Mukherjee"], "emails": ["skc@uh.edu,", "sumankalyan.maity@cse.iitkgp.ernet.in,", "arjun@uh.edu"], "sections": [{"heading": null, "text": "Keywords: Social Network; Spam Detection; Feature Learning"}, {"heading": "1 Introduction", "text": "Social medias are increasing their influence tremendously. Twitter is one of the popular platforms where people post information in the form of tweets and share the tweets. Twitter is available from wide range of web-enabled services to all the people. So, the real time reflection of a society can be viewed in twitter. Celebrities, governments, politicians, businesses are active in twitter to provide their updates and to listen to the views of the people. Thus, the bidirectional flow of information is high. The openness of the online platforms and reliance on users facilitates the spammers to easily penetrate the platform and overwhelm the users with malicious intent and content. This work attempts to detect the spammers in social network using a case study of twitter.\nSpammers in social networks constantly adapt to avoid the detection. Moreover, they follow reflexive reciprocity [6, 17] (users following back when they are followed by someone to show courtesy) to establish social influence and act normal. So, it is becoming difficult for traditional spam detection methods to detect the spammers. Such\nspammers have widespread impacts. There are several reports of army of fake Twitter accounts1 being used to troll2 and promote political agendas3. Even US President Donald Trump has been accused of fake followers4.\nIn this paper, we present ENWalk, a framework that uses the content information to bias a random walk of the network and obtain the latent feature embedding of the nodes in the network. ENWalk generates the biased random walks and uses them to maximize the likelihood of obtaining similar nodes in the neighborhood of the network. We study the twitter content dynamics that could be important to bias those random walks. We found that there are two types of spammers: follow-flood and vigilant. We found that success rate, activity window, fraudulence and mentioning behaviors can be used to compare the equivalence of users in the twitter. We calculate the network equivalence using these four behavioral features between pairs of nodes and try to bias the random walks with interaction proximity of the pair of nodes. Experimental results on 17 million user network from twitter show that the combination of behavioral features with the underlying network structure significantly outperform the existing state-of-the-art approaches for deception detection."}, {"heading": "2 Related Work", "text": "There have been several works on spam detection in general, especially review spam [7], and opinion spam. However, in Twitter there are limited attempts. One of the earliest works was done by Benevenuto et al. [1]. They manually labeled and trained a traditional classifier using the features extracted from user contents and behaviors. Lee et al. leveraged profile-based features and deployed social honeypots to detect new social spammers [9]. Stringhini et al. also studied spam detection using honey profiles [14]. Ghosh et al. studied the problem of link farming in Twitter [4] and introduced a ranking methodology to penalize the link farmers. Abuse of online social networks was studied in [16]. Campaign spams was studied on [3, 10, 19].\nSkip-gram model [12] has been popular to learn the features from a large corpus of data. It inspired to establish an analogy for networks by representing a network as a \u201cdocument\u201d. Similar to document being an ordered sequence of words, we can create an ordered sequence of nodes from a network using sampling techniques. DeepWalk [13] learns d-dimensional feature representations by simulating uniform random walks. LINE [15] learns the d-dimensional features into two phases: d/2 BFS-style simulations and another d/2 2-hop distant nodes. Node2vec [5] creates the ordered sequence simulating the BFS and DFS approaches. All these feature learning approaches don\u2019t use the data associated with node which are important to learn the behaviors of the nodes.\n1 http://theatln.tc/2m8g3eA 2 http://bzfd.it/2m8rlja 3 http://bit.ly/2kJiMKu 4 http://bit.ly/1ViorHd, http://53eig.ht/2kzrhfL"}, {"heading": "3 Dataset", "text": "For this work, we use the Twitter dataset used in [18]. It contains 17 million users having 467 million Twitter posts covering a seven month period from June 1 2009 to December 31 2009. To extract the network graph for those 17 million users, we extracted the follower-following topology of Twitter from [8] which contains all the entire twitter user profiles and their social relationships till July 2009. We pruned the users so that they have social relationship in [8] and tweets in [18] and are left with 4,405,698 users. Twitter suspends the accounts involved in the malicious activity (https://support.twitter.com/articles/18311). To obtain the suspend status of accounts, we re-crawled the profile pages of all the 17 million users. This yielded a total of 100,758 accounts that had been suspended (the profile page redirects to the page https://twitter.com/account/suspended). We use this suspension signal as the primary signal for evaluating our models as the primary reason for account suspension is the involvement in the spam activity. However, there might be other reasons like inactivity. So, to ensure the suspended accounts are spammers, we further checked for malicious activities for those users. For this, we examined various URLs from the account\u2019s timeline and checked them against a list of blacklisted URLs. We use three blacklists: Google Safebrowsing (http://code.google.com/apis/safebrowsing/), URIBL (http://uribl.com/) and Joewein (http://www.joewein.net/). We found that 75% of suspended accounts posted at least one shortened URL blacklisted. We also looked for duplicate tweets enforced for promotion. After applying these additional criteria, our final data comprised of 86,652 spammers and 4,319,046 non-spammers, which was used for evaluating our model."}, {"heading": "4 Spam Analysis", "text": "Characterizing the dominant spammer types is important as it is the first step in understanding the dynamics of spamming. We studied the follower-following network creation strategies of the spammers. We found that there are two main types of spamming based on the follow-following strategies: (1) follow-flood spammers and (2) vigilant spammers. So, the question arises why some spammers are more successful? In this section, we study the behavioral aspects of tweet dynamics of spammers. We later leverage them in model building."}, {"heading": "4.1 Spammer Type", "text": "To analyze the strategies of follower-following, we calculated the number of followers (users that are following the current user) and the number of followings (users that the current user is following) for each spammer. Figure 1 shows the plot in log scale count. It shows that the follower and following count differ for each spammers. The users with more followers than followings tend to be more successful as they have been able to \u201cearn\u201d a lot of users who are following them. So, we define success rate as:\n\ud835\udc60\ud835\udc5f\ud835\udc62 = # of followers of \ud835\udc62 # of followings of \ud835\udc62\n(1)\nBased on the network expansion success rate, we find that there are two dominant spamming strategies:\n4.2 Activity Window We compute the activity window as the number of days a user is active in the twitter network. Since, we don\u2019t have the exact time when a user was suspended, we approximate the time of suspension as the date of the last tweet tweeted by the user. We found that the average activity window of a vigilant spammer is 138 days with a standard deviation of 19 days compared to the average of 35 days and standard deviation of 12 days for follow-flood spammers. Although, the basic strategy of any spammer is to inject itself into the network and emit the spam contents, the success rate also depends how long it can remain undetected in the network. So, vigilant spammers have a higher success rate."}, {"heading": "4.3 Fraudulence", "text": "One of the primary reason to spam is to inject constant fraudulence information. So, we analyzed the fraudulence behavior of the two types of spammers. We labeled the tweets containing promotional, adult words or the blacklisted urls as fraud tweets. So, we compute fraudulence as:\n\ud835\udc53\ud835\udc5f\ud835\udc62 = # of fraud tweets of \ud835\udc62 total # of tweets of \ud835\udc62\n(2)\nWe found that the average fraudulence of vigilant spammers is 0.34 compared to 0.86 of follow-flood spammers. So, the follow-flood spammers are more involved in spam."}, {"heading": "4.4 Mentioning Celebrities and Popular Hashtags", "text": "Mentioning the popular celebrities or hashtags empowers a tweet. So, one of the common strategies of spammers is to include the popular ones in their tweets. We studied mentioning phenomenon and found that vigilant spammers mention half the celebrities per tweets compared to the follow-flood spammers."}, {"heading": "5 Learning Latent Features for Spam Detection", "text": "Having characterized the dynamics of spamming in Twitter, can we improve spam detection beyond the existing state-of-the-art approaches? To answer this we used our Twitter data to setup a latent feature learning problem in networks. Our analysis is general and can be used to any social network."}, {"heading": "5.1 Overview", "text": "As discussed in the previous section, the dynamics of Twitter are interesting and can be leveraged to catch the spammers. So, we use the spam dynamics to formulate the latent feature learning in social networks. Let \ud835\udc3a = (\ud835\udc49 , \ud835\udc38,\ud835\udc4b) be a given network with vertices, edges and the social network data of users in the social network. We aim to learn a mapping function \ud835\udc53 \u2236 \ud835\udc49 \u2192 \u211d\ud835\udc51 from nodes to a d-dimensional feature representations which can be used for prediction. The parameter specifies the number of dimensions of the latent features such that the size of \ud835\udc53 is |\ud835\udc49 | \u00d7 \ud835\udc51.\nWe present a novel sampling strategy that samples nodes in network exploiting the spam dynamics such that the equivalent neighborhood \ud835\udc38\ud835\udc41(\ud835\udc62) \u2282 \ud835\udc49 contains the node having similar tweeting behaviors with the node \ud835\udc62. We generate \ud835\udc38\ud835\udc41(\ud835\udc62) for each nodes in the network and predict which nodes are the members of \ud835\udc62\u2019s equivalent neighbors based on the learnt latent features \ud835\udc53 . The basic rationale is that we wish to learn latent feature representations for nodes that respect equivalent neighborhoods (which are based on the spamming dynamics) so that classification/ranking using the learned representation yields results that leverage the spamming dynamics."}, {"heading": "5.2 The Optimization Problem", "text": "As our goal is to learn the latent features \ud835\udc53 that best describe the equivalent neighborhood \ud835\udc38\ud835\udc41(\ud835\udc62) of node \ud835\udc62, we define the optimization problem as follows:\n\u2211 \ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc43 \ud835\udc5f(\ud835\udc38\ud835\udc41(\ud835\udc62)\u2223\ud835\udc53(\ud835\udc62)) \ud835\udc62 \u2208\ud835\udc49 \ud835\udc53 \ud835\udc5a\ud835\udc4e\ud835\udc65 (3)\nTo solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.\n\ud835\udc43 \ud835\udc5f(\ud835\udc38\ud835\udc41(\ud835\udc62)\u2223\ud835\udc53(\ud835\udc62)) = \u220f Pr (\ud835\udc63|\ud835\udc53(\ud835\udc62) \ud835\udc63 \u2208\ud835\udc38\ud835\udc41(\ud835\udc62)\n(4)\nSince, the source node and the equivalent neighborhood node have symmetric equivalence, the conditional likelihood can be modeled as softmax unit parameterized by a dot product of their features.\n\ud835\udc43\ud835\udc5f(\ud835\udc63\u2223\ud835\udc53(\ud835\udc62)) = \ud835\udc52\ud835\udc65\ud835\udc5d( \ud835\udc53(\ud835\udc63). \ud835\udc53(\ud835\udc62)) \u2211 \ud835\udc52\ud835\udc65\ud835\udc5d (\ud835\udc53(\ud835\udc61). \ud835\udc53(\ud835\udc62))\ud835\udc61\u2208\ud835\udc49\n(5)\nThe optimization problem now becomes:\n\u2211 [\u2212\ud835\udc59\ud835\udc5c\ud835\udc54 \ud835\udc4d\ud835\udc62 + \u2211 \ud835\udc53(\ud835\udc61). \ud835\udc53(\ud835\udc62) \ud835\udc61 \u2208\ud835\udc38\ud835\udc41(\ud835\udc62) ] \ud835\udc62 \u2208\ud835\udc49 \ud835\udc53 \ud835\udc5a\ud835\udc4e\ud835\udc65 (6)\nFor large networks, the partition function \ud835\udc4d\ud835\udc62 = \u2211 exp (\ud835\udc53(\ud835\udc61). \ud835\udc53(\ud835\udc62))\ud835\udc61\u2208\ud835\udc49 is expensive to compute. So, we use negative sampling [12] to approximate it. We use stochastic gradient descent over the model parameters defining the features \ud835\udc53 . Feature learning methods based on Skip-gram architecture are developed for natural language [11]. Since natural language texts are linear, the notion of a neighborhood can be naturally defined using a sliding window over consecutive words in sentences. Networks are not linear, and thus a richer notion of a neighborhood is needed. To mitigate this problem, we use multiple biased random walks each one in principle exploring a different neighborhood [5]."}, {"heading": "5.3 Equivalent Neighborhood Generation", "text": "The analyses of spam dynamics leads to an important inference that the nodes are similar if they have similar spam dynamics. So, we want to exploit those dynamics to generate the equivalent neighborhood \ud835\udc38\ud835\udc41(\ud835\udc62) for the node \ud835\udc62. Nodes in a network are equivalent if they share similar behaviors. We use the random walk procedure which can be biased to generate the equivalent neighborhood.\nWe bias the random walks based on the four dynamics: common time of activity (\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc63), success rate difference (\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc63), fraudulence commonalities (\ud835\udc53\ud835\udc5f\ud835\udc61\ud835\udc63) and common mentioning in tweets (\ud835\udc5a\ud835\udc52\ud835\udc61\ud835\udc63). We calculate each dynamics as follows:\n\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc63 = # of days with common activity # of days either \ud835\udc61 or \ud835\udc63 is active\n(7)\n\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc63 = 1 \u2212 \u2223max (1, # of followers of \ud835\udc61 # of followings of \ud835\udc61 ) \u2212 max (1, # of followers of \ud835\udc63 # of followings of \ud835\udc63 )\u2223 (8)\n\ud835\udc53\ud835\udc5f\ud835\udc61\ud835\udc63 = 1 \u2212 \u2223 # of fraud tweets of \ud835\udc61 # of tweets of \ud835\udc61 \u2212 # of fraud tweets of \ud835\udc63 # of tweets of \ud835\udc63 \u2223 (9)\n\ud835\udc5a\ud835\udc52\ud835\udc61\ud835\udc63 = common mentions between \ud835\udc61 and \ud835\udc63\ntotal mentions of \ud835\udc61 and \ud835\udc63 (10)\nFor all the above four features, a higher value represents a closer connection between the pair of nodes. For a source node \ud835\udc62, we generate a random walk of fixed length \ud835\udc58. The \ud835\udc56\ud835\udc61\u210e node \ud835\udc50\ud835\udc56 of a random walk starting at node \ud835\udc500 is generated with the distribution:\n\ud835\udc43(c\ud835\udc56 = \ud835\udc61 | c\ud835\udc56\u22121 = \ud835\udc63) = {\u212c\ud835\udc63\ud835\udc61, \ud835\udc56\ud835\udc53(\ud835\udc63, \ud835\udc61) \u2208 \ud835\udc380, \ud835\udc5c\ud835\udc61\u210e\ud835\udc52\ud835\udc5f\ud835\udc64\ud835\udc56\ud835\udc60\ud835\udc52 (11)\nwhere \u212c\ud835\udc63\ud835\udc61 is the normalized transition probability between nodes \ud835\udc63 and \ud835\udc61. The transition probability are computed based on the spam dynamics so that the source node has equivalent spam dynamics with its neighborhood nodes.\nWe define four parameters which guide the random walk. Consider that a random walk just traversed edge (\ud835\udc61, \ud835\udc63) to now reside at node \ud835\udc63. The walk now needs to decide on the next step so it evaluates the transition probabilities on edges (\ud835\udc63, \ud835\udc65) leading from \ud835\udc63. We set the transition probability to \u212c\ud835\udc63\ud835\udc65 = \ud835\udefc\ud835\udc5d\ud835\udc5e\ud835\udc5f\ud835\udc60(\ud835\udc61, \ud835\udc63, \ud835\udc65).\ud835\udc64\ud835\udc63\ud835\udc65, where\n\ud835\udefc\ud835\udc5d\ud835\udc5e\ud835\udc5f\ud835\udc60(\ud835\udc61, \ud835\udc63, \ud835\udc65) = \ud835\udc5d. (\ud835\udc50\ud835\udc61\ud835\udc61\ud835\udc63 + \ud835\udc50\ud835\udc61\ud835\udc63\ud835\udc65) + \ud835\udc5e. (\ud835\udc60\ud835\udc5f\ud835\udc61\ud835\udc63 + \ud835\udc60\ud835\udc5f\ud835\udc63\ud835\udc65) + \ud835\udc5f. (\ud835\udc53\ud835\udc5f\ud835\udc61\ud835\udc63 + \ud835\udc53\ud835\udc5f\ud835\udc63\ud835\udc65) + \ud835\udc60. (\ud835\udc5a\ud835\udc52\ud835\udc61\ud835\udc63 + \ud835\udc5a\ud835\udc52\ud835\udc63\ud835\udc65) (12)\nwhere the parameters \ud835\udc5d, \ud835\udc5e, \ud835\udc5f , \ud835\udc60 are used to prioritize the tweet dynamics. To select the next node, the random walk is biased towards the nodes which have similar tweet dynamics to both the current node and the previous node in the random walk."}, {"heading": "5.4 Algorithm: ENWalk", "text": "Algorithm 1 details our entire scheme. We start with \ud835\udf06 fixed length random walks at each node \ud835\udc59 times. To obtain each walk, we use GetEquivalentNeighbor, the random sampler that samples the node based on the transition probabilities computed in equation 12. It is worth noting that the tweet dynamics between the nodes (\ud835\udc36\ud835\udc47 ,\ud835\udc46\ud835\udc45, \ud835\udc39\ud835\udc45, \ud835\udc40\ud835\udc38) defined in equation 7, 8, 9, 10 respectively can be pre-computed. Once, we have random walks we can obtain \ud835\udc51 dimensional numeric features using the optimization function in equation 6 with a window size of \ud835\udc58. The three phases preprocessing, random sampling and optimization are asynchronous so that ENWalk is scalable."}, {"heading": "6 Experiment", "text": "We applied ENWalk to twitter dataset to evaluate its effectiveness. In this section, we discuss the baseline methods and compare with ENWalk for classification and ranking."}, {"heading": "6.1 Baseline Methods", "text": "For classification, we compare our model with two graph embedding methods: Deepwalk and node2vec. We use PageRank and Markov Random Field (MRF) approaches\nAlgorithm 1: ENWalk \ud835\udc3a, \ud835\udc51, \ud835\udf06, \ud835\udc59, \ud835\udc58, [\ud835\udc5d, \ud835\udc5e, \ud835\udc5f, \ud835\udc60] Input: graph \ud835\udc3a(\ud835\udc49 , \ud835\udc38,\ud835\udc4a,\ud835\udc4b) embedding dimensions \ud835\udc85 walks per node \ud835\udf06 walk length \ud835\udc59 context size \ud835\udc58 tweet parameters \ud835\udc91, \ud835\udc92, \ud835\udc93, \ud835\udc94 Output: matrix of latent features \ud835\udc6d\n1. ( , , , ) = Preprocess \ud835\udc6e,\ud835\udc91, \ud835\udc92, \ud835\udc93, \ud835\udc94) 2. Initialize \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c\ud835\udc94 to empty 3. for \ud835\udc56 = \ud835\udfcf to \ud835\udf40 do 4. for each \ud835\udc63\ud835\udc56 \ud835\udf3a \ud835\udc7d do 5. Initialize \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c to \ud835\udc63\ud835\udc56 6. for \ud835\udc57 = \ud835\udfcf to \ud835\udc8d do 7. \ud835\udc99 = GetEquivalentNeighbor(\ud835\udc3a,\ud835\udc36\ud835\udc47 , \ud835\udc46\ud835\udc45,\ud835\udc39\ud835\udc45, \ud835\udc40\ud835\udc38, \ud835\udc64\ud835\udc4e\ud835\udc59\ud835\udc58[\ud835\udc57], \ud835\udc4a ) 8. Append \ud835\udc99 to \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c 9. Append \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c to \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c\ud835\udc94 10. \ud835\udc6d = StochasticGradientDescent \ud835\udc8c , \ud835\udc85 , \ud835\udc98\ud835\udc82\ud835\udc8d\ud835\udc8c\ud835\udc94\nnodes in the network. It extends the language model of random walks employing a flexible notion of neighborhood. It designs a biased random walk using BFS and DFS neighborhood discovery. PageRank Models. PageRank is a popular ranking algorithm that exploits the linkbased structure of a network graph to rank the nodes of the graph.\n\ud835\udc43\ud835\udc45 = (1 \u2212 \u03b1) \u2217 \ud835\udc40 \u2217 \ud835\udc43\ud835\udc45 + \u03b1 \u2217 \ud835\udc5d (13)\nwhere \ud835\udc40 is transition probability matrix, \ud835\udc5d represents the prior probability with which a random surfer surfs to a random page and \ud835\udefc is damping factor. For variations of PageRank, we vary the values of \ud835\udc40 and \ud835\udc5d using trustworthiness of a user. Trustworthiness (\ud835\udc53\ud835\udc47\ud835\udc5f\ud835\udc62\ud835\udc60\ud835\udc61) is using a set of features (# of Blacklist URL, # of tweets, # of mentions, # of duplicate tweets, # of tweets containing adult/bad words, # of tweets containing violent words, # of tweets containing promotional words and the total time of activity for the user). We manually labeled \ud835\udc53\ud835\udc47\ud835\udc5f\ud835\udc62\ud835\udc60\ud835\udc61score of 800 users (400 non-suspended and 400 suspended). We gave a real-valued trustworthiness score between 0 and 1. A value closer to 0 means the user is most likely a spammer. We then obtain the weight of the features by learning linear regression model on the users.  Traditional PageRank We use the default PageRank settings for \ud835\udc40and \ud835\udc5d.  Trust Induced and Trust Prior: Transition matrix \ud835\udc40 is modified as \ud835\udc40\ud835\udc62\ud835\udc63 = M\ud835\udc62\ud835\udc63 \u2217\n\ud835\udc53\ud835\udc47\ud835\udc5f\ud835\udc62\ud835\udc60\ud835\udc61(\ud835\udc63), \u2200\ud835\udc62, \u2200\ud835\udc63 and \ud835\udc53\ud835\udc47\ud835\udc5f\ud835\udc62\ud835\udc60\ud835\udc61(\ud835\udc63) is used as prior probability. Markov Random Field Models. Markov Random Fields are undirected graphs (and can be cyclic) that satisfy the three conditional independence properties (Pairwise, Local, and Global). For the inference, we use the Loopy Belief Propagation algorithm. Inspired by spam detection in [2], we define 3 hidden states {Spammer, Mixed, NonSpammer} and the Propagation Matrix is used as in Table 1. Logically, spammers follow other spammers more (hence 0.8 probability) and non-spammers tend to follow other non- spammers. We also include the mixed state to include those users who are difficult to categorize spammers or non-spammers."}, {"heading": "6.2 Node Classification", "text": "We obtained the feature representations from three different algorithms: ENWalk, node2vec and DeepWalk using the settings used in node2vec and DeepWalk. All the feature learnings are unsupervised. Similar to node2vec and DeepWalk, we used \ud835\udc51 = 128, \ud835\udf06 = 10, \ud835\udc59 = 80, \ud835\udc58 = 10. We found that the parameters \ud835\udc51, \ud835\udf06, \ud835\udc59, \ud835\udc58 are sensitive in a similar style to node2vec and DeepWalk. We used each feature representation as an example for standard SVM classifier. We used 10-fold cross-validation using balanced\nS M N S 0.80 0.40 0.025 M 0.15 0.50 0.125 N 0.05 0.10 0.850\nis effective to screen the nodes that are probable being spammers. To evaluate the ranking performance of ENWalk, we use Logistic Regression on the features obtained from the model. We compare our model with PageRank and Markov Random Field models. We present the CDF in Fig 2. We can see that ENWalk outperforms all the baseline models. We also computed the AUC and precision@100 (Table 3). A higher AUC and precision@100 signifies the ability to profile the top spammers."}, {"heading": "7 Conclusion", "text": "We studied the problem of identifying spammers in Twitter who are involved in malicious attacks. This is very much important as it has many practical applications in today\u2019s world where almost everyone is actively social online. This paper proposed a method of spam detection in Twitter that makes use of the online network structure and information shared. This data driven approach is important as there is a lot of data of social medias online these days. We demonstrated the helpfulness of biased random walks in learning node embedding that can be used for classification and ranking tasks. Acknowledgements: This work is supported in part by NSF 1527364. We also thank anonymous reviewers for their helpful feedbacks.\nFigure 2. Cumulative Distribution Function of Suspended Nodes\nTable 3. Ranking Results: Area Under CDF Curve (AUC) and Precision@100(P@100)\nModel AUC P@100 PR-T 0.4059 0.02 PR-TITP 0.4181 0.03 MRF 0.4944 0.02 DeepWalk 0.5502 0.05 node2vec 0.5836 0.05 ENWalk 0.6335 0.12"}, {"heading": "8 References", "text": "[1] Benevenuto, F., Magno, G., Rodrigues, T. and Almeida, V. 2010. Detecting spammers on\ntwitter. Collaboration, electronic messaging, anti-abuse and spam conference (CEAS). 6, (2010), 12. [2] Fei, G., Mukherjee, A., Liu, B., Hsu, M., Castellanos, M. and Ghosh, R. 2013. Exploiting\nBurstiness in Reviews for Review Spammer Detection. Proceedings of the Seventh International Conference on Weblogs and Social Media, {ICWSM} 2013, Cambridge, Massachusetts, USA, July 8-11, 2013. (2013). [3] Gao, H., Hu, J., Wilson, C., Li, Z., Chen, Y. and Zhao, B.Y. 2010. Detecting and characterizing social spam campaigns. Proceedings of the 10th ACM SIGCOMM conference on Internet measurement. (2010), 35\u201347. [4] Ghosh, S., Viswanath, B., Kooti, F., Sharma, N.K., Korlam, G., Benevenuto, F., Ganguly, N. and Gummadi, K.P. 2012. Understanding and combating link farming in the twitter social network. Proceedings of the 21st \u2026. (2012), 61\u201370. [5] Grover, A. and Leskovec, J. 2016. node2vec: Scalable feature learning for networks. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016), 855\u2013864. [6] Hu, X., Tang, J., Zhang, Y. and Liu, H. 2013. Social Spammer Detection in Microblogging. IJCAI (2013), 2633\u20132639. [7] K C, S. and Mukherjee, A. 2016. On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp. 25th International World Wide Web Conference, {WWW} \u201916, Montr\u00e9al, Qu\u00e9bec, Canada, April 11-15, 2016 (2016). [8] Kwak, H., Lee, C., Park, H. and Moon, S. 2010. What is Twitter , a Social Network or a News Media? The International World Wide Web Conference Committee (IW3C2). (2010), 1\u201310. [9] Lee, K., Caverlee, J. and Webb, S. 2010. Uncovering social spammers: social honeypots+ machine learning. Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval (2010), 435\u2013442. [10] Li, H., Mukherjee, A., Liu, B., Kornfield, R. and Emery, S. 2014. Detecting Campaign Promoters on Twitter Using Markov Random Fields. 2014 {IEEE} International Conference on Data Mining, {ICDM} 2014, Shenzhen, China, December 14-17, 2014 (2014), 290\u2013299. [11] Mikolov, T., Chen, K., Corrado, G. and Dean, J. 2013. Distributed Representations of Words and Phrases and their Compositionality. Nips. (2013), 1\u20139. [12] Mikolov, T., Corrado, G., Chen, K. and Dean, J. 2013. Efficient Estimation of Word Representations in Vector Space. Proceedings of the International Conference on Learning Representations (ICLR 2013). (2013), 1\u201312. [13] Perozzi, B., Al-Rfou, R. and Skiena, S. 2014. Deepwalk: Online learning of social representations. Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining (2014), 701\u2013710. [14] Stringhini, G., Kruegel, C. and Vigna, G. 2010. Detecting spammers on social networks. Proceedings of the 26th annual computer security applications conference (2010), 1\u20139. [15] Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J. and Mei, Q. 2015. Line: Large-scale information network embedding. Proceedings of the 24th International Conference on World Wide Web (2015), 1067\u20131077. [16] Thomas, K., Grier, C., Song, D. and Paxson, V. 2011. Suspended accounts in retrospect: an analysis of twitter spam. Proceedings of the 2011 ACM \u2026. (2011), 243\u2013258. [17] Weng, J., Lim, E.P., Jiang, J. and He, Q. 2010. Twitterrank: Finding topic-sensitive influential twitterers. Proceedings of the 3rd ACM International Conference on Web Search and Data Mining (WSDM 2010). (2010), 261\u2013270. [18] Yang, J. and Leskovec, J. 2011. Patterns of temporal variation in online media. WSDM (2011), 177. [19] Zhang, X., Zhu, S. and Liang, W. 2012. Detecting spam and promoting campaigns in the\nTwitter social network. Proceedings - IEEE International Conference on Data Mining, ICDM (2012), 1194\u20131199."}], "references": [{"title": "Detecting spammers on twitter. Collaboration, electronic messaging, anti-abuse and spam conference (CEAS)", "author": ["F. Benevenuto", "G. Magno", "T. Rodrigues", "V. Almeida"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Exploiting Burstiness in Reviews for Review Spammer Detection", "author": ["G. Fei", "A. Mukherjee", "B. Liu", "M. Hsu", "M. Castellanos", "R. Ghosh"], "venue": "Proceedings of the Seventh International Conference on Weblogs and Social Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Detecting and characterizing social spam campaigns", "author": ["H. Gao", "J. Hu", "C. Wilson", "Z. Li", "Y. Chen", "B.Y. Zhao"], "venue": "Proceedings of the 10th ACM SIGCOMM conference on Internet measurement", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Understanding and combating link farming in the twitter social network", "author": ["S. Ghosh", "B. Viswanath", "F. Kooti", "N.K. Sharma", "G. Korlam", "F. Benevenuto", "N. Ganguly", "K.P. Gummadi"], "venue": "Proceedings of the 21st ...", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "node2vec: Scalable feature learning for networks", "author": ["A. Grover", "J. Leskovec"], "venue": "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2016}, {"title": "Social Spammer Detection in Microblogging", "author": ["X. Hu", "J. Tang", "Y. Zhang", "H. Liu"], "venue": "IJCAI", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "On the Temporal Dynamics of Opinion Spamming: Case Studies on Yelp", "author": ["S. K C", "A. Mukherjee"], "venue": "25th International World Wide Web Conference,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "What is Twitter , a Social Network or a News Media", "author": ["H. Kwak", "C. Lee", "H. Park", "S. Moon"], "venue": "The International World Wide Web Conference Committee", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Uncovering social spammers: social honeypots+ machine learning", "author": ["K. Lee", "J. Caverlee", "S. Webb"], "venue": "Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Detecting Campaign Promoters on Twitter", "author": ["H. Li", "A. Mukherjee", "B. Liu", "R. Kornfield", "S. Emery"], "venue": "Using Markov Random Fields. 2014 {IEEE} International Conference on Data Mining,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Distributed Representations of Words and Phrases and their Compositionality. Nips", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["T. Mikolov", "G. Corrado", "K. Chen", "J. Dean"], "venue": "Proceedings of the International Conference on Learning Representations (ICLR", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Detecting spammers on social networks. Proceedings of the 26th annual computer security applications conference", "author": ["G. Stringhini", "C. Kruegel", "G. Vigna"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Line: Large-scale information network embedding", "author": ["J. Tang", "M. Qu", "M. Wang", "M. Zhang", "J. Yan", "Q. Mei"], "venue": "Proceedings of the 24th International Conference on World Wide Web", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Suspended accounts in retrospect: an analysis of twitter spam", "author": ["K. Thomas", "C. Grier", "D. Song", "V. Paxson"], "venue": "Proceedings of the 2011 ACM ...", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Twitterrank: Finding topic-sensitive influential twitterers", "author": ["J. Weng", "E.P. Lim", "J. Jiang", "Q. He"], "venue": "Proceedings of the 3rd ACM International Conference on Web Search and Data Mining (WSDM", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Patterns of temporal variation in online media", "author": ["J. Yang", "J. Leskovec"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Detecting spam and promoting campaigns in the Twitter social network", "author": ["X. Zhang", "S. Zhu", "W. Liang"], "venue": "Proceedings - IEEE International Conference on Data Mining,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}], "referenceMentions": [{"referenceID": 5, "context": "Moreover, they follow reflexive reciprocity [6, 17] (users following back when they are followed by someone to show courtesy) to establish social influence and act normal.", "startOffset": 44, "endOffset": 51}, {"referenceID": 16, "context": "Moreover, they follow reflexive reciprocity [6, 17] (users following back when they are followed by someone to show courtesy) to establish social influence and act normal.", "startOffset": 44, "endOffset": 51}, {"referenceID": 6, "context": "There have been several works on spam detection in general, especially review spam [7], and opinion spam.", "startOffset": 83, "endOffset": 86}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "leveraged profile-based features and deployed social honeypots to detect new social spammers [9].", "startOffset": 93, "endOffset": 96}, {"referenceID": 13, "context": "also studied spam detection using honey profiles [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 3, "context": "studied the problem of link farming in Twitter [4] and introduced a ranking methodology to penalize the link farmers.", "startOffset": 47, "endOffset": 50}, {"referenceID": 15, "context": "Abuse of online social networks was studied in [16].", "startOffset": 47, "endOffset": 51}, {"referenceID": 2, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 9, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 18, "context": "Campaign spams was studied on [3, 10, 19].", "startOffset": 30, "endOffset": 41}, {"referenceID": 11, "context": "Skip-gram model [12] has been popular to learn the features from a large corpus of data.", "startOffset": 16, "endOffset": 20}, {"referenceID": 12, "context": "DeepWalk [13] learns d-dimensional feature representations by simulating uniform random walks.", "startOffset": 9, "endOffset": 13}, {"referenceID": 14, "context": "LINE [15] learns the d-dimensional features into two phases: d/2 BFS-style simulations and another d/2 2-hop distant nodes.", "startOffset": 5, "endOffset": 9}, {"referenceID": 4, "context": "Node2vec [5] creates the ordered sequence simulating the BFS and DFS approaches.", "startOffset": 9, "endOffset": 12}, {"referenceID": 17, "context": "For this work, we use the Twitter dataset used in [18].", "startOffset": 50, "endOffset": 54}, {"referenceID": 7, "context": "To extract the network graph for those 17 million users, we extracted the follower-following topology of Twitter from [8] which contains all the entire twitter user profiles and their social relationships till July 2009.", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "We pruned the users so that they have social relationship in [8] and tweets in [18] and are left with 4,405,698 users.", "startOffset": 61, "endOffset": 64}, {"referenceID": 17, "context": "We pruned the users so that they have social relationship in [8] and tweets in [18] and are left with 4,405,698 users.", "startOffset": 79, "endOffset": 83}, {"referenceID": 4, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 12, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 14, "context": "To solve the optimization problem, we extend the SkipGram architecture [5, 13, 15] which approximates the conditional probability using an independence assumption that the likelihood of observing an equivalent neighborhood node is independent of observing any other equivalent neighborhood given the latent features of the source node.", "startOffset": 71, "endOffset": 82}, {"referenceID": 11, "context": "So, we use negative sampling [12] to approximate it.", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "Feature learning methods based on Skip-gram architecture are developed for natural language [11].", "startOffset": 92, "endOffset": 96}, {"referenceID": 4, "context": "To mitigate this problem, we use multiple biased random walks each one in principle exploring a different neighborhood [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 0, "context": "We did not use feature extraction techniques like [1] as they only use the node features without using the graph structure.", "startOffset": 50, "endOffset": 53}, {"referenceID": 12, "context": "Deepwalk [13].", "startOffset": 9, "endOffset": 13}, {"referenceID": 12, "context": "Node2vec [13].", "startOffset": 9, "endOffset": 13}, {"referenceID": 1, "context": "Inspired by spam detection in [2], we define 3 hidden states {Spammer, Mixed, NonSpammer} and the Propagation Matrix is used as in Table 1.", "startOffset": 30, "endOffset": 33}], "year": 2017, "abstractText": null, "creator": "PScript5.dll Version 5.2.2"}}}