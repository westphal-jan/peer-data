{"id": "1704.07854", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Apr-2017", "title": "Pre-computed Liquid Spaces with Generative Neural Networks and Optical Flow", "abstract": "liquids automatically exhibit highly complex, non - redundant linear behavior under changing simulation conditions such as user interactions. we propose a discrete method to map towards this complex behavior over a parameter range onto a reduced representation based on space - time deformations. in standard order to represent the complexity of the full space of inputs, we use aligned deformations from optical flow tensor solves, tools and we leverage the power of generative neural networks to synthesize additional deformations for refinement. we introduce a novel deformation - phase aware loss function, which enables optimization in the highly non - linear product space of multiple directional deformations. to demonstrate the effectiveness of our gradient approach, see we showcase the method with several unexpectedly complex examples in two and four dimensions. possible our representation makes. it readily possible to generate implicit surfaces views of liquids very efficiently, which allows us to very efficiently display the scene from any angle, and to add secondary effects such as particle systems. we have implemented all a mobile application with our full pipeline to demonstrate that real - time system interaction is possible with our approach.", "histories": [["v1", "Tue, 25 Apr 2017 18:21:42 GMT  (2752kb,D)", "http://arxiv.org/abs/1704.07854v1", "Supplemental Android app:this https URL"]], "COMMENTS": "Supplemental Android app:this https URL", "reviews": [], "SUBJECTS": "cs.GR cs.LG", "authors": ["boris bonev", "lukas prantl", "nils thuerey"], "accepted": false, "id": "1704.07854"}, "pdf": {"name": "1704.07854.pdf", "metadata": {"source": "META", "title": "Pre-computed Liquid Spaces with Generative Neural Networks and Optical Flow", "authors": ["Boris Bonev", "Lukas Prantl", "Nils Thuerey"], "emails": [], "sections": [{"heading": null, "text": "Liquids exhibit highly complex, non-linear behavior under changing simulation conditions such as user interactions. We propose a method to map this complex behavior over a parameter range onto a reduced representation based on space-time deformations. In order to represent the complexity of the full space of inputs, we use aligned deformations from optical flow solves, and we leverage the power of generative neural networks to synthesize additional deformations for refinement. We introduce a novel deformation-aware loss function, which enables optimization in the highly non-linear space of multiple deformations. To demonstrate the effectiveness of our approach, we showcase the method with several complex examples in two and four dimensions. Our representation makes it possible to generate implicit surfaces of liquids very efficiently, which allows us to very efficiently display the scene from any angle, and to add secondary effects such as particle systems. We have implemented a mobile application with our full pipeline to demonstrate that real-time interaction is possible with our approach.\nKeywords: fluid simulation, convolutional neural networks, optical flow, space-time deformation"}, {"heading": "1 Introduction", "text": "Having the possibility to interact with physical effects allows users to experience and explore their complexity directly. In interactive settings, users can ideally inspect the scene from different angles, and experiment with the physical phenomena using varying modes of interaction. This hands-on experience is difficult to convey with pre-simulated and rendered sequences. While it is possible to perform real-time simulations with enough computing power at hand [Macklin et al. 2014], many practical applications cannot rely on a dedicated GPU at their full disposal. An alternative to these di-\nrect simulations are data-driven methods that pre-compute the motion and/or the interaction space to extract a reduced representation that can be evaluated in real-time. This direction has been demonstrated for a variety of interesting effects such as detailed clothing [Kim et al. 2013], soft-tissue effects [Xu and Barbic\u030c 2016], swirling smoke [Treuille et al. 2006], or for forces in SPH simulations [Ladicky et al. 2015].\nLiquids are an especially tough candidate in this area, as the constantly changing boundary conditions at the liquid-gas interface result in a strongly varying and complex space of surface motions and configurations. A notable exception here is the StateRank approach [Stanton et al. 2014], which enables interactive liquids by carefully pre-computing a large graph of pre-rendered video clips to synthesize the desired liquid behavior. The algorithm by Ladicky et al. also successfully proposes a pre-computation scheme for liquids, which however targets the accelerations in a Lagrangian approach in order to accelerate a full dynamic simulation.\nIn the following, we will present a novel approach to realize interactive liquid simulations: we treat a (potentially very large) collection of input simulations as a smoothly deforming set of space-time signed-distance functions (SDF). An initial implicit surface is deformed in space and time to yield the desired behavior as specified by the initial collection of simulations. To calculate and represent the deformations efficiently, we take a two-step approach: First, we span the sides of the original collection with multiple pre-computed deformations. In a second step, we refine this rough surface with a generative neural network. Given the pre-computed deformations, this network is trained to represent the details within inner space of the initial collection.\nFor data-driven liquids, working with implicit surfaces represents a sweet spot between the raw simulation data, which for liquids often consists of a large number of particles, and a pre-rendered video. The deformed implicit surface can be rendered very efficiently from\nar X\niv :1\n70 4.\n07 85\n4v 1\n[ cs\nany viewpoint, and can be augmented with secondary effects such as splashes or foam floating on the surface. At the same time, it makes our method general in the sense that we can work with implicit surfaces generated by any simulation approach.\nAll steps of our pipeline, from applying the pre-computed deformations to evaluating the neural network and rendering the surface, can be performed very efficiently. To demonstrate the very low computational footprint of our approach, we run our final models on a regular mobile device at interactive frame rates. Our demo application can be obtained online in the Android Play store under the title Neural Liquid Drop [Prantl et al. 2017], and several screenshots of it can be found in Fig. 2. In this app, generating the implicit surface for each frame requires only 30ms on average. The central contributions of our work are a novel deformation-aware neural network approach to efficiently represent large collections of space-time surfaces, an improved deformation alignment step in order to apply the pre-computed deformations, and a real-time synthesis framework for mobile devices. Our contributions make it possible to represent the deformation space for more than 1000 input simulations in a 30MB mobile executable."}, {"heading": "2 Related Work", "text": "Representing complex physics with reduced models has a long and successful history in computer graphics. Initially, works focused particularly on deformable models, e.g., demonstrating fast simulations with modal dynamics [Pentland and Williams 1989] or using tabulation techniques for deformable scenes [James and Fatahalian 2003] (capturing illumination effects at the same time). Subsequent works targeted more expressive and general constitutive models [Barbic\u030c and James 2005] and related effects such as sound generation [James et al. 2006]. More recently, researchers have also demonstrated flexible character animations with reduced models [Kim and James 2012], even including interactions with collisions not captured in the pre-computed basis [Teng et al. 2015] or coupling Lagrangian and Eulerian reduced representations [Teng et al. 2016]. Pre-computed models were shown to be especially useful in constrained and repetitive settings, e.g. for secondary soft-tissue effects [Xu and Barbic\u030c 2016]. In the following, we will focus on fluid effects, for which the commonly used physical model is given by the Navier-Stokes (NS) equations: Du/Dt = \u2212\u2207p+\u03bd\u2207\u00b7\u2207u+fext, in conjunction with the constraint\u2207\u00b7u = 0. Here u is the flow velocity, p the pressure, and fext denotes the external body forces. \u03bd parametrizes viscosity, and is typically set to zero for graphics applications, yielding the incompressible Euler equations. Model reduction techniques have also been applied successfully to single-phase flows, i.e. wind and smoke effects [Treuille et al. 2006]. This approach was generalized to work with modular bases [Wicke et al. 2009], to include rendering effects [Gupta and Narasimhan 2007], and to accurately model the semi-Lagrangian transport commonly employed in graphics solvers [Kim and Delaney 2013]. Other researchers have explored specialized basis constructions [De Witt et al. 2012], and compression techniques [Jones\net al. 2016]. The gradient calculation of our learning approach also shares similarities with the adjoint method for fluid flow [McNamara et al. 2004], where gradients of the advection operator likewise play an important role. There, the optimization works on sequences of three-dimensional, divergence free motions with comparably small motions.\nWhile suitable for single phase flows, the aforementioned techniques become problematic for free-surface flows. In this setting, the commonly used free surface boundary conditions strongly influence the dynamics of the liquid phase and require prohibitively large numbers of basis functions to be captured with sufficient detail. The StateRank approach proposed by Stanton et al. [2014] takes a different viewpoint to make pre-computations for liquid simulations possible. It pre-computes a state graph based on user interactions to capture the liquid, and refines the graph at runtime. In contrast to our approach, the data in this state graph is static. While temporal transitions employ blending, all other pre-rendered video sequences are used without modification. On the other hand, our approach uses a single data point, which is then transformed smoothly into a desired space-time motion. As such, we believe our contributions could complement such a state graph to significantly reduce its size.\nThe non-linear model we employ for our reduced representations is centered around concatenated deformations. A central building block for our approach is the calculation of deformation fields from surface correspondences established by close proximity. Previous works employed non-rigid iterative closest point methods for Lagrangian surfaces [Raveendran et al. 2014], and variational formulations for Eulerian data sets [Thuerey 2017]. We will likewise take an Eulerian viewpoint and employ the latter method. However, we outline two changes when computing and applying Eulerian deformations to increase accuracy and robustness. What sets our method apart from these two previous approaches is that both of them focused on computing single deformations, instead of dealing with optimization problems that target a whole spaces spanned by deformations. These previous approaches always work with two single data points, source and target, while our approach considers the whole collection of target data sets at once. It is worth pointing out that the deformations typically have long range, vary strongly in space and time and that applying them is a non-linear operation. While this makes our representation very small and expressive, the high degree of non-linearity makes them difficult to handle in optimization frameworks. This is one of the central issues we will address in Sec. 4.2.\nThere are various methods in graphics that have targeted real-time simulations with specialized techniques. Especially for larger open water scenes, reducing the dimensionality with two-dimensional models allows for very fast simulations [Kass and Miller 1990; Wang et al. 2007]. Interesting variations include erosion effects [Stava et al. 2008] or incorporate three-dimensional effects near the surface [Chentanez and Mu\u0308ller 2011]. Particle-based liquid simulations are also highly interesting for fast simulations [Solenthaler and Pajarola 2009; Macklin and Mu\u0308ller 2013] Likewise, many recent techniques focus on novel representations to allow for fast simulations, e.g. to represent highly detailed surfaces with meshes [Chentanez et al. 2015] or to represent detailed cut surfaces [Manteaux et al. 2015]. We employ a typical NS solver from the graphics area [Stam 1999; Enright et al. 2003], using ghost-fluid boundaries [Enright et al. 2003], and the FLuid-Implicit Particle method [Zhu and Bridson 2005]. However, our method is not restricted to inputs from this particular choice of solver. Liquid surfaces from particle based simulators [Ihmsen et al. 2014] or any other type of physical simulator would likewise be suitable inputs, as long as they are available as implicit representation for each time step.\nWhile the fundamentals of machine learning have been established at the advent of computer technology, the field of machine learning with neural networks (NNs) has recently experienced a steep increase in interest due to technological advances [Werbos 1974; Rumelhart et al. 1988]. Impressive results have been achieved in many disciplines of computer vision, such as image classification [Krizhevsky et al. 2012] and object detection and segmentation [Girshick et al. 2014]. In the field of computer graphics, researchers have also employed neural networks for diverse tasks such as robust human correspondences from depth maps [Wei et al. 2015], visual similarity for product design [Bell and Bala 2015], automatic image colorization [Iizuka et al. 2016] and photo retrieval from sketches [Sangkloy et al. 2016]. The general architecture of our networks follows other generative approaches [Goodfellow et al. 2014], with the central difference that we focus on learning deformations, and do not employ an adversarial network architecture.\nCloser to our area of application, researchers have also investigated computing image deformations, i.e. solving the optical flow problem, with neural networks. While many works target localized regions and feature descriptors to retrieve depth and correspondences [Bailer et al. 2016], several works have investigated retrieving dense image-space deformations. The so called FlowNet architecture has proven to be efficient and accurate [Dosovitskiy et al. 2015] and has been extended to compute large-range motions with the help of multi-scale approaches [Ranjan and Black 2016; Ilg et al. 2016]. These papers require explicit annotations with deformation data during the learning phase. In contrast, our networks learn to deform the data given only a target data set. This is crucial for applications where reference motions are not readily available for all inputs.\nDespite the success stories in many areas of computer science, machine learning techniques have rarely been applied in the area of physically-based animations. Specifically for liquid simulations, a recent approach was proposed to efficiently model response forces for particle-based simulations using regression forests [Ladicky et al. 2015]. Only few papers exist up to now employing neural networks for Eulerian simulations: one work aims for learning localized, divergence-free velocity updates [Yang et al. 2016], while the another work learns to remove divergent motions for whole grids using convolutional neural networks [Tompson et al. 2016]. In addition, neural networks have recently been used to learn the similarity of coarse and fine smoke simulations [Chu and Thuerey 2017], and to generate small-scale splash effects [Um et al. 2017]. All of these works employ machine learning to speed up or augment direct simulations, while we aim to represent clearly defined regions of liquid behavior with our approach. We will employ convolutional neural networks in the following, as their generative capabilities were shown to be powerful tools [Goodfellow et al. 2014]. After spanning the sides of a chosen region with pre-computed long range deformations, our networks learn to generate deformations to respect the content of these regions."}, {"heading": "3 Problem Description", "text": "Given a Navier-Stokes boundary value problem with a liquid-gas interface, we consider the interface over time as a single space-time surface. We start with a set of these space-time surfaces, which we will call \u0393, defined over a convex region of our simulation parameters \u03b1. We assume all parameter dimensions to be normalized, i.e. \u03b1 \u2208 [0, 1]N . In practice, \u03b1 could be any parameter of the simulation, e.g. initial positions, velocity boundary conditions, or physical parameters such as viscosity. Looking at this set of surfaces as a whole, \u0393(\u03b1) represents the complex manifold that we want to capture and represent. We choose implicit functions \u03c6(\u03b1) \u2208 R3 \u00d7 R+ \u2192 R to represent specific instances of the manifold, such that \u0393(\u03b1) = { x \u2208 R3 \u00d7 R+;\u03c6(\u03b1)(x) = 0 } . In the following, \u03c6 and \u03c8 will denote four-dimensional signed distance functions, where the first three dimensions are space, while the fourth dimension represents time. We will abbreviate \u03c6(\u03b1) with \u03c6\u03b1 in the following to simplify notation, and to indicate that this set of surfaces represents a collection of constant reference surfaces in our setting.\nRepresenting the whole set \u03c6\u03b1 is a challenging task. In theory, the original surfaces of \u0393 are continuous, and by choosing the implicit representation \u03c6\u03b1, we regularize the space of inputs. Due to bifurcations and noise-like artifacts (as seen in Fig. 3) from discretization errors there can, however, be very significant differences even for small changes of \u03b1. Despite these challenges, our goal is to find a manageable and reduced representation. We use our prior knowledge of the problem, and embed \u03c6\u03b1 into a space spanned by warping a single input surface with a set of deformation fields. Thus, we generate an approximation of \u03c6\u03b1 by applying a spacetime deformation F : R4 \u2192 R4 to an initial surface \u03c8(x), where F (x, U,\u03b1) again depends on the simulation parameters \u03b1. In our case F is constructed from a set of auxiliary deformation fields U : {u1, ...uN}, where ui : R4 \u2192 R4. Note that even the simplest choice for F with a single deformation, i.e. F = x \u2212 \u03b11u1, is already non-linear. For now we will assume that all functions are continuous, and sufficiently differentiable. We will later on discretize all functions with Cartesian grids and employ linear interpolation, although other Eulerian representations and higher order basis functions could likewise be used.\nWe have two goals when calculating the reduced representation: the first goal is staying true to the original simulations by minimizing\u222b \u2016\u03c8(F (x, U,\u03b1))\u2212 \u03c6\u03b1(x)\u201622 d\u03b1, where we used the L\n2 norm \u2016.\u20162 to measure the distance between the two implicit functions. Although we will present our algorithm with the use of said norm, the concepts described here generalize well and can be adapted to other metrics. As a secondary goal, we would like to minimize the function above with a small number of deformation fields |U |. The size of this set1 not only directly represents the amount of data we have to store, but also the amount of computations we have to perform to generate an output. We will focus on single sets of N deformations in the following, but naturally multiple sets for adjacent parameter regions could be combined to cover even larger spaces of behavior.\nFor our method, we span the outer sides of the \u03b1 simplex with pre-computed end-point deformations, and then refine the insides using a generative neural network with a deformation-aware loss function. As the end-point deformations only consider source and target, they do not necessarily represent the space between the two extremes well. This region is where our generative neural network will be active to refine the surfaces produced by the end-point deformations. In the following, we will use an optical flow solver to\n1Note that the set of deformations can not be considered a basis, as the application of a single, arbitrary deformation is already a non-linear process.\ncompute the end-point deformations ui [Thuerey 2017]. However, our approach is not limited to inputs from optical flow. Any algorithm that computes deformations between two implicit surfaces could be used for this pre-processing stage [Solomon et al. 2015]. As we will point out below, we require these deformations to be smooth. This is usually directly enforced with corresponding regularization when computing the end-point deformations.\nIn line with previous work [Raveendran et al. 2014; Thuerey 2017] we concatenate spatial surfaces as slices of each 4D volume, and then generate a 4D SDF from this initial surface. Without loss of generality, we assume similar resolutions in space in time in the following. Otherwise, this straight forward concatenation could lead to a space vs. time distance bias in the volumes, which however could be corrected for with a suitable scaled distance metric, if necessary."}, {"heading": "3.1 Deformation Alignment", "text": "As outlined above, \u03c6\u03b1 will denote the reference signed distance functions (SDFs) of our input parameter space, while \u03c8 will denote instances of a single input surface deformed by our algorithm. We will denote the single initial surface with\u03c80 in the following. Here, we typically use the zero point of our parameter space, i.e., \u03c80 = \u03c6\u03b10 , with \u03b10 = 0. Hence, we aim for deforming \u03c80 such that it matches all instances of \u03c6\u03b1 as closely as possible. Before we formalize this in terms of a loss function in the next section, we will explain our approach for applying the deformation.\nFor the end-point deformations, it is our goal to only use a single deformation for each dimension of the parameter space \u03b1. Thus u1 will correspond to \u03b11, and we can apply \u03b11u1 to compute a deformation for an intermediate point along this dimension. E.g., the deformed initial surface for a chosen point \u03b1\u0303 on the first dimension \u03b11 can be computed with \u03c80(x\u2212 \u03b1\u0303u1).\nGiven the sequence end-point deformations {u1,u2, . . . ,uN} and a point in parameter space {\u03b11, . . . , \u03b1N} a straight-forward approach is to apply each deformation sequentially:\n\u03c81(x,\u03b1) = \u03c80(x\u2212 \u03b11u1) \u03c82(x,\u03b1) = \u03c81(x\u2212 \u03b12u2)\n...\n\u03c8N (x,\u03b1) = \u03c8N\u22121(x\u2212 \u03b1NuN ). (1)\nHowever, there are two disadvantages to this approach. The main problem of this approach is that the deformations ui are only meaningful if applied with \u03b1i = 1 (see Fig. 4). This means, that if a previous deformation wasn\u2019t applied fully with a weight of 1, each subsequent deformation will lead to an accumulation of deformation errors. The second disadvantage of this simple method is the fact that many advection steps have to be applied in order to arrive at the final deformed SDF. This also affects performance as each advection step introduces additional computations. We present an alternative approach which aligns the deformation fields to the final position of the deformation sequence in order to combine them in a meaningful manner. To do this, we introduce the intermediate deformation fields:\nu\u2217N (x) = uN (x),\nu\u2217N\u22121(x) = uN\u22121(x\u2212 u\u2217N (x)), u\u2217N\u22122(x) = uN\u22122(x\u2212 u\u2217N (x)\u2212 u\u2217N\u22121(x)),\n...\nu\u22171(x) = u1(x\u2212 u\u2217N (x)\u2212 u\u2217N\u22121(x) . . .\u2212 u\u22172(x)). (2)\nIn this way, we align all deformation fields to the final destination of the deformation sequence. The Eulerian representation we are using means that advection steps look backward to gather data, which in our context means that we start from the last deformation uN to align previous deformations. Using the aligned deformation fields u\u2217 we can include \u03b1 and assemble the weighted intermediate fields\nv(x,\u03b1) = N\u2211 i=1 \u03b1iu \u2217 i (x) (3)\nand\nv\u0303(x,\u03b1) = \u2212 N\u2211 i=1 (1\u2212 \u03b1i)u\u2217i (x). (4)\nThe first deformation field v(x) represents the weighted sum of all aligned deformations, weighted with the correct amount of defor-\nmation specified by the deformation parameters \u03b1i. The second deformation v\u0303, weighted by the inverse weights, is a correction term. Intuitively, this term represents the offset of the deformation field v from its destination. Therefore, we correct the position of v by this offset with the help of an additional forward-advection step calculated as:\nV(x + v\u0303(x,\u03b1),\u03b1) = v(x,\u03b1), (5)\nThis gives us the final deformation field V(x,\u03b1). It is important to note that the deformation v for a position x is assembled at an initially unknown location x\u2032. It is then transported to x with the help of v\u0303. This is illustrated in the following figure:\nx\u2032\nx\nv(x\u2032)\nv\u0303(x\u2032)\nx\u2032\nx V(x)\nThus, this step is not a regular advection step, as the deformation is being \u2019pushed\u2019 from x + v\u0303(x, \u03b2) to x. In order to solve this advection equation we use an inverse semi-Lagrangian step. This step pushes values forward with linear interpolation. As multiple values can end up in a single location, we normalize their contribution. Afterwards, we perform several iterations of a flood fill step to make sure all cells in the target deformation grid receive a contribution (we simply extend and average deformation values from all initialized cells into uninitialized regions). The deformed SDF is then calculated by a regular advection equation applying the final, aligned deformation with\n\u03c8(x,\u03b1) = \u03c80(x\u2212V(x,\u03b1)). (6)\nBased on our correction step from Eq. (5) this method now respects the case when deformations are not applied fully. As each deformation u\u2217(x) is already aligned and does not depend on \u03b1, we can pre-compute them. To retrieve the final result it is now sufficient to sum up all deformations in v and v\u0303, then apply one forwardadvection step to compute V, and finally deform the SDF by applying semi-Lagrange advection. While our method is identical with alignment from previous work [Thuerey 2017] for \u03b1i = 1, its importance for practical deformations with weights \u03b1i 6= 1 is illustrated in Fig. 4.\nThis algorithm for aligning deformations will be our starting point for generating initial deformed surfaces with end-point deformations. These deformed surfaces will then be adjusted and refined by our neural networks that we will explain in the following section."}, {"heading": "4 Learning Deformations", "text": "In this section we will outline a deformation-aware machine learning approach to improve the approximation of the initial surface set \u03c6\u03b1. When adjusting the composition of deformations the algorithm explained so far will yield a smooth transition, but it will typically not capture the complex, non-linear behavior that occurs when fluid simulation parameters are changed. This is not surprising, due to the fact that the end-point deformations are optimized to yield the best possible final result for each \u03b1i = 1. We will show that our network can learn to adjust these deformation parameters \u03b1i, and additionally that it can learn to generate new deformations to improve the quality of the generated liquid surfaces.\nTo train our machine learning model, we propose the following objective function, which measures the similiarity of a known reference surface \u03c6\u03b1 and the corresponding, approximated result\n\u03c8(xi, \u03b1). To this end, we introduce the numerical equivalent of the L2 loss\nL = 1\n2 \u2211 i (\u03c8(xi, \u03b1)\u2212 \u03c6\u03b1(xi))2 , (7)\nwhich approximates the analytical loss \u2016\u03c8(x, \u03b1)\u2212 \u03c6\u03b1(x)\u201622. Here the integration over the domain was replaced by the summation over all cells with cell-centers at xi. Regardless of the approach we are using, we strive to match the surface of the advected solution \u03c8(x, \u03b1) = 0 to the surface of the reference solution \u03c6\u03b1(x) = 0 as well as possible. This is reflected by a vanishing loss in Eq. (7).\nWhile this loss function looks trivial at first, note that\u03c8(xi, \u03b1) from Eq. (6) encapsulates a series of highly non-linear deformation steps. In the following, a central challenge will be to compute reliable gradients in spite of these accumulated non-linearities."}, {"heading": "4.1 Learning Optimal Deformation Parameters", "text": "We will first focus on the intermediate parameters \u03b1. We replace these simulation parameters in Eq. (6) with new parameters \u03b2(\u03b1) = (\u03b21(\u03b1), . . . , \u03b2N (\u03b1)) so that we can vary the extent to which a specific deformation is applied. We assume that there is an optimal function which gives us the best deformation parameters with respect to Eq. (7) for any given simulation parameter set \u03b1. We approximate this function with a feed-forward neural network. Thus, given a set of \u03b1 values an input, the network should learn to output corresponding weights \u03b2 for the deformations, such that the initial surface matches the desired simulation state at \u03b1 when the deformations are applied. This application of the weighted deformations includes our alignment step from Sec. 3.1.\nThe network is characterized by the number of layers in the neural network, by the activation function h(x), the number of nodes in each each layer nL and their respective weights \u03b8lij . We can then write the activation ali of the i-th node in the l-th layer as a function of all the activations in the previous layer:\nali = h (nl\u22121\u2211 j=1 \u03b8lij a l\u22121 j ) . (8)\nWe use the common simplified notation to include the bias in \u03b8l with a constant input for each node. Through composition, we can construct the parameter function \u03b2(\u03b1, \u03b8)\n\u03b2i(\u03b1, \u03b8) = h (nL\u22121\u2211 j=1 \u03b8Lij h (nL\u22122\u2211 k=1 \u03b8L\u22121jk \u00b7 \u00b7 \u00b7 )) , (9)\nwhich is a function of the input parameters \u03b1 and all weights \u03b8 = (\u03b8111, . . . , \u03b8 L nlnl\u22121). With this function \u03b2(\u03b1, \u03b8), we replace all instances of \u03b1i in Eq. (6) with \u03b2i(\u03b1, \u03b8) to compute a differently weighted, and aligned final deformation field V.\nTo train the neural network, we need to specify gradients of Eq. (7) with respect to the network weights \u03b8i. With the chain rule we obtain d\nd\u03b8lij L = d\u03b2 d\u03b8lij dL d\u03b2 . Since the derivative of the network output \u03b2i with respect to a specific network weight \u03b8lij is easily calculated with backpropagation [Bishop 2006], it is sufficient for us to specify the second term. The gradient of Eq. (7) with respect to the deformation parameter \u03b2i is given by\nd d\u03b2i L = \u2211 j d d\u03b2i \u03c8(xj ,\u03b2) [\u03c8(xj ,\u03b2)\u2212 \u03c6\u03b1(xj)] , (10)\nwhere we have inserted Eq. (6). While the second term in the sum is easily computed, we need to calculate the first term by differentiating Eq. (6) with respect to \u03b2i, which yields\nd d\u03b2i \u03c8(x,\u03b2) = \u2212 d d\u03b2i V(x,\u03b2) \u00b7 \u2207\u03c80(x\u2212V(x,\u03b2)). (11)\nIt is clear, that we need to calculate the change dd\u03b2iV(x, \u03b2) in the deformation field, when a small change is applied to the deformation parameter \u03b2i. This is non-trivial as it is not possible to derive a closed form V(x, \u03b2) from Eq. (5). It is important to note that even for the case of small corrections v\u0303(x, \u03b2), Eq. (5) cannot be handled as another backward-advection step V(x,\u03b1) = v(x \u2212 v\u0303(x,\u03b1),\u03b1). While it might be tempting to assume that differentiating this advection equation will produce reasonable outcomes, it can lead to noticeable errors in the gradient. These in turn quickly lead to diverging results in the learning process, due to the non-linearity of the problem.\nThe correct way of deriving the change in V(x, \u03b2) is by taking the total derivative of v(x, \u03b2) = V(x+ v\u0303(x, \u03b2), \u03b2) with respect to \u03b2i:\nd d\u03b2i v(x, \u03b2)\n= \u2202\n\u2202\u03b2i V(x + v\u0303(x, \u03b2), \u03b2) + JV (x + v\u0303(x, \u03b2), \u03b2)\n\u2202\n\u2202\u03b2i v\u0303(x, \u03b2),\n(12)\nwhere, JV (x+ v\u0303(x, \u03b2), \u03b2) denotes the Jacobian of V with respect to x, evaluated at x + v\u0303(x, \u03b2). Rearranging Eq. (12) and inserting v and v\u0303 yields\n\u2202\n\u2202\u03b2i V(x + v\u0303(x, \u03b2), \u03b2) (13)\n= d\nd\u03b2i v(x, \u03b2)\u2212 JV (x + v\u0303(x, \u03b2), \u03b2)\n\u2202\n\u2202\u03b2i v\u0303(x, \u03b2)\n= d\nd\u03b2i N\u2211 i=1 \u03b2iu \u2217 i (x) + JV (x + v\u0303(x, \u03b2), \u03b2) \u2202 \u2202\u03b2i N\u2211 i=1 (1\u2212 \u03b2i)u\u2217i (x)\n= [1\u2212 JV (x + v\u0303(x, \u03b2), \u03b2)]u\u2217i (x). (14)\nWe note that the Jacobian in the equation above has small entries due to the smooth nature of the deformations V. Thus, compared to the unit matrix it is small in magnitude. (Note that this is not yet visible in Eq. (12).) We have verified in experiments that JV does not improve the gradient significantly, and we thus set this Jacobian to zero, arriving at\n\u2202\n\u2202\u03b2i V(x + v\u0303(x, \u03b2), \u03b2) \u2248 u\u2217i (x), (15)\nwhere the u\u2217 are the deformation fields aligned for the target configuration from Eq. (2). We use Eq. (15) to estimate the change in the final deformation fields for changes of the i-th deformation parameter. We see that this equation has the same structure as Eq. (5). On the left-hand side, we have \u2202\n\u2202\u03b2i V, evaluated at x + v\u0303(x, \u03b2),\nwhereas u\u2217i on the right-hand side is evaluated at x. To calculate d d\u03b2i V(x, \u03b2) then, we can use the same forward-advection algorithm, which is applied to the correction in Eq. (5).\nWith this, we have all the necessary tools to train the neural network, as we can calculate all the required terms for Eq. (10). Therefore, we can backpropagate these gradients into the neural network. In this way we can now optimize the deformation parameters to improve the results of the advection for any intermediate values of \u03b1i. We will demonstrate the effects of this step in Sec. 7.\n8 8\n\u21b5\nin out\nParameter network:"}, {"heading": "4.2 Generating Deformations with Neural Networks", "text": "Our efforts so far have been centered around producing a good approximation of \u03c6\u03b1, with the given end-point deformations {u0, . . . ,un}. The performance of this method is therefore inherently constrained by the amount of variation we can produce with the deformation inputs. Our approach so far only optimizes the weights \u03b2i of the individual deformations ui in order to produce V(x, \u03b2(\u03b1)).\nTo allow for more variation, we propose to generate an additional space-time deformation field w(\u03b1), that changes with the simulation parameters \u03b1. Once again, we model this function with a neural network, effectively giving the network more expressive capabilities to directly influence the final deformed surface. Therefore, we will now explain how to set up and train this generative neural network architecture. Typically, generative approaches take low-dimensional input data and create high-dimensional outputs. The problem with such an approach lies in the vast number of degrees of freedom it can lead to, especially for our four dimensional setting.\nTo counter this issue, we choose a network structure with additional four-dimensional deconvolution layers. The deconvolution layers can be seen as the transpose of a regular convolution layer, and they can drastically decrease the number of network weights. The resulting structure of our neural network closely resembles an inverted regular convolutional network, and is illustrated in Fig. 5. We apply the trained deformation with an additional advection step:\n\u03c8\u0303(x) = \u03c80 (x\u2212V(x, \u03b2(\u03b1, \u03b8))) , (16)\n\u03c8(x) = \u03c8\u0303 (x\u2212w(x, \u03b1,\u0398)) . (17)\nThis way, the network only has to learn to refine the deformed surface \u03c8\u0303 to accommodate the nonlinear behavior of \u03c6\u03b1.\nThe velocity field w(x, \u03b1,\u0398) is characterized by the network structure, the network weights \u0398 = (\u0398111, . . . ,\u0398Lnlnl\u22121) and the activation function H(x). As input, we supply the network with the simulation parameters \u03b1 = (\u03b1i, . . . , \u03b1N ) as a vector. The output of the network are four-component vectors, with the resolution Rx \u00d7 Ry \u00d7 Rz \u00d7 Rt. Note that in general the SDF resolution\nand the deformation resolution do not need to be identical. Given a fixed SDF resolution, we can use a smaller resolution for the deformation, which reduces the number of weights and computations required for training significantly. This means that in practice each four-dimensional vector of the deformation acts on a region of the SDF, for which we assume the deformation to be constant. Therefore, we write the deformation field as\nw(x, \u03b1,\u0398) = \u2211 j Xj(x) wj(\u03b1,\u0398), (18)\nwhere Xj(x) is the indicator function of the j-th region on which the four-dimensional deformation vector wj(\u03b1) acts. This vector is the j-th output of the neural network.\nTo train the network weights \u0398, we need to calculate the gradient of the loss-function Eq. (7) with respect to the network weights. Just like in the previous section, it is sufficient to specify the gradient with respect to the network outputs wi(\u03b1,\u0398), for the update of \u0398 we can rely on backpropagation. Deriving Eq. (7) yields\nd dwi L\n= \u2211 j d dwi \u03c8(x) (\u03c8(x)\u2212 \u03c6\u03b1(x))\n= \u2211 j d dwi \u03c8\u0303 (x\u2212w(x, \u03b1,\u0398)) (\u03c8(x)\u2212 \u03c6\u03b1(x))\n=\u2212 \u2211 j Xi(xj)\u2207\u03c8\u0303(xj \u2212w(xj , \u03b1,\u0398)) (\u03c8(xj , \u03b1)\u2212 \u03c6\u03b1(xj)) .\n(19)\nThus, we can calculate the derivative by summation over the region that is affected by the network output wi. The gradient term is first calculated by evaluating a finite difference stencil on \u03c8\u0303(xj) and then advecting it with the corresponding deformation vector w(xj , \u03b1,\u0398). The other terms in Eq. (19) are readily available. Alg. 1 summarizes how the training of the network weights \u0398 is performed.\nData: training samples from \u03c6\u03b1 Result: trained network weights \u03b8 for each training sample {\u03b1\u0303, \u03c6\u0303} do\nevaluate neural network to compute \u03b2(\u03b1\u0303) ; load reference SDF \u03c6\u0303; load initial SDF \u03c80; calculate V(xi, \u03b2(\u03b1\u0303)); advect \u03c80 with V and store as \u03c8\u0303; calculate \u2207\u03c8\u0303; evaluate neural network to compute wi(\u03b1\u0303) ; assemble w(xi) from wi(\u03b1\u0303,\u0398) according to Eq. (18); advect \u03c8\u0303 with w; advect \u2207\u03c8\u0303 with w; for each wi do\ncalculate the gradient ddwiL according to Eq. (19); end backpropagation with ddwiL to adjust \u0398;\nend Algorithm 1: Training the network weights\nWorking in conjunction, our two machine learning steps capture significantly more complex behavior of the fluid space-time surface \u03c6\u03b1 over the whole parameter domain. We first adjust the application of the initial deformations with \u03b2(\u03b1), and then let our network\ngenerate an additional, input-dependent deformation field. We will demonstrate in Sec. 7 that learning a correction to the previously advected SDF \u03c8\u0303 performs significantly better than only learning the deformation from \u03c80 in a single step."}, {"heading": "4.3 Training Details", "text": "To train both networks we apply the gradient descent method in combination with backpropagation [Bishop 2006]. More specifically, we use the ADAM optimizer, which is a standard for training neural networks. The outputs of the parameter network are the deformation parameters \u03b2i(\u03b1). The network structure that we use to model this is a simple network with two fully connected layers with 8 nodes each.\nThe deformation network requires more degrees of freedom, as we can expect the function w(\u03b1) to be much more complex. As such, we use a combination of fully connected layers and deconvolution\nlayers to model the deformation field w(\u03b1). Fig. 5 depicts a sketch of this network structure. We choose the first two layers to be fullyconnected, with 16 and 2592 nodes respectively, and ReLU nonlinearities.\nThe output of the second fully connected layer represents a fourdimensional vector array with dimensions 34 containing 32 features. The resolution of the deformation field is then upscaled with multiple four-dimensional deconvolution layers depending on the final resolution of the deformation field. To facilitate training, we choose it such that the final SDF resolution is a multiple of the deformation resolution. We also noticed that regular SDFs can lead to overly large error values far away from the surface. Thus, we apply the tanh function to the SDF values, in order to put more emphasis on the surface region. This slightly improved our training results.\nAs often the case with PDEs, special care is required for boundary conditions. In our case, this means the sides of our domain. Here, we use the common practice of Neumann boundary conditions for values outside of the computational domain. Hence, the SDF values extend to the outside with constant values. The problem with this approach is that this leads to vanishing gradients \u2207\u03c80(x) = 0 in Eq. (19), which in turn often leads to artificial minima or maxima in the loss function. While this could be alleviated with strong regularization, we opted against this approach, and instead perform an on-the-fly distance extrapolation. Here we use the knowledge that the outside of our domain will always contain values outside of the liquid volume. Thus, we increase the retrieved SDF values by the distance of the retrieval point to the domain boundary. In this way, \u2207\u03c80(x) can still be evaluated correctly at the boundaries.\nFor our implementation we use the TensorFlow framework. We integrated our custom deformation-aware loss function (7) and a four-dimensional deconvolution, which is currently, to the best of our knowledge, not supported by any machine-learning library.\nFinally, the training is performed separately for both networks. Since the end-point deformations are applied first, we typically start by training the parameter network with 1000 training steps at a learning rate of 0.001. Once this is completed, we switch to the deformation network, and train it for another 9000 iterations, with the same learning rate."}, {"heading": "4.4 Evaluation", "text": "In order to evaluate our method, we will first use a two-dimensional setup parameter space with two dimensional surfaces. For this purpose we use the SDFs extracted from two-dimensional simulations of a drop falling into a basin. As simulation parameters we choose \u03b11 to be the size of the drop, and \u03b12 to be its initial x-position. From this simulation we extract a single frame at t = 30, which gives us a two-dimensional parameter-space \u03b1 = (\u03b11, \u03b12), where each instance of \u03b1 has a corresponding two-dimensional SDF. This setup is illustrated in Fig. 6.\nWe span the parameter domain with two deformations u1 and u2. In order to train the networks described in section 4, we sample the parameter domain with a regular 44\u00d749 grid, which gives us 2156 training samples.\nTo train the network we divide these samples into 2056 training samples and 100 validation samples. The samples are randomized and used individually in each iteration. Fig. 8 shows the validation loss and the training loss over the iterations both for parameter learning and for deformation learning. We observe that in both cases the learning process reduces the loss, and finally converges to a stable solution. This value is lower in the case of deformation training, which can be easily explained with the increased expressive capabilities of the deformation network. We verified that the solution converged by continuing training for another 36000 steps, during which the solution changed only minimally. In Fig. 7 we see the actual results of our parameter training algorithm. While the improvement is subtle, we can see that both splashes have an improved shape after adjusting the deformation parameters with the neural network.\nFor the gradient of Eq. (10) we mentioned above that it might seem attractive to approximate the effect of the forward-advection with a regular backward-advection step, as this simplifies the calculations significantly. However, due to the strong non-linearity of our setting, this is does not yield a usable algorithm, as the network will not converge with this simplification, as shown in Fig. 9.\nThe effect of our deformation learning approach is illustrated in Fig. 10. This figure compares our full method (on the right) with several other algorithms. As a baseline, the result from previous work is shown on the far left. As the surfaces of this example have larger distances and more complex correspondences than those originally demonstrated with previous work [Thuerey 2017], the\ndebug note: frames 7, 19, 31\nclosest-distance correspondences lead to an unsatisfactory results. A different, but popular approach for non-linear dimensionality reduction, which can be considered as an alternative to our method, is to construct a reduced basis with PCA. Using the mean surface with four eigenvectors yields a similar reduction to our method in terms of memory footprint. We additionally re-project the different reference surfaces into the reduced basis to improve the reconstruction quality of the PCA version. The result is a very smooth surface that fails to capture any details of the behavior of the parameter space, as can be seen in the second column of Fig. 10.\nThe middle column of this figure shows the surfaces obtained with the learned deformation weights with our parameter NN (Fig. 5 top), but without an additional NN deformation network. As this case is based on end-point deformations, it cannot adapt to larger changes of surface structure in the middle of the domain. In contrast, using our full pipeline with an NN deformation yields surfaces that adapt to the varying behavior in the interior of the parameter space, as shown on the right side of Fig. 10. However, it is also apparent that the deformations generated by the NN do not capture every detail of the references. Our reduced representation in this case is regularized by the varying reference surfaces in small neighborhoods of \u03b1, and it learns an averaged behavior from the inputs.\nDiscussion It is worth noting that using the end-point deformations only, we would have to store many additional deformations in order to accurately resolve the complex behavior for intermediate simulation parameters. This problem even gets worse when the dimensionality of the simulation parameters is increased, as we would require a dense web of deformations covering the whole parameter domain in this case. We circumvent this problem with our generative approach, which is based on the assumption that an approximate flow behavior is already present in the initial surface \u03c80 and the deformed version \u03c8\u0303. Based on this approximation, the network only has to learn how to deform the intermediate surfaces so that they match the references throughout the whole parameter domain. We have demonstrated that in two-dimensions, our method is able learn a very compact representation of the liquid surface \u0393(\u03b1)\nthat allows the generation of very good approximations. For this reason, we see our method as a specialized technique to perform non-linear-dimensionality reduction on the space of liquid surfaces \u0393(\u03b1)."}, {"heading": "5 Long-range Deformations", "text": "Our neural network can successfully refine the deformations based on an initial set of pre-computed deformations along the sides of the parameter space. Therefore, any improvement for these initial deformations typically also translates into improvements of quality for the output of our neural network. For this reason, we will propose an additional step that targets long-range correspondences, before discussing more complex four-dimensional results.\nWhen computing the end-point deformations we have two closely related goals: to accurately match the target, and to establish correct correspondences between source and target. The algorithm we use (optical flow), and many others such as the iterative closest point methods, work by matching closest distances. For inputs with significant differences, a deterioration of both desired qualities goes hand in hand: parts of the target shape can get lost, and the likelihood of reconstructing a target feature from an arbitrary different source feature increases. We make the following observation: high similarity between inputs improves matching quality and correspondences, and this similarity is not proportional to distances in simulation parameter space. I.e., two inputs A and B with a distance d in \u03b1 can be more similar than A and a third point C with a distance less than d. This is a result of the high non-linearity of the input simulations. This effect is visible in Fig. 3, where the first image is closer to the third one on the right, while it is closer to the second one in parameter space.\nTherefore, given the problem to compute a deformation from source surface at simulation parameter \u03b1a to a surface at \u03b1b, we subdivide this interval by inserting additional data points. We can, e.g., use linear interpolation on the simulation parameters, and generate additional four-dimensional surfaces as data points along the line. In the following, we will denote the subdivisions of the in-\nterval [\u03b1a,\u03b1b] with a0, a1, a2, ...al\u22121, al, where a0 = a, al = b, and deformations for a section of this interval with uai,aj (with i, j \u2208 [0..l]). We typically use a fixed spacing for the additional parameter samples ai, but our method is not restricted to a regular sampling of the [a,b]-interval. To shorten the notation, we will drop \u03b1 in the following section for subscripts, i.e., instead of \u03c6\u03b1i, we will use \u03c6i. Thus, the deformations with double indices cover a partial distance of a single dimension of our parameter space, in contrast to the final endpoint deformations, e.g., uj , which cover the full extent of a single dimension j of the parameter space. In order to reach the target state \u03c6b we want to minimize the error between the final surface \u03c8 (computed by deforming \u03c6\u03b1a ) and the target, i.e. e(\u03c8, \u03c6\u03b1b), where e(\u00b7, \u00b7) computes the error between the two surfaces. In the following we use the indicator function from FlOF for e [Thuerey 2017], but an L2 norm of the SDF values with tanh, as for our neural networks, is likewise applicable.\nIn contrast to previous work [Raveendran et al. 2014; Thuerey 2017], we compute a single end-point deformation deformation to retrieve \u03c6\u0303a with a merged sequence of carefully selected deformations ul0,l1 ,ul1,l2 , ...,ule\u22121,le that minimizes the accumulated error. Each step in the deformation sequence potentially introduces an error that is propagated towards the target. This error is not propagated additively when applying several deformations in a row. However, the additive accumulation of errors represents a practical lower bound. Consider an example deformation from interval position i to k via an intermediate point j. For a surface \u03a6 deformed by two deformations as \u03a6 = \u03c6i(x\u2212uj,k(x)\u2212ui,j(x\u2212uj,k(x))) the error bound is given by\ne(\u03a6, \u03c6k) > e(\u03c6i(x\u2212 ui,j(x)), \u03c6j) + e(\u03c6j(x\u2212 uj,k(x)), \u03c6k). (20)\nThe reason is that ui,j will typically introduce imperfections, and \u03c6i(x \u2212 ui,j(x)) will be a worse starting point for uj,k than \u03c6j . Thus, we minimize the accumulated errors along a sequence of discrete pairs S = {(i0, j0), (i1, j1), ..., (inS , jnS )}, each with an associated error value, and with i0 = a, jnS = b. We calculate the total error for the sequence ES with the error metric e as\nES = \u2211\n(ik,jk)\u2208S\ne(\u03c6ik (x\u2212 uik,jk (x)), \u03c6jk ) . (21)\nMinimizing ES is a classic dynamic programming problem. We compute a dense directed graph G, where the associated cost for each edge is the deformation error of the corresponding deformation. Thus, given a sequence of surfaces \u03c60, \u03c61, ..., \u03c6l we compute deformations from every surface \u03c6i towards the next nj surfaces, adding the edge di,j with the cost from Eq. (21) to G. Theoretically, we could compute all possible deformations, but we found that nj \u2248 l/4 works well in practice. The optimal sequence S is\nthen computed by using Dijkstra\u2019s algorithm on G, and we compute the final deformation ua,b by concatenating the deformations of S with our alignment from Sec. 3.1 to yield a single end-point deformation for one dimension of the parameter space.\nExamples Fig. 11 shows an example deformation computed with this approach. In this example, the goal is to move a droplet with a distance of ca. 15 cells from the surface of a basin horizontally. We match a source surface (with the drop on the left) with a target where the drop is translated by various distances to the right. For targets with a distance larger than 15, a single regular deformation merges the drop into the basin, and re-creates the target droplet from the basin, instead of moving the droplet horizontally. While a single deformation fails at preserving the correspondences of the drop for distances of 20 and above (Fig. 11c,d), our algorithm can recover the whole translation of the droplet across the domain (Fig. 11e). While our method successfully establishes correspondences, the motion along the way is typically not linear, as can be seen in Fig. 11.\nThe error values from Eq. (21) for this test case are shown in Fig. 13. For this simple case, the error values change smoothly in the graph, and large distances consistently get worse. A diagonal high-error line at a distance of ca. 18 cells is clearly visible in the graph. This is the critical point where the source drop has a similar distance to the target drop as well as the basin. This typically causes the drop to break up when applying the deformation, leading to larger error measurements. Our algorithm detects the increased error, and for this case makes one large step towards this error barrier. Afterwards, it stays just below it to reach the target state. The initial position of the droplet is x = 25, and our algorithm finds the solution to combine deformations u25,39,u39,49,u49,59,u67,75 to reach the target at position x = 75.\nA second example using the dataset of Fig. 6 can be seen in Fig. 12. Here the source is shown on the left, and the target surface on the right. The single deformation, in line with previous work [Thuerey 2017], mostly restores the target shape, but erroneously merges both \u201darms\u201d into the single wave of the target. In contrast, our method reconstructs the wave using only the left arm of the source shape, and correctly merges the right arm into the surface of the basin. The full sequence can be seen in the accompanying video.\nNote that while this approach takes into account the in-between data to improve correspondences, the resulting deformations still can not re-construct any of the details in-between the end-points. We leave it to our neural network step to correct this behavior during deformation refinement."}, {"heading": "6 Mobile Device Implementation", "text": "The significant amount of pre-calculations to compute our reduced model pays off especially for interactive settings. To demonstrate the high performance our representation achieves, we have implemented a proof-of-concept application for mobile devices. Our application is divided into two parts: a main loop used for the surface generation and rendering, and a second loop which handles the user interaction, and calculates a final deformation for the main loop to display. Both loops are working with separated threads and are using double-buffering to provide the results.\nThe performance intensive tasks of our pipeline are computed with RenderScript, which is a framework which distributes tasks onto the CPU and GPU. The neural network instead will be computed on the CPU using the TensorFlow C++ library in conjunction with our custom 4D deconvolution. Here, we load a graph and a pre-trained set of weights computed during a pre-processing stage. Thus, our application only handles the evaluation of the network, but not the training. In order to guarantee temporal coherence, we temporally blend the SDFs when restarting the simulation or switching to a new deformation.\nAs we have a full implicit surface of the liquid, we implemented a three-state particle system, to model splashes, bubbles and foam floating on the surface [Ihmsen et al. 2012]. We approximate the fluid velocity using the gradients of the SDF. For bubbles and floating particles, we can again make use of the implicit representation to project them onto the liquid surface. The scene is rendered with a custom raytracer, that handles reflection, refraction, and shading with an environment map. We use depth-based attenuation to visualize the liquid volume, and we shade the surface based on curvature to highlight detail. Both depth and curvature can be easily\nretrieved from the implicit surfaces that our algorithm generates.\nOur second thread becomes active whenever the user interacts with the application. User input typically yields a selection of a point in our parameter space \u03b1. Based on this value, we first let the neural network calculate the adjusted parameters \u03b2. With these parameters, we calculate the aligned end-point deformations, and combine the resulting field with the deformation calculated by the neural network. While we typically perform two advection steps during our off-line implementation, we can use our alignment in this real-time setting to combine end-point deformation and neural network deformation into a single field. In this way, we only have to calculate a single advection step to extract the final, three-dimensional SDF surfaces from slices of the 4D buffers. Once the calculations are completed, the main loop swaps the active deformation buffer with the buffer of the newly generated one, and starts displaying the new configuration."}, {"heading": "7 Results", "text": "Below we will demonstrate results of our algorithm for full, threedimensional simulations. In the following, we will show that our network approach is effective at learning good approximations of the four-dimensional liquid surfaces and that we can render them very efficiently in real-time scenarios.\nLiquid Drop falling into a Basin As our first 4D test case, we chose a drop of liquid falling into a basin. As our simulation parameters we chose the x and y coordinates of the initial drop position, as well as the size of the drop. Due to non-linearity of splashes and wall interactions and due to the three-dimensional parameter space, this set of inputs has a wide variety of sheets and splashes. Examples are shown on the left of Fig. 1, and in our video. To generate the training data, we sample the parameter space on a regular grid, and run simulations, each with a spatial resolution of 1003 to generate a total of 1764 reference SDFs.\nAs a first test we want to demonstrate the effectiveness of the neural network deformation by showcasing it on its own. For this purpose, we conduct a test, were \u03c80 is simply a basin filled with liquid at rest. We retrieve the result directly by evaluating \u03c8(x) = \u03c80 (x\u2212w(x, \u03b1,\u0398)). This means we do not employ any end-point deformations for this test. As \u03c80 contains only a planar surface that is not moving, the neural network has to learn to represent all motions of the liquid. For this test we only consider the latter two-thirds in time, i.e. after the drop has merged with the basin. Fig. 14 shows several results from the space of solutions, after training for 10000 iterations. For all pairs, our network correctly approximates the large scale motion of the splashes. Considering the lack of features in \u03c80, this is a very good result, as there are\nno small scale details the network can shift in space and time to represent the targets.\nWe now explain the setup for our full pipeline with this drop setup. We start with the biggest possible drop falling into the upper right corner of the basin. We then span the parameter space with the three deformations u1, u2 and u3. The first two parameters are the x- and y-coordinates of the drop. The third parameter stands for the size of the drop.\nThe still frame of Fig. 15 illustrates the gain in quality we can achieve with our neural network deformation. Also note the increase in small scale detail we achieve in comparison to the flat surface test above. Several other examples from the whole space of solutions can be found in the video. This direct comparison illustrates that our network successfully learns to accurately correct the complex space-time surface of our inputs.\nWe run the trained model for this setup in our mobile application to demonstrate the high performance of our approach. In this application the user can interact by tapping on the screen to select the drop position. Fig. 16 depicts a capture of our android application. In Table 1 we have listed the runtimes and framerates of our mobile application. The deformation calculation step is the most time consuming one; e.g. 440ms using deformations of size 204. Here, our implementation does not yet use the GPU for computing the deconvolutions. However, this calculation of deformations is hidden from the user with our double buffering setup. Once the deformation is calculated, rendering is the most expensive task with 65ms on average.\nNote that the original simulation for this setup (to generate a single input) took 530 seconds on average with a parallel implementation using all cores of a desktop workstation. Assuming a best-case slowdown of only 4x for the mobile device, it would require more\nthan 30 minutes to run the original simulation. Reducing the spatial and temporal resolution would result in faster runtimes, but also in a correspondingly reduced quality. Thus, our reduced model generates detailed outputs highly efficiently, with only very moderate computational resources.\nIn addition, popular approaches such as particle based liquid simulations would require additional time and implementation complexity to generate a renderable surface from the particle cloud. Our choice to work with implicit surface data directly yields a 3D dataset that can be visualized with ray-marching.\nOur approach very efficiently represents a region of complex behavior with a strongly reduced representation. This becomes obvious when comparing our method with a direct interpolation of SDF data-sets. Our algorithms requires a single full-resolution SDF, three half resolution deformations, and the neural network (which is negligible in practice). While a single 404 SDF requires ca. 2.5 mio. scalar values, all deformations and network weights require ca. 2 mio. scalars. Thus our representation encodes the full behavior with less storage than two full SDFs. To illustrate this point, we show the result of a direct SDF interpolation in Fig. 17. Here we sample the paramter space with 8 SDFs in total (at all corners of the 3D parameter space). Hence, this version requires more than 4x the storage our approach requires. Despite the additional memory, direct SDF interpolations lead to very obvious, and undesirable artifacts. The result shown in the lower row of Fig. 17 neither represents the initial drop, nor the resulting splash. Rather, it leads to strong ghosting artifacts, and an overall loss of detail.\nLiquid flowing over Stairs Our second test setup illustrates a different parameter space that captures a variety of obstacle boundary conditions with \u03b1. Our first two simulation parameters are the heights of two stair-like steps, while the third parameter is control-\nling the position of a middle divider obstacle. The liquid flows in a U-shaped manner around the divider, down the stairs. For this setup, we used a slightly higher overall resolution for both spacetime SDFs, as well as for the output of the network, details can be found in Table 1.\nFig. 18 depicts still frames captured from our mobile application for this setup. With this setup the user can adjust stair heights and wall width dynamically while deformations are computed in the background. While this setup has more temporal coherence in its motion than the drop setup, the changing obstacle boundary conditions lead to strongly differing streams of liquid down the stairs. E.g., changing the position of the divider changes the flow from a narrow, fast stream to a slow, broad front.\nPlease note that the mobile application is part of our submission materials, and we encourage readers to try out our method. Unfortunately, we only support Android at the moment.\nDiscussion and Limitations Our formulation is centered around our loss function which can evaluate network outputs according to the resulting difference to a reference it produces. Using this loss function we were able to combine prescribed deformations such that they generate optimal results across the whole parameter range. Our generative neural network can then capture additional non-linear interactions that the end-point deformations missed.\nWhile we have demonstrated the effectiveness of this approach, it is apparent that the deformations generated by our algorithm can\nintroduce spatial and temporal discontinuities. This is noticeable when deforming the flat surface in Fig. 14. We believe it is important to show these artifacts, as this is how the unmodified output of our neural network behaves. However, as we use an Eulerian representation for the deformations, it would be relatively straight forward to smoothen the deformation, or, even better, to introduce a regularization term in the loss function. However, we believe that in its current form we have demonstrated that the trained networks have learned to deform the surfaces towards the desired targets, as demonstrated, e.g., in Fig. 15.\nCurrently, our training steps also require a large amount of input data. While we believe this is necessary to some extent to specifiy the target space, we have experimented with using only a smaller, randomly chosen subset of samples for training. Our tests indicate that it is possible to achieve similarly good results with data-set reduced by a factor of two to four in comparison to our full, densely sampled training sets.\nRight now our pipeline is not physics-aware, as it purely considers space-time surfaces, and neglects potential constraints from the governing equations of the physical systems (e.g., conservation of mass). While previous work shares this limitation [Raveendran et al. 2014; Thuerey 2017], this property also makes these methods more general, as no assumptions need to be made about the inputs. However, it is clearly an interesting topic for future work to incorporate physics constraints.\nAdditionally, our approach is only applicable in settings where inputs can be grouped around a reasonably representative initial surface \u03c80. We have demonstrated that we can achieve a significant amount of variance with our examples above. For future extensions, we believe it will be very interesting to automate the process of finding good sub-spaces where our method is applicable from even larger spaces of liquid behavior."}, {"heading": "8 Conclusions", "text": "We have presented a novel method to pre-compute a complex liquid space with deformation-aware neural networks. Due to the cho-\nsen representation, our approach allows for real-time interactions with complex liquid effects. To the best of our knowledge, we are also the first to introduce a machine-learning approach that actively learns to deform surfaces.\nWe believe that it is exciting to see how such generative neural networks can be successfully applied to problems in the context of fluid simulations. In the future, it will be interesting to simulate other types of phenomena with our synthesis pipeline, and we plan to investigate how our deformation-aware networks perform for optical flow-like problems outside of the area of fluid simulations."}, {"heading": "DOSOVITSKIY, A., FISCHERY, P., ILG, E., HAZIRBAS, C., GOLKOV, V., VAN DER", "text": "SMAGT, P., CREMERS, D., BROX, T., ET AL. 2015. Flownet: Learning optical flow with convolutional networks. In International Conference on Computer Vision (ICCV), IEEE, 2758\u20132766.\nENRIGHT, D., NGUYEN, D., GIBOU, F., AND FEDKIW, R. 2003. Using the Particle Level Set Method and a Second Order Accurate Pressure Boundary Condition for Free-Surface Flows. Proc. of the 4th ASME-JSME Joint Fluids Engineering Conference.\nGIRSHICK, R., DONAHUE, J., DARRELL, T., AND MALIK, J. 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proc. Conference on Computer Vision and Pattern Recognition, IEEE, 580\u2013587.\nGOODFELLOW, I. J., POUGET-ABADIE, J., MIRZA, M., XU, B., WARDE-FARLEY, D., OZAIR, S., COURVILLE, A., AND BENGIO, Y. 2014. Generative adversarial nets. stat 1050, 10.\nGUPTA, M., AND NARASIMHAN, S. G. 2007. Legendre fluids: a unified framework for analytic reduced space modeling and rendering of participating media. In Proc. Symposium on Computer Animation, ACM/Eurographics, 17\u201325.\nIHMSEN, M., AKINCI, N., AKINCI, G., AND TESCHNER, M. 2012. Unified spray, foam and air bubbles for particle-based fluids. The Visual Computer 28, 6-8, 669\u2013 677."}, {"heading": "IHMSEN, M., ORTHMANN, J., SOLENTHALER, B., KOLB, A., AND TESCHNER, M.", "text": "2014. SPH fluids in computer graphics. In State of the Art Reports, Eurographics, 21\u201342.\nIIZUKA, S., SIMO-SERRA, E., AND ISHIKAWA, H. 2016. Let there be color!: joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification. ACM Transactions on Graphics (TOG) 35, 4, 110."}, {"heading": "ILG, E., MAYER, N., SAIKIA, T., KEUPER, M., DOSOVITSKIY, A., AND BROX, T.", "text": "2016. Flownet 2.0: Evolution of optical flow estimation with deep networks. arXiv preprint: 1612.01925.\nJAMES, D. L., AND FATAHALIAN, K. 2003. Precomputing interactive dynamic deformable scenes. Proc. SIGGRAPH 22, 3.\nJAMES, D. L., BARBIC\u030c, J., AND PAI, D. K. 2006. Precomputed acoustic transfer: output-sensitive, accurate sound generation for geometrically complex vibration sources. ACM Transactions on Graphics (TOG) 25, 3, 987\u2013995.\nJONES, A. D., SEN, P., AND KIM, T. 2016. Compressing fluid subspaces. In Proc. Symposium on Computer Animation, ACM/Eurographics, 77\u201384.\nKASS, M., AND MILLER, G. 1990. Rapid, Stable Fluid Dynamics for Computer Graphics. ACM Trans. Graph. 24, 4, 49\u201355.\nKIM, T., AND DELANEY, J. 2013. Subspace fluid re-simulation. ACM Trans. Graph. 32, 4 (July), 62:1\u201362:9.\nKIM, T., AND JAMES, D. L. 2012. Physics-based character skinning using multidomain subspace deformations. IEEE transactions on visualization and computer graphics 18, 8, 1228\u20131240."}, {"heading": "KIM, D., KOH, W., NARAIN, R., FATAHALIAN, K., TREUILLE, A., AND O\u2019BRIEN,", "text": "J. F. 2013. Near-exhaustive precomputation of secondary cloth effects. ACM Transactions on Graphics (TOG) 32, 4, 87.\nKRIZHEVSKY, A., SUTSKEVER, I., AND HINTON, G. E. 2012. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, NIPS, 1097\u20131105."}, {"heading": "LADICKY, L., JEONG, S., SOLENTHALER, B., POLLEFEYS, M., AND GROSS, M.", "text": "2015. Data-driven fluid simulations using regression forests. ACM Transactions on Graphics (TOG) 34, 6, 199.\nMACKLIN, M., AND MU\u0308LLER, M. 2013. Position based fluids. ACM Transactions on Graphics (TOG) 32, 4, 104.\nMACKLIN, M., MU\u0308LLER, M., CHENTANEZ, N., AND KIM, T.-Y. 2014. Unified particle physics for real-time applications. ACM Transactions on Graphics (TOG) 33, 4, 153."}, {"heading": "MANTEAUX, P.-L., SUN, W.-L., FAURE, F., CANI, M.-P., AND O\u2019BRIEN, J. F.", "text": "2015. Interactive detailed cutting of thin sheets. In Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games, ACM, 125\u2013132.\nMCNAMARA, A., TREUILLE, A., POPOVIC\u0301, Z., AND STAM, J. 2004. Fluid Control Using the Adjoint Method. ACM Trans. Graph. 23, 3, 449\u2013456.\nPENTLAND, A., AND WILLIAMS, J. 1989. Good vibrations: Modal dynamics for graphics and animation. Proc. SIGGRAPH 23, 3.\nPRANTL, L., BONEV, B., AND THUEREY, N., 2017. Neural Liquid Drop. https://play.google.com/store/apps/details?id=fluidsim.de.interactivedrop.\nRANJAN, A., AND BLACK, M. J. 2016. Optical flow estimation using a spatial pyramid network. CoRR abs/1611.00850.\nRAVEENDRAN, K., THUEREY, N., WOJTAN, C., AND TURK, G. 2014. Blending Liquids. ACM Trans. Graph. 33 (4) (August), 10.\nRUMELHART, D. E., HINTON, G. E., AND WILLIAMS, R. J. 1988. Learning representations by back-propagating errors. Cognitive modeling 5, 3, 1.\nSANGKLOY, P., BURNELL, N., HAM, C., AND HAYS, J. 2016. The sketchy database: learning to retrieve badly drawn bunnies. ACM Transactions on Graphics (TOG) 35, 4, 119.\nSOLENTHALER, B., AND PAJAROLA, R. 2009. Predictive-corrective incompressible sph. ACM transactions on graphics (TOG) 28, 3, 40."}, {"heading": "SOLOMON, J., DE GOES, F., PEYRE\u0301, G., CUTURI, M., BUTSCHER, A., NGUYEN,", "text": "A., DU, T., AND GUIBAS, L. 2015. Convolutional wasserstein distances: Efficient optimal transportation on geometric domains. ACM Transactions on Graphics (TOG) 34, 4, 66.\nSTAM, J. 1999. Stable Fluids. In Proc. ACM SIGGRAPH, ACM, 121\u2013128."}, {"heading": "STANTON, M., HUMBERSTON, B., KASE, B., O\u2019BRIEN, J., FATAHALIAN, K., AND", "text": "TREUILLE, A. 2014. Self-refining games using player analytics. ACM Trans. Graph. 33 (4), 9.\nSTAVA, O., BENES\u030c, B., BRISBIN, M., AND KR\u030cIVA\u0301NEK, J. 2008. Interactive terrain modeling using hydraulic erosion. In Proc. Symposium on Computer Animation, ACM/Eurographics, 201\u2013210.\nTENG, Y., MEYER, M., DEROSE, T., AND KIM, T. 2015. Subspace condensation: full space adaptivity for subspace deformations. ACM Transactions on Graphics 34, 4, 76.\nTENG, Y., LEVIN, D. I., AND KIM, T. 2016. Eulerian solid-fluid coupling. ACM Transactions on Graphics 35, 6, 200.\nTHUEREY, N. 2017. Interpolations of Smoke and Liquid Simulations. Transactions on Graphics 36(1) (July), 15.\nTOMPSON, J., SCHLACHTER, K., SPRECHMANN, P., AND PERLIN, K. 2016. Accelerating eulerian fluid simulation with convolutional networks. arXiv preprint: 1607.03597.\nTREUILLE, A., LEWIS, A., AND POPOVIC\u0301, Z. 2006. Model reduction for real-time fluids. ACM Trans. Graph. 25, 3 (July), 826\u2013834.\nUM, K., HU, X., AND THUEREY, N. 2017. Splash modeling with neural networks. arXiv preprint.\nWANG, H., MILLER, G., AND TURK, G. 2007. Solving general shallow wave equations on surfaces. In Proc. Symposium on Computer Animation, ACM/Eurographics, 229\u2013238.\nWEI, L., HUANG, Q., CEYLAN, D., VOUGA, E., AND LI, H. 2015. Dense human body correspondences using convolutional networks. arXiv preprint: 1511.05904.\nWERBOS, P. J. 1974. Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences. PhD thesis, Harvard University. Department of Applied Mathematics.\nWICKE, M., STANTON, M., AND TREUILLE, A. 2009. Modular bases for fluid dynamics. ACM Trans. on Graphics 28, 3 (Aug.), 39.\nXU, H., AND BARBIC\u030c, J. 2016. Pose-space subspace dynamics. ACM Transactions on Graphics (TOG) 35, 4, 35.\nYANG, C., YANG, X., AND XIAO, X. 2016. Data-driven projection method in fluid simulation. Computer Animation and Virtual Worlds 27, 3-4, 415\u2013424.\nZHU, Y., AND BRIDSON, R. 2005. Animating Sand as a Fluid. ACM Trans. Graph. 24, 3, 965\u2013972."}], "references": [{"title": "Cnn-based patch matching for optical flow with thresholded hinge loss", "author": ["C. BAILER", "K. VARANASI", "D. STRICKER"], "venue": "arXiv preprint:", "citeRegEx": "BAILER et al\\.,? \\Q2016\\E", "shortCiteRegEx": "BAILER et al\\.", "year": 2016}, {"title": "Real-time subspace integration for st. venantkirchhoff deformable models", "author": ["J. BARBI\u010c", "D.L. JAMES"], "venue": "ACM transactions on graphics (TOG) 24,", "citeRegEx": "BARBI\u010c and JAMES,? \\Q2005\\E", "shortCiteRegEx": "BARBI\u010c and JAMES", "year": 2005}, {"title": "Learning visual similarity for product design with convolutional neural networks", "author": ["S. BELL", "K. BALA"], "venue": "ACM Transactions on Graphics (TOG) 34,", "citeRegEx": "BELL and BALA,? \\Q2015\\E", "shortCiteRegEx": "BELL and BALA", "year": 2015}, {"title": "Pattern Recognition and Machine Learning (Information Science and Statistics)", "author": ["C.M. BISHOP"], "venue": null, "citeRegEx": "BISHOP,? \\Q2006\\E", "shortCiteRegEx": "BISHOP", "year": 2006}, {"title": "Real-time eulerian water simulation using a restricted tall cell", "author": ["N. CHENTANEZ", "M. M\u00dcLLER"], "venue": "grid. ACM Transactions on Graphics (TOG) 30,", "citeRegEx": "CHENTANEZ and M\u00dcLLER,? \\Q2011\\E", "shortCiteRegEx": "CHENTANEZ and M\u00dcLLER", "year": 2011}, {"title": "Fast gridfree surface tracking", "author": ["N. CHENTANEZ", "M. M\u00dcLLER", "M. MACKLIN", "KIM", "T.-Y"], "venue": "ACM Transactions on Graphics (TOG) 34,", "citeRegEx": "CHENTANEZ et al\\.,? \\Q2015\\E", "shortCiteRegEx": "CHENTANEZ et al\\.", "year": 2015}, {"title": "Data-driven synthesis of smoke flows with CNNbased feature descriptors", "author": ["M. CHU", "N. THUEREY"], "venue": "ACM Transaction on Graphics", "citeRegEx": "CHU and THUEREY,? \\Q2017\\E", "shortCiteRegEx": "CHU and THUEREY", "year": 2017}, {"title": "Fluid simulation using laplacian eigenfunctions", "author": ["T. DE WITT", "C. LESSIG", "E. FIUME"], "venue": "ACM Transactions on Graphics (TOG) 31,", "citeRegEx": "WITT et al\\.,? \\Q2012\\E", "shortCiteRegEx": "WITT et al\\.", "year": 2012}, {"title": "Flownet: Learning optical flow with convolutional networks", "author": ["A. DOSOVITSKIY", "P. FISCHERY", "E. ILG", "C. HAZIRBAS", "V. GOLKOV", "P. VAN DER SMAGT", "D. CREMERS", "T BROX"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "DOSOVITSKIY et al\\.,? \\Q2015\\E", "shortCiteRegEx": "DOSOVITSKIY et al\\.", "year": 2015}, {"title": "Using the Particle Level Set Method and a Second Order Accurate Pressure Boundary Condition for Free-Surface Flows", "author": ["D. ENRIGHT", "D. NGUYEN", "F. GIBOU", "R. FEDKIW"], "venue": "Proc. of the 4th ASME-JSME Joint Fluids Engineering Conference", "citeRegEx": "ENRIGHT et al\\.,? \\Q2003\\E", "shortCiteRegEx": "ENRIGHT et al\\.", "year": 2003}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. GIRSHICK", "J. DONAHUE", "T. DARRELL", "J. MALIK"], "venue": "In Proc. Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "GIRSHICK et al\\.,? \\Q2014\\E", "shortCiteRegEx": "GIRSHICK et al\\.", "year": 2014}, {"title": "Legendre fluids: a unified framework for analytic reduced space modeling and rendering of participating media", "author": ["M. GUPTA", "S.G. NARASIMHAN"], "venue": "In Proc. Symposium on Computer Animation,", "citeRegEx": "GUPTA and NARASIMHAN,? \\Q2007\\E", "shortCiteRegEx": "GUPTA and NARASIMHAN", "year": 2007}, {"title": "Unified spray, foam and air bubbles for particle-based fluids", "author": ["M. IHMSEN", "N. AKINCI", "G. AKINCI", "M. TESCHNER"], "venue": "The Visual Computer", "citeRegEx": "IHMSEN et al\\.,? \\Q2012\\E", "shortCiteRegEx": "IHMSEN et al\\.", "year": 2012}, {"title": "SPH fluids in computer graphics", "author": ["M. IHMSEN", "J. ORTHMANN", "B. SOLENTHALER", "A. KOLB", "M. TESCHNER"], "venue": "In State of the Art Reports,", "citeRegEx": "IHMSEN et al\\.,? \\Q2014\\E", "shortCiteRegEx": "IHMSEN et al\\.", "year": 2014}, {"title": "Let there be color!: joint end-to-end learning of global and local image priors for automatic image colorization with simultaneous classification", "author": ["S. IIZUKA", "E. SIMO-SERRA", "H. ISHIKAWA"], "venue": "ACM Transactions on Graphics (TOG)", "citeRegEx": "IIZUKA et al\\.,? \\Q2016\\E", "shortCiteRegEx": "IIZUKA et al\\.", "year": 2016}, {"title": "Flownet 2.0: Evolution of optical flow estimation with deep networks. arXiv preprint: 1612.01925", "author": ["E. ILG", "N. MAYER", "T. SAIKIA", "M. KEUPER", "A. DOSOVITSKIY", "T. BROX"], "venue": null, "citeRegEx": "ILG et al\\.,? \\Q2016\\E", "shortCiteRegEx": "ILG et al\\.", "year": 2016}, {"title": "Precomputing interactive dynamic deformable scenes", "author": ["D.L. JAMES", "K. FATAHALIAN"], "venue": "Proc. SIGGRAPH 22,", "citeRegEx": "JAMES and FATAHALIAN,? \\Q2003\\E", "shortCiteRegEx": "JAMES and FATAHALIAN", "year": 2003}, {"title": "Precomputed acoustic transfer: output-sensitive, accurate sound generation for geometrically complex vibration sources", "author": ["D.L. JAMES", "J. BARBI\u010c", "PAI", "D. K"], "venue": "ACM Transactions on Graphics (TOG)", "citeRegEx": "JAMES et al\\.,? \\Q2006\\E", "shortCiteRegEx": "JAMES et al\\.", "year": 2006}, {"title": "Compressing fluid subspaces", "author": ["JONES A. D", "SEN P", "KIM"], "venue": "In Proc. Symposium on Computer Animation,", "citeRegEx": "D. et al\\.,? \\Q2016\\E", "shortCiteRegEx": "D. et al\\.", "year": 2016}, {"title": "Rapid, Stable Fluid Dynamics for Computer Graphics", "author": ["M. KASS", "G. MILLER"], "venue": "ACM Trans. Graph", "citeRegEx": "KASS and MILLER,? \\Q1990\\E", "shortCiteRegEx": "KASS and MILLER", "year": 1990}, {"title": "Subspace fluid re-simulation", "author": ["T. KIM", "J. DELANEY"], "venue": "ACM Trans. Graph. 32,", "citeRegEx": "KIM and DELANEY,? \\Q2013\\E", "shortCiteRegEx": "KIM and DELANEY", "year": 2013}, {"title": "Physics-based character skinning using multidomain subspace deformations", "author": ["T. KIM", "D.L. JAMES"], "venue": "IEEE transactions on visualization and computer graphics 18,", "citeRegEx": "KIM and JAMES,? \\Q2012\\E", "shortCiteRegEx": "KIM and JAMES", "year": 2012}, {"title": "Near-exhaustive precomputation of secondary cloth effects", "author": ["D. KIM", "W. KOH", "R. NARAIN", "K. FATAHALIAN", "A. TREUILLE", "J.F. O\u2019BRIEN"], "venue": "ACM Transactions on Graphics (TOG) 32,", "citeRegEx": "KIM et al\\.,? \\Q2013\\E", "shortCiteRegEx": "KIM et al\\.", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. KRIZHEVSKY", "I. SUTSKEVER", "G.E. HINTON"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "KRIZHEVSKY et al\\.,? \\Q2012\\E", "shortCiteRegEx": "KRIZHEVSKY et al\\.", "year": 2012}, {"title": "Data-driven fluid simulations using regression forests", "author": ["L. LADICKY", "S. JEONG", "B. SOLENTHALER", "M. POLLEFEYS", "M. GROSS"], "venue": "ACM Transactions on Graphics (TOG) 34,", "citeRegEx": "LADICKY et al\\.,? \\Q2015\\E", "shortCiteRegEx": "LADICKY et al\\.", "year": 2015}, {"title": "Position based fluids", "author": ["M. MACKLIN", "M. M\u00dcLLER"], "venue": "ACM Transactions on Graphics (TOG) 32,", "citeRegEx": "MACKLIN and M\u00dcLLER,? \\Q2013\\E", "shortCiteRegEx": "MACKLIN and M\u00dcLLER", "year": 2013}, {"title": "Unified particle physics for real-time applications", "author": ["M. MACKLIN", "M. M\u00dcLLER", "N. CHENTANEZ", "KIM", "T.-Y"], "venue": "ACM Transactions on Graphics (TOG) 33,", "citeRegEx": "MACKLIN et al\\.,? \\Q2014\\E", "shortCiteRegEx": "MACKLIN et al\\.", "year": 2014}, {"title": "Interactive detailed cutting of thin sheets", "author": ["MANTEAUX", "SUN P.-L", "W.-L", "F. FAURE", "CANI", "M.-P", "J.F. O\u2019BRIEN"], "venue": "In Proceedings of the 8th ACM SIGGRAPH Conference on Motion in Games,", "citeRegEx": "MANTEAUX et al\\.,? \\Q2015\\E", "shortCiteRegEx": "MANTEAUX et al\\.", "year": 2015}, {"title": "Fluid Control Using the Adjoint Method", "author": ["A. MCNAMARA", "A. TREUILLE", "Z. POPOVI\u0106", "J. STAM"], "venue": "ACM Trans. Graph", "citeRegEx": "MCNAMARA et al\\.,? \\Q2004\\E", "shortCiteRegEx": "MCNAMARA et al\\.", "year": 2004}, {"title": "Good vibrations: Modal dynamics for graphics and animation", "author": ["A. PENTLAND", "J. WILLIAMS"], "venue": "Proc. SIGGRAPH 23,", "citeRegEx": "PENTLAND and WILLIAMS,? \\Q1989\\E", "shortCiteRegEx": "PENTLAND and WILLIAMS", "year": 1989}, {"title": "Neural Liquid Drop. https://play.google.com/store/apps/details?id=fluidsim.de.interactivedrop", "author": ["L. PRANTL", "B. BONEV", "N. THUEREY"], "venue": null, "citeRegEx": "PRANTL et al\\.,? \\Q2017\\E", "shortCiteRegEx": "PRANTL et al\\.", "year": 2017}, {"title": "Optical flow estimation using a spatial pyramid network. CoRR abs/1611.00850", "author": ["A. RANJAN", "M.J. BLACK"], "venue": null, "citeRegEx": "RANJAN and BLACK,? \\Q2016\\E", "shortCiteRegEx": "RANJAN and BLACK", "year": 2016}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. RUMELHART", "G.E. HINTON", "R.J. WILLIAMS"], "venue": "Cognitive modeling 5,", "citeRegEx": "RUMELHART et al\\.,? \\Q1988\\E", "shortCiteRegEx": "RUMELHART et al\\.", "year": 1988}, {"title": "The sketchy database: learning to retrieve badly drawn bunnies", "author": ["P. SANGKLOY", "N. BURNELL", "C. HAM", "J. HAYS"], "venue": "ACM Transactions on Graphics (TOG) 35,", "citeRegEx": "SANGKLOY et al\\.,? \\Q2016\\E", "shortCiteRegEx": "SANGKLOY et al\\.", "year": 2016}, {"title": "Predictive-corrective incompressible sph", "author": ["B. SOLENTHALER", "R. PAJAROLA"], "venue": "ACM transactions on graphics (TOG) 28,", "citeRegEx": "SOLENTHALER and PAJAROLA,? \\Q2009\\E", "shortCiteRegEx": "SOLENTHALER and PAJAROLA", "year": 2009}, {"title": "Convolutional wasserstein distances: Efficient optimal transportation on geometric domains", "author": ["J. SOLOMON", "F. DE GOES", "G. PEYR\u00c9", "M. CUTURI", "A. BUTSCHER", "A. NGUYEN", "T. DU", "L. GUIBAS"], "venue": "ACM Transactions on Graphics (TOG) 34,", "citeRegEx": "SOLOMON et al\\.,? \\Q2015\\E", "shortCiteRegEx": "SOLOMON et al\\.", "year": 2015}, {"title": "Stable Fluids", "author": ["J. STAM"], "venue": "In Proc. ACM SIGGRAPH,", "citeRegEx": "STAM,? \\Q1999\\E", "shortCiteRegEx": "STAM", "year": 1999}, {"title": "Self-refining games using player analytics", "author": ["M. STANTON", "B. HUMBERSTON", "B. KASE", "J. O\u2019BRIEN", "K. FATAHALIAN", "A. TREUILLE"], "venue": "ACM Trans. Graph", "citeRegEx": "STANTON et al\\.,? \\Q2014\\E", "shortCiteRegEx": "STANTON et al\\.", "year": 2014}, {"title": "Interactive terrain modeling using hydraulic erosion", "author": ["O. STAVA", "B. BENE\u0160", "M. BRISBIN", "J. K\u0158IV\u00c1NEK"], "venue": "In Proc. Symposium on Computer Animation,", "citeRegEx": "STAVA et al\\.,? \\Q2008\\E", "shortCiteRegEx": "STAVA et al\\.", "year": 2008}, {"title": "Subspace condensation: full space adaptivity for subspace deformations", "author": ["Y. TENG", "M. MEYER", "T. DEROSE", "KIM"], "venue": "ACM Transactions on Graphics", "citeRegEx": "TENG et al\\.,? \\Q2015\\E", "shortCiteRegEx": "TENG et al\\.", "year": 2015}, {"title": "Eulerian solid-fluid coupling", "author": ["Y. TENG", "D.I. LEVIN", "KIM"], "venue": "ACM Transactions on Graphics 35,", "citeRegEx": "TENG et al\\.,? \\Q2016\\E", "shortCiteRegEx": "TENG et al\\.", "year": 2016}, {"title": "Interpolations of Smoke and Liquid Simulations", "author": ["N. THUEREY"], "venue": "Transactions on Graphics", "citeRegEx": "THUEREY,? \\Q2017\\E", "shortCiteRegEx": "THUEREY", "year": 2017}, {"title": "Accelerating eulerian fluid simulation with convolutional networks", "author": ["J. TOMPSON", "K. SCHLACHTER", "P. SPRECHMANN", "K. PERLIN"], "venue": "arXiv preprint:", "citeRegEx": "TOMPSON et al\\.,? \\Q2016\\E", "shortCiteRegEx": "TOMPSON et al\\.", "year": 2016}, {"title": "Model reduction for real-time fluids", "author": ["A. TREUILLE", "A. LEWIS", "Z. POPOVI\u0106"], "venue": "ACM Trans. Graph", "citeRegEx": "TREUILLE et al\\.,? \\Q2006\\E", "shortCiteRegEx": "TREUILLE et al\\.", "year": 2006}, {"title": "Splash modeling with neural networks", "author": ["UM K", "HU X", "THUEREY N"], "venue": null, "citeRegEx": "K. et al\\.,? \\Q2017\\E", "shortCiteRegEx": "K. et al\\.", "year": 2017}, {"title": "Solving general shallow wave equations on surfaces", "author": ["H. WANG", "G. MILLER", "G. TURK"], "venue": "In Proc. Symposium on Computer Animation,", "citeRegEx": "WANG et al\\.,? \\Q2007\\E", "shortCiteRegEx": "WANG et al\\.", "year": 2007}, {"title": "Dense human body correspondences using convolutional networks. arXiv preprint: 1511.05904", "author": ["L. WEI", "Q. HUANG", "D. CEYLAN", "E. VOUGA", "LI"], "venue": null, "citeRegEx": "WEI et al\\.,? \\Q2015\\E", "shortCiteRegEx": "WEI et al\\.", "year": 2015}, {"title": "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences", "author": ["P.J. WERBOS"], "venue": "PhD thesis,", "citeRegEx": "WERBOS,? \\Q1974\\E", "shortCiteRegEx": "WERBOS", "year": 1974}, {"title": "Modular bases for fluid dynamics", "author": ["M. WICKE", "M. STANTON", "A. TREUILLE"], "venue": "ACM Trans. on Graphics 28,", "citeRegEx": "WICKE et al\\.,? \\Q2009\\E", "shortCiteRegEx": "WICKE et al\\.", "year": 2009}, {"title": "Pose-space subspace dynamics", "author": ["H. XU", "J. BARBI\u010c"], "venue": "ACM Transactions on Graphics (TOG) 35,", "citeRegEx": "XU and BARBI\u010c,? \\Q2016\\E", "shortCiteRegEx": "XU and BARBI\u010c", "year": 2016}, {"title": "Data-driven projection method in fluid simulation", "author": ["C. YANG", "X. YANG", "X. XIAO"], "venue": "Computer Animation and Virtual Worlds", "citeRegEx": "YANG et al\\.,? \\Q2016\\E", "shortCiteRegEx": "YANG et al\\.", "year": 2016}, {"title": "Animating Sand as a Fluid", "author": ["Y. ZHU", "R. BRIDSON"], "venue": "ACM Trans. Graph", "citeRegEx": "ZHU and BRIDSON,? \\Q2005\\E", "shortCiteRegEx": "ZHU and BRIDSON", "year": 2005}], "referenceMentions": [], "year": 2017, "abstractText": "Liquids exhibit highly complex, non-linear behavior under changing simulation conditions such as user interactions. We propose a method to map this complex behavior over a parameter range onto a reduced representation based on space-time deformations. In order to represent the complexity of the full space of inputs, we use aligned deformations from optical flow solves, and we leverage the power of generative neural networks to synthesize additional deformations for refinement. We introduce a novel deformation-aware loss function, which enables optimization in the highly non-linear space of multiple deformations. To demonstrate the effectiveness of our approach, we showcase the method with several complex examples in two and four dimensions. Our representation makes it possible to generate implicit surfaces of liquids very efficiently, which allows us to very efficiently display the scene from any angle, and to add secondary effects such as particle systems. We have implemented a mobile application with our full pipeline to demonstrate that real-time interaction is possible with our approach.", "creator": "LaTeX acmsiggraph.cls (11/2015)"}}}