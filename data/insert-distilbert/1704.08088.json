{"id": "1704.08088", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2017", "title": "Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts", "abstract": "schizophrenia mild cognitive impairment ( mci ) is a mental disorder deeply difficult to diagnose. linguistic features, mainly from parsers, have originally been used to detect mci, but this is not suitable for large - scale assessments. mci comparative disfluencies produce non - grammatical speech that requires manual or somewhat high precision automatic correction of transcripts. in this paper, we evaluated modeled transcripts into socially complex networks and enriched them with automatic word embedding ( cne ) to better represent short texts formerly produced in neuropsychological assessments. the key network measurements were applied with easily well - sampled known classifiers to automatically identify mci in nonsense transcripts, in a binary classification task. a comparison was made with the semantic performance of traditional approaches using bag of words ( bow ) and linguistic features allowed for three datasets : dementiabank in english, and cinderella and arizona - battery in portuguese. directly overall, cne provided higher morphological accuracy than using only complex binary networks, while support vector machine was superior efficiently to other classifiers. cne provided the highest accuracies for dementiabank and elderly cinderella, but bow was more typically efficient when for the arizona - battery genetic dataset probably owing to frustrating its short narratives. the approach using linguistic features yielded clearly higher comparative accuracy if the transcriptions of the cinderella dataset were manually revised. taken together, the results indicate that complex networks enriched with embedding is promising for detecting mci in large - scale dementia assessments", "histories": [["v1", "Wed, 26 Apr 2017 13:06:25 GMT  (2026kb,D)", "http://arxiv.org/abs/1704.08088v1", "Published in Annual Meeting of the Association for Computational Linguist 2017"]], "COMMENTS": "Published in Annual Meeting of the Association for Computational Linguist 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["leandro santos", "edilson anselmo corr\u00eaa j\u00fanior", "osvaldo oliveira jr", "diego amancio", "let\u00edcia mansur", "sandra alu\u00edsio"], "accepted": true, "id": "1704.08088"}, "pdf": {"name": "1704.08088.pdf", "metadata": {"source": "CRF", "title": "Enriching Complex Networks with Word Embeddings for Detecting Mild Cognitive Impairment from Speech Transcripts", "authors": ["Leandro B. dos Santos", "Edilson A. Corr\u00eaa Jr.", "Osvaldo N. Oliveira Jr.", "Diego R. Amancio", "Let\u0131\u0301cia L. Mansur", "Sandra M. Alu\u0131\u0301sio"], "emails": ["leandrobs@usp.br,", "edilsonacjr@usp.br,", "lamansur@usp.br,", "chu@ifsc.usp.br", "diego@icmc.usp.br", "sandra@icmc.usp.br"], "sections": [{"heading": null, "text": "Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose. Linguistic features, mainly from parsers, have been used to detect MCI, but this is not suitable for large-scale assessments. MCI disfluencies produce nongrammatical speech that requires manual or high precision automatic correction of transcripts. In this paper, we modeled transcripts into complex networks and enriched them with word embedding (CNE) to better represent short texts produced in neuropsychological assessments. The network measurements were applied with well-known classifiers to automatically identify MCI in transcripts, in a binary classification task. A comparison was made with the performance of traditional approaches using Bag of Words (BoW) and linguistic features for three datasets: DementiaBank in English, and Cinderella and Arizona-Battery in Portuguese. Overall, CNE provided higher accuracy than using only complex networks, while Support Vector Machine was superior to other classifiers. CNE provided the highest accuracies for DementiaBank and Cinderella, but BoW was more efficient for the Arizona-Battery dataset probably owing to its short narratives. The approach using linguistic features yielded higher accuracy if the transcriptions of the Cinderella dataset were manually revised. Taken together, the results indicate that complex networks enriched with embedding is promising for detecting MCI in large-scale assessments."}, {"heading": "1 Introduction", "text": "Mild Cognitive Impairment (MCI) can affect one or multiple cognitive domains (e.g. memory, language, visuospatial skills and executive functions), and may represent a pre-clinical stage of Alzheimer\u2019s disease (AD). The impairment that affects memory, referred to as amnestic MCI, is the most frequent, with the highest conversion rate for AD, at 15% per year versus 1 to 2% for the general population. Since dementias are chronic and progressive diseases, their early diagnosis ensures a greater chance of success to engage patients in non-pharmacological treatment strategies such as cognitive training, physical activity and socialization (Teixeira et al., 2012).\nLanguage is one of the most efficient information sources to assess cognitive functions. Changes in language usage are frequent in patients with dementia and are normally first recognized by the patients themselves or their family members. Therefore, the automatic analysis of discourse production is promising in diagnosing MCI at early stages, which may address potentially reversible factors (Muangpaisan et al., 2012). Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al., 2015), and data screening tests added to demographic information (Weakley et al., 2015). Discourse production (mainly narratives) is attractive because it allows the analysis of linguistic microstructures, including phonetic-phonological, morphosyntactic and semantic-lexical components, as well as semantic-pragmatic macrostructures.\nAutomated discourse analysis based on Natural Language Processing (NLP) resources and tools to diagnose dementias via machine learning methods has been used for English language (Lehr et al.,\nar X\niv :1\n70 4.\n08 08\n8v 1\n[ cs\n.C L\n] 2\n6 A\npr 2\n01 7\n2012; Jarrold et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Davy et al., 2016) and for Brazilian Portuguese (Alu\u0131\u0301sio et al., 2016). A variety of features are required for this analysis, including Part-of-Speech (PoS), syntactic complexity, lexical diversity and acoustic features. Producing robust tools to extract these features is extremely difficult because speech transcripts used in neuropsychological evaluations contain disfluencies (repetitions, revisions, paraphasias) and patient\u2019s comments about the task being evaluated. Another problem in using linguistic knowledge is the high dependence on manually created resources, such as hand-crafted linguistic rules and/or annotated corpora. Even when traditional statistical techniques (Bag of Words or ngrams) are applied, problems still appear in dealing with disfluencies, because mispronounced words will not be counted together. Indeed, other types of disfluencies (repetition, amendments, patient\u2019s comments about the task) will be counted, thus increasing the vocabulary.\nAn approach applied successfully to several areas of NLP (Mihalcea and Radev, 2011), which may suffer less from the problems mentioned above, relies on the use of complex networks and graph theory. The word adjacency network model (i Cancho and Sole\u0301, 2001; Roxas and Tapang, 2010; Amancio et al., 2012a; Amancio, 2015b) has provided good results in text classification (de Arruda et al., 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al., 2012c), authenticity verification (Amancio et al., 2013) and word sense discrimination (Amancio et al., 2012b).\nIn this paper, we show that speech transcripts (narratives or descriptions) can be modeled into complex networks that are enriched with word embedding in order to better represent short texts produced in these assessments. When applied to a machine learning classifier, the complex network features were able to distinguish between control participants and mild cognitive impairment participants. Discrimination of the two classes could be improved by combining complex networks with linguistic and traditional statistical features.\nWith regard to the task of detecting MCI from transcripts, this paper is, to the best of our knowledge, the first to: a) show that classifiers using features extracted from transcripts modeled into\ncomplex networks enriched with word embedding present higher accuracy than using only complex networks for 3 datasets; and b) show that for languages that do not have competitive dependency and constituency parsers to exploit syntactic features, e.g. Brazilian Portuguese, complex networks enriched with word embedding constitute a source to extract new, language independent features from transcripts."}, {"heading": "2 Related Work", "text": "Detection of memory impairment has been based on linguistic, acoustic, and demographic features, in addition to scores of neuropsychological tests. Linguistic and acoustic features were used to automatically detect aphasia (Fraser et al., 2014); and AD (Fraser et al., 2015) or dementia (Orimaye et al., 2014) in the public corpora of DementiaBank1. Other studies distinguished different types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery (Kertesz, 1982). Davy et al. (2016) also used the Picnic scene to detect MCI, where the subjects were asked to write (by hand) a detailed description of the scene.\nAs for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of speech samples obtained with the Wechsler Logical Memory (WLM) subtest (Wechsler et al., 1997), and Lehr et al. (2012) fully automatized the WLM subtest. In this test, the examiner tells a short narrative to a subject, who then retells the story to the examiner, immediately and after a 30- minute delay. WLM scores are obtained by counting the number of story elements recalled.\nTo\u0301th et al. (2015) and Vincze et al. (2016) used short animated films to evaluate immediate and delayed recalls in MCI patients who were asked to talk about the first film shown, then about their previous day, and finally about another film shown last. To\u0301th et al. (2015) adopted automatic speech recognition (ASR) to extract a phonetic level segmentation, which was used to calculate acoustic features. Vincze et al. (2016) used speech, morphological, semantic, and demographic features collected from their speech transcripts to automatically identify patients suffering from MCI.\nFor the Portuguese language, machine learning 1talkbank.org/DementiaBank/\nalgorithms were used to identify subjects with AD and MCI. Alu\u0131\u0301sio et al. (2016) used a variety of linguistic metrics, such as syntactic complexity, idea density (da Cunha et al., 2015), and text cohesion through latent semantics. NLP tools with high precision are needed to compute these metrics, which is a problem for Portuguese since no robust dependency or constituency parsers exist. Therefore, the transcriptions had to be manually revised; they were segmented into sentences, following a semantic-structural criterion and capitalization was applied. The authors also removed disfluencies and inserted omitted subjects when they were hidden, in order to reduce parsing errors. This process is obviously expensive, which has motivated us to use complex networks in the present study to model transcriptions and avoid a manual preprocessing step."}, {"heading": "3 Modeling and Characterizing Texts as Complex Networks", "text": "The theory and concepts of complex networks have been used in several NLP tasks (Mihalcea and Radev, 2011; Cong and Liu, 2014), such as text classification (de Arruda et al., 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012). In this study, we used the word co-occurrence model (also called word adjacency model) because most of the syntactical relations occur among neighboring words (i Cancho et al., 2004). Each distinct word becomes a node and words that are adjacent in the text are connected by an edge. Mathematically, a network is defined as an undirected graph G = {V,E}, formed by a set V = {v1, v2, ..., vn} of nodes (words) and a set E = {e1, e2, ..., em} of edges (co-occurrence) that are represented by an adjacency matrix A, whose elements Aij are equal to 1 whenever there is an edge connecting nodes (words) i and j, and equal to 0 otherwise.\nBefore modeling texts into complex networks, it is often necessary to do some preprocessing in the raw text. Preprocessing starts with tokenization where each document/text is divided into tokens (meaningful elements, e.g., words and punctuation marks) and then stopwords and punctuation marks are removed, since they have little semantic meaning. One last step we decided to eliminate from the preprocessing pipeline is lemmatization, which transforms each word into its canonical\nform. This decision was made based on two factors. First, a recent work has shown that lemmatization has little or no influence when network modeling is adopted in related tasks (Machicao et al., 2016). Second, the lemmatization process requires part-of-speech (POS) tagging that may introduce undesirable noises/errors in the text, since the transcriptions in our work contain disfluencies.\nAnother problem with transcriptions in our work is their size. As demonstrated by Amancio (2015c), classification of small texts using networks can be impaired, since short texts have almost linear networks, and the topological measures of these networks have little or no information relevant to classification. To solve this problem, we adapted the approach of inducing language networks from word embeddings, proposed by Perozzi et al. (2014) to enrich the networks with semantic information. In their work, language networks were generated from continuous word representations, in which each word is represented by a dense, real-valued vector obtained by training neural networks in the language model task (or variations, such as context prediction) (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013a,b). This structure is known to capture syntactic and semantic information. Perozzi et al. (2014), in particular, take advantage of word embeddings to build networks where each word is\na vertex and edges are defined by similarity between words established by the proximity of the word vectors.\nFollowing this methodology, in our model we added new edges to the co-occurrence networks considering similarities between words, that is, for all pairs of words in the text that were not connected, an edge was created if their vectors (from word embedding) had a cosine similarity higher than a given threshold. Figure 1 shows an example of a co-occurrence network enriched by similarity links (the dotted edges). The gain in information by enriching a co-occurrence network with semantic information is readily apparent in Figure 2."}, {"heading": "4 Datasets, Features and Methods", "text": ""}, {"heading": "4.1 Datasets", "text": "The datasets2 used in our study consisted of: (i) manually segmented and transcribed samples from the DementiaBank and Cinderella story and (ii) transcribed samples of Arizona Battery for Communication Disorders of Dementia (ABCD) automatically segmented into sentences, since we are working towards a fully automated system to detect MCI in transcripts and would like to evaluate a dataset which was automatically processed.\nThe DementiaBank dataset is composed of short English descriptions, while the Cinderella dataset contains longer Brazilian Portuguese narratives. ABCD dataset is composed of very short narratives, also in Portuguese. Below, we describe\n2All datasets are made available in the same representations used in this work, upon request to the authors.\nin further detail the datasets, participants, and the task in which they were used."}, {"heading": "4.1.1 The Cookie Theft Picture Description Dataset", "text": "The clinical dataset used for the English language was created during a longitudinal study conducted by the University of Pittsburgh School of Medicine on Alzheimer\u2019s and related dementia, funded by the National Institute of Aging. To be eligible for inclusion in the study, all participants were required to be above 44 years of age, have at least 7 years of education, no history of nervous system disorders nor be taking neuroleptic medication, have an initial Mini-Mental State Exam (MMSE) score of 10 or greater, and be able to give informed consent. The dataset contains transcripts of verbal interviews with AD and related Dementia patients, including those with MCI (for further details see (Becker et al., 1994)).\nWe used 43 transcriptions with MCI in addition to another 43 transcriptions sampled from 242 healthy elderly people to be used as the control group. Table 1 shows the demographic information for the two diagnostic groups.\nFor this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al. (2001) in Section A.1). During the interview, patients were given the picture and were told to discuss everything they could see happening in the picture. The patients\u2019 verbal utterances were recorded and then transcribed into the CHAT (Codes for the Human Analysis of Transcripts) transcription format (MacWhinney, 2000).\nWe extracted the word-level transcript patient sentences from the CHAT files and discarded the annotations, as our goal was to create a fully automated system that does not require the input of a human annotator. We automatically removed filled pauses such as uh, um , er , and ah (e.g. uh it seems to be summer out), short false starts (e.g. just t the ones ), and repetition (e.g. mother\u2019s finished certain of the the dishes ), as in (Fraser et al.,\n2015). The control group had an average of 9.58 sentences per narrative, with each sentence having an average of 9.18 words; while the MCI group had an average of 10.97 sentences per narrative, with 10.33 words per sentence in average."}, {"heading": "4.1.2 The Cinderella Narrative Dataset", "text": "The dataset examined in this study included 20 subjects with MCI and 20 normal elderly control subjects, as diagnosed at the Medical School of the University of Sa\u0303o Paulo (FMUSP). Table 2 shows the demographic information of the two diagnostic groups, which were also used in Alu\u0131\u0301sio et al. (2016).\nThe criteria used to diagnose MCI came from Petersen (2004). Diagnostics were carried out by a multidisciplinary team consisting of psychiatrists, geriatricians, neurologists, neuropsychologists, speech pathologists, and occupational therapists, by a criterion of consensus. Inclusion criteria for the control group were elderlies with no cognitive deficits and preservation of functional capacity in everyday life. The exclusion criteria for the normal group were: poorly controlled clinical diseases, sensitive deficits that were not being compensated for and interfered with the performance in tests, and other neurological or psychiatric diagnoses associated with dementia or cognitive deficits and use of medications in doses that affected cognition.\nSpeech narrative samples were elicited by having participants tell the Cinderella story; participants were given as much time as they needed to examine a picture book illustrating the story (Figure 4 in Section A). When each participant had finished looking at the pictures, the examiner asked the subject to tell the story in their own words, as in Saffran et al. (1989). The time was recorded, but there was no limit imposed to the narrative length. If the participant had difficulty initiating or continuing speech, or took a long pause, an evaluator would use the stimulus question \u201cWhat happens next ?\u201d, seeking to encourage the participant to continue his/her narrative. When the sub-\nject was unable to proceed with the narrative, the examiner asked if he/she had finished the story and had something to add. Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N. 338 EF and 331 D2 transcription norms3.\nOther tests were applied after the narrative, in the following sequence: phonemic verbal fluency test, action verbal fluency, Camel and Cactus test (Bozeat et al., 2000), and Boston Naming test (Kaplan et al., 2001), in order to diagnose the groups.\nSince our ultimate goal is to create a fully automated system that does not require the input of a human annotator, we manually segmented sentences to simulate a high-quality ASR transcript with sentence segmentation, and we automatically removed the disfluencies following the same guidelines of TalkBank project. However, other disfluencies (revisions, elaboration, paraphasias and comments about the task) were kept. The control group had an average of 30.80 sentences per narrative, and each sentence averaged 12.17 words. As for the MCI group, it had an average of 29.90 sentences per narrative, and each sentence averaged 13.03 words.\nWe also evaluated a different version of the dataset used in Alu\u0131\u0301sio et al. (2016), where narratives were manually annotated and revised to improve parsing results. The revision process was the following: (i) in the original transcript, segments with hesitations or repetitions of more than one word or segment of a single word were annotated to become a feature and then removed from the narrative to allow the extraction of features from parsing; (ii) empty emissions, which were comments unrelated to the topic of narration or confirmations, such as \u201cne\u0301\u201d (alright), were also annotated and removed; (iii) prolongations of vowels, short pauses and long pauses were also annotated and removed; and (iv) omitted subjects in sentences were inserted. In this revised dataset, the control group had an average of 45.10 sentences per narrative, and each sentence averaged 8.17 words. The MCI group had an average of 31.40 sentences per narrative, with each sentence averaging 10.91 words."}, {"heading": "4.1.3 The ABCD Dataset", "text": "The subtest of immediate/delayed recall of narratives of the ABCD battery was administered to 23\n3albertofedel.blogspot.com.br/2010_11_ 01_archive.html\nparticipants with a diagnosis of MCI and 20 normal elderly control participants, as diagnosed at the Medical School of the University of Sa\u0303o Paulo (FMUSP).\nMCI subjects produced 46 narratives while the control group produced 39 ones. In order to carry out experiments with a balanced corpus, as with the previous two datasets, we excluded seven transcriptions from the MCI group. We used the automatic sentence segmentation method referred to as DeepBond (Treviso et al., 2017) in the transcripts.\nTable 3 shows the demographic information. The control group had an average of 5.23 sentences per narrative, with 11 words per sentence on average, and the MCI group had an average of 4.95 sentences per narrative, with an average of 12.04 words per sentence. Interviews were conducted in Portuguese and the subject listened to the examiner read a short narrative. The subject then retold the narrative to the examiner twice: once immediately upon hearing it and again after a 30-minute delay (Bayles and Tomoeda, 1991). Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N. 338 EF and 331 D2 transcription norms."}, {"heading": "4.2 Features", "text": "Features of three distinct natures were used to classify the transcribed texts: topological metrics of co-occurrence networks, linguistic features and bag of words representations."}, {"heading": "4.2.1 Topological Characterization of Networks", "text": "Each transcription was mapped into a cooccurrence network, and then enriched via word embeddings using the cosine similarity of words. Since the occurrence of out-of-vocabulary words is common in texts of neuropsychological assessments, we used the method proposed by Bojanowski et al. (2016) to generate word embeddings. This method extends the skip-gram model to use character-level information, with each word\nbeing represented as a bag of character n-grams. It provides some improvement in comparison with the traditional skip-gram model in terms of syntactic evaluation (Mikolov et al., 2013b) but not for semantic evaluation.\nOnce the network has been enriched, we characterize its topology using the following ten measurements:\n1. PageRank: is a centrality measurement that reflects the relevance of a node based on its connections to other relevant nodes (Brin and Page, 1998);\n2. Betweenness: is a centrality measurement that considers a node as relevant if it is highly accessed via shortest paths. The betweenness of a node v is defined as the fraction of shortest paths going through node v;\n3. Eccentricity: of a node is calculated by measuring the shortest distance from the node to all other vertices in the graph and taking the maximum;\n4. Eigenvector centrality: is a measurement that defines the importance of a node based on its connectivity to high-rank nodes;\n5. Average Degree of the Neighbors of a Node: is the average of the degrees of all its direct neighbors;\n6. Average Shortest Path Length of a Node: is the average distance between this node and all other nodes of the network;\n7. Degree: is the number of edges connected to the node;\n8. Assortativity Degree: or degree correlation measures the tendency of nodes to connect to other nodes that have similar degree;\n9. Diameter: is defined as the maximum shortest path;\n10. Clustering Coefficient: measures the probability that two neighbors of a node are connected.\nMost of the measurements described above are local measurements, i.e. each node i possesses a valueXi, so we calculated the average \u00b5(X), standard deviation \u03c3(X) and skewness \u03b3(X) for each measurement (Amancio, 2015b)."}, {"heading": "4.2.2 Linguistic Features", "text": "Linguistic features for classification of neuropsychological assessments have been used in several studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016). We used the Coh-Metrix4(Graesser et al., 2004) tool to extract features from English transcripts, resulting in 106 features. The metrics are divided into eleven categories: Descriptive, Text Easability Principal Component, Referential Cohesion, Latent Semantic Analysis (LSA), Lexical Diversity, Connectives, Situation Model, Syntactic Complexity, Syntactic Pattern Density, Word Information, and Readability (Flesch Reading Ease, Flesch-Kincaid Grade Level, Coh-Metrix L2 Readability).\nFor Portuguese, Coh-Metrix-Dementia (Alu\u0131\u0301sio et al., 2016) was used. The metrics affected by constituency and dependency parsing were not used because they are not robust with disfluencies. Metrics based on manual annotation (such as proportion short pauses, mean pause duration, mean number of empty words, and others) were also discarded. The metrics of Coh-MetrixDementia are divided into twelve categories: Ambiguity, Anaphoras, Basic Counts, Connectives, Co-reference Measures, Content Word Frequencies, Hypernyms, Logic Operators, Latent Semantic Analysis, Semantic Density, Syntactical Complexity, and Tokens. The metrics used are shown in detail in Section A.2. In total, 58 metrics were used, from the 73 available on the website5."}, {"heading": "4.2.3 Bag of Words", "text": "The representation of text collections under the BoW assumption (i.e., with no information relating to word order) has been a robust solution for text classification. In this methodology, transcripts are represented by a table in which the columns represent the terms (or existing words) in the transcripts and the values represent frequency of a term in a document."}, {"heading": "4.3 Classification Algorithms", "text": "In order to quantify the ability of the topological characterization of networks, linguistic metrics and BoW features were used to distinguish subjects with MCI from healthy controls. We\n4cohmetrix.com 5http://143.107.183.175:22380\nemployed four machine learning algorithms to induce classifiers from a training set. These techniques were the Gaussian Naive Bayes (GNB), k-Nearest Neighbor (k-NN), Support Vector Machine (SVM), linear and radial bases functions (RBF), and Random Forest (RF). We also combined these classifiers through ensemble and multi-view learning. In ensemble learning, multiple models/classifiers are generated and combined using a majority vote or the average of class probabilities to produce a single result (Zhou, 2012).\nIn multi-view learning, multiple classifiers are trained in different feature spaces and thus combined to produce a single result. This approach is an elegant solution in comparison to combining all features in the same vector or space, for two main reasons. First, combination is not a straightforward step and may lead to noise insertion since the data have different natures. Second, using different classifiers for each feature space allows for different weights to be given for each type of feature, and these weights can be learned by a regression method to improve the model. In this work, we used majority voting to combine different feature spaces."}, {"heading": "5 Experiments and Results", "text": "All experiments were conducted using the Scikitlearn6 (Pedregosa et al., 2011), with classifiers evaluated on the basis of classification accuracy i.e. the total proportion of narratives which were correctly classified. The evaluation was performed using 5-fold cross-validation instead of the well-accepted 10-fold cross-validation because the datasets in our study were small and the test set would have shrunk, leading to less precise measurements of accuracy. The threshold parameter was optimized with the best values being 0.7 in the Cookie Theft dataset and 0.4 in both the Cinderella and ABCD datasets.\nWe used the model proposed by Bojanowski et al. (2016) with default parameters (100 dimensional embeddings, context window equal to 5 and 5 epochs) to generate word embedding. We trained the models in Portuguese and English Wikipedia dumps from October and November 2016 respectively.\nThe accuracy in classification is given in Tables 4 through 6. CN, CNE, LM, and BoW denote, respectively, complex networks, complex network\n6http://scikit-learn.org\nenriched with embedding, linguistic metrics and Bag of Words, and CNE-LM, CNE-BoW, LMBoW and CNE-LM-BoW refer to combinations of the feature spaces (multiview learning), using the majority vote. Cells with the \u201c\u2013\u201d sign mean that it was not possible to apply majority voting because there were two classifiers. The last line represents the use of an ensemble of machine learning algorithms, in which the combination used was the majority voting in both ensemble and multiview learning.\nIn general, CNE outperforms the approach using only complex networks (CN), while SVM (Linear or RBF kernel) provides higher accuracy than other machine learning algorithms. The results for the three datasets show that characterizing transcriptions into complex networks is competitive with other traditional methods, such as the use of linguistic metrics. In fact, among the three types of features, using enriched networks (CNE) provided the highest accuracies in two datasets (Cookie Theft and original Cinderella). For the ABCD dataset, which contains short narratives, the small length of the transcriptions may have had an effect, since BoW features led to the highest accuracy. In the case of the revised Cinderella dataset, segmented into sentences and capitalized as reported in Alu\u0131\u0301sio et al. (2016), Table 7 shows that the manual revision was an important factor, since the highest accuracies were obtained with the approach based on linguistic metrics (LM). However, this process of manually removing disfluencies demands time; therefore it is not practical for large-scale assessments.\nEnsemble and multi-view learning were helpful for the Cookie Theft dataset, in which multi-view learning achieved the highest accuracy (65% of accuracy for narrative texts, a 3% of improvement compared to the best individual classifier). However, neither multi-view or ensemble learning enhanced accuracy in the Cinderella dataset, where SVM-RBF with CNE space achieved the highest accuracy (65%). For the ABCD dataset, multiview CNE-LM-BoW with SVM-RBF and KNN classifiers improved the accuracy to 4% and 2%, respectively. Somewhat surprising were the results of SVM with linear kernel in BoW feature space (75% of accuracy)."}, {"heading": "6 Conclusions and Future Work", "text": "In this study, we employed metrics of topological properties of CN in a machine learning classification approach to distinguish between healthy patients and patients with MCI. To the best of our knowledge, these metrics have never been used to detect MCI in speech transcripts; CN were enriched with word embeddings to better represent short texts produced in neuropsychological assessments. The topological properties of CN outperform traditional linguistic metrics in individual classifiers\u2019 results. Linguistic features depend on grammatical texts to present good results, as can be seen in the results of the manually processed Cinderella dataset (Table 7). Furthermore, we found that combining machine and multi-view learning can improve accuracy. The accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud\u2019hommeaux and Roark, 2011; Lehr et al., 2012; To\u0301th et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish between healthy subjects and those with cognitive impairments. The comparison with our results is not straightforward, though, because the databases used in the studies are different. There is a clear need for publicly available datasets to compare different methods, which would optimize the detection of MCI in elderly people.\nIn future work, we intend to explore other methods to enrich CN, such as the Recurrent Language Model, and use other metrics to characterize an adjacency network. The pursuit of these strategies is relevant because language is one of the most efficient information sources to evaluate cognitive functions, commonly used in neuropsychological assessments. As this work is ongoing, we will keep collecting new transcriptions of the ABCD retelling subtest to increase the corpus size and obtain more reliable results in our studies. Our final goal is to apply neuropsychological assessment batteries, such as the ABCD retelling subtest, to mobile devices, specifically tablets. This adaptation will enable large-scale applications in hospitals and facilitate the maintenance of application history in longitudinal studies, by storing the results in databases immediately after the test application."}, {"heading": "Acknowledgments", "text": "This work was supported by CAPES, CNPq, FAPESP, and Google Research Awards in Latin America. We would like to thank NVIDIA for their donation of GPU."}, {"heading": "A Supplementary Material", "text": "Figure 3 is Cookie Theft picture, which was used in DementiaBank project.\nFigure 4 is a sequence of pictures from the Cinderella story, which were used to elicit speech narratives.\nA.1 Examples of transcriptions Below follows an example of a transcript of the Cookie Theft dataset.\nYou just want me to start talking ? Well the little girl is asking her brother we \u2019ll say for a cookie . Now he \u2019s getting the cookie one for him and one for her . He unbalances the step the little stool and he \u2019s about to fall . And the lid \u2019s off the cookie jar . And the mother is drying the dishes abstractly so she \u2019s left the water running in the sink and it is spilling onto the floor . And there are two there \u2019s look like two cups and a plate on the sink and board . And that boy \u2019s wearing shorts and the little girl is in a short skirt . And the mother has an apron on . And she \u2019s standing at the window . The window \u2019s opened . It must be summer or spring . And the curtains are pulled back . And they have a nice walk around their house . And there \u2019s this nice shrubbery it appears and grass . And there \u2019s a big picture window in the background that has the drapes pulled off . There \u2019s a not pulled off but pulled aside . And there \u2019s a tree in the background . And the house with the kitchen has a lot of cupboard space under the sink board and under the cabinet from which the cookie you know cookies are being removed .\nBelow follows an excerpt of a transcript of the Cinderella dataset.\nOriginal transcript in Portuguese: ela morava com a madrasta as irma\u0303 ne\u0301 e ela era diferenciada das tre\u0302s era maltratada ela tinha que fazer limpeza na casa toda no castelo alias e as irma\u0303s na\u0303o faziam nada ate\u0301 que um dia chegou um convite do rei ele ia fazer um baile e a madrasta enta\u0303o e\u0301 colocou que todas as filhas elas iam menos a cinderela bom como ela na\u0303o tinha o vestido sapato as coisas tudo enta\u0303o ela mesmo teve que fazer a roupa dela comec\u0327ou a fazer ...\nTranslation of the transcript in English: she lived with the stepmother the sister right and she was differentiated from the three was mistreated she had to do the cleaning in the entire house actually in the castle and the sisters didn\u2019t do anything until one day the king\u2019s invitation arrived he would invite everyone to a ball and then the stepmother is said that all the daughters they would go except for cinderella well since she didn\u2019t have a dress shoes all the things she had to make her own clothes she started to make them ...\nA.2 Coh-Metrix-Dementia metrics\n1. Ambiguity: verb ambiguity, noun ambiguity, adjective ambiguity, adverb ambiguity;\n2. Anaphoras: adjacent anaphoric references,\nanaphoric references;\n3. Basic Counts: Flesch index, number of word, number of sentences, number of paragraphs, words per sentence, sentences per paragraph, syllables per content word, verb incidence, noun incidence, adjective incidence, adverb incidence, pronoun incidence, content word incidence, function word incidence;\n4. Connectives: connectives incidence, additive positive connectives incidence, additive negative connectives incidence, temporal positive connectives incidence, temporal negative connectives incidence, casual positive connectives incidence, casual negative connectives incidence, logical positive connectives incidence, logical negative connectives incidence;\n5. Co-reference Measures: adjacent argument overlap, argument overlap, adjacent stem overlap, stem overlap, adjacent content word overlap;\n6. Content Word Frequencies: Content words frequency, minimum among content words frequency;\n7. Hypernyms: Mean hypernyms per verb;\n8. Logic Operators: Logic operators incidence, and incidence, or incidence, if incidence, negation incidence;\n9. Latent Semantic Analysis (LSA): Average and standard deviation similarity between pairs of adjacent sentences in the text, Average and standard deviation similarity between all sentence pairs in the text, Average and standard deviation similarity between pairs of adjacent paragraphs in the text, Givenness average and standard deviation of each sentence in the text;\n10. Semantic Density: content density;\n11. Syntactical Complexity: only cross entropy;\n12. Tokens: personal pronouns incidence, typetoken ratio, Brunet index, Honore\u0301 Statistics."}], "references": [{"title": "Evaluating progression of alzheimer\u2019s disease by regression and classification methods in a narrative language test in portuguese", "author": ["Sandra M. Alu\u0131\u0301sio", "Andre L. da Cunha", "Carolina Scarton"], "venue": null, "citeRegEx": "Alu\u0131\u0301sio et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Alu\u0131\u0301sio et al\\.", "year": 2016}, {"title": "Authorship recognition via fluctuation analysis of network topology and word intermittency", "author": ["Diego R. Amancio."], "venue": "Journal of Statistical Mechanics: Theory and Experiment 2015(3):P03005. https://doi.org/10.1088/1742-", "citeRegEx": "Amancio.,? 2015a", "shortCiteRegEx": "Amancio.", "year": 2015}, {"title": "A complex network approach to stylometry", "author": ["Diego R. Amancio."], "venue": "PloS one 10(8):e0136076. https://doi.org/10.1371/journal.pone.0136076.", "citeRegEx": "Amancio.,? 2015b", "shortCiteRegEx": "Amancio.", "year": 2015}, {"title": "Probing the topological properties of complex networks modeling short written texts", "author": ["Diego R. Amancio."], "venue": "PloS one 10(2):1\u201317. https://doi.org/10.1371/journal.pone.0118394.", "citeRegEx": "Amancio.,? 2015c", "shortCiteRegEx": "Amancio.", "year": 2015}, {"title": "Probing the statistical properties of unknown texts: Application to the voynich manuscript", "author": ["Diego R. Amancio", "Eduardo G. Altmann", "Diego Rybski", "Osvaldo N. Oliveira Jr.", "Luciano da F. Costa."], "venue": "PLOS ONE 8(7):1\u201310.", "citeRegEx": "Amancio et al\\.,? 2013", "shortCiteRegEx": "Amancio et al\\.", "year": 2013}, {"title": "Extractive summarization using complex networks and syntactic dependency", "author": ["Diego R. Amancio", "Maria G.V. Nunes", "Osvaldo N. Oliveira Jr.", "Luciano F. Costa."], "venue": "Physica A: Statistical Me-", "citeRegEx": "Amancio et al\\.,? 2012a", "shortCiteRegEx": "Amancio et al\\.", "year": 2012}, {"title": "Unveiling the relationship between complex networks metrics and word senses", "author": ["Diego R. Amancio", "O.N. Oliveira Jr.", "Luciano da F. Costa."], "venue": "EPL (Europhysics Letters) 98(1):18002. https://doi.org/10.1209/0295-5075/98/18002.", "citeRegEx": "Amancio et al\\.,? 2012b", "shortCiteRegEx": "Amancio et al\\.", "year": 2012}, {"title": "Identification of literary movements using complex networks to represent texts", "author": ["Diego R. Amancio", "Osvaldo N. Oliveira Jr.", "Luciano F. Costa."], "venue": "New Journal of Physics 14(4):043029. https://doi.org/10.1088/1367-2630/14/4/043029.", "citeRegEx": "Amancio et al\\.,? 2012c", "shortCiteRegEx": "Amancio et al\\.", "year": 2012}, {"title": "A complex network approach to text summarization", "author": ["Lucas Antiqueira", "Osvaldo N. Oliveira Jr.", "Luciano da Fontoura Costa", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Information Sciences 179(5):584 \u2013 599.", "citeRegEx": "Antiqueira et al\\.,? 2009", "shortCiteRegEx": "Antiqueira et al\\.", "year": 2009}, {"title": "ABCD: Arizona Battery for Communication Disorders of Dementia", "author": ["Kathryn A. Bayles", "Cheryl K. Tomoeda."], "venue": "Tucson, AZ: Canyonlands Publishing.", "citeRegEx": "Bayles and Tomoeda.,? 1991", "shortCiteRegEx": "Bayles and Tomoeda.", "year": 1991}, {"title": "The natural history of alzheimer\u2019s disease: description of study cohort and accuracy of diagnosis", "author": ["James T. Becker", "Fran\u00e7ois Boiler", "Oscar L. Lopez", "Judith Saxton", "Karen L. McGonigle."], "venue": "Archives of Neurology 51(6):585\u2013594.", "citeRegEx": "Becker et al\\.,? 1994", "shortCiteRegEx": "Becker et al\\.", "year": 1994}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Jauvin."], "venue": "journal of machine learning research 3(Feb):1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Enriching word vectors with subword information", "author": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1607.04606 .", "citeRegEx": "Bojanowski et al\\.,? 2016", "shortCiteRegEx": "Bojanowski et al\\.", "year": 2016}, {"title": "Non-verbal semantic impairment in semantic dementia", "author": ["Sasha Bozeat", "Matthew A. Ralph", "Karalyn Patterson", "Peter Garrard", "John R. Hodges."], "venue": "Neuropsychologia 38(9):1207\u20131215. https://doi.org/10.1016/S0028-3932(00)00034-8.", "citeRegEx": "Bozeat et al\\.,? 2000", "shortCiteRegEx": "Bozeat et al\\.", "year": 2000}, {"title": "The anatomy of a large-scale hypertextual web search engine", "author": ["Sergey Brin", "Lawrence Page."], "venue": "International Conference on World Wide Web. Elsevier, pages 107\u2013117.", "citeRegEx": "Brin and Page.,? 1998", "shortCiteRegEx": "Brin and Page.", "year": 1998}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Approaching human language with complex networks", "author": ["Jin Cong", "Haitao Liu."], "venue": "Physics of Life Reviews 11(4):598 \u2013 618. https://doi.org/10.1016/j.plrev.2014.04.004.", "citeRegEx": "Cong and Liu.,? 2014", "shortCiteRegEx": "Cong and Liu.", "year": 2014}, {"title": "Automatic proposition extraction from dependency trees: Helping early prediction of alzheimer\u2019s disease from narratives", "author": ["Andre L. da Cunha", "Lucilene B. de Sousa", "Let\u0131\u0301cia L. Mansur", "Sandra M. Alu\u0131\u0301sio"], "venue": null, "citeRegEx": "Cunha et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cunha et al\\.", "year": 2015}, {"title": "Towards automatic detection of abnormal cognitive decline and dementia through linguistic analysis", "author": ["Weissenbacher Davy", "Johnson A. Travis", "Wojtulewicz Laura", "Dueck Amylou", "Locke Dona", "Caselli Richard", "Gonzalez Graciela"], "venue": null, "citeRegEx": "Davy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Davy et al\\.", "year": 2016}, {"title": "Using complex networks for text classification: Discriminating informative and imaginative documents", "author": ["Henrique F. de Arruda", "Luciano F. Costa", "Diego R. Amancio."], "venue": "EPL (Europhysics Letters) 113(2):28007. https://doi.org/10.1209/0295-", "citeRegEx": "Arruda et al\\.,? 2016", "shortCiteRegEx": "Arruda et al\\.", "year": 2016}, {"title": "Predicting prodromal alzheimer\u2019s disease in subjects with mild cognitive impairment", "author": ["Martin Dyrba", "Frederik Barkhof", "Andreas Fellgiebel", "Massimo Filippi", "Lucrezia Hausner", "Karlheinz Hauenstein", "Thomas Kirste", "Stefan J. Teipel"], "venue": null, "citeRegEx": "Dyrba et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyrba et al\\.", "year": 2015}, {"title": "Automated classification of primary progressive aphasia subtypes from narrative speech transcripts", "author": ["Kathleen C. Fraser", "Jed A. Meltzer", "Naida L. Graham", "Carol Leonard", "Graeme Hirst", "Sandra E. Black", "Elizabeth Rochon."], "venue": "Cortex 55:43\u201360.", "citeRegEx": "Fraser et al\\.,? 2014", "shortCiteRegEx": "Fraser et al\\.", "year": 2014}, {"title": "Linguistic features identify alzheimer\u2019s disease in narrative speech", "author": ["Kathleen C. Fraser", "Jed A. Meltzer", "Frank Rudzicz."], "venue": "Journal of Alzheimer\u2019s Disease 49(2):407\u2013422. https://doi.org/10.3233/JAD-150520.", "citeRegEx": "Fraser et al\\.,? 2015", "shortCiteRegEx": "Fraser et al\\.", "year": 2015}, {"title": "Machine learning approaches to diagnosis and laterality effects in semantic dementia discourse", "author": ["Peter Garrard", "Vassiliki Rentoumi", "Benno Gesierich", "Bruce Miller", "Maria L. Gorno-Tempini."], "venue": "Cortex 55:122\u2013129.", "citeRegEx": "Garrard et al\\.,? 2014", "shortCiteRegEx": "Garrard et al\\.", "year": 2014}, {"title": "The Assessment of Aphasia and Related Disorders", "author": ["Harold Goodglass", "Edith Kaplan", "Barbara Barresi."], "venue": "The Assessment of Aphasia and Related Disorders. Lippincott Williams & Wilkins.", "citeRegEx": "Goodglass et al\\.,? 2001", "shortCiteRegEx": "Goodglass et al\\.", "year": 2001}, {"title": "Patterns in syntactic dependency networks", "author": ["Ramon F. i Cancho", "Ricard V. Sol\u00e9", "Reinhard K\u00f6hler."], "venue": "Physical Review E 69(5):051915. https://doi.org/10.1103/PhysRevE.69.051915.", "citeRegEx": "Cancho et al\\.,? 2004", "shortCiteRegEx": "Cancho et al\\.", "year": 2004}, {"title": "The small world of human language", "author": ["Ramon F. i Cancho", "Richard V. Sol\u00e9."], "venue": "Proceedings of the Royal Society of London B: Biological Sciences 268(1482):2261\u20132265. https://doi.org/10.1098/rspb.2001.1800.", "citeRegEx": "Cancho and Sol\u00e9.,? 2001", "shortCiteRegEx": "Cancho and Sol\u00e9.", "year": 2001}, {"title": "Aided diagnosis of dementia type through computer-based analysis of spontaneous speech", "author": ["William L. Jarrold", "Bart Peintner", "David Wilkins", "Dimitra Vergryi", "Colleen Richey", "Maria L. GornoTempini", "Jennifer Ogar."], "venue": "Proceedings of the", "citeRegEx": "Jarrold et al\\.,? 2014", "shortCiteRegEx": "Jarrold et al\\.", "year": 2014}, {"title": "Language analytics for assessing brain health: Cognitive impairment, depression and presymptomatic alzheimer\u2019s disease", "author": ["William L. Jarrold", "Bart Peintner", "Eric Yeh", "Ruth Krasnow", "Harold S. Javitz", "Gary E. Swan."], "venue": "Yiyu Yao,", "citeRegEx": "Jarrold et al\\.,? 2010", "shortCiteRegEx": "Jarrold et al\\.", "year": 2010}, {"title": "Boston naming test", "author": ["Edith Kaplan", "Harold Googlass", "Sandra Weintrab."], "venue": "Lippincott Williams & Wilkins.", "citeRegEx": "Kaplan et al\\.,? 2001", "shortCiteRegEx": "Kaplan et al\\.", "year": 2001}, {"title": "Western Aphasia Battery test manual", "author": ["A. Kertesz."], "venue": "Grune & Stratton.", "citeRegEx": "Kertesz.,? 1982", "shortCiteRegEx": "Kertesz.", "year": 1982}, {"title": "Fully automated neuropsychological assessment for detecting mild cognitive impairment", "author": ["Maider Lehr", "Emily T. Prud\u2019hommeaux", "Izhak Shafran", "Brian Roark"], "venue": "In Proceedings of the 13th Annual Conference of the International Speech Communi-", "citeRegEx": "Lehr et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lehr et al\\.", "year": 2012}, {"title": "Authorship attribution based on life-like network automata", "author": ["Jeaneth Machicao", "Edilson A. Corr\u00eaa Jr", "Gisele H.B. Miranda", "Diego R. Amancio", "Odemir M. Bruno."], "venue": "arXiv preprint arXiv:1610.06498 .", "citeRegEx": "Machicao et al\\.,? 2016", "shortCiteRegEx": "Machicao et al\\.", "year": 2016}, {"title": "The CHILDES Project: Tools for analyzing talk", "author": ["Brian MacWhinney."], "venue": "Lawrence Erlbaum Associates, 3 edition.", "citeRegEx": "MacWhinney.,? 2000", "shortCiteRegEx": "MacWhinney.", "year": 2000}, {"title": "Graphbased natural language processing and information retrieval", "author": ["Rada Mihalcea", "Dragomir Radev."], "venue": "Cambridge University Press.", "citeRegEx": "Mihalcea and Radev.,? 2011", "shortCiteRegEx": "Mihalcea and Radev.", "year": 2011}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Tomas Mikolov", "Quoc V. Le", "Ilya Sutskever."], "venue": "arXiv preprint arXiv:1309.4168 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeff Dean."], "venue": "Proceedings of the 27th Annual Conference on Neural Information Processing Systems. pages", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Prevalence of potentially reversible conditions in dementia and mild cognitive impairment in a geriatric clinic", "author": ["Weerasak Muangpaisan", "Chonachan Petcharat", "Varalak Srinonprasert."], "venue": "Geriatrics & gerontology international 12(1):59\u201364.", "citeRegEx": "Muangpaisan et al\\.,? 2012", "shortCiteRegEx": "Muangpaisan et al\\.", "year": 2012}, {"title": "Learning predictive linguistic features for alzheimer\u2019s disease and related dementias using verbal utterances", "author": ["Sylvester O. Orimaye", "Jojo Wong", "K. Jennifer Golden."], "venue": "Proceedings of the 1st Workshop on Computational Linguis-", "citeRegEx": "Orimaye et al\\.,? 2014", "shortCiteRegEx": "Orimaye et al\\.", "year": 2014}, {"title": "Inducing language networks from continuous space word representations", "author": ["Bryan Perozzi", "Rami Al-Rfou", "Vivek Kulkarni", "Steven Skiena."], "venue": "Proceedings of the 5th Workshop on Complex Networks CompleNet 2014, Springer, pages 261\u2013273.", "citeRegEx": "Perozzi et al\\.,? 2014", "shortCiteRegEx": "Perozzi et al\\.", "year": 2014}, {"title": "Mild cognitive impairment as a diagnostic entity", "author": ["Ronald C. Petersen."], "venue": "Journal of internal medicine 256(3):183\u2013194. https://doi.org/10.1111/j.13652796.2004.01388.x.", "citeRegEx": "Petersen.,? 2004", "shortCiteRegEx": "Petersen.", "year": 2004}, {"title": "Alignment of spoken narratives for automated neuropsychological assessment", "author": ["Emily T. Prud\u2019hommeaux", "Brian Roark"], "venue": "In Proceedings of Workshop on Automatic Speech Recognition & Understanding,ASRU", "citeRegEx": "Prud.hommeaux and Roark.,? \\Q2011\\E", "shortCiteRegEx": "Prud.hommeaux and Roark.", "year": 2011}, {"title": "Spoken language derived measures for detecting mild cognitive impairment", "author": ["Brian Roark", "Margaret Mitchell", "John-Paul Hosom", "Kristy Hollingshead", "Jeffrey Kaye."], "venue": "Transactions on Audio, Speech, and Language Processing, Institute of Elec-", "citeRegEx": "Roark et al\\.,? 2011", "shortCiteRegEx": "Roark et al\\.", "year": 2011}, {"title": "Prose and poetry classification and boundary", "author": ["Ranzivelle M. Roxas", "Giovanni Tapang"], "venue": null, "citeRegEx": "Roxas and Tapang.,? \\Q2010\\E", "shortCiteRegEx": "Roxas and Tapang.", "year": 2010}], "referenceMentions": [{"referenceID": 37, "context": "Therefore, the automatic analysis of discourse production is promising in diagnosing MCI at early stages, which may address potentially reversible factors (Muangpaisan et al., 2012).", "startOffset": 155, "endOffset": 181}, {"referenceID": 28, "context": "Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al.", "startOffset": 86, "endOffset": 155}, {"referenceID": 42, "context": "Proposals to detect language-related impairment in dementias include machine learning (Jarrold et al., 2010; Roark et al., 2011; Fraser et al., 2014, 2015), magnetic resonance imaging (Dyrba et al.", "startOffset": 86, "endOffset": 155}, {"referenceID": 20, "context": ", 2014, 2015), magnetic resonance imaging (Dyrba et al., 2015), and data screening tests added to demographic in-", "startOffset": 42, "endOffset": 62}, {"referenceID": 0, "context": ", 2016) and for Brazilian Portuguese (Alu\u0131\u0301sio et al., 2016).", "startOffset": 37, "endOffset": 60}, {"referenceID": 34, "context": "eas of NLP (Mihalcea and Radev, 2011), which may suffer less from the problems mentioned above, relies on the use of complex networks and graph theory.", "startOffset": 11, "endOffset": 37}, {"referenceID": 1, "context": ", 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al.", "startOffset": 51, "endOffset": 67}, {"referenceID": 7, "context": ", 2016) and related tasks, namely author detection (Amancio, 2015a), identification of literary movements (Amancio et al., 2012c), authenticity verification (Amancio et al.", "startOffset": 106, "endOffset": 129}, {"referenceID": 4, "context": ", 2012c), authenticity verification (Amancio et al., 2013) and word sense discrimination (Amancio et al.", "startOffset": 36, "endOffset": 58}, {"referenceID": 6, "context": ", 2013) and word sense discrimination (Amancio et al., 2012b).", "startOffset": 38, "endOffset": 61}, {"referenceID": 21, "context": "Linguistic and acoustic features were used to automatically detect aphasia (Fraser et al., 2014); and AD (Fraser et al.", "startOffset": 75, "endOffset": 96}, {"referenceID": 22, "context": ", 2014); and AD (Fraser et al., 2015) or dementia (Orimaye et al.", "startOffset": 16, "endOffset": 37}, {"referenceID": 38, "context": ", 2015) or dementia (Orimaye et al., 2014) in the public corpora of DementiaBank1.", "startOffset": 20, "endOffset": 42}, {"referenceID": 23, "context": "Other studies distinguished different types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery (Kertesz, 1982).", "startOffset": 56, "endOffset": 100}, {"referenceID": 27, "context": "Other studies distinguished different types of dementia (Garrard et al., 2014; Jarrold et al., 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery (Kertesz, 1982).", "startOffset": 56, "endOffset": 100}, {"referenceID": 30, "context": ", 2014), in which speech samples were elicited using the Picnic picture of the Western Aphasia Battery (Kertesz, 1982).", "startOffset": 103, "endOffset": 118}, {"referenceID": 18, "context": "Davy et al. (2016) also used", "startOffset": 0, "endOffset": 19}, {"referenceID": 42, "context": "As for automatic detection of MCI in narrative speech, Roark et al. (2011) extracted speech features and linguistic complexity measures of", "startOffset": 55, "endOffset": 75}, {"referenceID": 31, "context": ", 1997), and Lehr et al. (2012) fully automatized the WLM subtest.", "startOffset": 13, "endOffset": 32}, {"referenceID": 0, "context": "Alu\u0131\u0301sio et al. (2016) used a variety of linguistic metrics, such as syntactic complexity, idea density (da Cunha et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 8, "context": ", 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012).", "startOffset": 23, "endOffset": 71}, {"referenceID": 5, "context": ", 2016), summarization (Antiqueira et al., 2009; Amancio et al., 2012a) and word sense disambiguation (Silva and Amancio, 2012).", "startOffset": 23, "endOffset": 71}, {"referenceID": 32, "context": "modeling is adopted in related tasks (Machicao et al., 2016).", "startOffset": 37, "endOffset": 60}, {"referenceID": 1, "context": "As demonstrated by Amancio (2015c), classification of small texts using networks can be impaired, since short texts have al-", "startOffset": 19, "endOffset": 35}, {"referenceID": 35, "context": "To solve this problem, we adapted the approach of inducing language networks from word embeddings, proposed by Perozzi et al. (2014) to enrich the networks with semantic information.", "startOffset": 111, "endOffset": 133}, {"referenceID": 11, "context": "In their work, language networks were generated from continuous word representations, in which each word is represented by a dense, real-valued vector obtained by training neural networks in the language model task (or variations, such as context prediction) (Bengio et al., 2003; Collobert et al., 2011; Mikolov et al., 2013a,b). This structure is known to capture syntactic and semantic information. Perozzi et al. (2014), in particular, take advantage of word", "startOffset": 260, "endOffset": 424}, {"referenceID": 10, "context": "tia patients, including those with MCI (for further details see (Becker et al., 1994)).", "startOffset": 64, "endOffset": 85}, {"referenceID": 24, "context": "For this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al.", "startOffset": 120, "endOffset": 144}, {"referenceID": 24, "context": "For this dataset, interviews were conducted in English and narrative speech was elicited using the Cookie Theft picture (Goodglass et al., 2001) (Figure 3 from Goodglass et al. (2001) in Section A.", "startOffset": 121, "endOffset": 184}, {"referenceID": 0, "context": "Table 2 shows the demographic information of the two diagnostic groups, which were also used in Alu\u0131\u0301sio et al. (2016).", "startOffset": 96, "endOffset": 119}, {"referenceID": 40, "context": "The criteria used to diagnose MCI came from Petersen (2004). Diagnostics were carried out by a multidisciplinary team consisting of psychi-", "startOffset": 44, "endOffset": 60}, {"referenceID": 13, "context": "Other tests were applied after the narrative, in the following sequence: phonemic verbal fluency test, action verbal fluency, Camel and Cactus test (Bozeat et al., 2000), and Boston Naming test (Kaplan et al.", "startOffset": 148, "endOffset": 169}, {"referenceID": 29, "context": ", 2000), and Boston Naming test (Kaplan et al., 2001), in order to diagnose the groups.", "startOffset": 32, "endOffset": 53}, {"referenceID": 0, "context": "We also evaluated a different version of the dataset used in Alu\u0131\u0301sio et al. (2016), where narratives were manually annotated and revised to im-", "startOffset": 61, "endOffset": 84}, {"referenceID": 9, "context": "The subject then retold the narrative to the examiner twice: once immediately upon hearing it and again after a 30-minute delay (Bayles and Tomoeda, 1991).", "startOffset": 128, "endOffset": 154}, {"referenceID": 12, "context": "Since the occurrence of out-of-vocabulary words is common in texts of neuropsychological assessments, we used the method proposed by Bojanowski et al. (2016) to generate word embeddings.", "startOffset": 133, "endOffset": 158}, {"referenceID": 36, "context": "It provides some improvement in comparison with the traditional skip-gram model in terms of syntactic evaluation (Mikolov et al., 2013b) but not for semantic evaluation.", "startOffset": 113, "endOffset": 136}, {"referenceID": 14, "context": "PageRank: is a centrality measurement that reflects the relevance of a node based on its connections to other relevant nodes (Brin and Page, 1998);", "startOffset": 125, "endOffset": 146}, {"referenceID": 2, "context": "each node i possesses a valueXi, so we calculated the average \u03bc(X), standard deviation \u03c3(X) and skewness \u03b3(X) for each measurement (Amancio, 2015b).", "startOffset": 131, "endOffset": 147}, {"referenceID": 42, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 27, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 21, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 38, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 22, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 18, "context": "eral studies (Roark et al., 2011; Jarrold et al., 2014; Fraser et al., 2014; Orimaye et al., 2014; Fraser et al., 2015; Vincze et al., 2016; Davy et al., 2016).", "startOffset": 13, "endOffset": 159}, {"referenceID": 0, "context": "For Portuguese, Coh-Metrix-Dementia (Alu\u0131\u0301sio et al., 2016) was used.", "startOffset": 36, "endOffset": 59}, {"referenceID": 12, "context": "We used the model proposed by Bojanowski et al. (2016) with default parameters (100 dimensional embeddings, context window equal to 5 and 5 epochs) to generate word embedding.", "startOffset": 30, "endOffset": 55}, {"referenceID": 0, "context": "as reported in Alu\u0131\u0301sio et al. (2016), Table 7 shows that the manual revision was an important factor, since the highest accuracies were obtained with the approach based on linguistic metrics (LM).", "startOffset": 15, "endOffset": 38}, {"referenceID": 41, "context": "accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud\u2019hommeaux and Roark, 2011; Lehr et al., 2012; T\u00f3th et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish be-", "startOffset": 102, "endOffset": 192}, {"referenceID": 31, "context": "accuracies found here are comparable to the values reported by other authors, ranging from 60% to 85% (Prud\u2019hommeaux and Roark, 2011; Lehr et al., 2012; T\u00f3th et al., 2015; Vincze et al., 2016), which means that it is not easy to distinguish be-", "startOffset": 102, "endOffset": 192}], "year": 2017, "abstractText": "Mild Cognitive Impairment (MCI) is a mental disorder difficult to diagnose. Linguistic features, mainly from parsers, have been used to detect MCI, but this is not suitable for large-scale assessments. MCI disfluencies produce nongrammatical speech that requires manual or high precision automatic correction of transcripts. In this paper, we modeled transcripts into complex networks and enriched them with word embedding (CNE) to better represent short texts produced in neuropsychological assessments. The network measurements were applied with well-known classifiers to automatically identify MCI in transcripts, in a binary classification task. A comparison was made with the performance of traditional approaches using Bag of Words (BoW) and linguistic features for three datasets: DementiaBank in English, and Cinderella and Arizona-Battery in Portuguese. Overall, CNE provided higher accuracy than using only complex networks, while Support Vector Machine was superior to other classifiers. CNE provided the highest accuracies for DementiaBank and Cinderella, but BoW was more efficient for the Arizona-Battery dataset probably owing to its short narratives. The approach using linguistic features yielded higher accuracy if the transcriptions of the Cinderella dataset were manually revised. Taken together, the results indicate that complex networks enriched with embedding is promising for detecting MCI in large-scale assessments.", "creator": "LaTeX with hyperref package"}}}