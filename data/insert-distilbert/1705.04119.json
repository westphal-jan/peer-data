{"id": "1705.04119", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2017", "title": "Memetic search for identifying critical nodes in sparse graphs", "abstract": "critical node problems involve identifying a subset of eliminated critical nodes from an undirected graph whose removal results in optimizing a pre - defined measure over the residual graph. as useful models for a variety of practical applications, these problems are fairly computational challenging. in this early paper, we study the classic critical node problem ( cnp ) and introduce an effective memetic algorithm for solving cnp. the proposed algorithm combines a double backbone - based crossover operator ( to generate promising offspring content solutions ), a component - based neighborhood search compression procedure ( to find high - quality local optima ) and a rank - based pool updating strategy ( to guarantee a healthy population ). specially, the global component - based neighborhood search integrates two key techniques, i. e., two - phase node exchange strategy and node weighting scheme. obtaining the double backbone - based crossover extends the idea of general backbone - based crossovers. extensive evaluations on 42 synthetic and real - world benchmark instances show that the proposed algorithm discovers 21 new model upper bounds and matches 18 previous best - known upper bounds. we also demonstrate the relevance of adjusting our algorithm optimization for effectively solving a variant of the classic cnp, called the cardinality - constrained critical node problem. finally, we investigate the usefulness of each key algorithmic component.", "histories": [["v1", "Thu, 11 May 2017 11:43:30 GMT  (109kb)", "http://arxiv.org/abs/1705.04119v1", null], ["v2", "Sat, 7 Oct 2017 13:15:03 GMT  (119kb)", "http://arxiv.org/abs/1705.04119v2", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["yangming zhou", "jin-kao hao", "fred glover"], "accepted": false, "id": "1705.04119"}, "pdf": {"name": "1705.04119.pdf", "metadata": {"source": "CRF", "title": "Memetic search for identifying critical nodes in sparse graphs", "authors": ["Yangming Zhou", "Jin-Kao Hao", "Fred Glover"], "emails": ["yangming@info.univ-angers.fr", "jin-kao.hao@univ-"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 5.\n04 11\n9v 1\n[ cs\n.A I]\n1 1\nM ay\n2 01\n7 1\nIndex Terms\u2014Heuristics, memetic search, critical node problems, sparse graph.\nI. INTRODUCTION\nGiven an undirected graph G = (V,E) with vertex (node) set V and edge set E, critical node problems aim to delete a \u201climited\u201d subset of nodes S \u2286 V from G such that a predefined connectivity metric over the residual graphG[V \\S] (i.e., the sub-graph of G induced by V \\ S) is maximized or minimized. These deleted nodes in S are commonly called critical nodes.\nCNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17]. For instance, in a social network, each node corresponds to a person, edges represent some type of interactions between the individuals (e.g., friendship or collaboration), and critical nodes correspond to the \u201ckey players\u201d of the network (e.g., leaders of the organization or community) [9].\nY. Zhou and J.K. Hao (Corresponding author) are with the Computer Science Department, LERIA, Universite\u0301 d\u2019Angers, 2 Boulevard Lavoisier, 49045 Angers 01, France, J.K. Hao is also affiliated with the Institut Universitaire de France (E-mail: yangming@info.univ-angers.fr and jin-kao.hao@univangers.fr). F. Glover is with the University of Colorado, Leeds School of Business, Boulder, CO, USA.\nIn this work, we are interested in the classic critical node problem (denoted as CNP hereinafter), which involves optimizing a pair-wise connectivity measure in the residual graph, i.e., minimizing the total number of connected node pairs. CNP is known to be NP-hard on general graphs [5], even if there are polynomially solvable special cases [37]. The computational challenge and wide range of applications of CNP have motivated a variety of solution approaches in the literature, including exact algorithms and heuristic algorithms. Exact solution methods [5], [38], [44] guarantee the optimality of the solutions they find, but may fail on hard and large instances. Heuristic algorithms without guaranteed optimality of their solutions have also been studied to find good approximate solutions for large and hard instances within a reasonable computing time. For instance, an early heuristic starts with an independent set and uses a greedy criterion to remove vertices from the set [5]. Another greedy algorithm using a modified depth-first search is proposed in [43]. More recently, a number of metaheuristic algorithms have been reported for CNP, including iterated local search [3], [48], variable neighborhood search [3], multi-start greedy algorithm [33], greedy randomized adaptive search procedure with path relinking [34], and genetic algorithm [4].\nNeighborhood search plays a particularly important role in a metaheuristic search algorithm for CNP. In general, a neighborhood for CNP can be conveniently defined by the exchange (or swap) operation which exchanges a vertex in S against a vertex in V \\ S. However, this neighborhood has a quadratic size in terms of the number of nodes, making its exploration highly expensive.\nTo alleviate this difficulty and create an effective neighborhood search procedure, we propose a component-based neighborhood, which relies on a two-phase node exchange strategy and a node weighting technique. First, the two-phase node exchange strategy decomposes the exchange operation into two phases: a removal phase and an add phase, and performs them separately. Moreover, based on the fact that some swaps are irrelevant for optimizing the objective function, we constrain the exchange operations to some specific nodes (i.e., from large connected components in the residual graph). This constrained component-based neighborhood not only considerably reduces the number of candidate solutions to consider at each search iteration, but also makes the search more focused. Moreover, to make the node exchange operation efficient, we devise a node weighting technique to provide useful information for node selection within each exchange operation. Based on this component-based neighborhood, we introduce an effective local optimization procedure and apply\n2 it together with a double-backbone based crossover operator which can generate new promising offspring solutions from existing parent solutions. The whole algorithm (called MACNP for memetic algorithm for CNP), which also integrates a rank-based pool updating mechanism, proves to be highly effective for solving CNP. In addition, we extend the proposed algorithm to solve a cardinality constrained version of the classic CNP, i.e., the cardinality-constrained critical node problem (CC-CNP). We summarize our main contributions as follows.\n\u2022 First, the component-based neighborhood search proce-\ndure integrates two original ingredients, i.e., a two phase node exchange strategy and a node weighting scheme, which equips local optimization with a more focused and reduced neighborhood (Section III-D). The double backbone-based crossover operator extends the idea of backbone-based crossovers by adopting a double backbone structure (Section III-E). \u2022 The proposed MACNP algorithm yields highly competi-\ntive results compared with the state-of-the-art algorithms on both synthetic and real-world benchmarks. In particular, for the set of 16 synthetic instances, MACNP discovers 6 new upper bounds and matches the best known upper bounds for all 10 remaining instances. For the set of 26 real-world instances, MACNP attains 15 new upper bounds and matches 8 previous best-known upper bounds. Compared to the state-of-the-art algorithms, our algorithm also shows a superior performance on CC-CNP and achieves the best objective values on 39 out of 42 benchmark instances, yielding 22 new upper bounds.\nThe remainder of the paper is organized as follows. In Section I, we recapitulate the description of the critical node problem and indicate its relation to some other problems. In Section III, we describe the proposed MACNP algorithm. In Section IV, we present computational results for MACNP in comparison with the results of state-of-the-art algorithms. To show the generality of the proposed approach, we also verify its performance on the cardinality constrained critical node problem in Section V. In Section VI, we experimentally analyze several key ingredients of the proposed approach to understand their impacts on the performance of the algorithm. Concluding remarks are provided in the last section."}, {"heading": "II. PROBLEM DESCRIPTION AND NOTATION", "text": "Critical node problems in a graph G = (V,E) aim to delete a \u201climited\u201d subset of nodes S \u2286 V in order to maximize or minimize a pre-defined connectivity measure over the residual graph G[V \\ S]. Once the critical nodes have been removed, the residual graph G[V \\ S] can be represented by a set of connected components H = {C1, C2, . . . , CT }, where a connected component Ci is a set of nodes such that all nodes in this set are mutually connected (reachable by some paths), and no two nodes in different sets are connected.\nCritical node problems have been extensively investigated in the last decade, and different connectivity measures have been studied according to the particular interests. These connectivity measures can be divided into three categories:\n(i) To optimize the pair-wise connectivity, i.e., the total\nnumber of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4]. (ii) To optimize the size of the largest connected component\nin the residual graph [37], [45], [33], [4].\n(iii) To optimize the total number of connected components\nin the residual graph [37], [45], [4].\nHowever, most studies in the literature have focused on the classic critical node problem (denoted as CNP), which aims to minimize the pair-wise connectivity measure [5] and belongs to the first category mentioned above. Formally, given an integer K , CNP is to identify a subset S \u2286 V where |S| 6 K , such that the following pair-wise connectivity objective f(S) is minimized:\nf(S) = T \u2211\ni=1\n(\n|Ci|\n2\n)\n(1)\nwhere T is the total number of connected components Ci in the residual graph G[V \\ S]. CNP can be also considered as a problem of maximally fragmenting a graph and simultaneously minimizing the variance among the sizes of connected components in the residual graph. In other words, the resulting residual graph should be composed of a relatively large number of connected components while each connected component has a similar size [43].\nIn this paper, we focus on solving this classic critical node problem. In Section V, we also show the applicability of our memetic algorithm to solve an important variant of CNP, i.e., the cardinality-constrained critical node problem (CC-CNP) [6], which falls into the second category mentioned above.\nCNP is closely related to a variety of other NP-hard optimization problems. For example, the k-cut problem [24], which is a popular graph partitioning problem. Given an undirected weighted graph, the k-cut problem is to find a minimum cost set of edges that separates the graph into k connected components. Another similar problem is the minimum contamination problem, which minimizes the expected size of contamination by removing a set of edges of at most a given cardinality [28]."}, {"heading": "III. THE PROPOSED MEMETIC APPROACH FOR CNP", "text": "In this section, we present MACNP, an effective memetic algorithm for solving the classic critical node problem. The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13]. The memetic framework combines population-based search and singletrajectory local search to achieve a suitable balance between search intensification and diversification."}, {"heading": "A. Solution representation and evaluation", "text": "Given a graph G = (V,E) and an integer K (the maximum allowed number of nodes that can be removed), a feasible solution of CNP can be represented by S = {vS(1), vS(2), . . . , vS(K)} (1 6 S(i) 6= S(j) 6 |V | for all\n3 i 6= j) where S(l) (1 6 l 6 K) is the index of a selected node in S. Therefore, the whole solution space \u2126 contains all possible subsets S \u2286 V such that |S| 6 K . According to Equation (1), for a feasible solution S, the corresponding objective function value f(S) calculates the total number of node pairs still connected in the residual graph G[V \\ S]. f(S) can be computed with a modified depth-first search algorithm by identifying the connected components of a graph [26], requiringO(|V |+|E|) time. The modified depthfirst search algorithm works as follows. It finds the connected components of a graph by performing the depth-first search on each connected component. Each new node visited is marked. When no more nodes can be reached along the edges from the marked nodes, a connected component is found. Then, an unvisited node is selected, and the process is repeated until the entire graph is explored."}, {"heading": "B. General scheme", "text": "The proposed MACNP algorithm is composed of four main procedures: a population initialization procedure, a component-based neighborhood search procedure, a double backbone-based crossover procedure and a rank-based pool updating procedure. MACNP starts from a set of distinct elite individuals which are obtained by the population initialization procedure (Section III-C). At each generation, an offspring solution is generated by the double backbone-based crossover procedure (Section III-E). This offspring solution is further improved by the component-based neighborhood search procedure (Section III-D) and then considered for acceptance by the rank-based pool updating procedure (see Section III-F). The process is repeated until a stopping condition (e.g., time limit) is satisfied. The general framework of the proposed MACNP algorithm is presented in Algorithm 1 while its four procedures are respectively described in the following sections.\nAlgorithm 1 The proposed memetic algorithm for CNP\n1: Input: an undirected graph G = (V,E) and an integer K 2: Output: the best solution S\u2217 found so far\n// build an initial population, Section III-C 3: P = {S1, S2, . . . , Sp} \u2190 PoolInitialize() 4: S\u2217 = argmin{f1(S\ni) : i = 1, 2, . . . , p} 5: while a stopping condition is not reached do 6: randomly select two parent solutions Si and Sj from P // generate an offspring by crossover, Section III-E 7: S\u2032 \u2190 DoubleBackboneBasedCrossover(Si, Sj) // perform a local search, Section III-D 8: S\u2032 \u2190 ComponentBasedNeighborhoodSearch(S\u2032) 9: if f(S\u2032) < f(S\u2217) then\n10: S\u2217 = S\u2032 11: end if // insert or discard the improved solution, Section III-F 12: P \u2190 RankBasedPoolUpdating (P, S\u2032) 13: end while"}, {"heading": "C. Population initialization", "text": "Our MACNP algorithm starts its search with an initial population composed of diverse and high-quality solutions. To construct such a population, we first generate randomly\na feasible solution (i.e., any set of at most K nodes), and then we improve it by the component-based neighborhood search procedure described in Section III-D. We insert the improved solution into the population if it is different from the existing individuals of the population. Otherwise, we modify the improved solution with the exchange operation until it becomes different from all existing individuals before inserting it into the population. We repeat the procedure p times to fill the population with p distinct solutions."}, {"heading": "D. Component-based neighborhood search", "text": "To ensure an effective local optimization, MACNP employs a fast and effective component-based neighborhood search (denoted by CBNS) procedure (see Algorithm 2). CBNS integrates two key techniques, i.e., a two-phase node exchange strategy and a node weighting technique.\nAlgorithm 2 Component-based neighborhood search\n1: Input: a starting solution S 2: Output: the best solution S\u2217 found so far 3: S\u2217 \u2190 S 4: iter \u2190 0 5: while iter < MaxIter do 6: select a large component c at random 7: remove a node u from component c with the node weighting scheme 8: S \u2190 S \u222a {u} 9: v \u2190 argminw\u2208S{f(S \\ {w}) \u2212 f(S)}\n10: S \u2190 S \\ {v} 11: if f(S) < f(S\u2217) then 12: S\u2217 \u2190 S 13: iter \u2190 0 14: else 15: iter \u2190 iter + 1 16: end if 17: end while\n1) Component-based neighborhood structure: The performance of a local search procedure greatly depends on its neighborhood structure for candidate solution exploration. A traditional neighborhood for CNP is defined by the conventional exchange operator which swaps a node u \u2208 S with a node v \u2208 V \\ S [3], [2], [34], [41]. For a given solution, this neighborhood yieldsO(K(|V |\u2212K)) neighboring solutions. To evaluate a neighboring solution, no incremental technique is known and a full computation from scratch is required by running the modified depth-first search algorithm of complexity O(|V |+ |E|) [26]. Therefore, examining the whole neighborhood requires a time of O(K(|V | \u2212 K)(|V | + |E|)), which becomes too expensive when many local search iterations are performed (which is usually the case).\nTo overcome this limitation, we design a component-based neighborhood which is both smaller in size and more focused with respect to the optimization objective. Recall that CNP involves fragmenting the graph in order to minimize the total number of connected node pairs in the residual graphG[V \\S]. This can be achieved by fragmenting the largest connected components in the residual graph in order to obtain more homogeneous components, which helps to minimize the number of node pairs still connected. As a result, when exchanging a\n4 node u \u2208 S with a node v \u2208 V \\S, it is preferable to consider v \u2208 V \\ S from a large component (see Definition 1 below) instead of a small component. Let L be a predefined threshold to qualify large components. We consider only a subset of nodes Z \u2282 V \\S such that Z = \u222a|Ci|>LCi as candidate nodes for exchanges. Consequently, the neighborhood size is reduced to K|Z|, which is generally far smaller than K(|V | \u2212K) for reasonable L values we used in this paper. Definition 1 (large component): A connected component in the residual graph G[V \\ S] qualifies as a large component if the number of its nodes is greater than the predefined threshold L = (max nc +min nc)/2 \u2212 random(3), where max nc and min nc are respectively the number of nodes in the largest and smallest connected components in the residual graph G[V \\S], and the function random(i) returns a random integer in [0, . . . , i\u2212 1]. 2) Two-phase node exchange strategy: To further reduce the size of the above component-based neighborhood, we employ a two-phase node exchange strategy which relies on an extension of a candidate list strategy also called a neighborhood decomposition strategy or a successive filtration strategy [23], [35], [49]. The two-phase node exchange strategy breaks an exchange operation on a node pair into two distinct phases: a \u201cremoval phase\u201d removes a node from the residual graph and an \u201cadd phase\u201d adds a removed node back to the residual graph. This type of two-phase strategy is often used in conjunction with a candidate list approach in tabu search (see, e.g., [19]). In our case, the two-phase node exchange strategy first selects a component at random among the qualified large components and removes a node v from the selected component with the node weighting scheme. For the node u \u2208 S to be moved to the residual graph, we select the node which minimally deteriorates the objective function. With the help of the two-phase node exchange strategy, the computational effort required to examine the candidate solutions greatly decreases. Consider the CNP instance \u2018BA1000\u2019 with 1000 vertices and K = 75 as an example. Using the conventional exchange neighborhood requires consideration of (1000 \u2212 75) \u00d7 75 = 69375 candidate solutions. Instead, by adopting our two-phase node exchange strategy and only considering the qualified large connected components, only 75 \u226a 69375 candidate solutions need to be evaluated by our local search procedure because the process of removing a node from a connected component is performed regardless of its influence on the objective function. As we show in Section IV, the component-based neighborhood with the two-phase node exchange strategy makes the search much more efficient.\nThe two-phase exchange strategy yields an efficient neighborhood search, in which the process of selecting a node v to remove from G[V \\S] is performed regardless of its influence on the objective function. The process can be finished in O(T+nbrv), where T is the number of connected components in G[V \\ S] and nbrv is the length of the adjacency list of node v. Once a node is added into S, S is an infeasible solution (|S| = K + 1) and we need to remove a node u from S, where we select u to cause the minimum increase in the objective function. The evaluation of the increase in the objective function for each node in S is performed by scanning\nthe adjacency list of the node to determine if removing the node will re-connect some existing components to form a large component in the residual graphG[V \\S]. This operation requires time O(K \u2217 nbru) where nbru is the length of the adjacency list of node u.\n3) Node weighting scheme: The node weighting technique is the second useful technique we adopted in the componentbased neighborhood search. Weighting is a popular technique, which has been used in a number of heuristic algorithms, such as clause weighting for satisfiability problems [40], edge weighting for the minimum vertex cover problem [11], and row weighting for the set cover problem [18].\nOur node weighting scheme works as follows. Each node of a large component is associated with a positive integer as its weight, initialized to 0. At each step, we randomly select a component Ci among the large connected components, and select the node v in Ci with the largest weight (breaking ties in favor of the node with the largest degree) to move to S. Simultaneously, the weights of the remaining nodes in Ci are increased by one. Additionally, when a node v \u2208 Ci is exchanged with a node u \u2208 S, we set the weight of u to 0. With the help of the node weighting scheme, the \u201chard to remove\u201d nodes will have larger weights, and thus have a higher chance to be considered for removal from the component in the following iterations. The node weighting technique helps the search to escape from potential local optima. Our node weighing scheme follows the general penalty idea for constraint satisfaction problems, which was first used in this setting in Morris\u2019s breakout method [32]. We note that this scheme is also an instance of a tabu search frequency-based memory (see, e.g., the six frequency-based memory classes proposed earlier in [B] and their refinements in [22]). To the best of our knowledge, it is the first time that a node weight learning technique is applied to a heuristic procedure for CNP."}, {"heading": "E. Double backbone-based crossover", "text": "Crossover is another important ingredient of the MACNP algorithm. It should be noted that the meaning of crossover has changed from the genetic conception adopted in the early formulation of memetic algorithms. The modern conception embraces the principle of structured combinations introduced in [20], where solutions are combined by domain specific heuristics that map them into new solutions faithful to the structure of the problems considered. (A similar evolution in the notion of crossover has been occurring within genetic algorithms to incorporate the notion of structured combinations, although often incompletely.) As observed in [25], a successful crossover should be able to generate promising offspring solutions by inheriting good properties of the parents and introducing useful new features, while respecting the domain specific structure of the problem context . The concept of backbone has been used to design some successful crossover operators for subset selection problems [46], [49]. The critical node problem being a typical subset selection problem, we adopt the backbone idea and design a double backbonebased crossover operator to create structured combinations as follows.\n5 Let S1 and S2 be two solutions of CNP. According to Su\nand Sv, we divide the set of elements V into three subsets of common elements, unique elements and unrelated elements, as shown in Definition 2, 3 and 4 respectively.\nDefinition 2 (common elements): The set of common elements XA is the set of elements of V shared by S 1 and S2, i.e., XA = S 1 \u2229 S2.\nDefinition 3 (exclusive elements): The set of exclusive elements XB is the set of elements of V shared by either S1 or S2, i.e., XB = (S\n1 \u222a S2) \\ (S1 \u2229 S2) (the symmetric difference of S1 and S2). Definition 4 (excluding elements): The set of excluding elements XC is the set of elements of V which are not included in S1 and S2, i.e., XC = V \\ (S\n1 \u222a S2). From two parent solutions S1 and S2 randomly selected from the population P , an offspring solution S0 is constructed in three phases: (i) create a partial solution by inheriting all common elements (i.e., the first backbone), i.e., S0 \u2190 XA; (ii) add exclusive elements (i.e., the second backbone) into the partial solution in a probabilistic way. That is, for each exclusive element, we add it into S0 with probability p0 (0 < p0 < 1), otherwise we discard it; (iii) repair the partial solution structurally until a feasible solution is achieved. Specifically, if |S0| < K , we randomly add some elements to S0 from a random large connected component in the residual graph; Otherwise we greedily remove some elements from S0 until |S0| = K . The elements added in the first two phases form the whole backbone of the parent solutions. Therefore, the double backbones are composed of |XA| common elements (i.e., the first backbone) and about p0 \u2217 |XB| exclusive elements (i.e., the second backbone).\nThis double backbone-based crossover operator shares similar ideas with the crossovers proposed in [46], [49], i.e., directly inheriting all common elements from its parent solutions (see Definition 2). However, our double backbone based crossover operator distinguishes itself from these crossovers by adopting the double backbone structure. That is, it also directly inherits some exclusive elements (see Definition 3) with a selection probability p0. This strategy of combining solutions by introducing elements beyond their union is shared with the approach of exterior path relinking [21], which likewise has recently been found effective in discrete optimization."}, {"heading": "F. Rank-based pool updating", "text": "Each offspring solution is submitted for improvement by the component-based neighborhood search procedure presented in Section III-D. Then we use a rank-based pool updating strategy to decide whether the improved offspring solution S0 should be accepted in the population. This pool updating strategy resorts to a score function to evaluate each individual. The score function not only considers the quality of the offspring but also its average distance to other individuals in the population. This strategy is inspired by the population management strategies presented in [31], [13], [49].\nThe rank-based pool updating strategy applied in our algorithm is described in Algorithm 3. At first, we temporarily insert S0 to the population P (line 3 of Alg.3), then we\nevaluate all individuals of the population according to the score function [49] (lines 4-8 of Alg.3) and identify the worst solution Sw with the largest Score value (line 9 of Alg.3). Finally, if S0 is different from Sw, we replace Sw by S0. Otherwise, we discard S0 (lines 10-12 of Alg.3).\nAlgorithm 3 Rank-based pool updating strategy\n1: Input: a population P and an improved solution S0 2: Output: a new population P 3: P \u2032 \u2190 P \u222a {S0} 4: i \u2190 0 5: while i 6 p do 6: Evaluate individual Si according to the score function 7: i \u2190 i+ 1 8: end while 9: Identify the worst solution Sw in population P \u2032\ni.e., w \u2190 maxj\u2208{0,1,...,p} Score(S j , P \u2032)\n10: if w 6= 0 then 11: Replace Sw with S0, i.e., P \u2190 P \u2032 \\ {Sw} 12: end if"}, {"heading": "G. Computational complexity of MACNP", "text": "To analyze the computational complexity of the proposed MACNP algorithm, we consider the main steps in one generation in the main loop of Algorithm 1.\nAs displayed in Algorithm 1, at each generation, our MACNP algorithm consists of four subroutines: parent selection, double backbone-based crossover, component-based neighborhood search and rank-based pool updating. The parent selection is very simple and takes time O(1). The double backbone-based crossover operator can be realized in time O(|V |K2). The computational complexity of the componentbased neighborhood search is O(K(|V | + |E|)MaxIter, where MaxIter is the maximum allowable number of iterations without improvement. The rank-based pool updating can be achieved in time O(p(K2 + p)), where p is the population size. Hence, for each generation, the total complexity of MACNP is O(|V |K2 +K(|V |+ |E|)MaxIter)."}, {"heading": "IV. COMPUTATIONAL STUDIES", "text": "This section presents computational studies to evaluate the performance of our MACNP algorithm and compare it with state-of-the-art algorithms."}, {"heading": "A. Benchmark instances", "text": "Our computational studies were based on two benchmarks.1 Synthetic benchmark was originally presented in [41] and contains 16 instances classified into four categories: BarabasiAlbert (BA) graphs, Erdos-Renyi (ER) graphs, Forest-Fire (FF) graphs and Watts-Strogatz (WS) graphs.\nReal-world benchmark was first presented in [4] and consists of 26 real-world graphs from various practical applications, including protein interaction, the electronic circuit, flight network, train network, electricity distribution network, social network and etc.\n1Both synthetic and real-world benchmarks are publicly available at http://individual.utoronto.ca/mventresca/cnd.html and http://www.di.unito.it/\u223caringhie/cnp.html respectively.\n6\nIt is worth noting that both the benchmark instances are all\nsparse graphs. We use an indicator \u03b2 = 2|E|/(|V |(|V | + 1)) (0 < \u03b2 6 1) to measure the sparse degree of an instance, and we observe that \u03b2 6 0.045 holds for all instances."}, {"heading": "B. Experimental settings", "text": "The proposed algorithm was implemented in the C++ programming language and complied with gcc 4.1.2 and flag \u2018-O3\u2019. All the experiments were carried out on a computer equipped with an Intel E5-2670 processor with 2.5 GHz and 2 GB RAM operating under the Linux system. Without using any compiler flag, running the well-known DIMACS machine benchmark procedure dfmax.c2 on our machine requires 0.19, 1.17 and 4.54 seconds to solve the benchmark graphs r300.5, r400.5 and r500.5 respectively. Our computational results were obtained by running the MACNP algorithm with the parameter settings provided in Table I.\nFor our experiments, we adopted a cutoff time as the stopping condition, which is a standard practice for solving CNPs [3], [4], [34], [48]. Given its stochastic nature, the proposed algorithm was independently executed 30 times on each test instance like [41].\nTo analyze the experimental results, we resort to the wellknown two-tailed sign test [15] to check the significant difference on each comparison indicator between the compared algorithms. When two algorithms are compared, the corresponding null-hypothesis is that the algorithms are equivalent. The null-hypothesis is accepted if and only if each algorithm wins on approximately X/2 out of X instances. Since tied matches support the null-hypothesis, we split them evenly between the two compared algorithms, i.e., each one receives the value 0.5. At a significance level of 0.05, the Critical Values (CV) of the two-tailed sign test are respectively CV 160.05 = 12 and CV 200.05 = 18 when the number of instances in each benchmark is X = 16 and X = 26. Consequently, Algorithm A is significantly better than algorithm B if A wins at least CV X0.05 instances for a benchmark of X instances."}, {"heading": "C. Performance of the MACNP algorithm", "text": "Table II shows the computational results for MACNP on the synthetic and real-world benchmarks under the time limit tmax = 3600 seconds. Columns 1-3 respectively describe for each instance its name (Instance), the number of critical nodes (K) and the known best objective value (KBV ) reported in the literature. Columns 4-8 report the detailed results of MACNP, including the difference between the best objective value fbest\n2dfmax: ftp://dimacs.rutgers.edu/pub/dsj/clique\nand its known best value KBV (i.e., \u2206fbest = fbest\u2212KBV ), the difference between the average objective value favg and KBV (i.e., \u2206favg = favg\u2212KBV ), the average time to attain the objective value (tavg) and the average number of steps (i.e., exchanges) to achieve the objective value (#step).\nFrom Table II, we observe that MACNP is able to attain the best objective values for all 16 benchmark instances while yielding in particular 5 new upper bounds (see \u2206fbest < 0 in Table II). For instances ER2344 and WS250, our average objective values are also better than the previously best known upper bound (see \u2206favg < 0 in Table VII). To the best of our knowledge, our MACNP algorithm is the first heuristic which reaches the optimal solution 4545 of FF2000. The average time to find the optimal value 4545 is 107.6, which is far less than 5 days by the exact algorithm [38] (as reported in [3]). For the real-world benchmark, MACNP also shows a highly competitive performance and achieves the best objective value on 22 out of 26 instances, yielding 17 new upper bounds (see \u2206fbest < 0 in Table II) and matches 5 previous upper bounds\n7 (see \u2206fbest = 0 in Table II). Also, the average objective value achieved by our MACNP algorithm is better than the previous upper bound for 14 instances (see \u2206favg < 0 in Table II). However, MACNP failed to attain the known best value for three large instances (hepph, astroph,and condmat) within the time limit tmax = 3600 seconds. Indeed, this time limit is too short for the population-based MACNP algorithm to converge. Note that in [4], a large time limit of tmax = 16000 seconds was used. When we re-ran our MACNP algorithm under this condition, MACNP managed to find better solutions, including two new upper bounds (see results displayed in italic format in Table IV). This experiment demonstrates the effectiveness of our MACNP algorithm for solving the CNP on both the synthetic and real-world benchmarks."}, {"heading": "D. Comparison with the state-of-the-art algorithms", "text": "To further assess the performance of our MACNP algorithm, we carried out detailed comparisons between MACNP and state-of-the-art heuristic algorithms. We consider 7 reference algorithms, including the dynamic restarting greedy algorithms (Greedy3d and Greedy4d) [2], iterated local search (ILS) [3], variable neighborhood search (VNS) [3], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA1) [33] and a fast heuristic (FastCNP) [48].\nSince the source codes of CNA1 and FastCNP are available to us, we first make a detailed comparison between MACNP and these two reference algorithms. To make a fair comparison, all the three algorithms were run on our platform with the same time limit tmax = 3600 seconds, and each algorithm was executed 30 trials to solve each instance. The comparative results are shown in Table III. In this table, the first column provides the name of each instance (Instance), Columns 2- 5 report the results of the CNA1 algorithm, including the best objective value (fbest), the average objective value (favg), the average time to attain the objective value (tavg) and the number of steps to achieve the objective value (#step). Correspondingly, columns 6-9 and columns 10-13 respectively represent the results of algorithms FastCNP and MACNP. The best values of the compared results are in bold, and when the same best objective values are achieved, fewer steps are underlined (which indicates a better performance in terms of computational efficiency). In addition, we give the number of instances (wins) for which our algorithm obtained a better performance (i.e., fbest and favg) compared to the corresponding algorithms. The win values for indicators tavg and #steps are meaningless and are marked by \u2018*\u2019.\nFrom Table III, we observe that our MACNP algorithm significantly outperforms CNA1 and FastCNP, achieving the best objective values for 38 out of the 42 instances, and the best average objective values for 37 out of 42 instances. For the synthetic benchmark, MACNP is significantly better than CNA1 in terms of the best objective value, winning 12.5 instances (i.e., 12.5 > CV 160.05 = 12). Compared to FastCNP, MACNP is also very competitive and wins 10.5 instances, which is slightly smaller than the critical value CV 160.05 = 12. As to the average objective value, MACNP significantly outperforms both CNA1 and FastCNP by winning\n13 instances. For the real-world benchmark, MACNP also proves to be significantly better than CNA1 and FastCNP both in terms of the best objective value and the average objective value. Moreover, for the 14 instances where all three algorithms attain the same best objective values, our MACNP algorithm needs the least number of steps to reach its results (see values underlined).\nWe also compared our MACNP algorithm with five additional algorithms reported in the literature. As the source code of these five reference algorithms is not available, we used their best results reported in the corresponding papers. Fortunately, these five algorithms have been evaluated on the same platform (i.e., an HP ProLiant DL585 G6 server with two 2.1 GHz AMD Opteron 8425HE processors and 16 GB of RAM) [3], [4], which is slower than our machine with a factor 0.84 according to the Standard Performance Evaluation Corporation (www.spec.org). However, their results were obtained under a longer time limit, i.e., tmax \u2208 (7200, 10000] for the most of the synthetic instances and tmax \u2208 [3000, 16000] for most of the real-world instances. Note that, in our comparison, we do not consider the simulated annealing algorithm [41], the population-based incremental learning algorithm [41], and the greedy randomized adaptive search procedure with path relinking [34] because they are completely dominated by FastCNP proposed in [48].\nThe comparative results of MACNP with the seven stateof-the-art heuristic algorithms on the synthetic and real-world benchmarks are summarized in Table IV. Note that the result of \u201cBest ILS\u201d for each instance is the best result among 6 ILS variants, and \u201cBest VNS\u2019 corresponds to the best result among all 24 VNS variants [3].\nTable IV shows that our MACNP algorithm attains the best results for all instances. Specifically, MACNP finds 6 new upper bounds and reaches the best objective values for the remaining 10 instances. MACNP is significantly better than the reference algorithms except for FastCNP, respectively winning 15.0, 15.0, 12.5, 15.5, 12.0, 12.5 compared to Greedy3d, Greedy4d, Best VNS, Best ILS, GA, and CNA1. Compared to FastCNP, MACNP wins 10.5 instances, which is just slightly smaller than the critical value CV 160.05 = 12. These observations indicate that compared to the state-of-the-art algorithms, our MACNP algorithm is highly competitive for solving the synthetic instances.\nSimilar observations are found on the real-world benchmark in Table IV. MACNP significantly outperforms the reference algorithms, respectively winning 24.0, 24.0, 24.5, 22.5, 23.5, 21.0, 21.0 instances with respect to the reference algorithms Greedy3d, Greedy4d, Best VNS, Best ILS, GA, CNA1, and FastCNP. Specifically, MACNP achieves the best objective values for 21 out of the 26 real-world instances, including 13 new upper bounds and 8 known best objective values."}, {"heading": "V. APPLICATION TO THE CARDINALITY-CONSTRAINED CRITICAL NODE PROBLEM", "text": "In this section, we show that our algorithm can also be used to solve other critical node problem, by testing MACNP on the cardinality-constrained critical node problem (CC-CNP).\n8\nThe experiments were again conducted on the synthetic and real-world benchmarks described in Section IV-A."}, {"heading": "A. Cardinality-constrained critical node problem", "text": "CC-CNP is a cardinality constrained version of the classic CNP [6]. CC-CNP aims to identify a minimum subset S \u2286 V such that any connected component in the residual graph G[V \\ S] contains at most W nodes where W is a given threshold value.\nTo approximate K\u2217, we solve a series of CC-CNP with decreasing K > K\u2217 values. For a fixed K , we try to find a set S \u2286 V of K nodes, whose removal minimizes the number of nodes in each connected component which exceeds the cardinality threshold W . For this purpose, we define an\nauxiliary (minimization) function f \u2032:\nf \u2032(S) = T \u2211\ni=1\nmax(|Ci| \u2212W, 0) (2)\nwhich calculates the total number of nodes in excess of W in all T connected components of the residual graph. It is clear that if f \u2032(S) = 0, then S is a feasible solution of CC-CNP."}, {"heading": "B. Solving CC-CNP with MACNP", "text": "To solve CC-CNP, we adapt MACNP slightly and denote the new algorithm by MACC-CNP. Basically, we replace the objective function f used in MACNP with the minimization function f \u2032 defined by Equation (2). To solve CC-CNP, we start with an initial K value (obtained with a construction method, see below), and apply MACC-CNP to find a set S of K nodes whose removal minimizes the number of exceeded\n9\nnodes (i.e., minimizing f \u2032(S)). If f \u2032(S) = 0, then S is a feasible solution of CC-CNP. At this moment, we decrease K by one and solve the problem again. We repeat this process until no feasible solution can be found and report the last S found with f \u2032(S) = 0. This general solution procedure is inspired by a popular approach for solving the classic graph coloring problem [31], [47].\nThe initial K value is obtained with an initial feasible solution S0. We first set S0 to be empty. Then we iteratively pick a node v from a large connected component whose cardinality exceeds W and move v to S0. We repeat this process until a feasible solution S0 is obtained (i.e., f \u2032(S0) = 0, meaning that all components contain at most W nodes). We set the initial K to equal |S0|."}, {"heading": "C. Comparison with the state-of-the-art algorithms", "text": "Based on the synthetic and real-world benchmarks, we compared our MACC-CNP algorithm with the five state-ofthe-art algorithms: greedy algorithms (G1 and G2) [4], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA2)\n[33], fast heuristic (FastCNP) [48]. Among these reference algorithms, FastCNP was originally proposed for the classic critical node problem, and we adapted it for solving CC-CNP in the same way as for MACNP. The source code of CNA2 was provided by its author [33]. For algorithms G1, G2 and GA, whose source codes are not available, we used the results reported in [4]. These results have been obtained with different time limits tmax \u2208 [100, 16000] seconds, which are, for most instances, larger than our time limit of tmax = 3600 seconds. For our comparative study, we ran CNA2 and FastCNP with their default parameters under the time limit tmax = 3600 seconds, and each instance was solved 30 times. For our MACC-CNP algorithm, we also solved each instance 30 times independently under the same time limit.\nThe comparative results of running our MACC-CNP algorithm against the reference algorithms on the synthetic and real-world benchmarks are displayed in Table V. To analyze these results, we calculated the number of instances (wins) in which MACC-CNP proved superior according to the twotailed sign test [15], as shown in the last row for each\n10\nbenchmark.\nTABLE V COMPARISON BETWEEN MACC\u2212 CNP AND THE STATE-OF-THE-ART ALGORITHMS ON SYNTHETIC AND REAL-WORLD BENCHMARKS.\nInstance L KBV G1 G2 GA CNA2 FA\u25e6 MA\u22c4\nBA500 4 47 47 47 47 47 47 47 BA1000 5 61 61 61 61 61 61 61 BA2500 10 100 101 100 100 100 100 100 BA5000 13 149 154 151 149 149 149 149 ER235 7 47 49 50 47 47 47 47 ER466 14 81 86 85 81 79 79 79\u22c6 ER941 25 139 149 152 139 141 135 135\u22c6\nER2344 1400 204 252 270 204 194 189 185\u22c6\nFF250 5 48 48 49 48 48 48 48 FF500 4 100 102 102 100 100 100 100 FF1000 7 142 145 145 142 142 142 142 FF2000 12 182 191 187 182 182 182 182 WS250 40 73 79 80 72 71 70 70\u22c6\nWS500 15 126 145 144 126 124 123 123\u22c6 WS1000 500 162 195 418 162 180 166 157\u22c6\nWS1500 30 278 339 332 278 273 256 254\u22c6\nwins 11.5 14.5 14.5 11.5 11.0 9.5 *\nBovine 15 4 4 4 4 4 4 4 Circuit 30 24 25 26 24 24 24 24 E.coli 20 15 16 15 15 15 15 15 USAir97 70 33 34 40 33 33 33 33 HumanDi 10 49 51 50 49 49 49 49 TreniR 10 28 30 31 28 27 27 27 EU fli 850 113 127 118 113 113 112 112 openfli 140 184 194 206 184 183 180 180 yeast1 6 195 202 199 195 193 193 193 H1000 800 103 172 151 103 97 95 92\u22c6 H2000 1600 221 362 313 221 207 195 188\u22c6 H3000a 2500 279 448 402 279 276 252 242\u22c6 H3000b 2500 279 456 401 279 270 251 244\u22c6 H3000c 2500 276 446 404 276 274 250 244\u22c6 H3000d 2500 276 452 402 276 272 250 244\u22c6 H3000e 2500 280 455 403 280 270 252 244\u22c6 H4000 3300 398 651 571 398 388 354 347\u22c6 H5000 4200 458 745 662 458 459 413 410\u22c6 powergr 20 428 449 440 428 430 397 397\u22c6 Oclinks 1100 197 209 200 197 193 193 192\u22c6 faceboo 450 324 472 821 324 523 375 378 grqc 20 480 497 501 480 486 462 461\u22c6 hepth 70 981 1040 1042 981 1029 955 944\u22c6 hepph 3600 1228 1416 1572 1228 1103 994 1120\u22c6 astroph 12000 1322 3284 1769 1322 1364 1249 1329 condmat 500 2506 2506 2651 2506 2357 2357 2320\u22c6\nwins 21.5 25.5 25.0 21.5 22.5 19.0 * \u22c6 Improved best upper bounds. \u25e6 We adapted the FastCNP algorithm [48] for solving CC-CNP, and the new algorithm is denoted by FastCC-CNP (FA). \u22c4 The proposed MACC-CNP (MA) algorithm.\nAs indicated in Table V, MACC-CNP achieves the best objective values for all synthetic instances, and yielding in particular 2 new upper bounds. At a significance level of 0.05, MACC-CNP is significantly better than G1 and G2. For algorithms GA, CNA2 and FastCNP, MACNP is better but the differences are not significant, winning 11.5, 11.0 and 9.5 instances. We also observe that MACC-CNP is very effective on the real-world benchmark. For this benchmark, at a significance level 0.05, our MACC-CNP algorithm significantly outperforms all reference algorithms. Specifically, MACC-CNP discovers new upper bounds for 15 instances and reaches the known best upper bounds on 8 out of 11 remaining instances. These observations show that MACC-CNP is also highly competitive compared to state-of-the-art algorithms for solving CC-CNP."}, {"heading": "VI. DISCUSSION", "text": "We now analyze the key ingredients of the proposed MACNP algorithm: the two-phase node exchange strategy and node weighting scheme used in the component-based neighborhood search (Sections VI-A and VI-B) and the backbonebased crossover (Section VI-C). Based on the classic critical node problem, the experiments were carried out on 4 representative synthetic instances from different families (BA5000, ER941, FF500 and WS250) as well as 4 representative realworld instances (TreniR, H3000a, H4000 and hepth). These instances cover different classes with different sizes and have different levels of difficulties. For each algorithm variant, we ran it on each instance 15 times with a time limit tmax = 3600 seconds."}, {"heading": "A. Benefit of the two-phase node exchange strategy", "text": "Our component-based neighborhood search decomposes the exchanging procedure into two phases, i.e., the \u201cadd-phase\u201d and \u201cremoval-phase\u201d, and performs them separately. To investigate the benefit of the two-phase node exchange strategy, we compare MACNP with an alternative algorithm MACNP0 which uses the conventional two node exchange strategy to swap a node u \u2208 S (S being the current solution) with a node v \u2208 V \\ S. MACNP0 and MACNP share thus the same components except the neighborhood.\nTABLE VI COMPARATIVE PERFORMANCE OF MACNP WITH MACNP0 .\nMACNP0 MACNP\nInstance fbest favg steps\nsec fbest favg\nsteps\nsec\nBA5000 3083 3257.7 37.6 3083 3101.1 59954.5 ER941 257 257.0 134.9 257 257.0 21445.3 FF500 5014 5171.1 5.8 5012 5013.7 29428.5 WS250 10198 10200.8 1.5 10196 10196.0 5708.9 TreniR 918 918.0 1322.5 918 918.0 102275.0 H3000a 3451908 3483709.9 < 0.1 2849170 2883554.5 3909.4 H4000 6165357 6224768.6 < 0.1 5081209 5144354.2 2117.6 hepth 23964174 24528095.0 < 0.1 106552 108354.0 1100.8\nThe comparative results for MACNP and MACNP0 are summarized in Table VI. In this table, for each instance, we report the best objective value (fbest), the average objective value (favg), and the average number of steps per second ( steps\nsec ) over 15 trials achieved by each algorithm. The comparative results show that MACNP performs significantly better thanMACNP0 in terms of all comparison indicators primarily due to its much lower computational complexity per step. In each second, MACNP is able to perform seventy or even tens of thousands times more steps than that of MACNP0."}, {"heading": "B. Effectiveness of the node weighting scheme", "text": "To assess the effectiveness of the node weighting scheme in the component-based neighborhood search (CBNS), we compared our MACNP algorithm with its alternative algorithm MACNP1 where the node weighting scheme is disabled in CBNS. In MACNP1, we also decompose the exchanging operation into two phases (\u201cadd-phase\u201d and \u201cremoval-phase\u201d), and execute them separately. However, for \u201cadd-phase\u201d, a\n11\nnode is randomly removed from a large connected component instead of selecting the node by the node weighting scheme.\nTable VII shows the comparative results of MACNP and MACNP1 on the tested instances, based on four indicators: best objective value (fbest), average objective value (favg), average time to find the best objective value (tavg), average number of steps required to find the objective value (#steps). An obvious observation from this table is that the algorithm with the node weighting scheme (i.e., MACNP) significantly outperforms MACNP1 (which lacks the node weighting scheme) on almost all instances except WS250. For WS250, both MACNP and MACNP1 achieve the best objective value 3083, while the average objective value 3093.8 of MACNP1 is slightly better than 3101.1 of MACNP. More importantly, MACNP needs less time and fewer steps to achieve the best objective values. These observations demonstrate the effectiveness of the node weighting scheme."}, {"heading": "C. Rationale behind the double backbone-based crossover", "text": "As introduced in Section III-E, we specially designed a double backbone-based crossover operator to generate offspring solutions. To investigate the rationale behind this crossover, we compare MACNP with an alternative version MACNP2. MACNP2 is obtained from MACNP by replacing our dedicated backbone-based crossover with a single backbone-based crossover which only treats the common elements as the backbone. Specifically, the single backbone-based crossover operator first constructs a partial solution S0 by directly inheriting all the common elements of two parent solutions and then completes the partial solution S0 by removing a node from a large component of the residual graph until |S0| = K . Comparative performance of MACNP and its alternative MACNP2 in terms of the best objective value and average objective value are displayed in the left and right part of Figure 1 respectively. The X-axis indicates the instance, and the Yaxis shows the gap between our results (eight best values or average values) to the known best values in percentage, which is defined as (f \u2212 KBV ) \u00d7 100/KBV where f is the best objective value or average objective value, and KBV is the known best objective (see 3rd column of Table IV). A gap smaller than zero means the algorithm obtains a new upper bound for the corresponding instance.\nFrom Figure 1, we observe that compared to MACNP2, our MACNP algorithm is able to attain a better fbest for all 8 instances including 4 new upper bounds (see values below 0 on the left part of Figure 1). MACNP also outperformsMACNP2 on all 8 tested instances in terms of the average objective value (favg), as shown in the right part of Figure 1. This experiment confirms the value of our double backbone-based crossover."}, {"heading": "VII. CONCLUSIONS AND FUTURE WORK", "text": "In this work, we proposed an effective memetic search approach for solving the classic critical node problem (MACNP), which combines a component-based neighborhood search for local optimization, a double backbone-based crossover operator for solution recombination and a rank-based pool updating strategy to guarantee a healthy diversity of the population. To\nensure its effectiveness, the component-based neighborhood search relies on a focused and reduced neighborhood owing to its two-phase node exchange strategy and the node weighting scheme. Additionally, the double backbone-based crossover not only conserves solution features from the parent solutions, but also introduces diversity by including exclusive elements from parent solutions in a probabilistic way.\nTo demonstrate the competitiveness of the proposed algorithm, we evaluated MACNP on a broad range of synthetic and real-world benchmarks. The computational results showed that MACNP significantly outperforms state-of-the-art algorithms on both two benchmarks. We also assessed the performance of MACNP for solving the cardinality-constrained critical node problem (MACC-CNP), which is an important variant of the classic CNP. Our results showed that the approach is also highly competitive compared with state-of-the-art algorithms. Finally, we performed experiments to investigate the benefit of different search components and techniques.\nFuture work motivated by our findings will be to investigate opportunities for further improving the performance of our algorithm by incorporating machine learning techniques (e.g. reinforcement learning and opposition-based learning). Another inviting avenue for research is to adapt the proposed approach to solve other critical node problems with different measures (e.g. distance-based connectivity and betweenness centrality)."}, {"heading": "ACKNOWLEDGMENT", "text": "We would like to thank Dr. W. Pullan for kindly sharing the\nsource codes of the CNA1 and CNA2 algorithms."}], "references": [{"title": "Identifying critical nodes in undirected graphs: Complexity results and polynomial algorithms for the case of bounded treewidth", "author": ["B. Addis", "M. Di Summa", "A. Grosso"], "venue": "Discrete Applied Mathematics, 161(16):2349\u20132360, 2013.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2013}, {"title": "Hybrid constructive heuristics for the critical node problem", "author": ["B. Addis", "R. Aringhieri", "A. Grosso", "P. Hosteins"], "venue": "Annals of Operations Research, 238(1-2):637\u2013649, 2016.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "A general evolutionary framework for different classes of critical node problems", "author": ["R. Aringhieri", "A. Grosso", "P. Hosteins", "R. Scatamacchia"], "venue": "Engineering Applications of Artificial Intelligence, 55:128\u2013145, 2016.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Detecting critical nodes in sparse graphs", "author": ["A. Arulselvan", "C.W. Commander", "L. Elefteriadou", "P.M. Pardalos"], "venue": "Computers & Operations Research, 36(7):2193\u20132200, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Cardinality-constrained critical node detection problem", "author": ["A. Arulselvan", "C.W. Commander", "O. Shylo", "P.M. Pardalos"], "venue": "Springer Optimization and Its Applications,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "A multilevel memetic approach for improving graph k-partitions", "author": ["U. Benlic", "J.-K. Hao"], "venue": "IEEE Transactions on Evolutionary Computation, 15(5):624\u2013642, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Identifying critical nodes in protein\u2013protein interaction networks", "author": ["V. Boginski", "C.W. Commander"], "venue": "Clustering Challenges in Biological Networks, pp. 153\u2013167, 2009.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Identifying sets of key players in a social network", "author": ["S.P. Borgatti"], "venue": "Computational & Mathematical Organization Theory, 12(1):21\u201334, 2006.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Local search with edge weighting and configuration checking heuristics for minimum vertex cover", "author": ["S. Cai", "K. Su", "A. Sattar"], "venue": "Artificial Intelligence, 175(9):1672 \u2013 1696, 2011.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Two weighting local search for minimum vertex cover.", "author": ["S. Cai", "J. Lin", "K. Su"], "venue": "Proceedings of the AAAI-2015,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "System vulnerability assessment and critical nodes identification", "author": ["X. Chen"], "venue": "Expert Systems with Applications, 65:212\u2013220, 2016.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "Memetic search for the generalized quadratic multiple knapsack problem", "author": ["Y. Chen", "J.K. Hao"], "venue": "IEEE Transactions on Evolutionary Computation, 20(6):908\u2013923, 2016.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "The wireless network jamming problem", "author": ["C.W. Commander", "P.M. Pardalos", "V. Ryabchenko", "S. Uryasev", "G. Zrazhevsky"], "venue": "Journal of Combinatorial Optimization, 14(4):481\u2013498, 2007.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Statistical comparisons of classifiers over multiple data sets", "author": ["J. Dem\u0161ar"], "venue": "Journal of Machine Learning Research, 7:1\u201330, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "On new approaches of assessing network vulnerability: hardness and approximation", "author": ["T.N. Dinh", "Y. Xuan", "M.T. Thai", "P.M. Pardalos", "T. Znati"], "venue": "IEEE/ACM Transactions on Networking, 20(2):609\u2013 619, 2012.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Robust optimization of graph partitioning and critical node detection in analyzing networks", "author": ["N. Fan", "P.M. Pardalos"], "venue": "Lecture Notes in Computer Science, 6508:170\u2013183. 2010.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "An efficient local search heuristic with row weighting for the unicost set covering problem", "author": ["C. Gao", "X. Yao", "T. Weise", "J. Li"], "venue": "European Journal of Operational Research, 246(3):750\u2013761, 2015.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Tabu search: A tutorial", "author": ["F. Glover"], "venue": "Interfaces, 20(1)74\u201394, 1990.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1990}, {"title": "Tabu search for nonlinear and parametric optimization (with links to genetic algorithms)", "author": ["F. Glover"], "venue": "Discrete Applied Mathematics, 49:231\u2013 255, 1994.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1994}, {"title": "Exterior path relinking for zero-one optimization", "author": ["F. Glover"], "venue": "International Journal of Applied Metaheuristic Computing, 5(3):1\u20138, 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Tabu Search", "author": ["F. Glover", "M. Laguna"], "venue": "C. Reeves (Ed.) Modern Heuristic Techniques for Combinatorial Problems, Blackwell Scientific Publishing, pp. 71\u2013140, 1993.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1993}, {"title": "A user\u2019s guide to tabu search", "author": ["F. Glover", "E. Taillard", "E. Taillard"], "venue": "Annals of Operations Research, 41(1):1\u201328, 1993.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1993}, {"title": "Approximation algorithms for minimum k-cut", "author": ["N. Guttmann-Beck", "R. Hassin"], "venue": "Algorithmica, 27(2):198\u2013207, 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "Memetic algorithms in discrete optimization", "author": ["J.-K. Hao"], "venue": "Handbook of Memetic Algorithms. Studies in Computational Intelligence 379,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Algorithm 447: Efficient algorithms for graph manipulation", "author": ["J. Hopcroft", "R. Tarjan"], "venue": "Communications of the ACM, 16(6):372\u2013378, 1973.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1973}, {"title": "Finding critical nodes for inhibiting diffusion of complex contagions in social networks", "author": ["C.J. Kuhlman", "V.S. Anil Kumar", "M.V. Marathe", "S.S. Ravi", "D.J. Rosenkrantz"], "venue": "Lecture Notes in Computer Science, 6322:111\u2013127, 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Existence theorems and approximation algorithms for generalized network security games", "author": ["V.A. Kumar", "R. Rajaraman", "Z. Sun", "R. Sundaram"], "venue": "Proc. of 2010 IEEE 30th International Conference on Distributed Computing Systems, IEEE, 2010, pp. 348\u2013357.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J. Vanbriesen", "N. Glance"], "venue": "Proc. of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 420\u2013429, 2007.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimizing network attacks by artificial bee colony", "author": ["M. Lozano", "C. Garc\u0131\u0301a-Mart\u0131\u0301nez", "F.J. Rodr\u0131\u0301guez", "H.M. Trujillo"], "venue": "Information Sciences, 377:30 \u2013 50, 2017.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2017}, {"title": "A memetic algorithm for graph coloring", "author": ["Z. L\u00fc", "J.-K. Hao"], "venue": "European Journal of Operational Research, 203(1):241\u2013250, 2010.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "The breakout method for escaping from local minima", "author": ["P. Morris"], "venue": "Proceedings of the 11th AAAI, USA, July 11-15, 1993, pp. 40\u201345, 1993.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 1993}, {"title": "Heuristic identification of critical nodes in sparse real-world graphs", "author": ["W. Pullan"], "venue": "Journal of Heuristics, 21(5):577\u2013598, 2015.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Heuristic algorithm for identifying critical nodes in graphs", "author": ["D. Purevsuren", "G. Cui", "N.N.H. Win", "X. Wang"], "venue": "Advances in Computer Science : an International Journal, 5(3):1\u20134, 2016.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2016}, {"title": "Tabu search candidate list strategies in scheduling", "author": ["B. Rangaswamy", "A.S. Jain", "F. Glover"], "venue": "Operations Research/Computer Science Interfaces Series, 9:15\u2013233, 1998.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1998}, {"title": "On the discovery of critical links and nodes for assessing network vulnerability", "author": ["Y. Shen", "N.P. Nguyen", "Y. Xuan", "M.T. Thai"], "venue": "IEEE/ACM Transactions on Networking, 21(3):963\u2013973, 2013.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2013}, {"title": "Polynomial-time algorithms for solving a class of critical node problems on trees and series-parallel graphs", "author": ["S. Shen", "J.C. Smith"], "venue": "Networks, 60(2):103\u2013119, 2012.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}, {"title": "Branch and cut algorithms for detecting critical nodes in undirected graphs", "author": ["M.D. Summa", "A. Grosso", "M. Locatelli"], "venue": "Computational Optimization and Applications, 53(3):649\u2013680, 2012.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2012}, {"title": "Studying connectivity properties in human protein\u2013protein interaction network in cancer", "author": ["V. Tomaino", "A. Arulselvan", "P. Veltri", "P.M. Pardalos"], "venue": "pathway,\u201c Optimization and Its Applications,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}, {"title": "Clause weighting local search for sat", "author": ["J. Thornton"], "venue": "Journal of Automated Reasoning, 35(1-3):97\u2013142, 2005.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2005}, {"title": "Global search algorithms using a combinatorial unranking-based problem representation for the critical node detection problem", "author": ["M. Ventresca"], "venue": "Computers & Operations Research, 39(11):2763\u20132775, 2012.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 2012}, {"title": "A derandomized approximation algorithm for the critical node detection problem", "author": ["M. Ventresca", "D.M. Aleman"], "venue": "Computers & Operations Research, 43:261\u2013270, 2014.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2014}, {"title": "Efficiently identifying critical nodes in large complex networks", "author": ["M. Ventresca", "D. Aleman"], "venue": "Computational Social Networks, 2(1): 6, 2015.", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2015}, {"title": "Exact identification of critical nodes in sparse networks via new compact formulations", "author": ["A. Veremyev", "V. Boginski", "E.L. Pasiliao"], "venue": "Optimization Letters, 8(4):1245\u20131259, 2014.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2014}, {"title": "An integer programming framework for critical elements detection in graphs", "author": ["A. Veremyev", "O.A. Prokopyev", "E.L. Pasiliao"], "venue": "Journal of Combinatorial Optimization, 28(1):233\u2013273, 2014.  13", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2014}, {"title": "A hybrid metaheuristic method for the maximum diversity problem", "author": ["Q. Wu", "J.-K. Hao"], "venue": "European Journal of Operational Research, 231(2):452\u2013464, 2013.", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2013}, {"title": "Reinforcement learning based local search for grouping problems: A case study on graph coloring", "author": ["Y. Zhou", "J.-K. Hao", "B. Duval"], "venue": "Expert Systems with Applications, 64:412\u2013422, 2016.", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2016}, {"title": "A fast heuristic algorithm for the critical node probelm", "author": ["Y. Zhou", "J.K. Hao"], "venue": "to appear in Genetic and Evolutionary Computation Conference Companion (GECOO\u201917), Berlin, Germany, July 15-19, 2017, (2 pages short paper).", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2017}, {"title": "Opposition-based memetic search for the maximum diversity problem", "author": ["Y. Zhou", "J.K. Hao", "B. Duval"], "venue": "IEEE Transactions on Evolutionary Computation, DOI: 10.1109/TEVC.2017.2674800, 2017. (in press).", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2017}], "referenceMentions": [{"referenceID": 34, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 95, "endOffset": 99}, {"referenceID": 10, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 101, "endOffset": 105}, {"referenceID": 40, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 6, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 158, "endOffset": 161}, {"referenceID": 37, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 163, "endOffset": 167}, {"referenceID": 3, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 190, "endOffset": 193}, {"referenceID": 25, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 195, "endOffset": 199}, {"referenceID": 12, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 224, "endOffset": 228}, {"referenceID": 28, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 246, "endOffset": 250}, {"referenceID": 7, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 279, "endOffset": 282}, {"referenceID": 27, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 284, "endOffset": 288}, {"referenceID": 15, "context": "CNPs have natural applications in a number of fields, such as network vulnerability assessment [36], [12], epidemic control [42], biological molecule studies [8], [39], network immunization [5], [27], network communications [14], network attacks [30] and social network analysis [9], [29], [17].", "startOffset": 290, "endOffset": 294}, {"referenceID": 7, "context": ", leaders of the organization or community) [9].", "startOffset": 44, "endOffset": 47}, {"referenceID": 3, "context": "CNP is known to be NP-hard on general graphs [5], even if there are polynomially solvable special cases [37].", "startOffset": 45, "endOffset": 48}, {"referenceID": 35, "context": "CNP is known to be NP-hard on general graphs [5], even if there are polynomially solvable special cases [37].", "startOffset": 104, "endOffset": 108}, {"referenceID": 3, "context": "Exact solution methods [5], [38], [44] guarantee the optimality of the solutions they find, but may fail on hard and large instances.", "startOffset": 23, "endOffset": 26}, {"referenceID": 36, "context": "Exact solution methods [5], [38], [44] guarantee the optimality of the solutions they find, but may fail on hard and large instances.", "startOffset": 28, "endOffset": 32}, {"referenceID": 42, "context": "Exact solution methods [5], [38], [44] guarantee the optimality of the solutions they find, but may fail on hard and large instances.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "For instance, an early heuristic starts with an independent set and uses a greedy criterion to remove vertices from the set [5].", "startOffset": 124, "endOffset": 127}, {"referenceID": 41, "context": "Another greedy algorithm using a modified depth-first search is proposed in [43].", "startOffset": 76, "endOffset": 80}, {"referenceID": 46, "context": "More recently, a number of metaheuristic algorithms have been reported for CNP, including iterated local search [3], [48], variable neighborhood search [3], multi-start greedy algorithm [33], greedy randomized adaptive search procedure with path relinking [34], and genetic algorithm [4].", "startOffset": 117, "endOffset": 121}, {"referenceID": 31, "context": "More recently, a number of metaheuristic algorithms have been reported for CNP, including iterated local search [3], [48], variable neighborhood search [3], multi-start greedy algorithm [33], greedy randomized adaptive search procedure with path relinking [34], and genetic algorithm [4].", "startOffset": 186, "endOffset": 190}, {"referenceID": 32, "context": "More recently, a number of metaheuristic algorithms have been reported for CNP, including iterated local search [3], [48], variable neighborhood search [3], multi-start greedy algorithm [33], greedy randomized adaptive search procedure with path relinking [34], and genetic algorithm [4].", "startOffset": 256, "endOffset": 260}, {"referenceID": 2, "context": "More recently, a number of metaheuristic algorithms have been reported for CNP, including iterated local search [3], [48], variable neighborhood search [3], multi-start greedy algorithm [33], greedy randomized adaptive search procedure with path relinking [34], and genetic algorithm [4].", "startOffset": 284, "endOffset": 287}, {"referenceID": 3, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 79, "endOffset": 82}, {"referenceID": 14, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 90, "endOffset": 93}, {"referenceID": 43, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 95, "endOffset": 99}, {"referenceID": 41, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 101, "endOffset": 105}, {"referenceID": 31, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 107, "endOffset": 111}, {"referenceID": 1, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 113, "endOffset": 116}, {"referenceID": 32, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 118, "endOffset": 122}, {"referenceID": 2, "context": ", the total number of pairs of nodes connected by a path in the residual graph [5], [16], [1], [45], [43], [33], [2], [34], [3], [4].", "startOffset": 129, "endOffset": 132}, {"referenceID": 35, "context": "(ii) To optimize the size of the largest connected component in the residual graph [37], [45], [33], [4].", "startOffset": 83, "endOffset": 87}, {"referenceID": 43, "context": "(ii) To optimize the size of the largest connected component in the residual graph [37], [45], [33], [4].", "startOffset": 89, "endOffset": 93}, {"referenceID": 31, "context": "(ii) To optimize the size of the largest connected component in the residual graph [37], [45], [33], [4].", "startOffset": 95, "endOffset": 99}, {"referenceID": 2, "context": "(ii) To optimize the size of the largest connected component in the residual graph [37], [45], [33], [4].", "startOffset": 101, "endOffset": 104}, {"referenceID": 35, "context": "(iii) To optimize the total number of connected components in the residual graph [37], [45], [4].", "startOffset": 81, "endOffset": 85}, {"referenceID": 43, "context": "(iii) To optimize the total number of connected components in the residual graph [37], [45], [4].", "startOffset": 87, "endOffset": 91}, {"referenceID": 2, "context": "(iii) To optimize the total number of connected components in the residual graph [37], [45], [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 3, "context": "However, most studies in the literature have focused on the classic critical node problem (denoted as CNP), which aims to minimize the pair-wise connectivity measure [5] and belongs to the first category mentioned above.", "startOffset": 166, "endOffset": 169}, {"referenceID": 41, "context": "In other words, the resulting residual graph should be composed of a relatively large number of connected components while each connected component has a similar size [43].", "startOffset": 167, "endOffset": 171}, {"referenceID": 4, "context": ", the cardinality-constrained critical node problem (CC-CNP) [6], which falls into the second category mentioned above.", "startOffset": 61, "endOffset": 64}, {"referenceID": 22, "context": "For example, the k-cut problem [24], which is a popular graph partitioning problem.", "startOffset": 31, "endOffset": 35}, {"referenceID": 26, "context": "Another similar problem is the minimum contamination problem, which minimizes the expected size of contamination by removing a set of edges of at most a given cardinality [28].", "startOffset": 171, "endOffset": 175}, {"referenceID": 29, "context": "The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13].", "startOffset": 142, "endOffset": 146}, {"referenceID": 5, "context": "The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13].", "startOffset": 164, "endOffset": 167}, {"referenceID": 44, "context": "The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13].", "startOffset": 187, "endOffset": 191}, {"referenceID": 47, "context": "The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13].", "startOffset": 193, "endOffset": 197}, {"referenceID": 11, "context": "The memetic framework is a powerful general method which has been successfully applied to solve many NP-hard problems, such as graph coloring [31], graph partition [7], maximum diversity [46], [49] and quadratic knapsack [13].", "startOffset": 221, "endOffset": 225}, {"referenceID": 24, "context": "f(S) can be computed with a modified depth-first search algorithm by identifying the connected components of a graph [26], requiringO(|V |+|E|) time.", "startOffset": 117, "endOffset": 121}, {"referenceID": 1, "context": "A traditional neighborhood for CNP is defined by the conventional exchange operator which swaps a node u \u2208 S with a node v \u2208 V \\ S [3], [2], [34], [41].", "startOffset": 136, "endOffset": 139}, {"referenceID": 32, "context": "A traditional neighborhood for CNP is defined by the conventional exchange operator which swaps a node u \u2208 S with a node v \u2208 V \\ S [3], [2], [34], [41].", "startOffset": 141, "endOffset": 145}, {"referenceID": 39, "context": "A traditional neighborhood for CNP is defined by the conventional exchange operator which swaps a node u \u2208 S with a node v \u2208 V \\ S [3], [2], [34], [41].", "startOffset": 147, "endOffset": 151}, {"referenceID": 24, "context": "To evaluate a neighboring solution, no incremental technique is known and a full computation from scratch is required by running the modified depth-first search algorithm of complexity O(|V |+ |E|) [26].", "startOffset": 198, "endOffset": 202}, {"referenceID": 21, "context": "2) Two-phase node exchange strategy: To further reduce the size of the above component-based neighborhood, we employ a two-phase node exchange strategy which relies on an extension of a candidate list strategy also called a neighborhood decomposition strategy or a successive filtration strategy [23], [35], [49].", "startOffset": 296, "endOffset": 300}, {"referenceID": 33, "context": "2) Two-phase node exchange strategy: To further reduce the size of the above component-based neighborhood, we employ a two-phase node exchange strategy which relies on an extension of a candidate list strategy also called a neighborhood decomposition strategy or a successive filtration strategy [23], [35], [49].", "startOffset": 302, "endOffset": 306}, {"referenceID": 47, "context": "2) Two-phase node exchange strategy: To further reduce the size of the above component-based neighborhood, we employ a two-phase node exchange strategy which relies on an extension of a candidate list strategy also called a neighborhood decomposition strategy or a successive filtration strategy [23], [35], [49].", "startOffset": 308, "endOffset": 312}, {"referenceID": 17, "context": ", [19]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 38, "context": "Weighting is a popular technique, which has been used in a number of heuristic algorithms, such as clause weighting for satisfiability problems [40], edge weighting for the minimum vertex cover problem [11], and row weighting for the set cover problem [18].", "startOffset": 144, "endOffset": 148}, {"referenceID": 9, "context": "Weighting is a popular technique, which has been used in a number of heuristic algorithms, such as clause weighting for satisfiability problems [40], edge weighting for the minimum vertex cover problem [11], and row weighting for the set cover problem [18].", "startOffset": 202, "endOffset": 206}, {"referenceID": 16, "context": "Weighting is a popular technique, which has been used in a number of heuristic algorithms, such as clause weighting for satisfiability problems [40], edge weighting for the minimum vertex cover problem [11], and row weighting for the set cover problem [18].", "startOffset": 252, "endOffset": 256}, {"referenceID": 30, "context": "Our node weighing scheme follows the general penalty idea for constraint satisfaction problems, which was first used in this setting in Morris\u2019s breakout method [32].", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": ", the six frequency-based memory classes proposed earlier in [B] and their refinements in [22]).", "startOffset": 90, "endOffset": 94}, {"referenceID": 18, "context": "The modern conception embraces the principle of structured combinations introduced in [20], where solutions are combined by domain specific heuristics that map them into new solutions faithful to the structure of the problems considered.", "startOffset": 86, "endOffset": 90}, {"referenceID": 23, "context": ") As observed in [25], a successful crossover should be able to generate promising offspring solutions by inheriting good properties of the parents and introducing useful new features, while respecting the domain specific structure of the problem context .", "startOffset": 17, "endOffset": 21}, {"referenceID": 44, "context": "The concept of backbone has been used to design some successful crossover operators for subset selection problems [46], [49].", "startOffset": 114, "endOffset": 118}, {"referenceID": 47, "context": "The concept of backbone has been used to design some successful crossover operators for subset selection problems [46], [49].", "startOffset": 120, "endOffset": 124}, {"referenceID": 44, "context": "This double backbone-based crossover operator shares similar ideas with the crossovers proposed in [46], [49], i.", "startOffset": 99, "endOffset": 103}, {"referenceID": 47, "context": "This double backbone-based crossover operator shares similar ideas with the crossovers proposed in [46], [49], i.", "startOffset": 105, "endOffset": 109}, {"referenceID": 19, "context": "This strategy of combining solutions by introducing elements beyond their union is shared with the approach of exterior path relinking [21], which likewise has recently been found effective in discrete optimization.", "startOffset": 135, "endOffset": 139}, {"referenceID": 29, "context": "This strategy is inspired by the population management strategies presented in [31], [13], [49].", "startOffset": 79, "endOffset": 83}, {"referenceID": 11, "context": "This strategy is inspired by the population management strategies presented in [31], [13], [49].", "startOffset": 85, "endOffset": 89}, {"referenceID": 47, "context": "This strategy is inspired by the population management strategies presented in [31], [13], [49].", "startOffset": 91, "endOffset": 95}, {"referenceID": 47, "context": "3), then we evaluate all individuals of the population according to the score function [49] (lines 4-8 of Alg.", "startOffset": 87, "endOffset": 91}, {"referenceID": 39, "context": "Synthetic benchmark was originally presented in [41] and contains 16 instances classified into four categories: BarabasiAlbert (BA) graphs, Erdos-Renyi (ER) graphs, Forest-Fire (FF) graphs and Watts-Strogatz (WS) graphs.", "startOffset": 48, "endOffset": 52}, {"referenceID": 2, "context": "Real-world benchmark was first presented in [4] and consists of 26 real-world graphs from various practical applications, including protein interaction, the electronic circuit, flight network, train network, electricity distribution network, social network and etc.", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "For our experiments, we adopted a cutoff time as the stopping condition, which is a standard practice for solving CNPs [3], [4], [34], [48].", "startOffset": 124, "endOffset": 127}, {"referenceID": 32, "context": "For our experiments, we adopted a cutoff time as the stopping condition, which is a standard practice for solving CNPs [3], [4], [34], [48].", "startOffset": 129, "endOffset": 133}, {"referenceID": 46, "context": "For our experiments, we adopted a cutoff time as the stopping condition, which is a standard practice for solving CNPs [3], [4], [34], [48].", "startOffset": 135, "endOffset": 139}, {"referenceID": 39, "context": "Given its stochastic nature, the proposed algorithm was independently executed 30 times on each test instance like [41].", "startOffset": 115, "endOffset": 119}, {"referenceID": 13, "context": "To analyze the experimental results, we resort to the wellknown two-tailed sign test [15] to check the significant difference on each comparison indicator between the compared algorithms.", "startOffset": 85, "endOffset": 89}, {"referenceID": 36, "context": "\u2217 Optimal results obtained by exact algorithm [38] within 5 days.", "startOffset": 46, "endOffset": 50}, {"referenceID": 36, "context": "6, which is far less than 5 days by the exact algorithm [38] (as reported in [3]).", "startOffset": 56, "endOffset": 60}, {"referenceID": 2, "context": "Note that in [4], a large time limit of tmax = 16000 seconds was used.", "startOffset": 13, "endOffset": 16}, {"referenceID": 1, "context": "We consider 7 reference algorithms, including the dynamic restarting greedy algorithms (Greedy3d and Greedy4d) [2], iterated local search (ILS) [3], variable neighborhood search (VNS) [3], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA1) [33] and a fast heuristic (FastCNP) [48].", "startOffset": 111, "endOffset": 114}, {"referenceID": 2, "context": "We consider 7 reference algorithms, including the dynamic restarting greedy algorithms (Greedy3d and Greedy4d) [2], iterated local search (ILS) [3], variable neighborhood search (VNS) [3], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA1) [33] and a fast heuristic (FastCNP) [48].", "startOffset": 212, "endOffset": 215}, {"referenceID": 31, "context": "We consider 7 reference algorithms, including the dynamic restarting greedy algorithms (Greedy3d and Greedy4d) [2], iterated local search (ILS) [3], variable neighborhood search (VNS) [3], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA1) [33] and a fast heuristic (FastCNP) [48].", "startOffset": 253, "endOffset": 257}, {"referenceID": 46, "context": "We consider 7 reference algorithms, including the dynamic restarting greedy algorithms (Greedy3d and Greedy4d) [2], iterated local search (ILS) [3], variable neighborhood search (VNS) [3], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA1) [33] and a fast heuristic (FastCNP) [48].", "startOffset": 289, "endOffset": 293}, {"referenceID": 2, "context": "1 GHz AMD Opteron 8425HE processors and 16 GB of RAM) [3], [4], which is slower than our machine with a factor 0.", "startOffset": 59, "endOffset": 62}, {"referenceID": 39, "context": "Note that, in our comparison, we do not consider the simulated annealing algorithm [41], the population-based incremental learning algorithm [41], and the greedy randomized adaptive search procedure with path relinking [34] because they are completely dominated by FastCNP proposed in [48].", "startOffset": 83, "endOffset": 87}, {"referenceID": 39, "context": "Note that, in our comparison, we do not consider the simulated annealing algorithm [41], the population-based incremental learning algorithm [41], and the greedy randomized adaptive search procedure with path relinking [34] because they are completely dominated by FastCNP proposed in [48].", "startOffset": 141, "endOffset": 145}, {"referenceID": 32, "context": "Note that, in our comparison, we do not consider the simulated annealing algorithm [41], the population-based incremental learning algorithm [41], and the greedy randomized adaptive search procedure with path relinking [34] because they are completely dominated by FastCNP proposed in [48].", "startOffset": 219, "endOffset": 223}, {"referenceID": 46, "context": "Note that, in our comparison, we do not consider the simulated annealing algorithm [41], the population-based incremental learning algorithm [41], and the greedy randomized adaptive search procedure with path relinking [34] because they are completely dominated by FastCNP proposed in [48].", "startOffset": 285, "endOffset": 289}, {"referenceID": 4, "context": "CC-CNP is a cardinality constrained version of the classic CNP [6].", "startOffset": 63, "endOffset": 66}, {"referenceID": 36, "context": "\u2217 Optimal results obtained by exact algorithm [38] within 5 days.", "startOffset": 46, "endOffset": 50}, {"referenceID": 29, "context": "This general solution procedure is inspired by a popular approach for solving the classic graph coloring problem [31], [47].", "startOffset": 113, "endOffset": 117}, {"referenceID": 45, "context": "This general solution procedure is inspired by a popular approach for solving the classic graph coloring problem [31], [47].", "startOffset": 119, "endOffset": 123}, {"referenceID": 2, "context": "Based on the synthetic and real-world benchmarks, we compared our MACC-CNP algorithm with the five state-ofthe-art algorithms: greedy algorithms (G1 and G2) [4], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA2) [33], fast heuristic (FastCNP) [48].", "startOffset": 157, "endOffset": 160}, {"referenceID": 2, "context": "Based on the synthetic and real-world benchmarks, we compared our MACC-CNP algorithm with the five state-ofthe-art algorithms: greedy algorithms (G1 and G2) [4], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA2) [33], fast heuristic (FastCNP) [48].", "startOffset": 185, "endOffset": 188}, {"referenceID": 31, "context": "Based on the synthetic and real-world benchmarks, we compared our MACC-CNP algorithm with the five state-ofthe-art algorithms: greedy algorithms (G1 and G2) [4], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA2) [33], fast heuristic (FastCNP) [48].", "startOffset": 226, "endOffset": 230}, {"referenceID": 46, "context": "Based on the synthetic and real-world benchmarks, we compared our MACC-CNP algorithm with the five state-ofthe-art algorithms: greedy algorithms (G1 and G2) [4], genetic algorithm (GA) [4], multi-start greedy algorithm (CNA2) [33], fast heuristic (FastCNP) [48].", "startOffset": 257, "endOffset": 261}, {"referenceID": 31, "context": "The source code of CNA2 was provided by its author [33].", "startOffset": 51, "endOffset": 55}, {"referenceID": 2, "context": "For algorithms G1, G2 and GA, whose source codes are not available, we used the results reported in [4].", "startOffset": 100, "endOffset": 103}, {"referenceID": 13, "context": "To analyze these results, we calculated the number of instances (wins) in which MACC-CNP proved superior according to the twotailed sign test [15], as shown in the last row for each", "startOffset": 142, "endOffset": 146}, {"referenceID": 46, "context": "\u25e6 We adapted the FastCNP algorithm [48] for solving CC-CNP, and the new algorithm is denoted by FastCC-CNP (FA).", "startOffset": 35, "endOffset": 39}], "year": 2017, "abstractText": "Critical node problems involve identifying a subset of critical nodes from an undirected graph whose removal results in optimizing a pre-defined measure over the residual graph. As useful models for a variety of practical applications, these problems are computational challenging. In this paper, we study the classic critical node problem (CNP) and introduce an effective memetic algorithm for solving CNP. The proposed algorithm combines a double backbone-based crossover operator (to generate promising offspring solutions), a component-based neighborhood search procedure (to find high-quality local optima) and a rank-based pool updating strategy (to guarantee a healthy population). Specially, the component-based neighborhood search integrates two key techniques, i.e., two-phase node exchange strategy and node weighting scheme. The double backbone-based crossover extends the idea of general backbonebased crossovers. Extensive evaluations on 42 synthetic and realworld benchmark instances show that the proposed algorithm discovers 21 new upper bounds and matches 18 previous bestknown upper bounds. We also demonstrate the relevance of our algorithm for effectively solving a variant of the classic CNP, called the cardinality-constrained critical node problem. Finally, we investigate the usefulness of each key algorithmic component.", "creator": "gnuplot 4.6 patchlevel 4"}}}