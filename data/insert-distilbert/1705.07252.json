{"id": "1705.07252", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2017", "title": "SVM via Saddle Point Optimization: New Bounds and Distributed Algorithms", "abstract": "support vector machine is one of the most classical approaches for classification and regression. despite being often studied successfully for decades, obtaining practical algorithms explicitly for svm is currently still an active research problem in machine learning. in this paper, often we excitedly propose a new perspective alternative for svm detection via saddle point optimization. basically we provide an algorithm which achieves $ ( 1 - \\ epsilon ) $ - 100 approximations with running time $ \\ tilde { o } ( nd + n \\ sqrt { d / \\ epsilon } ) $ for both separable ( hard margin svm ) and non - separable cases ( $ \\ nu $ - epsilon svm ), where $ n $ is the number of points and $ d $ is the dimensionality. but to assure the absolute best of our knowledge, the current best algorithm applying for an hard run margin svm achieved by gilbert algorithm ~ \\ cite { gartner2009coresets } requires $ o ( nd / \\ epsilon ) $ time. modifying our algorithm improves the running time achieved by averaging a factor of $ \\ sqrt { d } / \\ sqrt { \\ epsilon } $. for $ \\ nu $ - svm, extends besides the well known quadratic programming approach which requires $ \\ omega ( c n ^ 2 \u2265 d ) $ time ~ \\ cite { joachims1998making, platt199912 }, although no better algorithm is known. in obtaining the paper, we provide the above first nearly linear time algorithm for $ \\ nu $ - svm. we also consider converting the distributed settings data and provide distributed algorithms with low communication cost utilization via saddle point comparison optimization. our algorithms must require $ \\ tilde { 1st o } ( k ( d + \\ sqrt { d / \\ epsilon } ) ) $ communication cost where $ k $ 1 is the number of clients, almost matching the only theoretical estimate lower bound.", "histories": [["v1", "Sat, 20 May 2017 03:06:13 GMT  (1558kb,D)", "https://arxiv.org/abs/1705.07252v1", "20 pages"], ["v2", "Tue, 23 May 2017 07:09:30 GMT  (0kb,I)", "http://arxiv.org/abs/1705.07252v2", "Error for template"], ["v3", "Wed, 24 May 2017 05:40:16 GMT  (1555kb,D)", "http://arxiv.org/abs/1705.07252v3", null]], "COMMENTS": "20 pages", "reviews": [], "SUBJECTS": "cs.LG cs.NA", "authors": ["yifei jin", "lingxiao huang", "jian li"], "accepted": false, "id": "1705.07252"}, "pdf": {"name": "1705.07252.pdf", "metadata": {"source": "CRF", "title": "SVM via Saddle Point Optimization: New Bounds and Distributed Algorithms", "authors": ["Yifei Jin", "Lingxiao Huang", "Jian Li"], "emails": [], "sections": [{"heading": null, "text": "), where n is the number of points and d is the dimensionality. To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time. Our algorithm improves the running time by a factor of \u221a d/ \u221a . For \u03bd-SVM, besides the well known quadratic programming approach which requires \u2126(n2d) time [21, 31], no better algorithm is known. In the paper, we provide the first nearly linear time algorithm for \u03bd-SVM. We also consider the distributed settings and provide distributed algorithms with low communication cost via saddle point optimization. Our algorithms require O\u0303(k(d+\u221a d/ )) communication cost where k is the number of clients, almost matching the theoretical lower bound."}, {"heading": "1 Introduction", "text": "Support Vector Machine (SVM) is a fundamental model for classification and regression [7, 11], widely used in many areas such as nature language process, computer vision, and bioinformatics. Consider a set of instance-label pairs (xi, yi) for i \u2208 [n], xi \u2208 Rd, yi \u2208 {\u00b11}. In the hard-margin scenario in which all labeled points are linearly separable, the goal of SVM is to find a separating hyperplane such that points with different labels are separated by the hyperplane, and the margin of separation is maximized. Several SVM variants have been designed to handle linearly non-separable cases (see [16]). The common strategy for these variants is to add a penalty term for the misclassified points. The most common penalty terms are l1- and l2-losses. The corresponding SVM variant for l2-loss is called l2-SVM or the standard version SVM in the literature. Theoretically, l1-loss penalty may be more robust in the presence of the outliers [42]. There are two well-known l1-loss SVMs called C-SVM and \u03bd-SVM\nar X\niv :1\n70 5.\n07 25\n2v 3\n[ cs\n.L G\n] 2\n4 M\nrespectively. In comparison to C-SVM, which uses the l1-loss as the penalty term directly, the penalty term of \u03bd-SVM is somewhat more complicated. \u03bd-SVM is first proposed by Sch\u00f6lkopf and Smola [34]. The advantage of \u03bd-SVM is that the parameter \u03bd has a clearer meaning, which is always between [0, 1].1 Moreover, Sch\u00f6lkopf et al. [34] showed that \u03bd is an upper bound on the fraction of margin errors and a lower bound on the fraction of support vectors.\nIn general, SVM and its variants can be formulated as convex quadratic programs. It takesO(n2d) time by solving quadratic programs directly [21, 31]. QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on. However, the quadratic running time limits SVM to be used in much larger data sets. There are several improvements for some specific settings. For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1\u2212 )-approximation with O(nd/ \u03b22) running time where \u03b2 is the distance between the two polytopes of the two types of points after we scale all points in a unit ball. For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2]. However, these techniques cannot be extended to \u03bd-SVM directly because \u03bdSVM cannot be transformed to single-objective unconstrained optimization problems. Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for \u03bd-SVM.\nDistributed SVM has also attracted significant attention in recent years. The most popular distributed model is to store data in distributed sites, and those sites collaboratively solve the algorithmic problem of interest by communicating with each other through network links. A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40]. Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details). For distributed hard-margin SVM, recently, Liu et al. [25] proposed a distributed algorithm with O(kd/ ) communication cost, where k is the number of the clients.\nOur Contributions: We summarize our main contributions as follows.\n1. Hard-Margin SVM: Inspired by the recent work of Zhang and Lin [41] and Allen-Zhu et al. [3], we propose a new perspective for solving hard-margin SVM via saddle point optimization. From the geometric point of view, it is known that training an SVM is equivalent to computing the polytope distance between two sets of points. We show that this view can be translated to a saddle point optimization problem. Then, we provide a new (1\u2212 )-approximation algorithm with running time O\u0303(nd+ n \u221a d/ \u221a \u03b2) 2 to solve the saddle point optimization,\nwhere n is the number of points, d is the dimension and \u03b2 is a lower bound of the margin after scaling points to a unit ball. Compared to Gilbert algorithm [16], our algorithm improves the running time by a factor of \u221a d/ \u221a .\n1 On the contrary, the range of parameter C in C-SVM is from zero to infinity 2O\u0303 notation hides logarithm factors such as log(n), log(\u03b2) and log(1/ ).\n2. \u03bd-SVM: Different from other geometric methods such as Gilbert algorithm, our algorithm can be extended to an important linearly non-separable scenario, \u03bdSVM. It is known that \u03bd-SVM is equivalent to computing the distance between two reduced polytopes [5, 12]. The obstacle for providing an efficient algorithm based on the reduced polytopes is that the number of vertices in the reduced polytopes may be exponentially large. However, in our framework, we do not need to compute the reduced polytopes explicitly. Instead, we only need to implicitly represent the reduced polytopes. We show that using the similar saddle point optimization framework, together with a projection method, \u03bd-SVM can be solved efficiently by the same time complexity as the hard-margin case. Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n. To the best of our knowledge, this is the first nearly linear time algorithm for \u03bd-SVM. The experimental result shows that our algorithm is much faster than the previous QP based algorithm NuSVC, implemented in scikit-learn [30].\n3. Distributed SVM: We also consider the distributed setting and provide a distributed algorithm for SVM with low communication cost. For hard-margin SVM, Liu et al. [25] proposed a distributed algorithm withO(kd/ ) communication cost where k is the number of the clients. We improve their result through adapting our saddle point optimization algorithms to the distributed setting. Note that our distributed algorithm works for both hard-margin SVM and \u03bd-SVM. The communication cost of our algorithm is O\u0303(k(d+ \u221a d/ )), which is significantly\nbetter than the previous one if is very small and d is large. Moreover, this communication cost is almost optimal according to the lower bound provided in [25].\nThe paper is organized as follows. In Section 2.1, we prove that hard-margin SVM and \u03bd-SVM are equivalent to saddle point optimization problems. Then we present our algorithms to solve the saddle point optimization problems and analyze the running time in Section 2.2. In Section 3, we provide the distributed version of our algorithms and analyze its communication complexity. In Section 4, we provide the experimental results, including our algorithm of \u03bd-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16]. Due to space constraints, we defer many proof details and some experimental results to the appendix.\nRelated Work: Two important variants C-SVM and l2-SVM have been well studied in the literature. Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37]. Recently, Allen-Zhu [2] provided the current best algorithms which achieve O(nd/ \u221a ) time for l2-SVM and O(nd/ ) time for C-SVM.\nAllen-Zhu et al. [3] used the saddle point optimization and obtained an O\u0303(nd + n \u221a d/ \u221a ) algorithm for the minimum enclosing ball problem (MinEB) in Euclidean space. This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]). Based on Tsang et al. [38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.\nHowever, it maps the d-dimensional points to the (d + n)-dimensional space. Thus, we need quadratic time to solve l2-SVM by this mapping. To avoid this mapping, they designed an algorithm called Core Vector Machine (CVM), in which they solve O(1/ ) MinEB problems sequentially. Under this framework, it seems impossible to achieve an algorithm for l2-SVM with running time better than O(nd/ )."}, {"heading": "2 Saddle Point Optimization for SVM", "text": "In this section, we first formulate both hard-margin SVM and \u03bd-SVM, and show that they can be reduced to saddle point optimizations. Then we provide an algorithm SVMSPSolver to solve the saddle point optimizations. For convenience, the default vectors in the paper are all column vectors."}, {"heading": "2.1 Formulate SVM as Saddle Point Optimization", "text": "Definition 1 (Hard-margin SVM). Suppose we have n points xi \u2208 Rd for 1 \u2264 i \u2264 n. Each xi has a label yi \u2208 {+1,\u22121}. Let P = {x+i | x+i = xi, yi = +1} and Q = {x\u2212i | x\u2212i = xi, yi = \u22121}. The goal of hard-margin SVM is to find a hyperplane H = {x \u2208 Rd | wTx = b} that separates P from Q. Meanwhile, the distances from P to H and from Q to H are equial and the sum of such distances is maximized.\nFor convenience, we assume that in the hard margin case \u2016xi\u20162 \u2264 1 for 1 \u2264 i \u2264 n.3 Moreover, we assume that the margin is at least some constant \u03b2 > 0. It is well known that hard-margin SVM can be formalized as the following quadratic programming [11].\nmin w,b\n1 2\u2016w\u20162\ns.t. yi(wTxi \u2212 b) \u2265 1, \u2200i (1)\nSuppose |P| = n1 and |Q| = n2. Let d\u00d7n1 matrix A = [x+1 , x+2 , . . . , x+n1 ] and d\u00d7n2 matrix B = [x\u22121 , x \u2212 2 , . . . , x \u2212 n2 ]. The dual problem of (1) is equivalent to the problem of finding the two closest points between the convex hulls of two types of points [5]. We call the problem a C-Hull problem, defined as follows.\nmin w,b\n1 2\u2016A\u03b7 \u2212B\u03be\u20162\ns.t. \u2016\u03b7\u20161 = 1, \u2016\u03be\u20161 = 1. \u03b7 \u2265 0, \u03be \u2265 0. (2)\nSince \u2211 i \u03b7i = 1, we can regard it as a probability distribution among points in P (similarly for Q). We denote \u2206n1 to be the set of n1-dimensional probability vectors over P and \u2206n2 to be that over Q. Then, we prove that the C-Hull (2) is equivalent to the following saddle point optimization by Lemma 2. We defer the proof in Appendix A.\nOPT = max w min \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162 (3)\n3 It can be achieved by scale all data by factor 1/max \u2016xi\u20162 in O(n) time. In the paper, \u2016 \u00b7 \u2016 represents the l2-norm.\nLemma 2. Problem C-Hull (2) is equivalent to the saddle point optimization (3).\nLet \u03c6(w, \u03b7, \u03be) = wTA\u03b7\u2212wTB\u03be\u2212 12\u2016w\u20162. Note that \u03c6(w, \u03b7, \u03be) is only linear with respect to \u03b7 and \u03be. However, in order to obtain an algorithm which converges faster, we hope the objective function is strongly convex with respect to \u03b7 and \u03be. Fortunately, we can add a small regularization term which ensures that the objective function is strongly convex. This is a commonly used approach in optimization (see [3] for example). In this paper, we use the entropy function H(u) := \u2211 i ui log ui as the regularization term. The new saddle point optimization problem is as follows.\nmax w min \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2 wTA\u03b7 \u2212 wTB\u03be + \u03b3H(\u03b7) + \u03b3H(\u03be)\u2212 1 2 \u2016w\u20162, (4)\nwhere \u03b3 = \u03b2/2 log n. The following lemma describes the efficiency of the above saddle point optimization (4). We defer the proof to Appendix A.\nLemma 3. Let (w\u2217, \u03b7\u2217, \u03be\u2217) and (w\u25e6, \u03b7\u25e6, \u03be\u25e6) be the optimal solution of saddle point optimizations (3) and (4) respectively. Define OPT as in (3). Define\ng(w) := min \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162.\nThen g(w\u2217)\u2212 g(w\u25e6) \u2264 OPT (note that g(w\u2217) = OPT).\nWe call the saddle point optimization (4) a Hard-Margin Saddle problem, abbreviated to HM-Saddle. Next, we discuss \u03bd-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.\nDefinition 4 (\u03bd-SVM). Given n points xi \u2208 Rd for 1 \u2264 i \u2264 n, each xi has a label yi \u2208 {+1,\u22121}. \u03bd-SVM is the quadratic programming as follows.\nmin w,b,\u03c1,\u03b4\n1 2\u2016w\u20162 \u2212 \u03c1+ \u03bd2 \u2211 i \u03b4i\ns.t. yi(wTxi \u2212 b) \u2265 \u03c1\u2212 \u03b4i, \u03b4i \u2265 0, \u2200i (5)\nCrisp and Burges [12] present a geometry interpretation for \u03bd-SVM. They proved that \u03bd-SVM is equivalent to the problem of finding the closest distance between two reduced convex hulls as follows.\nmin \u03b7,\u03be\n1 2\u2016A\u03b7 \u2212B\u03be\u20162\ns.t. \u2016\u03b7\u20161 = 1, \u2016\u03be\u20161 = 1. 0 \u2264 \u03b7i \u2264 \u03bd, 0 \u2264 \u03bej \u2264 \u03bd, \u2200i, j (6)\nWe call the above problem a Reduced Convex Hull problem, abbreviated to RC-Hull. The difference between problem C-Hull (2) and RC-Hull (6) is that in the latter one, each entry of \u03b7 and \u03be has an upper bound \u03bd. Geometrically, it means to compress the convex hull of P and Q such that the two reduced convex hulls are separate. We define Dn1 to be the domain of \u03b7 in RC-Hull, i.e., {\u03b7 | \u2016\u03b7\u20161 = 1, 0 \u2264 \u03b7i \u2264 \u03bd, \u2200i} and Dn2 to be the domain of \u03be, i.e., {\u03be | \u2016\u03be\u20161 = 1, 0 \u2264 \u03bej \u2264 \u03bd, \u2200j}. Similar to Lemma 2, we have the following lemma. The proof is deferred to Appendix A.\nLemma 5. RC-Hull (6) is equivalent to the following saddle point optimization.\nOPT = max w min \u03b7\u2208Dn1 , \u03be\u2208Dn2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162. (7)\nSimilarly, we add two entropy terms to make the objective function strongly convex with respective to \u03b7 and \u03be.\nmax w min \u03b7\u2208Dn1 , \u03be\u2208Dn2 wTA\u03b7 \u2212 wTB\u03be + \u03b3H(\u03b7) + \u03b3H(\u03be)\u2212 1 2 \u2016w\u20162. (8)\nwhere \u03b3 = \u03b2/2 log n. We call this problem a \u03bd-Saddle problem. Similar to Lemma 3, we can prove that \u03bd-Saddle (8) is (1\u2212 )-approximation of the saddle point optimization (13). See Lemma 8 in Appendix A for the details. Overall, we can solve hard-margin SVM and \u03bd-SVM through solving HM-Saddle and \u03bd-Saddle.4"}, {"heading": "2.2 Saddle Point Optimization Algorithms for SVM", "text": "In this section, we propose efficient algorithms to solve HM-Saddle (4) and \u03bd-Saddle (8). The framework is inspired by the prior work by Allen-Zhu et al. [3]. They provide an algorithm L1L2SPSolver for saddle point optimization. However, we have mentioned in \u2018related work\u2019 that their algorithm does not imply an effective SVM algorithm directly. Instead, we show that under the same pre-processing step, through some modified update rules, we can apply their framework to solve HM-Saddle and \u03bd-Saddle efficiently. For completeness, we briefly introduce their algorithm.\nRecall that we assume all points are in a unit ball, i.e., \u2016xi\u20162 \u2264 1. We first apply a randomized Hadamard space rotation as in [3]. Concretely speaking, let H be the d\u00d7 d Walsh-Hadamard matrix and D be a d\u00d7 d diagonal matrix whose entries are i.i.d. chosen from \u00b11 with equal probability. Then, we transform our data by left-producting the matrix HD. It is well known [1] that with high probability, for any point xi we have\n\u2200j \u2208 [d], |(HDxi)j | \u2264 O( \u221a log n/d).\nLet X+ = HDA and X\u2212 = HDB. It means that after transformation, with high probability, each entry in X+ or X\u2212 is at most O( \u221a log n/d). We can speed up this transformation to O(nd log d) time by FFT. After the data transformation, we initialize the necessary parameters. Here we use \u201c\u03b1[t]\u201d to represent the value of variable \u201c\u03b1\u201d at iteration t. For example, w[0], \u03b7[0], \u03be[0] are the initial value of w, \u03b7, \u03be. The preprocessing step is given by Algorithm 1. We denote Xi to be the ith row and X\u00b7j to be the jth column of a given matrix X .\nThen, we discuss the update rules. We call our algorithm SVMSPSolver and provide the details in Algorithm 2. In order to unify HM-Saddle and \u03bd-Saddle in the same framework, we use (S1,S2) to represent the domains (\u2206n1 ,\u2206n2) in HM-Saddle and (Dn1 ,Dn2) in \u03bd-Saddle. Let Vx(y) = H(y)\u2212\u3008\u2207H(x), y\u2212x\u3009\u2212H(x) be the Bregman\n4The careful readers may doubt that the formulations of HM-Saddle and \u03bd-Saddle only depends on (w, \u03b7, \u03be) but not the offset b. In fact, according to the hyperplane bisecting the closest points in the (reduced) convex hulls, it is not difficult to prove that b\u2217 = w\u2217T(A\u03b7\u2217 +B\u03be\u2217)/2.\nAlgorithm 1 Pre-processing Input: P: n1 points x+i with label +1 and Q: n2 points x\u2212i with label \u22121\n1: H \u2190 d-dimensional Hadamard Matrix 2: D \u2190 d\u00d7 d diagonal matrix whose entries are i.i.d. chosen from \u00b11 3: X+ \u2190 HD \u00b7 [x+1 , x+2 , . . . , x+n1 ], X\u2212 \u2190 HD \u00b7 [x\u22121 , x\u22122 , . . . , x\u2212n2 ] 4: w[0] \u2190 [0, . . . , 0]T, \u03b7[\u22121] = \u03b7[0] \u2190 [ 1n1 , . . . , 1 n1\n]T, \u03be[\u22121] = \u03be[0] \u2190 [ 1n2 , . . . , 1 n2 ]T\n5: \u03b3 \u2190 \u03b22 logn , q \u2190 O( \u221a log n), \u03c4 \u2190 12q \u221a d \u03b3 , \u03c3 \u2190 12q \u221a d\u03b3, \u03b8 \u2190 1\u2212 1 d+q \u221a d/ \u221a \u03b3\nAlgorithm 2 Update Rules of SVMSPSolver 1: Pick an index i\u2217 in [d] uniformly at random , 2: \u03b4+i\u2217 \u2190 \u3008X+i\u2217 , \u03b7[t] + \u03b8(\u03b7[t]\u2212 \u03b7[t\u2212 1])\u3009, \u03b4\u2212i\u2217 \u2190 \u3008X\u2212i\u2217 , \u03be[t] + \u03b8(\u03be[t]\u2212 \u03be[t\u2212 1])\u3009 3: \u2200i \u2208 [d], wi[t+ 1]\u2190 { (wi[t] + \u03c3(\u03b4 + i \u2212 \u03b4\u2212i ))/(\u03c3 + 1), if i = i\u2217\nwi[t], if i 6= i\u2217 4: \u03b7[t+1]\u2190 arg min\n\u03b7\u2208S1 { 1d (w[t]+d(w[t+1]\u2212w[t]))TX+\u03b7+ \u03b3 dH(\u03b7)+ 1 \u03c4 V\u03b7[t](\u03b7)}\n5: \u03be[t+1]\u2190 arg min \u03be\u2208S2 {\u2212 1d (w[t]+d(w[t+1]\u2212w[t]))TX\u2212\u03be+ \u03b3 dH(\u03be)+ 1 \u03c4 V\u03be[t](\u03be)}\ndivergence function. Generally speaking, we alternatively maximize the objective with respect to w and minimize with respect to \u03b7 and \u03be. The update rules use some useful technique for speeding up the convergence, such as the proximal gradient method and momentum (see the book [6]). In the following, we analyze the update rules in details.\nFirstly, it is not hard to check that the update rule for w (line 3 in Algorithm 2) is equivalent to\nwi\u2217 [t+ 1] = arg max wi\u2217 \u2212 { \u2212(\u03b4+i\u2217 \u2212 \u03b4\u2212i\u2217)wi\u2217 + w2i\u2217 2 + (wi\u2217 \u2212 wi\u2217 [t])2 2\u03c3 } (9)\nIn fact, this is a variant of the proximal coordinate gradient method with l2-norm regularization. In order to accelerate the convergence, we randomly select one dimension i\u2217 \u2208 [d] and update the corresponding wi\u2217 in each iteration. Moreover, note that the term (\u03b4+i\u2217 \u2212 \u03b4\u2212i\u2217) can be considered as the term (\u3008X+i\u2217 , \u03b7[t]\u3009 \u2212 \u3008X\u2212i\u2217 , \u03be[t]\u3009) appending a momentum term. The update rules for \u03b7 and \u03be use the proximal gradient method with a Bergman divergence regularization. We also add a momentum term d(w[t+ 1]\u2212 w[t]) for primal variable w when updating \u03b7 and \u03be.\nWe need to show that we can solve the optimization problems in line 4 and 5 of Algorithm 2 efficiently. In fact, for both HM-Saddle and \u03bd-Saddle, we can obtain explicit expressions of these two optimization problems using the method of Lagrange multipliers. Firstly, the explicit expressions of HM-Saddle for \u03b7 and \u03be are as follows.\n\u03b7i[t+ 1]\u2190 \u03a6(\u03b7i[t], X+)/Z+, \u03bej [t+ 1]\u2190 \u03a6(\u03bej [t], X\u2212)/Z\u2212, \u2200i \u2208 [n1], j \u2208 [n2] (10)\nwhere Z+ = \u2211 i \u03b7i[t+ 1], Z \u2212 = \u2211 j \u03bej [t+ 1], and\n\u03a6(\u03bbi, X) = exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03bbi \u2212 yi \u00b7 \u3008w[t] + d(w[t+ 1]\u2212 w[t], X\u00b7i)\u3009) } (11) Note that the factors Z+ and Z\u2212 are used to project the value \u03a6(\u03b7i[t], X+) and \u03a6(\u03bej [t], X\n\u2212) to the domains \u2206n1 and \u2206n2 . The above update rules of \u03b7 and \u03be can be also considered as the multiplicative weight update method (see [4]).\nThen we consider \u03bd-Saddle. The update rules are similar but require a more careful projection method. Let \u03b7i and \u03bej to be \u03a6(\u03b7i[t], X+)/Z+ and \u03a6(\u03bej [t], X\u2212)/Z\u2212 respectively. However, we have an extra constraint that \u03b7i, \u03bej \u2264 \u03bd compared to HM-Saddle. Thus, we need another projection process (12) to ensure that \u03b7[t+ 1] and \u03be[t+ 1] locate in domain Dn1 and Dn2 respectively. For convenience, we only present the projection for \u03b7 here. The projection for \u03be is similar.\nwhile \u03c2 := \u2211 \u03b7i>\u03bd\n(\u03b7i \u2212 \u03bd) 6= 0 : \u2126 = \u2211 \u03b7i<\u03bd\n\u03b7i \u2200i, if \u03b7i \u2265 \u03bd, then \u03b7i = \u03bd \u2200i, if \u03b7i < \u03bd, then \u03b7i = \u03b7i(1 + \u03c2/\u2126)\n(12)\nNote that there are at most 1/\u03bd (a constant) entries \u03b7i of value \u03bd during the whole projection process. In each iteration, there must be at least 1 more entry \u03b7i = \u03bd since we make all entries \u03b7j > \u03bd equal to \u03bd after the iteration. Thus, the number of iterations in (12) is at most 1/\u03bd. By (12), we project \u03b7 and \u03be to the domains Dn1 and Dn2 respectively. We still need to show the projection result of (12) is exactly the optimal solution in line 4. The proof is deferred to Appendix B. Thus, we need O(n/\u03bd) time to compute \u03b7[t+ 1]. Since we assume that \u03bd is a constant, it only costs linear time. If \u03bd is extremely small, we have another update rule to get \u03b7[t+ 1] and \u03be[t+ 1] in O(n log n) time. See Appendix B for details. Finally, we give our main theorem for our algorithm as follows. See the proof in Appendix C.\nTheorem 6. Algorithm 2 computes (1\u2212 )-approximate solutions for HM-Saddle and \u03bd-Saddle by O\u0303(d+ \u221a d/ \u03b2) iterations. Moreover, it takes O(n) time for each iteration.\nCombining with Lemmas 2, 3, 5 and 8 we obtain (1\u2212 )-approximate solutions for CHull and RC-Hull problems. Hence by strong duality, we obtain (1\u2212 )-approximations for hard-margin SVM and \u03bd-SVM in O\u0303(n(d+ \u221a d/ \u03b2)) time.\nTheorem 7. A (1\u2212 )-approximation for either hard-margin SVM or \u03bd-SVM can be computed in O\u0303(n(d+ \u221a d/ \u03b2)) time."}, {"heading": "3 Distributed SVM", "text": "Server and Clients Model: We apply Algorithm SVMSPSolver in the distributed setting and call it DisSVMSPSolver. We consider a popular distributed setting: the server and clients model. Denote by S the server. Let C be the set of clients and |C| = k. We use the notation C.\u03b1 to represent any variable \u03b1 saved in client C and use S.\u03b1 to represent a variable \u03b1 saved in the server.\nFirst, we initialize some parameters in each client as the pre-processing step in Algorithm 1 (see Algorithm 3 for the pseudocode). Each client maintains the same random diagonal matrix Dd\u00d7d and the total number of points in each type (i.e, |P| = n1 and |Q| = n2).5 Moreover, each client C applies a Hadamard transformation to its own data and initialize the partial probability vectors C.\u03b7 and C.\u03be for its own points. We first consider HM-Saddle. The interaction between clients and the server can be divided into three rounds in each iteration.\n1. In the first round, the server randomly chooses a number i\u2217 \u2208 [d] and broadcasts i\u2217 to all clients. Each client computes C.\u03b4+i\u2217 and C.\u03b4 \u2212 i\u2217 and sends them back to\nthe server.\n2. In the second round, the server sums up all C.\u03b4+i\u2217 and C.\u03b4 \u2212 i\u2217 and computes S.\u03b4 + i\u2217\nand S.\u03b4\u2212i\u2217 . We can see that S.\u03b4 + i\u2217 (resp. S.\u03b4 \u2212 i\u2217) is exactly \u03b4 + i\u2217 (resp. \u03b4 \u2212 i\u2217 ) in Algorithm 2. The server broadcasts S.\u03b4+i\u2217 and S.\u03b4 \u2212 i\u2217 to all clients. By S.\u03b4 + i\u2217 and S.\u03b4\u2212i\u2217 , each client updates w individually. Moreover, each client C \u2208 C updates its own C.\u03b7 and C.\u03be according to the new directional vector w. In order to normalize the probability vectors \u03b7 and \u03be, each client sends the summation C.Z+ and C.Z\u2212 to the server.\n3. In the third round, the server computes (S.Z+, S.Z\u2212)\u2190\u2211C\u2208C(C.Z+, C.Z\u2212) and broadcasts to all clients the normalization factors S.Z+ and S.Z\u2212. Finally, each client updates its partial probability vector C.\u03b7 and C.\u03be based on the normalization factors.\nAs we discuss in Section 2.2, for \u03bd-Saddle, we need another O(1/\u03bd) rounds to project \u03b7 and \u03be to the domains Dn1 and Dn2 .\n4. Each client computes C.\u03c2+, C.\u03c2\u2212 and C.\u2126+, C.\u2126\u2212 according to (12) and sends them to the server. The server sums up all C.\u03c2+, C.\u03c2\u2212, C.\u2126+, C.\u2126\u2212 respectively and gets S.\u03c2+, S.\u03c2\u2212, S.\u2126+, S.\u2126\u2212. If both S.\u03c2+ and S.\u03c2\u2212 are zeroes, the server stops this iteration. Otherwise, the server broadcasts to all clients the factors S.\u03c2+, S.\u03c2\u2212, S.\u2126+, S.\u2126\u2212. All clients update their C.\u03b7 and C.\u03be according to (12) and repeat Step 4 again.\nWe give the pseudocode in Algorithm 4 in Appendix D. By Theorem 6, after T = O\u0303(d+ \u221a d/ ) iterations, all clients compute the same (1\u2212 )-approximate solution w = w[T ] for SVM. W.l.o.g, let the first client send w to the server. By at most O(n) more communication cost, the server can compute the offset b, the margin for hard-margin SVM and the objective value for the \u03bd-SVM. The correctness of Algorithm DisSVMSPSolver is oblivious since we obtain the same w[t] as in SVMSPSolver after each iteration.\nCommunication Complexity of DisSVMSPSolver: We claim that the communication cost of DisSVMSPSolver is O\u0303(k(d+ \u221a d/ )), and show that the lower bound of the communication cost for distributed SVM is \u2126(kmin{d, 1/ }). Note that if d = \u0398(1/ ), the communication lower bound is \u2126(k(d+ \u221a d/ )) which matches the communication cost of our algorithm DisSVMSPSolver. We defer the details to Appendix D. 5It can be realized using O(k) communication bits."}, {"heading": "4 Experiments", "text": "In this section, we first compare our SVMSPSolver with library NuSVC in scikitlearn [30]. We show that under the same parameters for \u03bd-SVM6, our algorithm achieves better accuracy using significantly less time. Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25]. Our simulation show that our DisSVMSPSolver has lower communication cost in practice. The CPU of our platform is Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz, and the system is CentOS Linux. We use both synthetic and real-world data sets. The real data is from [8]. See Appendix E for the way to generate synthetic data. Besides, more experimental results can be found in Appendix E.\nThe experimental results for \u03bd-Saddle: We compare our SVMSPSolver with NuSVC in scikit-learn [30] and summarize the results in Table 1. In the table, we can see that the time cost of SVMSPSolver is much less than NuSVC when they achieve almost the same accuracy. Especially, the gap of the running time is more significant when the size of the data set is larger. For example, the time cost of NuSVC is more than two hundreds times larger than SVMSPSolver for the data set \u201ccovtype.binary\u201d. The running time of SVMSPSolver is nearly linear to the size of data sets, which matches Theorem 6.\nDistributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25]. The data is distributed to k = 20 nodes. We compare both linearly separable and non-separable cases.\nFor the separable cases, we compare the margins solved by the algorithms with respect to the communication cost. We compare the results for synthetic data sets with different dimensions. Moreover, we test them in the real-world data set \u201cmushrooms\u201d. The experimental results can be found in Figure 1 (a)-(d). Since it takes kd communication cost if each client sends a point to the server, we set one unit of x-coordinate to represent kd communication cost.\nFor the non-separable cases, we compare the accuracy of each algorithm based on the same communication cost. Again, we generate data to analyze the relationship between the running time and the dimensionality d. We also select the real world datasets \u201cphishing\u201d and \u201ca9a\u201d from [8]. We illustrate the objective function value of\n6Scikit-learn uses another equivalent form of \u03bd-SVM. See the details in Appendix E.\n0.1\n0.1\n0.05\n0.2\n\u03bd-Saddle in each iteration in Figure 1 (e)-(h) and compare the accuracy of different algorithms in Figure 1 (i)-(l).\nThe experimental results are consistent with our theoretical results. DisSVMSPSolver achieves better results in both linearly separable and non-separable cases. The convergence rate of the distributed algorithm DisSVMSPSolver is better than the distributed HOGWILD! and Gilbert algorithm under the same communication cost. The performance gap is more significant when the dimensionality is larger. See Figure 1 (a)-(c) and Figure 1 (i)-(j) for examples."}, {"heading": "A Missing Proofs in Section 2.1", "text": "Lemma 2 (restated). Problem C-Hull (2) is equivalent to the saddle point optimization (3).\nProof. Consider the saddle point optimization (3). First, note that\nwTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162 = wT(A\u03b7 \u2212B\u03be)\u2212 1 2 \u2016w\u20162\nThe range of the term (A\u03b7 \u2212 B\u03be) for \u03b7 \u2208 \u2206n1 , \u03be \u2208 \u2206n2 is a convex set, denoted by S. Since the convex hulls of P and Q are linearly separable, we have 0 /\u2208 S. Denote \u03c6(w, z) = wTz \u2212 12\u2016w\u20162 for any w \u2208 Rd, z \u2208 S. Then (3) is equivalent to maxw minz\u2208S \u03c6(w, z). Note that\nmax w min z\u2208S \u03c6(w, z) \u2265 min z\u2208S \u03c6(0d, z) = 0.\nThus, we only need to consider those directions w \u2208 Rd such that there exists a point z \u2208 S with wT z \u2265 0. We useW to denote the collection of such directions.\nLet u be a unit vector inW . Denote zu := arg minz\u2208S \u03c6(u, z) = arg minz\u2208S uT z. By this definition, zu is the point with smallest projection distance to u among S (see Figure 2). Observe that if a directionw = c\u00b7u (c > 0), then we have arg minz \u03c6(w, z) = arg minz \u03c6(u, z). Also note that\nmax w=c\u00b7u:c>0\nwTzu \u2212 1\n2 \u2016w\u20162 = max w=c\u00b7u:c>0\n1 2 (\u2212\u2016w \u2212 zu\u20162 + \u2016zu\u20162).\nLet wu := arg maxw=c\u00b7u:c>0 \u03c6(w, zu) = arg minw=c\u00b7u:c>0 \u2016w \u2212 zu\u20162. wu is the projection point of zu to the line ou, where o is the origin. See Figure 2 for an example.\nOverall, we have\nmax w min \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2 wT(A\u03b7 \u2212B\u03be)\u2212 1 2 \u2016w\u20162\n= max u\u2208W:\u2016u\u2016=1\n1 2 (\u2212\u2016wu \u2212 zu\u20162 + \u2016zu\u20162)\n= max u\u2208W:\u2016u\u2016=1\n1 2 \u2016wu\u20162.\nThe last equality is by the Pythagorean theorem. Let z\u2217 be the closest point in S to the origin point. Next, we show that maxu\u2208W:\u2016u\u2016=1 \u2016wu\u20162 = \u2016z\u2217\u20162. Given a unit vector u \u2208 W , define w\u2032 to be the projection point of z\u2217 to the line ou. By the definition of zu and wu, we have that maxu \u2016wu\u20162 \u2264 \u2016w\u2032\u20162 \u2264 \u2016z\u2217\u20162. Moreover, let u = z\u2217/\u2016z\u2217\u2016. In this case, we have \u2016wu\u20162 = \u2016z\u2217\u20162. Thus, we conclude that maxu \u2016wu\u20162 = \u2016z\u2217\u20162.\nOverall, we prove that\nmax u\u2208W:\u2016u\u2016=1\n1 2 \u2016wu\u20162 = 1 2 \u2016z\u2217\u20162 = min z\u2208S 1 2 \u2016z\u20162 = min\n\u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2\n1 2 \u2016A\u03b7 \u2212B\u03be\u20162\nThus, C-Hull (2) is equivalent to the saddle point optimization (3).\nLemma 3 (restated). Let (w\u2217, \u03b7\u2217, \u03be\u2217) and (w\u25e6, \u03b7\u25e6, \u03be\u25e6) be the optimal solution of saddle point optimizations (3) and (4) respectively. Define OPT as in (3). Define\ng(w) := min \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162.\nThen g(w\u2217)\u2212 g(w\u25e6) \u2264 OPT (note that g(w\u2217) = OPT). Proof. Let\n\u03c6(w, \u03b7, \u03be) = wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162,\n\u03c6\u03b3(w, \u03b7, \u03be) = \u03c6(w, \u03b7, \u03be) + \u03b3H(\u03b7) + \u03b3H(\u03be),\n\u03b7\u0303, \u03be\u0303 = argmin \u03b7\u2208\u2206n1 ,\u03be\u2208\u2206n2\n\u03c6(w\u25e6, \u03b7, \u03be).\nBy the definition of saddle points, we have\ng(w\u25e6) = \u03c6(w\u25e6, \u03b7\u0303, \u03be\u0303) = \u03c6\u03b3(w \u25e6, \u03b7\u0303, \u03be\u0303)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303)\n\u2265 \u03c6\u03b3(w\u25e6, \u03b7\u25e6, \u03be\u25e6)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303) \u2265 \u03c6\u03b3(w\u2217, \u03b7\u25e6, \u03be\u25e6)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303) = \u03c6(w\u2217, \u03b7\u25e6, \u03be\u25e6)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303) + \u03b3H(\u03b7\u25e6) + \u03b3H(\u03be\u25e6) \u2265 \u03c6(w\u2217, \u03b7\u2217, \u03be\u2217)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303) + \u03b3H(\u03b7\u25e6) + \u03b3H(\u03be\u25e6) = g(w\u2217)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303) + \u03b3H(\u03b7\u25e6) + \u03b3H(\u03be\u25e6) \u2265 g(w\u2217)\u2212 \u03b3H(\u03b7\u0303)\u2212 \u03b3H(\u03be\u0303).\nNote that entropy function satisfies 0 \u2264 H(u) \u2264 log n for any u \u2208 \u2206n. Thus, \u03b3H(\u03b7\u0303) +\u03b3H(\u03be\u0303) \u2264 \u03b22 logn \u00b7 (log n1 + log n2) \u2264 OPT. Overall, we prove that g(w\u2217)\u2212 g(w\u25e6) \u2264 OPT.\nLemma 5 (restated). RC-Hull (6) is equivalent to the following saddle point optimization.\nOPT = max w min \u03b7\u2208Dn1 , \u03be\u2208Dn2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162. (13)\nProof. The proof is almost the same to the proof of Lemma 2. The only difference is that the range of the term (A\u03b7\u2212B\u03be) is another convex set defined by \u03b7 \u2208 Dn1 , \u03be \u2208 Dn2 .\nLemma 8. Let (w\u2217, \u03b7\u2217, \u03be\u2217) and (w\u25e6, \u03b7\u25e6, \u03be\u25e6) be the optimal solution of saddle point optimizations (13) and (8) respectively. Define OPT as in (13). Define\ng(w) := min \u03b7\u2208Dn1 ,\u03be\u2208Dn2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162.\nThen g(w\u2217)\u2212 g(w\u25e6) \u2264 OPT. Proof. Note that Dn1 is a convex polytope contained in \u2206n1 and Dn2 is a convex polytope contained in \u2206n2 . It is not hard to verify that the proof of Lemma 3 still holds for Dn1 and Dn2 ."}, {"heading": "B The Equivalence of the Explicit and Implicit Update Rules of \u03b7 and \u03be", "text": "Lemma 9 (Update Rules of HM-Saddle). The following two update rules are equivalent.\n\u2022 \u03b7[t+1] = arg min \u03b7\u2208\u2206n1\n{ 1 d (w[t] + d(w[t+ 1]\u2212 w[t]))TX\u03b7 + \u03b3 dH(\u03b7) + 1 \u03c4 V\u03b7[t](\u03b7) } \u2022 \u03b7i = Z\u22121 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009)\n} for each i \u2208 [n1], where Z = \u2211 i \u03b7i 7\nProof. The Lagrangian function of the first optimization formulation is\nL(\u03b7, \u03bb) = 1 d (w[t] + d(w[t+ 1]\u2212 w[t]))TX\u03b7 + \u03b3 d H(\u03b7) + 1 \u03c4 V\u03b7[t](\u03b7) + \u03bb( \u2211 i \u03b7i \u2212 1)\nThus, we have\n\u2202L \u2202\u03b7i = 0 = (\u03b3d\u22121 + \u03c4\u22121) log \u03b7i + d \u22121\u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009 \u2212 \u03c4\u22121 log \u03b7i[t] + (\u03bb+ \u03c4\u22121),\u2200i \u2202L \u2202\u03bb = 0 = \u22121 + \u2211 i \u03b7i\nSolve the above equalities, we obtain\n\u03b7i[t+1] = Z \u22121 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009 } 7Recall that X\u00b7i is the ith column of X .\nLemma 10 (Update Rules of \u03bd-Saddle). The following three update rules are equivalent.\nRule 1: \u03b7[t+1] = arg min \u03b7\u2208S1\n{ 1 d (w[t] + d(w[t+ 1]\u2212 w[t]))TX\u03b7 + \u03b3 dH(\u03b7) + 1 \u03c4 V\u03b7[t](\u03b7) } Rule 2:\n\u2022 Step 1: \u03b7i = Z\u22121 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009) }\nfor each i \u2208 [n1], where Z = \u2211 i \u03b7i.\n\u2022 Step 2: Sort \u03b7i by the increasing order. W.l.o.g., assume that \u03b71, . . . , \u03b7n1 is in increasing order. Define \u03c2i = \u2211 j\u2265i(\u03b7j \u2212 \u03bd) and \u2126i = \u2211 j<i \u03b7j . Find the largest\nindex i\u2217 \u2208 [n] such that \u03c2i\u2217 \u2265 0 and \u03b7i\u2217\u22121(1 + \u03c2i\u2217/\u2126i\u2217) < \u03bd by binary search.\n\u2022 Step 3: \u2200i, \u03b7i[t+ 1] =\n{ \u03b7i(1 + \u03c2i\u2217/\u2126i\u2217), if i < i\u2217\n\u03bd, if i \u2265 i\u2217\nRule 3: \u2022 Step 1: \u03b7i = Z\u22121 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009) }\nfor each i \u2208 [n1], where Z = \u2211 i \u03b7i.\n\u2022 Step 2: while \u03c2 := \u2211 \u03b7i>\u03bd\n(\u03b7i \u2212 \u03bd) 6= 0 : \u2126 = \u2211 \u03b7i<\u03bd\n\u03b7i \u2200i, if \u03b7i \u2265 \u03bd, then \u03b7i = \u03bd \u2200i, if \u03b7i < \u03bd, then \u03b7i = \u03b7i(1 + \u03c2/\u2126)\n(14)\nProof. Similar to the proof of Lemma 9, we first give the Lagrangian function of the first optimization formulation as follows.\nL(\u03b7, \u03bb, \u03c3) = 1 d (w[t]+d(w[t+1]\u2212w[t]))TX\u03b7+\u03b3 d H(\u03b7)+ 1 \u03c4 V\u03b7[t](\u03b7)+\u03bb( \u2211 i \u03b7i\u22121)+ \u2211 i \u03b1i(\u03b7i\u2212\u03bd)\nBy KKT conditions, we have the following.\n0 = (\u03b3d\u22121 + \u03c4\u22121) log \u03b7i + d \u22121\u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009 \u2212 \u03c4\u22121 log \u03b7i[t] + (\u03bb+ \u03b1i + \u03c4\u22121),\u2200i 1 = \u2211 i \u03b7i 0 = \u03b1i(\u03b7i \u2212 \u03bd),\u2200i 0 \u2265 \u03b7i \u2212 \u03bd, \u2200i 0 \u2264 \u03b1i,\u2200i\nWe first show the equivalence between Rule 1 and Rule 2. Note that \u03b7[t+ 1] in Rule 2 satisfies the second and the fourth KKT conditions. We only need to give all \u03b1i and \u03bb satisfying other KKT conditions for Rule 2. Let\n\u03b7\u0303i = exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009) } .\nLet\n\u03b7i = Z \u22121\u03b7\u0303i = Z \u22121 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 log \u03b7i[t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), X\u00b7i\u3009) }\nas defined in Step 1 of Rule 2. For 1 \u2264 i \u2264 i\u2217 \u2212 1, let \u03b1i = 0. For i \u2265 i\u2217, let\n\u03b1i = (\u03b3d \u22121 + \u03c4\u22121)\u22121 ln\n\u03b7i(1 + \u03c2i\u2217/\u2126i\u2217)\n\u03bd \u2265 0.\nThe inequality follows from the definition of i\u2217. Note that we only need to prove that \u03b7i\u2217(1 + \u03c2i\u2217/\u2126i\u2217) \u2265 \u03bd. If i\u2217 \u2265 \u03bd, then the above inequality holds directly. Otherwise if \u03b7i\u2217 < \u03bd and \u03b7i\u2217(1 + \u03c2i\u2217/\u2126i\u2217) < \u03bd, we have that \u03c2i\u2217+1 = \u03c2i\u2217 + \u03bd \u2212 \u03b7i\u2217 > 0 and \u2126i\u2217+1 = \u2126i\u2217 + \u03b7i\u2217 . We also have the following inequality\n\u03b7i\u2217(1 + \u03c2i\u2217+1 \u2126i\u2217+1 )\u2212 \u03bd = \u03b7i\u2217(\u03c2i\u2217 + \u2126i\u2217)\u2212 \u2126i\u2217\u03bd \u2126i\u2217 + \u03b7i\u2217 = \u03b7i\u2217(1 + \u03c2i\u2217/\u2126i\u2217)\u2212 \u03bd \u2126i\u2217(\u2126i\u2217 + \u03b7i\u2217) < 0,\nwhich contradicts with the definition of i\u2217. Finally, randomly choose an index i, let\n\u03bb = (\u03b3d\u22121 + \u03c4\u22121)\u22121 ln Z\u03b7i\n\u03b7i[t+ 1] \u2212 \u03b1i \u2212 \u03c4\u22121.\nBy the chosen of \u03b1i, it is not hard to check that the value of \u03bb is the same for any index i. Thus, \u03b7i[t+ 1], \u03b1i and \u03bb are the unique solution of KKT conditions. So Rule 1 and Rule 2 are equivalent. By a similar argument (define suitable \u03b1i and \u03bb), we can prove that Rule 1 and Rule 3 are equivalent, which finishes the proof.\nRemark 11. We analyze Rule 2 in Lemma 10. Roughly speaking, we find a suitable value \u03b7i\u2217 , set all value \u03b7j > \u03b7i\u2217 to be \u03bd, and scales up other values by some factor 1 + \u03c2i\u2217/\u2126i\u2217 . We can verify that the running time of Rule 2 is O(n log n) since both the sorting time and the binary search time are O(n log n). On the other hand, recall that the running time of Rule 3 is O(n/\u03bd) (explained in Section 2.2). Thus, if the parameter \u03bd is extremely small, we can use Rule 2 in practice."}, {"heading": "C Proof of Theorem 6", "text": "For preparation, we give two useful Lemmas 12 and 13. The two lemmas generalize Lemma A.1 and Lemma A.2 in [3] by changing the domain \u2206m to a convex polytope Sm contained in \u2206m. Fortunately, the proofs of Lemma A.1 and Lemma A.2 still work for the following general version. We omit detail proofs here. Recall that Vx(y) is the Bregman divergence function which is defined as H(y)\u2212 \u3008\u2207H(x), y \u2212 x\u3009 \u2212H(x).\nLemma 12. Let x2 = argminz\u2208Sm { Vx1 (z) \u03c4 + \u03b3H(z) }\n. Let Sm be a convex polytope contained in \u2206m. Then for every u \u2208 Sm, we have\n1 \u03c4 Vx1(u)\u2212\n( 1\n\u03c4 + \u03b7\n) Vx2(u)\u2212 1\n2\u03c4 \u2016x2 \u2212 x1\u201621 \u2265 \u03b3H(x2)\u2212 \u03b3H(u).\nLemma 13. Let x = argminz\u2208Sm {H(z)}. Let Sm be a convex polytope contained in \u2206m. Then for all u \u2208 Sm,\nH(u)\u2212H(x) \u2265 Vx(u). Combing the above lemmas and an almost same analysis as in Theorem 2.2 in [3],\nwe obtain the following Theorem 14.\nTheorem 14. After T iterations of Algorithm 2 (both HM-Saddle and \u03bd-Saddle versions), we obtain a directional vector w[T ] \u2208 Rd satisfying that\n(\u03c4\u22121 + 2\u03b3d\u22121)E [ V\u03b7[T ](\u03b7 \u25e6) + V\u03be[T ](\u03be \u25e6) ]\n+ ((4\u03c3)\u22121 + 1)E[\u2016w\u25e6 \u2212 w[T ]\u20162] \u2264\u03b8T \u00b7 ( 2 ( \u03c4\u22121 + 2\u03b3d\u22121 ) log n+ ((2\u03c3)\u22121 + 1)\u2016w\u25e6\u20162 ) ,\nwhere \u03c4 \u2190 12q \u221a d \u03b3 , \u03c3 \u2190 12q \u221a d\u03b3, \u03b8 \u2190 1\u2212 1 d+q \u221a d/ \u221a \u03b3 , for some q = O( \u221a log n).\nProof Sketch. The difference between our statement and Theorem 2.2 in [3] is that we update two probability vectors \u03b7 and \u03be instead of one in an iteration. Thus, we have two terms V\u03b7[T ](\u03b7\u25e6) and V\u03be[T ](\u03be\u25e6) on the left hand side. Moreover, we care about convex polytopes S1 \u2282 \u2206n1 and S2 \u2282 \u2206n2 instead of \u2206n1 and \u2206n2 .\nHowever, these differences do not influence the correctness of the proof of Theorem 2.2 in [3]. Note that we replace Lemma A.1 and Lemma A.2 in [3] by Lemma 12 and Lemma 13. It is not hard to verify the proof of Theorem 2.2 in [3] works for our theorem.\nWe also need the following lemma.\nLemma 15. Define\ng(w) := min \u03b7\u2208S1,\u03be\u2208S2 wTA\u03b7 \u2212 wTB\u03be \u2212 1 2 \u2016w\u20162.\nwhere S1 and S2 are two convex polytopes such that S1 \u2282 \u2206n1 and S2 \u2282 \u2206n2 . For any u, v \u2208 Rd, we have\ng(u)\u2212 g(v) \u2264 2(1 + \u2016v\u2016)\u2016u\u2212 v\u2016. Proof. Denote by \u2207g(w) any subgradient of g(w) at point w. We write \u2207g(w) = A\u03b7\u0303w \u2212B\u03be\u0303w \u2212w for any arbitrary \u03b7\u0303w \u2208 S1, \u03be\u0303w \u2208 S2 satisfying that g(w) = wTA\u03b7\u0303w \u2212 wTB\u03be\u0303w \u2212 \u2016w\u20162. Note that A\u03b7\u0303w (resp. B\u03be\u0303w) can be considered as a weighted combination of all points xi (resp. xi), we claim that \u2016A\u03b7\u0303w\u2016 \u2264 1 (\u2016B\u03be\u0303w\u2016 \u2264 1) owing to the assumption that every xi satisfies \u2016xi\u2016 \u2264 1. Next, we compute as follows\ng(u)\u2212 g(v) = \u222b 1 \u03c4=0 \u3008\u2207g(v + \u03c4(u\u2212 v)), u\u2212 v\u3009d\u03c4\n= \u222b 1 \u03c4=0 \u3008A\u03b7\u0303v+\u03c4(u\u2212v) \u2212B\u03be\u0303v+\u03c4(u\u2212v) \u2212 (v + \u03c4(u\u2212 v)), u\u2212 v\u3009d\u03c4\n\u2264\u2016A\u03b7\u0303v+\u03c4(u\u2212v)\u2016\u2016u\u2212 v\u2016+ \u2016B\u03be\u0303v+\u03c4(u\u2212v)\u2016\u2016u\u2212 v\u2016+ \u222b 1 \u03c4=0 \u3008\u2212v, u\u2212 v\u3009d\u03c4 \u2212 1 2 \u2016u\u2212 v\u20162 \u2264\u2016u\u2212 v\u2016+ \u2016u\u2212 v\u2016+ \u2016v\u2016\u2016u\u2212 v\u2016 \u2264 2(1 + \u2016v\u2016)\u2016u\u2212 v\u2016.\nNow we are ready to prove Theorem 6 as follows.\nTheorem 6 (restated). Algorithm 2 computes (1\u2212 )-approximate solutions for HMSaddle and \u03bd-Saddle by O\u0303(d + \u221a d/ \u03b2) iterations. Moreover, it takes O(n) time for each iteration.\nProof. Let\n\u03c8(n, d) = ( 2 ( \u03c4\u22121 + 2\u03b3d\u22121 ) log n+ ((2\u03c3)\u22121 + 1)\u2016w\u25e6\u20162 ) \u00b7 ((4\u03c3)\u22121 + 1)\u22121\nAccording to Theorem 14, we have\nE[\u2016w\u25e6 \u2212 w[T ]\u20162] \u2264 \u03b8T\u03c8(n, d)\u21d2 E[\u2016w\u25e6 \u2212 w[T ]\u2016] \u2264 \u03b8T/2\u03c81/2(n, d)\nIn order to get a (1\u2212 )-approximate solution, according to Lemma 15, it suffices to choose T such that\nE [ g(w\u25e6)\u2212 g(w[T ]) ] \u2264 E [ 2(1 + \u2016w[T ]\u2016) \u00b7 \u2016w\u25e6 \u2212 w[T ]\u2016 ] \u2264 2E [( 1 + \u2016w\u25e6 \u2212 w[T ]\u2016+ \u2016w\u25e6\u2016 ) \u00b7 \u2016w\u25e6 \u2212 w[T ]\u2016\n] = 2E [ \u2016w\u25e6 \u2212 w[T ]\u20162 ] + 2E [ (1 + \u2016w\u25e6\u2016)\u2016w\u25e6 \u2212 w[T ]\u2016\n] \u2264 2\u03b8T\u03c8(n, d) + 2(1 + \u2016w\u25e6\u2016)\u03b8T/2\u03c81/2(n, d) \u2264 OPT.\nNote that \u03b8 = 1\u2212 1 d+q \u221a d/ \u221a \u03b3 = 1\u2212 1 d+q \u221a d/ \u221a \u03b2/2 logn . Thus, we only need to have\nT \u2265 log\u03b8 ( OPT\n2\u03c8(n, d)\n) + 2 log\u03b8 ( OPT\n1 + \u2016w\u25e6\u2016 \u00b7 \u03c8 \u22121/2(n, d) ) \u2265 2(d+ \u221a 2d/ \u03b2 \u00b7O(log n)) log ( (1 + \u2016w\u25e6\u2016)\u03c8(n, d)\nOPT ) = \u2126\u0303(d+ \u221a d/ \u03b2)"}, {"heading": "D Missing Details in Section 3", "text": "First, we give the pseudocode of DisSVMSPSolver. See Algorithm 3 for the preprocessing step for each clients. Recall that we assume there arem1 points x+1 , x + 2 , . . . , x + m1 and m2 points x\u22121 , x \u2212 2 , . . . , x \u2212 m2 maintained in C. We use 1\nm to denote a vector with all components being 1. The initialization is as follows.\nC.X+ = HD \u00b7 [x+1 , x+2 , . . . , x+m1 ], C.\u03b7[\u22121] = C.\u03b7[0] = n\u221211 1m1 C.X\u2212 = HD \u00b7 [x\u22121 , x\u22122 , . . . , x\u2212m2 ], C.\u03be[\u22121] = C.\u03be[0] = n\u221212 1m2\nAlgorithm 3 Pre-processing in Clients Input: P: n1 points x+i with label +1 and Q: n2 points x\u2212i with label \u22121, distributed\nat k clients 1: for all clients in C do 2: H \u2190 d-dimensional Hadamard Matrix 3: D \u2190 d\u00d7 d diagonal matrix whose entries are i.i.d. chosen from \u00b11 4: \u03b3 \u2190 \u03b22 logn , q \u2190 O( \u221a log n)\n5: \u03c4 \u2190 12q \u221a d \u03b3 , \u03c3 \u2190 12q \u221a d\u03b3, \u03b8 \u2190 1\u2212 1 d+q \u221a d/ \u221a \u03b3 . 6: d-dimension vector w(0) \u2190 [0, . . . , 0] 7: end for 8: for client C \u2208 C do 9: Assume that there are m1 points x+1 , . . . , x + m1 and m2 points x \u2212 1 , . . . , x \u2212 m2 main-\ntained in C 10: C.X+ \u2190 HD \u00b7 [x+1 , x+2 , . . . , x+m1 ], 11: C.X\u2212 \u2190 HD \u00b7 [x\u22121 , x\u22122 , . . . , x\u2212m2 ], 12: C.\u03b7[\u22121] = C.\u03b7[0]\u2190 [ 1n1 , . . . , 1 n1\n]T \u2208 Rm1 , 13: C.\u03be[\u22121] = C.\u03be[0]\u2190 [ 1n2 , . . . , 1 n2\n]T \u2208 Rm2 . 14: end for\nNext, see Algorithm 4 for the interactions between the server and clients in every iteration. Note that only \u03bd-Saddle needs the fourth round in Algorithm 4. We use flag\u03bd \u2208 {True,False} to distinguish the two cases. If we consider \u03bd-Saddle, let flag\u03bd be True. Otherwise, let flag\u03bd be False.\nThen, we analyze the communication cost. Theorem 16. The communication cost of DisSVMSPSolver is O\u0303(k(d+ \u221a d/ )).\nProof. Note that in each iteration of Algorithm 4, the server and clients interact three times for hard-margin SVM and O(1/\u03bd) times for \u03bd-SVM. The communication cost of each iteration is O(k). By Theorem 6, it takes O\u0303(d+ \u221a d/ ) iterations. Thus, the total\ncommunication cost is O\u0303(k(d+ \u221a d/ )).\nLiu et al. [25] proved a theoretical lower bound of the communication cost for distributed SVM as follows. Note that the statement of Theorem 17 is not exactly the same as the Theorem 6 in Liu et al. [25]. This is because they omit the case that d < 1/ . We prove that they are equivalent briefly. Note that if d = \u0398(1/ ), the communication lower bound is \u2126(k(d + \u221a d/ )) which matches the communication cost of our algorithm DisSVMSPSolver.\nTheorem 17 (Theorem 6 in [25]). Consider a set of d-dimension points distributed at k clients. The communication cost to achieve a (1\u2212 )-approximation of the distributed SVM problem is at least \u2126(kmin{d, 1/ }) for any > 0.\nProof Sketch. In Theorem 6 of [25], the authors obtain a lower bound \u2126(kd) if \u2264 ( \u221a 17 \u2212 4)/16).. Their proof can be extended to the case \u2265 ( \u221a 17 \u2212 4)/16).. In this\ncase, we can make a reduction from the k-OR problem in which each client maintains a (( \u221a\n17\u2212 4)/16 )-bit vector instead of a d-bit vector. As the proof of Theorem 6 in [25], we can obtain a lower bound \u2126(k/ ), which proves the theorem."}, {"heading": "E Supplementary of Experiments", "text": "Data set: We use both synthetic and real-world data sets. The real data is from [8]. The synthetic data is generated as follows. For the separable data, we randomly choose a hyperplane H which overlaps with the unit norm ball in Rd space. Then we randomly sample n points in a subset of the unit ball such that the ratio of the maximum distance among the points to H over the minimum distance to H is \u03b21 = 0.1. Let the labels of points above H be +1 and let others be \u22121. For the non-separable data, the difference is that for those points with distance to H smaller than \u03b22 = 0.1, we randomly choose their labels to be +1 or \u22121 with equal probability. Moreover, we also use real-world including the separable data set \u201cmushrooms\u201d and non-separable ones \u201cw8a\u201d, \u201cgisette\u201d, \u201cmadelon\u201d, \u201cphishing\u201d, \u201ca1a\u201d, \u201ca5a\u201d,\u201ca9a\u201d, \u201cijcnn1\u201d, \u201ccovtype.binary\u201d, \u201chiggs\u201d.\nExperiments of unbalance data sets: We also process some unbalanced data sets in which one type of points is much more than the other types of points. In this case, classifying all test points to the major type could achieve a good accuracy. However, this classifier is not useful in practice. Instead, we often use true positive rate (TPR) and true negative rate (TNR) to measure a classifier over such data sets. By the experimental results, our SVMSPSolver achieves more reasonable TPR and TNR, i.e., |TPR \u2212 TNR| is smaller. See Table 2 for the details. Thus, the performance of our algorithm SVMSPSolver is better for the unbalance data. 8\nMore distributed experiments for SVM: Besides the results in Figure 1, we test more data sets for the distributed algorithms. We give the results in Figure 4. By the experimental results, we obtain the same conclusion as in Section 4.\nIn the following, we give some remarks for the Gilbert Algorithms and HOGWILD! by the experimental results.\nNuSVC in scikit-learn: The form of the \u03bd-SVM used in scikit-learn is a variant of the 8Note that the performance of SVMSPSolver and NuSVC are not same for the unbalance data. This is because their bias b are not exactly the same. See [5, 12] for more explanations.\nform in the paper. We give the formulation as follows.\nmin w,b,\u03c1,\u03b4\n1 2\u2016w\u20162 \u2212 \u00b5\u03c1\u2032 + 1n \u2211 i \u03b4i\ns.t. yi(wTxi \u2212 b) \u2265 \u03c1\u2032 \u2212 \u03b4i, \u03b4i \u2265 0, \u2200i (15)\nCrisp and Burges [12] prove that through reparameterizing, the above formulation is equivalent to \u03bd-SVM (5). Concretely speaking, let\n\u03bd = 2\n\u00b5n , \u03c1 =\n\u03c1\u2032 \u00b5 .\nThen, (15) can be transformed to \u03bd-SVM (5).\nRemark 18. The Gilbert Algorithm only has performance guarantee for the linearly separable data. The accuracy of Gilbert Algorithm for the non-separable cases is unstable and not good.\nRemark 19. Note that HOGWILD! is a lock-free stochastic gradient descent algorithm. Theoretically, the HOGWILD! can only process the non-separable case. In order to compare with our HM-Saddle algorithm, we set the penalty coefficient of HOGWILD! to be a very large constant to approximately solve the separable case.\nAlgorithm 4 DisSVMSPSolver 1: for t\u2190 0 to T \u2212 1 do 2: # first round 3: Server: Pick an index i\u2217 \u2208 {1, 2, . . . , d} uniformly at random and send i\u2217 to\nevery client. 4: for client C \u2208 C do 5: C.\u03b4+i\u2217 \u2190 \u3008C.X+i\u2217 , C.\u03b7[t] + \u03b8(C.\u03b7[t]\u2212 C.\u03b7[t\u2212 1])\u3009 6: C.\u03b4\u2212i\u2217 \u2190 \u3008C.X\u2212i\u2217 , C.\u03be[t] + \u03b8(C.\u03be[t]\u2212 C.\u03be[t\u2212 1])\u3009 7: Send C.\u03b4+i\u2217 and C.\u03b4 \u2212 i\u2217 to server. 8: end for 9: # second round\n10: Server: Let S.\u03b4+i\u2217 = \u2211 C\u2208C C.\u03b4 + i\u2217 and S.\u03b4 \u2212 i\u2217 = \u2211 C\u2208C C.\u03b4 \u2212 i\u2217 . Broadcast S.\u03b4 + i\u2217 and S.\u03b4\u2212i\u2217 . 11: for client C \u2208 C do 12: \u2200i \u2208 [d], wi[t+ 1]\u2190 { (wi[t] + \u03c3(S.\u03b4 + i \u2212 S.\u03b4\u2212i ))/(\u03c3 + 1), if i = i\u2217 wi[t], if i 6= i\u2217 13: \u2200j, C.\u03b7j [t+1]\u2190 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 logC.\u03b7j [t]\u2212 \u3008w[t] + d(w[t+ 1]\u2212 w[t]), C.X+\u00b7j \u3009)\n} 14: \u2200j, C.\u03bej [t+1]\u2190 exp { (\u03b3 + d\u03c4\u22121)\u22121(d\u03c4\u22121 logC.\u03bej [t] + \u3008w[t] + d(w[t+ 1]\u2212 w[t]), C.X\u2212\u00b7j \u3009)\n} 15: C.Z+ \u2190\u2211j C.\u03b7j [t+ 1], C.Z\u2212 \u2190\u2211j C.\u03bej [t+ 1] 16: Send C.Z+ and C.Z\u2212 to server 17: end for 18: # third round 19: Server: Let (S.Z+, S.Z\u2212)\u2190\u2211C\u2208C(C.Z+, C.Z\u2212), and broadcast S.Z+ and S.Z\u2212. 20: for client C \u2208 C do 21: C.\u03b7j [t+ 1]\u2190 C.\u03b7j [t+ 1]/S.Z+, \u2200C.\u03bej [t+ 1]\u2190 C.\u03bej [t+ 1]/S.Z\u2212 22: end for 23: # fourth round, only for \u03bd-Saddle. flag\u03bd is true if use the code for \u03bd-Saddle 24: if flag\u03bd is True then 25: repeat 26: for client C \u2208 C do 27: C.\u03c2+ = \u2211 \u03b7i>\u03bd (\u03b7i \u2212 \u03bd), C.\u2126+ = \u2211 \u03b7i<\u03bd\n\u03b7i. 28: C.\u03c2\u2212 = \u2211 \u03bej>\u03bd (\u03bej \u2212 \u03bd), C.\u2126\u2212 = \u2211 \u03bej<\u03bd\n\u03bej . 29: Send C.\u03c2+, C.\u03c2\u2212, C.\u2126+, C.\u2126\u2212 to server. 30: end for 31: Server: Broadcast (S.\u03c2+, S.\u03c2\u2212, S.\u2126+, S.\u2126\u2212)\u2190\u2211C\u2208C(C.\u03c2+, C.\u03c2\u2212,C.\u2126+,C.\u2126\u2212). 32: for client C \u2208 C do 33: \u2200i, if \u03b7i > \u03bd, then \u03b7i = \u03bd; \u2200i, if \u03b7i < \u03bd, then \u03b7i = \u03b7i(1 + S.\u03c2+/S.\u2126+) 34: \u2200j, if \u03bej > \u03bd, then \u03bej = \u03bd; \u2200j, if \u03bej < \u03bd, then \u03bej = \u03bej(1 + S.\u03c2\u2212/S.\u2126\u2212) 35: end for 36: until S.\u03c2+ and S.\u03c2\u2212 are zeroes 37: end if 38: end for 26"}], "references": [{"title": "Faster dimension reduction", "author": ["Nir Ailon", "Bernard Chazelle"], "venue": "Communications of the ACM,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Katyusha: The first direct acceleration of stochastic gradient methods", "author": ["Zeyuan Allen-Zhu"], "venue": "Proceedings of the 49th annual ACM symposium on theory of computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2016}, {"title": "Optimization algorithms for faster computational geometry", "author": ["Zeyuan Allen-Zhu", "Zhenyu Liao", "Yang Yuan"], "venue": "In LIPIcs-Leibniz International Proceedings in Informatics,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "The multiplicative weights update method: a meta-algorithm and applications", "author": ["Sanjeev Arora", "Elad Hazan", "Satyen Kale"], "venue": "Theory of Computing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Duality and geometry in svm classifiers", "author": ["Kristin P Bennett", "Erin J Bredensteiner"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2000}, {"title": "Convex optimization algorithms", "author": ["Dimitri P Bertsekas", "Athena Scientific"], "venue": "Athena Scientific Belmont,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "A training algorithm for optimal margin classifiers", "author": ["Bernhard E Boser", "Isabelle M Guyon", "Vladimir N Vapnik"], "venue": "In Proceedings of the fifth annual workshop on Computational learning theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1992}, {"title": "Libsvm: a library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Psvm: Parallelizing support vector machines on distributed computers", "author": ["Edward Y Chang"], "venue": "In Foundations of Large-Scale Multimedia Information Management and Retrieval,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Coresets, sparse greedy approximation, and the frank-wolfe algorithm", "author": ["Kenneth L Clarkson"], "venue": "ACM Transactions on Algorithms (TALG),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "A geometry interpretation of \u03bc-svm classifiers", "author": ["DJ Crisp", "CJC Burges"], "venue": "Advances in Neural Information Processing Systems (NIPS", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["John Duchi", "Yoram Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Consensus-based distributed support vector machines", "author": ["Pedro A Forero", "Alfonso Cano", "Georgios B Giannakis"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Optimized cutting plane algorithm for support vector machines", "author": ["Vojt\u011bch Franc", "Soeren Sonnenburg"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Coresets for polytope distance", "author": ["Bernd G\u00e4rtner", "Martin Jaggi"], "venue": "In Proceedings of the twenty-fifth annual symposium on Computational geometry,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "An iterative procedure for computing the minimum of a quadratic form on a convex set", "author": ["Elmer G Gilbert"], "venue": "SIAM Journal on Control,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1966}, {"title": "Parallel support vector machines: The cascade svm", "author": ["Hans Peter Graf", "Eric Cosatto", "Leon Bottou", "Igor Durdanovic", "Vladimir Vapnik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2004}, {"title": "Maximum margin coresets for active and noise tolerant learning", "author": ["Sariel Har-Peled", "Dan Roth", "Dav Zimak"], "venue": "In International Joint Conference on Artificial Intelligence,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "A dual coordinate descent method for large-scale linear svm", "author": ["Cho-Jui Hsieh", "Kai-Wei Chang", "Chih-Jen Lin", "S Sathiya Keerthi", "Sellamanickam Sundararajan"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Making large-scale svm learning practical", "author": ["Thorsten Joachims"], "venue": "Technical report,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1998}, {"title": "Training linear svms in linear time", "author": ["Thorsten Joachims"], "venue": "In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Online learning with kernels", "author": ["Jyrki Kivinen", "Alexander J Smola", "Robert C Williamson"], "venue": "IEEE transactions on signal processing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Communication complexity", "author": ["Eyal Kushilevitz"], "venue": "Advances in Computers,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1997}, {"title": "Distributed and robust support vector machine", "author": ["Yangwei Liu", "Hu Ding", "Ziyun Huang", "Jinhui Xu"], "venue": "In LIPIcs-Leibniz International Proceedings in Informatics,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Distributed parallel support vector machines in strongly connected networks", "author": ["Yumao Lu", "Vwani Roychowdhury", "Lieven Vandenberghe"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Distributed support vector machines", "author": ["A Navia-Vazquez", "D Gutierrez-Gonzalez", "Emilio Parrado-Hern\u00e1ndez", "JJ Navarro-Abellan"], "venue": "IEEE Trans. Neural Networks,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Average and randomized communication complexity", "author": ["Alon Orlitsky", "Abbas El Gamal"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}, {"title": "Solving large scale linear svm with distributed block minimization", "author": ["Dmitry Pechyony", "Libin Shen", "Rosie Jones"], "venue": "In NIPS workshop on Big Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Scikit-learn: Machine learning in python", "author": ["Fabian Pedregosa", "Ga\u00ebl Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "12 fast training of support vector machines using sequential minimal optimization", "author": ["John C Platt"], "venue": "Advances in kernel methods,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1999}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Benjamin Recht", "Christopher Re", "Stephen Wright", "Feng Niu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "New approximation algorithms for minimum enclosing convex shapes", "author": ["Ankan Saha", "SVN Vishwanathan", "Xinhua Zhang"], "venue": "In Proceedings of the twenty-second annual ACM-SIAM symposium on Discrete Algorithms,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2011}, {"title": "New support vector algorithms", "author": ["Bernhard Sch\u00f6lkopf", "Alex J Smola", "Robert C Williamson", "Peter L Bartlett"], "venue": "Neural computation,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2000}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2007}, {"title": "Bundle methods for machine learning", "author": ["Alexander J Smola", "SVN Vishwanathan", "Quoc V Le"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "Simpler core vector machines with enclosing balls", "author": ["Ivor W Tsang", "Andras Kocsor", "James T Kwok"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2007}, {"title": "Core vector machines: Fast svm training on very large data sets", "author": ["Ivor W Tsang", "James T Kwok", "Pak-Ming Cheung"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2005}, {"title": "Some complexity questions related to distributive computing (preliminary report)", "author": ["Andrew Chi-Chih Yao"], "venue": "In Proceedings of the eleventh annual ACM symposium on Theory of computing,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1979}, {"title": "Efficient distributed linear classification algorithms via the alternating direction method of multipliers", "author": ["Caoxie Zhang", "Honglak Lee", "Kang G Shin"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2012}, {"title": "Stochastic primal-dual coordinate method for regularized empirical risk minimization", "author": ["Yuchen Zhang", "Xiao Lin"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2015}], "referenceMentions": [{"referenceID": 14, "context": "To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time.", "startOffset": 107, "endOffset": 111}, {"referenceID": 19, "context": "For \u03bd-SVM, besides the well known quadratic programming approach which requires \u03a9(nd) time [21, 31], no better algorithm is known.", "startOffset": 91, "endOffset": 99}, {"referenceID": 29, "context": "For \u03bd-SVM, besides the well known quadratic programming approach which requires \u03a9(nd) time [21, 31], no better algorithm is known.", "startOffset": 91, "endOffset": 99}, {"referenceID": 6, "context": "Support Vector Machine (SVM) is a fundamental model for classification and regression [7, 11], widely used in many areas such as nature language process, computer vision, and bioinformatics.", "startOffset": 86, "endOffset": 93}, {"referenceID": 14, "context": "Several SVM variants have been designed to handle linearly non-separable cases (see [16]).", "startOffset": 84, "endOffset": 88}, {"referenceID": 32, "context": "\u03bd-SVM is first proposed by Sch\u00f6lkopf and Smola [34].", "startOffset": 47, "endOffset": 51}, {"referenceID": 0, "context": "The advantage of \u03bd-SVM is that the parameter \u03bd has a clearer meaning, which is always between [0, 1].", "startOffset": 94, "endOffset": 100}, {"referenceID": 32, "context": "[34] showed that \u03bd is an upper bound on the fraction of margin errors and a lower bound on the fraction of support vectors.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "It takesO(nd) time by solving quadratic programs directly [21, 31].", "startOffset": 58, "endOffset": 66}, {"referenceID": 29, "context": "It takesO(nd) time by solving quadratic programs directly [21, 31].", "startOffset": 58, "endOffset": 66}, {"referenceID": 7, "context": "QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on.", "startOffset": 75, "endOffset": 78}, {"referenceID": 28, "context": "QP-based algorithms are widely used in open source projects such as libsvm [8], scikit-learn [30] and so on.", "startOffset": 93, "endOffset": 97}, {"referenceID": 14, "context": "For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1\u2212 )-approximation with O(nd/ \u03b2) running time where \u03b2 is the distance between the two polytopes of the two types of points after we scale all points in a unit ball.", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "For hard-margin SVM, based on the geometric linear separable property, Gartner and Jaggi [16] showed that Gilbert algorithm [17] achieves a (1\u2212 )-approximation with O(nd/ \u03b2) running time where \u03b2 is the distance between the two polytopes of the two types of points after we scale all points in a unit ball.", "startOffset": 124, "endOffset": 128}, {"referenceID": 21, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 33, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 11, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 11, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 13, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 1, "context": "For the l2-SVM and C-SVM, since we can transform the quadratic programs to a single-objective unconstrained optimization problem, there also exist efficient algorithms for the two variants [23, 35, 13, 13, 15, 2].", "startOffset": 189, "endOffset": 212}, {"referenceID": 29, "context": "Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for \u03bd-SVM.", "startOffset": 99, "endOffset": 107}, {"referenceID": 32, "context": "Except the traditional quadratic programming approach such as Sequential Minimal Optimization(SMO) [31, 34], there is no better algorithm with the theoretical guarantee for \u03bd-SVM.", "startOffset": 99, "endOffset": 107}, {"referenceID": 12, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 27, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 25, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 24, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 8, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 16, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 38, "context": "A number of distributed algorithms for SVM in this setting have been obtained in the past [14, 29, 27, 26, 9, 18, 40].", "startOffset": 90, "endOffset": 117}, {"referenceID": 37, "context": "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).", "startOffset": 160, "endOffset": 168}, {"referenceID": 26, "context": "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).", "startOffset": 160, "endOffset": 168}, {"referenceID": 22, "context": "Typically, the communication complexity is one of the most important performance measurements for distributed algorithms, and has been studied extensively (see [39, 28] and the book [24] for more details).", "startOffset": 182, "endOffset": 186}, {"referenceID": 23, "context": "[25] proposed a distributed algorithm with O(kd/ ) communication cost, where k is the number of the clients.", "startOffset": 0, "endOffset": 4}, {"referenceID": 39, "context": "Hard-Margin SVM: Inspired by the recent work of Zhang and Lin [41] and Allen-Zhu et al.", "startOffset": 62, "endOffset": 66}, {"referenceID": 2, "context": "[3], we propose a new perspective for solving hard-margin SVM via saddle point optimization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "Compared to Gilbert algorithm [16], our algorithm improves the running time by a factor of \u221a d/ \u221a .", "startOffset": 30, "endOffset": 34}, {"referenceID": 4, "context": "It is known that \u03bd-SVM is equivalent to computing the distance between two reduced polytopes [5, 12].", "startOffset": 93, "endOffset": 100}, {"referenceID": 10, "context": "It is known that \u03bd-SVM is equivalent to computing the distance between two reduced polytopes [5, 12].", "startOffset": 93, "endOffset": 100}, {"referenceID": 19, "context": "Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n.", "startOffset": 55, "endOffset": 63}, {"referenceID": 29, "context": "Compared with the QP-based algorithms in previous work [21, 31], our algorithm significantly improves the running time, by a factor of n.", "startOffset": 55, "endOffset": 63}, {"referenceID": 28, "context": "The experimental result shows that our algorithm is much faster than the previous QP based algorithm NuSVC, implemented in scikit-learn [30].", "startOffset": 136, "endOffset": 140}, {"referenceID": 23, "context": "[25] proposed a distributed algorithm withO(kd/ ) communication cost where k is the number of the clients.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "Moreover, this communication cost is almost optimal according to the lower bound provided in [25].", "startOffset": 93, "endOffset": 97}, {"referenceID": 30, "context": "In Section 4, we provide the experimental results, including our algorithm of \u03bd-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16].", "startOffset": 209, "endOffset": 213}, {"referenceID": 14, "context": "In Section 4, we provide the experimental results, including our algorithm of \u03bd-SVM versus the QP based algorithm NuSVC and our distributed algorithms for SVM versus traditional distributed algorithm HOGWILD! [32] and Gilbert Algorithm [16].", "startOffset": 236, "endOffset": 240}, {"referenceID": 21, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 78, "endOffset": 97}, {"referenceID": 33, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 78, "endOffset": 97}, {"referenceID": 11, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 78, "endOffset": 97}, {"referenceID": 13, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 78, "endOffset": 97}, {"referenceID": 1, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 78, "endOffset": 97}, {"referenceID": 20, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 134, "endOffset": 146}, {"referenceID": 34, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 134, "endOffset": 146}, {"referenceID": 18, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 134, "endOffset": 146}, {"referenceID": 36, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 173, "endOffset": 181}, {"referenceID": 35, "context": "Basically, there are three main strategies: the primal gradient-based methods [23, 35, 13, 15, 2], dual quadratic programming methods [22, 36, 20] and dual geometry methods [38, 37].", "startOffset": 173, "endOffset": 181}, {"referenceID": 1, "context": "Recently, Allen-Zhu [2] provided the current best algorithms which achieve O(nd/ \u221a ) time for l2-SVM and O(nd/ ) time for C-SVM.", "startOffset": 20, "endOffset": 23}, {"referenceID": 2, "context": "[3] used the saddle point optimization and obtained an \u00d5(nd + n \u221a d/ \u221a ) algorithm for the minimum enclosing ball problem (MinEB) in Euclidean space.", "startOffset": 0, "endOffset": 3}, {"referenceID": 36, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 17, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 14, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 9, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 31, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 35, "context": "This result also implies algorithms for l2-SVM directly by the connection of MinEB and l2-SVM (see [38, 19, 16, 10, 33, 37]).", "startOffset": 99, "endOffset": 123}, {"referenceID": 36, "context": "[38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.", "startOffset": 0, "endOffset": 8}, {"referenceID": 35, "context": "[38, 37], the dual of l2-SVM is equivalent to a MinEB by a specific feature mapping.", "startOffset": 0, "endOffset": 8}, {"referenceID": 4, "context": "The dual problem of (1) is equivalent to the problem of finding the two closest points between the convex hulls of two types of points [5].", "startOffset": 135, "endOffset": 138}, {"referenceID": 2, "context": "This is a commonly used approach in optimization (see [3] for example).", "startOffset": 54, "endOffset": 57}, {"referenceID": 10, "context": "Next, we discuss \u03bd-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.", "startOffset": 28, "endOffset": 36}, {"referenceID": 32, "context": "Next, we discuss \u03bd-SVM (see [12, 34]) and again provide an equivalent saddle point optimization formulation.", "startOffset": 28, "endOffset": 36}, {"referenceID": 10, "context": "Crisp and Burges [12] present a geometry interpretation for \u03bd-SVM.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "We first apply a randomized Hadamard space rotation as in [3].", "startOffset": 58, "endOffset": 61}, {"referenceID": 0, "context": "It is well known [1] that with high probability, for any point xi we have \u2200j \u2208 [d], |(HDxi)j | \u2264 O( \u221a log n/d).", "startOffset": 17, "endOffset": 20}, {"referenceID": 5, "context": "The update rules use some useful technique for speeding up the convergence, such as the proximal gradient method and momentum (see the book [6]).", "startOffset": 140, "endOffset": 143}, {"referenceID": 3, "context": "The above update rules of \u03b7 and \u03be can be also considered as the multiplicative weight update method (see [4]).", "startOffset": 105, "endOffset": 108}, {"referenceID": 28, "context": "In this section, we first compare our SVMSPSolver with library NuSVC in scikitlearn [30].", "startOffset": 84, "endOffset": 88}, {"referenceID": 30, "context": "Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25].", "startOffset": 112, "endOffset": 116}, {"referenceID": 23, "context": "Second, in the distributed setting, we compare DisSVMSPSolver with two distributed algorithms for SVM, HOGWILD! [32] and distributed Gilbert algorithm [25].", "startOffset": 151, "endOffset": 155}, {"referenceID": 7, "context": "The real data is from [8].", "startOffset": 22, "endOffset": 25}, {"referenceID": 28, "context": "The experimental results for \u03bd-Saddle: We compare our SVMSPSolver with NuSVC in scikit-learn [30] and summarize the results in Table 1.", "startOffset": 93, "endOffset": 97}, {"referenceID": 30, "context": "Distributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Distributed experiments: In the distributed setting, we compare our algorithms with HOGWILD! [32] and distributed Gilbert algorithm [25].", "startOffset": 132, "endOffset": 136}, {"referenceID": 7, "context": "We also select the real world datasets \u201cphishing\u201d and \u201ca9a\u201d from [8].", "startOffset": 65, "endOffset": 68}], "year": 2017, "abstractText": "Support Vector Machine is one of the most classical approaches for classification and regression. Despite being studied for decades, obtaining practical algorithms for SVM is still an active research problem in machine learning. In this paper, we propose a new perspective for SVM via saddle point optimization. We provide an algorithm which achieves (1 \u2212 )-approximations with running time \u00d5(nd + n \u221a d/ ) for both separable (hard margin SVM) and non-separable cases (\u03bd-SVM ), where n is the number of points and d is the dimensionality. To the best of our knowledge, the current best algorithm for hard margin SVM achieved by Gilbert algorithm [16] requires O(nd/ ) time. Our algorithm improves the running time by a factor of \u221a d/ \u221a . For \u03bd-SVM, besides the well known quadratic programming approach which requires \u03a9(nd) time [21, 31], no better algorithm is known. In the paper, we provide the first nearly linear time algorithm for \u03bd-SVM. We also consider the distributed settings and provide distributed algorithms with low communication cost via saddle point optimization. Our algorithms require \u00d5(k(d+ \u221a d/ )) communication cost where k is the number of clients, almost matching the theoretical lower bound.", "creator": "LaTeX with hyperref package"}}}