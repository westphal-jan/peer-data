{"id": "1705.08044", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-May-2017", "title": "Detection Algorithms for Communication Systems Using Deep Learning", "abstract": "the design and analysis of communication systems typically rely on the development of mathematical models that describe the underlying communication channel, which dictates the relationship between the transmitted and the received signals. normally however, in some systems, such : as molecular communication systems where chemical signals are used for transfer of information, it is completely not possible to accurately model this relationship. in these scenarios, because of the lack of mathematical channel models, a completely new approach to design synthesis and analysis is required. in this work, we actively focus historically on one important aspect of communication systems, the detection algorithms, and demonstrate proof that by borrowing tools from deep learning, it commonly is possible to train detectors that perform well, without any knowledge of the underlying channel models. we evaluate either these algorithms using experimental data that is routinely collected by a chemical signals communication platform, typically where the mechanical channel mechanism model is unknown and difficult to model correctly analytically. we show that deep learning automation algorithms perform significantly better than any a simple detector that was used in completely previous works, which just also did not assume any knowledge of the channel.", "histories": [["v1", "Mon, 22 May 2017 23:47:47 GMT  (3586kb,D)", "https://arxiv.org/abs/1705.08044v1", null], ["v2", "Mon, 31 Jul 2017 02:43:27 GMT  (3586kb,D)", "http://arxiv.org/abs/1705.08044v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.ET", "authors": ["nariman farsad", "andrea goldsmith"], "accepted": false, "id": "1705.08044"}, "pdf": {"name": "1705.08044.pdf", "metadata": {"source": "CRF", "title": "Detection Algorithms for Communication Systems Using Deep Learning", "authors": ["Nariman Farsad"], "emails": ["nfarsad@stanford.edu", "andrea@wsl.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "The design and analysis of communication systems typically rely on developing mathematical models that describe signal transmission, signal propagation, receiver noise, and many of the other components of the system that affect the end-to-end signal transmission. Particularly, most communication systems today lend themselves to tractable channel models based on a simplification of Maxwell\u2019s equations. However, there are cases where this does not hold, either because the electromagnetic (EM) signal propagation is very complicated and/or poorly understood, or because the signal is not an EM signal and hence good models for its propagation don\u2019t exist. Some examples of the latter includes underwater communication using acoustic signals [1], and a new technique called molecular communication, which relies on chemical signals to interconnect tiny devices with submillimeter dimensions in environments such as inside the human body [2, 3, 4, 5]. In many chemical communication systems, the underlying channel models are unknown and it is difficult to derive tractable analytical models. For example, signal propagation in chemical communication channels with multiple reactive chemicals are highly complex [6]. Therefore, an approach to design and engineer these systems that does not require analytical channel models is required.\nMachine learning and deep learning are techniques that could be used for this task [7, 8, 9]. Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16]. Most previous work have used machine learning and deep learning\nar X\niv :1\n70 5.\n08 04\n4v 2\n[ cs\n.L G\n] 3\n1 Ju\nl 2 01\nto improve one component of the communication system based on the knowledge of the underlying channel models.\nOur approach is different from these work since we assume that the mathematical models for the communication channel are completely unknown. Particularly, we focus on one of the important modules of any communication system, the detection algorithm, where the transmitted signal is estimated from a noisy and corrupted version that is observed at the receiver. We demonstrate that, using deep learning, it is possible to train a detector without any knowledge of the underlying channel models. In this scheme, the receiver goes through a training phase where a deep learning detector is trained using known transmission signals. At first glance, this may seem like extra overhead. However, any channel model needs to be validated experimentally before it can used for designing detection algorithms. In fact, even in wireless radio communication, experimental data are used to \u201ctrain\u201d and \u201clearn\u201d (i.e., validate and revise) the channel models. Another important benefit of using deep learning detectors is that they return likelihoods of each symbol, which is used in soft decision error correction decoders that are typically the next module in a communication system after the detector.\nTo evaluate the performance of deep learning detectors, we focus on molecular communication where chemical signals are used to transfer messages [2, 3, 4, 5]. Molecular communication is a perfect platform for evaluation since the underlying channel models are nonlinear and unknown. An experimental platform is used for collecting measurement data, which is used to train and evaluate the deep learning detection algorithms. We demonstrate that for this setup deep learning detectors perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel [17, 18].\nNote that although the proposed techniques can be used with any communication system, use of these techniques in chemical communication systems enable many interesting applications. For example, one particular area of interest is in-body communication where bio-sensors, such as synthetic biological devices, constantly monitor the body for different bio-markers for diseases [19]. Naturally, these biological sensors, which are adapt at detecting biomarkers in vivo [20, 21, 22], need to convey their measurements to the outside world. Chemical signaling is a natural solution to this communication problem where the sensor nodes chemically send their measurements to each other or to other devices under/on the skin. The device on the skin is connected to the Internet through wireless technology and can therefore perform complex computations. Thus, the experimental platform we use in this work to validate deep learning algorithms for signal detection can be used directly to support this important application.\nThe rest of the paper is organized as follows. In Section 2, we present the problem statement. Then in Section 3, detection algorithms based on deep learning are introduced. An experimental platform, which is used for data collection, is presented in Section 4. Section 5 compares the performance of different detection algorithms, and concluding remarks are provided in Section 6."}, {"heading": "2 Problem Statement", "text": "In a digital communication system a message is converted into a sequence of transmission symbols that represent different transmission signals. Let X = {s1, s2, \u00b7 \u00b7 \u00b7 , sm} be a finite set of all transmission symbols, and xk \u2208 X be the kth transmission symbol. The signal corresponding to the kth transmission propagates in the environment, and a noisy and corrupted version, which is represented by the random vector yk of length `, is detected at the receiver. In a simple memoryless system, the relation between the transmitted symbol and the received signal can be represented by a statistical channel model that characterizes the probability distribution function P (yk | xk). In many communication systems, the channel characteristics have memory, e.g., because of a person moving or in some system due to intersymbol interference (ISI) from previous transmissions. Therefore, the statistics of the channel also depend on the current state of the channel. In this work, we focus on channels with ISI. Note that chemical communication channels suffer from significant ISI. For the ISI channel, the relation between the transmitted signal and the received signal is characterized by the statistical channel model P (yk,yk\u22121, \u00b7 \u00b7 \u00b7 ,y1 | xk, xk\u22121, \u00b7 \u00b7 \u00b7 , x1). The receiver has no prior knowledge of the transmitted signal and a detection algorithm at the receiver is used to estimate the transmitted symbols from the received signals. Let x\u0302k be the symbol estimated\nby the detection algorithm for the kth transmission. Then detection can be performed through symbolby-symbol detection where x\u0302k is estimated from yk, or using sequence detection where the sequence x\u0302k, x\u0302k\u22121, \u00b7 \u00b7 \u00b7 , x\u03021 is estimated from the sequence yk,yk\u22121, \u00b7 \u00b7 \u00b7 ,y1. The traditional approach to designing the detection algorithm has relied on probabilistic models of the channel. For example, for a simple channel with no ISI, given by the channel model Pmodel(yk | xk), and a known probability mass function (PMF) for the transmission symbols PX(x) (note that we know this PMF since it is part of the system design), a maximum a posteriori estimation (MAP) algorithm can be devised as\nx\u0302k = argmax x\u2208X\nPmodel(yk | x)PX(x). (1)\nOne major challenge with this technique is that the channel model, and in particular its input-output statistics, has to be known. Moreover, the model has to be simple enough such that (1) can be solved in a computationally efficient manner [23]. In many cases, this may be the case. For example, chemical communication systems may be nonlinear and the analytical channel models may be non-existent [6, 24]. Therefore, this begs the question as to how we can design detectors when the underlying channel models are unknown or are sufficiently complex such that devising computationally efficient detection algorithms may not be possible.\nIn the next section we show how deep learning can be used as a solution to this problem."}, {"heading": "3 Detection Using Deep Learning", "text": "Estimating the transmitted symbol from the received signals yk can be mapped to a clustering problem. Particularly, let m = |X | be the total number of symbols, and let xk be the one-hot representation of the symbol transmitted during the kth transmission, given by\nxk = [1(xk = s1),1(xk = s2), \u00b7 \u00b7 \u00b7 ,1(xk = sm)] \u1d40 , (2)\nwhere 1(.) is the indicator function. Therefore, the element corresponding to the symbol that is transmitted is 1, and all other elements of xk are zero. Note that this is also the PMF of the transmitted symbol during the kth transmission where at the transmitter, with probability 1, one of the symbols is transmitted.\nDesigning the detection algorithm involves two phases. In the first phase, known sequences of transmission symbols are transmitted repeatedly and received by the system to create a set of training data. For example, random number generators with the same seed at the transmitter and receiver could be used for this task. Let XK = [x1,x2, \u00b7 \u00b7 \u00b7 ,xK ] be a sequence of K consecutively transmitted symbols, and YK = [y1,y2, \u00b7 \u00b7 \u00b7 ,yK ] the corresponding sequence of received feature vectors. Then, the training dataset is represented by\n{(X(1)K ,Y (1) K ), (X (2) K ,Y (2) K ), \u00b7 \u00b7 \u00b7 , (X (n) K ,Y (n) K )}, (3)\nwhich consists of n samples of K consecutive transmissions.\nThis dataset is then used to train a deep learning classifier that classifies the received signal yk as one of the transmission symbols in X . The input to the deep learning network can be the received signals yk, or a set of features rk extracted from the received signals. The deep learning network output are the vectors x\u0302k, which is the estimated PMF that the kth transmission symbol belongs to each of the m possible symbols. Note that this output is also useful for soft decision error correction decoders, which are typically the next module after detection. The symbol with the highest mass point in x\u0302k is chosen as the estimated symbol for the kth transmission.\nDuring the training, an optimization algorithm such as stochastic gradient decent is used to minimize the loss between the actual PMF xk in (2), and the estimated PMF x\u0302k [8]. Particularly, in this work we use the categorical cross-entropy loss function L for this optimization [8]. For symbol-by-symbol detection, this function is defined as\nLsymb = H(xk, x\u0302k) = H(xk) +DKL (xk \u2016 x\u0302k) , (4) and for sequence detection, where a sequence of length \u03c4 is estimated from the received signals, it is given by\nLseq = \u03c4\u2211 k=1 H(xk, x\u0302k) = \u03c4\u2211 k=1 H(xk) +DKL (xk \u2016 x\u0302k) , (5)\nwhereH(xk, x\u0302k) is the cross entropy between the correct PMF and the estimated PMF, andDKL (. \u2016 .) is the Kullback-Leibler divergence [25]. Note that minimizing the loss is equivalent to minimizing the cross-entropy or the Kullback-Leibler divergence distance between the true PMF given in (2) and the one estimated based on the neural network. Alternatively, (4) and (5) can be written as\nLsymb = \u2212 log ( x\u0302k[xk] ) , (6)\nLseq = \u2212 \u03c4\u2211 k=1 log ( x\u0302k[xk] ) , (7)\nwhere x\u0302k[xk] indicates the element of x\u0302k corresponding to symbol that was actually transmitted, i.e., xk. Note that minimizing (6) and (7) is equivalent to maximizing the log expression, which essentially maximizes the log-likelihoods. Therefore, during the training, known transmission data are used to train a detector that maximizes log-likelihoods. Using Bayes\u2019 theorem, it is easy to show that minimizing the loss in (6) is equivalent to maximizing (1). Therefore, deep learning can be a powerful tool for designing detection algorithms for communication systems, especially when the underlying channel models are unknown. We now discuss several generic architectures that can be used for symbol-by-symbol and sequence detection."}, {"heading": "3.1 Symbol-by-Symbol Detection", "text": "The most basic neural network architecture that can be employed for detection uses several dense neural network layers followed by a final softmax layer [7, 8]. In this network, the ith layer is given by\noi = f(Wioi\u22121 + bi), (8)\nwhere f() is the activation function, Wi and bi are the weight and bias parameters, and oi is the output of the ith layer. The input to the first layer is the received signal yk or the feature vector rk, which is selectively extracted from the received signal through preprocessing. The output of the final layer is of length m (i.e., the cardinality the symbol set), and the activation function for the final layer is the softmax activation given by\n\u03c6i(z) = ezi\u2211 j e zj . (9)\nThis ensures that the output of the layer x\u0302k is a PMF. Figure 1(a) shows the structure of this neural network.\nIn many cases, the received signal may be randomly shifted in time because of random delays introduced by the communication channel. A more sophisticated neural network that is more resilient to this effect is the convolution neural network (CNN) [26, 27, 7]. Essentially, for our purposes the CNN is a set of filters that extracts the most relevant features from the data. The final layer in CNN detector is a dense layer with output of length m, and a softmax activation function, which result in an estimated x\u0302k. Figure 1(b) shows the structure of this neural network.\nFor symbol-by-symbol detection the estimated PMF x\u0302k is given by x\u0302k = [ P\u0302model(x\u0302k = s1|yk), P\u0302model(x\u0302k = s2|yk), \u00b7 \u00b7 \u00b7 , P\u0302model(x\u0302k = sm|yk) ]\u1d40 , (10)\nwhere P\u0302model is the probability of estimating each symbol based on the neural network model used. The better the structure of the neural network at capturing the physical channel characteristics, the better this estimate and the results. Therefore, it is important to use insights from the physical channel characteristics when designing the network architecture."}, {"heading": "3.2 Sequence Detection", "text": "The symbol-by-symbol detector may not perform well in systems with ISI and memory. In this case, sequence detection can be performed using recurrent neural networks (RNN) [7, 8]. In particular, we use long short-term memory (LSTM) networks in this work [28], which is composed of the following\nik = \u03c3(Wy,iyk +Wa,iak\u22121 +Wc,ick\u22121 + bi), (11) fk = \u03c3(Wy,fyk +Wa,fak\u22121 +Wc,fck\u22121 + bf ), (12) ck = fk ck\u22121 + ik tanh(Wy,cyk +Wa,cak\u22121 + bc), (13) uk = \u03c3(Wy,uyk +Wa,uak\u22121 +Wc,uck + bu), (14) ak = uk tanh(ck), (15)\nwhere is the element-wise vector multiplication, W and b are weights and biases, and \u03c3 is the logistic sigmoid function [8]. The output of the LSTM cell is ak, and the hidden state hk (see Figure 1(c)), which is passed to the next cell in the next time instance, are ck and ak. The output of the LSTM may be passed to other LSTM layers as shown in Figure 1(c). Let a(l)k be the output of the final LSTM layer. Then a dense layer with the softmax activation in (9) is used to obtain x\u0302k as\nx\u0302k = \u03c6(Waa (l) k + bx). (16)\nThis estimated x\u0302k is essentially a PMF given by\nx\u0302k =  P\u0302model(x\u0302k = s1|yk,a(l)k\u22121, c (l) k\u22121) \u2248 P\u0302model(x\u0302k = s1|yk,yk\u22121, \u00b7 \u00b7 \u00b7 ,y1) P\u0302model(x\u0302k = s2|yk,a(l)k\u22121, c (l) k\u22121) \u2248 P\u0302model(x\u0302k = s2|yk,yk\u22121, \u00b7 \u00b7 \u00b7 ,y1)\n... P\u0302model(x\u0302k = sm|yk,a(l)k\u22121, c (l) k\u22121) \u2248 P\u0302model(x\u0302k = sm|yk,yk\u22121, \u00b7 \u00b7 \u00b7 ,y1)  , (17) where P\u0302model is the probability of estimating each symbol based on the neural network model used. Note that the decoder considers the information from previously received signals, encoded in a(l)k\u22121 and c(l)k\u22121, as well as the received signal from current symbol for detection.\nOne issue with this detector is that the signal that is received in the jth transmission yj where j > k may carry information about the kthsymbol xk, and this signal is not considered by the detector. One way to overcome this limitation is by using bidirectional RNNs (BRNNs) [29] on sequences of fixed length \u03c4 (see Figure 1(d)). Particularly, we use a bidirectional LSTM network [30]. In this network, the sequence of received signals are once fed in the forward direction into one LSTM cell (11)-(15) resulting in output \u2212\u2192a k, and once fed in backwards into another LSTM cell resulting in the output \u2190\u2212a k. The two outputs may be passed to more bidirectional layers. Let \u2212\u2192a (l)k and\n\u2190\u2212a (l)k be the outputs of the final bidirectional layer. Then a dense layer with softmax activation is used to obtain x\u0302k as\nx\u0302k = \u03c6(W\u2212\u2192a \u2212\u2192a (l)k +W\u2190\u2212a \u2190\u2212a (l)k + bx). (18) This estimated x\u0302k is essentially a PMF given by\nx\u0302k =  P\u0302model(x\u0302k = s1|yk,\u2212\u2192a (l)k\u22121, \u2212\u2192c (l)k\u22121, \u2190\u2212a (l)k\u22121, \u2190\u2212c (l)k\u22121)\u2248 P\u0302model(x\u0302k = s1|y\u03c4 ,y\u03c4\u22121,\u00b7 \u00b7 \u00b7 ,y1) P\u0302model(x\u0302k = s2|yk,\u2212\u2192a (l)k\u22121, \u2212\u2192c (l)k\u22121, \u2190\u2212a (l)k\u22121, \u2190\u2212c (l)k\u22121)\u2248 P\u0302model(x\u0302k = s2|y\u03c4 ,y\u03c4\u22121,\u00b7 \u00b7 \u00b7 ,y1) ...\nP\u0302model(x\u0302k = sm|yk,\u2212\u2192a (l)k\u22121, \u2212\u2192c (l)k\u22121, \u2190\u2212a (l)k\u22121, \u2190\u2212c (l)k\u22121)\u2248 P\u0302model(x\u0302k = sm|y\u03c4 ,y\u03c4\u22121,\u00b7 \u00b7 \u00b7 ,y1)  . (19)\nTherefore, the current symbol is decoded based on the signal received during the current symbol, as well as all the other signals received over the sequence of length \u03c4 , which are encoded in \u2212\u2192a (l)k\u22121, \u2212\u2192c (l)k\u22121, \u2190\u2212a (l)k\u22121, and\n\u2190\u2212c (l)k\u22121. To evaluate the performance of the deep learning detection algorithms, we use an experimental platform to collect data for training and testing the algorithms. In the next section we describe this platform."}, {"heading": "4 Experimental Setup", "text": "We consider a chemical communication system for evaluating the performance of deep learning detection algorithms. There are several benefits to using this system. First, the experimental platform is inexpensive and can be used to collect large amounts of data required for training and testing. Second, chemical communication channels are poorly understood and the underlying endto-end channel models are unknown. Third, the multi-chemical signal propagation, where multiple reactive chemical are present in the environment, tend to be inherently nonlinear, which makes deep learning detection an attractive solution. Finally, for the envisioned application of in-body chemical communication, where biological sensing devices [20, 21, 22] monitor the body and chemically send their measurements to a device on or under the skin, each person may have different body chemistry, which may require detection algorithms trained on each individual.\nFigure 2 shows a demonstrator for a single-link point-to-point in-vessel communication system. The platform uses peristaltic pumps to inject different chemicals into a main fluid flow in small silicon tubes. Multiple tubes with different diameters can be networked in branches to replicate a more complex environment such as the cardiovascular system in the body or complex networks of pipes in industrial complexes and city infrastructures. In the platform, there is always a main fluid flow in the tubes, for example, water or blood. The transmitter uses peristaltic pumps to inject different reactive chemicals into the main flow. Some examples includes acids and bases, or proteins, carbohydrates and enzymes. The central receiver uses a sensor such as a pH electrode or a glucose sensor to detect the chemical signals transmitted by the sender. In our platform, the main fluid flow is water and the transmitter used acids (vinegar) and bases (window cleaning solution) to encode information on the pH level. We use these particular chemicals since they are easily available and inexpensive. However, the results can be extended to blood as the main flow, and proteins and enzymes as the chemicals that are released by the transmitter.\nIn the platform, time-slotted communication is employed where the transmitter modulates information on acid and base signals by injecting these chemicals into the channel during each symbol duration. We use a simple binary modulation in this work where the bit-0 is transmitted by pumping acid into the environment for 30 ms at the beginning of the symbol interval, and bit-1 is represented by pumping base into the environment for 30 ms at the beginning of the symbol interval. The symbol interval then depends on the period of silence that follows the 30 ms chemical injection. In particular, four different pause durations of 220 ms, 304 ms, 350 ms, and 470 ms are used in this work to represent bit rates of 4, 3, 2.6, and 2 bps.\nTo synchronize the transmitter and the receiver, every message sequence starts with one initial injection of acid into the environment for 100 ms, followed by 900 ms of silence. The receiver then detects the starting point of this pulse and uses it to synchronize itself with the transmitter. Figure 3\nshows the received pH signal for the transmission sequence \u201c110011010001001\u201d. The start of the initial acid pulse detected by the receiver is shown using the red line. This detected time is used for synchronization and all the subsequent symbol intervals are shown by the green dashed and dotted lines. The dashed lines are used to indicate a bit-1 transmission and dotted lines to indicate a bit-0. A special termination sequence can be used to indicate the end of transmission. For example, if 5-bit encoded letters are used [17], the all zero sequence can be used to signal the end of transmission.\nAlthough it is difficult to obtain analytical models for multi-chemical communication systems [6], it is expected that when an acid pulse is transmitted, the pH should drop, and when a base pulse is injected into the environment, the pH should increase. Therefore, one approach to detection is to use the rate of change of pH to detect the symbols. To remove the noise from the raw pH signal, we divide the symbol interval (the time between green lines in Figure 3) into a number of equal subintervals or bins. Then the pH values inside each bin are averaged to represent the pH value for the corresponding bin. Let B be the number of bins, and b = [b1, b2, \u00b7 \u00b7 \u00b7 , bB ] the corresponding values of each bin. The difference between values of these bins d = [d1, d2, \u00b7 \u00b7 \u00b7 , dB\u22121], where di\u22121 = bi \u2212 bi\u22121, are used as a baseline detection algorithm. This algorithm has two parameters: the number of bins B, and the index \u03b3 that is used for detection. If d\u03b3 \u2264 0, acid transmission and hence bit-0 is detected, and if d\u03b3 > 0, bit-1 is detected. This technique was used in previous work for detection [17, 18]. In the next section we compare this to the deep learning detection algorithms presented in previous sections."}, {"heading": "5 Results", "text": "We use our experimental platform to collect measurement data and create the data set that is used for training and testing the detection algorithms. Particularly, as explained in the previous section, four symbol intervals of 250 ms, 334 ms, 380 ms and 500 ms are considered which results in data rates ranging from 2 to 4 bits per second (bps). For each symbol interval, random bit sequences of length 120 are transmitted 100 times, where each of the 100 transmissions are separated in times. This results in 12k bits per symbol interval that is used for training and testing. From the data, 84 transmissions per symbol interval (10,080 bits) are used for training and 16 transmissions are used for testing (1,920 bits). Therefore, the total number of training bits are 40,320, and the total number of bits used for testing is 7,680.\nWe start by considering the baseline detection using the rate of change of the pH. We use the training data to find the best detection parameters B and \u03b3, and the test data for evaluating the performance. Besides this algorithm we consider different deep learning detectors. For all training, the Adam optimization algorithm [31] is used with the learning rate 10\u22123. Unless specified otherwise the number of epoch used during training is 200 and the batch size is 10.\nWe use two symbol-by-symbol detectors based on deep learning. The first detector uses three dense layers with 80 hidden nodes and a final softmax layer for detection. Each dense layer uses the rectified linear unit (ReLU) activation function [8]. The input to the network are a set of features extracted from the received signal, which are chosen based on performance and the characteristics of the physical channel. The input includes: b1 and bB , i.e., the pH level in the first and the last bins, d, i.e., the vector of differences of consecutive bins, and a number that indicates the symbol duration. Here, we refer to this network as Dense-Net. A second symbol-by-symbol detector uses 1-dimensional CNNs. Particularly, the best network architecture that we found has the following\nlayers. 1) 16 filters of length 2 with ReLU activation; 2) 16 filters of length 4 with ReLU activation; 3) max pooling layer with pool size 2; 4) 16 filters of length 6 with ReLU activation; 5) 16 filters of length 8 with ReLU activation; 6) max pooling layer with pool size 2; 7) flatten and a softmax layer. The stride size for the filters is 1 in all layers. The input to this network is the vector of pH values corresponding to each bin b. We refer to this network as CNN-Net.\nFor the sequence detection, we use three networks, two based on the architecture in Figure 1(c) and one based on 1(d). The first network has 3 LSTM layers and a final softmax layer, where the length of the output of each LSTM layer is 40. Two different inputs are used with this network. In the first, the input is the same set of features as the Dense-Net above. We refer to this network as LSTM3-Net. In the second, the input is the pretrained CNN-Net described above without the top softmax layer. In this network, the CNN-Net chooses the features directly from the pH levels of the bins. We refer to this network as CNN-LSTM3-Net. Finally, we consider three layers of bidirectional LSTM cells, where each cell\u2019s output length is 40, and a final softmax layer. The input to this network are the same set of features used for Dense-Net and the LSTM3-Net. We refer to this network as BiLSTM3-Net.\nFor each of the networks, one parameter of interest that affects the input to the networks is the number of bins B. We have trained each network using different bin numbers to find the best value for each network. For the Dense-Net B = 9, for the CNN-Net B = 30 and for all networks where the first layer is an LSTM cell B = 8. Note that during the training, for all deep learning detectors, the data from all symbol durations are used to train a single network, which can then perform detection on all symbol durations.\nWe first compare the bit error rate (BER) performance of LSTM3-Net with BiLSTM3-Net as a function of sequence length. Figure 4 shows this result. Note that the number of epoch used for this plot is 50 and batch size 32. Since BiLSTM3-Net considers the received signal over the whole sequence for detection, on average, it performs better than LSTM3-Net. However, one issue with BiLSTM3-Net is that it must wait for the whole sequence to arrive before detection, whereas LSTM3Net can detect each symbol as it arrives. Generally, for both networks the bit error rate drops as the sequence length increases.\nTable 1 BER performance we were able to obtain for all detection algorithms, including the baseline algorithm. The number in front of the sequence detectors, indicates the sequence length. For example, LSTM3-Net120 is an LSTM3-Net that is trained on 120 bit sequences. In general, algorithms that use sequence detection perform significantly better than any symbol-by-symbol detection algorithm including the baseline algorithm. This is due to significant ISI present in chemical communication systems. Without knowing the channel models, it is difficult to devise sophisticated detection algorithms. This demonstrates the effectiveness of deep learning detectors in communication systems."}, {"heading": "6 Conclusions", "text": "We used several deep learning architectures for building detectors for communication systems. Different architectures were considered for symbol-by-symbol detection as well as sequence detection. These algorithms have many potentials in systems where the underlying physical models of the channel are unknown or inaccurate. For example, molecular communication, which has many potential applications in medicine is very difficult to model using tractable analytical models. We use an experimental platform that simulates in-vessel chemical communication to collect experimental data for training and testing deep learning algorithms. We show that deep learning sequence detectors can improve the detection performance significantly compared to a baseline approach that also does not rely on channel models. This demonstrates the promising performance deep learning detection algorithms could have in designing future communication systems. Some interesting open problems that we would like to explore in the future are as follows. First, we would like to perform more parameter tuning to find better neural networks for detection. Another important problem we plan to explore is how resilient deep learning detectors are to changing channel conditions, for example, as the concentration of acid and base is changed, and what would be good protocols for quickly retraining the network when a change in channel conditions is detected. Finally, we plan to collect more data on our platform, and make our dataset publicly available to other researchers."}], "references": [{"title": "Underwater acoustic communication channels: Propagation models and statistical characterization", "author": ["M. Stojanovic", "J. Preisig"], "venue": "IEEE Communications Magazine, vol. 47, no. 1, pp. 84\u201389, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Molecular communication for health care applications", "author": ["Y. Moritani", "S. Hiyama", "T. Suda"], "venue": "Proc. of 4th Annual IEEE International Conference on Pervasive Computing and Communications Workshops, Pisa, Italy, 2006, p. 5.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Nanonetworks: A new communication paradigm", "author": ["I.F. Akyildiz", "F. Brunetti", "C. Blazquez"], "venue": "Computer Networks, vol. 52, no. 12, pp. 2260\u20132279, August 2008.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "A comprehensive survey of recent advancements in molecular communication", "author": ["N. Farsad", "H.B. Yilmaz", "A. Eckford", "C.B. Chae", "W. Guo"], "venue": "IEEE Communications Surveys & Tutorials, vol. 18, no. 3, pp. 1887\u20131919, thirdquarter 2016.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1887}, {"title": "Chemistry in Motion: Reaction-Diffusion Systems for Micro- and Nanotechnology", "author": ["B. Grzybowski"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, vol. 521, no. 7553, pp. 436\u2013444, May 2015. [Online]. Available: http://dx.doi.org/10.1038/nature14539", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "Applications of neural networks to digital communications \u2013 a survey", "author": ["M. Ibnkahla"], "venue": "Signal Processing, vol. 80, no. 7, pp. 1185\u20131215, 2000.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2000}, {"title": "Neural networks for multiuser detection in code-division multiple-access communications", "author": ["B. Aazhang", "B.P. Paris", "G.C. Orsak"], "venue": "IEEE Transactions on Communications, vol. 40, no. 7, pp. 1212\u20131222, Jul 1992.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1992}, {"title": "Neural network techniques for adaptive multiuser demodulation", "author": ["U. Mitra", "H.V. Poor"], "venue": "IEEE Journal on Selected Areas in Communications, vol. 12, no. 9, pp. 1460\u20131470, Dec 1994.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1994}, {"title": "Gaussian processes for multiuser detection in cdma receivers", "author": ["J.J. Murillo-fuentes", "S. Caro", "F. P\u00e9rez-Cruz"], "venue": "Advances in Neural Information Processing Systems 18, Y. Weiss, P. B. Sch\u00f6lkopf, and J. C. Platt, Eds. MIT Press, 2006, pp. 939\u2013946.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Multiuser detection with neural network and pic in cdma systems for awgn and rayleigh fading asynchronous channels", "author": ["Y. I\u015f\u0131k", "N. Ta\u015fp\u0131nar"], "venue": "Wireless Personal Communications, vol. 43, no. 4, pp. 1185\u20131194, 2007.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning to decode linear codes using deep learning", "author": ["E. Nachmani", "Y. Be\u2019ery", "D. Burshtein"], "venue": "2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton), Sept 2016, pp. 341\u2013346.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Learning to communicate: Channel auto-encoders, domain specific regularizers, and attention", "author": ["T.J. O\u2019Shea", "K. Karra", "T.C. Clancy"], "venue": "2016 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), Dec 2016, pp. 223\u2013228.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Machine learning based channel modeling for molecular MIMO communications", "author": ["C. Lee", "H.B. Yilmaz", "C.-B. Chae", "N. Farsad", "A. Goldsmith"], "venue": "IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), 1997.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Tabletop molecular communication: Text messages through chemical signals", "author": ["N. Farsad", "W. Guo", "A.W. Eckford"], "venue": "PLOS ONE, vol. 8, no. 12, p. e82935, Dec 2013.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Molecular MIMO: From theory to prototype", "author": ["B.H. Koo", "C. Lee", "H.B. Yilmaz", "N. Farsad", "A. Eckford", "C.B. Chae"], "venue": "IEEE Journal on Selected Areas in Communications, vol. 34, no. 3, pp. 600\u2013614, March 2016.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2016}, {"title": "Body area nanonetworks with molecular communications in nanomedicine", "author": ["B. Atakan", "O. Akan", "S. Balasubramaniam"], "venue": "IEEE Communications Magazine, vol. 50, no. 1, pp. 28\u201334, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Environmentally controlled invasion of cancer cells by engineered bacteria", "author": ["J.C. Anderson", "E.J. Clarke", "A.P. Arkin", "C.A. Voigt"], "venue": "Journal of Molecular Biology, vol. 355, no. 4, pp. 619\u2013627, 2006. 9", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2006}, {"title": "Programmable probiotics for detection of cancer in urine", "author": ["T. Danino", "A. Prindle", "G.A. Kwong", "M. Skalak", "H. Li", "K. Allen", "J. Hasty", "S.N. Bhatia"], "venue": "Science Translational Medicine, vol. 7, no. 289, pp. 289ra84\u2013 289ra84, 2015.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Synthetic biology devices for in vitro and in vivo diagnostics", "author": ["S. Slomovic", "K. Pardee", "J.J. Collins"], "venue": "Proceedings of the National Academy of Sciences, vol. 112, no. 47, pp. 14 429\u201314 435, Nov. 2015.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "Time-slotted transmission over molecular timing channels", "author": ["Y. Murin", "N. Farsad", "M. Chowdhury", "A. Goldsmith"], "venue": "Nano Communication Networks, vol. 12, pp. 12\u201324, 2017.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2017}, {"title": "A molecular communication system using acids, bases and hydrogen ions", "author": ["N. Farsad", "A. Goldsmith"], "venue": "2016 IEEE 17th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), 2016, pp. 1\u20136.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "Face recognition: A convolutional neural-network approach", "author": ["S. Lawrence", "C.L. Giles", "A.C. Tsoi", "A.D. Back"], "venue": "IEEE transactions on neural networks, vol. 8, no. 1, pp. 98\u2013113, 1997.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "Advances in neural information processing systems, 2012, pp. 1097\u20131105.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 1997}, {"title": "Bidirectional recurrent neural networks", "author": ["M. Schuster", "K.K. Paliwal"], "venue": "IEEE Transactions on Signal Processing, vol. 45, no. 11, pp. 2673\u20132681, 1997.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1997}, {"title": "Framewise phoneme classification with bidirectional lstm and other neural network architectures", "author": ["A. Graves", "J. Schmidhuber"], "venue": "Neural Networks, vol. 18, no. 5, pp. 602\u2013610, 2005.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2005}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980, 2014. 10", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Some examples of the latter includes underwater communication using acoustic signals [1], and a new technique called molecular communication, which relies on chemical signals to interconnect tiny devices with submillimeter dimensions in environments such as inside the human body [2, 3, 4, 5].", "startOffset": 85, "endOffset": 88}, {"referenceID": 1, "context": "Some examples of the latter includes underwater communication using acoustic signals [1], and a new technique called molecular communication, which relies on chemical signals to interconnect tiny devices with submillimeter dimensions in environments such as inside the human body [2, 3, 4, 5].", "startOffset": 280, "endOffset": 292}, {"referenceID": 2, "context": "Some examples of the latter includes underwater communication using acoustic signals [1], and a new technique called molecular communication, which relies on chemical signals to interconnect tiny devices with submillimeter dimensions in environments such as inside the human body [2, 3, 4, 5].", "startOffset": 280, "endOffset": 292}, {"referenceID": 3, "context": "Some examples of the latter includes underwater communication using acoustic signals [1], and a new technique called molecular communication, which relies on chemical signals to interconnect tiny devices with submillimeter dimensions in environments such as inside the human body [2, 3, 4, 5].", "startOffset": 280, "endOffset": 292}, {"referenceID": 4, "context": "For example, signal propagation in chemical communication channels with multiple reactive chemicals are highly complex [6].", "startOffset": 119, "endOffset": 122}, {"referenceID": 5, "context": "Machine learning and deep learning are techniques that could be used for this task [7, 8, 9].", "startOffset": 83, "endOffset": 92}, {"referenceID": 6, "context": "Machine learning and deep learning are techniques that could be used for this task [7, 8, 9].", "startOffset": 83, "endOffset": 92}, {"referenceID": 7, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 168, "endOffset": 184}, {"referenceID": 8, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 168, "endOffset": 184}, {"referenceID": 9, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 168, "endOffset": 184}, {"referenceID": 10, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 168, "endOffset": 184}, {"referenceID": 11, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 211, "endOffset": 215}, {"referenceID": 12, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 267, "endOffset": 271}, {"referenceID": 13, "context": "Some examples of machine learning tools applied to design problems in communication systems include multiuser detection in code-division multiple-access (CDMA) systems [10, 11, 12, 13], decoding of linear codes [14], design of new modulation and demodulation schemes [15], and estimating channel model parameters [16].", "startOffset": 313, "endOffset": 317}, {"referenceID": 1, "context": "To evaluate the performance of deep learning detectors, we focus on molecular communication where chemical signals are used to transfer messages [2, 3, 4, 5].", "startOffset": 145, "endOffset": 157}, {"referenceID": 2, "context": "To evaluate the performance of deep learning detectors, we focus on molecular communication where chemical signals are used to transfer messages [2, 3, 4, 5].", "startOffset": 145, "endOffset": 157}, {"referenceID": 3, "context": "To evaluate the performance of deep learning detectors, we focus on molecular communication where chemical signals are used to transfer messages [2, 3, 4, 5].", "startOffset": 145, "endOffset": 157}, {"referenceID": 14, "context": "We demonstrate that for this setup deep learning detectors perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel [17, 18].", "startOffset": 199, "endOffset": 207}, {"referenceID": 15, "context": "We demonstrate that for this setup deep learning detectors perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel [17, 18].", "startOffset": 199, "endOffset": 207}, {"referenceID": 16, "context": "For example, one particular area of interest is in-body communication where bio-sensors, such as synthetic biological devices, constantly monitor the body for different bio-markers for diseases [19].", "startOffset": 194, "endOffset": 198}, {"referenceID": 17, "context": "Naturally, these biological sensors, which are adapt at detecting biomarkers in vivo [20, 21, 22], need to convey their measurements to the outside world.", "startOffset": 85, "endOffset": 97}, {"referenceID": 18, "context": "Naturally, these biological sensors, which are adapt at detecting biomarkers in vivo [20, 21, 22], need to convey their measurements to the outside world.", "startOffset": 85, "endOffset": 97}, {"referenceID": 19, "context": "Naturally, these biological sensors, which are adapt at detecting biomarkers in vivo [20, 21, 22], need to convey their measurements to the outside world.", "startOffset": 85, "endOffset": 97}, {"referenceID": 20, "context": "Moreover, the model has to be simple enough such that (1) can be solved in a computationally efficient manner [23].", "startOffset": 110, "endOffset": 114}, {"referenceID": 4, "context": "For example, chemical communication systems may be nonlinear and the analytical channel models may be non-existent [6, 24].", "startOffset": 115, "endOffset": 122}, {"referenceID": 21, "context": "For example, chemical communication systems may be nonlinear and the analytical channel models may be non-existent [6, 24].", "startOffset": 115, "endOffset": 122}, {"referenceID": 5, "context": "The most basic neural network architecture that can be employed for detection uses several dense neural network layers followed by a final softmax layer [7, 8].", "startOffset": 153, "endOffset": 159}, {"referenceID": 22, "context": "A more sophisticated neural network that is more resilient to this effect is the convolution neural network (CNN) [26, 27, 7].", "startOffset": 114, "endOffset": 125}, {"referenceID": 23, "context": "A more sophisticated neural network that is more resilient to this effect is the convolution neural network (CNN) [26, 27, 7].", "startOffset": 114, "endOffset": 125}, {"referenceID": 5, "context": "A more sophisticated neural network that is more resilient to this effect is the convolution neural network (CNN) [26, 27, 7].", "startOffset": 114, "endOffset": 125}, {"referenceID": 5, "context": "In this case, sequence detection can be performed using recurrent neural networks (RNN) [7, 8].", "startOffset": 88, "endOffset": 94}, {"referenceID": 24, "context": "In particular, we use long short-term memory (LSTM) networks in this work [28], which is composed of the following", "startOffset": 74, "endOffset": 78}, {"referenceID": 25, "context": "One way to overcome this limitation is by using bidirectional RNNs (BRNNs) [29] on sequences of fixed length \u03c4 (see Figure 1(d)).", "startOffset": 75, "endOffset": 79}, {"referenceID": 26, "context": "Particularly, we use a bidirectional LSTM network [30].", "startOffset": 50, "endOffset": 54}, {"referenceID": 17, "context": "Finally, for the envisioned application of in-body chemical communication, where biological sensing devices [20, 21, 22] monitor the body and chemically send their measurements to a device on or under the skin, each person may have different body chemistry, which may require detection algorithms trained on each individual.", "startOffset": 108, "endOffset": 120}, {"referenceID": 18, "context": "Finally, for the envisioned application of in-body chemical communication, where biological sensing devices [20, 21, 22] monitor the body and chemically send their measurements to a device on or under the skin, each person may have different body chemistry, which may require detection algorithms trained on each individual.", "startOffset": 108, "endOffset": 120}, {"referenceID": 19, "context": "Finally, for the envisioned application of in-body chemical communication, where biological sensing devices [20, 21, 22] monitor the body and chemically send their measurements to a device on or under the skin, each person may have different body chemistry, which may require detection algorithms trained on each individual.", "startOffset": 108, "endOffset": 120}, {"referenceID": 14, "context": "For example, if 5-bit encoded letters are used [17], the all zero sequence can be used to signal the end of transmission.", "startOffset": 47, "endOffset": 51}, {"referenceID": 4, "context": "Although it is difficult to obtain analytical models for multi-chemical communication systems [6], it is expected that when an acid pulse is transmitted, the pH should drop, and when a base pulse is injected into the environment, the pH should increase.", "startOffset": 94, "endOffset": 97}, {"referenceID": 14, "context": "This technique was used in previous work for detection [17, 18].", "startOffset": 55, "endOffset": 63}, {"referenceID": 15, "context": "This technique was used in previous work for detection [17, 18].", "startOffset": 55, "endOffset": 63}, {"referenceID": 27, "context": "For all training, the Adam optimization algorithm [31] is used with the learning rate 10\u22123.", "startOffset": 50, "endOffset": 54}], "year": 2017, "abstractText": "The design and analysis of communication systems typically rely on the development of mathematical models that describe the underlying communication channel, which dictates the relationship between the transmitted and the received signals. However, in some systems, such as molecular communication systems where chemical signals are used for transfer of information, it is not possible to accurately model this relationship. In these scenarios, because of the lack of mathematical channel models, a completely new approach to design and analysis is required. In this work, we focus on one important aspect of communication systems, the detection algorithms, and demonstrate that by borrowing tools from deep learning, it is possible to train detectors that perform well, without any knowledge of the underlying channel models. We evaluate these algorithms using experimental data that is collected by a chemical communication platform, where the channel model is unknown and difficult to model analytically. We show that deep learning algorithms perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel.", "creator": "LaTeX with hyperref package"}}}