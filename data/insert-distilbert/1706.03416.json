{"id": "1706.03416", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2017", "title": "Learning Large-Scale Topological Maps Using Sum-Product Networks", "abstract": "in order to perform complex construction actions in human environments, an autonomous robot needs the ability to understand the environment, that is, to gather and subsequently maintain spatial knowledge. topological map is commonly used for representing large scale, global maps such as floor plans. although much work has been done in topological map extraction, we have found little previous work on the problem of learning the topological map using a probabilistic model. learning a topological map means further learning the structure of the large - scale space and dependency between places, for example, how the evidence of a group of places influence the attributes topology of other places. this is rather an important step towards planning complex actions in the environment. in this thesis, we consider the problem of using probabilistic deep learning model to learn the topological map, which is essentially a locally sparse undirected graph where nodes represent places closely annotated with their semantic attributes ( e. g. place category ). we propose to use a novel probabilistic deep model, sum - product networks ( spns ), due to their unique properties. we present two methods for learning topological maps using spns : the place grid method and the descriptive template - based method. we contribute an algorithm that builds spns for graphs using quantitative template models. our experiments evaluate the ability of our models to enable robots to infer semantic attributes and detect maps with novel semantic attribute arrangements. indeed our results demonstrate their understanding of the topological map structure and spatial relations between places.", "histories": [["v1", "Sun, 11 Jun 2017 21:52:56 GMT  (1554kb,D)", "https://arxiv.org/abs/1706.03416v1", "26 pages, 14 figures, senior thesis for departmental honors at the Allen School of Computer Science and Engineering at the University of Washington"], ["v2", "Mon, 10 Jul 2017 06:16:23 GMT  (1611kb,D)", "http://arxiv.org/abs/1706.03416v2", "26 pages, 14 figures, senior thesis for departmental honors at the Allen School of Computer Science and Engineering at the University of Washington"]], "COMMENTS": "26 pages, 14 figures, senior thesis for departmental honors at the Allen School of Computer Science and Engineering at the University of Washington", "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["kaiyu zheng"], "accepted": false, "id": "1706.03416"}, "pdf": {"name": "1706.03416.pdf", "metadata": {"source": "CRF", "title": "Learning Large-Scale Topological Maps Using Sum-Product Networks", "authors": ["Kaiyu Zheng"], "emails": [], "sections": [{"heading": null, "text": "I\nContents"}, {"heading": "1 Introduction 1", "text": "1.1 Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Thesis outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2"}, {"heading": "2 Related Works 3", "text": ""}, {"heading": "3 Background 4", "text": "3.1 Sum-Product Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n3.1.1 Definitions and Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 3.1.2 Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 3.1.3 Learning Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 3.1.4 Learning Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n3.2 Deep Affordance Spatial Hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 3.3 Topological Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3.3.1 Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9"}, {"heading": "4 Problem Statement & Proposed Solutions 9", "text": "4.1 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 4.2 Place Grid Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2.1 From Topological Map to Place Grid . . . . . . . . . . . . . . . . . . . . . . . 10 4.2.2 Modeling a Place Grid Using Rotation-Invariant SPN . . . . . . . . . . . . . 11\n4.3 Template-Based Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 4.3.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 4.3.2 Building Instance-Specific SPN for Graphs from Templates . . . . . . . . . . 13"}, {"heading": "5 Experiments 16", "text": "5.1 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 5.2 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5.2.1 Software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 5.2.2 Experiments for Place Grid Method . . . . . . . . . . . . . . . . . . . . . . . 16 5.2.3 Experiments for Template-Based Method . . . . . . . . . . . . . . . . . . . . 17\n5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5.3.1 Place Grid Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5.3.2 Template-Based Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18"}, {"heading": "6 Conclusion & Future Work 21", "text": ""}, {"heading": "7 Acknowledgements 22", "text": "II"}, {"heading": "1 Introduction", "text": "The fundamental value of robotics is two-fold. First, robots can take risks in the place of humans, do what humans cannot or struggle to do. Second, robots can assist humans to achieve their goals in a more efficient and effective way. The last several decades saw an explosion of interest and investment in robotics both in commercial applications and academic research [18], and the field of autonomous robots is expected to be a topic of continuous heavy research. In this thesis, we concentrate on mobile robots in indoor environments. Mobile robots are desirable to fulfill both aspects of the value, especially the latter; They have the potential to provide various kinds of services, and recently attempts have been made to apply mobile robots to real-world problems such as helping older people [11], guiding passengers in airports [29], and telepresence [15]. However, these robots are still far from fully autonomous, and only perform limited actions with specially designed tasks.\nTo enable autonomous mobile robots to exhibit complex behaviors in indoor environments, it is crucial for them to form an understanding of the environment, that is, to gather and maintain spatial knowledge. The framework that organizes this understanding is a spatial knowledge representation. Additionally, due to the uncertainty in human environments, it is also crucial for the robots to be able to learn about the spatial knowledge representation in a probabilistic manner. In this thesis, we use the Deep Affordance Spatial Hierarchy (DASH) [22], a recently proposed hierarchical spatial representation that spans from low-level sensory input to high-level human semantics. The ultimate goal of our research is to use a unified deep generative model to capture all layers of DASH, an approach fundamentally different from the traditional where an assembly of independent spatial models exchange information in a limited way [21]. Specifically, in this thesis, we focus on learning the layer of topological map, a mainstream graphical representation of the information of places and their connectivity in a full floor map. We have chosen to use Sum-Product Networks (SPN) [20], a new class of deep probabilistic models. It is particularly well-suited for our purpose primarily because of three reasons. First, it is a deep generative model, therefore probabilistic by nature. Second, it guarantees tractable training and inference time with respect to the size of the network, a property important in robotics where real-time inference and planning is often required. Third, it is simple to combine multiple SPNs into a single unified SPN with interpretable layers, which naturally matches our purpose of learning a hierarchical representation.\nLearning a topological map means learning the structure of the large-scale space and dependency between places, for example, how the evidence of a group of places influence the attributes of other places. This is an important step towards planning complex actions in the environment. By itself, it is also useful for tasks such as inferring missing information of a place based on the surrounding places. In the context of DASH, it is can be used for correcting the classification results of the local environment model1. Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].\nThere are three main challenges in this work. First, topological maps have varying sizes (number of places and connections), because the underlying environment may have different dimensions. Second, it is not clear how graphs such as topological maps should be modeled2 using an SPN. Third, it is difficult to obtain topological maps for training, therefore the model needs to learn from small datasets.\nWe address the above challenges through our contributions. We present two methods to use SPNs to model topological maps: the place grid method, and the template-based method. Both methods aim to deal with the variability of topological maps but with different emphasis on the\n1In DASH, above the layer of low-level sensory input, there is a layer called \u201cperipersonal layer\u201d which converts sensory input into robot-centric representation of the immediate surroundings, i.e. local environment. More details about DASH is given in section 3.2.\n2In this thesis, \u201cmodeling\u201d a topological map means the same as \u201clearning\u201d it.\n1\ndependency between places. In the place grid method, we project the topological map onto a grid of fixed size, and generate an SPN structure on top of the grid. In the template-based method, we propose an algorithm to build SPNs for graphs based on template models. Each template is a basic graph structure that occurs throughout in the topological map. We train an SPN on a template, or a hierarchy of templates. For each topological map instance, we construct an instance-specific full SPN using the template SPNs as children, and do inference on the full SPN. To our knowledge, these are the first methods to use SPN to model a graph. We evaluate the two methods by experiments and our results show their capability of enabling robots to do inference of environment attributes with promising output, showing the understanding of the spatial relations between places. In addition, we created a large dataset with fully annotated localization, sensory information and virtual scans, a low-level geometry representation of robot-centric environment3. This dataset is used to evaluate our methods."}, {"heading": "1.1 Constraints", "text": "In this thesis, we focus on place category as the only semantic attribute for a place. Our rationale is the following. In terms of the learned model\u2019s potential usage, it would certainly help if other information such as types of objects in a place, or the low-level sensory information, is provided. However, our goal in this work is to evaluate the problem of learning topological maps in separation. The proposed methods naturally extend to the case where more types of semantic attributes or sensory information are considered. This is a direction for future work."}, {"heading": "1.2 Thesis outline", "text": "Section 2 - Related Works We review related works in the use of topological maps as a part of spatial knowledge, learning of topological maps, and recent machine learning techniques used to model graphs.\nSection 3 - Background We discuss details about the theoretical background related to our work. First, we describe details of Sum-Product Networks. Then, we present an overview of the Deep Affordance Spatial Hierarchy. Finally, we formalize the notion of topological map and describe the method we use to extract topological maps.\nSection 4 - Problem Statement & Proposed Solutions We formalize the problem that we try to solve in this thesis. Then, we describe the details of the two presented methods that model topological maps using SPNs: the place grid method and the template-based method.\nSection 5 - Experiments We describe the dataset, methodology, and results of our experiments.\nSection 6 - Conclusion & Future Work We conclude our thesis by providing a summary of the presented methods and experiment results. Finally, we discuss improvements to be made in the future.\n3We plan to publish this dataset to IJRR soon.\n2"}, {"heading": "2 Related Works", "text": "The use of topological maps in navigation and mapping dates back to the work by Kulpers and Byun [14] in 1991, where they first considered the use of qualitative maps to avoid error-prone geometrically precise maps. Topological maps then began to be considered as a form of spatial knowledge [13]. More recently, Beeson et. al. [3] proposed a hybrid approach of spatial knowledge representation that uses metrical representation for local environment and topological representation for large environment. Pronobis et. al. [23] outlined criteria for good spatial knowledge representation where the use of topological map to represent global environment is also promoted.\nAydemir et. al. [1] investigated the statistical properties of indoor environments by analyzing two large floor plan datasets consisting of over 197 buildings and 38,000 rooms in total. They pointed out that indoor environments are not yet well understood. They discovered that local complexity remains unchanged for growing global complexity in real-world indoor environments. This finding provides important statistical support for our template-based method discussed later. They also proposed two methods for predicting room categories for a given topological map, but their methods rely on the maintenance of a large dataset of possible graphs, and do not involve learning of the actual topological map. In contrast, our methods can learn the dependency of place categories from a limited amount of data.\nSum-Product Networks (SPNs), proposed by Poon and Domingos [20] are a new class of probabilistic model that guarantee tractable inference. Despite their competitive or state-of-the art results on tasks such as image completion [20], image classification [9], and language modeling [4], the advantages of SPNs have not been exploited much in robotics, besides [21]. Moreover, for neural networks, the problem of learning from data naturally structured as graphs has been on the radar for around a decade. Scarselli et. al. [25] proposed graphical neural networks, and recently there is an increase of intererst for generalizing convolutional neural networks (CNNs) beyond grid data such as images to model data in graph domains [6][12], showing promising progress. In contrast, there has been no research on using Sum-Product Networks to learn similar data. This work offers a straightforward first step in broadening the scope of applications for SPNs.\nAmong the numerous attempts in extracting topological maps, some tried to learn the place categories in topological maps as well. Mozos and Burgard [16] presented an approach which first classifies each point in the metric map into semantic categories using AdaBoost, then segments the labeled metric map into regions in order to extract a topological map. This approach is good for classifying nodes on the topological maps accurately, but the model does not learn the spatial relations between the categories since it does not support probabilistic inference. Friedman et. al. [8] proposed an approach based on Voronoi random fields (VRFs), which also attempts to estimate the label of each node. A VRF is a conditional random field (CRF) converted from a Voronoi graph created from a metric grid map. Although this approach uses CRF, a discriminative probabilistic graphical model, it relies on pseudolikelihood and loopy belief propagation [17] to achieve approximate MAP inference, which may not converge to correct probability distribution. Besides, this approach relies on AdaBoost to learn features for place classification, similar to [16]. In this thesis, we use SPNs which guarantee efficient inference and correctness of the modeled probability distribution. Furthermore, as descrbed in section 3.1, theoretical properties of SPNs support combining several SPNs into a unified SPN. This avoids the complexity of using multiple kinds of machine learning models trained for different purposes.\n3"}, {"heading": "3 Background", "text": "In this section, I provide the background information for this thesis in detail. First, I describe in detail the properties of Sum-Product Networks (SPNs), how inferences are performed, and how the parameters and structure of the network can be learned. Next, I describe the Deep Affordance Spatial Hierarchy (DASH), the spatial knowledge representation that we use to enable environment understanding for mobile robots. Finally, I describe indoor topological maps in general, and how topological maps are generated in DASH."}, {"heading": "3.1 Sum-Product Networks", "text": ""}, {"heading": "3.1.1 Definitions and Properties", "text": "SPN, proposed by Poon and Domingos [20], is a new class of probabilistic graphical models with built-in properties that allow tractable inference, a major advantage over traditional graphical models such as Bayesian networks. The idea is built upon Darwiche\u2019s work on network polynomial and differentials in arithmetic circuit representation of the polynomial [5]. Here, we provide the definition of SPN and several of its key properties.\nDefinition 3.1 (SPN). [20] Let X = {X1, \u00b7 \u00b7 \u00b7Xn} be a set of variables. A Sum-Product Network (SPN) defined over X is a rooted directed acyclic graph. The leaves are indicators [Xp = \u00b7]. The internal nodes are sum nodes and product nodes. Each edge (i, j) from sum node i has a nonnegative weight wij . The value of a sum node is \u2211 j\u2208Ch(i) wijvj , where Ch(i) is the children of i. The value of a product node is the product of the values of its children. The value of an SPN is the value of its root.\nWe use S to denote an SPN as a function of the indicator variables (i.e. the leaves). Let x be an instantiation of the indicator variables, a full state. Let e be an evidence (partial instantiation). For a given node i, we use Si to denote the sub-SPN rooted at i. Also, we use x a p to mean [Xp = a] is true, and use x\u0304ap to mean the negation, for simplicity. We define the following properties of SPN.\nDefinition 3.2 (Validity). An SPN is valid if and only if it always correctly computes the probability of evidence: S(e) = \u03a6S(e), where \u03a6S(e) is the unnormalized probability of e.\nDefinition 3.3 (Consistency). An SPN is consistent if and only if for every product node i, there is no variable Xp that has indicator x a p as one leaf of the sub-SPN Si and indicator x b p with b 6= a as another leaf.\nDefinition 3.4 (Completeness). An SPN is complete if and only if all children of the same sum node have the same scope. (The scope of an SPN is the set of variables in X that the indicators of an SPN are defined on.)\nDefinition 3.5 (Decomposability). An SPN is decomposable if and only if the children of every product node have disjoint scopes.\nThe above definitions can constrain an SPN so that it is no longer an arbitrary multi-linear map from the indicators to a real number. Poon and Domingos proved that if an SPN is complete and consistent, then it is valid [20]. A more restricted theorem for validity is that if an SPN is complete and decomposible, then it is valid [19]. We will apply the latter theorem in to solve our problem, since it is easier to guarantee that the children of a product node have disjoint scopes.\nHidden Variables Given a complete and consistent SPN S and an arbitrary sum node i, we know: Si(x) = \u2211\nj\u2208Ch(i)\nwijSj(x) (1)\n4\nIf \u2211\nj\u2208Ch(i) wij = 1, we can view the value of the sum node i as summing out a hidden variable Yi, where P (Yi = j) = wij . Also, in this case, the partition function ZS = S(1 \u00b7 \u00b7 \u00b7 1) = \u2211\nx S(x)=1, because all of the indicators have value 1, and the product nodes and sum nodes all output 1. It follows that the value of every sub-SPN is a normalized probability. Therefore, the SPN rooted at sum node i can be viewed as a mixture model, where each child j is a mixture component with distribution Sj(x)."}, {"heading": "3.1.2 Inference", "text": "We can perform marginal inference and MPE inference with a valid SPN in time linear to its size. This uses the same idea as Darwiche\u2019s derivation of partial differentiations in arithmetic circuits [5].\nGiven an SPN S and an arbitrary intermediate node i, let Si(x) be the value of the node on state x. Let Pa(i) be the parent nodes of i. Then,\n\u2202S(x) \u2202Si(x) = \u2211 k\u2208Pa(i) \u2202S(x) \u2202Sk(x) \u2202Sk(x) \u2202Si(x) (2)\nIf node i is a product node, \u2202Sk(x)\u2202Si(x) = wki. If node i is a sum node, \u2202Sk(x) \u2202Si(x)\n= \u220f\nl\u2208Ch\u2212i(k) Sl(x). We\ncan compute \u2202S(x)\u2202Sk(x) by first going upwards from leaves to root then going downwards from root to node i.\nMarginal inference Suppose node i is an indicator xap. Then, as derived in [5],\nP (Xp = a|e) = 1\nS(e)\n\u2202S(e) \u2202Si(e) \u221d \u2202S(e) \u2202Si(e)\n(3)\nWe can also infer the marginal of hidden variables. Suppose node i is a sum node which marginalizes out a hidden variable Yi. For child j branching out from i, we can consider the value of indicator [Yi = j] = Sj(e). This holds because the indicators are actually real-valued [5][19], and this is important when we take the derivative with respect to an indicator [19]. Thus, we use the partial differentials derived by Darwiche [5] to obtain the following. Note that by definition, E and Y must be disjoint.\nP (Yi = j, e) = \u2202S(e)\n\u2202Sj(e) (4)\nP (Yi = j|e) = P (Yi = j, e)\nP (e) =\n1\nS(e)\n\u2202S(e)\n\u2202Sj(e)\n= 1\nS(e)\n\u2202S(e)\n\u2202Si(e)\n\u2202Si(e) \u2202Sj(e)\n= wij S(e) \u2202S(e)\n\u2202Si(e)\n\u221d wij \u2202S(e)\n\u2202Si(e)\n(5)\nMPE inference The task of MPE inference is to find the most likely assignment of unobserved variables given the evidence. Suppose we have evidence e for a set of observed variables E, we have hidden variables Y, and we have the unobserved input variables X = X \u2212 E. We are computing argmaxx,y P (x,y|e).\nThis can be done by replacing each sum operation with a maximization operation, such that Si(e) = maxj wijSj(e). First, we compute Si(e) for every node from bottom to top. Next, we\n5\ntraverse recursively from the root to the leaves: At a sum node, we pick its child that led to the value of that sum node; At a product node, we select all of its children for traversal.\nIf S is consistent, it is guaranteed that there is no conflicting values among the children of a product node, which means that the MPE result is a valid instantiation of the variables. In this case, the obtained instantiation x\u0302 has the maximum value of S(x\u0302|e) [20]."}, {"heading": "3.1.3 Learning Parameters", "text": "Gradient descent and backpropagation Suppose S is a valid SPN over the set of variables X , and suppose wij represents the weight of the edge from sum node i to its j-th child. Suppose we have observations of states x = {x1, \u00b7 \u00b7 \u00b7 ,xn}. We aim to estimate the weights w by maximizing the log-likelihood function:\nl(w|x) = n\u2211\np=1\nlogPw(xp) = n\u2211 p=1 log (S(xp) Z ) (6)\nwhere Z is the partition function that equals to S(1 \u00b7 \u00b7 \u00b7 1). The second equal sign holds because S is valid. Now we take the gradient with respect to a single weight wij :\n\u2202l(w|x) \u2202wij = n\u2211 p=1 \u2202 \u2202wij log (S(xp) Z ) = n\u2211 p=1 1 S(xp) \u2202S(xp) \u2202wij \u2212 n\u2211 p=1 1 Z \u2202Z \u2202wij (7)\nThe value of the sum node i is Si(xp) = \u2211\nj\u2208Ch(i) wijSj(xp). We can thus use the chain rule to obtain:\n\u2202S(xp)\n\u2202wij =\n\u2202S(xp) \u2202Si(xp) \u2202Si(xp) \u2202wij = \u2202S(xp) \u2202Si(xp) Sj(xp) (8)\nUsing (2), we can compute \u2202S(xp)/\u2202Si(xp) by first computing the partial derivative with respect to the parents of i. Computing \u2202Z/\u2202wij follows similar derivation. This is naturally a backpropagation process. Alternatively, we can ensure that S(xp) to be a normalized probability by renormalizing the weights after each full update, so that we can discard the Z in the derivation.\nHard EM As discussed previously, a sub-SPN rooted at sum node i in an SPN S can be viewed as a mixture model. Poon and Domingos found that their EM method does not work well in practice, so they opt to use MPE inference instead of the marginal inference in the E step, and changes the M step accordingly. The algorithm can be described as follows.\n(1) In E step, compute MPE inference:\nj\u2217 = argmax j P (xp, Yi = j) = argmax j\n\u2202S(xp) \u2202Sj(xp) = argmax j wij \u2202S(xp) \u2202Si(xp) (9)\nA count is kept for every child of the node i to record the number of times the index of that child equals to j\u2217.\n(2) In M step, the count of child j\u2217 increments by one."}, {"heading": "3.1.4 Learning Structure", "text": "LearnSPN The most commonly used structure learning algorithm is LearnSPN [10]. This algorithm recursively divides up the training data either by rows (instances) or columns (features). A product node is added when the variables can be partitioned into approximately independent subsets. If this is not the case, the instances are partitioned into similar subsets, and sum node is added on top of the subsets. This algorithm requires a large amount of training data to yield good partition results. This is not very feasible in our problem because there is very little data for the topological maps and it is difficult to acquire a massive amount of such data.\n6\nRandom-Decomposition We use a different approach in learning the SPN structure, similar to the one used in [21]. This algorithm is visualized in figure 4. Given a set of variables X , we decompose it into random subsets multiple times. A sum node is used to model a mixture of these decompositions, summing up the output of SPNs built upon each of these decompositions. This process is done recursively for each subset until singleton. Product nodes combine the output of the SPNs on each subset to union their scopes. Weights are shared for each sum node at the same level, and edges with zero weight are pruned once the parameter learning is finished."}, {"heading": "3.2 Deep Affordance Spatial Hierarchy", "text": "Pronobis et. al. [22] proposed a hierarchical spatial representation named Deep Affordance Spatial Hierarchy (DASH). In their work, they also discussed the properties of a desired representation. We summarize these properties as follows:\n(1) Minimal;\n(2) Hierarchical. It allows long-term, high-level, global planning to break down to short-term, lower-level local planning;\n(3) Correlating abstraction with information persistence. In other words, more dynamic means less persistent, which requires higher level of abstraction;\n(4) Probabilistic;\n(5) Representing the unknowns, that is, it allows the representation of default knowledge;\nGuided by the above principles, the authors presented DASH, which is aimed to be used by deep learning frameworks. DASH consists of four layers.\n(1) Perceptual layer represents the robot\u2019s raw sensor readings. In the paper, the authors used occupancy grid to represent the laser-range observations, centered at the robot\u2019s position.\n(2) Peripersonal layer represents objects, obstacles, and landmarks in the space immediately surrounding the robot. The authors used a polar occupancy grid representation which is a simplification of this layer\u2019s information.\n(3) Topological layer represents the graphical structure of the map that connects places together. It maintains information of the places, such as place categories and views at different angles, and the connectivity between places. It also contains placeholders. In the paper, a topological map is constructed from first sampling places in a window centered at the robot, according to the probability distribution P (E|G), where E is the variable for existance of places, and G is the occupancy grid provided by the perceptual layer. Then, according to navigation affordance, places reachable from the robot are added. The affordance is determined by A* search over the potential field P (E|G). More details on topological map generation is discussed in the next section.\n(4) Semantic Layer represents human concepts about the places. It can be visualized as a concept map that specifies the relations between concepts. The knowledge represented in this layer can be used for complex human-robot interaction tasks. In the paper, the authors implemented a probabilistic relational data structure that mimics a concept map.\nWhen the robot is handed with a DASH, ideally it is supposed to be able to navigate around and complete tasks that involve interaction with humans. And the robot should be able to explore the environment and build up the topological layer on its own. However, on its own, it does not have the ability to model uncertainty in the environment, and infer semantics of placeholders or other\n7\nlatent variables. To enable this, the authors used DGSM (Deep Generative Spatial Model) [21] to represent the default knowledge about the environment. Default knowledge can be understood as the knowledge that the system assumes before it is provided explicitly. In the context of the paper, default knowledge means place semantics that the model infers for all places (including placeholders) based on its training data. In this thesis, we also focus on using place categories as our semantic information. While DGSM learns a local version of the DASH spatial knowledge, we enable the learning of the topological layer in this thesis. Eventually, we look to connect the two so that the entire spatial knowledge hierarchy is represented."}, {"heading": "3.3 Topological Maps", "text": "A topological map is a graph that captures important places in the map as well as their connectivity. In the context of robotics, the nodes in this graph are the places accessible by the robot, and edges indicate navigation affordance between places, i.e. the feasibility of navigating from one place to another. Figure 1 shows examples of simplified topological maps.\nAs discussed previously, topological map is used as a layer to capture the geometry of the map and connectivity between places in the DASH. The authors of DASH [22] also describe a mapping algorithm that builds a topological map. As the robot explores an environment, the mapping algorithm expands the topological map by adding placeholders [23] as nodes, according to a probability formulation as follows\nP (E|G) = 1 Z \u220f i \u03c6I(Ei)\u03c6N (Ei, E) (10)\nwhere P (E|G) is the probability of placeholder locations E given robot-centered occupancy grid G which represents laser-range observations. The potential function \u03c6I(Ei) models the existence of placeholder at location i, denoted as Ei \u2208 {0, 1}. For details about how \u03c6I(Ei) is defined, refer to the original paper [22].. The potential function \u03c6N (Ei, E) models the probability of placeholder Ei in the neighborhood of the set of existing places E . It is defined as\n\u03c6N (Ei, E) = \u2211 p\u2208E exp ( \u2212 (d(i, p)\u2212 dn) 2 2\u03c32 ) (11)\nwhere d(i, p) is the distance between location i and place p. The key point to note here is that \u03c6N (Ei, E) promotes places that are of certain distance dn apart from existing places. This fact is important when we describe the place grid method in section 4.2.\nUsing this method, in addition to capturing topological relations between places, the overall geometric structure of the full map is also preserved in the topological map, since each node has its coordinates on the metric map. For example, corridor nodes usually form a long and straight\n8\nline, room nodes are usually cluttered, and doorway nodes usually have edges coming out from two opposite sides. We hope to learn these general geometric properties of place categories as well."}, {"heading": "3.3.1 Challenges", "text": "There are several challenges in modeling topological maps due to their scale and variability. A full map of a workspace may contain dozens of nodes and hundreds of edges. The number of places in one map likely differs from that in another. Different topological maps may represent environments of different dimensions. The structure of places in one map may appear very differently compared to another. Finally, because our topological maps can encode geometric structure as described above, even for similar environments, different topological maps may be rotated differently, since the underlying metric maps, built by SLAM (Simultaneous Localization and Mapping), may be rotated differently as a whole."}, {"heading": "4 Problem Statement & Proposed Solutions", "text": ""}, {"heading": "4.1 Problem Statement", "text": "Our problem is the following. Given datasets of topological maps with unknown number of nodes per map, we would like to train Sum-Product Networks such that the resulting model is able to demonstrate its understanding of the spatial relations of categories.\nIt can demonstrate this ability in several ways. For example, if we provide a topological map instance with missing semantic information, the model should reasonably predict what the missing information is. In addition, if we provide a topological map instance with strange category arragements (e.g. corridor nodes labeled office), the model should be able to detect this novelty. In section 5, we describe experiments conducted to test out this ability."}, {"heading": "4.2 Place Grid Method", "text": "To address the challenge that topological maps are of different sizes and shapes, we present a simple idea which is to map them to fixed-size grids. A grid can be considered as a generic representation of topological maps. It approximates the topological map, but preserves most of the adjacency relations between places. It is straightforward to use SPN to model this grid. Using the algorithm in 3.1.4, we can train an SPN for the grid, which then indirectly models topological maps as a whole.\n9"}, {"heading": "4.2.1 From Topological Map to Place Grid", "text": "In this section, we first define a place in a topological map, then define a place grid, and then describe in detail how can a topological map be mapped to a place grid. Our definition of a place follows from the polar occupancy grid representation for local environment described by Pronobis and Rao in [21].\nDefinition 4.1 (Place). A place p in a topological map is a three-tuple (L, V, a) where L is the location of p with respect to the topological map\u2019s coordinate system, V is the set of views in the polar occupancy grid, and a is the label for place category.\nAn example polar occupancy grid of a place is shown in figure 3.\nDefinition 4.2 (Place Grid). A place grid G with resolution r (meter per cell) is an m\u00d7 n matrix where each cell contains a place.\nGiven a 2D place grid G with resolution r, we can map a place p in topological map M with L = (pMx , p M y ) to a cell in G at (p G x , p G y ) simply by\n(pGx , p G y ) =\n( b pMx \u2212 pMxmin\nr c, b pMy \u2212 pMymin r\nc )\n(12)\nwhere pMxmin is the x coordinate for the place with minimum x coordinate (similar goes for p M xmin).\nTo avoid gaps between places mapped to the grid which disturb adjacency relations between places, we can map the topological map to a place grid with resolution at most dn. (Recall from equation (11) that places in a topological map are separated by a predefined distance dn.)\nTo deal with the situation where multiple places map to the same cell, we can do either of the following:\n\u2022 Pick the place with the highest value of \u03c6I(Ep), as shown in equation (10).\n\u2022 Create a hybrid place by sampling views from these places with probability according to \u03c6I(Ep).\nWe conduct experiments to test this place grid method (section 5). Because the training and validation topological map instances of our experiment are built from one single building, these instances do not vary much in rotation. In general, however, we need to deal with the case where we have no assumption of from where the topological maps are generated. Next, we provide a solution in theory to deal with topological maps with different rotations, in the context of the place grid method.\n10"}, {"heading": "4.2.2 Modeling a Place Grid Using Rotation-Invariant SPN", "text": "There are multiple ways to deal with the rotation of topological maps. We could rotate all the topological maps before hand, based on the prior knowledge that human environments typically have right angle corners and straight walls. Another way is to incorporate rotation-invariance into the SPN that models the place grid. Here, we present the theory of constructing a rotation-invariant SPN based on a place grid.\nRotation-invariant SPN We consider k number of major directions (e.g. 8). At the top level of the SPN, we add a max node with k children of sum nodes where each sum node models the place grid for a certain orientation. Suppose one child A is a grid resulted from rotating another child B by angle \u03b8. Then, a cell (xB , yB) in B corresponds with (has the same value as) a cell (xA, yA) in A by the following transform: [\nxB yB\n] = [ bcos(\u03b8)xA + sin(\u03b8)yAc b\u2212sin(\u03b8)xA + cos(\u03b8)yAc ] (13)\nWith the above relation, we are not adding more inputs to the SPN. We simply connect a cell in the grid with the corresponding input for the place. There is a case where this relation causes (xB , yB) to be out of bound, which means that there are some cells in the \u201crotated\u201d grid B that\n11\nhave no corresponding cells in A. We simply ignore the out of bound cells, and feed 1 as input for those cells that have no correspondence. One way to reduce the effect of this on the trained SPN is by using a place grid with large dimension where there are loops of cells that are supposed to be empty. The point is that these cells do not really affect the SPN\u2019s representation of the useful parts in the place grid where mapping happens."}, {"heading": "4.3 Template-Based Method", "text": ""}, {"heading": "4.3.1 Motivation", "text": "One shortcoming of the place grid method is its rely on a predefined size and resolution of the grid; choosing the right dimensions and resolution is a difficult task and usually the chosen parameters does not generalize well for other unseen topological map instances. Besides, the grid itself is in the middleground between being accurate and approximate: Althougth the grid is metric, the cells do not accurately represent the location of places. This may affect the quality of inference.\nTo some extent, it is unnecessary to have an accurate absolute representation of the topological map, because (1) it is hard to maintain this accuracy given the variability of topological maps, and (2) topological maps are usually used in conjunction with metric grid maps for robot planning and navigation, serving as a reference for high-level planning. Therefore, we propose a template-based relative representation of the topological map, which models some certain basic structure of a graph, and expands as needed. As discussed before, the findings by Aydemir et. al. [1] support the idea of using a subgraph of small size as the template for the entire topological map.\n12"}, {"heading": "4.3.2 Building Instance-Specific SPN for Graphs from Templates", "text": "Consider a basic graph structure B, such as the three-node structure in figure 6. The only constraint that this structure has is the connectivity of the places; How the views are connected is not constrained. Therefore, this basic structure is rotation-insensitive. We can partition a given graph instance using B. Note that B should be a very simple structure. Examples of such basic structure are shown in figure 5. One reason is that a simple structure likely occurs very often in the topological map. Another reason is that finding if a graph is a subgraph of another (subgraph isomorphism problem) is NP-complete. Linear time solution exists but only works for planar graphs [7], and a topological map is not necessarily planar.\nAlgorithm 1 is a greedy algorithm to partition the graph when B is very simple. In this algorithm, match graph is assumed to be a function that is specific to B; it could be hard-coded. The output of this algorithm is a graph H where nodes are the basic structures and edges indicate their connectivity (see the green groups in figure 5). It is likely that the output of this algorithm is a graph that does not cover all nodes from the input graph. Yet, as shown in figure 8, the number of uncovered nodes drops rapidly as we increase the number of partition attempts, that is, the number of times we run this algorithm. With this, we know that we can cover the topological relations in the graph better if we partition the graph multiple times, both in training and testing.\nAlgorithm 1: Graph Partition by a Basic Structure\n1 function Graph-Partition (G,B); Input : A graph G = (VG, EG) and a graph B representing a basic structure. Output: A graph H = (VH , EH) resulting from the partition of G using B. 2 Vavailable \u2190 VG; 3 M \u2190 empty map; 4 while Vavailable 6= \u2205 do 5 v \u2190 draw from Vavailable randomly; 6 Vused \u2190 B.match graph(G, v); 7 if Vused 6= \u2205 then 8 Vavailable \u2190 Vavailable \u2212 Vused; 9 u\u2190 a node that represents Vused;\n10 VH \u2190 VH \u222a {u}; 11 foreach v\u2032 \u2208 Vused \u222a {v} do 12 EH \u2190 EH \u222a (u,M.get(v\u2032)); 13 M.put(v\u2032, u);"}, {"heading": "14 end", "text": ""}, {"heading": "15 end", "text": "16 Vavailable = Vavailable \u2212 {v}; 17 end 18 return (VH , EH)\nNow that we have a basic structure as our template, we can consider constructing a hierarchy of the templates. Consider another simple graph structure S that consists of B. For example, S is a pair of B connected as shown in the red region of the topological map in figure 6. We can again partition the graph H by S using the same algorithm. Therefore, the given graph instance can be partitioned into a graph with nodes that represent S\u2019s.\nWe can think of B as the template, and P (S) as the joint distribution of the templates defined in S. The probability P (S) is the expansion model of the template that dictates how a template expands to form a graph. Unlike other template-based models such as hidden Markov Models (HMMs), we don\u2019t have to use a transition model between the templates, because there is no notion\n13\nof \u201dorder\u201d between the places in a topological map. We can construct an SPN for the hierarchy of templates using the random-decomposition method. The resulting SPN is likely small. We can perform inference at the scale of the entire topology map\n14\nby constructing an instance-specific SPN: For a given test case, we partition the topological map using the same structures B and S. For each hierarchical template structure resulted from the partitioning, we construct a sub-SPN that has the exact same structure and weights as the learned hierarchical template SPN. We combine these sub-SPNs together simply by a product node. We do this partition multiple times to capture as much combination of nodes that form the template structures as possible. We use a sum node to sum up the product nodes that represent the partition attempts. The resulting instance-specific SPN for a topological map is illustrated in figure 9.\nNote that there are uncovered nodes after partitioning (see figure 6). Each product node that represents a partition attempt needs to cover these nodes as well, otherwise the sum node at the root would have children with different scopes, leading to invalid SPN. These uncovered nodes cannot form any more template structures. Therefore, we can train separate SPNs to cover them. For example, if we use the three node structure as the template for partitioning the graph, the uncovered nodes would either be single nodes or pairs of nodes. We train an SPN for a trivial single node template, and an SPN for a pair template. We can them use these template SPNs when constructing the full SPN for the entire topological map.\n15"}, {"heading": "5 Experiments", "text": ""}, {"heading": "5.1 Data Collection", "text": "In support of the larger goal of our research to learn the Deep Affordance Spatial Hierarchy (DASH), we collected a large dataset of fully-annotated sensory (RGB, laser rangefinder readings, odometry), localization, and virtual scans, a low-level representation of the environment immediate to the robot. For this thesis, we utilized this dataset to generate topological maps with nodes labeled by place categories.\nThe dataset consists of 100 sequences and total of 11 different floor plans in three buildings in three different locations: Stockholm, Sweden, Freiburg, Germany, and Saarbrucken, Germany. Summary of the sequences is shown in table 1. For each sequence, among the types of data contained, there is a corresponding canonical map and annotated floor plan, on which the annotated localized poses are generated using adaptive Monte-Carlo Localization (AMCL) with frequency of 30 Hz. We use the canonical map and the localized poses to generate topological maps, one for each sequence. We used 1.0m as the desired separation between place nodes when generating topological maps. We trained and tested our methods mostly on the Stockholm sequences as the building in Stockholm has much larger number of rooms and bigger in scale."}, {"heading": "5.2 Methodology", "text": ""}, {"heading": "5.2.1 Software", "text": "We used LibSPN [21], a Python library that implements learning and inference with SPNs on GPUs. This library provides the functionality to generate a dense SPN structure using the randomdecomposition method as described in section 3.1.4. We use this functinoality to generate SPN on top of a place grid as well as on templates. We implemented ourselves weight-sharing and instancespecific full SPN construction as needed for the template-based method."}, {"heading": "5.2.2 Experiments for Place Grid Method", "text": "We converted topological maps from Stockholm sequences into place grids. We used place grids of size of 15 rows by 10 columns with resolution of 1.5m per cell. The resolution is lower than the 1.0m of desired place separation in topological map to ensure the connectivity of places when mapped to the grid, as suggested in section 4.2.1. Since the size of our dataset is not very large, we lowered the number of place categories to four: doorway, corridor, small office, and large office. so that we can better assess the learning of structure and dependency. Note that for other categories such as kitchen and meeting room, we do not distinguish them from the unknown place category.\nTo verify the consistency of the place grid method, we used cross-validation by training the network on three floors and test it on the other one, for each combination of the four floors in the Stockholm dataset. The training procedure\u2019s likelihood curve is shown in 10. As we can see, the standard deviation of the likelihood values is small, which suggests that training on either three of the four floors results in a very similar model.\n4We did not generate topological maps for the Saarbrucken sequences.\n16\nWe did not implement the rotation-invariant SPN when testing the place grid method, as the canonical maps in the Stockholm dataset have the same orientation, and the topological map data examples are aligned well with each other. In the future, we plan to let the SPN learn the topological maps from two datasets (e.g. Stockholm and Freiburg) and test it on another (e.g. Saarbrucken), and implement the rotation-invariant SPN.\nWe test the method by using it for two main types of tasks, map completion and novel map structure detection. For map completion, we use the SPN to do MPE inference for the full map and the occluded part of the map. Also, we randomly occlude cells in the place grid that may or may not have been mapped directly from the topological maps, and test if the network can infer their values correctly. For novel structure detection, we construct test examples of topological maps by swapping the labels of pairs of classes, such as doorway and corridor, large office and small office, and small office and corridor."}, {"heading": "5.2.3 Experiments for Template-Based Method", "text": "As described in section 4.3, during training, we train an SPN for a single template, or a hierarchy of templates. Therefore, we created a dataset where each example is an assignment of the template variables. The dataset is created from both Stockholm sequences and Freiburg sequences, because the topological relations of place categories are generally the same across different environments [1]. We do this by partitioning the available topological maps using the templates. The partition operation is done 10 times for each topological map, to capture different combinations of nodes. During testing, we construct a full SPN for each test instance according to the algorithm described in section 4.3.2.\nSimilar to the experiments for the place grid method, we also occlude parts of the topological map, and ask the model to infer their attributes. Because the templates only consider connectivity of places, and place category is the only semantic attribute used as input for the template SPN, we do not expect the current template-based method to be able to infer a large occluded region accurately5, but it should exhibit reasonable inference behavior in smaller scopes of the map. Therefore, we only randomly occlude several nodes per test instance. Also, because the training data is fundamentally different from the testing data (template versus full graph), we simply trained on the templates obtained from all sequences, and randomly picked a sequence to use its full topological map for testing."}, {"heading": "5.3 Results", "text": ""}, {"heading": "5.3.1 Place Grid Method", "text": "Map completion We tested our trained model\u2019s ability to infer missing information in the topological map. For each topological map test case, we occlude different parts of its projected place grid, and use the model to perform MPE inference to get an assignment for the missing values. The results are shown in figure 11. The images on the left side are results from training samples, and those on the right side are results from validation samples. The first three rows show the results of map completion on place grid with different occluded regions. The last row show the results of map completion on place grid with randomly occluded cells. These results indicate that the model learns the relations between place categories and general map structure to some degree. It is able to place doorway nodes between corridor and rooms. It is also able to learn that corridors extend along the same line, and different rooms categories do not mix up together. Errors in the inference do exist, as shown in several validation results where no doorway node is added between corridor and office.\nWe also demonstrate the actual use of the place grid method to fill in the spatial knowledge gaps in the topological graph in figure 12. This figure shows two validation samples of the map completion task. On the left shows the completion of randomly occluded cells. On the right shows\n5This is the problem for place classification.\n17\nthe completion of a place grid with an entirely occluded topological map. The graphs show the topological map with labels mapped from the corresponding place grids. The bottom row of images show the MPE inference results6. As we can see, the model can reasonably infer missing information, and it is possible to map from the inferred place grid to the original topological map to correct or fill in place categories.\nNovel structure detection One other way of checking the model\u2019s understanding of the environment is to see if it acts differently when two room classes switch their residing cells. Our result is shown in figure 13. There are three groups of bars. The blue bar is the convergence likelihood during training (see figure 10). The green bars show the average likelihood using as input the place grids in training set where cells with certain place categories are swapped. The red bars show the same for place grids in validation set. From this plot, we can see that there is indeed a lower likelihood for unexpected swapping of place categories (e.g. between doorway and corridor). Also, it is reasonable that the likelihood after switching the two office classes (small and large) is higher than likelihoods of other, more irregular combinations of swapping. This shows that the model does learn the positional role that each room category plays. The slight decrease of likelihood in validation set is considered reasoanble. The bars in training (green) has similar pattern of uneven length compared to those in validation (red), which indicates that the model exhibits consistent behavior for both training and validation data."}, {"heading": "5.3.2 Template-Based Method", "text": "We conducted the missing value completion experiment on three sequences7. Figure 14 shows the result of one of the sequences, where we skipped the places with unknown category, and we used a hierarchy of templates. We found that typically a template hierarchy leads to better results than using only a single template. The constructed full SPN is able to infer place classes according to the surrounding information, but the performance is not very stable. It is able to infer that there is a doorway structure between two places of different classes, and that rooms have cluttered nodes\n6For the case on the right, note that because we do not distinguish between certain place categories (such as kitchen) and the unknown, those skipped categories have the same label as the unknown. Therefore, the model believes that it is reasonable t place a doorway cell between an unknown (background) cell and a corridor cell, because that background cell may refer to some category that we skipped.\n7The amount tested is limited by time, mostly due to the current expensive weight-sharing implementation.\n18\nof the same category. The unstable performance behaviors are mostly reflected in, for example, inferring a place to have class \u201csmall office\u201d when its surroundings are mostly \u201clarge office\u201d. Figure 14 also demonstrates this issue.\n19\n20"}, {"heading": "6 Conclusion & Future Work", "text": "In this thesis, we motivated the importance of learning a spatial representation for autonomous mobile robotics. We described the role of topological map and discussed its generation in the context of Deep Affordance Spatial Hierarchy. Then, we presented two methods that can enable learning of topological map using Sum-Product Networks. Finally, we described experiments and presented results that demonstrate the effect of the learning for each method.\nIndeed, there is work to be done to improve each of the two methods. Especially for templatebased method, the current method only consider connectivity of places and place categories as the only semantic attribute. We are looking to introduce more complexity in the templates and consider more information (such as laser range readings) when learning the template SPNs.\n21"}, {"heading": "7 Acknowledgements", "text": "I am sincerely grateful for the advice and encouragement from my advisor Dr. Andrzej Pronobis, and insightful discussions I had we him as well as with my lab partner Kousuke Ariga. I also thank Yu Xiang, who shared plenty of his valuable experience in doing reserach projects. I thank the Robotics State-Estimation Lab run by Prof. Dieter Fox for providing the space for me to do this work, and I enjoyed the atmosphere as well as the kind labmates there."}], "references": [{"title": "and J", "author": ["A. Aydemir", "P. Jensfelt"], "venue": "Folkesson. What can we learn from 38,000 rooms? reasoning about unexplored space in indoor environments. In Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pages 4675\u20134682. IEEE", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Integrating multiple representations of spatial knowledge for mapping", "author": ["P. Beeson", "M. MacMahon", "J. Modayil", "A. Murarka", "B. Kuipers", "B. Stankiewicz"], "venue": "navigation, and communication. In Interaction Challenges for Intelligent Assistants, pages 1\u20139", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Factoring the mapping problem: Mobile robot mapbuilding in the hybrid spatial semantic hierarchy", "author": ["P. Beeson", "J. Modayil", "B. Kuipers"], "venue": "The International Journal of Robotics Research, 29(4):428\u2013459", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Language modeling with sum-product networks", "author": ["W.-C. Cheng", "S. Kok", "H.V. Pham", "H.L. Chieu", "K.M.A. Chai"], "venue": "Fifteenth Annual Conference of the International Speech Communication Association", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "A differential approach to inference in bayesian networks", "author": ["A. Darwiche"], "venue": "Journal of the ACM (JACM), 50(3):280\u2013305", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2003}, {"title": "Convolutional neural networks on graphs with fast localized spectral filtering", "author": ["M. Defferrard", "X. Bresson", "P. Vandergheynst"], "venue": "Advances in Neural Information Processing Systems, pages 3837\u20133845", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2016}, {"title": "Subgraph isomorphism in planar graphs and related problems", "author": ["D. Eppstein"], "venue": "SODA, volume 95, pages 632\u2013640", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1995}, {"title": "Voronoi random fields: Extracting topological structure of indoor environments via place labeling", "author": ["S. Friedman", "H. Pasula", "D. Fox"], "venue": "IJCAI, volume 7, pages 2109\u20132114", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Discriminative learning of sum-product networks", "author": ["R. Gens", "P.M. Domingos"], "venue": "Nips, pages 3248\u20133256", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning the structure of sum-product networks", "author": ["R. Gens", "D. Pedro"], "venue": "International Conference on Machine Learning, pages 873\u2013880", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2013}, {"title": "et al", "author": ["C. Jayawardena", "I.H. Kuo", "U. Unger", "A. Igic", "R. Wong", "C.I. Watson", "R. Stafford", "E. Broadbent", "P. Tiwari", "J. Warren"], "venue": "Deployment of a service robot to help older people. In Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on, pages 5990\u20135995. IEEE", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Semi-supervised classification with graph convolutional networks", "author": ["T.N. Kipf", "M. Welling"], "venue": "arXiv preprint arXiv:1609.02907", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "The spatial semantic hierarchy", "author": ["B. Kuipers"], "venue": "Artificial intelligence, 119(1-2):191\u2013233", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2000}, {"title": "A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations", "author": ["B. Kuipers", "Y.-T. Byun"], "venue": "Robotics and autonomous systems, 8(1):47\u201363", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1991}, {"title": "Scalablebody: A telepresence robot supporting socially acceptable interactions and human augmentation through vertical actuation", "author": ["A. Matsuda", "J. Rekimoto"], "venue": "Proceedings of the 29th Annual Symposium on User Interface Software and Technology, pages 103\u2013105. ACM", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2016}, {"title": "Supervised learning of topological maps using semantic information extracted from range data", "author": ["O.M. Mozos", "W. Burgard"], "venue": "Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on, pages 2772\u20132777. IEEE", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Loopy belief propagation for approximate inference: An empirical study", "author": ["K.P. Murphy", "Y. Weiss", "M.I. Jordan"], "venue": "Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, pages 467\u2013475. Morgan Kaufmann Publishers Inc.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1999}, {"title": "The future of robotics technology", "author": ["L. Pagliarini", "H.H. Lund"], "venue": "JOURNAL OF ROBOTICS NETWORKING AND ARTIFICIAL LIFE, 3(4):270\u2013273", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2017}, {"title": "On theoretical properties of sumproduct networks", "author": ["R. Peharz", "S. Tschiatschek", "F. Pernkopf", "P. Domingos"], "venue": "Artificial Intelligence and Statistics, pages 744\u2013752", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Sum-product networks: A new deep architecture", "author": ["H. Poon", "P. Domingos"], "venue": "Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on, pages 689\u2013 690. IEEE", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning deep generative spatial models for mobile robots", "author": ["A. Pronobis", "R.P. Rao"], "venue": "arXiv preprint arXiv:1610.02627", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2016}, {"title": "Deep spatial affordance hierarchy: spatial knowledge representation for planning in large-scale envirionments", "author": ["A. Pronobis", "F. Riccio", "R.P. Rao"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2017}, {"title": "Representing spatial knowledge in mobile cognitive systems", "author": ["A. Pronobis", "K. Sj\u00f6\u00f6", "A. Aydemir", "A.N. Bishop", "P. Jensfelt"], "venue": "11th International Conference on Intelligent Autonomous Systems (IAS-11), Ottawa, Canada", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Online probabilistic topological mapping", "author": ["A. Ranganathan", "F. Dellaert"], "venue": "The International Journal of Robotics Research, 30(6):755\u2013771", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "The graph neural network model", "author": ["F. Scarselli", "M. Gori", "A.C. Tsoi", "M. Hagenbuchner", "G. Monfardini"], "venue": "IEEE Transactions on Neural Networks, 20(1):61\u201380", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning topological maps with weak local odometric information", "author": ["H. Shatkay", "L.P. Kaelbling"], "venue": "IJCAI (2), pages 920\u2013929", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1997}, {"title": "Online topological map building and qualitative localization in large-scale environment", "author": ["C. Shi", "Y. Wang", "J. Yang"], "venue": "Robotics and Autonomous Systems, 58(5):488\u2013496", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Hybrid simultaneous localization and map building: a natural integration of topological and metric", "author": ["N. Tomatis", "I. Nourbakhsh", "R. Siegwart"], "venue": "Robotics and Autonomous systems, 44(1):3\u2013 14", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2003}, {"title": "et al", "author": ["R. Triebel", "K. Arras", "R. Alami", "L. Beyer", "S. Breuers", "R. Chatila", "M. Chetouani", "D. Cremers", "V. Evers", "M. Fiore"], "venue": "Spencer: A socially aware service robot for passenger guidance and help in busy airports. In Field and Service Robotics, pages 607\u2013622. Springer", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Conceptual spatial representations for indoor mobile robots", "author": ["H. Zender", "O.M. Mozos", "P. Jensfelt", "G.-J. Kruijff", "W. Burgard"], "venue": "Robotics and Autonomous Systems, 56(6):493\u2013502", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 19, "context": "We propose to use a novel probabilistic deep model, Sum-Product Networks (SPNs) [20], due to their unique properties.", "startOffset": 80, "endOffset": 84}, {"referenceID": 17, "context": "The last several decades saw an explosion of interest and investment in robotics both in commercial applications and academic research [18], and the field of autonomous robots is expected to be a topic of continuous heavy research.", "startOffset": 135, "endOffset": 139}, {"referenceID": 10, "context": "Mobile robots are desirable to fulfill both aspects of the value, especially the latter; They have the potential to provide various kinds of services, and recently attempts have been made to apply mobile robots to real-world problems such as helping older people [11], guiding passengers in airports [29], and telepresence [15].", "startOffset": 263, "endOffset": 267}, {"referenceID": 28, "context": "Mobile robots are desirable to fulfill both aspects of the value, especially the latter; They have the potential to provide various kinds of services, and recently attempts have been made to apply mobile robots to real-world problems such as helping older people [11], guiding passengers in airports [29], and telepresence [15].", "startOffset": 300, "endOffset": 304}, {"referenceID": 14, "context": "Mobile robots are desirable to fulfill both aspects of the value, especially the latter; They have the potential to provide various kinds of services, and recently attempts have been made to apply mobile robots to real-world problems such as helping older people [11], guiding passengers in airports [29], and telepresence [15].", "startOffset": 323, "endOffset": 327}, {"referenceID": 21, "context": "In this thesis, we use the Deep Affordance Spatial Hierarchy (DASH) [22], a recently proposed hierarchical spatial representation that spans from low-level sensory input to high-level human semantics.", "startOffset": 68, "endOffset": 72}, {"referenceID": 20, "context": "The ultimate goal of our research is to use a unified deep generative model to capture all layers of DASH, an approach fundamentally different from the traditional where an assembly of independent spatial models exchange information in a limited way [21].", "startOffset": 250, "endOffset": 254}, {"referenceID": 19, "context": "We have chosen to use Sum-Product Networks (SPN) [20], a new class of deep probabilistic models.", "startOffset": 49, "endOffset": 53}, {"referenceID": 7, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 82, "endOffset": 85}, {"referenceID": 23, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 85, "endOffset": 89}, {"referenceID": 26, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 185, "endOffset": 188}, {"referenceID": 7, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 188, "endOffset": 191}, {"referenceID": 15, "context": "Although there has been considerable effort in the extraction of topological maps [8][24][27][28], only few works is tried to learn it with semantic information in the past two decades [1][8][16].", "startOffset": 191, "endOffset": 195}, {"referenceID": 13, "context": "The use of topological maps in navigation and mapping dates back to the work by Kulpers and Byun [14] in 1991, where they first considered the use of qualitative maps to avoid error-prone geometrically precise maps.", "startOffset": 97, "endOffset": 101}, {"referenceID": 12, "context": "Topological maps then began to be considered as a form of spatial knowledge [13].", "startOffset": 76, "endOffset": 80}, {"referenceID": 2, "context": "[3] proposed a hybrid approach of spatial knowledge representation that uses metrical representation for local environment and topological representation for large environment.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "[23] outlined criteria for good spatial knowledge representation where the use of topological map to represent global environment is also promoted.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1] investigated the statistical properties of indoor environments by analyzing two large floor plan datasets consisting of over 197 buildings and 38,000 rooms in total.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "Sum-Product Networks (SPNs), proposed by Poon and Domingos [20] are a new class of probabilistic model that guarantee tractable inference.", "startOffset": 59, "endOffset": 63}, {"referenceID": 19, "context": "Despite their competitive or state-of-the art results on tasks such as image completion [20], image classification [9], and language modeling [4], the advantages of SPNs have not been exploited much in robotics, besides [21].", "startOffset": 88, "endOffset": 92}, {"referenceID": 8, "context": "Despite their competitive or state-of-the art results on tasks such as image completion [20], image classification [9], and language modeling [4], the advantages of SPNs have not been exploited much in robotics, besides [21].", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "Despite their competitive or state-of-the art results on tasks such as image completion [20], image classification [9], and language modeling [4], the advantages of SPNs have not been exploited much in robotics, besides [21].", "startOffset": 142, "endOffset": 145}, {"referenceID": 20, "context": "Despite their competitive or state-of-the art results on tasks such as image completion [20], image classification [9], and language modeling [4], the advantages of SPNs have not been exploited much in robotics, besides [21].", "startOffset": 220, "endOffset": 224}, {"referenceID": 24, "context": "[25] proposed graphical neural networks, and recently there is an increase of intererst for generalizing convolutional neural networks (CNNs) beyond grid data such as images to model data in graph domains [6][12], showing promising progress.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[25] proposed graphical neural networks, and recently there is an increase of intererst for generalizing convolutional neural networks (CNNs) beyond grid data such as images to model data in graph domains [6][12], showing promising progress.", "startOffset": 205, "endOffset": 208}, {"referenceID": 11, "context": "[25] proposed graphical neural networks, and recently there is an increase of intererst for generalizing convolutional neural networks (CNNs) beyond grid data such as images to model data in graph domains [6][12], showing promising progress.", "startOffset": 208, "endOffset": 212}, {"referenceID": 15, "context": "Mozos and Burgard [16] presented an approach which first classifies each point in the metric map into semantic categories using AdaBoost, then segments the labeled metric map into regions in order to extract a topological map.", "startOffset": 18, "endOffset": 22}, {"referenceID": 7, "context": "[8] proposed an approach based on Voronoi random fields (VRFs), which also attempts to estimate the label of each node.", "startOffset": 0, "endOffset": 3}, {"referenceID": 16, "context": "Although this approach uses CRF, a discriminative probabilistic graphical model, it relies on pseudolikelihood and loopy belief propagation [17] to achieve approximate MAP inference, which may not converge to correct probability distribution.", "startOffset": 140, "endOffset": 144}, {"referenceID": 15, "context": "Besides, this approach relies on AdaBoost to learn features for place classification, similar to [16].", "startOffset": 97, "endOffset": 101}, {"referenceID": 19, "context": "SPN, proposed by Poon and Domingos [20], is a new class of probabilistic graphical models with built-in properties that allow tractable inference, a major advantage over traditional graphical models such as Bayesian networks.", "startOffset": 35, "endOffset": 39}, {"referenceID": 4, "context": "The idea is built upon Darwiche\u2019s work on network polynomial and differentials in arithmetic circuit representation of the polynomial [5].", "startOffset": 134, "endOffset": 137}, {"referenceID": 19, "context": "[20] Let X = {X1, \u00b7 \u00b7 \u00b7Xn} be a set of variables.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "Poon and Domingos proved that if an SPN is complete and consistent, then it is valid [20].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "A more restricted theorem for validity is that if an SPN is complete and decomposible, then it is valid [19].", "startOffset": 104, "endOffset": 108}, {"referenceID": 4, "context": "This uses the same idea as Darwiche\u2019s derivation of partial differentiations in arithmetic circuits [5].", "startOffset": 100, "endOffset": 103}, {"referenceID": 4, "context": "Then, as derived in [5], P (Xp = a|e) = 1 S(e) \u2202S(e) \u2202Si(e) \u221d \u2202S(e) \u2202Si(e) (3)", "startOffset": 20, "endOffset": 23}, {"referenceID": 4, "context": "This holds because the indicators are actually real-valued [5][19], and this is important when we take the derivative with respect to an indicator [19].", "startOffset": 59, "endOffset": 62}, {"referenceID": 18, "context": "This holds because the indicators are actually real-valued [5][19], and this is important when we take the derivative with respect to an indicator [19].", "startOffset": 62, "endOffset": 66}, {"referenceID": 18, "context": "This holds because the indicators are actually real-valued [5][19], and this is important when we take the derivative with respect to an indicator [19].", "startOffset": 147, "endOffset": 151}, {"referenceID": 4, "context": "Thus, we use the partial differentials derived by Darwiche [5] to obtain the following.", "startOffset": 59, "endOffset": 62}, {"referenceID": 19, "context": "In this case, the obtained instantiation x\u0302 has the maximum value of S(x\u0302|e) [20].", "startOffset": 77, "endOffset": 81}, {"referenceID": 9, "context": "LearnSPN The most commonly used structure learning algorithm is LearnSPN [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 20, "context": "Random-Decomposition We use a different approach in learning the SPN structure, similar to the one used in [21].", "startOffset": 107, "endOffset": 111}, {"referenceID": 21, "context": "[22] proposed a hierarchical spatial representation named Deep Affordance Spatial Hierarchy (DASH).", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "To enable this, the authors used DGSM (Deep Generative Spatial Model) [21] to represent the default knowledge about the environment.", "startOffset": 70, "endOffset": 74}, {"referenceID": 21, "context": "The authors of DASH [22] also describe a mapping algorithm that builds a topological map.", "startOffset": 20, "endOffset": 24}, {"referenceID": 22, "context": "As the robot explores an environment, the mapping algorithm expands the topological map by adding placeholders [23] as nodes, according to a probability formulation as follows", "startOffset": 111, "endOffset": 115}, {"referenceID": 21, "context": "For details about how \u03c6I(Ei) is defined, refer to the original paper [22].", "startOffset": 69, "endOffset": 73}, {"referenceID": 20, "context": "Our definition of a place follows from the polar occupancy grid representation for local environment described by Pronobis and Rao in [21].", "startOffset": 134, "endOffset": 138}, {"referenceID": 20, "context": "(Image adapted from [21])", "startOffset": 20, "endOffset": 24}, {"referenceID": 20, "context": "The leaf (singleton) variable, in our context, is a place which can be modeled by an SPN in DGSM [21].", "startOffset": 97, "endOffset": 101}, {"referenceID": 0, "context": "[1] support the idea of using a subgraph of small size as the template for the entire topological map.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "Linear time solution exists but only works for planar graphs [7], and a topological map is not necessarily planar.", "startOffset": 61, "endOffset": 64}, {"referenceID": 20, "context": "We used LibSPN [21], a Python library that implements learning and inference with SPNs on GPUs.", "startOffset": 15, "endOffset": 19}, {"referenceID": 0, "context": "The dataset is created from both Stockholm sequences and Freiburg sequences, because the topological relations of place categories are generally the same across different environments [1].", "startOffset": 184, "endOffset": 187}], "year": 2017, "abstractText": "In order to perform complex actions in human environments, an autonomous robot needs the ability to understand the environment, that is, to gather and maintain spatial knowledge. Topological map is commonly used for representing large scale, global maps such as floor plans. Although much work has been done in topological map extraction, we have found little previous work on the problem of learning the topological map using a probabilistic model. Learning a topological map means learning the structure of the large-scale space and dependency between places, for example, how the evidence of a group of places influence the attributes of other places. This is an important step towards planning complex actions in the environment. In this thesis, we consider the problem of using probabilistic deep learning model to learn the topological map, which is essentially a sparse undirected graph where nodes represent places annotated with their semantic attributes (e.g. place category). We propose to use a novel probabilistic deep model, Sum-Product Networks (SPNs) [20], due to their unique properties. We present two methods for learning topological maps using SPNs: the place grid method and the template-based method. We contribute an algorithm that builds SPNs for graphs using template models. Our experiments evaluate the ability of our models to enable robots to infer semantic attributes and detect maps with novel semantic attribute arrangements. Our results demonstrate their understanding of the topological map structure and spatial relations between places.", "creator": "LaTeX with hyperref package"}}}