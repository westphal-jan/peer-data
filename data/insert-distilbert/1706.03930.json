{"id": "1706.03930", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2017", "title": "Item Difficulty-Based Label Aggregation Models for Crowdsourcing", "abstract": "a large amount of labeled data is required for supervised learning. however, labeling by domain variance experts is expensive and time - consuming. a low cost and high efficiency way to obtain large training datasets is done to aggregate noisy labels collected from non - professional management crowds. prior works have proposed confusion matrices to evaluate the reliability effects of workers. in this paper, we redefine the structure of the confusion matrices and propose two bayesian network based methods which utilize item difficulty in label aggregation. we assume that labels evaluated are generated by a probability distribution over confusion matrices, item difficulties, imperfect labels and true labels. we use markov chain monte carlo method to generate samples from the posterior distribution of model simulation parameters and then infer the results. to avoid bad local optima, we design a method, to both preliminarily dramatically predict the difficulty of each item and initialize the model parameters. we also introduce how to improve the scalability of our model. empirical results show that our methods consistently outperform state - of - the - art methods.", "histories": [["v1", "Tue, 13 Jun 2017 07:28:26 GMT  (129kb)", "http://arxiv.org/abs/1706.03930v1", null], ["v2", "Wed, 5 Jul 2017 07:28:14 GMT  (2431kb)", "http://arxiv.org/abs/1706.03930v2", null], ["v3", "Tue, 3 Oct 2017 09:18:04 GMT  (78kb)", "http://arxiv.org/abs/1706.03930v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.HC cs.LG", "authors": ["chi hong"], "accepted": false, "id": "1706.03930"}, "pdf": {"name": "1706.03930.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["hc15@mails.tsinghua.edu.cn"], "sections": [{"heading": null, "text": "ar X\niv :1\n70 6.\n03 93\n0v 1\n[ cs\n.A I]\n1 3\nJu n\n20 17\nsupervised learning. However, labeling by domain experts is\nexpensive and time-consuming. A low cost and high efficiency\nway to obtain large training datasets is to aggregate noisy\nlabels collected from non-professional crowds. Prior works\nhave proposed confusion matrices to evaluate the reliability\nof workers. In this paper, we redefine the structure of the\nconfusion matrices and propose two Bayesian Network based\nmethods which utilize item difficulty in label aggregation. We\nassume that labels are generated by a probability distribution\nover confusion matrices, item difficulties, labels and true labels.\nWe use Markov chain Monte Carlo method to generate samples\nfrom the posterior distribution of model parameters and then\ninfer the results. To avoid bad local optima, we design a method\nto preliminarily predict the difficulty of each item and initialize\nthe model parameters. We also introduce how to improve\nthe scalability of our model. Empirical results show that our\nmethods consistently outperform state-of-the-art methods."}, {"heading": "1. Introduction", "text": "Nowadays, huge amounts of data are produced from various sources which allows people to build models for all kinds of applications. Usually, these data cannot be directly used for model building, they should be labeled at first. It is expensive and time-consuming to employ domain experts to manually label data. Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4]. Online platforms such as Crowdflower1 and Amazon Mechanical Turk2 can split large dataset into small parts and distribute these small labeling tasks to workers [5]. However, these non-professional workers may provide noisy labels. The accuracy of each worker may be lower than expected. To improve the accuracy, it is important to aggregate the noisy labels and infer the true labels.\nNote that each item may be labeled multiple times by different workers. The most straightforward way to infer the true label for each item is to simply choose the most frequent label. This approach is called as majority voting. In most cases, it has significantly better performance than single workers [6], [7]. However, majority voting implicitly\n1. http://crowdflower.com/ 2. https://www.mturk.com/mturk\nassumes that all workers are equally good and treats each item independently. For a specific case, majority voting will make mistake if there are few true labels given by experienced workers and lots of identical error labels generated by novices. To overcome this problem, some methods take into account the worker reliability in label aggregation. Dawid and Skene [8] associated each worker with a confusion matrix which can evaluate the reliabilities and potential biases of the workers. For a given worker, each element of the confusion matrix is a probability that the worker labels items in one class as another.\nIn recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11]. However, in these methods, each worker only uses one confusion matrix to generate labels for items. There is a one-to-one correspondence between an worker and an confusion matrix. They don\u2019t consider the characteristics of items, such as difficulty. It is somewhat unreasonable. Actually, different items may have different difficulty levels. For example, there are two face photos of the same person, one is very clear, the other is blurred. A worker is more likely to make mistakes when recognizing the blurred one. He or she should have different confusion in the face of items (face photos) with different difficulties (blurred or clear).\nDifferent from these methods, in this paper, we set a confusion matrix for each worker-difficulty level pair. The confusion matrices is not only correlate to workers, but also correlate to item difficulty levels. We haven\u2019t seen any previous work taking this into account. We assume that the collected labels are generated by a distribution over the confusion matrices, item difficulties, true labels and labels. Based on this assumption, we propose models which utilize item difficulty information in the process of label aggregation. In this paper, our main contributions are as follows:\n\u2022 We define a Bayesian network based model which considers item difficulty in label aggregation. Gibbs sampling is used to generate samples from the posterior distribution of model parameters. We call this model as Item Difficulty-Based Label Aggregation (IDBLA) model. \u2022 We propose a new model which is a variation of the\nIDBLA model, considering the existence of particularly simple items and particularly difficult items. \u2022 We also design a method to preliminarily predict the difficulty of each item. The predicted results are used to initialize our models. The initialization is important for the performance of our models. \u2022 Finally, we introduce how to apply variational inference to the IDBLA model so as to improve its scalability.\nWe conduct our experiments on three real datasets and one synthetic dataset. The experimental results show that our methods have better performance than state-of-the-art label aggregation methods.\nThe structure of the paper is as follows. Section 2 introduces the related work. Section 3 introduces the preliminary notation and the majority voting algorithm. Section 4 illustrates our methods in detail. Section 5 introduces the experiments and the results. Section 6 introduces how to apply variational inference to the IDBLA model. Section 7 concludes the paper."}, {"heading": "2. Related Work", "text": "Raykar et al. [9] proposed the two two-coin model for binary labeling tasks, which can be seen as a variation of the confusion matrix. In their method, the labels generated by workers are directly used for learning. Estimating the reliability of the workers and the true labels of the items is a byproduct of the method. In Minimax Conditional Entropy (MMCE) [6], each worker-item pair is related to a independent distribution. The authors used a minimax entropy method to estimate the distributions and infer the true labels. Kim and Ghahramani [10] used the confusion matrix to define their Bayesian Classifier Combination (BCC) model which is a Bayesian extension of Dawid and Skene\u2019s method. Venanzi et al. [12] extended the BCC model and proposed the CommunityBCC model, which groups workers into communities. The workers that belong to the same community have the similar confusion matrices. CommunityBCC is particularly suit for sparse dataset which doesn\u2019t have enough labels to learn a large number of parameters. Nguyen et al. [13] also proposed a graphical model based approach for crowdsourcing. This model can capture the correlations between entries in worker confusion matrices and use the correlations to improve the estimation of the confusion matrices.\nThere are many other methods besides confusion matrixbased methods. Zhou and He [14] proposed a approach which based on tensor augmentation and completion for crowdsourcing. The collected labels are represented as tensor. The GLAD model [5] is based on parameters which represent the expertise of workers and difficulties of items. The authors used the Expectation-Maximization algorithm as the learning and inference algorithm. GLAD is a label aggregation model for binary labeling tasks. It simultaneously considers the expertise of each worker and the difficulty of each item. Liu et al. [15] also used a single parameter\nto describe the reliability of a worker. Gaunt et al. [16] trained a deep neural network for label aggregation. Unlike Bayesian network based methods, this method doesn\u2019t need to make assumptions for the model definition. However, it is not adapt to the case of incomplete data where some workers labeled only few items. Karger et al. [17] put different weights on workers in their model. This work extended the majority voting algorithm. In recent years, Multi-Armed Bandits based method [18] has been proposed for crowdsourcing."}, {"heading": "3. Preliminary", "text": ""}, {"heading": "3.1. Notation", "text": "In the aggregation problem, we consider that there are K workers and I items. In each task, the workers are required to label one item. Li,k is the label of item i which labeled by worker k, where Li,k \u2208 {1, ..., C}. C is the number of classes. L is a collection of all the collected labels. Note that each worker may only labels a part of the dataset, if worker k hasn\u2019t labeled item i, then Li,k = None. Ti is the true label of item i and T = {T1, ..., TI} includes all the true labels."}, {"heading": "3.2. Majority Voting", "text": "Majority voting is a simple and straightforward way to aggregate labels. For each item i, it selects the most frequent answer as the true label Ti. This can be represented as:\nTi = argmax l\u2208{1,...,C}\nK \u2211\nk=1\nI(Li,k = l) (1)\nwhere I(\u00b7) is the indicator function taking the value 1 when the predicate is true, and 0 otherwise. Majority voting is easy to implement and normally can generate high quality aggregation result although it only considers each item independently. Recent years, there are several works have extended this method [19], [20]."}, {"heading": "4. Methods", "text": "Dawid and Skene\u2019s method [8] associates each worker k with a probabilistic confusion matrix \u03c6(k). \u03c6 (k) t,c is the probability of worker k classifies an item as class c when the true label of the item is t. Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.\nAs mentioned in Section 1, these models don\u2019t consider the characteristics of the labeling tasks, such as the difficulties of items. In these models, the confusion matrix is only correlate to worker k. It is somewhat unreasonable. Therefore, we try predicting and utilizing the item difficulty information in label aggregation. In our models, we use two indexes for the confusion matrix, one is worker k and the other is difficulty level h.\nNext, we will describe our methods detailedly, including model representation, inference and parameter initialization. In Section 4.1 we propose the IDBLA model. In Section 4.2 we introduce the Fixed-IDBLA model which is a variation of the IDBLA model. Finally, in section 4.3, we present how to predict the difficulties of items and initialize the model parameters."}, {"heading": "4.1. Item Difficulty-Based Label Aggregation Model", "text": "In our model, each item i correlates to a difficulty level Qi which takes integer values. Qi \u2208 {1, ..., H}, where H is the number of difficulty levels. We set an independent probabilistic confusion matrix \u03c0(k,h) for each worker-difficulty level pair (k, h). Consider item i with true label Ti \u2208 {1, ..., C} and difficulty level Qi, we let p(Li,k|Ti, Qi) = \u03c0 (k,Qi) Ti,Li,k\n. That is to say the label Li,k that generated by worker k for item i has a multinomial distribution with parameters \u03c0 (k,Qi) Ti :\nLi,k \u223c Multinomial(\u03c0 (k,Qi) Ti ). (2)\nEach worker generates her own labels independently. Labels for different items are independent and identically distributed. So we can get:\np(L|\u03c0,T ,Q) = K \u220f\nk=1\nH \u220f\nh=1\nC \u220f\nt=1\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) Nk,ht,c , (3)\nwhere\nN k,ht,c = I \u2211\ni=1\nI(Li,k = c, Ti = t, Qi = h)\nis the number of times worker k labels c when the item difficulty level is h and the correct label is t. We assume that \u03c0 (k,h) t follow a Dirichlet distribution which is the conjugate prior of the multinomial distribution:\n\u03c0 (k,h) t \u223c Dir(\u03c9 (k,h) t ) (4)\nwhere \u03c9 (k,h) t is a collection of hyperparameters. We further assume that all the elements in the confusion matrix \u03c0(k,h) = {\u03c0\n(k,h) 1 , ...,\u03c0 (k,h) C } are independent of\neach other. \u03c0 is a collection of \u03c0(k,h), where k \u2208 {1, ...,K}, h \u2208 {1, ..., H}. \u03c9 is a collection of \u03c9(k,h) = {\u03c9 (k,h) 1 , ...,\u03c9 (k,h) C }. Using (4), then we have:\np(\u03c0|\u03c9) \u221d K \u220f\nk=1\nH \u220f\nh=1\nC \u220f\nt=1\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) \u03c9 (k,h) t,c \u22121 (5)\nAssuming that the true label Ti and difficulty level Qi of item i have multinomial distributions:\nTi \u223c Multinomial(\u03b1) (6)\nQi \u223c Multinomial(\u03b2) (7)\nwhere, \u03b1 = {\u03b11, ..., \u03b1C} and \u03b2 = {\u03b21, ..., \u03b2H}. Labeling tasks are independent of each other. Using (6):\np(T |\u03b1) = C \u220f\nc=1\n\u03b1NT (c)c , (8)\nwhere NT (c) = \u2211I\ni=1 I(Ti = c) and T = {T1, ..., TI}. Similarly, using (7) we have:\np(Q|\u03b2) = H \u220f\nh=1\n\u03b2 NQ(h) h (9)\nwhere Q = {Q1, ..., QI} is a collection of item difficulties. Note that NQ(h) = \u2211I i=1 I(Qi = h). The prior for \u03b1 is set to be a Dirichlet distribution with hyperparameter \u03b3\u03b1 = {\u03b3\u03b11, ..., \u03b3\u03b1C}. \u03b2 has a Dirichlet distribution with hyperparameter \u03b3\u03b2 = {\u03b3\u03b21, ..., \u03b3\u03b2H}.\n\u03b1 \u223c Dir(\u03b3\u03b1) (10)\n\u03b2 \u223c Dir(\u03b3\u03b2) (11)\nLet \u00b5 represents the hyperparameters \u03c9, \u03b3\u03b1 and \u03b3\u03b2 . Then the posterior distribution over model parameters can be written as:\np(T ,Q,\u03c0,\u03b1,\u03b2|L,\u00b5) \u221d p(T |\u03b1)p(\u03b1|\u03b3\u03b1)\np(Q|\u03b2)p(\u03b2|\u03b3\u03b2)p(L|\u03c0,T ,Q)p(\u03c0|\u03c9) (12)\nAccording to (3), (5), (8), (9), (10) and (11), equation (12) can be rewritten as:\np(T ,Q,\u03c0,\u03b1,\u03b2|L,\u00b5) \u221d {\nC \u220f\nc=1\n\u03b1NT (c)+\u03b3\u03b1c\u22121c\n}{\nH \u220f\nh=1\n\u03b2 NQ(h)+\u03b3\u03b2h\u22121 h\n}\n{\nK \u220f\nk=1\nH \u220f\nh=1\nC \u220f\nt=1\nC \u220f\nc=1\n(\u03c0 (k,h) t,c )\nNk,ht,c +\u03c9 (k,h) t,c \u22121\n}\n(13)\nThe factor graph for the IDBLA model is shown in Figure 1. Next, let\u2019s talk about the inference of this model.\nWe use Gibbs sampling to infer the unknown model parameters T , Q, \u03c0, \u03b1 and \u03b2. For each iteration, we update each parameter by sampling from its conditional distribution given the rest parameters. Here are the conditional distributions for Gibbs sampling which are derived from equation (13):\np(Ti = t|rest) \u221d \u03b1t\u03b2Qi\nK \u220f\nk=1\nC \u220f\nc=1\n(\u03c0 (k,Qi) t,c ) I(Li,k=c) (14)\np(Qi = h|rest) \u221d \u03b1Ti\u03b2h\nK \u220f\nk=1\nC \u220f\nc=1\n(\u03c0 (k,h) Ti,c )I(Li,k=c) (15)\np(\u03c0 (k,h) t |rest) \u221d\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) Nk,ht,c +\u03c9 (k,h) t,c \u22121 (16)\np(\u03b1|rest) \u221d C \u220f\nc=1\n\u03b1NT (c)+\u03b3\u03b1c\u22121c (17)\np(\u03b2|rest) \u221d H \u220f\nh=1\n\u03b2 NQ(h)+\u03b3\u03b2h\u22121 h (18)\nWe see that the posterior distributions of \u03c0 (k,h) t , \u03b1 and \u03b2 take the form of Dirichlet distributions. The new values of Ti and Qi are generated by multinomial distributions. So model parameters T , Q, \u03c0, \u03b1 and \u03b2 all can be easily sampled."}, {"heading": "4.2. Fixed-IDBLA Model", "text": "In the dataset, there may be some very easy items and some very difficult items. We assume that every worker labels the easy items with a high correct rate and labels the difficult items with a very low correct rate. Based on this assumption, we propose the Fixed-IDBLA model which is a variation of IDBLA. The factor graph for this model is shown in Figure 2.\nIn Fixed-IDBLA, we set \u03c0(k,H\u22121) for easy items and set \u03c0(k,H) for difficult items, where k \u2208 {1, ...,K}. \u03c0(k,H\u22121) and \u03c0(k,H) are fixed as:\n\u03c0(k,H\u22121) =\n\n   \n1\u2212 \u03bd \u03bd C\u22121 . . . \u03bd C\u22121\n\u03bd C\u22121 1\u2212 \u03bd . . . \u03bd C\u22121\n... ...\n. . . ...\n\u03bd C\u22121\n\u03bd C\u22121 . . . 1\u2212 \u03bd\n\n   \n\u03c0(k,H) =\n\n   \n1\u2212 \u03b4 \u03b4 C\u22121 . . . \u03b4 C\u22121\n\u03b4 C\u22121 1\u2212 \u03b4 . . . \u03b4 C\u22121\n... ...\n. . . ...\n\u03b4 C\u22121\n\u03b4 C\u22121 . . . 1\u2212 \u03b4\n\n   \nwhere \u03bd and \u03b4 are constants. We assume that:\n\u03c0 (k,h) t \u223c Dir(\u03c8 (k,h) t ),\nh \u2208 {1, ..., H \u2212 2}, k \u2208 {1, ...,K} (19)\nwhere \u03c8 (k,h) t is a collection of hyperparameters. The distributions of L, T , \u03b1, Q and \u03b2 are the same as described in 4.1. According to (3) and (19) we have:\np(L|\u03c0,T ,Q)p(\u03c0|\u03c8) \u221d {\nK \u220f\nk=1\nH\u22122 \u220f\nh=1\nC \u220f\nt=1\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) Nk,ht,c +\u03c8 (k,h) t,c \u22121\n}\n{\nK \u220f\nk=1\nH \u220f\nh=H\u22121\nC \u220f\nt=1\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) Nk,ht,c\n}\n(20)\nwhere \u03c8 is a collection of \u03c8(k,h). We again use Gibbs sampling to sample all the unknown model parameters. The latent parameters T , Q, \u03b1 and \u03b2 are still sampled by (14), (15), (17) and (18). For each worker k, \u03c0 (k,h) t is sampled by conditional distribution:\np(\u03c0 (k,h) t |rest) \u221d\nC \u220f\nc=1\n(\u03c0 (k,h) t,c ) Nk,ht,c +\u03c8 (k,h) t,c \u22121 (21)\nwhere h = 1, ..., H \u2212 2. Note that the posterior distribution of \u03c0\n(k,h) t is a Dirichlet distribution."}, {"heading": "4.3. Parameter Initialization", "text": "In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.\nIn our models, we have introduced the concept of item difficulty. Both parameters T and Q need to be initialized. We manage to design a low overhead method to initialize them. Note that instead of making a precise prediction, we just make a preliminarily prediction of true labels T and difficulty levels Q to avoid bad local optima in the nonconvex optimization.\nIn actually, the ground truth labels are unknown. So we use majority voting to initialize T , and approximate T as a collection of the ground truth labels. Based on T , we calculate the correct rate Rk for each worker k:\nRk =\n\u2211I i=1 I(Li,k = Ti)\n\u2211I i=1 I(Li,k 6= None)\n(22)\nThen, let \u03bbk = xRk be the ability of worker k, where x is a constant. We assume that:\np(Li,k = Ti)|\u03bbk, \u01ebi) = 1\n1 + (C \u2212 1)e\u2212\u03bbk\u01ebi ,\ni \u2208 {1, ..., I}, k \u2208 {1, ...,K} (23)\nwhere 1/\u01ebi \u2208 [0,+\u221e) is the difficulty of item i. We see that as the item difficulty 1/\u01ebi increases, the probability of labeling the item correctly decreases toward 1/C. That means for the most difficult item the worker just arbitrarily chooses a label. When 1/\u01ebi decreases toward 0, the probability of labeling the item correctly increases\ntoward 1. Using (23), we have the likelihood of the observed labels:\np(L|T ,\u03bb, \u01eb) = I \u220f\ni=1\n\u220f\nk\u2208Si\np(Li,k|Ti, \u03bbk, \u01ebi) (24)\nwhere \u03bb = {\u03bb1, ..., \u03bbK}, \u01eb = {\u01eb1, ..., \u01ebI} and Si is a set of workers who have labeled the item i. We use gradient ascent to locally maximize the log-likelihood F (\u01eb) = ln p(L|T ,\u03bb, \u01eb) and get the corresponding value of \u01eb. Further, according to \u01eb, we can put items into different difficulty levels and initialize Q. This idea is inspired by GLAD [5] which can simultaneously infer the true labels of items, the abilities of workers and the difficulties of items. The initialization method introduced in this section is important for the performance of the IDBLA model and the FixedIDBLA model. We will validate the effectiveness of the initialization in Section 5."}, {"heading": "5. Experiments", "text": "IDBLA and Fixed-IDBLA are compared with three state-of-the-art algorithms: majority voting, DS-EM and BCC. We use three real crowdsourcing datasets and one synthetic dataset in our experiments. In the following, we will introduce our experiments in detail, and evaluate the effectiveness of our models."}, {"heading": "5.1. Datasets", "text": "The four datasets are shown in Table 1. They have different sizes and features. We introduce them in the following sections.\n5.1.1. Heart Disease Diagnosis. We got the heart disease instances [22] and the corresponding ground truth labels from the UC Irvine machine learning repository website. Each instance include attributes such as age, sex, maximum heart rate achieved, etc. We removed the ground truth labels and requested 12 medical students to label the instances in their spare time. These students volunteer to offer the labels without pay. They have different expertise levels about heart disease diagnosis. For each instance we don\u2019t care about the type of heart disease, we only consider whether the patient has heart disease. Each student doesn\u2019t have to label all the instances. The number of the instances for heart disease is 87 and there are other 150 instances for health. There are 237 instances in total. We finally got 952 labels. The average accuracy of the students is 68.59%. The student who labeled the most labeled 213 instances with accuracy of 87.79%. Each student labeled at least 43 instances. For the sake of simplicity, in the following we refer to this data set as Heartdisease.\n5.1.2. Web Search Relevance Judgment. TheWeb Search [6] dataset is about web search relevance judgment. In the original dataset, workers are asked to rate a set of 2665 query-URL pairs on a relevance rating scale from 1 to 5. It is difficult to evaluate the worker who only labeled few items.\nTherefore, we removed the workers who labeled less than 30 items. We also removed the items that haven\u2019t ground truth labels. Then we got 2653 items and 14638 labels which are offered by 76 workers. The average accuracy of these workers is 41.08%. The accuracy of the best worker is 76.73% and this worker generated 1225 labels. All the labels are offered by workers in MTurk website. The accuracies of the workers are shown in Figure 3(a), each bar represents the accuracy of a worker.\n5.1.3. RTE Dataset. In this dataset, the tasks are about recognizing textual entailment. RTE [7] contains 8000 binary labels for 800 documents. The numbers of the documents for each class are all equal to 400. A total of 164 labelers participated in the labeling task. The average accuracy of the labelers is 83.70%. The labeler who labeled the most generated 800 labels and had a accuracy of 50.63%.\n5.1.4. Synthetic Dataset. In addition to the above three real data sets, we also made a Synthetic dataset. We generated 1000 items and 100 workers. The true label of each item is sampled from {1, 2, 3, 4, 5} with probabilities {0.18, 0.27, 0.45, 0.05, 0.05}, the classes are imbalanced. In order to simulate the real situation, each worker k labels a item with probability \u03c1k. The maximum value in \u03c1 = {\u03c11, ..., \u03c1100} is 0.74, most elements in \u03c1 get values in the interval [0.03, 0.2]. The average accuracy of the workers is 41.92%. The best worker has a accuracy of 83.49%. Finally, we got a total of 11615 labels. The accuracies of the workers are shown in Figure 3(b), each bar denotes the accuracy of a worker."}, {"heading": "5.2. Baselines", "text": "We have already introduced majority voting in Section 3. In this section, we simply introduce DS-EM and BCC.\n5.2.1. DS-EM. DS-EM [8] is a classic generative approach. It assumes that the worker has consistent performances in different labeling tasks and let \u03c6 (k) t,c be the probability of worker k labels an item as class c when the true label of the item is t. It also assumes that Ti has a multinomial distribution, p(Ti = t) = pt, where i \u2208 {1, ..., I} and t \u2208\n{1, ..., C}. DS-EM uses an expectation-maximization (EM) algorithm to obtain maximum likelihood estimates of \u03c6 and T .\nE-step: Estimating T by using:\np(Ti = t|L,\u03c6) \u221d p(Ti = t)p(Li|Ti = t,\u03c6)\n\u221d pt\nK \u220f\nk=1\nC \u220f\nl=1\n(\u03c6 (k) t,l ) I(Li,k=l)\nwhere Li = {Li,1, ..., Li,k}. The value of pt can be estimated by p\u0302t = \u2211I i=1 I(Ti = t)/I .\nM-step: The likelihood for the full data is:\nM(\u03c6) = I \u220f\ni=1\nC \u220f\nt=1\n{\npt\nK \u220f\nk=1\nC \u220f\nl=1\n(\u03c6 (k) t,l ) I(Li,k=l)\n} I(Ti=t)\nwhere the values of T and {p1, ..., pC} are known, then \u03c6 can be estimated by the maximum-likelihood estimation: \u03c6\u0302 = argmax\u03c6M(\u03c6). Note that this optimisation problem can be analytically solved.\n5.2.2. BCC. BCC is a probabilistic graphical model which can learn the items\u2019 true labels and the workers\u2019 confusion matrices. It can be seen as a Bayesian version of DS-EM. BCC and DS-EM have the same definition of confusion matrix. We implemented the method according to Kim\u2019s paper [10] which uses Gibbs sampling and rejection sampling to infer the unknown model parameters."}, {"heading": "5.3. Setups", "text": "Majority voting is implemented according to the introduction in Section 3. In a specific task, if there are multiple most frequent classes for the item, the majority voting algorithm will randomly choose one among them.\nIn order to avoid bad local optima, DS-EM and BCC use majority voting to initialize the unknown true labels. For BCC, the hyperparameters are set as described in Kim\u2019s paper. The model parameters are also initialized according to the paper\u2019s description.\nFor IDBLA model, \u03c9 (k,h) t,c , \u03b3\u03b1c and \u03b3\u03b2h are all set as 1.0. Which means the distributions of \u03c0 (k,h) t , \u03b1 and \u03b2 have uninformed priors. As described in Section 4.3, T is\ninitialized by majority voting. \u03b1 is initialized by the result of counting T ,\n\u03b1c =\n\u2211I i=1 I(Ti = c)\nI .\nUsing the method aforementioned in Section 4.3, we can get the value of \u01eb = {\u01eb1, ..., \u01ebI}, where 1/\u01ebi denotes the difficulty of item i. The items are divided into H groups which belong to different difficulty levels based on \u01eb, Q is initialized. \u03b2 is initialized by the result of counting Q,\n\u03b2h =\n\u2211I i=1 I(Qi = h)\nI .\nAccording to T , Q and the known L, \u03c0 (k,h) t,c can be initialized by:\n\u03c0 (k,h) t,c =\n\u2211I i=1 I(Li,k = c, Ti = t, Qi = h)\n\u2211I i=1 I(Li,k 6= None, Ti = t, Qi = h)\nFor Fixed-IDBLA model, \u03bd is set as 0.1, \u03b4 is set as 0.8, the hyperparameters \u03c8\n(k,h) t,c , \u03b3\u03b1c and \u03b3\u03b2h are all set as 1.0.\nThe other model parameters and hyperparameters are set the same as in IDBLA.\nH selection:For IDBLA and Fixed-IDBLA models, the number of difficulty levels H should be determined. Given a value H\u0302 and a dataset, the corresponding likelihood p(L|\u03c0\u0302, T\u0302 , Q\u0302) could be computed. So, for each dataset, we can try several values of H and select the value which generates the maximum likelihood. Note that the likelihood p(L|\u03c0\u0302, T\u0302 , Q\u0302) and the accuracy are not directly related."}, {"heading": "5.4. Experimental Results", "text": "In this section, we will compare the accuracy of our methods and the three baseline methods. We also show the iteration processes of BCC, IDBLA and Fixed-IDBLA. In Section 5.4.3, the negative log likelihood is used to evaluate the models. In Section 5.4.4, we will further investigate our methods.\nWe used a PC with Intel Core i5 2.6GHz CPU and 8GB RAM for our experiments. In order to guarantee the fairness of the experiments. We use uninformed priors in all methods. We use majority voting to initialize parameters in all methods. All the graphical models use the same inference algorithm. Gibbs sampling is capable of performing inference in our experiments. Every method have the same input data format for fair comparison.\n5.4.1. Accuracies of Methods. Firstly, we use accuracy to evaluate the performance of each method. For BCC, IDBLA and Fixed-IDBLA, we sampled 500 samples in each run. On each dataset, we executed every method independently 10 times and averaged the accuracies.\nThe accuracies of all the methods are shown in Table 2. Compared to Figure 3(a) and Figure 3(b), we can see that these label aggregation methods generate results obviously better than single workers. The best result for each dataset is highlighted in bold. Every method have the same input data format for fair comparison. In our experiments, IDBLA consistently outperforms majority voting, DS-EM and BCC across all datasets. On the Heartdisease dataset, FixedIDBLA has the best performance. IDBLA has higher accuracy than Fixed-IDBLA on Web Search dataset and RTE dataset. On the Synthetic dataset, IDBLA and Fixed-IDBLA have the same accuracies. DS-EM, BCC, IDBLA and FixedIDBLA are substantially better than majority voting. They are methods based on confusion matrix. The experimental results show that predicting and utilizing item difficulty is an effective way for crowdsourcing.\n5.4.2. Iteration Process. We also investigate the convergence of BCC, IDBLA and Fixed-IDBLA. These three methods are all based on sampling.\nFigure 4(a) shows the runtime and corresponding error rates for the methods on the Heartdisease dataset. Using the selection method aforementioned in Section 5.3, we set H = 3 for IDBLA and H = 4 for Fixed-IDBLA. We can see that BCC quickly converges to a high error rate result. IDBLA has a gentle convergence process. Fixed-IDBLA converges to a low error rate fast, and keeps stable in the following running time.\nFigure 4(b) illustrates the iteration processes of BCC, IDBLA and Fixed-IDBLA on the Synthetic dataset. In this experiment, the selection method sets H = 3 for both IDBLA and Fixed-IDBLA. In the beginning the error rates of IDBLA and Fixed-IDBLA drop rapidly. Then the models converge to the final stable error rates with a relatively long time. BCC converge fast, however the error rate of BCC is higher.\nThe experiments show that IDBLA and Fixed-IDBLA converge a little slower than BCC, but they tend to generate better results.\n5.4.3. Negative Log Likelihood. Then, we use negative log likelihood (NLL) to evaluate the methods. It provides a more comprehensive measure. NLL can simultaneously\nevaluate the true labels and the confusion matrices found by the model. The likelihoods of IDBLA and Fixed-IDBLA are computed with equation (3). The likelihoods of DS-EM and BCC are computed with:\np(L|\u03c6,T ) = I \u220f\ni=1\nK \u220f\nk=1\nC \u220f\nl=1\n(\u03c6 (k) Ti,l )I(Li,k=l)\nwhere \u03c6(k) is the confusion matrix for worker k. The NLLs of DS-EM, BCC and our methods on the Heartdisease dataset are shown in Figure 5(a). IDBLA and Fixed-IDBLA have lower NLLs than the two baseline methods, which shows that our methods find better confusion matrices on this dataset.\nFigure 5(b) shows the NLLs of the methods on the Synthetic dataset. The NLLs of IDBLA and Fixed-IDBLA are higher than the NLLs of the baselines.\nActually, the NLLs of the four methods are close to each other which means that our methods can also find high quality confusion matrices to evaluate the reliabilities and potential biases of workers.\n5.4.4. Model Analysis. Finally, we further investigate the effectiveness of the parameter initialization and the quality\nof the difficulty level prediction of our models.\nParameter Initialization Effectiveness: We introduce the parameter initialization method in Section 4.3. In order to prove the effectiveness of the initialization, we remove it from our methods and then conduct the experiments again. For simplicity, we show the results on the Heartdisease dataset in Table 3. For IDBLA model, the error rate increases from 0.160 to 0.409. For Fixed-IDBLA model, the error rate increases from 0.156 to 0.430.\nDifficulty Level Prediction Quality: Compare to the ground truth labels, we can get the labeling error rate Ei of a item i.\nEi =\n\u2211K k=1 I(Li,k 6= None, Li,k 6= TRUTHi)\n\u2211K k=1 I(Li,k 6= None)\nwhere TRUTHi is the ground truth labels of item i. Average the labeling error rates of items in the same difficulty level, we can get the average labeling error rate of the difficulty level. We illustrate the results on the Heartdisease dataset. For IDBLA model, the average labeling error rate of the predicted easiest difficulty level is 0.280 and the average labeling error rate of the predicted hardest difficulty level is 0.523. For Fixed-IDBLA model, the average labeling error rate of the predicted easiest difficulty level is 0.213, the average labeling error rate of the predicted hardest difficulty level is 0.694. All the prediction results are consistent with the truth. That means the prediction of item difficulty is effective."}, {"heading": "6. Extension", "text": "In Section 5, the inference is done with Gibbs sampling. Sampling methods is computationally demanding. Gibbs sampling is incapable of inferring in very large dataset. Fortunately, in recently GPU has been used to accelerate sampling [23].\nWe also can use variational inference [24], [25] to solve the problem of scalability. Limited by space, in this section we will briefly introduce how to apply variational inference to our IDBLA model.\nThe true posterior distribution p(T ,Q,\u03c0,\u03b1,\u03b2|L,\u00b5) can be approximated via a simpler distribution q(T ,Q,\u03c0,\u03b1,\u03b2|\u00b5\u0302). We assume that q factorizes:\nq(T ,Q,\u03c0,\u03b1,\u03b2|\u00b5\u0302) =\n{\nK \u220f\nk=1\nH \u220f\nh=1\nC \u220f\nt=1\nq(\u03c0 (k,h) t |\u03c6 (k,h) t )\n}\n{\nI \u220f\ni=1\nq(Ti|\u03bbi)q(Qi|\u03c1i)\n}\nq(\u03b1|\u03c3)q(\u03b2|\u03b8)\nwhere \u00b5\u0302 represents the variational parameters \u03c6, \u03bb, \u03c1, \u03c3 and \u03b8. We assume that\nq(\u03c0 (k,h) t |\u03c6 (k,h) t ) = Dir(\u03c6 (k,h) t )\nq(\u03b1|\u03c3) = Dir(\u03c3)\nq(\u03b2|\u03b8) = Dir(\u03b8)\nq(Ti|\u03bbi) = Multinomial(\u03bbi)\nq(Qi|\u03c1i) = Multinomial(\u03c1i).\nMaximizing a lower bound on the data log likelihood is equivalent to maximize\nL(\u03c6,\u03bb,\u03c1,\u03c3, \u03b8;\u00b5) = Eq[log p(T ,Q,\u03c0,\u03b1,\u03b2,L|\u00b5)]\u2212\nEq[log q(T ,Q,\u03c0,\u03b1,\u03b2|\u00b5\u0302)]\nThe optimizing values of the variational parameters are found by maximizing L.\n(\u03c6\u2217,\u03bb\u2217,\u03c1\u2217,\u03c3\u2217, \u03b8\u2217) = argmax \u00b5\u0302 L(\u03c6,\u03bb,\u03c1,\u03c3, \u03b8;\u00b5)\nMaximizing L respect to \u00b5\u0302 can be done by taking derivatives with respect to every single parameter in \u00b5\u0302 and setting the\nderivatives to zero. Such as let \u2202L \u2202\u03bbit\n= 0, where \u03bbit is the t th element in \u03bbi. Resolving the equation group, we can get the optimizing values of the variational parameters."}, {"heading": "7. Conclusion", "text": "We propose the IDBLA model to aggregate labels collected from non-professional workers. In this model, the item difficulties are taken into consideration. Each workerdifficulty level pair is associated with a confusion matrix. The model finds the values of the confusion matrices and other latent variables in the learning process, and further uses them to infer the true labels. We also define a variation model of IDBLA which assumes that there exists some very easy items and some very difficult items. We call this variation model as Fixed-IDBLA. We design a method to preliminarily predict the difficulty of each item. The prediction results are used to initialize the latent parameters in IDBLA and Fixed-IDBLA. The initialization is important for the performance of our models. The experiments are conducted on three real datasets and one synthetic dataset. These datasets have different features as shown in Section 5.1. The empirical results show that our methods are effective. We used uninformed priors in our experiments. If we have the prior knowledge of the workers and items, the accuracy may be further improved. We also introduce how to apply variational inference to the IDBLA model so as to improve its scalability. In the future work, we would like to define a new model which can capture more item characteristics."}], "references": [{"title": "and C", "author": ["S. Ertekin", "H. Hirsh"], "venue": "Rudin, Approximating the wisdom of the crowd", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning to predict from crowdsourced data", "author": ["W. Bi", "L. Wang", "J.T. Kwok", "Z. Tu"], "venue": "UAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "Combining human and machine intelligence in large-scale crowdsourcing", "author": ["E. Kamar", "S. Hacker", "E. Horvitz"], "venue": "Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1. International Foundation for Autonomous Agents and Multiagent Systems", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "The multidimensional wisdom of crowds", "author": ["P. Welinder", "S. Branson", "S.J. Belongie", "P. Perona"], "venue": "NIPS, vol. 23", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise, in Advances in neural information processing", "author": ["J. Whitehill", "T.-f. Wu", "J. Bergsma", "J.R. Movellan", "P.L. Ruvolo"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["D. Zhou", "S. Basu", "Y. Mao", "J.C. Platt"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Cheap and fastbut is it good?: evaluating non-expert annotations for natural language tasks", "author": ["R. Snow", "B. OConnor", "D. Jurafsky", "A.Y. Ng"], "venue": "Proceedings of the conference on empirical methods in natural language processing. Association for Computational Linguistics", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Maximum likelihood estimation of observer error-rates using the em algorithm", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "Applied statistics, pp. 2028", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1979}, {"title": "Learning from crowds", "author": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"], "venue": "Journal of Machine Learning Research, vol. 11, no. Apr, pp. 12971322", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Bayesian classifier combination", "author": ["H.-C. Kim", "Z. Ghahramani"], "venue": "AISTATS", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Identifying and accounting for task-dependent bias in crowdsourcing", "author": ["E. Kamar", "A. Kapoor", "E. Horvitz"], "venue": "Third AAAI Conference on Human Computation and Crowdsourcing", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "Community-based bayesian aggregation models for crowdsourcing", "author": ["M. Venanzi", "J. Guiver", "G. Kazai", "P. Kohli", "M. Shokouhi"], "venue": "Proceedings of the 23rd international conference on World wide web. ACM", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2014}, {"title": "A correlated worker model for grouped", "author": ["A.T. Nguyen", "B.C. Wallace", "M. Lease"], "venue": "imbalanced and multitask data, in Proceedings of The Conference on Uncertainty in Artificial Intelligence (UAI)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Crowdsourcing via tensor augmentation and completion", "author": ["Y. Zhou", "J. He"], "venue": "Proceedings of the Twenty- Fifth International Joint Conference on Artificial Intelligence. AAAI Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "Variational inference for crowdsourcing", "author": ["Q. Liu", "J. Peng", "A.T. Ihler"], "venue": "Advances in neural information  processing systems", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Training deep neural nets to aggregate crowdsourced responses", "author": ["A. Gaunt", "D. Borsa", "Y. Bachrach"], "venue": "Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence. AUAI Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Iterative learning for reliable crowdsourcing systems", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": "Advances in neural information processing systems", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Efficient crowdsourcing of unknown experts using bounded multi-armed bandits", "author": ["L. Tran-Thanh", "S. Stein", "A. Rogers", "N.R. Jennings"], "venue": "Artificial Intelligence, vol. 214, pp. 89111", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Max-margin majority voting for learning from crowds", "author": ["T. Tian", "J. Zhu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Error rate bounds and iterative weighted majority voting for crowdsourcing", "author": ["H. Li", "B. Yu"], "venue": "arXiv preprint arXiv:1411.4086", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Spectral methods meet em: A provably optimal algorithm for crowdsourcing", "author": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"], "venue": "Advances in neural information processing systems", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Heart disease data set", "author": ["A. Janosi", "W. Steinbrunn", "M. Pfisterer", "R. Detrano"], "venue": "https://archive.ics.uci.edu/ml/datasets/Heart+Disease", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1988}, {"title": "Saberlda: Sparsity-aware learning of topic models on gpus", "author": ["K. Li", "J. Chen", "W. Chen", "J. Zhu"], "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems (ASP- LOS), pp. 497509", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2017}, {"title": "M", "author": ["M.J. Wainwright"], "venue": "I. Jordan et al., Graphical models, exponential families, and variational inference, Foundations and Trends R in Machine Learning, vol. 1, no. 12, pp. 1305", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}, {"title": "Latent dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "Journal of machine Learning research, vol. 3, no. Jan, pp. 9931022", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 93, "endOffset": 96}, {"referenceID": 1, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 103, "endOffset": 106}, {"referenceID": 3, "context": "Recently, crowdsourcing has become a cheap and efficient way to make large training datasets [1], [2], [3], [4].", "startOffset": 108, "endOffset": 111}, {"referenceID": 4, "context": "Online platforms such as Crowdflower and Amazon Mechanical Turk can split large dataset into small parts and distribute these small labeling tasks to workers [5].", "startOffset": 158, "endOffset": 161}, {"referenceID": 5, "context": "In most cases, it has significantly better performance than single workers [6], [7].", "startOffset": 75, "endOffset": 78}, {"referenceID": 6, "context": "In most cases, it has significantly better performance than single workers [6], [7].", "startOffset": 80, "endOffset": 83}, {"referenceID": 7, "context": "Dawid and Skene [8] associated each worker with a confusion matrix which can evaluate the reliabilities and potential biases of the workers.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 106, "endOffset": 109}, {"referenceID": 8, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 111, "endOffset": 114}, {"referenceID": 9, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 122, "endOffset": 126}, {"referenceID": 10, "context": "In recent years, there are many works which also use confusion matrices to build label aggregation models [9], [9], [10], [10], [11].", "startOffset": 128, "endOffset": 132}, {"referenceID": 8, "context": "[9] proposed the two two-coin model for binary labeling tasks, which can be seen as a variation of the confusion matrix.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "In Minimax Conditional Entropy (MMCE) [6], each worker-item pair is related to a independent distribution.", "startOffset": 38, "endOffset": 41}, {"referenceID": 9, "context": "Kim and Ghahramani [10] used the confusion matrix to define their Bayesian Classifier Combination (BCC) model which is a Bayesian extension of Dawid and Skene\u2019s method.", "startOffset": 19, "endOffset": 23}, {"referenceID": 11, "context": "[12] extended the BCC model and proposed the CommunityBCC model, which groups workers into communities.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] also proposed a graphical model based approach for crowdsourcing.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "Zhou and He [14] proposed a approach which based on tensor augmentation and completion for crowdsourcing.", "startOffset": 12, "endOffset": 16}, {"referenceID": 4, "context": "The GLAD model [5] is based on parameters which represent the expertise of workers and difficulties of items.", "startOffset": 15, "endOffset": 18}, {"referenceID": 14, "context": "[15] also used a single parameter to describe the reliability of a worker.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] trained a deep neural network for label aggregation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] put different weights on workers in their model.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "In recent years, Multi-Armed Bandits based method [18] has been proposed for crowdsourcing.", "startOffset": 50, "endOffset": 54}, {"referenceID": 18, "context": "Recent years, there are several works have extended this method [19], [20].", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "Recent years, there are several works have extended this method [19], [20].", "startOffset": 70, "endOffset": 74}, {"referenceID": 7, "context": "Methods Dawid and Skene\u2019s method [8] associates each worker k with a probabilistic confusion matrix \u03c6.", "startOffset": 33, "endOffset": 36}, {"referenceID": 8, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 36, "endOffset": 40}, {"referenceID": 14, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 42, "endOffset": 46}, {"referenceID": 20, "context": "Recently, there are many works [9], [10], [15], [21] use this kind of confusion matrix to evaluate the ability of a worker, and build their own models.", "startOffset": 48, "endOffset": 52}, {"referenceID": 9, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 68, "endOffset": 72}, {"referenceID": 7, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 79, "endOffset": 82}, {"referenceID": 18, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "Parameter Initialization In many crowdsourcing methods, such as BCC [10], DSEM [8], CrowdSVM [19], and DiagCov [13], the unknown true labels are initialized by majority voting to avoid bad local optima.", "startOffset": 111, "endOffset": 115}, {"referenceID": 4, "context": "This idea is inspired by GLAD [5] which can simultaneously infer the true labels of items, the abilities of workers and the difficulties of items.", "startOffset": 30, "endOffset": 33}, {"referenceID": 21, "context": "We got the heart disease instances [22] and the corresponding ground truth labels from the UC Irvine machine learning repository website.", "startOffset": 35, "endOffset": 39}, {"referenceID": 5, "context": "TheWeb Search [6] dataset is about web search relevance judgment.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "RTE [7] contains 8000 binary labels for 800 documents.", "startOffset": 4, "endOffset": 7}, {"referenceID": 7, "context": "DS-EM [8] is a classic generative approach.", "startOffset": 6, "endOffset": 9}, {"referenceID": 9, "context": "We implemented the method according to Kim\u2019s paper [10] which uses Gibbs sampling and rejection sampling to infer the unknown model parameters.", "startOffset": 51, "endOffset": 55}, {"referenceID": 22, "context": "Fortunately, in recently GPU has been used to accelerate sampling [23].", "startOffset": 66, "endOffset": 70}, {"referenceID": 23, "context": "We also can use variational inference [24], [25] to solve the problem of scalability.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "We also can use variational inference [24], [25] to solve the problem of scalability.", "startOffset": 44, "endOffset": 48}], "year": 2017, "abstractText": "A large amount of labeled data is required for supervised learning. However, labeling by domain experts is expensive and time-consuming. A low cost and high efficiency way to obtain large training datasets is to aggregate noisy labels collected from non-professional crowds. Prior works have proposed confusion matrices to evaluate the reliability of workers. In this paper, we redefine the structure of the confusion matrices and propose two Bayesian Network based methods which utilize item difficulty in label aggregation. We assume that labels are generated by a probability distribution over confusion matrices, item difficulties, labels and true labels. We use Markov chain Monte Carlo method to generate samples from the posterior distribution of model parameters and then infer the results. To avoid bad local optima, we design a method to preliminarily predict the difficulty of each item and initialize the model parameters. We also introduce how to improve the scalability of our model. Empirical results show that our methods consistently outperform state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}