{"id": "1707.05228", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2017", "title": "Object Tracking based on Quantum Particle Swarm Optimization", "abstract": "in computer vision domain, moving object pixel tracking considered as one of the toughest problem. as there so many factors associated like natural illumination of light, buzzing noise, occlusion, sudden start and frequent stop suppression of moving object, shading which nearly makes tracking even harder tricky problem not only for computing dynamic background but also worse for finding static background. in this scientific paper we present a new object tracking algorithm based on dominant points on tracked object using quantum particle magnetic swarm optimization ( simply qpso ) which is a completely new different version of pso based on fuzzy quantum theory. the novelty in our approach is that it can be successfully applicable in variable background as well as static background and application of quantum pso makes the algorithm they runs lot faster where other basic pso algorithm failed to do so due to heavy computation. in our approach firstly dominants points of tracked objects detected, then a group of interacting particles form - a swarm are initialized randomly over the image search space and then start searching the curvature connected distances between two consecutive dominant points until they also satisfy fitness criteria. obviously it is a multi - swarm approach as there frequently are each multiple dominant points, as suddenly they moves, the curvature moves and the curvature object movement is tracked by the swarm throughout the video and, eventually when the swarm reaches optimal solution, a bounding box drawn based on variable particles final position. experimental results independently demonstrate this proposed qpso based method work efficiently and effectively in visual object tracking in both dynamic and static environments data and run time shows that it runs closely 90 % faster than basic normal pso. in our approach we also apply parallelism using matlab parfor command to show how very less computational number of iteration and swarm loop size will naturally enable us to successfully track object.", "histories": [["v1", "Wed, 24 May 2017 10:29:45 GMT  (1700kb)", "http://arxiv.org/abs/1707.05228v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["rajesh misra", "kumar s ray"], "accepted": false, "id": "1707.05228"}, "pdf": {"name": "1707.05228.pdf", "metadata": {"source": "CRF", "title": "Object Tracking based on Quantum Particle Swarm Optimization", "authors": ["Rajesh Misra", "Kumar S. Ray"], "emails": ["rajeshmisra.85@gmail.com", "ksray@isical.ac.in"], "sections": [{"heading": null, "text": "toughest problem. As there so many factors associated like illumination of light, noise, occlusion, sudden start and stop of moving object, shading which makes tracking even harder problem not only for dynamic background but also for static background. In this paper we present a new object tracking algorithm based on Dominant points on tracked object using Quantum particle swarm optimization (QPSO) which is a new different version of PSO based on Quantum theory. The novelty in our approach is that it can be successfully applicable in variable background as well as static background and application of quantum PSO makes the algorithm runs lot faster where other basic PSO algorithm failed to do so due to heavy computation. In our approach firstly dominants points of tracked objects detected, then a group of particles form a swarm are initialized randomly over the image search space and then start searching the curvature connected between two consecutive dominant points until they satisfy fitness criteria. Obviously it is a Multi-Swarm approach as there are multiple dominant points, as they moves, the curvature moves and the curvature movement is tracked by the swarm throughout the video and eventually when the swarm reaches optimal solution , a bounding box drawn based on particles final position. Experimental results demonstrate this proposed QPSO based method work efficiently and effectively in visual object tracking in both dynamic and static environments and run time shows that it runs closely 90% faster than basic PSO.in our approach we also apply parallelism using MatLab \u2018Parfor\u2019 command to show how very less number of iteration and swarm size will enable us to successfully track object.\nKeywords \u2013 Variable background, Dominant Point, Lucas-Kanade method (KLT), Particle Swarm Optimization (PSO), Quantum Particle Swarm Optimization (QPSO), Multiswarm, Curvature, Parallelism.\nI. Introduction\nObject Tracking simply employs the idea of following an object as long as its movement can be captured by a camera in various environment like either camera is moving with the object(Variable Background) or Camera is static (Static Background).moving object detection and tracking pose a challenge in real world scenario like surveillance system, traffic monitoring, vehicle navigation etc. In many scenarios where background changes dynamically due to motion of camera, abrupt changes in speed of the tracked object, illuminating noise, occlusion creates tracking more challenging. Therefore tracking algorithms under such situation should be robust, flexible and adaptive and capable of real time execution.\nMoving object tracking is a more than a two decade problem, so many methods has been proposed with a certain degree of effectiveness. Considering bio inspired swarm based method as effective tools for object tracking draws extensive attention in past decades. Among other bio inspired method like Genetic Algorithm (GA), Particle Swarm Optimization (PSO) emerges real fast because of its efficient, robust and quick convergence. Some of the earlier work has been done on tracking using PSO successfully.\nParticle Swarm Optimization is applied by Zheng and Meng[14] on high dimensional feature space for searching optimal matching in Haar-Like features detected by a predefined classifier set. Xiaoqin Zhanget all in [15] calculates temporal continuity between two frames and use that information for swarm particle to fly and track that information. Vijay John, Emanuele Trucco, Spela Ivekovic [13] construct Human Body Model as a collection of truncated cones , numbering those cones and PSO cost function will check how well a pose matches with data taken from multiple camera. Multiple people tracking has been done by Chen Ching-Han and Yan Miao-Chun [11] where people body constructed by feature vector and histogram and PSO used that histogram information for its tracking purposes.Fakheredine Keyrouz shows in [6] use of multiple swarm for multiple parts of object tracking and those swarm will share information with each other to make tracking of object as a whole. Multiple object tracking also be done by Chen-Chien Hsu, Guo-Tang Dai [9] using PSO, there method is constructing a feature model using grey-level histogram and apply PSO particles to track the difference between grey level histogram information of consecutive frames in a video sequence. Bogdan Kwolek [5] represent an approach where object is represented by image template , after constructing a covariance matrix based on that, by using similarity measure PSO will keep track of the difference appeared during movement of the object with target template.\nAbove we discussed all those considerable contribution towards object tracking using PSO in various ways, but there are significantly less work has been done in object tracking using Quantum Particle Swarm Optimization (QPSO), Though this QPSO concept is not very old[17] developed by Sun, Jun, Bin Feng, and Wenbo Xu but still a decade gone, while we found Chen, Jinyin, Yi Zhen, and Dongyong Yang work [4] on object tracking but other than that not much work to mention.\nIn this paper we approach a new method for object tracking under different background scenario. The uniqueness of our algorithm lies on three factors,1) use of Dominant points 2) a singular algorithm applicable for static and variable background. 3) use of Quantum Particle Swarm Optimization method. None of the earlier work discussed above use dominant point as tracking tools except Prasad, Dilip K., and Michael S. Brown[4] uses dominant point for boundary contour and propose a time propagation method of those dominant points so that it can effectively detect deformation of object and track. Our method completely different than this approach, we calculate chain code, chose dominant points, determine the curvature between two dominant points, randomly define swarms and let the swarms track that curvatures from frame to frame.The use of quantum PSO helps us to reduce swarm size and number of iteration hugely, as a result our algorithm takes less time compare to other PSO approach.\nThis paper organized as follows. Section II discusses basic QPSO algorithm, Dominant Point and Optical Flow method. Section III cover detail approach of our proposed\nalgorithm. Section IV cover how we implement QPSO using parallelism and Section V gives experimental results and in Section VI we will discuss overall performance and comparison between PSO,QPSO and QPSO parallel algorithms and finally we draw conclusion.\nII. Quantum Particle Swarm Optimization\na. Particle Swarm Optimization\nIn 1995 James Kennedy and Russell Eberhart proposed an evolutionary algorithm that create a ripple in Bio-inspired algorithmic approach called Particle Swarm Optimization (PSO). In a simple term it is a method of optimization for continuous non-linear function. As this method influenced by swarming theory form biological world like fish schooling, bird swarming etc.\nPSO effectively applied to the problems in which each solution of that problem can be consider as a set of points in a solution space. Particle is the term associated to those set of points. Analogically suppose there is a food source and a swarm of birds tries to reach that food source. Every bird will try by its own to reach there and whomever is reached or nearly reached to that food source will share that information with other birds who are close neighbor, as a ripple in water that information will be flown among entire swarm of birds and every birds will synchronously update their velocity and position if they got better position in terms of nearest position to the food source .As a result after certain period of time entire swarm will eventually gather to the food source. Similarly every solution considered as particle will compute there value based on some cost function, until they satisfy certain criteria known as stopping condition, they will keep updating their velocity and position, if their neighbor got better solution.\nPosition and Velocity are two associated terms in Particle Swarm Optimization. Position of every particle is calculated by particle\u2019s own velocity. Let Xi (t) denote position of particle i in the search space at time t. position Updation formula is as follows \u2013\nXi (t + 1) = Xi (t) + Vi (t+1) (1)\nWhere\nVi (t+1) is the velocity of particle i at time (t+1), which will be computed\nbased on this following formula \u2013\nVi (t) = Vi (t-1) + C1 * R1 ( PLB(t) \u2013 Xi (t-1)) + C2 * R2 ( PGB (t) \u2013 Xi (t-1)) (2)\nWhere\nC1, C2 = Constants determine the relative influence on social and cognitive components, also known as learning rate, often set to same value to give each component equal weights.\nR1, R2 = random values associated with learning rate components to give more robustness.\nPLB = Particle Local Best position \u2013 it is the historically best position of the ith particle achieved so far\nPGB = Particle Global Best position \u2013 it is the historically best position of the entire swarm, basically position of a particle which achieve closest solution.\nEquation (2) is Kennedy and Eberhart\u2019s original idea, after that lot of different research has been going on, based on that one of the remarkable idea comes up by Shi and Eberhart [15] of addition of a new factor called \u201cinertia weight\u201d or \u201cw \u201c. After addition of inertia weight the eq. (2) becomes as follows \u2013\nVi (t) = w *Vi (t-1) + C1 * R1 (PLB(t) \u2013 Xi (t-1)) + C2 * R2 ( PGB (t) \u2013 Xi (t-1)) (3)\nThis inertia weight helps to balance local and global search abilities, small weight means local search and larger weight means global search.\nb. Quantum Behaved Particle Swarm Optimization :\nThe main disadvantageous factor of basic PSO algorithm is Convergence. It is not guaranteed that it will converge or not after certain number of iteration. There are many different approaches has been taken by different researcher like Hybrid PSO, Variable PSO, GA-based-PSO to tackle this issue. Quantum PSO is another such approach with a different angle which not only guarantee convergence but also assure its speediness over basic PSO.\nIn the quantum world the state of a particle is determined by its wave function\n\u03a8(x,t)instead of position and velocity because according to Heisenberg\u2019s \u201cUncertainty Principal\u201d we cannot determine position and velocity of a particle at the same time. We will calculate probability of particle position in x using probability density function\n|\u03a8(x,t)|2 . In Quantum time space framework the particle will move according to the following iteration introduced by Jun Sun et al.\nX(t+1) = Pi \u2013 \u03b2 * (mBest \u2013 Xt ) * ln ( 1/ u ) if K \u2265 0.5 (4)\nX(t+1) = Pi + \u03b2 * (mBest \u2013 Xt ) * ln ( 1/ u ) if K < 0.5 (5)\nWhere,\nPi = \u03c6 * pBesti + (1 \u2013 \u03c6) * gBest (6)\nN\nmBest = 1 / N \u2211pBesti (7) i=1\nin the formula (7) mBest is the current centre of all individual optimal location which is the mean best position of all the best position of the population. K , u , \u03c6 are random\nnumber distributed uniformly over the range [0,1]. \u03b2 is the only different parameter used in QPSO known as Contraction - Expansion coefficient. It will be used to control convergence speed by tuning its value. N is the population size. pBest and gBest aare same as basic PSO\u2019s PLB and PGB.\nWe can observe the difference between PSO and QPSO as QPSO introduce stochastic distribution of particle position. This exponential distribution makes the search space a real space covering whole solution space which increase the chances of optimality, besides introduction of mBest enhances the convergence possibility.\nQPSO algorithm\nPseudo code of the QPSO algorithm as follows \u2013\nProcedure QPSO For each particle\ninitialize particle Xiby randomizing them;\nEvaluate Xi ; pBesti = Xi ;"}, {"heading": "END", "text": "Do\nCompute gBest = Min or Max ( f(pBest)); Compute mBest by equation (7)\nFor each particle\nCalculate Pi using equation (6) Update Position Xi using equation (4 and 5) If f(Xi) < f ( pBesti ) pBesti = Xi ; ENDIF\nEndFOR\nUntil While maximum iterations or minimum error criteria is not attained\nc. Dominant Points\nF. Attneave observation [25] on information about shape and overall structure of any curve lies on those points having high curvature. Since then dominants points are considered as one of the significant candidate of object boundary detection because they hold important feature information about object contours. There are number of approaches has been offered by various researchers on efficient, successful detection of dominant points after Attneave\u2019s careful observation.\nAccording to Wu, Wen-Yen[18], A digital curve C consist of n consecutive points and can be written as follows \u2013\nC = { pi(xi, yi) | i = 1,2,3\u2026n}\npi is the ith point having coordinate values (xi, yi).\nAs Ray and Ray proposed k-Cosine value [22] as follows \u2013\n(aik.bik )\nCosik = ------------------ (8)\n|aik|. |bik |\nWhere vectoraik = (xi-k - xi,yi-k \u2013 yi), bik = ( xi+k \u2013 xi, yi+k \u2013 yi), .is the inner product operator. And | * | is the vector length. After calculating k-cosine values by above formula (3) of each boundary points the dominant points will be selected as those points having maximum k-cosine values. This k-cosine values is used to determine the length of the support region. Maximum length of the support value will give higher chance of the particle for selection of dominant points. We use Ray and Ray [22] method and Wu, Wen-Yen [18] method for dominant point selection which will be discussed in next section in detail.\nd. Optical Flow method\nAccording to Horn, Berthold KP [24], optical flow is \u201cdistribution of apparent velocities of movement of brightness patterns in an image\u201d, in other terms it is the change of the light in an image due to motion of camera sensors. A video can be thought of as a sequence of image frames, which can be constructed from spatial and temporal sampling of incoming light. Then optical flow can captures the light changes in these images using vector fields.an accurate, pixel wise estimation of optical flow gives correct position of pixels in consecutive image sequences.\nThere are different methods for determining optical flow like Horn\u2013Schunck method , Lucas -Kanade method. We use Lucas -Kanade optical flow method in this paper which is discussed next.\ne. Lucas -Kanade method optical flow method (KLT)\nThe basic optical flow problem is How to estimate the motion form one image frame to next one? Lucas- Kanade method assumes the motion of the pixels nearly constant in local neighborhood of the pixel under considerations. In mathematical form it will looks like as follows \u2013\nIx (q1) Vx+ Iy (q1) Vy = - It (q1)\nIx (q2) Vx+ Iy (q2) Vy = - It (q2)\n.\n.\nIx (qn) Vx+ Iy (qn) Vy = - It (qn)\nwhere q1 \u2026.qnare pixels inside the window, Ix(qi),Iy(qi),It(qi) partial derivatives of\nthe image I with respect to position x, y and time t, evaluated at the point qi at the current time.\nThis formula can be written as matrix form Av = b\nIx(q1) Iy(q1)\nA = Ix(q2) Iy(q2) Vx - It(q1). .\nv = b = - It(q2)\n. . vy . Ix(qn) Iy(qn) - It(qn)\nThis mathematical system has more equation than unknown, Lucas-Kanade applies Least Square principle to solve this equation. As follows \u2013\nAT Av = ATb.\nThe matrix ATA is known as structure tensor of the image at a certain point.\nIII. QPSO Based Tracking Approach\nA. General Idea\nWe begin our tracking process by first calculating dominant points of object. As dominant points hold the highest curvature values of the object so selection of dominant points will definitely be a critical task. in our approach we took a random number which will guide how many dominant points will be selected from the object body and for calculating dominant points we follow [22][18]] approach.\nAfter we find required number of dominant points we create a swarm of random particle by using (1) and (2). Those swarm will find its closest curvature that will connected by two consecutive dominant points, as per tracking purpose those swarm will track their curvature as long as object moves. From frame to frame those dominant points are tracked by Lucas \u2013Kanade ( KLT) optical flow algorithm. So every time a new frame appears old dominant points change their position and new position will be calculated by KLT method and this new-position curvature will again tracked by QPSO algorithm.\nAs we can see there are multiple curvature of a single object body, and each one tracked by an individual swarm so there will be multiple swarm for object tracking. In each frame once the QPSO successfully finds all curvature connected by dominant points, we will create a bounding box around the moving object. For creation of that bounding box we didn\u2019t follow any predefined bonding box algorithm rather we formulate our own algorithm which will suite our QPSO based method most.\nB. Dominant Point selection\nOn Dominant point detection we first perform contour tracking of the target object body to find the Chain Code. For that purpose we use Freeman Chain Code. Freeman Chain code gives us list of pixels around object body. Among those pixels we eliminate linear points, as those points does not provide us any significant curvature information. For elimination of linear points we follow the following rule \u2013\nIf Ci-1 = Ci then point Pi is linear point. (9)\nWhere Ci-1 is previous chain code value and Ci is current one on point Pi .\nAfter excluding those linear points rest of the points are called breakpoints, which are candidates for dominant points. We have to consider region of supports of only those breakpoints. Now we need to calculate length of support of each breakpoints. Rather considering all breakpoints at once we group them as a group of 10 for Variable background and group of 5 for static background. The number of breakpoints in a group will be decided based on which background we perform our tracking, normally on variable background object shape change fast for that we need our curvature of the object body smaller such that more breakpoints are close to each other that\u2019s why we chose high number of breakpoints, comparatively in static background as the object is more stable we can use much longer curvature so less number of breakpoints will suffice for dominant point calculation.\nFor each group of breakpoints we calculate k-Cosine values of each of them and apply following rule \u2013\nStart with k =1 form group. Increase value of k by 1 until we reach all\nbreakpoints on this group. ki = k if cosik = max { cosij | j= Kmin \u2026\u2026\u2026 Kmax } for j = 1 , 2, \u2026n (10)\nWe chose dominant point as those points which are max k \u2013Cosine values.\nDi = max { cos(pi)} (11)\nWhole procedure for calculating dominant points are as follows \u2013\nStep 1: Use Freeman Chain Code for performing couture tracking, get those pixels store them in a file.\nStep 2: Eliminate linear points by following rule (9) form those stored pixels. Save them in a file called breakpoints\nStep 3: Perform K \u2013Cosine for each of the breakpoints by following rule (10).\nStep 4: Select those points as dominant points which has max k-cosine values called Dominant point set.\nC. Dominant point tracking by KLT method\nThe main advantage of dominant point is that they hold most curvature information which hardly changes if the environment changes, rather calculating dominant point every time on a new image frame it is always better if we can track those dominant points form frame to frame. For tracking those dominant point we apply optical Flow the method.\nAs earlier we discussed Lucas-Kanade Optical method which quite a useful\napproach for tracking any point in dynamic background. We run KLT method for each Dominant points and store their position (Xi,Yi) in separate table. So every time a new image frame comes, KLT algorithm gives us the new probable position.\nD. Curvature tracking by QPSO.\nWhat we assume as a curvature is that the path between two consecutive dominant points. As we know dominant points are boundary points so curvature connecting two dominant points gives us the object boundary curve. Now using QPSO we are going to track that curvature.\ni) Setting QPSO parameters and Initialization\nBecause of dynamic nature setting QPSO parameters to right value is a crucial task.\n Multiswarm \u2013 our approach is based on multiple swarms and the number of\nswarm will be decided by how many dominant points we are considering. if\nwe have D number of dominant points and each curvature will be represented\nby 2 dominant points then there will be \u2013\nnumber of curvature (C) = D/2\nas each curvature is tracked by each swarm then there will be C swarms. It is worth considering that this is the maximum value of swarms we started with, as the procedure goes on it may be possible that some swarm may lost tracking because dominant points are not tracked by KLT method which is inherent problems in optiocal flow method. So latter no of swarm may reduce which will not affect much in our approach. as per our exoeriment we obseve that probably 10% of swarm may lost their path. So we can conclude that \u2013\n10% of C <= no. of swarm <= C\n Swarm size- Here we have huge improvement over basic PSO. We initialize\nswarm size through some trial and error process and we conclude that for\nstatic background swarm size =7 and for variable background that will be 10,\nthis are approximated values so if we set swarm size near about10 (for both\nstatic and dynamic environment) this algorithm works at its best. We can\neasily observe that we need very less number of particle in a swarm. It is\nobvious that more particles in a swarm means more computation and also\nless particle means divergence of tracked object, so we need to keep the\nswarm size optimum which is depend on different application. In our case it is\ndepends on the length of the curvature, the long is the curvature the more\nparticle we need to track that curvature successfully, but as far QPSO\nconcerned we don\u2019t need high number of particle in a single swarm. Our\nexperimental shows how very less number of particle do the job.\n Position initialization \u2013As ofQPSO methodology we need to initialize the\nposition of every particle of the swarm. This position of particle for each\nswarm will be inside the search space and randomly defined. In our case we\nfirst calculate the X and Y length of the image which is basically the\ndimension of the target image. Position of each particle is defined randomly\non the [X,Y] range for each image frame.\n Local best value of Particle i (pBesti )\u2013 local best value of an individual\nparticle in a swarm indicates its current best position it achieved in\nconvergence with the target curvature. We initialize each particle Plbest\nvalue with its current position. Latter it will be modified according to the\nupdating rule.\n Global best value of Particle i (gBest ) \u2013 In a particular swarm, the particle\nwhich hold the best position such as closest to the curvature boundary\nconsidered as global particle and its position is gBest. each particle first compute the perpendicular distance from the curvature connected by\ndominant points, the particle which hold minimum distance considered as\ngBbest\ngBest = { min ( distance(XD1,YD1,Xi,Yi,XD2,YD2))} Where (XD1,YD1) is the position of the 1st dominant point and (XD2,YD2) position of the 2nd dominant point.\n mBest computation\u2013we will compute mBest according to the formula (7)\nonce we completed our pBest and gBest calculation.\n \u03c6 ,\u03b2, u , k values initialization \u2013earlier we define the meaning of this\ntermson equation [4-6], all those variables values are randomly distributed\nin range [0-1].\n Position Updation \u2013 particles position will be updated based on formula (4)\nand (5). If random value of k is greater than 0.5 then we will apply formula\n(4) else position will be calculated based on formula (5). Our computation\nreduced as there is no velocity concerned in QPSO.\nII) Curvature Computation \u2013\nIn this paper we construct the curvature based on dominant points. Let\nconsider two dominant points are D1 and D2 calculated using formula (11). The curvature between this two points will be the curve joining this two\npoints. There could be infinitely many curve that will pass through this two\npoints, but in this paper we consider Euclidean Distances between this two\npoints.\nIn Cartesian coordinate, D1 (X1,Y1) and D2(X2,Y2) are the two points in Euclidian space, the distance between this two points will be calculated based\non Pythagorean formula as follows \u2013\nD1D2 =\u221a( X2- X1 ) 2 + (Y2 \u2013 Y1) 2 (12)\nUsing a random curve we can show as follows \u2013\nD1\nD2\nL1 C\nD3 L2\nD4\nL3\nFigure \u2013 1\nIn the above figure (1) , we draw a curve C , which contains dominant points like D1,D2, D3, D4, line L1, L2 and L3 passing through D1D2 , D2D3 and D3D4 respectively.Though it is not exactly the curve connecting dominant points D1D2 , D2D3or D3D4 but as figure shows it serves the purpose of identifying approximate object boundary. As we are not detecting or tracking exact object body curvature, we are focusing only moving area of target so inexact curvature of the boundary not so serious threat for tracking. As it is always acceptable if we can find exact curvature which is another research area of couture tracking, not the main focus area in this paper.\nIII) Fitness Function\nEvery QPSO model based on some cost function, each particle of the swarm will compute that fitness function in each iteration to confirm whether they converge to the final solution or not. In this paper, our cost function is perpendicular distance of the particle i to the curvature under tracking\nFigure \u2013 2\nBorrowing our earlier figure (1), we draw figure (2), here there is a particle P1 and the curvature is line L1. We are computing the perpendicular distance from the point P1 to the line L1.\nAs L1 passes through two dominant points D1(X1,Y1) and D2(X2,Y2) then the distance from the point P1(X0, Y0) is \u2013\n| (Y2 \u2013 Y1) * X0 \u2013 (X2 \u2013 X1) * Y0 + X2 * Y1 \u2013 Y2 * X1 |\nPerDist (D1,D2,P1) = ----------------------------------------------------------------------- (13)\n\u221a(Y2 \u2013 Y1)2 + (X2 \u2013 X1)2\nThe denominator is the length of D1 and D2. Numerator is the twice the area of triangle with its vertices at 3 points D1, D2, P1.\n. P1 D1\nD2\nL1\nD3\nD4\nEvery particle will compute this perpendicular distance with curvature and if the distance is in the acceptable range iteration stops else this procedure continues. We summaries algorithm for cost computation as follows \u2013\nProcedure FitnessComputeQPSO (Particle set)\nfor each particle Pi\nCompute PerDist (D1,D2,Pi) if PerDist (D1,D2,Pi)< acceptable range particle Pi accepted\nend for\nendFitnessComputeQPSO\nIV) New pBest , gBest Updation and re-initialization\nUntil all the particle inside a swarm are successfully converged on the curvature they keep updating their position using formula (4) and (6). gBest and pBbest will be updated as \u2013\nNew_gBest (Pi) = {min (PerDist (D1,D2,Pi)) for all particle i } (14)\nNew_pBest (Pi) = (PerDist (D1,D2,Pi) if (PerDist (D1,D2,Pi)< previous (PerDist\n(D1,D2,Pi)\nprevious (PerDist (D1,D2,Pi) (15)\nReinitailization is sometime required as it is inherent nature of QPSO that sometime particles are too diverge that several updation may not bring them toward their goal, in our case it is also possible that some particle are too far away from curvature boundary and after a finite number of iteration they still unable to converge then we need to reinitialize those particle. Reinitializing particles over entire image space certainly feasible but not a practical idea, because it again may diverge, so we have a better possibility to converge if we assign the position randomly over the range of two particle\u2019s position which has the best position so far. mathematically we can write as \u2013\nPos_x(Pi) = rand(pos_x(Pi-1) , pos_x(Pi+1) (16) Pos_y(Pi) = rand(pos_y(Pi-1) , pos_y(Pi+1) (17)\nWhere rand () is a random number generator function, Pos_x(Pi-1) is the x direction coordinate of the particle Pi-1, it may be possible that this exactly earlier particle of Pi may not be best particle they we have to move Pi-2 and so on until we find best particle. Similarly pos_x(Pi+1) is X- direction position of particle Pi+1.\nE. Bounding Box formulation\nTo identify tracked target object usually a rectangle bounded box utilized. There are some pre defined algorithm exist for that purpose, but here we design our own bounded box based on QPSO particle position which will best suite our target tracking.\nThe main idea is whenever all particle in all swarm successfully converge for a particular image frame we find p number of particles which has smallest X \u2013 direction and smallest Y-Direction, those particle are close to (0,0) in our image space. This p value could be first 10 smallest particle, though it is entirely depends on application but as per our experiment goes it will be effective if we take first [10 \u2013 20] smallest X,Y direction particles. Now take an average of those p- points, which will be our starting point for bounding box formation.\nLet consider that particle is q,\nq = ceil [ { p1 +p2 + p3 \u2026\u2026\u2026.pp-1 + pp } / p ] (19)\nFigure - 3\nThis straight line shows we are taking average and point q is on the line. Now\nonce we got the starting point (q) now we have to calculate length and breadth of the box. Length and breadth will be calculated as follows \u2013\nLength (L) = { li | all li are min(x- direction) and max (y- direction) } for i =\n1,2,3\u2026p\n= { (l1 + l2 +l3 + \u2026\u2026\u2026.. lp ) / p\n(20)\nBreadth (B) = { bi | all bi are min( y-direction) and max( x- direction) } for\ni=1,2,3\u2026p\n= { (b1 +b2 +b3 + \u2026\u2026bp) /p }\n(21)\nSo as now we got all 3 parameters we can draw the box as \u2013\n.P1 X\n.P2\n.P5 .P3\nY P4\n.q(xq,yq) .qb(xq+breadth,yq)\n.ql(xq,yq+length) qlb(xq+breadth,yq+length)\nFigure \u2013 4\nAs per figure (4) q is the starting point calculated using formula (14) and once we\ngot L and B from formula (15) and (16) we can construct the box as \u2013\nq = (xq,yq)\nql = (xq,yq+length) four boundary position formula (22) qb = (xq+breadth,yq) qlb = (xq+breadth,yq+length)\nF. Algorithmic summary\nIf we summaries as a whole the QPSO object tracking algorithm that will be as following \u2013\nProcedure ObjectTrackingQPSO\nbrpts \u2190 calculate Breakpoints of target objects. dompts \u2190 eliminate linear points and find dominant points using rule (6) and(7) nSwarm \u2190 number of swarms ss \u2190 define swarm size. for swarm \u2190 1 to nSwarm\nfor pi to ss\nInitialize particles position. Initialize pBest and gBest. Compute Procedure FitnessComputeQPSO\nend for\nend for perform Bounding box calculation\nend Procedure ObjectTrackingQPSO\nIV. Implementing QPSO in parallel environment :\nOne of the major feature in QPSO or PSO based approach is that if we can implement our algorithm in such a way that multiple swarms can run simultaneously then it will give a lot better results in terms of run time. Running parallel is inherent nature of PSO/ QPSO based algorithm. But implementing parallel environment is quite hard in sequential machine unless our code framework support that, fortunately MatLab do that.\nMatLab has a special command for parallel run environment called \u201cparfor\u201d, it is parallel implementation of \u201cfor\u201d loop. By default \u201cParfor\u201d will create 4 workers and distribute all its computation inside the loop into this 4 workers.so entire computation will be divided into 4 parts and each one will take 1/4rth parts of it, as a result its execution time is lot faster. But we have to remember here that whatever\ncomputation we have inside the loop must be independent, otherwise \u201cParfor\u201d will not work.\nIn our work, we also make our code independent so that we can implement \u201cParfor\u201d to create the parallel environment. Making entire code independent is rigours and unnecessary work, we only perform following work parallel \u2013\n1. Fitness computation\n2. Pi computation (Formula \u2013 6) 3. Position computation (formula \u2013 4,5)\nIn algorithmic structure it will look like this \u2013\nProcedure QPSO_Parallel ( nSwarm) Begin\nParfor 1 to nSwarm\nProcedure FitnessComputePSO(); Pi computation based on pBest and gBest; Position computation based on k values.;\nEnd Parfor\nEnd\nV. Experimental Result\nThe proposed algorithm for object tracking based on QPSO on different background is simulated by MatLab 2015a on a 64 bit PC with Intel i5 processor with 3 GHz speed. The image size of the frame 180 X 144. Static video is 20 sec duration whereas variable background is 13 sec duration.\nAll the experimental dataset has been taken form benchmark library created by Yi Wu, Member, IEEE, Jongwoo Lim, Member, IEEE, and Ming-Hsuan Yang, Senior Member, IEEE[1] work which will be available on http://pami.visual-tracking.net.\nWe first take frames from the video and store them in a separate location then use each frame in our algorithm for tracking.\nStatic background\nOur first experiment is on example 1 static background. In figure (5) a single person is coming towards the camera. Which multiple swarm successfully track that person and figure (6) shows same person with bounding box which is our own designed algorithm Consecutive figure shows how that person comes more and more close to the camera our algorithm successfully track that person.\nExample 1:\nFigure \u2013 5 Figure - 6\nFigure \u2013 7 Figure - 8\nFigure \u2013 9 Figure - 10\nFigure \u2013 11 Figure \u2013 12\nFigure (5) - (12) shows a sequence of frames of a single person moving towards a camera where background is static. All left side figure shows how swarms particles successfully track the figure as it moves .and all right side figure shows when we draw a bounding box using our QPSO based algorithm.\nExample 2:\nFigure \u2013 13 Figure \u2013 14\nFigure \u2013 15 Figure - 16\nFigure \u2013 17 Figure \u2013 18\nFigure \u2013 19 Figure \u2013 20\nFrom figure- (13) \u2013 (20) A girl face is moving left and right, and back and forth , our algorithm successfully track the movement\nExample -3\nFigure -21 Figure- 22\nFigure -24\nFigure -23\nFigure -25 Figure -26\nFigure -27 Figure -28\nFrom figure- (21) \u2013 (28) A lady walking on a campus when she is obstructed by another man, or algorithm successfully track the lady during occlusion.\nVariable Background\nNow we experiment our algorithm on a video where background is moving with object, video is taken by a moving camera. Here we can see 3 persons moving from left to right with the camera, as two persons are very close to each other they are considered as a single tracking object, if one person moves far from another PSO will leave that person and focus on only that person who is under tracking, but if from beginning two separate persons are under tracking then if two person moves far from one another our algorithm will successfully track both the persons.\nExample 1:\nFigure \u2013 29 Figure - 30\nFigure \u2013 31 Figure \u2013 32\nFigure -33 Figure -34\nFigure \u2013 35 Figure \u2013 36\nForm figure \u2013 (29) to (36) we are showing from left side swarms are successfully track the middle person on figure (29), and on right side we can see the same person is tracked on bounding box. Here we are tracking single person on not all three persons, they are comes inside the box due to their relative speed of movement. If we want to track them also it is possible by our algorithm.\nExample 2:\nFigure \u2013 37 Figure -38\nFigure -39 Figure -40\nFigure -43 Figure 44\nForm figure \u2013 (37) to (44) we are showing from left side swarms are successfully track the left jogger, where background is continuously changing and on right side we can see the same person is tracked on bounding box. Here traffic light post work as an occlusion, but out method able to track during occlusion.\nExample \u2013 3\nFigure -45 Figure -46\nFigure - 47 Figure \u2013 48\nFigure -49 Figure -50\nFigure \u2013 51 Figure -52\nForm figure \u2013 (45) to (52) this dynamic background video show a moving SUV car moving fast first then slow down when another car going to cross and den again slow down during traffic signal. The white SUV successfully tracked by our algorithm during all kind of movement.\nVI. Overall Performance\nA. Performance comparison between basic PSO, Quantum PSO and Quantum PSO\nin parallel framework of our proposed algorithm. -\nBefore going through all our test dataset and all respective results we specifically want to mention that we mainly focus on following parameters during test runs about performance analysis.\n1. Iteration\n2. Swarm size\n3. Run time\nTable \u2013 1: Comparison results obtained by PSO, Quantum PSO, and Quantum PSO in parallel for static Background in 3 different test file.\nTest Environment Test Data file\nTest Parameters Basic PSO particle run time Basic PSO box run time QPSO particle run time QPSO box run time\nQPSO_Para particle run time QPSO_Para box run time\nStatic Background\nRailway walking man.avi Swarm Size 25 25 15 15 7 7\nIteration 1000 1000 100 100 5 5 Runtime 1260 sec 1221 sec 1160 sec 34 sec 1262 sec 1149 sec\nGirl face moving.avi Swarm Size 25 25 15 15 7 7\nIteration 1000 1000 100 100 5 5 Runtime 4662 sec 4431 sec 3663 sec 483 Sec 4561 sec 4552 sec\nLady waking on campus.avi Swarm Size 25 25 15 15 7 7\nIteration 1000 1000 85 85 7 7 Runtime 3389 sec 3443 sec 3300 sec 289 sec 3210 sec 3110 sec\nStatic Background Environment\nThe above table shows we perform test runs on a static background environment where we took 3 different .avi file. 4rth column shows basic PSO run time when only Swarm particles are marked on images like figure- 5 and next column shows same basic PSO run time when we formed a bounding box using our Bounding Box algorithm. Like figure -6. Next onwards columns are QPSO particle and box run time and QPSO particle and box run time when we use \u201cParfor\u201d command for parallel framework. The above table shows when basic PSO took almost 21 minutes to run, Quantum PSO took 19 min for particle mapping but took 34 sec for bounding box design. Now if we consider Quantum PSO in parallel, its performance close to basic PSO but number of iteration and Swarm sizes are very less. The reason behind this the overhead for creating 4 workers is high then the computation inside the loop.so as a results its busy in doing overhead work rather than actual computation.\nIf we observe other two results QPSO gives so far the best performance results in bounding box designing which is our own designed algorithm. QPSO gives close to 96% performance improvement over basic PSO. Following graphs shows our performance improvement results.\nFigure \u2013 53: performance comparison graph over basic PSO, Quantum PSO\nand Quantum PSO in parallel on Railway_Walking_man.avi video sequence.\nIn figure -53 graph in X- direction we have frame sequence and in Y- Direction we have Execution times. It is clearly observed that QPSO by far gives the best execution time result where other two increases their times proportionally with frame sequences. The above graph only shows one experiment graph(Railway_Walking_man.avi), others also gives quite same results, we intentionally keep aside creating same kind graph repeatedly, this above is more generalized performance graph on static background environment.\n0\n200\n400\n600\n800\n1000\n1200\n1400\n10 20 30 40 50 60 70 80 90 100 110 120 130 140 150\nEx e\ncu ti\no n\nT im\ne s\n(s e\ncs )\nFrame Sequence\nRailway Walking man\nQPSO_execution time QPSO_Para_execution time Basic _execution time\nTable \u2013 2: Comparison results obtained by PSO, Quantum PSO, and Quantum PSO in parallel\nfor dynamic Background in 3 different test file.\nDynamic Background Environment\nTable -2 is in same format like table -1 but it is for those test files which works on dynamic environment.\nWe can observe that QPSO parallel took very less number of iteration and swarm size (10 iteration and 5-8 number of particles in a single swarm) again like static background, and QPSO gives better results again in terms of run times in comparison with others.\nTest Environment Test Data file\nTest Parameters Basic PSO particle run time Basic PSO box run time QPSO particle run time QPSO box run time QPSO_Para particle run time QPSO_Para box run time\nDynamic Background\nThree people walking.avi Swarm Size 35 35 20 20 10 10\nIteration 2000 2000 150 150 8 8 Runtime 8445 sec 8223 sec 7828 sec 890 sec 8210 sec 8093 sec\nJogging.avi Swarm Size 35 35 20 20 10 10\nIteration 2000 2000 120 120 8 8 Runtime 7656 sec 7234 sec 6829 sec 561 sec 6892 sec 6726 sec\nwhite car moving on traffic signal.avi Swarm Size 35 35 20 20 10 10\nIteration 1600 1600 150 150 5 5 Runtime 8239 sec 8120 sec 5929 sec 536 sec 7889 sec 7656 sec\nFigure \u2013 53: performance comparison graph over basic PSO, Quantum PSO and Quantum PSO in parallel on three_walking_people.avi video sequence.-\nSame as earlier graph in figure-52, in dynamic framework number of frame sequence is higher than static one, as a result execution times takes longer time but it is evident from the above graph that QPSO gives us the far better result in object tracking in variable changing background.\nB. Comparison in Multicore CPU Utilization for basic PSO, QPSO and QPSO\nparallel.\nWe also perform another comparison in terms of CPU utilization and Multicore utilization. The reason behind is that as we are using parallel framework our objective should be utilization of multicore and distribution of computation in all cores. We also want to observe how we can put more pressure on CPU and makes full utilization of CPY cycles.\nWe did this by opening task manager in our Windows \u2013 7 64 bit operating system which installed in Intel Core i5 processor which works on 3.00GHz speed, it has 4 cores, all are utilized. Following figures shows how CPU are stressed and achieve their maximum performance and how all cores are properly used.\nIn following figure -54 we have seen CPU achieve 71% performance and first two cores are used core number 3 achieve much less performance during basic PSO run. In figure -55 during QPSO run CPU achieve 75% utilization with 3rd core shows good improvement over basic PSO and in figure \u2013 56 during QPSO in parallel run CPU achieve 88% performance with all cores are almost equally utilized, QPSO in parallel shows best CPU performance so far we tested.\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0\n1 0\n0\n1 1\n0\n1 2\n0\n1 3\n0\n1 4\n0\n1 5\n0\n1 6\n0\n1 7\n0\n1 8\n0\n1 9\n0\n2 0\n0\n2 1\n0\n2 2\n0\n2 3\n0\n2 4\n0\n2 5\n0\n2 6\n0\n2 7\n0\n2 8\n0\n2 9\n0\n3 0\n0\n3 1\n0\n3 2\n0\nEx e\ncu ti\no n\nt im\ne s\n(S e\ncs )\nFrame sequence\nThree Walking People\nQPSO_execution time QPSO_Para_execution time Basic _execution time\nFigure \u2013 54: CPU and Core Utilization during Basic PSO algorithm run\nFigure \u2013 55: CPU and Core Utilization during Quantum PSO algorithm run\nFigure \u2013 56: CPU and Core Utilization during Quantum PSO in Parallel algorithm run\nVII. Conclusion and Future Work\nHere in this paper we proposed a novel approach for object tracking by QPSO on both static and dynamic environment. The basic mechanism of this algorithm is introduced and proof of this approach is also provided by various experimental results. we also shows performance measurement on 3 different mechanism PSO, QPSO and QPSO-inparallel. As we earlier discussed the uniqueness of this method is few things \u2013 I) Successful application of Dominant points in tracking purpose II) a unified approach for applying a singular algorithm in both the environment III) we achieve 95% faster method by applying QPSO approach over basic PSO. Our experimental results show how effectively our algorithm track objects throughout video frames and perform faster tracking.\nWe still can improve this method on various fine tuning grounds. They are like 1) we can fine tune QPSO parameters like \u03c6 ,\u03b2 , u , k, mBest, more careful investigation will give us more accurate boundary tracking as well as bounding box designing. 2) curvature designing , we are initially assumes our curvature as a Euclidean Distance or considering a straight line, rather considering this if we fit B-Spline like curve which give us accuracy in curvature then our method will became more strong and provide more accurate boundary tracking. QPSO in parallel framework can be improved by including more CPU intensive computation inside \u201cParfor\u201d loop which gives better result in tracking.\nReference\n[1].Li, Yangyang, et al. \"A Novel Distributed Quantum-Behaved Particle Swarm Optimization.\" Journal of Optimization 2017 (2017).\n[2]. Wu, Yi, Jongwoo Lim, and Ming-Hsuan Yang. \"Object tracking benchmark.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 37.9 (2015)\n[3]. Henriques, Jo\u00e3o F., et al. \"High-speed tracking with kernelized correlation filters.\" IEEE Transactions on Pattern Analysis and Machine Intelligence37.3 (2015)\n[4]. Chen, Jinyin, Yi Zhen, and Dongyong Yang. \"Fast Moving Object Tracking Algorithm based on Hybrid Quantum PSO.\" target 2 (2014)\n[5]. Kwolek, Bogdan. \"Multi-object tracking using particle swarm optimization on target interactions.\" Advances in Heuristic Signal Processing and Applications. Springer Berlin Heidelberg, (2013). 63-78.\n[6] .Prasad, Dilip K., and Michael S. Brown. \"Online tracking of deformable objects under occlusion using dominant points.\" JOSA A 30.8 (2013): 1484-1491\n[6].Fakheredine Keyrouz, \u201cA Fast-Multiplying PSO Algorithm for Real-Time Multiple Object Tracking\u201d, International Journal of Computer Applications (0975 - 8887) Volume 60 - No. 3, December 2012\n[8]. Ahmed, Hazem, and Janice Glasgow. \"Swarm intelligence: concepts, models and applications.\" School Of Computing, Queens University Technical Report (2012).\n[9]. Chen-Chien Hsu, Guo-Tang Dai, \u201c Multiple Object Tracking using Particle Swarm Optimization\u201d, World Academy of Science, Engineering and TechnologyVol:6 (2012)-08- 21 [10]. Sun, Jun, et al. \"Quantum-behaved particle swarm optimization with Gaussian distributed local attractor point.\" Applied Mathematics and Computation 218.7 (2011)\n[11]. Chen Ching-Han and Yan Miao-Chun., \u201cPSO-Based Multiple People Tracking\u201d,\nInternational Conference on Digital Information and Communication Technology and\nIts Applications. Springer Berlin Heidelberg, 2011.\n[12]. Rini, Dian Palupi, Siti Mariyam Shamsuddin, and Siti Sophiyati Yuhaniz. \"Particle swarm optimization: technique, system and challenges.\"International Journal of Computer Applications 14.1 (2011): 19-26.\n[13]. Vijay John, Emanuele Trucco, Spela Ivekovic, \u201cMarkerless human articulated tracking using hierarchical particle swarm optimization\u201d , Image and Vision Computing 28.11 (2010): 1530-1547.\n[14]Yuhua Zeng, Yan Meng , \u201cSwarm Intelligence based Dynamic Object Tracking\u201d, IEEE 2008.\n[15].Xiaoqin Zhang,Weiming Hu,Steve Maybank,Xi Li,Mingliang Zhu, \u201cSequential Particle Swarm Optimization for Visual Tracking\u201d, Computer Vision and Pattern Recognition, 2008. CVPR 2008.\n[16].Yuhua Meng, Yan Meng , \u201cAdaptive Object Tracking using Particle Swarm Optimization\u201d, Proceedings of the 2007 IEEE International Symposium on Computational Intelligence in Robotics and Automation2007.\n[17]. Sun, Jun, Bin Feng, and Wenbo Xu. \"Particle swarm optimization with particles having quantum behavior.\" Evolutionary Computation, 2004. CEC2004. Congress on. Vol. 1. IEEE, 2004.\n[18]. Wu, Wen-Yen. \"An adaptive method for detecting dominant points.\" Pattern Recognition 36.10 (2003): 2231-2237\n[19]. Carlisle, A. and Dozier, G. (2001), An off-the-shelf pso, In: Proceedings of the Workshop on Particle Swarm Optimization, Purdue School of Engineering and Technology, Indianapolis, USA.\n[20] Shi, Y. and Eberhart, R. C.: (1998) A modified particle swarm optimizer, in Proc.IEEE Congr. Evol. Compute., 1998, pp. 69\u201373.\n[21].R.C Eberhart and J.Kennedy , \u201cParticle Swarm Optimization\u201d, in Proceeding of IEEE International Conference on Neural Networks, 1995.\n[22] .B.K. Ray, K.S. Ray, Detection of significant pointsand polygonalapproximation of digitized curves, Pattern Recognition Letter. 13 (1992) 443\u2013452.\n[23]. Teh, C-H., and Roland T. Chin. \"On the detection of dominant points on digital\ncurves.\" IEEE Transactions on pattern analysis and machine intelligence 11.8 (1989): 859-872.\n[24] Horn, Berthold KP, and Brian G. Schunck. \"Determining optical flow.\"Artificial intelligence 17.1-3 (1981): 185-203.\n[25]. F. Attneave, Some information aspects of visual perception, Psychol. Rev. 61 (1954) 183\u2013193.\nRajesh Misra - is a lecturerin Information Technology at an Undergraduate college, India .prior teaching he worked in Software Industry as a Test Engineer in the field of Networking Protocol for 3 years. He received his Master in Technology degree From Calcutta University, India in 2010after receiving his B.Sc. and M.Sc. in Computer Science from same Institute in 2006 and 2008. His research interest includes Computer Vision, Particle Swarm Optimization, GeneticAlgorithm, Machine Learning, Image Processing.\nKumar S. Ray- PhD, is a Professor in the Electronics and Communication Sciences Unit at Indian Statistical Institute, Kolkata, India. He is an alumnus of University of Bradford, UK. Prof. Ray was a member of task force committee of the Government of India, Department of Electronics (DoE/MIT), for the application of AI in power plants. He is the founder member of Indian Society for Fuzzy Mathematics and Information Processing (ISFUMIP) and member of Indian Unit for Pattern Recognition and Artificial Intelligence (IUPRAI).His current research interests include artificial intelligence, computer vision, common sense reasoning, soft computing, non-monotonic deductive database systems, and DNA computing. He is the author of two research monographs viz, Soft Computing Approach to Pattern Classification and Object Recognition, a unified concept, Springer, Network, and Polygonal Approximation and Scale-Space Analysis of closed digital curves, Apple Academic Press, Canada, 2013"}], "references": [{"title": "A Novel Distributed Quantum-Behaved Particle Swarm Optimization.", "author": ["Li", "Yangyang"], "venue": "Journal of Optimization", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Object tracking benchmark.", "author": ["Wu", "Yi", "Jongwoo Lim", "Ming-Hsuan Yang"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "High-speed tracking with kernelized correlation filters.", "author": ["Henriques", "Jo\u00e3o F"], "venue": "IEEE Transactions on Pattern Analysis and Machine", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Fast Moving Object Tracking Algorithm based on Hybrid Quantum PSO.\" target", "author": ["Chen", "Jinyin", "Yi Zhen", "Dongyong Yang"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Multi-object tracking using particle swarm optimization on target interactions.\" Advances in Heuristic Signal Processing and Applications", "author": ["Kwolek", "Bogdan"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "Bogdan Kwolek [5] represent an approach where object is represented by image template , after constructing a covariance matrix based on that, by using similarity measure PSO will keep track of the difference appeared during movement of the object with target template.", "startOffset": 14, "endOffset": 17}, {"referenceID": 3, "context": "Above we discussed all those considerable contribution towards object tracking using PSO in various ways, but there are significantly less work has been done in object tracking using Quantum Particle Swarm Optimization (QPSO), Though this QPSO concept is not very old[17] developed by Sun, Jun, Bin Feng, and Wenbo Xu but still a decade gone, while we found Chen, Jinyin, Yi Zhen, and Dongyong Yang work [4] on object tracking but other than that not much work to mention.", "startOffset": 404, "endOffset": 407}, {"referenceID": 3, "context": "Brown[4] uses dominant point for boundary contour and propose a time propagation method of those dominant points so that it can effectively detect deformation of object and track.", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "K , u , \u03c6 are random number distributed uniformly over the range [0,1].", "startOffset": 65, "endOffset": 70}, {"referenceID": 3, "context": "\uf0b7 \u03c6 ,\u03b2, u , k values initialization \u2013earlier we define the meaning of this termson equation [4-6], all those variables values are randomly distributed in range [0-1].", "startOffset": 92, "endOffset": 97}, {"referenceID": 4, "context": "\uf0b7 \u03c6 ,\u03b2, u , k values initialization \u2013earlier we define the meaning of this termson equation [4-6], all those variables values are randomly distributed in range [0-1].", "startOffset": 92, "endOffset": 97}, {"referenceID": 0, "context": "\uf0b7 \u03c6 ,\u03b2, u , k values initialization \u2013earlier we define the meaning of this termson equation [4-6], all those variables values are randomly distributed in range [0-1].", "startOffset": 160, "endOffset": 165}, {"referenceID": 0, "context": "All the experimental dataset has been taken form benchmark library created by Yi Wu, Member, IEEE, Jongwoo Lim, Member, IEEE, and Ming-Hsuan Yang, Senior Member, IEEE[1] work which will be available on http://pami.", "startOffset": 166, "endOffset": 169}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3].", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4].", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5].", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "In Computer Vision domain, moving Object Tracking considered as one of the toughest problem. As there so many factors associated like illumination of light, noise, occlusion, sudden start and stop of moving object, shading which makes tracking even harder problem not only for dynamic background but also for static background. In this paper we present a new object tracking algorithm based on Dominant points on tracked object using Quantum particle swarm optimization (QPSO) which is a new different version of PSO based on Quantum theory. The novelty in our approach is that it can be successfully applicable in variable background as well as static background and application of quantum PSO makes the algorithm runs lot faster where other basic PSO algorithm failed to do so due to heavy computation. In our approach firstly dominants points of tracked objects detected, then a group of particles form a swarm are initialized randomly over the image search space and then start searching the curvature connected between two consecutive dominant points until they satisfy fitness criteria. Obviously it is a Multi-Swarm approach as there are multiple dominant points, as they moves, the curvature moves and the curvature movement is tracked by the swarm throughout the video and eventually when the swarm reaches optimal solution , a bounding box drawn based on particles final position. Experimental results demonstrate this proposed QPSO based method work efficiently and effectively in visual object tracking in both dynamic and static environments and run time shows that it runs closely 90% faster than basic PSO.in our approach we also apply parallelism using MatLab \u2018Parfor\u2019 command to show how very less number of iteration and swarm size will enable us to successfully track object.", "creator": "Microsoft\u00ae Office Word 2007"}}}