{"id": "1707.06756", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jul-2017", "title": "An Infinite Hidden Markov Model With Similarity-Biased Transitions", "abstract": "we describe a generalization of the hierarchical dirichlet process hidden markov model ( hdp - hmm ) which explicitly is able to encode prior information that state transitions are more likely between \" nearby \" states. this is accomplished by defining a similarity function on the state space and scaling transition probabilities by pair - wise similarities, thereby inducing correlations behavior among the transition distributions. further we present an augmented behavioral data density representation of the cluster model as a markov capture jump loop process in which : ( 1 ) some jump attempts fail, and ( 2 ) the probability of predicting success is proportional to the similarity between the source and destination states. this augmentation restores conditional conjugacy and admits a simple gibbs sampler. we evaluate the model and inference method on a speaker diarization task and a \" harmonic parsing \" task set using four - part chorale data, as well as on several synthetic datasets, achieving favorable comparisons to existing models.", "histories": [["v1", "Fri, 21 Jul 2017 04:39:10 GMT  (441kb,D)", "http://arxiv.org/abs/1707.06756v1", "16 pages, 4 figures, accepted to ICML 2017, includes supplemental appendix"]], "COMMENTS": "16 pages, 4 figures, accepted to ICML 2017, includes supplemental appendix", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG stat.ME", "authors": ["colin reimer dawson", "chaofan huang", "clayton t morrison"], "accepted": true, "id": "1707.06756"}, "pdf": {"name": "1707.06756.pdf", "metadata": {"source": "CRF", "title": "An Infinite Hidden Markov Model With Similarity-Biased Transitions", "authors": ["Colin Reimer Dawson", "Chaofan Huang", "Clayton T. Morrison"], "emails": ["<cdawson@oberlin.edu>."], "sections": [{"heading": "1. Introduction and Background", "text": "The hierarchical Dirichlet process hidden Markov model (HDP-HMM) (Beal et al., 2001; Teh et al., 2006) is a Bayesian model for time series data that generalizes the conventional hidden Markov Model to allow a countably infinite state space. The hierarchical structure ensures that, despite the infinite state space, a common set of destination states will be reachable with positive probability from each source state. The HDP-HMM can be characterized by the following generative process.\nEach state, indexed by j, has parameters, \u03b8j , drawn from a base measure, H . A top-level sequence of state\n1 Oberlin College, Oberlin, OH, USA 2The University of Arizona, Tucson, AZ, USA. Correspondence to: Colin Reimer Dawson <cdawson@oberlin.edu>. Code: http://colindawson.net/hdp-hmm-lt.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nweights, \u03b2 = (\u03b21, \u03b22, . . . ), is drawn by iteratively breaking a \u201cstick\u201d off of the remaining weight according to a Beta (1, \u03b3) distribution. The parameter \u03b3 > 0 is known as the concentration parameter and governs how quickly the weights tend to decay, with large \u03b3 corresponding to slow decay, and hence more weights needed before a given cumulative weight is reached. This stick-breaking process is denoted by GEM (Ewens, 1990; Sethuraman, 1994) for Griffiths, Engen and McCloskey. We thus have a discrete probability measure, G0, with weights \u03b2j at locations \u03b8j , j = 1, 2, . . . , defined by\n\u03b8j i.i.d.\u223c H \u03b2 \u223c GEM(\u03b3). (1)\nG0 drawn in this way is a Dirichlet Process (DP) random measure with concentration \u03b3 and base measure H .\nThe actual transition distribution, \u03c0j , from state j, is drawn from another DP with concentration \u03b1 and base measure G0:\n\u03c0j i.i.d.\u223c DP(\u03b1G0) j = 0, 1, 2, . . . (2)\nwhere \u03c00 represents the initial distribution. The hidden state sequence, z1, z2, . . . zT is then generated according to z1 |\u03c00 \u223c Cat(\u03c00), and\nzt | zt\u22121,\u03c0zt\u22121 \u223c Cat(\u03c0zt\u22121) t = 1, 2, . . . , T (3)\nFinally, the emission distribution for state j is a function of \u03b8j , so that observation yt is drawn according to\nyt | zt, \u03b8zt \u223c F (\u03b8zt) (4)\nA shortcoming of the HDP prior on the transition matrix is that it does not use the fact that the source and destination states are the same set: that is, each \u03c0j has a special element which corresponds to a self-transition. In the HDPHMM, however, self-transitions are no more likely a priori than transitions to any other state. The Sticky HDP-HMM (Fox et al., 2008) addresses this issue by adding an extra mass \u03ba at location j to the base measure of the DP that generates \u03c0j . That is, (2) is replaced by\n\u03c0j \u223c DP(\u03b1G0 + \u03ba\u03b4\u03b8j ). (5)\nAn alternative approach that treats self-transitions as special is the HDP Hidden Semi-Markov Model (HDPHSMM; Johnson & Willsky (2013)), wherein state duration distributions are modeled separately, and ordinary selftransitions are ruled out. However, while both of these\nar X\niv :1\n70 7.\n06 75\n6v 1\n[ st\nat .M\nL ]\n2 1\nJu l 2\n01 7\nmodels have the ability to privilege self-transitions, they contain no notion of similarity for pairs of states that are not identical: in both cases, when the transition matrix is integrated out, the prior probability of transitioning to state j\u2032 depends only on the top-level stick weight associated with state j\u2032, and not on the identity or parameters of the previous state j.\nThe two main contributions of this paper are (1) a generalization of the HDP-HMM, which we call the HDP-HMM with local transitions (HDP-HMM-LT) that allows for a geometric structure to be defined on the latent state space, so that \u201cnearby\u201d states are a priori more likely to have transitions between them, and (2) a simple Gibbs sampling algorithm for this model. The \u201cLT\u201d property is introduced by elementwise rescaling and then renormalizing of the HDP transition matrix. Two versions of the similarity structure are illustrated: in one case, two states are similar to the extent that their emission distributions are similar. In another, the similarity structure is inferred separately. In both cases, we give augmented data representations that restore conditional conjugacy and thus allow a simple Gibbs sampling algorithm to be used for inference.\nA rescaling and renormalization approach similar to the one used in the HDP-HMM-LT is used by Paisley et al. (2012) to define their Discrete Infinite Logistic Normal (DILN) model, an instance of a correlated random measure (Ranganath & Blei, 2016), in the setting of topic modeling. There, however, the contexts and the mixture components (topics) are distinct sets, and there is no notion of temporal dependence. Zhu et al. (2016) developed an HMM based directly on the DILN model1. Both Paisley et al. and Zhu et al. employ variational approximations, whereas we present a Gibbs sampler, which converges asymptotically to the true posterior. We discuss additional differences between our model and the DILN-HMM in Sec. 2.2.\nOne class of application in which it is useful to incorporate a notion of locality occurs when the latent state sequence consists of several parallel chains, so that the global state changes incrementally, but where these increments are not independent across chains. Factorial HMMs (Ghahramani et al., 1997) are commonly used in this setting, but this ignores dependence among chains, and hence may do poorly when some combinations of states are much more probable than suggested by the chain-wise dynamics.\nAnother setting where the LT property is useful is when there is a notion of state geometry that licenses syllogisms: e.g., if A frequently leads to B and C and B frequently leads to D and E, then it may be sensible to infer that A and C may lead to D and E as well. This property is arguably\n1We thank an anonymous ICML reviewer for bringing this paper to our attention.\npresent in musical harmony, where consecutive chords are often (near-)neighbors in the \u201ccircle of fifths\u201d, and small steps along the circle are more common than large ones.\nThe paper is structured as follows: In section 2 we define the model. In section 3, we develop a Gibbs sampling algorithm based on an augmented data representation, which we call the Markov Jump Process with Failed Transitions (MJP-FT). In section 4 we test two versions of the model: one on a speaker diarization task in which the speakers are inter-dependent, and another on a fourpart chorale corpus, demonstrating performance improvements over state-of-the-art models when \u201clocal transitions\u201d are more common in the data. Using sythetic data from an HDP-HMM, we show that the LT variant can learn not to use its similarity bias when the data does not support it. Finally, in section 5, we conclude and discuss the relationships between the HDP-HMM-LT and existing HMM variants. Code and additional details are available at http://colindawson.net/hdp-hmm-lt/"}, {"heading": "2. An HDP-HMM With Local Transitions", "text": "We wish to add to the transition model the concept of a transition to a \u201cnearby\u201d state, where transitions between states j and j\u2032 are more likely a priori to the extent that they are \u201cnearby\u201d in some similarity space. In order to accomplish this, we first consider an alternative construction of the transition distributions, based on the Normalized Gamma Process representation of the DP (Ishwaran & Zarepour, 2002; Ferguson, 1973)."}, {"heading": "2.1. A Normalized Gamma Process representation of the HDP-HMM", "text": "The Dirichlet Process is an instance of a normalized completely random measure (Kingman, 1967; Ferguson, 1973), that can be defined as G = \u2211\u221e k=1 \u03c0\u0303k\u03b4\u03b8k , where\n\u03c0k ind.\u223c Gamma(\u03b1\u03b2k, 1) T = \u221e\u2211 k=1 \u03c0k \u03c0\u0303k = \u03c0k T , (6)\n\u03b4\u03b8 is a measure assigning 1 to sets if they contain \u03b8 and 0 otherwise, and subject to the constraint that \u2211 k\u22651 \u03b2k = 1 and 0 < \u03b1 <\u221e. It has been shown (Ferguson, 1973; Paisley et al., 2012; Favaro et al., 2013) that the normalization constant T is positive and finite almost surely, and thatG is distributed as a DP with base measure G0 = \u2211\u221e k=1 \u03b2k\u03b4\u03b8k . If we draw \u03b2 = (\u03b21, \u03b22, . . . ) from the GEM(\u03b3) stickbreaking process, draw an i.i.d. sequence of \u03b8k from a base measure H , and then draw an i.i.d. sequence of random measures, {Gj}, j = 1, 2, . . . , from the above process, this defines a Hierarchical Dirichlet Process (HDP). If each Gj is associated with the hidden states of an HMM, \u03c0 is the infinite matrix where entry \u03c0jj\u2032 is the j\u2032th mass associated\nwith the jth random measure, and Tj is the sum of row j, then we obtain the prior for the HDP-HMM, where\np(zt | zt\u22121,\u03c0) = \u03c0\u0303zt\u22121zt = \u03c0jj\u2032/Tj (7)"}, {"heading": "2.2. Promoting \u201cLocal\u201d Transitions", "text": "In the HDP prior, the rows of the transition matrix are conditionally independent. We wish to relax this assumption, to incorporate possible prior knowledge that certain pairs of states are \u201cnearby\u201d in some sense and thus more likely than others to produce large transition weights between them (in both directions); that is, transitions are likely to be \u201clocal\u201d. We accomplish this by associating each latent state j with a location `j in some space \u2126, introducing a \u201csimilarity function\u201d \u03c6 : \u2126 \u00d7 \u2126 \u2192 (0, 1], and scaling each element \u03c0jj\u2032 by \u03c6jj\u2032 = \u03c6(`j , `j\u2032). For example, we might wish to define a (possibly asymmetric) divergence function d : \u2126\u00d7 \u2126\u2192 [0,\u221e) and set \u03c6(`j , `j) = exp{\u2212d(`j , `j\u2032)} so that transitions are less likely the farther apart two states are. By setting \u03c6 \u2261 1, we obtain the standard HDP-HMM. The DILN-HMM (Zhu et al., 2016), employs a similar rescaling of transition probabilities via an exponentiated Gaussian Process, following (Paisley et al., 2012), but the scaling function must be positive semi-definite, and in particular symmetric, whereas in the HDP-HMM-LT, \u03c6 need only take values in (0, 1]. Moreover, the DILN-HMM does not allow the scales to be tied to other state parameters, and hence encode an independent notion of similarity.\nLetting ` = (`1, `2, . . . ), we can replace (6) for j \u2265 1 by\n\u03c0jj\u2032 |\u03b2, ` \u223c Gamma(\u03b1\u03b2j\u2032 , 1), Tj = \u221e\u2211 j\u2032=1 \u03c0jj\u2032\u03c6jj\u2032\n\u03c0\u0303jj\u2032 = \u03c0jj\u2032\u03c6jj\u2032/Tj , p(zt | zt\u22121,\u03c0, `) = \u03c0\u0303zt\u22121zt .\n(8)\nSince the \u03c6jj\u2032 are positive and bounded above by 1, 0 < \u03c0j1\u03c6j1 \u2264 Tj \u2264 \u2211 j\u2032 \u03c0jj\u2032 <\u221e (9)\nalmost surely, where the last inequality carries over from the original HDP. The prior means of the unnormalized transition distributions, \u03c0j are then proportional (for each j) to \u03b1\u03b2\u03c6j where \u03c6j = (\u03c6j1, \u03c6j2, . . . ).\nThe distribution of the latent state sequence z given \u03c0 and ` is now\np(z |\u03c0, `) = T\u220f t=1 \u03c0zt\u22121zt\u03c6zt\u22121ztT \u2212nzt\u22121\u00b7 zt\u22121\n= \u221e\u220f j=1 T\u22121j \u221e\u220f j\u2032=1 \u03c0 njj\u2032 jj\u2032 \u03c6 njj\u2032 jj\u2032\n(10)\nwhere njj\u2032 = \u2211T t=1 I(zt\u22121 = j, zt = j\n\u2032) is the number of transitions from state j to state j\u2032 in the sequence z\nand nj\u00b7 = \u2211 j\u2032 njj\u2032 is the total number of visits to state j. Since Tj is a sum over products of \u03c0jj\u2032 and \u03c6jj\u2032 terms, the posterior for \u03c0 is no longer a DP. However, conditional conjugacy can be restored by a data-augmentation process with a natural interpretation, which is described next."}, {"heading": "2.3. The HDP-HMM-LT as the Marginalization of a Markov Jump Process with \u201cFailed\u201d Transitions", "text": "In this section, we define a stochastic process that we call the Markov Jump Process with Failed Transitions (MJP-FT), from which we obtain the HDP-HMM-LT by marginalizing over some of the variables. By reinstating these auxiliary variables, we obtain a simple Gibbs sampling algorithm over the full MJP-FT, which can be used to sample from the marginal posterior of the variables used by the HDP-HMM-LT.\nLet \u03b2, \u03c0, ` and Tj , j = 1, 2, . . . be defined as in the last section. Consider a continuous-time Markov Process over the states j = 1, 2, . . . , and suppose that if the process makes a jump to state zt at time \u03c4t, the next jump, which is to state zt+1, occurs at time \u03c4t + u\u0303t, where u\u0303t \u223c Exp( \u2211 j\u2032 \u03c0jj\u2032), and p(zt+1 = j\n\u2032 | zt = j) \u221d \u03c0jj\u2032 , independent of u\u0303t. Note that in this formulation, unlike in standard formulations of Markov Jump Processes, we are assuming that self-jumps are possible.\nIf we only observe the jump sequence z and not the holding times u\u0303t, this is an ordinary Markov chain with transition matrix row-proportional to \u03c0. If we do not observe the jumps directly, but instead an observation is generated once per jump from a distribution that depends on the state being jumped to, then we have an ordinary HMM whose transition matrix is obtained by normalizing \u03c0; that is, we have the HDP-HMM.\nWe modify this process as follows. Suppose each jump attempt from state j to state j\u2032 has probability (1 \u2212 \u03c6jj\u2032) of failing, in which case no transition occurs and no observation is generated. Assuming independent failures, the rates of successful and failed jumps from j to j\u2032 are \u03c0jj\u2032\u03c6jj\u2032 and \u03c0jj\u2032(1 \u2212 \u03c6jj\u2032), respectively. The probability that the first successful jump is to state j\u2032 (that is, that zt+1 = j\u2032) is proportional to the rate of successful jump attempts to j\u2032, which is \u03c0jj\u2032\u03c6jj\u2032 . Conditioned on zt, the holding time, u\u0303t, is independent of zt+1 and is distributed as Exp(Tzt). We denote the total time spent in state j by uj = \u2211 t:zt=j\nu\u0303t, where, as the sum of i.i.d. Exponentials,\nuj | z,\u03c0,\u03b8 ind.\u223c Gamma(nj\u00b7, Tj) (11)\nDuring this period there will be qjj\u2032 failed attempts to jump to state j\u2032, where qjj\u2032 \u223c Poisson(uj\u03c0jj\u2032(1\u2212 \u03c6jj\u2032)) are independent. This data augmentation bears some conceptual similarity to the Geometrically distributed \u03c1 auxiliary variables introduced to the HDP-HSMM (Johnson & Willsky,\n2013) to restore conditional conjugacy. However, there are key differences: first, \u03c1 measure how many steps the chain would have remained in state j under Markovian dynamics, whereas our u represents putative continuous holding times between each transition, and second \u03c1 allows for the restoration of a zeroed out entry in each row, whereas u allows us to work with unnormalized \u03c0 entries, avoiding the need to restore zeroed out entries in the HSMM-LT\nIncorporating u = {uj} and Q = {qjj\u2032} as augmented data simplifies the likelihood for \u03c0, yielding\np(z,u,Q |\u03c0) = p(z |\u03c0)p(u | z,\u03c0)p(Q |u,\u03c0) (12)\nwhere dependence on ` has been omitted for conciseness. After grouping terms and omitting terms that do not depend on \u03c0, this proportional (as a function of \u03c0) to\u220f\nj \u220f j\u2032 \u03c0 njj\u2032+qjj\u2032 jj\u2032 \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 e\u2212\u03c0jj\u2032uj (13)\nConveniently, the Tj have canceled, and the exponential terms involving \u03c0jj\u2032 and \u03c6jj\u2032 in the Gamma and Poisson distributions of uj and qjj\u2032 combine to cause \u03c6jj\u2032 to vanish.\nAdditional details and derivations for this data augmentation are in Appendix A."}, {"heading": "2.4. Sticky and Semi-Markov Generalizations", "text": "We note that the local transition property of the HDPHMM-LT can be combined with the Sticky property of the Sticky HDP-HMM (Fox et al., 2008), or the nongeometric duration distributions of the HDP-HSMM (Johnson & Willsky, 2013), to add additional prior weight on self-transitions. In the former case, no changes to inference are needed; one can simply add the the extra mass \u03ba to the shape parameter of the Gamma prior on the \u03c0jj , and employ the same auxiliary variable method used by Fox et al. to distinguish \u201cSticky\u201d from \u201cregular\u201d self-transitions. For the semi-Markov case, we can fix the diagonal elements of \u03c0 to zero, and allow Dt observations to be emitted i.i.d. according to a state-specific duration distribution, and sample the latent state sequence using a suitable semi-Markov message passing algorithm (Johnson & Willsky, 2013). Inference for the \u03c6 matrix is not affected, since the diagonal elements are assumed to be 1. Unlike in the original representation of the HDP-HSMM, no further dataaugmentation is needed, as the (continuous) durations u already account for the normalization of the \u03c0."}, {"heading": "2.5. Obtaining the Factorial HMM as a Limiting Case", "text": "One setting in which a local transition property is desirable is the case where the latent states encode multiple hidden features at time t as a vector of categories. Such problems are often modeled using factorial HMMs (Ghahramani\net al., 1997). In fact, the HDP-HMM-LT yields the factorial HMM in the limit as \u03b1, \u03b3 \u2192\u221e, fixing each row of \u03c0 to be uniform with probability 1, so the dynamics are controlled entirely by \u03c6. If A(d) is the transition matrix for chain d, then setting \u03c6(`j , `j\u2032) = exp\u2212d(`j , `j\u2032) with asymmetric \u201cdivergences\u201d d(`j , `j\u2032) = \u2212 \u2211 d log(A (d) `jd,`j\u2032d\n) yields the factorial transition model."}, {"heading": "2.6. An Infinite Factorial HDP-HMM-LT", "text": "Nonparametric extensions of the factorial HMM, such as the infinite factorial hidden Markov Model (Gael et al., 2009) and the infinite factorial dynamic model (Valera et al., 2015), have been developed in recent years by making use of the Indian Buffet Process (Ghahramani & Griffiths, 2005) as a state prior. It would be conceptually straightforward to combine the IBP state prior with the similarity bias of the LT model, provided the chosen similarity function is uniformly bounded above on the space of infinite length binary vectors (for example, take \u03c6(u, v) to be the exponentiated negative Hamming distance between u and v). Since the number of differences between two draws from the IBP is finite with probability 1, this yields a reasonable similarity metric."}, {"heading": "3. Inference", "text": "We develop a Gibbs sampling algorithm based on the MJPFT representation described in Sec. A, augmenting the data with the duration variables u, the failed jump attempt count matrix, Q, as well as additional auxiliary variables which we will define below. In this representation the transition matrix is not represented directly, but is a deterministic function of the unscaled transition \u201crate\u201d matrix, \u03c0, and the similarity matrix, \u03c6. The full set of variables is partitioned into blocks: {\u03b3, \u03b1, \u03b2,\u03c0}, {z,u,Q,\u039b}, {\u03b8, `}, and {\u03be}, where \u039b represents a set of auxiliary variables that will be introduced below, \u03b8 represents the emission parameters (which may be further blocked depending on the specific choice of model), and \u03be represents additional parameters such as any free parameters of the similarity function, \u03c6, and any hyperparameters of the emission distribution."}, {"heading": "3.1. Sampling Transition Parameters and Hyperparameters", "text": "The joint posterior over \u03b3, \u03b1, \u03b2 and \u03c0 given the augmented data D = (z,u,Q,\u039b) will factor as\np(\u03b3,\u03b1,\u03b2,\u03c0 | D) = p(\u03b3 | D)p(\u03b1 | D)p(\u03b2 | \u03b3,D)p(\u03c0 |\u03b1, \u03b2,D) (14)\nWe describe these four factors in reverse order. For additional details, see Appendix B.\nSampling \u03c0 Having used data augmentation to simplify the likelihood for \u03c0 to the factored conjugate form in (40), the individual \u03c0jj\u2032 are a posteriori independent Gamma(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032 , 1 + uj) distributed.\nSampling \u03b2 To enable joint sampling of z, we employ a weak limit approximation to the HDP (Johnson & Willsky, 2013), approximating the stick-breaking process for \u03b2 using a finite Dirichlet distribution with a J components, where J is larger than we expect to need. Due to the product-of-Gammas form, we can integrate out \u03c0 analytically to obtain the marginal likelihood:\np(\u03b2 | \u03b3) = \u0393(\u03b3/J) J\n\u0393(\u03b3) \u220f j \u03b2 \u03b3 J\u22121 j (15)\np(D |\u03b2, \u03b1) \u221d J\u220f j=1 (1 + uj) \u2212\u03b1 \u220f j\u2032 \u0393(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032) \u0393(\u03b1\u03b2j\u2032)\nwhere we have used the fact that the \u03b2j sum to 1 to pull out terms of the form (1 + uj)\u2212\u03b1\u03b2j\u2032 from the inner product in the likelihood. Following Teh et al. (2006), we can introduce auxiliary variables M = {mjj\u2032}, with\np(mjj\u2032 |\u03b2j\u2032 , \u03b1,D) ind\u221d snjj\u2032+qjj\u2032 ,mjj\u2032\u03b1 mjj\u2032\u03b2 mjj\u2032 j\u2032 (16)\nfor integer mjj\u2032 ranging between 0 and njj\u2032 + qjj\u2032 , where sn,m is an unsigned Stirling number of the first kind. The normalizing constant in this distribution cancels the ratio of Gamma functions in the \u03b2 likelihood, so, letting m\u00b7j\u2032 = \u2211 jmjj\u2032 and m\u00b7\u00b7 = \u2211 j\u2032 m\u00b7j\u2032 , the posterior for (the truncated) \u03b2 is a Dirichlet whose jth mass parameter is \u03b3J +m\u00b7j .\nSampling Concentration Parameters Incorporating M into D, we can integrate out \u03b2 to obtain\np(D |\u03b1, \u03b3) \u221d \u03b1m\u00b7\u00b7e\u2212 \u2211 j\u2032\u2032 log(1+uj\u2032\u2032 )\u03b1\n\u0393(\u03b3) \u0393(\u03b3 +m\u00b7\u00b7) \u00d7 \u220f j \u0393( \u03b3J +m\u00b7j) \u0393( \u03b3J )\n(17)\nAssuming that \u03b1 and \u03b3 have Gamma priors with shape and rate parameters a\u03b1, b\u03b1 and a\u03b3 , b\u03b3 , then\n\u03b1 | D \u223c Gamma(a\u03b1 +m\u00b7\u00b7, b\u03b1 + \u2211 j log(1 + uj)). (18)\nTo simplify the likelihood for \u03b3, we can introduce a final set of auxiliary variables, r = (r1, . . . , rJ), rj\u2032 \u2208 {0, . . . ,m\u00b7j\u2032} and w \u2208 (0, 1) with the following distributions:\np(rj\u2032 = r |m\u00b7j\u2032 , \u03b3) \u221d s(m\u00b7j\u2032 , r) ( \u03b3 J )r (19) p(w |m\u00b7\u00b7\u03b3) \u221d w\u03b3\u22121(1\u2212 w)m\u00b7\u00b7\u22121 (20)\nThe normalizing constants are ratios of Gamma functions, which cancel those in (17), so that\n\u03b3 | D, r, w \u223c Gamma(a\u03b3 + r\u00b7, b\u03b3 \u2212 log(w)) (21)"}, {"heading": "3.2. Sampling z and the auxiliary variables", "text": "We sample the hidden state sequence, z, jointly with the auxiliary variables, which consist of u, Q, M, r and w. The joint conditional distribution of these variables is defined directly by the generative model:\np(D) = p(z)p(u | z)p(Q |u)p(M | z,Q)p(r |M)p(w |M)\nSince we are conditioning on the transition matrix, we can sample the entire sequence z jointly with the forwardbackward algorithm, as in an ordinary HMM. Since we are sampling the labels jointly, this step requiresO(TJ2) computation per iteration, which is the bottleneck of the inference algorithm for reasonably large T or J (other updates are constant in T or in J). Having done this, we can sample u, Q, M, r andw from their forward distributions. It is also possible to employ a variant on beam sampling (Van Gael et al., 2008) to speed up each iteration, at the cost of slower mixing, but we did not use this variant here."}, {"heading": "3.3. Sampling state and emission parameters", "text": "Depending on the application, the locations ` may or may not depend on the emission parameters, \u03b8. If not, sampling \u03b8 conditional on z is unchanged from the HDP-HMM. There is no general-purpose method for sampling `, or for sampling \u03b8 in the dependent case, due to the dependence on the form of \u03c6 and on the emission model, but specific instances are illustrated in the experiments below."}, {"heading": "4. Experiments", "text": "The parameter space for the hidden states, the associated prior H on \u03b8, and the similarity function \u03c6, is applicationspecific; we consider here two cases. The first is a speakerdiarization task, where each state consists of a finite Ddimensional binary vector whose entries indicate which speakers are currently speaking. In this experiment, the state vectors both determine the pairwise similarities and partially determine the emission distributions via a linearGaussian model. In the second experiment, the data consists of Bach chorales, and the latent states can be thought of as harmonic contexts. There, the components of the states that govern similarities are modeled as independent of the emission distributions, which are categorical distributions over four-voice chords."}, {"heading": "4.1. Cocktail Party", "text": "The Data The data was constructed using audio signals collected from the PASCAL 1st Speech Separation Chal-\nlenge2. The underlying signal consisted ofD = 16 speaker channels recorded at each of T = 2000 time steps, with the resulting T \u00d7 D signal matrix, denoted by \u03b8\u2217, mapped to K = 12 microphone channels via a weight matrix, W. The 16 speakers were grouped into 4 conversational groups of 4, where speakers within a conversation took turns speaking (see Fig. 2). In such a task, there are naively 2D possible states (here, 65536). However, due to the conversational grouping, if at most one speaker in a conversation is speaking at any given time, the state space is constrained, with only \u220f c(sc + 1) states possible, where sc is the number of speakers in conversation c (in this case sc \u2261 4, for a total of 625 possible states).\nEach \u201cturn\u201d within a conversation consisted of a single sentence (average duration \u223c 3s) and turn orders within a conversation were randomly generated, with random pauses distributed as N (1/4s, (1/4s)2) inserted between sentences. Every time a speaker has a turn, the sentence is drawn randomly from the 500 sentences uttered by that speaker in the data. The conversations continued for 40s, and the signal was down-sampled to length 2000. The \u2019on\u2019 portions of each speaker\u2019s signal were normalized to have amplitudes with mean 1 and standard deviation 0.5. An additional column of 1s was added to the speaker signal matrix, \u03b8\u2217, representing background noise. The resulting signal matrix, denoted \u03b8\u2217, was thus 2000\u00d7 17 and the weight matrix, W, was 17\u00d7 12. Following Gael et al. (2009) and Valera et al. (2015), the weights were drawn independently from a Unif(0, 1) distribution, and independentN (0, 0.32) noise was added to each entry of the observation matrix.\nThe Model The latent states, \u03b8j , are the D-dimensional binary vectors whose dth entry indicates whether or not speaker d is speaking. The locations `j are identified with the binary vectors, `j := \u03b8j . We use a Laplacian similarity function on Hamming distance, d0, so that \u03c6jj\u2032 := exp(\u2212\u03bbd0(`j , `j\u2032)), \u03bb \u2265 0. The emission model is linearGaussian as in the data, with (D + 1) \u00d7K weight matrix W, and T \u00d7 (D + 1) signal matrix \u03b8\u2217 whose tth row is \u03b8t := (1,\u03b8zt), so that yt | z \u223c N (WT\u03b8 \u2217 t ,\u03a3). For the experiments discussed here, we assume that \u03a3 is independent of j, but this assumption is easily relaxed if appropriate.\nFor finite-length binary vector states, the set of possible states is finite, and so it may seem that a nonparametric model is unnecessary. However, if D is reasonably large, likely most of the 2D possible states are vanishingly unlikely (and the number of observations may well be less than 2D), and so we would like to encourage the selection of a sparse set of states. Moreover, there could be more than one state with the same emission parameters, but with different transition dynamics. Next we describe the addi-\n2 http://laslab.org/SpeechSeparationChallenge/\ntional inference steps needed for this version of the model.\nSampling \u03b8 / ` Since \u03b8j and `j are identified, influencing both the transition matrix and the emission distributions, both the state sequence z and the observation matrix Y are used in the update. We put independent Beta-Bernoulli priors on each coordinate of \u03b8, and Gibbs sample each coordinate \u03b8jd conditioned on all the others and the coordinatewise prior means, {\u00b5d}, which we sample in turn conditioned on \u03b8. Details are in Appendix C.\nSampling \u03bb The \u03bb parameter of the similarity function governs the connection between ` and \u03c6. Substituting the definition of \u03c6 into (40) yields\np(z,Q | `, \u03bb) \u221d \u220f j \u220f j\u2032 e\u2212\u03bbdjj\u2032njj\u2032 (1\u2212 e\u2212\u03bbdjj\u2032 )qjj\u2032 (22)\nWe put an Exp(b\u03bb) prior on \u03bb, which yields a posterior density\np(\u03bb | z,Q, `) \u221d e\u2212(b\u03bb+ \u2211 j \u2211 j\u2032 djj\u2032njj\u2032 )\u03bb (23)\n\u00d7 \u220f j \u220f j\u2032 (1\u2212 e\u2212\u03bbdjj\u2032 )qjj\u2032\nThis density is log-concave, and so we use Adaptive Rejection Sampling (Gilks & Wild, 1992) to sample from it.\nSampling W and \u03a3 Conditioned on Y and \u03b8\u2217, W and \u03a3 can be sampled as in Bayesian linear regression. If each column of W has a multivariate Normal prior, then the columns are a posteriori independent multivariate Normals. For the experiments reported here, we fix W to its ground truth value so that \u03b8\u2217 can be compared directly with the ground truth signal matrix, and we constrain \u03a3 to be diagonal, with Inverse Gamma priors on the variances, resulting in conjugate updates.\nResults We attempted to infer the binary speaker matrices using five models: (1) a binary-state Factorial HMM (Ghahramani et al., 1997), where individual binary speaker sequences are modeled as independent, (2) an ordinary HDP-HMM without local transitions (Teh et al., 2006), where the latent states are binary vectors, (3) a Sticky HDPHMM (Fox et al., 2008), (4) our HDP-HMM-LT model, and (5) a model that combines the Sticky and LT properties3. For all models, all concentration and noise precision parameters are given Gamma(0.1, 0.1) priors. For the Sticky models, the ratio \u03ba\u03b1+\u03ba is given a Unif(0, 1) prior. We evaluated the models at each iteration using both the\n3We attempted to add a comparison to the DILN-HMM (Zhu et al., 2016) as well, but code could not be obtained, and the paper did not provide enough detail to reproduce their inference algorithm.\nHamming distance between inferred and ground truth state matrices and F1 score. We also plot the inferred decay rate \u03bb, and the number of states used by the LT and Sticky-LT models. The results for the five models are in Fig. 1. In Fig. 2, we plot the ground truth state matrix against the average state matrix, \u03b7\u2217, averaged over runs and post-burn-in iterations.\nThe LT and Sticky-LT models outperform the others, while the regular Sticky model exhibits only a small advantage over the vanilla HDP-HMM. Both converge on a nonnegligible \u03bb value of about 1.6 (see Fig. 1), suggesting that the local transition structure explains the data well. The LT models also use more states than the non-LT models, perhaps owing to the fact that the weaker transition prior of the non-LT model is more likely to explain nearby similar observations as a single persisting state, whereas the LT model places a higher probability on transitioning to a new state with a similar latent vector."}, {"heading": "4.2. Synthetic Data Without Local Transitions", "text": "We generated data directly from the ordinary HDP-HMM used in the cocktail experiment as a sanity check, to examine the performance of the LT model in the absence of a similarity bias. The results are in Fig. 3. When the \u03bb parameter is large, the LT model has worse performance than the non-LT model on this data; however, the \u03bb parameter settles near zero as the model learns that local transitions are not more probable. When \u03bb = 0, the HDP-HMM-LT is an ordinary HDP-HMM. The LT model does not make entirely the same inferences as the non-LT model, however; in particular, the \u03b1 concentration parameter is larger. To some\nextent, \u03b1 and \u03bb trade off: sparsity of the transition matrix can be achieved either by beginning with a sparse rate matrix prior to rescaling (\u03b1 small), or by beginning with a less sparse rate matrix which becomes sparser through rescaling (larger \u03b1 and non-zero \u03bb)."}, {"heading": "4.3. Bach Chorales", "text": "To test a version of the HDP-HMM-LT model in which the components of the latent state governing similarity are unrelated to the emission distributions, we used our model to do unsupervised \u201cgrammar\u201d learning from a corpus of Bach chorales. The data was a corpus of 217 four-voice major key chorales by J.S. Bach from music214, 200 of which were randomly selected as a training set, with the other 17 used as a test set to evaluate surprisal (marginal log likelihood per observation) by the trained models. All chorales were transposed to C-major, and each distinct four-voice chord (with voices ordered) was encoded as a single integer. In total there were 3307 distinct chord types and 20401 chord tokens in the 217 chorales, with 3165 types and 18818 tokens in the 200 training chorales, and 143 chord types that were unique to the test set.\nModifications to Model and Inference Since the chords were encoded as integers, the emission distribution for each state is Cat(\u03b8j). We use a symmetric Dirichlet prior for each \u03b8j , resulting in conjugate updates to \u03b8 conditioned on the latent state sequence, z.\n4 http://web.mit.edu/music21\nIn this experiment, the locations, `j , are independent of the \u03b8j , withN (0, I) priors. We use a Gaussian similarity function, \u03c6jj := exp{\u2212\u03bbd2(`j , `j\u2032)2} where d2 is Euclidean distance. Since the latent states are continuous, we use a Hamiltonian Monte Carlo (HMC) update (Duane et al., 1987; Neal et al., 2011) to update the `j simultaneously, conditioned on z and \u03c0 (see Appendix D for details).\nResults We ran 5 Gibbs chains for 10,000 iterations each using the HDP-HMM-LT, Sticky-HDP-HMM-LT, HDPHMM and Sticky-HDP-HMM models on the 200 training chorales, which were modeled as conditionally independent of one another. We evaluated the marginal log likelihood on the 17 test chorales (integrating out z) at every 50th iteration. The training and test log likelihoods are in Fig. 4. Although the LT model does not achieve as close a fit to the training data, its generalization performance is better, suggesting that the vanilla HDP-HMM is overfitting. This is perhaps counterintuitive, since the LT model is more flexible, and might be expected to be more prone to overfitting. However, the similarity bias induces greater information sharing across parameters, as in a hierarchical model: instead of each entry of the transition matrix being informed mainly by transitions directly involving the corresponding states, it is informed to some extent by all transitions, as they all inform the similarity structure."}, {"heading": "5. Discussion", "text": "We have defined a new probabilistic model, the Hierarchical Dirichlet Process Hidden Markov Model with Local Transitions (HDP-HMM-LT), which generalizes the\nHDP-HMM by allowing state space geometry to be represented via a similarity kernel, making transitions between \u201cnearby\u201d pairs of states (\u201clocal\u201d transitions), more likely a priori. By introducing an augmented data representation, which we call the Markov Jump Process with Failed Transitions (MJP-FT), we obtain a Gibbs sampling algorithm that simplifies inference in both the LT and ordinary HDPHMM. When multiple latent chains are interdependent, as in speaker diarization, the HDP-HMM-LT model combines the HDP-HMM\u2019s capacity to discover a small set of joint states with the Factorial HMM\u2019s ability to encode the property that most transitions involve a small number of chains. The HDP-HMM-LT outperforms both, as well as outperforming the Sticky-HDP-HMM, on a speaker diarization task in which speakers form conversational groups. Despite the addition of the similarity kernel, the HDP-HMM-LT is able to suppress its local transition prior when the data does not support it, achieving identical performance to the HDPHMM on data generated directly from the latter.\nThe local transition property is particularly clear when transitions occur at different times for different latent features, as with binary vector-valued states in the cocktail party setting, but the model can be used with any state space equipped with a suitable similarity kernel. Similarities need not be defined in terms of emission parameters; state \u201clocations\u201d can be represented and inferred separately, which we demonstrate using Bach chorale data. There, the LT model achieves better predictive performance on a held-out test set, while the ordinary HDP-HMM overfits the training set: the LT property here acts to encourage a concise harmonic representation where chord contexts are arranged in bidirectional functional relationships.\nWe focused on fixed-dimension binary vectors for the cocktail party and synthetic data experiments, but it would be straightforward to add the LT property to a model with nonparametric latent states, such as the iFHMM (Gael et al., 2009) and the infinite factorial dynamic model (Valera et al., 2015), both of which use the Indian Buffet Process (IBP) (Ghahramani & Griffiths, 2005) as a state prior. The\nsimilarity function used here could be employed without changes: since only finitely many coordinates are non-zero in the IBP, the distance between any two states is finite."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was funded in part by DARPA grant W911NF14-1-0395 under the Big Mechanism Program and DARPA grant W911NF-16-1-0567 under the Communicating with Computers Program."}, {"heading": "A. Details of the Markov Jump Process with Failed Transitions Representation", "text": "We can gain stronger intuition, as well as simplify posterior inference, by re-casting the HDP-HMM-LT as a continuous time Markov Jump Process where some of the attempts to jump from one state to another fail, and where the failure probability increases as a function of the \u201cdistance\u201d between the states.\nLet \u03c6 be defined as in the last section, and let \u03b2, \u03b8 and \u03c0 be defined as in the Normalized Gamma Process representation of the ordinary HDP-HMM. That is,\n\u03b2 \u223c GEM(\u03b3) (24)\n\u03b8j i.i.d\u223c H (25)\n\u03c0jj\u2032 |\u03b2,\u03b8 \u223c Gamma(\u03b1\u03b2j\u2032 , 1) (26)\nNow suppose that when the process is in state j, jumps to state j\u2032 are made at rate \u03c0jj\u2032 . This defines a continuous-time Markov Process where the off-diagonal elements of the transition rate matrix are the off diagonal elements of \u03c0. In addition, self-jumps are allowed, and occur with rate \u03c0jj . If we only observe the jumps and not the durations between jumps, this is an ordinary Markov chain, whose transition matrix is obtained by appropriately normalizing \u03c0. If we do not observe the jumps themselves, but instead an observation is generated once per jump from a distribution that depends on the state being jumped to, then we have an ordinary HMM.\nWe modify this process as follows. Suppose that each jump attempt from state j to state j\u2032 has a chance of failing, which is an increasing function of the \u201cdistance\u201d between the states. In particular, let the success probability be \u03c6jj\u2032 (recall that we assumed above that 0 \u2264 \u03c6jj\u2032 \u2264 1 for all j, j\u2032). Then, the rate of successful jumps from j to j\u2032 is \u03c0jj\u2032\u03c6jj\u2032 , and the corresponding rate of unsuccessful jump attempts is \u03c0jj\u2032(1 \u2212 \u03c6jj\u2032). To see this, denote by Njj\u2032 the total number of jump attempts to j\u2032 in a unit interval of time spent in state j. Since we are assuming the process is Markovian, the total number of attempts is Poisson(\u03c0jj\u2032) distributed. Conditioned on Njj\u2032 , njj\u2032 will be successful, where\nnjj\u2032 |Njj\u2032 \u223c Binom(Njj\u2032 , \u03c6jj\u2032) (27)\nIt is easy to show (and well known) that the marginal distribution of njj\u2032 is Poisson(\u03c0jj\u2032\u03c6jj\u2032), and the marginal distribution of q\u0303jj\u2032 := Njj\u2032 \u2212 njj\u2032 is Poisson(\u03c0jj\u2032(1 \u2212 \u03c6jj\u2032)). The rate of successful jumps from state j overall is then Tj :=\u2211 j\u2032 \u03c0jj\u2032\u03c6jj\u2032 .\nLet t index jumps, so that zt indicates the tth state visited by the process (couting self-jumps as a new time step). Given that the process is in state j at discretized time t\u2212 1 (that is, zt\u22121 = j), it is a standard property of Markov Processes that the probability that the first successful jump is to state j\u2032 (that is, zt = j\u2032) is proportional to the rate of successful attempts to j\u2032, which is \u03c0jj\u2032\u03c6jj\u2032 .\nLet u\u0303t indicate the time elapsed between the tth and and t\u22121th successful jump (where we assume that the first observation occurs when the first successful jump from a distinguished initial state is made). We have\nu\u0303t | zt\u22121 \u223c Exp(Tzt\u22121) (28)\nwhere u\u0303t is independent of zt.\nDuring this period, there will be q\u0303j\u2032t unsuccessful attempts to jump to state j\u2032, where\nq\u0303j\u2032t | zt\u22121 \u223c Poisson(u\u0303t\u03c0zt\u22121j\u2032(1\u2212 \u03c6zt\u22121j\u2032)) (29)\nDefine the following additional variables\nTj = {t | zt\u22121 = j} (30) qjj\u2032 = \u2211 t\u2208Tj q\u0303j\u2032t (31)\nuj = \u2211 t\u2208Tj u\u0303t (32)\nand let Q = (qjj\u2032)j,j\u2032\u22651 be the matrix of unsuccessful jump attempt counts, and u = (uj)j\u22651 be the vector of the total times spent in each state.\nSince each of the u\u0303t with t \u2208 Tj are i.i.d. Exp(Tj), we get the marginal distribution\nuj | z,\u03c0,\u03c6 ind\u223c Gamma(nj\u00b7, Tj) (33)\nby the standard property that sums of i.i.d. Exponential distributions has a Gamma distribution with shape equal to the number of variates in the sum, and rate equal to the rate of the individual exponentials. Moreover, since the q\u0303j\u2032t with t \u2208 Tj are Poisson distributed, the total number of failed attempts in the total duration uj is\nqjj\u2032 ind\u223c Poisson(uj\u03c0jj\u2032(1\u2212 \u03c6jj\u2032)). (34)\nThus if we marginalize out the individual u\u0303t and q\u0303j\u2032t, we have a joint distribution over z, u, and Q, conditioned on the transition rate matrix \u03c0 and the success probability matrix \u03c6, which is\np(z,u,Q |\u03c0,\u03c6) = ( T\u220f t=1 p(zt | zt\u22121) )\u220f j p(uj | z,\u03c0,\u03c6) \u220f j\u2032 p(qjj\u2032 |uj\u03c0jj\u2032 , \u03c6jj\u2032) (35)\n= (\u220f t \u03c0zt\u22121zt\u03c6zt\u22121zt Tzt\u22121 )\u220f j T nj\u00b7 j \u0393(nj\u00b7) u nj\u00b7\u22121 j e \u2212Tjuj (36)\n\u00d7 \u220f j\u2032 e\u2212uj\u03c0jj\u2032 (1\u2212\u03c6jj\u2032 )u qjj\u2032 j \u03c0 qjj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (37)\n= \u220f j \u0393(nj\u00b7) \u22121u nj\u00b7+qj\u00b7\u22121 j (38)\n\u00d7 \u220f j\u2032 \u03c0 njj\u2032+qjj\u2032 jj\u2032 \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 e\u2212\u03c0jj\u2032\u03c6jj\u2032uje\u2212\u03c0jj\u2032 (1\u2212\u03c6jj\u2032 )uj (qjj\u2032 !) \u22121 (39)\n= \u220f j \u0393(nj\u00b7) \u22121u nj\u00b7+qj\u00b7\u22121 j \u220f j\u2032 \u03c0 njj\u2032+qjj\u2032 jj\u2032 \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 e\u2212\u03c0jj\u2032uj (qjj\u2032 !) \u22121 (40)\nSetting aside terms that do not depend on \u03c0, we get the conditional likelihood function used in sampling \u03c0: p(z,u,Q |\u03c0,\u03c6) \u221d \u220f j \u220f j\u2032 \u03c0 njj\u2032+qjj\u2032 jj\u2032 e \u2212\u03c0jj\u2032uj (41)\nwhich, combined with the independent Gamma priors on \u03c0 yields conditionally independent Gamma posteriors:\n\u03c0jj\u2032 | z,u,Q,\u03b2, \u03b1 ind.\u223c Gamma(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032 , 1 + uj) (42)\nB. Inference details for hyperparameters of the rescaled HDP B.1. Sampling \u03c0, \u03b2, \u03b1 and \u03b3\nThe joint conditional over \u03b3, \u03b1, \u03b2 and \u03c0 given the augmented data D = (z,u,Q,M, r, w) factors as\np(\u03b3, \u03b1, \u03b2, \u03c0 | D) = p(\u03b3 | D)p(\u03b1 | D)p(\u03b2 | \u03b3,D)p(\u03c0 |\u03b1, \u03b2,D) (43)\nWe will derive these four factors in reverse order.\nSampling \u03c0 The entries in \u03c0 are conditionally independent given \u03b1 and \u03b2, so we have the prior p(\u03c0 |\u03b2, \u03b1) = \u220f j \u220f j\u2032 \u0393(\u03b1\u03b2j\u2032) \u22121\u03c0 \u03b1\u03b2j\u2032\u22121 jj\u2032 exp(\u2212\u03c0jj\u2032), (44)\nand the likelihood given {z,u,Q} given by (40). Combining these, we have p(\u03c0, z,u,Q |\u03b2, \u03b1,\u03c6) = \u220f j u nj\u00b7+qj\u00b7\u22121 j \u220f j\u2032 \u0393(\u03b1\u03b2j\u2032) \u22121\u03c0 \u03b1\u03b2j\u2032+njj\u2032+qjj\u2032\u22121 jj\u2032 (45)\n\u00d7 e\u2212(1+uj)\u03c0jj\u2032\u03c6njj\u2032jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (46)\nConditioning on everything except \u03c0, we get p(\u03c0 |Q,u, z,\u03b2, \u03b1) \u221d \u220f j \u220f j\u2032 \u03c0 \u03b1\u03b2j\u2032+njj\u2032+qjj\u2032\u22121 jj\u2032 exp(\u2212(1 + uj)\u03c0jj\u2032) (47)\nand thus we see that the \u03c0jj\u2032 are conditionally independent given u, z and Q, and distributed according to\n\u03c0jj\u2032 |njj\u2032 , qjj\u2032 , \u03b2j\u2032 , \u03b1 ind\u223c Gamma(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032 , 1 + uj) (48)\nSampling \u03b2 Consider the conditional distribution of \u03b2 having integrated out \u03c0. The prior density of \u03b2 is\np(\u03b2 | \u03b3) = \u0393(\u03b3) \u0393( \u03b3J ) J \u220f j \u03b2 \u03b3 J\u22121 j (49)\nAfter integrating out \u03c0 in (45), we have\np(z,u,Q |\u03b2, \u03b1, \u03b3,\u03c6) = J\u220f j=1 u\u22121j J\u220f j\u2032=1 unjj\u2032+qjj\u2032\u22121(1 + uj) \u2212(\u03b1\u03b2j\u2032+njj\u2032+qjj\u2032 ) (50)\n\u00d7 \u0393(\u03b1\u03b2j \u2032 + njj\u2032 + qjj\u2032) \u0393(\u03b1\u03b2j\u2032) \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (51)\n= J\u220f j=1 \u0393(nj\u00b7) \u22121u\u22121j (1 + uj) \u2212\u03b1 ( uj 1 + uj )nj\u00b7+qj\u00b7 (52)\n\u00d7 J\u220f\nj\u2032=1\n\u0393(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032)\n\u0393(\u03b1\u03b2j\u2032) \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (53)\nwhere we have used the fact that the \u03b2j sum to 1. Therefore\np(\u03b2 | z,u,Q, \u03b1, \u03b3) \u221d J\u220f j=1 \u03b2 \u03b3 J\u22121 j J\u220f j\u2032=1 \u0393(\u03b1\u03b2j\u2032 + njj\u2032 + qjj\u2032) \u0393(\u03b1\u03b2j\u2032) . (54)\nFollowing (Teh et al., 2006), we can write the ratios of Gamma functions as polynomials in \u03b2j , as\np(\u03b2 | z,u,Q, \u03b1, \u03b3) \u221d J\u220f j=1 \u03b2 \u03b3 J\u22121 j J\u220f j\u2032=1 njj\u2032\u2211 mjj\u2032=1 s(njj\u2032 + qjj\u2032 ,mjj\u2032)(\u03b1\u03b2j\u2032) mjj\u2032 (55)\nwhere s(m,n) is an unsigned Stirling number of the first kind, which is used to represent the number of permutations of n elements such that there are m distinct cycles.\nThis admits an augmented data representation, where we introduce a random matrix M = (mjj\u2032)1\u2264j,j\u2032\u2264J , whose entries are conditionally independent given \u03b2, Q and z, with\np(mjj\u2032 = m |\u03b2j\u2032 , \u03b1, njj\u2032 , qjj\u2032) = s(njj\u2032 + qjj\u2032 ,m)\u03b1 m\u03b2mj\u2032\u2211njj\u2032+qjj\u2032 m\u2032=0 s(njj\u2032 + qjj\u2032 ,m \u2032)\u03b1m\u2032\u03b2m \u2032 j\u2032\n(56)\nfor integer m ranging between 0 and njj\u2032 + qjj\u2032 . Note that s(n, 0) = 0 if n > 0, s(0, 0) = 1, s(0,m) = 0 if m > 0, and we have the recurrence relation s(n + 1,m) = ns(n,m) + s(n,m \u2212 1), and so we could compute each of these coefficients explicitly; however, it is typically simpler and more computationally efficient to sample from this distribution by simulating the number of occupied tables in a Chinese Restaurant Process with n customers, than it is to enumerate its probabilities.\nFor each mjj\u2032 we simply draw njj\u2032 assignments of customers to tables according to the Chinese Restaurant Process and set mjj\u2032 to be the number of distinct tables realized; that is, assign the first customer to a table, setting mjj\u2032 to 1, and then, after n customers are assigned, assign the n+ 1th customer to a new table with probability \u03b1\u03b2j\u2032/(n+\u03b1\u03b2j\u2032), in which case we increment mjj\u2032 , and to an existing table with probability n/(n+ \u03b1), in which case we do not increment mjj\u2032 .\nThen, we have joint distribution\np(\u03b2,M | z,u,Q, \u03b1, \u03b3) \u221d J\u220f j=1 \u03b2 \u03b3 J\u22121 j J\u220f j\u2032=1 s(njj\u2032 + qjj\u2032 ,mjj\u2032)\u03b1 mjj\u2032\u03b2 mjj\u2032 j\u2032 (57)\nwhich yields (55) when marginalized over M. Again discarding constants in \u03b2 and regrouping yields\np(\u03b2 |M, z, u, \u03b8, \u03b1, \u03b3) \u221d J\u220f\nj\u2032=1\n\u03b2 \u03b3 J+m\u00b7j\u2032\u22121 j\u2032 (58)\nwhich is Dirichlet: \u03b2 |M,\u03b3 \u223c Dirichlet( \u03b3\nJ +m\u00b71, . . . ,\n\u03b3 J +m\u00b7J) (59)\nSampling \u03b1 and \u03b3 Assume that \u03b1 and \u03b3 have Gamma priors, parameterized by shape, a and rate, b:\np(\u03b1) = ba\u03b1\u03b1\n\u0393(a\u03b1) \u03b1a\u03b1\u22121 exp(\u2212b\u03b1\u03b1) (60)\np(\u03b3) = b a\u03b3 \u03b3\n\u0393(a\u03b3) \u03b3a\u03b3\u22121 exp(\u2212b\u03b3\u03b3) (61)\nHaving integrated out \u03c0, we have\np(\u03b2, z,u,Q,M |\u03b1, \u03b3,\u03c6) = \u0393(\u03b3) \u0393( \u03b3J ) J \u03b1m\u00b7\u00b7 J\u220f j=1 \u03b2 \u03b3 J+m\u00b7j\u22121 j \u0393(nj\u00b7) \u22121u\u22121j (1 + uj) \u2212\u03b1 ( uj 1 + uj )nj\u00b7+qj\u00b7 (62)\n\u00d7 J\u220f\nj\u2032=1\ns(njj\u2032 + qjj\u2032 ,mjj\u2032)\u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (63)\nWe can also integrate out \u03b2, to yield\np(z,u,Q,M |\u03b1, \u03b3,\u03c6) = \u03b1m\u00b7\u00b7e\u2212 \u2211 j\u2032\u2032 log(1+uj\u2032\u2032 )\u03b1 \u0393(\u03b3)\n\u0393(\u03b3 +m\u00b7\u00b7) (64)\n\u00d7 \u220f j \u0393( \u03b3J +m\u00b7j) \u0393( \u03b3J )\u0393(nj\u00b7) u\u22121j ( uj 1 + uj )nj\u00b7+qj\u00b7 (65) \u00d7 J\u220f\nj\u2032=1\ns(njj\u2032 + qjj\u2032 ,mjj\u2032)\u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032 (qjj\u2032 !) \u22121 (66)\ndemonstrating that \u03b1 and \u03b3 are independent given \u03c6 and the augmented data, with\np(\u03b1 | z,u,Q,M) \u221d \u03b1a\u03b1+m\u00b7\u00b7 exp(\u2212(b\u03b1 + \u2211 j log(1 + uj))\u03b1) (67)\nand\np(\u03b3 | z,u,Q,M) \u221d \u03b3a\u03b3\u22121 exp(\u2212b\u03b3\u03b3) \u0393(\u03b3)\n\u220fJ j=1 \u0393( \u03b3 J +m\u00b7j)\n\u0393( \u03b3J ) J\u0393(\u03b3 +m\u00b7\u00b7)\n(68)\nSo we see that \u03b1 | z,u,Q,M \u223c Gamma(a\u03b1 +m\u00b7\u00b7, b\u03b1 + \u2211 j log(1 + uj)) (69)\nTo sample \u03b3, we introduce a new set of auxiliary variables, r = (r1, . . . , rJ) and w with the following distributions:\np(rj\u2032 = r |m\u00b7j\u2032 , \u03b3) = \u0393( \u03b3J )\n\u0393( \u03b3J +m\u00b7j\u2032) s(m\u00b7j\u2032 , r)\n( \u03b3 J )r r = 1, . . . ,m\u00b7j (70)\np(w |m\u00b7\u00b7\u03b3) = \u0393(\u03b3 +m\u00b7\u00b7)\n\u0393(\u03b3)\u0393(m\u00b7\u00b7) w\u03b3\u22121(1\u2212 w)m\u00b7\u00b7\u22121 w \u2208 (0, 1) (71)\nso that\np(\u03b3, r, w |M) \u221d \u03b3a\u03b3\u22121 exp(\u2212b\u03b3\u03b3)w\u03b3\u22121(1\u2212 w)m\u00b7\u00b7\u22121 J\u220f\nj\u2032=1\ns(m\u00b7j\u2032 , rj\u2032) ( \u03b3 J )rj\u2032 (72)\nand\np(\u03b3 | r, w) \u221d \u03b3a\u03b3+r\u00b7\u22121 exp(\u2212(b\u03b3 \u2212 log(w))\u03b3), (73)\nwhich is to say \u03b3 | r, w, z,u,Q,M \u223c Gamma(a\u03b3 + r\u00b7, b\u03b3 \u2212 log(w)) (74)"}, {"heading": "C. Derivation of \u03b7 update in the Cocktail Party and Synthetic Data Experiments", "text": "In principle, \u03b7 can have any distribution over binary vectors, but we will suppose for simplicity that it can be factored into D independent coordinate-wise Bernoulli variates. Let \u00b5d be the Bernoulli parameter for the dth coordinate.\nThe similarity function \u03c6jj\u2032 is the Laplacian kernel:\n\u03c6jj\u2032 = \u03a6(\u03b7j ,\u03b7j\u2032) = exp(\u2212\u03bbdjj\u2032) (75)\nwhere djj\u2032d = \u2223\u2223\u03b7jd \u2212 \u03b7j\u2032d\u2223\u2223 is Hamming distance in the dth coordinate, djj\u2032 := \u2211Dd=1 djj\u2032 is the total Hamming distance between \u03b7j and \u03b7j\u2032 , and \u03bb \u2265 0 (if \u03bb = 0, the \u03c6jj\u2032 are identically 1, and so do not have any influence, reducing the model to an ordinary HDP-HMM).\nLet\n\u03c6jj\u2032\u2212d = exp(\u2212\u03bb(djj\u2032 \u2212 djj\u2032d)) (76)\nso that \u03c6jj\u2032 = \u03c6jj\u2032\u2212de\u2212\u03bbdjj\u2032d .\nSince the matrix \u03c6 is assumed to be symmetric, we have\np(z,Q | \u03b7jd = 1,\u03b7 \\ \u03b7jd) p(z,Q | \u03b7jd = 0,\u03b7 \\ \u03b7jd) \u221d \u220f j\u2032 6=j e\u2212\u03bb(njj\u2032+nj\u2032j)|1\u2212\u03b8j\u2032d|(1\u2212 \u03c6jj\u2032\u2212de\u2212\u03bb|1\u2212\u03b8j\u2032d|)qjj\u2032+qj\u2032j e\u2212\u03bb(njj\u2032+nj\u2032j)|\u03b8j\u2032d|(1\u2212 \u03c6jj\u2032\u2212de\u2212\u03bb|\u03b8j\u2032d|)qjj\u2032+qj\u2032j (77)\n= e\u2212\u03bb(cjd0\u2212cjd1) \u220f j\u2032 6=j ( 1\u2212 \u03c6jj\u2032\u2212de\u2212\u03bb 1\u2212 \u03c6jj\u2032\u2212d )(\u22121)\u03b8j\u2032d (qjj\u2032+qj\u2032j) (78)\nwhere cjd0 and cjd1 are the number of successful jumps to or from state j, to or from states with a 0 or 1, respectively, in position d. That is, cjd0 = \u2211\n{j\u2032 | \u03b8j\u2032d=0}\nnjj\u2032 + nj\u2032j cjd1 = \u2211\n{j\u2032 | \u03b8j\u2032d=1}\nnjj\u2032 + nj\u2032j (79)\nTherefore, we can Gibbs sample \u03b7jd from its conditional posterior Bernoulli distribution given the rest of \u03b7, where we compute the Bernoulli parameter via the log-odds\nlog ( p(\u03b7jd = 1 |Y, z,Q,\u03b7 \\ \u03b7jd) p(\u03b7jd = 0 |Y, z,Q,\u03b7 \\ \u03b7jd) ) = log ( p(\u03b7jd = 1)p(z,Q | \u03b7jd = 1,\u03b7 \\ \u03b7jd)p(Y | z, \u03b7jd = 1,\u03b7 \\ \u03b7jd) p(\u03b7jd = 0)p(z,Q | \u03b7jd = 0,\u03b7 \\ \u03b7jd)p(Y | z, \u03b7jd = 0,\u03b7 \\ \u03b7jd) ) (80)\n= log\n( \u00b5d\n1\u2212 \u00b5d\n) + (cjd1 \u2212 cjd0)\u03bb+ \u2211 j\u2032 6=j (\u22121)\u03b8j\u2032d(qjj\u2032 + qj\u2032j) log ( 1\u2212 \u03c6(\u2212d)jj\u2032 e\u2212\u03bb 1\u2212 \u03c6(\u2212d)jj\u2032 ) (81)\n+ \u2211\n{t | zt=j}\nlog ( f(yt; \u03b7jd = 1,\u03b7j \\ \u03b7jd) f(yt; \u03b7jd = 0,\u03b7j \\ \u03b7jd) ) (82)\nSuppose also that the observed data Y consists of a T \u00d7 K matrix, where the tth row yt = (yt1, . . . , ytK)T is a Kdimensional feature vector associated with time t, and let W be a D \u00d7 K weight matrix with kth column wk, such that\nf(yt;\u03b7j) = g(yt; W T\u03b7j) (83)\nfor a suitable parametric function g. We assume for simplicity that g factors as\ng(yt; W T\u03b7j) = K\u220f k=1 gk(ytk; wk \u00b7 \u03b7j) (84)\nDefine xtk = wk \u00b7 \u03b8zt , and x (\u2212d) tk = w \u2212d k \u00b7 \u03b8\u2212dzt , where \u03b8 \u2212d j and w \u2212d k are \u03b8j and wk, respectively, with the dth coordinate removed. Then\nlog ( f(yt; \u03b7jd = 1,\u03b7j \\ \u03b7jd) f(yt; \u03b7jd = 0,\u03b7j \\ \u03b7jd) ) = K\u2211 k=1 log ( gk(ytk;x (\u2212d) tk + wdk) gk(ytk;x (\u2212d) tk ) ) . (85)\nIf gk(y;x) is a Normal density with mean x and unit variance, then\nlog\n( gk(ytk;x (\u2212d) tk + wdk)\ngk(ytk;x (\u2212d) tk )\n) = \u2212wdk(ytk \u2212 x(\u2212d)tk + 1\n2 wdk) (86)"}, {"heading": "D. Derivation of HMC update for ` in the Bach Chorale Experiment", "text": "We have a set of states with parameters `j , j = 1, . . . , J . In the previous version of the model, `j was a binary state vector on which both the similarities \u03c6jj\u2032 and the emission distribution Fj depended. Here, we define the latent locations `j = (`j1, `jD) to be locations in RD, independent of the emission distributions, so that during inference they are informed solely by the transitions.\nWe set\n\u03c6jj\u2032(`j , `j\u2032) = exp\n( \u2212\u03bb\n2 d2jj\u2032 ) where djj\u2032 is the Euclidean distance between `j and `j\u2032 ; that is,\nd2jj\u2032 = \u2211 d (`jd \u2212 `j\u2032d)2\nSince now `j are continuous locations, we use Hamlitonian Monte Carlo (Duane et al., 1987; Neal et al., 2011) to sample them jointly. HMC is a variation on Metropolis-Hastings algorithm which is designed to more efficiently explore a highdimensional continuous distribution by adopting a proposal distribution which incorporates an auxiliary \u201cmomentum\u201d variable to make it more likely that proposals will go in useful directions and improve mixing compared to naive movement.\nTo do Hamiltonian Monte Carlo to sample from the conditional posterior of ` given z and Q, we need to compute the gradient of the log posterior, which is just the sum of the gradient of the log prior and the gradient of the log likelihood.\nAssume independent and isotropic Gaussian priors on each `j , so we have\np(`j) \u221d exp ( \u2212h`\n2 \u2211 d `2jd\n) ,\nwhere h` is the prior precision which does not depend on d.\nThen the log prior density, up to an additive constant c, is\nlog p(`j) = c\u2212 h` 2 \u2211 d `2jd\nThe relevant log likelihood is the log of the probability of the z and Q variables given the \u03c6jj\u2032 . In particular, we have\nL := p(z,Q |\u03c6) \u221d \u220f j \u220f j\u2032 \u03c6 njj\u2032 jj\u2032 (1\u2212 \u03c6jj\u2032) qjj\u2032\nso that logL = \u2211 j \u2211 j\u2032 (njj\u2032 log(\u03c6jj\u2032) + qjj\u2032 log(1\u2212 \u03c6jj\u2032))\nThe j, d coordinate of the gradient of the log prior is simply \u2212h``jd.\nTo get the j, d coordinate of the gradient of the log likelihood, we can apply the chain rule to terms as is convenient. In particular,\n\u2202L \u2202`jd = \u2211 j \u2211 j\u2032 njj\u2032 \u2202 log(\u03c6jj\u2032) \u2202d2jj\u2032 \u2202d2jj\u2032 \u2202`jd + \u2211 j \u2211 j\u2032 qjj\u2032 \u2202 log(1\u2212 \u03c6jj\u2032) \u2202(1\u2212 \u03c6jj\u2032) \u2202(1\u2212 \u03c6jj\u2032) \u2202d2jj\u2032 \u2202d2jj\u2032 \u2202`jd\nWe have the following components:\n\u2202 log(\u03c6jj\u2032) \u2202d2jj\u2032 = \u2212\u03bb 2\n\u2202d2jj\u2032 \u2202`jd = 2djj\u2032dI(j 6= j\u2032)\n\u2202 log(1\u2212 \u03c6jj\u2032) \u2202(1\u2212 \u03c6jj\u2032) = 1\n1\u2212 \u03c6jj\u2032 \u2202(1\u2212 \u03c6jj\u2032) \u2202d2jj\u2032 = \u03bb 2 \u03c6jj\u2032\nwhich yields\n\u2202L\n\u2202`jd = \u2212\u03bb \u2211 j \u2211 j\u2032 njj\u2032djj\u2032dI(j 6= j\u2032) + \u03bb \u2211 j \u2211 j\u2032 qjj\u2032djj\u2032d \u03c6jj\u2032 1\u2212 \u03c6jj\u2032 I(j 6= j)\n= \u2212\u03bb \u2211\n(j,j\u2032):j 6=j\u2032 djj\u2032d\n( njj\u2032 \u2212 qjj\u2032 \u03c6jj\u2032\n1\u2212 \u03c6jj\u2032\n)"}], "references": [{"title": "The infinite hidden Markov model", "author": ["Beal", "Matthew J", "Ghahramani", "Zoubin", "Rasmussen", "Carl E"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Beal et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Beal et al\\.", "year": 2001}, {"title": "Hybrid monte carlo", "author": ["Duane", "Simon", "Kennedy", "Anthony D", "Pendleton", "Brian J", "Roweth", "Duncan"], "venue": "Physics letters B,", "citeRegEx": "Duane et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Duane et al\\.", "year": 1987}, {"title": "Population genetics theory \u2013 the past and the future", "author": ["Ewens", "Warren John"], "venue": "In Mathematical and Statistical Developments of Evolutionary Theory,", "citeRegEx": "Ewens and John.,? \\Q1990\\E", "shortCiteRegEx": "Ewens and John.", "year": 1990}, {"title": "MCMC for normalized random measure mixture models", "author": ["Favaro", "Stefano", "Teh", "Yee Whye"], "venue": "Statistical Science,", "citeRegEx": "Favaro et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Favaro et al\\.", "year": 2013}, {"title": "A Bayesian analysis of some nonparametric problems", "author": ["Ferguson", "Thomas S"], "venue": "The annals of statistics,", "citeRegEx": "Ferguson and S.,? \\Q1973\\E", "shortCiteRegEx": "Ferguson and S.", "year": 1973}, {"title": "An HDP-HMM for systems with state persistence", "author": ["Fox", "Emily B", "Sudderth", "Erik B", "Jordan", "Michael I", "Willsky", "Alan S"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Fox et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fox et al\\.", "year": 2008}, {"title": "The infinite factorial hidden Markov model", "author": ["Gael", "Jurgen V", "Teh", "Yee W", "Ghahramani", "Zoubin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gael et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gael et al\\.", "year": 2009}, {"title": "Infinite latent feature models and the Indian buffet process", "author": ["Ghahramani", "Zoubin", "Griffiths", "Thomas L"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Ghahramani et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ghahramani et al\\.", "year": 2005}, {"title": "Factorial hidden Markov models", "author": ["Ghahramani", "Zoubin", "Jordan", "Michael I", "Smyth", "Padhraic"], "venue": "Machine learning,", "citeRegEx": "Ghahramani et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Ghahramani et al\\.", "year": 1997}, {"title": "Adaptive rejection sampling for Gibbs sampling", "author": ["Gilks", "Walter R", "Wild", "Pascal"], "venue": "Applied Statistics,", "citeRegEx": "Gilks et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Gilks et al\\.", "year": 1992}, {"title": "Exact and approximate sum representations for the Dirichlet process", "author": ["Ishwaran", "Hemant", "Zarepour", "Mahmoud"], "venue": "Canadian Journal of Statistics,", "citeRegEx": "Ishwaran et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ishwaran et al\\.", "year": 2002}, {"title": "Bayesian nonparametric hidden semi-Markov models", "author": ["Johnson", "Matthew J", "Willsky", "Alan S"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Johnson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2013}, {"title": "Completely random measures", "author": ["Kingman", "John"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "Kingman and John.,? \\Q1967\\E", "shortCiteRegEx": "Kingman and John.", "year": 1967}, {"title": "MCMC using Hamiltonian dynamics", "author": ["Neal", "Radford M"], "venue": "Handbook of Markov Chain Monte Carlo,", "citeRegEx": "Neal and M,? \\Q2011\\E", "shortCiteRegEx": "Neal and M", "year": 2011}, {"title": "The discrete infinite logistic normal distribution", "author": ["Paisley", "John", "Wang", "Chong", "Blei", "David M"], "venue": "Bayesian Analysis,", "citeRegEx": "Paisley et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Paisley et al\\.", "year": 2012}, {"title": "Correlated random measures", "author": ["Ranganath", "Rajesh", "Blei", "David M"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Ranganath et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ranganath et al\\.", "year": 2016}, {"title": "A constructive definition of Dirichlet processes", "author": ["Sethuraman", "Jayaram"], "venue": "Statistica Sinica,", "citeRegEx": "Sethuraman and Jayaram.,? \\Q1994\\E", "shortCiteRegEx": "Sethuraman and Jayaram.", "year": 1994}, {"title": "Hierarchical Dirichlet processes", "author": ["Teh", "Yee Whye", "Jordan", "Michael I", "Beal", "Matthew J", "Blei", "David M"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2006}, {"title": "Infinite factorial dynamical model", "author": ["Valera", "Isabel", "Ruiz", "Francisco", "Svensson", "Lennart", "Perez-Cruz", "Fernando"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Valera et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Valera et al\\.", "year": 2015}, {"title": "Beam sampling for the infinite hidden Markov model", "author": ["Van Gael", "Jurgen", "Saatci", "Yunus", "Teh", "Yee Whye", "Ghahramani", "Zoubin"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "Gael et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Gael et al\\.", "year": 2008}, {"title": "Hidden Markov models with discrete infinite logistic normal distribution priors", "author": ["Zhu", "Hao", "Hu", "Jinsong", "Leung", "Henry"], "venue": "In Information Fusion (FUSION),", "citeRegEx": "Zhu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "Introduction and Background The hierarchical Dirichlet process hidden Markov model (HDP-HMM) (Beal et al., 2001; Teh et al., 2006) is a Bayesian model for time series data that generalizes the conventional hidden Markov Model to allow a countably infinite state space.", "startOffset": 93, "endOffset": 130}, {"referenceID": 17, "context": "Introduction and Background The hierarchical Dirichlet process hidden Markov model (HDP-HMM) (Beal et al., 2001; Teh et al., 2006) is a Bayesian model for time series data that generalizes the conventional hidden Markov Model to allow a countably infinite state space.", "startOffset": 93, "endOffset": 130}, {"referenceID": 5, "context": "The Sticky HDP-HMM (Fox et al., 2008) addresses this issue by adding an extra mass \u03ba at location j to the base measure of the DP that generates \u03c0j .", "startOffset": 19, "endOffset": 37}, {"referenceID": 5, "context": "The Sticky HDP-HMM (Fox et al., 2008) addresses this issue by adding an extra mass \u03ba at location j to the base measure of the DP that generates \u03c0j . That is, (2) is replaced by \u03c0j \u223c DP(\u03b1G0 + \u03ba\u03b4\u03b8j ). (5) An alternative approach that treats self-transitions as special is the HDP Hidden Semi-Markov Model (HDPHSMM; Johnson & Willsky (2013)), wherein state duration distributions are modeled separately, and ordinary selftransitions are ruled out.", "startOffset": 20, "endOffset": 338}, {"referenceID": 8, "context": "Factorial HMMs (Ghahramani et al., 1997) are commonly used in this setting, but this ignores dependence among chains, and hence may do poorly when some combinations of states are much more probable than suggested by the chain-wise dynamics.", "startOffset": 15, "endOffset": 40}, {"referenceID": 12, "context": "A rescaling and renormalization approach similar to the one used in the HDP-HMM-LT is used by Paisley et al. (2012) to define their Discrete Infinite Logistic Normal (DILN) model, an instance of a correlated random measure (Ranganath & Blei, 2016), in the setting of topic modeling.", "startOffset": 94, "endOffset": 116}, {"referenceID": 12, "context": "A rescaling and renormalization approach similar to the one used in the HDP-HMM-LT is used by Paisley et al. (2012) to define their Discrete Infinite Logistic Normal (DILN) model, an instance of a correlated random measure (Ranganath & Blei, 2016), in the setting of topic modeling. There, however, the contexts and the mixture components (topics) are distinct sets, and there is no notion of temporal dependence. Zhu et al. (2016) developed an HMM based directly on the DILN model1.", "startOffset": 94, "endOffset": 432}, {"referenceID": 14, "context": "It has been shown (Ferguson, 1973; Paisley et al., 2012; Favaro et al., 2013) that the normalization constant T is positive and finite almost surely, and thatG is distributed as a DP with base measure G0 = \u2211\u221e k=1 \u03b2k\u03b4\u03b8k .", "startOffset": 18, "endOffset": 77}, {"referenceID": 3, "context": "It has been shown (Ferguson, 1973; Paisley et al., 2012; Favaro et al., 2013) that the normalization constant T is positive and finite almost surely, and thatG is distributed as a DP with base measure G0 = \u2211\u221e k=1 \u03b2k\u03b4\u03b8k .", "startOffset": 18, "endOffset": 77}, {"referenceID": 20, "context": "The DILN-HMM (Zhu et al., 2016), employs a similar rescaling of transition probabilities via an exponentiated Gaussian Process, following (Paisley et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 14, "context": ", 2016), employs a similar rescaling of transition probabilities via an exponentiated Gaussian Process, following (Paisley et al., 2012), but the scaling function must be positive semi-definite, and in particular symmetric, whereas in the HDP-HMM-LT, \u03c6 need only take values in (0, 1].", "startOffset": 114, "endOffset": 136}, {"referenceID": 5, "context": "Sticky and Semi-Markov Generalizations We note that the local transition property of the HDPHMM-LT can be combined with the Sticky property of the Sticky HDP-HMM (Fox et al., 2008), or the nongeometric duration distributions of the HDP-HSMM (Johnson & Willsky, 2013), to add additional prior weight on self-transitions.", "startOffset": 162, "endOffset": 180}, {"referenceID": 8, "context": "Such problems are often modeled using factorial HMMs (Ghahramani et al., 1997).", "startOffset": 53, "endOffset": 78}, {"referenceID": 6, "context": "An Infinite Factorial HDP-HMM-LT Nonparametric extensions of the factorial HMM, such as the infinite factorial hidden Markov Model (Gael et al., 2009) and the infinite factorial dynamic model (Valera et al.", "startOffset": 131, "endOffset": 150}, {"referenceID": 18, "context": ", 2009) and the infinite factorial dynamic model (Valera et al., 2015), have been developed in recent years by making use of the Indian Buffet Process (Ghahramani & Griffiths, 2005) as a state prior.", "startOffset": 49, "endOffset": 70}, {"referenceID": 17, "context": "Following Teh et al. (2006), we can introduce auxiliary variables M = {mjj\u2032}, with p(mjj\u2032 |\u03b2j\u2032 , \u03b1,D) ind \u221d snjj\u2032+qjj\u2032 ,mjj\u2032\u03b1 jj\u2032\u03b2 mjj\u2032 j\u2032 (16) for integer mjj\u2032 ranging between 0 and njj\u2032 + qjj\u2032 , where sn,m is an unsigned Stirling number of the first kind.", "startOffset": 10, "endOffset": 28}, {"referenceID": 6, "context": "Following Gael et al. (2009) and Valera et al.", "startOffset": 10, "endOffset": 29}, {"referenceID": 6, "context": "Following Gael et al. (2009) and Valera et al. (2015), the weights were drawn independently from a Unif(0, 1) distribution, and independentN (0, 0.", "startOffset": 10, "endOffset": 54}, {"referenceID": 8, "context": "Results We attempted to infer the binary speaker matrices using five models: (1) a binary-state Factorial HMM (Ghahramani et al., 1997), where individual binary speaker sequences are modeled as independent, (2) an ordinary HDP-HMM without local transitions (Teh et al.", "startOffset": 110, "endOffset": 135}, {"referenceID": 17, "context": ", 1997), where individual binary speaker sequences are modeled as independent, (2) an ordinary HDP-HMM without local transitions (Teh et al., 2006), where the latent states are binary vectors, (3) a Sticky HDPHMM (Fox et al.", "startOffset": 129, "endOffset": 147}, {"referenceID": 5, "context": ", 2006), where the latent states are binary vectors, (3) a Sticky HDPHMM (Fox et al., 2008), (4) our HDP-HMM-LT model, and (5) a model that combines the Sticky and LT properties3.", "startOffset": 73, "endOffset": 91}, {"referenceID": 20, "context": "We evaluated the models at each iteration using both the We attempted to add a comparison to the DILN-HMM (Zhu et al., 2016) as well, but code could not be obtained, and the paper did not provide enough detail to reproduce their inference algorithm.", "startOffset": 106, "endOffset": 124}, {"referenceID": 1, "context": "Since the latent states are continuous, we use a Hamiltonian Monte Carlo (HMC) update (Duane et al., 1987; Neal et al., 2011) to update the `j simultaneously, conditioned on z and \u03c0 (see Appendix D for details).", "startOffset": 86, "endOffset": 125}, {"referenceID": 6, "context": "We focused on fixed-dimension binary vectors for the cocktail party and synthetic data experiments, but it would be straightforward to add the LT property to a model with nonparametric latent states, such as the iFHMM (Gael et al., 2009) and the infinite factorial dynamic model (Valera et al.", "startOffset": 218, "endOffset": 237}, {"referenceID": 18, "context": ", 2009) and the infinite factorial dynamic model (Valera et al., 2015), both of which use the Indian Buffet Process (IBP) (Ghahramani & Griffiths, 2005) as a state prior.", "startOffset": 49, "endOffset": 70}], "year": 2017, "abstractText": "We describe a generalization of the Hierarchical Dirichlet Process Hidden Markov Model (HDPHMM) which is able to encode prior information that state transitions are more likely between \u201cnearby\u201d states. This is accomplished by defining a similarity function on the state space and scaling transition probabilities by pairwise similarities, thereby inducing correlations among the transition distributions. We present an augmented data representation of the model as a Markov Jump Process in which: (1) some jump attempts fail, and (2) the probability of success is proportional to the similarity between the source and destination states. This augmentation restores conditional conjugacy and admits a simple Gibbs sampler. We evaluate the model and inference method on a speaker diarization task and a \u201charmonic parsing\u201d task using fourpart chorale data, as well as on several synthetic datasets, achieving favorable comparisons to existing models.", "creator": "LaTeX with hyperref package"}}}