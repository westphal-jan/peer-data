{"id": "1708.03993", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Aug-2017", "title": "Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm", "abstract": "with the transition from people's traditional ` brick - and - glass mortar'affordable shopping to online standard mobile home shopping patterns in web 2. 0 $ \\ mathit { era } $, the recommender system gradually plays a critical role in e - commerce and e - retails. this is especially always true when designing this system better for more retailers than $ \\ \u00b7 mathbf { + 236 ~ million } $ daily active users. ranking for strategy, the key module of the recommender system, needs to be precise, accurate, and properly responsive for estimating customers'preferred intents. we propose a dynamic dynamic ranking paradigm, named incorrectly as dnn - mab, that is composed of a pairwise underlying deep global neural matrix network ( dnn ) $ \\ mathit { pre } $ - ranker tag connecting a revised multi - armed bandit ( mab ) dynamic $ \\ mathit { post } $ - ranker. by taking values into account of explicit and implicit user feedbacks such as impressions, clicks, conversions, etc. dnn - ba mab is able to adjust dnn $ \\ mathit { pre } $ - ranking scores available to assist busy customers locating items they are interested in most attributes so that ensure they can converge quickly and frequently. to the best of our knowledge, frameworks like dnn - mab have not been discussed in the previous literature to either e - commerce or machine learning audiences. in practice, dnn - mab has been deployed to assess production decisions and it easily outperforms against other state - of - the - art models by hence significantly lifting the gross merchandise volume ( < gmv ) which is the objective metrics applied at a jd.", "histories": [["v1", "Mon, 14 Aug 2017 02:33:53 GMT  (7227kb,D)", "http://arxiv.org/abs/1708.03993v1", "7 pages, 7 figures, accepted by 'IJCAI-17 Workshop AI Applications in E-Commerce'"]], "COMMENTS": "7 pages, 7 figures, accepted by 'IJCAI-17 Workshop AI Applications in E-Commerce'", "reviews": [], "SUBJECTS": "cs.AI cs.IR", "authors": ["yan yan", "wentao guo", "meng zhao", "jinghe hu", "weipeng p yan"], "accepted": false, "id": "1708.03993"}, "pdf": {"name": "1708.03993.pdf", "metadata": {"source": "CRF", "title": "Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm", "authors": ["Wentao Guo", "Meng Zhao", "Jinghe Hu", "Weipeng P. Yan", "Yan Yan"], "emails": ["yan.yan}@jd.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "Effectively generating the right list of items for customers is the key to the success of E-Commerce websites and applications. How fast and how frequent the customers could converge (place orders) decide if the E-Commerce company would thrive. The recommender system, an information filtering, rating, and recommending engine that assists users to reach a small group of items that describe and satisfy their purchasing needs in real time, is emerged for solving this challenge.\nFounded in 2004, JD has quickly ascended into one of the most popular E-Commerce websites in China. Customers come to JD to discover, browse and purchase items sold by\nitself as well as over hundreds of thousands other government certificated E-Retailers. Everyday tens of millions of users generate billions of querying requests, place tens of millions of orders. At the same time, the statistics shows that in average the active users visit only limited number of items from specific positions like the front page, topic driven recommending sections in JD\u2019s app. (Fig.1 presents two type of layout). Therefore, despite the huge amount of serving loads, the number of ranked items presented to users are actually small, the recommender system at JD must provide robust, agile and accurate recommendation service to make sure conversion happens frequently in every user\u2019s item browsing experience.\nThe ranking module decides how the final list of items from the retrieval should be generated and positioned so that the items interest the customers most are placed first. As a result, the ranking problem is always the centric issue of the recommender system. In the use case of E-commerce recommendations, people mine each customer\u2019s information including search-history, clicks, orders, etc. to model customers\u2019 purchasing intent across the whole platform.\nTraditional ranking modules in recommender systems are not as efficient regarding with learning the users\u2019 intent and behavioral feebacks while they browse the ranked items. This is due to the fact that most of the ranking results in the ECommerce apps come in a fashion of the waterflow streaming. Traditional ranking ideas usually have difficulties to incorporate the users\u2019 real time feedbacks so that the results are either not not precise enough or in the extreme cases not legitimate anymore (e.g. the static ranking results still promote items that users just clicked or placed orders on, based on recent behavioral histories). In this paper, we propose an innovative dynamic ranking paradigm. By combining the deep learning model and the multi-armed dandit algorithm together, this framework is capable of learning customers\u2019 real time feedbacks so to change the ranking results for reflectng users\u2019 current purchasing intent and improving the overall recommender system performance."}, {"heading": "1.1 Contributions", "text": "This paper has two primary contributions in research and industry:\n1. an innovative ranking paradigm for solving the dynamic ranking problem by combining the pairwise deep neural\nar X\niv :1\n70 8.\n03 99\n3v 1\n[ cs\n.A I]\n1 4\nA ug\n2 01\n7\nnetwork and multi-armed bandit algorithms; 2. a revised Thompson sampling algorithm with the brand\nnew initialization strategy under the production use case that enables the customers\u2019 fast convergence."}, {"heading": "1.2 Organization", "text": "The rest of this paper is organized as follows: Sec.2 briefly describes the recommender system utilized in JD and discusses the ranking module in detail: 2.3 learning-to-rank DNN module as the pre-ranker and 2.4 MAB Thompson sampling as the post-ranker; Sec.3 first discusses a simple case study which simulates the real world for testing how Thompson sampling works comparing with other popular MAB algorithms and then reports the proposed DNN-MAB performance regarding with different metrics; Sec.4 discusses some prominent related studies regarding with recommender systems, learning-to-rank via deep neural network models and multi-armed bandit models; we summarize our work and point out some future directions in Sec.5."}, {"heading": "2 FORMULATION", "text": ""}, {"heading": "2.1 System design", "text": "Our recommender system in Fig.2 includes three main function modules: the item-retrieval module, the item post-\nretrieval module, and the ranking module. Users typically trigger the recommender system via directing from the mobile application entry point or from our mobile version websites. After the system indicates users\u2019 identities, the recommender issues a query request to the user database and the item database to fetch other information regarding with user profiles such like: gender, geo location, purchasing history, price sensitivity etc. This piece of information combining with the items that the users have either recently clicked or put in carts are collected and serve as the input of the retrieval system. Next, the retrieval system selects a large pool of candidate items that are related to the input.\nThe motivation for the post-retrieval module is to filter out items that are not suitable for recommending, including items that users have already purchased, items containing sensitive contents, and other disqualified items etc.\nThe ranking module compares all candidate items provided from the post-retrieval module and generate the final top-K item sublist. Such list of items should be optimized so that the items that users interested in most should be placed at top positions. Generally this is achieved by sophisticated machine learning models such as Factorization Machines [Rendle, 2010], pairwise learning-to-rank [Burges et al., 2005; Severyn and Moschitti, 2015], listwise learning-to-rank [Cao et al., 2007], etc. In our use case, the ranking module is implemented by a pairwise loss learning-to-rank DNN and a revised MAB Thompson sampling."}, {"heading": "2.2 Input data", "text": "We now formally propose the ranking problem. Assuming that each sample is indicated as a m-dimentional feature vector \u03be \u2208 Rm coming from a certain category c \u2208 R1, with their gmv \u2208 R1. By given a set of items TN = {\u03be}N and a template triggering item \u03betem, a subset of K items are selected from TN and ordered in a particular way {\u03be1, \u03be2, . . . , \u03beK} so that the dcg of the sublist\u2019s GMV is optimized:\ndcgK = K\u2211 i=1 gmviI(\u03bei) log2(i+ 1)\n(1)\nHere, I(\u03be) is the indicator function such that: I(\u03be) {\n1 \u03be ordered by user 0 \u03be not ordered by user\n(2)\n2.3 learning-to-rank DNN pre-ranker The learning-to-rank DNN model is to compute the pairwise loss for ranking different items based upon the label information of whether users have ordered/ not-ordered certain items. The simplified model structure is shown as Fig.3. It is implemented by two miorring 5-layers DNNs: one input layer which takes item features that are sparsem-dimensional vectors, three fully-connected layers that generalize item features x, and one output layer w [Basak et al., 2007; Cherkassky and Ma, 2004] which outputs ys serving as the pre-ranker regression scores. Noting that both DNNs share the same set of parameters.\nLH = \u2211Ni=1\u03bb(x1i,x2i)max(0,m\u2212 (y1i \u2212 y2i)(t1i \u2212 t2i)) y = xTw (3)\nThe loss function LH in Eq.3 is inspired by SVM-rank [Elisseeff et al., 2001], where x1i and x2i are the pair of item features labeled as t1i and t2i. The label t is valued as either 0 (negative) or 1 (positive). Each pair is generated in such a way that only one out of two items is from the positive class: t1i + t2i = 1. m is the tunning parameter representing the classification margin making sure that the better separability between two classes is preferred. \u03bb(\u00b7, \u00b7) is the pairwise weighting function that emphasizes the losses from pairs of greater gmv values.\nIn the training phase, N positive and negative item pairs input to both sides of the DNN models shown as the of Fig.3 (L), since both DNNs are sharing the same parameters, learning-to-rank DNNs learn from the pair-labeling difference and aim to find the scoring scheme that correctly classifies items with the largest margin.\nIn the testing phase, each item from TN passes through the predictor (Fig.3 (R)), and is evaluated and scored by learningto-rank DNN. The pre-ranker scores yis are then served as the candidate scores for the MAB post-ranker.\n2.4 Multi-armed bandit post-ranker The reasons for designing the MAB post-ranker are mainly the following three:\n1. the real-time \u2018click\u2019 and \u2018order\u2019 types of labels represent the user\u2019s current purchasing intent out of many other recent intents and it should be emphasized in rankings;\n2. the real-time \u2018no-action\u2019 labels indicate item categories that the user is not currently interested in and they should be de-emphasized in rankings;\n3. users tend to click items under the same category and place orders by comparing them over different attributes.\nThe first and second reasons are well discussed in [Radlinski et al., 2008] by stating that static rankings contain lots of redundant results. The MAB post-ranker is to emphasize items that users are potentially interested in by referencing other items clicked; de-emphasize items that users are intentionally ignored, meanwhile exploring items from different categories to diversify the ranking results.\nWe follow the problem settings of the contextual multiarmed bandit problem in [Langford and Zhang, 2008], and define the problem as follows:\nDefinition 2.4.1 (Contextual bandit in DNN-MAB) Given M arms CM = {c1, c2, . . . , cM}, and a set of items TN = {x}N scored from learning-to-rank DNN that each item belongs to exactly one out of M arms. The player needs to pull one arm ci \u2208 CM at each round i, so that the item xi from that arm is picked up and placed at position i. The reward at round i is observed as gmviI(xi). Ideally, we would like to choose the actions so that the total rewards are maximized.\nDefinition 2.4.2 (Rewards in DNN-MAB) The expected rewards are defined as the total GMV generated from the listed items that users place orders on. In general it shall be translated into the company\u2019s operating revenue:\nRe = K\u2211 i=1 gmvjiI(xji) (4)\nwhere {xj1, xj2, . . . , xjK} is the ranked sublist from TN which is co-decided by both DNN and MAB.\nThe revised Thompson sampling algorithm is triggered after learning-to-rank DNN pre-ranker and we describe it in Algo.1. The main idea of Algo.1 is to take the pre-ranker\u2019s output as the initial static ranking and finetune the local orders via users\u2019 online feedbacks so to reflect the current user purchasing intent in the final ranking. Some important parameters are highlighted as follows: SCALE is to adjust the intensity from negative feedbacks, alleviating the potential issue with the treatment that most items of no-actions are seen as negative; \u03b81, \u03b82, \u03b83 are to control the weights for how much the pre-ranking scores are to be changed; Uc is the set of items from arm c that have not yet been selected; Ec is the set of items from arm c that are presented but not clicked by users during post-ranking; Ac is the set of items that are presented and clicked; | \u00b7 |0 is the cardinality computation.\nAt round i, DNN-MAB Thompson sampling randomly draws M samples {r}M based upon the M beta distributions estimated, and then selects the arm with the max ri and the item in that arm containing the max adjusted score yi. If it is clicked after exposure, the algorithm updates the beta distribution parameter \u03b1ci in arm ci. Otherwise the algorithm updates the beta distribution parameter \u03b2ci in arm ci."}, {"heading": "3 EXPERIMENTAL EVALUATION", "text": ""}, {"heading": "3.1 Case study", "text": "Before the real system online a/b test discussion, we first walk through a simple case study to evaluate different bandit algorithms\u2019 performance under our use cases. We picked three state-of-the-art bandit algorithms: -greedy[Watkins, 1989], Upper Confidence Bound or UCB[Auer et al., 2002], and Thompson sampling. Specifically, we simulate two versions of Thompson sampling: 1. the revised Thompson sampling with the specially designed initialization (revisedThompson) (Algo.1); 2. the normal Thompson sampling\nAlgorithm 1 post-ranker: DNN-MAB Thompson sampling 1: procedure INITIALIZATION 2: for each \u3008x, y\u3009 \u2208 TN do 3: for arm c such that x \u2208 c 4: \u03b1c = \u03b1c + y 5: \u03b2c = \u03b2c + (1\u2212 y) 6: Uc \u2190 \u3008x, y\u3009 7: avgc = \u03b1c/|Uc|0 8: procedure AT ROUND-i MAB RANKING 9: PULLING ARMS: 10: for each arm c \u2208 CM do 11: draw sample r \u223c beta(\u03b1c, \u03b2c) 12: update all y = y \u2217 (1 + r/\u03b81) for \u3008x, y\u3009 \u2208 c"}, {"heading": "13: pick \u3008xi, yi\u3009 = argmax(y,rc){\u3008x, y\u3009 \u2208 c}", "text": "14: Uc = Uci \u2212 \u3008xi, yi\u3009 15:"}, {"heading": "16: FEEDBACK:", "text": "17: if \u3008xi, yi\u3009 is exposed but not clicked then 18: Ec \u2190 \u3008xi, yi\u3009 19: \u03b2ci = \u03b2ci+(1\u2212avgci)\u2217(1\u2212exp(\u2212 |Eci |0 SCALE ))\u2217\u03b82 20: if \u3008xi, yi\u3009 is exposed and clicked then 21: Aci \u2190 \u3008xi, yi\u3009 22: \u03b1ci = \u03b1ci + avgci \u2217 (\n|Aci |0 |Eci |0 ) \u2217 \u03b83\n(normal-Thompson). The random selection is also performed serving as a naive baseline.\nIn our simulation, we design M = 5 arms and simply set each item\u2019s reward as 1 if the user clicks, 0 if the user does not click. The way we define the \u2018click\u2019 action is by presetting a thresholding probability fthreshold, once the item is selected, we randomly generate another probability fitem via the real unknown beta distribution. If fitem \u2265 fthreshold, we assume as the \u2018click\u2019 action happens, otherwise we assume the customer is not interested in the item selected at this round.\nWe perform the simulation 10 times and each simulation keeps running over 10, 000 rounds. The average performance is shown in Fig.4 & 5. The left subfigures of Fig.4 & 5 are about the cumulative gains / regrets and the right ones are their zoom-ins. As shown, -greedy remains sub-optimal regarding with both rewards and regrets, UCB and normalThompson perform almost equally well, and the revisedThompson performs the best by beating UCB and normalThompson with faster convergence. This is due to the fact that the revised-Thompson\u2019s initialization phase personalizes the arms based upon the user information. Hence, revisedThompson could converge in less steps relative to other standard MAB algorithms. The random selection no-surpisingly performs the worst among the five. Implementation-wise, the revised-Thompson is also straightforward and the overall system latency remains low (reported in Sec.3.4). With the above arguments, the revised-Thompson becomes the choice of our post-ranker module."}, {"heading": "3.2 Experiment setup", "text": "JD processes billions of requests in a daily basis, any new models about to launch have to be evaluated by JD\u2019s online\ntesting platform. It divides the real traffics into 10 buckets, each bucket gets about 8% of the total traffics, and the remaining 20% is held by the control bucket.\nWe deploy the proposed dynamic ranking paradigm on this platform for 7 days, and track following metrics: GMV, order numbers, overall (Eq.1) and page-wise (Eq.5) discounted cumulative gains (dcg).\ndcgp,page\u2212k = i=p\u2211 i=1,k\u2208page gmvkiI(xki) log2(i+ 1)\n(5)\nSince the item lists are presented to users in a page-wise fashion and each page contains 4 - 20 items, page-wise dcgp is a perfect metric for evaluating how is the revisedThompson module functioning in the application and how much gains we observed should be credited to it (we use p = 8 in the evaluation)."}, {"heading": "3.3 Production performance", "text": "We report the performance between DNN-MAB and DNNrt-ft as the baseline in Tab.1. DNN-rt-ft is to utilize the DNN pre-ranker by taking both offline users\u2019 feedbacks, online browsing and click signals as features for training a nearline model that is better than models taking offline signals only. In average we see DNN-MAB\u2019s daily GMV has increased 16.69% over DNN-rt-ft. Any performance gains that are greater than 1.0% over 7 days are considered statistically significant in the real production system. DNN-MAB paradigm has clearly proved its superiority against the current production DNN-rt-ft ranking strategy. To emphasize the importance of the parameter initialization and the feeback revision in Thompson sampling, we also report DNN + normalThompson in Tab.2. Due to the space limitation, we do not\ngo to the very details but simply put our conclusion that DNN + normal-Thompson in general will not beat DNN-rt-ft because it can not learn users online behaviors quickly enough to improve the ranking quality. We also report the overall dcg gains in Tab.3 and page-wise dcg gains in Tab.4. At the first glance, it seems that DNN-MAB beats the production baseline consistently in terms of overall dcg as well as page-wise dcg. By taking a closer look at the page-wise dcg comparison (Fig.6) and the MAB-DNN page-wise dcg gains in percentage (Fig.7), we find that the revised-Thompson is able to effectively learn the users\u2019 intent. Due to the fact that the revised-Thompson takes each user\u2019s recent behaviors for the personalized initialization and keeps tracking the real-time user browsing signals for the dynamic ranking adjustment. Although the page-wise percentage gains are not quite visible at the page-1 (+1.47%), the dynamic ranking performances are maximized at page-2 (+9.96%) and page3 (+8.90%), and then deminish along with users browsing more and more pages. In the end DNN-MAB and DNN-rt-ft both end up with similar page-wise performances at page-7 (+1.54%) and page-8 (+1.34%)."}, {"heading": "3.4 System specifications", "text": "Our current DNN-MAB ranking system is maintained by hundreds of Linux servers1, the qps (query per second) is 32\n1We could not release this piece of information regarding with the exact number of operating servers due to the company confidentiality.\nin average (peak at 52), and the overall recomendation end-toend response latency is within 50.0 milli-seconds (including both retrieval and ranking phases)."}, {"heading": "4 RELATED WORK", "text": ""}, {"heading": "4.1 Recommender system", "text": "The recommender system is the key to the success of E-Commerce websites as well as other indexing service providers, such as Alibaba, Ebay, Google, Baidu, Youtube, etc. Efforts from different parties regarding with how the recommender systems should be designed include [Linden et al., 2003; Davidson et al., 2010; Schafer et al., 2001; Sarwar et al., 2000]. There are in general two streams of works in the recommender system researches: contentbased approaches and item-based approaches. Item-based approaches represent users and items as a huge M by N matrix and focus on learning the underlying relations between items. Works of item-based approaches such like [Sarwar et al., 2001; Rendle et al., 2010]have all received enormous success. Yet item-based approaches suffer from issues like cold-start, scalability and plasticity, etc. Content based approaches treat the problem as the query-indexing problem, which in general, scales better and performs well\nfor cases that users do not have too many previous actions in records but it tends to have query generalization issues for users with many behavior histories. [Burke, 2002; Lops et al., 2011] both provide thorough surveys about this topic and readers should refer to them for in depth details.\n4.2 learning-to-rank via deep neural network Learning-to-rank, emerged from late 90s, has always been an interesting research topic in information retrieval. Approaches for solving this problem could be summarized into two main threads depending on the loss funtions that different approaches utilize: the pairwise loss and the listwise loss. In pairwise approaches, it has been formulated as a classification problem: item pairs are generated by picking up samples from positive and negative classes, the goal for learning-to-rank models is to correctly categorize item pairs into the binary classes, so that the loss defined is minimized. Research works in this thread include [Freund et al., 2003; Cao et al., 2006]. Listwise approaches, on the other hand, formulate the ranking problem as a classification problem on permulations. The loss will only be minimized if the whole list is perfectly ranked. Successful listwise approaches include ListNet[Cao et al., 2007] and RankCosine[Qin et al., 2008]. For more in-depth discussions regarding with learning-to-rank, please refer to [Liu and others, 2009].\nWith the growth in popularity of deep learning, people start to think of using different deep learning structures to tackle the learning-to-rank problem. Maybe the works that are most similar to our pre-ranker could be [Severyn and Moschitti, 2015; Kalchbrenner et al., 2014; Kim, 2014]. They utilized convolutional deep neural network for ranking texts in natural languarage processing problems."}, {"heading": "4.3 Contextual multi-armed bandit problems", "text": "Multi-armed bandit problem has been well studied and discussed in literatures such like [Lai and Robbins, 1985; Even-Dar et al., 2006; Auer et al., 2002] The basic setup for MAB is to select K items from M arms consecutively with feedbacks so the total expected regrets are minimized. Thompson sampling, dated back from [Thompson, 1933], albeit its simplicity, has been proved quite efficient regarding with productional performance [Tang et al., 2013; Chapelle and Li, 2011]and suprisingly straightforward to implement. Other works regarding with Thompson sampling models include [Scott, 2010]."}, {"heading": "5 CONCLUSION", "text": "We proposed a dynamic ranking framework called DNNMAB which is composed of learning-to-rank DNN preranker and revised-Thompson post-ranker. This effective ranking paradigm takes into consideration of both the user and the item information so that the DNN could reach the decent static ranking performance. Meanwhile, by tracking real time user feedbacks, the revised-Thompson sampling is able to adjust the pre-rankings that futher boosts the objective metrics. To our knowledge, such a ranking framework has not been discussed in previous researches. Real production tests show that both GMVs and dcgs have been significantly improved. However, for the sake of model simplicity, we have not paid too much attention to the position-bias which is one important factor that affects the ranking performance [Radlinski et al., 2008] in the learning-to-rank DNN pre-ranker, since bringing in the listwise loss would introduce some scalability issues in our use cases. Meanwhile we have not optimized the proposed paradigm regarding with other user behaviors such as \u2018clicks\u2019, \u2018orders\u2019, etc. either (we do observe negative moves in several days regarding with order numbers, which is reported in Tab.1). Which said, how to optimize multiple KPIs simultaniously still remains as a big challenge. We plan to further improve our ranking models along with the these research paths in the future."}, {"heading": "Acknowledgements", "text": "We are thankful to Dali Yang, Huisi Ou, Sulong Xu, Jincheng Wang, Lu Bai, Lixing Bo as well as anonymous reviewers for their helpful comments. This research has been supported in part by JD Business Growth BU and JD Santa Clara Research Center."}], "references": [{"title": "Machine learning", "author": ["Peter Auer", "Nicolo Cesa-Bianchi", "Paul Fischer. Finite-time analysis of the multiarmed bandit problem"], "venue": "47(2-3):235\u2013256,", "citeRegEx": "Auer et al.. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Neural Information Processing-Letters and Reviews", "author": ["Debasish Basak", "Srimanta Pal", "Dipak Chandra Patranabis. Support vector regression"], "venue": "11(10):203\u2013 224,", "citeRegEx": "Basak et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "In Proceedings of the 22nd international conference on Machine learning", "author": ["Chris Burges", "Tal Shaked", "Erin Renshaw", "Ari Lazier", "Matt Deeds", "Nicole Hamilton", "Greg Hullender. Learning to rank using gradient descent"], "venue": "pages 89\u201396. ACM,", "citeRegEx": "Burges et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Hybrid recommender systems: Survey and experiments", "author": ["Robin Burke"], "venue": "User modeling and user-adapted interaction, 12(4):331\u2013370,", "citeRegEx": "Burke. 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "Adapting ranking svm to document retrieval", "author": ["Cao et al", "2006] Yunbo Cao", "Jun Xu", "Tie-Yan Liu", "Hang Li", "Yalou Huang", "Hsiao-Wuen Hon"], "venue": "In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "al. et al\\.,? \\Q2006\\E", "shortCiteRegEx": "al. et al\\.", "year": 2006}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Zhe Cao", "Tao Qin", "Tie-Yan Liu", "MingFeng Tsai", "Hang Li"], "venue": "Proceedings of the 24th international conference on Machine learning, pages 129\u2013 136. ACM,", "citeRegEx": "Cao et al.. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "In Advances in neural information processing systems", "author": ["Olivier Chapelle", "Lihong Li. An empirical evaluation of thompson sampling"], "venue": "pages 2249\u2013 2257,", "citeRegEx": "Chapelle and Li. 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Neural networks", "author": ["Vladimir Cherkassky", "Yunqian Ma. Practical selection of svm parameters", "noise estimation for svm regression"], "venue": "17(1):113\u2013126,", "citeRegEx": "Cherkassky and Ma. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "The youtube video recommendation system", "author": ["Davidson et al", "2010] James Davidson", "Benjamin Liebald", "Junning Liu", "Palash Nandy", "Taylor Van Vleet", "Ullas Gargi", "Sujoy Gupta", "Yu He", "Mike Lambert", "Blake Livingston"], "venue": "In Proceedings of the fourth ACM conference on Recommender", "citeRegEx": "al. et al\\.,? \\Q2010\\E", "shortCiteRegEx": "al. et al\\.", "year": 2010}, {"title": "et al", "author": ["Andr\u00e9 Elisseeff", "Jason Weston"], "venue": "A kernel method for multi-labelled classification. In NIPS, volume 14, pages 681\u2013687,", "citeRegEx": "Elisseeff et al.. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Journal of machine learning research", "author": ["Eyal Even-Dar", "Shie Mannor", "Yishay Mansour. Action elimination", "stopping conditions for the multi-armed bandit", "reinforcement learning problems"], "venue": "7(Jun):1079\u20131105,", "citeRegEx": "Even.Dar et al.. 2006", "shortCiteRegEx": null, "year": 2006}, {"title": "Journal of machine learning research", "author": ["Yoav Freund", "Raj Iyer", "Robert E Schapire", "Yoram Singer. An efficient boosting algorithm for combining preferences"], "venue": "4(Nov):933\u2013969,", "citeRegEx": "Freund et al.. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1404.2188,", "citeRegEx": "Kalchbrenner et al.. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "arXiv preprint arXiv:1408.5882,", "citeRegEx": "Kim. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Advances in applied mathematics", "author": ["Tze Leung Lai", "Herbert Robbins. Asymptotically efficient adaptive allocation rules"], "venue": "6(1):4\u201322,", "citeRegEx": "Lai and Robbins. 1985", "shortCiteRegEx": null, "year": 1985}, {"title": "In Advances in neural information processing systems", "author": ["John Langford", "Tong Zhang. The epoch-greedy algorithm for multi-armed bandits with side information"], "venue": "pages 817\u2013824,", "citeRegEx": "Langford and Zhang. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "com recommendations: Item-to-item collaborative filtering", "author": ["Greg Linden", "Brent Smith", "Jeremy York. Amazon"], "venue": "IEEE Internet computing, 7(1):76\u201380,", "citeRegEx": "Linden et al.. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "Information Processing & Management", "author": ["Tao Qin", "Xu-Dong Zhang", "Ming-Feng Tsai", "De-Sheng Wang", "Tie-Yan Liu", "Hang Li. Querylevel loss functions for information retrieval"], "venue": "44(2):838\u2013855,", "citeRegEx": "Qin et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "In Proceedings of the 25th international conference on Machine learning", "author": ["Filip Radlinski", "Robert Kleinberg", "Thorsten Joachims. Learning diverse rankings with multi-armed bandits"], "venue": "pages 784\u2013791. ACM,", "citeRegEx": "Radlinski et al.. 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "In Proceedings of the 19th international conference on World wide web", "author": ["Steffen Rendle", "Christoph Freudenthaler", "Lars Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation"], "venue": "pages 811\u2013820. ACM,", "citeRegEx": "Rendle et al.. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "In Data Mining (ICDM)", "author": ["Steffen Rendle. Factorization machines"], "venue": "2010 IEEE 10th International Conference on, pages 995\u20131000. IEEE,", "citeRegEx": "Rendle. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "In Proceedings of the 2nd ACM conference on Electronic commerce", "author": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl. Analysis of recommendation algorithms for e-commerce"], "venue": "pages 158\u2013167. ACM,", "citeRegEx": "Sarwar et al.. 2000", "shortCiteRegEx": null, "year": 2000}, {"title": "In Proceedings of the 10th international conference on World Wide Web", "author": ["Badrul Sarwar", "George Karypis", "Joseph Konstan", "John Riedl. Item-based collaborative filtering recommendation algorithms"], "venue": "pages 285\u2013295. ACM,", "citeRegEx": "Sarwar et al.. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Joseph A Konstan", "author": ["J Ben Schafer"], "venue": "and John Riedl. E-commerce recommendation applications. In Applications of Data Mining to Electronic Commerce, pages 115\u2013153. Springer", "citeRegEx": "Schafer et al.. 2001", "shortCiteRegEx": null, "year": 2001}, {"title": "Applied Stochastic Models in Business and Industry", "author": ["Steven L Scott. A modern bayesian look at the multi-armed bandit"], "venue": "26(6):639\u2013658,", "citeRegEx": "Scott. 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning to rank short text pairs with convolutional deep neural networks", "author": ["Severyn", "Moschitti", "2015] Aliaksei Severyn", "Alessandro Moschitti"], "venue": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Severyn et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Severyn et al\\.", "year": 2015}, {"title": "In Proceedings of the 22nd ACM international conference on Conference on information & knowledge management", "author": ["Liang Tang", "Romer Rosales", "Ajit Singh", "Deepak Agarwal. Automatic ad format selection via contextual bandits"], "venue": "pages 1587\u20131594. ACM,", "citeRegEx": "Tang et al.. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Biometrika", "author": ["William R Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples"], "venue": "25(3/4):285\u2013 294,", "citeRegEx": "Thompson. 1933", "shortCiteRegEx": null, "year": 1933}, {"title": "PhD thesis", "author": ["Christopher John Cornish Hellaby Watkins. Learning from delayed rewards"], "venue": "University of Cambridge England,", "citeRegEx": "Watkins. 1989", "shortCiteRegEx": null, "year": 1989}], "referenceMentions": [{"referenceID": 20, "context": "Generally this is achieved by sophisticated machine learning models such as Factorization Machines [Rendle, 2010], pairwise learning-to-rank [Burges et al.", "startOffset": 99, "endOffset": 113}, {"referenceID": 2, "context": "Generally this is achieved by sophisticated machine learning models such as Factorization Machines [Rendle, 2010], pairwise learning-to-rank [Burges et al., 2005; Severyn and Moschitti, 2015], listwise learning-to-rank [Cao et al.", "startOffset": 141, "endOffset": 191}, {"referenceID": 5, "context": ", 2005; Severyn and Moschitti, 2015], listwise learning-to-rank [Cao et al., 2007], etc.", "startOffset": 64, "endOffset": 82}, {"referenceID": 1, "context": "It is implemented by two miorring 5-layers DNNs: one input layer which takes item features that are sparsem-dimensional vectors, three fully-connected layers that generalize item features x, and one output layer w [Basak et al., 2007; Cherkassky and Ma, 2004] which outputs ys serving as the pre-ranker regression scores.", "startOffset": 214, "endOffset": 259}, {"referenceID": 7, "context": "It is implemented by two miorring 5-layers DNNs: one input layer which takes item features that are sparsem-dimensional vectors, three fully-connected layers that generalize item features x, and one output layer w [Basak et al., 2007; Cherkassky and Ma, 2004] which outputs ys serving as the pre-ranker regression scores.", "startOffset": 214, "endOffset": 259}, {"referenceID": 9, "context": "3 is inspired by SVM-rank [Elisseeff et al., 2001], where x1i and x2i are the pair of item features labeled as t1i and t2i.", "startOffset": 26, "endOffset": 50}, {"referenceID": 18, "context": "The first and second reasons are well discussed in [Radlinski et al., 2008] by stating that static rankings contain lots of redundant results.", "startOffset": 51, "endOffset": 75}, {"referenceID": 15, "context": "We follow the problem settings of the contextual multiarmed bandit problem in [Langford and Zhang, 2008], and define the problem as follows:", "startOffset": 78, "endOffset": 104}, {"referenceID": 28, "context": "We picked three state-of-the-art bandit algorithms: -greedy[Watkins, 1989], Upper Confidence Bound or UCB[Auer et al.", "startOffset": 59, "endOffset": 74}, {"referenceID": 0, "context": "We picked three state-of-the-art bandit algorithms: -greedy[Watkins, 1989], Upper Confidence Bound or UCB[Auer et al., 2002], and Thompson sampling.", "startOffset": 105, "endOffset": 124}, {"referenceID": 16, "context": "Efforts from different parties regarding with how the recommender systems should be designed include [Linden et al., 2003; Davidson et al., 2010; Schafer et al., 2001; Sarwar et al., 2000].", "startOffset": 101, "endOffset": 188}, {"referenceID": 23, "context": "Efforts from different parties regarding with how the recommender systems should be designed include [Linden et al., 2003; Davidson et al., 2010; Schafer et al., 2001; Sarwar et al., 2000].", "startOffset": 101, "endOffset": 188}, {"referenceID": 21, "context": "Efforts from different parties regarding with how the recommender systems should be designed include [Linden et al., 2003; Davidson et al., 2010; Schafer et al., 2001; Sarwar et al., 2000].", "startOffset": 101, "endOffset": 188}, {"referenceID": 22, "context": "Works of item-based approaches such like [Sarwar et al., 2001; Rendle et al., 2010]have all received enormous success.", "startOffset": 41, "endOffset": 83}, {"referenceID": 19, "context": "Works of item-based approaches such like [Sarwar et al., 2001; Rendle et al., 2010]have all received enormous success.", "startOffset": 41, "endOffset": 83}, {"referenceID": 3, "context": "[Burke, 2002; Lops et al., 2011] both provide thorough surveys about this topic and readers should refer to them for in depth details.", "startOffset": 0, "endOffset": 32}, {"referenceID": 11, "context": "Research works in this thread include [Freund et al., 2003; Cao et al., 2006].", "startOffset": 38, "endOffset": 77}, {"referenceID": 5, "context": "Successful listwise approaches include ListNet[Cao et al., 2007] and RankCosine[Qin et al.", "startOffset": 46, "endOffset": 64}, {"referenceID": 17, "context": ", 2007] and RankCosine[Qin et al., 2008].", "startOffset": 22, "endOffset": 40}, {"referenceID": 12, "context": "Maybe the works that are most similar to our pre-ranker could be [Severyn and Moschitti, 2015; Kalchbrenner et al., 2014; Kim, 2014].", "startOffset": 65, "endOffset": 132}, {"referenceID": 13, "context": "Maybe the works that are most similar to our pre-ranker could be [Severyn and Moschitti, 2015; Kalchbrenner et al., 2014; Kim, 2014].", "startOffset": 65, "endOffset": 132}, {"referenceID": 14, "context": "Multi-armed bandit problem has been well studied and discussed in literatures such like [Lai and Robbins, 1985; Even-Dar et al., 2006; Auer et al., 2002] The basic setup for MAB is to select K items from M arms consecutively with feedbacks so the total expected regrets are minimized.", "startOffset": 88, "endOffset": 153}, {"referenceID": 10, "context": "Multi-armed bandit problem has been well studied and discussed in literatures such like [Lai and Robbins, 1985; Even-Dar et al., 2006; Auer et al., 2002] The basic setup for MAB is to select K items from M arms consecutively with feedbacks so the total expected regrets are minimized.", "startOffset": 88, "endOffset": 153}, {"referenceID": 0, "context": "Multi-armed bandit problem has been well studied and discussed in literatures such like [Lai and Robbins, 1985; Even-Dar et al., 2006; Auer et al., 2002] The basic setup for MAB is to select K items from M arms consecutively with feedbacks so the total expected regrets are minimized.", "startOffset": 88, "endOffset": 153}, {"referenceID": 27, "context": "Thompson sampling, dated back from [Thompson, 1933], albeit its simplicity, has been proved quite efficient regarding with productional performance [Tang et al.", "startOffset": 35, "endOffset": 51}, {"referenceID": 26, "context": "Thompson sampling, dated back from [Thompson, 1933], albeit its simplicity, has been proved quite efficient regarding with productional performance [Tang et al., 2013; Chapelle and Li, 2011]and suprisingly straightforward to implement.", "startOffset": 148, "endOffset": 190}, {"referenceID": 6, "context": "Thompson sampling, dated back from [Thompson, 1933], albeit its simplicity, has been proved quite efficient regarding with productional performance [Tang et al., 2013; Chapelle and Li, 2011]and suprisingly straightforward to implement.", "startOffset": 148, "endOffset": 190}, {"referenceID": 24, "context": "Other works regarding with Thompson sampling models include [Scott, 2010].", "startOffset": 60, "endOffset": 73}, {"referenceID": 18, "context": "However, for the sake of model simplicity, we have not paid too much attention to the position-bias which is one important factor that affects the ranking performance [Radlinski et al., 2008] in the learning-to-rank DNN pre-ranker, since bringing in the listwise loss would introduce some scalability issues in our use cases.", "startOffset": 167, "endOffset": 191}], "year": 2017, "abstractText": "With the transition from people\u2019s traditional \u2018brickand-mortar\u2019 shopping to online mobile shopping patterns in web 2.0 era, the recommender system plays a critical role in E-Commerce and E-Retails. This is especially true when designing this system for more than 236 million active users. Ranking strategy, the key module of the recommender system, needs to be precise, accurate, and responsive for estimating customers\u2019 intents. We propose a dynamic ranking paradigm, named as DNNMAB, that is composed of a pairwise deep neural network (DNN) pre-ranker connecting a revised multi-armed bandit (MAB) dynamic post-ranker. By taking into account of explicit and implicit user feedbacks such as impressions, clicks, conversions, etc. DNN-MAB is able to adjust DNN preranking scores to assist customers locating items they are interested in most so that they can converge quickly and frequently. To the best of our knowledge, frameworks like DNN-MAB have not been discussed in the previous literature to either E-Commerce or machine learning audiences. In practice, DNN-MAB has been deployed to production and it easily outperforms against other stateof-the-art models by significantly lifting the gross merchandise volume (GMV) which is the objective metrics at JD.", "creator": "LaTeX with hyperref package"}}}