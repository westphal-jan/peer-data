{"id": "1708.05563", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Aug-2017", "title": "Induction of Decision Trees based on Generalized Graph Queries", "abstract": "usually, decision tree induction algorithms are limited to work with non relational data. given a record, they don't take into account other shared objects attributes even though they can provide valuable information for the learning task. in this paper we present ggq - id3, a multi - relational decision tree learning algorithm that uses generalized graph queries ( ggq ) as predicates in the decision nodes. ggqs allow to express complex word patterns ( including cycles ) and they can be refined step - algorithm by - step. plus also, maybe they can visually evaluate structures ( not only single records ) and perform regular pattern matching. ggq are built dynamically ( pattern mining ) during the ggq - id3 tree construction process process. we will show how to use complex ggq - id3 to perform multi - relational machine learning keeping complexity under control. finally, some real examples of automatically obtained classification query trees computational and semantic patterns are shown.", "histories": [["v1", "Fri, 18 Aug 2017 11:19:01 GMT  (1916kb,D)", "http://arxiv.org/abs/1708.05563v1", "Multi-lingual Paper. Main language: English. Additional Language: Spanish. 7 Figures. Engish: 16 pages. Spanish: 20 pages"]], "COMMENTS": "Multi-lingual Paper. Main language: English. Additional Language: Spanish. 7 Figures. Engish: 16 pages. Spanish: 20 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["pedro almagro-blanco", "fernando sancho-caparrini"], "accepted": false, "id": "1708.05563"}, "pdf": {"name": "1708.05563.pdf", "metadata": {"source": "CRF", "title": "Induction of Decision Trees based on Generalized Graph Queries", "authors": ["Fernando Sancho-Caparrini"], "emails": [], "sections": [{"heading": null, "text": "Induction of Decision Trees based on Generalized\nGraph Queries\nPedro Almagro-Blanco and Fernando Sancho-Caparrini\nAugust 21, 2017"}, {"heading": "1 Introduction", "text": "A decision tree is a classification (and regression) model that, based on the characteristics of a given object, and applying a series of rules, is able to classify it (or return a continuous value in the case of regression). The induction of decision trees from a set of previously classified objects is one of the most popular machine learning models due, among other things, to the low computational demand in their training and the interpretability of their results, so it is a representative white box model.\nID3 algorithm presented by R. Quinlan in 1983 for the automatic construction of decision trees from a training set of objects described through a collection of properties. Each object in the training set belongs to a class (usually represented by the value of its target attribute) of a set of mutually exclusive classes. ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7].\nThe main goal of this work is to offer a methodology that allows to carry out machine learning tasks using decision trees on multi-relational graph data. In this context, the number of possible properties of each object goes far beyond those that it has directly associated, since the properties of the elements that are related to it can also be considered attributes of the object, and even the topological structure formed by the objects in their environment and the various measures that can be taken from the graph structure could be considered as additional attributes. With this objective, we will analyse different techniques that allow automatic induction of decision trees from graph data and we will present our proposal, GGQ-ID3, that aims to provide a framework to classify substructures in a graph, from simple nodes and edges, to larger paths and subgraphs, making use of Generalized Graph Query (GGQ) [1].\nThis paper is structured as follows: we will start reviewing different techniques of induction of relational decision trees; then, we present our proposal based on the use of Generalized Graph Queries as evaluation tool; once our proposal is presented, we will show some examples of its application; and finally we present some conclusions and future work lines.\nar X\niv :1\n70 8.\n05 56\n3v 1\n[ cs\n.L G\n] 1\n8 A\nug 2\n01 7"}, {"heading": "2 Related Works", "text": "This section does not pretend to be an exhaustive compilation of the related works that can be found in the literature, but a selection showing their predictive capacity, computational efficiency, or widespread use.\nInductive Logic Programming (ILP) [16] is a machine learning area that uses Logic Programming to consistently represent examples, knowledge bases, and hypotheses. Although ILP itself (without proper transformation of the relationships between data to logical predicates) does not allow the generation of relational decision trees, it does allow automatic generation of logical decision trees that can be considered the basis of one of the most important relational decision tree algorithms, Multi-Relational Decision Tree Learning (MRDTL). ILP provides interpretability, but is inefficient when working with complex databases [15].\nA Logical Decision Tree [3] is a binary decision tree in which all the tests of the internal nodes are expressed as conjunction of literals of a prefixed First Order Language. The Top-Down Induction of Logical Decision Trees (TILDE) algorithm builds logical decision trees from a set of classified examples [4]. The only difference between this algorithm and ID3 (without taking into account the possible optimizations implemented in C4.5 or others) is found in the tests carried out in each node of the tree. Following the rise of the ILP, some major breakthroughs were made in multi-relational data mining [8, 21]. Yin Xiaoxin [20] designed CrossMine, a multi-relational classification model that merges ILP and relational databases, improving efficiency in this type of tasks through virtual joins [11].\nMulti-Relational Decision Tree Learning (MRDTL) is a multi-relational machine learning algorithm [10] based on the ideas of Knobles et al. [9] that works with Selection Graphs. A Selection Graph is a graph representation of a SQL query that selects records which match some constraints expressed by paths connected with them. In order to construct complex selection graphs from an initial one, some atomic operations allow to refine the queries. In addition, in order to be used as tests for ID3-like processes, it must be possible to obtain the complementary selection graph in each case. Essentially, MRDTL works as ID3, but making use of selection graphs as binary attributes in each decision node of the tree. The specification of this method is oriented to relational databases.\nGraph-Based Induction (GBI) is a data mining technique to perform network motifs mining from labelled and directed graphs through the union of pairs of connected nodes [14]. It is very efficient because it uses a greedy technique. Tree Graph-Based Induction Decision (DT-GBI) is a decision tree construction algorithm to classify graphs using GBI principles. In DT-GBI the attributes (called patterns or substructures) are generated during the execution of the algorithm [5], adding feature extraction capacity [13]. It should be noted that, unlike our proposal or MRDTL, DT-GBI constructs decision trees to classify complete graphs, not general subgraphs (as is the case of GGQ-ID3) or nodes (as is the case of MRDTL)."}, {"heading": "3 Generalized Graph Queries", "text": "Generalized Graph Query, on which the multi-relational decision tree induction model GGQ-ID3 is based, is briefly presented now. A more comprehensive description of this framework can be found in [1].\nA Generalized Graph (which will also be called Property Graph) is a concept that covers several variants of graphs that can be found in the literature.\nDefinition 1. A Generalized Graph is a tuple G = (V,E, \u00b5) where:\n\u2022 V and E are sets, called, respectively, set of nodes and set of edges of G.\n\u2022 \u00b5 is a relation (usually functional, but not necessarily) that associates each node or edge in the graph with a set of properties, that is, \u00b5 : (V \u222aE)\u00d7R\u2192 S, where R represents the set of possible keys for available properties, and S the set of possible values associated.\nUsually, for each \u03b1 \u2208 R and x \u2208 V \u222a E, we write \u03b1(x) = \u00b5(x, \u03b1). In addition, we require the existence of a special key for the edges of the graph, called incidences and denote by \u03b3, which associates to each edge of the graph a tuple, ordered or not, of vertices of the graph.\nGeneralized Graph Query allows structural and semantic, accurate, optimal, and based on a type of Regular Pattern Matching queries, associating edges of the pattern with paths on the graph that meet the constraints imposed, and allowing cycles.\nLet L be a First Order Language with equality using a collection containing all the functions of \u00b5 and constants associated with each element of the graph as non logical symbols (and some additional symbols, for example metrics defined on the elements of the graph). Constructing in the usual way the set of terms of the language and the set of formulas, FORM(L) (which we will call predicates), we can define queries on generalized graphs:\nDefinition 2. A Generalized Graph Query (GGQ) over L is a binary generalized graph, Q = (VQ, EQ, \u00b5Q), where exist \u03b1 and \u03b8, properties in \u00b5Q, such that:\n\u2022 \u03b1 : VQ \u222a EQ \u2192 {+,\u2212} total.\n\u2022 \u03b8 : VQ \u222a EQ \u2192 FORM(L) associates a binary predicate, \u03b8x, to every element x of VQ \u222a EQ.\nThe second parameter of \u03b8 is used to express conditions of membership on subgraphs and the first one will receive elements of the corresponding type to which it is associated (nodes or edges/paths).\nGiven a GGQ, x+, respectively x\u2212, will indicate that \u03b1(x) = +, respectively \u03b1(x) = \u2212, and V +Q /V \u2212Q (respectively, E+Q/E\u2212Q) the set of positive/negative nodes (respectively, edges). If for an element, \u03b8x is not explicitly defined, we assume it to be a tautology (generally denoted by T ). As we will see below, positive elements of the pattern represent elements verifying the associated predicates that must be present in the graph, while negative ones represent elements that should not be present in the graph.\nIn order to express the necessary conditions that define the application of a GGQ on a graph, the following notations are useful:\nDefinition 3. Given a GGQ, Q = (VQ, EQ, \u00b5Q), the set of Q-predicates associated to Q is:\n1. For each edge, e \u2208 EQ, we define:\nQeo(v, S) = \u2203\u03c1 \u2208 Pov (G) ( \u03b8e(\u03c1, S) \u2227 \u03b8eo(\u03c1o, S) \u2227 \u03b8ei(\u03c1i, S) ) Qei(v, S) = \u2203\u03c1 \u2208 Piv(G) ( \u03b8e(\u03c1, S) \u2227 \u03b8eo(\u03c1o, S) \u2227 \u03b8ei(\u03c1i, S) )\nIn general, we will write Qe\u2217(v, S), where \u2217 \u2208 {o, i}, and we will denote:\nQ+e\u2217 = Qe\u2217 , Q \u2212 e\u2217 = \u00acQe\u2217\n2. For each node, n \u2208 VQ, we define:\nQn(S) = \u2203v \u2208 V\n  \u2227\ne\u2208\u03b3o(n) Q \u03b1(e) eo (v, S) \u2227\n\u2227\ne\u2208\u03b3i(n) Q \u03b1(e) ei (v, S)\n \n= \u2203v \u2208 V\n  \u2227\ne\u2208\u03b3\u2217(n) Q \u03b1(e) e\u2217 (v, S)\n \nThat can be written generally as:\nQn(S) = \u2203v \u2208 V\n  \u2227\ne\u2208\u03b3(n) Q\u03b1(e)e (v, S)\n \nIn addition, we denote:\nQ+n = Qn, Q \u2212 n = \u00acQn\nWhere eo/ei represents the source/target node of the edge e, Pov (G)/Piv(G) represents the paths in G starting/ending in node v.\nFrom these notations, we can formally define when a subgraph matches a given GGQ:\nDefinition 4. Given a subgraph S of a property graph, G = (V,E, \u00b5), and a Generalized Graph Query, Q = (VQ, EQ, \u00b5Q), both over a language L, we say that S matches Q, S Q, if it is verified:\nQ(S) = \u2227\nn\u2208VQ Q\u03b1(n)n (S)\nOtherwise, we will write: S 2 Q.\nIn order to obtain controlled query generation methods, refinements can be defined in order to modify a GGQ by unit steps. Given two GGQ, Q1, Q2, we say that Q1 refine Q2 in a graph G, Q1 G Q2, if for all S \u2286 G that S Q1, then S Q2.\nDefinition 5. Given Q \u2208 GGQ, R \u2286 GGQ is a refinement set of Q in G if:\n1. \u2200 Q\u2032 \u2208 R (Q\u2032 G Q)\n2. \u2200 S \u2286 G (S Q\u21d2 \u2203! Q\u2032 \u2208 R (S Q\u2032)) In what follows, given Q, ClWQ is the graph obtained from Q by duplicating the nodes in W \u2286 VQ (with the incident edges if they have). Following [1], we can prove that the following sets of GGQ are refinements of Q:\n\u2022 Add new node: if m /\u2208 VQ, then Q+ {m}: Q1 = (VQ \u222a {m}, EQ, \u03b1Q \u222a (m,+), \u03b8Q \u222a (m,T )) Q2 = (VQ \u222a {m}, EQ, \u03b1Q \u222a (m,\u2212), \u03b8Q \u222a (m,T ))\n\u2022 Add new edge between positive nodes: if n,m \u2208 V +Q , then Q + {n+ e \u2217 \u2212\u2192 m+} (\u2217 \u2208 {+,\u2212}) (where Q\u2032 = Cl{n,m}Q ):\nQ1 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2217 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e, T )) Q2 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2217 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e, T )) Q3 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2217 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e, T )) Q4 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2217 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e, T ))\n\u2022 Add predicate to positive edge connecting positive nodes: if n,m \u2208 V +Q , with n+\ne+\u2212\u2192 m+, and \u03d5 \u2208 FORM , then Q + {n+ e\u2227\u03d5\u2212\u2192 m+} (where Q\u2032 = Cl{n,m}Q ):\nQ1 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2032 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q2 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2032 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q3 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2032 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q4 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2032 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5))\n\u2022 Add predicate to positive node with positive environment: if n \u2208 V +Q , NQ(n) \u2286 V +Q , and \u03d5 \u2208 FORM , then Q+ {n \u2227 \u03d5}:\n{Q\u03c3 = (VQ\u2032 , EQ\u2032 , \u03b1Q\u2032 \u222a \u03c3, \u03b8Q\u2032 \u222a (n\u2032, \u03b8n \u2227 \u03d5)) : \u03c3 \u2208 {+,\u2212}NQ(n)}\nwhere Q\u2032 = ClNQ(n)Q , and {+,\u2212}NQ(n) is the set of all possible sign assignations to the elements in NQ(n) (the neighborhood of n in Q).\nIt is an open problem how to automatically obtain a complementary GGQ of a given one. Refinements cover this gap and allow, for example, the construction of an embedded partitions tree with nodes labelled as follows (Fig. 1):\n\u2022 The root node is labelled Q0 (any initial GGQ). \u2022 If a tree node is labelled Q, and R = (Q1, . . . , Qn) is a refinement set of Q, then its child nodes are labelled with the R elements.\nNote that the construction of this tree completely depends on the refinement chosen in each branch and the initial GGQ."}, {"heading": "4 GGQ-ID3", "text": "GGQ-ID3 is an adaptation of ID3 algorithm to create decision trees to classify structures immersed in a property graph using Generalized Graph Query framework as test tools in each decision node of the decision tree.\nSimilarly to ID3, our proposal, using refinements, will look for GGQs that best classify the examples of the training set along the tree construction (feature extraction). For that, in each internal node of the tree a discrimination will be performed between the structures of a graph G that fulfil each GGQ resulting from a refinement. As usual, the measure of impurity used is a hyper-parameter of the algorithm.\nAlthough GGQ-ID3 has a very similar structure to other algorithms for construction of decision trees, it presents the novelty of receiving structures (subgraphs) immersed in a property graph as training set. By using appropriate predicates, GGQs constructed by the algorithm can not only evaluate properties of the structure under evaluation, but also properties of any element (subgraph) in its environment.\nThe complete training set, L, will consist of pairs of the form (S, value), where S is a subgraph of G and value is its associated output value. Consequently, each node n of the decision tree will have associated the following structures:\n\u2022 Ln = {(S1, y1), ..., (SN , yN )} \u2286 L, a subset of the training set. \u2022 Qn = (VQn , EQn , \u03b1Qn , \u03b8Qn), A GGQ verified by all subgraphs in Ln. Algorithm 1 formally represents GGQ-ID3. Note that the set of available refinements, REFS, to extend the GGQ in each step, as well as the stopping condition and refinement selection criteria, remain as free parameters of the model.\nIn a typical learning process, the input of the algorithm will be:\n\u2022 G = (V,E, \u00b5), graph in which the structures to be classified are immersed. \u2022 L = {(S1, y1), ..., (SN , yN )}, set of pairs (Si, yi) where Si \u2286 G represents\na subgraph and yi is its associated output value.\n\u2022 Q0 = (VQ, EQ, \u00b5Q), initial GGQ (usually a GGQ with the largest common structure in S1, ..., SN ).\nAlgorithm 1 GGQ-ID3(G,Q,L, REFS) 1: Create a Root node for the tree 2: if Stop criteria is reached then 3: return The single-node tree Root, with most frequent label in L. 4: else 5: (Q1, .., Qk) = Optimal Refinement(G,Q,L,REFS) 6: L1 = {(S, y) \u2208 L : S Q1}, ...,Lk = {(S, y) \u2208 L : S Qk} 7: Add k new tree branches below Root with values GGQ-\nID3(G,Qi,Li, REFS) for every 1 \u2264 i \u2264 k. 8: end if\n\u2022 REFS, available refinements set.\nThe algorithm follows the usual procedure in ID3. It begins by creating a tree containing a single node (root node) to which all the L objects and Q0 are associated. If n is the node of the decision tree which we are working with, the algorithm evaluates which refinement divides Ln better and it will be chosen to be applied to Qn. Next, as many branches from n as GGQs are in the chosen refinement will be created and each pair of Ln will be transmitted through the corresponding branch. Each child node of n will inherit the GGQ resulting from the refinement and proceed to search (if the stop condition is not reached) the best refinement for the new GGQ. Each branch of the tree will receive a set of objects and a GGQ that is verified by all of them. If the stop condition is met, the node will become a leaf node associated with the corresponding class. This process is repeated recursively.\nDecision trees obtained in most automatic procedures divide the data into binary complementary subsets in a recursive way [17], but in the multi-relational case the production of complementary patterns of this type is not straightforward. This is the reason a set of refinements that generate complementary GGQs, but not necessarily binary, were presented."}, {"heading": "5 Some Examples", "text": "Next we present an example of GGQ-ID3 algorithm application on a small property graph as a demonstration. The available refinements REFS will be those seen in the previous section, we will use the most restrictive stop condition (all the pairs in the current node belong to the same class), and the Information Gain [12] will be used as impurity measure.\nWe will work with the social graph shown in Figure 2, which represents some marital connections between users and information related to photographs publication. There are nodes of types user and photo, and edges of types wife, husband, publish and likes. In this case, L is not extended with topological measures of the graph. In addition, user nodes have gender property with value F (female) or M (male). photo nodes have the value None associated to gender property.\nAlthough GGQ-ID3 algorithm is able to construct decision trees to classify any structure (subgraph), in order to show a simple example, we approach a problem of classifying nodes, specifically trying to predict the gender of nodes.\nIn order to make the exposition clearer and to avoid confusion, the nodes belonging to the training set will be called objects, and we will use nodes for the nodes of the decision tree under construction.\nGGQ-ID3 algorithm constructs the decision tree in Figure 3 (positive nodes/ edges are marked in black and negative ones in red) that correctly classify all nodes from Figure 2 according to their gender: M, F or None. Next indications about the construction follow the representation shown in Figure 3.\nThe initial training set, L, is formed by all pairs of nodes and their corresponding gender. Initial GGQ, Q0, is composed of two positive nodes, one with a predicate that requires belonging to the subgraph under evaluation (v \u2208 S) and another with the opposite condition (V /\u2208 S). As previously mentioned, usually the initial GGQ will correspond to the largest common substructure in the subgraphs to be classified, in this case the largest common structure is composed of a single node with no restrictions. In addition, and for reasons of efficiency, in each step of the algorithm an isolated positive node will be created with a predicate that requires non belonging to the subgraph under evaluation (v /\u2208 S) if there is no such isolated node. If the subgraph under evaluation does not cover all the nodes of the graph in which it is immersed (which is true in all the examples presented), adding a node of this type does not modify the meaning of the GGQ but allows to reach optimal GGQ easily.\nAs a first step, the algorithm will analyse what refinement in REFS (and with what parameters) represents the highest impurity reduction, resulting in refinement +{ e +\n\u2212\u2192}, add edge between the only two existing nodes in Q0. Although refinement add edge generates a refinement of four elements, we consider only those that intervene in the classification process, removing those that transmit an empty set of objects.\nBecause the subgraphs to classify are composed of a single object, this refinement evaluates the existence or not of an outgoing edge in this object. According to Figure 3, the right branch will transmit all objects with no outgoing relations.\nIn this case, all photo objects of the data graph, that have None as gender, so this branch is associated with the output value None and becomes a leaf of the decision tree.\nThe left branch will transmit all objects with an outgoing relation (in this case, all objects of the data graph of type user). As the values of gender are not homogeneous in this set, the algorithm must continue and a new refinement to this branch have to be applied. Here we have nodes that reflect male and female users with an outgoing edge.\n+{e\u2227{type=publish}\u2212\u2192 } refinement (add a new predicate to edge) produces the greatest information gain. The refinements applied to this node in the decision tree will discriminate which objects (of those with an outgoing edge)\nverify that this edge is of type publish and which do not. According to Figure 3, objects with no outgoing edge of type publish will be transmitted through the right branch of this node. In our case, all these objects are male gender users, so the node becomes a leaf associated with class M. Through the left branch the objects with an outgoing publish edge will be transmitted. In this case, again the values of the gender property are not homogeneous (they present impurity) so the algorithm must continue looking for a new refinement in this branch.\nWe repeat the process for the new node, with objects having an outgoing edge of type publish. The refinement with the maximum impurity reduction is +{ e +\n\u2212\u2192}, add an edge between the isolated node (v /\u2208 S) and the target node of the publish relationship. The interpretation is to discriminate, from the objects that have published something, those whose publications receive some incoming edge by another object outside the structure under evaluation. In other words, users that have published a photo that someone else likes.\nAll objects in the right branch are associated to gender M (users who have posted a photo that nobody likes), so the stop condition is reached and the node becomes a leaf associated with class M. Users who have published a photo and there is someone who likes it will be transmitted by the left branch. All these users are of gender F, so the stop condition is also checked and the produced leaf is associated with the corresponding class.\nWe have obtained a decision tree able to correctly classify all the objects in the data graph regarding to their gender making use of the multi-relational structure in which they are immersed. In addition, we automatically obtain GGQ that evaluate properties of the context differentiating between the objects that must be inside the structure under analysis and those that must be outside, one of the big differences that GGQ shows in relation with other multi-relational query frameworks.\nLet us continue showing some more examples of multi-relational decision trees that use GGQ and that have been obtained following the GGQ-ID3 algorithm. As in the case explained above, isolated positive nodes non belonging to the subgraph under evaluation were added at each step if they did not exist in the GGQ. These examples have been extracted from small databases with sufficient complexity to show pattern discovery capability of the GGQ-ID3 algorithm. In some cases only the more interesting leafs are shown."}, {"heading": "5.1 StarWars", "text": "In this case we will mine the graph presented in the Figure 4 with information on StarWars 1.\nThe several GGQ shown in Figure 5 allow to discriminate each character in the graph according to whether it is devotee of the Empire, Rebellion or neither. They correspond to classification leafs of the decision tree automatically generated by GGQ-ID3. To construct it, nodes of type institution (along with the edges in which they participate) have been removed from the original graph database. The queries show that even working with small graphs a high semantic query level is automatically obtained.\n1http://console.neo4j.org/?id=StarWars"}, {"heading": "5.2 The Hobbit", "text": "The third example is obtained by mining another toy graph, in this case related to the the Lord of the Rings world 2. This graph contains 105 nodes with 7 different types (Character, Event, Item, Clan, Aligment, Location and Text) and 209 edges distributed through 65 types, showing a very high edge typology, with very few instances of some types of edges, so that inefficient mechanisms will tend to create very large trees. Figure 6 shows a subgraph extracted from this database.\nDecision tree presented in Figure 7 was automatically obtained using GGQID3 algorithm and allows to discriminate location types (Hills, Forest, Valley, Mountain, Caves and Lake). A maximum depth of 5 levels was imposed in the construction of the tree."}, {"heading": "6 Some Notes About Implementation", "text": "In order to perform verification tests on the GGQ query system and GGQ-ID3 algorithm, a proof-of-concept implementation 3 developed in Python and using Neo4j 4 as persistence system has been carried out. Some parts of the system has been implemented using the Cypher query language. This implementation would gain efficiency if, instead of using Cypher, the Java API of Neo4j or an ad hoc persistence system oriented to support this type of tasks would been used.\nAlthough our goal has been to demonstrate that the formal query system is able to perform this type of tasks in a simple way, some basic optimizations\n2http://neo4j.com/graphgist/c43ade7d259a77fe49a8 3https://github.com/palmagro/ggq 4https://neo4j.com/\nhave been made in the implementation (like the use of complementarity of the queries from a refinement to save time and empty leaves pruning).\nIf an object verifies a GGQ, it will also verify all its predecessors GGQ, so the classification power of a GGQ-ID3 decision tree is contained in the leaves. To gain efficiency, when classifying a new example, is advisable to use the complete tree, since only at least k evaluations (with k the depth of the tree) are needed, but there may be an exponential amount of classification leaves. In addition, since an atomic change has occurred from one level to the next, provided by the corresponding refinement, the evaluation of a subgraph in a node of the decision tree involves considering only some additional checks added to the evaluation of its parent node."}, {"heading": "7 Conclusions and Future Work", "text": "In this paper the GGQ-ID3 algorithm has been presented, it uses Generalized Graph Query framework as test tools following the fundamentals of the algorithm ID3. GGQ-ID3 has shown capabilities to extract interesting patterns to be used in complex learning tasks, that can be interpreted as new attributes discovered by the algorithm (feature extraction).\nWe have used an initial set of refinements in the examples, but this set can be modified by adding refinements according to the structure of the graph under evaluation or to the task to be achieved.\nMRDTL algorithm was developed a decade ago to work specifically on relational databases and with simple classification tasks, and can be seen as a particular case of GGQ-ID3 algorithm where only tree-shaped GGQ are allowed (since they use selection graphs) and where only learning from very simple structures (nodes) is allowed. In this sense, GGQ-ID3 is a step forward in this line of work.\nThe main problem presented by multi-relational decision tree construction algorithms is that the hypothesis space is extremely large. GGQ-ID3 also suffers from this problem. To reduce complexity, and to guide the search, several solutions can be proposed. On the one hand, the frequency of certain structures can be statistically analysed in order to reduce the number of possible refinements to be applied in each case and the refinements search cost. Thus, it is necessary to use measures developed for generalized graphs extending the simpler frequency measurements that are used in the case of MRDTL-2 [2]. On the other hand, more complex refinement families (for example, combining add edge with adding property to an edge in a single step) can be created to reduce the number of steps to get complex GGQ. If this last option is carried out properly (unifying the refinements according to the frequency of structures in the graph), the algorithm can reach the solution faster. In both cases, an improvement in efficiency is achieved by sacrificing the possibility of covering a wider hypothesis space (but probably offering alternatives in which the impurity\nreduction is larger). In this sense, a minimal set of well-constructed refinements has been offered in this paper, but not with the intention of being optimal for certain learning tasks.\nThe second major problem with GGQ-ID3 (shared by all ID3-inspired algorithms) is the inability to undo the decisions taken during the construction process. Refinement election at a given step depends on refinements chosen in previous steps. To solve this problem, some backtracking procedure can be considered, or some Beam-Search procedure (as in the algorithm GBI [6]), allowing to take several decisions in parallel, and finally select the one that has resulted in a better solution.\nWith regard to the future work that derives from the research presented here, it is worth mentioning that, since GGQs are constructed using the generalized graph structure, and that this structure allows the definition of hypergraphs in a natural way, GGQs can evaluate hypergraphs with properties just with slight modifications. In addition, the development of different refinement sets according to the type of graph to query or even the automatic generation of such sets from statistics extracted from the graph to be analysed can lead to important optimizations in processes of automatic and effective GGQ construction.\nDecision trees are an ideal tool to be combined through some ensemble model, such as Random Forest, thanks to its low computational training cost and the randomness obtained from small changes in the data set from which\nto learn. Therefore, having adequate models for automatic generation of multirelational random forests becomes a task of great importance.\nMulri-relational Machine Learning has received (and still receives) less attention than the more standard machine learning methods that make use of non relational information (usually in the form of tables and other more regular structures). The most commonly used databases, in which information about most of the studied phenomena is stored, make use of schemes and systems based on the relational model that do not show optimal performance when working with complex relationships. In addition, the greater expressive richness of more complex information representation structures imposes greater difficulty in making new algorithms and provides, at least in the first approximations, less striking results than the more refined and more traditional methods.\nAnother important feature of decision tree-based learning methods is that they represent a white-box model, providing an interpretable explanation of the decisions taken when performing regression or classification. In the case of GGQ-ID3, this characteristic is enhanced due to the interpretability of the GGQ. This advantage may be blurred when using ensembles, but there are methods to extract knowledge of aggregated results that could be reused in this context. One possibility is to combine the leaves associated with the same class from GGQ of different trees, giving rise to combined patterns (possibly probabilistically) that are able to condense the different predicates that characterize the same class in a more powerful predicate."}, {"heading": "2. Trabajos Relacionados", "text": "Este apartado no pretende ser una recopilacio\u0301n exhaustiva de los trabajos relacionados que se pueden encontrar en la literatura, sino una seleccio\u0301n de aquellos que hemos encontrado ma\u0301s interesantes, bien sea por su capacidad de prediccio\u0301n, su eficiencia computacional, o porque han servido de base a otras te\u0301cnicas y trabajos relevantes.\nLa Programacio\u0301n Lo\u0301gica Inductiva (ILP) [21] es un a\u0301rea del aprendizaje automa\u0301tico que utiliza fundamentos de Programacio\u0301n Lo\u0301gica para representar de manera uniforme ejemplos, base de conocimientos, e hipo\u0301tesis. A pesar de que la ILP por s\u0301\u0131 misma (sin una transformacio\u0301n adecuada de las relaciones entre datos a predicados lo\u0301gicos) no permite generar a\u0301rboles de decisio\u0301n relacionales, s\u0301\u0131 permite generar de manera automa\u0301tica a\u0301rboles de decisio\u0301n lo\u0301gicos que pueden ser considerados la base de uno de los algoritmos ma\u0301s importantes de generacio\u0301n automa\u0301tica de a\u0301rboles de decisio\u0301n, como es el algoritmo Multi-Relational Decision Tree Learning (MRDTL). La gran potencia que proporciona ILP en nuestro contexto es su interpretabilidad, pero su punto de\u0301bil radica en la ineficiencia para trabajar con bases de datos complejas [19].\nUn A\u0301rbol de Decisio\u0301n Lo\u0301gico [3] es un a\u0301rbol de decisio\u0301n binario en el que que todos los test de los nodos internos se expresan como conjuncio\u0301n de literales de una Lo\u0301gica de Primer Orden prefijada. El algoritmo TILDE (Top-Down Induction of Logical Decision Trees) [3] construye a\u0301rboles de decisio\u0301n lo\u0301gicos para clasificar instancias a partir de un conjunto de ejemplos clasificados, una base de conocimientos, y un lenguaje que indica que\u0301 tipo de preguntas esta\u0301n permitidas en el a\u0301rbol [4]. La u\u0301nica diferencia entre este algoritmo y el ID3 presentado por Quinlan (sin tener en cuenta las posibles optimizaciones implementadas en C4.5 u otros) se encuentra en los tests llevados a cabo en cada nodo del a\u0301rbol. Tras el auge de la ILP se lograron algunos avances importantes en la miner\u0301\u0131a de datos multi-relacional [11, 28]. Yin Xiaoxin [27] disen\u0303o\u0301 CrossMine, un modelo de clasificacio\u0301n multi-relacional que mezcla ILP y las bases de datos relacionales, mejorando la eficiencia en este tipo de tareas a trave\u0301s de un me\u0301todo para realizar uniones virtuales de tablas de la base de datos [15].\nMulti-Relational Decision Tree Learning (MRDTL) es un algoritmo para el aprendizaje de a\u0301rboles de decisio\u0301n multi-relacionales [14] basado en las ideas de Knobles et al. [13] que trabaja con el concepto de Grafo de Seleccio\u0301n (Selection Graph). Un grafo de seleccio\u0301n es una representacio\u0301n en forma de grafo de una consulta SQL que selecciona registros que cumplan con una serie de restricciones expresadas en forma de estructuras con las que debe (o no debe) estar conectado el registro bajo evaluacio\u0301n. Adema\u0301s, los grafos de seleccio\u0301n permiten ser refinados usando un conjunto de operaciones ato\u0301micas con el fin de construir grafos de seleccio\u0301n complejos a partir de un grafo de seleccio\u0301n inicial. Adema\u0301s, para poder ser usados en un proceso similar a ID3, se debe poder obtener el grafo de\nseleccio\u0301n complementario a uno dado. Esencialmente, MRDTL funciona como ID3, pero se caracteriza por hacer uso de grafos de seleccio\u0301n como atributos binarios en cada nodo de decisio\u0301n del a\u0301rbol. La especificacio\u0301n de este me\u0301todo esta\u0301 orientada a bases de datos relacionales debido, en parte, a que en el tiempo en el que se presento\u0301 au\u0301n no se hab\u0301\u0131an desarrollado otro tipo de bases de datos ma\u0301s adecuadas para este tipo de tareas.\nGraph-Based Induction (GBI) es una te\u0301cnica de miner\u0301\u0131a de datos que extrae patrones frecuentes (network motifs) de grafos etiquetados y dirigidos a trave\u0301s de la unio\u0301n de pares de nodos conectados [18] y que es muy eficiente debido a que utiliza una te\u0301cnica voraz. A partir de esta te\u0301cnica, Decisio\u0301n Tree Graph-Based Induction (DT-GBI) es un algoritmo de construccio\u0301n de a\u0301rboles de decisio\u0301n para clasificar grafos utilizando los principios de GBI. En DT-GBI los atributos (llamados patrones o subestructuras) son generados durante la ejecucio\u0301n del algoritmo [7], por lo que DT-GBI es un generador de a\u0301rboles de decisio\u0301n con capacidad de construccio\u0301n de atributos [17]. Hay que indicar que, a diferencia de nuestra propuesta o de MRDTL, DT-GBI construye a\u0301rboles de decisio\u0301n para clasificar grafos completos, y no subestructuras generales inmersas en e\u0301l (como es el caso de GGQ-ID3) o nodos (como es el caso de MRDTL).\nA continuacio\u0301n presentamos brevemente el concepto de Generalized Graph Query, base del modelo de generacio\u0301n de a\u0301rboles de decisio\u0301n GGQ-ID3, se puede encontrar una descripcio\u0301n ma\u0301s amplia del mismo en [1]."}, {"heading": "3. Generalized Graph Query", "text": "El Grafo Generalizado (que a veces, y por extensio\u0301n, tambie\u0301n denominaremos Grafo con Propiedades) es un concepto que abarca diferentes variantes de grafos que se pueden encontrar en la literatura, tanto aquellos que sirven desde un punto de vista puramente matema\u0301tico, como los que sirven de sustrato teo\u0301rico para las redes sema\u0301nticas o bases de datos en grafo.\nDefinicio\u0301n 1. Un Grafo Generalizado es una tupla G = (V,E, \u00b5) donde:\nV y E son conjuntos, que llamaremos, respectivamente, conjunto de nodos y conjunto de aristas de G.\n\u00b5 es una funcio\u0301n que asocia a cada nodo o arista en el grafo su conjunto de propiedades, es decir, \u00b5 : (V \u222a E) \u00d7 R \u2192 S, donde R representa el conjunto de posibles claves para dichas propiedades, y S el conjunto de posibles valores asociados a las mismas.\nHabitualmente, para cada \u03b1 \u2208 R y x \u2208 V \u222a E, escribiremos \u03b1(x) = \u00b5(x, \u03b1). Adema\u0301s, exigiremos la existencia de una clave destacada para las aristas del grafo, que llamaremos incidencias y denotaremos por \u03b3, que asocia a cada arista del grafo una tupla, ordenada o no, de ve\u0301rtices del grafo.\nLas Generalized Graph Queries permiten llevar a cabo consultas estructurales y sema\u0301nticas, exactas, o\u0301ptimas, y basadas en un tipo de Regular Pattern Matching que permite, adema\u0301s de proyectar aristas del patro\u0301n en caminos (no necesariamente aristas) que cumplan las restricciones impuestas, expresar restricciones ma\u0301s complejas sobre cada elemento del patro\u0301n y realizar consultas que posean ciclos.\nSi consideramos L un Lenguaje de Primer Orden con igualdad que usa como s\u0301\u0131mbolos no lo\u0301gicos una coleccio\u0301n que contiene todas las funciones de \u00b5 junto con constantes asociadas a cada elemento del grafo (y algunos s\u0301\u0131mbolos adicionales, por ejemplo para denotar me\u0301tricas definidas sobre los elementos del grafo), y construimos de la forma usual el conjunto de te\u0301rminos del lenguaje y el conjunto de fo\u0301rmulas, FORM(L) (que llamaremos predicados), podemos definir las consultas sobre grafos generalizados haciendo uso de las mismas estructuras como:\nDefinicio\u0301n 2. Un Generalized Graph Query (GGQ) sobre L es un grafo generalizado, Q = (VQ, EQ, \u00b5Q), donde existen \u03b1 y \u03b8, propiedades destacadas en \u00b5Q, tales que:\n\u03b1 : VQ \u222a EQ \u2192 {+,\u2212} total. \u03b8 : VQ\u222aEQ \u2192 FORM(L) asocia un predicado binario, \u03b8x, a cada elemento x de VQ \u222a EQ.\nComo veremos, la segunda entrada de estos predicados binarios se usara\u0301 para hablar de condiciones de pertenencia sobre subgrafos de G (el grafo general sobre el que estamos evaluando las consultas), mientras que la primera esperara\u0301 recibir como entrada elementos adecuados al tipo de elemento al que esta\u0301 asociado.\nDado un GGQ en las condiciones anteriores, notaremos x+, respectivamente x\u2212, para indicar que \u03b1(x) = +, respectivamente \u03b1(x) = \u2212. Si para un elemento x, \u03b8x no esta\u0301 expl\u0301\u0131citamente definida, supondremos que \u03b8x es una tautolog\u0301\u0131a, que podemos denotar en general por T . Intuitivamente los elementos positivos del patro\u0301n representan elementos que deben estar presentes en el grafo sobre el que se realiza la consulta y que verifican los predicados asociados, mientras que los elementos negativos en el patro\u0301n representan elementos que no pueden estar presentes en el grafo.\nPara poder expresar con ma\u0301s facilidad las condiciones necesarias que definen la aplicacio\u0301n de un GGQ sobre un grafo, as\u0301\u0131 como los resultados que veremos ma\u0301s adelante, introducimos las notaciones:\nDefinicio\u0301n 3. Dado Q = (VQ, EQ, \u00b5Q) un GGQ, el conjunto de Q-predicados asociados a Q es:\n1. Para cada arista, e \u2208 EQ: Qeo(v, S) = \u2203\u03c1 \u2208 Pov (G) ( \u03b8e(\u03c1, S) \u2227 \u03b8eo(\u03c1o, S) \u2227 \u03b8ei(\u03c1i, S) )\nQei(v, S) = \u2203\u03c1 \u2208 Piv(G) ( \u03b8e(\u03c1, S) \u2227 \u03b8eo(\u03c1o, S) \u2227 \u03b8ei(\u03c1i, S) )\nEn general, escribiremos Qe\u2217(v, S), donde \u2217 \u2208 {o, i}, y notaremos: Q+e\u2217 = Qe\u2217 , Q \u2212 e\u2217 = \u00acQe\u2217\n2. Para cada nodo, n \u2208 VQ:\nQn(S) = \u2203v \u2208 V\n  \u2227\ne\u2208\u03b3o(n) Q \u03b1(e) eo (v, S) \u2227\n\u2227\ne\u2208\u03b3i(n) Q \u03b1(e) ei (v, S)\n \nAdema\u0301s, notaremos:\nQ+n = Qn, Q \u2212 n = \u00acQn\nDonde eo representa el nodo del que parte la arista e y ei representa el nodo destino de dicha relacio\u0301n, Pov (G) (resp. Piv(G)) representa los caminos en G que parten del (resp., terminan en) nodo v.\nA partir de estas notaciones, podemos definir formalmente cua\u0301ndo un subgrafo verifica un GGQ determinado:\nDefinicio\u0301n 4. Dado un subgrafo S de un grafo con propiedades, G = (V,E, \u00b5), y un Generalized Graph Query, Q = (VQ, EQ, \u00b5Q), ambos sobre el lenguaje L, diremos que S verifica Q, y lo denotaremos S Q, si se verifica la fo\u0301rmula:\nQ(S) = \u2227\nn\u2208VQ Q\u03b1(n)n (S)"}, {"heading": "En caso contrario, escribiremos: S 2 Q.", "text": "Con el fin de obtener me\u0301todos controlados de generacio\u0301n de consultas se pueden definir refinamientos para ir modificando un GGQ por pasos unitarios. Dados dos GGQ, Q1, Q2, Q1 refina Q2 en G, Q1 G Q2, si para todo S \u2286 G, si S Q1, entonces S Q2.\nDefinicio\u0301n 5. Dado Q \u2208 GGQ. Diremos que un conjunto de GGQs R es un conjunto de refinamiento de Q en G si verifica:\n1. \u2200 Q\u2032 \u2208 R (Q\u2032 G Q)\n2. \u2200 S \u2286 G (S Q\u21d2 \u2203! Q\u2032 \u2208 R (S Q\u2032))\nEn lo que sigue, dado Q, ClWQ representa un grafo derivado de Q en el que se han duplicado los nodos presentes en W \u2286 VQ (con las respectivas aristas si las tuvieran).\nSiguiendo [1], se puede probar que los siguientes conjuntos de GGQ son refinamientos de Q:\nAn\u0303adir nodo nuevo: si m /\u2208 VQ, entonces Q+ {m}:\nQ1 = (VQ \u222a {m}, EQ, \u03b1Q \u222a (m,+), \u03b8Q \u222a (m,T )) Q2 = (VQ \u222a {m}, EQ, \u03b1Q \u222a (m,\u2212), \u03b8Q \u222a (m,T ))\nAn\u0303adir arista nueva entre nodos positivos: si n,m \u2208 V +Q , entonces Q+ {n+ e \u2217 \u2212\u2192 m+} (\u2217 \u2208 {+,\u2212}) (donde Q\u2032 = Cl{n,m}Q ):\nQ1 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2217 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e, T )) Q2 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2217 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e, T )) Q3 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2217 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e, T )) Q4 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2217 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e, T ))\nAn\u0303adir predicado a arista positiva entre nodos positivos: si n,m \u2208 V +Q , con n + e + \u2212\u2192 m+, y \u03d5 \u2208 FORM , entonces Q + {n+ e\u2227\u03d5\u2212\u2192 m+} (donde\nQ\u2032 = Cl{n,m}Q ):\nQ1 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2032 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q2 = (VQ\u2032 , EQ\u2032 \u222a {n+ e \u2032 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q3 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2032 \u2212\u2192 m+}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5)) Q4 = (VQ\u2032 , EQ\u2032 \u222a {n\u2212 e \u2032 \u2212\u2192 m\u2212}, \u03b8Q\u2032 \u222a (e\u2032, \u03b8e \u2227 \u03d5))\nAn\u0303adir predicado a nodo positivo con entorno positivo: si n \u2208 V +Q , NQ(n) \u2286 V +Q , y \u03d5 \u2208 FORM , entonces Q+ {n \u2227 \u03d5}:\n{Q\u03c3 = (VQ\u2032 , EQ\u2032 , \u03b1Q\u2032 \u222a \u03c3, \u03b8Q\u2032 \u222a (n\u2032, \u03b8n \u2227 \u03d5)) : \u03c3 \u2208 {+,\u2212}NQ(n)}\ndonde Q\u2032 = ClNQ(n)Q , y {+,\u2212}NQ(n) es el conjunto todas las posibles asignaciones de signo a los elementos de NQ(n) (el entorno en Q del nodo n).\nA partir de la estructura de un GGQ no es fa\u0301cil obtener un GGQ complementario con e\u0301l. Sin embargo, hay muchos procesos de ana\u0301lisis sobre grafos con propiedades en los que necesitamos trabajar con sucesiones de consultas que verifiquen algunas propiedades de contencio\u0301n y complementariedad como predicados. Los refinamientos vistos en esta seccio\u0301n vienen a cubrir esta carencia y permiten, por ejemplo, construir un a\u0301rbol de particiones encajadas con los nodos etiquetados de la siguiente forma (Fig. 1):\nEl nodo ra\u0301\u0131z esta\u0301 etiquetado con Q0 (un GGQ inicial cualquiera).\nSi un nodo del a\u0301rbol esta\u0301 etiquetado con Q, y R = (Q1, . . . , Qn) es un conjunto de refinamiento de Q, entonces sus nodos hijo se etiquetan con los elementos de R.\nFigura 1: A\u0301rbol de refinamientos.\nObse\u0301rvese que la construccio\u0301n del a\u0301rbol anterior depende por completo de la eleccio\u0301n del conjunto de refinamiento que se elija en cada ramificacio\u0301n."}, {"heading": "4. GGQ-ID3", "text": "GGQ-ID3 es una adaptacio\u0301n del algoritmo ID3 para crear a\u0301rboles de decisio\u0301n capaces de clasificar correctamente estructuras inmersas en un Grafo con Propiedades haciendo uso de Generalized Graph Queries como herramientas de test en cada nodo interno del a\u0301rbol de decisio\u0301n.\nDe forma similar a como trabaja cualquier algoritmo de tipo ID3, nuestra propuesta buscara\u0301 las consultas que mejor clasifiquen los ejemplos del conjunto de entrenamiento obteniendo los GGQ a evaluar a lo largo de la construccio\u0301n del a\u0301rbol (extraccio\u0301n de caracter\u0301\u0131sticas) por medio de refinamientos. De esta forma, en cada nodo interno del a\u0301rbol se realizara\u0301 una discriminacio\u0301n entre las estructuras que cumplen cada GGQ resultante de un refinamiento. Como suele ser habitual, tanto la medida de impureza usada como la estrategia que elige la mejor ampliacio\u0301n del patro\u0301n asociado a un nodo interno es un hiper-para\u0301metro del algoritmo.\nAunque GGQ-ID3 posee una estructura muy similar a los diferentes algoritmos de construccio\u0301n de a\u0301rboles de decisio\u0301n, presenta la novedad de recibir como conjunto de entrenamiento estructuras (subgrafos) inmersas en un grafo con propiedades. Por medio del uso adecuado de predicados, los GGQ del a\u0301rbol resultante del algoritmo podra\u0301n no solo evaluar propiedades de la estructura a clasificar, sino tambie\u0301n propiedades de cualquier elemento (subgrafo) en su entorno.\nEl conjunto de entrenamiento completo, L, estara\u0301 formado por pares de la forma (S, valor), donde S es un subgrafo de un grafo con propiedades G. En consecuencia, cada nodo, n, del a\u0301rbol de decisio\u0301n construido tendra\u0301 asociadas las siguientes estructuras:\nLn = {(S1, y1), ..., (SN , yN )} \u2286 L, un subconjunto del conjunto de entrenamiento.\nQn = (VQn , EQn , \u03b1Qn , \u03b8Qn), un GGQ que verifican todos los subgrafos de Ln.\nEl algoritmo 1 presenta formalmente el algoritmo GGQ-ID3. No\u0301tese que el conjunto de refinamientos disponibles, REFS, para ampliar el GGQ en cada paso, as\u0301\u0131 como la condicio\u0301n de parada y el criterio de seleccio\u0301n del refinamiento, permanecen como para\u0301metros libres del modelo.\nAlgorithm 1 GGQ-ID3(G,Q,L, REFS) 1: Create a Root node for the tree 2: if Stop criteria is reached then 3: return The single-node tree Root, with most frequent label in L. 4: else 5: (Q1, .., Qk) = Optimal Refinement(G,Q,L,REFS) 6: L1 = {(S, y) \u2208 L : S Q1}, ...,Lk = {(S, y) \u2208 L : S Qk} 7: Add k new tree branches below Root with values GGQ-\nID3(G,Qi,Li, REFS) for every 1 \u2264 i \u2264 k. 8: end if\nEn un proceso habitual de aprendizaje a partir de subgrafos de G, los para\u0301metros de la llamada inicial del algoritmo sera\u0301n:\nG = (V,E, \u00b5), grafo en el que se encuentran inmersos las estructuras a clasificar.\nL = {(S1, y1), ..., (SN , yN )}, conjunto de pares (Si, yi) donde Si \u2286 G representa un subgrafo e yi es su valor de salida asociado.\nQ0 = (VQ, EQ, \u00b5Q), GGQ inicial (normalmente un GGQ con la estructura comu\u0301n ma\u0301s grande en S1, ..., SN ).\nREFS, conjunto de refinamientos disponibles.\nEl algoritmo sigue el procedimiento habitual en un algoritmo de tipo ID3. Comienza creando un a\u0301rbol que contiene un u\u0301nico nodo (nodo ra\u0301\u0131z) al que esta\u0301n asociados todos los objetos de L y Q0. Si n es el nodo del a\u0301rbol de decisio\u0301n con el que estamos trabajando, el algoritmo evalu\u0301a que\u0301 refinamiento permite dividir de mejor manera Ln (ma\u0301xima reduccio\u0301n de impureza) y e\u0301ste sera\u0301 elegido para ser aplicado a Qn. A continuacio\u0301n se creara\u0301n tantas ramas a partir de n como GGQs tenga el refinamiento elegido y por cada una de ellas se transmitira\u0301n los pares de Ln que cumplan con el GGQ asociado. Cada nodo hijo de n heredara\u0301 cada GGQ resultante del refinamiento y procedera\u0301 a buscar (si no se alcanza la condicio\u0301n de parada) el mejor refinamiento para el nuevo GGQ. De esta manera, por cada rama del a\u0301rbol se heredara\u0301, no so\u0301lo un conjunto de pares, sino un GGQ que verifican todos ellos. En caso de que se cumpla la condicio\u0301n de parada, el nodo se convertira\u0301 en un nodo hoja asociada a la clase correspondiente. Este proceso se repite de manera recursiva.\nLos a\u0301rboles de decisio\u0301n que se obtienen en la mayor\u0301\u0131a de los procedimientos automa\u0301ticos dividen los datos en subconjuntos complementarios de manera recursiva [23]. Habitualmente, la divisio\u0301n se lleva a cabo mediante la evaluacio\u0301n de una condicio\u0301n sobre el conjunto de objetos actual y su correspondiente divisio\u0301n binaria: una rama recibira\u0301 el conjunto de objetos que cumplen con la condicio\u0301n, mientras que la otra recibe aquellos que no la cumplen. En los casos simples los patrones complementarios binarios se pueden producir simplemente negando la condicio\u0301n, pero en el caso multi-relacional la produccio\u0301n de patrones complementarios de este tipo no es tan directa. Es por ello que en la seccio\u0301n 3 se presentaron una serie de refinamientos que generan GGQ complementarios, aunque no necesariamente binarios. Nosotros usaremos esos refinamientos como conjunto REFS en la llamada del algoritmo en los ejemplos que se mostrara\u0301n a continuacio\u0301n, pero podr\u0301\u0131a enriquecerse con cualquier refinamiento adicional que se considerase de valor."}, {"heading": "4.1. Ejemplo de aplicacio\u0301n del algoritmo GGQ-ID3", "text": "Vamos a presentar un caso concreto de aplicacio\u0301n del algoritmo GGQ-ID3 sobre un pequen\u0303o grafo con propiedades a modo de demostracio\u0301n. Los refinamientos sera\u0301n los vistos en la seccio\u0301n 3, usaremos la condicio\u0301n de parada ma\u0301s restrictiva (que todos los pares del nodo actual pertenezcan a la misma clase), y se usara\u0301 la Ganancia de Informacio\u0301n [16] como medida de impureza.\nTrabajaremos con el grafo social mostrado en la Figura 2, en el que se representan algunas conexiones de tipo marital entre usuarios, y otras relacionadas con la publicacio\u0301n de fotograf\u0301\u0131as por estos usuarios. Podemos encontrar nodos de tipo user y photo, y relaciones de tipo husband, wife, publish y\nlikes. En este caso, no potenciaremos L por medio de medidas topolo\u0301gicas del grafo, por lo que en el caso del refinamiento an\u0303adir predicado a nodo los predicados disponibles sera\u0301n {type = photo, type = user}, y en el caso del refinamiento an\u0303adir predicado a arista, los predicados disponibles sera\u0301n {type = publish, type = likes, type = husband}.\nFigura 2: Grafo Social.\nAdicionalmente, tenemos una propiedad en algunos nodos (los de tipo user) que indica su ge\u0301nero, con posibles valores F (female) y M (male), los nodos de tipo photo tendra\u0301n asociado un valor de ge\u0301nero None.\nAunque como hemos indicado el algoritmo GGQ-ID3 esta\u0301 preparado para construir a\u0301rboles de decisio\u0301n capaces de clasificar cualquier estructura (subgrafo) en un grafo con propiedades, con el fin de mostrar un primer ejemplo simple, abordamos un problema que solo intenta clasificar nodos, e intentaremos predecir el valor del ge\u0301nero en los mismos. Con el objetivo de que la exposicio\u0301n resulte ma\u0301s clara, y para evitar confusiones con la terminolog\u0301\u0131a, a los nodos pertenecientes al conjunto de entrenamiento los denominaremos objetos, mientras que dejaremos el te\u0301rmino nodos para los nodos del a\u0301rbol de decisio\u0301n en construccio\u0301n.\nEl algoritmo GGQ-ID3 construye el a\u0301rbol de decisio\u0301n de la Figura 3 (los nodos/aristas positivas son marcados en negro y los negativos en rojo) que es capaz de clasificar correctamente todos los nodos del grafo social de la Figura 2 segu\u0301n su ge\u0301nero: F, M o None. Todas las indicaciones que se hagan acerca de la construccio\u0301n siguen la representacio\u0301n mostrada en la citada figura.\nEl conjunto de entrenamiento inicial, L, lo forman todos los pares formados por objetos del grafo de datos y su correspondiente ge\u0301nero. En la ejecucio\u0301n del algoritmo el GGQ inicial, Q0, esta\u0301 compuesto por dos nodos positivos, uno de ellos con un predicado que exige pertenencia al subgrafo bajo evaluacio\u0301n (v \u2208 S) y otro que exige la condicio\u0301n contraria (v /\u2208 S). Como se ha comentado anteriormente, es habitual que el GGQ inicial corresponda a la mayor subestructura comu\u0301n en los subgrafos a clasificar, en este caso, la mayor estructura comu\u0301n esta\u0301 compuesta por un u\u0301nico nodo sin restricciones. Adema\u0301s, y por motivos de eficiencia, en cada paso del algoritmo se creara\u0301 un nodo positivo aislado con un\nFigura 3: A\u0301rbol de decisio\u0301n GGQ (grafo social).\npredicado que exige la no pertenencia al subgrafo bajo evalacuio\u0301n (v /\u2208 S) si es que no existe ningu\u0301n nodo aislado de este tipo en el GGQ actual. Si el subgrafo bajo evaluacio\u0301n no cubre todos los nodos del grafo en el que se encuentra inmerso (lo cual se cumple en todos los ejemplos presentados), an\u0303adir un nodo de este tipo no modifica la sema\u0301ntica asociada al GGQ al que es an\u0303adido.\nComo primer paso, el algoritmo analizara\u0301 que\u0301 refinamiento de REFS (y con que\u0301 para\u0301metros) aporta mayor ganancia de informacio\u0301n, dando como resultado el refinamiento +{ e +\n\u2212\u2192} entre los u\u0301nicos dos nodos existentes en Q0. Por lo que el primer nodo (ra\u0301\u0131z) del a\u0301rbol de decisio\u0301n sera\u0301 el que realice el test sobre la existencia o no de una arista saliente en alguno de los nodos en el subgrafo a evaluar. Aunque el refinamiento an\u0303adir arista genera un refinamiento de\ncuatro elementos, consideramos solo aquellos que intervienen en el proceso de clasificacio\u0301n, y no los que transmiten un conjunto vac\u0301\u0131o de objetos.\nDebido a que los subgrafos que se quieren clasificar esta\u0301n compuestos por un u\u0301nico objeto, este refinamiento evalu\u0301a la existencia o no de una arista saliente en este objeto. Las ramas correspondientes a la existencia (respectivamente, no existencia) de dicha relacio\u0301n trasmitira\u0301n los objetos que posean (respectivamente, no posean) una relacio\u0301n saliente. De acuerdo a la representacio\u0301n dada en la Figura 3, por la rama derecha se trasmitira\u0301n todos los objetos que no posean una relacio\u0301n saliente (en este caso concreto, todos los objetos del grafo de datos de tipo photo y ninguno de tipo user), ninguno de estos objetos poseen valor asociado a la propiedad genre por lo que directamente esta rama queda asociada al valor de salida None y genera una hoja del a\u0301rbol de decisio\u0301n (ya que presenta pureza ma\u0301xima respecto de la clasificacio\u0301n buscada). Por la rama izquierda se trasmitira\u0301n todos los objetos que posean una relacio\u0301n saliente (en este caso, todos los objetos del grafo de datos de tipo user y ninguno de tipo photo).\nComo los valores de la propiedad genre no son homoge\u0301neos para estos objetos (este nodo del a\u0301rbol de decisio\u0301n actual presenta impureza), el algoritmo no acaba y es necesario aplicar un nuevo refinamiento a esta rama que produzca alguna ganancia de informacio\u0301n adicional. Recordemos que hasta este nodo han llegado los objetos que reflejan usuarios masculinos y femeninos con una arista saliente. De nuevo, se debe evaluar que\u0301 refinamiento aporta una mayor ganancia de informacio\u0301n.\nEl refinamiento +{e\u2227{type=publish}\u2212\u2192 }, an\u0303adir un nuevo predicado a la arista saliente, es el que mayor ganancia de informacio\u0301n aporta. De nuevo, aunque este refinamiento contiene cuatro GGQ, representamos solo aquellos que intervienen en el proceso de clasificacio\u0301n.\nLos refinamientos aplicados a este nodo del a\u0301rbol de decisio\u0301n discriminara\u0301n que\u0301 objetos (de los que le llegan, que son los que tienen una arista saliente) verifican que esta arista es de tipo publish y cua\u0301les no. De acuerdo a la representacio\u0301n dada en la Figura 3, por la rama derecha de dicho nodo se transmitira\u0301n los objetos que no tengan una arista saliente de tipo publish. En el caso que estamos clasificando, todos estos objetos son usuarios de ge\u0301nero masculino, por lo que se alcanza la condicio\u0301n de parada de ma\u0301xima pureza y el nodo pasa a ser una hoja del a\u0301rbol de decisio\u0301n asociada a la clase M. Por la rama izquierda del nodo se transmitira\u0301n los objetos del grafo de datos que tengan una arista saliente de tipo publish. En este caso, de nuevo los valores de la propiedad genre no son homoge\u0301neos (presentan impureza) por lo que el algoritmo debe continuar buscando un nuevo refinamiento en esta rama.\nProcedemos, pues, a repetir el procedimiento para este nodo, al que han llegado los objetos que se corresponden con usuarios con propiedades M y F con una arista saliente de tipo publish. El refinamiento que mayor ganancia de informacio\u0301n aporta es +{ e +\n\u2212\u2192}, an\u0303adir una arista entre el nodo aislado (v /\u2208 S) y el nodo destino de la relacio\u0301n tipo publish. De nuevo, tomamos en cuenta solo aquellos refinamientos por los que se transmiten objetos del grafo de datos original. La interpretacio\u0301n a este nivel del a\u0301rbol de decisio\u0301n es discriminar, de entre los objetos que han publicado algo, aquellos cuya publicacio\u0301n recibe alguna arista entrante por otro objeto que no pertenece a la estructura bajo evaluacio\u0301n y los que no.\nDe las dos ramas que producen algu\u0301n tipo de filtrado efectivo, por la derecha (siempre segu\u0301n la representacio\u0301n de la Figura 3) se transmitira\u0301n los objetos que no cumplan con dicha condicio\u0301n. Todos estos objetos son usuarios de ge\u0301nero M (y representan usuarios que han publicado una foto que no le gusta a nadie), por lo que se alcanza la condicio\u0301n de parada (ma\u0301xima pureza) y el nodo se convierte en una hoja del a\u0301rbol de decisio\u0301n asociada a la clase M. Por la rama izquierda se transmitira\u0301n los usuarios que hayan publicado una fotograf\u0301\u0131a y les haya gustado a alguien (esta fotograf\u0301\u0131a publicada tiene una arista entrante que no proviene del nodo bajo evaluacio\u0301n). Todos estos usuarios son de ge\u0301nero F, por lo que se verifica tambie\u0301n la condicio\u0301n de parada y la hoja producida queda asociada a la clase correspondiente.\nDe esta manera, obtenemos un a\u0301rbol de decisio\u0301n que es capaz de clasificar correctamente todos los objetos en el grafo de datos asigna\u0301ndolos correctamente a la clase a la que pertenecen segu\u0301n su ge\u0301nero haciendo uso de la estructura multi-relacional en la que se encuentran inmersos.\nAdema\u0301s, la interpretacio\u0301n de los diversos nodos del a\u0301rbol de decisio\u0301n muestra claramente co\u0301mo, por medio de los Generalized Graph Queries y el sistema de refinamientos construido, se pueden conseguir refinamientos que evalu\u0301an propiedades del contexto diferenciando entre los objetos que deben estar dentro de la estructura analizada y aquellos que deben estar fuera, ampliando considerablemente la capacidad expresiva del sistema de consulta y, en consecuencia, su capacidad discriminadora."}, {"heading": "5. Ejemplos de Aplicacio\u0301n", "text": "A continuacio\u0301n presentamos algunos ejemplos de a\u0301rboles de decisio\u0301n multirelacionales que hacen uso de GGQ y que han sido obtenidos siguiendo el algoritmo GGQ-ID3 presentado. Al igual que en el caso explicado anteriormente, se han ido an\u0303adiendo nodos positivos aislados no pertenecientes al subgrafo bajo evaluacio\u0301n en cada paso si no exist\u0301\u0131an en el GGQ y se ha partido de GGQ iniciales que conten\u0301\u0131an un nodo positivo con un predicado que lo fija al subgrafo bajo evaluacio\u0301n y otro nodo positivo con la restriccio\u0301n contraria.\nLos ejemplos han sido extra\u0301\u0131dos de bases de datos en grafo pequen\u0303as pero con la suficiente complejidad como para mostrar la capacidad de descubrimiento de patrones que posee el algoritmo GGQ-ID3. No mostraremos los a\u0301rboles completos resultantes (debido a la falta de resolucio\u0301n del papel para ser mostrados adecuadamente) sino so\u0301lo las hojas clasificadoras o algunas de las ramas ma\u0301s interesantes."}, {"heading": "5.1. StarWars", "text": "El primer ejemplo obtenido a trave\u0301s del algoritmo GGQ-ID3 lo conseguimos minando el grafo presentado en la Figura 4 con informacio\u0301n sobre StarWars 1.\nLos GGQ presentados en la Figura 5 permiten discriminar cada personaje presente en el grafo segu\u0301n si es devoto del Imperio, de la Rebelio\u0301n o de ninguno de los dos bandos. Se corresponden con las diversas hojas clasificadoras del a\u0301rbol de decisio\u0301n calculado automa\u0301ticamente. Para ello, los nodos de tipo institution (junto con las aristas en las que participan) han sido eliminados de dicho grafo.\n1http://console.neo4j.org/?id=StarWars\nFigura 4: Grafo Starwars.\nLas posibles clases en las que clasifica el a\u0301rbol obtenido son: empire, rebellion o None (en el caso en el que el personaje no sea devoto de ninguna de las dos instituciones).\nLos GGQ obtenidos en las hojas muestran que incluso trabajando con grafos relativamente pequen\u0303os el nivel de complejidad que pueden alcanzar las consultas proporcionan ejemplos muy interesantes de aprendizaje de patrones de forma automa\u0301tica usando la metodolog\u0301\u0131a presentada."}, {"heading": "5.2. El Hobbit", "text": "El segundo ejemplo lo obtenemos minando otro grafo de juguete habitual en las pruebas realizadas para bases de datos en grafo, en este caso relacionado con la historia del Sen\u0303or de los Anillos 2. Este grafo contiene 105 nodos distribuidos a trave\u0301s de 7 tipos (Character, Event, Item, Clan, Aligment, Location y Chapter) y 209 aristas distribuidas a trave\u0301s de 65 tipos. Parte de su intere\u0301s para hacer pruebas de aprendizaje de estructuras radica en que presenta una tipolog\u0301\u0131a en aristas muy elevada, con muy pocos representantes de algunos tipos de aristas, por lo que mecanismos ineficientes tendera\u0301n a crear a\u0301rboles muy grandes como u\u0301nico me\u0301todo para poder realizar clasificaciones multi-relacionales. La Figura 6 muestra un subgrafo extra\u0301\u0131do de esta pequen\u0303a base de datos.\nEl a\u0301rbol de decisio\u0301n presentado en la Figura 7 se ha obtenido automa\u0301ticamente por medio de GGQ-ID3 y permite discriminar los posibles tipos de ubicacio\u0301n (Location) presentes (Hills, Forest, Valley, Mountain, Caves y Lake). En la construccio\u0301n del a\u0301rbol se ha impuesto una profundidad ma\u0301xima de 5 niveles y se han eliminado algunas ramas por motivos de presentacio\u0301n.\n2http://neo4j.com/graphgist/c43ade7d259a77fe49a8\nFigura 5: Hojas del a\u0301rbol de decisio\u0301n GGQ (grafo Starwars)"}, {"heading": "6. Algunas Notas sobre la Implementacio\u0301n", "text": "Con el fin de hacer pruebas de verificacio\u0301n sobre el sistema de consultas creado (GGQ) y el algoritmo GGQ-ID3 que hace uso del mismo, se ha llevado a cabo una implementacio\u0301n como prueba de concepto 3 en el lenguaje de programacio\u0301n Python que hace uso de la base de datos en grafo Neo4j 4 como sistema de persistencia. La verificacio\u0301n de un GGQ sobre subgrafos almacenados en Neo4j ha sido realizada apoya\u0301ndose en el lenguaje de consultas Cypher, donde las evaluaciones relacionadas con la existencia de caminos son muy expresivas y esta\u0301n altamente optimizadas.\nSin lugar a dudas, esta implementacio\u0301n ganar\u0301\u0131a en eficiencia si, en lugar de haber desarrollado el sistema de consulta sobre el lenguaje Cypher, se hubiera utilizado la API Java de Neo4j o incluso implementando un sistema de persistencia ad hoc orientado a soportar este tipo de tareas, pero nuestro objetivo ha\n3https://github.com/palmagro/ggq 4http://neo4j.org\nFigura 6: Seccio\u0301n del grafo El Hobbit.\nsido el de demostrar que el sistema formal de consultas es capaz de realizar este tipo de tareas de forma sencilla.\nEn la implementacio\u0301n se han realizado algunas optimizaciones leves, pero que son determinantes para poder llevar a cabo la tarea de forma efectiva, como por ejemplo aprovechar la complementariedad de los GGQ resultantes de un refinamiento para ahorrar tiempo en las consultas y podar directamente las hojas a las que no llega ningu\u0301n elemento del conjunto de entrenamiento.\nPor la forma en que se construyen los refinamientos, y como se almacenan en el a\u0301rbol de decisio\u0301n, si un objeto verifica un GGQ, tambie\u0301n verificara\u0301 todos los GGQ antecesores de e\u0301ste, por lo que la potencia clasificadora de un a\u0301rbol de decisio\u0301n obtenido a trave\u0301s del algoritmo GGQ-ID3 esta\u0301 contenida en las hojas del a\u0301rbol. Sin embargo, para ganar eficiencia, a la hora de clasificar un ejemplo nuevo a partir del a\u0301rbol obtenido, se aconseja usar el a\u0301rbol completo, ya que solo sera\u0301n necesarias, a lo sumo, k evaluaciones (con k la profundidad del a\u0301rbol), pero puede haber una cantidad exponencial de hojas clasificadoras. Adema\u0301s, como de un nivel al siguiente se ha producido una modificacio\u0301n ato\u0301mica, aportada por el refinamiento correspondiente, la evaluacio\u0301n de un subgrafo en un nodo del a\u0301rbol de decisio\u0301n supone considerar u\u0301nicamente algunas comprobaciones adicionales a la evaluacio\u0301n de su nodo padre."}, {"heading": "7. Conclusiones y Trabajo Futuro", "text": "En este art\u0301\u0131culo se ha presentado el algoritmo GGQ-ID3, que hace uso de los Generalized Graph Queries como herramientas de test para la construccio\u0301n de un a\u0301rbol de decisio\u0301n siguiendo los fundamentos del algoritmo ID3. En los resultados de los experimentos llevados a cabo, se muestra que GGQ-ID3 es capaz de extraer patrones interesantes que pueden ser utilizados en tareas de aprendizaje complejas. Para ello, basta considerar los GGQ contenidos en las hojas como nuevos atributos descubiertos por el algoritmo. De esta forma, adema\u0301s de construir un a\u0301rbol clasificador, el algoritmo es capaz de descubrir patrones\nFigura 7: A\u0301rbol de decisio\u0301n GGQ (grafo El Hobbit).\nque caracterizan diferentes estructuras en el grafo (graph pattern mining) y que pueden ser utilizados como atributos de las estructuras clasificadoras en tareas posteriores (feature extraction).\nHemos mostrado un conjunto inicial de refinamientos a la hora de presentar ejemplos de aplicacio\u0301n del algoritmo GGQ-ID3, pero este conjunto puede ser modificado an\u0303adiendo refinamientos acordes a la estructura del grafo utilizado en el aprendizaje o a la tarea a la que se orienta el mismo.\nEl algoritmo MRDTL fue desarrollado hace ma\u0301s de una de\u0301cada para trabajar espec\u0301\u0131ficamente en bases de datos relacionales y con tareas simples de clasificacio\u0301n, y puede ser visto como un caso particular del algoritmo GGQ-ID3 en el que so\u0301lo se permiten GGQ con forma de a\u0301rbol (ya que hacen uso de grafos de seleccio\u0301n) y donde so\u0301lo se permite aprendizaje a partir de estructuras formadas por un u\u0301nico nodo. En este sentido, GGQ-ID3 supone un salto adelante en una l\u0301\u0131nea de trabajo iniciada hace an\u0303os y que se consideraba estancada desde entonces.\nEl principal problema que presentan los algoritmos de construccio\u0301n de a\u0301rboles de decisio\u0301n multi-relacionales es que el espacio de hipo\u0301tesis es extremadamente grande, y evidentemente GGQ-ID3 no esta\u0301 libre de este problema. Para reducir su complejidad y orientar la bu\u0301squeda se pueden proponer varias soluciones. Por un lado, se puede analizar de manera estad\u0301\u0131stica la frecuencia de aparicio\u0301n de ciertas estructuras atendiendo a las propiedades que intervienen\ny a las restricciones asociadas con el fin de reducir el nu\u0301mero de posibles refinamientos a aplicar en cada caso y reducir el coste de la bu\u0301squeda del mejor refinamiento. Para ello es necesario hacer uso de diversas medidas desarrolladas para grafos generalizados que extienden las medidas de frecuencia ma\u0301s simples que se usan en el caso de MRDTL-2 [2]. Por otro lado, se pueden crear familias de refinamientos ma\u0301s complejos (por ejemplo, combinar el refinamiento an\u0303adir arista con an\u0303adir propiedad a una arista en un solo paso) para de esta manera reducir el nu\u0301mero de pasos para obtener GGQ complejos y ampliar la reduccio\u0301n de impureza que suponen los pasos ato\u0301micos que son menos informativos. Si se lleva a cabo esta u\u0301ltima opcio\u0301n de manera adecuada (unificando los refinamientos en funcio\u0301n de la frecuencia de aparicio\u0301n de estructuras en el grafo) se puede conseguir que el algoritmo se acerque de manera ma\u0301s ra\u0301pida a la solucio\u0301n. En ambos casos se consigue una mejora en la eficiencia sacrificando la posibilidad de cubrir un espacio de hipo\u0301tesis ma\u0301s amplio (pero que probablemente ofrece alternativas en las que la reduccio\u0301n de impureza es menor). En este sentido, en este trabajo se ha ofrecido un conjunto minimal de refinamientos bien construidos, pero debe tenerse en cuenta que no se ofrecen con la intencio\u0301n de que sea o\u0301ptimo para ciertas tareas de aprendizaje.\nEl segundo gran problema que tiene el agoritmo GGQ-ID3 (y que es heredado por todos los algoritmos inspirados en ID3) es la imposibilidad de deshacer las decisiones tomadas durante la construccio\u0301n del a\u0301rbol. De tal manera que las opciones de refinamiento en un paso determinado del algoritmo dependen de los refinamientos elegidos en pasos anteriores y determinan, hasta cierto punto, las opciones futuras. Para solucionar este problema, es habitual utilizar algu\u0301n procedimiento de backtracking que permita deshacer decisiones si han desembocado en un mal resultado, o algu\u0301n procedimiento de Beam-Search, como el utilizado en el algoritmo GBI [8], que permita tomar varias decisiones en paralelo, y finalmente seleccionar la que haya derivado en una mejor solucio\u0301n.\nCon respecto a los trabajos futuros que derivan del desarrollo aqu\u0301\u0131 presentado, cabe mencionar que, gracias a que los GGQ esta\u0301n construidos utilizando la estructura de grafo generalizado, y que dicha estructura permite la definicio\u0301n de hipergrafos de manera natural, los GGQ pueden evaluar hipergrafos con propiedades teniendo en cuenta pequen\u0303as modificaciones sobre las definiciones presentadas, por lo que la extensio\u0301n de los Generalized Graph Queries hacia Generalized Hypergraph Queries y por tanto a un GGQ-ID3 capaz de aprender de hipergrafos es un paso natural que merece la pena ser considerado. Adema\u0301s, el desarrollo de diferentes conjuntos de refinamiento en funcio\u0301n del tipo de grafo a consultar o incluso la generacio\u0301n automa\u0301tica de dichos conjuntos a partir de estad\u0301\u0131sticas extra\u0301\u0131das del grafo a analizar puede derivar en optimizaciones importantes en procesos de construccio\u0301n automa\u0301tica y efectiva de GGQ. Por u\u0301tlimo, cabe destacar que a pesar de que los GGQ ya esta\u0301n siendo utilizados por procedimientos de descubrimiento/aprendizaje como el algoritmo GGQ-ID3, son grandes candidatos para ser utilizados por otros algoritmos de este tipo.\nLos a\u0301rboles de decisio\u0301n constituyen una herramienta ido\u0301nea de Aprendizaje Automa\u0301tico para ser combinada a trave\u0301s de algu\u0301n modelo ensemble, como Random Forest, gracias a su bajo coste computacional en el entrenamiento y a la aletoriedad conseguida en el modelo a partir de pequen\u0303os cambios en el conjunto de datos de los que aprender. Por ello, disponer de modelos adecuados de generacio\u0301n automa\u0301tica de a\u0301rboles de decisio\u0301n multi-relacionales se convierte en una tarea de gran importancia en el conjunto de la Inteligencia Artificial.\nEl aprendizaje automa\u0301tico que hace uso de informacio\u0301n relacional ha estado (y sigue estando) en un segundo plano en relacio\u0301n al aprendizaje automa\u0301tico ma\u0301s esta\u0301ndar, que hace uso de informacio\u0301n no relacional, habitualmente en forma de tablas y otras estructuras ma\u0301s regulares. Las bases de datos que ma\u0301s habitualmente se han utilizado, y en las que se encuentra almacenada la informacio\u0301n referente a la mayor\u0301\u0131a de los feno\u0301menos estudiados, hacen uso de esquemas y sistemas basados en bases de datos relacionales, que no muestran un desempen\u0303o o\u0301ptimo al trabajar con relaciones complejas. Adema\u0301s, la mayor riqueza expresiva de las estructuras de representacio\u0301n de la informacio\u0301n ma\u0301s complejas impone una mayor dificultad a la hora de realizar nuevos algoritmos y proporciona, al menos en las primeras aproximaciones, resultados menos llamativos que los me\u0301todos ma\u0301s depurados y ma\u0301s tradicionales.\nCon respecto al aprendizaje en grafos con propiedades, cabe destacar que existen varias l\u0301\u0131neas de trabajo que transforman los datos originales (en forma de grafo) hacia otras estructuras que los algoritmos ma\u0301s extendidos son capaces de manejar de manera ma\u0301s natural (debido a que fueron creados para trabajar espec\u0301\u0131ficamente con dichas estructuras). Es el caso de las inmersiones de grafos en espacios vectoriales [20, 26], as\u0301\u0131 como de la propuesta presentada en [9], que muestrean el grafo a partir de subestructuras para acomodarlo a una coleccio\u0301n de objetos (pares (elemento, contexto)) que los algoritmos tradicionales pueden consumir de manera o\u0301ptima. Tambie\u0301n es el caso de los trabajos que usan Redes Neuronales Convolucionales para realizar tareas de aprendizaje en grafos [12, 5, 6]. Para poder utilizar este tipo de modelos sobre grafos debemos definir que\u0301 se entiende por el contexto espacial de un elemento del grafo, haciendo suposiciones que incluyen un sesgo adicional a la informacio\u0301n analizada. Desde nuestro punto de vista, e\u0301stas son aproximaciones va\u0301lidas que deben seguir siendo investigadas, pero se deben considerar otras opciones como la de trabajar directamente con la estructura de grafo, que ha sido una de las l\u0301\u0131neas de investigacio\u0301n seguidas en este trabajo y que ha demostrado ser va\u0301lida.\nOtra caractert\u0301\u0131stica importante de los me\u0301todos de aprendizaje basados en a\u0301rboles de decisio\u0301n es que representan un modelo de caja blanca, ofreciendo una explicacio\u0301n interpretable por un humano de las decisiones tomadas a la hora de realizar regresio\u0301n o clasificacio\u0301n. En el caso del algoritmo GGQ-ID3, este caracter\u0301\u0131stica es potenciada gracias a la interpretabilidad de los GGQ.\nEl hecho de que perdamos capacidad en la interpretacio\u0301n de un resultado al combinar a\u0301rboles multi-relacionales no impide que algoritmos como GGQ-ID3 puedan ser combinados en este tipo de me\u0301todos agregados para llevar a cabo tareas de prediccio\u0301n de tipo caja negra. Sin embargo, existen posibilidades para combinar diferentes a\u0301rboles de este tipo y que sigan ofreciendo justificaciones interpretables por los humanos. Una posibilidad es combinar los GGQ de hojas asociadas a la misma clase en los diferentes a\u0301rboles, dando lugar a patrones combinados (posiblemente de manera probabil\u0301\u0131stica) que son capaces de condensar los diferentes predicados que caracterizan a una misma clase en un predicado ma\u0301s potente.\nReferencias\n[1] P. Almagro-Blanco and F. Sancho-Caparrini. Generalized Graph Pattern Matching. arXiv e-prints arXiv:1708.03734.\n[2] Anna Atramentov, Hector Leiva, and Vasant Honavar. A Multi-relational Decision Tree Learning Algorithm \u2013 Implementation and Experiments, pages 38\u201356. Springer Berlin Heidelberg, Berlin, Heidelberg, 2003.\n[3] Hendrik Blockeel and Luc De Raedt. Top-down induction of logical decision trees.\n[4] Hendrik Blockeel and Luc De Raedt. Top-down induction of first-order logical decision trees. Artificial Intelligence, 101(1):285 \u2013 297, 1998.\n[5] Michae\u0308l Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. CoRR, abs/1606.09375, 2016.\n[6] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2224\u20132232. Curran Associates, Inc., 2015.\n[7] Warodom Geamsakul, Takashi Matsuda, Tetsuya Yoshida, Hiroshi Motoda, and Takashi Washio. Classifier Construction by Graph-Based Induction for Graph-Structured Data, pages 52\u201362. Springer Berlin Heidelberg, Berlin, Heidelberg, 2003.\n[8] Warodom Geamsakul, Tetsuya Yoshida, Kouzou Ohara, Hiroshi Motoda, Hideto Yokoi, and Katsuhiko Takabayashi. Constructing a decision tree for graph-structured data and its applications. Fundam. Inf., 66(1-2):131\u2013160, November 2004.\n[9] Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks, 2016. cite arxiv:1607.00653 Comment: In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016.\n[10] Yi He, Jian-chao Han, and Shao-hua Zeng. Classification Algorithm based on Improved ID3 in Bank Loan Application, pages 1124\u20131130. Springer London, London, 2012.\n[11] Yusuf Kavurucu, Pinar Senkul, and Ismail Hakki Toroslu. Confidence-based concept discovery in multi-relational data mining.\n[12] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.\n[13] Arno J. Knobbe, Arno Siebes, Danil Van Der Wallen, and Syllogic B. V. Multi-relational decision tree induction. In In Proceedings of PKDD\u2019 99, Prague, Czech Republic, Septembre, pages 378\u2013383. Springer, 1999.\n[14] He\u0301ctor Ariel Leiva, Shashi Gadia, and Drena Dobbs. Mrdtl: A multirelational decision tree learning algorithm. In Proceedings of the 13th International Conference on Inductive Logic Programming (ILP 2003, pages 38\u201356. Springer-Verlag, 2002.\n[15] Juan Li. Improved multi-relational decision tree classification algorithm.\n[16] Thomas M. Mitchell. Machine Learning. McGraw-Hill, Inc., New York, NY, USA, 1 edition, 1997.\n[17] Phu Chien Nguyen, Kouzou Ohara, Akira Mogi, Hiroshi Motoda, and Takashi Washio. Constructing Decision Trees for Graph-Structured Data by Chunkingless Graph-Based Induction, pages 390\u2013399. Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.\n[18] Phu Chien Nguyen, Kouzou Ohara, Hiroshi Motoda, and Takashi Washio. Cl-GBI: A Novel Approach for Extracting Typical Patterns from GraphStructured Data, pages 639\u2013649. Springer Berlin Heidelberg, Berlin, Heidelberg, 2005.\n[19] Neelamadhab Padhy and Rasmita Panigrahi. Multi relational data mining approaches: A data mining technique. CoRR, abs/1211.3871, 2012.\n[20] Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social representations. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD \u201914, pages 701\u2013710, New York, NY, USA, 2014. ACM.\n[21] Gordon Plotkin. Automatic methods of inductive inference. 1972.\n[22] J. R. Quinlan. Induction of decision trees. Mach. Learn., 1(1):81\u2013106, March 1986.\n[23] J. Ross Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1993.\n[24] Marcos Salganicoff, Lyle H. Ungar, and Ruzena Bajcsy. Active learning for vision-based robot grasping. Machine Learning, 23(2):251\u2013278, 1996.\n[25] Anand Takale. Constructing Predictive Models to Assess the Importance of Variables in Epidemiological Data Using A Genetic Algorithm System employing Decision Trees. PhD thesis, UNIVERSITY OF MINNESOTA, 2004.\n[26] Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In Proceedings of the 24th International Conference on World Wide Web, WWW \u201915, pages 1067\u20131077, New York, NY, USA, 2015. ACM.\n[27] Xiaoxin Yin, Jiawei Han, Jiong Yang, and Philip S. Yu. CrossMine: Efficient Classification Across Multiple Database Relations, pages 172\u2013195. Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.\n[28] Wei Zhang. Multi-relational data mining based on higher-order inductive logic programming. 2013 Fourth Global Congress on Intelligent Systems, 2:453\u2013458, 2009."}], "references": [{"title": "A Multi-relational Decision Tree Learning Algorithm \u2013 Implementation and Experiments, pages 38\u201356", "author": ["Anna Atramentov", "Hector Leiva", "Vasant Honavar"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Top-down induction of first-order logical decision trees", "author": ["Hendrik Blockeel", "Luc De Raedt"], "venue": "Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1998}, {"title": "Classifier Construction by Graph-Based Induction for Graph-Structured Data, pages 52\u201362", "author": ["Warodom Geamsakul", "Takashi Matsuda", "Tetsuya Yoshida", "Hiroshi Motoda", "Takashi Washio"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Constructing a decision tree for graph-structured data and its applications", "author": ["Warodom Geamsakul", "Tetsuya Yoshida", "Kouzou Ohara", "Hiroshi Motoda", "Hideto Yokoi", "Katsuhiko Takabayashi"], "venue": "Fundam. Inf.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2004}, {"title": "Classification Algorithm based on Improved ID3 in Bank Loan Application, pages 1124\u20131130", "author": ["Yi He", "Jian-chao Han", "Shao-hua Zeng"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Multi-relational decision tree induction", "author": ["Arno J. Knobbe", "Arno Siebes", "Danil Van Der Wallen", "Syllogic B. V"], "venue": "Proceedings of PKDD\u2019 99,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "Mrdtl: A multirelational decision tree learning algorithm", "author": ["H\u00e9ctor Ariel Leiva", "Shashi Gadia", "Drena Dobbs"], "venue": "In Proceedings of the 13th International Conference on Inductive Logic Programming (ILP", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Machine Learning. McGraw-Hill, Inc., New York, NY, USA, 1 edition", "author": ["Thomas M. Mitchell"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1997}, {"title": "Constructing Decision Trees for Graph-Structured Data by Chunkingless Graph-Based Induction, pages 390\u2013399", "author": ["Phu Chien Nguyen", "Kouzou Ohara", "Akira Mogi", "Hiroshi Motoda", "Takashi Washio"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Cl-GBI: A Novel Approach for Extracting Typical Patterns from Graph- Structured Data, pages 639\u2013649", "author": ["Phu Chien Nguyen", "Kouzou Ohara", "Hiroshi Motoda", "Takashi Washio"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Multi relational data mining approaches: A data mining technique", "author": ["Neelamadhab Padhy", "Rasmita Panigrahi"], "venue": "CoRR, abs/1211.3871,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Automatic methods of inductive inference", "author": ["Gordon Plotkin"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1972}, {"title": "Programs for Machine Learning", "author": ["J. Ross Quinlan"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Active learning for vision-based robot grasping", "author": ["Marcos Salganicoff", "Lyle H. Ungar", "Ruzena Bajcsy"], "venue": "Machine Learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1996}, {"title": "Constructing Predictive Models to Assess the Importance of Variables in Epidemiological Data Using A Genetic Algorithm System employing Decision Trees", "author": ["Anand Takale"], "venue": "PhD thesis, UNIVERSITY OF MINNESOTA,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "CrossMine: Efficient Classification Across Multiple Database Relations, pages 172\u2013195", "author": ["Xiaoxin Yin", "Jiawei Han", "Jiong Yang", "Philip S. Yu"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Induction of decision trees", "author": ["J.R. Quinlan"], "venue": "Mach. Learn.,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1986}, {"title": "Programs for Machine Learning", "author": ["J. Ross Quinlan"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1993}, {"title": "Active learning for vision-based robot grasping", "author": ["Marcos Salganicoff", "Lyle H. Ungar", "Ruzena Bajcsy"], "venue": "Machine Learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1996}, {"title": "Constructing Predictive Models to Assess the Importance of Variables in Epidemiological Data Using A Genetic Algorithm System employing Decision Trees", "author": ["Anand Takale"], "venue": "PhD thesis, UNIVERSITY OF MINNESOTA,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2004}, {"title": "Line: Large-scale information network embedding", "author": ["Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei"], "venue": "In Proceedings of the 24th International Conference on World Wide Web, WWW", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "CrossMine: Efficient Classification Across Multiple Database Relations, pages 172\u2013195", "author": ["Xiaoxin Yin", "Jiawei Han", "Jiong Yang", "Philip S. Yu"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Multi-relational data mining based on higher-order inductive logic programming", "author": ["Wei Zhang"], "venue": "Fourth Global Congress on Intelligent Systems,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}], "referenceMentions": [{"referenceID": 14, "context": "ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7].", "startOffset": 214, "endOffset": 225}, {"referenceID": 13, "context": "ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7].", "startOffset": 214, "endOffset": 225}, {"referenceID": 4, "context": "ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7].", "startOffset": 214, "endOffset": 225}, {"referenceID": 11, "context": "Inductive Logic Programming (ILP) [16] is a machine learning area that uses Logic Programming to consistently represent examples, knowledge bases, and hypotheses.", "startOffset": 34, "endOffset": 38}, {"referenceID": 10, "context": "ILP provides interpretability, but is inefficient when working with complex databases [15].", "startOffset": 86, "endOffset": 90}, {"referenceID": 1, "context": "The Top-Down Induction of Logical Decision Trees (TILDE) algorithm builds logical decision trees from a set of classified examples [4].", "startOffset": 131, "endOffset": 134}, {"referenceID": 15, "context": "Yin Xiaoxin [20] designed CrossMine, a multi-relational classification model that merges ILP and relational databases, improving efficiency in this type of tasks through virtual joins [11].", "startOffset": 12, "endOffset": 16}, {"referenceID": 6, "context": "Multi-Relational Decision Tree Learning (MRDTL) is a multi-relational machine learning algorithm [10] based on the ideas of Knobles et al.", "startOffset": 97, "endOffset": 101}, {"referenceID": 5, "context": "[9] that works with Selection Graphs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Graph-Based Induction (GBI) is a data mining technique to perform network motifs mining from labelled and directed graphs through the union of pairs of connected nodes [14].", "startOffset": 168, "endOffset": 172}, {"referenceID": 2, "context": "(called patterns or substructures) are generated during the execution of the algorithm [5], adding feature extraction capacity [13].", "startOffset": 87, "endOffset": 90}, {"referenceID": 8, "context": "(called patterns or substructures) are generated during the execution of the algorithm [5], adding feature extraction capacity [13].", "startOffset": 127, "endOffset": 131}, {"referenceID": 12, "context": "Decision trees obtained in most automatic procedures divide the data into binary complementary subsets in a recursive way [17], but in the multi-relational case the production of complementary patterns of this type is not straightforward.", "startOffset": 122, "endOffset": 126}, {"referenceID": 7, "context": "Gain [12] will be used as impurity measure.", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "Thus, it is necessary to use measures developed for generalized graphs extending the simpler frequency measurements that are used in the case of MRDTL-2 [2].", "startOffset": 153, "endOffset": 156}, {"referenceID": 3, "context": "To solve this problem, some backtracking procedure can be considered, or some Beam-Search procedure (as in the algorithm GBI [6]), allowing to take several decisions in parallel, and finally select the one that has resulted in a better solution.", "startOffset": 125, "endOffset": 128}], "year": 2017, "abstractText": "A decision tree is a classification (and regression) model that, based on the characteristics of a given object, and applying a series of rules, is able to classify it (or return a continuous value in the case of regression). The induction of decision trees from a set of previously classified objects is one of the most popular machine learning models due, among other things, to the low computational demand in their training and the interpretability of their results, so it is a representative white box model. ID3 algorithm presented by R. Quinlan in 1983 for the automatic construction of decision trees from a training set of objects described through a collection of properties. Each object in the training set belongs to a class (usually represented by the value of its target attribute) of a set of mutually exclusive classes. ID3 has been one of the most used techniques in machine learning with applications to tasks as diverse as epidemics prediction, robot control, and automatic classification of clients in banks or insurance entities [19, 18, 7]. The main goal of this work is to offer a methodology that allows to carry out machine learning tasks using decision trees on multi-relational graph data. In this context, the number of possible properties of each object goes far beyond those that it has directly associated, since the properties of the elements that are related to it can also be considered attributes of the object, and even the topological structure formed by the objects in their environment and the various measures that can be taken from the graph structure could be considered as additional attributes. With this objective, we will analyse different techniques that allow automatic induction of decision trees from graph data and we will present our proposal, GGQ-ID3, that aims to provide a framework to classify substructures in a graph, from simple nodes and edges, to larger paths and subgraphs, making use of Generalized Graph Query (GGQ) [1]. This paper is structured as follows: we will start reviewing different techniques of induction of relational decision trees; then, we present our proposal based on the use of Generalized Graph Queries as evaluation tool; once our proposal is presented, we will show some examples of its application; and finally we present some conclusions and future work lines.", "creator": "LaTeX with hyperref package"}}}