{"id": "1708.07336", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Aug-2017", "title": "Active Sampling of Pairs and Points for Large-scale Linear Bipartite Ranking", "abstract": "bipartite ranking is a fundamental ranking problem that learns to order relevant instances ahead of irrelevant ones. specifically the pair - wise approach. for most bi - partite relational ranking tools construct a quadratic number composite of pairs to solve the problem, which is infeasible for large - scale robust data sets. the point - wise approach, frequently albeit more efficient, still often results in inferior performance. that is, perhaps it is difficult to conduct bipartite ranking only accurately and efficiently at the same time. in this paper, first we would develop a novel active sampling scheme within the pair - link wise approach to conduct bipartite ranking efficiently. the scheme is inspired from active learning and can reach a competitive ranking performance while focusing only on a small subset of the correlated many pairs during training. moreover, tentatively we propose a general combined ranking and classification ( crc ) statistical framework to accurately conduct bipartite ranking. the framework unifies earlier point - wise and pair - wise approaches and is simply based on the classical idea of treating each instance point as a pseudo - positive pair. experiments on 14 real - word large - scale data input sets demonstrate that the proposed algorithm of active sampling within crc, aimed when partly coupled specifically with a linear support vector machine, generally usually outperforms state - of - the - art point - wise and pair - wise ranking approaches in terms of both accuracy and efficiency.", "histories": [["v1", "Thu, 24 Aug 2017 09:43:17 GMT  (147kb,D)", "http://arxiv.org/abs/1708.07336v1", "a shorter version was presented in ACML 2013"]], "COMMENTS": "a shorter version was presented in ACML 2013", "reviews": [], "SUBJECTS": "cs.LG cs.IR", "authors": ["wei-yuan shen", "hsuan-tien lin"], "accepted": false, "id": "1708.07336"}, "pdf": {"name": "1708.07336.pdf", "metadata": {"source": "CRF", "title": "Active Sampling of Pairs and Points for Large-scale Linear Bipartite Ranking", "authors": ["Wei-Yuan Shen", "Hsuan-Tien Lin"], "emails": [], "sections": [{"heading": null, "text": "F"}, {"heading": "1 INTRODUCTION", "text": "The bipartite ranking problem aims at learning a ranking function that orders positive instances ahead of negative ones. For example, in information retrieval, bipartite ranking can be used to order the preferred documents in front of the less-preferred ones within a list of search-engine results; in bioinformatics, bipartite ranking can be used to identify genes related to a certain disease by ranking the relevant genes higher than irrelevant ones. Bipartite ranking algorithms take some positive and negative instances as the input data, and produce a ranking function that maps an instance to a real-valued score. Given a pair of a positive instance and a negative one, we say that the pair is misordered if the ranking function gives a higher score to the negative instance. The performance of the ranking function is measured by the probability of mis-ordering an unseen pair of randomly chosen positive and negative instances, which is equal to one minus the Area Under the ROC Curve (AUC) [16], a popular criterion for evaluating the sensitivity and the specificity of binary classifiers in many real-world tasks [9] and large-scale data mining competitions [8], [38].\nGiven the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27]. Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24]. The majority of those reduction-based algorithms can be categorized to two approaches: the pair-wise approach and the point-wise one. The pair-wise approach transforms the input data of positive and negative instances to pairs of instances, and learns a binary classifier for pre-\nW.-Y. Shen and H.-T. Lin are with the Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, e-mail: {r00922024, htlin}@csie.ntu.edu.tw. Manuscript received August ??, 2014; revised ??.\ndicting whether the first instance in a pair should be scored higher than the second one. Note that for an input data set that contains N+ positive instances and N\u2212 negative ones, the pair-wise approach trains a binary classifier by optimizing an objective function that consists of N+N\u2212 terms, one for each pair of instances. The pair-wise approach comes with strong theoretical guarantee. For example, [3] shows that a low-regret ranking function can indeed be formed by a low-regret binary classifier. The strong theoretical guarantee leads to promising experimental results in many state-ofthe-art bipartite ranking algorithms, such as RankSVM [20], RankBoost [17] and RankNet [6]. Nevertheless, the number of pairs in the input data can easily be of size \u0398(N2), where N is the size of the input data, if the data is not extremely unbalanced. The quadratic number of pairs with respect to N makes the pair-wise approach computationally infeasible for large-scale data sets in general, except in a few special algorithms like RankBoost [17] or the efficient linear RankSVM [22]. RankBoost enjoys an efficient implementation by reducing the quadratic number of pair-wise terms in the objective function to a linear number of equivalent terms; efficient linear RankSVM transforms the pair-wise optimization formulation to an equivalent formulation that can be solved in subquadratic time complexity [24].\nOn the other hand, the point-wise approach directly runs binary classification on the positive and negative instance points of the input data, and takes the scoring function behind the resulting binary classifier as the ranking function. In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30]. In other cases, the point-wise approach often operates with an approximate objective function that involves only N terms [24]. For example, [24] shows that minimizing the exponential or the logistic loss function on the instance points decreases an upper bound on the number of mis-ordered pairs within the input data. Because of the approximate nature of the point-wise approach, its\nar X\niv :1\n70 8.\n07 33\n6v 1\n[ cs\n.L G\n] 2\n4 A\nug 2\n01 7\n2 ranking performance can sometimes be inferior to the pairwise approach.\nFrom the discussion above, we see that the pair-wise approach leads to more satisfactory performance while the point-wise approach comes with efficiency, and there is a trade-off between the two. In this paper, we are interested in designing bipartite ranking algorithms that enjoy both satisfactory performance and efficiency for large-scale bipartite ranking. The concrete problem setup will be provided in Section 2. We focus on using the linear Support Vector Machine (SVM) [37] given its recent advances for efficient large-scale learning [40]. We first show that the loss function behind the usual point-wise SVM [37] minimizes an upper bound on the loss function behind RankSVM, which suggests that the point-wise SVM could be an approximate bipartite ranking algorithm that enjoys efficiency. Then, we design a better ranking algorithm with two major contributions.\nAs illustrated in Section 3, firstly, we study an active sampling scheme to select important pairs for the pairwise approach and name the scheme Active Sampling for RankSVM (ASRankSVM). The scheme makes the pair-wise SVM computationally feasible by focusing only on a few valuable pairs out of the quadratic number of pairs , and allows us to overcome the challenge of having a quadratic number of pairs. The active sampling scheme is inspired by active learning, another popular machine learning setup that aims to save the efforts of labeling [32]. More specifically, we discuss the similarity and differences between active sampling (selecting a few of valuable pairs within a pool of potential pairs) and pool-based active learning (labeling a few of valuable instances within a pool of unlabeled instances), and propose some active sampling strategies based on the similarity. Secondly, we propose a general framework that unifies the point-wise SVM and the pair-wise SVM (RankSVM) as special cases. The framework, called combined ranking and classification (CRC), is simply based on the idea of treating each instance point as a pseudo-pair. The CRC framework coupled with active sampling (ASCRC) improves the performance of the pointwise SVM by considering not only points but also pairs in its objective function.\nPerforming active sampling within the CRC framework leads to a promising algorithm for large-scale linear bipartite ranking. In Section 4, we conduct experiments on 14 real-world large-scale data sets and compare the proposed algorithms (ASRankSVM and ASCRC) with several stateof-the-art bipartite ranking algorithms, including the pointwise linear SVM [15], the efficient linear RankSVM [22], and the Combined Ranking and Regression (CRR) algorithm [31] which is closely related to the CRC framework. In addition, we demonstrate the robustness and the efficiency of the active sampling strategies and discuss some advantages and disadvantages of different strategies. The results show that ASRankSVM is able to efficiently sample only 8, 000 of the more than millions of the possible pairs to achieve better performance than other state-of-the-art algorithms that use all the pairs, while ASCRC that considers the pseudopairs can sometimes be helpful. Those results validate that the proposed algorithm can indeed enjoy both satisfactory performance and efficiency for large-scale bipartite ranking.\nA preliminary version of this paper appeared in the 5th Asian Conference on Machine Learning [34]. The paper is then enriched by 1) extending the design of the proposed CRC framework\nto allow a threshold term for the classification part in Section 3.5 2) examining the necessity of each part of the proposed CRC framework in Section 4.2 3) studying the effect of the budget parameter of active sampling in Section 4.4"}, {"heading": "2 SETUP AND RELATED WORKS", "text": "In a bipartite ranking problem, we are given a training set D = {(xk, yk)}Nk=1, where each (xk, yk) is a training instance with the feature vector xk in an n-dimensional space X \u2286 Rn and the binary label yk \u2208 {+1,\u22121}. Such a training set is of the same format as the training set in usual binary classification problems. We assume that the instances (xk, yk) are drawn i.i.d. from an unknown distribution P on X \u00d7 {+1,\u22121}. Bipartite ranking algorithms take D as the input and learn a ranking function r : X \u2192 R that maps a feature vector x to a real-valued score r(x).\nFor any pair of two instances, we call the pair misordered by r iff the pair contains a positive instance (x+,+1) and a negative one (x\u2212,\u22121) while r(x+) \u2264 r(x\u2212). For a distribution P that generates instances (x, y), we can define its pair distribution P2 that generates (x, y,x\u2032, y\u2032) to be the conditional probability of sampling two instances (x, y) and (x\u2032, y\u2032) from P , conditioned on y 6= y\u2032. Then, let the expected bipartite ranking loss LP (r) for any ranking function r be the expected number of mis-ordered pairs over P2.\nLP (r) = E (x,y,x\u2032,y\u2032)\u223cP2\n[ I ( (y \u2212 y\u2032)(r(x)\u2212 r(x\u2032)) \u2264 0 )] ,\nwhere I(\u2022) is an indicator function that returns 1 iff the condition (\u2022) is true, and returns 0 otherwise. The goal of bipartite ranking is to use the training set D to learn a ranking function r that minimizes the expected bipartite ranking loss LP (r).\nBecause P is unknown, LP (r) cannot be computed directly. Thus, bipartite ranking algorithms usually resort to the empirical bipartite ranking loss LD(r), which takes the expectation over the pairs in D instead of over the pair distribution P2, with the hope that LD(r) would be sufficiently close to LP (r) when the model complexity of the candidate ranking functions r is properly controlled. Denote D+ as the set of the positive instances in D, and D\u2212 as the set of negative instances in D. The formal definition of LD(r) is\nLD(r) = 1\nN+N\u2212 \u2211 xi\u2208D+ \u2211 xj\u2208D\u2212 I ( r(xi) \u2264 r(xj) ) .\nThe bipartite ranking loss LP (r) is closely related to the area under the ROC curve (AUC), which is commonly used to evaluate the sensitivity and the specificity of binary classifiers [5], [8], [9], [38]. More specifically, AUC calculates the expected number of correctly-ordered pairs. Hence, AUC\u2022(r) = 1 \u2212 L\u2022(r) for \u2022 = P or D, and higher AUC indicates better ranking performance.\n3 Bipartite ranking is a special case of the general ranking problem in which the labels y can be any real value, not necessarily {+1,\u22121}. There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems. In this paper, instead of considering the general ranking problem, we focus on using the specialty of bipartite ranking, namely its connection to binary classification, to improve the accuracy and the efficiency.\nMotivated by the recent advances of linear models for efficient large-scale learning [40], we consider linear models for efficient large-scale bipartite ranking. That is, the ranking functions would be of the form r(x) = wTx, which is linear to the components of the feature vector x. In particular, we study the linear Support Vector Machine (SVM) [37] for bipartite ranking. There are two possible approaches for adopting the linear SVM on bipartite ranking problem, the pair-wise SVM approach and the point-wise SVM approach.\nThe pair-wise approach corresponds to the famous RankSVM algorithm [20], which is originally designed for ranking with ordinal-scaled scores, but can be easily extended to general ranking with real-valued labels or restricted to bipartite ranking with binary labels. For each positive instance (xi, yi = +1) and negative instance (xj , yj = \u22121), the pair-wise approach transforms the two instances to two symmetric pairs of instance ((xi,xj),+1) and ((xj ,xi),\u22121), the former for indicating that xi should be scored higher than xj and the latter for indicating that xj should be scored lower than xi. In the linear case, the pairs transformed from D are then fed to a linear SVM for learning a ranking function of the form r(x) = wTx. Then, for the pair ((xi,xj),+1), we see that I ( r(xi) \u2264 r(xj) ) = 0\niff wT (xi \u2212 xj) > 0. Define the transformed feature vector xij = xi\u2212xj and the transformed label yij = sign(yi\u2212 yj), we can equivalently view the pair-wise linear SVM as simply running a linear SVM on the pair-wise training set Dpair = {(xij , yij)|yi 6= yj}. The pair-wise linear SVM minimizes the hinge loss as a surrogate to the 0/1 loss on Dpair [35], and the 0/1 loss on Dpair is equivalent to LD(r), the empirical bipartite ranking loss of interest. That is, if the linear SVM learns an accurate binary classifier using Dpair , the resulting ranker r(x) = wTx would also be accurate in terms of the bipartite ranking loss.\nDenote the hinge function max(\u2022, 0) by [\u2022]+, RankSVM solves the following optimization problem\nmin w\n1 2 wTw + \u2211 xij\u2208Dpair Cij [1\u2212wT yijxij ]+ , (1)\nwhere Cij denotes the weight of the pair xij . Because of the symmetry of xij and xji, we naturally assume that Cij = Cji. In the original RankSVM formulation, Cij is set to a constant for all the pairs. Here we list a more flexible formulation (1) to facilitate some discussions later. RankSVM has reached promising bipartite ranking performance in the literature [5]. Because of the symmetry of positive and negative pairs, we can equivalently solve (1) on those positive pairs with yij = 1. The number of such positive pairs is N+N\u2212 if there are N+ positive instances and N\u2212 negative ones. The huge number of pairs make it\ndifficult to solve (1) with a na\u0131\u0308ve quadratic programming algorithm.\nIn contrast with the na\u0131\u0308ve RankSVM, the efficient linear RankSVM [22] changes (1) to a more sophisticated and equivalent one with an exponential number of constraints, each corresponding to a particular linear combination of the pairs. Then, it reaches O(N logN) time complexity by using a cutting-plane solver to identify the most-violated constraints iteratively, while the constant hidden in the bigO notation depends on the parameter Cij as well as the desired precision of optimization. The subquadratic time complexity of the efficient RankSVM can make it much slower than the point-wise approach (to be discussed below), and hence may not always be fast enough for largescale bipartite ranking.\nThe point-wise SVM approach, on the other hand, directly runs an SVM on the original training set D instead of Dpair . That is, in the linear case, the point-wise approach solves the following optimization problem\nmin w\n1 2 wTw+C+ \u2211 xi\u2208D+ [1\u2212wTxi]++C\u2212 \u2211 xj\u2208D\u2212 [1+wTxj ]+ .\n(2) Such an approach comes with some theoretical justification [24]. In particular, the 0/1 loss on D has been proved to be an upper bound of the empirical bipartite ranking loss. In fact, the bound can be tightened by adjusting C+ and C\u2212 to balance the distribution of the positive and negative instances in D. When C+ = C\u2212, [5] shows that the pointwise approach (2) is inferior to the pair-wise approach (1) in performance. The inferior performance can be attributed to the fact that the point-wise approach only operates with an approximation (upper bound) of the bipartite ranking loss of interest.\nNext, inspired by the theoretical result of upperbounding the bipartite ranking loss with a balanced 0/1 loss, we study the connection between (1) and (2) by balancing the hinge loss in (2). In particular, as shown in Theorem 1, a balanced form of (2) can be viewed as minimizing an upper bound of the objective function within (1). In other words, the weighted point-wise SVM can be viewed as a reasonable baseline algorithm for large-scale bipartite ranking problem.\nTheorem 1. Let Cij = C2 be a constant in (1); C+ = 2N \u2212 \u00b7 C and C\u2212 = 2N+ \u00b7 C in (2). Then, for every w, the objective function of (1) is upper-bounded by 14 times the objective function of (2).\n4 Proof. The objective function of (1)\n= 1\n2 wTw + \u2211 xij\u2208Dpair,yij=+1 C[1\u2212wTxij ]+\n\u2264 1 2 wTw\n+ C\n2 \u2211 xi\u2208D+ \u2211 xj\u2208D\u2212 ( [1\u2212 2wTxi]+ + [1 + 2wTxj ]+ ) = 1\n2 wTw +\nC 2 \u00b7N\u2212 \u2211 xi\u2208D+ [1\u2212 2wTxi]+\n+ C\n2 \u00b7N+ \u2211 xj\u2208D\u2212 [1 + 2wTxj ]+.\nThe theorem can be easily proved by substituting 2w with a new variable u."}, {"heading": "3 PROPOSED ALGORITHM", "text": "As discussed in the previous section, the pair-wise approach (1) is infeasible on large-scale data sets due to the huge number of pairs. Then, either some random subsampling of the pairs are needed [31], or the less-accurate point-wise approach (2) is taken as the approximate alternative [24]. Nevertheless, the better ranking performance of the pair-wise approach over the point-wise one suggest that some of the key pairs shall carry more valuable information than the instance-points. Next, we design an algorithm that samples a few key pairs actively during learning. We first show that some proposed active sampling schemes can help identify those key pairs better than random sub-sampling. Then, we discuss how we can unify point-wise and pairwise ranking approaches under the same framework."}, {"heading": "3.1 Pool-based Active Learning", "text": "The pair-wise SVM approach (1) is challenging to solve because of the huge number of pairs involved in Dpair . To make the computation feasible, we can only afford to work on a small subset of Dpair during training. Existing algorithms conquer the computational difficulty of the huge number of pairs in different ways. The Combined Ranking and Regression approach [31] performs stochastic gradient descent on its objective function, which essentially selects within the huge number of pairs in a random manner; the efficient RankSVM [22] identifies the most-violated constraints during optimization, which corresponds to selecting the most valuable pairs from an optimization perspective.\nWe take an alternative route and hope to select the most valuable pairs from a learning perspective. That is, our task is to iteratively select a small number of valuable pairs for training while reaching similar performance to the pair-wise approach that trains with all the pairs. One machine learning setup that works for a similar task is active learning [32], which iteratively select a small number of valuable instances for labeling (and training) while reaching similar performance to the approach that trains with all the instances fully labeled. [1] avoids the quadratic number of pairs in the general ranking problem from an active learning perspective, and proves that selecting a subquadratic number of pairs is sufficient to obtain a ranking function that is\nclose to the optimal ranking function trained by using all the pairs. The algorithm is theoretical in nature, while many other promising active learning tools [25], [29], [32] have not been explored for selecting valuable pairs in large-scale bipartite ranking.\nNext, we start exploring those tools by providing a brief review about active learning. We focus on the setup of poolbased active learning [32] because of its strong connection to our needs. In a pool-based active learning problem, the training instances are separated into two parts, the labeled pool (L) and the unlabeled pool (U ). As the name suggests, the labeled pool consists of labeled instances that contain both the feature vector xk and its corresponding label yk, and the unlabeled pool contains unlabeled instances x` only. Pool-based active learning assumes that a (huge) pool of unlabeled instances is relatively easy to gather, while labeling those instances can be expensive. Therefore, we hope to achieve promising learning performance with as few labeled instances as possible.\nA pool-based active learning algorithm is generally iterative. In each iteration, there are two steps: the training step and the querying step. In the training step, the algorithm trains a decision function from the labeled pool; in the querying step, the algorithm selects one (or a few) unlabeled instances, queries an oracle to label those instances, and moves those instances from the unlabeled pool to the labeled one. The pool-based active learning framework repeats the training and querying steps iteratively until a given budget B on the number of queries is met, with the hope that the decision functions returned throughout the learning steps are as accurate as possible for prediction.\nBecause labeling is expensive, active learning algorithms aim to select the most valuable instance(s) from the unlabeled pool at each querying step. Various selection criteria have been proposed to describe the value of an unlabeled instance [32], such as uncertainty sampling [25], expected error reduction [29], and expected model change [33].\nMoreover, there are several works that solve bipartite ranking under the active learning scenario [11], [12], [39]. For example, [11] selects points that reduce the ranking loss functions most from the unlabeled pool while [12] selects points that maximize the AUC in expectation. Nevertheless, these active learning algorithms require either sorting or enumerating over the huge unlabeled pool in each querying step. The sorting or enumerating process can be time consuming, but have not been considered seriously because labeling is assumed to be even more expensive. We will discuss later that those algorithms that require sorting or enumerating may not fit our goal."}, {"heading": "3.2 Active Sampling", "text": "Following the philosophy of active learning, we propose the active sampling scheme for choosing a smaller set of key pairs on the huge training set Dpair . We call the scheme Active Sampling in order to highlight some differences to active learning. One particular difference is that RankSVM (1) only requires optimizing with positive pairs. Then, the label yij of a pair is a constant 1 and thus easy to get during active sampling, while the label in active learning remains unknown before the possibly expensive querying step. Thus, while\n5 active sampling and active learning both focus on using as few labeled data as possible, the costly part of the active sampling scheme is on training rather than querying.\nFor active sampling, we denote B as the budget on the number of pairs that can be used in training, which plays a similar role to the budget on querying in active learning. In brief, active sampling chooses B informative pairs iteratively for solving the optimization problem (1). We separate the pair-wise training set Dpair into two parts, the chosen pool (L\u2217) and the unchosen pool (U\u2217). The chosen pool is the subset of pairs to be used for training, and the unchosen pool contains the unused pairs. The chosen pool is similar to the labeled pool in pool-based active learning; the unchosen pool acts like the unlabeled pool. The fact that it is almost costless to \u201clabel\u201d the instances in the unchosen pool allows us to design simpler sampling strategies than those commonly used for active learning, because no effort is needed to estimate the unknown labels.\nAlgorithm 1 Active Sampling Input: the initial chosen pool, L\u2217; the initial unchosen pool, U\u2217; the regularization parameters, {Cij}. the number of pairs sampled per iteration, b; the budget on the total number of pairs sampled, B; the sampling strategy, Sample : (U\u2217,w)\u2192 xij Output: the ranking function represented by the weights w. w = linearSVM(L\u2217, {Cij},0); repeat\nfor i = 1\u2192 b do xij = Sample(U\u2217,w); L\u2217 = L\u2217 \u222a {(xij , yij)} and U\u2217 = U\u2217 \\ {xij}; end for w = linearSVM(L\u2217, {Cij},w);\nuntil (|L\u2217| \u2265 B) return w;\nThe proposed scheme of active sampling is illustrated in Algorithm 1. The algorithm takes an initial chosen pool L\u2217 and an initial unchosen pool U\u2217, where we simply mimic the usual setup in pool-based active learning by letting L\u2217 be a randomly chosen subset of Dpair and U\u2217 be the set of unchosen pairs in Dpair . In each iteration of the algorithm, we use Sample to actively choose b instances to be moved from U\u2217 to L\u2217. The strategy Sample takes the current ranking function w into account. After sampling, a linearSVM is called to learn from L\u2217 along with the weights in {Cij}. We feed the current w to the linearSVM solver to allow a warm-start in optimization. The warm-start step enhances the efficiency and the performance. The iterative procedure continues until the budget B of chosen instances is fully consumed.\nAnother main difference between the active sampling scheme and typical pool-based active learning is that we sample b instances before the training step, while pool-based active learning often considers executing the training step right after querying the label of one instance. The difference is due to the fact that the pair-wise labels yij can be obtained very easily and thus sampling and labeling can be relatively cheaper than querying in pool-based active learning. Furthermore, updating the weights right after knowing one instance may not lead to much improvement and can be\ntoo time consuming for the large-scale bipartite ranking problem that we want to solve."}, {"heading": "3.3 Sampling Strategies", "text": "Next, we discuss some possible sampling strategies that can be used in Algorithm 1. One na\u0131\u0308ve strategy is to passively choose a random sample within U\u2217. For active sampling strategies, we define two measures that estimate the (learning) value of an unchosen pair. The two measures correspond to well-known criteria in pool-based active learning. Let xij be the unchosen pair in U\u2217 with yij = 1, the two measures with respect to the current ranking function w are\ncloseness(xij ,w) = |wTxij | (3)\ncorrectness(xij ,w) = \u2212[1\u2212wTxij ]+ (4)\nThe closeness measure corresponds to one of the most popular criteria in pool-based active learning called uncertainty sampling [25]. It captures the uncertainty of the ranking function w on the unchosen pair. Intuitively, a low value of closeness means that the ranking function finds it hard to distinguish the two instances in the pair, which implies that the ranking function is less confident on the pair. Therefore, sampling the unchosen pairs that come with the lowest closeness values may improve the ranking performance by resolving the uncertainty.\nOn the other hand, the correctness measure is related to another common criterion in pool-based active learning called expected error reduction [29]. It captures the performance of the ranking function w on the unchosen pair. Note that this exact correctness measure is only available within our active sampling scheme because we know the pair-label yij to always be 1 without loss of generality, while usual active learning algorithms do not know the exact measure before querying and hence have to estimate it [11], [12]. A low value of correctness indicates that the ranking function does not perform well on the pair. Then, sampling the unchosen pairs that come with the lowest correctness values may improve the ranking performance by correcting the possible mistakes. Moreover, sampling the pair with lowest correctness value shall change w the most in general, which echoes another criterion in pool-based active learning called expected model change [33].\nSimilar to other active learning algorithms [11], [12], computing the pairs that come with the lowest closeness or correctness values can be time consuming, as it requires at least evaluating the values of wTxk for each instance (xk, yk) \u2208 D, and then computing the measures on the pairs along with some selection or sorting steps that may be of super-linear time complexity [22]. Thus, such a hard version of active sampling is not computationally feasible for largescale bipartite ranking. Next, we discuss the soft version of active sampling that randomly chooses pairs that come with lower closeness or correctness values by rejection sampling.\nThe soft version of active sampling can be described as follows: we consider a rejection sampling step that samples a pair xij with probability pij based on a method random() that generates random numbers between [0, 1]. A pair that comes with a lower closeness or correctness values would enjoy a higher probability pij of being accepted.\n6 Next, we define the probability value functions that correspond to the hard versions of closeness and correctness. Both value functions are in the shape of the sigmoid function, which is widely used to represent probabilities in logistic regression and neural networks [4]. For soft closeness sampling, we define the probability value as: pij \u2261 2/ ( 1 + e|w Txij | ) For soft correctness sampling, we\ndefine pij as: pij \u2261 1 \u2212 2/ ( 1 + e[1\u2212w T (xij)]+ ) We take different forms of soft versions because closeness is of range [0,\u221e) while correctness is of range (\u2212\u221e, 0].\nNote that the sampling strategies above, albeit focusing on the most valuable pairs, is inheritedly biased. The chosen pool may not be representative enough of the whole training set because of the biased sampling strategies. There is a simple way that allows us to correct the sampling bias for learning a ranking function that performs well on the original bipartite ranking loss of interest. We take the idea of [21] to weight the sampled pair by the inverse of its probability of being sampled. That is, we could multiply the weight Cij for a chosen pair xij by 1pij when it gets returned by the rejection sampling."}, {"heading": "3.4 Combined Ranking and Classification", "text": "Inspired by Theorem 1, the points can also carry some information for ranking. Next, we study how we can take those points into account during active sampling. We start by taking a closer look at the similarity and differences between the point-wise SVM (2) and the pair-wise SVM (1). The pair-wise SVM considers the weighted hinge loss on the pairs xij = xi\u2212xj , while the point-wise SVM considers the weighted hinge loss on the points xk. Consider one positive point (xk,+1). Its hinge loss is [1 \u2212 wTxi]+, which is the same as [1\u2212wT (xi\u22120)]+. In other words, the positive point (xi,+1) can also be viewed as a pseudo-pair that consists of (xi,+1) and (0,\u22121). Similarly, a negative point (xj ,\u22121) can be viewed as a pseudo-pair that consists of (xj ,\u22121) and (0,+1). Let the set of all pseudo-pairs within D be Dpseu. Then, the point-wise SVM (2) is just a variant of the pairwise one (1) using the pseudo-pairs and some particular weights. Thus, we can easily unify the point-wise and the pair-wise SVMs together by minimizing some weighted hinge loss on the joint set D\u2217 = Dpair \u222a Dpseu of pairs and pseudo-pairs. By introducing a parameter \u03b3 \u2208 [0, 1] to control the relative importance between the real pairs and the pseudo-pairs, we propose the following novel formulation.\nmin w\n1 2 wTw + \u03b3 \u2211 xij\u2208D+pair C(ij)crc [1\u2212wTxij ]+\n+(1\u2212 \u03b3) \u2211\nxk`\u2208D+pseu\nC(k`)crc \u00b7 [1\u2212wTxk`]+ , (5)\nwhere D+pair and D+pseu denote the set of positive pairs and positive pseudo-pairs, respectively. The new formulation (5) combines the point-wise SVM and the pair-wise SVM in its objective function, and hence is named the Combined Ranking and Classification (CRC) framework. When \u03b3 = 1, CRC takes the pair-wise SVM (1) as a special case withCij = 2C (ij) crc ; when \u03b3 = 0, CRC takes the point-wise SVM (2) as a special case with C+ = C (i0) crc and C\u2212 = C (0j) crc . The CRC\nframework (5) remains as challenging to solve as the pairwise SVM approach (1) because of the huge number of pairs. However, the general framework can be easily extended to the active sampling scheme, and hence be solved efficiently. We only need to change the training set from Dpair to the joint set D\u2217, and multiply the probability value pij in the soft version sampling by \u03b3 or (1 \u2212 \u03b3) for actual pairs or pseudo-pairs.\nThe CRC framework is closely related to the algorithm of Combined Ranking and Regression (CRR) [31] for general ranking. The CRR algorithm similarly considers a combined objective function of the point-wise terms and the pair-wise terms for improving the ranking performance. The main difference between CRR and CRC is that the CRR approach takes the squared loss on the points, while CRC takes the nature of bipartite ranking into account and considers the hinge loss on the points. On the other hand, the idea of combining pair-wise and point-wise approaches had been used in another machine learning setup, the multi-label classification problem [36]. The algorithm of Calibrated Ranking by Pairwise Comparison [19] assumes a calibration label between relevant and irrelevant labels, and hence unifies the pair-wise and point-wise label learning for multi-label classification. The calibration label plays a similar role to the zero-vector in the pseudo-pairs for combining pair-wise and point-wise approaches.\nTo the best of our knowledge, while the CRR approach has reached promising performance in practice [31], the CRC formulation has not been seriously studied. The hinge loss used in CRC allows unifying the point-wise SVM and the pair-wise SVM under the same framework, and the unification is essential for applying one active sampling strategy on both the real pairs and the pseudo-pairs.\nIn summary, we propose the active sampling scheme for RankSVM (ASRankSVM) and the more general CRC framework (ASCRC), and derive two sampling strategies that correspond to popular strategies in pool-based active learning. The soft version of the sampling strategies helps reducing the computational cost, and allows correcting the sampling bias by adjusting the weights with the inverse probability of being sampled."}, {"heading": "3.5 CRC with Threshold", "text": "In Theorem 1, we connect the point-wise SVM without threshold term (2) to the pair-wise SVM (1). The standard SVM for binary classification, however, often come with a threshold term \u03b8 to allow the classification hyperplane to be away from the origin. That is, the standard SVM solves\nmin \u03b8,w\n1 2 wTw + C+ \u2211 xi\u2208D+ [1\u2212wTxi + \u03b8]+\n+C\u2212 \u2211\nxj\u2208D\u2212 [1 + wTxj \u2212 \u03b8]+ . (6)\nNote that for any given (\u03b8,w),\n[1\u2212wTxij ]+ \u2264 1\n2\n( [1\u2212 2wTxi + 2\u03b8]+ + [1 + 2wTxj \u2212 2\u03b8]+ ) .\nIf we revisit the proof of Theorem 1 with the equation above, we get a similar theorem that connects the standard SVM to the pair-wise SVM.\n7\nTheorem 2. Let Cij = C2 be a constant in (1); C+ = 2N \u2212 \u00b7 C and C\u2212 = 2N+ \u00b7 C in (6). Then, for every (\u03b8,w), the objective function of (1) is upper-bounded by 14 times the objective function of (6).\nGiven the connection between (6) to (1) in Theorem 2, one may wonder whether the trick of pseudo-pair works for connecting the two formulations. Consider one positive point (xk,+1). Its hinge loss within (6) is [1\u2212wTxi + \u03b8]+, which is the same as [ 1\u2212 [ \u03b8 wT ] ([\u22121 xi ] \u2212 0n+1 )] + , where 0n+1 is a zero vector of length n+1. Thus, the positive point (xi,+1) can also be viewed as an extended pseudo-\npair that consists of ([ \u22121 xi ] ,+1 ) and (0n+1,\u22121), ranked\nby the extended vector [ \u03b8 w ] . We will denote the extended\nvector [ \u22121 xi ] as x\u0303i. Similarly, a negative point (xj ,\u22121) can be viewed as an extended pseudo-pair that consists of (x\u0303j ,\u22121) and (0n+1,+1).\nNote that if we consider all the extended vectors x\u0303i, ranking pair-wise extended vectors by [ \u03b8 w ] means calculating[ \u03b8 w ]T (x\u0303i \u2212 x\u0303j) = [ \u03b8 w ]T ([\u22121 xi ] \u2212 [ \u22121 xj ]) = wT (xi \u2212 xj)\nThat is, the hinge loss on extended pairs is exactly the same as the hinge loss on the original pairs.\nBased on the discussions above, if we define extended pairs x\u0303ij and extended pseudo-pairs x\u0303k` based on the extended vectors x\u0303i and 0n+1, we can combine the pairwise SVM and the standard SVM with threshold term to design a variant of the CRC formulation. In the variant, we take one common trick to include We use one trick (as taken by LIBLINEAR [15]) that includes \u03b8 in the regularization term to allow simpler design of optimization routines. That is, we solve\nmin \u03b8,w\n1 2 (\u03b8T \u03b8 + wTw)\n+\u03b3 \u2211\nxij\u2208D+pair\nC(ij)crc [1\u2212 [ \u03b8 wT ] xij ]+\n+(1\u2212 \u03b3) \u2211\nxk`\u2208D+pseu\nC(k`)crc \u00b7 [1\u2212 [ \u03b8 wT ] x\u0303k`]+ (7)\nin our study. We call this formulation (7) CRC-threshold, which is simply equivalent to the original CRC formulation (5) applied to the extended vectors. The equivalence allows us to easily test whether the flexibility of \u03b8 (through using the extended vectors x\u0303i) can improve the original CRC formulation."}, {"heading": "4 EXPERIMENTS", "text": "In this section, we study the performance and efficiency of our proposed ASCRC algorithm on real-world largescale data sets. We compare ASCRC with random-CRC, which does random sampling under the CRC framework. In addition, we compare ASCRC with three other stateof-the-art algorithms for large-scale bipartite ranking: the\npoint-wise weighted linear SVM (2) (WSVM), an efficient implementation [22] of the pair-wise linear RankSVM (1) (ERankSVM), and the combined ranking and regression (CRR) [31] algorithm for general ranking.\nWe use 14 data sets from the LIBSVM Tools1 and the UCI Repository [23] in the experiments. Table 1 shows the statistics of the data sets, which contains more than ten-thousands of instances and more than ten-millions of pairs. The data sets are definitely too large for a na\u0131\u0308ve implementation of RankSVM (1). The data sets marked with (\u2217) are originally multi-class data sets, and we take the subproblem of ranking the first class ahead of the other classes as a bipartite ranking task. For data sets that come with a moderate-sized test set, we report the test AUC. Otherwise we perform a 5-fold cross validation and report the crossvalidation AUC."}, {"heading": "4.1 Experiment Settings", "text": "Given a budget B on the number of pairs to be used in each algorithm and a global regularization parameter C , we set the instance weights for each algorithm to fairly maintain the numerical scale between the regularization term and the loss terms. The global regularization parameter C is fixed to 0.1 in all the experiments. In particular, the setting below ensures that the total C(ij), summed over all the pairs (or pseudo-pairs), would be C \u00b7B for all the algorithms. \u2022 WSVM: As discussed in Section 2, C+ and C\u2212 shall\nbe inverse-proportional to N+ and N\u2212 to make the weighted point-wise SVM a reasonable baseline for bipartite ranking. Thus, we set C+ = B2N+ \u00b7 C and C\u2212 = B 2N\u2212 \u00b7C in (2). We solve the weighted SVM by the LIBLINEAR [15] package with its extension on instance weights. \u2022 ERankSVM: We use the SVMperf [22] package to efficiently solve the linear RankSVM (1) with the\n1. http://www.csie.ntu.edu.tw/\u223ccjlin/libsvmtools/\n8"}, {"heading": "4.2 Performance Comparison and Robustness", "text": "Next, we examine the necessity of three key designs within the active sampling framework: soft-version versus hardversion, sampling bias correction within soft-version of active sampling, and the choice of soft-version value functions. We first set \u03b3 = 1 in ASCRC and random-CRC, which makes ASCRC equivalent to ASRankSVM. We let b = 100 and B = 8000, which is a relatively small budget out of the millions of pairs."}, {"heading": "4.2.1 Soft-Version versus Hard-Version", "text": "We will discuss the time difference between the soft- and hard-versions of sampling in Table 5 of Section 4.3. The softversions are both coupled with bias correction. Intuitively, the soft version is much faster than the hard version. Here we examine the performance difference between the two\nversions first. In Table 2, we compare the soft- and hardversions of closeness and correctness sampling under the ttest of 95% confidence level. For closeness sampling, the soft version performs better than the hard version on 9 data sets and ties with 3; for correctness sampling, the soft version performs better than the hard version on 12 data sets and ties with 1. The results justify that the soft version is a better choice than the hard-version in terms of AUC performance.\nFig. 1 further show how the AUC changes as |L\u2217| grows for different versions of sampling, along with the baseline ERankSVM algorithm. We see that hard-correctnesssampling always leads to unsatisfactory performance. One possible reason is that hard correctness-sampling can easily suffer from sampling the noisy pairs, which come with larger hinge loss. On the other hand, hard-closeness-sampling is competitive to the soft-versions (albeit slower), but appears to be saturating to less satisfactory model in Fig. 1(b). The saturation corresponds to a known problem of uncertainty sampling in active learning because of the restricted view of the non-perfect model used for sampling [26]. The softversion, on the other hand, has some probability of escaping from the restricted view, and hence enjoys better performance."}, {"heading": "4.2.2 Bias Correction for Soft Version Sampling", "text": "Next, we show the AUC difference between doing bias correction (see Section 3.3) and not doing so for soft-version sampling in Table 3. A positive difference indicates that doing bias correction leads to better performance. First of all, we see that the difference of the bias correction is relatively small. For soft-close sampling, performing bias correction is slightly worse in 12 data sets; for soft-correct sampling, performing bias correction is slightly better in 9 data sets. Note correctness sampling is inheritedly more biased towards the noisy pairs as discussed during hardversion sampling. Thus, performing bias correction can be necessary and helpful in ensuring the stability, as justified by the better performance in those 9 data sets."}, {"heading": "4.2.3 Value Functions for Soft Version Sampling", "text": "We show how the AUC changes as |L\u2217| grows throughout the active sampling steps of ASRankSVM in Fig. 4. For WSVM, ERankSVM and CRR, we plot a horizontal line on the AUC achieved when using the whole training set. We also list the final AUC with the standard deviation of all the algorithms in Table 4.\nFrom Fig. 4 and Table 4, we see that soft-correct sampling is generally the best. We also conduct the right-tail t-test for soft-correct against the others, and list the results in Table 4 to show whether the improvement of soft-correct sampling is significant.\nFirst, we compare soft-correct with random sampling and discover that soft-correct performs better on 10 data sets and ties with 4, which shows that active sampling is working reasonably well. While comparing soft-close with soft-correct in Table 4, we find that soft-correct outperforms soft-close on 7 data sets and ties with 5. Moreover, Fig. 4 shows the strong performance of soft-correct comes from the early steps of active sampling. Finally, when comparing softcorrect with other algorithms, we discover that soft-correct performs the best on 8 data sets: it outperforms ERankSVM\n9\non 8 data sets, WSVM on 9 data sets, and CRR on 11 data sets. The results demonstrate that even when using a pretty small sampling budget of 8, 000 pairs, ASRankSVM with soft-correct sampling can achieve significant improvement over those state-of-the-art ranking algorithms that use the whole training data set. Also, the tiny standard deviation shown in Table 4 and the significant results from the t-test suggest the robustness of ASRankSVM with soft-correct in general.\nNevertheless, we observe a potential problem of softcorrect sampling from Fig. 4. In data sets letter and mnist, the performance of soft-correct increases faster than softclose in the beginning, but starts dropping in the middle. The possible reason, similar to the hard-version sampling, is the existence of noisy pairs that shall better not to be put into the chosen pool. When sampling more pairs, the probability that some noisy pairs (which come with larger hinge loss) are sampled by soft-correct sampling is higher, and can in term lead to degrading of performance. The results suggest a possible future work in combining the benefits of soft-close and soft-correct sampling to be more noise-tolerant."}, {"heading": "4.3 Efficiency Comparison", "text": "First, we study the efficiency of soft active sampling by checking the average number of rejected samples before passing the probability threshold during rejection sampling.\nThe number is plotted against the size of L\u2217 in Fig. 5. The soft-close strategy usually needs fewer than 10 rejected samples, while the soft-correct strategy generally needs an increasing number of rejected samples. The reason is that when the ranking performance becomes better throughout the iterations, the probability threshold behind soft-correct could be pretty small. The results suggest that the soft-close strategy is generally efficient, while the soft-correct strategy may be less efficient as |L\u2217| grows.\nNext, we list the CPU time consumed for all algorithms under 8, 000 pairs budget in Table 5, and the data sets are ordered ascendantly by its size. We can see that WSVM and CRR run fast but give inferior performance; ERankSVM performs better but the training time grows fast as the data size increases. The result is consistent with the discussion in Section 1 that conducting bipartite ranking efficiently and accurately at the same time is challenging.\nFor ASRankSVM, random runs the fastest, then softclose, and soft-correct is the slowest. The results reflect the average number of rejected samples discussed above. In addition, not surprisingly, the soft version samplings are usually much faster then the corresponding hard versions, which validate that the time consuming enumerating or sorting steps do not fit our goal in terms of efficiency.\nMore importantly, when comparing soft-correct with ERankSVM, soft-correct runs faster on 7 data sets, which suggests ASRankSVM is as efficient as the state-of-the-art\n10\nERankSVM on large-scale data sets in general. Nevertheless, we can find that the CPU time of soft-correct grows much slower than ERankSVM as data size increases because the time complexity of ASRankSVM mainly depends on the budget B and the step size b, not the size of data."}, {"heading": "4.4 The Usefulness of Larger Budget", "text": "From the previous experiments, we have shown that ASRankSVM with a budget of 8, 000 pairs can perform better than other competitors on large-scale data sets. Now, we check the performance of ASRankSVM with different budget size. In Figure 2, we show the AUC curves with much larger budgets on two data sets. Then, we find that the performance of ASRankSVM can be improved or maintained as the budget size increases. For example, in data\nset protein, we can match the performance of WSVM with around 40,000 pairs and surpass it slightly with around 80,000 pairs. Nevertheless, in most data sets, we find that the slope of AUC curves become flat around 10,000 pairs, and eventually converge as the budget increases. That is, increasing the budget in ASRankSVM leads to consistent but marginal improvements.\nNote that the potential problem of sampling noisy pairs within the soft-correct sampling can be more serious when the budget size increases. Fig. 3 illustrates the problem with the real-sim data when B = 50000, b = 1250, and \u03b3 = 1.0, where the performance of soft-correct degrades and rejects many more pairs in the latter sampling iterations. On the other hand, soft-close maintains the robustness and the efficiency as the budget increases, and improves the performance consistently throughout the iterations. Thus, if a larger budget is used, soft-close can be a better choice than soft-correct."}, {"heading": "4.5 The Usefulness of the CRC Framework", "text": "Next, we study the necessity of the CRC framework by comparing the performance of soft-closeness and\n11\nsoft-correctness under different choices of \u03b3. We report the best \u03b3 under a 95% significance level within {uniform, 0.1, 0.2, ..., 1.0}, where uniform means balancing the influence of actual pairs and pseudo-pairs by \u03b3 = |Dpair| |D\u2217| . Moreover, we check whether CRC-threshold can be useful. Table 6 shows the best \u03b3 and formulation for each sampling strategy. The entries with \u201c-th\u201d indicates CRC-threshold. The bold entries indicates that the setting outperforms ERankSVM significantly. The table suggests three observations. Firstly, the choice of sampling strategy does not effect the optimal \u03b3 much, and most data sets have similar optimal \u03b3 for both soft-closeness and soft-correctness sampling. Secondly, we find that adding a threshold term for CRC can sometimes reach better performance. Last, we see that using \u03b3 = 1 (real pairs only) performs well in most data sets, while a smaller \u03b3 or uniform can sometimes reach better performance. The results justify that the real pairs are more important than the pseudo-pairs, while the latter can sometimes be helpful.\nIn summary, a special case of the proposed ASCRC algorithm that only samples actual pairs (ASRankSVM) works reasonably well for a budget of 8, 000 when coupled with soft-correct sampling. The setting significantly outperforms WSVM, ERankSVM, CRR and soft-close on most of the data sets, also the execution time shown the efficiency of soft-correct sampling is comparable with ERankSVM. While \u03b3 = 1 leads to promising performance on most of the data sets, further tuning with a smaller \u03b3 or adding a threshold term helps in some data sets."}, {"heading": "5 CONCLUSION", "text": "We propose the algorithm of Active Sampling (AS) under Combined Ranking and Classification (CRC) based on the linear SVM. There are two major components of the proposed algorithm. The AS scheme selects valuable pairs for training and resolves the computational burden in largescale bipartite ranking. The CRC framework unifies the concept of point-wise ranking and pair-wise ranking under the same framework, and can perform better than pure point-wise ranking or pair-wise ranking. The unified view of pairs and points (pseudo-pairs) in CRC allows using one AS scheme to select from both types of pairs.\nExperiments on 14 real-world large-scale data sets demonstrate the promising performance and efficiency of the ASRankSVM and ASCRC algorithms. The algorithms usually outperform state-of-the-art bipartite ranking algorithms, including the point-wise SVM, the pair-wise SVM, and the combined ranking and regression approach. The results not only justify the validity of ASCRC, but also shows the valuable pairs or pseudo-pairs can be helpful for large-scale bipartite ranking."}], "references": [{"title": "An active learning algorithm for ranking from pairwise preferences with an almost optimal query complexity", "author": ["N. Ailon"], "venue": "JMLR, 13:137\u2013164,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "An efficient reduction of ranking to classification", "author": ["N. Ailon", "M. Mohri"], "venue": "arXiv preprint arXiv:0710.2889,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Robust reductions from ranking to classification", "author": ["M.-F. Balcan", "N. Bansal", "A. Beygelzimer", "D. Coppersmith", "J. Langford", "G.B. Sorkin"], "venue": "Machine learning, 72(1-2):139\u2013153,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Supervised learning of probability distributions by neural networks", "author": ["E.B. Baum", "F. Wilczek"], "venue": "NIPS, pages 52\u201361,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1988}, {"title": "AUC maximizing support vector learning", "author": ["U. Brefeld", "T. Scheffer"], "venue": "ICML Workshop on ROC Analysis in Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning to rank using gradient descent", "author": ["C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender"], "venue": "ICML, pages 89\u201396,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning to rank with nonsmooth cost functions", "author": ["C.J. Burges", "Q.V. Le", "R. Ragno"], "venue": "NIPS, 19:193\u2013200,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "KDD-Cup 2004: results and analysis", "author": ["R. Caruana", "T. Joachims", "L. Backstrom"], "venue": "ACM SIGKDD Explorations Newsletter, 6(2):95\u2013108,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Ranking and empirical minimization of U-statistics", "author": ["S. Clemen\u00e7on", "G. Lugosi", "N. Vayatis"], "venue": "The Annals of Statistics, 36(2):844\u2013874,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2008}, {"title": "AUC optimization vs", "author": ["C. Cortes", "M. Mohri"], "venue": "error rate minimization. NIPS, 16(16):313\u2013320,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Optimizing estimated loss reduction for active sampling in rank learning", "author": ["P. Donmez", "J.G. Carbonell"], "venue": "ICML, pages 248\u2013255,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2008}, {"title": "Active sampling for rank learning via optimizing the area under the ROC curve", "author": ["P. Donmez", "J.G. Carbonell"], "venue": "Advances in Information Retrieval, pages 78\u201389,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "On the consistency of ranking algorithms", "author": ["J. Duchi", "L. Mackey", "M.I. Jordan"], "venue": "ICML, pages 327\u2013334,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "On equivalence relationships between classification and ranking algorithms", "author": ["\u015e. Ertekin", "C. Rudin"], "venue": "JMLR, 12:2905\u20132929,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "JMLR, 9:1871\u2013 1874,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "An introduction to ROC analysis", "author": ["T. Fawcett"], "venue": "Pattern Recognition Letters, 27(8):861\u2013874,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Y. Freund", "R. Iyer", "R.E. Schapire", "Y. Singer"], "venue": "JMLR, 4:933\u2013969,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2003}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R.E. Schapire"], "venue": "Journal of Computer and System Sciences, 55(1):119\u2013139,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Multilabel classification via calibrated label ranking", "author": ["J. F\u00fcrnkranz", "E. H\u00fcllermeier", "E.L. Menc\u0131\u0301a", "K. Brinker"], "venue": "Machine Learning,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "NIPS, pages 115\u2013132,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1999}, {"title": "A generalization of sampling without replacement from a finite universe", "author": ["D.G. Horvitz", "D.J. Thompson"], "venue": "Journal of the American Statistical Association, 47(260):663\u2013685,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1952}, {"title": "Training linear svms in linear time", "author": ["T. Joachims"], "venue": "KDD, pages 217\u2013226,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Bipartite ranking through minimization of univariate loss", "author": ["W. Kot\u0142lowski", "K. Dembczynski", "E. H\u00fcllermeier"], "venue": "ICML, pages 1113\u20131120,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "A sequential algorithm for training text classifiers", "author": ["D.D. Lewis", "W.A. Gale"], "venue": "SIGIR, pages 3\u201312,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1994}, {"title": "Active learning with hinted support vector machine", "author": ["C.-L. Li", "C.-S. Ferng", "H.-T. Lin"], "venue": "ACML,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning to rank for information retrieval", "author": ["T.-Y. Liu"], "venue": "Foundations and Trends in Information Retrieval, 3(3):225\u2013331,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2009}, {"title": "Diverse active ranking for multimedia search", "author": ["S. Rajaram", "C.K. Dagli", "N. Petrovic", "T.S. Huang"], "venue": "CVPR, pages 1\u20138,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2007}, {"title": "Toward optimal active learning through monte carlo estimation of error reduction", "author": ["N. Roy", "A. McCallum"], "venue": "ICML, pages 441\u2013448,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2001}, {"title": "Margin-based ranking and an equivalence between AdaBoost and RankBoost", "author": ["C. Rudin", "R.E. Schapire"], "venue": "JMLR, 10:2193\u2013 2232,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Combined regression and ranking", "author": ["D. Sculley"], "venue": "KDD, pages 979\u2013988,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2010}, {"title": "Active learning literature survey", "author": ["B. Settles"], "venue": "U. of Wisconsin, Madison,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Multiple-instance active learning", "author": ["B. Settles", "M. Craven", "S. Ray"], "venue": "NIPS,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Active sampling of pairs and points for large-scale linear bipartite ranking", "author": ["W.-Y. Shen", "H.-T. Lin"], "venue": "ACML, pages 388\u2013403,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2013}, {"title": "Hinge rank loss and the area under the ROC curve", "author": ["H. Steck"], "venue": "ECML, pages 347\u2013358,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2007}, {"title": "Multi-label classification: An overview", "author": ["G. Tsoumakas", "I. Katakis"], "venue": "International Journal of Data Warehousing and Mining, 3(3):1\u201313,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2007}, {"title": "The nature of statistical learning theory", "author": ["V. Vapnik"], "venue": "Springer,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1999}, {"title": "SVM selective sampling for ranking with application to data retrieval", "author": ["H. Yu"], "venue": "KDD, pages 354\u2013363,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2005}, {"title": "Recent advances of large-scale linear classification", "author": ["G.-X. Yuan", "C.-H. Ho", "C.-J. Lin"], "venue": "Proceedings of the IEEE, 100(9):2584\u20132603,", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 15, "context": "The performance of the ranking function is measured by the probability of mis-ordering an unseen pair of randomly chosen positive and negative instances, which is equal to one minus the Area Under the ROC Curve (AUC) [16], a popular criterion for evaluating the sensitivity and the specificity of binary classifiers in many real-world tasks [9] and large-scale data mining competitions [8], [38].", "startOffset": 217, "endOffset": 221}, {"referenceID": 8, "context": "The performance of the ranking function is measured by the probability of mis-ordering an unseen pair of randomly chosen positive and negative instances, which is equal to one minus the Area Under the ROC Curve (AUC) [16], a popular criterion for evaluating the sensitivity and the specificity of binary classifiers in many real-world tasks [9] and large-scale data mining competitions [8], [38].", "startOffset": 341, "endOffset": 344}, {"referenceID": 7, "context": "The performance of the ranking function is measured by the probability of mis-ordering an unseen pair of randomly chosen positive and negative instances, which is equal to one minus the Area Under the ROC Curve (AUC) [16], a popular criterion for evaluating the sensitivity and the specificity of binary classifiers in many real-world tasks [9] and large-scale data mining competitions [8], [38].", "startOffset": 386, "endOffset": 389}, {"referenceID": 9, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 187, "endOffset": 191}, {"referenceID": 13, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 193, "endOffset": 197}, {"referenceID": 16, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 199, "endOffset": 203}, {"referenceID": 21, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 205, "endOffset": 209}, {"referenceID": 22, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 211, "endOffset": 215}, {"referenceID": 25, "context": "Given the many potential applications in information retrieval, bioinformatics, and recommendation systems, bipartite ranking has received much research attention in the past two decades [10], [14], [17], [22], [24], [27].", "startOffset": 217, "endOffset": 221}, {"referenceID": 4, "context": "Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24].", "startOffset": 193, "endOffset": 196}, {"referenceID": 13, "context": "Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24].", "startOffset": 198, "endOffset": 202}, {"referenceID": 16, "context": "Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24].", "startOffset": 204, "endOffset": 208}, {"referenceID": 19, "context": "Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24].", "startOffset": 210, "endOffset": 214}, {"referenceID": 22, "context": "Many existing bipartite ranking algorithms explicitly or implicitly reduce the problem to binary classification to inherit the benefits from the well-developed methods in binary classification [5], [14], [17], [20], [24].", "startOffset": 216, "endOffset": 220}, {"referenceID": 2, "context": "For example, [3] shows that a low-regret ranking function can indeed be formed by a low-regret binary classifier.", "startOffset": 13, "endOffset": 16}, {"referenceID": 19, "context": "The strong theoretical guarantee leads to promising experimental results in many state-ofthe-art bipartite ranking algorithms, such as RankSVM [20], RankBoost [17] and RankNet [6].", "startOffset": 143, "endOffset": 147}, {"referenceID": 16, "context": "The strong theoretical guarantee leads to promising experimental results in many state-ofthe-art bipartite ranking algorithms, such as RankSVM [20], RankBoost [17] and RankNet [6].", "startOffset": 159, "endOffset": 163}, {"referenceID": 5, "context": "The strong theoretical guarantee leads to promising experimental results in many state-ofthe-art bipartite ranking algorithms, such as RankSVM [20], RankBoost [17] and RankNet [6].", "startOffset": 176, "endOffset": 179}, {"referenceID": 16, "context": "The quadratic number of pairs with respect to N makes the pair-wise approach computationally infeasible for large-scale data sets in general, except in a few special algorithms like RankBoost [17] or the efficient linear RankSVM [22].", "startOffset": 192, "endOffset": 196}, {"referenceID": 21, "context": "The quadratic number of pairs with respect to N makes the pair-wise approach computationally infeasible for large-scale data sets in general, except in a few special algorithms like RankBoost [17] or the efficient linear RankSVM [22].", "startOffset": 229, "endOffset": 233}, {"referenceID": 22, "context": "RankBoost enjoys an efficient implementation by reducing the quadratic number of pair-wise terms in the objective function to a linear number of equivalent terms; efficient linear RankSVM transforms the pair-wise optimization formulation to an equivalent formulation that can be solved in subquadratic time complexity [24].", "startOffset": 318, "endOffset": 322}, {"referenceID": 16, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 22, "endOffset": 26}, {"referenceID": 26, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 28, "endOffset": 32}, {"referenceID": 17, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 92, "endOffset": 96}, {"referenceID": 13, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 183, "endOffset": 187}, {"referenceID": 28, "context": "In some special cases [17], [28], such as AdaBoost [18] and its pair-wise sibling RankBoost [17], the point-wise approach is shown to be equivalent to the corresponding pair-wise one [14], [30].", "startOffset": 189, "endOffset": 193}, {"referenceID": 22, "context": "In other cases, the point-wise approach often operates with an approximate objective function that involves only N terms [24].", "startOffset": 121, "endOffset": 125}, {"referenceID": 22, "context": "For example, [24] shows that minimizing the exponential or the logistic loss function on the instance points decreases an upper bound on the number of mis-ordered pairs within the input data.", "startOffset": 13, "endOffset": 17}, {"referenceID": 35, "context": "We focus on using the linear Support Vector Machine (SVM) [37] given its recent advances for efficient large-scale learning [40].", "startOffset": 58, "endOffset": 62}, {"referenceID": 37, "context": "We focus on using the linear Support Vector Machine (SVM) [37] given its recent advances for efficient large-scale learning [40].", "startOffset": 124, "endOffset": 128}, {"referenceID": 35, "context": "We first show that the loss function behind the usual point-wise SVM [37] minimizes an upper bound on the loss function behind RankSVM, which suggests that the point-wise SVM could be an approximate bipartite ranking algorithm that enjoys efficiency.", "startOffset": 69, "endOffset": 73}, {"referenceID": 30, "context": "The active sampling scheme is inspired by active learning, another popular machine learning setup that aims to save the efforts of labeling [32].", "startOffset": 140, "endOffset": 144}, {"referenceID": 14, "context": "In Section 4, we conduct experiments on 14 real-world large-scale data sets and compare the proposed algorithms (ASRankSVM and ASCRC) with several stateof-the-art bipartite ranking algorithms, including the pointwise linear SVM [15], the efficient linear RankSVM [22], and the Combined Ranking and Regression (CRR) algorithm [31] which is closely related to the CRC framework.", "startOffset": 228, "endOffset": 232}, {"referenceID": 21, "context": "In Section 4, we conduct experiments on 14 real-world large-scale data sets and compare the proposed algorithms (ASRankSVM and ASCRC) with several stateof-the-art bipartite ranking algorithms, including the pointwise linear SVM [15], the efficient linear RankSVM [22], and the Combined Ranking and Regression (CRR) algorithm [31] which is closely related to the CRC framework.", "startOffset": 263, "endOffset": 267}, {"referenceID": 29, "context": "In Section 4, we conduct experiments on 14 real-world large-scale data sets and compare the proposed algorithms (ASRankSVM and ASCRC) with several stateof-the-art bipartite ranking algorithms, including the pointwise linear SVM [15], the efficient linear RankSVM [22], and the Combined Ranking and Regression (CRR) algorithm [31] which is closely related to the CRC framework.", "startOffset": 325, "endOffset": 329}, {"referenceID": 32, "context": "A preliminary version of this paper appeared in the 5th Asian Conference on Machine Learning [34].", "startOffset": 93, "endOffset": 97}, {"referenceID": 4, "context": "The bipartite ranking loss LP (r) is closely related to the area under the ROC curve (AUC), which is commonly used to evaluate the sensitivity and the specificity of binary classifiers [5], [8], [9], [38].", "startOffset": 185, "endOffset": 188}, {"referenceID": 7, "context": "The bipartite ranking loss LP (r) is closely related to the area under the ROC curve (AUC), which is commonly used to evaluate the sensitivity and the specificity of binary classifiers [5], [8], [9], [38].", "startOffset": 190, "endOffset": 193}, {"referenceID": 8, "context": "The bipartite ranking loss LP (r) is closely related to the area under the ROC curve (AUC), which is commonly used to evaluate the sensitivity and the specificity of binary classifiers [5], [8], [9], [38].", "startOffset": 195, "endOffset": 198}, {"referenceID": 6, "context": "There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems.", "startOffset": 59, "endOffset": 62}, {"referenceID": 12, "context": "There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems.", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems.", "startOffset": 70, "endOffset": 74}, {"referenceID": 1, "context": "There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems.", "startOffset": 90, "endOffset": 93}, {"referenceID": 16, "context": "There are lots of recent studies on improving the accuracy [7], [13], [20] and efficiency [2], [17] of general ranking problems.", "startOffset": 95, "endOffset": 99}, {"referenceID": 37, "context": "Motivated by the recent advances of linear models for efficient large-scale learning [40], we consider linear models for efficient large-scale bipartite ranking.", "startOffset": 85, "endOffset": 89}, {"referenceID": 35, "context": "In particular, we study the linear Support Vector Machine (SVM) [37] for bipartite ranking.", "startOffset": 64, "endOffset": 68}, {"referenceID": 19, "context": "The pair-wise approach corresponds to the famous RankSVM algorithm [20], which is originally designed for ranking with ordinal-scaled scores, but can be easily extended to general ranking with real-valued labels or restricted to bipartite ranking with binary labels.", "startOffset": 67, "endOffset": 71}, {"referenceID": 33, "context": "The pair-wise linear SVM minimizes the hinge loss as a surrogate to the 0/1 loss on Dpair [35], and the 0/1 loss on Dpair is equivalent to LD(r), the empirical bipartite ranking loss of interest.", "startOffset": 90, "endOffset": 94}, {"referenceID": 4, "context": "RankSVM has reached promising bipartite ranking performance in the literature [5].", "startOffset": 78, "endOffset": 81}, {"referenceID": 21, "context": "In contrast with the na\u0131\u0308ve RankSVM, the efficient linear RankSVM [22] changes (1) to a more sophisticated and equivalent one with an exponential number of constraints, each corresponding to a particular linear combination of the pairs.", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "(2) Such an approach comes with some theoretical justification [24].", "startOffset": 63, "endOffset": 67}, {"referenceID": 4, "context": "When C+ = C\u2212, [5] shows that the pointwise approach (2) is inferior to the pair-wise approach (1) in performance.", "startOffset": 14, "endOffset": 17}, {"referenceID": 29, "context": "Then, either some random subsampling of the pairs are needed [31], or the less-accurate point-wise approach (2) is taken as the approximate alternative [24].", "startOffset": 61, "endOffset": 65}, {"referenceID": 22, "context": "Then, either some random subsampling of the pairs are needed [31], or the less-accurate point-wise approach (2) is taken as the approximate alternative [24].", "startOffset": 152, "endOffset": 156}, {"referenceID": 29, "context": "The Combined Ranking and Regression approach [31] performs stochastic gradient descent on its objective function, which essentially selects within the huge number of pairs in a random manner; the efficient RankSVM [22] identifies the most-violated constraints during optimization, which corresponds to selecting the most valuable pairs from an optimization perspective.", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "The Combined Ranking and Regression approach [31] performs stochastic gradient descent on its objective function, which essentially selects within the huge number of pairs in a random manner; the efficient RankSVM [22] identifies the most-violated constraints during optimization, which corresponds to selecting the most valuable pairs from an optimization perspective.", "startOffset": 214, "endOffset": 218}, {"referenceID": 30, "context": "One machine learning setup that works for a similar task is active learning [32], which iteratively select a small number of valuable instances for labeling (and training) while reaching similar performance to the approach that trains with all the instances fully labeled.", "startOffset": 76, "endOffset": 80}, {"referenceID": 0, "context": "[1] avoids the quadratic number of pairs in the general ranking problem from an active learning perspective, and proves that selecting a subquadratic number of pairs is sufficient to obtain a ranking function that is close to the optimal ranking function trained by using all the pairs.", "startOffset": 0, "endOffset": 3}, {"referenceID": 23, "context": "The algorithm is theoretical in nature, while many other promising active learning tools [25], [29], [32] have not been explored for selecting valuable pairs in large-scale bipartite ranking.", "startOffset": 89, "endOffset": 93}, {"referenceID": 27, "context": "The algorithm is theoretical in nature, while many other promising active learning tools [25], [29], [32] have not been explored for selecting valuable pairs in large-scale bipartite ranking.", "startOffset": 95, "endOffset": 99}, {"referenceID": 30, "context": "The algorithm is theoretical in nature, while many other promising active learning tools [25], [29], [32] have not been explored for selecting valuable pairs in large-scale bipartite ranking.", "startOffset": 101, "endOffset": 105}, {"referenceID": 30, "context": "We focus on the setup of poolbased active learning [32] because of its strong connection to our needs.", "startOffset": 51, "endOffset": 55}, {"referenceID": 30, "context": "Various selection criteria have been proposed to describe the value of an unlabeled instance [32], such as uncertainty sampling [25], expected error reduction [29], and expected model change [33].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "Various selection criteria have been proposed to describe the value of an unlabeled instance [32], such as uncertainty sampling [25], expected error reduction [29], and expected model change [33].", "startOffset": 128, "endOffset": 132}, {"referenceID": 27, "context": "Various selection criteria have been proposed to describe the value of an unlabeled instance [32], such as uncertainty sampling [25], expected error reduction [29], and expected model change [33].", "startOffset": 159, "endOffset": 163}, {"referenceID": 31, "context": "Various selection criteria have been proposed to describe the value of an unlabeled instance [32], such as uncertainty sampling [25], expected error reduction [29], and expected model change [33].", "startOffset": 191, "endOffset": 195}, {"referenceID": 10, "context": "Moreover, there are several works that solve bipartite ranking under the active learning scenario [11], [12], [39].", "startOffset": 98, "endOffset": 102}, {"referenceID": 11, "context": "Moreover, there are several works that solve bipartite ranking under the active learning scenario [11], [12], [39].", "startOffset": 104, "endOffset": 108}, {"referenceID": 36, "context": "Moreover, there are several works that solve bipartite ranking under the active learning scenario [11], [12], [39].", "startOffset": 110, "endOffset": 114}, {"referenceID": 10, "context": "For example, [11] selects points that reduce the ranking loss functions most from the unlabeled pool while [12] selects points that maximize the AUC in expectation.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "For example, [11] selects points that reduce the ranking loss functions most from the unlabeled pool while [12] selects points that maximize the AUC in expectation.", "startOffset": 107, "endOffset": 111}, {"referenceID": 23, "context": "The closeness measure corresponds to one of the most popular criteria in pool-based active learning called uncertainty sampling [25].", "startOffset": 128, "endOffset": 132}, {"referenceID": 27, "context": "On the other hand, the correctness measure is related to another common criterion in pool-based active learning called expected error reduction [29].", "startOffset": 144, "endOffset": 148}, {"referenceID": 10, "context": "Note that this exact correctness measure is only available within our active sampling scheme because we know the pair-label yij to always be 1 without loss of generality, while usual active learning algorithms do not know the exact measure before querying and hence have to estimate it [11], [12].", "startOffset": 286, "endOffset": 290}, {"referenceID": 11, "context": "Note that this exact correctness measure is only available within our active sampling scheme because we know the pair-label yij to always be 1 without loss of generality, while usual active learning algorithms do not know the exact measure before querying and hence have to estimate it [11], [12].", "startOffset": 292, "endOffset": 296}, {"referenceID": 31, "context": "Moreover, sampling the pair with lowest correctness value shall change w the most in general, which echoes another criterion in pool-based active learning called expected model change [33].", "startOffset": 184, "endOffset": 188}, {"referenceID": 10, "context": "Similar to other active learning algorithms [11], [12], computing the pairs that come with the lowest closeness or correctness values can be time consuming, as it requires at least evaluating the values of wxk for each instance (xk, yk) \u2208 D, and then computing the measures on the pairs along with some selection or sorting steps that may be of super-linear time complexity [22].", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Similar to other active learning algorithms [11], [12], computing the pairs that come with the lowest closeness or correctness values can be time consuming, as it requires at least evaluating the values of wxk for each instance (xk, yk) \u2208 D, and then computing the measures on the pairs along with some selection or sorting steps that may be of super-linear time complexity [22].", "startOffset": 50, "endOffset": 54}, {"referenceID": 21, "context": "Similar to other active learning algorithms [11], [12], computing the pairs that come with the lowest closeness or correctness values can be time consuming, as it requires at least evaluating the values of wxk for each instance (xk, yk) \u2208 D, and then computing the measures on the pairs along with some selection or sorting steps that may be of super-linear time complexity [22].", "startOffset": 374, "endOffset": 378}, {"referenceID": 0, "context": "The soft version of active sampling can be described as follows: we consider a rejection sampling step that samples a pair xij with probability pij based on a method random() that generates random numbers between [0, 1].", "startOffset": 213, "endOffset": 219}, {"referenceID": 3, "context": "Both value functions are in the shape of the sigmoid function, which is widely used to represent probabilities in logistic regression and neural networks [4].", "startOffset": 154, "endOffset": 157}, {"referenceID": 20, "context": "We take the idea of [21] to weight the sampled pair by the inverse of its probability of being sampled.", "startOffset": 20, "endOffset": 24}, {"referenceID": 0, "context": "By introducing a parameter \u03b3 \u2208 [0, 1] to control the relative importance between the real pairs and the pseudo-pairs, we propose the following novel formulation.", "startOffset": 31, "endOffset": 37}, {"referenceID": 29, "context": "The CRC framework is closely related to the algorithm of Combined Ranking and Regression (CRR) [31] for general ranking.", "startOffset": 95, "endOffset": 99}, {"referenceID": 34, "context": "On the other hand, the idea of combining pair-wise and point-wise approaches had been used in another machine learning setup, the multi-label classification problem [36].", "startOffset": 165, "endOffset": 169}, {"referenceID": 18, "context": "The algorithm of Calibrated Ranking by Pairwise Comparison [19] assumes a calibration label between relevant and irrelevant labels, and hence unifies the pair-wise and point-wise label learning for multi-label classification.", "startOffset": 59, "endOffset": 63}, {"referenceID": 29, "context": "To the best of our knowledge, while the CRR approach has reached promising performance in practice [31], the CRC formulation has not been seriously studied.", "startOffset": 99, "endOffset": 103}, {"referenceID": 14, "context": "In the variant, we take one common trick to include We use one trick (as taken by LIBLINEAR [15]) that includes \u03b8 in the regularization term to allow simpler design of optimization routines.", "startOffset": 92, "endOffset": 96}, {"referenceID": 21, "context": "point-wise weighted linear SVM (2) (WSVM), an efficient implementation [22] of the pair-wise linear RankSVM (1) (ERankSVM), and the combined ranking and regression (CRR) [31] algorithm for general ranking.", "startOffset": 71, "endOffset": 75}, {"referenceID": 29, "context": "point-wise weighted linear SVM (2) (WSVM), an efficient implementation [22] of the pair-wise linear RankSVM (1) (ERankSVM), and the combined ranking and regression (CRR) [31] algorithm for general ranking.", "startOffset": 170, "endOffset": 174}, {"referenceID": 14, "context": "We solve the weighted SVM by the LIBLINEAR [15] package with its extension on instance weights.", "startOffset": 43, "endOffset": 47}, {"referenceID": 21, "context": "\u2022 ERankSVM: We use the SVM [22] package to efficiently solve the linear RankSVM (1) with the", "startOffset": 27, "endOffset": 31}, {"referenceID": 29, "context": "\u2022 CRR: We use the package sofia-ml [31] with the sgdsvm learner type, combined-ranking loop type and the default number of iterations that SGD takes to solve the problem.", "startOffset": 35, "endOffset": 39}, {"referenceID": 14, "context": "We solve the linearSVM within ASCRC by the LIBLINEAR [15] package with its extension on instance weights.", "startOffset": 53, "endOffset": 57}, {"referenceID": 24, "context": "The saturation corresponds to a known problem of uncertainty sampling in active learning because of the restricted view of the non-perfect model used for sampling [26].", "startOffset": 163, "endOffset": 167}], "year": 2017, "abstractText": "Bipartite ranking is a fundamental ranking problem that learns to order relevant instances ahead of irrelevant ones. The pair-wise approach for bi-partite ranking construct a quadratic number of pairs to solve the problem, which is infeasible for large-scale data sets. The point-wise approach, albeit more efficient, often results in inferior performance. That is, it is difficult to conduct bipartite ranking accurately and efficiently at the same time. In this paper, we develop a novel active sampling scheme within the pair-wise approach to conduct bipartite ranking efficiently. The scheme is inspired from active learning and can reach a competitive ranking performance while focusing only on a small subset of the many pairs during training. Moreover, we propose a general Combined Ranking and Classification (CRC) framework to accurately conduct bipartite ranking. The framework unifies point-wise and pair-wise approaches and is simply based on the idea of treating each instance point as a pseudo-pair. Experiments on 14 real-word large-scale data sets demonstrate that the proposed algorithm of Active Sampling within CRC, when coupled with a linear Support Vector Machine, usually outperforms state-of-the-art point-wise and pair-wise ranking approaches in terms of both accuracy and efficiency.", "creator": "LaTeX with hyperref package"}}}