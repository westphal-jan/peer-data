{"id": "1709.00084", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Aug-2017", "title": "Behavior Trees in Robotics and AI, an Introduction", "abstract": "a behavior tree ( bt ) is a way to structure the switching behaviors between different tasks in an autonomous agent, such as a mini robot or a complex virtual entity in a computer the game. bts are a very efficient way of creating numerous complex systems that are both modular and reactive. these properties are crucial in many applications, which has led to the spread of bt from computer game programming to many scientific branches of ai and robotics. in this book, we will first give schneider an introduction to bts, then we describe instantly how his bts relate to, and in many cases generalize, earlier traditional switching structures. these ideas generated are then used as a foundation for a set of efficient and easy to use design structure principles. properties such as job safety, robustness, and efficient efficiency are important for an autonomous system, and we describe a set of tools and for formally analyzing these using a state space description of bts. with the new analysis tools, however we possibly can formalize the simplest descriptions of how bts generalize earlier approaches. finally, we describe an extended standard set of tools to capture simulate the behavior of traditional stochastic bts, where the outcomes of actions are described by probabilities. providing these assessment tools enable the computation of both success mode probabilities and time to completion.", "histories": [["v1", "Thu, 31 Aug 2017 21:05:18 GMT  (7737kb,D)", "http://arxiv.org/abs/1709.00084v1", null], ["v2", "Thu, 21 Sep 2017 07:33:32 GMT  (7737kb,D)", "http://arxiv.org/abs/1709.00084v2", null]], "reviews": [], "SUBJECTS": "cs.RO cs.AI", "authors": ["michele colledanchise", "petter \\\"ogren"], "accepted": false, "id": "1709.00084"}, "pdf": {"name": "1709.00084.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Petter \u00d6gren"], "emails": [], "sections": [{"heading": null, "text": "Michele Colledanchise and Petter O\u0308gren\nBehavior Trees in Robotics and AI\nAn Introduction\nar X\niv :1\n70 9.\n00 08\n4v 1\n[ cs\n.R O\n] 3\n1 A\nug 2\n01 7\nContents\n1 What are Behavior Trees? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.1 A Short History of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.2 What is wrong with FSMs? The Need for Reactiveness and\nModularity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.3 Classical Formulation of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.1 Execution Example of a BT . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.3.2 Control Flow Nodes with Memory . . . . . . . . . . . . . . . . . . . . . . 10\n1.4 Creating a BT for Pac-Man from Scratch . . . . . . . . . . . . . . . . . . . . . . . 12 1.5 Creating a BT for a Mobile Manipulator Robot . . . . . . . . . . . . . . . . . . 14 1.6 Use of BTs in Robotics and AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n1.6.1 BTs in autonomous vehicles . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 1.6.2 BTs in industrial robotics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 1.6.3 BTs in the Amazon Picking Challenge . . . . . . . . . . . . . . . . . . 20 1.6.4 BTs inside the social robot JIBO . . . . . . . . . . . . . . . . . . . . . . . 21"}, {"heading": "2 How Behavior Trees Generalize and Relate to Earlier Ideas . . . . . . . . . 23", "text": "2.1 Finite State Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.1.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 24 2.1.2 Hierarchical Finite State Machines . . . . . . . . . . . . . . . . . . . . . . 24 2.1.3 Creating a FSM that works like a BTs . . . . . . . . . . . . . . . . . . 29 2.1.4 Creating a BT that works like a FSM . . . . . . . . . . . . . . . . . . . 31\n2.2 Subsumption Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 2.2.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 32 2.2.2 How BTs Generalize the Subsumption Architecture . . . . . . . 33 2.3 Teleo-Reactive programs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34 2.3.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 35 2.3.2 How BTs Generalize Teleo-Reactive Programs . . . . . . . . . . . 35 2.4 Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 2.4.1 Advantages and disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.4.2 How BTs Generalize Decision Trees . . . . . . . . . . . . . . . . . . . . 37 2.5 Advantages and Disadvantages of Behavior Trees . . . . . . . . . . . . . . . 38\nI\nII Contents\n2.5.1 Advantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 2.5.2 Disadvantages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n3 Design principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 3.1 Improving Readability using Explicit Success Conditions . . . . . . . . . 45 3.2 Improving Reactivity using Implicit Sequences . . . . . . . . . . . . . . . . . . 46 3.3 Handling Different Cases using a Decision Tree Structure . . . . . . . . . 47 3.4 Improving Safety using Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 3.5 Creating Deliberative BTs using Backchaining . . . . . . . . . . . . . . . . . . 49 3.6 Creating Un-Reactive BTs using Memory Nodes . . . . . . . . . . . . . . . . 51 3.7 Choosing the Proper Granularity of a BT . . . . . . . . . . . . . . . . . . . . . . . 52"}, {"heading": "4 Analysis of Efficiency, Safety, and Robustness . . . . . . . . . . . . . . . . . . . . . 55", "text": "4.1 Statespace Formulation of BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.2 Efficiency and Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 4.3 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 4.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n4.4.1 Robustness and Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 4.4.2 Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 4.4.3 Complex BT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73"}, {"heading": "5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas . . . . 77", "text": "5.1 How BTs Generalize Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 77 5.2 How BTs Generalize the Subsumption Architecture . . . . . . . . . . . . . . 79 5.3 How BTs Generalize Sequential Behavior Compositions . . . . . . . . . . 81 5.4 How BTs Generalize TRs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\n5.4.1 Universal TRs and FT-Successful BTs . . . . . . . . . . . . . . . . . . . 84\n6 Stochastic BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 6.1 Stochastic BTs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n6.1.1 Markov Chains and Markov Processes . . . . . . . . . . . . . . . . . . 89 6.1.2 Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n6.2 Transforming a SBT into a DTMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 6.2.1 Computing Transition Properties of the DTMC . . . . . . . . . . . 99 6.3 Reliability of a SBT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 6.3.1 Average sojourn time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 6.3.2 Mean Time To Fail and Mean Time To Succeed . . . . . . . . . . 103 6.3.3 Probabilities Over Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 6.3.4 Stochastic Execution Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 6.3.5 Deterministic Execution Times . . . . . . . . . . . . . . . . . . . . . . . . . 105 6.4 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\nQuotes on Behavior Trees\n\u201cThere are a lot of different ways to create AI\u2019s, and I feel like I\u2019ve tried pretty much all of them at one point or another, but ever since I started using behavior trees, I wouldn\u2019t want to do it any other way. I wish I could go back in time with this information and do some things differently.\u201d 1\nMike Weldon Disney, Pixar\n\u201c[...]. Sure you could build the very same behaviors with a finite state machine (FSM). But anyone who has worked with this kind of technology in industry knows how fragile such logic gets as it grows. A finely tuned hierarchical FSM before a game ships is often a temperamental work of art not to be messed with!\u201d 2\nAlex J. Champandard Editor in Chief & Founder AiGameDev.com,\nSenior AI Programmer Rockstar Games\n\u201cBehavior trees offer a good balance of supporting goal-oriented behaviors and reactivity. 3 \u201d\nDaniel Broder Unreal Engine developer\n\u201cThe main advantage [of Behavior Trees] is that individual behaviors can easily be reused in the context of another higher-level behavior, without needing to specify how they relate to subsequent behaviors, [1]\u201d.\nAndrew Bagnell et al. Carnegie Mellon University."}, {"heading": "1 http://www.gamasutra.com/blogs/ChrisSimpson/20140717/221339/ Behavior_trees_for_AI_How_they_work.php", "text": ""}, {"heading": "2 http://aigamedev.com/open/article/fsm-age-is-over/", "text": ""}, {"heading": "3 https://forums.unrealengine.com/showthread.php?6016-Behavior-", "text": "Trees-What-and-Why\nChapter 1 What are Behavior Trees?\nA Behavior Tree (BT) is a way to structure the switching between different tasks1 in an autonomous agent, such as a robot or a virtual entity in a computer game. An example of a BT can be seen in Fig. 1.1a. As will be explained, BTs are a very efficient way of creating complex systems that are both modular and reactive. These properties are crucial in many applications, which has led to the spread of BT from computer game programming to many branches of AI and Robotics.\nIn this book, we will first give an introduction to BTs, in the present chapter. Then, in Chapter 2 we describe how BTs relate to, and in many cases generalize, earlier switching structures. These ideas are then used as a foundation for a set of efficient and easy to use design principles described in Chapter 3. Properties such as safety, robustness, and efficiency are important for an autonomous system, and in Chapter 4 we describe a set of tools for formally analyzing these using a state space description of BTs. With the new analysis tools, we can formalize the descriptions of how BTs generalize earlier approaches in Chapter 5. Finally, we describe an extended set of tools to capture the behavior of Stochastic BTs, where the outcomes of actions are described by probabilities, in Chapter 6. These tools enable the computation of both success probabilities and time to completion.\nIn this chapter, we will first tell a brief history of BTs in Section 1.1, and explain what are the core benefits of BTs, in Section 1.2, then in Section 1.3 we will describe how a BT works. Then, we will create a simple BT for the video game Pac-Man in Section 1.4 and a more sophisticated BT for a mobile manipulator in Section 1.5. We finally describe the usage of BT in a number of applications in Section 1.6.\n1 assuming that an activity can somehow be broken down into reusable sub-activities called tasks sometimes also denoted actions or control modes\n3\n4 1 What are Behavior Trees?"}, {"heading": "1.1 A Short History of BTs", "text": "BTs were developed in the video game industry, as a tool to increase modularity in the control structures of Non-Player Characters (NPCs) [18, 7, 19, 25, 36]. In this billion-dollar industry, modularity is a key property that enables reuse of code, incremental design of functionality, and efficient testing.\nIn games, the control structures of NPCs were often formulated in terms of Finite State Machines (FSMs). However, just as Petri Nets [29] provide an alternative to FSMs that supports concurrency, BTs provide an alternative view of FSMs that supports modularity.\nFollowing the development in the industry, BTs have now also started to receive attention in academia [22, 30, 38, 3, 33, 23, 1, 21, 8, 12, 17, 15].\nAt Carnegie Mellon University, BTs have been used extensively to do robotic manipulation [1, 12]. The fact that modularity is the key reason for using BTs is clear from the following quote from [1]: \u201cThe main advantage is that individual behaviors can easily be reused in the context of another higher-level behavior, without needing to specify how they relate to subsequent behaviors\u201d.\nBTs have also been used to enable non-experts to do robot programming of pick and place operations, due to their \u201cmodular, adaptable representation of a robotic task\u201d [15] and allowed \u201cend-users to visually create programs with the same amount of complexity and power as traditionally-written programs\u201d [34]. Furthermore, BTs have been proposed as a key component in brain surgery robotics due to their \u201cflexibility, reusability, and simple syntax\u201d [17].\nThe advantages of BTs as compared to FSMs was the reason for extending the so-called JADE agent Behavior Model with BTs in [3], and the benefits of using BTs to control complex multi mission UAVs was described in [33].\nThe modularity of BTs was used to address the formal verification of mission plans in [21] while the execution time of stochastic BTs was analyzed in [8]. BTs have also been studied in machine learning applications [22, 30] and details regarding efficient parameter passing were investigated in [38]. Finally, a Modelica implementation of BTs was presented in [20]."}, {"heading": "1.2 What is wrong with FSMs? The Need for Reactiveness and Modularity", "text": "Many autonomous agents need to be both reactive and modular. By reactive we mean the ability to quickly and efficiently react to changes. We want a robot to slow down and avoid a collision if a human enters into its planned trajectory and we want a virtual game character to hide, flee, or fight, if made aware of an approaching enemy. By modular, we mean the degree to which a system\u2019s components may be separated into building blocks, and recombined [13]. We want the agent to be modular, to enable components to be developed, tested, and reused independently of one\n1.2 What is wrong with FSMs? The Need for Reactiveness and Modularity 5\nanother. Since complexity grows with size, it is beneficial to be able to work with components one at a time, rather than the combined system.\nFSMs have long been the standard choice when designing a task switching structure, see e.g. [35, 26]. FSMs will be discussed in detail in Chapter 2.1, but here we make a short description of the tradeoff between reactivity and modularity that is inherent in FSMs. This tradeoff can be understood in terms of the classical Gotostatement that was used in early programming languages. The Goto statement is an example of a so-called one-way control transfer, where the execution of a program jumps to another part of the code and continue executing from there. Instead of one-way control transfers, modern programming languages tend to rely on two-way control transfers embodied in e.g. function calls. Here, execution jumps to a particular part of the code, executes it, and then returns to where the function call was made. The drawbacks of one-way control transfers were made explicit by Edsgar Dijkstra in his paper Goto statement considered harmful [10], where he states that \u201cThe Goto statement as it stands is just too primitive; it is too much an invitation to make a mess of one\u2019s program\u201d. Looking back at the state transitions in FSMs, we note that they are indeed one-way control transfers. This is where the tradeoff between reactivity and modularity is created. For the system to be reactive, there needs to be many transitions between components, and many transitions means many oneway control transfers which, just as Dijkstra noted, harms modularity by being an \u201cinvitation to make a mess of one\u2019s program\u201d. If, for example, one component is removed, every transition to that component needs to be revised. As will be seen, BTs use two-way control transfers, governed by the internal nodes of the trees.\nUsing BTs instead of FSMs to implement the task switching, allows us to describe the desired behavior in modules as depicted in Figure 1.1a. Note that in the next section we will describe how BTs work in detail, so these figures are just meant to give a first glimpse of BTs, rather than the whole picture.\nA behavior is often composed of a sequence of sub-behaviors that are task independent, meaning that while creating a sub-behavior the designer does not need to know which sub-behavior will be performed next. Sub-behaviors can be designed recursively, adding more details as in Figure 1.1b. BTs are executed in a particular way, which will be described in the following section, that allows the behavior to be carried out reactively. For example, the BTs in Figure 1.1 execute the sub-behavior Place Ball, but also verifies that the ball is still at a known location and securely grasped. If, due to an external event, the ball slips out out of the grasp, then the robot will abort the sub-behavior Place Ball and will re-execute the sub-behavior Pick Ball or Find Ball according to the current situation.\n6 1 What are Behavior Trees?"}, {"heading": "1.3 Classical Formulation of BTs", "text": "At the core, BTs are built from a small set of simple components, just as many other powerful concepts, but throughout this book, we will see how this simple formalism can be used to create very rich structures, in terms of both applications and theory.\nFormally speaking, a BT is a directed rooted tree where the internal nodes are called control flow nodes and leaf nodes are called execution nodes. For each connected node we use the common terminology of parent and child. The root is the node without parents; all other nodes have one parent. The control flow nodes have at least one child. Graphically, the children of a node are placed below it, as shown in Figures 1.2-1.4.\nA BT starts its execution from the root node that generates signals that allow the execution of a node called ticks with a given frequency, which are sent to its children. A node is executed if and only if it receives ticks. The child immediately returns running to the parent, if its execution is under way, success if it has achieved its goal, or failure otherwise.\nIn the classical formulation, there exist four categories of control flow nodes (sequence, fallback, parallel, and decorator) and two categories of execution nodes (action and condition). They are all explained below and summarized in Table 1.1.\n1.3 Classical Formulation of BTs 7\nThe sequence node executes Algorithm 1, which corresponds to routing the ticks to its children from the left until it finds a child that returns either failure or running, then it returns failure or running accordingly to its own parent. It returns success if and only if all its children return success. Note that when a child returns running or failure, the sequence node does not route the ticks to the next child (if any). The symbol of the sequence node is a box containing the label \u201c\u2192\u201d, shown in Figure 1.2.\nAlgorithm 1: Pseudocode of a Sequence node with N children 1 for i\u2190 1 to N do 2 childStatus\u2190 Tick(child(i)) 3 if childStatus = running then 4 return running 5 else if childStatus = failure then 6 return failure\n7 return success\nThe fallback node2 executes Algorithm 2, which corresponds to routing the ticks to its children from the left until it finds a child that returns either success or running, then it returns success or running accordingly to its own parent. It returns failure if and only if all its children return failure. Note that when a child returns running or success, the fallback node does not route the ticks to the next child (if any). The symbol of the the fallback node is a box containing the label \u201c?\u201d, shown in Figure 1.3.\nThe parallel node executes Algorithm 3, which corresponds to routing the ticks to all its children and it returns success if M children return success, it returns failure if N\u2212M+1 children return failure, and it returns running otherwise, where N is the number of children and M \u2264 N is a user defined threshold. The symbol of the the parallel node is a box containing the label \u201c\u21d2\u201d, shown in Figure 1.4.\n2 Fallback nodes are sometimes also called selector nodes.\n8 1 What are Behavior Trees?\nAlgorithm 3: Pseudocode of a Parallel node with N children and success threshold M 1 for i\u2190 1 to N do 2 childStatus(i)\u2190 Tick(child(i)) 3 if \u03a3i:childStatus(i)=success1\u2265M then 4 return Success 5 else if \u03a3i:childStatus(i)= f ailure1 > N\u2212M then 6 return failure\n7 return running\nWhen it receives ticks, an action node executes a command. It returns success if the action is correctly completed or failure if the action has failed. While the action is ongoing it returns running. An action node is shown in Figure 1.5a.\nWhen it receives ticks, a condition node checks a proposition. It returns success or failure depending on if the proposition holds or not. Note that a condition node never returns a status of running. A condition node is shown in Figure 1.5b.\nThe decorator node is a control flow node with a single child that manipulates the return status of its child according to a user-defined rule and also selectively ticks the child according to some predefined rule. For example, an invert decorator inverts the success/failure status of the child; a max-N-tries decorator only lets its child fail N times, then always returns failure without ticking the child; a max-Tsec decorator lets the child run for T seconds then, if the child is still running, the decorator returns failure without ticking the child. The symbol of the the decorator is a rhombus, as in Figure 1.5c."}, {"heading": "1.3.1 Execution Example of a BT", "text": "Consider the BT in Figure 1.6 designed to make an agent look for a ball, approach it, grasp it, proceed to a bin, and place the ball in the bin. This example will illustrate the execution of the BT, including the reactivity when another (external) agent takes the ball from the first agent, making it switch to looking for the ball and approaching it again. When the execution starts, the ticks traverse the BT reaching the condition node Ball Found. The agent does not know the ball position hence the condition node returns failure and the ticks reach the action Find Ball, which returns running (see Figure 1.7a). While executing this action, the agent sees the ball with the camera. In\n10 1 What are Behavior Trees?\nthis new situation the agent knows the ball position. Hence the condition node Ball Found now returns success resulting in the ticks no longer reaching the action node Find Ball and the action is preempted. The ticks continue exploring the tree, and reach the condition node Ball Close, which returns failure (the ball is far away) and then reach the action node Approach Ball, which returns running (see Figure 1.7b). Then the agent eventually reaches the ball, picks it up and goes towards the bin (see Figure 1.7c). When an external agent moves the ball from the hand of the first agent to the floor (where the ball is visible), the condition node Ball Found returns success while the condition node Ball Close returns failure. In this situation the ticks no longer reach the action Approach Bin (which is preempted) and they instead reach the action Approach Ball (see Figure 1.7d)."}, {"heading": "1.3.2 Control Flow Nodes with Memory", "text": "As seen in the example above, to provide reactivity the control flow nodes sequence and fallback keep sending ticks to the children to the left of a running child, in order to verify whether a child has to be re-executed and the current one has to be preempted. However, sometimes the user knows that a child, once executed, does not need to be re-executed.\nNodes with memory [25] have been introduced to enable the designer to avoid the unwanted re-execution of some nodes. Control flow nodes with memory always remember whether a child has returned success or failure, avoiding the re-execution of the child until the whole sequence or fallback finishes in either success or failure. In this book, nodes with memory are graphically represented with the addition of the symbol \u201c\u2217\u201d (e.g. a sequence node with memory is graphically represented by a box with a \u201c\u2192\u2217\u201d). The memory is cleared when the parent node returns either success or failure, so that at the next activation all children are considered. Note however that every execution of a control flow node with memory can be obtained with a nonmemory BT using some auxiliary conditions as shown in Figure 1.8. Hence nodes with memory can be considered to be syntactic sugar.\nRemark 1.1. Some BT implementations, such as the one described in [25], do not include the running return status. Instead, they let each action run until it returns\n1.3 Classical Formulation of BTs 11\nfailure or success. We denote these BTs as non-reactive, since they do not allow actions other than the currently active one to react to changes. This is a significant limitation on non-reactive BTs, which was also noted in [25]. A non-reactive BT can be seen as a BT with only memory nodes.\nAs reactivity is one of the key strengths of BTs, the non-reactive BTs are of limited use.\n12 1 What are Behavior Trees?"}, {"heading": "1.4 Creating a BT for Pac-Man from Scratch", "text": "In this section we create a set of BTs of increasing complexity for playing the game Pac-Man. The source code of all the examples is publicly available and editable, see Appendix A. We use a clone of the Namco\u2019s Pac-Man computer game depicted in\nFigure 1.93.\nIn the testbed, a BT controls the agent, Pac-Man, through a maze containing two ghosts, a large number of pills, including two so-called power pills. The goal of the game is to consume all the pills, without being eaten by the ghosts. The power pills are such that, if eaten, Pac-Man receives temporary super powers, and is able to eat the ghosts. After a given time the effect of the power pill wears off, and the ghosts can again eat Pac-Man. When a ghost is eaten, it returns to the center box where it is regenerated and becomes dangerous again. Edible ghosts change color, and then flash to signal when they are about to become dangerous again.\n3 The software was developed at UC Berkeley for educational purposes. More information available at: http://ai.berkeley.edu/project_overview.html\n1.4 Creating a BT for Pac-Man from Scratch 13\nThe simplest behavior is to let Pac-Man ignore the ghosts and just focus on eating pills. This is done using a greedy action Eat pills as in Figure 1.10.\nThe simple behavior described above ignores the ghosts. To take them into account, we can extend the previous behavior by adding an Avoid Ghosts action to be executed whenever the condition Ghost Close is true. This action will greedily maximize the distance to all ghosts. The new action and condition can be added to the BT as depicted in Fig. 1.11. The resulting BT will switch between Eat Pills and Avoid Ghost depending on whether Ghost Close returns success or failure.\nThe next extension we make is to take the power pills into account. When PacMan eats a Power pill, the ghosts are edible, and we would like to chase them, instead of avoiding them. To do this we add the condition Ghost Scared and the action Chase Ghost to the BT, as shown in Fig. 1.12. Chase Ghost greedily minimizes the distance to the closest edible ghost. Note that we only start chasing the ghost if it is close, otherwise we continue eating pills. Note also that all extensions are modular, without the need to rewire the previous BT.\nWith this incremental design, we have created a basic AI for playing Pac-Man, but what if we want to make a world class Pac-Man AI? You could add additional nodes to the BT, such as moving towards the Power pills when being chased, and stop chasing ghosts when they are blinking and soon will transform into normal ghosts. However, much of the fine details of Pac-Man lies in considerations of the Maze geometry, choosing paths that avoid dead ends and possible capture by multiple ghosts. Such spatial analysis is probably best done inside the actions, e.g., making Avoid Ghosts take dead ends and ghost positions into account. The question\n14 1 What are Behavior Trees?\nof what functionality to address in the BT structure, and what to take care of inside the actions is open, and must be decided on a case to case basis, as discussed in Section 3.7."}, {"heading": "1.5 Creating a BT for a Mobile Manipulator Robot", "text": "1.5 Creating a BT for a Mobile Manipulator Robot 15\nIn this section, we create a set of BTs of increasing complexity for controlling a mobile manipulator. The source code of all the examples is publicly available and editable. See Appendix B. We use a custom-made testbed created in the V-REP robot simulator depicted in Figure 1.13.\nIn the testbed, a BT controls a mobile manipulator robot, a youBot, on a flat surface. In the scenario, there are several colored cubes lying on a flat surface. The goal is to move the green cube to the goal area while avoiding the other cubes. The youBot\u2019s grippers are such that the robot is able to pick and place the cubes if the robot is close enough.\nThe simplest possible BT is to check the goal condition Green Cube on Goal. If this condition is satisfied (i.e. the cube is on the goal) the task is done, if it is not satisfied the robot needs to place the cube onto the goal area. To correctly execute the action Place Cube, two conditions need to hold: the robot is holding the green cube and the robot is close to the goal area. The behavior described so far can be encoded in the BT in Figure 1.14. This BT is able to place the green cube on the goal area if and only if the robot is close to the goal area with the green cube grasped.\nNow, thanks to the modularity of BTs, we can separately design the BTs needed to satisfy the two lower conditions in Fig. 1.14, i.e., the BT needed to grasp the green cube and the BT needed to reach the goal area. To grasp the green cube, the robot needs to have the hand free and be close to the cube. If it is not close, it approaches as long as a collision free trajectory exists. This behavior can be engoded is the BT in Figure 1.15a. To reach the goal area we let the robot simply Move To the Goal as long as a collision free trajectory exists. This behavior can be engoded is the BT in Figure 1.15b.\nNow we can extend the simple BT above by replacing the two lower conditions in Fig. 1.14 with the two BTs in Fig. 1.15. The result can be seen in Fig. 1.16. Using this design, the robot is able to place the green cube in the goal area as long as there exists a collision free trajectory to the green cube and to the goal area.\nWe can continue to incrementally build the BT in this way to handle more situations, for instance removing obstructing objects to ensure that a collision free trajectory exists, and dropping things in the hand to be able to pick the green cube up.\n16 1 What are Behavior Trees?"}, {"heading": "1.6 Use of BTs in Robotics and AI", "text": "In this section we describe the use of BTs in a set of real robot applications and projects, spanning from autonomous navigation to industrial robotics."}, {"heading": "1.6.1 BTs in autonomous vehicles", "text": "There is no standard CA for autonomous vehicles, however reviewing the CAs used to address the DARPA Grand Challenge, a competition for autonomous vehicles, we note that most teams employed FSMs designed and developed exactly for that challenge [40, 41]. Some of them used a HFSM[26] decomposing the mission task in multiple sub-tasks in a hierarchy.\n1.6 Use of BTs in Robotics and AI 17\niQmatic is a Scania led project that aims at developing a fully autonomous heavy vehicle, i.e. a truck, for goods transport; mining; and other industrial applications. The vehicle\u2019s software has to be reusable, maintainable and easy to develop. For these reasons, the iQmatic\u2019s developers chose BTs as the CA for the project. BTs are appreciated in iQmatic for their human readability, that support the design and\n4 Picture courtesy of Scania.com\n18 1 What are Behavior Trees?\ndevelopment of early prototypes; and their maintainability, that makes the editing task easier. Figure 1.17 shows two trucks used in the iQmatic project."}, {"heading": "1.6.2 BTs in industrial robotics", "text": "Industrial robots usually operate in structured environments and their CA is designed for a single specific task. Hence classical CAs such as FSMs or Petri Nets [29] have found successful applications in the last decades. However, future generations of industrial robots, so-called cobots, will operate in less structured environments and collaborate closely with humans. Several research projects explore this research direction.\nCoSTAR [34] is a project that aims at developing a software framework that contains tools for industrial applications that involve human cooperation. The use cases include non trained operators composing task plans, and training robots to perform complex behaviors. BTs have found successful applications in this project as they simplify the composition of sub-tasks. The order in which the sub-tasks are executed is independent from the sub-task implementation; this enables easy composition of trees and the iterative composition of larger and larger trees. Figure 1.18 shows one of the robotic platforms of the project.\n5 Picture courtesy of http://cpaxton.github.io/\n1.6 Use of BTs in Robotics and AI 19\nSARAFun7 is a project that aims at developing a robot-programming framework that enables a non-expert user to program an assembly task from scratch on a robot in less than a day. It takes advantages of state of the art techniques in sensory and cognitive abilities, robot control, and planning.\nBTs are used to execute the generic actions learned or planned. For the purpose of this project, the CA must be human readable, enable code reuse, and modular. BTs have created advantages also during the development stage, when the code written by different partners had to be integrated. Figure 1.19 shows an ABB Yumi robot used in the SARAFun testbed.\n7 http://h2020sarafun.eu\n20 1 What are Behavior Trees?\nRethink Robotics released its software platform Intera in 2017, with BTs at the \u201cheart of the design\u201d. Intera claims to be a \u201cfirst-of-its-kind software platform that connects everything from a single robot controller, extending the smart, flexible power of Rethink Robotics\u2019 Sawyer to the entire work cell and simplifying automation with unparalleled ease of deployment.\u201d9 It is designed with the goal of creating the world\u2019s fastest-to-deploy robot and fundamentally changing the concepts of integration, making it drastically easier and affordable.\nIntera\u2019s BT defines the sequence of tasks the robot will perform. The tree can be created manually or trained by demonstration. Users can inspect any portion of the BT and make adjustments. The Intera interface (see Figure 1.20) also includes a simulated robot, so a user can run simulations while the program executes the BT. BTs are appreciated in this context because the train-by-demonstration framework builds a BT that is easily inspectable and modifiable.10"}, {"heading": "1.6.3 BTs in the Amazon Picking Challenge", "text": "The Amazon Picking Challenge (APC) is an international robot competition. Robots need to autonomously retrieve a wide range of products from a shelf and put them into a container. The challenge was conceived with the purpose of strengthening the ties between industrial and academic robotic research, promoting shared solutions to some open problems in unstructured automation. Over thirty companies and research laboratories from different continents competed in the APC\u2019s preliminary phases. The best performing teams earned the right to compete at the finals and the source codes of the finalists were made publicly available 11.\nThe KTH entry in the final challenge used BTs in both editions (2015 and 2016). BTs were appreciated for their modularity and code reusability, which allowed the integration of different functionalities developed by programmers with different background and coding styles. In 2015, the KTH entry got the best result out of the four teams competing with PR2 robots.\n9 http://www.rethinkrobotics.com/news-item/rethink-roboticsreleases-intera-5-new-approach-automation/ 9 Setup located at CERTH, Thessaloniki, Greece. Picture courtesy of Angeliki TopalidouKyniazopoulou. 9 Picture courtesy of http://www.rethinkrobotics.com/intera/ 10 http://twimage.net/rodney-brooks-743452002 11 https://github.com/amazon-picking-challenge\n1.6 Use of BTs in Robotics and AI 21"}, {"heading": "1.6.4 BTs inside the social robot JIBO", "text": "JIBO is a social robot that can recognize faces and voices, tell jokes, play games and share information. It is intended to be used in homes, providing the functionality of a tablet, but with an interface relying on speech and video instead of a touch screen. BTs are a fundamental part of the software architecture of JIBO12, including an open SDK inviting external contributors to develop new skills for the robot.\n12 https://developers.jibo.com/docs/behavior-trees.html\n22 1 What are Behavior Trees?\nChapter 2 How Behavior Trees Generalize and Relate to Earlier Ideas\nIn this chapter we describe how BT relate to, and often generalize, a number of well known control architectures including Finite State Machines (2.1), the Subsumption Architecture (2.2), the Teleo-Reactive Approach (2.3) and Decision Trees (2.4). We also present advantages and disadvantages of each approach. Finally, we list a set of advantages and disadvantages of BTs (2.5). Some of the results of this chapter were previously published in the journal paper [9]."}, {"heading": "2.1 Finite State Machines", "text": "A FSM is one of the most basic mathematical models of computation. The FSM consists of a set of states, transitions and events, as illustrated in Fig. 2.1 showing an example of a FSM designed to carry out a grab-and-throw task. Note that the discussion here is valid for all CAs based on FSMs, including Mealy [27] and Moore [24] machines.\n23\n24 2 How Behavior Trees Generalize and Relate to Earlier Ideas"}, {"heading": "2.1.1 Advantages and disadvantages", "text": "FSMs are widely used due to their three main advantages:\n\u2022 Very common structure, used in many different parts of computer science. \u2022 Intuitive and easy to understand. \u2022 Easy to implement.\nHowever, the drawbacks of FSMs gives rise to problems when the system modelled grows in complexity and number of states, as described briefly in Section 1.2. In particular we have the following drawbacks\n\u2022 Reactivity/Modularity tradeoff. A reactive system needs many transitions, and every transition corresponds to a goto-statement, see Section refsec:modularity. In particular, the transitions give rise to the problems below:\n\u2013 Maintainability: Adding or removing states requires to re-evaluate possibly all the transitions and internal states of the whole FSM. This makes FSMs highly susceptible to human design errors and makes them inefficient to be used and generated by computer programs. \u2013 Scalability: FSMs with many states and many transitions between them are hard to modify, for both humans and computers. \u2013 Reusability: The transitions between states may depend on internal variables (like in a Hybrid Automaton), making it unpractical to encode the same task for use in multiple projects."}, {"heading": "2.1.2 Hierarchical Finite State Machines", "text": "Hierarchical Finite State Machines (HFSMs), also known as State Charts[16], where developed to alleviate some of the disadvantages of FSMs. In a HFSM, a state can in turn contain one or more sub states. A state containing two or more states is called a super state. In a HFSM, a generalized transition is a transition between super states. Generalized transitions can reduce the number of transitions by connecting two super states rather than connecting a larger number of sub states individually. Each super state has one sub state identified as the starting state, executing whenever a transition to the super state occurs. Figure 2.2 shows an example of a HFSM for a video game character."}, {"heading": "2.1.2.1 Advantages and disadvantages", "text": "The main advantages of HFSMs are:\n2.1 Finite State Machines 25\n\u2022 Increased Modularity: it is possible to separate the tasks in sub-tasks. However these sub-tasks often still depend on each other through state-dependent transitions. \u2022 Behavior inheritance: The state nesting in HFSMs allows so-called behavior inheritance. Behavior inheritance allows sub-states to inherit behaviors from the superstate; for example, in the HFSM depicted in Figure 2.2, while in the sub-states inside Use Handgun, the character holds the weapon using one hand whereas while in the sub-states inside Use Rifle, the character holds the weapon using two hands. Thus, there is no need for the sub states to specify this property, instead, it is inherited from the superstate.\nThe main disadvantages of HFSMs are:\n\u2022 Maintainability: Adding or removing states is still hard. A long sequence of actions, with the possibility of going back in the sequence and re-execute a task that was undone by external agents (e.g. the environment), still requires a fully connected sub-graph. \u2022 Manually created hierarchy: Although HFSMs were conceived as a hierarchical version of FSMs, the hierarchy has to be user defined and editing such a hierarchy can be difficult. The hierarchy resolves some problems, but a reactive HFSM still results in some sub graphs being fully connected with many possible transitions, see Fig. 2.3.\n26 2 How Behavior Trees Generalize and Relate to Earlier Ideas\nFrom a theoretical standpoint, every execution described by a BT can be described by a FSM and vice-versa [33, 23]. However, due to the number of transitions, using a FSM as a CA is unpractical for some applications as shown in Chapter 1. Moreover, a potential problem is that a FSM does not assume that the propositions triggering the outgoing transitions from the same state are mutually exclusive. When implemented, the propositions are checked regularly in discrete time, hence there exists a non-zero probability that two or more propositions hold simultaneously after one cycle. To solve this problem we need to redefine some transitions, as done in the FSM in Figure 2.22, making the propositions of the outgoing transitions mutually exclusive. A FSM of this format is impractical to design for both humans and computers. Adding and removing behaviors by a human is prone to errors. After adding a new state, each existing transition must be re-evaluated (possibly removed or replaced) and new transitions from/to the new state must be evaluated as well. A high number of transitions make any automated process to analyze or synthesize FSMs computationally expensive.\nHFSMs is the most similar CA to BTs in terms of purpose and use. To compare BTs with HFSMs we use the following complex example. Consider the HFSM shown in Figure 2.3 describing the behavior of a humanoid robot. We can describe the same functionality using the BT shown in Figure 2.4. Note that we have used the standard notation [16] of HFSMs to denote two activities running in parallel with a dashed line as separation. One important difference is that, in HFSMs, each layer in the hierarchy needs to be added explicitly, whereas in BTs every sub-tree can be seen as a module of its own, with the same interface as an atomic action.\nIn the HFSM shown in Figure 2.3, a proposition needs to be given for each transition, and to improve readability we have numbered these propositions from C1 to C10. In the top layer of the HFSM we have the sub-HFSMs of Self Protection and Perform Activites. Inside the latter we have two parallel sub-HFSMs. One is handling the user interaction, while the larger one contains a complete directed graph handling the switching between the different activities. Finally, Play Ball Game is yet another sub-HFSM with the ball tracking running in parallel with another complete directed graph, handling the reactive switching between Approach Ball, Grasp Ball, and Throw Ball.\nIt is clear from the two figures how modularity is handled by the HFSM. The explicitly defined sub-HFSM encapsulates Self Protection, Perform Activities and Play Ball Game. However, inside these sub-HFSMs, the transition structure is a complete directed graph, with n(n\u2212 1) transitions that need to be maintained (n being the number of nodes).\n2.1 Finite State M achines 27\n28 2 H ow B ehaviorTrees G eneralize and R elate to E arlierIdeas\n2.1 Finite State Machines 29"}, {"heading": "2.1.3 Creating a FSM that works like a BTs", "text": "As described in Chapter 1, each BT returns Success, Running or Failure. Imagine we have a state in an FSM that has 3 transitions, corresponding to these 3 return statements. Adding a Tick source that collect the return transitions and transfer the execution back into the state, as depicted in Figure 2.5, we have a structure that resembles a BT.\nWe can now compose such FSM states using both Fallback and Sequence constructs. The FSM corresponding to the Fallback example in Figure 2.6 would then look like the one shown in Figure 2.7.\nSimilarly, the FSM corresponding to the Sequence example in Figure 2.8 would then look like the one shown in Figure 2.9, and a two level BT, such as the one in Figure 2.10 would look like Figure 2.11.\nA few observations can be made from the above examples. First, it is perfectly possible to design FSMs with a structure taken from BTs. Second, considering that a BT with 2 levels corresponds to the FSM in Figure 2.11, a BT with 5 levels, such as the one in Figure 2.12 would correspond to a somewhat complex FSM.\nThird, and more importantly, the modularity of the BT construct is illustrated in Figures 2.5-2.11. Figure 2.11 might be complex, but that complexity is encapsulated in a box with a single in-transition and three out-transitions, just as the box in Figure 2.5.\nFourth, as was mentioned in Section 1.2, the decision of what to do after a given sub-BT returns is always decided on the parent level of that BT. The sub-BT is ticked, and returns Success, Running or Failure and the parent level decides whether to tick the next child, or return something to its own parent. Thus, the BT ticking and returning of a sub-BT is similar to a function call in a piece of source code, just as described in Section 1.2. A function call in Java, C++ or Python moves execution to another piece of the source code, but then returns the execution to the line right below the function call. What to do next is decided by the piece of code that made the function call, not the function itself. As we will see below, this is quite different\n30 2 How Behavior Trees Generalize and Relate to Earlier Ideas\nfrom standard FSMs where the decision of what to do next is decided by the state being transitioned to, in a way that resembles the Goto statement.\n2.2 Subsumption Architecture 31"}, {"heading": "2.1.4 Creating a BT that works like a FSM", "text": "If you have a FSM design and want to convert it to a BT, the most straight forward way is to create a State Variable available to all parts of the BT and then list all the states of the FSM and their corresponding transitions and actions as shown in Figure 2.13."}, {"heading": "2.2 Subsumption Architecture", "text": "The Subsumption Architecture [4] is heavily associated with the behavior-based robotic architecture, which was very popular in the late 1980s and 90s. This archi-\n32 2 How Behavior Trees Generalize and Relate to Earlier Ideas\ntecture has been widely influential in autonomous robotics and elsewhere in realtime AI and has found a number of successful applications [5]. The basic idea of the Subsumpion Architecture is to have several controllers, each one implementing a task, running in parallel. Each controller is allowed to output both its actuation commands and a binary value that signifies if it wants to control the robot or not. The controllers are ordered according to some priority (usually user defined), and the highest priority controller, out of the ones that want to control the robot, has the access to the actuators. Thus, a controller with a higher priority is able to subsume a lower level one. Figure 2.14 shows an example of a Subsumption Architecture."}, {"heading": "2.2.1 Advantages and disadvantages", "text": "The Subsumption Architecture has many practical advantages, in particular:\n2.2 Subsumption Architecture 33\n\u2022 Easy development: The Subsumption Architecture is naturally well suited for iterative development and testing. \u2022 Modularity: The Subsumption Architecture connects limited, task-specific actions. \u2022 Hierarchy: The controllers are hierarchically ordered, which makes it possible to define high priority behaviors (e.g. safety guarantees) that override others.\nThe main disadvantages of the Subsumption Architecture are:\n\u2022 Scalability: Designing complex action selection through a distributed system of inhibition and suppression can be hard. \u2022 Maintainability: Due to the lack of structure, the consequences of adding or removing controllers can be hard to estimate."}, {"heading": "2.2.2 How BTs Generalize the Subsumption Architecture", "text": "There is a straightforward mapping from a Subsumption Architecture design to a BT using a fallback node. If each controller in the SA is turned into a BT action, returning running if the binary output indicates that it wants to run and failure the rest of the time, a standard fallback composition will create an equivalent BT. As an example we see that the structure in Fig. 2.14 is represented by the BT in Fig. 2.15. A more formal argument using a state space representation of BTs will be given in Section 5.2.\n34 2 How Behavior Trees Generalize and Relate to Earlier Ideas"}, {"heading": "2.3 Teleo-Reactive programs", "text": "Teleo-Reactive (TR) programs were introduced by Nils Nilsson [31] at Stanford University in 1994 to allow engineers to define the behavior of a robotics system that had to achieve specific goals while being responsive to changes in the environment. A TR program is composed of a set of prioritized condition-action rules that directs the agent towards a goal state (hence the term teleo) while monitoring the environmental changes (hence the term reactive). In its simplest form, a TR program is described by a list of condition-action rules as the following:\nc1 \u2192 a1 c2 \u2192 a2 \u00b7 \u00b7 \u00b7\ncm \u2192 am\nwhere the ci are conditions and ai are actions. The condition-action rules list is scanned from the top until it finds a condition that holds, then the corresponding action is executed. In a TR program, actions are usually durative rather than discrete. A durative action is one that continues indefinitely in time (e.g. the action move forwards is a durative action, whereas the action take one step is discrete). In a TR program, a durative action is executed as long as its corresponding condition remains the one with the highest priority among the ones that hold. When the highest priority condition that holds changes, the action executed changes accordingly. Thus, the conditions must be evaluated continuously so that the action associated with the current highest priority condition that holds, is always the one being executed. A running action terminates when its corresponding condition ceases to hold or when another condition with higher priority takes precedence. Figure 2.16 shows an example of a TR program for navigating in a obstacle free environment.\nTR programs have been extended in several directions, including integrating TR programs with automatic planning and machine learning [2, 42], removing redundant parts of a TR program [28], and using TR programs to play robot soccer [14].\n2.4 Decision Trees 35"}, {"heading": "2.3.1 Advantages and disadvantages", "text": "The main advantages of a TR program are:\n\u2022 Reactive execution: TR programs enable reactive executions by continually monitoring the conditions and aborting actions when needed. \u2022 Intuitive structure: The list of condition-action rules is intuitive to design for small problems.\nThe main disadvantages of a TR program are:\n\u2022 Maintainability: Due to its structure (a long list of rules), adding or removing condition-action rules is prone to cause errors when a TR program has to encode a complex system. In those cases, a TR program takes the shape of a long list. \u2022 Failure handling: To enable failure handling, a TR program needs to have a condition that checks if an action fails.\n2.3.2 How BTs Generalize Teleo-Reactive Programs\nThe core idea of continuously checking conditions and applying the corresponding rules can be captured using a Fallback node and pairs of conditions and actions. Thus, a general TR program can be represented in the BT of Fig. 2.17. A more formal argument using a state space representation of BTs will be given in Section 5.4."}, {"heading": "2.4 Decision Trees", "text": "A Decision Tree (DT) is a directed tree that represents a list of nested if-then clauses used to derive decisions [37]. Leaf nodes describe decisions, conclusions, or actions\n36 2 How Behavior Trees Generalize and Relate to Earlier Ideas\nto be carried out, whereas non-leaf nodes describe predicates to be evaluated. Figure 2.18 shows a DT where according to some conditions, a robot will decide what to do."}, {"heading": "2.4.1 Advantages and disadvantages", "text": "The main advantages of a DT are:\n\u2022 Modularity: The DT structure is modular, in the sense that a sub-DT can be developed independently from the rest of the DT, and added where suitable. \u2022 Hierarchy: DT\u2019s structure is hierarchical, in the sense that predicates are evaluated in a top-down fashion. \u2022 Intuitive structure: It is straightforward to design and understand DTs. The main disadvantages of a DT are:\n\u2022 No information flow out from the nodes, giving an absence of failure handling \u2022 Repetitions: To describe a reactive behavior, a given predicate must be reevalu-\nated at different depths of the tree resulting in a DT with many repetitions. \u2022 Maintainability: Due to repetitions, if the number of outgoing arcs from a predi-\ncate should change, this will affect the entire tree where such predicates appears."}, {"heading": "2.4.2 How BTs Generalize Decision Trees", "text": "A general DT can be converted into a BT using the mapping shown in Fig. 2.19. By converting the Predicate to a Condition, letting the leaves be actions always returning running, we can map each decision node of the DT to a small BT. Applying the mapping to the DT of Fig. 2.18 we get the BT of Fig. 2.20. A more formal argument using a state space representation of BTs will be given in Section 5.1. Note that this structure requires actions always returning running, reflecting the drawback of DTs that no information flows out of the actions\n38 2 How Behavior Trees Generalize and Relate to Earlier Ideas"}, {"heading": "2.5 Advantages and Disadvantages of Behavior Trees", "text": "Having looked at how BTs relate to a set of existing control architectures we will now take a step back and list a number of advantages and disadvantages of BTs."}, {"heading": "2.5.1 Advantages", "text": "As described in Section 1.2 many advantages stem from BTs being both modular and reactive. Below we list a set of advantages of BTs.\nModular: By modular, we mean the degree to which a system\u2019s components may be separated into building blocks, and recombined [13]. A modular system can be designed, implemented, tested and reused one module at a time. The benefits of modularity thus increases, the more complex a system is, by enabling a divide and conquer approach when designing, implementing and testing. BTs are modular, since each subtree of a BT can be seen as a module in the above sense, with a standard interface given by the return statuses. Thus, BTs are modular on all scales ranging from the topmost subtrees to all the leaves of the tree. Hierarchical organization: If a control architecture contains several levels of decision making it is denoted hierarchical. The possibility of designing and analyzing structures on different hierarchical levels is important for both humans and machines, as it enables e.g., iterative refinement and extensions of plan, see Section 3.5. BTs are hierarchical, since each level of a BT automatically defines a level in the hierarchy. Reusable code: Having reusable code is very important in any large, complex, long-term project. The ability to reuse designs relies in an essential way on the ability to build larger things from smaller parts, and on the independence of the input and output of those parts from their use in the project. To enable reuse of code, each module must interface the CA in a rigorous and well-defined fashion. BTs enable reusable code, since given the proper implementation, any subtree can be reused in multiple places of a BT. Furthermore, when writing the code of a leaf node, the developer needs to just take care of returning the correct return status which is universally predefined as either running, success, or failure. Unlike FSMs and HFSMs, where the outgoing transitions require knowledge about the next state, in BTs leaf nodes are developed disregarding which node is going to be executed next. Hence, the BT logic is independent from the leaf node executions and vice versa. Reactivity: By reactive we mean the ability to quickly and efficiently react to changes. For unstructured environments where outcomes of actions are not certain, and the state of the world is constantly changed by external actors, plans that\n2.5 Advantages and Disadvantages of Behavior Trees 39\nwere created offline and then executed in an open loop fashion are often likely to fail. BTs are reactive, since the continual generation of ticks and their tree traversal result in a closed loop execution. Actions are executed and aborted according to the ticks\u2019 traversal, which depends on the leaf nodes\u2019 return statuses. Leaf nodes are tightly connected with the environment (e.g. condition nodes evaluate the overall system properties and action nodes return failure/success if the action failed/succeeded). Thus, BTs are highly responsive to changes in the environment. Human readable: A readable structure is desirable for reducing the cost of development and debugging, especially when the task is human designed. The structure should remain readable even for large systems. Human readability requires a coherent and compact structure. BTs are human readable due to the tree structure and modularity. Expressive: A control architecture must be sufficiently expressive to encode a large variety of behaviors. BTs are at least as expressive as FSMs, see Section 2.1, the Subsumption Architecture, see Section 2.2, Teleo-reactive programs, see Section 2.3, and Decision Trees, see Section 2.4. Suitable for analysis: Safety critical robot applications often require an analysis of qualitative and quantitative system properties. These properties include: safety, in the sense of avoiding irreversible undesired behaviors; robustness, in the sense of a large domain of operation; efficiency, in the sense of time to completion; reliability, in the sense of success probability; and composability, in the sense on analyzing whether properties are preserved over compositions of sub-tasks. BTs have tools available to evaluate such system properties, see Chapters 4 and 5 below. Suitable for automatic synthesis: In some problem instances, it is preferable that the action ordering of a task, or a policy, is automatically synthesized using taskplanning or machine learning techniques. The CA can influence the efficiency of such synthesis techniques (e.g. a FSM with a large number of transitions can drastically deteriorate the speed of an algorithm that has to consider all the possible paths in the FSMs). BTs are suitable for automatic synthesis in terms of both planning, see Section 3.5 and learning, see [cite Learning papers].\nTo illustrate the advantages listed above, we consider the following simple example.\nExample 2.1. A robot is tasked to find a ball, pick it up and place it into a bin. If the robot fails to complete the task, it should go to a safe position and wait for a human operator. After picking up the ball (Figure 2.21a), the robot moves towards the bin (Figure 2.21b). While moving towards the bin, an external entity takes the ball from the robot\u2019s gripper (Figure 2.21c) and immediately throws it in front of the robot, where it can be seen (Figure 2.21d). The robot aborts the execution of moving and it starts to approach the ball again.\n40 2 How Behavior Trees Generalize and Relate to Earlier Ideas\n2.5 A dvantages and D isadvantages ofB ehaviorTrees\n41\n42 2 How Behavior Trees Generalize and Relate to Earlier Ideas\nIn this example, the robot does not simply execute a pick-and-place task. It continually monitors the progress of the actions, stops whenever needed, skips planned actions, decides the actions to execute, and responds to exogenous events. In order to execute some actions, the robot might need to inject new actions into the plan (e.g. the robot might need to empty the bin before placing the ball). Hence the task requires a CA suitable for extensions. These extensions might be man made (e.g. the robot asks the operator to update the current action policy) requiring a CA to be human readable, or automated (e.g. using model-based reasoning) requiring a CA to be suitable for automatic synthesis. In either case, to be able to easily extend and modify the action policy, its representation must be modular. In addition, new actions may subsume existing ones whenever needed (e.g. empty the bin if it is full must be executed before place the ball). This requires a hierarchical representation of the policy. Moreover there might be multiple different ways of carrying out a task (e.g. picking the ball using the left hand or the right hand). The robot must be able to decide which option is the best, requiring the CA to be suitable for analysis. Finally, once the policy is designed, it is desirable that it can be reused in other contexts.\nMost used CAs do not show characteristics suitable for the properties described above. Take as an example a FSM modeling the behavior of the robot in Example 2.1, depicted in Figure 2.22. As it can be seen, even for this simple example the FSM gets fairly complex with many transitions."}, {"heading": "2.5.2 Disadvantages", "text": "In this section we describe some disadvantages of BTs experienced by different BT developers.\nThe BT engine can be complex to implement. The implementation of the BT engine can get complicated using single threaded sequential programming. To guarantee the full functionality of BTs, the tick\u2019s generation and traversal should be executed in parallel with the action execution. However the BT engine only needs to be implemented once, it can be reused, and several BT engines are available as off the shelf software libraries.1 Checking all the conditions can be expensive. A BT needs to check several conditions to implement the closed-loop task execution. In some applications this checking is expensive or not feasible. In those cases a closed-loop execution (using any CA) presents more costs than advantages. However it is still possible to design an open-loop task execution using BTs with memory nodes, see Section 1.3.2.\n1 C++ library: https://github.com/miccol/Behavior-Tree ROS library: http://wiki.ros.org/behavior_tree python library: https://github.com/futureneer/beetree\n2.5 Advantages and Disadvantages of Behavior Trees 43\nSometimes a feed-forward execution is just fine. In applications where the robot operates in a very structured environment, predictable in space and time, BTs do not have any advantages over simpler CAs. BTs are different from FSM. BTs, despite being easy to understand, require a new mindset when designing a task execution. The execution is not focused on states but on conditions and the execution is not event driven but tick driven. At least some of the design principles described in Chapter 3 needs to be learned and applied. BTs are less mature. Although there is software for developing BTs, it is still far behind the amount and maturity of the software available for e.g. FSMs.\nChapter 3 Design principles\nBTs are fairly easy to understand and use, but to make full use of their potential it can be good to be aware of a set of design principles that can be used in different situations. In this chapter we will describe these principles using a number of examples. First, in Section 3.1, we will describe the benefit of using explicit success conditions in sequences, then, in Section 3.2, we describe how the reactivity of a BT can be increased by creating implicit sequences, using fallback nodes. In Section 3.3, we show how BTs can also be designed in a way that is similar to Decision Trees. Then, in Section 3.4, we show how safety can be improved using sequences. Finally, in Section 3.7, we discuss the choice of granularity when designing a BT.\nNote that these design principles are applicable at any level of a BT and can be combined freely.\nThus the safety principle can be combined with an implicit sequence etc."}, {"heading": "3.1 Improving Readability using Explicit Success Conditions", "text": "One advantage of BTs is that the switching structure is clearly shown in the graphical representation of the tree. However, one detail that is not shown is the when the individual actions return success and failure.\n45\n46 3 Design principles\nConsider the sequence in Figure 3.1. One can assume that Unlock Door returns success when it has unlocked the door, but what if it is called when the door is already unlocked? Depending on the implementation it might either return success immediately, or actually try to unlock the door again, with the possibility of returning failure if the key cannot be turned further. A similar uncertainty holds regarding the implementation of Open Door (what if the door is already open?) and Pass through Door. To address this problem, and remove uncertainties regarding the implementation, explicit success conditions can be included in the BT.\nIn Figure 3.2, the BT from Figure 3.1 has been extended to include explicit success conditions. These conditions are added in a pair with the corresponding action using a Fallback node. Now, if the door is already unlocked and open, the two first conditions of Figure 3.2 will return Success, the third will return Failure, and the agent will proceed to execute the action Pass through Door."}, {"heading": "3.2 Improving Reactivity using Implicit Sequences", "text": "It turns out that we can improve the reactivity of the BT in Figure 3.2 even further, using the fact that BTs generalize the Teleo-reactive approach, see Section 2.3.2. Consider the case when the agent has already passed the door, but the door is closed behind it. The BT in Figure 3.2 would then proceed to unlock the door, open it, and then notice that it had already passed it and return success.\n3.4 Improving Safety using Sequences 47\nThe key observation needed to improve reactivity is to realize that the goal is to get through the door, and that the other actions are just means to get to that goal. In the BT in Figure 3.3 we have reversed the order of the actions in order the check the goal state first. We then changed fallbacks to sequences and vice versa, and finally changed the conditions. Now, instead of checking outcomes, or success conditions as we did in Figure 3.2, we check preconditions, conditions needed to execute the corresponding actions, in Figure 3.3. First the BT checks if the agent has passed the door, if so it returns success. If not, it proceeds to check if the door is open, and if so passes through it. If neither of the previous conditions are satisfied, it checks if the door is unlocked, and if so starts to open it. As a final check, if nothing else returns success, it checks if it has the key to the door. If it does, it tries to open it, if not it returns failure.\nThe use of implicit sequences is particularly important in cases where the agent needs to undo some of its own actions, such as closing a door after passing it. A systematic way of creating implicit sequences is to use back chaining, as described in Section 3.5."}, {"heading": "3.3 Handling Different Cases using a Decision Tree Structure", "text": "Sometimes, a reactive switching policy can be easily described in terms of a set of cases, much like a Decision Tree. Then, the fact that BTs generalize Decision Trees can be exploited, see Section 2.4.2.\nA simple Pac-Man example can be found in Figure 3.4. The cases are separated by the two conditions Ghost Close and Ghost Scared. If no ghost is close, Pac-Man continues to eat pills. If a ghost is close, the BT checks the second condition, Ghost Scared, which turns true if Pac-Man eats a Power Pill. If the ghost is scared, PacMan chases it, if not, Pac-Man avoids the Ghost."}, {"heading": "3.4 Improving Safety using Sequences", "text": "In some agents, in particular robots capable of performing irreversible actions such as damaging equipment, it is very important to be able to guarantee that some situations will never occur. These unwanted situations might be as simple as failing to reach the recharging station before running out of battery, or as serious as falling down a staircase and hurting someone.\nA sequence node can be used to guarantee safety, as shown in Fig. 3.5. Looking closer at the BT in Fig. 3.5 we see that it will probably lead to an unwanted chattering behavior. It will recharge until it reaches just over 20% and then start doing Main Task, but the stop as soon as the battery is back at 20%, and possibly end up\n48 3 Design principles\nchattering i.e. quickly switching between the two tasks. The solution is to make sure that once recharging, the robot waits until the battery is back at 100%. This can be achieved by the BT in Fig 3.6.\n3.5 Creating Deliberative BTs using Backchaining 49"}, {"heading": "3.5 Creating Deliberative BTs using Backchaining", "text": "BT can also be used to create deliberative agents, where the actions are carried out in order to reach a specific goal. We will use an example to see how this is done. Imagine we want the agent to end up inside a house. To make that goal explicit, we create the trivial BT in Figure 3.7, with just a single condition checking if the goal is achieved or not.\nNow imagine we have a set of small BTs such as the ones in Figs. 3.8 and 3.9, each on the format of the general Postcondition-Precondition-Action (PPA) BT in Figure 3.11.\nIf we have such a set, be can work our way backwards from the goal (backchaining) by replacing preconditions with PPAs having the corresponding postcondition. Thus replacing the single condition in Figure 3.7 with the PPA of Figure 3.8 we get Figure 3.8. More interestingly, if we replace the precondition Door is Open in Figure 3.8 with the PPA of Figure 3.9 we get the BT of Figure 3.10\nThus we can iteratively build a deliberative BT by applying Algorithm 4. Looking at the BT in Figure 3.10 we note that it first checks if the agent Is Inside House, it so it returns Success. If not it checks if Door is Open, and if it is, it proceeds to Go Inside. If not it checks if Door Unlocked and correspondingly executes Open Door. Else it checks if Door is Weak, and it Has Crowbar and proceeds to Brake Door Open if that is the case. Else it returns Failure. If an action is executed it might either succeed, which will result in a new condition being satisfied and another action being executed until the task is finished, or it might fail. If Go Inside fails, the\n50 3 Design principles\nwhole BT returns failure, but if Open Door failes, the conditions Door is Weak and Has Crowbar are checked.\nIn general, we let the PPA have the form of Figure 3.11, with one postcondition C that can be achieved by either one of set of actions Ai, each of these action are combined in a sequence with its corresponding list of preconditions Ci j, and these\n3.6 Creating Un-Reactive BTs using Memory Nodes 51\naction precondition sequences are fallbacks for achieving the same objective. We see that from an efficiency point of view it makes sense to put actions that are most likely to succeed first (to avoid unnecessary failures) and check preconditions that are most likely to fail first (to quickly move on to the next fallback option)."}, {"heading": "3.6 Creating Un-Reactive BTs using Memory Nodes", "text": "As mentioned is Section 1.3.2, sometimes a child, once executed, does not need to be re-executed for the whole execution of a task. Control flow nodes with memory are used to simplify the design of a BT avoiding the unwanted re-execution of some nodes. The use of nodes with memory is advised exclusively for those cases where there is no unexpected event that will undo the execution of the sub-tree in a composition with memory, as in Example 3.1 below.\nExample 3.1 (Nodes with Memory). Consider the behavior of an industrial manipulator in a production line. That has to pick, move, and place objects. The robot\u2019s actions are carried out in a fixed workspace, with high precision. Human operators make sure that nothing on the line changes. If they need a change in the line, the software is manually updated accordingly. In this example the robot operates in a structured environment that is fully predictable in space and time. In this case we can disregard any unexpected change letting us describing the desired behavior by a sequence with memory of pick and place as in Figure 3.12. In this scenario, after picking we can be sure that the object does not slips out of the robot\u2019s grippers. Hence while the robot is moving the object, the BT does not need to check if the object is still picked.\n52 3 Design principles"}, {"heading": "3.7 Choosing the Proper Granularity of a BT", "text": "In any modular design, the choice of the granularity of the modules needs to be decided on. In a BTs framework, this is translated into the choice of what to represent as a leaf node (single action or condition) and what to represent as a BT. In BTs, in general, there are two reasons behind encoding a behavior inside a leaf node:\n\u2022 Module to be re-used: It is advisable to aggregate a behavior in a leaf node whenever that behavior has to he reused in different parts of the tree or in different projects. As in Example 3.2 below. \u2022 Modules may have to be re-executed due to unexpected changes in the environment: It is advisable to separate a behavior in different sub-behaviors whenever the execution of a sub-behavior might be undone by unexpected uncontrollable changes (e.g. environmental changes) as in Example 3.3 below. In that case, we do not separate the different steps of assemble object as we do not need to account for any affecting unexpected changes during the execution of the different steps.\nExample 3.2 (Re-use). Consider the BT in Figure 3.13 describing the behavior of a humanoid robot. The actions sit and stand are re-used in different parts of the tree.\nExample 3.3 (Re-execution needed). Consider an assembly task for an industrial robot that coexists in a semistructured environment with human workers. The tasks to perform are pick object, assemble object, and place object. A closed-loop execution of this task can be represented with the BT in Figure 3.14. Note that the BT can reactively handle the unexpected changes due to the human worker in the line such as: the worker picks up the object that the robot is trying to reach, the object slips out from the robots grippers while the robot is placing it, etc. If we had instead chosen to aggregrate the actions pick object, assemble object, and place object into a single action we would lose reactiveness when, for example, the robot has to re-pick and assembled object slept out from the robot\u2019s grippers. With a single action the robot will try to re-assemble an assembled object.\nThe advice above should give the designer an idea on how to reach a balanced BT that is neither too sparse nor too compact. A sparse BT might be unreasonably\n3.7 Choosing the Proper Granularity of a BT 53\ncomplex. While a compact BT may risk being not sufficiently reactive, by executing too many operations in a feed-forward fashion, losing one main advantage of BTs.\nChapter 4 Analysis of Efficiency, Safety, and Robustness\nAutonomous agents will need to be efficient, robust, and reliable in order to be used on a large scale. In this chapter, we present a mathematical framework for analyzing the these properties for a BT (4.1). The analysis includes efficiency (4.2), in terms of execution time\u2019s bound; robustness (4.2), in terms of capability to operate in large domains; and safety (4.3), in terms of avoiding some particular parts of the state space. Some of the results of this chapter were previously published in the journal paper [9]."}, {"heading": "4.1 Statespace Formulation of BTs", "text": "In this section we present a new formulation of BTs. The new formulation is more formal, and will allow us to analyze how properties are preserved over modular compositions of BTs. In the functional version, the tick is replaced by a recursive function call that includes both the return status, the system dynamics and the system state.\nDefinition 4.1 (Behavior Tree). A BT is a three-tuple\nTi = { fi,ri,\u2206 t}, (4.1)\nwhere i\u2208N is the index of the tree, fi :Rn\u2192Rn is the right hand side of an ordinary difference equation, \u2206 t is a time step and ri : Rn\u2192 {R,S ,F} is the return status that can be equal to either Running (R), Success (S ), or Failure (F ). Let the Running/Activation region (Ri), Success region (Si) and Failure region (Fi) correspond to a partitioning of the state space, defined as follows:\nRi = {x : ri(x) = R} (4.2) Si = {x : ri(x) = S } (4.3) Fi = {x : ri(x) = F}. (4.4)\n55\n56 4 Analysis of Efficiency, Safety, and Robustness\nFinally, let xk = x(tk) be the system state at time tk, then the execution of a BT Ti is a standard ordinary difference equation\nxk+1 = fi(xk), (4.5) tk+1 = tk +\u2206 t. (4.6)\nThe return status ri will be used when combining BTs recursively, as explained below.\nAssumption 1 From now on we will assume that all BTs evolve in the same continuous space Rn using the same time step \u2206 t.\nRemark 4.1. It is often the case, that different BTs, controlling different vehicle subsystems evolving in different state spaces, need to be combined into a single BT. Such cases can be accommodated in the assumption above by letting all systems evolve in a larger state space, that is the Cartesian product of the smaller state spaces.\nDefinition 4.2 (Sequence compositions of BTs). Two or more BTs can be composed into a more complex BT using a Sequence operator,\nT0 = Sequence(T1,T2).\nThen r0, f0 are defined as follows\nIf xk \u2208 S1 (4.7) r0(xk) = r2(xk) (4.8) f0(xk) = f2(xk) (4.9)\nelse r0(xk) = r1(xk) (4.10) f0(xk) = f1(xk). (4.11)\nT1 and T2 are called children of T0. Note that when executing the new BT, T0 first keeps executing its first child T1 as long as it returns Running or Failure. The second child is executed only when the first returns Success, and T0 returns Success only when all children have succeeded, hence the name Sequence, just as the classical definition of Sequences in Algorithm 1 of Section 1.3. For notational convenience, we write\nSequence(T1,Sequence(T2,T3)) = Sequence(T1,T2,T3), (4.12)\nand similarly for arbitrarily long compositions.\nDefinition 4.3 (Fallback compositions of BTs). Two or more BTs can be composed into a more complex BT using a Fallback operator,\n4.1 Statespace Formulation of BTs 57\nT0 = Fallback(T1,T2).\nThen r0, f0 are defined as follows\nIf xk \u2208 F1 (4.13) r0(xk) = r2(xk) (4.14) f0(xk) = f2(xk) (4.15)\nelse r0(xk) = r1(xk) (4.16) f0(xk) = f1(xk). (4.17)\nNote that when executing the new BT, T0 first keeps executing its first child T1 as long as it returns Running or Success. The second child is executed only when the first returns Failure, and T0 returns Failure only when all children have tried, but failed, hence the name Fallback, just as the classical definition of Fallbacks in Algorithm 2 of Section 1.3.\nFor notational convenience, we write\nFallback(T1,Fallback(T2,T3)) = Fallback(T1,T2,T3), (4.18)\nand similarly for arbitrarily long compositions. Parallel compositions only make sense if the BTs to be composed control separate parts of the state space, thus we make the following assumption.\nAssumption 2 Whenever two BTs T1,T2 are composed in parallel, we assume that there is a partition of the state space x = (x1,x2) such that f1(x) = ( f11(x), f12(x)) implies f12(x) = x and f2(x) = ( f21(x), f22(x)) implies f21(x) = x (i.e. the two BTs control different parts of the system).\nDefinition 4.4 (Parallel compositions of BTs). Two or more BTs can be composed into a more complex BT using a Parallel operator,\nT0 = Parallel(T1,T2).\nLet x = (x1,x2) be the partitioning of the state space described in Assumption 2, then f0(x) = ( f11(x), f22(x)) and r0 is defined as follows\n58 4 Analysis of Efficiency, Safety, and Robustness\nIf M = 1 r0(x) = S If r1(x) = S \u2228 r2(x) = S (4.19) r0(x) = F If r1(x) = F \u2227 r2(x) = F (4.20) r0(x) = R else (4.21)\nIf M = 2 r0(x) = S If r1(x) = S \u2227 r2(x) = S (4.22) r0(x) = F If r1(x) = F \u2228 r2(x) = F (4.23) r0(x) = R else (4.24)"}, {"heading": "4.2 Efficiency and Robustness", "text": "In this section we will show how some aspects of time efficiency and robustness carry across modular compositions of BTs. This result will then enable us to conclude, that if two BTs are efficient, then their composition will also be efficient, if the right conditions are satisfied. We also show how the Fallback composition can be used to increase the region of attraction of a BT, thereby making it more robust to uncertainties in the initial configuration.\nNote that, as in [6], by robustness we mean large regions of attraction. We do not investigate e.g. disturbance rejection, or other forms of robustness.\nMany control problems, in particular in robotics, can be formulated in terms of achieving a given goal configuration in a way that is time efficient and robust with respect to the initial configuration. Since all BTs return either Success, Failure or Running, the definitions below will include a finite time, at which Success must be achieved.\nIn order to formalize the discussion above, we say that efficiency can be measured by the size of a time bound \u03c4 in Definition 4.5 and robustness can be measured by the size of the region of attraction R\u2032 in the same definition.\nDefinition 4.5 (Finite Time Successful). A BT is Finite Time Successful (FTS) with region of attraction R\u2032, if for all starting points x(0) \u2208 R\u2032 \u2282 R, there is a time \u03c4 , and a time \u03c4 \u2032(x(0)) such that \u03c4 \u2032(x) \u2264 \u03c4 for all starting points, and x(t) \u2208 R\u2032 for all t \u2208 [0,\u03c4 \u2032) and x(t) \u2208 S for t = \u03c4 \u2032) As noted in the following Lemma, exponential stability implies FTS, given the right choices of the sets S,F,R.\nLemma 4.1 (Exponential stability and FTS). A BT for which xs is a globally exponentially stable equilibrium of the execution (4.5), and S \u2283 {x : ||x\u2212 xs|| \u2264 \u03b5}, \u03b5 > 0, F = /0, R = Rn \\S, is FTS. Proof. Global exponential stability implies that there exists a > 0 such that ||x(k)\u2212 xs|| \u2264 e\u2212ak for all k. Then, for each \u03b5 there is a time \u03c4 such that ||x(k)\u2212xs|| \u2264 e\u2212a\u03c4 < \u03b5 , which implies that there is a \u03c4 \u2032 < \u03c4 such that x(\u03c4 \u2032) \u2208 S and the BT is FTS.\n4.2 Efficiency and Robustness 59\nWe are now ready to look at how these properties extend across compositions of BTs.\nLemma 4.2. (Robustness and Efficiency of Sequence Compositions) If T1,T2 are FTS, with S1 = R\u20322 \u222a S2, then T0 = Sequence(T1,T2) is FTS with \u03c40 = \u03c41 + \u03c42, R\u20320 = R \u2032 1\u222aR\u20322 and S0 = S1\u2229S2 = S2.\nProof. First we consider the case when x(0) \u2208 R\u20321. Then, as T1 is FTS, the state will reach S1 in a time k1 < \u03c41, without leaving R\u20321. Then T2 starts executing, and will keep the state inside S1, since S1 = R\u20322 \u222a S2. T2 will then bring the state into S2, in a time k2 < \u03c42, and T0 will return Success. Thus we have the combined time k1 + k2 < \u03c41 + \u03c41.\nIf x(0) \u2208 R\u20322, T1 immediately returns Success, and T2 starts executing as above.\nThe Lemma above is illustrated in Figure 4.2, and Example 4.1 below.\n60 4 Analysis of Efficiency, Safety, and Robustness\nExample 4.1. Consider the BT in Figure 4.1. If we know that Open Front Door is FTS and will finish in less than \u03c41 seconds, and that Pass through Door is FTS and will finish in less than \u03c42 seconds. Then, as long as S1 = R\u20322 \u222a S2, Lemma 4.2 states that the combined BT in Figure 4.1 is also FTS, with an upper bound on the execution time of \u03c41+\u03c42. Note that the condition S1 =R\u20322\u222aS2 implies that the action Pass through Door will not make the system leave S1, by e.g. accidentally colliding with the door and thereby closing it without having passed through it.\nThe result for Fallback compositions is related, but with a slightly different condition on Si and R\u2032j. Note that this is the theoretical underpinning of the design principle Implicit Sequences described in Section 3.2.\nLemma 4.3. (Robustness and Efficiency of Fallback Compositions) If T1,T2 are FTS, with S2 \u2282 R\u20321 and R1 = R1, then T0 = Fallback(T1,T2) is FTS with \u03c40 = \u03c41 + \u03c42, R\u20320 = R \u2032 1\u222aR\u20322 and S0 = S1. Proof. First we consider the case when x(0) \u2208 R\u20321. Then, as T1 is FTS, the state will reach S1 before k = \u03c41 < \u03c40, without leaving R\u20321. If x(0) \u2208 R\u20322 \\ R\u20321, T2 will execute, and the state will progress towards S2. But as S2 \u2282 R\u20321, x(k1) \u2208 R\u20321 at some time k1 < \u03c42. Then, we have the case above, reaching x(k2) \u2208 S1 in a total time of k2 < \u03c41 + k1 < \u03c41 + \u03c42.\nThe Lemma above is illustrated in Figure 4.3, and Example 4.2 below.\nRemark 4.2. As can be noted, the necessary conditions in Lemma 4.2, including S1 = R\u20322 \u222a S2 might be harder to satisfy than the conditions of Lemma 4.3, including S2 \u2282 R\u20321. Therefore, Lemma 4.3 is often preferable from a practical point of view, e.g. using implicit sequences as shown below.\n4.2 Efficiency and Robustness 61\nExample 4.2. This example will illustrate the design principle Implicit sequences, see Section 3.2. Consider the BT in Figure 4.4. During execution, if the door is closed, then Pass through Door will fail and Open Front Door will start to execute. Now, right before Open Front Door returns Success, the first action Pass through Door (with higher priority) will realize that the state of the world has now changed enough to enable a possible success and starts to execute, i.e. return Running instead of Failure. The combined action of this BT will thus make the robot open the door (if necessary) and then pass through if.\nThus, even though a Fallback composition is used, the result is sometimes a sequential execution of the children in reverse order (from right to left). Hence the name Implicit sequence.\nThe example above illustrates how we can increase the robustness of a BT. If we want to be able to handle more diverse situations, such as a closed door, we do not have to make the door passing action more complex, instead we combine it with another BT that can handle the situation and move the system into a part of the statespace that the first BT can handle. The sets S0,F0,R0 and f0 of the combined BT are shown in Figure 4.5, together with the vector field f0(x)\u2212x. As can be seen, the combined BT can now move a larger set of initial conditions to the desired region S0 = S1.\nLemma 4.4. (Robustness and Efficiency of Parallel Compositions) If T1,T2 are FTS, then T0 = Parallel(T1,T2) is FTS with\nIf M = 1 R\u20320 = {R\u20321\u222aR\u20322}\\{S1\u222aS2} (4.25) S0 = S1\u222aS2 (4.26) \u03c40 = min(\u03c41,\u03c42) (4.27)\nIf M = 2 R\u20320 = {R\u20321\u2229R\u20322}\\{S1\u2229S2} (4.28) S0 = S1\u2229S2 (4.29) \u03c40 = max(\u03c41,\u03c42) (4.30)\n62 4 Analysis of Efficiency, Safety, and Robustness\nProof. The parallel composition executes T1 and T2 independently. If M = 1 the parallel composition returns success if either T1 or T2 returns success, thus \u03c40 = min(\u03c41,\u03c42). It returns running if either T1 or T2 returns running and the other does not return success. If M = 2 the parallel composition returns success if and only if both T1 and T2 return success, thus \u03c40 = max(\u03c41,\u03c42). It returns running if either T1 or T2 returns running and the other does not return failure."}, {"heading": "4.3 Safety", "text": "In this section we will show how some aspects of safety carry across modular compositions of BTs. The results will enable us to design a BTs to handle safety guarantees and a BT to handle the task execution separately.\nIn order to formalize the discussion above, we say that safety can be measured by the ability to avoid a particular part of the statespace, that we for simplicity denote the Obstacle Region.\nDefinition 4.6 (Safe). A BT is Safe, with respect to the obstacle region O \u2282 Rn, and the initialization region I \u2282 R, if for all starting points x(0) \u2208 I, we have that x(t) 6\u2208 O, for all t \u2265 0.\nIn order to make statements about the safety of composite BTs we also need the following definition.\nDefinition 4.7 (Safeguarding). A BT is Safeguarding, with respect to the step length d, the obstacle region O \u2282 Rn, and the initialization region I \u2282 R, if it is\n4.3 Safety 63\nsafe, and FTS with region of attraction R\u2032 \u2283 I and a success region S, such that I surrounds S in the following sense:\n{x \u2208 X \u2282 Rn : inf s\u2208S ||x\u2212 s|| \u2264 d} \u2282 I, (4.31)\nwhere X is the reachable part of the state space Rn.\nThis implies that the system, under the control of another BT with maximal statespace steplength d, cannot leave S without entering I, and thus avoiding O, see Lemma 4.5 below.\nExample 4.3. To illustrate how safety can be improved using a Sequence composition, we consider the UAV control BT in Figure 4.6. The sets Si,Fi,Ri are shown in Figure 4.7. As T1 is Guarrantee altitude above 1000 ft, its failure region F1 is a small part of the state space (corresponding to a crash) surrounded by the running region R1 that is supposed to move the UAV away from the ground, guaranteeing a minimum altitude of 1000 ft. The success region S1 is large, every state sufficiently distant from F1. The BT that performs the mission, T2, has a smaller success region S2, surrounded by a very large running region R2, containing a small failure region F2. The function f0 is governed by Equations (4.9) and (4.9) and is depicted in form of the vector field ( f0(x)\u2212 x) in Figure 4.8.\nThe discussion above is formalized in Lemma 4.5 below.\nLemma 4.5 (Safety of Sequence Compositions). If T1 is safeguarding, with respect to the obstacle O1 initial region I1, and margin d, and T2 is an arbitrary BT with maxx ||x\u2212 f2(x)|| < d, then the composition T0 = Sequence(T1,T2) is Safe with respect to O1 and I1.\nProof. T1 is safeguarding, which implies that T1 is safe and thus any trajectory starting in I1 will stay out of O1 as long as T1 is executing. But if the trajectory reaches S1, T2 will execute until the trajectory leaves S1. We must now show that the trajectory cannot reach O1 without first entering I1. But any trajectory leaving S1 must immediately enter I1, as the first state outside S1 must lie in the set {x \u2208 Rn : infs\u2208S1 ||x\u2212 s|| \u2264 d} \u2282 I1 due to the fact that for T2, ||x(k)\u2212 x(k+ 1)|| = ||x(k)\u2212 f2(x(k))||< d.\n64 4 Analysis of Efficiency, Safety, and Robustness\nWe conclude this section with a discussion about undesired chattering in switching systems.\nThe issue of undesired chattering, i.e., switching back and fourth between different sub-controllers, is always an important concern when designing switched control systems, and BTs are no exception. As is suggested by the right part of Figure 4.8, chattering can be a problem when vector fields meet at a switching surface.\nAlthough the efficiency of some compositions can be computed using Lemma 4.2 and 4.3 above, chattering can significantly reduce the efficiency of others. Inspired by [11] the following result can give an indication of when chattering is to be expected.\nLet Ri and R j be the running region of Ti and T j respectively. We want to study the behavior of the system when a composition of Ti and T j is applied. In some cases the execution of a BT will lead to the running region of the other BT and viceversa. Then, both BTs are alternatively executed and the state trajectory chatters\n4.3 Safety 65\non the boundary between Ri and R j. We formalize this discussion in the following lemma.\nLemma 4.6. Given a composition T0 = Sequence(T1,T2), where fi depend on \u2206 t such that || fi(x)\u2212 x|| \u2192 0 when \u2206 t \u2192 0. Let s : Rn \u2192 R be such that s(x) = 0 if x \u2208 \u03b4S1\u2229R2, s(x)< 0 if x \u2208 interior(S1)\u2229R2, s(x)> 0 if x \u2208 interior(Rn \\S1)\u2229R2, and let\n\u03bbi(x) = ( \u2202 s \u2202x )T ( fi(x)\u2212 x).\nThen, x \u2208 \u03b4S1 is chatter free, i.e., avoids switching between T1 and T2 at every timestep, for small enough \u2206 t, if \u03bb1(x)< 0 or \u03bb2(x)> 0.\nProof. When the condition holds, the vector field is pointing outwards on at least one side of the switching boundary.\nNote that this condition is not satisfied on the right hand side of Figure 4.8. This concludes our analysis of BT compositions.\n66 4 Analysis of Efficiency, Safety, and Robustness"}, {"heading": "4.4 Examples", "text": "In this section we show some BTs of example and we analyze their properties. Section 4.4.1 Illustrates how to analyze robustness and efficiency of a robot executing a generic task. Section 4.3 illustrates to compute safety using the functional representation of Section 4.1. Section 6.4 illustrate how to compute the performance estimate of a given BT. Finally, Section 4.4.3 illustrate the properties above of a complex BT .\nAll BTs were implemented using the ROS BT package.1 A video showing the executions of the BTs used in Sections 4.4.2-4.4.1 is publicly available. 2"}, {"heading": "4.4.1 Robustness and Efficiency", "text": "To illustrate Lemma 4.3 we look at the BT of Figure 4.9 controlling a NAO robot. The BT has three sub-trees Walk Home, which is first tried, if that fails (the robot cannot walk if it is not standing up) it tries the sub-tree Sit to Stand, and if that fails, it tries Lie down to Sit Up. Thus, each fallback action brings the system into the running region of the action to its left, e.g., the result of Sit to Stand is to enable the execution of Walk Home.\nExample 4.4. Let xk = (x1k,x2k) \u2208R2, where x1k \u2208 [0,0.5] is the horizontal position of the robot head and x2k \u2208 [0,0.55] is vertical position (height above the floor) of the robot head. The objective of the robot is to get to the destination at (0,0.48).\nFirst we describe the sets Si,Fi,Ri and the corresponding vector fields of the functional representation. Then we apply Lemma 4.3 to see that the combination does indeed improve robustness. For this example \u2206 t = 1s.\nFor Walk Home, T4, we have that\n1 library available at http://wiki.ros.org/behavior_tree. 2 https://youtu.be/fH7jx4ZsTG8\n4.4 Examples 67\nS4 = {x : x1 \u2264 0} (4.32) R4 = {x : x1 6= 0,x2 \u2265 0.48} (4.33) F4 = {x : x1 6= 0,x2 < 0.48} (4.34)\nf4(x) = (\nx1\u22120.1 x2\n) (4.35)\nthat is, it runs as long as the vertical position of the robot head, x2, is at least 0.48m above the floor, and moves towards the origin with a speed of 0.1m/s. If the robot is not standing up x2 < 0.48m it returns Failure. A phase portrait of f4(x)\u2212x is shown in Figure 4.10. Note that T4 is FTS with the completion time bound \u03c44 = 0.5/0.1 = 10 and region of attraction R\u20324 = R4.\nFor Sit to Stand, T5, we have that\nS5 = {x : 0.48\u2264 x2} (4.36) R5 = {x : 0.3\u2264 x2 < 0.48} (4.37) F5 = {x : x2 < 0.3} (4.38)\nf5(x) = (\nx1 x2 +0.05\n) (4.39)\nthat is, it runs as long as the vertical position of the robot head, x2, is in between 0.3m and 0.48m above the floor. If 0.48\u2264 x2 the robot is standing up, and it returns Success. If x2 \u2264 0.3 the robot is lying down, and it returns Failure. A phase portrait of f5(x)\u2212 x is shown in Figure 4.11. Note that T5 is FTS with the completion time bound \u03c45 = ceil(0.18/0.05) = ceil(3.6) = 4 and region of attraction R\u20325 = R5\n68 4 Analysis of Efficiency, Safety, and Robustness\nFor Lie down to Sit Up, T6, we have that\nS6 = {x : 0.3\u2264 x2} (4.40) R6 = {x : 0\u2264 x2 < 0.3} (4.41) F6 = /0 (4.42)\nf6(x) = (\nx1 x2 +0.03\n) (4.43)\nthat is, it runs as long as the vertical position of the robot head, x2, is below 0.3m above the floor. If 0.3 \u2264 x2 the robot is sitting up (or standing up), and it returns Success. If x2 < 0.3 the robot is lying down, and it returns Running. A phase portrait of f6(x)\u2212 x is shown in Figure 4.12. Note that T6 is FTS with the completion time bound \u03c46 = 0.3/0.03 = 10 and region of attraction R\u20326 = R6\nInformally, we can look at the phase portrait in Figure 4.13 to get a feeling for what is going on. As can be seen the fallbacks make sure that the robot gets on its feet and walks back, independently of where it started in {x : 0 < x1 \u2264 0.5,0\u2264 x2 \u2264 0.55}.\nFormally, we can use Lemma 4.3 to compute robustness in terms of the region of attraction R\u20323, and efficiency in terms of bounds on completion time \u03c43. The results are described in the following Lemma.\nLemma 4.7. Given T4,T5,T6 defined in Equations (4.32)-(4.43). The combined BT T3 = Fallback(T4,T5,T6) is FTS, with region of attraction R\u20323 = {x : 0 < x1 \u2264 0.5,0\u2264 x2 \u2264 0.55}, completion time bound \u03c43 = 24.\nProof. We note that T4,T5,T6 are FTS with \u03c44 = 10, \u03c45 = 4, \u03c46 = 10 and regions of attractions equal to the running regions R\u2032i = Ri. Thus we have that S6 \u2282 R5 = R\u20325 and\n4.4 Examples 69\nS5 \u2282 R4 = R\u20324. Applying Lemma 4.3 twice now gives the desired results, R\u20323 = R\u20324\u222a R\u20325\u222aR\u20326 = {x : 0\u2264 x1\u2264 0.5,0\u2264 x2\u2264 0.55} and \u03c43 = \u03c44+\u03c45+\u03c46 = 10+4+10= 24."}, {"heading": "4.4.2 Safety", "text": "To illustrate Lemma 4.5 we choose the BT of Figure 4.14. The idea is that the first sub-tree in the sequence (named Guarantee Power Supply) is to guarantee that the\n70 4 Analysis of Efficiency, Safety, and Robustness\ncombination does not run out of power, under very general assumptions about what is going on in the second BT.\nFirst we describe the sets Si,Fi,Ri and the corresponding vector fields of the functional representation. Then we apply Lemma 4.5 to see that the combination does indeed guarantee against running out of batteries.\nExample 4.5. Let T1 be Guarantee Power Supply and T2 be Do other tasks. Let furthermore xk =(x1k,x2k)\u2208R2, where x1k \u2208 [0,100] is the distance from the current position to the recharging station and x2k \u2208 [0,100] is the battery level. For this example \u2206 t = 10s.\nFor Guarantee Power Supply, T1, we have that\nS1 = {x : 100\u2264 x2 or (0.1\u2264 x1,20 < x2)} (4.44) R1 = {x : x2 \u2264 20 or (x2 < 100 and x1 < 0.1)} (4.45) F1 = /0 (4.46)\nf1(x) = (\nx1 x2 +1\n) if x1 < 0.1,x2 < 100 (4.47)\n=\n( x1\u22121\nx2\u22120.1\n) else (4.48)\nthat is, when running, the robot moves to x1 < 0.1 and recharges. While moving, the battery level decreases and while charging the battery level increases. If at the recharge position, it returns Success only after reaching x2 \u2265 100. Outside of the recharge area, it returns Success as long as the battery level is above 20. A phase portrait of f1(x)\u2212 x is shown in Figure 4.15.\nFor Do Other Task, T2, we have that\n4.4 Examples 71\nS2 = /0 (4.49)\nR2 = R2 (4.50) F2 = /0 (4.51)\nf2(x) = (\nx1 +(50\u2212 x1)/50 x2\u22120.1\n) (4.52)\nthat is, when running, the robot moves towards x1 = 50 and does some important task, while the battery level keeps on decreasing. A phase portrait of f2(x)\u2212 x is shown in Figure 4.15.\n72 4 Analysis of Efficiency, Safety, and Robustness\nGiven T1 and T2, the composition T0=Sequence(T1,T2) is created to improve the safety of T2, as described below.\nInformally, we can look at the phase portrait in Figure 4.17 to get a feeling for what is going on. The obstacle to be avoided is the Empty Battery state O= {x : x2 = 0}, and T0 makes sure that this state is never reached, since the Guarantee Power Supply action starts executing as soon as Do Other Task brings the battery level below 20%. The remaining battery level is also enough for the robot to move back to the recharging station, given that the robot position is limited by the reachable space, i.e., x1k \u2208 [0,100].\nFormally, we state the following Lemma\nLemma 4.8. Let the obstacle region be O= {x : x2 = 0} and the initialization region be I = {x : x1 \u2208 [0,100],x2 \u2265 15}.\nFurthermore, let T1 be given by (4.44)-(4.48) and T2 be an arbitrary BT satisfying maxx ||x\u2212 f2(x)||< d = 5, then T0=Sequence(T1,T2) is Safe with respect to I and O, i.e. if x(0) \u2208 I, then x(t) 6\u2208 O, for all t > 0.\nProof. First we see that T1 is Safe with respect to O and I. Then we notice that T1 is Safeguarding with margin d = 10 for the reachable set X = {x : x1 \u2208 [0,100],x2 \u2208 [0,100]}. Finally we conclude that T0 is Safe, according to Lemma 4.5.\nNote that if we did not constraint the robot to move in some reachable set X = {x : x1 \u2208 [0,100],x2 \u2208 [0,100]}, it would be able to move so far away from the recharging station that the battery would not be sufficient to bring it back again before reaching x2 = 0.\n4.4 Examples 73"}, {"heading": "4.4.3 Complex BT", "text": "Below we will use a larger BT to illustrate modularity, as well as the applicability of the proposed analysis tools to more complex problems.\nExample 4.6. The BT in Figure 4.18 is designed for controlling a NAO humanoid robot in an interactive capability demo, and includes the BTs of Figures 4.14 and 4.9 as subtrees, as discussed below.\nThe top left part of the tree includes some exception handling, in terms of battery management, and backing up and complaining in case the toe bumpers are pressed. The top right part of the tree is a parallel node, listening for new user commands, along with a request for such commands if none are given and an execution of the corresponding activities if a command has been received.\nThe subtree Perform Activities is composed of checking of what activity to do, and execution of the corresponding command. Since the activities are mutually exclusive, we let the Current Activity hold only the latest command and no ambiguities of control commands will occur.\nThe subtree Play Ball Game runs the ball tracker, in parallel with moving closer to the ball, grasping it, and throwing it.\n74 4 Analysis of Efficiency, Safety, and Robustness\nAs can be seen, the design is quite modular. A HDS implementation of the same functionality would need an extensive amount of transition arrows going in between the different actions.\nWe will now apply the analysis tools of the paper to the example, initially assuming that all atomic actions are FTS, as described in Definition 4.5.\nComparing Figures 4.14 and 4.18 we see that they are identical, if we let Do Other Task correspond to the whole right part of the larger BT. Thus, according to Lemma 4.8, the complete BT is safe, i.e. it will not run out of batteries, as long as the reachable state space is bounded by 100 distance units from the recharging station and the time steps are small enough so that maxx ||x\u2212 f2(x)|| < d = 5, i.e. the battery does not decrease more than 5% in a single time step.\nThe design of the right subtree in Play Ball Game is made to satisfy Lemma 4.2, with the condition S1 = R\u20322 \u222a S2. Let T1 = Fallback(Ball Close?, Approach Ball), T2 = Fallback(Ball Grasped?, Grasp Ball), T3 = Throw Ball. Note that the use of condition action pairs makes the success regions explicit. Thus S1 = R\u20322 \u222a S2, i.e. Ball Close is designed to describe the Region of Attraction of Grasp Ball, and S2 = R\u20323\u222aS3, i.e. Ball Grasped is designed to describe the Region of Attraction of Throw Ball. Finally, applying Lemma 4.2 twice we conclude that the right part of Play Ball Game is FTS with completion time bound \u03c41 + \u03c42 + \u03c43, region of attraction R\u20321\u222aR\u20322\u222aR\u20323 and success region S1\u2229S2\u2229S3.\nThe parallel composition at the top of Play Ball Game combines Ball Tracker which always returns Running, with the subtree discussed above. The parallel node has M = 1, i.e. it only needs the Success of one child to return Success. Thus, it is clear from Definition 4.4 that the whole BT Play Ball Game has the same properties regarding FTS as the right subtree.\nFinally, we note that Play Ball Game fails if the robot is not standing up. Therefore, we improve the robustness of that subtree in a way similar to Example 4.4 in Figure 4.9. Thus we create the composition Fallback(Play Ball Game, T5, T6), with T5 = Sit to Stand, T6 = Lie Down to Sit Up.\n4.4 Examples 75\nAssuming that that high dimensional dynamics of Play Ball Game is somehow captured in the x1 dimension we can apply an argument similar to Lemma 4.7 to conclude that the combined BT is indeed also FTS with completion time bound \u03c41 +\u03c42 +\u03c43 +\u03c45 +\u03c46, region of attraction R\u20321\u222aR\u20322\u222aR\u20323\u222aR\u20325\u222aR\u20326 and success region S1\u2229S2\u2229S3.\nThe rest of the BT concerns user interaction and is thus not suitable for doing performance analysis.\nNote that the assumption on all atomic actions being FTS is fairly strong. For example, the NAO grasping capabilities are somewhat unreliable. A deterministic analysis such as this one is still useful for making good design choices, but in order to capture the stochastic properties of a BT, we need the tools of Chapter 6.\nBut first we will use the tools developed in this chapter to formally investigate how BTs relate to other control architectures.\nChapter 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas\nIn this chapter, we will formalize the arguments of Chapter 2, using the tools developed in Chapter 4. In particular, we prove that BTs generalize Decision Trees (5.1), the Subsumptions Architecture (5.2), Sequential Behavior Compositions (5.3) and the Teleo-Reactive Approach (5.4). Some of the results of this chapter were previously published in the journal paper [9]."}, {"heading": "5.1 How BTs Generalize Decision Trees", "text": "Consider the Decision Tree of Figure 5.1, the robot has to decide whether to perform a given task or recharge its batteries. This decision is taken based upon the urgency of the task, and the current battery level. The following Lemma shows how to create an equivalent BT from a given Decision Tree.\nLemma 5.1. Given a Decision Tree as follows\n77\n78 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas\nDTi = { DTi1 if predicate Pi is true DTi2 if predicate Pi is false\n(5.1)\nwhere DTi1, DTi2 are either atomic actions, or sub DTs with identical structure, we can create an equivalent BT by setting\nTi = Fallback(Sequence(Pi,Ti1),Ti2) (5.2)\nfor non-atomic actions, Ti = DTi for atomic actions and requiring all actions to return Running all the time.\nThe original Decision Tree and the new BT are equivalent in the sense that the same values for Pi will always lead to the same atomic action being executed. The lemma is illustrated in Figure 5.2.\nProof. The BT equivalent of the Decision Tree is given by\nTi = Fallback(Sequence(Pi,Ti1),Ti2)\nFor the atomic actions always returning running we have ri = R, for the actions being predicates we have that ri = Pi. This, together with Definitions 4.2-4.3 gives that\nfi(x) = { fi1 if predicate Pi is true fi2 if predicate Pi is false\n(5.3)\nwhich is equivalent to (5.1).\nInformally, first we note that by requiring all actions to return Running, we basically disable the feedback functionality that is built into the BT. Instead whatever action that is ticked will be the one that executes, just as the Decision Tree. Second the result is a direct consequence of the fact that the predicates of the Decision Trees are essentially \u2018If ... then ... else ...\u2019 statements, that can be captured by BTs as shown in Figure 5.2.\nNote that this observation opens possibilities of using the extensive literature on learning Decision Trees from human operators, see e.g. [37], to create BTs. These learned BTs can then be extended with safety or robustness features, as described in Section 4.2.\n5.2 How BTs Generalize the Subsumption Architecture 79\nWe finish this section with an example of how BTs generalize Decision Trees. Consider the Decision Tree in Figure 5.1. Applying Lemma 5.1 we get the equivalent BT of Figure 5.3. However the direct mapping does not always take full advantage of the features of BTs. Thus a more compact, and still equivalent, BT can be found in Figure 5.4, where again, we assume that all actions always return Running."}, {"heading": "5.2 How BTs Generalize the Subsumption Architecture", "text": "In this section we will see how the subsumption architecture, proposed by Brooks [4], can be realized using a Fallback composition. The basic idea in [4] was to have a\n80 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas\nnumber of controllers set up in parallel and each controller was allowed to output both actuator commands, and a binary value, signaling if it wanted to control the robot or not. The controllers were then ordered according to some priority, and the highest priority controller, out of the ones signaling for action, was allowed to control the robot. Thus, a higher level controller was able to subsume the actions of a lower level one.\nAn example of a Subsumption architecture can be found in Figure 5.5. Here, the basic level controller Do Other Tasks is assumed to be controlling the robot for most of the time. However, when the battery level is low enough, the Recharge if Needed controller will signal that it needs to command the robot, subsume the lower level controller, and guide the robot towards the recharging station. Similarly, if there is risk for overheating, the top level controller Stop if Overheated will subsume both of the lower level ones, and stop the robot until it has cooled down.\nLemma 5.2. Given a Subsumption architecture, we can create an equivalent BT by arranging the controllers as actions under a Fallback composition, in order from higher to lower priority. Furthermore, we let the return status of the actions be Failure if they do not need to execute, and Running if they do. They never return Success. Formally, a subsumption architecture composition Si(x)= Sub(Si1(x),Si2(x)) can be defined by\nSi(x) = { Si1(x) if Si1 needs to execute Si2(x) else\n(5.4)\nThen we write an equivalent BT as follows\nTi = Fallback(Ti1,Ti2) (5.5)\nwhere Ti j is defined by fi j(x) = Si j(x) and\nri j(x) = { R if Si j needs to execute F else.\n(5.6)\nProof. By the above arrangement, and Definition 4.3 we have that\nfi(x) = { fi1(x) if Si1 needs to execute fi2(x) else,\n(5.7)\n5.3 How BTs Generalize Sequential Behavior Compositions 81\nwhich is equivalent to (5.4) above. In other words, actions will be checked in order of priority, until one that returns running is found.\nA BT version of the example in Figure 5.5 can be found in Figure 5.6. Table 5.1 illustrates how the two control structures are equivalent, listing all the 23 possible return status combinations. Note that no action is executed if all actions return Failure."}, {"heading": "5.3 How BTs Generalize Sequential Behavior Compositions", "text": "In this section, we will see how the Fallback composition, and Lemma 4.3, can also be used to implement the Sequential Behavior Compositions proposed in [6].\nThe basic idea proposed by [6] is to extend the region of attraction by using a family of controllers, where the asymptotically stable equilibrium of each controller was either the goal state, or inside the region of attraction of another controller, positioned earlier in the sequence.\nWe will now describe the construction of [6] in some detail, and then see how this concept is captured in the BT framework. Given a family of controllers U = {\u03a6i},\n82 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas\nwe say that \u03a6i prepares \u03a6 j if the goal G(\u03a6i) is inside the domain D(\u03a6 j). Assume the overall goal is located at G(\u03a61). A set of execution regions C(\u03a6i) for each controller was then calculated according to the following scheme:\n1. Let a Queue contain \u03a61. Let C(\u03a61) = D(\u03a61), N = 1, D1 = D(\u03a61). 2. Remove the first element of the queue and append all controllers that prepare it\nto the back of the queue. 3. Remove all elements in the queue that already has a defined C(\u03a6i). 4. Let \u03a6 j be the first element in the queue. Let C(\u03a6 j) = D(\u03a6 j) \\DN , DN+1 =\nDN \u222aD(\u03a6 j) and N\u2190 N +1. 5. Repeat steps 2, 3 and 4 until the queue is empty.\nThe combined controller is then executed by finding j such that x \u2208C(\u03a6 j) and then invoking controller \u03a6 j.\nLooking at the design of the Fallback operator in BTs, it turns out that it does exactly the job of the Burridge algorithm above, as long as the subtrees of the Fallback are ordered in the same fashion as the queue above. We formalize this in Lemma 5.3 below.\nLemma 5.3. Given a set of controllers U = {\u03a6i} we define the corresponding regions Si = G(\u03a6i),R\u2032i = D(\u03a6i),Fi = Complement(D(\u03a6i)), and consider the controllers as atomic BTs, Ti = \u03a6i. Assume S1 is the overall goal region. Iteratively create a larger BT TL as follows\n1. Let TL = T1. 2. Find a BT T\u2217 \u2208U such that S\u2217 \u2282 R\u2032L 3. Let TL\u2190 Fallback(TL,T\u2217) 4. Let U \u2190U \\T\u2217 5. Repeat steps 2, 3 and 4 until U is empty.\nIf all Ti are FTS, then so is TL.\nProof. The statement is a direct consequence of iteratively applying Lemma 4.3.\nThus, we see that BTs generalize the Sequential Behavior Compositions of [6], with the execution region computations and controller switching replaced by the Fallback composition, as long as the ordering is given by Lemma 5.3 above."}, {"heading": "5.4 How BTs Generalize TRs", "text": "In this section, we use the following Lemma to show how to create a BT with the same execution as a given TR. The lemma is illustrated by Example 5.1 and Figure 5.7.\n5.4 How BTs Generalize TRs 83\nLemma 5.4 (TR-BT analogy). Given a TR in terms of conditions ki and actions ai, an equivalent BT can be constructed as follows\nTT R = Fallback(Sequence(c1,a1), . . . ,Sequence(cm,am)), (5.8)\nwhere we convert the True/False of the conditions to Success/Failure, and let the actions only return Running.\nProof. It is straightforward to see that the BT above executes the exact same ai as the original TR would have, depending on the values of the conditions ci, i.e. it finds the first condition ci that returns Success, and executes the corresponding ai.\nWe will now illustrate the lemma with an example from Nilssons original paper [31].\nExample 5.1. The TR Goto(loc) is described as follows, with conditions on the left and corresponding actions to the right:\nEqual(pos,loc)\u2192 Idle (5.9) Heading Towards (loc)\u2192 Go Forwards (5.10)\n(else)\u2192 Rotate (5.11)\nwhere pos is the current robot position and loc is the current destination. Executing this TR, we get the following behavior. If the robot is at the destination it does nothing. If it is heading the right way it moves forward, and else it rotates on the spot. In a perfect world without obstacles, this will get the robot to the goal, just as predicted in Lemma 5.5. Applying Lemma 5.4, the GoTo TR is translated to a BT in Figure 5.8.\nThe example continues in [31] with a higher level recursive TR, called Amble(loc), designed to add a basic obstacle avoidance behavior\n84 5 Formal Analysis of How Behavior Trees Generalize Earlier Ideas\nEqual(pos,loc)\u2192 Idle (5.12) Clear Path(pos,loc)\u2192 GoTo(loc) (5.13)\n(else)\u2192 Amble(new point(pos,loc)) (5.14)\nwhere new point picks a new random point in the vicinity of pos and loc. Again, if the robot is at the destination it does nothing. If the path to goal is clear it executes the GoTo TR. Else it picks a new point relative to its current position and destination (loc) and recursively executes a new copy of Amble with that destination. Applying Lemma 5.4, the Amble TR is translated to a BT in Figure 5.9."}, {"heading": "5.4.1 Universal TRs and FT-Successful BTs", "text": "Using the functional form of BTs introduced in 4.1 we can show that Lemma 4.3 is a richer version of Lemma 5.5 below, and also fix one of its assumptions. Lemma 4.3 includes execution time, but more importantly builds on a finite difference equation system model over a continuous state space. Thus control theory concepts can be used to include phenomena such as imperfect sensing and actuation into the analy-\n5.4 How BTs Generalize TRs 85\nsis, that was removed in the strong assumptions of Lemma 5.5. Thus, the BT analogy provides a powerful tool for analyzing TR designs.\nLemma 5.5 (Nilsson 1994). If a TR-program is Universal, and there are no sensing and execution errors, then the execution of the program will lead to the satisfaction of k1.\nProof. In [31] it is stated that it is easy to see that this is the case.\nThe idea of the proof is indeed straight forward, but as we will see when we compare it to the BT results in Section 5.4.1 below, the proof is incomplete.\nIn Lemma 4.3, Si,Ri,Fi correspond to Success, Running and Failure regions and R\u2032 denotes the region of attraction.\nLemma 4.3 shows under what conditions we can guarantee that the Success region S0 is reached in finite time. If we for illustrative purposes assume that the regions of attraction are identical to the running regions Ri = R\u2032i, the Lemma states that as long as the system starts in R\u20320 = R \u2032 1 \u222aR\u20322 it will reach S0 = S1 in less than \u03c40 = \u03c41 + \u03c42 time units. The condition analogous to the Regression property is that S2 \u2282 R\u20321, i.e. that the Success region of the second BT is a subset of the region of attraction R\u20321 of the first BT. The regions of attraction, R \u2032 1 and R \u2032 2 are very important, but there is no corresponding concept in Lemma 5.5. In fact, we can construct a counter example showing that Lemma 5.5 does not hold.\nExample 5.2 (Counter Example). Assume that a TR program is Universal in the sense described above. Thus, the execution of action ai eventually leads to the satisfaction of k j where j < i for all i 6= 1. However, assume it is also the case that the execution of ai, on its way towards satisfying k j actually leads to a violation of ki. This would lead to the first true condition being some km, with m > i and the execution of the corresponding action am. Thus, the chain of decreasing condition numbers is broken, and the goal condition a1 might never be reached.\nThe fix is however quite straightforward, and amounts to using the following definition with a stronger assumption.\nDefinition 5.1 (Stronger Regression property). For each ki, i > 1 there is k j, j < i such that the execution of action ai leads to the satisfaction of k j, without ever violating ki.\nChapter 6 Stochastic BTs\nSome of the results of this chapter were previously published in the paper [8]. We are interested in modeling the reliability of reactive robot plan executions, in terms of execution times and success probabilities. To clarify what we mean by these concepts, we consider the following minimalistic example: a robot is searching for an object, and can choose between the two subtasks searching on the table, and opening/searching the drawer. One possible plan is depicted in Figure 6.1. Here, the robot first searches the table and then, if the object was not found on the table, opens the drawer and searches the drawer. In the figure, each task is assigned an execution time, and a success probability. For example, searching the table has a success probability of 0.1 and an execution time of 5s. Given a plan like this, it is fairly straightforward to compute the reliability of the entire plan, in terms of execution time distribution and success probability. In this chapter, we show how to compute such performance metrics for arbitrary complex plans encoded using BTs. In particular, we will define Stochastic BTs in Section 6.1, transform them into DTMCs in Section 6.2, compute reliabilities in Section 6.3 and describe examples Section 6.4.\nBefore motivating our study of BTs we will make a few more observations regarding the example above. First we note that the plan would still make sense if we changed the order of searching on the table and opening/searching the drawer, both subtasks achieve the objective of finding the object. Such subtasks, where ordering is not critical, and succeeding in just one is enough, will be called Fallbacks. Note however that it does not make sense to swap the order of opening the drawer and searching the drawer. Here, the order cannot be changed, and both subtasks must succeed. It does not make sense to search the drawer if we were not able to open it. We call such a set of subtasks a Sequence. Note that adding subtasks to a Sequence generally decreases overall success probabilities, whereas adding Fallbacks generally increases overall success probabilities.\n87\n88 6 Stochastic BTs"}, {"heading": "6.1 Stochastic BTs", "text": "In this section we will show how some probabilistic measures as term of Mean Time to Succeed (MTTS), Mean Time to Fail (MTTF), and probability over time carry across modular compositions of BTs. The advantage of using BTs lie in their modularity and hierarchical structure, which provides good scalability, as explained below. These features would be lost if the whole process from problem formulation to solution was carried out within the classical framework. To do show the properties above, we need to introduce some concepts from Markov theory.\n6.1 Stochastic BTs 89"}, {"heading": "6.1.1 Markov Chains and Markov Processes", "text": "Markov theory [32] deals with memory-less processes. If a process is given by a sequence of actions that changes the system\u2019s state disregarding its history, a DTMC is suitable to model the plan execution. Whereas if a process is given by a transition rates between states, a Continuous Time Markov Chain (CTMC) it then suitable to model such plan execution. A DTMC is given by a collection of states S = {s1,s2, . . . ,sd} and the transitions probabilities pi j between states si and s j. A CTMC is given by a collection of states S and the transition rates q\u22121i j between states si and s j.\nDefinition 6.1. The stochastic sequence {Xn,n = 0,1,2, . . .} is a DTMC provided that:\nP{Xn+1 = sn+1|Xn = sn,Xn\u22121 = sn\u22121, . . . ,X0 = s0}= = P{Xn+1 = sn+1|Xn = sn}\n(6.1)\n\u2200 n \u2208 N, and \u2200 s \u2208S\nThe expression on the right hand side of (6.1) is the so-called one step transition probability of the chain and denotes the probability that the process goes from state sn to state sn+1. We use the following notation:\npi j = P{Xn+1 = s j|Xn = si} (6.2)\nto denote the probability to jump from a state si to a state s j. Since we only consider homogeneous DTMC, the above probabilities do not change in time.\nDefinition 6.2. The one-step transition matrix P is a |S |\u00d7 |S |matrix in which the entries are the transition probabilities pi j.\nLet \u03c0(k) = [\u03c01(k), . . . ,\u03c0|S |(k)]>, where \u03c0i is the probability of being in state i, then the Markov process can be described as a discrete time system with the following time evolution:\n90 6 Stochastic BTs{ \u03c0(k+1) = P>\u03c0(k) \u03c0(0) = \u03c00. . (6.3)\nwhere \u03c00 is assumed to be known a priori. Definition 6.3. The stochastic sequence {X(t), t \u2265 0} is a CTMC provided that:\nP{X(tn+1) = sn+1|X(tn) = sn,X(tn\u22121) = sn\u22121, . . . , ,X(t0) = s0}= P{X(tn+1) = sn+1|X(tn) = sn}\n(6.4)\n\u2200 n \u2208 N, \u2200 s \u2208S , and all sequences {t0, t1, . . . , tn+1} such that t0 < t1 < .. . < tn < tn+1. We use the following notation:\npi j(\u03c4) = P{X(t + \u03c4) = s j|X(\u03c4) = si} (6.5)\nto denote the probability to be in a state s j after a time interval of length \u03c4 given that at present time is into a state si. Since we only consider homogeneous CTMC, the above probabilities only depend on the time length \u03c4 .\nTo study the continuous time behavior of a Markov process we define the socalled infinitesimal generator matrix Q.\nDefinition 6.4. The infinitesimal generator of the transition probability matrix P(t) is given by:\nQ = [qi j] (6.6)\nwhere\nqi j =  lim \u2206 t\u21920 pi j(\u2206 t) \u2206 t if i 6= j\n\u2212\u2211 k 6=i\nqk j otherwise. (6.7)\nThen, the continuous time behavior of the Markov process is described by the following ordinary differential equation, known as the Cauchy problem:{\n\u03c0\u0307(t) = Q>\u03c0(t) \u03c0(0) = \u03c00\n(6.8)\nwhere the initial probability vector \u03c00 is assumed to be known a priori. Definition 6.5. The average sojourn time SJi of a state si in a CTMC is the average time spent in that state. It is given by [39]:\nSJi =\u2212 1 qii\n(6.9)\nDefinition 6.6. Considering the CTMC {X(t), t \u2265 0}, the stochastic sequence {Yn,n= 0,1,2, . . .} is a DTMC and it is called Embedded MC (EMC) of the process X(t) [39].\n6.1 Stochastic BTs 91\nThe transition probabilities of the EMC ri j are defined as:\nri j = P{Yn+1 = s j|Yn = si} (6.10)\nand they can be easily obtained as a function of the transition rates qi j:\nri j = \u2212 qi j qii if i 6= j 1\u2212\u2211\nk 6=i rk j otherwise. (6.11)\nOn the other hand the infinitesimal generator matrix Q can be reconstructed from the EMC as follows\nqi j =  1 SJ j ri j if i 6= j\n\u2212\u2211 k 6=i\nrk j otherwise . (6.12)"}, {"heading": "6.1.2 Formulation", "text": "We are now ready to make some definitions and assumptions, needed to compute the performance estimates. We begin with a formal definition of the BTs, first introduced in Chapter 1.\nDefinition 6.7. An action A in a BT, is called stochastic if the following holds:\n\u2022 It first returns running, for an amount of time that might be zero or non-zero, then consistently returns either success or failure for the rest of the execution of its parent node1. \u2022 The probability to succeed ps and the probability to fail p f are known a priori. \u2022 The probability to succeed ps(t) and the probability to fail p f (t) are exponen-\ntially distributed with the following Probability Density Functions (PDFs):\np\u0302s(t) = ps\u00b5e\u2212\u00b5t (6.13) p\u0302 f (t) = p f \u03bde\u2212\u03bdt (6.14)\nfrom which we can calculate the Cumulative Distribution Functions (CDFs)\np\u0304s(t) = ps(1\u2212 e\u2212\u00b5t) (6.15) p\u0304 f (t) = p f (1\u2212 e\u2212\u03bdt) (6.16)\nDefinition 6.8. An action A in a BT, is called deterministic (in terms of execution time, not outcome) if the following holds:\n1 The execution of the parent node starts when it receives a tick and finishes when it returns either success/failure to its parent.\n92 6 Stochastic BTs\n\u2022 It first returns running, for an amount of time that might be zero or non-zero, then consistently returns either success or failure for the rest of the execution of its parent node. \u2022 The probability to succeed ps and the probability to fail p f are known a priori. \u2022 The time to succeed and the time to fail are deterministic variables \u03c4s and \u03c4 f\nknown a priori. \u2022 The probability to succeed ps(t) and the probability to fail p f (t) have the follow-\ning PDFs:\np\u0302s(t) = ps\u03b4 (t\u2212 \u03c4s) (6.17) p\u0302 f (t) = p f \u03b4 (t\u2212 \u03c4 f ) (6.18)\nwhere \u03b4 (\u00b7) is the Dirac\u2019s delta function. From the PDFs we can calculate the CDFs:\np\u0304s(t) = psH(t\u2212 \u03c4s) (6.19) p\u0304 f (t) = p f H(t\u2212 \u03c4 f ) (6.20)\nwhere H(\u00b7) is the step function.\nRemark 6.1. Note that it makes sense to sometimes have \u03c4s 6= \u03c4 f . Imagine a door opening task which takes 10s to complete successfully but fails 30% of the time after 5s when the critical grasp phase fails.\nExample 6.1. For comparison, given a deterministic action with \u03c4s, we let the rates of a stochastic action have \u00b5 = \u03c4\u22121s . Then the PDFs and CDFs are as seen in Fig. 6.4.\nAs we want to analyze the BT composition of actions, we must also define actions that include both stochastic and deterministic parts.\nDefinition 6.9. An action A in a BT, is called hybrid if one of ps(t) and p f (t) is a random variable with exponential distribution, and the other one is deterministic.\nThus hybrid actions come in two different variations:\nDeterministic success time\nFor this type of hybrid action, the following holds:\n\u2022 It first returns running, for an amount of time that might be zero or non-zero, then consistently returns either success or failure for the rest of the execution of its parent node. \u2022 The probability to succeed ps is known a priori. \u2022 The time to succeed is a deterministic variable \u03c4s known a priori.\n6.1 Stochastic BTs 93\n\u2022 The probability to fail has the following PDF:\np\u0302 f (t) =  p f (1\u2212 e\u2212\u03bdt) if t < \u03c4s 1\u2212 ps if t = \u03c4s 0 otherwise . (6.21)\nIn this case the CDF and the PDF of the probability to succeed are discontinuous. In fact this hybrid action will return failure if, after the success time \u03c4s, it does not return success. Then, to have an analogy with stochastic actions we derive the PDF of the probability to succeed:\np\u0302s(t) = ps\u03b4 (t\u2212 \u03c4s) (6.22)\nand the CDFs as follows: p\u0304s(t) = psH(t\u2212 \u03c4s) (6.23)\n94 6 Stochastic BTs\np\u0304 f (t) = { p f (1\u2212 e\u2212\u03bdt) if t < \u03c4s 1\u2212 p\u0304s(t) otherwise . (6.24)\nThus, the probability of running is zero after \u03c4s i.e. after \u03c4s it either fails or succeeds. Moreover, the success rate is set to \u00b5 = \u03c4\u22121s .\nDeterministic failure time\nFor this type of hybrid action, the following holds:\n\u2022 It first returns running, for an amount of time that might be zero or non-zero, then consistently returns either success or failure for the rest of the execution of its parent node. \u2022 The probability to fail p f is known a priori. \u2022 The time to succeed is a random variables with exponential distribution with rate\n\u00b5 known a priori. \u2022 The probability to succeed has the following PDF:\np\u0302s(t) =  ps(1\u2212 e\u2212\u00b5t) if t < \u03c4 f 1\u2212 p f if t = \u03c4 f 0 otherwise . (6.25)\nTo have an analogy with stochastic actions we derive the PDF of the probability to fail: p\u0302 f (t) = p f \u03b4 (t\u2212 \u03c4 f ) (6.26) and the CDFs as follows:\np\u0304 f (t) = p f H(t\u2212 \u03c4 f ) (6.27)\np\u0304s(t) = { ps(1\u2212 e\u2212\u00b5t) if t < \u03c4 f 1\u2212 p\u0304 f (t) otherwise . (6.28)\nMoreover, the failure rate is set to \u03bd = \u03c4\u22121f\nRemark 6.2. Note that the addition of deterministic execution times makes (6.8) discontinuous on the right hand side, but it still has a unique solution in the Carathe\u0301odory sense [11].\nWe will now give an example of how these concepts transfer over BT compositions.\nExample 6.2. Consider the BT in Fig. 6.5. The parallel node is set to returns success as soon as one child returns success, and the two children are of different kinds, one deterministic and the other stochastic. Note that the MTTS and MTTF of this\n6.1 Stochastic BTs 95\nBT has to account for the heterogeneity of its children. The deterministic child can succeed only at time \u03c4s. The CDF of the parallel node is given by the sum of the CDFs of its children. The PDF has a jump at time \u03c4s accounting for the fact that the parallel node is more likely to return success after that time. Thus, the PDF and the CDF of a Success return status are shown in Fig. 6.6.\n96 6 Stochastic BTs\nDefinition 6.10. A BT T1 and a BT T2 are said to be equivalent if and only if T1 can be created from T2 by permutations of the children of Fallbacks and Parallel compositions.\nAn example of two equivalent BTs is shown in Fig. 6.7.\nAssumption 3 For each action A in the BT, one of the following holds\n\u2022 The action A is a stochastic action. \u2022 The action A is a deterministic action. \u2022 The action A is a hybrid action.\nAssumption 4 For each condition C in the BT, the following holds\n\u2022 It consistently returns the same value (success or failure) throughout the execution of its parent node. \u2022 The probability to succeed at any given time ps(t) and the probability to fail at any given time p f (t) are known a priori.\nWe are now ready to define a SBT.\nDefinition 6.11. A SBT is a BT satisfying Assumptions 3 and 4.\nGiven a SBT, we want to use the probabilistic descriptions of its actions and conditions, ps(t), p f (t), \u00b5 and \u03bd , to recursively compute analogous descriptions for every sub-trees and finally the whole tree.\nTo illustrate the investigated problems and SBTs we take a look at the following example.\nExample 6.3. Imagine a robot that is to search for a set of keys on a table and in a drawer. The robot knows that the keys are often located in the drawer, so that location is more likely than the table. However, searching the table takes less time, since the drawer must be opened first. Two possible plans are conceivable: searching the table first, and then the drawer, as in Fig. 6.7a, or the other way around as in Fig. 6.7b. These two plans can be formulated as SBTs and analyzed through the scope of Problem 1 and 2, using the results of Section 6.1 below. Depending on the user requirements in terms of available time or desired reliability at a given time, the proper SBT can be chosen.\nRemark 6.3. Note that Assumption 1 corresponds to the return status of the search actions in Example 6.3 behaving in a reasonable way, e.g., not switching between success and failure."}, {"heading": "6.2 Transforming a SBT into a DTMC", "text": "The first step of our approach is to define, for each control flow node in V , a vector representation of the children\u2019s outcomes and a description of its execution policy,\n6.2 Transforming a SBT into a DTMC 97\n1\n1\nthen we map the execution into a DTMC with a direct representation of the one-step transition matrix, and finally we compute the probability of success and failure over time for each node.\nNote that the modularity of BTs comes from the recursive tree structure, any BT can be inserted as sub-tree in another BT. This modularity allows us to do the analysis in a recursive fashion, beginning with the leaves of the BT, i.e. the actions and conditions which have known probabilistic parameters according to Assumptions 3 and 4, and then progressing upwards in a scalable fashion.\nTo keep track of the execution of a given flow control node, the children outcomes are collected in a vector state called the marking of the node, and the transitions between markings are defined according to the execution policy of the node. In detail, let m(k) = [m1(k),m2(k), . . . ,mN(k)] be a marking of a given BT node with N children at time step k with\nmi(k) =  \u22121 if child i returns failure at k\n1 if child i returns success at k 0 otherwise\n(6.29)\nExample 6.4. Consider the BT in Figure 6.7(a). If the first child (Search Table) has failed, and the second (Search Drawer) is currently running, the marking would be m(k) = [\u22121,0]. We define an event related to a BT node when one of its children returns either success or failure. Defining ei(k) to be the vector associated to the event of the i-th running child, all zeros except the i-th entry which is equal to ei(k) \u2208 {\u22121,1}:\nei(k) =\n{ \u22121 if child i has failed at k\n1 if child i has succeeeded at k. (6.30)\nWe would like to describe the time evolution of the node marking due to an event associated with the child i as follows:\n98 6 Stochastic BTs\nm(k+1) = m(k)+ ei(k) (6.31)\nwith the event ei(k) restricted to the feasible set of events at m(k), i.e.\nei(k) \u2208F (m(k)).\nIn general, F (m(k))\u2282F0, with\nF0 = {ei : ei \u2208 {\u22121,0,1}N , ||ei||2 = 1}, (6.32)\ni.e. events having only one nonzero element, with value \u22121 or 1. We will now describe the set F (m(k)) for the three different node types.\nFeasibility condition in the Fallback node\nFFB(m(k)) = {ei \u2208F0 :\u2203i : mi(k) = 0,ei 6= 0, m j(k) =\u22121,\u2200 j,0 < j < i},\n(6.33)\ni.e. the event of a child returning success or failure is only allowed if it was ticked, which only happens if it is the first child, or if all children before it have returned failure.\nFeasibility condition in the Sequence node\nFS(m(k)) = {ei \u2208F0 :\u2203i : mi(k) = 0,ei 6= 0, m j(k) = 1,\u2200 j,0 < j < i},\n(6.34)\ni.e. the event of a child returning success or failure is only allowed if it was ticked, which only happens if it is the first child, or if all children before it have returned success.\nFeasibility condition in the Parallell node\nFP(m(k)) = {ei \u2208F0 :\u2203i : mi(k) = 0,ei 6= 0, \u03a3 j:m j(k)>0m j(k)< M\n\u03a3 j:m j(k)<0m j(k)< N\u2212M+1}, (6.35)\ni.e. the event of a child returning success or failure is only allowed it if has not returned yet, and the conditions for success (< M successful children) and failure (< N\u2212M\u22121 failed children) of the parallell node are not yet fulfilled.\n6.2 Transforming a SBT into a DTMC 99\nExample 6.5. Continuing Example 6.4 above, F (m(k))=FFB([\u22121,0])= {(0,1),(0,\u22121)}, i.e. the second child returning success or failure. Note that if the first child would have returned success, the feasible set would be empty FFB([1,0]) = /0.\nThe Reachability Graph (RG), see Figure 6.8, of a BT node can now be computed starting from the initial marking m(0) = m0 = 0>, taking into account all the possible event combinations that satisfy the feasibility condition.\nDefinition 6.12. A marking mi is reachable from a marking m j if there exists a sequence of feasible events \u03c3 = [\u03c31,\u03c32, . . . ,\u03c3g] such that mi = m j +\u2211gh=1 \u03c3h.\nRemark 6.4. Note that m(k) = mi when mi is the marking at time k."}, {"heading": "6.2.1 Computing Transition Properties of the DTMC", "text": "The RG of a BT node comprises all the reachable markings, the transitions between them describe events which have a certain success/failure probability. We can then map the node execution to a DTMC where the states are the markings in the RG\n100 6 Stochastic BTs\nand the one-step transition matrix P is given by the probability of jump between markings, with off diagonal entries defined as follows:\n6.3 Reliability of a SBT 101\npi j =  p\u0303sh if m j\u2212mi \u2208F (mi)\u2227 eheTh (m j\u2212mi)> 0 p\u0303 f h if m j\u2212mi \u2208F (mi)\u2227 eheTh (m j\u2212mi)< 0 0 otherwise\n(6.36)\nand diagonal entries defined as:\npii = 1\u2212\u2211 j pi j. (6.37)\nwith:\np\u0303sh = psh\u00b5h\u03bdh\np f h\u00b5h + psh\u03bdh \u00b7  \u2211 j:e j\u2208F (mi) \u00b5 j\u03bd j p f j\u00b5 j + ps j\u03bd j \u22121 (6.38) and\np\u0303 f h = p f h\u00b5h\u03bdh\np f h\u00b5h + psh\u03bdh \u00b7  \u2211 j:e j\u2208F (mi) \u00b5 j\u03bd j p f j\u00b5 j + ps j\u03bd j \u22121 (6.39) where ps j and p f j is the ps and p f of child j.\nRemark 6.5. For sequence and selector node the following holds: p\u0303sh = psh and p\u0303 f h = p f h.\nIn Figs. 6.8 and 6.9 the mapping from RG to a DTCM related to a sequence node and a fallback node are shown. In Fig. 6.10 the mapping for a parallel node with two children and M = 2 is shown. We choose not to depict the mapping of a general parallel node, due to its large amount of states and possible transition between them.\nTo obtain the continuous time probability vector \u03c0(t) we need to compute the infinitesimal generator matrix Q associated with the BT node. For doing so we construct a CTMC for which the EMC is the DTMC of the BT node above computed. According to (6.7) the map from the EMC and the related CTMC is direct, given the average sojourn times SJi."}, {"heading": "6.3 Reliability of a SBT", "text": ""}, {"heading": "6.3.1 Average sojourn time", "text": "We now compute the average sojourn time of each marking mi of a BT node.\nLemma 6.1. For a BT node with psi, p f i,\u00b5i,\u03bdi given for each child, the average sojourn time of in a marking mi is:\n102 6 Stochastic BTs\nSJi = ( \u2211\nh:eh\u2208F (mi)\n( psh \u00b5h + p f h \u03bdh )\u22121)\u22121 (6.40)\nwith h : eh \u2208F (mi).\nProof. In each marking one of the following occur: the running child h fails or succeeds. To take into account both probabilities and time rates, that influence the average sojourn time, we describe the child execution using an additional CTMC, depicted in Fig. 6.11\nAccording to (6.9) the average sojourn time is:\n\u03c4i = p f h\u00b5h + psh\u03bdh\n\u03bdh\u00b5h = psh \u00b5h + p f h \u03bdh\n(6.41)\nand the rate of leaving that state is \u03c4i\u22121. Now to account all the possible running children outcome, e.g. in a parallel node, we consider all the rates associate to the running children. The rate of such node is the sum of all the rates associated to the running children \u03c4i\u22121. Finally, the average sojourn time of a marking mi is given by the inverse of the combined rate:\n1 SJi\n= \u2211 h:eh\u2208F (mh) 1 psh \u00b5h + p f h \u03bdh\n(6.42)\nfrom which we obtain (6.40).\nRemark 6.6. The EMC associated with the CTMC in Fig. 6.11 is depicted in Fig. 6.12. It describes the child\u2019s execution as a DTMC.\n6.3 Reliability of a SBT 103"}, {"heading": "6.3.2 Mean Time To Fail and Mean Time To Succeed", "text": "To derive a closed form of the mean time to fail (MTTF) and mean time to succeed (MTTS) of a BT node, we take the probability to reach a success (failure) state from the DTCM and the average time spent in each state visited before reaching this state obtained from (6.40). We rearrange the state space of the DTMC so that the initial state is first, the other transient states are second, the failure states are second last and the success states are last:\nP>c =  T 0 0RF I 0 RS 0 I  (6.43) where T is the matrix describing the one-step transition from a transit state to another one, RF is a the matrix describing the one-step transition from a transit state to a failure state, and RS is the matrix describing the one-step transition from a transit state to a success state. We call this rearrangement the canonization of the state space.\nLemma 6.2. Let A be a matrix with the i j-th entry defined as exp(ti j) where ti j is the time needed to transit from a state j to a state i if j, i are neighbors in the RG, 0 otherwise. The MTTF and MTTS of the BT node can be computed as follows\nMT T F = \u2211|SF |i=1 u F i1log(h F i1)\n\u2211|SF |i=1 u F i1\n(6.44)\nwhere:\nHF , AF \u221e\n\u2211 i=0 AiT . (6.45)\nand\nMT T S = \u2211|SS|i=1 u S i1log(h S i1)\n\u2211|SS|i=1 u S i1\n(6.46)\n104 6 Stochastic BTs\nwhere:\nHS , AS \u221e\n\u2211 i=0 AiT (6.47)\nwhere AT , AF , and AS are the sub-matrices of A corresponding to the canonization described in (6.43), for which the following holds:\nA = AT 0 0AF 0 0 AS 0 0  . (6.48) Proof. Failure and success states are absorbing, hence we focus our attention on the probability of leaving a transient state, described by the matrix U , defined below:\nU = \u221e\n\u2211 k=0 T i, (6.49)\nThus, considering i as the initial transient state, the entries ui j is the mean number of visits of j starting from i before being absorbed, we have to distinguish the case in which the absorbing state is a failure state from the case in which it is a success state:\nUF , RFU (6.50) US , RSU. (6.51)\nEquations (6.50) and (6.51) represent the mean number of visits before being absorbed in a failure or success state respectively.\nTo derive MTTF (MTTS) we take into account the mean time needed to reach every single failure (success) state with its probability, normalized over the probability of reaching any failure (success) state, starting from the initial state. Hence we sum the probabilities of reaching a state starting from the initial one, taking into account only the first column of the matrices obtaining Eq. (6.44) and Eq. (6.46).\nRemark 6.7. Since there are no self loops in the transient state of the DTMC above, the matrix T is nilpotent. Hence ui j is finite \u2200i, j."}, {"heading": "6.3.3 Probabilities Over Time", "text": "Since all the marking of a BT node have a non null corresponding average sojourn time, the corresponding DTMC is a EMC of a CTMC with infinitesimal generator matrix Q(t) as defined in (6.7). Hence, we can compute the probability distribution over time of the node according to (6.8) with the initial condition \u03c00 = [1 0]> that represents the state in which none of the children have returned success/failure yet.\n6.3 Reliability of a SBT 105"}, {"heading": "6.3.4 Stochastic Execution Times", "text": "Proposition 6.1. Given a SBT, with known probabilistic parameters for actions and conditions, we can compute probabilistic measures for the rest of the tree as follows: For each node whose children have known probabilistic measures we compute the related DTMC. Now the probability of a node to return success ps(t) (failure p f (t)) is given by the sum of the probabilities of the DTMC of being in a success (failure) state. Let SS \u2282SA, and SF \u2282SA be the set of the success and failure states respectively of a DTMC related to a node, i.e. those states representing a marking in which the node returns success or failure, with SF \u222aSS = SA and SF \u2229SS = /0.\nThen we have\np\u0304s(t) = \u2211 i:si\u2208SS \u03c0i(t) (6.52)\np\u0304 f (t) = \u2211 i:si\u2208SF \u03c0i(t) (6.53)\nwhere \u03c0(t) is the probability vector of the DTMC related to the node (i.e. the solution of (6.8)). The time to succeed (fail) for a node is given by a random variable with exponential distribution and rate given by the inverse of the MTTS (MTTF) since for such random variables the mean time is given by the inverse of the rate.\n\u00b5 = MT T S\u22121 (6.54) \u03bd = MT T F\u22121 (6.55)\nRemark 6.8. Proposition 6.55 holds also for deterministic and hybrid BTs, as (6.8) has a unique solution in the Carathe\u0301odory sense [11]."}, {"heading": "6.3.5 Deterministic Execution Times", "text": "As the formulation of the deterministic case involves Dirac delta functions, see Equation (6.17)-(6.18), the approach described above might lead to computational difficulties. As an alternative, we can take advantage of the fact that we know the exact time of possible transitions. Thus, the success and failure probabilities of a deterministic node are unchanged in the intervals between the MT T F and MT T S of its children.\nExample 6.6. Consider the tree\nT = fallback(A1,A2) (6.56)\n106 6 Stochastic BTs\ndepicted in Fig. 6.13 and let \u03c4Fi (\u03c4Si) be the MT T F (MT T S) of action i and p f i (psi) its probability to fail (succeed). The success/failure probability over time of the tree T is a discontinuous function depicted in Fig. 6.14.\nHence the success and failure probability have discrete jumps over time. These piece-wise continuous functions can be described by the discrete time system (6.3) introducing the information of the time when the transitions take place, which is more tractable than directly solving (6.8). Then, the calculation of \u03c0(t) is given by a zero order hold of the discrete solution.\nProposition 6.2. Let P be the one-step transition matrix given in Definition 6.2 and let \u03c4Fi (\u03c4Si) be the time to fail (succeed) of action i and p f i (psi) its probability to fail (succeed). Let \u03c0\u0303(\u03c4) = [\u03c0\u03031(\u03c4), . . . , \u03c0\u0303|S |(\u03c4)]>, where \u03c0\u0303i(\u03c4) is the probability of being in a marking mi at time \u03c4 of a RG representing a deterministic node with N children, let P\u0303(\u03c4) be a matrix which entries p\u0303i j(\u03c4) are defined as:\np\u0303i j(\u03c4) = pi j \u00b7\u03b4 (\u03c4\u2212 (log(a\u0303 j1)) if i 6= j1\u2212\u2211 k 6=i p\u0303ik otherwise (6.57)\n6.4 Examples 107\nwith a\u0303i j the i j-th entry of the matrix A\u0303 defined as:\nA\u0303, \u221e\n\u2211 i=0 Ai (6.58)\nwith A as defined in (6.48). Then the evolution of \u03c0\u0303(k) process can be described as a discrete time system with the following time evolution:\n\u03c0\u0303(\u03c4 +\u2206\u03c4) = P\u0303(\u03c4)>\u03c0\u0303(\u03c4) (6.59)\nwhere \u2206\u03c4 is the common factor of {\u03c4F1,\u03c4S1,\u03c4F2,\u03c4S2, . . . ,\u03c4FN ,\u03c4SN} Then for, deterministic nodes, given \u03c0\u0303(\u03c4) the probability over time is given by:\n\u03c0(t) = ZOH(\u03c0\u0303(\u03c4)) (6.60)\nwhere ZOH is the zero order hold function.\nProof. The proof is trivial considering that Eq. (6.59) is a piece-wise constant function and \u2206\u03c4 is the common faction of all the step instants."}, {"heading": "6.4 Examples", "text": "In this section, we present three examples. The first example is the BT in Figure 6.15a, which is fairly small and allows us to show the details of each step. The second example is the deterministic time version of the same BT, illustrating the differences between the two cases. The third example involves a more complex BT, shown in Figure 6.16. This example will be used to verify the approach numerically, by performing Monte Carlo simulations and comparing the numeric results to the analytical ones, see Table 6.2 and Figure 6.19. It is also used to illustrate the difference in performance metrics, between two equivalent BTs, see Figure 6.21.\nWe will now carry out the computation of probabilistic parameters for an example SBT.\nExample 6.7. Given the tree shown in Fig. 6.15a, its probabilistic parameters are given by evaluating the fallback node, since it is the child of the root node. The given PDF of the i-th action are:\np\u0302s(t) = psi \u00b5e \u2212\u00b5it (6.61) p\u0302 f (t) = p fi\u03bde \u2212\u03bdit (6.62)\nwhere:\n\u2022 p fi probability of failure\n108 6 Stochastic BTs\n1\n\u2022 psi probability of success \u2022 \u03bdi failure rate \u2022 \u00b5i success rate The DTMC related as shown in Fig. 6.15b has S = {s1,s2,s3,s4,s5,s6,s7}, SF = {s4} and SS = {s5,s6,s7}.\nAccording to the canonization in (6.43), the one-step transition matrix is:\nP>c =  0 0 0 0 0 0 0 p f1 0 0 0 0 0 0 0 p f2 0 0 0 0 0 0 0 p f3 1 0 0 0\nps1 0 0 0 1 0 0 0 ps2 0 0 0 1 0 0 0 ps3 0 0 0 1\n (6.63)\nAccording to Equation (6.40) the average sojourn times are collected in the following vector SJ = [\nps1 \u00b51 + p f1 \u03bd1 , ps2 \u00b52 + p f2 \u03bd2 , ps3 \u00b53 + p f3 \u03bd3\n] (6.64)\nThe infinitesimal generator matrix is defined, according to (6.7), as follows:\n6.4 Examples 109\nQ =  \u2212\u00b51\u03bd1 ps1 \u03bd1+p f1 \u00b51\n0 0 0 0 0 0\n\u00b51\u03bd1 p f1 ps1 \u03bd1+p f1 \u00b51 \u2212\u00b52\u03bd2 ps2 \u03bd2+p f2 \u00b52\n0 0 0 0 0\n0 \u00b52\u03bd2 p f2 ps2 \u03bd2+p f2 \u00b52 \u2212\u00b53\u03bd3 ps3 \u03bd3+p f3 \u00b53 0 0 0 0 0 0 \u00b53\u03bd3 p f3\nps3 \u03bd3+p f3 \u00b53 0 0 0 0\n\u00b51\u03bd1 ps1 ps1 \u03bd1+p f1 \u00b51\n0 0 0 0 0 0\n0 \u00b52\u03bd2 ps2\nps2 \u03bd2+p f2 \u00b52 0 0 0 0 0\n0 0 \u00b53\u03bd3 ps3\nps3 \u03bd3+p f3 \u00b53 0 0 0 0\n . (6.65)\nThe probability vector, according to (6.8), is given by:\n\u03c0(t) = [ \u03c01(t)\u03c02(t)\u03c03(t)\u03c04(t)\u03c05(t)\u03c06(t)\u03c07(t) ]> (6.66)\nWe can now derive closed form expression for MTTS and MTTF. Using the decomposition in (6.43), the matrices computed according Equations 6.51 and 6.50 are:\nUS =  ps1 0 0p f1 ps2 ps2 0 p f1 p f2 ps3 p f2 ps3 ps3  (6.67) UF = [ p f1 p f2 p f3 p f2 p f3 p f3 ] (6.68)\nNote that US is a 3\u00d7 3 matrix and US is a 1\u00d7 3 matrix since there are 3 transient states, 3 success state and 1 failure state. For action i we define t fi = \u03bd \u22121 i the time to fail and tsi = \u00b5 \u22121 i the time to succeed. The non-zero entries of the matrix given by (6.48) are:\na2,1 = e t f1 a3,2 = e t f2 a4,3 = e t f3 a5,1 = ets1 a6,2 = ets2 a7,3 = ets3 (6.69)\nfrom which we derive (6.45) and (6.47) as:\nHS =  ets1 0 0et f1 ets2 ets2 0 et f1 et f2 ets3 et f2 ets3 ets3  (6.70) HF = [ et f1 et f2 et f3 et f2 et f3 et f3 ] (6.71)\nUsing Equations (6.44) and (6.46) we obtain the MTTS and MTTF. Finally, the probabilistic parameters of the tree are expressed in a closed form according to Equations (6.52)-(6.55):\n110 6 Stochastic BTs\np\u0304s(t) = \u03c05(t)+\u03c06(t)+\u03c07(t) (6.72) p\u0304 f (t) = \u03c04(t) (6.73)\n\u00b5 = ps1+p f1 ps2+p f1 p f2 ps3\nps1 ts1+p f1 ps2 (t f1+ts2 )+p f1 p f2 ps3 (t f1+t f2+ts3 ) (6.74) \u03bd = 1t f1+t f2+t f3 (6.75)\nExample 6.8. Consider the tree given in Example 6.4, we now compute the performances in case when the actions are all deterministic.\nThe computation of MTTF and MTTS follows from Example 6.4, whereas the computation of \u03c0(t) can be made according to Proposition 6.2.\nAccording to (6.58) the matrix A\u0303 takes the form below\nA\u0303 =  0 0 0 0 0 0 0 et f1 0 0 0 0 0 0 et f1 et f2 et f2 0 0 0 0 0 et f1 et f2 et f3 et f2 et f3 et f3 0 0 0 0 ets1 0 0 0 0 0 0 et f1 ets2 ets2 0 0 0 0 0\net f1 et f2 ets3 et f2 ets3 ets3 0 0 0 0\n (6.76)\nthereby, according to (6.57), the modified one step transition matrix takes the form of (6.77), and the probability vector \u03c0(t) is given by (6.60).\nP\u0303> =  1\u2212 (p f1 \u03b4 (t\u2212t f1 )+ps1 \u03b4 (t\u2212ts1 )) 0 0 0 0 0 0 p f1 \u03b4 (t\u2212t f1 ) 1\u2212 (p f2 \u03b4 (t\u2212(t f1+t f2 ))+ps2 \u03b4 (t\u2212(t f1+ts2 ))) 0 0 0 0 0 0 p f2 \u03b4 (t\u2212(t f1+t f2 )) 1\u2212 (p f3 \u03b4 (t\u2212(t f1+t f2+t f3 ))+ps3 \u03b4 (t\u2212(t f1+t f2+ts3 ))) 0 0 0 0 0 0 p f3 \u03b4 (t\u2212(t f1+t f2+t f3 )) 1 0 0 0\nps1 \u03b4 (t\u2212ts1 ) 0 0 0 1 0 0 0 ps2 \u03b4 (t\u2212(t f1+ts2 )) 0 0 0 1 0 0 0 ps3 \u03b4 (t\u2212(t f1+t f2+ts3 )) 0 0 0 1  (6.77)\nBelow we present a more complex example, extending Example 6.4 above. We use this example for two purposes, first, to verify the correctness of the proposed approach using Monte Carlo simulations, and second, to illustrate how changes in the SBT lead to different performance metrics.\nExample 6.9. The task given to a two armed robot is to find and collect objects which can be found either on the floor, in the drawers or in the closet. The time needed to search for a desired object on the floor is less than the time needed to search for it in the drawers, since the latter has to be reached and opened first. On the other hand, the object is more likely to be in the drawers than on the floor, or in the closet. Moreover, the available policies for picking up objects are the one-hand and the two-hands grasps. The one-hand grasp most likely fails, but it takes less time to check if it has failed or not. Given these options, the task can be achieved\n6.4 Examples 111\nin different ways, each of them corresponding to a different performance measure. The plan chosen for this example is modeled by the SBT shown in Fig. 6.16.\nThe performance estimates given by the proposed approach for the whole BT, as well as for two sub trees can be seen in Figs. 6.17-6.18 .\nWe also use the example above to verify the correctness of the analytical estimates, and the results can be seen in Table 6.2. We compared the analytical solution derived using our approach with numerical results given by a massive Monte Carlo simulation carried out using a BT implementation in the Robot Operative System (ROS) [23] where actions and conditions are performed using ROS nodes with outcomes computed using the C++ random number generator with exponential distribution. The BT implementation in ROS was run approximately 80000 times to have enough samples to get numerical averages close to the true values. For each run we stored if the tree (and some sub-trees) succeeded or failed and how long it took, allowing us to estimate \u00b5 , \u03bd , ps(t), p f (t) experimentally. The match is reported in Figs. 6.17-6.18 and in Table 6.1. As can be seen, all estimates are within 0.18 % of the analytical results.\nTo further illustrate the difference between modeling the actions as deterministic and stochastic, we again use the BT in Fig. 6.16 and compute the accumulated Succes/Failure/Running probabilities for the two cases. Defining the time to succeed and fail as the inverse of the given rates and computing the probabilities as described in Section 6.3.5 we get the results depicted in Figs. 6.19 and 6.20. As can be seen, the largest deviation is found in the Failure probabilities. In the stochastic\n112 6 Stochastic BTs\ncase the CDF rises instantly, whereas in the deterministic case it becomes non-zero only after all the fallbacks in at least one of the two sub-trees have failed.\nIn Fig. 6.21 the results of swapping the order of \u201cSearch on the Floor\u201d and \u201cSearch in the Drawers\u201d are shown in. As can be seen, the success probability after 100s is about 30% when starting with the drawers, and about 20% when starting with the floor. Thus the optimal solution is a new BT, with the drawer search as the first option. Note that the asymptotic probabilities are always the same for equivalent BT, see Definition 6.10, as the changes considered are only permutations of fallbacks.\n6.4 Examples 113\n114 6 Stochastic BTs\n6.4 Examples 115\n(a) Node 5\n0 500 1000 1500 0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP ro\nb a b ili\nti e s o\nf th\ne n\no d e 3\nTime [s]\nRunning Failed Succeeded\n(b) Node 3\nFig. 6.20: Comparison of Success/Failure/Running probabilities of the node 5 (a) and node 3 (b) in the case of deterministic times (thick) and stochastic times (thin).\n116 6 Stochastic BTs\nReferences 117"}], "references": [{"title": "An Integrated System for Autonomous Robotics Manipulation", "author": ["J. Andrew (Drew) Bagnell", "Felipe Cavalcanti", "Lei Cui", "Thomas Galluzzo", "Martial Hebert", "Moslem Kazemi", "Matthew Klingensmith", "Jacqueline Libby", "Tian Yu Liu", "Nancy Pollard", "Mikhail Pivtoraiko", "Jean-Sebastien Valois", "Ranqi Zhu"], "venue": "In IEEE/RSJ International Conference on Intelligent Robots and Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Reacting, planning, and learning in an autonomous agent", "author": ["Scott Benson", "Nils J Nilsson"], "venue": "In Machine intelligence", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Extending the JADE Agent Behaviour Model with JBehaviourtrees Framework", "author": ["Iva Bojic", "Tomislav Lipic", "Mario Kusek", "Gordan Jezic"], "venue": "In Agent and Multi-Agent Systems: Technologies and Applications,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "A Robust Layered Control System for a Mobile Robot", "author": ["R. Brooks"], "venue": "Robotics and Automation, IEEE Journal of,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1986}, {"title": "Elephants don\u2019t play chess", "author": ["R.A. Brooks"], "venue": "Robotics and autonomous systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1990}, {"title": "Sequential Composition of Dynamically Dexterous Robot Behaviors", "author": ["Robert R Burridge", "Alfred A Rizzi", "Daniel E Koditschek"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1999}, {"title": "Understanding Behavior Trees", "author": ["A.J. Champandard"], "venue": "AiGameDev. com,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Performance Analysis of Stochastic Behavior Trees", "author": ["Michele Colledanchise", "Alejandro Marzinotto", "Petter \u00d6gren"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "How behavior trees modularize hybrid control systems and generalize sequential behavior compositions, the subsumption architecture, and decision trees", "author": ["Michele Colledanchise", "Petter \u00d6gren"], "venue": "IEEE Transactions on Robotics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2017}, {"title": "Letters to the editor: go to statement considered harmful", "author": ["Edsger W. Dijkstra"], "venue": "Commun. ACM,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1968}, {"title": "Differential Equations with Discontinuous Righthand Sides: Control Systems", "author": ["A.F. Filippov", "F.M. Arscott"], "venue": "Mathematics and its Applications. Kluwer Academic Publishers,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1988}, {"title": "Bart - behavior architecture for robotic tasks, https://code.google.com/p/bart", "author": ["Thomas Galluzzo", "Moslem Kazemi", "Jean-Sebastien Valois"], "venue": "Technical report,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Product modularity: definitions and benefits", "author": ["JK Gershenson", "GJ Prasad", "Y Zhang"], "venue": "Journal of Engineering design,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "A teleo-reactive architecture for fast, reactive and robust control of mobile robots", "author": ["Gerhard Gubisch", "Gerald Steinbauer", "Martin Weiglhofer", "Franz Wotawa"], "venue": "In New Frontiers in Applied Artificial Intelligence,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "A framework for enduser instruction of a robot assistant for manufacturing", "author": ["Kelleher R. Guerin", "Colin Lea", "Chris Paxton", "Gregory D. Hager"], "venue": "In IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Statecharts: A visual formalism for complex", "author": ["David Harel"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1987}, {"title": "Semi-autonomous simulated brain tumor ablation with raven ii surgical robot using behavior tree", "author": ["Danying Hu", "Yuanzheng Gong", "Blake Hannaford", "Eric J. Seibel"], "venue": "In IEEE International Conference on Robotics and Automation (ICRA),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Handling Complexity in the Halo 2 AI", "author": ["D. Isla"], "venue": "In Game Developers Conference,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Halo 3-building a Better Battle", "author": ["Damian Isla"], "venue": "In Game Developers Conference,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "The Modelica BehaviorTrees Library: Mission planning in continuous-time for unmanned aircraft", "author": ["Andreas Kl\u00f6ckner", "Franciscus van der Linden", "Dirk Zimmer"], "venue": "In Proceedings of the 10th International Modelica Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Interfacing Behavior Trees with the World Using Description Logic", "author": ["Andreas Kl\u00f6kner"], "venue": "In AIAA conference on Guidance, Navigation and Control,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "Evolving Behaviour Trees for the Commercial Game DEFCON", "author": ["C.U. Lim", "R. Baumgarten", "S. Colton"], "venue": "Applications of Evolutionary Computation,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Towards a Unified Behavior Trees Framework for Robot Control", "author": ["Alejandro Marzinotto", "Michele Colledanchise", "Christian Smith", "Petter \u00d6gren"], "venue": "In Robotics and Automation (ICRA),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "A method for synthesizing sequential circuits", "author": ["G.H. Mealy"], "venue": "The Bell System Technical Journal,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1955}, {"title": "Artificial intelligence for games", "author": ["Ian Millington", "John Funge"], "venue": "CRC Press,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Junior: The stanford entry in the urban challenge", "author": ["Michael Montemerlo", "Jan Becker", "Suhrid Bhat", "Hendrik Dahlkamp", "Dmitri Dolgov", "Scott Ettinger", "Dirk Haehnel", "Tim Hilden", "Gabe Hoffmann", "Burkhard Huhnke"], "venue": "Journal of field Robotics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2008}, {"title": "Gedanken-experiments on sequential machines", "author": ["Edward F Moore"], "venue": "Automata studies,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1956}, {"title": "Simplification Of Teleo-Reactive sequences", "author": ["Seyed R Mousavi", "Krysia Broda"], "venue": "Imperial College of Science, Technology and Medicine, Department of Computing,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2003}, {"title": "Petri nets: Properties, analysis and applications", "author": ["Tadao Murata"], "venue": "Proceedings of the IEEE,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1989}, {"title": "Evolutionary behavior tree approaches for navigating platform games", "author": ["M. Nicolau", "D. Perez-Liebana", "M. O\u2019Neill", "A. Brabazon"], "venue": "IEEE Transactions on Computational Intelligence and AI in Games,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}, {"title": "Teleo-reactive programs for agent control", "author": ["Nils J. Nilsson"], "venue": "JAIR, 1:139\u2013158,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1994}, {"title": "Markov Chains. Number no. 2008 in Cambridge Series in Statistical and Probabilistic Mathematics", "author": ["J.R. Norris"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1998}, {"title": "Increasing Modularity of UAV Control Systems using Computer Game Behavior Trees", "author": ["Petter \u00d6gren"], "venue": "In AIAA Guidance, Navigation and Control Conference,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Costar: Instructing collaborative robots with behavior trees and vision", "author": ["Chris Paxton", "Andrew Hundt", "Felix Jonathan", "Kelleher Guerin", "Gregory D Hager"], "venue": "arXiv preprint arXiv:1611.06145,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2016}, {"title": "The Sting Racing Team\u2019s Entry to the Urban Challenge", "author": ["Matthew Powers", "Dave Wooden", "Magnus Egerstedt", "Henrik Christensen", "Tucker Balch"], "venue": "In Experience from the DARPA Urban Challenge,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2012}, {"title": "Game AI Pro, chapter 6. The Behavior Tree Starter Kit", "author": ["Steve Rabin"], "venue": "CRC Press,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Imitation in Animals and Artifacts, chapter Learning to Fly, page 171", "author": ["Claude Sammut", "Scott Hurst", "Dana Kedzier", "Donald Michie"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2002}, {"title": "Parameterizing Behavior Trees", "author": ["Alexander Shoulson", "Francisco M Garcia", "Matthew Jones", "Robert Mead", "Norman I Badler"], "venue": "In Motion in Games. Springer,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Probability, Markov chains, queues, and simulation: the mathematical basis of performance modeling", "author": ["William J Stewart"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2009}, {"title": "Autonomous driving in urban environments: Boss and the urban challenge", "author": ["Chris Urmson", "Joshua Anhalt", "Drew Bagnell", "Christopher Baker", "Robert Bittner", "MN Clark", "John Dolan", "Dave Duggins", "Tugrul Galatali", "Chris Geyer"], "venue": "Journal of Field Robotics,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2008}, {"title": "Tartan racing: A multi-modal approach to the darpa urban challenge", "author": ["Chris Urmson", "J Andrew Bagnell", "Christopher R Baker", "Martial Hebert", "Alonzo Kelly", "Raj Rajkumar", "Paul E Rybski", "Sebastian Scherer", "Reid Simmons", "Sanjiv Singh"], "venue": null, "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2007}, {"title": "Solving navigation tasks with learned teleo-reactive programs", "author": ["Blanca Vargas", "E Morales"], "venue": "Proceedings of IEEE International Conference on Robots and Systems (IROS),", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2008}], "referenceMentions": [], "year": 2017, "abstractText": null, "creator": "LaTeX with hyperref package"}}}