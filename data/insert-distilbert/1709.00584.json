{"id": "1709.00584", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Sep-2017", "title": "Deep Learning-Guided Image Reconstruction from Incomplete Data", "abstract": "an approach to incorporate deep learning within introducing an autonomous iterative image reconstruction framework to reconstruct existing images from severely generated incomplete measurement data is presented. specifically, we utilize a convolutional neural network ( cnn ) as a hypothetical quasi - projection operator within a least squares minimization procedure. the cnn tool is normally trained to encode high level information about the class of transmitted images accurately being imaged ; this information is utilized to mitigate artifacts recorded in intermediate images produced by use of an iterative method. gradually the structure of the method was inspired by the proximal gradient descent method, where performing the primitive proximal operator gradient is replaced by a deep probing cnn and occasionally the gradient descent step is generalized by use of a linear reconstruction operator. it is demonstrated that this approach improves image quality for several cases of limited - view image reconstruction approaches and that using a cnn in rejecting an earlier iterative method increases performance compared to conventional image reconstruction approaches. we test our method on several limited - view image reconstruction problems. qualitative and broad quantitative results demonstrate state - of - the - art performance.", "histories": [["v1", "Sat, 2 Sep 2017 14:15:24 GMT  (6144kb,D)", "http://arxiv.org/abs/1709.00584v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["brendan kelly", "thomas p matthews", "mark a anastasio"], "accepted": false, "id": "1709.00584"}, "pdf": {"name": "1709.00584.pdf", "metadata": {"source": "CRF", "title": "Deep Learning-Guided Image Reconstruction from Incomplete Data", "authors": ["Brendan Kelly", "Thomas P. Matthews"], "emails": ["bmkelly@wustl.edu", "thomas.matthews@wustl.edu", "anastasio@wustl.edu"], "sections": [{"heading": "1 Introduction", "text": "Deep learning (DL) methods have had a profound impact on computer vision and image analysis applications. Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few. Until very recently, however, DL methods have not been utilized for the upstream task of improving the quality of the images themselves that are produced by computed imaging systems. The process of forming an image from a collection of measurements by use of a computational procedure is referred to as image reconstruction. Almost all modern imaging systems that are utilized in scientific or medical applications are computed in nature and utilize an image reconstruction method to form an image. The next wave in DL methodologies for imaging applications is likely to address the important task of improving the quality of images produced by computed imaging systems [27].\nIn many imaging applications, in order to reduce data-acquisition times or radiation doses in the case of X-ray-based systems, it is desirable to reconstruct an accurate image from an incomplete set of measurements. Here, an incomplete set of measurements refers to one that does not uniquely specify an image that can produce the measured data, even in the idealized situation where noise or other measurement errors are absent. In such cases, the measurement process is not described by an\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nar X\niv :1\n70 9.\n00 58\n4v 1\n[ cs\n.C V\ninjective operator and therefore the inverse operator is not defined. Accordingly, image reconstruction from incomplete data corresponds to an ill-posed inverse problem and a regularized solution must be computed. Bayesian theory provides a natural framework for computing regularized solutions via penalized least squares estimators by incorporating a priori information regarding the sought-after image. For example, image priors that describe sparseness properties are routinely employed and have proven to be successful for certain classes of problems. They are particularly effective when the measurement model satisfies the mathematical conditions prescribed by compressive sampling theory [6]. However, most computed imaging systems do not satisfy these conditions. Although recent advances in generative neural networks are exciting and encouraging [21] [23], the task of specifying an image prior that comprehensively describes the statistical properties of a specified ensemble of images remains a challenging task. Human observers can often reliably identify artifacts in reconstructed images. Codifying this knowledge in a mathematically tractable way such that it can be incorporated into a reconstruction method has proven difficult. These issues have limited the effectiveness of regularized methods for reconstructing images from inconsistent and/or incomplete measurement data.\nDL methods hold great promise for circumventing these limitations and may enable great improvements in image reconstruction performance when the measurement data are incomplete. As mentioned above, for this problem, there exists a large number of images that can produce the measured data; one of these images is the sought-after \u2018true\u2019 image, while the others will contain artifacts and distortions. The fundamental problem is that it is difficult to design a regularization strategy (i.e., optimization program) that results in computation of the true solution, or some accurate approximation of it. To circumvent this, DL methods can be naturally employed to learn domain knowledge that is subsequently exploited by the reconstruction method to improve the accuracy of the reconstructed image. A DL-assisted image reconstruction method would be \u2018intelligent\u2019 in the sense that it is able to utilize this domain knowledge to guide it to arrive at a solution that contains greatly reduced artifact levels as compared to a solution computed by use of a traditional reconstruction method. Intuitively, the DL-assisted reconstruction method would be able to avoid producing an image that contains strong artifacts because the DL model knows what those images look like. As described below, in terms of linear operator theory, the DL model would permit the reconstruction method to accurately estimate the null space component of the image that is invisible to the imaging system.\nIn this paper, a DL-assisted image reconstruction method for use with incomplete data is proposed and investigated. Consider that two ensembles of images are available: one ensemble corresponds to artifact free (\u2018true\u2019) images while the second contains images that are degraded by artifacts and distortions that are attributable to the incompleteness of the measurement data. A convolutional neural network (CNN) is trained by use of these data to learn a mapping that relates the true and artifact-laden images. This mapping is subsequently embedded within an iterative image reconstruction method to guide the iterative method toward a solution that contains greatly reduced artifact levels. The proposed approach holds conceptual similarities to the proximal gradient descent method, which alternates between taking a step along the gradient of some cost function and applying a proximal operator. In the proposed approach, the proximal operator is replaced by the mapping learned by the CNN and the gradient descent update is generalized by use of a reconstruction operator. A novel two-stage training scheme is introduced in order to train the CNN to be used within the proposed framework."}, {"heading": "Related Work", "text": "Extensive work has been performed on applying DL methods to image restoration tasks, such as denoising or in-painting [16, 30, 19]. These tasks share similarities with image reconstruction tasks, but differ in the information provided as input. In image restoration, a degraded image is provided as input, while in image reconstruction, measurements corresponding to some operator applied to the image are provided. Typically, these measurements differ structurally in some significant way from the images themselves. Additionally, many image reconstruction methods require an initial guess of the true image, which itself may be a degraded image.\nImage restoration methods can be combined with image reconstruction methods as a post-processing step to try to correct any artifacts in the reconstructed image. However, since these restoration methods accept only an image as input, it is not possible to consider the measured data during this post-processing step. Thus, in summarizing the related work, the methods have been partitioned into those that apply DL-based image restoration methods to independently reconstructed images and those that consider the measured data as part of a larger DL-based image reconstruction approach. To contrast with the proposed approach, the image restoration methods will be referred to as single-pass approaches, as the images pass through DL-based network a single time.\nDeep Image Restoration: The problem of image restoration using DL techniques has been wellstudied, and, as such, it is not possible to mention all the meaningful contributions. In [16], a deep residual network is proposed for the task of image super-resolution. In [19], an autoencoder style CNN is proposed which makes use of residual-style layers [11], and is applied to the tasks of image denoising and super-resolution. Recently, several groups has have used DL techniques to remove artifacts and noise from images reconstructed from incomplete and/or inconsistent measurement data [7, 1, 28].\nDeep Image Reconstruction: Recently, several groups have proposed using DL techniques to improve image reconstruction. In [12], inference algorithms are unfolded into a series of layers and the parameters of those layers are optimized by a neural network. This technique has been expanded to incorporate many standard inference algorithms and applications [29, 22, 10, 15]. In [18], the original image is directly estimated by a CNN. In [5], the original image is estimated by gradient descent where the estimated image is constrained to lie in the range of a generative CNN. In [20], the proximal operator is replaced by a denoising CNN for an image reconstruction problem.\nThere has been a large amount of work conducted on understanding and improving the optimization of conventional CNNs for the task of image restoration. However, many of the deep image reconstruction techniques are more difficult to train than CNNs, which has limited the complexity of the DL models they employ. In this work, a DL-assisted reconstruction method is proposed that embeds a conventional CNN within an iterative framework. In this way, the method is able to exploit the power of a deep CNN that is relatively easy to train but also is responsive to the measured data."}, {"heading": "2 Statement of image reconstruction problem", "text": "Consider an inverse problems in which one seeks to recover an image f \u2208 Rn from a collection of measurements g \u2208 Rm for m < n. While the proposed approach is more general, for ease of discussion and interpretation, we will focus on the case in which the measured data are related to the true image via\ng = Hf , (1)\nwhere H \u2208 Rm\u00d7n is a linear operator describing the measurement system. Given some H, any object f can be decomposed into two orthogonal components, the measurable component fmeas \u2208 Umeas, and the null space component fnull \u2208 Unull, where Unull \u2261 {f | Hf = 0} and Umeas is its orthogonal complement. A key challenge is how to recover the component of f that lies in Unull. From the definition of Unull, it follows that the measured data g does not contain any information on fnull, which is invisible to the imaging system. Thus, to accurately recover fnull and thereby avoid strong artifacts in the reconstructed f = fmeas + fnull, some a priori knowledge about the set of objects that might be measured is needed.\nThe penalized least squares (PLS) approach to image reconstruction seeks to compute an estimate f\u0302 of the image by minimizing an objective function consisting of a data fidelity (loss) term and a penalty, or regularization, term. For example,\nf\u0302 = arg min f\u2208S\n\u2016Hf \u2212 g\u201622 + \u03bb\u03a6(f), (2)\nwhere S is some, typically convex, set, \u03a6 is a regularization term, and \u03bb > 0 is a scalar parameter that controls the relative weight of the two terms in the objective function."}, {"heading": "3 Approach", "text": "DL-Guided Image Reconstruction The structure of the proposed approach is inspired by that of proximal (or projected) gradient descent. In that approach, an initial guess for the true object f (0) is iteratively refined by first taking a step along the gradient of some cost function C (f) and then applying a proximal operator P that maps the current iterate to:\nf\u0302 (k+1) = P ( f\u0302 (k) \u2212 \u03b1\u2207C ( f\u0302 (k) ))\n(3)\nHere, k is the iteration number and \u03b1 is the step size. In theory, this approach can be very effective. For example, P could be defined as a projection operator onto the set of all artifact-free images. In practice, however, it is difficult to determine a method for computing P except for relatively simple\ncases. This limits the amount and complexity of a priori information that can be encoded in the projection operator.\nTo move beyond this restriction, P is replaced with a quasi-projection operator Q (f ;w), consisting of a CNN parameterized by a set of weights w. These weights will be determined by training the CNN to map images from the space of artifact-laden images to the space of artifact-free images. In this case, the learned operator Q may not strictly satisfy the properties of a projection or proximal operator. However, as demonstrated below, embedding this quasi-projection operator within an iterative reconstruction method can result in images that possess significantly reduced artifact levels as compared to those produced by use conventional (non-DL-based) reconstruction methods.\nAlgorithm 1 General reconstruction procedure Input: w,p,g,H, n,R,Q Output: f\u0302\n1: f\u0302 (0)Q \u2190 0 2: k \u2190 0 {k is the algorithm iteration number.} 3: while k < n do 4: f\u0302 (k+1)R \u2190 R ( f\u0302 (k) Q ;H,g,p\n) 5: f\u0302 (k+1)Q \u2190 Q ( f\u0302 (k+1) R ;w\n) 6: k \u2190 k + 1 7: end while 8: f\u0302 \u2190 f\u0302 (k)Q Traditionally, projection or proximal operators are applied at every iteration during the reconstruction process. However, that would require the quasi-projection operator Q to project the estimated images at early iterations, which may be very inaccurate. Instead, a further generalization of the proximal gradient descent method is proposed. The single gradient descent step performed at each iteration is replaced by a more general approximate reconstruction operatorR (f ;H,g,p), where p is a set of parameters for the reconstruction method. This approximate reconstruction operator should update the current estimate of the object to more closely match the measured data. For example,R could be a solution to the optimization problem given in Eqn. 2 subject to some stopping criteria. As a result, the output ofR should be closer to the sought-after image, yielding a simpler quasi-projection mapping for the CNN to learn. In this way, the training problem is made easier, while Q still learns all the necessary a priori information to improve the reconstructed image given by our conventional reconstruction operatorR. Pseudocode for our algorithm is provided in Alg. 1, where n is the number of timesR and Q are applied. When Q is chosen to be a projection operator and R is chosen to correspond to a single gradient descent step, the proposed approach reduces to the projected gradient descent method as a special case. Further, when n = 1, the proposed approach reduces to the single-pass approach."}, {"heading": "Network Architecture for Establishing Q", "text": "The operator Q represents a mapping from Rn to Rn. When employing a DL model to implement this mapping, there is great freedom in selecting the appropriate network architecture. We base our selection on two main reasons. The first is that recent work has shown that deeper networks are more powerful than shallower networks with the same number of parameters [11],[25]. Deeper networks consist of a larger chain of non-linear layers which allows for a higher level of abstraction. The second reason is that learning a residual mapping is an attractive alternative when there is a high correlation between the input and output. Since the input and output are quite similar for this problem, it is intuitively an easier problem to learn the residual instead of learning the direct mapping.\nThe chosen network architecture for implementing Q corresponds to a deep residual CNN, inspired by [16]. The network contains 20 convolutional layers, with a ReLU layer after each convolutional layer except for the final layer. In all but the final layer, there are 64 filters of size 3\u00d7 3. In the final layer the CNN is mapping back to the original image space so it contains a single 3\u00d7 3 layer. Instead of learning a direct mapping, this network predicts a residual image that is added to the original input to get the final output. Additional details can be found in [16]."}, {"heading": "Training Q", "text": "Conventional training: Given a training set of images F and their corresponding measured data {g = Hf | f \u2208 F}, the weights w are determined by minimizing\nw\u0302 = arg min w\n1\n2 \u2211 i \u2016f(i) \u2212Q ( f\u0302 (1) R,(i);w ) \u201622, (4)\nwhere the subscript (i) denotes the i-th training sample and f\u0302 (k)R,(i) denotes the estimate of the image given by line 4 of Alg. 1 for the k-th iteration and the i-th training sample. This corresponds to optimizing the weights of the CNN using reconstructed images generated byR for an initial guess of all zeros.\nTwo stage training: It was observed that a CNN optimized by the conventional training scheme described above may not generalize well to inputs of f\u0302 (k)R,(i) for k > 1. In order to regularize the weights, a two-stage training scheme was introduced, where the network is initially trained with only zero-initialized reconstructed images as in Eqn. 4. Then, the weights are fine-tuned with intermediate results acquired by applying Alg. 1 with the weights trained in the first stage,\nw\u0302\u2217 = arg min w\u0302\n1\n2 \u2211 i,k \u2016f(i) \u2212Q ( f\u0302 (k) R,(i); w\u0302 ) \u201622, (5)\nwhere k denotes the iteration number during which the reconstructed image was estimated. During training, no additional improvement is made after including 10 intermediate results per image, so n = 10 during this second training stage. This phenomena is likely due to the second stage acting as a data augmentation technique which produces very similar, and therefore redundant, results after n = 10 iterations. Use of dropout or traditional data augmentation techniques lead to worse improvement compared to the two stage training scheme.\nA separate CNN was trained for each of the studies described below. All models were trained in the same way, using ADAM [17], a batchsize of 64 and minimizing the mean squared error loss as in Eqn. 4 and 5. The default parameters for ADAM [17] were used, except for a learning rate of 0.0001. Each model was trained for 3 million iterations in each stage, taking around 10 hours total on 2 NVIDIA Titan X GPU cards. We employed the weight initialization strategy introduced in [9]."}, {"heading": "4 Computer-simulation studies", "text": "As a demonstration of our approach, a canonical image reconstruction problem in X-ray computed tomography (CT) that utilizes very limited measurements was considered."}, {"heading": "Sample generation", "text": "Taking inspiration from the Shepp-Logan phantom [14], the generated images are made up of one main ellipse and between 2 and 7 other minor ellipses. The number and characteristics of the ellipses were chosen randomly. Additional details about the sample generation process are provided in the supplementary materials. This particular form for the samples allowed use of a closed form solution for calculating the measured data. This provided an independent way to calculate the measured data that did not depend on the numerical model H.\nThe images were of size 256 \u00d7 256, with 7500 training images, 1000 validation images, and 500 testing images. The validation images were used to optimize hyper-parameters, and the test images where used to evaluate performance only once."}, {"heading": "X-ray CT forward model", "text": "An idealized 2-D X-ray CT forward model is considered. A series of parallel X-rays are transmitted through a 2-D object with the intensity of the X-rays decreasing as they travel through the object. The resulting intensity of the transmitted X-rays is recorded by a linear detector. The detector is rotated about the object and this process is repeated for a collection of tomographic views. Typically, the detector is swept across an angular range of 180\u25e6. Here, we consider the limited-view case in which the angular coverage is much less than 180\u25e6.\nThere exists two main sources of error when reconstructing images. The first source is model error, where the assumed forward operator, H, does not correspond to the forward operator that generated the measured data. In practice, H cannot exactly capture all properties of a real-world imaging system so there is always some amount of model error. In simulations, we can construct a scenario with no model error by using the same H in the generation of the measured data by Eqn. 1 and in the reconstruction. This scenario is referred to as inverse crime. The second source of error is noise in the measured data. This occurs due to imperfections in the measurement equipment, and we can simulate this phenomena by treating the measured data as a random vector.\nIn this work, we simulated three different scenarios: (1) the inverse crime scenario, where we have no model error and no noise in the measured data; (2) a scenario with model error but no stochastic\nnoise; and (3) a scenario that contains both model error and stochastic noise in the measured data. We simulated noise in the measured data by introducing Gaussian noise to g with a standard deviation equal to 2% of the maximum of g.\nFor the non-inverse-crime scenarios, we use three different ranges of tomographic view angles: 60, 100, and 140 degrees, with one view at each degree. These angular ranges all correspond to a severely under-determined problems that cannot be accurately solved with existing methods. For the inverse crime case, we only consider the 60 degree case. In all cases, the detector has 256 elements."}, {"heading": "Image reconstruction methods", "text": "In this work, three different formulations of the optimization problem given by Eqn. 2 were considered for purposes of comparison, corresponding to different choices of S and \u03a6 (f):\n1. Least squares (LS): S = Rn, \u03a6 (f) = 0 2. Non-negative least squares (LS-NN): S = Rn\u22650, \u03a6 (f) = 0\n3. Penalized least squares with TV regularization (PLS-TV): S = Rn\u22650, \u03a6 (f) = \u2016f\u2016TV ,\nwhere Rn\u22650 denotes the set of non-negative real numbers and \u2016f\u2016TV denotes the total-variation (TV) semi-norm.\nThe proposed DL-assisted approach requires some choice for the approximate reconstruction operator R (line 4 in Alg. 1). In this work, the action ofR was computed by approximately minimizing the LS objective function or the LS-NN objective function.\nThe LS objective function was employed in the inverse crime case. The least squares solution was computed by applying the Moore-Penrose pseudoinverse of H, denoted H\u22121MP , to the measured data. The Moore-Penrose pseudoinverse was computed by first performing singular value decomposition of H and then employing the method described in [3].\nThe LS-NN objective function was employed in the case of inconsistent data. Empirically, it was observed that this produced superior results in the case of inconsistent data, perhaps as the nonnegativity constraint results in estimated images that are closer to the true images. As a result, the mapping that must be learned by the quasi-projection operator Q may be simpler and thus easier to approximate with a given finite-capacity network architecture. In this case, the LS-NN optimization problem was solved by projected gradient descent.\nFor all iterative methods, a constant step size of 0.75 was employed. The stopping criteria was set to be when the relative change in the `2-norm of the object between consecutive iterations was less than 0.001."}, {"heading": "5 Numerical experiments", "text": ""}, {"heading": "Interpretation", "text": "The least challenging version of the inverse problem, the inverse crime case, was first considered. The operatorR was specified to compute the solution of the LS optimization problem. This solution can be calculated by applying the Moore-Penrose pseudoinverse to the measured data. Since the measured data is consistent and H\u22121MPH is the projection operator onto Umeas, R, in this case, recovers the measurable component of the true object. The null space component of the estimated object will remain unchanged from that of the initial guess. Further, any alterations to measurable component made byQ can be corrected by applyingR while leaving the null component unchanged. In this way, R and Q each take responsibility for estimating different components of the object: the measurable component is estimated byR and the null component is estimated by Q. By applying each of these operators in an alternating fashion, the information in the measured data and the learned a priori information encoded in the network are jointly considered, allowing both the measurable space and null space components to be more accurately reconstructed.\nThis behavior is reflected in the plots of the RMSEs in the measurable and null space components, shown in Fig. 1. The RMSE of the null space component is progressively improved with repeated application of Q. The RMSE of the measurable space component estimated by R (e.g. before application of Q) is quite small for all iterations, as this component can be reliably estimated from the measured data. The RMSE of the measurable space component is increased after applying the\nQ operator, but repeated application of R recovers the high accuracy estimate of the measurable space component. With iteration, the method converges to an estimate that has low RMSE in both the measurable and null space components.\nWhen R does not correspond to the solution of the LS optimization problem, R may make changes to the estimated null space component. Still, the division of responsibility in which R estimates the measurable space component and Q estimates the null space component may largely, though perhaps not strictly, hold true. While this approach does not necessarily have as simple an interpretation, it may be beneficial for two reasons. First, if the output ofR is closer to the true object, the mapping that must be learned by the Q operator may be simpler, resulting in an easier training task. Second, the learned network may not strictly enforce simple constraints, such as non-negativity, which can be readily included within a conventional reconstruction approach. By incorporating these constraints withinR, both learned and user-specified a priori information can be included within the proposed framework."}, {"heading": "Results", "text": "The proposed approach was compared with a single-pass approach and PLS-TV method. In the DL-assisted approach, little to no increase in\nperformance was observed after 5 iterations; thus n = 5 was employed.\nIn order to compare with the single-pass approach (i.e., CNN-based image restoration), a CNN with the same architecture described above was initially trained using the conventional training scheme. The performance of the single-pass CNN increased when trained with the two stage scheme. This performance increase can be explained by the additional training data acting in the capacity of common data augmentation techniques which increase the ability of the CNN to generalize to new data. Therefore, to fairly compare the single-pass approach with the proposed DL-assisted reconstruction approach, the same CNN is used for both methods.\nThe PLS-TV optimization problem was solved using the FISTA [4] with an initial guess of all zeros. This approach represents a state-of-the-art method for sparse image reconstruction [24]. It should be especially effective for the piece-wise constant images considered in this work, which possess\nrelatively sparse gradient maps. The regularization parameter was swept using a grid search and the image corresponding to the lowest RMSE was selected for comparison with the proposed approach.\nRepresentative reconstructed images for the 60 and 100 degree noisy cases are displayed in Figs. 2 and 3. None of the example images considered were contained in the training set. Additionally, results for the other cases are presented in the supplementary material. The PLS-TV reconstruction was quite well suited to remove noise from the measured data, but it was not as successful at removing streaking artifacts. It is apparent that a single-pass with the CNN significantly improved the accuracy of the reconstructed images, but the proposed approach provided substantial further improvement.\nFor each case, the performance was evaluated on 500 test images. The average root mean squared error (RMSE) and structural similarity (SSIM) were computed as summary measures of performance. RMSE corresponds to the pixel-wise difference between the original image and the reconstructed image, while SSIM attempts to measure differences between images in a manner more consistent with human visual perception. As indicated in Table 1, the proposed approach produces the best measures for all test cases. Interestingly, the performance of PLS-TV varied little between the noisy and noiseless cases, which suggests it performed extremely well at removing the noise from the measured data. The single-pass and the proposed approach performed worse in the noisy cases compared with the noiseless cases, with the single-pass approach achieving worse SSIM than PLS-TV for the noisy cases.\nThe LS-NN reconstructions are significantly worse than PLS-TV reconstructions, yet the DL approaches performed quite well using the LS-NN as the R operator. This suggests a significant possible performance increase in using PLS-TV in the DL approaches, as PLS-TV successfully removes stochastic noise from the measured data."}, {"heading": "6 Conclusion", "text": "An approach was presented that embeds a conventional deep CNN within an iterative framework for the task of image reconstruction. Due to its iterative nature, our approach balances the information available in the measured data with the learned a priori information encoded within the CNN. Experimental results and our analysis show our approach achieves better results than a common single-pass CNN-based image restoration approach and a state-of-the-art reconstruction method that exploits sparsity for regularization. Our framework is general enough to incorporate other variants of R, such as ones that estimate a PLS-TV solution, and can be applied to fields outside image reconstruction as well."}], "references": [{"title": "Deep learning for photoacoustic tomography from sparse data", "author": ["Stephan Antholzer", "Markus Haltmeier", "Johannes Schwab"], "venue": "arXiv preprint arXiv:1704.04587,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2017}, {"title": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "author": ["Vijay Badrinarayanan", "Alex Kendall", "Roberto Cipolla"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2017}, {"title": "Foundations of image science", "author": ["H.H. Barrett", "K.J. Myers"], "venue": "Wiley series in pure and applied optics. Wiley-Interscience,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["Amir Beck", "Marc Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Compressed sensing using generative models", "author": ["Ashish Bora", "Ajil Jalal", "Eric Price", "Alexandros G Dimakis"], "venue": "arXiv preprint arXiv:1703.03208,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2017}, {"title": "Stable signal recovery from incomplete and inaccurate measurements", "author": ["Emmanuel J. Cand\u00e8s", "Justin K. Romberg", "Terence Tao"], "venue": "Communications on Pure and Applied Mathematics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Low-dose ct with a residual encoder-decoder convolutional neural network (red-cnn)", "author": ["Hu Chen", "Yi Zhang", "Mannudeep K Kalra", "Feng Lin", "Peixi Liao", "Jiliu Zhou", "Ge Wang"], "venue": "arXiv preprint arXiv:1702.00288,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2017}, {"title": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "author": ["Liang-Chieh Chen", "George Papandreou", "Iasonas Kokkinos", "Kevin Murphy", "Alan L Yuille"], "venue": "arXiv preprint arXiv:1606.00915,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio"], "venue": "International conference on artificial intelligence and statistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "A Deep Learning Architecture for Limited-Angle Computed Tomography Reconstruction, pages 92\u201397", "author": ["Kerstin Hammernik", "Tobias W\u00fcrfl", "Thomas Pock", "Andreas Maier"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2017}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Deep unfolding: Model-based inspiration of novel deep architectures", "author": ["John R. Hershey", "Jonathan Le Roux", "Felix Weninger"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Globally and Locally Consistent Image Completion", "author": ["Satoshi Iizuka", "Edgar Simo-Serra", "Hiroshi Ishikawa"], "venue": "ACM Transactions on Graphics (Proc. of SIGGRAPH 2017),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2017}, {"title": "Fundamentals of Digital Image Processing, page 439", "author": ["Anil K. Jain"], "venue": "Englewood Cliffs, NJ, Prentice,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1989}, {"title": "Learning Optimal Nonlinearities for Iterative Thresholding Algorithms", "author": ["U.S. Kamilov", "H. Mansour"], "venue": "IEEE Signal Processing Letters,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Accurate image super-resolution using very deep convolutional networks", "author": ["Jiwon Kim", "Jung Kwon Lee", "Kyoung Mu Lee"], "venue": "In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR Oral),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik P. Kingma", "Jimmy Ba"], "venue": "CoRR, abs/1412.6980,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Reconnet: Non-iterative reconstruction of images from compressively sensed random measurements", "author": ["Kuldeep Kulkarni", "Suhas Lohit", "Pavan Turaga", "Ronan Kerviche", "Amit Ashok"], "venue": "arXiv preprint arXiv:1601.06892,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2016}, {"title": "Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections", "author": ["Xiaojiao Mao", "Chunhua Shen", "Yu-Bin Yang"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Learning proximal operators: Using denoising networks for regularizing inverse imaging problems", "author": ["Tim Meinhardt", "Michael M\u00f6ller", "Caner Hazirbas", "Daniel Cremers"], "venue": "arXiv preprint arXiv:1704.03488,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2017}, {"title": "Plug & play generative networks: Conditional iterative generation of images in latent space", "author": ["Anh Nguyen", "Jason Yosinski", "Yoshua Bengio", "Alexey Dosovitskiy", "Jeff Clune"], "venue": "arXiv preprint arXiv:1612.00005,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Learning the weight matrix for sparsity averaging in compressive imaging", "author": ["Dimitris Perdios", "Adrien Georges Jean Besson", "Philippe Rossinelli", "Jean-Philippe Thiran"], "venue": "In IEEE International Conference on Image Processing (ICIP 2017),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2017}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Alec Radford", "Luke Metz", "Soumith Chintala"], "venue": "CoRR, abs/1511.06434,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization", "author": ["Emil Y Sidky", "Xiaochuan Pan"], "venue": "Physics in medicine and biology,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Inception-v4, inceptionresnet and the impact of residual connections on learning", "author": ["Christian Szegedy", "Sergey Ioffe", "Vincent Vanhoucke", "Alex Alemi"], "venue": "arXiv preprint arXiv:1602.07261,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "A perspective on deep imaging", "author": ["Ge Wang"], "venue": "IEEE Access,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Accelerating magnetic resonance imaging via deep learning", "author": ["Shanshan Wang", "Zhenghang Su", "Leslie Ying", "Xi Peng", "Shun Zhu", "Feng Liang", "Dagan Feng", "Dong Liang"], "venue": "In Biomedical Imaging (ISBI),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Deep admm-net for compressive sensing mri", "author": ["Yan Yang", "Jian Sun", "Huibin Li", "Zongben Xu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Semantic image inpainting with perceptual and contextual losses", "author": ["Raymond Yeh", "Chen Chen", "Teck Yian Lim", "Mark Hasegawa-Johnson", "Minh N Do"], "venue": "arXiv preprint arXiv:1607.07539,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2016}], "referenceMentions": [{"referenceID": 10, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 99, "endOffset": 107}, {"referenceID": 24, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 99, "endOffset": 107}, {"referenceID": 7, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 122, "endOffset": 128}, {"referenceID": 1, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 122, "endOffset": 128}, {"referenceID": 28, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 151, "endOffset": 159}, {"referenceID": 12, "context": "Such methods are now ubiquitous and routinely employed for tasks that include image classification [11, 26], segmentation [8, 2], and image completion [30, 13], to name a few.", "startOffset": 151, "endOffset": 159}, {"referenceID": 25, "context": "The next wave in DL methodologies for imaging applications is likely to address the important task of improving the quality of images produced by computed imaging systems [27].", "startOffset": 171, "endOffset": 175}, {"referenceID": 5, "context": "They are particularly effective when the measurement model satisfies the mathematical conditions prescribed by compressive sampling theory [6].", "startOffset": 139, "endOffset": 142}, {"referenceID": 20, "context": "Although recent advances in generative neural networks are exciting and encouraging [21] [23], the task of specifying an image prior that comprehensively describes the statistical properties of a specified ensemble of images remains a challenging task.", "startOffset": 84, "endOffset": 88}, {"referenceID": 22, "context": "Although recent advances in generative neural networks are exciting and encouraging [21] [23], the task of specifying an image prior that comprehensively describes the statistical properties of a specified ensemble of images remains a challenging task.", "startOffset": 89, "endOffset": 93}, {"referenceID": 15, "context": "Extensive work has been performed on applying DL methods to image restoration tasks, such as denoising or in-painting [16, 30, 19].", "startOffset": 118, "endOffset": 130}, {"referenceID": 28, "context": "Extensive work has been performed on applying DL methods to image restoration tasks, such as denoising or in-painting [16, 30, 19].", "startOffset": 118, "endOffset": 130}, {"referenceID": 18, "context": "Extensive work has been performed on applying DL methods to image restoration tasks, such as denoising or in-painting [16, 30, 19].", "startOffset": 118, "endOffset": 130}, {"referenceID": 15, "context": "In [16], a deep residual network is proposed for the task of image super-resolution.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "In [19], an autoencoder style CNN is proposed which makes use of residual-style layers [11], and is applied to the tasks of image denoising and super-resolution.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "In [19], an autoencoder style CNN is proposed which makes use of residual-style layers [11], and is applied to the tasks of image denoising and super-resolution.", "startOffset": 87, "endOffset": 91}, {"referenceID": 6, "context": "Recently, several groups has have used DL techniques to remove artifacts and noise from images reconstructed from incomplete and/or inconsistent measurement data [7, 1, 28].", "startOffset": 162, "endOffset": 172}, {"referenceID": 0, "context": "Recently, several groups has have used DL techniques to remove artifacts and noise from images reconstructed from incomplete and/or inconsistent measurement data [7, 1, 28].", "startOffset": 162, "endOffset": 172}, {"referenceID": 26, "context": "Recently, several groups has have used DL techniques to remove artifacts and noise from images reconstructed from incomplete and/or inconsistent measurement data [7, 1, 28].", "startOffset": 162, "endOffset": 172}, {"referenceID": 11, "context": "In [12], inference algorithms are unfolded into a series of layers and the parameters of those layers are optimized by a neural network.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "This technique has been expanded to incorporate many standard inference algorithms and applications [29, 22, 10, 15].", "startOffset": 100, "endOffset": 116}, {"referenceID": 21, "context": "This technique has been expanded to incorporate many standard inference algorithms and applications [29, 22, 10, 15].", "startOffset": 100, "endOffset": 116}, {"referenceID": 9, "context": "This technique has been expanded to incorporate many standard inference algorithms and applications [29, 22, 10, 15].", "startOffset": 100, "endOffset": 116}, {"referenceID": 14, "context": "This technique has been expanded to incorporate many standard inference algorithms and applications [29, 22, 10, 15].", "startOffset": 100, "endOffset": 116}, {"referenceID": 17, "context": "In [18], the original image is directly estimated by a CNN.", "startOffset": 3, "endOffset": 7}, {"referenceID": 4, "context": "In [5], the original image is estimated by gradient descent where the estimated image is constrained to lie in the range of a generative CNN.", "startOffset": 3, "endOffset": 6}, {"referenceID": 19, "context": "In [20], the proximal operator is replaced by a denoising CNN for an image reconstruction problem.", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "The first is that recent work has shown that deeper networks are more powerful than shallower networks with the same number of parameters [11],[25].", "startOffset": 138, "endOffset": 142}, {"referenceID": 15, "context": "The chosen network architecture for implementing Q corresponds to a deep residual CNN, inspired by [16].", "startOffset": 99, "endOffset": 103}, {"referenceID": 15, "context": "Additional details can be found in [16].", "startOffset": 35, "endOffset": 39}, {"referenceID": 16, "context": "All models were trained in the same way, using ADAM [17], a batchsize of 64 and minimizing the mean squared error loss as in Eqn.", "startOffset": 52, "endOffset": 56}, {"referenceID": 16, "context": "The default parameters for ADAM [17] were used, except for a learning rate of 0.", "startOffset": 32, "endOffset": 36}, {"referenceID": 8, "context": "We employed the weight initialization strategy introduced in [9].", "startOffset": 61, "endOffset": 64}, {"referenceID": 13, "context": "Taking inspiration from the Shepp-Logan phantom [14], the generated images are made up of one main ellipse and between 2 and 7 other minor ellipses.", "startOffset": 48, "endOffset": 52}, {"referenceID": 2, "context": "The Moore-Penrose pseudoinverse was computed by first performing singular value decomposition of H and then employing the method described in [3].", "startOffset": 142, "endOffset": 145}, {"referenceID": 3, "context": "The PLS-TV optimization problem was solved using the FISTA [4] with an initial guess of all zeros.", "startOffset": 59, "endOffset": 62}, {"referenceID": 23, "context": "This approach represents a state-of-the-art method for sparse image reconstruction [24].", "startOffset": 83, "endOffset": 87}], "year": 2017, "abstractText": "An approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented. Specifically, we utilize a convolutional neural network (CNN) as a quasi-projection operator within a least squares minimization procedure. The CNN is trained to encode high level information about the class of images being imaged; this information is utilized to mitigate artifacts in intermediate images produced by use of an iterative method. The structure of the method was inspired by the proximal gradient descent method, where the proximal operator is replaced by a deep CNN and the gradient descent step is generalized by use of a linear reconstruction operator. It is demonstrated that this approach improves image quality for several cases of limited-view image reconstruction and that using a CNN in an iterative method increases performance compared to conventional image reconstruction approaches. We test our method on several limited-view image reconstruction problems. Qualitative and quantitative results demonstrate state-of-the-art performance.", "creator": "LaTeX with hyperref package"}}}