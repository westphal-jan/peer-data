{"id": "1709.03406", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "Social Media Text Processing and Semantic Analysis for Smart Cities", "abstract": "with the ensuing rise of social media, people obtain and share information almost instantly on a 24 / 7 basis. many research areas have tried to gain valuable insights far from incorporating these large large volumes of freely available user generated content.", "histories": [["v1", "Mon, 11 Sep 2017 14:30:35 GMT  (8207kb,D)", "http://arxiv.org/abs/1709.03406v1", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL cs.CY", "authors": ["jo\\~ao filipe figueiredo pereira"], "accepted": false, "id": "1709.03406"}, "pdf": {"name": "1709.03406.pdf", "metadata": {"source": "CRF", "title": "Social Media Text Processing and Semantic Analysis for Smart Cities", "authors": ["Jo\u00e3o Filipe Figueiredo Pereira", "Rosaldo Jos\u00e9 Fernandes Rossetti", "Pedro dos Santos", "Saleiro da Cruz", "Jo\u00e3o Filipe Figueiredo"], "emails": [], "sections": [{"heading": null, "text": "FACULDADE DE ENGENHARIA DA UNIVERSIDADE DO PORTO\nSocial Media Text Processing and Semantic Analysis for Smart Cities\nJo\u00e3o Filipe Figueiredo Pereira\nMestrado Integrado em Engenharia Inform\u00e1tica e Computa\u00e7\u00e3o\nSupervisor: Rosaldo Jos\u00e9 Fernandes Rossetti\nCo-supervisor: Pedro dos Santos Saleiro da Cruz\nJune 27, 2017\nar X\niv :1\n70 9.\n03 40\n6v 1\n[ cs\n.S I]\n1 1\nSe p\n20 17\nSocial Media Text Processing and Semantic Analysis for Smart Cities\nJo\u00e3o Filipe Figueiredo Pereira\nMestrado Integrado em Engenharia Inform\u00e1tica e Computa\u00e7\u00e3o\nJune 27, 2017\nAbstract\nWith the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to gain valuable insights from these large volumes of freely available user generated content. The research areas of intelligent transportation systems and smart cities are no exception. However, extracting meaningful and actionable knowledge from user generated content is a complex endeavor. First, each social media service has its own data collection specificities and constraints, second the volume of messages/posts produced can be overwhelming for automatic processing and mining, and last but not the least, social media texts are usually short, informal, with a lot of abbreviations, jargon, slang and idioms.\nIn this thesis, we try to tackle some of the aforementioned challenges with the goal of extracting knowledge from social media streams that might be useful in the context of intelligent transportation systems and smart cities. We designed and developed a framework for collection, processing and mining of geo-located Tweets. More specifically, it provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization.\nWe performed an extensive exploratory data analysis of geo-located tweets in 5 different cities: Rio de Janeiro, S\u00e3o Paulo, New York City, London and Melbourne, comprising a total of more than 43 millions tweets in a period of 3 months. Furthermore, we performed a large scale topic modelling comparison between Rio de Janeiro and S\u00e3o Paulo. As far as we know this is the largest scale content analysis of geo-located tweets from Brazil. Interestingly, most of the topics are shared between both cities which despite being in the same country are considered very different regarding population, economy and lifestyle.\nWe take advantage of recent developments in word embeddings and train such representations from the collections of geo-located tweets. We then use a combination of bag-of-embeddings and traditional bag-of-words to train travel-related classifiers in both Portuguese and English to filter travel-related content from non-related. We created specific gold-standard data to perform empirical evaluation of the resulting classifiers. Results are in line with research work in other application areas by showing the robustness of using word embeddings to learn word similarities that bag-of-words is not able to capture. The source code and resources developed in this dissertation will be publicly available to foster further developments by the research community in smart cities and intelligent transportation systems.\ni\nii\nResumo\nDevido \u00e0 ascens\u00e3o das Redes Sociais, as pessoas obt\u00eam e partilham informa\u00e7\u00e3o quase que instantaneamente 24/7. Muitas \u00e1reas de investiga\u00e7\u00e3o tentaram extrair informa\u00e7\u00f5es importantes destes grandes volumes de conte\u00fado, gerado por utilizadores, e livremente dispon\u00edveis. As \u00e1reas de investiga\u00e7\u00e3o de sistemas inteligentes de transportes e de cidades inteligentes (smart cities) n\u00e3o s\u00e3o excep\u00e7\u00e3o. Contudo, extrair conhecimento acion\u00e1vel e significativo de conte\u00fado gerado por utilizadores exige um esfor\u00e7o complexo. Primeiro, cada servi\u00e7o de social media possui as suas pr\u00f3prias especificidades e restri\u00e7\u00f5es para o m\u00e9todo de recolha dos dados; em segundo lugar, o volume de mensagens produzidas pode ser esmagador para o processamento autom\u00e1tico e prospe\u00e7\u00e3o; e por \u00faltimo, n\u00e3o menos importante, os textos das redes sociais s\u00e3o, geralmente, curtos, informais, com muitas abrevia\u00e7\u00f5es, jarg\u00f5es, g\u00edrias e express\u00f5es idiom\u00e1ticas.\nNesta disserta\u00e7\u00e3o, tentamos abordar alguns dos desafios acima mencionados com o objectivo de extrair conhecimento de mensagens das redes sociais que possam ser \u00fateis no contexto de sistemas inteligentes de transportes e cidades inteligentes (smart cities). N\u00f3s idealizamos e desenvolvemos uma framework para a recolha de dados, processamento e prospe\u00e7\u00e3o de Tweets geo-localizados. Mais especificamente, a framework fornece funcionalidades para a recolha paralela de tweets geo-localizados de bounding-boxes (cidades ou regi\u00f5es), incluindo filtragem de tweets n\u00e3o preenchidos, pr\u00e9-processamento de texto para a l\u00edngua portuguesa e inglesa, modelagem de t\u00f3picos e classificadores de texto espec\u00edficos para transportes, bem como, agrega\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados.\nN\u00f3s realizamos uma an\u00e1lise explorat\u00f3ria extensiva relativamente a tweets geo-referenciados para 5 cidades diferentes: Rio de Janeiro, S\u00e3o Paulo, Nova Iorque, Londres e Melbourne, perfazendo um total de mais de 43 milh\u00f5es de tweets num per\u00edodo de 3 meses. Posteriormente, n\u00f3s realiz\u00e1mos modela\u00e7\u00e3o de t\u00f3picos em grande escala entre as cidades do Rio de janiero e S\u00e3o Paulo. Tanto quanto n\u00f3s conhecemos, esta \u00e9 a an\u00e1lise de conte\u00fado em maior escala para tweets geo-referenciados no Brasil. Curiosamente, a maioria dos t\u00f3picos detectados s\u00e3o partilhados por ambas as cidades, que apesar de pertecerem ao mesmo pa\u00eds, s\u00e3o muito diferentes em termos de popula\u00e7\u00e3o, economia e estilo de vida.\nN\u00f3s tiramos partido dos desenvolvimentos recentes em word embeddings e treinamos tais representa\u00e7\u00f5es a partir das cole\u00e7\u00f5es de tweets geo-referenciados. N\u00f3s ent\u00e3o usamos a combina\u00e7\u00e3o dos bag-of-embedding e dos tradicionais bag-of-words para treinar os classificadores relacionados com viagens, tanto em Portugu\u00eas como em Ingl\u00eas, para filtrar conte\u00fado relacionado com transportes de conte\u00fado n\u00e3o relacionado. N\u00f3s criamos dados gold-standard espec\u00edficos para realizar an\u00e1lise emp\u00edrica dos classificadores resultantes. Os resultados est\u00e3o coerentes com o trabalho de investiga\u00e7\u00e3o realizado em outras \u00e1reas de aplica\u00e7\u00e3o demonstrando a robustez da utiliza\u00e7\u00e3o de word embeddings para aprender similaridades que os bag-of-words n\u00e3o s\u00e3o capazes de capturar. O c\u00f3digo fonte e os recursos desenvolvidos nesta disserta\u00e7\u00e3o estar\u00e3o publicamente dispon\u00edveis a fim de motivar outros desenvolvimentos pela comunidade cient\u00edfica em smart cities e sistemas de transportes inteligentes.\niii\niv"}, {"heading": "Acknowledgements", "text": "First of all, my deep gratitude to my friends for being on my side when I was a bit down.\nTo my companions at Lab I120, Jo\u00e3o Neto, Jos\u00e9 Pinto, Jo\u00e3o Pedro Dias and Lu\u00eds Reis (\u03c17 Boyz): thank you for the funny moments during the whole dissertation period, specifically, during the tough process of writing up the document.\nTo my colleagues, specially, Henrique Ferrolho: thank you for the friendship, patience and support in these five long years. Now, I am sure that more challenges are coming to us which may imply distance but besides that I truly believe that in the future we still would cross paths at the professional or even academic course.\nTo Professor Rosaldo Rossetti and Pedro Saleiro, thank you very much for all support, dedication, enthusiasm and knowledge passed to me. During each task you defined in the dissertation period, I was able to improve myself in both academic and social levels.\nTo the institution that host me, Faculty of Engineering of University of Porto (FEUP), as well as to all of its docents that guide me during this Master\u2019s program, I am thankful for everything I have learn until now.\nLast and more important, I would like to express my deep gratitude to my mother, Ana Brito, and my father, J\u00falio Pereira, for all the sacrifice and effort made to assure my future and concede me this opportunity to fulfil a dream: be graduated. I hope this achievement of mine make you very proud and I wish all success for both mine and your\u2019s ambitions and goals in the future. Like always, you know that you can count on me for everything you need.\nJo\u00e3o Pereira\nv\nvi\n\u201cLife is too short for long-term grudges.\u201d\nElon Musk\nvii\nviii\nContents"}, {"heading": "1 Introduction 1", "text": "1.1 Scope and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.3 Aim and Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.4 Document Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4"}, {"heading": "2 Background and Literature Review 7", "text": "2.1 Smart Cities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.2 Intelligent Transportation Systems . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.3 Social Media Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.4 Text Mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.4.1 Topic Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.4.2 Text Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.5 Related Social Media Frameworks . . . . . . . . . . . . . . . . . . . . . . . . . 18 2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19"}, {"heading": "3 Framework 21", "text": "3.1 Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.2 Architecture Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.3 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3.1 Data Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.4 Text Pre-processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.5 Text Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n3.5.1 Topic Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.5.2 Travel-related Classification . . . . . . . . . . . . . . . . . . . . . . . . 30\n3.6 Data Storage and Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.7 Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33"}, {"heading": "4 Exploratory Data Analysis 35", "text": "4.1 Geographic Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 4.2 Temporal Frequencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 4.3 Content Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46"}, {"heading": "5 Text Analytics Experiments 49", "text": "5.1 Topic Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5.1.1 Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\nix\nCONTENTS\n5.1.2 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 5.2 Travel-related Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n5.2.1 Rio de Janeiro and S\u00e3o Paulo . . . . . . . . . . . . . . . . . . . . . . . . 53 5.2.2 New York City . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 5.2.3 Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63"}, {"heading": "6 Conclusions and Future Work 65", "text": "6.1 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 6.2 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 6.3 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 6.4 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\nAcronyms 71\nGlossary 73\nReferences 75\nx\nList of Figures\n2.1 Smart City conjecture of four forces. Source: [Ang15] . . . . . . . . . . . . . . . 8\n3.1 Framework Architecture Overview . . . . . . . . . . . . . . . . . . . . . . . . . 23 3.2 Bounding-boxes filtering process . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.3 Plate notation of Latent Dirichlet Allocation (LDA) by Blei et al. [BNJ03] . . . 29\n4.1 Search Bounding-boxes for the data collection . . . . . . . . . . . . . . . . . . . 36 4.2 Exploratory analysis in Brazilian cities . . . . . . . . . . . . . . . . . . . . . . . 38 4.3 Exploratory analysis in English-speaking cities . . . . . . . . . . . . . . . . . . 39 4.4 Daily volume of tweets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 4.5 Days-of-the-week box-plots for the volume of tweets . . . . . . . . . . . . . . . 42 4.6 Hour-of-the-day box-plots for the volume of tweets . . . . . . . . . . . . . . . . 43 4.7 Log-log plots of users distribution . . . . . . . . . . . . . . . . . . . . . . . . . 46\n5.1 Day-of-the-week Twitter activity . . . . . . . . . . . . . . . . . . . . . . . . . . 52 5.2 ROC Curve of SVM, LR and RF experiences . . . . . . . . . . . . . . . . . . . 55 5.3 Positive Predicted Tweets per Day of Week . . . . . . . . . . . . . . . . . . . . 55 5.4 Rio de Janeiro heat map to the positive tweets . . . . . . . . . . . . . . . . . . . 56 5.5 S\u00e3o Paulo heat map to the positive tweets . . . . . . . . . . . . . . . . . . . . . 57 5.6 SVM model with BoE(200) for each travel mode . . . . . . . . . . . . . . . . . 61 5.7 Spatial density of the predicted tweets . . . . . . . . . . . . . . . . . . . . . . . 62\nxi\nLIST OF FIGURES\nxii\nList of Tables\n2.1 Text mining issues by Stavrianou [SAN07] . . . . . . . . . . . . . . . . . . . . 12 2.2 Brief overview of the related work for topic modelling . . . . . . . . . . . . . . 15 2.3 Brief overview of the related work for text classification - Best Experiments . . . 17\n4.1 Collecting Bounding-boxes Coordinates (South-West and North-East) . . . . . . 36 4.2 Twitter Default Bounding-boxes Coordinates (South-West and North-East) . . . . 37 4.3 Datasets composition according bounding-box analysis . . . . . . . . . . . . . . 37 4.4 Volume of tweets for each type of geo-location . . . . . . . . . . . . . . . . . . 37 4.5 Percentage of Metadata composing the datasets . . . . . . . . . . . . . . . . . . 45\n5.1 Example of the topics labels . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 5.2 LDA model final results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 5.3 Travel terms used to build the training set . . . . . . . . . . . . . . . . . . . . . 54 5.4 Performance results with 100 sized vectors for BoE . . . . . . . . . . . . . . . . 55 5.5 English-speaking tweets datasets . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.6 New York City First Experiment Results . . . . . . . . . . . . . . . . . . . . . . 59 5.7 Leave-one-group-out expirement datasets . . . . . . . . . . . . . . . . . . . . . 60 5.8 Leave one group out experiments results for SVM, LR and RF classifiers . . . . . 60 5.9 Sample of tweet messages correctly classified . . . . . . . . . . . . . . . . . . . 62\nxiii\nChapter 1\nIntroduction"}, {"heading": "1.1 Scope and Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1", "text": ""}, {"heading": "1.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2", "text": ""}, {"heading": "1.3 Aim and Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4", "text": ""}, {"heading": "1.4 Document Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4", "text": ""}, {"heading": "1.1 Scope and Motivation", "text": "With the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to extract valuable insights from these large volumes of user generated content. The research areas of intelligent transportation systems and smart cities are no exception. Transforming this data into valuable information can be meaningful and useful for city governance, support traffic management and control, transportation services or even ordinary citizens wanting to be constantly informed about their cities. For instance, if a social media message is about the service quality of the bus transportation mode - \"My bus is delayed.\" - then the responsible entities should have the necessary tools and information to tackle the existent problem. However, to extract the knowledge to handle the solving task, first it is necessary to filter travel-related messages from the non-related and only then explore the topic, sentiment, or even the target of its content.\nSocial Media Content (SMC) is still in the process of maturation regarding its use in the smart cities [BAG+12] and transportation [GTGMK+14] fields; users tend to publicly share events in which they participate, as well as the ones related to the operation of the transportation network, such as accidents and other disruptions. Indeed, this type of content is also targeted by studies about opinion mining, human behavior and respective activity patterns, political issues, social communication (e.g. news websites). Such studies focus their efforts on ways of understanding what people think and talk about and transform this knowledge into actionable and meaningful\n1\nIntroduction\ncontent such as the identification of terrorist movement [ZNHG16], potential news to be reported or even the prediction of the sentiment polarity regarding politicians, for example.\nThe exploration of SMC brings particular advantages, under virtually no cost, such as real-time data and content authenticity due to its human generated nature [KMN+17] since users express the reason why they prefer a certain product or a certain transportation mode service to others. The availability of this kind of data may be seen as its main advantage. Social media companies provide tools to the developers community that do not require additional costs regarding its exploration, allowing the local storage of data and the possibility of performing off-line analysis.\nAmong the existing social networks, Twitter is probably the most adequate for these purposes due to its microblog nature in which users publicly share short messages about their daily lifes. Twitter has already proved its value and potential in domains ranging from news detection [SST+09] to real-time traffic sensing [CSR10]. Other social networks, such as Facebook are not so accessible as users tend to publish content within a private circle of friends. Twitter is the 11th most visited website1 in the planet. Its community is continuously growing and, nowadays, the number of active users is about 313 million2, registering a daily average of 400 million new posts. Although only 1-2% of all tweets published everyday are geo-located [IHO+13], these tweets have the advantage of having an explicit geographic relevance to the city where users published those messages."}, {"heading": "1.2 Problem Statement", "text": "que classificar travel-related tweets ser\u00e1 um 1o passo para filtrar ruido que \u00e9 preciso agregar o conhecimento etc fazer uma ponte entre o scope e os goals mas este problem statement ta assim um pouco mais scope do que descri\u00e7\u00e3o concreta dos problemas que se vai atacar mas est\u00e1 muito melhor do que dantes por isso...\nMining Twitter data is a laborious and time-consuming process due to the restrictions and difficulties in its content. The informal language, the existence of slang, abbreviations, jargons and the short length of the message are some of the problems when analyzing this data. Harvesting tweets automatically and, at the same time, extracting valuable information for smart cities and transportation domains makes the task even more complex. Geo-located tweets can have a fundamental role since the study of its content can serve to characterize topics that may be associate the current subjects, events or even interests in specific locations. The lack of gold standards datasets is the most disturbing problem since we are not able to benchmark any analysis performed to these aforementioned domains.\nHaving this considered, the problem on focus in this dissertation is to find a way of demonstrating social media text analysis about cities/regions/countries that can be valuable for entities, governments or even ordinary citizens during decision-making policies, such as, for example, which city presents the most safety level or which mode of transport may an individual choose to\n1http://www.alexa.com/topsites 2https://about.twitter.com/company\n2\nIntroduction\ntravel across a city. However, demonstrate valuable information to these stakeholders is complex since a continuous flow of social media streams is composed of a large number of noisy messages which do not bring additional meaningful and actionable knowledge and due to the previously mentioned restrictions present in a social media message, the text analysis needs to follow a predefined group of operations to erase/minimize these limitations. On the other hand, the analytics process flow may be automatic, i.e. the collection, filtering, text processing, results aggregation and visualization tasks may be associated with each other performing a tool capable of monitoring automatically the current state of a city\u2019s transportation domain or even identify differences between cities apart from the demographic, economic and lifestyle factors.\nThe first point to be tackled here is the continuous collection of geo-located tweets from multiple cities. Each social network, Twitter inclusive, has its own particular specificities regarding the data collection methodology. To solve this problem, it is necessary to know what are the targets (stakeholders) of the resulting information and what are the methods available in the collecting tools provided by social networks, as well as its limitations.\nSecond, it is necessary to filter noisy messages from the final datasets of each city. We must ensure that every tweet is actually located inside the city, that knowledge can be extract from messages besides the aforementioned restrictions (short text, informality, existence of abbreviations, jargon, slang and idioms) in its content and what are the geo-located tweets that are indeed related to specific domains such as the transportation area. In the transportation domain, we can identify multiple modes of transport such as \"bike\", \"car\", \"taxi\", \"train\", and for this reason, a important challenge to surpass is the automatic classification of geo-located tweets related to travel, allowing through this an preliminary filtering process of what messages are relevant for the domain in study. Nowadays, new modes of transport emerges unexpectedly and conventional approaches to filter travel-related tweets are limited to a set of terms during the training process of the text classifiers. This challenges to use recent advances in text mining such as the usage of word embeddings to capture syntactic and semantic similarities reducing the previously mentioned problem of limited number of transportation modes a text classifier tackle.\nOther issue to be concerned is the ambiguity in the social media text messages where the name of a transportation mode may also have other meaning such as \"train\" which can be seen as a mode of transport or even a physical or mental activity. For this reason, it is important the application of text mining techniques that allows the correct identification of a certain entity in a text message [SRP+13]. Nonetheless, the community does not publicly share datasets for this domain (transportation) and due to this we are obligated to build our own datasets if we choose to use supervised learning methods for the conceptualization of a domain-specific text classifier.\nThird, the volume of data retrieved by social media collecting tools is overwhelming and to automatically process and mine these data it is necessary to study what are the most valuable and less time consuming approaches to extract the desired information, useful to entities in the context of Smart Cities and Intelligent Transportation Systems (ITS). Nowadays, there is already a large group of Natural Language Processing (NLP) techniques applied to social media streams, such as topic modelling which consists in discovering latent topics within the messages, to monitor what\n3\nIntroduction\nis being talked about in cities. Several authors have already explored this text mining technique to monitor and also characterize regions and cities as reported in the work of Lansley and Longley [LL16] where the city on focus was London. Here, the main problem focus on the discovering of latent topics and further aggregation at geographic and temporal level to characterize each city and then compare them.\nLast but not least, the final tool needs to be built having into consideration not only the aforementioned text analysis but also needs to be scalable to implement further and complementary tasks, such as sentiment analysis which is not tackled in this dissertation. Hence, another problem here is the design and implementation of a framework, or at least a prototype, which has as basis components modularity, scalability and flexibility, and might be capable of collecting, processing, aggregate and demonstrate results for multiple cities in parallel during a continuous period of time. Moreover, the final system must be capable of using in a easier way, being only necessary to turn on the tool, defining a specific area and the results are performed automatically."}, {"heading": "1.3 Aim and Goals", "text": "This thesis aims to design and develop of a research framework for text processing and semantic analysis of geo-located Tweets within a pre-defined geographical area (e.g. cities). More specifically, to practically implement such a framework we shall accomplish the following goals:\n\u2022 Continuous collection of geo-located tweets from multiple bounding boxes in parallel and in compliance with Twitter API usage limits;\n\u2022 Tackling Twitter Geo API inconsistencies and filtering noisy tweets;\n\u2022 Implement standard text pre-processing methods for social media texts;\n\u2022 Content analysis using topic modeling and comparative characterization among different bounding boxes (e.g. cities);\n\u2022 Travel-related classification of tweets using supervised learning;\n\u2022 Train word embeddings from geo-located tweets;\n\u2022 Study the impact of word embeddings in travel-related classification;\n\u2022 Creation of gold-standard data for travel-related supervised learning;\n\u2022 Aggregation and visualization of results."}, {"heading": "1.4 Document Structure", "text": "The remainder of this document is organized as follows. Chapter 2 starts with a brief contextualization in the Smart Cities and ITS domains, as well as previous related works using social media\n4\nIntroduction\ncontent as its basis. The proposed framework is referenced in Chapter 3, being each its composing modules depth described. Experiments performed to test each module of the framework are reported in Chapter 5. We end the document with Chapter 6 where conclusions, future work and a few final remarks are exposed.\n5\nIntroduction\n6\nChapter 2\nBackground and Literature Review"}, {"heading": "2.1 Smart Cities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7", "text": ""}, {"heading": "2.2 Intelligent Transportation Systems . . . . . . . . . . . . . . . . . . . . . . . 9", "text": ""}, {"heading": "2.3 Social Media Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10", "text": ""}, {"heading": "2.4 Text Mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11", "text": ""}, {"heading": "2.5 Related Social Media Frameworks . . . . . . . . . . . . . . . . . . . . . . . 18", "text": ""}, {"heading": "2.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19", "text": "This section aims the analysis and reflection about some works that has as final goal, similarly to ours, the development of a framework with the purpose of exploring social media data to extract meaningful domain-specific information. Nonetheless, studying works from other authors may help or even find already proposed solutions in order to solve the aforementioned problems.\nHence, this section will contemplate a brief contextualization about how can an intelligent system contribute to the improvement of a city or transportation services. Moreover, technologies and methods that allow extraction of information from a text document or, in this particular case, from tweets will be described. Finally, an exploration through already existent frameworks regarding the information extraction from social media content as well as the identification of its application domain."}, {"heading": "2.1 Smart Cities", "text": "Smart City is a concept appeared thanks to the continuous growth of a city\u2019s population which contributed to an aggressive level of urban and technological developments [USRS16]. In the last few years, several definitions for its meaning have emerged but its main idealization is not yet fully known [Kom09]. Angelidou [Ang15] defined Smart City as\n\"Conceptual urban development model on the basis of the utilization of human, collective, and\ntechnological capital for the development of urban agglomerations\",\n7\nBackground and Literature Review\nenhancing knowledge and innovation economy as the primary factors that support the development of a city. Alongside with the previous factors, the author identifies other three distinct forces that shape the concept of a Smart City:\n1. Technology Push: The need of new products and solutions are introduced into the market\ndue to a fast advance in science and technology.\n2. Demand Pull: Current problems are solved originating new possibilities to respond society\ndemands such as the continuous growth of the population.\n3. Urban Future: Represents the final goal of a city constituting for that reason an important\nrole in the whole transformation process.\n4. Knowledge and Innovation Economy: The creation of new products using the most recent\ntechnologies is associated to solution for the efficiency and sustainability of a city.\nThe first two forces previous mentioned are directly dependent of the other ones as it is showed in Figure 2.1. However, the absence of desire to reach a better future having into consideration the city\u2019s economy and resources can result in the break of its dynamics and healthy, affecting services of a city due to the population discontentment.\nThe development environment of a city tagged as smart is another key factor to reach the success. Komninos [Kom09] associates collective sources of innovation to the improvement of life quality in cities. The globalization of innovation networks is responsible for the emergency of another types of environments and infrastructures, as so \"global innovation clusters and i-hubs, intelligent agglomerations, intelligent technology districts and intelligent clusters, living labs\" allowing the testing of products or services by the ordinary citizens in order to identify problems or even analyse their behaviour and reactions regarding what have experimented [Kom09]. Hence, it is possible to affirm that the development of a city has its starting point in the community but also depends on the quality of Information and Communications Technologys (ICTs) [Hol08], an essential requirement in the city\u2019s evolution process.\n8\nBackground and Literature Review\nLast but not least, a Smart City may focus its efforts in several sectors, such as the environment, culture and recreation, education, social and economic aspects, demography, and travel and transportation [CDBN11] in order to have equally advances in all of them."}, {"heading": "2.2 Intelligent Transportation Systems", "text": "The transportation system is inherently connected to the progress of a city because people uses on a daily-basis transportation modes, i.e. bus, private cars, metropolitan, and others, in order to go to their jobs and make their own life and through that they contribute to the economic progress of it. Although this connection, such system is also influenced by the problem of population growth being relevant and necessary the finding of solutions to minimize or even erase it [CD15]. Hence, \"a smart city should be focused on its actions to become smart\", coming up the concept of innovation [USRS16].\nTo understand what are ITS, it is necessary to introduce the meaning of Smart Mobility (SM). SM is a combination of comprehensive and smarter traffic service with smart technology, enabling several intelligent traffic systems which provide control in the signals regarding the traffic volume, information about smooth traffic flows, times of bus, train, subway and flight arrivals, their routes or even the knowledge of what citizens thought about the city\u2019s services [CL15]. The majority of ITS are expressed through smart applications where transportation and traffic management has became more efficient and practicable, allowing the users to access important information about the transportation systems in order to make correct decisions about what they want to use in their cities [CD15]. ICT-based infrastructures are the main support for smart cities and due to that, they also serve as support to ITS, since the information provide by such infrastructures allows the piloting of activities such as traffic operations, as well as its management over a long period of time [USRS16].\nThe ITS research community have made multiple advances through the last years in the prediction of traffic flow using GPS-traced mechanisms [SRM+16] and bluetooth [FRK+14]. Besides these real-time traffic prediction methods [BAR15], the exploration of social media in this area is still in a maturing process. This kind of data allows new ways to study human behaviour, such as the mood and reactions of people, and smart mobility allowing the usage of new techniques instead of conventional ones [LAB+13].\nNowadays, cities are exploring some initiatives of sensing to support the development of technological projects. Areas such as utilities management (where, for example, is monitored the consumption level of power, water and gas), traffic management (using vibration sensors to measure the traffic flows on bridges, or even the full capacity of a parking lot), environment awareness (using video cameras to monitor the population behaviour and sensors to measure the level of air pollution) make use of physical sensors, i.e. some devices that can capture information to study and improve the quality of life in a daily basis [DSGD15]. Szabo et al. [SFI+13] and Doran et al. [DSGD15] reported the highly economic cost to this kind of sensing, since it is require maintenance and replacement of this devices, as well as a tracking infrastructure to store and process\n9\nBackground and Literature Review\nthe collected information. Hence, a new form of sensing has emerged - Crowdsensing or mobile crowdsensing - offering to the cities several ways to improve their services by exploring the participation of the citizens through social networks where there is a publicly sharing of opinions and thoughts regarding some problems around the city where they live are passing in [RMM+12]. This type of sensing consists in human-generated data provided by the population through the usage of mobile devices and social networks web-based platforms. Such data can be further used to extract some analytics regarding specific services in a city, namely the urban transportation system [RMM+12]. Having this considered, social media can be seen as a good source of data to extract valuable information aiming the direct use of it into the smartness evolution process of a city [SFI+13]. Recently, it is possible to verify that cities are increasingly opting for technological opportunities based on crowd sensing, once this type of exploration brings a considerable reduction of costs and support in the development of news valuable technologies. witter In the last few years, several authors have published a widely range of social-media-based contributions focusing this specific domain. Kurkcu et al. [KOM16] use geo-located tweets to try and discover human mobility and activity patterns. The subject of transport modes was explored by Maghrebi et al. [MAW16] in the city of Melbourne, Australia. From a dataset of 300,000 geo-located tweets, authors tried to extract tweets related to several modes of transport using a keyword-based search method.\nAdditionally, there were also different efforts focused on the tracking of accidents using Twitter social media data. Mai and Hranac [MH13] tried to establish a correlation between the California Highway Patrol incident reports and the increased volume of tweets posted at the time they were reported. On the other hand, Rebelo et al. [RSR15] implemented a system capable of extract and analyse events related to road traffic, coined TwitterJam. In that study, authors also used geolocated tweets that were already confirmed as being related to events on the roads and compared their counts with official sources.\nPerforming robustness experiments over this domain is challeging since although the large number of recently publications, gold standards are yet not defined or even public being for this reason difficult to prove the methodology chosen or suppositions made. Maghrebi et al. [MAW16] enhances some terms related to the transportation domain, however they are limited and also very common ones. After a tough investigation work, it is worth noting a list produced by Gal-Tzur et al. [GTGMK+14] containing a large number of terms whose may serve as support for new scientific contributions using social media in studies of the transportation domain."}, {"heading": "2.3 Social Media Analytics", "text": "In the last few years social networks have made impact on the business communications since users assumed the role of costumers through the publication of content on these networks, rising high levels of interaction between them, as well as with businesses entities [USRS16]. A proof of that is the amount of information produced since 2011 which is equivalent to a number over\n10\nBackground and Literature Review\nthan 90% of the available data online [SIN13]. Facebook1, Twitter2 and other social networking websites are nowadays used as business tools by companies aiming the efficient use of digital marketing techniques to publicize their products [RL14b]. Besides the business field, the population turn widely into this new communication technologies publicly sharing real-life events, their opinions about certain topics and their on-time feelings in the network through a simple message [DDLM15].\nSocial Media Analytics (SMA) can be described as a type of digital analytics which focus is the study of interactions between, their opinions/thoughts, their own life, companies as so its products or services through the social media data. Such study provides important information to \"analysts, brands, agencies or vendors\" facilitating the generation of economic value to many organizations [Phi12]. In order to achieve the main goal of the SMA, companies focus their effort in the development automatic systems to make possible an easy collection, analysis, summarization and visualization of processed social media data establishing specific points about what is necessary to improved in their products [ZCLL10].\nHowever the potential value that SMA can provide, Phillips [Phi12] enhance some important factors to be considered in the analytics process: (1) Users permissions; (2) Awareness/listening of real-time information; (3) Search mechanisms; (4) Text analysis methodologies and techniques; (5) Data access and integration; (6) System integration, customization and growth.\nThe previous mentioned factors will help during the identification and comprehension of possible necessary features in a social media analytics tool, as well as to establish potential parameters/metrics to test and evaluate such tool. Without careful conduction in the social media tool elaboration, for instance, use of a wrong technique of SMA could have a bad business impact for the company resulting possible bankruptcies and increase the unemployment tax of a city."}, {"heading": "2.4 Text Mining", "text": "Text mining comprises a richer set of fields such as information retrieval, data mining, machine learning, statistics and computational linguistics which aims the extraction of valuable information from unstructured textual data [HZL13]. The intensively usage of this analysis methodology is due to the massive amount of information stored in text documents being necessary automatic techniques to identify, extract, manage and integrate the knowledge acquired from these texts exploration in a efficiently and systematically way [ACK+05]. On the other hand, the emergency of social media applications have also contributed to the widely growth of text mining usage because of the \"application\u2019s perspective and the associated unique technical and social science challenges and opportunities\" [ZCLL10].\nText mining shares some of the issues presented by the NLP field. Texts are performed by humans and due to that, some problems in its construction can appear, such as spelling mistakes, wrong phrasal construction, slang among other. Before the mining process of a text, it is important\n1https://www.facebook.com/ 2https://twitter.com/\n11\nBackground and Literature Review\nto apply some preprocessing steps in order to eliminate or, at least reduce, undesired content (words) in the primary analysis process. Stavrianou et al. [SAN07] cite these issues very well alongside their work and some of them are observable in Table 2.1.\nThe removal of words from text may sometimes not be desirable because some sentences can lose its information or even leads to a different meaning compared with its original form. The generation of a stop list words should be a supervised task as long as little words could induce distinct results in the text classification [Ril95].\nStemming is a task that depends mostly from the speaking language of the text than its specific domain [SAN07]. The main goal of this technique is to reduce a word to its root form helping in the calculus of distances between texts, keywords or phrases, or even in the text representation.\nThe noisy data is derived from spelling mistakes, acronyms and abbreviations in texts and to solve this, a conversion of these terms should be done to maintain the integrity of data. Commonly solution approaches involve text edit distances (Levenshtein Distance3) and phonetic distances measures between known words and the misspelling ones to achieve good corrections [BDF+13]\nWord Sense Disambiguation (WSD) is focused on solving the ambiguity in the meaning of a word. Other similar field to WSD is Name Entity Disambiguation (NED) where the disambiguation target are named-entities mentions, while WSD focus on common words. WordNet4 is a commonly used resource to extinguish this ambiguity [CSMA16]. There are two types of disambiguation: the unsupervised, where the task is support by a dictionary or a thesaurus [SAN07]; 3https://en.wikipedia.org/wiki/Levenshtein_distance 4https://wordnet.princeton.edu/\n12\nBackground and Literature Review\nand, the supervised one, where different meanings of a word are unknown and normally learning algorithms with training examples are used to achieve good results regarding the performance of the disambiguation task [Yar95].\nTagging can be describe as the process of labeling each term of the text with a part-of-speech tag, i.e. classify each word as a noun, verb, adjective, and others [HNP05]. Collocations are groups and constitutes a very important step in some text mining approaches. Grouping two or more words to give its correct meaning is sometimes crucial to perform tasks such as sentiment analysis where negations (e.g. \"don\u2019t like\") needed to be composed by two or more words in order to assure the negative value of, for example, a verb. Collocations are usually made before the WSD task since some compound technical terms have different meaning from the individual words which composed it [SAN07].\nTokenization serves to pick up all the terms presented in a text document and to achieve this it\u2019s necessary splitting its content into a stream of words implying the removal of the punctuation marks and non-text characters [HNP05]. Some authors also see tokenization as a text representation form since one of the most used models to represent texts is Bag-of-words (BoW). This model broke down texts into words and stores it in a term-frequency vector according the occurrence of a word in the text. Hence, each word may represent a feature [SFD+10]. Another commonly used model to represent texts is Vector Space Models that represent all the documents in a multidimensional space where documents are converted to vectors and each vector may be seen as a feature. This model provides some advantages since the documents can be compared with each other by performing some specific vector operations [HNP05].\nOnce been introduced some of the most preliminary important steps in text mining, the remainder subsection are focused in two different text analytics approaches: topic modelling and text classification. The majority of SMA approaches focus its efforts in modelling and classification tasks in order to understand the large range of data collected and support commonly used techniques to extract information from it, such as sentiment analysis, trend analysis and topic modeling [FG13]."}, {"heading": "2.4.1 Topic Modelling", "text": "Topic modelling is a text mining unsupervised technique/method aiming the identification of similarities in unlabeled texts. Usually, this technique is applied over texts of large volume since to correctly identify the resulting patterns in its content requires the existence of lots of information.\nOne of the first studies made using Twitter data was proposed by Kwak et al. [KLPM10] and consisted in the collection of messages to classify the trends in its content. Results showed that almost 80% of the trends in Twitter are related to real-time news and the period in which each trend maintains itself in the top is limited. The authors proved that Twitter can be seen as a mirror of real-time occurring events/incidents in the world.\nSeveral works were already proposed to identify social patterns in the population daily-basis life and mapping such patterns geographically by topic modelling techniques to discover latent topics in social media streams. Usually, studies about topic modelling, in particular LDA model,\n13\nBackground and Literature Review\nto text mining problems follow unsupervised approaches [LL16, OPST16] - where is not required the creation of a training dataset. Others improved the model and made it an supervised approach [RDL10], dependent of training data, and compare to the traditional one in order to prove better results.\nUsing entity-centric aggregations and topic modelling techniques, Oliveira et al. [OPST16] built a system focused in data visualization that allows an user to search for an entity during a specific period and shows which are the main topics identified in the Twitter messages. Ordinary weekday patterns were identified by Lansley and Longley [LL16] in their study regarding the inner region of London. The authors used a LDA model to distribute 20 topics over 1.3M tweets. After crossing the results of the experiment with land-uses datasets it was possible to observe interesting patterns in specific zones and places of the British city. Nonetheless, Ramage et al. [RDL10] improved a LDA model by adding a supervised layer that automatic label each tweet used in their experiment.\nConditional Random Fields (CRF) are explored by Nikfarjam et. al [NSO+15] which have applied word embeddings in combination to other text features, such as adverse drug reactions lexicons, Part-of-the-Speech Tagging (POS) and negation collocations in order to train a supervised model. Such model was able to demonstrate high performances on the extraction of concepts/topics from the social media user-generated content. To prove robustness and efficiency in the model, authors have compared the obtained results with DailyStrength corpus and were able to notice that due to the limited size of text in a tweet, the detection of different reactions about drugs is more complex, which could be simplified with access of greater amount of information provided in the training process of the model.\nDifferently from the majority of works involving topic modelling techniques, Tuarob and Tucker [TT15] take support of a LDA model to extract the most frequent words for groups of tweets previously collected. The overall work is focused in sentiment analysis approaches and aims the perception of what people fells about a specific product as well as its composing features. Authors used the LDA model to find what were the main 2 topics present in each product set of tweets and considered the most frequent 30 words. Moreover, POS tagging, disambiguation and stemming techniques were used in order to filter out and normalized words related to the product. Finally, an unsupervised method to calculate the sentiment polarity was applied to the data being final results coherent to the product feature/aspect extracted.\nTopic modeling techniques consisting in supervised learning approaches were explored by Zhang et al. [ZNHG16], where authors have compared the results obtained from a SVM classification for accident-related tweets with a classification using a two-topic generative model SLDA (Supervised LDA). Contrarily to the unsupervised method, this one takes into consideration the label assigned to the training examples and can be trained as a genuine classification model. By comparing the final results between both models, it is possible to observe a significative increase of the precision and a decrease of only 0.04 points in the accuracy meaning that supervised topic modelling techniques to binary classification may compete well with conventional classification models, with respect to tweets.\n14\nBackground and Literature Review\nProbabilistic topic models, such as LDA, are the most used techniques in topic detection tasks. Although high applicability, authors question themselves regarding the performance of this technique over social media data which present limitations, starting at the size of the message and ending in the bad phrasal construction and informality [MSBX13]. In this dissertation we will tackle this question and try to answer it by presenting results obtained in a real-world scenario experiments."}, {"heading": "2.4.2 Text Classification", "text": "Text classification is a text mining task which main goal is the discrimination or characterization of a piece of text into a specific format value. Such value can vary from number (sentiment analysis tasks), labels (multi-labeling tasks), classes (binary or multi-class tasks). Classification in text analysis is a widely used methodology and had already been reported in several scientic contributions regarding the smart cities and transportation domains.\nSuport Vector Machines (SVM), Ordinary Least Squares (OLS), Random Forests (RF), Multilayer Perceptron (MLP), Na\u00efve Bayes (NB) and Decision Trees J48 (DT J48) are some of the supervised classification models used to analyse social media data over fields such as health [SSP11] and pharmacovigilance, political opinion [SGS16], transportation (travel classification [CSR10, KMN+17], traffic and incidents detection [ZNHG16]), financial sentiment analysis [SRSO17] and online reputation monitoring [SMRSO17].\nSifnorini et al. [SSP11] reported a study which main goal was the tracking of the disease Influenza A virus. Tweets collected by the authors using term-based search sum up more than 300 million examples. Their methodology consists in training SVM models with sets of frequency features composed by the most used weekly-terms over the whole dataset. Each model was specifically trained according a certain set of keywords and follow an iterative process, i.e. authors firstly have classified all illness-related tweets related and than used the resulting related subset of data to perform new classification regarding specific keywords, such as what was the disease source, countermeasures used and infected people characteristics. Final results allowed the verification of a decrease of Twitter activity while more new cases were appearing meaning less concerning about this epidemic through time.\n15\nBackground and Literature Review\nAccident-related classification for Twitter data was proposed by Zhang et al. [ZNHG16]. Authors explored the Twitter Streaming API to collect geo-located tweets from Northern Virginia during a completed year, January to December of 2014, and recurring to auxiliary loop detectors that are, in intervals of 15 minutes, recording the traffic flow. In order to automatize the detection of accidents in that interval of time (were the sensors are not recording the scene), authors have built a binary classification model using Linear SVM with a balanced dataset composed by 400 training examples for each of the accident-related and non-related classes composed by a booleanvectors according the final 3,000 tokens resulted from the token filtering and stemming process. Performance was improved by submitting the model to a 5-fold cross validation which was proved by values of accuracy and precision over than 70% of success.\nConsidering the task of discriminate travel-related tweets, Carvalho et al. [CSR10, KFC+15] have constructed a bag-of-words dependent classification model and achieved improvements at the model\u2019s performance with support of a bootstrapping approach implying a two phases train to the SVM model. By assuming the similarities, i.e. all four works were related to binary text classifications, we can induce an hypotheses that Linear SVM models have superior performances relatively to other models for this type of classification tasks.\nMulti-class classification models were also applied to the transportation domain through text analysis of social media content. Kufliket et al. [KMN+17] build multiple classification models using methods such as NB and DT J48 to predict multiple modes of transport during three different sports events. Tweets sum up a total of 3.7M and were submitted to the models classification task in order to prove that an harvesting automatically information from SMC is possible and may help transportation entities in the planning and management of their services during social occasions as it is demonstrate in theirs use cases.\nOn the other hand, Saleiro et al. [SGS16] tried to predict the 2011 Portuguese bailout results analysing opinion within the tweets about all five political parties candidates. The opinion was measure using a OLS model trained with specific sentiment aggregate functions and proved to be capable of correctly predict who would be elected prime minister of Portugal only exploring sentiment analysis in social media data. In SemEval-2017 Task 5, Saleiro et al. [SRSO17] explored word embeddings techniques to extract the sentiment polarity and intensity in financial-related tweets. Authors have proved good performance of models trained with bag-of-words and bag-ofembeddings features together although the approach been applied to a specific domain. The usage of features representing syntactic and semantic similarities of texts, such as word embeddings, can be seen with great potential namely to the area of travel-related text classification.\nThere is a wide diversity in text classification approaches. A worth noting fact in this review at the literature is that word embeddings have been supporting conventional techniques in order to improve performances in text classification tasks. Transportation domain lacks in studies having this particular feature in the training process of its classification models. Hence, it is of major importance perform experiments about this domain aiming conclusions and additional content to support the potential advantages brought by word embeddings.\n16\nBackground and Literature Review"}, {"heading": "2.4.2.1 Classification Evaluation Metrics", "text": "In order to measure the performance of a text classification model, there are several types of metrics that can help this process, depending of course the context of the task. Regarding binary classification tasks, the most common evaluation metrics used are precision, recall (sensitivity) and F1-score which is the harmonic mean or the weighted average of the previous two. Therefore, it is described each of these metrics as well the mathematical equation used in its calculation.\n\u2022 Precison: Represents the fraction of correct predictions for the travel-related class (Equation 2.1).\n\u2022 Recall: Represents the fraction of travel-related tweets correctly predicted (Equation 2.2).\nPrecision = t p\nt p+ f p (2.1) Recall = t p t p+ f n\n(2.2)\nwhere t p is related to the true positives classified tweets, f p represents the false positives and f n are the false negatives.\n\u2022 F1-score: Represents the harmonic mean of precision and recall.\nF1score = 2\u2217 precision\u2217 recall precision+ recall\n(2.3)\nThese first three metrics only showed us the performance of the classifier for a discrimination threshold of 0.5. The Receiver Operating Characteristic (ROC) curve gives us the True Positive Rate (TPR) and the False Positive Rate (FPR) for all possible variations of the discrimination threshold. Through the ROC curve, it is possible to compute the Area Under the Curve (AUC) to see what was the probability of the classifier to rank a random positive higher than a random negative one.\n17\nBackground and Literature Review"}, {"heading": "2.5 Related Social Media Frameworks", "text": "In the last few years, the number of proposals of frameworks to treat social media content and produce valuable information to the end-users has widely increased. For instance, each framework has it own domain of application and generalization is not the center focus. Event detection, online reputation monitoring, socio-semantic analysis to human reactions and traffic sensing are some of the application domains that research community present their contribute through framework proposals.\nLiu et al. [LAR12] have made a study in three different transportation modes (private cars, public transportations and bicyclists) using theirs channels on Twitter to estimate a percentage of the majority gender that uses this services in the city of Toronto. They have extracted all the channel\u2019s tweets appealing only to the non-protected followers and applied an already developed classification model to label each tweet with its creator gender: male or female. Author decided to implement a system that produce automatically analysis since they have find interesting results in the experiment conducted.\nRegarding the field of event/incident detection, Abel et al [AHH+12] developed Twitcident, a real life accidents-aware web-based framework that is connected to a emergency broadcast system in order to detect incidents across the world. Then, an automatically system starts the collection and filtering of content from social media platforms and extracts information about entities using Named Entity Recognition and Disambiguation techniques. Data temporal distributions are also produced to analyse the time line of the events.\nAnastasi et al. [AAB+13] proposed a framework which objective was the promotion of flexible transportation systems usage, i.e. encouraging people to share transport or to opt for the use of bicycles in order to minimize infrastructural and environmental problems. Their tool takes advantages of the crowd sensing techniques by exploring social media streams to predict accidents or traffic congestion and alert the users of their service about this type of events.\nLudwig et al. [LSP15] proposed a tool capable of collect and display social media streams to help the integration and coordination of volunteers in emergency services to prevent engagement in dangerous areas. Their tool present to the end-users map visualization of a city where they could identify public calls of the emergency services to accept or deny them.\nTraffic sensing over the city of Rio de Janeiro, Brazil, was studied by Rebelo et al. [RSR15] which have implemented a system capable of extract and analyse events related to road traffic, coined TwitterJam. In that study, authors used geo-located tweets that were already confirmed as being related to events on the roads and compared their counts with official sources. Finally but not least, authors depicted geographic visualizations to the end-users in order to understand what is the current traffic-state of a certain road.\nSocial Media is used by Ludwig et al. [LSP15], in a framework that attempts the creation of voluntary and emergency activities, coined CrowdMonitor. The systems allows through the analyse of human mobality through tweets posted in the platform. Although absence of text analysis methodologies, such system intents to promote more cooperation between citizens and also\n18\nBackground and Literature Review\npromotes the applicability of crowd sensing, a crucial factor for the smartness evolution of a city.\nTechnological companies is the main target of the framework proposed by Lippizzi et al. [LIR15]. The system analyses social media content having in consideration specific products, such as mobile phones, tablets and others, and tries to extract information of what their customers talk about it. By measuring the sentiment of word clusters produced by the system, companies may take profit and additional insights about what in needed to be improved in their products.\nCrowdPulse is a domain-agnostic framework proposed by Musto et al. [MSLdG15] which main objective is the presentation of text analytics to the end-users. Such framework is rich regarding implemented text methods, which range from entities disambiguation to sentiment analysis. Authors followed unsupervised approaches to implement all the framework composing methods, and applied the resulting system in two real-world scenarios, the earthquake of L\u2019Aquila city and The Italian Hate Map. Further analysis of the results proved that simple techniques can provide faster insights about people sentiment regarding any type of domain.\nPOPMine [SASS15] is a framework capable of performing real-time analysis based on entity filtering and sentiment analysis techniques for the political domain. Later on, Saleiro et al. [SMRSO17] extend this tool to a large group of scenarios and present a full-based text mining framework for online reputation monitoring that explores and extracts multiple types of information from a wide range of Web sources. TextRep is divided in several modules in order to perform correctly the different text mining techniques, such as the collection of data, disambiguation and sentiment analysis. The system is adaptable to different domains as well and applications of it to political opinion mining and financial sentiment analysis are two of the use cases presented by the authors."}, {"heading": "2.6 Summary", "text": "The literature review shows positives and negatives points that are necessary to be reported. First, the conceptualization of a meritorious system capable of bringing value to the smartness evolution of a city is a labourious and time-consuming process. Although iterative steps, it is necessary the stipulation of a detailed work-plan and what are/is indeed the final target/s and objectives of such system. Crowd sensing is a type of sensing that enables the study of what citizens say about a specific topic, and social media platforms can easily be explored in order to take its content to futher analysis and support the construction of a adaptable and profitable tool for the city\u2019s entities. Nowadays, text mining techniques allows the extraction of information from social media content, which can be represented, after accurate aggregations on the results, in visualization views facilitating analysis by the end-users of these systems. Last but not least, we could identify two unexplored approaches in this literature. Word embedding is a technique which has not been applied to transportation domain using social media content. Domain-agnostic frameworks using supervised learning methods are an hard task regarding its conception, however, due to the learning\n19\nBackground and Literature Review\nphase, models could learn new similarities from the text, and we see potential in this approach since it is not necessary construction of auxiliar dictionaries to perform the desired tasks.\n20\nChapter 3\nFramework"}, {"heading": "3.1 Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21", "text": ""}, {"heading": "3.2 Architecture Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22", "text": ""}, {"heading": "3.3 Data Collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24", "text": ""}, {"heading": "3.4 Text Pre-processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27", "text": ""}, {"heading": "3.5 Text Analytics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28", "text": ""}, {"heading": "3.6 Data Storage and Aggregation . . . . . . . . . . . . . . . . . . . . . . . . . 32", "text": ""}, {"heading": "3.7 Visualization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32", "text": ""}, {"heading": "3.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33", "text": "In this chapter we describe the details and specificities of the framework proposed in this dissertation. First, we enunciate the necessary requirements to fulfill and achieve the mentioned development. Moreover, it is present the framework architecture design, as well as it inner pipeline. The modules that constitutes such architecture are described afterwards as so the required methodologies and algorithms incorporated in each of its tasks. Finally but not least, we mention and explain the different data visualizations available in the framework."}, {"heading": "3.1 Requirements", "text": "The development of frameworks to the domain of smart cities and intelligent transportation systems using human-generated content (e.g. text messages) is a laborious and time-consuming process. The source of the data to fed such system is one of the biggest challenges in this kind of developments, ranging from social media, smart phones and urban sensors. In this dissertation we tackle the problem of exploring social media data since this kind of data have, recently, been seen as a new opportunity and source to mine valuable information to the cities services and corresponding responsible entities [MSLdG15].\nSocial media data is mostly represented by text messages being necessary the application of NLP methodologies in order to extract information from its content. Such methodologies are\n21\nFramework\nusually complex and composed by several different steps (e.g. some related to the syntax of the sentences while others are related to the semantics of its content) before the achievement of the desired results. Social media streams are no exception, indeed, the analysis of such texts is even more complex since messages are usually short and present lots of informal characteristics.\nA framework for the domain of social media content requires, in the first place, a data collection module. Depending on the social network, the data collection module can have different heuristics with respect to the data retrieving. Here, the choice of such heuristics is important and needs to be made according the final users expectations, or at least, according the framework final use case. Towards the application of NLP techniques, a module in charge of preprocessing tasks is required. The main purpose of this module establishes in the performance and robustness of the results obtained by the previously mentioned techniques. NLP techniques can provide different types of information, however in this dissertation the focus is on the classification of travel-related tweets and characterization of the topic associated with a tweet. Each technique is represented as an independent module whose belongs to the boundary of text analytics. This framework needs also to be capable of processing information regarding the creation date of a tweet, metadata and geographic distribution associated to it. For the fast retrieving of this informations to the data visualization view, some aggregations need to be made. This requirement is due to one of the big data demands, the instantly availability of the results. Such demand is important for the framework end-users since it helps in the entities\u2019 decision-making process making easier and faster the improvement of its services.\nThe construction of this complex system requires careful planning since there are dependency between a task and the one that follows it, at least with respect to the filtering and preprocessing of data. Adaptability to different languages is considered and further addiction of new ones may be possible. For the same reason, but this time regarding new functionalities, the framework needs to follow a modular architecture allowing new text analysis layers as well as other type of data visualizations. The domain of smart cities is vast in terms of indicators and fields that constituting it. For this reason, the final architecture may be designed in a way that allows configuration about the user\u2019s field of interest, if he do not desire analytics visualization from all fields."}, {"heading": "3.2 Architecture Overview", "text": "The framework proposed in this dissertation is divided into four different modules: (1) collection and filtering; (2) text pre-processing and analysis; (3) aggregation and (4) data visualization.\nThe current collection module is implemented to retrieve geo-location tweets from a specific bounding-box, however if the user demands, multiple locations can be explored at the same time. Other collection heuristics are also available, such as the keyword-search and users following. Depending on the target scenario and analytics to be explored, these two heuristics will need to be added in the module. This detail was considered during implementation period and flexibility was assured into the module composition.\n22\nFramework\nFiltering tasks are directly related to locations heuristic of the collection module. Since this framework is designed to analyse cities or specific regions/zones of it, it is necessary guarantee if a\n23\nFramework\ntweet is actually inside of the searching bounding-box to do not induce information in the analysis from places far away of the target location. For instance, a bounding-box is a rectangle obtained by two coordinate pairs (latitude and longitude, for the South-West point and the North-East point). If other heuristics will be implemented, the filtering module can be configured to support other filtering-specific operations.\nThe text pre-processing module has into consideration the future task in the framework. Having this considered, we implemented a segmented pipeline allowing the user a definition of the desired tasks he wants to analyse in the text messages since different text analysis may have different operation in the preprocessing routine. Methods implemented here are carefully described in Section 3.4.\nText analytics module is composed by two different sub-modules, both of them focusing in a specific text analysis method. Travel-related classification of tweets for two different speaking languages is available since one of the final goals regarding domain-agnostic framework is its adaptability into different scenarios and the language of texts constitutes one of them. Topic Modelling sub-module is available as a text analytics method provided by the framework. We trained a model over a sample of tweets and characterize each topic generated in order instantly characterize future tweets by only being necessary passing it over the transformation process to have their topic identified. In terms of generalization, the main module, text analytics module, was construct following adaptability and flexibility approaches to, in the future, new analysis be integrated.\nBy adding new functionalities, new aggregations are required in order to present the specifictask final results to the end-user. The aggregation module is structured into integrative methods facilitating future extensions or updates on it. Last but not least, aggregation results are communicated to the visualization module, where, similar to other modules, it is possible the inclusion of new data visualization charts, according to the new integrated functionalities."}, {"heading": "3.3 Data Collection", "text": "In Section 3.1, we explain the importance of the decision made to the data collection\u2019s heuristics. Twitter allows the developers\u2019 community two different tools to collect data, the Search and the Streaming Application Programming Interfaces (APIs). The Search API is based on the Representational State Transfer (REST) protocol and only looks up for tweets published in the last 7 days, while the Streaming API creates basic endpoints (independent of the RESTful endpoints) and retrieves up to 1% of the Twitter Firehose. Regarding the proposed and developed framework, we chose the Streaming API due to its free-access for the community, smooth integration in the module implementation and due to the availability of real-time information. A positive point about the Streaming API is the three available heuristics to the data collection, allowing the retrieval of tweets that match a specific text query (e.g. tweets with the word bus or car), the retrieval of tweets associated to a variable number of users - being necessary previous knowledge about these users ids - or even the retrieval of tweets located inside a bounding-box [MKWP+16]. There are\n24\nFramework\ntwo negative points regarding the Twitter Streaming API: first, Twitter imposes limits in its data exploration, where only 400 words can be tracked, 5,000 users can be followed and 25 different bounding-boxes can be explored1; second, the previously mentioned heuristics cannot be used together, i.e. we can not track specific tweets from an user that match with certain words. Although the negative points, we remain with the choice made, of using the Twitter Streaming API as our source of information and limiting the heuristic to the one that retrieves tweets located inside a pre-defined bounding-box. Our choice is additionally supported by the need of studying cities and exploring the information derived from it. In this way, we know, a priori, that if the data collection method is able to retrieve tweets with precise geo-location then this makes our work easier since the exploration of specific regions of a city is already available taking into consideration the information available in tweets.\nAfter the method selection, as well as the selection of its heuristic, we conduct an experiment regarding the amount of tweets being retrieved by one Twitter client for a city. Twitter has into consideration the number of clients used in the data collection process by tracking the IP address of the machine in the network. This constitutes a restriction to explore several cities with the same client since the Streaming API retrieves only 1% of the total overcome. In the experiment, we tested the capacity of a client to retrieve all the tweets posted in New York City and used four different clients for it: one defined with the city bounding-box, and the other three defined with bounding-boxes of three boroughs in the city: Bronx, Brooklyn and Manhattan. Considering the bounding-boxes creation, we took support of an open-source online tool coined BoundingBox 2, which is integrated with the Google Maps API and allows an user to create a bounding-box for an existing place in that API.\nResults showed that the client defined with the greatest bounding-box, New York City, was able to retrieve 100% of the tweets from the three different boroughs. This experiment is consolidated with the work of Morstatter et al. [MPLC13] where it was compared the Streaming API\u2019s capacity, regarding geo-located tweets, against the Twitter Firehose. Authors concluded that the percentage of geo-located tweets corresponds to 1-2% of total overcome from Twitter and the Streaming API is able to retrieve almost 90% of it. Hence, we do not need to be concerned about how many bounding-boxes are used in the collection process because if we did so, we would need to be aware of 90% of the world, which is not the case."}, {"heading": "3.3.1 Data Filtering", "text": "In the first attempts to study the data collected geographic distribution, we discover that not all tweets had a precise coordinate attached to it. Nonetheless, there were cases where tweets from other cities were collected by our crawler and this phenomenon is not supposed to happen when the collection method is based in geo-located characteristics. By studying the Twitter mobile application, we found out that a user can tag himself in the tweet by two different ways: (1) a user\n1https://dev.twitter.com/streaming/reference/post/statuses/filter (Accessed on 18/06/2017)\n2http://boundingbox.klokantech.com/ (Accessed on 23/06/2017)\n25\nFramework\ncan activate the Global Positioning System (GPS) in the mobile application and associate to the tweet his precisely geo-location; (2) a user can choose a place from a predefined list provide by Twitter and associate the place to the tweet.\nThe second method of tagging the geo-location to the tweet can arise some conflicts when this kind of tweets is used to perform scientific studies or even development of system to help the cities in the regularization, control and improvement of its services. Having this considered, it was necessary to understand how the Twitter Streaming API works and what kind of heuristics follows in order to retrieve such type of tweets. The documentation 3 enhances two different heuristics:\n1. If the coordinates field is populated, the values there will be tested against the bounding-box;\n2. If the coordinates field is empty but place is populated, the region defined in place is checked\nfor intersections against the locations bounding-box. Any overlapping areas will yield a positive match.\nThe first heuristic only happens if a user is able/willing to tag a post with his precise geolocation associated with it; otherwise, the user can tag the post associated with a place and in this case the second heuristic is applied. Each place contained in the previous mentioned list, which is provided by Twitter, is composed by a bounding-box, and if any piece of it overlaps the boundingbox used in the collecting process, then a positive match is yielded and the tweet is retrieved. For instance, if a tweet has a place such as Portugal and our filter bounding-box is defined for Porto, all tweets from place Portugal will be in our dataset, regardless the fact some tweets are posted elsewhere, such as in the city of Lisbon, very far away from Porto.\nThis restriction required the development of a external layer which was responsible for the filter of tweets located outside the area of each city. To built this so, it was necessary a posteriori information and, thus, we extract the Twitter default bounding-box of each city in study appealing to the tweets place field. Such information was then used as the limited area in order to filter out tweets which coordinates field was not populated. The methodology behind the filtering process consists in the matching of the Twitter default bounding-box of the city against all places\u2019 3https://dev.twitter.com/streaming/overview/request-parameters#locations (Accessed on 17/06/2017)\n26\nFramework\nbounding-boxes in tweets. In Figure 3.2, we illustrate an example of our method in which the green color represents the matching of a tweet attached with place Duque de Caxias yielding a positive result, while the red color represents a tweet with place Nova Igua\u00e7u yielding a negative match result with the Twitter default bounding-box for the city of Rio de Janeiro."}, {"heading": "3.4 Text Pre-processing", "text": "In the requirements section (3.1), we mentioned some problems of social media streams as the short length and informality of the text message. The informality problem ranges from the writing style of each person to the existence of lots of abbreviations, slang, jargons, emoticons and bad usage of punctuation signs. The preprocessing module presented in this section has as main goal the submission of the text messages under several operations in order to remove, or at least, reduce this type of informality characteristics and make easier the work of future tasks.\nBelow, we enumerate and described the different preprocessing methods implemented:\n\u2022 Lowercasing: This operation is responsible for the conversion upper case characters to lower representation. The advantages provided by this operation are centered in the analy-\nsis of words written in different ways. An representative example is london and London whose meaning is the same but due to the different casing in one letter, its representation/interpretation by text mining techniques may be disparate.\nTravel-related Classification and Topic Modelling modules explore this pre-processing operation.\n\u2022 Lemmatization: Only plural words are transformed into singular ones (e.g. cars -> car).\nTopic Modelling module explores this pre-processing operation.\n\u2022 Tokenization: Is the method of dividing each sentence in a list of tokens/words. Since we are dealing with social media content, standard tokenizations techniques available in pack-\nages, such as the tokenize 4 from Python\u2019s Natural Language Toolkit (NLTK), perform poorly and are not capable of dealing with #hashtags, @mentions, abbreviations, strings of punctuation (e.g. ... or %&$), emoticons (e.g. :) or :-) or =D) and unicode glyphs which are very common in Twitter. Having considered this, we used a Twitter-based tokenization package, coined Twokenize and firstly presented by O\u2019Connor et al. [OKA10], which is capable of dealing with these special characteristics of tweets.\nTopic Modelling module explores this pre-processing operation.\n\u2022 Transforming repeated characters: Sequences of characters repeated more than three times were transformed, e.g. \"loooool\" was converted to \"loool\".\nTravel-related Classification and Topic Modelling modules explore this pre-processing operation.\n4http://www.nltk.org/api/nltk.tokenize.html\n27\nFramework\n\u2022 Punctuation removal: Every punctuation symbols are removed from the text message, including the previous mentioned emoticons.\nTopic Modelling module explores this pre-processing operation.\n\u2022 Cleaning Entities and Numerical Symbols: Removing URLs, user mentions, hashtags and digits from the text messages.\nTravel-related Classification and Topic Modelling modules explore this pre-processing operation.\n\u2022 Stop and short words removal: This operation consists in the removing of the most common words in the language in analysis. We used the standard words of the NLTK Corpus\npackage for the stop words removal task. Other type of words, such as \u2019kkk\u2019 or \u2019aff\u2019 represent short words that do not bring any valuable information from the message analysis. For this reason, we conceive a short dictionary containing these words and removed it from the message.\nTravel-related Classification and Topic Modelling modules explore this pre-processing operation.\nRegarding other fields in a tweet, this module was also in charge of convert the date of creation of a tweet to the city timezone. The field created_at in a tweet is given in the Coordinated Universal Timezone (UTC) and in order to have knowledge about the most active local hours and days on Twitter, we used the Python timezone package pytz 5 to convert the world timezone to the one desired.\nAlthough the existence of more text preprocessing techniques, in this dissertation we only used the ones previously described since each of them is associated to, at least, one text analytics module whose are described in the following section."}, {"heading": "3.5 Text Analytics", "text": "The extraction of information from texts can vary in several types depending on the task performed to achieve it. In this dissertation, we explored two different types of analysis to the tweets: topic modelling and travel-related classification."}, {"heading": "3.5.1 Topic Modelling", "text": "Social media, more specifically, microblog services are platforms where people publicly share their opinions and due to that they are seen as a rich source of content to explore. In order to mine such information, we implement in our framework a generative module using topic modelling techniques.\n5https://pypi.python.org/pypi/pytz\n28\nFramework\nTopic modelling is a text mining technique which goal is the identification of latent topics in a collection of documents. During the last decade, the research community had been using this technique in a vast range of works aiming the test of its applicability in different domains. Here, we also used topic modelling to characterize different cities and provide this type of information to the framework\u2019s end-users.\nLatent Dirichlet Allocation (LDA) is a generative statistical model proposed by D. Blei et al. [BNJ03] that makes possible the discovering of unknown groups and its similarities over a collection of text documents. The model tries to identify what topics are present in a document by observing all the words that composing it, producing as final result a topic distribution.\nIn Figure 3.3 it is illustrated the plate notation to the graphical model of LDA. There, we can observe that for a collection of documents M, each one composed by a sequence of N words, the model tries to attribute a per-document topic distribution, using an \u03b1 dirichlet prior, to a topicword distribution \u03be (associated also with a dirichlet prior \u03b2 ), inducing that each topic\u2019s probability \u03b8 is focused in a small set of words w which characterize that topic.\nThe most important advantage this model provides is related to the group of features involved in its training process. Conventional application of this model uses only as features a bag-of-words matrix representation, and for this reason the task of topic modelling becomes very simple since only the frequency of words in documents are taken into account. Last but not least, LDA model performs two different distributions: (1) distribution of words over topics and (2) distribution of topics over the documents, resulting in the assumption that each document is random mixture of topics, whose in turn are composed by a probabilistic distribution of words.\nThe cities\u2019 characterization provided by our framework centers in the topics being talked about at the time. We conduct an experiment to evaluate if such information could bring added-value for the cities entities and the results although being very promiscuous proved to have potential in certain occasions. The overall experiment is described in Section 5.1 as well as potential improvements to the generated model.\n29\nFramework"}, {"heading": "3.5.1.1 Features", "text": "Topic modelling requires, like in other learning model, a group of features to be trained. In this case, we used the representation matrix - which is a representation where each document is converted to a frequency vector according to the number of occurrences of each word in the message. The set of features was limit to a dictionary containing 10,000 words and it only took into account uni-grams in the message content. The dictionary was also limited to words that occur in a maximum percentage of 40% in the whole dataset, avoiding common words that were not removed because they were not included in the Python\u2019s NLTK stop words list for the specific language in analysis. The minimal occurrence value for a word being considered was set to 10."}, {"heading": "3.5.1.2 LDA Model Resulting Topics", "text": "The final model used in the implementation of our framework is defined to characterize a tweet into 50 different topics. Although that, in the experiment made to comprove the added-value brought by the model, we were obligated to cluster some of the topics due to the similarity presented in words constituting them. The final list of possible topics can be seen in Section 5.1.1, more specifically in Table 5.2."}, {"heading": "3.5.2 Travel-related Classification", "text": "Prima facie, we tried to extract and characterize travel-related tweets from large datasets in order to study the geographical and temporal distributions of such specific content. The transportation entities may take advantages from this kind of information since human mobility can be study, as well as citizens\u2019 opinions regarding the transportation services. The Twitter Streaming API provides a massive amount of data and filter out the relevant in a short period of time is a laborious process. In order to be successful in this task, we created an automatic text classifier capable of discriminating travel-related tweets from non-related ones. Due to the absence of gold standard datasets in this domain, there was the need of creating a training and testing set of data in order to proceed the experiment and evaluate the performance of the produced model. Conventional classification tasks in the domain of intelligent transportation systems follow traditional approaches by constructing their group of features using standard bag-of-words techniques. In our experiment, we tried to combine a BoW features with Bag-of-embeddings (BoE) (word embeddings representation matrices), producing, for the best of our knowledge, the first travel-related classification model with both type of features."}, {"heading": "3.5.2.1 Features", "text": "BoW representation matrix is a list of lists, where each entry of the matrix is associated to a sentence of the document and takes the form of a term-frequency vector. In this group of features, we only considered uni-grams as the basis of text representation form. The final dictionary of this\n30\nFramework\nform was produced with the 3,000 most frequent terms across the training set excluding the ones found in more than 60% of the documents (tweets).\nThe technique of word embeddings is used by Mikolov et al. [MCCD13] in the implementation of a powerful computational method named word2vec. This method is capable of learning distributed representations of words, and each word is represented by a distribution of weights across a fixed number of dimensions. Authors have also proved that such representation is robust when encoding syntactic and semantic similarities in the embedding space.\nThe training objective of the skip-gram model, as defined by Mikolov et al. [MYZ13], is to learn the target word representation, maximizing the prediction of its surrounding words given a predefined context window. For instance, to the word wt , present in a vocabulary, the objective is to maximize the average log probability:\n1 T\nT\n\u2211 t=1 \u2211 \u2212c\u2264 j\u2264c, j 6=0 log P(wt+ j|wt) (3.1)\nwhere c is the size of the context window, T is the total number of words in the vocabulary and wt+ j is a word in the context window of wt . After training, a low dimensionality embedding matrix E encapsulates information about each word in the vocabulary and its use (i.e. the surrounding contexts). For instance, by using the skip-gram model over our datasets we were able to verify that words such as \u00f4nibus and bus\u00e3o are used in the similar contexts, as a mode of transport.\nLater on, Le and Mikolov [LM14] developed paragraph2vec, an unsupervised learning algorithm operating on pieces of text not necessarily of the same length. The model is similar to word2vec but learns distributed representations of sentences, paragraphs or even whole documents instead of words. Hence, we explored paragraph2vec to learn the vector representations of each tweet and tried several configurations in the model hyper-parameterization.\nUsing paragraph2vec [LM14], we created BoE representation matrices for the tweets in order to explore the learning distributed representations of words where each word is represented by a distribution of weights across a fixed number of dimensions. Mikolov et al. [MYZ13] proved that this kind of text representation is robust when encoding syntactic and semantic similarities in the embedding space. The training process of our classification models involved 10 iterations over the datasets using a context window of value 2 and feature vectors of 50, 100 and 200 dimensions. Then, the corresponding embedding matrix yielded the group of features fed into our classification routine.\nBoth previous described methods are available in the collection of Python scripts we used in this dissertation, coined Gensim 6, presented and lately improved by R\u030cehu\u030ar\u030cek and Sojka [RS10].\nThe overall experiments regarding the travel-related classification of tweets are described and detailed in Sections 5.2.1 and 5.2.2. Concluded the experiments, we select the best classifiers for each case and used it in the implementation of the framework\u2019s travel-related modules allowing discrimination of potential new tweets related to the transportation domain.\n6https://radimrehurek.com/gensim/about.html (Accessed on 20/06/2017)\n31\nFramework"}, {"heading": "3.6 Data Storage and Aggregation", "text": "Besides the few percentage of geo-located tweets provided by Twitter (1-2% of the total Firehose overcome), this data requires, in the first place, large storage capability and, secondly, a tool that allows the easy manipulation and quick access of data. Having considered this, we opted for the use MongoDB, an open-source cross-platform document-oriented database, as the data warehouse technology for our framework. MongoDB allows storage of JavaScript Object Notation (JSON) documents which is the retrieved format of tweets by the Streaming API. Since in this dissertation we developed the framework as a prototype of a system capable of extracting information related to smart cities and transportation services, the large physical space to storage data was not a priority.\nMongoDB presents, alongside the high performance, availability and scaling, an inner framework that allows the aggregation of data according to specific user-generated queries. Here, we took advantage of such a pipeline in order to produce interesting statistics regarding the processed data. Map-reduce is the processing paradigm behind the aggregating operations allowing high performance even when applied to large volumes of data, as in this particular case where it is necessary to process thousands or millions of tweets in a short period of time."}, {"heading": "3.7 Visualization", "text": "One of the most laborious and time-consuming tasks in the development of this social-mediabased framework is the selection of data visualizations to illustrate the results provided by the previous mentioned modules. Visualization of information retrieved from the social networks needs to be easy of understanding and the majority of systems explores key performance indicators while others use more complex visual representations such as egocentric networks [STSO16]. Due to the amount of data being processed, the generation of data visualization using an atomic implementation is sometimes poorly in terms of response time. Hence, we needed to adopt a different approach in order to solve this non-efficient procedure.\nAfter a long period of research, we found a solution to this problem by creating a set of routines (bash scripts) that are called periodically (hourly) to execute all type of necessary aggregations and update its corresponding data collections in the database. Then, other routine is invoked to generate all type of data visualizations and store its visual representation in HyperText Markup Language (HTML) files. In the implementation of this module, these files - containing the data visualization - were embedded inside several view pages. Plotly 7 is a Python graphing library that has available the saving of the visualizations produced in files with HTML format. Besides that, the library offers an extensive range of graphical representations, such as basic charts (bar charts, scatter plots, etc), scientific charts (heatmaps), financial charts (time series) and maps (choropleth, bubble and line maps), which facilitates the construction and designing of dynamic dashboards. Here, we explore mostly the section of basic charts to build simple representations of the results\n7https://plot.ly/python/\n32\nFramework\nobtained from the analytics phase and also added top lists about some metadata of the tweets, as so the overall, daily and hourly top hashtags and uni-grams."}, {"heading": "3.8 Summary", "text": "In this Chapter we detail the implementation of our framework, the modules that compose it, as well as the methodologies and methods chosen for each module conceptualization.\nDuring the construction and implementation phase, we tried to maintain modularity in the whole system in order to make possible future extensions to it or even complementarity of the existing modules. The final framework is composed by four different modules connected between them. However, if the situation demands, each module can be adaptable to other systems.\nConcluded the overview of the main characteristics of our framework, we provide the final users information that have been collected, filtered and analysed in a almost real-time scenario. It is worth noting that due to the laborious tasks each tweets passes through, it is impossible to provide instantaneous results because the system should be coherent and not treat each message separately. Information is given to the final user in short periods of time (e.g. 30 minutes), making possible that all text analytics modules conclude its tasks and all type of analysis is actually available.\nAn interesting future improvement to the framework is the incorporation of an extra module to perform tasks of sentiment analysis. Work together with the two already developed the information provided is of additional value to the services of a smart city, including the transportation domain.\n33\nFramework\n34\nChapter 4\nExploratory Data Analysis"}, {"heading": "4.1 Geographic Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35", "text": ""}, {"heading": "4.2 Temporal Frequencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40", "text": ""}, {"heading": "4.3 Content Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44", "text": ""}, {"heading": "4.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46", "text": "The main goal of this chapter is the devise of relevant analysis taking into consideration the five different collected datasets. Since this dissertation is supported in experiments using real-world data, such analysis is crucial in order to gain better knowledge of the intrinsic characteristics of it. A tweet provides some fields of interest, such as, the text message, date of creation, language, and the entities, which are constantly analysed in several data analytics systems. An entity is metadata and additional contextual information contained in the tweet and is composed by the hashtags, user mentions, urls and media fields. We count the amount of tweets containing this kind of information for all the cities, London, New York, Melbourne, Rio de Janeiro and S\u00e3o Paulo, and projected some data visualizations for different temporal frequencies. The following subsections are divided into three different categories: (1) Geographical Distribution, (2) Temporal Frequencies and (3) Metadata Composition. Additionally, we discuss the results of each city, as well as the main observable differences."}, {"heading": "4.1 Geographic Distributions", "text": "As previously mentioned, in Section 3.3, we exploit an auxiliary online tool to generate the coordinates for the bounding-boxes used in the collection process. The visual representation of the each city bounding-box is illustrated in Figure 4.1, as well as its the corresponding coordinates which are presented in Table 4.1.\nTaking a careful observation into to coordinates used within each bounding-box, we can affirm\nthat Rio de Janeiro present the broadest bounding-box comparatively to the others cities.\n35\nExploratory Data Analysis\nTo conduct the data filtering process, we extracted from data the Twitter default boundingboxes for each city in study, being possible to observe their corresponding South-West and NorthEast coordinates in Table 4.2. The map visualization of these bounding-boxes is demonstrated in Figures 4.2 (subfigures 4.2b and 4.2a) and 4.3 (subfigures 4.3a, 4.3b and 4.3c), where the biggest rectangle represents the Twitter default bounding-boxes for each city.\nThe final volume of tweets located inside and outside the cities correspondent bounding-boxes are presented in Table 4.3. Alongside with the location analysis, the language count was also performed since future experiments only took into consideration tweets with the native language of the city in study and not foreign ones. In the abovementioned table (4.3) it is possible to verify a vast difference regarding the activity on Twitter in Rio de Janeiro. Numbers tell that such activity, with respect to geo-located tweets, is almost two times more than S\u00e3o Paulo and New York City, four times London and twenty five times Melbourne. A possible justification for this noticeable difference may be associated to the area of the bounding-box used in the collection process, but, on\nExploratory Data Analysis\nthe other hand, according to some sources related to the demographic measures, for the case Rio De Janeiro versus S\u00e3o Paulo, the population volume has an opposite behavior, where S\u00e3o Paulo 1 has almost 12 millions habitants while Rio de Janeiro 2 has 6 million. Having only this amount of information it is impossible, at the moment, formulate a explanation to this phenomenon.\nLater, after the filtering process, we tried to understand the volume, as well as the location of each tweet. Through this kind of analysis it was possible to find out that a tweet which coordinates field was empty and is, actually, represented with a bounding-box, can also be a specific place, i.e. a place that has a precise coordinate. Not all places were represented by a bounding-box in which each point that composed it are different. An example to that is Est\u00e1dio do Maracan\u00e3 which although its location field being represented by a bounding-box format, all four points are equal. A division was made considering this three types of location - (1) bounding-box with four different points; (2) bounding-box with four equal points; (3) precise coordinate - in order to have a perception of how different specific places and bounding-boxes as so which is the volume of tweets that are related to it.\nExploratory Data Analysis\n38\nExploratory Data Analysis\n39\nExploratory Data Analysis\nThe final counts of the analysis for each identified type of geo-location are presented in Table 4.4. Looking at the numbers it is possible to conclude some facts applicable to all cities. Citizens tend to geo-locate themselves with a location which has variable bounding-box size since more than 70% of the tweets are of this type. Furthermore, only a few percentage of tweets, between 0% and 1.43%, are located in specific places, although the existence of a higher number of distinct specific places comparatively to the bounding-boxes with variable size, with exception of Melbourne that has zero specific places in our dataset.\nOther interesting point to enhance is the considerable percentage of tweets with precise location (i.e. tweets that people tagged himself using the GPS). The Brazilian cities proved to be less supportive of precisely located tweets, while the English cities were more contributive. The distribution of each type of geo-located tweet is illustrated in Figures 4.2 and 4.3. The variable bounding-boxes are showed in 4.2a, 4.2b, 4.3a, 4.3b and 4.3c proving that our filter method was able to correctly agglomerate places that were, indeed, inside of the Twitter default boundingboxes. In 4.2c, 4.2d, 4.3d, 4.3e and 4.3f is illustrated the distribution of the specific places found out in our datasets for each city. A particular point identified was the absence of specific places in Melbourne and the limited places in a certain area of London. With a first look at the image of London, there may be doubts about the results concerning the filter method, however the bounding-box used to that process was the same in both cases, and so the only viable explanation for such result is the absence of specific locations for that area in the predefined list of places provided by the Twitter applications. Lastly, in 4.2e, 4.2f, 4.3g, 4.3h and 4.3i is illustrated the distribution of precisely located tweets. Through a careful observation in this distribution it was possible the arising of another doubt relatively to the first aforementioned heuristic of the Twitter Streaming API. There were tweets retrieved that not matched the bounding-box used in the collection process and this fact conducts to uncertainty and mistrust regarding the performance of this type of collection available on Twitter."}, {"heading": "4.2 Temporal Frequencies", "text": "Another interesting analysis in our datasets concerns the temporal distribution of the data. The volume of tweets posted per hour, per day, as well as the activity by day-of-the-week or hour-ofthe-day are statistics that enable the possibility of finding out patterns or variations which can be correlated to some events or incidents happening in a city.\nDuring and after remarkable events, citizens are impelled to share their feelings, opinions or even report their safety and well-being conditions (e.g. in cases of terrorist attack) through mobile applications. This share of information increases the activity of social media platforms, which can be potentially used for the identification of uncommon events. Figure 4.4 illustrates the daily distribution of all cities for the period of collection, three whole months, between 12 March and 12 June, 2017. The Brazilian cities present high level of variation between consecutive days (with the volume varying in a tens of thousands of tweets) and so the task of identifying remarkable events turns out to be much harder. On the other hand, the English speaking cities in our study are\n40\nExploratory Data Analysis\n41\nExploratory Data Analysis\nvery similar, with exception of Melbourne whose activity is very low comparatively to the other cities (New York City and London). In the particular case of London, we can identify an abrupt increase of volume during days 8 and 9 of June. With the support of external sources such as news websites, we learnt about the United Kingdom General Elections 2017 3 occurred on that period which suggests that an increase of the Twitter activity might be associated with that event.\nIn order to understand the most active days and hours in Twitter, for all cities under this study, we aggregate the datasets by these attributes and represented the final results in a box-plot representation. This type of data visualization allows, in a standardized way, the displaying of distributions of data based on the six different values: (1) minimum and (2) maximum values for each day/hour regarding the activity on Twitter; (3) median value for the each day/hour, (4) first and (5)\n3https://www.theguardian.com/politics/general-election-2017 (Accessed on 17/06/2017)\n42\nExploratory Data Analysis\n43\nExploratory Data Analysis\nthird quartiles as well as (6) the Interquartile-range (IQR). Figures 4.5 and 4.6 illustrated this type of data visualization for the whole three months of data collected. Taking into analysis the city of Rio de Janeiro, it was possible to observe and enhance Tuesdays as the day of the week where there is more activity on Twitter. Moreover, Fridays revealed to be the day less active, not only for the city of Rio de Janeiro, but for all remaining cities with exception of Melbourne. Particularly, the activity on Twitter in Melbourne is centered in the weekend days while the other cities the highest levels of activity is spread between week and weekend days. The interquartile range in the plots can tell us the amount of days whose activity was above and behold the median value, and through that we identify Rio de Janeiro and Melbourne as the cities where this phenomenon happen more times. S\u00e3o Paulo, New York City and London present an almost regular IQR which means that the days of weeks are similarly regarding the activity on Twitter.\nLooking at the hour-of-the-day box-plot (4.6), it is possible to verify an decrease in terms of activity on Twitter during the night period to all cities. More specifically, there were cases in which the volume of tweets was inexistent and based on this fact, two possible reason are suggested: (1) the absence of tweets during this period is explained through the zero activity of users in the city, regarding geo-located tweets; (2) the service on Twitter was in maintenance and due to that, any tweet was retrieved by the API. Although the observable increase of activity during day-time, the peak of it is similiar to all cities and it is established between the 19 and 23 hours."}, {"heading": "4.3 Content Composition", "text": "Tweets although its classification as text messages, also contain other kind of metadata which exploration of it can sometimes be transformed in added-value information. The metadata present in a tweet is represented by the hashtags, user mentions, URLs and media attached to it. Other point to explore is the number of distinct users that contributed to the datasets composition. Users which number of posts are unnatural may sometimes be bots. If there is a time pattern associated to the post of tweets by a user, for example, the user posts a tweet in a period of 5 minutes over the whole day, then this user is a potential bot. The existence of bots is not considered in this dissertation because the information provide by such automatic system can also be valuable. In this subsection, we demonstrated the distribution of users over the number of posts made by themselves, as well as the counts of the different type of metadata contained in the data.\nSocial media platforms present similar characteristics between themselves. One of the most studied ones is the behviour of the its users activity in its services (social media services). The visualization of users activity usually is similar to the power-law distribution long tail [MPP+13]. Here, we tried to reproduce such visualization in order to establish this kind of correlation as so to prove this behaviour over social media services. The results are present in Figure 4.7. Each city proved to have a high number of users with few posts and that is observable in the long-tail showed in the cities corresponding sub-figures ( 4.7a, 4.7b, 4.7c, 4.7d, 4.7e).\nThe counts and percentages of users that have posted a certain number of tweets was calculated in order to assure the trustiness of the aforementioned distribution. Rio de Janeiro although the\n44\nExploratory Data Analysis\nhighest number of tweets in the datasets only was composed by 135,449 distinct users followed by S\u00e3o Paulo with a lower number 110,352 individuals. The English speaking cities revealed to be very different comparatively to the Portuguese speaking cities in this factor. New York City dataset was composed by 279,554 distinct users, London presented 266,128 users and Melbourne only was composed by 31,733 individuals. Looking at these numbers, we may conclude that Rio de Janeiro has a high percentage of users with more than a certain number of tweets and following this assumption, the log-log distribution made to correlate the behaviour of a power-law distribution must be different from the other cities, at least the English speaking ones.\nFor example, the percentage of users that posted 20 tweets in a period of three months was almost 63% for the city of Rio de Janeiro, S\u00e3o Paulo registered 75%, New York City presented 84%, London showed 87% while Melbourne had 87% of his users with that number of tweets shared. Only taking this example in consideration we proved the assumption mentioned before. The distributions also presented differences if the x-axis is considered. The scale at such axis is one magnitude higher for the English speaking cities, and this means that the number of users with lower number of tweets posted in a three months period is much higher than the users with the same number for the city of Rio de Janeiro.\nThe last analysis presented in this subsection is related to the metadata contained in the tweets. Here, we want to characterize the different cities with respect to the amount of extra content used by the users in the posts and what kind of information such results suggests for each city.\nHaving this considered, we counted the volume of each element constituting the previously mentioned metadata and calculate the percentage of tweets containing it. In Table 4.5 are listed the counts and the corresponding percentage of it relatively to the datasets. The resulting analysis and results were performed over the tweets with the city\u2019s native language and located inside the bounding-box area used in the filtering process. The most observable evidence in the results is the greater use of this elements in the English speaking cities. User mentions, as well as URLs are the most used metadata. This elements may suggest that citizens tend to tag other people in their messages when posting and also share information about certain topic through urls. Regarding the Brazilian cities, the metadata usage is not so noticeable. This fact may me related to the number of users composing each dataset because, as it was previously mentioned, the English speaking cities possesses almost two times more users than the Brazilian cities and this characteristic contributes to the increase of this type of metadata usage since when someone tag another one in a message, usually a re-post is sent tagging the person responsible by the starting of the conversation. To prove this so, an intensive study about social media tracking and mapping of the flow of each Twitter conversation is needed.\nExploratory Data Analysis"}, {"heading": "4.4 Summary", "text": "In this chapter we tried to identify interesting patterns and valuable information recurring only to the simple characteristics provided by a tweet: location, date of creation and metadata content. First, it was possible to find out existing problems regarding the collection of geo-located tweets. During the last few years, the research community is proposing lots of studies using geo-located tweets, however, for the best of our knowledge none of them report the problem we identified regarding the geographic analysis. Our datasets represent only three months of data, however supporting in the analysis made, we conclude that the majority (> 70%) of tweets are tagged with variable sized bounding-boxes instead of precisely geo-coordinates. This problem turns on difficult challenges when proposals of studies about human activity patterns our even human mobility\n46\nExploratory Data Analysis\nneed to be conducted using social media content, with respect to geo-located tweets.\nFurthermore, we tried to instigate temporal patterns using the tweets already filtered and proved that it is possible to learn about remarkable events only seeing abrupt activity on Twitter for some days.\nBy studying the Twitter users distribution it was possible correlate the behaviour of it with the well-known power-law distribution. Nonetheless, we were able to identify high differences of the amount of tweets posted by some users. It is worth noting that some of them may be robot users, and due to the limited time in the implementation of our framework we did not perform any filtering regarding this problem.\nLast but not least, a brief analysis of the metadata was performed in order to see the amount of possible topics identified on it (hashtags), the volume of tweets mentioning another user and how many information can be share through the use of urls in this microblog. Hashtags combined with temporal analysis can provide quickly and easier identification of remarkable events while user mentions, can prove that people are using microblogs services as a communication service and for this reason human behaviour studies can be explored through this platform - Twitter.\n47\nExploratory Data Analysis\n48\nChapter 5\nText Analytics Experiments"}, {"heading": "5.1 Topic Modelling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49", "text": ""}, {"heading": "5.2 Travel-related Classification . . . . . . . . . . . . . . . . . . . . . . . . . . 52", "text": ""}, {"heading": "5.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63", "text": "In this section we present two different text analytics experiments regarding topic modelling and travel-related tweets classification. First, we manually labelled topics to characterize two Brazilian cities, namely Rio de Janeiro and S\u00e3o Paulo. Later on, we built two travel-related classification models to discriminate tweets for two different speaking languages. For both experiments related to travel classification we manually annotated a English-speaking and a Portuguesespeaking training and test datasets. The remainder sections described each experiment as well as discussion and analysis of the obtained results."}, {"heading": "5.1 Topic Modelling", "text": "In this section we describe the experiment of automatic characterization of tweets in two different Brazilian cities, Rio de Janeiro and S\u00e3o Paulo. Here, as previous mentioned in Section 3.5.1, we use LDA model to find out which are the latent topics in both cities. We conduct this experiment using data collected from a period of two months, between March 12 and May 12, 2017. After the data filtering and text pre-processing steps, we obtain a total of 6.6M tweets for Rio de Janeiro and 2.7M tweets for S\u00e3o Paulo.\nWe tried training LDA model with 5, 10, 20, 25 and 50 latent topics and manually inspected the top most probable words for each topic. Models with 5, 10, 20 and 25 presented a high number number of overlap terms between topics. Therefore, we opted to proceed with the experiment using 50 latent topics. The number of iterations to train the model was set to 20, in line with the work of Lansley and Longley [LL16].\n49\nText Analytics Experiments"}, {"heading": "5.1.1 Results and Analysis", "text": "The LDA model does not provide a semantic label for each topic, such as \"topic x is about Sports\". We inspected the most frequent words of each topic and manually assigned a semantic label. Table 5.1 presents the most frequent words for 5 random topics and the corresponding labels manually assigned. For instance, the topic containing frequent words such as \"gol\", \"jogo\", \"time\" is labelled as \"Sports and Games\". We follow the semantic taxonomy proposed by Lansley and Longley [LL16] to manually labelling each topic.\nWe observed that many different latent topics were about the same semantic subject but at different levels of granularity. For instance, \"European Football vs Brazilian Football\". We decided to manually aggregate these overlapping topics to create a simpler and easier to analyse list of topics, resulting in a total of 29 aggregated topics. We performed this process to both cities independently.\nThe resulting list of topics and their distribution (number of tweets) for both cities is depicted in Table 5.2. We first observe that the majority of topics is common in both cities, with exception of 4 topics: Weather and Shopping are not discussed in Rio de Janeiro; Antecipation & Socializing and Health are not discussed in S\u00e3o Paulo. We were not able to assign labels using the Lansley and Longley [LL16] taxonomy to 7 different topics. In such cases, we created our own labels, e.g., \"BBB17\" is about a highly popular reality TV show in Brazil named Big Brother Brazil.\nThere is a wide range of topics covered by both cities, from \"Food and Drink\", \"Politics\" and \"Religion\" to \"Sports and Games\" or \"Transportation and Travel\". The most talked topics in Rio de Janeiro are \"Relationships and Friendship\", \"Actions and Intentions\" and \"Sports and Games\", while in S\u00e3o Paulo, the most talked about topics are \"Personal Feelings\", \"Relationships and Friendship\" and \"Negativism, Pessimism and Anger\". Comparing both cities, the topics with higher relative difference are \"Relationships and Friendships\" (+16% in Rio de Janeiro) and \"Personal Feelings\" (+13% in S\u00e3o Paulo).\nWe also produced a day-of-the-week temporal distribution of topics in both cities as depicted in Figure 5.1. We selected 12 topics for Rio de Janeiro and 13 for S\u00e3o Paulo that are more prone\n50\nText Analytics Experiments\nto temporal shift of popularity, such as \"Religion\" and \"Sports and Games\" which are presumably more popular on the weekends. For both cities the topic \"Sports and Games\" is more mentioned on Tuesdays and Saturdays. Indeed, this observation correlates with Tuesdays where UEFA Champions League competition happens and Saturdays when occur Brazilian Football League matches. Also in both cities, \"Holidays and Weekends\" presented Sundays as the day where more people talk about it, while \"Religion\" and \"Tourism and Places\" are less prone to be talked about in Fridays, which is similar to all the remaining topics. \"Live Shows, Social Events and Nightlife\" are more talked about on Saturdays in Rio de Janeiro, while on S\u00e3o Paulo we identify Tuesdays as the day more popular. Sundays and Tuesdays are the days when the well-famous reality show TV program is emitted, and due to that exists more popularity in these days for the \"BBB17\" topic. \"Weather\" topic presents more activity in Saturday probably due to people going out to take a walk.\n51\nText Analytics Experiments"}, {"heading": "5.1.2 Final Remarks", "text": "To the best of our knowledge, this is the first large scale analysis of topic modelling of geo-located tweets from Rio de Janeiro and S\u00e3o Paulo. Most of the topics are common to both cities. Is is interesting to notice that people in Brazil post geo-located tweets about general purpose topics, such as reality TV show, health issues and relationship and friendship. Transportation and travel are marginal topics with less 2% of relative frequency in Rio de Janeiro and 2.3% in S\u00e3o Paulo.\nThis experiment demonstrates the capability of our framework to handle different topic modelling analysis under unregulated and non-conventional data such as the content found in most social media. The application of topic modeling technique to tweets from two different cities enables interesting comparisons between them since the whole analytics process accounts for what inhabitants talk about in their social networks. Through these analysis, cities\u2019 services are capable of monitoring human behaviour, activity patterns as well as of identifying regions where there may be some levels of intolerance on certain topics, making it possible to trigger preventive measures to solve problems in those specific areas.\nFuture direction for this research will include application of spatio-temporal aggregation methods over both datasets in order to create meta-documents (tweets group by day/hour/location) and verify whether results can be different taking into consideration temporal and spatial factors. To pursue this, it is required that a large dataset for both cities is available, which is expectable only in mid- to long-term."}, {"heading": "5.2 Travel-related Classification", "text": "The main goal of this section is to describe the experiments conducted to discriminate travelrelated tweets in Rio de Janeiro, S\u00e3o Paulo and New York City. Considering the volume of the\n52\nText Analytics Experiments\ncollected data for each scenario, it is necessary to automatically identify tweets whose content somehow suggests to be related to the transportation domain. Conventional approaches would require us to specify travel-related keywords to classify such tweets. On the contrary, our approach consisted in training a classification model to automatically discriminate travel-related tweets from non-related ones.\nOne big challenge always present in text analysis is the sparse nature of data, which is especially the case in Twitter messages. Conventional techniques such as bag-of-words tend to produce sparse representations, which become even worse when data is composed by informal and noisy content.\nWord embeddings, on the other hand, is a text representation technique that tries to capture syntactic and semantic relations from words. The result is a more cohesive representation where similar words are represented by similar vectors. For instance, \"taxi\"/\"uber\", \"bus/bus\u00e3o/\u00f4nibus\", \"go to work\"/\"go to school\"/\"ir para a escola\" would yield similar vectors respectively. We are particularly interested in exploring the characteristics of word embeddings techniques to understand which extent it is possible to improve the performance of our classifier to capture such travel-related expressions. In the reminder subsections, we describe two different text classification experiments following distinct approaches across two speaking languages - Portuguese and English. We trained the word embeddings using all tweets from the two different use cases with support of the Python\u2019s library, Gensim, and window size of 2.\nSupport Vector Machines (SVM), Logistic Regression (LR) and Random Forests (RF) were the classifiers used in these experiments. The SVM classifier was tested under three different kernels, namely rbf, sigmoid and linear; the latter proved to obtain the best results for both experiments.\nThe LR classifier was used with the standard parameters, whereas the RF classifier used 100 trees in the forest. The gini criterion and the maximum number of features were limited to those as aforementioned in Section 3.5.2.1, in the case of the RF classifier.\nTo evaluate the performance of classifiers in our experiences we used five different metrics:\nprecision, recall, F1-score, ROC and AUC.\nWe established the use of different groups of features to train our classification model, namely bag-of-words, bag-of-embeddings - word embeddings dependent technique - and both combined (horizontally combination of bag-of-words and bag-of-embeddings matrices into a single one)."}, {"heading": "5.2.1 Rio de Janeiro and S\u00e3o Paulo", "text": "Messages were collected for a period of a whole month, between days March 12 and April 12, 2017, and the resulting datasets sum up a total of 6.1M and 2.9M tweets for Rio de Janeiro and S\u00e3o Paulo, respectively. Due to the problem detected in Section 4.1, we filtered the data in order to use only tweets that were actually inside the cities\u2019 areas. The data considered in this experiment sum up a total of 7.7M tweets - 5.3M and 2.4M tweets for Rio de Janeiro and S\u00e3o Paulo, respectively.\n53\nText Analytics Experiments"}, {"heading": "5.2.1.1 Training and Test Datasets", "text": "The construction of the training and test sets followed a semi-automatic labeling approach. We tried to build a balanced training set, consisting of 2,000 travel-related tweets and 2,000 nonrelated. We start by searching tweets using specific travel-terms as described in study of Maghrebi et al. [MAW16]. Table 5.3 shows the terms used for querying each travel-mode. We found 30,000 tweets matching those terms. From this subset, we created a stratified random sample of 3,000 tweets and manually annotated them. We ended up with 2,000 tweets annotated as positive (travelrelated). To select negative examples we randomly sampled 2,000 tweets and manually verified if they were negative (non-travel-related).\nTo create a test set, we randomly selected 1,000 tweets different from the training set and then manually labelled them as travel-related or non-travel-related. We forced the positive test examples to contain travel-modes terms that were not used in the training set construction. For instance, the word \"uber\" is relted to the taxi travel-mode but is just available in the tests set and not in the training set. The same happens with the word \"bus\u00e3o\" which is an informal word meaning \"bus\". The idea of behind this approach is to try to access the robustness and generalization of the travel-related classifiers. In the end, 71 tweets were found to be travel-related and whereas 929 were not."}, {"heading": "5.2.1.2 Results and Analysis", "text": "Table 5.4 presents the results obtained using the different features combination for our test set composed by 1,000 tweets manually annotated. According to the evaluation metrics we conclude that the bag-of-word and bag-of-embeddings combined produced better classification models. The model produced by the Linear SVM performed slightly better than the LR and the RF. Interesting to note is that BoW features have influence on the precision scores obtained from our results, producing more conservative classifiers. Regarding the recall results, we can see that the Logistic Regression using only bag-of-embeddings features was the model with best results; perhaps if the precision is taken into consideration, the same conclusions will not be possible. Analysing the scores provided in Table 5.4, the best model under the F1-score was the Linear SVM, with a score of 0.85. It is worth noting that combining Bag-of-words and Bag-of-embedding with size 100 was the group of features with best performance taking into consideration the evaluation metrics used in this experiment.\n54\nText Analytics Experiments\n55\nText Analytics Experiments\nThe performance of all three classifiers is illustrated using the ROC Curve in Figure 5.2.\nThe area under the curve of the Receiver Operating Characteristic (AUROC) was very similar for both the Logistic Regression and the Linear SVM models. The results obtained from the Random Forest model were not so promising as expected since this classifier is pretty tough to beat due to its versatility.\nAfter the selection of our classification model, we decided to classify all the Portuguese dataset and draw some statistics from the results. The trained Linear SVM classifier was used to predict whether tweets were travel-related or not, since it was the model presenting the best score under the F1-score metric (as shown in Table 5.4). From a total of 7.8M tweets, our classifier was able identified 37,300 travel-related entries.\nFigure 5.3 depicts the distribution of travel-related tweets over the days of the week. We can see that the first three business days (Monday, Tuesday and Wednesday) are the ones on which the Twitter activity is higher for both cities in our study.\nIn order to understand the spatial distribution of travel-related tweets we generated a heatmap for both cities. From the heatmap of Rio de Janeiro, illustrated in Figure 5.4, it is possible to identify that some agglomerations of tweets are located at Central do Brasil, Cidade Nova and Triagem train stations, as well as at Uruguaiana, Maracan\u00e3 and Carioca metro stations. The Rio-Niter\u00f3i bridge, connecting Rio de Janeiro to Niter\u00f3i, as well as the piers on both sides also presented considerable clouds of tweets classified as travel-related.\nThe heatmap for the city of SP, illustrated in Figure 5.5, was also an interesting case to observe.\n56\nText Analytics Experiments\nAlmost every agglomeration matched some metro or train station. Esta\u00e7\u00e3o Br\u00e1s, Tatuap\u00e9, Bel\u00e9m, Esta\u00e7\u00e3o Paulista, S\u00e9, Liberdade were some of the stations highlighted in the heatmap. We could also identify a little agglomeration of travel-related tweets at Congonhas airport, even though no tweets seemed to mention the word plane explicitly in the training of our classification model."}, {"heading": "5.2.1.3 Final Remarks", "text": "The previous described experiment explores an approach of supervised learning using as training examples a set of manually annotated tweets extracted from the whole datasets with the support of a term-based regular expression. The overall methodology is concerned with the problem of construct a fine-grained Twitter training set for the travel domain and also the automatic identification of travel-related tweets from a large scale corpus. We combined different word representations to verify whether our classification model could learn relations between words at both syntactic and semantic levels. After using standard techniques such as bag-of-words and bag-of-embeddings, we have used them combined yielding results that showed that these different groups of features can complement each other, with respect to Portuguese-speaking tweets. Modes of transport are always evolving and new services emerges making the identification of tweets related to it difficult. Overall, our experiment proved that word-embeddings features are actually an advantage regarding its applicability into instable real-world scenarios such as the transportation domain.\n57\nText Analytics Experiments"}, {"heading": "5.2.2 New York City", "text": "Similar to the experiment of Portuguese-speaking travel-related classification of tweets, we built a model to discriminate English-speaking travel-related tweets. However, the construction of the training and test sets in this experiment follows a different approach. While in the Rio de Janeiro and S\u00e3o Paulo experiment we explore an semi-automatic approach and tweets were almost instantaneous formed as a group, here we were obligate to follow a two-phase approach due to the polysemy level of English travel terms.\nDifferently from the Brazilian cities experiment, tweets were collected from New York City during a period of two months, between days March 12 and May 12, 2017. Ignoring all nonEnglish, as well as tweets located outside the bounding-box of New York City, the resulting dataset comprehends 4M tweets.\nRegarding the preparation of data, we used the same preprocessing operations in both experiments, Brazilian and North-American. The operations were lowercasing, transformation of repeated characters and cleaning of entities (user mentions and URLs) from the message content."}, {"heading": "5.2.2.1 Training and Test Datasets", "text": "In the Portuguese dictionary, travel-related terms do not have more than one meaning. For instance \"caminhar\" or even \"comboio\" possesses only one meaning. Regarding the English dictionary, travel-related tweets may have more than one meaning since some of them present high level of polysemy. Terms such as \"walk\" may be used to describe the action of walk or, for example, the action of walk into. On the other hand, the term \"train\" can be used to describe the mode of transport train or a type of behaviour through practice and instruction.\nThe polysemy level of such terms was took into consideration while the construction process of our training set of tweets for the English-language travel-related classification model. In the first stage of the construction process, we used the same strategy of the Portuguese training set. By take support on a semi-automatic labeling technique using a regular expression, we find out almost 16,000 tweets. The next step in the construction process was a manually verification followed by a manually annotation. Overall, 1,686 tweets were selected for each of both binary classes, travelrelated and non-related. The travel-related set was strictly balanced in order to have almost the same amount of examples for each of the travel-modes involved in this study. The non-related training set is composed of several subjects that are not related to travel, e.g. football, leisure, politician, personal tweets, among others.\nNonetheless, we include into the training set tweets which polysemy level may induce doubts regarding the context of the message in order to make possible higher levels of discrimination in our model. This inclusion may help the learning process of our model making it capable of correctly identify which are the tweets that are actually related to the travel and transportation domain. The final composition of the training datasets is presented in Table 5.5.\n58\nText Analytics Experiments"}, {"heading": "5.2.2.2 Preliminary Results", "text": "Due to the laborious and time-consuming effort made in the construction of the training set, we opt to apply a different approach in the training phase of our model classification model. In order to enhance the differences between tweets whose terms present high levels of polysemy, the model was trained using a k-fold cross-validation technique with 10 iterations for all groups of features: bag-of-words and bag-of-embeddings and both combined. Results showed good performance for all models regarding the selected evaluation metrics. The best model in this experiment was the Logistic Regression classifier trained with bag-of-words and bag-of-embeddings features, presenting a F1-score of 0,98324.\nThe fact that all models performed incredibly well, in particular models using the features group of BoW and BoW+BoE raise to us some questions and doubts about the robustness of the features used in the training process. First, in the Brazilian cities experiment, by following the same approach over the training set construction process we did not obtain results of this kind. Second, the selected tweets are very specific and our model may be overfitted due to training data. In order to pursue and have answers to our questions, we designed another experiment using the same dataset.\nText Analytics Experiments\n5.2.2.3 Leave-one-group-out\nIt is worth noting that in our first experiment all travel-mode classes were known by the model before the classification of the test set (the remaining sub-dataset in the 10-fold cross-validation). Comparing with real-world scenarios, this may not be true since new modes of transport and companies, such as Uber, Lyft and Cabify, arise from unpredictable moments. This second experiment follows a leave-one-group-out strategy, meaning that one travel-mode class if left out of the training set and moved into the test set. Hence, the behaviour of the learned model when facing a completely unknown travel-mode class can be evaluated. A model for each hidden transportmode class was built and evaluated using the same training conditions and metrics. The datasets composition of each experiment led in this strategy can be observed in Table 5.7.\nFor each experiment of the learning models, we maintain a 10-fold cross-validation approach, however it was built a test set with a hidden travel-mode class and 300 non-related tweets (negative class). Here, only bag-of-words and bag-of-embeddings features were fed into our models classification routine since the main goal of this experiment is to check the features robustness. Table 5.8 presents the best results for each model, as so the group of features feeding it. To achieve the final results of this experiment, we calculated the mean between all models\u2019 results to each of the hidden transport-mode classes.\nAccording to results, all classification models have performed reasonably well under the bagof-embeddings features group, although the dimensionality used being different for the Linear SVM classifier.\nAfter testing each model with a hidden travel-mode class, the models trained with bag-ofwords features demonstrated poor performance when facing unknown travel-modes, revealing higher sensitivity and lower generalization capabilities in comparison to the bag-of-embeddings\nText Analytics Experiments\nversion. The generalization power is an important and crucial characteristic for our desired solution since in a real world scenario is very likely that we will face a higher variety of categories that were not taken into consideration in the training phase of our model. Having this considered, the bag-of-words features group presents lack of robustness as we doubt in our first experiment (Section 5.2.2.2).\nThe best result of the leave-one-group-out was the Linear SVM model, with the dimensionality of 200 in the size of the feature vectors. Figure 5.6 presents the results of each experiment led for the different hidden travel-mode classes. An interesting point to observe is the low performance obtained to the experiment with the travel-mode class \"Walk\" hidden. This is due to the different semantic and syntactic contexts that the word walk is used. Although all other classes can be used in the same context, for example, car, train, or bus, usually the word walk is not applied in the same way.\nHaving the experiments concluded, we used the best model, in this case, Linear SVM for the dimensionality of 200, to predict the 4M tweets that composed the NYC dataset. Almost 300,000 tweets were classified as travel-related. After the classification step, a sample of 10,000 tweets was taken from all the travel-related classified tweets and it was produced a heat-map distribution in order to verify which are the most concentrated zones. Such distribution enables the identification of associations with metro, train, bus stations. In Figure 5.7a, that shows the south of the Manhattan island and also the Brooklyn bridge, it is possible no note some agglomerations over the bridge and also in the port and closed to the Wall Street(4.5) where there are some metro stations. The Central Park is one place that also took our attention since presented several agglomerations of tweets. In this particular place, tweets related to the walk class were correctly identified.\n61\nText Analytics Experiments\n62\nText Analytics Experiments"}, {"heading": "5.2.3 Concluding Remarks", "text": "The main objective of this experiment was to devise a travel-related tweet classifier using word embeddings trained with geo-located English-speaking tweets. Similar to the Portuguese travelrelated classification, we tried to build our model using a combined approach relying on bag-ofwords and bag-of-embeddings features; however, results presented signs of dependency in the bag-of-words features which is not desired when facing real-world scenarios and lots of changes happen in short periods of time. On the other hand, by looking at the results, the almost perfect performance lead us to doubt about the existence of overfitting, and so, a leave-one-groupout strategy was applied to validate the robustness of features. There, we excluded one of the travel-modes classes, which resulted in the fact that models using bag-of-words features could not maintain the performance previously demonstrated. Comparatively to the approach based on bag-of-words, the models using bag-of-embeddings features revealed consistency and robustness in the classification task. The Linear SVM model proved to be the best option with respect to the performance metrics considered in this work. We thus used that model trained with bag-ofembeddings to predict all the travel-related English tweets from our NYC dataset, whose results showed significant improvement over a standard bag-of-words baseline. Finally, we applied the resulting classifier to a stream of geo-located tweets in New York City, which was able to depict important spatio-temporal patterns."}, {"heading": "5.3 Summary", "text": "This chapter has the purpose of report the experiments conducted over the period of this dissertation in order to help and validate the implementation of the different modules designed in our framework architecture.\nFirstly, topic modelling techniques were applied under Portuguese-speaking tweets for two different megacities, Rio de Janeiro and S\u00e3o Paulo, in order to extract information that may enabling interesting characterizations in different regions/zones of the cities regarding temporal and geographical distributions. Although huge restrictions regardind the labeling of each topic, results show promising contributions and informations to the smart cities entities, allowing until this point possible identifications of the most hot topics through time. The location of these topics is hard since, as it was mentioned in Section 4.1, the design of a geographical distribution is difficult because the majority of tweets do not have precisely location. In the future, this problem will need to be tackled in order to allow the cities\u2019 services possible geographical recognition of the topics.\nMoreover, two different classification models for travel-related tweets were developed taking into consideration two possible languages in texts, Portuguese and English. Under the implementation of the Portuguese classification, we were able to prove that the combination of conventional techniques (bag-of-words) and recent ones (word embeddings) performed very well. However, for the English-speaking messages, where polysemy levels are higher than Portuguese-speaking\n63\nText Analytics Experiments\nmessages, the same group of features did not perform well. Furthermore, by following a leaveone-group-out strategy, we study and proved robustness regarding word-ebeddings features. The omission of a transport-mode class cause the model fed with bag-of-words features to perform worst than the one using only bag-of-embeddings. Such results need to be seen as a positive point since through this experiment we were able to capable of produce two classification models with higher levels of generalization. The resulting models were used in the development of our frameworks\u2019 travel-related classification module. We can conclude that is now able of discriminate travel-related tweets for two distinct speaking languages based on two important factors: consistency and robustness.\n64\nChapter 6\nConclusions and Future Work"}, {"heading": "6.1 Final Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65", "text": ""}, {"heading": "6.2 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67", "text": ""}, {"heading": "6.3 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68", "text": ""}, {"heading": "6.4 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68", "text": ""}, {"heading": "6.1 Final Remarks", "text": "This work tackles the problem of extracting meaningful and actionable knowledge from user generated content in the scope of smart cities and intelligent transportation systems. We designed and developed a framework for collection, processing and mining of geo-located Tweets. More specifically, it provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization.\nThe Twitter Streaming API has three different heuristics to collect tweets: terms-based retrieval, following the activity of users and collect all tweets inside a specific bounding-box. The final stakeholders of our framework are cities and to provide content and geographical analysis, we opt for the locations heuristic. However, we found that several retrieved tweets do not respect the pre-defined bounding-box, i.e., the limits the tweets coordinates are outside the pre-defined bounding-box. Most of previous work using geo-located tweets do not take into account this phenomenon. We designed a filtering model capable to cope with noisy geo-located tweets. This module also filters out tweets written in any language besides the pre-defined English and Portuguese languages.\nTo analyse the text message of tweets, we design a text analytics module which is composed by two sub-modules. These sub-modules are in charge of performing topic modelling and travelrelated classification tasks. In the module responsible for characterize tweets over latent topics,\n65\nConclusions and Future Work\nwe needed to submit each tweet to a pre-defined group of text pre-processing operations. Lower casing, transformation of repeated characters, removal of metadata, punctuation. short tokens and Portuguese stop words are the pre-processing operations used to clean the text message and facilitate the identification of latent topics. With respect to the travel-related classification of tweets, we tried to combine different text representation to fed as features group in the training routine of our models. To clean and make easier the task of classification, we perform lower casing, transformation of repeated characters and removal of metadata and Portuguese and English stop words.\nTo aggregate the final results provided by the text analytics module, we used the MongoDB aggregation framework since it present high performance and scalability, dealing well with large volumes of data. Finally, the visualization of results explores a library capable of saving locally the graphical representations of results. By using this saving method, the framework only needs to execute its text and statistical analysis in specific periods of time since when a user requests for a visualization, there is no need to consult the data warehouse. Lower response time is one of the most important factors in systems dealing with high volumes of data.\nTo illustrate our approach we conduct an exploratory data analysis and performed experiments for each text analytics module in real-world scenarios. We performed empirical studies and implemented illustrative examples for 5 cities: Rio de Janeiro, S\u00e3o Paulo, New York City, London and Melbourne, comprising a total of more than 43 millions tweets in a period of 3 months. Through the exploratory data analysis we identify that more than 70% of tweets do not have a fine-grained geographic coordinate but they refer to bounding-boxes representing large areas on each city, such as \"Ipanema\". This fact reduces the ability to perform thorough spatial analysis of geo-located tweets.\nOur framework focuses on content analysis of geo-located tweets. We performed a topic modeling experiment for a large volume of tweets from the two most populous and active Brazilian cities, Rio de Janeiro and S\u00e3o Paulo. The latent topics discovered might serve as actionable information to cities helping in the monitoring of what is being talked about in its urban regions. Both Rio de Janeiro and S\u00e3o Paulo presented similar latent topics in which 25 of them were equal and only 2 latent topics were specific of each city, summing up a total of 29 distinct topics. It is worth to notice that our latent topic model was capable of recognize general purpose topics such as \"Relationship ad Friendship\" and \"Personal Feelings\", making us to question why Brazilian people talk about such personal subjects into social media networks.\nIn the experiment of travel-related tweets classification, we constructed different gold standard datasets for two distinct speaking-languages, Portuguese and English. In the features construction process, we take support of recent advanced text mining techniques such as word-embeddings. This technique enhances the semantic and syntactic similarities between text messages allowing the identification that \"bus\u00e3o\" (a Brazilian informal term for the bus transport-mode) is used in the same context that is formal term \"\u00f4nibus\". We have further used the embedding matrix (bag-ofembeddings) of tweets in combination with bag-of-words features to train our text classifiers. The Portuguese classification model performed very well and was able to discriminate tweets which\n66\nConclusions and Future Work\ntravel terms were omitted from the training process. The classification of tweets having \"Uber\" and \"Bus\u00e3o\" as travel-related ones is a proof of the robustness and generalization of our model.\nOn the other hand, the English text classifier revealed high levels of dependency with the bagof-words features. The training set of this model was conducted using a k-fold cross-validation technique since English travel-terms, such as \"Walk\" and \"Train\", have high levels of polysemy. The preliminary scores of our model were almost perfect and beacuse of that, we designed a new strategy to conduct the remainder of the experiment. By following a leave-one-group-out strategy, we verified that models trained with word embeddings features maintain their performance while models trained with bag-of-words have drastically decrease its performance. Such strategy was enough to conclude the lack of robustness in the bag-of-words features making us to decide to use of a model trained with word-embeddings into the framework implementation for English speaking cities.\nRegarding the Portuguese cities, we chose to use the model trained with both type of features:\nBoE and BoW."}, {"heading": "6.2 Contributions", "text": "At the end of this dissertation, we summarise the contributions achieve in three main dimensions:\n\u2022 Technical Contributions We designed and developed an open-source framework implemented in Python programming language using the Tweepy library for collecting geo-\nlocated tweets. Our implementation allows the collection of multiple and parallel boundingboxes (cities or regions) and it is complying with the Twitter Streaming API usage limits. We opted to use a no-SQL database (MongoDB) as data storage software which provides flexibility, scalability and adaptability to the framework. We rely on Python\u2019s LDA library fro topic modelling, Gensim library to train paragraph2vec embeddings from geo-located tweets and Sckit-learn to train the test classifiers. The framework also provide flexible aggregations and on-time visualization using the Plotly library. The framework can be used in multiple application scenarios, from different content languages to different levels of geographic granularity (streets vs cities vs regions vs countries).\n\u2022 Applicational Contributions To the best of our knowledge this work is the first large scale comparative topic modelling study of geo-located tweets in Brazilian megacities. We are\nalso the first to explore the recent advances in word-embeddings with application to text classification in the scope of smart cities and intelligent transportation cities.\n\u2022 Scientific Contributions We performed empirical evaluation on the applicability and robustness of word-embeddings representation as features to train a travel-related classifier of\ngeo-located tweets. To perform these studies, we had to create new gold standard data that can be used by the community for further experimentation.\n67\nConclusions and Future Work\nThe main finding of the analysis carried out were documented in papers submitted to conferences as follows."}, {"heading": "6.3 Publications", "text": "During the period of this dissertation, we published three different scientific papers in order to share our experiments\u2019 methodologies and results.\n\u2022 Jo\u00e3o Pereira, Arian Pasquali, Pedro Saleiro and Rosaldo J. F. Rossetti. Transportation in Social Media: an automatic classifier for travel-related tweets. In Portuguese Conference\non Artificial Intelligence (EPIA), 2017. In Press [PPSR17].\n\u2022 Jo\u00e3o Pereira, Arian Pasquali, Pedro Saleiro, Rosaldo J. F. Rossetti and Javier SanchezMedina. Classifying Travel-related Tweets Using Word Embeddings. In IEEE 20th In-\nternational Conference on Intelligent Transportation Systems (IEEE ITSC), 2017. Under review.\n\u2022 Jo\u00e3o Pereira, Arian Pasquali, Pedro Saleiro, Rosaldo J. F. Rossetti and N\u00e9lio Cacho. Characterizing Geo-located Tweets in Brazilian Megacities. In The Third International Smart\nCities Conference (ISC2), 2017. Under review."}, {"heading": "6.4 Future Work", "text": "The dissertation purpose had as it main focus the conception of an automatic system capable of analyse real-time data streams from social media platforms in order to produce valuable information for users of services or even its responsible entities. For achieve the proposed goals, we tried to explore already consistent state-of-the-art methodologies as well as unexplored ones regarding specific domains. Since this framework can be seen as a prototype of a future complex system, several improvements can be invested here. Although already existent modules and text analysis devised, it worth noting the conjecture of a additional sentiment analysis module in order to infer the sentiment polarity value regarding specific zones where the travel-related tweets were located in, as so the overall sentiment in an identified topic.\nIn this dissertation we trained word embeddings using geo-located tweets to further use such embeddings matrices as features to train our transportation text classifiers. Later we will perform an intrinsic evaluation of these word embeddings in order to publicly share benchmarks for travelrelated terms as Saleiro et al. [SSR+17] have made using general tweets to study practical aspects of this text representation.\nThe extension of our training and test sets is other future work to take into consideration, as\nwell as the application of deep learning classifiers into our classification tasks.\nNonetheless, we can explore a way of predicting future events in a city or even the impact that certain transportation entities will have in specific places [SS16] in order to monitor correctly the the agglomeration of people in these places and the roads traffic.\n68\nConclusions and Future Work\nAnother important work to pursue in the future is to correlate the results of this study with official sources of transportation agencies relatively to traffic congestions and other events on the transportation network, including all modes of transports and their integration interfaces and modules. This kind of association will be useful both to validate the proposed approach as well as to improve the inference process and knowledge extraction. The automatic classifier herein presented will then be integrated into data fusion routines to enhance transportation supply and demand prediction processes alongside other sensors and sources of information. Additionally, such correlations and inference results can be very useful as input to traffic simulation tools [PRK11, ARB15], and to support multi-resolution and multi-purpose transportation analysis [TARO10, FERO08].\nA possible future direction to improve the topic modelling approach is the application of spatio-temporal aggregation methods under a sample of data to create more complex documents, retrain the model and verify if the results can be different taking into consideration some of the factors that distinguish both cities: demographics, culture and location. An attempt to pursue good performances using supervised LDA models also needs to be enhanced here.\nLastly, there is a need of creation of other specific models to other fields of a smart city in order to assure equally performances for any of its fields. Nonetheless, this work will also be integrated into the MAS-Ter Lab framework [ROB07], whose main objective is to support the design, evaluation, and implementation of transportation engineering solutions and smart mobility relying on the concept of Artificial Transportation Systems [RL14a], combining both data- and model-driven methodologies.\n69\nConclusions and Future Work\n70\nAcronyms\nAPI Application Programming Interface. 24\u201326, 30, 32, 70\nAUC Area Under the Curve. 17, 70\nBoE Bag-of-embeddings. 30, 31, 59, 67, 70\nBoW Bag-of-words. 13, 30, 54, 59, 67, 70\nCRF Conditional Random Fields. 14, 70\nDT J48 Decision Trees J48. 15, 16, 70\nFPR False Positive Rate. 17, 70\nGPS Global Positioning System. 26, 70\nHTML HyperText Markup Language. 32, 70\nICT Information and Communications Technology. 8, 9, 70\nIQR Interquartile-range. 44, 70\nITS Intelligent Transportation Systems. 3, 4, 9, 70\nJSON JavaScript Object Notation. 32, 70\nLDA Latent Dirichlet Allocation. xi, 13\u201315, 29, 49, 70\nMLP Multilayer Perceptron. 15, 70\nNB Na\u00efve Bayes. 15, 16, 70\nNED Name Entity Disambiguation. 12, 70\nNLP Natural Language Processing. 3, 11, 21, 22, 70\nNLTK Natural Language Toolkit. 27, 28, 30, 70\nOLS Ordinary Least Squares. 15, 16, 70\nPOS Part-of-the-Speech Tagging. 14, 70\n71\nAcronyms\nREST Representational State Transfer. 24, 70\nRF Random Forests. 15, 70\nROC Receiver Operating Characteristic. 17, 70\nSM Smart Mobility. 9, 70\nSMA Social Media Analytics. 11, 13, 70\nSMC Social Media Content. 1, 2, 16, 70\nSVM Suport Vector Machines. 15, 16, 70\nTPR True Positive Rate. 17, 70\nUGC User Generated Content. 70\nUI User Interface. 70\nUTC Coordinated Universal Timezone. 28, 70\nWSD Word Sense Disambiguation. 12, 13, 70\n72\nGlossary\nbounding-box A bounding-box is a rectangle obtained by two coordinate pairs (latitude and longitude, for the South-West point and the North-East point). 22, 24, 70\nCrowdsensing or mobile crowdsensing Technique used to collectively share and extract information from large groups of individuals in order to analyse, infer or even measure processes\nof common interest. 9, 70\nInfluenza A Influenza A is a type of virus capable of infecting animals, although it is more common for people to suffer the ailments associated with this type of flu. 15, 70\nk-fold cross-validation It is a technique where the original dataset is randomly partitioned into k equal sized sub-datasets. Of the k sub-datasets, only one is retained as the validation data\nfor testing the model, and the remaining k - 1 sub-datasets are used as training data. 59, 67, 70\nMicroBlog It is a tool that allows quick abd short status updates, and if possible, through multiple different platforms. 70\nTwitter Firehose It is a paid Twitter service that guarantees the delivery of 100% of the tweets matched with certain criteria. 24, 70\n73\nGlossary\n74"}], "references": [{"title": "Urban and social sensing for sustainable mobility in smart cities", "author": ["Giuseppe Anastasi", "Michela Antonelli", "Alessio Bechini", "Simone Brienza", "Eleonora D\u2019Andrea", "Domenico De Guglielmo", "Pietro Ducange", "Beatrice Lazzerini", "Francesco Marcelloni", "Armando Segatori"], "venue": "In Sustainable Internet and ICT for Sustainability (SustainIT),", "citeRegEx": "Anastasi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Anastasi et al\\.", "year": 2013}, {"title": "The national centre for text mining: Aims and objectives", "author": ["Sophia Ananiadou", "Julia Chruszcz", "John Keane", "John McNaught", "Paul Watry"], "venue": "[Accessed on 25/06/2017]", "citeRegEx": "Ananiadou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Ananiadou et al\\.", "year": 2005}, {"title": "Twitcident. Proceedings of the 21st international conference companion on World Wide Web - WWW", "author": ["Fabian Abel", "Claudia Hauff", "Geert-Jan Houben", "Richard Stronkman", "Ke Tao"], "venue": "Cited on page 18", "citeRegEx": "Abel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Abel et al\\.", "year": 2012}, {"title": "Smart cities: A conjuncture of four", "author": ["Margarita Angelidou"], "venue": "forces. Cities,", "citeRegEx": "Angelidou.,? \\Q2015\\E", "shortCiteRegEx": "Angelidou.", "year": 2015}, {"title": "A state-of-the-art integrated transportation simulation platform. In Models and Technologies for Intelligent Transportation Systems", "author": ["Tiago Azevedo", "Rosaldo JF Rossetti", "Jorge G Barbosa"], "venue": "(MT-ITS), 2015 International Conference on,", "citeRegEx": "Azevedo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Azevedo et al\\.", "year": 2015}, {"title": "Smart cities of the future", "author": ["Michael Batty", "Kay W Axhausen", "Fosca Giannotti", "Alexei Pozdnoukhov", "Armando Bazzani", "Monica Wachowicz", "Georgios Ouzounis", "Yuval Portugali"], "venue": "The European Physical Journal Special Topics,", "citeRegEx": "Batty et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Batty et al\\.", "year": 2012}, {"title": "Short-term real-time traffic prediction methods: A survey. In Models and Technologies for Intelligent Transportation Systems", "author": ["Joaquim Barros", "Miguel Araujo", "Rosaldo JF Rossetti"], "venue": "(MT-ITS), 2015 International Conference on,", "citeRegEx": "Barros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Barros et al\\.", "year": 2015}, {"title": "Twitie: An open-source information extraction pipeline for microblog text", "author": ["Kalina Bontcheva", "Leon Derczynski", "Adam Funk", "Mark A Greenwood", "Diana Maynard", "Niraj Aswani"], "venue": "In RANLP, pages 83\u201390,", "citeRegEx": "Bontcheva et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bontcheva et al\\.", "year": 2013}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of machine Learning research,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Do Smart Cities Invest in Smarter Policies? Learning From the Past, Planning for the Future", "author": ["Andrea Caragliu", "Chiara F. Del Bo"], "venue": "Social Science Computer Review,", "citeRegEx": "Caragliu and Bo.,? \\Q2015\\E", "shortCiteRegEx": "Caragliu and Bo.", "year": 2015}, {"title": "Smart cities in europe", "author": ["Andrea Caragliu", "Chiara Del Bo", "Peter Nijkamp"], "venue": "Journal of urban technology,", "citeRegEx": "Caragliu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Caragliu et al\\.", "year": 2011}, {"title": "Review on ITS in Smart City", "author": ["Byung-tae Chun", "Seong-hoon Lee"], "venue": "Advanced Science and Technology Letters,", "citeRegEx": "Chun and Lee.,? \\Q2015\\E", "shortCiteRegEx": "Chun and Lee.", "year": 2015}, {"title": "A comparison of named-entity disambiguation and word sense disambiguation", "author": ["Angel X Chang", "Valentin I Spitkovsky", "Christopher D Manning", "Eneko Agirre"], "venue": "In LREC,", "citeRegEx": "Chang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2016}, {"title": "Real-time sensing of traffic information in twitter messages", "author": ["Sara Carvalho", "Lu\u00eds Sarmento", "Rosaldo J.F. Rossetti"], "venue": "In 4th Workshop on Artificial Transportation Systems and Simulation (ATSS),", "citeRegEx": "Carvalho et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2010}, {"title": "Real-Time Detection of Traffic from Twitter Stream Analysis", "author": ["Eleonora D\u2019Andrea", "Pietro Ducange", "Beatrice Lazzerini", "Francesco Marcelloni"], "venue": "IEEE Transactions on Intelligent Transportation Systems,", "citeRegEx": "D.Andrea et al\\.,? \\Q2015\\E", "shortCiteRegEx": "D.Andrea et al\\.", "year": 2015}, {"title": "Social media enabled human sensing for smart cities", "author": ["Derek Doran", "Karl Severin", "Swapna Gokhale", "Aldo Dagnino"], "venue": "AI Communications,", "citeRegEx": "Doran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Doran et al\\.", "year": 2015}, {"title": "A cooperative simulation framework for traffic and transportation engineering", "author": ["Paulo AF Ferreira", "Edgar F Esteves", "Rosaldo JF Rossetti", "Eug\u00e9nio C Oliveira"], "venue": "In International Conference on Cooperative Design, Visualization and Engineering,", "citeRegEx": "Ferreira et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ferreira et al\\.", "year": 2008}, {"title": "Unveiling the Power of Social Media Analytics", "author": ["Weiguo Fan", "Michael D Gordon"], "venue": "Communications of the ACM,", "citeRegEx": "Fan and Gordon.,? \\Q2013\\E", "shortCiteRegEx": "Fan and Gordon.", "year": 2013}, {"title": "Sensing bluetooth mobility data: potentials and applications", "author": ["Joao Filgueiras", "Rosaldo JF Rossetti", "Zafeiris Kokkinogenis", "Michel Ferreira", "Cristina Olaverri-Monreal", "Marco Paiva", "Jo\u00e3o Manuel RS Tavares", "Joaquim Gabriel"], "venue": "In Computer-based Modelling and Optimization in Transportation,", "citeRegEx": "Filgueiras et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Filgueiras et al\\.", "year": 2014}, {"title": "The potential of social media in delivering transport policy goals", "author": ["Ayelet Gal-Tzur", "Susan M Grant-Muller", "Tsvi Kuflik", "Einat Minkov", "Silvio Nocera", "Itay Shoor"], "venue": "Transport Policy,", "citeRegEx": "Gal.Tzur et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gal.Tzur et al\\.", "year": 2014}, {"title": "A brief survey of text mining", "author": ["Andreas Hotho", "Andreas N\u00fcrnberger", "Gerhard Paa\u00df"], "venue": "In Ldv Forum,", "citeRegEx": "Hotho et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hotho et al\\.", "year": 2005}, {"title": "Will the real smart city please stand up? intelligent, progressive or entrepreneurial? City", "author": ["Robert G Hollands"], "venue": "Cited on page", "citeRegEx": "Hollands.,? \\Q2008\\E", "shortCiteRegEx": "Hollands.", "year": 2008}, {"title": "Social media competitive analysis and text mining: A case study in the pizza industry", "author": ["Wu He", "Shenghua Zha", "Ling Li"], "venue": "International Journal of Information Management,", "citeRegEx": "He et al\\.,? \\Q2013\\E", "shortCiteRegEx": "He et al\\.", "year": 2013}, {"title": "Twitter user profiling based on text and community mining for market analysis", "author": ["Kazushi Ikeda", "Gen Hattori", "Chihiro Ono", "Hideki Asoh", "Teruo Higashino"], "venue": "Knowledge-Based Systems,", "citeRegEx": "Ikeda et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ikeda et al\\.", "year": 2013}, {"title": "Mobility network evaluation in the user perspective: Real-time sensing of traffic information in twitter messages", "author": ["Zafeiris Kokkinogenis", "J Filguieras", "Sara Carvalho", "Lu\u00eds Sarmento", "RJ Rossetti"], "venue": "Advances in Artificial Transportation Systems and Simulation,", "citeRegEx": "Kokkinogenis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kokkinogenis et al\\.", "year": 2015}, {"title": "What is twitter, a social network or a news media", "author": ["Haewoon Kwak", "Changhyun Lee", "Hosung Park", "Sue Moon"], "venue": "In Proceedings of the 19th international conference on World wide web,", "citeRegEx": "Kwak et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kwak et al\\.", "year": 2010}, {"title": "Automating a framework to extract and analyse transport related social media content: The potential and the challenges", "author": ["Tsvi Kuflik", "Einat Minkov", "Silvio Nocera", "Susan Grant-Muller", "Ayelet Gal-Tzur", "Itay Shoor"], "venue": "Transportation Research Part C: Emerging Technologies,", "citeRegEx": "Kuflik et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Kuflik et al\\.", "year": 2017}, {"title": "Intelligent cities: towards interactive and global innovation environments", "author": ["Nicos Komninos"], "venue": "International Journal of Innovation and Regional Development,", "citeRegEx": "Komninos.,? \\Q2009\\E", "shortCiteRegEx": "Komninos.", "year": 2009}, {"title": "Evaluating the usability of geo-located twitter as a tool for human activity and mobility patterns: A case study for new york city", "author": ["Abdullah Kurkcu", "Kaan Ozbay", "Ender Faruk Morgul"], "venue": "In Transportation Research Board 95th Annual Meeting,", "citeRegEx": "Kurkcu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kurkcu et al\\.", "year": 2016}, {"title": "Understanding sequential decisions via inverse reinforcement learning", "author": ["Siyuan Liu", "Miguel Araujo", "Emma Brunskill", "Rosaldo Rossetti", "Joao Barros", "Ramayya Krishnan"], "venue": "In Mobile Data Management (MDM),", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Using Social Media to Infer Gender Composition of Commuter Populations", "author": ["Wendy Liu", "Faiyaz Al Zamal", "Derek Ruths"], "venue": "Sixth International AAAI Conference on Weblogs and Social Media, pages 26\u201329,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Extracting and evaluating conversational patterns in social media: A socio-semantic analysis of customers\u2019 reactions to the launch of new products using Twitter streams", "author": ["Carlo Lipizzi", "Luca Iandoli", "Jos?? Emmanuel Ramirez Marquez"], "venue": "International Journal of Information Management,", "citeRegEx": "Lipizzi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lipizzi et al\\.", "year": 2015}, {"title": "The geography of twitter topics in london", "author": ["Guy Lansley", "Paul A Longley"], "venue": "Computers, Environment and Urban Systems,", "citeRegEx": "Lansley and Longley.,? \\Q2016\\E", "shortCiteRegEx": "Lansley and Longley.", "year": 2016}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc Le", "Tomas Mikolov"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Le and Mikolov.,? \\Q2014\\E", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Transportation application of social media: Travel mode extraction", "author": ["Mojtaba Maghrebi", "Alireza Abbasi", "S Travis Waller"], "venue": "In Intelligent Transportation Systems (ITSC),", "citeRegEx": "Maghrebi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Maghrebi et al\\.", "year": 2016}, {"title": "Supervised topic models. In Advances in neural information processing systems, pages 121\u2013128", "author": ["Jon D Mcauliffe", "David M Blei"], "venue": "Cited on page", "citeRegEx": "Mcauliffe and Blei.,? \\Q2008\\E", "shortCiteRegEx": "Mcauliffe and Blei.", "year": 2008}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "arXiv preprint arXiv:1301.3781,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Twitter interactions as a data source for transportation incidents", "author": ["Eric Mai", "Rob Hranac"], "venue": "In Proc. Transportation Research Board 92nd Ann. Meeting,", "citeRegEx": "Mai and Hranac.,? \\Q2013\\E", "shortCiteRegEx": "Mai and Hranac.", "year": 2013}, {"title": "The effects of data collection methods in twitter", "author": ["Sunghwan Mac Kim", "Stephen Wan", "C\u00e9cile Paris", "Brian Jin", "Bella Robinson"], "venue": "NLP+ CSS 2016,", "citeRegEx": "Kim et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2016}, {"title": "Is the sample good enough? comparing data from twitter\u2019s streaming api with twitter\u2019s firehose", "author": ["Fred Morstatter", "J\u00fcrgen Pfeffer", "Huan Liu", "Kathleen M Carley"], "venue": "arXiv preprint arXiv:1306.5204,", "citeRegEx": "Morstatter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Morstatter et al\\.", "year": 2013}, {"title": "Origins of power-law degree distribution in the heterogeneity of human activity in social networks", "author": ["Lev Muchnik", "Sen Pei", "Lucas C Parra", "Saulo DS Reis", "Jos\u00e9 S Andrade Jr.", "Shlomo Havlin", "Hern\u00e1n A Makse"], "venue": "arXiv preprint arXiv:1304.4523,", "citeRegEx": "Muchnik et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Muchnik et al\\.", "year": 2013}, {"title": "Improving lda topic models for microblogs via tweet pooling and automatic labeling", "author": ["Rishabh Mehrotra", "Scott Sanner", "Wray Buntine", "Lexing Xie"], "venue": "In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Mehrotra et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mehrotra et al\\.", "year": 2013}, {"title": "Crowdpulse: A framework for real-time semantic analysis of social streams", "author": ["Cataldo Musto", "Giovanni Semeraro", "Pasquale Lops", "Marco de Gemmis"], "venue": "Information Systems,", "citeRegEx": "Musto et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Musto et al\\.", "year": 2015}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig"], "venue": "In Hlt-naacl,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Pharmacovigilance from social media: mining adverse drug reaction mentions using sequence labeling with word embedding cluster features", "author": ["Azadeh Nikfarjam", "Abeed Sarker", "Karen O\u2019Connor", "Rachel Ginn", "Graciela Gonzalez"], "venue": "Journal of the American Medical Informatics Association,", "citeRegEx": "Nikfarjam et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nikfarjam et al\\.", "year": 2015}, {"title": "Tweetmotif: Exploratory search and topic summarization for twitter", "author": ["Brendan O\u2019Connor", "Michel Krieger", "David Ahn"], "venue": "In ICWSM, pages 384\u2013385,", "citeRegEx": "O.Connor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "O.Connor et al\\.", "year": 2010}, {"title": "Sentibubbles: Topic modeling and sentiment visualization of entity-centric tweets", "author": ["Jo\u00e3o Oliveira", "Mike Pinto", "Pedro Saleiro", "Jorge Teixeira"], "venue": "In Proceedings of the Ninth International C* Conference on Computer Science & Software Engineering,", "citeRegEx": "Oliveira et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oliveira et al\\.", "year": 2016}, {"title": "Social Media Analytics, pages 247\u2013269", "author": ["Judah Phillips"], "venue": "Cited on page", "citeRegEx": "Phillips.,? \\Q2012\\E", "shortCiteRegEx": "Phillips.", "year": 2012}, {"title": "Transportation in social media: an automatic classifier for travel-related tweets", "author": ["Jo\u00e3o Pereira", "Arian Pasquali", "Pedro Saleiro", "Rosaldo JF Rossetti"], "venue": "In Progress in Artificial Intelligence,", "citeRegEx": "Pereira et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Pereira et al\\.", "year": 2017}, {"title": "Towards the next-generation traffic simulation tools: a first appraisal", "author": ["Lucio Sanchez Passos", "Rosaldo JF Rossetti", "Zafeiris Kokkinogenis"], "venue": "In Information systems and technologies (CISTI),", "citeRegEx": "Passos et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Passos et al\\.", "year": 2011}, {"title": "Characterizing microblogs with topic models", "author": ["Daniel Ramage", "Susan T Dumais", "Daniel J Liebling"], "venue": "ICWSM, 10:1\u20131,", "citeRegEx": "Ramage et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ramage et al\\.", "year": 2010}, {"title": "Little words can make a big difference for text classification", "author": ["Ellen Riloff"], "venue": "In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,", "citeRegEx": "Riloff.,? \\Q1995\\E", "shortCiteRegEx": "Riloff.", "year": 1995}, {"title": "Advances in artificial transportation systems and simulation, 2014", "author": ["Rosaldo JF Rossetti", "Ronghui Liu"], "venue": "Cited on page", "citeRegEx": "Rossetti and Liu.,? \\Q2014\\E", "shortCiteRegEx": "Rossetti and Liu.", "year": 2014}, {"title": "The digital marketing skills gap : Developing a Digital Marketer Model for the communication industries", "author": ["Jo Royle", "Audrey Laing"], "venue": "International Journal of Information Management,", "citeRegEx": "Royle and Laing.,? \\Q2014\\E", "shortCiteRegEx": "Royle and Laing.", "year": 2014}, {"title": "Harnessing the crowds for smart city sensing", "author": ["Haggai Roitman", "Jonathan Mamou", "Sameep Mehta", "Aharon Satt", "L.V. Subramaniam"], "venue": "In Proceedings of the 1st International Workshop on Multimodal Crowd Sensing,", "citeRegEx": "Roitman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Roitman et al\\.", "year": 2012}, {"title": "Towards a specification of a framework for sustainable transportation analysis", "author": ["Rosaldo JF Rossetti", "Eug\u00e9nio C Oliveira", "Ana LC Bazzan"], "venue": "In 13th Portuguese Conference on Artificial Intelligence,", "citeRegEx": "Rossetti et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rossetti et al\\.", "year": 2007}, {"title": "Software framework for topic modelling with large corpora", "author": ["Radim Rehurek", "Petr Sojka"], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks. Citeseer,", "citeRegEx": "Rehurek and Sojka.,? \\Q2010\\E", "shortCiteRegEx": "Rehurek and Sojka.", "year": 2010}, {"title": "Twitterjam: Identification of mobility patterns in urban centers based on tweets", "author": ["Francisco Rebelo", "Carlos Soares", "Rosaldo JF Rossetti"], "venue": "In Smart Cities Conference (ISC2),", "citeRegEx": "Rebelo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rebelo et al\\.", "year": 2015}, {"title": "Overview and semantic issues of text mining", "author": ["Anna Stavrianou", "Periklis Andritsos", "Nicolas Nicoloyannis"], "venue": "ACM Sigmod Record,", "citeRegEx": "Stavrianou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Stavrianou et al\\.", "year": 2007}, {"title": "Popmine: Tracking political opinion on the web. In Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM), 2015", "author": ["Pedro Saleiro", "Silvio Amir", "M\u00e1rio Silva", "Carlos Soares"], "venue": "IEEE International Conference on,", "citeRegEx": "Saleiro et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2015}, {"title": "Short text classification in twitter to improve information filtering", "author": ["Bharath Sriram", "Dave Fuhry", "Engin Demir", "Hakan Ferhatosmanoglu", "Murat Demirbas"], "venue": "In Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Sriram et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sriram et al\\.", "year": 2010}, {"title": "Framework for smart city applications based on participatory sensing", "author": ["R\u00f3bert Szab\u00f3", "K\u00e1roly Farkas", "M\u00e1rton Isp\u00e1ny", "Andr\u00e1s A Benczur", "Norbert B\u00e1tfai", "P\u00e9ter Jeszenszky", "S\u00e1ndor Laki", "Anik\u00f3 V\u00e1gner", "Lajos Koll\u00e1r", "Cs Sidl\u00f3"], "venue": "In Cognitive Infocommunications (CogInfoCom),", "citeRegEx": "Szab\u00f3 et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szab\u00f3 et al\\.", "year": 2013}, {"title": "Sentiment aggregate functions for political opinion polling using microblog streams", "author": ["Pedro Saleiro", "Lu\u00eds Gomes", "Carlos Soares"], "venue": "In Proceedings of the Ninth International C* Conference on Computer Science & Software Engineering,", "citeRegEx": "Saleiro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2016}, {"title": "Texrep: A text mining framework for online reputation monitoring", "author": ["Pedro Saleiro", "Eduarda Mendes Rodrigues", "Carlos Soares", "Eugenio Oliveira"], "venue": "New Generation Computing,", "citeRegEx": "Saleiro et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2017}, {"title": "Using gps-based avl data to calculate and predict traffic network performance metrics: A systematic review", "author": ["Miguel Sandim", "Rosaldo JF Rossetti", "Daniel C Moura", "Zafeiris Kokkinogenis", "Thiago RPM R\u00fabio"], "venue": "In Intelligent Transportation Systems (ITSC),", "citeRegEx": "Sandim et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sandim et al\\.", "year": 2016}, {"title": "Popstar at replab 2013: Name ambiguity resolution on twitter", "author": ["Pedro Saleiro", "Luis Rei", "Arian Pasquali", "Carlos Soares", "Jorge Teixeira", "F\u00e1bio Pinto", "Mohammad Nozari Zarmehri", "Catarina F\u00e9lix", "Pedro Strecht"], "venue": "In CLEF (Working Notes),", "citeRegEx": "Saleiro et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2013}, {"title": "Feup at semeval-2017 task 5: Predicting sentiment polarity and intensity", "author": ["Pedro Saleiro", "Eduarda Mendes Rodrigues", "Carlos Soares", "Eug\u00e9nio Oliveira"], "venue": null, "citeRegEx": "Saleiro et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2017}, {"title": "Learning from the news: Predicting entity popularity on twitter", "author": ["Pedro Saleiro", "Carlos Soares"], "venue": "In International Symposium on Intelligent Data Analysis,", "citeRegEx": "Saleiro and Soares.,? \\Q2016\\E", "shortCiteRegEx": "Saleiro and Soares.", "year": 2016}, {"title": "The use of twitter to track levels of disease activity and public concern in the us during the influenza a h1n1 pandemic", "author": ["Alessio Signorini", "Alberto Maria Segre", "Philip M Polgreen"], "venue": "PloS one,", "citeRegEx": "Signorini et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Signorini et al\\.", "year": 2011}, {"title": "Learning word embeddings from the portuguese twitter stream: A study of some practical aspects", "author": ["Pedro Saleiro", "Lu\u00eds Sarmento", "Eduarda Mendes Rodrigues", "Carlos Soares", "Eug\u00e9nio Oliveira"], "venue": "In Progress in Artificial Intelligence,", "citeRegEx": "Saleiro et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2017}, {"title": "Twitterstand: news in tweets", "author": ["Jagan Sankaranarayanan", "Hanan Samet", "Benjamin E Teitler", "Michael D Lieberman", "Jon Sperling"], "venue": "In Proceedings of the 17th acm sigspatial international conference on advances in geographic information systems,", "citeRegEx": "Sankaranarayanan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sankaranarayanan et al\\.", "year": 2009}, {"title": "Timemachine: Entity-centric search and visualization of news archives", "author": ["Pedro Saleiro", "Jorge Teixeira", "Carlos Soares", "Eug\u00e9nio Oliveira"], "venue": "In European Conference on Information Retrieval,", "citeRegEx": "Saleiro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Saleiro et al\\.", "year": 2016}, {"title": "Trasmapi: An api oriented towards multi-agent systems real-time interaction with multiple traffic simulators", "author": ["Ivo JPM Tim\u00f3teo", "Miguel R Ara\u00fajo", "Rosaldo JF Rossetti", "Eugenio C Oliveira"], "venue": "In Intelligent Transportation Systems (ITSC),", "citeRegEx": "Tim\u00f3teo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tim\u00f3teo et al\\.", "year": 2010}, {"title": "Quantifying product favorability and extracting notable product features using large scale social media data", "author": ["Suppawong Tuarob", "Conrad S Tucker"], "venue": "Journal of Computing and Information Science in Engineering,", "citeRegEx": "Tuarob and Tucker.,? \\Q2015\\E", "shortCiteRegEx": "Tuarob and Tucker.", "year": 2015}, {"title": "Mining social media for open innovation in transportation systems", "author": ["Daniela Ulloa", "Pedro Saleiro", "Rosaldo JF Rossetti", "Elis Regina Silva"], "venue": "In Intelligent Transportation Systems (ITSC),", "citeRegEx": "Ulloa et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ulloa et al\\.", "year": 2016}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["David Yarowsky"], "venue": "In Proceedings of the 33rd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Yarowsky.,? \\Q1995\\E", "shortCiteRegEx": "Yarowsky.", "year": 1995}, {"title": "Social media analytics and intelligence", "author": ["Daniel Zeng", "Hsinchun Chen", "Robert Lusch", "Shu-Hsing Li"], "venue": "IEEE Intelligent Systems,", "citeRegEx": "Zeng et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2010}], "referenceMentions": [], "year": 2017, "abstractText": "With the rise of Social Media, people obtain and share information almost instantly on a 24/7 basis. Many research areas have tried to gain valuable insights from these large volumes of freely available user generated content. The research areas of intelligent transportation systems and smart cities are no exception. However, extracting meaningful and actionable knowledge from user generated content is a complex endeavor. First, each social media service has its own data collection specificities and constraints, second the volume of messages/posts produced can be overwhelming for automatic processing and mining, and last but not the least, social media texts are usually short, informal, with a lot of abbreviations, jargon, slang and idioms. In this thesis, we try to tackle some of the aforementioned challenges with the goal of extracting knowledge from social media streams that might be useful in the context of intelligent transportation systems and smart cities. We designed and developed a framework for collection, processing and mining of geo-located Tweets. More specifically, it provides functionalities for parallel collection of geo-located tweets from multiple pre-defined bounding boxes (cities or regions), including filtering of non complying tweets, text pre-processing for Portuguese and English language, topic modeling, and transportation-specific text classifiers, as well as, aggregation and data visualization. We performed an extensive exploratory data analysis of geo-located tweets in 5 different cities: Rio de Janeiro, S\u00e3o Paulo, New York City, London and Melbourne, comprising a total of more than 43 millions tweets in a period of 3 months. Furthermore, we performed a large scale topic modelling comparison between Rio de Janeiro and S\u00e3o Paulo. As far as we know this is the largest scale content analysis of geo-located tweets from Brazil. Interestingly, most of the topics are shared between both cities which despite being in the same country are considered very different regarding population, economy and lifestyle. We take advantage of recent developments in word embeddings and train such representations from the collections of geo-located tweets. We then use a combination of bag-of-embeddings and traditional bag-of-words to train travel-related classifiers in both Portuguese and English to filter travel-related content from non-related. We created specific gold-standard data to perform empirical evaluation of the resulting classifiers. Results are in line with research work in other application areas by showing the robustness of using word embeddings to learn word similarities that bag-of-words is not able to capture. The source code and resources developed in this dissertation will be publicly available to foster further developments by the research community in smart cities and intelligent transportation systems.", "creator": "LaTeX with hyperref package"}}}