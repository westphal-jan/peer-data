{"id": "1709.03441", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2017", "title": "The Diverse Cohort Selection Problem: Multi-Armed Bandits with Varied Pulls", "abstract": "how should a firm allocate its limited subjective interviewing resources available to directly select onto the optimal cohort of new employees from a large set of crowded job applicants? how should that firm allocate cheap but noisy resume screenings and expensive but in - depth in - custody person interviews? we view this problem through tapping the lens of combinatorial pure exploration ( cpe ) in the multi - armed bandit setting, where a central learning agent performs partially costly exploration of a set stream of arms before selecting a final subset obtained with some matching combinatorial structure.... we generalize a recent cpe algorithm to map the setting where arm pulls can have different cost, but return different levels of subjective information, and prove theoretical upper bounds for a general class of arm - pulling strategies in this new setting. we then apply our successful general algorithm to a real - world problem with combinatorial structure : incorporating diversity into university admissions. we take real data from admissions at one of the largest us - based computer instructional science graduate programs and show that a simulation of our algorithm uniformly produced more diverse student cohorts at low cost to establish individual student quality, and does so collectively by spending comparable budget to the current admissions enrollment process occurring at that howard university.", "histories": [["v1", "Mon, 11 Sep 2017 15:38:49 GMT  (2361kb)", "http://arxiv.org/abs/1709.03441v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["candice schumann", "samsara n counts", "jeffrey s foster", "john p dickerson"], "accepted": false, "id": "1709.03441"}, "pdf": {"name": "1709.03441.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Jeffrey S. Foster", "John P. Dickerson"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :1\n70 9.\n03 44\n1v 1\n[ cs\n.L G\n] 1\n1 Se\np 20"}, {"heading": "1 Introduction", "text": "How should a firm, school, or fellowship committee allocate its limited interviewing resources to select the optimal cohort of new employees, students, or awardees from a large set of applicants? Here, the central decision maker must first form a belief about the true quality of an applicant via costly information gathering, and then select a subset of applicants that maximizes some objective function. Furthermore, various types of information gathering can be performed\u2014 reviewing a re\u0301sume\u0301, scheduling a Skype interview, flying a candidate out for an all-day interview, and so on\u2014to gather greater amounts of information, but also at greater cost. Complicating matters further, the total utility of a cohort may not be the simple sum of its parts. For example, with a cohort of size two, a software engineering firm may value two Java developers less than a single Java developer and a web developer. That is, applicants with otherwise similar skillsets or backgrounds may yield diminishing marginal gain as more are added to a cohort. Optimizing with a nonlinear objective function\u2014in this case, a submodular function\u2014presents additional complexity, even assuming perfect knowledge of the applicants\u2019 underlying true\nutilities. In this paper, we model the allocation of interviewing resources and subsequent selection of a cohort as a combinatorial pure exploration problem in the multi-armed bandit (MAB) setting. Here, each application is an arm, and a decision maker can pull the arm, at some cost, to receive a noisy signal about the underlying quality of that application. We further model different levels of interviews as strong and weak pulls\u2014the former costing more to perform than the latter, but also resulting in a less noisy signal. We introduce the strong-weak arm-pulls (SWAP) algorithm, generalizing an algorithm by Chen et al. (2014), and provide theoretical upper bounds for a general class of our varied arm-pull strategies. To complement these asymptotic bounds, we provide simulation results comparing a variety of pulling strategies on a toy problem that mimics our theoretical assumptions. We then validate our proposed method on a real-world scenario: accepting a diverse cohort of graduate students.We take recent data from one of the largest computer science graduate programs in the United States\u2014applications including recommendation letters, statements of purpose, transcripts, and other information, as well as the department\u2019s reviews of applications and final admissions decisions\u2014and run experiments comparing our algorithm\u2019s performance under a variety of assumptions to reviews and decisions made in reality. We find that our simulation of SWAP increased a diversity score (over gender and region of origin) with little loss in fit using roughly the same amount of resources as in practice. This gain demonstrates that SWAP can serve as a useful decision support tool to promote diversity in practice."}, {"heading": "2 Related Work", "text": "The multi-armed bandit (MAB) problem is a classical setting for modeling sequential decision making; for a general overview of historical research, we direct the reader to Bubeck, Cesa-Bianchi, and others (2012). Our work builds on contributions by Chen et al. (2014), who propose a general algorithm that relies on an oracle for insight into the true utility of a subset of arms, where subsets have some combinatorial structure. Chen et al. propose two algorithms: Combinatorial Lower-Upper Confidence Bound (CLUCB), for the fixed confidence setting, and Combinatorial Successive Accept Reject (CSAR), for the fixed budget and batch setting with variable batch sizes, detailed in Sec-\ntion 4 and Appendix B. We adapt the CLUCB algorithm for the cohort selection setting with varying types of pulls to reflect different information gathering techniques.\nAll of the following MAB formulations select some highutility subset of arms using a single type of arm pull, with varying ways of modeling decisions focusing on different problem features. In the Top-K problem, the goal is to select a subset of k probability distributions with highest means from a set of n total distributions, which Cao et al. (2015) study in the MAB setting. Their linear objective is less general than the setting in which we and Chen et al. (2014) operate. Locatelli, Gutzeit, and Carpentier (2016) address the thresholding bandit problem, where the aim is to identify the arms above and below threshold \u03c4 with precision \u01eb. Jun et al. (2016) address the MAB problem with batch arm pulls, aiming to identify the top k-set from n arms while pulling arms in batches of size b. Singla et al. (2015) propose an algorithm that hires a team of workers for specific tasks from a crowdsourcing point of view, treating different types of workers as separate problems and arm-pulls as asking a worker to perform an action with uniform cost. Modeling workers and tasks in separate graphs, their algorithms take advantage of known side-observations between the graphs to inform optimal team selection. Thus, their algorithm can operate in both the bandit setting (no side observations) and the information setting (fully connected graphs). Our algorithm focuses solely on the bandit setting.\nFor the task of selecting the best subset while satisfying a submodular function, Singla, Tschiatschek, and Krause (2016) propose an algorithm that maximizes an unknown submodular function accessed through noisy evaluations, in comparison to SWAP maximizing a given submodular function. Yue and Guestrin (2011) introduce the linear submodular bandits problem to select diverse sets of content in an online learning setting for optimizing a class of featurerich submodular utility models. Unlike our focus on selfreported, concrete features to prioritize diversity, they categorize arms based on the information they probabilistically contain, determined by a topic model like LDA, which is potentially noisy and biased. Their notion of diverse, similar to that of Radlinski, Kleinberg, and Joachims (2008), comes from the diversified retrieval setting, meaning they seek to avoid redundant coverage of topics in the set of arms they select. Radlinski, Kleinberg, and Joachims (2008) learn a diverse ranking from the behavior patterns of different users and then use a greedy algorithm to select the next document to rank. They treat each rank of documents as a separate MAB instance, rather than our approach using a singleMAB to model the whole system.\nWe are motivated by the observation that, in many realworld settings, different levels of information gathering can be performed at different costs. Previous work has used stochastic, varying costs in the MAB setting; however, our costs are fixed for specific types of arm pulls. Ding et al. (2013) look at a MAB problem with variable rewards and cost with budget constraints. When an arm is pulled, a random reward is received and a random cost is taken from the budget\u2014discovered only after pulling it. Over time they aim to maximize total rewards and minimize regret while com-\nplying with the pull budget. Similarly, Xia et al. (2016) propose a batch-arm-pullMAB solution to a problem with variable, random rewards and costs. Jain et al. (2014) frame the MAB problemwith variable reward and cost in the setting of crowdsourcing. They select workers to perform binary tasks while achieving an assured accuracy for each task, where the costs of workers are unknown. This differs from our formulation in that we decide how many resources to use when pulling an arm. Other authors have used standard supervised learning techniques to model higher education admissions decisions. However, previous work focuses on developing an accurate admissions classifier; none model how to select an optimal cohort in a novel way. Furthermore, they do not try to satisfy a certain objective, unlike our aim to select a more diverse cohort. Lux et al. (2016) and Waters and Miikkulainen (2013) work alongside the admissions office, motivated by the desire to optimize the admissions process. Gupta, Sawhney, and Roth (2016) model the graduate admissions process from the student\u2019s perspective, to inform prospective applicants on which schools to apply to based on their likelihood of admission."}, {"heading": "3 Problem Formulation", "text": "We now formally describe the stochastic multi-armed bandit setting in which we operate. For exposition\u2019s sake, we do so in the context of a decisionmaker reviewing a set of job applicants; yet, the formulation itself maintains full generality. We represent a set of n applications as arms ai \u2208 A for i \u2208 [n]. Each arm has a true utility, u(ai) \u2208 [0, 1], which is unknown, an empirical estimate u\u0302(ai) \u2208 [0, 1] of that underlying true utility, and an uncertainty bound rad(ai). Once arm ai is pulled (e.g., application reviewed or applicant interviewed), u\u0302(ai) and rad(ai) are updated. The set of potential cohorts, or subsets of arms, is defined by a decision class M \u2286 2[n]. Note that this need not be the power set of arms, but can include cardinality and other constraints. The total utility for a cohort is given by some monotone, submodular function w : M \u2192 R and takes as input the (unknown) true utilities u(\u00b7) of the constituent arms in the cohort. Thus, our overall goal is to accurately estimate the true utilities of arms and then select the optimal subset of armsM\u2217 = argmaxM\u2208M w(M). Throughout the paper, we assume a maximization oracle\u2014that is, we do not focus on the combinatorial optimization problem of solving for M\u2217 given information about the arms\u2019 utilities. Instead, we focus on the arm pulling policies that reveal estimates of the arms\u2019 utilities. Formally, the oracle can be written as\nOracle(v) = argmaxM\u2208Mw(M), (1)\nwhere v \u2208 Rn is vector of weights\u2014in this case, estimated or true utilities for each arm. In Section 5.1, we give an example submodular oracle based on a notion of diversity; other examples include linear and set maximum. Following the notation of Chen et al. (2014), we can define a gap score for each arm. For each arm a that is in the optimal set M\u2217, the gap is the difference in optimality between M\u2217 and the best set without arm a. For each\narm a that is not in the optimal set M\u2217, the gap is the suboptimality of the best set that includes arm a. Formally the gap is defined as\n\u2206a =\n{\nw(M\u2217)\u2212maxM\u2208M:a\u2208M w(M), if a /\u2208 M\u2217 w(M\u2217)\u2212maxM\u2208M:a/\u2208M w(M), if a \u2208 M\u2217.\n(2) This gap score serves as a useful signal for problem hardness, which we use in our theoretical analysis in Section 4. Formally, the hardness of the problem can be defined as the sum of inverse squared gaps\nH = \u2211\na\u2208AT\n\u2206\u22122a . (3)\nIn reality, there is more than one way to gather information or receive rewards; therefore, we introduce two kinds of arm pulls. A weak arm pull has normalized cost 1 but results in a small amount of information. In our domain of graduate admissions, weak arm pulls are standard application reviews, which involve reading submitted materials and then making a recommendation. A strong arm pull, in contrast, has cost j \u2265 1, but results in s \u2265 1 times the information as a weak arm pull, modeled as s parallel pulls of an arm. The values s and j are parameters given to the SWAP algorithm. In our domain, strong arm pulls combine reading submitted materials with a Skype interview, followed by note-taking and a recommendation. In our experience, the latter can reduce uncertainty considerably, which we quantify and discuss in Section 5. However, due to their high cost, such interviews are allocated relatively sparingly.We explore this problem in a formal setting in Section 4 and provide a formal algorithm for selecting which arms to pull, along with asymptotic upper bounds on total cost."}, {"heading": "4 Strong Weak Arm Pulls", "text": "In this section, we propose a new multi-armed bandit algorithm, strong-weak arm-pulls (SWAP), that is parameterized by s and j and uses a combination of strong and weak arm pulls to gain information about arms. Our setting and the algorithm we present generalize the CLUCB algorithm proposed by Chen et al. (2014), which can be viewed as a special case with s = j = 1. We present the algorithm in generality here, and then instantiate it with a specific objective (a submodular diversity-promoting function) in the following section. Algorithm 1 gives pseudocode for SWAP. It starts by weak pulling all arms once to initialize an empirical estimate of the true underlying utility of each arm. It then iteratively pulls arms, selects to weak or strong pull based on a general strategy, updates empirical estimates of arms, and terminates with the optimal (i.e., objective-maximizing) subset of arms with probability 1\u2212 \u03b4, for some user-supplied parameter \u03b4. During each iteration t, the algorithm starts by finding the set of arms Mt that, according to current empirical estimates of their means, maximizes the objective function; this is done via an oracle. It then computes a confidence radius (radt(a)) for each arm and estimates the worst-case utility\nof that arm with some corresponding bound. If an arm a is in the set Mt then the worst case is when the true utility of a is less than our estimate (the oracle may not have chosen arm a). Alternatively, if an arm is not in the set Mt then the worst case is when the true utility of a is greater than our estimate (the oracle may have chosen arm a). Using the worstcase estimates instead of the empirical means of the arms,\nwe compute an alternate subset of arms M\u0303t. If the utility of the initial set Mt and the worst-case set M\u0303t are equal then the algorithm terminates with output Mt, which is correct with probability 1 \u2212 \u03b4 using similar reasoning to that found in Chen et al. (2014). If they differ, the algorithm looks at a set of candidate arms in the symmetric difference ofMt and M\u0303t, and chooses the arm pt with the largest radius\u2014that is, the largest uncertainty bound. The algorithm then chooses to either strong or weak pull the selected arm pt, decided using a strong pull policy depending on value parameter s and cost parameter j. A strong pull policy is defined as spp : R\u00d7R \u2192 [0, 1]. For example, in the experiments in Section 5, we use the following pull policy:\nspp(s, j) = s\u2212 j s\u2212 1 . (4)\nNotice that this pull policy performs only strong pulls when j = 1 and s > j, and performs only weak pulls when j = s. For other values of s and j, it probabilistically chooses a type of arm pull. We define X\u0304Cost = E[Cost] as the expected cost and X\u0304Gain = E[Gain] as the expected gain. Assume that each arm a \u2208 [n] has mean u(a) with an \u03c3-subGaussian tail. Following Chen et al. (2014) set radt(a) =\n\u03c3\n\u221a\n2 log (\n4nCost3t \u03b4\n)\n/Tt(a) for all t > 0 and a \u2208 [n]. Notice that if we use strong pull policy spp(s, j) = 0 then we only perform weak arm pulls, and Algorithm 1 reduces to Chen et al. (2014)\u2019s CLUCB. We call this reduction the weak only pull problem. Chen et. al. proved that CLUCB returns the optimal setM\u2217 and uses at most O\u0303(width(M)2H) samples.\nTheorem 1 (Chen et al. 2014). Given any \u03b4 \u2208 (0, 1), any decision class M \u2286 2[n], and any expected rewards w \u2208 R\nn, assume that the reward distribution\u03d5a for each arm a \u2208 [n] has mean w(a) with an \u03c3-sub-Gaussian tail. Let M\u2217 = argmaxM\u2208M w(M) denote the optimal set. Set radt(a) = \u03c3 \u221a 2 log ( 4nt3\n\u03b4 /Tt(a) ) for all t > 0 and a \u2208 [n]. Then, with probability at least 1 \u2212 \u03b4, the SWAP algorithm with only weak pulls returns the optimal set Out = M\u2217 and\nT \u2264 O ( \u03c32 width(M)2H log(nR2H/\u03b4) )\n(5)\nwhere T denotes the number of samples used by the SWAP algorithm,H is defined in Eq.3.\nSimilarly, if we set spp(s, j) = 1 then we only perform strong arm pulls (Strong Only Pull Problem). We show that this version of SWAP returns the optimal setM\u2217 and uses at most O\u0303(width(M)2H/s) samples. The proof of the following theorem can be found in the appendix.\nAlgorithm 1 Strong Weak Arm Pulls (SWAP)\nRequire: Confidence \u03b4 \u2208 (0, 1); Maximization oracle: Oracle(\u00b7) : Rn \u2192 M\n1: Weak pull each arm a \u2208 [n] once. 2: Initialize empirical means u\u0304n 3: \u2200a \u2208 [n] set Tn(a) \u2190 1, Total information gain for arm\na 4: Costn \u2190 n, Total resources spent 5: for t = n, n+ 1, . . . do 6: Mt \u2190 Oracle(u\u0304t) 7: \u2200a \u2208 [n] compute confidence radius radt(a) 8: for a = 1, . . . , n do 9: if a \u2208 Mt then u\u0303t(a) \u2190 u\u0304t(a)\u2212 radt(a) 10: else u\u0303t(a) \u2190 u\u0304t(a) + radt(a) 11: M\u0303t \u2190 Oracle(u\u0303t) 12: if w\u0303(M\u0303t) = w\u0303(Mt) then 13: Out \u2190 Mt 14: return Out 15: pt \u2190 argmaxa\u2208(M\u0303t\\Mt)\u222a(Mt\\M\u0303t) radt(a) 16: \u03b1 \u2190 spp(s, j) 17: with probability \u03b1 do 18: Strong pull pt 19: Tt+1(pt) \u2190 Tt(pt) + s 20: Costt+1 \u2190 Costt + j 21: else 22: Weak pull pt 23: Tt+1(pt) \u2190 Tt(pt) + 1 24: Costt+1 \u2190 Costt + 1 25: Update empirical mean u\u0304t+1 using observed reward 26: Tt+1 \u2190 Tt(a) \u2200a 6= pt\nTheorem 2. Given any \u03b4 \u2208 (0, 1), any decision class M \u2286 2[n], and any expected rewards w \u2208 Rn, assume that the reward distribution \u03d5a for each arm a \u2208 [n] has mean w(a) with an \u03c3-sub-Gaussian tail. Let M\u2217 = argmaxM\u2208M w(M) denote the optimal set. Set radt(a) =\n\u03c3\n\u221a\n2 log ( 4nt3j3 \u03b4 /Tt(a) )\nfor all t > 0 and a \u2208 [n]. Then, with probability at least 1 \u2212 \u03b4, the SWAP algorithm with only strong pulls where j \u2265 1 and s > j returns the optimal set Out = M\u2217 and\nT \u2264 O ( \u03c32 width(M)2H log(nj3R2H/\u03b4) s )\n(6)\nwhere T denotes the number of samples used by the SWAP algorithm,H is defined in Eq.3.\nAlthough s and j are problem-specific, it is important to know when to use the strong only pull problem over the weak only pull problem. Corollary 2.1 provides weak bounds for s and j for the strong only pull problem.\nCorollary 2.1. SWAP with only strong pulls is equally or more efficient than SWAP with only weak pulls when s > 0 and 0 < j \u2264 C s3\u2212 13 where C = 4nH\u0303/\u03b4. Proof.\nTstrong \u2264 Tweak\n499H\u0303 log(4nj3H\u0303/\u03b4)\ns + 2n \u2264 499H\u0303 log(4nj3H\u0303/\u03b4) + 2n\nlog(Cj3)\ns \u2264 log(C) (7)\nSolving for Eq.7 we get s > 0 and 0 < j \u2264 C s3\u2212 13 . We now address the general case of SWAP, for any probabilistic strong pull policy parameterized by s and j. For this general case, we show in Theorem 3 that SWAP returnsM\u2217 in O\u0303 ( width(M)2H/X\u0304Gain )\nsamples. (The full proof can be found in Appendix C.)\nTheorem 3. Given any \u03b41, \u03b42, \u03b43 \u2208 (0, 1), any decision class M \u2286 2[n] and any expected rewards w \u2208 Rn, assume that the reward distribution \u03d5a for each arm a \u2208 [n] has mean w(a) with an \u03c3-sub-Gaussian tail. Let M\u2217 = argmaxM\u2208M w(M) denote the optimal set. Set radt(a) =\n\u03c31\n\u221a\n2 log ( 4nCost3t \u03b4 /Tt(a) ) for all t > 0 and a \u2208 [n], set\n\u01eb1 = \u03c32\n\u221a\n2 log ( 1 2\u03b42/T ) , and set \u01eb2 = \u03c32\n\u221a\n2 log ( 1 2\u03b43/n ) .\nThen, with probability at least (1 \u2212 \u03b41)(1 \u2212 \u03b42)(1 \u2212 \u03b43), the SWAP algorithm (Algorithm 1) returns the optimal set Out = M\u2217 and\nT \u2264 O\n\n\n\u03c321 width(M)2H log ( nR2 ( X\u0304Cost \u2212 \u01eb1 )3 H/\u03b4 )\nX\u0304Gain \u2212 \u01eb2\n\n ,\n(8) where T denotes the number of samples used by Algorithm 1, H is defined in Eq. 3 and width(M) is defined by Chen et. al (Chen et al. 2014).\nFinding where the general version of SWAP is better than both the SWAP algorithm with only strong pulls and the SWAP algorithm with only weak pulls is nontrivial, given the asymptotic nature of all three bounds (Theorems 1, 2, and 3). Based on our experiments (\u00a75), we conjecture that there is an optimal zone of s and j pairs where SWAP is the optimal algorithm, even for relatively low numbers of arm pulls, but this is problem specific."}, {"heading": "5 Experiments", "text": "In this section, we experimentally validate the SWAP algorithm under a variety of arm pull strategies. We begin by concretely instantiating a submodular objective function (\u00a75.1) that promotes diversity in the final cohort selected by the algorithm. Then, we explore (\u00a75.2) in simulation the efficacy of our bounds in Theorem 3 and Corollary 2.1. Finally, we deploy SWAP on real data (\u00a75.3) drawn from one of the largest computer science graduate programs in the United States. We show a significant increase in diversity with little loss in fit while using roughly the same amount of resources as used in practice."}, {"heading": "5.1 Formally Promoting the Diversity of a Cohort", "text": "The SWAP algorithm presented in Section 4 is defined in the context of a generic submodular and monotone oracle; in practice, domain experts would specify an ap-\npropriate function to maximize. Motivated by recent evidence that diversity in the workforce can increase productivity (Hunt, Layton, and Prince 2015; Desrochers 2001), in this section, we explore the effect of formally promoting diversity in the cohort selection problem.\nQuantifying the diversity of a set of elements is of interest in a variety of fields, including recommender systems, information retrieval, computer vision, and others (Liu, Suel, and Memon 2014; Qin and Zhu 2013; Ashkan et al. 2015; Sha, Wu, and Niu 2016; Radlinski, Kleinberg, and Joachims 2008; Ahmed, Dickerson, and Fuge 2017). For our experiments, we choose a recent formalization from Lin and Bilmes (2011) and apply it to both simulated and real data. At a high level their diversity function f is defined as\nf(M) =\nK \u2211\ni=1\n\u221a\n\u2211\nj\u2208Pi\u2229M\nu(a), (9)\nwhere u(a) \u2265 0 and M = P1 \u222a P2 \u222a . . . \u222a PK . Lin and Bilmes showed that f is submodular and monotone. Nemhauser, Wolsey, and Fisher (1978) proved that a close to optimal ( f(S\u2217) \u2265 (\n1\u2212 1e ) OPT )\ngreedy algorithm exists for submodular, monotone functions that are subject to a cardinality constraint. We use this algorithm in our implementation of the diverse oracle."}, {"heading": "5.2 Gaussian Arm Experiment", "text": "We begin by validating the tightness of our theoretical results in a simulation setting that mimics the assumptions made in Section 4. We pull from a Gaussian distribution around each arm. When arm a is weak pulled, a reward is pulled from a Gaussian distribution with mean ua, the arm\u2019s true utility, and standard deviation of \u03c3. Similarly, when arm a is strong pulled, the algorithm is charged j cost, and a reward is pulled from a distribution with mean ua and standard deviation of \u03c3/ \u221a s. This strong pull distribution is equivalent to pulling the arm s times and averaging the reward, thus ensuring an information gain of s. We ran all three algorithms\u2014SWAP with the strong pull policy defined in Equation 4, SWAP with only strong pulls, and SWAPwith only weak pulls\u2014while varying s and j. For each s and j pair we ran the algorithms at least 4000 times on a randomly generated initialization of arm values. Random seeds were maintained across policies. We then compared the cost of running each of the algorithms to completion.1\nThe first comparison was of SWAP with only weak pulls and SWAP with only strong pulls; a heat map of performance is given as Figure 1. We found that Corollary 2.1 is a weak bound on the boundary value of j. Yet, SWAP with only strong pulls has a lower cost than SWAP with only weak pulls for values greater than j < (4n H\u0303 /\u03b4) s 3 \u2212 1\n3 , given this experiment.\nThe general version of SWAP should be used when it performs better\u2014costs less\u2014than both the strong only and\n1All code to replicate this experiment will be posted after the double-blind review period concludes.\nweak only versions of SWAP. The zone where SWAP is effective varies with the problem. Figure 2 shows the optimal zone for the Gaussian Arm Experiment."}, {"heading": "5.3 Graduate Admissions Experiment", "text": "Now, we describe a preliminary exploration of SWAP on real graduate admissions data from one of the largest CS graduate programs in the United States. The experiment was approved by the University\u2019s Institutional Review Board. Our dataset consists of three years of graduate admissions applications, graduate committee application review text and ratings, and final admissions decisions. Information was gathered from the first two academic years (treated as a training set), while the data from last academic year was used to evaluate the performance of SWAP (treated as a test set).\nDataset. During the admissions process, potential students from all over the world send in their applications. A single application consists of quantitative information such as GPA, GRE scores, TOEFL scores, nationality, sex, previous degrees and so on, as well as qualitative information in the form of recommendation letters and statements of purpose. In the most recent academic year we received approximately 1600 applications, with roughly 4500 applications over all three years. The most recent 1600 applications are roughly split into 1000 applicants seeking Masters Degrees and 600 applicants seeking Ph.D. Degrees. The acceptance rate for Masters students is about 3%, while the acceptance rate for Ph.D. students is about 20%. In the most recent academic year 24% of the applicants were female and 26% of the applicants admitted were female.\nOnce all of the applications are submitted, they are sent to a review committee of faculty and current graduate students at the university. Each application is reviewed at least once; for our dataset, each application received an average of 1.21 reviews. Generally, applicants at the top (who far exceed ex-\npectations) and applicants at the bottom (who do not fulfill the program\u2019s strict requirements) only need one review. The majority of reviews are quick looks at the application, equivalent to weak arm pulls. Some of the reviews are oneon-one interviews, equivalent to strong arm pulls. We estimate that our interviews are approximately six times longer than a quick review thereforewe set our j value (the cost of a strong pull) to be 6. The gain of an interview is uncertain so we ran tests over a wide range of s values (the information gain of a strong pull). Once all reviews have been made the graduate director decides on the final applicants to admit.\nExperimental Setup. We simulate an arm pull by returning a real score that a reviewer gave during the admissions process (first) or a score from a probabilistic classifier (second, if all committee members\u2019 reviews have been used already). An arm pull returns a score drawn from a distribution around the probabilistic result from the classifier. The distribution is structured similarly to the Gaussian arm experiment. This is done in order to simulate some human error or bias. The classifier used is a random forest (Pedregosa et al. 2011) trained with 3-fold cross validation on the data from the two academic years prior to the most recent academic year. We used a number of features including general features found on the application (GPA, GRE scores, area of interest, sex, region, etc.) and features generated from the texts of the recommendation letters. Features pulled from the recommendation letters were letter length and word counts from the word groups discussed by Schmader, Whitehead, and Wysocki (2007) created from Chemistry and Biochemistry recommendation letters. We found that these word groups are general and translated well to Computer Science students.\nLimitations. In this experiment, we assume that the true utility of an applicant can be modeled by our classifier,\nwhich is not entirely accurate. In reality, the true utility of an applicant is nontrivial to estimate as it depends on a wide range of factors. This experiment also simulated strong arm pulls\u2014reviewers did not give any additional interviews of applicants during the experiment. Another limiting factor is that not every applicant we admit will matriculate into the program. Although the following results are promising, SWAP should be run in conjunction with an actual admissions process to assess its true performance.\nResults. We ran SWAP using the strong pull policy defined in Equation 4 over multiple values of s. We then compared the results of SWAP with the real decisions made during the admissions process. Averaging over all of the SWAP decisions, we compared the utility of the SWAP decision to that of the real decision, where the utility of each arm is defined by the classifier. There are two different types of objective functions that we take into account. The first treats all applicants as members of one global class, defined as \u221a\u2211\na\u2208M u(a). This mimics a Top-K style objective, where applicants are valued based on individual merit alone. The second objective function is diversity-promoting, as defined in Equation 9, using reported gender (which is binary in our dataset) and region of origin for class memberships. We use those classes as our objective during separate runs of SWAP.\nTable 1 and Figure 3 show experimental results on the test set (final year) of real admissions data. Since SWAP uses a diversity oracle (\u00a75.1), we notice a slight drop in Top-K utility. We do, however, notice a gain in diversity.\nSWAP, on average, used 1.17 pulls per arm, of which 0.05 were strong. During the last admissions decision process each applicant was reviewed on average 1.21 times. SWAP performed more strong pulls (interviews) of applicants than the graduate admissions committee did in practice, but did fewer weak pulls. SWAP spent roughly the same amount of total resources, when weighted by strong pull cost j = 6 and weak pull cost of 1, than the committee did. Given the gains in diversity, this supports SWAP\u2019s potential use in practice.\nDistribution of Regions in True Acceptances"}, {"heading": "6 Conclusion", "text": "In this paper, we modeled the allocation of interviewing resources and subsequent selection of a cohort of applicants as a combinatorial pure exploration (CPE) problem in the multi-armed bandit setting. We generalized a recent CPE algorithm to the setting where arm pulls can have different costs\u2014that is, where a decision maker can perform strong and weak pulls, with the former costing more than the latter, but also resulting in a less noisy signal. We presented the strong-weak arm-pulls (SWAP) algorithm and proved theoretical upper bounds for a general class of arm pulling strategies in that setting. We also provided simulation results to test the tightness of these bounds. We then applied SWAP to a real-world problem with combinatorial structure: incorporating diversity into university admissions. On real admissions data from one of the largest US-based computer science graduate programs, we showed that SWAP produces more diverse student cohorts at low cost to student quality while spending a budget comparable to that of the current\nadmissions process at that university.\nIt would be of both practical and theoretical interest to tighten the upper bounds on convergence for SWAP, either for a reduced or general set of arm pulling strategies. SWAP should also be extended to include more than two types of pulls or information gathering strategies. We aim to incorporate a more realistic version of diversity and achieve a provably fair multi-armed bandit algorithm, as formulated by Joseph et al. (2016). Furthermore, we hope to determine whether or not there was bias in past admissions decisions and, if any, adapt the formulation of our diversity function to address it. Future work will include a live version of SWAP that will be used during the 2017-18 admissions period, with the goal of allocating resources more efficiently with an ever-increasing number of applicants."}, {"heading": "A Admissions Decisions Classifier", "text": "To effectively model the graduate admissions process, we needed a way to accurately represent whether a particular applicant will be admitted to the program. Using 3 years of previous admissions data, including letters of recommendation, we built a classifier modeling the graduate chair\u2019s decision for a particular applicant. The classifier\u2019s accuracy can be found in Table 2.\nSome general features from the application are GPA, GRE scores, TOEFL scores, area of interest (Machine Learning, Theory, Vision, and so on), previous degrees, and universities attended. We included country of origin since the nature of applications may vary in different regions due to cultural norms. Another basic feature included was sex. We included this to check if the classifier picked up on any biased decision making (with sex and region).\nOther features were generated from automatically processing the recommendation letters. Text from the letters was pulled from pdfs and OCR for scanned letters. We then cleaned the raw text with NLTK, removing stop words and stemming text (Bird 2006). One feature we chose was the length of recommendation letter, chosen after polling the admissions committee on what they thought would be important. Schmader, Whitehead, and Wysocki (2007) used Latent Dirichlet Allocation (LDA) to find word groups in recommendation letters for Chemistry and Biochemistry students (Blei, Ng, and Jordan 2003). Their five word groups included standout words (excellen*, superb, outstanding etc.), ability words ( talent*, intell*, smart*, skill*, etc.), grindstone words (hardworking, conscientious, depend*, etc.), teaching words (teach, instruct, educat*, etc.), and research words (research*, data, study, etc.). We found that these word groups translated well to Computer Science students. Important words for acceptance were research words, standout words, and ability words. Letters that only included words from the teaching word group indicated a less useful recommendation letter. We used counts of the various word groups as a feature in the classifier."}, {"heading": "B CLUCB Algorithm", "text": "The Combinatorial Lower-Upper Confidence Bound (CLUCB) algorithm by Chen et al. (2014) is shown in Algorithm 2. At the beginning of the algorithm, pull each arm once and initialize the empirical means with the rewards from that first arm pull. During iteration t of the algorithm, first find the set Mt using the Oracle. Then, compute the confidence radius for each arm. Find the worst case for each arm and compute a new set M\u0303t using the worst case estimates of the arms. If the utility of the initial set Mt and\nthe worst case set M\u0303t are equal then output set Mt. Pull the most uncertain arm (the arm with the widest radius) from the symmetric difference of the two sets Mt and M\u0303t. Update the empirical means.\nAlgorithm 2 Combinatorial Lower-Upper Confidence Bound (CLUCB)\nRequire: Confidence \u03b4 \u2208 (0, 1); Maximization oracle: Oracle(\u00b7) : Rn \u2192 M\n1: Weak pull each arm a \u2208 [n] once. 2: Initialize empirical means u\u0304n 3: \u2200a \u2208 [n] set Tn(a) \u2190 1 4: for t = n, n+ 1, . . . do 5: Mt \u2190 Oracle(u\u0304t) 6: \u2200a \u2208 [n] compute confidence radius radt(a) 7: for a = 1, . . . , n do 8: if a \u2208 Mt then u\u0303t(a) \u2190 u\u0304t(a)\u2212 radt(a) 9: else u\u0303t(a) \u2190 u\u0304t(a) + radt(a) 10: M\u0303t \u2190 Oracle(u\u0303t) 11: if w\u0303(M\u0303t) = w\u0303(Mt) then 12: Out\u2190 Mt 13: return Out 14: pt \u2190 argmaxa\u2208(M\u0303t\\Mt)\u222a(Mt\\M\u0303t) radt(a) 15: Pull arm pt 16: Update empirical means u\u0304t+1 using the observed re-\nward 17: Tt+1(pt) \u2190 Tt(pt) + 1 18: Tt+1 \u2190 Tt(a) \u2200a 6= pt"}, {"heading": "C Proofs", "text": "In this section, we formally prove the theorems discussed in our paper. Some lemmas we show directly feed from Chen et al. (2014)\u2019s paper.\nC.1 Strong Arm Pull Problem\nThe following maps to Lemma 8 in Chen et al. (2014).\nLemma 1. Suppose that the reward distribution \u03d5a is a \u03c3sub-Gaussian distribution for all a \u2208 [n]. And if, for all t > 0 and all a \u2208 [n], the confidence radius radt(a) is given by\nradt(a) = \u03c3\n\u221a \u221a \u221a \u221a 2 log ( 4nt3j3 \u03b4 )\nTt(a)\nwhere Tt(a) is the number of samples of arm a up to round t. Since s > 1 the number of samples in a single strong pull will be s each with cost j. Then, we have\nPr\n[\n\u221e \u22c2\nt=1\n\u03bet\n]\n\u2265 1\u2212 \u03b4.\nProof. Fix any t > 0 and a \u2208 [n]. Note that \u03d5a is a \u03c3-subGaussian tail distribution with mean w(a) and w\u0304t(a) is the empirical mean of \u03d5a from Tt(a) samples.\nPr\n\n  |w\u0304t(a)\u2212 wt(a)| \u2265 \u03c3\n\u221a \u221a \u221a \u221a 2 log ( 4nt3j3 \u03b4 )\nTt(a)\n\n \n= t\u22121 \u2211\nb=1\nPr\n\n   |w\u0304t(a)\u2212 wt(a)| \u2265 \u03c3\n\u221a \u221a \u221a \u221a 2 log ( 4nt3j3\n\u03b4\n)\nbs , Tt(a) = bs\n\n  \n(10a)\n\u2264 t\u22121 \u2211\nb=1\n2 exp\n\n     \n\u2212bs ( \u03c3\n\u221a\n2 log ( 4nt3j3\n\u03b4\n)\nbs\n)2\n2\u03c32\n\n     \n(10b)\n=\nt\u22121 \u2211\nb=1\n\u03b4\n2nt3j3\n\u2264 \u03b4 2nt2j3\n(10c)\nwhere Eq.10a follows from the fact that 1 \u2264 Tt(a)/s \u2264 t\u22121 and Eq.10b follows from Hoeffding\u2019s inequality. By a union bound over all a \u2208 [n], we see thatPr[\u03bet] \u2265 1\u2212 \u03b42t2j3 . Using a union bound again over all t > 0, we have\nPr\n[\n\u221e \u22c2\nt=1\n\u03bet\n]\n\u2265 1\u2212 \u221e \u2211\nt=1\nPr[\u00ac\u03bet]\n\u2265 1\u2212 \u221e \u2211\nt=1\n\u03b4\n2t2j3\n= 1\u2212 \u03c0 2\n12j3 \u03b4\n\u2265 1\u2212 \u03b4\nThe rest of the lemmas in Chen et al. (2014)\u2019s paper hold. We can now prove Theorem 2\nTheorem 2. Given any \u03b4 \u2208 (0, 1), any decision class M \u2286 2[n], and any expected rewards w \u2208 Rn, assume that the reward distribution \u03d5a for each arm a \u2208 [n] has mean w(a) with an \u03c3-sub-Gaussian tail. Let M\u2217 = argmaxM\u2208M w(M) denote the optimal set. Set radt(a) =\n\u03c3\n\u221a\n2 log ( 4nt3j3 \u03b4 /Tt(a) )\nfor all t > 0 and a \u2208 [n]. Then, with probability at least 1 \u2212 \u03b4, the CLUCB algorithm with only strong pulls where j \u2265 1 and s > j returns the optimal set Out = M\u2217 and\nT \u2264 O ( \u03c32 width(M)2H log(nj3R2H/\u03b4) s )\n(11)\nwhere T denotes the number of samples used by the CLUCB algorithm,H is defined in Eq.3.\nProof. Lemma 1 indicates that the event \u03be , \u22c2\u221e\nt=1 \u03bet occurs with probability at least 1 \u2212 \u03b4. In the rest of the proof, we shall assume that this event holds. By using Lemma 9 from Chen et al. (2014) and the assumption on \u03be, we see that Out = M\u2217. Next, we focus on bounding the total number of T samples.\nFix any arm a \u2208 [n]. Let T (a) denote the total information gained from pulling arm a \u2208 [n]. Let ta be the last round which arm a is pulled, which means that pta = e. It is easy to see that Tta(a) = T (a)\u2212 s. By Lemma 10 from chen et. al., we see that radta \u2265 \u2206a3width(M) . Using the definition of radta , we have\n\u2206a 3width(M) \u2264 \u03c3\n\u221a\n2 log(4nt3aj 3/\u03b4) T (a)\u2212 s \u2264 \u03c3 \u221a 2 log(4nT 3j3/\u03b4) T (a)\u2212 s .\n(12) By solving Eq.12 for T (a), we obtain\nT (a) \u2264 18width(M) 2\u03c32\n\u22062a log(4nT 3j3/\u03b4) + s (13)\nDefine H\u0303 = max{width(M)2\u03c32H, 1}. Using similar logic to Chen et al. (2014) and the fact that the information gained per pull is s, we show that\nT \u2264 499 H\u0303 log(4nj 3 H\u0303 /\u03b4)\ns + 2n (14)\nTheorem 2 follows immediately from Eq. 14. If n \u2265 12T , then T \u2264 2n and Eq. 14 holds. For the second case we assume n < 12T . Since T > n, we write\nT = C H\u0303 log\n( 4nj3 H\u0303 /\u03b4 )\ns + n, for some C > 0. (15)\nIf C < 499, then Eq. 14 holds. Suppose, on the contrary, that C > 499. We know that T = 1s \u2211 a\u2208[n] T (a). Using this fact and summing Eq. 13 for all a \u2208 [n], we have\nT \u2264 1 s\n\nns+ \u2211\na\u2208[n]\n18width(M)2\u03c32 \u22062a log(4nj3T 3/\u03b4)\n\n\n\u2264 n+ 18 H\u0303 log(4nj 3T 3/\u03b4)\ns\n= n+ 18 H\u0303 log(4nj3/\u03b4)\ns +\n54 H\u0303 log(T )\ns\n\u2264 n+ 18 H\u0303 log(4nj 3/\u03b4)\ns\n+ 54 H\u0303 log(2C H\u0303 log(4nj3 H\u0303 /\u03b4))\ns (16)\n= n+ 18 H\u0303 log(4nj3/\u03b4)\ns\n+ 54 H\u0303 log(2C)\ns +\n54 H\u0303 log(H\u0303)\ns\n+ 54 H\u0303 log log(4nj3 H\u0303 /\u03b4)\ns\n\u2264 n+ 18 H\u0303 log(4nj 3 H\u0303 /\u03b4)\ns\n+ 54 H\u0303 log(2C) log(4nj3 H\u0303 /\u03b4)\ns\n+ 54 H\u0303 log(4nj3 H\u0303 /\u03b4)\ns +\n54 H\u0303 log(4nj3 H\u0303 /\u03b4)\ns (17)\n= (126 + 54 log(2C)) H\u0303 log(4nj3 H\u0303 /\u03b4)\ns\n< n+ C H\u0303 log(4nj3 H\u0303 /\u03b4)\ns (18)\n= T, (19)\nwhere Eq. 16 follows from Eq. 15 and the assumption that n < 12T ; Eq. 17 follows from H\u0303 \u2265 1, j \u2265 1, and \u03b4 < 1; Eq. 18 follows since 126 + 54 log(2C) < C for all C > 499; and Eq. 19 is due to Eq. 15. So Eq. 19 is a contradiction. Therefore C \u2264 499 and we have proved Eq. 14.\nC.2 Strong Weak Arm Pull (SWAP)\nThe following corresponds to Lemma 8 in work by the Chen et al. (2014).\nLemma 2. Suppose that the reward distribution \u03d5a is a \u03c31sub-Gaussian distribution for all a \u2208 [n]. For all t > 0 and all a \u2208 [n], the confidence radius radt(a) is given by\nradt(a) = \u03c31\n\u221a \u221a \u221a \u221a 2 log ( 4nCost3t \u03b4 )\nTt(a)\nwhere Tt(a) is the number of samples of arm a up to round t. Since s > 1, the number of samples in a single strong pull are s each with cost j. Then, we have\nPr\n[\n\u221e \u22c2\nt=1\n\u03bet\n]\n\u2265 1\u2212 \u03b4.\nProof. Fix any t > 0 and a \u2208 [n]. Note that \u03d5a is \u03c31-subGaussian tail distribution with mean w(a) and w\u0304(a) is the empirical mean of \u03d5a from Tt(a) samples. Then we have\nPr\n\n  |w\u0304t(a)\u2212 wt(a)| \u2265 \u03c31\n\u221a \u221a \u221a \u221a 2 log ( 4nCost3t \u03b4 )\nTt(a)\n\n  (20)\n=\nt\u22121 \u2211\nb=1\nPr\n\n   |w\u0304t(a)\u2212 wt(a)| \u2265 \u03c31\n\u221a \u221a \u221a \u221a 2 log ( 4nCost3t \u03b4 )\nGainb\n\n  \n(21)\n\u2264 t\u22121 \u2211\nb=1\n2 exp\n\n          \u2212Gainb\n\n  \u03c31\n\u221a\n2 log\n(\n4nCost3 t\n\u03b4\n)\nGainb\n\n \n2\n2R2\n\n          (22)\n=\nt\u22121 \u2211\nb=1\n\u03b4\n2nAvCost3t3\n\u2264 \u03b4 2nt2AvCost3\n(23)\nwhere AvCost equal to the average cost until time t. Eq.21 follows from 1 \u2264 Tt(a)/Gaint \u2264 t \u2212 1 and Eq.22 follows from Hoeffding\u2019s inequality. By a union bound over all a \u2208 [n], we see that Pr[\u03bet] \u2265 1 \u2212 \u03b42t2AvCost3t . Using a union bound again over all t > 0, we have\nPr\n[\n\u221e \u22c2\nt=1\n\u03bet\n]\n\u2265 1\u2212 \u221e \u2211\nt=1\nPr[\u00ac\u03bet]\n\u2265 1\u2212 \u221e \u2211\nt=1\n\u03b4\n2t2AvCost3\n= 1\u2212 \u03c0 2\n12AvCost3 \u03b4\n\u2265 1\u2212 \u03b4\nGiven that the rest of the lemmas in the Chen et al. (2014) paper hold, we now prove the main theorem of our paper.\nTheorem 3. Given any \u03b41, \u03b42, \u03b43 \u2208 (0, 1), any decision class M \u2286 2[n] and any expected rewards w \u2208 Rn, assume that the reward distribution \u03d5a for each arm a \u2208 [n] has mean w(a) with an \u03c31-sub-Gaussian tail. Let M\u2217 = argmaxM\u2208M w(M) denote the optimal set. Set radt(a) =\n\u03c31\n\u221a\n2 log (\n4nCost3t \u03b4 /Tt(a)\n)\nfor all t > 0 and a \u2208 [n], set\n\u01eb1 = \u03c32\n\u221a\n2 log ( 1 2\u03b42/T ) , and set \u01eb2 = \u03c33\n\u221a\n2 log ( 1 2\u03b43/n ) .\nThen, with probability at least (1 \u2212 \u03b41)(1 \u2212 \u03b42)(1 \u2212 \u03b43), the SWAP algorithm (Algorithm 1) returns the optimal set Out = M\u2217 and\nT \u2264 O\n\n\nR2 width(M)2H log ( nR2 ( X\u0304Cost \u2212 \u01eb1 )3 H/\u03b4 )\nX\u0304Gain \u2212 \u01eb2\n\n ,\n(24) where T denotes the number of samples used by Algorithm 1, H is defined in Eq. 3 and width(M) is defined by Chen et al. (2014).\nProof. Lemma 2 indicates that the event \u03be , \u22c2\u221e\nt=1 \u03bet occurs with probability at least 1 \u2212 \u03b4. In the rest of the proof, we assume that this event holds. Using Lemma 9 from Chen et al. (2014) and the assumption on \u03be, we see that Out = M\u2217. Next, we bound the total number of T samples. Fix any arm a \u2208 [n]. Let T (a) denote the total information gained from pulling arm a \u2208 [n]. Let ta be the last round which arm a is pulled, which means that pta = a. Trivially, Tta(a) = T (a)\u2212 s. By Lemma 10 from Chen et al. (2014), we see that radta \u2265 \u2206a3width(M) . Using the definition of radta , we have\n\u2206a 3width(M) \u2264 R\n\u221a\n2 log(4nCost3ta/\u03b4)\nT (e)\u2212Gainta\n\u2264 R \u221a 2 log(4nCost3T /\u03b4)\nT (a)\u2212Gainta . (25)\nSolving for T (a) in Eq. 25 we get\nT (a) \u2264 18width(M) 2R2\n\u22062e log(4nCost3T /\u03b4) +Gainta\n(26) Define X\u0304Cost = E[Cost] as the expected cost of pulling an arm. Since we strong pull an arm with probability \u03b1 = s\u2212j s\u22121 , we know\nX\u0304Cost = E[CostT ] = \u03b1j + (1 \u2212 \u03b1). (27) DefineXCostt as the cost of pulling an arm at time t. Assuming that each random variable XCostt is R1-sub-Gaussian we can write the following using the Hoeffding inequality,\nPr\n(\u2223\n\u2223 \u2223 \u2223 \u2223 1 T\nT \u2211\nt=1\nCCostt \u2212 X\u0304Cost\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2265 \u01eb1 ) \u2264 2 exp ( \u2212 T \u01eb 2 1\n2R1\n)\n(28)\nIf we set \u01eb1 = R1\n\u221a\n2log(12\u03b42)/T then with probability (1\u2212 \u03b42)\nCostT T \u2208 ( X\u0304Cost \u2212 \u01eb1, X\u0304Cost + \u01eb ) . (29)\nCombining Eq. 26 and Eq. 29 we get\nT (e) \u2264 18width(M) 2R2\n\u22062e log(4n(X\u0304Cost\u2212\u01eb1)3T 3/\u03b4)+Gainte\n(30) Define X\u0304Gain = E[Gain] as the expected information gain from pulling an arm. Since we pull an arm with probability \u03b1, we know that\nX\u0304Gain = E[Gain] = \u03b1s+ (1 \u2212 \u03b1) (31) Define XGaint as the information gain of pulling an arm at time t. Assuming that each random variable XGaint is R2sub-Gaussian we can write the following using the Hoeffding inequality.\nPr\n\n\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 1 n \u2211\ne\u2208[n]\nGainte \u2212 X\u0304Gain\n\u2223 \u2223 \u2223 \u2223 \u2223 \u2223 \u2265 \u01eb2   \u2264 2 exp (\u2212n\u01eb22 2R22 )\n(32)\nIf we set \u01eb2 = R2\n\u221a\n2log(12\u03b43)/n then with probability (1 \u2212 \u03b42)\n\u2211\ne\u2208[n] Gainte\nn \u2208 ( X\u0304Gain \u2212 \u01eb2, X\u0304Gain + \u01eb2 ) . (33)\nSimilarly to the proof for Theorem 2, define H\u0303 = max{width(M)2R2H, 1}. In the rest of the proof we will show that\nT \u2264 499 H\u0303 log\n(\n4n ( X\u0304Cost + \u01eb1 )3 H\u0303 /\u03b4 ) X\u0304Gain\u2212 \u01eb2 + 2n (34)\nNotice that theorem follows immediately from Eq. 34. If n \u2265 12T , then Eq. 34 holds. Let\u2019s then assume that n < 12T . Since T > n, we can write\nT = C H\u0303 log(4n(XCost + \u01eb1)\n3 H\u0303 /\u03b4\nX\u0304Gain \u2212 \u01eb2 + n (35)\nIf C \u2264 499 then Eq. 34 holds. Suppose then that C > 499. Notice that T = \u2211\na\u2208[n] T (a)/Gainta . By summing up Eq.\n30 for all a \u2208 [n] we have\nT \u2264 n+ \u2211\na\u2208[n]\n18width(M)2R2 log(4n(X\u0304Cost + \u01eb1)T 3/\u03b4 \u22062aGainta\n\u2264 n+ 18 H\u0303 log(4n(X\u0304Cost + \u01eb1) 3T 3/\u03b4)\nX\u0304Gain \u2212 \u01eb2 (36)\n= n+ 18 H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3/\u03b4)\nX\u0304Gain \u2212 \u01eb2 +\n54 H\u0303 log(T ) X\u0304Gain \u2212 \u01eb2\n\u2264 n+ 18 H\u0303 log(4n(X\u0304Cost + \u01eb1) 3/\u03b4)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log(2c H\u0303 log(4n(X\u0304Cost \u2212 \u01eb1)3 H\u0303 /\u03b4))\nX\u0304Gain \u2212 \u01eb2 (37)\n= n+ 18 H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3/\u03b4)\nX\u0304Gain \u2212 \u01eb2 +\n54 H\u0303 log(2C)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log(H\u0303)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2\n\u2264 n+ 18 H\u0303 log(4n(X\u0304Cost + \u01eb1) 3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log(2C) log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2\n+ 54 H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2 (38)\n= n+ (126 + 54 log(2C)) H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2\n< n+ C H\u0303 log(4n(X\u0304Cost + \u01eb1)\n3 H\u0303 /\u03b4)\nX\u0304Gain \u2212 \u01eb2 (39)\n= T, (40)\nwhere Eq. 36 follows from Eq. 33; Eq. 37 follows from Eq. 35 and the assumption n < 12T ; Eq. 38 follows from H\u0303 \u2265 1, \u03b4 < 1, and X\u0304Cost + \u01eb \u2265 1; Eq. 39 follows since 126 + 54 log(2C) < C for all C > 499; and Eq. 40 is due to Eq. 35. So Eq. 40 is a contradiction. Therefore C \u2264 499 and we have proved Eq. 34."}, {"heading": "D Experiments", "text": "D.1 Gaussian Experiments\nWhile running SWAP, we first compare where the general, varied-cost version of SWAP is better than SWAP with strong pulls only (Figure 4) and where it is better than SWAP with only weak pulls (Figure 5). We then noticed that there should be an optimal zone where the general version of SWAP would perform better than both of the trivial cases.\nBoth graphs examine the symmetric difference between the average cost values of SWAP and either Strong or Weak Pull only with different parameter values of s and j.\nD.2 Graduate Admissions Experiment\nWe ran SWAP over both Masters and Ph.D. students over various values of s (Figure 6). The total cost of running these experiments aligns with the resources spent during the actual admissions decision process. When running SWAP experiments to formally promote diversity, one experiment not listed in the main paper was testing our diverse SWAP algorithm over an applicant\u2019smain choice of research area (Table 3). In practice, the applicants accepted already had a high diversity utility in regards to research area. SWAP slightly increased this diversity utility."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "How should a firm allocate its limited interviewing resources to select the optimal cohort of new employees from a large set of job applicants? How should that firm allocate cheap but noisy r\u00e9sum\u00e9 screenings and expensive but in-depth in-person interviews? We view this problem through the lens of combinatorial pure exploration (CPE) in the multi-armed bandit setting, where a central learning agent performs costly exploration of a set of arms before selecting a final subset with some combinatorial structure. We generalize a recent CPE algorithm to the setting where arm pulls can have different cost, but return different levels of information, and prove theoretical upper bounds for a general class of arm-pulling strategies in this new setting. We then apply our general algorithm to a real-world problem with combinatorial structure: incorporating diversity into university admissions. We take real data from admissions at one of the largest US-based computer science graduate programs and show that a simulation of our algorithm produced more diverse student cohorts at low cost to individual student quality, and does so by spending comparable budget to the current admissions process at that university.", "creator": "LaTeX with hyperref package"}}}