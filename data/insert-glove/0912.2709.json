{"id": "0912.2709", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Dec-2009", "title": "The Gaussian Surface Area and Noise Sensitivity of Degree-$d$ Polynomials", "abstract": "hootin We tims provide #b asymptotically giuffrida sharp zeta bounds 18.7 for malaprop the norbu Gaussian calving surface area 114.26 and 16.51 the bertozzi Gaussian 2,889 noise sensitivity of paraboloid polynomial threshold bursch functions. In particular e.i. we karra show that 787-billion if $ f $ ostrowiec is a microprobe degree - $ mccahill d $ government-imposed polynomial embrittlement threshold standfast function, then stovepipes its jirapan Gaussian little-endian sensitivity dendrite at lynley noise sjc rate $ \\ inuktitut epsilon $ calma is steamrollers less than chester-upland some erichson quantity matzen asymptotic 5.40 to $ \\ modernising frac {kottarakkara d \\ peesk sqrt {ghosn 2 \\ epsilon} } {\\ grid-connected pi} $ publicy and jes\u00fas the papoose Gaussian surface thatcherite area carne is kazmunaigaz at most $ \\ insurgente frac {dur\u00e1n d} {\\ mashan sqrt {silje 2 \\ pi} } $. manap Furthermore ibaraki these bounds artemisium are maenas asymptotically tight nijboer as $ \\ ohga epsilon \\ to calderone 0 $ friedrich and $ effectually f $ mirrorlike the threshold surdas function of creekview a product bravada of $ notwithstanding d $ distinct airmen homogeneous linear functions.", "histories": [["v1", "Mon, 14 Dec 2009 19:14:03 GMT  (6kb)", "http://arxiv.org/abs/0912.2709v1", null]], "reviews": [], "SUBJECTS": "cs.CC cs.LG", "authors": ["daniel m kane"], "accepted": false, "id": "0912.2709"}, "pdf": {"name": "0912.2709.pdf", "metadata": {"source": "CRF", "title": "The Gaussian Surface Area and Noise Sensitivity of Degree-d Polynomials", "authors": ["Daniel M. Kane"], "emails": [], "sections": [{"heading": null, "text": "ar X\niv :0\n91 2.\n27 09\nv1 [\ncs .C\nC ]\n1 4\nD ec\n2 00\n9\nThe Gaussian Surface Area and Noise Sensitivity\nof Degree-d Polynomials\nDaniel M. Kane\nDecember 15, 2009"}, {"heading": "1 Introduction", "text": "We provide asymptotically sharp bounds for the Gaussian surface area and the Gaussian noise sensitivity of polynomial threshold functions. In particular we show that if f is a degree-d polynomial threshold function, then its Gaussian sensitivity at noise rate \u01eb is less than some quantity asymptotic to d \u221a 2\u01eb\n\u03c0 and the\nGaussian surface area is at most d\u221a 2\u03c0 . Furthermore these bounds are asymptotically tight as \u01eb \u2192 0 and f the threshold function of a product of d distinct homogeneous linear functions.\nThe noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]). In particular our results imply that the class of degree-d polynomial threshold functions is agnostically learnable under the n-dimensional Gaussian distribution in time nO(d\n2/\u01eb4). A number of other authors have attempted to prove bounds along these lines. [7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin. Our bounds are obtained via a simple computation in the case of d = 1. A bound of O\u0303(\u01eb1/(2d)) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.\nThere is also interest in related questions for points picked uniformly from vertices of the hypercube rather than with the Gaussian distribution. It is conjectured in [4] that the corresponding noise sensitivity in this case is also always O(d \u221a \u01eb). The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(\u01eb1/4) of [2]. It is noted in [3] that such a result would imply a similar bound for the Gaussian case. Hence our results can be thought of as a first step toward proving this conjecture."}, {"heading": "1.1 Basic Definitions", "text": "Given a function f : Rn \u2192 {\u22121, 1} we define the Gaussian noise sensitivity at noise rate \u01eb as GNS\u01eb(f) := Pr(f(X) 6= f(Z)) where X is an n-dimensional Gaussian random variable, and Z = (1 \u2212 \u01eb)X +\u221a 2\u01eb\u2212 \u01eb2Y for Y an independent n-dimensional Gaussian. This is closely related to the Gaussian surface area of f\u22121(1). In particular we define the Gaussian surface area of a set A to be\n\u0393(A) := lim inf \u03b4\u21920 GaussianVolume(A\u03b4\\A) \u03b4 .\nWhere the Gaussian volume of a region R is Pr(X \u2208 R) for X a Gaussian random variable, and where A\u03b4 is the set of points x so that d(x,A) \u2264 \u03b4 (under the Euclidean metric). We note that if A is an open region whose boundary is smooth away from codimension 2, that its Gaussian surface area is equal to\n\u222b\n\u2202A\n\u03c6(x)d\u03c3.\nWhere \u03c6(x) is the Gaussian density, and d\u03c3 is the surface measure on \u2202A. Furthermore if A is such a region, then its Gaussian surface area is seen to be equal to\nlim \u03b4\u21920\nGaussianVolume((\u2202A)\u03b4)\n2\u03b4 .\nFor f a boolean function, we define\n\u0393(f) := \u0393(f\u22121(1)).\nThe concepts of noise sensitivity and surface area are related to each other by noting that the noise sensitivity is roughly the probability that X is close enough to the boundary that wiggling it will push it over the boundary."}, {"heading": "1.2 Statement of Results", "text": "We focus on proving two main results. We define f to be a degree d polynomial threshold function if f(x) = sgn(p(x)) for some degree d polynomial p. We prove the following Theorems about such functions:\nTheorem 1. If f is a degree d polynomial threshold function, then\nGNS\u01eb(f) \u2264 d arcsin(\n\u221a 2\u01eb\u2212 \u01eb2)\n\u03c0 \u223c d\n\u221a 2\u01eb\n\u03c0 = O(d\n\u221a \u01eb).\nFurthermore this bound is asymptotically tight as \u01eb \u2192 0 for the threshold function of any product of distinct linear functions.\nTheorem 2. If f is a degree-d polynomial threshold function then \u0393(f) \u2264 d\u221a 2\u03c0 .\nSection 2 will be devoted to the proof of Theorem 1, Section 3 to the proof of Theorem 2, and Section 4 will provide some closing notes."}, {"heading": "2 Proof of the Noise Sensitivity Bound", "text": "Proof of Theorem 1. We begin by letting \u03b8 = arcsin( \u221a 2\u01eb\u2212 \u01eb2). We need to bound p := GNS\u01eb(f) = Pr(f(X) 6= f(cos(\u03b8)X + sin(\u03b8)Y )). (1)\nWe note that the value of p given in Equation 1 remains the same if X and Y are replaced by any X \u2032 and Y \u2032 that are i.i.d. Gaussian distributions. In particular we define\nX\u03c6 = cos(\u03c6)X + sin(\u03c6)Y.\nNote that X\u03c6 and X\u03c6+\u03c0/2 are i.i.d. Gaussians. Using these distributions we find that for any \u03c6 that since\nX\u03b8+\u03c6 = cos(\u03b8 + \u03c6)X + sin(\u03b8 + \u03c6)Y\n= cos(\u03b8) cos(\u03c6)X \u2212 sin(\u03b8) sin(\u03c6)X + cos(\u03b8) sin(\u03c6)Y + sin(\u03b8) cos(\u03c6)Y = cos(\u03b8)X\u03c6 + sin(\u03b8)X\u03c6+\u03c0/2,\nwe have p = Pr(f(X\u03c6) 6= f(X\u03c6+\u03b8)).\nTherefore we have for any integer n that\nnp = Pr(f(X0) 6= f(X\u03b8))+Pr(f(X\u03b8) 6= f(X2\u03b8))+. . .+Pr(f(X(n\u22121)\u03b8) 6= f(Xn\u03b8)). (2) We define the random function F : R \u2192 {\u22121, 1} by\nF (\u03c6) = f(X\u03c6).\n(F depends on X and Y as well as \u03c6). We note that the left hand side of Equation 2 is at most the number of times that F (\u03c6) changes signs on the interval [0, n\u03b8]. Therefore we have that\np \u2264 E[number of times F changes signs on [0, n\u03b8]] n . (3)\nWe note that F (\u03c6) is periodic in \u03c6 with period 2\u03c0. Therefore the number of times F changes sign on [0, n\u03b8] is the number of times that F changes sign on [0, 2\u03c0) times (\nn\u03b8 2\u03c0 +O(1)\n)\n. Applying this to Equation 3, we get that\np \u2264 E[number of sign changes of F on [0, 2\u03c0)] ( n\u03b8 2\u03c0 +O(1) )\nn .\nTaking a limit as n \u2192 \u221e yields\np \u2264 \u03b8E[number of sign changes of F on [0, 2\u03c0]] 2\u03c0 . (4)\nWe now make use of the fact that f is a degree d polynomial threshold function. In particular we will show that for any X and Y that F changes signs\nat most 2d times on [0, 2\u03c0). We let f = sgn(g) for some degree d polynomial g. We note that the number of sign changes of F is equal to the number of zeroes of the function g(cos(\u03c6)X + sin(\u03c6)Y ) (unless this function is identically 0, which happens with probability 0 and can be ignored). It should be noted though that g(cos(\u03c6)X + sin(\u03c6)Y ) = 0 if and only if z = ei\u03c6 is a root of the degree-2d polynomial\nzdg\n((\nz + z\u22121\n2\n)\nX +\n(\nz \u2212 z\u22121 2i\n)\nY\n)\n.\nTherefore the expectation in Equation 4 is at most 2d. Therefore we have\np \u2264 2d\u03b8 2\u03c0 = d\u03b8 \u03c0\nas desired. We also note the ways in which the above bound can fail to be tight. Firstly, there may be some probability that F changes signs less than 2d times on a full circle. Secondly, the number of times F changes signs may be more than the fraction of the time that f(n\u03b8) 6= f((n + 1)\u03b8) if sign changes are spaced more tightly than \u03b8. On the other hand it should be noted that if f is the threshold function for a product of d distinct homogeneous linear functions, the first case happens with probability 0, and the probability of the second case occurring will necessarily go to 0 as \u01eb does. Therefore for such functions our bound is asymptotically correct as \u01eb \u2192 0."}, {"heading": "3 Proof of the Gaussian Surface Area Bounds", "text": "We will first need to bound a slight variant of the noise sensitivity of a polynomial threshold function. We begin by proving the following Lemma:\nLemma 3. If f is a degree d polynomial threshold function in n dimensions, \u01eb > 0 and X a random Gaussian variable, then\nPr(f(X) 6= f(X(1 + \u01eb))) \u2264 d\u01eb \u221a n\n4\u03c0 .\nProof. First note that by first conditioning on the line that X lies in we may reduce this problem to the case of a one dimensional distribution. Note that f changes sign at most d times along this line. We need to bound the probability that at least one of these sign changes is between X and (1 + \u01eb)X . It therefore suffices to prove that for any one of these sign changes, that it lies between X and (1 + \u01eb)X with probability at most \u01eb \u221a\nn 4\u03c0 . Note that the probability\nthat X is on the correct side of the origin is 12 . Beyond that |X |2 satisfies the \u03c72 distribution with n degrees of freedom, namely 1\n2n/2\u0393(n/2) xn/2\u22121e\u2212x/2dx.\nLetting y = log(x) = 2 log(|X |) we find that that y has distribution 1\n2n/2\u0393(n/2) eny/2e\u2212e y/2dy.\nWe want the probability that y is within a particular range of size 2 log(1 + \u01eb). This is at most 2\u01eb times the densest part of the density function. This is achieved when ny \u2212 ey is maximal, or when y = log(n). Then the density is\n1\n2n/2\u0393(n/2) nn/2e\u2212n/2 =\n\u221a\nn\n4\u03c0\n(n/2)n/2e\u2212n/2 \u221a 2\u03c0(n/2)\n(n/2)! \u2264\n\u221a\nn\n4\u03c0 .\nMultiplying this by d, 2\u01eb and 12 (the probability that X is on the correct side of 0), we get our bound. Notice also that this bound should be nearly sharp if the polynomial giving f is a product of terms of the form |X |2 \u2212 ri for ri approximately n and spaced apart by factors of (1 + \u01eb)2.\nWe can now prove a bound on a quantity more relevant to Gaussian surface area:\nCorollary 4. If f is an n dimensional, degree d polynomial threshold function, \u01eb > 0 and X and Y independent Gaussians, then\nPr(f(X) 6= f(X + \u01ebY )) \u2264 d\u01eb \u03c0 + d\u01eb2 4\n\u221a\nn \u03c0 .\nProof. We let r = \u221a 1 + \u01eb2, \u03b8 = arctan(\u01eb), and let Z = cos(\u03b8)X + sin(\u03b8)Y be a normal random variable. Note that X + \u01ebY = rZ. We then have that\nPr(f(X) 6= f(X + \u01ebY )) \u2264 Pr(f(X) 6= f(Z)) + Pr(f(Z) 6= f(rZ)).\nBy Theorem 1 and Lemma 3 this is at most\nd\u03b8\n\u03c0 + d(r \u2212 1)\n\u221a\nn 4\u03c0 \u2264 d\u01eb \u03c0 +\nd\u01eb2\n4\n\u221a\nn \u03c0 .\nIn particular, we relate this to Gaussian surface area by:\nLemma 5. If f is a boolean function with f\u22121(1) open with smooth boundary and Gaussian area S, and if X and Y are independent Gaussians then,\nlim \u01eb\u21920 Pr(f(X) = \u22121 and f(X + \u01ebY ) = 1) \u01eb = S\u221a 2\u03c0 . (5)\nProof. First note that if A = f\u22121(1), then\nlim \u01eb\u21920 GaussianVolume(A\u01eb\\A) \u01eb = S\nrather than just the liminf being equal. Next note that since the probability that |\u01ebY | > \u01eb2/3 goes rapidly to 0 as \u01eb \u2192 0, we can throw away all cases where X is not within \u01eb2/3 of \u2202A from the left hand side of Equation 5. When X is close to \u2202A and when f(X) = \u22121, we may approximate the probability that\nf(X + \u01ebY ) = 1 by the probability that the component of \u01ebY in the direction of the shortest path from X to A is more than d(X,A). Since \u2202A is smooth, this approximation is accurate for X close to A, and in particular for X within \u01eb2/3 should introduce an error of O(\u01eb4/3), which can be ignored. Hence if Z is a normalized one variable Gaussian, the numerator of left hand side can be replaced by\nPr(\u01ebZ \u2265 d(X,A) > 0) = Pr ( Z \u2265 d(X,A) \u01eb > 0 ) .\nThis is easily seen to be \u222b \u221e\n0\n1\u221a 2\u03c0 e\u2212x 2/2Pr(0 < d(X,A) \u2264 \u01ebx)dx =\n\u222b \u221e\n0\n1\u221a 2\u03c0 e\u2212x 2/2GVol(A\u01ebx\\A)dx\n=\n\u222b \u221e\n0\n1\u221a 2\u03c0 e\u2212x 2/2S\u01ebx(1 + o(1))dx\n= S\u01eb\u221a 2\u03c0 + o(\u01eb).\nThus completing our proof.\nProof of Theorem 2. This follows immediately from Corollary 4 and Lemma 5 after noting that\nPr(f(X) = \u22121, f(X + \u01ebY ) = 1) \u223c 1 2 Pr(f(X) 6= f(X + \u01ebY )) \u223c d\u01eb 2\u03c0 ."}, {"heading": "4 Conclusion", "text": "We have shown nearly tight bounds on the Gaussian surface area and noise sensitivity of polynomial threshold functions. One might hope to generalize these results to work for other distributions, such as the uniform distribution on vertices of the hypercube. Unfortunately, several aspects of this proof are difficult to generalize. Perhaps most significantly, we lose the symmetry that allowed us to prove our original result on noise sensitivity. Another difficulty would be in the relation between noise sensitivity and surface area. In our case the two are essentially equivalent quantities of study. On the other hand [6] defined a notion of surface area for the hypercube distribution and proved that for even linear threshold functions there could be a gap between noise sensitivity and surface area of as much as \u0398( \u221a log(n))."}], "references": [{"title": "The Reverse Isoperimetric Problem for Gaussian Measure", "author": ["K. Ball"], "venue": "Discrete and Computational Geometry,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Noise sensitivity of Boolean functions and applications to percolation, Inst", "author": ["I. Benjamini", "G. Kalai", "O. Schramm"], "venue": "Hautes Etudes Sci. Publ. Math.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Average sensitivity and noise sensitivity of polynomial threshold functions, Manuscript, available at http://arxiv.org/abs/0909.5011", "author": ["I. Diakonikolas", "P. Raghavendra", "R. Servedio", "L.-Y. Tan"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Bounding the sensitivity of polynomial threshold functions, Manuscript, available at http://arxiv.org/abs/0909.5175", "author": ["P. Harsha", "A. Klivans", "R. Meka"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Learning Geometric Concepts via Gaussian Surface Area", "author": ["Adam R. Klivans", "Ryan O\u2019Donnell", "Rocco A. Servedio"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Semigroup proofs of the isoperimetric inequality in Euclidean and Gauss space", "author": ["M. Ledoux"], "venue": "Bull. Sci. Math.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Noise Stability of Weighted Majority", "author": ["Yuval Peres"], "venue": "Manuscript, available at http://arxiv.org/abs/math/0412377,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}], "referenceMentions": [{"referenceID": 4, "context": "The noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]).", "startOffset": 136, "endOffset": 139}, {"referenceID": 5, "context": "[7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "A bound of \u00d5(\u01eb) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "A bound of \u00d5(\u01eb) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials.", "startOffset": 82, "endOffset": 85}, {"referenceID": 6, "context": "The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(\u01eb) of [2].", "startOffset": 48, "endOffset": 51}, {"referenceID": 1, "context": "The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(\u01eb) of [2].", "startOffset": 87, "endOffset": 90}, {"referenceID": 2, "context": "It is noted in [3] that such a result would imply a similar bound for the Gaussian case.", "startOffset": 15, "endOffset": 18}, {"referenceID": 4, "context": "On the other hand [6] defined a notion of surface area for the hypercube distribution and proved that for even linear threshold functions there could be a gap between noise sensitivity and surface area of as much as \u0398( \u221a", "startOffset": 18, "endOffset": 21}], "year": 2009, "abstractText": "We provide asymptotically sharp bounds for the Gaussian surface area and the Gaussian noise sensitivity of polynomial threshold functions. In particular we show that if f is a degree-d polynomial threshold function, then its Gaussian sensitivity at noise rate \u01eb is less than some quantity asymptotic to d \u221a 2\u01eb \u03c0 and the Gaussian surface area is at most d \u221a 2\u03c0 . Furthermore these bounds are asymptotically tight as \u01eb \u2192 0 and f the threshold function of a product of d distinct homogeneous linear functions. The noise sensitivity and surface area are both of fundamental interest and useful in the analysis of agnostic learning algorithms (see [6]). In particular our results imply that the class of degree-d polynomial threshold functions is agnostically learnable under the n-dimensional Gaussian distribution in time n 2/\u01eb4). A number of other authors have attempted to prove bounds along these lines. [7] proves a bound on noise sensitivity in terms of surface area and we relate our bounds essentially by also proving the other direction of this inequality for boolean functions with smooth interface that switch signs a bounded number of times on any line through the origin. Our bounds are obtained via a simple computation in the case of d = 1. A bound of \u00d5(\u01eb) noise sensitivity was recently proved by [3] and independently by [5] for multilinear polynomials. There is also interest in related questions for points picked uniformly from vertices of the hypercube rather than with the Gaussian distribution. It is conjectured in [4] that the corresponding noise sensitivity in this case is also always O(d \u221a \u01eb). The d = 1 case of this conjecture was proved by [8], improving upon a bound of O(\u01eb) of [2]. It is noted in [3] that such a result would imply a similar bound for the Gaussian case. Hence our results can be thought of as a first step toward proving this conjecture.", "creator": "LaTeX with hyperref package"}}}