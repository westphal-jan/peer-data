{"id": "1106.2489", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2011", "title": "Eliciting Forecasts from Self-interested Experts: Scoring Rules for Decision Makers", "abstract": "boussac Scoring valle rules 114th for 114.6 eliciting valdaysky expert predictions of afor random wrs variables 765,000 are bomar usually developed masdevallia assuming that eiffel experts ascendence derive utility only d\u00e9mocrate from weakling the tehf quality 794,000 of their glicksman predictions (e. g. , misr score baltiansky awarded 32-pounders by the ciccio rule, cabela or payoff pachyderm in dreadzone a hilpert prediction longridge market ). rindu We stropping study messa a more jamiya realistic setting windir in histiocytes which (labont\u00e9 a) the poliziottesco principal haughley is mihm a transfiguration decision troja maker and pennies will copolymer take newpage a mashing decision arbitrage based config.sys on riverbank the multiflora expert ' formula s prediction; and (b) the editoral expert has dewatered an headon inherent internic interest utt in the paparesta decision. aprobacion For example, 54.96 in 754 a corporate 1982-89 decision shoichet market, maillet the dolch expert may derive different levels of jacobinism utility g\u00fcssing from amoo the latter actions taken noorda by her overage manager. As a gills consequence the expert organises will u-70 usually threesome have an heroically incentive steepness to misreport her forecast to 19.98 influence the latour-maubourg choice flybridge of the decision soph maker multiplan if proof-of-concept typical bastard scoring martial-arts rules are choudhury used. We hermanns develop a 46-million general nauplius model for this setting and sex-related introduce the 86.29 concept of a k-ci compensation rule. brigadiers When fran\u00e7oise combined with the 17:41 expert ' s slots inherent schuff utility embong for cholecystitis decisions, penfolds a compensation euro289 rule induces sluggers a net scoring candaele rule el\u00edo that behaves like a normal kalumburu scoring pratincole rule. medill Assuming monophosphate full 2,693 knowledge of chola expert leid utility, we provide a complete characterization southey of all (strictly) proper barany compensation bifengxia rules. We snacking then naviera analyze the rxd4 situation metrovacesa where rile the onder expert ' s utility kitchell function is not fully known naugatuck to the neurasthenic decision maker. We show afro-caribbean bounds on: (xeroxed a) expert incentive frollo to ovens misreport; (b) the degree gaj to which bushies an fedepetrol expert vads will anamorphic misreport; juoro and (fy97 c) lep decision maker artifacts loss mogavero in utility due nansi to such uncertainty. These leprechauns bounds embrasure depend westermann in harbingers natural allard ways cogswell on the vasantha degree of goindwal uncertainty, the local degree of convexity \u0443\u043d\u0438\u0432\u0435\u0440\u0441\u0438\u0442\u0435\u0442 of net euro-atlantic scoring hultberg function, alstyne and rauhala natural lamoria properties of precede the 31-story decision yag\u00fce maker ' osservatore s utility function. They radivojevi\u0107 also suggest hanoune optimization heinousness procedures for the design of compensation mariem rules. kad Finally, semiquaver we beven briefly jiggs discuss honeymooners the grisi use puygrenier of cook-off compensation rules idowu as market doamnei scoring srikakulam rules for mcginness self - interested gueckedou experts in a prediction qia market.", "histories": [["v1", "Mon, 13 Jun 2011 17:04:03 GMT  (56kb,D)", "http://arxiv.org/abs/1106.2489v1", "11 pages 4 figures pdflatex Seethis http URL"]], "COMMENTS": "11 pages 4 figures pdflatex Seethis http URL", "reviews": [], "SUBJECTS": "cs.GT cs.AI cs.MA cs.SI", "authors": ["craig boutilier"], "accepted": false, "id": "1106.2489"}, "pdf": {"name": "1106.2489.pdf", "metadata": {"source": "CRF", "title": "Eliciting Forecasts from Self-interested Experts: Scoring Rules for Decision Makers", "authors": ["Craig Boutilier"], "emails": ["cebly@cs.toronto.edu"], "sections": [{"heading": "1. INTRODUCTION", "text": "Eliciting predictions of uncertain events from experts or other knowledgeable agents\u2014or relevant information pertaining to events\u2014 is a fundamental problem of study in statistics, economics, operations research, artificial intelligence and a variety of other areas [16, 5]. Increasingly, robust mechanisms for prediction are being developed, proposed and/or applied in real-world domains ranging from elections and sporting events, to events of public interest (e.g., disease spread or terrorist action), to corporate decision making. Indeed, the very idea of crowd-sourcing and information (or prediction) markets is predicated on the existence of practical mechanisms for information elicitation and aggregation.\nA key element in any prediction mechanism involves providing an expert agent with the appropriate incentives to reveal a forecast they believe to be accurate. Many forms of \u201coutcome-based\u201d scoring rules, either individual or market-based, provide experts with incentives to (a) provide sincere forecasts; (b) invest effort to improve the accuracy of their personal forecasts; and (c) participate\nWorking Paper\nin the mechanism if they believe they can improve the quality of the principal\u2019s forecast. However, with just a few exceptions (see, e.g., [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put. Furthermore, even these models assume that the experts who provide their forecasts derive no utility from the final forecast, or how it will be used, except insofar as they will be rewarded by the prediction mechanism itself.\nIn many real-world uses of prediction mechanisms, this assumption is patently false. Setting aside purely informational and entertainment uses of information markets, the principal is often interested in exploiting the elicited forecast in order to make a decision [10, 13, 3]. In corporate prediction markets, the principal may base strategic business decisions on internal predictions of uncertain events. In a hiring committee, the estimated probability of various candidates accepting offers (and being given offers by competitors) will influence the order in which (and whether) offers are made. Of course, other examples abound. Providing appropriate incentives in the form of scoring rules is often difficult in such settings, especially when the outcome distribution is conditional on the decision ultimately taken by the principal [13, 3]. However, just as critically, in these settings, the experts whose forecasts are sought often have their own interests in seeing specific decisions being taken, interests that are not (fully) aligned with those of the principal. For example, in a corporate setting, an expert from a certain division may have an incentive to misreport demand for specific products, thus influencing R&D decisions that favor her division. In a hiring committee, an committee member may misreport the odds that a candidate will accept a competing position in order to bias the \u201coffer strategy\u201d in a way that favors his preferred candidate.\nIn this work, we develop what we believe to be the first class of scoring rules that incentivizes truthful forecasts even when experts have an interest in the decisions taken by the principal, and hence would like to provide forecasts that manipulate that decision \u201cin their favor.\u201d Other work has studied both decision making and incentive issues in prediction markets, but none that we are aware of addresses the natural question of expert self-interest in the decisions of the principal.\nHanson [10] introduced the term decision markets to refer to the broad notion of prediction markets where experts offer forecasts for events conditional on some policy being adopted or a decision being taken. Othman and Sandholm [13] provide the first explicit, formal treatment of a principal who makes decisions based on expert forecasts. They address several key difficulties that arise due to the conditional nature of forecasts, but assume that the experts themselves have no direct interest in the decision that is taken. Chen and Kash [3] extend this model to a wider class of informational settings and decision policies. Dimitrov and Sami [7] consider the\nar X\niv :1\n10 6.\n24 89\nv1 [\ncs .G\nT ]\n1 3\nJu n\n20 11\nissue of strategic behavior across multiple markets and the possibility that an expert may misreport her beliefs in one market to manipulate prices (and hence gain some advantage) in another. Similarly, Conitzer [6] explores strategic aspects of prediction markets through their connections to mechanism design. While the mechanism design approach could prove very useful for the problems we address (see concluding remarks in Sec. 6), Conitzer assumes an expert\u2019s utility is derived solely from the payoff provided by the prediction mechanism. Also related to the model we develop here is the analysis of Shi et al. [15], who consider experts that, once they report their forecasts, can take action to alter the probabilities of the outcomes in question. Unlike our model, they do not consider expert utility apart from the payoff offered by the mechanism (though, as in our model, the principal does have a utility function that dictates the value of an expert report).\nOur basic building block is a scoring rule for a single expert who knows the principal\u2019s policy\u2014i.e., mapping from forecasts to decisions\u2014and where the principal knows the expert\u2019s utility for decisions. We show that the scoring rule must compensate the expert in a very simple and intuitive way based on her utility function. Specifically, the principal uses a compensation function that, when added to the inherent utility the expert derives from the principal\u2019s decision, induces a proper scoring rule. In a finite decision space, an expert\u2019s optimal utility function is piecewise-linear and convex in probability space\u2014we describe one natural scoring rule based on this function that is proper, but not strictly so. We then provide a complete characterization of all proper compensation functions. We also characterize those which, in addition, satisfy weak and strong participation constraints that ensure an expert will be sufficiently compensated to \u201cplay the game.\u201d\nWe then provide a detailed analysis of both expert uncertainty in the principal\u2019s policy, and principal uncertainty in the expert\u2019s utility for decisions. First we observe that the expert need not know the principal\u2019s policy prior to providing her forecast as long as she can verify the decision taken after the fact. Second, we analyze the impact of principal uncertainty regarding the expert\u2019s utility function. In general, the principal cannot ensure truthful reporting. However, we show that, given bounds on this uncertainty, bounds can then be derived on all of the following: (i) the expert\u2019s incentive to misreport; (ii) the deviation of the expert\u2019s misreported forecast from its true beliefs; and (iii) the loss in utility the principal will realize due to this uncertainty. The first two bounds rely on the notion of strong convexity of the net scoring function induced by the compensation rule. The third bound uses natural properties of the principal\u2019s utility function. Apart from bounds derived from global strong convexity, we show that these bounds can be significantly tightened using local strong convexity, specifically, by ensuring merely that the net scoring function is sufficiently (and differentially) strongly convex near the decision boundaries of the principal\u2019s policy. These bounds suggest computational optimization methods for for designing compensation rules (e.g., using splines related to the principal\u2019s utility function). We conclude by briefly discussing a market scoring rule (MSR) based on our one-shot compensation rule. Using this MSR, the principal may need to provide more generous compensation to each expert than in the one-shot case, simply to ensure participation; but in some special cases, no additional compensation is needed.\nThe paper is organized as follows. We begin with a basic background on scoring rules for prediction mechanisms in Sec. 2. In Sec. 3 we define our model for analyzing the behavior of selfinterested experts, introduce compensation rules, and show that the resulting net scoring function can be used to analyze expert behavior. We provide a complete characterization of (strict) proper com-\npensation rules and and further characterize two subclasses of compensation rules that satisfy the two participation constraints mentioned above. In Sec. 4 we relax two assumptions in our model. We first show the expert need to be aware of the principal\u2019s policy for our model to work. We then consider a principal that has imperfect knowledge of the expert\u2019s utility function, and using the notion of (local and global) strong convexity derives bounds on the expert\u2019s incentive to misreport and the impact on the quality of the principal\u2019s decision. After a brief discussion of market scoring rules in Sec. 5, we conclude in Sec. 6 with a discussion of several avenues for future research."}, {"heading": "2. BACKGROUND: SCORING RULES", "text": "We begin with a very brief review of relevant concepts from the literature on scoring rules and prediction markets. For comprehensive overviews, see the surveys [16, 5].\nWe assume that an agent\u2014the principal\u2014is interested in assessing the distribution of some discrete random variable X with finite domain X = {x1, . . . , xm}. Let \u2206(X) denote the set of distributions over X , where p \u2208 \u2206(X) is a nonnegative vector \u3008p1, . . . , pm\u3009 s.t. \u2211 i pi = 1. The principle can engage one or more experts to provide a forecast p \u2208 \u2206(X). We focus first on the case of a single expert E. For instance, to consider a simple toy example we use throughout the sequel, the mayor of a small town may ask the local weather forecaster to offer a probabilistic estimate of weather conditions for the following weekend.1\nWe assumeE has beliefs p aboutX , but a key question is how to incentivize E to report p faithfully (and devote reasonable effort to developing accurate beliefs). A variety of scoring rules have been developed for just this purpose [2, 14, 12, 8]. A scoring rule is a function S : \u2206(X) \u00d7 X \u2192 R that provides a score (or payoff) S(r, xi) to E if she reports forecast r and the realized outcome of X is xi, essentially rewarding E for her predictive \u201cperformance\u201d [2, 12]. If E has beliefs p and reports r, her expected score is S(r,p) = \u2211 i S(r, xi)pi. We say S is a proper scoring rule iff a truthful report is optimal for E:\nS(p,p) \u2265 S(r,p), \u2200p, r \u2208 \u2206(X) (1)\nWe say that S is strictly proper if inequality (1) is strict for r 6= p (i.e., E has strict disincentive to misreport). A variety of strictly proper scoring rules have been developed, among the more popular being the log scoring rule, where S(p, xi) = a log pi + bi (for arbitrary constants a > 0 and bi) [12, 14]. In what follows, we will restrict attention to regular scoring rules in which payment S(r, xi) is bounded whenever ri > 0.\nProper scoring rules can be fully characterized in terms of convex cost functions [12, 14]; here we review the formulation of Gneiting and Raftery [8]. Let G : \u2206(X) \u2192 R be any convex function over distributions\u2014we refer to G as a cost function. We denote by G\u2217 : \u2206(X) \u2192 Rm some subgradient of G, i.e., a function satisfying\nG(q) \u2265 G(p) +G\u2217(p) \u00b7 (q\u2212 p) for all p,q \u2208 \u2206(X).2 Such cost functions and associated subgradients can be used to derive any proper scoring rule.\nTHEOREM 1. [12, 14, 8] A regular scoring rule S is proper iff\nS(p, xi) = G(p)\u2212G\u2217(p) \u00b7 (p) +G\u2217i (p) (2) 1More significant examples in the domains of public policy or corporate decision making, as discussed above, can easily be constructed by the reader. 2If G is differentiable at p then the subgradient at that point is unique, namely, the gradient\u2207G(p).\nfor some convex G and subgradient G\u2217. S is strictly proper iff G is strictly convex.\nIntuitively, Eq. 2 defines a hyperplane\nHp = \u3008S(p, x1), . . . , S(p, xm)\u3009,\nfor each point p, that is subtangent to G at p. This defines a linear function, for any fixed report p, giving the expected score of that report given beliefs q: S(p,q) = Hp \u00b7 q. An illustration is given in Fig. 1 for a simple one-dimensional (two-outcome) scenario.\nThere are a number of prediction market mechanisms that allow the principal to extract information from multiple experts; see [16, 5] for excellent surveys. Here we focus on market scoring rules (MSRs) [9, 11], which allow experts to (sequentially) change the forecasted p using any proper scoring rule S. Given the current forecast p\u2032, an expert can change the forecast to p if she is willing to pay according to S(p\u2032, \u00b7) and receive payment S(p, \u00b7). If her true beliefs p are different from p\u2032 and the scoring rule is strictly proper, then she has incentive to participate and report truthfully. Under certain conditions, MSRs can be interpreted as automated market makers [4]. Since each expert pays the amount due to the previous expert for her prediction, the net payment of the principal is the score associated with the final prediction."}, {"heading": "3. SCORING RULES FOR SELF-INTERESTED EXPERTS", "text": "Scoring rules in standard models assume that an expert offering a forecast is uninterested in any aspect her forecast other than the score she will derive from her prediction. As discussed above, there are many settings where the principal will make a decision based on the received forecast, and the expert has a direct interest in this decision. In this section, we develop a model for this situation and devise a class of scoring rules that incentive self-interested agents to report their true beliefs."}, {"heading": "3.1 Model Formulation", "text": "We assume the principal, or decision maker (DM), will elicit a forecast ofX from expertE, and make a decision that is influenced by this forecast. Let D = {d1, . . . , dn} be the set of possible decisions, and uij be DM\u2019s utility should it take decision di with xj being the realization of X . Letting ui = \u3008ui1, \u00b7 \u00b7 \u00b7 , uim\u3009, the expected utility of decision di given distribution p is Ui(p) = ui \u00b7p. For any beliefs p, DM will want to take the decision that maximizes expected utility, giving DM the utility function U(p) = maxi\u2264n Ui(p). Since each Ui is a linear function of p, U is piecewise linear and convex (PWLC). Furthermore, each di is optimal\nin a (possibly empty) convex region of belief space Di = {p : ui \u00b7p \u2265 uj \u00b7p, \u2200j}. We assume DM acts optimally and that it has a policy \u03c0 : \u2206(X) \u2192 D that selects some optimal decision \u03c0(p) for any expert forecast p. In what follows, we take Di = \u03c0\u22121(di). We denote by Dij the (possibly empty) boundary between Di and Dj . Notice that for any p \u2208 Dij we must have Ui(p) = Uj(p).3\nIn our running example, suppose the mayor must decide whether to hold a civic ceremony in the town park or at a private banquet facility. Given a forecast probability p of rain, she will make outdoor arrangements at the park if p falls below some threshold \u03c4 , and will rent the banquet facility if p is above \u03c4 (here \u03c4 is the indifference probability: Upark(\u03c4) = Ubanq(\u03c4)).\nWe note that this model of DM utility is slightly more restricted than that of [13, 3], who allow the utility of each decision to depend on a different random variable, and assume that the realization of a variable will be observed only if the corresponding decision is taken. This introduces difficulties in offering suitable incentives for participation that do not arise in our setting; indeed, the primary contribution of Othman and Sandholm [6], and the extension by Chen and Kash [3], is a characterization of a form of proper scoring in the face of these complications. We also confine our attention primarily to a principal that maximizes its expected utility given E\u2019s report (in the terminology of [13], DM uses the max decision rule), though we remark on the possible use of stochastic policies by DM in Sec. 4.2.\nNow suppose a single expert E is asked to provide a forecast of X that permits DM to make a decision. Assume that E knows DM\u2019s policy \u03c0: knowledge of DM\u2019s utility function is sufficient for knowledge of the policy but is not required (we discuss the possibility of E being uncertain about \u03c0 in Sec. 4.1). Further, assume that E has its own utility function or bias b, where bij is E\u2019s utility should DM take decision di and xj is the realization of X . Define bi = \u3008bi1, \u00b7 \u00b7 \u00b7 , bim\u3009; and let E\u2019s expected utility for di given p be Bi(p) = bi \u00b7 p. In our small example, the weather forecaster may be related to the owner of the banquet facility, and will get some degree of satisfaction (or a small kickback) if the mayor\u2019s ceremony is held there.\nAs with DM, E\u2019s optimal utility functionB\u2217 (if DM were acting on E\u2019s behalf) is PWLC:\nB\u2217(p) = max i bi \u00b7 p. (3)\nDenote by D\u2217(p) the decision di that maximizes Eq. 3, i.e., E\u2019s preferred decision given beliefs p (see Fig. 2 for an illustration).\nOf course, DM is pursuing its own policy \u03c0, not acting to optimize E\u2019s utility. Hence E\u2019s actual utility for a specific report r under beliefs p is given by\nB\u03c0(r,p) = b\u03c0(r) \u00b7 p; (4)\nthat is, if she reports r, DM will take decision \u03c0(r) = dk for some k, and she will derive benefit Bk(p). We refer to B\u03c0(r,p) as E\u2019s inherent utility for reporting r. Similarly, B(r, xi) = bi,\u03c0(r) is E\u2019s inherent utility for report r under realization xi. This is simply the inherent benefit she derives from the decision she induces DM to take. This is illustrated in Fig. 2. Notice that E\u2019s utility for reports, given any fixed beliefs p, is not generally continuous, with potential (jump) discontinuities at DM\u2019s decision boundaries.\nWithout some scoring rule, there is a clear incentive for E to misreport its true beliefs to induce DM to take a decision that E prefers, thereby causing DM to take a suboptimal decision. For instance, in Fig. 2, if E\u2019s true beliefs p lie in R1, its preferred de-\n3Assuming \u201cties\u201d at boundaries are broken consistently, the regions Di will be convex, but possibly open.\ncision is d1; but truthful reporting will induce DM to take decision d3. E has greater inherent utility for reporting (any) r \u2208 D1. Indeed, its gain from the misreport is p \u00b7 (b1 \u2212 b3). Equivalently, E stands to lose p \u00b7 (b1 \u2212 b3) by reporting truthfully. Intuitively, a proper scoring rule would remove this incentive to misreport."}, {"heading": "3.2 Compensation Rules", "text": "If DM knows E utility function, it could reason about E\u2019s incentive to misreport and revise its decision policy accordingly. Of course, this would naturally lead to a Bayesian game requiring analysis of its Bayes-Nash equilibria, and generally leaving DM with uncertainty about E\u2019s true beliefs.4 Instead, we wish to derive a scoring rule that DM can use to incentivize E to report truthfully.\nA compensation function C : \u2206(X) \u00d7 X \u2192 R is a mapping from reports and outcomes into payoffs, exactly like a standard scoring rule. Unlike a scoring rule, however, C does not fully determine E\u2019s utility for a report; one must also take into account the inherent utility E derives from the decision it prompts the DM to take. Any compensation function C induces a net scoring function:\nS(p, xi) = C(p, xi) +B \u03c0(p, xi) (5)\nE\u2019s expected net score for report r under beliefs p is S(r,p) = C(r,p) + B\u03c0(r,p), where C(r,p) = \u2211 i piC(r, xi) is E\u2019s expected compensation. One natural way to structure the compensation function is to use C to compensate E for the loss in inherent utility incurred by reporting its true beliefs p (relative to its best report). This would remove any incentive for E to misreport. We define a particular compensation function C1 that accounts for this loss:\nC1(p, xi) = bi,D\u2217(p) \u2212 bi,\u03c0(p). (6)\nC1(p, xi) is simply the difference between E\u2019s realized utility for its optimal decision (relative to its report p) and the actual decision she induced. C1 does not satisfy the usual properties of scoring rules: it is given by a subgradient of the loss function, which is not convex, nor even continuous. However, E\u2019s payoff for a report consists of both this compensation and its inherent utility, i.e., her 4See Dimitrov and Sami [7] and Conitzer [6] for just such a gametheoretic treatment of prediction markets (without decisions).\nnet score:\nS1(p, xi) = C1(p, xi) +B \u03c0(p, xi) (7)\n= (bi,D\u2217(p) \u2212 bi,\u03c0(p)) + bi,\u03c0(p)) (8) = bi,D\u2217(p) (9)\nE\u2019s expected net score under beliefs p is identical to her expected utility for the optimal decision D\u2217(p). Hence, no other report can induce a decision that gives her greater utility. Informally, this shows that truthful reporting is optimal. It can be seen directly by observing that the net score S1 can be derived from Eq. 2 by letting G(p) = B\u2217(p) = maxi\u2264nBi(p) be E\u2019s optimal utility function (which is PWLC, hence convex), and using the subgradient G\u2217(p) given by the hyperplane corresponding to the optimal decision D\u2217(p) at that point.5\nDEFINITION 2. A compensation function C is proper iff the expected net score function S satisfies S(p,p) \u2265 S(q,p) for all p,q \u2208 \u2206(X). C is strictly proper if the inequality is strict.\nWe don\u2019t prove this formally since we prove a more general result below, but the above informal argument shows:\nPROPOSITION 3. Compensation function C1 is proper.\nREMARK 4. We\u2019ve defined the compensation function using the space of all decisions D. However, this may cause DM to compensate E for decisions it will never take. If we restrict attention to those decisions in the range of DM\u2019s policy \u03c0, then the above characterization still applies (and will typically reduce total compensation). In what follows, we assume the set of decisions has been pruned to include only those d \u2208 D for which \u03c0\u22121(d) 6= \u2205, and that E\u2019s utility function is defined relative to that set.\nCompensation function C1, while proper, is not strictly proper. The induced net scoring function S1 is characterized by a nonstrictly convex cost function G, since G = B\u2217. In particular, for any region R(d) of belief space where a single decision d is optimal for E, every report p \u2208 R(d) has the same expected net score, hence there is no \u201cpositive\u201d incentive for truthtelling.\nWhile C1 gives us one mechanism for proper scoring with selfinterested experts, we can generalize the approach to provide a complete characterization of all proper (and strictly proper) compensation functions. We derived C1 by compensating E for its loss due to truthful reporting. This approach is more \u201cgenerous\u201d than necessary. Rather than compensating E for its loss, we need only remove the potential gain from misreporting. The key component of C1 is not the \u201ccompensation term\u201d bi,D\u2217(p), but rather the the penalty term \u2212bi,\u03c0(p). It is this penalty that prevents E from benefiting by changing DM\u2019s decision. Any such gain is subtracted from its compensation by the inclusion of \u2212bi,\u03c0(p). We insist only that the positive compensation term is convex: it need bear no connection to E\u2019s actual utility function to incentivize truthfulness.6 Indeed, we can fully characterize the space of proper and strictly proper compensation functions:\nTHEOREM 5. A compensation rule C is proper for E iff\nC(p, xi) = G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\u2212 bi,\u03c0(p) (10)\nfor some convex functionG, and subgradientG\u2217 ofG. C is strictly proper iff G is strictly convex. 5At interior points of E\u2019s decision regions, the hyperplane is the unique subgradient. At E\u2019s decision boundaries, an arbitrary subgradient can be used. 6Incentive to participate is discussed below.\nPROOF. Suppose C is given by Eq. 10. E\u2019s utility for a report p given outcome xi is given by its net score:\nS(p, xi) = C(p, xi) +B \u03c0(p, xi)\n= G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\u2212 bi,\u03c0(p) + bi,\u03c0(p) = G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\nSince S satisfies the conditions of Thm. 1, the standard proof of propriety of S can be used. Similarly, if G is strictly convex, S is strictly proper.\nConversely, suppose C is proper (so that the induced net score satisfies S(p,p) \u2265 S(q,p)). Define G(p) = S(p,p). If S is proper in this sense, it is easy to show that S(q,p) is a convex function of q (for fixed beliefs p); and since G(p) = S(p,p) = maxq S(q,p) is the maximum of a set of convex functions (where the last equality holds because C is proper), G is itself convex. Thm. 1 (or more precisely the method used to prove it) ensures that, for some subgradient G\u2217 of G, we have S(p, xi) = G(p) \u2212 G\u2217(p) \u00b7 p +G\u2217i (p). Hence,\nC(p, xi) = S(p, xi)\u2212B\u03c0(p, xi) = G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\u2212 bi,\u03c0(p)\nso C has the required form. If C is strictly proper, then G must be strictly convex and Thm. 1 can again be applied.\nAn illustration of a cost function G(p) that gives rise to a proper compensation function is shown in Fig. 3(a).\nThe characterization of Thm. 5 ensures truthful reporting, but may not provide incentives for participation. Indeed, the expert may be forced to pay the DM in expectation for certain beliefs. Specifically, ifG(p) < B\u03c0(p),E\u2019s expected compensationC(p,p) is negative. Unless the DM can \u201cforce\u201d E to participate, this will cause E to avoid providing a forecast if its beliefs are p (e.g., see point p is Fig. 3(a)). In general, we\u2019d like to provide E with nonnegative expected compensation. We can do this by insisting that the compensation rule weakly incentives participation:\nDEFINITION 6. A compensation function C satisfies weak participation iff for any beliefs p,E\u2019s expected compensation for truthful reporting C(p,p) is non-negative.\n(See Fig. 3(b) for an illustration of a cost function G that induces a compensation rule C satisfying weak participation.)\nTHEOREM 7. A proper compensation ruleC satisfies weak participation iff it meets the conditions of Thm. 5 and G(p) \u2265 B\u03c0(p) for all p \u2208 \u2206(X).\nPROOF. The proof is straightforward: if G(p) \u2265 B\u03c0(p) for all p, then for any truthful report p E\u2019s expected compensation is G(p) \u2212 B\u03c0(p) \u2265 0. Conversely, if G(p) < B\u03c0(p) for some p, then if E holds beliefs p, a truthful report has negative expected compensation G(p)\u2212B\u03c0(p) < 0.\nWhile weak participation seems desirable, even it is not strong enough to ensure an expert\u2019s participation in the mechanism in general. Suppose we define a compensation function using some convex cost function G(p). If E participates, she will maximize her net payoff by reporting her true beliefs, say, p. But suppose that G(p) < B\u2217(p). While E may not be certain how DM will act without its input (e.g., she may not know DM\u2019s \u201cdefault beliefs\u201d precisely), she may nevertheless have beliefs about DM\u2019s default policy. And, ifE believes DM will take decisionD\u2217(p) if she provides no forecast, then she will be better off not participating and taking the expected payoff B\u2217(p) derived solely from her inherent\nutility, and forego participation in the mechanism (which limits her expected payoff to G(p)). (See point q in Fig. 3(b).) To prevent this we can require that C strongly incentivize participation, by insisting no matter what E believes about DM\u2019s default policy (i.e., its action given no reporting), it will not sacrifice expected utility by participating in the mechanism.\nDEFINITION 8. A compensation functionC satisfies strong participation iff, for any decision di \u2208 D, for any beliefs p, E\u2019s net score for truthful reporting is no less than Bi(p).\nStrong participation means that E has no incentive to abstain from participation (and need not \u201ctake its chances\u201d that DM will make a decision it likes). This definition is equivalent to requiring that E\u2019s expected utility for truthful reporting, as a function of p is at least as great as her optimal utility function, i.e., S(p,p) \u2265 B\u2217(p) for all p \u2208 \u2206(X). Fig. 3(c) illustrates such a compensation rule.\nTHEOREM 9. Proper compensation ruleC satisfies strong participation iff it meets the conditions of Thm. 5 and G(p) \u2265 B\u2217(p) for all p \u2208 \u2206(X).\nPROOF. The proof is straightforward. Suppose G(p) \u2265 B\u2217(p) for all p. If E holds beliefs p, then a truthful report has expected net score of G(p) \u2265 B\u2217(p), and for no beliefs about DM\u2019s default policy can E derive higher utility by not participating. Conversely, suppose G(p) < B\u2217(p) for some p. If E holds beliefs p and also believes that DM will take action d = D\u2217(p) if E does not report, then E will derive utility B\u2217(p) by not participating, better than the optimal expected score G(p) from participating.\nOBSERVATION 10. Compensation rule C1 is the unique minimal (non-strictly) proper rule satisfying strong participation. That is, no compensation rule offers lower compensation for any report without violating strong participation.\nIn general, if we insist on strong participation, DM must provide potential compensation up to the level ofE\u2019s maximum utility gap:\ng(B) = max i\u2264m,j,k\u2264n\nbik \u2212 bij .\nHowever, this degree of compensation is needed only if DM and E have \u201cdirectly conflicting\u201d interests (i.e., DM takes a decision whose realized utility is as far from optimal as possible from E\u2019s perspective). In such cases, one would expect E\u2019s utility to be significantly less than DM\u2019s. If not, this compensation would not be worthwhile for DM. Conversely, if E\u2019s interests are well aligned with those of DM, the total compensation required will be small. The most extreme case of well-aligned utility is one where functions \u03c0 and D\u2217 coincide, i.e., \u03c0(p) = D\u2217(p) for all beliefs p, in which case, no compensation is required. Specifically, compensation function C1(p) = 0 for all p; and while C1 is not strictly proper, the only misreports thatE will contemplate (i.e., that do not reduce its net score) are those that cannot change DM\u2019s decision (i.e., cannot impact DM\u2019s utility). As a consequence, DM should elicit forecasts from an expert who either (a) has well-aligned interests in the decisions being contemplated; (b) has interest whose magnitude is small (hence requires modest compensation) relative to DM\u2019s own utility; or (c) can be \u201cforced\u201d to make a prediction (possibly at negative net cost).7"}, {"heading": "4. POLICY AND UTILITY UNCERTAINTY", "text": "We now relax two key assumptions underlying our compensation rule from Section 3.1: that E knows DM\u2019s policy, and that DM knows E\u2019s utility function. 7For instance, managers may require forecasts from expert employees under conditions of negative expected cost."}, {"heading": "4.1 Policy Uncertainty", "text": "We first consider the case where DM does not want to disclose its policy to E. For example, suppose DM wanted to forego a truthful compensation rule C and simply rely on a proper scoring rule of the usual form that ignores the E\u2019s inherent utility. Thm. 5 shows that DM cannot prevent misreporting in general if it ignoresE\u2019s inherent utility; hence it can suffer a loss in its own utility. However, by refusing to disclose its policy \u03c0, DM could reduce the incentive for E to misreport. Without accurate knowledge of \u03c0, E would be forced to rely on uncertain beliefs about \u03c0 to determine the utility of a misreport, generally lowering its incentive. However, this will not remove the misreporting incentive completely. For instance, referring to Fig. 2, suppose DM does not disclose \u03c0. If E believes with sufficient probability that the decision boundary between d3 and d1 is located at the point indicated, it will misreport any forecast p in region D3 sufficiently close to that boundary should DM use a scoring rule rather than a compensation rule. As such, refusing to disclose its policy can be used to reduce, but not eliminate, the incentive to misreport if DM does not want to use a proper compensation rule.8\nOur analysis in the previous section assumed thatE used it knowledge of \u03c0 to determine the report that maximizes her net score. However, DM does not need to disclose \u03c0 to make good use of a compensation rule. It can specify a compensation rule implicitly by announcing its net scoring function S(p, xi) (or the cost function G and subgradient G\u2217) and promising to deduct Bd \u00b7 p from this score for whatever decision d it ultimately takes. E need not know in advance what decision will be taken to be incentivized to offer a truthful forecast. Nor does E ever need to know what decisions would have been taken had it reported differently. Thus the only information E needs to learn about \u03c0 is the value of \u03c0(p) at its reported forecast p; and even this need not be revealed until after the decision is taken (and its outcome realized).9"}, {"heading": "4.2 Uncertainty in Expert Utility", "text": "We now consider the more interesting issues that arise when DM is uncertain about the parameters b of E\u2019s utility function. If the DM has a distribution over b, one obvious technique is to specify a proper compensation rule using the expectation of b. This may work reasonably well in practice, depending on the nature of the distribution; but it follows immediately from Thm. 5 that this\n8A similar argument shows that a stochastic policy can be used to reduce misreporting incentive, e.g., the soft max policy that sees DM take decision di with probability proportional to e\u03bbui(p). . 9Some mechanism to verify the decision post hoc may be needed in some circumstances, but this is no different than requiring verification of the realized outcome in standard models of scoring rules.\napproach will not induce truthful reporting in general. Rather than analyzing probabilistic beliefs, we instead suppose that DM has constraints on b that define a bounded feasible region B \u2286 Rmn in which E\u2019s utility parameters must lie. We will confine our analysis to a simple, but natural class of constraints, specifically, upper and lower bounds on each utility parameter; i.e., assume DM has upper and lower bounds bij\u2191 and bij\u2193, respectively, on each bij . This induces a hyper-rectangular feasible region B. If B is a more general region (e.g., a polytope defined by more general linear constraints), our analysis below can be applied to the tightest \u201cbounding box\u201d of the feasible region.10 Again by Thm. 5 it is clear that DM cannot define a proper compensation rule in general: without certain knowledge of E\u2019s utility, any proposed \u201cdeduction\u201d of inherent utility from E\u2019s compensation could mistaken, leading to an incentive to misreport. However, this incentive can be bounded.\nUnder conditions of utility uncertainty, it is natural for DM to restrict its attention to \u201cconsistent\u201d compensation rules:\nDEFINITION 11. Let B be the set of feasible expert utility functions. A compensation rule is consistent with B iff it has the form, for some (strictly) convex G:\nC(p, xi) = G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\u2212 b\u0303i,\u03c0(p) (11)\nfor some b\u0303 \u2208 B.\nNotice that consistent compensation rules are naturally linear: intuitively, we select a single consistent estimate of each parameter b\u0303ij \u2208 [bij\u2193, bij\u2191], treatE as if this were her true (linear) utility function, and define C using this estimate. Let\u2019s say DM is \u03b4-certain of E\u2019s utility iff bij\u2191 \u2212 bij\u2193 \u2264 \u03b4 for all i, j. Then we can bound the incentive for E to misreport as follows:\nTHEOREM 12. If DM is \u03b4-certain ofE\u2019s utility, thenE\u2019s incentive to misreport under any consistent compensation rule is bounded by 2\u03b4. That is, S(r,p)\u2212 S(p,p) \u2264 2\u03b4.\nPROOF. Let p be E\u2019s actual beliefs and r some report.\nS(r,p) = [G(r)\u2212 b\u0303\u03c0(r) + b\u03c0(r)] \u00b7 p \u2264 G(r) \u00b7 p + \u03b4 \u2264 G(p) \u00b7 p + \u03b4\n\u2264 [G(p)\u2212 b\u0303\u03c0(p) + b\u03c0(p) + \u03b4] \u00b7 p + \u03b4 \u2264 S(p,p) + 2\u03b4\n10General linear constraints on E\u2019s parameters could be could be inferred, for example, from observed behavior.\nNotice that the proof assumes that: (a) the estimated utility b\u0303\u03c0(r) for the decision induced by E\u2019s report r underestimates her true utility by \u03b4; and (b) the estimated utility b\u0303\u03c0(p) for the optimal decision overestimates E\u2019s true utility by \u03b4. We can limit the misreporting incentive further by using a uniform compensation rule.\nDEFINITION 13. A consistent compensation rule is uniform if each parameter is estimated by b\u0303i,\u03c0(p) = \u03bbbij\u2193 + (1 \u2212 \u03bb)bij\u2191 for some fixed \u03bb \u2208 [0, 1].\nFor example, if DM uses the lower bound (or midpoint, or upper bound, etc.) of each parameter interval uniformly, we call its compensation rule uniform.\nCOROLLARY 14. If DM is \u03b4-certain of E\u2019s utility, then E\u2019s incentive to misreport under any uniform compensation rule is bounded by \u03b4. That is, S(r,p)\u2212 S(p,p) \u2264 \u03b4.\nWhile bounding the incentive to misreport is somewhat useful, it is more important to understand the impact such misreporting can have on DM. Fortunately, this too can be bounded. The (strict) convexity ofGmeans that the greatest incentive to misreport occurs at the decision boundaries of DM\u2019s policy \u03c0 in Thm. 12. Since, by definition, DM is indifferent between the adjacent decisions at any decision boundary, misreports in a bounded region around decision boundaries have limited impact on DM\u2019s utility, as we now show. Specifically, we show that the amount by which E will misreport is bounded using the \u201cdegree of convexity\u201d of the cost function G, which in turn bounds how much loss in utility DM will realize.\nDEFINITION 15. Let G be a convex cost function with subgradient G\u2217. We say G is robust relative to G\u2217 with factor m > 0 iff, for all p,q \u2208 \u2206(X):11\nG(q) \u2265 G(p) +G\u2217(p) \u00b7 (q\u2212 p) +m||q\u2212 p||2 (12)\nIt is not hard to see that m-robustness of the pair G,G\u2217 imposes a minimum \u201cpenalty\u201d on any expert misreport, as a function of its distance from her true beliefs:\nOBSERVATION 16. LetC be a proper compensation rule based on an m-robust cost function G and subgradient G\u2217. Let S be the induced net scoring function. Then\nS(p,p)\u2212 S(q,p) \u2265 m||q\u2212 p||2.\nTogether with Thm. 12, this gives a bound on the degree to which an expert will misreport when an uncertain DM uses a consistent compensation rule.\nCOROLLARY 17. Let DM be \u03b4-certain of E\u2019s utility and use a consistent compensation rule based on an m-robust cost function and subgradient. Let p be E\u2019s true beliefs. Then the report q that maximizes E\u2019s net score satisfies ||q \u2212 p||2 \u2264 2\u03b4m . If the compensation rule is uniform, then ||q\u2212 p||2 \u2264 \u03b4m .\nIn other words, E\u2019s utility-maximizing report must be within a bounded distance of her true beliefs if DM uses an m-robust cost function to define its compensation rule.\nThe notion of m-robustness is a slight variant of the notion of strong convexity [1] in which we use the specific subgradient G\u2217 to measure the \u201cdegree of convexity.\u201d In the specific case of twice differentiable cost function G, we say G is strongly convex with\n11The definition ofm-robustness can be recast using any reasonable metric, e.g., L1-norm or KL-divergence; but the L2-norm is most convenient below when we relate robustness to strong convexity.\nfactor m iff \u22072G(p) mI for all p \u2208 \u2206(X); i.e., if the matrix \u22072G(p)\u2212mI is positive definite [1].12 m-convexity is a sufficient condition for the robustness we seek.\nCOROLLARY 18. Let DM be \u03b4-certain of E\u2019s utility and use a consistent compensation rule based on an m-convex, twice differentiable cost function G. Let p be E\u2019s true beliefs. Then the report\nq that maximizes E\u2019s net score satisfies ||q \u2212 p||2 \u2264 \u221a\n4\u03b4 m . If the compensation rule is uniform, then ||q\u2212 p||2 \u2264 \u221a\n2\u03b4 m .\nPROOF. G\u2019s assumed differentiability ensures its gradient \u2207G is the unique subgradient. Since G is m-convex, we have\nG(q) \u2265 G(p) +\u2207GT (p)(q\u2212 p) + m 2 ||q\u2212 p||22\nfor all p,q \u2208 \u2206(X) (see [1]). HenceE\u2019s loss in compensation is at least m\n2 ||q\u2212p||22. Since its gain in inherent utility by misreporting\nis bounded by 2\u03b4 (Thm. 12), setting the former to be no greater than 2\u03b4 yields the result. Since the gain in inherent utility under a uniform compensation rule is \u03b4, the stronger bound follows by substituting \u03b4 for 2\u03b4 in the preceding argument.\nRobustness\u2014and strong convexity if we use a differentiable cost function\u2014allow us to globally bound the maximum degree to which E will misreport. This allows us to give a simple, global bound on the loss in DM utility that results from its uncertainty about the expert\u2019s utility function. Recall that DM\u2019s utility function Ui for any decision di is linear, hence has a constant gradient\u2207Ui. (We abuse notation and simply write\u2207Ui for\u2207Ui(p).) The function Ui\u2212Uj is also linear, given by parameter vector (ui \u2212 uj). Let ek denote the n-dimensional unit vector with a 1 in component k and zeros elsewhere.\nTHEOREM 19. Let DM be \u03b4-certain of E\u2019s utility and use a consistent compensation rule based on an m-robust cost function and subgradient. Assume E reports to maximize her net score. Then DM\u2019s loss in utility relative to a truthful report by E is at most maxk[eTk maxi,j \u2207(Ui \u2212 Uj)] \u221a n 2\u03b4 m\n. If the compensation rule is uniform, then the bound is tightened by a factor of two.\nPROOF. By Cor. 17, E\u2019s utility maximizing report q has an L2 distance at most 2\u03b4m from her true beliefs p. By the CauchySchwartz inequality we have ||q \u2212 p||1 \u2264 \u221a n||q \u2212 p||2, hence bounding its max L1-deviation at \u221a n 2\u03b4 m\n. Then DM\u2019s loss for any (utility-maximizing) misreport is:\nud(p) \u00b7 p\u2212 ud(q) \u00b7 p = ud(p) \u00b7 q +\u2207Ud(p)(p\u2212 q)\u2212 ud(q) \u00b7 q\u2212\u2207Ud(q)(p\u2212 q) \u2264 \u2207Ud(p)(p\u2212 q)\u2212\u2207Ud(q)(p\u2212 q) \u2264 \u2207[Ud(p) \u2212 Ud(q)](p\u2212 q) \u2264 max\ni,j \u2207(Ui \u2212 Uj)(p\u2212 q)\n\u2264 max k [eTk max i,j \u2207(Ui \u2212 Uj)]\n\u221a n 2\u03b4\nm .\nHere the first inequality holds by virtue of ud(p) \u00b7 q \u2264 ud(q) \u00b7 q (since ud(q) is DM\u2019s optimal decision at q).\nThe same proof can be adapted to strongly convex cost functions.\n12Alternative definitions exist for non-differentiable G, but we assume a twice differentiable G when discussing strong convexity and use robustness relative to a specific subgradient G\u2217 for nondifferentiable G.\nCOROLLARY 20. Let DM be \u03b4-certain of E\u2019s utility and use a linear compensation rule based on an m-convex, twice differentiable cost function G. Assume E reports to maximize her net score. Then DM\u2019s loss in utility relative to a truthful report by E is\nat most maxk[eTk maxi,j \u2207(Ui\u2212Uj)] \u221a n 4\u03b4 m\n. If the compensation rule is uniform, then the bound is tightened by a factor of two.\nThe results above all rely on the global robustness or global strong convexity of the cost function G. Designing a specific cost function (and if not differentiable, choosing its subgradients) can be challenging if we try to ensure uniform m-robustness or mconvexity across the entire probability space \u2206(X). But recall that E can only impact DM\u2019s utility if its misreport causes DM to change its decision. This means that the cost function need only induce strong penalties for misreporting near decision boundaries. Furthermore, the strength of these penalties should be related to the rate at which DM\u2019s utility is negatively impacted. For example, suppose p lies on the decision boundary between region Di and Dj . If |\u2207(Ui\u2212Uj)| is large, then a misreport in the region around p will cause a greater loss in utility than if |\u2207(Ui \u2212 Uj)| is small. This suggests that the cost function should be more strongly convex (or more robust) near decision boundaries whose corresponding decisions differ significantly in utility, and can be less strong when the decisions are \u201csimilar.\u201d See Fig. 4 for an illustration of this point. Furthermore, the cost function need only be robust or strongly convex in a local region around these decision boundaries. In particular, supposeG ism-robust in some local region around the decision boundary betweenDi andDj . The degree of robustness bounds the maximum deviation from truth that E will contemplate. If the region of m-robustness includes these maximal deviations, that will be sufficient to bound DM\u2019s utility loss for any true beliefsE has in that region. Outside of these regions, no misreport by E will cause DM to change its decisions (relative to a truthful report).\nWe can summarize this as follows:\nDEFINITION 21. G is locally robust relative to G\u2217 in the \u03b5neighborhood around p with factor m > 0 iff, for all q \u2208 \u2206(X)\ns.t. ||q\u2212 p||2 \u2264 \u03b5:\nG(q) \u2265 G(p) +G\u2217(p) \u00b7 (q\u2212 p) +m||q\u2212 p||2 (13)\nLocal strong convexity is defined similarly.\nNow suppose DM wishes to bound its loss due to misreporting by E by some factor \u03c3 > 0. This can be accomplished using a locally robust cost function:\nTHEOREM 22. Let DM be \u03b4-certain of E\u2019s utility and fix \u03c3 > 0. For any pair of decisions di, dj with non-empty decision boundary Dij , define\nmij = maxk(e\nT k\u2207[Ui\u2212Uj ])\n\u221a n2\u03b4\n\u03c3 ; \u03b5ij =\n\u03c3\nmaxk(e T k\u2207[Ui\u2212Uj ])\n\u221a n .\nLetG be a convex cost function with subgradientG\u2217 such that, for all i, j and any p \u2208 Dij , (a) G is locally robust with factor mij in the \u03b5ij-neighborhood around p; (b) no other decision boundary lies within the \u03b5ij-neighborhood around p. Let DM use a consistent compensation rule based onG,G\u2217. Assume E reports to maximize her net score. Then DM\u2019s loss in utility relative to a truthful report by E is at most \u03c3. If the compensation rule is uniform, the result holds with both mij and \u03b5ij decreased by a factor of two.\nPROOF. (Sketch). The proof proceeds by cases involving the location of E\u2019s true beliefs p and the location of possible utilitymaximizing misreports r. W.l.o.g., assume that p is in decision region Di. We consider four classes of misreports.\n(A) Suppose r \u2208 Di. In this case, DM\u2019s utility loss is zero since the decision is the same as if E had reported truthfully.\n(B) Now consider the case where p is in the \u03b5ij-neighborhood of some decision boundary Dij . We show that any report r \u2208 Dj satisfies the condition of the theorem. Let q \u2208 Dj be an arbitrary point s.t. ||q\u2212p||2 \u2264 \u03b5ij (this must exist by the assumption that p lies in the \u03b5ij-neighborhood ofDij). DM\u2019s utility loss for reporting q is then bounded as follows:\nui \u00b7 p\u2212 uj \u00b7 p = ui \u00b7 q +\u2207Ui(p\u2212 q)\u2212 uj \u00b7 q +\u2207Uj(p\u2212 q) \u2264 \u2207[Ui \u2212 Uj ](p\u2212 q)\n\u2264 max k [eTk\u2207(Ui \u2212 Uj)]||p\u2212 q||1\n\u2264 max k\n[eTk\u2207(Ui \u2212 Uj)] \u221a n||p\u2212 q||2\n\u2264 max k\n[eTk\u2207(Ui \u2212 Uj)] \u221a n\u03b5ij\n= \u03c3.\nIf r \u2208 Dj , then it must be such a q (i.e., be within \u03b5ij of p), since any report in Dj has the same inherent utility, while those closest to p maximize compensation. Hence utility loss for r is no greater than \u03c3. Note that p may lie within the \u03b5ij neighborhood of multiple decision boundariesDij adjacent toDi, but the argument holds for any report in any such region Dj .\n(C) Now consider the case where boundary Dij exists, but p does not lie within the \u03b5ij-neighborhood of Dij . We show that E\u2019s utility maximizing report cannot be inDj . By way of contradiction, consider a report r \u2208 Dj . Let ` be the closed line segment {(1 \u2212 \u03bb)p + \u03bbr : \u03bb \u2208 [0, 1]}; and let q \u2208 Dij be the point where ` intersects the decision boundary, and let p\u2032 \u2208 Di be the point on ` on the \u201cDi side\u201d of the boundary that is distance \u03b5ij from the boundary. E\u2019s loss in net score (ignoring any error due inherent\nutility misestimate by DM) is given by:\nS(p,p)\u2212 S(r,p) = Hp \u00b7 p\u2212Hr \u00b7 p = (Hp \u00b7p\u2212Hp\u2032 \u00b7p) + (Hp\u2032 \u00b7p\u2212Hq \u00b7p) + (Hq \u00b7p\u2212Hr \u00b7p)\nWe have (Hp \u00b7p\u2212Hp\u2032 \u00b7p) \u2265 0 by the propriety of the compensation rule (ignoring error due to inherent utility misestimation). We also have\nHp\u2032 \u00b7 p\u2212Hq \u00b7 p = Hp\u2032 \u00b7 (p\u2212 p\u2032 + p\u2032)\u2212Hq \u00b7 (p\u2212 p\u2032 + p\u2032) = Hp\u2032 \u00b7 p\u2032 \u2212Hq \u00b7 p\u2032 +Hp\u2032 \u00b7 (p\u2212 p\u2032)\u2212Hq \u00b7 (p\u2212 p\u2032) \u2265 mij\u03b5ij +Hp\u2032 \u00b7 (p\u2212 p\u2032)\u2212Hq \u00b7 (p\u2212 p\u2032) \u2265 mij\u03b5ij \u2265 2\u03b4\nwhere the first inequality holds due to the local robustness of G and the second due to the convexity of G and the collinearity of (p,p\u2032,q). Finally, we must have (Hq \u00b7 p \u2212 Hr \u00b7 p) \u2265 0 again due to the convexity of G and the collinearity of (p,q, r). Thus E\u2019s loss in compensation due to misreporting is at least 2\u03b4 (and is strictly greater if G is strictly convex). But by Thm. 12 its gain in inherent utility by misreporting can be no greater than 2\u03b4. Hence its optimal report r cannot lie in Dj .\n(D) The preceding argument can be adapted in a straightforward way to the case where Di and Dj are not adjacent (i.e., Dij is empty).\nThis result can be generalized to the case where the degree of robustness around one decision boundary is relaxed sufficiently so that the neighborhood within which E can profitably misreport crosses more than one decision boundary (i.e., when another decision boundary overlaps the \u03b5ij-neighborhood around Dij). Utility loss will increase but is can be bounded by considering the maximum gradient\u2207(Ui\u2212Uj) over decisions that can be swapped. The result can also be adapted to locally strongly convex cost functions in the obvious way.\nCOROLLARY 23. Let DM be \u03b4-certain of E\u2019s utility and fix \u03c3 > 0. For any pair of decisions di, dj with non-empty decision boundary Dij , define\nmij = maxk(e\nT k\u2207[Ui\u2212Uj ])\n\u221a n2\u03b4\n\u03c3 ; \u03b5ij =\n\u03c3\nmaxk(e T k\u2207[Ui\u2212Uj ])\n\u221a n .\nLet G be a convex cost function such that, for all i, j and any p \u2208 Dij , (a) G is locally convex with factor mij in the \u03b5ijneighborhood around p; (b) no other decision boundary lies within the \u03b5ij-neighborhood around p. Let DM use a consistent compensation rule based on G,G\u2217. Assume E reports to maximize her net score. Then DM\u2019s loss in utility relative to a truthful report by E is at most \u03c3.\nThese results quantify the \u201ccost\u201d to the decision maker of its imprecise knowledge of the expert\u2019s utility function, i.e., its worst-case expected utility relative to what it could have achieved if it had full knowledge of E\u2019s utility (i.e., with truthful reporting by E).\nREMARK 24. If we relax the constraint that DM choose the decision di with maximum expected utility, we can exploit local robustness to induce truthful forecasts. Suppose DM uses the softmax decision policy (see footnote 8): this stochastic policy makes E\u2019s utility B\u03c0(r,p) continuous in its report r. An analysis similar to that above, using local robustness or strong convexity of the cost\nfunction, allows DM to induce truthtelling as long as the degree of convexity compensates for the gradient of B\u03c0 at decision boundaries. Since adding randomness to the policy removes the discontinuities in B\u03c0 , this is now possible. Of course, this \u201cincentivecompatibility\u201d comes at a cost: the DM is committed to taking suboptimal actions with some probability. We defer a full analysis of the tradeoffs, and the relative benefits of \u201cacting optimally\u201d but risking misleading reports vs. \u201cacting suboptimally\u201d relative to truthful report, to a longer version of this paper.\nThe characterization of DM loss using local robustness or local strong convexity not only offers theoretical guarantees on DM utility\u2014it has potential operation significance in the design of compensation rules. Specifically, it suggests an optimization procedure for designing a cost function G\u2014from which the induced compensation rule C is recovered\u2014so as to minimize DM utility loss. Intuitively, the design ofG will attempt to optimize two conflicting objectives: minimizing the bound \u03c3 on utility loss, which generally requires increasing the degree of robustness or convexity of G at decision boundaries; and minimizing expected compensation c which, given the requirement of strict convexity of G, generally requires decreasing robustness or convexity. This tension can be addressed by either: (a) explicitly trading \u03c3 and c off against each other in the design objective; (b) minimizing c subject to a target bound \u03c3; or (c) minimizing \u03c3 subject to a target compensation level c. The optimization itself is defined over the space of n-dimensional convex curves G, and could be treated as an ndimensional spline problem. The objective is to fit a convex function to a set of points with specific local curvature constraints that enforce a certain degree of local convexity at particular decision boundaries. Specific classes of spline functions (e.g., Catmull-Rom splines) might prove useful for this purpose. We leave to future research the question of the practical design of cost and compensation functions under conditions of utility uncertainty."}, {"heading": "5. MARKET SCORING RULES", "text": "Space precludes a comprehensive treatment, but we provide a brief sketch of how one might exploit compensation functions in settings where DM aggregates the forecasts of multiple experts. One natural means of doing so is to develop a market scoring rule (MSR) [9, 11] that sequentially applies a standard scoring rule based on how an expert alters the prior forecast (see Sec. 2). The typical means of creating an MSR given a scoring rule S is to have the kth expert (implicitly) pay the k\u22121st expert for its forecast according to S, and have the principal pay only final expert for its forecast using S. In this way, the principal\u2019s total payment is bounded by the maximal possible payment to a single expert [11].\nWhen one attempts this with self-interested experts, difficulties emerge. For instance, Shi et al. [15] show that experts who can alter the outcome distribution after making a forecast, each require compensation to prevent them from manipulating the distribution in ways that are detrimental to the principal.13 A related form of subsidy arises in our decision setting.\nFollowing [15], we assume a collection of n experts, each of whom can provide alter the forecast p exactly once. Suppose the experts have an interest in DM\u2019s decision. An \u201cobvious\u201d MSR in our model would simply adopt a proper compensation rule, and have each expert pay the either the compensation or the net score due to the expert who provided the incumbent forecast, and receive her payment from the next expert. If we use compensation, we run into strategic issues. With a proper compensation rule, an expert\n13Shi et al. [15] actually use a one-round variant of an MSR.\nk reports truthfully based on her net score (total utility), consisting of both compensation and the inherent utility of the decision she induces. In a market setting, k\u2019s proposed decision may be changed by the next expert that provides a forecast. This (depending on her beliefs about other expert opinions) may incentivize k to misreport in order to maximize her compensation rather than her net score. Overcoming such strategic issues seems challenging.\nAlternatively, each expert might pay the net score due her predecessor. Unfortunately, an arbitrary proper compensation rule may not pay expert k enough score to \u201ccover her costs\u201d (e.g., if k\u22121\u2019s inherent utility is much higher than k\u2019s). However, if we set aside issues associated with incentive for participation for the moment, the usual MSR approach can be adapted as follows: we fix a single (strictly) convex cost function G for all experts, and define the compensation rule Ck for expert k using G in the usual way:\nCk(p, xi) = G(p)\u2212G\u2217(p) \u00b7 p +G\u2217i (p)\u2212 bki,\u03c0(p),\nwhere bk is k\u2019s utility function (bias). If G satisfies strong participation for all experts (i.e., if G(xi) \u2265 B\u2217(xi) for all i), then any expert k whose beliefs p[k] differ from the forecast p[k\u22121] provided by k\u22121 will have an expected net score (given p[k]) greater than her expected payment to k\u22121 and will maximize her utility by providing a truthful forecast. In particular, let\u2019s denote k\u2019s expected payment to k\u22121 by \u03c1(k, k\u22121); then we have:\n\u03c1(k, k\u22121) = (Hp[k\u22121] \u2212 bk\u22121\u03c0(p[k\u22121])) \u00b7 p[k] + b k\u22121 \u03c0(p[k\u22121]) \u00b7 p[k]\n= Hp[k\u22121] \u00b7 p[k] \u2264 Hp[k] \u00b7 p[k].\nHence k\u2019s expected payment \u03c1(k, k\u22121) is less than its expected net utility, leaving it with a (positive) net gain of (Hp[k] \u2212 Hp[k\u22121]) \u00b7 p[k]. However, this gain may be smaller than the inherent utility she derives from the decision induced by k\u22121, namely, bk\u03c0(p[k\u22121]) \u00b7 p[k]. Hence this scheme may not incentivize participation. In cases where DM can force participation, such a scheme can be used; but in general, the self-subsidizing nature of standard MSRs cannot be exploited with self-interested experts.14\nTo incentivize participation, DM can subsidize these payments. In the most extreme case, DM simply pays each displaced expert its net utility, which removes any incentives to misreport, but at potentially high cost. In certain circumstances, we can reduce the DM subsidy to the market by having it pay only the inherent utility bk\u22121i,\u03c0(p[k\u22121]) (given realized outcome xi) of the displaced expert k\u22121, and requiring the displacing expert k to pay the compensation Hi,p[k\u22121]. Under certain conditions on the relative utility of different experts for different decisions, this is sufficient to induce participation; that is, k\u2019s net gain for partipating exceeds her inherent utility for the incumbent decision.\nFor instance, suppose all experts have the same utility function b (e.g., consider experts in the same division of a company who are asked to predict the outcome of some event, and have different estimates, but have aligned interests in other respects). In this case,\n14If expert utility is small relative to overall compensation, we can exploit the strong robustness (or strong convexity) of the cost function to show that experts will abstain from offering predictions only if their beliefs are sufficiently close to the incumbent prediction. Providing the degree of compensation induced by an \u201cextremely convex\u201d cost function can, of course, be interpreted as a form of subsidy.\nk\u2019s net gain for reporting her true beliefs is:\n(Hp[k] \u2212 (Hp[k\u22121] \u2212 b\u03c0(p[k\u22121]))) \u00b7 p[k] = (Hp[k] \u2212Hp[k\u22121]) \u00b7 p[k] + b\u03c0(p[k\u22121]) \u00b7 p[k] \u2265 b\u03c0(p[k\u22121]) \u00b7 p[k].\nHence k\u2019s expected net gain is at least as great as her inherent expected utility for the decision induced by k\u22121, and strictly greater if her beliefs differ from those of k\u22121. Thus participation is assured.\nIndeed, the argument holds even if the utility functions are not identical: we require only that k\u2019s expected utility for the decision it displaces is less than the expected utility (given k\u2019s beliefs) to be offered to her predecessor k\u22121. A sufficient condition for this is that bk \u2264 bk\u22121 (pointwise). This suggests that if the DM can elicit predictions of its experts in a particular order, it should do so by eliciting forecasts of those with the greatest utility first.\nIn general, even in the extreme case of identical expert utility functions, there seems to be no escape from the requirement that DM subsidize the market, at a level that grows linearly with the number of agents. This is very similar to the conclusions drawn by Shi et al. [15]. We provide a more detailed formalization and analysis in an extended version of the paper."}, {"heading": "6. CONCLUDING REMARKS", "text": "We have presented a model that allows the analysis of the incentives facing experts in a decision-making context who have a vested interest in the decision taken by the principal. We have developed a class of compensation rules that are necessary and sufficient to induce truthful forecasts from self-interested experts and also characterized the subclasses of such rules that satisfy weak and strong participation constraints. While vanilla compensation rules assume knowledge of the expert\u2019s utility function on the part of the principal, we\u2019ve also shown how to design compensation rules when the principal has only rough bounds on expert utility parameters in such a way that (a) the incentive for the expert to misreport is bounded; and (b) the impact on the principal\u2019s decision/utility is similarly bounded relative to the case of full knowledge. These bounds are derived from the robustness or strong convexity of the cost function, in either a global or a local sense.\nA number of other interesting directions remain. One is the development of computationally effective procedures to design cost functions that minimize principal utility loss in settings where expert utility is not fully known, without inducing extreme degrees of compensation. Another direction is the analysis of the tradeoff between the principal\u2019s decision space and the payments required to induce truthfulness or participation on the part of experts. We discussed above the possibility that by acting (somewhat) suboptimally through the use of a stochastic policy, the principal could diminish the incentive for the expert to misreport. We can take this a step further: intuitively, by limiting its policy to use only a subset of its potential decisions, the principal may dramatically reduce the potential for strategic behavior\u2014either misreporting or failure to participate\u2014on the part of an expert, while at the same time, doing little damage its own utility by restricting its policy in this way.15\nFinally, the question of joint elicitation both the utility function and the forecast of an expert remains intriguing. This can be viewed as a mechanism design problem where the expert\u2019s type consists of both its preferences and its \u201cinformation\u201d or forecast (see [6] for a treatment of forecasts themselves from a mechanism design perspective). Preliminary results (joint with Tuomas Sandholm) sug-\n15Thanks to Tuomas Sandholm for suggesting this and preliminary discussion in this direction.\ngest, not surprisingly, that truthful elicitation is not generally possible when the principal takes a decision that maximizes its expected utility. However, it remains to be seen if effective mechanisms can be designed that offer \u201creasonable\u201d performance from the perspective of the principal."}, {"heading": "Acknowledgements", "text": "Thanks to Yiling Chen, Vince Conitzer, Ian Kash, Tuomas Sandholm and Jenn Wortman Vaughan for helpful discussions and suggestions. This work was supported by NSERC."}, {"heading": "7. REFERENCES", "text": "[1] S. Boyd and L. Vandenberghe. Convex Optimization.\nCambridge University Press, Cambridge, 2004. [2] G. W. Brier. Verification of forecasts expressed in terms of\nprobability. Monthly Weather Review, 78(1):1\u20133, 1950. [3] Y. Chen and I. Kash. Information elicitation for decision\nmaking. In Proceedings of the Tenth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-11), Taipei, 2011. to appear.\n[4] Y. Chen and D. Pennock. A utility framework for bounded-loss market makers. In Proceedings of the Twenty-third Conference on Uncertainty in Artificial Intelligence (UAI-07), pages 49\u201356, Vancouver, 2007.\n[5] Y. Chen and D. Pennock. Prediction markets. AI Magazine, 31(4):42\u201352, 2011.\n[6] V. Conitzer. Prediction markets, mechanism design, and cooperative game theory. In Proceedings of the Twenty-fifth Conference on Uncertainty in Artificial Intelligence (UAI-09), pages 101\u2013108, Montreal, 2009.\n[7] S. Dimitrov and R. Sami. Non-myopic strategies in prediction markets. In Proceedings of the Ninth ACM Conference on Electronic Commerce (EC\u201908), pages 200\u2013209, Chicago, 2008.\n[8] T. Gneiting and A. E. Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359\u2013378, 2007.\n[9] R. Hanson. Combinatorial information market design. Information Systems Frontiers, 5(1):107\u2013119, 2003.\n[10] R. Hanson. Decision markets. IEEE Intelligent Systems, 14(3):16\u201319, 1997.\n[11] R. Hanson. Logarithmic market scoring rules for modular combinatorial information aggregation. Journal of Prediction Markets, 1(1):3\u201315, 2007.\n[12] J. McCarthy. Measures of the value of information. Proceedings of the National Academy of Sciences, 42(9):654\u2013655, 1956.\n[13] A. Othman and T. Sandholm. Decision rules and decision markets. In Proceedings of the Ninth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-10), pages 625\u2013632, Toronto, 2010.\n[14] L. J. Savage. Elicitation of personal probabilities and expectations. Journal of the American Statistical Association, 66(336):783\u2013801, 1971.\n[15] P. Shi, V. Conitzer, and M. Guo. Prediction mechanisms that do not incentivize undesirable actions. In Proceedings of the Fifth Workshop on Internet and Network Economics (WINE-09), pages 89\u2013100, Rome, 2009.\n[16] J. Wolfers and E. Zitzewitz. Prediction markets. Journal of Economic Perspectives, 18(2):107\u2013126, 2004."}], "references": [{"title": "Convex Optimization", "author": ["S. Boyd", "L. Vandenberghe"], "venue": "Cambridge University Press, Cambridge", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2004}, {"title": "Verification of forecasts expressed in terms of probability", "author": ["G.W. Brier"], "venue": "Monthly Weather Review, 78(1):1\u20133", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1950}, {"title": "Information elicitation for decision making", "author": ["Y. Chen", "I. Kash"], "venue": "Proceedings of the Tenth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-11), Taipei", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "A utility framework for bounded-loss market makers", "author": ["Y. Chen", "D. Pennock"], "venue": "Proceedings of the Twenty-third Conference on Uncertainty in Artificial Intelligence (UAI-07), pages 49\u201356, Vancouver", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Prediction markets", "author": ["Y. Chen", "D. Pennock"], "venue": "AI Magazine, 31(4):42\u201352", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Prediction markets", "author": ["V. Conitzer"], "venue": "mechanism design, and cooperative game theory. In Proceedings of the Twenty-fifth Conference on Uncertainty in Artificial Intelligence (UAI-09), pages 101\u2013108, Montreal", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Non-myopic strategies in prediction markets", "author": ["S. Dimitrov", "R. Sami"], "venue": "Proceedings of the Ninth ACM Conference on Electronic Commerce (EC\u201908), pages 200\u2013209, Chicago", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Strictly proper scoring rules", "author": ["T. Gneiting", "A.E. Raftery"], "venue": "prediction, and estimation. Journal of the American Statistical Association, 102(477):359\u2013378", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Combinatorial information market design", "author": ["R. Hanson"], "venue": "Information Systems Frontiers, 5(1):107\u2013119", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Decision markets", "author": ["R. Hanson"], "venue": "IEEE Intelligent Systems, 14(3):16\u201319", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1997}, {"title": "Logarithmic market scoring rules for modular combinatorial information aggregation", "author": ["R. Hanson"], "venue": "Journal of Prediction Markets, 1(1):3\u201315", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Measures of the value of information", "author": ["J. McCarthy"], "venue": "Proceedings of the National Academy of Sciences, 42(9):654\u2013655", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1956}, {"title": "Decision rules and decision markets", "author": ["A. Othman", "T. Sandholm"], "venue": "Proceedings of the Ninth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-10), pages 625\u2013632, Toronto", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Elicitation of personal probabilities and expectations", "author": ["L.J. Savage"], "venue": "Journal of the American Statistical Association, 66(336):783\u2013801", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1971}, {"title": "Prediction mechanisms that do not incentivize undesirable actions", "author": ["P. Shi", "V. Conitzer", "M. Guo"], "venue": "Proceedings of the Fifth Workshop on Internet and Network Economics (WINE-09), pages 89\u2013100, Rome", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Prediction markets", "author": ["J. Wolfers", "E. Zitzewitz"], "venue": "Journal of Economic Perspectives, 18(2):107\u2013126", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}], "referenceMentions": [{"referenceID": 15, "context": "Eliciting predictions of uncertain events from experts or other knowledgeable agents\u2014or relevant information pertaining to events\u2014 is a fundamental problem of study in statistics, economics, operations research, artificial intelligence and a variety of other areas [16, 5].", "startOffset": 265, "endOffset": 272}, {"referenceID": 4, "context": "Eliciting predictions of uncertain events from experts or other knowledgeable agents\u2014or relevant information pertaining to events\u2014 is a fundamental problem of study in statistics, economics, operations research, artificial intelligence and a variety of other areas [16, 5].", "startOffset": 265, "endOffset": 272}, {"referenceID": 14, "context": ", [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put.", "startOffset": 2, "endOffset": 16}, {"referenceID": 12, "context": ", [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put.", "startOffset": 2, "endOffset": 16}, {"referenceID": 2, "context": ", [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put.", "startOffset": 2, "endOffset": 16}, {"referenceID": 6, "context": ", [15, 13, 3, 7], most work fails to account for the ultimate use to which the forecast will be put.", "startOffset": 2, "endOffset": 16}, {"referenceID": 9, "context": "Setting aside purely informational and entertainment uses of information markets, the principal is often interested in exploiting the elicited forecast in order to make a decision [10, 13, 3].", "startOffset": 180, "endOffset": 191}, {"referenceID": 12, "context": "Setting aside purely informational and entertainment uses of information markets, the principal is often interested in exploiting the elicited forecast in order to make a decision [10, 13, 3].", "startOffset": 180, "endOffset": 191}, {"referenceID": 2, "context": "Setting aside purely informational and entertainment uses of information markets, the principal is often interested in exploiting the elicited forecast in order to make a decision [10, 13, 3].", "startOffset": 180, "endOffset": 191}, {"referenceID": 12, "context": "Providing appropriate incentives in the form of scoring rules is often difficult in such settings, especially when the outcome distribution is conditional on the decision ultimately taken by the principal [13, 3].", "startOffset": 205, "endOffset": 212}, {"referenceID": 2, "context": "Providing appropriate incentives in the form of scoring rules is often difficult in such settings, especially when the outcome distribution is conditional on the decision ultimately taken by the principal [13, 3].", "startOffset": 205, "endOffset": 212}, {"referenceID": 9, "context": "Hanson [10] introduced the term decision markets to refer to the broad notion of prediction markets where experts offer forecasts for events conditional on some policy being adopted or a decision being taken.", "startOffset": 7, "endOffset": 11}, {"referenceID": 12, "context": "Othman and Sandholm [13] provide the first explicit, formal treatment of a principal who makes decisions based on expert forecasts.", "startOffset": 20, "endOffset": 24}, {"referenceID": 2, "context": "Chen and Kash [3] extend this model to a wider class of informational settings and decision policies.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "Dimitrov and Sami [7] consider the ar X iv :1 10 6.", "startOffset": 18, "endOffset": 21}, {"referenceID": 5, "context": "Similarly, Conitzer [6] explores strategic aspects of prediction markets through their connections to mechanism design.", "startOffset": 20, "endOffset": 23}, {"referenceID": 14, "context": "[15], who consider experts that, once they report their forecasts, can take action to alter the probabilities of the outcomes in question.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "For comprehensive overviews, see the surveys [16, 5].", "startOffset": 45, "endOffset": 52}, {"referenceID": 4, "context": "For comprehensive overviews, see the surveys [16, 5].", "startOffset": 45, "endOffset": 52}, {"referenceID": 1, "context": "A variety of scoring rules have been developed for just this purpose [2, 14, 12, 8].", "startOffset": 69, "endOffset": 83}, {"referenceID": 13, "context": "A variety of scoring rules have been developed for just this purpose [2, 14, 12, 8].", "startOffset": 69, "endOffset": 83}, {"referenceID": 11, "context": "A variety of scoring rules have been developed for just this purpose [2, 14, 12, 8].", "startOffset": 69, "endOffset": 83}, {"referenceID": 7, "context": "A variety of scoring rules have been developed for just this purpose [2, 14, 12, 8].", "startOffset": 69, "endOffset": 83}, {"referenceID": 1, "context": "A scoring rule is a function S : \u2206(X) \u00d7 X \u2192 R that provides a score (or payoff) S(r, xi) to E if she reports forecast r and the realized outcome of X is xi, essentially rewarding E for her predictive \u201cperformance\u201d [2, 12].", "startOffset": 214, "endOffset": 221}, {"referenceID": 11, "context": "A scoring rule is a function S : \u2206(X) \u00d7 X \u2192 R that provides a score (or payoff) S(r, xi) to E if she reports forecast r and the realized outcome of X is xi, essentially rewarding E for her predictive \u201cperformance\u201d [2, 12].", "startOffset": 214, "endOffset": 221}, {"referenceID": 11, "context": "A variety of strictly proper scoring rules have been developed, among the more popular being the log scoring rule, where S(p, xi) = a log pi + bi (for arbitrary constants a > 0 and bi) [12, 14].", "startOffset": 185, "endOffset": 193}, {"referenceID": 13, "context": "A variety of strictly proper scoring rules have been developed, among the more popular being the log scoring rule, where S(p, xi) = a log pi + bi (for arbitrary constants a > 0 and bi) [12, 14].", "startOffset": 185, "endOffset": 193}, {"referenceID": 11, "context": "Proper scoring rules can be fully characterized in terms of convex cost functions [12, 14]; here we review the formulation of Gneiting and Raftery [8].", "startOffset": 82, "endOffset": 90}, {"referenceID": 13, "context": "Proper scoring rules can be fully characterized in terms of convex cost functions [12, 14]; here we review the formulation of Gneiting and Raftery [8].", "startOffset": 82, "endOffset": 90}, {"referenceID": 7, "context": "Proper scoring rules can be fully characterized in terms of convex cost functions [12, 14]; here we review the formulation of Gneiting and Raftery [8].", "startOffset": 147, "endOffset": 150}, {"referenceID": 11, "context": "[12, 14, 8] A regular scoring rule S is proper iff", "startOffset": 0, "endOffset": 11}, {"referenceID": 13, "context": "[12, 14, 8] A regular scoring rule S is proper iff", "startOffset": 0, "endOffset": 11}, {"referenceID": 7, "context": "[12, 14, 8] A regular scoring rule S is proper iff", "startOffset": 0, "endOffset": 11}, {"referenceID": 15, "context": "There are a number of prediction market mechanisms that allow the principal to extract information from multiple experts; see [16, 5] for excellent surveys.", "startOffset": 126, "endOffset": 133}, {"referenceID": 4, "context": "There are a number of prediction market mechanisms that allow the principal to extract information from multiple experts; see [16, 5] for excellent surveys.", "startOffset": 126, "endOffset": 133}, {"referenceID": 8, "context": "Here we focus on market scoring rules (MSRs) [9, 11], which allow experts to (sequentially) change the forecasted p using any proper scoring rule S.", "startOffset": 45, "endOffset": 52}, {"referenceID": 10, "context": "Here we focus on market scoring rules (MSRs) [9, 11], which allow experts to (sequentially) change the forecasted p using any proper scoring rule S.", "startOffset": 45, "endOffset": 52}, {"referenceID": 3, "context": "Under certain conditions, MSRs can be interpreted as automated market makers [4].", "startOffset": 77, "endOffset": 80}, {"referenceID": 12, "context": "We note that this model of DM utility is slightly more restricted than that of [13, 3], who allow the utility of each decision to depend on a different random variable, and assume that the realization of a variable will be observed only if the corresponding decision is taken.", "startOffset": 79, "endOffset": 86}, {"referenceID": 2, "context": "We note that this model of DM utility is slightly more restricted than that of [13, 3], who allow the utility of each decision to depend on a different random variable, and assume that the realization of a variable will be observed only if the corresponding decision is taken.", "startOffset": 79, "endOffset": 86}, {"referenceID": 5, "context": "This introduces difficulties in offering suitable incentives for participation that do not arise in our setting; indeed, the primary contribution of Othman and Sandholm [6], and the extension by Chen and Kash [3], is a characterization of a form of proper scoring in the face of these complications.", "startOffset": 169, "endOffset": 172}, {"referenceID": 2, "context": "This introduces difficulties in offering suitable incentives for participation that do not arise in our setting; indeed, the primary contribution of Othman and Sandholm [6], and the extension by Chen and Kash [3], is a characterization of a form of proper scoring in the face of these complications.", "startOffset": 209, "endOffset": 212}, {"referenceID": 12, "context": "We also confine our attention primarily to a principal that maximizes its expected utility given E\u2019s report (in the terminology of [13], DM uses the max decision rule), though we remark on the possible use of stochastic policies by DM in Sec.", "startOffset": 131, "endOffset": 135}, {"referenceID": 6, "context": "See Dimitrov and Sami [7] and Conitzer [6] for just such a gametheoretic treatment of prediction markets (without decisions).", "startOffset": 22, "endOffset": 25}, {"referenceID": 5, "context": "See Dimitrov and Sami [7] and Conitzer [6] for just such a gametheoretic treatment of prediction markets (without decisions).", "startOffset": 39, "endOffset": 42}, {"referenceID": 0, "context": "A consistent compensation rule is uniform if each parameter is estimated by b\u0303i,\u03c0(p) = \u03bbbij\u2193 + (1 \u2212 \u03bb)bij\u2191 for some fixed \u03bb \u2208 [0, 1].", "startOffset": 126, "endOffset": 132}, {"referenceID": 0, "context": "The notion of m-robustness is a slight variant of the notion of strong convexity [1] in which we use the specific subgradient G\u2217 to measure the \u201cdegree of convexity.", "startOffset": 81, "endOffset": 84}, {"referenceID": 0, "context": ", if the matrix \u2207G(p)\u2212mI is positive definite [1].", "startOffset": 46, "endOffset": 49}, {"referenceID": 0, "context": "for all p,q \u2208 \u2206(X) (see [1]).", "startOffset": 24, "endOffset": 27}, {"referenceID": 0, "context": "Let ` be the closed line segment {(1 \u2212 \u03bb)p + \u03bbr : \u03bb \u2208 [0, 1]}; and let q \u2208 Dij be the point where ` intersects the decision boundary, and let p\u2032 \u2208 Di be the point on ` on the \u201cDi side\u201d of the boundary that is distance \u03b5ij from the boundary.", "startOffset": 54, "endOffset": 60}, {"referenceID": 8, "context": "One natural means of doing so is to develop a market scoring rule (MSR) [9, 11] that sequentially applies a standard scoring rule based on how an expert alters the prior forecast (see Sec.", "startOffset": 72, "endOffset": 79}, {"referenceID": 10, "context": "One natural means of doing so is to develop a market scoring rule (MSR) [9, 11] that sequentially applies a standard scoring rule based on how an expert alters the prior forecast (see Sec.", "startOffset": 72, "endOffset": 79}, {"referenceID": 10, "context": "In this way, the principal\u2019s total payment is bounded by the maximal possible payment to a single expert [11].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "[15] show that experts who can alter the outcome distribution after making a forecast, each require compensation to prevent them from manipulating the distribution in ways that are detrimental to the principal.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Following [15], we assume a collection of n experts, each of whom can provide alter the forecast p exactly once.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "[15] actually use a one-round variant of an MSR.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "This can be viewed as a mechanism design problem where the expert\u2019s type consists of both its preferences and its \u201cinformation\u201d or forecast (see [6] for a treatment of forecasts themselves from a mechanism design perspective).", "startOffset": 145, "endOffset": 148}], "year": 2011, "abstractText": "Scoring rules for eliciting expert predictions of random variables are usually developed assuming that experts derive utility only from the quality of their predictions (e.g., score awarded by the rule, or payoff in a prediction market). We study a more realistic setting in which (a) the principal is a decision maker and will take a decision based on the expert\u2019s prediction; and (b) the expert has an inherent interest in the decision. For example, in a corporate decision market, the expert may derive different levels of utility from the actions taken by her manager. As a consequence the expert will usually have an incentive to misreport her forecast to influence the choice of the decision maker if typical scoring rules are used. We develop a general model for this setting and introduce the concept of a compensation rule. When combined with the expert\u2019s inherent utility for decisions, a compensation rule induces a net scoring rule that behaves like a normal scoring rule. Assuming full knowledge of expert utility, we provide a complete characterization of all (strictly) proper compensation rules. We then analyze the situation where the expert\u2019s utility function is not fully known to the decision maker. We show bounds on: (a) expert incentive to misreport; (b) the degree to which an expert will misreport; and (c) decision maker loss in utility due to such uncertainty. These bounds depend in natural ways on the degree of uncertainty, the local degree of convexity of net scoring function, and natural properties of the decision maker\u2019s utility function. They also suggest optimization procedures for the design of compensation rules. Finally, we briefly discuss the use of compensation rules as market scoring rules for self-interested experts in a prediction market.", "creator": "LaTeX with hyperref package"}}}