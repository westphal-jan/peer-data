{"id": "1202.4828", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Feb-2012", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "abstract": "Computer - namesakes supported learning is an diemens increasingly guayaquil important gruban form of saariaho study since it allows for independent bjork learning bandmembers and individualized instruction. biser In this schilling paper, reinstituted we hasslacher discuss a novel daubing approach waqf to eppy developing an 46.26 intelligent biharis tutoring system for teaching textbook - style mutsuko mathematical proofs. mustered We characterize tbl the hypokalemia particularities of the domain n'daw and discuss pide common chazov ITS sadosky design coms models. abdelghani Our approach 3/9 is motivated by guanghui phenomena chlorofluorocarbons found rakoczi in genseric a almeria corpus of tutorial calamine dialogs kub\u014d that andrx were n\u00f6dtveidt collected in idiosyncrasies a Wizard - of - 14:00 Oz experiment. broederbond We cryptanalytic show how an seagull intelligent spiderbait tutor for condra textbook - treasurer style terminos mathematical proofs can stroll be hoarders built sanjiv on stenhammar top of an marceta adapted dega assertion - kyoko level proof assistant by reusing krivyi representations and 139.4 proof miroslav search strategies dolarhyde originally biparental developed danebury for kiszla automated and 38.35 interactive theorem 1-gallon proving. The papae resulting prototype irish-catholic was successfully ordering evaluated bilek on a hybridised corpus of kreiger tutorial dialogs ahuachap\u00e1n and yields organda good rathores results.", "histories": [["v1", "Wed, 22 Feb 2012 06:41:20 GMT  (67kb)", "http://arxiv.org/abs/1202.4828v1", "In Proceedings THedu'11,arXiv:1202.4535"]], "COMMENTS": "In Proceedings THedu'11,arXiv:1202.4535", "reviews": [], "SUBJECTS": "cs.AI cs.LO cs.MS cs.SC", "authors": ["serge autexier", "bremen", "germany)", "dominik dietrich", "bremen", "germany)", "marvin schiller"], "accepted": false, "id": "1202.4828"}, "pdf": {"name": "1202.4828.pdf", "metadata": {"source": "CRF", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "authors": ["Serge Autexier", "Dominik Dietrich", "Marvin Schiller"], "emails": ["Serge.Autexier@dfki.de", "Dominik.Dietrich@dfki.de", "Marvin.Schiller@brunel.ac.uk"], "sections": [{"heading": null, "text": "P. Quaresma and R.-J. Back (Eds.); THedu\u201911 EPTCS 79, 2012, pp. 1\u201328, doi:10.4204/EPTCS.79.1\nc\u00a9 Autexier, Dietrich, Schiller This work is licensed under the Creative Commons Attribution License.\nTowards an Intelligent Tutor for Mathematical Proofs\nSerge Autexier Dominik Dietrich German Research Center for Artificial\nIntelligence (DFKI), Bremen, Germany\nSerge.Autexier@dfki.de Dominik.Dietrich@dfki.de\nMarvin Schiller Brunel University, London, UK\nMarvin.Schiller@brunel.ac.uk\nComputer-supported learning is an increasingly important form of study since it allows for independent learning and individualized instruction. In this paper, we discuss a novel approach to developing an intelligent tutoring system for teaching textbook-style mathematical proofs. We characterize the particularities of the domain and discuss common ITS design models. Our approach is motivated by phenomena found in a corpus of tutorial dialogs that were collected in a Wizard-of-Oz experiment. We show how an intelligent tutor for textbook-style mathematical proofs can be built on top of an adapted assertion-level proof assistant by reusing representations and proof search strategies originally developed for automated and interactive theorem proving. The resulting prototype was successfully evaluated on a corpus of tutorial dialogs and yields good results."}, {"heading": "1 Introduction", "text": "Computer-supported learning is an increasingly important form of study since it allows for independent learning and individualized instruction and has resulted in many tutoring systems for different domains. Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few). However, teaching and tutoring support on the ability of how to do proofs is underdeveloped in state of the art e-learning systems. Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]). The overall goal of the work presented in this paper is to provide e-learning support for classical textbook-style proofs, which is not fostered by the above approaches.\nFollowing Van Lehn (see [69]), intelligent tutoring systems (ITSs) can be characterized as having both an outer loop and an inner loop. The outer loop selects a relevant task (exercise) for the student to complete. The inner loop iterates over individual problem-solving steps, evaluates the steps and provides feedback to the student. Typically, this is achieved by providing the following services: (S1) minimal feedback on a step, (S2) error specific feedback on an incorrect step, (S3) hints on the next step, (S4) assessment of knowledge, and (S5) review of the solution.\nIn this paper we focus on the inner loop and report on how we adapted the proof assistant system \u2126mega to realize the services (S1), (S2), (S3) and a bit of (S5). The services are provided by two components, one for step analysis, and one for step generation. The step analyzer produces minimal feedback on a student\u2019s proof step, such as whether the step is correct or not, together with additional information that might be used to provide more sophisticated feedback, e.g., if a specific error type could be extracted. The step generator returns information about a step the student should do next, e.g., when a hint is requested by the student.\nIndividual aspects of this work have been published before and describe different stages of the development of the different components. For instance, parts of the step analyser described in [58] have never\nbeen described in connection with the other parts of the final step analyzer or the final hint generation module [29]. The contribution of this paper is to provide a coherent overview of all components from the initial requirements analysis, via the design phase to their final implementation and evaluation.\nThe paper is organized as follows: Section 2 discusses the aspects of the tutoring problem by analyzing the teaching domain and reports on a Wizard-of-Oz experiment which was part of the design phase of our ITS system. The collected data in the form of tutorial dialogs represents a kind of \u201cgold standard\u201d which we try to approximate. Informed by the analysis of the collected data, we briefly review the state of the art in designing tutoring systems and derive the architecture of our tutoring system. The methods and tools to analyze student\u2019s proof steps are presented in Section 3. Section 4 presents how hints with an increasing degree of explicitness are generated from the domain specific proof strategies specified by the domain expert. The intelligent tutor services have been evaluated on the corpus of tutorial dialogs about proofs as presented in Section 5. Section 6 presents an outlook of further qualitative service improvements that are within grasp. We review related work in Section 7 and conclude in Section 8."}, {"heading": "2 Requirements Analysis and Functional Specification", "text": "The teaching goal in our domain is that students develop the skill to conduct and author mathematical proofs in textbook style. Our target students are in the final high-school years or undergraduate university students. Therefore, the assumptions on the students are that they have a knowledge of specific mathematics domains, but not necessarily of mathematical logic. Textbook-style proofs themselves consist of intermediate proof steps in a declarative style stating a subgoal or a derived fact. In that sense they are compatible to formal logic proofs. In contrast, the justifications in textbook style proofs are typically not exclusively references to basic formal logic rules. Rather, they are justified by references to hypotheses, definitions, lemmas or theorems\u2014collectively called assertions\u2014as well as specific proof strategies (e.g., well-founded induction) or symbolic computations (e.g., polynomial factorization)\u2014collectively called reasoning techniques. It is common practice to reduce the size of a proof by leaving out references to assertions or reasoning techniques if they can easily be inferred by the reader.\nSolution Space. For a given theorem, there is typically a space of possible proofs. This is for a variety of reasons: First, from a mathematical point of view, there often exist various distinct proofs for the same proof problem. For example, Ribenboim gives eleven proofs that there are infinitely many primes (see [55] for details). Especially, given a set of proofs it is difficult to be certain that no further mathematically sensible proof is possible, i.e., that a given set of proofs contains all mathematically sensible proofs.\nSecondly, even for a specific proof, there are different ways to formulate the proof: permutability of proof steps is one reason which essentially leaves the proof structure invariant. Additionally, a proof step can be formulated in forward-style by deriving new facts or in backward-style by introducing new subgoals: the choice of forward-style vs. backward-style has a more severe impact on how the proof is structured. Typically, in textbook-style proofs most steps are in forward-style because it makes it easier to follow the proof. However, proof search often happens in backward-style, and the proofs are reformulated in forward-style afterwards (see [62] p. 13-15 for a discussion).\nA given proof with a specific proof-style and a particular order of applying assertions is considered to be at the lowest level of mathematical proof, as all information is explicitly provided. However, this is often much too detailed and more high-level versions of the proof are also acceptable or preferred. For instance, one may allow for larger proof steps (w.r.t. step-size) and the omission of those justification details that are considered as trivial. The step-size of proof steps and the detailedness of their justifica-\ntions directly correlates with the conciseness of a proof, which in turn is crucial in order to effectively communicate the idea of a proof. Which high-level proof is actually still acceptable depends, of course, on the expertise of the audience; for instance, proofs in introductory mathematical textbooks are much more detailed than in advanced mathematical textbooks. Thus, thirdly, the detailedness of proofs adds a further dimension along which a proof may vary.\nProof Analysis Criteria. When judging a proof there are local and global aspects: On a local scale, one may judge each proof step separately. The first and foremost criterion, of course, is whether the proof step is correct or not. For an incorrect proof step, it is important to know why it is wrong in order to be able to repair or remove it. On the other hand, a correct proof step is not necessarily relevant for a proof, such as tautological steps or redundant proof steps. Thus, a second criterion is the relevance of a proof step. Furthermore, conciseness is important to convey the idea of a proof. On the local scale of proof steps this boils down to judging if a proof step is of adequate size and whether the details of its justification are appropriate. Finally, for textbook proofs it matters whether a backward-style proof step should preferably be re-formulated into a forward step or vice versa. On a global scale, the conciseness of a proof in the sense of whether the proof is without detours, or if there exist alternative shorter proofs, are interesting aspects.\nProof Construction. The goal to write proofs in textbook style requires knowledge of how to find a proof in the first place. Both the construction of a proof as well as the ability to come up with a good presentation of the proof which conveys the proof idea well requires proof strategic knowledge, as well as knowledge about when which proof strategy is appropriate or inappropriate. A human teacher tries to develop that knowledge by training the students on proof problems requiring a specific strategy. When students get stuck in the proof, trying to help them by strategic advise is the primary choice instead of showing them the detailed next steps."}, {"heading": "2.1 Wizard-of-Oz Experiment", "text": "Our approach to the intelligent tutoring of proofs is informed by experiments to study the specific requirements for such a system. In particular, we used the Wizard-of-Oz paradigm1 to assess the requirements for the system\u2019s sub-components to fulfill the tasks of the inner loop that are specific to proof tutoring, as outlined in the previous section.\nThe data was collected in an experiment where thirty-seven students interacted with a mock-up of a natural language dialog tutoring system for mathematical proofs. The system was simulated via a specific software environment [17] and the help of four experienced human tutors. We obtained a corpus of tutorial dialogs [16] that allowed us to study the actions of students and tutors related to proof exercises illustrating the properties of binary relations. Student input consisted of natural language text and formulas, to investigate the prospect of natural-language understanding for mathematics within such a tutoring system. In addition to providing feedback to student\u2019s actions (proof steps, questions or comments), the tutors rated each proof step with respect to correctness, granularity (or proof step size) and relevance to the current task.\nFigure 1 shows a fragment of a tutorial session in which the student was instructed to prove the theorem (R\u25e6S)\u22121 = (S\u22121 \u25e6R\u22121), where R and S are relations, and \u25e6 and \u22121 denote relation composition\n1Wizard-of-Oz experiments [40] simulate a complex system via a partial/prototype implementation that is assisted by a human expert (the \u201cwizard\u201d). Such experiments provide valuable data to assist the design and to evaluate components of such a system in advance of its completion.\nand relation inverse, respectively. In the examples, S refers to a student turn and T to a tutor turn. The approach taken by the student in the first example on the left of Figure 1 is to apply set extensionality and then to show that the subset relation holds in both directions. The student begins in utterance S8 by directly introducing a pair (x,y) in the set (R\u25e6S)\u22121. This is rated as correct by the tutor, who recognizes that the student wants to prove both directions separately and that the introduction of the pair (x,y) is useful due to the definition of subset. The student then states an incorrect formula in S10, which the tutor rates as incorrect.\nTwo alternative ways that the student could have started the same exercise, which we will use as running examples in this paper, are shown on the right in Figure 1. In S8a the student explicitly splits the proof into two subgoals with an application of set extensionality. In S8b the same rule is applied, but only one of the two resulting proof obligations is explicitly presented.\nWe analyzed those utterances from the corpus which contain contributions to the theorem proving task. We were able to identify five general phenomena which must be accounted for in order to correctly verify (or reject) the proof steps that students perform and to maintain correct consistent representations of the proofs they are building. These phenomena show that verification in this scenario is not simply a matter of logical correctness, but must also take into account the proof context, for instance.\nUnderspecification. Some subset of the complete description of a proof step is often left unstated. Utterance S8 is an example of a number of different types of this underspecification which appear throughout the corpus. The proof step in S8 includes the application of set extensionality, but the rule and its parameter are not stated explicitly. The student also does not specify that of the two subgoals introduced by set extensionality, he is now proving one particular subset direction, nor does he specify the number of steps needed to reach this proof state. Part of the task of analyzing such steps is to instantiate the missing information so that the formal proof object is complete.\nIncomplete Information. Proof steps can, in addition to issues of underspecification, be missing information which is necessary for their verification by formal means. For instance, utterance S8b is a correct contribution to the proof, but the second subgoal is not stated. This second subgoal is however necessary to verify that proving the subset relation is part of justifying the equality of the sets, since one subgoal alone does not imply the set equality which is to be shown.\nAmbiguity. Ambiguity pervades all levels of the analysis of the natural language and mathematical expressions that students use. Even in fully specified proof steps an element of ambiguity can remain. For example in any proof step which follows S8a, we cannot know which subgoal the student has decided to work on. Also, when students state formulas without indicating a proof step type, such as \u201chence\u201d or \u201csubgoal\u201d, it is not clear whether the formula is a newly derived fact or a newly introduced subgoal. Again, this type of ambiguity can only be resolved in the context of the current proof, and when resolution is not possible, the ambiguity must be maintained by the system.\nProof Step Granularity. As outlined above, proofs can generally be constructed at various levels of detail. In a tutorial setting, however, the tutor needs to ascertain that the student develops the proof at an acceptable pace. For this task, classical reasoners are of little help, since they usually provide large proof objects based on some particular logical calculus, such as resolution, that operate at a different step size (granularity) than typical mathematical practice. Generally, typical proof steps may represent several steps in a more formal representation, such as the natural deduction calculus or proofs at the assertion level. This is even the case for proofs at the beginner level (cf. [15]).\nIn the Wizard-of-Oz studies, the tutors were found to react to deviations in step size, e.g. in the dialog fragment in Figure 2, where the student is skipping a sub-step the tutor expects to see. Generally, whether a proof is of acceptable step size (granularity) depends on the student\u2019s knowledge (which we represent via a simple overlay student model) and other factors.\nRelevance of Proof Steps. The tutors in the experiments indicated when they believed that steps suggested by the student were not goal-directed. One problem that we address in this work is that the student may introduce hypotheses (e.g. \u201clet (x,y) \u2208 (R\u25e6S)\u22121\u201d in Figure 1), which may or may not be useful with respect to the current proof goal. We refer to this form of assessment as relevance checking."}, {"heading": "2.2 Domain Modelling & Teaching Strategies", "text": "ITS are designed to be effective \u2013 i.e., to lead to increased knowledge and skill via engaging the student with the system. There are three main approaches in the literature on how to build an ITS: Model tracing tutors, constraint based tutors, and example tracing tutors: Model Tracing Tutors (MTTs), such as the Andes physics tutor (see [71]), contain a cognitive model of the domain that the tutor uses to \u201ctrace\u201d the student\u2019s input, i.e., to infer the process by which a student arrived at a solution. MTTs are based on the ACT-R theory of skill knowledge [3] that assumes that problem solving skills can be modeled by a set of production rules. Given a student input, a model tracer then uses these rules to find a trace, i.e., a sequence of rule applications that derive the student\u2019s input. If such a trace can be found, the student is assumed to have used the same reasoning as encoded in the rules to arrive at his input and the step is reported to be correct (cf. (S1)). Thus, the tutor can use the trace to analyze the cognitive process of the student. Alternative solutions are supported by providing rules that capture alternative solution approaches.\nTo be able to also trace common student errors, a MTT typically provides a set of buggy rules (see [20]) that model incorrect reasoning. If a trace contains one or several buggy rules, the step is assumed to be incorrect and error specific feedback can be given to the student (cf. (S2)).\nIn practice, it turns out that a model tracer will not always be able to trace all student inputs, for example, if a solution cannot be found due to the complexity of the search space, or because a faulty step is not captured by a buggy rule. In this case, it is either assumed that the student step is wrong or an undefined answer is returned by the analysis component.\nMTTs can offer strategic and context sensitive problem-solving hints on demand by computing a solution for the current proof state using the expert module (cf. (S3)). By analyzing this solution, hint sequences can be computed that contain increasingly more information about the next step to be performed. The dynamic generation of the solution guarantees that the hint will be tailored to the specific situation in which the student got stuck.\nConstraint Based Tutors (CBTs), such as the SQL tutor (see [64]), are based on Ohlsson\u2019s theory of learning from performance errors (see [54]) and use constraints to describe abstract features of correct solutions. There are two fundamental assumptions:\n(i) Correct solutions are similar to each other in that they satisfy all the general principles of the domain.\n(ii) Diagnostic information is not contained in the sequence of actions leading to the problem state, but solely in the problem state itself.\nConstraints describe equivalent student states and consist of three components: a relevance condition, a satisfaction condition, and a feedback message. The relevance condition describes the abstract properties of the class of solution states that is represented by the constraint. The satisfaction condition contains additional checks a state of this class must satisfy in order to be correct. The feedback message contains the feedback that is given to the student when the satisfaction condition is not satisfied, i.e., when an error is detected (cf. (S2)). If the student enters a situation where the tutor has no knowledge of, i.e., no relevance condition evaluates to true, the CBM remains silent (cf. S(1)). Typically, CBTs provide two kinds of constraints: syntactic constraints and semantic constraints. Syntactic constraints check whether the input is well-formed, whereas semantic constraints compare the input with an optimal solution provided by the tutor. Semantic constraints also check for alternative solutions by capturing alternative subexpressions of a solution.\nAs CBTs are not equipped with an expert system that solves problems, they cannot automatically complete solutions for a given problem state. Therefore, hints can only be given by comparing the current solution state with an ideal solution, trying to detect missing features. This entails the risk that the hints that are given are overly general or misleading if the student follows a solution different to the ideal solution that is given by the tutor (cf. (S3)).\nExample Tracing Tutors (ETTs), such as the stoichiometry tutor (see [48]), interpret a student\u2019s solution step with respect to a predefined solution graph that represents a generalized solution, which is often also called behavior graph (cf. [52]). A behavior graph is a directed, acyclic graph, whose nodes represent problem solving states and whose edges represent problem solving actions. Several outgoing edges represent different ways of solving the problem represented by the state corresponding to the node. Misconceptions and common errors can be included within the graph using so-called failure links that indicate typical failures. This way, ETTs can give specific feedback to both correct and incorrect steps (cf. (S1, S2)).\nInitially, the current student\u2019s state is the root node of the graph, which is the only node that is marked as visited. Given a student\u2019s input, the input is matched against all outgoing edges of the current node. If the input matches a regular link leading to a yet unvisited node, the step is classified to be correct, if it matches a failure link or no link at all, it is classified to be incorrect. If a step matches\nmultiple regular links, all successor nodes represent possible interpretations of the student\u2019s step, which are then maintained in parallel. Behavior graphs can be extended to generalized behavior graphs, e.g., by defining groups of unordered steps (so the student can change the order of the steps), or by generalizing the matching condition for a link.\nBehavior graphs are also used to provide hints as to what a student might do next (cf. (S3)). This is done by identifying an unvisited link in the behavior graph, and then displaying a hint message associated with that link. ETT have the advantage that they do not require to model domain knowledge in form of production rules or constraints and are therefore considerably cheaper to develop. However, they work only for solutions that were foreseen by the author of the exercise.\nSummary. Table 1 summarizes the properties of the different approaches to design an ITS."}, {"heading": "2.3 Functional Specification for the Proof Tutoring System", "text": "For our Wizard-of-Oz experiments we deliberately did not impose any restrictions on the language used to write proof steps, and the input varied from pure formulas to pure natural language and all forms of mixed natural language and formulas (see the example fragment shown in Figure 1). Processing that input poses challenging problems for natural language understanding. In order to have a clear separation of concern, we devised a clear, formal interface language for the kernel module, which serves as target for the natural language analysis component(s) that still need to be developed (see [74] for recent work on that topic). This also has the advantage that different natural language analysis components for different languages can be used on top of the kernel module.\nOur interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process. This is because declarative proofs that can be processed by current proof assistants are usually much more detailed than corresponding textbook proofs that we want to teach. For example, we do not enforce the student to give justification hints or restrict the student to a specific granularity. By allowing arbitrarily large gaps between the commands, one arrives at the notion of a proof plan [28] or proof sketch [73]. Following van Lehn\u2019s requirement that an ITS should allow a\nstudent to stepwise construct a solution, we obtain as individual building blocks single declarative proof commands. This approach has the following properties:\n1. Proof commands are the primary solution steps a student can enter.\n2. The sum of all proof commands gives a complete solution in the style of a textbook proof.\n3. A proof command is justified in the context of the previously given steps.\n4. Proof steps might be partial, incomplete or underspecified.\nWe use \u2126mega\u2019s declarative proof script language presented in Figure 3 (see also [8]) as input language and allow underspecified proof scripts that are obtained by omitting \u201cby\u201d and \u201cfrom\u201d as well as the \u201cthus form\u201d in assume-proof steps. We also added them as special closing proof steps (cstep) at the end of steps following an introductory assume. Similarly, we relax the required qed at the end of a proof.\nTo develop the intelligent tutor we follow the MTT approach: first, the size of the solution space of textbook-style proofs with adaptive degree of detailedness ruled out the EBT approach. Since the solutions are proof sketches, the constraints that would have to be formulated when following the CBT approach would have to be constraints on proof sketches. The formalism required to formulate such constraints comes close to what is expressed in the tactic and declarative proof script language of the proof assistant system. The difference is that constraints are descriptive while information contained in tactics is constructive, which makes them attractive to generate (strategic) hints. Finally, the solution objects, i.e. (sketches of) declarative proofs, are themselves abstract structurings of parts of the cognitive model representing how the student solves the problem (proving the theorem). Filling the remaining gaps in proof sketches allows to obtain a very detailed cognitive model.\nThe functional specification of the ITS for proofs is shown in Figure 4: The student\u2019s inputs are analyzed by a natural language processing module, which provides either a declarative proof command in the declarative proof script language as output, or the information that a hint has been requested. The ITS maintains the focus on the current open goal and interprets the inputs in that context. Subsequently, the proof analyzer tries to automatically reconstruct missing proof steps and derive missing justifications. If that succeeds, the proof step is further analyzed with respect to granularity and relevance by the granularity analyzer. If the reconstruction fails, the proof assistant tries to find a reconstruction using in addition buggy rules specified by the tutor. In either case, the result is a feature vector composed of local proof analysis criteria soundness, granularity, and relevance (see Section 2). Due to the characteristics of the solution space, several alternative proof reconstructions may be possible for the same proof step sketch. In order to not rule out any of the possible solutions the student may follow, the ITS must trace all possible reconstructions simultaneously. All this is described in Section 3.\nIn order to generate hints, the ITS shall be able to provide hints with increasing degree of explicitness. It shall use automated theorem proving to try to complete the current partial proof (branch) to a complete\nproof and use the information used for proof search to generate the hints. Proof search is conducted by specific tactics, which the teacher can provide for a specific mathematical domain. The tactics encode strategic knowledge and the hierarchy of tactics used to complete a proof is recorded in order to be exploited to generate hints with increasing degree of explicitness. This is described in Section 4."}, {"heading": "3 Step Analysis", "text": "Human one-on-one tutoring is thought to be effective due to its very interactive nature and frequent (stepby-step) feedback [50]. It was found that using step-by-step feedback in an ITS translates to significant learning gains (cf. [25]). A recent meta-analysis [70] determines that tutoring systems with step-based feedback are almost as effective as human tutoring, and more effective than systems that are answerbased (i.e. they provide feedback at the level of the solution). Interestingly, systems that use even finer levels of feedback (so-called sub-step feedback) are found to be (only) similarly effective to traditional step-based systems.\nImplementing the concept of step-wise tutoring requires that, whenever the student performs a proof step, the step is evaluated in the current context by a step analyzer. In our approach, a three-dimensional feedback vector is computed with an entry for a proof step\u2019s soundness, granularity, and relevance, respectively. Computing the feedback vector is a two-staged process: First, a reconstruction algorithm is started that tries to relate the proof step given by the student to the current proof situation. Afterwards, the derivation obtained from the reconstruction algorithm is analyzed to compute the granularity and relevance measure.\nWhen and how the computed feedback is given to the student is determined by the feedback policy. Our default feedback policy is to give feedback on the correctness of a proof step immediately, whereas feedback on the granularity and relevance is only given when the student violates the condition that is demanded by the tutor."}, {"heading": "3.1 Proof Step Reconstruction", "text": "Didactic considerations require theorem provers to support actual mathematical practice, in addition to providing powerful automation in a selected mathematical domain. Since the development of classi-\ncal automated search based theorem provers and the corresponding investigations of logical calculi are mainly driven by correctness, completeness and efficiency issues, these theorem provers operate not on a \u201chuman-oriented level\u201d, but almost on the \u201cmachine code\u201d of some particular logical calculus, such as resolution. Hence, they can generally not be used as a model tracer. While there exist techniques to convert (completed) resolution proofs or matrix proofs into natural deduction proofs, (see for example [4, 51]), it turns out that performing the proof search directly at a more abstract level is beneficial for the runtime of the reconstruction. Moreover, it provides the possibility to run in a \u201cdiscovery\u201d mode without explicitly having to state an isolated proof obligation, which is often very difficult in a tutorial context due to underspecification or incomplete information.\nAbstract Reasoning: The Assertion Level. To come close to the style of proofs as done by humans, Huang [37, 38] introduced the assertion-level, where individual proof steps are justified by axioms, definitions, or theorems, or even above at the so-called proof level, such as \u201cby analogy\u201d. The idea of the assertion-level is, for instance, that given the facts U \u2282V and V \u2282W we can prove U \u2282W directly using the assertion:\n\u2282Trans: \u2200U.\u2200V.\u2200W.U \u2282V \u2227V \u2282W \u21d2U \u2282W\nAn assertion level step usually subsumes several deduction steps in a standard calculus, say the classical sequent calculus [32]. Therefore, traditional theorem provers can only achieve such conclusions after a number of proof steps. To use an assertion in the classical sequent calculus, it must be present in the antecedent of the sequent and be processed by means of decomposition rules, usually leading to new branches in the derivation tree. Some of these branches are subsequently closed by means of the axiom rule which correspond to \u201cusing\u201d that assertion on known facts or goals.\nThe technique to obtain such inferences automatically from assertions follows the introduction and elimination rules of a natural deduction (ND) calculus [32] and can be found in [29].\nThe Reconstruction Algorithm. The proof step reconstruction algorithm is based on two main ideas (see [30] for details): (i) Represent the possible states the student might be in as so-called mental proof state (MPS). (ii) Given a new proof step and a MPS, perform a depth-limited BFS at the assertion level, trying to derive one/several successor states that are consistent with the student\u2019s utterance, where the consistency is proof command specific. The depth limiter imposes an upper bound on the number of assertion level inferences that are assumed to be contained implicitly in the student\u2019s input.2 Whether this limit is sufficient depends on (i) the step size of the available proof mechanism and (ii) the experience of the student, as we discuss in Section 3.2. We have determined such a bound empirically for the corpus of students\u2019 proof steps from the Wizard-of-Oz experiments, as discussed in Section 5. The bound is needed to guarantee termination of the reconstruction algorithm, which might otherwise not terminate.\nFigure 5 shows an example reconstruction of a complete dialog taken from the corpus. In the figure, the shaded formulas correspond to the steps entered by the student. The white formulas correspond to assertions the student has left out and which were filled in by the reconstruction module.\nA MPS is represented as a set of sequents that are the subproblems to be solved, together with a global substitution which instantiates meta-variables. One of these sequents is always marked and represents the sequent the student is working on. Always keeping track of the student\u2019s subgoals facilitates task sensitive feedback.\n2Note that the correspondence of student steps to calculus steps may vary for each calculus.\nInitially, the MPS is unique and consists of the exercise given to the student as single sequent, together with the empty substitution. During the search, an invariant is that a MPS always represents a valid proof state. By expanding a given proof state only by valid actions, it is guaranteed that only reachable and consistent proof states are generated. Let us stress again that due to ambiguity and underspecification several consistent successor states are possible (as in the case of statement S8b shown in Figure 1 where the next subgoal the student will work on is underspecified). There can also be several reconstructions for a given proof step. Therefore, the verification algorithm works on a list of MPS rather than on a single one.\nWhile the reconstruction algorithm might look similar to the processing model of proof commands in a pure verification setting, there are the following subtle differences:\n\u2022 In a pure verification setting, it is sufficient to find some verification for a proof command. The verification itself is usually not of interest and needs not to be further processed. In contrast, in a tutorial setting we need to consider several, if not all, possible verifications of the given proof command and need to relate them to the student\u2019s knowledge to avoid the student to rely on the power of the underlying theorem prover to solve the exercise.\n\u2022 In a pure verification setting, we can assume the user to be an expert in the problem domain as well as in the field of formal reasoning. This has several implications on the processing model: (i) inputs can be expected to be correct and just need to be checked, (ii) proof commands can lazily be verified until a (sub)proof is completed, (iii) justification hints are given that indicate how to verify a given proof command, (iv) feedback is limited to \u201ccheckable\u201d or \u201cnot checkable\u201d. In contrast, in a tutorial setting, we must assume the user to be neither a domain expert nor an expert in formal reasoning. The underlying mechanisms need to be hidden from the user, direct and comprehensive feedback has to be provided at each step. Therefore, it is for example a requirement to anticipate why an assumption is made, in contrast to a lazy checking once the conclusion has been obtained.\n\u2022 In a pure verification setting, we can assume the user to indicate when the proof of a subgoal is finished (as usually done by so-called proof step markers in the proof language). However, in the tutorial setting this information is implicit. Similarly, we must be able to perform backward steps where some of the new proof obligations have not yet been shown.\nIn order to illustrate how the verification algorithm works, we will step through the verification of utterance S8 from Figure 1, beginning with the initial MPS and finishing with the MPS extended by the proof step. The initial MPS is {\u3008\u22a2 (R\u25e6S)\u22121 = S\u22121 \u25e6R\u22121; /0\u3009} and the proof step to be verified is let (x,y) \u2208 (R\u25e6S)\u22121.\nHaving expanded the current proof state (step (i), shown in Figure 6), we apply a let-proof step specific filter to find the set of newly-created sequents which are consistent with the given proof step. Of the sequents in the tree, only the node containing the sequent Tk passes, since the formula in the proof step appears on the left-hand side of the sequent. Now that we have found the consistent successor sequents, we must complete these sequents to MPSs. Because the decomposition of the sequent T0 introduced a subgoal split, the sequent Tj must be proved in addition to Tk. The resulting MPS is therefore {\u3008Tk,Tj; /0\u3009}, that is, Tk is now the current sequent, and Tj is still to be proved. Finally, we prune the nodes which were rejected by the filter.\nRelevance Checking. Using the proof step reconstruction mechanism for each proof step allows our approach to perform a form of relevance checking when a hypothesis is introduced. A hypothesis introduced by the student is matched against a proof search in \u2126mega, and considered relevant only if it can be unified with a step that is part of one of the partial solutions that are discovered via strategic proof search.\nIn practice, it turns out that it is very important for a tutoring system to enable a broad range of people to create content for the system in form of exercises and domain expertise. One of the main advantages of our approach is to use existing mature representation and search technology that has been developed over the last decades in the context of ITP/ATP. New domains can easily be added by users either by relying on already existing specifications of formalized mathematics, or by writing new specifications from scratch. That is, the only information the author has to provide is a problem description and the knowledge needed to solve the problem. As inferences are automatically synthesized from theorems and definitions, it is sufficient to provide this knowledge in a declarative form. For simple domains, this is already sufficient and there is a high chance that modifications of existing proofs or even new proofs are recognized by the tutor. For more complex domains in which the reasoning is more complicated, the author also has to provide strategic information on how to solve a problem."}, {"heading": "3.2 Granularity Analysis", "text": "In addition to verifying the correctness of proof steps generated by the student, and to detect steps that are logically incorrect, we use proof reconstructions to judge about another qualitative aspect of proof steps: granularity. By assessing the step size (in the context of the ongoing proof and a student model), a tutoring system for proofs can react if the student\u2019s solution lacks necessary detail, or, to the contrary, the student is progressing at smaller steps than expected, and adapt feedback and hints accordingly. Having a metric for step size also allows the system to generate and present hierarchical proofs (or steps to be used as hints) at specific levels of granularity.\nWe have devised a framework to analyze the step size of proof steps [58], where a proof step can refer to either the single application of an inference rule, or consist of several (tacit) intermediate inference applications provided by the reconstruction algorithm. Granularity judgments for such a (single or aggregate) step are considered as a classification task. Proof steps are characterized according to a catalog of criteria (cf. [58]) that are thought to be indicative of granularity, and classified as appropriate, too small, or to big according to a classifier.\nGranularity criteria, which are the basis for the classification task, take into account the current proof context, the content of the student model, and the verbal explanations given by the student. We currently use an overlay student model which for each assertion-level inference rule maintains an assumption whether it is mastered by the student or not, based on the student\u2019s actions.3 Analyzing a proof step with respect to the catalog of criteria yields a vector that is encoded numerically. For example, the criterion \u201cunmastered concepts\u201d is assigned the count of mathematical concepts employed as inferences in the (simple or aggregate) step which are supposed to be not yet mastered by the student. Classifiers can be represented in the form of decision trees, where decision nodes represent granularity criteria, and leaves record the granularity verdict. In our evaluation discussed in Section 5, we have also considered other forms of classifiers, such as rule based classifiers and classifiers learned by the support vector machine approach. An example for a simple decision tree classifier for granularity is presented in Figure 7. According to this particular classifier, for example, a proof step that consists of two inference applications at the assertion level (total=2), which represent two different concepts both of which have previously been mastered according to the current state of the student model (m.c.u.=2) and none of which introduces a new hypothesis into the proof (hypintro=0) is classified as \u201ctoo small\u201d. Note that this particular decision tree only uses a small number of criteria. Granularity classifiers can be written by hand, but an interesting question is what kind of judgments human experts actually make when assessing proof steps. In order to assess what granularity criteria are relevant for human tutors, and whether corresponding classifiers can be learned from samples of proof steps annotated with granularity judgments, we conducted an experiment presented in Section 5.\n3There are more sophisticated techniques (e.g. Bayesian networks) for estimating the student\u2019s knowledge that can be used instead. However, student modelling as such was not the focus of this research."}, {"heading": "4 Next Step Generation for Hinting", "text": "At any time of a tutorial session, a student might get stuck and request help on what step to perform next. Help can also be given without an explicit request, for example after repeated student errors, or a long period of silence. Thus, one important design decision for a tutoring system is when to give a hint, i.e., to provide a hinting policy. For our tutoring system, we use the simplest possible hinting policy, namely to give a hint only if it is explicitly requested by the student. As discussed in [2], this might not be optimal, as students might abuse this functionality or refuse to ask the system for a hint; nevertheless it is the strategy that is used in most tutoring systems.\nIt has been shown that human tutors use hint sequences that start with abstract hints and refine the hint on demand. The principle of progressively providing more concrete hints if required has been applied to a number of tutoring systems, including the Carnegie Proof Lab [60]. The goal is to leave the student to perform the actual concrete steps that the hint has requested, leading to better knowledge construction. If the student is still stuck, subsequent hints should refer to smaller subtasks of the proof, becoming increasingly close to the fully-specified assertion level step.\nTo find a relevant, context-sensitive hint, we follow the typical approach of MTTs and invoke the domain reasoner to find a solution for the current proof state. This solution is then analyzed to extract a hint. In our approach, the provision of increasingly concrete hints is supported by a problem solver that generates a hierarchical solution (see [7] for details) based on proof strategies, where each (sub)invocation of a strategy introduces a new hierarchy in the computed solution. Intuitively, a high level in the hierarchy sketches how the overall problem was structured into subproblems. At the lowest level, a concrete proof with concrete assertion steps is given. Consequently, we can synthesize both strategic hints as well as information about the concrete next step to be performed. Of course, the quality of the hints directly depends on the quality of the proof strategies, i.e., how the knowledge is encoded by the author of the exercise.\nWe first describe in Section 4.1 how an author can encode proof strategies and how these strategies are used to generate a hierarchical proof object, and in Section 4.2 how the computed solution is used to synthesize a hint."}, {"heading": "4.1 Authoring of Proof Strategies", "text": "A proof strategy represents some mathematical technique that happens to be typical for a given problem. For example, there are strategies which perform proof by induction, proof by contradiction, solve equations, or unfold definitions. To achieve a (strategic) goal, a strategy performs a heuristically guided search using a dynamic set of assertions, as well as other strategies.\nIn contrast to other approaches that require to encode the knowledge in the underlying programming language of the system, we encode proof strategies in a separate strategy language (see [31, 8] for an overview).\nA simple proof strategy that is proposed in [62] is the \u201cForward-Backward Method\u201d, which combines the two well-known problem solving strategies: forward chaining and backward chaining: The method starts with backward chaining by matching the current proof goal with the conclusions of theorems and definitions and adding their premises as new goals to be proved. The backward chaining phase continues until all conclusions have been solved or until no further definition or theorem can be applied. Subsequently, a forward chaining phase is started. Forward chaining starts from available assumptions and given facts and continuously applies definitions and theorems forwards by instantiating all their premises and adding their conclusions to the current proof state.\nWe have formalized this method as a strategy \u201cClose-by-Definition\u201d. Each phase is realized by a sub-strategy: \u201cWork-Backward\u201d applies definitions in backward direction, as indicated by the keyword backward, that is, expands definitions that occur in the goal. \u201cWork-Forward\u201d applies all definitions in forward direction, as indicated by the keyword forward (see Figure 8), that is, expands concepts that occur on the left-hand side of the sequent. It is the responsibility of the author of the strategy to guarantee termination.\nAs additional logical steps are commonly needed to close a proof task, we provide a third strategy \u201cClose-by-Logic\u201d, which performs case-splits and applies the axiom rule to close sequents. Finally, these strategies are assembled to the overall strategy \u201cClose-by-Definition\u201d, which calls the strategies in a specific order. The strategy keyword try ensures that a strategy application can also be skipped, e.g., when the student has already expanded the goal completely."}, {"heading": "4.2 Hinting", "text": "Once a solution of the current proof state has been computed in the form of a hierarchical proof, the proof hierarchies can be used to synthesize hints of increasing specificity. This is done as follows: (i) selecting a certain level of hierarchy in the reconstruction, (ii) selecting a successor state at the selected hierarchy (iii) extracting information from the selected state and converting it to a concrete hint. A given hint can be refined by either switching to a more detailed level in the hierarchy, or by increasing the information which was extracted from the selected successor state.\nHow should the next proof step be communicated to the user? A general issue in ITS design is how much scaffolding is to be provided to the learner, which is known as the \u201cassistance dilemma\u201d \u2013 both too much and too little assistance hamper learning [41]. So-called Socratic teaching strategies (cf. [57]) have been demonstrated to be superior to didactic teaching strategies, i.e. hinting based on direct instruction, especially regarding their long-term effects [57, 23, 5]. Socratic teaching is motivated by the idea that learners a priori posses the necessary prerequisites to acquire new knowledge from existing knowledge (cf. [75]). The role of the tutor thus is to moderate this process by asking knowledge-eliciting questions. Such a teaching strategy for the domain of mathematical proofs has been developed and automated by Tsovaltzi [68] and provides the background for our work. By applying the Socratic teaching strategy, the next proof step is not given directly to the student. Instead, a question is formulated that encourages the student to think for himself and construct his own solution to the task at hand.\nSimilar to Andes (see [34]), we use templates to generate hints in natural language. Variables in the templates are filled with the concrete objects that are available in the actual proof situation. We have designed a general ordered set of templates that can be used for arbitrary assertion level steps; moreover, we attach an ordered set of templates to each strategy. The hints can be classified as follows:\n(i) A strategic hint that describes what to apply from a strategic viewpoint, for example: \u201cWhat asser-\ntion can be applied backward to the goal?\u201d\n(ii) A hint on an inference to be applied by pointing to involved variables, for example: \u201cCan you say anything about the sets A and B?\u201d\n(iii) A hint on an inference to be applied without stating the premises and conclusion that are involved, for example: \u201cHow can you show that two sets are equal?\u201d\n(iv) A hint that points to the premises of an inference that is applied backwards without naming the inference, for example: \u201cIf you want to show that A\u2229B = B\u2229A, what should be true about these sets?\u201d\n(v) A hint that points to a subgoal but does not say how the subgoal is achieved, for example: \u201cHow can you show that A\u2229B \u2282 B\u2229A?\u201d\n(vi) A hint that points to the conclusion of an inference that is applied forwards without naming the inference, for example: \u201cWhat can you conclude if you know that x \u2208 A and x \u2208 B?\u201d\n(vii) A hint that describes the complete application of an inference, that is, the name of the inference, together with the instantiated premises and conclusion.\n(viii) A hint that points to an inference application together with restating the assertion to be applied.\nLet us illustrate our approach by means of an example. Consider the exercise (R\u25e6S)\u22121 = S\u22121 \u25e6R\u22121. Suppose that the student starts the proof by equality, yielding two subtasks\nT1 : \u22a2 (R\u25e6S) \u22121 \u2282 S\u22121 \u25e6R\u22121 (1) T \u20321 : \u22a2 S \u22121 \u25e6R\u22121 \u2282 (R\u25e6S)\u22121 (2)\nand requests a hint for the task T1. A possible completion of the proof, encoded in the strategy \u201cCloseby-Definition\u201d, consists of expanding all definitions and then using logical reasoning to complete the proof. The resulting hierarchical proof object is shown schematically in Figure 9. The task T1 has three outgoing edges, the topmost two corresponding to a strategy application and the lower-most one corresponding to an assertion application, respectively. Internally, the edges are ordered with respect to their granularity, according to the hierarchy of nested strategy applications that generated them. In the example the most abstract outgoing edge of T1 is the edge labelled with \u201cClose-by-Definition\u201d, followed by the edge labelled with \u201cWork-Backward\u201d, both representing strategy applications. The edge with the most fine-grained granularity is the edge labelled with \u201cDef \u2282\u201d and represents an inference application.\nBy selecting the edges \u201cWork-Backward\u201d, \u201cWork-Forward\u201d, and \u201cClose-by-Logic\u201d, we obtain a flat graph connecting the nodes T1, T4, and T5. A more detailed proof-view can be obtained by selecting the\nedge \u201cDef \u2282\u201d instead of \u201cWork-Backward\u201d. In this case the previous single step leading from T1 to T4 is replaced by the subgraph traversing T2 and T3.\nAs mentioned above, each selection can be used to generate several hints. Suppose for example that we select the lowest level of granularity, and the first proof state to extract a hint. This already allows the generation of three hints, such as\n\u2022 \u201cTry to apply Def \u2282\u201d\n\u2022 \u201cTry to apply Def \u2282 on (R\u25e6S)\u22121 \u2282 S\u22121 \u25e6R\u22121\u201d\n\u2022 \u201cBy the application of Def \u2282 we obtain the new goal (x,y) \u2208 (R\u25e6S)\u22121 \u21d2 (x,y) \u2208 S\u22121 \u25e6R\u22121\u201d\nSelecting a more abstract level would result in hints like \u201cTry to work backward from the goal\u201d, or \u201cTry to apply definitions on the goal and assumptions\u201d. The ability to provide hints that address several dimensions at which scaffolding can be provided in proof tutoring is beneficial for providing targeted, adaptive feedback."}, {"heading": "5 Evaluation", "text": "The presented techniques have been successfully evaluated using experiments and experimental data from the Wizard-of-Oz experiments described in Section 2.1. In particular, we examined in how far the proof reconstruction mechanism successfully models the proofs from the students (who were unconstrained in their solution attempts). We performed additional experiments to study granularity judgments by human tutors, and in how far these judgments can be learned via machine learning techniques and represented as classifiers within the tutoring system.\nProof Reconstruction & Assessment. In the Wizard-of-Oz experiments introduced in Section 2.1, tutors were asked to indicate explicitly whether steps are correct or incorrect. We investigated in how far the steps judged as correct by the tutors are reconstructed by our approach \u2013 to provide appropriate feedback on correctness, but also to serve as the basis for further analysis, e.g. granularity analysis. Since the algorithm uses breadth-first-search, an important question is what search depth is necessary to verify the proof steps from the students.\nIn our analysis, we used 144 proof steps from the Wizard-of-Oz experiment which deal with an exercise about binary relations, namely to show that (R\u25e6S)\u22121 = R\u22121 \u25e6S\u22121 (where the operators \u25e6 and \u22121 denote relation composition and inverse). Of these steps, 116 were judged as correct and 28 as incorrect. Table 2 shows the proportion of steps that were correctly accepted and rejected, and the proportion of steps that were not verified or wrongly accepted, using a depth-limit of four steps for BFS. Apart from three steps, all proof steps are correctly verified or rejected (which corresponds to an overall accuracy of 98%). Since the relatively small depth limit of four steps is sufficient for accurate verification in our sample, we conclude that our approach to proof reconstruction is feasible (within the given domain of proofs).\nGranularity. We have used proof reconstructions at the assertion level as the basis for granularity analysis (as outlined in Section 3.2) within a framework for judging granularity (presented in [58]). To investigate the prospect of learning granularity classifiers from the granularity judgments by expert tutors, we asked four expert tutors to contribute to a corpus of granularity judgments. This corpus was used to analyze agreement between tutors, to synthesize granularity classifiers via machine learning techniques, and to determine what granularity criteria are most useful for judging granularity (as presented in more\ndetail in [58]). A first exploratory analysis revealed that most of the proof steps that were presented to the tutors (which were constructed from one or a few inference steps at the assertion level) were considered to be of appropriate granularity. This is in particular the case for proof steps that correspond to one single inference at the assertion level, which were considered of appropriate size in 93%, 69%, 83% and 96% of the cases by the four tutors. When the bias towards the \u201cappropriate\u201d class is accounted for, agreement between tutors is moderate. The individual sub-corpora of granularity judgments by the four tutors also differed in how far they were found to be amenable to the automated learning of classifiers. We used several algorithms (decision tree learning, decision rule learning and support vector machines) offered by the data mining tool Weka4, with different degrees of success for the four sub-corpora (cf. [58]). It should be noted that the experiment investigated the naturalistic judgments of tutors without enforcing \u201cconsistency\u201d in the judgments, therefore some disagreement was to be expected. Overall, the experiments indicated that the proof steps at the assertion level are a good basis for granularity analysis, since they are close to what human judges (in the setting of our experiments) consider as appropriate step size. Furthermore, counting the number of assertion level steps in the reconstruction of a student\u2019s proof step was determined as the most indicative criterion when only judgments are considered where three out of the four judges agree. The experiment illustrates the prospects of learning classifiers from expert tutors, but it also points at the differences between experts in judging granularity.\nDiscussion. The evaluation illustrates the use of assertion level reasoning for assessing proof steps as they occur in relatively unconstrained tutoring dialogs that we collected in the Wizard-of-Oz experiments. Furthermore, we have shown that these reconstructions are a useful basis for analyzing further aspects of proof steps, such as granularity."}, {"heading": "6 Outlook", "text": "The previous sections describe how the proof assistant \u2126mega was utilized as a domain reasoner providing feedback on proof steps and generating hints. We believe that using a proof assistant offers a lot more of not yet exploited potential to improve the quality of ITSs. In this section we present some of these ideas that are the basis for future work.\nFurther Qualitative Proof Step Assessment Criteria. Reconstruction of a proof step is usually a task that is local to an individual student session and can be seen as the process of generating an individual solution graph for the given subject. To make the tutoring system more efficient, it is possible to cache solution graphs from previous tutoring sessions and to combine them to an overall solution graph. This has two major advantages: (i) The instructor gets a compact overview over typical approaches taken by\n4http://www.cs.waikato.ac.nz/ml/weka/\nall of his students, (ii) the instructor can review and refine hints that were given by the system, (iii) each student that comes up with a new solution becomes an author, (iv) whether a proof is sensible or whether a (irrelevant) proof step is nevertheless sensible typically are properties that need the comparison with other solutions. The hope is that eventually a fixed point will be reached, containing a fully specified trace over all possibilities.\nAnother criterion to analyze a proof step for is whether it is consistent with an overall strategy. For instance, if the teaching goal also consists in teaching a specific proof strategy, then the proof assistant must interpret a student\u2019s proof step not only with respect to a current open goal, but also with respect to an upper strategy. In case a strategy consists of different sequential sub-strategies, such as, for instance, the \u201cForward-Backward Method\u201d from Section 4.1, this also requires to be able to find out when one strategy is finished and the next one starts. How to achieve this tracking of strategy execution is an open problem, but a solution could be to hook the user input into the tactic execution mechanism.\nIntegration of Model Generators. A variety of tools has been developed for finding finite models of first order logic (FOL) formulas, such as Paradox [24] and Mace [47], to name a few. Given for example the theory of groups and the assertion that all groups are commutative, they are able to produce a countermodel of the assertion, i.e., a non-commutative group. This is done by providing an interpretation for the involved function symbols which makes the assertion false, which can be understood as a group table. Similarly, counter-models can be generated for other theories, such as the theory of binary relations. Note that in contrast to the verification of a proof step, the counter-model provides the information that the given step is wrong. Proof step reconstruction could be made more efficient by systematically checking for counter-models during the reconstruction process. Moreover, in case no reconstruction was possible, model-finders could be employed to generate a counter-model for the proof step and the error-feedback routine could employ the counter-model to provide hints or explain why a proof step is invalid. The challenge here consists of adequately verbalizing the found counter-model.\nReviewing of Solution (service S5, p. 1). Mathematical proofs in textbook-style mainly contain forward proof steps. However, to find a proof often a backward-style is used. Checking if a specific proof step entered by the student is in forward-style or in backward-style is easy. Depending on the didactic strategy and possibly depending on the skills of a student, the ITS has the choice of enforcing forwardstyle proof steps immediately, or to let a student having difficulties with proving in the first place write a proof in any style. In the second case, the tutor can then review the solution with the student, for instance, by indicating backward proof steps and subsequently asking to transform them into a forwardstyle proof. Or simply by showing the student his own proof in forward-style, which is easily possible in \u2126mega already now.\nAssessment of Student Knowledge (service S4, p. 1). The student\u2019s knowledge is incorporated in the granularity classifier by exploiting the information which concepts are mastered by the student. During the proof development that information is updated, for instance, by adding initially unmastered concepts to the mastered concepts once they have been used correctly a number of times in a proof step. Since our approach uses a full-fledged proof assistant system for the analysis of the student\u2019s input, a precise and detailed assessment of the student\u2019s actions is provided, which is considered beneficial for student modeling. In this context, the benefit of using state-of-the-art techniques in student modeling for diagnosing student knowledge (using, for example, statistical inference) could be explored. Such a modeling\nof student knowledge can enable the system to adjust instructions and exercises to the particular strengths and difficulties of individual students.\nFurthermore, an interesting feature that an ITS as outlined in this paper could offer is a walk-through of the student\u2019s proof solution, where the proof steps that were rejected by the system are presented along with the reasons for rejection, as well as the accepted proof steps and their relation to the final proof.\nAutomatic hint generation for logic proof tutoring using historical data. So far the hint generation uses the recorded hierarchy of strategies used to find a proof. Of course, there are choices which hierarchy-level to consider and which form of hint (Socratic vs. didactic, next step vs. strategic) to deliver in a specific situation. Following ideas from [12] the tutor system itself could record the hints given away in specific proof situations and try to assess how useful they were. From that historical tutoring data it could come up with a classifier deciding which form of hint to use in which situation."}, {"heading": "7 Related Work", "text": "We discuss our work in connection with related approaches that (i) focus on domain reasoning techniques for tutoring proofs in logics and mathematics (AProS and the Carnegie Proof Lab [60], the EPGY Proving Environment [63], Tutch [1] and approaches using hierarchical proofs), and (ii) hint generation (Carnegie Proof Lab, Andes [34] and the NovaNet Proof Tutorial [13]).\nAPROS. The AProS project (see [60] for an overview) provides an integrated environment for strategic proof search and tutoring in natural deduction calculi for predicate logic. It consists of four modules: the proof generator which implements strategic proof search based on the intercalation calculus, the proof lab, which builds the interface to the students, the proof tutor, which generates hints for students that are stuck, and a web-based course containing additional learning material. Proofs are represented in a Fitchstyle diagram and constructed by adding/removing steps to the diagram. This means that the student enters stepwise the proof at the calculus level, and that the performed steps can therefore immediately be checked. If a student requests a hint, the proof generator initiates the construction of a complete proof, which the tutor analyzes to extract a hint. The first hint provided at any point in the proof is a general strategic one, and subsequent hints provide more concrete advice as to how to proceed. The last hint in the sequence recommends that the student take a particular step in the proof construction.\nCompared with AProS, which focuses on the teaching of one particular logical calculus (without equality), the main difference with our approach is that we focus on the teaching of more abstract assertion level proofs, which are rather independent of a particular logical calculus. Proofs are essentially constructed in a declarative proof language in the form of proof sketches. If the information provided by the student is complete and correct, the verification is just a simple checking, as in the case of AProS. However, within our setting, this is not the typical situation. Rather, it is common that the information provided by the student is incomplete, as humans typically omit information they consider unimportant or trivial. Therefore, reconstruction of the missing information is necessary, as well as an analysis of the complexity of this information.\nThe generation of hints is similar to our approach in the sense that (i) it is dynamic and based on a completion of the student\u2019s proof attempt, and (ii) that it can be provided at several levels of granularity. However, we do not focus on a particular calculus, neither on a fixed proof strategy. This necessitates the sophisticated techniques presented in Section 3.2 to instantiate the system with the required problem\nsolving knowledge in the form of assertions and proof strategies, and to model the student\u2019s knowledge via a student model, which is used for granularity analysis.\nEPGY. The Epgy theorem proving environment aims to support \u201cstandard mathematical practice\u201d both in how the final proofs look as well as the techniques students use to produce them (see [63] p. 227). To verify the proof steps entered by a student, Epgy relies on the CAS Maple and the ATP Otter. The system is domain independent in the sense that the course authors can specify the theory in which a particular proof exercise takes place. Proof construction works by selecting predefined rules and strategies from a menu, such as definition expansion or proof by contradiction, or by entering formulas. For computational transformations, a so-called derivation system is provided. Once a statement is entered, the student selects a set of justifications that he thinks is sufficient to verify the new statement. The assumptions together with the goal and implicit hidden assumptions are then sent to Otter with a time limit of four to five seconds to verify the proof step.\nCompared to our approach, the main similarities are that the system aims at teaching ordinary mathematical practice independent of a particular calculus. Moreover, it uses a theorem prover as domain reasoner to dynamically verify statements entered by a student. The authors acknowledge that the use of a classical ATP to verify proof steps has the following drawbacks ([63] p. 253-254): (i) \u201cOne weakness of the Theorem Proving Environment is that, like most computer-based learning tools, it does not easily assess the elegance and efficiency of the student\u2019s work\u201d. (ii) \u201cIn the current version of the Theorem Proving Environment, students are not given any information as to why an inference has been rejected. Students are told generally that an inference may be rejected because it represents too big a step of logic, because the justifications are insufficient to imply the goal, or because the goal is simply unverifiable in the current setting. From our standpoint, Otter\u2019s output is typically not enough to decide which is the reason of failure\u201d.\nIn contrast, our approach relies on using the assertion level as a basis to verify statements uttered by a student. This results in an abstract proof object, which can further be analyzed, for example with respect to granularity, as demonstrated in Section 3.2, or to extract hints on how to proceed if the student gets stuck. In particular, the problem whether specified assertions were used in the derivation can trivially be solved. We believe that limiting the runtime of Otter does not reveal any information about the complexity of a particular proof step. While it would also be possible to analyze the resulting proof object, we believe that it is not at an appropriate level of granularity and does not reflect a human-style of proof construction. Even for natural deduction calculi, an investigation [59] into the correspondence between human proofs and their counterparts in natural deduction points out a mismatch with respect to their granularity.\nMoreover, our approach is more flexible with respect to the following aspects: (i) Due to the use of a proof language, the student is more flexible in entering the solution. (ii) It is compatible with the buggy rule approach. Note that this is not the case for classical automated reasoners, in which an inconsistent theory makes everything provable. In contrast, our approach allows for a full control over buggy rules, such as limiting their application to a single step. (iii) Our approach supports incomplete information such as a missing subgoal. Note that by leaving out such a subgoal, the resulting proof obligation becomes unverifiable and can therefore not be supported by a classical ATP. Finally, our approach is extensible and supports the specification of domain-dependent proof strategies, as well as checking whether a particular step can be checked by a specified proof strategy. This is not possible in the work cited above.\nTUTCH. Tutch (see [1]) is a proof checker that was originally designed for natural deduction proofs in propositional logic. However, it was later extended to also feature constructive first order logic to support human oriented proof steps. To that end, a simple proof language that allows steps at the assertion level was developed, as well as proof strategies that allow for an efficient proof checking for proofs within that language. This is similar to our approach, which also relies on a proof language as well as a dynamic reconstruction of the proof steps. Because of these similarities, we focus on the details of the proof language and the strategies to verify the proof steps.\nHierarchical Proofs. Hierarchical proofs have been advocated by several people, such as Lamport [44] in the context of informal proofs. A similar idea is proposed by Back and colleagues for calculational proofs [11, 10]. In the context of HOL, Grundy and Langbacka [35] developed an algorithm to present hierarchical proofs in a browsable format. Another possibility for hierarchical proof construction is provided by a method called window inference [56]. Window inference allows the user to focus on a particular sub-formula of the proof state, transforming it and thereby making use of its context, as well as opening subwindows, resulting in a hierarchical structure.\nOur approach is based on previous work by Cheikhrouhou and Sorge who developed the hierarchical proof data structure PDS in an earlier version of the \u2126mega system, intended to support hierarchical proof presentation and proof search [22]. In particular, the PDS supports so-called \u201cisland proofs\u201d, i.e. proofs that contain gaps which can be filled via refinement operations. The same idea has been picked up by Denney, who developed the notion of hiproof [27]. Most recently, a tactic language for hiproofs has been proposed in [6].\nMathsTiles. MathsTiles [19] are a flexible language to be used as an interface for an intelligent book on mathematics. In particular, proof exercises are offered where proofs formulated by the student are checked via Isabelle/HOL. The tiles correspond to graphical elements that can be arranged and recombined within a mathematical document, and which are used to represent formulas. This allows for flexibility while writing the proofs (e.g. in the order in which proof lines are written). However, the approach in [19] checks proofs linearly. In this context, the question of proof granularity is discussed. The authors state that the students should not use the prover to solve the exercises for them, and therefore the student is limited to using only Isabelle\u2019s simplifier (simp). Since rules can be added or removed from the simplifier, this makes the approach configurable. In contrast to our approach, however, such rule sets within the mathematical domain represent only an implicit model of granularity which does not take into account dynamic information such as the proof context and the student\u2019s knowledge.\nAndes. Andes [34] is an ITS for teaching Newtonian physics. Like in our approach, student and tutor solve problems collaboratively, which is called coached problem solving. Andes includes a problem solver, which is run on the problem description to generate a solution graph. The system uses abstract plans, such that the resulting solution graph represents a hierarchical dependency network. Similar to our approach, Andes uses templates to generate hints based on the solution graph [34]. There may be several paths to a solution. Andes uses a Bayesian network for plan recognition to determine on which solution path the student might be on for giving an appropriate hint. As a justification, the authors mention their own informal studies where they found that human tutors rarely ask students about their goals before giving a hint. This can also be considered a motivation for our approach, where we keep track of several possible proof reconstructions simultaneously. Similarly to our approach again, the hints that are generated by Andes range from general to specific.\nNovaNet Proof Tutorial. The NovaNet Proof Tutorial [13] is a learning tool for logic proofs. Students write proofs line by line which are verified by the system. To generate hints for the next step, a path through the space of the previously explored actions is sought by optimizing a Markov decision process. This substitutes the use of (strategic) proof search by data-mining a large number of example solutions. The process can be tuned to extract an expert, a typical, or least error-prone solution. For the suggested steps, four levels of hint are generated and presented to the student in sequence; (i) the goal is indicated, (ii) what rule is to be applied, (iii) the statement the rule can be applied to, (iv) both the rule and the statements (bottom-out-hint). These variants of hints are a subset of the hinting categories provided by our approach as presented in Section 4.2, and do not involve proof hierarchies."}, {"heading": "8 Conclusion", "text": "In this paper we presented a coherent overview of the design of and methods for an ITS to teach students to write mathematical proofs in textbook style. Based on a detailed analysis of the teaching domain, the paper argues in favor of adopting the model-tracing tutor style to support the inner loop of such an ITS. The tutor was then built on top of the slightly adapted proof assistant \u2126mega to provide step analysis and hint generation. Feedback is provided on each proof step entered by the student in form of a vector composed of the criteria soundness, relevance and granularity. Hints are provided with increasing degree if explicitness.\nThe following features of \u2126mega were particularly important to realize the system: First, \u2126mega\u2019s declarative proof script language allowed to define a clean interface proof sketch language to separate natural language analysis from the pure step analysis and hint generation tasks. Second, the assertionlevel proof calculus allowed for a depth limited search to reconstruct missing information in proof steps. We established that information obtained by proof reconstruction is a good basis for classifier-based granularity analysis. In particular, this allows the system to judge granularity based on criteria such as the number of assertions used by the student (which was found to be a useful criterion for modelling human tutors\u2019 judgments), the number of which are mastered or unmastered by the student, etc. We furthermore investigated the use of machine learning techniques to instantiate the classification module via corpora of example classifications from human experts. Third, \u2126mega\u2019s strategy language combining declarative and procedural LCF-style tactics served as an authoring language for domain specific strategic proof procedures. They can be used both to generate a proof from scratch as well as to complete the partial proof of the student. Recording the hierarchy of strategies completing a proof provided an excellent basis for generating hints.\nThe resulting prototype tutoring system has been evaluated on a corpus of tutorial dialogues to analyze the student inputs and yields good results. Having a proof assistant system as domain reasoner bears a lot of potential in order to improve the quality of proof step analysis, feedback, and reviewing of solutions. Further work is also devoted to design the interface towards the student, which maps the student input to the intermediate formal proof step format."}], "references": [{"title": "Human-Readable Machine-Verifiable Proofs for Teaching Constructive Logic", "author": ["Andreas Abel", "Bor-Yuh Evan Chang", "Frank Pfenning"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Limitations of Student Control: Do Students Know when They Need Help", "author": ["Vincent Aleven", "Kenneth Koedinger"], "venue": "editors: Intelligent Tutoring Systems, Lecture Notes in Computer Science", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Transforming matings into natural deduction proofs", "author": ["Peter B. Andrews"], "venue": "Proceedings of the 5th Conference on Automated Deduction (CADE),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1980}, {"title": "Teaching Case-Based Argumentation Concepts using Dialectic Arguments vs. Didactic Explanations", "author": ["Kevin D. Ashley", "Ravi Desai", "John M. Levine"], "venue": "Proceedings of the Intelligent Tutoring Systems Conference,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Tactics for Hierarchical Proofs", "author": ["David Aspinall", "Ewen Denney", "Christoph L\u00fcth"], "venue": "Journal Mathematics in Computer Science", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2010}, {"title": "A Generic Modular Data Structure for Proof Attempts Alternating on Ideas and Granularity", "author": ["Serge Autexier", "Christoph Benzm\u00fcller", "Dominik Dietrich", "Andreas Meier", "Claus-Peter Wirth"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "A Tactic Language for Declarative Proofs", "author": ["Serge Autexier", "Dominik Dietrich"], "venue": "First International Conference,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Textbook Proofs Meet Formal Logic - The Problem of Underspecification and Granularity", "author": ["Serge Autexier", "Armin Fiedler"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Structured derivations: a unified proof style for teaching mathematics", "author": ["Ralph-Johan Back"], "venue": "Formal Asp. Comput", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Toward Automatic Hint Generation for Logic Proof Tutoring Using Historical Student Data", "author": ["Tiffany Barnes", "John C. Stamper"], "venue": "editors: Intelligent Tutoring Systems, 9th International Conference,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Automatic Hint Generation for Logic Proof Tutoring Using Historical Data", "author": ["Tiffany Barnes", "John C. Stamper"], "venue": "Educational Technology & Society", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "Mathpert: Computer Support for Learning Algebra, Trig, and Calculus. In Andrei Voronkov, editor:  LPAR, Lecture Notes in Computer Science 624", "author": ["Michael Beeson"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "Deep Inference for Automated Proof Tutoring", "author": ["Christoph Benzm\u00fcller", "Dominik Dietrich", "Marvin Schiller", "Serge Autexier"], "venue": "editors: KI 2007: Advances in Artificial Intelligence. 30th Annual German Conference on AI, LNAI 4667,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "A corpus of tutorial dialogs on theorem proving; the influence of the presentation of the study-material", "author": ["Christoph Benzm\u00fcller", "Helmut Horacek", "Henri Lesourd", "Ivana Kruijff-Korbayov\u00e1", "Marvin Schiller", "Magdalena Wolska"], "venue": "Proceedings of International Conference on Language Resources and Evaluation (LREC", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "DiaWOz-II - A tool for wizard-of-oz experiments in mathematics", "author": ["Christoph Benzm\u00fcller", "Helmut Horacek", "Henri Lesourd", "Ivana Kruijff-Korbayov\u00e1", "Marvin Schiller", "Magdalena Wolska"], "venue": "KI", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Student Proof Exercises Using MathsTiles and Isabelle/HOL in an Intelligent Book", "author": ["William Billingsley", "Peter Robinson"], "venue": "J. Autom. Reasoning", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Repair theory: A generative theory of bugs in procedural skills", "author": ["John Seely Brown", "Kurt VanLehn"], "venue": "Cognitive Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1980}, {"title": "PDS \u2013 A Three-Dimensional Data Structure for Proof Plans", "author": ["Lassaad Cheikhrouhou", "Volker Sorge"], "venue": "Proceedings of the International Conference on Artificial and Computational Intelligence For Decision, Control and Automation In Engineering and Industrial Applications (ACIDCA)", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Cognitive Computer Tutors: Solving the Two-Sigma Problem", "author": ["Albert Corbett"], "venue": "editors: User Modeling", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2001}, {"title": "A Declarative Language for the Coq Proof Assistant", "author": ["Pierre Corbineau"], "venue": "Cividale del Friuli,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2007}, {"title": "Hiproofs: A Hierarchical Notion of Proof Tree", "author": ["Ewen Denney", "John Power", "Konstantinos Tourlas"], "venue": "Proc. of the 21st Annual Conference on Mathematical Foundations of Programming Semantics (MFPS XXI),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "On the Comparison of Proof Planning Systems: lambdaCLAM, OMEGA and IsaPlanner", "author": ["Louise A. Dennis", "Mateja Jamnik", "Martin Pollet"], "venue": "Electr. Notes Theor. Comput. Sci", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2006}, {"title": "Assertion Level Proof Planning with Compiled Strategies", "author": ["Dominik Dietrich"], "venue": "Ph.D. thesis,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2010}, {"title": "Verification of Human-level Proof Steps in Mathematics Education", "author": ["Dominik Dietrich", "Mark Buckley"], "venue": "Teaching Mathematics and Computer Science", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Integrating Structured Queries into a Tactic Language. JAL - Special issue on Programming Languages and Mechanized Mathematics Systems Available at http://dx. doi.org/10.1007/s10817-009-9138-5", "author": ["Dominik Dietrich", "Ewaryst Schulz"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "Recording HOL Proofs in a Structured Browsable Format. In Michael Johnson, editor:  Algebraic Methodology and Software Technology, 6th International Conference, AMAST \u201997, Sydney, Australia", "author": ["Jim Grundy", "Thomas L\u00e5ngbacka"], "venue": "December 13-17,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 1997}, {"title": "Web-Based Evaluations Showing Differential Learning for Tutorial Strategies Employed by the Ms", "author": ["Neil T. Heffernan", "Ethan A. Croteau"], "venue": "editors: Intelligent Tutoring Systems, Lecture Notes in Computer Science", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2004}, {"title": "Reconstructing Proofs at the Assertion Level", "author": ["Xiaorong Huang"], "venue": "In Alan Bundy, editor: Proc. 12th CADE,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1994}, {"title": "Human Oriented Proof Presentation: A Reconstructive Approach", "author": ["Xiaorong Huang"], "venue": "DISKI", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 1996}, {"title": "Teaching logic using a state-of-the-art proof assistant", "author": ["Cezary Kaliszyk", "Freek Wiedijk", "Maxim Hendriks", "Femke van Raamsdonk"], "venue": "editors: Proc. of the International Workshop on Proof Assistants and Types in Education,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2007}, {"title": "An iterative design methodology for user-friendly natural language office information applications", "author": ["John F. Kelley"], "venue": "ACM Trans. Inf. Syst", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1984}, {"title": "Exploring the Assistance Dilemma in Experiments with Cognitive Tutors", "author": ["Kenneth R. Koedinger", "Vincent Aleven"], "venue": "Educational Psychology Review", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2007}, {"title": "Reifying implicit planning in geometry: Guidelines for model-based intelligent tutoring system design", "author": ["Kenneth R. Koedinger", "John R. Anderson"], "venue": "editors: Computers as cognitive tools,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 1993}, {"title": "How to write a proof", "author": ["Leslie Lamport"], "venue": "American Mathematical Monthly", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 1995}, {"title": "Artificial Intelligence in Education - Supporting Learning through Intelligent and Socially Informed Technology", "author": ["Chee-Kit Looi", "Gordon I. McCalla", "Bert Bredeweg", "Joost Breuker"], "venue": "Proceedings of the 12th International Conference on Artificial Intelligence in Education,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2005}, {"title": "Advanced Geometry Tutor: An intelligent tutor that teaches proofwriting with construction", "author": ["Noboru Matsuda", "Kurt VanLehn"], "venue": "In Looi et al", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2005}, {"title": "When and how often should worked examples be given to students? New results and a summary of the current state of research", "author": ["Bruce M. McLaren", "Sung-Joo Lim", "Kenneth R. Koedinger"], "venue": "Proceedings of the 30th Annual Conference of the Cognitive Science Society,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2008}, {"title": "Effective Tutoring Techniques: A Comparison of Human Tutors and Intelligent Tutoring Systems", "author": ["Douglas C. Merrill", "Brian J. Reiser", "Michael Ranney", "J. Gregory Trafton"], "venue": "The Journal of the Learning Sciences", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1992}, {"title": "Expansion Tree Proofs and Their Conversion to Natural Deduction Proofs", "author": ["Dale A. Miller"], "venue": "editor:  7th International Conference on Automated Deduction, Napa, California,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1984}, {"title": "Human Problem Solving", "author": ["Allen. Newell", "Herbert A. Simon"], "venue": null, "citeRegEx": "52", "shortCiteRegEx": "52", "year": 1972}, {"title": "The Aplusix-Editor: A New Kind of Software for the Learning of Algebra", "author": ["Jean-Franois Nicaud", "Denis Bouhineau", "Thomas Huguet"], "venue": "In Cerri et al", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2002}, {"title": "Learning from performance errors", "author": ["Stellan Ohlsson"], "venue": "Psychological Review", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 1996}, {"title": "The New Book of Prime Number Records", "author": ["Paulo Ribenboim"], "venue": null, "citeRegEx": "55", "shortCiteRegEx": "55", "year": 1996}, {"title": "Formalizing a Hierarchical Structure of Practical Mathematical Reasoning", "author": ["Peter J. Robinson", "John Staples"], "venue": "J. Log. Comput", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 1993}, {"title": "A comparative evaluation of socratic versus didactic tutoring", "author": ["Carolyn Penstein Ros\u00e9", "Johanna D. Moore", "Kurt Vanlehn", "David Allbritton"], "venue": null, "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2001}, {"title": "Granularity Analysis for Tutoring Mathematical Proofs", "author": ["Marvin Schiller"], "venue": "AKA Verlag,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2011}, {"title": "The AProS Project: Strategic Thinking & Computational Logic", "author": ["Wilfried Sieg"], "venue": "Logic Journal of the IGPL", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2007}, {"title": "Computer Environments for Proof Construction", "author": ["Wilfried Sieg", "Richard Scheines"], "venue": "Interactive Learning Environments", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 1994}, {"title": "How to read and do proofs", "author": ["Daniel Solow"], "venue": null, "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2005}, {"title": "A Proof Environment for Teaching Mathematics", "author": ["Richard Sommer", "Gregory Nuckols"], "venue": "Journal of Automated Reasoning", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2004}, {"title": "KERMIT: A Constraint-Based Tutor for Database Modeling", "author": ["Pramuditha Suraweera", "Antonija Mitrovic"], "venue": "In Cerri et al", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2002}, {"title": "Three Tactic Theorem Proving", "author": ["Don Syme"], "venue": "In Bertot et al", "citeRegEx": "65", "shortCiteRegEx": "65", "year": 1999}, {"title": "DECLARE: a prototype declarative proof system for higher order logic", "author": ["Donald Syme"], "venue": "Technical Report UCAM-CL-TR-416,", "citeRegEx": "66", "shortCiteRegEx": "66", "year": 1997}, {"title": "Automatic analysis of proof in a computer-based environment", "author": ["Jana Trgalova", "Hamid"], "venue": "Chaachoua", "citeRegEx": "67", "shortCiteRegEx": "67", "year": 2009}, {"title": "MENON - Automating a Socratic Teaching Model for Mathematical Proofs", "author": ["Dimitra Tsovaltzi"], "venue": "Phd thesis, Universita\u0308t des Saarlandes, Saarbru\u0308cken, Germany", "citeRegEx": "68", "shortCiteRegEx": "68", "year": 2010}, {"title": "The Behavior of Tutoring Systems. I", "author": ["Kurt VanLehn"], "venue": "J. Artificial Intelligence in Education", "citeRegEx": "69", "shortCiteRegEx": "69", "year": 2006}, {"title": "The Relative Effectiveness of Human Tutoring, Intelligent Tutoring Systems, and Other Tutoring Systems", "author": ["Kurt VanLehn"], "venue": "Educational Psychologist", "citeRegEx": "70", "shortCiteRegEx": "70", "year": 2011}, {"title": "Isar - A Generic Interpretative Approach to Readable Formal Proof Documents", "author": ["Markus Wenzel"], "venue": "In Bertot et al", "citeRegEx": "72", "shortCiteRegEx": "72", "year": 1999}, {"title": "Formal Proof Sketches", "author": ["Freek Wiedijk"], "venue": "editors: Types for Proofs and Programs: Third International Workshop TYPES", "citeRegEx": "73", "shortCiteRegEx": "73", "year": 2004}, {"title": "Linguistic Processing in a Mathematics Tutoring System: Cooperative Input Interpretation and Dialogue Modelling", "author": ["Magdalena Wolska", "Mark Buckley", "Helmut Horacek", "Ivana Kruijff-Korbayov", "Manfred Pinkal"], "venue": null, "citeRegEx": "74", "shortCiteRegEx": "74", "year": 2010}, {"title": "Building intelligent interactive tutors: Student-centered strategies for revolutionizing e-learning", "author": ["Beverly Park Woolf"], "venue": null, "citeRegEx": "75", "shortCiteRegEx": "75", "year": 2008}], "referenceMentions": [{"referenceID": 31, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 35, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 26, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 11, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 40, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 15, "context": "Mathematics is a key discipline in education and today, there exist strong systems to teach and tutor specific mathematical skills, such as mathematical computations, problem solving and geometry (see for instance, [49, 41, 46, 36, 14, 53, 33, 19] to name a few).", "startOffset": 215, "endOffset": 247}, {"referenceID": 34, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 67, "endOffset": 79}, {"referenceID": 32, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 67, "endOffset": 79}, {"referenceID": 53, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 67, "endOffset": 79}, {"referenceID": 47, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 150, "endOffset": 154}, {"referenceID": 10, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 183, "endOffset": 187}, {"referenceID": 29, "context": "Notable exceptions are the tutoring systems for geometrical proofs [45, 42, 67], as well as for pure formal logic proofs (such as the CMU proof tutor [61], the NovaNet Proof Tutorial [13] or Proofweb [39]).", "startOffset": 200, "endOffset": 204}, {"referenceID": 55, "context": "Following Van Lehn (see [69]), intelligent tutoring systems (ITSs) can be characterized as having both an outer loop and an inner loop.", "startOffset": 24, "endOffset": 28}, {"referenceID": 45, "context": "For instance, parts of the step analyser described in [58] have never", "startOffset": 54, "endOffset": 58}, {"referenceID": 22, "context": "been described in connection with the other parts of the final step analyzer or the final hint generation module [29].", "startOffset": 113, "endOffset": 117}, {"referenceID": 42, "context": "For example, Ribenboim gives eleven proofs that there are infinitely many primes (see [55] for details).", "startOffset": 86, "endOffset": 90}, {"referenceID": 48, "context": "However, proof search often happens in backward-style, and the proofs are reformulated in forward-style afterwards (see [62] p.", "startOffset": 120, "endOffset": 124}, {"referenceID": 14, "context": "The system was simulated via a specific software environment [17] and the help of four experienced human tutors.", "startOffset": 61, "endOffset": 65}, {"referenceID": 13, "context": "We obtained a corpus of tutorial dialogs [16] that allowed us to study the actions of students and tutors related to proof exercises illustrating the properties of binary relations.", "startOffset": 41, "endOffset": 45}, {"referenceID": 30, "context": "1Wizard-of-Oz experiments [40] simulate a complex system via a partial/prototype implementation that is assisted by a human expert (the \u201cwizard\u201d).", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "[15]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "To be able to also trace common student errors, a MTT typically provides a set of buggy rules (see [20]) that model incorrect reasoning.", "startOffset": 99, "endOffset": 103}, {"referenceID": 50, "context": "Constraint Based Tutors (CBTs), such as the SQL tutor (see [64]), are based on Ohlsson\u2019s theory of learning from performance errors (see [54]) and use constraints to describe abstract features of correct solutions.", "startOffset": 59, "endOffset": 63}, {"referenceID": 41, "context": "Constraint Based Tutors (CBTs), such as the SQL tutor (see [64]), are based on Ohlsson\u2019s theory of learning from performance errors (see [54]) and use constraints to describe abstract features of correct solutions.", "startOffset": 137, "endOffset": 141}, {"referenceID": 36, "context": "Example Tracing Tutors (ETTs), such as the stoichiometry tutor (see [48]), interpret a student\u2019s solution step with respect to a predefined solution graph that represents a generalized solution, which is often also called behavior graph (cf.", "startOffset": 68, "endOffset": 72}, {"referenceID": 39, "context": "[52]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 59, "context": "In order to have a clear separation of concern, we devised a clear, formal interface language for the kernel module, which serves as target for the natural language analysis component(s) that still need to be developed (see [74] for recent work on that topic).", "startOffset": 224, "endOffset": 228}, {"referenceID": 51, "context": "Our interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process.", "startOffset": 94, "endOffset": 113}, {"referenceID": 57, "context": "Our interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process.", "startOffset": 94, "endOffset": 113}, {"referenceID": 7, "context": "Our interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process.", "startOffset": 94, "endOffset": 113}, {"referenceID": 19, "context": "Our interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process.", "startOffset": 94, "endOffset": 113}, {"referenceID": 52, "context": "Our interface language for the kernel module is a declarative proof language (see for example [65, 72, 9, 26, 66]) that has been modified to support the elision of information that is typically required to facilitate the verification process.", "startOffset": 94, "endOffset": 113}, {"referenceID": 21, "context": "By allowing arbitrarily large gaps between the commands, one arrives at the notion of a proof plan [28] or proof sketch [73].", "startOffset": 99, "endOffset": 103}, {"referenceID": 58, "context": "By allowing arbitrarily large gaps between the commands, one arrives at the notion of a proof plan [28] or proof sketch [73].", "startOffset": 120, "endOffset": 124}, {"referenceID": 6, "context": "We use \u03a9mega\u2019s declarative proof script language presented in Figure 3 (see also [8]) as input language and allow underspecified proof scripts that are obtained by omitting \u201cby\u201d and \u201cfrom\u201d as well as the \u201cthus form\u201d in assume-proof steps.", "startOffset": 81, "endOffset": 84}, {"referenceID": 37, "context": "Human one-on-one tutoring is thought to be effective due to its very interactive nature and frequent (stepby-step) feedback [50].", "startOffset": 124, "endOffset": 128}, {"referenceID": 18, "context": "[25]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 56, "context": "A recent meta-analysis [70] determines that tutoring systems with step-based feedback are almost as effective as human tutoring, and more effective than systems that are answerbased (i.", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "While there exist techniques to convert (completed) resolution proofs or matrix proofs into natural deduction proofs, (see for example [4, 51]), it turns out that performing the proof search directly at a more abstract level is beneficial for the runtime of the reconstruction.", "startOffset": 135, "endOffset": 142}, {"referenceID": 38, "context": "While there exist techniques to convert (completed) resolution proofs or matrix proofs into natural deduction proofs, (see for example [4, 51]), it turns out that performing the proof search directly at a more abstract level is beneficial for the runtime of the reconstruction.", "startOffset": 135, "endOffset": 142}, {"referenceID": 27, "context": "To come close to the style of proofs as done by humans, Huang [37, 38] introduced the assertion-level, where individual proof steps are justified by axioms, definitions, or theorems, or even above at the so-called proof level, such as \u201cby analogy\u201d.", "startOffset": 62, "endOffset": 70}, {"referenceID": 28, "context": "To come close to the style of proofs as done by humans, Huang [37, 38] introduced the assertion-level, where individual proof steps are justified by axioms, definitions, or theorems, or even above at the so-called proof level, such as \u201cby analogy\u201d.", "startOffset": 62, "endOffset": 70}, {"referenceID": 22, "context": "The technique to obtain such inferences automatically from assertions follows the introduction and elimination rules of a natural deduction (ND) calculus [32] and can be found in [29].", "startOffset": 179, "endOffset": 183}, {"referenceID": 23, "context": "The proof step reconstruction algorithm is based on two main ideas (see [30] for details): (i) Represent the possible states the student might be in as so-called mental proof state (MPS).", "startOffset": 72, "endOffset": 76}, {"referenceID": 45, "context": "We have devised a framework to analyze the step size of proof steps [58], where a proof step can refer to either the single application of an inference rule, or consist of several (tacit) intermediate inference applications provided by the reconstruction algorithm.", "startOffset": 68, "endOffset": 72}, {"referenceID": 45, "context": "[58]) that are thought to be indicative of granularity, and classified as appropriate, too small, or to big according to a classifier.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "As discussed in [2], this might not be optimal, as students might abuse this functionality or refuse to ask the system for a hint; nevertheless it is the strategy that is used in most tutoring systems.", "startOffset": 16, "endOffset": 19}, {"referenceID": 46, "context": "The principle of progressively providing more concrete hints if required has been applied to a number of tutoring systems, including the Carnegie Proof Lab [60].", "startOffset": 156, "endOffset": 160}, {"referenceID": 5, "context": "In our approach, the provision of increasingly concrete hints is supported by a problem solver that generates a hierarchical solution (see [7] for details) based on proof strategies, where each (sub)invocation of a strategy introduces a new hierarchy in the computed solution.", "startOffset": 139, "endOffset": 142}, {"referenceID": 24, "context": "In contrast to other approaches that require to encode the knowledge in the underlying programming language of the system, we encode proof strategies in a separate strategy language (see [31, 8] for an overview).", "startOffset": 187, "endOffset": 194}, {"referenceID": 6, "context": "In contrast to other approaches that require to encode the knowledge in the underlying programming language of the system, we encode proof strategies in a separate strategy language (see [31, 8] for an overview).", "startOffset": 187, "endOffset": 194}, {"referenceID": 48, "context": "A simple proof strategy that is proposed in [62] is the \u201cForward-Backward Method\u201d, which combines the two well-known problem solving strategies: forward chaining and backward chaining: The method starts with backward chaining by matching the current proof goal with the conclusions of theorems and definitions and adding their premises as new goals to be proved.", "startOffset": 44, "endOffset": 48}, {"referenceID": 31, "context": "How should the next proof step be communicated to the user? A general issue in ITS design is how much scaffolding is to be provided to the learner, which is known as the \u201cassistance dilemma\u201d \u2013 both too much and too little assistance hamper learning [41].", "startOffset": 249, "endOffset": 253}, {"referenceID": 44, "context": "[57]) have been demonstrated to be superior to didactic teaching strategies, i.", "startOffset": 0, "endOffset": 4}, {"referenceID": 44, "context": "hinting based on direct instruction, especially regarding their long-term effects [57, 23, 5].", "startOffset": 82, "endOffset": 93}, {"referenceID": 3, "context": "hinting based on direct instruction, especially regarding their long-term effects [57, 23, 5].", "startOffset": 82, "endOffset": 93}, {"referenceID": 60, "context": "[75]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 54, "context": "Such a teaching strategy for the domain of mathematical proofs has been developed and automated by Tsovaltzi [68] and provides the background for our work.", "startOffset": 109, "endOffset": 113}, {"referenceID": 45, "context": "2) within a framework for judging granularity (presented in [58]).", "startOffset": 60, "endOffset": 64}, {"referenceID": 45, "context": "detail in [58]).", "startOffset": 10, "endOffset": 14}, {"referenceID": 45, "context": "[58]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "Following ideas from [12] the tutor system itself could record the hints given away in specific proof situations and try to assess how useful they were.", "startOffset": 21, "endOffset": 25}, {"referenceID": 46, "context": "We discuss our work in connection with related approaches that (i) focus on domain reasoning techniques for tutoring proofs in logics and mathematics (AProS and the Carnegie Proof Lab [60], the EPGY Proving Environment [63], Tutch [1] and approaches using hierarchical proofs), and (ii) hint generation (Carnegie Proof Lab, Andes [34] and the NovaNet Proof Tutorial [13]).", "startOffset": 184, "endOffset": 188}, {"referenceID": 49, "context": "We discuss our work in connection with related approaches that (i) focus on domain reasoning techniques for tutoring proofs in logics and mathematics (AProS and the Carnegie Proof Lab [60], the EPGY Proving Environment [63], Tutch [1] and approaches using hierarchical proofs), and (ii) hint generation (Carnegie Proof Lab, Andes [34] and the NovaNet Proof Tutorial [13]).", "startOffset": 219, "endOffset": 223}, {"referenceID": 0, "context": "We discuss our work in connection with related approaches that (i) focus on domain reasoning techniques for tutoring proofs in logics and mathematics (AProS and the Carnegie Proof Lab [60], the EPGY Proving Environment [63], Tutch [1] and approaches using hierarchical proofs), and (ii) hint generation (Carnegie Proof Lab, Andes [34] and the NovaNet Proof Tutorial [13]).", "startOffset": 231, "endOffset": 234}, {"referenceID": 10, "context": "We discuss our work in connection with related approaches that (i) focus on domain reasoning techniques for tutoring proofs in logics and mathematics (AProS and the Carnegie Proof Lab [60], the EPGY Proving Environment [63], Tutch [1] and approaches using hierarchical proofs), and (ii) hint generation (Carnegie Proof Lab, Andes [34] and the NovaNet Proof Tutorial [13]).", "startOffset": 366, "endOffset": 370}, {"referenceID": 46, "context": "The AProS project (see [60] for an overview) provides an integrated environment for strategic proof search and tutoring in natural deduction calculi for predicate logic.", "startOffset": 23, "endOffset": 27}, {"referenceID": 49, "context": "The Epgy theorem proving environment aims to support \u201cstandard mathematical practice\u201d both in how the final proofs look as well as the techniques students use to produce them (see [63] p.", "startOffset": 180, "endOffset": 184}, {"referenceID": 49, "context": "The authors acknowledge that the use of a classical ATP to verify proof steps has the following drawbacks ([63] p.", "startOffset": 107, "endOffset": 111}, {"referenceID": 0, "context": "Tutch (see [1]) is a proof checker that was originally designed for natural deduction proofs in propositional logic.", "startOffset": 11, "endOffset": 14}, {"referenceID": 33, "context": "Hierarchical proofs have been advocated by several people, such as Lamport [44] in the context of informal proofs.", "startOffset": 75, "endOffset": 79}, {"referenceID": 8, "context": "A similar idea is proposed by Back and colleagues for calculational proofs [11, 10].", "startOffset": 75, "endOffset": 83}, {"referenceID": 25, "context": "In the context of HOL, Grundy and Langbacka [35] developed an algorithm to present hierarchical proofs in a browsable format.", "startOffset": 44, "endOffset": 48}, {"referenceID": 43, "context": "Another possibility for hierarchical proof construction is provided by a method called window inference [56].", "startOffset": 104, "endOffset": 108}, {"referenceID": 17, "context": "Our approach is based on previous work by Cheikhrouhou and Sorge who developed the hierarchical proof data structure PDS in an earlier version of the \u03a9mega system, intended to support hierarchical proof presentation and proof search [22].", "startOffset": 233, "endOffset": 237}, {"referenceID": 20, "context": "The same idea has been picked up by Denney, who developed the notion of hiproof [27].", "startOffset": 80, "endOffset": 84}, {"referenceID": 4, "context": "Most recently, a tactic language for hiproofs has been proposed in [6].", "startOffset": 67, "endOffset": 70}, {"referenceID": 15, "context": "MathsTiles [19] are a flexible language to be used as an interface for an intelligent book on mathematics.", "startOffset": 11, "endOffset": 15}, {"referenceID": 15, "context": "However, the approach in [19] checks proofs linearly.", "startOffset": 25, "endOffset": 29}, {"referenceID": 10, "context": "The NovaNet Proof Tutorial [13] is a learning tool for logic proofs.", "startOffset": 27, "endOffset": 31}], "year": 2012, "abstractText": "Reasoning: The Assertion Level. To come close to the style of proofs as done by humans, Huang [37, 38] introduced the assertion-level, where individual proof steps are justified by axioms, definitions, or theorems, or even above at the so-called proof level, such as \u201cby analogy\u201d. The idea of the assertion-level is, for instance, that given the facts U \u2282V and V \u2282W we can prove U \u2282W directly using the assertion: \u2282Trans: \u2200U.\u2200V.\u2200W.U \u2282V \u2227V \u2282W \u21d2U \u2282W An assertion level step usually subsumes several deduction steps in a standard calculus, say the classical sequent calculus [32]. Therefore, traditional theorem provers can only achieve such conclusions after a number of proof steps. To use an assertion in the classical sequent calculus, it must be present in the antecedent of the sequent and be processed by means of decomposition rules, usually leading to new branches in the derivation tree. Some of these branches are subsequently closed by means of the axiom rule which correspond to \u201cusing\u201d that assertion on known facts or goals. The technique to obtain such inferences automatically from assertions follows the introduction and elimination rules of a natural deduction (ND) calculus [32] and can be found in [29]. The Reconstruction Algorithm. The proof step reconstruction algorithm is based on two main ideas (see [30] for details): (i) Represent the possible states the student might be in as so-called mental proof state (MPS). (ii) Given a new proof step and a MPS, perform a depth-limited BFS at the assertion level, trying to derive one/several successor states that are consistent with the student\u2019s utterance, where the consistency is proof command specific. The depth limiter imposes an upper bound on the number of assertion level inferences that are assumed to be contained implicitly in the student\u2019s input.2 Whether this limit is sufficient depends on (i) the step size of the available proof mechanism and (ii) the experience of the student, as we discuss in Section 3.2. We have determined such a bound empirically for the corpus of students\u2019 proof steps from the Wizard-of-Oz experiments, as discussed in Section 5. The bound is needed to guarantee termination of the reconstruction algorithm, which might otherwise not terminate. Figure 5 shows an example reconstruction of a complete dialog taken from the corpus. In the figure, the shaded formulas correspond to the steps entered by the student. The white formulas correspond to assertions the student has left out and which were filled in by the reconstruction module. A MPS is represented as a set of sequents that are the subproblems to be solved, together with a global substitution which instantiates meta-variables. One of these sequents is always marked and represents the sequent the student is working on. Always keeping track of the student\u2019s subgoals facilitates task sensitive feedback. 2Note that the correspondence of student steps to calculus steps may vary for each calculus. Autexier, Dietrich, Schiller 11 (x,y) \u2208 S \u25e6R \u22a2 \u201d\u2014\u201d Ax (z,y) \u2208 R\u22121 \u2227 (x,z) \u2208 S\u22121 \u22a2 \u201d\u2014\u201d Def\u25e6 (y,z) \u2208 R\u2227 (x,z) \u2208 S\u22121 \u22a2 \u201d\u2014\u201d Def\u22121 (y,z) \u2208 R\u2227 (z,x) \u2208 S \u22a2 \u201d\u2014\u201d Def\u22121 (y,x) \u2208 (R\u25e6S) \u22a2 \u201d\u2014\u201d Def\u25e6 (x,y) \u2208 (R\u25e6S) \u22a2 (x,y) \u2208 S \u25e6R Def\u22121 (R\u25e6S) \u2282 S \u25e6R Def \u2282 (x,y) \u2208 (R\u25e6S) \u22a2 \u201d\u2014\u201d Ax (y,x) \u2208 (R\u25e6S) \u22a2 \u201d\u2014\u201d Def\u22121 (z,x) \u2208 S\u2227 (y,z) \u2208 R \u22a2 \u201d\u2014\u201d Def\u25e6 (x,z) \u2208 S\u22121 \u2227 (y,z) \u2208 R \u22a2 \u201d\u2014\u201d Def (x,z) \u2208 S\u22121 \u2227 (z,y) \u2208 R\u22121 \u22a2 \u201d\u2014\u201d Def (x,y) \u2208 S \u25e6R \u22a2 (x,y) \u2208 (R\u25e6S) Def\u25e6 S \u25e6R \u2282 (R\u25e6S) Def \u2282 \u22a2 (R\u25e6S)\u22121 = S\u22121 \u25e6R\u22121 Def = Figure 5: Annotated \u03a9mega assertion level proof Initially, the MPS is unique and consists of the exercise given to the student as single sequent, together with the empty substitution. During the search, an invariant is that a MPS always represents a valid proof state. By expanding a given proof state only by valid actions, it is guaranteed that only reachable and consistent proof states are generated. Let us stress again that due to ambiguity and underspecification several consistent successor states are possible (as in the case of statement S8b shown in Figure 1 where the next subgoal the student will work on is underspecified). There can also be several reconstructions for a given proof step. Therefore, the verification algorithm works on a list of MPS rather than on a single one. While the reconstruction algorithm might look similar to the processing model of proof commands in a pure verification setting, there are the following subtle differences: \u2022 In a pure verification setting, it is sufficient to find some verification for a proof command. The verification itself is usually not of interest and needs not to be further processed. In contrast, in a tutorial setting we need to consider several, if not all, possible verifications of the given proof command and need to relate them to the student\u2019s knowledge to avoid the student to rely on the power of the underlying theorem prover to solve the exercise. \u2022 In a pure verification setting, we can assume the user to be an expert in the problem domain as well as in the field of formal reasoning. This has several implications on the processing model: (i) inputs can be expected to be correct and just need to be checked, (ii) proof commands can lazily be verified until a (sub)proof is completed, (iii) justification hints are given that indicate how to verify a given proof command, (iv) feedback is limited to \u201ccheckable\u201d or \u201cnot checkable\u201d. In contrast, in a tutorial setting, we must assume the user to be neither a domain expert nor an expert in formal reasoning. The underlying mechanisms need to be hidden from the user, direct and comprehensive feedback has to be provided at each step. Therefore, it is for example a requirement to anticipate why an assumption is made, in contrast to a lazy checking once the conclusion has been obtained. \u2022 In a pure verification setting, we can assume the user to indicate when the proof of a subgoal is finished (as usually done by so-called proof step markers in the proof language). However, in the tutorial setting this information is implicit. Similarly, we must be able to perform backward steps where some of the new proof obligations have not yet been shown. In order to illustrate how the verification algorithm works, we will step through the verification of utterance S8 from Figure 1, beginning with the initial MPS and finishing with the MPS extended by the proof step. The initial MPS is {\u3008\u22a2 (R\u25e6S)\u22121 = S\u22121 \u25e6R\u22121; / 0\u3009} and the proof step to be verified is let (x,y) \u2208 (R\u25e6S)\u22121. 12 Towards an Intelligent Tutor for Mathematical Proofs Having expanded the current proof state (step (i), shown in Figure 6), we apply a let-proof step specific filter to find the set of newly-created sequents which are consistent with the given proof step. Of the sequents in the tree, only the node containing the sequent Tk passes, since the formula in the proof step appears on the left-hand side of the sequent. Now that we have found the consistent successor sequents, we must complete these sequents to MPSs. Because the decomposition of the sequent T0 introduced a subgoal split, the sequent Tj must be proved in addition to Tk. The resulting MPS is therefore {\u3008Tk,Tj; / 0\u3009}, that is, Tk is now the current sequent, and Tj is still to be proved. Finally, we prune the nodes which were rejected by the filter. Relevance Checking. Using the proof step reconstruction mechanism for each proof step allows our approach to perform a form of relevance checking when a hypothesis is introduced. A hypothesis introduced by the student is matched against a proof search in \u03a9mega, and considered relevant only if it can be unified with a step that is part of one of the partial solutions that are discovered via strategic proof search. In practice, it turns out that it is very important for a tutoring system to enable a broad range of people to create content for the system in form of exercises and domain expertise. One of the main advantages of our approach is to use existing mature representation and search technology that has been developed over the last decades in the context of ITP/ATP. New domains can easily be added by users either by relying on already existing specifications of formalized mathematics, or by writing new specifications from scratch. That is, the only information the author has to provide is a problem description and the knowledge needed to solve the problem. As inferences are automatically synthesized from theorems and definitions, it is sufficient to provide this knowledge in a declarative form. For simple domains, this is already sufficient and there is a high chance that modifications of existing proofs or even new proofs are recognized by the tutor. For more complex domains in which the reasoning is more complicated, the author also has to provide strategic information on how to solve a problem. 3.2 Granularity Analysis In addition to verifying the correctness of proof steps generated by the student, and to detect steps that are logically incorrect, we use proof reconstructions to judge about another qualitative aspect of proof steps: granularity. By assessing the step size (in the context of the ongoing proof and a student model), a tutoring system for proofs can react if the student\u2019s solution lacks necessary detail, or, to the contrary, the student is progressing at smaller steps than expected, and adapt feedback and hints accordingly. Having a metric for step size also allows the system to generate and present hierarchical proofs (or steps to be used as hints) at specific levels of granularity. T0 : \u22a2 (R\u25e6S)\u22121 = S\u22121 \u25e6R\u22121 Ti : \u22a2 (R\u25e6S)\u22121 \u2286 S\u22121 \u25e6R\u22121 Tk : (x,y) \u2208 (R\u25e6S)\u22121 \u22a2 (x,y) \u2208 S\u22121 \u25e6R\u22121 . . . Tl Tj : \u22a2 (R\u25e6S)\u22121 \u2287 S\u22121 \u25e6R\u22121", "creator": "LaTeX with hyperref package"}}}