{"id": "1203.4523", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Mar-2012", "title": "On the Equivalence between Herding and Conditional Gradient Algorithms", "abstract": "We biochem show that the ef0 herding procedure of 59.67 Welling (2009) takes attractive exactly clutch the 1-d form of servizio a standard convex optimization keihin algorithm - - polari namely a tepito conditional tante gradient overexpressing algorithm minimizing a quadratic campeonatos moment discrepancy. adia This labella link 86.0 enables us to invoke oberman convergence results fenster from boosh convex optimization glater and 986 to consider ziese faster alternatives tadpoles for the seductive task of helmeted approximating chrismation integrals in 42-31 a serapong reproducing chithra kernel Hilbert 2,613 space. mini-estrella We siad study humadi the behavior joshi of the different brianna variants through kerber numerical displaysearch simulations. The lundberg experiments indicate balochi that lonchakov while sasser we can improve autoglass over geninho herding bfe on snowglobe the flavigny task of approximating integrals, the audiogalaxy original knapdale herding algorithm tends to approach asthana more munton often monotonically the maximum fsh entropy tamandar\u00e9 distribution, shedding a330s more becora light shut on the learning 2,805 bias print behind herding.", "histories": [["v1", "Tue, 20 Mar 2012 17:49:56 GMT  (344kb)", "https://arxiv.org/abs/1203.4523v1", null], ["v2", "Tue, 11 Sep 2012 08:35:39 GMT  (115kb)", "http://arxiv.org/abs/1203.4523v2", null]], "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["francis r bach", "simon lacoste-julien", "guillaume obozinski"], "accepted": true, "id": "1203.4523"}, "pdf": {"name": "1203.4523.pdf", "metadata": {"source": "META", "title": "On the Equivalence between Herding and Conditional Gradient Algorithms", "authors": ["Francis Bach", "Simon Lacoste-Julien", "Guillaume Obozinski"], "emails": ["firstname.lastname@inria.fr"], "sections": [{"heading": null, "text": "ar X\niv :1\n20 3.\n45 23\nv2 [\ncs .L\nG ]\n1 1\nSe p\n20 12"}, {"heading": "1. Introduction", "text": "The herding algorithm has recently been presented by Welling (2009b) as a computationally attractive alternative method for learning in intractable Markov random fields models (MRF). Instead of first estimating the parameters of the MRF by maximum likelihood / maximum entropy (which requires approximate inference to estimate the gradient of the partition function), and then sampling from the learned MRF to answer queries, herding directly generates pseudosamples in a deterministic fashion with the property of asymptotically matching the empirical moments of the data (akin to maximum entropy). The herding algorithm generates pseudo-samples xt with the following simple recursion:\nxt+1 \u2208 argmax x\u2208X \u3008wt,\u03a6(x)\u3009 wt+1 = wt + \u00b5\u2212 \u03a6(xt+1),\n(1)\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nwhere X is the observation space; \u03a6 is a feature map from X to F , which could be viewed as the vector of sufficient statistics for some exponential family, and \u00b5 is a mean vector to match (the empirical moment vector of the same family). Unlike in frequentist learning of MRFs, the parameter wt never converges to a point in herding and actually follows a \u201cweakly chaotic\u201d walk (Welling & Chen, 2010).\nThe herding updates can be motivated from two different perspectives. From the learning perspective, the herding updates can be derived by performing fixedstep-size subgradient ascent on the zero-temperature limit of the annealed likelihood function of the MRF\u2014 called the \u201ctipi function\u201d by Welling (2009b). From this perspective, herding was later generalized to MRFs with latent variables (Welling, 2009a) as well as discriminative MRFs (Gelfand et al., 2010).\nFrom the moment matching perspective, which has been explored more in details by Chen et al. (2010), the herding updates can be derived as an effective way to choose greedily pseudo-samples xt in order to quickly decrease the moment discrepancy Et .= \u2016\u00b5 \u2212 1t \u2211t i=1 \u03a6(xi)\u2016 (Chen et al., 2010). Under suitable regularity conditions, Et decreases as O(1/t) for the herding updates\u2014this is faster than i.i.d. sampling from the distribution generating \u00b5 (e.g., the training data) which would yield the slower O(1/ \u221a t) rate. This faster rate has been explained by negative autocorrelations amongst the pseudo-samples and was used by Chen et al. (2010) to sub-select a small collection of representative \u201csuper-samples\u201d from a much larger set of i.i.d. samples. We make the following contributions:\n\u2013 We show that herding as described by Eq. (1) is equivalent to a specific type of conditional gradient algorithm (a.k.a. Frank-Wolfe algorithm) for the problem of estimating the mean \u00b5. This provides a novel understanding and another explicit cost function that herding is minimizing.\n\u2013 This interpretation yields improvements, for the task of estimating means, with other faster variants of the conditional gradient algorithm, which lead to\nnon-uniform weights, one based on line-search, one based on an active-set algorithm.\n\u2013 Based on existing results from convex optimization, we extend and improve the convergence results of herding. In particular, we provide a linear convergence rate for the line-search variant in finitedimensional settings and show how the conditions assumed by Chen et al. (2010) in fact never hold in the infinite-dimensional setting.\n\u2013 We run experiments that show that algorithms which estimate faster the mean than herding generate samples that are not better (and typically worse) than the ones obtained with herding when evaluated in terms of the ability to approximate a sample with large entropy, a property which (if or when satisfied by herding) could be the basis for an interpretation of herding as a learning algorithm (Welling, 2009b)."}, {"heading": "2. Mean estimation", "text": "We start with a similar setup as Chen et al. (2010), where herding can be interpreted as a way to approximate integrals of functions in a reproducing kernel Hilbert space (RKHS). We consider a set X and a mapping \u03a6 from X to a RKHS F . Through this mapping, all elements of F may be identified with real functions f on X defined by f(x) = \u3008f,\u03a6(x)\u3009, for x \u2208 X . We denote by k : (x, y) 7\u2192 k(x, y) the associated positive definite kernel. Note that the mapping \u03a6 may be explicit (classically in low-dimensional settings) or implicit\u2014where the kernel trick can be used, see Section 4.3 and Chen et al. (2010).\nThroughout the paper, we assume that the data is uniformly bounded in feature space, that is, for all x \u2208 X , \u2016\u03a6(x)\u2016 6 R, for some R > 0; this condition is needed for the updates of Eq. (1) to be well-defined.\nWe denote by M \u2282 F the marginal polytope (Wainwright & Jordan, 2008; Chen et al., 2010), i.e., the convex-hull of all vectors \u03a6(x) for x \u2208 X . Note that for any f \u2208 F , we have\nsup x\u2208X f(x) = sup g\u2208M\n\u3008f, g\u3009,\nand that |f(x)| = |\u3008f,\u03a6(x)\u3009| 6 \u2016f\u2016R for all x \u2208 X and f \u2208 F (i.e., all functions with finite norm are bounded).\nExtreme points of the marginal polytope. In all the cases we consider in Section 5, it turns out that all points of the form \u03a6(x), x \u2208 X are extreme points of M (see an illustration in Figure 1). This is indeed always true when \u2016\u03a6(x)\u2016 is constant for all x \u2208 X (for example for our infinite-dimensional kernels on [0, 1] in Section 5.1); it is also true if \u03a6(x) contains both an\ninjective feature map \u03a6\u0303(x) and its self-tensor-product\n\u03a6\u0303(x)\u2297 \u03a6\u0303(x), which is the case in the graphical model examples in Section 5.2.\nMean element and expectation. We consider a fixed probability distribution p(x) over X . Following Chen et al. (2010), we denote by \u00b5 the mean element (see, e.g., Smola et al., 2007):\n\u00b5 = Ep(x)\u03a6(x) \u2208 M.\nNote that in the learning perspective, p is the empirical distribution on the data and so \u00b5 is the corresponding empirical moment vector to match. To approximate this mean, we consider n points x1, . . . , xn \u2208 X combined linearly with positive weights w1, . . . , wn that sum to one. These define p\u0302, the associated weighted empirical distribution, and \u00b5\u0302 the approximating mean:\n\u00b5\u0302 = Ep\u0302(x)\u03a6(x) = \u2211n i=1 wi\u03a6(xi) \u2208 M. (2)\nFor all functions f \u2208 F , we then have\nEp(x)f(x) = Ep(x)\u3008f,\u03a6(x)\u3009 = \u3008\u00b5, f\u3009,\nand similarly Ep\u0302(x)f(x) = \u3008\u00b5\u0302, f\u3009. We thus get, using Cauchy-Schwarz inequality,\nsupf\u2208F , \u2016f\u2016=1 |Ep(x)f(x)\u2212 Ep\u0302(x)f(x)| = \u2016\u00b5\u2212 \u00b5\u0302\u2016,\nand controlling \u00b5 \u2212 \u00b5\u0302 is enough to control the error in computing the expectation for all f \u2208 F with finite norm. Note that a random i.i.d. sample from p(x) would lead to an expected worst-case error which is less than 4R\u221a\nn \u2014a classical result based on Rademacher\naverages (see, e.g. Boucheron et al., 2005).\nIn this paper, we will try to find a good estimate \u00b5\u0302 of \u00b5 based on a weighted set of points from {\u03a6(x), x \u2208 X}, generalizing Chen et al. (2010), and show how this relates to herding."}, {"heading": "3. Related work", "text": "This paper brings together three lines of work, namely the approximation of integrals, herding and convex optimization. The links between the first two were clearly outlined by Chen et al. (2010), while the present paper provides the novel interpretation of herding as a well-established convex optimization algorithm."}, {"heading": "3.1. Quadrature/cubature formulas", "text": "The evaluation of expectation, or equivalently of integrals, is a classical problem in numerical analysis. When the input space X is a compact subset of Rp and p(x) is the density of the distribution with respect to the Lebesgue measure, then this is equivalent to evaluating the integral \u222b X f(x)p(x)dx. Quadrature formulas are aimed at computing such integrals as a weighted combinations of values of f at certain points, which is exactly the problem we consider in Section 2.\nAlthough a thorough review of quadrature formulas is outside of the scope of this paper, we mention two methods which are related to our approach. First, given a positive definite kernel and a given set of points (typically sampled i.i.d. from a given distribution), the Bayes-Hermite quadrature of O\u2019Hagan (1991) essentially computes an orthogonal projection of \u00b5 onto the affine hull of this set of points. This does not lead to positive quadrature weights, and one may thus replace the affine hull by the convex hull to obtain such nonnegative weights, which we do in our experiments in Section 5.\nMoreover, quasi-Monte Carlo methods consider sequences of so-called \u201cquasi-random\u201d quadrature points so that the empirical average approaches the integral. These quasi-random sequences are such that the approximation error goes down as O(1/n) (up to logarithmic terms) for functions of bounded variation, as opposed to O(1/ \u221a n) for a random sequence. In simulations, we used a Sobol sequence (see, e.g., Morokoff & Caflisch, 1994)."}, {"heading": "3.2. Franke-Wolfe algorithms", "text": "Given a smooth (twice continuously differentiable) convex function J on a compact convex set M with gradient J \u2032, Frank-Wolfe algorithms are a class of iterative optimization algorithms that only require (in addition to the computation of the gradient J \u2032) to be able to optimize linear functions on M. The first class of such algorithms is often referred to as conditional gradient algorithms: given an iterate gt, the minimum of \u3008J \u2032(gt), g\u3009 over g \u2208 M is computed, and the next iterate is taken on the segment between gt and g, i.e., gt+1 = \u03c1tgt+(1\u2212\u03c1t)g, where \u03c1t \u2208 [0, 1]. There are two natural choices for \u03c1t, (a) simply taking \u03c1t = 1/(t+1) and (b) performing a line search to find the point in the segment with optimal value (either for J or for a quadratic upper-bound of J). These are illustrated in Figure 2, and convergence rates are detailed in Section 4.2. Moreover, for quadratic functions, the conditional gradient algorithm with step sizes \u03c1t = 1/(t+1) has a dual interpretation as subgradient ascent (see, e.g., Bach, 2011), which we outline in Section 4.1.\nFinally, in order to minimize the number of iterations, a variant known as the minimum-norm-point algorithm will find gt+1 that minimizes J on the convex hull of all previously visited points, using a specific active-set algorithm (see Bach, 2011, Sec. 6, for details). For convex sets with finitely many extreme points, it converges in a finite number of iterations with higher (though still polynomial) iteration computational cost (Wolfe, 1976)."}, {"heading": "4. Herding as a Frank-Wolfe algorithm", "text": "To relate herding with conditional gradient algorithms, we consider the following optimization problem:\nmin g\u2208M\nJ(g) = 1\n2 \u2016g \u2212 \u00b5\u20162, (3)\nwith the trivial unique solution \u00b5. A conditional gradient algorithm to solve this optimization problem with stepsize \u03c1t = 1/(t+ 1) use the iterates\ng\u0304t+1 \u2208 arg min g\u2208M \u3008gt \u2212 \u00b5, g\u3009, gt+1 = (1\u2212 \u03c1t) gt + \u03c1t g\u0304t+1. (4)\nBut these updates are exactly the same as herding via the change of variable gt = \u00b5 \u2212 wt/t. Indeed, the minimizer of a linear function of a convex set g\u0304t+1 can be restricted to be an extreme point of M; this implies that g\u0304t+1 = \u03a6(xt+1) for a certain xt+1. The herding updates in Eq. (1) are thus equivalent to the conditional gradient minimization of J with step size given by \u03c1t = 1/(t+ 1).\nWith this choice of step size, we get (t + 1)gt+1 = tgt+\u03a6(xt+1), that is gt = 1 t \u2211t u=1 \u03a6(xu), and we thus get uniform weights in Eq. (2).\nFor general step-sizes \u03c1t \u2208 [0, 1], if we assume that we start the algorithm with \u03c10 = 1 (which implies g1 = \u03a6(x1)), then we get that gt = \u2211t\nu=1 (\u220ft\u22121 v=u(1 \u2212\n\u03c1v\u22121)\u03c1u\u22121 ) \u03a6(xu), which thus leads to non-uniform weights in Eq. (2), though they still sum to one. The conditional gradient updates in Eq. (4) can thus be seen as a generic algorithm to obtain a weighted set of points to approximate \u00b5, and traditional herding is the \u03c1t = 1/(t+ 1) step-size case.\nA second choice of step-size for t \u2265 1 is to use a line search, which leads in this setting (where the global\nunconstrained minimum happens to belong to M) to \u03c1t =\n\u3008gt\u2212\u00b5,gt\u2212g\u0304t+1\u3009 \u2016g\u0304t+1\u2212gt\u20162 \u2208 [0, 1]. This leads to a variant of\nherding with non-uniform weights.\nWe finally comment on the initialization g0 for the updates in Eq. (4). In the kernel herding algorithm of Chen et al. (2010), the authors use w0 = \u00b5 as this is required to interpret the herding updates as greedily minimizing Et (with the additional assumptions that \u2016\u03a6(x)\u2016 is constant). In our setting, this corresponds to choosing g0 = 0 (which might be outside ofM, though this is not problematic in practice). Another standard choice (for MRFs in particular) is to use w0 = 0 (g0 = \u00b5), which means that the first point x1 is chosen randomly from the extreme points of M\u2014this is the scheme we used. As is common in convex optimization, we didn\u2019t see any qualitative difference in our experiments between the two types of initialization."}, {"heading": "4.1. Dual problem and subgradient descent", "text": "Welling (2009b) proposed originally an algorithmic interpretation of herding as performing subgradient ascent with constant step size on a function obtained as the zero temperature limit of the log-likelihood of an exponential model that he called the \u201ctipi function\u201d. Our interpretation of the procedure as a FrankWolfe algorithm might therefore appear as a conflicting interpretation at first sight. To establish a natural connection between these two interpretations, we can compute the Fenchel-dual optimization problem to Eq. (3). Indeed, we have (with standard arguments for swapping the min and max operations):\nmin g\u2208M\n1 2 \u2016g \u2212 \u00b5\u20162 = min g\u2208M max f\u2208F f\u22a4(g \u2212 \u00b5)\u2212 1 2 \u2016f\u20162\n= max f\u2208F min g\u2208M f\u22a4(g \u2212 \u00b5)\u2212 1 2 \u2016f\u20162\n= max f\u2208F { min x\u2208X f(x)\u2212 \u3008f, \u00b5\u3009 \u2212 1 2 \u2016f\u20162 } .\nThe dual function f 7\u2192 minx\u2208X f(x)\u2212\u3008f, \u00b5\u3009\u2212 12\u2016f\u20162 is 1-strongly concave and non-differentiable, and a natural algorithm to maximize it is thus subgradient ascent with a step size equal to 1t+1 , which is known to be equivalent to the primal conditional gradient algorithm with step sizes \u03c1t = 1/(t + 1) (Bach, 2011, App. A). It is therefore not surprising that herding is equivalent to subgradient ascent with a decreasing stepsize on this function (with the identification ft = gt \u2212 \u00b5 = \u2212wt/t). The presence of the squared norm which is added to the \u201ctipi function\u201d merely reflects the change of scaling between gt and wt. It is worthwhile mentioning that other functions, like Bregman divergences, would have led to a different dual function hence adding a different term than a squared norm to the \u201ctipi function\u201d."}, {"heading": "4.2. Convergence analysis", "text": "Without further assumptions on the problem, then the two choices of step sizes lead to a convergence rate of the form (Dunn, 1980; Bach, 2011):\n1 2 \u2016gt \u2212 \u00b5\u20162 6 4\nR2\nt ,\nwhere R is diameter of the marginal polytope. Note that the convergence in O(1/t) does not lead to improved estimation of integrals over random sampling. Moreover, without further assumptions, current theoretical analysis does not allow to distinguish between the two forms of conditional gradient algorithms (although they differ a bit in practice, see Section 5).\nHowever, if we assume that within the affine hull of M, there exists a ball of center \u00b5 and radius d > 0 that is included in M (i.e., \u00b5 is in the relative interior of M), then both choices of step sizes yield faster rates than random sampling. For the version with line search, we actually obtain a linear convergence rate (Beck & Teboulle, 2004):\n1 2 \u2016gt \u2212 \u00b5\u20162 6 R2 exp\n( \u2212 d 2t R2 ) .\nFor the version without line search (\u03c1t = 1/(t + 1)), Chen et al. (2010) shows the slower convergence rate in O(1/t2):\n1 2 \u2016gt \u2212 \u00b5\u20162 6\n2R4 d2t2 .\nConcerning the assumption that \u00b5 is in the relative interior of M, we now show that in finite-dimensional settings, this assumption is always satisfied under reasonable conditions, while it is never satisfied in a large class of infinite-dimensional settings (namely for Mercer kernels).\nWe first provide an equivalent definition of this condition which is used in the proofs. Let A be the affine hull of M, \u00b50 the orthogonal projection of 0 on A, and F\u0303 the space of directions (or difference space) of A (i.e., F\u0303 = A\u2212 \u00b50).1 Now there exists d > 0 so that any element of A which is at distance less than d of \u00b5 is in M if and only if \u2200f \u2208 F , the maximum of f\u22a4g over g \u2208 A and \u2016g\u2212 \u00b5\u2016 6 d is less than the maximum of f\u22a4g over g \u2208 M. Given the properties of A and F\u0303 , this is equivalent to:\n\u2200f \u2208 F\u0303 , max \u2016g\u2212\u00b5\u20166d f\u22a4g 6 max g\u2208M f\u22a4g\n\u21d4 \u2200f \u2208 F\u0303 , \u3008\u00b5, f\u3009+ d\u2016f\u2016 6 max x\u2208X f(x). (5)\nProposition 1 Assume that F is finite-dimensional, that X is a compact topological measurable space with\n1It turns out that \u00b50 is a function taking a constant value since the orthogonality condition yields \u3008\u00b50,\u03a6(x) \u2212 \u03a6(y)\u3009 = 0, i.e., \u00b50(x) = \u00b50(y) for all x, y \u2208 X , by the reproducing property of F .\na continuous kernel function, and that the distribution p has full support on X . Then \u2203d > 0 so that Eq. (5) is true. Proof sketch. It is sufficient to show that \u2126 : f 7\u2192 maxx\u2208X f(x) \u2212 \u3008\u00b5, f\u3009 is a norm on F\u0303 : as all norms are equivalent in finite dimensions, we get d\u2016f\u2016 \u2264 \u2126(f) for some d > 0, yielding Eq. (5). \u2126 is convex and positively homogeneous by construction. Now \u2126(f) = 0 implies that Ep(x)[f(x) \u2212 maxy f(y)] = 0, and thus f(x) = maxy f(y) for x in the support of p (assumed to be X ) using the fact that f is continuous (since the kernel is continuous), and so f is a constant function. We then have two possibilities: either \u00b50 = 0, in which case one can show that there is no non-zero constant functions in F ; otherwise f = \u03b1\u00b50 for some \u03b1 and thus the orthogonality condition \u3008f, \u00b50\u3009 = 0 implies that \u03b1 = 0. Both cases imply f = 0, hence \u2126 is a norm.\nProposition 2 Assume X is a compact subspace of R\nd, and that the kernel k is a continuous function on X \u00d7 X . If F is infinite-dimensional, then there exists no d > 0 so that Eq. (5) is true. Proof sketch. We can apply Mercer theorem to the kernel k\u0303(x, y) of the projection onto the orthogonal of {\u00b5, \u00b50}. This kernel is also a Mercer kernel, and we get an orthonormal basis (ek)k>1 of L\n2(X ) with countably many eigenvalues \u03bbk that are summable. Moreover, (\u03bb 1/2 k ek)k>1 is known to be an orthonormal basis of the associated feature space F (Cucker & Smale, 2002), and for all x, y \u2208 X , k\u0303(x, y) = \u2211k>1 \u03bbkek(x)ek(y), with uniform convergence. This implies that for fk = \u03bb 1/2 k ek, we have \u2016fk\u2016 = 1, and \u3008fk, \u00b50\u3009 = \u3008fk, \u00b5\u3009 = 0.\nIf we assume that there exists d > 0 so that Eq. (5) is true, then we have for all k > 1, maxx\u2208X |fk(x)| > d. Since X is compact, there exists a cover of F with finitely many balls of radius d/4R. Let Y be the finite set of centers. Since all functions fk are Lipschitzcontinuous with constant 2R, then for all k > 1, maxx\u2208Y |fk(x)| > d \u2212 2R \u00d7 d/4R = d/2. Since Y is finite, there exists x \u2208 Y so that |fk(x)| > d/2 > 0 for infinitely many values of k; this contradicts the summability of \u2211 k>1 fk(x) 2. Hence the result.\nThe last proposition shows that the current theory only supports the slower rates of O(1/t) for the two conditional gradient algorithms in infinite-dimensional settings. On the other hand, we note that, in some cases, traditional herding performs empirically better without known theoretical justification (see Section 5)."}, {"heading": "4.3. Computational issues", "text": "In order to run a herding algorithm, there are two potential computational bottlenecks:\nComputing expectations \u3008\u00b5,\u03a6(x)\u3009: in a learning\ncontext (empirical moment matching), these are done through an empirical average. In an integral evaluation context, in finite-dimensional settings, one needs to compute Ep(x)\u03a6(x); while in an infinite-dimensional setting, following Chen et al. (2010), expectations of the form Ep(x)k(x, y) need to be computed. This can be done for some pairs of kernels/distributions, like the ones we choose in Section 5, but not in general.\nMinimizing \u3008gt \u2212 \u00b5,\u03a6(x)\u3009 with respect to x \u2208 X : in general, this computation may be relatively hard (it is for example NP-hard in the context of the graphical models we consider in Section 5). In practice, Chen et al. (2010) and Welling (2009a) perform local search, while another possibility is to perform the minimization through exhaustive search in a finite sample. Note that a convex relaxation through variational methods (Wainwright & Jordan, 2008) could provide an interesting alternative."}, {"heading": "5. Experiments", "text": "The goals of these simulations are (a) to compare the different algorithms aimed at estimating integrals, i.e., assess herding for the task of mean estimation (Section 5.1 and Section 5.2), and (b) to briefly study the empirical relationship with maximum entropy estimation in a learning context (Section 5.3).\n5.1. Kernel herding on X = [0, 1] Problem set-up. In this section, we consider X = [0, 1] and the norm \u2016f\u20162 = \u222b 1 0 [f\n(\u03bd)(x)]2dx on the infinite-dimensional space of functions with zero mean and whose \u03bd-th derivative exists and is in L2([0, 1]). As shown by Wahba (1990), the associated kernel is equal to B2\u03bd(x\u2212y\u2212\u230ax\u2212y\u230b)(2\u03bd)! , where B2\u03bd is the (2\u03bd)-th Bernoulli polynomial, with B2(x) = x 2 \u2212 x + 16 and B6(x) = x 6 \u2212 3x5 + 52x4 \u2212 12x2 + 142 .\nWe consider either the uniform density on [0, 1], or a randomly selected density of the form p(x) \u221d(\u2211d\ni=1 ai cos(2i\u03c0x) + bi sin(2i\u03c0x) )2 , for which all required expectations may be computed in closed form. In particular, the mean element is computed as \u00b5 : x 7\u2192 E[k(Y, x)] which may be computed in closed form by expanding all terms in the Fourier basis. As for the optimization step, it consists in minimizing gt(x)\u2212 \u00b5(x) over the interval [0, 1] which can be done efficiently with exhaustive search.\nComparison of mean estimation procedures. We compare in Figure 3 two kernels, i.e., with \u03bd = 1 (left and middle plots) and \u03bd = 3 (right plot), the following mean estimation procedures, and plot log10 \u2016\u00b5\u0302 \u2212 \u00b5\u2016, for two densities, the uniform density (middle and right) and a randomly selected nonuniform density (left). We compare the following:\n\u2013 cg-1/(t+1): conditional gradient procedure with \u03c1t = 1 t+1 , which is the original herding procedure\nof Welling (2009a), leading to uniform weights. \u2013 cg-l.search: conditional gradient procedure with line search (with non-uniform weights). \u2013 min-norm-point: Minimum-norm point algorithm. This leads to non-uniform weights. \u2013 random: Random selection of points (from p(x)), averaged over 10 replications. \u2013 sobol: a classical quasi-random sequence, with uniform weights. For non-uniform densities, we first apply the inverse cumulative distribution function.\nFor all of these (except for min-norm-point), we also consider an extra a posteriori projection step (denoted by the -proj suffix), which computes the optimal set of non-uniform weights by finding the best approximation of \u00b5 in the convex hull of the points selected by the algorithm. We can draw the following conclusions:\n\u2013 Min-norm-point algorithms always perform best. \u2013 Conditional gradient with line search is performing slightly worse than regular herding. (Note that we are in the infinite-dimensional setting and so they both have O(t\u22121) as theoretical rate.) \u2013 The extra projection step always significantly improves performance, and sometimes enough that random selection of point combined with a reprojection outperforms regular herding (at least for \u03bd = 3, i.e., with a smaller feature space). \u2013 On the right plot, it turns out that the Sobol sequence is known to achieve the optimal rate of O(t\u22122) for \u2016\u00b5 \u2212 \u00b5\u0302\u20162 for the associated Sobolev space (Wahba, 1990). In this situation, regular herding empirically achieves the same rate; however, the theoretical analysis provided in the present paper or by Chen et al. (2010) does not allow to explain or support this statement theoretically.\nEstimation from a finite sample. In Figure 4, we compare three of the previously mentioned herding procedures when all quantities are computed from a random sample of size 1000. In plain, testing errors are computed (using exact expectations) while in dashed, the training errors are computed. All methods eventually fit the empirical mean, with no further progress on the testing error, this behavior happening faster with the min-norm-point algorithm."}, {"heading": "5.2. Estimation on graphical models", "text": "We consider X = {\u22121, 1}d and a random variable computed as the sign (in {\u22121, 1}) of a Gaussian random vector in Rd, together with \u03a6(x) composed of x and of all of its pairwise products xx\u22a4. In this set-up, we can compute the expectation Ep(x)\u03a6(x) in closed form, as the mass assigned to the positive orthant by a bivariate Gaussian distribution with correlation \u03c1, which is\nequal to 14 + 1 2\u03c0 sin \u22121 \u03c1 (Abramowitz & Stegun, 1964). We are here in the finite-dimensional setting and the faster rates derived in Section 4.2 apply.\nWe generated 10000 samples from such a distribution and performed herding with exact expectations but with minima with respect to x computed over this sample (by exhaustive search over the sample). We plot results in Figure 5, where we see the superiority of the min-norm-point procedure over the two other procedures (which include regular herding). Note that the line-search algorithm is slower than the 1/(t+1)-rule, which seems to contradict the bounds. The bounds depend on the distance d between the mean and the boundary of the marginal polytope. If this is too small (much like if the strong convexity constant is too small for gradient descent), the linear convergence rate can only be seen for larger numbers of iterations."}, {"heading": "5.3. Herding and maximum/minimum entropy", "text": "Given a moment vector \u00b5 obtained from the empirical mean of \u03a6(x) on data, the goal of herding is to produce a pseudo-sample whose moments match \u00b5 without having to estimate the canonical parameters of the corresponding model. A natural candidate for such a distribution is the maximum entropy distribution and we will compare it to the results of herding in cases where it can be easily computed, namely for X = {\u22121, 1}d (with d 6 10) and either \u03a6(x) = x \u2208 [\u22121, 1]d or \u03a6(x) = (x, xx\u22a4). In this setup, following Welling (2009a), the distribution on x \u2208 X is estimated by the empirical distribution \u2211t i=1 wi\u03b4(x = xi).\nLearning independent bits. We first consider \u03a6(x) = x and some specific feasible moment \u00b5 \u2208 M. It is well-known that the maximum entropy distribution is the one with independent bits. In the top panels of Figure 6, we compare the norm between the maximum entropy probability vector and the one estimated by two versions of herding, namely conditional gradient with stepsize \u03c1t = 1/(t + 1) (regular herding with uniform weights) and with line search (with non-uniform weights)\u2014the min-norm-point algorithm leads to quantitatively similar results. We show results in Figure 6 for a mean vector \u00b5 which is a random uniform vector in [\u22121, 1]d (left plots), and for a mean \u00b5 which is random with uniform (\u00b5i + 1)/2 values in {1, 2, 3, 4, 5}\u00d7 2 \u221a 2\n3 (middle plots), and for mean values \u00b5 which is are random with uniform (\u00b5i + 1)/2 values in {1, 2, 3, 4, 5}/6 (right plots). Note that the difference between rational and irrational means was already brought up by Welling & Chen (2010) through the link between herding and Sturmian sequences.\nFor each of the mean vector, we plot in the top plots, the error in estimating the full maximum entropy distribution (a vector of size 2d), and in the bottom plots, the error in estimating the feature means (a vector of size d). We can draw the following conclusions:\n\u2013 For a random vector \u00b5 (left plots), then regular herding (with no line search) empirically converges to the maximum entropy distribution.\n\u2013 For rational ratios between the means (but irrational means, middle plots), then there is no convergence to the maximum entropy distribution.\n\u2013 For rational means (right), there is no convergence either, but the behavior is more erratic.\n\u2013 The line-search procedure never converges to the maximum entropy procedure. On the opposite, it happens to be close to a minimum entropy solution, where many states have probability zero.\nExperiments considered in Figure 6 considered a single draw of the mean vector \u00b5, but similar empirical conclusions may be drawn from other random samples, and we conjecture that for almost surely all random\nvectors \u00b5 \u2208 [\u22121, 1]d (which would avoid rational ratios between mean values), then regular herding converges to the maximum entropy distribution. The next experiment shows that this is not the case in general.\nLearning non-independent bits. We now consider \u03a6(x) = (x, xx\u22a4), and a certain random feasible moment \u00b5 \u2208 M. As before, we compare the norm between the maximum entropy probability vector and the one estimated by the two versions of herding. We present results in Figure 7 for a mean vector obtained by the corresponding exponential family distribution with zero weights for the features x and constant weights on the features xx\u22a4. We see that the herding procedures, while leading to a consistent estimation of the mean vector, does not converge to the maximum entropy distribution and other unreported experiments have led to similar results."}, {"heading": "6. Conclusion", "text": "We showed that herding generates a sequence of points which give in sequence the descent directions of a conditional gradient algorithm minimizing the quadratic error on the moment vector. Therefore, if herding is only assessed in terms of its ability to approximate the moment vector, it is outperformed by other more efficient algorithms. Clearly, herding was originally defined with another goal, which was to generate a pseudo-sample whose distribution could approach the maximum entropy distribution with a given moment vector. Our experiments suggest empirically, that while this is the case in certain cases, herding fails in other case, which are not chosen to be particularly pathological. This probably prompts for a further study of herding.\nOur experiments also show that algorithms that are more efficient than herding at approximating the moment vector fail more blatantly to approach a maximum entropy distribution and they present characteristics which would rather suggest a minimization of the entropy. This suggests the question of whether there is a tradeoff between approximating most efficiently the\nmean vector and approximating well the maximum entropy distribution, or if the two goals are in fact rather aligned? In any case, we hope that formulating herding as an optimization problem can help form a better understanding of its goals and its properties.\nAcknowledgements. We thank Ferenc Husza\u0301r and Zoubin Ghahramani for helpful discussions. This work was supported by the European Research Council (SIERRA Project) and the city of Paris (\u201cResearch in Paris\u201d program)."}], "references": [{"title": "Learning with submodular functions: A convex optimization perspective", "author": ["F. Bach"], "venue": "Technical Report 1111.6453,", "citeRegEx": "Bach,? \\Q2011\\E", "shortCiteRegEx": "Bach", "year": 2011}, {"title": "A conditional gradient method with linear rate of convergence for solving convex linear systems", "author": ["A. Beck", "M. Teboulle"], "venue": "Math. Meth. Op. Res.,", "citeRegEx": "Beck and Teboulle,? \\Q2004\\E", "shortCiteRegEx": "Beck and Teboulle", "year": 2004}, {"title": "Theory of classification: A survey of some recent advances", "author": ["S. Boucheron", "O. Bousquet", "G. Lugosi"], "venue": "ESAIM Probability and statistics,", "citeRegEx": "Boucheron et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Boucheron et al\\.", "year": 2005}, {"title": "Super-samples from kernel herding", "author": ["Y. Chen", "M. Welling", "A. Smola"], "venue": "In Proc. UAI,", "citeRegEx": "Chen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2010}, {"title": "On the mathematical foundations of learning", "author": ["F. Cucker", "S. Smale"], "venue": "Bull. AMS,", "citeRegEx": "Cucker and Smale,? \\Q2002\\E", "shortCiteRegEx": "Cucker and Smale", "year": 2002}, {"title": "Convergence rates for conditional gradient sequences generated by implicit step length rules", "author": ["J.C. Dunn"], "venue": "SIAM J. Control & Opt.,", "citeRegEx": "Dunn,? \\Q1980\\E", "shortCiteRegEx": "Dunn", "year": 1980}, {"title": "On herding and the perceptron cycling theorem", "author": ["A. Gelfand", "L. van der Maaten", "Y. Chen", "M. Welling"], "venue": "In Adv. NIPS,", "citeRegEx": "Gelfand et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gelfand et al\\.", "year": 2010}, {"title": "Quasi-random sequences and their discrepancies", "author": ["W.J. Morokoff", "R.E. Caflisch"], "venue": "SIAM Journal on Scientific Computing,", "citeRegEx": "Morokoff and Caflisch,? \\Q1994\\E", "shortCiteRegEx": "Morokoff and Caflisch", "year": 1994}, {"title": "Bayes-Hermite quadrature", "author": ["A. O\u2019Hagan"], "venue": "J. Stat. Planning & Inference,", "citeRegEx": "O.Hagan,? \\Q1991\\E", "shortCiteRegEx": "O.Hagan", "year": 1991}, {"title": "A Hilbert space embedding for distributions", "author": ["A. Smola", "A. Gretton", "L. Song", "B. Sch\u00f6lkopf"], "venue": "In Algorithmic Learning Theory,", "citeRegEx": "Smola et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Smola et al\\.", "year": 2007}, {"title": "Spline Models for Observational Data", "author": ["Wahba", "Grace"], "venue": null, "citeRegEx": "Wahba and Grace.,? \\Q1990\\E", "shortCiteRegEx": "Wahba and Grace.", "year": 1990}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "Wainwright and Jordan,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan", "year": 2008}, {"title": "Herding dynamic weights for partially observed random field models", "author": ["M. Welling"], "venue": "In Proc. UAI,", "citeRegEx": "Welling,? \\Q2009\\E", "shortCiteRegEx": "Welling", "year": 2009}, {"title": "Herding dynamical weights to learn", "author": ["M. Welling"], "venue": "In Proc. ICML,", "citeRegEx": "Welling,? \\Q2009\\E", "shortCiteRegEx": "Welling", "year": 2009}, {"title": "Statistical inference using weak chaos and infinite memory", "author": ["M. Welling", "Y. Chen"], "venue": "J. Physics: Conf. Series,", "citeRegEx": "Welling and Chen,? \\Q2010\\E", "shortCiteRegEx": "Welling and Chen", "year": 2010}, {"title": "Finding the nearest point in a polytope", "author": ["P. Wolfe"], "venue": "Math. Progr.,", "citeRegEx": "Wolfe,? \\Q1976\\E", "shortCiteRegEx": "Wolfe", "year": 1976}], "referenceMentions": [{"referenceID": 12, "context": "We show that the herding procedure of Welling (2009b) takes exactly the form of a standard convex optimization algorithm\u2014 namely a conditional gradient algorithm minimizing a quadratic moment discrepancy.", "startOffset": 38, "endOffset": 54}, {"referenceID": 12, "context": "The herding algorithm has recently been presented by Welling (2009b) as a computationally attractive alternative method for learning in intractable Markov random fields models (MRF).", "startOffset": 53, "endOffset": 69}, {"referenceID": 6, "context": "From this perspective, herding was later generalized to MRFs with latent variables (Welling, 2009a) as well as discriminative MRFs (Gelfand et al., 2010).", "startOffset": 131, "endOffset": 153}, {"referenceID": 11, "context": "From the learning perspective, the herding updates can be derived by performing fixedstep-size subgradient ascent on the zero-temperature limit of the annealed likelihood function of the MRF\u2014 called the \u201ctipi function\u201d by Welling (2009b). From this perspective, herding was later generalized to MRFs with latent variables (Welling, 2009a) as well as discriminative MRFs (Gelfand et al.", "startOffset": 222, "endOffset": 238}, {"referenceID": 3, "context": "= \u2016\u03bc \u2212 1t \u2211t i=1 \u03a6(xi)\u2016 (Chen et al., 2010).", "startOffset": 24, "endOffset": 43}, {"referenceID": 3, "context": "From the moment matching perspective, which has been explored more in details by Chen et al. (2010), the herding updates can be derived as an effective way to choose greedily pseudo-samples xt in order to quickly decrease the moment discrepancy Et .", "startOffset": 81, "endOffset": 100}, {"referenceID": 3, "context": "From the moment matching perspective, which has been explored more in details by Chen et al. (2010), the herding updates can be derived as an effective way to choose greedily pseudo-samples xt in order to quickly decrease the moment discrepancy Et . = \u2016\u03bc \u2212 1t \u2211t i=1 \u03a6(xi)\u2016 (Chen et al., 2010). Under suitable regularity conditions, Et decreases as O(1/t) for the herding updates\u2014this is faster than i.i.d. sampling from the distribution generating \u03bc (e.g., the training data) which would yield the slower O(1/ \u221a t) rate. This faster rate has been explained by negative autocorrelations amongst the pseudo-samples and was used by Chen et al. (2010) to sub-select a small collection of representative \u201csuper-samples\u201d from a much larger set of i.", "startOffset": 81, "endOffset": 649}, {"referenceID": 3, "context": "In particular, we provide a linear convergence rate for the line-search variant in finitedimensional settings and show how the conditions assumed by Chen et al. (2010) in fact never hold in the infinite-dimensional setting.", "startOffset": 149, "endOffset": 168}, {"referenceID": 3, "context": "We start with a similar setup as Chen et al. (2010), where herding can be interpreted as a way to approximate integrals of functions in a reproducing kernel Hilbert space (RKHS).", "startOffset": 33, "endOffset": 52}, {"referenceID": 3, "context": "We start with a similar setup as Chen et al. (2010), where herding can be interpreted as a way to approximate integrals of functions in a reproducing kernel Hilbert space (RKHS). We consider a set X and a mapping \u03a6 from X to a RKHS F . Through this mapping, all elements of F may be identified with real functions f on X defined by f(x) = \u3008f,\u03a6(x)\u3009, for x \u2208 X . We denote by k : (x, y) 7\u2192 k(x, y) the associated positive definite kernel. Note that the mapping \u03a6 may be explicit (classically in low-dimensional settings) or implicit\u2014where the kernel trick can be used, see Section 4.3 and Chen et al. (2010).", "startOffset": 33, "endOffset": 606}, {"referenceID": 3, "context": "We denote by M \u2282 F the marginal polytope (Wainwright & Jordan, 2008; Chen et al., 2010), i.", "startOffset": 41, "endOffset": 87}, {"referenceID": 3, "context": "Following Chen et al. (2010), we denote by \u03bc the mean element (see, e.", "startOffset": 10, "endOffset": 29}, {"referenceID": 3, "context": "In this paper, we will try to find a good estimate \u03bc\u0302 of \u03bc based on a weighted set of points from {\u03a6(x), x \u2208 X}, generalizing Chen et al. (2010), and show how this relates to herding.", "startOffset": 126, "endOffset": 145}, {"referenceID": 3, "context": "The links between the first two were clearly outlined by Chen et al. (2010), while the present paper provides the novel interpretation of herding as a well-established convex optimization algorithm.", "startOffset": 57, "endOffset": 76}, {"referenceID": 8, "context": "from a given distribution), the Bayes-Hermite quadrature of O\u2019Hagan (1991) essentially computes an orthogonal projection of \u03bc onto the affine hull of this set of points.", "startOffset": 60, "endOffset": 75}, {"referenceID": 15, "context": "For convex sets with finitely many extreme points, it converges in a finite number of iterations with higher (though still polynomial) iteration computational cost (Wolfe, 1976).", "startOffset": 164, "endOffset": 177}, {"referenceID": 3, "context": "In the kernel herding algorithm of Chen et al. (2010), the authors use w0 = \u03bc as this is required to interpret the herding updates as greedily minimizing Et (with the additional assumptions that \u2016\u03a6(x)\u2016 is constant).", "startOffset": 35, "endOffset": 54}, {"referenceID": 5, "context": "Without further assumptions on the problem, then the two choices of step sizes lead to a convergence rate of the form (Dunn, 1980; Bach, 2011):", "startOffset": 118, "endOffset": 142}, {"referenceID": 0, "context": "Without further assumptions on the problem, then the two choices of step sizes lead to a convergence rate of the form (Dunn, 1980; Bach, 2011):", "startOffset": 118, "endOffset": 142}, {"referenceID": 3, "context": "For the version without line search (\u03c1t = 1/(t + 1)), Chen et al. (2010) shows the slower convergence rate in O(1/t): 1", "startOffset": 54, "endOffset": 73}, {"referenceID": 3, "context": "In an integral evaluation context, in finite-dimensional settings, one needs to compute Ep(x)\u03a6(x); while in an infinite-dimensional setting, following Chen et al. (2010), expectations of the form Ep(x)k(x, y) need to be computed.", "startOffset": 151, "endOffset": 170}, {"referenceID": 3, "context": "In practice, Chen et al. (2010) and Welling (2009a) perform local search, while another possibility is to perform the minimization through exhaustive search in a finite sample.", "startOffset": 13, "endOffset": 32}, {"referenceID": 3, "context": "In practice, Chen et al. (2010) and Welling (2009a) perform local search, while another possibility is to perform the minimization through exhaustive search in a finite sample.", "startOffset": 13, "endOffset": 52}, {"referenceID": 12, "context": "\u2013 cg-1/(t+1): conditional gradient procedure with \u03c1t = 1 t+1 , which is the original herding procedure of Welling (2009a), leading to uniform weights.", "startOffset": 106, "endOffset": 122}, {"referenceID": 3, "context": "In this situation, regular herding empirically achieves the same rate; however, the theoretical analysis provided in the present paper or by Chen et al. (2010) does not allow to explain or support this statement theoretically.", "startOffset": 141, "endOffset": 160}, {"referenceID": 12, "context": "In this setup, following Welling (2009a), the distribution on x \u2208 X is estimated by", "startOffset": 25, "endOffset": 41}, {"referenceID": 12, "context": "Note that the difference between rational and irrational means was already brought up by Welling & Chen (2010) through the link between herding and Sturmian sequences.", "startOffset": 89, "endOffset": 111}], "year": 2012, "abstractText": "We show that the herding procedure of Welling (2009b) takes exactly the form of a standard convex optimization algorithm\u2014 namely a conditional gradient algorithm minimizing a quadratic moment discrepancy. This link enables us to invoke convergence results from convex optimization and to consider faster alternatives for the task of approximating integrals in a reproducing kernel Hilbert space. We study the behavior of the different variants through numerical simulations. Our experiments shed more light on the learning bias of herding: they indicate that while we can improve over herding on the task of approximating integrals, the original herding algorithm approaches more often the maximum entropy distribution.", "creator": "LaTeX with hyperref package"}}}