{"id": "1206.3437", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2012", "title": "Improving the Asymmetric TSP by Considering Graph Structure", "abstract": "Recent coevolutionary works sub-montane on cost 1.85-meter based relaxations mikhailov have congratulatory improved Constraint kabah Programming (CP) models melford for the 41.10 Traveling holaday Salesman Problem (TSP ). izabella We non-equity provide a short survey over solving beholding asymmetric TSP with disassemble CP. radanasin Then, we preachers suggest renovator new implied 79.3 propagators caxias based on geman general w\u0119gorzewo graph properties. We taubes experimentally show helal that alize such implied 7,360 propagators coster bring robustness chiriboga to leogang pathological instances step-children and highlight transfusion the fact hypsotropa that graph nerpa structure can euro455 significantly fundoshi improve polar search zumiez heuristics behavior. madalyn Finally, we show preferred that promiscuously our shk approach outperforms erects current techsavvy state holtzclaw of 1780s the ul\u00faa art results.", "histories": [["v1", "Fri, 15 Jun 2012 12:15:31 GMT  (108kb,D)", "http://arxiv.org/abs/1206.3437v1", "Technical report"]], "COMMENTS": "Technical report", "reviews": [], "SUBJECTS": "cs.DM cs.AI cs.DS", "authors": ["jean-guillaume fages", "xavier lorca"], "accepted": false, "id": "1206.3437"}, "pdf": {"name": "1206.3437.pdf", "metadata": {"source": "CRF", "title": "Improving the Asymmetric TSP by Considering Graph Structure", "authors": ["Jean-Guillaume Fages", "Xavier Lorca"], "emails": ["Jean-Guillaume.Fages@mines-nantes.fr", "Xavier.Lorca@mines-nantes.fr"], "sections": [{"heading": "1 Introduction", "text": "Given a n node, m arc complete directed weighted graph G = (V,A, f : A\u2192 R), the Asymmetric Traveling Salesman Problem [1] (ATSP) consists in finding a partial subgraph G\u2032 = (V,A\u2032, f) of G which forms a Hamiltonian circuit of minimum cost. This NP-hard problem is one of the most studied by the Operation Research community. It has various practical applications such as vehicle routing problems of logistics, microchips production optimization or even scheduling.\nThe symmetric TSP is well handled by linear programming techniques [1]. However, such methods suffer from the addition of side constraints and asymmetric cost matrix, whereas constraint programming models do not. Since the real world is not symmetric and industrial application often involve constraints such as time windows, precedences, loading capacities and several other constraints, improving the CP general model for solving the ATSP leads to make CP more competitive on real world routing problems. Recent improvements on cost based relaxations [4] had a very strong impact on the ability of CP technologies to solve the TSP. In this paper, we investigate how the graph structure can contribute to the resolution process, in order to tackle larger instances. For this purpose, we developed usual and original filtering algorithms using classical graph structures, such as strongly connected components or dominators. We analyzed their behavior both from a quantitative (time complexity) and a qualitative (consistency level) point of view. Also, we experimentally show that such implied propagators bring robustness to hard instances, and highlight the fact that the ar X iv :1\n20 6.\n34 37\nv1 [\ncs .D\nM ]\n1 5\nJu n\ngraph structure can significantly improve the behavior of search heuristics. Our main contribution is both a theoretical and an experimental study which lead to a robust model that outperforms state of the art results in CP.\nThis paper is divided into six main parts. Section 2 provides some vocabulary and notations. Section 3 discusses the state of the art implied constraints. Next, we show in Section 4 how the reduced graph can provide useful information for pruning and improving existing models. In Section 5 we provide some improvements about the implementation of the Held and Karp method within a directed context. Section 6 shows an experimental study on the ATSP and some openings about its symmetric version (TSP). Section 7 concludes the paper with several perspectives."}, {"heading": "2 Background", "text": "Let us consider a directed graph G = (V,A). A Strongly Connected Component (SCC) is a maximal subgraph of G such that for each pair of nodes {a, b} \u2208 V 2, a path exists from a to b and from b to a. A reduced graph GR = (VR, AR) of a directed graph G represents the SCC of G. This graph is obtained by merging the nodes of G which are in the same SCC and removing any loop. Such a graph is unique and contains no circuit. We link G and GR with two functions: sccOf : V \u2192 VR and nodesOf : VR \u2192 V V . The method sccOf can be represented by one n-size integer array. Also, since each node of V belongs to exactly one SCC of VR, the method nodesOf can be represented by two integer arrays: the first one represents the canonical element of each SCC while the second one links nodes of the same SCC, behaving like a linked list. Those two arrays have respectively size of nR and n, where nR = |VR|. The transitive closure of G is a graph GTC = (V,ATC) representing node reachability in G, i.e. such that (i, j) \u2208 ATC if and only if a path from i to j exists in G.\nIn a CP context a Graph Variable can be used to model a graph. Such a concept has been introduced by Le Pape et al. [24] and detailed by Re\u0301gin [28] and Dooms et al. [9]. We define a graph variable GV by two graphs: the graph of potential elements, GP = (VP , AP ), contains all the nodes and arcs that potentially occur in at least one solution whereas the graph of mandatory elements, GM = (VM , AM ), contains all the nodes and arcs that occur in every solution. It has to be noticed that GM \u2286 GP \u2286 G. During resolution, decisions and filtering rules will remove nodes/arcs from GP and add nodes/arcs to GM until the Graph Variable is instantiated, i.e. when GP = GM . It should be noticed that, regarding the TSP, VP = VM = V , so resolution will focus on AM and AP : branching strategies and propagators will remove infeasible arcs from AP and add mandatory arcs of AP into AM ."}, {"heading": "3 Related Work", "text": "This section describes the state of the art of existing approaches for solving ATSP with CP. We distinguish the structural filtering, which ensures that a solution is a Hamiltonian path, from cost based pruning, which mainly focus on the solution cost. Then, we study a few representative branching heuristics.\nGiven, a directed weighted graph G = (V,A, f), and a function f : A \u2192 R, the ATSP consists in finding a partial subgraph G\u2032 = (V,A\u2032, f) of G which forms a Hamiltonian circuit of minimum cost. A simple ATSP model in CP, involving a graph variable GV , can basically be stated as minimizing the sum of costs of arcs in the domain of GV and maintaining GV to be a Hamiltonian circuit with a connectivity constraint and a degree constraint (one predecessor and one successor for each node). However, it is often more interesting to convert such a model in order to find a path instead of a circuit [15,25]. Our motivation for this transformation is that it brings graph structure that is more likely to be exploited.\nIn this paper, we consider the ATSP as the problem of finding a minimum cost Hamiltonian path with fixed start and end nodes in a directed weighted graph. In the following, s, e \u2208 V respectively denote the start and the end of the expected path. s and e are supposed to be known. They can be obtained by duplicating any arbitrary node, but it makes more sense to duplicate the node representing the salesman\u2019s home."}, {"heading": "3.1 Structural filtering algorithms", "text": "Our formulation of the ATSP involves the search of a path instead of a circuit, the degree constraints has thus to be stated as follows: For all v \u2208 V \\{e}, \u03b4+G\u2032(v) = 1 and for any v \u2208 V \\{s}, \u03b4\u2212G\u2032(v) = 1, where \u03b4 + G\u2032(v) (respectively \u03b4 \u2212 G\u2032(v)) denotes the number of successors (respectively predecessors) of v. Extremal conditions, being \u03b4+G\u2032(e) = \u03b4 \u2212 G\u2032(s) = 0, are ensured by the initial domain of the graph variable. An efficient filtering can be obtained with two special purpose incremental propagators. One reacts on mandatory arc detections: whenever arc (u, v) is enforced, other outgoing arc of u and ingoing arcs of v can be pruned. The other reacts on arc removals: whenever a node has only one outgoing (or ingoing) potential arc left, this arc is mandatory and can be enforced. A higher level of consistency can be achieved by using a graph-based AllDifferent constraint maintaining a node-successor perfect matching [27]. Deleting circuits is the second important structural aspect of the TSP. Caseau and Laburthe [7] suggested the simple and efficient NoCycle constraint to remove circuits of the graph. Their fast incremental algorithm is based on the subpaths fusion process. It runs in constant time per arc enforcing event. The conjunction of this circuit elimination constraint and the above degree constraints is sufficient to guarantee that the solution is a Hamiltonian path from s to e.\nHowever, other implied constraints provide additional filtering that may help the resolution process. For instance, Quesada [26] suggested the general propagator DomReachability which maintains the transitive closure and the dominance\ntree of the graph variable. However, its running time, O(nm) in the worst case, makes it unlikely to be profitable in practice. A faster constraint, also based on the concept of dominance, is the Arborescence constraint. It is nothing else but a simplification of the Tree constraint [2] recently improved to a O(n+m) worst case time complexity [12]. Given a graph variable GV and a node s, such a constraint ensures that GV is an arborescence rooted in node s. More precisely, it enforces GAC over the conjunction of the following properties: GP has no circuit, each node is reachable from s and, each node but s has exactly one predecessor. Such a filtering can also be used to define the AntiArborescence by switching s with e and predecessors with successors.\nA dual approach consists in assigning to each node its position in the path. In such a case, the position of a node is represented by an integer variable with initial domain [0, n \u2212 1]. Positions are different from a node to another, which can be ensured by an AllDifferent constraint. Since the number of nodes is equal to the number of positions, the bound consistency algorithm of AllDifferent constraint only requires O(n) time. Plus, a channeling has to be done between the graph variable and position variables. Such a channeling requires O(n+m) worst case time. In particular, lower bounds of positions are adjusted according to a single Breadth First Search (BFS) of GP (s) while upper bounds of positions are shortened by a BFS of G\u22121P (e). It has to be noticed that this approach is related to disjunctive scheduling [33]: nodes are tasks of duration 1 which are executed on the same machine. The structure of the input graph creates implicit precedence constraints.\nFinally, some greedy procedures based on the finding of cuts have been suggested in the literature: Benchimol et al. enforce some cut-sets of size two [4] while Kaya and Hooker use graph separators for pruning [21]. The drawback of such methods is that they provide no level of consistency."}, {"heading": "3.2 Cost-based filtering algorithms", "text": "CP models often embed relaxation based constraints, to provide inference from costs. Fischetti and Toth [14] suggested a general bounding procedure for combining different relaxations of the same problem.\nThe most natural relaxation is obtained by considering the cheapest outgoing arc of each node: LBtrivial = \u2211 u\u2208V \\{e}min{f(u, v)|(u, v) \u2208 AP }. Such a lower bound can be computed efficiently but it is in general relatively far from the optimal value.\nA stronger relaxation is the weighted version of the AllDifferent constraint, corresponding to the Minimum Assignment Problem (MAP). It requires O(n(m + n log n)) time [23] to compute a first minimum cost assignment but then O(n2) time [6] to check consistency and filter incrementally. Some interesting evaluations are provided by [16], but are mainly related to the TSP with time windows constraints.\nA widely exploited subproblem of the ATSP is the Minimum Spanning Tree (MST) problem where the degree constraint and arc direction are relaxed. We remark that a hamiltonian path is a spanning tree and that it is possible to\ncompute a MST with a degree restriction at one node [17]. A MST can be computed in two ways. The first one is Kruskal\u2019s algorithm, which runs in O(\u03b1m) worst case time, where \u03b1 is the inverse Ackermann function, but requires edges to be sorted according to their weights. Sorting edges can be done once and for all in O(m logm) time. The second option is to use Prim\u2019s algorithm which requires O(m+n log n) time with Fibonacci heaps [17] or O(m log n) time if binomial heaps are used instead. Based on Kruskal\u2019s algorithm, Re\u0301gin et al. [29,30] made the Weighted Spanning Tree constraint which ensures consistency, provides a complete pruning and detects mandatory arcs incrementally, within O(\u03b1m) time. Dooms and Katriel [10,11] presented a more complex Minimum Spanning Tree constraint which maintains a graph and its spanning tree, pruning according to King\u2019s algorithm [22].\nAn improvement of the MST relaxation is the approach of Held and Karp [19], adapted for CP by Benchimol et al.[4]. It is the Lagrangian MST relaxation with a policy for updating Langrangian multipliers that provides a fast convergence. The idea of this method is to iteratively compute MST that converge towards a path by adding penalties on arc costs according to degree constraints violations. It must be noticed that since arc costs change from one iteration to another, Prim\u2019s algorithm is better than Kruskal\u2019s which requires to sort edges. Moreover, to our knowledge neither algorithm can be applied incrementally.\nA more accurate relaxation is the Minimum Spanning Arborescence (MSA) relaxation, since it does not relax the orientation of the graph. This relaxation has been studied by [14,15] who provide a O(n2) time filtering algorithm based on primal/dual linear programs. The best algorithm for computing a MSA has been provided by Gabow et al. [17]. Their algorithm runs in O(m+n log n) worst case time, but it does not provide reduced costs that are used for pruning. Thus, it could be used to create a Minimum Spanning Arborescence constraint with a O(m + n log n) time consistency checking but the complete filtering algorithm remains in O(n2) time. The Lagrangian MSA relaxation, with a MSA computation based on Edmonds\u2019 algorithm, has been suggested in [7]. This method was very accurate but unfortunately unstable. Also, Benchimol et al. [4] report that the MSA based Held and Karp scheme lead to disappointing results."}, {"heading": "3.3 Branching heuristics", "text": "Branching strategies forms a fundamental aspect of CP which can drastically reduce the search space. We study here dedicated heuristics, because the literature is not clear about which branching heuristic should be used.\nPesant et al. have introduced Sparse heuristic [25] which has the singularity of considering occurrences of successors and ignoring costs. In this way, this heuristic is based on the graph structure. It behaves as following: First, it selects the set of nodes X with no successor in GM and the smallest set of successors in GP . Second, it finds the node x \u2208 X which maximize \u2211 (x,y)\u2208AP |{(z, y) \u2208 AP |z \u2208 X}|. The heuristic then iterates on x\u2019s successors. This process is optimized by performing a dichotomic exploration of large domains.\nHowever, very recently, Benchimol et al. [4] suggested a binary heuristic, based on the MST relaxation, that we call RemoveMaxRC. It consists in removing from GP the tree arc of maximum replacement cost, i.e. the arc which would involve the highest cost augmentation if it was removed. By tree arc, we mean the fact that it appears in the MST of the last iteration of the Held and Karp procedure. Acutally, as shown in section 6, this branching leads to poor results and should not be used.\nFinally, Focacci et al. solve the TSPTW [15] by guiding the search with time windows, which means that the efficiency of CP for solving the ATSP should not rely entirely on its branching heuristic."}, {"heading": "4 Considering the reduced graph", "text": "In this section, we consider a subproblem which is not a subset of constraints, as usual, but consists in the whole ATSP itself applied to a more restrictive scope: the reduced graph of GP . The structure of the reduced graph has already been considered in a similar way for path partitioning problems [3,5]. In this section, we first study structural properties that arise from considering the reduced graph. Second, we show how to adapt such information to some state of the art implied models, including cost based reasonings."}, {"heading": "4.1 Structural properties", "text": "We introduce a propagator, the Reduced Path propagator, which makes the reduced graph a (Hamiltonian) simple path and ensures by the way that each node is reachable from s and can reach e. It is a monotonic generalization of the algorithm depicted in [31]. Necessary conditions for this propagator have already been partially highlighted in [5]. We first modify them in order to fit with the TSP and our model. Next, we provide a linear time incremental algorithm.\nDefinition 1. Reduced path guarantees that any arc in GP that connects two SCC, is part of a simple path which go through every SCC of GP .\nProposition 1. Given any directed graph G, its reduced graph GR contains at most one Hamiltonian path.\nProof. Let us consider a graph G such that GR contains at least two Hamiltonian paths p1 and p2, p1 6= p2. Since both p1 and p2 are Hamiltonian then there exists at least two nodes {x, y} \u2282 VR, x 6= y, such that x is visited before y in p1 and after y in p2. Thus, the graph P = p1 \u22c3 p2 contains a path from x to y and from y to x. This is a circuit. As P \u2282 GR, GR also contains a circuit, which is a contradiction. ut\nWe note GR the reduced graph of GP . We remark that, as s has no predecessor then its SCC is the node s itself. Also, as e has no successor then sccOf(e)= {e}. To distinguish nodes of V from nodes of the reduced graph, we note sccOf(s)= sR and sccOf(e)= eR. It follows that any Hamiltonian path in GR will be from sR to eR.\nProposition 2. If there exists a Hamiltonian path from s to e in GP then there exists a Hamiltonian path in GR.\nProof. Lets suppose that GR has no Hamiltonian path from sR to eR. Then for any path pR in GR starting at sR and ending at eR, there exist at least one node x \u2208 VR, which is not visited by pR. Thus, for any path pE in GP starting at s and ending at e, there exist at least one SCC x \u2208 VR which is not traversed by pE , so \u2200u \u2208 nodesOf(x ), then u /\u2208 pE . Thus any path in GP starting at s and ending at e is not Hamiltonian. ut\nIt follows that any transitive arc of GR must be pruned and that remaining arcs ofGR are mandatory (otherwise the graph becomes disconnected): any SCC, but eR, must have exactly one outgoing arc. An example is given in figure 1: the graph GP contains four SCC. Its reduced graph, GR, has a unique Hamiltonian path PR = ({A}, {B,C}, {E,D,F}, {G}). Arcs of GR\\PR are infeasible so (A,E) and (C,G) must be pruned from GP .\nWe introduce a new data structure in GR that we call outArcs : for each node x \u2208 VR, outArcs(x ) is the list of arcs {(u, v) \u2208 AP | sccOf(u)= x and sccOf(v)6= x}. We can now easily draw a complete filtering algorithm for the Reduced Path propagator which ensures the GAC over the property that GR must be a path in O(n+m) time:\n1. Data structures: Compute the SCC of GP (with Tarjan\u2019s algorithm [32]) and build the reduced graph GR = (VR, AR). 2. Taking mandatory arcs into account: \u2200(u, v) \u2208 AM such that x =sccOf(u) and x 6=sccOf(v), \u2200(p, q) \u2208 outArcs(x ) \\{(u, v)} remove arc (p, q).\n3. Consistency checking: Make GR a path if possible, fail otherwise. 4. for each arc (u, v) \u2208 AP such that x =sccOf(u) and y =sccOf(v), x 6= y,\n(a) Pruning: if (x, y) /\u2208 AR, remove arc (u, v). (b) Enforcing: if (x, y) \u2208 AR and (u, v) is the only arc of AP that links x\nand y, enforce arc (u, v).\nA procedure performing step 3 starts on node sR, finds its right successor next (the one which has only one predecessor) and removes other outgoing arcs. Then, the same procedure is applied on next and so on, until eR is reached. Such an algorithm must be performed once during the initial propagation. Then, the propagator reacts to fine events. To have an incremental behavior, the propagator must maintain the set of SCC and the reduced graph. Haeupler et al. [18] worked on maintaining SCC and a topological ordering of nodes in the reduced graph, but under the addition of arcs. We deal with arc deletions. Moreover, we may have lots of arc deletions per propagation (at least for the first ones), thus we should not use a completely on-line algorithm.\nSCC maintenance: Let us consider an arc (u, v) \u2208 AP such that sccOf(u)= x and sccOf(v)= y. If x 6= y and if (u, v) is removed from AP then it must be removed from outArcs(x ) also. If x = y then the removal of (u, v) may split the SCC x, so computation is required. As many arcs can be removed from one propagation to another, we suggest a partially incremental algorithm which computes exclusively SCC that contains at least one removed arc, each one exactly once. We introduce a bit set to mark nodes of GR. Initially, each node is unmarked, then when a removed arc, inside an unmarked SCC x, is considered, we apply Tarjan\u2019s algorithm on GP \u22c2 nodesOf(x ) and mark x. Tarjan\u2019s algorithm will return either x if x is still strongly connected, or the new set of SCC induced by all arc removals from x. In both cases, we can ignore other arcs that have been removed from nodesOf(x ). Since the SCC of a graph are node-disjoint, the overall processing time of a propagation dealing with k arc deletions involving some SCC K \u2282 VR is \u2211 x\u2208K O(nx +mx) = O(n+m).\nGR maintenance and filtering: Algorithm 1 shows how to get an incremental propagator that reacts to SCC splits. When a SCC x is split into k new SCC, the reduced graph gets k \u2212 1 new nodes and must be turned into a path while some filtering may be performed on GV . The good thing is that there is no need to consider the entire graph. We note X \u2282 VR the set of nodes induced by the breaking of SCC x. Since GR was a path at the end of the last propagation, we call p the predecessor of x in GR and s its successor. Then, we only need to consider nodes of X \u22c3 {p, s} in GR. To compute new arcs in GR it is necessary to examine arcs of GP , but only outArcs(p) and arcs that have the tail in a SCC of X need to be considered. Note that we filter during the maintenance process.\nOnce we get those data structures, then it is worth exploiting them the most we can, to make such a computation profitable. Especially, a few trivial ad hoc rules come when considering SCC. We call an indoor a node with a predecessor outside its own SCC, an outdoor, a node with a successor outside its SCC and a door a node which is an indoor or/and an outdoor.\nAlgorithm 1 Incremental Reduced Path Propagator Let x be the old SCC split into a set X of new SCC\np\u2190 GR.predecessors(x).first() {get the first (and unique) predecessor of x in GR} s\u2190 GR.successors(x).first() if (VISIT(p, s) 6= |X|+ 2) then\nFAIL end if\n\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2212 int VISIT(int current, int last)\nif (current = last) then return 1 end if next\u2190 \u22121 for (node x \u2208 current.successors) do\nif (|x.predecessors| = 1) then if (next 6= \u22121) then\nreturn 0 {next and x are incomparable which is a contradiction} end if next\u2190 x\nelse GR.removeArc(current, x)\nend if end for for (arc (u, v) \u2208 outArcs(current)) do\nif (sccOf(v) 6= next) then GP.removeArc(u, v) {Prune infeasible arcs} outArcs.remove(u, v)\nend if end for if (|outArcs(current)| = 1) then\nGM.addArc(outArcs(current).getFirst()) {Enforce mandatory arcs} end if return 1 + VISIT(next, last)\nProposition 3. If a SCC X has only one indoor i \u2208 X, then any arc (j, i) \u2208 X is infeasible.\nProof. First we remark that i cannot be s since s has no predecessors. Let us then suppose that such arc (j, i) \u2208 X is enforced. As the TSP requires nodes of V \\{s} to have exactly one predecessors, all other predecessors of i will be pruned. As i was the only indoor of X, then X is not reachable anymore from sR, which is by Proposition 2 a contradiction. ut\nBy symmetry, if a SCC X has only one outdoor i \u2208 X, then any arc (i, j) \u2208 X is infeasible. Moreover, if a SCC X of more than two nodes has only two doors i, j \u2208 X, then arcs (i, j) and (j, i) are infeasible."}, {"heading": "4.2 Strengthening other models", "text": "In general, the reduced graph provides three kinds of information: Precedences between nodes of distinct SCC; Reachability between nodes of the graph; Cardinality sets \u2200x \u2208 VR\\{eR}, |outArcs(x )| = 1. Such information can be directly used to generate lazy clauses [13]. It can also improve the quality of the channeling between the graph variable and position variables by considering precedences: When adjusting bounds of position variables (or time windows), the BFS must be tuned accordingly, processing SCC one after the other.\nSome propagators such as DomReachability [26], require the transitive closure of the graph. Its computation requires O(nm) worst case time in general, but since the reduced graph is now a path, we can sketch a trivial and optimal algorithm: For any node v \u2208 V , we call Sv \u2282 V \\{v} the set of nodes reachable from v in GP and Dv \u2282 VR the set of nodes reachable from sccOf(v)\u2208 VR in GR, including sccOf(v). More formally, Sv = {u \u2208 V |v \u2192 u} and Dv = x\u222a{y \u2208 VR|x\u2192 y}, where x =sccOf(v). Then, for any node v \u2208 V , Sv = {nodesOf(y) |y \u2208 Dv}\\{v}. As GR is a path, iterating on Dv requires O(|Dv|) operations. Also, since SCC are node-disjoints, computing Sv takes O(|Dv|+ \u2211 y\u2208Dv |nodesOf(y)|) = O(|Sv|) because |Dv| \u2264 |Sv|+ 1 and |{nodesOf(y) |y \u2208 Dv}| = |Sv|+ 1. As |Sv| \u2264 n, the computation of the transitive closure takes O( \u2211 v\u2208V |Sv|) which is bounded by O(n2). It can be performed incrementally by considering SCC splits only. Finally we show how the MST relaxation of the TSP can be improved by considering the reduced graph. We call a Bounding Spanning Tree (BST) of GP a spanning tree of GP obtained by finding a minimum spanning tree in every SCC of GP independently and then linking them together using the cheapest arcs:\nBST (GP ) = \u22c3 x\u2208GR MST (GP \u22c2\nnodesOf(x ))\u22c3 a\u2208VR minf{(u, v) |(u, v) \u2208 outArcs(a)}.\nThe resulting spanning tree provides a tighter bound than a MST. Indeed, since BST and MST both are spanning trees, f(BST (GP )) \u2265 f(MST (GP )), otherwise MST is not minimal.\nWe will now see how to improve the Weighted Spanning Tree (WST) constraint, leading to the Bounding Spanning Tree (BST) propagator. We assume that the reader is already familiar with this constraint, otherwise papers [29,30] should be considered as references. The BST can replace the MST of the WST constraint: the pruning rules of WST constraint will provide more inference since the bound it tighter. Actually, we can do even better by slightly modifying the pruning rule of the WST constraint for arcs that are between two SCC: an arc linking two SCC can only replace (or be replaced by) another arc linking those two same SCC. Consider a BST of cost B, the upper bound of the objective variable UB, an arc (x, y) \u2208 AR and a tree arc (u, v) \u2208 outArcs(x ), we can rephrase the pruning rule by: Any arc (u2, v2) \u2208 outArcs(x ) is infeasible if B\u2212f(u, v)+f(u2, v2) > UB. The reader should notice that no Lowest Common Ancestor (LCA) query is performed here. This do not only accelerate the algorithm, it also enables more pruning, because a LCA query could have returned an arc that does not link SCC x and y. Such an arc cannot replace (u, v) since exactly one arc of outArcs(x ) is mandatory.\nWe now briefly describe a simple and efficient way to compute the BST. We assume that the Reduced Path propagator has been applied and that GR is thus a path. Initially the BST is empty. First, we add to the BST mandatory arcs of GP , then for each x \u2208 VR we add minf ((u, v) \u2208 outArcs(x )). Finally, we run Kruskal\u2019s algorithm as described in [29,30] until the BST has n\u22121 arcs. A faster way to compute a BST is to perform Prim\u2019s algorithm on successive SCC, but this method does not enable to use the efficient filtering algorithm of Re\u0301gin [29].\nFigure 2 illustrates this relaxation : the input directed graph, on figure 2(a), is composed of four SCC {A}, {B,C}, {E,D,F} and {G}. For simplicity purpose, costs are symmetric. Its minimum hamiltonian path, figure 2(b), costs 28 and we will suppose that such a value is the current upper bound of the objective variable. The MST of the graph, figure 2(c), only costs 19, which is unfortunately too low to filter any arc. Instead, the BST, figure 2(d), is much more accurate. It actually consists of the MST of each SCC, {\u2205, {(BC)}, {(D,F ), (E,F )}, \u2205} with respective costs {0, 10, 10, 0}, and the cheapest arcs that connect SCC each others: {(A,B), (C,D), (F,G)} with respective costs {2, 3, 2}. Thus, the entire BST costs 27. It is worth noticing that it enables to filter arcs (B,E) and (E,G). Indeed, (B,E) can only replace (C,D) in the relaxation, so its marginal cost is f(BST ) + f(B,E) \u2212 f(C,D) = 27 + 5 \u2212 3 = 29 which is strictly greater than the upper bound of the objective. The same reasoning enables to prune (E,G)."}, {"heading": "5 The Held and Karp method", "text": "The Lagrangian relaxation of Held and Karp has initially been defined for solving symmetric TSP. Instead of converting asymmetric instances into symmetric ones, through the transformation of Jonker and Volgenant [4], we can directly adapt it to the asymmetric case: at each iteration k, we define two penalties per node v \u2208 V , \u03c0\n(k) in (v) and \u03c0 (k) out(v), respectively equal to (\u03b4 \u2212(k)(v)\u22121)\u2217C(k) and (\u03b4+(k)(v)\u2212 1) \u2217C(k). We note \u03b4\u2212(k)(v) the in-degree of v in the MST of iteration k whereas \u03b4+(k)(v) is its out-degree and C(k) is a constant whose calculation is discussed in [19,20]. As a path is expected, we post \u03c0 (k) in (s) = \u03c0 (k) out(e) = 0. Arc costs are then changed according to: f (k+1)(x, y) = f (k)(x, y) + \u03c0 (k) out(x) + \u03c0 (k) in (y). It has to be noticed that, since it relies on the computation of successive MST, such a model is equivalent to what would give the usual Held and Karp scheme used on a transformed instance. However, this framework is more general and can also handle the computation of Minimum Spanning Arborescence.\nSuch a method should be implemented within a specific propagator to be easily plugged, or unplugged, into a constraint. We noticed that keeping track of Lagrangian multipliers from one propagation to another, even upon backtracking, saves lots of computations and provides better results on average. Our approach is based on a few runs. A run is composed of K iterations in which we compute a MST according to Prim\u2019s algorithm and update C(k) and the cost matrix. Then, we run a Kruskal\u2019s based MST to apply the complete filtering of [4,29]. We first chose K = O(n) but this led to disappointing results when scaling up to a hundred nodes. We thus decided to fix K to a constant. The value K = 30 appeared as a good compromise between speed and accuracy. Remark that, as we perform a fix point, the method may be called several times per search node, and since it is relatively slow, we always schedule this propagator at the end of the propagation queue.\nThis procedure has the inconvenient of not being monotonic1 (it is not even idempotent): filtering, related to other propagators, can slow down the convergence of the method. The intuition is that to go from a MST to an optimal tour, it may be easier to use some infeasible arcs during the convergence process. One can see an analogy with local search techniques that explore infeasible solutions in order to reach the best (feasible) ones more quickly [8]. This fact, which occured during some of our experiments involving static branching heuristics, breaks the usual saying the more filtering, the better. Moreover, it follows that we cannot measure precisely the improvement stemming from additional structural filtering. We mention that the BST relaxation can be used within the Held and Karp scheme, however, this may also affect the convergence of the method and thus sometimes yield to poorer results. For that reason, we recommend to use a Lagrangian BST relaxation in addition to, rather than in replacement of, the usual Held and Karp procedure."}, {"heading": "6 Experimental study", "text": "This section presents some experiments we made in order to measure the impact of the graph structure. We will show that branching according to graph structure only outperforms current state of the art results while using implied filtering based on graph structure avoids pathological behaviors on hard instances at a negligible time consumption. Our implementations have been done within the CHOCO solver which is an open source Java library. Tests have been performed on a Macbook pro under OS X 10.7.2 and with a 2.7 GHz Intel core i7 and 8Go of DDR3. We set a limit of 3 Go to be allocated to the JVM. We tested TSP and ATSP instance of the TSPLIB. For each one, we refer to the number of search nodes by |nodes| and report time measurements in seconds. As in [4], we study optimality proof and thus provide the optimal value as an upper bound of the\n1 A propagator P , involving a graph variable GV and a filtering function f : GV 7\u2192 GV is said to be monotonic [31] iff for any GV \u2032 \u2286 GV, f(GV \u2032) \u2286 f(GV ), where GV \u2032 \u2286 GV \u21d4 G\u2032P \u2286 GP \u2227GM \u2286 G\u2032M .\nproblem. We computed equivalent state of the art results (SOTA) (referred as 1- tree with filtering in [4]), to position our model in general. Their implementation is in C++ and has no memory restriction.\nOur implementation (referred as BASIC) involves one graph variable, one integer variable (the objective) and one single constraint that is composed of several propagators. Subtour elimination is performed by a special purpose incremental propagator, inspired from the NoCycle constraint [7]. The degree constraint is ensured by special purpose incremental propagators described in section 3.1. The objective is adjusted by the natural relaxation and an implied propagator, based on the Held and Karp method. We mention that we solved rbg instances (that are highly asymmetric) by replacing the tree based relaxation by a Minimum Assignment Problem relaxation (also in SOTA). For that, we have implemented a simple Hungarian algorithm. Indeed, it always provided the optimal value as a lower bound at the root node. When a relaxation finds an optimal solution, this one can be directly enforced [4]. However, it could be in contradiction with side constraints. Thus, we unplugged such a greedy mode. The solver works under a trailing environment."}, {"heading": "6.1 Dedicated heuristics", "text": "We experimentally compare the branching heuristics RemoveMaxRC and Sparse of section 3.3. We also introduce three variants of these methods: - EnforceMaxRC, consists in enforcing the tree arc of maximum replacement cost. It is the opposite of RemoveMaxRC. - RemoveMaxMC, consists in removing the non tree arc of maximum marginal cost, i.e. the arc which would involve the highest cost augmentation if it was enforced. This heuristic may require an important number of decisions to solve the problem. There are low probabilities to make wrong decisions, but if a mistake has been performed early in the search tree, it might be disastrous for the resolution. - EnforceSparse, which first selects the set of nodes X with no successor in GM and the smallest set of successors in GP . Second, it finds the node x \u2208 X which maximize \u2211 (x,y)\u2208AP |{(z, y) \u2208 AP |z \u2208 X}|. Then it fixes the successor of x by enforcing the arc (x, y) \u2208 AP such that |{(z, y) \u2208 AP |z \u2208 X}| is maximal. All branching heuristics are performed in a binary tree search. RemoveMaxRC, RemoveMaxMC and Sparse can be said to be reduction heuristics. They respectively involve a worst case depth for the search tree of O(n2), O(n2) and O(n log n). In contrast, EnforceMaxRC and EnforceSparse perform assignments, leading to a O(n) depth in the worst case. Assignment heuristics perform strong decisions that bring more structure in left branches of the search tree while it is the opposite for reduction branchings that restrict more right branches. An exception is Sparse which has a balanced impact on both branches."}, {"heading": "6.2 Structural filtering", "text": "We then study the benefit we could get from adding some implied filtering algorithms to the BASIC model with RemoveMaxMC and Sparse heuristics: - ARB: Arborescence and AntiArborescence propagators used together. - POS: The model based on nodes position, with an AllDifferent constraint performing bound consistency. - AD: AllDifferent propagator, adapted to graph variables, with GAC. - BST: Reduced Path propagator with a Lagrangian relaxation based on a BST, in addition to the usual Held-Karp scheme. - ALL: combine all above propagators."}, {"heading": "6.3 Results and analysis", "text": "Table 1 provides our experimental results over the impact of branching strategies. RemoveMaxRC can be seen as our implementation of the SOTA model. The main differences between these two are the fact that we perform a fixpoint and implementation details of the Held and Karp scheme. As it can be seen, our Java implementation is faster and more robust (br17, kro124p and rbg323). Results clearly show that the most recently used heuristic [4] is actually not very appropriate and that the more natural EnforceMaxRC is much more efficient. EnforceMaxRC is in general better than RemoveMaxRC, showing the limits of the first fail principle. The worst heuristic is clearly RemoveMaxMC while the best ones are EnforceMaxRC, Sparse and EnforceSparse. More precisely, graph based heuristics are the best choice for the ftv set of instances whereas EnforceMaxRC behaves better on rbg instances. This efficiency (not a single failure for instances rbg) is explained by the fact that EnforceMaxRC is driven by the MAP relaxation, which is extremely accurate here. In contrast, Sparse heuristic does too many decisions (because of the dichotomic branching), even if the number of wrong ones is negligible. Results show that assignment based branchings work better than reduction heuristics. The most robust branching strategy is EnforceSparse. Thus, graph structure can play a significant role during the search. However, side constraints of real world applications might require to use dedicated heuristics, so results should not entirely rely on the branching strategy.\nWe now study the impact of implied filtering algorithms on robustness of the model. For that, we consider the best heuristic, EnforceSparse, and solve TSPLIB\u2019s instances within different model configurations. Results can be seen on Table 2. It can be seen that implied algorithms do not significantly increase performances on all instances, but it seriously improves the resolution of hard ones (ftv170 and p43 are solved 5 times faster by ALL). Moreover, those extra algorithms are not significantly time expensive. The eventual loss is more due to model instability rather than filtering algorithms\u2019 computing time. Indeed, a stronger filtering sometimes yields to more failures because it affects both the branching heuristic and the Langrangian relaxation\u2019s convergence. In general, no implied propagator outperforms others, it depends on instances and branching heuristics. The combination of them (ALL) is not always the best model but it provides robustness at a good trade off between filtering quality and resolution time."}, {"heading": "6.4 Consequences on symmetric instances", "text": "In this section, we show the repercussion of our study on the (symmetric) Traveling Salesman Problem (TSP), which can be seen as the undirected variant of the ATSP. For that, we use an undirected model, as in [4]: Each node has now two neighbors. Previously mentioned implied structural filtering algorithms are defined for directed graphs, and thus cannot be used for solving the TSP. However, our study about search heuristics can be extended to the symmetric case.\nIt is worth noticing that the Sparse heuristic cannot be used here because the dichotomic exploration is not defined for set variables that must take two values. We suggest to measure the impact of EnforceSparse heuristic that we have introduced and which appeared as the best choice for solving the ATSP. As can be seen in Table 3, the EnforceSparse heuristic can dramatically enhance performances on TSP instances. While the SOTA model fails to solve most instances within the time limit of 30 minutes, our approach solves all instances that have up to 150 nodes in less than one minute (kroB150 appart) and close half of the others that have up to 300 nodes. This seems to be the new limit of CP. Scaling further on simple instances would be easy: the number of iterations in the Lagrangian relaxation should be decreased to get reasonable computing times, but solving bigger and still hard instances would require serious improvements."}, {"heading": "7 Conclusion", "text": "We have provided a short survey over solving the ATSP in CP and shown how general graph properties, standing from the consideration of the reduced graph, could improve existing models, such as the Minimum Spanning Tree relaxation. As future work, this could be extended to scheduling oriented TSP (TSPTW for instance) since Reduced Path finds some sets of precedences in linear time.\nWe also provided some implementation guidelines to have efficient algorithms, including the Held and Karp procedure. We have shown that our model outperforms the current state of the art CP model for solving both TSP and ATSP, pushing further the limit of CP. Our experiments enable us to state that graph structure has a serious impact on resolution: not only cost matters. More precisely, the EnforceSparse heuristic provides impressive results while implied structural filtering improves robustness for a negligible time consumption.\nWe also pointed out the fact that non monotonicity of the Lagrangian relaxation could make implied filtering decrease performances. An interesting future work would be to introduce some afterglow into the Held and Karp method: when the tree based relaxation is applied, it first performs a few iterations allowing, but penalizing, the use of arcs that have been removed since the last call of the constraint. This smoothing could make the convergence easier and thus lead to better results."}, {"heading": "Acknowledgement", "text": "The authors thank Pascal Benchimol and Louis-Martin Rousseau for interesting talks and having provided their C++ implementation as well as Charles Prud\u2019Homme for useful implementation advise. They are also grateful to the regional council of Pays de la Loire for its financial support."}], "references": [{"title": "The Traveling Salesman Problem: A Computational Study", "author": ["David L. Applegate", "Robert E. Bixby", "Vasek Chv\u00e1tal", "William J. Cook"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Combining Tree Partitioning, Precedence, and Incomparability", "author": ["Nicolas Beldiceanu", "Pierre Flener", "Xavier Lorca"], "venue": "Constraints. Constraints,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Necessary Condition for Path Partitioning Constraints", "author": ["Nicolas Beldiceanu", "Xavier Lorca"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2007}, {"title": "Conception d\u2019une contrainte globale de chemin", "author": ["Hadrien Cambazard", "Eric Bourreau"], "venue": "In Journe\u0301es Nationales sur la re\u0301solution Pratique de Proble\u0300mes NP Complets,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Algorithms and codes for the assignment problem", "author": ["Giorgio Carpaneto", "Silvano Martello", "Paolo Toth"], "venue": "Annals of Operations Research,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1988}, {"title": "Solving Small TSPs with Constraints", "author": ["Yves Caseau", "Fran\u00e7ois Laburthe"], "venue": "In International Conference on Logic Programming,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "A tabu search heuristic for the static multi-vehicle dial-a-ride problem", "author": ["Jean-Fran\u00e7ois Cordeau", "Gilbert Laporte"], "venue": "Transportation Research Part B: Methodological,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2003}, {"title": "CP(Graph): Introducing a Graph Computation Domain in Constraint Programming", "author": ["Gr\u00e9goire Dooms", "Yves Deville", "Pierre Dupont"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "The Minimum Spanning Tree Constraint", "author": ["Gr\u00e9goire Dooms", "Irit Katriel"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "The \u201dNot-Too-Heavy Spanning Tree", "author": ["Gr\u00e9goire Dooms", "Irit Katriel"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Revisiting the tree Constraint", "author": ["Jean-Guillaume Fages", "Xavier Lorca"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Lazy Clause Generation Reengineered", "author": ["Thibaut Feydy", "Peter J. Stuckey"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "An additive bounding procedure for the asymmetric travelling salesman problem", "author": ["Matteo Fischetti", "Paolo Toth"], "venue": "Mathematical Programming,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1992}, {"title": "Embedding Relaxations in Global Constraints for Solving TSP and TSPTW", "author": ["Filippo Focacci", "Andrea Lodi", "Michela Milano"], "venue": "Annals of Mathematics and Artificial Intelligence,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2002}, {"title": "A Hybrid Exact Algorithm for the TSPTW", "author": ["Filippo Focacci", "Andrea Lodi", "Michela Milano"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2002}, {"title": "Efficient algorithms for finding minimum spanning trees in undirected and directed graphs", "author": ["Harold N. Gabow", "Zvi Galil", "Thomas H. Spencer", "Robert E. Tarjan"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1986}, {"title": "Incremental Cycle Detection, Topological Ordering, and Strong Component Maintenance", "author": ["Bernhard Haeupler", "Telikepalli Kavitha", "Rogers Mathew", "Siddhartha Sen", "Robert E. Tarjan"], "venue": "The Computing Research Repository, CoRR,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "The traveling-salesman problem and minimum spanning trees: Part II", "author": ["Michael Held", "Richard M. Karp"], "venue": "Mathematical Programming,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1971}, {"title": "An effective implementation of the Lin-Kernighan traveling salesman heuristic", "author": ["Keld Helsgaun"], "venue": "European Journal of Operational Research,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2000}, {"title": "A Filter for the Circuit Constraint", "author": ["Latife Gen\u00e7 Kaya", "John N. Hooker"], "venue": "In Principles and Practice of Constraint Programming,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "A Simpler Minimum Spanning Tree Verification Algorithm", "author": ["Valerie King"], "venue": "In Workshop on Algorithms and Data Structures, WADS,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1995}, {"title": "The Hungarian Method for the Assignment Problem", "author": ["Harold W. Kuhn"], "venue": "Years of Integer Programming", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1958}, {"title": "Robust and Parallel Solving of a Network Design Problem", "author": ["Claude Le Pape", "Laurent Perron", "Jean-Charles R\u00e9gin", "Paul Shaw"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "An Exact Constraint Logic Programming Algorithm for the Traveling Salesman Problem with Time Windows", "author": ["Gilles Pesant", "Michel Gendreau", "Jean-Yves Potvin", "Jean-Marc Rousseau"], "venue": "Transportation Science,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Using Dominators for Solving Constrained Path Problems", "author": ["Luis Quesada", "Peter Van Roy", "Yves Deville", "Rapha\u00ebl Collet"], "venue": "In Practical Aspects of Declarative Languages,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2006}, {"title": "A Filtering Algorithm for Constraints of Difference in CSPs", "author": ["Jean-Charles R\u00e9gin"], "venue": "In National Conference on Artificial Intelligence,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1994}, {"title": "Tutorial: Modeling Problems in Constraint Programming", "author": ["Jean-Charles. R\u00e9gin"], "venue": "In Principles and Practice of Constraint Programming,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2004}, {"title": "Simpler and Incremental Consistency Checking and Arc Consistency Filtering Algorithms for the Weighted Spanning Tree Constraint. In Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization", "author": ["Jean-Charles R\u00e9gin"], "venue": "Problems, CPAIOR,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "The Weighted Spanning Tree Constraint Revisited. In Integration of AI  and OR Techniques in Constraint Programming for Combinatorial Optimization", "author": ["Jean-Charles R\u00e9gin", "Louis-Martin Rousseau", "Michel Rueher", "Willem Jan van Hoeve"], "venue": "Problems, CPAIOR,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "Weakly Monotonic Propagators", "author": ["Christian Schulte", "Guido Tack"], "venue": "In Principles and Practice of Constraint Programming, CP,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "Depth-First Search and Linear Graph Algorithms", "author": ["Robert E. Tarjan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1972}, {"title": "O(n log n) Filtering Algorithms for Unary Resource Constraint", "author": ["Petr Vi\u013a\u0131m"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "Given a n node, m arc complete directed weighted graph G = (V,A, f : A\u2192 R), the Asymmetric Traveling Salesman Problem [1] (ATSP) consists in finding a partial subgraph G\u2032 = (V,A\u2032, f) of G which forms a Hamiltonian circuit of minimum cost.", "startOffset": 118, "endOffset": 121}, {"referenceID": 0, "context": "The symmetric TSP is well handled by linear programming techniques [1].", "startOffset": 67, "endOffset": 70}, {"referenceID": 22, "context": "[24] and detailed by R\u00e9gin [28] and Dooms et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[24] and detailed by R\u00e9gin [28] and Dooms et al.", "startOffset": 27, "endOffset": 31}, {"referenceID": 7, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 13, "context": "However, it is often more interesting to convert such a model in order to find a path instead of a circuit [15,25].", "startOffset": 107, "endOffset": 114}, {"referenceID": 23, "context": "However, it is often more interesting to convert such a model in order to find a path instead of a circuit [15,25].", "startOffset": 107, "endOffset": 114}, {"referenceID": 25, "context": "A higher level of consistency can be achieved by using a graph-based AllDifferent constraint maintaining a node-successor perfect matching [27].", "startOffset": 139, "endOffset": 143}, {"referenceID": 5, "context": "Caseau and Laburthe [7] suggested the simple and efficient NoCycle constraint to remove circuits of the graph.", "startOffset": 20, "endOffset": 23}, {"referenceID": 24, "context": "For instance, Quesada [26] suggested the general propagator DomReachability which maintains the transitive closure and the dominance", "startOffset": 22, "endOffset": 26}, {"referenceID": 1, "context": "It is nothing else but a simplification of the Tree constraint [2] recently improved to a O(n+m) worst case time complexity [12].", "startOffset": 63, "endOffset": 66}, {"referenceID": 10, "context": "It is nothing else but a simplification of the Tree constraint [2] recently improved to a O(n+m) worst case time complexity [12].", "startOffset": 124, "endOffset": 128}, {"referenceID": 31, "context": "It has to be noticed that this approach is related to disjunctive scheduling [33]: nodes are tasks of duration 1 which are executed on the same machine.", "startOffset": 77, "endOffset": 81}, {"referenceID": 19, "context": "enforce some cut-sets of size two [4] while Kaya and Hooker use graph separators for pruning [21].", "startOffset": 93, "endOffset": 97}, {"referenceID": 12, "context": "Fischetti and Toth [14] suggested a general bounding procedure for combining different relaxations of the same problem.", "startOffset": 19, "endOffset": 23}, {"referenceID": 21, "context": "It requires O(n(m + n log n)) time [23] to compute a first minimum cost assignment but then O(n) time [6] to check consistency and filter incrementally.", "startOffset": 35, "endOffset": 39}, {"referenceID": 4, "context": "It requires O(n(m + n log n)) time [23] to compute a first minimum cost assignment but then O(n) time [6] to check consistency and filter incrementally.", "startOffset": 102, "endOffset": 105}, {"referenceID": 14, "context": "Some interesting evaluations are provided by [16], but are mainly related to the TSP with time windows constraints.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "compute a MST with a degree restriction at one node [17].", "startOffset": 52, "endOffset": 56}, {"referenceID": 15, "context": "The second option is to use Prim\u2019s algorithm which requires O(m+n log n) time with Fibonacci heaps [17] or O(m log n) time if binomial heaps are used instead.", "startOffset": 99, "endOffset": 103}, {"referenceID": 27, "context": "[29,30] made the Weighted Spanning Tree constraint which ensures consistency, provides a complete pruning and detects mandatory arcs incrementally, within O(\u03b1m) time.", "startOffset": 0, "endOffset": 7}, {"referenceID": 28, "context": "[29,30] made the Weighted Spanning Tree constraint which ensures consistency, provides a complete pruning and detects mandatory arcs incrementally, within O(\u03b1m) time.", "startOffset": 0, "endOffset": 7}, {"referenceID": 8, "context": "Dooms and Katriel [10,11] presented a more complex Minimum Spanning Tree constraint which maintains a graph and its spanning tree, pruning according to King\u2019s algorithm [22].", "startOffset": 18, "endOffset": 25}, {"referenceID": 9, "context": "Dooms and Katriel [10,11] presented a more complex Minimum Spanning Tree constraint which maintains a graph and its spanning tree, pruning according to King\u2019s algorithm [22].", "startOffset": 18, "endOffset": 25}, {"referenceID": 20, "context": "Dooms and Katriel [10,11] presented a more complex Minimum Spanning Tree constraint which maintains a graph and its spanning tree, pruning according to King\u2019s algorithm [22].", "startOffset": 169, "endOffset": 173}, {"referenceID": 17, "context": "An improvement of the MST relaxation is the approach of Held and Karp [19], adapted for CP by Benchimol et al.", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "This relaxation has been studied by [14,15] who provide a O(n) time filtering algorithm based on primal/dual linear programs.", "startOffset": 36, "endOffset": 43}, {"referenceID": 13, "context": "This relaxation has been studied by [14,15] who provide a O(n) time filtering algorithm based on primal/dual linear programs.", "startOffset": 36, "endOffset": 43}, {"referenceID": 15, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "The Lagrangian MSA relaxation, with a MSA computation based on Edmonds\u2019 algorithm, has been suggested in [7].", "startOffset": 105, "endOffset": 108}, {"referenceID": 23, "context": "have introduced Sparse heuristic [25] which has the singularity of considering occurrences of successors and ignoring costs.", "startOffset": 33, "endOffset": 37}, {"referenceID": 13, "context": "solve the TSPTW [15] by guiding the search with time windows, which means that the efficiency of CP for solving the ATSP should not rely entirely on its branching heuristic.", "startOffset": 16, "endOffset": 20}, {"referenceID": 2, "context": "The structure of the reduced graph has already been considered in a similar way for path partitioning problems [3,5].", "startOffset": 111, "endOffset": 116}, {"referenceID": 3, "context": "The structure of the reduced graph has already been considered in a similar way for path partitioning problems [3,5].", "startOffset": 111, "endOffset": 116}, {"referenceID": 29, "context": "It is a monotonic generalization of the algorithm depicted in [31].", "startOffset": 62, "endOffset": 66}, {"referenceID": 3, "context": "Necessary conditions for this propagator have already been partially highlighted in [5].", "startOffset": 84, "endOffset": 87}, {"referenceID": 30, "context": "Data structures: Compute the SCC of GP (with Tarjan\u2019s algorithm [32]) and build the reduced graph GR = (VR, AR).", "startOffset": 64, "endOffset": 68}, {"referenceID": 16, "context": "[18] worked on maintaining SCC and a topological ordering of nodes in the reduced graph, but under the addition of arcs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Such information can be directly used to generate lazy clauses [13].", "startOffset": 63, "endOffset": 67}, {"referenceID": 24, "context": "Some propagators such as DomReachability [26], require the transitive closure of the graph.", "startOffset": 41, "endOffset": 45}, {"referenceID": 27, "context": "We assume that the reader is already familiar with this constraint, otherwise papers [29,30] should be considered as references.", "startOffset": 85, "endOffset": 92}, {"referenceID": 28, "context": "We assume that the reader is already familiar with this constraint, otherwise papers [29,30] should be considered as references.", "startOffset": 85, "endOffset": 92}, {"referenceID": 27, "context": "Finally, we run Kruskal\u2019s algorithm as described in [29,30] until the BST has n\u22121 arcs.", "startOffset": 52, "endOffset": 59}, {"referenceID": 28, "context": "Finally, we run Kruskal\u2019s algorithm as described in [29,30] until the BST has n\u22121 arcs.", "startOffset": 52, "endOffset": 59}, {"referenceID": 27, "context": "A faster way to compute a BST is to perform Prim\u2019s algorithm on successive SCC, but this method does not enable to use the efficient filtering algorithm of R\u00e9gin [29].", "startOffset": 162, "endOffset": 166}, {"referenceID": 17, "context": "in [19,20].", "startOffset": 3, "endOffset": 10}, {"referenceID": 18, "context": "in [19,20].", "startOffset": 3, "endOffset": 10}, {"referenceID": 27, "context": "Then, we run a Kruskal\u2019s based MST to apply the complete filtering of [4,29].", "startOffset": 70, "endOffset": 76}, {"referenceID": 6, "context": "One can see an analogy with local search techniques that explore infeasible solutions in order to reach the best (feasible) ones more quickly [8].", "startOffset": 142, "endOffset": 145}, {"referenceID": 29, "context": "1 A propagator P , involving a graph variable GV and a filtering function f : GV 7\u2192 GV is said to be monotonic [31] iff for any GV \u2032 \u2286 GV, f(GV \u2032) \u2286 f(GV ), where GV \u2032 \u2286 GV \u21d4 GP \u2286 GP \u2227GM \u2286 GM .", "startOffset": 111, "endOffset": 115}, {"referenceID": 5, "context": "Subtour elimination is performed by a special purpose incremental propagator, inspired from the NoCycle constraint [7].", "startOffset": 115, "endOffset": 118}], "year": 2012, "abstractText": "Recent works on cost based relaxations have improved Constraint Programming (CP) models for the Traveling Salesman Problem (TSP). We provide a short survey over solving asymmetric TSP with CP. Then, we suggest new implied propagators based on general graph properties. We experimentally show that such implied propagators bring robustness to pathological instances and highlight the fact that graph structure can significantly improve search heuristics behavior. Finally, we show that our approach outperforms current state of the art results.", "creator": "LaTeX with hyperref package"}}}