{"id": "1206.4608", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "A Hybrid Algorithm for Convex Semidefinite Optimization", "abstract": "80 We therefore present dub\u00e9 a hybrid desiderata algorithm for tribus optimizing a papadimitriou convex, berrios smooth function ressa over nacorda the epigallocatechin cone of tice positive semidefinite matrices. Our j.league algorithm fanaa converges to hobert the global optimal hazelhurst solution and can be dongle used to anneliese solve 104.22 general kinlaw large - kessiakoff scale semidefinite 3.2-kilometer programs and hence 2,510 can amelioration be wynant readily pushdown applied povoa to a chikmagalur variety hiap of stationarity machine learning bachao problems. timecode We show experimental ellas results ala.-based on three machine learning soekarno-hatta problems (kreuk matrix completion, narvekar metric lanning learning, disinvest and sparse PCA ). calandra Our 48.09 approach podian outperforms beara state - of - the - art chameleon algorithms.", "histories": [["v1", "Mon, 18 Jun 2012 14:44:28 GMT  (247kb)", "http://arxiv.org/abs/1206.4608v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.DS cs.NA stat.ML", "authors": ["s\u00f6ren laue"], "accepted": true, "id": "1206.4608"}, "pdf": {"name": "1206.4608.pdf", "metadata": {"source": "META", "title": "A Hybrid Algorithm for Convex Semidefinite Optimization", "authors": ["S\u00f6ren Laue"], "emails": ["soeren.laue@uni-jena.de"], "sections": [{"heading": "1. Introduction", "text": "We consider the following unconstrained semidefinite optimization problem:\nmin f(X) s.t. X 0 , (1)\nwhere f(X) : Rn\u00d7n \u2192 R is a convex and differentiable function over the cone of positive semidefinite matrices. Many machine learning problems can be cast as a semidefinite optimization problem. Prominent examples include sparse PCA (d\u2019Aspremont et al., 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al., 2004).\nWe provide an algorithm that solves general large-scale unconstrained semidefinite optimization problems efficiently. The idea to our algorithm is a hybrid approach: we combine the algorithm of Hazan (2008) with a standard quasi-Newton algorithm. The algorithm achieves convergence to the global optimum with very good running time. It can be readily used for a\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\nvariety of machine learning problems and we demonstrate its efficiency on three different tasks: matrix completion, metric learning, and sparse PCA. Another advantage of the algorithm is its simplicity, as it can be implemented in less than 30 lines of Matlab code."}, {"heading": "1.1. Related Work", "text": "A constrained version of Problem 1 is called a semidefinite program (SDP) if function f as well as the constraints are linear. Semidefinite programs have gained a lot of attention in recent years, since many NP-hard problems can be relaxed into SDPs and many machine learning problems can be modeled as SDPs.\nThe most widely known implementations of SDP solvers are interior point methods. They provide highaccuracy solutions in polynomial time. However, since the running time is a low-order polynomial in the dimension n they do not scale well to medium and large problems that often occur in machine learning. On the other hand, the high accuracy of their solutions is typically not needed as the input data is often noisy. Among other methods, proximal methods have been employed to solve SDPs in order to circumvent the large running time of interior point methods. They achieve better running times at the expense of less accurate solutions. Examples include (Nesterov, 2007; Nemirovski, 2004) and (Arora et al., 2005) where the multiplicative weights update rule is employed.\nThe algorithm of (Arora et al., 2005) has been randomized by (Garber & Hazan, 2011) based on the same idea as in (Grigoriadis & Khachiyan, 1995) to achieve sublinear running time. Another randomized algorithm has appeared in (Kleiner et al., 2010). Furthermore, alternating direction methods have been proposed to solve SDPs (Wen et al., 2010).\nAnother line of algorithms for solving SDPs are FrankWolfe type algorithms such as (Hazan, 2008). This approach is also known as sparse greedy approximation and these algorithms have the advantage that they produce sparse solutions (Clarkson, 2008) which, for SDPs, corresponds to low-rank solutions. Low-rank\nsolutions are very appealing since they can drastically reduce the computational effort. Instead of storing a low-rank positive semidefinite matrix X \u2208 Rn\u00d7n one just stores a matrix V \u2208 Rn\u00d7k where X = V V T , with k being the rank of X. Matrix-vector multiplications, for instance, can be done in O(nk) instead of O(n2).\nThere have also been nonlinear approaches to linear SDPs, however, without general convergence guarantees (Burer & Monteiro, 2003). In some special cases (matrix completion problems where it is assumed that the data is indeed generated by a low rank matrix and the restricted isometry property holds) convergence guarantees have been shown. In general, the problem of solving an SDP with a low-rank constraint is NP-hard (Goemans & Williamson, 1995).\nOrganization of the Paper Section 2 describes our algorithm while in Section 3 we provide experimental results on three different machine learning problems. We compare our algorithm against a standard interior point method and against algorithms that are specifically designed for each of the individual problems. Section 4 provides theoretical guarantees for the running time and for the convergence to the global optimal solution."}, {"heading": "2. The Hybrid Algorithm", "text": "Our algorithm is summarized in pseudo-code in Algorithm 1.\nAlgorithm 1 Hybrid Algorithm Input: Smooth, convex function f : Rn\u00d7n \u2192 R Output: Approximate solution of Problem 1 Initialize X0 = 0, V0 = 0 repeat\nIncrease rank by 1 using Hazan update: Compute vi = ApproxEV(\u2212\u2207f(ViV Ti ), \u03b5\u0303). Solve\nmin\u03b1,\u03b2 f(\u03b1 \u00b7 ViV Ti + \u03b2 \u00b7 vivTi ) s. t. \u03b1, \u03b2 \u2265 0.\nSet Vi+1 = [ \u221a \u03b1 \u00b7 Vi, \u221a \u03b2 \u00b7 vi].\nRun nonlinear update: Improve Vi+1 by finding a local minimum of f(V V T ) wrt. V starting with Vi+1.\nuntil Approximation guarantee has been reached\nThe notation [Vi, vi] used in Algorithm 1 stands for the horizontal concatenation of matrix Vi and column vector vi. The function ApproxEV returns an approximate eigenvector to the largest eigenvalue:\ngiven a square matrix M it returns a vector vi = ApproxEV(M, \u03b5\u0303) of unit length that satisfies vTi Mvi \u2265 \u03bbmax(M) \u2212 \u03b5\u0303, where \u03bbmax(M) denotes the largest eigenvector of matrix M .\nOur algorithm runs in iterations. Each iteration consists of two steps: a rank-1 update and a subsequent nonlinear improvement of the current solution. The rank-1 update step follows a Frank-Wolfe type approach. A linear approximation to function f at the current iterate Xi is minimized over the cone of semidefinite matrices. The minimum is attained at viv T i where vi = \u03bbmax(\u2212\u2207f(Xi)) is the vector to the largest eigenvalue of \u2212\u2207f(Xi). Then the next iterate Xi+1 is a linear combination of the current iterate Xi = ViV Ti and viv T i such that it minimizes f .\nIn the second step, the nonlinear update step, the current solution Xi+1 = Vi+1V Ti+1 is further improved by minimizing function f(V V T ) with respect to V . Note that this function is no longer convex with respect to V . Hence, we can only expect to find a local minimum. Our analysis however shows, that this is sufficient to still converge to the global optimal solution of Problem 1. In fact, it is even not necessary to find a local minimum, any improvement will work.\nIn Section 4 we will prove that after at most O( 1\u03b5 ) many iterations Algorithm 1 will return a solution that is \u03b5-close to the global optimal solution."}, {"heading": "3. Applications and Experiments", "text": "We have implemented our hybrid algorithm in Matlab exactly as described in Algorithm 1. For the nonlinear update we use minFunc (Schmidt) which implements the limited memory BFGS algorithm. The twovariable optimization problem in the rank-1 update is also solved using minFunc. We use the default settings of minFunc. The approximate eigenvector computation is done using the Matlab function eigs. We ran all experiments in single-thread mode on a 2.50GHz CPU."}, {"heading": "3.1. Matrix Completion", "text": "In this section we consider the matrix completion problem used for collaborative filtering. Given a matrix Y where only a few entries have been observed the goal is to complete this matrix by finding a low-complexity matrix X which approximates the given entries of Y as good as possible. Low complexity can be achieved for instance by a low rank or by small trace norm. Also different error norms can be considered depending on the specific application. For instance, the l1-norm in combination with the trace-norm regularization leads\nto the robust PCA approach for matrix completion with low rank (Cande\u0300s et al., 2011). Here, we use the l2-norm and the rank constraint as a measure of complexity. Hence, the matrix completion problem becomes the following optimization problem:\nmin \u2211\n(i,j)\u2208\u2126(Xij \u2212 Yij)2 s.t. rank(X) \u2264 k , (2)\nwhere \u2126 is the set of all given entries of Y . Note that Problem (2) is NP-hard (Gillis & Glineur, 2011). However, we can still attempt to find a good solution to it by using our hybrid algorithm. Problem (2) can be transformed into the following equivalent semidefinite optimization problem:\nmin \u2211\n(i,j)\u2208\u2126\u0302(X\u0302ij \u2212 Y\u0302ij)2\ns.t. rank(X\u0302) \u2264 k X\u0302 0 ,\n(3)\nwhere X\u0302 = (\nV X XT W\n) and Y\u0302 = ( 0 Y Y T 0 ) ,\nand X\u0302 is a positive semidefinite matrix. V and W are suitable symmetric matrices. Hence, the matrix completion Problem (2) for an input matrix Y \u2208 Rm\u00d7n can be cast into a semidefinite optimization problem over matrices X \u2208 R(m+n)\u00d7(m+n).\nWe compare our algorithm to a state-of-the-art solver GECO (Shalev-Shwartz et al., 2011) which was specifi-\ncally designed for solving large-scale matrix minimization problems with a low-rank constraint. We follow the experimental setting of (Shalev-Shwartz et al., 2011). We use three standard matrix completion datasets: MovieLens100k, MovieLens1M, and MovieLens10M. The dimensions of the three datasets are 943 \u00d7 1682, 6040 \u00d7 3706, and 69878 \u00d7 10677 respectively and they contain 105, 106, and 107 movie ratings from 1 to 5. The task is to predict a movie rating for user i and movie j. We used the datasets without any normalization1 and split them randomly such that for each user 80% of the ratings went into training data and 20% into test data.\nOur algorithm minimizes the training error much faster than GECO and at the same time also needs a much smaller rank. As a result we also achieve an optimal test error much faster and with a smaller rank than GECO. Table 1 reports the test root-mean-square error (RMSE) as well as the rank where it was achieved and the running times. Both rows for GECO in Table 1 reflect the same runs. The first row shows the statistics where the test error reaches the minimum. However, since GECO slows down a lot with the rank we also added intermediate results when the test error is approaching the minimum. As it can be observed our algorithm achieves the same or better test error by requiring only a fraction of the time needed by GECO.\n1We noticed that normalization had no impact on the results.\nBoth algorithms need quasi-linear time in the number of ratings and hence can be used to solve large scale matrix factorization problems. Note however, that for our algorithm the runtime per iteration scales linearly with the rank k whereas GECO needs O(k6). This behavior slows down GECO considerably, which can be seen in Figure 1."}, {"heading": "3.2. Metric Learning", "text": "The second problem we approach is the metric learning problem. We are given a labeled dataset X = (xi, yi)i. Let S be a set containing all pairs of indices (i, j) whose data points xi and xj are similar to each other, i.e. its labels yi and yj are equal; let the set S\u0304 contain all indices of data points that are dissimilar to each other. For a given semidefinite matrix A, the Mahalanobis distance between xi and xj is defined as dA(i, j) = \u221a (xi \u2212 xj)TA(xi \u2212 xj). The metric learning problem is that of finding a positive semidefinite matrix A, such that under the induced Mahalanobis distance, points that are similar are close to each other and points that are dissimilar are far apart. This problem can be cast as a semidefinite optimization problem(Xing et al., 2002):\nmin \u2211\n(i,j)\u2208S dA(i, j) 2 s.t. \u2211\n(i,j)\u2208S\u0304 dA(i, j) \u2265 1 A 0.\n(4)\nNote that the 1 in the inequality constraint in Problem (4) can be changed to any arbitrary positive constant. This constraint is just to ensure that not all points are mapped onto the same point. Problem (4) does not fit into our framework. However, we can transform it into the following equivalent unconstrained semidefinite problem:\nmin \u2211\n(i,j)\u2208S dA(i, j) 2 \u2212 \u03bb \u2211 (i,j)\u2208S\u0304 dA(i, j)\ns. t. A 0. (5)\nProblem (5) is just the Lagrangian of Problem (4). Since the 1 in the inequality constrained was chosen arbitrary we can also choose any positive constant for \u03bb. In our experiments we set it to 1.\nWe follow the experimental setting of (Kleiner et al., 2010). We compared our approach against an interior point method implemented in SeDuMi (Sturm, 1999) (via CVX (Grant & Boyd, 2011)) and the algorithm of (Xing et al., 2002) which is a projected gradient approach and was specifically designed to solve the above SDP. We could not directly compare our algorithm to that of (Kleiner et al., 2010) as the code was not available. However, the authors show that it performs similarly to (Xing et al., 2002).\nAs a measure of quality for a given solution A we define:\nQ(A) = 1 \u03be \u00b7 \u2211 i \u2211 j:(i,j)\u2208S \u2211 l:(i,l)\u2208S\u0304 1[dA(i, j) < dA(i, l))],\nwhere 1[.] is the indicator function and \u03be =\u2211 i \u2211 j:(i,j)\u2208S \u2211 l:(i,l)\u2208S\u0304 1 is a normalization factor. In essence Q captures how many points with the same label are mapped closer to each other than points with different labels.\nWe initially apply metric learning to the UCI ionosphere dataset which contains 351 labeled data points in dimension 34. The results of this experiment are shown in Figure 2. As it can be seen, our hybrid algorithm achieves the optimal value almost instantly. The projected gradient descent algorithm (PG) needs about 20 times as long to achieve a solution of comparable quality. Since the interior point method (IP) scales very badly with the number of data points, we only ran it on a sub-sample of size 4*34=136. On this dataset, our method achieves the same function value as IP: 5.47e-05, while requiring only 0.28 seconds as opposed to 1513 seconds that IP needs. PG achieves a function value of 5.50e-05 in 88 seconds.\nFollowing (Kleiner et al., 2010), we ran a second set of experiments on synthetic data in order to measure the dependence on the dimension d. We sampled points from Rd as follows: We define two sets of cluster centers C1 = {(\u22121, 1), (\u22121,\u22121)} and C2 = {(1,\u22121), (1, 1)} and apply a random rotation to both sets. We then sample each data point from a uniform Gaussian distribution N (0, Id). The first two coordinates of each data point are replaced by one of the cluster centers and the label of this data point is set accordingly to either 1 or 2. Finally, a small perturbation drawn from N (0, 0.25I2) is added to the first two coordinates. The results are depicted in Table 2, which shows the running times for the various algorithms until a quality measure of Q > 0.99 has been reached.\nOur algorithm achieves the same optimal function values as the interior point method, while requiring less\ntime than the PG method. For larger dimensions we plot the results in Figure 3. As it can be observed, our algorithm is considerably faster than PG on these larger dimensions. We omit the IP method here, as this scales badly with increased dimension."}, {"heading": "3.3. Sparse PCA", "text": "As a third problem we consider the sparse principal component analysis problem (sparse PCA). For a given covariance matrix A \u2208 Rn\u00d7n, sparse PCA tries to find a sparse vector x that maximizes xTAx, i.e. a sparse principal component of A. This problem can be relaxed into the following SDP (d\u2019Aspremont et al., 2007):\nmin \u03c1 \u2211\n(i,j) |Xij | \u2212A \u2022X s. t. Tr(X) = 1\nX 0, (6)\nwhere A\u2022X denotes Tr(ATX). In a subsequent rounding step the largest eigenvector of the solution to Problem (6) is returned as the solution vector x. The parameter \u03c1 controls the tradeoff between the sparsity of x and the explained variance xTAx.\nProblem (6) is not in form (1). However, one can easily transform it into an unconstrained semidefinite problem by defining the functions g(X) = XTr(X) and f(X) = \u03c1 \u2211 (i,j) |Xij | \u2212 A \u2022X. Hence, Problem (6) is equivalent to min f(g(X))\nX 0. (7)\nNote that f(g(X)) is again a convex function over\nthe set of semidefinite matrices without the zero matrix. However, f(g(X)) is not smooth. Smoothness of f(g(X)) can be achieved either by implicitly smoothing it, e.g. using Nesterov\u2019s smoothing technique (Nesterov, 2005) or by explicitly smoothing it and replacing the absolute function |.| with the scaled Huber-loss HM . The Huber-loss is defined as:\nHM (x) = { x2 if |x| \u2264M 2M |x| \u2212M2 if |x| > M\nBy appropriate scaling one can achieve an arbitrary small difference between |x| and HM (x). We obtain a smooth, convex function fHM by replacing the absolute function with the Huber-loss in function f . In our experiments we set M = 10\u22126 such that functions fHM and f differ only marginally from each other.\nWe again follow the experimental setting of (Kleiner et al., 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d\u2019Aspremont et al., 2007) which is specifically designed to solve Problem (6). We used the colon cancer data set which contains 2000 microarray readings from 62 subjects. We randomly sampled readings in order to vary the dimension d. As standard with this task, we normalized the data to mean 0 and standard deviation 1. We set \u03c1 = 0.2 in Problem (6) to obtain sparse solutions for all d.\nTable 3 reports the running time, the function value at convergence, the sparsity of the solution and the\ncaptured variance for these data sets. As mentioned above, we ran our algorithm on the function fHM , however we report the function value f(X) for the original formulation (6). The solutions of our algorithm are basically identical to those of the interior point method. However, it needs only a fraction of the time spent by the interior point method. The DSPCA algorithm provides accurate solutions within short time even with increasing dimension, however our algorithm is still considerably faster, especially for large dimensions."}, {"heading": "4. Analysis", "text": ""}, {"heading": "4.1. The Duality Gap", "text": "In this section we provide a duality gap for Problem (1) and analyze the running time of Algorithm 1. Let Problem (1) have finite optimal solution denoted by f\u2217 obtained at X\u2217. Let t be an upper bound on the trace norm Tr(X\u2217). Such a trace bound always exists if f\u2217 > \u2212\u221e. Then the optimization Problem (1) is equivalent to:\nmin f(X) s. t. Tr(X) \u2264 t\nX 0 (8)\nIn order to simplify some technicalities in the proof we change Problem (8) into:\nmin f\u0302(X\u0302) s. t. Tr(X\u0302) = t\nX\u0302 0. (9)\nProblems (8) and Problem (9) are equivalent if we define\nf\u0302(X\u0302) := f(X),\nwhere\nX\u0302 = ( X 0 0 t\u2032 ) and t\u2032 = t \u2212 Tr(X) \u2265 0. Note that X\u0302 is positive semidefinite whenever X is positive semidefinite. This transformation is only done here for simplifying the analysis of Algorithm 1. It does not alter Algorithm 1.\nWe denote by St := {X \u2208 Rn\u00d7n |X 0, Tr(X) = t} the set of all positive semidefinite matrices with trace constraint t.\nHence, we have that Problem (1) is equivalent to\nmin f(X), s. t. X \u2208 St. (10)\nBy convexity of f , we have the following linearization, for any X,Y \u2208 St:\nf(Y ) \u2265 \u2207f(X) \u2022 (Y \u2212X) + f(X).\nThis allows us to define the Wolfe-dual of (10) for any fixed matrix X \u2208 St as follows,\n\u03c9(X) := min Y \u2208St \u2207f(X) \u2022 (Y \u2212X) + f(X)\n= f(X)\u2212 max Y \u2208St \u2212\u2207f(X) \u2022 (Y \u2212X)\nand the duality gap as\ng(X) := f(X)\u2212 \u03c9(X) = max\nY \u2208St \u2212\u2207f(X) \u2022 (Y \u2212X).\nBy the definition of the objective function f , the gradient \u2207f(X) is always a symmetric matrix and therefore has real eigenvalues, which will be important in the following.\nLemma 1. The duality gap can be written as\ng(X) = t \u00b7 \u03bbmax (\u2212\u2207f(X)) +\u2207f(X) \u2022X.\nProof. We will prove the claim by showing that for any symmetric matrix G \u2208 Rn\u00d7n, one can equivalently reformulate the linear optimization problem maxY \u2208St G \u2022 Y as follows:\nmax Y \u2208St G \u2022 Y = max G \u2022 n\u2211 i=1 \u03b1iuiu T i\n= max n\u2211 i=1 \u03b1i(G \u2022 uiuTi ),\nwhere the latter maximization is taken over unit vectors ui \u2208 Rn, \u2016ui\u2016 = 1, for 1 \u2264 i \u2264 n, and real coefficients \u03b1i \u2265 0, with \u2211n i=1 \u03b1i = t.\nFor Y \u2208 St let Y = UTU be its Cholesky factorization. Let \u03b1i be the squared norms of the rows of U , and let ui be the row vectors of U , scaled to unit length. From the observation Tr(Y ) = Tr(UTU) = Tr(UUT ) = \u2211 i \u03b1i = t it follows that any Y \u2208 St can be written as a convex combination of rank-1 matrices Y = \u2211n i=1 \u03b1iuiu T i with unit vectors ui \u2208 Rn.\nIt follows\nmax Y \u2208St G \u2022 Y = max n\u2211 i=1 \u03b1i(G \u2022 uiuTi )\n= max n\u2211 i=1 \u03b1iu T i Gui\n= t \u00b7 max v\u2208Rn,\u2016v\u2016=1 G \u2022 vvT\n= t \u00b7 max v\u2208Rn,\u2016v\u2016=1 vTGv\n= t \u00b7 \u03bbmax (G) ,\nwhere the last equality is the variational characterization of the largest eigenvalue.\nFinally, both claims follow by plugging in \u2212\u2207f(X) for G.\nBy construction the duality gap g(X) is always an upper bound on the primal error h(X) = f(X)\u2212 f(X\u2217). This can also be used as a stopping criterion in Algorithm 1. If g(X) \u2264 \u03b5 then f(X) is an \u03b5-approximation to the optimal solution."}, {"heading": "4.2. Runtime and Convergence Analysis", "text": "In this section we will show that after at most O( 1\u03b5 ) iterations Algorithm 1 returns a solution that is an \u03b5-approximation to the global optimal solution. The proof is along the lines of (Clarkson, 2008) and (Hazan, 2008). However, we improve by lowering the needed accuracy for the eigenvector computation from O(\u03b52) to O(\u03b5). This in turn lowers the computational effort for a eigenvector computation from O( 1\u03b5 ) to O( 1\u221a \u03b5 ) per iteration when using the Lanczos method.\nLet the curvature constant Cf be defined as follows:\nCf :=\nsup X,Z\u2208St,\u03b1\u2208[0,1] Y=X+\u03b1(Z\u2212X)\n1 \u03b12 (f(Y )\u2212 f(X)\u2212 (Y \u2212X) \u2022 \u2207f(X)) .\nThe curvature constant is a measure of how much the function f(X) deviates from a linear approximation in X, and hence can be seen as an upper bound on the relative Bregman divergence induced by f . Now we can prove the following theorem.\nTheorem 2. For each i \u2265 1, the iterate Xi of Algorithm 1 satisfies f(Xi) \u2212 f(X\u2217) \u2264 \u03b5, where f(X\u2217) is the optimal value for the minimization Problem (1), and \u03b5 = 8Cfi+2 .\nProof. We have Xi = ViV Ti . Let the sequence \u03b1i = 2 i+2 . For each iteration of Hazan\u2019s rank-1 update, we have that\nf(Xi+1) = min\n\u03b1,\u03b2\u22650 f(\u03b1 \u00b7 ViV Ti + \u03b2 \u00b7 vivTi )\n\u2264 f((1\u2212 \u03b1i) \u00b7 ViV Ti + \u03b1it \u00b7 vivTi ) = f(Xi + \u03b1i(t \u00b7 vivTi \u2212Xi)) \u2264 f(Xi) + \u03b1i(t \u00b7 vivTi \u2212Xi) \u2022 \u2207f(Xi) + \u03b12iCf(11)\nwhere the first inequality follows from choosing \u03b1 = 1 \u2212 \u03b1i and \u03b2 = \u03b1i \u00b7 t and the last inequality follows\nfrom the definition of the curvature constant Cf . Furthermore,\n(t \u00b7 vivTi \u2212X) \u2022 \u2207f(Xi) = (Xi \u2212 t \u00b7 vivTi ) \u2022 (\u2212\u2207f(Xi)) = Xi \u2022 (\u2212\u2207f(Xi))\u2212 t \u00b7 vTi (\u2212\u2207f(Xi))vi \u2264 \u2212Xi \u2022 \u2207f(Xi)\u2212 t \u00b7 (\u03bbmax(\u2212\u2207f(Xi))\u2212 \u03b5\u0303) \u2264 \u2212g(Xi) + t \u00b7 \u03b5\u0303 \u2264 \u2212g(Xi) + \u03b1i \u00b7 Cf .\nThe last inequality follows from setting \u03b5\u0303 to a value at most \u03b1i\u00b7Cft within Algorithm 1. Hence, Inequality (11) evaluates to\nf(Xi+1) \u2264 f(Xi)\u2212 \u03b1ig + \u03b12iCf + \u03b12iCf = f(Xi)\u2212 \u03b1ig(Xi) + 2\u03b12iCf . (12)\nSubtracting f(X\u2217) on both sides of Inequality (12), and denoting the current primal error by h(Xi) = f(Xi)\u2212 f(X\u2217), we get\nh(Xi+1) \u2264 h(Xi)\u2212 \u03b1ig(Xi) + 2\u03b12iCf , (13)\nwhich by using the fact that the duality gap g(Xi) is always an upper bound on the primal error h(Xi) gives\nh(Xi+1) \u2264 h(Xi)\u2212 \u03b1ih(Xi) + 2\u03b12iCf . (14)\nThe claim of this theorem is that the primal error h(Xi) = f(Xi) \u2212 f(X\u2217) is small after a sufficiently large number of iterations. Indeed, we will show by induction that h(Xi) \u2264 8Cfi+2 . In the first iteration (i = 0), we know from (14) that the claim holds, because of the choice of \u03b10 = 1.\nAssume now that h(Xi) \u2264 8Cfi+2 holds. Using \u03b1i = 2 i+2 in Inequality (14) we can now bound h(Xi+1) as follows:\nh(Xi+1) \u2264 h(Xi)(1\u2212 \u03b1i) + 2\u03b12iCf\n\u2264 8Cf i+ 2\n( 1\u2212 2\ni+ 2\n) +\n8Cf (i+ 2)2\n\u2264 8Cf i+ 2 \u2212 8Cf (i+ 2)2\n\u2264 8Cf i+ 1 + 2 .\nSo far we only considered the progress made by Algorithm 1 trough the rank-1 update. Running the nonlinear improvement on f(ViV Ti ) in each iteration only improves the primal error h(Xi) in each iteration. Hence, the claim of the theorem follows.\nWe can set \u03b5\u0303 = \u03b54t throughout Algorithm 1. This will ensure \u03b5\u0303 \u2264 \u03b1i\u00b7Cft as needed by the analysis of the algorithm."}, {"heading": "5. Discussion", "text": "We have provided an algorithm that optimizes convex, smooth functions over the cone of positive semidefinite matrices. It can be readily used for a variety of machine learning problems, as many of these fall into this framework or can be equivalently transformed into such a problem. In this paper we have performed experiments on three of such problems and we have shown that our algorithm significantly outperformes state-of-the-art solvers without the need of tuning it to any of the specific tasks. Additionally, the algorithm proposed has the advantage of being very simple, and it comes with the guarantee to always converge to the global optimal solution. In the future, we plan to implement our algorithm in C++ for further speedups."}, {"heading": "Acknowledgements", "text": "The author would like to thank Georgiana Dinu and Joachim Giesen for useful discussions on the topic. This work was supported by the Deutsche Forschungsgemeinschaft (DFG) under grant GI-711/3-2."}], "references": [{"title": "Fast algorithms for approximate semidefinite programming using the multiplicative weights update method", "author": ["Arora", "Sanjeev", "Hazan", "Elad", "Kale", "Satyen"], "venue": "In FOCS,", "citeRegEx": "Arora et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2005}, {"title": "A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization", "author": ["Burer", "Samuel", "Monteiro", "Renato D.C"], "venue": "Math. Program.,", "citeRegEx": "Burer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Burer et al\\.", "year": 2003}, {"title": "Robust principal component analysis", "author": ["Cand\u00e8s", "Emmanuel J", "Li", "Xiaodong", "Ma", "Yi", "Wright", "John"], "venue": "J. ACM,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2011}, {"title": "Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm", "author": ["Clarkson", "Kenneth L"], "venue": "In SODA,", "citeRegEx": "Clarkson and L.,? \\Q2008\\E", "shortCiteRegEx": "Clarkson and L.", "year": 2008}, {"title": "A direct formulation of sparse PCA using semidefinite programming", "author": ["d\u2019Aspremont", "Alexandre", "El Ghaoui", "Laurent", "Jordan", "Michael I", "Lanckriet", "Gert R. G"], "venue": "SIAM Review,", "citeRegEx": "d.Aspremont et al\\.,? \\Q2007\\E", "shortCiteRegEx": "d.Aspremont et al\\.", "year": 2007}, {"title": "Approximating semidefinite programs in sublinear time", "author": ["Garber", "Dan", "Hazan", "Elad"], "venue": "In NIPS,", "citeRegEx": "Garber et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Garber et al\\.", "year": 2011}, {"title": "Low-rank matrix approximation with weights or missing data is NP-hard", "author": ["Gillis", "Nicolas", "Glineur", "Fran\u00e7ois"], "venue": "SIAM J. Matrix Analysis Applications,", "citeRegEx": "Gillis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gillis et al\\.", "year": 2011}, {"title": "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming", "author": ["Goemans", "Michel X", "Williamson", "David P"], "venue": "J. ACM,", "citeRegEx": "Goemans et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Goemans et al\\.", "year": 1995}, {"title": "CVX: Matlab software for disciplined convex programming, version 1.21", "author": ["Grant", "Michael", "Boyd", "Stephen"], "venue": "http: //cvxr.com/cvx,", "citeRegEx": "Grant et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Grant et al\\.", "year": 2011}, {"title": "A sublinear-time randomized approximation algorithm for matrix games", "author": ["Grigoriadis", "Michael D", "Khachiyan", "Leonid G"], "venue": "Operations Research Letters,", "citeRegEx": "Grigoriadis et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Grigoriadis et al\\.", "year": 1995}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["Hazan", "Elad"], "venue": "In LATIN,", "citeRegEx": "Hazan and Elad.,? \\Q2008\\E", "shortCiteRegEx": "Hazan and Elad.", "year": 2008}, {"title": "Random conic pursuit for semidefinite programming", "author": ["Kleiner", "Ariel", "Rahimi", "Ali", "Jordan", "Michael I"], "venue": "In NIPS,", "citeRegEx": "Kleiner et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kleiner et al\\.", "year": 2010}, {"title": "Learning the kernel matrix with semidefinite programming", "author": ["Lanckriet", "Gert R. G", "Cristianini", "Nello", "Bartlett", "Peter", "Ghaoui", "Laurent El", "Jordan", "Michael I"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Lanckriet et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lanckriet et al\\.", "year": 2004}, {"title": "Prox-method with rate of convergence O(1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems", "author": ["Nemirovski", "Arkadi"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski and Arkadi.,? \\Q2004\\E", "shortCiteRegEx": "Nemirovski and Arkadi.", "year": 2004}, {"title": "Smooth minimization of non-smooth functions", "author": ["Nesterov", "Yurii"], "venue": "Math. Program.,", "citeRegEx": "Nesterov and Yurii.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov and Yurii.", "year": 2005}, {"title": "Smoothing technique and its applications in semidefinite optimization", "author": ["Nesterov", "Yurii"], "venue": "Math. Program.,", "citeRegEx": "Nesterov and Yurii.,? \\Q2007\\E", "shortCiteRegEx": "Nesterov and Yurii.", "year": 2007}, {"title": "Joint covariate selection and joint subspace selection for multiple classification problems", "author": ["Obozinski", "Guillaume", "Taskar", "Ben", "Jordan", "Michael I"], "venue": "Statistics and Computing,", "citeRegEx": "Obozinski et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Obozinski et al\\.", "year": 2010}, {"title": "Large-scale convex minimization with a low-rank constraint", "author": ["Schmidt", "Shai", "Gonen", "Alon", "Shamir", "Ohad"], "venue": "In ICML,", "citeRegEx": "Schmidt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2011}, {"title": "Maximum-margin matrix factorization", "author": ["Srebro", "Nathan", "Rennie", "Jason D. M", "Jaakkola", "Tommi"], "venue": "In NIPS,", "citeRegEx": "Srebro et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2004}, {"title": "Using sedumi 1.02, a MATLAB toolbox for optimization over symmetric cones", "author": ["Sturm", "Jos F"], "venue": "Optimization Methods and Software,", "citeRegEx": "Sturm and F.,? \\Q1999\\E", "shortCiteRegEx": "Sturm and F.", "year": 1999}, {"title": "Graph laplacian regularization for largescale semidefinite programming", "author": ["Weinberger", "Kilian Q", "Sha", "Fei", "Zhu", "Qihui", "Saul", "Lawrence K"], "venue": "In NIPS,", "citeRegEx": "Weinberger et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Weinberger et al\\.", "year": 2006}, {"title": "Alternating direction augmented lagrangian methods for semidefinite programming", "author": ["Wen", "Zaiwen", "Goldfarb", "Donald", "Yin", "Wotao"], "venue": "Math. Prog. Comp.,", "citeRegEx": "Wen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2010}, {"title": "Distance metric learning, with application to clustering with side-information", "author": ["Xing", "Eric P", "Ng", "Andrew Y", "Jordan", "Michael I", "Russell", "Stuart"], "venue": "In NIPS,", "citeRegEx": "Xing et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Xing et al\\.", "year": 2002}], "referenceMentions": [{"referenceID": 4, "context": "Prominent examples include sparse PCA (d\u2019Aspremont et al., 2007), distance metric learning (Xing et al.", "startOffset": 38, "endOffset": 64}, {"referenceID": 22, "context": ", 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al.", "startOffset": 34, "endOffset": 53}, {"referenceID": 20, "context": ", 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al.", "startOffset": 44, "endOffset": 69}, {"referenceID": 12, "context": ", 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al.", "startOffset": 34, "endOffset": 58}, {"referenceID": 16, "context": ", 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al.", "startOffset": 28, "endOffset": 52}, {"referenceID": 18, "context": ", 2010), and matrix completion (Srebro et al., 2004).", "startOffset": 31, "endOffset": 52}, {"referenceID": 4, "context": "Prominent examples include sparse PCA (d\u2019Aspremont et al., 2007), distance metric learning (Xing et al., 2002), nonlinear dimensionality reduction (Weinberger et al., 2006), multiple kernel learning (Lanckriet et al., 2004), multitask learning (Obozinski et al., 2010), and matrix completion (Srebro et al., 2004). We provide an algorithm that solves general large-scale unconstrained semidefinite optimization problems efficiently. The idea to our algorithm is a hybrid approach: we combine the algorithm of Hazan (2008) with a standard quasi-Newton algorithm.", "startOffset": 39, "endOffset": 522}, {"referenceID": 0, "context": "Examples include (Nesterov, 2007; Nemirovski, 2004) and (Arora et al., 2005) where the multiplicative weights update rule is employed.", "startOffset": 56, "endOffset": 76}, {"referenceID": 0, "context": "The algorithm of (Arora et al., 2005) has been randomized by (Garber & Hazan, 2011) based on the same idea as in (Grigoriadis & Khachiyan, 1995) to achieve sublinear running time.", "startOffset": 17, "endOffset": 37}, {"referenceID": 11, "context": "Another randomized algorithm has appeared in (Kleiner et al., 2010).", "startOffset": 45, "endOffset": 67}, {"referenceID": 21, "context": "Furthermore, alternating direction methods have been proposed to solve SDPs (Wen et al., 2010).", "startOffset": 76, "endOffset": 94}, {"referenceID": 2, "context": "to the robust PCA approach for matrix completion with low rank (Cand\u00e8s et al., 2011).", "startOffset": 63, "endOffset": 84}, {"referenceID": 22, "context": "This problem can be cast as a semidefinite optimization problem(Xing et al., 2002):", "startOffset": 63, "endOffset": 82}, {"referenceID": 11, "context": "We follow the experimental setting of (Kleiner et al., 2010).", "startOffset": 38, "endOffset": 60}, {"referenceID": 22, "context": "We compared our approach against an interior point method implemented in SeDuMi (Sturm, 1999) (via CVX (Grant & Boyd, 2011)) and the algorithm of (Xing et al., 2002) which is a projected gradient approach and was specifically designed to solve the above SDP.", "startOffset": 146, "endOffset": 165}, {"referenceID": 11, "context": "We could not directly compare our algorithm to that of (Kleiner et al., 2010) as the code was not available.", "startOffset": 55, "endOffset": 77}, {"referenceID": 22, "context": "However, the authors show that it performs similarly to (Xing et al., 2002).", "startOffset": 56, "endOffset": 75}, {"referenceID": 11, "context": "Following (Kleiner et al., 2010), we ran a second set of experiments on synthetic data in order to measure the dependence on the dimension d.", "startOffset": 10, "endOffset": 32}, {"referenceID": 4, "context": "This problem can be relaxed into the following SDP (d\u2019Aspremont et al., 2007): min \u03c1 \u2211 (i,j) |Xij | \u2212A \u2022X s.", "startOffset": 51, "endOffset": 77}, {"referenceID": 11, "context": "We again follow the experimental setting of (Kleiner et al., 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d\u2019Aspremont et al.", "startOffset": 44, "endOffset": 66}, {"referenceID": 4, "context": ", 2010) and we compare to an interior point method and to a state-of-the-art algorithm, the DSPCA algorithm (d\u2019Aspremont et al., 2007) which is specifically designed to solve Problem (6).", "startOffset": 108, "endOffset": 134}], "year": 2012, "abstractText": "We present a hybrid algorithm for optimizing a convex, smooth function over the cone of positive semidefinite matrices. Our algorithm converges to the global optimal solution and can be used to solve general largescale semidefinite programs and hence can be readily applied to a variety of machine learning problems. We show experimental results on three machine learning problems. Our approach outperforms state-of-the-art algorithms.", "creator": "LaTeX with hyperref package"}}}