{"id": "1206.4662", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Bayesian Watermark Attacks", "abstract": "This paper pra presents an haytor application of gr4 statistical machine learning wiretapped to the minidresses field of watermarking. We transiting propose kontra a wihdat new attack model on sancho additive barrus spread - baruq spectrum dawgs watermarking bradtke systems. The kubba proposed attack mazandarani is bentwaters based s13 on Bayesian statistics. We richfield consider the pleo scenario salsola in which a watermark re-fit signal is namrup repeatedly eurobarometer embedded in al-hakam specific, castmates possibly chosen based on a secret message ch\u00e1vez bitstream, segments (coanda signals) of maundy the 4-under host vus data. The host iais signal can ksar represent a 4,751 patch of ribbs pixels chehr from muhan an image rench or michaele a video frame. steensnaes We propose a wecht probabilistic 16,900 model duangmanee that worldperks infers the embedded message harley-davidson bitstream cleansing and sarin watermark quarterly signal, coupe directly intramuscularly from ls7 the katalyst watermarked data, elvy without 390-7862 access to ordonnance the gordes decoder. We develop gu\u00f0mundsson an \u02bfal\u012b efficient Markov elegans chain Monte brg Carlo lagisquet sampler m\u00e9hul for updating the 77.94 model ghassemlou parameters from farmer-labor their sosnick conjugate electorate full conditional posteriors. We also bmtc provide talpade a variational bajhang Bayesian tumwater solution, which unopened further yipping increases choekyi the convergence roone speed carom of braised the algorithm. eon Experiments panga with setapak synthetic and integrilin real except image signals demonstrate neeley that sratsimir the attack 1030gmt model finetune is 118.52 able to correctly archival infer a large part of floresiensis the message swardt bitstream and owi obtain knockabout a putrid very accurate apted estimate of the watermark vociferous signal.", "histories": [["v1", "Mon, 18 Jun 2012 15:30:35 GMT  (1881kb)", "http://arxiv.org/abs/1206.4662v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.CR cs.LG cs.MM", "authors": ["ivo shterev", "david b dunson"], "accepted": true, "id": "1206.4662"}, "pdf": {"name": "1206.4662.pdf", "metadata": {"source": "META", "title": "Bayesian Watermark Attacks", "authors": ["Ivo D. Shterev", "David B. Dunson"], "emails": ["i.shterev@duke.edu", "dunson@stat.duke.edu"], "sections": [{"heading": "1. Introduction", "text": "Watermarking is the process of imperceptibly embedding a watermark signal into a host signal (audio segment, pixel patch from image or video frame). The watermark signal should only introduce tolerable distortion to the host signal and it should be recoverable by the intended receiver. Watermark-\nAppearing in Proceedings of the 29 th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012. Copyright 2012 by the author(s)/owner(s).\ning techniques differ by the way they modulate the host signal to embed information. There are two major classes of watermark embedding schemes, namely spread spectrum and quantization index modulation (QIM) (Chen & Wornell, 2001).\nSpread spectrum watermarking (Cox et al., 2007; Hartung et al., 1999) constitutes a popular class of watermarking algorithms. In their simplest form, the watermarked signal is constructed by adding the host and watermark signals together, i.e. additive watermark embedding. Although, in terms of additive noise attacks they have been outperformed by the more robust QIM watermarking techniques (Chen & Wornell, 2001), spread-spectrum techniques have advantageous features that make them preferable in some watermarking scenarios. Examples of such inherent features include their simplicity and robustness to removal attacks. Another advantage is that spread-spectrum watermarking can be applied in different forms (multiplicative watermarking (Huang & Zhang, 2007)) that can further improve performance in some cases. They can also effectively exploit the human visual system (HVS) (Podilchuk & Zheng, 1998) to reduce perceptual degradation of the host signal.\nMany attacks have been designed to hamper the performance of watermarking in general and spreadspectrum watermarking in particular. The attacks are usually classified with respect to the attacker\u2019s assumed knowledge about the watermark scheme. Robustness attacks pertain to the class of attacks under which the attacker has no knowledge of the watermark scheme. Examples of such attacks include adding random noise (Chen & Wornell, 2001) to the watermarked signal, replacing signal blocks with perceptually similar blocks computed in a certain way (Kirovski et al., 2007), applying a geometric transformation (cropping, scaling, translation, etc.) to the watermarked signal, or applying a malicious filtering operation (Su et al., 2001), to name a few. Other attacks belong to the\nso called worst case class of attacks, where the attacker has knowledge about the watermark technique and designs the attack such that the watermark detector (decoder) performance is minimized, under suitably defined distortion constraints. Usually, this type of attack is based on game theory (Cohen & Lapidoth, 2002) and is mostly of theoretical importance.\nA third class of attacks aims at compromising the watermark system security (security attacks) (Cayre et al., 2005; Freire & Gonzalez, 2009). Under this scenario, the attacker has access only to the watermarked data and tries to estimate the secret key used for embedding the watermark. Having estimated the secret key, he can then reconstruct the watermark and remove it from the watermarked data (the so called removal attacks), thus creating a forgery of the host signal, which can then be freely copied and distributed by pirates. Although (Cayre et al., 2005; Freire & Gonzalez, 2009) develop theoretical security attack frameworks, the proposed algorithms do not perform well with real correlated host signals.\nAnother type of attack is the so called sensitivity analysis attack, which constitutes a powerful subclass of removal attacks (Kalker et al., 1998; Linnartz & van Dijk, 1998; Choubassi & Moulin, 2007). In their attempt to estimate the watermark signal, they rely on unlimited access to the decoder.\nIn this paper, we consider the scenario in which a watermark signal is repeatedly embedded in specific (possibly secretly chosen) host signals. The host signal can represent a patch of pixels from image or video frame. The host signals may be perceptually similar or quite disparate, as the watermark algorithm may choose, for security reasons, to embed the watermark in specific signals of the host data based on a secret message bitstream. Repetitive watermark embedding is of particular interest in image and video watermarking (Voloshynovskiy et al., 2001; Lu & Hsu, 2007; Bas et al., 2002; Tang & Hang, 2003; Doerr & Dugelay, 2004; Kalker et al., 1999), where the watermark signal is repeatedly allocated into small blocks to ensure robustness and resistance to geometric (desynchronization) attacks. However, the proposed attacks related to this scenario assume that the watermark signal is not secretly hidden but is added to every host signal and therefore do not try to estimate an embedded message bitstream.\nThe attack model proposed in this paper jointly estimates the embedded message bitstream and watermark signal from the watermarked data, without access to the decoder. We develop a probabilistic model based on Bayesian statistics. The algorithm models\nthe host signal as having a multivariate Gaussian distribution with unknown mean and full covariance matrix. The watermark signal itself is also modeled as having a multivariate Gaussian distribution, but with separate unknown mean and full covariance matrix. The model parameters are updated sequentially from their respective conjugate full conditional posterior distributions, via Markov chain Monte Carlo (MCMC) sampling. To further increase the convergence speed of the proposed algorithm, we develop a variational Bayesian (VB) (Beal & Ghahramani, 2003) solution to it. In addition to its suitability for large scale data analysis, the VB solution also allows for diagnosing convergence, via the lower bound to the log-likelihood. Both MCMC and VB solutions perform comparably with respect to probability of bit error and relative watermark reconstruction error, with both synthetic and real host data.\nOur model borrows similar ideas from sparse factor regression formulations (sparse models) used in gene expression data analysis (West, 2003; Carvalho et al., 2008). The objective of such sparse models is to specify a prior for the elements of a highly sparse factor loadings matrix, with most elements being exactly zero and few of them having relatively large variances. To contrast with our model, the role of the zero elements here is taken by the data points (signals) that are not watermarked, which do not necessarily constitute the majority of all data points. The watermarked data points have the interpretation of the non-zero elements in the factor loadings matrix. However in our case, they are a sum of the host and the watermark signals, with the watermark signal being much weaker than the host signal. The problem becomes that of a joint identification-estimation of a subtle signal."}, {"heading": "2. Spread-Spectrum Watermarking", "text": "Throughout this paper, random variables are denoted by small letters. Random vectors and their realizations are denoted by bold small letters. The notation x \u2208 Rd indicates a d-dimensional random vector of real elements. Square random matrices and their realizations are denoted by bold capital letters. The notationX \u2208 Rd\u00d7d indicates a d\u00d7d matrix of real elements and X\u2032 is its transpose. The probability of an event is denoted by Pr(\u00b7). The notation x \u223c p(x) indicates that x has a probability density function (pdf) p(x).\nIn this paper we concentrate on one of the most popular additive spread-spectrum watermarking systems, in which a watermark signal is repeatedly used to embed a message bitstream into a host data. The watermark encoder is shown in Fig. 1. Considering\nthe ith data point and depending on the message bit bi \u2208 {0, 1}, the encoder adds (bi = 1) the watermark signal w to the host signal xi, or leaves the host signal unchanged (bi = 0). The watermarked signal can therefore be written as\nyi =\n{\nxi +w if bi = 1, xi if bi = 0,\n(1)\nwhere i \u2208 {1, . . . , n} and n is the number of available data points.\nThe watermark decoder is shown in Fig. 2. The decoder has access to the watermark signal w. Based on the received (watermarked) signal yi and the watermark signal, the decoder computes a detection test statistic f(yi,w) and compares it to a suitably chosen threshold \u03c4 . The decoder then outputs an estimate b\u0302i of the embedded message bit bi in the following way\nb\u0302i =\n{\n1 if f(yi,w) > \u03c4, 0 if otherwise.\n(2)\nThroughout the paper, the document-to-watermark (DWR) ratio is defined as DWR = 10 log10 \u03c3 2 x/\u03c3 2 w, where \u03c32x is the variance of a single element in xi, for i \u2208 {1, . . . , n}, and \u03c32w is the variance of a single element in w."}, {"heading": "3. Attack Model", "text": "It is assumed that the attacker has access to the watermarked signal, but has no access to the watermark decoder. The complete form of the attack model can\nbe summarized as follows:\nyi = xi + biw (3)\nxi \u223c N (xi|\u00b5,\u03a3) (4)\nw \u223c N (w|m,V) (5)\nbi \u223c Bernoulli(bi|\u03c0) (6)\n{\u00b5,\u03a3} \u223c N (\u00b5|\u00b50,\u03a3)IW(\u03a3|\u03c90,\u03a30) (7)\n{m,V} \u223c N (m|m0,V)IW(V|\u03c90,V0) (8)\n\u03c0 \u223c Beta(\u03c0|a\u03c0, b\u03c0), (9)\nwhere N (x|\u00b5,\u03a3) is the d-variate Gaussian distribution of x with mean \u00b5 and covariance matrix \u03a3, IW(\u03a3|\u03c90,\u03a30) is the inverse Wishart distribution of \u03a3 with degrees of freedom \u03c90 and base covariance matrix \u03a30, Bernoulli(bi|\u03c0) is the Bernoulli distribution of bi with mean \u03c0, and Beta(\u03c0|a\u03c0 , b\u03c0) is the Beta distribution of \u03c0 with parameters a\u03c0 and b\u03c0.\nA graphical representation of the attack model is shown in Fig. 3. The blue circle represents the observed variable, the white circles represent hidden (latent) variables and the squares represent hyperparameters. Conditional dependence between variables is shown via the directed edges."}, {"heading": "4. Posterior Updates", "text": "In this section we derive the update equations for the attack model parameters, with respect to the MCMC and VB solutions. The update equations are based on the full likelihood of the model, which can be written as\nL(y) = p(y,x,w,\u00b5,\u03a3,m,V,b, \u03c0)\n= \u220f\ni\np(yi|xi,w, bi)p(xi|\u00b5,\u03a3)p(bi|\u03c0)\n\u00d7 p(w|m,V)p(\u00b5,\u03a3)p(m,V)p(\u03c0) (10)\nAs it can be seen the likelihood (10) is in an intractable form, since it is not possible to jointly estimate all model parameters directly from (10). That is why the MCMC and VB solutions developed below update every model parameter sequentially from its respective conditional posterior distribution. While the MCMC solution is based on exact conditional posterior distributions, the VB solution utilizes an approximation to the true conditional posterior distribution."}, {"heading": "4.1. MCMC Update Equations", "text": "We derive the MCMC update equations, based on the exact full conditional posteriors of the attack model parameters and construct a Gibbs sampler that iteratively samples from these update equations.\nThe full conditional posterior distributions of the model parameters are as follows:\n\u2022 updating {\u00b5,\u03a3}.\np(\u00b5,\u03a3|x) \u221d p(\u00b5,\u03a3) \u220f\ni\np(xi|\u00b5,\u03a3)\n\u221d IW ( \u03a3|\u03c90 + n,\u03a3\u03a3 ) N ( \u00b5|\u00b5\u00b5, \u03a3\nn+ 1\n)\n, (11)\nwhere\n\u03a3\u03a3 = \u03a30 + n\nn+ 1 (x\u0304\u2212 \u00b50)(x\u0304\u2212 \u00b50)\n\u2032\n+ \u2211\ni\n(xi \u2212 x\u0304)(xi \u2212 x\u0304) \u2032 (12)\n\u00b5\u00b5 = \u00b50 + nx\u0304\nn+ 1 (13)\nx\u0304 = 1\nn\n\u2211\ni\nxi. (14)\n\u2022 updating w.\np(w|y) \u221d p(w|m,V) \u220f\ni\n1(bi = 1)p(yi|\u00b5,\u03a3,w)\n\u221d N ( w|mw,Vw ) , (15)\nwhere\nVw = (V \u22121 + n1\u03a3 \u22121)\u22121 (16) mw = Vw ( V\u22121m\n+ \u03a3\u22121 \u2211\ni\n1(bi = 1)(yi \u2212 \u00b5) ) (17)\nn1 = \u2211\ni\n1(bi = 1), (18)\nand 1(\u00b7) is an indicator function.\n\u2022 updating bi.\np(bi|\u03c0\u0302i) \u221d Bernoulli(bi|\u03c0\u0302i), (19)\nwhere\n\u03c0\u0302i = 1\n1 + 1\u2212\u03c0 \u03c0 N (yi|\u00b5,\u03a3) N (yi|\u00b5+m,\u03a3+V)\n. (20)\n\u2022 updating \u03c0.\np(\u03c0|b) = Beta(\u03c0|a\u0302\u03c0 , b\u0302\u03c0), (21)\nwhere\na\u0302\u03c0 = a\u03c0 + \u2211\ni\n1(bi = 1), (22)\nb\u0302\u03c0 = b\u03c0 + \u2211\ni\n1(bi = 0). (23)\n\u2022 updating {m,V}.\np(m,V|w) \u221d p(m,V)p(w|m,V)\n\u221d IW ( V|\u03c90 + 1,Vv ) N (m|mm, V\n2 ), (24)\nwhere\nVv = V0 + 1\n2 (w \u2212m0)(w \u2212m0)\n\u2032 (25)\nmm = m0 +w\n2 . (26)\n\u2022 updating xi.\nxi =\n{\nyi \u2212w if bi = 1, yi if bi = 0\n(27)"}, {"heading": "4.2. VB Update Equations", "text": "The VB approach tries to find a tractable lower bound L(q) to the logarithm of the marginal likelihood (10), which can be iteratively updated (tightened). If we denote by \u03b8 the model parameters {w,\u00b5,\u03a3,m,V,b, \u03c0} that we want to update, the optimal posterior update that gives the tightest bound (Beal & Ghahramani, 2003) is given as\nqj(\u03b8j) \u221d exp ( \u2329 ln p(y, \u03b8) \u232a\n\u2212j\n)\n, (28)\nwhere \u3008\u00b7\u3009\u2212j denotes expectation with respect to all parameters except for the jth parameter that is being updated.\nUsing (28), the posterior VB updates of the model parameters are as follows:\n\u2022 updating {\u00b5,\u03a3}.\nq(\u00b5,\u03a3) \u221d exp \u2329 ln ( p(\u00b5,\u03a3) \u220f\ni\np(xi|\u00b5,\u03a3) )\n\u232a\n\u221d IW ( \u03a3|\u03c90 + n,\u03a3 vb \u03a3 ) N ( \u00b5|\u00b5vb \u00b5 , \u3008\u03a3\u22121\u3009\u22121\nn+ 1\n)\n, (29)\nwhere\n\u03a3vb\u03a3 = \u03a30 + n\nn+ 1 (z\u0304+ \u00b50)(z\u0304 + \u00b50)\n\u2032\n+ \u2211\ni\n(\n\u3008b2i \u3009\u3008ww \u2032\u3009 \u2212 \u3008bi\u3009 2\u3008w\u3009\u3008w\u3009\u2032 )\n+ \u2211\ni\n( \u3008bi\u3009\u3008w\u3009 \u2212 yi \u2212 z\u0304)(\u3008bi\u3009\u3008w\u3009 \u2212 yi \u2212 z\u0304) \u2032 ) (30)\n\u00b5vb \u00b5\n= \u00b50 \u2212 nz\u0304\nn+ 1 (31)\nz\u0304 = 1\nn\n\u2211\ni\n( \u3008bi\u3009\u3008w\u3009 \u2212 yi ) , (32)\nand b2i = bi, following the properties of the Bernoulli random variable.\n\u2022 updating w.\nq(w) \u221d exp \u2329 ln ( p(w) \u220f\ni\np(yi|w) )\n\u232a\n\u221d N (w|mvbw ,V vb w ), (33)\nwhere\nVvbw = ( \u3008V\u22121\u3009+ \u3008\u03a3\u22121\u3009\n\u00d7 \u2211\ni\n(\n\u3008bi\u3009 2 +\n\u2329 bi \u2212 \u3008bi\u3009 \u232a2)\n)\u22121\n(34)\nmvbw = V vb w\n(\n\u3008V\u22121\u3009\u3008m\u3009\n+ \u3008\u03a3\u22121\u3009 \u2211\ni\n\u3008bi\u3009 ( yi \u2212 \u3008\u00b5\u3009 )\n)\n. (35)\n\u2022 updating bi.\nq(bi|\u03c0\u0302i) \u221d Bernoulli(bi|\u03c0\u0302i), (36)\nwhere\n\u03c0\u0302i = 1\n1 + exp\n\u2329 ln(1\u2212\u03c0) \u232a N ( yi|\u3008\u00b5\u3009,\u3008\u03a3\u22121\u3009\u22121 )\nexp \u3008ln\u03c0\u3009N ( yi|\u3008\u00b5\u3009+\u3008m\u3009,\u3008\u03a3\u22121\u3009\u22121+\u3008V\u22121\u3009\u22121 )\n.\n\u2022 updating \u03c0.\nq(\u03c0|b) \u221d Beta(\u03c0|avb\u03c0 , b vb \u03c0 ), (37)\nwhere\navb\u03c0 = a\u03c0 + \u2211\ni\n\u3008bi\u3009 (38)\nbvb\u03c0 = b\u03c0 + n\u2212 \u2211\ni\n\u3008bi\u3009. (39)\n\u2022 updating {m,V}.\nq(m,V|w) \u221d exp \u2329 ln ( p(m,V)p(w|m,V) ) \u232a\n\u221d IW ( V|\u03c90 + 1,V vb v ) N ( m|mvbm , \u3008V\u22121\u3009\u22121\n2\n)\n, (40)\nwhere\nVvbv = V0 + 1\n2\n( m0 \u2212 \u3008w\u3009 )( m0 \u2212 \u3008w\u3009 )\u2032\n(41)\nmvbm = m0 + \u3008w\u3009\n2 . (42)"}, {"heading": "5. Experiments", "text": "We perform experiments with both synthetic and real host signals. To quantify the performance of our algorithm, we compute the probability of error Pe = 1 n \u2211 i 1(bi 6= b\u0302i) and the relative watermark reconstruction error Rw = \u2016w\u2212w\u0302\u20162 \u2016w\u20162 , where \u2016 \u00b7 \u20162 is the L2 norm, and w\u0302 is the estimated watermark signal.\nIn all experiments, the model hyper-parameters are initialized as a\u03c0 = b\u03c0 = 0.5n, \u00b50 = m0 = 1 n \u2211\ni yi, \u03c90 = d + 1, \u03a30 = 1 n \u2211 i(yi \u2212 \u00b50)(yi \u2212 \u00b50) \u2032 and V0 = 1\n10DWR/10 \u03a30. For each iteration, we computed\n95% credible intervals of the individual samples in the watermark signal estimate w\u0302. With respect to the MCMC solution, we performed 2000 iterations of the Gibbs sampler, discarding the first 1000 as burn in iterations and averaging the results of the remaining 1000 iterations. For the VB solution, we performed 100 iterations and using the last iteration updates of \u3008w\u3009, and \u3008bi\u3009, as the estimated watermark signal w\u0302 and message bit b\u0302i for i \u2208 {1, . . . , n}, respectively.\nWe implemented the proposed attack model solutions in R, with some of the routines implemented in C/C++. It takes approximately 6 minutes for the MCMC solution to perform 2000 iterations, using 4096 64-dimensional data points. In contrast, the VB solution performs 100 iterations in less than a minute, using the same data points."}, {"heading": "5.1. Synthetic Host Signals", "text": "In this subsection we perform experiments with synthetic host signals. We generated n = 4096, d = 64- dimensional host data points. Each data point was independent and identically drawn from N ( 0, IW ( d +\n1, IW(d + 1, I) )\n)\n, where I is the identity matrix. In\nthis way, the host signal covariance matrix, although randomly drawn, imposes some structure on the host signal. The watermark signal was drawn from a multivariate Gaussian with mean N ( 0, IW(d+1, I) ) and\ncovariance IW(d + 1, I). The watermark signal was zero mean transformed and scaled so that DWR = 30db. The watermark message bits were drawn from Bernoulli(0.5), and the watermarked signal was formed by additive spread-spectrum modulation. The host image and the difference between the watermarked and host images are shown in Fig. 4. Each block of pixels was formed by row-wise transformation of the data point into an 8 \u00d7 8 matrix. The blocks were then ordered row-wise to form the whole image.\nExperimental results of the difference bi \u2212 b\u0302i for i \u2208 {1, . . . , n}, the watermark signal w and its estimate w\u0302 for the MCMC and VB solutions are shown in Fig. 5. The results show that the algorithm was able to obtain a good estimate of the watermark signal and message bitstream, with only a small fraction of misidentified bits. Based on the experimental results, we can see that the MCMC and VB solutions perform comparably in terms of Pe and Rw."}, {"heading": "5.2. Real Host Signals", "text": "In this subsection we perform experiments with real image signals. We applied our algorithm on gray scale images. In the experiments we used image sizes of 512 \u00d7 512 and 1024 \u00d7 1024 pixels. The images were split in 8 \u00d7 8 patches of pixels, making a total of n = 4096 and n = 16384 patches respectively. The pixels within each patch were concatenated row-wise to form the d-dimensional (d = 64) data points. The host signal was then normalized to have zero mean.\nAs in the case of synthetic host signals, the watermark signal was drawn from a multivariate Gaussian with mean N ( 0, IW(d + 1, I) )\nand covariance IW(d + 1, I). The watermark signal was then scaled such that DWR = 30db and embedded by additive spread-spectrum modulation with Pr(bi = 1) = 0.5, for i \u2208 {1 . . . n}. The real host images used in the experiments are shown in Fig. 6.\nExperimental results for the MCMC and VB solutions applied to the real host images from Fig. 6 are shown in Fig. 7. It can be seen that both solutions perform comparably with respect to real host signals.\nComputations of the lower bound L(q) for the VB solution applied on the real host images in Fig. 6 are shown in Fig. 8. The results show that the VB so-\nlution converges in less than 20 iterations for all real host images considered in the experiments.\nTo quantify the performance of the attack model with respect to different DWR levels, we perform experiments with the real host images in Fig. 6 and varying the DWR \u2208 {20, . . . , 40}. The interval of values for the DWR was chosen so that the middle is at DWR = 30db, at which level no perceptual degradation to the host image was observed. The watermark signal was drawn from a multivariate Gaussian with mean N ( 0, IW(d+1, I) )\nand covariance IW(d+1, I). For each host image, the watermark signal was drawn only once and then zero mean transformed, and scaled down differently to achieve the different DWR levels. Experimental results of Pe and Rw as functions of DWR are shown in Fig. 9 and Fig. 10 respectively, with both solutions performing comparably."}, {"heading": "6. Discussion", "text": "We presented a new attack model on repetitive spreadspectrum watermarking systems, based on Bayesian statistics. The proposed algorithm jointly estimates the watermark signal and message bitstream, directly from the watermarked signal and without access to the watermark decoder. We developed MCMC and VB solutions that perform comparably in terms of probability of error and relative watermark reconstruction error, on both synthetic and real host signals. Fast convergence is observed in both solutions, particularly in the VB solution where the algorithm converges in less than 20 iterations, with both synthetic and real host signals. While the MCMC solution is expected to result in more accurate estimates for infinite number of iterations, the VB solution is computationally more efficient and therefore more appropriate for large data sets. We demonstrated that the attack model is able\nto correctly infer a large part of the message bitstream while at the same time obtaining a good estimate of the watermark signal."}, {"heading": "7. Acknowledgments", "text": "The authors wish to acknowledge the helpful suggestions of the reviewers."}], "references": [{"title": "Geometrically invariant watermarking using feature points", "author": ["P. Bas", "J.M. Chassery", "B. Macq"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "Bas et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bas et al\\.", "year": 2002}, {"title": "The variational bayesian em algorithm for incomplete data: with application to scoring graphical model structures", "author": ["M.J. Beal", "Z. Ghahramani"], "venue": "Bayesian Statistics", "citeRegEx": "Beal and Ghahramani,? \\Q2003\\E", "shortCiteRegEx": "Beal and Ghahramani", "year": 2003}, {"title": "High-dimensional sparse factor modeling: Applications in gene expression genomics", "author": ["C.M. Carvalho", "J. Chang", "J.E. Lucas", "J.R. Nevins", "Q. Wang", "M. West"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Carvalho et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2008}, {"title": "Watermarking security: Theory and practice", "author": ["F. Cayre", "C. Fontaine", "T. Furon"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Cayre et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Cayre et al\\.", "year": 2005}, {"title": "Quantization index modulation: A class of provably good methods for digital watermarking and information embedding", "author": ["B. Chen", "G.W. Wornell"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Chen and Wornell,? \\Q2001\\E", "shortCiteRegEx": "Chen and Wornell", "year": 2001}, {"title": "Noniterative algorithms for sensitivity analysis attacks", "author": ["Choubassi", "M. El", "P. Moulin"], "venue": "IEEE Transactions on Information Forensics and Security,", "citeRegEx": "Choubassi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Choubassi et al\\.", "year": 2007}, {"title": "The gaussian watermarking game", "author": ["A.S. Cohen", "A. Lapidoth"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Cohen and Lapidoth,? \\Q2002\\E", "shortCiteRegEx": "Cohen and Lapidoth", "year": 2002}, {"title": "Digital Watermarking and Steganography, 2nd Ed", "author": ["I.J. Cox", "M.L. Miller", "J.A. Bloom", "J. Fridrich", "T. Kalker"], "venue": null, "citeRegEx": "Cox et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cox et al\\.", "year": 2007}, {"title": "Security pitfalls of frame-by-frame approaches to video watermarking", "author": ["G. Doerr", "J.L. Dugelay"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Doerr and Dugelay,? \\Q2004\\E", "shortCiteRegEx": "Doerr and Dugelay", "year": 2004}, {"title": "Spread-spectrum watermarking security", "author": ["L.P. Freire", "F.P. Gonzalez"], "venue": "IEEE Transactions on Information Forensics and Security,", "citeRegEx": "Freire and Gonzalez,? \\Q2009\\E", "shortCiteRegEx": "Freire and Gonzalez", "year": 2009}, {"title": "Statistically robust detection of multiplicative spread-spectrum watermarks", "author": ["X. Huang", "B. Zhang"], "venue": "IEEE Transactions on Information Forensics and Security,", "citeRegEx": "Huang and Zhang,? \\Q2007\\E", "shortCiteRegEx": "Huang and Zhang", "year": 2007}, {"title": "Watermark estimation through detection analysis", "author": ["T. Kalker", "J.P. Linnartz", "M. van Dijk"], "venue": "In Proc. International Conference on Image Processing,", "citeRegEx": "Kalker et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kalker et al\\.", "year": 1998}, {"title": "A video watermarking system for broadcast monitoring", "author": ["T. Kalker", "G. Depovere", "J. Haitsma", "M. Maes"], "venue": "In Proc. SPIE Security and Watermarking of Multimedia Contents,", "citeRegEx": "Kalker et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Kalker et al\\.", "year": 1999}, {"title": "The replacement attack", "author": ["D. Kirovski", "F.A.P. Petitcolas", "Z. Landau"], "venue": "IEEE Transactions on Audio, Speech, and Language Processing,", "citeRegEx": "Kirovski et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kirovski et al\\.", "year": 2007}, {"title": "Analysis of the sensitivity attack against electronic watermarks in images", "author": ["J.P. Linnartz", "M. van Dijk"], "venue": "In Proc. Workshop on Information Hiding,", "citeRegEx": "Linnartz and Dijk,? \\Q1998\\E", "shortCiteRegEx": "Linnartz and Dijk", "year": 1998}, {"title": "Near-optimal watermark estimation and its countermeasure: Antidisclosure watermark for multiple watermark embedding", "author": ["C.S. Lu", "C.Y. Hsu"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology,", "citeRegEx": "Lu and Hsu,? \\Q2007\\E", "shortCiteRegEx": "Lu and Hsu", "year": 2007}, {"title": "Image-adaptive watermarking using visual models", "author": ["C.I. Podilchuk", "W. Zheng"], "venue": "IEEE Transactions on Selected Areas in Communications,", "citeRegEx": "Podilchuk and Zheng,? \\Q1998\\E", "shortCiteRegEx": "Podilchuk and Zheng", "year": 1998}, {"title": "Analysis of digital watermarks subjected to optimum linear filtering and additive noise", "author": ["J.K. Su", "J.J. Eggers", "B. Girod"], "venue": "Signal Processing,", "citeRegEx": "Su et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Su et al\\.", "year": 2001}, {"title": "A feature-based robust digital image watermarking scheme", "author": ["C.W. Tang", "H.M. Hang"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Tang and Hang,? \\Q2003\\E", "shortCiteRegEx": "Tang and Hang", "year": 2003}, {"title": "Multibit digital watermarking robust against local nonlinear geometrical distortions", "author": ["S. Voloshynovskiy", "F. Deguillaume", "T. Pun"], "venue": "In Proc. International Conference on Image Processing, Thessaloniki,", "citeRegEx": "Voloshynovskiy et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Voloshynovskiy et al\\.", "year": 2001}, {"title": "Bayesian factor regression models in the large p, small n paradigm", "author": ["M. West"], "venue": "Bayesian Statistics", "citeRegEx": "West,? \\Q2003\\E", "shortCiteRegEx": "West", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": "Spread spectrum watermarking (Cox et al., 2007; Hartung et al., 1999) constitutes a popular class of watermarking algorithms.", "startOffset": 29, "endOffset": 69}, {"referenceID": 13, "context": "Examples of such attacks include adding random noise (Chen & Wornell, 2001) to the watermarked signal, replacing signal blocks with perceptually similar blocks computed in a certain way (Kirovski et al., 2007), applying a geometric transformation (cropping, scaling, translation, etc.", "startOffset": 186, "endOffset": 209}, {"referenceID": 17, "context": ") to the watermarked signal, or applying a malicious filtering operation (Su et al., 2001), to name a few.", "startOffset": 73, "endOffset": 90}, {"referenceID": 3, "context": "A third class of attacks aims at compromising the watermark system security (security attacks) (Cayre et al., 2005; Freire & Gonzalez, 2009).", "startOffset": 95, "endOffset": 140}, {"referenceID": 3, "context": "Although (Cayre et al., 2005; Freire & Gonzalez, 2009) develop theoretical security attack frameworks, the proposed algorithms do not perform well with real correlated host signals.", "startOffset": 9, "endOffset": 54}, {"referenceID": 11, "context": "Another type of attack is the so called sensitivity analysis attack, which constitutes a powerful subclass of removal attacks (Kalker et al., 1998; Linnartz & van Dijk, 1998; Choubassi & Moulin, 2007).", "startOffset": 126, "endOffset": 200}, {"referenceID": 19, "context": "Repetitive watermark embedding is of particular interest in image and video watermarking (Voloshynovskiy et al., 2001; Lu & Hsu, 2007; Bas et al., 2002; Tang & Hang, 2003; Doerr & Dugelay, 2004; Kalker et al., 1999), where the watermark signal is repeatedly allocated into small blocks to ensure robustness and resistance to geometric (desynchronization) attacks.", "startOffset": 89, "endOffset": 215}, {"referenceID": 0, "context": "Repetitive watermark embedding is of particular interest in image and video watermarking (Voloshynovskiy et al., 2001; Lu & Hsu, 2007; Bas et al., 2002; Tang & Hang, 2003; Doerr & Dugelay, 2004; Kalker et al., 1999), where the watermark signal is repeatedly allocated into small blocks to ensure robustness and resistance to geometric (desynchronization) attacks.", "startOffset": 89, "endOffset": 215}, {"referenceID": 12, "context": "Repetitive watermark embedding is of particular interest in image and video watermarking (Voloshynovskiy et al., 2001; Lu & Hsu, 2007; Bas et al., 2002; Tang & Hang, 2003; Doerr & Dugelay, 2004; Kalker et al., 1999), where the watermark signal is repeatedly allocated into small blocks to ensure robustness and resistance to geometric (desynchronization) attacks.", "startOffset": 89, "endOffset": 215}, {"referenceID": 20, "context": "Our model borrows similar ideas from sparse factor regression formulations (sparse models) used in gene expression data analysis (West, 2003; Carvalho et al., 2008).", "startOffset": 129, "endOffset": 164}, {"referenceID": 2, "context": "Our model borrows similar ideas from sparse factor regression formulations (sparse models) used in gene expression data analysis (West, 2003; Carvalho et al., 2008).", "startOffset": 129, "endOffset": 164}], "year": 2012, "abstractText": "This paper presents an application of statistical machine learning to the field of watermarking. We propose a new attack model on additive spread-spectrum watermarking systems. The proposed attack is based on Bayesian statistics. We consider the scenario in which a watermark signal is repeatedly embedded in specific, possibly chosen based on a secret message bitstream, segments (signals) of the host data. The host signal can represent a patch of pixels from an image or a video frame. We propose a probabilistic model that infers the embedded message bitstream and watermark signal, directly from the watermarked data, without access to the decoder. We develop an efficient Markov chain Monte Carlo sampler for updating the model parameters from their conjugate full conditional posteriors. We also provide a variational Bayesian solution, which further increases the convergence speed of the algorithm. Experiments with synthetic and real image signals demonstrate that the attack model is able to correctly infer a large part of the message bitstream and obtain a very accurate estimate of the watermark signal.", "creator": "LaTeX with hyperref package"}}}