{"id": "1206.5244", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2012", "title": "Search for Choquet-optimal paths under uncertainty", "abstract": "Choquet 48.1 expected utility (anti-saloon CEU) brancaster is wilman one of the most female-female sophisticated valved decision cowen criteria abingdon used vidricaire in pheochromocytoma decision awja theory censored under hilli uncertainty. ccie It merrin provides 28.29 a generalisation of expected theofanous utility enhancing lenited both mcgann descriptive ludwigshafen and coeval prescriptive possibilities. bithorn In http://www.nwguild.org this kifuji paper, zaius we investigate the use demi-gods of sommes CEU darvin for suraiya path - planning under uncertainty with co-counsel a special badie focus rheinland on sk\u00f6tkonung robust solutions. genotoxic We first wrg recall bruere the main 1990/91 features of the CEU japanese-canadians model undeserved and introduce some h\u00e9rcules examples mody showing ginseng its concerts descriptive potential. Then universes we focus on scaffolds the salukvadze search 107.97 for teepencolumn@earthlink.net Choquet - optimal paths agit in aiya multivalued implicit graphs where neuberger costs depend ifaf on pspp different d'origine scenarios. After discussing country-music complexity issues, we propose two different heuristic tonna search algorithms to solve counterfeiter the mont\u00fafar problem. bogalusa Finally, muhan numerical experiments are gfl reported, culprits showing 02 the practical efficiency slec of the bowron proposed adorf algorithms.", "histories": [["v1", "Wed, 20 Jun 2012 14:53:49 GMT  (737kb)", "http://arxiv.org/abs/1206.5244v1", "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["lucie galand", "patrice perny"], "accepted": false, "id": "1206.5244"}, "pdf": {"name": "1206.5244.pdf", "metadata": {"source": "CRF", "title": "Search for Choquet-optimal paths under uncertainty", "authors": ["Lucie Galand", "Patrice Perny"], "emails": [], "sections": [{"heading": null, "text": "Choquet expected utility (CEU) is one of the most sophisticated decision criteria used in decision theory under uncertainty. It provides a generalisation of expected utility enhancing both descriptive and prescriptive possibilities. In this paper, we investigate the use of CEU for path-planning under uncertainty with a special focus on robust solutions. We first recall the main features of the CEU model and introduce some examples showing its descriptive potential. Then we focus on the search for Choquet-optimal paths in multivalued implicit graphs where costs depend on different scenarios. After discussing complexity issues, we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported, showing the practical efficiency of the proposed algorithms."}, {"heading": "1 INTRODUCTION", "text": "An important source of complexity in practical applications of problem solving methods developed in AI is the imperfect knowledge of the real problem to deal with. This is particularly true in path-planning problems where the map is not always the territory. When seeking the optimal path from a given node to a goal node, several uncertainty factors might indeed increase the complexity of the optimization task. Firstly, the consequences of the actions might not be certain, which can be modeled by non-deterministic transitions between states. Secondly, the current state might not be known exactly (partial observability), which requires maintaining beliefs on possible states revised during the search. These problems are widely discussed in the litterature on MDPs and POMDPs, see e.g. Puterman (1994), Kaebling et al. (1999).\nBeside these sources of complexity, the cost transitions between states might also be uncertain. This eventuality has motivated work aimed at revisiting, under uncertainty, the shortest path problem in a state space graph, and its classical resolution with the A\u2217 algorithm. For example, Wellman and Wurman consider a case where the costs are time dependent and representable by random variables (Wellman et al., 1995). They introduce the SDA\u2217 algorithm to determine the preferred paths according to the stochastic dominance partial order. Moreover, an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria is proposed in (Wurman and Wellman, 1996).\nAnother way of introducing uncertainty in costs is to consider a set of plausible scenarios, each bringing a different valuation to transitions and therefore to solution paths. This is the natural formulation when the costs depend on exogenous variables not controlled by the decision maker, these variables having an overall impact on the graph (e.g. transfer times in a city depending on the weather, security of moves depending on enemy positions, asset values depending on market evolution). The introduction of scenarios implicitly defines a family of possible instances of the same problem, all sharing the same feasible solutions, but with different views on the possible costs. In such problems, the aim is to seek for \u201crobust\u201d solutions, i.e. solutions yielding a \u201creasonable\u201d cost in all plausible instances of the problem. This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.g. min-max, min-max regret) to define the absolute or relative robustness of a solution. Under these criteria, the shortest path problem becomes NP-hard, as do many other polynomially solvable problems (see e.g., Aron and van Hentenryck (2002) for robust spanning tree problems), thus bringing new algorithmic challenges. In the same vein, alternative models such as Lorenz dominance and\nordered weighted averages have been introduced and justified to model robustness in (Perny and Spanjaard, 2003), as well as a multiobjective search algorithm to determine robust solution paths in state space graphs under total uncertainty.\nOne major limitation of these robustness criteria is overpessimism (worst case analysis) in cost aggregation, making them not sufficiently discriminating. When information about the relative plausibility of scenarios is available, robustness criteria can be refined using models introduced in decision theory under uncertainty and risk to convey pessimism, prudence, riskaversion or uncertainty aversion in the comparisons of acts. This idea is exploited in (Perny et al., 2007) for path-planning under risk (when probabilities of scenarios are known), where a multiobjective heuristic search algorithm is proposed for the determination of optimal solution paths with respect to second-order stochastic dominance, or expected utility for risk-averse agents. However, in some situations, these models do not apply directly, either because the objective probabilities of scenarios are not known, or because observed preferences do not match EU theory with respect to any probabilities. An example of such a problematic situation, inspired by the so-called Ellsberg\u2019s urn example (Ellsberg, 1961), is presented below in the context of path planning:\nExample 1 Consider a problem with 3 scenarios (S = {1, 2, 3}) and assume that objective probabilities of scenarios are imprecisely known and defined by p1 = 1/3 and p2 + p3 = 2/3. Consider now 4 solution paths P1, P2, P3, P4 to reach a goal node from the initial node with the following costs c(Pi, sj):\n1 2 3 P1 0 100 100 P2 100 0 100 P3 0 100 0 P4 100 0 0\nOn the one hand, a decision maker who is averse to uncertainty might prefer P1 to P2 because P1 has probability 1/3 of reaching the goal for free, whereas P2 might have a cost of 100 for sure. On the other hand, the same decision maker might prefer P4 to P3 because P4 has probability 2/3 of reaching the goal for free, whereas P3 might have only probability 1/3. Although such preferences are natural they cannot be described by the EU model. Indeed P1 P2 implies p2 + p3 > p1 + p3 whereas P4 P3 implies p1 > p2. Note that these inequalities are contradictory. This makes it impossible to assume that subjective probabilities are implicitly assigned to states by the decision maker. Trying to reveal them would be meaningless.\nThe impossibility of revealing probabilities through the EU model in some situations has led to the introduction of alternative numerical representations of beliefs in events by a capacity function, a less constraining representation of uncertainty that relaxes the additivity assumption. The standard decision model associated to capacities is based on the use of the Choquet integral, following Schmeidler (1989), who gives the foundations of the Choquet Expected Utility criterion (CEU). Despite its descriptive appeal, until now, CEU has not been considered in the field of path-planning under uncertainty. The aim of this paper is to fill this gap and to complete the previous studies by investigating the potential of CEU in the search of robust paths. The paper is organized as follows. In Section 2 we recall the main features of the CEU model and introduce some examples showing its descriptive potential in the context of search under uncertainty; then we discuss complexity issues concerning the search of Choquetoptimal paths. In Section 3 we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported in Section 4, showing the practical efficiency of the proposed algorithms."}, {"heading": "2 PROBLEM FORMULATION", "text": ""}, {"heading": "2.1 Notations and Definitions", "text": "We consider a state space graph G = (N,A) where N is a finite set of nodes (possible states), and A is a set of arcs representing feasible transitions between nodes. Formally, we have A = {(n, n\u2032) : n \u2208 N,n\u2032 \u2208 S(n)} where S(n) \u2286 N is the set of all successors of node n (nodes that can be reached from n by a feasible elementary transition). We denote P(n, n\u2032) the set of all paths linking n to n\u2032, and P(n,N \u2032) the set of all paths from n to any node n\u2032 \u2286 N \u2032 (with N \u2032 \u2286 N). We call solution path a path from s to a goal node \u03b3 \u2208 \u0393 (i.e. a path in P(s,\u0393)). Throughout the paper, we assume that there exists at least one finite length solution path. We consider a finite set S = {1, . . . ,m} of possible scenarios, each having possibly a different impact on the transition costs, and a scenariodependent valuation c : A \u00d7 S \u2192 R+ where c(a, s) is the cost of the transition represented by a in scenario s. By abuse of notation, c(a) denotes the cost vector (c(a, 1), . . . , c(a,m)). The costs over a path are assumed to be additive, which allows valuation c to be extended from arcs to paths by setting, for any path P and any scenario s, c(P, s) = \u2211 a\u2208P c(a, s). A cost vector x = (x1, x2, . . . , xm) \u2208 Rm+ is associated to each path P in G such that xi = c(P, i), hence, the comparison of paths reduces to the comparison of their associated cost vectors. In the sequel we assume\nthat, for all scenarios, the cost of each solution path is bounded by a positive constant M . Throughout the paper, we will consider a weak preference over paths (or cost vectors), denoted %. For any pair of paths P and P \u2032 with respective costs x and x\u2032 in Rm+ we will use notation P % P \u2032 or x % x\u2032 to say P is at least as good as P \u2032. As usual relation P \u223c P \u2032 (or x \u223c x\u2032) represents indifference between the two paths and corresponds to P % P \u2032 and P \u2032 % P . Finally, relation P P \u2032 (or x x\u2032) represents strict preference and corresponds to P % P \u2032 and not(P \u2032 % P )."}, {"heading": "2.2 Capacities and the Choquet Integral", "text": "The Choquet integral (Choquet, 1953) is used in decision theory to generalize the notion of expectation when beliefs in events are represented by a capacity, i.e. a set function v : 2S \u2192 [0, 1] such that v(\u2205) = 0, v(S) = 1 and \u2200A,B \u2208 2S such that A \u2286 B, v(A) \u2264 v(B). For any event A \u2286 S, v(A) represents the plausibility of event A. The capacity v is said to be convex (or supermodular) when v(A \u222aB) + v(A \u2229B) \u2265 v(A) + v(B) for all A,B \u2286 S, and it is said to be concave (or submodular) when v(A \u222aB) + v(A \u2229B) \u2264 v(A) + v(B) for all A,B \u2286 S. To any capacity v, we can associate a dual capacity v\u0304 defined by v\u0304(A) = 1 \u2212 v(S \\ A) for all A \u2286 S. It is well known that v\u0304 is concave if and only if v is convex and vice-versa. When v is concave, we have v(A) + v(S \\ A) \u2265 1, hence v\u0304(A) \u2264 v(A). In this case the core of v\u0304 defined by core(v\u0304) = {P \u2208 L, v\u0304(A) \u2264 P (A) \u2264 v(A)} where L is the set of probability measures on S is known to be non-empty since v\u0304 is convex (Shapley, 1971). This result will be used in Section 3.\nExample 1 continued Coming back to Example 1, let P be the set of all probability distributions on S = {1, 2, 3} such that P ({1}) = 1/3, the set function defined by v(A) = supP\u2208P P (A) for all A \u2286 {1, 2, 3} and its dual v\u0304 are given by:\nA \u2205 {1} {2} {3} {1, 2} {1, 3} {2, 3} S v(A) 0 1/3 2/3 2/3 1 1 2/3 1 v\u0304(A) 0 1/3 0 0 1/3 1/3 2/3 1\nIn this case, it is easy to check that v (resp. v\u0304) is a concave (resp. convex) capacity. Moreover we have core{v\u0304} = P.\nThe Choquet integral of a vector x \u2208 Rm+ with respect to capacity v is defined by:\nCv(x) = m\u2211\ni=1\n[ v(X(i))\u2212 v(X(i+1) ] x(i) (1)\n= m\u2211\ni=1\n[ x(i) \u2212 x(i\u22121) ] v(X(i)) (2)\nwhere (.) represents a permutation on {1, . . . ,m} such that 0 = x(0) \u2264 x(1) \u2264 . . . \u2264 x(m), X(i) = {j \u2208 S, xj \u2265 x(i)} = {(i),(i + 1), . . ., (m)} for i \u2264 m and X(m+1) = \u2205. Note that X(i+1) \u2282 X(i), hence v(X(i)) \u2265 v(X(i+1)) for all i. The Choquet integral generalizes the classical notion of expectation with the following interpretation based on Equation (2): for a given vector x = (x1, . . . , xm), the outcome is at least x(1) with plausibility v(X(1)) = 1, and the outcome might increase from x(1) to x(2) with plausibility v(X(2)); the same applies from x(2) to x(3) with plausibility v(X(3)), and so on. The overall integral is therefore obtained by aggregation of marginal increments x(i) \u2212 x(i\u22121) weighted by plausibilities v(X(i))."}, {"heading": "In decision theory, the Choquet integral is often used in maximization problems under the form", "text": "Cv(u(x1), . . . , u(xm)) with utility function u on payoffs to be maximized (CEU criterion, Schmeidler (1989)). In path-planning problems where costs replace payoffs, we need to reformulate the criterion using a disutility function to be minimized. Let w : R+ \u2192 [0, 1] be an increasing disutility function on costs such that w(0) = 0 and w(M) = 1. We introduce the Choquet Expected Disutility (CED), a function to be minimized over all feasible vectors x \u2208 Rm+ , defined by:\n\u03c8wv (x) = Cv(w(x1), . . . , w(xm)) (3)\nNote that CED includes classical expected disutility as a particular case. Indeed, whenever v is additively decomposable, we have v(A) = \u2211 i\u2208A vi for all A \u2286 S, where vi = v({i}). Hence v(X(i))\u2212v(X(i+1)) = v(i) for all i and \u03c8wv (x) = \u2211m i=1 v(i)w(x(i)) = \u2211m i=1 viw(xi). When used with a non-additive capacity, it offers additional descriptive possibilities. As an illustration, let us continue Example 1.\nExample 1 continued Assume that w(0) = 0, w(100) = 1. We get: \u03c8wv ((0, 100, 100)) = v({2, 3}), \u03c8wv (((100, 0, 100)) = v({1, 3}), \u03c8wv ((0, 100, 0)) = v({2}), \u03c8wv ((100, 0, 0)) = v({1}). If v is the concave capacity introduced above, we get v({2, 3}) = 2/3 < 1 = v({1, 3}) and v(2) = 2/3 > 1/3 = v(1). Hence we get the desired preferences, i.e. (0, 100, 100) (100, 0, 100) and (0, 100, 0) \u227a (100, 0, 0). This example shows that \u03c8wv is compatible with some uncertainty aversion."}, {"heading": "2.3 Uncertainty aversion in CEU theory", "text": "Uncertainty aversion means intuitively that smoothing or averaging a cost vector makes the decision maker better off. A useful formalization of this idea is introduced in Chateauneuf and Tallon (2002) through an axiom named \u201cpreference for diversification\u201d due to its interpretation in the context of portofolio man-\nagement. This axiom can be reformulate in our framework:\nDefinition 1 A preference % reveals uncertainty aversion if, for any x1, . . . , xn \u2208 Rm+ , and \u03b11, . . . , \u03b1n \u2265 0 such that for all \u2211n i=1 \u03b1i = 1, we have:\n[x1 \u223c x2 \u223c . . . \u223c xn]\u21d2 \u2211n\ni=1 \u03b1ix i % xk, k = 1, . . . , n\nInterestingly enough, it is shown in Chateauneuf and Tallon (2002) that, within CEU theory, the above axiom on preference is equivalent to choosing a concave utility u and a convex capacity v. The direct counterpart of this result in our context (minimization of Choquet expected disutility) says that we should use a convex disutility w and a concave capacity v to exhibit uncertainty aversion with \u03c8wv as defined in Equation (3). For this reason, throughout the paper, we will assume that w is convex and v is concave.\nExample 2 In a two-scenario instance with scenarios having approximatively the same plausibility, consider two solution paths with cost vectors x = (10, 0) and y = (0, 10) respectively. A decision maker averse to uncertainty might be indifferent between x and y, i.e. x \u223c y, but would prefer z = (5, 5) to x and y, i.e. z x and z y. Such preferences are fully consistent with the idea of robustness. Suppose now that we have a convex disutility w defined by \u2200t \u2208 R+, w(t) = t2/100 and a concave capacity v such that v({1}) = v({2}) = 2/3. Then \u03c8wv (x) = \u03c8 w v (y) = 2/3 > \u03c8 w v (z) = 1/4 which induces the desired preferences. Note that using a concave disutility w such as w(t) = \u221a t/10 gives \u03c8wv (x) = \u03c8 w v (y) = 0.67 < 0.71 = \u03c8 w v (z), which is not compatible with uncertainty aversion. The same observation can be made with a convex capacity.\nWe are now in position to formulate the central problem of this paper:\nThe \u03c8wv -OPT problem. Instance: a state space graph G = (N,A) as introduced in Subsection 2.1, an initial node s and a set \u0393 \u2286 N of goal nodes, a finite set of states S, a scenariodependent valuation c : A \u00d7 S \u2192 R+, and a concave capacity v and a convex disutility w. Goal: determine a \u03c8wv -optimal path among all paths in P(s,\u0393) where \u03c8wv is defined as in Equation (3)."}, {"heading": "2.4 Complexity issues", "text": "If v(A) = 1 for all non-empty A \u2286 S, then \u03c8wv (x) =\u2211m i=1 [ w(x(i))\u2212 w(x(i\u22121)) ] v(X(i)) = w(x(m)) = maxi\u2208S w(xi). Hence \u03c8wv -OPT reduces to the minmax search problem, which was proved NP-hard by Murthy and Her (1992). This shows that \u03c8wv -OPT is also NP-hard.\nWe wish to propose a heuristic search algorithms to solve the \u03c8wv -OPT problem. The efficient resolution of shortest-path problems with A\u2217 in the classical case relies on the Bellman principle that justifies local pruning of sub-optimal subpaths during the search. However, in the case of multiple scenarios the CED model breaks the Bellman principle, as shown by the following example:\nExample 3 Consider an instance with two paths P and P \u2032 from s to a node n with costs vectors x = (0, 100, 0) and x\u2032 = (100, 0, 0). Consider a Choquet expected disutility criterion \u03c8wv with w(0) = 0, w(100) = 1 and v({1}) = 0.4, v({2}) = 0.5, v({2, 3}) = 0.7, v({1, 3}) = 0.8. Here we have \u03c8wv (x) = 0.5 and \u03c8wv (x\n\u2032) = 0.4 and therefore P \u2032 P . For search efficiency, we might want to prune P at node n due to the existence of the better subpath P \u2032. However, it might be a mistake. Assume, for example, that a path P \u2032\u2032 from n to \u0393 exists with cost y = (0, 0, 100); we have P \u2032 \u222a P \u2032\u2032 \u227a P \u222a P \u2032\u2032 because \u03c8wv (x\u2032 + y) = \u03c8wv ((100, 0, 100)) = 0.8 > 0.7 = \u03c8 w v ((0, 100, 100)) = \u03c8wv (x+ y).\nSuch a preference reversal shows that, at any node visited during the search, a naive pruning of sub-optimal sub-paths with respect to \u03c8wv might lose the admissibility of the algorithm. A similar violation of the Bellman principle is highlighted in De Cooman and Troffaes (2005), in the general framework of dynamic programming with uncertain gain and imprecise probabilities. It concerns the notion of P -maximinity, a counterpart of \u03c8wv -optimality for imprecise probabilities. The next section presents two admissible algorithms to solve \u03c8wv -OPT."}, {"heading": "3 ALGORITHMS", "text": ""}, {"heading": "3.1 Optimistic Heuristics for \u03c8wv \u2212OPT", "text": "Before introducing algorithms for the \u03c8wv -OPT problem, we establish an inequality providing an easily computable lower bound for criterion \u03c8wv (x).\nProposition 1 If v is concave then for all P \u2208 core(v\u0304) the following inequality holds: \u03c8wv (x) \u2265\u2211m\ni=1 piw(xi) with pi = P ({i}). Moreover, if w is convex we have: \u03c8wv (x) \u2265 w( \u2211m i=1 pixi).\nProof. \u03c8wv (x) = \u2211m i=1 [ w(x(i))\u2212 w(x(i\u22121)) ] v(X(i))\n\u2265 \u2211m\ni=1\n[ w(x(i))\u2212 w(x(i\u22121)) ] P (X(i)) since inequal-\nities v(X(i)) \u2265 P (X(i)) hold for all i (P \u2208 core(v\u0304)). Further, \u2211m i=1 [ w(x(i))\u2212 w(x(i\u22121)) ] P (X(i)) =\u2211m\ni=1[P (X(i)) \u2212 P (X(i+1))]w(x(i)) = \u2211m\ni=1 p(i)w(x(i)) = \u2211m i=1 piw(xi) \u2265 w( \u2211m i=1 pixi) when w is convex.\nHence, any probability distribution P in core(v\u0304) can be used to produce a lower bound that can be used as an optimistic heuristic in the search. Among the natural choices for P that give efficient bounds in practice, let us mention Shapley values \u03c6i that represent the average marginal contribution of any state i = 1, . . . ,m to events (Shapley, 1971). Shapley values are positive and add up to one. In our context they are defined by:\n\u03c6i = \u2211\nK\u2286S\\{i}\n(m\u2212 |K| \u2212 1)!|K|! m! (v\u0304(K \u222a {i})\u2212 v\u0304(K))\nAnother possible choice among probability laws in core(v\u0304) is P \u2217, the probability distribution maximizing entropy h(P ) = \u2212 \u2211m i=1 pi log pi over the core(v\u0304). This propability distribution can easily be obtained using the following greedy algorithm proposed in Jaffray (1995), where p\u2217i stands for the probability P \u2217({i}).\nAlgorithm 1: computing P \u2217 with max-entropy Initialization: A\u2190 \u2205; B \u2190 \u2205; while B 6= S do\nA\u2190 argmin{v(B\u222aE)\u2212v(B)|E| , E \u2286 S\\B,E 6= \u2205}; for all i \u2208 A do\np\u2217i \u2190 v(B\u222aA)\u2212v(B)\n|A| ; B \u2190 B \u222aA;\nOutput: (p\u22171, . . . , p \u2217 m)\nExample 1 continued Coming back to Example 1, Algorithm 1 outputs probabilities p\u22171 = p \u2217 2 = p \u2217 3 = 1/3. With w(0) = 0 and w(100) = 1 we get the following evaluations for paths.\nxk 1 2 3 \u03c8wv \u22113 i=1 p \u2217 i x k i x1 0 100 100 2/3 2/3 x2 100 0 100 1 2/3 x3 0 100 0 2/3 1/3 x4 100 0 0 1/3 1/3\nWe observe that \u03c8wv (x k) \u2265 \u22113 i=1 p \u2217 i x k i for all k.\nIn Example 1, Shapley values coincide with maximal entropy probabilities but this is not true in the general case.\nWe introduce now two exact algorithms for the \u03c8wv - OPT problem. The first one is based on multiobjective search and the second one is based on a ranking approach with prior scalarization of the problem."}, {"heading": "3.2 Multiobjective Search", "text": "The presence of m scenarios in our problem provides m different viewpoints on costs in the state space\ngraph. This clearly points out connections with the field of multiobjective optimization. More precisely, since \u03c8wv (x1, . . . , xm) is increasing in each component, it is clear that \u03c8wv -optimal vectors belong to the Pareto set, i.e., the set of feasible vectors that cannot be improved on a component without being degraded on another. More formally, within a set X \u2286 Rm+ , the Pareto-set is defined by:\nND(X) = {x \u2208 X : \u2200y \u2208 X, y %P x\u21d2 x %P y}\nwhere %P is the weak Pareto-dominance relation defined on Rm+ by: x %P y \u21d0\u21d2 [\u2200i \u2208 S, xi \u2264 yi]. Hence the search for a \u03c8wv -optimal path might be performed with a multiobjective search algorithm. For this reason, we recall now the main features of the MOA\u2217 algorithm proposed by Stewart and White III (1991) to find the set ND(P(s,\u0393)) of non-dominated solution paths in G. Algorithm MOA\u2217 relies on the same foundations as A\u2217, adapted to the field of vectorvalued evaluation. In particular, the Bellman principle holds. Thus, any subpath from s to a node n \u2208 N of a non-dominated solution path is non-dominated in P(s, n). Hence, the algorithm constructs incrementally the non-dominated solution paths from nondominated subpaths.\nIn a graph valued by cost vectors, there may exist several non-dominated paths to reach a given node n. In MOA\u2217 these paths are kept in a label attached to the concerned node and all these paths are expanded when the label is developed. The choice of a node n to be developed at the current iteration is based on a vector valued evaluation function that uses a vector-valued heuristic H(n) containing cost vectors underestimating the real costs of any path in P(n,\u0393). This set is an optimistic approximation of H\u2217(n) = ND(P(n,\u0393)).\nRecently, a variant of this algorithm was proposed in Mandow and de la Cruz (2005), managing and expanding labels attached to paths rather than nodes. This variant makes it possible to not expand some sub-paths that will lead to dominated paths whereas they would be expanded by MOA\u2217. To this end, each detected subpath P from s to n, is given a label l = [nl, gl, fl, Pl], where nl = n is the terminal node of P , gl is the cost vector associated to P , fl is the cost vector gl + h(n) where h(n) is a vectorvalued heuristic of H(n), and Pl is the sequence of nodes \u3008s, . . . , n\u3009 forming P . In the sequel, L(n) will denote the set of labels attached to detected paths in ND(P(s, n)). Two sets of labels are mantained to avoid the expansion of a label already expanded: the set of open labels O contains those labels attached to already detected but not expanded subpaths, and the set of closed labels C contains those labels already detected and expanded. The expansion of a label l, at a given step of the search, proceeds as follows: (1)\nmove l from O to C; (2) insert in O new labels of type [n\u2032, gl + c(n, n\u2032), gl + c(n, n\u2032) + h, \u3008Pl, n\u2032\u3009] for all n\u2032 \u2208 S(nl) and h \u2208 H(n\u2032).\nAt any iteration, the algorithm selects a new nondominated label in O. It stops when there is no remaining label to expand (i.e. O = \u2205), which means there is no remaining Pareto-optimal solution paths to explore.\nStarting from this general multiobjective search procedure, we use two pruning rules to focus the search on \u03c8wv -optimal paths.\nRULE 1: at node n, we prune any label l in L(n)\u2229O such that there exists another label l\u2032 \u2208 L(n) such that gl\u2032 %P gl. Indeed, path Pl cannot lead to a nondominated solution path since any extension of Pl with a sub-path P will be dominated by path Pl\u2032\u222aP . Therefore, Pl cannot lead to a \u03c8wv -optimal solution path either.\nIn order to introduce the second pruning rule, we consider, for any probability vector p = (p1, . . . , pm) \u2208 core(v\u0304), an arc valuation function cp : A \u2192 R+ derived from c by setting cp(a) = \u2211 i\u2208S pic(a, i) for all a \u2208 A (linear aggregation of costs). Hence Rule 2 can be expressed as follows.\nRULE 2: at node n we discard any label l such that max{\u03c8wv (fl), w(cp(Pl) + h\u0304(nl))} \u2265 \u03c8wv (x\u2217), where x\u2217 is the cost vector of the current \u03c8wv -optimal solution path among all already detected solution paths and h\u0304(n) is an optimistic heuristic on the cost of the best path from n to a goal node with respect to cp.\nRule 2 enables the early elimination of uninteresting labels while keeping admissibility of the algorithm, provided optimisic heuristic are used. Indeed, consider any solution path P = Pl \u222a P \u2032 that extends Pl. Then the two following cases must be considered. i) \u03c8wv (fl) \u2265 \u03c8wv (x\u2217). Path P has a cost vector g which is Pareto-dominated by fl provided H is admissible, i.e., \u2200n \u2208 N,\u2200h\u2217(n) \u2208 H\u2217(n), \u2203h \u2208 H(n) such that h(n) %P h\u2217(n). Thus we have \u03c8wv (g) \u2265 \u03c8wv (fl) and therefore \u03c8wv (g) \u2265 \u03c8wv (x\u2217) by transitivity. ii) w(cp(Pl) + h\u0304(nl)) \u2265 \u03c8wv (x\u2217). By Proposition 1, we have \u03c8wv (g) \u2265 w(cp(P )) where g is the cost vector of P ; moreover w(cp(P )) = w(cp(Pl) + cp(P \u2032)) \u2265 w(cp(Pl)+ h\u0304(nl)) since h\u0304 is optimistic. Hence \u03c8wv (g) \u2265 w(cp(Pl) + h\u0304(nl)) \u2265 \u03c8wv (x\u2217). In both cases we have \u03c8wv (g) \u2265 \u03c8wv (x\u2217) which proves that P is suboptimal and justifies Rule 2.\nAlgorithm 2 formally presents the resulting search procedure. In this procedure, sol denotes the current \u03c8wv - optimal solution path represented by the pair (cost vector, sequence of nodes), and ND(L) = {l \u2208 L : \u2200k \u2208 L, gk %P gl \u21d2 gl %P gk}.\nAlgorithm 2: Choquet-optimization Initialization: C \u2190 \u2205; L(s)\u2190 \u22c3 h\u2208H(s){[s; (0, . . . , 0);h; \u3008s\u3009)}; O \u2190 {l\u2032 \u2208 L(s)}; l\u2190 arg mink\u2208L(s) max{\u03c8wv (fk), w(h\u0304(s))} ; \u03bb\u2190\u221e; while [O 6= \u2205, \u03c8wv (fl) < \u03bb, w(cp(Pl) + h\u0304(nl)) < \u03bb] do\nmove l from O to C; if nl \u2208 \u0393 then\nif \u03c8wv (gl) < \u03bb then sol\u2190 (gl, Pl); \u03bb\u2190 \u03c8wv (gl);\nelse for each node n\u2032 \u2208 S(nl) do\nfor each cost vector h(n\u2032) \u2208 H(n\u2032) do x\u2190 gl + c(nl, n\u2032) + h(n\u2032); if \u03c8wv (x)) < \u03bb then\ncreate label l\u2032 = [n\u2032, gl + c(nl, n\u2032), x, \u3008Pl, n\u2032\u3009]; L(n\u2032)\u2190 ND(L(n\u2032) \u222a {l\u2032}); O \u2190 O \u22c3 {l\u2032}\nl\u2190 argminl\u2032\u2208O max{\u03c8wv (fl\u2032), w(cp(Pl\u2032) + h\u0304(nl\u2032)} ; Output: sol"}, {"heading": "3.3 The Ranking Approach", "text": "For any path P j in the graph we have cp(P j) = \u2211 a\u2208P j cp(a) = \u2211 a\u2208P j \u2211 i\u2208S pic(a, i) =\u2211\ni\u2208S pi \u2211 a\u2208P j c(a, i) = \u2211 i\u2208S pic(P j , i). Let xj be the cost vector of P j defined by xji = c(P j , i) for all i. Then the Choquet expected disutility associated to P j is \u03c8wv (x j) \u2265 w( \u2211 i\u2208S pic(P j , i)) by Proposition 1, which is equal to w(cp(P j)). Therefore we have:\n\u03c8wv (x j) \u2265 w(cp(P j)) (4)\nHence the value of any path in the graph endowed with the scalar valuation cp provides a lower bound on the optimal value of \u03c8wv (x) over feasible vectors x. This statement led us to seek the optimal solution of \u03c8wv -OPT through a ranking algorithm performing the enumeration of k best paths by increasing values cp(P ), i.e. by increasing values of w(cp(P )). Denoting P 1, . . . , P j the first solution paths in the enumeration, we have cp(P 1) \u2264 . . . \u2264 cp(P j). Suppose that P j is the first of these paths satisfying w(cp(P j)) \u2265 \u03c8wv (x\u2217) where x\u2217 = argmini=1,...,j \u03c8wv (x\ni) is the cost of the current \u03c8wv -optimal path P\n\u2217, then Equation (4) implies that all forthcoming paths P k, k > j in the enumeration will satisfy \u03c8wv (x\nk) \u2265 w(cp(P k)). Since by construction w(cp(P k)) \u2265 w(cp(P j)) \u2265 \u03c8wv (x\u2217), we get \u03c8wv (x\nk) \u2265 \u03c8wv (x\u2217). Therefore P \u2217 is a \u03c8wv -optimal solution path and we can stop the enumeration.\nLet us explain now how to rank solution paths from best to worst according to cp. We propose a modified version of A\u2217 that uses labels attached to paths. To any detected path P with a cost vector x from s to n \u2208 N , we assign a label l = [nl, gl, g\u0304l, Pl] where nl is node n, gl is cost vector x, g\u0304l is scalar cost cp(P ), and Pl is the sequence of nodes \u3008s, . . . , n\u3009 forming P . After the determination of a first cp-optimal solution path, we have to continue so as to find the second-best solution path and then the following. For that, all detected sub-paths during the search (i.e., all labels) are kept. Therefore, several labels can be attached to a same node. Moreover, in order to favour a depth-first search in the state space graph, only the current most promising label on each node is expanded, until the corresponding solution path is found. To implement this principle, we use the two sets of nodes O (set of open nodes), and C (set of closed nodes). More precisely, set O is the set of already detected nodes having no expanded label. Set C is defined as the set of nodes having exactly one expanded label corresponding to a path which is not part of an already detected solution path.\nThe complete procedure is formalized in Algorithm 3 given below, where L(n) is the set of labels attached to n, sol is the current \u03c8wv -optimal solution path represented by the ordered-pair (cost vector, sequence of nodes), and h\u0304 : N \u2192 R is an optimistic heuristic on the cost of the best path from n to a goal node with respect to cp."}, {"heading": "4 NUMERICAL EXPERIMENTS", "text": "We have performed numerical experiments of Algorithms 2 and 3 on path-planning problems, the size of which varies from 1,000 nodes to 3,000 (with arc density of 45%). On each transition, the cost of each scenario is randomly drawn between 0 and 100. For the two algorithms, the tests have been performed with the convex disutility function w(x) = x2, and a concave capacity v1 defined, for all A \u2286 S, as follows: v1(A) = 1 \u2212 ( \u2211 i/\u2208A pi)\n2 for a randomly drawn probability distribution (p1, . . . , pm).\nIn Algorithm 2, heuristic H(n) used at node n is the vector h(n) defined by hi(n) = \u03b3h\u2217i (n) where h \u2217 i (n) is the cost of the shortest path in P(n,\u0393) with respect to scenario i \u2208 S and \u03b3 is randomly drawn in [0.7; 1). We have tested Algorithm 3 with a heuristic function h\u0304 at node n, determined by setting h\u0304(n) = \u03b3h\u0304\u2217(n) where h\u0304\u2217(n) is the cost of the shortest path in P(n,\u0393) with respect to cp, and \u03b3 is randomly drawn in [0.7; 1).\nWe compare here execution times of Algorithms 2 (A2) and 3 (A3) for two different lower-bounds obtained for the two probability vectors considered in Section 3.2\nAlgorithm 3: Choquet-optimization by ranking Initialization: C \u2190 \u2205; O \u2190 {s}; L(n)\u2190 \u2205, \u2200n \u2208 N ; l\u2190 [s, (0, . . . , 0), 0, \u3008s\u3009]; L(s)\u2190 {l}; \u03bb\u2190\u221e; while O 6= \u2205 and w(g\u0304l + h\u0304(nl)) < \u03bb do\nremove l from L(nl); remove nl from O and put nl in C; if nl \u2208 \u0393 then\nif \u03c8wv (gl) < \u03bb then sol\u2190 (gl, Pl); \u03bb\u2190 \u03c8wv (gl); for each node n in Pl do remove n from C; if L(n) 6= \u2205 then\nput n in O; else\nfor each node n \u2208 S(nl) do l\u2032 \u2190 [n, gl + c(nl, n), g\u0304l + c\u0304(nl, n), \u3008Pl, n\u3009]; if g\u0304\u2032l + h\u0304(n) < \u03bb then L(n)\u2190 L(n) \u222a {l\u2032}; if n /\u2208 C then\nput n in O; l\u2190 argmin {g\u0304\u2032l + h\u0304(nl\u2032), l\u2032 \u2208 \u22c3\nn\u2208O L(n)}; Output: sol\n(maximal entropy (p\u2217i ) and Shapley values (\u03c6i)). The results are given in Table 1. They show the efficiency of the two algorithms. Remark that execution times are slightly better with Algorithm 3 but the difference is not very significant. Moreover, probabilities p\u2217i used for linear scalarization seem to provide a slightly better bound than \u03c6i in most cases. We have performed the same experiments with another capacity v2 defined, for all A \u2286 S, as follows: v2(A) = \u2211 E\u2229A6=\u2205 \u03d5(E) where {\u03d5(E), E \u2286 S} are randomly drawn positive Mo\u0308bius masses adding up to 1, which ensures that v2 is a plausibility function (for more details, see Shafer (1976);\nChateauneuf and Jaffray (1995)). The execution times were similar."}, {"heading": "5 FUTURE WORK", "text": "We have shown the potential of the Choquet integral in modelling risk-averse preferences for path-planning under uncertainty. Despite the complexity of the \u03c8wv - OPT problem in the worst case, the experiments show that the two heuristic search algorithms introduced in the paper are very efficient on average. In the future, it might be interesting to investigate the use of the Choquet integral in dynamic decision making problems e.g. decision trees or Markov decision processes. The main problem there is the existence of dynamic inconsistencies induced by the Choquet integral in sequential decision making.\nAnother direction might be to explore the potential of the Choquet integral in multiobjective planning problems. As shown by Grabisch (1996), the descriptive potential of the Choquet integral provides interesting possibilities in the field of multicriteria analysis. We might use the Choquet integral to characterize fine compromise solution paths in state space graphs. The algorithmic material presented here could certainly be adapted to determine Choquet-optimal paths in such multiobjective search problems."}, {"heading": "Acknowledgements", "text": "We would like to thank Jean-Yves Jaffray and Judy Goldsmith for fruitful discussions on this work and anonymous reviewers for their useful comments. This work has been supported by the ANR (project PHAC) which is gratefully acknowledged."}, {"heading": "I. Aron and P. van Hentenryck (2002). A constraint satisfaction approach to the robust spanning tree with", "text": "interval data. In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. 18\u201325.\nA. Chateauneuf and J. Jaffray (1995). Local-mobius transforms of monotone capacities. In C. Froidevaux and J. Kohlas (eds.), Symbolic and Quantitative Approaches to Reasoning and Uncertainty . SpringerVerlag, 115\u2013124."}, {"heading": "A. Chateauneuf and J. Tallon (2002). Diversification, convex preferences and non-empty core in the choquet", "text": "expected utlity model. Economic Theory 19:509\u2013523.\nG. Choquet (1953). Theory of capacities. Annales de l\u2019Institut Fourier 5:131\u2013295."}, {"heading": "G. De Cooman and M. C. M. Troffaes (2005). Dynamic", "text": "programming for deterministic discrete-time systems\nwith uncertain gain. International Journal of Approximate Reasoning 39:257\u2013278."}, {"heading": "D. Ellsberg (1961). Risk, ambiguity and the Savage", "text": "axioms. Quarterly Journal of Economics 75:643\u2013669."}, {"heading": "M. Grabisch (1996). The application of fuzzy integrals", "text": "in multicriteria decision making. European Journal of Operational Research 89:445\u2013456.\nJ.-Y. Jaffray (1995). On the maximum probability which is consistent with a convex capacity. International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS) 3(1):27\u201334."}, {"heading": "L. Kaebling, M. Littman, and A. Cassandra (1999). Planning and acting in partially observable stochastic", "text": "domains. Artificial Intelligence 101:99\u2013134.\nP. Kouvelis and G. Yu (1997). Robust discrete optimization and its applications. Kluwer Academic Publishers.\nL. Mandow and J. P. de la Cruz (2005). A new approach to multiobjective A\u2217 search. In Proceedings of IJCAI-05 . Professional Book Center, 218\u2013223."}, {"heading": "I. Murthy and S. Her (1992). Solving min-max", "text": "shortest-path problems on a network. Naval Research Logistics 39:669\u2013683."}, {"heading": "P. Perny and O. Spanjaard (2003). An axiomatic approach to robustness in search problems with multiple", "text": "scenarios. In Proc. of the 19th conference on Uncertainty in Artificial Intelligence. Acapulco, 469\u2013476."}, {"heading": "P. Perny, O. Spanjaard, and L. Storme (2007). State", "text": "space search for risk-averse agents. In Twentieth International Joint Conference on Artificial Intelligence. 2353\u20132358.\nM. Puterman (1994). Markov decision processes, discrete stochastic dynamic programming . Wiley & Sons."}, {"heading": "D. Schmeidler (1989). Integral representation without", "text": "additivity. Prooceedings of the American Mathematical Society 97(2):255\u2013261.\nG. Shafer (1976). A Mathematical Theory of Evidence. Princeton University Press.\nL. Shapley (1971). Cores of convex games. International Journal of Game Theory 1:11\u201322.\nB. Stewart and C. White III (1991). Multiobjective A*. Journal of the Association for Computing Machinery 38(4):775\u2013814.\nM. Wellman, K. Larson, M. Ford, and P. Wurman (1995). Path planning under time-dependent uncertainty. In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence. 532\u2013539.\nP. Wurman and M. Wellman (1996). Optimal factory scheduling using stochastic dominance A\u2217. In Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence. 554\u2013563."}], "references": [{"title": "A constraint satisfaction approach to the robust spanning tree with interval data", "author": ["I. Aron", "P. van Hentenryck"], "venue": "Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence. 18\u201325.", "citeRegEx": "Aron and Hentenryck,? 2002", "shortCiteRegEx": "Aron and Hentenryck", "year": 2002}, {"title": "Local-mobius transforms of monotone capacities", "author": ["A. Chateauneuf", "J. Jaffray"], "venue": "C. Froidevaux and J. Kohlas (eds.), Symbolic and Quantitative Approaches to Reasoning and Uncertainty . SpringerVerlag, 115\u2013124.", "citeRegEx": "Chateauneuf and Jaffray,? 1995", "shortCiteRegEx": "Chateauneuf and Jaffray", "year": 1995}, {"title": "Diversification, convex preferences and non-empty core in the choquet expected utlity model", "author": ["A. Chateauneuf", "J. Tallon"], "venue": "Economic Theory 19:509\u2013523.", "citeRegEx": "Chateauneuf and Tallon,? 2002", "shortCiteRegEx": "Chateauneuf and Tallon", "year": 2002}, {"title": "Theory of capacities", "author": ["G. Choquet"], "venue": "Annales de l\u2019Institut Fourier 5:131\u2013295.", "citeRegEx": "Choquet,? 1953", "shortCiteRegEx": "Choquet", "year": 1953}, {"title": "Dynamic programming for deterministic discrete-time systems", "author": ["G. De Cooman", "M.C.M. Troffaes"], "venue": null, "citeRegEx": "Cooman and Troffaes,? \\Q2005\\E", "shortCiteRegEx": "Cooman and Troffaes", "year": 2005}, {"title": "Risk, ambiguity and the Savage axioms", "author": ["D. Ellsberg"], "venue": "Quarterly Journal of Economics 75:643\u2013669.", "citeRegEx": "Ellsberg,? 1961", "shortCiteRegEx": "Ellsberg", "year": 1961}, {"title": "The application of fuzzy integrals in multicriteria decision making", "author": ["M. Grabisch"], "venue": "European Journal of Operational Research 89:445\u2013456.", "citeRegEx": "Grabisch,? 1996", "shortCiteRegEx": "Grabisch", "year": 1996}, {"title": "On the maximum probability which is consistent with a convex capacity", "author": ["J.-Y. Jaffray"], "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems (IJUFKS) 3(1):27\u201334.", "citeRegEx": "Jaffray,? 1995", "shortCiteRegEx": "Jaffray", "year": 1995}, {"title": "Planning and acting in partially observable stochastic domains", "author": ["L. Kaebling", "M. Littman", "A. Cassandra"], "venue": "Artificial Intelligence 101:99\u2013134.", "citeRegEx": "Kaebling et al\\.,? 1999", "shortCiteRegEx": "Kaebling et al\\.", "year": 1999}, {"title": "Robust discrete optimization and its applications", "author": ["P. Kouvelis", "G. Yu"], "venue": "Kluwer Academic Publishers.", "citeRegEx": "Kouvelis and Yu,? 1997", "shortCiteRegEx": "Kouvelis and Yu", "year": 1997}, {"title": "A new approach to multiobjective A\u2217 search", "author": ["L. Mandow", "J.P. de la Cruz"], "venue": "Proceedings of IJCAI-05 . Professional Book Center, 218\u2013223.", "citeRegEx": "Mandow and Cruz,? 2005", "shortCiteRegEx": "Mandow and Cruz", "year": 2005}, {"title": "Solving min-max shortest-path problems on a network", "author": ["I. Murthy", "S. Her"], "venue": "Naval Research Logistics 39:669\u2013683.", "citeRegEx": "Murthy and Her,? 1992", "shortCiteRegEx": "Murthy and Her", "year": 1992}, {"title": "An axiomatic approach to robustness in search problems with multiple scenarios", "author": ["P. Perny", "O. Spanjaard"], "venue": "Proc. of the 19th conference on Uncertainty in Artificial Intelligence. Acapulco, 469\u2013476.", "citeRegEx": "Perny and Spanjaard,? 2003", "shortCiteRegEx": "Perny and Spanjaard", "year": 2003}, {"title": "State space search for risk-averse agents", "author": ["P. Perny", "O. Spanjaard", "L. Storme"], "venue": "Twentieth International Joint Conference on Artificial Intelligence. 2353\u20132358.", "citeRegEx": "Perny et al\\.,? 2007", "shortCiteRegEx": "Perny et al\\.", "year": 2007}, {"title": "Markov decision processes, discrete stochastic dynamic programming", "author": ["M. Puterman"], "venue": "Wiley & Sons.", "citeRegEx": "Puterman,? 1994", "shortCiteRegEx": "Puterman", "year": 1994}, {"title": "Integral representation without additivity", "author": ["D. Schmeidler"], "venue": "Prooceedings of the American Mathematical Society 97(2):255\u2013261.", "citeRegEx": "Schmeidler,? 1989", "shortCiteRegEx": "Schmeidler", "year": 1989}, {"title": "A Mathematical Theory of Evidence", "author": ["G. Shafer"], "venue": "Princeton University Press.", "citeRegEx": "Shafer,? 1976", "shortCiteRegEx": "Shafer", "year": 1976}, {"title": "Cores of convex games", "author": ["L. Shapley"], "venue": "International Journal of Game Theory 1:11\u201322.", "citeRegEx": "Shapley,? 1971", "shortCiteRegEx": "Shapley", "year": 1971}, {"title": "Multiobjective A", "author": ["B. Stewart", "C. White III"], "venue": "Journal of the Association for Computing Machinery 38(4):775\u2013814.", "citeRegEx": "Stewart and III,? 1991", "shortCiteRegEx": "Stewart and III", "year": 1991}, {"title": "Path planning under time-dependent uncertainty", "author": ["M. Wellman", "K. Larson", "M. Ford", "P. Wurman"], "venue": "Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence. 532\u2013539.", "citeRegEx": "Wellman et al\\.,? 1995", "shortCiteRegEx": "Wellman et al\\.", "year": 1995}, {"title": "Optimal factory scheduling using stochastic dominance A\u2217", "author": ["P. Wurman", "M. Wellman"], "venue": "Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence. 554\u2013563.", "citeRegEx": "Wurman and Wellman,? 1996", "shortCiteRegEx": "Wurman and Wellman", "year": 1996}], "referenceMentions": [{"referenceID": 19, "context": "For example, Wellman and Wurman consider a case where the costs are time dependent and representable by random variables (Wellman et al., 1995).", "startOffset": 121, "endOffset": 143}, {"referenceID": 20, "context": "Moreover, an extension of this algorithm specifically designed to cope with both uncertainty and multiple criteria is proposed in (Wurman and Wellman, 1996).", "startOffset": 130, "endOffset": 156}, {"referenceID": 13, "context": "Puterman (1994), Kaebling et al.", "startOffset": 0, "endOffset": 16}, {"referenceID": 8, "context": "Puterman (1994), Kaebling et al. (1999). Beside these sources of complexity, the cost transitions between states might also be uncertain.", "startOffset": 17, "endOffset": 40}, {"referenceID": 9, "context": "This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.", "startOffset": 106, "endOffset": 129}, {"referenceID": 9, "context": "This robustness idea has actively developed in discrete optimization since the publication of the book by Kouvelis and Yu (1997), which considers several criteria imported from decision theory under total uncertainty (e.g. min-max, min-max regret) to define the absolute or relative robustness of a solution. Under these criteria, the shortest path problem becomes NP-hard, as do many other polynomially solvable problems (see e.g., Aron and van Hentenryck (2002) for robust spanning tree problems), thus bringing new algorithmic challenges.", "startOffset": 106, "endOffset": 464}, {"referenceID": 12, "context": "ordered weighted averages have been introduced and justified to model robustness in (Perny and Spanjaard, 2003), as well as a multiobjective search algorithm to determine robust solution paths in state space graphs under total uncertainty.", "startOffset": 84, "endOffset": 111}, {"referenceID": 13, "context": "This idea is exploited in (Perny et al., 2007) for path-planning under risk (when probabilities of scenarios are known), where a multiobjective heuristic search algorithm is proposed for the determination of optimal solution paths with respect to second-order stochastic dominance, or expected utility for risk-averse agents.", "startOffset": 26, "endOffset": 46}, {"referenceID": 5, "context": "An example of such a problematic situation, inspired by the so-called Ellsberg\u2019s urn example (Ellsberg, 1961), is presented below in the context of path planning:", "startOffset": 93, "endOffset": 109}, {"referenceID": 3, "context": "The standard decision model associated to capacities is based on the use of the Choquet integral, following Schmeidler (1989), who gives the foundations of the Choquet Expected Utility criterion (CEU).", "startOffset": 80, "endOffset": 126}, {"referenceID": 3, "context": "The Choquet integral (Choquet, 1953) is used in decision theory to generalize the notion of expectation when beliefs in events are represented by a capacity, i.", "startOffset": 21, "endOffset": 36}, {"referenceID": 17, "context": "In this case the core of v\u0304 defined by core(v\u0304) = {P \u2208 L, v\u0304(A) \u2264 P (A) \u2264 v(A)} where L is the set of probability measures on S is known to be non-empty since v\u0304 is convex (Shapley, 1971).", "startOffset": 172, "endOffset": 187}, {"referenceID": 3, "context": "In decision theory, the Choquet integral is often used in maximization problems under the form Cv(u(x1), . . . , u(xm)) with utility function u on payoffs to be maximized (CEU criterion, Schmeidler (1989)).", "startOffset": 24, "endOffset": 205}, {"referenceID": 2, "context": "A useful formalization of this idea is introduced in Chateauneuf and Tallon (2002) through an axiom named \u201cpreference for diversification\u201d due to its interpretation in the context of portofolio manGALAND & PERNY 127", "startOffset": 53, "endOffset": 83}, {"referenceID": 2, "context": "Interestingly enough, it is shown in Chateauneuf and Tallon (2002) that, within CEU theory, the above axiom on preference is equivalent to choosing a concave utility u and a convex capacity v.", "startOffset": 37, "endOffset": 67}, {"referenceID": 11, "context": "Hence \u03c8 v -OPT reduces to the minmax search problem, which was proved NP-hard by Murthy and Her (1992). This shows that \u03c8 v -OPT is also NP-hard.", "startOffset": 81, "endOffset": 103}, {"referenceID": 4, "context": "A similar violation of the Bellman principle is highlighted in De Cooman and Troffaes (2005), in the general framework of dynamic programming with uncertain gain and imprecise probabilities.", "startOffset": 66, "endOffset": 93}, {"referenceID": 17, "context": ",m to events (Shapley, 1971).", "startOffset": 13, "endOffset": 28}, {"referenceID": 7, "context": "This propability distribution can easily be obtained using the following greedy algorithm proposed in Jaffray (1995), where pi stands for the probability P \u2217({i}).", "startOffset": 102, "endOffset": 117}, {"referenceID": 16, "context": "We have performed the same experiments with another capacity v2 defined, for all A \u2286 S, as follows: v2(A) = \u2211 E\u2229A6=\u2205 \u03c6(E) where {\u03c6(E), E \u2286 S} are randomly drawn positive M\u00f6bius masses adding up to 1, which ensures that v2 is a plausibility function (for more details, see Shafer (1976); GALAND & PERNY 131", "startOffset": 272, "endOffset": 286}, {"referenceID": 3, "context": "Another direction might be to explore the potential of the Choquet integral in multiobjective planning problems. As shown by Grabisch (1996), the descriptive potential of the Choquet integral provides interesting possibilities in the field of multicriteria analysis.", "startOffset": 59, "endOffset": 141}], "year": 2009, "abstractText": "Choquet expected utility (CEU) is one of the most sophisticated decision criteria used in decision theory under uncertainty. It provides a generalisation of expected utility enhancing both descriptive and prescriptive possibilities. In this paper, we investigate the use of CEU for path-planning under uncertainty with a special focus on robust solutions. We first recall the main features of the CEU model and introduce some examples showing its descriptive potential. Then we focus on the search for Choquet-optimal paths in multivalued implicit graphs where costs depend on different scenarios. After discussing complexity issues, we propose two different heuristic search algorithms to solve the problem. Finally, numerical experiments are reported, showing the practical efficiency of the proposed algorithms.", "creator": "Adobe InDesign CS2 (4.0.4)"}}}