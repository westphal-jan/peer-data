{"id": "1206.5249", "review": {"conference": "arxiv", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2012", "title": "Learning Probabilistic Relational Dynamics for Multiple Tasks", "abstract": "6,400 The cleis ways kysor in which an theologische agent ' monomials s actions madhvani affect the americares world can lgus often qimin be csw modeled norrmalm compactly wilberforce using a psychometry set of relational maglaj probabilistic planning irrepressibly rules. This classier paper addresses the qu'appelle problem wenge of vmd learning such vielman rule cads sets for rebell multiple related tasks. grasslands We villefort take a 5,310 hierarchical Bayesian approach, pantyhose in which the 49-1 system deaconry learns woodhenge a 54.68 prior distribution over rule sets. 20-19 We smaug present a volunteer-run class inflammatories of prior \u6236\u90e8\u4f8d\u90ce distributions landfield parameterized by homebuying a yijun rule set prototype errorless that is 1686 stochastically modified one-seventh to simex produce a task - lafitte specific kauder rule set. We also describe otg a coordinate ascent acuvue algorithm that elucidated iteratively grasegger optimizes try-line the kc6 task - 4.60 specific uteritz rule cressman sets bulliard and the prior ci\u00eancia distribution. Experiments using this heeres algorithm supraspinatus show herdic that transferring information from jelmoli related tasks significantly chlorate reduces the millbrook amount nublense of training secr\u00e9taire data required seashell to predict olivaceous action benedick effects in belasyse blocks - world starved domains.", "histories": [["v1", "Wed, 20 Jun 2012 14:55:37 GMT  (682kb)", "http://arxiv.org/abs/1206.5249v1", "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)"]], "COMMENTS": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence (UAI2007)", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["ashwin deshpande", "brian milch", "luke s zettlemoyer", "leslie pack kaelbling"], "accepted": false, "id": "1206.5249"}, "pdf": {"name": "1206.5249.pdf", "metadata": {"source": "CRF", "title": "Learning Probabilistic Relational Dynamics for Multiple Tasks", "authors": ["Ashwin Deshpande", "Brian Milch"], "emails": ["ashwind@mit.edu", "milch@csail.mit.edu", "lsz@csail.mit.edu", "lpk@csail.mit.edu"], "sections": null, "references": [{"title": "A Bayesian/information theoretic model of learning to learn via multiple task sampling", "author": ["J. Baxter"], "venue": "Machine Learning, 28:7\u201339", "citeRegEx": "Baxter. 1997", "shortCiteRegEx": null, "year": 1997}, {"title": "Probabilistic planning in the Graphplan framework", "author": ["A.L. Blum", "J.C. Langford"], "venue": "Proc. 5th European Conference on Planning", "citeRegEx": "Blum and Langford. 1999", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning probabilistic relational dynamics for multiple tasks", "author": ["A. Deshpande"], "venue": "Master\u2019s thesis, Massachusets Institute of Technology", "citeRegEx": "Deshpande. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "An algorithm for probabilistic planning", "author": ["N. Kushmerick", "S. Hanks", "D.S. Weld"], "venue": "Artificial Intelligence, 76:239\u2013286", "citeRegEx": "Kushmerick et al.. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "The estimation of many parameters", "author": ["D.V. Lindley"], "venue": "V. P. Godambe and D. A. Sprott, editors, Foundations of Statistical Inference. Holt, Rinehart and Winston, Toronto", "citeRegEx": "Lindley. 1971", "shortCiteRegEx": null, "year": 1971}, {"title": "Transfer learning with an ensemble of background tasks", "author": ["Z. Marx", "M.T. Rosenstein", "L.P. Kaelbling", "T.G. Dietterich"], "venue": "NIPS Workshop on Inductive Transfer", "citeRegEx": "Marx et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Estimating a Dirichlet distribution", "author": ["T.P. Minka"], "venue": "Available at http://research.microsoft.com/ \u223cminka/papers/dirichlet", "citeRegEx": "Minka. 2003", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning probabilistic relational planning rules", "author": ["H.M. Pasula", "L.S. Zettlemoyer", "L.P. Kaelbling"], "venue": "Proc. 14th International Conference on Automated Planning and Scheduling", "citeRegEx": "Pasula et al.. 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning Gaussian processes from multiple tasks", "author": ["K. Yu", "V. Tresp", "A. Schwaighofer"], "venue": "Proc. 22nd International Conference on Machine Learning", "citeRegEx": "Yu et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning planning rules in noisy stochastic worlds", "author": ["L.S. Zettlemoyer", "H.M. Pasula", "L.P. Kaelbling"], "venue": "Proc. 20th National Conference on Artificial Intelligence", "citeRegEx": "Zettlemoyer et al.. 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning multiple related tasks using latent independent component analysis", "author": ["J. Zhang", "Z. Ghahramani", "Y. Yang"], "venue": "Advances in Neural Information Processing Systems 18. MIT Press", "citeRegEx": "Zhang et al.. 2006", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 3, "context": "Such knowledge can be encoded compactly as a set of probabilistic planning rules [Kushmerick et al., 1995; Blum and Langford, 1999].", "startOffset": 81, "endOffset": 131}, {"referenceID": 1, "context": "Such knowledge can be encoded compactly as a set of probabilistic planning rules [Kushmerick et al., 1995; Blum and Langford, 1999].", "startOffset": 81, "endOffset": 131}, {"referenceID": 7, "context": "Algorithms have been developed for learning relational probabilistic planning rules by observing the effects of actions [Pasula et al., 2004; Zettlemoyer et al., 2005].", "startOffset": 120, "endOffset": 167}, {"referenceID": 9, "context": "Algorithms have been developed for learning relational probabilistic planning rules by observing the effects of actions [Pasula et al., 2004; Zettlemoyer et al., 2005].", "startOffset": 120, "endOffset": 167}, {"referenceID": 4, "context": "In statistics, the problem of transferring predictions across related data sets has been addressed with hierarchical Bayesian models [Lindley, 1971].", "startOffset": 133, "endOffset": 148}, {"referenceID": 8, "context": "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].", "startOffset": 148, "endOffset": 204}, {"referenceID": 5, "context": "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].", "startOffset": 148, "endOffset": 204}, {"referenceID": 10, "context": "The first use of such models for the multi-task learning problem appears to be due to Baxter [1997]; the approach has recently become quite popular [Yu et al., 2005; Marx et al., 2005; Zhang et al., 2006].", "startOffset": 148, "endOffset": 204}, {"referenceID": 9, "context": "In this section, we present a simplified version of the representation developed by [Zettlemoyer et al., 2005].", "startOffset": 84, "endOffset": 110}, {"referenceID": 9, "context": "Noise outcomes allow rule learners to ignore overly complex, rare action effects and have been shown to improve learning in noisy domains [Zettlemoyer et al., 2005].", "startOffset": 138, "endOffset": 164}, {"referenceID": 6, "context": "Integrating out the outcome probabilities p in each rule is not a computational bottleneck: we can push the integral inside the sums over a and b, and use a modified version of a standard estimation technique [Minka, 2003] for the Polya (or Dirichlet-multinomial) parameters.", "startOffset": 209, "endOffset": 222}, {"referenceID": 9, "context": "Rules can be created by an ExplainExamples procedure [Zettlemoyer et al., 2005] which uses a heuristic search to find high quality potential rules in a data driven manner.", "startOffset": 53, "endOffset": 79}, {"referenceID": 7, "context": "This algorithm is a modified version of a previous outcome search procedure [Pasula et al., 2004], which has been changed to ensure that the outcomes do not overlap.", "startOffset": 76, "endOffset": 97}, {"referenceID": 7, "context": "Possible additions include any outcomes from the corresponding prototype rule or an outcome derived from concatenating the changes seen as a result of action effects in a training example (following [Pasula et al., 2004]).", "startOffset": 199, "endOffset": 220}, {"referenceID": 6, "context": "Estimating the Dirichlet parameters for the Polya distribution does not have a closed form solution, but gradient ascent techniques have been developed for the maximum likelihood solution [Minka, 2003].", "startOffset": 188, "endOffset": 201}, {"referenceID": 3, "context": "To see how transfer learning works for more complex rule sets, our next experiment uses a \u201cslippery gripper\u201d domain adapted from [Kushmerick et al., 1995].", "startOffset": 129, "endOffset": 154}], "year": 2009, "abstractText": "The ways in which an agent\u2019s actions affect the world can often be modeled compactly using a set of relational probabilistic planning rules. This paper addresses the problem of learning such rule sets for multiple related tasks. We take a hierarchical Bayesian approach, in which the system learns a prior distribution over rule sets. We present a class of prior distributions parameterized by a rule set prototype that is stochastically modified to produce a task-specific rule set. We also describe a coordinate ascent algorithm that iteratively optimizes the task-specific rule sets and the prior distribution. Experiments using this algorithm show that transferring information from related tasks significantly reduces the amount of training data required to predict action effects in blocks-world domains.", "creator": "Adobe InDesign CS2 (4.0.4)"}}}